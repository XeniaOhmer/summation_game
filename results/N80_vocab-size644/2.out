# ["--N=80", "--n_epochs=250", "--batch_size=32", "--lr=0.001", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=1", "--n_layers=3", "--save_run=1", "--n_symbols=644"]
Namespace(N=80, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=250, n_layers=3, n_runs=1, n_summands=2, n_symbols=644, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1375851505, receiver_embed_dim=64, save_run=True, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.4030423164367676, acc=0.20302794873714447, loss=2.4030423164367676
test: epoch 1, loss 5.825486183166504, acc=0.058594413101673126, loss=5.825486183166504
train: epoch 2, loss 1.3801794052124023, acc=0.4067400395870209, loss=1.3801794052124023
test: epoch 2, loss 4.991123199462891, acc=0.08924639970064163, loss=4.991123199462891
train: epoch 3, loss 1.1597925424575806, acc=0.4915461540222168, loss=1.1597925424575806
test: epoch 3, loss 4.605321407318115, acc=0.11075359582901001, loss=4.605321407318115
train: epoch 4, loss 0.9897175431251526, acc=0.5734055638313293, loss=0.9897175431251526
test: epoch 4, loss 3.926137924194336, acc=0.15207451581954956, loss=3.926137924194336
train: epoch 5, loss 0.7840240597724915, acc=0.6756037473678589, loss=0.7840240597724915
test: epoch 5, loss 5.082491874694824, acc=0.1568162590265274, loss=5.082491874694824
train: epoch 6, loss 0.6084955930709839, acc=0.7565114498138428, loss=0.6084955930709839
test: epoch 6, loss 4.155519008636475, acc=0.17290431261062622, loss=4.155519008636475
train: epoch 7, loss 0.5081474781036377, acc=0.7998238801956177, loss=0.5081474781036377
test: epoch 7, loss 4.030731678009033, acc=0.21608805656433105, loss=4.030731678009033
train: epoch 8, loss 0.42170342803001404, acc=0.8389838933944702, loss=0.42170342803001404
test: epoch 8, loss 3.933298110961914, acc=0.24267569184303284, loss=3.933298110961914
train: epoch 9, loss 0.32079803943634033, acc=0.8845012784004211, loss=0.32079803943634033
test: epoch 9, loss 3.843275547027588, acc=0.24572396278381348, loss=3.843275547027588
train: epoch 10, loss 0.24791695177555084, acc=0.9137205481529236, loss=0.24791695177555084
test: epoch 10, loss 3.16719651222229, acc=0.29009315371513367, loss=3.16719651222229
train: epoch 11, loss 0.20812956988811493, acc=0.9295647740364075, loss=0.20812956988811493
test: epoch 11, loss 3.2759103775024414, acc=0.26977136731147766, loss=3.2759103775024414
train: epoch 12, loss 0.18113970756530762, acc=0.9403589963912964, loss=0.18113970756530762
test: epoch 12, loss 3.5023715496063232, acc=0.2563928961753845, loss=3.5023715496063232
train: epoch 13, loss 0.16437900066375732, acc=0.9464454054832458, loss=0.16437900066375732
test: epoch 13, loss 3.0664615631103516, acc=0.3058425188064575, loss=3.0664615631103516
train: epoch 14, loss 0.15116214752197266, acc=0.950980544090271, loss=0.15116214752197266
test: epoch 14, loss 3.0005970001220703, acc=0.2922946512699127, loss=3.0005970001220703
train: epoch 15, loss 0.14176738262176514, acc=0.9541574716567993, loss=0.14176738262176514
test: epoch 15, loss 3.32613468170166, acc=0.3117696940898895, loss=3.32613468170166
train: epoch 16, loss 0.134162038564682, acc=0.9568061232566833, loss=0.134162038564682
test: epoch 16, loss 2.938575029373169, acc=0.320406436920166, loss=2.938575029373169
train: epoch 17, loss 0.12600316107273102, acc=0.95932936668396, loss=0.12600316107273102
test: epoch 17, loss 3.105213165283203, acc=0.3325994908809662, loss=3.105213165283203
train: epoch 18, loss 0.12160336971282959, acc=0.9607011079788208, loss=0.12160336971282959
test: epoch 18, loss 2.803579568862915, acc=0.3224385976791382, loss=2.803579568862915
train: epoch 19, loss 0.11684716492891312, acc=0.9627942442893982, loss=0.11684716492891312
test: epoch 19, loss 3.151825189590454, acc=0.3366638422012329, loss=3.151825189590454
train: epoch 20, loss 0.11115436255931854, acc=0.9651380181312561, loss=0.11115436255931854
test: epoch 20, loss 2.579709053039551, acc=0.37392041087150574, loss=2.579709053039551
train: epoch 21, loss 0.10882681608200073, acc=0.9657612442970276, loss=0.10882681608200073
test: epoch 21, loss 2.5367772579193115, acc=0.3879762887954712, loss=2.5367772579193115
train: epoch 22, loss 0.1047341600060463, acc=0.9672210216522217, loss=0.1047341600060463
test: epoch 22, loss 2.5856385231018066, acc=0.37815409898757935, loss=2.5856385231018066
train: epoch 23, loss 0.10164106637239456, acc=0.9680948257446289, loss=0.10164106637239456
test: epoch 23, loss 2.2914698123931885, acc=0.37476715445518494, loss=2.2914698123931885
train: epoch 24, loss 0.09890609234571457, acc=0.9691922068595886, loss=0.09890609234571457
test: epoch 24, loss 2.2489705085754395, acc=0.4237087070941925, loss=2.2489705085754395
train: epoch 25, loss 0.09510393440723419, acc=0.9706621766090393, loss=0.09510393440723419
test: epoch 25, loss 2.26554012298584, acc=0.42235392332077026, loss=2.26554012298584
train: epoch 26, loss 0.09514350444078445, acc=0.9707434177398682, loss=0.09514350444078445
test: epoch 26, loss 2.5070431232452393, acc=0.4057578444480896, loss=2.5070431232452393
train: epoch 27, loss 0.08978749811649323, acc=0.972470760345459, loss=0.08978749811649323
test: epoch 27, loss 2.240640640258789, acc=0.4613039791584015, loss=2.240640640258789
train: epoch 28, loss 0.08895555883646011, acc=0.9734428524971008, loss=0.08895555883646011
test: epoch 28, loss 2.5546531677246094, acc=0.4558848440647125, loss=2.5546531677246094
train: epoch 29, loss 0.08525516092777252, acc=0.9743776321411133, loss=0.08525516092777252
test: epoch 29, loss 2.385178804397583, acc=0.4604572355747223, loss=2.385178804397583
train: epoch 30, loss 0.08183181285858154, acc=0.9750415086746216, loss=0.08183181285858154
test: epoch 30, loss 2.3210065364837646, acc=0.44640135765075684, loss=2.3210065364837646
train: epoch 31, loss 0.08220016211271286, acc=0.9756511449813843, loss=0.08220016211271286
test: epoch 31, loss 1.9937224388122559, acc=0.5156646966934204, loss=1.9937224388122559
train: epoch 32, loss 0.07822320610284805, acc=0.9763928651809692, loss=0.07822320610284805
test: epoch 32, loss 2.0796456336975098, acc=0.5244708061218262, loss=2.0796456336975098
train: epoch 33, loss 0.07745577394962311, acc=0.9773716926574707, loss=0.07745577394962311
test: epoch 33, loss 2.1841135025024414, acc=0.4789161682128906, loss=2.1841135025024414
train: epoch 34, loss 0.07362767308950424, acc=0.9783302545547485, loss=0.07362767308950424
test: epoch 34, loss 2.3767054080963135, acc=0.4723115861415863, loss=2.3767054080963135
train: epoch 35, loss 0.0734635517001152, acc=0.9788112044334412, loss=0.0734635517001152
test: epoch 35, loss 1.8257311582565308, acc=0.5271803736686707, loss=1.8257311582565308
train: epoch 36, loss 0.06999295949935913, acc=0.9793260097503662, loss=0.06999295949935913
test: epoch 36, loss 1.9810476303100586, acc=0.5261642932891846, loss=1.9810476303100586
train: epoch 37, loss 0.06835802644491196, acc=0.9801591634750366, loss=0.06835802644491196
test: epoch 37, loss 1.816937804222107, acc=0.5559695363044739, loss=1.816937804222107
train: epoch 38, loss 0.06772653013467789, acc=0.9802506566047668, loss=0.06772653013467789
test: epoch 38, loss 1.7955946922302246, acc=0.5771380066871643, loss=1.7955946922302246
train: epoch 39, loss 0.06839971244335175, acc=0.9808095097541809, loss=0.06839971244335175
test: epoch 39, loss 1.7159687280654907, acc=0.5895004272460938, loss=1.7159687280654907
train: epoch 40, loss 0.06603699177503586, acc=0.9814360737800598, loss=0.06603699177503586
test: epoch 40, loss 1.6866116523742676, acc=0.5661303997039795, loss=1.6866116523742676
train: epoch 41, loss 0.06293654441833496, acc=0.9822760224342346, loss=0.06293654441833496
test: epoch 41, loss 1.5940099954605103, acc=0.5786621570587158, loss=1.5940099954605103
train: epoch 42, loss 0.06076137349009514, acc=0.9830178022384644, loss=0.06076137349009514
test: epoch 42, loss 1.5719633102416992, acc=0.6331921815872192, loss=1.5719633102416992
train: epoch 43, loss 0.0583878755569458, acc=0.9836850166320801, loss=0.0583878755569458
test: epoch 43, loss 1.602230191230774, acc=0.6269263625144958, loss=1.602230191230774
train: epoch 44, loss 0.06165284290909767, acc=0.9838238954544067, loss=0.06165284290909767
test: epoch 44, loss 1.5172685384750366, acc=0.6179509162902832, loss=1.5172685384750366
train: epoch 45, loss 0.05462132766842842, acc=0.985198974609375, loss=0.05462132766842842
test: epoch 45, loss 1.9511983394622803, acc=0.6323454976081848, loss=1.9511983394622803
train: epoch 46, loss 0.056983914226293564, acc=0.9844945073127747, loss=0.056983914226293564
test: epoch 46, loss 1.5223926305770874, acc=0.6775614023208618, loss=1.5223926305770874
train: epoch 47, loss 0.054388441145420074, acc=0.9857747554779053, loss=0.054388441145420074
test: epoch 47, loss 1.0799660682678223, acc=0.6972057819366455, loss=1.0799660682678223
train: epoch 48, loss 0.05110723897814751, acc=0.9866587519645691, loss=0.05110723897814751
test: epoch 48, loss 1.165103554725647, acc=0.7202370762825012, loss=1.165103554725647
train: epoch 49, loss 0.0500824898481369, acc=0.9867434501647949, loss=0.0500824898481369
test: epoch 49, loss 1.2835181951522827, acc=0.7412362694740295, loss=1.2835181951522827
train: epoch 50, loss 0.0485818088054657, acc=0.9870855212211609, loss=0.0485818088054657
test: epoch 50, loss 0.9506275057792664, acc=0.7662997245788574, loss=0.9506275057792664
train: epoch 51, loss 0.0480843223631382, acc=0.9875664710998535, loss=0.0480843223631382
test: epoch 51, loss 1.1006503105163574, acc=0.755800187587738, loss=1.1006503105163574
train: epoch 52, loss 0.04451005533337593, acc=0.988558828830719, loss=0.04451005533337593
test: epoch 52, loss 0.7007569670677185, acc=0.7857747673988342, loss=0.7007569670677185
train: epoch 53, loss 0.04409163072705269, acc=0.988988995552063, loss=0.04409163072705269
test: epoch 53, loss 0.8479668498039246, acc=0.8023708462715149, loss=0.8479668498039246
train: epoch 54, loss 0.04351004958152771, acc=0.9892430305480957, loss=0.04351004958152771
test: epoch 54, loss 0.6029995083808899, acc=0.8574090003967285, loss=0.6029995083808899
train: epoch 55, loss 0.040872346609830856, acc=0.9898154139518738, loss=0.040872346609830856
test: epoch 55, loss 0.4956524968147278, acc=0.8674005270004272, loss=0.4956524968147278
train: epoch 56, loss 0.037169136106967926, acc=0.9912548661231995, loss=0.037169136106967926
test: epoch 56, loss 0.5310750007629395, acc=0.8535139560699463, loss=0.5310750007629395
train: epoch 57, loss 0.035880088806152344, acc=0.9915732145309448, loss=0.035880088806152344
test: epoch 57, loss 0.39277589321136475, acc=0.8831498622894287, loss=0.39277589321136475
train: epoch 58, loss 0.03665432333946228, acc=0.991664707660675, loss=0.03665432333946228
test: epoch 58, loss 0.5302212238311768, acc=0.8843352794647217, loss=0.5302212238311768
train: epoch 59, loss 0.03350703790783882, acc=0.9921591877937317, loss=0.03350703790783882
test: epoch 59, loss 0.546149730682373, acc=0.8887383341789246, loss=0.546149730682373
train: epoch 60, loss 0.032113928347826004, acc=0.9924978613853455, loss=0.032113928347826004
test: epoch 60, loss 0.27493682503700256, acc=0.9280270934104919, loss=0.27493682503700256
train: epoch 61, loss 0.034369099885225296, acc=0.9928331971168518, loss=0.034369099885225296
test: epoch 61, loss 0.23778605461120605, acc=0.9287045001983643, loss=0.23778605461120605
train: epoch 62, loss 0.027685249224305153, acc=0.9943505525588989, loss=0.027685249224305153
test: epoch 62, loss 0.177738219499588, acc=0.9581710696220398, loss=0.177738219499588
train: epoch 63, loss 0.02617764100432396, acc=0.9946418404579163, loss=0.02617764100432396
test: epoch 63, loss 0.1415938287973404, acc=0.96782386302948, loss=0.1415938287973404
train: epoch 64, loss 0.02791452780365944, acc=0.9947231411933899, loss=0.02791452780365944
test: epoch 64, loss 0.1711447685956955, acc=0.9625740647315979, loss=0.1711447685956955
train: epoch 65, loss 0.024525174871087074, acc=0.9952446818351746, loss=0.024525174871087074
test: epoch 65, loss 0.14622345566749573, acc=0.974259078502655, loss=0.14622345566749573
train: epoch 66, loss 0.027993539348244667, acc=0.9949601888656616, loss=0.027993539348244667
test: epoch 66, loss 0.03880167007446289, acc=0.989331066608429, loss=0.03880167007446289
train: epoch 67, loss 0.02407245710492134, acc=0.9958171248435974, loss=0.02407245710492134
test: epoch 67, loss 0.0540248267352581, acc=0.9913632273674011, loss=0.0540248267352581
