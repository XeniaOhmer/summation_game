# ["--N=40", "--n_epochs=250", "--batch_size=32", "--lr=0.001", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=1", "--n_layers=3", "--save_run=1", "--n_symbols=324"]
Namespace(n_summands=2, N=40, test_split=0.1, data_scaling=50, one_hot=True, receiver_embed_dim=64, n_layers=3, n_symbols=324, temperature=2.0, temp_decay=0.995, early_stopping_acc=0.99, n_runs=1, save_run=True, random_seed=1380959143, checkpoint_dir=None, preemptable=False, checkpoint_freq=0, validation_freq=1, n_epochs=250, load_from_checkpoint=None, no_cuda=True, batch_size=32, optimizer='adam', lr=0.001, update_freq=1, vocab_size=10, max_len=1, tensorboard=False, tensorboard_dir='runs/', distributed_port=18363, fp16=False, cuda=False, device=device(type='cpu'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'))
train: epoch 1, loss 2.7671265602111816, acc=0.11421018093824387, loss=2.7671265602111816
test: epoch 1, loss 7.187354564666748, acc=0.07005948573350906, loss=7.187354564666748
train: epoch 2, loss 1.5766674280166626, acc=0.35074687004089355, loss=1.5766674280166626
test: epoch 2, loss 4.242994785308838, acc=0.1487111747264862, loss=4.242994785308838
train: epoch 3, loss 1.1041361093521118, acc=0.5324652791023254, loss=1.1041361093521118
test: epoch 3, loss 3.8853166103363037, acc=0.1579643040895462, loss=3.8853166103363037
train: epoch 4, loss 1.044974684715271, acc=0.5481824278831482, loss=1.044974684715271
test: epoch 4, loss 3.7752912044525146, acc=0.1870456039905548, loss=3.7752912044525146
train: epoch 5, loss 0.8708101511001587, acc=0.6299405097961426, loss=0.8708101511001587
test: epoch 5, loss 3.1626148223876953, acc=0.24190349876880646, loss=3.1626148223876953
train: epoch 6, loss 0.7284414172172546, acc=0.698228657245636, loss=0.7284414172172546
test: epoch 6, loss 3.3748602867126465, acc=0.2571050822734833, loss=3.3748602867126465
train: epoch 7, loss 0.5581132769584656, acc=0.7791143655776978, loss=0.5581132769584656
test: epoch 7, loss 3.1220364570617676, acc=0.2828816771507263, loss=3.1220364570617676
train: epoch 8, loss 0.4848620891571045, acc=0.8101123571395874, loss=0.4848620891571045
test: epoch 8, loss 2.9148621559143066, acc=0.31328487396240234, loss=2.9148621559143066
train: epoch 9, loss 0.4049924314022064, acc=0.847534716129303, loss=0.4049924314022064
test: epoch 9, loss 3.2282862663269043, acc=0.2927957773208618, loss=3.2282862663269043
train: epoch 10, loss 0.3872808814048767, acc=0.8557699918746948, loss=0.3872808814048767
test: epoch 10, loss 3.4086830615997314, acc=0.26503634452819824, loss=3.4086830615997314
train: epoch 11, loss 0.3979867100715637, acc=0.8458294868469238, loss=0.3979867100715637
test: epoch 11, loss 2.9887328147888184, acc=0.3106411099433899, loss=2.9887328147888184
train: epoch 12, loss 0.3976730406284332, acc=0.8469530940055847, loss=0.3976730406284332
test: epoch 12, loss 2.6020381450653076, acc=0.33773958683013916, loss=2.6020381450653076
train: epoch 13, loss 0.24177555739879608, acc=0.9172108173370361, loss=0.24177555739879608
test: epoch 13, loss 2.8473079204559326, acc=0.3721083998680115, loss=2.8473079204559326
train: epoch 14, loss 0.22087769210338593, acc=0.9231328368186951, loss=0.22087769210338593
test: epoch 14, loss 2.68709135055542, acc=0.35558491945266724, loss=2.68709135055542
train: epoch 15, loss 0.1931534707546234, acc=0.9334434866905212, loss=0.1931534707546234
test: epoch 15, loss 2.6682052612304688, acc=0.35095834732055664, loss=2.6682052612304688
train: epoch 16, loss 0.17190271615982056, acc=0.942802369594574, loss=0.17190271615982056
test: epoch 16, loss 3.129695415496826, acc=0.34104427695274353, loss=3.129695415496826
train: epoch 17, loss 0.15755993127822876, acc=0.9481163024902344, loss=0.15755993127822876
test: epoch 17, loss 2.119891881942749, acc=0.42630535364151, loss=2.119891881942749
train: epoch 18, loss 0.13768650591373444, acc=0.9561929702758789, loss=0.13768650591373444
test: epoch 18, loss 2.3467094898223877, acc=0.3787177801132202, loss=2.3467094898223877
train: epoch 19, loss 0.13489283621311188, acc=0.9572504758834839, loss=0.13489283621311188
test: epoch 19, loss 1.8357363939285278, acc=0.46662259101867676, loss=1.8357363939285278
train: epoch 20, loss 0.12433934956789017, acc=0.961348295211792, loss=0.12433934956789017
test: epoch 20, loss 2.30072021484375, acc=0.40515533089637756, loss=2.30072021484375
train: epoch 21, loss 0.11628658324480057, acc=0.9633179306983948, loss=0.11628658324480057
test: epoch 21, loss 2.4516923427581787, acc=0.42366158962249756, loss=2.4516923427581787
train: epoch 22, loss 0.11318320780992508, acc=0.9649834632873535, loss=0.11318320780992508
test: epoch 22, loss 2.6915712356567383, acc=0.3932584226131439, loss=2.6915712356567383
train: epoch 23, loss 0.10109511017799377, acc=0.968684732913971, loss=0.10109511017799377
test: epoch 23, loss 2.1617772579193115, acc=0.41440844535827637, loss=2.1617772579193115
train: epoch 24, loss 0.10340853035449982, acc=0.9674421548843384, loss=0.10340853035449982
test: epoch 24, loss 2.1896698474884033, acc=0.4884335696697235, loss=2.1896698474884033
train: epoch 25, loss 0.10149283707141876, acc=0.9689226746559143, loss=0.10149283707141876
test: epoch 25, loss 2.142517566680908, acc=0.4778585731983185, loss=2.142517566680908
train: epoch 26, loss 0.09463805705308914, acc=0.9714342355728149, loss=0.09463805705308914
test: epoch 26, loss 2.1147027015686035, acc=0.4408459961414337, loss=2.1147027015686035
train: epoch 27, loss 0.09438709169626236, acc=0.9705353379249573, loss=0.09438709169626236
test: epoch 27, loss 2.2607102394104004, acc=0.37012559175491333, loss=2.2607102394104004
train: epoch 28, loss 0.08929844200611115, acc=0.9724124073982239, loss=0.08929844200611115
test: epoch 28, loss 1.9046094417572021, acc=0.4692663550376892, loss=1.9046094417572021
train: epoch 29, loss 0.08666291832923889, acc=0.9737078547477722, loss=0.08666291832923889
test: epoch 29, loss 2.117055892944336, acc=0.4923992156982422, loss=2.117055892944336
train: epoch 30, loss 0.082236647605896, acc=0.9763251543045044, loss=0.082236647605896
test: epoch 30, loss 1.861092209815979, acc=0.5267680287361145, loss=1.861092209815979
train: epoch 31, loss 0.08382801711559296, acc=0.975175142288208, loss=0.08382801711559296
test: epoch 31, loss 2.1575610637664795, acc=0.46728354692459106, loss=2.1575610637664795
train: epoch 32, loss 0.08343973755836487, acc=0.9749768376350403, loss=0.08343973755836487
test: epoch 32, loss 1.695611834526062, acc=0.4983476400375366, loss=1.695611834526062
train: epoch 33, loss 0.07907862961292267, acc=0.9758228659629822, loss=0.07907862961292267
test: epoch 33, loss 2.0965237617492676, acc=0.45142102241516113, loss=2.0965237617492676
train: epoch 34, loss 0.07819236814975739, acc=0.9762458801269531, loss=0.07819236814975739
test: epoch 34, loss 1.8909777402877808, acc=0.5023132562637329, loss=1.8909777402877808
train: epoch 35, loss 0.08000293374061584, acc=0.9759153723716736, loss=0.08000293374061584
test: epoch 35, loss 1.877816081047058, acc=0.529411792755127, loss=1.877816081047058
train: epoch 36, loss 0.07257512956857681, acc=0.9784930348396301, loss=0.07257512956857681
test: epoch 36, loss 1.6825319528579712, acc=0.5657633543014526, loss=1.6825319528579712
train: epoch 37, loss 0.07977723330259323, acc=0.9763780832290649, loss=0.07977723330259323
test: epoch 37, loss 1.6918569803237915, acc=0.5532055497169495, loss=1.6918569803237915
train: epoch 38, loss 0.07074722647666931, acc=0.9791143536567688, loss=0.07074722647666931
test: epoch 38, loss 1.6137133836746216, acc=0.5591539740562439, loss=1.6137133836746216
train: epoch 39, loss 0.06335493177175522, acc=0.9807931184768677, loss=0.06335493177175522
test: epoch 39, loss 1.5192452669143677, acc=0.5783212184906006, loss=1.5192452669143677
train: epoch 40, loss 0.07266083359718323, acc=0.9785856008529663, loss=0.07266083359718323
test: epoch 40, loss 1.561437964439392, acc=0.5994712710380554, loss=1.561437964439392
train: epoch 41, loss 0.06860111653804779, acc=0.9792729616165161, loss=0.06860111653804779
test: epoch 41, loss 1.4115244150161743, acc=0.6331791281700134, loss=1.4115244150161743
train: epoch 42, loss 0.06760574877262115, acc=0.9805287718772888, loss=0.06760574877262115
test: epoch 42, loss 1.4387634992599487, acc=0.6206212639808655, loss=1.4387634992599487
train: epoch 43, loss 0.06095949932932854, acc=0.9817977547645569, loss=0.06095949932932854
test: epoch 43, loss 1.3779826164245605, acc=0.6721745133399963, loss=1.3779826164245605
train: epoch 44, loss 0.06503521651029587, acc=0.9808724522590637, loss=0.06503521651029587
test: epoch 44, loss 1.0269252061843872, acc=0.7072042226791382, loss=1.0269252061843872
train: epoch 45, loss 0.0618862621486187, acc=0.9821810722351074, loss=0.0618862621486187
test: epoch 45, loss 1.2194617986679077, acc=0.6939854621887207, loss=1.2194617986679077
train: epoch 46, loss 0.05982045829296112, acc=0.9827495217323303, loss=0.05982045829296112
test: epoch 46, loss 1.1315118074417114, acc=0.7309980392456055, loss=1.1315118074417114
train: epoch 47, loss 0.058595988899469376, acc=0.98342365026474, loss=0.058595988899469376
test: epoch 47, loss 0.9825491905212402, acc=0.7290152311325073, loss=0.9825491905212402
train: epoch 48, loss 0.05407196655869484, acc=0.9845207929611206, loss=0.05407196655869484
test: epoch 48, loss 0.9793845415115356, acc=0.7614011764526367, loss=0.9793845415115356
train: epoch 49, loss 0.055687882006168365, acc=0.983780562877655, loss=0.055687882006168365
test: epoch 49, loss 0.8120790123939514, acc=0.7732980847358704, loss=0.8120790123939514
train: epoch 50, loss 0.056176330894231796, acc=0.9842564463615417, loss=0.056176330894231796
test: epoch 50, loss 0.8267191052436829, acc=0.7561137080192566, loss=0.8267191052436829
train: epoch 51, loss 0.05299758166074753, acc=0.9854064583778381, loss=0.05299758166074753
test: epoch 51, loss 0.7266367077827454, acc=0.8070059418678284, loss=0.7266367077827454
train: epoch 52, loss 0.0520942360162735, acc=0.9853800535202026, loss=0.0520942360162735
test: epoch 52, loss 0.48816826939582825, acc=0.8499669432640076, loss=0.48816826939582825
train: epoch 53, loss 0.05116696655750275, acc=0.9859352111816406, loss=0.05116696655750275
test: epoch 53, loss 0.5565890073776245, acc=0.8565763235092163, loss=0.5565890073776245
train: epoch 54, loss 0.04409436881542206, acc=0.9879048466682434, loss=0.04409436881542206
test: epoch 54, loss 0.46669435501098633, acc=0.8737607598304749, loss=0.46669435501098633
train: epoch 55, loss 0.04475918784737587, acc=0.9880369901657104, loss=0.04475918784737587
test: epoch 55, loss 0.3174351751804352, acc=0.9028420448303223, loss=0.3174351751804352
train: epoch 56, loss 0.04393993318080902, acc=0.988499641418457, loss=0.04393993318080902
test: epoch 56, loss 0.3253953158855438, acc=0.920026421546936, loss=0.3253953158855438
train: epoch 57, loss 0.04253733903169632, acc=0.9885525703430176, loss=0.04253733903169632
test: epoch 57, loss 0.3159492015838623, acc=0.9339061379432678, loss=0.3159492015838623
train: epoch 58, loss 0.037991300225257874, acc=0.9902445673942566, loss=0.037991300225257874
test: epoch 58, loss 0.2771381437778473, acc=0.9332451820373535, loss=0.2771381437778473
train: epoch 59, loss 0.038620878010988235, acc=0.9899405241012573, loss=0.038620878010988235
test: epoch 59, loss 0.18331874907016754, acc=0.9583608508110046, loss=0.18331874907016754
train: epoch 60, loss 0.033874597400426865, acc=0.9918043613433838, loss=0.033874597400426865
test: epoch 60, loss 0.20316660404205322, acc=0.9563780426979065, loss=0.20316660404205322
train: epoch 61, loss 0.036544524133205414, acc=0.9911566376686096, loss=0.036544524133205414
test: epoch 61, loss 0.20159189403057098, acc=0.9471248984336853, loss=0.20159189403057098
train: epoch 62, loss 0.028227221220731735, acc=0.992729663848877, loss=0.028227221220731735
test: epoch 62, loss 0.16375721991062164, acc=0.9596827626228333, loss=0.16375721991062164
train: epoch 63, loss 0.029886798933148384, acc=0.9926239252090454, loss=0.029886798933148384
test: epoch 63, loss 0.06773804873228073, acc=0.9689359068870544, loss=0.06773804873228073
train: epoch 64, loss 0.026040131226181984, acc=0.9935359954833984, loss=0.026040131226181984
test: epoch 64, loss 0.0745820701122284, acc=0.9788499474525452, loss=0.0745820701122284
train: epoch 65, loss 0.023887891322374344, acc=0.9938268065452576, loss=0.023887891322374344
test: epoch 65, loss 0.04468220844864845, acc=0.9742233753204346, loss=0.04468220844864845
train: epoch 66, loss 0.02364571951329708, acc=0.9941837191581726, loss=0.02364571951329708
test: epoch 66, loss 0.09269046038389206, acc=0.9722405672073364, loss=0.09269046038389206
train: epoch 67, loss 0.021826403215527534, acc=0.9950958490371704, loss=0.021826403215527534
test: epoch 67, loss 0.057455874979496, acc=0.9801718592643738, loss=0.057455874979496
train: epoch 68, loss 0.020942261442542076, acc=0.9949768781661987, loss=0.020942261442542076
test: epoch 68, loss 0.16209448873996735, acc=0.973562479019165, loss=0.16209448873996735
train: epoch 69, loss 0.021170884370803833, acc=0.9949504137039185, loss=0.021170884370803833
test: epoch 69, loss 0.08639038354158401, acc=0.9742233753204346, loss=0.08639038354158401
train: epoch 70, loss 0.018680721521377563, acc=0.995479166507721, loss=0.018680721521377563
test: epoch 70, loss 0.0655534639954567, acc=0.9808327555656433, loss=0.0655534639954567
train: epoch 71, loss 0.020246699452400208, acc=0.9952280521392822, loss=0.020246699452400208
test: epoch 71, loss 0.07129935175180435, acc=0.976867139339447, loss=0.07129935175180435
train: epoch 72, loss 0.022813182324171066, acc=0.9951619505882263, loss=0.022813182324171066
test: epoch 72, loss 0.0629667267203331, acc=0.9808327555656433, loss=0.0629667267203331
train: epoch 73, loss 0.02019227109849453, acc=0.9958493113517761, loss=0.02019227109849453
test: epoch 73, loss 0.12758225202560425, acc=0.9742233753204346, loss=0.12758225202560425
train: epoch 74, loss 0.018642187118530273, acc=0.9955849051475525, loss=0.018642187118530273
test: epoch 74, loss 0.05443404242396355, acc=0.9828156232833862, loss=0.05443404242396355
train: epoch 75, loss 0.013451159000396729, acc=0.9967746138572693, loss=0.013451159000396729
test: epoch 75, loss 0.04294663295149803, acc=0.9814937114715576, loss=0.04294663295149803
train: epoch 76, loss 0.019983729347586632, acc=0.9959550499916077, loss=0.019983729347586632
test: epoch 76, loss 0.0922185406088829, acc=0.9821546673774719, loss=0.0922185406088829
train: epoch 77, loss 0.023970648646354675, acc=0.9952412247657776, loss=0.023970648646354675
test: epoch 77, loss 0.05998152494430542, acc=0.9821546673774719, loss=0.05998152494430542
train: epoch 78, loss 0.017385728657245636, acc=0.9965763092041016, loss=0.017385728657245636
test: epoch 78, loss 0.08495098352432251, acc=0.9821546673774719, loss=0.08495098352432251
train: epoch 79, loss 0.015002401545643806, acc=0.9968010783195496, loss=0.015002401545643806
test: epoch 79, loss 0.09551570564508438, acc=0.9781890511512756, loss=0.09551570564508438
train: epoch 80, loss 0.01546269841492176, acc=0.9963648319244385, loss=0.01546269841492176
test: epoch 80, loss 0.07123281061649323, acc=0.9814937114715576, loss=0.07123281061649323
train: epoch 81, loss 0.014832856133580208, acc=0.9965366721153259, loss=0.014832856133580208
test: epoch 81, loss 0.07694286108016968, acc=0.9821546673774719, loss=0.07694286108016968
train: epoch 82, loss 0.018609842285513878, acc=0.9970390200614929, loss=0.018609842285513878
test: epoch 82, loss 0.0512082576751709, acc=0.9821546673774719, loss=0.0512082576751709
train: epoch 83, loss 0.016802454367280006, acc=0.9966821074485779, loss=0.016802454367280006
test: epoch 83, loss 0.08239702880382538, acc=0.9821546673774719, loss=0.08239702880382538
train: epoch 84, loss 0.024134084582328796, acc=0.9957832098007202, loss=0.024134084582328796
test: epoch 84, loss 0.07224640995264053, acc=0.9821546673774719, loss=0.07224640995264053
train: epoch 85, loss 0.014134650118649006, acc=0.9967746138572693, loss=0.014134650118649006
test: epoch 85, loss 0.05429695546627045, acc=0.9814937114715576, loss=0.05429695546627045
train: epoch 86, loss 0.01417842973023653, acc=0.9971843957901001, loss=0.01417842973023653
test: epoch 86, loss 0.09891745448112488, acc=0.9814937114715576, loss=0.09891745448112488
train: epoch 87, loss 0.02224581129848957, acc=0.9956642389297485, loss=0.02224581129848957
test: epoch 87, loss 0.07494891434907913, acc=0.9808327555656433, loss=0.07494891434907913
train: epoch 88, loss 0.013769223354756832, acc=0.9972372651100159, loss=0.013769223354756832
test: epoch 88, loss 0.08603139221668243, acc=0.9814937114715576, loss=0.08603139221668243
train: epoch 89, loss 0.015643851831555367, acc=0.9967085123062134, loss=0.015643851831555367
test: epoch 89, loss 0.06350109726190567, acc=0.9821546673774719, loss=0.06350109726190567
train: epoch 90, loss 0.014591139741241932, acc=0.9973430037498474, loss=0.014591139741241932
test: epoch 90, loss 0.13082368671894073, acc=0.9814937114715576, loss=0.13082368671894073
train: epoch 91, loss 0.0159252118319273, acc=0.997105062007904, loss=0.0159252118319273
test: epoch 91, loss 0.09489451348781586, acc=0.9821546673774719, loss=0.09489451348781586
train: epoch 92, loss 0.008477579802274704, acc=0.997673511505127, loss=0.008477579802274704
test: epoch 92, loss 0.11375610530376434, acc=0.9788499474525452, loss=0.11375610530376434
train: epoch 93, loss 0.018097784370183945, acc=0.9970654249191284, loss=0.018097784370183945
test: epoch 93, loss 0.09896121174097061, acc=0.9808327555656433, loss=0.09896121174097061
train: epoch 94, loss 0.02576180174946785, acc=0.9953998923301697, loss=0.02576180174946785
test: epoch 94, loss 0.11014115810394287, acc=0.9814937114715576, loss=0.11014115810394287
train: epoch 95, loss 0.01734333299100399, acc=0.9966952800750732, loss=0.01734333299100399
test: epoch 95, loss 0.08707235753536224, acc=0.9808327555656433, loss=0.08707235753536224
train: epoch 96, loss 0.02093208022415638, acc=0.9957171082496643, loss=0.02093208022415638
test: epoch 96, loss 0.14921876788139343, acc=0.9801718592643738, loss=0.14921876788139343
train: epoch 97, loss 0.013029733672738075, acc=0.9974884390830994, loss=0.013029733672738075
test: epoch 97, loss 0.11816845089197159, acc=0.9821546673774719, loss=0.11816845089197159
train: epoch 98, loss 0.016653835773468018, acc=0.9974223375320435, loss=0.016653835773468018
test: epoch 98, loss 0.08234809339046478, acc=0.9821546673774719, loss=0.08234809339046478
train: epoch 99, loss 0.013312004506587982, acc=0.9976602792739868, loss=0.013312004506587982
test: epoch 99, loss 0.04313354939222336, acc=0.9821546673774719, loss=0.04313354939222336
train: epoch 100, loss 0.00859332550317049, acc=0.9982947707176208, loss=0.00859332550317049
test: epoch 100, loss 0.09717601537704468, acc=0.9821546673774719, loss=0.09717601537704468
train: epoch 101, loss 0.02040531300008297, acc=0.9968142509460449, loss=0.02040531300008297
test: epoch 101, loss 0.06827173382043839, acc=0.9821546673774719, loss=0.06827173382043839
train: epoch 102, loss 0.015937093645334244, acc=0.9967349767684937, loss=0.015937093645334244
test: epoch 102, loss 0.15358160436153412, acc=0.9781890511512756, loss=0.15358160436153412
train: epoch 103, loss 0.030467089265584946, acc=0.9933773875236511, loss=0.030467089265584946
test: epoch 103, loss 0.08540697395801544, acc=0.9801718592643738, loss=0.08540697395801544
train: epoch 104, loss 0.01744885742664337, acc=0.9955452680587769, loss=0.01744885742664337
test: epoch 104, loss 0.07004279643297195, acc=0.9814937114715576, loss=0.07004279643297195
train: epoch 105, loss 0.024226270616054535, acc=0.9965366721153259, loss=0.024226270616054535
test: epoch 105, loss 0.2661464512348175, acc=0.9781890511512756, loss=0.2661464512348175
train: epoch 106, loss 0.02037365362048149, acc=0.9964309334754944, loss=0.02037365362048149
test: epoch 106, loss 0.11500243097543716, acc=0.9801718592643738, loss=0.11500243097543716
train: epoch 107, loss 0.01251995749771595, acc=0.9976602792739868, loss=0.01251995749771595
test: epoch 107, loss 0.10118477046489716, acc=0.9801718592643738, loss=0.10118477046489716
train: epoch 108, loss 0.013720882125198841, acc=0.9972637295722961, loss=0.013720882125198841
test: epoch 108, loss 0.09029313176870346, acc=0.9814937114715576, loss=0.09029313176870346
train: epoch 109, loss 0.01390912290662527, acc=0.997329831123352, loss=0.01390912290662527
test: epoch 109, loss 0.10063493251800537, acc=0.9814937114715576, loss=0.10063493251800537
train: epoch 110, loss 0.012015043757855892, acc=0.9974752068519592, loss=0.012015043757855892
test: epoch 110, loss 0.06994019448757172, acc=0.9814937114715576, loss=0.06994019448757172
train: epoch 111, loss 0.01476591918617487, acc=0.9974752068519592, loss=0.01476591918617487
test: epoch 111, loss 0.08723196387290955, acc=0.9808327555656433, loss=0.08723196387290955
train: epoch 112, loss 0.02099640481173992, acc=0.996192991733551, loss=0.02099640481173992
test: epoch 112, loss 0.09090131521224976, acc=0.9801718592643738, loss=0.09090131521224976
train: epoch 113, loss 0.02755855955183506, acc=0.9949901103973389, loss=0.02755855955183506
test: epoch 113, loss 0.07057099044322968, acc=0.9808327555656433, loss=0.07057099044322968
train: epoch 114, loss 0.019603118300437927, acc=0.9951487183570862, loss=0.019603118300437927
test: epoch 114, loss 0.2126573771238327, acc=0.9755452871322632, loss=0.2126573771238327
train: epoch 115, loss 0.027346814051270485, acc=0.9941969513893127, loss=0.027346814051270485
test: epoch 115, loss 0.085132896900177, acc=0.9795109033584595, loss=0.085132896900177
train: epoch 116, loss 0.021902408450841904, acc=0.9952544569969177, loss=0.021902408450841904
test: epoch 116, loss 0.12272799015045166, acc=0.9795109033584595, loss=0.12272799015045166
train: epoch 117, loss 0.019533373415470123, acc=0.9957435727119446, loss=0.019533373415470123
test: epoch 117, loss 0.10302870720624924, acc=0.9795109033584595, loss=0.10302870720624924
train: epoch 118, loss 0.014516015537083149, acc=0.9963119626045227, loss=0.014516015537083149
test: epoch 118, loss 0.10288401693105698, acc=0.9808327555656433, loss=0.10288401693105698
train: epoch 119, loss 0.013827367685735226, acc=0.9966292381286621, loss=0.013827367685735226
test: epoch 119, loss 0.09481928497552872, acc=0.9808327555656433, loss=0.09481928497552872
train: epoch 120, loss 0.023409899324178696, acc=0.9949636459350586, loss=0.023409899324178696
test: epoch 120, loss 0.10431355237960815, acc=0.9801718592643738, loss=0.10431355237960815
train: epoch 121, loss 0.04362195357680321, acc=0.9899669289588928, loss=0.04362195357680321
test: epoch 121, loss 0.1304885596036911, acc=0.9715796709060669, loss=0.1304885596036911
train: epoch 122, loss 0.03315228968858719, acc=0.9970125555992126, loss=0.03315228968858719
test: epoch 122, loss 0.1324688345193863, acc=0.9808327555656433, loss=0.1324688345193863
train: epoch 123, loss 0.024389510974287987, acc=0.9957038760185242, loss=0.024389510974287987
test: epoch 123, loss 0.09679889678955078, acc=0.9801718592643738, loss=0.09679889678955078
train: epoch 124, loss 0.014292350970208645, acc=0.9968010783195496, loss=0.014292350970208645
test: epoch 124, loss 0.12715834379196167, acc=0.9801718592643738, loss=0.12715834379196167
train: epoch 125, loss 0.0231035016477108, acc=0.9956907033920288, loss=0.0231035016477108
test: epoch 125, loss 0.11011532694101334, acc=0.9808327555656433, loss=0.11011532694101334
train: epoch 126, loss 0.024166425690054893, acc=0.9948314428329468, loss=0.024166425690054893
test: epoch 126, loss 0.1106499508023262, acc=0.9788499474525452, loss=0.1106499508023262
train: epoch 127, loss 0.028812658041715622, acc=0.9945803284645081, loss=0.028812658041715622
test: epoch 127, loss 0.11576613038778305, acc=0.9795109033584595, loss=0.11576613038778305
train: epoch 128, loss 0.01439305767416954, acc=0.9961665272712708, loss=0.01439305767416954
test: epoch 128, loss 0.09979749470949173, acc=0.9795109033584595, loss=0.09979749470949173
train: epoch 129, loss 0.018054328858852386, acc=0.9964309334754944, loss=0.018054328858852386
test: epoch 129, loss 0.09949617832899094, acc=0.9808327555656433, loss=0.09949617832899094
train: epoch 130, loss 0.01558633055537939, acc=0.9965895414352417, loss=0.01558633055537939
test: epoch 130, loss 0.110877126455307, acc=0.9808327555656433, loss=0.110877126455307
train: epoch 131, loss 0.025058649480342865, acc=0.9950958490371704, loss=0.025058649480342865
test: epoch 131, loss 0.13223861157894135, acc=0.9781890511512756, loss=0.13223861157894135
train: epoch 132, loss 0.02287432737648487, acc=0.9946596026420593, loss=0.02287432737648487
test: epoch 132, loss 0.1364780217409134, acc=0.9788499474525452, loss=0.1364780217409134
train: epoch 133, loss 0.01957911252975464, acc=0.9962194561958313, loss=0.01957911252975464
test: epoch 133, loss 0.11026652157306671, acc=0.9801718592643738, loss=0.11026652157306671
train: epoch 134, loss 0.03387876972556114, acc=0.9930601716041565, loss=0.03387876972556114
test: epoch 134, loss 0.12363910675048828, acc=0.9781890511512756, loss=0.12363910675048828
train: epoch 135, loss 0.024500781670212746, acc=0.9939590096473694, loss=0.024500781670212746
test: epoch 135, loss 0.08089045435190201, acc=0.9781890511512756, loss=0.08089045435190201
train: epoch 136, loss 0.026646405458450317, acc=0.9941969513893127, loss=0.026646405458450317
test: epoch 136, loss 0.12867602705955505, acc=0.9775280952453613, loss=0.12867602705955505
train: epoch 137, loss 0.03438814729452133, acc=0.9933377504348755, loss=0.03438814729452133
test: epoch 137, loss 0.14861388504505157, acc=0.9781890511512756, loss=0.14861388504505157
train: epoch 138, loss 0.028962397947907448, acc=0.9943952560424805, loss=0.028962397947907448
test: epoch 138, loss 0.12368052452802658, acc=0.9788499474525452, loss=0.12368052452802658
train: epoch 139, loss 0.022475406527519226, acc=0.9942762851715088, loss=0.022475406527519226
test: epoch 139, loss 0.11527854949235916, acc=0.9781890511512756, loss=0.11527854949235916
train: epoch 140, loss 0.02418980374932289, acc=0.9945803284645081, loss=0.02418980374932289
test: epoch 140, loss 0.023871948942542076, acc=0.9940515756607056, loss=0.023871948942542076
