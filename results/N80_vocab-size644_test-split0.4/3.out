# ["--N=80", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=1", "--n_layers=3", "--save_run=1", "--test_split=0.4", "--n_symbols=644"]
Namespace(N=80, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=644, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=686125680, receiver_embed_dim=64, save_run=True, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.4, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.7378034591674805, acc=0.15317246317863464, loss=2.7378034591674805
test: epoch 1, loss 5.703134536743164, acc=0.06731013208627701, loss=5.703134536743164
train: epoch 2, loss 1.5297143459320068, acc=0.383545845746994, loss=1.5297143459320068
test: epoch 2, loss 5.459456443786621, acc=0.0795021578669548, loss=5.459456443786621
train: epoch 3, loss 1.165213942527771, acc=0.5255168676376343, loss=1.165213942527771
test: epoch 3, loss 5.0600128173828125, acc=0.11277622729539871, loss=5.0600128173828125
train: epoch 4, loss 0.8859550356864929, acc=0.6488392353057861, loss=0.8859550356864929
test: epoch 4, loss 4.104700088500977, acc=0.17576834559440613, loss=4.104700088500977
train: epoch 5, loss 0.6343854665756226, acc=0.7618592977523804, loss=0.6343854665756226
test: epoch 5, loss 4.341879367828369, acc=0.18110236525535583, loss=4.341879367828369
train: epoch 6, loss 0.4769366979598999, acc=0.8285648822784424, loss=0.4769366979598999
test: epoch 6, loss 3.8777785301208496, acc=0.2331724613904953, loss=3.8777785301208496
train: epoch 7, loss 0.36885592341423035, acc=0.8720853328704834, loss=0.36885592341423035
test: epoch 7, loss 4.054459571838379, acc=0.2059944123029709, loss=4.054459571838379
train: epoch 8, loss 0.3173188865184784, acc=0.8915722370147705, loss=0.3173188865184784
test: epoch 8, loss 3.514930009841919, acc=0.2227584421634674, loss=3.514930009841919
train: epoch 9, loss 0.2703632116317749, acc=0.9101396799087524, loss=0.2703632116317749
test: epoch 9, loss 3.390756845474243, acc=0.25374650955200195, loss=3.390756845474243
train: epoch 10, loss 0.22459663450717926, acc=0.9278486371040344, loss=0.22459663450717926
test: epoch 10, loss 3.1200098991394043, acc=0.2547625005245209, loss=3.1200098991394043
train: epoch 11, loss 0.20061235129833221, acc=0.9361290335655212, loss=0.20061235129833221
test: epoch 11, loss 3.2020368576049805, acc=0.2689865231513977, loss=3.2020368576049805
train: epoch 12, loss 0.18592585623264313, acc=0.9411277770996094, loss=0.18592585623264313
test: epoch 12, loss 3.288806438446045, acc=0.23977647721767426, loss=3.288806438446045
train: epoch 13, loss 0.17229914665222168, acc=0.9452425837516785, loss=0.17229914665222168
test: epoch 13, loss 3.0005342960357666, acc=0.27889254689216614, loss=3.0005342960357666
train: epoch 14, loss 0.1622203141450882, acc=0.9489967226982117, loss=0.1622203141450882
test: epoch 14, loss 2.9597442150115967, acc=0.24079248309135437, loss=2.9597442150115967
train: epoch 15, loss 0.15065889060497284, acc=0.9527559280395508, loss=0.15065889060497284
test: epoch 15, loss 3.2227532863616943, acc=0.2943865954875946, loss=3.2227532863616943
train: epoch 16, loss 0.14898504316806793, acc=0.9537718892097473, loss=0.14898504316806793
test: epoch 16, loss 2.78275465965271, acc=0.3030225932598114, loss=2.78275465965271
train: epoch 17, loss 0.14064599573612213, acc=0.9567894339561462, loss=0.14064599573612213
test: epoch 17, loss 3.048675775527954, acc=0.32867667078971863, loss=3.048675775527954
train: epoch 18, loss 0.1380918323993683, acc=0.9580289721488953, loss=0.1380918323993683
test: epoch 18, loss 2.9685845375061035, acc=0.31419864296913147, loss=2.9685845375061035
train: epoch 19, loss 0.13447295129299164, acc=0.9592075347900391, loss=0.13447295129299164
test: epoch 19, loss 2.985663890838623, acc=0.31115061044692993, loss=2.985663890838623
train: epoch 20, loss 0.1279982477426529, acc=0.9616510272026062, loss=0.1279982477426529
test: epoch 20, loss 2.6759321689605713, acc=0.3449326753616333, loss=2.6759321689605713
train: epoch 21, loss 0.1264047771692276, acc=0.9616510272026062, loss=0.1264047771692276
test: epoch 21, loss 2.9865801334381104, acc=0.3495047092437744, loss=2.9865801334381104
train: epoch 22, loss 0.12252768874168396, acc=0.9628753066062927, loss=0.12252768874168396
test: epoch 22, loss 3.0229811668395996, acc=0.327406644821167, loss=3.0229811668395996
train: epoch 23, loss 0.11817644536495209, acc=0.9644297957420349, loss=0.11817644536495209
test: epoch 23, loss 2.4848132133483887, acc=0.37947675585746765, loss=2.4848132133483887
train: epoch 24, loss 0.11678703129291534, acc=0.9652882814407349, loss=0.11678703129291534
test: epoch 24, loss 2.7142345905303955, acc=0.3685547411441803, loss=2.7142345905303955
train: epoch 25, loss 0.11330427974462509, acc=0.9662026762962341, loss=0.11330427974462509
test: epoch 25, loss 2.563140869140625, acc=0.37871477007865906, loss=2.563140869140625
train: epoch 26, loss 0.10971909761428833, acc=0.967025637626648, loss=0.10971909761428833
test: epoch 26, loss 2.668316125869751, acc=0.40817880630493164, loss=2.668316125869751
train: epoch 27, loss 0.10645183175802231, acc=0.9679248332977295, loss=0.10645183175802231
test: epoch 27, loss 2.593294620513916, acc=0.4053848087787628, loss=2.593294620513916
train: epoch 28, loss 0.10750458389520645, acc=0.9686309099197388, loss=0.10750458389520645
test: epoch 28, loss 2.4970498085021973, acc=0.46253493428230286, loss=2.4970498085021973
train: epoch 29, loss 0.10726166516542435, acc=0.9682804346084595, loss=0.10726166516542435
test: epoch 29, loss 2.549039840698242, acc=0.44780290126800537, loss=2.549039840698242
train: epoch 30, loss 0.10722922533750534, acc=0.9681635499000549, loss=0.10722922533750534
test: epoch 30, loss 2.284335136413574, acc=0.4490728974342346, loss=2.284335136413574
train: epoch 31, loss 0.10389969497919083, acc=0.9698450565338135, loss=0.10389969497919083
test: epoch 31, loss 2.147763729095459, acc=0.4856489598751068, loss=2.147763729095459
train: epoch 32, loss 0.10109025985002518, acc=0.9705562591552734, loss=0.10109025985002518
test: epoch 32, loss 1.9575703144073486, acc=0.47625094652175903, loss=1.9575703144073486
train: epoch 33, loss 0.09879031777381897, acc=0.9712623953819275, loss=0.09879031777381897
test: epoch 33, loss 2.1792092323303223, acc=0.4902209937572479, loss=2.1792092323303223
train: epoch 34, loss 0.0992063581943512, acc=0.9715366959571838, loss=0.0992063581943512
test: epoch 34, loss 2.1331512928009033, acc=0.5085090398788452, loss=2.1331512928009033
train: epoch 35, loss 0.09865476936101913, acc=0.9716789722442627, loss=0.09865476936101913
test: epoch 35, loss 1.8207783699035645, acc=0.5600711107254028, loss=1.8207783699035645
train: epoch 36, loss 0.09323341399431229, acc=0.9728575348854065, loss=0.09323341399431229
test: epoch 36, loss 2.131513833999634, acc=0.5415290594100952, loss=2.131513833999634
train: epoch 37, loss 0.0943058431148529, acc=0.9727863669395447, loss=0.0943058431148529
test: epoch 37, loss 1.8361873626708984, acc=0.5618491172790527, loss=1.8361873626708984
train: epoch 38, loss 0.09109052270650864, acc=0.9737719297409058, loss=0.09109052270650864
test: epoch 38, loss 1.8085484504699707, acc=0.5979171991348267, loss=1.8085484504699707
train: epoch 39, loss 0.08796491473913193, acc=0.9746609330177307, loss=0.08796491473913193
test: epoch 39, loss 1.6566619873046875, acc=0.6240792274475098, loss=1.6566619873046875
train: epoch 40, loss 0.0888262391090393, acc=0.9746100902557373, loss=0.0888262391090393
test: epoch 40, loss 1.6801962852478027, acc=0.5953772068023682, loss=1.6801962852478027
train: epoch 41, loss 0.08540759980678558, acc=0.9760071039199829, loss=0.08540759980678558
test: epoch 41, loss 1.5147792100906372, acc=0.6642113327980042, loss=1.5147792100906372
train: epoch 42, loss 0.08475115150213242, acc=0.9762560129165649, loss=0.08475115150213242
test: epoch 42, loss 1.3328744173049927, acc=0.6769113540649414, loss=1.3328744173049927
train: epoch 43, loss 0.08590760827064514, acc=0.9765709638595581, loss=0.08590760827064514
test: epoch 43, loss 1.255307674407959, acc=0.7063754200935364, loss=1.255307674407959
train: epoch 44, loss 0.07697930932044983, acc=0.9785013794898987, loss=0.07697930932044983
test: epoch 44, loss 1.3705532550811768, acc=0.7106934189796448, loss=1.3705532550811768
train: epoch 45, loss 0.07900609821081161, acc=0.9785674214363098, loss=0.07900609821081161
test: epoch 45, loss 1.3015291690826416, acc=0.7112014293670654, loss=1.3015291690826416
train: epoch 46, loss 0.07829313725233078, acc=0.9787808060646057, loss=0.07829313725233078
test: epoch 46, loss 1.0199785232543945, acc=0.7373634576797485, loss=1.0199785232543945
train: epoch 47, loss 0.07249439507722855, acc=0.9800965189933777, loss=0.07249439507722855
test: epoch 47, loss 0.9112900495529175, acc=0.7785115838050842, loss=0.9112900495529175
train: epoch 48, loss 0.07044829428195953, acc=0.9813258647918701, loss=0.07044829428195953
test: epoch 48, loss 0.9443924427032471, acc=0.8008636236190796, loss=0.9443924427032471
train: epoch 49, loss 0.07068685442209244, acc=0.9815239906311035, loss=0.07068685442209244
test: epoch 49, loss 0.7468743324279785, acc=0.8397256731987, loss=0.7468743324279785
train: epoch 50, loss 0.0666055828332901, acc=0.9825247526168823, loss=0.0666055828332901
test: epoch 50, loss 0.6656804084777832, acc=0.8465836644172668, loss=0.6656804084777832
train: epoch 51, loss 0.06478208303451538, acc=0.9835712313652039, loss=0.06478208303451538
test: epoch 51, loss 0.5345677733421326, acc=0.8887477517127991, loss=0.5345677733421326
train: epoch 52, loss 0.058316729962825775, acc=0.985481321811676, loss=0.058316729962825775
test: epoch 52, loss 0.5475584864616394, acc=0.879095733165741, loss=0.5475584864616394
train: epoch 53, loss 0.056929465383291245, acc=0.9857810735702515, loss=0.056929465383291245
test: epoch 53, loss 0.47258174419403076, acc=0.9141478538513184, loss=0.47258174419403076
train: epoch 54, loss 0.058964647352695465, acc=0.9863906502723694, loss=0.058964647352695465
test: epoch 54, loss 0.3187936544418335, acc=0.9268478751182556, loss=0.3187936544418335
train: epoch 55, loss 0.049343593418598175, acc=0.9885293245315552, loss=0.049343593418598175
test: epoch 55, loss 0.3344745934009552, acc=0.9453898668289185, loss=0.3344745934009552
train: epoch 56, loss 0.0466177836060524, acc=0.9896469116210938, loss=0.0466177836060524
test: epoch 56, loss 0.2239489108324051, acc=0.9570739269256592, loss=0.2239489108324051
train: epoch 57, loss 0.048292599618434906, acc=0.9896266460418701, loss=0.048292599618434906
test: epoch 57, loss 0.18623299896717072, acc=0.9631699323654175, loss=0.18623299896717072
train: epoch 58, loss 0.0411357507109642, acc=0.9910947680473328, loss=0.0411357507109642
test: epoch 58, loss 0.16249379515647888, acc=0.9679959416389465, loss=0.16249379515647888
train: epoch 59, loss 0.04069835692644119, acc=0.9916281700134277, loss=0.04069835692644119
test: epoch 59, loss 0.12581996619701385, acc=0.9697739481925964, loss=0.12581996619701385
train: epoch 60, loss 0.03607245162129402, acc=0.9926491975784302, loss=0.03607245162129402
test: epoch 60, loss 0.120509073138237, acc=0.9776479601860046, loss=0.120509073138237
train: epoch 61, loss 0.03956089913845062, acc=0.9921920299530029, loss=0.03956089913845062
test: epoch 61, loss 0.0884692445397377, acc=0.9784099459648132, loss=0.0884692445397377
train: epoch 62, loss 0.0396418571472168, acc=0.9926797151565552, loss=0.0396418571472168
test: epoch 62, loss 0.07925998419523239, acc=0.981965959072113, loss=0.07925998419523239
train: epoch 63, loss 0.03996194154024124, acc=0.9926746487617493, loss=0.03996194154024124
test: epoch 63, loss 0.08600546419620514, acc=0.9796799421310425, loss=0.08600546419620514
train: epoch 64, loss 0.03503301367163658, acc=0.9939954280853271, loss=0.03503301367163658
test: epoch 64, loss 0.09538663178682327, acc=0.978663980960846, loss=0.09538663178682327
train: epoch 65, loss 0.03318295627832413, acc=0.9937261939048767, loss=0.03318295627832413
test: epoch 65, loss 0.056349433958530426, acc=0.9784099459648132, loss=0.056349433958530426
train: epoch 66, loss 0.032574791461229324, acc=0.9938938021659851, loss=0.032574791461229324
test: epoch 66, loss 0.06018524616956711, acc=0.9837439656257629, loss=0.06018524616956711
train: epoch 67, loss 0.02914786897599697, acc=0.9947624802589417, loss=0.02914786897599697
test: epoch 67, loss 0.15379153192043304, acc=0.9804419875144958, loss=0.15379153192043304
train: epoch 68, loss 0.03271199017763138, acc=0.9942697286605835, loss=0.03271199017763138
test: epoch 68, loss 0.07161683589220047, acc=0.9794259667396545, loss=0.07161683589220047
train: epoch 69, loss 0.03170992434024811, acc=0.9947980642318726, loss=0.03170992434024811
test: epoch 69, loss 0.18372663855552673, acc=0.9824739694595337, loss=0.18372663855552673
train: epoch 70, loss 0.038284484297037125, acc=0.9935077428817749, loss=0.038284484297037125
test: epoch 70, loss 0.15322661399841309, acc=0.9779019355773926, loss=0.15322661399841309
train: epoch 71, loss 0.034231919795274734, acc=0.9938430190086365, loss=0.034231919795274734
test: epoch 71, loss 0.06876904517412186, acc=0.9794259667396545, loss=0.06876904517412186
train: epoch 72, loss 0.041677363216876984, acc=0.9935280680656433, loss=0.041677363216876984
test: epoch 72, loss 0.147955521941185, acc=0.9738379716873169, loss=0.147955521941185
train: epoch 73, loss 0.02903032675385475, acc=0.9947269558906555, loss=0.02903032675385475
test: epoch 73, loss 0.06964069604873657, acc=0.9801879525184631, loss=0.06964069604873657
train: epoch 74, loss 0.029315579682588577, acc=0.9952298998832703, loss=0.029315579682588577
test: epoch 74, loss 0.10124243795871735, acc=0.9827279448509216, loss=0.10124243795871735
train: epoch 75, loss 0.02408311888575554, acc=0.995773434638977, loss=0.02408311888575554
test: epoch 75, loss 0.07752599567174911, acc=0.9852679967880249, loss=0.07752599567174911
train: epoch 76, loss 0.03607610985636711, acc=0.9946964979171753, loss=0.03607610985636711
test: epoch 76, loss 0.13088881969451904, acc=0.9829819798469543, loss=0.13088881969451904
train: epoch 77, loss 0.031424980610609055, acc=0.9949758648872375, loss=0.031424980610609055
test: epoch 77, loss 0.08600838482379913, acc=0.9814579486846924, loss=0.08600838482379913
train: epoch 78, loss 0.03433065116405487, acc=0.994889497756958, loss=0.03433065116405487
test: epoch 78, loss 0.07181607931852341, acc=0.9827279448509216, loss=0.07181607931852341
train: epoch 79, loss 0.03477977588772774, acc=0.9943764209747314, loss=0.03477977588772774
test: epoch 79, loss 0.056220587342977524, acc=0.9824739694595337, loss=0.056220587342977524
train: epoch 80, loss 0.028751904144883156, acc=0.9949402809143066, loss=0.028751904144883156
test: epoch 80, loss 0.06923544406890869, acc=0.9832359552383423, loss=0.06923544406890869
train: epoch 81, loss 0.03531523793935776, acc=0.9947929978370667, loss=0.03531523793935776
test: epoch 81, loss 0.08382819592952728, acc=0.9794259667396545, loss=0.08382819592952728
train: epoch 82, loss 0.035949625074863434, acc=0.9943459630012512, loss=0.035949625074863434
test: epoch 82, loss 0.07643542438745499, acc=0.9817119836807251, loss=0.07643542438745499
train: epoch 83, loss 0.03143180161714554, acc=0.9947167634963989, loss=0.03143180161714554
test: epoch 83, loss 0.08492163568735123, acc=0.9812039732933044, loss=0.08492163568735123
train: epoch 84, loss 0.03224600851535797, acc=0.9946812391281128, loss=0.03224600851535797
test: epoch 84, loss 0.0831829309463501, acc=0.9822199940681458, loss=0.0831829309463501
train: epoch 85, loss 0.03162722662091255, acc=0.9948691725730896, loss=0.03162722662091255
test: epoch 85, loss 0.09311341494321823, acc=0.9824739694595337, loss=0.09311341494321823
train: epoch 86, loss 0.042759090662002563, acc=0.9941275119781494, loss=0.042759090662002563
test: epoch 86, loss 0.06830552965402603, acc=0.981965959072113, loss=0.06830552965402603
train: epoch 87, loss 0.03316958248615265, acc=0.9949454069137573, loss=0.03316958248615265
test: epoch 87, loss 0.11213688552379608, acc=0.9842519760131836, loss=0.11213688552379608
train: epoch 88, loss 0.03246638551354408, acc=0.9953517913818359, loss=0.03246638551354408
test: epoch 88, loss 0.08938083052635193, acc=0.9812039732933044, loss=0.08938083052635193
train: epoch 89, loss 0.03978365287184715, acc=0.9936855435371399, loss=0.03978365287184715
test: epoch 89, loss 0.07891851663589478, acc=0.9817119836807251, loss=0.07891851663589478
train: epoch 90, loss 0.038436803966760635, acc=0.9943967461585999, loss=0.038436803966760635
test: epoch 90, loss 0.12559081614017487, acc=0.9784099459648132, loss=0.12559081614017487
train: epoch 91, loss 0.03964737057685852, acc=0.9943154454231262, loss=0.03964737057685852
test: epoch 91, loss 0.0859466940164566, acc=0.9822199940681458, loss=0.0859466940164566
train: epoch 92, loss 0.03632451593875885, acc=0.9944526553153992, loss=0.03632451593875885
test: epoch 92, loss 0.08245474100112915, acc=0.9814579486846924, loss=0.08245474100112915
train: epoch 93, loss 0.04770166799426079, acc=0.9932029247283936, loss=0.04770166799426079
test: epoch 93, loss 0.0923042893409729, acc=0.9791719317436218, loss=0.0923042893409729
train: epoch 94, loss 0.042485348880290985, acc=0.9929540157318115, loss=0.042485348880290985
test: epoch 94, loss 0.09916672855615616, acc=0.9822199940681458, loss=0.09916672855615616
train: epoch 95, loss 0.042928047478199005, acc=0.9933096170425415, loss=0.042928047478199005
test: epoch 95, loss 0.07353894412517548, acc=0.9837439656257629, loss=0.07353894412517548
train: epoch 96, loss 0.03772363439202309, acc=0.9946304559707642, loss=0.03772363439202309
test: epoch 96, loss 0.12593629956245422, acc=0.9806959629058838, loss=0.12593629956245422
train: epoch 97, loss 0.04097585752606392, acc=0.9938735365867615, loss=0.04097585752606392
test: epoch 97, loss 0.09744084626436234, acc=0.9781559705734253, loss=0.09744084626436234
train: epoch 98, loss 0.040092695504426956, acc=0.9930099248886108, loss=0.040092695504426956
test: epoch 98, loss 0.08565517514944077, acc=0.9799339771270752, loss=0.08565517514944077
train: epoch 99, loss 0.06246279180049896, acc=0.9899822473526001, loss=0.06246279180049896
test: epoch 99, loss 0.1007613092660904, acc=0.978663980960846, loss=0.1007613092660904
train: epoch 100, loss 0.06490994244813919, acc=0.989560604095459, loss=0.06490994244813919
test: epoch 100, loss 0.12412344664335251, acc=0.9799339771270752, loss=0.12412344664335251
train: epoch 101, loss 0.050593238323926926, acc=0.9922783970832825, loss=0.050593238323926926
test: epoch 101, loss 0.07934974879026413, acc=0.9817119836807251, loss=0.07934974879026413
train: epoch 102, loss 0.03224749118089676, acc=0.994462788105011, loss=0.03224749118089676
test: epoch 102, loss 0.11533790081739426, acc=0.9799339771270752, loss=0.11533790081739426
train: epoch 103, loss 0.05452832952141762, acc=0.9898907542228699, loss=0.05452832952141762
test: epoch 103, loss 0.0782204270362854, acc=0.9801879525184631, loss=0.0782204270362854
train: epoch 104, loss 0.03833092749118805, acc=0.9935280680656433, loss=0.03833092749118805
test: epoch 104, loss 0.08043258637189865, acc=0.9817119836807251, loss=0.08043258637189865
train: epoch 105, loss 0.06369924545288086, acc=0.9893624782562256, loss=0.06369924545288086
test: epoch 105, loss 0.12398111075162888, acc=0.9700279235839844, loss=0.12398111075162888
train: epoch 106, loss 0.06617182493209839, acc=0.9870815277099609, loss=0.06617182493209839
test: epoch 106, loss 0.09878148883581161, acc=0.9682499170303345, loss=0.09878148883581161
train: epoch 107, loss 0.07603894174098969, acc=0.9872593283653259, loss=0.07603894174098969
test: epoch 107, loss 0.13879428803920746, acc=0.9735839366912842, loss=0.13879428803920746
train: epoch 108, loss 0.10483793169260025, acc=0.9813665151596069, loss=0.10483793169260025
test: epoch 108, loss 0.13155211508274078, acc=0.9636779427528381, loss=0.13155211508274078
train: epoch 109, loss 0.0809088721871376, acc=0.9843840599060059, loss=0.0809088721871376
test: epoch 109, loss 0.1651814579963684, acc=0.9715519547462463, loss=0.1651814579963684
train: epoch 110, loss 0.09509321302175522, acc=0.9841046333312988, loss=0.09509321302175522
test: epoch 110, loss 0.15393491089344025, acc=0.9697739481925964, loss=0.15393491089344025
train: epoch 111, loss 0.09838367998600006, acc=0.9840487837791443, loss=0.09838367998600006
test: epoch 111, loss 0.155989870429039, acc=0.9733299612998962, loss=0.155989870429039
train: epoch 112, loss 0.07514389604330063, acc=0.9863296747207642, loss=0.07514389604330063
test: epoch 112, loss 0.09299534559249878, acc=0.9738379716873169, loss=0.09299534559249878
train: epoch 113, loss 0.06538176536560059, acc=0.9874828457832336, loss=0.06538176536560059
test: epoch 113, loss 0.10357502102851868, acc=0.9766319394111633, loss=0.10357502102851868
train: epoch 114, loss 0.07217767834663391, acc=0.987005352973938, loss=0.07217767834663391
test: epoch 114, loss 0.11269071698188782, acc=0.9725679159164429, loss=0.11269071698188782
train: epoch 115, loss 0.06523296236991882, acc=0.9885801076889038, loss=0.06523296236991882
test: epoch 115, loss 0.11479601263999939, acc=0.9804419875144958, loss=0.11479601263999939
train: epoch 116, loss 0.06339828670024872, acc=0.9894945621490479, loss=0.06339828670024872
test: epoch 116, loss 0.1430254429578781, acc=0.9740919470787048, loss=0.1430254429578781
train: epoch 117, loss 0.07458247989416122, acc=0.9864566922187805, loss=0.07458247989416122
test: epoch 117, loss 0.1217765361070633, acc=0.9740919470787048, loss=0.1217765361070633
train: epoch 118, loss 0.08690216392278671, acc=0.984876811504364, loss=0.08690216392278671
test: epoch 118, loss 0.1332736313343048, acc=0.970535933971405, loss=0.1332736313343048
train: epoch 119, loss 0.08009057492017746, acc=0.9855219721794128, loss=0.08009057492017746
test: epoch 119, loss 0.11508253216743469, acc=0.9712979197502136, loss=0.11508253216743469
train: epoch 120, loss 0.0705505833029747, acc=0.9876251220703125, loss=0.0705505833029747
test: epoch 120, loss 0.1604086011648178, acc=0.9723139405250549, loss=0.1604086011648178
train: epoch 121, loss 0.09906429797410965, acc=0.9825196862220764, loss=0.09906429797410965
test: epoch 121, loss 0.1832726150751114, acc=0.9692659378051758, loss=0.1832726150751114
train: epoch 122, loss 0.08571645617485046, acc=0.9851968288421631, loss=0.08571645617485046
test: epoch 122, loss 0.13121484220027924, acc=0.9758699536323547, loss=0.13121484220027924
train: epoch 123, loss 0.09331939369440079, acc=0.9853289127349854, loss=0.09331939369440079
test: epoch 123, loss 0.13847731053829193, acc=0.9677419066429138, loss=0.13847731053829193
train: epoch 124, loss 0.08550582826137543, acc=0.9832766056060791, loss=0.08550582826137543
test: epoch 124, loss 0.16159546375274658, acc=0.9710439443588257, loss=0.16159546375274658
train: epoch 125, loss 0.09028786420822144, acc=0.9831648468971252, loss=0.09028786420822144
test: epoch 125, loss 0.11794187128543854, acc=0.972059965133667, loss=0.11794187128543854
train: epoch 126, loss 0.09988628327846527, acc=0.9816306829452515, loss=0.09988628327846527
test: epoch 126, loss 0.1742173731327057, acc=0.9641859531402588, loss=0.1742173731327057
train: epoch 127, loss 0.09612783044576645, acc=0.9832258224487305, loss=0.09612783044576645
test: epoch 127, loss 0.22295935451984406, acc=0.9733299612998962, loss=0.22295935451984406
train: epoch 128, loss 0.136874258518219, acc=0.9767335653305054, loss=0.136874258518219
test: epoch 128, loss 0.14083465933799744, acc=0.9707899689674377, loss=0.14083465933799744
train: epoch 129, loss 0.11609098315238953, acc=0.9818694591522217, loss=0.11609098315238953
test: epoch 129, loss 0.13479526340961456, acc=0.9664719104766846, loss=0.13479526340961456
train: epoch 130, loss 0.12327577918767929, acc=0.9769367575645447, loss=0.12327577918767929
test: epoch 130, loss 0.14172683656215668, acc=0.9697739481925964, loss=0.14172683656215668
train: epoch 131, loss 0.10835190862417221, acc=0.979339599609375, loss=0.10835190862417221
test: epoch 131, loss 0.14496420323848724, acc=0.9692659378051758, loss=0.14496420323848724
train: epoch 132, loss 0.10948160290718079, acc=0.9805638790130615, loss=0.10948160290718079
test: epoch 132, loss 0.1324661374092102, acc=0.9702819585800171, loss=0.1324661374092102
train: epoch 133, loss 0.16401438415050507, acc=0.9714757204055786, loss=0.16401438415050507
test: epoch 133, loss 0.22106362879276276, acc=0.9611379504203796, loss=0.22106362879276276
train: epoch 134, loss 0.1889573633670807, acc=0.9656438827514648, loss=0.1889573633670807
test: epoch 134, loss 0.24052393436431885, acc=0.9441198706626892, loss=0.24052393436431885
train: epoch 135, loss 0.1680743247270584, acc=0.9611531496047974, loss=0.1680743247270584
test: epoch 135, loss 0.22063374519348145, acc=0.9494538903236389, loss=0.22063374519348145
train: epoch 136, loss 0.22801291942596436, acc=0.9529743194580078, loss=0.22801291942596436
test: epoch 136, loss 0.3059997856616974, acc=0.937769889831543, loss=0.3059997856616974
train: epoch 137, loss 0.2866191565990448, acc=0.9440233707427979, loss=0.2866191565990448
test: epoch 137, loss 0.2957635819911957, acc=0.9344678521156311, loss=0.2957635819911957
train: epoch 138, loss 0.22498862445354462, acc=0.9477876424789429, loss=0.22498862445354462
test: epoch 138, loss 0.21464431285858154, acc=0.9441198706626892, loss=0.21464431285858154
train: epoch 139, loss 0.23414385318756104, acc=0.9518516659736633, loss=0.23414385318756104
test: epoch 139, loss 0.29491710662841797, acc=0.9357378482818604, loss=0.29491710662841797
train: epoch 140, loss 0.24168723821640015, acc=0.9526644945144653, loss=0.24168723821640015
test: epoch 140, loss 0.3310815989971161, acc=0.9291338324546814, loss=0.3310815989971161
train: epoch 141, loss 0.3695206940174103, acc=0.9281381964683533, loss=0.3695206940174103
test: epoch 141, loss 0.4300135672092438, acc=0.9098297953605652, loss=0.4300135672092438
train: epoch 142, loss 0.2981320023536682, acc=0.9318161010742188, loss=0.2981320023536682
test: epoch 142, loss 0.31896844506263733, acc=0.919989824295044, loss=0.31896844506263733
train: epoch 143, loss 0.28067782521247864, acc=0.9336652159690857, loss=0.28067782521247864
test: epoch 143, loss 0.29443246126174927, acc=0.9210058450698853, loss=0.29443246126174927
train: epoch 144, loss 0.3130955994129181, acc=0.9308509230613708, loss=0.3130955994129181
test: epoch 144, loss 0.3689553439617157, acc=0.9230378270149231, loss=0.3689553439617157
train: epoch 145, loss 0.29763633012771606, acc=0.9299415946006775, loss=0.29763633012771606
test: epoch 145, loss 0.37080276012420654, acc=0.913385808467865, loss=0.37080276012420654
train: epoch 146, loss 0.3345162272453308, acc=0.9284277558326721, loss=0.3345162272453308
test: epoch 146, loss 0.33266574144363403, acc=0.9156718254089355, loss=0.33266574144363403
train: epoch 147, loss 0.2990267276763916, acc=0.933263897895813, loss=0.2990267276763916
test: epoch 147, loss 0.39975130558013916, acc=0.9204978346824646, loss=0.39975130558013916
train: epoch 148, loss 0.3090609908103943, acc=0.9357683658599854, loss=0.3090609908103943
test: epoch 148, loss 0.37879976630210876, acc=0.9146558046340942, loss=0.37879976630210876
train: epoch 149, loss 0.30517804622650146, acc=0.9306781888008118, loss=0.30517804622650146
test: epoch 149, loss 0.38325235247612, acc=0.9105918407440186, loss=0.38325235247612
train: epoch 150, loss 0.3476526439189911, acc=0.9229260683059692, loss=0.3476526439189911
test: epoch 150, loss 0.5267982482910156, acc=0.9098297953605652, loss=0.5267982482910156
