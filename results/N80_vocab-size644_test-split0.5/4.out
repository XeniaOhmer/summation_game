# ["--N=80", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=1", "--n_layers=3", "--save_run=1", "--test_split=0.5", "--n_symbols=644"]
Namespace(N=80, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=644, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=931838406, receiver_embed_dim=64, save_run=True, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.5, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.115516424179077, acc=0.10118865966796875, loss=3.115516424179077
test: epoch 1, loss 6.348775386810303, acc=0.04663212597370148, loss=6.348775386810303
train: epoch 2, loss 1.8764234781265259, acc=0.2825480103492737, loss=1.8764234781265259
test: epoch 2, loss 5.424929141998291, acc=0.07253886014223099, loss=5.424929141998291
train: epoch 3, loss 1.334609031677246, acc=0.46473637223243713, loss=1.334609031677246
test: epoch 3, loss 5.255777835845947, acc=0.0999695211648941, loss=5.255777835845947
train: epoch 4, loss 1.0436604022979736, acc=0.5864614248275757, loss=1.0436604022979736
test: epoch 4, loss 5.080594539642334, acc=0.14782078564167023, loss=5.080594539642334
train: epoch 5, loss 0.7957435250282288, acc=0.6939469575881958, loss=0.7957435250282288
test: epoch 5, loss 4.904012203216553, acc=0.14903992414474487, loss=4.904012203216553
train: epoch 6, loss 0.6815112233161926, acc=0.7473331093788147, loss=0.6815112233161926
test: epoch 6, loss 5.08717679977417, acc=0.196891188621521, loss=5.08717679977417
train: epoch 7, loss 0.504292368888855, acc=0.8193233609199524, loss=0.504292368888855
test: epoch 7, loss 4.439135551452637, acc=0.21274001896381378, loss=4.439135551452637
train: epoch 8, loss 0.390241414308548, acc=0.8661322593688965, loss=0.390241414308548
test: epoch 8, loss 4.267789840698242, acc=0.21395915746688843, loss=4.267789840698242
train: epoch 9, loss 0.3215918242931366, acc=0.8921060562133789, loss=0.3215918242931366
test: epoch 9, loss 3.8559062480926514, acc=0.2346845418214798, loss=3.8559062480926514
train: epoch 10, loss 0.2762295603752136, acc=0.9088326692581177, loss=0.2762295603752136
test: epoch 10, loss 3.9598822593688965, acc=0.2520573139190674, loss=3.9598822593688965
train: epoch 11, loss 0.246003657579422, acc=0.9209631085395813, loss=0.246003657579422
test: epoch 11, loss 3.9493484497070312, acc=0.24047546088695526, loss=3.9493484497070312
train: epoch 12, loss 0.22696566581726074, acc=0.9275586605072021, loss=0.22696566581726074
test: epoch 12, loss 3.4811136722564697, acc=0.2630295753479004, loss=3.4811136722564697
train: epoch 13, loss 0.21284154057502747, acc=0.9331667423248291, loss=0.21284154057502747
test: epoch 13, loss 3.769348382949829, acc=0.2651630640029907, loss=3.769348382949829
train: epoch 14, loss 0.19493430852890015, acc=0.9384273290634155, loss=0.19493430852890015
test: epoch 14, loss 3.5127742290496826, acc=0.2889362871646881, loss=3.5127742290496826
train: epoch 15, loss 0.18559978902339935, acc=0.9413349628448486, loss=0.18559978902339935
test: epoch 15, loss 3.4442567825317383, acc=0.25784820318222046, loss=3.4442567825317383
train: epoch 16, loss 0.1758054494857788, acc=0.9455227255821228, loss=0.1758054494857788
test: epoch 16, loss 3.0248982906341553, acc=0.3063090443611145, loss=3.0248982906341553
train: epoch 17, loss 0.165426105260849, acc=0.9490399360656738, loss=0.165426105260849
test: epoch 17, loss 3.165344476699829, acc=0.2511429488658905, loss=3.165344476699829
train: epoch 18, loss 0.16000135242938995, acc=0.9506857395172119, loss=0.16000135242938995
test: epoch 18, loss 2.825989246368408, acc=0.3322157859802246, loss=2.825989246368408
train: epoch 19, loss 0.15291927754878998, acc=0.9531667232513428, loss=0.15291927754878998
test: epoch 19, loss 2.7941830158233643, acc=0.327644020318985, loss=2.7941830158233643
train: epoch 20, loss 0.14531755447387695, acc=0.9560682773590088, loss=0.14531755447387695
test: epoch 20, loss 2.710864543914795, acc=0.3501981198787689, loss=2.710864543914795
train: epoch 21, loss 0.14322249591350555, acc=0.9562938213348389, loss=0.14322249591350555
test: epoch 21, loss 2.662860631942749, acc=0.3529411852359772, loss=2.662860631942749
train: epoch 22, loss 0.1403214931488037, acc=0.9573483467102051, loss=0.1403214931488037
test: epoch 22, loss 2.5273051261901855, acc=0.3629990816116333, loss=2.5273051261901855
train: epoch 23, loss 0.1340317577123642, acc=0.959201455116272, loss=0.1340317577123642
test: epoch 23, loss 2.9407596588134766, acc=0.3550746738910675, loss=2.9407596588134766
train: epoch 24, loss 0.1308947652578354, acc=0.9605486392974854, loss=0.1308947652578354
test: epoch 24, loss 3.24072265625, acc=0.34044498205184937, loss=3.24072265625
train: epoch 25, loss 0.1258382499217987, acc=0.9626333713531494, loss=0.1258382499217987
test: epoch 25, loss 2.852324962615967, acc=0.3489789664745331, loss=2.852324962615967
train: epoch 26, loss 0.12307251989841461, acc=0.9630295634269714, loss=0.12307251989841461
test: epoch 26, loss 2.5640547275543213, acc=0.38555318117141724, loss=2.5640547275543213
train: epoch 27, loss 0.12028073519468307, acc=0.9641633629798889, loss=0.12028073519468307
test: epoch 27, loss 2.4018514156341553, acc=0.41145992279052734, loss=2.4018514156341553
train: epoch 28, loss 0.11988019198179245, acc=0.9641206860542297, loss=0.11988019198179245
test: epoch 28, loss 2.4813809394836426, acc=0.37823835015296936, loss=2.4813809394836426
train: epoch 29, loss 0.11419069766998291, acc=0.9666199088096619, loss=0.11419069766998291
test: epoch 29, loss 2.39310359954834, acc=0.42395609617233276, loss=2.39310359954834
train: epoch 30, loss 0.11313150078058243, acc=0.9667296409606934, loss=0.11313150078058243
test: epoch 30, loss 2.640227794647217, acc=0.4056690037250519, loss=2.640227794647217
train: epoch 31, loss 0.11008515954017639, acc=0.9680829048156738, loss=0.11008515954017639
test: epoch 31, loss 2.3944263458251953, acc=0.4489485025405884, loss=2.3944263458251953
train: epoch 32, loss 0.10734967142343521, acc=0.9683511257171631, loss=0.10734967142343521
test: epoch 32, loss 2.500272035598755, acc=0.4340140223503113, loss=2.500272035598755
train: epoch 33, loss 0.10858038067817688, acc=0.968296229839325, loss=0.10858038067817688
test: epoch 33, loss 2.2862937450408936, acc=0.4733313024044037, loss=2.2862937450408936
train: epoch 34, loss 0.10515190660953522, acc=0.9692837595939636, loss=0.10515190660953522
test: epoch 34, loss 2.4883339405059814, acc=0.4276135265827179, loss=2.4883339405059814
train: epoch 35, loss 0.10574261844158173, acc=0.9692593812942505, loss=0.10574261844158173
test: epoch 35, loss 2.206511974334717, acc=0.4986284673213959, loss=2.206511974334717
train: epoch 36, loss 0.10098844766616821, acc=0.9708991050720215, loss=0.10098844766616821
test: epoch 36, loss 2.2304346561431885, acc=0.48552271723747253, loss=2.2304346561431885
train: epoch 37, loss 0.09819550812244415, acc=0.9720268249511719, loss=0.09819550812244415
test: epoch 37, loss 2.0844767093658447, acc=0.5248399972915649, loss=2.0844767093658447
train: epoch 38, loss 0.09664734452962875, acc=0.9726547002792358, loss=0.09664734452962875
test: epoch 38, loss 1.9782311916351318, acc=0.5278878211975098, loss=1.9782311916351318
train: epoch 39, loss 0.09477288275957108, acc=0.9731179475784302, loss=0.09477288275957108
test: epoch 39, loss 1.9644761085510254, acc=0.557147204875946, loss=1.9644761085510254
train: epoch 40, loss 0.09212088584899902, acc=0.9742212891578674, loss=0.09212088584899902
test: epoch 40, loss 1.8925731182098389, acc=0.5431271195411682, loss=1.8925731182098389
train: epoch 41, loss 0.0928964763879776, acc=0.9738616347312927, loss=0.0928964763879776
test: epoch 41, loss 1.7574999332427979, acc=0.6138372421264648, loss=1.7574999332427979
train: epoch 42, loss 0.08741311728954315, acc=0.976184070110321, loss=0.08741311728954315
test: epoch 42, loss 1.5640432834625244, acc=0.6101798415184021, loss=1.5640432834625244
train: epoch 43, loss 0.08754447847604752, acc=0.9761596918106079, loss=0.08754447847604752
test: epoch 43, loss 1.5255013704299927, acc=0.6510210037231445, loss=1.5255013704299927
train: epoch 44, loss 0.08350762724876404, acc=0.9768607020378113, loss=0.08350762724876404
test: epoch 44, loss 1.4898314476013184, acc=0.6921670436859131, loss=1.4898314476013184
train: epoch 45, loss 0.08281652629375458, acc=0.9779274463653564, loss=0.08281652629375458
test: epoch 45, loss 1.4296051263809204, acc=0.6601645946502686, loss=1.4296051263809204
train: epoch 46, loss 0.07740293443202972, acc=0.9790064096450806, loss=0.07740293443202972
test: epoch 46, loss 1.0612856149673462, acc=0.7305699586868286, loss=1.0612856149673462
train: epoch 47, loss 0.07886167615652084, acc=0.9791222214698792, loss=0.07886167615652084
test: epoch 47, loss 0.9529708027839661, acc=0.7503809928894043, loss=0.9529708027839661
train: epoch 48, loss 0.07538657635450363, acc=0.980359673500061, loss=0.07538657635450363
test: epoch 48, loss 0.9378580451011658, acc=0.8012800812721252, loss=0.9378580451011658
train: epoch 49, loss 0.07219235599040985, acc=0.980737566947937, loss=0.07219235599040985
test: epoch 49, loss 0.8358018398284912, acc=0.8067662119865417, loss=0.8358018398284912
train: epoch 50, loss 0.0671437457203865, acc=0.9827735424041748, loss=0.0671437457203865
test: epoch 50, loss 0.7133688926696777, acc=0.8558366298675537, loss=0.7133688926696777
train: epoch 51, loss 0.06362330913543701, acc=0.9839317202568054, loss=0.06362330913543701
test: epoch 51, loss 0.586582601070404, acc=0.8604084253311157, loss=0.586582601070404
train: epoch 52, loss 0.059339672327041626, acc=0.9845229983329773, loss=0.059339672327041626
test: epoch 52, loss 0.5607524514198303, acc=0.8780859708786011, loss=0.5607524514198303
train: epoch 53, loss 0.055186137557029724, acc=0.9860042929649353, loss=0.055186137557029724
test: epoch 53, loss 0.37150925397872925, acc=0.9238037467002869, loss=0.37150925397872925
train: epoch 54, loss 0.05257236585021019, acc=0.9871380925178528, loss=0.05257236585021019
test: epoch 54, loss 0.3562847375869751, acc=0.9177080392837524, loss=0.3562847375869751
train: epoch 55, loss 0.04901518300175667, acc=0.9886803030967712, loss=0.04901518300175667
test: epoch 55, loss 0.20145069062709808, acc=0.951539158821106, loss=0.20145069062709808
train: epoch 56, loss 0.04547234997153282, acc=0.9893203377723694, loss=0.04547234997153282
test: epoch 56, loss 0.18613186478614807, acc=0.9521487355232239, loss=0.18613186478614807
train: epoch 57, loss 0.04233187064528465, acc=0.9903200268745422, loss=0.04233187064528465
test: epoch 57, loss 0.20156531035900116, acc=0.9591587781906128, loss=0.20156531035900116
train: epoch 58, loss 0.04108957201242447, acc=0.991075873374939, loss=0.04108957201242447
test: epoch 58, loss 0.1666487455368042, acc=0.9615970849990845, loss=0.1666487455368042
train: epoch 59, loss 0.03907053545117378, acc=0.9916000962257385, loss=0.03907053545117378
test: epoch 59, loss 0.14579635858535767, acc=0.9707406163215637, loss=0.14579635858535767
train: epoch 60, loss 0.031212223693728447, acc=0.9934410452842712, loss=0.031212223693728447
test: epoch 60, loss 0.12015119194984436, acc=0.9725693464279175, loss=0.12015119194984436
train: epoch 61, loss 0.03420310840010643, acc=0.9931179285049438, loss=0.03420310840010643
test: epoch 61, loss 0.10084659606218338, acc=0.9811033010482788, loss=0.10084659606218338
train: epoch 62, loss 0.03248880058526993, acc=0.9938859939575195, loss=0.03248880058526993
test: epoch 62, loss 0.10538483411073685, acc=0.9771411418914795, loss=0.10538483411073685
train: epoch 63, loss 0.027558716014027596, acc=0.9941602945327759, loss=0.027558716014027596
test: epoch 63, loss 0.10262634605169296, acc=0.9777506589889526, loss=0.10262634605169296
train: epoch 64, loss 0.03095766343176365, acc=0.9940444827079773, loss=0.03095766343176365
test: epoch 64, loss 0.06916274130344391, acc=0.9814081192016602, loss=0.06916274130344391
train: epoch 65, loss 0.025726381689310074, acc=0.9952697157859802, loss=0.025726381689310074
test: epoch 65, loss 0.08651620894670486, acc=0.9798842072486877, loss=0.08651620894670486
train: epoch 66, loss 0.028150133788585663, acc=0.9946784377098083, loss=0.028150133788585663
test: epoch 66, loss 0.05911479890346527, acc=0.9817128777503967, loss=0.05911479890346527
train: epoch 67, loss 0.027872465550899506, acc=0.995019793510437, loss=0.027872465550899506
test: epoch 67, loss 0.10673990100622177, acc=0.9789698123931885, loss=0.10673990100622177
train: epoch 68, loss 0.027836794033646584, acc=0.9953367710113525, loss=0.027836794033646584
test: epoch 68, loss 0.06128370389342308, acc=0.9814081192016602, loss=0.06128370389342308
train: epoch 69, loss 0.023163771256804466, acc=0.9953367710113525, loss=0.023163771256804466
test: epoch 69, loss 0.05728628486394882, acc=0.984455943107605, loss=0.05728628486394882
train: epoch 70, loss 0.025607692077755928, acc=0.9955928325653076, loss=0.025607692077755928
test: epoch 70, loss 0.06707314401865005, acc=0.9817128777503967, loss=0.06707314401865005
train: epoch 71, loss 0.023353517055511475, acc=0.9960194826126099, loss=0.023353517055511475
test: epoch 71, loss 0.0737757533788681, acc=0.9832367897033691, loss=0.0737757533788681
train: epoch 72, loss 0.026042211800813675, acc=0.9959768652915955, loss=0.026042211800813675
test: epoch 72, loss 0.0817071720957756, acc=0.984455943107605, loss=0.0817071720957756
train: epoch 73, loss 0.02129163220524788, acc=0.9961535930633545, loss=0.02129163220524788
test: epoch 73, loss 0.07928075641393661, acc=0.9798842072486877, loss=0.07928075641393661
train: epoch 74, loss 0.0269438736140728, acc=0.9954648017883301, loss=0.0269438736140728
test: epoch 74, loss 0.10542535036802292, acc=0.9756171703338623, loss=0.10542535036802292
train: epoch 75, loss 0.022849394008517265, acc=0.9962145686149597, loss=0.022849394008517265
test: epoch 75, loss 0.05464262142777443, acc=0.9823224544525146, loss=0.05464262142777443
train: epoch 76, loss 0.02699902094900608, acc=0.9959158897399902, loss=0.02699902094900608
test: epoch 76, loss 0.06505315005779266, acc=0.9829320311546326, loss=0.06505315005779266
train: epoch 77, loss 0.02715664729475975, acc=0.9953550696372986, loss=0.02715664729475975
test: epoch 77, loss 0.08779863268136978, acc=0.9795793890953064, loss=0.08779863268136978
train: epoch 78, loss 0.03229058161377907, acc=0.9948064684867859, loss=0.03229058161377907
test: epoch 78, loss 0.08126071840524673, acc=0.9789698123931885, loss=0.08126071840524673
train: epoch 79, loss 0.028422467410564423, acc=0.9947881698608398, loss=0.028422467410564423
test: epoch 79, loss 0.0935007631778717, acc=0.9820176959037781, loss=0.0935007631778717
train: epoch 80, loss 0.023161865770816803, acc=0.9962145686149597, loss=0.023161865770816803
test: epoch 80, loss 0.07172523438930511, acc=0.9804937243461609, loss=0.07172523438930511
train: epoch 81, loss 0.03192264586687088, acc=0.9957451820373535, loss=0.03192264586687088
test: epoch 81, loss 0.08925623446702957, acc=0.9804937243461609, loss=0.08925623446702957
train: epoch 82, loss 0.030760442838072777, acc=0.9946845769882202, loss=0.030760442838072777
test: epoch 82, loss 0.06611880660057068, acc=0.9862846732139587, loss=0.06611880660057068
train: epoch 83, loss 0.03072652965784073, acc=0.9946540594100952, loss=0.03072652965784073
test: epoch 83, loss 0.10464147478342056, acc=0.9853703379631042, loss=0.10464147478342056
train: epoch 84, loss 0.02837788127362728, acc=0.9954769611358643, loss=0.02837788127362728
test: epoch 84, loss 0.06787446141242981, acc=0.9850655198097229, loss=0.06787446141242981
train: epoch 85, loss 0.027546430006623268, acc=0.9954343438148499, loss=0.027546430006623268
test: epoch 85, loss 0.14132651686668396, acc=0.9817128777503967, loss=0.14132651686668396
train: epoch 86, loss 0.035649221390485764, acc=0.9946784377098083, loss=0.035649221390485764
test: epoch 86, loss 0.09467773139476776, acc=0.9786650538444519, loss=0.09467773139476776
train: epoch 87, loss 0.029349952936172485, acc=0.9953916668891907, loss=0.029349952936172485
test: epoch 87, loss 0.055393412709236145, acc=0.9881134033203125, loss=0.055393412709236145
train: epoch 88, loss 0.02647772803902626, acc=0.9959036707878113, loss=0.02647772803902626
test: epoch 88, loss 0.05745375156402588, acc=0.9884181618690491, loss=0.05745375156402588
train: epoch 89, loss 0.025443060323596, acc=0.9959768652915955, loss=0.025443060323596
test: epoch 89, loss 0.07310221344232559, acc=0.9884181618690491, loss=0.07310221344232559
train: epoch 90, loss 0.030359135940670967, acc=0.9957878589630127, loss=0.030359135940670967
test: epoch 90, loss 0.06846605986356735, acc=0.9881134033203125, loss=0.06846605986356735
train: epoch 91, loss 0.032853927463293076, acc=0.9952758550643921, loss=0.032853927463293076
test: epoch 91, loss 0.059771183878183365, acc=0.9853703379631042, loss=0.059771183878183365
train: epoch 92, loss 0.030155479907989502, acc=0.9953916668891907, loss=0.030155479907989502
test: epoch 92, loss 0.11363260447978973, acc=0.9862846732139587, loss=0.11363260447978973
train: epoch 93, loss 0.04054194688796997, acc=0.9938372373580933, loss=0.04054194688796997
test: epoch 93, loss 0.08513674885034561, acc=0.9859798550605774, loss=0.08513674885034561
train: epoch 94, loss 0.04125708341598511, acc=0.9941664338111877, loss=0.04125708341598511
test: epoch 94, loss 0.09043871611356735, acc=0.9856750965118408, loss=0.09043871611356735
train: epoch 95, loss 0.034563224762678146, acc=0.9939591884613037, loss=0.034563224762678146
test: epoch 95, loss 0.045686833560466766, acc=0.9887229800224304, loss=0.045686833560466766
train: epoch 96, loss 0.02543899044394493, acc=0.9959341883659363, loss=0.02543899044394493
test: epoch 96, loss 0.026404347270727158, acc=0.9896373152732849, loss=0.026404347270727158
train: epoch 97, loss 0.030874265357851982, acc=0.996092677116394, loss=0.030874265357851982
test: epoch 97, loss 0.060746174305677414, acc=0.9875038266181946, loss=0.060746174305677414
train: epoch 98, loss 0.028376249596476555, acc=0.9957147240638733, loss=0.028376249596476555
test: epoch 98, loss 0.05693017318844795, acc=0.9896373152732849, loss=0.05693017318844795
train: epoch 99, loss 0.029136862605810165, acc=0.9955623149871826, loss=0.029136862605810165
test: epoch 99, loss 0.05581539869308472, acc=0.9878085851669312, loss=0.05581539869308472
train: epoch 100, loss 0.03731919080018997, acc=0.9951478242874146, loss=0.03731919080018997
test: epoch 100, loss 0.07142722606658936, acc=0.9865894317626953, loss=0.07142722606658936
train: epoch 101, loss 0.03852759301662445, acc=0.9941176176071167, loss=0.03852759301662445
test: epoch 101, loss 0.10238923877477646, acc=0.9862846732139587, loss=0.10238923877477646
train: epoch 102, loss 0.0465678945183754, acc=0.9941785931587219, loss=0.0465678945183754
test: epoch 102, loss 0.05786836892366409, acc=0.9865894317626953, loss=0.05786836892366409
train: epoch 103, loss 0.03608905151486397, acc=0.9940323233604431, loss=0.03608905151486397
test: epoch 103, loss 0.04918108880519867, acc=0.9875038266181946, loss=0.04918108880519867
train: epoch 104, loss 0.04281260818243027, acc=0.9922096729278564, loss=0.04281260818243027
test: epoch 104, loss 0.0677642822265625, acc=0.9850655198097229, loss=0.0677642822265625
train: epoch 105, loss 0.05246913433074951, acc=0.9917647242546082, loss=0.05246913433074951
test: epoch 105, loss 0.11219540238380432, acc=0.9789698123931885, loss=0.11219540238380432
train: epoch 106, loss 0.05525728687644005, acc=0.9908686280250549, loss=0.05525728687644005
test: epoch 106, loss 0.06591951102018356, acc=0.9847607612609863, loss=0.06591951102018356
train: epoch 107, loss 0.046579454094171524, acc=0.9906613826751709, loss=0.046579454094171524
test: epoch 107, loss 0.07656100392341614, acc=0.9838463664054871, loss=0.07656100392341614
train: epoch 108, loss 0.0799672082066536, acc=0.9844254851341248, loss=0.0799672082066536
test: epoch 108, loss 0.10028957575559616, acc=0.9743980765342712, loss=0.10028957575559616
train: epoch 109, loss 0.10341350734233856, acc=0.9841451048851013, loss=0.10341350734233856
test: epoch 109, loss 0.09546893835067749, acc=0.9832367897033691, loss=0.09546893835067749
train: epoch 110, loss 0.06068633124232292, acc=0.9886924624443054, loss=0.06068633124232292
test: epoch 110, loss 0.06172437593340874, acc=0.9878085851669312, loss=0.06172437593340874
train: epoch 111, loss 0.06581670045852661, acc=0.9882292151451111, loss=0.06581670045852661
test: epoch 111, loss 0.14308546483516693, acc=0.9798842072486877, loss=0.14308546483516693
train: epoch 112, loss 0.07411645352840424, acc=0.9878208041191101, loss=0.07411645352840424
test: epoch 112, loss 0.0712752491235733, acc=0.9814081192016602, loss=0.0712752491235733
train: epoch 113, loss 0.0400594137609005, acc=0.9919536709785461, loss=0.0400594137609005
test: epoch 113, loss 0.07665883749723434, acc=0.9850655198097229, loss=0.07665883749723434
train: epoch 114, loss 0.048646170645952225, acc=0.9921609163284302, loss=0.048646170645952225
test: epoch 114, loss 0.029061783105134964, acc=0.9929899573326111, loss=0.029061783105134964
