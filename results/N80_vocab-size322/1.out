# ["--N=80", "--n_epochs=250", "--batch_size=32", "--lr=0.001", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=1", "--n_layers=3", "--save_run=1", "--n_symbols=322"]
Namespace(N=80, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=250, n_layers=3, n_runs=1, n_summands=2, n_symbols=322, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1088067580, receiver_embed_dim=64, save_run=True, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.412248373031616, acc=0.19474005699157715, loss=2.412248373031616
test: epoch 1, loss 4.411476135253906, acc=0.07468247413635254, loss=4.411476135253906
train: epoch 2, loss 1.4273489713668823, acc=0.3835461437702179, loss=1.4273489713668823
test: epoch 2, loss 4.256814956665039, acc=0.09534292668104172, loss=4.256814956665039
train: epoch 3, loss 1.183451533317566, acc=0.4809618890285492, loss=1.183451533317566
test: epoch 3, loss 3.703183650970459, acc=0.11549534648656845, loss=3.703183650970459
train: epoch 4, loss 1.0216177701950073, acc=0.553710401058197, loss=1.0216177701950073
test: epoch 4, loss 4.160549163818359, acc=0.12988992035388947, loss=4.160549163818359
train: epoch 5, loss 0.8830388188362122, acc=0.6225774884223938, loss=0.8830388188362122
test: epoch 5, loss 3.6441922187805176, acc=0.14936494827270508, loss=3.6441922187805176
train: epoch 6, loss 0.7109588384628296, acc=0.7064623236656189, loss=0.7109588384628296
test: epoch 6, loss 3.5778350830078125, acc=0.1593564748764038, loss=3.5778350830078125
train: epoch 7, loss 0.5702452063560486, acc=0.7706214785575867, loss=0.5702452063560486
test: epoch 7, loss 4.074096202850342, acc=0.1849280297756195, loss=4.074096202850342
train: epoch 8, loss 0.40547212958335876, acc=0.8481693267822266, loss=0.40547212958335876
test: epoch 8, loss 3.5975165367126465, acc=0.23234547674655914, loss=3.5975165367126465
train: epoch 9, loss 0.23675522208213806, acc=0.9197595119476318, loss=0.23675522208213806
test: epoch 9, loss 3.045689105987549, acc=0.2794242203235626, loss=3.045689105987549
train: epoch 10, loss 0.2011040598154068, acc=0.9325622320175171, loss=0.2011040598154068
test: epoch 10, loss 3.657745838165283, acc=0.28179508447647095, loss=3.657745838165283
train: epoch 11, loss 0.18254221975803375, acc=0.9377070069313049, loss=0.18254221975803375
test: epoch 11, loss 3.333313465118408, acc=0.2856900990009308, loss=3.333313465118408
train: epoch 12, loss 0.16836291551589966, acc=0.9434546828269958, loss=0.16836291551589966
test: epoch 12, loss 3.3740105628967285, acc=0.3112616539001465, loss=3.3740105628967285
train: epoch 13, loss 0.1585029512643814, acc=0.9480135440826416, loss=0.1585029512643814
test: epoch 13, loss 3.1850078105926514, acc=0.331752747297287, loss=3.1850078105926514
train: epoch 14, loss 0.1468236893415451, acc=0.9515258073806763, loss=0.1468236893415451
test: epoch 14, loss 3.645024299621582, acc=0.2521591782569885, loss=3.645024299621582
train: epoch 15, loss 0.13824312388896942, acc=0.9545707106590271, loss=0.13824312388896942
test: epoch 15, loss 3.331461191177368, acc=0.28094834089279175, loss=3.331461191177368
train: epoch 16, loss 0.13561633229255676, acc=0.9558306336402893, loss=0.13561633229255676
test: epoch 16, loss 3.162771224975586, acc=0.33361557126045227, loss=3.162771224975586
train: epoch 17, loss 0.1271900087594986, acc=0.9588890671730042, loss=0.1271900087594986
test: epoch 17, loss 3.488468647003174, acc=0.3195596933364868, loss=3.488468647003174
train: epoch 18, loss 0.12102892249822617, acc=0.9612227082252502, loss=0.12102892249822617
test: epoch 18, loss 3.2058448791503906, acc=0.315664678812027, loss=3.2058448791503906
train: epoch 19, loss 0.11736834794282913, acc=0.962763786315918, loss=0.11736834794282913
test: epoch 19, loss 3.292781352996826, acc=0.3093988001346588, loss=3.292781352996826
train: epoch 20, loss 0.1108454093337059, acc=0.9644606113433838, loss=0.1108454093337059
test: epoch 20, loss 3.2234315872192383, acc=0.33039796352386475, loss=3.2234315872192383
train: epoch 21, loss 0.10896345227956772, acc=0.9654462337493896, loss=0.10896345227956772
test: epoch 21, loss 3.293971061706543, acc=0.31007620692253113, loss=3.293971061706543
train: epoch 22, loss 0.10116168111562729, acc=0.968209981918335, loss=0.10116168111562729
test: epoch 22, loss 3.054877519607544, acc=0.3453005850315094, loss=3.054877519607544
train: epoch 23, loss 0.09820540994405746, acc=0.9689280390739441, loss=0.09820540994405746
test: epoch 23, loss 3.2768619060516357, acc=0.3520745038986206, loss=3.2768619060516357
train: epoch 24, loss 0.0940403938293457, acc=0.9705165028572083, loss=0.0940403938293457
test: epoch 24, loss 3.3256094455718994, acc=0.33107537031173706, loss=3.3256094455718994
train: epoch 25, loss 0.09176510572433472, acc=0.9712650179862976, loss=0.09176510572433472
test: epoch 25, loss 3.2816312313079834, acc=0.3708721399307251, loss=3.2816312313079834
train: epoch 26, loss 0.0873434841632843, acc=0.9729619026184082, loss=0.0873434841632843
test: epoch 26, loss 3.2299158573150635, acc=0.3495343029499054, loss=3.2299158573150635
train: epoch 27, loss 0.08632224798202515, acc=0.9735105633735657, loss=0.08632224798202515
test: epoch 27, loss 2.9119787216186523, acc=0.3852667212486267, loss=2.9119787216186523
train: epoch 28, loss 0.08435675501823425, acc=0.9743708968162537, loss=0.08435675501823425
test: epoch 28, loss 2.7705676555633545, acc=0.3920406401157379, loss=2.7705676555633545
train: epoch 29, loss 0.08289797604084015, acc=0.9747569561004639, loss=0.08289797604084015
test: epoch 29, loss 3.532705545425415, acc=0.35596951842308044, loss=3.532705545425415
train: epoch 30, loss 0.08009360730648041, acc=0.9754343628883362, loss=0.08009360730648041
test: epoch 30, loss 2.928673505783081, acc=0.3666384518146515, loss=2.928673505783081
train: epoch 31, loss 0.07936454564332962, acc=0.9760473966598511, loss=0.07936454564332962
test: epoch 31, loss 2.9068784713745117, acc=0.4006773829460144, loss=2.9068784713745117
train: epoch 32, loss 0.07553250342607498, acc=0.9776087999343872, loss=0.07553250342607498
test: epoch 32, loss 2.801187515258789, acc=0.39441150426864624, loss=2.801187515258789
train: epoch 33, loss 0.07772327214479446, acc=0.9772768616676331, loss=0.07772327214479446
test: epoch 33, loss 2.6616098880767822, acc=0.42912787199020386, loss=2.6616098880767822
train: epoch 34, loss 0.07280419021844864, acc=0.9783810377120972, loss=0.07280419021844864
test: epoch 34, loss 2.6430118083953857, acc=0.41625741124153137, loss=2.6430118083953857
train: epoch 35, loss 0.07376576215028763, acc=0.9786587357521057, loss=0.07376576215028763
test: epoch 35, loss 2.464240789413452, acc=0.45469939708709717, loss=2.464240789413452
train: epoch 36, loss 0.07045496255159378, acc=0.9792277812957764, loss=0.07045496255159378
test: epoch 36, loss 2.569801092147827, acc=0.44555461406707764, loss=2.569801092147827
train: epoch 37, loss 0.0702996477484703, acc=0.9792447090148926, loss=0.0702996477484703
test: epoch 37, loss 2.6252574920654297, acc=0.4345470070838928, loss=2.6252574920654297
train: epoch 38, loss 0.06859180331230164, acc=0.9795563220977783, loss=0.06859180331230164
test: epoch 38, loss 2.2157320976257324, acc=0.46587637066841125, loss=2.2157320976257324
train: epoch 39, loss 0.06772687286138535, acc=0.9806028604507446, loss=0.06772687286138535
test: epoch 39, loss 2.4247052669525146, acc=0.4399661421775818, loss=2.4247052669525146
train: epoch 40, loss 0.06592489033937454, acc=0.981009304523468, loss=0.06592489033937454
test: epoch 40, loss 2.7135965824127197, acc=0.42404741048812866, loss=2.7135965824127197
train: epoch 41, loss 0.06538058817386627, acc=0.981510579586029, loss=0.06538058817386627
test: epoch 41, loss 2.5722458362579346, acc=0.45656222105026245, loss=2.5722458362579346
train: epoch 42, loss 0.062153976410627365, acc=0.9819441437721252, loss=0.062153976410627365
test: epoch 42, loss 2.3147780895233154, acc=0.47705334424972534, loss=2.3147780895233154
train: epoch 43, loss 0.06318461149930954, acc=0.9817883372306824, loss=0.06318461149930954
test: epoch 43, loss 2.2741315364837646, acc=0.4613039791584015, loss=2.2741315364837646
train: epoch 44, loss 0.06072450429201126, acc=0.982624888420105, loss=0.06072450429201126
test: epoch 44, loss 2.023890733718872, acc=0.4960203170776367, loss=2.023890733718872
train: epoch 45, loss 0.06210092082619667, acc=0.9824826121330261, loss=0.06210092082619667
test: epoch 45, loss 2.1640589237213135, acc=0.48450466990470886, loss=2.1640589237213135
train: epoch 46, loss 0.059284310787916183, acc=0.9833700060844421, loss=0.059284310787916183
test: epoch 46, loss 2.2020680904388428, acc=0.4909398853778839, loss=2.2020680904388428
train: epoch 47, loss 0.06319623440504074, acc=0.9823742508888245, loss=0.06319623440504074
test: epoch 47, loss 2.25441312789917, acc=0.4995766282081604, loss=2.25441312789917
train: epoch 48, loss 0.058576278388500214, acc=0.9836578965187073, loss=0.058576278388500214
test: epoch 48, loss 1.9417906999588013, acc=0.539712131023407, loss=1.9417906999588013
train: epoch 49, loss 0.06079939752817154, acc=0.9835529327392578, loss=0.06079939752817154
test: epoch 49, loss 1.7250089645385742, acc=0.5630821585655212, loss=1.7250089645385742
train: epoch 50, loss 0.05823113024234772, acc=0.9837459921836853, loss=0.05823113024234772
test: epoch 50, loss 2.0371041297912598, acc=0.5405588746070862, loss=2.0371041297912598
train: epoch 51, loss 0.0586991086602211, acc=0.9840677380561829, loss=0.0586991086602211
test: epoch 51, loss 1.9842958450317383, acc=0.5332768559455872, loss=1.9842958450317383
train: epoch 52, loss 0.058958787471055984, acc=0.9841083884239197, loss=0.058958787471055984
test: epoch 52, loss 1.9012776613235474, acc=0.53767991065979, loss=1.9012776613235474
train: epoch 53, loss 0.0577937550842762, acc=0.9843217730522156, loss=0.0577937550842762
test: epoch 53, loss 1.7735098600387573, acc=0.5647755861282349, loss=1.7735098600387573
train: epoch 54, loss 0.06250636279582977, acc=0.9838306307792664, loss=0.06250636279582977
test: epoch 54, loss 1.756908893585205, acc=0.5459780097007751, loss=1.756908893585205
train: epoch 55, loss 0.05727013200521469, acc=0.9845927357673645, loss=0.05727013200521469
test: epoch 55, loss 1.5210336446762085, acc=0.6230313181877136, loss=1.5210336446762085
train: epoch 56, loss 0.059796255081892014, acc=0.9843353033065796, loss=0.059796255081892014
test: epoch 56, loss 1.7180538177490234, acc=0.590347170829773, loss=1.7180538177490234
train: epoch 57, loss 0.05830592289566994, acc=0.9846537113189697, loss=0.05830592289566994
test: epoch 57, loss 1.634209156036377, acc=0.5872988700866699, loss=1.634209156036377
train: epoch 58, loss 0.05832788720726967, acc=0.985256552696228, loss=0.05832788720726967
test: epoch 58, loss 1.5028769969940186, acc=0.6636748313903809, loss=1.5028769969940186
train: epoch 59, loss 0.059611640870571136, acc=0.9846401214599609, loss=0.059611640870571136
test: epoch 59, loss 1.5901768207550049, acc=0.6480948328971863, loss=1.5901768207550049
train: epoch 60, loss 0.05578174814581871, acc=0.9857307076454163, loss=0.05578174814581871
test: epoch 60, loss 1.4067944288253784, acc=0.6585944294929504, loss=1.4067944288253784
train: epoch 61, loss 0.05627494305372238, acc=0.9857815504074097, loss=0.05627494305372238
test: epoch 61, loss 1.459306240081787, acc=0.6508044004440308, loss=1.459306240081787
train: epoch 62, loss 0.05476757511496544, acc=0.9862049221992493, loss=0.05476757511496544
test: epoch 62, loss 1.4099571704864502, acc=0.6711261868476868, loss=1.4099571704864502
train: epoch 63, loss 0.05343545973300934, acc=0.9865707159042358, loss=0.05343545973300934
test: epoch 63, loss 1.2357913255691528, acc=0.695681631565094, loss=1.2357913255691528
train: epoch 64, loss 0.05210288614034653, acc=0.9867095947265625, loss=0.05210288614034653
test: epoch 64, loss 1.1513152122497559, acc=0.7239627242088318, loss=1.1513152122497559
train: epoch 65, loss 0.05101153999567032, acc=0.9872413277626038, loss=0.05101153999567032
test: epoch 65, loss 1.2921339273452759, acc=0.7207451462745667, loss=1.2921339273452759
train: epoch 66, loss 0.050110168755054474, acc=0.9875833988189697, loss=0.050110168755054474
test: epoch 66, loss 1.2086706161499023, acc=0.7319220900535583, loss=1.2086706161499023
train: epoch 67, loss 0.04845324903726578, acc=0.987746000289917, loss=0.04845324903726578
test: epoch 67, loss 0.9656336307525635, acc=0.7685012817382812, loss=0.9656336307525635
train: epoch 68, loss 0.04787534847855568, acc=0.9885690212249756, loss=0.04787534847855568
test: epoch 68, loss 0.7406641244888306, acc=0.8081287145614624, loss=0.7406641244888306
train: epoch 69, loss 0.047639552503824234, acc=0.9886232018470764, loss=0.047639552503824234
test: epoch 69, loss 0.8127363324165344, acc=0.8106689453125, loss=0.8127363324165344
train: epoch 70, loss 0.048527464270591736, acc=0.988673985004425, loss=0.048527464270591736
test: epoch 70, loss 0.6545413136482239, acc=0.8247247934341431, loss=0.6545413136482239
train: epoch 71, loss 0.0422094464302063, acc=0.9898865222930908, loss=0.0422094464302063
test: epoch 71, loss 0.548806369304657, acc=0.8697713613510132, loss=0.548806369304657
train: epoch 72, loss 0.04475536569952965, acc=0.9897273778915405, loss=0.04475536569952965
test: epoch 72, loss 0.6083315014839172, acc=0.8765453100204468, loss=0.6083315014839172
train: epoch 73, loss 0.04807356745004654, acc=0.9893581867218018, loss=0.04807356745004654
test: epoch 73, loss 0.5439038872718811, acc=0.871972918510437, loss=0.5439038872718811
train: epoch 74, loss 0.03934468701481819, acc=0.9904860258102417, loss=0.03934468701481819
test: epoch 74, loss 0.49772560596466064, acc=0.9036409854888916, loss=0.49772560596466064
train: epoch 75, loss 0.04096138849854469, acc=0.9912548661231995, loss=0.04096138849854469
test: epoch 75, loss 0.34499749541282654, acc=0.9114310145378113, loss=0.34499749541282654
train: epoch 76, loss 0.04030780494213104, acc=0.9911701679229736, loss=0.04030780494213104
test: epoch 76, loss 0.3146323561668396, acc=0.9219305515289307, loss=0.3146323561668396
train: epoch 77, loss 0.035935793071985245, acc=0.992494523525238, loss=0.035935793071985245
test: epoch 77, loss 0.2206212282180786, acc=0.954784095287323, loss=0.2206212282180786
train: epoch 78, loss 0.033370375633239746, acc=0.9930262565612793, loss=0.033370375633239746
test: epoch 78, loss 0.3042506277561188, acc=0.948348879814148, loss=0.3042506277561188
train: epoch 79, loss 0.03570445626974106, acc=0.9932091236114502, loss=0.03570445626974106
test: epoch 79, loss 0.27277395129203796, acc=0.9502117037773132, loss=0.27277395129203796
train: epoch 80, loss 0.03526979312300682, acc=0.9930431842803955, loss=0.03526979312300682
test: epoch 80, loss 0.1948424130678177, acc=0.9644368886947632, loss=0.1948424130678177
train: epoch 81, loss 0.03504515066742897, acc=0.9922946691513062, loss=0.03504515066742897
test: epoch 81, loss 0.12292338162660599, acc=0.9679931998252869, loss=0.12292338162660599
train: epoch 82, loss 0.03075706772506237, acc=0.9946249127388, loss=0.03075706772506237
test: epoch 82, loss 0.11299349367618561, acc=0.9703640937805176, loss=0.11299349367618561
train: epoch 83, loss 0.03937047719955444, acc=0.9930093288421631, loss=0.03937047719955444
test: epoch 83, loss 0.12507300078868866, acc=0.9718882441520691, loss=0.12507300078868866
train: epoch 84, loss 0.041783057153224945, acc=0.9916579127311707, loss=0.041783057153224945
test: epoch 84, loss 0.12225978076457977, acc=0.9740897417068481, loss=0.12225978076457977
train: epoch 85, loss 0.027817415073513985, acc=0.9936257600784302, loss=0.027817415073513985
test: epoch 85, loss 0.08193571865558624, acc=0.9771380424499512, loss=0.08193571865558624
train: epoch 86, loss 0.027014268562197685, acc=0.9942591190338135, loss=0.027014268562197685
test: epoch 86, loss 0.10487576574087143, acc=0.9757832288742065, loss=0.10487576574087143
train: epoch 87, loss 0.040540847927331924, acc=0.9923319220542908, loss=0.040540847927331924
test: epoch 87, loss 0.1764899492263794, acc=0.9701947569847107, loss=0.1764899492263794
train: epoch 88, loss 0.03434029594063759, acc=0.9928603172302246, loss=0.03434029594063759
test: epoch 88, loss 0.09837465733289719, acc=0.9791702032089233, loss=0.09837465733289719
train: epoch 89, loss 0.023712579160928726, acc=0.9947095513343811, loss=0.023712579160928726
test: epoch 89, loss 0.10276143997907639, acc=0.9779847860336304, loss=0.10276143997907639
train: epoch 90, loss 0.023008938878774643, acc=0.9955766201019287, loss=0.023008938878774643
test: epoch 90, loss 0.09704796969890594, acc=0.9773073792457581, loss=0.09704796969890594
train: epoch 91, loss 0.03517141565680504, acc=0.9930601119995117, loss=0.03517141565680504
test: epoch 91, loss 0.1099592074751854, acc=0.9769686460494995, loss=0.1099592074751854
train: epoch 92, loss 0.022916166111826897, acc=0.9945063591003418, loss=0.022916166111826897
test: epoch 92, loss 0.08059944957494736, acc=0.9810330271720886, loss=0.08059944957494736
train: epoch 93, loss 0.025317469611763954, acc=0.994194746017456, loss=0.025317469611763954
test: epoch 93, loss 0.3441501557826996, acc=0.9735817313194275, loss=0.3441501557826996
train: epoch 94, loss 0.024453843012452126, acc=0.9954614639282227, loss=0.024453843012452126
test: epoch 94, loss 0.07202894985675812, acc=0.9795088768005371, loss=0.07202894985675812
train: epoch 95, loss 0.03040742129087448, acc=0.99485182762146, loss=0.03040742129087448
test: epoch 95, loss 0.09285996109247208, acc=0.9781541228294373, loss=0.09285996109247208
train: epoch 96, loss 0.03077574260532856, acc=0.9948010444641113, loss=0.03077574260532856
test: epoch 96, loss 0.08163842558860779, acc=0.982726514339447, loss=0.08163842558860779
train: epoch 97, loss 0.02724367566406727, acc=0.9946316480636597, loss=0.02724367566406727
test: epoch 97, loss 0.11463514715433121, acc=0.9783234596252441, loss=0.11463514715433121
train: epoch 98, loss 0.021360397338867188, acc=0.9957256317138672, loss=0.021360397338867188
test: epoch 98, loss 0.12649814784526825, acc=0.9823877811431885, loss=0.12649814784526825
train: epoch 99, loss 0.01907852664589882, acc=0.9964064359664917, loss=0.01907852664589882
test: epoch 99, loss 0.08738601207733154, acc=0.982726514339447, loss=0.08738601207733154
train: epoch 100, loss 0.021464357152581215, acc=0.9959119558334351, loss=0.021464357152581215
test: epoch 100, loss 0.07930926233530045, acc=0.98391193151474, loss=0.07930926233530045
train: epoch 101, loss 0.024196214973926544, acc=0.9958747029304504, loss=0.024196214973926544
test: epoch 101, loss 0.09414064884185791, acc=0.9812023639678955, loss=0.09414064884185791
train: epoch 102, loss 0.030551280826330185, acc=0.9949601888656616, loss=0.030551280826330185
test: epoch 102, loss 0.06662404537200928, acc=0.9840812683105469, loss=0.06662404537200928
train: epoch 103, loss 0.020225705578923225, acc=0.9963488578796387, loss=0.020225705578923225
test: epoch 103, loss 0.07965116202831268, acc=0.9825571775436401, loss=0.07965116202831268
train: epoch 104, loss 0.026264669373631477, acc=0.9954445362091064, loss=0.026264669373631477
test: epoch 104, loss 0.059933073818683624, acc=0.9817104339599609, loss=0.059933073818683624
train: epoch 105, loss 0.02906649559736252, acc=0.9951532483100891, loss=0.02906649559736252
test: epoch 105, loss 0.08034154772758484, acc=0.9849280118942261, loss=0.08034154772758484
train: epoch 106, loss 0.023195059970021248, acc=0.9964368939399719, loss=0.023195059970021248
test: epoch 106, loss 0.0745653435587883, acc=0.9866214990615845, loss=0.0745653435587883
train: epoch 107, loss 0.023251809179782867, acc=0.9958983659744263, loss=0.023251809179782867
test: epoch 107, loss 0.06055488809943199, acc=0.9861134886741638, loss=0.06055488809943199
train: epoch 108, loss 0.024194683879613876, acc=0.9963048100471497, loss=0.024194683879613876
test: epoch 108, loss 0.06897485256195068, acc=0.985097348690033, loss=0.06897485256195068
train: epoch 109, loss 0.025311609730124474, acc=0.996667206287384, loss=0.025311609730124474
test: epoch 109, loss 0.05457555130124092, acc=0.9830651879310608, loss=0.05457555130124092
train: epoch 110, loss 0.02194470539689064, acc=0.9969856142997742, loss=0.02194470539689064
test: epoch 110, loss 0.1008792370557785, acc=0.9812023639678955, loss=0.1008792370557785
train: epoch 111, loss 0.03859836235642433, acc=0.994150698184967, loss=0.03859836235642433
test: epoch 111, loss 0.13535325229167938, acc=0.9776460528373718, loss=0.13535325229167938
train: epoch 112, loss 0.03153036907315254, acc=0.9955258369445801, loss=0.03153036907315254
test: epoch 112, loss 0.08214285969734192, acc=0.9845893383026123, loss=0.08214285969734192
train: epoch 113, loss 0.031224023550748825, acc=0.9958509802818298, loss=0.031224023550748825
test: epoch 113, loss 0.09069473296403885, acc=0.9822184443473816, loss=0.09069473296403885
train: epoch 114, loss 0.02790776826441288, acc=0.9953632354736328, loss=0.02790776826441288
test: epoch 114, loss 0.06943780183792114, acc=0.985097348690033, loss=0.06943780183792114
train: epoch 115, loss 0.04222239553928375, acc=0.9941473603248596, loss=0.04222239553928375
test: epoch 115, loss 0.13427190482616425, acc=0.9710415005683899, loss=0.13427190482616425
train: epoch 116, loss 0.046601634472608566, acc=0.9907739162445068, loss=0.046601634472608566
test: epoch 116, loss 0.0746493712067604, acc=0.9835732579231262, loss=0.0746493712067604
train: epoch 117, loss 0.03350896015763283, acc=0.9940423369407654, loss=0.03350896015763283
test: epoch 117, loss 0.08515114337205887, acc=0.9817104339599609, loss=0.08515114337205887
train: epoch 118, loss 0.036082345992326736, acc=0.9943640828132629, loss=0.036082345992326736
test: epoch 118, loss 0.12786594033241272, acc=0.985097348690033, loss=0.12786594033241272
train: epoch 119, loss 0.032514095306396484, acc=0.9951465129852295, loss=0.032514095306396484
test: epoch 119, loss 0.05953586474061012, acc=0.9834039211273193, loss=0.05953586474061012
train: epoch 120, loss 0.03282340615987778, acc=0.9950922727584839, loss=0.03282340615987778
test: epoch 120, loss 0.07499349862337112, acc=0.9835732579231262, loss=0.07499349862337112
train: epoch 121, loss 0.041217487305402756, acc=0.9943640828132629, loss=0.041217487305402756
test: epoch 121, loss 0.09821370244026184, acc=0.9815410375595093, loss=0.09821370244026184
train: epoch 122, loss 0.03553520888090134, acc=0.9956240653991699, loss=0.03553520888090134
test: epoch 122, loss 0.07908938080072403, acc=0.982726514339447, loss=0.07908938080072403
train: epoch 123, loss 0.02747292071580887, acc=0.9962133765220642, loss=0.02747292071580887
test: epoch 123, loss 0.07538238912820816, acc=0.9847586750984192, loss=0.07538238912820816
train: epoch 124, loss 0.031690455973148346, acc=0.9954038858413696, loss=0.031690455973148346
test: epoch 124, loss 0.07042961567640305, acc=0.9856054186820984, loss=0.07042961567640305
train: epoch 125, loss 0.023193614557385445, acc=0.9967247843742371, loss=0.023193614557385445
test: epoch 125, loss 0.06048658490180969, acc=0.9901778101921082, loss=0.06048658490180969
