# ["--N=80", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=1", "--n_layers=3", "--save_run=1", "--test_split=0.3", "--n_symbols=644"]
Namespace(N=80, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=644, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1448217868, receiver_embed_dim=64, save_run=True, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.3, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.5194761753082275, acc=0.17885912954807281, loss=2.5194761753082275
test: epoch 1, loss 5.273270606994629, acc=0.06684084236621857, loss=5.273270606994629
train: epoch 2, loss 1.5503100156784058, acc=0.3460483253002167, loss=1.5503100156784058
test: epoch 2, loss 5.542381286621094, acc=0.08055736869573593, loss=5.542381286621094
train: epoch 3, loss 1.3046034574508667, acc=0.43728718161582947, loss=1.3046034574508667
test: epoch 3, loss 5.4490742683410645, acc=0.1121271476149559, loss=5.4490742683410645
train: epoch 4, loss 1.1683810949325562, acc=0.4959721267223358, loss=1.1683810949325562
test: epoch 4, loss 4.447908401489258, acc=0.12758545577526093, loss=4.447908401489258
train: epoch 5, loss 0.9640352129936218, acc=0.5947746634483337, loss=0.9640352129936218
test: epoch 5, loss 5.052275657653809, acc=0.14391465485095978, loss=5.052275657653809
train: epoch 6, loss 0.7530854344367981, acc=0.6920052170753479, loss=0.7530854344367981
test: epoch 6, loss 3.8507533073425293, acc=0.19333769381046295, loss=3.8507533073425293
train: epoch 7, loss 0.5932689905166626, acc=0.7662747502326965, loss=0.5932689905166626
test: epoch 7, loss 3.7139346599578857, acc=0.17940343916416168, loss=3.7139346599578857
train: epoch 8, loss 0.466105580329895, acc=0.8251513242721558, loss=0.466105580329895
test: epoch 8, loss 3.9038586616516113, acc=0.21010233461856842, loss=3.9038586616516113
train: epoch 9, loss 0.36714088916778564, acc=0.8653168082237244, loss=0.36714088916778564
test: epoch 9, loss 4.03062629699707, acc=0.1889832317829132, loss=4.03062629699707
train: epoch 10, loss 0.3100442886352539, acc=0.8897017240524292, loss=0.3100442886352539
test: epoch 10, loss 3.3812813758850098, acc=0.22643151879310608, loss=3.3812813758850098
train: epoch 11, loss 0.272688627243042, acc=0.9035793542861938, loss=0.272688627243042
test: epoch 11, loss 3.710400104522705, acc=0.22556063532829285, loss=3.710400104522705
train: epoch 12, loss 0.24697290360927582, acc=0.9141302108764648, loss=0.24697290360927582
test: epoch 12, loss 3.221876382827759, acc=0.2543000280857086, loss=3.221876382827759
train: epoch 13, loss 0.21862748265266418, acc=0.9251469373703003, loss=0.21862748265266418
test: epoch 13, loss 3.4575207233428955, acc=0.2571304142475128, loss=3.4575207233428955
train: epoch 14, loss 0.19883783161640167, acc=0.9345003366470337, loss=0.19883783161640167
test: epoch 14, loss 3.1357038021087646, acc=0.28151535987854004, loss=3.1357038021087646
train: epoch 15, loss 0.1802288442850113, acc=0.9414544105529785, loss=0.1802288442850113
test: epoch 15, loss 2.8017494678497314, acc=0.3365991711616516, loss=2.8017494678497314
train: epoch 16, loss 0.16345354914665222, acc=0.9468713402748108, loss=0.16345354914665222
test: epoch 16, loss 3.1461362838745117, acc=0.30198127031326294, loss=3.1461362838745117
train: epoch 17, loss 0.15516643226146698, acc=0.9509819149971008, loss=0.15516643226146698
test: epoch 17, loss 3.23240327835083, acc=0.3178750276565552, loss=3.23240327835083
train: epoch 18, loss 0.14680099487304688, acc=0.9532288312911987, loss=0.14680099487304688
test: epoch 18, loss 3.24031138420105, acc=0.3067711591720581, loss=3.24031138420105
train: epoch 19, loss 0.13974618911743164, acc=0.9559416770935059, loss=0.13974618911743164
test: epoch 19, loss 2.8779091835021973, acc=0.3039407730102539, loss=2.8779091835021973
train: epoch 20, loss 0.1364399939775467, acc=0.9569867253303528, loss=0.1364399939775467
test: epoch 20, loss 2.921294689178467, acc=0.3187459111213684, loss=2.921294689178467
train: epoch 21, loss 0.12921017408370972, acc=0.9597387313842773, loss=0.12921017408370972
test: epoch 21, loss 3.2380173206329346, acc=0.33768779039382935, loss=3.2380173206329346
train: epoch 22, loss 0.12937390804290771, acc=0.9604093432426453, loss=0.12937390804290771
test: epoch 22, loss 2.9387097358703613, acc=0.3747006356716156, loss=2.9387097358703613
train: epoch 23, loss 0.12163452804088593, acc=0.9625952243804932, loss=0.12163452804088593
test: epoch 23, loss 2.861178398132324, acc=0.3718702495098114, loss=2.861178398132324
train: epoch 24, loss 0.11754477024078369, acc=0.9638144969940186, loss=0.11754477024078369
test: epoch 24, loss 2.6302590370178223, acc=0.3801437020301819, loss=2.6302590370178223
train: epoch 25, loss 0.11561919003725052, acc=0.964363157749176, loss=0.11561919003725052
test: epoch 25, loss 2.8520426750183105, acc=0.3712170720100403, loss=2.8520426750183105
train: epoch 26, loss 0.11207370460033417, acc=0.9659046530723572, loss=0.11207370460033417
test: epoch 26, loss 3.4401073455810547, acc=0.3688221275806427, loss=3.4401073455810547
train: epoch 27, loss 0.10965511947870255, acc=0.9665621519088745, loss=0.10965511947870255
test: epoch 27, loss 2.5808990001678467, acc=0.40300458669662476, loss=2.5808990001678467
train: epoch 28, loss 0.10751740634441376, acc=0.9675984978675842, loss=0.10751740634441376
test: epoch 28, loss 2.8253278732299805, acc=0.4075767397880554, loss=2.8253278732299805
train: epoch 29, loss 0.10658252239227295, acc=0.9687698483467102, loss=0.10658252239227295
test: epoch 29, loss 2.7892398834228516, acc=0.42303505539894104, loss=2.7892398834228516
train: epoch 30, loss 0.10193105041980743, acc=0.9694970846176147, loss=0.10193105041980743
test: epoch 30, loss 2.643425703048706, acc=0.43261486291885376, loss=2.643425703048706
train: epoch 31, loss 0.1005389392375946, acc=0.9703461527824402, loss=0.1005389392375946
test: epoch 31, loss 2.5594301223754883, acc=0.4724580943584442, loss=2.5594301223754883
train: epoch 32, loss 0.09824968129396439, acc=0.9707816243171692, loss=0.09824968129396439
test: epoch 32, loss 2.2742152214050293, acc=0.4432832598686218, loss=2.2742152214050293
train: epoch 33, loss 0.09725941717624664, acc=0.9716960787773132, loss=0.09725941717624664
test: epoch 33, loss 2.5057191848754883, acc=0.4800783693790436, loss=2.5057191848754883
train: epoch 34, loss 0.09160850942134857, acc=0.9733028411865234, loss=0.09160850942134857
test: epoch 34, loss 2.134107828140259, acc=0.48791638016700745, loss=2.134107828140259
train: epoch 35, loss 0.09363696724176407, acc=0.9726017713546753, loss=0.09363696724176407
test: epoch 35, loss 1.96666419506073, acc=0.5360330939292908, loss=1.96666419506073
train: epoch 36, loss 0.08761952072381973, acc=0.974583089351654, loss=0.08761952072381973
test: epoch 36, loss 1.9865361452102661, acc=0.5303723216056824, loss=1.9865361452102661
train: epoch 37, loss 0.08775198459625244, acc=0.9746745228767395, loss=0.08775198459625244
test: epoch 37, loss 1.9756463766098022, acc=0.5406052470207214, loss=1.9756463766098022
train: epoch 38, loss 0.08228135108947754, acc=0.9760200381278992, loss=0.08228135108947754
test: epoch 38, loss 1.8245844841003418, acc=0.5948181748390198, loss=1.8245844841003418
train: epoch 39, loss 0.08428880572319031, acc=0.9753799438476562, loss=0.08428880572319031
test: epoch 39, loss 1.8435431718826294, acc=0.5828434824943542, loss=1.8435431718826294
train: epoch 40, loss 0.08036774396896362, acc=0.9771521687507629, loss=0.08036774396896362
test: epoch 40, loss 1.5911660194396973, acc=0.6215980648994446, loss=1.5911660194396973
train: epoch 41, loss 0.0804908350110054, acc=0.9775092601776123, loss=0.0804908350110054
test: epoch 41, loss 1.5376116037368774, acc=0.6401045322418213, loss=1.5376116037368774
train: epoch 42, loss 0.07766669243574142, acc=0.9780927300453186, loss=0.07766669243574142
test: epoch 42, loss 1.6233830451965332, acc=0.6529501676559448, loss=1.6233830451965332
train: epoch 43, loss 0.07350143790245056, acc=0.9788112640380859, loss=0.07350143790245056
test: epoch 43, loss 1.3635313510894775, acc=0.68691486120224, loss=1.3635313510894775
train: epoch 44, loss 0.0746263712644577, acc=0.9793076515197754, loss=0.0746263712644577
test: epoch 44, loss 1.2300028800964355, acc=0.6967123746871948, loss=1.2300028800964355
train: epoch 45, loss 0.07402506470680237, acc=0.9799477458000183, loss=0.07402506470680237
test: epoch 45, loss 1.2108701467514038, acc=0.7106466293334961, loss=1.2108701467514038
train: epoch 46, loss 0.06752961874008179, acc=0.9814239144325256, loss=0.06752961874008179
test: epoch 46, loss 1.061062216758728, acc=0.7504898905754089, loss=1.061062216758728
train: epoch 47, loss 0.06913330405950546, acc=0.9814935922622681, loss=0.06913330405950546
test: epoch 47, loss 0.9415382146835327, acc=0.7774874567985535, loss=0.9415382146835327
train: epoch 48, loss 0.0662931576371193, acc=0.9825299382209778, loss=0.0662931576371193
test: epoch 48, loss 0.9005324840545654, acc=0.791204035282135, loss=0.9005324840545654
train: epoch 49, loss 0.061798058450222015, acc=0.9832876324653625, loss=0.061798058450222015
test: epoch 49, loss 0.7213488221168518, acc=0.8445460200309753, loss=0.7213488221168518
train: epoch 50, loss 0.06256526708602905, acc=0.9839668869972229, loss=0.06256526708602905
test: epoch 50, loss 0.7040227055549622, acc=0.8410624861717224, loss=0.7040227055549622
train: epoch 51, loss 0.05908610299229622, acc=0.9851905107498169, loss=0.05908610299229622
test: epoch 51, loss 0.48226407170295715, acc=0.8917918801307678, loss=0.48226407170295715
train: epoch 52, loss 0.0517917200922966, acc=0.9864228367805481, loss=0.0517917200922966
test: epoch 52, loss 0.4581679701805115, acc=0.8991944193840027, loss=0.4581679701805115
train: epoch 53, loss 0.05222490429878235, acc=0.986967146396637, loss=0.05222490429878235
test: epoch 53, loss 0.26818761229515076, acc=0.9394730925559998, loss=0.26818761229515076
train: epoch 54, loss 0.04723571613430977, acc=0.9887306690216064, loss=0.04723571613430977
test: epoch 54, loss 0.27913177013397217, acc=0.9346832036972046, loss=0.27913177013397217
train: epoch 55, loss 0.05014298856258392, acc=0.9887829422950745, loss=0.05014298856258392
test: epoch 55, loss 0.14176341891288757, acc=0.9714783430099487, loss=0.14176341891288757
train: epoch 56, loss 0.04297838732600212, acc=0.9904071688652039, loss=0.04297838732600212
test: epoch 56, loss 0.14344292879104614, acc=0.9608099460601807, loss=0.14344292879104614
train: epoch 57, loss 0.038178980350494385, acc=0.9916612505912781, loss=0.038178980350494385
test: epoch 57, loss 0.139667809009552, acc=0.9738732576370239, loss=0.139667809009552
train: epoch 58, loss 0.034921273589134216, acc=0.9925277829170227, loss=0.034921273589134216
test: epoch 58, loss 0.0705094039440155, acc=0.9878075122833252, loss=0.0705094039440155
train: epoch 59, loss 0.0342680960893631, acc=0.9929370880126953, loss=0.0342680960893631
test: epoch 59, loss 0.06281787157058716, acc=0.9917265176773071, loss=0.06281787157058716
