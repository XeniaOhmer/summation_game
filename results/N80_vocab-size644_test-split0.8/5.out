# ["--N=80", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=1", "--n_layers=3", "--save_run=1", "--test_split=0.8", "--n_symbols=644"]
Namespace(N=80, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=644, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1746324174, receiver_embed_dim=64, save_run=True, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.8, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 4.000148773193359, acc=0.030677836388349533, loss=4.000148773193359
test: epoch 1, loss 9.414840698242188, acc=0.028941355645656586, loss=9.414840698242188
train: epoch 2, loss 2.7100930213928223, acc=0.1496877372264862, loss=2.7100930213928223
test: epoch 2, loss 8.436348915100098, acc=0.05255140736699104, loss=8.436348915100098
train: epoch 3, loss 1.9061518907546997, acc=0.35861384868621826, loss=1.9061518907546997
test: epoch 3, loss 9.172249794006348, acc=0.061690784990787506, loss=9.172249794006348
train: epoch 4, loss 1.3768235445022583, acc=0.5203807950019836, loss=1.3768235445022583
test: epoch 4, loss 6.276787757873535, acc=0.0891089141368866, loss=6.276787757873535
train: epoch 5, loss 0.9774880409240723, acc=0.6649200320243835, loss=0.9774880409240723
test: epoch 5, loss 6.563378810882568, acc=0.13023610413074493, loss=6.563378810882568
train: epoch 6, loss 0.7316175103187561, acc=0.7528103590011597, loss=0.7316175103187561
test: epoch 6, loss 5.975280284881592, acc=0.20182786881923676, loss=5.975280284881592
train: epoch 7, loss 0.43917375802993774, acc=0.8575323820114136, loss=0.43917375802993774
test: epoch 7, loss 6.4690022468566895, acc=0.19649657607078552, loss=6.4690022468566895
train: epoch 8, loss 0.38212019205093384, acc=0.8776694536209106, loss=0.38212019205093384
test: epoch 8, loss 5.337889194488525, acc=0.2284843921661377, loss=5.337889194488525
train: epoch 9, loss 0.289192795753479, acc=0.914699137210846, loss=0.289192795753479
test: epoch 9, loss 5.284304618835449, acc=0.23914699256420135, loss=5.284304618835449
train: epoch 10, loss 0.24344085156917572, acc=0.9295201897621155, loss=0.24344085156917572
test: epoch 10, loss 5.535106658935547, acc=0.26808834075927734, loss=5.535106658935547
train: epoch 11, loss 0.21761630475521088, acc=0.938293993473053, loss=0.21761630475521088
test: epoch 11, loss 4.667980194091797, acc=0.2627570331096649, loss=4.667980194091797
train: epoch 12, loss 0.19746683537960052, acc=0.9447524547576904, loss=0.19746683537960052
test: epoch 12, loss 4.607627868652344, acc=0.30997714400291443, loss=4.607627868652344
train: epoch 13, loss 0.18153919279575348, acc=0.9488499760627747, loss=0.18153919279575348
test: epoch 13, loss 4.24916934967041, acc=0.2962680757045746, loss=4.24916934967041
train: epoch 14, loss 0.16866663098335266, acc=0.9524752497673035, loss=0.16866663098335266
test: epoch 14, loss 4.000673770904541, acc=0.29398325085639954, loss=4.000673770904541
train: epoch 15, loss 0.1558242291212082, acc=0.9554150700569153, loss=0.1558242291212082
test: epoch 15, loss 3.9363889694213867, acc=0.3160700798034668, loss=3.9363889694213867
train: epoch 16, loss 0.1512995958328247, acc=0.9583548903465271, loss=0.1512995958328247
test: epoch 16, loss 3.8030402660369873, acc=0.31835490465164185, loss=3.8030402660369873
train: epoch 17, loss 0.1406576931476593, acc=0.960868239402771, loss=0.1406576931476593
test: epoch 17, loss 3.4331140518188477, acc=0.3160700798034668, loss=3.4331140518188477
train: epoch 18, loss 0.13638459146022797, acc=0.9641126990318298, loss=0.13638459146022797
test: epoch 18, loss 3.34928035736084, acc=0.3648134171962738, loss=3.34928035736084
train: epoch 19, loss 0.12736599147319794, acc=0.9658339619636536, loss=0.12736599147319794
test: epoch 19, loss 3.3184800148010254, acc=0.3343488276004791, loss=3.3184800148010254
train: epoch 20, loss 0.1278112232685089, acc=0.9651789665222168, loss=0.1278112232685089
test: epoch 20, loss 3.40061092376709, acc=0.3465346395969391, loss=3.40061092376709
train: epoch 21, loss 0.1219923347234726, acc=0.9666107892990112, loss=0.1219923347234726
test: epoch 21, loss 3.0157251358032227, acc=0.40137091279029846, loss=3.0157251358032227
train: epoch 22, loss 0.11168809235095978, acc=0.9690936803817749, loss=0.11168809235095978
test: epoch 22, loss 3.114370346069336, acc=0.39756283164024353, loss=3.114370346069336
train: epoch 23, loss 0.10766816884279251, acc=0.9691089391708374, loss=0.10766816884279251
test: epoch 23, loss 2.778263568878174, acc=0.38994669914245605, loss=2.778263568878174
train: epoch 24, loss 0.1081123948097229, acc=0.9697486758232117, loss=0.1081123948097229
test: epoch 24, loss 3.1436820030212402, acc=0.3648134171962738, loss=3.1436820030212402
train: epoch 25, loss 0.10498616844415665, acc=0.9714242219924927, loss=0.10498616844415665
test: epoch 25, loss 2.5985052585601807, acc=0.453922301530838, loss=2.5985052585601807
train: epoch 26, loss 0.09764446318149567, acc=0.9726732969284058, loss=0.09764446318149567
test: epoch 26, loss 2.3521056175231934, acc=0.4280274212360382, loss=2.3521056175231934
train: epoch 27, loss 0.09742855280637741, acc=0.9734653234481812, loss=0.09742855280637741
test: epoch 27, loss 2.3234474658966064, acc=0.4310738742351532, loss=2.3234474658966064
train: epoch 28, loss 0.09324357658624649, acc=0.9740289449691772, loss=0.09324357658624649
test: epoch 28, loss 2.4901962280273438, acc=0.4615384638309479, loss=2.4901962280273438
train: epoch 29, loss 0.09513349086046219, acc=0.9744554162025452, loss=0.09513349086046219
test: epoch 29, loss 2.6555163860321045, acc=0.4211728870868683, loss=2.6555163860321045
train: epoch 30, loss 0.08731510490179062, acc=0.975674033164978, loss=0.08731510490179062
test: epoch 30, loss 2.185603141784668, acc=0.497334361076355, loss=2.185603141784668
train: epoch 31, loss 0.09101779758930206, acc=0.9747448563575745, loss=0.09101779758930206
test: epoch 31, loss 1.9437296390533447, acc=0.5605483651161194, loss=1.9437296390533447
train: epoch 32, loss 0.08126182854175568, acc=0.9780045747756958, loss=0.08126182854175568
test: epoch 32, loss 2.2620251178741455, acc=0.502665638923645, loss=2.2620251178741455
train: epoch 33, loss 0.08677785098552704, acc=0.9763899445533752, loss=0.08677785098552704
test: epoch 33, loss 2.0050010681152344, acc=0.5156130790710449, loss=2.0050010681152344
train: epoch 34, loss 0.087874636054039, acc=0.9769687652587891, loss=0.087874636054039
test: epoch 34, loss 2.018923282623291, acc=0.5498857498168945, loss=2.018923282623291
train: epoch 35, loss 0.08094041794538498, acc=0.9786595702171326, loss=0.08094041794538498
test: epoch 35, loss 1.557690978050232, acc=0.6351866126060486, loss=1.557690978050232
train: epoch 36, loss 0.08004915714263916, acc=0.9783244729042053, loss=0.08004915714263916
test: epoch 36, loss 2.0057971477508545, acc=0.5765422582626343, loss=2.0057971477508545
train: epoch 37, loss 0.0764143094420433, acc=0.9793602228164673, loss=0.0764143094420433
test: epoch 37, loss 1.5833165645599365, acc=0.6245239973068237, loss=1.5833165645599365
train: epoch 38, loss 0.07663043588399887, acc=0.9796192049980164, loss=0.07663043588399887
test: epoch 38, loss 1.5710479021072388, acc=0.6153846383094788, loss=1.5710479021072388
train: epoch 39, loss 0.07529934495687485, acc=0.9792841076850891, loss=0.07529934495687485
test: epoch 39, loss 1.4321964979171753, acc=0.6747905611991882, loss=1.4321964979171753
train: epoch 40, loss 0.07148749381303787, acc=0.9815080165863037, loss=0.07148749381303787
test: epoch 40, loss 1.6101040840148926, acc=0.6626047492027283, loss=1.6101040840148926
train: epoch 41, loss 0.06874444335699081, acc=0.9817060232162476, loss=0.06874444335699081
test: epoch 41, loss 1.2484110593795776, acc=0.7250571250915527, loss=1.2484110593795776
train: epoch 42, loss 0.07049555331468582, acc=0.981843113899231, loss=0.07049555331468582
test: epoch 42, loss 1.2121185064315796, acc=0.709824800491333, loss=1.2121185064315796
train: epoch 43, loss 0.0607762411236763, acc=0.9839299321174622, loss=0.0607762411236763
test: epoch 43, loss 0.904606282711029, acc=0.808073103427887, loss=0.904606282711029
train: epoch 44, loss 0.06674551963806152, acc=0.983137845993042, loss=0.06674551963806152
test: epoch 44, loss 0.882142961025238, acc=0.7715156078338623, loss=0.882142961025238
train: epoch 45, loss 0.055724117904901505, acc=0.9853922128677368, loss=0.055724117904901505
test: epoch 45, loss 0.7809708118438721, acc=0.8149276375770569, loss=0.7809708118438721
train: epoch 46, loss 0.0574738085269928, acc=0.9853008389472961, loss=0.0574738085269928
test: epoch 46, loss 0.529752790927887, acc=0.8895658850669861, loss=0.529752790927887
train: epoch 47, loss 0.05572405084967613, acc=0.9859101176261902, loss=0.05572405084967613
test: epoch 47, loss 0.7034461498260498, acc=0.8598629236221313, loss=0.7034461498260498
train: epoch 48, loss 0.050049591809511185, acc=0.9876313805580139, loss=0.050049591809511185
test: epoch 48, loss 0.31733423471450806, acc=0.9207921028137207, loss=0.31733423471450806
train: epoch 49, loss 0.04920274391770363, acc=0.9885757565498352, loss=0.04920274391770363
test: epoch 49, loss 0.3759661912918091, acc=0.9040365815162659, loss=0.3759661912918091
train: epoch 50, loss 0.039029937237501144, acc=0.9909824728965759, loss=0.039029937237501144
test: epoch 50, loss 0.24478305876255035, acc=0.9337395429611206, loss=0.24478305876255035
train: epoch 51, loss 0.03795977309346199, acc=0.9910281896591187, loss=0.03795977309346199
test: epoch 51, loss 0.21047772467136383, acc=0.9482101798057556, loss=0.21047772467136383
train: epoch 52, loss 0.03463629633188248, acc=0.9921553730964661, loss=0.03463629633188248
test: epoch 52, loss 0.14475810527801514, acc=0.9733434915542603, loss=0.14475810527801514
train: epoch 53, loss 0.03131552413105965, acc=0.9935262799263, loss=0.03131552413105965
test: epoch 53, loss 0.09963345527648926, acc=0.9710586667060852, loss=0.09963345527648926
train: epoch 54, loss 0.027076616883277893, acc=0.9941660165786743, loss=0.027076616883277893
test: epoch 54, loss 0.05363073945045471, acc=0.9923838376998901, loss=0.05363073945045471
