# ["--N=20", "--n_epochs=250", "--batch_size=32", "--lr=0.001", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=1", "--n_layers=3", "--save_run=1", "--n_symbols=328"]
Namespace(n_summands=2, N=20, test_split=0.1, data_scaling=50, one_hot=True, receiver_embed_dim=64, n_layers=3, n_symbols=328, temperature=2.0, temp_decay=0.995, early_stopping_acc=0.99, n_runs=1, save_run=True, random_seed=485159176, checkpoint_dir=None, preemptable=False, checkpoint_freq=0, validation_freq=1, n_epochs=250, load_from_checkpoint=None, no_cuda=True, batch_size=32, optimizer='adam', lr=0.001, update_freq=1, vocab_size=10, max_len=1, tensorboard=False, tensorboard_dir='runs/', distributed_port=18363, fp16=False, cuda=False, device=device(type='cpu'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'))
train: epoch 1, loss 2.818345308303833, acc=0.09581863880157471, loss=2.818345308303833
test: epoch 1, loss 6.3829803466796875, acc=0.08564231544733047, loss=6.3829803466796875
train: epoch 2, loss 1.7892757654190063, acc=0.250327467918396, loss=1.7892757654190063
test: epoch 2, loss 5.481062412261963, acc=0.13602015376091003, loss=5.481062412261963
train: epoch 3, loss 1.4029771089553833, acc=0.3807556629180908, loss=1.4029771089553833
test: epoch 3, loss 6.094245433807373, acc=0.14105793833732605, loss=6.094245433807373
train: epoch 4, loss 0.9592297077178955, acc=0.6021158695220947, loss=0.9592297077178955
test: epoch 4, loss 4.562741279602051, acc=0.16120906174182892, loss=4.562741279602051
train: epoch 5, loss 0.7141014933586121, acc=0.7226196527481079, loss=0.7141014933586121
test: epoch 5, loss 3.516434669494629, acc=0.23425692319869995, loss=3.516434669494629
train: epoch 6, loss 0.5378805994987488, acc=0.7992443442344666, loss=0.5378805994987488
test: epoch 6, loss 4.132174015045166, acc=0.188916876912117, loss=4.132174015045166
train: epoch 7, loss 0.45335090160369873, acc=0.8354659676551819, loss=0.45335090160369873
test: epoch 7, loss 3.854221820831299, acc=0.33249369263648987, loss=3.854221820831299
train: epoch 8, loss 0.36052465438842773, acc=0.876070499420166, loss=0.36052465438842773
test: epoch 8, loss 3.198378324508667, acc=0.38287153840065, loss=3.198378324508667
train: epoch 9, loss 0.32796406745910645, acc=0.8909823894500732, loss=0.32796406745910645
test: epoch 9, loss 4.482335090637207, acc=0.30226701498031616, loss=4.482335090637207
train: epoch 10, loss 0.26449522376060486, acc=0.9131990075111389, loss=0.26449522376060486
test: epoch 10, loss 3.3176865577697754, acc=0.38287153840065, loss=3.3176865577697754
train: epoch 11, loss 0.251392126083374, acc=0.9190931916236877, loss=0.251392126083374
test: epoch 11, loss 4.1013007164001465, acc=0.2795969843864441, loss=4.1013007164001465
train: epoch 12, loss 0.24400386214256287, acc=0.9221158623695374, loss=0.24400386214256287
test: epoch 12, loss 4.60940408706665, acc=0.29974812269210815, loss=4.60940408706665
train: epoch 13, loss 0.21187327802181244, acc=0.9343577027320862, loss=0.21187327802181244
test: epoch 13, loss 3.3428151607513428, acc=0.35516372323036194, loss=3.3428151607513428
train: epoch 14, loss 0.1932438462972641, acc=0.9385893940925598, loss=0.1932438462972641
test: epoch 14, loss 3.8890490531921387, acc=0.2896725535392761, loss=3.8890490531921387
train: epoch 15, loss 0.185667023062706, acc=0.9445843696594238, loss=0.185667023062706
test: epoch 15, loss 3.401916980743408, acc=0.3173803389072418, loss=3.401916980743408
train: epoch 16, loss 0.17796380817890167, acc=0.9448866248130798, loss=0.17796380817890167
test: epoch 16, loss 3.149151563644409, acc=0.4005037844181061, loss=3.149151563644409
train: epoch 17, loss 0.17727163434028625, acc=0.9452393054962158, loss=0.17727163434028625
test: epoch 17, loss 2.983363628387451, acc=0.38790932297706604, loss=2.983363628387451
train: epoch 18, loss 0.15316013991832733, acc=0.9527456164360046, loss=0.15316013991832733
test: epoch 18, loss 2.7146127223968506, acc=0.35264483094215393, loss=2.7146127223968506
train: epoch 19, loss 0.1345394253730774, acc=0.9604533910751343, loss=0.1345394253730774
test: epoch 19, loss 3.6583683490753174, acc=0.3073047995567322, loss=3.6583683490753174
train: epoch 20, loss 0.15344616770744324, acc=0.9543073177337646, loss=0.15344616770744324
test: epoch 20, loss 2.4604883193969727, acc=0.45591938495635986, loss=2.4604883193969727
train: epoch 21, loss 0.13963618874549866, acc=0.9569269418716431, loss=0.13963618874549866
test: epoch 21, loss 3.3272037506103516, acc=0.36523929238319397, loss=3.3272037506103516
train: epoch 22, loss 0.128570094704628, acc=0.9619143605232239, loss=0.128570094704628
test: epoch 22, loss 2.179056167602539, acc=0.39798489212989807, loss=2.179056167602539
train: epoch 23, loss 0.11781772971153259, acc=0.9640806317329407, loss=0.11781772971153259
test: epoch 23, loss 3.312272071838379, acc=0.38287153840065, loss=3.312272071838379
train: epoch 24, loss 0.12337925285100937, acc=0.9651385545730591, loss=0.12337925285100937
test: epoch 24, loss 2.654668092727661, acc=0.4005037844181061, loss=2.654668092727661
train: epoch 25, loss 0.12173325568437576, acc=0.9637279510498047, loss=0.12173325568437576
test: epoch 25, loss 2.7714762687683105, acc=0.45340049266815186, loss=2.7714762687683105
train: epoch 26, loss 0.11667457222938538, acc=0.9659949541091919, loss=0.11667457222938538
test: epoch 26, loss 2.693918466567993, acc=0.42821159958839417, loss=2.693918466567993
train: epoch 27, loss 0.09543350338935852, acc=0.9725440740585327, loss=0.09543350338935852
test: epoch 27, loss 2.7472548484802246, acc=0.4156171381473541, loss=2.7472548484802246
train: epoch 28, loss 0.11294207721948624, acc=0.9679597020149231, loss=0.11294207721948624
test: epoch 28, loss 2.5975024700164795, acc=0.4105793535709381, loss=2.5975024700164795
train: epoch 29, loss 0.10335253179073334, acc=0.9703274369239807, loss=0.10335253179073334
test: epoch 29, loss 2.525460958480835, acc=0.3173803389072418, loss=2.525460958480835
train: epoch 30, loss 0.0921325609087944, acc=0.9728967547416687, loss=0.0921325609087944
test: epoch 30, loss 2.1618592739105225, acc=0.4382871389389038, loss=2.1618592739105225
train: epoch 31, loss 0.11050871759653091, acc=0.9669521450996399, loss=0.11050871759653091
test: epoch 31, loss 1.9637694358825684, acc=0.48110830783843994, loss=1.9637694358825684
train: epoch 32, loss 0.09371597319841385, acc=0.9729974865913391, loss=0.09371597319841385
test: epoch 32, loss 1.9437615871429443, acc=0.48866498470306396, loss=1.9437615871429443
train: epoch 33, loss 0.08788584917783737, acc=0.9755667448043823, loss=0.08788584917783737
test: epoch 33, loss 1.6701552867889404, acc=0.501259446144104, loss=1.6701552867889404
train: epoch 34, loss 0.09263063222169876, acc=0.9702267050743103, loss=0.09263063222169876
test: epoch 34, loss 2.4177491664886475, acc=0.4408060312271118, loss=2.4177491664886475
train: epoch 35, loss 0.09140759706497192, acc=0.9734508991241455, loss=0.09140759706497192
test: epoch 35, loss 1.6463745832443237, acc=0.511335015296936, loss=1.6463745832443237
train: epoch 36, loss 0.09349264204502106, acc=0.9713854193687439, loss=0.09349264204502106
test: epoch 36, loss 1.9480595588684082, acc=0.4382871389389038, loss=1.9480595588684082
train: epoch 37, loss 0.0844937264919281, acc=0.9760201573371887, loss=0.0844937264919281
test: epoch 37, loss 1.747098445892334, acc=0.5717884302139282, loss=1.747098445892334
train: epoch 38, loss 0.08689108490943909, acc=0.9744080901145935, loss=0.08689108490943909
test: epoch 38, loss 1.6005460023880005, acc=0.5390428304672241, loss=1.6005460023880005
train: epoch 39, loss 0.07645943015813828, acc=0.9785894155502319, loss=0.07645943015813828
test: epoch 39, loss 1.7826734781265259, acc=0.503778338432312, loss=1.7826734781265259
train: epoch 40, loss 0.06346618384122849, acc=0.9811083078384399, loss=0.06346618384122849
test: epoch 40, loss 1.7880438566207886, acc=0.501259446144104, loss=1.7880438566207886
train: epoch 41, loss 0.07360859215259552, acc=0.9779849052429199, loss=0.07360859215259552
test: epoch 41, loss 1.8047771453857422, acc=0.496221661567688, loss=1.8047771453857422
train: epoch 42, loss 0.07413054257631302, acc=0.9768765568733215, loss=0.07413054257631302
test: epoch 42, loss 1.661784052848816, acc=0.511335015296936, loss=1.661784052848816
train: epoch 43, loss 0.07412012666463852, acc=0.9768261909484863, loss=0.07412012666463852
test: epoch 43, loss 2.055889129638672, acc=0.4130982458591461, loss=2.055889129638672
train: epoch 44, loss 0.07632587105035782, acc=0.9781863689422607, loss=0.07632587105035782
test: epoch 44, loss 1.8670005798339844, acc=0.4609571695327759, loss=1.8670005798339844
train: epoch 45, loss 0.06972108781337738, acc=0.9797984957695007, loss=0.06972108781337738
test: epoch 45, loss 1.4231165647506714, acc=0.5264483690261841, loss=1.4231165647506714
train: epoch 46, loss 0.07025738805532455, acc=0.9803022742271423, loss=0.07025738805532455
test: epoch 46, loss 1.5208781957626343, acc=0.6498740315437317, loss=1.5208781957626343
train: epoch 47, loss 0.05999316647648811, acc=0.982367753982544, loss=0.05999316647648811
test: epoch 47, loss 1.6982589960098267, acc=0.5743073225021362, loss=1.6982589960098267
train: epoch 48, loss 0.07646599411964417, acc=0.9777330160140991, loss=0.07646599411964417
test: epoch 48, loss 1.8637131452560425, acc=0.5365239381790161, loss=1.8637131452560425
train: epoch 49, loss 0.058767929673194885, acc=0.9834760427474976, loss=0.058767929673194885
test: epoch 49, loss 1.1762181520462036, acc=0.5642317533493042, loss=1.1762181520462036
train: epoch 50, loss 0.06667129695415497, acc=0.9802519083023071, loss=0.06667129695415497
test: epoch 50, loss 1.4313708543777466, acc=0.6372795701026917, loss=1.4313708543777466
train: epoch 51, loss 0.059979699552059174, acc=0.9828211665153503, loss=0.059979699552059174
test: epoch 51, loss 1.32962167263031, acc=0.6826196312904358, loss=1.32962167263031
train: epoch 52, loss 0.05086635425686836, acc=0.9844835996627808, loss=0.05086635425686836
test: epoch 52, loss 1.0317635536193848, acc=0.6523929238319397, loss=1.0317635536193848
train: epoch 53, loss 0.05438787862658501, acc=0.98423171043396, loss=0.05438787862658501
test: epoch 53, loss 1.0741493701934814, acc=0.7279596924781799, loss=1.0741493701934814
train: epoch 54, loss 0.06332368403673172, acc=0.9821158647537231, loss=0.06332368403673172
test: epoch 54, loss 1.3073251247406006, acc=0.735516369342804, loss=1.3073251247406006
train: epoch 55, loss 0.0540287122130394, acc=0.9839798212051392, loss=0.0540287122130394
test: epoch 55, loss 0.790274977684021, acc=0.7682619690895081, loss=0.790274977684021
train: epoch 56, loss 0.05958861857652664, acc=0.9829218983650208, loss=0.05958861857652664
test: epoch 56, loss 0.8108791708946228, acc=0.7984886765480042, loss=0.8108791708946228
train: epoch 57, loss 0.05260726064443588, acc=0.9851385354995728, loss=0.05260726064443588
test: epoch 57, loss 0.8231849074363708, acc=0.755667507648468, loss=0.8231849074363708
train: epoch 58, loss 0.04882771894335747, acc=0.986448347568512, loss=0.04882771894335747
test: epoch 58, loss 0.8876945376396179, acc=0.7783375382423401, loss=0.8876945376396179
train: epoch 59, loss 0.05437196046113968, acc=0.9848362803459167, loss=0.05437196046113968
test: epoch 59, loss 0.8651899695396423, acc=0.7959697842597961, loss=0.8651899695396423
train: epoch 60, loss 0.04935572296380997, acc=0.9860453605651855, loss=0.04935572296380997
test: epoch 60, loss 1.0477169752120972, acc=0.750629723072052, loss=1.0477169752120972
train: epoch 61, loss 0.04493243247270584, acc=0.9873551726341248, loss=0.04493243247270584
test: epoch 61, loss 0.4539627432823181, acc=0.8690176606178284, loss=0.4539627432823181
train: epoch 62, loss 0.053011875599622726, acc=0.9844332337379456, loss=0.053011875599622726
test: epoch 62, loss 0.5711813569068909, acc=0.8287153840065002, loss=0.5711813569068909
train: epoch 63, loss 0.045263126492500305, acc=0.9871536493301392, loss=0.045263126492500305
test: epoch 63, loss 0.6750063300132751, acc=0.8287153840065002, loss=0.6750063300132751
train: epoch 64, loss 0.053252000361680984, acc=0.9847859144210815, loss=0.053252000361680984
test: epoch 64, loss 0.584633469581604, acc=0.8136020302772522, loss=0.584633469581604
train: epoch 65, loss 0.03558187931776047, acc=0.9904785752296448, loss=0.03558187931776047
test: epoch 65, loss 0.3170796036720276, acc=0.8992443084716797, loss=0.3170796036720276
train: epoch 66, loss 0.03808881342411041, acc=0.98896723985672, loss=0.03808881342411041
test: epoch 66, loss 0.24749787151813507, acc=0.8916876316070557, loss=0.24749787151813507
train: epoch 67, loss 0.04100315645337105, acc=0.989622175693512, loss=0.04100315645337105
test: epoch 67, loss 0.25056010484695435, acc=0.9345088005065918, loss=0.25056010484695435
train: epoch 68, loss 0.04759499803185463, acc=0.9877581596374512, loss=0.04759499803185463
test: epoch 68, loss 0.3447820544242859, acc=0.9345088005065918, loss=0.3447820544242859
train: epoch 69, loss 0.04052045941352844, acc=0.9890176057815552, loss=0.04052045941352844
test: epoch 69, loss 0.32144248485565186, acc=0.9269521236419678, loss=0.32144248485565186
train: epoch 70, loss 0.033901844173669815, acc=0.990226686000824, loss=0.033901844173669815
test: epoch 70, loss 0.16649430990219116, acc=0.9496221542358398, loss=0.16649430990219116
train: epoch 71, loss 0.03188219666481018, acc=0.9920907020568848, loss=0.03188219666481018
test: epoch 71, loss 0.12672550976276398, acc=0.9722921848297119, loss=0.12672550976276398
train: epoch 72, loss 0.03353797644376755, acc=0.9906297326087952, loss=0.03353797644376755
test: epoch 72, loss 0.07688071578741074, acc=0.9798488616943359, loss=0.07688071578741074
train: epoch 73, loss 0.025561554357409477, acc=0.9932493567466736, loss=0.025561554357409477
test: epoch 73, loss 0.16949255764484406, acc=0.9496221542358398, loss=0.16949255764484406
train: epoch 74, loss 0.026251161471009254, acc=0.9928463697433472, loss=0.026251161471009254
test: epoch 74, loss 0.0647180899977684, acc=0.984886646270752, loss=0.0647180899977684
train: epoch 75, loss 0.02943713776767254, acc=0.9931486248970032, loss=0.02943713776767254
test: epoch 75, loss 0.1405068337917328, acc=0.9697732925415039, loss=0.1405068337917328
train: epoch 76, loss 0.01981806755065918, acc=0.9954156279563904, loss=0.01981806755065918
test: epoch 76, loss 0.11893752217292786, acc=0.982367753982544, loss=0.11893752217292786
train: epoch 77, loss 0.02911655604839325, acc=0.993400514125824, loss=0.02911655604839325
test: epoch 77, loss 0.0403648316860199, acc=0.992443323135376, loss=0.0403648316860199
