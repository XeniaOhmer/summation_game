# ["--N=20", "--n_epochs=250", "--batch_size=32", "--lr=0.001", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=1", "--n_layers=3", "--save_run=1", "--n_symbols=41"]
Namespace(n_summands=2, N=20, test_split=0.1, data_scaling=50, one_hot=True, receiver_embed_dim=64, n_layers=3, n_symbols=41, temperature=2.0, temp_decay=0.995, early_stopping_acc=0.99, n_runs=1, save_run=True, random_seed=207805375, checkpoint_dir=None, preemptable=False, checkpoint_freq=0, validation_freq=1, n_epochs=250, load_from_checkpoint=None, no_cuda=True, batch_size=32, optimizer='adam', lr=0.001, update_freq=1, vocab_size=10, max_len=1, tensorboard=False, tensorboard_dir='runs/', distributed_port=18363, fp16=False, cuda=False, device=device(type='cpu'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'))
train: epoch 1, loss 2.832152843475342, acc=0.10221662372350693, loss=2.832152843475342
test: epoch 1, loss 3.819279909133911, acc=0.08564231544733047, loss=3.819279909133911
train: epoch 2, loss 1.6259208917617798, acc=0.35350126028060913, loss=1.6259208917617798
test: epoch 2, loss 3.5514705181121826, acc=0.1536523997783661, loss=3.5514705181121826
train: epoch 3, loss 1.1845322847366333, acc=0.4994458556175232, loss=1.1845322847366333
test: epoch 3, loss 3.895432472229004, acc=0.16624684631824493, loss=3.895432472229004
train: epoch 4, loss 0.9028550386428833, acc=0.6172292232513428, loss=0.9028550386428833
test: epoch 4, loss 3.0075948238372803, acc=0.21158690750598907, loss=3.0075948238372803
train: epoch 5, loss 0.7212446928024292, acc=0.7112342715263367, loss=0.7212446928024292
test: epoch 5, loss 3.0283150672912598, acc=0.254408061504364, loss=3.0283150672912598
train: epoch 6, loss 0.6127399206161499, acc=0.7545592188835144, loss=0.6127399206161499
test: epoch 6, loss 2.7797434329986572, acc=0.23425692319869995, loss=2.7797434329986572
train: epoch 7, loss 0.550835371017456, acc=0.7761712670326233, loss=0.550835371017456
test: epoch 7, loss 2.7235054969787598, acc=0.2795969843864441, loss=2.7235054969787598
train: epoch 8, loss 0.4879949986934662, acc=0.803778350353241, loss=0.4879949986934662
test: epoch 8, loss 2.7048521041870117, acc=0.256926953792572, loss=2.7048521041870117
train: epoch 9, loss 0.4305993318557739, acc=0.8275063037872314, loss=0.4305993318557739
test: epoch 9, loss 2.4349968433380127, acc=0.2770780920982361, loss=2.4349968433380127
train: epoch 10, loss 0.42499619722366333, acc=0.8290176391601562, loss=0.42499619722366333
test: epoch 10, loss 2.9625813961029053, acc=0.251889169216156, loss=2.9625813961029053
train: epoch 11, loss 0.3916584551334381, acc=0.8427203893661499, loss=0.3916584551334381
test: epoch 11, loss 2.176278591156006, acc=0.3375314772129059, loss=2.176278591156006
train: epoch 12, loss 0.35485169291496277, acc=0.856574296951294, loss=0.35485169291496277
test: epoch 12, loss 2.3685715198516846, acc=0.26700252294540405, loss=2.3685715198516846
train: epoch 13, loss 0.3344617486000061, acc=0.864483654499054, loss=0.3344617486000061
test: epoch 13, loss 2.4416189193725586, acc=0.249370276927948, loss=2.4416189193725586
train: epoch 14, loss 0.3408150374889374, acc=0.8640806078910828, loss=0.3408150374889374
test: epoch 14, loss 2.5813658237457275, acc=0.3073047995567322, loss=2.5813658237457275
train: epoch 15, loss 0.32413458824157715, acc=0.8692191243171692, loss=0.32413458824157715
test: epoch 15, loss 2.467155933380127, acc=0.32997480034828186, loss=2.467155933380127
train: epoch 16, loss 0.2864002585411072, acc=0.8881611824035645, loss=0.2864002585411072
test: epoch 16, loss 2.107642889022827, acc=0.3501259386539459, loss=2.107642889022827
train: epoch 17, loss 0.2977191209793091, acc=0.8806045055389404, loss=0.2977191209793091
test: epoch 17, loss 2.5096192359924316, acc=0.4005037844181061, loss=2.5096192359924316
train: epoch 18, loss 0.256558358669281, acc=0.8997985124588013, loss=0.256558358669281
test: epoch 18, loss 2.6093645095825195, acc=0.3400503695011139, loss=2.6093645095825195
train: epoch 19, loss 0.2783891260623932, acc=0.8980352878570557, loss=0.2783891260623932
test: epoch 19, loss 2.036219596862793, acc=0.367758184671402, loss=2.036219596862793
train: epoch 20, loss 0.2543051838874817, acc=0.9070025086402893, loss=0.2543051838874817
test: epoch 20, loss 2.4453673362731934, acc=0.3400503695011139, loss=2.4453673362731934
train: epoch 21, loss 0.23738093674182892, acc=0.9161713123321533, loss=0.23738093674182892
test: epoch 21, loss 2.2063205242156982, acc=0.375314861536026, loss=2.2063205242156982
train: epoch 22, loss 0.21910803020000458, acc=0.925743043422699, loss=0.21910803020000458
test: epoch 22, loss 1.9113014936447144, acc=0.4156171381473541, loss=1.9113014936447144
train: epoch 23, loss 0.19631697237491608, acc=0.932090699672699, loss=0.19631697237491608
test: epoch 23, loss 2.3519999980926514, acc=0.38539043068885803, loss=2.3519999980926514
train: epoch 24, loss 0.20534323155879974, acc=0.9288665056228638, loss=0.20534323155879974
test: epoch 24, loss 2.0908937454223633, acc=0.39294710755348206, loss=2.0908937454223633
train: epoch 25, loss 0.1912500113248825, acc=0.934609591960907, loss=0.1912500113248825
test: epoch 25, loss 2.3641209602355957, acc=0.4005037844181061, loss=2.3641209602355957
train: epoch 26, loss 0.17766010761260986, acc=0.9418639540672302, loss=0.17766010761260986
test: epoch 26, loss 2.053602695465088, acc=0.42317381501197815, loss=2.053602695465088
train: epoch 27, loss 0.1658163219690323, acc=0.9432745575904846, loss=0.1658163219690323
test: epoch 27, loss 2.3570823669433594, acc=0.36020150780677795, loss=2.3570823669433594
train: epoch 28, loss 0.1979740709066391, acc=0.9339042901992798, loss=0.1979740709066391
test: epoch 28, loss 2.5753750801086426, acc=0.4005037844181061, loss=2.5753750801086426
train: epoch 29, loss 0.17126016318798065, acc=0.942115843296051, loss=0.17126016318798065
test: epoch 29, loss 2.4972493648529053, acc=0.3501259386539459, loss=2.4972493648529053
train: epoch 30, loss 0.15967126190662384, acc=0.9489168524742126, loss=0.15967126190662384
test: epoch 30, loss 2.492584228515625, acc=0.39798489212989807, loss=2.492584228515625
train: epoch 31, loss 0.15670306980609894, acc=0.9492695331573486, loss=0.15670306980609894
test: epoch 31, loss 2.9743499755859375, acc=0.3425692617893219, loss=2.9743499755859375
train: epoch 32, loss 0.1488661766052246, acc=0.9522922039031982, loss=0.1488661766052246
test: epoch 32, loss 2.7677552700042725, acc=0.4408060312271118, loss=2.7677552700042725
train: epoch 33, loss 0.15364296734333038, acc=0.9490176439285278, loss=0.15364296734333038
test: epoch 33, loss 1.9272375106811523, acc=0.4030226767063141, loss=1.9272375106811523
train: epoch 34, loss 0.1428513377904892, acc=0.9536020159721375, loss=0.1428513377904892
test: epoch 34, loss 2.793978214263916, acc=0.45591938495635986, loss=2.793978214263916
train: epoch 35, loss 0.1467583179473877, acc=0.9532997608184814, loss=0.1467583179473877
test: epoch 35, loss 2.2501399517059326, acc=0.42317381501197815, loss=2.2501399517059326
train: epoch 36, loss 0.1314006745815277, acc=0.9568765759468079, loss=0.1314006745815277
test: epoch 36, loss 2.306415319442749, acc=0.4307304918766022, loss=2.306415319442749
train: epoch 37, loss 0.14650830626487732, acc=0.9524937272071838, loss=0.14650830626487732
test: epoch 37, loss 2.520202875137329, acc=0.4433249235153198, loss=2.520202875137329
train: epoch 38, loss 0.14406487345695496, acc=0.9530478715896606, loss=0.14406487345695496
test: epoch 38, loss 2.3803300857543945, acc=0.4130982458591461, loss=2.3803300857543945
train: epoch 39, loss 0.12326036393642426, acc=0.9600504040718079, loss=0.12326036393642426
test: epoch 39, loss 2.2582733631134033, acc=0.39294710755348206, loss=2.2582733631134033
train: epoch 40, loss 0.12615832686424255, acc=0.9610579609870911, loss=0.12615832686424255
test: epoch 40, loss 2.2837607860565186, acc=0.4382871389389038, loss=2.2837607860565186
train: epoch 41, loss 0.13185951113700867, acc=0.9582367539405823, loss=0.13185951113700867
test: epoch 41, loss 1.9678705930709839, acc=0.42569270730018616, loss=1.9678705930709839
train: epoch 42, loss 0.12562303245067596, acc=0.9602518677711487, loss=0.12562303245067596
test: epoch 42, loss 2.351519823074341, acc=0.45843827724456787, loss=2.351519823074341
train: epoch 43, loss 0.11846581101417542, acc=0.9619143605232239, loss=0.11846581101417542
test: epoch 43, loss 2.368924617767334, acc=0.41813603043556213, loss=2.368924617767334
train: epoch 44, loss 0.11902408301830292, acc=0.9602015018463135, loss=0.11902408301830292
test: epoch 44, loss 2.516221523284912, acc=0.4685138463973999, loss=2.516221523284912
train: epoch 45, loss 0.116753950715065, acc=0.9622669816017151, loss=0.116753950715065
test: epoch 45, loss 2.2755892276763916, acc=0.4634760618209839, loss=2.2755892276763916
train: epoch 46, loss 0.10542899370193481, acc=0.9667002558708191, loss=0.10542899370193481
test: epoch 46, loss 2.5216734409332275, acc=0.48866498470306396, loss=2.5216734409332275
train: epoch 47, loss 0.11328825354576111, acc=0.9638287425041199, loss=0.11328825354576111
test: epoch 47, loss 3.075061321258545, acc=0.4055415689945221, loss=3.075061321258545
train: epoch 48, loss 0.10879509150981903, acc=0.9642820954322815, loss=0.10879509150981903
test: epoch 48, loss 3.1003520488739014, acc=0.380352646112442, loss=3.1003520488739014
train: epoch 49, loss 0.11513549834489822, acc=0.9617128372192383, loss=0.11513549834489822
test: epoch 49, loss 2.5201168060302734, acc=0.496221661567688, loss=2.5201168060302734
train: epoch 50, loss 0.10757700353860855, acc=0.9644836187362671, loss=0.10757700353860855
test: epoch 50, loss 2.472994089126587, acc=0.498740553855896, loss=2.472994089126587
train: epoch 51, loss 0.11521250754594803, acc=0.9642820954322815, loss=0.11521250754594803
test: epoch 51, loss 1.9131757020950317, acc=0.48614609241485596, loss=1.9131757020950317
train: epoch 52, loss 0.10842233151197433, acc=0.9655415415763855, loss=0.10842233151197433
test: epoch 52, loss 2.4749231338500977, acc=0.44836270809173584, loss=2.4749231338500977
train: epoch 53, loss 0.11054091155529022, acc=0.9642317295074463, loss=0.11054091155529022
test: epoch 53, loss 1.8677772283554077, acc=0.50629723072052, loss=1.8677772283554077
train: epoch 54, loss 0.10306888073682785, acc=0.9665995240211487, loss=0.10306888073682785
test: epoch 54, loss 2.163339376449585, acc=0.4710327386856079, loss=2.163339376449585
train: epoch 55, loss 0.09287800639867783, acc=0.9698740839958191, loss=0.09287800639867783
test: epoch 55, loss 2.718545436859131, acc=0.5239294767379761, loss=2.718545436859131
train: epoch 56, loss 0.11475279927253723, acc=0.9645339846611023, loss=0.11475279927253723
test: epoch 56, loss 1.9782891273498535, acc=0.5314861536026001, loss=1.9782891273498535
train: epoch 57, loss 0.1080477312207222, acc=0.9649873971939087, loss=0.1080477312207222
test: epoch 57, loss 2.0974652767181396, acc=0.5214105844497681, loss=2.0974652767181396
train: epoch 58, loss 0.10585090517997742, acc=0.9660453200340271, loss=0.10585090517997742
test: epoch 58, loss 2.072892189025879, acc=0.5591939687728882, loss=2.072892189025879
train: epoch 59, loss 0.10242152214050293, acc=0.9669521450996399, loss=0.10242152214050293
test: epoch 59, loss 1.8915505409240723, acc=0.508816123008728, loss=1.8915505409240723
train: epoch 60, loss 0.10131882131099701, acc=0.9673551917076111, loss=0.10131882131099701
test: epoch 60, loss 2.376162528991699, acc=0.48614609241485596, loss=2.376162528991699
train: epoch 61, loss 0.10804146528244019, acc=0.9635264277458191, loss=0.10804146528244019
test: epoch 61, loss 1.6482815742492676, acc=0.5340050458908081, loss=1.6482815742492676
train: epoch 62, loss 0.10147427022457123, acc=0.9694206714630127, loss=0.10147427022457123
test: epoch 62, loss 1.6809626817703247, acc=0.5314861536026001, loss=1.6809626817703247
train: epoch 63, loss 0.09805534034967422, acc=0.9689672589302063, loss=0.09805534034967422
test: epoch 63, loss 1.5965628623962402, acc=0.5843828916549683, loss=1.5965628623962402
train: epoch 64, loss 0.10336513817310333, acc=0.9664987325668335, loss=0.10336513817310333
test: epoch 64, loss 1.95835542678833, acc=0.5491183996200562, loss=1.95835542678833
train: epoch 65, loss 0.10428968071937561, acc=0.9677078127861023, loss=0.10428968071937561
test: epoch 65, loss 2.070183038711548, acc=0.5188916921615601, loss=2.070183038711548
train: epoch 66, loss 0.0985960140824318, acc=0.9681108593940735, loss=0.0985960140824318
test: epoch 66, loss 1.8507498502731323, acc=0.508816123008728, loss=1.8507498502731323
train: epoch 67, loss 0.10845186561346054, acc=0.9656926989555359, loss=0.10845186561346054
test: epoch 67, loss 1.7673944234848022, acc=0.5314861536026001, loss=1.7673944234848022
train: epoch 68, loss 0.10723121464252472, acc=0.9660957455635071, loss=0.10723121464252472
test: epoch 68, loss 1.6604164838790894, acc=0.5491183996200562, loss=1.6604164838790894
train: epoch 69, loss 0.1010713279247284, acc=0.9678085446357727, loss=0.1010713279247284
test: epoch 69, loss 1.5634313821792603, acc=0.6045340299606323, loss=1.5634313821792603
train: epoch 70, loss 0.11369465291500092, acc=0.9636775851249695, loss=0.11369465291500092
test: epoch 70, loss 1.8613301515579224, acc=0.5264483690261841, loss=1.8613301515579224
train: epoch 71, loss 0.10012567043304443, acc=0.9681612253189087, loss=0.10012567043304443
test: epoch 71, loss 2.1451518535614014, acc=0.508816123008728, loss=2.1451518535614014
train: epoch 72, loss 0.09853897988796234, acc=0.9671536684036255, loss=0.09853897988796234
test: epoch 72, loss 1.6100850105285645, acc=0.6020151376724243, loss=1.6100850105285645
train: epoch 73, loss 0.0916135385632515, acc=0.9705793261528015, loss=0.0916135385632515
test: epoch 73, loss 1.8442133665084839, acc=0.6549118161201477, loss=1.8442133665084839
train: epoch 74, loss 0.11157059669494629, acc=0.9650881886482239, loss=0.11157059669494629
test: epoch 74, loss 1.4554643630981445, acc=0.6347606778144836, loss=1.4554643630981445
train: epoch 75, loss 0.09942791610956192, acc=0.9680100679397583, loss=0.09942791610956192
test: epoch 75, loss 1.1692750453948975, acc=0.6221662759780884, loss=1.1692750453948975
train: epoch 76, loss 0.09355569630861282, acc=0.9684634804725647, loss=0.09355569630861282
test: epoch 76, loss 1.3570986986160278, acc=0.6599496006965637, loss=1.3570986986160278
train: epoch 77, loss 0.09126817435026169, acc=0.9705793261528015, loss=0.09126817435026169
test: epoch 77, loss 1.3458373546600342, acc=0.6070529222488403, loss=1.3458373546600342
train: epoch 78, loss 0.09990282356739044, acc=0.9671536684036255, loss=0.09990282356739044
test: epoch 78, loss 1.6232904195785522, acc=0.6246851682662964, loss=1.6232904195785522
train: epoch 79, loss 0.09221785515546799, acc=0.9693198800086975, loss=0.09221785515546799
test: epoch 79, loss 1.4429153203964233, acc=0.6549118161201477, loss=1.4429153203964233
train: epoch 80, loss 0.10474276542663574, acc=0.9667506217956543, loss=0.10474276542663574
test: epoch 80, loss 1.9275039434432983, acc=0.6146095991134644, loss=1.9275039434432983
train: epoch 81, loss 0.09386158734560013, acc=0.9698740839958191, loss=0.09386158734560013
test: epoch 81, loss 1.5521891117095947, acc=0.6297228932380676, loss=1.5521891117095947
train: epoch 82, loss 0.09452272951602936, acc=0.9700251817703247, loss=0.09452272951602936
test: epoch 82, loss 1.6533710956573486, acc=0.6775818467140198, loss=1.6533710956573486
train: epoch 83, loss 0.10121507197618484, acc=0.9683123230934143, loss=0.10121507197618484
test: epoch 83, loss 1.7176603078842163, acc=0.6725440621376038, loss=1.7176603078842163
train: epoch 84, loss 0.08926576375961304, acc=0.9722921848297119, loss=0.08926576375961304
test: epoch 84, loss 1.3525233268737793, acc=0.6725440621376038, loss=1.3525233268737793
train: epoch 85, loss 0.08100450783967972, acc=0.9740554094314575, loss=0.08100450783967972
test: epoch 85, loss 1.30266535282135, acc=0.7027707695960999, loss=1.30266535282135
train: epoch 86, loss 0.09944137930870056, acc=0.9690176248550415, loss=0.09944137930870056
test: epoch 86, loss 1.2909513711929321, acc=0.6775818467140198, loss=1.2909513711929321
train: epoch 87, loss 0.09251239150762558, acc=0.9710831046104431, loss=0.09251239150762558
test: epoch 87, loss 1.1464145183563232, acc=0.6901763081550598, loss=1.1464145183563232
train: epoch 88, loss 0.09013031423091888, acc=0.9715868830680847, loss=0.09013031423091888
test: epoch 88, loss 1.2119280099868774, acc=0.7279596924781799, loss=1.2119280099868774
train: epoch 89, loss 0.086237832903862, acc=0.9730982184410095, loss=0.086237832903862
test: epoch 89, loss 1.4338923692703247, acc=0.6473551392555237, loss=1.4338923692703247
train: epoch 90, loss 0.08523163199424744, acc=0.9728967547416687, loss=0.08523163199424744
test: epoch 90, loss 1.0524823665618896, acc=0.7027707695960999, loss=1.0524823665618896
train: epoch 91, loss 0.09337645769119263, acc=0.9702267050743103, loss=0.09337645769119263
test: epoch 91, loss 1.24458646774292, acc=0.6952140927314758, loss=1.24458646774292
train: epoch 92, loss 0.0725896954536438, acc=0.9763224124908447, loss=0.0725896954536438
test: epoch 92, loss 1.0923833847045898, acc=0.7682619690895081, loss=1.0923833847045898
train: epoch 93, loss 0.09180540591478348, acc=0.9712342619895935, loss=0.09180540591478348
test: epoch 93, loss 1.265777587890625, acc=0.732997477054596, loss=1.265777587890625
train: epoch 94, loss 0.09181887656450272, acc=0.9721410870552063, loss=0.09181887656450272
test: epoch 94, loss 0.8952933549880981, acc=0.7758186459541321, loss=0.8952933549880981
train: epoch 95, loss 0.07785873860120773, acc=0.9756171107292175, loss=0.07785873860120773
test: epoch 95, loss 1.5275423526763916, acc=0.7027707695960999, loss=1.5275423526763916
train: epoch 96, loss 0.07315168529748917, acc=0.9762216806411743, loss=0.07315168529748917
test: epoch 96, loss 0.8816725015640259, acc=0.7657430768013, loss=0.8816725015640259
train: epoch 97, loss 0.07721362262964249, acc=0.9763727784156799, loss=0.07721362262964249
test: epoch 97, loss 0.986167848110199, acc=0.763224184513092, loss=0.986167848110199
train: epoch 98, loss 0.08082073926925659, acc=0.9749118685722351, loss=0.08082073926925659
test: epoch 98, loss 0.788774311542511, acc=0.750629723072052, loss=0.788774311542511
train: epoch 99, loss 0.0771435871720314, acc=0.9753148555755615, loss=0.0771435871720314
test: epoch 99, loss 1.149632215499878, acc=0.7229219079017639, loss=1.149632215499878
train: epoch 100, loss 0.07628128677606583, acc=0.9759193658828735, loss=0.07628128677606583
test: epoch 100, loss 1.2257732152938843, acc=0.75314861536026, loss=1.2257732152938843
train: epoch 101, loss 0.0826917439699173, acc=0.9742065668106079, loss=0.0826917439699173
test: epoch 101, loss 0.8107838034629822, acc=0.8110831379890442, loss=0.8107838034629822
train: epoch 102, loss 0.07549959421157837, acc=0.9760705232620239, loss=0.07549959421157837
test: epoch 102, loss 0.9904258847236633, acc=0.7984886765480042, loss=0.9904258847236633
train: epoch 103, loss 0.07949351519346237, acc=0.9769773483276367, loss=0.07949351519346237
test: epoch 103, loss 0.9507051110267639, acc=0.8161209225654602, loss=0.9507051110267639
train: epoch 104, loss 0.08413632959127426, acc=0.9742569327354431, loss=0.08413632959127426
test: epoch 104, loss 0.745161771774292, acc=0.8211587071418762, loss=0.745161771774292
train: epoch 105, loss 0.07997415959835052, acc=0.9751133322715759, loss=0.07997415959835052
test: epoch 105, loss 0.9381327033042908, acc=0.8060453534126282, loss=0.9381327033042908
train: epoch 106, loss 0.08808422833681107, acc=0.9706297516822815, loss=0.08808422833681107
test: epoch 106, loss 0.6092848777770996, acc=0.8136020302772522, loss=0.6092848777770996
train: epoch 107, loss 0.06757819652557373, acc=0.979193925857544, loss=0.06757819652557373
test: epoch 107, loss 0.6356263756752014, acc=0.8161209225654602, loss=0.6356263756752014
train: epoch 108, loss 0.07080099731683731, acc=0.9776322245597839, loss=0.07080099731683731
test: epoch 108, loss 0.7508993744850159, acc=0.8186398148536682, loss=0.7508993744850159
train: epoch 109, loss 0.06980158388614655, acc=0.9785390496253967, loss=0.06980158388614655
test: epoch 109, loss 0.7444372773170471, acc=0.8236775994300842, loss=0.7444372773170471
train: epoch 110, loss 0.06801871210336685, acc=0.9787909388542175, loss=0.06801871210336685
test: epoch 110, loss 0.9008884429931641, acc=0.8060453534126282, loss=0.9008884429931641
train: epoch 111, loss 0.05921193212270737, acc=0.9819143414497375, loss=0.05921193212270737
test: epoch 111, loss 0.9124700427055359, acc=0.8035264611244202, loss=0.9124700427055359
train: epoch 112, loss 0.07031980901956558, acc=0.9797984957695007, loss=0.07031980901956558
test: epoch 112, loss 0.9645614624023438, acc=0.8236775994300842, loss=0.9645614624023438
train: epoch 113, loss 0.0637991800904274, acc=0.9801511168479919, loss=0.0637991800904274
test: epoch 113, loss 0.9991568922996521, acc=0.8035264611244202, loss=0.9991568922996521
train: epoch 114, loss 0.07008139044046402, acc=0.979193925857544, loss=0.07008139044046402
test: epoch 114, loss 0.9101002216339111, acc=0.8060453534126282, loss=0.9101002216339111
train: epoch 115, loss 0.06770972162485123, acc=0.9794962406158447, loss=0.06770972162485123
test: epoch 115, loss 0.7992759943008423, acc=0.8236775994300842, loss=0.7992759943008423
train: epoch 116, loss 0.07065664231777191, acc=0.9792443513870239, loss=0.07065664231777191
test: epoch 116, loss 0.7397447824478149, acc=0.8186398148536682, loss=0.7397447824478149
train: epoch 117, loss 0.06086476147174835, acc=0.9808564186096191, loss=0.06086476147174835
test: epoch 117, loss 0.6394293308258057, acc=0.8236775994300842, loss=0.6394293308258057
train: epoch 118, loss 0.06671082228422165, acc=0.9788916707038879, loss=0.06671082228422165
test: epoch 118, loss 0.7262154817581177, acc=0.8186398148536682, loss=0.7262154817581177
train: epoch 119, loss 0.06648615747690201, acc=0.9795466065406799, loss=0.06648615747690201
test: epoch 119, loss 0.8920295238494873, acc=0.8186398148536682, loss=0.8920295238494873
train: epoch 120, loss 0.053943756967782974, acc=0.9831234216690063, loss=0.053943756967782974
test: epoch 120, loss 0.7980995178222656, acc=0.8261964917182922, loss=0.7980995178222656
train: epoch 121, loss 0.05983618646860123, acc=0.9807556867599487, loss=0.05983618646860123
test: epoch 121, loss 0.9626338481903076, acc=0.8236775994300842, loss=0.9626338481903076
train: epoch 122, loss 0.05764495208859444, acc=0.9808060526847839, loss=0.05764495208859444
test: epoch 122, loss 0.899631142616272, acc=0.8261964917182922, loss=0.899631142616272
train: epoch 123, loss 0.05260239541530609, acc=0.9839798212051392, loss=0.05260239541530609
test: epoch 123, loss 0.8599067330360413, acc=0.8236775994300842, loss=0.8599067330360413
train: epoch 124, loss 0.054948482662439346, acc=0.9828211665153503, loss=0.054948482662439346
test: epoch 124, loss 0.9403596520423889, acc=0.8186398148536682, loss=0.9403596520423889
train: epoch 125, loss 0.054232511669397354, acc=0.9829218983650208, loss=0.054232511669397354
test: epoch 125, loss 0.811630368232727, acc=0.8161209225654602, loss=0.811630368232727
train: epoch 126, loss 0.06563328206539154, acc=0.9799495935440063, loss=0.06563328206539154
test: epoch 126, loss 1.0572254657745361, acc=0.8186398148536682, loss=1.0572254657745361
train: epoch 127, loss 0.05844276398420334, acc=0.9809571504592896, loss=0.05844276398420334
test: epoch 127, loss 0.7047646641731262, acc=0.8261964917182922, loss=0.7047646641731262
train: epoch 128, loss 0.056500647217035294, acc=0.9822670221328735, loss=0.056500647217035294
test: epoch 128, loss 0.659880518913269, acc=0.8211587071418762, loss=0.659880518913269
train: epoch 129, loss 0.05043251812458038, acc=0.9832745790481567, loss=0.05043251812458038
test: epoch 129, loss 0.834855854511261, acc=0.8136020302772522, loss=0.834855854511261
train: epoch 130, loss 0.05465731397271156, acc=0.9829218983650208, loss=0.05465731397271156
test: epoch 130, loss 1.0234392881393433, acc=0.8110831379890442, loss=1.0234392881393433
train: epoch 131, loss 0.05042312294244766, acc=0.983627200126648, loss=0.05042312294244766
test: epoch 131, loss 1.2351126670837402, acc=0.8110831379890442, loss=1.2351126670837402
train: epoch 132, loss 0.05328759923577309, acc=0.9841813445091248, loss=0.05328759923577309
test: epoch 132, loss 1.0161406993865967, acc=0.8186398148536682, loss=1.0161406993865967
train: epoch 133, loss 0.05219618231058121, acc=0.9831234216690063, loss=0.05219618231058121
test: epoch 133, loss 0.738375186920166, acc=0.8287153840065002, loss=0.738375186920166
train: epoch 134, loss 0.0466778501868248, acc=0.9857430458068848, loss=0.0466778501868248
test: epoch 134, loss 1.1997500658035278, acc=0.7884131073951721, loss=1.1997500658035278
train: epoch 135, loss 0.05671252682805061, acc=0.9827203750610352, loss=0.05671252682805061
test: epoch 135, loss 0.8449876308441162, acc=0.8261964917182922, loss=0.8449876308441162
train: epoch 136, loss 0.05067676305770874, acc=0.9863476157188416, loss=0.05067676305770874
test: epoch 136, loss 0.8126295208930969, acc=0.8060453534126282, loss=0.8126295208930969
train: epoch 137, loss 0.05069863051176071, acc=0.9844835996627808, loss=0.05069863051176071
test: epoch 137, loss 0.7422569990158081, acc=0.8161209225654602, loss=0.7422569990158081
train: epoch 138, loss 0.04282866045832634, acc=0.9859949350357056, loss=0.04282866045832634
test: epoch 138, loss 1.010624885559082, acc=0.8287153840065002, loss=1.010624885559082
train: epoch 139, loss 0.0467851385474205, acc=0.9864987134933472, loss=0.0467851385474205
test: epoch 139, loss 1.1462990045547485, acc=0.8211587071418762, loss=1.1462990045547485
train: epoch 140, loss 0.04825718328356743, acc=0.9851385354995728, loss=0.04825718328356743
test: epoch 140, loss 0.99277663230896, acc=0.8110831379890442, loss=0.99277663230896
train: epoch 141, loss 0.05014028772711754, acc=0.9850378036499023, loss=0.05014028772711754
test: epoch 141, loss 0.9723818302154541, acc=0.8261964917182922, loss=0.9723818302154541
train: epoch 142, loss 0.04630855843424797, acc=0.9860957264900208, loss=0.04630855843424797
test: epoch 142, loss 0.8241673111915588, acc=0.8136020302772522, loss=0.8241673111915588
train: epoch 143, loss 0.041724562644958496, acc=0.9870529174804688, loss=0.041724562644958496
test: epoch 143, loss 0.7684301733970642, acc=0.8236775994300842, loss=0.7684301733970642
train: epoch 144, loss 0.043801888823509216, acc=0.986146092414856, loss=0.043801888823509216
test: epoch 144, loss 1.0731923580169678, acc=0.8110831379890442, loss=1.0731923580169678
train: epoch 145, loss 0.04394512623548508, acc=0.9869521260261536, loss=0.04394512623548508
test: epoch 145, loss 0.793694019317627, acc=0.8035264611244202, loss=0.793694019317627
train: epoch 146, loss 0.043655578047037125, acc=0.986146092414856, loss=0.043655578047037125
test: epoch 146, loss 0.8097675442695618, acc=0.8010075688362122, loss=0.8097675442695618
train: epoch 147, loss 0.043399035930633545, acc=0.986750602722168, loss=0.043399035930633545
test: epoch 147, loss 0.679140031337738, acc=0.7984886765480042, loss=0.679140031337738
train: epoch 148, loss 0.04302937909960747, acc=0.9864987134933472, loss=0.04302937909960747
test: epoch 148, loss 0.7243025302886963, acc=0.8211587071418762, loss=0.7243025302886963
train: epoch 149, loss 0.047482460737228394, acc=0.985541582107544, loss=0.047482460737228394
test: epoch 149, loss 1.0661078691482544, acc=0.8110831379890442, loss=1.0661078691482544
train: epoch 150, loss 0.04116581752896309, acc=0.9877581596374512, loss=0.04116581752896309
test: epoch 150, loss 0.8211784362792969, acc=0.8060453534126282, loss=0.8211784362792969
train: epoch 151, loss 0.03734320029616356, acc=0.98896723985672, loss=0.03734320029616356
test: epoch 151, loss 0.7587029933929443, acc=0.8186398148536682, loss=0.7587029933929443
train: epoch 152, loss 0.04558167979121208, acc=0.9862468242645264, loss=0.04558167979121208
test: epoch 152, loss 0.7919753789901733, acc=0.8161209225654602, loss=0.7919753789901733
train: epoch 153, loss 0.04979599639773369, acc=0.9845340251922607, loss=0.04979599639773369
test: epoch 153, loss 0.8961009383201599, acc=0.8211587071418762, loss=0.8961009383201599
train: epoch 154, loss 0.04096774384379387, acc=0.986801028251648, loss=0.04096774384379387
test: epoch 154, loss 0.847091794013977, acc=0.8261964917182922, loss=0.847091794013977
train: epoch 155, loss 0.03958015516400337, acc=0.9881612062454224, loss=0.03958015516400337
test: epoch 155, loss 0.9864903092384338, acc=0.8035264611244202, loss=0.9864903092384338
train: epoch 156, loss 0.03983577713370323, acc=0.9861964583396912, loss=0.03983577713370323
test: epoch 156, loss 1.0168421268463135, acc=0.7959697842597961, loss=1.0168421268463135
train: epoch 157, loss 0.04794110357761383, acc=0.9858942031860352, loss=0.04794110357761383
test: epoch 157, loss 0.7502780556678772, acc=0.8186398148536682, loss=0.7502780556678772
train: epoch 158, loss 0.04144471883773804, acc=0.9868513941764832, loss=0.04144471883773804
test: epoch 158, loss 1.1523598432540894, acc=0.8060453534126282, loss=1.1523598432540894
train: epoch 159, loss 0.039188023656606674, acc=0.9879093170166016, loss=0.039188023656606674
test: epoch 159, loss 1.059488296508789, acc=0.8186398148536682, loss=1.059488296508789
train: epoch 160, loss 0.058222927153110504, acc=0.9850881695747375, loss=0.058222927153110504
test: epoch 160, loss 0.6609417200088501, acc=0.8261964917182922, loss=0.6609417200088501
train: epoch 161, loss 0.04125599190592766, acc=0.9874559044837952, loss=0.04125599190592766
test: epoch 161, loss 0.8196637630462646, acc=0.8136020302772522, loss=0.8196637630462646
train: epoch 162, loss 0.036684587597846985, acc=0.9881108403205872, loss=0.036684587597846985
test: epoch 162, loss 0.9121521711349487, acc=0.8186398148536682, loss=0.9121521711349487
train: epoch 163, loss 0.04280029982328415, acc=0.9876070618629456, loss=0.04280029982328415
test: epoch 163, loss 0.8108332753181458, acc=0.8261964917182922, loss=0.8108332753181458
train: epoch 164, loss 0.041362106800079346, acc=0.9872040152549744, loss=0.041362106800079346
test: epoch 164, loss 0.7182349562644958, acc=0.8236775994300842, loss=0.7182349562644958
train: epoch 165, loss 0.03407450020313263, acc=0.9894710183143616, loss=0.03407450020313263
test: epoch 165, loss 0.8448767066001892, acc=0.8236775994300842, loss=0.8448767066001892
train: epoch 166, loss 0.0425771065056324, acc=0.986801028251648, loss=0.0425771065056324
test: epoch 166, loss 0.645975649356842, acc=0.8060453534126282, loss=0.645975649356842
train: epoch 167, loss 0.04059514403343201, acc=0.9874559044837952, loss=0.04059514403343201
test: epoch 167, loss 0.7450109720230103, acc=0.8287153840065002, loss=0.7450109720230103
train: epoch 168, loss 0.03701920062303543, acc=0.988362729549408, loss=0.03701920062303543
test: epoch 168, loss 1.0694440603256226, acc=0.8035264611244202, loss=1.0694440603256226
train: epoch 169, loss 0.03427891060709953, acc=0.9890176057815552, loss=0.03427891060709953
test: epoch 169, loss 0.8996939659118652, acc=0.8261964917182922, loss=0.8996939659118652
train: epoch 170, loss 0.03874785453081131, acc=0.9882115721702576, loss=0.03874785453081131
test: epoch 170, loss 0.9437308311462402, acc=0.7884131073951721, loss=0.9437308311462402
train: epoch 171, loss 0.04222084581851959, acc=0.9870529174804688, loss=0.04222084581851959
test: epoch 171, loss 0.9252792596817017, acc=0.8085642457008362, loss=0.9252792596817017
train: epoch 172, loss 0.037875570356845856, acc=0.988060474395752, loss=0.037875570356845856
test: epoch 172, loss 0.6776685118675232, acc=0.8211587071418762, loss=0.6776685118675232
train: epoch 173, loss 0.04201687127351761, acc=0.9881612062454224, loss=0.04201687127351761
test: epoch 173, loss 0.8107972145080566, acc=0.8211587071418762, loss=0.8107972145080566
train: epoch 174, loss 0.04081159830093384, acc=0.9869521260261536, loss=0.04081159830093384
test: epoch 174, loss 0.8715262413024902, acc=0.8136020302772522, loss=0.8715262413024902
train: epoch 175, loss 0.034047286957502365, acc=0.9890176057815552, loss=0.034047286957502365
test: epoch 175, loss 0.8795577883720398, acc=0.8236775994300842, loss=0.8795577883720398
train: epoch 176, loss 0.03929358720779419, acc=0.9877581596374512, loss=0.03929358720779419
test: epoch 176, loss 0.8894992470741272, acc=0.7959697842597961, loss=0.8894992470741272
train: epoch 177, loss 0.04080697521567345, acc=0.9878589510917664, loss=0.04080697521567345
test: epoch 177, loss 0.7482115030288696, acc=0.8085642457008362, loss=0.7482115030288696
train: epoch 178, loss 0.036805376410484314, acc=0.988362729549408, loss=0.036805376410484314
test: epoch 178, loss 0.7968531847000122, acc=0.8287153840065002, loss=0.7968531847000122
train: epoch 179, loss 0.044503964483737946, acc=0.986448347568512, loss=0.044503964483737946
test: epoch 179, loss 0.9535426497459412, acc=0.8236775994300842, loss=0.9535426497459412
train: epoch 180, loss 0.040778301656246185, acc=0.98740553855896, loss=0.040778301656246185
test: epoch 180, loss 0.9765303134918213, acc=0.8261964917182922, loss=0.9765303134918213
train: epoch 181, loss 0.043788835406303406, acc=0.9864987134933472, loss=0.043788835406303406
test: epoch 181, loss 1.008259892463684, acc=0.8186398148536682, loss=1.008259892463684
train: epoch 182, loss 0.03279540687799454, acc=0.9895213842391968, loss=0.03279540687799454
test: epoch 182, loss 0.9701142311096191, acc=0.8261964917182922, loss=0.9701142311096191
train: epoch 183, loss 0.043135229498147964, acc=0.9863476157188416, loss=0.043135229498147964
test: epoch 183, loss 0.8011927604675293, acc=0.8287153840065002, loss=0.8011927604675293
train: epoch 184, loss 0.034296274185180664, acc=0.9897732734680176, loss=0.034296274185180664
test: epoch 184, loss 0.9136785268783569, acc=0.8186398148536682, loss=0.9136785268783569
train: epoch 185, loss 0.042010996490716934, acc=0.9873048067092896, loss=0.042010996490716934
test: epoch 185, loss 0.8582315444946289, acc=0.8312342762947083, loss=0.8582315444946289
train: epoch 186, loss 0.03154410794377327, acc=0.9899747967720032, loss=0.03154410794377327
test: epoch 186, loss 1.0293270349502563, acc=0.8186398148536682, loss=1.0293270349502563
train: epoch 187, loss 0.032779376953840256, acc=0.9897229075431824, loss=0.032779376953840256
test: epoch 187, loss 0.8714213967323303, acc=0.8161209225654602, loss=0.8714213967323303
train: epoch 188, loss 0.048726413398981094, acc=0.9861964583396912, loss=0.048726413398981094
test: epoch 188, loss 1.285518765449524, acc=0.8035264611244202, loss=1.285518765449524
train: epoch 189, loss 0.03499845042824745, acc=0.9894710183143616, loss=0.03499845042824745
test: epoch 189, loss 1.0608057975769043, acc=0.8211587071418762, loss=1.0608057975769043
train: epoch 190, loss 0.040304530411958694, acc=0.9881108403205872, loss=0.040304530411958694
test: epoch 190, loss 0.8858393430709839, acc=0.8312342762947083, loss=0.8858393430709839
train: epoch 191, loss 0.030529798939824104, acc=0.990226686000824, loss=0.030529798939824104
test: epoch 191, loss 0.8659819960594177, acc=0.8287153840065002, loss=0.8659819960594177
train: epoch 192, loss 0.03837502375245094, acc=0.9882619380950928, loss=0.03837502375245094
test: epoch 192, loss 0.7684261798858643, acc=0.8236775994300842, loss=0.7684261798858643
train: epoch 193, loss 0.04067670553922653, acc=0.9881612062454224, loss=0.04067670553922653
test: epoch 193, loss 0.7262955904006958, acc=0.8312342762947083, loss=0.7262955904006958
train: epoch 194, loss 0.035343483090400696, acc=0.9890176057815552, loss=0.035343483090400696
test: epoch 194, loss 0.9163467884063721, acc=0.8236775994300842, loss=0.9163467884063721
train: epoch 195, loss 0.0419863685965538, acc=0.9883123636245728, loss=0.0419863685965538
test: epoch 195, loss 0.704844057559967, acc=0.8337531685829163, loss=0.704844057559967
train: epoch 196, loss 0.03311866894364357, acc=0.9897732734680176, loss=0.03311866894364357
test: epoch 196, loss 0.8737500905990601, acc=0.8236775994300842, loss=0.8737500905990601
train: epoch 197, loss 0.04429313912987709, acc=0.9862972497940063, loss=0.04429313912987709
test: epoch 197, loss 0.5372745990753174, acc=0.8287153840065002, loss=0.5372745990753174
train: epoch 198, loss 0.04632091149687767, acc=0.9859949350357056, loss=0.04632091149687767
test: epoch 198, loss 0.865341067314148, acc=0.8539043068885803, loss=0.865341067314148
train: epoch 199, loss 0.033466488122940063, acc=0.9897229075431824, loss=0.033466488122940063
test: epoch 199, loss 0.6581108570098877, acc=0.8387909531593323, loss=0.6581108570098877
train: epoch 200, loss 0.03576761484146118, acc=0.9888665080070496, loss=0.03576761484146118
test: epoch 200, loss 0.8690209984779358, acc=0.8614609837532043, loss=0.8690209984779358
train: epoch 201, loss 0.029117166996002197, acc=0.9908312559127808, loss=0.029117166996002197
test: epoch 201, loss 0.9359921216964722, acc=0.8513854146003723, loss=0.9359921216964722
train: epoch 202, loss 0.030336549505591393, acc=0.9907304644584656, loss=0.030336549505591393
test: epoch 202, loss 0.7959664463996887, acc=0.8614609837532043, loss=0.7959664463996887
train: epoch 203, loss 0.04852621629834175, acc=0.9858438372612, loss=0.04852621629834175
test: epoch 203, loss 0.7608727812767029, acc=0.8413098454475403, loss=0.7608727812767029
train: epoch 204, loss 0.034577272832393646, acc=0.9894710183143616, loss=0.034577272832393646
test: epoch 204, loss 1.0070523023605347, acc=0.8413098454475403, loss=1.0070523023605347
train: epoch 205, loss 0.03172110766172409, acc=0.9898236989974976, loss=0.03172110766172409
test: epoch 205, loss 0.800532341003418, acc=0.8614609837532043, loss=0.800532341003418
train: epoch 206, loss 0.03278075531125069, acc=0.989924430847168, loss=0.03278075531125069
test: epoch 206, loss 0.6582901477813721, acc=0.8564231991767883, loss=0.6582901477813721
train: epoch 207, loss 0.032797254621982574, acc=0.9894710183143616, loss=0.032797254621982574
test: epoch 207, loss 0.7445158362388611, acc=0.8614609837532043, loss=0.7445158362388611
train: epoch 208, loss 0.03169333562254906, acc=0.9897732734680176, loss=0.03169333562254906
test: epoch 208, loss 0.7219743132591248, acc=0.8438287377357483, loss=0.7219743132591248
train: epoch 209, loss 0.0381995253264904, acc=0.9887657165527344, loss=0.0381995253264904
test: epoch 209, loss 0.7344627976417542, acc=0.8513854146003723, loss=0.7344627976417542
train: epoch 210, loss 0.029953375458717346, acc=0.990881621837616, loss=0.029953375458717346
test: epoch 210, loss 0.8624187707901001, acc=0.8589420914649963, loss=0.8624187707901001
train: epoch 211, loss 0.0321410708129406, acc=0.9890680313110352, loss=0.0321410708129406
test: epoch 211, loss 0.7076612114906311, acc=0.8539043068885803, loss=0.7076612114906311
train: epoch 212, loss 0.03756174445152283, acc=0.9893702864646912, loss=0.03756174445152283
test: epoch 212, loss 0.6655504703521729, acc=0.8513854146003723, loss=0.6655504703521729
train: epoch 213, loss 0.03397399187088013, acc=0.9894206523895264, loss=0.03397399187088013
test: epoch 213, loss 0.9025110006332397, acc=0.8413098454475403, loss=0.9025110006332397
train: epoch 214, loss 0.040729623287916183, acc=0.989319920539856, loss=0.040729623287916183
test: epoch 214, loss 0.6674007773399353, acc=0.8589420914649963, loss=0.6674007773399353
train: epoch 215, loss 0.033583927899599075, acc=0.989319920539856, loss=0.033583927899599075
test: epoch 215, loss 0.7098421454429626, acc=0.8614609837532043, loss=0.7098421454429626
train: epoch 216, loss 0.026879271492362022, acc=0.9907808303833008, loss=0.026879271492362022
test: epoch 216, loss 0.6975400447845459, acc=0.8564231991767883, loss=0.6975400447845459
train: epoch 217, loss 0.03690321743488312, acc=0.989924430847168, loss=0.03690321743488312
test: epoch 217, loss 1.1721655130386353, acc=0.8387909531593323, loss=1.1721655130386353
train: epoch 218, loss 0.03425884619355202, acc=0.9891687631607056, loss=0.03425884619355202
test: epoch 218, loss 0.9581781029701233, acc=0.8387909531593323, loss=0.9581781029701233
train: epoch 219, loss 0.028317874297499657, acc=0.9912342429161072, loss=0.028317874297499657
test: epoch 219, loss 0.6129382252693176, acc=0.8690176606178284, loss=0.6129382252693176
train: epoch 220, loss 0.039284124970436096, acc=0.9888665080070496, loss=0.039284124970436096
test: epoch 220, loss 0.8425163626670837, acc=0.8664987683296204, loss=0.8425163626670837
train: epoch 221, loss 0.03858104720711708, acc=0.9879093170166016, loss=0.03858104720711708
test: epoch 221, loss 0.8157144784927368, acc=0.8614609837532043, loss=0.8157144784927368
train: epoch 222, loss 0.030068637803196907, acc=0.9909319877624512, loss=0.030068637803196907
test: epoch 222, loss 0.7120544910430908, acc=0.8639798760414124, loss=0.7120544910430908
train: epoch 223, loss 0.02678714133799076, acc=0.9912846088409424, loss=0.02678714133799076
test: epoch 223, loss 0.76377272605896, acc=0.8690176606178284, loss=0.76377272605896
train: epoch 224, loss 0.033942241221666336, acc=0.9897732734680176, loss=0.033942241221666336
test: epoch 224, loss 0.6655337810516357, acc=0.8614609837532043, loss=0.6655337810516357
train: epoch 225, loss 0.030901234596967697, acc=0.9906800985336304, loss=0.030901234596967697
test: epoch 225, loss 0.7793824076652527, acc=0.8740554451942444, loss=0.7793824076652527
train: epoch 226, loss 0.02731400355696678, acc=0.9909823536872864, loss=0.02731400355696678
test: epoch 226, loss 0.8505081534385681, acc=0.8513854146003723, loss=0.8505081534385681
train: epoch 227, loss 0.03689074516296387, acc=0.9896725416183472, loss=0.03689074516296387
test: epoch 227, loss 0.8092301487922668, acc=0.8639798760414124, loss=0.8092301487922668
train: epoch 228, loss 0.028358999639749527, acc=0.9906800985336304, loss=0.028358999639749527
test: epoch 228, loss 0.787007749080658, acc=0.8715365529060364, loss=0.787007749080658
train: epoch 229, loss 0.03347716107964516, acc=0.989269495010376, loss=0.03347716107964516
test: epoch 229, loss 0.6648616194725037, acc=0.8513854146003723, loss=0.6648616194725037
train: epoch 230, loss 0.036014754325151443, acc=0.9895718097686768, loss=0.036014754325151443
test: epoch 230, loss 0.7781735062599182, acc=0.8740554451942444, loss=0.7781735062599182
train: epoch 231, loss 0.040678996592760086, acc=0.9893702864646912, loss=0.040678996592760086
test: epoch 231, loss 0.6919780969619751, acc=0.8765742778778076, loss=0.6919780969619751
train: epoch 232, loss 0.03375094383955002, acc=0.9904282093048096, loss=0.03375094383955002
test: epoch 232, loss 0.6625233888626099, acc=0.8765742778778076, loss=0.6625233888626099
train: epoch 233, loss 0.0249682255089283, acc=0.9913854002952576, loss=0.0249682255089283
test: epoch 233, loss 0.6378580331802368, acc=0.8715365529060364, loss=0.6378580331802368
train: epoch 234, loss 0.030811119824647903, acc=0.9903274774551392, loss=0.030811119824647903
test: epoch 234, loss 0.5912714004516602, acc=0.8589420914649963, loss=0.5912714004516602
train: epoch 235, loss 0.03627549111843109, acc=0.9891687631607056, loss=0.03627549111843109
test: epoch 235, loss 0.6851800680160522, acc=0.8539043068885803, loss=0.6851800680160522
train: epoch 236, loss 0.031088538467884064, acc=0.989924430847168, loss=0.031088538467884064
test: epoch 236, loss 0.5642353296279907, acc=0.8790931701660156, loss=0.5642353296279907
train: epoch 237, loss 0.030930129811167717, acc=0.99057936668396, loss=0.030930129811167717
test: epoch 237, loss 0.685305118560791, acc=0.8765742778778076, loss=0.685305118560791
train: epoch 238, loss 0.026266051456332207, acc=0.9915869235992432, loss=0.026266051456332207
test: epoch 238, loss 0.7756882905960083, acc=0.8790931701660156, loss=0.7756882905960083
train: epoch 239, loss 0.02605585940182209, acc=0.9917380213737488, loss=0.02605585940182209
test: epoch 239, loss 0.6596939563751221, acc=0.8790931701660156, loss=0.6596939563751221
train: epoch 240, loss 0.049025919288396835, acc=0.9874559044837952, loss=0.049025919288396835
test: epoch 240, loss 0.703191876411438, acc=0.8715365529060364, loss=0.703191876411438
train: epoch 241, loss 0.03217949718236923, acc=0.99057936668396, loss=0.03217949718236923
test: epoch 241, loss 0.857334554195404, acc=0.8690176606178284, loss=0.857334554195404
train: epoch 242, loss 0.023781269788742065, acc=0.9917380213737488, loss=0.023781269788742065
test: epoch 242, loss 0.7059008479118347, acc=0.8790931701660156, loss=0.7059008479118347
train: epoch 243, loss 0.03435765206813812, acc=0.989319920539856, loss=0.03435765206813812
test: epoch 243, loss 0.8423101305961609, acc=0.8790931701660156, loss=0.8423101305961609
train: epoch 244, loss 0.03459903970360756, acc=0.990881621837616, loss=0.03459903970360756
test: epoch 244, loss 0.6797968745231628, acc=0.8790931701660156, loss=0.6797968745231628
train: epoch 245, loss 0.03150494024157524, acc=0.9898740649223328, loss=0.03150494024157524
test: epoch 245, loss 0.6352643966674805, acc=0.8790931701660156, loss=0.6352643966674805
train: epoch 246, loss 0.028475258499383926, acc=0.9912342429161072, loss=0.028475258499383926
test: epoch 246, loss 0.5576095581054688, acc=0.8816120624542236, loss=0.5576095581054688
train: epoch 247, loss 0.027230562642216682, acc=0.9906800985336304, loss=0.027230562642216682
test: epoch 247, loss 0.6887248754501343, acc=0.8816120624542236, loss=0.6887248754501343
train: epoch 248, loss 0.027607768774032593, acc=0.991183876991272, loss=0.027607768774032593
test: epoch 248, loss 0.6602829098701477, acc=0.8816120624542236, loss=0.6602829098701477
train: epoch 249, loss 0.029855189844965935, acc=0.9908312559127808, loss=0.029855189844965935
test: epoch 249, loss 0.5500667095184326, acc=0.8790931701660156, loss=0.5500667095184326
train: epoch 250, loss 0.030821621417999268, acc=0.989622175693512, loss=0.030821621417999268
test: epoch 250, loss 0.661869466304779, acc=0.8513854146003723, loss=0.661869466304779
