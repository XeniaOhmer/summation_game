# ["--N=80", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=1", "--n_layers=3", "--save_run=1", "--test_split=0.2", "--n_symbols=644"]
Namespace(N=80, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=644, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=206349434, receiver_embed_dim=64, save_run=True, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.2, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.372882843017578, acc=0.2033034861087799, loss=2.372882843017578
test: epoch 1, loss 5.613419532775879, acc=0.07125166803598404, loss=5.613419532775879
train: epoch 2, loss 1.4649962186813354, acc=0.3764336109161377, loss=1.4649962186813354
test: epoch 2, loss 4.730934143066406, acc=0.0906839370727539, loss=4.730934143066406
train: epoch 3, loss 1.192736268043518, acc=0.487932950258255, loss=1.192736268043518
test: epoch 3, loss 4.232533931732178, acc=0.12916746735572815, loss=4.232533931732178
train: epoch 4, loss 0.911552906036377, acc=0.6162812113761902, loss=0.911552906036377
test: epoch 4, loss 4.0306596755981445, acc=0.13869307935237885, loss=4.0306596755981445
train: epoch 5, loss 0.7419917583465576, acc=0.690131425857544, loss=0.7419917583465576
test: epoch 5, loss 3.7167561054229736, acc=0.17508096992969513, loss=3.7167561054229736
train: epoch 6, loss 0.6346065402030945, acc=0.7373137474060059, loss=0.6346065402030945
test: epoch 6, loss 3.3630211353302, acc=0.19375118613243103, loss=3.3630211353302
train: epoch 7, loss 0.5782233476638794, acc=0.7623128294944763, loss=0.5782233476638794
test: epoch 7, loss 3.514507532119751, acc=0.17565250396728516, loss=3.514507532119751
train: epoch 8, loss 0.5389490127563477, acc=0.7795122861862183, loss=0.5389490127563477
test: epoch 8, loss 3.853911876678467, acc=0.16688893735408783, loss=3.853911876678467
train: epoch 9, loss 0.484767884016037, acc=0.8038597702980042, loss=0.484767884016037
test: epoch 9, loss 3.2934224605560303, acc=0.1735568642616272, loss=3.2934224605560303
train: epoch 10, loss 0.4553512930870056, acc=0.8187464475631714, loss=0.4553512930870056
test: epoch 10, loss 3.221061944961548, acc=0.2255667746067047, loss=3.221061944961548
train: epoch 11, loss 0.4138398766517639, acc=0.8369670510292053, loss=0.4138398766517639
test: epoch 11, loss 3.2167391777038574, acc=0.22442370653152466, loss=3.2167391777038574
train: epoch 12, loss 0.3777503967285156, acc=0.8536978363990784, loss=0.3777503967285156
test: epoch 12, loss 3.079538345336914, acc=0.2629072070121765, loss=3.079538345336914
train: epoch 13, loss 0.34706029295921326, acc=0.8673499822616577, loss=0.34706029295921326
test: epoch 13, loss 2.9987969398498535, acc=0.22842445969581604, loss=2.9987969398498535
train: epoch 14, loss 0.3093336522579193, acc=0.8845418095588684, loss=0.3093336522579193
test: epoch 14, loss 3.186121702194214, acc=0.21356448531150818, loss=3.186121702194214
train: epoch 15, loss 0.2830655574798584, acc=0.8961973786354065, loss=0.2830655574798584
test: epoch 15, loss 2.9765655994415283, acc=0.280243843793869, loss=2.9765655994415283
train: epoch 16, loss 0.25122523307800293, acc=0.9106420278549194, loss=0.25122523307800293
test: epoch 16, loss 2.9615848064422607, acc=0.2920556366443634, loss=2.9615848064422607
train: epoch 17, loss 0.22483226656913757, acc=0.9209297299385071, loss=0.22483226656913757
test: epoch 17, loss 3.0512847900390625, acc=0.28138694167137146, loss=3.0512847900390625
train: epoch 18, loss 0.20608414709568024, acc=0.9290722012519836, loss=0.20608414709568024
test: epoch 18, loss 3.0685484409332275, acc=0.2650028467178345, loss=3.0685484409332275
train: epoch 19, loss 0.19194358587265015, acc=0.9348104596138, loss=0.19194358587265015
test: epoch 19, loss 2.973783016204834, acc=0.31148791313171387, loss=2.973783016204834
train: epoch 20, loss 0.17593295872211456, acc=0.9410287737846375, loss=0.17593295872211456
test: epoch 20, loss 3.1957390308380127, acc=0.31053534150123596, loss=3.1957390308380127
train: epoch 21, loss 0.16678117215633392, acc=0.9444960951805115, loss=0.16678117215633392
test: epoch 21, loss 2.862518310546875, acc=0.3274909555912018, loss=2.862518310546875
train: epoch 22, loss 0.1635252684354782, acc=0.9464659690856934, loss=0.1635252684354782
test: epoch 22, loss 2.780940055847168, acc=0.3375881016254425, loss=2.780940055847168
train: epoch 23, loss 0.15473459661006927, acc=0.94968181848526, loss=0.15473459661006927
test: epoch 23, loss 2.975923538208008, acc=0.35321012139320374, loss=2.975923538208008
train: epoch 24, loss 0.14584128558635712, acc=0.9524785876274109, loss=0.14584128558635712
test: epoch 24, loss 2.6268129348754883, acc=0.360259085893631, loss=2.6268129348754883
train: epoch 25, loss 0.141470268368721, acc=0.9546085000038147, loss=0.141470268368721
test: epoch 25, loss 2.6907756328582764, acc=0.3379691243171692, loss=2.6907756328582764
train: epoch 26, loss 0.1327298879623413, acc=0.9576185941696167, loss=0.1327298879623413
test: epoch 26, loss 2.9382643699645996, acc=0.36006858944892883, loss=2.9382643699645996
train: epoch 27, loss 0.1276276856660843, acc=0.9598551988601685, loss=0.1276276856660843
test: epoch 27, loss 2.561339855194092, acc=0.3827395737171173, loss=2.561339855194092
train: epoch 28, loss 0.12630967795848846, acc=0.9601181149482727, loss=0.12630967795848846
test: epoch 28, loss 2.3113090991973877, acc=0.4301771819591522, loss=2.3113090991973877
train: epoch 29, loss 0.12170354276895523, acc=0.9617908000946045, loss=0.12170354276895523
test: epoch 29, loss 2.3909077644348145, acc=0.45532482862472534, loss=2.3909077644348145
train: epoch 30, loss 0.11674872785806656, acc=0.9636273384094238, loss=0.11674872785806656
test: epoch 30, loss 2.6789257526397705, acc=0.3972185254096985, loss=2.6789257526397705
train: epoch 31, loss 0.11424250900745392, acc=0.9649723768234253, loss=0.11424250900745392
test: epoch 31, loss 2.5457305908203125, acc=0.45894455909729004, loss=2.5457305908203125
train: epoch 32, loss 0.10956855118274689, acc=0.9661916494369507, loss=0.10956855118274689
test: epoch 32, loss 2.562894105911255, acc=0.4196989834308624, loss=2.562894105911255
train: epoch 33, loss 0.11109103262424469, acc=0.9661573767662048, loss=0.11109103262424469
test: epoch 33, loss 2.273428201675415, acc=0.4574204683303833, loss=2.273428201675415
train: epoch 34, loss 0.10775940865278244, acc=0.9676814675331116, loss=0.10775940865278244
test: epoch 34, loss 2.2365493774414062, acc=0.47532862424850464, loss=2.2365493774414062
train: epoch 35, loss 0.10638093948364258, acc=0.9677576422691345, loss=0.10638093948364258
test: epoch 35, loss 2.341284990310669, acc=0.4522766172885895, loss=2.341284990310669
train: epoch 36, loss 0.10036876052618027, acc=0.9695408940315247, loss=0.10036876052618027
test: epoch 36, loss 2.2575900554656982, acc=0.5046675801277161, loss=2.2575900554656982
train: epoch 37, loss 0.09919743984937668, acc=0.9703410267829895, loss=0.09919743984937668
test: epoch 37, loss 1.8478171825408936, acc=0.508858859539032, loss=1.8478171825408936
train: epoch 38, loss 0.0985693410038948, acc=0.9709392189979553, loss=0.0985693410038948
test: epoch 38, loss 1.8906315565109253, acc=0.5212421417236328, loss=1.8906315565109253
train: epoch 39, loss 0.09604929387569427, acc=0.9719451069831848, loss=0.09604929387569427
test: epoch 39, loss 2.0586352348327637, acc=0.5096209049224854, loss=2.0586352348327637
train: epoch 40, loss 0.09588746726512909, acc=0.9722651839256287, loss=0.09588746726512909
test: epoch 40, loss 1.7947211265563965, acc=0.5351495742797852, loss=1.7947211265563965
train: epoch 41, loss 0.09057232737541199, acc=0.9733930230140686, loss=0.09057232737541199
test: epoch 41, loss 1.7446699142456055, acc=0.5648695230484009, loss=1.7446699142456055
train: epoch 42, loss 0.0922836884856224, acc=0.973229169845581, loss=0.0922836884856224
test: epoch 42, loss 1.7671197652816772, acc=0.5707753896713257, loss=1.7671197652816772
train: epoch 43, loss 0.08772993087768555, acc=0.9747685194015503, loss=0.08772993087768555
test: epoch 43, loss 1.8075060844421387, acc=0.5797294974327087, loss=1.8075060844421387
train: epoch 44, loss 0.08606810867786407, acc=0.9747799634933472, loss=0.08606810867786407
test: epoch 44, loss 1.704983115196228, acc=0.630024790763855, loss=1.704983115196228
train: epoch 45, loss 0.08333276957273483, acc=0.9760944843292236, loss=0.08333276957273483
test: epoch 45, loss 1.4960280656814575, acc=0.6433606147766113, loss=1.4960280656814575
train: epoch 46, loss 0.0854300856590271, acc=0.9759306311607361, loss=0.0854300856590271
test: epoch 46, loss 1.2247188091278076, acc=0.6725090742111206, loss=1.2247188091278076
train: epoch 47, loss 0.08210073411464691, acc=0.9767993688583374, loss=0.08210073411464691
test: epoch 47, loss 1.3297277688980103, acc=0.6641265153884888, loss=1.3297277688980103
train: epoch 48, loss 0.07986043393611908, acc=0.9774014353752136, loss=0.07986043393611908
test: epoch 48, loss 1.2393605709075928, acc=0.696894645690918, loss=1.2393605709075928
train: epoch 49, loss 0.07682530581951141, acc=0.9781748652458191, loss=0.07682530581951141
test: epoch 49, loss 1.25318443775177, acc=0.7189940810203552, loss=1.25318443775177
train: epoch 50, loss 0.07611856609582901, acc=0.9784759283065796, loss=0.07611856609582901
test: epoch 50, loss 1.0641160011291504, acc=0.7241379022598267, loss=1.0641160011291504
train: epoch 51, loss 0.07310134917497635, acc=0.9795541763305664, loss=0.07310134917497635
test: epoch 51, loss 0.8826528787612915, acc=0.7675747871398926, loss=0.8826528787612915
train: epoch 52, loss 0.07018140703439713, acc=0.9809221029281616, loss=0.07018140703439713
test: epoch 52, loss 0.8429340720176697, acc=0.7851019501686096, loss=0.8429340720176697
train: epoch 53, loss 0.0692509338259697, acc=0.9810554385185242, loss=0.0692509338259697
test: epoch 53, loss 0.7889384031295776, acc=0.8047246932983398, loss=0.7889384031295776
train: epoch 54, loss 0.06718867272138596, acc=0.9824919104576111, loss=0.06718867272138596
test: epoch 54, loss 0.6814590096473694, acc=0.8428272008895874, loss=0.6814590096473694
train: epoch 55, loss 0.06315630674362183, acc=0.9835549592971802, loss=0.06315630674362183
test: epoch 55, loss 0.5395035147666931, acc=0.8603543639183044, loss=0.5395035147666931
train: epoch 56, loss 0.06489614397287369, acc=0.9838597774505615, loss=0.06489614397287369
test: epoch 56, loss 0.5115513801574707, acc=0.9028386473655701, loss=0.5115513801574707
train: epoch 57, loss 0.06547777354717255, acc=0.9836845397949219, loss=0.06547777354717255
test: epoch 57, loss 0.4310266673564911, acc=0.8992189168930054, loss=0.4310266673564911
train: epoch 58, loss 0.060273051261901855, acc=0.985120952129364, loss=0.060273051261901855
test: epoch 58, loss 0.3042409420013428, acc=0.9268432259559631, loss=0.3042409420013428
train: epoch 59, loss 0.05691935122013092, acc=0.9865536093711853, loss=0.05691935122013092
test: epoch 59, loss 0.3321416676044464, acc=0.9506572484970093, loss=0.3321416676044464
train: epoch 60, loss 0.05180833488702774, acc=0.9875900149345398, loss=0.05180833488702774
test: epoch 60, loss 0.2698914408683777, acc=0.9397980570793152, loss=0.2698914408683777
train: epoch 61, loss 0.04705100879073143, acc=0.9884358644485474, loss=0.04705100879073143
test: epoch 61, loss 0.16029426455497742, acc=0.9681844115257263, loss=0.16029426455497742
train: epoch 62, loss 0.051842302083969116, acc=0.9880891442298889, loss=0.051842302083969116
test: epoch 62, loss 0.15375849604606628, acc=0.9698989987373352, loss=0.15375849604606628
train: epoch 63, loss 0.04626103490591049, acc=0.9892665147781372, loss=0.04626103490591049
test: epoch 63, loss 0.19590821862220764, acc=0.9681844115257263, loss=0.19590821862220764
train: epoch 64, loss 0.04397718980908394, acc=0.9901581406593323, loss=0.04397718980908394
test: epoch 64, loss 0.07303027808666229, acc=0.9822823405265808, loss=0.07303027808666229
train: epoch 65, loss 0.04958431050181389, acc=0.9893884658813477, loss=0.04958431050181389
test: epoch 65, loss 0.09576060622930527, acc=0.9733282327651978, loss=0.09576060622930527
train: epoch 66, loss 0.04276502877473831, acc=0.9909316301345825, loss=0.04276502877473831
test: epoch 66, loss 0.06099916994571686, acc=0.9874261617660522, loss=0.06099916994571686
train: epoch 67, loss 0.04181987792253494, acc=0.9913545250892639, loss=0.04181987792253494
test: epoch 67, loss 0.07024383544921875, acc=0.9876167178153992, loss=0.07024383544921875
train: epoch 68, loss 0.03638017550110817, acc=0.9925890564918518, loss=0.03638017550110817
test: epoch 68, loss 0.048052530735731125, acc=0.9910458922386169, loss=0.048052530735731125
