# ["--N=20", "--n_epochs=250", "--batch_size=32", "--lr=0.001", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=1", "--n_layers=3", "--save_run=1", "--n_symbols=82"]
Namespace(n_summands=2, N=20, test_split=0.1, data_scaling=50, one_hot=True, receiver_embed_dim=64, n_layers=3, n_symbols=82, temperature=2.0, temp_decay=0.995, early_stopping_acc=0.99, n_runs=1, save_run=True, random_seed=341223678, checkpoint_dir=None, preemptable=False, checkpoint_freq=0, validation_freq=1, n_epochs=250, load_from_checkpoint=None, no_cuda=True, batch_size=32, optimizer='adam', lr=0.001, update_freq=1, vocab_size=10, max_len=1, tensorboard=False, tensorboard_dir='runs/', distributed_port=18363, fp16=False, cuda=False, device=device(type='cpu'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'))
train: epoch 1, loss 2.84162974357605, acc=0.08947103470563889, loss=2.84162974357605
test: epoch 1, loss 4.779159069061279, acc=0.07808564603328705, loss=4.779159069061279
train: epoch 2, loss 1.8567479848861694, acc=0.22664988040924072, loss=1.8567479848861694
test: epoch 2, loss 3.7750542163848877, acc=0.14861461520195007, loss=3.7750542163848877
train: epoch 3, loss 1.5079565048217773, acc=0.3494710326194763, loss=1.5079565048217773
test: epoch 3, loss 4.329776287078857, acc=0.125944584608078, loss=4.329776287078857
train: epoch 4, loss 1.1020913124084473, acc=0.5309823751449585, loss=1.1020913124084473
test: epoch 4, loss 2.9231326580047607, acc=0.23425692319869995, loss=2.9231326580047607
train: epoch 5, loss 0.8399102091789246, acc=0.6550126075744629, loss=0.8399102091789246
test: epoch 5, loss 3.167591094970703, acc=0.24181360006332397, loss=3.167591094970703
train: epoch 6, loss 0.6668076515197754, acc=0.7349622249603271, loss=0.6668076515197754
test: epoch 6, loss 3.1984877586364746, acc=0.27204030752182007, loss=3.1984877586364746
train: epoch 7, loss 0.5365644097328186, acc=0.7917380332946777, loss=0.5365644097328186
test: epoch 7, loss 2.745558500289917, acc=0.249370276927948, loss=2.745558500289917
train: epoch 8, loss 0.46308597922325134, acc=0.8271536231040955, loss=0.46308597922325134
test: epoch 8, loss 3.188840627670288, acc=0.29722923040390015, loss=3.188840627670288
train: epoch 9, loss 0.4085855185985565, acc=0.8480604290962219, loss=0.4085855185985565
test: epoch 9, loss 2.550502300262451, acc=0.3173803389072418, loss=2.550502300262451
train: epoch 10, loss 0.339566171169281, acc=0.8756675124168396, loss=0.339566171169281
test: epoch 10, loss 2.750875473022461, acc=0.29219144582748413, loss=2.750875473022461
train: epoch 11, loss 0.3231099545955658, acc=0.8833752870559692, loss=0.3231099545955658
test: epoch 11, loss 2.2513203620910645, acc=0.35264483094215393, loss=2.2513203620910645
train: epoch 12, loss 0.2879805564880371, acc=0.8979848623275757, loss=0.2879805564880371
test: epoch 12, loss 2.2589104175567627, acc=0.3400503695011139, loss=2.2589104175567627
train: epoch 13, loss 0.2415449321269989, acc=0.9169269800186157, loss=0.2415449321269989
test: epoch 13, loss 2.4052915573120117, acc=0.375314861536026, loss=2.4052915573120117
train: epoch 14, loss 0.24019382894039154, acc=0.9175314903259277, loss=0.24019382894039154
test: epoch 14, loss 2.009650707244873, acc=0.37027707695961, loss=2.009650707244873
train: epoch 15, loss 0.2302047312259674, acc=0.9230226874351501, loss=0.2302047312259674
test: epoch 15, loss 2.726710081100464, acc=0.3425692617893219, loss=2.726710081100464
train: epoch 16, loss 0.20171675086021423, acc=0.9342065453529358, loss=0.20171675086021423
test: epoch 16, loss 2.3886325359344482, acc=0.4357682764530182, loss=2.3886325359344482
train: epoch 17, loss 0.19811975955963135, acc=0.9331989884376526, loss=0.19811975955963135
test: epoch 17, loss 2.338404893875122, acc=0.367758184671402, loss=2.338404893875122
train: epoch 18, loss 0.20139552652835846, acc=0.9317883849143982, loss=0.20139552652835846
test: epoch 18, loss 1.73855721950531, acc=0.4130982458591461, loss=1.73855721950531
train: epoch 19, loss 0.16155406832695007, acc=0.9463979601860046, loss=0.16155406832695007
test: epoch 19, loss 2.227125406265259, acc=0.4357682764530182, loss=2.227125406265259
train: epoch 20, loss 0.17567653954029083, acc=0.940856397151947, loss=0.17567653954029083
test: epoch 20, loss 2.0220041275024414, acc=0.44836270809173584, loss=2.0220041275024414
train: epoch 21, loss 0.15972721576690674, acc=0.946851372718811, loss=0.15972721576690674
test: epoch 21, loss 2.3489575386047363, acc=0.42821159958839417, loss=2.3489575386047363
train: epoch 22, loss 0.14831607043743134, acc=0.9496221542358398, loss=0.14831607043743134
test: epoch 22, loss 3.049837589263916, acc=0.4055415689945221, loss=3.049837589263916
train: epoch 23, loss 0.15872128307819366, acc=0.9486145973205566, loss=0.15872128307819366
test: epoch 23, loss 1.9219746589660645, acc=0.38539043068885803, loss=1.9219746589660645
train: epoch 24, loss 0.1357763707637787, acc=0.9545088410377502, loss=0.1357763707637787
test: epoch 24, loss 2.204712152481079, acc=0.4357682764530182, loss=2.204712152481079
train: epoch 25, loss 0.1535881757736206, acc=0.9492695331573486, loss=0.1535881757736206
test: epoch 25, loss 2.473987340927124, acc=0.42317381501197815, loss=2.473987340927124
train: epoch 26, loss 0.12435790151357651, acc=0.9596977233886719, loss=0.12435790151357651
test: epoch 26, loss 2.5993592739105225, acc=0.35768261551856995, loss=2.5993592739105225
train: epoch 27, loss 0.1298566609621048, acc=0.9561712741851807, loss=0.1298566609621048
test: epoch 27, loss 2.397003173828125, acc=0.45088160037994385, loss=2.397003173828125
train: epoch 28, loss 0.11880436539649963, acc=0.9616121053695679, loss=0.11880436539649963
test: epoch 28, loss 1.9036211967468262, acc=0.5264483690261841, loss=1.9036211967468262
train: epoch 29, loss 0.12012195587158203, acc=0.9610075354576111, loss=0.12012195587158203
test: epoch 29, loss 2.453775405883789, acc=0.4710327386856079, loss=2.453775405883789
train: epoch 30, loss 0.13137459754943848, acc=0.9555163979530334, loss=0.13137459754943848
test: epoch 30, loss 1.992120623588562, acc=0.4634760618209839, loss=1.992120623588562
train: epoch 31, loss 0.106749527156353, acc=0.9647858738899231, loss=0.106749527156353
test: epoch 31, loss 2.3475420475006104, acc=0.39798489212989807, loss=2.3475420475006104
train: epoch 32, loss 0.11480453610420227, acc=0.9621158838272095, loss=0.11480453610420227
test: epoch 32, loss 2.557180166244507, acc=0.42821159958839417, loss=2.557180166244507
train: epoch 33, loss 0.12419707328081131, acc=0.9612594246864319, loss=0.12419707328081131
test: epoch 33, loss 2.2409887313842773, acc=0.4609571695327759, loss=2.2409887313842773
train: epoch 34, loss 0.10976427048444748, acc=0.9642317295074463, loss=0.10976427048444748
test: epoch 34, loss 2.0572891235351562, acc=0.45843827724456787, loss=2.0572891235351562
train: epoch 35, loss 0.10662490129470825, acc=0.9659949541091919, loss=0.10662490129470825
test: epoch 35, loss 2.0269837379455566, acc=0.4710327386856079, loss=2.0269837379455566
train: epoch 36, loss 0.10780764371156693, acc=0.9653400778770447, loss=0.10780764371156693
test: epoch 36, loss 1.9570024013519287, acc=0.513853907585144, loss=1.9570024013519287
train: epoch 37, loss 0.09959721565246582, acc=0.9680604338645935, loss=0.09959721565246582
test: epoch 37, loss 1.9030048847198486, acc=0.516372799873352, loss=1.9030048847198486
train: epoch 38, loss 0.10722558945417404, acc=0.9659949541091919, loss=0.10722558945417404
test: epoch 38, loss 2.031367540359497, acc=0.45088160037994385, loss=2.031367540359497
train: epoch 39, loss 0.1088494062423706, acc=0.9649370312690735, loss=0.1088494062423706
test: epoch 39, loss 1.6240955591201782, acc=0.49370276927948, loss=1.6240955591201782
train: epoch 40, loss 0.0996033176779747, acc=0.9681612253189087, loss=0.0996033176779747
test: epoch 40, loss 1.8811310529708862, acc=0.5793451070785522, loss=1.8811310529708862
train: epoch 41, loss 0.0961778312921524, acc=0.9697229266166687, loss=0.0961778312921524
test: epoch 41, loss 1.669485092163086, acc=0.48110830783843994, loss=1.669485092163086
train: epoch 42, loss 0.09708115458488464, acc=0.9698740839958191, loss=0.09708115458488464
test: epoch 42, loss 1.9705321788787842, acc=0.47858941555023193, loss=1.9705321788787842
train: epoch 43, loss 0.09928171336650848, acc=0.9677581787109375, loss=0.09928171336650848
test: epoch 43, loss 1.9918763637542725, acc=0.508816123008728, loss=1.9918763637542725
train: epoch 44, loss 0.09528013318777084, acc=0.9694206714630127, loss=0.09528013318777084
test: epoch 44, loss 1.7554714679718018, acc=0.5188916921615601, loss=1.7554714679718018
train: epoch 45, loss 0.09267833083868027, acc=0.9707808494567871, loss=0.09267833083868027
test: epoch 45, loss 2.2586896419525146, acc=0.45591938495635986, loss=2.2586896419525146
train: epoch 46, loss 0.0910620242357254, acc=0.9712846279144287, loss=0.0910620242357254
test: epoch 46, loss 1.6503995656967163, acc=0.5919395685195923, loss=1.6503995656967163
train: epoch 47, loss 0.10245709121227264, acc=0.9672544002532959, loss=0.10245709121227264
test: epoch 47, loss 2.1929240226745605, acc=0.48362720012664795, loss=2.1929240226745605
train: epoch 48, loss 0.09186618775129318, acc=0.9706297516822815, loss=0.09186618775129318
test: epoch 48, loss 1.8321194648742676, acc=0.6020151376724243, loss=1.8321194648742676
train: epoch 49, loss 0.08789259940385818, acc=0.9738035202026367, loss=0.08789259940385818
test: epoch 49, loss 1.7682570219039917, acc=0.5365239381790161, loss=1.7682570219039917
train: epoch 50, loss 0.09168840944766998, acc=0.9715365171432495, loss=0.09168840944766998
test: epoch 50, loss 1.5282323360443115, acc=0.5869017839431763, loss=1.5282323360443115
train: epoch 51, loss 0.08594139665365219, acc=0.9730982184410095, loss=0.08594139665365219
test: epoch 51, loss 1.2863283157348633, acc=0.6272040009498596, loss=1.2863283157348633
train: epoch 52, loss 0.08144375681877136, acc=0.9749622344970703, loss=0.08144375681877136
test: epoch 52, loss 1.6446441411972046, acc=0.6095718145370483, loss=1.6446441411972046
train: epoch 53, loss 0.08775462210178375, acc=0.9721410870552063, loss=0.08775462210178375
test: epoch 53, loss 1.1790870428085327, acc=0.6272040009498596, loss=1.1790870428085327
train: epoch 54, loss 0.08995023369789124, acc=0.9732997417449951, loss=0.08995023369789124
test: epoch 54, loss 1.3305879831314087, acc=0.6624684929847717, loss=1.3305879831314087
train: epoch 55, loss 0.0790223553776741, acc=0.9754155874252319, loss=0.0790223553776741
test: epoch 55, loss 1.5674610137939453, acc=0.5793451070785522, loss=1.5674610137939453
train: epoch 56, loss 0.09026247262954712, acc=0.9725440740585327, loss=0.09026247262954712
test: epoch 56, loss 1.0446860790252686, acc=0.6775818467140198, loss=1.0446860790252686
train: epoch 57, loss 0.07295460999011993, acc=0.9782367944717407, loss=0.07295460999011993
test: epoch 57, loss 1.1023954153060913, acc=0.6624684929847717, loss=1.1023954153060913
train: epoch 58, loss 0.07870180904865265, acc=0.9762720465660095, loss=0.07870180904865265
test: epoch 58, loss 1.8000932931900024, acc=0.6397984623908997, loss=1.8000932931900024
train: epoch 59, loss 0.08047908544540405, acc=0.9754155874252319, loss=0.08047908544540405
test: epoch 59, loss 1.294888973236084, acc=0.5919395685195923, loss=1.294888973236084
train: epoch 60, loss 0.08837946504354477, acc=0.9719395637512207, loss=0.08837946504354477
test: epoch 60, loss 1.3258731365203857, acc=0.6372795701026917, loss=1.3258731365203857
train: epoch 61, loss 0.06767131388187408, acc=0.9786397814750671, loss=0.06767131388187408
test: epoch 61, loss 1.3226057291030884, acc=0.6574307084083557, loss=1.3226057291030884
train: epoch 62, loss 0.07479798793792725, acc=0.9776322245597839, loss=0.07479798793792725
test: epoch 62, loss 1.1868796348571777, acc=0.6926952004432678, loss=1.1868796348571777
train: epoch 63, loss 0.06791859120130539, acc=0.980453372001648, loss=0.06791859120130539
test: epoch 63, loss 1.0727031230926514, acc=0.6952140927314758, loss=1.0727031230926514
train: epoch 64, loss 0.06501691043376923, acc=0.9811083078384399, loss=0.06501691043376923
test: epoch 64, loss 1.1910494565963745, acc=0.6876574158668518, loss=1.1910494565963745
train: epoch 65, loss 0.07691091299057007, acc=0.9774307012557983, loss=0.07691091299057007
test: epoch 65, loss 1.2199655771255493, acc=0.743073046207428, loss=1.2199655771255493
train: epoch 66, loss 0.069102942943573, acc=0.9796473383903503, loss=0.069102942943573
test: epoch 66, loss 1.1619277000427246, acc=0.6649873852729797, loss=1.1619277000427246
train: epoch 67, loss 0.07915195822715759, acc=0.9773803353309631, loss=0.07915195822715759
test: epoch 67, loss 0.9133934378623962, acc=0.7103274464607239, loss=0.9133934378623962
train: epoch 68, loss 0.06837538629770279, acc=0.9797984957695007, loss=0.06837538629770279
test: epoch 68, loss 0.7944539785385132, acc=0.7682619690895081, loss=0.7944539785385132
train: epoch 69, loss 0.06621663272380829, acc=0.9803526401519775, loss=0.06621663272380829
test: epoch 69, loss 0.8369238376617432, acc=0.75314861536026, loss=0.8369238376617432
train: epoch 70, loss 0.060641203075647354, acc=0.9816120862960815, loss=0.060641203075647354
test: epoch 70, loss 0.6989741325378418, acc=0.7934508919715881, loss=0.6989741325378418
train: epoch 71, loss 0.06777051836252213, acc=0.9805037975311279, loss=0.06777051836252213
test: epoch 71, loss 0.8501647710800171, acc=0.75314861536026, loss=0.8501647710800171
train: epoch 72, loss 0.05759158357977867, acc=0.9828211665153503, loss=0.05759158357977867
test: epoch 72, loss 0.5856848359107971, acc=0.8161209225654602, loss=0.5856848359107971
train: epoch 73, loss 0.058748211711645126, acc=0.9834760427474976, loss=0.058748211711645126
test: epoch 73, loss 0.5163682103157043, acc=0.8513854146003723, loss=0.5163682103157043
train: epoch 74, loss 0.05645613744854927, acc=0.9830226898193359, loss=0.05645613744854927
test: epoch 74, loss 0.6576787233352661, acc=0.8337531685829163, loss=0.6576787233352661
train: epoch 75, loss 0.04810372367501259, acc=0.9850881695747375, loss=0.04810372367501259
test: epoch 75, loss 0.4022749960422516, acc=0.8614609837532043, loss=0.4022749960422516
train: epoch 76, loss 0.0557686872780323, acc=0.9841309785842896, loss=0.0557686872780323
test: epoch 76, loss 0.6660552620887756, acc=0.8539043068885803, loss=0.6660552620887756
train: epoch 77, loss 0.06053069606423378, acc=0.9831234216690063, loss=0.06053069606423378
test: epoch 77, loss 0.395643413066864, acc=0.8942065238952637, loss=0.395643413066864
train: epoch 78, loss 0.04880585893988609, acc=0.9851385354995728, loss=0.04880585893988609
test: epoch 78, loss 0.2601407468318939, acc=0.9193954467773438, loss=0.2601407468318939
train: epoch 79, loss 0.04775479808449745, acc=0.985491156578064, loss=0.04775479808449745
test: epoch 79, loss 0.49453499913215637, acc=0.8916876316070557, loss=0.49453499913215637
train: epoch 80, loss 0.046371940523386, acc=0.9877581596374512, loss=0.046371940523386
test: epoch 80, loss 0.3739204704761505, acc=0.9294710159301758, loss=0.3739204704761505
train: epoch 81, loss 0.040273699909448624, acc=0.989319920539856, loss=0.040273699909448624
test: epoch 81, loss 0.3325393497943878, acc=0.9445843696594238, loss=0.3325393497943878
train: epoch 82, loss 0.03906567022204399, acc=0.9893702864646912, loss=0.03906567022204399
test: epoch 82, loss 0.26192668080329895, acc=0.9420654773712158, loss=0.26192668080329895
train: epoch 83, loss 0.047532204538583755, acc=0.9866498708724976, loss=0.047532204538583755
test: epoch 83, loss 0.1893579065799713, acc=0.9647355079650879, loss=0.1893579065799713
train: epoch 84, loss 0.034432508051395416, acc=0.9908312559127808, loss=0.034432508051395416
test: epoch 84, loss 0.16609804332256317, acc=0.9596977233886719, loss=0.16609804332256317
train: epoch 85, loss 0.029559090733528137, acc=0.9922921657562256, loss=0.029559090733528137
test: epoch 85, loss 0.2248711884021759, acc=0.9596977233886719, loss=0.2248711884021759
train: epoch 86, loss 0.03692246600985527, acc=0.989622175693512, loss=0.03692246600985527
test: epoch 86, loss 0.18818245828151703, acc=0.9622166156768799, loss=0.18818245828151703
train: epoch 87, loss 0.030566303059458733, acc=0.991838812828064, loss=0.030566303059458733
test: epoch 87, loss 0.19789016246795654, acc=0.9622166156768799, loss=0.19789016246795654
train: epoch 88, loss 0.029534878209233284, acc=0.9921914339065552, loss=0.029534878209233284
test: epoch 88, loss 0.10572262108325958, acc=0.9647355079650879, loss=0.10572262108325958
train: epoch 89, loss 0.02659718506038189, acc=0.9929974675178528, loss=0.02659718506038189
test: epoch 89, loss 0.08709452301263809, acc=0.9798488616943359, loss=0.08709452301263809
train: epoch 90, loss 0.0221323873847723, acc=0.9942569136619568, loss=0.0221323873847723
test: epoch 90, loss 0.08305053412914276, acc=0.9748110771179199, loss=0.08305053412914276
train: epoch 91, loss 0.0217580609023571, acc=0.9926448464393616, loss=0.0217580609023571
test: epoch 91, loss 0.060515426099300385, acc=0.9748110771179199, loss=0.060515426099300385
train: epoch 92, loss 0.022143976762890816, acc=0.9940553903579712, loss=0.022143976762890816
test: epoch 92, loss 0.058645524084568024, acc=0.9798488616943359, loss=0.058645524084568024
train: epoch 93, loss 0.031597528606653214, acc=0.9928967356681824, loss=0.031597528606653214
test: epoch 93, loss 0.06904676556587219, acc=0.9722921848297119, loss=0.06904676556587219
train: epoch 94, loss 0.022599969059228897, acc=0.9944080710411072, loss=0.022599969059228897
test: epoch 94, loss 0.06248924881219864, acc=0.984886646270752, loss=0.06248924881219864
train: epoch 95, loss 0.022193023934960365, acc=0.9940553903579712, loss=0.022193023934960365
test: epoch 95, loss 0.03371046110987663, acc=0.984886646270752, loss=0.03371046110987663
train: epoch 96, loss 0.018129799515008926, acc=0.9958186149597168, loss=0.018129799515008926
test: epoch 96, loss 0.05513272434473038, acc=0.982367753982544, loss=0.05513272434473038
train: epoch 97, loss 0.01200835406780243, acc=0.9960705041885376, loss=0.01200835406780243
test: epoch 97, loss 0.020566973835229874, acc=0.98740553855896, loss=0.020566973835229874
train: epoch 98, loss 0.028745096176862717, acc=0.9931486248970032, loss=0.028745096176862717
test: epoch 98, loss 0.04792215675115585, acc=0.984886646270752, loss=0.04792215675115585
train: epoch 99, loss 0.020871315151453018, acc=0.9949118494987488, loss=0.020871315151453018
test: epoch 99, loss 0.051170021295547485, acc=0.984886646270752, loss=0.051170021295547485
train: epoch 100, loss 0.013650511391460896, acc=0.9964735507965088, loss=0.013650511391460896
test: epoch 100, loss 0.049124740064144135, acc=0.984886646270752, loss=0.049124740064144135
train: epoch 101, loss 0.016839798539876938, acc=0.9957178831100464, loss=0.016839798539876938
test: epoch 101, loss 0.07092516869306564, acc=0.984886646270752, loss=0.07092516869306564
train: epoch 102, loss 0.012986736372113228, acc=0.99687659740448, loss=0.012986736372113228
test: epoch 102, loss 0.03715589642524719, acc=0.984886646270752, loss=0.03715589642524719
train: epoch 103, loss 0.016224894672632217, acc=0.9961209297180176, loss=0.016224894672632217
test: epoch 103, loss 0.05349813029170036, acc=0.984886646270752, loss=0.05349813029170036
train: epoch 104, loss 0.013220592401921749, acc=0.9967758059501648, loss=0.013220592401921749
test: epoch 104, loss 0.050081487745046616, acc=0.984886646270752, loss=0.050081487745046616
train: epoch 105, loss 0.009422041475772858, acc=0.9979848861694336, loss=0.009422041475772858
test: epoch 105, loss 0.03799409419298172, acc=0.992443323135376, loss=0.03799409419298172
