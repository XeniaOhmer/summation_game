# ["--N=40", "--n_epochs=250", "--batch_size=32", "--lr=0.001", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=1", "--n_layers=3", "--save_run=1", "--n_symbols=81"]
Namespace(n_summands=2, N=40, test_split=0.1, data_scaling=50, one_hot=True, receiver_embed_dim=64, n_layers=3, n_symbols=81, temperature=2.0, temp_decay=0.995, early_stopping_acc=0.99, n_runs=1, save_run=True, random_seed=105666326, checkpoint_dir=None, preemptable=False, checkpoint_freq=0, validation_freq=1, n_epochs=250, load_from_checkpoint=None, no_cuda=True, batch_size=32, optimizer='adam', lr=0.001, update_freq=1, vocab_size=10, max_len=1, tensorboard=False, tensorboard_dir='runs/', distributed_port=18363, fp16=False, cuda=False, device=device(type='cpu'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'))
train: epoch 1, loss 2.699941873550415, acc=0.13551883399486542, loss=2.699941873550415
test: epoch 1, loss 4.242722034454346, acc=0.09451421350240707, loss=4.242722034454346
train: epoch 2, loss 1.4849706888198853, acc=0.37438201904296875, loss=1.4849706888198853
test: epoch 2, loss 3.0851964950561523, acc=0.14606741070747375, loss=3.0851964950561523
train: epoch 3, loss 1.1788469552993774, acc=0.48619961738586426, loss=1.1788469552993774
test: epoch 3, loss 3.2020206451416016, acc=0.19762061536312103, loss=3.2020206451416016
train: epoch 4, loss 0.9685238003730774, acc=0.5827627182006836, loss=0.9685238003730774
test: epoch 4, loss 3.883270740509033, acc=0.1487111747264862, loss=3.883270740509033
train: epoch 5, loss 0.7854390740394592, acc=0.6721348166465759, loss=0.7854390740394592
test: epoch 5, loss 3.5458827018737793, acc=0.17580965161323547, loss=3.5458827018737793
train: epoch 6, loss 0.738325834274292, acc=0.6914739012718201, loss=0.738325834274292
test: epoch 6, loss 3.216102123260498, acc=0.21810971200466156, loss=3.216102123260498
train: epoch 7, loss 0.6913123726844788, acc=0.7149768471717834, loss=0.6913123726844788
test: epoch 7, loss 3.5359947681427, acc=0.20290812849998474, loss=3.5359947681427
train: epoch 8, loss 0.7244535088539124, acc=0.6941969394683838, loss=0.7244535088539124
test: epoch 8, loss 3.1481502056121826, acc=0.20026437938213348, loss=3.1481502056121826
train: epoch 9, loss 0.6172705292701721, acc=0.7439788579940796, loss=0.6172705292701721
test: epoch 9, loss 3.2952423095703125, acc=0.23661600053310394, loss=3.2952423095703125
train: epoch 10, loss 0.5051173567771912, acc=0.7964838147163391, loss=0.5051173567771912
test: epoch 10, loss 2.830233573913574, acc=0.2339722365140915, loss=2.830233573913574
train: epoch 11, loss 0.46099913120269775, acc=0.8155320286750793, loss=0.46099913120269775
test: epoch 11, loss 3.0221290588378906, acc=0.2815598249435425, loss=3.0221290588378906
train: epoch 12, loss 0.4180258512496948, acc=0.8357700109481812, loss=0.4180258512496948
test: epoch 12, loss 2.754359006881714, acc=0.26635822653770447, loss=2.754359006881714
train: epoch 13, loss 0.3793925642967224, acc=0.8535757064819336, loss=0.3793925642967224
test: epoch 13, loss 2.6695261001586914, acc=0.3000660836696625, loss=2.6695261001586914
train: epoch 14, loss 0.36049479246139526, acc=0.8629874587059021, loss=0.36049479246139526
test: epoch 14, loss 2.657813549041748, acc=0.3060145378112793, loss=2.657813549041748
train: epoch 15, loss 0.33210864663124084, acc=0.8749107718467712, loss=0.33210864663124084
test: epoch 15, loss 2.7604520320892334, acc=0.30403172969818115, loss=2.7604520320892334
train: epoch 16, loss 0.34025904536247253, acc=0.8731791377067566, loss=0.34025904536247253
test: epoch 16, loss 3.311706066131592, acc=0.27098479866981506, loss=3.311706066131592
train: epoch 17, loss 0.35286369919776917, acc=0.8641507029533386, loss=0.35286369919776917
test: epoch 17, loss 2.5784387588500977, acc=0.3245208263397217, loss=2.5784387588500977
train: epoch 18, loss 0.3559282720088959, acc=0.8630931973457336, loss=0.3559282720088959
test: epoch 18, loss 2.734527349472046, acc=0.30931922793388367, loss=2.734527349472046
train: epoch 19, loss 0.30778810381889343, acc=0.8838995099067688, loss=0.30778810381889343
test: epoch 19, loss 2.6821835041046143, acc=0.31725049018859863, loss=2.6821835041046143
train: epoch 20, loss 0.26532578468322754, acc=0.9020357131958008, loss=0.26532578468322754
test: epoch 20, loss 2.554433584213257, acc=0.3119629919528961, loss=2.554433584213257
train: epoch 21, loss 0.24596871435642242, acc=0.9105750322341919, loss=0.24596871435642242
test: epoch 21, loss 3.038135051727295, acc=0.33377397060394287, loss=3.038135051727295
train: epoch 22, loss 0.24170631170272827, acc=0.9133906364440918, loss=0.24170631170272827
test: epoch 22, loss 2.680070400238037, acc=0.3298083245754242, loss=2.680070400238037
train: epoch 23, loss 0.2228223979473114, acc=0.9200792908668518, loss=0.2228223979473114
test: epoch 23, loss 2.9468724727630615, acc=0.3628552556037903, loss=2.9468724727630615
train: epoch 24, loss 0.22129270434379578, acc=0.9211896657943726, loss=0.22129270434379578
test: epoch 24, loss 2.8573062419891357, acc=0.32319894433021545, loss=2.8573062419891357
train: epoch 25, loss 0.20747020840644836, acc=0.9267812371253967, loss=0.20747020840644836
test: epoch 25, loss 2.4693357944488525, acc=0.37475213408470154, loss=2.4693357944488525
train: epoch 26, loss 0.19751714169979095, acc=0.9307600855827332, loss=0.19751714169979095
test: epoch 26, loss 2.8331403732299805, acc=0.3245208263397217, loss=2.8331403732299805
train: epoch 27, loss 0.19884391129016876, acc=0.9316986203193665, loss=0.19884391129016876
test: epoch 27, loss 2.5368130207061768, acc=0.3721083998680115, loss=2.5368130207061768
train: epoch 28, loss 0.1945732980966568, acc=0.932161271572113, loss=0.1945732980966568
test: epoch 28, loss 2.6246442794799805, acc=0.34699273109436035, loss=2.6246442794799805
train: epoch 29, loss 0.1893819123506546, acc=0.9334699511528015, loss=0.1893819123506546
test: epoch 29, loss 2.738941192626953, acc=0.37673497200012207, loss=2.738941192626953
train: epoch 30, loss 0.18286538124084473, acc=0.9367613792419434, loss=0.18286538124084473
test: epoch 30, loss 2.700080394744873, acc=0.36615994572639465, loss=2.700080394744873
train: epoch 31, loss 0.17697003483772278, acc=0.9392861723899841, loss=0.17697003483772278
test: epoch 31, loss 2.647101640701294, acc=0.37144744396209717, loss=2.647101640701294
train: epoch 32, loss 0.17764601111412048, acc=0.939272940158844, loss=0.17764601111412048
test: epoch 32, loss 2.538883686065674, acc=0.37475213408470154, loss=2.538883686065674
train: epoch 33, loss 0.17273615300655365, acc=0.9418506026268005, loss=0.17273615300655365
test: epoch 33, loss 2.294398784637451, acc=0.4117647111415863, loss=2.294398784637451
train: epoch 34, loss 0.16568635404109955, acc=0.9442300200462341, loss=0.16568635404109955
test: epoch 34, loss 2.872138023376465, acc=0.3826833963394165, loss=2.872138023376465
train: epoch 35, loss 0.16062109172344208, acc=0.946688711643219, loss=0.16062109172344208
test: epoch 35, loss 2.8744213581085205, acc=0.38070058822631836, loss=2.8744213581085205
train: epoch 36, loss 0.15550245344638824, acc=0.9471909999847412, loss=0.15550245344638824
test: epoch 36, loss 2.684462785720825, acc=0.3978849947452545, loss=2.684462785720825
train: epoch 37, loss 0.15408146381378174, acc=0.9492399096488953, loss=0.15408146381378174
test: epoch 37, loss 3.1037938594818115, acc=0.3939193785190582, loss=3.1037938594818115
train: epoch 38, loss 0.14988230168819427, acc=0.951407790184021, loss=0.14988230168819427
test: epoch 38, loss 2.6208677291870117, acc=0.4018506407737732, loss=2.6208677291870117
train: epoch 39, loss 0.14214211702346802, acc=0.9541969299316406, loss=0.14214211702346802
test: epoch 39, loss 2.5159199237823486, acc=0.39920687675476074, loss=2.5159199237823486
train: epoch 40, loss 0.13948675990104675, acc=0.9537475109100342, loss=0.13948675990104675
test: epoch 40, loss 2.4500606060028076, acc=0.3787177801132202, loss=2.4500606060028076
train: epoch 41, loss 0.13877227902412415, acc=0.9548182487487793, loss=0.13877227902412415
test: epoch 41, loss 2.4985413551330566, acc=0.4216787815093994, loss=2.4985413551330566
train: epoch 42, loss 0.1338418424129486, acc=0.9572240710258484, loss=0.1338418424129486
test: epoch 42, loss 2.514817714691162, acc=0.40912094712257385, loss=2.514817714691162
train: epoch 43, loss 0.13583479821681976, acc=0.9562855362892151, loss=0.13583479821681976
test: epoch 43, loss 2.412476062774658, acc=0.40846002101898193, loss=2.412476062774658
train: epoch 44, loss 0.12530286610126495, acc=0.9599868059158325, loss=0.12530286610126495
test: epoch 44, loss 2.4429702758789062, acc=0.4454725682735443, loss=2.4429702758789062
train: epoch 45, loss 0.13207906484603882, acc=0.9578453302383423, loss=0.13207906484603882
test: epoch 45, loss 2.3777387142181396, acc=0.41308659315109253, loss=2.3777387142181396
train: epoch 46, loss 0.1275501400232315, acc=0.9587442278862, loss=0.1275501400232315
test: epoch 46, loss 2.4406590461730957, acc=0.4296100437641144, loss=2.4406590461730957
train: epoch 47, loss 0.12360832095146179, acc=0.9603701233863831, loss=0.12360832095146179
test: epoch 47, loss 2.314023017883301, acc=0.449438214302063, loss=2.314023017883301
train: epoch 48, loss 0.12014460563659668, acc=0.9618241786956787, loss=0.12014460563659668
test: epoch 48, loss 2.6283199787139893, acc=0.4368803799152374, loss=2.6283199787139893
train: epoch 49, loss 0.12215165793895721, acc=0.9615862369537354, loss=0.12215165793895721
test: epoch 49, loss 2.355952024459839, acc=0.42828816175460815, loss=2.355952024459839
train: epoch 50, loss 0.11815988272428513, acc=0.9619563817977905, loss=0.11815988272428513
test: epoch 50, loss 2.380715847015381, acc=0.42696627974510193, loss=2.380715847015381
train: epoch 51, loss 0.11425469070672989, acc=0.963463306427002, loss=0.11425469070672989
test: epoch 51, loss 2.6091268062591553, acc=0.43886318802833557, loss=2.6091268062591553
train: epoch 52, loss 0.1195848286151886, acc=0.9620357155799866, loss=0.1195848286151886
test: epoch 52, loss 2.1479434967041016, acc=0.44679445028305054, loss=2.1479434967041016
train: epoch 53, loss 0.11713650077581406, acc=0.962762713432312, loss=0.11713650077581406
test: epoch 53, loss 2.104140043258667, acc=0.4580304026603699, loss=2.104140043258667
train: epoch 54, loss 0.10984210669994354, acc=0.9649173617362976, loss=0.10984210669994354
test: epoch 54, loss 2.4473307132720947, acc=0.4454725682735443, loss=2.4473307132720947
train: epoch 55, loss 0.11290740966796875, acc=0.9654989838600159, loss=0.11290740966796875
test: epoch 55, loss 2.4284939765930176, acc=0.4025115668773651, loss=2.4284939765930176
train: epoch 56, loss 0.1141904667019844, acc=0.9635822772979736, loss=0.1141904667019844
test: epoch 56, loss 1.9923468828201294, acc=0.4771976172924042, loss=1.9923468828201294
train: epoch 57, loss 0.10898234695196152, acc=0.9658162593841553, loss=0.10898234695196152
test: epoch 57, loss 1.86517333984375, acc=0.4553866386413574, loss=1.86517333984375
train: epoch 58, loss 0.10577603429555893, acc=0.9667547941207886, loss=0.10577603429555893
test: epoch 58, loss 2.188749074935913, acc=0.46199604868888855, loss=2.188749074935913
train: epoch 59, loss 0.11003720015287399, acc=0.9658955931663513, loss=0.11003720015287399
test: epoch 59, loss 1.9096516370773315, acc=0.5201586484909058, loss=1.9096516370773315
train: epoch 60, loss 0.10937550663948059, acc=0.96614670753479, loss=0.10937550663948059
test: epoch 60, loss 1.8448954820632935, acc=0.4990085959434509, loss=1.8448954820632935
train: epoch 61, loss 0.10555291920900345, acc=0.9662260413169861, loss=0.10555291920900345
test: epoch 61, loss 2.17849063873291, acc=0.48182418942451477, loss=2.17849063873291
train: epoch 62, loss 0.1039615124464035, acc=0.9675478935241699, loss=0.1039615124464035
test: epoch 62, loss 1.7182539701461792, acc=0.4963648319244385, loss=1.7182539701461792
train: epoch 63, loss 0.10088931024074554, acc=0.9684864282608032, loss=0.10088931024074554
test: epoch 63, loss 1.830496907234192, acc=0.5532055497169495, loss=1.830496907234192
train: epoch 64, loss 0.10528009384870529, acc=0.9676008224487305, loss=0.10528009384870529
test: epoch 64, loss 1.7762868404388428, acc=0.5122273564338684, loss=1.7762868404388428
train: epoch 65, loss 0.09741278737783432, acc=0.968684732913971, loss=0.09741278737783432
test: epoch 65, loss 1.6180588006973267, acc=0.527428925037384, loss=1.6180588006973267
train: epoch 66, loss 0.10467279702425003, acc=0.9674950242042542, loss=0.10467279702425003
test: epoch 66, loss 1.7096004486083984, acc=0.5406477451324463, loss=1.7096004486083984
train: epoch 67, loss 0.1027887761592865, acc=0.9682353138923645, loss=0.1027887761592865
test: epoch 67, loss 2.0467238426208496, acc=0.5201586484909058, loss=2.0467238426208496
train: epoch 68, loss 0.09634563326835632, acc=0.9706411361694336, loss=0.09634563326835632
test: epoch 68, loss 1.8140523433685303, acc=0.5499008297920227, loss=1.8140523433685303
train: epoch 69, loss 0.10021138936281204, acc=0.969596803188324, loss=0.10021138936281204
test: epoch 69, loss 1.793808937072754, acc=0.5776602625846863, loss=1.793808937072754
train: epoch 70, loss 0.09806282818317413, acc=0.9697951078414917, loss=0.09806282818317413
test: epoch 70, loss 1.7807894945144653, acc=0.5419695973396301, loss=1.7807894945144653
train: epoch 71, loss 0.09756451845169067, acc=0.9693324565887451, loss=0.09756451845169067
test: epoch 71, loss 1.777409315109253, acc=0.5617977380752563, loss=1.777409315109253
train: epoch 72, loss 0.10171439498662949, acc=0.9685128927230835, loss=0.10171439498662949
test: epoch 72, loss 1.5543723106384277, acc=0.5961665511131287, loss=1.5543723106384277
train: epoch 73, loss 0.10225159674882889, acc=0.9677726626396179, loss=0.10225159674882889
test: epoch 73, loss 1.4736607074737549, acc=0.6153337955474854, loss=1.4736607074737549
train: epoch 74, loss 0.09866392612457275, acc=0.9701255559921265, loss=0.09866392612457275
test: epoch 74, loss 1.497666835784912, acc=0.619960367679596, loss=1.497666835784912
train: epoch 75, loss 0.09783751517534256, acc=0.9693853259086609, loss=0.09783751517534256
test: epoch 75, loss 1.337195634841919, acc=0.6133509874343872, loss=1.337195634841919
train: epoch 76, loss 0.09842412173748016, acc=0.9699801802635193, loss=0.09842412173748016
test: epoch 76, loss 1.5405246019363403, acc=0.6470588445663452, loss=1.5405246019363403
train: epoch 77, loss 0.09613422304391861, acc=0.9705089330673218, loss=0.09613422304391861
test: epoch 77, loss 1.3862143754959106, acc=0.6543291211128235, loss=1.3862143754959106
train: epoch 78, loss 0.09638310968875885, acc=0.9701784253120422, loss=0.09638310968875885
test: epoch 78, loss 1.0765154361724854, acc=0.6596166491508484, loss=1.0765154361724854
train: epoch 79, loss 0.09896565973758698, acc=0.9699273109436035, loss=0.09896565973758698
test: epoch 79, loss 1.0735633373260498, acc=0.6820885539054871, loss=1.0735633373260498
train: epoch 80, loss 0.09564197808504105, acc=0.9709451198577881, loss=0.09564197808504105
test: epoch 80, loss 1.349315881729126, acc=0.6880370378494263, loss=1.349315881729126
train: epoch 81, loss 0.09220243990421295, acc=0.9721348285675049, loss=0.09220243990421295
test: epoch 81, loss 1.2113298177719116, acc=0.6953073143959045, loss=1.2113298177719116
train: epoch 82, loss 0.09467262774705887, acc=0.9708922505378723, loss=0.09467262774705887
test: epoch 82, loss 1.3012292385101318, acc=0.6801057457923889, loss=1.3012292385101318
train: epoch 83, loss 0.08610948920249939, acc=0.9726900458335876, loss=0.08610948920249939
test: epoch 83, loss 1.4059844017028809, acc=0.6992729902267456, loss=1.4059844017028809
train: epoch 84, loss 0.09147940576076508, acc=0.9725049734115601, loss=0.09147940576076508
test: epoch 84, loss 0.9964022040367126, acc=0.7323198914527893, loss=0.9964022040367126
train: epoch 85, loss 0.08935371786355972, acc=0.973337709903717, loss=0.08935371786355972
test: epoch 85, loss 1.1380013227462769, acc=0.6972901225090027, loss=1.1380013227462769
train: epoch 86, loss 0.08586639910936356, acc=0.9740383625030518, loss=0.08586639910936356
test: epoch 86, loss 1.0345373153686523, acc=0.70522141456604, loss=1.0345373153686523
train: epoch 87, loss 0.09177051484584808, acc=0.973126232624054, loss=0.09177051484584808
test: epoch 87, loss 1.12354576587677, acc=0.7250495553016663, loss=1.12354576587677
train: epoch 88, loss 0.0847339779138565, acc=0.9736946225166321, loss=0.0847339779138565
test: epoch 88, loss 1.1401281356811523, acc=0.7362855076789856, loss=1.1401281356811523
train: epoch 89, loss 0.08791833370923996, acc=0.9743159413337708, loss=0.08791833370923996
test: epoch 89, loss 1.1843019723892212, acc=0.72108393907547, loss=1.1843019723892212
train: epoch 90, loss 0.08323506265878677, acc=0.975677490234375, loss=0.08323506265878677
test: epoch 90, loss 0.9206241369247437, acc=0.7739590406417847, loss=0.9206241369247437
train: epoch 91, loss 0.08515338599681854, acc=0.9741308689117432, loss=0.08515338599681854
test: epoch 91, loss 1.0059409141540527, acc=0.7534699440002441, loss=1.0059409141540527
train: epoch 92, loss 0.08489204198122025, acc=0.9749636650085449, loss=0.08489204198122025
test: epoch 92, loss 0.9907168745994568, acc=0.7693324685096741, loss=0.9907168745994568
train: epoch 93, loss 0.07635856419801712, acc=0.9774355292320251, loss=0.07635856419801712
test: epoch 93, loss 1.0515589714050293, acc=0.7627230882644653, loss=1.0515589714050293
train: epoch 94, loss 0.07409194111824036, acc=0.9776338338851929, loss=0.07409194111824036
test: epoch 94, loss 0.9929028749465942, acc=0.7805684208869934, loss=0.9929028749465942
train: epoch 95, loss 0.07518351823091507, acc=0.9773562550544739, loss=0.07518351823091507
test: epoch 95, loss 0.8336222767829895, acc=0.7871778011322021, loss=0.8336222767829895
train: epoch 96, loss 0.0751381441950798, acc=0.9772372841835022, loss=0.0751381441950798
test: epoch 96, loss 1.0162034034729004, acc=0.7805684208869934, loss=1.0162034034729004
train: epoch 97, loss 0.07831032574176788, acc=0.9774223566055298, loss=0.07831032574176788
test: epoch 97, loss 1.028524398803711, acc=0.7660277485847473, loss=1.028524398803711
train: epoch 98, loss 0.07446164637804031, acc=0.9790878891944885, loss=0.07446164637804031
test: epoch 98, loss 0.9354475736618042, acc=0.7752808928489685, loss=0.9354475736618042
train: epoch 99, loss 0.07405149936676025, acc=0.9785194993019104, loss=0.07405149936676025
test: epoch 99, loss 1.0144751071929932, acc=0.7732980847358704, loss=1.0144751071929932
train: epoch 100, loss 0.07101453840732574, acc=0.9798281788825989, loss=0.07101453840732574
test: epoch 100, loss 0.9400178790092468, acc=0.7865168452262878, loss=0.9400178790092468
train: epoch 101, loss 0.07255362719297409, acc=0.9791143536567688, loss=0.07255362719297409
test: epoch 101, loss 0.8980714678764343, acc=0.7970918416976929, loss=0.8980714678764343
train: epoch 102, loss 0.06722013652324677, acc=0.9801850914955139, loss=0.06722013652324677
test: epoch 102, loss 1.016884207725525, acc=0.7805684208869934, loss=1.016884207725525
train: epoch 103, loss 0.0658879205584526, acc=0.9810839295387268, loss=0.0658879205584526
test: epoch 103, loss 0.9162236452102661, acc=0.785194993019104, loss=0.9162236452102661
train: epoch 104, loss 0.07617707550525665, acc=0.9788367748260498, loss=0.07617707550525665
test: epoch 104, loss 0.8639642000198364, acc=0.7858558893203735, loss=0.8639642000198364
train: epoch 105, loss 0.0660836473107338, acc=0.9808063507080078, loss=0.0660836473107338
test: epoch 105, loss 0.9850280284881592, acc=0.7878387570381165, loss=0.9850280284881592
train: epoch 106, loss 0.06739544868469238, acc=0.9805287718772888, loss=0.06739544868469238
test: epoch 106, loss 0.7442869544029236, acc=0.8010575175285339, loss=0.7442869544029236
train: epoch 107, loss 0.06437946110963821, acc=0.9814012050628662, loss=0.06437946110963821
test: epoch 107, loss 0.8588042855262756, acc=0.7970918416976929, loss=0.8588042855262756
train: epoch 108, loss 0.07302028685808182, acc=0.9807798862457275, loss=0.07302028685808182
test: epoch 108, loss 0.8985415697097778, acc=0.8003965616226196, loss=0.8985415697097778
train: epoch 109, loss 0.06142232194542885, acc=0.9821810722351074, loss=0.06142232194542885
test: epoch 109, loss 0.7805293798446655, acc=0.8017184138298035, loss=0.7805293798446655
train: epoch 110, loss 0.06742435693740845, acc=0.9812954664230347, loss=0.06742435693740845
test: epoch 110, loss 0.9518455862998962, acc=0.7792465090751648, loss=0.9518455862998962
train: epoch 111, loss 0.06520169973373413, acc=0.9826173186302185, loss=0.06520169973373413
test: epoch 111, loss 1.0232948064804077, acc=0.7918043732643127, loss=1.0232948064804077
train: epoch 112, loss 0.05949891731142998, acc=0.9825379848480225, loss=0.05949891731142998
test: epoch 112, loss 0.7892323136329651, acc=0.7970918416976929, loss=0.7892323136329651
train: epoch 113, loss 0.06104935705661774, acc=0.9823265075683594, loss=0.06104935705661774
test: epoch 113, loss 0.8354533314704895, acc=0.7990747094154358, loss=0.8354533314704895
train: epoch 114, loss 0.05945805087685585, acc=0.9835293889045715, loss=0.05945805087685585
test: epoch 114, loss 0.8485039472579956, acc=0.8043621778488159, loss=0.8485039472579956
train: epoch 115, loss 0.06341935694217682, acc=0.9829874634742737, loss=0.06341935694217682
test: epoch 115, loss 0.8765900731086731, acc=0.8017184138298035, loss=0.8765900731086731
train: epoch 116, loss 0.05702279880642891, acc=0.983780562877655, loss=0.05702279880642891
test: epoch 116, loss 1.0540013313293457, acc=0.7904824614524841, loss=1.0540013313293457
train: epoch 117, loss 0.06268476694822311, acc=0.9831593036651611, loss=0.06268476694822311
test: epoch 117, loss 0.833914577960968, acc=0.8037012815475464, loss=0.833914577960968
train: epoch 118, loss 0.06585226953029633, acc=0.9836748242378235, loss=0.06585226953029633
test: epoch 118, loss 0.8506206274032593, acc=0.8043621778488159, loss=0.8506206274032593
train: epoch 119, loss 0.05961122363805771, acc=0.982789158821106, loss=0.05961122363805771
test: epoch 119, loss 0.8954706788063049, acc=0.7970918416976929, loss=0.8954706788063049
train: epoch 120, loss 0.05653895065188408, acc=0.9836748242378235, loss=0.05653895065188408
test: epoch 120, loss 0.9055215120315552, acc=0.8056840896606445, loss=0.9055215120315552
train: epoch 121, loss 0.05710761994123459, acc=0.9842432141304016, loss=0.05710761994123459
test: epoch 121, loss 0.8524141907691956, acc=0.8023793697357178, loss=0.8524141907691956
train: epoch 122, loss 0.05138981342315674, acc=0.9850627779960632, loss=0.05138981342315674
test: epoch 122, loss 0.9818258285522461, acc=0.8030403256416321, loss=0.9818258285522461
train: epoch 123, loss 0.06203524395823479, acc=0.9834501147270203, loss=0.06203524395823479
test: epoch 123, loss 0.9384074211120605, acc=0.7977527976036072, loss=0.9384074211120605
train: epoch 124, loss 0.06464333832263947, acc=0.9842564463615417, loss=0.06464333832263947
test: epoch 124, loss 1.0104295015335083, acc=0.7904824614524841, loss=1.0104295015335083
train: epoch 125, loss 0.05982315167784691, acc=0.9844415187835693, loss=0.05982315167784691
test: epoch 125, loss 0.8463805913925171, acc=0.8175809383392334, loss=0.8463805913925171
train: epoch 126, loss 0.05580902472138405, acc=0.985115647315979, loss=0.05580902472138405
test: epoch 126, loss 0.8653517365455627, acc=0.8056840896606445, loss=0.8653517365455627
train: epoch 127, loss 0.05771682411432266, acc=0.9839920401573181, loss=0.05771682411432266
test: epoch 127, loss 0.920714795589447, acc=0.7977527976036072, loss=0.920714795589447
train: epoch 128, loss 0.05554446205496788, acc=0.9846662282943726, loss=0.05554446205496788
test: epoch 128, loss 0.832877516746521, acc=0.811632513999939, loss=0.832877516746521
train: epoch 129, loss 0.057607509195804596, acc=0.9844018220901489, loss=0.057607509195804596
test: epoch 129, loss 0.7975957989692688, acc=0.8149372339248657, loss=0.7975957989692688
train: epoch 130, loss 0.06026704981923103, acc=0.9846265912055969, loss=0.06026704981923103
test: epoch 130, loss 0.7965604066848755, acc=0.8050231337547302, loss=0.7965604066848755
train: epoch 131, loss 0.0585598386824131, acc=0.9842696785926819, loss=0.0585598386824131
test: epoch 131, loss 0.8368769288063049, acc=0.8175809383392334, loss=0.8368769288063049
train: epoch 132, loss 0.05340138077735901, acc=0.9848116040229797, loss=0.05340138077735901
test: epoch 132, loss 0.9269813895225525, acc=0.8109715580940247, loss=0.9269813895225525
train: epoch 133, loss 0.06472820788621902, acc=0.9840317368507385, loss=0.06472820788621902
test: epoch 133, loss 0.8014068603515625, acc=0.8109715580940247, loss=0.8014068603515625
train: epoch 134, loss 0.06033572182059288, acc=0.9834104180335999, loss=0.06033572182059288
test: epoch 134, loss 0.8593975901603699, acc=0.8175809383392334, loss=0.8593975901603699
train: epoch 135, loss 0.05322277173399925, acc=0.9841374754905701, loss=0.05322277173399925
test: epoch 135, loss 0.8703374266624451, acc=0.8208856582641602, loss=0.8703374266624451
train: epoch 136, loss 0.06327971816062927, acc=0.9824322462081909, loss=0.06327971816062927
test: epoch 136, loss 0.8078323006629944, acc=0.8122934699058533, loss=0.8078323006629944
train: epoch 137, loss 0.058968156576156616, acc=0.9839391708374023, loss=0.058968156576156616
test: epoch 137, loss 0.8728830814361572, acc=0.8056840896606445, loss=0.8728830814361572
train: epoch 138, loss 0.06362723559141159, acc=0.9827495217323303, loss=0.06362723559141159
test: epoch 138, loss 0.7214179039001465, acc=0.8155981302261353, loss=0.7214179039001465
train: epoch 139, loss 0.07128041982650757, acc=0.9819034934043884, loss=0.07128041982650757
test: epoch 139, loss 0.9811797142028809, acc=0.7845340371131897, loss=0.9811797142028809
train: epoch 140, loss 0.07147079706192017, acc=0.9801453948020935, loss=0.07147079706192017
test: epoch 140, loss 0.7457472085952759, acc=0.8017184138298035, loss=0.7457472085952759
train: epoch 141, loss 0.07115144282579422, acc=0.9792994260787964, loss=0.07115144282579422
test: epoch 141, loss 0.9573298692703247, acc=0.7984137535095215, loss=0.9573298692703247
train: epoch 142, loss 0.07072736322879791, acc=0.9803304672241211, loss=0.07072736322879791
test: epoch 142, loss 0.9496374726295471, acc=0.8122934699058533, loss=0.9496374726295471
train: epoch 143, loss 0.07681974023580551, acc=0.9806609153747559, loss=0.07681974023580551
test: epoch 143, loss 0.704818069934845, acc=0.8155981302261353, loss=0.704818069934845
train: epoch 144, loss 0.06762009114027023, acc=0.9808063507080078, loss=0.06762009114027023
test: epoch 144, loss 0.7817228436470032, acc=0.8129543662071228, loss=0.7817228436470032
train: epoch 145, loss 0.06763014942407608, acc=0.9819431304931641, loss=0.06763014942407608
test: epoch 145, loss 0.8710350394248962, acc=0.822207510471344, loss=0.8710350394248962
train: epoch 146, loss 0.06977468729019165, acc=0.9814408421516418, loss=0.06977468729019165
test: epoch 146, loss 0.8330490589141846, acc=0.8195638060569763, loss=0.8330490589141846
train: epoch 147, loss 0.07227028906345367, acc=0.9826305508613586, loss=0.07227028906345367
test: epoch 147, loss 0.864197313785553, acc=0.8261731863021851, loss=0.864197313785553
train: epoch 148, loss 0.06046522781252861, acc=0.9831857085227966, loss=0.06046522781252861
test: epoch 148, loss 0.9887385368347168, acc=0.8010575175285339, loss=0.9887385368347168
train: epoch 149, loss 0.06489714980125427, acc=0.9834633469581604, loss=0.06489714980125427
test: epoch 149, loss 0.8341190218925476, acc=0.811632513999939, loss=0.8341190218925476
train: epoch 150, loss 0.07009728252887726, acc=0.9825644493103027, loss=0.07009728252887726
test: epoch 150, loss 0.7971218824386597, acc=0.8241903781890869, loss=0.7971218824386597
train: epoch 151, loss 0.06546495854854584, acc=0.9824718832969666, loss=0.06546495854854584
test: epoch 151, loss 0.7467955946922302, acc=0.8248512744903564, loss=0.7467955946922302
train: epoch 152, loss 0.0550486221909523, acc=0.9849438071250916, loss=0.0550486221909523
test: epoch 152, loss 0.7068922519683838, acc=0.8314606547355652, loss=0.7068922519683838
train: epoch 153, loss 0.07280255854129791, acc=0.9831857085227966, loss=0.07280255854129791
test: epoch 153, loss 0.8097094893455505, acc=0.8162590861320496, loss=0.8097094893455505
train: epoch 154, loss 0.059044282883405685, acc=0.9845340251922607, loss=0.059044282883405685
test: epoch 154, loss 0.8047276735305786, acc=0.8268340826034546, loss=0.8047276735305786
train: epoch 155, loss 0.06435976922512054, acc=0.9832650423049927, loss=0.06435976922512054
test: epoch 155, loss 0.7203679084777832, acc=0.8195638060569763, loss=0.7203679084777832
train: epoch 156, loss 0.07156045734882355, acc=0.9825248122215271, loss=0.07156045734882355
test: epoch 156, loss 0.9149748682975769, acc=0.822207510471344, loss=0.9149748682975769
train: epoch 157, loss 0.06379483640193939, acc=0.9837673306465149, loss=0.06379483640193939
test: epoch 157, loss 0.791489839553833, acc=0.8010575175285339, loss=0.791489839553833
train: epoch 158, loss 0.058550864458084106, acc=0.9841242432594299, loss=0.058550864458084106
test: epoch 158, loss 0.7169826626777649, acc=0.8347653746604919, loss=0.7169826626777649
train: epoch 159, loss 0.06277558952569962, acc=0.98342365026474, loss=0.06277558952569962
test: epoch 159, loss 0.7951081395149231, acc=0.8149372339248657, loss=0.7951081395149231
train: epoch 160, loss 0.06425454467535019, acc=0.983701229095459, loss=0.06425454467535019
test: epoch 160, loss 0.7518227696418762, acc=0.8261731863021851, loss=0.7518227696418762
train: epoch 161, loss 0.06579803675413132, acc=0.9832782745361328, loss=0.06579803675413132
test: epoch 161, loss 0.8660221695899963, acc=0.8096497058868408, loss=0.8660221695899963
train: epoch 162, loss 0.07220358401536942, acc=0.9821678996086121, loss=0.07220358401536942
test: epoch 162, loss 0.7808607816696167, acc=0.8129543662071228, loss=0.7808607816696167
train: epoch 163, loss 0.07257130742073059, acc=0.9823265075683594, loss=0.07257130742073059
test: epoch 163, loss 0.6811936497688293, acc=0.8155981302261353, loss=0.6811936497688293
train: epoch 164, loss 0.06879965215921402, acc=0.9814012050628662, loss=0.06879965215921402
test: epoch 164, loss 0.7790616154670715, acc=0.8248512744903564, loss=0.7790616154670715
train: epoch 165, loss 0.08935550600290298, acc=0.9784666299819946, loss=0.08935550600290298
test: epoch 165, loss 0.8656425476074219, acc=0.792465329170227, loss=0.8656425476074219
train: epoch 166, loss 0.08409900963306427, acc=0.9789557456970215, loss=0.08409900963306427
test: epoch 166, loss 0.7842591404914856, acc=0.8281559944152832, loss=0.7842591404914856
train: epoch 167, loss 0.09625521302223206, acc=0.979061484336853, loss=0.09625521302223206
test: epoch 167, loss 1.0054256916046143, acc=0.8037012815475464, loss=1.0054256916046143
train: epoch 168, loss 0.07859665155410767, acc=0.9814144372940063, loss=0.07859665155410767
test: epoch 168, loss 0.9616009593009949, acc=0.8169200420379639, loss=0.9616009593009949
train: epoch 169, loss 0.09132291376590729, acc=0.9787706732749939, loss=0.09132291376590729
test: epoch 169, loss 0.8672968745231628, acc=0.8215466141700745, loss=0.8672968745231628
train: epoch 170, loss 0.08521925657987595, acc=0.9790482521057129, loss=0.08521925657987595
test: epoch 170, loss 0.6776654720306396, acc=0.8288168907165527, loss=0.6776654720306396
train: epoch 171, loss 0.09192974865436554, acc=0.9787574410438538, loss=0.09192974865436554
test: epoch 171, loss 0.7973811626434326, acc=0.8122934699058533, loss=0.7973811626434326
train: epoch 172, loss 0.07064153254032135, acc=0.9817448854446411, loss=0.07064153254032135
test: epoch 172, loss 0.8149366974830627, acc=0.8360872268676758, loss=0.8149366974830627
train: epoch 173, loss 0.07424577325582504, acc=0.9821282029151917, loss=0.07424577325582504
test: epoch 173, loss 0.7675313949584961, acc=0.8241903781890869, loss=0.7675313949584961
train: epoch 174, loss 0.0675913468003273, acc=0.9824058413505554, loss=0.0675913468003273
test: epoch 174, loss 0.7785415649414062, acc=0.8261731863021851, loss=0.7785415649414062
train: epoch 175, loss 0.07484134286642075, acc=0.9818638563156128, loss=0.07484134286642075
test: epoch 175, loss 0.8086644411087036, acc=0.8248512744903564, loss=0.8086644411087036
train: epoch 176, loss 0.06679284572601318, acc=0.9833311438560486, loss=0.06679284572601318
test: epoch 176, loss 0.8802247643470764, acc=0.8341044187545776, loss=0.8802247643470764
train: epoch 177, loss 0.07166676223278046, acc=0.9833311438560486, loss=0.07166676223278046
test: epoch 177, loss 0.91093909740448, acc=0.8268340826034546, loss=0.91093909740448
train: epoch 178, loss 0.07631320506334305, acc=0.98200923204422, loss=0.07631320506334305
test: epoch 178, loss 0.7464434504508972, acc=0.8255122303962708, loss=0.7464434504508972
train: epoch 179, loss 0.07525821775197983, acc=0.9815598130226135, loss=0.07525821775197983
test: epoch 179, loss 0.9527620077133179, acc=0.8334434628486633, loss=0.9527620077133179
train: epoch 180, loss 0.05907157436013222, acc=0.9852743148803711, loss=0.05907157436013222
test: epoch 180, loss 0.7393614053726196, acc=0.8380700349807739, loss=0.7393614053726196
train: epoch 181, loss 0.07548533380031586, acc=0.983925998210907, loss=0.07548533380031586
test: epoch 181, loss 0.8373416662216187, acc=0.8341044187545776, loss=0.8373416662216187
train: epoch 182, loss 0.08293487131595612, acc=0.9807006120681763, loss=0.08293487131595612
test: epoch 182, loss 0.8602861166000366, acc=0.818902850151062, loss=0.8602861166000366
train: epoch 183, loss 0.07224372774362564, acc=0.982366144657135, loss=0.07224372774362564
test: epoch 183, loss 0.8409515619277954, acc=0.8274950385093689, loss=0.8409515619277954
train: epoch 184, loss 0.0862155333161354, acc=0.979762077331543, loss=0.0862155333161354
test: epoch 184, loss 0.8190484642982483, acc=0.8182418942451477, loss=0.8190484642982483
train: epoch 185, loss 0.08165201544761658, acc=0.9806080460548401, loss=0.08165201544761658
test: epoch 185, loss 0.7932703495025635, acc=0.8314606547355652, loss=0.7932703495025635
train: epoch 186, loss 0.0759815126657486, acc=0.981731653213501, loss=0.0759815126657486
test: epoch 186, loss 0.8770053386688232, acc=0.8215466141700745, loss=0.8770053386688232
train: epoch 187, loss 0.07799871265888214, acc=0.9823265075683594, loss=0.07799871265888214
test: epoch 187, loss 0.9175204038619995, acc=0.822207510471344, loss=0.9175204038619995
train: epoch 188, loss 0.08602327853441238, acc=0.9813615083694458, loss=0.08602327853441238
test: epoch 188, loss 0.8770991563796997, acc=0.8288168907165527, loss=0.8770991563796997
train: epoch 189, loss 0.07134760916233063, acc=0.9834368824958801, loss=0.07134760916233063
test: epoch 189, loss 0.7936721444129944, acc=0.8321216106414795, loss=0.7936721444129944
train: epoch 190, loss 0.08539692312479019, acc=0.9830799698829651, loss=0.08539692312479019
test: epoch 190, loss 0.9740626811981201, acc=0.8208856582641602, loss=0.9740626811981201
train: epoch 191, loss 0.07019324600696564, acc=0.9833972454071045, loss=0.07019324600696564
test: epoch 191, loss 0.8225857019424438, acc=0.8301388025283813, loss=0.8225857019424438
train: epoch 192, loss 0.08228231221437454, acc=0.9819828271865845, loss=0.08228231221437454
test: epoch 192, loss 0.7920656204223633, acc=0.8341044187545776, loss=0.7920656204223633
train: epoch 193, loss 0.08432423323392868, acc=0.9817712903022766, loss=0.08432423323392868
test: epoch 193, loss 0.7829889059066772, acc=0.8334434628486633, loss=0.7829889059066772
train: epoch 194, loss 0.07447952032089233, acc=0.9824851155281067, loss=0.07447952032089233
test: epoch 194, loss 0.8348391056060791, acc=0.8347653746604919, loss=0.8348391056060791
train: epoch 195, loss 0.07605627924203873, acc=0.983502984046936, loss=0.07605627924203873
test: epoch 195, loss 0.8154430985450745, acc=0.811632513999939, loss=0.8154430985450745
train: epoch 196, loss 0.06851992756128311, acc=0.9841374754905701, loss=0.06851992756128311
test: epoch 196, loss 0.9285368919372559, acc=0.8248512744903564, loss=0.9285368919372559
train: epoch 197, loss 0.0692066177725792, acc=0.9835558533668518, loss=0.0692066177725792
test: epoch 197, loss 0.8551269769668579, acc=0.8228684663772583, loss=0.8551269769668579
train: epoch 198, loss 0.08222362399101257, acc=0.9818506240844727, loss=0.08222362399101257
test: epoch 198, loss 0.9282428026199341, acc=0.8228684663772583, loss=0.9282428026199341
train: epoch 199, loss 0.10151530057191849, acc=0.9784401655197144, loss=0.10151530057191849
test: epoch 199, loss 0.9462723731994629, acc=0.8182418942451477, loss=0.9462723731994629
train: epoch 200, loss 0.09825059026479721, acc=0.9780568480491638, loss=0.09825059026479721
test: epoch 200, loss 0.942139208316803, acc=0.8248512744903564, loss=0.942139208316803
train: epoch 201, loss 0.10806158185005188, acc=0.9761533141136169, loss=0.10806158185005188
test: epoch 201, loss 1.0182987451553345, acc=0.808327853679657, loss=1.0182987451553345
train: epoch 202, loss 0.12511388957500458, acc=0.977144718170166, loss=0.12511388957500458
test: epoch 202, loss 0.9659152030944824, acc=0.7964309453964233, loss=0.9659152030944824
train: epoch 203, loss 0.10689932852983475, acc=0.9770918488502502, loss=0.10689932852983475
test: epoch 203, loss 0.9444388747215271, acc=0.8056840896606445, loss=0.9444388747215271
train: epoch 204, loss 0.09576384723186493, acc=0.9773166179656982, loss=0.09576384723186493
test: epoch 204, loss 1.035354495048523, acc=0.7990747094154358, loss=1.035354495048523
train: epoch 205, loss 0.08914470672607422, acc=0.9785856008529663, loss=0.08914470672607422
test: epoch 205, loss 1.0194909572601318, acc=0.8030403256416321, loss=1.0194909572601318
train: epoch 206, loss 0.09222287684679031, acc=0.9786384701728821, loss=0.09222287684679031
test: epoch 206, loss 1.00145423412323, acc=0.8030403256416321, loss=1.00145423412323
train: epoch 207, loss 0.08569733053445816, acc=0.9787442088127136, loss=0.08569733053445816
test: epoch 207, loss 1.0114922523498535, acc=0.8030403256416321, loss=1.0114922523498535
train: epoch 208, loss 0.08511609584093094, acc=0.9795902371406555, loss=0.08511609584093094
test: epoch 208, loss 0.8859532475471497, acc=0.8003965616226196, loss=0.8859532475471497
train: epoch 209, loss 0.0946207121014595, acc=0.9784137606620789, loss=0.0946207121014595
test: epoch 209, loss 1.0013724565505981, acc=0.8023793697357178, loss=1.0013724565505981
train: epoch 210, loss 0.1296776682138443, acc=0.9752677083015442, loss=0.1296776682138443
test: epoch 210, loss 0.8667968511581421, acc=0.8182418942451477, loss=0.8667968511581421
train: epoch 211, loss 0.09983599185943604, acc=0.9773562550544739, loss=0.09983599185943604
test: epoch 211, loss 0.9224935173988342, acc=0.8017184138298035, loss=0.9224935173988342
train: epoch 212, loss 0.10488984733819962, acc=0.9755716919898987, loss=0.10488984733819962
test: epoch 212, loss 0.9583021402359009, acc=0.8175809383392334, loss=0.9583021402359009
train: epoch 213, loss 0.10589049011468887, acc=0.9740251302719116, loss=0.10589049011468887
test: epoch 213, loss 0.9644318222999573, acc=0.8215466141700745, loss=0.9644318222999573
train: epoch 214, loss 0.09915192425251007, acc=0.9757567644119263, loss=0.09915192425251007
test: epoch 214, loss 0.882904052734375, acc=0.8248512744903564, loss=0.882904052734375
train: epoch 215, loss 0.08972381800413132, acc=0.9777528047561646, loss=0.08972381800413132
test: epoch 215, loss 0.9586926102638245, acc=0.8182418942451477, loss=0.9586926102638245
train: epoch 216, loss 0.08659963309764862, acc=0.9781229496002197, loss=0.08659963309764862
test: epoch 216, loss 0.9405376315116882, acc=0.8334434628486633, loss=0.9405376315116882
train: epoch 217, loss 0.10365098714828491, acc=0.9772505164146423, loss=0.10365098714828491
test: epoch 217, loss 0.939121663570404, acc=0.8248512744903564, loss=0.939121663570404
train: epoch 218, loss 0.12632377445697784, acc=0.9752808809280396, loss=0.12632377445697784
test: epoch 218, loss 0.9474058747291565, acc=0.811632513999939, loss=0.9474058747291565
train: epoch 219, loss 0.11696507781744003, acc=0.9731526970863342, loss=0.11696507781744003
test: epoch 219, loss 0.8907278776168823, acc=0.8195638060569763, loss=0.8907278776168823
train: epoch 220, loss 0.12373354285955429, acc=0.9714738726615906, loss=0.12373354285955429
test: epoch 220, loss 0.9443070292472839, acc=0.8235294222831726, loss=0.9443070292472839
train: epoch 221, loss 0.12904107570648193, acc=0.970812976360321, loss=0.12904107570648193
test: epoch 221, loss 0.928896427154541, acc=0.8182418942451477, loss=0.928896427154541
train: epoch 222, loss 0.12309527397155762, acc=0.9725578427314758, loss=0.12309527397155762
test: epoch 222, loss 0.9550135731697083, acc=0.818902850151062, loss=0.9550135731697083
train: epoch 223, loss 0.12161596864461899, acc=0.9745935201644897, loss=0.12161596864461899
test: epoch 223, loss 1.068895697593689, acc=0.8215466141700745, loss=1.068895697593689
train: epoch 224, loss 0.0998411476612091, acc=0.9754263162612915, loss=0.0998411476612091
test: epoch 224, loss 1.20700204372406, acc=0.8136153221130371, loss=1.20700204372406
train: epoch 225, loss 0.10371693968772888, acc=0.9759418368339539, loss=0.10371693968772888
test: epoch 225, loss 0.9727789759635925, acc=0.8215466141700745, loss=0.9727789759635925
train: epoch 226, loss 0.10320037603378296, acc=0.9742233753204346, loss=0.10320037603378296
test: epoch 226, loss 0.9054017066955566, acc=0.8208856582641602, loss=0.9054017066955566
train: epoch 227, loss 0.111712247133255, acc=0.9740118980407715, loss=0.111712247133255
test: epoch 227, loss 0.932366669178009, acc=0.822207510471344, loss=0.932366669178009
train: epoch 228, loss 0.09934963285923004, acc=0.976232647895813, loss=0.09934963285923004
test: epoch 228, loss 1.1018017530441284, acc=0.8129543662071228, loss=1.1018017530441284
train: epoch 229, loss 0.1121247336268425, acc=0.9729015231132507, loss=0.1121247336268425
test: epoch 229, loss 1.0518192052841187, acc=0.8182418942451477, loss=1.0518192052841187
train: epoch 230, loss 0.10468799620866776, acc=0.9744613170623779, loss=0.10468799620866776
test: epoch 230, loss 0.9664701819419861, acc=0.8162590861320496, loss=0.9664701819419861
train: epoch 231, loss 0.09878230094909668, acc=0.9734699130058289, loss=0.09878230094909668
test: epoch 231, loss 1.1225308179855347, acc=0.8162590861320496, loss=1.1225308179855347
train: epoch 232, loss 0.11069273948669434, acc=0.9717118144035339, loss=0.11069273948669434
test: epoch 232, loss 0.9702666401863098, acc=0.8255122303962708, loss=0.9702666401863098
train: epoch 233, loss 0.12746159732341766, acc=0.9714474678039551, loss=0.12746159732341766
test: epoch 233, loss 0.9878355860710144, acc=0.811632513999939, loss=0.9878355860710144
train: epoch 234, loss 0.11967959254980087, acc=0.9740118980407715, loss=0.11967959254980087
test: epoch 234, loss 1.0083900690078735, acc=0.8235294222831726, loss=1.0083900690078735
train: epoch 235, loss 0.11096208542585373, acc=0.9747124910354614, loss=0.11096208542585373
test: epoch 235, loss 1.1056362390518188, acc=0.8215466141700745, loss=1.1056362390518188
train: epoch 236, loss 0.1255553513765335, acc=0.9742498397827148, loss=0.1255553513765335
test: epoch 236, loss 1.099265456199646, acc=0.8103106617927551, loss=1.099265456199646
train: epoch 237, loss 0.11818770319223404, acc=0.9751222729682922, loss=0.11818770319223404
test: epoch 237, loss 0.9753144383430481, acc=0.8208856582641602, loss=0.9753144383430481
train: epoch 238, loss 0.14155207574367523, acc=0.9734302759170532, loss=0.14155207574367523
test: epoch 238, loss 0.9609833359718323, acc=0.8122934699058533, loss=0.9609833359718323
train: epoch 239, loss 0.12559352815151215, acc=0.9730998277664185, loss=0.12559352815151215
test: epoch 239, loss 1.0523053407669067, acc=0.8103106617927551, loss=1.0523053407669067
train: epoch 240, loss 0.12098578363656998, acc=0.9732452034950256, loss=0.12098578363656998
test: epoch 240, loss 0.9763559699058533, acc=0.8122934699058533, loss=0.9763559699058533
train: epoch 241, loss 0.1174505427479744, acc=0.9739590287208557, loss=0.1174505427479744
test: epoch 241, loss 1.0945271253585815, acc=0.8136153221130371, loss=1.0945271253585815
train: epoch 242, loss 0.12404882162809372, acc=0.9722009301185608, loss=0.12404882162809372
test: epoch 242, loss 0.9204629063606262, acc=0.8241903781890869, loss=0.9204629063606262
train: epoch 243, loss 0.11799170821905136, acc=0.9741572737693787, loss=0.11799170821905136
test: epoch 243, loss 0.9177860021591187, acc=0.8169200420379639, loss=0.9177860021591187
train: epoch 244, loss 0.13073977828025818, acc=0.9713945984840393, loss=0.13073977828025818
test: epoch 244, loss 0.8810491561889648, acc=0.8109715580940247, loss=0.8810491561889648
train: epoch 245, loss 0.157060906291008, acc=0.9705353379249573, loss=0.157060906291008
test: epoch 245, loss 1.1443623304367065, acc=0.8096497058868408, loss=1.1443623304367065
train: epoch 246, loss 0.17377175390720367, acc=0.9645869135856628, loss=0.17377175390720367
test: epoch 246, loss 1.001317024230957, acc=0.8037012815475464, loss=1.001317024230957
train: epoch 247, loss 0.16913995146751404, acc=0.9649834632873535, loss=0.16913995146751404
test: epoch 247, loss 0.9294930696487427, acc=0.7997356057167053, loss=0.9294930696487427
train: epoch 248, loss 0.15942631661891937, acc=0.9650627970695496, loss=0.15942631661891937
test: epoch 248, loss 0.8707823753356934, acc=0.8202247023582458, loss=0.8707823753356934
train: epoch 249, loss 0.1283685714006424, acc=0.969120979309082, loss=0.1283685714006424
test: epoch 249, loss 1.1909105777740479, acc=0.8056840896606445, loss=1.1909105777740479
train: epoch 250, loss 0.13410267233848572, acc=0.9689623117446899, loss=0.13410267233848572
test: epoch 250, loss 0.9089716076850891, acc=0.8155981302261353, loss=0.9089716076850891
