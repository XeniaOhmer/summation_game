# ["--N=20", "--n_epochs=250", "--batch_size=32", "--lr=0.001", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=1", "--n_layers=3", "--save_run=1", "--n_symbols=164"]
Namespace(n_summands=2, N=20, test_split=0.1, data_scaling=50, one_hot=True, receiver_embed_dim=64, n_layers=3, n_symbols=164, temperature=2.0, temp_decay=0.995, early_stopping_acc=0.99, n_runs=1, save_run=True, random_seed=2088308360, checkpoint_dir=None, preemptable=False, checkpoint_freq=0, validation_freq=1, n_epochs=250, load_from_checkpoint=None, no_cuda=True, batch_size=32, optimizer='adam', lr=0.001, update_freq=1, vocab_size=10, max_len=1, tensorboard=False, tensorboard_dir='runs/', distributed_port=18363, fp16=False, cuda=False, device=device(type='cpu'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'))
train: epoch 1, loss 2.8475868701934814, acc=0.09057934582233429, loss=2.8475868701934814
test: epoch 1, loss 4.923476219177246, acc=0.08564231544733047, loss=4.923476219177246
train: epoch 2, loss 1.8263888359069824, acc=0.245743066072464, loss=1.8263888359069824
test: epoch 2, loss 5.375549793243408, acc=0.0931989923119545, loss=5.375549793243408
train: epoch 3, loss 1.3873820304870605, acc=0.4077581763267517, loss=1.3873820304870605
test: epoch 3, loss 6.295110702514648, acc=0.128463476896286, loss=6.295110702514648
train: epoch 4, loss 0.9891457557678223, acc=0.5876070261001587, loss=0.9891457557678223
test: epoch 4, loss 5.26405143737793, acc=0.14357683062553406, loss=5.26405143737793
train: epoch 5, loss 0.7119195461273193, acc=0.7163224220275879, loss=0.7119195461273193
test: epoch 5, loss 3.7235043048858643, acc=0.16120906174182892, loss=3.7235043048858643
train: epoch 6, loss 0.5502353310585022, acc=0.7890176177024841, loss=0.5502353310585022
test: epoch 6, loss 2.809872627258301, acc=0.30226701498031616, loss=2.809872627258301
train: epoch 7, loss 0.42800307273864746, acc=0.8452392816543579, loss=0.42800307273864746
test: epoch 7, loss 3.458773374557495, acc=0.2191435694694519, loss=3.458773374557495
train: epoch 8, loss 0.3447619080543518, acc=0.8806549310684204, loss=0.3447619080543518
test: epoch 8, loss 2.845384359359741, acc=0.2216624617576599, loss=2.845384359359741
train: epoch 9, loss 0.3039558231830597, acc=0.8930478692054749, loss=0.3039558231830597
test: epoch 9, loss 2.819532632827759, acc=0.2846347689628601, loss=2.819532632827759
train: epoch 10, loss 0.2712429165840149, acc=0.9070528745651245, loss=0.2712429165840149
test: epoch 10, loss 3.539341688156128, acc=0.2821158766746521, loss=3.539341688156128
train: epoch 11, loss 0.26023584604263306, acc=0.9130478501319885, loss=0.26023584604263306
test: epoch 11, loss 2.1425395011901855, acc=0.3425692617893219, loss=2.1425395011901855
train: epoch 12, loss 0.20821908116340637, acc=0.9309823513031006, loss=0.20821908116340637
test: epoch 12, loss 2.5839686393737793, acc=0.3501259386539459, loss=2.5839686393737793
train: epoch 13, loss 0.2004183828830719, acc=0.9306297302246094, loss=0.2004183828830719
test: epoch 13, loss 2.763645648956299, acc=0.3400503695011139, loss=2.763645648956299
train: epoch 14, loss 0.2087816298007965, acc=0.9281108379364014, loss=0.2087816298007965
test: epoch 14, loss 2.5457587242126465, acc=0.3501259386539459, loss=2.5457587242126465
train: epoch 15, loss 0.18257880210876465, acc=0.938992440700531, loss=0.18257880210876465
test: epoch 15, loss 2.577049493789673, acc=0.3476070463657379, loss=2.577049493789673
train: epoch 16, loss 0.18195927143096924, acc=0.9397984743118286, loss=0.18195927143096924
test: epoch 16, loss 2.0856997966766357, acc=0.36523929238319397, loss=2.0856997966766357
train: epoch 17, loss 0.1736782342195511, acc=0.9426196217536926, loss=0.1736782342195511
test: epoch 17, loss 1.9647743701934814, acc=0.35768261551856995, loss=1.9647743701934814
train: epoch 18, loss 0.16447757184505463, acc=0.9459949731826782, loss=0.16447757184505463
test: epoch 18, loss 2.0399158000946045, acc=0.4357682764530182, loss=2.0399158000946045
train: epoch 19, loss 0.1508202999830246, acc=0.950025200843811, loss=0.1508202999830246
test: epoch 19, loss 2.1234495639801025, acc=0.36272040009498596, loss=2.1234495639801025
train: epoch 20, loss 0.16188623011112213, acc=0.9478589296340942, loss=0.16188623011112213
test: epoch 20, loss 2.0694785118103027, acc=0.3476070463657379, loss=2.0694785118103027
train: epoch 21, loss 0.14263838529586792, acc=0.952846348285675, loss=0.14263838529586792
test: epoch 21, loss 2.286830425262451, acc=0.3375314772129059, loss=2.286830425262451
train: epoch 22, loss 0.13585099577903748, acc=0.9563727974891663, loss=0.13585099577903748
test: epoch 22, loss 2.5579822063446045, acc=0.38539043068885803, loss=2.5579822063446045
train: epoch 23, loss 0.1455947309732437, acc=0.950931966304779, loss=0.1455947309732437
test: epoch 23, loss 2.021043062210083, acc=0.4005037844181061, loss=2.021043062210083
train: epoch 24, loss 0.1328796148300171, acc=0.9574307203292847, loss=0.1328796148300171
test: epoch 24, loss 2.0690715312957764, acc=0.42821159958839417, loss=2.0690715312957764
train: epoch 25, loss 0.11958432197570801, acc=0.9596473574638367, loss=0.11958432197570801
test: epoch 25, loss 1.9909991025924683, acc=0.36523929238319397, loss=1.9909991025924683
train: epoch 26, loss 0.1326511949300766, acc=0.9561209082603455, loss=0.1326511949300766
test: epoch 26, loss 1.7232364416122437, acc=0.501259446144104, loss=1.7232364416122437
train: epoch 27, loss 0.1246345266699791, acc=0.9613098502159119, loss=0.1246345266699791
test: epoch 27, loss 2.2344532012939453, acc=0.36523929238319397, loss=2.2344532012939453
train: epoch 28, loss 0.11900579184293747, acc=0.9602015018463135, loss=0.11900579184293747
test: epoch 28, loss 2.242917537689209, acc=0.4105793535709381, loss=2.242917537689209
train: epoch 29, loss 0.1171826720237732, acc=0.9624181389808655, loss=0.1171826720237732
test: epoch 29, loss 1.9376364946365356, acc=0.4307304918766022, loss=1.9376364946365356
train: epoch 30, loss 0.11577076464891434, acc=0.9618136286735535, loss=0.11577076464891434
test: epoch 30, loss 2.021851062774658, acc=0.4080604612827301, loss=2.021851062774658
train: epoch 31, loss 0.10262198746204376, acc=0.9670528769493103, loss=0.10262198746204376
test: epoch 31, loss 2.0903663635253906, acc=0.4710327386856079, loss=2.0903663635253906
train: epoch 32, loss 0.1143919974565506, acc=0.9619647264480591, loss=0.1143919974565506
test: epoch 32, loss 2.2213690280914307, acc=0.45591938495635986, loss=2.2213690280914307
train: epoch 33, loss 0.11548752337694168, acc=0.9624685049057007, loss=0.11548752337694168
test: epoch 33, loss 1.3612788915634155, acc=0.5591939687728882, loss=1.3612788915634155
train: epoch 34, loss 0.11241783946752548, acc=0.9630226492881775, loss=0.11241783946752548
test: epoch 34, loss 1.6013778448104858, acc=0.48614609241485596, loss=1.6013778448104858
train: epoch 35, loss 0.10304488241672516, acc=0.9652896523475647, loss=0.10304488241672516
test: epoch 35, loss 1.2709921598434448, acc=0.5642317533493042, loss=1.2709921598434448
train: epoch 36, loss 0.0968940481543541, acc=0.9688665270805359, loss=0.0968940481543541
test: epoch 36, loss 1.7768601179122925, acc=0.49370276927948, loss=1.7768601179122925
train: epoch 37, loss 0.10052639245986938, acc=0.9671033024787903, loss=0.10052639245986938
test: epoch 37, loss 1.6659600734710693, acc=0.501259446144104, loss=1.6659600734710693
train: epoch 38, loss 0.10039609670639038, acc=0.9677581787109375, loss=0.10039609670639038
test: epoch 38, loss 2.3661649227142334, acc=0.49370276927948, loss=2.3661649227142334
train: epoch 39, loss 0.10684927552938461, acc=0.9663476347923279, loss=0.10684927552938461
test: epoch 39, loss 1.6279693841934204, acc=0.41813603043556213, loss=1.6279693841934204
train: epoch 40, loss 0.09728161990642548, acc=0.9689168930053711, loss=0.09728161990642548
test: epoch 40, loss 1.513728141784668, acc=0.5214105844497681, loss=1.513728141784668
train: epoch 41, loss 0.09658118337392807, acc=0.9685642123222351, loss=0.09658118337392807
test: epoch 41, loss 1.7673767805099487, acc=0.4634760618209839, loss=1.7673767805099487
train: epoch 42, loss 0.11137986183166504, acc=0.9647858738899231, loss=0.11137986183166504
test: epoch 42, loss 1.4234023094177246, acc=0.5314861536026001, loss=1.4234023094177246
train: epoch 43, loss 0.09430805593729019, acc=0.9702267050743103, loss=0.09430805593729019
test: epoch 43, loss 2.1424150466918945, acc=0.44584381580352783, loss=2.1424150466918945
train: epoch 44, loss 0.09462130814790726, acc=0.9693703055381775, loss=0.09462130814790726
test: epoch 44, loss 1.7089143991470337, acc=0.4659949541091919, loss=1.7089143991470337
train: epoch 45, loss 0.09881822019815445, acc=0.9677581787109375, loss=0.09881822019815445
test: epoch 45, loss 1.901031255722046, acc=0.45340049266815186, loss=1.901031255722046
train: epoch 46, loss 0.08803853392601013, acc=0.9723929762840271, loss=0.08803853392601013
test: epoch 46, loss 1.7032039165496826, acc=0.48866498470306396, loss=1.7032039165496826
train: epoch 47, loss 0.08438179641962051, acc=0.9730478525161743, loss=0.08438179641962051
test: epoch 47, loss 1.4697431325912476, acc=0.5566750764846802, loss=1.4697431325912476
train: epoch 48, loss 0.08929748088121414, acc=0.9701763391494751, loss=0.08929748088121414
test: epoch 48, loss 1.7156403064727783, acc=0.5365239381790161, loss=1.7156403064727783
train: epoch 49, loss 0.07935980707406998, acc=0.9736019968986511, loss=0.07935980707406998
test: epoch 49, loss 1.2677981853485107, acc=0.5692695379257202, loss=1.2677981853485107
train: epoch 50, loss 0.08501022309064865, acc=0.9719899296760559, loss=0.08501022309064865
test: epoch 50, loss 1.5401585102081299, acc=0.5188916921615601, loss=1.5401585102081299
train: epoch 51, loss 0.08750531822443008, acc=0.9724937081336975, loss=0.08750531822443008
test: epoch 51, loss 1.5373151302337646, acc=0.5793451070785522, loss=1.5373151302337646
train: epoch 52, loss 0.08403152227401733, acc=0.9742065668106079, loss=0.08403152227401733
test: epoch 52, loss 1.5528006553649902, acc=0.498740553855896, loss=1.5528006553649902
train: epoch 53, loss 0.08135563880205154, acc=0.9735516309738159, loss=0.08135563880205154
test: epoch 53, loss 1.6046491861343384, acc=0.45340049266815186, loss=1.6046491861343384
train: epoch 54, loss 0.07689381390810013, acc=0.9750629663467407, loss=0.07689381390810013
test: epoch 54, loss 1.3219380378723145, acc=0.6272040009498596, loss=1.3219380378723145
train: epoch 55, loss 0.07471809536218643, acc=0.9767758250236511, loss=0.07471809536218643
test: epoch 55, loss 1.5714420080184937, acc=0.503778338432312, loss=1.5714420080184937
train: epoch 56, loss 0.09052998572587967, acc=0.9721914529800415, loss=0.09052998572587967
test: epoch 56, loss 1.5610452890396118, acc=0.5289672613143921, loss=1.5610452890396118
train: epoch 57, loss 0.08318574726581573, acc=0.9745591878890991, loss=0.08318574726581573
test: epoch 57, loss 1.2509714365005493, acc=0.6120907068252563, loss=1.2509714365005493
train: epoch 58, loss 0.07454703003168106, acc=0.9773299694061279, loss=0.07454703003168106
test: epoch 58, loss 1.4898948669433594, acc=0.5465995073318481, loss=1.4898948669433594
train: epoch 59, loss 0.07703521102666855, acc=0.9748110771179199, loss=0.07703521102666855
test: epoch 59, loss 1.111796259880066, acc=0.5717884302139282, loss=1.111796259880066
train: epoch 60, loss 0.07635048031806946, acc=0.9753652215003967, loss=0.07635048031806946
test: epoch 60, loss 1.6568856239318848, acc=0.5390428304672241, loss=1.6568856239318848
train: epoch 61, loss 0.08664426952600479, acc=0.9736524224281311, loss=0.08664426952600479
test: epoch 61, loss 0.983044445514679, acc=0.6372795701026917, loss=0.983044445514679
train: epoch 62, loss 0.0717034786939621, acc=0.9780856370925903, loss=0.0717034786939621
test: epoch 62, loss 1.2353414297103882, acc=0.6322417855262756, loss=1.2353414297103882
train: epoch 63, loss 0.07577857375144958, acc=0.9762720465660095, loss=0.07577857375144958
test: epoch 63, loss 1.6308492422103882, acc=0.5541561841964722, loss=1.6308492422103882
train: epoch 64, loss 0.06149432063102722, acc=0.9814609289169312, loss=0.06149432063102722
test: epoch 64, loss 1.3350034952163696, acc=0.6649873852729797, loss=1.3350034952163696
train: epoch 65, loss 0.07684716582298279, acc=0.9769773483276367, loss=0.07684716582298279
test: epoch 65, loss 1.3059916496276855, acc=0.6649873852729797, loss=1.3059916496276855
train: epoch 66, loss 0.07490140199661255, acc=0.9778337478637695, loss=0.07490140199661255
test: epoch 66, loss 1.0230003595352173, acc=0.6523929238319397, loss=1.0230003595352173
train: epoch 67, loss 0.07565347850322723, acc=0.9765743017196655, loss=0.07565347850322723
test: epoch 67, loss 1.0028753280639648, acc=0.7229219079017639, loss=1.0028753280639648
train: epoch 68, loss 0.06444964557886124, acc=0.9810579419136047, loss=0.06444964557886124
test: epoch 68, loss 1.2488884925842285, acc=0.6624684929847717, loss=1.2488884925842285
train: epoch 69, loss 0.07332217693328857, acc=0.9767758250236511, loss=0.07332217693328857
test: epoch 69, loss 1.1206390857696533, acc=0.6775818467140198, loss=1.1206390857696533
train: epoch 70, loss 0.06281573325395584, acc=0.9794458150863647, loss=0.06281573325395584
test: epoch 70, loss 1.0571436882019043, acc=0.7279596924781799, loss=1.0571436882019043
train: epoch 71, loss 0.05968744307756424, acc=0.9807556867599487, loss=0.05968744307756424
test: epoch 71, loss 0.7027486562728882, acc=0.7304785847663879, loss=0.7027486562728882
train: epoch 72, loss 0.05911135673522949, acc=0.9816120862960815, loss=0.05911135673522949
test: epoch 72, loss 0.6291751861572266, acc=0.7909319996833801, loss=0.6291751861572266
train: epoch 73, loss 0.06905994564294815, acc=0.9801007509231567, loss=0.06905994564294815
test: epoch 73, loss 0.717603862285614, acc=0.7732997536659241, loss=0.717603862285614
train: epoch 74, loss 0.053288549184799194, acc=0.9841309785842896, loss=0.053288549184799194
test: epoch 74, loss 0.45982012152671814, acc=0.8337531685829163, loss=0.45982012152671814
train: epoch 75, loss 0.05914589390158653, acc=0.9827203750610352, loss=0.05914589390158653
test: epoch 75, loss 0.7058709859848022, acc=0.8110831379890442, loss=0.7058709859848022
train: epoch 76, loss 0.05942656472325325, acc=0.981712818145752, loss=0.05942656472325325
test: epoch 76, loss 0.7181677222251892, acc=0.8564231991767883, loss=0.7181677222251892
train: epoch 77, loss 0.05194348096847534, acc=0.9841309785842896, loss=0.05194348096847534
test: epoch 77, loss 0.48798349499702454, acc=0.8186398148536682, loss=0.48798349499702454
train: epoch 78, loss 0.058217477053403854, acc=0.9822165966033936, loss=0.058217477053403854
test: epoch 78, loss 0.32833853363990784, acc=0.8992443084716797, loss=0.32833853363990784
train: epoch 79, loss 0.04068296030163765, acc=0.9887657165527344, loss=0.04068296030163765
test: epoch 79, loss 0.814825177192688, acc=0.8740554451942444, loss=0.814825177192688
train: epoch 80, loss 0.0525076687335968, acc=0.984886646270752, loss=0.0525076687335968
test: epoch 80, loss 0.5043901205062866, acc=0.8740554451942444, loss=0.5043901205062866
train: epoch 81, loss 0.04551747068762779, acc=0.9872543811798096, loss=0.04551747068762779
test: epoch 81, loss 0.3712612986564636, acc=0.8992443084716797, loss=0.3712612986564636
train: epoch 82, loss 0.04382477328181267, acc=0.987103283405304, loss=0.04382477328181267
test: epoch 82, loss 0.22240586578845978, acc=0.9370276927947998, loss=0.22240586578845978
train: epoch 83, loss 0.043021321296691895, acc=0.9876574277877808, loss=0.043021321296691895
test: epoch 83, loss 0.2943792939186096, acc=0.9294710159301758, loss=0.2943792939186096
train: epoch 84, loss 0.03519251197576523, acc=0.9901763200759888, loss=0.03519251197576523
test: epoch 84, loss 0.29491865634918213, acc=0.9093198776245117, loss=0.29491865634918213
train: epoch 85, loss 0.03302076458930969, acc=0.9917380213737488, loss=0.03302076458930969
test: epoch 85, loss 0.275353342294693, acc=0.9294710159301758, loss=0.275353342294693
train: epoch 86, loss 0.03832685947418213, acc=0.9900755882263184, loss=0.03832685947418213
test: epoch 86, loss 0.08181466907262802, acc=0.989924430847168, loss=0.08181466907262802
train: epoch 87, loss 0.030905190855264664, acc=0.9912846088409424, loss=0.030905190855264664
test: epoch 87, loss 0.1828162670135498, acc=0.9496221542358398, loss=0.1828162670135498
train: epoch 88, loss 0.03429555520415306, acc=0.9916876554489136, loss=0.03429555520415306
test: epoch 88, loss 0.09668374061584473, acc=0.9697732925415039, loss=0.09668374061584473
train: epoch 89, loss 0.025120355188846588, acc=0.9941058158874512, loss=0.025120355188846588
test: epoch 89, loss 0.07885167747735977, acc=0.9773299694061279, loss=0.07885167747735977
train: epoch 90, loss 0.023734750226140022, acc=0.994307279586792, loss=0.023734750226140022
test: epoch 90, loss 0.024829436093568802, acc=0.989924430847168, loss=0.024829436093568802
train: epoch 91, loss 0.017237553372979164, acc=0.9957178831100464, loss=0.017237553372979164
test: epoch 91, loss 0.0051338220946490765, acc=1.0, loss=0.0051338220946490765
