# ["--N=40", "--n_epochs=250", "--batch_size=32", "--lr=0.001", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=1", "--n_layers=3", "--save_run=1", "--n_symbols=162"]
Namespace(n_summands=2, N=40, test_split=0.1, data_scaling=50, one_hot=True, receiver_embed_dim=64, n_layers=3, n_symbols=162, temperature=2.0, temp_decay=0.995, early_stopping_acc=0.99, n_runs=1, save_run=True, random_seed=1673514172, checkpoint_dir=None, preemptable=False, checkpoint_freq=0, validation_freq=1, n_epochs=250, load_from_checkpoint=None, no_cuda=True, batch_size=32, optimizer='adam', lr=0.001, update_freq=1, vocab_size=10, max_len=1, tensorboard=False, tensorboard_dir='runs/', distributed_port=18363, fp16=False, cuda=False, device=device(type='cpu'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'))
train: epoch 1, loss 2.6711173057556152, acc=0.1313284933567047, loss=2.6711173057556152
test: epoch 1, loss 4.6754961013793945, acc=0.05684071406722069, loss=4.6754961013793945
train: epoch 2, loss 1.5723556280136108, acc=0.35377395153045654, loss=1.5723556280136108
test: epoch 2, loss 3.624807119369507, acc=0.12227363139390945, loss=3.624807119369507
train: epoch 3, loss 1.1622459888458252, acc=0.5021414160728455, loss=1.1622459888458252
test: epoch 3, loss 3.6782193183898926, acc=0.1625908762216568, loss=3.6782193183898926
train: epoch 4, loss 0.8733456134796143, acc=0.6362326741218567, loss=0.8733456134796143
test: epoch 4, loss 3.4108998775482178, acc=0.19762061536312103, loss=3.4108998775482178
train: epoch 5, loss 0.8250598907470703, acc=0.6533377170562744, loss=0.8250598907470703
test: epoch 5, loss 3.0962331295013428, acc=0.2524785101413727, loss=3.0962331295013428
train: epoch 6, loss 0.6598565578460693, acc=0.730046272277832, loss=0.6598565578460693
test: epoch 6, loss 3.0175178050994873, acc=0.20951750874519348, loss=3.0175178050994873
train: epoch 7, loss 0.5516510009765625, acc=0.7815333604812622, loss=0.5516510009765625
test: epoch 7, loss 3.3236498832702637, acc=0.19960343837738037, loss=3.3236498832702637
train: epoch 8, loss 0.4539830982685089, acc=0.8268869519233704, loss=0.4539830982685089
test: epoch 8, loss 3.170194625854492, acc=0.22141440212726593, loss=3.170194625854492
train: epoch 9, loss 0.39832204580307007, acc=0.8520290851593018, loss=0.39832204580307007
test: epoch 9, loss 2.981572151184082, acc=0.2828816771507263, loss=2.981572151184082
train: epoch 10, loss 0.3601107895374298, acc=0.8667812347412109, loss=0.3601107895374298
test: epoch 10, loss 2.2646901607513428, acc=0.3007270395755768, loss=2.2646901607513428
train: epoch 11, loss 0.2494731843471527, acc=0.912756085395813, loss=0.2494731843471527
test: epoch 11, loss 2.18645977973938, acc=0.34633180499076843, loss=2.18645977973938
train: epoch 12, loss 0.2059820592403412, acc=0.9287508130073547, loss=0.2059820592403412
test: epoch 12, loss 2.655031204223633, acc=0.3390614688396454, loss=2.655031204223633
train: epoch 13, loss 0.18638046085834503, acc=0.9358228445053101, loss=0.18638046085834503
test: epoch 13, loss 2.474210262298584, acc=0.3165895640850067, loss=2.474210262298584
train: epoch 14, loss 0.16191738843917847, acc=0.9465697407722473, loss=0.16191738843917847
test: epoch 14, loss 2.5170133113861084, acc=0.3635161817073822, loss=2.5170133113861084
train: epoch 15, loss 0.15370823442935944, acc=0.9501520395278931, loss=0.15370823442935944
test: epoch 15, loss 2.456131935119629, acc=0.4058162569999695, loss=2.456131935119629
train: epoch 16, loss 0.14315658807754517, acc=0.9538136124610901, loss=0.14315658807754517
test: epoch 16, loss 2.6463210582733154, acc=0.36087244749069214, loss=2.6463210582733154
train: epoch 17, loss 0.13133692741394043, acc=0.9573694467544556, loss=0.13133692741394043
test: epoch 17, loss 2.3446590900421143, acc=0.3721083998680115, loss=2.3446590900421143
train: epoch 18, loss 0.13003522157669067, acc=0.9580700397491455, loss=0.13003522157669067
test: epoch 18, loss 2.3774921894073486, acc=0.41837409138679504, loss=2.3774921894073486
train: epoch 19, loss 0.11669250577688217, acc=0.9628023505210876, loss=0.11669250577688217
test: epoch 19, loss 2.633378744125366, acc=0.3826833963394165, loss=2.633378744125366
train: epoch 20, loss 0.11365730315446854, acc=0.964097797870636, loss=0.11365730315446854
test: epoch 20, loss 2.2971408367156982, acc=0.42894911766052246, loss=2.2971408367156982
train: epoch 21, loss 0.11252634972333908, acc=0.9646662473678589, loss=0.11252634972333908
test: epoch 21, loss 2.535688638687134, acc=0.38929280638694763, loss=2.535688638687134
train: epoch 22, loss 0.11268944293260574, acc=0.9653007388114929, loss=0.11268944293260574
test: epoch 22, loss 2.281569004058838, acc=0.4203568994998932, loss=2.281569004058838
train: epoch 23, loss 0.10201777517795563, acc=0.9682220816612244, loss=0.10201777517795563
test: epoch 23, loss 2.5795233249664307, acc=0.40846002101898193, loss=2.5795233249664307
train: epoch 24, loss 0.09798724949359894, acc=0.9690812826156616, loss=0.09798724949359894
test: epoch 24, loss 2.6618564128875732, acc=0.40383344888687134, loss=2.6618564128875732
train: epoch 25, loss 0.09953746944665909, acc=0.9690284132957458, loss=0.09953746944665909
test: epoch 25, loss 2.1997883319854736, acc=0.41374751925468445, loss=2.1997883319854736
train: epoch 26, loss 0.09505272656679153, acc=0.9706014394760132, loss=0.09505272656679153
test: epoch 26, loss 2.2899630069732666, acc=0.4309319257736206, loss=2.2899630069732666
train: epoch 27, loss 0.09140980988740921, acc=0.9716854095458984, loss=0.09140980988740921
test: epoch 27, loss 2.852224349975586, acc=0.37012559175491333, loss=2.852224349975586
train: epoch 28, loss 0.09600701928138733, acc=0.9710773229598999, loss=0.09600701928138733
test: epoch 28, loss 2.2317886352539062, acc=0.4633179008960724, loss=2.2317886352539062
train: epoch 29, loss 0.08930537104606628, acc=0.9730204939842224, loss=0.08930537104606628
test: epoch 29, loss 2.424421548843384, acc=0.43886318802833557, loss=2.424421548843384
train: epoch 30, loss 0.09058646857738495, acc=0.9725181460380554, loss=0.09058646857738495
test: epoch 30, loss 2.7320632934570312, acc=0.41903501749038696, loss=2.7320632934570312
train: epoch 31, loss 0.08565276116132736, acc=0.9725578427314758, loss=0.08565276116132736
test: epoch 31, loss 1.8141082525253296, acc=0.4540647864341736, loss=1.8141082525253296
train: epoch 32, loss 0.08579421788454056, acc=0.974263072013855, loss=0.08579421788454056
test: epoch 32, loss 2.034055709838867, acc=0.4732320010662079, loss=2.034055709838867
train: epoch 33, loss 0.08805043995380402, acc=0.9728618860244751, loss=0.08805043995380402
test: epoch 33, loss 2.078352212905884, acc=0.42894911766052246, loss=2.078352212905884
train: epoch 34, loss 0.08511907607316971, acc=0.9736549854278564, loss=0.08511907607316971
test: epoch 34, loss 2.1953930854797363, acc=0.46596166491508484, loss=2.1953930854797363
train: epoch 35, loss 0.0818084329366684, acc=0.975095808506012, loss=0.0818084329366684
test: epoch 35, loss 1.9618154764175415, acc=0.43886318802833557, loss=1.9618154764175415
train: epoch 36, loss 0.08192837238311768, acc=0.9751619100570679, loss=0.08192837238311768
test: epoch 36, loss 2.0704023838043213, acc=0.509583592414856, loss=2.0704023838043213
train: epoch 37, loss 0.07836074382066727, acc=0.9765366911888123, loss=0.07836074382066727
test: epoch 37, loss 1.8540639877319336, acc=0.5082617402076721, loss=1.8540639877319336
train: epoch 38, loss 0.08108582347631454, acc=0.9750826358795166, loss=0.08108582347631454
test: epoch 38, loss 2.131899356842041, acc=0.4970257878303528, loss=2.131899356842041
train: epoch 39, loss 0.07675918936729431, acc=0.9764441251754761, loss=0.07675918936729431
test: epoch 39, loss 2.2049996852874756, acc=0.4507600665092468, loss=2.2049996852874756
train: epoch 40, loss 0.07638359069824219, acc=0.9769332408905029, loss=0.07638359069824219
test: epoch 40, loss 2.1846728324890137, acc=0.4487772583961487, loss=2.1846728324890137
train: epoch 41, loss 0.07372571527957916, acc=0.9781890511512756, loss=0.07372571527957916
test: epoch 41, loss 2.0758883953094482, acc=0.5082617402076721, loss=2.0758883953094482
train: epoch 42, loss 0.07161771506071091, acc=0.9780303835868835, loss=0.07161771506071091
test: epoch 42, loss 2.225658655166626, acc=0.5009914040565491, loss=2.225658655166626
train: epoch 43, loss 0.07514762878417969, acc=0.9777660369873047, loss=0.07514762878417969
test: epoch 43, loss 2.2450332641601562, acc=0.5188367366790771, loss=2.2450332641601562
train: epoch 44, loss 0.07400894910097122, acc=0.9774223566055298, loss=0.07400894910097122
test: epoch 44, loss 1.6049362421035767, acc=0.5723727941513062, loss=1.6049362421035767
train: epoch 45, loss 0.07288546115159988, acc=0.9783344268798828, loss=0.07288546115159988
test: epoch 45, loss 1.9773180484771729, acc=0.509583592414856, loss=1.9773180484771729
train: epoch 46, loss 0.07809173315763474, acc=0.9773297905921936, loss=0.07809173315763474
test: epoch 46, loss 1.7656917572021484, acc=0.5313946008682251, loss=1.7656917572021484
train: epoch 47, loss 0.06831761449575424, acc=0.9795109033584595, loss=0.06831761449575424
test: epoch 47, loss 1.6747130155563354, acc=0.5611368417739868, loss=1.6747130155563354
train: epoch 48, loss 0.0671570897102356, acc=0.9792994260787964, loss=0.0671570897102356
test: epoch 48, loss 1.8339223861694336, acc=0.5789821743965149, loss=1.8339223861694336
train: epoch 49, loss 0.07108674198389053, acc=0.9785988330841064, loss=0.07108674198389053
test: epoch 49, loss 1.6424719095230103, acc=0.5855915546417236, loss=1.6424719095230103
train: epoch 50, loss 0.06924910098314285, acc=0.9791407585144043, loss=0.06924910098314285
test: epoch 50, loss 1.3499540090560913, acc=0.6080634593963623, loss=1.3499540090560913
train: epoch 51, loss 0.06407596915960312, acc=0.9808856844902039, loss=0.06407596915960312
test: epoch 51, loss 1.580053448677063, acc=0.6087244153022766, loss=1.580053448677063
train: epoch 52, loss 0.07125721871852875, acc=0.9788499474525452, loss=0.07125721871852875
test: epoch 52, loss 1.5404211282730103, acc=0.6252478361129761, loss=1.5404211282730103
train: epoch 53, loss 0.06574928015470505, acc=0.9805287718772888, loss=0.06574928015470505
test: epoch 53, loss 1.3102737665176392, acc=0.6622604131698608, loss=1.3102737665176392
train: epoch 54, loss 0.06728103011846542, acc=0.9798810482025146, loss=0.06728103011846542
test: epoch 54, loss 1.2318042516708374, acc=0.6629213690757751, loss=1.2318042516708374
train: epoch 55, loss 0.064730703830719, acc=0.9808327555656433, loss=0.064730703830719
test: epoch 55, loss 1.4939097166061401, acc=0.6120290756225586, loss=1.4939097166061401
train: epoch 56, loss 0.0678199976682663, acc=0.9804494380950928, loss=0.0678199976682663
test: epoch 56, loss 0.9655793905258179, acc=0.7230667471885681, loss=0.9655793905258179
train: epoch 57, loss 0.06358786672353745, acc=0.9813879728317261, loss=0.06358786672353745
test: epoch 57, loss 1.2761485576629639, acc=0.6523463129997253, loss=1.2761485576629639
train: epoch 58, loss 0.0669960305094719, acc=0.980317234992981, loss=0.0669960305094719
test: epoch 58, loss 1.1690853834152222, acc=0.6972901225090027, loss=1.1690853834152222
train: epoch 59, loss 0.06172609329223633, acc=0.9824983477592468, loss=0.06172609329223633
test: epoch 59, loss 1.206982970237732, acc=0.7157964110374451, loss=1.206982970237732
train: epoch 60, loss 0.06041165068745613, acc=0.9826173186302185, loss=0.06041165068745613
test: epoch 60, loss 1.0600942373275757, acc=0.7124917507171631, loss=1.0600942373275757
train: epoch 61, loss 0.06012212112545967, acc=0.982511579990387, loss=0.06012212112545967
test: epoch 61, loss 1.2031913995742798, acc=0.7263714671134949, loss=1.2031913995742798
train: epoch 62, loss 0.05976034700870514, acc=0.9826569557189941, loss=0.05976034700870514
test: epoch 62, loss 0.8339122533798218, acc=0.7660277485847473, loss=0.8339122533798218
train: epoch 63, loss 0.055525559931993484, acc=0.9841507077217102, loss=0.055525559931993484
test: epoch 63, loss 1.1661375761032104, acc=0.744216799736023, loss=1.1661375761032104
train: epoch 64, loss 0.055862631648778915, acc=0.9833443760871887, loss=0.055862631648778915
test: epoch 64, loss 0.9111908078193665, acc=0.7633839845657349, loss=0.9111908078193665
train: epoch 65, loss 0.05773809552192688, acc=0.9838201999664307, loss=0.05773809552192688
test: epoch 65, loss 0.8705822229385376, acc=0.7759418487548828, loss=0.8705822229385376
train: epoch 66, loss 0.05468503013253212, acc=0.9845076203346252, loss=0.05468503013253212
test: epoch 66, loss 0.7667936086654663, acc=0.788499653339386, loss=0.7667936086654663
train: epoch 67, loss 0.05204666405916214, acc=0.9854329228401184, loss=0.05204666405916214
test: epoch 67, loss 0.7347385287284851, acc=0.8089887499809265, loss=0.7347385287284851
train: epoch 68, loss 0.052844345569610596, acc=0.9856708645820618, loss=0.052844345569610596
test: epoch 68, loss 0.6475858688354492, acc=0.8155981302261353, loss=0.6475858688354492
train: epoch 69, loss 0.0496920645236969, acc=0.9861335158348083, loss=0.0496920645236969
test: epoch 69, loss 0.8950232267379761, acc=0.8070059418678284, loss=0.8950232267379761
train: epoch 70, loss 0.05558851733803749, acc=0.9852743148803711, loss=0.05558851733803749
test: epoch 70, loss 0.56734699010849, acc=0.8618638515472412, loss=0.56734699010849
train: epoch 71, loss 0.049420297145843506, acc=0.986807644367218, loss=0.049420297145843506
test: epoch 71, loss 0.5230634808540344, acc=0.8856576085090637, loss=0.5230634808540344
train: epoch 72, loss 0.04710058122873306, acc=0.9865829348564148, loss=0.04710058122873306
test: epoch 72, loss 0.5623952150344849, acc=0.8664904236793518, loss=0.5623952150344849
train: epoch 73, loss 0.04250258952379227, acc=0.9883146286010742, loss=0.04250258952379227
test: epoch 73, loss 0.5026077032089233, acc=0.8929279446601868, loss=0.5026077032089233
train: epoch 74, loss 0.04696248844265938, acc=0.9870059490203857, loss=0.04696248844265938
test: epoch 74, loss 0.4306636154651642, acc=0.8942498564720154, loss=0.4306636154651642
train: epoch 75, loss 0.04202272370457649, acc=0.9885922074317932, loss=0.04202272370457649
test: epoch 75, loss 0.47456714510917664, acc=0.912756085395813, loss=0.47456714510917664
train: epoch 76, loss 0.042296115309000015, acc=0.9888433814048767, loss=0.042296115309000015
test: epoch 76, loss 0.45038607716560364, acc=0.9015201330184937, loss=0.45038607716560364
train: epoch 77, loss 0.03823218494653702, acc=0.9900462627410889, loss=0.03823218494653702
test: epoch 77, loss 0.44754430651664734, acc=0.9147389531135559, loss=0.44754430651664734
train: epoch 78, loss 0.04228411614894867, acc=0.9888830184936523, loss=0.04228411614894867
test: epoch 78, loss 0.3454967439174652, acc=0.9339061379432678, loss=0.3454967439174652
train: epoch 79, loss 0.03460812568664551, acc=0.9908658266067505, loss=0.03460812568664551
test: epoch 79, loss 0.4237745404243469, acc=0.9213483333587646, loss=0.4237745404243469
train: epoch 80, loss 0.03578053414821625, acc=0.991249144077301, loss=0.03578053414821625
test: epoch 80, loss 0.32753950357437134, acc=0.9418374300003052, loss=0.32753950357437134
train: epoch 81, loss 0.03550565242767334, acc=0.9914474487304688, loss=0.03550565242767334
test: epoch 81, loss 0.25084853172302246, acc=0.9497686624526978, loss=0.25084853172302246
train: epoch 82, loss 0.03756767138838768, acc=0.9908261895179749, loss=0.03756767138838768
test: epoch 82, loss 0.23852962255477905, acc=0.9444811344146729, loss=0.23852962255477905
train: epoch 83, loss 0.029267335310578346, acc=0.9926239252090454, loss=0.029267335310578346
test: epoch 83, loss 0.2907603979110718, acc=0.9510905742645264, loss=0.2907603979110718
train: epoch 84, loss 0.032704003155231476, acc=0.9920951724052429, loss=0.032704003155231476
test: epoch 84, loss 0.2832409739494324, acc=0.9477858543395996, loss=0.2832409739494324
train: epoch 85, loss 0.03262832388281822, acc=0.9925445914268494, loss=0.03262832388281822
test: epoch 85, loss 0.28043606877326965, acc=0.9391936659812927, loss=0.28043606877326965
train: epoch 86, loss 0.031670574098825455, acc=0.9924256205558777, loss=0.031670574098825455
test: epoch 86, loss 0.24280373752117157, acc=0.9477858543395996, loss=0.24280373752117157
train: epoch 87, loss 0.0290302075445652, acc=0.993007242679596, loss=0.0290302075445652
test: epoch 87, loss 0.18414688110351562, acc=0.9623265266418457, loss=0.18414688110351562
train: epoch 88, loss 0.03080504573881626, acc=0.9926239252090454, loss=0.03080504573881626
test: epoch 88, loss 0.19500310719013214, acc=0.9583608508110046, loss=0.19500310719013214
train: epoch 89, loss 0.025742970407009125, acc=0.9936946630477905, loss=0.025742970407009125
test: epoch 89, loss 0.22847461700439453, acc=0.9563780426979065, loss=0.22847461700439453
train: epoch 90, loss 0.02770351804792881, acc=0.9941969513893127, loss=0.02770351804792881
test: epoch 90, loss 0.23330184817314148, acc=0.9550561904907227, loss=0.23330184817314148
train: epoch 91, loss 0.030561037361621857, acc=0.9932055473327637, loss=0.030561037361621857
test: epoch 91, loss 0.18787480890750885, acc=0.9610046148300171, loss=0.18787480890750885
train: epoch 92, loss 0.02851392887532711, acc=0.9927164316177368, loss=0.02851392887532711
test: epoch 92, loss 0.2534940540790558, acc=0.9583608508110046, loss=0.2534940540790558
train: epoch 93, loss 0.027680914849042892, acc=0.9930469393730164, loss=0.027680914849042892
test: epoch 93, loss 0.13511182367801666, acc=0.9603436589241028, loss=0.13511182367801666
train: epoch 94, loss 0.02308209240436554, acc=0.9943291544914246, loss=0.02308209240436554
test: epoch 94, loss 0.18479986488819122, acc=0.9610046148300171, loss=0.18479986488819122
train: epoch 95, loss 0.022369293496012688, acc=0.9946199655532837, loss=0.022369293496012688
test: epoch 95, loss 0.2149842083454132, acc=0.959021806716919, loss=0.2149842083454132
train: epoch 96, loss 0.026461325585842133, acc=0.9948182702064514, loss=0.026461325585842133
test: epoch 96, loss 0.18066510558128357, acc=0.9576999545097351, loss=0.18066510558128357
train: epoch 97, loss 0.022158997133374214, acc=0.99505615234375, loss=0.022158997133374214
test: epoch 97, loss 0.1863902360200882, acc=0.9616655707359314, loss=0.1863902360200882
train: epoch 98, loss 0.024230720475316048, acc=0.9950165152549744, loss=0.024230720475316048
test: epoch 98, loss 0.1732056885957718, acc=0.9643093347549438, loss=0.1732056885957718
train: epoch 99, loss 0.023873168975114822, acc=0.9947389364242554, loss=0.023873168975114822
test: epoch 99, loss 0.15666088461875916, acc=0.9596827626228333, loss=0.15666088461875916
train: epoch 100, loss 0.018522491678595543, acc=0.9957303404808044, loss=0.018522491678595543
test: epoch 100, loss 0.20279400050640106, acc=0.9616655707359314, loss=0.20279400050640106
train: epoch 101, loss 0.02436763420701027, acc=0.9945670962333679, loss=0.02436763420701027
test: epoch 101, loss 0.1671270728111267, acc=0.9636483788490295, loss=0.1671270728111267
train: epoch 102, loss 0.020552748814225197, acc=0.9957171082496643, loss=0.020552748814225197
test: epoch 102, loss 0.17153429985046387, acc=0.9636483788490295, loss=0.17153429985046387
train: epoch 103, loss 0.020483452826738358, acc=0.9951222538948059, loss=0.020483452826738358
test: epoch 103, loss 0.1387387067079544, acc=0.9636483788490295, loss=0.1387387067079544
train: epoch 104, loss 0.026273461058735847, acc=0.9950958490371704, loss=0.026273461058735847
test: epoch 104, loss 0.18523384630680084, acc=0.9623265266418457, loss=0.18523384630680084
train: epoch 105, loss 0.012763815000653267, acc=0.9964970350265503, loss=0.012763815000653267
test: epoch 105, loss 0.14807218313217163, acc=0.9629874229431152, loss=0.14807218313217163
train: epoch 106, loss 0.02321825549006462, acc=0.9950826168060303, loss=0.02321825549006462
test: epoch 106, loss 0.19103574752807617, acc=0.9596827626228333, loss=0.19103574752807617
train: epoch 107, loss 0.019654512405395508, acc=0.9954395294189453, loss=0.019654512405395508
test: epoch 107, loss 0.2538551688194275, acc=0.955717146396637, loss=0.2538551688194275
train: epoch 108, loss 0.020244920626282692, acc=0.9960476160049438, loss=0.020244920626282692
test: epoch 108, loss 0.22592301666736603, acc=0.9636483788490295, loss=0.22592301666736603
train: epoch 109, loss 0.014517026022076607, acc=0.9969200491905212, loss=0.014517026022076607
test: epoch 109, loss 0.20390595495700836, acc=0.9610046148300171, loss=0.20390595495700836
train: epoch 110, loss 0.02504899725317955, acc=0.9956907033920288, loss=0.02504899725317955
test: epoch 110, loss 0.16323624551296234, acc=0.9616655707359314, loss=0.16323624551296234
train: epoch 111, loss 0.012577848508954048, acc=0.9969860911369324, loss=0.012577848508954048
test: epoch 111, loss 0.1794327348470688, acc=0.9603436589241028, loss=0.1794327348470688
train: epoch 112, loss 0.023038094863295555, acc=0.9955320358276367, loss=0.023038094863295555
test: epoch 112, loss 0.21630804240703583, acc=0.9583608508110046, loss=0.21630804240703583
train: epoch 113, loss 0.018736813217401505, acc=0.9957964420318604, loss=0.018736813217401505
test: epoch 113, loss 0.19254793226718903, acc=0.9616655707359314, loss=0.19254793226718903
train: epoch 114, loss 0.016871144995093346, acc=0.9964838027954102, loss=0.016871144995093346
test: epoch 114, loss 0.23133835196495056, acc=0.9583608508110046, loss=0.23133835196495056
train: epoch 115, loss 0.023675832897424698, acc=0.9952280521392822, loss=0.023675832897424698
test: epoch 115, loss 0.20957064628601074, acc=0.9576999545097351, loss=0.20957064628601074
train: epoch 116, loss 0.02431573159992695, acc=0.9952412247657776, loss=0.02431573159992695
test: epoch 116, loss 0.1515875607728958, acc=0.9623265266418457, loss=0.1515875607728958
train: epoch 117, loss 0.016152601689100266, acc=0.9962854981422424, loss=0.016152601689100266
test: epoch 117, loss 0.1741403192281723, acc=0.9629874229431152, loss=0.1741403192281723
train: epoch 118, loss 0.016780545935034752, acc=0.9964309334754944, loss=0.016780545935034752
test: epoch 118, loss 0.12930487096309662, acc=0.9636483788490295, loss=0.12930487096309662
train: epoch 119, loss 0.014686055481433868, acc=0.9966952800750732, loss=0.014686055481433868
test: epoch 119, loss 0.15763776004314423, acc=0.9682749509811401, loss=0.15763776004314423
train: epoch 120, loss 0.016336411237716675, acc=0.9965763092041016, loss=0.016336411237716675
test: epoch 120, loss 0.12055972218513489, acc=0.9729015231132507, loss=0.12055972218513489
train: epoch 121, loss 0.017419947311282158, acc=0.9970521926879883, loss=0.017419947311282158
test: epoch 121, loss 0.13659201562404633, acc=0.9702577590942383, loss=0.13659201562404633
train: epoch 122, loss 0.024181487038731575, acc=0.9968407154083252, loss=0.024181487038731575
test: epoch 122, loss 0.15513993799686432, acc=0.969596803188324, loss=0.15513993799686432
train: epoch 123, loss 0.014442766085267067, acc=0.9975148439407349, loss=0.014442766085267067
test: epoch 123, loss 0.17378398776054382, acc=0.9729015231132507, loss=0.17378398776054382
train: epoch 124, loss 0.009644020348787308, acc=0.9978453516960144, loss=0.009644020348787308
test: epoch 124, loss 0.16617745161056519, acc=0.973562479019165, loss=0.16617745161056519
train: epoch 125, loss 0.016712410375475883, acc=0.9970125555992126, loss=0.016712410375475883
test: epoch 125, loss 0.19578999280929565, acc=0.9702577590942383, loss=0.19578999280929565
train: epoch 126, loss 0.020993895828723907, acc=0.995915412902832, loss=0.020993895828723907
test: epoch 126, loss 0.15206868946552277, acc=0.973562479019165, loss=0.15206868946552277
train: epoch 127, loss 0.016642669215798378, acc=0.9970918893814087, loss=0.016642669215798378
test: epoch 127, loss 0.10671233385801315, acc=0.9643093347549438, loss=0.10671233385801315
train: epoch 128, loss 0.018968995660543442, acc=0.9963515996932983, loss=0.018968995660543442
test: epoch 128, loss 0.13378900289535522, acc=0.973562479019165, loss=0.13378900289535522
train: epoch 129, loss 0.01177914161235094, acc=0.9974619746208191, loss=0.01177914161235094
test: epoch 129, loss 0.21366190910339355, acc=0.9702577590942383, loss=0.21366190910339355
train: epoch 130, loss 0.016143962740898132, acc=0.9970390200614929, loss=0.016143962740898132
test: epoch 130, loss 0.14353007078170776, acc=0.973562479019165, loss=0.14353007078170776
train: epoch 131, loss 0.021032467484474182, acc=0.9961665272712708, loss=0.021032467484474182
test: epoch 131, loss 0.1849912852048874, acc=0.9715796709060669, loss=0.1849912852048874
train: epoch 132, loss 0.023511121049523354, acc=0.9952676892280579, loss=0.023511121049523354
test: epoch 132, loss 0.12480650842189789, acc=0.9729015231132507, loss=0.12480650842189789
train: epoch 133, loss 0.02002588100731373, acc=0.9959550499916077, loss=0.02002588100731373
test: epoch 133, loss 0.1713116466999054, acc=0.9715796709060669, loss=0.1713116466999054
train: epoch 134, loss 0.01525621023029089, acc=0.9965102672576904, loss=0.01525621023029089
test: epoch 134, loss 0.18485943973064423, acc=0.9689359068870544, loss=0.18485943973064423
train: epoch 135, loss 0.016246771439909935, acc=0.9960872530937195, loss=0.016246771439909935
test: epoch 135, loss 0.17523160576820374, acc=0.9629874229431152, loss=0.17523160576820374
train: epoch 136, loss 0.022010518237948418, acc=0.9953734278678894, loss=0.022010518237948418
test: epoch 136, loss 0.1796972155570984, acc=0.966292142868042, loss=0.1796972155570984
train: epoch 137, loss 0.02169226109981537, acc=0.9954262971878052, loss=0.02169226109981537
test: epoch 137, loss 0.16758300364017487, acc=0.966292142868042, loss=0.16758300364017487
train: epoch 138, loss 0.03266492486000061, acc=0.9931791424751282, loss=0.03266492486000061
test: epoch 138, loss 0.19662511348724365, acc=0.9643093347549438, loss=0.19662511348724365
train: epoch 139, loss 0.025411423295736313, acc=0.9936681985855103, loss=0.025411423295736313
test: epoch 139, loss 0.15559177100658417, acc=0.9709187150001526, loss=0.15559177100658417
train: epoch 140, loss 0.03530576080083847, acc=0.993364155292511, loss=0.03530576080083847
test: epoch 140, loss 0.18150222301483154, acc=0.9702577590942383, loss=0.18150222301483154
train: epoch 141, loss 0.026878904551267624, acc=0.9946067333221436, loss=0.026878904551267624
test: epoch 141, loss 0.19080713391304016, acc=0.9709187150001526, loss=0.19080713391304016
train: epoch 142, loss 0.027404652908444405, acc=0.9949107766151428, loss=0.027404652908444405
test: epoch 142, loss 0.23219513893127441, acc=0.969596803188324, loss=0.23219513893127441
train: epoch 143, loss 0.03297396004199982, acc=0.9940912127494812, loss=0.03297396004199982
test: epoch 143, loss 0.1473013162612915, acc=0.966292142868042, loss=0.1473013162612915
train: epoch 144, loss 0.027559196576476097, acc=0.9951883554458618, loss=0.027559196576476097
test: epoch 144, loss 0.2524360120296478, acc=0.9715796709060669, loss=0.2524360120296478
train: epoch 145, loss 0.020407527685165405, acc=0.996192991733551, loss=0.020407527685165405
test: epoch 145, loss 0.17755714058876038, acc=0.9682749509811401, loss=0.17755714058876038
train: epoch 146, loss 0.02074115350842476, acc=0.996113657951355, loss=0.02074115350842476
test: epoch 146, loss 0.2080385684967041, acc=0.9709187150001526, loss=0.2080385684967041
train: epoch 147, loss 0.015642624348402023, acc=0.9964177012443542, loss=0.015642624348402023
test: epoch 147, loss 0.13939139246940613, acc=0.9722405672073364, loss=0.13939139246940613
train: epoch 148, loss 0.022163841873407364, acc=0.995413064956665, loss=0.022163841873407364
test: epoch 148, loss 0.1349540501832962, acc=0.9709187150001526, loss=0.1349540501832962
train: epoch 149, loss 0.024203307926654816, acc=0.9959021806716919, loss=0.024203307926654816
test: epoch 149, loss 0.16774119436740875, acc=0.9729015231132507, loss=0.16774119436740875
train: epoch 150, loss 0.01509312354028225, acc=0.9976602792739868, loss=0.01509312354028225
test: epoch 150, loss 0.20344409346580505, acc=0.973562479019165, loss=0.20344409346580505
train: epoch 151, loss 0.01863110437989235, acc=0.9969860911369324, loss=0.01863110437989235
test: epoch 151, loss 0.12629958987236023, acc=0.9722405672073364, loss=0.12629958987236023
train: epoch 152, loss 0.011013091541826725, acc=0.9976867437362671, loss=0.011013091541826725
test: epoch 152, loss 0.17462071776390076, acc=0.973562479019165, loss=0.17462071776390076
train: epoch 153, loss 0.009891198016703129, acc=0.9978453516960144, loss=0.009891198016703129
test: epoch 153, loss 0.16787022352218628, acc=0.973562479019165, loss=0.16787022352218628
train: epoch 154, loss 0.011544371955096722, acc=0.9981757998466492, loss=0.011544371955096722
test: epoch 154, loss 0.17177553474903107, acc=0.9742233753204346, loss=0.17177553474903107
train: epoch 155, loss 0.022173535078763962, acc=0.9972769618034363, loss=0.022173535078763962
test: epoch 155, loss 0.1377226710319519, acc=0.973562479019165, loss=0.1377226710319519
train: epoch 156, loss 0.022610342130064964, acc=0.9967085123062134, loss=0.022610342130064964
test: epoch 156, loss 0.20132823288440704, acc=0.9715796709060669, loss=0.20132823288440704
train: epoch 157, loss 0.02318703569471836, acc=0.9968407154083252, loss=0.02318703569471836
test: epoch 157, loss 0.15484997630119324, acc=0.9742233753204346, loss=0.15484997630119324
train: epoch 158, loss 0.02571849524974823, acc=0.9965763092041016, loss=0.02571849524974823
test: epoch 158, loss 0.17507945001125336, acc=0.9729015231132507, loss=0.17507945001125336
train: epoch 159, loss 0.014910168945789337, acc=0.9972769618034363, loss=0.014910168945789337
test: epoch 159, loss 0.21720930933952332, acc=0.9702577590942383, loss=0.21720930933952332
train: epoch 160, loss 0.017064856365323067, acc=0.9973033666610718, loss=0.017064856365323067
test: epoch 160, loss 0.23497392237186432, acc=0.9722405672073364, loss=0.23497392237186432
train: epoch 161, loss 0.02513195388019085, acc=0.9963912963867188, loss=0.02513195388019085
test: epoch 161, loss 0.12560269236564636, acc=0.9748843312263489, loss=0.12560269236564636
train: epoch 162, loss 0.012143164873123169, acc=0.99788498878479, loss=0.012143164873123169
test: epoch 162, loss 0.11463696509599686, acc=0.9762061834335327, loss=0.11463696509599686
train: epoch 163, loss 0.018676429986953735, acc=0.9970125555992126, loss=0.018676429986953735
test: epoch 163, loss 0.1484215259552002, acc=0.9748843312263489, loss=0.1484215259552002
train: epoch 164, loss 0.020808542147278786, acc=0.9969993233680725, loss=0.020808542147278786
test: epoch 164, loss 0.21302126348018646, acc=0.973562479019165, loss=0.21302126348018646
train: epoch 165, loss 0.02654208615422249, acc=0.995836079120636, loss=0.02654208615422249
test: epoch 165, loss 0.19506672024726868, acc=0.973562479019165, loss=0.19506672024726868
train: epoch 166, loss 0.03509483113884926, acc=0.994500994682312, loss=0.03509483113884926
test: epoch 166, loss 0.17527396976947784, acc=0.973562479019165, loss=0.17527396976947784
train: epoch 167, loss 0.022290043532848358, acc=0.9965763092041016, loss=0.022290043532848358
test: epoch 167, loss 0.17096322774887085, acc=0.9748843312263489, loss=0.17096322774887085
train: epoch 168, loss 0.01693659834563732, acc=0.996893584728241, loss=0.01693659834563732
test: epoch 168, loss 0.12887945771217346, acc=0.9755452871322632, loss=0.12887945771217346
train: epoch 169, loss 0.013064553961157799, acc=0.9983741044998169, loss=0.013064553961157799
test: epoch 169, loss 0.1598656326532364, acc=0.9762061834335327, loss=0.1598656326532364
train: epoch 170, loss 0.022810421884059906, acc=0.9968803524971008, loss=0.022810421884059906
test: epoch 170, loss 0.12187175452709198, acc=0.9748843312263489, loss=0.12187175452709198
train: epoch 171, loss 0.00790133886039257, acc=0.9984930753707886, loss=0.00790133886039257
test: epoch 171, loss 0.17479956150054932, acc=0.9755452871322632, loss=0.17479956150054932
train: epoch 172, loss 0.010711095295846462, acc=0.9982419013977051, loss=0.010711095295846462
test: epoch 172, loss 0.16363510489463806, acc=0.973562479019165, loss=0.16363510489463806
train: epoch 173, loss 0.022301802411675453, acc=0.9966292381286621, loss=0.022301802411675453
test: epoch 173, loss 0.153847336769104, acc=0.9748843312263489, loss=0.153847336769104
train: epoch 174, loss 0.02355339750647545, acc=0.9962987303733826, loss=0.02355339750647545
test: epoch 174, loss 0.16352486610412598, acc=0.9729015231132507, loss=0.16352486610412598
train: epoch 175, loss 0.0437052883207798, acc=0.9928750991821289, loss=0.0437052883207798
test: epoch 175, loss 0.12077894061803818, acc=0.9729015231132507, loss=0.12077894061803818
train: epoch 176, loss 0.04595599323511124, acc=0.9916853904724121, loss=0.04595599323511124
test: epoch 176, loss 0.12679240107536316, acc=0.9702577590942383, loss=0.12679240107536316
train: epoch 177, loss 0.036640167236328125, acc=0.992306649684906, loss=0.036640167236328125
test: epoch 177, loss 0.12547798454761505, acc=0.9715796709060669, loss=0.12547798454761505
train: epoch 178, loss 0.037903185933828354, acc=0.9929147362709045, loss=0.037903185933828354
test: epoch 178, loss 0.1478831022977829, acc=0.9729015231132507, loss=0.1478831022977829
train: epoch 179, loss 0.02700384333729744, acc=0.9950958490371704, loss=0.02700384333729744
test: epoch 179, loss 0.10763424634933472, acc=0.9748843312263489, loss=0.10763424634933472
train: epoch 180, loss 0.01418393012136221, acc=0.9969860911369324, loss=0.01418393012136221
test: epoch 180, loss 0.18473605811595917, acc=0.9729015231132507, loss=0.18473605811595917
train: epoch 181, loss 0.033940594643354416, acc=0.994500994682312, loss=0.033940594643354416
test: epoch 181, loss 0.22721952199935913, acc=0.9729015231132507, loss=0.22721952199935913
train: epoch 182, loss 0.03056802973151207, acc=0.9945803284645081, loss=0.03056802973151207
test: epoch 182, loss 0.17931616306304932, acc=0.9709187150001526, loss=0.17931616306304932
train: epoch 183, loss 0.0250661913305521, acc=0.9951619505882263, loss=0.0250661913305521
test: epoch 183, loss 0.1335272341966629, acc=0.9748843312263489, loss=0.1335272341966629
train: epoch 184, loss 0.02259436435997486, acc=0.9955056309700012, loss=0.02259436435997486
test: epoch 184, loss 0.14007139205932617, acc=0.9715796709060669, loss=0.14007139205932617
train: epoch 185, loss 0.04240213334560394, acc=0.9941837191581726, loss=0.04240213334560394
test: epoch 185, loss 0.14728611707687378, acc=0.973562479019165, loss=0.14728611707687378
train: epoch 186, loss 0.023792143911123276, acc=0.9948050379753113, loss=0.023792143911123276
test: epoch 186, loss 0.10559555888175964, acc=0.973562479019165, loss=0.10559555888175964
train: epoch 187, loss 0.019892079755663872, acc=0.9950958490371704, loss=0.019892079755663872
test: epoch 187, loss 0.13112206757068634, acc=0.973562479019165, loss=0.13112206757068634
train: epoch 188, loss 0.038658589124679565, acc=0.9937607645988464, loss=0.038658589124679565
test: epoch 188, loss 0.13044925034046173, acc=0.9722405672073364, loss=0.13044925034046173
train: epoch 189, loss 0.03077804483473301, acc=0.9952412247657776, loss=0.03077804483473301
test: epoch 189, loss 0.14529705047607422, acc=0.9755452871322632, loss=0.14529705047607422
train: epoch 190, loss 0.023894496262073517, acc=0.9959021806716919, loss=0.023894496262073517
test: epoch 190, loss 0.15991000831127167, acc=0.9742233753204346, loss=0.15991000831127167
train: epoch 191, loss 0.022065307945013046, acc=0.9962590932846069, loss=0.022065307945013046
test: epoch 191, loss 0.1616460531949997, acc=0.973562479019165, loss=0.1616460531949997
train: epoch 192, loss 0.03370270878076553, acc=0.9945406317710876, loss=0.03370270878076553
test: epoch 192, loss 0.19196127355098724, acc=0.9729015231132507, loss=0.19196127355098724
train: epoch 193, loss 0.0277413297444582, acc=0.9947521686553955, loss=0.0277413297444582
test: epoch 193, loss 0.10182862728834152, acc=0.9742233753204346, loss=0.10182862728834152
train: epoch 194, loss 0.024038635194301605, acc=0.9958757162094116, loss=0.024038635194301605
test: epoch 194, loss 0.14229696989059448, acc=0.9742233753204346, loss=0.14229696989059448
train: epoch 195, loss 0.043696705251932144, acc=0.9946728348731995, loss=0.043696705251932144
test: epoch 195, loss 0.1666077971458435, acc=0.9742233753204346, loss=0.1666077971458435
train: epoch 196, loss 0.02433205395936966, acc=0.9967085123062134, loss=0.02433205395936966
test: epoch 196, loss 0.1634986400604248, acc=0.9755452871322632, loss=0.1634986400604248
train: epoch 197, loss 0.01204200554639101, acc=0.9980832934379578, loss=0.01204200554639101
test: epoch 197, loss 0.17602543532848358, acc=0.9755452871322632, loss=0.17602543532848358
train: epoch 198, loss 0.026451412588357925, acc=0.9971315264701843, loss=0.026451412588357925
test: epoch 198, loss 0.13683617115020752, acc=0.9755452871322632, loss=0.13683617115020752
train: epoch 199, loss 0.037109389901161194, acc=0.9953469634056091, loss=0.037109389901161194
test: epoch 199, loss 0.20441146194934845, acc=0.9715796709060669, loss=0.20441146194934845
train: epoch 200, loss 0.02725706808269024, acc=0.9943423867225647, loss=0.02725706808269024
test: epoch 200, loss 0.15956659615039825, acc=0.9709187150001526, loss=0.15956659615039825
train: epoch 201, loss 0.0455600842833519, acc=0.9920026659965515, loss=0.0455600842833519
test: epoch 201, loss 0.11122921854257584, acc=0.973562479019165, loss=0.11122921854257584
train: epoch 202, loss 0.0180711317807436, acc=0.9965763092041016, loss=0.0180711317807436
test: epoch 202, loss 0.1388186365365982, acc=0.9762061834335327, loss=0.1388186365365982
train: epoch 203, loss 0.012369447387754917, acc=0.9973958730697632, loss=0.012369447387754917
test: epoch 203, loss 0.1752028465270996, acc=0.973562479019165, loss=0.1752028465270996
train: epoch 204, loss 0.030753670260310173, acc=0.9936285614967346, loss=0.030753670260310173
test: epoch 204, loss 0.14383219182491302, acc=0.973562479019165, loss=0.14383219182491302
train: epoch 205, loss 0.021898210048675537, acc=0.9956246018409729, loss=0.021898210048675537
test: epoch 205, loss 0.16894182562828064, acc=0.9729015231132507, loss=0.16894182562828064
train: epoch 206, loss 0.02132733166217804, acc=0.9957699775695801, loss=0.02132733166217804
test: epoch 206, loss 0.1894419640302658, acc=0.9729015231132507, loss=0.1894419640302658
train: epoch 207, loss 0.027123916894197464, acc=0.9950297474861145, loss=0.027123916894197464
test: epoch 207, loss 0.18133744597434998, acc=0.9702577590942383, loss=0.18133744597434998
train: epoch 208, loss 0.029047947376966476, acc=0.9946463704109192, loss=0.029047947376966476
test: epoch 208, loss 0.12311199307441711, acc=0.9729015231132507, loss=0.12311199307441711
train: epoch 209, loss 0.03740758076310158, acc=0.9933906197547913, loss=0.03740758076310158
test: epoch 209, loss 0.17680886387825012, acc=0.9709187150001526, loss=0.17680886387825012
train: epoch 210, loss 0.04039165750145912, acc=0.9929543733596802, loss=0.04039165750145912
test: epoch 210, loss 0.20093394815921783, acc=0.969596803188324, loss=0.20093394815921783
train: epoch 211, loss 0.02731236442923546, acc=0.9943555593490601, loss=0.02731236442923546
test: epoch 211, loss 0.18892978131771088, acc=0.9715796709060669, loss=0.18892978131771088
train: epoch 212, loss 0.028236957266926765, acc=0.9949371814727783, loss=0.028236957266926765
test: epoch 212, loss 0.17595356702804565, acc=0.973562479019165, loss=0.17595356702804565
train: epoch 213, loss 0.028723428025841713, acc=0.9957567453384399, loss=0.028723428025841713
test: epoch 213, loss 0.12507952749729156, acc=0.973562479019165, loss=0.12507952749729156
train: epoch 214, loss 0.01946905441582203, acc=0.9962062239646912, loss=0.01946905441582203
test: epoch 214, loss 0.16317270696163177, acc=0.9742233753204346, loss=0.16317270696163177
train: epoch 215, loss 0.041999395936727524, acc=0.9935095906257629, loss=0.041999395936727524
test: epoch 215, loss 0.24746885895729065, acc=0.9709187150001526, loss=0.24746885895729065
train: epoch 216, loss 0.06449254602193832, acc=0.9915928840637207, loss=0.06449254602193832
test: epoch 216, loss 0.1808347851037979, acc=0.9689359068870544, loss=0.1808347851037979
train: epoch 217, loss 0.07040072977542877, acc=0.988724410533905, loss=0.07040072977542877
test: epoch 217, loss 0.193442240357399, acc=0.9676139950752258, loss=0.193442240357399
train: epoch 218, loss 0.05761078745126724, acc=0.9889887571334839, loss=0.05761078745126724
test: epoch 218, loss 0.20722845196723938, acc=0.9610046148300171, loss=0.20722845196723938
train: epoch 219, loss 0.05174288526177406, acc=0.9895042777061462, loss=0.05174288526177406
test: epoch 219, loss 0.20444443821907043, acc=0.9689359068870544, loss=0.20444443821907043
train: epoch 220, loss 0.057167354971170425, acc=0.9904825091362, loss=0.057167354971170425
test: epoch 220, loss 0.17140242457389832, acc=0.9676139950752258, loss=0.17140242457389832
train: epoch 221, loss 0.04950610548257828, acc=0.9895439743995667, loss=0.04950610548257828
test: epoch 221, loss 0.17302604019641876, acc=0.9669530987739563, loss=0.17302604019641876
train: epoch 222, loss 0.054377440363168716, acc=0.9887905120849609, loss=0.054377440363168716
test: epoch 222, loss 0.13863611221313477, acc=0.9676139950752258, loss=0.13863611221313477
train: epoch 223, loss 0.08972156047821045, acc=0.9805155396461487, loss=0.08972156047821045
test: epoch 223, loss 0.27882441878318787, acc=0.9464640021324158, loss=0.27882441878318787
train: epoch 224, loss 0.1142084002494812, acc=0.9745274186134338, loss=0.1142084002494812
test: epoch 224, loss 0.20606596767902374, acc=0.9616655707359314, loss=0.20606596767902374
train: epoch 225, loss 0.09658712893724442, acc=0.9842168092727661, loss=0.09658712893724442
test: epoch 225, loss 0.1632917821407318, acc=0.9623265266418457, loss=0.1632917821407318
train: epoch 226, loss 0.07792530208826065, acc=0.982511579990387, loss=0.07792530208826065
test: epoch 226, loss 0.2081732451915741, acc=0.959021806716919, loss=0.2081732451915741
train: epoch 227, loss 0.09414713084697723, acc=0.9826305508613586, loss=0.09414713084697723
test: epoch 227, loss 0.23046346008777618, acc=0.9636483788490295, loss=0.23046346008777618
train: epoch 228, loss 0.044085994362831116, acc=0.9878387451171875, loss=0.044085994362831116
test: epoch 228, loss 0.21285606920719147, acc=0.9669530987739563, loss=0.21285606920719147
train: epoch 229, loss 0.11699533462524414, acc=0.9770257472991943, loss=0.11699533462524414
test: epoch 229, loss 0.2586624026298523, acc=0.953734278678894, loss=0.2586624026298523
train: epoch 230, loss 0.09204760193824768, acc=0.9763383865356445, loss=0.09204760193824768
test: epoch 230, loss 0.1957980841398239, acc=0.9543952345848083, loss=0.1957980841398239
train: epoch 231, loss 0.0979817733168602, acc=0.9805551767349243, loss=0.0979817733168602
test: epoch 231, loss 0.18737244606018066, acc=0.9629874229431152, loss=0.18737244606018066
train: epoch 232, loss 0.07190776616334915, acc=0.9871645569801331, loss=0.07190776616334915
test: epoch 232, loss 0.24781925976276398, acc=0.9656311869621277, loss=0.24781925976276398
train: epoch 233, loss 0.061277225613594055, acc=0.9883146286010742, loss=0.061277225613594055
test: epoch 233, loss 0.18695689737796783, acc=0.9649702310562134, loss=0.18695689737796783
train: epoch 234, loss 0.06544901430606842, acc=0.9884335994720459, loss=0.06544901430606842
test: epoch 234, loss 0.17672275006771088, acc=0.9649702310562134, loss=0.17672275006771088
train: epoch 235, loss 0.0658634826540947, acc=0.985816240310669, loss=0.0658634826540947
test: epoch 235, loss 0.16461747884750366, acc=0.966292142868042, loss=0.16461747884750366
train: epoch 236, loss 0.06814508140087128, acc=0.9863846898078918, loss=0.06814508140087128
test: epoch 236, loss 0.17312221229076385, acc=0.9656311869621277, loss=0.17312221229076385
train: epoch 237, loss 0.08909127861261368, acc=0.9842432141304016, loss=0.08909127861261368
test: epoch 237, loss 0.21290908753871918, acc=0.9603436589241028, loss=0.21290908753871918
train: epoch 238, loss 0.0752069503068924, acc=0.9825379848480225, loss=0.0752069503068924
test: epoch 238, loss 0.1630326509475708, acc=0.9636483788490295, loss=0.1630326509475708
train: epoch 239, loss 0.05793861672282219, acc=0.9857369661331177, loss=0.05793861672282219
test: epoch 239, loss 0.2121264785528183, acc=0.9643093347549438, loss=0.2121264785528183
train: epoch 240, loss 0.06441889703273773, acc=0.9859616756439209, loss=0.06441889703273773
test: epoch 240, loss 0.5064378380775452, acc=0.9603436589241028, loss=0.5064378380775452
train: epoch 241, loss 0.07678868621587753, acc=0.9849570393562317, loss=0.07678868621587753
test: epoch 241, loss 0.42229825258255005, acc=0.9616655707359314, loss=0.42229825258255005
train: epoch 242, loss 0.09850230813026428, acc=0.9816126823425293, loss=0.09850230813026428
test: epoch 242, loss 0.3685067892074585, acc=0.9583608508110046, loss=0.3685067892074585
train: epoch 243, loss 0.07062913477420807, acc=0.9832121729850769, loss=0.07062913477420807
test: epoch 243, loss 0.30123385787010193, acc=0.9610046148300171, loss=0.30123385787010193
train: epoch 244, loss 0.07322165369987488, acc=0.9839656352996826, loss=0.07322165369987488
test: epoch 244, loss 0.2563026547431946, acc=0.9623265266418457, loss=0.2563026547431946
train: epoch 245, loss 0.07317054271697998, acc=0.9849570393562317, loss=0.07317054271697998
test: epoch 245, loss 0.21113719046115875, acc=0.9623265266418457, loss=0.21113719046115875
train: epoch 246, loss 0.08461061120033264, acc=0.9811500310897827, loss=0.08461061120033264
test: epoch 246, loss 0.2708487808704376, acc=0.9623265266418457, loss=0.2708487808704376
train: epoch 247, loss 0.06906932592391968, acc=0.9856972694396973, loss=0.06906932592391968
test: epoch 247, loss 0.25950708985328674, acc=0.9563780426979065, loss=0.25950708985328674
train: epoch 248, loss 0.11386612802743912, acc=0.9775809645652771, loss=0.11386612802743912
test: epoch 248, loss 0.33989110589027405, acc=0.9570389986038208, loss=0.33989110589027405
train: epoch 249, loss 0.0853501707315445, acc=0.9806477427482605, loss=0.0853501707315445
test: epoch 249, loss 0.2538831830024719, acc=0.9583608508110046, loss=0.2538831830024719
train: epoch 250, loss 0.06761271506547928, acc=0.9823265075683594, loss=0.06761271506547928
test: epoch 250, loss 0.3595127761363983, acc=0.9610046148300171, loss=0.3595127761363983
