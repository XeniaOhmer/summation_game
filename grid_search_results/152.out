# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=true", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=118495739, receiver_embed_dim=128, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.6784749031066895, acc=0.11294444650411606, loss=2.6784749031066895
test: epoch 1, loss 6.813431739807129, acc=0.06111111119389534, loss=6.813431739807129
train: epoch 2, loss 1.577399492263794, acc=0.3238333463668823, loss=1.577399492263794
test: epoch 2, loss 4.055070877075195, acc=0.125, loss=4.055070877075195
train: epoch 3, loss 1.1992267370224, acc=0.4511111080646515, loss=1.1992267370224
test: epoch 3, loss 2.8804006576538086, acc=0.2222222238779068, loss=2.8804006576538086
train: epoch 4, loss 0.9814108610153198, acc=0.5341110825538635, loss=0.9814108610153198
test: epoch 4, loss 2.411506175994873, acc=0.32499998807907104, loss=2.411506175994873
train: epoch 5, loss 0.8122775554656982, acc=0.6278333067893982, loss=0.8122775554656982
test: epoch 5, loss 1.9341553449630737, acc=0.35555556416511536, loss=1.9341553449630737
train: epoch 6, loss 0.7071138024330139, acc=0.6936110854148865, loss=0.7071138024330139
test: epoch 6, loss 1.986556053161621, acc=0.3638888895511627, loss=1.986556053161621
train: epoch 7, loss 0.6091979146003723, acc=0.7440000176429749, loss=0.6091979146003723
test: epoch 7, loss 1.8536272048950195, acc=0.42222222685813904, loss=1.8536272048950195
train: epoch 8, loss 0.5329521298408508, acc=0.7722222208976746, loss=0.5329521298408508
test: epoch 8, loss 1.435737133026123, acc=0.4277777671813965, loss=1.435737133026123
train: epoch 9, loss 0.4485754072666168, acc=0.8086666464805603, loss=0.4485754072666168
test: epoch 9, loss 1.4599603414535522, acc=0.48055556416511536, loss=1.4599603414535522
train: epoch 10, loss 0.3608858287334442, acc=0.8471111059188843, loss=0.3608858287334442
test: epoch 10, loss 1.5040124654769897, acc=0.5444444417953491, loss=1.5040124654769897
train: epoch 11, loss 0.3089100420475006, acc=0.8656666874885559, loss=0.3089100420475006
test: epoch 11, loss 1.3123198747634888, acc=0.47777777910232544, loss=1.3123198747634888
train: epoch 12, loss 0.28727036714553833, acc=0.8778333067893982, loss=0.28727036714553833
test: epoch 12, loss 1.2009834051132202, acc=0.605555534362793, loss=1.2009834051132202
train: epoch 13, loss 0.2503790259361267, acc=0.8878889083862305, loss=0.2503790259361267
test: epoch 13, loss 0.9201675653457642, acc=0.7111111283302307, loss=0.9201675653457642
train: epoch 14, loss 0.2550831437110901, acc=0.8855555653572083, loss=0.2550831437110901
test: epoch 14, loss 0.9060678482055664, acc=0.6833333373069763, loss=0.9060678482055664
train: epoch 15, loss 0.23091673851013184, acc=0.8975555300712585, loss=0.23091673851013184
test: epoch 15, loss 0.7461324334144592, acc=0.7472222447395325, loss=0.7461324334144592
train: epoch 16, loss 0.22343407571315765, acc=0.9085000157356262, loss=0.22343407571315765
test: epoch 16, loss 0.5016347169876099, acc=0.824999988079071, loss=0.5016347169876099
train: epoch 17, loss 0.20433107018470764, acc=0.9169444441795349, loss=0.20433107018470764
test: epoch 17, loss 0.9097568392753601, acc=0.7555555701255798, loss=0.9097568392753601
train: epoch 18, loss 0.18091702461242676, acc=0.9246110916137695, loss=0.18091702461242676
test: epoch 18, loss 0.42528119683265686, acc=0.8694444298744202, loss=0.42528119683265686
train: epoch 19, loss 0.1544477343559265, acc=0.9347777962684631, loss=0.1544477343559265
test: epoch 19, loss 0.7875028848648071, acc=0.8055555820465088, loss=0.7875028848648071
train: epoch 20, loss 0.17697589099407196, acc=0.9297778010368347, loss=0.17697589099407196
test: epoch 20, loss 0.6524617671966553, acc=0.8166666626930237, loss=0.6524617671966553
train: epoch 21, loss 0.15725260972976685, acc=0.933555543422699, loss=0.15725260972976685
test: epoch 21, loss 0.5971726775169373, acc=0.8416666388511658, loss=0.5971726775169373
train: epoch 22, loss 0.17600682377815247, acc=0.9295555353164673, loss=0.17600682377815247
test: epoch 22, loss 0.3378014862537384, acc=0.8833333253860474, loss=0.3378014862537384
train: epoch 23, loss 0.14809450507164001, acc=0.9367222189903259, loss=0.14809450507164001
test: epoch 23, loss 0.24822187423706055, acc=0.9083333611488342, loss=0.24822187423706055
train: epoch 24, loss 0.1383700668811798, acc=0.9404444694519043, loss=0.1383700668811798
test: epoch 24, loss 0.322625994682312, acc=0.9111111164093018, loss=0.322625994682312
train: epoch 25, loss 0.12286370247602463, acc=0.9429444670677185, loss=0.12286370247602463
test: epoch 25, loss 0.2528069019317627, acc=0.9138888716697693, loss=0.2528069019317627
train: epoch 26, loss 0.15191338956356049, acc=0.937833309173584, loss=0.15191338956356049
test: epoch 26, loss 0.3441391885280609, acc=0.9138888716697693, loss=0.3441391885280609
train: epoch 27, loss 0.13312552869319916, acc=0.9439444541931152, loss=0.13312552869319916
test: epoch 27, loss 0.31606096029281616, acc=0.9111111164093018, loss=0.31606096029281616
train: epoch 28, loss 0.15791936218738556, acc=0.9337777495384216, loss=0.15791936218738556
test: epoch 28, loss 0.3417518138885498, acc=0.8777777552604675, loss=0.3417518138885498
train: epoch 29, loss 0.16743656992912292, acc=0.9258333444595337, loss=0.16743656992912292
test: epoch 29, loss 0.5826292634010315, acc=0.8527777791023254, loss=0.5826292634010315
train: epoch 30, loss 0.1362248957157135, acc=0.9300000071525574, loss=0.1362248957157135
test: epoch 30, loss 0.3034924566745758, acc=0.8999999761581421, loss=0.3034924566745758
train: epoch 31, loss 0.12005801498889923, acc=0.9341111183166504, loss=0.12005801498889923
test: epoch 31, loss 0.32007062435150146, acc=0.9055555462837219, loss=0.32007062435150146
train: epoch 32, loss 0.1655101627111435, acc=0.9225000143051147, loss=0.1655101627111435
test: epoch 32, loss 0.3834618628025055, acc=0.8722222447395325, loss=0.3834618628025055
train: epoch 33, loss 0.1814107447862625, acc=0.9216111302375793, loss=0.1814107447862625
test: epoch 33, loss 0.4104502499103546, acc=0.8805555701255798, loss=0.4104502499103546
train: epoch 34, loss 0.16423889994621277, acc=0.9207777976989746, loss=0.16423889994621277
test: epoch 34, loss 0.4339436888694763, acc=0.8916666507720947, loss=0.4339436888694763
train: epoch 35, loss 0.1836572289466858, acc=0.9143333435058594, loss=0.1836572289466858
test: epoch 35, loss 0.31673556566238403, acc=0.8833333253860474, loss=0.31673556566238403
train: epoch 36, loss 0.16370439529418945, acc=0.913277804851532, loss=0.16370439529418945
test: epoch 36, loss 0.360200971364975, acc=0.875, loss=0.360200971364975
train: epoch 37, loss 0.16905827820301056, acc=0.918833315372467, loss=0.16905827820301056
test: epoch 37, loss 0.3787895441055298, acc=0.8916666507720947, loss=0.3787895441055298
train: epoch 38, loss 0.1354793757200241, acc=0.9224444627761841, loss=0.1354793757200241
test: epoch 38, loss 0.3379599153995514, acc=0.8916666507720947, loss=0.3379599153995514
train: epoch 39, loss 0.18734416365623474, acc=0.9119444489479065, loss=0.18734416365623474
test: epoch 39, loss 0.3896755278110504, acc=0.8888888955116272, loss=0.3896755278110504
train: epoch 40, loss 0.18296431005001068, acc=0.9122777581214905, loss=0.18296431005001068
test: epoch 40, loss 0.29357579350471497, acc=0.8666666746139526, loss=0.29357579350471497
train: epoch 41, loss 0.16602575778961182, acc=0.9144444465637207, loss=0.16602575778961182
test: epoch 41, loss 0.3928886651992798, acc=0.8805555701255798, loss=0.3928886651992798
train: epoch 42, loss 0.22554855048656464, acc=0.8927778005599976, loss=0.22554855048656464
test: epoch 42, loss 0.4536324441432953, acc=0.8416666388511658, loss=0.4536324441432953
train: epoch 43, loss 0.25562191009521484, acc=0.8756111264228821, loss=0.25562191009521484
test: epoch 43, loss 0.4343737065792084, acc=0.8472222089767456, loss=0.4343737065792084
train: epoch 44, loss 0.24737243354320526, acc=0.8730555772781372, loss=0.24737243354320526
test: epoch 44, loss 0.5204812288284302, acc=0.8305555582046509, loss=0.5204812288284302
train: epoch 45, loss 0.27177855372428894, acc=0.8702222108840942, loss=0.27177855372428894
test: epoch 45, loss 0.5094031691551208, acc=0.8305555582046509, loss=0.5094031691551208
train: epoch 46, loss 0.2471497803926468, acc=0.8749444484710693, loss=0.2471497803926468
test: epoch 46, loss 0.3767206370830536, acc=0.8722222447395325, loss=0.3767206370830536
train: epoch 47, loss 0.1553497463464737, acc=0.9137222170829773, loss=0.1553497463464737
test: epoch 47, loss 0.37752795219421387, acc=0.8888888955116272, loss=0.37752795219421387
train: epoch 48, loss 0.12982162833213806, acc=0.9254444241523743, loss=0.12982162833213806
test: epoch 48, loss 0.3112387955188751, acc=0.8888888955116272, loss=0.3112387955188751
train: epoch 49, loss 0.16064250469207764, acc=0.9184444546699524, loss=0.16064250469207764
test: epoch 49, loss 0.314898818731308, acc=0.8805555701255798, loss=0.314898818731308
train: epoch 50, loss 0.1387389451265335, acc=0.9187222123146057, loss=0.1387389451265335
test: epoch 50, loss 0.3502081036567688, acc=0.8861111402511597, loss=0.3502081036567688
train: epoch 51, loss 0.1912926286458969, acc=0.909500002861023, loss=0.1912926286458969
test: epoch 51, loss 0.3950803577899933, acc=0.8777777552604675, loss=0.3950803577899933
train: epoch 52, loss 0.1575918346643448, acc=0.9139999747276306, loss=0.1575918346643448
test: epoch 52, loss 0.3837451636791229, acc=0.8833333253860474, loss=0.3837451636791229
train: epoch 53, loss 0.185747429728508, acc=0.9083889126777649, loss=0.185747429728508
test: epoch 53, loss 0.3987879455089569, acc=0.8833333253860474, loss=0.3987879455089569
train: epoch 54, loss 0.14469899237155914, acc=0.9158333539962769, loss=0.14469899237155914
test: epoch 54, loss 0.3584793210029602, acc=0.8833333253860474, loss=0.3584793210029602
train: epoch 55, loss 0.1691666841506958, acc=0.9139444231987, loss=0.1691666841506958
test: epoch 55, loss 0.3859563171863556, acc=0.8805555701255798, loss=0.3859563171863556
train: epoch 56, loss 0.13847078382968903, acc=0.9190555810928345, loss=0.13847078382968903
test: epoch 56, loss 0.39934226870536804, acc=0.8888888955116272, loss=0.39934226870536804
train: epoch 57, loss 0.14586785435676575, acc=0.9211111068725586, loss=0.14586785435676575
test: epoch 57, loss 0.46699443459510803, acc=0.8611111044883728, loss=0.46699443459510803
train: epoch 58, loss 0.2038111388683319, acc=0.906166672706604, loss=0.2038111388683319
test: epoch 58, loss 0.4435155391693115, acc=0.875, loss=0.4435155391693115
train: epoch 59, loss 0.16314566135406494, acc=0.9103333353996277, loss=0.16314566135406494
test: epoch 59, loss 0.4387250244617462, acc=0.8805555701255798, loss=0.4387250244617462
train: epoch 60, loss 0.15098221600055695, acc=0.9152777791023254, loss=0.15098221600055695
test: epoch 60, loss 0.3920447528362274, acc=0.8861111402511597, loss=0.3920447528362274
train: epoch 61, loss 0.20539970695972443, acc=0.9126111268997192, loss=0.20539970695972443
test: epoch 61, loss 0.3417159616947174, acc=0.8833333253860474, loss=0.3417159616947174
train: epoch 62, loss 0.132979616522789, acc=0.9185555577278137, loss=0.132979616522789
test: epoch 62, loss 0.2673129141330719, acc=0.8861111402511597, loss=0.2673129141330719
train: epoch 63, loss 0.1429804414510727, acc=0.9157778024673462, loss=0.1429804414510727
test: epoch 63, loss 0.4579380452632904, acc=0.8583333492279053, loss=0.4579380452632904
train: epoch 64, loss 0.19124265015125275, acc=0.9135000109672546, loss=0.19124265015125275
test: epoch 64, loss 0.3716200888156891, acc=0.8666666746139526, loss=0.3716200888156891
train: epoch 65, loss 0.19713053107261658, acc=0.9148889183998108, loss=0.19713053107261658
test: epoch 65, loss 0.40813833475112915, acc=0.8833333253860474, loss=0.40813833475112915
train: epoch 66, loss 0.15685570240020752, acc=0.9163333177566528, loss=0.15685570240020752
test: epoch 66, loss 0.30524197220802307, acc=0.8833333253860474, loss=0.30524197220802307
train: epoch 67, loss 0.13988962769508362, acc=0.9220555424690247, loss=0.13988962769508362
test: epoch 67, loss 0.40059301257133484, acc=0.8861111402511597, loss=0.40059301257133484
train: epoch 68, loss 0.17346163094043732, acc=0.9165555834770203, loss=0.17346163094043732
test: epoch 68, loss 0.4550502598285675, acc=0.8805555701255798, loss=0.4550502598285675
train: epoch 69, loss 0.18349409103393555, acc=0.9169444441795349, loss=0.18349409103393555
test: epoch 69, loss 0.4429725706577301, acc=0.8777777552604675, loss=0.4429725706577301
train: epoch 70, loss 0.1843719333410263, acc=0.9090555310249329, loss=0.1843719333410263
test: epoch 70, loss 0.41614753007888794, acc=0.8722222447395325, loss=0.41614753007888794
train: epoch 71, loss 0.18417656421661377, acc=0.9096111059188843, loss=0.18417656421661377
test: epoch 71, loss 0.3229905068874359, acc=0.8777777552604675, loss=0.3229905068874359
train: epoch 72, loss 0.2033158838748932, acc=0.9035000205039978, loss=0.2033158838748932
test: epoch 72, loss 0.31247562170028687, acc=0.8638888597488403, loss=0.31247562170028687
train: epoch 73, loss 0.22801972925662994, acc=0.9111666679382324, loss=0.22801972925662994
test: epoch 73, loss 0.3945595622062683, acc=0.8722222447395325, loss=0.3945595622062683
train: epoch 74, loss 0.1726772040128708, acc=0.9211666584014893, loss=0.1726772040128708
test: epoch 74, loss 0.29418811202049255, acc=0.8861111402511597, loss=0.29418811202049255
train: epoch 75, loss 0.1787215918302536, acc=0.9148333072662354, loss=0.1787215918302536
test: epoch 75, loss 0.3997880816459656, acc=0.8805555701255798, loss=0.3997880816459656
train: epoch 76, loss 0.17101523280143738, acc=0.9120555520057678, loss=0.17101523280143738
test: epoch 76, loss 0.6633611917495728, acc=0.8777777552604675, loss=0.6633611917495728
train: epoch 77, loss 0.16859287023544312, acc=0.9136666655540466, loss=0.16859287023544312
test: epoch 77, loss 0.2595525085926056, acc=0.8888888955116272, loss=0.2595525085926056
train: epoch 78, loss 0.13437111675739288, acc=0.9190555810928345, loss=0.13437111675739288
test: epoch 78, loss 0.2593333423137665, acc=0.8888888955116272, loss=0.2593333423137665
train: epoch 79, loss 0.13114458322525024, acc=0.9192777872085571, loss=0.13114458322525024
test: epoch 79, loss 0.4261304438114166, acc=0.8888888955116272, loss=0.4261304438114166
train: epoch 80, loss 0.20532070100307465, acc=0.9135000109672546, loss=0.20532070100307465
test: epoch 80, loss 0.6087866425514221, acc=0.8361111283302307, loss=0.6087866425514221
train: epoch 81, loss 0.24441561102867126, acc=0.9082777500152588, loss=0.24441561102867126
test: epoch 81, loss 0.44120365381240845, acc=0.8722222447395325, loss=0.44120365381240845
train: epoch 82, loss 0.17088478803634644, acc=0.9320555329322815, loss=0.17088478803634644
test: epoch 82, loss 0.4831089675426483, acc=0.8805555701255798, loss=0.4831089675426483
train: epoch 83, loss 0.1548859179019928, acc=0.9382222294807434, loss=0.1548859179019928
test: epoch 83, loss 0.2641156017780304, acc=0.9027777910232544, loss=0.2641156017780304
train: epoch 84, loss 0.14774228632450104, acc=0.9364444613456726, loss=0.14774228632450104
test: epoch 84, loss 0.2715810239315033, acc=0.9083333611488342, loss=0.2715810239315033
train: epoch 85, loss 0.12230240553617477, acc=0.9415000081062317, loss=0.12230240553617477
test: epoch 85, loss 0.20784060657024384, acc=0.9194444417953491, loss=0.20784060657024384
train: epoch 86, loss 0.1256968379020691, acc=0.9418888688087463, loss=0.1256968379020691
test: epoch 86, loss 0.2562845051288605, acc=0.9194444417953491, loss=0.2562845051288605
train: epoch 87, loss 0.1488049030303955, acc=0.9402777552604675, loss=0.1488049030303955
test: epoch 87, loss 0.18639200925827026, acc=0.9222221970558167, loss=0.18639200925827026
train: epoch 88, loss 0.1292160600423813, acc=0.9385555386543274, loss=0.1292160600423813
test: epoch 88, loss 0.18193906545639038, acc=0.9222221970558167, loss=0.18193906545639038
train: epoch 89, loss 0.19671712815761566, acc=0.9214444160461426, loss=0.19671712815761566
test: epoch 89, loss 0.18031781911849976, acc=0.9166666865348816, loss=0.18031781911849976
train: epoch 90, loss 0.14976832270622253, acc=0.9272778034210205, loss=0.14976832270622253
test: epoch 90, loss 0.18658392131328583, acc=0.9222221970558167, loss=0.18658392131328583
train: epoch 91, loss 0.12353487312793732, acc=0.9440555572509766, loss=0.12353487312793732
test: epoch 91, loss 0.16222888231277466, acc=0.9277777671813965, loss=0.16222888231277466
train: epoch 92, loss 0.145578533411026, acc=0.9397777915000916, loss=0.145578533411026
test: epoch 92, loss 0.19927479326725006, acc=0.9166666865348816, loss=0.19927479326725006
train: epoch 93, loss 0.17530694603919983, acc=0.929111123085022, loss=0.17530694603919983
test: epoch 93, loss 0.18749919533729553, acc=0.9194444417953491, loss=0.18749919533729553
train: epoch 94, loss 0.13842201232910156, acc=0.9351111054420471, loss=0.13842201232910156
test: epoch 94, loss 0.22876235842704773, acc=0.9166666865348816, loss=0.22876235842704773
train: epoch 95, loss 0.1328170746564865, acc=0.9353888630867004, loss=0.1328170746564865
test: epoch 95, loss 0.25409558415412903, acc=0.9194444417953491, loss=0.25409558415412903
train: epoch 96, loss 0.1281438022851944, acc=0.9366666674613953, loss=0.1281438022851944
test: epoch 96, loss 0.1784069985151291, acc=0.9194444417953491, loss=0.1784069985151291
train: epoch 97, loss 0.11819016188383102, acc=0.9400555491447449, loss=0.11819016188383102
test: epoch 97, loss 0.24126870930194855, acc=0.9277777671813965, loss=0.24126870930194855
train: epoch 98, loss 0.1289827525615692, acc=0.945555567741394, loss=0.1289827525615692
test: epoch 98, loss 0.1390388458967209, acc=0.949999988079071, loss=0.1390388458967209
train: epoch 99, loss 0.11957766860723495, acc=0.9471666812896729, loss=0.11957766860723495
test: epoch 99, loss 0.08960355073213577, acc=0.9555555582046509, loss=0.08960355073213577
train: epoch 100, loss 0.09281585365533829, acc=0.9480555653572083, loss=0.09281585365533829
test: epoch 100, loss 0.0894434005022049, acc=0.9555555582046509, loss=0.0894434005022049
train: epoch 101, loss 0.12090659886598587, acc=0.94477778673172, loss=0.12090659886598587
test: epoch 101, loss 0.20294976234436035, acc=0.9361110925674438, loss=0.20294976234436035
train: epoch 102, loss 0.15796905755996704, acc=0.9411110877990723, loss=0.15796905755996704
test: epoch 102, loss 0.15708845853805542, acc=0.9444444179534912, loss=0.15708845853805542
train: epoch 103, loss 0.11135467886924744, acc=0.9468333125114441, loss=0.11135467886924744
test: epoch 103, loss 0.10834028571844101, acc=0.949999988079071, loss=0.10834028571844101
train: epoch 104, loss 0.1165003851056099, acc=0.9463889002799988, loss=0.1165003851056099
test: epoch 104, loss 0.11114848405122757, acc=0.949999988079071, loss=0.11114848405122757
train: epoch 105, loss 0.15270563960075378, acc=0.9405555725097656, loss=0.15270563960075378
test: epoch 105, loss 0.16945014894008636, acc=0.9388889074325562, loss=0.16945014894008636
train: epoch 106, loss 0.1256408989429474, acc=0.9444444179534912, loss=0.1256408989429474
test: epoch 106, loss 0.10507271438837051, acc=0.9527778029441833, loss=0.10507271438837051
train: epoch 107, loss 0.10695963352918625, acc=0.945888876914978, loss=0.10695963352918625
test: epoch 107, loss 0.10491596907377243, acc=0.9527778029441833, loss=0.10491596907377243
train: epoch 108, loss 0.10661108046770096, acc=0.9451666474342346, loss=0.10661108046770096
test: epoch 108, loss 0.10486478358507156, acc=0.9527778029441833, loss=0.10486478358507156
train: epoch 109, loss 0.11281988024711609, acc=0.945555567741394, loss=0.11281988024711609
test: epoch 109, loss 0.09555727988481522, acc=0.9555555582046509, loss=0.09555727988481522
train: epoch 110, loss 0.128055140376091, acc=0.9440000057220459, loss=0.128055140376091
test: epoch 110, loss 0.10283800959587097, acc=0.9527778029441833, loss=0.10283800959587097
train: epoch 111, loss 0.10320179909467697, acc=0.9448333382606506, loss=0.10320179909467697
test: epoch 111, loss 0.09314528852701187, acc=0.9555555582046509, loss=0.09314528852701187
train: epoch 112, loss 0.1601095050573349, acc=0.9304999709129333, loss=0.1601095050573349
test: epoch 112, loss 0.1421596258878708, acc=0.9388889074325562, loss=0.1421596258878708
train: epoch 113, loss 0.14456340670585632, acc=0.9307222366333008, loss=0.14456340670585632
test: epoch 113, loss 0.14124633371829987, acc=0.9388889074325562, loss=0.14124633371829987
train: epoch 114, loss 0.1488141566514969, acc=0.9300000071525574, loss=0.1488141566514969
test: epoch 114, loss 0.14163467288017273, acc=0.9388889074325562, loss=0.14163467288017273
train: epoch 115, loss 0.22126713395118713, acc=0.9152777791023254, loss=0.22126713395118713
test: epoch 115, loss 0.2044876217842102, acc=0.9222221970558167, loss=0.2044876217842102
train: epoch 116, loss 0.19182170927524567, acc=0.9218888878822327, loss=0.19182170927524567
test: epoch 116, loss 0.17655056715011597, acc=0.9277777671813965, loss=0.17655056715011597
train: epoch 117, loss 0.21013328433036804, acc=0.9205555319786072, loss=0.21013328433036804
test: epoch 117, loss 0.29234686493873596, acc=0.9083333611488342, loss=0.29234686493873596
train: epoch 118, loss 0.19590593874454498, acc=0.9192777872085571, loss=0.19590593874454498
test: epoch 118, loss 0.17047005891799927, acc=0.9277777671813965, loss=0.17047005891799927
train: epoch 119, loss 0.1566677689552307, acc=0.9263333082199097, loss=0.1566677689552307
test: epoch 119, loss 0.13782545924186707, acc=0.9388889074325562, loss=0.13782545924186707
train: epoch 120, loss 0.1393439620733261, acc=0.9313333630561829, loss=0.1393439620733261
test: epoch 120, loss 0.1366763710975647, acc=0.9388889074325562, loss=0.1366763710975647
train: epoch 121, loss 0.1393250674009323, acc=0.9304444193840027, loss=0.1393250674009323
test: epoch 121, loss 0.13662706315517426, acc=0.9388889074325562, loss=0.13662706315517426
train: epoch 122, loss 0.13705337047576904, acc=0.9361110925674438, loss=0.13705337047576904
test: epoch 122, loss 0.13273420929908752, acc=0.9416666626930237, loss=0.13273420929908752
train: epoch 123, loss 0.15492169559001923, acc=0.9346110820770264, loss=0.15492169559001923
test: epoch 123, loss 0.1663011759519577, acc=0.9305555820465088, loss=0.1663011759519577
train: epoch 124, loss 0.25810375809669495, acc=0.9038333296775818, loss=0.25810375809669495
test: epoch 124, loss 0.21508701145648956, acc=0.9111111164093018, loss=0.21508701145648956
train: epoch 125, loss 0.22258609533309937, acc=0.9061111211776733, loss=0.22258609533309937
test: epoch 125, loss 0.31403136253356934, acc=0.9027777910232544, loss=0.31403136253356934
train: epoch 126, loss 0.2644209563732147, acc=0.9010000228881836, loss=0.2644209563732147
test: epoch 126, loss 0.22385461628437042, acc=0.9138888716697693, loss=0.22385461628437042
train: epoch 127, loss 0.19931213557720184, acc=0.9200555682182312, loss=0.19931213557720184
test: epoch 127, loss 0.18269717693328857, acc=0.9277777671813965, loss=0.18269717693328857
train: epoch 128, loss 0.18494638800621033, acc=0.9254999756813049, loss=0.18494638800621033
test: epoch 128, loss 0.18139678239822388, acc=0.9277777671813965, loss=0.18139678239822388
train: epoch 129, loss 0.1844588816165924, acc=0.925000011920929, loss=0.1844588816165924
test: epoch 129, loss 0.18133023381233215, acc=0.9277777671813965, loss=0.18133023381233215
train: epoch 130, loss 0.18433602154254913, acc=0.925000011920929, loss=0.18433602154254913
test: epoch 130, loss 0.1813003420829773, acc=0.9277777671813965, loss=0.1813003420829773
train: epoch 131, loss 0.18421170115470886, acc=0.924833357334137, loss=0.18421170115470886
test: epoch 131, loss 0.18128184974193573, acc=0.9277777671813965, loss=0.18128184974193573
train: epoch 132, loss 0.18395358324050903, acc=0.925000011920929, loss=0.18395358324050903
test: epoch 132, loss 0.1813545525074005, acc=0.9277777671813965, loss=0.1813545525074005
train: epoch 133, loss 0.18461279571056366, acc=0.9253333210945129, loss=0.18461279571056366
test: epoch 133, loss 0.18025827407836914, acc=0.9277777671813965, loss=0.18025827407836914
train: epoch 134, loss 0.18379747867584229, acc=0.9259999990463257, loss=0.18379747867584229
test: epoch 134, loss 0.18126314878463745, acc=0.9277777671813965, loss=0.18126314878463745
train: epoch 135, loss 0.27935168147087097, acc=0.9131666421890259, loss=0.27935168147087097
test: epoch 135, loss 0.2952283024787903, acc=0.9027777910232544, loss=0.2952283024787903
train: epoch 136, loss 0.2321764975786209, acc=0.9092222452163696, loss=0.2321764975786209
test: epoch 136, loss 0.2233680635690689, acc=0.9083333611488342, loss=0.2233680635690689
train: epoch 137, loss 0.2213103026151657, acc=0.9045000076293945, loss=0.2213103026151657
test: epoch 137, loss 0.2167893946170807, acc=0.9111111164093018, loss=0.2167893946170807
train: epoch 138, loss 0.22039131820201874, acc=0.9027777910232544, loss=0.22039131820201874
test: epoch 138, loss 0.21660324931144714, acc=0.9111111164093018, loss=0.21660324931144714
train: epoch 139, loss 0.2202567160129547, acc=0.9027777910232544, loss=0.2202567160129547
test: epoch 139, loss 0.2111387550830841, acc=0.9138888716697693, loss=0.2111387550830841
train: epoch 140, loss 0.2122485637664795, acc=0.9055555462837219, loss=0.2122485637664795
test: epoch 140, loss 0.2089143544435501, acc=0.9138888716697693, loss=0.2089143544435501
train: epoch 141, loss 0.21188412606716156, acc=0.9055555462837219, loss=0.21188412606716156
test: epoch 141, loss 0.20887066423892975, acc=0.9138888716697693, loss=0.20887066423892975
train: epoch 142, loss 0.21216906607151031, acc=0.9058333039283752, loss=0.21216906607151031
test: epoch 142, loss 0.2088552713394165, acc=0.9138888716697693, loss=0.2088552713394165
train: epoch 143, loss 0.21164590120315552, acc=0.9055555462837219, loss=0.21164590120315552
test: epoch 143, loss 0.20882463455200195, acc=0.9138888716697693, loss=0.20882463455200195
train: epoch 144, loss 0.2116275131702423, acc=0.906166672706604, loss=0.2116275131702423
test: epoch 144, loss 0.2088092863559723, acc=0.9138888716697693, loss=0.2088092863559723
train: epoch 145, loss 0.21150341629981995, acc=0.9067222476005554, loss=0.21150341629981995
test: epoch 145, loss 0.20884770154953003, acc=0.9138888716697693, loss=0.20884770154953003
train: epoch 146, loss 0.21157611906528473, acc=0.906166672706604, loss=0.21157611906528473
test: epoch 146, loss 0.20879387855529785, acc=0.9138888716697693, loss=0.20879387855529785
train: epoch 147, loss 0.21135567128658295, acc=0.9082777500152588, loss=0.21135567128658295
test: epoch 147, loss 0.20877605676651, acc=0.9138888716697693, loss=0.20877605676651
train: epoch 148, loss 0.21137548983097076, acc=0.9103333353996277, loss=0.21137548983097076
test: epoch 148, loss 0.20878201723098755, acc=0.9138888716697693, loss=0.20878201723098755
train: epoch 149, loss 0.641167163848877, acc=0.8247777819633484, loss=0.641167163848877
test: epoch 149, loss 0.4306625425815582, acc=0.8166666626930237, loss=0.4306625425815582
train: epoch 150, loss 0.4371947944164276, acc=0.816277801990509, loss=0.4371947944164276
test: epoch 150, loss 0.42579320073127747, acc=0.8194444179534912, loss=0.42579320073127747
