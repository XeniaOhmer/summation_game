# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=0", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=1390036154, receiver_embed_dim=128, save_run=0, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=1390036154, receiver_embed_dim=128, save_run=False, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.284661293029785, acc=0.1792222261428833, loss=2.284661293029785
test: epoch 1, loss 7.120301723480225, acc=0.0555555559694767, loss=7.120301723480225
train: epoch 2, loss 1.5516921281814575, acc=0.3466111123561859, loss=1.5516921281814575
test: epoch 2, loss 5.22522497177124, acc=0.0972222238779068, loss=5.22522497177124
train: epoch 3, loss 1.2414616346359253, acc=0.46861112117767334, loss=1.2414616346359253
test: epoch 3, loss 5.694054126739502, acc=0.09166666865348816, loss=5.694054126739502
train: epoch 4, loss 1.082971215248108, acc=0.5464444160461426, loss=1.082971215248108
test: epoch 4, loss 4.711338043212891, acc=0.14722222089767456, loss=4.711338043212891
train: epoch 5, loss 0.9687520861625671, acc=0.5950000286102295, loss=0.9687520861625671
test: epoch 5, loss 2.8234658241271973, acc=0.21944443881511688, loss=2.8234658241271973
train: epoch 6, loss 0.8770577311515808, acc=0.6383888721466064, loss=0.8770577311515808
test: epoch 6, loss 4.100844383239746, acc=0.18888889253139496, loss=4.100844383239746
train: epoch 7, loss 0.8094232678413391, acc=0.6664999723434448, loss=0.8094232678413391
test: epoch 7, loss 2.909830093383789, acc=0.24166665971279144, loss=2.909830093383789
train: epoch 8, loss 0.7603795528411865, acc=0.6946666836738586, loss=0.7603795528411865
test: epoch 8, loss 3.2900514602661133, acc=0.26944443583488464, loss=3.2900514602661133
train: epoch 9, loss 0.7204983234405518, acc=0.7072222232818604, loss=0.7204983234405518
test: epoch 9, loss 3.5034472942352295, acc=0.21111111342906952, loss=3.5034472942352295
train: epoch 10, loss 0.6887470483779907, acc=0.7237777709960938, loss=0.6887470483779907
test: epoch 10, loss 2.6830618381500244, acc=0.2777777910232544, loss=2.6830618381500244
train: epoch 11, loss 0.6558166146278381, acc=0.7326666712760925, loss=0.6558166146278381
test: epoch 11, loss 2.373415946960449, acc=0.31388887763023376, loss=2.373415946960449
train: epoch 12, loss 0.5812167525291443, acc=0.7708333134651184, loss=0.5812167525291443
test: epoch 12, loss 2.7013912200927734, acc=0.29722222685813904, loss=2.7013912200927734
train: epoch 13, loss 0.5967044234275818, acc=0.7621111273765564, loss=0.5967044234275818
test: epoch 13, loss 2.9247539043426514, acc=0.3166666626930237, loss=2.9247539043426514
train: epoch 14, loss 0.5496523976325989, acc=0.7758888602256775, loss=0.5496523976325989
test: epoch 14, loss 3.233506917953491, acc=0.2916666567325592, loss=3.233506917953491
train: epoch 15, loss 0.5539140105247498, acc=0.7782777547836304, loss=0.5539140105247498
test: epoch 15, loss 2.503880262374878, acc=0.2666666805744171, loss=2.503880262374878
train: epoch 16, loss 0.537148118019104, acc=0.7832777500152588, loss=0.537148118019104
test: epoch 16, loss 2.3614861965179443, acc=0.3194444477558136, loss=2.3614861965179443
train: epoch 17, loss 0.4995764493942261, acc=0.7984444499015808, loss=0.4995764493942261
test: epoch 17, loss 2.350498914718628, acc=0.3444444537162781, loss=2.350498914718628
train: epoch 18, loss 0.554648756980896, acc=0.7780555486679077, loss=0.554648756980896
test: epoch 18, loss 1.788802146911621, acc=0.35277777910232544, loss=1.788802146911621
train: epoch 19, loss 0.47473573684692383, acc=0.8094444274902344, loss=0.47473573684692383
test: epoch 19, loss 2.170966625213623, acc=0.3444444537162781, loss=2.170966625213623
train: epoch 20, loss 0.49606889486312866, acc=0.8008333444595337, loss=0.49606889486312866
test: epoch 20, loss 1.7927348613739014, acc=0.41111111640930176, loss=1.7927348613739014
train: epoch 21, loss 0.48396244645118713, acc=0.8075555562973022, loss=0.48396244645118713
test: epoch 21, loss 2.2862966060638428, acc=0.38333332538604736, loss=2.2862966060638428
train: epoch 22, loss 0.45702871680259705, acc=0.8196666836738586, loss=0.45702871680259705
test: epoch 22, loss 2.080095052719116, acc=0.40833333134651184, loss=2.080095052719116
train: epoch 23, loss 0.43606036901474, acc=0.8297777771949768, loss=0.43606036901474
test: epoch 23, loss 2.530196189880371, acc=0.3583333194255829, loss=2.530196189880371
train: epoch 24, loss 0.45964792370796204, acc=0.8163333535194397, loss=0.45964792370796204
test: epoch 24, loss 2.185513496398926, acc=0.35555556416511536, loss=2.185513496398926
train: epoch 25, loss 0.4502614736557007, acc=0.8227777481079102, loss=0.4502614736557007
test: epoch 25, loss 2.473968982696533, acc=0.28333333134651184, loss=2.473968982696533
train: epoch 26, loss 0.42465880513191223, acc=0.8339999914169312, loss=0.42465880513191223
test: epoch 26, loss 2.6206371784210205, acc=0.3333333432674408, loss=2.6206371784210205
train: epoch 27, loss 0.4385806918144226, acc=0.8271111249923706, loss=0.4385806918144226
test: epoch 27, loss 1.9416723251342773, acc=0.38333332538604736, loss=1.9416723251342773
train: epoch 28, loss 0.42879676818847656, acc=0.8335000276565552, loss=0.42879676818847656
test: epoch 28, loss 1.532841682434082, acc=0.4000000059604645, loss=1.532841682434082
train: epoch 29, loss 0.3790692090988159, acc=0.852055549621582, loss=0.3790692090988159
test: epoch 29, loss 2.0710296630859375, acc=0.32777777314186096, loss=2.0710296630859375
train: epoch 30, loss 0.4115167558193207, acc=0.835777759552002, loss=0.4115167558193207
test: epoch 30, loss 2.3337883949279785, acc=0.2916666567325592, loss=2.3337883949279785
train: epoch 31, loss 0.3747795522212982, acc=0.8554444313049316, loss=0.3747795522212982
test: epoch 31, loss 1.9464960098266602, acc=0.42500001192092896, loss=1.9464960098266602
train: epoch 32, loss 0.42435434460639954, acc=0.8382777571678162, loss=0.42435434460639954
test: epoch 32, loss 1.9889194965362549, acc=0.36944442987442017, loss=1.9889194965362549
train: epoch 33, loss 0.37146425247192383, acc=0.8536111116409302, loss=0.37146425247192383
test: epoch 33, loss 1.8939496278762817, acc=0.35555556416511536, loss=1.8939496278762817
train: epoch 34, loss 0.3944920599460602, acc=0.848111093044281, loss=0.3944920599460602
test: epoch 34, loss 1.359632134437561, acc=0.4472222328186035, loss=1.359632134437561
train: epoch 35, loss 0.37480902671813965, acc=0.8535555601119995, loss=0.37480902671813965
test: epoch 35, loss 2.3850719928741455, acc=0.3499999940395355, loss=2.3850719928741455
train: epoch 36, loss 0.345600426197052, acc=0.8651111125946045, loss=0.345600426197052
test: epoch 36, loss 2.785388231277466, acc=0.32499998807907104, loss=2.785388231277466
train: epoch 37, loss 0.378028929233551, acc=0.8525555729866028, loss=0.378028929233551
test: epoch 37, loss 1.3118664026260376, acc=0.4888888895511627, loss=1.3118664026260376
train: epoch 38, loss 0.36776548624038696, acc=0.8564444184303284, loss=0.36776548624038696
test: epoch 38, loss 1.8285285234451294, acc=0.45277777314186096, loss=1.8285285234451294
train: epoch 39, loss 0.3668300211429596, acc=0.8550000190734863, loss=0.3668300211429596
test: epoch 39, loss 1.5835955142974854, acc=0.4861111044883728, loss=1.5835955142974854
train: epoch 40, loss 0.3320707678794861, acc=0.8681666851043701, loss=0.3320707678794861
test: epoch 40, loss 1.415823221206665, acc=0.47777777910232544, loss=1.415823221206665
train: epoch 41, loss 0.3449951112270355, acc=0.8671666383743286, loss=0.3449951112270355
test: epoch 41, loss 1.7121480703353882, acc=0.41111111640930176, loss=1.7121480703353882
train: epoch 42, loss 0.3425588607788086, acc=0.8657222390174866, loss=0.3425588607788086
test: epoch 42, loss 1.6762924194335938, acc=0.3861111104488373, loss=1.6762924194335938
train: epoch 43, loss 0.3222610652446747, acc=0.8737778067588806, loss=0.3222610652446747
test: epoch 43, loss 1.4811375141143799, acc=0.4444444477558136, loss=1.4811375141143799
train: epoch 44, loss 0.31172189116477966, acc=0.8783888816833496, loss=0.31172189116477966
test: epoch 44, loss 1.4111677408218384, acc=0.4444444477558136, loss=1.4111677408218384
train: epoch 45, loss 0.34852999448776245, acc=0.8663333058357239, loss=0.34852999448776245
test: epoch 45, loss 2.4204118251800537, acc=0.3638888895511627, loss=2.4204118251800537
train: epoch 46, loss 0.3239179849624634, acc=0.8734999895095825, loss=0.3239179849624634
test: epoch 46, loss 1.1478475332260132, acc=0.5472221970558167, loss=1.1478475332260132
train: epoch 47, loss 0.3232615888118744, acc=0.8730000257492065, loss=0.3232615888118744
test: epoch 47, loss 1.704588532447815, acc=0.4472222328186035, loss=1.704588532447815
train: epoch 48, loss 0.2922326624393463, acc=0.8871111273765564, loss=0.2922326624393463
test: epoch 48, loss 1.454291820526123, acc=0.45277777314186096, loss=1.454291820526123
train: epoch 49, loss 0.317796528339386, acc=0.8763889074325562, loss=0.317796528339386
test: epoch 49, loss 1.5247660875320435, acc=0.39722222089767456, loss=1.5247660875320435
train: epoch 50, loss 0.3320687711238861, acc=0.8697222471237183, loss=0.3320687711238861
test: epoch 50, loss 1.4743057489395142, acc=0.4972222149372101, loss=1.4743057489395142
train: epoch 51, loss 0.2826252281665802, acc=0.8929444551467896, loss=0.2826252281665802
test: epoch 51, loss 1.2653313875198364, acc=0.5305555462837219, loss=1.2653313875198364
train: epoch 52, loss 0.29936790466308594, acc=0.883222222328186, loss=0.29936790466308594
test: epoch 52, loss 1.3945872783660889, acc=0.46666666865348816, loss=1.3945872783660889
train: epoch 53, loss 0.30142614245414734, acc=0.8818333148956299, loss=0.30142614245414734
test: epoch 53, loss 1.2490768432617188, acc=0.5138888955116272, loss=1.2490768432617188
train: epoch 54, loss 0.30028626322746277, acc=0.8856111168861389, loss=0.30028626322746277
test: epoch 54, loss 1.3120979070663452, acc=0.5222222208976746, loss=1.3120979070663452
train: epoch 55, loss 0.2895834743976593, acc=0.8872222304344177, loss=0.2895834743976593
test: epoch 55, loss 1.388472080230713, acc=0.4694444537162781, loss=1.388472080230713
train: epoch 56, loss 0.3117794692516327, acc=0.8776111006736755, loss=0.3117794692516327
test: epoch 56, loss 1.2671523094177246, acc=0.5833333134651184, loss=1.2671523094177246
train: epoch 57, loss 0.28713110089302063, acc=0.887499988079071, loss=0.28713110089302063
test: epoch 57, loss 1.747420310974121, acc=0.4888888895511627, loss=1.747420310974121
train: epoch 58, loss 0.28277939558029175, acc=0.8929444551467896, loss=0.28277939558029175
test: epoch 58, loss 1.4070048332214355, acc=0.4972222149372101, loss=1.4070048332214355
train: epoch 59, loss 0.28421059250831604, acc=0.890666663646698, loss=0.28421059250831604
test: epoch 59, loss 1.3020983934402466, acc=0.5472221970558167, loss=1.3020983934402466
train: epoch 60, loss 0.27077460289001465, acc=0.8951666951179504, loss=0.27077460289001465
test: epoch 60, loss 1.676769495010376, acc=0.4833333194255829, loss=1.676769495010376
train: epoch 61, loss 0.2895837128162384, acc=0.8881111145019531, loss=0.2895837128162384
test: epoch 61, loss 1.4211987257003784, acc=0.5611110925674438, loss=1.4211987257003784
train: epoch 62, loss 0.2748759388923645, acc=0.8934999704360962, loss=0.2748759388923645
test: epoch 62, loss 1.38669753074646, acc=0.45277777314186096, loss=1.38669753074646
train: epoch 63, loss 0.29082855582237244, acc=0.8886111378669739, loss=0.29082855582237244
test: epoch 63, loss 1.328112006187439, acc=0.5222222208976746, loss=1.328112006187439
train: epoch 64, loss 0.2834041118621826, acc=0.8865000009536743, loss=0.2834041118621826
test: epoch 64, loss 1.2056246995925903, acc=0.4861111044883728, loss=1.2056246995925903
train: epoch 65, loss 0.272213339805603, acc=0.8959444165229797, loss=0.272213339805603
test: epoch 65, loss 1.1694962978363037, acc=0.5666666626930237, loss=1.1694962978363037
train: epoch 66, loss 0.2641630172729492, acc=0.8991666436195374, loss=0.2641630172729492
test: epoch 66, loss 1.1795231103897095, acc=0.5833333134651184, loss=1.1795231103897095
train: epoch 67, loss 0.26599955558776855, acc=0.8982222080230713, loss=0.26599955558776855
test: epoch 67, loss 1.3232946395874023, acc=0.49166667461395264, loss=1.3232946395874023
train: epoch 68, loss 0.2865988612174988, acc=0.8932777643203735, loss=0.2865988612174988
test: epoch 68, loss 1.477088451385498, acc=0.5333333611488342, loss=1.477088451385498
train: epoch 69, loss 0.25196072459220886, acc=0.9052777886390686, loss=0.25196072459220886
test: epoch 69, loss 1.0652307271957397, acc=0.6138888597488403, loss=1.0652307271957397
train: epoch 70, loss 0.26243096590042114, acc=0.899055540561676, loss=0.26243096590042114
test: epoch 70, loss 1.1996049880981445, acc=0.6666666865348816, loss=1.1996049880981445
train: epoch 71, loss 0.26375332474708557, acc=0.8996666669845581, loss=0.26375332474708557
test: epoch 71, loss 1.1282209157943726, acc=0.6111111044883728, loss=1.1282209157943726
train: epoch 72, loss 0.26141688227653503, acc=0.8968333601951599, loss=0.26141688227653503
test: epoch 72, loss 1.094222068786621, acc=0.6027777791023254, loss=1.094222068786621
train: epoch 73, loss 0.2452027052640915, acc=0.9049999713897705, loss=0.2452027052640915
test: epoch 73, loss 1.206055760383606, acc=0.5138888955116272, loss=1.206055760383606
train: epoch 74, loss 0.26691100001335144, acc=0.8995555639266968, loss=0.26691100001335144
test: epoch 74, loss 1.2131506204605103, acc=0.5527777671813965, loss=1.2131506204605103
train: epoch 75, loss 0.2510288655757904, acc=0.9042222499847412, loss=0.2510288655757904
test: epoch 75, loss 1.3906276226043701, acc=0.39722222089767456, loss=1.3906276226043701
train: epoch 76, loss 0.2745155394077301, acc=0.8945000171661377, loss=0.2745155394077301
test: epoch 76, loss 1.6338155269622803, acc=0.6194444298744202, loss=1.6338155269622803
train: epoch 77, loss 0.2577287256717682, acc=0.8997222185134888, loss=0.2577287256717682
test: epoch 77, loss 1.7084261178970337, acc=0.5, loss=1.7084261178970337
train: epoch 78, loss 0.2500340938568115, acc=0.9011111259460449, loss=0.2500340938568115
test: epoch 78, loss 1.1816678047180176, acc=0.49166667461395264, loss=1.1816678047180176
train: epoch 79, loss 0.25625380873680115, acc=0.9020000100135803, loss=0.25625380873680115
test: epoch 79, loss 0.9467985033988953, acc=0.550000011920929, loss=0.9467985033988953
train: epoch 80, loss 0.24990801513195038, acc=0.9035000205039978, loss=0.24990801513195038
test: epoch 80, loss 1.2771046161651611, acc=0.43611112236976624, loss=1.2771046161651611
train: epoch 81, loss 0.25782179832458496, acc=0.9024999737739563, loss=0.25782179832458496
test: epoch 81, loss 1.1932421922683716, acc=0.5333333611488342, loss=1.1932421922683716
train: epoch 82, loss 0.2471970021724701, acc=0.9045000076293945, loss=0.2471970021724701
test: epoch 82, loss 1.0684798955917358, acc=0.5555555820465088, loss=1.0684798955917358
train: epoch 83, loss 0.24470128118991852, acc=0.9053888916969299, loss=0.24470128118991852
test: epoch 83, loss 0.9624675512313843, acc=0.6388888955116272, loss=0.9624675512313843
train: epoch 84, loss 0.26209700107574463, acc=0.9008888602256775, loss=0.26209700107574463
test: epoch 84, loss 1.2502391338348389, acc=0.574999988079071, loss=1.2502391338348389
train: epoch 85, loss 0.23496359586715698, acc=0.9068333506584167, loss=0.23496359586715698
test: epoch 85, loss 1.1007628440856934, acc=0.5222222208976746, loss=1.1007628440856934
train: epoch 86, loss 0.26164883375167847, acc=0.8966666460037231, loss=0.26164883375167847
test: epoch 86, loss 1.0284098386764526, acc=0.4972222149372101, loss=1.0284098386764526
train: epoch 87, loss 0.2646982967853546, acc=0.8970000147819519, loss=0.2646982967853546
test: epoch 87, loss 0.9193230867385864, acc=0.6305555701255798, loss=0.9193230867385864
train: epoch 88, loss 0.22791258990764618, acc=0.913277804851532, loss=0.22791258990764618
test: epoch 88, loss 1.0194292068481445, acc=0.6111111044883728, loss=1.0194292068481445
train: epoch 89, loss 0.23099739849567413, acc=0.9119444489479065, loss=0.23099739849567413
test: epoch 89, loss 1.05843985080719, acc=0.5555555820465088, loss=1.05843985080719
train: epoch 90, loss 0.2500019371509552, acc=0.9069444537162781, loss=0.2500019371509552
test: epoch 90, loss 1.0886037349700928, acc=0.519444465637207, loss=1.0886037349700928
train: epoch 91, loss 0.2549660801887512, acc=0.9048888683319092, loss=0.2549660801887512
test: epoch 91, loss 0.9293242692947388, acc=0.675000011920929, loss=0.9293242692947388
train: epoch 92, loss 0.25312554836273193, acc=0.9041666388511658, loss=0.25312554836273193
test: epoch 92, loss 0.8903322219848633, acc=0.6861110925674438, loss=0.8903322219848633
train: epoch 93, loss 0.23214228451251984, acc=0.9127777814865112, loss=0.23214228451251984
test: epoch 93, loss 1.2388834953308105, acc=0.5694444179534912, loss=1.2388834953308105
train: epoch 94, loss 0.2653521001338959, acc=0.8978888988494873, loss=0.2653521001338959
test: epoch 94, loss 0.7960668206214905, acc=0.644444465637207, loss=0.7960668206214905
train: epoch 95, loss 0.24112583696842194, acc=0.9095555543899536, loss=0.24112583696842194
test: epoch 95, loss 1.042397141456604, acc=0.5861111283302307, loss=1.042397141456604
train: epoch 96, loss 0.2582181394100189, acc=0.897777795791626, loss=0.2582181394100189
test: epoch 96, loss 0.7949076294898987, acc=0.6583333611488342, loss=0.7949076294898987
train: epoch 97, loss 0.24146278202533722, acc=0.9071666598320007, loss=0.24146278202533722
test: epoch 97, loss 1.0534539222717285, acc=0.6166666746139526, loss=1.0534539222717285
train: epoch 98, loss 0.22262564301490784, acc=0.9144444465637207, loss=0.22262564301490784
test: epoch 98, loss 0.7068912386894226, acc=0.7138888835906982, loss=0.7068912386894226
train: epoch 99, loss 0.23752479255199432, acc=0.9092777967453003, loss=0.23752479255199432
test: epoch 99, loss 0.9113180041313171, acc=0.6222222447395325, loss=0.9113180041313171
train: epoch 100, loss 0.2582029402256012, acc=0.9018333554267883, loss=0.2582029402256012
test: epoch 100, loss 0.7061567306518555, acc=0.7111111283302307, loss=0.7061567306518555
train: epoch 101, loss 0.22171242535114288, acc=0.9163888692855835, loss=0.22171242535114288
test: epoch 101, loss 1.0706013441085815, acc=0.6777777671813965, loss=1.0706013441085815
train: epoch 102, loss 0.24459023773670197, acc=0.9066110849380493, loss=0.24459023773670197
test: epoch 102, loss 1.0794752836227417, acc=0.5416666865348816, loss=1.0794752836227417
train: epoch 103, loss 0.23006108403205872, acc=0.9130555391311646, loss=0.23006108403205872
test: epoch 103, loss 0.5485007762908936, acc=0.7777777910232544, loss=0.5485007762908936
train: epoch 104, loss 0.2298310101032257, acc=0.9118888974189758, loss=0.2298310101032257
test: epoch 104, loss 0.9498202204704285, acc=0.675000011920929, loss=0.9498202204704285
train: epoch 105, loss 0.21780158579349518, acc=0.9187777638435364, loss=0.21780158579349518
test: epoch 105, loss 0.9874122142791748, acc=0.6527777910232544, loss=0.9874122142791748
train: epoch 106, loss 0.23478512465953827, acc=0.9144444465637207, loss=0.23478512465953827
test: epoch 106, loss 0.9135225415229797, acc=0.6277777552604675, loss=0.9135225415229797
train: epoch 107, loss 0.22559009492397308, acc=0.9131110906600952, loss=0.22559009492397308
test: epoch 107, loss 0.8187801837921143, acc=0.6416666507720947, loss=0.8187801837921143
train: epoch 108, loss 0.2599806487560272, acc=0.9018333554267883, loss=0.2599806487560272
test: epoch 108, loss 1.4700850248336792, acc=0.5583333373069763, loss=1.4700850248336792
train: epoch 109, loss 0.23086391389369965, acc=0.9123333096504211, loss=0.23086391389369965
test: epoch 109, loss 0.8183495402336121, acc=0.6499999761581421, loss=0.8183495402336121
train: epoch 110, loss 0.21393810212612152, acc=0.918833315372467, loss=0.21393810212612152
test: epoch 110, loss 1.056899905204773, acc=0.6888889074325562, loss=1.056899905204773
train: epoch 111, loss 0.22673434019088745, acc=0.9153333306312561, loss=0.22673434019088745
test: epoch 111, loss 0.8119763731956482, acc=0.6972222328186035, loss=0.8119763731956482
train: epoch 112, loss 0.22137685120105743, acc=0.9175000190734863, loss=0.22137685120105743
test: epoch 112, loss 1.0463470220565796, acc=0.6027777791023254, loss=1.0463470220565796
train: epoch 113, loss 0.2365323156118393, acc=0.9090555310249329, loss=0.2365323156118393
test: epoch 113, loss 0.7260164022445679, acc=0.7277777791023254, loss=0.7260164022445679
train: epoch 114, loss 0.2554665207862854, acc=0.8999444246292114, loss=0.2554665207862854
test: epoch 114, loss 0.6530571579933167, acc=0.75, loss=0.6530571579933167
train: epoch 115, loss 0.21993733942508698, acc=0.9158333539962769, loss=0.21993733942508698
test: epoch 115, loss 0.5393989086151123, acc=0.7444444298744202, loss=0.5393989086151123
train: epoch 116, loss 0.2274477630853653, acc=0.9127222299575806, loss=0.2274477630853653
test: epoch 116, loss 0.7289408445358276, acc=0.7666666507720947, loss=0.7289408445358276
train: epoch 117, loss 0.22005338966846466, acc=0.9158889055252075, loss=0.22005338966846466
test: epoch 117, loss 0.5893591642379761, acc=0.6972222328186035, loss=0.5893591642379761
train: epoch 118, loss 0.22043205797672272, acc=0.9153333306312561, loss=0.22043205797672272
test: epoch 118, loss 0.666129469871521, acc=0.7388888597488403, loss=0.666129469871521
train: epoch 119, loss 0.27508676052093506, acc=0.8967777490615845, loss=0.27508676052093506
test: epoch 119, loss 0.72430419921875, acc=0.730555534362793, loss=0.72430419921875
train: epoch 120, loss 0.2506695091724396, acc=0.9053333401679993, loss=0.2506695091724396
test: epoch 120, loss 0.5682031512260437, acc=0.7805555462837219, loss=0.5682031512260437
train: epoch 121, loss 0.23185811936855316, acc=0.9114999771118164, loss=0.23185811936855316
test: epoch 121, loss 0.8025460243225098, acc=0.7027778029441833, loss=0.8025460243225098
train: epoch 122, loss 0.2045135796070099, acc=0.921833336353302, loss=0.2045135796070099
test: epoch 122, loss 0.8265131115913391, acc=0.7527777552604675, loss=0.8265131115913391
train: epoch 123, loss 0.2597092390060425, acc=0.8986666798591614, loss=0.2597092390060425
test: epoch 123, loss 0.6244403719902039, acc=0.6888889074325562, loss=0.6244403719902039
train: epoch 124, loss 0.25883686542510986, acc=0.8998888731002808, loss=0.25883686542510986
test: epoch 124, loss 0.5510658621788025, acc=0.7527777552604675, loss=0.5510658621788025
train: epoch 125, loss 0.21216630935668945, acc=0.9161111116409302, loss=0.21216630935668945
test: epoch 125, loss 0.6112585067749023, acc=0.7194444537162781, loss=0.6112585067749023
train: epoch 126, loss 0.24783383309841156, acc=0.906000018119812, loss=0.24783383309841156
test: epoch 126, loss 0.47506868839263916, acc=0.7583333253860474, loss=0.47506868839263916
train: epoch 127, loss 0.23634065687656403, acc=0.9075555801391602, loss=0.23634065687656403
test: epoch 127, loss 0.7405343055725098, acc=0.7166666388511658, loss=0.7405343055725098
train: epoch 128, loss 0.23073330521583557, acc=0.9104999899864197, loss=0.23073330521583557
test: epoch 128, loss 0.9323045611381531, acc=0.644444465637207, loss=0.9323045611381531
train: epoch 129, loss 0.24316523969173431, acc=0.9046666622161865, loss=0.24316523969173431
test: epoch 129, loss 0.6022438406944275, acc=0.7333333492279053, loss=0.6022438406944275
train: epoch 130, loss 0.2046830654144287, acc=0.9222221970558167, loss=0.2046830654144287
test: epoch 130, loss 0.43087103962898254, acc=0.8194444179534912, loss=0.43087103962898254
train: epoch 131, loss 0.2584604322910309, acc=0.9017221927642822, loss=0.2584604322910309
test: epoch 131, loss 0.6898439526557922, acc=0.7583333253860474, loss=0.6898439526557922
train: epoch 132, loss 0.22554734349250793, acc=0.9123888611793518, loss=0.22554734349250793
test: epoch 132, loss 0.5328226685523987, acc=0.7666666507720947, loss=0.5328226685523987
train: epoch 133, loss 0.24666371941566467, acc=0.9089444279670715, loss=0.24666371941566467
test: epoch 133, loss 0.8955345153808594, acc=0.6833333373069763, loss=0.8955345153808594
train: epoch 134, loss 0.21788886189460754, acc=0.9169999957084656, loss=0.21788886189460754
test: epoch 134, loss 0.587763249874115, acc=0.75, loss=0.587763249874115
train: epoch 135, loss 0.23560400307178497, acc=0.910611093044281, loss=0.23560400307178497
test: epoch 135, loss 0.42685142159461975, acc=0.7972221970558167, loss=0.42685142159461975
train: epoch 136, loss 0.2419171780347824, acc=0.9062222242355347, loss=0.2419171780347824
test: epoch 136, loss 0.5174593925476074, acc=0.7861111164093018, loss=0.5174593925476074
train: epoch 137, loss 0.22269318997859955, acc=0.9146666526794434, loss=0.22269318997859955
test: epoch 137, loss 0.6150087118148804, acc=0.7833333611488342, loss=0.6150087118148804
train: epoch 138, loss 0.22716699540615082, acc=0.9139444231987, loss=0.22716699540615082
test: epoch 138, loss 0.805611789226532, acc=0.6555555462837219, loss=0.805611789226532
train: epoch 139, loss 0.23217535018920898, acc=0.9114444255828857, loss=0.23217535018920898
test: epoch 139, loss 0.6787669062614441, acc=0.7416666746139526, loss=0.6787669062614441
train: epoch 140, loss 0.22130993008613586, acc=0.9160000085830688, loss=0.22130993008613586
test: epoch 140, loss 0.5068784356117249, acc=0.8166666626930237, loss=0.5068784356117249
train: epoch 141, loss 0.19568847119808197, acc=0.9253888726234436, loss=0.19568847119808197
test: epoch 141, loss 0.8100362420082092, acc=0.7388888597488403, loss=0.8100362420082092
train: epoch 142, loss 0.29136666655540466, acc=0.8914444446563721, loss=0.29136666655540466
test: epoch 142, loss 0.6704583764076233, acc=0.699999988079071, loss=0.6704583764076233
train: epoch 143, loss 0.25029611587524414, acc=0.9072222113609314, loss=0.25029611587524414
test: epoch 143, loss 0.5627614855766296, acc=0.7194444537162781, loss=0.5627614855766296
train: epoch 144, loss 0.23709337413311005, acc=0.9054444432258606, loss=0.23709337413311005
test: epoch 144, loss 0.6674627065658569, acc=0.7055555582046509, loss=0.6674627065658569
train: epoch 145, loss 0.25869667530059814, acc=0.893666684627533, loss=0.25869667530059814
test: epoch 145, loss 0.5744072794914246, acc=0.7916666865348816, loss=0.5744072794914246
train: epoch 146, loss 0.247786283493042, acc=0.8996111154556274, loss=0.247786283493042
test: epoch 146, loss 0.4657650887966156, acc=0.8111110925674438, loss=0.4657650887966156
train: epoch 147, loss 0.2593400776386261, acc=0.8945555686950684, loss=0.2593400776386261
test: epoch 147, loss 0.48718857765197754, acc=0.8111110925674438, loss=0.48718857765197754
train: epoch 148, loss 0.25126129388809204, acc=0.8963333368301392, loss=0.25126129388809204
test: epoch 148, loss 0.5319303274154663, acc=0.8055555820465088, loss=0.5319303274154663
train: epoch 149, loss 0.24384507536888123, acc=0.9013333320617676, loss=0.24384507536888123
test: epoch 149, loss 0.43916958570480347, acc=0.8194444179534912, loss=0.43916958570480347
train: epoch 150, loss 0.20469553768634796, acc=0.9208889007568359, loss=0.20469553768634796
test: epoch 150, loss 0.34246113896369934, acc=0.8361111283302307, loss=0.34246113896369934
