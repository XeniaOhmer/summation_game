# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=1.5", "--temp_decay=0.99", "--one_hot=false", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1112580642, receiver_embed_dim=128, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.6992197036743164, acc=0.10738889127969742, loss=2.6992197036743164
test: epoch 1, loss 2.6487059593200684, acc=0.14722222089767456, loss=2.6487059593200684
train: epoch 2, loss 1.761724591255188, acc=0.25772222876548767, loss=1.761724591255188
test: epoch 2, loss 2.1920993328094482, acc=0.21944443881511688, loss=2.1920993328094482
train: epoch 3, loss 1.4218618869781494, acc=0.3586111068725586, loss=1.4218618869781494
test: epoch 3, loss 2.207412004470825, acc=0.24722221493721008, loss=2.207412004470825
train: epoch 4, loss 1.2271738052368164, acc=0.43861111998558044, loss=1.2271738052368164
test: epoch 4, loss 1.7159627676010132, acc=0.34166666865348816, loss=1.7159627676010132
train: epoch 5, loss 1.0773836374282837, acc=0.5043888688087463, loss=1.0773836374282837
test: epoch 5, loss 1.9165741205215454, acc=0.2638888955116272, loss=1.9165741205215454
train: epoch 6, loss 0.9286665916442871, acc=0.5711110830307007, loss=0.9286665916442871
test: epoch 6, loss 1.4907057285308838, acc=0.41111111640930176, loss=1.4907057285308838
train: epoch 7, loss 0.849506139755249, acc=0.6199444532394409, loss=0.849506139755249
test: epoch 7, loss 1.0755435228347778, acc=0.519444465637207, loss=1.0755435228347778
train: epoch 8, loss 0.6900337934494019, acc=0.6881666779518127, loss=0.6900337934494019
test: epoch 8, loss 1.1739544868469238, acc=0.5111111402511597, loss=1.1739544868469238
train: epoch 9, loss 0.5818787217140198, acc=0.7367777824401855, loss=0.5818787217140198
test: epoch 9, loss 0.8174024224281311, acc=0.6972222328186035, loss=0.8174024224281311
train: epoch 10, loss 0.4964977502822876, acc=0.7788333296775818, loss=0.4964977502822876
test: epoch 10, loss 0.5968738198280334, acc=0.7277777791023254, loss=0.5968738198280334
train: epoch 11, loss 0.40276458859443665, acc=0.8150555491447449, loss=0.40276458859443665
test: epoch 11, loss 0.5833824276924133, acc=0.7805555462837219, loss=0.5833824276924133
train: epoch 12, loss 0.3803330361843109, acc=0.8238333463668823, loss=0.3803330361843109
test: epoch 12, loss 0.5692201256752014, acc=0.7861111164093018, loss=0.5692201256752014
train: epoch 13, loss 0.365167498588562, acc=0.8300555348396301, loss=0.365167498588562
test: epoch 13, loss 0.39760810136795044, acc=0.8222222328186035, loss=0.39760810136795044
train: epoch 14, loss 0.32176104187965393, acc=0.8421111106872559, loss=0.32176104187965393
test: epoch 14, loss 0.4755595326423645, acc=0.8111110925674438, loss=0.4755595326423645
train: epoch 15, loss 0.3182711899280548, acc=0.8454999923706055, loss=0.3182711899280548
test: epoch 15, loss 0.43040356040000916, acc=0.824999988079071, loss=0.43040356040000916
train: epoch 16, loss 0.3537636697292328, acc=0.840499997138977, loss=0.3537636697292328
test: epoch 16, loss 0.38621920347213745, acc=0.8333333134651184, loss=0.38621920347213745
train: epoch 17, loss 0.31486061215400696, acc=0.8416110873222351, loss=0.31486061215400696
test: epoch 17, loss 0.3698205351829529, acc=0.8416666388511658, loss=0.3698205351829529
train: epoch 18, loss 0.3479432761669159, acc=0.8380555510520935, loss=0.3479432761669159
test: epoch 18, loss 0.313694566488266, acc=0.8416666388511658, loss=0.313694566488266
train: epoch 19, loss 0.29560554027557373, acc=0.8523333072662354, loss=0.29560554027557373
test: epoch 19, loss 0.33261457085609436, acc=0.8305555582046509, loss=0.33261457085609436
train: epoch 20, loss 0.38307803869247437, acc=0.8289999961853027, loss=0.38307803869247437
test: epoch 20, loss 0.4868319034576416, acc=0.7972221970558167, loss=0.4868319034576416
train: epoch 21, loss 0.33071961998939514, acc=0.8370555639266968, loss=0.33071961998939514
test: epoch 21, loss 0.44721347093582153, acc=0.8111110925674438, loss=0.44721347093582153
train: epoch 22, loss 0.35448911786079407, acc=0.8325555324554443, loss=0.35448911786079407
test: epoch 22, loss 0.469803124666214, acc=0.7972221970558167, loss=0.469803124666214
train: epoch 23, loss 0.3160133957862854, acc=0.840499997138977, loss=0.3160133957862854
test: epoch 23, loss 0.37194108963012695, acc=0.8416666388511658, loss=0.37194108963012695
train: epoch 24, loss 0.37476250529289246, acc=0.8258888721466064, loss=0.37476250529289246
test: epoch 24, loss 0.49532192945480347, acc=0.800000011920929, loss=0.49532192945480347
train: epoch 25, loss 0.3411996364593506, acc=0.8325555324554443, loss=0.3411996364593506
test: epoch 25, loss 0.38270723819732666, acc=0.8305555582046509, loss=0.38270723819732666
train: epoch 26, loss 0.3615597188472748, acc=0.8141111135482788, loss=0.3615597188472748
test: epoch 26, loss 0.3637964129447937, acc=0.8111110925674438, loss=0.3637964129447937
train: epoch 27, loss 0.3949880599975586, acc=0.7951111197471619, loss=0.3949880599975586
test: epoch 27, loss 0.42203912138938904, acc=0.7861111164093018, loss=0.42203912138938904
train: epoch 28, loss 0.378135621547699, acc=0.8059444427490234, loss=0.378135621547699
test: epoch 28, loss 0.4520452916622162, acc=0.7972221970558167, loss=0.4520452916622162
train: epoch 29, loss 0.3396397829055786, acc=0.8165000081062317, loss=0.3396397829055786
test: epoch 29, loss 0.354882150888443, acc=0.8166666626930237, loss=0.354882150888443
train: epoch 30, loss 0.3420754373073578, acc=0.8190555572509766, loss=0.3420754373073578
test: epoch 30, loss 0.4938466548919678, acc=0.7888888716697693, loss=0.4938466548919678
train: epoch 31, loss 0.38005170226097107, acc=0.7976666688919067, loss=0.38005170226097107
test: epoch 31, loss 0.5424491763114929, acc=0.7722222208976746, loss=0.5424491763114929
train: epoch 32, loss 0.3598654270172119, acc=0.8077222108840942, loss=0.3598654270172119
test: epoch 32, loss 0.3022501766681671, acc=0.8388888835906982, loss=0.3022501766681671
train: epoch 33, loss 0.2694813013076782, acc=0.8421666622161865, loss=0.2694813013076782
test: epoch 33, loss 0.29501983523368835, acc=0.8444444537162781, loss=0.29501983523368835
train: epoch 34, loss 0.428915411233902, acc=0.8106111288070679, loss=0.428915411233902
test: epoch 34, loss 0.5510642528533936, acc=0.8083333373069763, loss=0.5510642528533936
train: epoch 35, loss 0.45697376132011414, acc=0.7947777509689331, loss=0.45697376132011414
test: epoch 35, loss 0.393979012966156, acc=0.8222222328186035, loss=0.393979012966156
train: epoch 36, loss 0.3338033854961395, acc=0.823722243309021, loss=0.3338033854961395
test: epoch 36, loss 0.3201889991760254, acc=0.8361111283302307, loss=0.3201889991760254
train: epoch 37, loss 0.4012523293495178, acc=0.7969444394111633, loss=0.4012523293495178
test: epoch 37, loss 0.3766571879386902, acc=0.8194444179534912, loss=0.3766571879386902
train: epoch 38, loss 0.48336267471313477, acc=0.7623888850212097, loss=0.48336267471313477
test: epoch 38, loss 0.49883902072906494, acc=0.7555555701255798, loss=0.49883902072906494
train: epoch 39, loss 0.4201474189758301, acc=0.7870555520057678, loss=0.4201474189758301
test: epoch 39, loss 0.4028751850128174, acc=0.8222222328186035, loss=0.4028751850128174
train: epoch 40, loss 0.32563790678977966, acc=0.8211666941642761, loss=0.32563790678977966
test: epoch 40, loss 0.302084356546402, acc=0.8361111283302307, loss=0.302084356546402
train: epoch 41, loss 0.3967944085597992, acc=0.8020555377006531, loss=0.3967944085597992
test: epoch 41, loss 0.48740074038505554, acc=0.8111110925674438, loss=0.48740074038505554
train: epoch 42, loss 0.4218045473098755, acc=0.7850000262260437, loss=0.4218045473098755
test: epoch 42, loss 0.38330578804016113, acc=0.7972221970558167, loss=0.38330578804016113
train: epoch 43, loss 0.3793133795261383, acc=0.7903333306312561, loss=0.3793133795261383
test: epoch 43, loss 0.34240108728408813, acc=0.8138889074325562, loss=0.34240108728408813
train: epoch 44, loss 0.44350188970565796, acc=0.7868333458900452, loss=0.44350188970565796
test: epoch 44, loss 0.4063792824745178, acc=0.800000011920929, loss=0.4063792824745178
train: epoch 45, loss 0.45649972558021545, acc=0.7714999914169312, loss=0.45649972558021545
test: epoch 45, loss 0.3370257616043091, acc=0.8222222328186035, loss=0.3370257616043091
train: epoch 46, loss 0.36243483424186707, acc=0.804111123085022, loss=0.36243483424186707
test: epoch 46, loss 0.4047613739967346, acc=0.7972221970558167, loss=0.4047613739967346
train: epoch 47, loss 0.5078598260879517, acc=0.7661111354827881, loss=0.5078598260879517
test: epoch 47, loss 0.46209362149238586, acc=0.7861111164093018, loss=0.46209362149238586
train: epoch 48, loss 0.38273271918296814, acc=0.7896666526794434, loss=0.38273271918296814
test: epoch 48, loss 0.31649118661880493, acc=0.8194444179534912, loss=0.31649118661880493
train: epoch 49, loss 0.4212763011455536, acc=0.7738333344459534, loss=0.4212763011455536
test: epoch 49, loss 0.48918089270591736, acc=0.7333333492279053, loss=0.48918089270591736
train: epoch 50, loss 0.47815483808517456, acc=0.7688888907432556, loss=0.47815483808517456
test: epoch 50, loss 0.46886971592903137, acc=0.769444465637207, loss=0.46886971592903137
train: epoch 51, loss 0.489994078874588, acc=0.7497777938842773, loss=0.489994078874588
test: epoch 51, loss 0.42102089524269104, acc=0.7833333611488342, loss=0.42102089524269104
train: epoch 52, loss 0.40978190302848816, acc=0.7619444727897644, loss=0.40978190302848816
test: epoch 52, loss 0.38998210430145264, acc=0.7972221970558167, loss=0.38998210430145264
train: epoch 53, loss 0.3918811082839966, acc=0.7622222304344177, loss=0.3918811082839966
test: epoch 53, loss 0.38048142194747925, acc=0.800000011920929, loss=0.38048142194747925
train: epoch 54, loss 0.3830483555793762, acc=0.7648888826370239, loss=0.3830483555793762
test: epoch 54, loss 0.38000577688217163, acc=0.800000011920929, loss=0.38000577688217163
train: epoch 55, loss 0.3827323317527771, acc=0.7649999856948853, loss=0.3827323317527771
test: epoch 55, loss 0.37995266914367676, acc=0.800000011920929, loss=0.37995266914367676
train: epoch 56, loss 0.38258254528045654, acc=0.7648888826370239, loss=0.38258254528045654
test: epoch 56, loss 0.3799276649951935, acc=0.800000011920929, loss=0.3799276649951935
train: epoch 57, loss 0.520595133304596, acc=0.7290555834770203, loss=0.520595133304596
test: epoch 57, loss 0.9149345755577087, acc=0.5972222089767456, loss=0.9149345755577087
train: epoch 58, loss 0.770697832107544, acc=0.6510000228881836, loss=0.770697832107544
test: epoch 58, loss 0.5679059028625488, acc=0.7250000238418579, loss=0.5679059028625488
train: epoch 59, loss 0.5716139674186707, acc=0.7124444246292114, loss=0.5716139674186707
test: epoch 59, loss 0.7269982695579529, acc=0.7027778029441833, loss=0.7269982695579529
train: epoch 60, loss 0.5169467926025391, acc=0.7153888940811157, loss=0.5169467926025391
test: epoch 60, loss 0.4821888208389282, acc=0.7444444298744202, loss=0.4821888208389282
train: epoch 61, loss 0.5682215690612793, acc=0.7010555267333984, loss=0.5682215690612793
test: epoch 61, loss 0.5287413001060486, acc=0.7388888597488403, loss=0.5287413001060486
train: epoch 62, loss 0.523385763168335, acc=0.7427777647972107, loss=0.523385763168335
test: epoch 62, loss 0.551530122756958, acc=0.7333333492279053, loss=0.551530122756958
train: epoch 63, loss 0.5501924753189087, acc=0.7260000109672546, loss=0.5501924753189087
test: epoch 63, loss 0.5217509269714355, acc=0.7444444298744202, loss=0.5217509269714355
train: epoch 64, loss 0.5374573469161987, acc=0.7184444665908813, loss=0.5374573469161987
test: epoch 64, loss 0.5532539486885071, acc=0.730555534362793, loss=0.5532539486885071
train: epoch 65, loss 0.6186414361000061, acc=0.7213888764381409, loss=0.6186414361000061
test: epoch 65, loss 0.6259884238243103, acc=0.7333333492279053, loss=0.6259884238243103
train: epoch 66, loss 0.44301605224609375, acc=0.7455000281333923, loss=0.44301605224609375
test: epoch 66, loss 0.4186766445636749, acc=0.7749999761581421, loss=0.4186766445636749
train: epoch 67, loss 0.4214290976524353, acc=0.7459999918937683, loss=0.4214290976524353
test: epoch 67, loss 0.41845232248306274, acc=0.7749999761581421, loss=0.41845232248306274
train: epoch 68, loss 0.42161375284194946, acc=0.7463889122009277, loss=0.42161375284194946
test: epoch 68, loss 0.4184347093105316, acc=0.7749999761581421, loss=0.4184347093105316
train: epoch 69, loss 0.4209088385105133, acc=0.7446110844612122, loss=0.4209088385105133
test: epoch 69, loss 0.41835373640060425, acc=0.7749999761581421, loss=0.41835373640060425
train: epoch 70, loss 0.7056145071983337, acc=0.6868333220481873, loss=0.7056145071983337
test: epoch 70, loss 0.6882098317146301, acc=0.6833333373069763, loss=0.6882098317146301
train: epoch 71, loss 0.5997713804244995, acc=0.7023333311080933, loss=0.5997713804244995
test: epoch 71, loss 0.5612340569496155, acc=0.7166666388511658, loss=0.5612340569496155
train: epoch 72, loss 0.6427888870239258, acc=0.6785555481910706, loss=0.6427888870239258
test: epoch 72, loss 0.6680876612663269, acc=0.675000011920929, loss=0.6680876612663269
train: epoch 73, loss 0.6686599850654602, acc=0.6647777557373047, loss=0.6686599850654602
test: epoch 73, loss 0.6606348156929016, acc=0.6805555820465088, loss=0.6606348156929016
train: epoch 74, loss 0.6304750442504883, acc=0.6617222428321838, loss=0.6304750442504883
test: epoch 74, loss 0.6216467022895813, acc=0.6833333373069763, loss=0.6216467022895813
train: epoch 75, loss 0.6685011982917786, acc=0.6498888731002808, loss=0.6685011982917786
test: epoch 75, loss 0.8933285474777222, acc=0.6083333492279053, loss=0.8933285474777222
train: epoch 76, loss 0.7081204652786255, acc=0.649222195148468, loss=0.7081204652786255
test: epoch 76, loss 0.6050748229026794, acc=0.7027778029441833, loss=0.6050748229026794
train: epoch 77, loss 0.5627543330192566, acc=0.7041666507720947, loss=0.5627543330192566
test: epoch 77, loss 0.5113237500190735, acc=0.7166666388511658, loss=0.5113237500190735
train: epoch 78, loss 0.5137531161308289, acc=0.7050555348396301, loss=0.5137531161308289
test: epoch 78, loss 0.509564220905304, acc=0.7166666388511658, loss=0.509564220905304
train: epoch 79, loss 0.5129847526550293, acc=0.7006111145019531, loss=0.5129847526550293
test: epoch 79, loss 0.5093714594841003, acc=0.7166666388511658, loss=0.5093714594841003
train: epoch 80, loss 0.5126089453697205, acc=0.6996666789054871, loss=0.5126089453697205
test: epoch 80, loss 0.5092920660972595, acc=0.7166666388511658, loss=0.5092920660972595
train: epoch 81, loss 0.5124348998069763, acc=0.6992777585983276, loss=0.5124348998069763
test: epoch 81, loss 0.509252667427063, acc=0.7166666388511658, loss=0.509252667427063
train: epoch 82, loss 0.6889216899871826, acc=0.6549444198608398, loss=0.6889216899871826
test: epoch 82, loss 0.8392471671104431, acc=0.6138888597488403, loss=0.8392471671104431
train: epoch 83, loss 0.7714982032775879, acc=0.6355555653572083, loss=0.7714982032775879
test: epoch 83, loss 0.6714717745780945, acc=0.6722221970558167, loss=0.6714717745780945
train: epoch 84, loss 0.6934719681739807, acc=0.6652777791023254, loss=0.6934719681739807
test: epoch 84, loss 0.6480637788772583, acc=0.6972222328186035, loss=0.6480637788772583
train: epoch 85, loss 0.6534563302993774, acc=0.6840555667877197, loss=0.6534563302993774
test: epoch 85, loss 0.6185194849967957, acc=0.699999988079071, loss=0.6185194849967957
train: epoch 86, loss 0.6217559576034546, acc=0.6788333058357239, loss=0.6217559576034546
test: epoch 86, loss 0.6175588965415955, acc=0.699999988079071, loss=0.6175588965415955
train: epoch 87, loss 0.6641784310340881, acc=0.6735555529594421, loss=0.6641784310340881
test: epoch 87, loss 0.6577431559562683, acc=0.6916666626930237, loss=0.6577431559562683
train: epoch 88, loss 0.6763463020324707, acc=0.6738888621330261, loss=0.6763463020324707
test: epoch 88, loss 0.7661542296409607, acc=0.6333333253860474, loss=0.7661542296409607
train: epoch 89, loss 0.7793996930122375, acc=0.6312222480773926, loss=0.7793996930122375
test: epoch 89, loss 0.7964447140693665, acc=0.625, loss=0.7964447140693665
train: epoch 90, loss 0.6620278358459473, acc=0.6859999895095825, loss=0.6620278358459473
test: epoch 90, loss 0.5861812829971313, acc=0.7083333134651184, loss=0.5861812829971313
train: epoch 91, loss 0.5919494032859802, acc=0.7041666507720947, loss=0.5919494032859802
test: epoch 91, loss 0.5790085196495056, acc=0.7111111283302307, loss=0.5790085196495056
train: epoch 92, loss 0.580051600933075, acc=0.707444429397583, loss=0.580051600933075
test: epoch 92, loss 0.5685648918151855, acc=0.7194444537162781, loss=0.5685648918151855
train: epoch 93, loss 0.5798651576042175, acc=0.7142221927642822, loss=0.5798651576042175
test: epoch 93, loss 0.5634294152259827, acc=0.7222222089767456, loss=0.5634294152259827
train: epoch 94, loss 0.691190242767334, acc=0.6861110925674438, loss=0.691190242767334
test: epoch 94, loss 0.633139431476593, acc=0.699999988079071, loss=0.633139431476593
train: epoch 95, loss 0.6196584701538086, acc=0.7007777690887451, loss=0.6196584701538086
test: epoch 95, loss 0.6077888011932373, acc=0.7083333134651184, loss=0.6077888011932373
train: epoch 96, loss 0.6109932065010071, acc=0.6976110935211182, loss=0.6109932065010071
test: epoch 96, loss 0.6075273156166077, acc=0.7083333134651184, loss=0.6075273156166077
train: epoch 97, loss 0.6296208500862122, acc=0.6973333358764648, loss=0.6296208500862122
test: epoch 97, loss 0.7009921073913574, acc=0.6861110925674438, loss=0.7009921073913574
train: epoch 98, loss 0.8183819651603699, acc=0.6340555548667908, loss=0.8183819651603699
test: epoch 98, loss 0.7406409382820129, acc=0.6638888716697693, loss=0.7406409382820129
train: epoch 99, loss 0.7168813347816467, acc=0.6551111340522766, loss=0.7168813347816467
test: epoch 99, loss 0.682767927646637, acc=0.6833333373069763, loss=0.682767927646637
train: epoch 100, loss 0.9225863814353943, acc=0.5842221975326538, loss=0.9225863814353943
test: epoch 100, loss 0.9150879383087158, acc=0.5916666388511658, loss=0.9150879383087158
train: epoch 101, loss 0.8766279220581055, acc=0.5760555267333984, loss=0.8766279220581055
test: epoch 101, loss 0.8392282724380493, acc=0.605555534362793, loss=0.8392282724380493
train: epoch 102, loss 0.8600600957870483, acc=0.5761666893959045, loss=0.8600600957870483
test: epoch 102, loss 0.8584200143814087, acc=0.6194444298744202, loss=0.8584200143814087
train: epoch 103, loss 0.8105204105377197, acc=0.6202222108840942, loss=0.8105204105377197
test: epoch 103, loss 0.7533313632011414, acc=0.6499999761581421, loss=0.7533313632011414
train: epoch 104, loss 0.7572500109672546, acc=0.617555558681488, loss=0.7572500109672546
test: epoch 104, loss 0.7512211203575134, acc=0.6499999761581421, loss=0.7512211203575134
train: epoch 105, loss 0.8756324052810669, acc=0.5991666913032532, loss=0.8756324052810669
test: epoch 105, loss 0.8062766194343567, acc=0.6333333253860474, loss=0.8062766194343567
train: epoch 106, loss 0.8009941577911377, acc=0.6222222447395325, loss=0.8009941577911377
test: epoch 106, loss 0.7901932001113892, acc=0.6333333253860474, loss=0.7901932001113892
train: epoch 107, loss 0.7920587658882141, acc=0.6228333115577698, loss=0.7920587658882141
test: epoch 107, loss 0.7860341668128967, acc=0.6361111402511597, loss=0.7860341668128967
train: epoch 108, loss 0.791019082069397, acc=0.6236666440963745, loss=0.791019082069397
test: epoch 108, loss 0.7859091758728027, acc=0.6361111402511597, loss=0.7859091758728027
train: epoch 109, loss 0.7817744016647339, acc=0.6174444556236267, loss=0.7817744016647339
test: epoch 109, loss 0.7739720940589905, acc=0.6388888955116272, loss=0.7739720940589905
train: epoch 110, loss 0.9122363328933716, acc=0.5902222394943237, loss=0.9122363328933716
test: epoch 110, loss 1.0739805698394775, acc=0.5305555462837219, loss=1.0739805698394775
train: epoch 111, loss 1.0276167392730713, acc=0.5390555262565613, loss=1.0276167392730713
test: epoch 111, loss 0.9874997138977051, acc=0.5527777671813965, loss=0.9874997138977051
train: epoch 112, loss 0.9890422224998474, acc=0.5529999732971191, loss=0.9890422224998474
test: epoch 112, loss 0.9509081840515137, acc=0.574999988079071, loss=0.9509081840515137
train: epoch 113, loss 0.9486265182495117, acc=0.5836666822433472, loss=0.9486265182495117
test: epoch 113, loss 0.8720513582229614, acc=0.6083333492279053, loss=0.8720513582229614
train: epoch 114, loss 0.903220534324646, acc=0.6016111373901367, loss=0.903220534324646
test: epoch 114, loss 0.8798608183860779, acc=0.6222222447395325, loss=0.8798608183860779
train: epoch 115, loss 0.9069973230361938, acc=0.6091111302375793, loss=0.9069973230361938
test: epoch 115, loss 0.9087710976600647, acc=0.6027777791023254, loss=0.9087710976600647
train: epoch 116, loss 0.8992326855659485, acc=0.5889999866485596, loss=0.8992326855659485
test: epoch 116, loss 0.8889641761779785, acc=0.605555534362793, loss=0.8889641761779785
train: epoch 117, loss 0.8938645720481873, acc=0.5836666822433472, loss=0.8938645720481873
test: epoch 117, loss 0.888523519039154, acc=0.605555534362793, loss=0.888523519039154
train: epoch 118, loss 0.938693642616272, acc=0.5796666741371155, loss=0.938693642616272
test: epoch 118, loss 0.9248031973838806, acc=0.6027777791023254, loss=0.9248031973838806
train: epoch 119, loss 0.9095606803894043, acc=0.5796111226081848, loss=0.9095606803894043
test: epoch 119, loss 0.8959228992462158, acc=0.5916666388511658, loss=0.8959228992462158
train: epoch 120, loss 0.9078123569488525, acc=0.5537777543067932, loss=0.9078123569488525
test: epoch 120, loss 0.9026711583137512, acc=0.5916666388511658, loss=0.9026711583137512
train: epoch 121, loss 0.898081362247467, acc=0.5571110844612122, loss=0.898081362247467
test: epoch 121, loss 0.8900789022445679, acc=0.5944444537162781, loss=0.8900789022445679
train: epoch 122, loss 0.8942437171936035, acc=0.5530555844306946, loss=0.8942437171936035
test: epoch 122, loss 0.8898388743400574, acc=0.5944444537162781, loss=0.8898388743400574
train: epoch 123, loss 0.8940597176551819, acc=0.5552777647972107, loss=0.8940597176551819
test: epoch 123, loss 0.8897591829299927, acc=0.5944444537162781, loss=0.8897591829299927
train: epoch 124, loss 0.8939644694328308, acc=0.5535555481910706, loss=0.8939644694328308
test: epoch 124, loss 0.8897140622138977, acc=0.5944444537162781, loss=0.8897140622138977
train: epoch 125, loss 1.0568301677703857, acc=0.5257777571678162, loss=1.0568301677703857
test: epoch 125, loss 1.56886887550354, acc=0.3888888955116272, loss=1.56886887550354
train: epoch 126, loss 1.2499854564666748, acc=0.4427777826786041, loss=1.2499854564666748
test: epoch 126, loss 1.1722697019577026, acc=0.47777777910232544, loss=1.1722697019577026
train: epoch 127, loss 1.1319760084152222, acc=0.48311111330986023, loss=1.1319760084152222
test: epoch 127, loss 1.1002978086471558, acc=0.4972222149372101, loss=1.1002978086471558
train: epoch 128, loss 1.1049851179122925, acc=0.4833333194255829, loss=1.1049851179122925
test: epoch 128, loss 1.0990681648254395, acc=0.4972222149372101, loss=1.0990681648254395
train: epoch 129, loss 1.1041159629821777, acc=0.47688889503479004, loss=1.1041159629821777
test: epoch 129, loss 1.0988062620162964, acc=0.4972222149372101, loss=1.0988062620162964
train: epoch 130, loss 1.1037229299545288, acc=0.47699999809265137, loss=1.1037229299545288
test: epoch 130, loss 1.0986756086349487, acc=0.4972222149372101, loss=1.0986756086349487
train: epoch 131, loss 1.1238471269607544, acc=0.47688889503479004, loss=1.1238471269607544
test: epoch 131, loss 1.3107632398605347, acc=0.47777777910232544, loss=1.3107632398605347
train: epoch 132, loss 1.7478762865066528, acc=0.3362777829170227, loss=1.7478762865066528
test: epoch 132, loss 1.6766090393066406, acc=0.3333333432674408, loss=1.6766090393066406
train: epoch 133, loss 1.6841959953308105, acc=0.33455556631088257, loss=1.6841959953308105
test: epoch 133, loss 1.9700120687484741, acc=0.2944444417953491, loss=1.9700120687484741
train: epoch 134, loss 1.7541406154632568, acc=0.3118889033794403, loss=1.7541406154632568
test: epoch 134, loss 1.7273892164230347, acc=0.32777777314186096, loss=1.7273892164230347
train: epoch 135, loss 1.732326865196228, acc=0.3143889009952545, loss=1.732326865196228
test: epoch 135, loss 1.7300019264221191, acc=0.32777777314186096, loss=1.7300019264221191
train: epoch 136, loss 1.7361962795257568, acc=0.3142777681350708, loss=1.7361962795257568
test: epoch 136, loss 1.7307909727096558, acc=0.32777777314186096, loss=1.7307909727096558
train: epoch 137, loss 1.7398933172225952, acc=0.31049999594688416, loss=1.7398933172225952
test: epoch 137, loss 1.7338799238204956, acc=0.32499998807907104, loss=1.7338799238204956
train: epoch 138, loss 1.7392648458480835, acc=0.30816665291786194, loss=1.7392648458480835
test: epoch 138, loss 1.7335693836212158, acc=0.32499998807907104, loss=1.7335693836212158
train: epoch 139, loss 1.7388625144958496, acc=0.30383333563804626, loss=1.7388625144958496
test: epoch 139, loss 1.7333883047103882, acc=0.32499998807907104, loss=1.7333883047103882
train: epoch 140, loss 1.7387609481811523, acc=0.30416667461395264, loss=1.7387609481811523
test: epoch 140, loss 1.7332693338394165, acc=0.32499998807907104, loss=1.7332693338394165
train: epoch 141, loss 1.7384213209152222, acc=0.30522221326828003, loss=1.7384213209152222
test: epoch 141, loss 1.7331794500350952, acc=0.32499998807907104, loss=1.7331794500350952
train: epoch 142, loss 1.7441272735595703, acc=0.31066668033599854, loss=1.7441272735595703
test: epoch 142, loss 1.741650104522705, acc=0.32499998807907104, loss=1.741650104522705
train: epoch 143, loss 1.8597668409347534, acc=0.29705554246902466, loss=1.8597668409347534
test: epoch 143, loss 2.0551345348358154, acc=0.28611111640930176, loss=2.0551345348358154
train: epoch 144, loss 1.8558881282806396, acc=0.29777777194976807, loss=1.8558881282806396
test: epoch 144, loss 1.80915367603302, acc=0.31388887763023376, loss=1.80915367603302
train: epoch 145, loss 1.6669085025787354, acc=0.3166666626930237, loss=1.6669085025787354
test: epoch 145, loss 1.6108390092849731, acc=0.3361110985279083, loss=1.6108390092849731
train: epoch 146, loss 1.6190394163131714, acc=0.3185555636882782, loss=1.6190394163131714
test: epoch 146, loss 1.6112372875213623, acc=0.3361110985279083, loss=1.6112372875213623
train: epoch 147, loss 1.6200730800628662, acc=0.3226666748523712, loss=1.6200730800628662
test: epoch 147, loss 1.558423399925232, acc=0.35277777910232544, loss=1.558423399925232
train: epoch 148, loss 1.5341405868530273, acc=0.3498888909816742, loss=1.5341405868530273
test: epoch 148, loss 1.4838206768035889, acc=0.3638888895511627, loss=1.4838206768035889
train: epoch 149, loss 1.4746509790420532, acc=0.38138890266418457, loss=1.4746509790420532
test: epoch 149, loss 1.3589837551116943, acc=0.4138889014720917, loss=1.3589837551116943
train: epoch 150, loss 1.3623360395431519, acc=0.39516666531562805, loss=1.3623360395431519
test: epoch 150, loss 1.3580023050308228, acc=0.4138889014720917, loss=1.3580023050308228
