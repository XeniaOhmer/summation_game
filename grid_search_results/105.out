# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.99", "--one_hot=1", "--n_layers=1"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=1072223271, receiver_embed_dim=64, save_run=0, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1072223271, receiver_embed_dim=64, save_run=False, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.5286173820495605, acc=0.04899999871850014, loss=3.5286173820495605
test: epoch 1, loss 3.363408088684082, acc=0.06666667014360428, loss=3.363408088684082
train: epoch 2, loss 3.436467170715332, acc=0.054722223430871964, loss=3.436467170715332
test: epoch 2, loss 3.1672186851501465, acc=0.07222222536802292, loss=3.1672186851501465
train: epoch 3, loss 3.0578453540802, acc=0.09905555844306946, loss=3.0578453540802
test: epoch 3, loss 6.872847557067871, acc=0.03888889029622078, loss=6.872847557067871
train: epoch 4, loss 2.5948355197906494, acc=0.16388888657093048, loss=2.5948355197906494
test: epoch 4, loss 7.788615703582764, acc=0.03055555559694767, loss=7.788615703582764
train: epoch 5, loss 2.36308217048645, acc=0.20055556297302246, loss=2.36308217048645
test: epoch 5, loss 7.872933864593506, acc=0.03888889029622078, loss=7.872933864593506
train: epoch 6, loss 2.2248375415802, acc=0.23311111330986023, loss=2.2248375415802
test: epoch 6, loss 8.189201354980469, acc=0.0555555559694767, loss=8.189201354980469
train: epoch 7, loss 2.1289196014404297, acc=0.25155556201934814, loss=2.1289196014404297
test: epoch 7, loss 7.824128150939941, acc=0.07222222536802292, loss=7.824128150939941
train: epoch 8, loss 2.0683653354644775, acc=0.2686111032962799, loss=2.0683653354644775
test: epoch 8, loss 7.701844692230225, acc=0.07777778059244156, loss=7.701844692230225
train: epoch 9, loss 2.0186355113983154, acc=0.27761110663414, loss=2.0186355113983154
test: epoch 9, loss 7.653959274291992, acc=0.0694444477558136, loss=7.653959274291992
train: epoch 10, loss 1.9783222675323486, acc=0.2978888750076294, loss=1.9783222675323486
test: epoch 10, loss 7.676215648651123, acc=0.06111111119389534, loss=7.676215648651123
train: epoch 11, loss 1.9287410974502563, acc=0.3065555691719055, loss=1.9287410974502563
test: epoch 11, loss 7.96293830871582, acc=0.08055555820465088, loss=7.96293830871582
train: epoch 12, loss 1.8981326818466187, acc=0.3157222270965576, loss=1.8981326818466187
test: epoch 12, loss 7.910820960998535, acc=0.07777778059244156, loss=7.910820960998535
train: epoch 13, loss 1.8743970394134521, acc=0.32766667008399963, loss=1.8743970394134521
test: epoch 13, loss 7.584662914276123, acc=0.07222222536802292, loss=7.584662914276123
train: epoch 14, loss 1.8444749116897583, acc=0.3306666612625122, loss=1.8444749116897583
test: epoch 14, loss 7.694531440734863, acc=0.0694444477558136, loss=7.694531440734863
train: epoch 15, loss 1.821305751800537, acc=0.3406111001968384, loss=1.821305751800537
test: epoch 15, loss 7.362399578094482, acc=0.06666667014360428, loss=7.362399578094482
train: epoch 16, loss 1.8037861585617065, acc=0.3452777862548828, loss=1.8037861585617065
test: epoch 16, loss 7.103012561798096, acc=0.0694444477558136, loss=7.103012561798096
train: epoch 17, loss 1.7680262327194214, acc=0.3503333330154419, loss=1.7680262327194214
test: epoch 17, loss 6.810875415802002, acc=0.08611111342906952, loss=6.810875415802002
train: epoch 18, loss 1.7604987621307373, acc=0.36666667461395264, loss=1.7604987621307373
test: epoch 18, loss 6.5635085105896, acc=0.08611111342906952, loss=6.5635085105896
train: epoch 19, loss 1.7310073375701904, acc=0.367333322763443, loss=1.7310073375701904
test: epoch 19, loss 6.055953025817871, acc=0.09166666865348816, loss=6.055953025817871
train: epoch 20, loss 1.7094011306762695, acc=0.3807222247123718, loss=1.7094011306762695
test: epoch 20, loss 5.695230484008789, acc=0.0972222238779068, loss=5.695230484008789
train: epoch 21, loss 1.7008845806121826, acc=0.38216665387153625, loss=1.7008845806121826
test: epoch 21, loss 5.406923770904541, acc=0.10833333432674408, loss=5.406923770904541
train: epoch 22, loss 1.672423005104065, acc=0.3926111161708832, loss=1.672423005104065
test: epoch 22, loss 5.1297430992126465, acc=0.11388888955116272, loss=5.1297430992126465
train: epoch 23, loss 1.6532646417617798, acc=0.4037777781486511, loss=1.6532646417617798
test: epoch 23, loss 4.839900016784668, acc=0.1111111119389534, loss=4.839900016784668
train: epoch 24, loss 1.64794921875, acc=0.3993888795375824, loss=1.64794921875
test: epoch 24, loss 4.5659661293029785, acc=0.10555555671453476, loss=4.5659661293029785
train: epoch 25, loss 1.6499778032302856, acc=0.41172221302986145, loss=1.6499778032302856
test: epoch 25, loss 4.454586982727051, acc=0.1111111119389534, loss=4.454586982727051
train: epoch 26, loss 1.6325621604919434, acc=0.4108888804912567, loss=1.6325621604919434
test: epoch 26, loss 4.267683506011963, acc=0.125, loss=4.267683506011963
train: epoch 27, loss 1.6045235395431519, acc=0.4248333275318146, loss=1.6045235395431519
test: epoch 27, loss 3.9981653690338135, acc=0.125, loss=3.9981653690338135
train: epoch 28, loss 1.5925788879394531, acc=0.4308333396911621, loss=1.5925788879394531
test: epoch 28, loss 3.8048534393310547, acc=0.12777778506278992, loss=3.8048534393310547
train: epoch 29, loss 1.5745296478271484, acc=0.4381110966205597, loss=1.5745296478271484
test: epoch 29, loss 3.694575309753418, acc=0.13611111044883728, loss=3.694575309753418
train: epoch 30, loss 1.574266791343689, acc=0.44127777218818665, loss=1.574266791343689
test: epoch 30, loss 3.5385243892669678, acc=0.1527777761220932, loss=3.5385243892669678
train: epoch 31, loss 1.561269760131836, acc=0.44511112570762634, loss=1.561269760131836
test: epoch 31, loss 3.401183843612671, acc=0.14722222089767456, loss=3.401183843612671
train: epoch 32, loss 1.5424416065216064, acc=0.4519444406032562, loss=1.5424416065216064
test: epoch 32, loss 3.2415521144866943, acc=0.15000000596046448, loss=3.2415521144866943
train: epoch 33, loss 1.5399876832962036, acc=0.45305556058883667, loss=1.5399876832962036
test: epoch 33, loss 3.2583439350128174, acc=0.14722222089767456, loss=3.2583439350128174
train: epoch 34, loss 1.5206176042556763, acc=0.4588888883590698, loss=1.5206176042556763
test: epoch 34, loss 3.050539255142212, acc=0.17222222685813904, loss=3.050539255142212
train: epoch 35, loss 1.5196292400360107, acc=0.47394445538520813, loss=1.5196292400360107
test: epoch 35, loss 3.007068395614624, acc=0.16111111640930176, loss=3.007068395614624
train: epoch 36, loss 1.5131964683532715, acc=0.4676666557788849, loss=1.5131964683532715
test: epoch 36, loss 2.9304966926574707, acc=0.18333333730697632, loss=2.9304966926574707
train: epoch 37, loss 1.5074377059936523, acc=0.4706111252307892, loss=1.5074377059936523
test: epoch 37, loss 2.851238965988159, acc=0.19166666269302368, loss=2.851238965988159
train: epoch 38, loss 1.4852122068405151, acc=0.4831666648387909, loss=1.4852122068405151
test: epoch 38, loss 2.792189359664917, acc=0.18888889253139496, loss=2.792189359664917
train: epoch 39, loss 1.4884570837020874, acc=0.4788333475589752, loss=1.4884570837020874
test: epoch 39, loss 2.6938424110412598, acc=0.19722221791744232, loss=2.6938424110412598
train: epoch 40, loss 1.4758586883544922, acc=0.4902222156524658, loss=1.4758586883544922
test: epoch 40, loss 2.5735747814178467, acc=0.23055554926395416, loss=2.5735747814178467
train: epoch 41, loss 1.449049472808838, acc=0.49816668033599854, loss=1.449049472808838
test: epoch 41, loss 2.6801111698150635, acc=0.20555555820465088, loss=2.6801111698150635
train: epoch 42, loss 1.459434151649475, acc=0.5018333196640015, loss=1.459434151649475
test: epoch 42, loss 2.605212450027466, acc=0.21944443881511688, loss=2.605212450027466
train: epoch 43, loss 1.4675960540771484, acc=0.5059444308280945, loss=1.4675960540771484
test: epoch 43, loss 2.606931209564209, acc=0.2083333283662796, loss=2.606931209564209
train: epoch 44, loss 1.4444799423217773, acc=0.5141111016273499, loss=1.4444799423217773
test: epoch 44, loss 2.6565239429473877, acc=0.22499999403953552, loss=2.6565239429473877
train: epoch 45, loss 1.4208141565322876, acc=0.5170555710792542, loss=1.4208141565322876
test: epoch 45, loss 2.5866105556488037, acc=0.21944443881511688, loss=2.5866105556488037
train: epoch 46, loss 1.4231607913970947, acc=0.5196666717529297, loss=1.4231607913970947
test: epoch 46, loss 2.5324387550354004, acc=0.23055554926395416, loss=2.5324387550354004
train: epoch 47, loss 1.3957889080047607, acc=0.528333306312561, loss=1.3957889080047607
test: epoch 47, loss 2.4472949504852295, acc=0.23888888955116272, loss=2.4472949504852295
train: epoch 48, loss 1.4026437997817993, acc=0.5320555567741394, loss=1.4026437997817993
test: epoch 48, loss 2.402611494064331, acc=0.24722221493721008, loss=2.402611494064331
train: epoch 49, loss 1.3830078840255737, acc=0.5410000085830688, loss=1.3830078840255737
test: epoch 49, loss 2.4052343368530273, acc=0.2361111044883728, loss=2.4052343368530273
train: epoch 50, loss 1.3839558362960815, acc=0.5422777533531189, loss=1.3839558362960815
test: epoch 50, loss 2.3980703353881836, acc=0.2361111044883728, loss=2.3980703353881836
train: epoch 51, loss 1.387682318687439, acc=0.5508888959884644, loss=1.387682318687439
test: epoch 51, loss 2.4139323234558105, acc=0.25, loss=2.4139323234558105
train: epoch 52, loss 1.3800050020217896, acc=0.5503888726234436, loss=1.3800050020217896
test: epoch 52, loss 2.3473994731903076, acc=0.24722221493721008, loss=2.3473994731903076
train: epoch 53, loss 1.3666462898254395, acc=0.5554444193840027, loss=1.3666462898254395
test: epoch 53, loss 2.360515832901001, acc=0.24444444477558136, loss=2.360515832901001
train: epoch 54, loss 1.3477356433868408, acc=0.5619444251060486, loss=1.3477356433868408
test: epoch 54, loss 2.2688443660736084, acc=0.2527777850627899, loss=2.2688443660736084
train: epoch 55, loss 1.3434796333312988, acc=0.5730000138282776, loss=1.3434796333312988
test: epoch 55, loss 2.2255873680114746, acc=0.27222222089767456, loss=2.2255873680114746
train: epoch 56, loss 1.313439130783081, acc=0.5724999904632568, loss=1.313439130783081
test: epoch 56, loss 2.1665573120117188, acc=0.2805555462837219, loss=2.1665573120117188
train: epoch 57, loss 1.3199225664138794, acc=0.5860000252723694, loss=1.3199225664138794
test: epoch 57, loss 2.1228065490722656, acc=0.28333333134651184, loss=2.1228065490722656
train: epoch 58, loss 1.3146092891693115, acc=0.5843889117240906, loss=1.3146092891693115
test: epoch 58, loss 2.119197130203247, acc=0.28333333134651184, loss=2.119197130203247
train: epoch 59, loss 1.2750024795532227, acc=0.5973888635635376, loss=1.2750024795532227
test: epoch 59, loss 2.0735831260681152, acc=0.2805555462837219, loss=2.0735831260681152
train: epoch 60, loss 1.2865350246429443, acc=0.6008333563804626, loss=1.2865350246429443
test: epoch 60, loss 2.0107758045196533, acc=0.29722222685813904, loss=2.0107758045196533
train: epoch 61, loss 1.255739450454712, acc=0.6050000190734863, loss=1.255739450454712
test: epoch 61, loss 2.0546815395355225, acc=0.2777777910232544, loss=2.0546815395355225
train: epoch 62, loss 1.2479426860809326, acc=0.6146666407585144, loss=1.2479426860809326
test: epoch 62, loss 2.0015251636505127, acc=0.31388887763023376, loss=2.0015251636505127
train: epoch 63, loss 1.2610679864883423, acc=0.6147222518920898, loss=1.2610679864883423
test: epoch 63, loss 2.0010931491851807, acc=0.3083333373069763, loss=2.0010931491851807
train: epoch 64, loss 1.227829098701477, acc=0.6203888654708862, loss=1.227829098701477
test: epoch 64, loss 1.9670735597610474, acc=0.31111112236976624, loss=1.9670735597610474
train: epoch 65, loss 1.226741075515747, acc=0.6282222270965576, loss=1.226741075515747
test: epoch 65, loss 1.9587211608886719, acc=0.3055555522441864, loss=1.9587211608886719
train: epoch 66, loss 1.2300200462341309, acc=0.6266111135482788, loss=1.2300200462341309
test: epoch 66, loss 1.9702391624450684, acc=0.31388887763023376, loss=1.9702391624450684
train: epoch 67, loss 1.2013585567474365, acc=0.6360555291175842, loss=1.2013585567474365
test: epoch 67, loss 1.8983808755874634, acc=0.3083333373069763, loss=1.8983808755874634
train: epoch 68, loss 1.1914860010147095, acc=0.6374444365501404, loss=1.1914860010147095
test: epoch 68, loss 1.8552707433700562, acc=0.32499998807907104, loss=1.8552707433700562
train: epoch 69, loss 1.1906404495239258, acc=0.6384444236755371, loss=1.1906404495239258
test: epoch 69, loss 1.829936146736145, acc=0.3166666626930237, loss=1.829936146736145
train: epoch 70, loss 1.1678907871246338, acc=0.647944450378418, loss=1.1678907871246338
test: epoch 70, loss 1.8045628070831299, acc=0.3222222328186035, loss=1.8045628070831299
train: epoch 71, loss 1.1814230680465698, acc=0.6458888649940491, loss=1.1814230680465698
test: epoch 71, loss 1.7537957429885864, acc=0.3222222328186035, loss=1.7537957429885864
train: epoch 72, loss 1.1640026569366455, acc=0.6549999713897705, loss=1.1640026569366455
test: epoch 72, loss 1.769902229309082, acc=0.3305555582046509, loss=1.769902229309082
train: epoch 73, loss 1.1595052480697632, acc=0.6587777733802795, loss=1.1595052480697632
test: epoch 73, loss 1.755660891532898, acc=0.3305555582046509, loss=1.755660891532898
train: epoch 74, loss 1.1483625173568726, acc=0.6618333458900452, loss=1.1483625173568726
test: epoch 74, loss 1.7320586442947388, acc=0.33888888359069824, loss=1.7320586442947388
train: epoch 75, loss 1.1360255479812622, acc=0.6628333330154419, loss=1.1360255479812622
test: epoch 75, loss 1.7712421417236328, acc=0.3305555582046509, loss=1.7712421417236328
train: epoch 76, loss 1.1399098634719849, acc=0.6650555729866028, loss=1.1399098634719849
test: epoch 76, loss 1.732202172279358, acc=0.3222222328186035, loss=1.732202172279358
train: epoch 77, loss 1.1597627401351929, acc=0.6683889031410217, loss=1.1597627401351929
test: epoch 77, loss 1.7130062580108643, acc=0.32777777314186096, loss=1.7130062580108643
train: epoch 78, loss 1.099881887435913, acc=0.6777777671813965, loss=1.099881887435913
test: epoch 78, loss 1.6802042722702026, acc=0.33888888359069824, loss=1.6802042722702026
train: epoch 79, loss 1.1026203632354736, acc=0.6743333339691162, loss=1.1026203632354736
test: epoch 79, loss 1.7045749425888062, acc=0.3333333432674408, loss=1.7045749425888062
train: epoch 80, loss 1.1033477783203125, acc=0.6834444403648376, loss=1.1033477783203125
test: epoch 80, loss 1.6512346267700195, acc=0.3499999940395355, loss=1.6512346267700195
train: epoch 81, loss 1.0898572206497192, acc=0.6818888783454895, loss=1.0898572206497192
test: epoch 81, loss 1.6697865724563599, acc=0.3499999940395355, loss=1.6697865724563599
train: epoch 82, loss 1.1021350622177124, acc=0.6786666512489319, loss=1.1021350622177124
test: epoch 82, loss 1.6458808183670044, acc=0.3361110985279083, loss=1.6458808183670044
train: epoch 83, loss 1.094748616218567, acc=0.6861110925674438, loss=1.094748616218567
test: epoch 83, loss 1.651731014251709, acc=0.33888888359069824, loss=1.651731014251709
train: epoch 84, loss 1.0807427167892456, acc=0.6903333067893982, loss=1.0807427167892456
test: epoch 84, loss 1.6367372274398804, acc=0.3361110985279083, loss=1.6367372274398804
train: epoch 85, loss 1.0727663040161133, acc=0.691777765750885, loss=1.0727663040161133
test: epoch 85, loss 1.6528645753860474, acc=0.3499999940395355, loss=1.6528645753860474
train: epoch 86, loss 1.046041488647461, acc=0.6918888688087463, loss=1.046041488647461
test: epoch 86, loss 1.6099871397018433, acc=0.3444444537162781, loss=1.6099871397018433
train: epoch 87, loss 1.0438390970230103, acc=0.698888897895813, loss=1.0438390970230103
test: epoch 87, loss 1.6076393127441406, acc=0.3472222089767456, loss=1.6076393127441406
train: epoch 88, loss 1.0611248016357422, acc=0.69605553150177, loss=1.0611248016357422
test: epoch 88, loss 1.5773546695709229, acc=0.3472222089767456, loss=1.5773546695709229
train: epoch 89, loss 1.0249576568603516, acc=0.703499972820282, loss=1.0249576568603516
test: epoch 89, loss 1.5613526105880737, acc=0.33888888359069824, loss=1.5613526105880737
train: epoch 90, loss 1.06590735912323, acc=0.6994444727897644, loss=1.06590735912323
test: epoch 90, loss 1.562084674835205, acc=0.33888888359069824, loss=1.562084674835205
train: epoch 91, loss 1.0526235103607178, acc=0.6986111402511597, loss=1.0526235103607178
test: epoch 91, loss 1.531166672706604, acc=0.3611111044883728, loss=1.531166672706604
train: epoch 92, loss 1.0296847820281982, acc=0.7061111330986023, loss=1.0296847820281982
test: epoch 92, loss 1.5284582376480103, acc=0.3611111044883728, loss=1.5284582376480103
train: epoch 93, loss 1.0203063488006592, acc=0.7070555686950684, loss=1.0203063488006592
test: epoch 93, loss 1.5232679843902588, acc=0.375, loss=1.5232679843902588
train: epoch 94, loss 1.022483468055725, acc=0.7039999961853027, loss=1.022483468055725
test: epoch 94, loss 1.5369495153427124, acc=0.3611111044883728, loss=1.5369495153427124
train: epoch 95, loss 1.0223842859268188, acc=0.706333339214325, loss=1.0223842859268188
test: epoch 95, loss 1.5051215887069702, acc=0.375, loss=1.5051215887069702
train: epoch 96, loss 1.0030182600021362, acc=0.7066666483879089, loss=1.0030182600021362
test: epoch 96, loss 1.5070021152496338, acc=0.3722222149372101, loss=1.5070021152496338
train: epoch 97, loss 1.0274736881256104, acc=0.7110555768013, loss=1.0274736881256104
test: epoch 97, loss 1.4786139726638794, acc=0.375, loss=1.4786139726638794
train: epoch 98, loss 1.0185184478759766, acc=0.7049999833106995, loss=1.0185184478759766
test: epoch 98, loss 1.4938595294952393, acc=0.36944442987442017, loss=1.4938595294952393
train: epoch 99, loss 1.0111116170883179, acc=0.7083333134651184, loss=1.0111116170883179
test: epoch 99, loss 1.4486874341964722, acc=0.3888888955116272, loss=1.4486874341964722
train: epoch 100, loss 1.0022315979003906, acc=0.7095555663108826, loss=1.0022315979003906
test: epoch 100, loss 1.4538172483444214, acc=0.3916666805744171, loss=1.4538172483444214
train: epoch 101, loss 0.9701217412948608, acc=0.7143333554267883, loss=0.9701217412948608
test: epoch 101, loss 1.4452992677688599, acc=0.39444443583488464, loss=1.4452992677688599
train: epoch 102, loss 0.9734110236167908, acc=0.7192777991294861, loss=0.9734110236167908
test: epoch 102, loss 1.4145441055297852, acc=0.4000000059604645, loss=1.4145441055297852
train: epoch 103, loss 0.9520918726921082, acc=0.7230555415153503, loss=0.9520918726921082
test: epoch 103, loss 1.4006081819534302, acc=0.4027777910232544, loss=1.4006081819534302
train: epoch 104, loss 0.9387643933296204, acc=0.7285000085830688, loss=0.9387643933296204
test: epoch 104, loss 1.3896887302398682, acc=0.38333332538604736, loss=1.3896887302398682
train: epoch 105, loss 0.9395906925201416, acc=0.7323889136314392, loss=0.9395906925201416
test: epoch 105, loss 1.4017436504364014, acc=0.4027777910232544, loss=1.4017436504364014
train: epoch 106, loss 0.9367499351501465, acc=0.7288333177566528, loss=0.9367499351501465
test: epoch 106, loss 1.3532353639602661, acc=0.4194444417953491, loss=1.3532353639602661
train: epoch 107, loss 0.9335611462593079, acc=0.7373889088630676, loss=0.9335611462593079
test: epoch 107, loss 1.3802958726882935, acc=0.4166666567325592, loss=1.3802958726882935
train: epoch 108, loss 0.9458116292953491, acc=0.7327777743339539, loss=0.9458116292953491
test: epoch 108, loss 1.3497735261917114, acc=0.4166666567325592, loss=1.3497735261917114
train: epoch 109, loss 0.9257798790931702, acc=0.7412777543067932, loss=0.9257798790931702
test: epoch 109, loss 1.3493505716323853, acc=0.42222222685813904, loss=1.3493505716323853
train: epoch 110, loss 0.906950056552887, acc=0.7449444532394409, loss=0.906950056552887
test: epoch 110, loss 1.3233556747436523, acc=0.4305555522441864, loss=1.3233556747436523
train: epoch 111, loss 0.8870453834533691, acc=0.7458333373069763, loss=0.8870453834533691
test: epoch 111, loss 1.32439386844635, acc=0.4166666567325592, loss=1.32439386844635
train: epoch 112, loss 0.8759596943855286, acc=0.7513333559036255, loss=0.8759596943855286
test: epoch 112, loss 1.3320916891098022, acc=0.4305555522441864, loss=1.3320916891098022
train: epoch 113, loss 0.8730525970458984, acc=0.7509444355964661, loss=0.8730525970458984
test: epoch 113, loss 1.3165473937988281, acc=0.40833333134651184, loss=1.3165473937988281
train: epoch 114, loss 0.8662627935409546, acc=0.7559444308280945, loss=0.8662627935409546
test: epoch 114, loss 1.288613200187683, acc=0.4333333373069763, loss=1.288613200187683
train: epoch 115, loss 0.8419984579086304, acc=0.7587222456932068, loss=0.8419984579086304
test: epoch 115, loss 1.301289439201355, acc=0.4277777671813965, loss=1.301289439201355
train: epoch 116, loss 0.8286479711532593, acc=0.765333354473114, loss=0.8286479711532593
test: epoch 116, loss 1.297739863395691, acc=0.4305555522441864, loss=1.297739863395691
train: epoch 117, loss 0.8558040261268616, acc=0.7647777795791626, loss=0.8558040261268616
test: epoch 117, loss 1.2887681722640991, acc=0.4305555522441864, loss=1.2887681722640991
train: epoch 118, loss 0.8301404118537903, acc=0.7710555791854858, loss=0.8301404118537903
test: epoch 118, loss 1.254472255706787, acc=0.4472222328186035, loss=1.254472255706787
train: epoch 119, loss 0.8313789367675781, acc=0.7683333158493042, loss=0.8313789367675781
test: epoch 119, loss 1.282189965248108, acc=0.4416666626930237, loss=1.282189965248108
train: epoch 120, loss 0.807965099811554, acc=0.7737777829170227, loss=0.807965099811554
test: epoch 120, loss 1.2570189237594604, acc=0.43888887763023376, loss=1.2570189237594604
train: epoch 121, loss 0.807189404964447, acc=0.7761111259460449, loss=0.807189404964447
test: epoch 121, loss 1.2459170818328857, acc=0.4555555582046509, loss=1.2459170818328857
train: epoch 122, loss 0.7889564633369446, acc=0.7807777523994446, loss=0.7889564633369446
test: epoch 122, loss 1.2603659629821777, acc=0.4555555582046509, loss=1.2603659629821777
train: epoch 123, loss 0.7934808731079102, acc=0.7796111106872559, loss=0.7934808731079102
test: epoch 123, loss 1.2674623727798462, acc=0.4444444477558136, loss=1.2674623727798462
train: epoch 124, loss 0.7988716959953308, acc=0.780055582523346, loss=0.7988716959953308
test: epoch 124, loss 1.2463548183441162, acc=0.4472222328186035, loss=1.2463548183441162
train: epoch 125, loss 0.7676355838775635, acc=0.7838888764381409, loss=0.7676355838775635
test: epoch 125, loss 1.2407567501068115, acc=0.4472222328186035, loss=1.2407567501068115
train: epoch 126, loss 0.7653733491897583, acc=0.7867777943611145, loss=0.7653733491897583
test: epoch 126, loss 1.2313449382781982, acc=0.44999998807907104, loss=1.2313449382781982
train: epoch 127, loss 0.7390840649604797, acc=0.7911666631698608, loss=0.7390840649604797
test: epoch 127, loss 1.2633512020111084, acc=0.45277777314186096, loss=1.2633512020111084
train: epoch 128, loss 0.7671265602111816, acc=0.7915555834770203, loss=0.7671265602111816
test: epoch 128, loss 1.2210646867752075, acc=0.46388888359069824, loss=1.2210646867752075
train: epoch 129, loss 0.7367936372756958, acc=0.7963888645172119, loss=0.7367936372756958
test: epoch 129, loss 1.2136714458465576, acc=0.45277777314186096, loss=1.2136714458465576
train: epoch 130, loss 0.7443183660507202, acc=0.7900555729866028, loss=0.7443183660507202
test: epoch 130, loss 1.1805169582366943, acc=0.46666666865348816, loss=1.1805169582366943
train: epoch 131, loss 0.747473955154419, acc=0.7965555787086487, loss=0.747473955154419
test: epoch 131, loss 1.2058497667312622, acc=0.4583333432674408, loss=1.2058497667312622
train: epoch 132, loss 0.7124910354614258, acc=0.7992222309112549, loss=0.7124910354614258
test: epoch 132, loss 1.1974740028381348, acc=0.4722222089767456, loss=1.1974740028381348
train: epoch 133, loss 0.7208765745162964, acc=0.7978888750076294, loss=0.7208765745162964
test: epoch 133, loss 1.1787554025650024, acc=0.46388888359069824, loss=1.1787554025650024
train: epoch 134, loss 0.721362292766571, acc=0.8037777543067932, loss=0.721362292766571
test: epoch 134, loss 1.1997239589691162, acc=0.46666666865348816, loss=1.1997239589691162
train: epoch 135, loss 0.6995505094528198, acc=0.8073889017105103, loss=0.6995505094528198
test: epoch 135, loss 1.1624677181243896, acc=0.4722222089767456, loss=1.1624677181243896
train: epoch 136, loss 0.7055251002311707, acc=0.8038333058357239, loss=0.7055251002311707
test: epoch 136, loss 1.1884820461273193, acc=0.47777777910232544, loss=1.1884820461273193
train: epoch 137, loss 0.7131953835487366, acc=0.8066111207008362, loss=0.7131953835487366
test: epoch 137, loss 1.175137996673584, acc=0.4749999940395355, loss=1.175137996673584
train: epoch 138, loss 0.7046350836753845, acc=0.808055579662323, loss=0.7046350836753845
test: epoch 138, loss 1.181803584098816, acc=0.47777777910232544, loss=1.181803584098816
train: epoch 139, loss 0.6662057638168335, acc=0.816444456577301, loss=0.6662057638168335
test: epoch 139, loss 1.1651960611343384, acc=0.4749999940395355, loss=1.1651960611343384
train: epoch 140, loss 0.6660772562026978, acc=0.8178333044052124, loss=0.6660772562026978
test: epoch 140, loss 1.1605806350708008, acc=0.4722222089767456, loss=1.1605806350708008
train: epoch 141, loss 0.6918603777885437, acc=0.8163333535194397, loss=0.6918603777885437
test: epoch 141, loss 1.1620920896530151, acc=0.49444442987442017, loss=1.1620920896530151
train: epoch 142, loss 0.6721747517585754, acc=0.8177222013473511, loss=0.6721747517585754
test: epoch 142, loss 1.1536098718643188, acc=0.46388888359069824, loss=1.1536098718643188
train: epoch 143, loss 0.6668563485145569, acc=0.8180000185966492, loss=0.6668563485145569
test: epoch 143, loss 1.1497584581375122, acc=0.4749999940395355, loss=1.1497584581375122
train: epoch 144, loss 0.6530940532684326, acc=0.8215000033378601, loss=0.6530940532684326
test: epoch 144, loss 1.1357508897781372, acc=0.49444442987442017, loss=1.1357508897781372
train: epoch 145, loss 0.6462457776069641, acc=0.8230000138282776, loss=0.6462457776069641
test: epoch 145, loss 1.1330333948135376, acc=0.4972222149372101, loss=1.1330333948135376
train: epoch 146, loss 0.646821141242981, acc=0.8232777714729309, loss=0.646821141242981
test: epoch 146, loss 1.1211735010147095, acc=0.4972222149372101, loss=1.1211735010147095
train: epoch 147, loss 0.6378259658813477, acc=0.8265555500984192, loss=0.6378259658813477
test: epoch 147, loss 1.1475403308868408, acc=0.5, loss=1.1475403308868408
train: epoch 148, loss 0.6157110333442688, acc=0.8268333077430725, loss=0.6157110333442688
test: epoch 148, loss 1.1173244714736938, acc=0.4972222149372101, loss=1.1173244714736938
train: epoch 149, loss 0.6260428428649902, acc=0.8288888931274414, loss=0.6260428428649902
test: epoch 149, loss 1.1422022581100464, acc=0.48055556416511536, loss=1.1422022581100464
train: epoch 150, loss 0.6086883544921875, acc=0.8343889117240906, loss=0.6086883544921875
test: epoch 150, loss 1.1155098676681519, acc=0.4861111044883728, loss=1.1155098676681519
