# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=1", "--one_hot=1", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=1068851855, receiver_embed_dim=64, save_run=0, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1068851855, receiver_embed_dim=64, save_run=False, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.8272347450256348, acc=0.11055555194616318, loss=2.8272347450256348
test: epoch 1, loss 4.418658256530762, acc=0.11666666716337204, loss=4.418658256530762
train: epoch 2, loss 1.6556684970855713, acc=0.3573888838291168, loss=1.6556684970855713
test: epoch 2, loss 5.751790523529053, acc=0.13333334028720856, loss=5.751790523529053
train: epoch 3, loss 0.9696714878082275, acc=0.6119999885559082, loss=0.9696714878082275
test: epoch 3, loss 4.851646900177002, acc=0.1944444477558136, loss=4.851646900177002
train: epoch 4, loss 0.6889177560806274, acc=0.7255555391311646, loss=0.6889177560806274
test: epoch 4, loss 4.049627780914307, acc=0.16388888657093048, loss=4.049627780914307
train: epoch 5, loss 0.5418343544006348, acc=0.7948333621025085, loss=0.5418343544006348
test: epoch 5, loss 3.2839603424072266, acc=0.22499999403953552, loss=3.2839603424072266
train: epoch 6, loss 0.42298272252082825, acc=0.8456666469573975, loss=0.42298272252082825
test: epoch 6, loss 3.044102668762207, acc=0.28611111640930176, loss=3.044102668762207
train: epoch 7, loss 0.36787131428718567, acc=0.8711666464805603, loss=0.36787131428718567
test: epoch 7, loss 2.6455116271972656, acc=0.3222222328186035, loss=2.6455116271972656
train: epoch 8, loss 0.3097863495349884, acc=0.8913333415985107, loss=0.3097863495349884
test: epoch 8, loss 2.820145845413208, acc=0.3333333432674408, loss=2.820145845413208
train: epoch 9, loss 0.28655242919921875, acc=0.8963333368301392, loss=0.28655242919921875
test: epoch 9, loss 2.6619629859924316, acc=0.3861111104488373, loss=2.6619629859924316
train: epoch 10, loss 0.27962929010391235, acc=0.901888906955719, loss=0.27962929010391235
test: epoch 10, loss 2.4345953464508057, acc=0.36666667461395264, loss=2.4345953464508057
train: epoch 11, loss 0.2537781000137329, acc=0.9156666398048401, loss=0.2537781000137329
test: epoch 11, loss 2.41674542427063, acc=0.2944444417953491, loss=2.41674542427063
train: epoch 12, loss 0.22697560489177704, acc=0.9244444370269775, loss=0.22697560489177704
test: epoch 12, loss 2.0165212154388428, acc=0.39722222089767456, loss=2.0165212154388428
train: epoch 13, loss 0.22678188979625702, acc=0.9214444160461426, loss=0.22678188979625702
test: epoch 13, loss 2.1538379192352295, acc=0.3916666805744171, loss=2.1538379192352295
train: epoch 14, loss 0.20496736466884613, acc=0.9266111254692078, loss=0.20496736466884613
test: epoch 14, loss 3.064002275466919, acc=0.3916666805744171, loss=3.064002275466919
train: epoch 15, loss 0.17871400713920593, acc=0.9372222423553467, loss=0.17871400713920593
test: epoch 15, loss 2.184948444366455, acc=0.45277777314186096, loss=2.184948444366455
train: epoch 16, loss 0.19588766992092133, acc=0.934333324432373, loss=0.19588766992092133
test: epoch 16, loss 2.461489200592041, acc=0.3499999940395355, loss=2.461489200592041
train: epoch 17, loss 0.17073117196559906, acc=0.9427222013473511, loss=0.17073117196559906
test: epoch 17, loss 2.064883232116699, acc=0.4583333432674408, loss=2.064883232116699
train: epoch 18, loss 0.1713085025548935, acc=0.9432777762413025, loss=0.1713085025548935
test: epoch 18, loss 2.079228401184082, acc=0.4055555462837219, loss=2.079228401184082
train: epoch 19, loss 0.15913273394107819, acc=0.9461110830307007, loss=0.15913273394107819
test: epoch 19, loss 2.324291467666626, acc=0.39444443583488464, loss=2.324291467666626
train: epoch 20, loss 0.15698829293251038, acc=0.9489444494247437, loss=0.15698829293251038
test: epoch 20, loss 2.3693485260009766, acc=0.42222222685813904, loss=2.3693485260009766
train: epoch 21, loss 0.15179724991321564, acc=0.9520555734634399, loss=0.15179724991321564
test: epoch 21, loss 2.0818305015563965, acc=0.39722222089767456, loss=2.0818305015563965
train: epoch 22, loss 0.13068997859954834, acc=0.9563888907432556, loss=0.13068997859954834
test: epoch 22, loss 2.9566469192504883, acc=0.3166666626930237, loss=2.9566469192504883
train: epoch 23, loss 0.12471779435873032, acc=0.9578333497047424, loss=0.12471779435873032
test: epoch 23, loss 1.8783555030822754, acc=0.5305555462837219, loss=1.8783555030822754
train: epoch 24, loss 0.13221587240695953, acc=0.9538888931274414, loss=0.13221587240695953
test: epoch 24, loss 2.1246166229248047, acc=0.36666667461395264, loss=2.1246166229248047
train: epoch 25, loss 0.13564857840538025, acc=0.9557222127914429, loss=0.13564857840538025
test: epoch 25, loss 2.2809839248657227, acc=0.42500001192092896, loss=2.2809839248657227
train: epoch 26, loss 0.11364512145519257, acc=0.9645000100135803, loss=0.11364512145519257
test: epoch 26, loss 2.664754867553711, acc=0.38055557012557983, loss=2.664754867553711
train: epoch 27, loss 0.12855884432792664, acc=0.9578333497047424, loss=0.12855884432792664
test: epoch 27, loss 2.1108314990997314, acc=0.519444465637207, loss=2.1108314990997314
train: epoch 28, loss 0.1150280013680458, acc=0.9632222056388855, loss=0.1150280013680458
test: epoch 28, loss 2.072183847427368, acc=0.4749999940395355, loss=2.072183847427368
train: epoch 29, loss 0.11880462616682053, acc=0.9601666927337646, loss=0.11880462616682053
test: epoch 29, loss 2.159984827041626, acc=0.41111111640930176, loss=2.159984827041626
train: epoch 30, loss 0.09327791631221771, acc=0.9696666598320007, loss=0.09327791631221771
test: epoch 30, loss 1.6728229522705078, acc=0.4722222089767456, loss=1.6728229522705078
train: epoch 31, loss 0.11700084805488586, acc=0.9631666541099548, loss=0.11700084805488586
test: epoch 31, loss 1.6892534494400024, acc=0.36666667461395264, loss=1.6892534494400024
train: epoch 32, loss 0.10734321922063828, acc=0.9642778038978577, loss=0.10734321922063828
test: epoch 32, loss 2.654688596725464, acc=0.3888888955116272, loss=2.654688596725464
train: epoch 33, loss 0.09312132000923157, acc=0.9705555438995361, loss=0.09312132000923157
test: epoch 33, loss 2.1176280975341797, acc=0.46388888359069824, loss=2.1176280975341797
train: epoch 34, loss 0.09687923640012741, acc=0.9695555567741394, loss=0.09687923640012741
test: epoch 34, loss 2.041081428527832, acc=0.5361111164093018, loss=2.041081428527832
train: epoch 35, loss 0.08999662101268768, acc=0.9697777628898621, loss=0.08999662101268768
test: epoch 35, loss 2.2847037315368652, acc=0.519444465637207, loss=2.2847037315368652
train: epoch 36, loss 0.08913718909025192, acc=0.9697777628898621, loss=0.08913718909025192
test: epoch 36, loss 2.3325603008270264, acc=0.4444444477558136, loss=2.3325603008270264
train: epoch 37, loss 0.08623892068862915, acc=0.9716110825538635, loss=0.08623892068862915
test: epoch 37, loss 1.4264684915542603, acc=0.4611110985279083, loss=1.4264684915542603
train: epoch 38, loss 0.08164483308792114, acc=0.9734444618225098, loss=0.08164483308792114
test: epoch 38, loss 1.8393484354019165, acc=0.43888887763023376, loss=1.8393484354019165
train: epoch 39, loss 0.08412624895572662, acc=0.9732778072357178, loss=0.08412624895572662
test: epoch 39, loss 1.7793843746185303, acc=0.4611110985279083, loss=1.7793843746185303
train: epoch 40, loss 0.08107578009366989, acc=0.9733889102935791, loss=0.08107578009366989
test: epoch 40, loss 2.038339376449585, acc=0.48055556416511536, loss=2.038339376449585
train: epoch 41, loss 0.08886021375656128, acc=0.9696111083030701, loss=0.08886021375656128
test: epoch 41, loss 2.127417802810669, acc=0.5055555701255798, loss=2.127417802810669
train: epoch 42, loss 0.07412414997816086, acc=0.9750555753707886, loss=0.07412414997816086
test: epoch 42, loss 1.6856852769851685, acc=0.5111111402511597, loss=1.6856852769851685
train: epoch 43, loss 0.09396960586309433, acc=0.9696666598320007, loss=0.09396960586309433
test: epoch 43, loss 1.9461407661437988, acc=0.41111111640930176, loss=1.9461407661437988
train: epoch 44, loss 0.06947213411331177, acc=0.9768333435058594, loss=0.06947213411331177
test: epoch 44, loss 1.8552148342132568, acc=0.48055556416511536, loss=1.8552148342132568
train: epoch 45, loss 0.06963074207305908, acc=0.9783889055252075, loss=0.06963074207305908
test: epoch 45, loss 1.9515131711959839, acc=0.4749999940395355, loss=1.9515131711959839
train: epoch 46, loss 0.08780507743358612, acc=0.971666693687439, loss=0.08780507743358612
test: epoch 46, loss 1.9807075262069702, acc=0.4472222328186035, loss=1.9807075262069702
train: epoch 47, loss 0.06928881257772446, acc=0.9763333201408386, loss=0.06928881257772446
test: epoch 47, loss 1.8387879133224487, acc=0.5666666626930237, loss=1.8387879133224487
train: epoch 48, loss 0.07583978027105331, acc=0.9747777581214905, loss=0.07583978027105331
test: epoch 48, loss 1.8069831132888794, acc=0.3722222149372101, loss=1.8069831132888794
train: epoch 49, loss 0.07318586111068726, acc=0.9763888716697693, loss=0.07318586111068726
test: epoch 49, loss 2.014075517654419, acc=0.5277777910232544, loss=2.014075517654419
train: epoch 50, loss 0.06614017486572266, acc=0.9788888692855835, loss=0.06614017486572266
test: epoch 50, loss 1.8502107858657837, acc=0.4749999940395355, loss=1.8502107858657837
train: epoch 51, loss 0.06341567635536194, acc=0.9785000085830688, loss=0.06341567635536194
test: epoch 51, loss 1.8557119369506836, acc=0.5805555582046509, loss=1.8557119369506836
train: epoch 52, loss 0.0584532730281353, acc=0.9808333516120911, loss=0.0584532730281353
test: epoch 52, loss 1.8853055238723755, acc=0.5166666507720947, loss=1.8853055238723755
train: epoch 53, loss 0.06645675003528595, acc=0.9788333177566528, loss=0.06645675003528595
test: epoch 53, loss 1.895452618598938, acc=0.5055555701255798, loss=1.895452618598938
train: epoch 54, loss 0.07188960909843445, acc=0.9769999980926514, loss=0.07188960909843445
test: epoch 54, loss 1.8813844919204712, acc=0.49166667461395264, loss=1.8813844919204712
train: epoch 55, loss 0.05981732904911041, acc=0.9804999828338623, loss=0.05981732904911041
test: epoch 55, loss 2.5216972827911377, acc=0.4277777671813965, loss=2.5216972827911377
train: epoch 56, loss 0.06114281713962555, acc=0.9798333048820496, loss=0.06114281713962555
test: epoch 56, loss 1.9732881784439087, acc=0.46666666865348816, loss=1.9732881784439087
train: epoch 57, loss 0.050329893827438354, acc=0.9827777743339539, loss=0.050329893827438354
test: epoch 57, loss 1.629070520401001, acc=0.5, loss=1.629070520401001
train: epoch 58, loss 0.06167621538043022, acc=0.980055570602417, loss=0.06167621538043022
test: epoch 58, loss 1.6093716621398926, acc=0.5777778029441833, loss=1.6093716621398926
train: epoch 59, loss 0.060692742466926575, acc=0.9795555472373962, loss=0.060692742466926575
test: epoch 59, loss 2.503599166870117, acc=0.4444444477558136, loss=2.503599166870117
train: epoch 60, loss 0.05228768289089203, acc=0.9828888773918152, loss=0.05228768289089203
test: epoch 60, loss 1.6600240468978882, acc=0.4888888895511627, loss=1.6600240468978882
train: epoch 61, loss 0.05157042667269707, acc=0.9831110835075378, loss=0.05157042667269707
test: epoch 61, loss 2.1407370567321777, acc=0.4749999940395355, loss=2.1407370567321777
train: epoch 62, loss 0.04831135272979736, acc=0.9834444522857666, loss=0.04831135272979736
test: epoch 62, loss 1.9803348779678345, acc=0.5361111164093018, loss=1.9803348779678345
train: epoch 63, loss 0.05024510249495506, acc=0.984000027179718, loss=0.05024510249495506
test: epoch 63, loss 2.084628105163574, acc=0.4611110985279083, loss=2.084628105163574
train: epoch 64, loss 0.056843992322683334, acc=0.9818333387374878, loss=0.056843992322683334
test: epoch 64, loss 1.5421772003173828, acc=0.5416666865348816, loss=1.5421772003173828
train: epoch 65, loss 0.05625755712389946, acc=0.9816666841506958, loss=0.05625755712389946
test: epoch 65, loss 1.8272531032562256, acc=0.5361111164093018, loss=1.8272531032562256
train: epoch 66, loss 0.049993496388196945, acc=0.984000027179718, loss=0.049993496388196945
test: epoch 66, loss 1.719473123550415, acc=0.46388888359069824, loss=1.719473123550415
train: epoch 67, loss 0.04215202108025551, acc=0.9852222204208374, loss=0.04215202108025551
test: epoch 67, loss 1.3375155925750732, acc=0.5388888716697693, loss=1.3375155925750732
train: epoch 68, loss 0.04782748594880104, acc=0.9843888878822327, loss=0.04782748594880104
test: epoch 68, loss 1.7227054834365845, acc=0.550000011920929, loss=1.7227054834365845
train: epoch 69, loss 0.05235075578093529, acc=0.9821666479110718, loss=0.05235075578093529
test: epoch 69, loss 1.7250810861587524, acc=0.5111111402511597, loss=1.7250810861587524
train: epoch 70, loss 0.05154911428689957, acc=0.984000027179718, loss=0.05154911428689957
test: epoch 70, loss 1.7944515943527222, acc=0.5444444417953491, loss=1.7944515943527222
train: epoch 71, loss 0.04946553707122803, acc=0.9851111173629761, loss=0.04946553707122803
test: epoch 71, loss 1.2317298650741577, acc=0.6277777552604675, loss=1.2317298650741577
train: epoch 72, loss 0.044936396181583405, acc=0.9850555658340454, loss=0.044936396181583405
test: epoch 72, loss 1.6959648132324219, acc=0.5388888716697693, loss=1.6959648132324219
train: epoch 73, loss 0.05507858470082283, acc=0.9815555810928345, loss=0.05507858470082283
test: epoch 73, loss 2.3898978233337402, acc=0.5111111402511597, loss=2.3898978233337402
train: epoch 74, loss 0.04219543933868408, acc=0.9860555529594421, loss=0.04219543933868408
test: epoch 74, loss 1.9345276355743408, acc=0.42222222685813904, loss=1.9345276355743408
train: epoch 75, loss 0.048807527869939804, acc=0.9839444160461426, loss=0.048807527869939804
test: epoch 75, loss 1.8649652004241943, acc=0.49166667461395264, loss=1.8649652004241943
train: epoch 76, loss 0.043655432760715485, acc=0.9849444627761841, loss=0.043655432760715485
test: epoch 76, loss 1.6881229877471924, acc=0.5444444417953491, loss=1.6881229877471924
train: epoch 77, loss 0.03867170959711075, acc=0.987500011920929, loss=0.03867170959711075
test: epoch 77, loss 1.387075424194336, acc=0.6000000238418579, loss=1.387075424194336
train: epoch 78, loss 0.04500411078333855, acc=0.9860000014305115, loss=0.04500411078333855
test: epoch 78, loss 1.5315287113189697, acc=0.5555555820465088, loss=1.5315287113189697
train: epoch 79, loss 0.04057706147432327, acc=0.9865555763244629, loss=0.04057706147432327
test: epoch 79, loss 1.5267289876937866, acc=0.5888888835906982, loss=1.5267289876937866
train: epoch 80, loss 0.03947720304131508, acc=0.9862777590751648, loss=0.03947720304131508
test: epoch 80, loss 1.483310341835022, acc=0.6194444298744202, loss=1.483310341835022
train: epoch 81, loss 0.041249774396419525, acc=0.9855555295944214, loss=0.041249774396419525
test: epoch 81, loss 2.234152317047119, acc=0.5083333253860474, loss=2.234152317047119
train: epoch 82, loss 0.03778110072016716, acc=0.9871110916137695, loss=0.03778110072016716
test: epoch 82, loss 1.6315046548843384, acc=0.49166667461395264, loss=1.6315046548843384
train: epoch 83, loss 0.03972717002034187, acc=0.9872778058052063, loss=0.03972717002034187
test: epoch 83, loss 1.717499852180481, acc=0.5361111164093018, loss=1.717499852180481
train: epoch 84, loss 0.0358746238052845, acc=0.9890000224113464, loss=0.0358746238052845
test: epoch 84, loss 2.0775885581970215, acc=0.4833333194255829, loss=2.0775885581970215
train: epoch 85, loss 0.035173553973436356, acc=0.9891666769981384, loss=0.035173553973436356
test: epoch 85, loss 1.473654866218567, acc=0.6138888597488403, loss=1.473654866218567
train: epoch 86, loss 0.04111725464463234, acc=0.9869444370269775, loss=0.04111725464463234
test: epoch 86, loss 1.5378059148788452, acc=0.675000011920929, loss=1.5378059148788452
train: epoch 87, loss 0.03902557119727135, acc=0.9875555634498596, loss=0.03902557119727135
test: epoch 87, loss 1.5617482662200928, acc=0.6527777910232544, loss=1.5617482662200928
train: epoch 88, loss 0.0423310250043869, acc=0.9871110916137695, loss=0.0423310250043869
test: epoch 88, loss 2.5902321338653564, acc=0.46388888359069824, loss=2.5902321338653564
train: epoch 89, loss 0.03207677602767944, acc=0.9893333315849304, loss=0.03207677602767944
test: epoch 89, loss 1.331735372543335, acc=0.5916666388511658, loss=1.331735372543335
train: epoch 90, loss 0.02916603721678257, acc=0.9911110997200012, loss=0.02916603721678257
test: epoch 90, loss 1.5093638896942139, acc=0.644444465637207, loss=1.5093638896942139
train: epoch 91, loss 0.032346535474061966, acc=0.9902222156524658, loss=0.032346535474061966
test: epoch 91, loss 1.8331772089004517, acc=0.5416666865348816, loss=1.8331772089004517
train: epoch 92, loss 0.032676272094249725, acc=0.9894999861717224, loss=0.032676272094249725
test: epoch 92, loss 1.8863475322723389, acc=0.5, loss=1.8863475322723389
train: epoch 93, loss 0.03514954075217247, acc=0.9894444346427917, loss=0.03514954075217247
test: epoch 93, loss 1.8984073400497437, acc=0.5416666865348816, loss=1.8984073400497437
train: epoch 94, loss 0.033640459179878235, acc=0.9890555739402771, loss=0.033640459179878235
test: epoch 94, loss 1.6448801755905151, acc=0.6638888716697693, loss=1.6448801755905151
train: epoch 95, loss 0.03286007046699524, acc=0.988777756690979, loss=0.03286007046699524
test: epoch 95, loss 1.6230026483535767, acc=0.6333333253860474, loss=1.6230026483535767
train: epoch 96, loss 0.030168144032359123, acc=0.9911666512489319, loss=0.030168144032359123
test: epoch 96, loss 1.7162318229675293, acc=0.6555555462837219, loss=1.7162318229675293
train: epoch 97, loss 0.03301987797021866, acc=0.9895555377006531, loss=0.03301987797021866
test: epoch 97, loss 1.8540846109390259, acc=0.605555534362793, loss=1.8540846109390259
train: epoch 98, loss 0.03182675689458847, acc=0.9898889064788818, loss=0.03182675689458847
test: epoch 98, loss 1.4541690349578857, acc=0.6222222447395325, loss=1.4541690349578857
train: epoch 99, loss 0.027308272197842598, acc=0.992555558681488, loss=0.027308272197842598
test: epoch 99, loss 1.7484999895095825, acc=0.6583333611488342, loss=1.7484999895095825
train: epoch 100, loss 0.032252389937639236, acc=0.9896110892295837, loss=0.032252389937639236
test: epoch 100, loss 1.4685328006744385, acc=0.699999988079071, loss=1.4685328006744385
train: epoch 101, loss 0.026932470500469208, acc=0.9915555715560913, loss=0.026932470500469208
test: epoch 101, loss 1.2216321229934692, acc=0.6638888716697693, loss=1.2216321229934692
train: epoch 102, loss 0.03306560590863228, acc=0.9895555377006531, loss=0.03306560590863228
test: epoch 102, loss 1.4642870426177979, acc=0.6194444298744202, loss=1.4642870426177979
train: epoch 103, loss 0.03169209882616997, acc=0.9896666407585144, loss=0.03169209882616997
test: epoch 103, loss 1.340353012084961, acc=0.6611111164093018, loss=1.340353012084961
train: epoch 104, loss 0.03328334912657738, acc=0.9903888702392578, loss=0.03328334912657738
test: epoch 104, loss 1.0963292121887207, acc=0.7166666388511658, loss=1.0963292121887207
train: epoch 105, loss 0.02331189438700676, acc=0.9924444556236267, loss=0.02331189438700676
test: epoch 105, loss 0.9851382970809937, acc=0.6722221970558167, loss=0.9851382970809937
train: epoch 106, loss 0.022409847006201744, acc=0.9926666617393494, loss=0.022409847006201744
test: epoch 106, loss 1.4821330308914185, acc=0.6111111044883728, loss=1.4821330308914185
train: epoch 107, loss 0.02696690522134304, acc=0.992388904094696, loss=0.02696690522134304
test: epoch 107, loss 1.475949764251709, acc=0.7111111283302307, loss=1.475949764251709
train: epoch 108, loss 0.03226644918322563, acc=0.9903888702392578, loss=0.03226644918322563
test: epoch 108, loss 1.415292501449585, acc=0.6527777910232544, loss=1.415292501449585
train: epoch 109, loss 0.02956775389611721, acc=0.9904999732971191, loss=0.02956775389611721
test: epoch 109, loss 1.1199052333831787, acc=0.7083333134651184, loss=1.1199052333831787
train: epoch 110, loss 0.022435370832681656, acc=0.9940555691719055, loss=0.022435370832681656
test: epoch 110, loss 1.252902626991272, acc=0.7138888835906982, loss=1.252902626991272
train: epoch 111, loss 0.028105059638619423, acc=0.991611123085022, loss=0.028105059638619423
test: epoch 111, loss 1.4565939903259277, acc=0.6916666626930237, loss=1.4565939903259277
train: epoch 112, loss 0.025013916194438934, acc=0.9925000071525574, loss=0.025013916194438934
test: epoch 112, loss 1.2924326658248901, acc=0.6499999761581421, loss=1.2924326658248901
train: epoch 113, loss 0.023160064592957497, acc=0.991777777671814, loss=0.023160064592957497
test: epoch 113, loss 1.4424543380737305, acc=0.605555534362793, loss=1.4424543380737305
train: epoch 114, loss 0.03472081199288368, acc=0.9903333187103271, loss=0.03472081199288368
test: epoch 114, loss 1.5754011869430542, acc=0.5972222089767456, loss=1.5754011869430542
train: epoch 115, loss 0.03274855762720108, acc=0.9909999966621399, loss=0.03274855762720108
test: epoch 115, loss 1.3537644147872925, acc=0.6805555820465088, loss=1.3537644147872925
train: epoch 116, loss 0.027673838660120964, acc=0.9912777543067932, loss=0.027673838660120964
test: epoch 116, loss 1.2410447597503662, acc=0.6944444179534912, loss=1.2410447597503662
train: epoch 117, loss 0.024097377434372902, acc=0.9930555820465088, loss=0.024097377434372902
test: epoch 117, loss 1.5311832427978516, acc=0.6000000238418579, loss=1.5311832427978516
train: epoch 118, loss 0.021909987553954124, acc=0.9934999942779541, loss=0.021909987553954124
test: epoch 118, loss 1.907436490058899, acc=0.6666666865348816, loss=1.907436490058899
train: epoch 119, loss 0.02902427315711975, acc=0.9916666746139526, loss=0.02902427315711975
test: epoch 119, loss 1.7532219886779785, acc=0.6805555820465088, loss=1.7532219886779785
train: epoch 120, loss 0.022404327988624573, acc=0.9933888912200928, loss=0.022404327988624573
test: epoch 120, loss 1.4624789953231812, acc=0.699999988079071, loss=1.4624789953231812
train: epoch 121, loss 0.020872222259640694, acc=0.9936666488647461, loss=0.020872222259640694
test: epoch 121, loss 1.1413543224334717, acc=0.7416666746139526, loss=1.1413543224334717
train: epoch 122, loss 0.023196132853627205, acc=0.9936110973358154, loss=0.023196132853627205
test: epoch 122, loss 1.5065829753875732, acc=0.7333333492279053, loss=1.5065829753875732
train: epoch 123, loss 0.022505754604935646, acc=0.9935555458068848, loss=0.022505754604935646
test: epoch 123, loss 0.9048401713371277, acc=0.7583333253860474, loss=0.9048401713371277
train: epoch 124, loss 0.01671498641371727, acc=0.9950000047683716, loss=0.01671498641371727
test: epoch 124, loss 0.9463717341423035, acc=0.7388888597488403, loss=0.9463717341423035
train: epoch 125, loss 0.021482408046722412, acc=0.9933333396911621, loss=0.021482408046722412
test: epoch 125, loss 1.2914984226226807, acc=0.800000011920929, loss=1.2914984226226807
train: epoch 126, loss 0.025393808260560036, acc=0.9931111335754395, loss=0.025393808260560036
test: epoch 126, loss 1.1093168258666992, acc=0.7555555701255798, loss=1.1093168258666992
train: epoch 127, loss 0.020568452775478363, acc=0.9944999814033508, loss=0.020568452775478363
test: epoch 127, loss 1.0746980905532837, acc=0.7555555701255798, loss=1.0746980905532837
train: epoch 128, loss 0.016110414639115334, acc=0.995888888835907, loss=0.016110414639115334
test: epoch 128, loss 0.9879067540168762, acc=0.824999988079071, loss=0.9879067540168762
train: epoch 129, loss 0.020569536834955215, acc=0.9941111207008362, loss=0.020569536834955215
test: epoch 129, loss 1.2484811544418335, acc=0.7250000238418579, loss=1.2484811544418335
train: epoch 130, loss 0.01774914748966694, acc=0.9947777986526489, loss=0.01774914748966694
test: epoch 130, loss 1.042175531387329, acc=0.7861111164093018, loss=1.042175531387329
train: epoch 131, loss 0.022003237158060074, acc=0.9931666851043701, loss=0.022003237158060074
test: epoch 131, loss 1.2423392534255981, acc=0.7361111044883728, loss=1.2423392534255981
train: epoch 132, loss 0.01208545546978712, acc=0.9959999918937683, loss=0.01208545546978712
test: epoch 132, loss 1.1054505109786987, acc=0.8361111283302307, loss=1.1054505109786987
train: epoch 133, loss 0.018001971766352654, acc=0.9948889017105103, loss=0.018001971766352654
test: epoch 133, loss 1.0143712759017944, acc=0.800000011920929, loss=1.0143712759017944
train: epoch 134, loss 0.022776881232857704, acc=0.9936666488647461, loss=0.022776881232857704
test: epoch 134, loss 1.1607844829559326, acc=0.7888888716697693, loss=1.1607844829559326
train: epoch 135, loss 0.014765321277081966, acc=0.9954444169998169, loss=0.014765321277081966
test: epoch 135, loss 0.7530897259712219, acc=0.8694444298744202, loss=0.7530897259712219
train: epoch 136, loss 0.018861398100852966, acc=0.9950000047683716, loss=0.018861398100852966
test: epoch 136, loss 1.0684055089950562, acc=0.7944444417953491, loss=1.0684055089950562
train: epoch 137, loss 0.01696106605231762, acc=0.9955000281333923, loss=0.01696106605231762
test: epoch 137, loss 1.1607049703598022, acc=0.8055555820465088, loss=1.1607049703598022
train: epoch 138, loss 0.028047852218151093, acc=0.9918333292007446, loss=0.028047852218151093
test: epoch 138, loss 0.8500184416770935, acc=0.8361111283302307, loss=0.8500184416770935
train: epoch 139, loss 0.013584904372692108, acc=0.996666669845581, loss=0.013584904372692108
test: epoch 139, loss 0.8373847603797913, acc=0.8333333134651184, loss=0.8373847603797913
train: epoch 140, loss 0.016145849600434303, acc=0.9956666827201843, loss=0.016145849600434303
test: epoch 140, loss 0.8272525668144226, acc=0.8138889074325562, loss=0.8272525668144226
train: epoch 141, loss 0.02285960130393505, acc=0.9932222366333008, loss=0.02285960130393505
test: epoch 141, loss 0.7216657996177673, acc=0.8444444537162781, loss=0.7216657996177673
train: epoch 142, loss 0.014072938822209835, acc=0.9964444637298584, loss=0.014072938822209835
test: epoch 142, loss 0.7556205987930298, acc=0.7777777910232544, loss=0.7556205987930298
train: epoch 143, loss 0.013457671739161015, acc=0.9959444403648376, loss=0.013457671739161015
test: epoch 143, loss 1.2352550029754639, acc=0.7611111402511597, loss=1.2352550029754639
train: epoch 144, loss 0.019552215933799744, acc=0.9953888654708862, loss=0.019552215933799744
test: epoch 144, loss 0.8650650382041931, acc=0.8055555820465088, loss=0.8650650382041931
train: epoch 145, loss 0.015886321663856506, acc=0.995555579662323, loss=0.015886321663856506
test: epoch 145, loss 0.6138164401054382, acc=0.8583333492279053, loss=0.6138164401054382
train: epoch 146, loss 0.014780954457819462, acc=0.9963889122009277, loss=0.014780954457819462
test: epoch 146, loss 0.9169103503227234, acc=0.824999988079071, loss=0.9169103503227234
train: epoch 147, loss 0.008260673843324184, acc=0.9973888993263245, loss=0.008260673843324184
test: epoch 147, loss 0.6638877391815186, acc=0.8805555701255798, loss=0.6638877391815186
train: epoch 148, loss 0.011668773368000984, acc=0.9969444274902344, loss=0.011668773368000984
test: epoch 148, loss 0.8490723967552185, acc=0.8583333492279053, loss=0.8490723967552185
train: epoch 149, loss 0.016430214047431946, acc=0.9956666827201843, loss=0.016430214047431946
test: epoch 149, loss 0.6401745080947876, acc=0.8666666746139526, loss=0.6401745080947876
train: epoch 150, loss 0.009201370179653168, acc=0.9980555772781372, loss=0.009201370179653168
test: epoch 150, loss 0.6136403679847717, acc=0.8833333253860474, loss=0.6136403679847717
