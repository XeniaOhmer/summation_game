# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=1", "--one_hot=false", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=308694906, receiver_embed_dim=64, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.8229141235351562, acc=0.10100000351667404, loss=2.8229141235351562
test: epoch 1, loss 3.6043813228607178, acc=0.10000000149011612, loss=3.6043813228607178
train: epoch 2, loss 1.8633897304534912, acc=0.24116666615009308, loss=1.8633897304534912
test: epoch 2, loss 3.133942127227783, acc=0.15833333134651184, loss=3.133942127227783
train: epoch 3, loss 1.5468499660491943, acc=0.3206111192703247, loss=1.5468499660491943
test: epoch 3, loss 3.6423544883728027, acc=0.16111111640930176, loss=3.6423544883728027
train: epoch 4, loss 1.3392139673233032, acc=0.4026666581630707, loss=1.3392139673233032
test: epoch 4, loss 3.5512661933898926, acc=0.17222222685813904, loss=3.5512661933898926
train: epoch 5, loss 1.1756489276885986, acc=0.47566667199134827, loss=1.1756489276885986
test: epoch 5, loss 2.8540825843811035, acc=0.22777777910232544, loss=2.8540825843811035
train: epoch 6, loss 1.1079381704330444, acc=0.495888888835907, loss=1.1079381704330444
test: epoch 6, loss 2.298795700073242, acc=0.23888888955116272, loss=2.298795700073242
train: epoch 7, loss 0.9920780062675476, acc=0.5602777600288391, loss=0.9920780062675476
test: epoch 7, loss 2.6341257095336914, acc=0.23888888955116272, loss=2.6341257095336914
train: epoch 8, loss 0.8977470397949219, acc=0.6087222099304199, loss=0.8977470397949219
test: epoch 8, loss 2.6114206314086914, acc=0.2916666567325592, loss=2.6114206314086914
train: epoch 9, loss 0.7819996476173401, acc=0.6705555319786072, loss=0.7819996476173401
test: epoch 9, loss 2.711507558822632, acc=0.38055557012557983, loss=2.711507558822632
train: epoch 10, loss 0.6144437789916992, acc=0.7457777857780457, loss=0.6144437789916992
test: epoch 10, loss 2.6815786361694336, acc=0.38333332538604736, loss=2.6815786361694336
train: epoch 11, loss 0.5298938751220703, acc=0.7798888683319092, loss=0.5298938751220703
test: epoch 11, loss 1.8791494369506836, acc=0.4138889014720917, loss=1.8791494369506836
train: epoch 12, loss 0.4309966266155243, acc=0.8133888840675354, loss=0.4309966266155243
test: epoch 12, loss 2.1692962646484375, acc=0.32777777314186096, loss=2.1692962646484375
train: epoch 13, loss 0.3802903890609741, acc=0.8409444689750671, loss=0.3802903890609741
test: epoch 13, loss 2.3674910068511963, acc=0.3638888895511627, loss=2.3674910068511963
train: epoch 14, loss 0.31976819038391113, acc=0.863611102104187, loss=0.31976819038391113
test: epoch 14, loss 2.1388988494873047, acc=0.44999998807907104, loss=2.1388988494873047
train: epoch 15, loss 0.28506723046302795, acc=0.8727777600288391, loss=0.28506723046302795
test: epoch 15, loss 2.1899044513702393, acc=0.3777777850627899, loss=2.1899044513702393
train: epoch 16, loss 0.26671046018600464, acc=0.8843888640403748, loss=0.26671046018600464
test: epoch 16, loss 1.955125331878662, acc=0.42500001192092896, loss=1.955125331878662
train: epoch 17, loss 0.2545073330402374, acc=0.8897222280502319, loss=0.2545073330402374
test: epoch 17, loss 2.0268824100494385, acc=0.4972222149372101, loss=2.0268824100494385
train: epoch 18, loss 0.23523467779159546, acc=0.895111083984375, loss=0.23523467779159546
test: epoch 18, loss 1.649340033531189, acc=0.49166667461395264, loss=1.649340033531189
train: epoch 19, loss 0.23759138584136963, acc=0.8951666951179504, loss=0.23759138584136963
test: epoch 19, loss 1.8356449604034424, acc=0.43611112236976624, loss=1.8356449604034424
train: epoch 20, loss 0.24676235020160675, acc=0.8939999938011169, loss=0.24676235020160675
test: epoch 20, loss 1.291467308998108, acc=0.6277777552604675, loss=1.291467308998108
train: epoch 21, loss 0.2043585479259491, acc=0.9071111083030701, loss=0.2043585479259491
test: epoch 21, loss 1.7403476238250732, acc=0.5416666865348816, loss=1.7403476238250732
train: epoch 22, loss 0.1896667182445526, acc=0.9133889079093933, loss=0.1896667182445526
test: epoch 22, loss 1.959531307220459, acc=0.5138888955116272, loss=1.959531307220459
train: epoch 23, loss 0.21914207935333252, acc=0.9026111364364624, loss=0.21914207935333252
test: epoch 23, loss 1.6890827417373657, acc=0.4972222149372101, loss=1.6890827417373657
train: epoch 24, loss 0.20002242922782898, acc=0.910277783870697, loss=0.20002242922782898
test: epoch 24, loss 1.9504340887069702, acc=0.49166667461395264, loss=1.9504340887069702
train: epoch 25, loss 0.20641320943832397, acc=0.9078333377838135, loss=0.20641320943832397
test: epoch 25, loss 1.922562599182129, acc=0.5222222208976746, loss=1.922562599182129
train: epoch 26, loss 0.19875675439834595, acc=0.9113333225250244, loss=0.19875675439834595
test: epoch 26, loss 1.572156310081482, acc=0.5, loss=1.572156310081482
train: epoch 27, loss 0.17189377546310425, acc=0.9190000295639038, loss=0.17189377546310425
test: epoch 27, loss 1.4193154573440552, acc=0.5722222328186035, loss=1.4193154573440552
train: epoch 28, loss 0.16965557634830475, acc=0.9233888983726501, loss=0.16965557634830475
test: epoch 28, loss 1.8105580806732178, acc=0.47777777910232544, loss=1.8105580806732178
train: epoch 29, loss 0.18951286375522614, acc=0.9176111221313477, loss=0.18951286375522614
test: epoch 29, loss 1.8084503412246704, acc=0.4694444537162781, loss=1.8084503412246704
train: epoch 30, loss 0.15209347009658813, acc=0.9467222094535828, loss=0.15209347009658813
test: epoch 30, loss 1.494111180305481, acc=0.6000000238418579, loss=1.494111180305481
train: epoch 31, loss 0.135092094540596, acc=0.9581111073493958, loss=0.135092094540596
test: epoch 31, loss 2.1114342212677, acc=0.5722222328186035, loss=2.1114342212677
train: epoch 32, loss 0.1316865235567093, acc=0.9567777514457703, loss=0.1316865235567093
test: epoch 32, loss 2.154207229614258, acc=0.5083333253860474, loss=2.154207229614258
train: epoch 33, loss 0.09934762120246887, acc=0.9669444561004639, loss=0.09934762120246887
test: epoch 33, loss 2.2061359882354736, acc=0.5305555462837219, loss=2.2061359882354736
train: epoch 34, loss 0.1194898709654808, acc=0.9605555534362793, loss=0.1194898709654808
test: epoch 34, loss 2.18406343460083, acc=0.5277777910232544, loss=2.18406343460083
train: epoch 35, loss 0.1175856813788414, acc=0.9631111025810242, loss=0.1175856813788414
test: epoch 35, loss 1.662798285484314, acc=0.5666666626930237, loss=1.662798285484314
train: epoch 36, loss 0.0986132100224495, acc=0.9676666855812073, loss=0.0986132100224495
test: epoch 36, loss 2.1895804405212402, acc=0.519444465637207, loss=2.1895804405212402
train: epoch 37, loss 0.10180240124464035, acc=0.9679444432258606, loss=0.10180240124464035
test: epoch 37, loss 1.7374449968338013, acc=0.5305555462837219, loss=1.7374449968338013
train: epoch 38, loss 0.09565983712673187, acc=0.9684444665908813, loss=0.09565983712673187
test: epoch 38, loss 1.4444069862365723, acc=0.6499999761581421, loss=1.4444069862365723
train: epoch 39, loss 0.10919614881277084, acc=0.9661666750907898, loss=0.10919614881277084
test: epoch 39, loss 1.7901489734649658, acc=0.5666666626930237, loss=1.7901489734649658
train: epoch 40, loss 0.08298209309577942, acc=0.9730555415153503, loss=0.08298209309577942
test: epoch 40, loss 1.5395691394805908, acc=0.6638888716697693, loss=1.5395691394805908
train: epoch 41, loss 0.09364546090364456, acc=0.9711666703224182, loss=0.09364546090364456
test: epoch 41, loss 1.5412025451660156, acc=0.6527777910232544, loss=1.5412025451660156
train: epoch 42, loss 0.08458736538887024, acc=0.9738333225250244, loss=0.08458736538887024
test: epoch 42, loss 1.9362587928771973, acc=0.6277777552604675, loss=1.9362587928771973
train: epoch 43, loss 0.08890009671449661, acc=0.9721666574478149, loss=0.08890009671449661
test: epoch 43, loss 1.889117956161499, acc=0.6361111402511597, loss=1.889117956161499
train: epoch 44, loss 0.09554493427276611, acc=0.9697222113609314, loss=0.09554493427276611
test: epoch 44, loss 1.8030892610549927, acc=0.625, loss=1.8030892610549927
train: epoch 45, loss 0.08459188044071198, acc=0.9740555286407471, loss=0.08459188044071198
test: epoch 45, loss 1.6072076559066772, acc=0.6583333611488342, loss=1.6072076559066772
train: epoch 46, loss 0.07468049228191376, acc=0.9762222170829773, loss=0.07468049228191376
test: epoch 46, loss 1.7387794256210327, acc=0.6499999761581421, loss=1.7387794256210327
train: epoch 47, loss 0.0677303820848465, acc=0.9795555472373962, loss=0.0677303820848465
test: epoch 47, loss 1.5670533180236816, acc=0.6944444179534912, loss=1.5670533180236816
train: epoch 48, loss 0.10670147091150284, acc=0.9674999713897705, loss=0.10670147091150284
test: epoch 48, loss 1.500352382659912, acc=0.6277777552604675, loss=1.500352382659912
train: epoch 49, loss 0.07803083956241608, acc=0.9752777814865112, loss=0.07803083956241608
test: epoch 49, loss 1.9124269485473633, acc=0.6277777552604675, loss=1.9124269485473633
train: epoch 50, loss 0.07635528594255447, acc=0.9761666655540466, loss=0.07635528594255447
test: epoch 50, loss 1.4834195375442505, acc=0.699999988079071, loss=1.4834195375442505
train: epoch 51, loss 0.09376164525747299, acc=0.9697222113609314, loss=0.09376164525747299
test: epoch 51, loss 1.9475752115249634, acc=0.6833333373069763, loss=1.9475752115249634
train: epoch 52, loss 0.07939261198043823, acc=0.9749444723129272, loss=0.07939261198043823
test: epoch 52, loss 2.0030550956726074, acc=0.6333333253860474, loss=2.0030550956726074
train: epoch 53, loss 0.08171248435974121, acc=0.9737777709960938, loss=0.08171248435974121
test: epoch 53, loss 1.5686067342758179, acc=0.7083333134651184, loss=1.5686067342758179
train: epoch 54, loss 0.08389119058847427, acc=0.9733889102935791, loss=0.08389119058847427
test: epoch 54, loss 1.4450337886810303, acc=0.7388888597488403, loss=1.4450337886810303
train: epoch 55, loss 0.07755506783723831, acc=0.9771111011505127, loss=0.07755506783723831
test: epoch 55, loss 1.4108595848083496, acc=0.7472222447395325, loss=1.4108595848083496
train: epoch 56, loss 0.06668803095817566, acc=0.9797777533531189, loss=0.06668803095817566
test: epoch 56, loss 1.0510599613189697, acc=0.7277777791023254, loss=1.0510599613189697
train: epoch 57, loss 0.06851403415203094, acc=0.9777222275733948, loss=0.06851403415203094
test: epoch 57, loss 1.3317598104476929, acc=0.7583333253860474, loss=1.3317598104476929
train: epoch 58, loss 0.07885647565126419, acc=0.9758889079093933, loss=0.07885647565126419
test: epoch 58, loss 1.412087082862854, acc=0.7333333492279053, loss=1.412087082862854
train: epoch 59, loss 0.05609119310975075, acc=0.9822221994400024, loss=0.05609119310975075
test: epoch 59, loss 1.2944564819335938, acc=0.7388888597488403, loss=1.2944564819335938
train: epoch 60, loss 0.055538494139909744, acc=0.9819444417953491, loss=0.055538494139909744
test: epoch 60, loss 1.4610226154327393, acc=0.7666666507720947, loss=1.4610226154327393
train: epoch 61, loss 0.06391061842441559, acc=0.9802777767181396, loss=0.06391061842441559
test: epoch 61, loss 1.4295604228973389, acc=0.7611111402511597, loss=1.4295604228973389
train: epoch 62, loss 0.05175141245126724, acc=0.9829444289207458, loss=0.05175141245126724
test: epoch 62, loss 1.4350427389144897, acc=0.7555555701255798, loss=1.4350427389144897
train: epoch 63, loss 0.0654587671160698, acc=0.979888916015625, loss=0.0654587671160698
test: epoch 63, loss 1.601950764656067, acc=0.7527777552604675, loss=1.601950764656067
train: epoch 64, loss 0.07105859369039536, acc=0.9787222146987915, loss=0.07105859369039536
test: epoch 64, loss 1.6592237949371338, acc=0.7250000238418579, loss=1.6592237949371338
train: epoch 65, loss 0.058927349746227264, acc=0.9830555319786072, loss=0.058927349746227264
test: epoch 65, loss 1.6183868646621704, acc=0.7611111402511597, loss=1.6183868646621704
train: epoch 66, loss 0.055488716810941696, acc=0.9811111092567444, loss=0.055488716810941696
test: epoch 66, loss 1.709558129310608, acc=0.7638888955116272, loss=1.709558129310608
train: epoch 67, loss 0.05776653066277504, acc=0.9812777638435364, loss=0.05776653066277504
test: epoch 67, loss 1.4925228357315063, acc=0.7944444417953491, loss=1.4925228357315063
train: epoch 68, loss 0.05175292119383812, acc=0.9836666584014893, loss=0.05175292119383812
test: epoch 68, loss 1.1541697978973389, acc=0.7444444298744202, loss=1.1541697978973389
train: epoch 69, loss 0.05621323361992836, acc=0.9820555448532104, loss=0.05621323361992836
test: epoch 69, loss 1.6488454341888428, acc=0.7722222208976746, loss=1.6488454341888428
train: epoch 70, loss 0.05280543118715286, acc=0.9831110835075378, loss=0.05280543118715286
test: epoch 70, loss 0.9965245127677917, acc=0.7722222208976746, loss=0.9965245127677917
train: epoch 71, loss 0.04065094143152237, acc=0.9860555529594421, loss=0.04065094143152237
test: epoch 71, loss 1.668161392211914, acc=0.699999988079071, loss=1.668161392211914
train: epoch 72, loss 0.05098387226462364, acc=0.9844444394111633, loss=0.05098387226462364
test: epoch 72, loss 1.0315172672271729, acc=0.7916666865348816, loss=1.0315172672271729
train: epoch 73, loss 0.03750433027744293, acc=0.9875555634498596, loss=0.03750433027744293
test: epoch 73, loss 0.9982788562774658, acc=0.7861111164093018, loss=0.9982788562774658
train: epoch 74, loss 0.058378882706165314, acc=0.9826111197471619, loss=0.058378882706165314
test: epoch 74, loss 1.3005590438842773, acc=0.8111110925674438, loss=1.3005590438842773
train: epoch 75, loss 0.037662506103515625, acc=0.9875555634498596, loss=0.037662506103515625
test: epoch 75, loss 1.4435888528823853, acc=0.7833333611488342, loss=1.4435888528823853
train: epoch 76, loss 0.0462166890501976, acc=0.9852222204208374, loss=0.0462166890501976
test: epoch 76, loss 1.3253170251846313, acc=0.800000011920929, loss=1.3253170251846313
train: epoch 77, loss 0.06569945812225342, acc=0.9812222123146057, loss=0.06569945812225342
test: epoch 77, loss 1.0305131673812866, acc=0.8388888835906982, loss=1.0305131673812866
train: epoch 78, loss 0.037601497024297714, acc=0.9877777695655823, loss=0.037601497024297714
test: epoch 78, loss 1.0478650331497192, acc=0.7916666865348816, loss=1.0478650331497192
train: epoch 79, loss 0.056638069450855255, acc=0.9843888878822327, loss=0.056638069450855255
test: epoch 79, loss 1.3235656023025513, acc=0.8083333373069763, loss=1.3235656023025513
train: epoch 80, loss 0.0532132051885128, acc=0.9857777953147888, loss=0.0532132051885128
test: epoch 80, loss 1.549466848373413, acc=0.8138889074325562, loss=1.549466848373413
train: epoch 81, loss 0.04379595071077347, acc=0.9857222437858582, loss=0.04379595071077347
test: epoch 81, loss 1.1442140340805054, acc=0.7888888716697693, loss=1.1442140340805054
train: epoch 82, loss 0.03716816380620003, acc=0.988611102104187, loss=0.03716816380620003
test: epoch 82, loss 1.2030696868896484, acc=0.8416666388511658, loss=1.2030696868896484
train: epoch 83, loss 0.03344688192009926, acc=0.9895555377006531, loss=0.03344688192009926
test: epoch 83, loss 1.219177484512329, acc=0.8083333373069763, loss=1.219177484512329
train: epoch 84, loss 0.045248351991176605, acc=0.9862222075462341, loss=0.045248351991176605
test: epoch 84, loss 1.1045358180999756, acc=0.8166666626930237, loss=1.1045358180999756
train: epoch 85, loss 0.03811859339475632, acc=0.9883333444595337, loss=0.03811859339475632
test: epoch 85, loss 1.0777666568756104, acc=0.8388888835906982, loss=1.0777666568756104
train: epoch 86, loss 0.05017254501581192, acc=0.9860555529594421, loss=0.05017254501581192
test: epoch 86, loss 1.2076513767242432, acc=0.7972221970558167, loss=1.2076513767242432
train: epoch 87, loss 0.04240168258547783, acc=0.9861111044883728, loss=0.04240168258547783
test: epoch 87, loss 0.9040283560752869, acc=0.855555534362793, loss=0.9040283560752869
train: epoch 88, loss 0.030115073546767235, acc=0.9896110892295837, loss=0.030115073546767235
test: epoch 88, loss 0.8140085935592651, acc=0.8444444537162781, loss=0.8140085935592651
train: epoch 89, loss 0.0472903810441494, acc=0.9869999885559082, loss=0.0472903810441494
test: epoch 89, loss 1.1130105257034302, acc=0.8472222089767456, loss=1.1130105257034302
train: epoch 90, loss 0.04361280798912048, acc=0.9860555529594421, loss=0.04361280798912048
test: epoch 90, loss 0.8985296487808228, acc=0.8416666388511658, loss=0.8985296487808228
train: epoch 91, loss 0.038667231798172, acc=0.988444447517395, loss=0.038667231798172
test: epoch 91, loss 0.8356518149375916, acc=0.8388888835906982, loss=0.8356518149375916
train: epoch 92, loss 0.03503195568919182, acc=0.9888333082199097, loss=0.03503195568919182
test: epoch 92, loss 1.1395844221115112, acc=0.8305555582046509, loss=1.1395844221115112
train: epoch 93, loss 0.04355999454855919, acc=0.9877222180366516, loss=0.04355999454855919
test: epoch 93, loss 1.0791637897491455, acc=0.8416666388511658, loss=1.0791637897491455
train: epoch 94, loss 0.03486371785402298, acc=0.9878333210945129, loss=0.03486371785402298
test: epoch 94, loss 1.0272599458694458, acc=0.8222222328186035, loss=1.0272599458694458
train: epoch 95, loss 0.044814273715019226, acc=0.9861111044883728, loss=0.044814273715019226
test: epoch 95, loss 1.0906264781951904, acc=0.8194444179534912, loss=1.0906264781951904
train: epoch 96, loss 0.04609525203704834, acc=0.9863333106040955, loss=0.04609525203704834
test: epoch 96, loss 0.6785377264022827, acc=0.8861111402511597, loss=0.6785377264022827
train: epoch 97, loss 0.0438070148229599, acc=0.988277792930603, loss=0.0438070148229599
test: epoch 97, loss 0.8490415811538696, acc=0.8472222089767456, loss=0.8490415811538696
train: epoch 98, loss 0.02843274176120758, acc=0.9907222390174866, loss=0.02843274176120758
test: epoch 98, loss 0.5177323222160339, acc=0.9055555462837219, loss=0.5177323222160339
train: epoch 99, loss 0.03234339877963066, acc=0.9893333315849304, loss=0.03234339877963066
test: epoch 99, loss 0.5853660702705383, acc=0.9027777910232544, loss=0.5853660702705383
train: epoch 100, loss 0.025034328922629356, acc=0.9915555715560913, loss=0.025034328922629356
test: epoch 100, loss 0.5571528077125549, acc=0.8805555701255798, loss=0.5571528077125549
train: epoch 101, loss 0.03770499676465988, acc=0.9892777800559998, loss=0.03770499676465988
test: epoch 101, loss 0.8177072405815125, acc=0.8916666507720947, loss=0.8177072405815125
train: epoch 102, loss 0.03140879049897194, acc=0.9891111254692078, loss=0.03140879049897194
test: epoch 102, loss 0.541323721408844, acc=0.9027777910232544, loss=0.541323721408844
train: epoch 103, loss 0.02842976711690426, acc=0.9898333549499512, loss=0.02842976711690426
test: epoch 103, loss 0.4530878961086273, acc=0.9111111164093018, loss=0.4530878961086273
train: epoch 104, loss 0.04274393618106842, acc=0.9886666536331177, loss=0.04274393618106842
test: epoch 104, loss 0.5836003422737122, acc=0.8916666507720947, loss=0.5836003422737122
train: epoch 105, loss 0.021204527467489243, acc=0.9926666617393494, loss=0.021204527467489243
test: epoch 105, loss 0.6068026423454285, acc=0.9138888716697693, loss=0.6068026423454285
train: epoch 106, loss 0.03781787306070328, acc=0.9888888597488403, loss=0.03781787306070328
test: epoch 106, loss 0.4933018982410431, acc=0.9166666865348816, loss=0.4933018982410431
train: epoch 107, loss 0.04381294548511505, acc=0.988111138343811, loss=0.04381294548511505
test: epoch 107, loss 0.6616359353065491, acc=0.9027777910232544, loss=0.6616359353065491
train: epoch 108, loss 0.031197089701890945, acc=0.9895555377006531, loss=0.031197089701890945
test: epoch 108, loss 0.4866909682750702, acc=0.9138888716697693, loss=0.4866909682750702
train: epoch 109, loss 0.03633972629904747, acc=0.9901666641235352, loss=0.03633972629904747
test: epoch 109, loss 0.4592711627483368, acc=0.9166666865348816, loss=0.4592711627483368
train: epoch 110, loss 0.01644669473171234, acc=0.9934999942779541, loss=0.01644669473171234
test: epoch 110, loss 0.621311604976654, acc=0.9138888716697693, loss=0.621311604976654
train: epoch 111, loss 0.0312664769589901, acc=0.9902777671813965, loss=0.0312664769589901
test: epoch 111, loss 0.4836135506629944, acc=0.9194444417953491, loss=0.4836135506629944
train: epoch 112, loss 0.025161894038319588, acc=0.9906666874885559, loss=0.025161894038319588
test: epoch 112, loss 0.5143119692802429, acc=0.9222221970558167, loss=0.5143119692802429
train: epoch 113, loss 0.03242703527212143, acc=0.9896666407585144, loss=0.03242703527212143
test: epoch 113, loss 0.7682575583457947, acc=0.9138888716697693, loss=0.7682575583457947
train: epoch 114, loss 0.024447934702038765, acc=0.9915555715560913, loss=0.024447934702038765
test: epoch 114, loss 0.5000897645950317, acc=0.925000011920929, loss=0.5000897645950317
train: epoch 115, loss 0.017383599653840065, acc=0.9931666851043701, loss=0.017383599653840065
test: epoch 115, loss 0.5899965763092041, acc=0.9166666865348816, loss=0.5899965763092041
train: epoch 116, loss 0.04854942485690117, acc=0.9871110916137695, loss=0.04854942485690117
test: epoch 116, loss 0.4991500973701477, acc=0.9416666626930237, loss=0.4991500973701477
train: epoch 117, loss 0.022515904158353806, acc=0.9918888807296753, loss=0.022515904158353806
test: epoch 117, loss 0.540148913860321, acc=0.9222221970558167, loss=0.540148913860321
train: epoch 118, loss 0.020230384543538094, acc=0.992388904094696, loss=0.020230384543538094
test: epoch 118, loss 0.6592738032341003, acc=0.9361110925674438, loss=0.6592738032341003
train: epoch 119, loss 0.04552174732089043, acc=0.9866111278533936, loss=0.04552174732089043
test: epoch 119, loss 0.5498604774475098, acc=0.894444465637207, loss=0.5498604774475098
train: epoch 120, loss 0.03908053785562515, acc=0.9876111149787903, loss=0.03908053785562515
test: epoch 120, loss 0.556266188621521, acc=0.8916666507720947, loss=0.556266188621521
train: epoch 121, loss 0.045538414269685745, acc=0.9851666688919067, loss=0.045538414269685745
test: epoch 121, loss 0.5984313488006592, acc=0.8999999761581421, loss=0.5984313488006592
train: epoch 122, loss 0.029860597103834152, acc=0.9900000095367432, loss=0.029860597103834152
test: epoch 122, loss 0.47925567626953125, acc=0.9083333611488342, loss=0.47925567626953125
train: epoch 123, loss 0.019701512530446053, acc=0.991944432258606, loss=0.019701512530446053
test: epoch 123, loss 0.44783979654312134, acc=0.9277777671813965, loss=0.44783979654312134
train: epoch 124, loss 0.028297895565629005, acc=0.9906666874885559, loss=0.028297895565629005
test: epoch 124, loss 0.6006566286087036, acc=0.9055555462837219, loss=0.6006566286087036
train: epoch 125, loss 0.016574157401919365, acc=0.9933888912200928, loss=0.016574157401919365
test: epoch 125, loss 0.5945591926574707, acc=0.9166666865348816, loss=0.5945591926574707
train: epoch 126, loss 0.041200269013643265, acc=0.988444447517395, loss=0.041200269013643265
test: epoch 126, loss 0.7270073294639587, acc=0.8888888955116272, loss=0.7270073294639587
train: epoch 127, loss 0.05178961157798767, acc=0.9871666431427002, loss=0.05178961157798767
test: epoch 127, loss 0.5688887238502502, acc=0.9277777671813965, loss=0.5688887238502502
train: epoch 128, loss 0.027285348623991013, acc=0.9913333058357239, loss=0.027285348623991013
test: epoch 128, loss 0.4260002374649048, acc=0.925000011920929, loss=0.4260002374649048
train: epoch 129, loss 0.018501324579119682, acc=0.9929444193840027, loss=0.018501324579119682
test: epoch 129, loss 0.4970880448818207, acc=0.925000011920929, loss=0.4970880448818207
train: epoch 130, loss 0.014298512600362301, acc=0.9938889145851135, loss=0.014298512600362301
test: epoch 130, loss 0.6381570100784302, acc=0.9416666626930237, loss=0.6381570100784302
train: epoch 131, loss 0.018629303202033043, acc=0.99272221326828, loss=0.018629303202033043
test: epoch 131, loss 0.6516289710998535, acc=0.9166666865348816, loss=0.6516289710998535
train: epoch 132, loss 0.03123936988413334, acc=0.9908888936042786, loss=0.03123936988413334
test: epoch 132, loss 0.64284747838974, acc=0.9111111164093018, loss=0.64284747838974
train: epoch 133, loss 0.04136539623141289, acc=0.9890000224113464, loss=0.04136539623141289
test: epoch 133, loss 0.5880612134933472, acc=0.9194444417953491, loss=0.5880612134933472
train: epoch 134, loss 0.02214452438056469, acc=0.9921666383743286, loss=0.02214452438056469
test: epoch 134, loss 0.5221702456474304, acc=0.9027777910232544, loss=0.5221702456474304
train: epoch 135, loss 0.017878051847219467, acc=0.9926111102104187, loss=0.017878051847219467
test: epoch 135, loss 0.5363721251487732, acc=0.9444444179534912, loss=0.5363721251487732
train: epoch 136, loss 0.051754724234342575, acc=0.9868888854980469, loss=0.051754724234342575
test: epoch 136, loss 0.3143826425075531, acc=0.9138888716697693, loss=0.3143826425075531
train: epoch 137, loss 0.0334288626909256, acc=0.9871110916137695, loss=0.0334288626909256
test: epoch 137, loss 0.30314570665359497, acc=0.925000011920929, loss=0.30314570665359497
train: epoch 138, loss 0.03153478726744652, acc=0.9894999861717224, loss=0.03153478726744652
test: epoch 138, loss 0.2827809154987335, acc=0.9166666865348816, loss=0.2827809154987335
train: epoch 139, loss 0.025710422545671463, acc=0.9907222390174866, loss=0.025710422545671463
test: epoch 139, loss 0.4925372898578644, acc=0.9277777671813965, loss=0.4925372898578644
train: epoch 140, loss 0.0367063507437706, acc=0.9895555377006531, loss=0.0367063507437706
test: epoch 140, loss 0.3661956787109375, acc=0.9222221970558167, loss=0.3661956787109375
train: epoch 141, loss 0.02064882591366768, acc=0.9923333525657654, loss=0.02064882591366768
test: epoch 141, loss 0.4356599748134613, acc=0.9277777671813965, loss=0.4356599748134613
train: epoch 142, loss 0.027401354163885117, acc=0.9911666512489319, loss=0.027401354163885117
test: epoch 142, loss 0.5785580277442932, acc=0.9416666626930237, loss=0.5785580277442932
train: epoch 143, loss 0.016855642199516296, acc=0.9932777881622314, loss=0.016855642199516296
test: epoch 143, loss 0.4714548885822296, acc=0.9166666865348816, loss=0.4714548885822296
train: epoch 144, loss 0.07023778557777405, acc=0.9845555424690247, loss=0.07023778557777405
test: epoch 144, loss 0.44263315200805664, acc=0.9222221970558167, loss=0.44263315200805664
train: epoch 145, loss 0.05464193597435951, acc=0.9816111326217651, loss=0.05464193597435951
test: epoch 145, loss 0.39967551827430725, acc=0.9222221970558167, loss=0.39967551827430725
train: epoch 146, loss 0.05994897335767746, acc=0.9835555553436279, loss=0.05994897335767746
test: epoch 146, loss 0.4022383391857147, acc=0.9361110925674438, loss=0.4022383391857147
train: epoch 147, loss 0.04619382321834564, acc=0.9842222332954407, loss=0.04619382321834564
test: epoch 147, loss 0.5519472360610962, acc=0.9111111164093018, loss=0.5519472360610962
train: epoch 148, loss 0.04922296851873398, acc=0.9847221970558167, loss=0.04922296851873398
test: epoch 148, loss 0.4829302728176117, acc=0.9194444417953491, loss=0.4829302728176117
train: epoch 149, loss 0.041147541254758835, acc=0.9874444603919983, loss=0.041147541254758835
test: epoch 149, loss 0.4536351263523102, acc=0.9333333373069763, loss=0.4536351263523102
train: epoch 150, loss 0.044161297380924225, acc=0.9869444370269775, loss=0.044161297380924225
test: epoch 150, loss 0.37465527653694153, acc=0.9361110925674438, loss=0.37465527653694153
