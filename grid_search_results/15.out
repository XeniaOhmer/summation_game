# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1", "--temp_decay=0.99", "--one_hot=false", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=150037449, receiver_embed_dim=32, temp_decay=0.99, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.4752016067504883, acc=0.047111112624406815, loss=3.4752016067504883
test: epoch 1, loss 3.7934393882751465, acc=0.05277777835726738, loss=3.7934393882751465
train: epoch 2, loss 3.1576194763183594, acc=0.06416666507720947, loss=3.1576194763183594
test: epoch 2, loss 3.588496208190918, acc=0.06388889253139496, loss=3.588496208190918
train: epoch 3, loss 2.730518341064453, acc=0.12577778100967407, loss=2.730518341064453
test: epoch 3, loss 3.1336705684661865, acc=0.09166666865348816, loss=3.1336705684661865
train: epoch 4, loss 2.4585559368133545, acc=0.17383334040641785, loss=2.4585559368133545
test: epoch 4, loss 2.813937187194824, acc=0.1111111119389534, loss=2.813937187194824
train: epoch 5, loss 2.177290916442871, acc=0.2238333374261856, loss=2.177290916442871
test: epoch 5, loss 2.670363664627075, acc=0.11944444477558136, loss=2.670363664627075
train: epoch 6, loss 2.007871389389038, acc=0.2657777667045593, loss=2.007871389389038
test: epoch 6, loss 2.5368733406066895, acc=0.14444445073604584, loss=2.5368733406066895
train: epoch 7, loss 1.893373727798462, acc=0.30177778005599976, loss=1.893373727798462
test: epoch 7, loss 2.4595143795013428, acc=0.14722222089767456, loss=2.4595143795013428
train: epoch 8, loss 1.8247708082199097, acc=0.3166666626930237, loss=1.8247708082199097
test: epoch 8, loss 2.4030826091766357, acc=0.13333334028720856, loss=2.4030826091766357
train: epoch 9, loss 1.7637555599212646, acc=0.32938888669013977, loss=1.7637555599212646
test: epoch 9, loss 2.339046001434326, acc=0.14444445073604584, loss=2.339046001434326
train: epoch 10, loss 1.7035479545593262, acc=0.3466666638851166, loss=1.7035479545593262
test: epoch 10, loss 2.342010259628296, acc=0.15833333134651184, loss=2.342010259628296
train: epoch 11, loss 1.6640384197235107, acc=0.35305556654930115, loss=1.6640384197235107
test: epoch 11, loss 2.2211697101593018, acc=0.1805555522441864, loss=2.2211697101593018
train: epoch 12, loss 1.6305607557296753, acc=0.36783334612846375, loss=1.6305607557296753
test: epoch 12, loss 2.2094314098358154, acc=0.18333333730697632, loss=2.2094314098358154
train: epoch 13, loss 1.597764253616333, acc=0.37805554270744324, loss=1.597764253616333
test: epoch 13, loss 2.196786642074585, acc=0.17499999701976776, loss=2.196786642074585
train: epoch 14, loss 1.546305537223816, acc=0.3935000002384186, loss=1.546305537223816
test: epoch 14, loss 2.1031155586242676, acc=0.1944444477558136, loss=2.1031155586242676
train: epoch 15, loss 1.5204718112945557, acc=0.40122222900390625, loss=1.5204718112945557
test: epoch 15, loss 2.0704619884490967, acc=0.19166666269302368, loss=2.0704619884490967
train: epoch 16, loss 1.4910778999328613, acc=0.41111111640930176, loss=1.4910778999328613
test: epoch 16, loss 2.032477617263794, acc=0.20555555820465088, loss=2.032477617263794
train: epoch 17, loss 1.4657644033432007, acc=0.4159444570541382, loss=1.4657644033432007
test: epoch 17, loss 2.0420126914978027, acc=0.2083333283662796, loss=2.0420126914978027
train: epoch 18, loss 1.4466711282730103, acc=0.4256666600704193, loss=1.4466711282730103
test: epoch 18, loss 2.028085947036743, acc=0.21111111342906952, loss=2.028085947036743
train: epoch 19, loss 1.405776858329773, acc=0.43755555152893066, loss=1.405776858329773
test: epoch 19, loss 1.987817406654358, acc=0.2222222238779068, loss=1.987817406654358
train: epoch 20, loss 1.3842108249664307, acc=0.4431111216545105, loss=1.3842108249664307
test: epoch 20, loss 1.9513503313064575, acc=0.2222222238779068, loss=1.9513503313064575
train: epoch 21, loss 1.3697149753570557, acc=0.4546666741371155, loss=1.3697149753570557
test: epoch 21, loss 1.9011766910552979, acc=0.22777777910232544, loss=1.9011766910552979
train: epoch 22, loss 1.3515077829360962, acc=0.4577777683734894, loss=1.3515077829360962
test: epoch 22, loss 1.9631680250167847, acc=0.22499999403953552, loss=1.9631680250167847
train: epoch 23, loss 1.3334439992904663, acc=0.46594443917274475, loss=1.3334439992904663
test: epoch 23, loss 1.929256558418274, acc=0.23055554926395416, loss=1.929256558418274
train: epoch 24, loss 1.3055788278579712, acc=0.4732777774333954, loss=1.3055788278579712
test: epoch 24, loss 1.8664140701293945, acc=0.2361111044883728, loss=1.8664140701293945
train: epoch 25, loss 1.292346477508545, acc=0.4794999957084656, loss=1.292346477508545
test: epoch 25, loss 1.865509033203125, acc=0.23055554926395416, loss=1.865509033203125
train: epoch 26, loss 1.2622910737991333, acc=0.49183332920074463, loss=1.2622910737991333
test: epoch 26, loss 1.803399920463562, acc=0.24722221493721008, loss=1.803399920463562
train: epoch 27, loss 1.2487558126449585, acc=0.4975000023841858, loss=1.2487558126449585
test: epoch 27, loss 1.8455760478973389, acc=0.25833332538604736, loss=1.8455760478973389
train: epoch 28, loss 1.2348198890686035, acc=0.49988889694213867, loss=1.2348198890686035
test: epoch 28, loss 1.8299896717071533, acc=0.25555557012557983, loss=1.8299896717071533
train: epoch 29, loss 1.223816990852356, acc=0.503166675567627, loss=1.223816990852356
test: epoch 29, loss 1.8526735305786133, acc=0.24722221493721008, loss=1.8526735305786133
train: epoch 30, loss 1.1885794401168823, acc=0.5158888697624207, loss=1.1885794401168823
test: epoch 30, loss 1.8298137187957764, acc=0.23888888955116272, loss=1.8298137187957764
train: epoch 31, loss 1.1815050840377808, acc=0.5191666483879089, loss=1.1815050840377808
test: epoch 31, loss 1.821597695350647, acc=0.2611111104488373, loss=1.821597695350647
train: epoch 32, loss 1.170558214187622, acc=0.5282222032546997, loss=1.170558214187622
test: epoch 32, loss 1.8713726997375488, acc=0.2638888955116272, loss=1.8713726997375488
train: epoch 33, loss 1.1546592712402344, acc=0.5332221984863281, loss=1.1546592712402344
test: epoch 33, loss 1.7652866840362549, acc=0.2750000059604645, loss=1.7652866840362549
train: epoch 34, loss 1.1420279741287231, acc=0.5341110825538635, loss=1.1420279741287231
test: epoch 34, loss 1.7931697368621826, acc=0.2777777910232544, loss=1.7931697368621826
train: epoch 35, loss 1.1206761598587036, acc=0.5374444723129272, loss=1.1206761598587036
test: epoch 35, loss 1.7827986478805542, acc=0.26944443583488464, loss=1.7827986478805542
train: epoch 36, loss 1.1146429777145386, acc=0.5411111116409302, loss=1.1146429777145386
test: epoch 36, loss 1.78917396068573, acc=0.27222222089767456, loss=1.78917396068573
train: epoch 37, loss 1.1076219081878662, acc=0.5484444499015808, loss=1.1076219081878662
test: epoch 37, loss 1.8143824338912964, acc=0.28611111640930176, loss=1.8143824338912964
train: epoch 38, loss 1.092342495918274, acc=0.5462222099304199, loss=1.092342495918274
test: epoch 38, loss 1.8198946714401245, acc=0.27222222089767456, loss=1.8198946714401245
train: epoch 39, loss 1.0835793018341064, acc=0.5452222228050232, loss=1.0835793018341064
test: epoch 39, loss 1.7602802515029907, acc=0.2805555462837219, loss=1.7602802515029907
train: epoch 40, loss 1.0574582815170288, acc=0.5560555458068848, loss=1.0574582815170288
test: epoch 40, loss 1.740913987159729, acc=0.27222222089767456, loss=1.740913987159729
train: epoch 41, loss 1.059676170349121, acc=0.5558333396911621, loss=1.059676170349121
test: epoch 41, loss 1.8092942237854004, acc=0.2750000059604645, loss=1.8092942237854004
train: epoch 42, loss 1.026100754737854, acc=0.5661666393280029, loss=1.026100754737854
test: epoch 42, loss 1.7652350664138794, acc=0.29722222685813904, loss=1.7652350664138794
train: epoch 43, loss 1.0327385663986206, acc=0.5663889050483704, loss=1.0327385663986206
test: epoch 43, loss 1.7369643449783325, acc=0.30000001192092896, loss=1.7369643449783325
train: epoch 44, loss 1.0300976037979126, acc=0.566611111164093, loss=1.0300976037979126
test: epoch 44, loss 1.7739217281341553, acc=0.3083333373069763, loss=1.7739217281341553
train: epoch 45, loss 1.0034176111221313, acc=0.5763888955116272, loss=1.0034176111221313
test: epoch 45, loss 1.7180681228637695, acc=0.2888889014720917, loss=1.7180681228637695
train: epoch 46, loss 1.011644721031189, acc=0.5758888721466064, loss=1.011644721031189
test: epoch 46, loss 1.6535454988479614, acc=0.3027777671813965, loss=1.6535454988479614
train: epoch 47, loss 1.0051939487457275, acc=0.5780555605888367, loss=1.0051939487457275
test: epoch 47, loss 1.7048903703689575, acc=0.3027777671813965, loss=1.7048903703689575
train: epoch 48, loss 0.9838841557502747, acc=0.5832777619361877, loss=0.9838841557502747
test: epoch 48, loss 1.7123841047286987, acc=0.3027777671813965, loss=1.7123841047286987
train: epoch 49, loss 0.9615116715431213, acc=0.5959444642066956, loss=0.9615116715431213
test: epoch 49, loss 1.746124029159546, acc=0.31111112236976624, loss=1.746124029159546
train: epoch 50, loss 0.9670384526252747, acc=0.5909444689750671, loss=0.9670384526252747
test: epoch 50, loss 1.66549551486969, acc=0.3166666626930237, loss=1.66549551486969
train: epoch 51, loss 0.9527732133865356, acc=0.5952222347259521, loss=0.9527732133865356
test: epoch 51, loss 1.7898222208023071, acc=0.3166666626930237, loss=1.7898222208023071
train: epoch 52, loss 0.942300021648407, acc=0.5985555648803711, loss=0.942300021648407
test: epoch 52, loss 1.726165771484375, acc=0.3222222328186035, loss=1.726165771484375
train: epoch 53, loss 0.9383249282836914, acc=0.6028888821601868, loss=0.9383249282836914
test: epoch 53, loss 1.749612808227539, acc=0.29722222685813904, loss=1.749612808227539
train: epoch 54, loss 0.9343093037605286, acc=0.6000000238418579, loss=0.9343093037605286
test: epoch 54, loss 1.7231320142745972, acc=0.34166666865348816, loss=1.7231320142745972
train: epoch 55, loss 0.9206452965736389, acc=0.605055570602417, loss=0.9206452965736389
test: epoch 55, loss 1.672619342803955, acc=0.32777777314186096, loss=1.672619342803955
train: epoch 56, loss 0.9147370457649231, acc=0.6075555682182312, loss=0.9147370457649231
test: epoch 56, loss 1.756135106086731, acc=0.3361110985279083, loss=1.756135106086731
train: epoch 57, loss 0.903765857219696, acc=0.6059444546699524, loss=0.903765857219696
test: epoch 57, loss 1.6155738830566406, acc=0.33888888359069824, loss=1.6155738830566406
train: epoch 58, loss 0.90328449010849, acc=0.6106111407279968, loss=0.90328449010849
test: epoch 58, loss 1.6836415529251099, acc=0.3361110985279083, loss=1.6836415529251099
train: epoch 59, loss 0.8978983163833618, acc=0.6152222156524658, loss=0.8978983163833618
test: epoch 59, loss 1.7041045427322388, acc=0.3361110985279083, loss=1.7041045427322388
train: epoch 60, loss 0.8877951502799988, acc=0.6211666464805603, loss=0.8877951502799988
test: epoch 60, loss 1.6481086015701294, acc=0.3444444537162781, loss=1.6481086015701294
train: epoch 61, loss 0.8860043287277222, acc=0.621666669845581, loss=0.8860043287277222
test: epoch 61, loss 1.6375256776809692, acc=0.3472222089767456, loss=1.6375256776809692
train: epoch 62, loss 0.8597025871276855, acc=0.6249444484710693, loss=0.8597025871276855
test: epoch 62, loss 1.6962813138961792, acc=0.32777777314186096, loss=1.6962813138961792
train: epoch 63, loss 0.8707799911499023, acc=0.6240555644035339, loss=0.8707799911499023
test: epoch 63, loss 1.7179923057556152, acc=0.3472222089767456, loss=1.7179923057556152
train: epoch 64, loss 0.8645423054695129, acc=0.6247777938842773, loss=0.8645423054695129
test: epoch 64, loss 1.6283326148986816, acc=0.35277777910232544, loss=1.6283326148986816
train: epoch 65, loss 0.8651499152183533, acc=0.6309999823570251, loss=0.8651499152183533
test: epoch 65, loss 1.63861083984375, acc=0.35555556416511536, loss=1.63861083984375
train: epoch 66, loss 0.8510265946388245, acc=0.6346666812896729, loss=0.8510265946388245
test: epoch 66, loss 1.7212845087051392, acc=0.3472222089767456, loss=1.7212845087051392
train: epoch 67, loss 0.8309360146522522, acc=0.6351110935211182, loss=0.8309360146522522
test: epoch 67, loss 1.6536728143692017, acc=0.35277777910232544, loss=1.6536728143692017
train: epoch 68, loss 0.831666886806488, acc=0.6395555734634399, loss=0.831666886806488
test: epoch 68, loss 1.7022639513015747, acc=0.3472222089767456, loss=1.7022639513015747
train: epoch 69, loss 0.8299117684364319, acc=0.6416110992431641, loss=0.8299117684364319
test: epoch 69, loss 1.614218831062317, acc=0.35277777910232544, loss=1.614218831062317
train: epoch 70, loss 0.8252263069152832, acc=0.6399999856948853, loss=0.8252263069152832
test: epoch 70, loss 1.7451785802841187, acc=0.3472222089767456, loss=1.7451785802841187
train: epoch 71, loss 0.8154247403144836, acc=0.6433888673782349, loss=0.8154247403144836
test: epoch 71, loss 1.5849158763885498, acc=0.3638888895511627, loss=1.5849158763885498
train: epoch 72, loss 0.8146853446960449, acc=0.6407222151756287, loss=0.8146853446960449
test: epoch 72, loss 1.645790696144104, acc=0.3444444537162781, loss=1.645790696144104
train: epoch 73, loss 0.8005115985870361, acc=0.6510000228881836, loss=0.8005115985870361
test: epoch 73, loss 1.6215403079986572, acc=0.3583333194255829, loss=1.6215403079986572
train: epoch 74, loss 0.7949530482292175, acc=0.6521666646003723, loss=0.7949530482292175
test: epoch 74, loss 1.6157244443893433, acc=0.3472222089767456, loss=1.6157244443893433
train: epoch 75, loss 0.7906110286712646, acc=0.6572777628898621, loss=0.7906110286712646
test: epoch 75, loss 1.6392320394515991, acc=0.3472222089767456, loss=1.6392320394515991
train: epoch 76, loss 0.7880501747131348, acc=0.6592777967453003, loss=0.7880501747131348
test: epoch 76, loss 1.6787229776382446, acc=0.34166666865348816, loss=1.6787229776382446
train: epoch 77, loss 0.7760825753211975, acc=0.6616111397743225, loss=0.7760825753211975
test: epoch 77, loss 1.5795154571533203, acc=0.36944442987442017, loss=1.5795154571533203
train: epoch 78, loss 0.780813455581665, acc=0.6573888659477234, loss=0.780813455581665
test: epoch 78, loss 1.7373085021972656, acc=0.3499999940395355, loss=1.7373085021972656
train: epoch 79, loss 0.760314404964447, acc=0.6662222146987915, loss=0.760314404964447
test: epoch 79, loss 1.526495099067688, acc=0.3583333194255829, loss=1.526495099067688
train: epoch 80, loss 0.7566169500350952, acc=0.6657222509384155, loss=0.7566169500350952
test: epoch 80, loss 1.5822933912277222, acc=0.36944442987442017, loss=1.5822933912277222
train: epoch 81, loss 0.7612721920013428, acc=0.6642777919769287, loss=0.7612721920013428
test: epoch 81, loss 1.6168311834335327, acc=0.36666667461395264, loss=1.6168311834335327
train: epoch 82, loss 0.757959246635437, acc=0.6628888845443726, loss=0.757959246635437
test: epoch 82, loss 1.6858478784561157, acc=0.3722222149372101, loss=1.6858478784561157
train: epoch 83, loss 0.7410255670547485, acc=0.6682222485542297, loss=0.7410255670547485
test: epoch 83, loss 1.6989821195602417, acc=0.38055557012557983, loss=1.6989821195602417
train: epoch 84, loss 0.7241081595420837, acc=0.6771110892295837, loss=0.7241081595420837
test: epoch 84, loss 1.644675374031067, acc=0.36944442987442017, loss=1.644675374031067
train: epoch 85, loss 0.7317749261856079, acc=0.6788333058357239, loss=0.7317749261856079
test: epoch 85, loss 1.734046459197998, acc=0.35555556416511536, loss=1.734046459197998
train: epoch 86, loss 0.733063817024231, acc=0.6753333210945129, loss=0.733063817024231
test: epoch 86, loss 1.670896053314209, acc=0.3777777850627899, loss=1.670896053314209
train: epoch 87, loss 0.7300339341163635, acc=0.6735000014305115, loss=0.7300339341163635
test: epoch 87, loss 1.5950943231582642, acc=0.38333332538604736, loss=1.5950943231582642
train: epoch 88, loss 0.7452157735824585, acc=0.6750555634498596, loss=0.7452157735824585
test: epoch 88, loss 1.6853387355804443, acc=0.36666667461395264, loss=1.6853387355804443
train: epoch 89, loss 0.7149739265441895, acc=0.6840000152587891, loss=0.7149739265441895
test: epoch 89, loss 1.6644309759140015, acc=0.3638888895511627, loss=1.6644309759140015
train: epoch 90, loss 0.7312237620353699, acc=0.6823333501815796, loss=0.7312237620353699
test: epoch 90, loss 1.6540462970733643, acc=0.3777777850627899, loss=1.6540462970733643
train: epoch 91, loss 0.7228915691375732, acc=0.6802777647972107, loss=0.7228915691375732
test: epoch 91, loss 1.578696608543396, acc=0.375, loss=1.578696608543396
train: epoch 92, loss 0.6980434656143188, acc=0.6884444355964661, loss=0.6980434656143188
test: epoch 92, loss 1.7050520181655884, acc=0.38055557012557983, loss=1.7050520181655884
train: epoch 93, loss 0.6982037425041199, acc=0.6834444403648376, loss=0.6982037425041199
test: epoch 93, loss 1.6792055368423462, acc=0.3777777850627899, loss=1.6792055368423462
train: epoch 94, loss 0.7018096446990967, acc=0.683055579662323, loss=0.7018096446990967
test: epoch 94, loss 1.697800874710083, acc=0.3777777850627899, loss=1.697800874710083
train: epoch 95, loss 0.6905635595321655, acc=0.6877222061157227, loss=0.6905635595321655
test: epoch 95, loss 1.6828129291534424, acc=0.38333332538604736, loss=1.6828129291534424
train: epoch 96, loss 0.701012134552002, acc=0.6828888654708862, loss=0.701012134552002
test: epoch 96, loss 1.6682968139648438, acc=0.38055557012557983, loss=1.6682968139648438
train: epoch 97, loss 0.6933521628379822, acc=0.6912222504615784, loss=0.6933521628379822
test: epoch 97, loss 1.6867784261703491, acc=0.3777777850627899, loss=1.6867784261703491
train: epoch 98, loss 0.6778468489646912, acc=0.6937777996063232, loss=0.6778468489646912
test: epoch 98, loss 1.690890908241272, acc=0.36944442987442017, loss=1.690890908241272
train: epoch 99, loss 0.6853652596473694, acc=0.6926666498184204, loss=0.6853652596473694
test: epoch 99, loss 1.783988118171692, acc=0.38055557012557983, loss=1.783988118171692
train: epoch 100, loss 0.6717151999473572, acc=0.6984444260597229, loss=0.6717151999473572
test: epoch 100, loss 1.7841702699661255, acc=0.3861111104488373, loss=1.7841702699661255
train: epoch 101, loss 0.6727035045623779, acc=0.6948888897895813, loss=0.6727035045623779
test: epoch 101, loss 1.539300799369812, acc=0.3888888955116272, loss=1.539300799369812
train: epoch 102, loss 0.6802458763122559, acc=0.6972777843475342, loss=0.6802458763122559
test: epoch 102, loss 1.6153318881988525, acc=0.39444443583488464, loss=1.6153318881988525
train: epoch 103, loss 0.6776488423347473, acc=0.6974444389343262, loss=0.6776488423347473
test: epoch 103, loss 1.5674594640731812, acc=0.39722222089767456, loss=1.5674594640731812
train: epoch 104, loss 0.6620851159095764, acc=0.7017777562141418, loss=0.6620851159095764
test: epoch 104, loss 1.6102217435836792, acc=0.39722222089767456, loss=1.6102217435836792
train: epoch 105, loss 0.6772304177284241, acc=0.7029444575309753, loss=0.6772304177284241
test: epoch 105, loss 1.6995198726654053, acc=0.38333332538604736, loss=1.6995198726654053
train: epoch 106, loss 0.6582354307174683, acc=0.7026666402816772, loss=0.6582354307174683
test: epoch 106, loss 1.636017918586731, acc=0.38333332538604736, loss=1.636017918586731
train: epoch 107, loss 0.6608150601387024, acc=0.7070555686950684, loss=0.6608150601387024
test: epoch 107, loss 1.7617251873016357, acc=0.4000000059604645, loss=1.7617251873016357
train: epoch 108, loss 0.654151201248169, acc=0.7056111097335815, loss=0.654151201248169
test: epoch 108, loss 1.693717122077942, acc=0.39722222089767456, loss=1.693717122077942
train: epoch 109, loss 0.6609748601913452, acc=0.7073333263397217, loss=0.6609748601913452
test: epoch 109, loss 1.6496232748031616, acc=0.4055555462837219, loss=1.6496232748031616
train: epoch 110, loss 0.6455825567245483, acc=0.7103333473205566, loss=0.6455825567245483
test: epoch 110, loss 1.6481086015701294, acc=0.3916666805744171, loss=1.6481086015701294
train: epoch 111, loss 0.6435270309448242, acc=0.7103333473205566, loss=0.6435270309448242
test: epoch 111, loss 1.6695955991744995, acc=0.3888888955116272, loss=1.6695955991744995
train: epoch 112, loss 0.6513945460319519, acc=0.7092221975326538, loss=0.6513945460319519
test: epoch 112, loss 1.7190181016921997, acc=0.39722222089767456, loss=1.7190181016921997
train: epoch 113, loss 0.6310986280441284, acc=0.7153333425521851, loss=0.6310986280441284
test: epoch 113, loss 1.5762324333190918, acc=0.4000000059604645, loss=1.5762324333190918
train: epoch 114, loss 0.6275715231895447, acc=0.714722216129303, loss=0.6275715231895447
test: epoch 114, loss 1.7187353372573853, acc=0.39722222089767456, loss=1.7187353372573853
train: epoch 115, loss 0.6346991062164307, acc=0.7163888812065125, loss=0.6346991062164307
test: epoch 115, loss 1.6934010982513428, acc=0.3861111104488373, loss=1.6934010982513428
train: epoch 116, loss 0.6292692422866821, acc=0.7165555357933044, loss=0.6292692422866821
test: epoch 116, loss 1.656429409980774, acc=0.4055555462837219, loss=1.656429409980774
train: epoch 117, loss 0.6258672475814819, acc=0.7187777757644653, loss=0.6258672475814819
test: epoch 117, loss 1.7098629474639893, acc=0.3777777850627899, loss=1.7098629474639893
train: epoch 118, loss 0.6255382895469666, acc=0.7230555415153503, loss=0.6255382895469666
test: epoch 118, loss 1.8099063634872437, acc=0.4055555462837219, loss=1.8099063634872437
train: epoch 119, loss 0.6194227933883667, acc=0.722611129283905, loss=0.6194227933883667
test: epoch 119, loss 1.6859242916107178, acc=0.3916666805744171, loss=1.6859242916107178
train: epoch 120, loss 0.6251598596572876, acc=0.7228888869285583, loss=0.6251598596572876
test: epoch 120, loss 1.8414682149887085, acc=0.4000000059604645, loss=1.8414682149887085
train: epoch 121, loss 0.6211545467376709, acc=0.7178333401679993, loss=0.6211545467376709
test: epoch 121, loss 1.7291420698165894, acc=0.4055555462837219, loss=1.7291420698165894
train: epoch 122, loss 0.6328123807907104, acc=0.7235555648803711, loss=0.6328123807907104
test: epoch 122, loss 1.7054730653762817, acc=0.41111111640930176, loss=1.7054730653762817
train: epoch 123, loss 0.6066886186599731, acc=0.725777804851532, loss=0.6066886186599731
test: epoch 123, loss 1.850014328956604, acc=0.4166666567325592, loss=1.850014328956604
train: epoch 124, loss 0.6201412081718445, acc=0.722611129283905, loss=0.6201412081718445
test: epoch 124, loss 1.6397722959518433, acc=0.4027777910232544, loss=1.6397722959518433
train: epoch 125, loss 0.6128205060958862, acc=0.7250000238418579, loss=0.6128205060958862
test: epoch 125, loss 1.643507957458496, acc=0.39722222089767456, loss=1.643507957458496
train: epoch 126, loss 0.6000733375549316, acc=0.7291111350059509, loss=0.6000733375549316
test: epoch 126, loss 1.6537355184555054, acc=0.4138889014720917, loss=1.6537355184555054
train: epoch 127, loss 0.6014201045036316, acc=0.7296666502952576, loss=0.6014201045036316
test: epoch 127, loss 1.782907485961914, acc=0.41111111640930176, loss=1.782907485961914
train: epoch 128, loss 0.5921531319618225, acc=0.7331666946411133, loss=0.5921531319618225
test: epoch 128, loss 1.6937106847763062, acc=0.41111111640930176, loss=1.6937106847763062
train: epoch 129, loss 0.5952115654945374, acc=0.7315555810928345, loss=0.5952115654945374
test: epoch 129, loss 1.6716639995574951, acc=0.4138889014720917, loss=1.6716639995574951
train: epoch 130, loss 0.585307240486145, acc=0.7342222332954407, loss=0.585307240486145
test: epoch 130, loss 1.70535147190094, acc=0.4166666567325592, loss=1.70535147190094
train: epoch 131, loss 0.6011622548103333, acc=0.7365000247955322, loss=0.6011622548103333
test: epoch 131, loss 1.8349599838256836, acc=0.3888888955116272, loss=1.8349599838256836
train: epoch 132, loss 0.5955424308776855, acc=0.7347221970558167, loss=0.5955424308776855
test: epoch 132, loss 1.7318780422210693, acc=0.4138889014720917, loss=1.7318780422210693
train: epoch 133, loss 0.5942655801773071, acc=0.7343888878822327, loss=0.5942655801773071
test: epoch 133, loss 1.7438409328460693, acc=0.4194444417953491, loss=1.7438409328460693
train: epoch 134, loss 0.5917968153953552, acc=0.7328333258628845, loss=0.5917968153953552
test: epoch 134, loss 1.7090858221054077, acc=0.41111111640930176, loss=1.7090858221054077
train: epoch 135, loss 0.5991783142089844, acc=0.73416668176651, loss=0.5991783142089844
test: epoch 135, loss 1.5664905309677124, acc=0.39444443583488464, loss=1.5664905309677124
train: epoch 136, loss 0.5923847556114197, acc=0.7331110835075378, loss=0.5923847556114197
test: epoch 136, loss 1.6438063383102417, acc=0.4138889014720917, loss=1.6438063383102417
train: epoch 137, loss 0.5787250399589539, acc=0.7384999990463257, loss=0.5787250399589539
test: epoch 137, loss 1.6218675374984741, acc=0.4194444417953491, loss=1.6218675374984741
train: epoch 138, loss 0.5782840847969055, acc=0.742222249507904, loss=0.5782840847969055
test: epoch 138, loss 1.784226655960083, acc=0.4194444417953491, loss=1.784226655960083
train: epoch 139, loss 0.5813241600990295, acc=0.741777777671814, loss=0.5813241600990295
test: epoch 139, loss 1.5967642068862915, acc=0.42500001192092896, loss=1.5967642068862915
train: epoch 140, loss 0.58475261926651, acc=0.7390555739402771, loss=0.58475261926651
test: epoch 140, loss 1.8512837886810303, acc=0.4277777671813965, loss=1.8512837886810303
train: epoch 141, loss 0.5786545872688293, acc=0.7416666746139526, loss=0.5786545872688293
test: epoch 141, loss 1.562722086906433, acc=0.42500001192092896, loss=1.562722086906433
train: epoch 142, loss 0.5913721919059753, acc=0.737500011920929, loss=0.5913721919059753
test: epoch 142, loss 1.6711372137069702, acc=0.42222222685813904, loss=1.6711372137069702
train: epoch 143, loss 0.5807598829269409, acc=0.7366111278533936, loss=0.5807598829269409
test: epoch 143, loss 1.6400243043899536, acc=0.4277777671813965, loss=1.6400243043899536
train: epoch 144, loss 0.5743013620376587, acc=0.7415555715560913, loss=0.5743013620376587
test: epoch 144, loss 1.6545051336288452, acc=0.42500001192092896, loss=1.6545051336288452
train: epoch 145, loss 0.5736380815505981, acc=0.7415000200271606, loss=0.5736380815505981
test: epoch 145, loss 1.6196376085281372, acc=0.4305555522441864, loss=1.6196376085281372
train: epoch 146, loss 0.5663145184516907, acc=0.7426111102104187, loss=0.5663145184516907
test: epoch 146, loss 1.697411298751831, acc=0.42500001192092896, loss=1.697411298751831
train: epoch 147, loss 0.578255295753479, acc=0.7409444451332092, loss=0.578255295753479
test: epoch 147, loss 1.8171204328536987, acc=0.4138889014720917, loss=1.8171204328536987
train: epoch 148, loss 0.5827611684799194, acc=0.7412222027778625, loss=0.5827611684799194
test: epoch 148, loss 1.6504181623458862, acc=0.4166666567325592, loss=1.6504181623458862
train: epoch 149, loss 0.5805210471153259, acc=0.7402777671813965, loss=0.5805210471153259
test: epoch 149, loss 1.69511079788208, acc=0.4305555522441864, loss=1.69511079788208
train: epoch 150, loss 0.5980114936828613, acc=0.7417222261428833, loss=0.5980114936828613
test: epoch 150, loss 1.8362417221069336, acc=0.4305555522441864, loss=1.8362417221069336
