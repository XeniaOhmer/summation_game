# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=1.5", "--temp_decay=1", "--one_hot=1", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=463662448, receiver_embed_dim=32, save_run=0, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=463662448, receiver_embed_dim=32, save_run=False, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.3929715156555176, acc=0.05394444614648819, loss=3.3929715156555176
test: epoch 1, loss 3.601388931274414, acc=0.07222222536802292, loss=3.601388931274414
train: epoch 2, loss 2.3568379878997803, acc=0.1901666671037674, loss=2.3568379878997803
test: epoch 2, loss 2.778468132019043, acc=0.13055555522441864, loss=2.778468132019043
train: epoch 3, loss 1.8056391477584839, acc=0.30505555868148804, loss=1.8056391477584839
test: epoch 3, loss 2.6293728351593018, acc=0.1388888955116272, loss=2.6293728351593018
train: epoch 4, loss 1.5892847776412964, acc=0.3718888759613037, loss=1.5892847776412964
test: epoch 4, loss 2.839108943939209, acc=0.15000000596046448, loss=2.839108943939209
train: epoch 5, loss 1.4553457498550415, acc=0.42222222685813904, loss=1.4553457498550415
test: epoch 5, loss 2.8706917762756348, acc=0.14722222089767456, loss=2.8706917762756348
train: epoch 6, loss 1.3448423147201538, acc=0.4692777693271637, loss=1.3448423147201538
test: epoch 6, loss 2.809715747833252, acc=0.14722222089767456, loss=2.809715747833252
train: epoch 7, loss 1.2596291303634644, acc=0.5041666626930237, loss=1.2596291303634644
test: epoch 7, loss 3.0422017574310303, acc=0.15000000596046448, loss=3.0422017574310303
train: epoch 8, loss 1.2117729187011719, acc=0.5292778015136719, loss=1.2117729187011719
test: epoch 8, loss 2.9594473838806152, acc=0.16111111640930176, loss=2.9594473838806152
train: epoch 9, loss 1.1445250511169434, acc=0.5497778058052063, loss=1.1445250511169434
test: epoch 9, loss 3.0306899547576904, acc=0.17499999701976776, loss=3.0306899547576904
train: epoch 10, loss 1.1005375385284424, acc=0.57105553150177, loss=1.1005375385284424
test: epoch 10, loss 2.9190871715545654, acc=0.18333333730697632, loss=2.9190871715545654
train: epoch 11, loss 1.056848406791687, acc=0.5909444689750671, loss=1.056848406791687
test: epoch 11, loss 2.915614128112793, acc=0.16388888657093048, loss=2.915614128112793
train: epoch 12, loss 1.0090783834457397, acc=0.6116666793823242, loss=1.0090783834457397
test: epoch 12, loss 2.910325288772583, acc=0.17777778208255768, loss=2.910325288772583
train: epoch 13, loss 0.9747664928436279, acc=0.6301666498184204, loss=0.9747664928436279
test: epoch 13, loss 3.0349817276000977, acc=0.18888889253139496, loss=3.0349817276000977
train: epoch 14, loss 0.9458232522010803, acc=0.6412777900695801, loss=0.9458232522010803
test: epoch 14, loss 2.848712921142578, acc=0.1944444477558136, loss=2.848712921142578
train: epoch 15, loss 0.8933247327804565, acc=0.6608333587646484, loss=0.8933247327804565
test: epoch 15, loss 2.791144609451294, acc=0.2083333283662796, loss=2.791144609451294
train: epoch 16, loss 0.8801103830337524, acc=0.6696666479110718, loss=0.8801103830337524
test: epoch 16, loss 2.82419490814209, acc=0.2222222238779068, loss=2.82419490814209
train: epoch 17, loss 0.852744996547699, acc=0.680055558681488, loss=0.852744996547699
test: epoch 17, loss 2.748494863510132, acc=0.2222222238779068, loss=2.748494863510132
train: epoch 18, loss 0.8232318758964539, acc=0.6947222352027893, loss=0.8232318758964539
test: epoch 18, loss 2.6257858276367188, acc=0.21666666865348816, loss=2.6257858276367188
train: epoch 19, loss 0.7848462462425232, acc=0.7119444608688354, loss=0.7848462462425232
test: epoch 19, loss 2.6210758686065674, acc=0.21944443881511688, loss=2.6210758686065674
train: epoch 20, loss 0.763042688369751, acc=0.7149444222450256, loss=0.763042688369751
test: epoch 20, loss 2.6753504276275635, acc=0.23333333432674408, loss=2.6753504276275635
train: epoch 21, loss 0.7495554089546204, acc=0.7221111059188843, loss=0.7495554089546204
test: epoch 21, loss 2.524174451828003, acc=0.25555557012557983, loss=2.524174451828003
train: epoch 22, loss 0.7376993894577026, acc=0.7239444255828857, loss=0.7376993894577026
test: epoch 22, loss 2.423941135406494, acc=0.25833332538604736, loss=2.423941135406494
train: epoch 23, loss 0.7179617285728455, acc=0.7356666922569275, loss=0.7179617285728455
test: epoch 23, loss 2.4645776748657227, acc=0.22499999403953552, loss=2.4645776748657227
train: epoch 24, loss 0.7016175389289856, acc=0.741777777671814, loss=0.7016175389289856
test: epoch 24, loss 2.5134546756744385, acc=0.2222222238779068, loss=2.5134546756744385
train: epoch 25, loss 0.6840784549713135, acc=0.7481111288070679, loss=0.6840784549713135
test: epoch 25, loss 2.7295455932617188, acc=0.2750000059604645, loss=2.7295455932617188
train: epoch 26, loss 0.6505953669548035, acc=0.7645000219345093, loss=0.6505953669548035
test: epoch 26, loss 2.4781079292297363, acc=0.26944443583488464, loss=2.4781079292297363
train: epoch 27, loss 0.6516080498695374, acc=0.7616111040115356, loss=0.6516080498695374
test: epoch 27, loss 2.422053813934326, acc=0.3166666626930237, loss=2.422053813934326
train: epoch 28, loss 0.6305738687515259, acc=0.7686111330986023, loss=0.6305738687515259
test: epoch 28, loss 2.2568535804748535, acc=0.29722222685813904, loss=2.2568535804748535
train: epoch 29, loss 0.6216472387313843, acc=0.7773333191871643, loss=0.6216472387313843
test: epoch 29, loss 2.279573678970337, acc=0.2805555462837219, loss=2.279573678970337
train: epoch 30, loss 0.6041728854179382, acc=0.7819444537162781, loss=0.6041728854179382
test: epoch 30, loss 2.3550639152526855, acc=0.2777777910232544, loss=2.3550639152526855
train: epoch 31, loss 0.5878681540489197, acc=0.7896666526794434, loss=0.5878681540489197
test: epoch 31, loss 2.2321243286132812, acc=0.30000001192092896, loss=2.2321243286132812
train: epoch 32, loss 0.5754342079162598, acc=0.7932778000831604, loss=0.5754342079162598
test: epoch 32, loss 2.292612075805664, acc=0.2638888955116272, loss=2.292612075805664
train: epoch 33, loss 0.5697075724601746, acc=0.7982222437858582, loss=0.5697075724601746
test: epoch 33, loss 2.153099298477173, acc=0.27222222089767456, loss=2.153099298477173
train: epoch 34, loss 0.5566219091415405, acc=0.8034999966621399, loss=0.5566219091415405
test: epoch 34, loss 2.131671905517578, acc=0.30000001192092896, loss=2.131671905517578
train: epoch 35, loss 0.5432918071746826, acc=0.8067777752876282, loss=0.5432918071746826
test: epoch 35, loss 1.9934035539627075, acc=0.28611111640930176, loss=1.9934035539627075
train: epoch 36, loss 0.5365011096000671, acc=0.8097777962684631, loss=0.5365011096000671
test: epoch 36, loss 1.9982836246490479, acc=0.3305555582046509, loss=1.9982836246490479
train: epoch 37, loss 0.5243673324584961, acc=0.8130000233650208, loss=0.5243673324584961
test: epoch 37, loss 1.8424605131149292, acc=0.29722222685813904, loss=1.8424605131149292
train: epoch 38, loss 0.5057916641235352, acc=0.8221666812896729, loss=0.5057916641235352
test: epoch 38, loss 1.9840444326400757, acc=0.31388887763023376, loss=1.9840444326400757
train: epoch 39, loss 0.49786069989204407, acc=0.8260555267333984, loss=0.49786069989204407
test: epoch 39, loss 2.0432939529418945, acc=0.32777777314186096, loss=2.0432939529418945
train: epoch 40, loss 0.48764917254447937, acc=0.8331666588783264, loss=0.48764917254447937
test: epoch 40, loss 2.038985252380371, acc=0.2611111104488373, loss=2.038985252380371
train: epoch 41, loss 0.486806720495224, acc=0.832111120223999, loss=0.486806720495224
test: epoch 41, loss 2.0907833576202393, acc=0.3333333432674408, loss=2.0907833576202393
train: epoch 42, loss 0.47495901584625244, acc=0.8327222466468811, loss=0.47495901584625244
test: epoch 42, loss 1.9691449403762817, acc=0.3333333432674408, loss=1.9691449403762817
train: epoch 43, loss 0.45556190609931946, acc=0.8398333191871643, loss=0.45556190609931946
test: epoch 43, loss 2.0369436740875244, acc=0.29722222685813904, loss=2.0369436740875244
train: epoch 44, loss 0.4508470594882965, acc=0.8390555381774902, loss=0.4508470594882965
test: epoch 44, loss 1.8749812841415405, acc=0.3305555582046509, loss=1.8749812841415405
train: epoch 45, loss 0.42969056963920593, acc=0.8488333225250244, loss=0.42969056963920593
test: epoch 45, loss 1.6517137289047241, acc=0.42222222685813904, loss=1.6517137289047241
train: epoch 46, loss 0.43912434577941895, acc=0.8518333435058594, loss=0.43912434577941895
test: epoch 46, loss 1.854089379310608, acc=0.3611111044883728, loss=1.854089379310608
train: epoch 47, loss 0.42476701736450195, acc=0.8500000238418579, loss=0.42476701736450195
test: epoch 47, loss 2.059256076812744, acc=0.32777777314186096, loss=2.059256076812744
train: epoch 48, loss 0.4223240613937378, acc=0.8554444313049316, loss=0.4223240613937378
test: epoch 48, loss 1.9001672267913818, acc=0.34166666865348816, loss=1.9001672267913818
train: epoch 49, loss 0.41384270787239075, acc=0.8589444160461426, loss=0.41384270787239075
test: epoch 49, loss 1.8708140850067139, acc=0.3444444537162781, loss=1.8708140850067139
train: epoch 50, loss 0.4081861078739166, acc=0.8602222204208374, loss=0.4081861078739166
test: epoch 50, loss 1.7749760150909424, acc=0.4027777910232544, loss=1.7749760150909424
train: epoch 51, loss 0.39611753821372986, acc=0.8650555610656738, loss=0.39611753821372986
test: epoch 51, loss 1.8812683820724487, acc=0.3499999940395355, loss=1.8812683820724487
train: epoch 52, loss 0.39890334010124207, acc=0.8596110939979553, loss=0.39890334010124207
test: epoch 52, loss 1.9471409320831299, acc=0.3777777850627899, loss=1.9471409320831299
train: epoch 53, loss 0.38135474920272827, acc=0.8681666851043701, loss=0.38135474920272827
test: epoch 53, loss 1.9333086013793945, acc=0.3583333194255829, loss=1.9333086013793945
train: epoch 54, loss 0.3710022568702698, acc=0.8736666440963745, loss=0.3710022568702698
test: epoch 54, loss 2.0856645107269287, acc=0.32499998807907104, loss=2.0856645107269287
train: epoch 55, loss 0.36486387252807617, acc=0.8723333477973938, loss=0.36486387252807617
test: epoch 55, loss 1.9996904134750366, acc=0.3638888895511627, loss=1.9996904134750366
train: epoch 56, loss 0.3689408004283905, acc=0.8738889098167419, loss=0.3689408004283905
test: epoch 56, loss 1.9388478994369507, acc=0.4000000059604645, loss=1.9388478994369507
train: epoch 57, loss 0.3582342565059662, acc=0.8759999871253967, loss=0.3582342565059662
test: epoch 57, loss 2.035956859588623, acc=0.38333332538604736, loss=2.035956859588623
train: epoch 58, loss 0.3591761589050293, acc=0.8763333559036255, loss=0.3591761589050293
test: epoch 58, loss 1.8002216815948486, acc=0.3861111104488373, loss=1.8002216815948486
train: epoch 59, loss 0.3477019965648651, acc=0.878944456577301, loss=0.3477019965648651
test: epoch 59, loss 1.8498369455337524, acc=0.36666667461395264, loss=1.8498369455337524
train: epoch 60, loss 0.34425923228263855, acc=0.8848888874053955, loss=0.34425923228263855
test: epoch 60, loss 1.6374987363815308, acc=0.40833333134651184, loss=1.6374987363815308
train: epoch 61, loss 0.3291803002357483, acc=0.8871111273765564, loss=0.3291803002357483
test: epoch 61, loss 1.8831485509872437, acc=0.38055557012557983, loss=1.8831485509872437
train: epoch 62, loss 0.3311319053173065, acc=0.8876110911369324, loss=0.3311319053173065
test: epoch 62, loss 1.8830569982528687, acc=0.38055557012557983, loss=1.8830569982528687
train: epoch 63, loss 0.32292163372039795, acc=0.8912222385406494, loss=0.32292163372039795
test: epoch 63, loss 2.0965473651885986, acc=0.35277777910232544, loss=2.0965473651885986
train: epoch 64, loss 0.32162731885910034, acc=0.8924444317817688, loss=0.32162731885910034
test: epoch 64, loss 1.9283872842788696, acc=0.3861111104488373, loss=1.9283872842788696
train: epoch 65, loss 0.3145369291305542, acc=0.8961111307144165, loss=0.3145369291305542
test: epoch 65, loss 1.8318203687667847, acc=0.3722222149372101, loss=1.8318203687667847
train: epoch 66, loss 0.3126979470252991, acc=0.8958888649940491, loss=0.3126979470252991
test: epoch 66, loss 1.7917386293411255, acc=0.3888888955116272, loss=1.7917386293411255
train: epoch 67, loss 0.3143557906150818, acc=0.8911111354827881, loss=0.3143557906150818
test: epoch 67, loss 1.7934489250183105, acc=0.40833333134651184, loss=1.7934489250183105
train: epoch 68, loss 0.2949976325035095, acc=0.897777795791626, loss=0.2949976325035095
test: epoch 68, loss 1.9793274402618408, acc=0.38333332538604736, loss=1.9793274402618408
train: epoch 69, loss 0.29088151454925537, acc=0.9035555720329285, loss=0.29088151454925537
test: epoch 69, loss 1.849759578704834, acc=0.39444443583488464, loss=1.849759578704834
train: epoch 70, loss 0.29303091764450073, acc=0.8997777700424194, loss=0.29303091764450073
test: epoch 70, loss 2.0176737308502197, acc=0.4138889014720917, loss=2.0176737308502197
train: epoch 71, loss 0.2863363027572632, acc=0.9051111340522766, loss=0.2863363027572632
test: epoch 71, loss 1.812486171722412, acc=0.43888887763023376, loss=1.812486171722412
train: epoch 72, loss 0.29084131121635437, acc=0.9026111364364624, loss=0.29084131121635437
test: epoch 72, loss 1.699103832244873, acc=0.4000000059604645, loss=1.699103832244873
train: epoch 73, loss 0.27190372347831726, acc=0.9082777500152588, loss=0.27190372347831726
test: epoch 73, loss 1.890989065170288, acc=0.3722222149372101, loss=1.890989065170288
train: epoch 74, loss 0.280128538608551, acc=0.9069444537162781, loss=0.280128538608551
test: epoch 74, loss 1.6512579917907715, acc=0.4166666567325592, loss=1.6512579917907715
train: epoch 75, loss 0.2670360505580902, acc=0.9113333225250244, loss=0.2670360505580902
test: epoch 75, loss 1.9070405960083008, acc=0.43611112236976624, loss=1.9070405960083008
train: epoch 76, loss 0.2812768518924713, acc=0.9060555696487427, loss=0.2812768518924713
test: epoch 76, loss 1.6845115423202515, acc=0.4416666626930237, loss=1.6845115423202515
train: epoch 77, loss 0.26113802194595337, acc=0.9135000109672546, loss=0.26113802194595337
test: epoch 77, loss 1.6793793439865112, acc=0.4194444417953491, loss=1.6793793439865112
train: epoch 78, loss 0.2688524127006531, acc=0.9132221937179565, loss=0.2688524127006531
test: epoch 78, loss 1.7555392980575562, acc=0.4194444417953491, loss=1.7555392980575562
train: epoch 79, loss 0.2523807883262634, acc=0.9158889055252075, loss=0.2523807883262634
test: epoch 79, loss 1.6332660913467407, acc=0.45277777314186096, loss=1.6332660913467407
train: epoch 80, loss 0.24966390430927277, acc=0.9141666889190674, loss=0.24966390430927277
test: epoch 80, loss 1.6630938053131104, acc=0.4555555582046509, loss=1.6630938053131104
train: epoch 81, loss 0.2583240568637848, acc=0.9128888845443726, loss=0.2583240568637848
test: epoch 81, loss 1.5252773761749268, acc=0.47777777910232544, loss=1.5252773761749268
train: epoch 82, loss 0.27241528034210205, acc=0.9137222170829773, loss=0.27241528034210205
test: epoch 82, loss 2.1338212490081787, acc=0.4027777910232544, loss=2.1338212490081787
train: epoch 83, loss 0.24909164011478424, acc=0.9212222099304199, loss=0.24909164011478424
test: epoch 83, loss 1.6842314004898071, acc=0.43611112236976624, loss=1.6842314004898071
train: epoch 84, loss 0.2281619906425476, acc=0.9238333106040955, loss=0.2281619906425476
test: epoch 84, loss 1.5948480367660522, acc=0.4888888895511627, loss=1.5948480367660522
train: epoch 85, loss 0.2428189367055893, acc=0.9196110963821411, loss=0.2428189367055893
test: epoch 85, loss 1.6478359699249268, acc=0.43611112236976624, loss=1.6478359699249268
train: epoch 86, loss 0.23457574844360352, acc=0.9230555295944214, loss=0.23457574844360352
test: epoch 86, loss 1.553233027458191, acc=0.4583333432674408, loss=1.553233027458191
train: epoch 87, loss 0.2291174679994583, acc=0.9232777953147888, loss=0.2291174679994583
test: epoch 87, loss 1.8175700902938843, acc=0.44999998807907104, loss=1.8175700902938843
train: epoch 88, loss 0.24520649015903473, acc=0.921999990940094, loss=0.24520649015903473
test: epoch 88, loss 1.6087850332260132, acc=0.5138888955116272, loss=1.6087850332260132
train: epoch 89, loss 0.22927691042423248, acc=0.9218888878822327, loss=0.22927691042423248
test: epoch 89, loss 1.8093136548995972, acc=0.4888888895511627, loss=1.8093136548995972
train: epoch 90, loss 0.22839350998401642, acc=0.9243888854980469, loss=0.22839350998401642
test: epoch 90, loss 1.6184909343719482, acc=0.47777777910232544, loss=1.6184909343719482
train: epoch 91, loss 0.2166142612695694, acc=0.9267777800559998, loss=0.2166142612695694
test: epoch 91, loss 1.5864875316619873, acc=0.5083333253860474, loss=1.5864875316619873
train: epoch 92, loss 0.22053876519203186, acc=0.9272222518920898, loss=0.22053876519203186
test: epoch 92, loss 1.5165785551071167, acc=0.5222222208976746, loss=1.5165785551071167
train: epoch 93, loss 0.2101789116859436, acc=0.9284999966621399, loss=0.2101789116859436
test: epoch 93, loss 1.6880344152450562, acc=0.46666666865348816, loss=1.6880344152450562
train: epoch 94, loss 0.20441706478595734, acc=0.9304999709129333, loss=0.20441706478595734
test: epoch 94, loss 1.725539207458496, acc=0.4472222328186035, loss=1.725539207458496
train: epoch 95, loss 0.21107342839241028, acc=0.929722249507904, loss=0.21107342839241028
test: epoch 95, loss 1.7177139520645142, acc=0.4611110985279083, loss=1.7177139520645142
train: epoch 96, loss 0.20060449838638306, acc=0.9324444532394409, loss=0.20060449838638306
test: epoch 96, loss 1.7326226234436035, acc=0.47777777910232544, loss=1.7326226234436035
train: epoch 97, loss 0.21547237038612366, acc=0.9267777800559998, loss=0.21547237038612366
test: epoch 97, loss 1.5712251663208008, acc=0.4861111044883728, loss=1.5712251663208008
train: epoch 98, loss 0.20808099210262299, acc=0.9316111207008362, loss=0.20808099210262299
test: epoch 98, loss 1.6363564729690552, acc=0.4972222149372101, loss=1.6363564729690552
train: epoch 99, loss 0.19840258359909058, acc=0.9322777986526489, loss=0.19840258359909058
test: epoch 99, loss 1.6973216533660889, acc=0.5277777910232544, loss=1.6973216533660889
train: epoch 100, loss 0.20322144031524658, acc=0.9339444637298584, loss=0.20322144031524658
test: epoch 100, loss 1.5077462196350098, acc=0.5361111164093018, loss=1.5077462196350098
train: epoch 101, loss 0.20607346296310425, acc=0.9309999942779541, loss=0.20607346296310425
test: epoch 101, loss 1.71474289894104, acc=0.4888888895511627, loss=1.71474289894104
train: epoch 102, loss 0.1936884969472885, acc=0.9344444274902344, loss=0.1936884969472885
test: epoch 102, loss 1.7242070436477661, acc=0.5444444417953491, loss=1.7242070436477661
train: epoch 103, loss 0.18280720710754395, acc=0.9373888969421387, loss=0.18280720710754395
test: epoch 103, loss 1.532968521118164, acc=0.550000011920929, loss=1.532968521118164
train: epoch 104, loss 0.2055874615907669, acc=0.9336666464805603, loss=0.2055874615907669
test: epoch 104, loss 1.780922532081604, acc=0.5055555701255798, loss=1.780922532081604
train: epoch 105, loss 0.18615373969078064, acc=0.9387778043746948, loss=0.18615373969078064
test: epoch 105, loss 1.707759976387024, acc=0.5027777552604675, loss=1.707759976387024
train: epoch 106, loss 0.18964318931102753, acc=0.9379444718360901, loss=0.18964318931102753
test: epoch 106, loss 1.6166609525680542, acc=0.5333333611488342, loss=1.6166609525680542
train: epoch 107, loss 0.18781152367591858, acc=0.9367222189903259, loss=0.18781152367591858
test: epoch 107, loss 1.52335786819458, acc=0.5083333253860474, loss=1.52335786819458
train: epoch 108, loss 0.1982133537530899, acc=0.9352222084999084, loss=0.1982133537530899
test: epoch 108, loss 1.5158441066741943, acc=0.5583333373069763, loss=1.5158441066741943
train: epoch 109, loss 0.18430787324905396, acc=0.9384444355964661, loss=0.18430787324905396
test: epoch 109, loss 1.7480119466781616, acc=0.5055555701255798, loss=1.7480119466781616
train: epoch 110, loss 0.18841612339019775, acc=0.9402777552604675, loss=0.18841612339019775
test: epoch 110, loss 1.5338953733444214, acc=0.5416666865348816, loss=1.5338953733444214
train: epoch 111, loss 0.1796933263540268, acc=0.9411110877990723, loss=0.1796933263540268
test: epoch 111, loss 1.557916283607483, acc=0.550000011920929, loss=1.557916283607483
train: epoch 112, loss 0.17867155373096466, acc=0.9389444589614868, loss=0.17867155373096466
test: epoch 112, loss 1.4965236186981201, acc=0.5333333611488342, loss=1.4965236186981201
train: epoch 113, loss 0.18870213627815247, acc=0.9403333067893982, loss=0.18870213627815247
test: epoch 113, loss 1.6904475688934326, acc=0.4833333194255829, loss=1.6904475688934326
train: epoch 114, loss 0.1778368204832077, acc=0.9403333067893982, loss=0.1778368204832077
test: epoch 114, loss 1.2902313470840454, acc=0.5611110925674438, loss=1.2902313470840454
train: epoch 115, loss 0.16901735961437225, acc=0.9440000057220459, loss=0.16901735961437225
test: epoch 115, loss 1.5732303857803345, acc=0.550000011920929, loss=1.5732303857803345
train: epoch 116, loss 0.18855758011341095, acc=0.9390000104904175, loss=0.18855758011341095
test: epoch 116, loss 1.503475308418274, acc=0.5, loss=1.503475308418274
train: epoch 117, loss 0.1699172705411911, acc=0.9430000185966492, loss=0.1699172705411911
test: epoch 117, loss 1.5046451091766357, acc=0.5222222208976746, loss=1.5046451091766357
train: epoch 118, loss 0.17578357458114624, acc=0.9439444541931152, loss=0.17578357458114624
test: epoch 118, loss 1.3114652633666992, acc=0.550000011920929, loss=1.3114652633666992
train: epoch 119, loss 0.17456978559494019, acc=0.9422777891159058, loss=0.17456978559494019
test: epoch 119, loss 1.510745644569397, acc=0.5638889074325562, loss=1.510745644569397
train: epoch 120, loss 0.164963036775589, acc=0.9430000185966492, loss=0.164963036775589
test: epoch 120, loss 1.3447235822677612, acc=0.5833333134651184, loss=1.3447235822677612
train: epoch 121, loss 0.17478756606578827, acc=0.9441666603088379, loss=0.17478756606578827
test: epoch 121, loss 1.72371506690979, acc=0.5333333611488342, loss=1.72371506690979
train: epoch 122, loss 0.1685566008090973, acc=0.9436110854148865, loss=0.1685566008090973
test: epoch 122, loss 1.3920847177505493, acc=0.550000011920929, loss=1.3920847177505493
train: epoch 123, loss 0.15945973992347717, acc=0.9463333487510681, loss=0.15945973992347717
test: epoch 123, loss 1.6439907550811768, acc=0.5861111283302307, loss=1.6439907550811768
train: epoch 124, loss 0.16306154429912567, acc=0.9459999799728394, loss=0.16306154429912567
test: epoch 124, loss 1.432117223739624, acc=0.5416666865348816, loss=1.432117223739624
train: epoch 125, loss 0.1436997503042221, acc=0.9525555372238159, loss=0.1436997503042221
test: epoch 125, loss 1.3463211059570312, acc=0.5555555820465088, loss=1.3463211059570312
train: epoch 126, loss 0.16523250937461853, acc=0.9459999799728394, loss=0.16523250937461853
test: epoch 126, loss 1.2981992959976196, acc=0.5527777671813965, loss=1.2981992959976196
train: epoch 127, loss 0.14779658615589142, acc=0.9512222409248352, loss=0.14779658615589142
test: epoch 127, loss 1.2719151973724365, acc=0.5694444179534912, loss=1.2719151973724365
train: epoch 128, loss 0.1644238978624344, acc=0.9472222328186035, loss=0.1644238978624344
test: epoch 128, loss 1.2396621704101562, acc=0.5916666388511658, loss=1.2396621704101562
train: epoch 129, loss 0.13745202124118805, acc=0.9524999856948853, loss=0.13745202124118805
test: epoch 129, loss 1.363776683807373, acc=0.5833333134651184, loss=1.363776683807373
train: epoch 130, loss 0.1461901068687439, acc=0.9526666402816772, loss=0.1461901068687439
test: epoch 130, loss 1.4055776596069336, acc=0.5472221970558167, loss=1.4055776596069336
train: epoch 131, loss 0.14246216416358948, acc=0.9531111121177673, loss=0.14246216416358948
test: epoch 131, loss 1.333533763885498, acc=0.5722222328186035, loss=1.333533763885498
train: epoch 132, loss 0.1443989872932434, acc=0.9532777667045593, loss=0.1443989872932434
test: epoch 132, loss 1.348583698272705, acc=0.5555555820465088, loss=1.348583698272705
train: epoch 133, loss 0.13673526048660278, acc=0.9543333053588867, loss=0.13673526048660278
test: epoch 133, loss 1.3317152261734009, acc=0.6027777791023254, loss=1.3317152261734009
train: epoch 134, loss 0.1466589868068695, acc=0.9533888697624207, loss=0.1466589868068695
test: epoch 134, loss 1.2075484991073608, acc=0.5638889074325562, loss=1.2075484991073608
train: epoch 135, loss 0.14697504043579102, acc=0.952833354473114, loss=0.14697504043579102
test: epoch 135, loss 1.4097322225570679, acc=0.5472221970558167, loss=1.4097322225570679
train: epoch 136, loss 0.138825461268425, acc=0.9561111330986023, loss=0.138825461268425
test: epoch 136, loss 1.2191112041473389, acc=0.5722222328186035, loss=1.2191112041473389
train: epoch 137, loss 0.13974213600158691, acc=0.9551666378974915, loss=0.13974213600158691
test: epoch 137, loss 1.3764005899429321, acc=0.6027777791023254, loss=1.3764005899429321
train: epoch 138, loss 0.1324169635772705, acc=0.9566666483879089, loss=0.1324169635772705
test: epoch 138, loss 1.3056490421295166, acc=0.5833333134651184, loss=1.3056490421295166
train: epoch 139, loss 0.12296786159276962, acc=0.9583333134651184, loss=0.12296786159276962
test: epoch 139, loss 1.1841506958007812, acc=0.6138888597488403, loss=1.1841506958007812
train: epoch 140, loss 0.13588139414787292, acc=0.9570555686950684, loss=0.13588139414787292
test: epoch 140, loss 1.289364218711853, acc=0.6222222447395325, loss=1.289364218711853
train: epoch 141, loss 0.13581734895706177, acc=0.9553333520889282, loss=0.13581734895706177
test: epoch 141, loss 1.5299092531204224, acc=0.5638889074325562, loss=1.5299092531204224
train: epoch 142, loss 0.12652930617332458, acc=0.9567221999168396, loss=0.12652930617332458
test: epoch 142, loss 1.3075029850006104, acc=0.5916666388511658, loss=1.3075029850006104
train: epoch 143, loss 0.1406882405281067, acc=0.9556111097335815, loss=0.1406882405281067
test: epoch 143, loss 1.1754122972488403, acc=0.6222222447395325, loss=1.1754122972488403
train: epoch 144, loss 0.12782423198223114, acc=0.9567221999168396, loss=0.12782423198223114
test: epoch 144, loss 1.161947250366211, acc=0.6027777791023254, loss=1.161947250366211
train: epoch 145, loss 0.1251833587884903, acc=0.9580555558204651, loss=0.1251833587884903
test: epoch 145, loss 1.4190508127212524, acc=0.625, loss=1.4190508127212524
train: epoch 146, loss 0.12331438064575195, acc=0.9583333134651184, loss=0.12331438064575195
test: epoch 146, loss 1.1727032661437988, acc=0.6499999761581421, loss=1.1727032661437988
train: epoch 147, loss 0.11978098005056381, acc=0.9590555429458618, loss=0.11978098005056381
test: epoch 147, loss 1.1904014348983765, acc=0.6222222447395325, loss=1.1904014348983765
train: epoch 148, loss 0.11755049973726273, acc=0.9610000252723694, loss=0.11755049973726273
test: epoch 148, loss 1.1215975284576416, acc=0.6583333611488342, loss=1.1215975284576416
train: epoch 149, loss 0.11905095726251602, acc=0.9595000147819519, loss=0.11905095726251602
test: epoch 149, loss 1.2387100458145142, acc=0.6416666507720947, loss=1.2387100458145142
train: epoch 150, loss 0.11963613331317902, acc=0.9592777490615845, loss=0.11963613331317902
test: epoch 150, loss 1.0954771041870117, acc=0.6638888716697693, loss=1.0954771041870117
