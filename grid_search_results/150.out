# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=true", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=2108998027, receiver_embed_dim=128, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.8181769847869873, acc=0.1332777738571167, loss=2.8181769847869873
test: epoch 1, loss 3.141023874282837, acc=0.10555555671453476, loss=3.141023874282837
train: epoch 2, loss 1.4491344690322876, acc=0.3995000123977661, loss=1.4491344690322876
test: epoch 2, loss 3.19952392578125, acc=0.15833333134651184, loss=3.19952392578125
train: epoch 3, loss 1.121968150138855, acc=0.5431666374206543, loss=1.121968150138855
test: epoch 3, loss 3.1543631553649902, acc=0.20000000298023224, loss=3.1543631553649902
train: epoch 4, loss 0.9534456729888916, acc=0.6218888759613037, loss=0.9534456729888916
test: epoch 4, loss 2.81240177154541, acc=0.20555555820465088, loss=2.81240177154541
train: epoch 5, loss 0.8273467421531677, acc=0.6727777719497681, loss=0.8273467421531677
test: epoch 5, loss 2.719423294067383, acc=0.20555555820465088, loss=2.719423294067383
train: epoch 6, loss 0.7358611226081848, acc=0.7141666412353516, loss=0.7358611226081848
test: epoch 6, loss 2.772263288497925, acc=0.20555555820465088, loss=2.772263288497925
train: epoch 7, loss 0.6788760423660278, acc=0.7409444451332092, loss=0.6788760423660278
test: epoch 7, loss 2.442863941192627, acc=0.2666666805744171, loss=2.442863941192627
train: epoch 8, loss 0.6222718358039856, acc=0.7652222514152527, loss=0.6222718358039856
test: epoch 8, loss 2.7872722148895264, acc=0.24722221493721008, loss=2.7872722148895264
train: epoch 9, loss 0.572138786315918, acc=0.7833333611488342, loss=0.572138786315918
test: epoch 9, loss 2.6221823692321777, acc=0.2750000059604645, loss=2.6221823692321777
train: epoch 10, loss 0.535929262638092, acc=0.7976666688919067, loss=0.535929262638092
test: epoch 10, loss 2.7952752113342285, acc=0.2361111044883728, loss=2.7952752113342285
train: epoch 11, loss 0.4911201000213623, acc=0.8172222375869751, loss=0.4911201000213623
test: epoch 11, loss 2.5112156867980957, acc=0.2222222238779068, loss=2.5112156867980957
train: epoch 12, loss 0.46222367882728577, acc=0.8284444212913513, loss=0.46222367882728577
test: epoch 12, loss 2.5067102909088135, acc=0.2888889014720917, loss=2.5067102909088135
train: epoch 13, loss 0.43220841884613037, acc=0.8388333320617676, loss=0.43220841884613037
test: epoch 13, loss 2.4774744510650635, acc=0.2611111104488373, loss=2.4774744510650635
train: epoch 14, loss 0.4146047830581665, acc=0.8492222428321838, loss=0.4146047830581665
test: epoch 14, loss 2.8004543781280518, acc=0.2611111104488373, loss=2.8004543781280518
train: epoch 15, loss 0.38022077083587646, acc=0.8592222332954407, loss=0.38022077083587646
test: epoch 15, loss 2.563520669937134, acc=0.3305555582046509, loss=2.563520669937134
train: epoch 16, loss 0.3748440444469452, acc=0.8624444603919983, loss=0.3748440444469452
test: epoch 16, loss 2.312687635421753, acc=0.33888888359069824, loss=2.312687635421753
train: epoch 17, loss 0.34340038895606995, acc=0.8799999952316284, loss=0.34340038895606995
test: epoch 17, loss 2.448291301727295, acc=0.3222222328186035, loss=2.448291301727295
train: epoch 18, loss 0.327282190322876, acc=0.88355553150177, loss=0.327282190322876
test: epoch 18, loss 2.5521514415740967, acc=0.3194444477558136, loss=2.5521514415740967
train: epoch 19, loss 0.31356436014175415, acc=0.8906111121177673, loss=0.31356436014175415
test: epoch 19, loss 2.2067580223083496, acc=0.3916666805744171, loss=2.2067580223083496
train: epoch 20, loss 0.29120078682899475, acc=0.8984444737434387, loss=0.29120078682899475
test: epoch 20, loss 2.361286163330078, acc=0.33888888359069824, loss=2.361286163330078
train: epoch 21, loss 0.28259408473968506, acc=0.9019444584846497, loss=0.28259408473968506
test: epoch 21, loss 2.2661688327789307, acc=0.3583333194255829, loss=2.2661688327789307
train: epoch 22, loss 0.2638719081878662, acc=0.9098333120346069, loss=0.2638719081878662
test: epoch 22, loss 2.325456142425537, acc=0.3499999940395355, loss=2.325456142425537
train: epoch 23, loss 0.24327027797698975, acc=0.9181110858917236, loss=0.24327027797698975
test: epoch 23, loss 2.528745174407959, acc=0.3305555582046509, loss=2.528745174407959
train: epoch 24, loss 0.23283809423446655, acc=0.9203888773918152, loss=0.23283809423446655
test: epoch 24, loss 2.3413965702056885, acc=0.4055555462837219, loss=2.3413965702056885
train: epoch 25, loss 0.2157377153635025, acc=0.9259999990463257, loss=0.2157377153635025
test: epoch 25, loss 2.3803417682647705, acc=0.3916666805744171, loss=2.3803417682647705
train: epoch 26, loss 0.21121613681316376, acc=0.9291666746139526, loss=0.21121613681316376
test: epoch 26, loss 2.640800952911377, acc=0.375, loss=2.640800952911377
train: epoch 27, loss 0.20777787268161774, acc=0.934166669845581, loss=0.20777787268161774
test: epoch 27, loss 2.439319610595703, acc=0.35555556416511536, loss=2.439319610595703
train: epoch 28, loss 0.18485599756240845, acc=0.9387778043746948, loss=0.18485599756240845
test: epoch 28, loss 2.3636927604675293, acc=0.4000000059604645, loss=2.3636927604675293
train: epoch 29, loss 0.1793377548456192, acc=0.9415555596351624, loss=0.1793377548456192
test: epoch 29, loss 2.1286733150482178, acc=0.4166666567325592, loss=2.1286733150482178
train: epoch 30, loss 0.15615108609199524, acc=0.9466666579246521, loss=0.15615108609199524
test: epoch 30, loss 2.601067066192627, acc=0.4333333373069763, loss=2.601067066192627
train: epoch 31, loss 0.16242621839046478, acc=0.9481666684150696, loss=0.16242621839046478
test: epoch 31, loss 2.217365026473999, acc=0.4166666567325592, loss=2.217365026473999
train: epoch 32, loss 0.16370517015457153, acc=0.9482777714729309, loss=0.16370517015457153
test: epoch 32, loss 2.554291248321533, acc=0.4277777671813965, loss=2.554291248321533
train: epoch 33, loss 0.14300835132598877, acc=0.9549999833106995, loss=0.14300835132598877
test: epoch 33, loss 2.4169774055480957, acc=0.43611112236976624, loss=2.4169774055480957
train: epoch 34, loss 0.16251112520694733, acc=0.948888897895813, loss=0.16251112520694733
test: epoch 34, loss 2.8371798992156982, acc=0.4444444477558136, loss=2.8371798992156982
train: epoch 35, loss 0.1459069848060608, acc=0.9549444317817688, loss=0.1459069848060608
test: epoch 35, loss 2.77241849899292, acc=0.4194444417953491, loss=2.77241849899292
train: epoch 36, loss 0.13412539660930634, acc=0.9573888778686523, loss=0.13412539660930634
test: epoch 36, loss 2.7354531288146973, acc=0.4166666567325592, loss=2.7354531288146973
train: epoch 37, loss 0.13031728565692902, acc=0.9582222104072571, loss=0.13031728565692902
test: epoch 37, loss 2.370272397994995, acc=0.4194444417953491, loss=2.370272397994995
train: epoch 38, loss 0.14180998504161835, acc=0.9568889141082764, loss=0.14180998504161835
test: epoch 38, loss 2.418370008468628, acc=0.4305555522441864, loss=2.418370008468628
train: epoch 39, loss 0.12200742214918137, acc=0.9609444737434387, loss=0.12200742214918137
test: epoch 39, loss 2.3461999893188477, acc=0.45277777314186096, loss=2.3461999893188477
train: epoch 40, loss 0.12348488718271255, acc=0.9627222418785095, loss=0.12348488718271255
test: epoch 40, loss 2.8080196380615234, acc=0.40833333134651184, loss=2.8080196380615234
train: epoch 41, loss 0.11819692701101303, acc=0.9653888940811157, loss=0.11819692701101303
test: epoch 41, loss 2.6906237602233887, acc=0.41111111640930176, loss=2.6906237602233887
train: epoch 42, loss 0.11715062707662582, acc=0.9653888940811157, loss=0.11715062707662582
test: epoch 42, loss 2.9310708045959473, acc=0.4305555522441864, loss=2.9310708045959473
train: epoch 43, loss 0.11700407415628433, acc=0.964388906955719, loss=0.11700407415628433
test: epoch 43, loss 2.8600573539733887, acc=0.4194444417953491, loss=2.8600573539733887
train: epoch 44, loss 0.10731890052556992, acc=0.9687777757644653, loss=0.10731890052556992
test: epoch 44, loss 2.8975298404693604, acc=0.44999998807907104, loss=2.8975298404693604
train: epoch 45, loss 0.1046106368303299, acc=0.9695555567741394, loss=0.1046106368303299
test: epoch 45, loss 2.7022488117218018, acc=0.5166666507720947, loss=2.7022488117218018
train: epoch 46, loss 0.11726649105548859, acc=0.9678888916969299, loss=0.11726649105548859
test: epoch 46, loss 2.373727798461914, acc=0.5083333253860474, loss=2.373727798461914
train: epoch 47, loss 0.09838828444480896, acc=0.9700555801391602, loss=0.09838828444480896
test: epoch 47, loss 2.865290641784668, acc=0.5, loss=2.865290641784668
train: epoch 48, loss 0.09189634770154953, acc=0.9736111164093018, loss=0.09189634770154953
test: epoch 48, loss 2.381453514099121, acc=0.519444465637207, loss=2.381453514099121
train: epoch 49, loss 0.10544251650571823, acc=0.9706666469573975, loss=0.10544251650571823
test: epoch 49, loss 3.3199174404144287, acc=0.4722222089767456, loss=3.3199174404144287
train: epoch 50, loss 0.09126070886850357, acc=0.9725000262260437, loss=0.09126070886850357
test: epoch 50, loss 2.52987003326416, acc=0.5166666507720947, loss=2.52987003326416
train: epoch 51, loss 0.10609456896781921, acc=0.9726666808128357, loss=0.10609456896781921
test: epoch 51, loss 2.4466280937194824, acc=0.5166666507720947, loss=2.4466280937194824
train: epoch 52, loss 0.08783023804426193, acc=0.9747222065925598, loss=0.08783023804426193
test: epoch 52, loss 2.615971088409424, acc=0.49444442987442017, loss=2.615971088409424
train: epoch 53, loss 0.09892494231462479, acc=0.9721666574478149, loss=0.09892494231462479
test: epoch 53, loss 2.617765426635742, acc=0.5138888955116272, loss=2.617765426635742
train: epoch 54, loss 0.09336048364639282, acc=0.9736666679382324, loss=0.09336048364639282
test: epoch 54, loss 2.326648235321045, acc=0.5305555462837219, loss=2.326648235321045
train: epoch 55, loss 0.0819346010684967, acc=0.9776111245155334, loss=0.0819346010684967
test: epoch 55, loss 2.2042346000671387, acc=0.5472221970558167, loss=2.2042346000671387
train: epoch 56, loss 0.0857769027352333, acc=0.9757221937179565, loss=0.0857769027352333
test: epoch 56, loss 2.1075172424316406, acc=0.5305555462837219, loss=2.1075172424316406
train: epoch 57, loss 0.08581859618425369, acc=0.9760555624961853, loss=0.08581859618425369
test: epoch 57, loss 2.451357126235962, acc=0.5277777910232544, loss=2.451357126235962
train: epoch 58, loss 0.08872257173061371, acc=0.9752222299575806, loss=0.08872257173061371
test: epoch 58, loss 2.3885021209716797, acc=0.5277777910232544, loss=2.3885021209716797
train: epoch 59, loss 0.0904245674610138, acc=0.9750555753707886, loss=0.0904245674610138
test: epoch 59, loss 2.0753767490386963, acc=0.5527777671813965, loss=2.0753767490386963
train: epoch 60, loss 0.07245679199695587, acc=0.9792222380638123, loss=0.07245679199695587
test: epoch 60, loss 2.1323275566101074, acc=0.5638889074325562, loss=2.1323275566101074
train: epoch 61, loss 0.09271055459976196, acc=0.9750000238418579, loss=0.09271055459976196
test: epoch 61, loss 2.207287549972534, acc=0.5416666865348816, loss=2.207287549972534
train: epoch 62, loss 0.08916615694761276, acc=0.9748333096504211, loss=0.08916615694761276
test: epoch 62, loss 1.9480597972869873, acc=0.6027777791023254, loss=1.9480597972869873
train: epoch 63, loss 0.07514204829931259, acc=0.9804999828338623, loss=0.07514204829931259
test: epoch 63, loss 2.3237640857696533, acc=0.5249999761581421, loss=2.3237640857696533
train: epoch 64, loss 0.0714489296078682, acc=0.9810555577278137, loss=0.0714489296078682
test: epoch 64, loss 2.080630302429199, acc=0.5972222089767456, loss=2.080630302429199
train: epoch 65, loss 0.0871930718421936, acc=0.9767777919769287, loss=0.0871930718421936
test: epoch 65, loss 2.2086808681488037, acc=0.5666666626930237, loss=2.2086808681488037
train: epoch 66, loss 0.08113233745098114, acc=0.9781110882759094, loss=0.08113233745098114
test: epoch 66, loss 2.1301748752593994, acc=0.574999988079071, loss=2.1301748752593994
train: epoch 67, loss 0.08539386093616486, acc=0.9771111011505127, loss=0.08539386093616486
test: epoch 67, loss 1.909608006477356, acc=0.574999988079071, loss=1.909608006477356
train: epoch 68, loss 0.08940818905830383, acc=0.9748333096504211, loss=0.08940818905830383
test: epoch 68, loss 1.7726130485534668, acc=0.5527777671813965, loss=1.7726130485534668
train: epoch 69, loss 0.07334518432617188, acc=0.980555534362793, loss=0.07334518432617188
test: epoch 69, loss 2.027031660079956, acc=0.6138888597488403, loss=2.027031660079956
train: epoch 70, loss 0.06867104023694992, acc=0.9794999957084656, loss=0.06867104023694992
test: epoch 70, loss 2.0459048748016357, acc=0.6083333492279053, loss=2.0459048748016357
train: epoch 71, loss 0.06897503137588501, acc=0.9807222485542297, loss=0.06897503137588501
test: epoch 71, loss 1.666506290435791, acc=0.644444465637207, loss=1.666506290435791
train: epoch 72, loss 0.07167302817106247, acc=0.980388879776001, loss=0.07167302817106247
test: epoch 72, loss 1.780312180519104, acc=0.6499999761581421, loss=1.780312180519104
train: epoch 73, loss 0.09333979338407516, acc=0.9745000004768372, loss=0.09333979338407516
test: epoch 73, loss 1.9638735055923462, acc=0.6111111044883728, loss=1.9638735055923462
train: epoch 74, loss 0.07942529767751694, acc=0.9792222380638123, loss=0.07942529767751694
test: epoch 74, loss 1.8159217834472656, acc=0.6666666865348816, loss=1.8159217834472656
train: epoch 75, loss 0.06754712015390396, acc=0.9806666374206543, loss=0.06754712015390396
test: epoch 75, loss 1.8497138023376465, acc=0.6333333253860474, loss=1.8497138023376465
train: epoch 76, loss 0.06716861575841904, acc=0.981166660785675, loss=0.06716861575841904
test: epoch 76, loss 2.334604501724243, acc=0.6194444298744202, loss=2.334604501724243
train: epoch 77, loss 0.0812830999493599, acc=0.979888916015625, loss=0.0812830999493599
test: epoch 77, loss 2.4812045097351074, acc=0.5972222089767456, loss=2.4812045097351074
train: epoch 78, loss 0.07292734086513519, acc=0.9795555472373962, loss=0.07292734086513519
test: epoch 78, loss 1.8820041418075562, acc=0.6666666865348816, loss=1.8820041418075562
train: epoch 79, loss 0.07385095208883286, acc=0.9791666865348816, loss=0.07385095208883286
test: epoch 79, loss 2.229357957839966, acc=0.6166666746139526, loss=2.229357957839966
train: epoch 80, loss 0.06807377189397812, acc=0.9810555577278137, loss=0.06807377189397812
test: epoch 80, loss 1.9245047569274902, acc=0.6277777552604675, loss=1.9245047569274902
train: epoch 81, loss 0.08051756769418716, acc=0.9785000085830688, loss=0.08051756769418716
test: epoch 81, loss 1.791457176208496, acc=0.6499999761581421, loss=1.791457176208496
train: epoch 82, loss 0.06883952021598816, acc=0.9801666736602783, loss=0.06883952021598816
test: epoch 82, loss 1.5758699178695679, acc=0.6944444179534912, loss=1.5758699178695679
train: epoch 83, loss 0.06733358651399612, acc=0.981166660785675, loss=0.06733358651399612
test: epoch 83, loss 1.601290225982666, acc=0.6472222208976746, loss=1.601290225982666
train: epoch 84, loss 0.07463855296373367, acc=0.9792777895927429, loss=0.07463855296373367
test: epoch 84, loss 1.7500718832015991, acc=0.6805555820465088, loss=1.7500718832015991
train: epoch 85, loss 0.07673142105340958, acc=0.9788333177566528, loss=0.07673142105340958
test: epoch 85, loss 1.8334503173828125, acc=0.6666666865348816, loss=1.8334503173828125
train: epoch 86, loss 0.07175075262784958, acc=0.9792777895927429, loss=0.07175075262784958
test: epoch 86, loss 1.8099840879440308, acc=0.644444465637207, loss=1.8099840879440308
train: epoch 87, loss 0.06860549002885818, acc=0.9803333282470703, loss=0.06860549002885818
test: epoch 87, loss 1.4390140771865845, acc=0.6972222328186035, loss=1.4390140771865845
train: epoch 88, loss 0.0798443928360939, acc=0.9787777662277222, loss=0.0798443928360939
test: epoch 88, loss 1.5020887851715088, acc=0.6861110925674438, loss=1.5020887851715088
train: epoch 89, loss 0.06726961582899094, acc=0.9815555810928345, loss=0.06726961582899094
test: epoch 89, loss 1.446045160293579, acc=0.7027778029441833, loss=1.446045160293579
train: epoch 90, loss 0.06079067662358284, acc=0.9822221994400024, loss=0.06079067662358284
test: epoch 90, loss 1.4595152139663696, acc=0.6888889074325562, loss=1.4595152139663696
train: epoch 91, loss 0.07317224144935608, acc=0.981333315372467, loss=0.07317224144935608
test: epoch 91, loss 1.5247581005096436, acc=0.6555555462837219, loss=1.5247581005096436
train: epoch 92, loss 0.07757647335529327, acc=0.9804444313049316, loss=0.07757647335529327
test: epoch 92, loss 1.6894463300704956, acc=0.7194444537162781, loss=1.6894463300704956
train: epoch 93, loss 0.07537397742271423, acc=0.9801111221313477, loss=0.07537397742271423
test: epoch 93, loss 1.7423275709152222, acc=0.644444465637207, loss=1.7423275709152222
train: epoch 94, loss 0.07404650747776031, acc=0.9787777662277222, loss=0.07404650747776031
test: epoch 94, loss 1.287607192993164, acc=0.7166666388511658, loss=1.287607192993164
train: epoch 95, loss 0.0709097608923912, acc=0.9823333621025085, loss=0.0709097608923912
test: epoch 95, loss 1.4004442691802979, acc=0.6722221970558167, loss=1.4004442691802979
train: epoch 96, loss 0.06602197885513306, acc=0.9818333387374878, loss=0.06602197885513306
test: epoch 96, loss 1.3961900472640991, acc=0.6861110925674438, loss=1.3961900472640991
train: epoch 97, loss 0.06715410202741623, acc=0.9826666712760925, loss=0.06715410202741623
test: epoch 97, loss 1.6409509181976318, acc=0.7027778029441833, loss=1.6409509181976318
train: epoch 98, loss 0.07587208598852158, acc=0.9792222380638123, loss=0.07587208598852158
test: epoch 98, loss 1.5691555738449097, acc=0.7027778029441833, loss=1.5691555738449097
train: epoch 99, loss 0.06595052778720856, acc=0.9828333258628845, loss=0.06595052778720856
test: epoch 99, loss 1.4603792428970337, acc=0.7083333134651184, loss=1.4603792428970337
train: epoch 100, loss 0.07955467700958252, acc=0.9792222380638123, loss=0.07955467700958252
test: epoch 100, loss 1.2350445985794067, acc=0.7194444537162781, loss=1.2350445985794067
train: epoch 101, loss 0.07478170096874237, acc=0.9783889055252075, loss=0.07478170096874237
test: epoch 101, loss 1.1177071332931519, acc=0.730555534362793, loss=1.1177071332931519
train: epoch 102, loss 0.066910520195961, acc=0.981166660785675, loss=0.066910520195961
test: epoch 102, loss 1.4221150875091553, acc=0.7055555582046509, loss=1.4221150875091553
train: epoch 103, loss 0.0747823715209961, acc=0.9796110987663269, loss=0.0747823715209961
test: epoch 103, loss 1.3681082725524902, acc=0.7194444537162781, loss=1.3681082725524902
train: epoch 104, loss 0.06076505780220032, acc=0.9826111197471619, loss=0.06076505780220032
test: epoch 104, loss 1.283796787261963, acc=0.7138888835906982, loss=1.283796787261963
train: epoch 105, loss 0.065833680331707, acc=0.9807222485542297, loss=0.065833680331707
test: epoch 105, loss 1.174174189567566, acc=0.7444444298744202, loss=1.174174189567566
train: epoch 106, loss 0.062858447432518, acc=0.9836111068725586, loss=0.062858447432518
test: epoch 106, loss 1.32048761844635, acc=0.7333333492279053, loss=1.32048761844635
train: epoch 107, loss 0.06290949881076813, acc=0.9808333516120911, loss=0.06290949881076813
test: epoch 107, loss 1.3204787969589233, acc=0.6777777671813965, loss=1.3204787969589233
train: epoch 108, loss 0.07001618295907974, acc=0.9803333282470703, loss=0.07001618295907974
test: epoch 108, loss 1.2998803853988647, acc=0.7416666746139526, loss=1.2998803853988647
train: epoch 109, loss 0.06905610114336014, acc=0.9798333048820496, loss=0.06905610114336014
test: epoch 109, loss 1.1172047853469849, acc=0.7111111283302307, loss=1.1172047853469849
train: epoch 110, loss 0.06325503438711166, acc=0.9821110963821411, loss=0.06325503438711166
test: epoch 110, loss 1.295400857925415, acc=0.7250000238418579, loss=1.295400857925415
train: epoch 111, loss 0.06941337883472443, acc=0.981333315372467, loss=0.06941337883472443
test: epoch 111, loss 1.0292404890060425, acc=0.7666666507720947, loss=1.0292404890060425
train: epoch 112, loss 0.06448867917060852, acc=0.9820555448532104, loss=0.06448867917060852
test: epoch 112, loss 1.1600401401519775, acc=0.7583333253860474, loss=1.1600401401519775
train: epoch 113, loss 0.06898444890975952, acc=0.980222225189209, loss=0.06898444890975952
test: epoch 113, loss 1.2480990886688232, acc=0.7277777791023254, loss=1.2480990886688232
train: epoch 114, loss 0.06362909823656082, acc=0.9815555810928345, loss=0.06362909823656082
test: epoch 114, loss 0.991840660572052, acc=0.7444444298744202, loss=0.991840660572052
train: epoch 115, loss 0.0651431530714035, acc=0.9824444651603699, loss=0.0651431530714035
test: epoch 115, loss 0.9568912982940674, acc=0.7583333253860474, loss=0.9568912982940674
train: epoch 116, loss 0.07093517482280731, acc=0.9813888669013977, loss=0.07093517482280731
test: epoch 116, loss 1.03729248046875, acc=0.7555555701255798, loss=1.03729248046875
train: epoch 117, loss 0.06357965618371964, acc=0.9819999933242798, loss=0.06357965618371964
test: epoch 117, loss 1.1972987651824951, acc=0.7722222208976746, loss=1.1972987651824951
train: epoch 118, loss 0.06958231329917908, acc=0.979888916015625, loss=0.06958231329917908
test: epoch 118, loss 1.1240828037261963, acc=0.7444444298744202, loss=1.1240828037261963
train: epoch 119, loss 0.06146930903196335, acc=0.9827777743339539, loss=0.06146930903196335
test: epoch 119, loss 1.0515151023864746, acc=0.7777777910232544, loss=1.0515151023864746
train: epoch 120, loss 0.058937665075063705, acc=0.984000027179718, loss=0.058937665075063705
test: epoch 120, loss 1.044551134109497, acc=0.7416666746139526, loss=1.044551134109497
train: epoch 121, loss 0.06492234021425247, acc=0.9825555682182312, loss=0.06492234021425247
test: epoch 121, loss 1.0155589580535889, acc=0.7611111402511597, loss=1.0155589580535889
train: epoch 122, loss 0.05392755568027496, acc=0.9851111173629761, loss=0.05392755568027496
test: epoch 122, loss 1.122517466545105, acc=0.7666666507720947, loss=1.122517466545105
train: epoch 123, loss 0.06615766137838364, acc=0.9821666479110718, loss=0.06615766137838364
test: epoch 123, loss 0.9777572154998779, acc=0.7833333611488342, loss=0.9777572154998779
train: epoch 124, loss 0.06055288016796112, acc=0.984499990940094, loss=0.06055288016796112
test: epoch 124, loss 0.9410102367401123, acc=0.7749999761581421, loss=0.9410102367401123
train: epoch 125, loss 0.06396164745092392, acc=0.9822221994400024, loss=0.06396164745092392
test: epoch 125, loss 0.9722171425819397, acc=0.7944444417953491, loss=0.9722171425819397
train: epoch 126, loss 0.06798159331083298, acc=0.9822777509689331, loss=0.06798159331083298
test: epoch 126, loss 1.044753909111023, acc=0.7861111164093018, loss=1.044753909111023
train: epoch 127, loss 0.07257696986198425, acc=0.9821666479110718, loss=0.07257696986198425
test: epoch 127, loss 0.8970788717269897, acc=0.7916666865348816, loss=0.8970788717269897
train: epoch 128, loss 0.06236860156059265, acc=0.9830555319786072, loss=0.06236860156059265
test: epoch 128, loss 0.8555361032485962, acc=0.8277778029441833, loss=0.8555361032485962
train: epoch 129, loss 0.061286576092243195, acc=0.9823333621025085, loss=0.061286576092243195
test: epoch 129, loss 0.9986921548843384, acc=0.7805555462837219, loss=0.9986921548843384
train: epoch 130, loss 0.0588463619351387, acc=0.9830555319786072, loss=0.0588463619351387
test: epoch 130, loss 0.7757168412208557, acc=0.8222222328186035, loss=0.7757168412208557
train: epoch 131, loss 0.060204483568668365, acc=0.9837777614593506, loss=0.060204483568668365
test: epoch 131, loss 0.7986459136009216, acc=0.8027777671813965, loss=0.7986459136009216
train: epoch 132, loss 0.06664250791072845, acc=0.9834444522857666, loss=0.06664250791072845
test: epoch 132, loss 0.7697877883911133, acc=0.7888888716697693, loss=0.7697877883911133
train: epoch 133, loss 0.06742196530103683, acc=0.9826111197471619, loss=0.06742196530103683
test: epoch 133, loss 0.746089518070221, acc=0.8222222328186035, loss=0.746089518070221
train: epoch 134, loss 0.058156728744506836, acc=0.984666645526886, loss=0.058156728744506836
test: epoch 134, loss 0.6930341720581055, acc=0.8166666626930237, loss=0.6930341720581055
train: epoch 135, loss 0.07108258455991745, acc=0.9816666841506958, loss=0.07108258455991745
test: epoch 135, loss 0.6927894353866577, acc=0.8194444179534912, loss=0.6927894353866577
train: epoch 136, loss 0.06587623804807663, acc=0.9819444417953491, loss=0.06587623804807663
test: epoch 136, loss 0.7377573847770691, acc=0.800000011920929, loss=0.7377573847770691
train: epoch 137, loss 0.05591856688261032, acc=0.9841111302375793, loss=0.05591856688261032
test: epoch 137, loss 0.7806679010391235, acc=0.824999988079071, loss=0.7806679010391235
train: epoch 138, loss 0.058407943695783615, acc=0.9842222332954407, loss=0.058407943695783615
test: epoch 138, loss 0.7116419672966003, acc=0.8305555582046509, loss=0.7116419672966003
train: epoch 139, loss 0.06129660829901695, acc=0.9822221994400024, loss=0.06129660829901695
test: epoch 139, loss 0.8319110870361328, acc=0.8277778029441833, loss=0.8319110870361328
train: epoch 140, loss 0.059907302260398865, acc=0.9828888773918152, loss=0.059907302260398865
test: epoch 140, loss 0.7558326721191406, acc=0.824999988079071, loss=0.7558326721191406
train: epoch 141, loss 0.0675048902630806, acc=0.9809444546699524, loss=0.0675048902630806
test: epoch 141, loss 0.7844715118408203, acc=0.7972221970558167, loss=0.7844715118408203
train: epoch 142, loss 0.05160803720355034, acc=0.9854444265365601, loss=0.05160803720355034
test: epoch 142, loss 0.7885541319847107, acc=0.8388888835906982, loss=0.7885541319847107
train: epoch 143, loss 0.052184976637363434, acc=0.9857222437858582, loss=0.052184976637363434
test: epoch 143, loss 0.5870757102966309, acc=0.8444444537162781, loss=0.5870757102966309
train: epoch 144, loss 0.05812394618988037, acc=0.984000027179718, loss=0.05812394618988037
test: epoch 144, loss 0.854733407497406, acc=0.8305555582046509, loss=0.854733407497406
train: epoch 145, loss 0.05782449617981911, acc=0.9837777614593506, loss=0.05782449617981911
test: epoch 145, loss 0.6504508256912231, acc=0.8333333134651184, loss=0.6504508256912231
train: epoch 146, loss 0.05574608966708183, acc=0.9845555424690247, loss=0.05574608966708183
test: epoch 146, loss 0.7280902862548828, acc=0.8305555582046509, loss=0.7280902862548828
train: epoch 147, loss 0.06538892537355423, acc=0.9819444417953491, loss=0.06538892537355423
test: epoch 147, loss 0.6257336735725403, acc=0.8527777791023254, loss=0.6257336735725403
train: epoch 148, loss 0.06731896102428436, acc=0.9813888669013977, loss=0.06731896102428436
test: epoch 148, loss 0.6210657954216003, acc=0.8333333134651184, loss=0.6210657954216003
train: epoch 149, loss 0.05726441368460655, acc=0.9837777614593506, loss=0.05726441368460655
test: epoch 149, loss 0.6135942339897156, acc=0.855555534362793, loss=0.6135942339897156
train: epoch 150, loss 0.06061994656920433, acc=0.9828888773918152, loss=0.06061994656920433
test: epoch 150, loss 0.7086758017539978, acc=0.8416666388511658, loss=0.7086758017539978
