# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=1", "--temp_decay=0.99", "--one_hot=false", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1578610350, receiver_embed_dim=128, temp_decay=0.99, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.9941325187683105, acc=0.08483333140611649, loss=2.9941325187683105
test: epoch 1, loss 2.5600268840789795, acc=0.12777778506278992, loss=2.5600268840789795
train: epoch 2, loss 1.8803985118865967, acc=0.2701111137866974, loss=1.8803985118865967
test: epoch 2, loss 1.9866204261779785, acc=0.2222222238779068, loss=1.9866204261779785
train: epoch 3, loss 1.4438831806182861, acc=0.3897777795791626, loss=1.4438831806182861
test: epoch 3, loss 1.7400553226470947, acc=0.2888889014720917, loss=1.7400553226470947
train: epoch 4, loss 1.2572365999221802, acc=0.4636666774749756, loss=1.2572365999221802
test: epoch 4, loss 1.7254154682159424, acc=0.30000001192092896, loss=1.7254154682159424
train: epoch 5, loss 1.1596033573150635, acc=0.511388897895813, loss=1.1596033573150635
test: epoch 5, loss 1.657917857170105, acc=0.34166666865348816, loss=1.657917857170105
train: epoch 6, loss 1.0856446027755737, acc=0.5331666469573975, loss=1.0856446027755737
test: epoch 6, loss 1.8621127605438232, acc=0.31111112236976624, loss=1.8621127605438232
train: epoch 7, loss 1.0330754518508911, acc=0.5527777671813965, loss=1.0330754518508911
test: epoch 7, loss 1.6669659614562988, acc=0.3222222328186035, loss=1.6669659614562988
train: epoch 8, loss 0.9886401891708374, acc=0.5728333592414856, loss=0.9886401891708374
test: epoch 8, loss 1.9488173723220825, acc=0.34166666865348816, loss=1.9488173723220825
train: epoch 9, loss 0.995058536529541, acc=0.5701666474342346, loss=0.995058536529541
test: epoch 9, loss 1.8704543113708496, acc=0.34166666865348816, loss=1.8704543113708496
train: epoch 10, loss 0.970269501209259, acc=0.5794444680213928, loss=0.970269501209259
test: epoch 10, loss 1.7047996520996094, acc=0.38333332538604736, loss=1.7047996520996094
train: epoch 11, loss 0.9563959836959839, acc=0.5831111073493958, loss=0.9563959836959839
test: epoch 11, loss 1.7143357992172241, acc=0.36666667461395264, loss=1.7143357992172241
train: epoch 12, loss 0.9432958960533142, acc=0.5918889045715332, loss=0.9432958960533142
test: epoch 12, loss 1.7127785682678223, acc=0.39444443583488464, loss=1.7127785682678223
train: epoch 13, loss 0.9340695738792419, acc=0.5964999794960022, loss=0.9340695738792419
test: epoch 13, loss 1.8481348752975464, acc=0.3861111104488373, loss=1.8481348752975464
train: epoch 14, loss 0.9489009976387024, acc=0.5918889045715332, loss=0.9489009976387024
test: epoch 14, loss 1.62663996219635, acc=0.39722222089767456, loss=1.62663996219635
train: epoch 15, loss 0.9152398705482483, acc=0.6001666784286499, loss=0.9152398705482483
test: epoch 15, loss 1.6455353498458862, acc=0.39444443583488464, loss=1.6455353498458862
train: epoch 16, loss 0.9234645366668701, acc=0.5972222089767456, loss=0.9234645366668701
test: epoch 16, loss 1.7566981315612793, acc=0.40833333134651184, loss=1.7566981315612793
train: epoch 17, loss 0.9496662020683289, acc=0.5892778038978577, loss=0.9496662020683289
test: epoch 17, loss 1.4557149410247803, acc=0.38333332538604736, loss=1.4557149410247803
train: epoch 18, loss 0.9146966934204102, acc=0.6021666526794434, loss=0.9146966934204102
test: epoch 18, loss 1.5685834884643555, acc=0.39722222089767456, loss=1.5685834884643555
train: epoch 19, loss 0.9250043034553528, acc=0.5985555648803711, loss=0.9250043034553528
test: epoch 19, loss 1.5912796258926392, acc=0.39444443583488464, loss=1.5912796258926392
train: epoch 20, loss 0.9062163829803467, acc=0.6006666421890259, loss=0.9062163829803467
test: epoch 20, loss 1.6622148752212524, acc=0.4027777910232544, loss=1.6622148752212524
train: epoch 21, loss 0.9206020832061768, acc=0.5931110978126526, loss=0.9206020832061768
test: epoch 21, loss 1.708222508430481, acc=0.39444443583488464, loss=1.708222508430481
train: epoch 22, loss 0.9101800322532654, acc=0.5946111083030701, loss=0.9101800322532654
test: epoch 22, loss 1.6406065225601196, acc=0.4055555462837219, loss=1.6406065225601196
train: epoch 23, loss 0.8991031050682068, acc=0.5963333249092102, loss=0.8991031050682068
test: epoch 23, loss 1.6339412927627563, acc=0.40833333134651184, loss=1.6339412927627563
train: epoch 24, loss 0.9118984341621399, acc=0.5929444432258606, loss=0.9118984341621399
test: epoch 24, loss 1.5817888975143433, acc=0.4055555462837219, loss=1.5817888975143433
train: epoch 25, loss 0.9039365649223328, acc=0.5930555462837219, loss=0.9039365649223328
test: epoch 25, loss 1.5640100240707397, acc=0.41111111640930176, loss=1.5640100240707397
train: epoch 26, loss 0.9131175875663757, acc=0.5962777733802795, loss=0.9131175875663757
test: epoch 26, loss 2.057934284210205, acc=0.38055557012557983, loss=2.057934284210205
train: epoch 27, loss 0.8988585472106934, acc=0.605222225189209, loss=0.8988585472106934
test: epoch 27, loss 1.5048043727874756, acc=0.4055555462837219, loss=1.5048043727874756
train: epoch 28, loss 0.8930694460868835, acc=0.6041111350059509, loss=0.8930694460868835
test: epoch 28, loss 1.517073154449463, acc=0.4166666567325592, loss=1.517073154449463
train: epoch 29, loss 0.9055778980255127, acc=0.6013888716697693, loss=0.9055778980255127
test: epoch 29, loss 1.683071255683899, acc=0.41111111640930176, loss=1.683071255683899
train: epoch 30, loss 0.910832405090332, acc=0.5960000157356262, loss=0.910832405090332
test: epoch 30, loss 1.4717546701431274, acc=0.42222222685813904, loss=1.4717546701431274
train: epoch 31, loss 0.8946185111999512, acc=0.6061111092567444, loss=0.8946185111999512
test: epoch 31, loss 1.4726815223693848, acc=0.4138889014720917, loss=1.4726815223693848
train: epoch 32, loss 0.9011271595954895, acc=0.6021111011505127, loss=0.9011271595954895
test: epoch 32, loss 1.510494351387024, acc=0.4194444417953491, loss=1.510494351387024
train: epoch 33, loss 0.8871302604675293, acc=0.6085000038146973, loss=0.8871302604675293
test: epoch 33, loss 1.56930410861969, acc=0.4194444417953491, loss=1.56930410861969
train: epoch 34, loss 0.8953906893730164, acc=0.6045555472373962, loss=0.8953906893730164
test: epoch 34, loss 1.7886977195739746, acc=0.42222222685813904, loss=1.7886977195739746
train: epoch 35, loss 0.8848790526390076, acc=0.6013333201408386, loss=0.8848790526390076
test: epoch 35, loss 1.519356608390808, acc=0.4277777671813965, loss=1.519356608390808
train: epoch 36, loss 0.8817803859710693, acc=0.6062777638435364, loss=0.8817803859710693
test: epoch 36, loss 1.6203452348709106, acc=0.42500001192092896, loss=1.6203452348709106
train: epoch 37, loss 0.8867740631103516, acc=0.6021666526794434, loss=0.8867740631103516
test: epoch 37, loss 1.8028253316879272, acc=0.42222222685813904, loss=1.8028253316879272
train: epoch 38, loss 0.8642773032188416, acc=0.6114444732666016, loss=0.8642773032188416
test: epoch 38, loss 1.5021400451660156, acc=0.42222222685813904, loss=1.5021400451660156
train: epoch 39, loss 0.8782967329025269, acc=0.6079999804496765, loss=0.8782967329025269
test: epoch 39, loss 1.6072425842285156, acc=0.42222222685813904, loss=1.6072425842285156
train: epoch 40, loss 0.8560227751731873, acc=0.6123889088630676, loss=0.8560227751731873
test: epoch 40, loss 1.6715255975723267, acc=0.4194444417953491, loss=1.6715255975723267
train: epoch 41, loss 0.8629804849624634, acc=0.6138333082199097, loss=0.8629804849624634
test: epoch 41, loss 1.6324198246002197, acc=0.4138889014720917, loss=1.6324198246002197
train: epoch 42, loss 0.8644707798957825, acc=0.6088333129882812, loss=0.8644707798957825
test: epoch 42, loss 1.7549517154693604, acc=0.4277777671813965, loss=1.7549517154693604
train: epoch 43, loss 0.8518580198287964, acc=0.6144999861717224, loss=0.8518580198287964
test: epoch 43, loss 1.7283837795257568, acc=0.42500001192092896, loss=1.7283837795257568
train: epoch 44, loss 0.8601300716400146, acc=0.6152777671813965, loss=0.8601300716400146
test: epoch 44, loss 1.6591064929962158, acc=0.42222222685813904, loss=1.6591064929962158
train: epoch 45, loss 0.8513968586921692, acc=0.6183333396911621, loss=0.8513968586921692
test: epoch 45, loss 1.5375802516937256, acc=0.42222222685813904, loss=1.5375802516937256
train: epoch 46, loss 0.8492530584335327, acc=0.6196666955947876, loss=0.8492530584335327
test: epoch 46, loss 1.6993569135665894, acc=0.4277777671813965, loss=1.6993569135665894
train: epoch 47, loss 0.8611358404159546, acc=0.6098889112472534, loss=0.8611358404159546
test: epoch 47, loss 1.5047231912612915, acc=0.4166666567325592, loss=1.5047231912612915
train: epoch 48, loss 0.847696840763092, acc=0.6188889145851135, loss=0.847696840763092
test: epoch 48, loss 1.5548025369644165, acc=0.42222222685813904, loss=1.5548025369644165
train: epoch 49, loss 0.8468969464302063, acc=0.6208333373069763, loss=0.8468969464302063
test: epoch 49, loss 1.6132410764694214, acc=0.4194444417953491, loss=1.6132410764694214
train: epoch 50, loss 0.84751957654953, acc=0.6179999709129333, loss=0.84751957654953
test: epoch 50, loss 1.7310230731964111, acc=0.4277777671813965, loss=1.7310230731964111
train: epoch 51, loss 0.8462502360343933, acc=0.6183333396911621, loss=0.8462502360343933
test: epoch 51, loss 1.4937198162078857, acc=0.4305555522441864, loss=1.4937198162078857
train: epoch 52, loss 0.8311227560043335, acc=0.6247222423553467, loss=0.8311227560043335
test: epoch 52, loss 1.482216715812683, acc=0.4555555582046509, loss=1.482216715812683
train: epoch 53, loss 0.8464339971542358, acc=0.6197222471237183, loss=0.8464339971542358
test: epoch 53, loss 1.5896040201187134, acc=0.4555555582046509, loss=1.5896040201187134
train: epoch 54, loss 0.8293372392654419, acc=0.6276111006736755, loss=0.8293372392654419
test: epoch 54, loss 1.554322361946106, acc=0.4583333432674408, loss=1.554322361946106
train: epoch 55, loss 0.8398618102073669, acc=0.6220555305480957, loss=0.8398618102073669
test: epoch 55, loss 1.5249475240707397, acc=0.4583333432674408, loss=1.5249475240707397
train: epoch 56, loss 0.8391627073287964, acc=0.6239444613456726, loss=0.8391627073287964
test: epoch 56, loss 1.6908191442489624, acc=0.45277777314186096, loss=1.6908191442489624
train: epoch 57, loss 0.8357229232788086, acc=0.6221666932106018, loss=0.8357229232788086
test: epoch 57, loss 1.6763604879379272, acc=0.4555555582046509, loss=1.6763604879379272
train: epoch 58, loss 0.8134531378746033, acc=0.6270555257797241, loss=0.8134531378746033
test: epoch 58, loss 1.6149101257324219, acc=0.43611112236976624, loss=1.6149101257324219
train: epoch 59, loss 0.8309347033500671, acc=0.6261666417121887, loss=0.8309347033500671
test: epoch 59, loss 1.6412007808685303, acc=0.4555555582046509, loss=1.6412007808685303
train: epoch 60, loss 0.8115555644035339, acc=0.6329444646835327, loss=0.8115555644035339
test: epoch 60, loss 1.5096149444580078, acc=0.4583333432674408, loss=1.5096149444580078
train: epoch 61, loss 0.8256364464759827, acc=0.6302222013473511, loss=0.8256364464759827
test: epoch 61, loss 1.4351071119308472, acc=0.46666666865348816, loss=1.4351071119308472
train: epoch 62, loss 0.7904960513114929, acc=0.6451666951179504, loss=0.7904960513114929
test: epoch 62, loss 1.6173990964889526, acc=0.4694444537162781, loss=1.6173990964889526
train: epoch 63, loss 0.7970690131187439, acc=0.6395000219345093, loss=0.7970690131187439
test: epoch 63, loss 1.6128994226455688, acc=0.46666666865348816, loss=1.6128994226455688
train: epoch 64, loss 0.7776378393173218, acc=0.6465555429458618, loss=0.7776378393173218
test: epoch 64, loss 1.6655468940734863, acc=0.46388888359069824, loss=1.6655468940734863
train: epoch 65, loss 0.7835285067558289, acc=0.6452777981758118, loss=0.7835285067558289
test: epoch 65, loss 1.5875611305236816, acc=0.46666666865348816, loss=1.5875611305236816
train: epoch 66, loss 0.786537766456604, acc=0.6421111226081848, loss=0.786537766456604
test: epoch 66, loss 1.6878130435943604, acc=0.46666666865348816, loss=1.6878130435943604
train: epoch 67, loss 0.7741149067878723, acc=0.6477222442626953, loss=0.7741149067878723
test: epoch 67, loss 1.6003482341766357, acc=0.46666666865348816, loss=1.6003482341766357
train: epoch 68, loss 0.7770610451698303, acc=0.6425555348396301, loss=0.7770610451698303
test: epoch 68, loss 1.6016861200332642, acc=0.46666666865348816, loss=1.6016861200332642
train: epoch 69, loss 0.7636813521385193, acc=0.6504999995231628, loss=0.7636813521385193
test: epoch 69, loss 1.627956509590149, acc=0.46666666865348816, loss=1.627956509590149
train: epoch 70, loss 0.7854212522506714, acc=0.6411666870117188, loss=0.7854212522506714
test: epoch 70, loss 1.6576071977615356, acc=0.46666666865348816, loss=1.6576071977615356
train: epoch 71, loss 0.7839715480804443, acc=0.6477222442626953, loss=0.7839715480804443
test: epoch 71, loss 1.5578001737594604, acc=0.46666666865348816, loss=1.5578001737594604
train: epoch 72, loss 0.7729973196983337, acc=0.6499444246292114, loss=0.7729973196983337
test: epoch 72, loss 1.723748803138733, acc=0.46666666865348816, loss=1.723748803138733
train: epoch 73, loss 0.7854673266410828, acc=0.64811110496521, loss=0.7854673266410828
test: epoch 73, loss 1.5321062803268433, acc=0.46388888359069824, loss=1.5321062803268433
train: epoch 74, loss 0.7696024775505066, acc=0.6544444561004639, loss=0.7696024775505066
test: epoch 74, loss 1.7323044538497925, acc=0.46666666865348816, loss=1.7323044538497925
train: epoch 75, loss 0.7708027362823486, acc=0.6480555534362793, loss=0.7708027362823486
test: epoch 75, loss 1.6424229145050049, acc=0.46666666865348816, loss=1.6424229145050049
train: epoch 76, loss 0.770123302936554, acc=0.6486111283302307, loss=0.770123302936554
test: epoch 76, loss 1.6210185289382935, acc=0.4722222089767456, loss=1.6210185289382935
train: epoch 77, loss 0.7694343328475952, acc=0.6571111083030701, loss=0.7694343328475952
test: epoch 77, loss 1.5092524290084839, acc=0.47777777910232544, loss=1.5092524290084839
train: epoch 78, loss 0.7520074844360352, acc=0.6663333177566528, loss=0.7520074844360352
test: epoch 78, loss 1.5629805326461792, acc=0.4861111044883728, loss=1.5629805326461792
train: epoch 79, loss 0.7424440979957581, acc=0.6678333282470703, loss=0.7424440979957581
test: epoch 79, loss 1.5137192010879517, acc=0.4861111044883728, loss=1.5137192010879517
train: epoch 80, loss 0.7437741160392761, acc=0.6685000061988831, loss=0.7437741160392761
test: epoch 80, loss 1.5604970455169678, acc=0.4833333194255829, loss=1.5604970455169678
train: epoch 81, loss 0.7389771342277527, acc=0.6724444627761841, loss=0.7389771342277527
test: epoch 81, loss 1.557251214981079, acc=0.48055556416511536, loss=1.557251214981079
train: epoch 82, loss 0.728131115436554, acc=0.6726666688919067, loss=0.728131115436554
test: epoch 82, loss 1.4727859497070312, acc=0.49166667461395264, loss=1.4727859497070312
train: epoch 83, loss 0.7189194560050964, acc=0.6763333082199097, loss=0.7189194560050964
test: epoch 83, loss 1.554971694946289, acc=0.49444442987442017, loss=1.554971694946289
train: epoch 84, loss 0.7227764129638672, acc=0.6764444708824158, loss=0.7227764129638672
test: epoch 84, loss 1.4949612617492676, acc=0.4972222149372101, loss=1.4949612617492676
train: epoch 85, loss 0.7309052348136902, acc=0.6755555272102356, loss=0.7309052348136902
test: epoch 85, loss 1.466170310974121, acc=0.5027777552604675, loss=1.466170310974121
train: epoch 86, loss 0.725957453250885, acc=0.6740555763244629, loss=0.725957453250885
test: epoch 86, loss 1.5190725326538086, acc=0.5, loss=1.5190725326538086
train: epoch 87, loss 0.720568060874939, acc=0.6766666769981384, loss=0.720568060874939
test: epoch 87, loss 1.4120899438858032, acc=0.5, loss=1.4120899438858032
train: epoch 88, loss 0.7161439061164856, acc=0.675611138343811, loss=0.7161439061164856
test: epoch 88, loss 1.4162452220916748, acc=0.5, loss=1.4162452220916748
train: epoch 89, loss 0.70696622133255, acc=0.675166666507721, loss=0.70696622133255
test: epoch 89, loss 1.6108015775680542, acc=0.5, loss=1.6108015775680542
train: epoch 90, loss 0.717812180519104, acc=0.6779999732971191, loss=0.717812180519104
test: epoch 90, loss 1.4825546741485596, acc=0.5, loss=1.4825546741485596
train: epoch 91, loss 0.7059556841850281, acc=0.6764444708824158, loss=0.7059556841850281
test: epoch 91, loss 1.5596461296081543, acc=0.5, loss=1.5596461296081543
train: epoch 92, loss 0.7061629295349121, acc=0.6742777824401855, loss=0.7061629295349121
test: epoch 92, loss 1.5105249881744385, acc=0.5055555701255798, loss=1.5105249881744385
train: epoch 93, loss 0.68651282787323, acc=0.6834444403648376, loss=0.68651282787323
test: epoch 93, loss 1.5906940698623657, acc=0.5027777552604675, loss=1.5906940698623657
train: epoch 94, loss 0.6976218223571777, acc=0.6779444217681885, loss=0.6976218223571777
test: epoch 94, loss 1.5549107789993286, acc=0.5027777552604675, loss=1.5549107789993286
train: epoch 95, loss 0.7074662446975708, acc=0.6776666641235352, loss=0.7074662446975708
test: epoch 95, loss 1.4887821674346924, acc=0.5, loss=1.4887821674346924
train: epoch 96, loss 0.7017025947570801, acc=0.6769444346427917, loss=0.7017025947570801
test: epoch 96, loss 1.527435302734375, acc=0.5027777552604675, loss=1.527435302734375
train: epoch 97, loss 0.7047433853149414, acc=0.6828333139419556, loss=0.7047433853149414
test: epoch 97, loss 1.4170877933502197, acc=0.5, loss=1.4170877933502197
train: epoch 98, loss 0.7012267112731934, acc=0.6827222108840942, loss=0.7012267112731934
test: epoch 98, loss 1.5261503458023071, acc=0.5, loss=1.5261503458023071
train: epoch 99, loss 0.6997604966163635, acc=0.6768888831138611, loss=0.6997604966163635
test: epoch 99, loss 1.4123611450195312, acc=0.5138888955116272, loss=1.4123611450195312
train: epoch 100, loss 0.6954946517944336, acc=0.6863333582878113, loss=0.6954946517944336
test: epoch 100, loss 1.391743779182434, acc=0.5222222208976746, loss=1.391743779182434
train: epoch 101, loss 0.6803939342498779, acc=0.6872777938842773, loss=0.6803939342498779
test: epoch 101, loss 1.4407304525375366, acc=0.5277777910232544, loss=1.4407304525375366
train: epoch 102, loss 0.6749802827835083, acc=0.6957777738571167, loss=0.6749802827835083
test: epoch 102, loss 1.2897214889526367, acc=0.5249999761581421, loss=1.2897214889526367
train: epoch 103, loss 0.661408543586731, acc=0.6978333592414856, loss=0.661408543586731
test: epoch 103, loss 1.3332113027572632, acc=0.5249999761581421, loss=1.3332113027572632
train: epoch 104, loss 0.6603260636329651, acc=0.6988333463668823, loss=0.6603260636329651
test: epoch 104, loss 1.359882116317749, acc=0.5305555462837219, loss=1.359882116317749
train: epoch 105, loss 0.6649891138076782, acc=0.703000009059906, loss=0.6649891138076782
test: epoch 105, loss 1.4913759231567383, acc=0.5555555820465088, loss=1.4913759231567383
train: epoch 106, loss 0.6329870820045471, acc=0.7124444246292114, loss=0.6329870820045471
test: epoch 106, loss 1.3514087200164795, acc=0.5722222328186035, loss=1.3514087200164795
train: epoch 107, loss 0.623506486415863, acc=0.7231666445732117, loss=0.623506486415863
test: epoch 107, loss 1.350008487701416, acc=0.574999988079071, loss=1.350008487701416
train: epoch 108, loss 0.6382361650466919, acc=0.7177222371101379, loss=0.6382361650466919
test: epoch 108, loss 1.1288576126098633, acc=0.5861111283302307, loss=1.1288576126098633
train: epoch 109, loss 0.601843535900116, acc=0.7285555601119995, loss=0.601843535900116
test: epoch 109, loss 1.1082578897476196, acc=0.5972222089767456, loss=1.1082578897476196
train: epoch 110, loss 0.6041454076766968, acc=0.7289444208145142, loss=0.6041454076766968
test: epoch 110, loss 1.097977876663208, acc=0.5944444537162781, loss=1.097977876663208
train: epoch 111, loss 0.6098551154136658, acc=0.7251111268997192, loss=0.6098551154136658
test: epoch 111, loss 1.2257755994796753, acc=0.5944444537162781, loss=1.2257755994796753
train: epoch 112, loss 0.600622296333313, acc=0.7306110858917236, loss=0.600622296333313
test: epoch 112, loss 1.2221437692642212, acc=0.5972222089767456, loss=1.2221437692642212
train: epoch 113, loss 0.5937657952308655, acc=0.7281110882759094, loss=0.5937657952308655
test: epoch 113, loss 1.1686707735061646, acc=0.5972222089767456, loss=1.1686707735061646
train: epoch 114, loss 0.6003944277763367, acc=0.7273333072662354, loss=0.6003944277763367
test: epoch 114, loss 1.1561728715896606, acc=0.5972222089767456, loss=1.1561728715896606
train: epoch 115, loss 0.5964251160621643, acc=0.7295555472373962, loss=0.5964251160621643
test: epoch 115, loss 1.0778297185897827, acc=0.5972222089767456, loss=1.0778297185897827
train: epoch 116, loss 0.6207588315010071, acc=0.7222222089767456, loss=0.6207588315010071
test: epoch 116, loss 1.1732192039489746, acc=0.5944444537162781, loss=1.1732192039489746
train: epoch 117, loss 0.6101300120353699, acc=0.7265555262565613, loss=0.6101300120353699
test: epoch 117, loss 1.1042560338974, acc=0.5944444537162781, loss=1.1042560338974
train: epoch 118, loss 0.5915548205375671, acc=0.7304444313049316, loss=0.5915548205375671
test: epoch 118, loss 1.1327601671218872, acc=0.5944444537162781, loss=1.1327601671218872
train: epoch 119, loss 0.5899826884269714, acc=0.730222225189209, loss=0.5899826884269714
test: epoch 119, loss 1.1502822637557983, acc=0.5944444537162781, loss=1.1502822637557983
train: epoch 120, loss 0.6055017113685608, acc=0.7264999747276306, loss=0.6055017113685608
test: epoch 120, loss 1.1474814414978027, acc=0.5944444537162781, loss=1.1474814414978027
train: epoch 121, loss 0.610805094242096, acc=0.7284444570541382, loss=0.610805094242096
test: epoch 121, loss 1.1037179231643677, acc=0.5944444537162781, loss=1.1037179231643677
train: epoch 122, loss 0.5996466279029846, acc=0.7323889136314392, loss=0.5996466279029846
test: epoch 122, loss 1.0017857551574707, acc=0.605555534362793, loss=1.0017857551574707
train: epoch 123, loss 0.5924322009086609, acc=0.7299444675445557, loss=0.5924322009086609
test: epoch 123, loss 1.031315803527832, acc=0.625, loss=1.031315803527832
train: epoch 124, loss 0.5865917801856995, acc=0.7336111068725586, loss=0.5865917801856995
test: epoch 124, loss 0.9816170930862427, acc=0.625, loss=0.9816170930862427
train: epoch 125, loss 0.5929388999938965, acc=0.7367777824401855, loss=0.5929388999938965
test: epoch 125, loss 1.0370303392410278, acc=0.6222222447395325, loss=1.0370303392410278
train: epoch 126, loss 0.6066391468048096, acc=0.733222246170044, loss=0.6066391468048096
test: epoch 126, loss 1.0413674116134644, acc=0.6222222447395325, loss=1.0413674116134644
train: epoch 127, loss 0.6076640486717224, acc=0.731333315372467, loss=0.6076640486717224
test: epoch 127, loss 1.0354617834091187, acc=0.6277777552604675, loss=1.0354617834091187
train: epoch 128, loss 0.5873495936393738, acc=0.7289999723434448, loss=0.5873495936393738
test: epoch 128, loss 1.0619621276855469, acc=0.6277777552604675, loss=1.0619621276855469
train: epoch 129, loss 0.5813758969306946, acc=0.7313888669013977, loss=0.5813758969306946
test: epoch 129, loss 0.9822892546653748, acc=0.6388888955116272, loss=0.9822892546653748
train: epoch 130, loss 0.5682623982429504, acc=0.7364444732666016, loss=0.5682623982429504
test: epoch 130, loss 0.8328338861465454, acc=0.6555555462837219, loss=0.8328338861465454
train: epoch 131, loss 0.5608773827552795, acc=0.7393888831138611, loss=0.5608773827552795
test: epoch 131, loss 0.9479405879974365, acc=0.6555555462837219, loss=0.9479405879974365
train: epoch 132, loss 0.5842217803001404, acc=0.737333357334137, loss=0.5842217803001404
test: epoch 132, loss 0.9197558164596558, acc=0.6499999761581421, loss=0.9197558164596558
train: epoch 133, loss 0.5741654634475708, acc=0.7350555658340454, loss=0.5741654634475708
test: epoch 133, loss 0.9907292723655701, acc=0.6555555462837219, loss=0.9907292723655701
train: epoch 134, loss 0.571526825428009, acc=0.7325000166893005, loss=0.571526825428009
test: epoch 134, loss 0.9244166016578674, acc=0.6527777910232544, loss=0.9244166016578674
train: epoch 135, loss 0.5625207424163818, acc=0.7328333258628845, loss=0.5625207424163818
test: epoch 135, loss 0.9521883130073547, acc=0.6555555462837219, loss=0.9521883130073547
train: epoch 136, loss 0.563396155834198, acc=0.7394444346427917, loss=0.563396155834198
test: epoch 136, loss 0.913212239742279, acc=0.6555555462837219, loss=0.913212239742279
train: epoch 137, loss 0.5522077083587646, acc=0.7410555481910706, loss=0.5522077083587646
test: epoch 137, loss 0.9501928091049194, acc=0.6611111164093018, loss=0.9501928091049194
train: epoch 138, loss 0.5404614806175232, acc=0.7454444169998169, loss=0.5404614806175232
test: epoch 138, loss 0.9315136671066284, acc=0.6638888716697693, loss=0.9315136671066284
train: epoch 139, loss 0.541311502456665, acc=0.7490555644035339, loss=0.541311502456665
test: epoch 139, loss 0.8965686559677124, acc=0.6666666865348816, loss=0.8965686559677124
train: epoch 140, loss 0.533194899559021, acc=0.7511666417121887, loss=0.533194899559021
test: epoch 140, loss 0.8642262816429138, acc=0.675000011920929, loss=0.8642262816429138
train: epoch 141, loss 0.5382388830184937, acc=0.7481666803359985, loss=0.5382388830184937
test: epoch 141, loss 0.7731135487556458, acc=0.6805555820465088, loss=0.7731135487556458
train: epoch 142, loss 0.5343093872070312, acc=0.7472222447395325, loss=0.5343093872070312
test: epoch 142, loss 0.8075940012931824, acc=0.6833333373069763, loss=0.8075940012931824
train: epoch 143, loss 0.5419284105300903, acc=0.7394444346427917, loss=0.5419284105300903
test: epoch 143, loss 0.7642554640769958, acc=0.6861110925674438, loss=0.7642554640769958
train: epoch 144, loss 0.5255850553512573, acc=0.7484444379806519, loss=0.5255850553512573
test: epoch 144, loss 0.769442081451416, acc=0.6861110925674438, loss=0.769442081451416
train: epoch 145, loss 0.5310275554656982, acc=0.7527777552604675, loss=0.5310275554656982
test: epoch 145, loss 0.768683910369873, acc=0.6861110925674438, loss=0.768683910369873
train: epoch 146, loss 0.5255870819091797, acc=0.7465555667877197, loss=0.5255870819091797
test: epoch 146, loss 0.7427555918693542, acc=0.6861110925674438, loss=0.7427555918693542
train: epoch 147, loss 0.5219963788986206, acc=0.7506666779518127, loss=0.5219963788986206
test: epoch 147, loss 0.8111680746078491, acc=0.6916666626930237, loss=0.8111680746078491
train: epoch 148, loss 0.5166606307029724, acc=0.7448889017105103, loss=0.5166606307029724
test: epoch 148, loss 0.8397659659385681, acc=0.6833333373069763, loss=0.8397659659385681
train: epoch 149, loss 0.5247609615325928, acc=0.746222198009491, loss=0.5247609615325928
test: epoch 149, loss 0.815772533416748, acc=0.6916666626930237, loss=0.815772533416748
train: epoch 150, loss 0.5312141180038452, acc=0.7506666779518127, loss=0.5312141180038452
test: epoch 150, loss 0.7997317910194397, acc=0.6833333373069763, loss=0.7997317910194397
