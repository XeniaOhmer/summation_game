# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1", "--temp_decay=0.995", "--one_hot=false", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=2070207265, receiver_embed_dim=32, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.314850091934204, acc=0.05461111292243004, loss=3.314850091934204
test: epoch 1, loss 3.1052510738372803, acc=0.08055555820465088, loss=3.1052510738372803
train: epoch 2, loss 2.5907983779907227, acc=0.1245555579662323, loss=2.5907983779907227
test: epoch 2, loss 2.5214014053344727, acc=0.13333334028720856, loss=2.5214014053344727
train: epoch 3, loss 2.258498430252075, acc=0.17766666412353516, loss=2.258498430252075
test: epoch 3, loss 2.368985652923584, acc=0.14722222089767456, loss=2.368985652923584
train: epoch 4, loss 2.0399529933929443, acc=0.21905554831027985, loss=2.0399529933929443
test: epoch 4, loss 2.2676799297332764, acc=0.14722222089767456, loss=2.2676799297332764
train: epoch 5, loss 1.8921340703964233, acc=0.25361111760139465, loss=1.8921340703964233
test: epoch 5, loss 2.131728410720825, acc=0.17777778208255768, loss=2.131728410720825
train: epoch 6, loss 1.7603201866149902, acc=0.28522223234176636, loss=1.7603201866149902
test: epoch 6, loss 2.2836551666259766, acc=0.17777778208255768, loss=2.2836551666259766
train: epoch 7, loss 1.6870651245117188, acc=0.3063333332538605, loss=1.6870651245117188
test: epoch 7, loss 2.1110310554504395, acc=0.16388888657093048, loss=2.1110310554504395
train: epoch 8, loss 1.6117349863052368, acc=0.33205556869506836, loss=1.6117349863052368
test: epoch 8, loss 2.168081521987915, acc=0.2222222238779068, loss=2.168081521987915
train: epoch 9, loss 1.5396075248718262, acc=0.3584444522857666, loss=1.5396075248718262
test: epoch 9, loss 2.0454485416412354, acc=0.23055554926395416, loss=2.0454485416412354
train: epoch 10, loss 1.3638912439346313, acc=0.45366665720939636, loss=1.3638912439346313
test: epoch 10, loss 1.773626446723938, acc=0.3027777671813965, loss=1.773626446723938
train: epoch 11, loss 1.1816562414169312, acc=0.5228888988494873, loss=1.1816562414169312
test: epoch 11, loss 1.6134003400802612, acc=0.3305555582046509, loss=1.6134003400802612
train: epoch 12, loss 1.0817798376083374, acc=0.5537777543067932, loss=1.0817798376083374
test: epoch 12, loss 1.6684589385986328, acc=0.3305555582046509, loss=1.6684589385986328
train: epoch 13, loss 1.0281254053115845, acc=0.569944441318512, loss=1.0281254053115845
test: epoch 13, loss 1.6937154531478882, acc=0.32777777314186096, loss=1.6937154531478882
train: epoch 14, loss 0.977229654788971, acc=0.5958333611488342, loss=0.977229654788971
test: epoch 14, loss 1.707980751991272, acc=0.33888888359069824, loss=1.707980751991272
train: epoch 15, loss 0.9600402116775513, acc=0.5970555543899536, loss=0.9600402116775513
test: epoch 15, loss 1.578989028930664, acc=0.3305555582046509, loss=1.578989028930664
train: epoch 16, loss 0.9147460460662842, acc=0.6122221946716309, loss=0.9147460460662842
test: epoch 16, loss 1.7032742500305176, acc=0.3333333432674408, loss=1.7032742500305176
train: epoch 17, loss 0.8757038712501526, acc=0.6255555748939514, loss=0.8757038712501526
test: epoch 17, loss 1.7506768703460693, acc=0.3305555582046509, loss=1.7506768703460693
train: epoch 18, loss 0.8712431192398071, acc=0.621833324432373, loss=0.8712431192398071
test: epoch 18, loss 1.8890833854675293, acc=0.3333333432674408, loss=1.8890833854675293
train: epoch 19, loss 0.85098797082901, acc=0.6349999904632568, loss=0.85098797082901
test: epoch 19, loss 1.7181317806243896, acc=0.33888888359069824, loss=1.7181317806243896
train: epoch 20, loss 0.8467957973480225, acc=0.6297222375869751, loss=0.8467957973480225
test: epoch 20, loss 1.9033855199813843, acc=0.3333333432674408, loss=1.9033855199813843
train: epoch 21, loss 0.8311910033226013, acc=0.6387222409248352, loss=0.8311910033226013
test: epoch 21, loss 1.728185772895813, acc=0.3333333432674408, loss=1.728185772895813
train: epoch 22, loss 0.8147681355476379, acc=0.6420555710792542, loss=0.8147681355476379
test: epoch 22, loss 1.837829828262329, acc=0.33888888359069824, loss=1.837829828262329
train: epoch 23, loss 0.8381173014640808, acc=0.6343888640403748, loss=0.8381173014640808
test: epoch 23, loss 1.7085694074630737, acc=0.3305555582046509, loss=1.7085694074630737
train: epoch 24, loss 0.8190550208091736, acc=0.6423333287239075, loss=0.8190550208091736
test: epoch 24, loss 1.8068088293075562, acc=0.3305555582046509, loss=1.8068088293075562
train: epoch 25, loss 0.7956982254981995, acc=0.6461111307144165, loss=0.7956982254981995
test: epoch 25, loss 1.7745352983474731, acc=0.3305555582046509, loss=1.7745352983474731
train: epoch 26, loss 0.7932426929473877, acc=0.6491666436195374, loss=0.7932426929473877
test: epoch 26, loss 1.767297625541687, acc=0.3305555582046509, loss=1.767297625541687
train: epoch 27, loss 0.7900970578193665, acc=0.6460000276565552, loss=0.7900970578193665
test: epoch 27, loss 1.8076215982437134, acc=0.32499998807907104, loss=1.8076215982437134
train: epoch 28, loss 0.7664388418197632, acc=0.6607778072357178, loss=0.7664388418197632
test: epoch 28, loss 1.7857195138931274, acc=0.34166666865348816, loss=1.7857195138931274
train: epoch 29, loss 0.780462384223938, acc=0.6509444713592529, loss=0.780462384223938
test: epoch 29, loss 1.7095710039138794, acc=0.3499999940395355, loss=1.7095710039138794
train: epoch 30, loss 0.7457729578018188, acc=0.6652777791023254, loss=0.7457729578018188
test: epoch 30, loss 1.7766425609588623, acc=0.3583333194255829, loss=1.7766425609588623
train: epoch 31, loss 0.765508770942688, acc=0.660277783870697, loss=0.765508770942688
test: epoch 31, loss 1.6672853231430054, acc=0.36944442987442017, loss=1.6672853231430054
train: epoch 32, loss 0.7594790458679199, acc=0.6586666703224182, loss=0.7594790458679199
test: epoch 32, loss 1.815463662147522, acc=0.3638888895511627, loss=1.815463662147522
train: epoch 33, loss 0.7582741975784302, acc=0.6652777791023254, loss=0.7582741975784302
test: epoch 33, loss 1.7147116661071777, acc=0.38055557012557983, loss=1.7147116661071777
train: epoch 34, loss 0.724568784236908, acc=0.6857222318649292, loss=0.724568784236908
test: epoch 34, loss 1.7493538856506348, acc=0.3861111104488373, loss=1.7493538856506348
train: epoch 35, loss 0.7393248081207275, acc=0.6730555295944214, loss=0.7393248081207275
test: epoch 35, loss 1.777841567993164, acc=0.36666667461395264, loss=1.777841567993164
train: epoch 36, loss 0.7198483347892761, acc=0.6804999709129333, loss=0.7198483347892761
test: epoch 36, loss 1.7310919761657715, acc=0.36944442987442017, loss=1.7310919761657715
train: epoch 37, loss 0.7307663559913635, acc=0.6767777800559998, loss=0.7307663559913635
test: epoch 37, loss 1.8870028257369995, acc=0.3777777850627899, loss=1.8870028257369995
train: epoch 38, loss 0.7169458270072937, acc=0.6841111183166504, loss=0.7169458270072937
test: epoch 38, loss 1.6667170524597168, acc=0.39444443583488464, loss=1.6667170524597168
train: epoch 39, loss 0.7199125289916992, acc=0.6783333420753479, loss=0.7199125289916992
test: epoch 39, loss 1.8315918445587158, acc=0.38055557012557983, loss=1.8315918445587158
train: epoch 40, loss 0.7202757596969604, acc=0.6823889017105103, loss=0.7202757596969604
test: epoch 40, loss 1.7684029340744019, acc=0.38333332538604736, loss=1.7684029340744019
train: epoch 41, loss 0.7392308115959167, acc=0.6733333468437195, loss=0.7392308115959167
test: epoch 41, loss 1.6818122863769531, acc=0.3916666805744171, loss=1.6818122863769531
train: epoch 42, loss 0.7050275206565857, acc=0.6868333220481873, loss=0.7050275206565857
test: epoch 42, loss 1.7072842121124268, acc=0.39444443583488464, loss=1.7072842121124268
train: epoch 43, loss 0.7127167582511902, acc=0.6869444251060486, loss=0.7127167582511902
test: epoch 43, loss 1.6856608390808105, acc=0.3916666805744171, loss=1.6856608390808105
train: epoch 44, loss 0.7125215530395508, acc=0.687666654586792, loss=0.7125215530395508
test: epoch 44, loss 1.7153775691986084, acc=0.3916666805744171, loss=1.7153775691986084
train: epoch 45, loss 0.7012987732887268, acc=0.691277801990509, loss=0.7012987732887268
test: epoch 45, loss 1.8727155923843384, acc=0.3861111104488373, loss=1.8727155923843384
train: epoch 46, loss 0.7102550864219666, acc=0.6859999895095825, loss=0.7102550864219666
test: epoch 46, loss 1.9338537454605103, acc=0.39444443583488464, loss=1.9338537454605103
train: epoch 47, loss 0.7130513787269592, acc=0.6855000257492065, loss=0.7130513787269592
test: epoch 47, loss 1.7282745838165283, acc=0.3888888955116272, loss=1.7282745838165283
train: epoch 48, loss 0.7298397421836853, acc=0.6772778034210205, loss=0.7298397421836853
test: epoch 48, loss 1.661523461341858, acc=0.3861111104488373, loss=1.661523461341858
train: epoch 49, loss 0.7234794497489929, acc=0.6808888912200928, loss=0.7234794497489929
test: epoch 49, loss 1.7001756429672241, acc=0.39444443583488464, loss=1.7001756429672241
train: epoch 50, loss 0.7029577493667603, acc=0.6913333535194397, loss=0.7029577493667603
test: epoch 50, loss 1.7964837551116943, acc=0.3916666805744171, loss=1.7964837551116943
train: epoch 51, loss 0.7047060132026672, acc=0.6923333406448364, loss=0.7047060132026672
test: epoch 51, loss 1.6769732236862183, acc=0.4000000059604645, loss=1.6769732236862183
train: epoch 52, loss 0.7007501721382141, acc=0.694611132144928, loss=0.7007501721382141
test: epoch 52, loss 1.8730655908584595, acc=0.39722222089767456, loss=1.8730655908584595
train: epoch 53, loss 0.7084032297134399, acc=0.6923888921737671, loss=0.7084032297134399
test: epoch 53, loss 1.7637568712234497, acc=0.3916666805744171, loss=1.7637568712234497
train: epoch 54, loss 0.7187680602073669, acc=0.6880555748939514, loss=0.7187680602073669
test: epoch 54, loss 1.7554339170455933, acc=0.39722222089767456, loss=1.7554339170455933
train: epoch 55, loss 0.7150357365608215, acc=0.6863333582878113, loss=0.7150357365608215
test: epoch 55, loss 1.8469408750534058, acc=0.39444443583488464, loss=1.8469408750534058
train: epoch 56, loss 0.7104493975639343, acc=0.6930000185966492, loss=0.7104493975639343
test: epoch 56, loss 1.7658095359802246, acc=0.39444443583488464, loss=1.7658095359802246
train: epoch 57, loss 0.7116771936416626, acc=0.6894999742507935, loss=0.7116771936416626
test: epoch 57, loss 1.800655484199524, acc=0.39722222089767456, loss=1.800655484199524
train: epoch 58, loss 0.7059986591339111, acc=0.6921666860580444, loss=0.7059986591339111
test: epoch 58, loss 1.5765323638916016, acc=0.39722222089767456, loss=1.5765323638916016
train: epoch 59, loss 0.7040519714355469, acc=0.6922777891159058, loss=0.7040519714355469
test: epoch 59, loss 1.880288004875183, acc=0.4000000059604645, loss=1.880288004875183
train: epoch 60, loss 0.6948060989379883, acc=0.6992777585983276, loss=0.6948060989379883
test: epoch 60, loss 1.9132860898971558, acc=0.39722222089767456, loss=1.9132860898971558
train: epoch 61, loss 0.7059993743896484, acc=0.6974999904632568, loss=0.7059993743896484
test: epoch 61, loss 1.8215088844299316, acc=0.39444443583488464, loss=1.8215088844299316
train: epoch 62, loss 0.7041208148002625, acc=0.6963889002799988, loss=0.7041208148002625
test: epoch 62, loss 1.7074403762817383, acc=0.4000000059604645, loss=1.7074403762817383
train: epoch 63, loss 0.7017922401428223, acc=0.6952221989631653, loss=0.7017922401428223
test: epoch 63, loss 1.7305878400802612, acc=0.39722222089767456, loss=1.7305878400802612
train: epoch 64, loss 0.7120809555053711, acc=0.6917222142219543, loss=0.7120809555053711
test: epoch 64, loss 1.7432811260223389, acc=0.39722222089767456, loss=1.7432811260223389
train: epoch 65, loss 0.6881910562515259, acc=0.6991111040115356, loss=0.6881910562515259
test: epoch 65, loss 1.7864868640899658, acc=0.4000000059604645, loss=1.7864868640899658
train: epoch 66, loss 0.6899957656860352, acc=0.7013888955116272, loss=0.6899957656860352
test: epoch 66, loss 1.7654635906219482, acc=0.4000000059604645, loss=1.7654635906219482
train: epoch 67, loss 0.7200729250907898, acc=0.691277801990509, loss=0.7200729250907898
test: epoch 67, loss 1.7152411937713623, acc=0.4000000059604645, loss=1.7152411937713623
train: epoch 68, loss 0.6770545244216919, acc=0.707611083984375, loss=0.6770545244216919
test: epoch 68, loss 1.828018069267273, acc=0.38055557012557983, loss=1.828018069267273
train: epoch 69, loss 0.6901028752326965, acc=0.7056666612625122, loss=0.6901028752326965
test: epoch 69, loss 1.7646845579147339, acc=0.39722222089767456, loss=1.7646845579147339
train: epoch 70, loss 0.6756997108459473, acc=0.7088888883590698, loss=0.6756997108459473
test: epoch 70, loss 1.6914843320846558, acc=0.4000000059604645, loss=1.6914843320846558
train: epoch 71, loss 0.6892536282539368, acc=0.7051110863685608, loss=0.6892536282539368
test: epoch 71, loss 1.9486186504364014, acc=0.4027777910232544, loss=1.9486186504364014
train: epoch 72, loss 0.6986100673675537, acc=0.7003333568572998, loss=0.6986100673675537
test: epoch 72, loss 1.7276397943496704, acc=0.4055555462837219, loss=1.7276397943496704
train: epoch 73, loss 0.678784966468811, acc=0.7127777934074402, loss=0.678784966468811
test: epoch 73, loss 1.8122549057006836, acc=0.4000000059604645, loss=1.8122549057006836
train: epoch 74, loss 0.6901420950889587, acc=0.7054444551467896, loss=0.6901420950889587
test: epoch 74, loss 1.8047573566436768, acc=0.4000000059604645, loss=1.8047573566436768
train: epoch 75, loss 0.674429178237915, acc=0.7127222418785095, loss=0.674429178237915
test: epoch 75, loss 1.7340396642684937, acc=0.4027777910232544, loss=1.7340396642684937
train: epoch 76, loss 0.6754508018493652, acc=0.706333339214325, loss=0.6754508018493652
test: epoch 76, loss 1.7815375328063965, acc=0.4055555462837219, loss=1.7815375328063965
train: epoch 77, loss 0.675021767616272, acc=0.7113333344459534, loss=0.675021767616272
test: epoch 77, loss 1.9735063314437866, acc=0.39722222089767456, loss=1.9735063314437866
train: epoch 78, loss 0.6658058762550354, acc=0.7148333191871643, loss=0.6658058762550354
test: epoch 78, loss 1.7368190288543701, acc=0.4055555462837219, loss=1.7368190288543701
train: epoch 79, loss 0.679918646812439, acc=0.7121111154556274, loss=0.679918646812439
test: epoch 79, loss 1.7514363527297974, acc=0.4055555462837219, loss=1.7514363527297974
train: epoch 80, loss 0.6783831119537354, acc=0.7116110920906067, loss=0.6783831119537354
test: epoch 80, loss 1.8832597732543945, acc=0.4055555462837219, loss=1.8832597732543945
train: epoch 81, loss 0.6633959412574768, acc=0.7203333377838135, loss=0.6633959412574768
test: epoch 81, loss 1.8145288228988647, acc=0.4027777910232544, loss=1.8145288228988647
train: epoch 82, loss 0.6413847804069519, acc=0.7243333458900452, loss=0.6413847804069519
test: epoch 82, loss 1.7465705871582031, acc=0.4027777910232544, loss=1.7465705871582031
train: epoch 83, loss 0.6788722276687622, acc=0.7108888626098633, loss=0.6788722276687622
test: epoch 83, loss 1.8188660144805908, acc=0.4000000059604645, loss=1.8188660144805908
train: epoch 84, loss 0.6614018678665161, acc=0.7166110873222351, loss=0.6614018678665161
test: epoch 84, loss 1.7902491092681885, acc=0.3861111104488373, loss=1.7902491092681885
train: epoch 85, loss 0.6470751762390137, acc=0.7235000133514404, loss=0.6470751762390137
test: epoch 85, loss 1.8942267894744873, acc=0.4055555462837219, loss=1.8942267894744873
train: epoch 86, loss 0.6483463644981384, acc=0.7233333587646484, loss=0.6483463644981384
test: epoch 86, loss 1.6207410097122192, acc=0.4055555462837219, loss=1.6207410097122192
train: epoch 87, loss 0.6496926546096802, acc=0.7210555672645569, loss=0.6496926546096802
test: epoch 87, loss 1.9045336246490479, acc=0.4055555462837219, loss=1.9045336246490479
train: epoch 88, loss 0.6456751227378845, acc=0.7276666760444641, loss=0.6456751227378845
test: epoch 88, loss 1.9629273414611816, acc=0.4055555462837219, loss=1.9629273414611816
train: epoch 89, loss 0.6641552448272705, acc=0.7201111316680908, loss=0.6641552448272705
test: epoch 89, loss 1.8381644487380981, acc=0.4027777910232544, loss=1.8381644487380981
train: epoch 90, loss 0.6549671292304993, acc=0.7216110825538635, loss=0.6549671292304993
test: epoch 90, loss 1.8737461566925049, acc=0.4055555462837219, loss=1.8737461566925049
train: epoch 91, loss 0.6274879574775696, acc=0.7328888773918152, loss=0.6274879574775696
test: epoch 91, loss 1.7465370893478394, acc=0.4055555462837219, loss=1.7465370893478394
train: epoch 92, loss 0.6345459818840027, acc=0.7321666479110718, loss=0.6345459818840027
test: epoch 92, loss 1.8632107973098755, acc=0.4055555462837219, loss=1.8632107973098755
train: epoch 93, loss 0.64453125, acc=0.7304999828338623, loss=0.64453125
test: epoch 93, loss 1.9704971313476562, acc=0.4055555462837219, loss=1.9704971313476562
train: epoch 94, loss 0.6431276202201843, acc=0.72688889503479, loss=0.6431276202201843
test: epoch 94, loss 1.8037828207015991, acc=0.4027777910232544, loss=1.8037828207015991
train: epoch 95, loss 0.6307912468910217, acc=0.7306110858917236, loss=0.6307912468910217
test: epoch 95, loss 1.7301530838012695, acc=0.4055555462837219, loss=1.7301530838012695
train: epoch 96, loss 0.625361442565918, acc=0.7358888983726501, loss=0.625361442565918
test: epoch 96, loss 1.7996653318405151, acc=0.4027777910232544, loss=1.7996653318405151
train: epoch 97, loss 0.6240320801734924, acc=0.7369444370269775, loss=0.6240320801734924
test: epoch 97, loss 1.8563121557235718, acc=0.4055555462837219, loss=1.8563121557235718
train: epoch 98, loss 0.6218705773353577, acc=0.7355555295944214, loss=0.6218705773353577
test: epoch 98, loss 2.0727415084838867, acc=0.4055555462837219, loss=2.0727415084838867
train: epoch 99, loss 0.6401122212409973, acc=0.7310555577278137, loss=0.6401122212409973
test: epoch 99, loss 1.9112495183944702, acc=0.4055555462837219, loss=1.9112495183944702
train: epoch 100, loss 0.6406877040863037, acc=0.7294999957084656, loss=0.6406877040863037
test: epoch 100, loss 1.8141193389892578, acc=0.4027777910232544, loss=1.8141193389892578
train: epoch 101, loss 0.6427311301231384, acc=0.7244444489479065, loss=0.6427311301231384
test: epoch 101, loss 1.867797613143921, acc=0.4055555462837219, loss=1.867797613143921
train: epoch 102, loss 0.6303517818450928, acc=0.7327777743339539, loss=0.6303517818450928
test: epoch 102, loss 1.7457205057144165, acc=0.4027777910232544, loss=1.7457205057144165
train: epoch 103, loss 0.6110981106758118, acc=0.7411666512489319, loss=0.6110981106758118
test: epoch 103, loss 1.7391700744628906, acc=0.4027777910232544, loss=1.7391700744628906
train: epoch 104, loss 0.6148639917373657, acc=0.7385555505752563, loss=0.6148639917373657
test: epoch 104, loss 1.9882005453109741, acc=0.4027777910232544, loss=1.9882005453109741
train: epoch 105, loss 0.6202638149261475, acc=0.7397222518920898, loss=0.6202638149261475
test: epoch 105, loss 2.025428533554077, acc=0.4027777910232544, loss=2.025428533554077
train: epoch 106, loss 0.6218389272689819, acc=0.7406666874885559, loss=0.6218389272689819
test: epoch 106, loss 1.8314731121063232, acc=0.4055555462837219, loss=1.8314731121063232
train: epoch 107, loss 0.6092139482498169, acc=0.7421666383743286, loss=0.6092139482498169
test: epoch 107, loss 1.8816032409667969, acc=0.4027777910232544, loss=1.8816032409667969
train: epoch 108, loss 0.6112269163131714, acc=0.7404999732971191, loss=0.6112269163131714
test: epoch 108, loss 1.7020938396453857, acc=0.4055555462837219, loss=1.7020938396453857
train: epoch 109, loss 0.6173381209373474, acc=0.7396110892295837, loss=0.6173381209373474
test: epoch 109, loss 1.8835422992706299, acc=0.4055555462837219, loss=1.8835422992706299
train: epoch 110, loss 0.608708918094635, acc=0.7431111335754395, loss=0.608708918094635
test: epoch 110, loss 1.914652943611145, acc=0.4027777910232544, loss=1.914652943611145
train: epoch 111, loss 0.6059869527816772, acc=0.7458333373069763, loss=0.6059869527816772
test: epoch 111, loss 2.2067344188690186, acc=0.4055555462837219, loss=2.2067344188690186
train: epoch 112, loss 0.6205394268035889, acc=0.7364444732666016, loss=0.6205394268035889
test: epoch 112, loss 1.95469331741333, acc=0.4027777910232544, loss=1.95469331741333
train: epoch 113, loss 0.5988761782646179, acc=0.7491111159324646, loss=0.5988761782646179
test: epoch 113, loss 1.881622314453125, acc=0.4055555462837219, loss=1.881622314453125
train: epoch 114, loss 0.6029191613197327, acc=0.742888867855072, loss=0.6029191613197327
test: epoch 114, loss 1.9281498193740845, acc=0.4055555462837219, loss=1.9281498193740845
train: epoch 115, loss 0.6077370643615723, acc=0.746666669845581, loss=0.6077370643615723
test: epoch 115, loss 2.1311042308807373, acc=0.4055555462837219, loss=2.1311042308807373
train: epoch 116, loss 0.6000563502311707, acc=0.7483888864517212, loss=0.6000563502311707
test: epoch 116, loss 1.935317039489746, acc=0.4055555462837219, loss=1.935317039489746
train: epoch 117, loss 0.6189216375350952, acc=0.7385555505752563, loss=0.6189216375350952
test: epoch 117, loss 1.9990181922912598, acc=0.4055555462837219, loss=1.9990181922912598
train: epoch 118, loss 0.6181252598762512, acc=0.7375555634498596, loss=0.6181252598762512
test: epoch 118, loss 1.8713639974594116, acc=0.4055555462837219, loss=1.8713639974594116
train: epoch 119, loss 0.5938444137573242, acc=0.7469444274902344, loss=0.5938444137573242
test: epoch 119, loss 1.9237359762191772, acc=0.4055555462837219, loss=1.9237359762191772
train: epoch 120, loss 0.6165525913238525, acc=0.742888867855072, loss=0.6165525913238525
test: epoch 120, loss 1.9954643249511719, acc=0.4055555462837219, loss=1.9954643249511719
train: epoch 121, loss 0.6127890944480896, acc=0.7421666383743286, loss=0.6127890944480896
test: epoch 121, loss 1.8995335102081299, acc=0.4055555462837219, loss=1.8995335102081299
train: epoch 122, loss 0.6038049459457397, acc=0.7472222447395325, loss=0.6038049459457397
test: epoch 122, loss 1.9717880487442017, acc=0.4055555462837219, loss=1.9717880487442017
train: epoch 123, loss 0.6017847657203674, acc=0.745555579662323, loss=0.6017847657203674
test: epoch 123, loss 1.9033539295196533, acc=0.4027777910232544, loss=1.9033539295196533
train: epoch 124, loss 0.6002913117408752, acc=0.7477222084999084, loss=0.6002913117408752
test: epoch 124, loss 1.8457374572753906, acc=0.4055555462837219, loss=1.8457374572753906
train: epoch 125, loss 0.5905042290687561, acc=0.7488333582878113, loss=0.5905042290687561
test: epoch 125, loss 1.890067219734192, acc=0.4027777910232544, loss=1.890067219734192
train: epoch 126, loss 0.5952649712562561, acc=0.7475555539131165, loss=0.5952649712562561
test: epoch 126, loss 1.7643059492111206, acc=0.4166666567325592, loss=1.7643059492111206
train: epoch 127, loss 0.6008519530296326, acc=0.7482222318649292, loss=0.6008519530296326
test: epoch 127, loss 1.6638495922088623, acc=0.4055555462837219, loss=1.6638495922088623
train: epoch 128, loss 0.5879930257797241, acc=0.7513889074325562, loss=0.5879930257797241
test: epoch 128, loss 1.9196662902832031, acc=0.4138889014720917, loss=1.9196662902832031
train: epoch 129, loss 0.5978694558143616, acc=0.7507777810096741, loss=0.5978694558143616
test: epoch 129, loss 1.9314143657684326, acc=0.4055555462837219, loss=1.9314143657684326
train: epoch 130, loss 0.5955765843391418, acc=0.749833345413208, loss=0.5955765843391418
test: epoch 130, loss 1.9515575170516968, acc=0.4138889014720917, loss=1.9515575170516968
train: epoch 131, loss 0.5989851951599121, acc=0.7491111159324646, loss=0.5989851951599121
test: epoch 131, loss 2.0108048915863037, acc=0.4166666567325592, loss=2.0108048915863037
train: epoch 132, loss 0.6015528440475464, acc=0.7463889122009277, loss=0.6015528440475464
test: epoch 132, loss 1.9208247661590576, acc=0.4166666567325592, loss=1.9208247661590576
train: epoch 133, loss 0.5858895182609558, acc=0.7503888607025146, loss=0.5858895182609558
test: epoch 133, loss 1.8758885860443115, acc=0.4166666567325592, loss=1.8758885860443115
train: epoch 134, loss 0.5900789499282837, acc=0.7515000104904175, loss=0.5900789499282837
test: epoch 134, loss 1.9460865259170532, acc=0.4166666567325592, loss=1.9460865259170532
train: epoch 135, loss 0.5896068215370178, acc=0.7485555410385132, loss=0.5896068215370178
test: epoch 135, loss 1.8372037410736084, acc=0.4166666567325592, loss=1.8372037410736084
train: epoch 136, loss 0.596187174320221, acc=0.7473888993263245, loss=0.596187174320221
test: epoch 136, loss 1.9670305252075195, acc=0.4166666567325592, loss=1.9670305252075195
train: epoch 137, loss 0.5897710919380188, acc=0.750166654586792, loss=0.5897710919380188
test: epoch 137, loss 1.783152461051941, acc=0.4138889014720917, loss=1.783152461051941
train: epoch 138, loss 0.6016672253608704, acc=0.7452222108840942, loss=0.6016672253608704
test: epoch 138, loss 1.7913343906402588, acc=0.4166666567325592, loss=1.7913343906402588
train: epoch 139, loss 0.6024120450019836, acc=0.7431666851043701, loss=0.6024120450019836
test: epoch 139, loss 2.0751547813415527, acc=0.4138889014720917, loss=2.0751547813415527
train: epoch 140, loss 0.5987061858177185, acc=0.7476666569709778, loss=0.5987061858177185
test: epoch 140, loss 1.91990327835083, acc=0.4138889014720917, loss=1.91990327835083
train: epoch 141, loss 0.5842611193656921, acc=0.7540000081062317, loss=0.5842611193656921
test: epoch 141, loss 2.0468626022338867, acc=0.4138889014720917, loss=2.0468626022338867
train: epoch 142, loss 0.5902039408683777, acc=0.7515555620193481, loss=0.5902039408683777
test: epoch 142, loss 1.9091241359710693, acc=0.4138889014720917, loss=1.9091241359710693
train: epoch 143, loss 0.5819670557975769, acc=0.7540000081062317, loss=0.5819670557975769
test: epoch 143, loss 1.8983039855957031, acc=0.4166666567325592, loss=1.8983039855957031
train: epoch 144, loss 0.593675434589386, acc=0.7492222189903259, loss=0.593675434589386
test: epoch 144, loss 1.838763952255249, acc=0.4138889014720917, loss=1.838763952255249
train: epoch 145, loss 0.5933279991149902, acc=0.750166654586792, loss=0.5933279991149902
test: epoch 145, loss 1.8738502264022827, acc=0.4166666567325592, loss=1.8738502264022827
train: epoch 146, loss 0.5956449508666992, acc=0.746999979019165, loss=0.5956449508666992
test: epoch 146, loss 1.810314655303955, acc=0.4138889014720917, loss=1.810314655303955
train: epoch 147, loss 0.5763841271400452, acc=0.7565000057220459, loss=0.5763841271400452
test: epoch 147, loss 1.9075794219970703, acc=0.4166666567325592, loss=1.9075794219970703
train: epoch 148, loss 0.5801093578338623, acc=0.753333330154419, loss=0.5801093578338623
test: epoch 148, loss 1.9221808910369873, acc=0.4138889014720917, loss=1.9221808910369873
train: epoch 149, loss 0.5841038227081299, acc=0.7520555257797241, loss=0.5841038227081299
test: epoch 149, loss 1.970055341720581, acc=0.4166666567325592, loss=1.970055341720581
train: epoch 150, loss 0.5718714594841003, acc=0.7571666836738586, loss=0.5718714594841003
test: epoch 150, loss 1.892155647277832, acc=0.4166666567325592, loss=1.892155647277832
