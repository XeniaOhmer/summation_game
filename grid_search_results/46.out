# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=1", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=1086558811, receiver_embed_dim=32, save_run=0, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1086558811, receiver_embed_dim=32, save_run=False, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.3588247299194336, acc=0.05622222274541855, loss=3.3588247299194336
test: epoch 1, loss 4.513406753540039, acc=0.06666667014360428, loss=4.513406753540039
train: epoch 2, loss 2.6332170963287354, acc=0.15772221982479095, loss=2.6332170963287354
test: epoch 2, loss 5.5886759757995605, acc=0.06666667014360428, loss=5.5886759757995605
train: epoch 3, loss 1.9571971893310547, acc=0.31466665863990784, loss=1.9571971893310547
test: epoch 3, loss 6.067721843719482, acc=0.08611111342906952, loss=6.067721843719482
train: epoch 4, loss 1.566896915435791, acc=0.429111123085022, loss=1.566896915435791
test: epoch 4, loss 5.761620044708252, acc=0.11666666716337204, loss=5.761620044708252
train: epoch 5, loss 1.3260127305984497, acc=0.5053333044052124, loss=1.3260127305984497
test: epoch 5, loss 5.693942546844482, acc=0.10277777910232544, loss=5.693942546844482
train: epoch 6, loss 1.136473536491394, acc=0.5789444446563721, loss=1.136473536491394
test: epoch 6, loss 5.992132663726807, acc=0.12777778506278992, loss=5.992132663726807
train: epoch 7, loss 0.995667040348053, acc=0.6375555396080017, loss=0.995667040348053
test: epoch 7, loss 5.350952625274658, acc=0.13611111044883728, loss=5.350952625274658
train: epoch 8, loss 0.8927580714225769, acc=0.6840555667877197, loss=0.8927580714225769
test: epoch 8, loss 4.802639007568359, acc=0.16111111640930176, loss=4.802639007568359
train: epoch 9, loss 0.7864079475402832, acc=0.7166666388511658, loss=0.7864079475402832
test: epoch 9, loss 4.9820427894592285, acc=0.20000000298023224, loss=4.9820427894592285
train: epoch 10, loss 0.7231826782226562, acc=0.7448889017105103, loss=0.7231826782226562
test: epoch 10, loss 4.489761829376221, acc=0.1944444477558136, loss=4.489761829376221
train: epoch 11, loss 0.6740514039993286, acc=0.7682222127914429, loss=0.6740514039993286
test: epoch 11, loss 4.570723056793213, acc=0.19722221791744232, loss=4.570723056793213
train: epoch 12, loss 0.636918306350708, acc=0.784333348274231, loss=0.636918306350708
test: epoch 12, loss 4.053178787231445, acc=0.23055554926395416, loss=4.053178787231445
train: epoch 13, loss 0.58577960729599, acc=0.7980555295944214, loss=0.58577960729599
test: epoch 13, loss 4.242134094238281, acc=0.21666666865348816, loss=4.242134094238281
train: epoch 14, loss 0.5739434361457825, acc=0.8057222366333008, loss=0.5739434361457825
test: epoch 14, loss 3.8547492027282715, acc=0.22499999403953552, loss=3.8547492027282715
train: epoch 15, loss 0.5306735038757324, acc=0.8194444179534912, loss=0.5306735038757324
test: epoch 15, loss 3.7439799308776855, acc=0.24444444477558136, loss=3.7439799308776855
train: epoch 16, loss 0.49855998158454895, acc=0.8343333601951599, loss=0.49855998158454895
test: epoch 16, loss 3.728407859802246, acc=0.24722221493721008, loss=3.728407859802246
train: epoch 17, loss 0.4966852366924286, acc=0.831944465637207, loss=0.4966852366924286
test: epoch 17, loss 3.6374669075012207, acc=0.24722221493721008, loss=3.6374669075012207
train: epoch 18, loss 0.4591376781463623, acc=0.843666672706604, loss=0.4591376781463623
test: epoch 18, loss 3.4771885871887207, acc=0.25, loss=3.4771885871887207
train: epoch 19, loss 0.44625553488731384, acc=0.8512222170829773, loss=0.44625553488731384
test: epoch 19, loss 3.2319235801696777, acc=0.2611111104488373, loss=3.2319235801696777
train: epoch 20, loss 0.4502265155315399, acc=0.8514999747276306, loss=0.4502265155315399
test: epoch 20, loss 3.3312296867370605, acc=0.2666666805744171, loss=3.3312296867370605
train: epoch 21, loss 0.41685745120048523, acc=0.8627777695655823, loss=0.41685745120048523
test: epoch 21, loss 3.147158622741699, acc=0.26944443583488464, loss=3.147158622741699
train: epoch 22, loss 0.39863547682762146, acc=0.8686666488647461, loss=0.39863547682762146
test: epoch 22, loss 3.3242175579071045, acc=0.2750000059604645, loss=3.3242175579071045
train: epoch 23, loss 0.39338168501853943, acc=0.8669999837875366, loss=0.39338168501853943
test: epoch 23, loss 3.0307841300964355, acc=0.2638888955116272, loss=3.0307841300964355
train: epoch 24, loss 0.36724504828453064, acc=0.8774999976158142, loss=0.36724504828453064
test: epoch 24, loss 2.8540053367614746, acc=0.28611111640930176, loss=2.8540053367614746
train: epoch 25, loss 0.369324266910553, acc=0.8798888921737671, loss=0.369324266910553
test: epoch 25, loss 2.697662115097046, acc=0.34166666865348816, loss=2.697662115097046
train: epoch 26, loss 0.35764676332473755, acc=0.8826666474342346, loss=0.35764676332473755
test: epoch 26, loss 2.6442654132843018, acc=0.2888889014720917, loss=2.6442654132843018
train: epoch 27, loss 0.3513014316558838, acc=0.8855555653572083, loss=0.3513014316558838
test: epoch 27, loss 2.7624807357788086, acc=0.28611111640930176, loss=2.7624807357788086
train: epoch 28, loss 0.338641494512558, acc=0.891777753829956, loss=0.338641494512558
test: epoch 28, loss 2.7587907314300537, acc=0.27222222089767456, loss=2.7587907314300537
train: epoch 29, loss 0.3392755687236786, acc=0.8884999752044678, loss=0.3392755687236786
test: epoch 29, loss 2.5083441734313965, acc=0.35277777910232544, loss=2.5083441734313965
train: epoch 30, loss 0.34685641527175903, acc=0.8896111249923706, loss=0.34685641527175903
test: epoch 30, loss 2.556748390197754, acc=0.3194444477558136, loss=2.556748390197754
train: epoch 31, loss 0.3238927721977234, acc=0.8967777490615845, loss=0.3238927721977234
test: epoch 31, loss 2.5728936195373535, acc=0.2750000059604645, loss=2.5728936195373535
train: epoch 32, loss 0.3143695890903473, acc=0.8996111154556274, loss=0.3143695890903473
test: epoch 32, loss 2.4297854900360107, acc=0.2944444417953491, loss=2.4297854900360107
train: epoch 33, loss 0.3127914071083069, acc=0.9008888602256775, loss=0.3127914071083069
test: epoch 33, loss 2.2870941162109375, acc=0.35277777910232544, loss=2.2870941162109375
train: epoch 34, loss 0.3116700053215027, acc=0.8991666436195374, loss=0.3116700053215027
test: epoch 34, loss 2.3113582134246826, acc=0.3472222089767456, loss=2.3113582134246826
train: epoch 35, loss 0.2950277030467987, acc=0.9043889045715332, loss=0.2950277030467987
test: epoch 35, loss 2.3315112590789795, acc=0.3333333432674408, loss=2.3315112590789795
train: epoch 36, loss 0.2904464304447174, acc=0.9067222476005554, loss=0.2904464304447174
test: epoch 36, loss 2.2786078453063965, acc=0.32499998807907104, loss=2.2786078453063965
train: epoch 37, loss 0.29875651001930237, acc=0.9068889021873474, loss=0.29875651001930237
test: epoch 37, loss 2.1480112075805664, acc=0.3638888895511627, loss=2.1480112075805664
train: epoch 38, loss 0.29016488790512085, acc=0.9072777628898621, loss=0.29016488790512085
test: epoch 38, loss 2.098757028579712, acc=0.3361110985279083, loss=2.098757028579712
train: epoch 39, loss 0.27617108821868896, acc=0.9128333330154419, loss=0.27617108821868896
test: epoch 39, loss 2.132002592086792, acc=0.3499999940395355, loss=2.132002592086792
train: epoch 40, loss 0.2792503535747528, acc=0.9120000004768372, loss=0.2792503535747528
test: epoch 40, loss 2.262239933013916, acc=0.3333333432674408, loss=2.262239933013916
train: epoch 41, loss 0.26601678133010864, acc=0.9127222299575806, loss=0.26601678133010864
test: epoch 41, loss 2.037426233291626, acc=0.32777777314186096, loss=2.037426233291626
train: epoch 42, loss 0.2779897451400757, acc=0.9133333563804626, loss=0.2779897451400757
test: epoch 42, loss 1.9937281608581543, acc=0.34166666865348816, loss=1.9937281608581543
train: epoch 43, loss 0.25752636790275574, acc=0.9137222170829773, loss=0.25752636790275574
test: epoch 43, loss 2.077052593231201, acc=0.34166666865348816, loss=2.077052593231201
train: epoch 44, loss 0.26816731691360474, acc=0.9152777791023254, loss=0.26816731691360474
test: epoch 44, loss 1.9796791076660156, acc=0.36666667461395264, loss=1.9796791076660156
train: epoch 45, loss 0.2679380476474762, acc=0.9166111350059509, loss=0.2679380476474762
test: epoch 45, loss 2.0440287590026855, acc=0.3916666805744171, loss=2.0440287590026855
train: epoch 46, loss 0.256141722202301, acc=0.9170555472373962, loss=0.256141722202301
test: epoch 46, loss 1.8537266254425049, acc=0.39722222089767456, loss=1.8537266254425049
train: epoch 47, loss 0.2636726200580597, acc=0.914555549621582, loss=0.2636726200580597
test: epoch 47, loss 1.8891472816467285, acc=0.35277777910232544, loss=1.8891472816467285
train: epoch 48, loss 0.23594340682029724, acc=0.9194444417953491, loss=0.23594340682029724
test: epoch 48, loss 1.9094085693359375, acc=0.36944442987442017, loss=1.9094085693359375
train: epoch 49, loss 0.24427348375320435, acc=0.9220555424690247, loss=0.24427348375320435
test: epoch 49, loss 2.016599655151367, acc=0.3583333194255829, loss=2.016599655151367
train: epoch 50, loss 0.23954501748085022, acc=0.9231111407279968, loss=0.23954501748085022
test: epoch 50, loss 1.8187179565429688, acc=0.36666667461395264, loss=1.8187179565429688
train: epoch 51, loss 0.2414490431547165, acc=0.9233333468437195, loss=0.2414490431547165
test: epoch 51, loss 1.7868025302886963, acc=0.4277777671813965, loss=1.7868025302886963
train: epoch 52, loss 0.23641282320022583, acc=0.9247221946716309, loss=0.23641282320022583
test: epoch 52, loss 1.7438229322433472, acc=0.43888887763023376, loss=1.7438229322433472
train: epoch 53, loss 0.2366059124469757, acc=0.925944447517395, loss=0.2366059124469757
test: epoch 53, loss 1.6985050439834595, acc=0.42500001192092896, loss=1.6985050439834595
train: epoch 54, loss 0.2308807671070099, acc=0.9243888854980469, loss=0.2308807671070099
test: epoch 54, loss 1.664003849029541, acc=0.4277777671813965, loss=1.664003849029541
train: epoch 55, loss 0.235835462808609, acc=0.9237777590751648, loss=0.235835462808609
test: epoch 55, loss 1.9793998003005981, acc=0.39444443583488464, loss=1.9793998003005981
train: epoch 56, loss 0.23118892312049866, acc=0.9293333292007446, loss=0.23118892312049866
test: epoch 56, loss 1.567260980606079, acc=0.42500001192092896, loss=1.567260980606079
train: epoch 57, loss 0.2259606122970581, acc=0.9278888702392578, loss=0.2259606122970581
test: epoch 57, loss 1.5902886390686035, acc=0.40833333134651184, loss=1.5902886390686035
train: epoch 58, loss 0.2207144945859909, acc=0.9273333549499512, loss=0.2207144945859909
test: epoch 58, loss 1.5313620567321777, acc=0.4472222328186035, loss=1.5313620567321777
train: epoch 59, loss 0.22178886830806732, acc=0.9287777543067932, loss=0.22178886830806732
test: epoch 59, loss 1.6067322492599487, acc=0.45277777314186096, loss=1.6067322492599487
train: epoch 60, loss 0.21405433118343353, acc=0.9331666827201843, loss=0.21405433118343353
test: epoch 60, loss 1.6634306907653809, acc=0.4305555522441864, loss=1.6634306907653809
train: epoch 61, loss 0.2112819105386734, acc=0.933555543422699, loss=0.2112819105386734
test: epoch 61, loss 1.5851709842681885, acc=0.4583333432674408, loss=1.5851709842681885
train: epoch 62, loss 0.22267787158489227, acc=0.9279999732971191, loss=0.22267787158489227
test: epoch 62, loss 1.5307902097702026, acc=0.4444444477558136, loss=1.5307902097702026
train: epoch 63, loss 0.2171173393726349, acc=0.9307777881622314, loss=0.2171173393726349
test: epoch 63, loss 1.5206706523895264, acc=0.4694444537162781, loss=1.5206706523895264
train: epoch 64, loss 0.21897025406360626, acc=0.9319999814033508, loss=0.21897025406360626
test: epoch 64, loss 1.4908993244171143, acc=0.45277777314186096, loss=1.4908993244171143
train: epoch 65, loss 0.21075738966464996, acc=0.9318888783454895, loss=0.21075738966464996
test: epoch 65, loss 1.5198123455047607, acc=0.47777777910232544, loss=1.5198123455047607
train: epoch 66, loss 0.20736220479011536, acc=0.9328333139419556, loss=0.20736220479011536
test: epoch 66, loss 1.5060964822769165, acc=0.46388888359069824, loss=1.5060964822769165
train: epoch 67, loss 0.21276119351387024, acc=0.9325555562973022, loss=0.21276119351387024
test: epoch 67, loss 1.4607638120651245, acc=0.46666666865348816, loss=1.4607638120651245
train: epoch 68, loss 0.21523940563201904, acc=0.933722198009491, loss=0.21523940563201904
test: epoch 68, loss 1.5432312488555908, acc=0.43888887763023376, loss=1.5432312488555908
train: epoch 69, loss 0.20517262816429138, acc=0.9325555562973022, loss=0.20517262816429138
test: epoch 69, loss 1.5959759950637817, acc=0.46388888359069824, loss=1.5959759950637817
train: epoch 70, loss 0.1995491087436676, acc=0.9355000257492065, loss=0.1995491087436676
test: epoch 70, loss 1.6502472162246704, acc=0.4416666626930237, loss=1.6502472162246704
train: epoch 71, loss 0.20312578976154327, acc=0.9350555539131165, loss=0.20312578976154327
test: epoch 71, loss 1.4397342205047607, acc=0.4722222089767456, loss=1.4397342205047607
train: epoch 72, loss 0.19827179610729218, acc=0.937333345413208, loss=0.19827179610729218
test: epoch 72, loss 1.484084129333496, acc=0.49166667461395264, loss=1.484084129333496
train: epoch 73, loss 0.20020973682403564, acc=0.9376111030578613, loss=0.20020973682403564
test: epoch 73, loss 1.4199408292770386, acc=0.4972222149372101, loss=1.4199408292770386
train: epoch 74, loss 0.19392026960849762, acc=0.9361110925674438, loss=0.19392026960849762
test: epoch 74, loss 1.4872676134109497, acc=0.4694444537162781, loss=1.4872676134109497
train: epoch 75, loss 0.20059384405612946, acc=0.9366666674613953, loss=0.20059384405612946
test: epoch 75, loss 1.4436503648757935, acc=0.46666666865348816, loss=1.4436503648757935
train: epoch 76, loss 0.2003500908613205, acc=0.9388889074325562, loss=0.2003500908613205
test: epoch 76, loss 1.4151344299316406, acc=0.5055555701255798, loss=1.4151344299316406
train: epoch 77, loss 0.1940353512763977, acc=0.9401666522026062, loss=0.1940353512763977
test: epoch 77, loss 1.5733240842819214, acc=0.4833333194255829, loss=1.5733240842819214
train: epoch 78, loss 0.18964362144470215, acc=0.9402777552604675, loss=0.18964362144470215
test: epoch 78, loss 1.489863395690918, acc=0.5138888955116272, loss=1.489863395690918
train: epoch 79, loss 0.19014449417591095, acc=0.9393333196640015, loss=0.19014449417591095
test: epoch 79, loss 1.3486689329147339, acc=0.49166667461395264, loss=1.3486689329147339
train: epoch 80, loss 0.18917088210582733, acc=0.9403889179229736, loss=0.18917088210582733
test: epoch 80, loss 1.380277395248413, acc=0.4972222149372101, loss=1.380277395248413
train: epoch 81, loss 0.17703962326049805, acc=0.9408888816833496, loss=0.17703962326049805
test: epoch 81, loss 1.2188348770141602, acc=0.5388888716697693, loss=1.2188348770141602
train: epoch 82, loss 0.19702032208442688, acc=0.9376111030578613, loss=0.19702032208442688
test: epoch 82, loss 1.4017550945281982, acc=0.519444465637207, loss=1.4017550945281982
train: epoch 83, loss 0.17783279716968536, acc=0.9439444541931152, loss=0.17783279716968536
test: epoch 83, loss 1.3523201942443848, acc=0.5138888955116272, loss=1.3523201942443848
train: epoch 84, loss 0.1905839890241623, acc=0.9399999976158142, loss=0.1905839890241623
test: epoch 84, loss 1.3854575157165527, acc=0.5388888716697693, loss=1.3854575157165527
train: epoch 85, loss 0.1741335391998291, acc=0.9441666603088379, loss=0.1741335391998291
test: epoch 85, loss 1.3736432790756226, acc=0.5277777910232544, loss=1.3736432790756226
train: epoch 86, loss 0.1788029670715332, acc=0.9441111087799072, loss=0.1788029670715332
test: epoch 86, loss 1.2605493068695068, acc=0.5666666626930237, loss=1.2605493068695068
train: epoch 87, loss 0.16410501301288605, acc=0.9463889002799988, loss=0.16410501301288605
test: epoch 87, loss 1.3061819076538086, acc=0.5583333373069763, loss=1.3061819076538086
train: epoch 88, loss 0.1756071001291275, acc=0.944611132144928, loss=0.1756071001291275
test: epoch 88, loss 1.3320420980453491, acc=0.5472221970558167, loss=1.3320420980453491
train: epoch 89, loss 0.1735667735338211, acc=0.941611111164093, loss=0.1735667735338211
test: epoch 89, loss 1.268454909324646, acc=0.5694444179534912, loss=1.268454909324646
train: epoch 90, loss 0.16945524513721466, acc=0.9465000033378601, loss=0.16945524513721466
test: epoch 90, loss 1.3106118440628052, acc=0.5305555462837219, loss=1.3106118440628052
train: epoch 91, loss 0.16155584156513214, acc=0.9470000267028809, loss=0.16155584156513214
test: epoch 91, loss 1.4382362365722656, acc=0.5694444179534912, loss=1.4382362365722656
train: epoch 92, loss 0.18325114250183105, acc=0.9433333277702332, loss=0.18325114250183105
test: epoch 92, loss 1.179044246673584, acc=0.5777778029441833, loss=1.179044246673584
train: epoch 93, loss 0.17108899354934692, acc=0.944944441318512, loss=0.17108899354934692
test: epoch 93, loss 1.1545928716659546, acc=0.5805555582046509, loss=1.1545928716659546
train: epoch 94, loss 0.16556181013584137, acc=0.9437222480773926, loss=0.16556181013584137
test: epoch 94, loss 1.373329520225525, acc=0.5638889074325562, loss=1.373329520225525
train: epoch 95, loss 0.1617453694343567, acc=0.9489444494247437, loss=0.1617453694343567
test: epoch 95, loss 1.375769019126892, acc=0.5805555582046509, loss=1.375769019126892
train: epoch 96, loss 0.17065081000328064, acc=0.9471111297607422, loss=0.17065081000328064
test: epoch 96, loss 1.1820478439331055, acc=0.5777778029441833, loss=1.1820478439331055
train: epoch 97, loss 0.17169316112995148, acc=0.9436666369438171, loss=0.17169316112995148
test: epoch 97, loss 1.2462977170944214, acc=0.5805555582046509, loss=1.2462977170944214
train: epoch 98, loss 0.16404850780963898, acc=0.9451666474342346, loss=0.16404850780963898
test: epoch 98, loss 1.174117088317871, acc=0.6027777791023254, loss=1.174117088317871
train: epoch 99, loss 0.16502828896045685, acc=0.9470000267028809, loss=0.16502828896045685
test: epoch 99, loss 1.1157256364822388, acc=0.6138888597488403, loss=1.1157256364822388
train: epoch 100, loss 0.15436379611492157, acc=0.9486111402511597, loss=0.15436379611492157
test: epoch 100, loss 1.2237565517425537, acc=0.5916666388511658, loss=1.2237565517425537
train: epoch 101, loss 0.16036921739578247, acc=0.9463889002799988, loss=0.16036921739578247
test: epoch 101, loss 1.1158065795898438, acc=0.6083333492279053, loss=1.1158065795898438
train: epoch 102, loss 0.15366947650909424, acc=0.9491666555404663, loss=0.15366947650909424
test: epoch 102, loss 1.2316139936447144, acc=0.5555555820465088, loss=1.2316139936447144
train: epoch 103, loss 0.16225369274616241, acc=0.9458333253860474, loss=0.16225369274616241
test: epoch 103, loss 1.1262593269348145, acc=0.6194444298744202, loss=1.1262593269348145
train: epoch 104, loss 0.15792322158813477, acc=0.949055552482605, loss=0.15792322158813477
test: epoch 104, loss 1.180284857749939, acc=0.605555534362793, loss=1.180284857749939
train: epoch 105, loss 0.14752909541130066, acc=0.9511111378669739, loss=0.14752909541130066
test: epoch 105, loss 1.1822608709335327, acc=0.625, loss=1.1822608709335327
train: epoch 106, loss 0.16141919791698456, acc=0.9508333206176758, loss=0.16141919791698456
test: epoch 106, loss 1.1152563095092773, acc=0.6388888955116272, loss=1.1152563095092773
train: epoch 107, loss 0.16967381536960602, acc=0.9497777819633484, loss=0.16967381536960602
test: epoch 107, loss 0.9914767742156982, acc=0.6277777552604675, loss=0.9914767742156982
train: epoch 108, loss 0.1522519439458847, acc=0.9508333206176758, loss=0.1522519439458847
test: epoch 108, loss 1.0049972534179688, acc=0.6333333253860474, loss=1.0049972534179688
train: epoch 109, loss 0.1550033837556839, acc=0.9527778029441833, loss=0.1550033837556839
test: epoch 109, loss 0.992943286895752, acc=0.6555555462837219, loss=0.992943286895752
train: epoch 110, loss 0.15044118463993073, acc=0.9512222409248352, loss=0.15044118463993073
test: epoch 110, loss 1.1290603876113892, acc=0.6194444298744202, loss=1.1290603876113892
train: epoch 111, loss 0.15984444320201874, acc=0.9512777924537659, loss=0.15984444320201874
test: epoch 111, loss 1.0219694375991821, acc=0.6611111164093018, loss=1.0219694375991821
train: epoch 112, loss 0.14285479485988617, acc=0.9518333077430725, loss=0.14285479485988617
test: epoch 112, loss 0.9806381464004517, acc=0.6611111164093018, loss=0.9806381464004517
train: epoch 113, loss 0.1420166790485382, acc=0.9531111121177673, loss=0.1420166790485382
test: epoch 113, loss 1.0973005294799805, acc=0.6499999761581421, loss=1.0973005294799805
train: epoch 114, loss 0.14543774724006653, acc=0.9509999752044678, loss=0.14543774724006653
test: epoch 114, loss 1.0042004585266113, acc=0.6583333611488342, loss=1.0042004585266113
train: epoch 115, loss 0.1503167450428009, acc=0.9505000114440918, loss=0.1503167450428009
test: epoch 115, loss 1.0258501768112183, acc=0.6611111164093018, loss=1.0258501768112183
train: epoch 116, loss 0.1436489075422287, acc=0.9517222046852112, loss=0.1436489075422287
test: epoch 116, loss 1.1434818506240845, acc=0.6555555462837219, loss=1.1434818506240845
train: epoch 117, loss 0.1455169916152954, acc=0.9518888592720032, loss=0.1455169916152954
test: epoch 117, loss 0.876007616519928, acc=0.7055555582046509, loss=0.876007616519928
train: epoch 118, loss 0.13928718864917755, acc=0.9531111121177673, loss=0.13928718864917755
test: epoch 118, loss 0.8665236234664917, acc=0.7333333492279053, loss=0.8665236234664917
train: epoch 119, loss 0.1383177936077118, acc=0.9559999704360962, loss=0.1383177936077118
test: epoch 119, loss 0.8015126585960388, acc=0.7138888835906982, loss=0.8015126585960388
train: epoch 120, loss 0.1485183984041214, acc=0.952833354473114, loss=0.1485183984041214
test: epoch 120, loss 0.9683464169502258, acc=0.6805555820465088, loss=0.9683464169502258
train: epoch 121, loss 0.13929124176502228, acc=0.9545555710792542, loss=0.13929124176502228
test: epoch 121, loss 0.8988087177276611, acc=0.6944444179534912, loss=0.8988087177276611
train: epoch 122, loss 0.1447325050830841, acc=0.9542222023010254, loss=0.1447325050830841
test: epoch 122, loss 0.7768307328224182, acc=0.7444444298744202, loss=0.7768307328224182
train: epoch 123, loss 0.15706773102283478, acc=0.9518888592720032, loss=0.15706773102283478
test: epoch 123, loss 0.8391303420066833, acc=0.7222222089767456, loss=0.8391303420066833
train: epoch 124, loss 0.14066831767559052, acc=0.9556111097335815, loss=0.14066831767559052
test: epoch 124, loss 0.8634962439537048, acc=0.7222222089767456, loss=0.8634962439537048
train: epoch 125, loss 0.14185264706611633, acc=0.9538333415985107, loss=0.14185264706611633
test: epoch 125, loss 0.8705729246139526, acc=0.7250000238418579, loss=0.8705729246139526
train: epoch 126, loss 0.13763220608234406, acc=0.9563888907432556, loss=0.13763220608234406
test: epoch 126, loss 0.7117214798927307, acc=0.7611111402511597, loss=0.7117214798927307
train: epoch 127, loss 0.1396467089653015, acc=0.9542222023010254, loss=0.1396467089653015
test: epoch 127, loss 0.8258017897605896, acc=0.7277777791023254, loss=0.8258017897605896
train: epoch 128, loss 0.136076420545578, acc=0.9556111097335815, loss=0.136076420545578
test: epoch 128, loss 0.688046932220459, acc=0.7555555701255798, loss=0.688046932220459
train: epoch 129, loss 0.12769293785095215, acc=0.9586111307144165, loss=0.12769293785095215
test: epoch 129, loss 0.6722372174263, acc=0.7749999761581421, loss=0.6722372174263
train: epoch 130, loss 0.13877324759960175, acc=0.9559444189071655, loss=0.13877324759960175
test: epoch 130, loss 0.7182385325431824, acc=0.7833333611488342, loss=0.7182385325431824
train: epoch 131, loss 0.1309504508972168, acc=0.9578889012336731, loss=0.1309504508972168
test: epoch 131, loss 0.8332107663154602, acc=0.75, loss=0.8332107663154602
train: epoch 132, loss 0.12264925241470337, acc=0.9601666927337646, loss=0.12264925241470337
test: epoch 132, loss 0.7256965637207031, acc=0.7805555462837219, loss=0.7256965637207031
train: epoch 133, loss 0.15561926364898682, acc=0.9573333263397217, loss=0.15561926364898682
test: epoch 133, loss 0.6783294677734375, acc=0.7916666865348816, loss=0.6783294677734375
train: epoch 134, loss 0.13092732429504395, acc=0.9589999914169312, loss=0.13092732429504395
test: epoch 134, loss 0.5989094972610474, acc=0.7861111164093018, loss=0.5989094972610474
train: epoch 135, loss 0.1246761903166771, acc=0.9612777829170227, loss=0.1246761903166771
test: epoch 135, loss 0.6897948384284973, acc=0.7916666865348816, loss=0.6897948384284973
train: epoch 136, loss 0.12922877073287964, acc=0.96061110496521, loss=0.12922877073287964
test: epoch 136, loss 0.6496663689613342, acc=0.7888888716697693, loss=0.6496663689613342
train: epoch 137, loss 0.11675598472356796, acc=0.9631111025810242, loss=0.11675598472356796
test: epoch 137, loss 0.6147415041923523, acc=0.7749999761581421, loss=0.6147415041923523
train: epoch 138, loss 0.12863339483737946, acc=0.9605555534362793, loss=0.12863339483737946
test: epoch 138, loss 0.7303072214126587, acc=0.7638888955116272, loss=0.7303072214126587
train: epoch 139, loss 0.12260828912258148, acc=0.9608333110809326, loss=0.12260828912258148
test: epoch 139, loss 0.651700496673584, acc=0.769444465637207, loss=0.651700496673584
train: epoch 140, loss 0.1177644357085228, acc=0.9622222185134888, loss=0.1177644357085228
test: epoch 140, loss 0.6604440808296204, acc=0.7972221970558167, loss=0.6604440808296204
train: epoch 141, loss 0.11558874696493149, acc=0.9651666879653931, loss=0.11558874696493149
test: epoch 141, loss 0.6908515095710754, acc=0.7805555462837219, loss=0.6908515095710754
train: epoch 142, loss 0.12922245264053345, acc=0.9610000252723694, loss=0.12922245264053345
test: epoch 142, loss 0.6383907794952393, acc=0.800000011920929, loss=0.6383907794952393
train: epoch 143, loss 0.12595568597316742, acc=0.9622777700424194, loss=0.12595568597316742
test: epoch 143, loss 0.533808708190918, acc=0.8166666626930237, loss=0.533808708190918
train: epoch 144, loss 0.12420513480901718, acc=0.9634444713592529, loss=0.12420513480901718
test: epoch 144, loss 0.45593711733818054, acc=0.8222222328186035, loss=0.45593711733818054
train: epoch 145, loss 0.11867769062519073, acc=0.9622222185134888, loss=0.11867769062519073
test: epoch 145, loss 0.46433505415916443, acc=0.8194444179534912, loss=0.46433505415916443
train: epoch 146, loss 0.12254250049591064, acc=0.9643333554267883, loss=0.12254250049591064
test: epoch 146, loss 0.4795111119747162, acc=0.8222222328186035, loss=0.4795111119747162
train: epoch 147, loss 0.10707638412714005, acc=0.9674444198608398, loss=0.10707638412714005
test: epoch 147, loss 0.461535781621933, acc=0.855555534362793, loss=0.461535781621933
train: epoch 148, loss 0.1062621921300888, acc=0.967555582523346, loss=0.1062621921300888
test: epoch 148, loss 0.4746457636356354, acc=0.8361111283302307, loss=0.4746457636356354
train: epoch 149, loss 0.10771609097719193, acc=0.964888870716095, loss=0.10771609097719193
test: epoch 149, loss 0.41141781210899353, acc=0.8472222089767456, loss=0.41141781210899353
train: epoch 150, loss 0.13095198571681976, acc=0.9627222418785095, loss=0.13095198571681976
test: epoch 150, loss 0.5118416547775269, acc=0.8333333134651184, loss=0.5118416547775269
