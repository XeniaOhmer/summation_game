# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=false", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=2025152177, receiver_embed_dim=32, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.0593783855438232, acc=0.0889444425702095, loss=3.0593783855438232
test: epoch 1, loss 3.822604179382324, acc=0.10000000149011612, loss=3.822604179382324
train: epoch 2, loss 1.9957197904586792, acc=0.2579444348812103, loss=1.9957197904586792
test: epoch 2, loss 3.781229019165039, acc=0.11944444477558136, loss=3.781229019165039
train: epoch 3, loss 1.568114995956421, acc=0.3941666781902313, loss=1.568114995956421
test: epoch 3, loss 4.8442206382751465, acc=0.1111111119389534, loss=4.8442206382751465
train: epoch 4, loss 1.3206753730773926, acc=0.4741666615009308, loss=1.3206753730773926
test: epoch 4, loss 4.7234601974487305, acc=0.13055555522441864, loss=4.7234601974487305
train: epoch 5, loss 1.186654806137085, acc=0.5220555663108826, loss=1.186654806137085
test: epoch 5, loss 5.340390205383301, acc=0.10833333432674408, loss=5.340390205383301
train: epoch 6, loss 1.0655971765518188, acc=0.5678889155387878, loss=1.0655971765518188
test: epoch 6, loss 4.763000011444092, acc=0.16388888657093048, loss=4.763000011444092
train: epoch 7, loss 0.985215961933136, acc=0.6018333435058594, loss=0.985215961933136
test: epoch 7, loss 4.700455188751221, acc=0.125, loss=4.700455188751221
train: epoch 8, loss 0.9087044596672058, acc=0.6312777996063232, loss=0.9087044596672058
test: epoch 8, loss 4.1693549156188965, acc=0.17222222685813904, loss=4.1693549156188965
train: epoch 9, loss 0.8652557730674744, acc=0.652388870716095, loss=0.8652557730674744
test: epoch 9, loss 3.9671971797943115, acc=0.1944444477558136, loss=3.9671971797943115
train: epoch 10, loss 0.7872527837753296, acc=0.6912222504615784, loss=0.7872527837753296
test: epoch 10, loss 3.256067991256714, acc=0.26944443583488464, loss=3.256067991256714
train: epoch 11, loss 0.69341641664505, acc=0.7345555424690247, loss=0.69341641664505
test: epoch 11, loss 3.390819787979126, acc=0.28611111640930176, loss=3.390819787979126
train: epoch 12, loss 0.6567379832267761, acc=0.7522222399711609, loss=0.6567379832267761
test: epoch 12, loss 3.287118911743164, acc=0.23888888955116272, loss=3.287118911743164
train: epoch 13, loss 0.5708515048027039, acc=0.7876666784286499, loss=0.5708515048027039
test: epoch 13, loss 2.918046236038208, acc=0.2805555462837219, loss=2.918046236038208
train: epoch 14, loss 0.5025490522384644, acc=0.8156111240386963, loss=0.5025490522384644
test: epoch 14, loss 2.6680283546447754, acc=0.3166666626930237, loss=2.6680283546447754
train: epoch 15, loss 0.48457756638526917, acc=0.8221666812896729, loss=0.48457756638526917
test: epoch 15, loss 2.550384521484375, acc=0.28611111640930176, loss=2.550384521484375
train: epoch 16, loss 0.42963168025016785, acc=0.8455555438995361, loss=0.42963168025016785
test: epoch 16, loss 2.5133864879608154, acc=0.3027777671813965, loss=2.5133864879608154
train: epoch 17, loss 0.40794679522514343, acc=0.8532778024673462, loss=0.40794679522514343
test: epoch 17, loss 2.4074959754943848, acc=0.28333333134651184, loss=2.4074959754943848
train: epoch 18, loss 0.37561818957328796, acc=0.8675000071525574, loss=0.37561818957328796
test: epoch 18, loss 2.164246082305908, acc=0.33888888359069824, loss=2.164246082305908
train: epoch 19, loss 0.3574937582015991, acc=0.8747777938842773, loss=0.3574937582015991
test: epoch 19, loss 2.184283971786499, acc=0.3444444537162781, loss=2.184283971786499
train: epoch 20, loss 0.3299141228199005, acc=0.8867777585983276, loss=0.3299141228199005
test: epoch 20, loss 2.8841969966888428, acc=0.3222222328186035, loss=2.8841969966888428
train: epoch 21, loss 0.3024980425834656, acc=0.8918333053588867, loss=0.3024980425834656
test: epoch 21, loss 2.2536168098449707, acc=0.3583333194255829, loss=2.2536168098449707
train: epoch 22, loss 0.308982789516449, acc=0.8909444212913513, loss=0.308982789516449
test: epoch 22, loss 2.0913214683532715, acc=0.38055557012557983, loss=2.0913214683532715
train: epoch 23, loss 0.28318747878074646, acc=0.9059444665908813, loss=0.28318747878074646
test: epoch 23, loss 2.182255744934082, acc=0.3722222149372101, loss=2.182255744934082
train: epoch 24, loss 0.2871812880039215, acc=0.9016666412353516, loss=0.2871812880039215
test: epoch 24, loss 1.7831764221191406, acc=0.4000000059604645, loss=1.7831764221191406
train: epoch 25, loss 0.2691078186035156, acc=0.9138333201408386, loss=0.2691078186035156
test: epoch 25, loss 1.78913414478302, acc=0.3472222089767456, loss=1.78913414478302
train: epoch 26, loss 0.256740540266037, acc=0.9124444723129272, loss=0.256740540266037
test: epoch 26, loss 1.8778355121612549, acc=0.3888888955116272, loss=1.8778355121612549
train: epoch 27, loss 0.2516367733478546, acc=0.9167222380638123, loss=0.2516367733478546
test: epoch 27, loss 2.094496726989746, acc=0.39722222089767456, loss=2.094496726989746
train: epoch 28, loss 0.22971299290657043, acc=0.9236111044883728, loss=0.22971299290657043
test: epoch 28, loss 1.862679362297058, acc=0.4027777910232544, loss=1.862679362297058
train: epoch 29, loss 0.22743456065654755, acc=0.926111102104187, loss=0.22743456065654755
test: epoch 29, loss 1.8779447078704834, acc=0.40833333134651184, loss=1.8779447078704834
train: epoch 30, loss 0.20694151520729065, acc=0.9314444661140442, loss=0.20694151520729065
test: epoch 30, loss 2.0422372817993164, acc=0.3638888895511627, loss=2.0422372817993164
train: epoch 31, loss 0.20461095869541168, acc=0.9315555691719055, loss=0.20461095869541168
test: epoch 31, loss 2.071510076522827, acc=0.39444443583488464, loss=2.071510076522827
train: epoch 32, loss 0.20039094984531403, acc=0.9346110820770264, loss=0.20039094984531403
test: epoch 32, loss 2.2582285404205322, acc=0.3611111044883728, loss=2.2582285404205322
train: epoch 33, loss 0.20380130410194397, acc=0.9307777881622314, loss=0.20380130410194397
test: epoch 33, loss 2.048090934753418, acc=0.36666667461395264, loss=2.048090934753418
train: epoch 34, loss 0.21795405447483063, acc=0.9286666512489319, loss=0.21795405447483063
test: epoch 34, loss 1.9494860172271729, acc=0.42500001192092896, loss=1.9494860172271729
train: epoch 35, loss 0.18817344307899475, acc=0.9374444484710693, loss=0.18817344307899475
test: epoch 35, loss 1.9203200340270996, acc=0.38333332538604736, loss=1.9203200340270996
train: epoch 36, loss 0.1825055181980133, acc=0.9394999742507935, loss=0.1825055181980133
test: epoch 36, loss 2.0710442066192627, acc=0.34166666865348816, loss=2.0710442066192627
train: epoch 37, loss 0.1892799288034439, acc=0.9374444484710693, loss=0.1892799288034439
test: epoch 37, loss 2.296032190322876, acc=0.3722222149372101, loss=2.296032190322876
train: epoch 38, loss 0.18463248014450073, acc=0.9403889179229736, loss=0.18463248014450073
test: epoch 38, loss 2.049274444580078, acc=0.39444443583488464, loss=2.049274444580078
train: epoch 39, loss 0.16546104848384857, acc=0.9466666579246521, loss=0.16546104848384857
test: epoch 39, loss 2.143836259841919, acc=0.38333332538604736, loss=2.143836259841919
train: epoch 40, loss 0.19407400488853455, acc=0.9360555410385132, loss=0.19407400488853455
test: epoch 40, loss 2.0008363723754883, acc=0.41111111640930176, loss=2.0008363723754883
train: epoch 41, loss 0.19303688406944275, acc=0.9374444484710693, loss=0.19303688406944275
test: epoch 41, loss 2.172576904296875, acc=0.38055557012557983, loss=2.172576904296875
train: epoch 42, loss 0.17010988295078278, acc=0.9431111216545105, loss=0.17010988295078278
test: epoch 42, loss 2.2570090293884277, acc=0.4000000059604645, loss=2.2570090293884277
train: epoch 43, loss 0.1656414419412613, acc=0.94605553150177, loss=0.1656414419412613
test: epoch 43, loss 2.278602361679077, acc=0.40833333134651184, loss=2.278602361679077
train: epoch 44, loss 0.1812790185213089, acc=0.9393333196640015, loss=0.1812790185213089
test: epoch 44, loss 2.073610544204712, acc=0.4166666567325592, loss=2.073610544204712
train: epoch 45, loss 0.16804511845111847, acc=0.9464444518089294, loss=0.16804511845111847
test: epoch 45, loss 1.8373901844024658, acc=0.39722222089767456, loss=1.8373901844024658
train: epoch 46, loss 0.1721881479024887, acc=0.9434999823570251, loss=0.1721881479024887
test: epoch 46, loss 2.115694999694824, acc=0.4472222328186035, loss=2.115694999694824
train: epoch 47, loss 0.1618260145187378, acc=0.9481111168861389, loss=0.1618260145187378
test: epoch 47, loss 2.156526565551758, acc=0.4055555462837219, loss=2.156526565551758
train: epoch 48, loss 0.17086121439933777, acc=0.94477778673172, loss=0.17086121439933777
test: epoch 48, loss 1.985379695892334, acc=0.4416666626930237, loss=1.985379695892334
train: epoch 49, loss 0.14765214920043945, acc=0.9495000243186951, loss=0.14765214920043945
test: epoch 49, loss 2.2763254642486572, acc=0.4583333432674408, loss=2.2763254642486572
train: epoch 50, loss 0.16255925595760345, acc=0.9463889002799988, loss=0.16255925595760345
test: epoch 50, loss 2.451812744140625, acc=0.35555556416511536, loss=2.451812744140625
train: epoch 51, loss 0.16517843306064606, acc=0.9471666812896729, loss=0.16517843306064606
test: epoch 51, loss 1.724147915840149, acc=0.46666666865348816, loss=1.724147915840149
train: epoch 52, loss 0.16003923118114471, acc=0.9485555291175842, loss=0.16003923118114471
test: epoch 52, loss 1.9395350217819214, acc=0.4166666567325592, loss=1.9395350217819214
train: epoch 53, loss 0.17511151731014252, acc=0.9417222142219543, loss=0.17511151731014252
test: epoch 53, loss 1.7811086177825928, acc=0.4472222328186035, loss=1.7811086177825928
train: epoch 54, loss 0.14441616833209991, acc=0.9520555734634399, loss=0.14441616833209991
test: epoch 54, loss 1.8953779935836792, acc=0.47777777910232544, loss=1.8953779935836792
train: epoch 55, loss 0.18159763514995575, acc=0.9415555596351624, loss=0.18159763514995575
test: epoch 55, loss 1.6975181102752686, acc=0.5444444417953491, loss=1.6975181102752686
train: epoch 56, loss 0.14411264657974243, acc=0.9543333053588867, loss=0.14411264657974243
test: epoch 56, loss 1.9650732278823853, acc=0.4194444417953491, loss=1.9650732278823853
train: epoch 57, loss 0.15158295631408691, acc=0.9506111145019531, loss=0.15158295631408691
test: epoch 57, loss 1.5762194395065308, acc=0.5416666865348816, loss=1.5762194395065308
train: epoch 58, loss 0.16131006181240082, acc=0.9473888874053955, loss=0.16131006181240082
test: epoch 58, loss 1.765724778175354, acc=0.4444444477558136, loss=1.765724778175354
train: epoch 59, loss 0.15278109908103943, acc=0.9494444727897644, loss=0.15278109908103943
test: epoch 59, loss 1.994867205619812, acc=0.4416666626930237, loss=1.994867205619812
train: epoch 60, loss 0.1412450671195984, acc=0.9517222046852112, loss=0.1412450671195984
test: epoch 60, loss 2.2719995975494385, acc=0.3861111104488373, loss=2.2719995975494385
train: epoch 61, loss 0.14315403997898102, acc=0.9535555839538574, loss=0.14315403997898102
test: epoch 61, loss 1.7906887531280518, acc=0.4694444537162781, loss=1.7906887531280518
train: epoch 62, loss 0.1536339521408081, acc=0.949055552482605, loss=0.1536339521408081
test: epoch 62, loss 1.7362006902694702, acc=0.49166667461395264, loss=1.7362006902694702
train: epoch 63, loss 0.14577804505825043, acc=0.9539999961853027, loss=0.14577804505825043
test: epoch 63, loss 1.8646577596664429, acc=0.4555555582046509, loss=1.8646577596664429
train: epoch 64, loss 0.1465085744857788, acc=0.9530555605888367, loss=0.1465085744857788
test: epoch 64, loss 2.2786660194396973, acc=0.4333333373069763, loss=2.2786660194396973
train: epoch 65, loss 0.1326903998851776, acc=0.957277774810791, loss=0.1326903998851776
test: epoch 65, loss 2.1251397132873535, acc=0.45277777314186096, loss=2.1251397132873535
train: epoch 66, loss 0.1417219340801239, acc=0.9520555734634399, loss=0.1417219340801239
test: epoch 66, loss 1.8358708620071411, acc=0.46666666865348816, loss=1.8358708620071411
train: epoch 67, loss 0.1384793519973755, acc=0.9547222256660461, loss=0.1384793519973755
test: epoch 67, loss 1.7559748888015747, acc=0.519444465637207, loss=1.7559748888015747
train: epoch 68, loss 0.14329330623149872, acc=0.9530555605888367, loss=0.14329330623149872
test: epoch 68, loss 1.9652591943740845, acc=0.5277777910232544, loss=1.9652591943740845
train: epoch 69, loss 0.15000015497207642, acc=0.9514444470405579, loss=0.15000015497207642
test: epoch 69, loss 1.7480628490447998, acc=0.4694444537162781, loss=1.7480628490447998
train: epoch 70, loss 0.14795604348182678, acc=0.9517222046852112, loss=0.14795604348182678
test: epoch 70, loss 1.926735520362854, acc=0.47777777910232544, loss=1.926735520362854
train: epoch 71, loss 0.1452852487564087, acc=0.9538888931274414, loss=0.1452852487564087
test: epoch 71, loss 1.8178942203521729, acc=0.46666666865348816, loss=1.8178942203521729
train: epoch 72, loss 0.14233267307281494, acc=0.9548888802528381, loss=0.14233267307281494
test: epoch 72, loss 1.706567406654358, acc=0.48055556416511536, loss=1.706567406654358
train: epoch 73, loss 0.14269137382507324, acc=0.9532777667045593, loss=0.14269137382507324
test: epoch 73, loss 2.0625722408294678, acc=0.4888888895511627, loss=2.0625722408294678
train: epoch 74, loss 0.1376064568758011, acc=0.954277753829956, loss=0.1376064568758011
test: epoch 74, loss 1.9527531862258911, acc=0.4861111044883728, loss=1.9527531862258911
train: epoch 75, loss 0.15435978770256042, acc=0.9499444365501404, loss=0.15435978770256042
test: epoch 75, loss 2.0937883853912354, acc=0.4722222089767456, loss=2.0937883853912354
train: epoch 76, loss 0.1335177719593048, acc=0.9555000066757202, loss=0.1335177719593048
test: epoch 76, loss 2.0833849906921387, acc=0.4027777910232544, loss=2.0833849906921387
train: epoch 77, loss 0.13517215847969055, acc=0.9561111330986023, loss=0.13517215847969055
test: epoch 77, loss 1.7300723791122437, acc=0.4972222149372101, loss=1.7300723791122437
train: epoch 78, loss 0.14236363768577576, acc=0.9535555839538574, loss=0.14236363768577576
test: epoch 78, loss 1.9823124408721924, acc=0.5138888955116272, loss=1.9823124408721924
train: epoch 79, loss 0.1360023468732834, acc=0.9540555477142334, loss=0.1360023468732834
test: epoch 79, loss 1.6715847253799438, acc=0.5055555701255798, loss=1.6715847253799438
train: epoch 80, loss 0.1444266438484192, acc=0.9540555477142334, loss=0.1444266438484192
test: epoch 80, loss 1.698920726776123, acc=0.43611112236976624, loss=1.698920726776123
train: epoch 81, loss 0.15389131009578705, acc=0.9506666660308838, loss=0.15389131009578705
test: epoch 81, loss 1.7947543859481812, acc=0.4888888895511627, loss=1.7947543859481812
train: epoch 82, loss 0.13419221341609955, acc=0.9564444422721863, loss=0.13419221341609955
test: epoch 82, loss 2.068575382232666, acc=0.49166667461395264, loss=2.068575382232666
train: epoch 83, loss 0.15141233801841736, acc=0.9527222514152527, loss=0.15141233801841736
test: epoch 83, loss 1.8799023628234863, acc=0.5111111402511597, loss=1.8799023628234863
train: epoch 84, loss 0.14200982451438904, acc=0.9542222023010254, loss=0.14200982451438904
test: epoch 84, loss 2.0517148971557617, acc=0.4583333432674408, loss=2.0517148971557617
train: epoch 85, loss 0.14434854686260223, acc=0.9549999833106995, loss=0.14434854686260223
test: epoch 85, loss 1.984224796295166, acc=0.5138888955116272, loss=1.984224796295166
train: epoch 86, loss 0.1426651030778885, acc=0.9546666741371155, loss=0.1426651030778885
test: epoch 86, loss 1.8072072267532349, acc=0.5166666507720947, loss=1.8072072267532349
train: epoch 87, loss 0.14088115096092224, acc=0.9553333520889282, loss=0.14088115096092224
test: epoch 87, loss 1.756969690322876, acc=0.5388888716697693, loss=1.756969690322876
train: epoch 88, loss 0.14865416288375854, acc=0.9513888955116272, loss=0.14865416288375854
test: epoch 88, loss 1.930924415588379, acc=0.5222222208976746, loss=1.930924415588379
train: epoch 89, loss 0.13605868816375732, acc=0.956333339214325, loss=0.13605868816375732
test: epoch 89, loss 1.8388173580169678, acc=0.5333333611488342, loss=1.8388173580169678
train: epoch 90, loss 0.13262785971164703, acc=0.9560555815696716, loss=0.13262785971164703
test: epoch 90, loss 1.475277066230774, acc=0.5361111164093018, loss=1.475277066230774
train: epoch 91, loss 0.13652606308460236, acc=0.9552778005599976, loss=0.13652606308460236
test: epoch 91, loss 1.4187296628952026, acc=0.5722222328186035, loss=1.4187296628952026
train: epoch 92, loss 0.14096233248710632, acc=0.9546666741371155, loss=0.14096233248710632
test: epoch 92, loss 1.7247494459152222, acc=0.5, loss=1.7247494459152222
train: epoch 93, loss 0.12885721027851105, acc=0.9582222104072571, loss=0.12885721027851105
test: epoch 93, loss 1.7471858263015747, acc=0.5777778029441833, loss=1.7471858263015747
train: epoch 94, loss 0.13581441342830658, acc=0.9556666612625122, loss=0.13581441342830658
test: epoch 94, loss 1.717590093612671, acc=0.519444465637207, loss=1.717590093612671
train: epoch 95, loss 0.1602531522512436, acc=0.9483333230018616, loss=0.1602531522512436
test: epoch 95, loss 1.5106327533721924, acc=0.5694444179534912, loss=1.5106327533721924
train: epoch 96, loss 0.14850707352161407, acc=0.9520555734634399, loss=0.14850707352161407
test: epoch 96, loss 1.563636302947998, acc=0.5777778029441833, loss=1.563636302947998
train: epoch 97, loss 0.12995482981204987, acc=0.9598888754844666, loss=0.12995482981204987
test: epoch 97, loss 1.4257168769836426, acc=0.5666666626930237, loss=1.4257168769836426
train: epoch 98, loss 0.13086675107479095, acc=0.9584444165229797, loss=0.13086675107479095
test: epoch 98, loss 1.554294228553772, acc=0.5333333611488342, loss=1.554294228553772
train: epoch 99, loss 0.13825489580631256, acc=0.9573333263397217, loss=0.13825489580631256
test: epoch 99, loss 1.7960190773010254, acc=0.5694444179534912, loss=1.7960190773010254
train: epoch 100, loss 0.15327127277851105, acc=0.9491111040115356, loss=0.15327127277851105
test: epoch 100, loss 1.5591037273406982, acc=0.574999988079071, loss=1.5591037273406982
train: epoch 101, loss 0.1494593322277069, acc=0.9532222151756287, loss=0.1494593322277069
test: epoch 101, loss 1.6501953601837158, acc=0.5583333373069763, loss=1.6501953601837158
train: epoch 102, loss 0.14734451472759247, acc=0.954277753829956, loss=0.14734451472759247
test: epoch 102, loss 1.419898509979248, acc=0.6305555701255798, loss=1.419898509979248
train: epoch 103, loss 0.1382530778646469, acc=0.9555555582046509, loss=0.1382530778646469
test: epoch 103, loss 1.8679662942886353, acc=0.5805555582046509, loss=1.8679662942886353
train: epoch 104, loss 0.14095579087734222, acc=0.9548888802528381, loss=0.14095579087734222
test: epoch 104, loss 1.4824564456939697, acc=0.5833333134651184, loss=1.4824564456939697
train: epoch 105, loss 0.13205626606941223, acc=0.9573333263397217, loss=0.13205626606941223
test: epoch 105, loss 1.3749288320541382, acc=0.6027777791023254, loss=1.3749288320541382
train: epoch 106, loss 0.14822804927825928, acc=0.9557777643203735, loss=0.14822804927825928
test: epoch 106, loss 1.2724865674972534, acc=0.7055555582046509, loss=1.2724865674972534
train: epoch 107, loss 0.12129391729831696, acc=0.9587777853012085, loss=0.12129391729831696
test: epoch 107, loss 1.7018344402313232, acc=0.5722222328186035, loss=1.7018344402313232
train: epoch 108, loss 0.1389411836862564, acc=0.9541110992431641, loss=0.1389411836862564
test: epoch 108, loss 1.1935334205627441, acc=0.625, loss=1.1935334205627441
train: epoch 109, loss 0.13192977011203766, acc=0.957111120223999, loss=0.13192977011203766
test: epoch 109, loss 1.368718147277832, acc=0.6499999761581421, loss=1.368718147277832
train: epoch 110, loss 0.13786543905735016, acc=0.9567777514457703, loss=0.13786543905735016
test: epoch 110, loss 1.5210044384002686, acc=0.6138888597488403, loss=1.5210044384002686
train: epoch 111, loss 0.1465674787759781, acc=0.9539444446563721, loss=0.1465674787759781
test: epoch 111, loss 1.401752233505249, acc=0.644444465637207, loss=1.401752233505249
train: epoch 112, loss 0.12329675257205963, acc=0.9576666951179504, loss=0.12329675257205963
test: epoch 112, loss 1.5602034330368042, acc=0.6027777791023254, loss=1.5602034330368042
train: epoch 113, loss 0.15804022550582886, acc=0.9512222409248352, loss=0.15804022550582886
test: epoch 113, loss 1.151885986328125, acc=0.6777777671813965, loss=1.151885986328125
train: epoch 114, loss 0.13172513246536255, acc=0.9580000042915344, loss=0.13172513246536255
test: epoch 114, loss 1.280869722366333, acc=0.6333333253860474, loss=1.280869722366333
train: epoch 115, loss 0.13109399378299713, acc=0.9586111307144165, loss=0.13109399378299713
test: epoch 115, loss 1.3166863918304443, acc=0.6611111164093018, loss=1.3166863918304443
train: epoch 116, loss 0.13679373264312744, acc=0.9552222490310669, loss=0.13679373264312744
test: epoch 116, loss 1.134993314743042, acc=0.6694444417953491, loss=1.134993314743042
train: epoch 117, loss 0.11955219507217407, acc=0.9605555534362793, loss=0.11955219507217407
test: epoch 117, loss 1.4182243347167969, acc=0.6694444417953491, loss=1.4182243347167969
train: epoch 118, loss 0.12357642501592636, acc=0.9599999785423279, loss=0.12357642501592636
test: epoch 118, loss 1.1501423120498657, acc=0.6277777552604675, loss=1.1501423120498657
train: epoch 119, loss 0.139143705368042, acc=0.956333339214325, loss=0.139143705368042
test: epoch 119, loss 1.1658296585083008, acc=0.6944444179534912, loss=1.1658296585083008
train: epoch 120, loss 0.1331801563501358, acc=0.956944465637207, loss=0.1331801563501358
test: epoch 120, loss 1.078896164894104, acc=0.7055555582046509, loss=1.078896164894104
train: epoch 121, loss 0.13764220476150513, acc=0.9563888907432556, loss=0.13764220476150513
test: epoch 121, loss 0.844616711139679, acc=0.7222222089767456, loss=0.844616711139679
train: epoch 122, loss 0.12759040296077728, acc=0.9596666693687439, loss=0.12759040296077728
test: epoch 122, loss 1.0663065910339355, acc=0.7027778029441833, loss=1.0663065910339355
train: epoch 123, loss 0.1189277395606041, acc=0.9618333578109741, loss=0.1189277395606041
test: epoch 123, loss 1.0876446962356567, acc=0.6833333373069763, loss=1.0876446962356567
train: epoch 124, loss 0.1342271864414215, acc=0.9580000042915344, loss=0.1342271864414215
test: epoch 124, loss 1.086303949356079, acc=0.7388888597488403, loss=1.086303949356079
train: epoch 125, loss 0.119477279484272, acc=0.9610555768013, loss=0.119477279484272
test: epoch 125, loss 0.9322854280471802, acc=0.7472222447395325, loss=0.9322854280471802
train: epoch 126, loss 0.12457000464200974, acc=0.9592777490615845, loss=0.12457000464200974
test: epoch 126, loss 0.9775809645652771, acc=0.7277777791023254, loss=0.9775809645652771
train: epoch 127, loss 0.12899670004844666, acc=0.9586666822433472, loss=0.12899670004844666
test: epoch 127, loss 1.059365153312683, acc=0.7666666507720947, loss=1.059365153312683
train: epoch 128, loss 0.1424226611852646, acc=0.956166684627533, loss=0.1424226611852646
test: epoch 128, loss 0.9586153030395508, acc=0.7277777791023254, loss=0.9586153030395508
train: epoch 129, loss 0.13224908709526062, acc=0.9568889141082764, loss=0.13224908709526062
test: epoch 129, loss 0.6591258645057678, acc=0.8166666626930237, loss=0.6591258645057678
train: epoch 130, loss 0.10937783122062683, acc=0.9629999995231628, loss=0.10937783122062683
test: epoch 130, loss 0.9464449882507324, acc=0.7777777910232544, loss=0.9464449882507324
train: epoch 131, loss 0.12969322502613068, acc=0.9584444165229797, loss=0.12969322502613068
test: epoch 131, loss 0.9265521764755249, acc=0.769444465637207, loss=0.9265521764755249
train: epoch 132, loss 0.1178276538848877, acc=0.9607222080230713, loss=0.1178276538848877
test: epoch 132, loss 0.4682992696762085, acc=0.8222222328186035, loss=0.4682992696762085
train: epoch 133, loss 0.11792049556970596, acc=0.961555540561676, loss=0.11792049556970596
test: epoch 133, loss 0.8701653480529785, acc=0.7555555701255798, loss=0.8701653480529785
train: epoch 134, loss 0.115615114569664, acc=0.9622777700424194, loss=0.115615114569664
test: epoch 134, loss 0.5752167105674744, acc=0.8138889074325562, loss=0.5752167105674744
train: epoch 135, loss 0.10919187217950821, acc=0.9632777571678162, loss=0.10919187217950821
test: epoch 135, loss 0.7639410495758057, acc=0.8083333373069763, loss=0.7639410495758057
train: epoch 136, loss 0.12405792623758316, acc=0.9605000019073486, loss=0.12405792623758316
test: epoch 136, loss 0.674575924873352, acc=0.7722222208976746, loss=0.674575924873352
train: epoch 137, loss 0.11455950886011124, acc=0.9626666903495789, loss=0.11455950886011124
test: epoch 137, loss 0.6370435357093811, acc=0.7916666865348816, loss=0.6370435357093811
train: epoch 138, loss 0.11553677171468735, acc=0.9630555510520935, loss=0.11553677171468735
test: epoch 138, loss 0.5817129611968994, acc=0.8388888835906982, loss=0.5817129611968994
train: epoch 139, loss 0.11784239858388901, acc=0.9637222290039062, loss=0.11784239858388901
test: epoch 139, loss 0.6414422392845154, acc=0.7833333611488342, loss=0.6414422392845154
train: epoch 140, loss 0.11991441994905472, acc=0.9599999785423279, loss=0.11991441994905472
test: epoch 140, loss 0.4317252039909363, acc=0.855555534362793, loss=0.4317252039909363
train: epoch 141, loss 0.10692528635263443, acc=0.9657777547836304, loss=0.10692528635263443
test: epoch 141, loss 0.5003520846366882, acc=0.8194444179534912, loss=0.5003520846366882
train: epoch 142, loss 0.12123362720012665, acc=0.9641666412353516, loss=0.12123362720012665
test: epoch 142, loss 0.5971046686172485, acc=0.8277778029441833, loss=0.5971046686172485
train: epoch 143, loss 0.10388798266649246, acc=0.9677222371101379, loss=0.10388798266649246
test: epoch 143, loss 0.7046719193458557, acc=0.8166666626930237, loss=0.7046719193458557
train: epoch 144, loss 0.10492023080587387, acc=0.9641666412353516, loss=0.10492023080587387
test: epoch 144, loss 0.45778632164001465, acc=0.8583333492279053, loss=0.45778632164001465
train: epoch 145, loss 0.11709607392549515, acc=0.9634444713592529, loss=0.11709607392549515
test: epoch 145, loss 0.6162948608398438, acc=0.8194444179534912, loss=0.6162948608398438
train: epoch 146, loss 0.10732284188270569, acc=0.9645000100135803, loss=0.10732284188270569
test: epoch 146, loss 0.5635719299316406, acc=0.8472222089767456, loss=0.5635719299316406
train: epoch 147, loss 0.1142345443367958, acc=0.9628888964653015, loss=0.1142345443367958
test: epoch 147, loss 0.4926109313964844, acc=0.8361111283302307, loss=0.4926109313964844
train: epoch 148, loss 0.09892900288105011, acc=0.9676111340522766, loss=0.09892900288105011
test: epoch 148, loss 0.44269827008247375, acc=0.8638888597488403, loss=0.44269827008247375
train: epoch 149, loss 0.11658704280853271, acc=0.9616666436195374, loss=0.11658704280853271
test: epoch 149, loss 0.6011643409729004, acc=0.8111110925674438, loss=0.6011643409729004
train: epoch 150, loss 0.09665652364492416, acc=0.9681666493415833, loss=0.09665652364492416
test: epoch 150, loss 0.582602322101593, acc=0.8111110925674438, loss=0.582602322101593
