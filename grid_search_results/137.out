# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=1", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=1288855330, receiver_embed_dim=128, save_run=0, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1288855330, receiver_embed_dim=128, save_run=False, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.7413415908813477, acc=0.10927777737379074, loss=2.7413415908813477
test: epoch 1, loss 3.4099268913269043, acc=0.0972222238779068, loss=3.4099268913269043
train: epoch 2, loss 1.5546166896820068, acc=0.37977778911590576, loss=1.5546166896820068
test: epoch 2, loss 3.1467325687408447, acc=0.20555555820465088, loss=3.1467325687408447
train: epoch 3, loss 1.0694594383239746, acc=0.5700555443763733, loss=1.0694594383239746
test: epoch 3, loss 2.133553981781006, acc=0.2750000059604645, loss=2.133553981781006
train: epoch 4, loss 0.8213254809379578, acc=0.6641111373901367, loss=0.8213254809379578
test: epoch 4, loss 2.0845401287078857, acc=0.32777777314186096, loss=2.0845401287078857
train: epoch 5, loss 0.686913788318634, acc=0.7170555591583252, loss=0.686913788318634
test: epoch 5, loss 2.331660747528076, acc=0.3222222328186035, loss=2.331660747528076
train: epoch 6, loss 0.6009829044342041, acc=0.7517777681350708, loss=0.6009829044342041
test: epoch 6, loss 1.8383880853652954, acc=0.3638888895511627, loss=1.8383880853652954
train: epoch 7, loss 0.5374174118041992, acc=0.7823333144187927, loss=0.5374174118041992
test: epoch 7, loss 1.6872626543045044, acc=0.3638888895511627, loss=1.6872626543045044
train: epoch 8, loss 0.48087969422340393, acc=0.8057777881622314, loss=0.48087969422340393
test: epoch 8, loss 2.1543736457824707, acc=0.3361110985279083, loss=2.1543736457824707
train: epoch 9, loss 0.4149378836154938, acc=0.8448888659477234, loss=0.4149378836154938
test: epoch 9, loss 1.7655538320541382, acc=0.3861111104488373, loss=1.7655538320541382
train: epoch 10, loss 0.3992900848388672, acc=0.8535000085830688, loss=0.3992900848388672
test: epoch 10, loss 1.707864761352539, acc=0.45277777314186096, loss=1.707864761352539
train: epoch 11, loss 0.3533199429512024, acc=0.8727222084999084, loss=0.3533199429512024
test: epoch 11, loss 1.9164944887161255, acc=0.3916666805744171, loss=1.9164944887161255
train: epoch 12, loss 0.3119565546512604, acc=0.890500009059906, loss=0.3119565546512604
test: epoch 12, loss 1.6897143125534058, acc=0.46666666865348816, loss=1.6897143125534058
train: epoch 13, loss 0.2967539131641388, acc=0.894777774810791, loss=0.2967539131641388
test: epoch 13, loss 1.619974136352539, acc=0.4722222089767456, loss=1.619974136352539
train: epoch 14, loss 0.27680110931396484, acc=0.9033889174461365, loss=0.27680110931396484
test: epoch 14, loss 1.782170295715332, acc=0.4555555582046509, loss=1.782170295715332
train: epoch 15, loss 0.25212615728378296, acc=0.9120555520057678, loss=0.25212615728378296
test: epoch 15, loss 1.8090522289276123, acc=0.5333333611488342, loss=1.8090522289276123
train: epoch 16, loss 0.24127480387687683, acc=0.9176666736602783, loss=0.24127480387687683
test: epoch 16, loss 1.7065714597702026, acc=0.5666666626930237, loss=1.7065714597702026
train: epoch 17, loss 0.24042539298534393, acc=0.9166111350059509, loss=0.24042539298534393
test: epoch 17, loss 1.6764428615570068, acc=0.5166666507720947, loss=1.6764428615570068
train: epoch 18, loss 0.19914773106575012, acc=0.9324444532394409, loss=0.19914773106575012
test: epoch 18, loss 1.6057231426239014, acc=0.5972222089767456, loss=1.6057231426239014
train: epoch 19, loss 0.1843142807483673, acc=0.9408888816833496, loss=0.1843142807483673
test: epoch 19, loss 1.5790380239486694, acc=0.5666666626930237, loss=1.5790380239486694
train: epoch 20, loss 0.19066546857357025, acc=0.9355000257492065, loss=0.19066546857357025
test: epoch 20, loss 1.5147736072540283, acc=0.5555555820465088, loss=1.5147736072540283
train: epoch 21, loss 0.20164866745471954, acc=0.9325555562973022, loss=0.20164866745471954
test: epoch 21, loss 1.4484719038009644, acc=0.5722222328186035, loss=1.4484719038009644
train: epoch 22, loss 0.17200149595737457, acc=0.9443888664245605, loss=0.17200149595737457
test: epoch 22, loss 1.3855546712875366, acc=0.5805555582046509, loss=1.3855546712875366
train: epoch 23, loss 0.1642475724220276, acc=0.9468888640403748, loss=0.1642475724220276
test: epoch 23, loss 1.1388047933578491, acc=0.6611111164093018, loss=1.1388047933578491
train: epoch 24, loss 0.16400665044784546, acc=0.9448888897895813, loss=0.16400665044784546
test: epoch 24, loss 1.2147319316864014, acc=0.625, loss=1.2147319316864014
train: epoch 25, loss 0.14947354793548584, acc=0.9520555734634399, loss=0.14947354793548584
test: epoch 25, loss 1.2509982585906982, acc=0.6555555462837219, loss=1.2509982585906982
train: epoch 26, loss 0.1511506587266922, acc=0.9509999752044678, loss=0.1511506587266922
test: epoch 26, loss 1.125680685043335, acc=0.675000011920929, loss=1.125680685043335
train: epoch 27, loss 0.15294267237186432, acc=0.9511111378669739, loss=0.15294267237186432
test: epoch 27, loss 1.0404139757156372, acc=0.675000011920929, loss=1.0404139757156372
train: epoch 28, loss 0.14595648646354675, acc=0.9521111249923706, loss=0.14595648646354675
test: epoch 28, loss 1.0566678047180176, acc=0.6916666626930237, loss=1.0566678047180176
train: epoch 29, loss 0.1285177320241928, acc=0.9584444165229797, loss=0.1285177320241928
test: epoch 29, loss 1.1172990798950195, acc=0.6388888955116272, loss=1.1172990798950195
train: epoch 30, loss 0.13545280694961548, acc=0.9570000171661377, loss=0.13545280694961548
test: epoch 30, loss 1.0329089164733887, acc=0.6499999761581421, loss=1.0329089164733887
train: epoch 31, loss 0.1347363144159317, acc=0.9563888907432556, loss=0.1347363144159317
test: epoch 31, loss 1.0432424545288086, acc=0.7888888716697693, loss=1.0432424545288086
train: epoch 32, loss 0.11650331318378448, acc=0.9641110897064209, loss=0.11650331318378448
test: epoch 32, loss 0.8586829304695129, acc=0.75, loss=0.8586829304695129
train: epoch 33, loss 0.12297307699918747, acc=0.960777759552002, loss=0.12297307699918747
test: epoch 33, loss 0.7591078877449036, acc=0.7916666865348816, loss=0.7591078877449036
train: epoch 34, loss 0.11108609288930893, acc=0.9649999737739563, loss=0.11108609288930893
test: epoch 34, loss 0.643488347530365, acc=0.8416666388511658, loss=0.643488347530365
train: epoch 35, loss 0.11767716705799103, acc=0.9635555744171143, loss=0.11767716705799103
test: epoch 35, loss 0.5414162874221802, acc=0.8416666388511658, loss=0.5414162874221802
train: epoch 36, loss 0.09776554256677628, acc=0.9700555801391602, loss=0.09776554256677628
test: epoch 36, loss 0.5995256900787354, acc=0.8333333134651184, loss=0.5995256900787354
train: epoch 37, loss 0.09818259626626968, acc=0.9688888788223267, loss=0.09818259626626968
test: epoch 37, loss 0.3934042751789093, acc=0.8722222447395325, loss=0.3934042751789093
train: epoch 38, loss 0.0829777792096138, acc=0.9740555286407471, loss=0.0829777792096138
test: epoch 38, loss 0.2960777282714844, acc=0.9222221970558167, loss=0.2960777282714844
train: epoch 39, loss 0.09069745242595673, acc=0.9711666703224182, loss=0.09069745242595673
test: epoch 39, loss 0.43531346321105957, acc=0.8861111402511597, loss=0.43531346321105957
train: epoch 40, loss 0.06947414577007294, acc=0.9772777557373047, loss=0.06947414577007294
test: epoch 40, loss 0.2644402086734772, acc=0.925000011920929, loss=0.2644402086734772
train: epoch 41, loss 0.08084279298782349, acc=0.9761666655540466, loss=0.08084279298782349
test: epoch 41, loss 0.2495436668395996, acc=0.925000011920929, loss=0.2495436668395996
train: epoch 42, loss 0.06106148660182953, acc=0.9798333048820496, loss=0.06106148660182953
test: epoch 42, loss 0.23549054563045502, acc=0.9305555820465088, loss=0.23549054563045502
train: epoch 43, loss 0.06524517387151718, acc=0.9784444570541382, loss=0.06524517387151718
test: epoch 43, loss 0.29799747467041016, acc=0.925000011920929, loss=0.29799747467041016
train: epoch 44, loss 0.058567311614751816, acc=0.981166660785675, loss=0.058567311614751816
test: epoch 44, loss 0.20305578410625458, acc=0.9222221970558167, loss=0.20305578410625458
train: epoch 45, loss 0.078403539955616, acc=0.9746666550636292, loss=0.078403539955616
test: epoch 45, loss 0.19174690544605255, acc=0.9388889074325562, loss=0.19174690544605255
train: epoch 46, loss 0.07018750160932541, acc=0.9793333411216736, loss=0.07018750160932541
test: epoch 46, loss 0.22824858129024506, acc=0.9388889074325562, loss=0.22824858129024506
train: epoch 47, loss 0.05780915543437004, acc=0.9819444417953491, loss=0.05780915543437004
test: epoch 47, loss 0.12880820035934448, acc=0.9416666626930237, loss=0.12880820035934448
train: epoch 48, loss 0.05313530191779137, acc=0.9818333387374878, loss=0.05313530191779137
test: epoch 48, loss 0.18700173497200012, acc=0.9416666626930237, loss=0.18700173497200012
train: epoch 49, loss 0.05799485743045807, acc=0.9813888669013977, loss=0.05799485743045807
test: epoch 49, loss 0.24371351301670074, acc=0.9388889074325562, loss=0.24371351301670074
train: epoch 50, loss 0.06340992450714111, acc=0.981166660785675, loss=0.06340992450714111
test: epoch 50, loss 0.15972748398780823, acc=0.9416666626930237, loss=0.15972748398780823
train: epoch 51, loss 0.051317472010850906, acc=0.9837222099304199, loss=0.051317472010850906
test: epoch 51, loss 0.23667822778224945, acc=0.9388889074325562, loss=0.23667822778224945
train: epoch 52, loss 0.04736946523189545, acc=0.9832777976989746, loss=0.04736946523189545
test: epoch 52, loss 0.18982696533203125, acc=0.9416666626930237, loss=0.18982696533203125
train: epoch 53, loss 0.05397966876626015, acc=0.9834444522857666, loss=0.05397966876626015
test: epoch 53, loss 0.1888783574104309, acc=0.9416666626930237, loss=0.1888783574104309
train: epoch 54, loss 0.05198804289102554, acc=0.9853333234786987, loss=0.05198804289102554
test: epoch 54, loss 0.17554539442062378, acc=0.9416666626930237, loss=0.17554539442062378
train: epoch 55, loss 0.04168953001499176, acc=0.9868888854980469, loss=0.04168953001499176
test: epoch 55, loss 0.2213996946811676, acc=0.9416666626930237, loss=0.2213996946811676
train: epoch 56, loss 0.05513611063361168, acc=0.9829999804496765, loss=0.05513611063361168
test: epoch 56, loss 0.20682181417942047, acc=0.9416666626930237, loss=0.20682181417942047
train: epoch 57, loss 0.04106941074132919, acc=0.9864444732666016, loss=0.04106941074132919
test: epoch 57, loss 0.25235024094581604, acc=0.9416666626930237, loss=0.25235024094581604
train: epoch 58, loss 0.07531490921974182, acc=0.9758333563804626, loss=0.07531490921974182
test: epoch 58, loss 0.24026964604854584, acc=0.9416666626930237, loss=0.24026964604854584
train: epoch 59, loss 0.04565555602312088, acc=0.9871666431427002, loss=0.04565555602312088
test: epoch 59, loss 0.15780788660049438, acc=0.9416666626930237, loss=0.15780788660049438
train: epoch 60, loss 0.046177711337804794, acc=0.9850000143051147, loss=0.046177711337804794
test: epoch 60, loss 0.2318916767835617, acc=0.9416666626930237, loss=0.2318916767835617
train: epoch 61, loss 0.05280017852783203, acc=0.9842222332954407, loss=0.05280017852783203
test: epoch 61, loss 0.188873291015625, acc=0.9416666626930237, loss=0.188873291015625
train: epoch 62, loss 0.04365995153784752, acc=0.9850555658340454, loss=0.04365995153784752
test: epoch 62, loss 0.2476487159729004, acc=0.9416666626930237, loss=0.2476487159729004
train: epoch 63, loss 0.04437628015875816, acc=0.9849444627761841, loss=0.04437628015875816
test: epoch 63, loss 0.2286904752254486, acc=0.9416666626930237, loss=0.2286904752254486
train: epoch 64, loss 0.050858333706855774, acc=0.9835000038146973, loss=0.050858333706855774
test: epoch 64, loss 0.183762788772583, acc=0.9388889074325562, loss=0.183762788772583
train: epoch 65, loss 0.04267401248216629, acc=0.9863888621330261, loss=0.04267401248216629
test: epoch 65, loss 0.17755702137947083, acc=0.9416666626930237, loss=0.17755702137947083
train: epoch 66, loss 0.0313832052052021, acc=0.9890555739402771, loss=0.0313832052052021
test: epoch 66, loss 0.2515549659729004, acc=0.9416666626930237, loss=0.2515549659729004
train: epoch 67, loss 0.06020879000425339, acc=0.9818333387374878, loss=0.06020879000425339
test: epoch 67, loss 0.23470722138881683, acc=0.9416666626930237, loss=0.23470722138881683
train: epoch 68, loss 0.04272495210170746, acc=0.9863333106040955, loss=0.04272495210170746
test: epoch 68, loss 0.15528064966201782, acc=0.9416666626930237, loss=0.15528064966201782
train: epoch 69, loss 0.039205729961395264, acc=0.987666666507721, loss=0.039205729961395264
test: epoch 69, loss 0.24070362746715546, acc=0.9416666626930237, loss=0.24070362746715546
train: epoch 70, loss 0.035677142441272736, acc=0.9883888959884644, loss=0.035677142441272736
test: epoch 70, loss 0.23892563581466675, acc=0.9416666626930237, loss=0.23892563581466675
train: epoch 71, loss 0.04858454689383507, acc=0.9857777953147888, loss=0.04858454689383507
test: epoch 71, loss 0.21008580923080444, acc=0.9416666626930237, loss=0.21008580923080444
train: epoch 72, loss 0.03293170779943466, acc=0.988611102104187, loss=0.03293170779943466
test: epoch 72, loss 0.23494607210159302, acc=0.9416666626930237, loss=0.23494607210159302
train: epoch 73, loss 0.03619082644581795, acc=0.9881666898727417, loss=0.03619082644581795
test: epoch 73, loss 0.2170623391866684, acc=0.9416666626930237, loss=0.2170623391866684
train: epoch 74, loss 0.03647994250059128, acc=0.9889444708824158, loss=0.03647994250059128
test: epoch 74, loss 0.2139369547367096, acc=0.9416666626930237, loss=0.2139369547367096
train: epoch 75, loss 0.03454446420073509, acc=0.9893888831138611, loss=0.03454446420073509
test: epoch 75, loss 0.24316978454589844, acc=0.9416666626930237, loss=0.24316978454589844
train: epoch 76, loss 0.043302033096551895, acc=0.9860555529594421, loss=0.043302033096551895
test: epoch 76, loss 0.20213493704795837, acc=0.9416666626930237, loss=0.20213493704795837
train: epoch 77, loss 0.04777292162179947, acc=0.9858333468437195, loss=0.04777292162179947
test: epoch 77, loss 0.24923914670944214, acc=0.9416666626930237, loss=0.24923914670944214
train: epoch 78, loss 0.038264963775873184, acc=0.9874444603919983, loss=0.038264963775873184
test: epoch 78, loss 0.2025822550058365, acc=0.9416666626930237, loss=0.2025822550058365
train: epoch 79, loss 0.037033867090940475, acc=0.987333357334137, loss=0.037033867090940475
test: epoch 79, loss 0.2306099832057953, acc=0.9472222328186035, loss=0.2306099832057953
train: epoch 80, loss 0.04081444814801216, acc=0.988111138343811, loss=0.04081444814801216
test: epoch 80, loss 0.26713863015174866, acc=0.9416666626930237, loss=0.26713863015174866
train: epoch 81, loss 0.0448983758687973, acc=0.9858333468437195, loss=0.0448983758687973
test: epoch 81, loss 0.23943468928337097, acc=0.9361110925674438, loss=0.23943468928337097
train: epoch 82, loss 0.06326765567064285, acc=0.9825000166893005, loss=0.06326765567064285
test: epoch 82, loss 0.2155693918466568, acc=0.9472222328186035, loss=0.2155693918466568
train: epoch 83, loss 0.046686820685863495, acc=0.9860000014305115, loss=0.046686820685863495
test: epoch 83, loss 0.20617683231830597, acc=0.9472222328186035, loss=0.20617683231830597
train: epoch 84, loss 0.039684049785137177, acc=0.9867222309112549, loss=0.039684049785137177
test: epoch 84, loss 0.24657465517520905, acc=0.9472222328186035, loss=0.24657465517520905
train: epoch 85, loss 0.036969494074583054, acc=0.9865555763244629, loss=0.036969494074583054
test: epoch 85, loss 0.19236446917057037, acc=0.9472222328186035, loss=0.19236446917057037
train: epoch 86, loss 0.05120650678873062, acc=0.9855555295944214, loss=0.05120650678873062
test: epoch 86, loss 0.18795454502105713, acc=0.9472222328186035, loss=0.18795454502105713
train: epoch 87, loss 0.050069939345121384, acc=0.9842777848243713, loss=0.050069939345121384
test: epoch 87, loss 0.11168516427278519, acc=0.9472222328186035, loss=0.11168516427278519
train: epoch 88, loss 0.037486303597688675, acc=0.9876111149787903, loss=0.037486303597688675
test: epoch 88, loss 0.2041938453912735, acc=0.9472222328186035, loss=0.2041938453912735
train: epoch 89, loss 0.044814884662628174, acc=0.9867777824401855, loss=0.044814884662628174
test: epoch 89, loss 0.25652962923049927, acc=0.9416666626930237, loss=0.25652962923049927
train: epoch 90, loss 0.03820713609457016, acc=0.9865555763244629, loss=0.03820713609457016
test: epoch 90, loss 0.1996152251958847, acc=0.9416666626930237, loss=0.1996152251958847
train: epoch 91, loss 0.03145448863506317, acc=0.9882222414016724, loss=0.03145448863506317
test: epoch 91, loss 0.22130966186523438, acc=0.9416666626930237, loss=0.22130966186523438
train: epoch 92, loss 0.040666453540325165, acc=0.987333357334137, loss=0.040666453540325165
test: epoch 92, loss 0.21217916905879974, acc=0.9388889074325562, loss=0.21217916905879974
train: epoch 93, loss 0.0482264943420887, acc=0.987666666507721, loss=0.0482264943420887
test: epoch 93, loss 0.24111345410346985, acc=0.9416666626930237, loss=0.24111345410346985
train: epoch 94, loss 0.0315864197909832, acc=0.9883888959884644, loss=0.0315864197909832
test: epoch 94, loss 0.2131340503692627, acc=0.9416666626930237, loss=0.2131340503692627
train: epoch 95, loss 0.030917000025510788, acc=0.988444447517395, loss=0.030917000025510788
test: epoch 95, loss 0.24546349048614502, acc=0.9416666626930237, loss=0.24546349048614502
train: epoch 96, loss 0.036429863423109055, acc=0.9889444708824158, loss=0.036429863423109055
test: epoch 96, loss 0.2541664242744446, acc=0.9416666626930237, loss=0.2541664242744446
train: epoch 97, loss 0.050454337149858475, acc=0.9848889112472534, loss=0.050454337149858475
test: epoch 97, loss 0.2500220537185669, acc=0.9388889074325562, loss=0.2500220537185669
train: epoch 98, loss 0.04904089868068695, acc=0.9850000143051147, loss=0.04904089868068695
test: epoch 98, loss 0.21350343525409698, acc=0.9416666626930237, loss=0.21350343525409698
train: epoch 99, loss 0.044027723371982574, acc=0.987666666507721, loss=0.044027723371982574
test: epoch 99, loss 0.15030524134635925, acc=0.9416666626930237, loss=0.15030524134635925
train: epoch 100, loss 0.033076703548431396, acc=0.987500011920929, loss=0.033076703548431396
test: epoch 100, loss 0.20002950727939606, acc=0.9416666626930237, loss=0.20002950727939606
train: epoch 101, loss 0.03984770551323891, acc=0.9885555505752563, loss=0.03984770551323891
test: epoch 101, loss 0.3003712296485901, acc=0.9416666626930237, loss=0.3003712296485901
train: epoch 102, loss 0.03825058415532112, acc=0.9893888831138611, loss=0.03825058415532112
test: epoch 102, loss 0.24032868444919586, acc=0.9416666626930237, loss=0.24032868444919586
train: epoch 103, loss 0.03288603574037552, acc=0.9893333315849304, loss=0.03288603574037552
test: epoch 103, loss 0.1548781394958496, acc=0.9416666626930237, loss=0.1548781394958496
train: epoch 104, loss 0.03851604089140892, acc=0.9872778058052063, loss=0.03851604089140892
test: epoch 104, loss 0.19054311513900757, acc=0.9416666626930237, loss=0.19054311513900757
train: epoch 105, loss 0.03142337128520012, acc=0.9896110892295837, loss=0.03142337128520012
test: epoch 105, loss 0.26150277256965637, acc=0.9416666626930237, loss=0.26150277256965637
train: epoch 106, loss 0.03813181817531586, acc=0.9883888959884644, loss=0.03813181817531586
test: epoch 106, loss 0.17729634046554565, acc=0.9416666626930237, loss=0.17729634046554565
train: epoch 107, loss 0.029800575226545334, acc=0.9897778034210205, loss=0.029800575226545334
test: epoch 107, loss 0.2717137336730957, acc=0.9388889074325562, loss=0.2717137336730957
train: epoch 108, loss 0.06396366655826569, acc=0.9841111302375793, loss=0.06396366655826569
test: epoch 108, loss 0.23955675959587097, acc=0.9388889074325562, loss=0.23955675959587097
train: epoch 109, loss 0.03615449741482735, acc=0.9882222414016724, loss=0.03615449741482735
test: epoch 109, loss 0.24249061942100525, acc=0.9416666626930237, loss=0.24249061942100525
train: epoch 110, loss 0.02926761470735073, acc=0.9901111125946045, loss=0.02926761470735073
test: epoch 110, loss 0.24923816323280334, acc=0.9416666626930237, loss=0.24923816323280334
train: epoch 111, loss 0.03136603906750679, acc=0.9897778034210205, loss=0.03136603906750679
test: epoch 111, loss 0.2088296115398407, acc=0.9416666626930237, loss=0.2088296115398407
train: epoch 112, loss 0.03627582639455795, acc=0.9883333444595337, loss=0.03627582639455795
test: epoch 112, loss 0.26367196440696716, acc=0.9361110925674438, loss=0.26367196440696716
train: epoch 113, loss 0.03527655079960823, acc=0.9897222518920898, loss=0.03527655079960823
test: epoch 113, loss 0.22454753518104553, acc=0.9416666626930237, loss=0.22454753518104553
train: epoch 114, loss 0.038334596902132034, acc=0.9870555400848389, loss=0.038334596902132034
test: epoch 114, loss 0.2271936684846878, acc=0.9472222328186035, loss=0.2271936684846878
train: epoch 115, loss 0.04719524830579758, acc=0.9855555295944214, loss=0.04719524830579758
test: epoch 115, loss 0.1971023976802826, acc=0.9416666626930237, loss=0.1971023976802826
train: epoch 116, loss 0.03191295266151428, acc=0.9888888597488403, loss=0.03191295266151428
test: epoch 116, loss 0.1601477861404419, acc=0.9416666626930237, loss=0.1601477861404419
train: epoch 117, loss 0.039845485240221024, acc=0.9878888726234436, loss=0.039845485240221024
test: epoch 117, loss 0.1971708983182907, acc=0.9388889074325562, loss=0.1971708983182907
train: epoch 118, loss 0.03867338225245476, acc=0.9893888831138611, loss=0.03867338225245476
test: epoch 118, loss 0.26495298743247986, acc=0.9416666626930237, loss=0.26495298743247986
train: epoch 119, loss 0.03526829928159714, acc=0.988777756690979, loss=0.03526829928159714
test: epoch 119, loss 0.2291686236858368, acc=0.9416666626930237, loss=0.2291686236858368
train: epoch 120, loss 0.053313467651605606, acc=0.9867777824401855, loss=0.053313467651605606
test: epoch 120, loss 0.24918149411678314, acc=0.9388889074325562, loss=0.24918149411678314
train: epoch 121, loss 0.05064782127737999, acc=0.9858333468437195, loss=0.05064782127737999
test: epoch 121, loss 0.24707628786563873, acc=0.9388889074325562, loss=0.24707628786563873
train: epoch 122, loss 0.044729579240083694, acc=0.9855555295944214, loss=0.044729579240083694
test: epoch 122, loss 0.18130943179130554, acc=0.9444444179534912, loss=0.18130943179130554
train: epoch 123, loss 0.042488403618335724, acc=0.9857222437858582, loss=0.042488403618335724
test: epoch 123, loss 0.21201269328594208, acc=0.9388889074325562, loss=0.21201269328594208
train: epoch 124, loss 0.04470234364271164, acc=0.9856111407279968, loss=0.04470234364271164
test: epoch 124, loss 0.2379400134086609, acc=0.9444444179534912, loss=0.2379400134086609
train: epoch 125, loss 0.06839016824960709, acc=0.9814444184303284, loss=0.06839016824960709
test: epoch 125, loss 0.18254759907722473, acc=0.9361110925674438, loss=0.18254759907722473
train: epoch 126, loss 0.08145413547754288, acc=0.9791666865348816, loss=0.08145413547754288
test: epoch 126, loss 0.24822932481765747, acc=0.9305555820465088, loss=0.24822932481765747
train: epoch 127, loss 0.08077097684144974, acc=0.9762222170829773, loss=0.08077097684144974
test: epoch 127, loss 0.21688024699687958, acc=0.9388889074325562, loss=0.21688024699687958
train: epoch 128, loss 0.08012092858552933, acc=0.9763333201408386, loss=0.08012092858552933
test: epoch 128, loss 0.2181749790906906, acc=0.9305555820465088, loss=0.2181749790906906
train: epoch 129, loss 0.08924514055252075, acc=0.9755555391311646, loss=0.08924514055252075
test: epoch 129, loss 0.29149776697158813, acc=0.9305555820465088, loss=0.29149776697158813
train: epoch 130, loss 0.08280329406261444, acc=0.9772777557373047, loss=0.08280329406261444
test: epoch 130, loss 0.15985536575317383, acc=0.9361110925674438, loss=0.15985536575317383
train: epoch 131, loss 0.06223919987678528, acc=0.9810555577278137, loss=0.06223919987678528
test: epoch 131, loss 0.19921794533729553, acc=0.9361110925674438, loss=0.19921794533729553
train: epoch 132, loss 0.06046450510621071, acc=0.9813888669013977, loss=0.06046450510621071
test: epoch 132, loss 0.2621193528175354, acc=0.9361110925674438, loss=0.2621193528175354
train: epoch 133, loss 0.07797321677207947, acc=0.9792777895927429, loss=0.07797321677207947
test: epoch 133, loss 0.28700387477874756, acc=0.9277777671813965, loss=0.28700387477874756
train: epoch 134, loss 0.07912196964025497, acc=0.9752777814865112, loss=0.07912196964025497
test: epoch 134, loss 0.24694973230361938, acc=0.9388889074325562, loss=0.24694973230361938
train: epoch 135, loss 0.07385962456464767, acc=0.9792222380638123, loss=0.07385962456464767
test: epoch 135, loss 0.1924157738685608, acc=0.9416666626930237, loss=0.1924157738685608
train: epoch 136, loss 0.06804034113883972, acc=0.980388879776001, loss=0.06804034113883972
test: epoch 136, loss 0.19893869757652283, acc=0.9361110925674438, loss=0.19893869757652283
train: epoch 137, loss 0.055806081742048264, acc=0.981166660785675, loss=0.055806081742048264
test: epoch 137, loss 0.2408897429704666, acc=0.9361110925674438, loss=0.2408897429704666
train: epoch 138, loss 0.06198880448937416, acc=0.9807778000831604, loss=0.06198880448937416
test: epoch 138, loss 0.21853607892990112, acc=0.9333333373069763, loss=0.21853607892990112
train: epoch 139, loss 0.06421954929828644, acc=0.9796110987663269, loss=0.06421954929828644
test: epoch 139, loss 0.23573267459869385, acc=0.9361110925674438, loss=0.23573267459869385
train: epoch 140, loss 0.05836521461606026, acc=0.9801666736602783, loss=0.05836521461606026
test: epoch 140, loss 0.13978609442710876, acc=0.9277777671813965, loss=0.13978609442710876
train: epoch 141, loss 0.0668562576174736, acc=0.9777222275733948, loss=0.0668562576174736
test: epoch 141, loss 0.18637140095233917, acc=0.9416666626930237, loss=0.18637140095233917
train: epoch 142, loss 0.06116262078285217, acc=0.9788888692855835, loss=0.06116262078285217
test: epoch 142, loss 0.1719134896993637, acc=0.9388889074325562, loss=0.1719134896993637
train: epoch 143, loss 0.05715693160891533, acc=0.981333315372467, loss=0.05715693160891533
test: epoch 143, loss 0.22688904404640198, acc=0.9416666626930237, loss=0.22688904404640198
train: epoch 144, loss 0.04805397614836693, acc=0.9837222099304199, loss=0.04805397614836693
test: epoch 144, loss 0.151835098862648, acc=0.9583333134651184, loss=0.151835098862648
train: epoch 145, loss 0.05518312379717827, acc=0.9828333258628845, loss=0.05518312379717827
test: epoch 145, loss 0.10372334718704224, acc=0.9666666388511658, loss=0.10372334718704224
train: epoch 146, loss 0.0553702749311924, acc=0.9823333621025085, loss=0.0553702749311924
test: epoch 146, loss 0.12922295928001404, acc=0.9666666388511658, loss=0.12922295928001404
train: epoch 147, loss 0.04974312335252762, acc=0.9843888878822327, loss=0.04974312335252762
test: epoch 147, loss 0.07365044206380844, acc=0.9694444537162781, loss=0.07365044206380844
train: epoch 148, loss 0.04574184864759445, acc=0.9855555295944214, loss=0.04574184864759445
test: epoch 148, loss 0.05817066878080368, acc=0.9750000238418579, loss=0.05817066878080368
train: epoch 149, loss 0.04066985100507736, acc=0.987333357334137, loss=0.04066985100507736
test: epoch 149, loss 0.08740388602018356, acc=0.9722222089767456, loss=0.08740388602018356
train: epoch 150, loss 0.03199697285890579, acc=0.987666666507721, loss=0.03199697285890579
test: epoch 150, loss 0.0790492370724678, acc=0.9722222089767456, loss=0.0790492370724678
