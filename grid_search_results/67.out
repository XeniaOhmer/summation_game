# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=1", "--temp_decay=0.99", "--one_hot=true", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=187839614, receiver_embed_dim=64, temp_decay=0.99, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.1217973232269287, acc=0.07022222131490707, loss=3.1217973232269287
test: epoch 1, loss 2.695417642593384, acc=0.1111111119389534, loss=2.695417642593384
train: epoch 2, loss 2.1896378993988037, acc=0.1792222261428833, loss=2.1896378993988037
test: epoch 2, loss 2.456589937210083, acc=0.14722222089767456, loss=2.456589937210083
train: epoch 3, loss 1.793485403060913, acc=0.29366666078567505, loss=1.793485403060913
test: epoch 3, loss 2.128298759460449, acc=0.21666666865348816, loss=2.128298759460449
train: epoch 4, loss 1.508644700050354, acc=0.37805554270744324, loss=1.508644700050354
test: epoch 4, loss 1.9459673166275024, acc=0.2527777850627899, loss=1.9459673166275024
train: epoch 5, loss 1.3254457712173462, acc=0.4390000104904175, loss=1.3254457712173462
test: epoch 5, loss 1.8030728101730347, acc=0.2805555462837219, loss=1.8030728101730347
train: epoch 6, loss 1.1978590488433838, acc=0.47288888692855835, loss=1.1978590488433838
test: epoch 6, loss 1.728073000907898, acc=0.2916666567325592, loss=1.728073000907898
train: epoch 7, loss 1.1332006454467773, acc=0.4942222237586975, loss=1.1332006454467773
test: epoch 7, loss 1.8910661935806274, acc=0.2777777910232544, loss=1.8910661935806274
train: epoch 8, loss 1.076627492904663, acc=0.5192777514457703, loss=1.076627492904663
test: epoch 8, loss 1.6370443105697632, acc=0.3055555522441864, loss=1.6370443105697632
train: epoch 9, loss 1.0253570079803467, acc=0.5369444489479065, loss=1.0253570079803467
test: epoch 9, loss 1.7293061017990112, acc=0.3027777671813965, loss=1.7293061017990112
train: epoch 10, loss 0.9890180230140686, acc=0.5490000247955322, loss=0.9890180230140686
test: epoch 10, loss 1.870635986328125, acc=0.32777777314186096, loss=1.870635986328125
train: epoch 11, loss 0.9639116525650024, acc=0.5594444274902344, loss=0.9639116525650024
test: epoch 11, loss 1.72454833984375, acc=0.3194444477558136, loss=1.72454833984375
train: epoch 12, loss 0.9474703073501587, acc=0.5647777915000916, loss=0.9474703073501587
test: epoch 12, loss 1.8733720779418945, acc=0.3333333432674408, loss=1.8733720779418945
train: epoch 13, loss 0.9261159300804138, acc=0.5716666579246521, loss=0.9261159300804138
test: epoch 13, loss 1.8330234289169312, acc=0.3194444477558136, loss=1.8330234289169312
train: epoch 14, loss 0.9163023829460144, acc=0.5699999928474426, loss=0.9163023829460144
test: epoch 14, loss 1.6717954874038696, acc=0.3222222328186035, loss=1.6717954874038696
train: epoch 15, loss 0.9084649085998535, acc=0.5785555839538574, loss=0.9084649085998535
test: epoch 15, loss 1.7726267576217651, acc=0.3194444477558136, loss=1.7726267576217651
train: epoch 16, loss 0.9048906564712524, acc=0.5789999961853027, loss=0.9048906564712524
test: epoch 16, loss 1.725511074066162, acc=0.30000001192092896, loss=1.725511074066162
train: epoch 17, loss 0.9128313064575195, acc=0.5756111145019531, loss=0.9128313064575195
test: epoch 17, loss 1.7334606647491455, acc=0.3611111044883728, loss=1.7334606647491455
train: epoch 18, loss 0.8903975486755371, acc=0.5845555663108826, loss=0.8903975486755371
test: epoch 18, loss 1.8076372146606445, acc=0.35555556416511536, loss=1.8076372146606445
train: epoch 19, loss 0.8806549310684204, acc=0.5947222113609314, loss=0.8806549310684204
test: epoch 19, loss 1.6451480388641357, acc=0.3611111044883728, loss=1.6451480388641357
train: epoch 20, loss 0.8817526698112488, acc=0.5952777862548828, loss=0.8817526698112488
test: epoch 20, loss 1.6364010572433472, acc=0.3611111044883728, loss=1.6364010572433472
train: epoch 21, loss 0.8676490187644958, acc=0.6044444441795349, loss=0.8676490187644958
test: epoch 21, loss 1.7930806875228882, acc=0.3611111044883728, loss=1.7930806875228882
train: epoch 22, loss 0.8572531342506409, acc=0.6067777872085571, loss=0.8572531342506409
test: epoch 22, loss 1.766057014465332, acc=0.375, loss=1.766057014465332
train: epoch 23, loss 0.8575632572174072, acc=0.6048333048820496, loss=0.8575632572174072
test: epoch 23, loss 1.666439175605774, acc=0.375, loss=1.666439175605774
train: epoch 24, loss 0.8616962432861328, acc=0.6004999876022339, loss=0.8616962432861328
test: epoch 24, loss 1.7556363344192505, acc=0.36666667461395264, loss=1.7556363344192505
train: epoch 25, loss 0.8600149154663086, acc=0.5979999899864197, loss=0.8600149154663086
test: epoch 25, loss 1.7337641716003418, acc=0.3777777850627899, loss=1.7337641716003418
train: epoch 26, loss 0.8634382486343384, acc=0.6047777533531189, loss=0.8634382486343384
test: epoch 26, loss 1.5846484899520874, acc=0.38055557012557983, loss=1.5846484899520874
train: epoch 27, loss 0.84182208776474, acc=0.60188889503479, loss=0.84182208776474
test: epoch 27, loss 1.7000983953475952, acc=0.41111111640930176, loss=1.7000983953475952
train: epoch 28, loss 0.8482260704040527, acc=0.6085000038146973, loss=0.8482260704040527
test: epoch 28, loss 1.6942030191421509, acc=0.3777777850627899, loss=1.6942030191421509
train: epoch 29, loss 0.8487856388092041, acc=0.6065000295639038, loss=0.8487856388092041
test: epoch 29, loss 1.8421319723129272, acc=0.4000000059604645, loss=1.8421319723129272
train: epoch 30, loss 0.8666256070137024, acc=0.6071110963821411, loss=0.8666256070137024
test: epoch 30, loss 1.722873330116272, acc=0.4166666567325592, loss=1.722873330116272
train: epoch 31, loss 0.8475281000137329, acc=0.6080555319786072, loss=0.8475281000137329
test: epoch 31, loss 1.6406718492507935, acc=0.4138889014720917, loss=1.6406718492507935
train: epoch 32, loss 0.8419219255447388, acc=0.6079444289207458, loss=0.8419219255447388
test: epoch 32, loss 1.7134819030761719, acc=0.4055555462837219, loss=1.7134819030761719
train: epoch 33, loss 0.8244629502296448, acc=0.6145555377006531, loss=0.8244629502296448
test: epoch 33, loss 1.7289286851882935, acc=0.40833333134651184, loss=1.7289286851882935
train: epoch 34, loss 0.837395429611206, acc=0.6123889088630676, loss=0.837395429611206
test: epoch 34, loss 1.530259609222412, acc=0.4055555462837219, loss=1.530259609222412
train: epoch 35, loss 0.8230804204940796, acc=0.616944432258606, loss=0.8230804204940796
test: epoch 35, loss 1.5441279411315918, acc=0.4000000059604645, loss=1.5441279411315918
train: epoch 36, loss 0.8400768041610718, acc=0.6145555377006531, loss=0.8400768041610718
test: epoch 36, loss 1.5903340578079224, acc=0.4027777910232544, loss=1.5903340578079224
train: epoch 37, loss 0.8276083469390869, acc=0.6128888726234436, loss=0.8276083469390869
test: epoch 37, loss 1.5861976146697998, acc=0.3888888955116272, loss=1.5861976146697998
train: epoch 38, loss 0.8296424150466919, acc=0.6141666769981384, loss=0.8296424150466919
test: epoch 38, loss 1.4622267484664917, acc=0.42500001192092896, loss=1.4622267484664917
train: epoch 39, loss 0.8217957615852356, acc=0.6143888831138611, loss=0.8217957615852356
test: epoch 39, loss 1.4662190675735474, acc=0.4166666567325592, loss=1.4662190675735474
train: epoch 40, loss 0.8188348412513733, acc=0.6180555820465088, loss=0.8188348412513733
test: epoch 40, loss 1.5813080072402954, acc=0.41111111640930176, loss=1.5813080072402954
train: epoch 41, loss 0.7976372241973877, acc=0.6288889050483704, loss=0.7976372241973877
test: epoch 41, loss 1.4778693914413452, acc=0.4166666567325592, loss=1.4778693914413452
train: epoch 42, loss 0.805941641330719, acc=0.617555558681488, loss=0.805941641330719
test: epoch 42, loss 1.6873112916946411, acc=0.42222222685813904, loss=1.6873112916946411
train: epoch 43, loss 0.8081147074699402, acc=0.6244999766349792, loss=0.8081147074699402
test: epoch 43, loss 1.7254259586334229, acc=0.4277777671813965, loss=1.7254259586334229
train: epoch 44, loss 0.7902143597602844, acc=0.6326666474342346, loss=0.7902143597602844
test: epoch 44, loss 1.6222138404846191, acc=0.4138889014720917, loss=1.6222138404846191
train: epoch 45, loss 0.7932519316673279, acc=0.6273333430290222, loss=0.7932519316673279
test: epoch 45, loss 1.5674389600753784, acc=0.4138889014720917, loss=1.5674389600753784
train: epoch 46, loss 0.8025727272033691, acc=0.6223888993263245, loss=0.8025727272033691
test: epoch 46, loss 1.5941052436828613, acc=0.4194444417953491, loss=1.5941052436828613
train: epoch 47, loss 0.7871654629707336, acc=0.6271111369132996, loss=0.7871654629707336
test: epoch 47, loss 1.494148850440979, acc=0.40833333134651184, loss=1.494148850440979
train: epoch 48, loss 0.7973183393478394, acc=0.6230555772781372, loss=0.7973183393478394
test: epoch 48, loss 1.5666579008102417, acc=0.42500001192092896, loss=1.5666579008102417
train: epoch 49, loss 0.7908944487571716, acc=0.6245555281639099, loss=0.7908944487571716
test: epoch 49, loss 1.5954078435897827, acc=0.4194444417953491, loss=1.5954078435897827
train: epoch 50, loss 0.7805745005607605, acc=0.6288889050483704, loss=0.7805745005607605
test: epoch 50, loss 1.814479112625122, acc=0.4194444417953491, loss=1.814479112625122
train: epoch 51, loss 0.7751328945159912, acc=0.6349444389343262, loss=0.7751328945159912
test: epoch 51, loss 1.6036436557769775, acc=0.4194444417953491, loss=1.6036436557769775
train: epoch 52, loss 0.7987819910049438, acc=0.6287222504615784, loss=0.7987819910049438
test: epoch 52, loss 1.765928030014038, acc=0.42222222685813904, loss=1.765928030014038
train: epoch 53, loss 0.7920023798942566, acc=0.6279444694519043, loss=0.7920023798942566
test: epoch 53, loss 1.6064817905426025, acc=0.4138889014720917, loss=1.6064817905426025
train: epoch 54, loss 0.7851959466934204, acc=0.6324999928474426, loss=0.7851959466934204
test: epoch 54, loss 1.856300711631775, acc=0.42500001192092896, loss=1.856300711631775
train: epoch 55, loss 0.7852499485015869, acc=0.6242222189903259, loss=0.7852499485015869
test: epoch 55, loss 1.5377695560455322, acc=0.42222222685813904, loss=1.5377695560455322
train: epoch 56, loss 0.7819375395774841, acc=0.6317222118377686, loss=0.7819375395774841
test: epoch 56, loss 1.5557318925857544, acc=0.42222222685813904, loss=1.5557318925857544
train: epoch 57, loss 0.7669985890388489, acc=0.6408888697624207, loss=0.7669985890388489
test: epoch 57, loss 1.5215996503829956, acc=0.42500001192092896, loss=1.5215996503829956
train: epoch 58, loss 0.7658271789550781, acc=0.6421111226081848, loss=0.7658271789550781
test: epoch 58, loss 1.7229593992233276, acc=0.4194444417953491, loss=1.7229593992233276
train: epoch 59, loss 0.7777576446533203, acc=0.6391666531562805, loss=0.7777576446533203
test: epoch 59, loss 1.4754509925842285, acc=0.42500001192092896, loss=1.4754509925842285
train: epoch 60, loss 0.7781548500061035, acc=0.6306666731834412, loss=0.7781548500061035
test: epoch 60, loss 1.5571107864379883, acc=0.41111111640930176, loss=1.5571107864379883
train: epoch 61, loss 0.7698256969451904, acc=0.6341111063957214, loss=0.7698256969451904
test: epoch 61, loss 1.6151014566421509, acc=0.40833333134651184, loss=1.6151014566421509
train: epoch 62, loss 0.7709062099456787, acc=0.6356111168861389, loss=0.7709062099456787
test: epoch 62, loss 1.6847219467163086, acc=0.42222222685813904, loss=1.6847219467163086
train: epoch 63, loss 0.7780463099479675, acc=0.6358888745307922, loss=0.7780463099479675
test: epoch 63, loss 1.6551355123519897, acc=0.42500001192092896, loss=1.6551355123519897
train: epoch 64, loss 0.7451223134994507, acc=0.6417222023010254, loss=0.7451223134994507
test: epoch 64, loss 1.7394670248031616, acc=0.42222222685813904, loss=1.7394670248031616
train: epoch 65, loss 0.7729113101959229, acc=0.6369444727897644, loss=0.7729113101959229
test: epoch 65, loss 1.5020960569381714, acc=0.42222222685813904, loss=1.5020960569381714
train: epoch 66, loss 0.760567843914032, acc=0.6460555791854858, loss=0.760567843914032
test: epoch 66, loss 1.8232264518737793, acc=0.4000000059604645, loss=1.8232264518737793
train: epoch 67, loss 0.763706624507904, acc=0.6370555758476257, loss=0.763706624507904
test: epoch 67, loss 1.5972330570220947, acc=0.42222222685813904, loss=1.5972330570220947
train: epoch 68, loss 0.7601765990257263, acc=0.6431666612625122, loss=0.7601765990257263
test: epoch 68, loss 1.759863018989563, acc=0.42222222685813904, loss=1.759863018989563
train: epoch 69, loss 0.7602633237838745, acc=0.6419444680213928, loss=0.7602633237838745
test: epoch 69, loss 1.6171449422836304, acc=0.4194444417953491, loss=1.6171449422836304
train: epoch 70, loss 0.7712828516960144, acc=0.6431666612625122, loss=0.7712828516960144
test: epoch 70, loss 1.7000410556793213, acc=0.42222222685813904, loss=1.7000410556793213
train: epoch 71, loss 0.7574434876441956, acc=0.6483888626098633, loss=0.7574434876441956
test: epoch 71, loss 1.5681637525558472, acc=0.42222222685813904, loss=1.5681637525558472
train: epoch 72, loss 0.7664090991020203, acc=0.6429444551467896, loss=0.7664090991020203
test: epoch 72, loss 1.5969160795211792, acc=0.42222222685813904, loss=1.5969160795211792
train: epoch 73, loss 0.7462322115898132, acc=0.6445555686950684, loss=0.7462322115898132
test: epoch 73, loss 1.668305516242981, acc=0.42222222685813904, loss=1.668305516242981
train: epoch 74, loss 0.7567721605300903, acc=0.6439999938011169, loss=0.7567721605300903
test: epoch 74, loss 1.6334706544876099, acc=0.42222222685813904, loss=1.6334706544876099
train: epoch 75, loss 0.7597302794456482, acc=0.648277759552002, loss=0.7597302794456482
test: epoch 75, loss 1.6649940013885498, acc=0.42222222685813904, loss=1.6649940013885498
train: epoch 76, loss 0.7440811991691589, acc=0.6528888940811157, loss=0.7440811991691589
test: epoch 76, loss 1.6966359615325928, acc=0.4194444417953491, loss=1.6966359615325928
train: epoch 77, loss 0.7520606517791748, acc=0.6501111388206482, loss=0.7520606517791748
test: epoch 77, loss 1.5690912008285522, acc=0.42222222685813904, loss=1.5690912008285522
train: epoch 78, loss 0.7476208806037903, acc=0.649222195148468, loss=0.7476208806037903
test: epoch 78, loss 1.59912109375, acc=0.42222222685813904, loss=1.59912109375
train: epoch 79, loss 0.7485585808753967, acc=0.6516666412353516, loss=0.7485585808753967
test: epoch 79, loss 1.6247185468673706, acc=0.4305555522441864, loss=1.6247185468673706
train: epoch 80, loss 0.7498806715011597, acc=0.6504444479942322, loss=0.7498806715011597
test: epoch 80, loss 1.4822639226913452, acc=0.42222222685813904, loss=1.4822639226913452
train: epoch 81, loss 0.7547293305397034, acc=0.6464999914169312, loss=0.7547293305397034
test: epoch 81, loss 1.603723168373108, acc=0.4194444417953491, loss=1.603723168373108
train: epoch 82, loss 0.7507089376449585, acc=0.6461666822433472, loss=0.7507089376449585
test: epoch 82, loss 1.6058919429779053, acc=0.42500001192092896, loss=1.6058919429779053
train: epoch 83, loss 0.7495714426040649, acc=0.6463888883590698, loss=0.7495714426040649
test: epoch 83, loss 1.5469119548797607, acc=0.4194444417953491, loss=1.5469119548797607
train: epoch 84, loss 0.7710568904876709, acc=0.6338889002799988, loss=0.7710568904876709
test: epoch 84, loss 1.5507824420928955, acc=0.4333333373069763, loss=1.5507824420928955
train: epoch 85, loss 0.7438514828681946, acc=0.6493889093399048, loss=0.7438514828681946
test: epoch 85, loss 1.5945016145706177, acc=0.42222222685813904, loss=1.5945016145706177
train: epoch 86, loss 0.7460777759552002, acc=0.6506666541099548, loss=0.7460777759552002
test: epoch 86, loss 1.5773261785507202, acc=0.42222222685813904, loss=1.5773261785507202
train: epoch 87, loss 0.7491942048072815, acc=0.649055540561676, loss=0.7491942048072815
test: epoch 87, loss 1.5894170999526978, acc=0.42500001192092896, loss=1.5894170999526978
train: epoch 88, loss 0.7450830340385437, acc=0.6491666436195374, loss=0.7450830340385437
test: epoch 88, loss 1.6063231229782104, acc=0.4277777671813965, loss=1.6063231229782104
train: epoch 89, loss 0.7484871745109558, acc=0.6511111259460449, loss=0.7484871745109558
test: epoch 89, loss 1.6880073547363281, acc=0.42222222685813904, loss=1.6880073547363281
train: epoch 90, loss 0.7280504703521729, acc=0.6579444408416748, loss=0.7280504703521729
test: epoch 90, loss 1.8203881978988647, acc=0.42222222685813904, loss=1.8203881978988647
train: epoch 91, loss 0.7441183924674988, acc=0.6549444198608398, loss=0.7441183924674988
test: epoch 91, loss 1.6828418970108032, acc=0.4194444417953491, loss=1.6828418970108032
train: epoch 92, loss 0.7304399013519287, acc=0.6575555801391602, loss=0.7304399013519287
test: epoch 92, loss 1.5589320659637451, acc=0.42222222685813904, loss=1.5589320659637451
train: epoch 93, loss 0.7279505729675293, acc=0.6588888764381409, loss=0.7279505729675293
test: epoch 93, loss 1.631235122680664, acc=0.44999998807907104, loss=1.631235122680664
train: epoch 94, loss 0.7250487804412842, acc=0.6616111397743225, loss=0.7250487804412842
test: epoch 94, loss 1.567094326019287, acc=0.4138889014720917, loss=1.567094326019287
train: epoch 95, loss 0.7244545817375183, acc=0.660277783870697, loss=0.7244545817375183
test: epoch 95, loss 1.7279067039489746, acc=0.4444444477558136, loss=1.7279067039489746
train: epoch 96, loss 0.7190305590629578, acc=0.6630555391311646, loss=0.7190305590629578
test: epoch 96, loss 1.4482815265655518, acc=0.4555555582046509, loss=1.4482815265655518
train: epoch 97, loss 0.7131548523902893, acc=0.6650555729866028, loss=0.7131548523902893
test: epoch 97, loss 1.6801263093948364, acc=0.4555555582046509, loss=1.6801263093948364
train: epoch 98, loss 0.711825966835022, acc=0.6667777895927429, loss=0.711825966835022
test: epoch 98, loss 1.6175434589385986, acc=0.4555555582046509, loss=1.6175434589385986
train: epoch 99, loss 0.7288186550140381, acc=0.6612777709960938, loss=0.7288186550140381
test: epoch 99, loss 1.5451538562774658, acc=0.46388888359069824, loss=1.5451538562774658
train: epoch 100, loss 0.7080156803131104, acc=0.6631110906600952, loss=0.7080156803131104
test: epoch 100, loss 1.5566610097885132, acc=0.4555555582046509, loss=1.5566610097885132
train: epoch 101, loss 0.7108853459358215, acc=0.6657778024673462, loss=0.7108853459358215
test: epoch 101, loss 1.5633724927902222, acc=0.43611112236976624, loss=1.5633724927902222
train: epoch 102, loss 0.6997383236885071, acc=0.6650000214576721, loss=0.6997383236885071
test: epoch 102, loss 1.4221638441085815, acc=0.43611112236976624, loss=1.4221638441085815
train: epoch 103, loss 0.6731992363929749, acc=0.6852222084999084, loss=0.6731992363929749
test: epoch 103, loss 1.5725843906402588, acc=0.4444444477558136, loss=1.5725843906402588
train: epoch 104, loss 0.660997748374939, acc=0.695888876914978, loss=0.660997748374939
test: epoch 104, loss 1.524146556854248, acc=0.4472222328186035, loss=1.524146556854248
train: epoch 105, loss 0.6415050029754639, acc=0.7022222280502319, loss=0.6415050029754639
test: epoch 105, loss 1.7548341751098633, acc=0.4472222328186035, loss=1.7548341751098633
train: epoch 106, loss 0.640419602394104, acc=0.6972222328186035, loss=0.640419602394104
test: epoch 106, loss 1.6718796491622925, acc=0.4555555582046509, loss=1.6718796491622925
train: epoch 107, loss 0.6307963728904724, acc=0.7010555267333984, loss=0.6307963728904724
test: epoch 107, loss 1.7037513256072998, acc=0.4555555582046509, loss=1.7037513256072998
train: epoch 108, loss 0.6254842877388, acc=0.7047222256660461, loss=0.6254842877388
test: epoch 108, loss 1.605136513710022, acc=0.4583333432674408, loss=1.605136513710022
train: epoch 109, loss 0.6242555975914001, acc=0.7046111226081848, loss=0.6242555975914001
test: epoch 109, loss 1.5264557600021362, acc=0.4555555582046509, loss=1.5264557600021362
train: epoch 110, loss 0.6254486441612244, acc=0.703000009059906, loss=0.6254486441612244
test: epoch 110, loss 1.5719492435455322, acc=0.45277777314186096, loss=1.5719492435455322
train: epoch 111, loss 0.6305792331695557, acc=0.7014444470405579, loss=0.6305792331695557
test: epoch 111, loss 1.794994831085205, acc=0.45277777314186096, loss=1.794994831085205
train: epoch 112, loss 0.625309407711029, acc=0.7041666507720947, loss=0.625309407711029
test: epoch 112, loss 1.645418643951416, acc=0.4444444477558136, loss=1.645418643951416
train: epoch 113, loss 0.6386281847953796, acc=0.7013333439826965, loss=0.6386281847953796
test: epoch 113, loss 1.5892055034637451, acc=0.4555555582046509, loss=1.5892055034637451
train: epoch 114, loss 0.612970232963562, acc=0.7105555534362793, loss=0.612970232963562
test: epoch 114, loss 1.5204848051071167, acc=0.4611110985279083, loss=1.5204848051071167
train: epoch 115, loss 0.6260703206062317, acc=0.7045555710792542, loss=0.6260703206062317
test: epoch 115, loss 1.693170189857483, acc=0.4555555582046509, loss=1.693170189857483
train: epoch 116, loss 0.6193633675575256, acc=0.7096111178398132, loss=0.6193633675575256
test: epoch 116, loss 1.6330400705337524, acc=0.4472222328186035, loss=1.6330400705337524
train: epoch 117, loss 0.6224580407142639, acc=0.7037222385406494, loss=0.6224580407142639
test: epoch 117, loss 1.5507659912109375, acc=0.4555555582046509, loss=1.5507659912109375
train: epoch 118, loss 0.6167469620704651, acc=0.7055000066757202, loss=0.6167469620704651
test: epoch 118, loss 1.5939767360687256, acc=0.4555555582046509, loss=1.5939767360687256
train: epoch 119, loss 0.6050096154212952, acc=0.7078333497047424, loss=0.6050096154212952
test: epoch 119, loss 1.6665366888046265, acc=0.4555555582046509, loss=1.6665366888046265
train: epoch 120, loss 0.6024061441421509, acc=0.7095000147819519, loss=0.6024061441421509
test: epoch 120, loss 1.4465456008911133, acc=0.4722222089767456, loss=1.4465456008911133
train: epoch 121, loss 0.6056825518608093, acc=0.7088333368301392, loss=0.6056825518608093
test: epoch 121, loss 1.517783284187317, acc=0.45277777314186096, loss=1.517783284187317
train: epoch 122, loss 0.6216123700141907, acc=0.7059999704360962, loss=0.6216123700141907
test: epoch 122, loss 1.5383107662200928, acc=0.4555555582046509, loss=1.5383107662200928
train: epoch 123, loss 0.6033092737197876, acc=0.7151111364364624, loss=0.6033092737197876
test: epoch 123, loss 1.5618462562561035, acc=0.4555555582046509, loss=1.5618462562561035
train: epoch 124, loss 0.6068754196166992, acc=0.7046111226081848, loss=0.6068754196166992
test: epoch 124, loss 1.7161955833435059, acc=0.4555555582046509, loss=1.7161955833435059
train: epoch 125, loss 0.6048222184181213, acc=0.707111120223999, loss=0.6048222184181213
test: epoch 125, loss 1.6131134033203125, acc=0.4583333432674408, loss=1.6131134033203125
train: epoch 126, loss 0.6330707669258118, acc=0.7060555815696716, loss=0.6330707669258118
test: epoch 126, loss 1.5662195682525635, acc=0.4555555582046509, loss=1.5662195682525635
train: epoch 127, loss 0.6010189652442932, acc=0.7138888835906982, loss=0.6010189652442932
test: epoch 127, loss 1.5656101703643799, acc=0.4555555582046509, loss=1.5656101703643799
train: epoch 128, loss 0.592925488948822, acc=0.7132777571678162, loss=0.592925488948822
test: epoch 128, loss 1.7683424949645996, acc=0.4555555582046509, loss=1.7683424949645996
train: epoch 129, loss 0.6081870198249817, acc=0.7118333578109741, loss=0.6081870198249817
test: epoch 129, loss 1.5908725261688232, acc=0.4555555582046509, loss=1.5908725261688232
train: epoch 130, loss 0.5902891755104065, acc=0.7236666679382324, loss=0.5902891755104065
test: epoch 130, loss 1.5919806957244873, acc=0.4555555582046509, loss=1.5919806957244873
train: epoch 131, loss 0.600721001625061, acc=0.7075555324554443, loss=0.600721001625061
test: epoch 131, loss 1.5532441139221191, acc=0.4555555582046509, loss=1.5532441139221191
train: epoch 132, loss 0.5877115726470947, acc=0.718833327293396, loss=0.5877115726470947
test: epoch 132, loss 1.5570849180221558, acc=0.4555555582046509, loss=1.5570849180221558
train: epoch 133, loss 0.58709716796875, acc=0.718999981880188, loss=0.58709716796875
test: epoch 133, loss 1.5805518627166748, acc=0.4555555582046509, loss=1.5805518627166748
train: epoch 134, loss 0.6012573838233948, acc=0.7164444327354431, loss=0.6012573838233948
test: epoch 134, loss 1.4579627513885498, acc=0.4555555582046509, loss=1.4579627513885498
train: epoch 135, loss 0.6022729873657227, acc=0.7130555510520935, loss=0.6022729873657227
test: epoch 135, loss 1.5609840154647827, acc=0.4611110985279083, loss=1.5609840154647827
train: epoch 136, loss 0.585154116153717, acc=0.7211111187934875, loss=0.585154116153717
test: epoch 136, loss 1.6452559232711792, acc=0.4611110985279083, loss=1.6452559232711792
train: epoch 137, loss 0.5895503759384155, acc=0.7207221984863281, loss=0.5895503759384155
test: epoch 137, loss 1.6211985349655151, acc=0.4555555582046509, loss=1.6211985349655151
train: epoch 138, loss 0.5853686332702637, acc=0.7223888635635376, loss=0.5853686332702637
test: epoch 138, loss 1.5033190250396729, acc=0.4555555582046509, loss=1.5033190250396729
train: epoch 139, loss 0.5962997078895569, acc=0.7131666541099548, loss=0.5962997078895569
test: epoch 139, loss 1.5667165517807007, acc=0.4555555582046509, loss=1.5667165517807007
train: epoch 140, loss 0.5898070931434631, acc=0.7203888893127441, loss=0.5898070931434631
test: epoch 140, loss 1.703917145729065, acc=0.4555555582046509, loss=1.703917145729065
train: epoch 141, loss 0.5895833969116211, acc=0.7177222371101379, loss=0.5895833969116211
test: epoch 141, loss 1.6273759603500366, acc=0.4555555582046509, loss=1.6273759603500366
train: epoch 142, loss 0.5873984694480896, acc=0.7167222499847412, loss=0.5873984694480896
test: epoch 142, loss 1.6346485614776611, acc=0.4611110985279083, loss=1.6346485614776611
train: epoch 143, loss 0.5871697664260864, acc=0.7214999794960022, loss=0.5871697664260864
test: epoch 143, loss 1.6479017734527588, acc=0.4555555582046509, loss=1.6479017734527588
train: epoch 144, loss 0.5730373859405518, acc=0.7289999723434448, loss=0.5730373859405518
test: epoch 144, loss 1.6348192691802979, acc=0.4555555582046509, loss=1.6348192691802979
train: epoch 145, loss 0.5949065089225769, acc=0.7186111211776733, loss=0.5949065089225769
test: epoch 145, loss 1.4543110132217407, acc=0.44999998807907104, loss=1.4543110132217407
train: epoch 146, loss 0.5856956839561462, acc=0.7220555543899536, loss=0.5856956839561462
test: epoch 146, loss 1.6162493228912354, acc=0.4555555582046509, loss=1.6162493228912354
train: epoch 147, loss 0.5784348249435425, acc=0.7260000109672546, loss=0.5784348249435425
test: epoch 147, loss 1.5895485877990723, acc=0.4555555582046509, loss=1.5895485877990723
train: epoch 148, loss 0.5952227711677551, acc=0.718666672706604, loss=0.5952227711677551
test: epoch 148, loss 1.6765929460525513, acc=0.4555555582046509, loss=1.6765929460525513
train: epoch 149, loss 0.5976334810256958, acc=0.718833327293396, loss=0.5976334810256958
test: epoch 149, loss 1.512265682220459, acc=0.4611110985279083, loss=1.512265682220459
train: epoch 150, loss 0.5826043486595154, acc=0.7198888659477234, loss=0.5826043486595154
test: epoch 150, loss 1.4498125314712524, acc=0.4555555582046509, loss=1.4498125314712524
