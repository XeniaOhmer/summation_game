# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=1.5", "--temp_decay=0.99", "--one_hot=1", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=1854675881, receiver_embed_dim=64, save_run=0, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1854675881, receiver_embed_dim=64, save_run=False, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.91225004196167, acc=0.09627778083086014, loss=2.91225004196167
test: epoch 1, loss 3.103687286376953, acc=0.11666666716337204, loss=3.103687286376953
train: epoch 2, loss 1.918932318687439, acc=0.2533888816833496, loss=1.918932318687439
test: epoch 2, loss 3.312181234359741, acc=0.11944444477558136, loss=3.312181234359741
train: epoch 3, loss 1.418956995010376, acc=0.4350000023841858, loss=1.418956995010376
test: epoch 3, loss 3.5953316688537598, acc=0.17222222685813904, loss=3.5953316688537598
train: epoch 4, loss 1.096447229385376, acc=0.5637221932411194, loss=1.096447229385376
test: epoch 4, loss 2.7314164638519287, acc=0.21944443881511688, loss=2.7314164638519287
train: epoch 5, loss 0.9152289032936096, acc=0.6346666812896729, loss=0.9152289032936096
test: epoch 5, loss 2.4126579761505127, acc=0.2944444417953491, loss=2.4126579761505127
train: epoch 6, loss 0.8062392473220825, acc=0.6823889017105103, loss=0.8062392473220825
test: epoch 6, loss 2.1592719554901123, acc=0.3333333432674408, loss=2.1592719554901123
train: epoch 7, loss 0.739702582359314, acc=0.7036666870117188, loss=0.739702582359314
test: epoch 7, loss 2.0113136768341064, acc=0.3638888895511627, loss=2.0113136768341064
train: epoch 8, loss 0.6688641905784607, acc=0.7287222146987915, loss=0.6688641905784607
test: epoch 8, loss 1.9376713037490845, acc=0.3722222149372101, loss=1.9376713037490845
train: epoch 9, loss 0.6055086851119995, acc=0.7547222375869751, loss=0.6055086851119995
test: epoch 9, loss 2.434751033782959, acc=0.22777777910232544, loss=2.434751033782959
train: epoch 10, loss 0.6049271821975708, acc=0.7573888897895813, loss=0.6049271821975708
test: epoch 10, loss 1.7649102210998535, acc=0.3888888955116272, loss=1.7649102210998535
train: epoch 11, loss 0.5489996671676636, acc=0.7753333449363708, loss=0.5489996671676636
test: epoch 11, loss 2.118381977081299, acc=0.3722222149372101, loss=2.118381977081299
train: epoch 12, loss 0.5445543527603149, acc=0.7747777700424194, loss=0.5445543527603149
test: epoch 12, loss 1.8107417821884155, acc=0.41111111640930176, loss=1.8107417821884155
train: epoch 13, loss 0.5028878450393677, acc=0.792388916015625, loss=0.5028878450393677
test: epoch 13, loss 1.7065277099609375, acc=0.4416666626930237, loss=1.7065277099609375
train: epoch 14, loss 0.4915032684803009, acc=0.8003333210945129, loss=0.4915032684803009
test: epoch 14, loss 1.542341947555542, acc=0.4583333432674408, loss=1.542341947555542
train: epoch 15, loss 0.4668600261211395, acc=0.8078888654708862, loss=0.4668600261211395
test: epoch 15, loss 1.628008246421814, acc=0.4583333432674408, loss=1.628008246421814
train: epoch 16, loss 0.4326992928981781, acc=0.8245000243186951, loss=0.4326992928981781
test: epoch 16, loss 1.5225969552993774, acc=0.4305555522441864, loss=1.5225969552993774
train: epoch 17, loss 0.4146779179573059, acc=0.8366110920906067, loss=0.4146779179573059
test: epoch 17, loss 1.356898307800293, acc=0.4749999940395355, loss=1.356898307800293
train: epoch 18, loss 0.3925244212150574, acc=0.8432777523994446, loss=0.3925244212150574
test: epoch 18, loss 1.4792290925979614, acc=0.43611112236976624, loss=1.4792290925979614
train: epoch 19, loss 0.39093297719955444, acc=0.8416666388511658, loss=0.39093297719955444
test: epoch 19, loss 1.318121314048767, acc=0.5027777552604675, loss=1.318121314048767
train: epoch 20, loss 0.37576401233673096, acc=0.8496666550636292, loss=0.37576401233673096
test: epoch 20, loss 1.4931892156600952, acc=0.4611110985279083, loss=1.4931892156600952
train: epoch 21, loss 0.35150814056396484, acc=0.8572777509689331, loss=0.35150814056396484
test: epoch 21, loss 1.377911925315857, acc=0.5416666865348816, loss=1.377911925315857
train: epoch 22, loss 0.3410344421863556, acc=0.8633333444595337, loss=0.3410344421863556
test: epoch 22, loss 1.4569766521453857, acc=0.5055555701255798, loss=1.4569766521453857
train: epoch 23, loss 0.3337150514125824, acc=0.8678333163261414, loss=0.3337150514125824
test: epoch 23, loss 1.276326298713684, acc=0.574999988079071, loss=1.276326298713684
train: epoch 24, loss 0.33666330575942993, acc=0.8667222261428833, loss=0.33666330575942993
test: epoch 24, loss 1.359635591506958, acc=0.519444465637207, loss=1.359635591506958
train: epoch 25, loss 0.30558133125305176, acc=0.8766111135482788, loss=0.30558133125305176
test: epoch 25, loss 1.0939548015594482, acc=0.550000011920929, loss=1.0939548015594482
train: epoch 26, loss 0.31851983070373535, acc=0.8724444508552551, loss=0.31851983070373535
test: epoch 26, loss 1.0240811109542847, acc=0.6083333492279053, loss=1.0240811109542847
train: epoch 27, loss 0.2941284477710724, acc=0.8796666860580444, loss=0.2941284477710724
test: epoch 27, loss 1.0244711637496948, acc=0.6472222208976746, loss=1.0244711637496948
train: epoch 28, loss 0.2972332835197449, acc=0.878944456577301, loss=0.2972332835197449
test: epoch 28, loss 1.2277647256851196, acc=0.6277777552604675, loss=1.2277647256851196
train: epoch 29, loss 0.2837091088294983, acc=0.883055567741394, loss=0.2837091088294983
test: epoch 29, loss 1.0765736103057861, acc=0.625, loss=1.0765736103057861
train: epoch 30, loss 0.28635311126708984, acc=0.8833333253860474, loss=0.28635311126708984
test: epoch 30, loss 1.0247056484222412, acc=0.5361111164093018, loss=1.0247056484222412
train: epoch 31, loss 0.2691534757614136, acc=0.8926666378974915, loss=0.2691534757614136
test: epoch 31, loss 1.1266233921051025, acc=0.6583333611488342, loss=1.1266233921051025
train: epoch 32, loss 0.27587413787841797, acc=0.890999972820282, loss=0.27587413787841797
test: epoch 32, loss 1.145334005355835, acc=0.6277777552604675, loss=1.145334005355835
train: epoch 33, loss 0.26846572756767273, acc=0.8925555348396301, loss=0.26846572756767273
test: epoch 33, loss 1.3379137516021729, acc=0.6222222447395325, loss=1.3379137516021729
train: epoch 34, loss 0.28422805666923523, acc=0.8889444470405579, loss=0.28422805666923523
test: epoch 34, loss 0.8299043774604797, acc=0.6472222208976746, loss=0.8299043774604797
train: epoch 35, loss 0.25199094414711, acc=0.8980555534362793, loss=0.25199094414711
test: epoch 35, loss 0.9764477610588074, acc=0.6583333611488342, loss=0.9764477610588074
train: epoch 36, loss 0.25801071524620056, acc=0.8959444165229797, loss=0.25801071524620056
test: epoch 36, loss 0.7994982600212097, acc=0.7194444537162781, loss=0.7994982600212097
train: epoch 37, loss 0.2474384754896164, acc=0.8985000252723694, loss=0.2474384754896164
test: epoch 37, loss 0.7746401429176331, acc=0.730555534362793, loss=0.7746401429176331
train: epoch 38, loss 0.23579412698745728, acc=0.9048333168029785, loss=0.23579412698745728
test: epoch 38, loss 0.9418584704399109, acc=0.6972222328186035, loss=0.9418584704399109
train: epoch 39, loss 0.24379867315292358, acc=0.9014444351196289, loss=0.24379867315292358
test: epoch 39, loss 0.6772435903549194, acc=0.730555534362793, loss=0.6772435903549194
train: epoch 40, loss 0.23472601175308228, acc=0.9042778015136719, loss=0.23472601175308228
test: epoch 40, loss 0.6978883147239685, acc=0.7527777552604675, loss=0.6978883147239685
train: epoch 41, loss 0.24211563169956207, acc=0.9007222056388855, loss=0.24211563169956207
test: epoch 41, loss 0.7232850790023804, acc=0.730555534362793, loss=0.7232850790023804
train: epoch 42, loss 0.2401420623064041, acc=0.9030555486679077, loss=0.2401420623064041
test: epoch 42, loss 0.8224416971206665, acc=0.7027778029441833, loss=0.8224416971206665
train: epoch 43, loss 0.22420671582221985, acc=0.9070555567741394, loss=0.22420671582221985
test: epoch 43, loss 0.6673952341079712, acc=0.7361111044883728, loss=0.6673952341079712
train: epoch 44, loss 0.20946337282657623, acc=0.9107778072357178, loss=0.20946337282657623
test: epoch 44, loss 0.7711678743362427, acc=0.7388888597488403, loss=0.7711678743362427
train: epoch 45, loss 0.2250632345676422, acc=0.9080555438995361, loss=0.2250632345676422
test: epoch 45, loss 0.7030375599861145, acc=0.7444444298744202, loss=0.7030375599861145
train: epoch 46, loss 0.2147289365530014, acc=0.9114444255828857, loss=0.2147289365530014
test: epoch 46, loss 0.6238789558410645, acc=0.7833333611488342, loss=0.6238789558410645
train: epoch 47, loss 0.21632923185825348, acc=0.9105555415153503, loss=0.21632923185825348
test: epoch 47, loss 0.6635727286338806, acc=0.7749999761581421, loss=0.6635727286338806
train: epoch 48, loss 0.2044094353914261, acc=0.9139444231987, loss=0.2044094353914261
test: epoch 48, loss 0.5139369368553162, acc=0.8111110925674438, loss=0.5139369368553162
train: epoch 49, loss 0.19649577140808105, acc=0.9159444570541382, loss=0.19649577140808105
test: epoch 49, loss 0.5383030772209167, acc=0.8305555582046509, loss=0.5383030772209167
train: epoch 50, loss 0.20576953887939453, acc=0.913777768611908, loss=0.20576953887939453
test: epoch 50, loss 0.41483214497566223, acc=0.8111110925674438, loss=0.41483214497566223
train: epoch 51, loss 0.2058020532131195, acc=0.9163888692855835, loss=0.2058020532131195
test: epoch 51, loss 0.5946701765060425, acc=0.8444444537162781, loss=0.5946701765060425
train: epoch 52, loss 0.19449684023857117, acc=0.9189444184303284, loss=0.19449684023857117
test: epoch 52, loss 0.43589699268341064, acc=0.8388888835906982, loss=0.43589699268341064
train: epoch 53, loss 0.17880766093730927, acc=0.9237222075462341, loss=0.17880766093730927
test: epoch 53, loss 0.42576083540916443, acc=0.8527777791023254, loss=0.42576083540916443
train: epoch 54, loss 0.17170967161655426, acc=0.9269444346427917, loss=0.17170967161655426
test: epoch 54, loss 0.2542456090450287, acc=0.9083333611488342, loss=0.2542456090450287
train: epoch 55, loss 0.1629539579153061, acc=0.9304444193840027, loss=0.1629539579153061
test: epoch 55, loss 0.1671307533979416, acc=0.9333333373069763, loss=0.1671307533979416
train: epoch 56, loss 0.1629931628704071, acc=0.9307222366333008, loss=0.1629931628704071
test: epoch 56, loss 0.13863275945186615, acc=0.9361110925674438, loss=0.13863275945186615
train: epoch 57, loss 0.15421687066555023, acc=0.9322777986526489, loss=0.15421687066555023
test: epoch 57, loss 0.1424306184053421, acc=0.9277777671813965, loss=0.1424306184053421
train: epoch 58, loss 0.15861503779888153, acc=0.9315555691719055, loss=0.15861503779888153
test: epoch 58, loss 0.1908070296049118, acc=0.9222221970558167, loss=0.1908070296049118
train: epoch 59, loss 0.1475854367017746, acc=0.9357222318649292, loss=0.1475854367017746
test: epoch 59, loss 0.24130961298942566, acc=0.9194444417953491, loss=0.24130961298942566
train: epoch 60, loss 0.13606135547161102, acc=0.9368888735771179, loss=0.13606135547161102
test: epoch 60, loss 0.17508454620838165, acc=0.9277777671813965, loss=0.17508454620838165
train: epoch 61, loss 0.13599331676959991, acc=0.9366666674613953, loss=0.13599331676959991
test: epoch 61, loss 0.17112189531326294, acc=0.9305555820465088, loss=0.17112189531326294
train: epoch 62, loss 0.1323801875114441, acc=0.9380555748939514, loss=0.1323801875114441
test: epoch 62, loss 0.17799833416938782, acc=0.9333333373069763, loss=0.17799833416938782
train: epoch 63, loss 0.1327488273382187, acc=0.9381666779518127, loss=0.1327488273382187
test: epoch 63, loss 0.1741734743118286, acc=0.9305555820465088, loss=0.1741734743118286
train: epoch 64, loss 0.13261204957962036, acc=0.9382222294807434, loss=0.13261204957962036
test: epoch 64, loss 0.1367505043745041, acc=0.9305555820465088, loss=0.1367505043745041
train: epoch 65, loss 0.13652333617210388, acc=0.9384444355964661, loss=0.13652333617210388
test: epoch 65, loss 0.15922094881534576, acc=0.9305555820465088, loss=0.15922094881534576
train: epoch 66, loss 0.11629613488912582, acc=0.9423888921737671, loss=0.11629613488912582
test: epoch 66, loss 0.16456572711467743, acc=0.9305555820465088, loss=0.16456572711467743
train: epoch 67, loss 0.13027821481227875, acc=0.9385555386543274, loss=0.13027821481227875
test: epoch 67, loss 0.14236566424369812, acc=0.9333333373069763, loss=0.14236566424369812
train: epoch 68, loss 0.12273721396923065, acc=0.941777765750885, loss=0.12273721396923065
test: epoch 68, loss 0.1726219207048416, acc=0.9305555820465088, loss=0.1726219207048416
train: epoch 69, loss 0.12305127829313278, acc=0.9421666860580444, loss=0.12305127829313278
test: epoch 69, loss 0.13658899068832397, acc=0.9305555820465088, loss=0.13658899068832397
train: epoch 70, loss 0.1264842301607132, acc=0.9401666522026062, loss=0.1264842301607132
test: epoch 70, loss 0.17294175922870636, acc=0.9305555820465088, loss=0.17294175922870636
train: epoch 71, loss 0.10965888202190399, acc=0.9440555572509766, loss=0.10965888202190399
test: epoch 71, loss 0.16588865220546722, acc=0.9305555820465088, loss=0.16588865220546722
train: epoch 72, loss 0.1218438595533371, acc=0.9412222504615784, loss=0.1218438595533371
test: epoch 72, loss 0.15165956318378448, acc=0.9277777671813965, loss=0.15165956318378448
train: epoch 73, loss 0.12179546803236008, acc=0.9416666626930237, loss=0.12179546803236008
test: epoch 73, loss 0.12868213653564453, acc=0.9305555820465088, loss=0.12868213653564453
train: epoch 74, loss 0.12973855435848236, acc=0.9398333430290222, loss=0.12973855435848236
test: epoch 74, loss 0.17153668403625488, acc=0.9333333373069763, loss=0.17153668403625488
train: epoch 75, loss 0.10784200578927994, acc=0.944944441318512, loss=0.10784200578927994
test: epoch 75, loss 0.15689720213413239, acc=0.9333333373069763, loss=0.15689720213413239
train: epoch 76, loss 0.10578745603561401, acc=0.945555567741394, loss=0.10578745603561401
test: epoch 76, loss 0.15406396985054016, acc=0.9333333373069763, loss=0.15406396985054016
train: epoch 77, loss 0.12077296525239944, acc=0.9423888921737671, loss=0.12077296525239944
test: epoch 77, loss 0.13206596672534943, acc=0.9333333373069763, loss=0.13206596672534943
train: epoch 78, loss 0.09993408620357513, acc=0.9467222094535828, loss=0.09993408620357513
test: epoch 78, loss 0.15226396918296814, acc=0.9333333373069763, loss=0.15226396918296814
train: epoch 79, loss 0.11225473135709763, acc=0.9449999928474426, loss=0.11225473135709763
test: epoch 79, loss 0.14615654945373535, acc=0.9333333373069763, loss=0.14615654945373535
train: epoch 80, loss 0.09938466548919678, acc=0.9467222094535828, loss=0.09938466548919678
test: epoch 80, loss 0.1490495353937149, acc=0.9333333373069763, loss=0.1490495353937149
train: epoch 81, loss 0.1110992357134819, acc=0.9447222352027893, loss=0.1110992357134819
test: epoch 81, loss 0.2036363184452057, acc=0.9222221970558167, loss=0.2036363184452057
train: epoch 82, loss 0.129452183842659, acc=0.9396111369132996, loss=0.129452183842659
test: epoch 82, loss 0.1301935464143753, acc=0.9333333373069763, loss=0.1301935464143753
train: epoch 83, loss 0.10382118821144104, acc=0.94605553150177, loss=0.10382118821144104
test: epoch 83, loss 0.1334327608346939, acc=0.9333333373069763, loss=0.1334327608346939
train: epoch 84, loss 0.10939224064350128, acc=0.9448888897895813, loss=0.10939224064350128
test: epoch 84, loss 0.234954833984375, acc=0.9361110925674438, loss=0.234954833984375
train: epoch 85, loss 0.1206035166978836, acc=0.9422222375869751, loss=0.1206035166978836
test: epoch 85, loss 0.16440390050411224, acc=0.9305555820465088, loss=0.16440390050411224
train: epoch 86, loss 0.10647904872894287, acc=0.9461666941642761, loss=0.10647904872894287
test: epoch 86, loss 0.1447482407093048, acc=0.9333333373069763, loss=0.1447482407093048
train: epoch 87, loss 0.10810253024101257, acc=0.945555567741394, loss=0.10810253024101257
test: epoch 87, loss 0.17344312369823456, acc=0.9333333373069763, loss=0.17344312369823456
train: epoch 88, loss 0.10961990058422089, acc=0.9456111192703247, loss=0.10961990058422089
test: epoch 88, loss 0.14680850505828857, acc=0.9333333373069763, loss=0.14680850505828857
train: epoch 89, loss 0.11527696996927261, acc=0.9441666603088379, loss=0.11527696996927261
test: epoch 89, loss 0.17715390026569366, acc=0.9333333373069763, loss=0.17715390026569366
train: epoch 90, loss 0.10739260911941528, acc=0.9463333487510681, loss=0.10739260911941528
test: epoch 90, loss 0.1179654449224472, acc=0.9333333373069763, loss=0.1179654449224472
train: epoch 91, loss 0.10226984322071075, acc=0.9465000033378601, loss=0.10226984322071075
test: epoch 91, loss 0.2556779682636261, acc=0.9222221970558167, loss=0.2556779682636261
train: epoch 92, loss 0.10832515358924866, acc=0.9462222456932068, loss=0.10832515358924866
test: epoch 92, loss 0.16110917925834656, acc=0.9333333373069763, loss=0.16110917925834656
train: epoch 93, loss 0.11234163492918015, acc=0.945277750492096, loss=0.11234163492918015
test: epoch 93, loss 0.17210902273654938, acc=0.9305555820465088, loss=0.17210902273654938
train: epoch 94, loss 0.10910080373287201, acc=0.945555567741394, loss=0.10910080373287201
test: epoch 94, loss 0.14545424282550812, acc=0.9333333373069763, loss=0.14545424282550812
train: epoch 95, loss 0.11131353676319122, acc=0.945888876914978, loss=0.11131353676319122
test: epoch 95, loss 0.15567557513713837, acc=0.9333333373069763, loss=0.15567557513713837
train: epoch 96, loss 0.0968361496925354, acc=0.9480000138282776, loss=0.0968361496925354
test: epoch 96, loss 0.1403045803308487, acc=0.9333333373069763, loss=0.1403045803308487
train: epoch 97, loss 0.09777823090553284, acc=0.9479444622993469, loss=0.09777823090553284
test: epoch 97, loss 0.13761937618255615, acc=0.9333333373069763, loss=0.13761937618255615
train: epoch 98, loss 0.09955856949090958, acc=0.9479444622993469, loss=0.09955856949090958
test: epoch 98, loss 0.12814445793628693, acc=0.9333333373069763, loss=0.12814445793628693
train: epoch 99, loss 0.11159410327672958, acc=0.9461110830307007, loss=0.11159410327672958
test: epoch 99, loss 0.14408868551254272, acc=0.9333333373069763, loss=0.14408868551254272
train: epoch 100, loss 0.11937636882066727, acc=0.9433888792991638, loss=0.11937636882066727
test: epoch 100, loss 0.12329741567373276, acc=0.9333333373069763, loss=0.12329741567373276
train: epoch 101, loss 0.10330797731876373, acc=0.9463333487510681, loss=0.10330797731876373
test: epoch 101, loss 0.1512022614479065, acc=0.9333333373069763, loss=0.1512022614479065
train: epoch 102, loss 0.09897417575120926, acc=0.9476666450500488, loss=0.09897417575120926
test: epoch 102, loss 0.24621647596359253, acc=0.9222221970558167, loss=0.24621647596359253
train: epoch 103, loss 0.11495941132307053, acc=0.9454444646835327, loss=0.11495941132307053
test: epoch 103, loss 0.14466606080532074, acc=0.9333333373069763, loss=0.14466606080532074
train: epoch 104, loss 0.10782375931739807, acc=0.9464444518089294, loss=0.10782375931739807
test: epoch 104, loss 0.1644682139158249, acc=0.9333333373069763, loss=0.1644682139158249
train: epoch 105, loss 0.10267960280179977, acc=0.9476110935211182, loss=0.10267960280179977
test: epoch 105, loss 0.14979641139507294, acc=0.9333333373069763, loss=0.14979641139507294
train: epoch 106, loss 0.10258656740188599, acc=0.9466666579246521, loss=0.10258656740188599
test: epoch 106, loss 0.1445467323064804, acc=0.9333333373069763, loss=0.1445467323064804
train: epoch 107, loss 0.09960958361625671, acc=0.9477777481079102, loss=0.09960958361625671
test: epoch 107, loss 0.15669624507427216, acc=0.9333333373069763, loss=0.15669624507427216
train: epoch 108, loss 0.09477263689041138, acc=0.9492777585983276, loss=0.09477263689041138
test: epoch 108, loss 0.15746524930000305, acc=0.9333333373069763, loss=0.15746524930000305
train: epoch 109, loss 0.11889583617448807, acc=0.9434444308280945, loss=0.11889583617448807
test: epoch 109, loss 0.14068447053432465, acc=0.9305555820465088, loss=0.14068447053432465
train: epoch 110, loss 0.11201734840869904, acc=0.9451666474342346, loss=0.11201734840869904
test: epoch 110, loss 0.1360606998205185, acc=0.9333333373069763, loss=0.1360606998205185
train: epoch 111, loss 0.10958555340766907, acc=0.9461110830307007, loss=0.10958555340766907
test: epoch 111, loss 0.1247694343328476, acc=0.9361110925674438, loss=0.1247694343328476
train: epoch 112, loss 0.11312777549028397, acc=0.9463889002799988, loss=0.11312777549028397
test: epoch 112, loss 0.13287539780139923, acc=0.9333333373069763, loss=0.13287539780139923
train: epoch 113, loss 0.09445033967494965, acc=0.9485555291175842, loss=0.09445033967494965
test: epoch 113, loss 0.14108389616012573, acc=0.9333333373069763, loss=0.14108389616012573
train: epoch 114, loss 0.09983948618173599, acc=0.9474444389343262, loss=0.09983948618173599
test: epoch 114, loss 0.17695792019367218, acc=0.9333333373069763, loss=0.17695792019367218
train: epoch 115, loss 0.10584563761949539, acc=0.9473333358764648, loss=0.10584563761949539
test: epoch 115, loss 0.1504850685596466, acc=0.9333333373069763, loss=0.1504850685596466
train: epoch 116, loss 0.1235365942120552, acc=0.9424444437026978, loss=0.1235365942120552
test: epoch 116, loss 0.13767284154891968, acc=0.9333333373069763, loss=0.13767284154891968
train: epoch 117, loss 0.10454010218381882, acc=0.9464444518089294, loss=0.10454010218381882
test: epoch 117, loss 0.1790321320295334, acc=0.9333333373069763, loss=0.1790321320295334
train: epoch 118, loss 0.09811095893383026, acc=0.9484999775886536, loss=0.09811095893383026
test: epoch 118, loss 0.12586426734924316, acc=0.9333333373069763, loss=0.12586426734924316
train: epoch 119, loss 0.10586590319871902, acc=0.9484999775886536, loss=0.10586590319871902
test: epoch 119, loss 0.14331629872322083, acc=0.9333333373069763, loss=0.14331629872322083
train: epoch 120, loss 0.09926853328943253, acc=0.9471111297607422, loss=0.09926853328943253
test: epoch 120, loss 0.14525464177131653, acc=0.9333333373069763, loss=0.14525464177131653
train: epoch 121, loss 0.09572850167751312, acc=0.9486111402511597, loss=0.09572850167751312
test: epoch 121, loss 0.13282768428325653, acc=0.9333333373069763, loss=0.13282768428325653
train: epoch 122, loss 0.09454235434532166, acc=0.9486666917800903, loss=0.09454235434532166
test: epoch 122, loss 0.1538051962852478, acc=0.9333333373069763, loss=0.1538051962852478
train: epoch 123, loss 0.10417724400758743, acc=0.9469444155693054, loss=0.10417724400758743
test: epoch 123, loss 0.1788850575685501, acc=0.9333333373069763, loss=0.1788850575685501
train: epoch 124, loss 0.14352969825267792, acc=0.9387221932411194, loss=0.14352969825267792
test: epoch 124, loss 0.1975104957818985, acc=0.925000011920929, loss=0.1975104957818985
train: epoch 125, loss 0.1072365790605545, acc=0.9475555419921875, loss=0.1072365790605545
test: epoch 125, loss 0.13797250390052795, acc=0.9333333373069763, loss=0.13797250390052795
train: epoch 126, loss 0.093031145632267, acc=0.9490000009536743, loss=0.093031145632267
test: epoch 126, loss 0.15532824397087097, acc=0.9333333373069763, loss=0.15532824397087097
train: epoch 127, loss 0.09091655910015106, acc=0.9491111040115356, loss=0.09091655910015106
test: epoch 127, loss 0.1659030169248581, acc=0.9333333373069763, loss=0.1659030169248581
train: epoch 128, loss 0.094723179936409, acc=0.9486111402511597, loss=0.094723179936409
test: epoch 128, loss 0.1416756510734558, acc=0.9333333373069763, loss=0.1416756510734558
train: epoch 129, loss 0.1075262576341629, acc=0.9464444518089294, loss=0.1075262576341629
test: epoch 129, loss 0.13646310567855835, acc=0.9333333373069763, loss=0.13646310567855835
train: epoch 130, loss 0.0963558480143547, acc=0.948722243309021, loss=0.0963558480143547
test: epoch 130, loss 0.14625172317028046, acc=0.9333333373069763, loss=0.14625172317028046
train: epoch 131, loss 0.1071428433060646, acc=0.9467777609825134, loss=0.1071428433060646
test: epoch 131, loss 0.13119468092918396, acc=0.9333333373069763, loss=0.13119468092918396
train: epoch 132, loss 0.10214003175497055, acc=0.9476110935211182, loss=0.10214003175497055
test: epoch 132, loss 0.16314107179641724, acc=0.9333333373069763, loss=0.16314107179641724
train: epoch 133, loss 0.10250863432884216, acc=0.9476666450500488, loss=0.10250863432884216
test: epoch 133, loss 0.1488151252269745, acc=0.9361110925674438, loss=0.1488151252269745
train: epoch 134, loss 0.09846782684326172, acc=0.9483888745307922, loss=0.09846782684326172
test: epoch 134, loss 0.15128201246261597, acc=0.9333333373069763, loss=0.15128201246261597
train: epoch 135, loss 0.09704612195491791, acc=0.9483333230018616, loss=0.09704612195491791
test: epoch 135, loss 0.14844578504562378, acc=0.9333333373069763, loss=0.14844578504562378
train: epoch 136, loss 0.10135146230459213, acc=0.9480000138282776, loss=0.10135146230459213
test: epoch 136, loss 0.2675367593765259, acc=0.925000011920929, loss=0.2675367593765259
train: epoch 137, loss 0.10228089243173599, acc=0.9473333358764648, loss=0.10228089243173599
test: epoch 137, loss 0.1532507687807083, acc=0.9333333373069763, loss=0.1532507687807083
train: epoch 138, loss 0.10027994215488434, acc=0.9474999904632568, loss=0.10027994215488434
test: epoch 138, loss 0.1465662270784378, acc=0.9333333373069763, loss=0.1465662270784378
train: epoch 139, loss 0.09793728590011597, acc=0.9481666684150696, loss=0.09793728590011597
test: epoch 139, loss 0.1479884535074234, acc=0.9333333373069763, loss=0.1479884535074234
train: epoch 140, loss 0.09451736509799957, acc=0.9486666917800903, loss=0.09451736509799957
test: epoch 140, loss 0.14952856302261353, acc=0.9333333373069763, loss=0.14952856302261353
train: epoch 141, loss 0.10803481191396713, acc=0.9473888874053955, loss=0.10803481191396713
test: epoch 141, loss 0.15713827311992645, acc=0.9333333373069763, loss=0.15713827311992645
train: epoch 142, loss 0.08829527348279953, acc=0.9504444599151611, loss=0.08829527348279953
test: epoch 142, loss 0.16156770288944244, acc=0.9333333373069763, loss=0.16156770288944244
train: epoch 143, loss 0.09483208507299423, acc=0.948888897895813, loss=0.09483208507299423
test: epoch 143, loss 0.13686300814151764, acc=0.9333333373069763, loss=0.13686300814151764
train: epoch 144, loss 0.09572384506464005, acc=0.9490000009536743, loss=0.09572384506464005
test: epoch 144, loss 0.15495257079601288, acc=0.9333333373069763, loss=0.15495257079601288
train: epoch 145, loss 0.0886981412768364, acc=0.9503333568572998, loss=0.0886981412768364
test: epoch 145, loss 0.15523627400398254, acc=0.9333333373069763, loss=0.15523627400398254
train: epoch 146, loss 0.09909242391586304, acc=0.9480555653572083, loss=0.09909242391586304
test: epoch 146, loss 0.1458071917295456, acc=0.9333333373069763, loss=0.1458071917295456
train: epoch 147, loss 0.09726405143737793, acc=0.9484444260597229, loss=0.09726405143737793
test: epoch 147, loss 0.16968227922916412, acc=0.9305555820465088, loss=0.16968227922916412
train: epoch 148, loss 0.10599308460950851, acc=0.9475555419921875, loss=0.10599308460950851
test: epoch 148, loss 0.188373401761055, acc=0.9305555820465088, loss=0.188373401761055
train: epoch 149, loss 0.10188184678554535, acc=0.9467777609825134, loss=0.10188184678554535
test: epoch 149, loss 0.1523459106683731, acc=0.9333333373069763, loss=0.1523459106683731
train: epoch 150, loss 0.09930478036403656, acc=0.9476110935211182, loss=0.09930478036403656
test: epoch 150, loss 0.19302262365818024, acc=0.9138888716697693, loss=0.19302262365818024
