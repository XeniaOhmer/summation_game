# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=1.5", "--temp_decay=1", "--one_hot=false", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=2073292178, receiver_embed_dim=64, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.9431681632995605, acc=0.08977777510881424, loss=2.9431681632995605
test: epoch 1, loss 3.158362627029419, acc=0.12222222238779068, loss=3.158362627029419
train: epoch 2, loss 1.967599630355835, acc=0.2358333319425583, loss=1.967599630355835
test: epoch 2, loss 2.8735854625701904, acc=0.15000000596046448, loss=2.8735854625701904
train: epoch 3, loss 1.451859474182129, acc=0.4251111149787903, loss=1.451859474182129
test: epoch 3, loss 2.354212760925293, acc=0.21944443881511688, loss=2.354212760925293
train: epoch 4, loss 1.0493216514587402, acc=0.5816666483879089, loss=1.0493216514587402
test: epoch 4, loss 2.2096359729766846, acc=0.25555557012557983, loss=2.2096359729766846
train: epoch 5, loss 0.8717649579048157, acc=0.6526666879653931, loss=0.8717649579048157
test: epoch 5, loss 2.0578975677490234, acc=0.3027777671813965, loss=2.0578975677490234
train: epoch 6, loss 0.7651383876800537, acc=0.690833330154419, loss=0.7651383876800537
test: epoch 6, loss 2.035126209259033, acc=0.30000001192092896, loss=2.035126209259033
train: epoch 7, loss 0.6771682500839233, acc=0.7256666421890259, loss=0.6771682500839233
test: epoch 7, loss 1.9580984115600586, acc=0.3194444477558136, loss=1.9580984115600586
train: epoch 8, loss 0.6022964715957642, acc=0.7573888897895813, loss=0.6022964715957642
test: epoch 8, loss 1.857344627380371, acc=0.3444444537162781, loss=1.857344627380371
train: epoch 9, loss 0.5606920719146729, acc=0.7700555324554443, loss=0.5606920719146729
test: epoch 9, loss 1.7338616847991943, acc=0.3611111044883728, loss=1.7338616847991943
train: epoch 10, loss 0.537014901638031, acc=0.7813888788223267, loss=0.537014901638031
test: epoch 10, loss 1.9840790033340454, acc=0.3611111044883728, loss=1.9840790033340454
train: epoch 11, loss 0.5003139972686768, acc=0.7992777824401855, loss=0.5003139972686768
test: epoch 11, loss 1.9621870517730713, acc=0.375, loss=1.9621870517730713
train: epoch 12, loss 0.46638578176498413, acc=0.8137778043746948, loss=0.46638578176498413
test: epoch 12, loss 1.8669500350952148, acc=0.43888887763023376, loss=1.8669500350952148
train: epoch 13, loss 0.4358160197734833, acc=0.8246666789054871, loss=0.4358160197734833
test: epoch 13, loss 1.8045709133148193, acc=0.40833333134651184, loss=1.8045709133148193
train: epoch 14, loss 0.3852505385875702, acc=0.8483333587646484, loss=0.3852505385875702
test: epoch 14, loss 1.7709788084030151, acc=0.3861111104488373, loss=1.7709788084030151
train: epoch 15, loss 0.3812221586704254, acc=0.8488888740539551, loss=0.3812221586704254
test: epoch 15, loss 1.8560773134231567, acc=0.4138889014720917, loss=1.8560773134231567
train: epoch 16, loss 0.36236056685447693, acc=0.85188889503479, loss=0.36236056685447693
test: epoch 16, loss 1.7192919254302979, acc=0.46388888359069824, loss=1.7192919254302979
train: epoch 17, loss 0.32922908663749695, acc=0.8654444217681885, loss=0.32922908663749695
test: epoch 17, loss 1.799089789390564, acc=0.3861111104488373, loss=1.799089789390564
train: epoch 18, loss 0.31401827931404114, acc=0.8737221956253052, loss=0.31401827931404114
test: epoch 18, loss 1.4588960409164429, acc=0.4749999940395355, loss=1.4588960409164429
train: epoch 19, loss 0.3108919560909271, acc=0.870555579662323, loss=0.3108919560909271
test: epoch 19, loss 1.518466591835022, acc=0.5055555701255798, loss=1.518466591835022
train: epoch 20, loss 0.29835933446884155, acc=0.8804444670677185, loss=0.29835933446884155
test: epoch 20, loss 1.9018059968948364, acc=0.43888887763023376, loss=1.9018059968948364
train: epoch 21, loss 0.26345640420913696, acc=0.891777753829956, loss=0.26345640420913696
test: epoch 21, loss 1.5390852689743042, acc=0.4749999940395355, loss=1.5390852689743042
train: epoch 22, loss 0.2733376920223236, acc=0.8855555653572083, loss=0.2733376920223236
test: epoch 22, loss 1.7756972312927246, acc=0.42500001192092896, loss=1.7756972312927246
train: epoch 23, loss 0.24811267852783203, acc=0.8940555453300476, loss=0.24811267852783203
test: epoch 23, loss 1.5022826194763184, acc=0.5222222208976746, loss=1.5022826194763184
train: epoch 24, loss 0.25092342495918274, acc=0.8905555605888367, loss=0.25092342495918274
test: epoch 24, loss 1.4607998132705688, acc=0.5472221970558167, loss=1.4607998132705688
train: epoch 25, loss 0.2321356236934662, acc=0.8996666669845581, loss=0.2321356236934662
test: epoch 25, loss 1.8696529865264893, acc=0.46388888359069824, loss=1.8696529865264893
train: epoch 26, loss 0.24344222247600555, acc=0.8966666460037231, loss=0.24344222247600555
test: epoch 26, loss 1.6746245622634888, acc=0.49166667461395264, loss=1.6746245622634888
train: epoch 27, loss 0.23204930126667023, acc=0.8999999761581421, loss=0.23204930126667023
test: epoch 27, loss 1.9235199689865112, acc=0.4749999940395355, loss=1.9235199689865112
train: epoch 28, loss 0.21337340772151947, acc=0.9036666750907898, loss=0.21337340772151947
test: epoch 28, loss 1.7073616981506348, acc=0.5444444417953491, loss=1.7073616981506348
train: epoch 29, loss 0.21663250029087067, acc=0.9054444432258606, loss=0.21663250029087067
test: epoch 29, loss 1.7999273538589478, acc=0.4972222149372101, loss=1.7999273538589478
train: epoch 30, loss 0.2111351639032364, acc=0.9072222113609314, loss=0.2111351639032364
test: epoch 30, loss 2.0583925247192383, acc=0.44999998807907104, loss=2.0583925247192383
train: epoch 31, loss 0.20332804322242737, acc=0.9095555543899536, loss=0.20332804322242737
test: epoch 31, loss 1.4881260395050049, acc=0.5388888716697693, loss=1.4881260395050049
train: epoch 32, loss 0.19343866407871246, acc=0.9121666550636292, loss=0.19343866407871246
test: epoch 32, loss 1.9653270244598389, acc=0.5083333253860474, loss=1.9653270244598389
train: epoch 33, loss 0.2016700655221939, acc=0.9100000262260437, loss=0.2016700655221939
test: epoch 33, loss 1.6241037845611572, acc=0.4694444537162781, loss=1.6241037845611572
train: epoch 34, loss 0.1750544160604477, acc=0.9200555682182312, loss=0.1750544160604477
test: epoch 34, loss 1.5919382572174072, acc=0.5, loss=1.5919382572174072
train: epoch 35, loss 0.18475081026554108, acc=0.9164444208145142, loss=0.18475081026554108
test: epoch 35, loss 1.4909542798995972, acc=0.5472221970558167, loss=1.4909542798995972
train: epoch 36, loss 0.18275007605552673, acc=0.9196110963821411, loss=0.18275007605552673
test: epoch 36, loss 1.683756947517395, acc=0.5138888955116272, loss=1.683756947517395
train: epoch 37, loss 0.17819158732891083, acc=0.9202222228050232, loss=0.17819158732891083
test: epoch 37, loss 1.6021692752838135, acc=0.5416666865348816, loss=1.6021692752838135
train: epoch 38, loss 0.174711674451828, acc=0.9225000143051147, loss=0.174711674451828
test: epoch 38, loss 1.6442322731018066, acc=0.5027777552604675, loss=1.6442322731018066
train: epoch 39, loss 0.16990356147289276, acc=0.9210555553436279, loss=0.16990356147289276
test: epoch 39, loss 1.6986054182052612, acc=0.5388888716697693, loss=1.6986054182052612
train: epoch 40, loss 0.15770241618156433, acc=0.9267777800559998, loss=0.15770241618156433
test: epoch 40, loss 1.8176063299179077, acc=0.5638889074325562, loss=1.8176063299179077
train: epoch 41, loss 0.17810127139091492, acc=0.9202777743339539, loss=0.17810127139091492
test: epoch 41, loss 1.408020257949829, acc=0.5444444417953491, loss=1.408020257949829
train: epoch 42, loss 0.15844818949699402, acc=0.9278333187103271, loss=0.15844818949699402
test: epoch 42, loss 1.4293524026870728, acc=0.5111111402511597, loss=1.4293524026870728
train: epoch 43, loss 0.15591660141944885, acc=0.9272222518920898, loss=0.15591660141944885
test: epoch 43, loss 1.7675819396972656, acc=0.5861111283302307, loss=1.7675819396972656
train: epoch 44, loss 0.1556047648191452, acc=0.9286666512489319, loss=0.1556047648191452
test: epoch 44, loss 1.71152925491333, acc=0.5666666626930237, loss=1.71152925491333
train: epoch 45, loss 0.1531352400779724, acc=0.9278888702392578, loss=0.1531352400779724
test: epoch 45, loss 1.6551311016082764, acc=0.6194444298744202, loss=1.6551311016082764
train: epoch 46, loss 0.15658727288246155, acc=0.9294999837875366, loss=0.15658727288246155
test: epoch 46, loss 1.5921345949172974, acc=0.5944444537162781, loss=1.5921345949172974
train: epoch 47, loss 0.1445969194173813, acc=0.9307222366333008, loss=0.1445969194173813
test: epoch 47, loss 1.3676122426986694, acc=0.6499999761581421, loss=1.3676122426986694
train: epoch 48, loss 0.15346616506576538, acc=0.9278888702392578, loss=0.15346616506576538
test: epoch 48, loss 1.1818231344223022, acc=0.644444465637207, loss=1.1818231344223022
train: epoch 49, loss 0.1522776037454605, acc=0.9307222366333008, loss=0.1522776037454605
test: epoch 49, loss 1.4582102298736572, acc=0.6527777910232544, loss=1.4582102298736572
train: epoch 50, loss 0.15279294550418854, acc=0.9310555458068848, loss=0.15279294550418854
test: epoch 50, loss 1.2412997484207153, acc=0.675000011920929, loss=1.2412997484207153
train: epoch 51, loss 0.13995036482810974, acc=0.9330000281333923, loss=0.13995036482810974
test: epoch 51, loss 1.2569631338119507, acc=0.6083333492279053, loss=1.2569631338119507
train: epoch 52, loss 0.13269466161727905, acc=0.9367777705192566, loss=0.13269466161727905
test: epoch 52, loss 0.9510576128959656, acc=0.6777777671813965, loss=0.9510576128959656
train: epoch 53, loss 0.14150865375995636, acc=0.9350555539131165, loss=0.14150865375995636
test: epoch 53, loss 1.295466423034668, acc=0.6388888955116272, loss=1.295466423034668
train: epoch 54, loss 0.12900538742542267, acc=0.9380000233650208, loss=0.12900538742542267
test: epoch 54, loss 1.1322247982025146, acc=0.6611111164093018, loss=1.1322247982025146
train: epoch 55, loss 0.1361621618270874, acc=0.937166690826416, loss=0.1361621618270874
test: epoch 55, loss 0.9284442663192749, acc=0.7250000238418579, loss=0.9284442663192749
train: epoch 56, loss 0.1255345493555069, acc=0.9407777786254883, loss=0.1255345493555069
test: epoch 56, loss 0.7654322385787964, acc=0.7138888835906982, loss=0.7654322385787964
train: epoch 57, loss 0.13638345897197723, acc=0.9366111159324646, loss=0.13638345897197723
test: epoch 57, loss 1.0870604515075684, acc=0.7027778029441833, loss=1.0870604515075684
train: epoch 58, loss 0.12525922060012817, acc=0.9405555725097656, loss=0.12525922060012817
test: epoch 58, loss 1.2929487228393555, acc=0.6805555820465088, loss=1.2929487228393555
train: epoch 59, loss 0.12433286756277084, acc=0.9392222166061401, loss=0.12433286756277084
test: epoch 59, loss 0.7522108554840088, acc=0.7416666746139526, loss=0.7522108554840088
train: epoch 60, loss 0.1322791874408722, acc=0.9381666779518127, loss=0.1322791874408722
test: epoch 60, loss 0.8856221437454224, acc=0.7111111283302307, loss=0.8856221437454224
train: epoch 61, loss 0.13072356581687927, acc=0.9382777810096741, loss=0.13072356581687927
test: epoch 61, loss 0.789899468421936, acc=0.7583333253860474, loss=0.789899468421936
train: epoch 62, loss 0.11910707503557205, acc=0.9440555572509766, loss=0.11910707503557205
test: epoch 62, loss 1.2600622177124023, acc=0.7416666746139526, loss=1.2600622177124023
train: epoch 63, loss 0.12538082897663116, acc=0.9418333172798157, loss=0.12538082897663116
test: epoch 63, loss 0.761722981929779, acc=0.7472222447395325, loss=0.761722981929779
train: epoch 64, loss 0.11315258592367172, acc=0.9437222480773926, loss=0.11315258592367172
test: epoch 64, loss 0.8837451934814453, acc=0.7722222208976746, loss=0.8837451934814453
train: epoch 65, loss 0.11682742834091187, acc=0.9424444437026978, loss=0.11682742834091187
test: epoch 65, loss 0.6489273905754089, acc=0.7888888716697693, loss=0.6489273905754089
train: epoch 66, loss 0.11083713173866272, acc=0.9453333616256714, loss=0.11083713173866272
test: epoch 66, loss 0.8551062941551208, acc=0.7888888716697693, loss=0.8551062941551208
train: epoch 67, loss 0.12193041294813156, acc=0.9421111345291138, loss=0.12193041294813156
test: epoch 67, loss 0.6443200707435608, acc=0.8083333373069763, loss=0.6443200707435608
train: epoch 68, loss 0.1033957451581955, acc=0.9476666450500488, loss=0.1033957451581955
test: epoch 68, loss 0.7262865900993347, acc=0.7555555701255798, loss=0.7262865900993347
train: epoch 69, loss 0.11396078020334244, acc=0.9434999823570251, loss=0.11396078020334244
test: epoch 69, loss 0.7119630575180054, acc=0.730555534362793, loss=0.7119630575180054
train: epoch 70, loss 0.11988849937915802, acc=0.9426666498184204, loss=0.11988849937915802
test: epoch 70, loss 0.7602354288101196, acc=0.75, loss=0.7602354288101196
train: epoch 71, loss 0.1046600490808487, acc=0.9470000267028809, loss=0.1046600490808487
test: epoch 71, loss 0.5170836448669434, acc=0.8388888835906982, loss=0.5170836448669434
train: epoch 72, loss 0.10481879115104675, acc=0.9473888874053955, loss=0.10481879115104675
test: epoch 72, loss 1.0061050653457642, acc=0.7666666507720947, loss=1.0061050653457642
train: epoch 73, loss 0.11193039268255234, acc=0.9434999823570251, loss=0.11193039268255234
test: epoch 73, loss 0.6887399554252625, acc=0.8277778029441833, loss=0.6887399554252625
train: epoch 74, loss 0.10459017753601074, acc=0.9464444518089294, loss=0.10459017753601074
test: epoch 74, loss 0.4333092272281647, acc=0.824999988079071, loss=0.4333092272281647
train: epoch 75, loss 0.10942327231168747, acc=0.9453333616256714, loss=0.10942327231168747
test: epoch 75, loss 0.4512251317501068, acc=0.8333333134651184, loss=0.4512251317501068
train: epoch 76, loss 0.10919427871704102, acc=0.9442777633666992, loss=0.10919427871704102
test: epoch 76, loss 0.9361384510993958, acc=0.769444465637207, loss=0.9361384510993958
train: epoch 77, loss 0.10665316134691238, acc=0.9452221989631653, loss=0.10665316134691238
test: epoch 77, loss 0.577316403388977, acc=0.8305555582046509, loss=0.577316403388977
train: epoch 78, loss 0.0920761227607727, acc=0.949833333492279, loss=0.0920761227607727
test: epoch 78, loss 0.7389932870864868, acc=0.8444444537162781, loss=0.7389932870864868
train: epoch 79, loss 0.10695817321538925, acc=0.9464444518089294, loss=0.10695817321538925
test: epoch 79, loss 0.756447970867157, acc=0.8333333134651184, loss=0.756447970867157
train: epoch 80, loss 0.08986341208219528, acc=0.9641110897064209, loss=0.08986341208219528
test: epoch 80, loss 0.545202374458313, acc=0.8388888835906982, loss=0.545202374458313
train: epoch 81, loss 0.066019706428051, acc=0.9775000214576721, loss=0.066019706428051
test: epoch 81, loss 0.6493409276008606, acc=0.8333333134651184, loss=0.6493409276008606
train: epoch 82, loss 0.06971271336078644, acc=0.9765555262565613, loss=0.06971271336078644
test: epoch 82, loss 0.7212014198303223, acc=0.8111110925674438, loss=0.7212014198303223
train: epoch 83, loss 0.05551455542445183, acc=0.9807222485542297, loss=0.05551455542445183
test: epoch 83, loss 0.6729328036308289, acc=0.8083333373069763, loss=0.6729328036308289
train: epoch 84, loss 0.0565003864467144, acc=0.9812222123146057, loss=0.0565003864467144
test: epoch 84, loss 0.5051287412643433, acc=0.7888888716697693, loss=0.5051287412643433
train: epoch 85, loss 0.05835045874118805, acc=0.9806110858917236, loss=0.05835045874118805
test: epoch 85, loss 0.5709546804428101, acc=0.8500000238418579, loss=0.5709546804428101
train: epoch 86, loss 0.06042707711458206, acc=0.9800000190734863, loss=0.06042707711458206
test: epoch 86, loss 0.5589888691902161, acc=0.8194444179534912, loss=0.5589888691902161
train: epoch 87, loss 0.05281926319003105, acc=0.9810555577278137, loss=0.05281926319003105
test: epoch 87, loss 0.6944701075553894, acc=0.8361111283302307, loss=0.6944701075553894
train: epoch 88, loss 0.05296168476343155, acc=0.9803333282470703, loss=0.05296168476343155
test: epoch 88, loss 0.6952010989189148, acc=0.8222222328186035, loss=0.6952010989189148
train: epoch 89, loss 0.05119963362812996, acc=0.9814444184303284, loss=0.05119963362812996
test: epoch 89, loss 0.5697081089019775, acc=0.8444444537162781, loss=0.5697081089019775
train: epoch 90, loss 0.058243393898010254, acc=0.9794999957084656, loss=0.058243393898010254
test: epoch 90, loss 0.7489890456199646, acc=0.8500000238418579, loss=0.7489890456199646
train: epoch 91, loss 0.05382397770881653, acc=0.9816111326217651, loss=0.05382397770881653
test: epoch 91, loss 0.6011621952056885, acc=0.8194444179534912, loss=0.6011621952056885
train: epoch 92, loss 0.05105069652199745, acc=0.9832777976989746, loss=0.05105069652199745
test: epoch 92, loss 0.7282913327217102, acc=0.8333333134651184, loss=0.7282913327217102
train: epoch 93, loss 0.05288130044937134, acc=0.9821666479110718, loss=0.05288130044937134
test: epoch 93, loss 0.7312076091766357, acc=0.8166666626930237, loss=0.7312076091766357
train: epoch 94, loss 0.05160962790250778, acc=0.9822777509689331, loss=0.05160962790250778
test: epoch 94, loss 0.5856838226318359, acc=0.8583333492279053, loss=0.5856838226318359
train: epoch 95, loss 0.05265355855226517, acc=0.9822221994400024, loss=0.05265355855226517
test: epoch 95, loss 0.7173712253570557, acc=0.8222222328186035, loss=0.7173712253570557
train: epoch 96, loss 0.04617544263601303, acc=0.9833889007568359, loss=0.04617544263601303
test: epoch 96, loss 0.5128872394561768, acc=0.8416666388511658, loss=0.5128872394561768
train: epoch 97, loss 0.05826049670577049, acc=0.9815000295639038, loss=0.05826049670577049
test: epoch 97, loss 0.5670726299285889, acc=0.8361111283302307, loss=0.5670726299285889
train: epoch 98, loss 0.04390890151262283, acc=0.9851666688919067, loss=0.04390890151262283
test: epoch 98, loss 0.5090498924255371, acc=0.8472222089767456, loss=0.5090498924255371
train: epoch 99, loss 0.04322517663240433, acc=0.9850000143051147, loss=0.04322517663240433
test: epoch 99, loss 0.6009534001350403, acc=0.8166666626930237, loss=0.6009534001350403
train: epoch 100, loss 0.04892551526427269, acc=0.9827777743339539, loss=0.04892551526427269
test: epoch 100, loss 0.3708627223968506, acc=0.8722222447395325, loss=0.3708627223968506
train: epoch 101, loss 0.04465021565556526, acc=0.9843888878822327, loss=0.04465021565556526
test: epoch 101, loss 0.3500204384326935, acc=0.8722222447395325, loss=0.3500204384326935
train: epoch 102, loss 0.0548701137304306, acc=0.9815000295639038, loss=0.0548701137304306
test: epoch 102, loss 0.4602185785770416, acc=0.8722222447395325, loss=0.4602185785770416
train: epoch 103, loss 0.045485176146030426, acc=0.9836111068725586, loss=0.045485176146030426
test: epoch 103, loss 0.4038996398448944, acc=0.855555534362793, loss=0.4038996398448944
train: epoch 104, loss 0.04400518536567688, acc=0.9845555424690247, loss=0.04400518536567688
test: epoch 104, loss 0.573205828666687, acc=0.8805555701255798, loss=0.573205828666687
train: epoch 105, loss 0.03686970844864845, acc=0.9857777953147888, loss=0.03686970844864845
test: epoch 105, loss 0.6706901788711548, acc=0.8583333492279053, loss=0.6706901788711548
train: epoch 106, loss 0.04901602491736412, acc=0.9824444651603699, loss=0.04901602491736412
test: epoch 106, loss 0.3407232463359833, acc=0.9111111164093018, loss=0.3407232463359833
train: epoch 107, loss 0.03995010256767273, acc=0.9852777719497681, loss=0.03995010256767273
test: epoch 107, loss 0.38277390599250793, acc=0.9194444417953491, loss=0.38277390599250793
train: epoch 108, loss 0.05478927493095398, acc=0.9823889136314392, loss=0.05478927493095398
test: epoch 108, loss 0.6192106604576111, acc=0.875, loss=0.6192106604576111
train: epoch 109, loss 0.0373082235455513, acc=0.9852222204208374, loss=0.0373082235455513
test: epoch 109, loss 0.43210890889167786, acc=0.8777777552604675, loss=0.43210890889167786
train: epoch 110, loss 0.04005778953433037, acc=0.9861111044883728, loss=0.04005778953433037
test: epoch 110, loss 0.4243643879890442, acc=0.8888888955116272, loss=0.4243643879890442
train: epoch 111, loss 0.04077355936169624, acc=0.9850555658340454, loss=0.04077355936169624
test: epoch 111, loss 0.20768551528453827, acc=0.9388889074325562, loss=0.20768551528453827
train: epoch 112, loss 0.04918611794710159, acc=0.9835555553436279, loss=0.04918611794710159
test: epoch 112, loss 0.4215632975101471, acc=0.9166666865348816, loss=0.4215632975101471
train: epoch 113, loss 0.03741057962179184, acc=0.9865555763244629, loss=0.03741057962179184
test: epoch 113, loss 0.35155215859413147, acc=0.9361110925674438, loss=0.35155215859413147
train: epoch 114, loss 0.04050561785697937, acc=0.9850555658340454, loss=0.04050561785697937
test: epoch 114, loss 0.32176676392555237, acc=0.9222221970558167, loss=0.32176676392555237
train: epoch 115, loss 0.0301216933876276, acc=0.9883888959884644, loss=0.0301216933876276
test: epoch 115, loss 0.43458646535873413, acc=0.9305555820465088, loss=0.43458646535873413
train: epoch 116, loss 0.04932517185807228, acc=0.9838333129882812, loss=0.04932517185807228
test: epoch 116, loss 0.3139224350452423, acc=0.9166666865348816, loss=0.3139224350452423
train: epoch 117, loss 0.031825996935367584, acc=0.9879444241523743, loss=0.031825996935367584
test: epoch 117, loss 0.23237524926662445, acc=0.9388889074325562, loss=0.23237524926662445
train: epoch 118, loss 0.038546159863471985, acc=0.9864444732666016, loss=0.038546159863471985
test: epoch 118, loss 0.3246108293533325, acc=0.9305555820465088, loss=0.3246108293533325
train: epoch 119, loss 0.03259025514125824, acc=0.9877222180366516, loss=0.03259025514125824
test: epoch 119, loss 0.23964785039424896, acc=0.9361110925674438, loss=0.23964785039424896
train: epoch 120, loss 0.04403442516922951, acc=0.9846110939979553, loss=0.04403442516922951
test: epoch 120, loss 0.3511205017566681, acc=0.9305555820465088, loss=0.3511205017566681
train: epoch 121, loss 0.03715180233120918, acc=0.9867777824401855, loss=0.03715180233120918
test: epoch 121, loss 0.3181396424770355, acc=0.9361110925674438, loss=0.3181396424770355
train: epoch 122, loss 0.031901806592941284, acc=0.987500011920929, loss=0.031901806592941284
test: epoch 122, loss 0.3510603606700897, acc=0.9388889074325562, loss=0.3510603606700897
train: epoch 123, loss 0.06592416763305664, acc=0.9818888902664185, loss=0.06592416763305664
test: epoch 123, loss 0.3082441985607147, acc=0.925000011920929, loss=0.3082441985607147
train: epoch 124, loss 0.03192366659641266, acc=0.9879999756813049, loss=0.03192366659641266
test: epoch 124, loss 0.22611203789710999, acc=0.9416666626930237, loss=0.22611203789710999
train: epoch 125, loss 0.032907187938690186, acc=0.9874444603919983, loss=0.032907187938690186
test: epoch 125, loss 0.6985366344451904, acc=0.9361110925674438, loss=0.6985366344451904
train: epoch 126, loss 0.03593927621841431, acc=0.9862222075462341, loss=0.03593927621841431
test: epoch 126, loss 0.23207703232765198, acc=0.9388889074325562, loss=0.23207703232765198
train: epoch 127, loss 0.04077981784939766, acc=0.9865000247955322, loss=0.04077981784939766
test: epoch 127, loss 0.2972401976585388, acc=0.9444444179534912, loss=0.2972401976585388
train: epoch 128, loss 0.025634706020355225, acc=0.9896110892295837, loss=0.025634706020355225
test: epoch 128, loss 0.2701318562030792, acc=0.9444444179534912, loss=0.2701318562030792
train: epoch 129, loss 0.036118391901254654, acc=0.9874444603919983, loss=0.036118391901254654
test: epoch 129, loss 0.18324433267116547, acc=0.9444444179534912, loss=0.18324433267116547
train: epoch 130, loss 0.03283880650997162, acc=0.987666666507721, loss=0.03283880650997162
test: epoch 130, loss 0.20561859011650085, acc=0.9444444179534912, loss=0.20561859011650085
train: epoch 131, loss 0.043583355844020844, acc=0.9863888621330261, loss=0.043583355844020844
test: epoch 131, loss 0.1948888599872589, acc=0.9444444179534912, loss=0.1948888599872589
train: epoch 132, loss 0.03245412930846214, acc=0.9883333444595337, loss=0.03245412930846214
test: epoch 132, loss 0.28127622604370117, acc=0.9444444179534912, loss=0.28127622604370117
train: epoch 133, loss 0.03278074041008949, acc=0.9874444603919983, loss=0.03278074041008949
test: epoch 133, loss 0.17531119287014008, acc=0.9472222328186035, loss=0.17531119287014008
train: epoch 134, loss 0.03848225250840187, acc=0.9868888854980469, loss=0.03848225250840187
test: epoch 134, loss 0.2393275499343872, acc=0.9444444179534912, loss=0.2393275499343872
train: epoch 135, loss 0.036420002579689026, acc=0.9871110916137695, loss=0.036420002579689026
test: epoch 135, loss 0.26639869809150696, acc=0.9472222328186035, loss=0.26639869809150696
train: epoch 136, loss 0.04255346581339836, acc=0.9847221970558167, loss=0.04255346581339836
test: epoch 136, loss 0.18026475608348846, acc=0.9444444179534912, loss=0.18026475608348846
train: epoch 137, loss 0.03585441783070564, acc=0.9874444603919983, loss=0.03585441783070564
test: epoch 137, loss 0.22313517332077026, acc=0.9472222328186035, loss=0.22313517332077026
train: epoch 138, loss 0.022732367739081383, acc=0.9903888702392578, loss=0.022732367739081383
test: epoch 138, loss 0.29975444078445435, acc=0.9444444179534912, loss=0.29975444078445435
train: epoch 139, loss 0.02971176989376545, acc=0.9890000224113464, loss=0.02971176989376545
test: epoch 139, loss 0.17827539145946503, acc=0.9472222328186035, loss=0.17827539145946503
train: epoch 140, loss 0.03925229609012604, acc=0.9866666793823242, loss=0.03925229609012604
test: epoch 140, loss 0.2163444608449936, acc=0.9472222328186035, loss=0.2163444608449936
train: epoch 141, loss 0.030833354219794273, acc=0.988611102104187, loss=0.030833354219794273
test: epoch 141, loss 0.23577754199504852, acc=0.9472222328186035, loss=0.23577754199504852
train: epoch 142, loss 0.029957862570881844, acc=0.9884999990463257, loss=0.029957862570881844
test: epoch 142, loss 0.22759340703487396, acc=0.9472222328186035, loss=0.22759340703487396
train: epoch 143, loss 0.03300946578383446, acc=0.9872221946716309, loss=0.03300946578383446
test: epoch 143, loss 0.21994243562221527, acc=0.9472222328186035, loss=0.21994243562221527
train: epoch 144, loss 0.025244297459721565, acc=0.9896666407585144, loss=0.025244297459721565
test: epoch 144, loss 0.3115515410900116, acc=0.9472222328186035, loss=0.3115515410900116
train: epoch 145, loss 0.03284590318799019, acc=0.9888333082199097, loss=0.03284590318799019
test: epoch 145, loss 0.19830888509750366, acc=0.9472222328186035, loss=0.19830888509750366
train: epoch 146, loss 0.033339712768793106, acc=0.9885555505752563, loss=0.033339712768793106
test: epoch 146, loss 0.23027655482292175, acc=0.9444444179534912, loss=0.23027655482292175
train: epoch 147, loss 0.02372159995138645, acc=0.9920555353164673, loss=0.02372159995138645
test: epoch 147, loss 0.1406627893447876, acc=0.9444444179534912, loss=0.1406627893447876
train: epoch 148, loss 0.03656042739748955, acc=0.9885555505752563, loss=0.03656042739748955
test: epoch 148, loss 0.2694017291069031, acc=0.9472222328186035, loss=0.2694017291069031
train: epoch 149, loss 0.021527599543333054, acc=0.9918888807296753, loss=0.021527599543333054
test: epoch 149, loss 0.24638359248638153, acc=0.9444444179534912, loss=0.24638359248638153
train: epoch 150, loss 0.03149431571364403, acc=0.9906111359596252, loss=0.03149431571364403
test: epoch 150, loss 0.2847209870815277, acc=0.9444444179534912, loss=0.2847209870815277
