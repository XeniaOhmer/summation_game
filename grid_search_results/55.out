# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=1", "--temp_decay=1", "--one_hot=true", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=679629933, receiver_embed_dim=64, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.0568692684173584, acc=0.07361111044883728, loss=3.0568692684173584
test: epoch 1, loss 2.814042806625366, acc=0.0972222238779068, loss=2.814042806625366
train: epoch 2, loss 2.197749137878418, acc=0.1809999942779541, loss=2.197749137878418
test: epoch 2, loss 2.450092315673828, acc=0.14722222089767456, loss=2.450092315673828
train: epoch 3, loss 1.7703030109405518, acc=0.30061110854148865, loss=1.7703030109405518
test: epoch 3, loss 2.039161443710327, acc=0.21388888359069824, loss=2.039161443710327
train: epoch 4, loss 1.4829840660095215, acc=0.3886111080646515, loss=1.4829840660095215
test: epoch 4, loss 2.153944253921509, acc=0.22777777910232544, loss=2.153944253921509
train: epoch 5, loss 1.3136606216430664, acc=0.4386666715145111, loss=1.3136606216430664
test: epoch 5, loss 1.7819932699203491, acc=0.2888889014720917, loss=1.7819932699203491
train: epoch 6, loss 1.205601692199707, acc=0.48188889026641846, loss=1.205601692199707
test: epoch 6, loss 1.7853792905807495, acc=0.28611111640930176, loss=1.7853792905807495
train: epoch 7, loss 1.095141887664795, acc=0.5274999737739563, loss=1.095141887664795
test: epoch 7, loss 1.7132192850112915, acc=0.2944444417953491, loss=1.7132192850112915
train: epoch 8, loss 1.010521411895752, acc=0.5560555458068848, loss=1.010521411895752
test: epoch 8, loss 1.7103960514068604, acc=0.32777777314186096, loss=1.7103960514068604
train: epoch 9, loss 0.9687703847885132, acc=0.5680000185966492, loss=0.9687703847885132
test: epoch 9, loss 1.68146550655365, acc=0.2944444417953491, loss=1.68146550655365
train: epoch 10, loss 0.9255696535110474, acc=0.5914999842643738, loss=0.9255696535110474
test: epoch 10, loss 1.5667206048965454, acc=0.3222222328186035, loss=1.5667206048965454
train: epoch 11, loss 0.9034909605979919, acc=0.6077777743339539, loss=0.9034909605979919
test: epoch 11, loss 1.7771823406219482, acc=0.36666667461395264, loss=1.7771823406219482
train: epoch 12, loss 0.86529541015625, acc=0.6248888969421387, loss=0.86529541015625
test: epoch 12, loss 1.547066330909729, acc=0.375, loss=1.547066330909729
train: epoch 13, loss 0.8133636713027954, acc=0.6503333449363708, loss=0.8133636713027954
test: epoch 13, loss 1.376069188117981, acc=0.3888888955116272, loss=1.376069188117981
train: epoch 14, loss 0.7637640237808228, acc=0.6811666488647461, loss=0.7637640237808228
test: epoch 14, loss 1.7182234525680542, acc=0.38055557012557983, loss=1.7182234525680542
train: epoch 15, loss 0.7432124018669128, acc=0.6924999952316284, loss=0.7432124018669128
test: epoch 15, loss 1.7245348691940308, acc=0.3916666805744171, loss=1.7245348691940308
train: epoch 16, loss 0.6991174221038818, acc=0.707444429397583, loss=0.6991174221038818
test: epoch 16, loss 1.6298739910125732, acc=0.39722222089767456, loss=1.6298739910125732
train: epoch 17, loss 0.6722726821899414, acc=0.7196666598320007, loss=0.6722726821899414
test: epoch 17, loss 1.4766502380371094, acc=0.40833333134651184, loss=1.4766502380371094
train: epoch 18, loss 0.6675118207931519, acc=0.7200000286102295, loss=0.6675118207931519
test: epoch 18, loss 1.5366052389144897, acc=0.4000000059604645, loss=1.5366052389144897
train: epoch 19, loss 0.6364575624465942, acc=0.7336111068725586, loss=0.6364575624465942
test: epoch 19, loss 1.6107808351516724, acc=0.39444443583488464, loss=1.6107808351516724
train: epoch 20, loss 0.6282409429550171, acc=0.7396666407585144, loss=0.6282409429550171
test: epoch 20, loss 1.6681996583938599, acc=0.4194444417953491, loss=1.6681996583938599
train: epoch 21, loss 0.6064421534538269, acc=0.7451111078262329, loss=0.6064421534538269
test: epoch 21, loss 1.69317626953125, acc=0.40833333134651184, loss=1.69317626953125
train: epoch 22, loss 0.595557689666748, acc=0.7487778067588806, loss=0.595557689666748
test: epoch 22, loss 1.7759813070297241, acc=0.41111111640930176, loss=1.7759813070297241
train: epoch 23, loss 0.5859136581420898, acc=0.7502222061157227, loss=0.5859136581420898
test: epoch 23, loss 1.5691221952438354, acc=0.42500001192092896, loss=1.5691221952438354
train: epoch 24, loss 0.5820603370666504, acc=0.7579444646835327, loss=0.5820603370666504
test: epoch 24, loss 1.7011786699295044, acc=0.40833333134651184, loss=1.7011786699295044
train: epoch 25, loss 0.5864977240562439, acc=0.7518888711929321, loss=0.5864977240562439
test: epoch 25, loss 1.778909683227539, acc=0.40833333134651184, loss=1.778909683227539
train: epoch 26, loss 0.5671555399894714, acc=0.7576666474342346, loss=0.5671555399894714
test: epoch 26, loss 1.6242754459381104, acc=0.4333333373069763, loss=1.6242754459381104
train: epoch 27, loss 0.5630930662155151, acc=0.7655555605888367, loss=0.5630930662155151
test: epoch 27, loss 2.030139207839966, acc=0.4000000059604645, loss=2.030139207839966
train: epoch 28, loss 0.5666119456291199, acc=0.7595555782318115, loss=0.5666119456291199
test: epoch 28, loss 1.7685621976852417, acc=0.4194444417953491, loss=1.7685621976852417
train: epoch 29, loss 0.5601490139961243, acc=0.7667222023010254, loss=0.5601490139961243
test: epoch 29, loss 1.5701833963394165, acc=0.4166666567325592, loss=1.5701833963394165
train: epoch 30, loss 0.5639064311981201, acc=0.7668889164924622, loss=0.5639064311981201
test: epoch 30, loss 1.7118974924087524, acc=0.4555555582046509, loss=1.7118974924087524
train: epoch 31, loss 0.5582955479621887, acc=0.7633888721466064, loss=0.5582955479621887
test: epoch 31, loss 1.515223503112793, acc=0.4583333432674408, loss=1.515223503112793
train: epoch 32, loss 0.5542073845863342, acc=0.7693333625793457, loss=0.5542073845863342
test: epoch 32, loss 1.6297539472579956, acc=0.4027777910232544, loss=1.6297539472579956
train: epoch 33, loss 0.5593313574790955, acc=0.76583331823349, loss=0.5593313574790955
test: epoch 33, loss 1.6863735914230347, acc=0.46388888359069824, loss=1.6863735914230347
train: epoch 34, loss 0.5281383991241455, acc=0.7758888602256775, loss=0.5281383991241455
test: epoch 34, loss 1.8462239503860474, acc=0.44999998807907104, loss=1.8462239503860474
train: epoch 35, loss 0.5282032489776611, acc=0.777999997138977, loss=0.5282032489776611
test: epoch 35, loss 1.6065596342086792, acc=0.4611110985279083, loss=1.6065596342086792
train: epoch 36, loss 0.5435767769813538, acc=0.7712222337722778, loss=0.5435767769813538
test: epoch 36, loss 1.6978583335876465, acc=0.4166666567325592, loss=1.6978583335876465
train: epoch 37, loss 0.5255936980247498, acc=0.7770000100135803, loss=0.5255936980247498
test: epoch 37, loss 1.8168803453445435, acc=0.4277777671813965, loss=1.8168803453445435
train: epoch 38, loss 0.5407459139823914, acc=0.7714444398880005, loss=0.5407459139823914
test: epoch 38, loss 1.70374596118927, acc=0.4694444537162781, loss=1.70374596118927
train: epoch 39, loss 0.5455408096313477, acc=0.7722777724266052, loss=0.5455408096313477
test: epoch 39, loss 1.560441255569458, acc=0.42500001192092896, loss=1.560441255569458
train: epoch 40, loss 0.5231488347053528, acc=0.7776666879653931, loss=0.5231488347053528
test: epoch 40, loss 1.578735589981079, acc=0.4444444477558136, loss=1.578735589981079
train: epoch 41, loss 0.5277808308601379, acc=0.7785555720329285, loss=0.5277808308601379
test: epoch 41, loss 1.868887186050415, acc=0.46666666865348816, loss=1.868887186050415
train: epoch 42, loss 0.530303955078125, acc=0.7758888602256775, loss=0.530303955078125
test: epoch 42, loss 1.6029661893844604, acc=0.4749999940395355, loss=1.6029661893844604
train: epoch 43, loss 0.5140156149864197, acc=0.7853888869285583, loss=0.5140156149864197
test: epoch 43, loss 1.6342226266860962, acc=0.4722222089767456, loss=1.6342226266860962
train: epoch 44, loss 0.5283966660499573, acc=0.7759444713592529, loss=0.5283966660499573
test: epoch 44, loss 1.7512485980987549, acc=0.43888887763023376, loss=1.7512485980987549
train: epoch 45, loss 0.5060147643089294, acc=0.7858333587646484, loss=0.5060147643089294
test: epoch 45, loss 1.8130284547805786, acc=0.45277777314186096, loss=1.8130284547805786
train: epoch 46, loss 0.5115596652030945, acc=0.7863888740539551, loss=0.5115596652030945
test: epoch 46, loss 1.7102673053741455, acc=0.46388888359069824, loss=1.7102673053741455
train: epoch 47, loss 0.5095207691192627, acc=0.7877222299575806, loss=0.5095207691192627
test: epoch 47, loss 1.5974630117416382, acc=0.47777777910232544, loss=1.5974630117416382
train: epoch 48, loss 0.511170506477356, acc=0.7836111187934875, loss=0.511170506477356
test: epoch 48, loss 1.5655348300933838, acc=0.4722222089767456, loss=1.5655348300933838
train: epoch 49, loss 0.5123435258865356, acc=0.7837777733802795, loss=0.5123435258865356
test: epoch 49, loss 1.5954103469848633, acc=0.4722222089767456, loss=1.5954103469848633
train: epoch 50, loss 0.5100080966949463, acc=0.7827222347259521, loss=0.5100080966949463
test: epoch 50, loss 1.6964491605758667, acc=0.4722222089767456, loss=1.6964491605758667
train: epoch 51, loss 0.5025388598442078, acc=0.7849444150924683, loss=0.5025388598442078
test: epoch 51, loss 1.8140869140625, acc=0.4583333432674408, loss=1.8140869140625
train: epoch 52, loss 0.49303150177001953, acc=0.7952222228050232, loss=0.49303150177001953
test: epoch 52, loss 1.6881917715072632, acc=0.4749999940395355, loss=1.6881917715072632
train: epoch 53, loss 0.4663827121257782, acc=0.8023333549499512, loss=0.4663827121257782
test: epoch 53, loss 1.5417450666427612, acc=0.4694444537162781, loss=1.5417450666427612
train: epoch 54, loss 0.4925472140312195, acc=0.7953888773918152, loss=0.4925472140312195
test: epoch 54, loss 1.782736897468567, acc=0.46388888359069824, loss=1.782736897468567
train: epoch 55, loss 0.4895388185977936, acc=0.7919444441795349, loss=0.4895388185977936
test: epoch 55, loss 1.483499526977539, acc=0.4694444537162781, loss=1.483499526977539
train: epoch 56, loss 0.4838961660861969, acc=0.7929999828338623, loss=0.4838961660861969
test: epoch 56, loss 1.5936763286590576, acc=0.47777777910232544, loss=1.5936763286590576
train: epoch 57, loss 0.48325273394584656, acc=0.7960000038146973, loss=0.48325273394584656
test: epoch 57, loss 1.9178249835968018, acc=0.4694444537162781, loss=1.9178249835968018
train: epoch 58, loss 0.46975573897361755, acc=0.801277756690979, loss=0.46975573897361755
test: epoch 58, loss 1.7822139263153076, acc=0.4694444537162781, loss=1.7822139263153076
train: epoch 59, loss 0.46635881066322327, acc=0.8026111125946045, loss=0.46635881066322327
test: epoch 59, loss 1.6179691553115845, acc=0.47777777910232544, loss=1.6179691553115845
train: epoch 60, loss 0.46300777792930603, acc=0.8022222518920898, loss=0.46300777792930603
test: epoch 60, loss 1.5290077924728394, acc=0.4722222089767456, loss=1.5290077924728394
train: epoch 61, loss 0.4777873754501343, acc=0.7996110916137695, loss=0.4777873754501343
test: epoch 61, loss 1.6068837642669678, acc=0.48055556416511536, loss=1.6068837642669678
train: epoch 62, loss 0.4758276641368866, acc=0.7983333468437195, loss=0.4758276641368866
test: epoch 62, loss 1.5937224626541138, acc=0.4888888895511627, loss=1.5937224626541138
train: epoch 63, loss 0.4671977758407593, acc=0.7993888854980469, loss=0.4671977758407593
test: epoch 63, loss 1.6483936309814453, acc=0.4833333194255829, loss=1.6483936309814453
train: epoch 64, loss 0.47962650656700134, acc=0.797166645526886, loss=0.47962650656700134
test: epoch 64, loss 1.6985840797424316, acc=0.46388888359069824, loss=1.6985840797424316
train: epoch 65, loss 0.46715718507766724, acc=0.8019444346427917, loss=0.46715718507766724
test: epoch 65, loss 1.6205732822418213, acc=0.4749999940395355, loss=1.6205732822418213
train: epoch 66, loss 0.45712220668792725, acc=0.8037222027778625, loss=0.45712220668792725
test: epoch 66, loss 1.491647720336914, acc=0.47777777910232544, loss=1.491647720336914
train: epoch 67, loss 0.4773012697696686, acc=0.7984444499015808, loss=0.4773012697696686
test: epoch 67, loss 1.5645332336425781, acc=0.4749999940395355, loss=1.5645332336425781
train: epoch 68, loss 0.4492548406124115, acc=0.8061110973358154, loss=0.4492548406124115
test: epoch 68, loss 1.5971767902374268, acc=0.48055556416511536, loss=1.5971767902374268
train: epoch 69, loss 0.4693659543991089, acc=0.8007222414016724, loss=0.4693659543991089
test: epoch 69, loss 1.6368720531463623, acc=0.4722222089767456, loss=1.6368720531463623
train: epoch 70, loss 0.4624077081680298, acc=0.8038889169692993, loss=0.4624077081680298
test: epoch 70, loss 1.5231668949127197, acc=0.4749999940395355, loss=1.5231668949127197
train: epoch 71, loss 0.454822838306427, acc=0.8029444217681885, loss=0.454822838306427
test: epoch 71, loss 1.7540792226791382, acc=0.4694444537162781, loss=1.7540792226791382
train: epoch 72, loss 0.43687891960144043, acc=0.8121111392974854, loss=0.43687891960144043
test: epoch 72, loss 1.5676156282424927, acc=0.4722222089767456, loss=1.5676156282424927
train: epoch 73, loss 0.46898606419563293, acc=0.800611138343811, loss=0.46898606419563293
test: epoch 73, loss 1.5130442380905151, acc=0.4694444537162781, loss=1.5130442380905151
train: epoch 74, loss 0.45017993450164795, acc=0.8063889145851135, loss=0.45017993450164795
test: epoch 74, loss 1.7502435445785522, acc=0.47777777910232544, loss=1.7502435445785522
train: epoch 75, loss 0.4468477666378021, acc=0.808055579662323, loss=0.4468477666378021
test: epoch 75, loss 1.61686372756958, acc=0.4749999940395355, loss=1.61686372756958
train: epoch 76, loss 0.4505705237388611, acc=0.8033888936042786, loss=0.4505705237388611
test: epoch 76, loss 1.7301619052886963, acc=0.48055556416511536, loss=1.7301619052886963
train: epoch 77, loss 0.46583062410354614, acc=0.8003333210945129, loss=0.46583062410354614
test: epoch 77, loss 1.6659742593765259, acc=0.48055556416511536, loss=1.6659742593765259
train: epoch 78, loss 0.447636216878891, acc=0.809166669845581, loss=0.447636216878891
test: epoch 78, loss 1.7455295324325562, acc=0.4611110985279083, loss=1.7455295324325562
train: epoch 79, loss 0.42717623710632324, acc=0.8125555515289307, loss=0.42717623710632324
test: epoch 79, loss 1.6700273752212524, acc=0.48055556416511536, loss=1.6700273752212524
train: epoch 80, loss 0.4491667151451111, acc=0.80522221326828, loss=0.4491667151451111
test: epoch 80, loss 1.6202905178070068, acc=0.4749999940395355, loss=1.6202905178070068
train: epoch 81, loss 0.44978100061416626, acc=0.8065555691719055, loss=0.44978100061416626
test: epoch 81, loss 1.618408441543579, acc=0.48055556416511536, loss=1.618408441543579
train: epoch 82, loss 0.4484902322292328, acc=0.8056666851043701, loss=0.4484902322292328
test: epoch 82, loss 1.5826048851013184, acc=0.48055556416511536, loss=1.5826048851013184
train: epoch 83, loss 0.44073694944381714, acc=0.8078333139419556, loss=0.44073694944381714
test: epoch 83, loss 1.7318980693817139, acc=0.4833333194255829, loss=1.7318980693817139
train: epoch 84, loss 0.4362776279449463, acc=0.8105555772781372, loss=0.4362776279449463
test: epoch 84, loss 1.6069836616516113, acc=0.4972222149372101, loss=1.6069836616516113
train: epoch 85, loss 0.4470546543598175, acc=0.8070555329322815, loss=0.4470546543598175
test: epoch 85, loss 1.638533592224121, acc=0.49444442987442017, loss=1.638533592224121
train: epoch 86, loss 0.43725597858428955, acc=0.8127222061157227, loss=0.43725597858428955
test: epoch 86, loss 1.758665680885315, acc=0.4861111044883728, loss=1.758665680885315
train: epoch 87, loss 0.43129482865333557, acc=0.8143888711929321, loss=0.43129482865333557
test: epoch 87, loss 1.5092058181762695, acc=0.5, loss=1.5092058181762695
train: epoch 88, loss 0.4328744113445282, acc=0.8130000233650208, loss=0.4328744113445282
test: epoch 88, loss 1.6939667463302612, acc=0.49444442987442017, loss=1.6939667463302612
train: epoch 89, loss 0.4397594928741455, acc=0.8110555410385132, loss=0.4397594928741455
test: epoch 89, loss 1.642736554145813, acc=0.5, loss=1.642736554145813
train: epoch 90, loss 0.4258353114128113, acc=0.8139444589614868, loss=0.4258353114128113
test: epoch 90, loss 1.7426711320877075, acc=0.4888888895511627, loss=1.7426711320877075
train: epoch 91, loss 0.4504973590373993, acc=0.8068333268165588, loss=0.4504973590373993
test: epoch 91, loss 1.7314246892929077, acc=0.4749999940395355, loss=1.7314246892929077
train: epoch 92, loss 0.4362647533416748, acc=0.8068888783454895, loss=0.4362647533416748
test: epoch 92, loss 1.742946743965149, acc=0.49444442987442017, loss=1.742946743965149
train: epoch 93, loss 0.4373655915260315, acc=0.8121111392974854, loss=0.4373655915260315
test: epoch 93, loss 1.5527435541152954, acc=0.5, loss=1.5527435541152954
train: epoch 94, loss 0.4328818917274475, acc=0.8096110820770264, loss=0.4328818917274475
test: epoch 94, loss 1.8365895748138428, acc=0.48055556416511536, loss=1.8365895748138428
train: epoch 95, loss 0.42701974511146545, acc=0.8133333325386047, loss=0.42701974511146545
test: epoch 95, loss 1.8203420639038086, acc=0.5, loss=1.8203420639038086
train: epoch 96, loss 0.4416854679584503, acc=0.8107222318649292, loss=0.4416854679584503
test: epoch 96, loss 1.463633418083191, acc=0.4888888895511627, loss=1.463633418083191
train: epoch 97, loss 0.42480969429016113, acc=0.8163333535194397, loss=0.42480969429016113
test: epoch 97, loss 1.7588199377059937, acc=0.47777777910232544, loss=1.7588199377059937
train: epoch 98, loss 0.4383681118488312, acc=0.8107777833938599, loss=0.4383681118488312
test: epoch 98, loss 1.6448404788970947, acc=0.4888888895511627, loss=1.6448404788970947
train: epoch 99, loss 0.44422000646591187, acc=0.8100555539131165, loss=0.44422000646591187
test: epoch 99, loss 1.4126194715499878, acc=0.5027777552604675, loss=1.4126194715499878
train: epoch 100, loss 0.42873772978782654, acc=0.815500020980835, loss=0.42873772978782654
test: epoch 100, loss 1.7319532632827759, acc=0.49444442987442017, loss=1.7319532632827759
train: epoch 101, loss 0.41913536190986633, acc=0.8163333535194397, loss=0.41913536190986633
test: epoch 101, loss 1.5519694089889526, acc=0.4972222149372101, loss=1.5519694089889526
train: epoch 102, loss 0.4340679347515106, acc=0.8112778067588806, loss=0.4340679347515106
test: epoch 102, loss 1.5620653629302979, acc=0.49166667461395264, loss=1.5620653629302979
train: epoch 103, loss 0.4367275834083557, acc=0.8104444742202759, loss=0.4367275834083557
test: epoch 103, loss 1.6586247682571411, acc=0.5, loss=1.6586247682571411
train: epoch 104, loss 0.41936296224594116, acc=0.8171111345291138, loss=0.41936296224594116
test: epoch 104, loss 1.7149872779846191, acc=0.4972222149372101, loss=1.7149872779846191
train: epoch 105, loss 0.43732529878616333, acc=0.8068888783454895, loss=0.43732529878616333
test: epoch 105, loss 1.6452102661132812, acc=0.49444442987442017, loss=1.6452102661132812
train: epoch 106, loss 0.4188949167728424, acc=0.8186110854148865, loss=0.4188949167728424
test: epoch 106, loss 1.8231536149978638, acc=0.4888888895511627, loss=1.8231536149978638
train: epoch 107, loss 0.4308328926563263, acc=0.8103888630867004, loss=0.4308328926563263
test: epoch 107, loss 1.703320026397705, acc=0.49444442987442017, loss=1.703320026397705
train: epoch 108, loss 0.42547205090522766, acc=0.8147222399711609, loss=0.42547205090522766
test: epoch 108, loss 1.6652191877365112, acc=0.4833333194255829, loss=1.6652191877365112
train: epoch 109, loss 0.43100813031196594, acc=0.8157222270965576, loss=0.43100813031196594
test: epoch 109, loss 1.7392290830612183, acc=0.5, loss=1.7392290830612183
train: epoch 110, loss 0.4155617356300354, acc=0.8187777996063232, loss=0.4155617356300354
test: epoch 110, loss 1.6686547994613647, acc=0.5, loss=1.6686547994613647
train: epoch 111, loss 0.4205780029296875, acc=0.8166666626930237, loss=0.4205780029296875
test: epoch 111, loss 1.8070305585861206, acc=0.4972222149372101, loss=1.8070305585861206
train: epoch 112, loss 0.41983482241630554, acc=0.8198888897895813, loss=0.41983482241630554
test: epoch 112, loss 1.6146066188812256, acc=0.5, loss=1.6146066188812256
train: epoch 113, loss 0.4192456901073456, acc=0.8163889050483704, loss=0.4192456901073456
test: epoch 113, loss 1.875457525253296, acc=0.49166667461395264, loss=1.875457525253296
train: epoch 114, loss 0.42436152696609497, acc=0.8157777786254883, loss=0.42436152696609497
test: epoch 114, loss 1.565934419631958, acc=0.5, loss=1.565934419631958
train: epoch 115, loss 0.43162640929222107, acc=0.8139444589614868, loss=0.43162640929222107
test: epoch 115, loss 1.689409613609314, acc=0.4888888895511627, loss=1.689409613609314
train: epoch 116, loss 0.4154614806175232, acc=0.8163889050483704, loss=0.4154614806175232
test: epoch 116, loss 1.4064254760742188, acc=0.4972222149372101, loss=1.4064254760742188
train: epoch 117, loss 0.4218083620071411, acc=0.812166690826416, loss=0.4218083620071411
test: epoch 117, loss 1.5413419008255005, acc=0.5, loss=1.5413419008255005
train: epoch 118, loss 0.4169984757900238, acc=0.8153333067893982, loss=0.4169984757900238
test: epoch 118, loss 1.7093898057937622, acc=0.5027777552604675, loss=1.7093898057937622
train: epoch 119, loss 0.41318967938423157, acc=0.8188333511352539, loss=0.41318967938423157
test: epoch 119, loss 1.7079522609710693, acc=0.5, loss=1.7079522609710693
train: epoch 120, loss 0.4107574224472046, acc=0.8204444646835327, loss=0.4107574224472046
test: epoch 120, loss 1.6933881044387817, acc=0.49444442987442017, loss=1.6933881044387817
train: epoch 121, loss 0.4115850627422333, acc=0.8224999904632568, loss=0.4115850627422333
test: epoch 121, loss 1.8794827461242676, acc=0.5027777552604675, loss=1.8794827461242676
train: epoch 122, loss 0.4158884584903717, acc=0.8196666836738586, loss=0.4158884584903717
test: epoch 122, loss 1.7790329456329346, acc=0.5166666507720947, loss=1.7790329456329346
train: epoch 123, loss 0.4183036983013153, acc=0.8191666603088379, loss=0.4183036983013153
test: epoch 123, loss 1.5699392557144165, acc=0.5027777552604675, loss=1.5699392557144165
train: epoch 124, loss 0.4185243248939514, acc=0.8167222142219543, loss=0.4185243248939514
test: epoch 124, loss 1.6957676410675049, acc=0.5, loss=1.6957676410675049
train: epoch 125, loss 0.4140421152114868, acc=0.8170555830001831, loss=0.4140421152114868
test: epoch 125, loss 1.771544098854065, acc=0.4861111044883728, loss=1.771544098854065
train: epoch 126, loss 0.4089542329311371, acc=0.8215000033378601, loss=0.4089542329311371
test: epoch 126, loss 1.7588165998458862, acc=0.49166667461395264, loss=1.7588165998458862
train: epoch 127, loss 0.4210323989391327, acc=0.8138889074325562, loss=0.4210323989391327
test: epoch 127, loss 1.732491135597229, acc=0.5, loss=1.732491135597229
train: epoch 128, loss 0.4071708619594574, acc=0.8181111216545105, loss=0.4071708619594574
test: epoch 128, loss 1.7881910800933838, acc=0.49444442987442017, loss=1.7881910800933838
train: epoch 129, loss 0.40725409984588623, acc=0.8188333511352539, loss=0.40725409984588623
test: epoch 129, loss 1.6387475728988647, acc=0.49444442987442017, loss=1.6387475728988647
train: epoch 130, loss 0.41663631796836853, acc=0.8180555701255798, loss=0.41663631796836853
test: epoch 130, loss 1.805000901222229, acc=0.4972222149372101, loss=1.805000901222229
train: epoch 131, loss 0.4099358022212982, acc=0.8207777738571167, loss=0.4099358022212982
test: epoch 131, loss 1.648812174797058, acc=0.4972222149372101, loss=1.648812174797058
train: epoch 132, loss 0.4082567095756531, acc=0.8207777738571167, loss=0.4082567095756531
test: epoch 132, loss 1.7222524881362915, acc=0.4972222149372101, loss=1.7222524881362915
train: epoch 133, loss 0.41602370142936707, acc=0.8194444179534912, loss=0.41602370142936707
test: epoch 133, loss 1.6570192575454712, acc=0.49166667461395264, loss=1.6570192575454712
train: epoch 134, loss 0.4101836681365967, acc=0.8195555806159973, loss=0.4101836681365967
test: epoch 134, loss 1.5457489490509033, acc=0.4972222149372101, loss=1.5457489490509033
train: epoch 135, loss 0.40308064222335815, acc=0.8226110935211182, loss=0.40308064222335815
test: epoch 135, loss 1.7171199321746826, acc=0.5, loss=1.7171199321746826
train: epoch 136, loss 0.4048437178134918, acc=0.8190000057220459, loss=0.4048437178134918
test: epoch 136, loss 1.805880069732666, acc=0.5027777552604675, loss=1.805880069732666
train: epoch 137, loss 0.3992128372192383, acc=0.8231111168861389, loss=0.3992128372192383
test: epoch 137, loss 1.6498483419418335, acc=0.4972222149372101, loss=1.6498483419418335
train: epoch 138, loss 0.4096001982688904, acc=0.8205000162124634, loss=0.4096001982688904
test: epoch 138, loss 1.7044527530670166, acc=0.4972222149372101, loss=1.7044527530670166
train: epoch 139, loss 0.4157565236091614, acc=0.8212222456932068, loss=0.4157565236091614
test: epoch 139, loss 1.8552181720733643, acc=0.5083333253860474, loss=1.8552181720733643
train: epoch 140, loss 0.4170664846897125, acc=0.8175555467605591, loss=0.4170664846897125
test: epoch 140, loss 1.7753797769546509, acc=0.5, loss=1.7753797769546509
train: epoch 141, loss 0.4033729135990143, acc=0.8211666941642761, loss=0.4033729135990143
test: epoch 141, loss 1.4825046062469482, acc=0.5027777552604675, loss=1.4825046062469482
train: epoch 142, loss 0.4162728488445282, acc=0.815500020980835, loss=0.4162728488445282
test: epoch 142, loss 1.7627204656600952, acc=0.4972222149372101, loss=1.7627204656600952
train: epoch 143, loss 0.42277461290359497, acc=0.8144999742507935, loss=0.42277461290359497
test: epoch 143, loss 1.605069875717163, acc=0.49444442987442017, loss=1.605069875717163
train: epoch 144, loss 0.40650174021720886, acc=0.8222222328186035, loss=0.40650174021720886
test: epoch 144, loss 1.8265703916549683, acc=0.49166667461395264, loss=1.8265703916549683
train: epoch 145, loss 0.39858880639076233, acc=0.824833333492279, loss=0.39858880639076233
test: epoch 145, loss 1.7750980854034424, acc=0.4972222149372101, loss=1.7750980854034424
train: epoch 146, loss 0.413089781999588, acc=0.8199999928474426, loss=0.413089781999588
test: epoch 146, loss 1.6917393207550049, acc=0.5111111402511597, loss=1.6917393207550049
train: epoch 147, loss 0.4069569408893585, acc=0.8178333044052124, loss=0.4069569408893585
test: epoch 147, loss 1.6204543113708496, acc=0.5027777552604675, loss=1.6204543113708496
train: epoch 148, loss 0.3899959921836853, acc=0.8256666660308838, loss=0.3899959921836853
test: epoch 148, loss 1.8943628072738647, acc=0.4972222149372101, loss=1.8943628072738647
train: epoch 149, loss 0.3910536468029022, acc=0.8220555782318115, loss=0.3910536468029022
test: epoch 149, loss 1.7195545434951782, acc=0.4972222149372101, loss=1.7195545434951782
train: epoch 150, loss 0.3985448479652405, acc=0.8232777714729309, loss=0.3985448479652405
test: epoch 150, loss 1.7831470966339111, acc=0.5, loss=1.7831470966339111
