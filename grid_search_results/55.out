# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=1", "--temp_decay=1", "--one_hot=0", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=1303669578, receiver_embed_dim=64, save_run=0, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=1303669578, receiver_embed_dim=64, save_run=False, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.891517400741577, acc=0.09716666489839554, loss=2.891517400741577
test: epoch 1, loss 3.490048885345459, acc=0.0694444477558136, loss=3.490048885345459
train: epoch 2, loss 2.432844638824463, acc=0.15449999272823334, loss=2.432844638824463
test: epoch 2, loss 3.0478312969207764, acc=0.08055555820465088, loss=3.0478312969207764
train: epoch 3, loss 2.1739466190338135, acc=0.20494444668293, loss=2.1739466190338135
test: epoch 3, loss 2.6568603515625, acc=0.13055555522441864, loss=2.6568603515625
train: epoch 4, loss 2.010178565979004, acc=0.24699999392032623, loss=2.010178565979004
test: epoch 4, loss 2.5075626373291016, acc=0.14444445073604584, loss=2.5075626373291016
train: epoch 5, loss 1.8945178985595703, acc=0.26677778363227844, loss=1.8945178985595703
test: epoch 5, loss 2.472055435180664, acc=0.14166666567325592, loss=2.472055435180664
train: epoch 6, loss 1.8019319772720337, acc=0.2913888990879059, loss=1.8019319772720337
test: epoch 6, loss 2.401472330093384, acc=0.1527777761220932, loss=2.401472330093384
train: epoch 7, loss 1.7446258068084717, acc=0.3161666691303253, loss=1.7446258068084717
test: epoch 7, loss 2.311034679412842, acc=0.13055555522441864, loss=2.311034679412842
train: epoch 8, loss 1.6933518648147583, acc=0.3207777738571167, loss=1.6933518648147583
test: epoch 8, loss 2.3470964431762695, acc=0.1527777761220932, loss=2.3470964431762695
train: epoch 9, loss 1.6484229564666748, acc=0.3403888940811157, loss=1.6484229564666748
test: epoch 9, loss 2.337113857269287, acc=0.14166666567325592, loss=2.337113857269287
train: epoch 10, loss 1.624558687210083, acc=0.3478333353996277, loss=1.624558687210083
test: epoch 10, loss 2.3019096851348877, acc=0.15555556118488312, loss=2.3019096851348877
train: epoch 11, loss 1.5691167116165161, acc=0.35955554246902466, loss=1.5691167116165161
test: epoch 11, loss 2.371631145477295, acc=0.15555556118488312, loss=2.371631145477295
train: epoch 12, loss 1.5631496906280518, acc=0.37227776646614075, loss=1.5631496906280518
test: epoch 12, loss 2.5125536918640137, acc=0.10833333432674408, loss=2.5125536918640137
train: epoch 13, loss 1.5271075963974, acc=0.38466668128967285, loss=1.5271075963974
test: epoch 13, loss 2.205021858215332, acc=0.15555556118488312, loss=2.205021858215332
train: epoch 14, loss 1.510244607925415, acc=0.3851666748523712, loss=1.510244607925415
test: epoch 14, loss 2.2127599716186523, acc=0.17499999701976776, loss=2.2127599716186523
train: epoch 15, loss 1.481137990951538, acc=0.4026666581630707, loss=1.481137990951538
test: epoch 15, loss 2.248239278793335, acc=0.15555556118488312, loss=2.248239278793335
train: epoch 16, loss 1.4622536897659302, acc=0.40905556082725525, loss=1.4622536897659302
test: epoch 16, loss 2.190814971923828, acc=0.20277777314186096, loss=2.190814971923828
train: epoch 17, loss 1.416909098625183, acc=0.4225555658340454, loss=1.416909098625183
test: epoch 17, loss 2.118239164352417, acc=0.21666666865348816, loss=2.118239164352417
train: epoch 18, loss 1.4142948389053345, acc=0.42399999499320984, loss=1.4142948389053345
test: epoch 18, loss 2.022235870361328, acc=0.22777777910232544, loss=2.022235870361328
train: epoch 19, loss 1.3722280263900757, acc=0.4355555474758148, loss=1.3722280263900757
test: epoch 19, loss 2.216275215148926, acc=0.2083333283662796, loss=2.216275215148926
train: epoch 20, loss 1.3732223510742188, acc=0.4415000081062317, loss=1.3732223510742188
test: epoch 20, loss 2.018791675567627, acc=0.18888889253139496, loss=2.018791675567627
train: epoch 21, loss 1.3410799503326416, acc=0.45444443821907043, loss=1.3410799503326416
test: epoch 21, loss 2.024649143218994, acc=0.22499999403953552, loss=2.024649143218994
train: epoch 22, loss 1.324205756187439, acc=0.4667777717113495, loss=1.324205756187439
test: epoch 22, loss 1.9557358026504517, acc=0.23333333432674408, loss=1.9557358026504517
train: epoch 23, loss 1.3031928539276123, acc=0.4689444303512573, loss=1.3031928539276123
test: epoch 23, loss 1.9360839128494263, acc=0.2222222238779068, loss=1.9360839128494263
train: epoch 24, loss 1.3021330833435059, acc=0.47527778148651123, loss=1.3021330833435059
test: epoch 24, loss 2.0056586265563965, acc=0.21388888359069824, loss=2.0056586265563965
train: epoch 25, loss 1.2818348407745361, acc=0.4777222275733948, loss=1.2818348407745361
test: epoch 25, loss 2.0622146129608154, acc=0.17499999701976776, loss=2.0622146129608154
train: epoch 26, loss 1.2417826652526855, acc=0.4905555546283722, loss=1.2417826652526855
test: epoch 26, loss 1.927000641822815, acc=0.21944443881511688, loss=1.927000641822815
train: epoch 27, loss 1.246657133102417, acc=0.49033331871032715, loss=1.246657133102417
test: epoch 27, loss 1.8996385335922241, acc=0.28333333134651184, loss=1.8996385335922241
train: epoch 28, loss 1.212138295173645, acc=0.5043333172798157, loss=1.212138295173645
test: epoch 28, loss 1.891097903251648, acc=0.27222222089767456, loss=1.891097903251648
train: epoch 29, loss 1.209130048751831, acc=0.5036666393280029, loss=1.209130048751831
test: epoch 29, loss 1.787300705909729, acc=0.2666666805744171, loss=1.787300705909729
train: epoch 30, loss 1.1863845586776733, acc=0.5166110992431641, loss=1.1863845586776733
test: epoch 30, loss 1.8739017248153687, acc=0.2916666567325592, loss=1.8739017248153687
train: epoch 31, loss 1.1732947826385498, acc=0.5187777876853943, loss=1.1732947826385498
test: epoch 31, loss 1.873970866203308, acc=0.2666666805744171, loss=1.873970866203308
train: epoch 32, loss 1.1546876430511475, acc=0.5254444479942322, loss=1.1546876430511475
test: epoch 32, loss 1.863999605178833, acc=0.30000001192092896, loss=1.863999605178833
train: epoch 33, loss 1.1351039409637451, acc=0.5368333458900452, loss=1.1351039409637451
test: epoch 33, loss 1.95490562915802, acc=0.24722221493721008, loss=1.95490562915802
train: epoch 34, loss 1.1332550048828125, acc=0.5407222509384155, loss=1.1332550048828125
test: epoch 34, loss 1.842099905014038, acc=0.31111112236976624, loss=1.842099905014038
train: epoch 35, loss 1.1221765279769897, acc=0.5460000038146973, loss=1.1221765279769897
test: epoch 35, loss 1.9215182065963745, acc=0.29722222685813904, loss=1.9215182065963745
train: epoch 36, loss 1.1236275434494019, acc=0.5471110939979553, loss=1.1236275434494019
test: epoch 36, loss 1.7167646884918213, acc=0.2805555462837219, loss=1.7167646884918213
train: epoch 37, loss 1.0887356996536255, acc=0.5558888912200928, loss=1.0887356996536255
test: epoch 37, loss 1.7663949728012085, acc=0.2777777910232544, loss=1.7663949728012085
train: epoch 38, loss 1.071521282196045, acc=0.5623888969421387, loss=1.071521282196045
test: epoch 38, loss 1.9245744943618774, acc=0.2777777910232544, loss=1.9245744943618774
train: epoch 39, loss 1.082700490951538, acc=0.555055558681488, loss=1.082700490951538
test: epoch 39, loss 1.8516680002212524, acc=0.25555557012557983, loss=1.8516680002212524
train: epoch 40, loss 1.059108018875122, acc=0.5662222504615784, loss=1.059108018875122
test: epoch 40, loss 1.8969151973724365, acc=0.2777777910232544, loss=1.8969151973724365
train: epoch 41, loss 1.0518256425857544, acc=0.5671666860580444, loss=1.0518256425857544
test: epoch 41, loss 1.9546936750411987, acc=0.2611111104488373, loss=1.9546936750411987
train: epoch 42, loss 1.0567995309829712, acc=0.570555567741394, loss=1.0567995309829712
test: epoch 42, loss 1.8327499628067017, acc=0.29722222685813904, loss=1.8327499628067017
train: epoch 43, loss 1.0300111770629883, acc=0.5813888907432556, loss=1.0300111770629883
test: epoch 43, loss 1.7410144805908203, acc=0.3055555522441864, loss=1.7410144805908203
train: epoch 44, loss 1.0284109115600586, acc=0.5824999809265137, loss=1.0284109115600586
test: epoch 44, loss 1.8151259422302246, acc=0.25, loss=1.8151259422302246
train: epoch 45, loss 1.0140628814697266, acc=0.5868889093399048, loss=1.0140628814697266
test: epoch 45, loss 1.8424488306045532, acc=0.3083333373069763, loss=1.8424488306045532
train: epoch 46, loss 1.0028234720230103, acc=0.5876666903495789, loss=1.0028234720230103
test: epoch 46, loss 1.8889670372009277, acc=0.25833332538604736, loss=1.8889670372009277
train: epoch 47, loss 1.0040260553359985, acc=0.5907777547836304, loss=1.0040260553359985
test: epoch 47, loss 1.932496190071106, acc=0.28333333134651184, loss=1.932496190071106
train: epoch 48, loss 1.0047439336776733, acc=0.5941110849380493, loss=1.0047439336776733
test: epoch 48, loss 1.9279017448425293, acc=0.25833332538604736, loss=1.9279017448425293
train: epoch 49, loss 0.9808330535888672, acc=0.6019444465637207, loss=0.9808330535888672
test: epoch 49, loss 1.8235745429992676, acc=0.24722221493721008, loss=1.8235745429992676
train: epoch 50, loss 0.9669073820114136, acc=0.605222225189209, loss=0.9669073820114136
test: epoch 50, loss 1.9218053817749023, acc=0.25555557012557983, loss=1.9218053817749023
train: epoch 51, loss 0.9736637473106384, acc=0.602222204208374, loss=0.9736637473106384
test: epoch 51, loss 1.825994610786438, acc=0.2916666567325592, loss=1.825994610786438
train: epoch 52, loss 0.9347880482673645, acc=0.6184999942779541, loss=0.9347880482673645
test: epoch 52, loss 1.8182082176208496, acc=0.29722222685813904, loss=1.8182082176208496
train: epoch 53, loss 0.9356369972229004, acc=0.6208333373069763, loss=0.9356369972229004
test: epoch 53, loss 1.9025074243545532, acc=0.20277777314186096, loss=1.9025074243545532
train: epoch 54, loss 0.9439327716827393, acc=0.6198333501815796, loss=0.9439327716827393
test: epoch 54, loss 1.7745444774627686, acc=0.2944444417953491, loss=1.7745444774627686
train: epoch 55, loss 0.9364868998527527, acc=0.6242222189903259, loss=0.9364868998527527
test: epoch 55, loss 1.6571567058563232, acc=0.34166666865348816, loss=1.6571567058563232
train: epoch 56, loss 0.9105011224746704, acc=0.6262778043746948, loss=0.9105011224746704
test: epoch 56, loss 1.9859412908554077, acc=0.24722221493721008, loss=1.9859412908554077
train: epoch 57, loss 0.9173529148101807, acc=0.6303889155387878, loss=0.9173529148101807
test: epoch 57, loss 1.8011846542358398, acc=0.28611111640930176, loss=1.8011846542358398
train: epoch 58, loss 0.8995093703269958, acc=0.6336666941642761, loss=0.8995093703269958
test: epoch 58, loss 1.9611735343933105, acc=0.2750000059604645, loss=1.9611735343933105
train: epoch 59, loss 0.9058564901351929, acc=0.63355553150177, loss=0.9058564901351929
test: epoch 59, loss 1.8632137775421143, acc=0.28611111640930176, loss=1.8632137775421143
train: epoch 60, loss 0.9007118344306946, acc=0.6395555734634399, loss=0.9007118344306946
test: epoch 60, loss 1.7815049886703491, acc=0.3222222328186035, loss=1.7815049886703491
train: epoch 61, loss 0.8882124423980713, acc=0.6418333053588867, loss=0.8882124423980713
test: epoch 61, loss 1.7179147005081177, acc=0.26944443583488464, loss=1.7179147005081177
train: epoch 62, loss 0.8747745752334595, acc=0.6460555791854858, loss=0.8747745752334595
test: epoch 62, loss 1.8389338254928589, acc=0.3027777671813965, loss=1.8389338254928589
train: epoch 63, loss 0.8832271695137024, acc=0.6430555582046509, loss=0.8832271695137024
test: epoch 63, loss 2.024933338165283, acc=0.28611111640930176, loss=2.024933338165283
train: epoch 64, loss 0.8598660826683044, acc=0.651888906955719, loss=0.8598660826683044
test: epoch 64, loss 1.7895636558532715, acc=0.3166666626930237, loss=1.7895636558532715
train: epoch 65, loss 0.8791379332542419, acc=0.6481666564941406, loss=0.8791379332542419
test: epoch 65, loss 2.0589206218719482, acc=0.2611111104488373, loss=2.0589206218719482
train: epoch 66, loss 0.8542910814285278, acc=0.6568333506584167, loss=0.8542910814285278
test: epoch 66, loss 1.8750176429748535, acc=0.3055555522441864, loss=1.8750176429748535
train: epoch 67, loss 0.8413626551628113, acc=0.6530555486679077, loss=0.8413626551628113
test: epoch 67, loss 1.8751453161239624, acc=0.30000001192092896, loss=1.8751453161239624
train: epoch 68, loss 0.8387055397033691, acc=0.6664999723434448, loss=0.8387055397033691
test: epoch 68, loss 1.6906638145446777, acc=0.32777777314186096, loss=1.6906638145446777
train: epoch 69, loss 0.8564726114273071, acc=0.6566666960716248, loss=0.8564726114273071
test: epoch 69, loss 1.6743292808532715, acc=0.3166666626930237, loss=1.6743292808532715
train: epoch 70, loss 0.8462633490562439, acc=0.6641666889190674, loss=0.8462633490562439
test: epoch 70, loss 1.9895938634872437, acc=0.26944443583488464, loss=1.9895938634872437
train: epoch 71, loss 0.819162130355835, acc=0.6710555553436279, loss=0.819162130355835
test: epoch 71, loss 1.8926032781600952, acc=0.25833332538604736, loss=1.8926032781600952
train: epoch 72, loss 0.8114027976989746, acc=0.6757222414016724, loss=0.8114027976989746
test: epoch 72, loss 1.786999225616455, acc=0.31111112236976624, loss=1.786999225616455
train: epoch 73, loss 0.8053379058837891, acc=0.6775000095367432, loss=0.8053379058837891
test: epoch 73, loss 1.950222373008728, acc=0.34166666865348816, loss=1.950222373008728
train: epoch 74, loss 0.7847915887832642, acc=0.6846666932106018, loss=0.7847915887832642
test: epoch 74, loss 1.9633334875106812, acc=0.31388887763023376, loss=1.9633334875106812
train: epoch 75, loss 0.7917050123214722, acc=0.6819444298744202, loss=0.7917050123214722
test: epoch 75, loss 1.9599982500076294, acc=0.3083333373069763, loss=1.9599982500076294
train: epoch 76, loss 0.7974385619163513, acc=0.6823889017105103, loss=0.7974385619163513
test: epoch 76, loss 1.9716418981552124, acc=0.22499999403953552, loss=1.9716418981552124
train: epoch 77, loss 0.7722815275192261, acc=0.691777765750885, loss=0.7722815275192261
test: epoch 77, loss 1.6881139278411865, acc=0.3472222089767456, loss=1.6881139278411865
train: epoch 78, loss 0.7788463234901428, acc=0.6842777729034424, loss=0.7788463234901428
test: epoch 78, loss 2.322690010070801, acc=0.2888889014720917, loss=2.322690010070801
train: epoch 79, loss 0.7713263034820557, acc=0.6906111240386963, loss=0.7713263034820557
test: epoch 79, loss 1.704759120941162, acc=0.4000000059604645, loss=1.704759120941162
train: epoch 80, loss 0.7983388304710388, acc=0.684166669845581, loss=0.7983388304710388
test: epoch 80, loss 1.9159632921218872, acc=0.32777777314186096, loss=1.9159632921218872
train: epoch 81, loss 0.7641478776931763, acc=0.6953333616256714, loss=0.7641478776931763
test: epoch 81, loss 1.9219704866409302, acc=0.33888888359069824, loss=1.9219704866409302
train: epoch 82, loss 0.7658208012580872, acc=0.6918333172798157, loss=0.7658208012580872
test: epoch 82, loss 1.94749915599823, acc=0.2888889014720917, loss=1.94749915599823
train: epoch 83, loss 0.7567261457443237, acc=0.6930000185966492, loss=0.7567261457443237
test: epoch 83, loss 1.8974844217300415, acc=0.39444443583488464, loss=1.8974844217300415
train: epoch 84, loss 0.7774503827095032, acc=0.6899444460868835, loss=0.7774503827095032
test: epoch 84, loss 1.8696396350860596, acc=0.3166666626930237, loss=1.8696396350860596
train: epoch 85, loss 0.7479760050773621, acc=0.6991111040115356, loss=0.7479760050773621
test: epoch 85, loss 1.8739469051361084, acc=0.3333333432674408, loss=1.8739469051361084
train: epoch 86, loss 0.7530018091201782, acc=0.6969444155693054, loss=0.7530018091201782
test: epoch 86, loss 2.065361976623535, acc=0.2638888955116272, loss=2.065361976623535
train: epoch 87, loss 0.7323038578033447, acc=0.7022222280502319, loss=0.7323038578033447
test: epoch 87, loss 1.745834231376648, acc=0.30000001192092896, loss=1.745834231376648
train: epoch 88, loss 0.7273070812225342, acc=0.7033888697624207, loss=0.7273070812225342
test: epoch 88, loss 1.7985111474990845, acc=0.3305555582046509, loss=1.7985111474990845
train: epoch 89, loss 0.7225108742713928, acc=0.7082222104072571, loss=0.7225108742713928
test: epoch 89, loss 1.6006557941436768, acc=0.35277777910232544, loss=1.6006557941436768
train: epoch 90, loss 0.7216707468032837, acc=0.7070000171661377, loss=0.7216707468032837
test: epoch 90, loss 1.889768123626709, acc=0.35277777910232544, loss=1.889768123626709
train: epoch 91, loss 0.7281854748725891, acc=0.7110555768013, loss=0.7281854748725891
test: epoch 91, loss 1.6222513914108276, acc=0.4194444417953491, loss=1.6222513914108276
train: epoch 92, loss 0.7169981598854065, acc=0.7137777805328369, loss=0.7169981598854065
test: epoch 92, loss 1.9514409303665161, acc=0.3777777850627899, loss=1.9514409303665161
train: epoch 93, loss 0.707904577255249, acc=0.7171111106872559, loss=0.707904577255249
test: epoch 93, loss 1.6496965885162354, acc=0.2944444417953491, loss=1.6496965885162354
train: epoch 94, loss 0.7084200382232666, acc=0.717555582523346, loss=0.7084200382232666
test: epoch 94, loss 1.6713602542877197, acc=0.39444443583488464, loss=1.6713602542877197
train: epoch 95, loss 0.7080769538879395, acc=0.7164444327354431, loss=0.7080769538879395
test: epoch 95, loss 1.736777424812317, acc=0.3444444537162781, loss=1.736777424812317
train: epoch 96, loss 0.703471302986145, acc=0.7231666445732117, loss=0.703471302986145
test: epoch 96, loss 1.9341505765914917, acc=0.38055557012557983, loss=1.9341505765914917
train: epoch 97, loss 0.6873261332511902, acc=0.7227222323417664, loss=0.6873261332511902
test: epoch 97, loss 1.8701322078704834, acc=0.3472222089767456, loss=1.8701322078704834
train: epoch 98, loss 0.697912871837616, acc=0.7200000286102295, loss=0.697912871837616
test: epoch 98, loss 1.967623233795166, acc=0.3472222089767456, loss=1.967623233795166
train: epoch 99, loss 0.6895757913589478, acc=0.7235555648803711, loss=0.6895757913589478
test: epoch 99, loss 1.90786612033844, acc=0.32777777314186096, loss=1.90786612033844
train: epoch 100, loss 0.6984418034553528, acc=0.7244444489479065, loss=0.6984418034553528
test: epoch 100, loss 1.934622883796692, acc=0.29722222685813904, loss=1.934622883796692
train: epoch 101, loss 0.6749882102012634, acc=0.7287222146987915, loss=0.6749882102012634
test: epoch 101, loss 2.0135273933410645, acc=0.2777777910232544, loss=2.0135273933410645
train: epoch 102, loss 0.6578261256217957, acc=0.7376111149787903, loss=0.6578261256217957
test: epoch 102, loss 1.789496898651123, acc=0.3222222328186035, loss=1.789496898651123
train: epoch 103, loss 0.6599966883659363, acc=0.7425000071525574, loss=0.6599966883659363
test: epoch 103, loss 1.7712595462799072, acc=0.2944444417953491, loss=1.7712595462799072
train: epoch 104, loss 0.6688699126243591, acc=0.7331666946411133, loss=0.6688699126243591
test: epoch 104, loss 2.0269596576690674, acc=0.3916666805744171, loss=2.0269596576690674
train: epoch 105, loss 0.6750025749206543, acc=0.7325555682182312, loss=0.6750025749206543
test: epoch 105, loss 1.7131714820861816, acc=0.3166666626930237, loss=1.7131714820861816
train: epoch 106, loss 0.6529096961021423, acc=0.7454444169998169, loss=0.6529096961021423
test: epoch 106, loss 1.863613247871399, acc=0.31388887763023376, loss=1.863613247871399
train: epoch 107, loss 0.7002823948860168, acc=0.7294444441795349, loss=0.7002823948860168
test: epoch 107, loss 1.8762116432189941, acc=0.3472222089767456, loss=1.8762116432189941
train: epoch 108, loss 0.6637005805969238, acc=0.7444999814033508, loss=0.6637005805969238
test: epoch 108, loss 2.0963220596313477, acc=0.2888889014720917, loss=2.0963220596313477
train: epoch 109, loss 0.6624112725257874, acc=0.742555558681488, loss=0.6624112725257874
test: epoch 109, loss 1.5974273681640625, acc=0.3722222149372101, loss=1.5974273681640625
train: epoch 110, loss 0.6612623929977417, acc=0.7409444451332092, loss=0.6612623929977417
test: epoch 110, loss 1.7892242670059204, acc=0.3472222089767456, loss=1.7892242670059204
train: epoch 111, loss 0.6584933400154114, acc=0.7433888912200928, loss=0.6584933400154114
test: epoch 111, loss 2.046612501144409, acc=0.3472222089767456, loss=2.046612501144409
train: epoch 112, loss 0.6647913455963135, acc=0.7429444193840027, loss=0.6647913455963135
test: epoch 112, loss 1.7221249341964722, acc=0.3499999940395355, loss=1.7221249341964722
train: epoch 113, loss 0.6346356272697449, acc=0.7492777705192566, loss=0.6346356272697449
test: epoch 113, loss 1.5222951173782349, acc=0.3888888955116272, loss=1.5222951173782349
train: epoch 114, loss 0.6650126576423645, acc=0.741611123085022, loss=0.6650126576423645
test: epoch 114, loss 1.8843716382980347, acc=0.3305555582046509, loss=1.8843716382980347
train: epoch 115, loss 0.6376936435699463, acc=0.7530555725097656, loss=0.6376936435699463
test: epoch 115, loss 2.0599944591522217, acc=0.27222222089767456, loss=2.0599944591522217
train: epoch 116, loss 0.6407806277275085, acc=0.7466111183166504, loss=0.6407806277275085
test: epoch 116, loss 1.6716915369033813, acc=0.3472222089767456, loss=1.6716915369033813
train: epoch 117, loss 0.6330758333206177, acc=0.749666690826416, loss=0.6330758333206177
test: epoch 117, loss 1.8339482545852661, acc=0.31388887763023376, loss=1.8339482545852661
train: epoch 118, loss 0.6396141648292542, acc=0.7507222294807434, loss=0.6396141648292542
test: epoch 118, loss 1.5609005689620972, acc=0.42500001192092896, loss=1.5609005689620972
train: epoch 119, loss 0.6238598823547363, acc=0.7518888711929321, loss=0.6238598823547363
test: epoch 119, loss 2.0251071453094482, acc=0.39444443583488464, loss=2.0251071453094482
train: epoch 120, loss 0.6349834203720093, acc=0.7475555539131165, loss=0.6349834203720093
test: epoch 120, loss 1.7155036926269531, acc=0.3722222149372101, loss=1.7155036926269531
train: epoch 121, loss 0.6722189784049988, acc=0.7404444217681885, loss=0.6722189784049988
test: epoch 121, loss 1.981203556060791, acc=0.36666667461395264, loss=1.981203556060791
train: epoch 122, loss 0.629579484462738, acc=0.7555000185966492, loss=0.629579484462738
test: epoch 122, loss 1.7921820878982544, acc=0.3472222089767456, loss=1.7921820878982544
train: epoch 123, loss 0.6414987444877625, acc=0.7489444613456726, loss=0.6414987444877625
test: epoch 123, loss 1.6141360998153687, acc=0.375, loss=1.6141360998153687
train: epoch 124, loss 0.6061443090438843, acc=0.7581666707992554, loss=0.6061443090438843
test: epoch 124, loss 1.7397712469100952, acc=0.35277777910232544, loss=1.7397712469100952
train: epoch 125, loss 0.6537956595420837, acc=0.7518333196640015, loss=0.6537956595420837
test: epoch 125, loss 1.7179107666015625, acc=0.375, loss=1.7179107666015625
train: epoch 126, loss 0.6161854267120361, acc=0.7609444260597229, loss=0.6161854267120361
test: epoch 126, loss 1.8734359741210938, acc=0.3333333432674408, loss=1.8734359741210938
train: epoch 127, loss 0.6152743101119995, acc=0.7641666531562805, loss=0.6152743101119995
test: epoch 127, loss 2.012328863143921, acc=0.35277777910232544, loss=2.012328863143921
train: epoch 128, loss 0.6274062991142273, acc=0.7566666603088379, loss=0.6274062991142273
test: epoch 128, loss 1.7005022764205933, acc=0.39444443583488464, loss=1.7005022764205933
train: epoch 129, loss 0.6072304844856262, acc=0.7657222151756287, loss=0.6072304844856262
test: epoch 129, loss 1.7802561521530151, acc=0.3499999940395355, loss=1.7802561521530151
train: epoch 130, loss 0.6166382431983948, acc=0.7603333592414856, loss=0.6166382431983948
test: epoch 130, loss 1.771501064300537, acc=0.3722222149372101, loss=1.771501064300537
train: epoch 131, loss 0.5982755422592163, acc=0.7687222361564636, loss=0.5982755422592163
test: epoch 131, loss 2.0923423767089844, acc=0.2805555462837219, loss=2.0923423767089844
train: epoch 132, loss 0.6170757412910461, acc=0.7618333101272583, loss=0.6170757412910461
test: epoch 132, loss 2.027071952819824, acc=0.28333333134651184, loss=2.027071952819824
train: epoch 133, loss 0.6024748086929321, acc=0.7642777562141418, loss=0.6024748086929321
test: epoch 133, loss 1.7263191938400269, acc=0.42500001192092896, loss=1.7263191938400269
train: epoch 134, loss 0.6032041311264038, acc=0.7620555758476257, loss=0.6032041311264038
test: epoch 134, loss 1.933329701423645, acc=0.3777777850627899, loss=1.933329701423645
train: epoch 135, loss 0.6094737648963928, acc=0.7655555605888367, loss=0.6094737648963928
test: epoch 135, loss 1.7146389484405518, acc=0.4166666567325592, loss=1.7146389484405518
train: epoch 136, loss 0.5938701629638672, acc=0.7666666507720947, loss=0.5938701629638672
test: epoch 136, loss 2.1505179405212402, acc=0.35277777910232544, loss=2.1505179405212402
train: epoch 137, loss 0.590680718421936, acc=0.7681666612625122, loss=0.590680718421936
test: epoch 137, loss 1.769290566444397, acc=0.36944442987442017, loss=1.769290566444397
train: epoch 138, loss 0.6018003225326538, acc=0.7664999961853027, loss=0.6018003225326538
test: epoch 138, loss 1.825381875038147, acc=0.3166666626930237, loss=1.825381875038147
train: epoch 139, loss 0.5779188871383667, acc=0.7756666541099548, loss=0.5779188871383667
test: epoch 139, loss 2.1527321338653564, acc=0.34166666865348816, loss=2.1527321338653564
train: epoch 140, loss 0.5897514224052429, acc=0.7675555348396301, loss=0.5897514224052429
test: epoch 140, loss 1.714569091796875, acc=0.39444443583488464, loss=1.714569091796875
train: epoch 141, loss 0.5737202763557434, acc=0.774055540561676, loss=0.5737202763557434
test: epoch 141, loss 1.7943692207336426, acc=0.38333332538604736, loss=1.7943692207336426
train: epoch 142, loss 0.5929162502288818, acc=0.7692777514457703, loss=0.5929162502288818
test: epoch 142, loss 1.807025671005249, acc=0.39722222089767456, loss=1.807025671005249
train: epoch 143, loss 0.5748844742774963, acc=0.7752777934074402, loss=0.5748844742774963
test: epoch 143, loss 2.005113124847412, acc=0.2916666567325592, loss=2.005113124847412
train: epoch 144, loss 0.617965817451477, acc=0.7631111145019531, loss=0.617965817451477
test: epoch 144, loss 1.967764973640442, acc=0.2916666567325592, loss=1.967764973640442
train: epoch 145, loss 0.5993484854698181, acc=0.7707222104072571, loss=0.5993484854698181
test: epoch 145, loss 1.819578766822815, acc=0.38333332538604736, loss=1.819578766822815
train: epoch 146, loss 0.5979245901107788, acc=0.7701666951179504, loss=0.5979245901107788
test: epoch 146, loss 2.0857226848602295, acc=0.3361110985279083, loss=2.0857226848602295
train: epoch 147, loss 0.5842230319976807, acc=0.7752777934074402, loss=0.5842230319976807
test: epoch 147, loss 1.5014458894729614, acc=0.4611110985279083, loss=1.5014458894729614
train: epoch 148, loss 0.571104109287262, acc=0.7743333578109741, loss=0.571104109287262
test: epoch 148, loss 1.679958462715149, acc=0.4027777910232544, loss=1.679958462715149
train: epoch 149, loss 0.5780631899833679, acc=0.7724444270133972, loss=0.5780631899833679
test: epoch 149, loss 1.4893507957458496, acc=0.4027777910232544, loss=1.4893507957458496
train: epoch 150, loss 0.5755126476287842, acc=0.7769444584846497, loss=0.5755126476287842
test: epoch 150, loss 1.794999599456787, acc=0.4444444477558136, loss=1.794999599456787
