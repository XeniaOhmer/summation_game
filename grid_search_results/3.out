# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1", "--temp_decay=1", "--one_hot=false", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1448629285, receiver_embed_dim=32, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.4687459468841553, acc=0.04538888856768608, loss=3.4687459468841553
test: epoch 1, loss 3.6225335597991943, acc=0.05277777835726738, loss=3.6225335597991943
train: epoch 2, loss 2.9654791355133057, acc=0.09972222149372101, loss=2.9654791355133057
test: epoch 2, loss 2.789557933807373, acc=0.0972222238779068, loss=2.789557933807373
train: epoch 3, loss 2.317326545715332, acc=0.19816666841506958, loss=2.317326545715332
test: epoch 3, loss 2.3605668544769287, acc=0.14444445073604584, loss=2.3605668544769287
train: epoch 4, loss 1.961656093597412, acc=0.2593333423137665, loss=1.961656093597412
test: epoch 4, loss 2.2542173862457275, acc=0.15555556118488312, loss=2.2542173862457275
train: epoch 5, loss 1.8146061897277832, acc=0.2845555543899536, loss=1.8146061897277832
test: epoch 5, loss 2.1938962936401367, acc=0.16111111640930176, loss=2.1938962936401367
train: epoch 6, loss 1.7238566875457764, acc=0.3137222230434418, loss=1.7238566875457764
test: epoch 6, loss 2.1799139976501465, acc=0.16388888657093048, loss=2.1799139976501465
train: epoch 7, loss 1.6447802782058716, acc=0.3448888957500458, loss=1.6447802782058716
test: epoch 7, loss 2.1644093990325928, acc=0.17777778208255768, loss=2.1644093990325928
train: epoch 8, loss 1.5781463384628296, acc=0.3667222261428833, loss=1.5781463384628296
test: epoch 8, loss 2.1047332286834717, acc=0.19166666269302368, loss=2.1047332286834717
train: epoch 9, loss 1.5229253768920898, acc=0.38688889145851135, loss=1.5229253768920898
test: epoch 9, loss 2.165135383605957, acc=0.19722221791744232, loss=2.165135383605957
train: epoch 10, loss 1.4623881578445435, acc=0.4142777919769287, loss=1.4623881578445435
test: epoch 10, loss 2.019798994064331, acc=0.20000000298023224, loss=2.019798994064331
train: epoch 11, loss 1.4215118885040283, acc=0.42205554246902466, loss=1.4215118885040283
test: epoch 11, loss 1.99143648147583, acc=0.20277777314186096, loss=1.99143648147583
train: epoch 12, loss 1.3691272735595703, acc=0.44699999690055847, loss=1.3691272735595703
test: epoch 12, loss 2.019118070602417, acc=0.19722221791744232, loss=2.019118070602417
train: epoch 13, loss 1.3367321491241455, acc=0.46327778697013855, loss=1.3367321491241455
test: epoch 13, loss 1.9669899940490723, acc=0.21111111342906952, loss=1.9669899940490723
train: epoch 14, loss 1.3082977533340454, acc=0.4704444408416748, loss=1.3082977533340454
test: epoch 14, loss 1.954403281211853, acc=0.20277777314186096, loss=1.954403281211853
train: epoch 15, loss 1.2705249786376953, acc=0.48277777433395386, loss=1.2705249786376953
test: epoch 15, loss 1.9688341617584229, acc=0.21944443881511688, loss=1.9688341617584229
train: epoch 16, loss 1.2600042819976807, acc=0.4868888854980469, loss=1.2600042819976807
test: epoch 16, loss 1.9950392246246338, acc=0.21388888359069824, loss=1.9950392246246338
train: epoch 17, loss 1.235865831375122, acc=0.4966111183166504, loss=1.235865831375122
test: epoch 17, loss 2.0183463096618652, acc=0.21666666865348816, loss=2.0183463096618652
train: epoch 18, loss 1.2187247276306152, acc=0.5059999823570251, loss=1.2187247276306152
test: epoch 18, loss 2.0275349617004395, acc=0.21666666865348816, loss=2.0275349617004395
train: epoch 19, loss 1.1899397373199463, acc=0.5101666450500488, loss=1.1899397373199463
test: epoch 19, loss 1.9955840110778809, acc=0.22499999403953552, loss=1.9955840110778809
train: epoch 20, loss 1.1775470972061157, acc=0.5176666378974915, loss=1.1775470972061157
test: epoch 20, loss 2.000180959701538, acc=0.2222222238779068, loss=2.000180959701538
train: epoch 21, loss 1.162142038345337, acc=0.5212222337722778, loss=1.162142038345337
test: epoch 21, loss 2.0259158611297607, acc=0.2222222238779068, loss=2.0259158611297607
train: epoch 22, loss 1.1481854915618896, acc=0.5271666646003723, loss=1.1481854915618896
test: epoch 22, loss 2.024837017059326, acc=0.23055554926395416, loss=2.024837017059326
train: epoch 23, loss 1.1249306201934814, acc=0.5372222065925598, loss=1.1249306201934814
test: epoch 23, loss 2.048534870147705, acc=0.22499999403953552, loss=2.048534870147705
train: epoch 24, loss 1.1125935316085815, acc=0.5426666736602783, loss=1.1125935316085815
test: epoch 24, loss 2.0290470123291016, acc=0.2361111044883728, loss=2.0290470123291016
train: epoch 25, loss 1.099482774734497, acc=0.5459444522857666, loss=1.099482774734497
test: epoch 25, loss 2.0482821464538574, acc=0.23055554926395416, loss=2.0482821464538574
train: epoch 26, loss 1.0735613107681274, acc=0.5541666746139526, loss=1.0735613107681274
test: epoch 26, loss 2.1257760524749756, acc=0.24444444477558136, loss=2.1257760524749756
train: epoch 27, loss 1.0778218507766724, acc=0.554111123085022, loss=1.0778218507766724
test: epoch 27, loss 2.026031017303467, acc=0.25, loss=2.026031017303467
train: epoch 28, loss 1.0621857643127441, acc=0.5613889098167419, loss=1.0621857643127441
test: epoch 28, loss 2.0001790523529053, acc=0.25833332538604736, loss=2.0001790523529053
train: epoch 29, loss 1.0478695631027222, acc=0.5646111369132996, loss=1.0478695631027222
test: epoch 29, loss 1.9887746572494507, acc=0.2527777850627899, loss=1.9887746572494507
train: epoch 30, loss 1.0318398475646973, acc=0.5740000009536743, loss=1.0318398475646973
test: epoch 30, loss 2.079294443130493, acc=0.2527777850627899, loss=2.079294443130493
train: epoch 31, loss 1.032044768333435, acc=0.570277750492096, loss=1.032044768333435
test: epoch 31, loss 2.1000468730926514, acc=0.25, loss=2.1000468730926514
train: epoch 32, loss 1.0194079875946045, acc=0.5706666707992554, loss=1.0194079875946045
test: epoch 32, loss 2.091262102127075, acc=0.25833332538604736, loss=2.091262102127075
train: epoch 33, loss 0.9939124584197998, acc=0.581166684627533, loss=0.9939124584197998
test: epoch 33, loss 1.9720309972763062, acc=0.2638888955116272, loss=1.9720309972763062
train: epoch 34, loss 0.9852866530418396, acc=0.5869444608688354, loss=0.9852866530418396
test: epoch 34, loss 2.053725481033325, acc=0.2666666805744171, loss=2.053725481033325
train: epoch 35, loss 0.9927054047584534, acc=0.5896111130714417, loss=0.9927054047584534
test: epoch 35, loss 2.018658399581909, acc=0.2611111104488373, loss=2.018658399581909
train: epoch 36, loss 0.98167884349823, acc=0.5872222185134888, loss=0.98167884349823
test: epoch 36, loss 2.034654140472412, acc=0.25555557012557983, loss=2.034654140472412
train: epoch 37, loss 0.9642530679702759, acc=0.5961666703224182, loss=0.9642530679702759
test: epoch 37, loss 2.0850510597229004, acc=0.25833332538604736, loss=2.0850510597229004
train: epoch 38, loss 0.9626884460449219, acc=0.6004999876022339, loss=0.9626884460449219
test: epoch 38, loss 2.010692834854126, acc=0.2638888955116272, loss=2.010692834854126
train: epoch 39, loss 0.9449825286865234, acc=0.6050000190734863, loss=0.9449825286865234
test: epoch 39, loss 2.1025936603546143, acc=0.2611111104488373, loss=2.1025936603546143
train: epoch 40, loss 0.9302722811698914, acc=0.6120555400848389, loss=0.9302722811698914
test: epoch 40, loss 2.023897409439087, acc=0.2777777910232544, loss=2.023897409439087
train: epoch 41, loss 0.9329237937927246, acc=0.6085000038146973, loss=0.9329237937927246
test: epoch 41, loss 2.0750608444213867, acc=0.28611111640930176, loss=2.0750608444213867
train: epoch 42, loss 0.9293203353881836, acc=0.6079444289207458, loss=0.9293203353881836
test: epoch 42, loss 2.062654495239258, acc=0.2805555462837219, loss=2.062654495239258
train: epoch 43, loss 0.910062849521637, acc=0.6143888831138611, loss=0.910062849521637
test: epoch 43, loss 2.1145434379577637, acc=0.2888889014720917, loss=2.1145434379577637
train: epoch 44, loss 0.9030138850212097, acc=0.6200555562973022, loss=0.9030138850212097
test: epoch 44, loss 2.053438663482666, acc=0.28611111640930176, loss=2.053438663482666
train: epoch 45, loss 0.8920837640762329, acc=0.6206666827201843, loss=0.8920837640762329
test: epoch 45, loss 2.074921131134033, acc=0.28333333134651184, loss=2.074921131134033
train: epoch 46, loss 0.886517345905304, acc=0.624833345413208, loss=0.886517345905304
test: epoch 46, loss 2.0447680950164795, acc=0.2888889014720917, loss=2.0447680950164795
train: epoch 47, loss 0.8737568259239197, acc=0.6295555830001831, loss=0.8737568259239197
test: epoch 47, loss 2.127126455307007, acc=0.30000001192092896, loss=2.127126455307007
train: epoch 48, loss 0.869395911693573, acc=0.6295555830001831, loss=0.869395911693573
test: epoch 48, loss 2.0731799602508545, acc=0.29722222685813904, loss=2.0731799602508545
train: epoch 49, loss 0.8694847226142883, acc=0.632888913154602, loss=0.8694847226142883
test: epoch 49, loss 2.010500431060791, acc=0.29722222685813904, loss=2.010500431060791
train: epoch 50, loss 0.8502017259597778, acc=0.6362777948379517, loss=0.8502017259597778
test: epoch 50, loss 2.049654245376587, acc=0.2916666567325592, loss=2.049654245376587
train: epoch 51, loss 0.8388503193855286, acc=0.6418333053588867, loss=0.8388503193855286
test: epoch 51, loss 2.0295913219451904, acc=0.3055555522441864, loss=2.0295913219451904
train: epoch 52, loss 0.8434072136878967, acc=0.6399999856948853, loss=0.8434072136878967
test: epoch 52, loss 2.012732982635498, acc=0.3027777671813965, loss=2.012732982635498
train: epoch 53, loss 0.8259949684143066, acc=0.644777774810791, loss=0.8259949684143066
test: epoch 53, loss 2.0696754455566406, acc=0.3027777671813965, loss=2.0696754455566406
train: epoch 54, loss 0.8087535500526428, acc=0.6495555639266968, loss=0.8087535500526428
test: epoch 54, loss 1.9911566972732544, acc=0.2916666567325592, loss=1.9911566972732544
train: epoch 55, loss 0.8206818699836731, acc=0.6507777571678162, loss=0.8206818699836731
test: epoch 55, loss 1.969430923461914, acc=0.29722222685813904, loss=1.969430923461914
train: epoch 56, loss 0.8068686127662659, acc=0.651888906955719, loss=0.8068686127662659
test: epoch 56, loss 2.12966251373291, acc=0.3083333373069763, loss=2.12966251373291
train: epoch 57, loss 0.8021435737609863, acc=0.6541110873222351, loss=0.8021435737609863
test: epoch 57, loss 2.0158097743988037, acc=0.3083333373069763, loss=2.0158097743988037
train: epoch 58, loss 0.7987813353538513, acc=0.6520000100135803, loss=0.7987813353538513
test: epoch 58, loss 2.0691897869110107, acc=0.3027777671813965, loss=2.0691897869110107
train: epoch 59, loss 0.7954741716384888, acc=0.656333327293396, loss=0.7954741716384888
test: epoch 59, loss 2.0396621227264404, acc=0.3083333373069763, loss=2.0396621227264404
train: epoch 60, loss 0.78753262758255, acc=0.6583889126777649, loss=0.78753262758255
test: epoch 60, loss 2.1236517429351807, acc=0.3055555522441864, loss=2.1236517429351807
train: epoch 61, loss 0.7839623689651489, acc=0.656333327293396, loss=0.7839623689651489
test: epoch 61, loss 2.1052494049072266, acc=0.31111112236976624, loss=2.1052494049072266
train: epoch 62, loss 0.781888484954834, acc=0.653333306312561, loss=0.781888484954834
test: epoch 62, loss 2.0616071224212646, acc=0.3083333373069763, loss=2.0616071224212646
train: epoch 63, loss 0.7667136788368225, acc=0.6611111164093018, loss=0.7667136788368225
test: epoch 63, loss 2.0634236335754395, acc=0.3055555522441864, loss=2.0634236335754395
train: epoch 64, loss 0.7769438028335571, acc=0.6587777733802795, loss=0.7769438028335571
test: epoch 64, loss 2.0530216693878174, acc=0.3055555522441864, loss=2.0530216693878174
train: epoch 65, loss 0.7696838974952698, acc=0.6588888764381409, loss=0.7696838974952698
test: epoch 65, loss 2.0170469284057617, acc=0.31111112236976624, loss=2.0170469284057617
train: epoch 66, loss 0.7687994837760925, acc=0.663777768611908, loss=0.7687994837760925
test: epoch 66, loss 2.059250593185425, acc=0.3027777671813965, loss=2.059250593185425
train: epoch 67, loss 0.7563135027885437, acc=0.6613888740539551, loss=0.7563135027885437
test: epoch 67, loss 2.0569324493408203, acc=0.3027777671813965, loss=2.0569324493408203
train: epoch 68, loss 0.7478439211845398, acc=0.6702222228050232, loss=0.7478439211845398
test: epoch 68, loss 2.0531222820281982, acc=0.3055555522441864, loss=2.0531222820281982
train: epoch 69, loss 0.7458037734031677, acc=0.6718888878822327, loss=0.7458037734031677
test: epoch 69, loss 2.138584613800049, acc=0.31111112236976624, loss=2.138584613800049
train: epoch 70, loss 0.7594484686851501, acc=0.6623333096504211, loss=0.7594484686851501
test: epoch 70, loss 2.160184860229492, acc=0.3194444477558136, loss=2.160184860229492
train: epoch 71, loss 0.7407792210578918, acc=0.6733888983726501, loss=0.7407792210578918
test: epoch 71, loss 2.0986239910125732, acc=0.31111112236976624, loss=2.0986239910125732
train: epoch 72, loss 0.7377392053604126, acc=0.6738333106040955, loss=0.7377392053604126
test: epoch 72, loss 2.106659412384033, acc=0.3194444477558136, loss=2.106659412384033
train: epoch 73, loss 0.7315435409545898, acc=0.6697221994400024, loss=0.7315435409545898
test: epoch 73, loss 2.0392143726348877, acc=0.31111112236976624, loss=2.0392143726348877
train: epoch 74, loss 0.7360475659370422, acc=0.6728888750076294, loss=0.7360475659370422
test: epoch 74, loss 2.2185115814208984, acc=0.32499998807907104, loss=2.2185115814208984
train: epoch 75, loss 0.7159003019332886, acc=0.6774444580078125, loss=0.7159003019332886
test: epoch 75, loss 2.107426404953003, acc=0.3361110985279083, loss=2.107426404953003
train: epoch 76, loss 0.7264316082000732, acc=0.6783888936042786, loss=0.7264316082000732
test: epoch 76, loss 2.0065200328826904, acc=0.3194444477558136, loss=2.0065200328826904
train: epoch 77, loss 0.722500741481781, acc=0.6752222180366516, loss=0.722500741481781
test: epoch 77, loss 1.996612310409546, acc=0.3166666626930237, loss=1.996612310409546
train: epoch 78, loss 0.7151633501052856, acc=0.6821666955947876, loss=0.7151633501052856
test: epoch 78, loss 2.000772476196289, acc=0.3333333432674408, loss=2.000772476196289
train: epoch 79, loss 0.7143986821174622, acc=0.6753333210945129, loss=0.7143986821174622
test: epoch 79, loss 2.0176198482513428, acc=0.32777777314186096, loss=2.0176198482513428
train: epoch 80, loss 0.7164894342422485, acc=0.6808333396911621, loss=0.7164894342422485
test: epoch 80, loss 2.153079032897949, acc=0.32777777314186096, loss=2.153079032897949
train: epoch 81, loss 0.7007104158401489, acc=0.683222234249115, loss=0.7007104158401489
test: epoch 81, loss 2.1032354831695557, acc=0.3333333432674408, loss=2.1032354831695557
train: epoch 82, loss 0.6931473612785339, acc=0.6856666803359985, loss=0.6931473612785339
test: epoch 82, loss 2.0971367359161377, acc=0.3361110985279083, loss=2.0971367359161377
train: epoch 83, loss 0.6978886127471924, acc=0.6857222318649292, loss=0.6978886127471924
test: epoch 83, loss 2.200321674346924, acc=0.32777777314186096, loss=2.200321674346924
train: epoch 84, loss 0.6831580996513367, acc=0.6898333430290222, loss=0.6831580996513367
test: epoch 84, loss 2.07521390914917, acc=0.3361110985279083, loss=2.07521390914917
train: epoch 85, loss 0.6941850185394287, acc=0.6861666440963745, loss=0.6941850185394287
test: epoch 85, loss 1.9485559463500977, acc=0.3361110985279083, loss=1.9485559463500977
train: epoch 86, loss 0.6779147982597351, acc=0.6973333358764648, loss=0.6779147982597351
test: epoch 86, loss 2.1088011264801025, acc=0.3361110985279083, loss=2.1088011264801025
train: epoch 87, loss 0.6863908171653748, acc=0.6966666579246521, loss=0.6863908171653748
test: epoch 87, loss 2.0182909965515137, acc=0.33888888359069824, loss=2.0182909965515137
train: epoch 88, loss 0.6730799674987793, acc=0.6964444518089294, loss=0.6730799674987793
test: epoch 88, loss 1.959944248199463, acc=0.34166666865348816, loss=1.959944248199463
train: epoch 89, loss 0.6744871139526367, acc=0.6975555419921875, loss=0.6744871139526367
test: epoch 89, loss 1.907650113105774, acc=0.3333333432674408, loss=1.907650113105774
train: epoch 90, loss 0.6728442311286926, acc=0.6997222304344177, loss=0.6728442311286926
test: epoch 90, loss 2.141160726547241, acc=0.3305555582046509, loss=2.141160726547241
train: epoch 91, loss 0.6673259735107422, acc=0.6976110935211182, loss=0.6673259735107422
test: epoch 91, loss 2.1044929027557373, acc=0.32777777314186096, loss=2.1044929027557373
train: epoch 92, loss 0.660511314868927, acc=0.7012777924537659, loss=0.660511314868927
test: epoch 92, loss 2.0439341068267822, acc=0.3361110985279083, loss=2.0439341068267822
train: epoch 93, loss 0.6523878574371338, acc=0.7039999961853027, loss=0.6523878574371338
test: epoch 93, loss 1.9354265928268433, acc=0.3472222089767456, loss=1.9354265928268433
train: epoch 94, loss 0.6563928723335266, acc=0.7018888592720032, loss=0.6563928723335266
test: epoch 94, loss 2.0328919887542725, acc=0.33888888359069824, loss=2.0328919887542725
train: epoch 95, loss 0.6582591533660889, acc=0.70333331823349, loss=0.6582591533660889
test: epoch 95, loss 2.193556547164917, acc=0.33888888359069824, loss=2.193556547164917
train: epoch 96, loss 0.6488039493560791, acc=0.7048333287239075, loss=0.6488039493560791
test: epoch 96, loss 2.000037908554077, acc=0.33888888359069824, loss=2.000037908554077
train: epoch 97, loss 0.6459263563156128, acc=0.7075555324554443, loss=0.6459263563156128
test: epoch 97, loss 2.0678060054779053, acc=0.3499999940395355, loss=2.0678060054779053
train: epoch 98, loss 0.6402392387390137, acc=0.7090555429458618, loss=0.6402392387390137
test: epoch 98, loss 1.9221792221069336, acc=0.35277777910232544, loss=1.9221792221069336
train: epoch 99, loss 0.6485558152198792, acc=0.7030555605888367, loss=0.6485558152198792
test: epoch 99, loss 2.0390007495880127, acc=0.3361110985279083, loss=2.0390007495880127
train: epoch 100, loss 0.6367931962013245, acc=0.7136666774749756, loss=0.6367931962013245
test: epoch 100, loss 2.0227668285369873, acc=0.34166666865348816, loss=2.0227668285369873
train: epoch 101, loss 0.6434003710746765, acc=0.7046666741371155, loss=0.6434003710746765
test: epoch 101, loss 2.111809015274048, acc=0.3333333432674408, loss=2.111809015274048
train: epoch 102, loss 0.6277491450309753, acc=0.7123888731002808, loss=0.6277491450309753
test: epoch 102, loss 2.0397233963012695, acc=0.3499999940395355, loss=2.0397233963012695
train: epoch 103, loss 0.632419228553772, acc=0.7124444246292114, loss=0.632419228553772
test: epoch 103, loss 2.1178112030029297, acc=0.3472222089767456, loss=2.1178112030029297
train: epoch 104, loss 0.6385732889175415, acc=0.7084444165229797, loss=0.6385732889175415
test: epoch 104, loss 2.004211187362671, acc=0.35277777910232544, loss=2.004211187362671
train: epoch 105, loss 0.6317992806434631, acc=0.7146666646003723, loss=0.6317992806434631
test: epoch 105, loss 2.1609296798706055, acc=0.34166666865348816, loss=2.1609296798706055
train: epoch 106, loss 0.6195066571235657, acc=0.7190555334091187, loss=0.6195066571235657
test: epoch 106, loss 2.1168270111083984, acc=0.34166666865348816, loss=2.1168270111083984
train: epoch 107, loss 0.6186630129814148, acc=0.7223333120346069, loss=0.6186630129814148
test: epoch 107, loss 2.105776786804199, acc=0.3444444537162781, loss=2.105776786804199
train: epoch 108, loss 0.610998809337616, acc=0.7189444303512573, loss=0.610998809337616
test: epoch 108, loss 2.096930742263794, acc=0.35277777910232544, loss=2.096930742263794
train: epoch 109, loss 0.6102611422538757, acc=0.7191666960716248, loss=0.6102611422538757
test: epoch 109, loss 2.1506903171539307, acc=0.3499999940395355, loss=2.1506903171539307
train: epoch 110, loss 0.6137502193450928, acc=0.7196111083030701, loss=0.6137502193450928
test: epoch 110, loss 1.9965919256210327, acc=0.33888888359069824, loss=1.9965919256210327
train: epoch 111, loss 0.6133244037628174, acc=0.715666651725769, loss=0.6133244037628174
test: epoch 111, loss 1.9725396633148193, acc=0.3583333194255829, loss=1.9725396633148193
train: epoch 112, loss 0.6110820770263672, acc=0.7229999899864197, loss=0.6110820770263672
test: epoch 112, loss 2.0762336254119873, acc=0.3499999940395355, loss=2.0762336254119873
train: epoch 113, loss 0.6148167848587036, acc=0.7208889126777649, loss=0.6148167848587036
test: epoch 113, loss 1.9653825759887695, acc=0.35277777910232544, loss=1.9653825759887695
train: epoch 114, loss 0.6041534543037415, acc=0.7238888740539551, loss=0.6041534543037415
test: epoch 114, loss 2.1678504943847656, acc=0.3444444537162781, loss=2.1678504943847656
train: epoch 115, loss 0.6017529368400574, acc=0.7229999899864197, loss=0.6017529368400574
test: epoch 115, loss 2.1596362590789795, acc=0.3611111044883728, loss=2.1596362590789795
train: epoch 116, loss 0.6030176877975464, acc=0.718999981880188, loss=0.6030176877975464
test: epoch 116, loss 2.2207934856414795, acc=0.3499999940395355, loss=2.2207934856414795
train: epoch 117, loss 0.5969550609588623, acc=0.7222777605056763, loss=0.5969550609588623
test: epoch 117, loss 2.0045299530029297, acc=0.35555556416511536, loss=2.0045299530029297
train: epoch 118, loss 0.6037822365760803, acc=0.7211666703224182, loss=0.6037822365760803
test: epoch 118, loss 2.151658058166504, acc=0.3499999940395355, loss=2.151658058166504
train: epoch 119, loss 0.5990834832191467, acc=0.7215555310249329, loss=0.5990834832191467
test: epoch 119, loss 2.0529510974884033, acc=0.35277777910232544, loss=2.0529510974884033
train: epoch 120, loss 0.5971380472183228, acc=0.7231666445732117, loss=0.5971380472183228
test: epoch 120, loss 2.027677059173584, acc=0.35277777910232544, loss=2.027677059173584
train: epoch 121, loss 0.5995821356773376, acc=0.7247777581214905, loss=0.5995821356773376
test: epoch 121, loss 2.0885019302368164, acc=0.3472222089767456, loss=2.0885019302368164
train: epoch 122, loss 0.5940877795219421, acc=0.722000002861023, loss=0.5940877795219421
test: epoch 122, loss 2.0993075370788574, acc=0.3583333194255829, loss=2.0993075370788574
train: epoch 123, loss 0.5917457938194275, acc=0.7211666703224182, loss=0.5917457938194275
test: epoch 123, loss 2.013195514678955, acc=0.35555556416511536, loss=2.013195514678955
train: epoch 124, loss 0.5897538065910339, acc=0.7204999923706055, loss=0.5897538065910339
test: epoch 124, loss 2.0188541412353516, acc=0.3611111044883728, loss=2.0188541412353516
train: epoch 125, loss 0.5865668654441833, acc=0.7242777943611145, loss=0.5865668654441833
test: epoch 125, loss 2.1382193565368652, acc=0.35555556416511536, loss=2.1382193565368652
train: epoch 126, loss 0.5865336060523987, acc=0.7276666760444641, loss=0.5865336060523987
test: epoch 126, loss 2.00933837890625, acc=0.35277777910232544, loss=2.00933837890625
train: epoch 127, loss 0.5944206118583679, acc=0.7232778072357178, loss=0.5944206118583679
test: epoch 127, loss 1.9504808187484741, acc=0.3499999940395355, loss=1.9504808187484741
train: epoch 128, loss 0.6021363735198975, acc=0.7252777814865112, loss=0.6021363735198975
test: epoch 128, loss 2.1060805320739746, acc=0.35277777910232544, loss=2.1060805320739746
train: epoch 129, loss 0.5783801078796387, acc=0.7298333048820496, loss=0.5783801078796387
test: epoch 129, loss 2.0348026752471924, acc=0.35555556416511536, loss=2.0348026752471924
train: epoch 130, loss 0.5974593162536621, acc=0.7227222323417664, loss=0.5974593162536621
test: epoch 130, loss 2.0535471439361572, acc=0.35555556416511536, loss=2.0535471439361572
train: epoch 131, loss 0.5876473188400269, acc=0.7245000004768372, loss=0.5876473188400269
test: epoch 131, loss 1.9517709016799927, acc=0.36666667461395264, loss=1.9517709016799927
train: epoch 132, loss 0.5747425556182861, acc=0.7308889031410217, loss=0.5747425556182861
test: epoch 132, loss 2.143120765686035, acc=0.3611111044883728, loss=2.143120765686035
train: epoch 133, loss 0.5884681344032288, acc=0.7242777943611145, loss=0.5884681344032288
test: epoch 133, loss 2.0938901901245117, acc=0.3611111044883728, loss=2.0938901901245117
train: epoch 134, loss 0.6029739379882812, acc=0.7236111164093018, loss=0.6029739379882812
test: epoch 134, loss 2.1458704471588135, acc=0.35555556416511536, loss=2.1458704471588135
train: epoch 135, loss 0.5838260054588318, acc=0.7252222299575806, loss=0.5838260054588318
test: epoch 135, loss 2.243704319000244, acc=0.3638888895511627, loss=2.243704319000244
train: epoch 136, loss 0.5782519578933716, acc=0.7263333201408386, loss=0.5782519578933716
test: epoch 136, loss 2.091729164123535, acc=0.3499999940395355, loss=2.091729164123535
train: epoch 137, loss 0.5816515684127808, acc=0.7273889183998108, loss=0.5816515684127808
test: epoch 137, loss 2.1417899131774902, acc=0.3583333194255829, loss=2.1417899131774902
train: epoch 138, loss 0.5768256783485413, acc=0.7296110987663269, loss=0.5768256783485413
test: epoch 138, loss 2.15555739402771, acc=0.3583333194255829, loss=2.15555739402771
train: epoch 139, loss 0.5807276964187622, acc=0.7277777791023254, loss=0.5807276964187622
test: epoch 139, loss 2.065657377243042, acc=0.3638888895511627, loss=2.065657377243042
train: epoch 140, loss 0.5715649724006653, acc=0.7331110835075378, loss=0.5715649724006653
test: epoch 140, loss 2.1277713775634766, acc=0.36666667461395264, loss=2.1277713775634766
train: epoch 141, loss 0.5793130397796631, acc=0.7291111350059509, loss=0.5793130397796631
test: epoch 141, loss 2.1289913654327393, acc=0.3611111044883728, loss=2.1289913654327393
train: epoch 142, loss 0.5683236122131348, acc=0.7316111326217651, loss=0.5683236122131348
test: epoch 142, loss 2.059126377105713, acc=0.35277777910232544, loss=2.059126377105713
train: epoch 143, loss 0.5820176005363464, acc=0.7241666913032532, loss=0.5820176005363464
test: epoch 143, loss 2.194049119949341, acc=0.35277777910232544, loss=2.194049119949341
train: epoch 144, loss 0.5742684006690979, acc=0.7276666760444641, loss=0.5742684006690979
test: epoch 144, loss 2.3193302154541016, acc=0.3583333194255829, loss=2.3193302154541016
train: epoch 145, loss 0.5803714990615845, acc=0.7239444255828857, loss=0.5803714990615845
test: epoch 145, loss 2.2306203842163086, acc=0.35555556416511536, loss=2.2306203842163086
train: epoch 146, loss 0.5700897574424744, acc=0.7297222018241882, loss=0.5700897574424744
test: epoch 146, loss 2.006122350692749, acc=0.35555556416511536, loss=2.006122350692749
train: epoch 147, loss 0.5719667673110962, acc=0.7294444441795349, loss=0.5719667673110962
test: epoch 147, loss 2.2879772186279297, acc=0.3638888895511627, loss=2.2879772186279297
train: epoch 148, loss 0.5715509057044983, acc=0.730388879776001, loss=0.5715509057044983
test: epoch 148, loss 2.178450107574463, acc=0.36666667461395264, loss=2.178450107574463
train: epoch 149, loss 0.5735592246055603, acc=0.7331666946411133, loss=0.5735592246055603
test: epoch 149, loss 2.0709338188171387, acc=0.36666667461395264, loss=2.0709338188171387
train: epoch 150, loss 0.571559488773346, acc=0.7282222509384155, loss=0.571559488773346
test: epoch 150, loss 2.088367462158203, acc=0.36666667461395264, loss=2.088367462158203
