# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=1", "--temp_decay=1", "--one_hot=1", "--n_layers=1"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=410104085, receiver_embed_dim=32, save_run=0, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=410104085, receiver_embed_dim=32, save_run=False, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.6063976287841797, acc=0.04205555468797684, loss=3.6063976287841797
test: epoch 1, loss 3.52300763130188, acc=0.0555555559694767, loss=3.52300763130188
train: epoch 2, loss 3.5074164867401123, acc=0.0490555539727211, loss=3.5074164867401123
test: epoch 2, loss 3.4011242389678955, acc=0.06666667014360428, loss=3.4011242389678955
train: epoch 3, loss 3.4814882278442383, acc=0.052666667848825455, loss=3.4814882278442383
test: epoch 3, loss 3.272089958190918, acc=0.05833333358168602, loss=3.272089958190918
train: epoch 4, loss 3.437772274017334, acc=0.04983333498239517, loss=3.437772274017334
test: epoch 4, loss 3.0969057083129883, acc=0.09166666865348816, loss=3.0969057083129883
train: epoch 5, loss 3.3105316162109375, acc=0.06177777796983719, loss=3.3105316162109375
test: epoch 5, loss 3.715669870376587, acc=0.04444444552063942, loss=3.715669870376587
train: epoch 6, loss 3.0958545207977295, acc=0.08566666394472122, loss=3.0958545207977295
test: epoch 6, loss 3.9906318187713623, acc=0.0416666679084301, loss=3.9906318187713623
train: epoch 7, loss 2.9390647411346436, acc=0.10111111402511597, loss=2.9390647411346436
test: epoch 7, loss 3.915926456451416, acc=0.05277777835726738, loss=3.915926456451416
train: epoch 8, loss 2.8258066177368164, acc=0.11355555802583694, loss=2.8258066177368164
test: epoch 8, loss 3.955411434173584, acc=0.03888889029622078, loss=3.955411434173584
train: epoch 9, loss 2.7626070976257324, acc=0.11905555427074432, loss=2.7626070976257324
test: epoch 9, loss 3.847416877746582, acc=0.03611111268401146, loss=3.847416877746582
train: epoch 10, loss 2.7026517391204834, acc=0.12861111760139465, loss=2.7026517391204834
test: epoch 10, loss 3.8231112957000732, acc=0.0416666679084301, loss=3.8231112957000732
train: epoch 11, loss 2.657984733581543, acc=0.13633333146572113, loss=2.657984733581543
test: epoch 11, loss 3.8160367012023926, acc=0.03888889029622078, loss=3.8160367012023926
train: epoch 12, loss 2.600156307220459, acc=0.14038889110088348, loss=2.600156307220459
test: epoch 12, loss 3.8534305095672607, acc=0.0416666679084301, loss=3.8534305095672607
train: epoch 13, loss 2.577723503112793, acc=0.14561110734939575, loss=2.577723503112793
test: epoch 13, loss 3.7487339973449707, acc=0.0416666679084301, loss=3.7487339973449707
train: epoch 14, loss 2.5526671409606934, acc=0.15216666460037231, loss=2.5526671409606934
test: epoch 14, loss 3.7752368450164795, acc=0.03888889029622078, loss=3.7752368450164795
train: epoch 15, loss 2.5238444805145264, acc=0.15688888728618622, loss=2.5238444805145264
test: epoch 15, loss 3.7934014797210693, acc=0.0416666679084301, loss=3.7934014797210693
train: epoch 16, loss 2.508831739425659, acc=0.15627777576446533, loss=2.508831739425659
test: epoch 16, loss 3.7544286251068115, acc=0.04444444552063942, loss=3.7544286251068115
train: epoch 17, loss 2.481506824493408, acc=0.16633333265781403, loss=2.481506824493408
test: epoch 17, loss 3.7455458641052246, acc=0.04722222313284874, loss=3.7455458641052246
train: epoch 18, loss 2.4598968029022217, acc=0.16705556213855743, loss=2.4598968029022217
test: epoch 18, loss 3.7027792930603027, acc=0.05000000074505806, loss=3.7027792930603027
train: epoch 19, loss 2.4516212940216064, acc=0.1696111112833023, loss=2.4516212940216064
test: epoch 19, loss 3.7555203437805176, acc=0.05000000074505806, loss=3.7555203437805176
train: epoch 20, loss 2.4248743057250977, acc=0.17116667330265045, loss=2.4248743057250977
test: epoch 20, loss 3.7426717281341553, acc=0.05833333358168602, loss=3.7426717281341553
train: epoch 21, loss 2.418687343597412, acc=0.17822222411632538, loss=2.418687343597412
test: epoch 21, loss 3.6947591304779053, acc=0.05833333358168602, loss=3.6947591304779053
train: epoch 22, loss 2.3916566371917725, acc=0.17738889157772064, loss=2.3916566371917725
test: epoch 22, loss 3.746617078781128, acc=0.06388889253139496, loss=3.746617078781128
train: epoch 23, loss 2.3814172744750977, acc=0.18461111187934875, loss=2.3814172744750977
test: epoch 23, loss 3.7214698791503906, acc=0.06111111119389534, loss=3.7214698791503906
train: epoch 24, loss 2.3642659187316895, acc=0.189277783036232, loss=2.3642659187316895
test: epoch 24, loss 3.727632999420166, acc=0.05833333358168602, loss=3.727632999420166
train: epoch 25, loss 2.347561836242676, acc=0.19066666066646576, loss=2.347561836242676
test: epoch 25, loss 3.801588296890259, acc=0.05833333358168602, loss=3.801588296890259
train: epoch 26, loss 2.346475601196289, acc=0.19027778506278992, loss=2.346475601196289
test: epoch 26, loss 3.7306249141693115, acc=0.06666667014360428, loss=3.7306249141693115
train: epoch 27, loss 2.3274433612823486, acc=0.19550000131130219, loss=2.3274433612823486
test: epoch 27, loss 3.7262866497039795, acc=0.0694444477558136, loss=3.7262866497039795
train: epoch 28, loss 2.3080081939697266, acc=0.20116665959358215, loss=2.3080081939697266
test: epoch 28, loss 3.7954490184783936, acc=0.0694444477558136, loss=3.7954490184783936
train: epoch 29, loss 2.2835466861724854, acc=0.2029999941587448, loss=2.2835466861724854
test: epoch 29, loss 3.8270421028137207, acc=0.07500000298023224, loss=3.8270421028137207
train: epoch 30, loss 2.2738192081451416, acc=0.2061111181974411, loss=2.2738192081451416
test: epoch 30, loss 3.864318370819092, acc=0.07222222536802292, loss=3.864318370819092
train: epoch 31, loss 2.2757081985473633, acc=0.20561110973358154, loss=2.2757081985473633
test: epoch 31, loss 3.806446075439453, acc=0.07222222536802292, loss=3.806446075439453
train: epoch 32, loss 2.256682872772217, acc=0.21416667103767395, loss=2.256682872772217
test: epoch 32, loss 3.830245018005371, acc=0.07500000298023224, loss=3.830245018005371
train: epoch 33, loss 2.235325336456299, acc=0.21205554902553558, loss=2.235325336456299
test: epoch 33, loss 3.8256545066833496, acc=0.08055555820465088, loss=3.8256545066833496
train: epoch 34, loss 2.2318315505981445, acc=0.21522222459316254, loss=2.2318315505981445
test: epoch 34, loss 3.841170310974121, acc=0.07222222536802292, loss=3.841170310974121
train: epoch 35, loss 2.218005418777466, acc=0.22183333337306976, loss=2.218005418777466
test: epoch 35, loss 3.8150477409362793, acc=0.08611111342906952, loss=3.8150477409362793
train: epoch 36, loss 2.204362154006958, acc=0.22616666555404663, loss=2.204362154006958
test: epoch 36, loss 3.8121285438537598, acc=0.08888889104127884, loss=3.8121285438537598
train: epoch 37, loss 2.18640398979187, acc=0.22716666758060455, loss=2.18640398979187
test: epoch 37, loss 3.731566905975342, acc=0.08888889104127884, loss=3.731566905975342
train: epoch 38, loss 2.171538829803467, acc=0.23555555939674377, loss=2.171538829803467
test: epoch 38, loss 3.7109286785125732, acc=0.09166666865348816, loss=3.7109286785125732
train: epoch 39, loss 2.1528446674346924, acc=0.24027778208255768, loss=2.1528446674346924
test: epoch 39, loss 3.541757345199585, acc=0.09166666865348816, loss=3.541757345199585
train: epoch 40, loss 2.1403884887695312, acc=0.24111111462116241, loss=2.1403884887695312
test: epoch 40, loss 3.5449378490448, acc=0.0972222238779068, loss=3.5449378490448
train: epoch 41, loss 2.118807554244995, acc=0.2506110966205597, loss=2.118807554244995
test: epoch 41, loss 3.5226123332977295, acc=0.10000000149011612, loss=3.5226123332977295
train: epoch 42, loss 2.106156349182129, acc=0.2464444488286972, loss=2.106156349182129
test: epoch 42, loss 3.555802583694458, acc=0.10000000149011612, loss=3.555802583694458
train: epoch 43, loss 2.104691982269287, acc=0.24977777898311615, loss=2.104691982269287
test: epoch 43, loss 3.5880656242370605, acc=0.10555555671453476, loss=3.5880656242370605
train: epoch 44, loss 2.093820810317993, acc=0.25172221660614014, loss=2.093820810317993
test: epoch 44, loss 3.521197557449341, acc=0.10833333432674408, loss=3.521197557449341
train: epoch 45, loss 2.054814577102661, acc=0.26472222805023193, loss=2.054814577102661
test: epoch 45, loss 3.4461441040039062, acc=0.1111111119389534, loss=3.4461441040039062
train: epoch 46, loss 2.0453760623931885, acc=0.2626666724681854, loss=2.0453760623931885
test: epoch 46, loss 3.2502429485321045, acc=0.1111111119389534, loss=3.2502429485321045
train: epoch 47, loss 2.0461227893829346, acc=0.2644444406032562, loss=2.0461227893829346
test: epoch 47, loss 3.1983697414398193, acc=0.11666666716337204, loss=3.1983697414398193
train: epoch 48, loss 2.023071050643921, acc=0.27238887548446655, loss=2.023071050643921
test: epoch 48, loss 2.9731926918029785, acc=0.12777778506278992, loss=2.9731926918029785
train: epoch 49, loss 1.9902303218841553, acc=0.27522221207618713, loss=1.9902303218841553
test: epoch 49, loss 2.91168212890625, acc=0.13611111044883728, loss=2.91168212890625
train: epoch 50, loss 1.9874950647354126, acc=0.28022223711013794, loss=1.9874950647354126
test: epoch 50, loss 2.8149421215057373, acc=0.13611111044883728, loss=2.8149421215057373
train: epoch 51, loss 1.9798120260238647, acc=0.28255555033683777, loss=1.9798120260238647
test: epoch 51, loss 2.7849173545837402, acc=0.13333334028720856, loss=2.7849173545837402
train: epoch 52, loss 1.965898871421814, acc=0.2904999852180481, loss=1.965898871421814
test: epoch 52, loss 2.6793699264526367, acc=0.15000000596046448, loss=2.6793699264526367
train: epoch 53, loss 1.9388927221298218, acc=0.2949444353580475, loss=1.9388927221298218
test: epoch 53, loss 2.647169828414917, acc=0.14722222089767456, loss=2.647169828414917
train: epoch 54, loss 1.9388842582702637, acc=0.2983333468437195, loss=1.9388842582702637
test: epoch 54, loss 2.638336658477783, acc=0.14444445073604584, loss=2.638336658477783
train: epoch 55, loss 1.9219774007797241, acc=0.29750001430511475, loss=1.9219774007797241
test: epoch 55, loss 2.614008665084839, acc=0.1527777761220932, loss=2.614008665084839
train: epoch 56, loss 1.890724778175354, acc=0.30533334612846375, loss=1.890724778175354
test: epoch 56, loss 2.6027045249938965, acc=0.15555556118488312, loss=2.6027045249938965
train: epoch 57, loss 1.8854998350143433, acc=0.31022220849990845, loss=1.8854998350143433
test: epoch 57, loss 2.568934917449951, acc=0.15555556118488312, loss=2.568934917449951
train: epoch 58, loss 1.8668053150177002, acc=0.3148888945579529, loss=1.8668053150177002
test: epoch 58, loss 2.519742250442505, acc=0.16944444179534912, loss=2.519742250442505
train: epoch 59, loss 1.8407937288284302, acc=0.32466667890548706, loss=1.8407937288284302
test: epoch 59, loss 2.5146102905273438, acc=0.16111111640930176, loss=2.5146102905273438
train: epoch 60, loss 1.8262544870376587, acc=0.32733333110809326, loss=1.8262544870376587
test: epoch 60, loss 2.461817502975464, acc=0.17499999701976776, loss=2.461817502975464
train: epoch 61, loss 1.8071969747543335, acc=0.3343888819217682, loss=1.8071969747543335
test: epoch 61, loss 2.4370779991149902, acc=0.17499999701976776, loss=2.4370779991149902
train: epoch 62, loss 1.8100208044052124, acc=0.3327222168445587, loss=1.8100208044052124
test: epoch 62, loss 2.3914546966552734, acc=0.17777778208255768, loss=2.3914546966552734
train: epoch 63, loss 1.7756800651550293, acc=0.3443889021873474, loss=1.7756800651550293
test: epoch 63, loss 2.387751340866089, acc=0.18611110746860504, loss=2.387751340866089
train: epoch 64, loss 1.7715699672698975, acc=0.34922221302986145, loss=1.7715699672698975
test: epoch 64, loss 2.3598759174346924, acc=0.18611110746860504, loss=2.3598759174346924
train: epoch 65, loss 1.74988853931427, acc=0.3544444441795349, loss=1.74988853931427
test: epoch 65, loss 2.3038463592529297, acc=0.18611110746860504, loss=2.3038463592529297
train: epoch 66, loss 1.742923378944397, acc=0.35483333468437195, loss=1.742923378944397
test: epoch 66, loss 2.296884298324585, acc=0.18611110746860504, loss=2.296884298324585
train: epoch 67, loss 1.7185890674591064, acc=0.3623333275318146, loss=1.7185890674591064
test: epoch 67, loss 2.2996089458465576, acc=0.19166666269302368, loss=2.2996089458465576
train: epoch 68, loss 1.6942973136901855, acc=0.3651111125946045, loss=1.6942973136901855
test: epoch 68, loss 2.299574136734009, acc=0.1944444477558136, loss=2.299574136734009
train: epoch 69, loss 1.6946783065795898, acc=0.3713333308696747, loss=1.6946783065795898
test: epoch 69, loss 2.1866791248321533, acc=0.1944444477558136, loss=2.1866791248321533
train: epoch 70, loss 1.6761384010314941, acc=0.3798888921737671, loss=1.6761384010314941
test: epoch 70, loss 2.2193214893341064, acc=0.19166666269302368, loss=2.2193214893341064
train: epoch 71, loss 1.659169316291809, acc=0.3829444348812103, loss=1.659169316291809
test: epoch 71, loss 2.197470188140869, acc=0.20000000298023224, loss=2.197470188140869
train: epoch 72, loss 1.660597324371338, acc=0.38822221755981445, loss=1.660597324371338
test: epoch 72, loss 2.1268694400787354, acc=0.2083333283662796, loss=2.1268694400787354
train: epoch 73, loss 1.626055359840393, acc=0.3885555565357208, loss=1.626055359840393
test: epoch 73, loss 2.0871241092681885, acc=0.21666666865348816, loss=2.0871241092681885
train: epoch 74, loss 1.5906208753585815, acc=0.3998333215713501, loss=1.5906208753585815
test: epoch 74, loss 2.0817573070526123, acc=0.21388888359069824, loss=2.0817573070526123
train: epoch 75, loss 1.5960009098052979, acc=0.4041111171245575, loss=1.5960009098052979
test: epoch 75, loss 2.038719654083252, acc=0.22499999403953552, loss=2.038719654083252
train: epoch 76, loss 1.6011147499084473, acc=0.4050000011920929, loss=1.6011147499084473
test: epoch 76, loss 2.05712890625, acc=0.21944443881511688, loss=2.05712890625
train: epoch 77, loss 1.5723867416381836, acc=0.4122222363948822, loss=1.5723867416381836
test: epoch 77, loss 2.0177485942840576, acc=0.2222222238779068, loss=2.0177485942840576
train: epoch 78, loss 1.5572150945663452, acc=0.41455554962158203, loss=1.5572150945663452
test: epoch 78, loss 1.993322491645813, acc=0.22777777910232544, loss=1.993322491645813
train: epoch 79, loss 1.5531578063964844, acc=0.4161111116409302, loss=1.5531578063964844
test: epoch 79, loss 1.9837497472763062, acc=0.22777777910232544, loss=1.9837497472763062
train: epoch 80, loss 1.544384479522705, acc=0.4267222285270691, loss=1.544384479522705
test: epoch 80, loss 1.9702483415603638, acc=0.2222222238779068, loss=1.9702483415603638
train: epoch 81, loss 1.5203022956848145, acc=0.4348333477973938, loss=1.5203022956848145
test: epoch 81, loss 1.9744948148727417, acc=0.22777777910232544, loss=1.9744948148727417
train: epoch 82, loss 1.5098706483840942, acc=0.4317777752876282, loss=1.5098706483840942
test: epoch 82, loss 1.939283847808838, acc=0.22777777910232544, loss=1.939283847808838
train: epoch 83, loss 1.492848515510559, acc=0.44172221422195435, loss=1.492848515510559
test: epoch 83, loss 1.9324424266815186, acc=0.23333333432674408, loss=1.9324424266815186
train: epoch 84, loss 1.499699592590332, acc=0.4422222077846527, loss=1.499699592590332
test: epoch 84, loss 1.9381121397018433, acc=0.23333333432674408, loss=1.9381121397018433
train: epoch 85, loss 1.4763379096984863, acc=0.45366665720939636, loss=1.4763379096984863
test: epoch 85, loss 1.9168270826339722, acc=0.23055554926395416, loss=1.9168270826339722
train: epoch 86, loss 1.4512361288070679, acc=0.45572221279144287, loss=1.4512361288070679
test: epoch 86, loss 1.8957182168960571, acc=0.23888888955116272, loss=1.8957182168960571
train: epoch 87, loss 1.4578883647918701, acc=0.4566666781902313, loss=1.4578883647918701
test: epoch 87, loss 1.9068806171417236, acc=0.24444444477558136, loss=1.9068806171417236
train: epoch 88, loss 1.4475765228271484, acc=0.46416667103767395, loss=1.4475765228271484
test: epoch 88, loss 1.8909502029418945, acc=0.24722221493721008, loss=1.8909502029418945
train: epoch 89, loss 1.4355709552764893, acc=0.46711111068725586, loss=1.4355709552764893
test: epoch 89, loss 1.8816664218902588, acc=0.24166665971279144, loss=1.8816664218902588
train: epoch 90, loss 1.4288722276687622, acc=0.472777783870697, loss=1.4288722276687622
test: epoch 90, loss 1.9164966344833374, acc=0.23888888955116272, loss=1.9164966344833374
train: epoch 91, loss 1.4088294506072998, acc=0.4652777910232544, loss=1.4088294506072998
test: epoch 91, loss 1.9120917320251465, acc=0.24722221493721008, loss=1.9120917320251465
train: epoch 92, loss 1.4018667936325073, acc=0.47866666316986084, loss=1.4018667936325073
test: epoch 92, loss 1.8738638162612915, acc=0.2527777850627899, loss=1.8738638162612915
train: epoch 93, loss 1.3741164207458496, acc=0.4863888919353485, loss=1.3741164207458496
test: epoch 93, loss 1.8719850778579712, acc=0.24444444477558136, loss=1.8719850778579712
train: epoch 94, loss 1.3655799627304077, acc=0.4886666536331177, loss=1.3655799627304077
test: epoch 94, loss 1.8658288717269897, acc=0.25, loss=1.8658288717269897
train: epoch 95, loss 1.3860138654708862, acc=0.4868333339691162, loss=1.3860138654708862
test: epoch 95, loss 1.867863655090332, acc=0.25, loss=1.867863655090332
train: epoch 96, loss 1.3690757751464844, acc=0.49272221326828003, loss=1.3690757751464844
test: epoch 96, loss 1.8325682878494263, acc=0.2638888955116272, loss=1.8325682878494263
train: epoch 97, loss 1.3418426513671875, acc=0.503777801990509, loss=1.3418426513671875
test: epoch 97, loss 1.8062585592269897, acc=0.26944443583488464, loss=1.8062585592269897
train: epoch 98, loss 1.3340752124786377, acc=0.5042222142219543, loss=1.3340752124786377
test: epoch 98, loss 1.790248990058899, acc=0.26944443583488464, loss=1.790248990058899
train: epoch 99, loss 1.3250311613082886, acc=0.5114444494247437, loss=1.3250311613082886
test: epoch 99, loss 1.8010294437408447, acc=0.27222222089767456, loss=1.8010294437408447
train: epoch 100, loss 1.3225101232528687, acc=0.5138888955116272, loss=1.3225101232528687
test: epoch 100, loss 1.8041589260101318, acc=0.27222222089767456, loss=1.8041589260101318
train: epoch 101, loss 1.30555260181427, acc=0.5157222151756287, loss=1.30555260181427
test: epoch 101, loss 1.7935367822647095, acc=0.27222222089767456, loss=1.7935367822647095
train: epoch 102, loss 1.3015413284301758, acc=0.5230555534362793, loss=1.3015413284301758
test: epoch 102, loss 1.776252269744873, acc=0.2777777910232544, loss=1.776252269744873
train: epoch 103, loss 1.2833669185638428, acc=0.5223888754844666, loss=1.2833669185638428
test: epoch 103, loss 1.7900665998458862, acc=0.2916666567325592, loss=1.7900665998458862
train: epoch 104, loss 1.2867531776428223, acc=0.5277222394943237, loss=1.2867531776428223
test: epoch 104, loss 1.7475718259811401, acc=0.2750000059604645, loss=1.7475718259811401
train: epoch 105, loss 1.2580498456954956, acc=0.5333333611488342, loss=1.2580498456954956
test: epoch 105, loss 1.7693424224853516, acc=0.2750000059604645, loss=1.7693424224853516
train: epoch 106, loss 1.2543926239013672, acc=0.5347222089767456, loss=1.2543926239013672
test: epoch 106, loss 1.7460931539535522, acc=0.28611111640930176, loss=1.7460931539535522
train: epoch 107, loss 1.2533738613128662, acc=0.5433333516120911, loss=1.2533738613128662
test: epoch 107, loss 1.7384872436523438, acc=0.2944444417953491, loss=1.7384872436523438
train: epoch 108, loss 1.250456690788269, acc=0.5403333306312561, loss=1.250456690788269
test: epoch 108, loss 1.7407748699188232, acc=0.2916666567325592, loss=1.7407748699188232
train: epoch 109, loss 1.2344166040420532, acc=0.5423333048820496, loss=1.2344166040420532
test: epoch 109, loss 1.7244642972946167, acc=0.29722222685813904, loss=1.7244642972946167
train: epoch 110, loss 1.228063702583313, acc=0.5518333315849304, loss=1.228063702583313
test: epoch 110, loss 1.7260149717330933, acc=0.29722222685813904, loss=1.7260149717330933
train: epoch 111, loss 1.2101686000823975, acc=0.5598888993263245, loss=1.2101686000823975
test: epoch 111, loss 1.7108726501464844, acc=0.2916666567325592, loss=1.7108726501464844
train: epoch 112, loss 1.213627576828003, acc=0.5611110925674438, loss=1.213627576828003
test: epoch 112, loss 1.7068970203399658, acc=0.29722222685813904, loss=1.7068970203399658
train: epoch 113, loss 1.1869550943374634, acc=0.5646111369132996, loss=1.1869550943374634
test: epoch 113, loss 1.7001506090164185, acc=0.3083333373069763, loss=1.7001506090164185
train: epoch 114, loss 1.1879438161849976, acc=0.5741111040115356, loss=1.1879438161849976
test: epoch 114, loss 1.698549747467041, acc=0.2916666567325592, loss=1.698549747467041
train: epoch 115, loss 1.1870383024215698, acc=0.5687222480773926, loss=1.1870383024215698
test: epoch 115, loss 1.6774733066558838, acc=0.29722222685813904, loss=1.6774733066558838
train: epoch 116, loss 1.1676933765411377, acc=0.5792222023010254, loss=1.1676933765411377
test: epoch 116, loss 1.6879785060882568, acc=0.3083333373069763, loss=1.6879785060882568
train: epoch 117, loss 1.1594072580337524, acc=0.5803333520889282, loss=1.1594072580337524
test: epoch 117, loss 1.6765981912612915, acc=0.2944444417953491, loss=1.6765981912612915
train: epoch 118, loss 1.145838975906372, acc=0.5836666822433472, loss=1.145838975906372
test: epoch 118, loss 1.6792185306549072, acc=0.29722222685813904, loss=1.6792185306549072
train: epoch 119, loss 1.1393604278564453, acc=0.5835000276565552, loss=1.1393604278564453
test: epoch 119, loss 1.6577223539352417, acc=0.3083333373069763, loss=1.6577223539352417
train: epoch 120, loss 1.1180487871170044, acc=0.5893333554267883, loss=1.1180487871170044
test: epoch 120, loss 1.6535980701446533, acc=0.3083333373069763, loss=1.6535980701446533
train: epoch 121, loss 1.1227736473083496, acc=0.5984444618225098, loss=1.1227736473083496
test: epoch 121, loss 1.6726583242416382, acc=0.3083333373069763, loss=1.6726583242416382
train: epoch 122, loss 1.1195991039276123, acc=0.598111093044281, loss=1.1195991039276123
test: epoch 122, loss 1.646661639213562, acc=0.3194444477558136, loss=1.646661639213562
train: epoch 123, loss 1.112282395362854, acc=0.6040555834770203, loss=1.112282395362854
test: epoch 123, loss 1.638393521308899, acc=0.3194444477558136, loss=1.638393521308899
train: epoch 124, loss 1.0928199291229248, acc=0.6076111197471619, loss=1.0928199291229248
test: epoch 124, loss 1.6175358295440674, acc=0.3166666626930237, loss=1.6175358295440674
train: epoch 125, loss 1.1028740406036377, acc=0.6033333539962769, loss=1.1028740406036377
test: epoch 125, loss 1.6540377140045166, acc=0.3166666626930237, loss=1.6540377140045166
train: epoch 126, loss 1.095968246459961, acc=0.6124444603919983, loss=1.095968246459961
test: epoch 126, loss 1.655828595161438, acc=0.31388887763023376, loss=1.655828595161438
train: epoch 127, loss 1.0738433599472046, acc=0.6126111149787903, loss=1.0738433599472046
test: epoch 127, loss 1.6420649290084839, acc=0.3194444477558136, loss=1.6420649290084839
train: epoch 128, loss 1.0716962814331055, acc=0.613611102104187, loss=1.0716962814331055
test: epoch 128, loss 1.6267796754837036, acc=0.3305555582046509, loss=1.6267796754837036
train: epoch 129, loss 1.0542188882827759, acc=0.6240000128746033, loss=1.0542188882827759
test: epoch 129, loss 1.6060367822647095, acc=0.3333333432674408, loss=1.6060367822647095
train: epoch 130, loss 1.048673391342163, acc=0.6233333349227905, loss=1.048673391342163
test: epoch 130, loss 1.5896207094192505, acc=0.3305555582046509, loss=1.5896207094192505
train: epoch 131, loss 1.0467596054077148, acc=0.6227222084999084, loss=1.0467596054077148
test: epoch 131, loss 1.6011366844177246, acc=0.3305555582046509, loss=1.6011366844177246
train: epoch 132, loss 1.0264793634414673, acc=0.633055567741394, loss=1.0264793634414673
test: epoch 132, loss 1.5788413286209106, acc=0.3361110985279083, loss=1.5788413286209106
train: epoch 133, loss 1.0204331874847412, acc=0.6366111040115356, loss=1.0204331874847412
test: epoch 133, loss 1.5540598630905151, acc=0.3333333432674408, loss=1.5540598630905151
train: epoch 134, loss 1.0214836597442627, acc=0.6388888955116272, loss=1.0214836597442627
test: epoch 134, loss 1.5734785795211792, acc=0.3333333432674408, loss=1.5734785795211792
train: epoch 135, loss 1.011685848236084, acc=0.6426666378974915, loss=1.011685848236084
test: epoch 135, loss 1.5553257465362549, acc=0.3444444537162781, loss=1.5553257465362549
train: epoch 136, loss 1.0143455266952515, acc=0.6471111178398132, loss=1.0143455266952515
test: epoch 136, loss 1.5415443181991577, acc=0.3444444537162781, loss=1.5415443181991577
train: epoch 137, loss 0.9962299466133118, acc=0.6514999866485596, loss=0.9962299466133118
test: epoch 137, loss 1.5405995845794678, acc=0.33888888359069824, loss=1.5405995845794678
train: epoch 138, loss 0.9943908452987671, acc=0.6512222290039062, loss=0.9943908452987671
test: epoch 138, loss 1.5401004552841187, acc=0.34166666865348816, loss=1.5401004552841187
train: epoch 139, loss 0.995710551738739, acc=0.6559444665908813, loss=0.995710551738739
test: epoch 139, loss 1.5299171209335327, acc=0.34166666865348816, loss=1.5299171209335327
train: epoch 140, loss 0.986011803150177, acc=0.6544444561004639, loss=0.986011803150177
test: epoch 140, loss 1.5469715595245361, acc=0.34166666865348816, loss=1.5469715595245361
train: epoch 141, loss 0.969819188117981, acc=0.6657778024673462, loss=0.969819188117981
test: epoch 141, loss 1.5163336992263794, acc=0.33888888359069824, loss=1.5163336992263794
train: epoch 142, loss 0.981860876083374, acc=0.6624444723129272, loss=0.981860876083374
test: epoch 142, loss 1.487837791442871, acc=0.3444444537162781, loss=1.487837791442871
train: epoch 143, loss 0.951287567615509, acc=0.6679444313049316, loss=0.951287567615509
test: epoch 143, loss 1.4917458295822144, acc=0.3499999940395355, loss=1.4917458295822144
train: epoch 144, loss 0.9507361650466919, acc=0.6705555319786072, loss=0.9507361650466919
test: epoch 144, loss 1.4753116369247437, acc=0.35277777910232544, loss=1.4753116369247437
train: epoch 145, loss 0.9398357272148132, acc=0.6737222075462341, loss=0.9398357272148132
test: epoch 145, loss 1.5006210803985596, acc=0.3499999940395355, loss=1.5006210803985596
train: epoch 146, loss 0.9510158896446228, acc=0.6713333129882812, loss=0.9510158896446228
test: epoch 146, loss 1.5083529949188232, acc=0.3499999940395355, loss=1.5083529949188232
train: epoch 147, loss 0.9304545521736145, acc=0.6747778058052063, loss=0.9304545521736145
test: epoch 147, loss 1.4882862567901611, acc=0.35277777910232544, loss=1.4882862567901611
train: epoch 148, loss 0.9401636719703674, acc=0.679444432258606, loss=0.9401636719703674
test: epoch 148, loss 1.4971504211425781, acc=0.3583333194255829, loss=1.4971504211425781
train: epoch 149, loss 0.9267229437828064, acc=0.6808333396911621, loss=0.9267229437828064
test: epoch 149, loss 1.501537561416626, acc=0.35277777910232544, loss=1.501537561416626
train: epoch 150, loss 0.9185959100723267, acc=0.6811666488647461, loss=0.9185959100723267
test: epoch 150, loss 1.5002743005752563, acc=0.35277777910232544, loss=1.5002743005752563
