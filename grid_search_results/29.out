# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=false", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=549445416, receiver_embed_dim=32, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.9828124046325684, acc=0.07616666704416275, loss=2.9828124046325684
test: epoch 1, loss 3.020063638687134, acc=0.11944444477558136, loss=3.020063638687134
train: epoch 2, loss 2.0008468627929688, acc=0.20483332872390747, loss=2.0008468627929688
test: epoch 2, loss 2.8869946002960205, acc=0.16944444179534912, loss=2.8869946002960205
train: epoch 3, loss 1.6903902292251587, acc=0.285277783870697, loss=1.6903902292251587
test: epoch 3, loss 2.708090305328369, acc=0.1944444477558136, loss=2.708090305328369
train: epoch 4, loss 1.5054978132247925, acc=0.33677777647972107, loss=1.5054978132247925
test: epoch 4, loss 2.505270004272461, acc=0.1805555522441864, loss=2.505270004272461
train: epoch 5, loss 1.3504070043563843, acc=0.39055556058883667, loss=1.3504070043563843
test: epoch 5, loss 2.9712491035461426, acc=0.16111111640930176, loss=2.9712491035461426
train: epoch 6, loss 1.2803646326065063, acc=0.4200555682182312, loss=1.2803646326065063
test: epoch 6, loss 2.5044479370117188, acc=0.28333333134651184, loss=2.5044479370117188
train: epoch 7, loss 1.2063096761703491, acc=0.4589444398880005, loss=1.2063096761703491
test: epoch 7, loss 2.1401093006134033, acc=0.26944443583488464, loss=2.1401093006134033
train: epoch 8, loss 1.146867036819458, acc=0.4929444491863251, loss=1.146867036819458
test: epoch 8, loss 2.061061143875122, acc=0.2777777910232544, loss=2.061061143875122
train: epoch 9, loss 1.0453054904937744, acc=0.5445555448532104, loss=1.0453054904937744
test: epoch 9, loss 1.846331000328064, acc=0.29722222685813904, loss=1.846331000328064
train: epoch 10, loss 0.9816068410873413, acc=0.5708333253860474, loss=0.9816068410873413
test: epoch 10, loss 1.8421950340270996, acc=0.3166666626930237, loss=1.8421950340270996
train: epoch 11, loss 0.9039417505264282, acc=0.602055549621582, loss=0.9039417505264282
test: epoch 11, loss 1.7844493389129639, acc=0.3611111044883728, loss=1.7844493389129639
train: epoch 12, loss 0.8168768882751465, acc=0.6446666717529297, loss=0.8168768882751465
test: epoch 12, loss 1.4886868000030518, acc=0.39722222089767456, loss=1.4886868000030518
train: epoch 13, loss 0.7366109490394592, acc=0.6771110892295837, loss=0.7366109490394592
test: epoch 13, loss 1.5328125953674316, acc=0.43888887763023376, loss=1.5328125953674316
train: epoch 14, loss 0.6890037059783936, acc=0.7035555839538574, loss=0.6890037059783936
test: epoch 14, loss 1.3531570434570312, acc=0.4972222149372101, loss=1.3531570434570312
train: epoch 15, loss 0.5459191203117371, acc=0.7709444165229797, loss=0.5459191203117371
test: epoch 15, loss 1.1051274538040161, acc=0.5222222208976746, loss=1.1051274538040161
train: epoch 16, loss 0.5099652409553528, acc=0.7773333191871643, loss=0.5099652409553528
test: epoch 16, loss 1.039853811264038, acc=0.5944444537162781, loss=1.039853811264038
train: epoch 17, loss 0.48653438687324524, acc=0.7885000109672546, loss=0.48653438687324524
test: epoch 17, loss 1.1688066720962524, acc=0.5305555462837219, loss=1.1688066720962524
train: epoch 18, loss 0.4173790216445923, acc=0.8198888897895813, loss=0.4173790216445923
test: epoch 18, loss 1.2097046375274658, acc=0.5249999761581421, loss=1.2097046375274658
train: epoch 19, loss 0.38943105936050415, acc=0.8284444212913513, loss=0.38943105936050415
test: epoch 19, loss 1.0384019613265991, acc=0.6388888955116272, loss=1.0384019613265991
train: epoch 20, loss 0.3810723125934601, acc=0.8386111259460449, loss=0.3810723125934601
test: epoch 20, loss 0.9351370930671692, acc=0.6000000238418579, loss=0.9351370930671692
train: epoch 21, loss 0.36309364438056946, acc=0.843500018119812, loss=0.36309364438056946
test: epoch 21, loss 1.247996211051941, acc=0.5972222089767456, loss=1.247996211051941
train: epoch 22, loss 0.36364954710006714, acc=0.8447222113609314, loss=0.36364954710006714
test: epoch 22, loss 0.9488962292671204, acc=0.6416666507720947, loss=0.9488962292671204
train: epoch 23, loss 0.3505747616291046, acc=0.850944459438324, loss=0.3505747616291046
test: epoch 23, loss 0.9769254922866821, acc=0.6416666507720947, loss=0.9769254922866821
train: epoch 24, loss 0.3343203067779541, acc=0.855555534362793, loss=0.3343203067779541
test: epoch 24, loss 0.8573338389396667, acc=0.6527777910232544, loss=0.8573338389396667
train: epoch 25, loss 0.31762975454330444, acc=0.8593888878822327, loss=0.31762975454330444
test: epoch 25, loss 0.9150280356407166, acc=0.6416666507720947, loss=0.9150280356407166
train: epoch 26, loss 0.30576956272125244, acc=0.8650555610656738, loss=0.30576956272125244
test: epoch 26, loss 1.167607307434082, acc=0.6388888955116272, loss=1.167607307434082
train: epoch 27, loss 0.33749082684516907, acc=0.8586666584014893, loss=0.33749082684516907
test: epoch 27, loss 1.1419140100479126, acc=0.5666666626930237, loss=1.1419140100479126
train: epoch 28, loss 0.29491791129112244, acc=0.871222198009491, loss=0.29491791129112244
test: epoch 28, loss 0.9969024658203125, acc=0.6777777671813965, loss=0.9969024658203125
train: epoch 29, loss 0.30522453784942627, acc=0.8686666488647461, loss=0.30522453784942627
test: epoch 29, loss 0.9534112811088562, acc=0.6694444417953491, loss=0.9534112811088562
train: epoch 30, loss 0.3024468719959259, acc=0.8718888759613037, loss=0.3024468719959259
test: epoch 30, loss 1.0948982238769531, acc=0.5861111283302307, loss=1.0948982238769531
train: epoch 31, loss 0.27655336260795593, acc=0.8816111087799072, loss=0.27655336260795593
test: epoch 31, loss 0.9597460031509399, acc=0.7027778029441833, loss=0.9597460031509399
train: epoch 32, loss 0.27412503957748413, acc=0.8829444646835327, loss=0.27412503957748413
test: epoch 32, loss 1.0496925115585327, acc=0.6222222447395325, loss=1.0496925115585327
train: epoch 33, loss 0.2896122932434082, acc=0.8799999952316284, loss=0.2896122932434082
test: epoch 33, loss 0.8004722595214844, acc=0.7083333134651184, loss=0.8004722595214844
train: epoch 34, loss 0.2787143886089325, acc=0.8837777972221375, loss=0.2787143886089325
test: epoch 34, loss 0.7580042481422424, acc=0.7083333134651184, loss=0.7580042481422424
train: epoch 35, loss 0.28890958428382874, acc=0.8804444670677185, loss=0.28890958428382874
test: epoch 35, loss 1.4582818746566772, acc=0.6138888597488403, loss=1.4582818746566772
train: epoch 36, loss 0.27334198355674744, acc=0.8843888640403748, loss=0.27334198355674744
test: epoch 36, loss 0.9764391779899597, acc=0.6583333611488342, loss=0.9764391779899597
train: epoch 37, loss 0.26367148756980896, acc=0.8895000219345093, loss=0.26367148756980896
test: epoch 37, loss 0.8006362915039062, acc=0.6916666626930237, loss=0.8006362915039062
train: epoch 38, loss 0.2529648244380951, acc=0.8916666507720947, loss=0.2529648244380951
test: epoch 38, loss 0.7286384105682373, acc=0.7194444537162781, loss=0.7286384105682373
train: epoch 39, loss 0.24350707232952118, acc=0.8957777619361877, loss=0.24350707232952118
test: epoch 39, loss 0.6636559367179871, acc=0.7777777910232544, loss=0.6636559367179871
train: epoch 40, loss 0.2688767611980438, acc=0.8871666789054871, loss=0.2688767611980438
test: epoch 40, loss 0.8014774322509766, acc=0.7222222089767456, loss=0.8014774322509766
train: epoch 41, loss 0.2819133698940277, acc=0.8843333125114441, loss=0.2819133698940277
test: epoch 41, loss 0.8221999406814575, acc=0.7138888835906982, loss=0.8221999406814575
train: epoch 42, loss 0.24639928340911865, acc=0.8955555558204651, loss=0.24639928340911865
test: epoch 42, loss 0.5944752097129822, acc=0.7777777910232544, loss=0.5944752097129822
train: epoch 43, loss 0.23643608391284943, acc=0.8976110816001892, loss=0.23643608391284943
test: epoch 43, loss 0.6805742383003235, acc=0.7388888597488403, loss=0.6805742383003235
train: epoch 44, loss 0.25342807173728943, acc=0.8946666717529297, loss=0.25342807173728943
test: epoch 44, loss 0.852218508720398, acc=0.7416666746139526, loss=0.852218508720398
train: epoch 45, loss 0.23040390014648438, acc=0.9005555510520935, loss=0.23040390014648438
test: epoch 45, loss 0.6814717054367065, acc=0.7472222447395325, loss=0.6814717054367065
train: epoch 46, loss 0.25426343083381653, acc=0.8928889036178589, loss=0.25426343083381653
test: epoch 46, loss 0.7624690532684326, acc=0.7749999761581421, loss=0.7624690532684326
train: epoch 47, loss 0.2344692349433899, acc=0.8982222080230713, loss=0.2344692349433899
test: epoch 47, loss 0.689033567905426, acc=0.7888888716697693, loss=0.689033567905426
train: epoch 48, loss 0.22616566717624664, acc=0.9014999866485596, loss=0.22616566717624664
test: epoch 48, loss 0.43165796995162964, acc=0.8416666388511658, loss=0.43165796995162964
train: epoch 49, loss 0.2281293421983719, acc=0.9014444351196289, loss=0.2281293421983719
test: epoch 49, loss 0.4615465998649597, acc=0.8111110925674438, loss=0.4615465998649597
train: epoch 50, loss 0.2163495570421219, acc=0.906000018119812, loss=0.2163495570421219
test: epoch 50, loss 0.47089073061943054, acc=0.8305555582046509, loss=0.47089073061943054
train: epoch 51, loss 0.22141727805137634, acc=0.9042778015136719, loss=0.22141727805137634
test: epoch 51, loss 0.46951624751091003, acc=0.8305555582046509, loss=0.46951624751091003
train: epoch 52, loss 0.25846728682518005, acc=0.8928889036178589, loss=0.25846728682518005
test: epoch 52, loss 0.39663079380989075, acc=0.8416666388511658, loss=0.39663079380989075
train: epoch 53, loss 0.2302556186914444, acc=0.9021666646003723, loss=0.2302556186914444
test: epoch 53, loss 0.5368878245353699, acc=0.8194444179534912, loss=0.5368878245353699
train: epoch 54, loss 0.2148590236902237, acc=0.9045555591583252, loss=0.2148590236902237
test: epoch 54, loss 0.4628048837184906, acc=0.8388888835906982, loss=0.4628048837184906
train: epoch 55, loss 0.2163640260696411, acc=0.9036111235618591, loss=0.2163640260696411
test: epoch 55, loss 0.45776060223579407, acc=0.8361111283302307, loss=0.45776060223579407
train: epoch 56, loss 0.22919005155563354, acc=0.901888906955719, loss=0.22919005155563354
test: epoch 56, loss 0.3795851469039917, acc=0.8416666388511658, loss=0.3795851469039917
train: epoch 57, loss 0.1965952068567276, acc=0.9102222323417664, loss=0.1965952068567276
test: epoch 57, loss 0.4814037084579468, acc=0.8416666388511658, loss=0.4814037084579468
train: epoch 58, loss 0.22550520300865173, acc=0.9045555591583252, loss=0.22550520300865173
test: epoch 58, loss 0.4326849579811096, acc=0.8416666388511658, loss=0.4326849579811096
train: epoch 59, loss 0.22163164615631104, acc=0.9038888812065125, loss=0.22163164615631104
test: epoch 59, loss 0.44729602336883545, acc=0.8388888835906982, loss=0.44729602336883545
train: epoch 60, loss 0.21789756417274475, acc=0.9062777757644653, loss=0.21789756417274475
test: epoch 60, loss 0.5043030381202698, acc=0.8416666388511658, loss=0.5043030381202698
train: epoch 61, loss 0.21201041340827942, acc=0.9057222008705139, loss=0.21201041340827942
test: epoch 61, loss 0.46027103066444397, acc=0.8388888835906982, loss=0.46027103066444397
train: epoch 62, loss 0.21519094705581665, acc=0.9048333168029785, loss=0.21519094705581665
test: epoch 62, loss 0.47249507904052734, acc=0.8444444537162781, loss=0.47249507904052734
train: epoch 63, loss 0.23250123858451843, acc=0.9010555744171143, loss=0.23250123858451843
test: epoch 63, loss 0.42479079961776733, acc=0.8388888835906982, loss=0.42479079961776733
train: epoch 64, loss 0.2037935107946396, acc=0.9081110954284668, loss=0.2037935107946396
test: epoch 64, loss 0.4571685194969177, acc=0.8416666388511658, loss=0.4571685194969177
train: epoch 65, loss 0.21501068770885468, acc=0.9083333611488342, loss=0.21501068770885468
test: epoch 65, loss 0.4524438679218292, acc=0.8388888835906982, loss=0.4524438679218292
train: epoch 66, loss 0.20765472948551178, acc=0.9081666469573975, loss=0.20765472948551178
test: epoch 66, loss 0.4738974869251251, acc=0.8388888835906982, loss=0.4738974869251251
train: epoch 67, loss 0.205995112657547, acc=0.9077777862548828, loss=0.205995112657547
test: epoch 67, loss 0.38350966572761536, acc=0.8416666388511658, loss=0.38350966572761536
train: epoch 68, loss 0.22348356246948242, acc=0.9027777910232544, loss=0.22348356246948242
test: epoch 68, loss 0.4306758940219879, acc=0.8416666388511658, loss=0.4306758940219879
train: epoch 69, loss 0.19666993618011475, acc=0.9113888740539551, loss=0.19666993618011475
test: epoch 69, loss 0.5065405368804932, acc=0.8111110925674438, loss=0.5065405368804932
train: epoch 70, loss 0.2177395522594452, acc=0.9057777523994446, loss=0.2177395522594452
test: epoch 70, loss 0.5410594344139099, acc=0.8194444179534912, loss=0.5410594344139099
train: epoch 71, loss 0.1900773048400879, acc=0.9129999876022339, loss=0.1900773048400879
test: epoch 71, loss 0.5257190465927124, acc=0.8388888835906982, loss=0.5257190465927124
train: epoch 72, loss 0.21954062581062317, acc=0.9040555357933044, loss=0.21954062581062317
test: epoch 72, loss 0.5592375993728638, acc=0.8361111283302307, loss=0.5592375993728638
train: epoch 73, loss 0.2110857218503952, acc=0.9067777991294861, loss=0.2110857218503952
test: epoch 73, loss 0.44995981454849243, acc=0.8333333134651184, loss=0.44995981454849243
train: epoch 74, loss 0.21802540123462677, acc=0.905055582523346, loss=0.21802540123462677
test: epoch 74, loss 0.6474428772926331, acc=0.8194444179534912, loss=0.6474428772926331
train: epoch 75, loss 0.20687593519687653, acc=0.9076111316680908, loss=0.20687593519687653
test: epoch 75, loss 0.4119158387184143, acc=0.8333333134651184, loss=0.4119158387184143
train: epoch 76, loss 0.23016279935836792, acc=0.9013333320617676, loss=0.23016279935836792
test: epoch 76, loss 0.41352808475494385, acc=0.8388888835906982, loss=0.41352808475494385
train: epoch 77, loss 0.21686582267284393, acc=0.9062777757644653, loss=0.21686582267284393
test: epoch 77, loss 0.45141416788101196, acc=0.8388888835906982, loss=0.45141416788101196
train: epoch 78, loss 0.22851094603538513, acc=0.9003888964653015, loss=0.22851094603538513
test: epoch 78, loss 0.3680800199508667, acc=0.8361111283302307, loss=0.3680800199508667
train: epoch 79, loss 0.19436217844486237, acc=0.9119444489479065, loss=0.19436217844486237
test: epoch 79, loss 0.39445963501930237, acc=0.8416666388511658, loss=0.39445963501930237
train: epoch 80, loss 0.1981421709060669, acc=0.9117777943611145, loss=0.1981421709060669
test: epoch 80, loss 0.48732808232307434, acc=0.8361111283302307, loss=0.48732808232307434
train: epoch 81, loss 0.20426832139492035, acc=0.9092777967453003, loss=0.20426832139492035
test: epoch 81, loss 0.41364866495132446, acc=0.8416666388511658, loss=0.41364866495132446
train: epoch 82, loss 0.21924039721488953, acc=0.9052222371101379, loss=0.21924039721488953
test: epoch 82, loss 0.44344228506088257, acc=0.8416666388511658, loss=0.44344228506088257
train: epoch 83, loss 0.21309852600097656, acc=0.910111129283905, loss=0.21309852600097656
test: epoch 83, loss 0.5263746380805969, acc=0.8305555582046509, loss=0.5263746380805969
train: epoch 84, loss 0.21428823471069336, acc=0.9065555334091187, loss=0.21428823471069336
test: epoch 84, loss 0.3818221390247345, acc=0.8416666388511658, loss=0.3818221390247345
train: epoch 85, loss 0.19466480612754822, acc=0.9105555415153503, loss=0.19466480612754822
test: epoch 85, loss 0.38584816455841064, acc=0.855555534362793, loss=0.38584816455841064
train: epoch 86, loss 0.2654886543750763, acc=0.8877778053283691, loss=0.2654886543750763
test: epoch 86, loss 0.45370572805404663, acc=0.8444444537162781, loss=0.45370572805404663
train: epoch 87, loss 0.21354492008686066, acc=0.9079999923706055, loss=0.21354492008686066
test: epoch 87, loss 0.43123891949653625, acc=0.8500000238418579, loss=0.43123891949653625
train: epoch 88, loss 0.21803148090839386, acc=0.9066666960716248, loss=0.21803148090839386
test: epoch 88, loss 0.4205488860607147, acc=0.8527777791023254, loss=0.4205488860607147
train: epoch 89, loss 0.18712978065013885, acc=0.9123888611793518, loss=0.18712978065013885
test: epoch 89, loss 0.43312790989875793, acc=0.8527777791023254, loss=0.43312790989875793
train: epoch 90, loss 0.20963165163993835, acc=0.9066110849380493, loss=0.20963165163993835
test: epoch 90, loss 0.40815287828445435, acc=0.855555534362793, loss=0.40815287828445435
train: epoch 91, loss 0.2145724892616272, acc=0.9049999713897705, loss=0.2145724892616272
test: epoch 91, loss 0.45597463846206665, acc=0.855555534362793, loss=0.45597463846206665
train: epoch 92, loss 0.18771830201148987, acc=0.9139444231987, loss=0.18771830201148987
test: epoch 92, loss 0.41836175322532654, acc=0.8527777791023254, loss=0.41836175322532654
train: epoch 93, loss 0.22150781750679016, acc=0.9043889045715332, loss=0.22150781750679016
test: epoch 93, loss 0.4150228798389435, acc=0.855555534362793, loss=0.4150228798389435
train: epoch 94, loss 0.19592030346393585, acc=0.9114444255828857, loss=0.19592030346393585
test: epoch 94, loss 0.4327487349510193, acc=0.8472222089767456, loss=0.4327487349510193
train: epoch 95, loss 0.17094624042510986, acc=0.9162222146987915, loss=0.17094624042510986
test: epoch 95, loss 0.38395369052886963, acc=0.855555534362793, loss=0.38395369052886963
train: epoch 96, loss 0.23464035987854004, acc=0.897944450378418, loss=0.23464035987854004
test: epoch 96, loss 0.5813348889350891, acc=0.8361111283302307, loss=0.5813348889350891
train: epoch 97, loss 0.18528135120868683, acc=0.9126666784286499, loss=0.18528135120868683
test: epoch 97, loss 0.36385345458984375, acc=0.855555534362793, loss=0.36385345458984375
train: epoch 98, loss 0.27016299962997437, acc=0.8889444470405579, loss=0.27016299962997437
test: epoch 98, loss 0.4415771961212158, acc=0.8222222328186035, loss=0.4415771961212158
train: epoch 99, loss 0.189729243516922, acc=0.9113888740539551, loss=0.189729243516922
test: epoch 99, loss 0.4126721918582916, acc=0.855555534362793, loss=0.4126721918582916
train: epoch 100, loss 0.3270314633846283, acc=0.8547222018241882, loss=0.3270314633846283
test: epoch 100, loss 0.5110253095626831, acc=0.8055555820465088, loss=0.5110253095626831
train: epoch 101, loss 0.34721848368644714, acc=0.8346111178398132, loss=0.34721848368644714
test: epoch 101, loss 0.4898965358734131, acc=0.8027777671813965, loss=0.4898965358734131
train: epoch 102, loss 0.3200143873691559, acc=0.8450000286102295, loss=0.3200143873691559
test: epoch 102, loss 0.4092400074005127, acc=0.8083333373069763, loss=0.4092400074005127
train: epoch 103, loss 0.3052462935447693, acc=0.8504999876022339, loss=0.3052462935447693
test: epoch 103, loss 0.44416874647140503, acc=0.8138889074325562, loss=0.44416874647140503
train: epoch 104, loss 0.3082010746002197, acc=0.8590555787086487, loss=0.3082010746002197
test: epoch 104, loss 0.42061901092529297, acc=0.8138889074325562, loss=0.42061901092529297
train: epoch 105, loss 0.2770141661167145, acc=0.8687222003936768, loss=0.2770141661167145
test: epoch 105, loss 0.5076387524604797, acc=0.800000011920929, loss=0.5076387524604797
train: epoch 106, loss 0.3072814643383026, acc=0.8686110973358154, loss=0.3072814643383026
test: epoch 106, loss 0.35750630497932434, acc=0.8500000238418579, loss=0.35750630497932434
train: epoch 107, loss 0.27132049202919006, acc=0.8725555539131165, loss=0.27132049202919006
test: epoch 107, loss 0.42247331142425537, acc=0.8194444179534912, loss=0.42247331142425537
train: epoch 108, loss 0.24534986913204193, acc=0.8742777705192566, loss=0.24534986913204193
test: epoch 108, loss 0.4737945795059204, acc=0.8166666626930237, loss=0.4737945795059204
train: epoch 109, loss 0.26457270979881287, acc=0.870888888835907, loss=0.26457270979881287
test: epoch 109, loss 0.5113143920898438, acc=0.8027777671813965, loss=0.5113143920898438
train: epoch 110, loss 0.2462964802980423, acc=0.8921111226081848, loss=0.2462964802980423
test: epoch 110, loss 0.37087300419807434, acc=0.8527777791023254, loss=0.37087300419807434
train: epoch 111, loss 0.20230521261692047, acc=0.9083889126777649, loss=0.20230521261692047
test: epoch 111, loss 0.37740522623062134, acc=0.8472222089767456, loss=0.37740522623062134
train: epoch 112, loss 0.20425325632095337, acc=0.9118333458900452, loss=0.20425325632095337
test: epoch 112, loss 0.38154229521751404, acc=0.8500000238418579, loss=0.38154229521751404
train: epoch 113, loss 0.1872471123933792, acc=0.9133889079093933, loss=0.1872471123933792
test: epoch 113, loss 0.3545326888561249, acc=0.855555534362793, loss=0.3545326888561249
train: epoch 114, loss 0.2014770209789276, acc=0.9087777733802795, loss=0.2014770209789276
test: epoch 114, loss 0.33703070878982544, acc=0.855555534362793, loss=0.33703070878982544
train: epoch 115, loss 0.1734115332365036, acc=0.9163333177566528, loss=0.1734115332365036
test: epoch 115, loss 0.3931834101676941, acc=0.855555534362793, loss=0.3931834101676941
train: epoch 116, loss 0.20975370705127716, acc=0.9103888869285583, loss=0.20975370705127716
test: epoch 116, loss 0.33123305439949036, acc=0.855555534362793, loss=0.33123305439949036
train: epoch 117, loss 0.19772827625274658, acc=0.9111666679382324, loss=0.19772827625274658
test: epoch 117, loss 0.35715028643608093, acc=0.855555534362793, loss=0.35715028643608093
train: epoch 118, loss 0.2695058584213257, acc=0.8897222280502319, loss=0.2695058584213257
test: epoch 118, loss 0.3948015570640564, acc=0.8444444537162781, loss=0.3948015570640564
train: epoch 119, loss 0.24741989374160767, acc=0.9002777934074402, loss=0.24741989374160767
test: epoch 119, loss 0.46610498428344727, acc=0.8500000238418579, loss=0.46610498428344727
train: epoch 120, loss 0.21189020574092865, acc=0.9063888788223267, loss=0.21189020574092865
test: epoch 120, loss 0.32657933235168457, acc=0.855555534362793, loss=0.32657933235168457
train: epoch 121, loss 0.19293200969696045, acc=0.9123333096504211, loss=0.19293200969696045
test: epoch 121, loss 0.3775882422924042, acc=0.8416666388511658, loss=0.3775882422924042
train: epoch 122, loss 0.17982465028762817, acc=0.9157222509384155, loss=0.17982465028762817
test: epoch 122, loss 0.3671115040779114, acc=0.855555534362793, loss=0.3671115040779114
train: epoch 123, loss 0.27031680941581726, acc=0.8917222023010254, loss=0.27031680941581726
test: epoch 123, loss 0.39557623863220215, acc=0.8388888835906982, loss=0.39557623863220215
train: epoch 124, loss 0.19465716183185577, acc=0.9075000286102295, loss=0.19465716183185577
test: epoch 124, loss 0.34049922227859497, acc=0.855555534362793, loss=0.34049922227859497
train: epoch 125, loss 0.23438164591789246, acc=0.9046111106872559, loss=0.23438164591789246
test: epoch 125, loss 0.4359849691390991, acc=0.855555534362793, loss=0.4359849691390991
train: epoch 126, loss 0.2521723508834839, acc=0.8841111063957214, loss=0.2521723508834839
test: epoch 126, loss 0.3444307744503021, acc=0.8333333134651184, loss=0.3444307744503021
train: epoch 127, loss 0.24489489197731018, acc=0.8827221989631653, loss=0.24489489197731018
test: epoch 127, loss 0.3560941517353058, acc=0.8305555582046509, loss=0.3560941517353058
train: epoch 128, loss 0.24906381964683533, acc=0.8855555653572083, loss=0.24906381964683533
test: epoch 128, loss 0.4070838987827301, acc=0.8277778029441833, loss=0.4070838987827301
train: epoch 129, loss 0.22878240048885345, acc=0.8972222208976746, loss=0.22878240048885345
test: epoch 129, loss 0.40227675437927246, acc=0.8527777791023254, loss=0.40227675437927246
train: epoch 130, loss 0.19790108501911163, acc=0.9070555567741394, loss=0.19790108501911163
test: epoch 130, loss 0.38282063603401184, acc=0.8527777791023254, loss=0.38282063603401184
train: epoch 131, loss 0.2600386440753937, acc=0.893666684627533, loss=0.2600386440753937
test: epoch 131, loss 0.32262372970581055, acc=0.8611111044883728, loss=0.32262372970581055
train: epoch 132, loss 0.26389971375465393, acc=0.890999972820282, loss=0.26389971375465393
test: epoch 132, loss 0.4071235656738281, acc=0.8416666388511658, loss=0.4071235656738281
train: epoch 133, loss 0.18399907648563385, acc=0.9150555729866028, loss=0.18399907648563385
test: epoch 133, loss 0.35762014985084534, acc=0.855555534362793, loss=0.35762014985084534
train: epoch 134, loss 0.20127622783184052, acc=0.9106666445732117, loss=0.20127622783184052
test: epoch 134, loss 0.3730732500553131, acc=0.8500000238418579, loss=0.3730732500553131
train: epoch 135, loss 0.21002818644046783, acc=0.9056110978126526, loss=0.21002818644046783
test: epoch 135, loss 0.3709743022918701, acc=0.855555534362793, loss=0.3709743022918701
train: epoch 136, loss 0.23461535573005676, acc=0.8992778062820435, loss=0.23461535573005676
test: epoch 136, loss 0.5666207075119019, acc=0.7916666865348816, loss=0.5666207075119019
train: epoch 137, loss 0.24784518778324127, acc=0.8880000114440918, loss=0.24784518778324127
test: epoch 137, loss 0.46593451499938965, acc=0.8388888835906982, loss=0.46593451499938965
train: epoch 138, loss 0.20954033732414246, acc=0.8911666870117188, loss=0.20954033732414246
test: epoch 138, loss 0.3562273681163788, acc=0.8388888835906982, loss=0.3562273681163788
train: epoch 139, loss 0.23156774044036865, acc=0.890500009059906, loss=0.23156774044036865
test: epoch 139, loss 0.4369211792945862, acc=0.8527777791023254, loss=0.4369211792945862
train: epoch 140, loss 0.21077504754066467, acc=0.906000018119812, loss=0.21077504754066467
test: epoch 140, loss 0.37913981080055237, acc=0.8472222089767456, loss=0.37913981080055237
train: epoch 141, loss 0.18528085947036743, acc=0.9127777814865112, loss=0.18528085947036743
test: epoch 141, loss 0.3642137050628662, acc=0.8527777791023254, loss=0.3642137050628662
train: epoch 142, loss 0.24991682171821594, acc=0.8956666588783264, loss=0.24991682171821594
test: epoch 142, loss 0.39571335911750793, acc=0.855555534362793, loss=0.39571335911750793
train: epoch 143, loss 0.1938079595565796, acc=0.9126111268997192, loss=0.1938079595565796
test: epoch 143, loss 0.5394802689552307, acc=0.8222222328186035, loss=0.5394802689552307
train: epoch 144, loss 0.1880139857530594, acc=0.9148889183998108, loss=0.1880139857530594
test: epoch 144, loss 0.34074416756629944, acc=0.855555534362793, loss=0.34074416756629944
train: epoch 145, loss 0.19916635751724243, acc=0.9076111316680908, loss=0.19916635751724243
test: epoch 145, loss 0.4591563045978546, acc=0.8500000238418579, loss=0.4591563045978546
train: epoch 146, loss 0.34284090995788574, acc=0.847777783870697, loss=0.34284090995788574
test: epoch 146, loss 0.4738493263721466, acc=0.8111110925674438, loss=0.4738493263721466
train: epoch 147, loss 0.2938805818557739, acc=0.8673333525657654, loss=0.2938805818557739
test: epoch 147, loss 0.37817755341529846, acc=0.8527777791023254, loss=0.37817755341529846
train: epoch 148, loss 0.18637032806873322, acc=0.9132221937179565, loss=0.18637032806873322
test: epoch 148, loss 0.41361522674560547, acc=0.8444444537162781, loss=0.41361522674560547
train: epoch 149, loss 0.22320348024368286, acc=0.9060555696487427, loss=0.22320348024368286
test: epoch 149, loss 0.4032621681690216, acc=0.8527777791023254, loss=0.4032621681690216
train: epoch 150, loss 0.22019943594932556, acc=0.9085000157356262, loss=0.22019943594932556
test: epoch 150, loss 0.37376344203948975, acc=0.8527777791023254, loss=0.37376344203948975
