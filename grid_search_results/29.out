# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=1", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=513119704, receiver_embed_dim=32, save_run=0, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=513119704, receiver_embed_dim=32, save_run=False, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.1100926399230957, acc=0.08283333480358124, loss=3.1100926399230957
test: epoch 1, loss 3.64011549949646, acc=0.08611111342906952, loss=3.64011549949646
train: epoch 2, loss 2.0800845623016357, acc=0.23133333027362823, loss=2.0800845623016357
test: epoch 2, loss 3.3641276359558105, acc=0.13333334028720856, loss=3.3641276359558105
train: epoch 3, loss 1.6378437280654907, acc=0.38172221183776855, loss=1.6378437280654907
test: epoch 3, loss 3.0457451343536377, acc=0.1666666716337204, loss=3.0457451343536377
train: epoch 4, loss 1.332173228263855, acc=0.4786111116409302, loss=1.332173228263855
test: epoch 4, loss 3.0297493934631348, acc=0.19166666269302368, loss=3.0297493934631348
train: epoch 5, loss 1.1210404634475708, acc=0.5705000162124634, loss=1.1210404634475708
test: epoch 5, loss 2.653458833694458, acc=0.21944443881511688, loss=2.653458833694458
train: epoch 6, loss 0.9783159494400024, acc=0.6230000257492065, loss=0.9783159494400024
test: epoch 6, loss 2.471026659011841, acc=0.2777777910232544, loss=2.471026659011841
train: epoch 7, loss 0.8775139451026917, acc=0.6597777605056763, loss=0.8775139451026917
test: epoch 7, loss 2.2441985607147217, acc=0.2638888955116272, loss=2.2441985607147217
train: epoch 8, loss 0.7721232771873474, acc=0.7022777795791626, loss=0.7721232771873474
test: epoch 8, loss 2.144529342651367, acc=0.3194444477558136, loss=2.144529342651367
train: epoch 9, loss 0.7207885384559631, acc=0.7268333435058594, loss=0.7207885384559631
test: epoch 9, loss 2.1172397136688232, acc=0.3194444477558136, loss=2.1172397136688232
train: epoch 10, loss 0.6726381778717041, acc=0.7523333430290222, loss=0.6726381778717041
test: epoch 10, loss 1.8752167224884033, acc=0.31111112236976624, loss=1.8752167224884033
train: epoch 11, loss 0.627277672290802, acc=0.7689999938011169, loss=0.627277672290802
test: epoch 11, loss 1.7525978088378906, acc=0.3222222328186035, loss=1.7525978088378906
train: epoch 12, loss 0.5904090404510498, acc=0.7831110954284668, loss=0.5904090404510498
test: epoch 12, loss 1.7152968645095825, acc=0.34166666865348816, loss=1.7152968645095825
train: epoch 13, loss 0.5314902663230896, acc=0.8061666488647461, loss=0.5314902663230896
test: epoch 13, loss 1.7929308414459229, acc=0.36666667461395264, loss=1.7929308414459229
train: epoch 14, loss 0.5282518267631531, acc=0.8098333477973938, loss=0.5282518267631531
test: epoch 14, loss 1.918829083442688, acc=0.32777777314186096, loss=1.918829083442688
train: epoch 15, loss 0.4893245995044708, acc=0.8257222175598145, loss=0.4893245995044708
test: epoch 15, loss 1.634196400642395, acc=0.33888888359069824, loss=1.634196400642395
train: epoch 16, loss 0.4653649926185608, acc=0.8340555429458618, loss=0.4653649926185608
test: epoch 16, loss 1.6745517253875732, acc=0.3916666805744171, loss=1.6745517253875732
train: epoch 17, loss 0.43903741240501404, acc=0.8465555310249329, loss=0.43903741240501404
test: epoch 17, loss 2.027846336364746, acc=0.39722222089767456, loss=2.027846336364746
train: epoch 18, loss 0.4313010573387146, acc=0.8485555648803711, loss=0.4313010573387146
test: epoch 18, loss 1.7602099180221558, acc=0.3861111104488373, loss=1.7602099180221558
train: epoch 19, loss 0.41091862320899963, acc=0.8567222356796265, loss=0.41091862320899963
test: epoch 19, loss 1.892815351486206, acc=0.3722222149372101, loss=1.892815351486206
train: epoch 20, loss 0.39306557178497314, acc=0.8644999861717224, loss=0.39306557178497314
test: epoch 20, loss 1.6941908597946167, acc=0.38333332538604736, loss=1.6941908597946167
train: epoch 21, loss 0.36413949728012085, acc=0.8732222318649292, loss=0.36413949728012085
test: epoch 21, loss 1.5883792638778687, acc=0.38055557012557983, loss=1.5883792638778687
train: epoch 22, loss 0.3640681803226471, acc=0.8722777962684631, loss=0.3640681803226471
test: epoch 22, loss 1.7180933952331543, acc=0.4166666567325592, loss=1.7180933952331543
train: epoch 23, loss 0.3641858994960785, acc=0.8721110820770264, loss=0.3641858994960785
test: epoch 23, loss 1.663591742515564, acc=0.4444444477558136, loss=1.663591742515564
train: epoch 24, loss 0.3552923798561096, acc=0.8829444646835327, loss=0.3552923798561096
test: epoch 24, loss 1.7954353094100952, acc=0.3611111044883728, loss=1.7954353094100952
train: epoch 25, loss 0.34269005060195923, acc=0.8847777843475342, loss=0.34269005060195923
test: epoch 25, loss 1.6925488710403442, acc=0.3888888955116272, loss=1.6925488710403442
train: epoch 26, loss 0.3438289165496826, acc=0.8820000290870667, loss=0.3438289165496826
test: epoch 26, loss 1.906060814857483, acc=0.3444444537162781, loss=1.906060814857483
train: epoch 27, loss 0.3293105363845825, acc=0.886722207069397, loss=0.3293105363845825
test: epoch 27, loss 1.5559345483779907, acc=0.4611110985279083, loss=1.5559345483779907
train: epoch 28, loss 0.3330974578857422, acc=0.8862777948379517, loss=0.3330974578857422
test: epoch 28, loss 1.5764248371124268, acc=0.4277777671813965, loss=1.5764248371124268
train: epoch 29, loss 0.3194996416568756, acc=0.8892222046852112, loss=0.3194996416568756
test: epoch 29, loss 1.7143155336380005, acc=0.44999998807907104, loss=1.7143155336380005
train: epoch 30, loss 0.32083964347839355, acc=0.8907222151756287, loss=0.32083964347839355
test: epoch 30, loss 1.7794721126556396, acc=0.45277777314186096, loss=1.7794721126556396
train: epoch 31, loss 0.3089049160480499, acc=0.8924999833106995, loss=0.3089049160480499
test: epoch 31, loss 1.5830036401748657, acc=0.4583333432674408, loss=1.5830036401748657
train: epoch 32, loss 0.31510937213897705, acc=0.8928889036178589, loss=0.31510937213897705
test: epoch 32, loss 1.4806389808654785, acc=0.47777777910232544, loss=1.4806389808654785
train: epoch 33, loss 0.3005412220954895, acc=0.8976666927337646, loss=0.3005412220954895
test: epoch 33, loss 1.5955719947814941, acc=0.4416666626930237, loss=1.5955719947814941
train: epoch 34, loss 0.30155348777770996, acc=0.8947222232818604, loss=0.30155348777770996
test: epoch 34, loss 1.3328958749771118, acc=0.46388888359069824, loss=1.3328958749771118
train: epoch 35, loss 0.29809167981147766, acc=0.8958333134651184, loss=0.29809167981147766
test: epoch 35, loss 1.7216362953186035, acc=0.4416666626930237, loss=1.7216362953186035
train: epoch 36, loss 0.3081406056880951, acc=0.8931111097335815, loss=0.3081406056880951
test: epoch 36, loss 1.56773042678833, acc=0.5111111402511597, loss=1.56773042678833
train: epoch 37, loss 0.2781350314617157, acc=0.9043333530426025, loss=0.2781350314617157
test: epoch 37, loss 1.3598825931549072, acc=0.5083333253860474, loss=1.3598825931549072
train: epoch 38, loss 0.288071870803833, acc=0.8996111154556274, loss=0.288071870803833
test: epoch 38, loss 1.385581135749817, acc=0.5249999761581421, loss=1.385581135749817
train: epoch 39, loss 0.27344101667404175, acc=0.9055555462837219, loss=0.27344101667404175
test: epoch 39, loss 1.665013313293457, acc=0.4611110985279083, loss=1.665013313293457
train: epoch 40, loss 0.28554433584213257, acc=0.9010555744171143, loss=0.28554433584213257
test: epoch 40, loss 1.6212917566299438, acc=0.5027777552604675, loss=1.6212917566299438
train: epoch 41, loss 0.28155258297920227, acc=0.9030555486679077, loss=0.28155258297920227
test: epoch 41, loss 1.2425228357315063, acc=0.5416666865348816, loss=1.2425228357315063
train: epoch 42, loss 0.27466529607772827, acc=0.9048333168029785, loss=0.27466529607772827
test: epoch 42, loss 1.4675692319869995, acc=0.5222222208976746, loss=1.4675692319869995
train: epoch 43, loss 0.25640761852264404, acc=0.9133889079093933, loss=0.25640761852264404
test: epoch 43, loss 1.1571993827819824, acc=0.5583333373069763, loss=1.1571993827819824
train: epoch 44, loss 0.2692285180091858, acc=0.9070000052452087, loss=0.2692285180091858
test: epoch 44, loss 1.5824809074401855, acc=0.5111111402511597, loss=1.5824809074401855
train: epoch 45, loss 0.2558618485927582, acc=0.9124444723129272, loss=0.2558618485927582
test: epoch 45, loss 1.4002145528793335, acc=0.5861111283302307, loss=1.4002145528793335
train: epoch 46, loss 0.2520616054534912, acc=0.9150000214576721, loss=0.2520616054534912
test: epoch 46, loss 1.2332823276519775, acc=0.47777777910232544, loss=1.2332823276519775
train: epoch 47, loss 0.2558245360851288, acc=0.9125555753707886, loss=0.2558245360851288
test: epoch 47, loss 1.5320587158203125, acc=0.5527777671813965, loss=1.5320587158203125
train: epoch 48, loss 0.23135030269622803, acc=0.9222777485847473, loss=0.23135030269622803
test: epoch 48, loss 1.3471683263778687, acc=0.5222222208976746, loss=1.3471683263778687
train: epoch 49, loss 0.24627727270126343, acc=0.9152777791023254, loss=0.24627727270126343
test: epoch 49, loss 1.2551220655441284, acc=0.6138888597488403, loss=1.2551220655441284
train: epoch 50, loss 0.2366446554660797, acc=0.9210000038146973, loss=0.2366446554660797
test: epoch 50, loss 1.4425849914550781, acc=0.574999988079071, loss=1.4425849914550781
train: epoch 51, loss 0.22709983587265015, acc=0.924833357334137, loss=0.22709983587265015
test: epoch 51, loss 1.731694221496582, acc=0.5305555462837219, loss=1.731694221496582
train: epoch 52, loss 0.24216343462467194, acc=0.918666660785675, loss=0.24216343462467194
test: epoch 52, loss 1.1507636308670044, acc=0.5333333611488342, loss=1.1507636308670044
train: epoch 53, loss 0.22413423657417297, acc=0.9247221946716309, loss=0.22413423657417297
test: epoch 53, loss 1.600401520729065, acc=0.605555534362793, loss=1.600401520729065
train: epoch 54, loss 0.21626706421375275, acc=0.9262222051620483, loss=0.21626706421375275
test: epoch 54, loss 1.228637933731079, acc=0.5805555582046509, loss=1.228637933731079
train: epoch 55, loss 0.20587995648384094, acc=0.9313333630561829, loss=0.20587995648384094
test: epoch 55, loss 1.4351216554641724, acc=0.5416666865348816, loss=1.4351216554641724
train: epoch 56, loss 0.21057240664958954, acc=0.9283888936042786, loss=0.21057240664958954
test: epoch 56, loss 1.4893782138824463, acc=0.550000011920929, loss=1.4893782138824463
train: epoch 57, loss 0.21662314236164093, acc=0.9295555353164673, loss=0.21662314236164093
test: epoch 57, loss 1.4849789142608643, acc=0.5388888716697693, loss=1.4849789142608643
train: epoch 58, loss 0.2176108956336975, acc=0.9277777671813965, loss=0.2176108956336975
test: epoch 58, loss 1.1398370265960693, acc=0.6583333611488342, loss=1.1398370265960693
train: epoch 59, loss 0.20666629076004028, acc=0.9282777905464172, loss=0.20666629076004028
test: epoch 59, loss 0.7996110916137695, acc=0.6972222328186035, loss=0.7996110916137695
train: epoch 60, loss 0.20461048185825348, acc=0.9301666617393494, loss=0.20461048185825348
test: epoch 60, loss 1.3363856077194214, acc=0.6222222447395325, loss=1.3363856077194214
train: epoch 61, loss 0.21068765223026276, acc=0.93022221326828, loss=0.21068765223026276
test: epoch 61, loss 1.3030638694763184, acc=0.5388888716697693, loss=1.3030638694763184
train: epoch 62, loss 0.2025398164987564, acc=0.9306111335754395, loss=0.2025398164987564
test: epoch 62, loss 1.2784526348114014, acc=0.6333333253860474, loss=1.2784526348114014
train: epoch 63, loss 0.2010127156972885, acc=0.9311666488647461, loss=0.2010127156972885
test: epoch 63, loss 1.1898378133773804, acc=0.6111111044883728, loss=1.1898378133773804
train: epoch 64, loss 0.20041030645370483, acc=0.9321666955947876, loss=0.20041030645370483
test: epoch 64, loss 1.2262914180755615, acc=0.5916666388511658, loss=1.2262914180755615
train: epoch 65, loss 0.19737300276756287, acc=0.9327222108840942, loss=0.19737300276756287
test: epoch 65, loss 0.9411894083023071, acc=0.6138888597488403, loss=0.9411894083023071
train: epoch 66, loss 0.19921942055225372, acc=0.9338333606719971, loss=0.19921942055225372
test: epoch 66, loss 1.0881444215774536, acc=0.6138888597488403, loss=1.0881444215774536
train: epoch 67, loss 0.20255175232887268, acc=0.930388867855072, loss=0.20255175232887268
test: epoch 67, loss 1.001063585281372, acc=0.6666666865348816, loss=1.001063585281372
train: epoch 68, loss 0.1917782723903656, acc=0.9352222084999084, loss=0.1917782723903656
test: epoch 68, loss 1.0309768915176392, acc=0.6638888716697693, loss=1.0309768915176392
train: epoch 69, loss 0.18924404680728912, acc=0.9369999766349792, loss=0.18924404680728912
test: epoch 69, loss 0.8820338845252991, acc=0.6583333611488342, loss=0.8820338845252991
train: epoch 70, loss 0.19791027903556824, acc=0.9338333606719971, loss=0.19791027903556824
test: epoch 70, loss 1.2477898597717285, acc=0.6194444298744202, loss=1.2477898597717285
train: epoch 71, loss 0.19811496138572693, acc=0.9326111078262329, loss=0.19811496138572693
test: epoch 71, loss 1.1761738061904907, acc=0.6361111402511597, loss=1.1761738061904907
train: epoch 72, loss 0.17290489375591278, acc=0.9430555701255798, loss=0.17290489375591278
test: epoch 72, loss 0.9971853494644165, acc=0.6805555820465088, loss=0.9971853494644165
train: epoch 73, loss 0.20029984414577484, acc=0.9333333373069763, loss=0.20029984414577484
test: epoch 73, loss 0.9610541462898254, acc=0.7333333492279053, loss=0.9610541462898254
train: epoch 74, loss 0.19161324203014374, acc=0.9358888864517212, loss=0.19161324203014374
test: epoch 74, loss 0.9714430570602417, acc=0.7027778029441833, loss=0.9714430570602417
train: epoch 75, loss 0.1999187022447586, acc=0.933222234249115, loss=0.1999187022447586
test: epoch 75, loss 0.7810558080673218, acc=0.6611111164093018, loss=0.7810558080673218
train: epoch 76, loss 0.17601019144058228, acc=0.9407777786254883, loss=0.17601019144058228
test: epoch 76, loss 1.0738712549209595, acc=0.6666666865348816, loss=1.0738712549209595
train: epoch 77, loss 0.18539826571941376, acc=0.9382777810096741, loss=0.18539826571941376
test: epoch 77, loss 1.0734014511108398, acc=0.6944444179534912, loss=1.0734014511108398
train: epoch 78, loss 0.1886499524116516, acc=0.9381666779518127, loss=0.1886499524116516
test: epoch 78, loss 0.9186738729476929, acc=0.6833333373069763, loss=0.9186738729476929
train: epoch 79, loss 0.1812632977962494, acc=0.9399999976158142, loss=0.1812632977962494
test: epoch 79, loss 1.0090711116790771, acc=0.675000011920929, loss=1.0090711116790771
train: epoch 80, loss 0.1865123212337494, acc=0.9385555386543274, loss=0.1865123212337494
test: epoch 80, loss 0.9249598383903503, acc=0.7166666388511658, loss=0.9249598383903503
train: epoch 81, loss 0.18727202713489532, acc=0.9383333325386047, loss=0.18727202713489532
test: epoch 81, loss 0.8938853144645691, acc=0.7027778029441833, loss=0.8938853144645691
train: epoch 82, loss 0.18276412785053253, acc=0.9372777938842773, loss=0.18276412785053253
test: epoch 82, loss 1.3253313302993774, acc=0.6416666507720947, loss=1.3253313302993774
train: epoch 83, loss 0.19106170535087585, acc=0.9357222318649292, loss=0.19106170535087585
test: epoch 83, loss 0.9653996825218201, acc=0.7166666388511658, loss=0.9653996825218201
train: epoch 84, loss 0.17014162242412567, acc=0.9442222118377686, loss=0.17014162242412567
test: epoch 84, loss 0.9738768339157104, acc=0.6972222328186035, loss=0.9738768339157104
train: epoch 85, loss 0.1803678274154663, acc=0.9397222399711609, loss=0.1803678274154663
test: epoch 85, loss 1.1808092594146729, acc=0.675000011920929, loss=1.1808092594146729
train: epoch 86, loss 0.18117380142211914, acc=0.940500020980835, loss=0.18117380142211914
test: epoch 86, loss 0.9907838702201843, acc=0.7138888835906982, loss=0.9907838702201843
train: epoch 87, loss 0.17855684459209442, acc=0.9409999847412109, loss=0.17855684459209442
test: epoch 87, loss 0.900830090045929, acc=0.6805555820465088, loss=0.900830090045929
train: epoch 88, loss 0.1751847267150879, acc=0.9415000081062317, loss=0.1751847267150879
test: epoch 88, loss 0.9020643830299377, acc=0.7222222089767456, loss=0.9020643830299377
train: epoch 89, loss 0.17530684173107147, acc=0.9402222037315369, loss=0.17530684173107147
test: epoch 89, loss 1.2493476867675781, acc=0.7027778029441833, loss=1.2493476867675781
train: epoch 90, loss 0.18063229322433472, acc=0.9408888816833496, loss=0.18063229322433472
test: epoch 90, loss 0.8879689574241638, acc=0.6916666626930237, loss=0.8879689574241638
train: epoch 91, loss 0.17164064943790436, acc=0.9448888897895813, loss=0.17164064943790436
test: epoch 91, loss 0.9345571398735046, acc=0.7222222089767456, loss=0.9345571398735046
train: epoch 92, loss 0.1559332013130188, acc=0.949833333492279, loss=0.1559332013130188
test: epoch 92, loss 1.0200289487838745, acc=0.7361111044883728, loss=1.0200289487838745
train: epoch 93, loss 0.16900095343589783, acc=0.9467222094535828, loss=0.16900095343589783
test: epoch 93, loss 0.8908799886703491, acc=0.730555534362793, loss=0.8908799886703491
train: epoch 94, loss 0.16542813181877136, acc=0.9462222456932068, loss=0.16542813181877136
test: epoch 94, loss 0.8862533569335938, acc=0.7361111044883728, loss=0.8862533569335938
train: epoch 95, loss 0.178859144449234, acc=0.9424444437026978, loss=0.178859144449234
test: epoch 95, loss 0.6984536051750183, acc=0.7805555462837219, loss=0.6984536051750183
train: epoch 96, loss 0.16490580141544342, acc=0.9465000033378601, loss=0.16490580141544342
test: epoch 96, loss 0.720132052898407, acc=0.7611111402511597, loss=0.720132052898407
train: epoch 97, loss 0.17724694311618805, acc=0.9403889179229736, loss=0.17724694311618805
test: epoch 97, loss 0.9673023223876953, acc=0.7333333492279053, loss=0.9673023223876953
train: epoch 98, loss 0.17075665295124054, acc=0.9447222352027893, loss=0.17075665295124054
test: epoch 98, loss 0.8098592162132263, acc=0.7833333611488342, loss=0.8098592162132263
train: epoch 99, loss 0.1595313549041748, acc=0.9480555653572083, loss=0.1595313549041748
test: epoch 99, loss 0.7580214738845825, acc=0.7861111164093018, loss=0.7580214738845825
train: epoch 100, loss 0.14978715777397156, acc=0.9517222046852112, loss=0.14978715777397156
test: epoch 100, loss 0.6717860102653503, acc=0.7916666865348816, loss=0.6717860102653503
train: epoch 101, loss 0.1634426862001419, acc=0.9481111168861389, loss=0.1634426862001419
test: epoch 101, loss 0.810591459274292, acc=0.7666666507720947, loss=0.810591459274292
train: epoch 102, loss 0.15586088597774506, acc=0.9495555758476257, loss=0.15586088597774506
test: epoch 102, loss 0.6653026938438416, acc=0.7888888716697693, loss=0.6653026938438416
train: epoch 103, loss 0.1537226438522339, acc=0.9499444365501404, loss=0.1537226438522339
test: epoch 103, loss 0.5431292057037354, acc=0.7888888716697693, loss=0.5431292057037354
train: epoch 104, loss 0.1582988202571869, acc=0.9486666917800903, loss=0.1582988202571869
test: epoch 104, loss 0.6891850233078003, acc=0.7916666865348816, loss=0.6891850233078003
train: epoch 105, loss 0.15361249446868896, acc=0.9509999752044678, loss=0.15361249446868896
test: epoch 105, loss 0.7023752927780151, acc=0.7944444417953491, loss=0.7023752927780151
train: epoch 106, loss 0.15791212022304535, acc=0.949999988079071, loss=0.15791212022304535
test: epoch 106, loss 0.6224509477615356, acc=0.7944444417953491, loss=0.6224509477615356
train: epoch 107, loss 0.17248985171318054, acc=0.94477778673172, loss=0.17248985171318054
test: epoch 107, loss 0.773334801197052, acc=0.8166666626930237, loss=0.773334801197052
train: epoch 108, loss 0.1580098271369934, acc=0.9506666660308838, loss=0.1580098271369934
test: epoch 108, loss 0.6360172629356384, acc=0.8138889074325562, loss=0.6360172629356384
train: epoch 109, loss 0.1491621881723404, acc=0.9513333439826965, loss=0.1491621881723404
test: epoch 109, loss 0.6751701235771179, acc=0.8027777671813965, loss=0.6751701235771179
train: epoch 110, loss 0.14311976730823517, acc=0.9551110863685608, loss=0.14311976730823517
test: epoch 110, loss 0.5910654664039612, acc=0.8333333134651184, loss=0.5910654664039612
train: epoch 111, loss 0.14739450812339783, acc=0.9551110863685608, loss=0.14739450812339783
test: epoch 111, loss 0.6983765959739685, acc=0.8138889074325562, loss=0.6983765959739685
train: epoch 112, loss 0.14724308252334595, acc=0.9536111354827881, loss=0.14724308252334595
test: epoch 112, loss 0.6164769530296326, acc=0.8111110925674438, loss=0.6164769530296326
train: epoch 113, loss 0.16342325508594513, acc=0.9500555396080017, loss=0.16342325508594513
test: epoch 113, loss 0.5671523809432983, acc=0.8305555582046509, loss=0.5671523809432983
train: epoch 114, loss 0.141161248087883, acc=0.954277753829956, loss=0.141161248087883
test: epoch 114, loss 0.5462087392807007, acc=0.824999988079071, loss=0.5462087392807007
train: epoch 115, loss 0.13696464896202087, acc=0.9565555453300476, loss=0.13696464896202087
test: epoch 115, loss 0.542677640914917, acc=0.855555534362793, loss=0.542677640914917
train: epoch 116, loss 0.14678961038589478, acc=0.9526110887527466, loss=0.14678961038589478
test: epoch 116, loss 0.5884956121444702, acc=0.8222222328186035, loss=0.5884956121444702
train: epoch 117, loss 0.1469556987285614, acc=0.9529444575309753, loss=0.1469556987285614
test: epoch 117, loss 0.48243287205696106, acc=0.8194444179534912, loss=0.48243287205696106
train: epoch 118, loss 0.13816186785697937, acc=0.9555000066757202, loss=0.13816186785697937
test: epoch 118, loss 0.44387537240982056, acc=0.8527777791023254, loss=0.44387537240982056
train: epoch 119, loss 0.1366834044456482, acc=0.9558333158493042, loss=0.1366834044456482
test: epoch 119, loss 0.6567099690437317, acc=0.824999988079071, loss=0.6567099690437317
train: epoch 120, loss 0.13145576417446136, acc=0.9582777619361877, loss=0.13145576417446136
test: epoch 120, loss 0.46642181277275085, acc=0.8666666746139526, loss=0.46642181277275085
train: epoch 121, loss 0.13870155811309814, acc=0.9557777643203735, loss=0.13870155811309814
test: epoch 121, loss 0.43470528721809387, acc=0.8638888597488403, loss=0.43470528721809387
train: epoch 122, loss 0.1340445727109909, acc=0.9573333263397217, loss=0.1340445727109909
test: epoch 122, loss 0.5536823272705078, acc=0.855555534362793, loss=0.5536823272705078
train: epoch 123, loss 0.13905294239521027, acc=0.9562222361564636, loss=0.13905294239521027
test: epoch 123, loss 0.4250590205192566, acc=0.8666666746139526, loss=0.4250590205192566
train: epoch 124, loss 0.14606045186519623, acc=0.9530555605888367, loss=0.14606045186519623
test: epoch 124, loss 0.4834989011287689, acc=0.8638888597488403, loss=0.4834989011287689
train: epoch 125, loss 0.12360454350709915, acc=0.9600555300712585, loss=0.12360454350709915
test: epoch 125, loss 0.4033624231815338, acc=0.8666666746139526, loss=0.4033624231815338
train: epoch 126, loss 0.12393000721931458, acc=0.9620555639266968, loss=0.12393000721931458
test: epoch 126, loss 0.48087963461875916, acc=0.8666666746139526, loss=0.48087963461875916
train: epoch 127, loss 0.13153894245624542, acc=0.956166684627533, loss=0.13153894245624542
test: epoch 127, loss 0.5085198283195496, acc=0.8666666746139526, loss=0.5085198283195496
train: epoch 128, loss 0.1349451243877411, acc=0.957444429397583, loss=0.1349451243877411
test: epoch 128, loss 0.4685323238372803, acc=0.8666666746139526, loss=0.4685323238372803
train: epoch 129, loss 0.1452339142560959, acc=0.9554444551467896, loss=0.1452339142560959
test: epoch 129, loss 0.4324568212032318, acc=0.8666666746139526, loss=0.4324568212032318
train: epoch 130, loss 0.12133725732564926, acc=0.9622777700424194, loss=0.12133725732564926
test: epoch 130, loss 0.49198049306869507, acc=0.8666666746139526, loss=0.49198049306869507
train: epoch 131, loss 0.1326708197593689, acc=0.9562222361564636, loss=0.1326708197593689
test: epoch 131, loss 0.34579649567604065, acc=0.8694444298744202, loss=0.34579649567604065
train: epoch 132, loss 0.14368434250354767, acc=0.9544444680213928, loss=0.14368434250354767
test: epoch 132, loss 0.32919469475746155, acc=0.8694444298744202, loss=0.32919469475746155
train: epoch 133, loss 0.1386919617652893, acc=0.9541666507720947, loss=0.1386919617652893
test: epoch 133, loss 0.4808318316936493, acc=0.8583333492279053, loss=0.4808318316936493
train: epoch 134, loss 0.13501369953155518, acc=0.9575555324554443, loss=0.13501369953155518
test: epoch 134, loss 0.43155205249786377, acc=0.8666666746139526, loss=0.43155205249786377
train: epoch 135, loss 0.12272395193576813, acc=0.960277795791626, loss=0.12272395193576813
test: epoch 135, loss 0.4346018135547638, acc=0.8666666746139526, loss=0.4346018135547638
train: epoch 136, loss 0.12366306781768799, acc=0.9595000147819519, loss=0.12366306781768799
test: epoch 136, loss 0.4446857273578644, acc=0.8666666746139526, loss=0.4446857273578644
train: epoch 137, loss 0.12485811859369278, acc=0.960277795791626, loss=0.12485811859369278
test: epoch 137, loss 0.392073392868042, acc=0.8666666746139526, loss=0.392073392868042
train: epoch 138, loss 0.1288495659828186, acc=0.9581666588783264, loss=0.1288495659828186
test: epoch 138, loss 0.3382370173931122, acc=0.8666666746139526, loss=0.3382370173931122
train: epoch 139, loss 0.1358368843793869, acc=0.9558888673782349, loss=0.1358368843793869
test: epoch 139, loss 0.3809131383895874, acc=0.8666666746139526, loss=0.3809131383895874
train: epoch 140, loss 0.1258379966020584, acc=0.9586666822433472, loss=0.1258379966020584
test: epoch 140, loss 0.42151567339897156, acc=0.8777777552604675, loss=0.42151567339897156
train: epoch 141, loss 0.11871994286775589, acc=0.9628888964653015, loss=0.11871994286775589
test: epoch 141, loss 0.3563643991947174, acc=0.8666666746139526, loss=0.3563643991947174
train: epoch 142, loss 0.12183835357427597, acc=0.960444450378418, loss=0.12183835357427597
test: epoch 142, loss 0.4429825246334076, acc=0.8666666746139526, loss=0.4429825246334076
train: epoch 143, loss 0.1205388531088829, acc=0.9606666564941406, loss=0.1205388531088829
test: epoch 143, loss 0.5173578858375549, acc=0.8638888597488403, loss=0.5173578858375549
train: epoch 144, loss 0.11316300928592682, acc=0.9644444584846497, loss=0.11316300928592682
test: epoch 144, loss 0.5089894533157349, acc=0.8638888597488403, loss=0.5089894533157349
train: epoch 145, loss 0.1245829313993454, acc=0.9601110816001892, loss=0.1245829313993454
test: epoch 145, loss 0.35900354385375977, acc=0.8833333253860474, loss=0.35900354385375977
train: epoch 146, loss 0.12577280402183533, acc=0.9599999785423279, loss=0.12577280402183533
test: epoch 146, loss 0.5804957747459412, acc=0.8472222089767456, loss=0.5804957747459412
train: epoch 147, loss 0.1185830682516098, acc=0.9622777700424194, loss=0.1185830682516098
test: epoch 147, loss 0.5214155912399292, acc=0.8666666746139526, loss=0.5214155912399292
train: epoch 148, loss 0.12646791338920593, acc=0.9598888754844666, loss=0.12646791338920593
test: epoch 148, loss 0.3609836995601654, acc=0.8833333253860474, loss=0.3609836995601654
train: epoch 149, loss 0.12955261766910553, acc=0.9611111283302307, loss=0.12955261766910553
test: epoch 149, loss 0.369590163230896, acc=0.8833333253860474, loss=0.369590163230896
train: epoch 150, loss 0.09884881228208542, acc=0.968500018119812, loss=0.09884881228208542
test: epoch 150, loss 0.4102350175380707, acc=0.8833333253860474, loss=0.4102350175380707
