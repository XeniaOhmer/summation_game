# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=1", "--temp_decay=1", "--one_hot=0", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=975848852, receiver_embed_dim=128, save_run=0, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=975848852, receiver_embed_dim=128, save_run=False, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.8519372940063477, acc=0.0916111096739769, loss=2.8519372940063477
test: epoch 1, loss 2.8725593090057373, acc=0.08888889104127884, loss=2.8725593090057373
train: epoch 2, loss 2.344597339630127, acc=0.16005556285381317, loss=2.344597339630127
test: epoch 2, loss 2.5740368366241455, acc=0.13333334028720856, loss=2.5740368366241455
train: epoch 3, loss 2.145636796951294, acc=0.20116665959358215, loss=2.145636796951294
test: epoch 3, loss 2.410421371459961, acc=0.14166666567325592, loss=2.410421371459961
train: epoch 4, loss 2.000898838043213, acc=0.23044444620609283, loss=2.000898838043213
test: epoch 4, loss 2.5212771892547607, acc=0.14166666567325592, loss=2.5212771892547607
train: epoch 5, loss 1.8781461715698242, acc=0.26883333921432495, loss=1.8781461715698242
test: epoch 5, loss 2.5434954166412354, acc=0.1111111119389534, loss=2.5434954166412354
train: epoch 6, loss 1.8411022424697876, acc=0.2737777829170227, loss=1.8411022424697876
test: epoch 6, loss 2.5079574584960938, acc=0.15833333134651184, loss=2.5079574584960938
train: epoch 7, loss 1.7296621799468994, acc=0.30399999022483826, loss=1.7296621799468994
test: epoch 7, loss 2.2657647132873535, acc=0.16111111640930176, loss=2.2657647132873535
train: epoch 8, loss 1.678320050239563, acc=0.3237777650356293, loss=1.678320050239563
test: epoch 8, loss 2.2329230308532715, acc=0.15833333134651184, loss=2.2329230308532715
train: epoch 9, loss 1.636276364326477, acc=0.3398333191871643, loss=1.636276364326477
test: epoch 9, loss 2.3159232139587402, acc=0.13611111044883728, loss=2.3159232139587402
train: epoch 10, loss 1.6011602878570557, acc=0.34655556082725525, loss=1.6011602878570557
test: epoch 10, loss 2.240495443344116, acc=0.21666666865348816, loss=2.240495443344116
train: epoch 11, loss 1.5487641096115112, acc=0.37361112236976624, loss=1.5487641096115112
test: epoch 11, loss 2.207204818725586, acc=0.17777778208255768, loss=2.207204818725586
train: epoch 12, loss 1.5221614837646484, acc=0.3781111240386963, loss=1.5221614837646484
test: epoch 12, loss 2.0850765705108643, acc=0.2361111044883728, loss=2.0850765705108643
train: epoch 13, loss 1.479660153388977, acc=0.39311110973358154, loss=1.479660153388977
test: epoch 13, loss 1.969663143157959, acc=0.21388888359069824, loss=1.969663143157959
train: epoch 14, loss 1.4536696672439575, acc=0.40638887882232666, loss=1.4536696672439575
test: epoch 14, loss 2.1699209213256836, acc=0.18333333730697632, loss=2.1699209213256836
train: epoch 15, loss 1.4034843444824219, acc=0.4256666600704193, loss=1.4034843444824219
test: epoch 15, loss 2.1111366748809814, acc=0.1944444477558136, loss=2.1111366748809814
train: epoch 16, loss 1.387162446975708, acc=0.4311666786670685, loss=1.387162446975708
test: epoch 16, loss 2.072913646697998, acc=0.2222222238779068, loss=2.072913646697998
train: epoch 17, loss 1.3437621593475342, acc=0.44749999046325684, loss=1.3437621593475342
test: epoch 17, loss 2.1052920818328857, acc=0.20555555820465088, loss=2.1052920818328857
train: epoch 18, loss 1.3138413429260254, acc=0.45750001072883606, loss=1.3138413429260254
test: epoch 18, loss 2.2142932415008545, acc=0.18888889253139496, loss=2.2142932415008545
train: epoch 19, loss 1.2927082777023315, acc=0.47111111879348755, loss=1.2927082777023315
test: epoch 19, loss 1.9882385730743408, acc=0.25555557012557983, loss=1.9882385730743408
train: epoch 20, loss 1.2694039344787598, acc=0.47466665506362915, loss=1.2694039344787598
test: epoch 20, loss 2.0067949295043945, acc=0.2222222238779068, loss=2.0067949295043945
train: epoch 21, loss 1.2454421520233154, acc=0.48661109805107117, loss=1.2454421520233154
test: epoch 21, loss 2.1014232635498047, acc=0.25833332538604736, loss=2.1014232635498047
train: epoch 22, loss 1.2066264152526855, acc=0.5017777681350708, loss=1.2066264152526855
test: epoch 22, loss 2.1098203659057617, acc=0.19722221791744232, loss=2.1098203659057617
train: epoch 23, loss 1.20829176902771, acc=0.5006111264228821, loss=1.20829176902771
test: epoch 23, loss 1.9169811010360718, acc=0.2527777850627899, loss=1.9169811010360718
train: epoch 24, loss 1.1910403966903687, acc=0.5027777552604675, loss=1.1910403966903687
test: epoch 24, loss 1.9419928789138794, acc=0.30000001192092896, loss=1.9419928789138794
train: epoch 25, loss 1.171301007270813, acc=0.5230000019073486, loss=1.171301007270813
test: epoch 25, loss 1.8490370512008667, acc=0.28333333134651184, loss=1.8490370512008667
train: epoch 26, loss 1.1454449892044067, acc=0.5239999890327454, loss=1.1454449892044067
test: epoch 26, loss 1.9502092599868774, acc=0.25833332538604736, loss=1.9502092599868774
train: epoch 27, loss 1.1224764585494995, acc=0.5358333587646484, loss=1.1224764585494995
test: epoch 27, loss 1.852403998374939, acc=0.3027777671813965, loss=1.852403998374939
train: epoch 28, loss 1.1186283826828003, acc=0.5386666655540466, loss=1.1186283826828003
test: epoch 28, loss 2.029064893722534, acc=0.2888889014720917, loss=2.029064893722534
train: epoch 29, loss 1.0922372341156006, acc=0.5487777590751648, loss=1.0922372341156006
test: epoch 29, loss 1.8995612859725952, acc=0.27222222089767456, loss=1.8995612859725952
train: epoch 30, loss 1.083174467086792, acc=0.5506666898727417, loss=1.083174467086792
test: epoch 30, loss 1.9604952335357666, acc=0.29722222685813904, loss=1.9604952335357666
train: epoch 31, loss 1.0696910619735718, acc=0.5571666955947876, loss=1.0696910619735718
test: epoch 31, loss 2.075592517852783, acc=0.24722221493721008, loss=2.075592517852783
train: epoch 32, loss 1.0679512023925781, acc=0.5625555515289307, loss=1.0679512023925781
test: epoch 32, loss 2.0027754306793213, acc=0.25555557012557983, loss=2.0027754306793213
train: epoch 33, loss 1.0532809495925903, acc=0.5725555419921875, loss=1.0532809495925903
test: epoch 33, loss 1.8537657260894775, acc=0.3222222328186035, loss=1.8537657260894775
train: epoch 34, loss 1.0221244096755981, acc=0.5836111307144165, loss=1.0221244096755981
test: epoch 34, loss 1.8304768800735474, acc=0.2666666805744171, loss=1.8304768800735474
train: epoch 35, loss 1.020349144935608, acc=0.5789444446563721, loss=1.020349144935608
test: epoch 35, loss 1.9888336658477783, acc=0.29722222685813904, loss=1.9888336658477783
train: epoch 36, loss 1.0165555477142334, acc=0.5851666927337646, loss=1.0165555477142334
test: epoch 36, loss 2.0292985439300537, acc=0.25555557012557983, loss=2.0292985439300537
train: epoch 37, loss 0.9998413324356079, acc=0.5932222008705139, loss=0.9998413324356079
test: epoch 37, loss 1.9974923133850098, acc=0.28611111640930176, loss=1.9974923133850098
train: epoch 38, loss 0.9947877526283264, acc=0.5927777886390686, loss=0.9947877526283264
test: epoch 38, loss 1.8731067180633545, acc=0.2916666567325592, loss=1.8731067180633545
train: epoch 39, loss 0.9892001748085022, acc=0.5896111130714417, loss=0.9892001748085022
test: epoch 39, loss 2.016339063644409, acc=0.25555557012557983, loss=2.016339063644409
train: epoch 40, loss 0.9794156551361084, acc=0.601277768611908, loss=0.9794156551361084
test: epoch 40, loss 1.9866048097610474, acc=0.24444444477558136, loss=1.9866048097610474
train: epoch 41, loss 0.9690404534339905, acc=0.5994444489479065, loss=0.9690404534339905
test: epoch 41, loss 2.316523551940918, acc=0.2361111044883728, loss=2.316523551940918
train: epoch 42, loss 0.9578502178192139, acc=0.6071666479110718, loss=0.9578502178192139
test: epoch 42, loss 1.847818374633789, acc=0.2805555462837219, loss=1.847818374633789
train: epoch 43, loss 0.9428948760032654, acc=0.616944432258606, loss=0.9428948760032654
test: epoch 43, loss 1.8740482330322266, acc=0.31111112236976624, loss=1.8740482330322266
train: epoch 44, loss 0.9351804852485657, acc=0.6174444556236267, loss=0.9351804852485657
test: epoch 44, loss 2.040097713470459, acc=0.2527777850627899, loss=2.040097713470459
train: epoch 45, loss 0.9231619834899902, acc=0.6211666464805603, loss=0.9231619834899902
test: epoch 45, loss 1.8987735509872437, acc=0.28333333134651184, loss=1.8987735509872437
train: epoch 46, loss 0.9271304607391357, acc=0.6188333630561829, loss=0.9271304607391357
test: epoch 46, loss 1.7549147605895996, acc=0.26944443583488464, loss=1.7549147605895996
train: epoch 47, loss 0.9015929102897644, acc=0.632111132144928, loss=0.9015929102897644
test: epoch 47, loss 2.049940586090088, acc=0.3083333373069763, loss=2.049940586090088
train: epoch 48, loss 0.9014735817909241, acc=0.6306666731834412, loss=0.9014735817909241
test: epoch 48, loss 1.6952850818634033, acc=0.3027777671813965, loss=1.6952850818634033
train: epoch 49, loss 0.9090430736541748, acc=0.6286110877990723, loss=0.9090430736541748
test: epoch 49, loss 1.9422601461410522, acc=0.26944443583488464, loss=1.9422601461410522
train: epoch 50, loss 0.8972729444503784, acc=0.6331111192703247, loss=0.8972729444503784
test: epoch 50, loss 2.0318427085876465, acc=0.26944443583488464, loss=2.0318427085876465
train: epoch 51, loss 0.8839051723480225, acc=0.6410555839538574, loss=0.8839051723480225
test: epoch 51, loss 1.7383511066436768, acc=0.3166666626930237, loss=1.7383511066436768
train: epoch 52, loss 0.8843305110931396, acc=0.6391111016273499, loss=0.8843305110931396
test: epoch 52, loss 1.9631578922271729, acc=0.28611111640930176, loss=1.9631578922271729
train: epoch 53, loss 0.8759293556213379, acc=0.6473333239555359, loss=0.8759293556213379
test: epoch 53, loss 1.8198318481445312, acc=0.3472222089767456, loss=1.8198318481445312
train: epoch 54, loss 0.8745499849319458, acc=0.6416666507720947, loss=0.8745499849319458
test: epoch 54, loss 2.0326931476593018, acc=0.28333333134651184, loss=2.0326931476593018
train: epoch 55, loss 0.8540512323379517, acc=0.6533889174461365, loss=0.8540512323379517
test: epoch 55, loss 1.829777717590332, acc=0.26944443583488464, loss=1.829777717590332
train: epoch 56, loss 0.841474175453186, acc=0.6610000133514404, loss=0.841474175453186
test: epoch 56, loss 2.1587047576904297, acc=0.3194444477558136, loss=2.1587047576904297
train: epoch 57, loss 0.8430778980255127, acc=0.6612777709960938, loss=0.8430778980255127
test: epoch 57, loss 1.9542886018753052, acc=0.31111112236976624, loss=1.9542886018753052
train: epoch 58, loss 0.8391490578651428, acc=0.6580555438995361, loss=0.8391490578651428
test: epoch 58, loss 1.9432387351989746, acc=0.3166666626930237, loss=1.9432387351989746
train: epoch 59, loss 0.8324922919273376, acc=0.6621666550636292, loss=0.8324922919273376
test: epoch 59, loss 1.7793819904327393, acc=0.3361110985279083, loss=1.7793819904327393
train: epoch 60, loss 0.8526222705841064, acc=0.6537777781486511, loss=0.8526222705841064
test: epoch 60, loss 2.051927089691162, acc=0.30000001192092896, loss=2.051927089691162
train: epoch 61, loss 0.8072755932807922, acc=0.6699444651603699, loss=0.8072755932807922
test: epoch 61, loss 1.9661028385162354, acc=0.3333333432674408, loss=1.9661028385162354
train: epoch 62, loss 0.8128368258476257, acc=0.6674444675445557, loss=0.8128368258476257
test: epoch 62, loss 1.8806583881378174, acc=0.31111112236976624, loss=1.8806583881378174
train: epoch 63, loss 0.8200012445449829, acc=0.6694999933242798, loss=0.8200012445449829
test: epoch 63, loss 1.832510232925415, acc=0.32777777314186096, loss=1.832510232925415
train: epoch 64, loss 0.8071065545082092, acc=0.6666666865348816, loss=0.8071065545082092
test: epoch 64, loss 2.0632519721984863, acc=0.25555557012557983, loss=2.0632519721984863
train: epoch 65, loss 0.8093380928039551, acc=0.6690555810928345, loss=0.8093380928039551
test: epoch 65, loss 1.9418888092041016, acc=0.31111112236976624, loss=1.9418888092041016
train: epoch 66, loss 0.8048112988471985, acc=0.6696110963821411, loss=0.8048112988471985
test: epoch 66, loss 1.9438154697418213, acc=0.3027777671813965, loss=1.9438154697418213
train: epoch 67, loss 0.805761456489563, acc=0.6692222356796265, loss=0.805761456489563
test: epoch 67, loss 1.843703269958496, acc=0.36666667461395264, loss=1.843703269958496
train: epoch 68, loss 0.7885866165161133, acc=0.6752222180366516, loss=0.7885866165161133
test: epoch 68, loss 2.001868963241577, acc=0.3055555522441864, loss=2.001868963241577
train: epoch 69, loss 0.7886286377906799, acc=0.6767777800559998, loss=0.7886286377906799
test: epoch 69, loss 2.858915328979492, acc=0.22777777910232544, loss=2.858915328979492
train: epoch 70, loss 0.7635707259178162, acc=0.6875, loss=0.7635707259178162
test: epoch 70, loss 2.0212812423706055, acc=0.3722222149372101, loss=2.0212812423706055
train: epoch 71, loss 0.7758548855781555, acc=0.6815000176429749, loss=0.7758548855781555
test: epoch 71, loss 2.2378125190734863, acc=0.25555557012557983, loss=2.2378125190734863
train: epoch 72, loss 0.7595070004463196, acc=0.6848888993263245, loss=0.7595070004463196
test: epoch 72, loss 1.8226993083953857, acc=0.3333333432674408, loss=1.8226993083953857
train: epoch 73, loss 0.7463416457176208, acc=0.6973333358764648, loss=0.7463416457176208
test: epoch 73, loss 2.023543119430542, acc=0.3305555582046509, loss=2.023543119430542
train: epoch 74, loss 0.761046826839447, acc=0.6883888840675354, loss=0.761046826839447
test: epoch 74, loss 2.1500935554504395, acc=0.3055555522441864, loss=2.1500935554504395
train: epoch 75, loss 0.7493103742599487, acc=0.6950555443763733, loss=0.7493103742599487
test: epoch 75, loss 2.204902172088623, acc=0.3166666626930237, loss=2.204902172088623
train: epoch 76, loss 0.7517312169075012, acc=0.6944444179534912, loss=0.7517312169075012
test: epoch 76, loss 1.9770132303237915, acc=0.33888888359069824, loss=1.9770132303237915
train: epoch 77, loss 0.7483344674110413, acc=0.6953333616256714, loss=0.7483344674110413
test: epoch 77, loss 1.9778521060943604, acc=0.31388887763023376, loss=1.9778521060943604
train: epoch 78, loss 0.7377021312713623, acc=0.7006666660308838, loss=0.7377021312713623
test: epoch 78, loss 2.2188992500305176, acc=0.3444444537162781, loss=2.2188992500305176
train: epoch 79, loss 0.7334383130073547, acc=0.6988333463668823, loss=0.7334383130073547
test: epoch 79, loss 1.7430418729782104, acc=0.3611111044883728, loss=1.7430418729782104
train: epoch 80, loss 0.73170405626297, acc=0.7045555710792542, loss=0.73170405626297
test: epoch 80, loss 1.9613542556762695, acc=0.2750000059604645, loss=1.9613542556762695
train: epoch 81, loss 0.7189046740531921, acc=0.7062777876853943, loss=0.7189046740531921
test: epoch 81, loss 2.372140645980835, acc=0.3166666626930237, loss=2.372140645980835
train: epoch 82, loss 0.7131790518760681, acc=0.7120000123977661, loss=0.7131790518760681
test: epoch 82, loss 2.196650266647339, acc=0.31388887763023376, loss=2.196650266647339
train: epoch 83, loss 0.7089871168136597, acc=0.714388906955719, loss=0.7089871168136597
test: epoch 83, loss 1.948660969734192, acc=0.3444444537162781, loss=1.948660969734192
train: epoch 84, loss 0.7106438875198364, acc=0.7159444689750671, loss=0.7106438875198364
test: epoch 84, loss 1.8226412534713745, acc=0.3861111104488373, loss=1.8226412534713745
train: epoch 85, loss 0.7063109278678894, acc=0.7143333554267883, loss=0.7063109278678894
test: epoch 85, loss 1.9490299224853516, acc=0.35277777910232544, loss=1.9490299224853516
train: epoch 86, loss 0.7137424945831299, acc=0.7137777805328369, loss=0.7137424945831299
test: epoch 86, loss 1.9558225870132446, acc=0.3361110985279083, loss=1.9558225870132446
train: epoch 87, loss 0.6911271810531616, acc=0.7242222428321838, loss=0.6911271810531616
test: epoch 87, loss 1.8950002193450928, acc=0.3444444537162781, loss=1.8950002193450928
train: epoch 88, loss 0.7065345644950867, acc=0.7154444456100464, loss=0.7065345644950867
test: epoch 88, loss 1.793952465057373, acc=0.3499999940395355, loss=1.793952465057373
train: epoch 89, loss 0.6904374361038208, acc=0.7278333306312561, loss=0.6904374361038208
test: epoch 89, loss 2.019787549972534, acc=0.38333332538604736, loss=2.019787549972534
train: epoch 90, loss 0.700051486492157, acc=0.7183889150619507, loss=0.700051486492157
test: epoch 90, loss 2.0508737564086914, acc=0.35277777910232544, loss=2.0508737564086914
train: epoch 91, loss 0.693700909614563, acc=0.7211111187934875, loss=0.693700909614563
test: epoch 91, loss 1.8515740633010864, acc=0.35277777910232544, loss=1.8515740633010864
train: epoch 92, loss 0.6898531913757324, acc=0.7211666703224182, loss=0.6898531913757324
test: epoch 92, loss 1.9761778116226196, acc=0.35277777910232544, loss=1.9761778116226196
train: epoch 93, loss 0.6757587194442749, acc=0.7280555367469788, loss=0.6757587194442749
test: epoch 93, loss 1.9395172595977783, acc=0.3166666626930237, loss=1.9395172595977783
train: epoch 94, loss 0.669678270816803, acc=0.7330555319786072, loss=0.669678270816803
test: epoch 94, loss 2.3335022926330566, acc=0.3861111104488373, loss=2.3335022926330566
train: epoch 95, loss 0.682350754737854, acc=0.72688889503479, loss=0.682350754737854
test: epoch 95, loss 2.0242812633514404, acc=0.3499999940395355, loss=2.0242812633514404
train: epoch 96, loss 0.6750102043151855, acc=0.7303333282470703, loss=0.6750102043151855
test: epoch 96, loss 1.9331563711166382, acc=0.35277777910232544, loss=1.9331563711166382
train: epoch 97, loss 0.671245276927948, acc=0.731166660785675, loss=0.671245276927948
test: epoch 97, loss 2.1609702110290527, acc=0.3361110985279083, loss=2.1609702110290527
train: epoch 98, loss 0.6734423637390137, acc=0.7303333282470703, loss=0.6734423637390137
test: epoch 98, loss 2.018723487854004, acc=0.30000001192092896, loss=2.018723487854004
train: epoch 99, loss 0.6545641422271729, acc=0.7348889112472534, loss=0.6545641422271729
test: epoch 99, loss 2.1457266807556152, acc=0.31388887763023376, loss=2.1457266807556152
train: epoch 100, loss 0.6639648079872131, acc=0.730055570602417, loss=0.6639648079872131
test: epoch 100, loss 1.932643175125122, acc=0.3722222149372101, loss=1.932643175125122
train: epoch 101, loss 0.6622136831283569, acc=0.7366111278533936, loss=0.6622136831283569
test: epoch 101, loss 2.0476667881011963, acc=0.4027777910232544, loss=2.0476667881011963
train: epoch 102, loss 0.6529260873794556, acc=0.738611102104187, loss=0.6529260873794556
test: epoch 102, loss 1.974244236946106, acc=0.3611111044883728, loss=1.974244236946106
train: epoch 103, loss 0.6522094011306763, acc=0.7378888726234436, loss=0.6522094011306763
test: epoch 103, loss 1.9887821674346924, acc=0.3499999940395355, loss=1.9887821674346924
train: epoch 104, loss 0.6696323752403259, acc=0.7318888902664185, loss=0.6696323752403259
test: epoch 104, loss 1.815619945526123, acc=0.3861111104488373, loss=1.815619945526123
train: epoch 105, loss 0.647678017616272, acc=0.7379999756813049, loss=0.647678017616272
test: epoch 105, loss 2.240037679672241, acc=0.32499998807907104, loss=2.240037679672241
train: epoch 106, loss 0.6587951183319092, acc=0.7363888621330261, loss=0.6587951183319092
test: epoch 106, loss 1.7230058908462524, acc=0.3722222149372101, loss=1.7230058908462524
train: epoch 107, loss 0.6465169191360474, acc=0.7356111407279968, loss=0.6465169191360474
test: epoch 107, loss 2.0863287448883057, acc=0.32777777314186096, loss=2.0863287448883057
train: epoch 108, loss 0.6377004384994507, acc=0.7463333606719971, loss=0.6377004384994507
test: epoch 108, loss 2.030498743057251, acc=0.3055555522441864, loss=2.030498743057251
train: epoch 109, loss 0.6607697606086731, acc=0.730222225189209, loss=0.6607697606086731
test: epoch 109, loss 1.9486054182052612, acc=0.3472222089767456, loss=1.9486054182052612
train: epoch 110, loss 0.6417216658592224, acc=0.7396666407585144, loss=0.6417216658592224
test: epoch 110, loss 2.129910945892334, acc=0.3305555582046509, loss=2.129910945892334
train: epoch 111, loss 0.6434746384620667, acc=0.7408333420753479, loss=0.6434746384620667
test: epoch 111, loss 1.9545234441757202, acc=0.3888888955116272, loss=1.9545234441757202
train: epoch 112, loss 0.6364034414291382, acc=0.7433333396911621, loss=0.6364034414291382
test: epoch 112, loss 1.8549752235412598, acc=0.38055557012557983, loss=1.8549752235412598
train: epoch 113, loss 0.6242764592170715, acc=0.7451666593551636, loss=0.6242764592170715
test: epoch 113, loss 2.0780158042907715, acc=0.32777777314186096, loss=2.0780158042907715
train: epoch 114, loss 0.6528593301773071, acc=0.7417222261428833, loss=0.6528593301773071
test: epoch 114, loss 2.80130934715271, acc=0.31388887763023376, loss=2.80130934715271
train: epoch 115, loss 0.6350150108337402, acc=0.7406111359596252, loss=0.6350150108337402
test: epoch 115, loss 2.2050797939300537, acc=0.3444444537162781, loss=2.2050797939300537
train: epoch 116, loss 0.6305935978889465, acc=0.7443888783454895, loss=0.6305935978889465
test: epoch 116, loss 2.146144390106201, acc=0.38055557012557983, loss=2.146144390106201
train: epoch 117, loss 0.6187355518341064, acc=0.7492777705192566, loss=0.6187355518341064
test: epoch 117, loss 2.3057737350463867, acc=0.3444444537162781, loss=2.3057737350463867
train: epoch 118, loss 0.6220008134841919, acc=0.7506666779518127, loss=0.6220008134841919
test: epoch 118, loss 2.0379726886749268, acc=0.35277777910232544, loss=2.0379726886749268
train: epoch 119, loss 0.616966724395752, acc=0.7493333220481873, loss=0.616966724395752
test: epoch 119, loss 1.9526957273483276, acc=0.35277777910232544, loss=1.9526957273483276
train: epoch 120, loss 0.6192252039909363, acc=0.7463333606719971, loss=0.6192252039909363
test: epoch 120, loss 2.178842067718506, acc=0.2944444417953491, loss=2.178842067718506
train: epoch 121, loss 0.6245118379592896, acc=0.7468888759613037, loss=0.6245118379592896
test: epoch 121, loss 1.9944713115692139, acc=0.3638888895511627, loss=1.9944713115692139
train: epoch 122, loss 0.6109573245048523, acc=0.753944456577301, loss=0.6109573245048523
test: epoch 122, loss 2.2048499584198, acc=0.3194444477558136, loss=2.2048499584198
train: epoch 123, loss 0.6118772029876709, acc=0.7524999976158142, loss=0.6118772029876709
test: epoch 123, loss 2.0518910884857178, acc=0.3861111104488373, loss=2.0518910884857178
train: epoch 124, loss 0.6244592070579529, acc=0.7453888654708862, loss=0.6244592070579529
test: epoch 124, loss 2.1294760704040527, acc=0.36666667461395264, loss=2.1294760704040527
train: epoch 125, loss 0.6219006776809692, acc=0.7487778067588806, loss=0.6219006776809692
test: epoch 125, loss 2.2416555881500244, acc=0.41111111640930176, loss=2.2416555881500244
train: epoch 126, loss 0.6284472346305847, acc=0.7466111183166504, loss=0.6284472346305847
test: epoch 126, loss 2.0401573181152344, acc=0.3499999940395355, loss=2.0401573181152344
train: epoch 127, loss 0.6143909096717834, acc=0.7527777552604675, loss=0.6143909096717834
test: epoch 127, loss 1.9542430639266968, acc=0.4055555462837219, loss=1.9542430639266968
train: epoch 128, loss 0.6075793504714966, acc=0.7534444332122803, loss=0.6075793504714966
test: epoch 128, loss 2.2620444297790527, acc=0.3861111104488373, loss=2.2620444297790527
train: epoch 129, loss 0.6029613018035889, acc=0.7598888874053955, loss=0.6029613018035889
test: epoch 129, loss 1.909934163093567, acc=0.40833333134651184, loss=1.909934163093567
train: epoch 130, loss 0.6048049926757812, acc=0.7549444437026978, loss=0.6048049926757812
test: epoch 130, loss 2.209325075149536, acc=0.31111112236976624, loss=2.209325075149536
train: epoch 131, loss 0.6206945776939392, acc=0.7519999742507935, loss=0.6206945776939392
test: epoch 131, loss 1.9856173992156982, acc=0.4305555522441864, loss=1.9856173992156982
train: epoch 132, loss 0.6250086426734924, acc=0.7473333477973938, loss=0.6250086426734924
test: epoch 132, loss 1.8736196756362915, acc=0.4166666567325592, loss=1.8736196756362915
train: epoch 133, loss 0.5964037179946899, acc=0.7584999799728394, loss=0.5964037179946899
test: epoch 133, loss 1.9808838367462158, acc=0.3638888895511627, loss=1.9808838367462158
train: epoch 134, loss 0.6110941171646118, acc=0.7483888864517212, loss=0.6110941171646118
test: epoch 134, loss 2.1493895053863525, acc=0.31388887763023376, loss=2.1493895053863525
train: epoch 135, loss 0.6062462329864502, acc=0.7547222375869751, loss=0.6062462329864502
test: epoch 135, loss 1.8746963739395142, acc=0.3861111104488373, loss=1.8746963739395142
train: epoch 136, loss 0.6000619530677795, acc=0.7611111402511597, loss=0.6000619530677795
test: epoch 136, loss 2.3143532276153564, acc=0.34166666865348816, loss=2.3143532276153564
train: epoch 137, loss 0.5947620868682861, acc=0.7559444308280945, loss=0.5947620868682861
test: epoch 137, loss 2.022947072982788, acc=0.38055557012557983, loss=2.022947072982788
train: epoch 138, loss 0.5985617637634277, acc=0.7592777609825134, loss=0.5985617637634277
test: epoch 138, loss 1.915157437324524, acc=0.3611111044883728, loss=1.915157437324524
train: epoch 139, loss 0.5974652767181396, acc=0.7591666579246521, loss=0.5974652767181396
test: epoch 139, loss 1.7976795434951782, acc=0.4027777910232544, loss=1.7976795434951782
train: epoch 140, loss 0.5938434600830078, acc=0.7574999928474426, loss=0.5938434600830078
test: epoch 140, loss 2.020465850830078, acc=0.42222222685813904, loss=2.020465850830078
train: epoch 141, loss 0.5863227248191833, acc=0.7610555291175842, loss=0.5863227248191833
test: epoch 141, loss 2.0761959552764893, acc=0.3611111044883728, loss=2.0761959552764893
train: epoch 142, loss 0.5927562713623047, acc=0.7590555548667908, loss=0.5927562713623047
test: epoch 142, loss 2.1444451808929443, acc=0.3916666805744171, loss=2.1444451808929443
train: epoch 143, loss 0.6071451902389526, acc=0.7570555806159973, loss=0.6071451902389526
test: epoch 143, loss 2.721205472946167, acc=0.2638888955116272, loss=2.721205472946167
train: epoch 144, loss 0.6099810004234314, acc=0.7508333325386047, loss=0.6099810004234314
test: epoch 144, loss 1.9721171855926514, acc=0.4055555462837219, loss=1.9721171855926514
train: epoch 145, loss 0.5934931635856628, acc=0.757888913154602, loss=0.5934931635856628
test: epoch 145, loss 1.882296085357666, acc=0.36666667461395264, loss=1.882296085357666
train: epoch 146, loss 0.5905603170394897, acc=0.7561110854148865, loss=0.5905603170394897
test: epoch 146, loss 2.381260395050049, acc=0.3361110985279083, loss=2.381260395050049
train: epoch 147, loss 0.5955316424369812, acc=0.7566111087799072, loss=0.5955316424369812
test: epoch 147, loss 2.0953094959259033, acc=0.42500001192092896, loss=2.0953094959259033
train: epoch 148, loss 0.6094502806663513, acc=0.7443888783454895, loss=0.6094502806663513
test: epoch 148, loss 2.196892023086548, acc=0.3722222149372101, loss=2.196892023086548
train: epoch 149, loss 0.5870414972305298, acc=0.7563889026641846, loss=0.5870414972305298
test: epoch 149, loss 1.9279851913452148, acc=0.4138889014720917, loss=1.9279851913452148
train: epoch 150, loss 0.5862676501274109, acc=0.7573888897895813, loss=0.5862676501274109
test: epoch 150, loss 2.243716239929199, acc=0.38333332538604736, loss=2.243716239929199
