# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1", "--temp_decay=0.995", "--one_hot=false", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=414157277, receiver_embed_dim=32, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.1675305366516113, acc=0.06866666674613953, loss=3.1675305366516113
test: epoch 1, loss 2.63006591796875, acc=0.11388888955116272, loss=2.63006591796875
train: epoch 2, loss 2.2637245655059814, acc=0.189277783036232, loss=2.2637245655059814
test: epoch 2, loss 2.4257776737213135, acc=0.17777778208255768, loss=2.4257776737213135
train: epoch 3, loss 1.9041733741760254, acc=0.2601666748523712, loss=1.9041733741760254
test: epoch 3, loss 2.5117030143737793, acc=0.16944444179534912, loss=2.5117030143737793
train: epoch 4, loss 1.6684861183166504, acc=0.31450000405311584, loss=1.6684861183166504
test: epoch 4, loss 2.1945769786834717, acc=0.25833332538604736, loss=2.1945769786834717
train: epoch 5, loss 1.5053855180740356, acc=0.3766111135482788, loss=1.5053855180740356
test: epoch 5, loss 2.0831210613250732, acc=0.2750000059604645, loss=2.0831210613250732
train: epoch 6, loss 1.3626748323440552, acc=0.42238888144493103, loss=1.3626748323440552
test: epoch 6, loss 2.262404680252075, acc=0.27222222089767456, loss=2.262404680252075
train: epoch 7, loss 1.2174230813980103, acc=0.4735555648803711, loss=1.2174230813980103
test: epoch 7, loss 1.99624502658844, acc=0.28333333134651184, loss=1.99624502658844
train: epoch 8, loss 1.1560595035552979, acc=0.4959999918937683, loss=1.1560595035552979
test: epoch 8, loss 1.9032925367355347, acc=0.3305555582046509, loss=1.9032925367355347
train: epoch 9, loss 1.0505214929580688, acc=0.5453333258628845, loss=1.0505214929580688
test: epoch 9, loss 1.6563873291015625, acc=0.3722222149372101, loss=1.6563873291015625
train: epoch 10, loss 0.9534057974815369, acc=0.5872777700424194, loss=0.9534057974815369
test: epoch 10, loss 1.3958141803741455, acc=0.4138889014720917, loss=1.3958141803741455
train: epoch 11, loss 0.90419602394104, acc=0.6096110939979553, loss=0.90419602394104
test: epoch 11, loss 1.4611586332321167, acc=0.42222222685813904, loss=1.4611586332321167
train: epoch 12, loss 0.8636488914489746, acc=0.6154444217681885, loss=0.8636488914489746
test: epoch 12, loss 1.4836417436599731, acc=0.4305555522441864, loss=1.4836417436599731
train: epoch 13, loss 0.8163597583770752, acc=0.6366666555404663, loss=0.8163597583770752
test: epoch 13, loss 1.4391602277755737, acc=0.4305555522441864, loss=1.4391602277755737
train: epoch 14, loss 0.7970136404037476, acc=0.6450555324554443, loss=0.7970136404037476
test: epoch 14, loss 1.2559500932693481, acc=0.4416666626930237, loss=1.2559500932693481
train: epoch 15, loss 0.7644144296646118, acc=0.6578888893127441, loss=0.7644144296646118
test: epoch 15, loss 1.296550989151001, acc=0.45277777314186096, loss=1.296550989151001
train: epoch 16, loss 0.7567244172096252, acc=0.6614444255828857, loss=0.7567244172096252
test: epoch 16, loss 1.445521593093872, acc=0.4583333432674408, loss=1.445521593093872
train: epoch 17, loss 0.7416617274284363, acc=0.6676666736602783, loss=0.7416617274284363
test: epoch 17, loss 1.3725541830062866, acc=0.45277777314186096, loss=1.3725541830062866
train: epoch 18, loss 0.7162535190582275, acc=0.6744999885559082, loss=0.7162535190582275
test: epoch 18, loss 1.335862636566162, acc=0.4583333432674408, loss=1.335862636566162
train: epoch 19, loss 0.713767409324646, acc=0.6742222309112549, loss=0.713767409324646
test: epoch 19, loss 1.4748001098632812, acc=0.4694444537162781, loss=1.4748001098632812
train: epoch 20, loss 0.6737450957298279, acc=0.6934444308280945, loss=0.6737450957298279
test: epoch 20, loss 1.4835193157196045, acc=0.4583333432674408, loss=1.4835193157196045
train: epoch 21, loss 0.6968939900398254, acc=0.6836110949516296, loss=0.6968939900398254
test: epoch 21, loss 1.1574256420135498, acc=0.4861111044883728, loss=1.1574256420135498
train: epoch 22, loss 0.6861518621444702, acc=0.6861666440963745, loss=0.6861518621444702
test: epoch 22, loss 1.3282089233398438, acc=0.4861111044883728, loss=1.3282089233398438
train: epoch 23, loss 0.6717274785041809, acc=0.690500020980835, loss=0.6717274785041809
test: epoch 23, loss 1.317604422569275, acc=0.48055556416511536, loss=1.317604422569275
train: epoch 24, loss 0.6554893255233765, acc=0.6946666836738586, loss=0.6554893255233765
test: epoch 24, loss 1.3603324890136719, acc=0.4861111044883728, loss=1.3603324890136719
train: epoch 25, loss 0.6520758867263794, acc=0.7006111145019531, loss=0.6520758867263794
test: epoch 25, loss 1.3693710565567017, acc=0.5, loss=1.3693710565567017
train: epoch 26, loss 0.6826248168945312, acc=0.6850000023841858, loss=0.6826248168945312
test: epoch 26, loss 1.3283582925796509, acc=0.5055555701255798, loss=1.3283582925796509
train: epoch 27, loss 0.6233148574829102, acc=0.7128888964653015, loss=0.6233148574829102
test: epoch 27, loss 1.2531603574752808, acc=0.5388888716697693, loss=1.2531603574752808
train: epoch 28, loss 0.5985628366470337, acc=0.7263888716697693, loss=0.5985628366470337
test: epoch 28, loss 1.2675451040267944, acc=0.5444444417953491, loss=1.2675451040267944
train: epoch 29, loss 0.6120362281799316, acc=0.7249444723129272, loss=0.6120362281799316
test: epoch 29, loss 1.385599136352539, acc=0.5055555701255798, loss=1.385599136352539
train: epoch 30, loss 0.5938423275947571, acc=0.7261666655540466, loss=0.5938423275947571
test: epoch 30, loss 1.4691762924194336, acc=0.4861111044883728, loss=1.4691762924194336
train: epoch 31, loss 0.5785388946533203, acc=0.7343888878822327, loss=0.5785388946533203
test: epoch 31, loss 1.1283576488494873, acc=0.5555555820465088, loss=1.1283576488494873
train: epoch 32, loss 0.5881986618041992, acc=0.7288888692855835, loss=0.5881986618041992
test: epoch 32, loss 1.0064297914505005, acc=0.5472221970558167, loss=1.0064297914505005
train: epoch 33, loss 0.5709256529808044, acc=0.737666666507721, loss=0.5709256529808044
test: epoch 33, loss 1.2176412343978882, acc=0.5333333611488342, loss=1.2176412343978882
train: epoch 34, loss 0.5667744874954224, acc=0.737333357334137, loss=0.5667744874954224
test: epoch 34, loss 1.1500922441482544, acc=0.5527777671813965, loss=1.1500922441482544
train: epoch 35, loss 0.6052599549293518, acc=0.726111114025116, loss=0.6052599549293518
test: epoch 35, loss 1.077130913734436, acc=0.5555555820465088, loss=1.077130913734436
train: epoch 36, loss 0.5798036456108093, acc=0.7348333597183228, loss=0.5798036456108093
test: epoch 36, loss 1.2032369375228882, acc=0.5583333373069763, loss=1.2032369375228882
train: epoch 37, loss 0.559903621673584, acc=0.7404444217681885, loss=0.559903621673584
test: epoch 37, loss 1.1828681230545044, acc=0.5583333373069763, loss=1.1828681230545044
train: epoch 38, loss 0.5779003500938416, acc=0.734499990940094, loss=0.5779003500938416
test: epoch 38, loss 1.1684420108795166, acc=0.5611110925674438, loss=1.1684420108795166
train: epoch 39, loss 0.5617942214012146, acc=0.7377777695655823, loss=0.5617942214012146
test: epoch 39, loss 1.2737407684326172, acc=0.5527777671813965, loss=1.2737407684326172
train: epoch 40, loss 0.5835241079330444, acc=0.729888916015625, loss=0.5835241079330444
test: epoch 40, loss 1.2387125492095947, acc=0.5361111164093018, loss=1.2387125492095947
train: epoch 41, loss 0.557081937789917, acc=0.7395555377006531, loss=0.557081937789917
test: epoch 41, loss 1.1543858051300049, acc=0.5611110925674438, loss=1.1543858051300049
train: epoch 42, loss 0.5769312381744385, acc=0.7363888621330261, loss=0.5769312381744385
test: epoch 42, loss 1.1581252813339233, acc=0.5555555820465088, loss=1.1581252813339233
train: epoch 43, loss 0.5538085103034973, acc=0.7396666407585144, loss=0.5538085103034973
test: epoch 43, loss 1.2059074640274048, acc=0.5583333373069763, loss=1.2059074640274048
train: epoch 44, loss 0.5589844584465027, acc=0.7402777671813965, loss=0.5589844584465027
test: epoch 44, loss 1.05015230178833, acc=0.5638889074325562, loss=1.05015230178833
train: epoch 45, loss 0.5582752227783203, acc=0.7396666407585144, loss=0.5582752227783203
test: epoch 45, loss 1.0048490762710571, acc=0.5611110925674438, loss=1.0048490762710571
train: epoch 46, loss 0.5511523485183716, acc=0.7402222156524658, loss=0.5511523485183716
test: epoch 46, loss 1.2581579685211182, acc=0.5555555820465088, loss=1.2581579685211182
train: epoch 47, loss 0.5437602400779724, acc=0.7413333058357239, loss=0.5437602400779724
test: epoch 47, loss 1.1068006753921509, acc=0.5611110925674438, loss=1.1068006753921509
train: epoch 48, loss 0.5538639426231384, acc=0.7411666512489319, loss=0.5538639426231384
test: epoch 48, loss 1.2065538167953491, acc=0.5611110925674438, loss=1.2065538167953491
train: epoch 49, loss 0.5463407039642334, acc=0.742111086845398, loss=0.5463407039642334
test: epoch 49, loss 1.1168227195739746, acc=0.5611110925674438, loss=1.1168227195739746
train: epoch 50, loss 0.5538939237594604, acc=0.7377222180366516, loss=0.5538939237594604
test: epoch 50, loss 1.2168630361557007, acc=0.5555555820465088, loss=1.2168630361557007
train: epoch 51, loss 0.5418222546577454, acc=0.7478333115577698, loss=0.5418222546577454
test: epoch 51, loss 1.166125774383545, acc=0.5444444417953491, loss=1.166125774383545
train: epoch 52, loss 0.5490983128547668, acc=0.7449444532394409, loss=0.5490983128547668
test: epoch 52, loss 1.206030011177063, acc=0.5583333373069763, loss=1.206030011177063
train: epoch 53, loss 0.5488191843032837, acc=0.7409444451332092, loss=0.5488191843032837
test: epoch 53, loss 1.124928593635559, acc=0.5555555820465088, loss=1.124928593635559
train: epoch 54, loss 0.555797815322876, acc=0.7373889088630676, loss=0.555797815322876
test: epoch 54, loss 1.2211503982543945, acc=0.5583333373069763, loss=1.2211503982543945
train: epoch 55, loss 0.5796752572059631, acc=0.7227222323417664, loss=0.5796752572059631
test: epoch 55, loss 1.1188879013061523, acc=0.5611110925674438, loss=1.1188879013061523
train: epoch 56, loss 0.5443049073219299, acc=0.7438889145851135, loss=0.5443049073219299
test: epoch 56, loss 1.1610687971115112, acc=0.5611110925674438, loss=1.1610687971115112
train: epoch 57, loss 0.54950350522995, acc=0.7440000176429749, loss=0.54950350522995
test: epoch 57, loss 1.2731225490570068, acc=0.5388888716697693, loss=1.2731225490570068
train: epoch 58, loss 0.5575463771820068, acc=0.74272221326828, loss=0.5575463771820068
test: epoch 58, loss 1.125535249710083, acc=0.5611110925674438, loss=1.125535249710083
train: epoch 59, loss 0.5356594920158386, acc=0.7521111369132996, loss=0.5356594920158386
test: epoch 59, loss 1.324729561805725, acc=0.5611110925674438, loss=1.324729561805725
train: epoch 60, loss 0.5473623275756836, acc=0.7440555691719055, loss=0.5473623275756836
test: epoch 60, loss 1.0990374088287354, acc=0.5611110925674438, loss=1.0990374088287354
train: epoch 61, loss 0.5615509152412415, acc=0.7326111197471619, loss=0.5615509152412415
test: epoch 61, loss 1.2322393655776978, acc=0.5611110925674438, loss=1.2322393655776978
train: epoch 62, loss 0.5416833162307739, acc=0.7497777938842773, loss=0.5416833162307739
test: epoch 62, loss 1.0903499126434326, acc=0.5611110925674438, loss=1.0903499126434326
train: epoch 63, loss 0.5474229454994202, acc=0.7393888831138611, loss=0.5474229454994202
test: epoch 63, loss 1.1068185567855835, acc=0.5583333373069763, loss=1.1068185567855835
train: epoch 64, loss 0.551876425743103, acc=0.7417222261428833, loss=0.551876425743103
test: epoch 64, loss 1.1474155187606812, acc=0.5611110925674438, loss=1.1474155187606812
train: epoch 65, loss 0.5431215763092041, acc=0.7493333220481873, loss=0.5431215763092041
test: epoch 65, loss 1.1663841009140015, acc=0.5638889074325562, loss=1.1663841009140015
train: epoch 66, loss 0.5551477670669556, acc=0.7465555667877197, loss=0.5551477670669556
test: epoch 66, loss 1.10226309299469, acc=0.5611110925674438, loss=1.10226309299469
train: epoch 67, loss 0.5476139783859253, acc=0.7436666488647461, loss=0.5476139783859253
test: epoch 67, loss 1.2594789266586304, acc=0.5611110925674438, loss=1.2594789266586304
train: epoch 68, loss 0.5322698950767517, acc=0.7521666884422302, loss=0.5322698950767517
test: epoch 68, loss 1.2247880697250366, acc=0.5583333373069763, loss=1.2247880697250366
train: epoch 69, loss 0.5532428622245789, acc=0.7434999942779541, loss=0.5532428622245789
test: epoch 69, loss 1.1199510097503662, acc=0.5611110925674438, loss=1.1199510097503662
train: epoch 70, loss 0.5460577607154846, acc=0.7436666488647461, loss=0.5460577607154846
test: epoch 70, loss 1.1872494220733643, acc=0.5583333373069763, loss=1.1872494220733643
train: epoch 71, loss 0.5327926874160767, acc=0.7446666955947876, loss=0.5327926874160767
test: epoch 71, loss 1.2624505758285522, acc=0.5416666865348816, loss=1.2624505758285522
train: epoch 72, loss 0.537056028842926, acc=0.7442222237586975, loss=0.537056028842926
test: epoch 72, loss 1.2160191535949707, acc=0.5611110925674438, loss=1.2160191535949707
train: epoch 73, loss 0.5239623188972473, acc=0.7546111345291138, loss=0.5239623188972473
test: epoch 73, loss 1.2731821537017822, acc=0.5611110925674438, loss=1.2731821537017822
train: epoch 74, loss 0.5425698161125183, acc=0.7532222270965576, loss=0.5425698161125183
test: epoch 74, loss 1.0640029907226562, acc=0.5611110925674438, loss=1.0640029907226562
train: epoch 75, loss 0.5288048982620239, acc=0.7533888816833496, loss=0.5288048982620239
test: epoch 75, loss 1.2936094999313354, acc=0.5583333373069763, loss=1.2936094999313354
train: epoch 76, loss 0.504776120185852, acc=0.7588889002799988, loss=0.504776120185852
test: epoch 76, loss 1.1745860576629639, acc=0.5555555820465088, loss=1.1745860576629639
train: epoch 77, loss 0.5321003794670105, acc=0.7528889179229736, loss=0.5321003794670105
test: epoch 77, loss 1.1691668033599854, acc=0.5611110925674438, loss=1.1691668033599854
train: epoch 78, loss 0.5385425686836243, acc=0.7463333606719971, loss=0.5385425686836243
test: epoch 78, loss 1.1742316484451294, acc=0.5583333373069763, loss=1.1742316484451294
train: epoch 79, loss 0.5079009532928467, acc=0.7593888640403748, loss=0.5079009532928467
test: epoch 79, loss 1.113302230834961, acc=0.5583333373069763, loss=1.113302230834961
train: epoch 80, loss 0.556226372718811, acc=0.7459444403648376, loss=0.556226372718811
test: epoch 80, loss 1.2347067594528198, acc=0.5444444417953491, loss=1.2347067594528198
train: epoch 81, loss 0.5267093777656555, acc=0.7555555701255798, loss=0.5267093777656555
test: epoch 81, loss 1.0754400491714478, acc=0.5555555820465088, loss=1.0754400491714478
train: epoch 82, loss 0.5257299542427063, acc=0.757777750492096, loss=0.5257299542427063
test: epoch 82, loss 1.2060060501098633, acc=0.5611110925674438, loss=1.2060060501098633
train: epoch 83, loss 0.504280686378479, acc=0.7650555372238159, loss=0.504280686378479
test: epoch 83, loss 1.257157802581787, acc=0.5611110925674438, loss=1.257157802581787
train: epoch 84, loss 0.5187747478485107, acc=0.757888913154602, loss=0.5187747478485107
test: epoch 84, loss 1.2178682088851929, acc=0.5611110925674438, loss=1.2178682088851929
train: epoch 85, loss 0.5285890698432922, acc=0.754444420337677, loss=0.5285890698432922
test: epoch 85, loss 1.0256255865097046, acc=0.5638889074325562, loss=1.0256255865097046
train: epoch 86, loss 0.5068536400794983, acc=0.7631111145019531, loss=0.5068536400794983
test: epoch 86, loss 1.202428936958313, acc=0.5611110925674438, loss=1.202428936958313
train: epoch 87, loss 0.5192025899887085, acc=0.7583333253860474, loss=0.5192025899887085
test: epoch 87, loss 1.1281967163085938, acc=0.5611110925674438, loss=1.1281967163085938
train: epoch 88, loss 0.5060437321662903, acc=0.7609444260597229, loss=0.5060437321662903
test: epoch 88, loss 1.217633605003357, acc=0.5583333373069763, loss=1.217633605003357
train: epoch 89, loss 0.4932679831981659, acc=0.7665555477142334, loss=0.4932679831981659
test: epoch 89, loss 1.2275015115737915, acc=0.5611110925674438, loss=1.2275015115737915
train: epoch 90, loss 0.5187890529632568, acc=0.7565555572509766, loss=0.5187890529632568
test: epoch 90, loss 1.1410448551177979, acc=0.5527777671813965, loss=1.1410448551177979
train: epoch 91, loss 0.5109485983848572, acc=0.7586110830307007, loss=0.5109485983848572
test: epoch 91, loss 1.277877926826477, acc=0.5583333373069763, loss=1.277877926826477
train: epoch 92, loss 0.5119221806526184, acc=0.7603333592414856, loss=0.5119221806526184
test: epoch 92, loss 1.2044180631637573, acc=0.5611110925674438, loss=1.2044180631637573
train: epoch 93, loss 0.5239139199256897, acc=0.7505000233650208, loss=0.5239139199256897
test: epoch 93, loss 1.0631173849105835, acc=0.5555555820465088, loss=1.0631173849105835
train: epoch 94, loss 0.5304120779037476, acc=0.7553333044052124, loss=0.5304120779037476
test: epoch 94, loss 1.215391993522644, acc=0.5583333373069763, loss=1.215391993522644
train: epoch 95, loss 0.4977155923843384, acc=0.7677778005599976, loss=0.4977155923843384
test: epoch 95, loss 1.2093348503112793, acc=0.5583333373069763, loss=1.2093348503112793
train: epoch 96, loss 0.4745035767555237, acc=0.7869444489479065, loss=0.4745035767555237
test: epoch 96, loss 1.293679118156433, acc=0.5583333373069763, loss=1.293679118156433
train: epoch 97, loss 0.4924585819244385, acc=0.7805555462837219, loss=0.4924585819244385
test: epoch 97, loss 1.3168870210647583, acc=0.5416666865348816, loss=1.3168870210647583
train: epoch 98, loss 0.4769454300403595, acc=0.7828333377838135, loss=0.4769454300403595
test: epoch 98, loss 1.2252979278564453, acc=0.5555555820465088, loss=1.2252979278564453
train: epoch 99, loss 0.4648982882499695, acc=0.7920555472373962, loss=0.4648982882499695
test: epoch 99, loss 1.1269234418869019, acc=0.5555555820465088, loss=1.1269234418869019
train: epoch 100, loss 0.4637335240840912, acc=0.788444459438324, loss=0.4637335240840912
test: epoch 100, loss 1.3905482292175293, acc=0.5583333373069763, loss=1.3905482292175293
train: epoch 101, loss 0.48220664262771606, acc=0.7814444303512573, loss=0.48220664262771606
test: epoch 101, loss 1.1819533109664917, acc=0.5583333373069763, loss=1.1819533109664917
train: epoch 102, loss 0.4833275079727173, acc=0.7826111316680908, loss=0.4833275079727173
test: epoch 102, loss 1.1683226823806763, acc=0.5583333373069763, loss=1.1683226823806763
train: epoch 103, loss 0.472987562417984, acc=0.7905555367469788, loss=0.472987562417984
test: epoch 103, loss 1.3111721277236938, acc=0.5583333373069763, loss=1.3111721277236938
train: epoch 104, loss 0.4619200825691223, acc=0.796500027179718, loss=0.4619200825691223
test: epoch 104, loss 1.183471441268921, acc=0.5527777671813965, loss=1.183471441268921
train: epoch 105, loss 0.45140406489372253, acc=0.7912222146987915, loss=0.45140406489372253
test: epoch 105, loss 1.2294681072235107, acc=0.5583333373069763, loss=1.2294681072235107
train: epoch 106, loss 0.4596728980541229, acc=0.7909444570541382, loss=0.4596728980541229
test: epoch 106, loss 1.30391263961792, acc=0.5555555820465088, loss=1.30391263961792
train: epoch 107, loss 0.46612149477005005, acc=0.7915555834770203, loss=0.46612149477005005
test: epoch 107, loss 1.1380248069763184, acc=0.5555555820465088, loss=1.1380248069763184
train: epoch 108, loss 0.46868041157722473, acc=0.792888879776001, loss=0.46868041157722473
test: epoch 108, loss 1.1918154954910278, acc=0.5583333373069763, loss=1.1918154954910278
train: epoch 109, loss 0.45842796564102173, acc=0.7942777872085571, loss=0.45842796564102173
test: epoch 109, loss 1.3012593984603882, acc=0.550000011920929, loss=1.3012593984603882
train: epoch 110, loss 0.44801032543182373, acc=0.7937777638435364, loss=0.44801032543182373
test: epoch 110, loss 1.2104319334030151, acc=0.5555555820465088, loss=1.2104319334030151
train: epoch 111, loss 0.4839456379413605, acc=0.7823888659477234, loss=0.4839456379413605
test: epoch 111, loss 1.3809794187545776, acc=0.5583333373069763, loss=1.3809794187545776
train: epoch 112, loss 0.428419828414917, acc=0.7958889007568359, loss=0.428419828414917
test: epoch 112, loss 1.2691372632980347, acc=0.5583333373069763, loss=1.2691372632980347
train: epoch 113, loss 0.44245439767837524, acc=0.792388916015625, loss=0.44245439767837524
test: epoch 113, loss 1.2915143966674805, acc=0.5583333373069763, loss=1.2915143966674805
train: epoch 114, loss 0.46647849678993225, acc=0.789722204208374, loss=0.46647849678993225
test: epoch 114, loss 1.2461656332015991, acc=0.5583333373069763, loss=1.2461656332015991
train: epoch 115, loss 0.46233290433883667, acc=0.7901666760444641, loss=0.46233290433883667
test: epoch 115, loss 1.2147352695465088, acc=0.5583333373069763, loss=1.2147352695465088
train: epoch 116, loss 0.4456556439399719, acc=0.793666660785675, loss=0.4456556439399719
test: epoch 116, loss 1.4160007238388062, acc=0.5583333373069763, loss=1.4160007238388062
train: epoch 117, loss 0.45260798931121826, acc=0.7963333129882812, loss=0.45260798931121826
test: epoch 117, loss 1.218082070350647, acc=0.5472221970558167, loss=1.218082070350647
train: epoch 118, loss 0.46883273124694824, acc=0.789555549621582, loss=0.46883273124694824
test: epoch 118, loss 1.347941279411316, acc=0.5611110925674438, loss=1.347941279411316
train: epoch 119, loss 0.45872122049331665, acc=0.7928333282470703, loss=0.45872122049331665
test: epoch 119, loss 1.2008055448532104, acc=0.5583333373069763, loss=1.2008055448532104
train: epoch 120, loss 0.44921422004699707, acc=0.7946110963821411, loss=0.44921422004699707
test: epoch 120, loss 1.2633262872695923, acc=0.5583333373069763, loss=1.2633262872695923
train: epoch 121, loss 0.4527376890182495, acc=0.7934444546699524, loss=0.4527376890182495
test: epoch 121, loss 1.220840334892273, acc=0.5583333373069763, loss=1.220840334892273
train: epoch 122, loss 0.4427211582660675, acc=0.7940000295639038, loss=0.4427211582660675
test: epoch 122, loss 1.2916406393051147, acc=0.5583333373069763, loss=1.2916406393051147
train: epoch 123, loss 0.4644789695739746, acc=0.7864999771118164, loss=0.4644789695739746
test: epoch 123, loss 1.1443296670913696, acc=0.5555555820465088, loss=1.1443296670913696
train: epoch 124, loss 0.44413331151008606, acc=0.7947221994400024, loss=0.44413331151008606
test: epoch 124, loss 1.217391848564148, acc=0.5583333373069763, loss=1.217391848564148
train: epoch 125, loss 0.44319388270378113, acc=0.8003888726234436, loss=0.44319388270378113
test: epoch 125, loss 1.1680392026901245, acc=0.5583333373069763, loss=1.1680392026901245
train: epoch 126, loss 0.4657960534095764, acc=0.7944444417953491, loss=0.4657960534095764
test: epoch 126, loss 1.2582643032073975, acc=0.5583333373069763, loss=1.2582643032073975
train: epoch 127, loss 0.4368390440940857, acc=0.7981666922569275, loss=0.4368390440940857
test: epoch 127, loss 1.3002707958221436, acc=0.5555555820465088, loss=1.3002707958221436
train: epoch 128, loss 0.46961501240730286, acc=0.7914444208145142, loss=0.46961501240730286
test: epoch 128, loss 1.2361030578613281, acc=0.5583333373069763, loss=1.2361030578613281
train: epoch 129, loss 0.437782347202301, acc=0.8018888831138611, loss=0.437782347202301
test: epoch 129, loss 1.2584682703018188, acc=0.5583333373069763, loss=1.2584682703018188
train: epoch 130, loss 0.44067469239234924, acc=0.7969444394111633, loss=0.44067469239234924
test: epoch 130, loss 1.160192608833313, acc=0.5472221970558167, loss=1.160192608833313
train: epoch 131, loss 0.44109833240509033, acc=0.7963888645172119, loss=0.44109833240509033
test: epoch 131, loss 1.303327202796936, acc=0.5583333373069763, loss=1.303327202796936
train: epoch 132, loss 0.42249298095703125, acc=0.8061110973358154, loss=0.42249298095703125
test: epoch 132, loss 1.262257695198059, acc=0.5611110925674438, loss=1.262257695198059
train: epoch 133, loss 0.4308544397354126, acc=0.8033333420753479, loss=0.4308544397354126
test: epoch 133, loss 1.3671294450759888, acc=0.5583333373069763, loss=1.3671294450759888
train: epoch 134, loss 0.43870556354522705, acc=0.8002777695655823, loss=0.43870556354522705
test: epoch 134, loss 1.1144490242004395, acc=0.5555555820465088, loss=1.1144490242004395
train: epoch 135, loss 0.44687288999557495, acc=0.7985000014305115, loss=0.44687288999557495
test: epoch 135, loss 1.2062911987304688, acc=0.5472221970558167, loss=1.2062911987304688
train: epoch 136, loss 0.4327055811882019, acc=0.7986666560173035, loss=0.4327055811882019
test: epoch 136, loss 1.244168996810913, acc=0.5611110925674438, loss=1.244168996810913
train: epoch 137, loss 0.4422604739665985, acc=0.7990555763244629, loss=0.4422604739665985
test: epoch 137, loss 1.3307685852050781, acc=0.5555555820465088, loss=1.3307685852050781
train: epoch 138, loss 0.4436385929584503, acc=0.7951666712760925, loss=0.4436385929584503
test: epoch 138, loss 1.2459746599197388, acc=0.5583333373069763, loss=1.2459746599197388
train: epoch 139, loss 0.45390790700912476, acc=0.8005555272102356, loss=0.45390790700912476
test: epoch 139, loss 1.2885013818740845, acc=0.5583333373069763, loss=1.2885013818740845
train: epoch 140, loss 0.43695345520973206, acc=0.8099444508552551, loss=0.43695345520973206
test: epoch 140, loss 1.3054070472717285, acc=0.5638889074325562, loss=1.3054070472717285
train: epoch 141, loss 0.43893352150917053, acc=0.8086666464805603, loss=0.43893352150917053
test: epoch 141, loss 1.1396138668060303, acc=0.5583333373069763, loss=1.1396138668060303
train: epoch 142, loss 0.43341541290283203, acc=0.8106666803359985, loss=0.43341541290283203
test: epoch 142, loss 1.2285963296890259, acc=0.5638889074325562, loss=1.2285963296890259
train: epoch 143, loss 0.4099871516227722, acc=0.816777765750885, loss=0.4099871516227722
test: epoch 143, loss 1.3051477670669556, acc=0.5638889074325562, loss=1.3051477670669556
train: epoch 144, loss 0.4162459671497345, acc=0.8152777552604675, loss=0.4162459671497345
test: epoch 144, loss 1.2632731199264526, acc=0.574999988079071, loss=1.2632731199264526
train: epoch 145, loss 0.41593512892723083, acc=0.8137778043746948, loss=0.41593512892723083
test: epoch 145, loss 1.1575000286102295, acc=0.6027777791023254, loss=1.1575000286102295
train: epoch 146, loss 0.4311455190181732, acc=0.8107777833938599, loss=0.4311455190181732
test: epoch 146, loss 1.2014505863189697, acc=0.5638889074325562, loss=1.2014505863189697
train: epoch 147, loss 0.40516197681427, acc=0.8203333616256714, loss=0.40516197681427
test: epoch 147, loss 1.292285680770874, acc=0.5777778029441833, loss=1.292285680770874
train: epoch 148, loss 0.4140338897705078, acc=0.8200555443763733, loss=0.4140338897705078
test: epoch 148, loss 1.3956387042999268, acc=0.519444465637207, loss=1.3956387042999268
train: epoch 149, loss 0.43099698424339294, acc=0.8094444274902344, loss=0.43099698424339294
test: epoch 149, loss 1.1978245973587036, acc=0.5638889074325562, loss=1.1978245973587036
train: epoch 150, loss 0.43596264719963074, acc=0.8089444637298584, loss=0.43596264719963074
test: epoch 150, loss 1.1896711587905884, acc=0.5611110925674438, loss=1.1896711587905884
