# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=2.0", "--temp_decay=0.99", "--one_hot=true", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1439083255, receiver_embed_dim=128, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.799461841583252, acc=0.13272222876548767, loss=2.799461841583252
test: epoch 1, loss 2.6017351150512695, acc=0.18611110746860504, loss=2.6017351150512695
train: epoch 2, loss 1.468726396560669, acc=0.39800000190734863, loss=1.468726396560669
test: epoch 2, loss 2.461021661758423, acc=0.21388888359069824, loss=2.461021661758423
train: epoch 3, loss 1.1446326971054077, acc=0.527388870716095, loss=1.1446326971054077
test: epoch 3, loss 2.400733709335327, acc=0.21111111342906952, loss=2.400733709335327
train: epoch 4, loss 0.9701846241950989, acc=0.6108888983726501, loss=0.9701846241950989
test: epoch 4, loss 2.3086740970611572, acc=0.23055554926395416, loss=2.3086740970611572
train: epoch 5, loss 0.8442047834396362, acc=0.6657778024673462, loss=0.8442047834396362
test: epoch 5, loss 2.3478519916534424, acc=0.2750000059604645, loss=2.3478519916534424
train: epoch 6, loss 0.7588041424751282, acc=0.7006666660308838, loss=0.7588041424751282
test: epoch 6, loss 2.345736503601074, acc=0.27222222089767456, loss=2.345736503601074
train: epoch 7, loss 0.6840171217918396, acc=0.7369999885559082, loss=0.6840171217918396
test: epoch 7, loss 2.4931466579437256, acc=0.24444444477558136, loss=2.4931466579437256
train: epoch 8, loss 0.6235798001289368, acc=0.7638888955116272, loss=0.6235798001289368
test: epoch 8, loss 2.3170688152313232, acc=0.24166665971279144, loss=2.3170688152313232
train: epoch 9, loss 0.5755758881568909, acc=0.7823333144187927, loss=0.5755758881568909
test: epoch 9, loss 2.2930245399475098, acc=0.28333333134651184, loss=2.2930245399475098
train: epoch 10, loss 0.5422050356864929, acc=0.7950000166893005, loss=0.5422050356864929
test: epoch 10, loss 2.340287923812866, acc=0.25833332538604736, loss=2.340287923812866
train: epoch 11, loss 0.5034359693527222, acc=0.8129444718360901, loss=0.5034359693527222
test: epoch 11, loss 2.5600454807281494, acc=0.2638888955116272, loss=2.5600454807281494
train: epoch 12, loss 0.4721418619155884, acc=0.8270555734634399, loss=0.4721418619155884
test: epoch 12, loss 2.1796305179595947, acc=0.3166666626930237, loss=2.1796305179595947
train: epoch 13, loss 0.43980011343955994, acc=0.8383888602256775, loss=0.43980011343955994
test: epoch 13, loss 2.1393673419952393, acc=0.3222222328186035, loss=2.1393673419952393
train: epoch 14, loss 0.41943949460983276, acc=0.8453333377838135, loss=0.41943949460983276
test: epoch 14, loss 2.0995514392852783, acc=0.31388887763023376, loss=2.0995514392852783
train: epoch 15, loss 0.38935041427612305, acc=0.859333336353302, loss=0.38935041427612305
test: epoch 15, loss 2.1065876483917236, acc=0.33888888359069824, loss=2.1065876483917236
train: epoch 16, loss 0.38392889499664307, acc=0.8585000038146973, loss=0.38392889499664307
test: epoch 16, loss 2.3059051036834717, acc=0.3166666626930237, loss=2.3059051036834717
train: epoch 17, loss 0.36694222688674927, acc=0.8692777752876282, loss=0.36694222688674927
test: epoch 17, loss 2.248546838760376, acc=0.3305555582046509, loss=2.248546838760376
train: epoch 18, loss 0.3530452847480774, acc=0.874833345413208, loss=0.3530452847480774
test: epoch 18, loss 2.23744535446167, acc=0.3638888895511627, loss=2.23744535446167
train: epoch 19, loss 0.34182024002075195, acc=0.8761110901832581, loss=0.34182024002075195
test: epoch 19, loss 2.11183500289917, acc=0.375, loss=2.11183500289917
train: epoch 20, loss 0.3256051242351532, acc=0.882777750492096, loss=0.3256051242351532
test: epoch 20, loss 2.4864308834075928, acc=0.38055557012557983, loss=2.4864308834075928
train: epoch 21, loss 0.3199287950992584, acc=0.887499988079071, loss=0.3199287950992584
test: epoch 21, loss 1.9721603393554688, acc=0.3638888895511627, loss=1.9721603393554688
train: epoch 22, loss 0.30780962109565735, acc=0.8933333158493042, loss=0.30780962109565735
test: epoch 22, loss 2.430446147918701, acc=0.3305555582046509, loss=2.430446147918701
train: epoch 23, loss 0.2969728708267212, acc=0.8974999785423279, loss=0.2969728708267212
test: epoch 23, loss 2.306408643722534, acc=0.3583333194255829, loss=2.306408643722534
train: epoch 24, loss 0.27532443404197693, acc=0.9076111316680908, loss=0.27532443404197693
test: epoch 24, loss 2.255535840988159, acc=0.40833333134651184, loss=2.255535840988159
train: epoch 25, loss 0.2838813364505768, acc=0.9008333086967468, loss=0.2838813364505768
test: epoch 25, loss 2.503141403198242, acc=0.36666667461395264, loss=2.503141403198242
train: epoch 26, loss 0.2600300908088684, acc=0.9108889102935791, loss=0.2600300908088684
test: epoch 26, loss 2.0567786693573, acc=0.42222222685813904, loss=2.0567786693573
train: epoch 27, loss 0.2627207636833191, acc=0.9114444255828857, loss=0.2627207636833191
test: epoch 27, loss 2.180438280105591, acc=0.41111111640930176, loss=2.180438280105591
train: epoch 28, loss 0.2555488049983978, acc=0.9135555624961853, loss=0.2555488049983978
test: epoch 28, loss 2.208096981048584, acc=0.3611111044883728, loss=2.208096981048584
train: epoch 29, loss 0.23834627866744995, acc=0.9200555682182312, loss=0.23834627866744995
test: epoch 29, loss 2.439685106277466, acc=0.3888888955116272, loss=2.439685106277466
train: epoch 30, loss 0.24348978698253632, acc=0.9182778000831604, loss=0.24348978698253632
test: epoch 30, loss 2.132695436477661, acc=0.4277777671813965, loss=2.132695436477661
train: epoch 31, loss 0.2301073670387268, acc=0.9217777848243713, loss=0.2301073670387268
test: epoch 31, loss 2.355469226837158, acc=0.42500001192092896, loss=2.355469226837158
train: epoch 32, loss 0.23390041291713715, acc=0.9242222309112549, loss=0.23390041291713715
test: epoch 32, loss 2.047313928604126, acc=0.4694444537162781, loss=2.047313928604126
train: epoch 33, loss 0.22119282186031342, acc=0.9254999756813049, loss=0.22119282186031342
test: epoch 33, loss 2.323204517364502, acc=0.36666667461395264, loss=2.323204517364502
train: epoch 34, loss 0.21199367940425873, acc=0.9290000200271606, loss=0.21199367940425873
test: epoch 34, loss 2.372546434402466, acc=0.3888888955116272, loss=2.372546434402466
train: epoch 35, loss 0.2167607992887497, acc=0.9286110997200012, loss=0.2167607992887497
test: epoch 35, loss 2.0992116928100586, acc=0.4194444417953491, loss=2.0992116928100586
train: epoch 36, loss 0.20098789036273956, acc=0.9323889017105103, loss=0.20098789036273956
test: epoch 36, loss 2.356417655944824, acc=0.4027777910232544, loss=2.356417655944824
train: epoch 37, loss 0.18817201256752014, acc=0.9391666650772095, loss=0.18817201256752014
test: epoch 37, loss 2.68992018699646, acc=0.42222222685813904, loss=2.68992018699646
train: epoch 38, loss 0.20032748579978943, acc=0.9366111159324646, loss=0.20032748579978943
test: epoch 38, loss 2.189906120300293, acc=0.4583333432674408, loss=2.189906120300293
train: epoch 39, loss 0.18591812252998352, acc=0.9435555338859558, loss=0.18591812252998352
test: epoch 39, loss 2.693880319595337, acc=0.4305555522441864, loss=2.693880319595337
train: epoch 40, loss 0.183314248919487, acc=0.9424444437026978, loss=0.183314248919487
test: epoch 40, loss 2.209293842315674, acc=0.4194444417953491, loss=2.209293842315674
train: epoch 41, loss 0.17115074396133423, acc=0.9458333253860474, loss=0.17115074396133423
test: epoch 41, loss 2.5677242279052734, acc=0.4749999940395355, loss=2.5677242279052734
train: epoch 42, loss 0.1874261498451233, acc=0.9437222480773926, loss=0.1874261498451233
test: epoch 42, loss 2.2721972465515137, acc=0.4555555582046509, loss=2.2721972465515137
train: epoch 43, loss 0.17049574851989746, acc=0.9476110935211182, loss=0.17049574851989746
test: epoch 43, loss 2.3117034435272217, acc=0.43611112236976624, loss=2.3117034435272217
train: epoch 44, loss 0.18897151947021484, acc=0.9401111006736755, loss=0.18897151947021484
test: epoch 44, loss 2.1889536380767822, acc=0.4611110985279083, loss=2.1889536380767822
train: epoch 45, loss 0.17191216349601746, acc=0.9474999904632568, loss=0.17191216349601746
test: epoch 45, loss 2.5399060249328613, acc=0.4749999940395355, loss=2.5399060249328613
train: epoch 46, loss 0.1731552630662918, acc=0.9471111297607422, loss=0.1731552630662918
test: epoch 46, loss 2.121716022491455, acc=0.43888887763023376, loss=2.121716022491455
train: epoch 47, loss 0.16891099512577057, acc=0.9493333101272583, loss=0.16891099512577057
test: epoch 47, loss 2.1812236309051514, acc=0.45277777314186096, loss=2.1812236309051514
train: epoch 48, loss 0.16422192752361298, acc=0.9489444494247437, loss=0.16422192752361298
test: epoch 48, loss 2.0768680572509766, acc=0.4472222328186035, loss=2.0768680572509766
train: epoch 49, loss 0.17542527616024017, acc=0.945388913154602, loss=0.17542527616024017
test: epoch 49, loss 2.352471351623535, acc=0.42222222685813904, loss=2.352471351623535
train: epoch 50, loss 0.17292116582393646, acc=0.9463889002799988, loss=0.17292116582393646
test: epoch 50, loss 2.2084743976593018, acc=0.49166667461395264, loss=2.2084743976593018
train: epoch 51, loss 0.1791308969259262, acc=0.9461666941642761, loss=0.1791308969259262
test: epoch 51, loss 2.5657222270965576, acc=0.45277777314186096, loss=2.5657222270965576
train: epoch 52, loss 0.16635382175445557, acc=0.948722243309021, loss=0.16635382175445557
test: epoch 52, loss 1.8597053289413452, acc=0.5, loss=1.8597053289413452
train: epoch 53, loss 0.16588006913661957, acc=0.9491666555404663, loss=0.16588006913661957
test: epoch 53, loss 2.210066080093384, acc=0.5388888716697693, loss=2.210066080093384
train: epoch 54, loss 0.18029841780662537, acc=0.9473888874053955, loss=0.18029841780662537
test: epoch 54, loss 1.9642956256866455, acc=0.48055556416511536, loss=1.9642956256866455
train: epoch 55, loss 0.17069226503372192, acc=0.9491666555404663, loss=0.17069226503372192
test: epoch 55, loss 2.5072085857391357, acc=0.4888888895511627, loss=2.5072085857391357
train: epoch 56, loss 0.1730692833662033, acc=0.9486666917800903, loss=0.1730692833662033
test: epoch 56, loss 1.9836654663085938, acc=0.4833333194255829, loss=1.9836654663085938
train: epoch 57, loss 0.15990741550922394, acc=0.9491111040115356, loss=0.15990741550922394
test: epoch 57, loss 1.8994534015655518, acc=0.4833333194255829, loss=1.8994534015655518
train: epoch 58, loss 0.17445403337478638, acc=0.9474444389343262, loss=0.17445403337478638
test: epoch 58, loss 2.1559746265411377, acc=0.4888888895511627, loss=2.1559746265411377
train: epoch 59, loss 0.16291169822216034, acc=0.9511666893959045, loss=0.16291169822216034
test: epoch 59, loss 1.8153825998306274, acc=0.5055555701255798, loss=1.8153825998306274
train: epoch 60, loss 0.16741029918193817, acc=0.9497222304344177, loss=0.16741029918193817
test: epoch 60, loss 2.2684524059295654, acc=0.49166667461395264, loss=2.2684524059295654
train: epoch 61, loss 0.1676958203315735, acc=0.9494444727897644, loss=0.1676958203315735
test: epoch 61, loss 2.285327434539795, acc=0.5138888955116272, loss=2.285327434539795
train: epoch 62, loss 0.16577573120594025, acc=0.9497222304344177, loss=0.16577573120594025
test: epoch 62, loss 1.8687107563018799, acc=0.5333333611488342, loss=1.8687107563018799
train: epoch 63, loss 0.16456899046897888, acc=0.9480555653572083, loss=0.16456899046897888
test: epoch 63, loss 1.78245210647583, acc=0.5666666626930237, loss=1.78245210647583
train: epoch 64, loss 0.16524378955364227, acc=0.9492777585983276, loss=0.16524378955364227
test: epoch 64, loss 1.9259425401687622, acc=0.5138888955116272, loss=1.9259425401687622
train: epoch 65, loss 0.18257048726081848, acc=0.9451666474342346, loss=0.18257048726081848
test: epoch 65, loss 1.582416296005249, acc=0.5583333373069763, loss=1.582416296005249
train: epoch 66, loss 0.16287267208099365, acc=0.9491111040115356, loss=0.16287267208099365
test: epoch 66, loss 1.8695132732391357, acc=0.5111111402511597, loss=1.8695132732391357
train: epoch 67, loss 0.16208714246749878, acc=0.9502778053283691, loss=0.16208714246749878
test: epoch 67, loss 1.6703691482543945, acc=0.5861111283302307, loss=1.6703691482543945
train: epoch 68, loss 0.17388972640037537, acc=0.9478333592414856, loss=0.17388972640037537
test: epoch 68, loss 1.7927582263946533, acc=0.6027777791023254, loss=1.7927582263946533
train: epoch 69, loss 0.1725853979587555, acc=0.9490000009536743, loss=0.1725853979587555
test: epoch 69, loss 1.6769306659698486, acc=0.5861111283302307, loss=1.6769306659698486
train: epoch 70, loss 0.17300193011760712, acc=0.9477777481079102, loss=0.17300193011760712
test: epoch 70, loss 1.3974169492721558, acc=0.5888888835906982, loss=1.3974169492721558
train: epoch 71, loss 0.1729000061750412, acc=0.9481666684150696, loss=0.1729000061750412
test: epoch 71, loss 1.4923884868621826, acc=0.6083333492279053, loss=1.4923884868621826
train: epoch 72, loss 0.16045615077018738, acc=0.9492777585983276, loss=0.16045615077018738
test: epoch 72, loss 1.4245645999908447, acc=0.5916666388511658, loss=1.4245645999908447
train: epoch 73, loss 0.1833232343196869, acc=0.9452221989631653, loss=0.1833232343196869
test: epoch 73, loss 1.6253854036331177, acc=0.574999988079071, loss=1.6253854036331177
train: epoch 74, loss 0.1673382669687271, acc=0.9499444365501404, loss=0.1673382669687271
test: epoch 74, loss 1.3790115118026733, acc=0.6333333253860474, loss=1.3790115118026733
train: epoch 75, loss 0.17161129415035248, acc=0.9478333592414856, loss=0.17161129415035248
test: epoch 75, loss 1.4574334621429443, acc=0.6527777910232544, loss=1.4574334621429443
train: epoch 76, loss 0.1646694839000702, acc=0.9491111040115356, loss=0.1646694839000702
test: epoch 76, loss 1.3329488039016724, acc=0.6611111164093018, loss=1.3329488039016724
train: epoch 77, loss 0.16740202903747559, acc=0.9491666555404663, loss=0.16740202903747559
test: epoch 77, loss 1.3596391677856445, acc=0.675000011920929, loss=1.3596391677856445
train: epoch 78, loss 0.17822106182575226, acc=0.9472222328186035, loss=0.17822106182575226
test: epoch 78, loss 1.0047554969787598, acc=0.7027778029441833, loss=1.0047554969787598
train: epoch 79, loss 0.16206955909729004, acc=0.9510555267333984, loss=0.16206955909729004
test: epoch 79, loss 0.9943630695343018, acc=0.7027778029441833, loss=0.9943630695343018
train: epoch 80, loss 0.16490383446216583, acc=0.9484999775886536, loss=0.16490383446216583
test: epoch 80, loss 1.2446527481079102, acc=0.6694444417953491, loss=1.2446527481079102
train: epoch 81, loss 0.17543070018291473, acc=0.9466111063957214, loss=0.17543070018291473
test: epoch 81, loss 1.0925219058990479, acc=0.7138888835906982, loss=1.0925219058990479
train: epoch 82, loss 0.18609167635440826, acc=0.9462777972221375, loss=0.18609167635440826
test: epoch 82, loss 0.9683142304420471, acc=0.7222222089767456, loss=0.9683142304420471
train: epoch 83, loss 0.1664380580186844, acc=0.9509999752044678, loss=0.1664380580186844
test: epoch 83, loss 0.9991024732589722, acc=0.7055555582046509, loss=0.9991024732589722
train: epoch 84, loss 0.17203772068023682, acc=0.9473888874053955, loss=0.17203772068023682
test: epoch 84, loss 1.048209309577942, acc=0.7055555582046509, loss=1.048209309577942
train: epoch 85, loss 0.16630399227142334, acc=0.9488333463668823, loss=0.16630399227142334
test: epoch 85, loss 1.0009320974349976, acc=0.7333333492279053, loss=1.0009320974349976
train: epoch 86, loss 0.17019958794116974, acc=0.9484999775886536, loss=0.17019958794116974
test: epoch 86, loss 1.0829709768295288, acc=0.6861110925674438, loss=1.0829709768295288
train: epoch 87, loss 0.16016606986522675, acc=0.9501110911369324, loss=0.16016606986522675
test: epoch 87, loss 1.0082019567489624, acc=0.7333333492279053, loss=1.0082019567489624
train: epoch 88, loss 0.15562641620635986, acc=0.9527222514152527, loss=0.15562641620635986
test: epoch 88, loss 0.9709915518760681, acc=0.7222222089767456, loss=0.9709915518760681
train: epoch 89, loss 0.18143132328987122, acc=0.9472222328186035, loss=0.18143132328987122
test: epoch 89, loss 0.8998204469680786, acc=0.7222222089767456, loss=0.8998204469680786
train: epoch 90, loss 0.15753957629203796, acc=0.9496111273765564, loss=0.15753957629203796
test: epoch 90, loss 1.0130681991577148, acc=0.7416666746139526, loss=1.0130681991577148
train: epoch 91, loss 0.16191266477108002, acc=0.9493333101272583, loss=0.16191266477108002
test: epoch 91, loss 0.9777637124061584, acc=0.7361111044883728, loss=0.9777637124061584
train: epoch 92, loss 0.15524020791053772, acc=0.9527222514152527, loss=0.15524020791053772
test: epoch 92, loss 1.0060580968856812, acc=0.7388888597488403, loss=1.0060580968856812
train: epoch 93, loss 0.1661527007818222, acc=0.949055552482605, loss=0.1661527007818222
test: epoch 93, loss 0.9571226835250854, acc=0.7583333253860474, loss=0.9571226835250854
train: epoch 94, loss 0.16399388015270233, acc=0.9497777819633484, loss=0.16399388015270233
test: epoch 94, loss 0.9681646227836609, acc=0.7250000238418579, loss=0.9681646227836609
train: epoch 95, loss 0.17525714635849, acc=0.9430555701255798, loss=0.17525714635849
test: epoch 95, loss 0.7454221248626709, acc=0.7416666746139526, loss=0.7454221248626709
train: epoch 96, loss 0.17544837296009064, acc=0.9455000162124634, loss=0.17544837296009064
test: epoch 96, loss 0.883020281791687, acc=0.7638888955116272, loss=0.883020281791687
train: epoch 97, loss 0.16186822950839996, acc=0.9470000267028809, loss=0.16186822950839996
test: epoch 97, loss 0.8870543837547302, acc=0.7361111044883728, loss=0.8870543837547302
train: epoch 98, loss 0.15790055692195892, acc=0.9477221965789795, loss=0.15790055692195892
test: epoch 98, loss 0.6934319734573364, acc=0.7888888716697693, loss=0.6934319734573364
train: epoch 99, loss 0.16680395603179932, acc=0.9467222094535828, loss=0.16680395603179932
test: epoch 99, loss 0.7699359655380249, acc=0.7805555462837219, loss=0.7699359655380249
train: epoch 100, loss 0.15686750411987305, acc=0.9466111063957214, loss=0.15686750411987305
test: epoch 100, loss 0.7747218012809753, acc=0.769444465637207, loss=0.7747218012809753
train: epoch 101, loss 0.15864454209804535, acc=0.9470555782318115, loss=0.15864454209804535
test: epoch 101, loss 0.806255042552948, acc=0.7527777552604675, loss=0.806255042552948
train: epoch 102, loss 0.15749740600585938, acc=0.9473333358764648, loss=0.15749740600585938
test: epoch 102, loss 0.7159098386764526, acc=0.7888888716697693, loss=0.7159098386764526
train: epoch 103, loss 0.15360720455646515, acc=0.9494444727897644, loss=0.15360720455646515
test: epoch 103, loss 0.6985916495323181, acc=0.7749999761581421, loss=0.6985916495323181
train: epoch 104, loss 0.15268923342227936, acc=0.9493333101272583, loss=0.15268923342227936
test: epoch 104, loss 0.6465844511985779, acc=0.7972221970558167, loss=0.6465844511985779
train: epoch 105, loss 0.13617943227291107, acc=0.9560555815696716, loss=0.13617943227291107
test: epoch 105, loss 0.7146957516670227, acc=0.7749999761581421, loss=0.7146957516670227
train: epoch 106, loss 0.14113448560237885, acc=0.9515555500984192, loss=0.14113448560237885
test: epoch 106, loss 0.6595026254653931, acc=0.7833333611488342, loss=0.6595026254653931
train: epoch 107, loss 0.14919635653495789, acc=0.9513888955116272, loss=0.14919635653495789
test: epoch 107, loss 0.6973490715026855, acc=0.7861111164093018, loss=0.6973490715026855
train: epoch 108, loss 0.1455627679824829, acc=0.949833333492279, loss=0.1455627679824829
test: epoch 108, loss 0.780778706073761, acc=0.7916666865348816, loss=0.780778706073761
train: epoch 109, loss 0.135489821434021, acc=0.9521111249923706, loss=0.135489821434021
test: epoch 109, loss 0.7774667143821716, acc=0.7916666865348816, loss=0.7774667143821716
train: epoch 110, loss 0.14011156558990479, acc=0.952833354473114, loss=0.14011156558990479
test: epoch 110, loss 0.7444307208061218, acc=0.8027777671813965, loss=0.7444307208061218
train: epoch 111, loss 0.14909619092941284, acc=0.9514999985694885, loss=0.14909619092941284
test: epoch 111, loss 0.6078248620033264, acc=0.8055555820465088, loss=0.6078248620033264
train: epoch 112, loss 0.14040148258209229, acc=0.9532777667045593, loss=0.14040148258209229
test: epoch 112, loss 0.7287701368331909, acc=0.7805555462837219, loss=0.7287701368331909
train: epoch 113, loss 0.1308218091726303, acc=0.9555555582046509, loss=0.1308218091726303
test: epoch 113, loss 0.6344457864761353, acc=0.8027777671813965, loss=0.6344457864761353
train: epoch 114, loss 0.135943204164505, acc=0.9534444212913513, loss=0.135943204164505
test: epoch 114, loss 0.7641659379005432, acc=0.7777777910232544, loss=0.7641659379005432
train: epoch 115, loss 0.13489297032356262, acc=0.9509444236755371, loss=0.13489297032356262
test: epoch 115, loss 0.6834069490432739, acc=0.7944444417953491, loss=0.6834069490432739
train: epoch 116, loss 0.13126438856124878, acc=0.9540555477142334, loss=0.13126438856124878
test: epoch 116, loss 0.714371919631958, acc=0.800000011920929, loss=0.714371919631958
train: epoch 117, loss 0.14017607271671295, acc=0.949388861656189, loss=0.14017607271671295
test: epoch 117, loss 0.6514084935188293, acc=0.7972221970558167, loss=0.6514084935188293
train: epoch 118, loss 0.13475088775157928, acc=0.9521111249923706, loss=0.13475088775157928
test: epoch 118, loss 0.6186609268188477, acc=0.7944444417953491, loss=0.6186609268188477
train: epoch 119, loss 0.13482728600502014, acc=0.9542222023010254, loss=0.13482728600502014
test: epoch 119, loss 0.8218591809272766, acc=0.7944444417953491, loss=0.8218591809272766
train: epoch 120, loss 0.1357472687959671, acc=0.9507222175598145, loss=0.1357472687959671
test: epoch 120, loss 0.5711786150932312, acc=0.8166666626930237, loss=0.5711786150932312
train: epoch 121, loss 0.13851669430732727, acc=0.9509999752044678, loss=0.13851669430732727
test: epoch 121, loss 0.6827396154403687, acc=0.7861111164093018, loss=0.6827396154403687
train: epoch 122, loss 0.13359054923057556, acc=0.9520555734634399, loss=0.13359054923057556
test: epoch 122, loss 0.623717188835144, acc=0.800000011920929, loss=0.623717188835144
train: epoch 123, loss 0.12943176925182343, acc=0.954277753829956, loss=0.12943176925182343
test: epoch 123, loss 0.6713632345199585, acc=0.7944444417953491, loss=0.6713632345199585
train: epoch 124, loss 0.1286250799894333, acc=0.9549999833106995, loss=0.1286250799894333
test: epoch 124, loss 0.6381018161773682, acc=0.7805555462837219, loss=0.6381018161773682
train: epoch 125, loss 0.12392810732126236, acc=0.9554444551467896, loss=0.12392810732126236
test: epoch 125, loss 0.5967090129852295, acc=0.8027777671813965, loss=0.5967090129852295
train: epoch 126, loss 0.12440076470375061, acc=0.9564444422721863, loss=0.12440076470375061
test: epoch 126, loss 0.7845954895019531, acc=0.7861111164093018, loss=0.7845954895019531
train: epoch 127, loss 0.13004834949970245, acc=0.9536111354827881, loss=0.13004834949970245
test: epoch 127, loss 0.6797819137573242, acc=0.7916666865348816, loss=0.6797819137573242
train: epoch 128, loss 0.12218989431858063, acc=0.9564444422721863, loss=0.12218989431858063
test: epoch 128, loss 0.7005700469017029, acc=0.8083333373069763, loss=0.7005700469017029
train: epoch 129, loss 0.11818428337574005, acc=0.9581111073493958, loss=0.11818428337574005
test: epoch 129, loss 0.7090356945991516, acc=0.8055555820465088, loss=0.7090356945991516
train: epoch 130, loss 0.12465786933898926, acc=0.9568889141082764, loss=0.12465786933898926
test: epoch 130, loss 0.7495062947273254, acc=0.800000011920929, loss=0.7495062947273254
train: epoch 131, loss 0.11769727617502213, acc=0.957611083984375, loss=0.11769727617502213
test: epoch 131, loss 0.7412109375, acc=0.7916666865348816, loss=0.7412109375
train: epoch 132, loss 0.11900355666875839, acc=0.957277774810791, loss=0.11900355666875839
test: epoch 132, loss 0.6953787803649902, acc=0.7916666865348816, loss=0.6953787803649902
train: epoch 133, loss 0.12373992055654526, acc=0.9589999914169312, loss=0.12373992055654526
test: epoch 133, loss 0.6739323139190674, acc=0.7861111164093018, loss=0.6739323139190674
train: epoch 134, loss 0.127022847533226, acc=0.9538888931274414, loss=0.127022847533226
test: epoch 134, loss 0.7416837215423584, acc=0.7861111164093018, loss=0.7416837215423584
train: epoch 135, loss 0.1190258339047432, acc=0.9576666951179504, loss=0.1190258339047432
test: epoch 135, loss 0.7109013199806213, acc=0.8027777671813965, loss=0.7109013199806213
train: epoch 136, loss 0.11703396588563919, acc=0.9550555348396301, loss=0.11703396588563919
test: epoch 136, loss 0.6011219620704651, acc=0.8027777671813965, loss=0.6011219620704651
train: epoch 137, loss 0.12305156886577606, acc=0.9571666717529297, loss=0.12305156886577606
test: epoch 137, loss 0.673053503036499, acc=0.7944444417953491, loss=0.673053503036499
train: epoch 138, loss 0.12295570224523544, acc=0.9572222232818604, loss=0.12295570224523544
test: epoch 138, loss 0.6390482783317566, acc=0.8111110925674438, loss=0.6390482783317566
train: epoch 139, loss 0.12397997826337814, acc=0.9579444527626038, loss=0.12397997826337814
test: epoch 139, loss 0.6508007049560547, acc=0.8083333373069763, loss=0.6508007049560547
train: epoch 140, loss 0.12069844454526901, acc=0.9592221975326538, loss=0.12069844454526901
test: epoch 140, loss 0.6919609904289246, acc=0.7833333611488342, loss=0.6919609904289246
train: epoch 141, loss 0.11906550079584122, acc=0.9578889012336731, loss=0.11906550079584122
test: epoch 141, loss 0.708870530128479, acc=0.7944444417953491, loss=0.708870530128479
train: epoch 142, loss 0.11033252626657486, acc=0.9618333578109741, loss=0.11033252626657486
test: epoch 142, loss 0.6365442276000977, acc=0.800000011920929, loss=0.6365442276000977
train: epoch 143, loss 0.11547882854938507, acc=0.960444450378418, loss=0.11547882854938507
test: epoch 143, loss 0.6002025604248047, acc=0.8055555820465088, loss=0.6002025604248047
train: epoch 144, loss 0.11651619523763657, acc=0.9598888754844666, loss=0.11651619523763657
test: epoch 144, loss 0.723274827003479, acc=0.7888888716697693, loss=0.723274827003479
train: epoch 145, loss 0.11880362033843994, acc=0.9582777619361877, loss=0.11880362033843994
test: epoch 145, loss 0.6412153840065002, acc=0.800000011920929, loss=0.6412153840065002
train: epoch 146, loss 0.11761275678873062, acc=0.9600555300712585, loss=0.11761275678873062
test: epoch 146, loss 0.6221895813941956, acc=0.8083333373069763, loss=0.6221895813941956
train: epoch 147, loss 0.11162704974412918, acc=0.9596666693687439, loss=0.11162704974412918
test: epoch 147, loss 0.699242353439331, acc=0.7861111164093018, loss=0.699242353439331
train: epoch 148, loss 0.11533540487289429, acc=0.9599444270133972, loss=0.11533540487289429
test: epoch 148, loss 0.5671885013580322, acc=0.8027777671813965, loss=0.5671885013580322
train: epoch 149, loss 0.12246844172477722, acc=0.9565555453300476, loss=0.12246844172477722
test: epoch 149, loss 0.7554119825363159, acc=0.8027777671813965, loss=0.7554119825363159
train: epoch 150, loss 0.11287805438041687, acc=0.9596111178398132, loss=0.11287805438041687
test: epoch 150, loss 0.6387342214584351, acc=0.8027777671813965, loss=0.6387342214584351
