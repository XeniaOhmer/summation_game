# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=2.0", "--temp_decay=0.99", "--one_hot=0", "--n_layers=1"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=1000897772, receiver_embed_dim=128, save_run=0, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=1000897772, receiver_embed_dim=128, save_run=False, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.937476873397827, acc=0.1063888892531395, loss=2.937476873397827
test: epoch 1, loss 6.292410850524902, acc=0.03888889029622078, loss=6.292410850524902
train: epoch 2, loss 2.4762794971466064, acc=0.16944444179534912, loss=2.4762794971466064
test: epoch 2, loss 7.7845635414123535, acc=0.0416666679084301, loss=7.7845635414123535
train: epoch 3, loss 2.3243775367736816, acc=0.19300000369548798, loss=2.3243775367736816
test: epoch 3, loss 8.801213264465332, acc=0.03611111268401146, loss=8.801213264465332
train: epoch 4, loss 2.2500226497650146, acc=0.21094444394111633, loss=2.2500226497650146
test: epoch 4, loss 9.517736434936523, acc=0.03611111268401146, loss=9.517736434936523
train: epoch 5, loss 2.19035005569458, acc=0.21627777814865112, loss=2.19035005569458
test: epoch 5, loss 9.838345527648926, acc=0.0416666679084301, loss=9.838345527648926
train: epoch 6, loss 2.1479685306549072, acc=0.22822222113609314, loss=2.1479685306549072
test: epoch 6, loss 10.112542152404785, acc=0.0416666679084301, loss=10.112542152404785
train: epoch 7, loss 2.1228113174438477, acc=0.2334444373846054, loss=2.1228113174438477
test: epoch 7, loss 10.159855842590332, acc=0.04444444552063942, loss=10.159855842590332
train: epoch 8, loss 2.0886499881744385, acc=0.24255555868148804, loss=2.0886499881744385
test: epoch 8, loss 10.627452850341797, acc=0.03611111268401146, loss=10.627452850341797
train: epoch 9, loss 2.058122158050537, acc=0.2442222237586975, loss=2.058122158050537
test: epoch 9, loss 11.103808403015137, acc=0.03888889029622078, loss=11.103808403015137
train: epoch 10, loss 2.047830820083618, acc=0.24650000035762787, loss=2.047830820083618
test: epoch 10, loss 11.012740135192871, acc=0.03055555559694767, loss=11.012740135192871
train: epoch 11, loss 2.0370309352874756, acc=0.253555566072464, loss=2.0370309352874756
test: epoch 11, loss 11.401948928833008, acc=0.0416666679084301, loss=11.401948928833008
train: epoch 12, loss 2.0155861377716064, acc=0.25716665387153625, loss=2.0155861377716064
test: epoch 12, loss 11.1357421875, acc=0.03888889029622078, loss=11.1357421875
train: epoch 13, loss 2.000159740447998, acc=0.2517777681350708, loss=2.000159740447998
test: epoch 13, loss 11.169350624084473, acc=0.03611111268401146, loss=11.169350624084473
train: epoch 14, loss 2.0097763538360596, acc=0.25566667318344116, loss=2.0097763538360596
test: epoch 14, loss 11.097661972045898, acc=0.03333333507180214, loss=11.097661972045898
train: epoch 15, loss 1.9842637777328491, acc=0.2529999911785126, loss=1.9842637777328491
test: epoch 15, loss 11.153341293334961, acc=0.03333333507180214, loss=11.153341293334961
train: epoch 16, loss 1.9745066165924072, acc=0.2626666724681854, loss=1.9745066165924072
test: epoch 16, loss 11.297286033630371, acc=0.03611111268401146, loss=11.297286033630371
train: epoch 17, loss 1.9797699451446533, acc=0.2587222158908844, loss=1.9797699451446533
test: epoch 17, loss 11.2404203414917, acc=0.03055555559694767, loss=11.2404203414917
train: epoch 18, loss 1.9667118787765503, acc=0.2687777876853943, loss=1.9667118787765503
test: epoch 18, loss 11.062188148498535, acc=0.03055555559694767, loss=11.062188148498535
train: epoch 19, loss 1.9610121250152588, acc=0.2726111114025116, loss=1.9610121250152588
test: epoch 19, loss 10.955717086791992, acc=0.02777777798473835, loss=10.955717086791992
train: epoch 20, loss 1.9707292318344116, acc=0.26499998569488525, loss=1.9707292318344116
test: epoch 20, loss 10.53767204284668, acc=0.03333333507180214, loss=10.53767204284668
train: epoch 21, loss 1.9579325914382935, acc=0.27077779173851013, loss=1.9579325914382935
test: epoch 21, loss 10.643824577331543, acc=0.03333333507180214, loss=10.643824577331543
train: epoch 22, loss 1.9469139575958252, acc=0.26838889718055725, loss=1.9469139575958252
test: epoch 22, loss 10.2470703125, acc=0.03333333507180214, loss=10.2470703125
train: epoch 23, loss 1.9477936029434204, acc=0.27344444394111633, loss=1.9477936029434204
test: epoch 23, loss 10.07229232788086, acc=0.03888889029622078, loss=10.07229232788086
train: epoch 24, loss 1.9649262428283691, acc=0.2711111009120941, loss=1.9649262428283691
test: epoch 24, loss 10.000988006591797, acc=0.0416666679084301, loss=10.000988006591797
train: epoch 25, loss 1.9681793451309204, acc=0.2646111249923706, loss=1.9681793451309204
test: epoch 25, loss 9.919118881225586, acc=0.03333333507180214, loss=9.919118881225586
train: epoch 26, loss 1.9519633054733276, acc=0.27444443106651306, loss=1.9519633054733276
test: epoch 26, loss 9.758522033691406, acc=0.03611111268401146, loss=9.758522033691406
train: epoch 27, loss 1.9484798908233643, acc=0.27416667342185974, loss=1.9484798908233643
test: epoch 27, loss 9.627890586853027, acc=0.02777777798473835, loss=9.627890586853027
train: epoch 28, loss 1.9433995485305786, acc=0.2786666750907898, loss=1.9433995485305786
test: epoch 28, loss 9.463890075683594, acc=0.03611111268401146, loss=9.463890075683594
train: epoch 29, loss 1.937599539756775, acc=0.27255555987358093, loss=1.937599539756775
test: epoch 29, loss 9.480561256408691, acc=0.03611111268401146, loss=9.480561256408691
train: epoch 30, loss 1.954813003540039, acc=0.26838889718055725, loss=1.954813003540039
test: epoch 30, loss 9.21155071258545, acc=0.03888889029622078, loss=9.21155071258545
train: epoch 31, loss 1.9594718217849731, acc=0.2743888795375824, loss=1.9594718217849731
test: epoch 31, loss 8.77818775177002, acc=0.02222222276031971, loss=8.77818775177002
train: epoch 32, loss 1.9381389617919922, acc=0.2805555462837219, loss=1.9381389617919922
test: epoch 32, loss 8.556038856506348, acc=0.03055555559694767, loss=8.556038856506348
train: epoch 33, loss 1.9500890970230103, acc=0.2770000100135803, loss=1.9500890970230103
test: epoch 33, loss 8.37476921081543, acc=0.03333333507180214, loss=8.37476921081543
train: epoch 34, loss 1.9630537033081055, acc=0.27516666054725647, loss=1.9630537033081055
test: epoch 34, loss 8.223071098327637, acc=0.03333333507180214, loss=8.223071098327637
train: epoch 35, loss 1.9529454708099365, acc=0.27844443917274475, loss=1.9529454708099365
test: epoch 35, loss 8.276634216308594, acc=0.03611111268401146, loss=8.276634216308594
train: epoch 36, loss 1.9481552839279175, acc=0.27238887548446655, loss=1.9481552839279175
test: epoch 36, loss 7.982766628265381, acc=0.03611111268401146, loss=7.982766628265381
train: epoch 37, loss 1.9641118049621582, acc=0.2706666588783264, loss=1.9641118049621582
test: epoch 37, loss 8.135292053222656, acc=0.03333333507180214, loss=8.135292053222656
train: epoch 38, loss 1.9562699794769287, acc=0.2759999930858612, loss=1.9562699794769287
test: epoch 38, loss 7.768036842346191, acc=0.03611111268401146, loss=7.768036842346191
train: epoch 39, loss 1.9556015729904175, acc=0.2749444544315338, loss=1.9556015729904175
test: epoch 39, loss 7.878415584564209, acc=0.03333333507180214, loss=7.878415584564209
train: epoch 40, loss 1.9639532566070557, acc=0.2778888940811157, loss=1.9639532566070557
test: epoch 40, loss 7.4761433601379395, acc=0.02777777798473835, loss=7.4761433601379395
train: epoch 41, loss 1.9797190427780151, acc=0.26944443583488464, loss=1.9797190427780151
test: epoch 41, loss 7.478111743927002, acc=0.03055555559694767, loss=7.478111743927002
train: epoch 42, loss 1.9786570072174072, acc=0.26722222566604614, loss=1.9786570072174072
test: epoch 42, loss 7.2316694259643555, acc=0.03611111268401146, loss=7.2316694259643555
train: epoch 43, loss 1.9767800569534302, acc=0.27488890290260315, loss=1.9767800569534302
test: epoch 43, loss 7.240520000457764, acc=0.03333333507180214, loss=7.240520000457764
train: epoch 44, loss 1.9767032861709595, acc=0.26988887786865234, loss=1.9767032861709595
test: epoch 44, loss 7.253279685974121, acc=0.0416666679084301, loss=7.253279685974121
train: epoch 45, loss 2.004124164581299, acc=0.2653333246707916, loss=2.004124164581299
test: epoch 45, loss 7.009924411773682, acc=0.03055555559694767, loss=7.009924411773682
train: epoch 46, loss 1.99692702293396, acc=0.26750001311302185, loss=1.99692702293396
test: epoch 46, loss 6.646611213684082, acc=0.03611111268401146, loss=6.646611213684082
train: epoch 47, loss 2.002798080444336, acc=0.2765555679798126, loss=2.002798080444336
test: epoch 47, loss 6.60206937789917, acc=0.0416666679084301, loss=6.60206937789917
train: epoch 48, loss 2.0036070346832275, acc=0.2644999921321869, loss=2.0036070346832275
test: epoch 48, loss 6.481332778930664, acc=0.03611111268401146, loss=6.481332778930664
train: epoch 49, loss 2.005894422531128, acc=0.26544445753097534, loss=2.005894422531128
test: epoch 49, loss 6.379249572753906, acc=0.0416666679084301, loss=6.379249572753906
train: epoch 50, loss 2.0168888568878174, acc=0.2633333206176758, loss=2.0168888568878174
test: epoch 50, loss 6.36263370513916, acc=0.03888889029622078, loss=6.36263370513916
train: epoch 51, loss 2.010688543319702, acc=0.2643333375453949, loss=2.010688543319702
test: epoch 51, loss 6.455873012542725, acc=0.03611111268401146, loss=6.455873012542725
train: epoch 52, loss 2.0245888233184814, acc=0.2628333270549774, loss=2.0245888233184814
test: epoch 52, loss 6.316760540008545, acc=0.0555555559694767, loss=6.316760540008545
train: epoch 53, loss 2.034381866455078, acc=0.26027777791023254, loss=2.034381866455078
test: epoch 53, loss 6.325611114501953, acc=0.04444444552063942, loss=6.325611114501953
train: epoch 54, loss 2.0447871685028076, acc=0.25905555486679077, loss=2.0447871685028076
test: epoch 54, loss 5.91826057434082, acc=0.05277777835726738, loss=5.91826057434082
train: epoch 55, loss 2.0628678798675537, acc=0.25727778673171997, loss=2.0628678798675537
test: epoch 55, loss 5.50673246383667, acc=0.0555555559694767, loss=5.50673246383667
train: epoch 56, loss 2.0437722206115723, acc=0.2571111023426056, loss=2.0437722206115723
test: epoch 56, loss 5.6358160972595215, acc=0.0555555559694767, loss=5.6358160972595215
train: epoch 57, loss 2.054016590118408, acc=0.25655555725097656, loss=2.054016590118408
test: epoch 57, loss 5.619890213012695, acc=0.0555555559694767, loss=5.619890213012695
train: epoch 58, loss 2.0668087005615234, acc=0.25511109828948975, loss=2.0668087005615234
test: epoch 58, loss 5.4910807609558105, acc=0.05000000074505806, loss=5.4910807609558105
train: epoch 59, loss 2.0704386234283447, acc=0.24755555391311646, loss=2.0704386234283447
test: epoch 59, loss 5.246654987335205, acc=0.0555555559694767, loss=5.246654987335205
train: epoch 60, loss 2.0814177989959717, acc=0.2508888840675354, loss=2.0814177989959717
test: epoch 60, loss 5.334656238555908, acc=0.0555555559694767, loss=5.334656238555908
train: epoch 61, loss 2.091257095336914, acc=0.24877777695655823, loss=2.091257095336914
test: epoch 61, loss 5.405930519104004, acc=0.0416666679084301, loss=5.405930519104004
train: epoch 62, loss 2.086695909500122, acc=0.24566666781902313, loss=2.086695909500122
test: epoch 62, loss 5.282838344573975, acc=0.0416666679084301, loss=5.282838344573975
train: epoch 63, loss 2.1006319522857666, acc=0.24133333563804626, loss=2.1006319522857666
test: epoch 63, loss 5.052234172821045, acc=0.03888889029622078, loss=5.052234172821045
train: epoch 64, loss 2.0946524143218994, acc=0.2417222261428833, loss=2.0946524143218994
test: epoch 64, loss 4.913865566253662, acc=0.03611111268401146, loss=4.913865566253662
train: epoch 65, loss 2.1252331733703613, acc=0.2409999966621399, loss=2.1252331733703613
test: epoch 65, loss 4.983313083648682, acc=0.03888889029622078, loss=4.983313083648682
train: epoch 66, loss 2.1262288093566895, acc=0.24266666173934937, loss=2.1262288093566895
test: epoch 66, loss 4.656383037567139, acc=0.0416666679084301, loss=4.656383037567139
train: epoch 67, loss 2.11864972114563, acc=0.23983334004878998, loss=2.11864972114563
test: epoch 67, loss 5.088963508605957, acc=0.03611111268401146, loss=5.088963508605957
train: epoch 68, loss 2.1206600666046143, acc=0.24161110818386078, loss=2.1206600666046143
test: epoch 68, loss 4.5250773429870605, acc=0.03611111268401146, loss=4.5250773429870605
train: epoch 69, loss 2.1387476921081543, acc=0.23250000178813934, loss=2.1387476921081543
test: epoch 69, loss 4.545016765594482, acc=0.0416666679084301, loss=4.545016765594482
train: epoch 70, loss 2.1183974742889404, acc=0.23783333599567413, loss=2.1183974742889404
test: epoch 70, loss 4.604063510894775, acc=0.05000000074505806, loss=4.604063510894775
train: epoch 71, loss 2.144796371459961, acc=0.23899999260902405, loss=2.144796371459961
test: epoch 71, loss 4.549673080444336, acc=0.05000000074505806, loss=4.549673080444336
train: epoch 72, loss 2.1629669666290283, acc=0.22983333468437195, loss=2.1629669666290283
test: epoch 72, loss 4.481088638305664, acc=0.04722222313284874, loss=4.481088638305664
train: epoch 73, loss 2.1620960235595703, acc=0.22433333098888397, loss=2.1620960235595703
test: epoch 73, loss 4.3802289962768555, acc=0.05833333358168602, loss=4.3802289962768555
train: epoch 74, loss 2.183302402496338, acc=0.22188888490200043, loss=2.183302402496338
test: epoch 74, loss 4.40048885345459, acc=0.05000000074505806, loss=4.40048885345459
train: epoch 75, loss 2.1432788372039795, acc=0.2260555624961853, loss=2.1432788372039795
test: epoch 75, loss 4.341960906982422, acc=0.06388889253139496, loss=4.341960906982422
train: epoch 76, loss 2.170769214630127, acc=0.2220555543899536, loss=2.170769214630127
test: epoch 76, loss 4.4255452156066895, acc=0.04722222313284874, loss=4.4255452156066895
train: epoch 77, loss 2.221895217895508, acc=0.2224999964237213, loss=2.221895217895508
test: epoch 77, loss 4.2224836349487305, acc=0.04444444552063942, loss=4.2224836349487305
train: epoch 78, loss 2.1819708347320557, acc=0.22611111402511597, loss=2.1819708347320557
test: epoch 78, loss 4.304402828216553, acc=0.05277777835726738, loss=4.304402828216553
train: epoch 79, loss 2.1823084354400635, acc=0.2195555567741394, loss=2.1823084354400635
test: epoch 79, loss 4.206068515777588, acc=0.0416666679084301, loss=4.206068515777588
train: epoch 80, loss 2.2084383964538574, acc=0.21772222220897675, loss=2.2084383964538574
test: epoch 80, loss 4.061249732971191, acc=0.0416666679084301, loss=4.061249732971191
train: epoch 81, loss 2.2263333797454834, acc=0.21827778220176697, loss=2.2263333797454834
test: epoch 81, loss 3.9589929580688477, acc=0.05833333358168602, loss=3.9589929580688477
train: epoch 82, loss 2.2279062271118164, acc=0.21161110699176788, loss=2.2279062271118164
test: epoch 82, loss 3.972426176071167, acc=0.06666667014360428, loss=3.972426176071167
train: epoch 83, loss 2.2241573333740234, acc=0.21311111748218536, loss=2.2241573333740234
test: epoch 83, loss 3.905413866043091, acc=0.06666667014360428, loss=3.905413866043091
train: epoch 84, loss 2.219893455505371, acc=0.20866666734218597, loss=2.219893455505371
test: epoch 84, loss 3.9152982234954834, acc=0.05000000074505806, loss=3.9152982234954834
train: epoch 85, loss 2.255854368209839, acc=0.20944444835186005, loss=2.255854368209839
test: epoch 85, loss 3.8657708168029785, acc=0.05277777835726738, loss=3.8657708168029785
train: epoch 86, loss 2.2664453983306885, acc=0.20616666972637177, loss=2.2664453983306885
test: epoch 86, loss 3.699850559234619, acc=0.0694444477558136, loss=3.699850559234619
train: epoch 87, loss 2.2617058753967285, acc=0.19938889145851135, loss=2.2617058753967285
test: epoch 87, loss 3.668980598449707, acc=0.05277777835726738, loss=3.668980598449707
train: epoch 88, loss 2.246492862701416, acc=0.20911110937595367, loss=2.246492862701416
test: epoch 88, loss 3.7026820182800293, acc=0.06111111119389534, loss=3.7026820182800293
train: epoch 89, loss 2.2523953914642334, acc=0.19750000536441803, loss=2.2523953914642334
test: epoch 89, loss 3.6551263332366943, acc=0.06666667014360428, loss=3.6551263332366943
train: epoch 90, loss 2.27352237701416, acc=0.20294444262981415, loss=2.27352237701416
test: epoch 90, loss 3.6525628566741943, acc=0.0555555559694767, loss=3.6525628566741943
train: epoch 91, loss 2.279242515563965, acc=0.19422222673892975, loss=2.279242515563965
test: epoch 91, loss 3.5373358726501465, acc=0.0694444477558136, loss=3.5373358726501465
train: epoch 92, loss 2.282277822494507, acc=0.19227777421474457, loss=2.282277822494507
test: epoch 92, loss 3.5442464351654053, acc=0.05833333358168602, loss=3.5442464351654053
train: epoch 93, loss 2.2796120643615723, acc=0.19861111044883728, loss=2.2796120643615723
test: epoch 93, loss 3.7862589359283447, acc=0.05833333358168602, loss=3.7862589359283447
train: epoch 94, loss 2.2930145263671875, acc=0.18761111795902252, loss=2.2930145263671875
test: epoch 94, loss 3.459287643432617, acc=0.05277777835726738, loss=3.459287643432617
train: epoch 95, loss 2.299426317214966, acc=0.18683333694934845, loss=2.299426317214966
test: epoch 95, loss 3.3804702758789062, acc=0.07500000298023224, loss=3.3804702758789062
train: epoch 96, loss 2.2912609577178955, acc=0.18994444608688354, loss=2.2912609577178955
test: epoch 96, loss 3.4310035705566406, acc=0.07500000298023224, loss=3.4310035705566406
train: epoch 97, loss 2.307138442993164, acc=0.1836666613817215, loss=2.307138442993164
test: epoch 97, loss 3.335468053817749, acc=0.06666667014360428, loss=3.335468053817749
train: epoch 98, loss 2.305128574371338, acc=0.18733333051204681, loss=2.305128574371338
test: epoch 98, loss 3.405092477798462, acc=0.07500000298023224, loss=3.405092477798462
train: epoch 99, loss 2.3041648864746094, acc=0.17972221970558167, loss=2.3041648864746094
test: epoch 99, loss 3.2781121730804443, acc=0.0833333358168602, loss=3.2781121730804443
train: epoch 100, loss 2.310354232788086, acc=0.18405555188655853, loss=2.310354232788086
test: epoch 100, loss 3.3325867652893066, acc=0.08611111342906952, loss=3.3325867652893066
train: epoch 101, loss 2.3263423442840576, acc=0.1783333271741867, loss=2.3263423442840576
test: epoch 101, loss 3.4134087562561035, acc=0.0694444477558136, loss=3.4134087562561035
train: epoch 102, loss 2.316570281982422, acc=0.18472221493721008, loss=2.316570281982422
test: epoch 102, loss 3.364389181137085, acc=0.05000000074505806, loss=3.364389181137085
train: epoch 103, loss 2.339747667312622, acc=0.1832222193479538, loss=2.339747667312622
test: epoch 103, loss 3.409331798553467, acc=0.05833333358168602, loss=3.409331798553467
train: epoch 104, loss 2.29996395111084, acc=0.18061110377311707, loss=2.29996395111084
test: epoch 104, loss 3.3177390098571777, acc=0.0833333358168602, loss=3.3177390098571777
train: epoch 105, loss 2.3055319786071777, acc=0.18383333086967468, loss=2.3055319786071777
test: epoch 105, loss 3.435685396194458, acc=0.06666667014360428, loss=3.435685396194458
train: epoch 106, loss 2.3187742233276367, acc=0.17994444072246552, loss=2.3187742233276367
test: epoch 106, loss 3.3845953941345215, acc=0.0416666679084301, loss=3.3845953941345215
train: epoch 107, loss 2.309077024459839, acc=0.1821666657924652, loss=2.309077024459839
test: epoch 107, loss 3.2828369140625, acc=0.0555555559694767, loss=3.2828369140625
train: epoch 108, loss 2.2915029525756836, acc=0.1854444444179535, loss=2.2915029525756836
test: epoch 108, loss 3.404409646987915, acc=0.04444444552063942, loss=3.404409646987915
train: epoch 109, loss 2.2863929271698, acc=0.19038888812065125, loss=2.2863929271698
test: epoch 109, loss 3.304060935974121, acc=0.07777778059244156, loss=3.304060935974121
train: epoch 110, loss 2.2999587059020996, acc=0.18788889050483704, loss=2.2999587059020996
test: epoch 110, loss 3.5486063957214355, acc=0.07500000298023224, loss=3.5486063957214355
train: epoch 111, loss 2.304079055786133, acc=0.18227778375148773, loss=2.304079055786133
test: epoch 111, loss 3.30476450920105, acc=0.07222222536802292, loss=3.30476450920105
train: epoch 112, loss 2.3134639263153076, acc=0.18561111390590668, loss=2.3134639263153076
test: epoch 112, loss 3.255324602127075, acc=0.09166666865348816, loss=3.255324602127075
train: epoch 113, loss 2.29841947555542, acc=0.1860000044107437, loss=2.29841947555542
test: epoch 113, loss 3.359128952026367, acc=0.0833333358168602, loss=3.359128952026367
train: epoch 114, loss 2.291620969772339, acc=0.18449999392032623, loss=2.291620969772339
test: epoch 114, loss 3.2306973934173584, acc=0.08888889104127884, loss=3.2306973934173584
train: epoch 115, loss 2.304525852203369, acc=0.18561111390590668, loss=2.304525852203369
test: epoch 115, loss 3.451488733291626, acc=0.06111111119389534, loss=3.451488733291626
train: epoch 116, loss 2.2850310802459717, acc=0.1868888884782791, loss=2.2850310802459717
test: epoch 116, loss 3.2235219478607178, acc=0.07222222536802292, loss=3.2235219478607178
train: epoch 117, loss 2.278163194656372, acc=0.1875, loss=2.278163194656372
test: epoch 117, loss 3.246704578399658, acc=0.07500000298023224, loss=3.246704578399658
train: epoch 118, loss 2.292100191116333, acc=0.18355555832386017, loss=2.292100191116333
test: epoch 118, loss 3.2682266235351562, acc=0.06111111119389534, loss=3.2682266235351562
train: epoch 119, loss 2.2871484756469727, acc=0.18827778100967407, loss=2.2871484756469727
test: epoch 119, loss 3.2489726543426514, acc=0.06666667014360428, loss=3.2489726543426514
train: epoch 120, loss 2.2997355461120605, acc=0.1805555522441864, loss=2.2997355461120605
test: epoch 120, loss 3.2319717407226562, acc=0.07500000298023224, loss=3.2319717407226562
train: epoch 121, loss 2.291494131088257, acc=0.18477778136730194, loss=2.291494131088257
test: epoch 121, loss 3.2882463932037354, acc=0.06666667014360428, loss=3.2882463932037354
train: epoch 122, loss 2.294410228729248, acc=0.18622222542762756, loss=2.294410228729248
test: epoch 122, loss 3.3393592834472656, acc=0.08888889104127884, loss=3.3393592834472656
train: epoch 123, loss 2.273538112640381, acc=0.189277783036232, loss=2.273538112640381
test: epoch 123, loss 3.295238733291626, acc=0.06388889253139496, loss=3.295238733291626
train: epoch 124, loss 2.275972843170166, acc=0.19216667115688324, loss=2.275972843170166
test: epoch 124, loss 3.3109688758850098, acc=0.04722222313284874, loss=3.3109688758850098
train: epoch 125, loss 2.268998861312866, acc=0.18711110949516296, loss=2.268998861312866
test: epoch 125, loss 3.301600933074951, acc=0.05833333358168602, loss=3.301600933074951
train: epoch 126, loss 2.2916903495788574, acc=0.18672221899032593, loss=2.2916903495788574
test: epoch 126, loss 3.28334903717041, acc=0.05833333358168602, loss=3.28334903717041
train: epoch 127, loss 2.282817840576172, acc=0.19216667115688324, loss=2.282817840576172
test: epoch 127, loss 3.2408287525177, acc=0.06666667014360428, loss=3.2408287525177
train: epoch 128, loss 2.266047954559326, acc=0.18994444608688354, loss=2.266047954559326
test: epoch 128, loss 3.288288116455078, acc=0.07222222536802292, loss=3.288288116455078
train: epoch 129, loss 2.2688324451446533, acc=0.18994444608688354, loss=2.2688324451446533
test: epoch 129, loss 3.3082234859466553, acc=0.05833333358168602, loss=3.3082234859466553
train: epoch 130, loss 2.2745068073272705, acc=0.19055555760860443, loss=2.2745068073272705
test: epoch 130, loss 3.2260384559631348, acc=0.05277777835726738, loss=3.2260384559631348
train: epoch 131, loss 2.2865676879882812, acc=0.19288888573646545, loss=2.2865676879882812
test: epoch 131, loss 3.197333574295044, acc=0.07222222536802292, loss=3.197333574295044
train: epoch 132, loss 2.2822558879852295, acc=0.18427777290344238, loss=2.2822558879852295
test: epoch 132, loss 3.2584989070892334, acc=0.0833333358168602, loss=3.2584989070892334
train: epoch 133, loss 2.2836544513702393, acc=0.18994444608688354, loss=2.2836544513702393
test: epoch 133, loss 3.3036274909973145, acc=0.08888889104127884, loss=3.3036274909973145
train: epoch 134, loss 2.3002803325653076, acc=0.18533332645893097, loss=2.3002803325653076
test: epoch 134, loss 3.339322328567505, acc=0.06111111119389534, loss=3.339322328567505
train: epoch 135, loss 2.278791904449463, acc=0.18994444608688354, loss=2.278791904449463
test: epoch 135, loss 3.2235121726989746, acc=0.05833333358168602, loss=3.2235121726989746
train: epoch 136, loss 2.270010232925415, acc=0.1891111135482788, loss=2.270010232925415
test: epoch 136, loss 3.282691478729248, acc=0.08611111342906952, loss=3.282691478729248
train: epoch 137, loss 2.279797077178955, acc=0.19205555319786072, loss=2.279797077178955
test: epoch 137, loss 3.1959402561187744, acc=0.09444444626569748, loss=3.1959402561187744
train: epoch 138, loss 2.2791333198547363, acc=0.1886666715145111, loss=2.2791333198547363
test: epoch 138, loss 3.241450071334839, acc=0.0694444477558136, loss=3.241450071334839
train: epoch 139, loss 2.2832295894622803, acc=0.1932777762413025, loss=2.2832295894622803
test: epoch 139, loss 3.133333444595337, acc=0.06111111119389534, loss=3.133333444595337
train: epoch 140, loss 2.2792935371398926, acc=0.18666666746139526, loss=2.2792935371398926
test: epoch 140, loss 3.116442918777466, acc=0.07500000298023224, loss=3.116442918777466
train: epoch 141, loss 2.274620294570923, acc=0.19077777862548828, loss=2.274620294570923
test: epoch 141, loss 3.2637417316436768, acc=0.0555555559694767, loss=3.2637417316436768
train: epoch 142, loss 2.2484755516052246, acc=0.19172222912311554, loss=2.2484755516052246
test: epoch 142, loss 3.3063700199127197, acc=0.05000000074505806, loss=3.3063700199127197
train: epoch 143, loss 2.2503538131713867, acc=0.1942777782678604, loss=2.2503538131713867
test: epoch 143, loss 3.2908523082733154, acc=0.05000000074505806, loss=3.2908523082733154
train: epoch 144, loss 2.2636282444000244, acc=0.19055555760860443, loss=2.2636282444000244
test: epoch 144, loss 3.3142735958099365, acc=0.07222222536802292, loss=3.3142735958099365
train: epoch 145, loss 2.2644336223602295, acc=0.19438889622688293, loss=2.2644336223602295
test: epoch 145, loss 3.24627423286438, acc=0.07500000298023224, loss=3.24627423286438
train: epoch 146, loss 2.2664413452148438, acc=0.19300000369548798, loss=2.2664413452148438
test: epoch 146, loss 3.1977760791778564, acc=0.08611111342906952, loss=3.1977760791778564
train: epoch 147, loss 2.2370922565460205, acc=0.19644445180892944, loss=2.2370922565460205
test: epoch 147, loss 3.300508737564087, acc=0.07500000298023224, loss=3.300508737564087
train: epoch 148, loss 2.25860333442688, acc=0.1883888840675354, loss=2.25860333442688
test: epoch 148, loss 3.219874858856201, acc=0.07500000298023224, loss=3.219874858856201
train: epoch 149, loss 2.2522449493408203, acc=0.19227777421474457, loss=2.2522449493408203
test: epoch 149, loss 3.094025135040283, acc=0.07777778059244156, loss=3.094025135040283
train: epoch 150, loss 2.274653196334839, acc=0.19333332777023315, loss=2.274653196334839
test: epoch 150, loss 3.0820679664611816, acc=0.0694444477558136, loss=3.0820679664611816
