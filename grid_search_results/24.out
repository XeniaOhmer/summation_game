# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=0", "--n_layers=1"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=845849906, receiver_embed_dim=32, save_run=0, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=845849906, receiver_embed_dim=32, save_run=False, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.251626968383789, acc=0.07027778029441833, loss=3.251626968383789
test: epoch 1, loss 4.218281269073486, acc=0.03611111268401146, loss=4.218281269073486
train: epoch 2, loss 2.7631070613861084, acc=0.13066667318344116, loss=2.7631070613861084
test: epoch 2, loss 4.906516075134277, acc=0.03611111268401146, loss=4.906516075134277
train: epoch 3, loss 2.605577230453491, acc=0.14872221648693085, loss=2.605577230453491
test: epoch 3, loss 5.326246738433838, acc=0.03888889029622078, loss=5.326246738433838
train: epoch 4, loss 2.5123775005340576, acc=0.16122221946716309, loss=2.5123775005340576
test: epoch 4, loss 5.776799201965332, acc=0.0416666679084301, loss=5.776799201965332
train: epoch 5, loss 2.460937023162842, acc=0.16966666281223297, loss=2.460937023162842
test: epoch 5, loss 5.923940658569336, acc=0.04722222313284874, loss=5.923940658569336
train: epoch 6, loss 2.4196536540985107, acc=0.17949999868869781, loss=2.4196536540985107
test: epoch 6, loss 5.978449821472168, acc=0.05277777835726738, loss=5.978449821472168
train: epoch 7, loss 2.3984220027923584, acc=0.1826111078262329, loss=2.3984220027923584
test: epoch 7, loss 6.1117048263549805, acc=0.04722222313284874, loss=6.1117048263549805
train: epoch 8, loss 2.3626644611358643, acc=0.1888333261013031, loss=2.3626644611358643
test: epoch 8, loss 6.186224460601807, acc=0.04722222313284874, loss=6.186224460601807
train: epoch 9, loss 2.3358395099639893, acc=0.18799999356269836, loss=2.3358395099639893
test: epoch 9, loss 6.3298444747924805, acc=0.04444444552063942, loss=6.3298444747924805
train: epoch 10, loss 2.3267662525177, acc=0.19588889181613922, loss=2.3267662525177
test: epoch 10, loss 6.48113489151001, acc=0.04444444552063942, loss=6.48113489151001
train: epoch 11, loss 2.2982587814331055, acc=0.19511111080646515, loss=2.2982587814331055
test: epoch 11, loss 6.466626167297363, acc=0.04444444552063942, loss=6.466626167297363
train: epoch 12, loss 2.2772605419158936, acc=0.2006666660308838, loss=2.2772605419158936
test: epoch 12, loss 6.5227556228637695, acc=0.0416666679084301, loss=6.5227556228637695
train: epoch 13, loss 2.264031171798706, acc=0.21044445037841797, loss=2.264031171798706
test: epoch 13, loss 6.550023078918457, acc=0.03888889029622078, loss=6.550023078918457
train: epoch 14, loss 2.253899097442627, acc=0.21161110699176788, loss=2.253899097442627
test: epoch 14, loss 6.66594934463501, acc=0.03888889029622078, loss=6.66594934463501
train: epoch 15, loss 2.238060474395752, acc=0.20961111783981323, loss=2.238060474395752
test: epoch 15, loss 6.595686912536621, acc=0.03888889029622078, loss=6.595686912536621
train: epoch 16, loss 2.2342047691345215, acc=0.21583333611488342, loss=2.2342047691345215
test: epoch 16, loss 6.73442268371582, acc=0.03611111268401146, loss=6.73442268371582
train: epoch 17, loss 2.2172441482543945, acc=0.22438888251781464, loss=2.2172441482543945
test: epoch 17, loss 6.5841064453125, acc=0.03888889029622078, loss=6.5841064453125
train: epoch 18, loss 2.203996181488037, acc=0.22477777302265167, loss=2.203996181488037
test: epoch 18, loss 6.6134819984436035, acc=0.03888889029622078, loss=6.6134819984436035
train: epoch 19, loss 2.1973280906677246, acc=0.22344444692134857, loss=2.1973280906677246
test: epoch 19, loss 6.695776462554932, acc=0.0416666679084301, loss=6.695776462554932
train: epoch 20, loss 2.191699266433716, acc=0.22361111640930176, loss=2.191699266433716
test: epoch 20, loss 6.540097713470459, acc=0.04722222313284874, loss=6.540097713470459
train: epoch 21, loss 2.179356575012207, acc=0.22522221505641937, loss=2.179356575012207
test: epoch 21, loss 6.44860315322876, acc=0.03888889029622078, loss=6.44860315322876
train: epoch 22, loss 2.184951066970825, acc=0.22461111843585968, loss=2.184951066970825
test: epoch 22, loss 6.3983683586120605, acc=0.0416666679084301, loss=6.3983683586120605
train: epoch 23, loss 2.1625466346740723, acc=0.22905555367469788, loss=2.1625466346740723
test: epoch 23, loss 6.4209394454956055, acc=0.04444444552063942, loss=6.4209394454956055
train: epoch 24, loss 2.1746387481689453, acc=0.23066666722297668, loss=2.1746387481689453
test: epoch 24, loss 6.244189739227295, acc=0.04444444552063942, loss=6.244189739227295
train: epoch 25, loss 2.1514899730682373, acc=0.2361111044883728, loss=2.1514899730682373
test: epoch 25, loss 6.241546154022217, acc=0.04444444552063942, loss=6.241546154022217
train: epoch 26, loss 2.1565630435943604, acc=0.23755554854869843, loss=2.1565630435943604
test: epoch 26, loss 5.989437103271484, acc=0.04444444552063942, loss=5.989437103271484
train: epoch 27, loss 2.1526026725769043, acc=0.23705555498600006, loss=2.1526026725769043
test: epoch 27, loss 5.996461391448975, acc=0.04444444552063942, loss=5.996461391448975
train: epoch 28, loss 2.146419048309326, acc=0.23894444108009338, loss=2.146419048309326
test: epoch 28, loss 6.0801100730896, acc=0.0416666679084301, loss=6.0801100730896
train: epoch 29, loss 2.1492345333099365, acc=0.24455556273460388, loss=2.1492345333099365
test: epoch 29, loss 5.964287281036377, acc=0.03888889029622078, loss=5.964287281036377
train: epoch 30, loss 2.1459908485412598, acc=0.24205555021762848, loss=2.1459908485412598
test: epoch 30, loss 5.942441940307617, acc=0.04444444552063942, loss=5.942441940307617
train: epoch 31, loss 2.1239571571350098, acc=0.23838889598846436, loss=2.1239571571350098
test: epoch 31, loss 6.082980632781982, acc=0.0416666679084301, loss=6.082980632781982
train: epoch 32, loss 2.124255657196045, acc=0.24461111426353455, loss=2.124255657196045
test: epoch 32, loss 6.162281036376953, acc=0.0416666679084301, loss=6.162281036376953
train: epoch 33, loss 2.1235616207122803, acc=0.24327777326107025, loss=2.1235616207122803
test: epoch 33, loss 5.837143421173096, acc=0.03611111268401146, loss=5.837143421173096
train: epoch 34, loss 2.1222798824310303, acc=0.24294444918632507, loss=2.1222798824310303
test: epoch 34, loss 6.013784408569336, acc=0.03611111268401146, loss=6.013784408569336
train: epoch 35, loss 2.1279282569885254, acc=0.24250000715255737, loss=2.1279282569885254
test: epoch 35, loss 5.731151103973389, acc=0.03888889029622078, loss=5.731151103973389
train: epoch 36, loss 2.1129655838012695, acc=0.24238888919353485, loss=2.1129655838012695
test: epoch 36, loss 5.902600288391113, acc=0.03611111268401146, loss=5.902600288391113
train: epoch 37, loss 2.114013910293579, acc=0.24433332681655884, loss=2.114013910293579
test: epoch 37, loss 5.732363224029541, acc=0.04444444552063942, loss=5.732363224029541
train: epoch 38, loss 2.1190454959869385, acc=0.24655555188655853, loss=2.1190454959869385
test: epoch 38, loss 5.6802873611450195, acc=0.03611111268401146, loss=5.6802873611450195
train: epoch 39, loss 2.113572597503662, acc=0.2477777749300003, loss=2.113572597503662
test: epoch 39, loss 5.6970624923706055, acc=0.03333333507180214, loss=5.6970624923706055
train: epoch 40, loss 2.1077215671539307, acc=0.2513333261013031, loss=2.1077215671539307
test: epoch 40, loss 5.483339309692383, acc=0.04444444552063942, loss=5.483339309692383
train: epoch 41, loss 2.1220500469207764, acc=0.2502777874469757, loss=2.1220500469207764
test: epoch 41, loss 5.661368370056152, acc=0.04722222313284874, loss=5.661368370056152
train: epoch 42, loss 2.1152236461639404, acc=0.2493888884782791, loss=2.1152236461639404
test: epoch 42, loss 5.359645843505859, acc=0.0416666679084301, loss=5.359645843505859
train: epoch 43, loss 2.1126034259796143, acc=0.25200000405311584, loss=2.1126034259796143
test: epoch 43, loss 5.4653401374816895, acc=0.0416666679084301, loss=5.4653401374816895
train: epoch 44, loss 2.114346742630005, acc=0.24516665935516357, loss=2.114346742630005
test: epoch 44, loss 5.7414445877075195, acc=0.03611111268401146, loss=5.7414445877075195
train: epoch 45, loss 2.108098268508911, acc=0.24899999797344208, loss=2.108098268508911
test: epoch 45, loss 5.417623519897461, acc=0.03333333507180214, loss=5.417623519897461
train: epoch 46, loss 2.1136415004730225, acc=0.2460000067949295, loss=2.1136415004730225
test: epoch 46, loss 5.544510841369629, acc=0.03888889029622078, loss=5.544510841369629
train: epoch 47, loss 2.10495924949646, acc=0.25244444608688354, loss=2.10495924949646
test: epoch 47, loss 5.371211051940918, acc=0.03333333507180214, loss=5.371211051940918
train: epoch 48, loss 2.103761911392212, acc=0.24711111187934875, loss=2.103761911392212
test: epoch 48, loss 5.271228313446045, acc=0.03333333507180214, loss=5.271228313446045
train: epoch 49, loss 2.104515314102173, acc=0.2507777810096741, loss=2.104515314102173
test: epoch 49, loss 5.326752662658691, acc=0.03888889029622078, loss=5.326752662658691
train: epoch 50, loss 2.10139799118042, acc=0.25450000166893005, loss=2.10139799118042
test: epoch 50, loss 5.333416938781738, acc=0.03611111268401146, loss=5.333416938781738
train: epoch 51, loss 2.0960381031036377, acc=0.25033333897590637, loss=2.0960381031036377
test: epoch 51, loss 5.342098712921143, acc=0.03333333507180214, loss=5.342098712921143
train: epoch 52, loss 2.091914415359497, acc=0.2561666667461395, loss=2.091914415359497
test: epoch 52, loss 5.270641326904297, acc=0.03611111268401146, loss=5.270641326904297
train: epoch 53, loss 2.1101691722869873, acc=0.24861110746860504, loss=2.1101691722869873
test: epoch 53, loss 5.102992534637451, acc=0.03333333507180214, loss=5.102992534637451
train: epoch 54, loss 2.089937210083008, acc=0.2510555684566498, loss=2.089937210083008
test: epoch 54, loss 5.300595760345459, acc=0.03611111268401146, loss=5.300595760345459
train: epoch 55, loss 2.0971179008483887, acc=0.24833333492279053, loss=2.0971179008483887
test: epoch 55, loss 5.292483329772949, acc=0.03888889029622078, loss=5.292483329772949
train: epoch 56, loss 2.106842517852783, acc=0.24988888204097748, loss=2.106842517852783
test: epoch 56, loss 4.946483135223389, acc=0.03333333507180214, loss=4.946483135223389
train: epoch 57, loss 2.0919039249420166, acc=0.2521111071109772, loss=2.0919039249420166
test: epoch 57, loss 5.182911396026611, acc=0.03333333507180214, loss=5.182911396026611
train: epoch 58, loss 2.101069211959839, acc=0.2525555491447449, loss=2.101069211959839
test: epoch 58, loss 5.004055023193359, acc=0.04722222313284874, loss=5.004055023193359
train: epoch 59, loss 2.09846830368042, acc=0.2548333406448364, loss=2.09846830368042
test: epoch 59, loss 4.931491374969482, acc=0.05277777835726738, loss=4.931491374969482
train: epoch 60, loss 2.099132537841797, acc=0.2483888864517212, loss=2.099132537841797
test: epoch 60, loss 4.910109996795654, acc=0.03888889029622078, loss=4.910109996795654
train: epoch 61, loss 2.093693733215332, acc=0.25138887763023376, loss=2.093693733215332
test: epoch 61, loss 4.7606048583984375, acc=0.04444444552063942, loss=4.7606048583984375
train: epoch 62, loss 2.113232374191284, acc=0.25033333897590637, loss=2.113232374191284
test: epoch 62, loss 4.962340831756592, acc=0.0416666679084301, loss=4.962340831756592
train: epoch 63, loss 2.094661235809326, acc=0.2538333237171173, loss=2.094661235809326
test: epoch 63, loss 4.648587703704834, acc=0.0416666679084301, loss=4.648587703704834
train: epoch 64, loss 2.1045901775360107, acc=0.24844443798065186, loss=2.1045901775360107
test: epoch 64, loss 4.6452155113220215, acc=0.03611111268401146, loss=4.6452155113220215
train: epoch 65, loss 2.113086700439453, acc=0.2533888816833496, loss=2.113086700439453
test: epoch 65, loss 4.881585597991943, acc=0.03888889029622078, loss=4.881585597991943
train: epoch 66, loss 2.101304292678833, acc=0.2532222270965576, loss=2.101304292678833
test: epoch 66, loss 4.829704761505127, acc=0.03333333507180214, loss=4.829704761505127
train: epoch 67, loss 2.1016733646392822, acc=0.2543888986110687, loss=2.1016733646392822
test: epoch 67, loss 4.674368858337402, acc=0.03611111268401146, loss=4.674368858337402
train: epoch 68, loss 2.1157357692718506, acc=0.2548333406448364, loss=2.1157357692718506
test: epoch 68, loss 4.790502071380615, acc=0.0416666679084301, loss=4.790502071380615
train: epoch 69, loss 2.1259350776672363, acc=0.24905554950237274, loss=2.1259350776672363
test: epoch 69, loss 4.574829578399658, acc=0.03888889029622078, loss=4.574829578399658
train: epoch 70, loss 2.112123489379883, acc=0.2528333365917206, loss=2.112123489379883
test: epoch 70, loss 4.522338390350342, acc=0.04444444552063942, loss=4.522338390350342
train: epoch 71, loss 2.1136703491210938, acc=0.2475000023841858, loss=2.1136703491210938
test: epoch 71, loss 4.582365989685059, acc=0.03888889029622078, loss=4.582365989685059
train: epoch 72, loss 2.1015877723693848, acc=0.2517777681350708, loss=2.1015877723693848
test: epoch 72, loss 4.402316093444824, acc=0.03888889029622078, loss=4.402316093444824
train: epoch 73, loss 2.138648748397827, acc=0.24994444847106934, loss=2.138648748397827
test: epoch 73, loss 4.317275047302246, acc=0.0416666679084301, loss=4.317275047302246
train: epoch 74, loss 2.1138837337493896, acc=0.2536666691303253, loss=2.1138837337493896
test: epoch 74, loss 4.479629039764404, acc=0.03888889029622078, loss=4.479629039764404
train: epoch 75, loss 2.130561590194702, acc=0.2495555579662323, loss=2.130561590194702
test: epoch 75, loss 4.274539947509766, acc=0.0416666679084301, loss=4.274539947509766
train: epoch 76, loss 2.117307186126709, acc=0.24922221899032593, loss=2.117307186126709
test: epoch 76, loss 4.387951850891113, acc=0.03888889029622078, loss=4.387951850891113
train: epoch 77, loss 2.1257612705230713, acc=0.25127777457237244, loss=2.1257612705230713
test: epoch 77, loss 4.359184265136719, acc=0.05833333358168602, loss=4.359184265136719
train: epoch 78, loss 2.141707181930542, acc=0.24799999594688416, loss=2.141707181930542
test: epoch 78, loss 4.426549911499023, acc=0.03611111268401146, loss=4.426549911499023
train: epoch 79, loss 2.1164612770080566, acc=0.24638888239860535, loss=2.1164612770080566
test: epoch 79, loss 4.364831447601318, acc=0.0555555559694767, loss=4.364831447601318
train: epoch 80, loss 2.1232192516326904, acc=0.24994444847106934, loss=2.1232192516326904
test: epoch 80, loss 4.290836811065674, acc=0.06666667014360428, loss=4.290836811065674
train: epoch 81, loss 2.1335344314575195, acc=0.24461111426353455, loss=2.1335344314575195
test: epoch 81, loss 4.310037612915039, acc=0.05277777835726738, loss=4.310037612915039
train: epoch 82, loss 2.1218063831329346, acc=0.25200000405311584, loss=2.1218063831329346
test: epoch 82, loss 4.312040328979492, acc=0.0416666679084301, loss=4.312040328979492
train: epoch 83, loss 2.1423819065093994, acc=0.2395000010728836, loss=2.1423819065093994
test: epoch 83, loss 4.203205585479736, acc=0.05277777835726738, loss=4.203205585479736
train: epoch 84, loss 2.1360511779785156, acc=0.24449999630451202, loss=2.1360511779785156
test: epoch 84, loss 4.2701520919799805, acc=0.05277777835726738, loss=4.2701520919799805
train: epoch 85, loss 2.134838104248047, acc=0.25022223591804504, loss=2.134838104248047
test: epoch 85, loss 4.184540271759033, acc=0.0555555559694767, loss=4.184540271759033
train: epoch 86, loss 2.146486759185791, acc=0.24711111187934875, loss=2.146486759185791
test: epoch 86, loss 4.233870506286621, acc=0.0416666679084301, loss=4.233870506286621
train: epoch 87, loss 2.1364476680755615, acc=0.23977777361869812, loss=2.1364476680755615
test: epoch 87, loss 4.181973457336426, acc=0.04722222313284874, loss=4.181973457336426
train: epoch 88, loss 2.131765127182007, acc=0.2414444386959076, loss=2.131765127182007
test: epoch 88, loss 4.177367687225342, acc=0.05277777835726738, loss=4.177367687225342
train: epoch 89, loss 2.1342599391937256, acc=0.2432222217321396, loss=2.1342599391937256
test: epoch 89, loss 4.077703475952148, acc=0.05000000074505806, loss=4.077703475952148
train: epoch 90, loss 2.1428143978118896, acc=0.24455556273460388, loss=2.1428143978118896
test: epoch 90, loss 4.0341572761535645, acc=0.05277777835726738, loss=4.0341572761535645
train: epoch 91, loss 2.137861967086792, acc=0.24444444477558136, loss=2.137861967086792
test: epoch 91, loss 3.8866889476776123, acc=0.06666667014360428, loss=3.8866889476776123
train: epoch 92, loss 2.154480457305908, acc=0.23855555057525635, loss=2.154480457305908
test: epoch 92, loss 3.8893473148345947, acc=0.05000000074505806, loss=3.8893473148345947
train: epoch 93, loss 2.145670175552368, acc=0.244111105799675, loss=2.145670175552368
test: epoch 93, loss 3.875192642211914, acc=0.07222222536802292, loss=3.875192642211914
train: epoch 94, loss 2.1660830974578857, acc=0.2412777841091156, loss=2.1660830974578857
test: epoch 94, loss 3.8998234272003174, acc=0.05277777835726738, loss=3.8998234272003174
train: epoch 95, loss 2.163426399230957, acc=0.23894444108009338, loss=2.163426399230957
test: epoch 95, loss 3.8033156394958496, acc=0.0555555559694767, loss=3.8033156394958496
train: epoch 96, loss 2.1676292419433594, acc=0.24072222411632538, loss=2.1676292419433594
test: epoch 96, loss 3.8637466430664062, acc=0.05277777835726738, loss=3.8637466430664062
train: epoch 97, loss 2.150099754333496, acc=0.23661111295223236, loss=2.150099754333496
test: epoch 97, loss 3.8855748176574707, acc=0.05000000074505806, loss=3.8855748176574707
train: epoch 98, loss 2.1603734493255615, acc=0.23372222483158112, loss=2.1603734493255615
test: epoch 98, loss 3.946640729904175, acc=0.05000000074505806, loss=3.946640729904175
train: epoch 99, loss 2.170135021209717, acc=0.23938888311386108, loss=2.170135021209717
test: epoch 99, loss 3.8990039825439453, acc=0.06111111119389534, loss=3.8990039825439453
train: epoch 100, loss 2.1705992221832275, acc=0.24338889122009277, loss=2.1705992221832275
test: epoch 100, loss 3.8751354217529297, acc=0.05833333358168602, loss=3.8751354217529297
train: epoch 101, loss 2.164807081222534, acc=0.24027778208255768, loss=2.164807081222534
test: epoch 101, loss 3.746914863586426, acc=0.0555555559694767, loss=3.746914863586426
train: epoch 102, loss 2.169874906539917, acc=0.23527777194976807, loss=2.169874906539917
test: epoch 102, loss 3.762275218963623, acc=0.05833333358168602, loss=3.762275218963623
train: epoch 103, loss 2.183459997177124, acc=0.23472222685813904, loss=2.183459997177124
test: epoch 103, loss 3.6331565380096436, acc=0.05833333358168602, loss=3.6331565380096436
train: epoch 104, loss 2.1874899864196777, acc=0.23738889396190643, loss=2.1874899864196777
test: epoch 104, loss 3.816035032272339, acc=0.07222222536802292, loss=3.816035032272339
train: epoch 105, loss 2.17929744720459, acc=0.23805555701255798, loss=2.17929744720459
test: epoch 105, loss 3.8021721839904785, acc=0.05833333358168602, loss=3.8021721839904785
train: epoch 106, loss 2.1758530139923096, acc=0.23333333432674408, loss=2.1758530139923096
test: epoch 106, loss 3.7236132621765137, acc=0.06111111119389534, loss=3.7236132621765137
train: epoch 107, loss 2.16921067237854, acc=0.23383332788944244, loss=2.16921067237854
test: epoch 107, loss 3.6283910274505615, acc=0.06111111119389534, loss=3.6283910274505615
train: epoch 108, loss 2.17266845703125, acc=0.23644444346427917, loss=2.17266845703125
test: epoch 108, loss 3.6247482299804688, acc=0.07222222536802292, loss=3.6247482299804688
train: epoch 109, loss 2.1917073726654053, acc=0.23783333599567413, loss=2.1917073726654053
test: epoch 109, loss 3.6809346675872803, acc=0.0694444477558136, loss=3.6809346675872803
train: epoch 110, loss 2.1745011806488037, acc=0.22983333468437195, loss=2.1745011806488037
test: epoch 110, loss 3.6663262844085693, acc=0.06111111119389534, loss=3.6663262844085693
train: epoch 111, loss 2.188948154449463, acc=0.23194444179534912, loss=2.188948154449463
test: epoch 111, loss 3.7314884662628174, acc=0.0555555559694767, loss=3.7314884662628174
train: epoch 112, loss 2.1916091442108154, acc=0.23250000178813934, loss=2.1916091442108154
test: epoch 112, loss 3.677293539047241, acc=0.06666667014360428, loss=3.677293539047241
train: epoch 113, loss 2.18849515914917, acc=0.22644443809986115, loss=2.18849515914917
test: epoch 113, loss 3.5561792850494385, acc=0.07222222536802292, loss=3.5561792850494385
train: epoch 114, loss 2.190560817718506, acc=0.22550000250339508, loss=2.190560817718506
test: epoch 114, loss 3.5829970836639404, acc=0.0694444477558136, loss=3.5829970836639404
train: epoch 115, loss 2.177783727645874, acc=0.23038889467716217, loss=2.177783727645874
test: epoch 115, loss 3.554445505142212, acc=0.06111111119389534, loss=3.554445505142212
train: epoch 116, loss 2.200195074081421, acc=0.22272221744060516, loss=2.200195074081421
test: epoch 116, loss 3.503826379776001, acc=0.06388889253139496, loss=3.503826379776001
train: epoch 117, loss 2.1910829544067383, acc=0.22627778351306915, loss=2.1910829544067383
test: epoch 117, loss 3.612338066101074, acc=0.05833333358168602, loss=3.612338066101074
train: epoch 118, loss 2.196917772293091, acc=0.22388888895511627, loss=2.196917772293091
test: epoch 118, loss 3.3894925117492676, acc=0.06388889253139496, loss=3.3894925117492676
train: epoch 119, loss 2.192258358001709, acc=0.22861111164093018, loss=2.192258358001709
test: epoch 119, loss 3.353012800216675, acc=0.07222222536802292, loss=3.353012800216675
train: epoch 120, loss 2.2217676639556885, acc=0.23000000417232513, loss=2.2217676639556885
test: epoch 120, loss 3.448946475982666, acc=0.08055555820465088, loss=3.448946475982666
train: epoch 121, loss 2.2050817012786865, acc=0.22538888454437256, loss=2.2050817012786865
test: epoch 121, loss 3.3640761375427246, acc=0.07500000298023224, loss=3.3640761375427246
train: epoch 122, loss 2.1976170539855957, acc=0.2282777726650238, loss=2.1976170539855957
test: epoch 122, loss 3.4687423706054688, acc=0.08611111342906952, loss=3.4687423706054688
train: epoch 123, loss 2.2206716537475586, acc=0.2199999988079071, loss=2.2206716537475586
test: epoch 123, loss 3.3743104934692383, acc=0.06111111119389534, loss=3.3743104934692383
train: epoch 124, loss 2.207817554473877, acc=0.22277778387069702, loss=2.207817554473877
test: epoch 124, loss 3.436647653579712, acc=0.09166666865348816, loss=3.436647653579712
train: epoch 125, loss 2.2072906494140625, acc=0.21449999511241913, loss=2.2072906494140625
test: epoch 125, loss 3.435063123703003, acc=0.05277777835726738, loss=3.435063123703003
train: epoch 126, loss 2.2226240634918213, acc=0.21922221779823303, loss=2.2226240634918213
test: epoch 126, loss 3.2775561809539795, acc=0.07500000298023224, loss=3.2775561809539795
train: epoch 127, loss 2.2122104167938232, acc=0.2224999964237213, loss=2.2122104167938232
test: epoch 127, loss 3.4036388397216797, acc=0.06388889253139496, loss=3.4036388397216797
train: epoch 128, loss 2.2173306941986084, acc=0.22272221744060516, loss=2.2173306941986084
test: epoch 128, loss 3.479720115661621, acc=0.08611111342906952, loss=3.479720115661621
train: epoch 129, loss 2.21230149269104, acc=0.22316665947437286, loss=2.21230149269104
test: epoch 129, loss 3.4437906742095947, acc=0.07777778059244156, loss=3.4437906742095947
train: epoch 130, loss 2.2218642234802246, acc=0.22038888931274414, loss=2.2218642234802246
test: epoch 130, loss 3.3890042304992676, acc=0.0694444477558136, loss=3.3890042304992676
train: epoch 131, loss 2.223151922225952, acc=0.2179444432258606, loss=2.223151922225952
test: epoch 131, loss 3.339967966079712, acc=0.05277777835726738, loss=3.339967966079712
train: epoch 132, loss 2.227276563644409, acc=0.22244444489479065, loss=2.227276563644409
test: epoch 132, loss 3.3501088619232178, acc=0.06666667014360428, loss=3.3501088619232178
train: epoch 133, loss 2.2056491374969482, acc=0.218833327293396, loss=2.2056491374969482
test: epoch 133, loss 3.4093215465545654, acc=0.0833333358168602, loss=3.4093215465545654
train: epoch 134, loss 2.207775831222534, acc=0.21994444727897644, loss=2.207775831222534
test: epoch 134, loss 3.366885185241699, acc=0.0833333358168602, loss=3.366885185241699
train: epoch 135, loss 2.224045515060425, acc=0.22083333134651184, loss=2.224045515060425
test: epoch 135, loss 3.2893006801605225, acc=0.07222222536802292, loss=3.2893006801605225
train: epoch 136, loss 2.245659112930298, acc=0.2160000056028366, loss=2.245659112930298
test: epoch 136, loss 3.3046157360076904, acc=0.06388889253139496, loss=3.3046157360076904
train: epoch 137, loss 2.2175040245056152, acc=0.21655555069446564, loss=2.2175040245056152
test: epoch 137, loss 3.3044373989105225, acc=0.08611111342906952, loss=3.3044373989105225
train: epoch 138, loss 2.24648380279541, acc=0.2083333283662796, loss=2.24648380279541
test: epoch 138, loss 3.2043261528015137, acc=0.09444444626569748, loss=3.2043261528015137
train: epoch 139, loss 2.2399961948394775, acc=0.21088889241218567, loss=2.2399961948394775
test: epoch 139, loss 3.1376771926879883, acc=0.09166666865348816, loss=3.1376771926879883
train: epoch 140, loss 2.2175498008728027, acc=0.21672222018241882, loss=2.2175498008728027
test: epoch 140, loss 3.2956788539886475, acc=0.09166666865348816, loss=3.2956788539886475
train: epoch 141, loss 2.218874931335449, acc=0.21477778255939484, loss=2.218874931335449
test: epoch 141, loss 3.2989606857299805, acc=0.10277777910232544, loss=3.2989606857299805
train: epoch 142, loss 2.2133476734161377, acc=0.21449999511241913, loss=2.2133476734161377
test: epoch 142, loss 3.1033267974853516, acc=0.12222222238779068, loss=3.1033267974853516
train: epoch 143, loss 2.221518039703369, acc=0.2197222262620926, loss=2.221518039703369
test: epoch 143, loss 3.1883864402770996, acc=0.07777778059244156, loss=3.1883864402770996
train: epoch 144, loss 2.2118892669677734, acc=0.2166111171245575, loss=2.2118892669677734
test: epoch 144, loss 3.3738675117492676, acc=0.08611111342906952, loss=3.3738675117492676
train: epoch 145, loss 2.21553635597229, acc=0.2121666669845581, loss=2.21553635597229
test: epoch 145, loss 3.277757406234741, acc=0.07777778059244156, loss=3.277757406234741
train: epoch 146, loss 2.2157161235809326, acc=0.21872222423553467, loss=2.2157161235809326
test: epoch 146, loss 3.3642737865448, acc=0.07777778059244156, loss=3.3642737865448
train: epoch 147, loss 2.229888916015625, acc=0.21344444155693054, loss=2.229888916015625
test: epoch 147, loss 3.217677116394043, acc=0.08055555820465088, loss=3.217677116394043
train: epoch 148, loss 2.1923635005950928, acc=0.21916666626930237, loss=2.1923635005950928
test: epoch 148, loss 3.2296178340911865, acc=0.07500000298023224, loss=3.2296178340911865
train: epoch 149, loss 2.2013306617736816, acc=0.2160000056028366, loss=2.2013306617736816
test: epoch 149, loss 3.216895580291748, acc=0.0833333358168602, loss=3.216895580291748
train: epoch 150, loss 2.21174693107605, acc=0.2231111079454422, loss=2.21174693107605
test: epoch 150, loss 3.247237205505371, acc=0.08611111342906952, loss=3.247237205505371
