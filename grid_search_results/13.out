# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1", "--temp_decay=0.99", "--one_hot=true", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=965673585, receiver_embed_dim=32, temp_decay=0.99, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.292188882827759, acc=0.0573333315551281, loss=3.292188882827759
test: epoch 1, loss 2.8250298500061035, acc=0.10000000149011612, loss=2.8250298500061035
train: epoch 2, loss 2.4223709106445312, acc=0.1619444489479065, loss=2.4223709106445312
test: epoch 2, loss 2.504190444946289, acc=0.14166666567325592, loss=2.504190444946289
train: epoch 3, loss 1.991295337677002, acc=0.253888875246048, loss=1.991295337677002
test: epoch 3, loss 2.125847816467285, acc=0.18611110746860504, loss=2.125847816467285
train: epoch 4, loss 1.6421821117401123, acc=0.33505555987358093, loss=1.6421821117401123
test: epoch 4, loss 2.0822103023529053, acc=0.20277777314186096, loss=2.0822103023529053
train: epoch 5, loss 1.4769136905670166, acc=0.3958333432674408, loss=1.4769136905670166
test: epoch 5, loss 1.9058572053909302, acc=0.25833332538604736, loss=1.9058572053909302
train: epoch 6, loss 1.3696613311767578, acc=0.43549999594688416, loss=1.3696613311767578
test: epoch 6, loss 1.8038727045059204, acc=0.24444444477558136, loss=1.8038727045059204
train: epoch 7, loss 1.2856099605560303, acc=0.4637777805328369, loss=1.2856099605560303
test: epoch 7, loss 1.8082321882247925, acc=0.29722222685813904, loss=1.8082321882247925
train: epoch 8, loss 1.2064509391784668, acc=0.4858333468437195, loss=1.2064509391784668
test: epoch 8, loss 1.7368476390838623, acc=0.29722222685813904, loss=1.7368476390838623
train: epoch 9, loss 1.161311388015747, acc=0.5057222247123718, loss=1.161311388015747
test: epoch 9, loss 1.6459959745407104, acc=0.3083333373069763, loss=1.6459959745407104
train: epoch 10, loss 1.1113395690917969, acc=0.5187222361564636, loss=1.1113395690917969
test: epoch 10, loss 1.536917805671692, acc=0.34166666865348816, loss=1.536917805671692
train: epoch 11, loss 1.0529894828796387, acc=0.5486666560173035, loss=1.0529894828796387
test: epoch 11, loss 1.5163166522979736, acc=0.3638888895511627, loss=1.5163166522979736
train: epoch 12, loss 1.0284289121627808, acc=0.5587777495384216, loss=1.0284289121627808
test: epoch 12, loss 1.4690289497375488, acc=0.3305555582046509, loss=1.4690289497375488
train: epoch 13, loss 0.9913812875747681, acc=0.5745555758476257, loss=0.9913812875747681
test: epoch 13, loss 1.5074530839920044, acc=0.3499999940395355, loss=1.5074530839920044
train: epoch 14, loss 0.9653087258338928, acc=0.582611083984375, loss=0.9653087258338928
test: epoch 14, loss 1.4645472764968872, acc=0.3722222149372101, loss=1.4645472764968872
train: epoch 15, loss 0.9098843932151794, acc=0.6035000085830688, loss=0.9098843932151794
test: epoch 15, loss 1.5070784091949463, acc=0.35555556416511536, loss=1.5070784091949463
train: epoch 16, loss 0.905799925327301, acc=0.6089444160461426, loss=0.905799925327301
test: epoch 16, loss 1.4874179363250732, acc=0.38055557012557983, loss=1.4874179363250732
train: epoch 17, loss 0.8841570615768433, acc=0.6122778058052063, loss=0.8841570615768433
test: epoch 17, loss 1.67345130443573, acc=0.38333332538604736, loss=1.67345130443573
train: epoch 18, loss 0.8637496829032898, acc=0.6203888654708862, loss=0.8637496829032898
test: epoch 18, loss 1.457314133644104, acc=0.3888888955116272, loss=1.457314133644104
train: epoch 19, loss 0.844025731086731, acc=0.6347222328186035, loss=0.844025731086731
test: epoch 19, loss 1.435094952583313, acc=0.4194444417953491, loss=1.435094952583313
train: epoch 20, loss 0.8204019665718079, acc=0.6429444551467896, loss=0.8204019665718079
test: epoch 20, loss 1.5594940185546875, acc=0.4000000059604645, loss=1.5594940185546875
train: epoch 21, loss 0.8148108124732971, acc=0.6445000171661377, loss=0.8148108124732971
test: epoch 21, loss 1.5701528787612915, acc=0.41111111640930176, loss=1.5701528787612915
train: epoch 22, loss 0.7898756265640259, acc=0.6568333506584167, loss=0.7898756265640259
test: epoch 22, loss 1.460932731628418, acc=0.39444443583488464, loss=1.460932731628418
train: epoch 23, loss 0.7882429361343384, acc=0.6551111340522766, loss=0.7882429361343384
test: epoch 23, loss 1.3636395931243896, acc=0.4444444477558136, loss=1.3636395931243896
train: epoch 24, loss 0.7751147747039795, acc=0.6579444408416748, loss=0.7751147747039795
test: epoch 24, loss 1.6355180740356445, acc=0.3722222149372101, loss=1.6355180740356445
train: epoch 25, loss 0.7542745471000671, acc=0.6682222485542297, loss=0.7542745471000671
test: epoch 25, loss 1.5362106561660767, acc=0.4277777671813965, loss=1.5362106561660767
train: epoch 26, loss 0.754364550113678, acc=0.6662222146987915, loss=0.754364550113678
test: epoch 26, loss 1.441285252571106, acc=0.4194444417953491, loss=1.441285252571106
train: epoch 27, loss 0.7502933740615845, acc=0.6713888645172119, loss=0.7502933740615845
test: epoch 27, loss 1.464536190032959, acc=0.4555555582046509, loss=1.464536190032959
train: epoch 28, loss 0.7453209161758423, acc=0.6775000095367432, loss=0.7453209161758423
test: epoch 28, loss 1.5090543031692505, acc=0.4444444477558136, loss=1.5090543031692505
train: epoch 29, loss 0.703982949256897, acc=0.6881666779518127, loss=0.703982949256897
test: epoch 29, loss 1.4495929479599, acc=0.4444444477558136, loss=1.4495929479599
train: epoch 30, loss 0.7084395289421082, acc=0.6851111054420471, loss=0.7084395289421082
test: epoch 30, loss 1.593764305114746, acc=0.40833333134651184, loss=1.593764305114746
train: epoch 31, loss 0.7049564719200134, acc=0.6886110901832581, loss=0.7049564719200134
test: epoch 31, loss 1.5910980701446533, acc=0.4055555462837219, loss=1.5910980701446533
train: epoch 32, loss 0.6860714554786682, acc=0.7003333568572998, loss=0.6860714554786682
test: epoch 32, loss 1.5122498273849487, acc=0.43888887763023376, loss=1.5122498273849487
train: epoch 33, loss 0.6807066798210144, acc=0.699833333492279, loss=0.6807066798210144
test: epoch 33, loss 1.5586893558502197, acc=0.40833333134651184, loss=1.5586893558502197
train: epoch 34, loss 0.6710296273231506, acc=0.7031111121177673, loss=0.6710296273231506
test: epoch 34, loss 1.7993135452270508, acc=0.43611112236976624, loss=1.7993135452270508
train: epoch 35, loss 0.670970618724823, acc=0.7029444575309753, loss=0.670970618724823
test: epoch 35, loss 1.4160600900650024, acc=0.46666666865348816, loss=1.4160600900650024
train: epoch 36, loss 0.6634668707847595, acc=0.7070000171661377, loss=0.6634668707847595
test: epoch 36, loss 1.2678747177124023, acc=0.4583333432674408, loss=1.2678747177124023
train: epoch 37, loss 0.6605933904647827, acc=0.7105000019073486, loss=0.6605933904647827
test: epoch 37, loss 1.492140769958496, acc=0.4444444477558136, loss=1.492140769958496
train: epoch 38, loss 0.6539298892021179, acc=0.7062222361564636, loss=0.6539298892021179
test: epoch 38, loss 1.5520333051681519, acc=0.4444444477558136, loss=1.5520333051681519
train: epoch 39, loss 0.6384996771812439, acc=0.7171111106872559, loss=0.6384996771812439
test: epoch 39, loss 1.612745761871338, acc=0.42222222685813904, loss=1.612745761871338
train: epoch 40, loss 0.6455782055854797, acc=0.7118889093399048, loss=0.6455782055854797
test: epoch 40, loss 1.458755373954773, acc=0.43888887763023376, loss=1.458755373954773
train: epoch 41, loss 0.6167022585868835, acc=0.7271666526794434, loss=0.6167022585868835
test: epoch 41, loss 1.527213215827942, acc=0.44999998807907104, loss=1.527213215827942
train: epoch 42, loss 0.6194512248039246, acc=0.7208333611488342, loss=0.6194512248039246
test: epoch 42, loss 1.4047589302062988, acc=0.46388888359069824, loss=1.4047589302062988
train: epoch 43, loss 0.6108140349388123, acc=0.7244444489479065, loss=0.6108140349388123
test: epoch 43, loss 1.6288827657699585, acc=0.44999998807907104, loss=1.6288827657699585
train: epoch 44, loss 0.6139745116233826, acc=0.7233333587646484, loss=0.6139745116233826
test: epoch 44, loss 1.3516422510147095, acc=0.46666666865348816, loss=1.3516422510147095
train: epoch 45, loss 0.6210542321205139, acc=0.7251111268997192, loss=0.6210542321205139
test: epoch 45, loss 1.3689277172088623, acc=0.4749999940395355, loss=1.3689277172088623
train: epoch 46, loss 0.6206402778625488, acc=0.7232221961021423, loss=0.6206402778625488
test: epoch 46, loss 1.4038138389587402, acc=0.4694444537162781, loss=1.4038138389587402
train: epoch 47, loss 0.5944932103157043, acc=0.7314444184303284, loss=0.5944932103157043
test: epoch 47, loss 1.5035905838012695, acc=0.45277777314186096, loss=1.5035905838012695
train: epoch 48, loss 0.604805588722229, acc=0.7307222485542297, loss=0.604805588722229
test: epoch 48, loss 1.3949071168899536, acc=0.47777777910232544, loss=1.3949071168899536
train: epoch 49, loss 0.5896119475364685, acc=0.7342222332954407, loss=0.5896119475364685
test: epoch 49, loss 1.5593763589859009, acc=0.4583333432674408, loss=1.5593763589859009
train: epoch 50, loss 0.6128637790679932, acc=0.7276111245155334, loss=0.6128637790679932
test: epoch 50, loss 1.4711564779281616, acc=0.46388888359069824, loss=1.4711564779281616
train: epoch 51, loss 0.595252513885498, acc=0.7331666946411133, loss=0.595252513885498
test: epoch 51, loss 1.4501943588256836, acc=0.4749999940395355, loss=1.4501943588256836
train: epoch 52, loss 0.5869954228401184, acc=0.7401666641235352, loss=0.5869954228401184
test: epoch 52, loss 1.5661039352416992, acc=0.47777777910232544, loss=1.5661039352416992
train: epoch 53, loss 0.5831971168518066, acc=0.7369444370269775, loss=0.5831971168518066
test: epoch 53, loss 1.4124196767807007, acc=0.4611110985279083, loss=1.4124196767807007
train: epoch 54, loss 0.5891820788383484, acc=0.7318333387374878, loss=0.5891820788383484
test: epoch 54, loss 1.4043669700622559, acc=0.49444442987442017, loss=1.4043669700622559
train: epoch 55, loss 0.5770595669746399, acc=0.7411666512489319, loss=0.5770595669746399
test: epoch 55, loss 1.596751093864441, acc=0.49166667461395264, loss=1.596751093864441
train: epoch 56, loss 0.5789976119995117, acc=0.7390000224113464, loss=0.5789976119995117
test: epoch 56, loss 1.463478922843933, acc=0.4833333194255829, loss=1.463478922843933
train: epoch 57, loss 0.5783211588859558, acc=0.7396110892295837, loss=0.5783211588859558
test: epoch 57, loss 1.4576596021652222, acc=0.4833333194255829, loss=1.4576596021652222
train: epoch 58, loss 0.570088267326355, acc=0.742388904094696, loss=0.570088267326355
test: epoch 58, loss 1.3869209289550781, acc=0.5166666507720947, loss=1.3869209289550781
train: epoch 59, loss 0.5864083170890808, acc=0.7396110892295837, loss=0.5864083170890808
test: epoch 59, loss 1.4662116765975952, acc=0.5027777552604675, loss=1.4662116765975952
train: epoch 60, loss 0.5816839337348938, acc=0.7398889064788818, loss=0.5816839337348938
test: epoch 60, loss 1.196661114692688, acc=0.5055555701255798, loss=1.196661114692688
train: epoch 61, loss 0.5541983842849731, acc=0.7477777600288391, loss=0.5541983842849731
test: epoch 61, loss 1.526154637336731, acc=0.46388888359069824, loss=1.526154637336731
train: epoch 62, loss 0.5931644439697266, acc=0.738444447517395, loss=0.5931644439697266
test: epoch 62, loss 1.314469814300537, acc=0.49444442987442017, loss=1.314469814300537
train: epoch 63, loss 0.5598606467247009, acc=0.7483888864517212, loss=0.5598606467247009
test: epoch 63, loss 1.4337140321731567, acc=0.47777777910232544, loss=1.4337140321731567
train: epoch 64, loss 0.5607144236564636, acc=0.7452222108840942, loss=0.5607144236564636
test: epoch 64, loss 1.5879255533218384, acc=0.4833333194255829, loss=1.5879255533218384
train: epoch 65, loss 0.5591796636581421, acc=0.7503888607025146, loss=0.5591796636581421
test: epoch 65, loss 1.4724681377410889, acc=0.49444442987442017, loss=1.4724681377410889
train: epoch 66, loss 0.5622060298919678, acc=0.7480000257492065, loss=0.5622060298919678
test: epoch 66, loss 1.3614118099212646, acc=0.49444442987442017, loss=1.3614118099212646
train: epoch 67, loss 0.5458805561065674, acc=0.7545555830001831, loss=0.5458805561065674
test: epoch 67, loss 1.3245521783828735, acc=0.49444442987442017, loss=1.3245521783828735
train: epoch 68, loss 0.5647689700126648, acc=0.7479444742202759, loss=0.5647689700126648
test: epoch 68, loss 1.4258863925933838, acc=0.4888888895511627, loss=1.4258863925933838
train: epoch 69, loss 0.5528783798217773, acc=0.7503888607025146, loss=0.5528783798217773
test: epoch 69, loss 1.551744818687439, acc=0.49444442987442017, loss=1.551744818687439
train: epoch 70, loss 0.555754542350769, acc=0.746222198009491, loss=0.555754542350769
test: epoch 70, loss 1.4654874801635742, acc=0.49166667461395264, loss=1.4654874801635742
train: epoch 71, loss 0.5626055598258972, acc=0.7466111183166504, loss=0.5626055598258972
test: epoch 71, loss 1.4806537628173828, acc=0.4833333194255829, loss=1.4806537628173828
train: epoch 72, loss 0.5424210429191589, acc=0.7527222037315369, loss=0.5424210429191589
test: epoch 72, loss 1.4903486967086792, acc=0.5111111402511597, loss=1.4903486967086792
train: epoch 73, loss 0.5456534624099731, acc=0.7536666393280029, loss=0.5456534624099731
test: epoch 73, loss 1.4702403545379639, acc=0.49166667461395264, loss=1.4702403545379639
train: epoch 74, loss 0.5466719269752502, acc=0.7525555491447449, loss=0.5466719269752502
test: epoch 74, loss 1.5438212156295776, acc=0.49444442987442017, loss=1.5438212156295776
train: epoch 75, loss 0.5530940294265747, acc=0.7513889074325562, loss=0.5530940294265747
test: epoch 75, loss 1.46983003616333, acc=0.4861111044883728, loss=1.46983003616333
train: epoch 76, loss 0.5363869667053223, acc=0.762499988079071, loss=0.5363869667053223
test: epoch 76, loss 1.4069503545761108, acc=0.5305555462837219, loss=1.4069503545761108
train: epoch 77, loss 0.5427811741828918, acc=0.7546111345291138, loss=0.5427811741828918
test: epoch 77, loss 1.3397492170333862, acc=0.5333333611488342, loss=1.3397492170333862
train: epoch 78, loss 0.5428341627120972, acc=0.7548888921737671, loss=0.5428341627120972
test: epoch 78, loss 1.4442037343978882, acc=0.5111111402511597, loss=1.4442037343978882
train: epoch 79, loss 0.5502484440803528, acc=0.753944456577301, loss=0.5502484440803528
test: epoch 79, loss 1.4163620471954346, acc=0.4888888895511627, loss=1.4163620471954346
train: epoch 80, loss 0.5389930605888367, acc=0.7559999823570251, loss=0.5389930605888367
test: epoch 80, loss 1.317873477935791, acc=0.5055555701255798, loss=1.317873477935791
train: epoch 81, loss 0.5371461510658264, acc=0.7608888745307922, loss=0.5371461510658264
test: epoch 81, loss 1.4597294330596924, acc=0.5305555462837219, loss=1.4597294330596924
train: epoch 82, loss 0.5421883463859558, acc=0.7561110854148865, loss=0.5421883463859558
test: epoch 82, loss 1.444459080696106, acc=0.49166667461395264, loss=1.444459080696106
train: epoch 83, loss 0.5272666215896606, acc=0.7576666474342346, loss=0.5272666215896606
test: epoch 83, loss 1.5297214984893799, acc=0.5138888955116272, loss=1.5297214984893799
train: epoch 84, loss 0.534592866897583, acc=0.7537222504615784, loss=0.534592866897583
test: epoch 84, loss 1.2908376455307007, acc=0.5305555462837219, loss=1.2908376455307007
train: epoch 85, loss 0.5388401746749878, acc=0.7579444646835327, loss=0.5388401746749878
test: epoch 85, loss 1.273278832435608, acc=0.5416666865348816, loss=1.273278832435608
train: epoch 86, loss 0.5306003093719482, acc=0.7581666707992554, loss=0.5306003093719482
test: epoch 86, loss 1.4855132102966309, acc=0.5027777552604675, loss=1.4855132102966309
train: epoch 87, loss 0.5298030376434326, acc=0.7577221989631653, loss=0.5298030376434326
test: epoch 87, loss 1.3834096193313599, acc=0.5222222208976746, loss=1.3834096193313599
train: epoch 88, loss 0.5293669700622559, acc=0.7565000057220459, loss=0.5293669700622559
test: epoch 88, loss 1.0815733671188354, acc=0.5388888716697693, loss=1.0815733671188354
train: epoch 89, loss 0.5148488283157349, acc=0.7673333287239075, loss=0.5148488283157349
test: epoch 89, loss 1.4488881826400757, acc=0.5305555462837219, loss=1.4488881826400757
train: epoch 90, loss 0.5114994049072266, acc=0.7698333263397217, loss=0.5114994049072266
test: epoch 90, loss 1.5321730375289917, acc=0.5388888716697693, loss=1.5321730375289917
train: epoch 91, loss 0.5102337598800659, acc=0.7683333158493042, loss=0.5102337598800659
test: epoch 91, loss 1.1651469469070435, acc=0.550000011920929, loss=1.1651469469070435
train: epoch 92, loss 0.49860212206840515, acc=0.7723888754844666, loss=0.49860212206840515
test: epoch 92, loss 1.451062560081482, acc=0.5416666865348816, loss=1.451062560081482
train: epoch 93, loss 0.5139066576957703, acc=0.7666666507720947, loss=0.5139066576957703
test: epoch 93, loss 1.2751492261886597, acc=0.5305555462837219, loss=1.2751492261886597
train: epoch 94, loss 0.48260074853897095, acc=0.7771111130714417, loss=0.48260074853897095
test: epoch 94, loss 1.4927424192428589, acc=0.49166667461395264, loss=1.4927424192428589
train: epoch 95, loss 0.4882960021495819, acc=0.7780555486679077, loss=0.4882960021495819
test: epoch 95, loss 1.3519710302352905, acc=0.5305555462837219, loss=1.3519710302352905
train: epoch 96, loss 0.49455514550209045, acc=0.773722231388092, loss=0.49455514550209045
test: epoch 96, loss 1.187296986579895, acc=0.5805555582046509, loss=1.187296986579895
train: epoch 97, loss 0.49371838569641113, acc=0.7781111001968384, loss=0.49371838569641113
test: epoch 97, loss 1.3362258672714233, acc=0.5305555462837219, loss=1.3362258672714233
train: epoch 98, loss 0.49535390734672546, acc=0.7758888602256775, loss=0.49535390734672546
test: epoch 98, loss 1.3117763996124268, acc=0.5666666626930237, loss=1.3117763996124268
train: epoch 99, loss 0.48310476541519165, acc=0.7816110849380493, loss=0.48310476541519165
test: epoch 99, loss 1.2664483785629272, acc=0.5555555820465088, loss=1.2664483785629272
train: epoch 100, loss 0.5020549297332764, acc=0.773277759552002, loss=0.5020549297332764
test: epoch 100, loss 1.3537949323654175, acc=0.5416666865348816, loss=1.3537949323654175
train: epoch 101, loss 0.4838571846485138, acc=0.7787777781486511, loss=0.4838571846485138
test: epoch 101, loss 1.3083027601242065, acc=0.5611110925674438, loss=1.3083027601242065
train: epoch 102, loss 0.48160240054130554, acc=0.7837777733802795, loss=0.48160240054130554
test: epoch 102, loss 1.2657618522644043, acc=0.5777778029441833, loss=1.2657618522644043
train: epoch 103, loss 0.48894202709198, acc=0.7811111211776733, loss=0.48894202709198
test: epoch 103, loss 1.2391602993011475, acc=0.5722222328186035, loss=1.2391602993011475
train: epoch 104, loss 0.4786539673805237, acc=0.7862777709960938, loss=0.4786539673805237
test: epoch 104, loss 1.2694957256317139, acc=0.574999988079071, loss=1.2694957256317139
train: epoch 105, loss 0.48713645339012146, acc=0.7801111340522766, loss=0.48713645339012146
test: epoch 105, loss 1.5160058736801147, acc=0.5777778029441833, loss=1.5160058736801147
train: epoch 106, loss 0.48116302490234375, acc=0.782444417476654, loss=0.48116302490234375
test: epoch 106, loss 1.385341763496399, acc=0.5638889074325562, loss=1.385341763496399
train: epoch 107, loss 0.4764312207698822, acc=0.7839444279670715, loss=0.4764312207698822
test: epoch 107, loss 1.3984160423278809, acc=0.5777778029441833, loss=1.3984160423278809
train: epoch 108, loss 0.48345139622688293, acc=0.7821666598320007, loss=0.48345139622688293
test: epoch 108, loss 1.6445286273956299, acc=0.5472221970558167, loss=1.6445286273956299
train: epoch 109, loss 0.4680350422859192, acc=0.7866666913032532, loss=0.4680350422859192
test: epoch 109, loss 1.2593438625335693, acc=0.5777778029441833, loss=1.2593438625335693
train: epoch 110, loss 0.4904457926750183, acc=0.7775555849075317, loss=0.4904457926750183
test: epoch 110, loss 1.269974708557129, acc=0.5638889074325562, loss=1.269974708557129
train: epoch 111, loss 0.4726758301258087, acc=0.7820000052452087, loss=0.4726758301258087
test: epoch 111, loss 1.3454469442367554, acc=0.574999988079071, loss=1.3454469442367554
train: epoch 112, loss 0.4719313085079193, acc=0.7852222323417664, loss=0.4719313085079193
test: epoch 112, loss 1.3530826568603516, acc=0.5722222328186035, loss=1.3530826568603516
train: epoch 113, loss 0.47866448760032654, acc=0.7836111187934875, loss=0.47866448760032654
test: epoch 113, loss 1.4498622417449951, acc=0.5388888716697693, loss=1.4498622417449951
train: epoch 114, loss 0.47587132453918457, acc=0.7836666703224182, loss=0.47587132453918457
test: epoch 114, loss 1.1812044382095337, acc=0.5722222328186035, loss=1.1812044382095337
train: epoch 115, loss 0.4679708182811737, acc=0.7877222299575806, loss=0.4679708182811737
test: epoch 115, loss 1.3479784727096558, acc=0.5805555582046509, loss=1.3479784727096558
train: epoch 116, loss 0.4686436653137207, acc=0.7881110906600952, loss=0.4686436653137207
test: epoch 116, loss 1.5690877437591553, acc=0.5555555820465088, loss=1.5690877437591553
train: epoch 117, loss 0.4629255533218384, acc=0.7850000262260437, loss=0.4629255533218384
test: epoch 117, loss 1.4081926345825195, acc=0.5416666865348816, loss=1.4081926345825195
train: epoch 118, loss 0.45794999599456787, acc=0.7896111011505127, loss=0.45794999599456787
test: epoch 118, loss 1.2276852130889893, acc=0.5555555820465088, loss=1.2276852130889893
train: epoch 119, loss 0.477141410112381, acc=0.784500002861023, loss=0.477141410112381
test: epoch 119, loss 1.2021708488464355, acc=0.5833333134651184, loss=1.2021708488464355
train: epoch 120, loss 0.47125348448753357, acc=0.7827222347259521, loss=0.47125348448753357
test: epoch 120, loss 1.204015851020813, acc=0.5694444179534912, loss=1.204015851020813
train: epoch 121, loss 0.46703261137008667, acc=0.7839444279670715, loss=0.46703261137008667
test: epoch 121, loss 1.3719362020492554, acc=0.5722222328186035, loss=1.3719362020492554
train: epoch 122, loss 0.4762471318244934, acc=0.7795000076293945, loss=0.4762471318244934
test: epoch 122, loss 1.2162587642669678, acc=0.5694444179534912, loss=1.2162587642669678
train: epoch 123, loss 0.4650338590145111, acc=0.784333348274231, loss=0.4650338590145111
test: epoch 123, loss 1.3065240383148193, acc=0.5777778029441833, loss=1.3065240383148193
train: epoch 124, loss 0.45481014251708984, acc=0.7878333330154419, loss=0.45481014251708984
test: epoch 124, loss 1.3911139965057373, acc=0.5638889074325562, loss=1.3911139965057373
train: epoch 125, loss 0.4527727961540222, acc=0.7894444465637207, loss=0.4527727961540222
test: epoch 125, loss 1.2512876987457275, acc=0.5861111283302307, loss=1.2512876987457275
train: epoch 126, loss 0.47269272804260254, acc=0.7850000262260437, loss=0.47269272804260254
test: epoch 126, loss 1.254205346107483, acc=0.5694444179534912, loss=1.254205346107483
train: epoch 127, loss 0.4725371301174164, acc=0.7825000286102295, loss=0.4725371301174164
test: epoch 127, loss 1.2650114297866821, acc=0.5777778029441833, loss=1.2650114297866821
train: epoch 128, loss 0.4579901397228241, acc=0.7867777943611145, loss=0.4579901397228241
test: epoch 128, loss 1.225525140762329, acc=0.5805555582046509, loss=1.225525140762329
train: epoch 129, loss 0.4591934084892273, acc=0.7886666655540466, loss=0.4591934084892273
test: epoch 129, loss 1.2323299646377563, acc=0.5777778029441833, loss=1.2323299646377563
train: epoch 130, loss 0.4685388207435608, acc=0.7888333201408386, loss=0.4685388207435608
test: epoch 130, loss 1.2484279870986938, acc=0.5722222328186035, loss=1.2484279870986938
train: epoch 131, loss 0.454693078994751, acc=0.7929444313049316, loss=0.454693078994751
test: epoch 131, loss 1.3555232286453247, acc=0.5611110925674438, loss=1.3555232286453247
train: epoch 132, loss 0.4696742594242096, acc=0.7874444723129272, loss=0.4696742594242096
test: epoch 132, loss 1.2320938110351562, acc=0.5805555582046509, loss=1.2320938110351562
train: epoch 133, loss 0.4767318069934845, acc=0.785111129283905, loss=0.4767318069934845
test: epoch 133, loss 1.2207467555999756, acc=0.5833333134651184, loss=1.2207467555999756
train: epoch 134, loss 0.4664675295352936, acc=0.7845555543899536, loss=0.4664675295352936
test: epoch 134, loss 1.168845295906067, acc=0.5472221970558167, loss=1.168845295906067
train: epoch 135, loss 0.4487757086753845, acc=0.7965555787086487, loss=0.4487757086753845
test: epoch 135, loss 1.3754733800888062, acc=0.5555555820465088, loss=1.3754733800888062
train: epoch 136, loss 0.4532417058944702, acc=0.7932778000831604, loss=0.4532417058944702
test: epoch 136, loss 1.135787844657898, acc=0.5833333134651184, loss=1.135787844657898
train: epoch 137, loss 0.4551014006137848, acc=0.792888879776001, loss=0.4551014006137848
test: epoch 137, loss 1.3082025051116943, acc=0.5805555582046509, loss=1.3082025051116943
train: epoch 138, loss 0.4600033760070801, acc=0.7958333492279053, loss=0.4600033760070801
test: epoch 138, loss 1.3922027349472046, acc=0.5611110925674438, loss=1.3922027349472046
train: epoch 139, loss 0.46324530243873596, acc=0.7917222380638123, loss=0.46324530243873596
test: epoch 139, loss 1.2334654331207275, acc=0.574999988079071, loss=1.2334654331207275
train: epoch 140, loss 0.4530757963657379, acc=0.7913333177566528, loss=0.4530757963657379
test: epoch 140, loss 1.3436590433120728, acc=0.5833333134651184, loss=1.3436590433120728
train: epoch 141, loss 0.4508245289325714, acc=0.7957777976989746, loss=0.4508245289325714
test: epoch 141, loss 1.3404254913330078, acc=0.5861111283302307, loss=1.3404254913330078
train: epoch 142, loss 0.4535115361213684, acc=0.7971110939979553, loss=0.4535115361213684
test: epoch 142, loss 1.353713035583496, acc=0.5833333134651184, loss=1.353713035583496
train: epoch 143, loss 0.4551379680633545, acc=0.7960555553436279, loss=0.4551379680633545
test: epoch 143, loss 1.3540126085281372, acc=0.5722222328186035, loss=1.3540126085281372
train: epoch 144, loss 0.45883357524871826, acc=0.7909444570541382, loss=0.45883357524871826
test: epoch 144, loss 1.1622161865234375, acc=0.5833333134651184, loss=1.1622161865234375
train: epoch 145, loss 0.4532979130744934, acc=0.7966111302375793, loss=0.4532979130744934
test: epoch 145, loss 1.2582933902740479, acc=0.5833333134651184, loss=1.2582933902740479
train: epoch 146, loss 0.46364256739616394, acc=0.7912222146987915, loss=0.46364256739616394
test: epoch 146, loss 1.105567216873169, acc=0.5833333134651184, loss=1.105567216873169
train: epoch 147, loss 0.4391268789768219, acc=0.7960555553436279, loss=0.4391268789768219
test: epoch 147, loss 1.2576336860656738, acc=0.5861111283302307, loss=1.2576336860656738
train: epoch 148, loss 0.46698567271232605, acc=0.788611114025116, loss=0.46698567271232605
test: epoch 148, loss 1.2936604022979736, acc=0.5777778029441833, loss=1.2936604022979736
train: epoch 149, loss 0.44429314136505127, acc=0.7962222099304199, loss=0.44429314136505127
test: epoch 149, loss 1.3526467084884644, acc=0.5833333134651184, loss=1.3526467084884644
train: epoch 150, loss 0.4455997347831726, acc=0.7944999933242798, loss=0.4455997347831726
test: epoch 150, loss 1.3431068658828735, acc=0.5666666626930237, loss=1.3431068658828735
