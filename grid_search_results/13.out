# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=1", "--temp_decay=0.99", "--one_hot=0", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=2003439459, receiver_embed_dim=32, save_run=0, temp_decay=0.99, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=2003439459, receiver_embed_dim=32, save_run=False, temp_decay=0.99, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.009923219680786, acc=0.08622222393751144, loss=3.009923219680786
test: epoch 1, loss 3.865267753601074, acc=0.05277777835726738, loss=3.865267753601074
train: epoch 2, loss 2.5569469928741455, acc=0.1428888887166977, loss=2.5569469928741455
test: epoch 2, loss 3.1851394176483154, acc=0.09444444626569748, loss=3.1851394176483154
train: epoch 3, loss 2.357294797897339, acc=0.17255555093288422, loss=2.357294797897339
test: epoch 3, loss 2.910954475402832, acc=0.11388888955116272, loss=2.910954475402832
train: epoch 4, loss 2.1967194080352783, acc=0.20305556058883667, loss=2.1967194080352783
test: epoch 4, loss 2.865525960922241, acc=0.11388888955116272, loss=2.865525960922241
train: epoch 5, loss 2.0865862369537354, acc=0.22788888216018677, loss=2.0865862369537354
test: epoch 5, loss 2.8538882732391357, acc=0.125, loss=2.8538882732391357
train: epoch 6, loss 2.0098536014556885, acc=0.24605555832386017, loss=2.0098536014556885
test: epoch 6, loss 2.6707122325897217, acc=0.15000000596046448, loss=2.6707122325897217
train: epoch 7, loss 1.949095368385315, acc=0.26216667890548706, loss=1.949095368385315
test: epoch 7, loss 2.5762081146240234, acc=0.14166666567325592, loss=2.5762081146240234
train: epoch 8, loss 1.883516788482666, acc=0.27761110663414, loss=1.883516788482666
test: epoch 8, loss 2.5259814262390137, acc=0.12777778506278992, loss=2.5259814262390137
train: epoch 9, loss 1.833746314048767, acc=0.2922777831554413, loss=1.833746314048767
test: epoch 9, loss 2.4691319465637207, acc=0.14166666567325592, loss=2.4691319465637207
train: epoch 10, loss 1.8011113405227661, acc=0.3072222173213959, loss=1.8011113405227661
test: epoch 10, loss 2.4809186458587646, acc=0.14722222089767456, loss=2.4809186458587646
train: epoch 11, loss 1.7697765827178955, acc=0.3043888807296753, loss=1.7697765827178955
test: epoch 11, loss 2.3555946350097656, acc=0.17499999701976776, loss=2.3555946350097656
train: epoch 12, loss 1.7432241439819336, acc=0.3171111047267914, loss=1.7432241439819336
test: epoch 12, loss 2.510618209838867, acc=0.14722222089767456, loss=2.510618209838867
train: epoch 13, loss 1.7262346744537354, acc=0.32716667652130127, loss=1.7262346744537354
test: epoch 13, loss 2.217500686645508, acc=0.17499999701976776, loss=2.217500686645508
train: epoch 14, loss 1.7225934267044067, acc=0.3311111032962799, loss=1.7225934267044067
test: epoch 14, loss 2.1489779949188232, acc=0.15555556118488312, loss=2.1489779949188232
train: epoch 15, loss 1.6877355575561523, acc=0.33933332562446594, loss=1.6877355575561523
test: epoch 15, loss 2.272402048110962, acc=0.1527777761220932, loss=2.272402048110962
train: epoch 16, loss 1.6833475828170776, acc=0.34033334255218506, loss=1.6833475828170776
test: epoch 16, loss 2.3228647708892822, acc=0.15833333134651184, loss=2.3228647708892822
train: epoch 17, loss 1.655442237854004, acc=0.3467777669429779, loss=1.655442237854004
test: epoch 17, loss 2.093271255493164, acc=0.1805555522441864, loss=2.093271255493164
train: epoch 18, loss 1.6468274593353271, acc=0.3471111059188843, loss=1.6468274593353271
test: epoch 18, loss 2.1551690101623535, acc=0.19722221791744232, loss=2.1551690101623535
train: epoch 19, loss 1.640861988067627, acc=0.35377776622772217, loss=1.640861988067627
test: epoch 19, loss 2.0236997604370117, acc=0.22499999403953552, loss=2.0236997604370117
train: epoch 20, loss 1.6192138195037842, acc=0.35600000619888306, loss=1.6192138195037842
test: epoch 20, loss 2.1050493717193604, acc=0.21944443881511688, loss=2.1050493717193604
train: epoch 21, loss 1.6331870555877686, acc=0.3578333258628845, loss=1.6331870555877686
test: epoch 21, loss 2.0432868003845215, acc=0.2083333283662796, loss=2.0432868003845215
train: epoch 22, loss 1.606745958328247, acc=0.36294445395469666, loss=1.606745958328247
test: epoch 22, loss 2.0406951904296875, acc=0.2083333283662796, loss=2.0406951904296875
train: epoch 23, loss 1.5799646377563477, acc=0.37138888239860535, loss=1.5799646377563477
test: epoch 23, loss 2.0446012020111084, acc=0.2222222238779068, loss=2.0446012020111084
train: epoch 24, loss 1.5842080116271973, acc=0.36577779054641724, loss=1.5842080116271973
test: epoch 24, loss 1.9809819459915161, acc=0.25, loss=1.9809819459915161
train: epoch 25, loss 1.5390340089797974, acc=0.3804999887943268, loss=1.5390340089797974
test: epoch 25, loss 2.028083562850952, acc=0.22777777910232544, loss=2.028083562850952
train: epoch 26, loss 1.5595510005950928, acc=0.37805554270744324, loss=1.5595510005950928
test: epoch 26, loss 2.0586884021759033, acc=0.22499999403953552, loss=2.0586884021759033
train: epoch 27, loss 1.5414180755615234, acc=0.3816111087799072, loss=1.5414180755615234
test: epoch 27, loss 1.9460302591323853, acc=0.2527777850627899, loss=1.9460302591323853
train: epoch 28, loss 1.528359055519104, acc=0.39516666531562805, loss=1.528359055519104
test: epoch 28, loss 1.9238301515579224, acc=0.2527777850627899, loss=1.9238301515579224
train: epoch 29, loss 1.5124030113220215, acc=0.39205554127693176, loss=1.5124030113220215
test: epoch 29, loss 1.8170132637023926, acc=0.25833332538604736, loss=1.8170132637023926
train: epoch 30, loss 1.49158775806427, acc=0.40105554461479187, loss=1.49158775806427
test: epoch 30, loss 1.8647009134292603, acc=0.25555557012557983, loss=1.8647009134292603
train: epoch 31, loss 1.4848122596740723, acc=0.3959999978542328, loss=1.4848122596740723
test: epoch 31, loss 1.9178982973098755, acc=0.2361111044883728, loss=1.9178982973098755
train: epoch 32, loss 1.4722501039505005, acc=0.4041111171245575, loss=1.4722501039505005
test: epoch 32, loss 1.8596768379211426, acc=0.3027777671813965, loss=1.8596768379211426
train: epoch 33, loss 1.4491055011749268, acc=0.41366666555404663, loss=1.4491055011749268
test: epoch 33, loss 1.8544756174087524, acc=0.26944443583488464, loss=1.8544756174087524
train: epoch 34, loss 1.4552258253097534, acc=0.4128333330154419, loss=1.4552258253097534
test: epoch 34, loss 1.8603177070617676, acc=0.2666666805744171, loss=1.8603177070617676
train: epoch 35, loss 1.4410767555236816, acc=0.4243333339691162, loss=1.4410767555236816
test: epoch 35, loss 1.8665900230407715, acc=0.2777777910232544, loss=1.8665900230407715
train: epoch 36, loss 1.4129199981689453, acc=0.42883333563804626, loss=1.4129199981689453
test: epoch 36, loss 1.738677740097046, acc=0.28333333134651184, loss=1.738677740097046
train: epoch 37, loss 1.4042013883590698, acc=0.4338333308696747, loss=1.4042013883590698
test: epoch 37, loss 1.8488490581512451, acc=0.23333333432674408, loss=1.8488490581512451
train: epoch 38, loss 1.3783738613128662, acc=0.4348333477973938, loss=1.3783738613128662
test: epoch 38, loss 1.7116014957427979, acc=0.3027777671813965, loss=1.7116014957427979
train: epoch 39, loss 1.4041813611984253, acc=0.4370555579662323, loss=1.4041813611984253
test: epoch 39, loss 1.8675273656845093, acc=0.24166665971279144, loss=1.8675273656845093
train: epoch 40, loss 1.365187406539917, acc=0.44733333587646484, loss=1.365187406539917
test: epoch 40, loss 1.7777135372161865, acc=0.2916666567325592, loss=1.7777135372161865
train: epoch 41, loss 1.349755048751831, acc=0.4512222111225128, loss=1.349755048751831
test: epoch 41, loss 1.7839688062667847, acc=0.25833332538604736, loss=1.7839688062667847
train: epoch 42, loss 1.3507148027420044, acc=0.4553889036178589, loss=1.3507148027420044
test: epoch 42, loss 1.7154605388641357, acc=0.3083333373069763, loss=1.7154605388641357
train: epoch 43, loss 1.3286396265029907, acc=0.45649999380111694, loss=1.3286396265029907
test: epoch 43, loss 1.7179290056228638, acc=0.2777777910232544, loss=1.7179290056228638
train: epoch 44, loss 1.3183479309082031, acc=0.45899999141693115, loss=1.3183479309082031
test: epoch 44, loss 1.7990138530731201, acc=0.2666666805744171, loss=1.7990138530731201
train: epoch 45, loss 1.306175947189331, acc=0.46683332324028015, loss=1.306175947189331
test: epoch 45, loss 1.7865068912506104, acc=0.31388887763023376, loss=1.7865068912506104
train: epoch 46, loss 1.3207646608352661, acc=0.4655555486679077, loss=1.3207646608352661
test: epoch 46, loss 1.8250482082366943, acc=0.30000001192092896, loss=1.8250482082366943
train: epoch 47, loss 1.3122812509536743, acc=0.4681110978126526, loss=1.3122812509536743
test: epoch 47, loss 1.7070814371109009, acc=0.28611111640930176, loss=1.7070814371109009
train: epoch 48, loss 1.3085697889328003, acc=0.4658333361148834, loss=1.3085697889328003
test: epoch 48, loss 1.7806950807571411, acc=0.30000001192092896, loss=1.7806950807571411
train: epoch 49, loss 1.2878990173339844, acc=0.48188889026641846, loss=1.2878990173339844
test: epoch 49, loss 1.8338220119476318, acc=0.26944443583488464, loss=1.8338220119476318
train: epoch 50, loss 1.2891868352890015, acc=0.48133334517478943, loss=1.2891868352890015
test: epoch 50, loss 1.8191407918930054, acc=0.27222222089767456, loss=1.8191407918930054
train: epoch 51, loss 1.261561632156372, acc=0.4818333387374878, loss=1.261561632156372
test: epoch 51, loss 1.7462246417999268, acc=0.3083333373069763, loss=1.7462246417999268
train: epoch 52, loss 1.2636854648590088, acc=0.48649999499320984, loss=1.2636854648590088
test: epoch 52, loss 1.804032564163208, acc=0.3166666626930237, loss=1.804032564163208
train: epoch 53, loss 1.2620123624801636, acc=0.4899444580078125, loss=1.2620123624801636
test: epoch 53, loss 1.9425946474075317, acc=0.25555557012557983, loss=1.9425946474075317
train: epoch 54, loss 1.234604835510254, acc=0.49711111187934875, loss=1.234604835510254
test: epoch 54, loss 1.7731775045394897, acc=0.2805555462837219, loss=1.7731775045394897
train: epoch 55, loss 1.2372336387634277, acc=0.4985555410385132, loss=1.2372336387634277
test: epoch 55, loss 1.6603468656539917, acc=0.28611111640930176, loss=1.6603468656539917
train: epoch 56, loss 1.224041223526001, acc=0.5021111369132996, loss=1.224041223526001
test: epoch 56, loss 1.6931556463241577, acc=0.3083333373069763, loss=1.6931556463241577
train: epoch 57, loss 1.2102962732315063, acc=0.5024444460868835, loss=1.2102962732315063
test: epoch 57, loss 1.7937809228897095, acc=0.25555557012557983, loss=1.7937809228897095
train: epoch 58, loss 1.2005990743637085, acc=0.5134444236755371, loss=1.2005990743637085
test: epoch 58, loss 1.8009538650512695, acc=0.3083333373069763, loss=1.8009538650512695
train: epoch 59, loss 1.201499581336975, acc=0.5063333511352539, loss=1.201499581336975
test: epoch 59, loss 1.6766337156295776, acc=0.2888889014720917, loss=1.6766337156295776
train: epoch 60, loss 1.2170753479003906, acc=0.5048333406448364, loss=1.2170753479003906
test: epoch 60, loss 1.7396413087844849, acc=0.2888889014720917, loss=1.7396413087844849
train: epoch 61, loss 1.1934022903442383, acc=0.5141666531562805, loss=1.1934022903442383
test: epoch 61, loss 1.6289126873016357, acc=0.32777777314186096, loss=1.6289126873016357
train: epoch 62, loss 1.187059998512268, acc=0.5140555500984192, loss=1.187059998512268
test: epoch 62, loss 1.577653408050537, acc=0.3333333432674408, loss=1.577653408050537
train: epoch 63, loss 1.1827399730682373, acc=0.5214999914169312, loss=1.1827399730682373
test: epoch 63, loss 1.5958468914031982, acc=0.2805555462837219, loss=1.5958468914031982
train: epoch 64, loss 1.1685216426849365, acc=0.518833339214325, loss=1.1685216426849365
test: epoch 64, loss 1.6913715600967407, acc=0.31111112236976624, loss=1.6913715600967407
train: epoch 65, loss 1.1741230487823486, acc=0.5203889012336731, loss=1.1741230487823486
test: epoch 65, loss 1.6492706537246704, acc=0.32499998807907104, loss=1.6492706537246704
train: epoch 66, loss 1.15322744846344, acc=0.5274444222450256, loss=1.15322744846344
test: epoch 66, loss 1.6412099599838257, acc=0.2944444417953491, loss=1.6412099599838257
train: epoch 67, loss 1.18631112575531, acc=0.5257777571678162, loss=1.18631112575531
test: epoch 67, loss 1.6189035177230835, acc=0.29722222685813904, loss=1.6189035177230835
train: epoch 68, loss 1.1692848205566406, acc=0.5282777547836304, loss=1.1692848205566406
test: epoch 68, loss 1.53745698928833, acc=0.4027777910232544, loss=1.53745698928833
train: epoch 69, loss 1.1414070129394531, acc=0.5360000133514404, loss=1.1414070129394531
test: epoch 69, loss 1.6532490253448486, acc=0.3444444537162781, loss=1.6532490253448486
train: epoch 70, loss 1.157914638519287, acc=0.5306666493415833, loss=1.157914638519287
test: epoch 70, loss 1.7266135215759277, acc=0.2777777910232544, loss=1.7266135215759277
train: epoch 71, loss 1.1499340534210205, acc=0.5388333201408386, loss=1.1499340534210205
test: epoch 71, loss 1.5944041013717651, acc=0.3472222089767456, loss=1.5944041013717651
train: epoch 72, loss 1.13205885887146, acc=0.5397777557373047, loss=1.13205885887146
test: epoch 72, loss 1.6569538116455078, acc=0.28611111640930176, loss=1.6569538116455078
train: epoch 73, loss 1.1461764574050903, acc=0.5419444441795349, loss=1.1461764574050903
test: epoch 73, loss 1.6404683589935303, acc=0.31388887763023376, loss=1.6404683589935303
train: epoch 74, loss 1.1204779148101807, acc=0.5457777976989746, loss=1.1204779148101807
test: epoch 74, loss 1.57240891456604, acc=0.35277777910232544, loss=1.57240891456604
train: epoch 75, loss 1.1130280494689941, acc=0.5491111278533936, loss=1.1130280494689941
test: epoch 75, loss 1.5829342603683472, acc=0.2944444417953491, loss=1.5829342603683472
train: epoch 76, loss 1.116984486579895, acc=0.5467222332954407, loss=1.116984486579895
test: epoch 76, loss 1.5322341918945312, acc=0.3861111104488373, loss=1.5322341918945312
train: epoch 77, loss 1.1004942655563354, acc=0.5556111335754395, loss=1.1004942655563354
test: epoch 77, loss 1.675216555595398, acc=0.3222222328186035, loss=1.675216555595398
train: epoch 78, loss 1.1008553504943848, acc=0.5524444580078125, loss=1.1008553504943848
test: epoch 78, loss 1.5282655954360962, acc=0.38055557012557983, loss=1.5282655954360962
train: epoch 79, loss 1.0903774499893188, acc=0.5562777519226074, loss=1.0903774499893188
test: epoch 79, loss 1.6002663373947144, acc=0.3777777850627899, loss=1.6002663373947144
train: epoch 80, loss 1.0964305400848389, acc=0.5602777600288391, loss=1.0964305400848389
test: epoch 80, loss 1.6822832822799683, acc=0.26944443583488464, loss=1.6822832822799683
train: epoch 81, loss 1.0833579301834106, acc=0.5562222003936768, loss=1.0833579301834106
test: epoch 81, loss 1.5894707441329956, acc=0.3166666626930237, loss=1.5894707441329956
train: epoch 82, loss 1.0768591165542603, acc=0.5634444355964661, loss=1.0768591165542603
test: epoch 82, loss 1.6330008506774902, acc=0.32499998807907104, loss=1.6330008506774902
train: epoch 83, loss 1.0820304155349731, acc=0.5617777705192566, loss=1.0820304155349731
test: epoch 83, loss 1.8526052236557007, acc=0.3083333373069763, loss=1.8526052236557007
train: epoch 84, loss 1.0609034299850464, acc=0.566444456577301, loss=1.0609034299850464
test: epoch 84, loss 1.646689534187317, acc=0.36666667461395264, loss=1.646689534187317
train: epoch 85, loss 1.0525665283203125, acc=0.5712777972221375, loss=1.0525665283203125
test: epoch 85, loss 1.603234052658081, acc=0.40833333134651184, loss=1.603234052658081
train: epoch 86, loss 1.0445111989974976, acc=0.5726110935211182, loss=1.0445111989974976
test: epoch 86, loss 1.5868512392044067, acc=0.3444444537162781, loss=1.5868512392044067
train: epoch 87, loss 1.079305648803711, acc=0.56977778673172, loss=1.079305648803711
test: epoch 87, loss 1.6182241439819336, acc=0.2916666567325592, loss=1.6182241439819336
train: epoch 88, loss 1.0508896112442017, acc=0.5780555605888367, loss=1.0508896112442017
test: epoch 88, loss 1.575251579284668, acc=0.3083333373069763, loss=1.575251579284668
train: epoch 89, loss 1.0414206981658936, acc=0.5809999704360962, loss=1.0414206981658936
test: epoch 89, loss 1.5600250959396362, acc=0.3611111044883728, loss=1.5600250959396362
train: epoch 90, loss 1.041671872138977, acc=0.5827777981758118, loss=1.041671872138977
test: epoch 90, loss 1.6247705221176147, acc=0.35277777910232544, loss=1.6247705221176147
train: epoch 91, loss 1.0311803817749023, acc=0.5838888883590698, loss=1.0311803817749023
test: epoch 91, loss 1.6439402103424072, acc=0.3083333373069763, loss=1.6439402103424072
train: epoch 92, loss 1.0335156917572021, acc=0.5828333497047424, loss=1.0335156917572021
test: epoch 92, loss 1.6120778322219849, acc=0.3166666626930237, loss=1.6120778322219849
train: epoch 93, loss 1.0076183080673218, acc=0.5913888812065125, loss=1.0076183080673218
test: epoch 93, loss 1.5338010787963867, acc=0.3638888895511627, loss=1.5338010787963867
train: epoch 94, loss 1.0430171489715576, acc=0.5893333554267883, loss=1.0430171489715576
test: epoch 94, loss 1.5853410959243774, acc=0.35277777910232544, loss=1.5853410959243774
train: epoch 95, loss 1.0119664669036865, acc=0.5874999761581421, loss=1.0119664669036865
test: epoch 95, loss 1.5982517004013062, acc=0.33888888359069824, loss=1.5982517004013062
train: epoch 96, loss 0.9965961575508118, acc=0.5942222476005554, loss=0.9965961575508118
test: epoch 96, loss 1.7340433597564697, acc=0.32777777314186096, loss=1.7340433597564697
train: epoch 97, loss 0.9919193387031555, acc=0.5985555648803711, loss=0.9919193387031555
test: epoch 97, loss 1.693156361579895, acc=0.3333333432674408, loss=1.693156361579895
train: epoch 98, loss 1.0008801221847534, acc=0.5967222452163696, loss=1.0008801221847534
test: epoch 98, loss 1.6054714918136597, acc=0.375, loss=1.6054714918136597
train: epoch 99, loss 0.9909323453903198, acc=0.6047777533531189, loss=0.9909323453903198
test: epoch 99, loss 1.6968574523925781, acc=0.32499998807907104, loss=1.6968574523925781
train: epoch 100, loss 0.9984287023544312, acc=0.6010555624961853, loss=0.9984287023544312
test: epoch 100, loss 1.5381124019622803, acc=0.3361110985279083, loss=1.5381124019622803
train: epoch 101, loss 0.9907443523406982, acc=0.6054444313049316, loss=0.9907443523406982
test: epoch 101, loss 1.628814697265625, acc=0.3055555522441864, loss=1.628814697265625
train: epoch 102, loss 0.986437976360321, acc=0.6028333306312561, loss=0.986437976360321
test: epoch 102, loss 1.7165240049362183, acc=0.28611111640930176, loss=1.7165240049362183
train: epoch 103, loss 0.9728994369506836, acc=0.6087777614593506, loss=0.9728994369506836
test: epoch 103, loss 1.6214121580123901, acc=0.31388887763023376, loss=1.6214121580123901
train: epoch 104, loss 0.9817734956741333, acc=0.6092777848243713, loss=0.9817734956741333
test: epoch 104, loss 1.616310477256775, acc=0.3166666626930237, loss=1.616310477256775
train: epoch 105, loss 0.9484601020812988, acc=0.6211666464805603, loss=0.9484601020812988
test: epoch 105, loss 1.5358384847640991, acc=0.3611111044883728, loss=1.5358384847640991
train: epoch 106, loss 0.9836784601211548, acc=0.6093888878822327, loss=0.9836784601211548
test: epoch 106, loss 1.4983470439910889, acc=0.4027777910232544, loss=1.4983470439910889
train: epoch 107, loss 0.9584563374519348, acc=0.6193333268165588, loss=0.9584563374519348
test: epoch 107, loss 1.529355525970459, acc=0.34166666865348816, loss=1.529355525970459
train: epoch 108, loss 0.9594438672065735, acc=0.6204444169998169, loss=0.9594438672065735
test: epoch 108, loss 1.6401939392089844, acc=0.36944442987442017, loss=1.6401939392089844
train: epoch 109, loss 0.9396253824234009, acc=0.6266111135482788, loss=0.9396253824234009
test: epoch 109, loss 1.5179439783096313, acc=0.3472222089767456, loss=1.5179439783096313
train: epoch 110, loss 0.9463366866111755, acc=0.6181666851043701, loss=0.9463366866111755
test: epoch 110, loss 1.5015604496002197, acc=0.3611111044883728, loss=1.5015604496002197
train: epoch 111, loss 0.946891188621521, acc=0.628000020980835, loss=0.946891188621521
test: epoch 111, loss 1.6931637525558472, acc=0.3055555522441864, loss=1.6931637525558472
train: epoch 112, loss 0.9499739408493042, acc=0.6238889098167419, loss=0.9499739408493042
test: epoch 112, loss 1.528281331062317, acc=0.3777777850627899, loss=1.528281331062317
train: epoch 113, loss 0.9388047456741333, acc=0.6262778043746948, loss=0.9388047456741333
test: epoch 113, loss 1.4804857969284058, acc=0.43888887763023376, loss=1.4804857969284058
train: epoch 114, loss 0.9283716082572937, acc=0.6282777786254883, loss=0.9283716082572937
test: epoch 114, loss 1.480723261833191, acc=0.4138889014720917, loss=1.480723261833191
train: epoch 115, loss 0.9543223977088928, acc=0.6190555691719055, loss=0.9543223977088928
test: epoch 115, loss 1.5042543411254883, acc=0.33888888359069824, loss=1.5042543411254883
train: epoch 116, loss 0.9275391697883606, acc=0.6286110877990723, loss=0.9275391697883606
test: epoch 116, loss 1.5424387454986572, acc=0.38333332538604736, loss=1.5424387454986572
train: epoch 117, loss 0.9172087907791138, acc=0.6340000033378601, loss=0.9172087907791138
test: epoch 117, loss 1.5306191444396973, acc=0.34166666865348816, loss=1.5306191444396973
train: epoch 118, loss 0.9197626113891602, acc=0.6313333511352539, loss=0.9197626113891602
test: epoch 118, loss 1.5326666831970215, acc=0.375, loss=1.5326666831970215
train: epoch 119, loss 0.9161425828933716, acc=0.6332777738571167, loss=0.9161425828933716
test: epoch 119, loss 1.4909602403640747, acc=0.32499998807907104, loss=1.4909602403640747
train: epoch 120, loss 0.9195717573165894, acc=0.6333333253860474, loss=0.9195717573165894
test: epoch 120, loss 1.412936806678772, acc=0.43888887763023376, loss=1.412936806678772
train: epoch 121, loss 0.9228743314743042, acc=0.6340000033378601, loss=0.9228743314743042
test: epoch 121, loss 1.6096391677856445, acc=0.36944442987442017, loss=1.6096391677856445
train: epoch 122, loss 0.9445600509643555, acc=0.632777750492096, loss=0.9445600509643555
test: epoch 122, loss 1.487192153930664, acc=0.4055555462837219, loss=1.487192153930664
train: epoch 123, loss 0.9087529182434082, acc=0.6344444155693054, loss=0.9087529182434082
test: epoch 123, loss 1.4889272451400757, acc=0.3888888955116272, loss=1.4889272451400757
train: epoch 124, loss 0.9019505977630615, acc=0.6446666717529297, loss=0.9019505977630615
test: epoch 124, loss 1.536063313484192, acc=0.3638888895511627, loss=1.536063313484192
train: epoch 125, loss 0.9045664668083191, acc=0.6398888826370239, loss=0.9045664668083191
test: epoch 125, loss 1.6974854469299316, acc=0.31388887763023376, loss=1.6974854469299316
train: epoch 126, loss 0.908057451248169, acc=0.640500009059906, loss=0.908057451248169
test: epoch 126, loss 1.6059728860855103, acc=0.3722222149372101, loss=1.6059728860855103
train: epoch 127, loss 0.8948262929916382, acc=0.6441666483879089, loss=0.8948262929916382
test: epoch 127, loss 1.4696540832519531, acc=0.3888888955116272, loss=1.4696540832519531
train: epoch 128, loss 0.8862326145172119, acc=0.6460000276565552, loss=0.8862326145172119
test: epoch 128, loss 1.6725387573242188, acc=0.3361110985279083, loss=1.6725387573242188
train: epoch 129, loss 0.9006255865097046, acc=0.6473888754844666, loss=0.9006255865097046
test: epoch 129, loss 1.45917546749115, acc=0.4305555522441864, loss=1.45917546749115
train: epoch 130, loss 0.8808251619338989, acc=0.6536111235618591, loss=0.8808251619338989
test: epoch 130, loss 1.5390689373016357, acc=0.4055555462837219, loss=1.5390689373016357
train: epoch 131, loss 0.8983708620071411, acc=0.6435555815696716, loss=0.8983708620071411
test: epoch 131, loss 1.6166267395019531, acc=0.3638888895511627, loss=1.6166267395019531
train: epoch 132, loss 0.8906635046005249, acc=0.6506111025810242, loss=0.8906635046005249
test: epoch 132, loss 1.5490742921829224, acc=0.3888888955116272, loss=1.5490742921829224
train: epoch 133, loss 0.8701840043067932, acc=0.6573333144187927, loss=0.8701840043067932
test: epoch 133, loss 1.6396973133087158, acc=0.375, loss=1.6396973133087158
train: epoch 134, loss 0.866234302520752, acc=0.6578888893127441, loss=0.866234302520752
test: epoch 134, loss 1.4845725297927856, acc=0.38055557012557983, loss=1.4845725297927856
train: epoch 135, loss 0.8677768111228943, acc=0.6573888659477234, loss=0.8677768111228943
test: epoch 135, loss 1.5980716943740845, acc=0.3611111044883728, loss=1.5980716943740845
train: epoch 136, loss 0.8794944882392883, acc=0.6564444303512573, loss=0.8794944882392883
test: epoch 136, loss 1.405373454093933, acc=0.4138889014720917, loss=1.405373454093933
train: epoch 137, loss 0.8789529204368591, acc=0.6557222008705139, loss=0.8789529204368591
test: epoch 137, loss 1.5750895738601685, acc=0.38333332538604736, loss=1.5750895738601685
train: epoch 138, loss 0.8523175120353699, acc=0.6610000133514404, loss=0.8523175120353699
test: epoch 138, loss 1.5460031032562256, acc=0.3916666805744171, loss=1.5460031032562256
train: epoch 139, loss 0.8494120240211487, acc=0.6660000085830688, loss=0.8494120240211487
test: epoch 139, loss 1.6094489097595215, acc=0.3638888895511627, loss=1.6094489097595215
train: epoch 140, loss 0.8483348488807678, acc=0.6646111011505127, loss=0.8483348488807678
test: epoch 140, loss 1.630960464477539, acc=0.39444443583488464, loss=1.630960464477539
train: epoch 141, loss 0.855441153049469, acc=0.6627777814865112, loss=0.855441153049469
test: epoch 141, loss 1.5172823667526245, acc=0.3861111104488373, loss=1.5172823667526245
train: epoch 142, loss 0.848162829875946, acc=0.6694999933242798, loss=0.848162829875946
test: epoch 142, loss 1.6435954570770264, acc=0.38055557012557983, loss=1.6435954570770264
train: epoch 143, loss 0.8587818145751953, acc=0.6673333048820496, loss=0.8587818145751953
test: epoch 143, loss 1.6973296403884888, acc=0.3166666626930237, loss=1.6973296403884888
train: epoch 144, loss 0.8522651195526123, acc=0.6627222299575806, loss=0.8522651195526123
test: epoch 144, loss 1.5211151838302612, acc=0.3222222328186035, loss=1.5211151838302612
train: epoch 145, loss 0.858278214931488, acc=0.6666111350059509, loss=0.858278214931488
test: epoch 145, loss 1.5447771549224854, acc=0.4277777671813965, loss=1.5447771549224854
train: epoch 146, loss 0.8427466154098511, acc=0.6698889136314392, loss=0.8427466154098511
test: epoch 146, loss 1.4323246479034424, acc=0.4138889014720917, loss=1.4323246479034424
train: epoch 147, loss 0.8252871036529541, acc=0.6768888831138611, loss=0.8252871036529541
test: epoch 147, loss 1.3655685186386108, acc=0.48055556416511536, loss=1.3655685186386108
train: epoch 148, loss 0.8480913043022156, acc=0.6698333621025085, loss=0.8480913043022156
test: epoch 148, loss 1.536279320716858, acc=0.4138889014720917, loss=1.536279320716858
train: epoch 149, loss 0.827216386795044, acc=0.675611138343811, loss=0.827216386795044
test: epoch 149, loss 1.4976736307144165, acc=0.4000000059604645, loss=1.4976736307144165
train: epoch 150, loss 0.8596577048301697, acc=0.6626666784286499, loss=0.8596577048301697
test: epoch 150, loss 1.328683853149414, acc=0.44999998807907104, loss=1.328683853149414
