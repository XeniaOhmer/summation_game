# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=1", "--temp_decay=1", "--one_hot=1", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=1213172217, receiver_embed_dim=32, save_run=0, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1213172217, receiver_embed_dim=32, save_run=False, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.2841310501098633, acc=0.05955555662512779, loss=3.2841310501098633
test: epoch 1, loss 3.193354606628418, acc=0.09444444626569748, loss=3.193354606628418
train: epoch 2, loss 2.4285364151000977, acc=0.15905556082725525, loss=2.4285364151000977
test: epoch 2, loss 3.044891357421875, acc=0.10277777910232544, loss=3.044891357421875
train: epoch 3, loss 2.1117489337921143, acc=0.2217777818441391, loss=2.1117489337921143
test: epoch 3, loss 2.8981359004974365, acc=0.1388888955116272, loss=2.8981359004974365
train: epoch 4, loss 1.861538290977478, acc=0.300388902425766, loss=1.861538290977478
test: epoch 4, loss 2.757866144180298, acc=0.16111111640930176, loss=2.757866144180298
train: epoch 5, loss 1.605245590209961, acc=0.37066665291786194, loss=1.605245590209961
test: epoch 5, loss 2.337282419204712, acc=0.21388888359069824, loss=2.337282419204712
train: epoch 6, loss 1.4428967237472534, acc=0.4217222332954407, loss=1.4428967237472534
test: epoch 6, loss 2.357771158218384, acc=0.19166666269302368, loss=2.357771158218384
train: epoch 7, loss 1.3567105531692505, acc=0.4493333399295807, loss=1.3567105531692505
test: epoch 7, loss 2.009429693222046, acc=0.2638888955116272, loss=2.009429693222046
train: epoch 8, loss 1.2929103374481201, acc=0.47183331847190857, loss=1.2929103374481201
test: epoch 8, loss 2.0680346488952637, acc=0.22499999403953552, loss=2.0680346488952637
train: epoch 9, loss 1.240902066230774, acc=0.4902222156524658, loss=1.240902066230774
test: epoch 9, loss 1.8862965106964111, acc=0.24444444477558136, loss=1.8862965106964111
train: epoch 10, loss 1.190091848373413, acc=0.5050555467605591, loss=1.190091848373413
test: epoch 10, loss 1.8676230907440186, acc=0.2611111104488373, loss=1.8676230907440186
train: epoch 11, loss 1.123735785484314, acc=0.5274999737739563, loss=1.123735785484314
test: epoch 11, loss 1.7477624416351318, acc=0.27222222089767456, loss=1.7477624416351318
train: epoch 12, loss 1.083185076713562, acc=0.5426666736602783, loss=1.083185076713562
test: epoch 12, loss 1.7904950380325317, acc=0.28333333134651184, loss=1.7904950380325317
train: epoch 13, loss 1.059967041015625, acc=0.5526666641235352, loss=1.059967041015625
test: epoch 13, loss 1.7844984531402588, acc=0.30000001192092896, loss=1.7844984531402588
train: epoch 14, loss 1.016662836074829, acc=0.574055552482605, loss=1.016662836074829
test: epoch 14, loss 1.7393873929977417, acc=0.31388887763023376, loss=1.7393873929977417
train: epoch 15, loss 0.9888694286346436, acc=0.5796666741371155, loss=0.9888694286346436
test: epoch 15, loss 1.707889199256897, acc=0.33888888359069824, loss=1.707889199256897
train: epoch 16, loss 0.976378858089447, acc=0.5894444584846497, loss=0.976378858089447
test: epoch 16, loss 1.7122877836227417, acc=0.3194444477558136, loss=1.7122877836227417
train: epoch 17, loss 0.9431684613227844, acc=0.5987777709960938, loss=0.9431684613227844
test: epoch 17, loss 1.6615777015686035, acc=0.35555556416511536, loss=1.6615777015686035
train: epoch 18, loss 0.9299043416976929, acc=0.6041666865348816, loss=0.9299043416976929
test: epoch 18, loss 1.8491146564483643, acc=0.32499998807907104, loss=1.8491146564483643
train: epoch 19, loss 0.9057154655456543, acc=0.6206111311912537, loss=0.9057154655456543
test: epoch 19, loss 1.6440027952194214, acc=0.3444444537162781, loss=1.6440027952194214
train: epoch 20, loss 0.8835430145263672, acc=0.6230555772781372, loss=0.8835430145263672
test: epoch 20, loss 1.7436381578445435, acc=0.375, loss=1.7436381578445435
train: epoch 21, loss 0.8669413924217224, acc=0.6301666498184204, loss=0.8669413924217224
test: epoch 21, loss 1.8179512023925781, acc=0.3333333432674408, loss=1.8179512023925781
train: epoch 22, loss 0.8482974171638489, acc=0.6419444680213928, loss=0.8482974171638489
test: epoch 22, loss 1.6388100385665894, acc=0.3638888895511627, loss=1.6388100385665894
train: epoch 23, loss 0.8139735460281372, acc=0.6624444723129272, loss=0.8139735460281372
test: epoch 23, loss 1.7263773679733276, acc=0.35555556416511536, loss=1.7263773679733276
train: epoch 24, loss 0.7962599396705627, acc=0.6616111397743225, loss=0.7962599396705627
test: epoch 24, loss 1.694512963294983, acc=0.41111111640930176, loss=1.694512963294983
train: epoch 25, loss 0.763555645942688, acc=0.6739444732666016, loss=0.763555645942688
test: epoch 25, loss 1.6754449605941772, acc=0.3638888895511627, loss=1.6754449605941772
train: epoch 26, loss 0.7408643364906311, acc=0.6875555515289307, loss=0.7408643364906311
test: epoch 26, loss 1.6857361793518066, acc=0.3583333194255829, loss=1.6857361793518066
train: epoch 27, loss 0.7035746574401855, acc=0.7000555396080017, loss=0.7035746574401855
test: epoch 27, loss 1.9232839345932007, acc=0.36666667461395264, loss=1.9232839345932007
train: epoch 28, loss 0.6768539547920227, acc=0.7105000019073486, loss=0.6768539547920227
test: epoch 28, loss 1.7086093425750732, acc=0.38055557012557983, loss=1.7086093425750732
train: epoch 29, loss 0.6680020689964294, acc=0.7178333401679993, loss=0.6680020689964294
test: epoch 29, loss 1.7311995029449463, acc=0.3722222149372101, loss=1.7311995029449463
train: epoch 30, loss 0.6490718126296997, acc=0.7229999899864197, loss=0.6490718126296997
test: epoch 30, loss 1.6583316326141357, acc=0.3861111104488373, loss=1.6583316326141357
train: epoch 31, loss 0.6484688520431519, acc=0.718666672706604, loss=0.6484688520431519
test: epoch 31, loss 1.7000157833099365, acc=0.4138889014720917, loss=1.7000157833099365
train: epoch 32, loss 0.6301261186599731, acc=0.7309444546699524, loss=0.6301261186599731
test: epoch 32, loss 1.5104000568389893, acc=0.3888888955116272, loss=1.5104000568389893
train: epoch 33, loss 0.6297380328178406, acc=0.7327777743339539, loss=0.6297380328178406
test: epoch 33, loss 1.8085523843765259, acc=0.3305555582046509, loss=1.8085523843765259
train: epoch 34, loss 0.6252613067626953, acc=0.7328333258628845, loss=0.6252613067626953
test: epoch 34, loss 1.8487732410430908, acc=0.38333332538604736, loss=1.8487732410430908
train: epoch 35, loss 0.6276718378067017, acc=0.7311111092567444, loss=0.6276718378067017
test: epoch 35, loss 1.8248097896575928, acc=0.4138889014720917, loss=1.8248097896575928
train: epoch 36, loss 0.6122747659683228, acc=0.7407777905464172, loss=0.6122747659683228
test: epoch 36, loss 1.7415196895599365, acc=0.4138889014720917, loss=1.7415196895599365
train: epoch 37, loss 0.6067956686019897, acc=0.742111086845398, loss=0.6067956686019897
test: epoch 37, loss 1.7436591386795044, acc=0.4000000059604645, loss=1.7436591386795044
train: epoch 38, loss 0.6016952991485596, acc=0.7482222318649292, loss=0.6016952991485596
test: epoch 38, loss 1.5869395732879639, acc=0.3777777850627899, loss=1.5869395732879639
train: epoch 39, loss 0.5870153903961182, acc=0.7565000057220459, loss=0.5870153903961182
test: epoch 39, loss 1.5468720197677612, acc=0.4333333373069763, loss=1.5468720197677612
train: epoch 40, loss 0.5800344347953796, acc=0.7608888745307922, loss=0.5800344347953796
test: epoch 40, loss 1.7506616115570068, acc=0.41111111640930176, loss=1.7506616115570068
train: epoch 41, loss 0.5824015140533447, acc=0.7619444727897644, loss=0.5824015140533447
test: epoch 41, loss 1.6887177228927612, acc=0.4416666626930237, loss=1.6887177228927612
train: epoch 42, loss 0.5625839829444885, acc=0.7670000195503235, loss=0.5625839829444885
test: epoch 42, loss 1.683816909790039, acc=0.42222222685813904, loss=1.683816909790039
train: epoch 43, loss 0.5518515706062317, acc=0.7689444422721863, loss=0.5518515706062317
test: epoch 43, loss 1.8450124263763428, acc=0.4277777671813965, loss=1.8450124263763428
train: epoch 44, loss 0.5355092883110046, acc=0.7784444689750671, loss=0.5355092883110046
test: epoch 44, loss 1.7074114084243774, acc=0.4166666567325592, loss=1.7074114084243774
train: epoch 45, loss 0.5461657643318176, acc=0.7728333473205566, loss=0.5461657643318176
test: epoch 45, loss 1.7314690351486206, acc=0.4305555522441864, loss=1.7314690351486206
train: epoch 46, loss 0.5368468165397644, acc=0.7784444689750671, loss=0.5368468165397644
test: epoch 46, loss 1.7416870594024658, acc=0.3916666805744171, loss=1.7416870594024658
train: epoch 47, loss 0.5335811376571655, acc=0.7819444537162781, loss=0.5335811376571655
test: epoch 47, loss 1.7952518463134766, acc=0.3888888955116272, loss=1.7952518463134766
train: epoch 48, loss 0.5350403785705566, acc=0.7798888683319092, loss=0.5350403785705566
test: epoch 48, loss 1.8154760599136353, acc=0.40833333134651184, loss=1.8154760599136353
train: epoch 49, loss 0.512616753578186, acc=0.7833333611488342, loss=0.512616753578186
test: epoch 49, loss 1.8866665363311768, acc=0.4138889014720917, loss=1.8866665363311768
train: epoch 50, loss 0.5233991146087646, acc=0.7808889150619507, loss=0.5233991146087646
test: epoch 50, loss 1.4892927408218384, acc=0.4888888895511627, loss=1.4892927408218384
train: epoch 51, loss 0.5110794901847839, acc=0.7864444255828857, loss=0.5110794901847839
test: epoch 51, loss 1.641205072402954, acc=0.4305555522441864, loss=1.641205072402954
train: epoch 52, loss 0.522438645362854, acc=0.782444417476654, loss=0.522438645362854
test: epoch 52, loss 1.8250582218170166, acc=0.4277777671813965, loss=1.8250582218170166
train: epoch 53, loss 0.4911985993385315, acc=0.7931666374206543, loss=0.4911985993385315
test: epoch 53, loss 1.8292495012283325, acc=0.4000000059604645, loss=1.8292495012283325
train: epoch 54, loss 0.5133742690086365, acc=0.7866666913032532, loss=0.5133742690086365
test: epoch 54, loss 1.6380916833877563, acc=0.4333333373069763, loss=1.6380916833877563
train: epoch 55, loss 0.48515409231185913, acc=0.7960555553436279, loss=0.48515409231185913
test: epoch 55, loss 1.7255401611328125, acc=0.4694444537162781, loss=1.7255401611328125
train: epoch 56, loss 0.5223753452301025, acc=0.7861111164093018, loss=0.5223753452301025
test: epoch 56, loss 1.4343667030334473, acc=0.4888888895511627, loss=1.4343667030334473
train: epoch 57, loss 0.48622027039527893, acc=0.7952222228050232, loss=0.48622027039527893
test: epoch 57, loss 1.7696435451507568, acc=0.48055556416511536, loss=1.7696435451507568
train: epoch 58, loss 0.49238768219947815, acc=0.7941111326217651, loss=0.49238768219947815
test: epoch 58, loss 1.362762212753296, acc=0.519444465637207, loss=1.362762212753296
train: epoch 59, loss 0.49238860607147217, acc=0.792888879776001, loss=0.49238860607147217
test: epoch 59, loss 1.6755177974700928, acc=0.49166667461395264, loss=1.6755177974700928
train: epoch 60, loss 0.47463729977607727, acc=0.8000555634498596, loss=0.47463729977607727
test: epoch 60, loss 1.432862401008606, acc=0.5249999761581421, loss=1.432862401008606
train: epoch 61, loss 0.47012975811958313, acc=0.8023889064788818, loss=0.47012975811958313
test: epoch 61, loss 1.625282645225525, acc=0.4833333194255829, loss=1.625282645225525
train: epoch 62, loss 0.48180389404296875, acc=0.7929444313049316, loss=0.48180389404296875
test: epoch 62, loss 1.9068241119384766, acc=0.5138888955116272, loss=1.9068241119384766
train: epoch 63, loss 0.47617045044898987, acc=0.8006666898727417, loss=0.47617045044898987
test: epoch 63, loss 1.5539984703063965, acc=0.5111111402511597, loss=1.5539984703063965
train: epoch 64, loss 0.47189024090766907, acc=0.8004444241523743, loss=0.47189024090766907
test: epoch 64, loss 1.6282445192337036, acc=0.5055555701255798, loss=1.6282445192337036
train: epoch 65, loss 0.474610298871994, acc=0.7991666793823242, loss=0.474610298871994
test: epoch 65, loss 1.4591413736343384, acc=0.5222222208976746, loss=1.4591413736343384
train: epoch 66, loss 0.4487137198448181, acc=0.8077777624130249, loss=0.4487137198448181
test: epoch 66, loss 1.4823648929595947, acc=0.5277777910232544, loss=1.4823648929595947
train: epoch 67, loss 0.46046575903892517, acc=0.8048333525657654, loss=0.46046575903892517
test: epoch 67, loss 1.5894179344177246, acc=0.49444442987442017, loss=1.5894179344177246
train: epoch 68, loss 0.44727304577827454, acc=0.8094444274902344, loss=0.44727304577827454
test: epoch 68, loss 1.852612018585205, acc=0.47777777910232544, loss=1.852612018585205
train: epoch 69, loss 0.45677927136421204, acc=0.8086110949516296, loss=0.45677927136421204
test: epoch 69, loss 1.621237874031067, acc=0.5027777552604675, loss=1.621237874031067
train: epoch 70, loss 0.4479653239250183, acc=0.8101666569709778, loss=0.4479653239250183
test: epoch 70, loss 1.7032883167266846, acc=0.4722222089767456, loss=1.7032883167266846
train: epoch 71, loss 0.4588751196861267, acc=0.8013333082199097, loss=0.4588751196861267
test: epoch 71, loss 1.3515613079071045, acc=0.5361111164093018, loss=1.3515613079071045
train: epoch 72, loss 0.42841917276382446, acc=0.8155555725097656, loss=0.42841917276382446
test: epoch 72, loss 1.5303276777267456, acc=0.5277777910232544, loss=1.5303276777267456
train: epoch 73, loss 0.43821781873703003, acc=0.8132222294807434, loss=0.43821781873703003
test: epoch 73, loss 1.4867286682128906, acc=0.5138888955116272, loss=1.4867286682128906
train: epoch 74, loss 0.4426765739917755, acc=0.8119444251060486, loss=0.4426765739917755
test: epoch 74, loss 1.5170687437057495, acc=0.5333333611488342, loss=1.5170687437057495
train: epoch 75, loss 0.4385492205619812, acc=0.8157777786254883, loss=0.4385492205619812
test: epoch 75, loss 1.6108890771865845, acc=0.550000011920929, loss=1.6108890771865845
train: epoch 76, loss 0.44306597113609314, acc=0.8100000023841858, loss=0.44306597113609314
test: epoch 76, loss 1.512527346611023, acc=0.5166666507720947, loss=1.512527346611023
train: epoch 77, loss 0.43941327929496765, acc=0.8116666674613953, loss=0.43941327929496765
test: epoch 77, loss 1.5780839920043945, acc=0.5222222208976746, loss=1.5780839920043945
train: epoch 78, loss 0.4402623474597931, acc=0.8141111135482788, loss=0.4402623474597931
test: epoch 78, loss 1.6229326725006104, acc=0.4722222089767456, loss=1.6229326725006104
train: epoch 79, loss 0.43241044878959656, acc=0.8146111369132996, loss=0.43241044878959656
test: epoch 79, loss 1.6290334463119507, acc=0.5305555462837219, loss=1.6290334463119507
train: epoch 80, loss 0.43175727128982544, acc=0.8163333535194397, loss=0.43175727128982544
test: epoch 80, loss 1.4431389570236206, acc=0.5027777552604675, loss=1.4431389570236206
train: epoch 81, loss 0.4377889037132263, acc=0.812166690826416, loss=0.4377889037132263
test: epoch 81, loss 1.498090147972107, acc=0.550000011920929, loss=1.498090147972107
train: epoch 82, loss 0.4337540864944458, acc=0.8132222294807434, loss=0.4337540864944458
test: epoch 82, loss 1.4454213380813599, acc=0.5083333253860474, loss=1.4454213380813599
train: epoch 83, loss 0.42488858103752136, acc=0.8166666626930237, loss=0.42488858103752136
test: epoch 83, loss 1.5582401752471924, acc=0.5111111402511597, loss=1.5582401752471924
train: epoch 84, loss 0.42758113145828247, acc=0.8140555620193481, loss=0.42758113145828247
test: epoch 84, loss 1.8093332052230835, acc=0.5388888716697693, loss=1.8093332052230835
train: epoch 85, loss 0.4176495373249054, acc=0.8187222480773926, loss=0.4176495373249054
test: epoch 85, loss 1.5749837160110474, acc=0.5444444417953491, loss=1.5749837160110474
train: epoch 86, loss 0.4287931025028229, acc=0.8173333406448364, loss=0.4287931025028229
test: epoch 86, loss 1.4545059204101562, acc=0.5111111402511597, loss=1.4545059204101562
train: epoch 87, loss 0.42379650473594666, acc=0.8197222352027893, loss=0.42379650473594666
test: epoch 87, loss 1.3816171884536743, acc=0.5527777671813965, loss=1.3816171884536743
train: epoch 88, loss 0.41741040349006653, acc=0.820111095905304, loss=0.41741040349006653
test: epoch 88, loss 1.5912638902664185, acc=0.5027777552604675, loss=1.5912638902664185
train: epoch 89, loss 0.4209025204181671, acc=0.8188889026641846, loss=0.4209025204181671
test: epoch 89, loss 1.5717687606811523, acc=0.5527777671813965, loss=1.5717687606811523
train: epoch 90, loss 0.42136093974113464, acc=0.8165555596351624, loss=0.42136093974113464
test: epoch 90, loss 1.4666799306869507, acc=0.5222222208976746, loss=1.4666799306869507
train: epoch 91, loss 0.4361100494861603, acc=0.8148888945579529, loss=0.4361100494861603
test: epoch 91, loss 1.9906426668167114, acc=0.519444465637207, loss=1.9906426668167114
train: epoch 92, loss 0.4100824296474457, acc=0.8242777585983276, loss=0.4100824296474457
test: epoch 92, loss 1.8530857563018799, acc=0.5, loss=1.8530857563018799
train: epoch 93, loss 0.4102645516395569, acc=0.8216111063957214, loss=0.4102645516395569
test: epoch 93, loss 1.5562870502471924, acc=0.5555555820465088, loss=1.5562870502471924
train: epoch 94, loss 0.4169412851333618, acc=0.8216111063957214, loss=0.4169412851333618
test: epoch 94, loss 1.4254508018493652, acc=0.550000011920929, loss=1.4254508018493652
train: epoch 95, loss 0.4059543311595917, acc=0.8243333101272583, loss=0.4059543311595917
test: epoch 95, loss 1.35577392578125, acc=0.5222222208976746, loss=1.35577392578125
train: epoch 96, loss 0.40405234694480896, acc=0.8242777585983276, loss=0.40405234694480896
test: epoch 96, loss 1.4311808347702026, acc=0.5527777671813965, loss=1.4311808347702026
train: epoch 97, loss 0.41859540343284607, acc=0.8200555443763733, loss=0.41859540343284607
test: epoch 97, loss 1.4703415632247925, acc=0.550000011920929, loss=1.4703415632247925
train: epoch 98, loss 0.4014401435852051, acc=0.8282222151756287, loss=0.4014401435852051
test: epoch 98, loss 1.5767351388931274, acc=0.5472221970558167, loss=1.5767351388931274
train: epoch 99, loss 0.41763415932655334, acc=0.8206666707992554, loss=0.41763415932655334
test: epoch 99, loss 1.4356977939605713, acc=0.5527777671813965, loss=1.4356977939605713
train: epoch 100, loss 0.4229045808315277, acc=0.8191111087799072, loss=0.4229045808315277
test: epoch 100, loss 1.5627182722091675, acc=0.5416666865348816, loss=1.5627182722091675
train: epoch 101, loss 0.40728670358657837, acc=0.8230000138282776, loss=0.40728670358657837
test: epoch 101, loss 1.6984846591949463, acc=0.5722222328186035, loss=1.6984846591949463
train: epoch 102, loss 0.4034976661205292, acc=0.8259999752044678, loss=0.4034976661205292
test: epoch 102, loss 1.3625223636627197, acc=0.5583333373069763, loss=1.3625223636627197
train: epoch 103, loss 0.40019965171813965, acc=0.828499972820282, loss=0.40019965171813965
test: epoch 103, loss 1.276031494140625, acc=0.5583333373069763, loss=1.276031494140625
train: epoch 104, loss 0.405917763710022, acc=0.8246111273765564, loss=0.405917763710022
test: epoch 104, loss 1.668116807937622, acc=0.5527777671813965, loss=1.668116807937622
train: epoch 105, loss 0.4000402092933655, acc=0.8277222514152527, loss=0.4000402092933655
test: epoch 105, loss 1.6613138914108276, acc=0.5527777671813965, loss=1.6613138914108276
train: epoch 106, loss 0.4046202600002289, acc=0.8263333439826965, loss=0.4046202600002289
test: epoch 106, loss 1.4515299797058105, acc=0.5277777910232544, loss=1.4515299797058105
train: epoch 107, loss 0.3952218294143677, acc=0.8305555582046509, loss=0.3952218294143677
test: epoch 107, loss 1.3361868858337402, acc=0.5527777671813965, loss=1.3361868858337402
train: epoch 108, loss 0.3983825445175171, acc=0.8293889164924622, loss=0.3983825445175171
test: epoch 108, loss 1.438364028930664, acc=0.5555555820465088, loss=1.438364028930664
train: epoch 109, loss 0.3984564542770386, acc=0.82833331823349, loss=0.3984564542770386
test: epoch 109, loss 1.5797446966171265, acc=0.5527777671813965, loss=1.5797446966171265
train: epoch 110, loss 0.38963931798934937, acc=0.8325555324554443, loss=0.38963931798934937
test: epoch 110, loss 1.5788846015930176, acc=0.5527777671813965, loss=1.5788846015930176
train: epoch 111, loss 0.4060259759426117, acc=0.8246666789054871, loss=0.4060259759426117
test: epoch 111, loss 1.5465192794799805, acc=0.5555555820465088, loss=1.5465192794799805
train: epoch 112, loss 0.3989078998565674, acc=0.8272777795791626, loss=0.3989078998565674
test: epoch 112, loss 1.555006980895996, acc=0.5527777671813965, loss=1.555006980895996
train: epoch 113, loss 0.401885986328125, acc=0.8264999985694885, loss=0.401885986328125
test: epoch 113, loss 1.5936880111694336, acc=0.5527777671813965, loss=1.5936880111694336
train: epoch 114, loss 0.3925202786922455, acc=0.8301110863685608, loss=0.3925202786922455
test: epoch 114, loss 1.5478112697601318, acc=0.5555555820465088, loss=1.5478112697601318
train: epoch 115, loss 0.39103835821151733, acc=0.8293889164924622, loss=0.39103835821151733
test: epoch 115, loss 1.4473627805709839, acc=0.5583333373069763, loss=1.4473627805709839
train: epoch 116, loss 0.40184682607650757, acc=0.8281111121177673, loss=0.40184682607650757
test: epoch 116, loss 1.4752618074417114, acc=0.5583333373069763, loss=1.4752618074417114
train: epoch 117, loss 0.39374789595603943, acc=0.8296111226081848, loss=0.39374789595603943
test: epoch 117, loss 1.4930306673049927, acc=0.5638889074325562, loss=1.4930306673049927
train: epoch 118, loss 0.38837313652038574, acc=0.8317777514457703, loss=0.38837313652038574
test: epoch 118, loss 1.5223942995071411, acc=0.5583333373069763, loss=1.5223942995071411
train: epoch 119, loss 0.38433292508125305, acc=0.8312777876853943, loss=0.38433292508125305
test: epoch 119, loss 1.34230637550354, acc=0.5583333373069763, loss=1.34230637550354
train: epoch 120, loss 0.3874739706516266, acc=0.8321666717529297, loss=0.3874739706516266
test: epoch 120, loss 1.4281158447265625, acc=0.550000011920929, loss=1.4281158447265625
train: epoch 121, loss 0.38653767108917236, acc=0.8327222466468811, loss=0.38653767108917236
test: epoch 121, loss 1.4078905582427979, acc=0.5527777671813965, loss=1.4078905582427979
train: epoch 122, loss 0.39003971219062805, acc=0.8296666741371155, loss=0.39003971219062805
test: epoch 122, loss 1.5940839052200317, acc=0.5583333373069763, loss=1.5940839052200317
train: epoch 123, loss 0.4053734540939331, acc=0.8264444470405579, loss=0.4053734540939331
test: epoch 123, loss 1.594374656677246, acc=0.5666666626930237, loss=1.594374656677246
train: epoch 124, loss 0.3622688055038452, acc=0.8387777805328369, loss=0.3622688055038452
test: epoch 124, loss 1.539014220237732, acc=0.5666666626930237, loss=1.539014220237732
train: epoch 125, loss 0.38643336296081543, acc=0.8325555324554443, loss=0.38643336296081543
test: epoch 125, loss 1.733209252357483, acc=0.5694444179534912, loss=1.733209252357483
train: epoch 126, loss 0.3894200623035431, acc=0.8295555710792542, loss=0.3894200623035431
test: epoch 126, loss 1.6285735368728638, acc=0.5527777671813965, loss=1.6285735368728638
train: epoch 127, loss 0.3968355059623718, acc=0.827833354473114, loss=0.3968355059623718
test: epoch 127, loss 1.514063835144043, acc=0.5416666865348816, loss=1.514063835144043
train: epoch 128, loss 0.3827805519104004, acc=0.8327222466468811, loss=0.3827805519104004
test: epoch 128, loss 1.7880713939666748, acc=0.5583333373069763, loss=1.7880713939666748
train: epoch 129, loss 0.3726986050605774, acc=0.836388885974884, loss=0.3726986050605774
test: epoch 129, loss 1.391111135482788, acc=0.5638889074325562, loss=1.391111135482788
train: epoch 130, loss 0.38301679491996765, acc=0.832444429397583, loss=0.38301679491996765
test: epoch 130, loss 1.596604824066162, acc=0.5527777671813965, loss=1.596604824066162
train: epoch 131, loss 0.3781375288963318, acc=0.8341666460037231, loss=0.3781375288963318
test: epoch 131, loss 1.6511482000350952, acc=0.574999988079071, loss=1.6511482000350952
train: epoch 132, loss 0.38400301337242126, acc=0.831944465637207, loss=0.38400301337242126
test: epoch 132, loss 1.6423377990722656, acc=0.5722222328186035, loss=1.6423377990722656
train: epoch 133, loss 0.3775177001953125, acc=0.8335555791854858, loss=0.3775177001953125
test: epoch 133, loss 1.4516621828079224, acc=0.5611110925674438, loss=1.4516621828079224
train: epoch 134, loss 0.3826649785041809, acc=0.8348333239555359, loss=0.3826649785041809
test: epoch 134, loss 1.613356590270996, acc=0.5583333373069763, loss=1.613356590270996
train: epoch 135, loss 0.37454718351364136, acc=0.8382777571678162, loss=0.37454718351364136
test: epoch 135, loss 1.7609180212020874, acc=0.5527777671813965, loss=1.7609180212020874
train: epoch 136, loss 0.38214704394340515, acc=0.8336111307144165, loss=0.38214704394340515
test: epoch 136, loss 1.5107734203338623, acc=0.5694444179534912, loss=1.5107734203338623
train: epoch 137, loss 0.36448219418525696, acc=0.8376666903495789, loss=0.36448219418525696
test: epoch 137, loss 1.5238844156265259, acc=0.5583333373069763, loss=1.5238844156265259
train: epoch 138, loss 0.37572070956230164, acc=0.8368333578109741, loss=0.37572070956230164
test: epoch 138, loss 1.5048651695251465, acc=0.5611110925674438, loss=1.5048651695251465
train: epoch 139, loss 0.3865733742713928, acc=0.8342777490615845, loss=0.3865733742713928
test: epoch 139, loss 1.7211107015609741, acc=0.5583333373069763, loss=1.7211107015609741
train: epoch 140, loss 0.3709706664085388, acc=0.8356666564941406, loss=0.3709706664085388
test: epoch 140, loss 1.5535309314727783, acc=0.5722222328186035, loss=1.5535309314727783
train: epoch 141, loss 0.37010547518730164, acc=0.8367778062820435, loss=0.37010547518730164
test: epoch 141, loss 1.4689840078353882, acc=0.5833333134651184, loss=1.4689840078353882
train: epoch 142, loss 0.36431756615638733, acc=0.839555561542511, loss=0.36431756615638733
test: epoch 142, loss 1.496895432472229, acc=0.5777778029441833, loss=1.496895432472229
train: epoch 143, loss 0.37313634157180786, acc=0.836722195148468, loss=0.37313634157180786
test: epoch 143, loss 1.4904913902282715, acc=0.5833333134651184, loss=1.4904913902282715
train: epoch 144, loss 0.3859294354915619, acc=0.8336111307144165, loss=0.3859294354915619
test: epoch 144, loss 1.3128807544708252, acc=0.5777778029441833, loss=1.3128807544708252
train: epoch 145, loss 0.3765469491481781, acc=0.8351666927337646, loss=0.3765469491481781
test: epoch 145, loss 1.465580940246582, acc=0.574999988079071, loss=1.465580940246582
train: epoch 146, loss 0.37800970673561096, acc=0.8336111307144165, loss=0.37800970673561096
test: epoch 146, loss 1.418576717376709, acc=0.5638889074325562, loss=1.418576717376709
train: epoch 147, loss 0.37054920196533203, acc=0.8376666903495789, loss=0.37054920196533203
test: epoch 147, loss 1.5086151361465454, acc=0.574999988079071, loss=1.5086151361465454
train: epoch 148, loss 0.3648846745491028, acc=0.8387777805328369, loss=0.3648846745491028
test: epoch 148, loss 1.5788004398345947, acc=0.5777778029441833, loss=1.5788004398345947
train: epoch 149, loss 0.3716018795967102, acc=0.8386111259460449, loss=0.3716018795967102
test: epoch 149, loss 1.5693141222000122, acc=0.5833333134651184, loss=1.5693141222000122
train: epoch 150, loss 0.37570279836654663, acc=0.835444450378418, loss=0.37570279836654663
test: epoch 150, loss 1.3588056564331055, acc=0.5777778029441833, loss=1.3588056564331055
