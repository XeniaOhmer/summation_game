# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1", "--temp_decay=1", "--one_hot=false", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=226764163, receiver_embed_dim=32, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.246995210647583, acc=0.056388888508081436, loss=3.246995210647583
test: epoch 1, loss 2.9740560054779053, acc=0.07777778059244156, loss=2.9740560054779053
train: epoch 2, loss 2.83223295211792, acc=0.09016666561365128, loss=2.83223295211792
test: epoch 2, loss 3.330127716064453, acc=0.08888889104127884, loss=3.330127716064453
train: epoch 3, loss 2.54761004447937, acc=0.13272222876548767, loss=2.54761004447937
test: epoch 3, loss 2.68168306350708, acc=0.0972222238779068, loss=2.68168306350708
train: epoch 4, loss 2.3744056224823, acc=0.17122222483158112, loss=2.3744056224823
test: epoch 4, loss 2.6927077770233154, acc=0.1111111119389534, loss=2.6927077770233154
train: epoch 5, loss 2.2611563205718994, acc=0.18933333456516266, loss=2.2611563205718994
test: epoch 5, loss 2.632390022277832, acc=0.13055555522441864, loss=2.632390022277832
train: epoch 6, loss 2.1724066734313965, acc=0.20572222769260406, loss=2.1724066734313965
test: epoch 6, loss 2.6301631927490234, acc=0.13611111044883728, loss=2.6301631927490234
train: epoch 7, loss 2.0984766483306885, acc=0.21638889610767365, loss=2.0984766483306885
test: epoch 7, loss 2.5116348266601562, acc=0.15000000596046448, loss=2.5116348266601562
train: epoch 8, loss 2.0387725830078125, acc=0.23944444954395294, loss=2.0387725830078125
test: epoch 8, loss 2.502948045730591, acc=0.14722222089767456, loss=2.502948045730591
train: epoch 9, loss 1.9702610969543457, acc=0.2741111218929291, loss=1.9702610969543457
test: epoch 9, loss 2.2129924297332764, acc=0.21666666865348816, loss=2.2129924297332764
train: epoch 10, loss 1.9123995304107666, acc=0.3073333203792572, loss=1.9123995304107666
test: epoch 10, loss 2.1249117851257324, acc=0.2361111044883728, loss=2.1249117851257324
train: epoch 11, loss 1.8171144723892212, acc=0.3431110978126526, loss=1.8171144723892212
test: epoch 11, loss 2.245344400405884, acc=0.23888888955116272, loss=2.245344400405884
train: epoch 12, loss 1.7367525100708008, acc=0.3702777922153473, loss=1.7367525100708008
test: epoch 12, loss 2.0871732234954834, acc=0.25833332538604736, loss=2.0871732234954834
train: epoch 13, loss 1.6532267332077026, acc=0.4058888852596283, loss=1.6532267332077026
test: epoch 13, loss 1.9723577499389648, acc=0.30000001192092896, loss=1.9723577499389648
train: epoch 14, loss 1.6081657409667969, acc=0.42266666889190674, loss=1.6081657409667969
test: epoch 14, loss 2.0480992794036865, acc=0.31111112236976624, loss=2.0480992794036865
train: epoch 15, loss 1.5611006021499634, acc=0.43922221660614014, loss=1.5611006021499634
test: epoch 15, loss 1.8771685361862183, acc=0.32499998807907104, loss=1.8771685361862183
train: epoch 16, loss 1.529335618019104, acc=0.45705556869506836, loss=1.529335618019104
test: epoch 16, loss 1.8425754308700562, acc=0.32499998807907104, loss=1.8425754308700562
train: epoch 17, loss 1.4818172454833984, acc=0.472944438457489, loss=1.4818172454833984
test: epoch 17, loss 2.0027337074279785, acc=0.32499998807907104, loss=2.0027337074279785
train: epoch 18, loss 1.439241647720337, acc=0.4933333396911621, loss=1.439241647720337
test: epoch 18, loss 1.7973968982696533, acc=0.3583333194255829, loss=1.7973968982696533
train: epoch 19, loss 1.4089629650115967, acc=0.5077221989631653, loss=1.4089629650115967
test: epoch 19, loss 1.7930859327316284, acc=0.3861111104488373, loss=1.7930859327316284
train: epoch 20, loss 1.3723071813583374, acc=0.5213333368301392, loss=1.3723071813583374
test: epoch 20, loss 1.7812066078186035, acc=0.3888888955116272, loss=1.7812066078186035
train: epoch 21, loss 1.3530572652816772, acc=0.5303333401679993, loss=1.3530572652816772
test: epoch 21, loss 1.8059803247451782, acc=0.38055557012557983, loss=1.8059803247451782
train: epoch 22, loss 1.3374032974243164, acc=0.5339444279670715, loss=1.3374032974243164
test: epoch 22, loss 1.6471378803253174, acc=0.39722222089767456, loss=1.6471378803253174
train: epoch 23, loss 1.3099826574325562, acc=0.5488333106040955, loss=1.3099826574325562
test: epoch 23, loss 1.8398126363754272, acc=0.39444443583488464, loss=1.8398126363754272
train: epoch 24, loss 1.2901890277862549, acc=0.5535555481910706, loss=1.2901890277862549
test: epoch 24, loss 2.016700267791748, acc=0.38333332538604736, loss=2.016700267791748
train: epoch 25, loss 1.2670484781265259, acc=0.5618888735771179, loss=1.2670484781265259
test: epoch 25, loss 1.6495685577392578, acc=0.3916666805744171, loss=1.6495685577392578
train: epoch 26, loss 1.2852641344070435, acc=0.5554999709129333, loss=1.2852641344070435
test: epoch 26, loss 1.7093628644943237, acc=0.3916666805744171, loss=1.7093628644943237
train: epoch 27, loss 1.2412545680999756, acc=0.5721666812896729, loss=1.2412545680999756
test: epoch 27, loss 1.7665228843688965, acc=0.3888888955116272, loss=1.7665228843688965
train: epoch 28, loss 1.2427221536636353, acc=0.5712777972221375, loss=1.2427221536636353
test: epoch 28, loss 1.6250211000442505, acc=0.39444443583488464, loss=1.6250211000442505
train: epoch 29, loss 1.2299842834472656, acc=0.5753889083862305, loss=1.2299842834472656
test: epoch 29, loss 1.8980491161346436, acc=0.39722222089767456, loss=1.8980491161346436
train: epoch 30, loss 1.2046180963516235, acc=0.5822222232818604, loss=1.2046180963516235
test: epoch 30, loss 1.9189543724060059, acc=0.3861111104488373, loss=1.9189543724060059
train: epoch 31, loss 1.2046481370925903, acc=0.5863333344459534, loss=1.2046481370925903
test: epoch 31, loss 1.6296024322509766, acc=0.42500001192092896, loss=1.6296024322509766
train: epoch 32, loss 1.1924654245376587, acc=0.5872777700424194, loss=1.1924654245376587
test: epoch 32, loss 1.6231327056884766, acc=0.43611112236976624, loss=1.6231327056884766
train: epoch 33, loss 1.1989517211914062, acc=0.5873333215713501, loss=1.1989517211914062
test: epoch 33, loss 1.7203271389007568, acc=0.42222222685813904, loss=1.7203271389007568
train: epoch 34, loss 1.1880323886871338, acc=0.5895000100135803, loss=1.1880323886871338
test: epoch 34, loss 1.7703579664230347, acc=0.42500001192092896, loss=1.7703579664230347
train: epoch 35, loss 1.1893351078033447, acc=0.5871111154556274, loss=1.1893351078033447
test: epoch 35, loss 1.727027416229248, acc=0.42500001192092896, loss=1.727027416229248
train: epoch 36, loss 1.1665443181991577, acc=0.5985000133514404, loss=1.1665443181991577
test: epoch 36, loss 1.729320764541626, acc=0.4194444417953491, loss=1.729320764541626
train: epoch 37, loss 1.1761325597763062, acc=0.5988333225250244, loss=1.1761325597763062
test: epoch 37, loss 1.7536840438842773, acc=0.42500001192092896, loss=1.7536840438842773
train: epoch 38, loss 1.1419438123703003, acc=0.6114444732666016, loss=1.1419438123703003
test: epoch 38, loss 1.6964322328567505, acc=0.4277777671813965, loss=1.6964322328567505
train: epoch 39, loss 1.1439982652664185, acc=0.6102222204208374, loss=1.1439982652664185
test: epoch 39, loss 1.7113763093948364, acc=0.4416666626930237, loss=1.7113763093948364
train: epoch 40, loss 1.1336153745651245, acc=0.6141666769981384, loss=1.1336153745651245
test: epoch 40, loss 1.7204322814941406, acc=0.4138889014720917, loss=1.7204322814941406
train: epoch 41, loss 1.1085566282272339, acc=0.6223888993263245, loss=1.1085566282272339
test: epoch 41, loss 1.6881732940673828, acc=0.4166666567325592, loss=1.6881732940673828
train: epoch 42, loss 1.1126008033752441, acc=0.620555579662323, loss=1.1126008033752441
test: epoch 42, loss 1.868182897567749, acc=0.4194444417953491, loss=1.868182897567749
train: epoch 43, loss 1.1063395738601685, acc=0.621222198009491, loss=1.1063395738601685
test: epoch 43, loss 1.8134578466415405, acc=0.4166666567325592, loss=1.8134578466415405
train: epoch 44, loss 1.1142444610595703, acc=0.6199444532394409, loss=1.1142444610595703
test: epoch 44, loss 1.7415425777435303, acc=0.4194444417953491, loss=1.7415425777435303
train: epoch 45, loss 1.1078523397445679, acc=0.6225555539131165, loss=1.1078523397445679
test: epoch 45, loss 1.8062623739242554, acc=0.4333333373069763, loss=1.8062623739242554
train: epoch 46, loss 1.0953887701034546, acc=0.6264444589614868, loss=1.0953887701034546
test: epoch 46, loss 1.8276294469833374, acc=0.4138889014720917, loss=1.8276294469833374
train: epoch 47, loss 1.0769647359848022, acc=0.6297222375869751, loss=1.0769647359848022
test: epoch 47, loss 1.8904842138290405, acc=0.4444444477558136, loss=1.8904842138290405
train: epoch 48, loss 1.0847655534744263, acc=0.6251111030578613, loss=1.0847655534744263
test: epoch 48, loss 1.7534034252166748, acc=0.4555555582046509, loss=1.7534034252166748
train: epoch 49, loss 1.0946425199508667, acc=0.6242777705192566, loss=1.0946425199508667
test: epoch 49, loss 1.535672903060913, acc=0.4555555582046509, loss=1.535672903060913
train: epoch 50, loss 1.082323670387268, acc=0.628777801990509, loss=1.082323670387268
test: epoch 50, loss 1.708412766456604, acc=0.4583333432674408, loss=1.708412766456604
train: epoch 51, loss 1.0575282573699951, acc=0.6309999823570251, loss=1.0575282573699951
test: epoch 51, loss 1.7836335897445679, acc=0.4722222089767456, loss=1.7836335897445679
train: epoch 52, loss 1.008067011833191, acc=0.6349444389343262, loss=1.008067011833191
test: epoch 52, loss 1.691308856010437, acc=0.4722222089767456, loss=1.691308856010437
train: epoch 53, loss 1.0027931928634644, acc=0.6290000081062317, loss=1.0027931928634644
test: epoch 53, loss 1.7066891193389893, acc=0.46388888359069824, loss=1.7066891193389893
train: epoch 54, loss 0.9908564686775208, acc=0.6313333511352539, loss=0.9908564686775208
test: epoch 54, loss 1.5987331867218018, acc=0.46388888359069824, loss=1.5987331867218018
train: epoch 55, loss 0.9931986927986145, acc=0.6269444227218628, loss=0.9931986927986145
test: epoch 55, loss 1.7290817499160767, acc=0.4749999940395355, loss=1.7290817499160767
train: epoch 56, loss 0.9875624179840088, acc=0.6277222037315369, loss=0.9875624179840088
test: epoch 56, loss 1.8250699043273926, acc=0.4611110985279083, loss=1.8250699043273926
train: epoch 57, loss 0.9866984486579895, acc=0.6311666369438171, loss=0.9866984486579895
test: epoch 57, loss 1.7930659055709839, acc=0.4749999940395355, loss=1.7930659055709839
train: epoch 58, loss 0.9699149131774902, acc=0.6399444341659546, loss=0.9699149131774902
test: epoch 58, loss 1.8031158447265625, acc=0.48055556416511536, loss=1.8031158447265625
train: epoch 59, loss 0.960066556930542, acc=0.640666663646698, loss=0.960066556930542
test: epoch 59, loss 1.7352237701416016, acc=0.4722222089767456, loss=1.7352237701416016
train: epoch 60, loss 0.958618700504303, acc=0.6398888826370239, loss=0.958618700504303
test: epoch 60, loss 1.545506477355957, acc=0.4833333194255829, loss=1.545506477355957
train: epoch 61, loss 0.9551558494567871, acc=0.6419444680213928, loss=0.9551558494567871
test: epoch 61, loss 1.7822279930114746, acc=0.4694444537162781, loss=1.7822279930114746
train: epoch 62, loss 0.9680052399635315, acc=0.64083331823349, loss=0.9680052399635315
test: epoch 62, loss 1.6053189039230347, acc=0.48055556416511536, loss=1.6053189039230347
train: epoch 63, loss 0.9558416604995728, acc=0.6409444212913513, loss=0.9558416604995728
test: epoch 63, loss 1.6771031618118286, acc=0.4833333194255829, loss=1.6771031618118286
train: epoch 64, loss 0.9381835460662842, acc=0.6508333086967468, loss=0.9381835460662842
test: epoch 64, loss 1.8144067525863647, acc=0.4722222089767456, loss=1.8144067525863647
train: epoch 65, loss 0.9327074885368347, acc=0.6518333554267883, loss=0.9327074885368347
test: epoch 65, loss 1.70609712600708, acc=0.46666666865348816, loss=1.70609712600708
train: epoch 66, loss 0.9312753081321716, acc=0.6514999866485596, loss=0.9312753081321716
test: epoch 66, loss 1.721316933631897, acc=0.48055556416511536, loss=1.721316933631897
train: epoch 67, loss 0.9363554120063782, acc=0.6495000123977661, loss=0.9363554120063782
test: epoch 67, loss 1.7418385744094849, acc=0.47777777910232544, loss=1.7418385744094849
train: epoch 68, loss 0.9379518628120422, acc=0.6537222266197205, loss=0.9379518628120422
test: epoch 68, loss 1.6832720041275024, acc=0.4472222328186035, loss=1.6832720041275024
train: epoch 69, loss 0.908537745475769, acc=0.6609444618225098, loss=0.908537745475769
test: epoch 69, loss 1.7799381017684937, acc=0.4583333432674408, loss=1.7799381017684937
train: epoch 70, loss 0.9290685057640076, acc=0.6582777500152588, loss=0.9290685057640076
test: epoch 70, loss 1.6284394264221191, acc=0.46388888359069824, loss=1.6284394264221191
train: epoch 71, loss 0.9274157881736755, acc=0.657444417476654, loss=0.9274157881736755
test: epoch 71, loss 1.625197410583496, acc=0.4722222089767456, loss=1.625197410583496
train: epoch 72, loss 0.9092945456504822, acc=0.6646111011505127, loss=0.9092945456504822
test: epoch 72, loss 1.668026089668274, acc=0.4611110985279083, loss=1.668026089668274
train: epoch 73, loss 0.9080503582954407, acc=0.6630555391311646, loss=0.9080503582954407
test: epoch 73, loss 1.6767632961273193, acc=0.48055556416511536, loss=1.6767632961273193
train: epoch 74, loss 0.9200791120529175, acc=0.6589444279670715, loss=0.9200791120529175
test: epoch 74, loss 1.746091604232788, acc=0.4722222089767456, loss=1.746091604232788
train: epoch 75, loss 0.912720263004303, acc=0.660277783870697, loss=0.912720263004303
test: epoch 75, loss 1.567367434501648, acc=0.48055556416511536, loss=1.567367434501648
train: epoch 76, loss 0.9063209295272827, acc=0.6635555624961853, loss=0.9063209295272827
test: epoch 76, loss 1.8183218240737915, acc=0.4722222089767456, loss=1.8183218240737915
train: epoch 77, loss 0.8940134644508362, acc=0.6682222485542297, loss=0.8940134644508362
test: epoch 77, loss 1.7120730876922607, acc=0.4583333432674408, loss=1.7120730876922607
train: epoch 78, loss 0.8956458568572998, acc=0.6662777662277222, loss=0.8956458568572998
test: epoch 78, loss 1.8084059953689575, acc=0.4888888895511627, loss=1.8084059953689575
train: epoch 79, loss 0.9243230223655701, acc=0.6541666388511658, loss=0.9243230223655701
test: epoch 79, loss 1.757369041442871, acc=0.4749999940395355, loss=1.757369041442871
train: epoch 80, loss 0.8810056447982788, acc=0.6698889136314392, loss=0.8810056447982788
test: epoch 80, loss 1.672432541847229, acc=0.4722222089767456, loss=1.672432541847229
train: epoch 81, loss 0.8902556896209717, acc=0.6661111116409302, loss=0.8902556896209717
test: epoch 81, loss 1.595363736152649, acc=0.4722222089767456, loss=1.595363736152649
train: epoch 82, loss 0.8970298171043396, acc=0.6675000190734863, loss=0.8970298171043396
test: epoch 82, loss 1.6444262266159058, acc=0.4861111044883728, loss=1.6444262266159058
train: epoch 83, loss 0.8835237622261047, acc=0.672166645526886, loss=0.8835237622261047
test: epoch 83, loss 1.5620285272598267, acc=0.48055556416511536, loss=1.5620285272598267
train: epoch 84, loss 0.8874092102050781, acc=0.6713333129882812, loss=0.8874092102050781
test: epoch 84, loss 1.7654846906661987, acc=0.4749999940395355, loss=1.7654846906661987
train: epoch 85, loss 0.8811354041099548, acc=0.6728333234786987, loss=0.8811354041099548
test: epoch 85, loss 1.6739593744277954, acc=0.4888888895511627, loss=1.6739593744277954
train: epoch 86, loss 0.881695568561554, acc=0.6758333444595337, loss=0.881695568561554
test: epoch 86, loss 1.6721400022506714, acc=0.4833333194255829, loss=1.6721400022506714
train: epoch 87, loss 0.8911659121513367, acc=0.6706110835075378, loss=0.8911659121513367
test: epoch 87, loss 1.6181176900863647, acc=0.4833333194255829, loss=1.6181176900863647
train: epoch 88, loss 0.8800938725471497, acc=0.6726111173629761, loss=0.8800938725471497
test: epoch 88, loss 1.7251858711242676, acc=0.46388888359069824, loss=1.7251858711242676
train: epoch 89, loss 0.8843611478805542, acc=0.6743333339691162, loss=0.8843611478805542
test: epoch 89, loss 1.6159132719039917, acc=0.4722222089767456, loss=1.6159132719039917
train: epoch 90, loss 0.8590808510780334, acc=0.6823889017105103, loss=0.8590808510780334
test: epoch 90, loss 1.7101824283599854, acc=0.4972222149372101, loss=1.7101824283599854
train: epoch 91, loss 0.8850163221359253, acc=0.6741666793823242, loss=0.8850163221359253
test: epoch 91, loss 1.6715047359466553, acc=0.4722222089767456, loss=1.6715047359466553
train: epoch 92, loss 0.8605887293815613, acc=0.6780555844306946, loss=0.8605887293815613
test: epoch 92, loss 1.7572886943817139, acc=0.47777777910232544, loss=1.7572886943817139
train: epoch 93, loss 0.8677336573600769, acc=0.6754999756813049, loss=0.8677336573600769
test: epoch 93, loss 1.7747186422348022, acc=0.4833333194255829, loss=1.7747186422348022
train: epoch 94, loss 0.8690915107727051, acc=0.6772778034210205, loss=0.8690915107727051
test: epoch 94, loss 1.7416640520095825, acc=0.4888888895511627, loss=1.7416640520095825
train: epoch 95, loss 0.8636333346366882, acc=0.679611086845398, loss=0.8636333346366882
test: epoch 95, loss 1.604292869567871, acc=0.4694444537162781, loss=1.604292869567871
train: epoch 96, loss 0.8694816827774048, acc=0.6754444241523743, loss=0.8694816827774048
test: epoch 96, loss 1.6622812747955322, acc=0.4888888895511627, loss=1.6622812747955322
train: epoch 97, loss 0.8715129494667053, acc=0.6744999885559082, loss=0.8715129494667053
test: epoch 97, loss 1.6749869585037231, acc=0.47777777910232544, loss=1.6749869585037231
train: epoch 98, loss 0.8552898168563843, acc=0.6827222108840942, loss=0.8552898168563843
test: epoch 98, loss 1.8627899885177612, acc=0.48055556416511536, loss=1.8627899885177612
train: epoch 99, loss 0.8513399958610535, acc=0.684166669845581, loss=0.8513399958610535
test: epoch 99, loss 1.88634192943573, acc=0.4833333194255829, loss=1.88634192943573
train: epoch 100, loss 0.852363646030426, acc=0.6823333501815796, loss=0.852363646030426
test: epoch 100, loss 1.67609703540802, acc=0.48055556416511536, loss=1.67609703540802
train: epoch 101, loss 0.8441470861434937, acc=0.6870555281639099, loss=0.8441470861434937
test: epoch 101, loss 1.587267279624939, acc=0.4833333194255829, loss=1.587267279624939
train: epoch 102, loss 0.8729689717292786, acc=0.6779999732971191, loss=0.8729689717292786
test: epoch 102, loss 1.578558087348938, acc=0.4888888895511627, loss=1.578558087348938
train: epoch 103, loss 0.850459098815918, acc=0.6883333325386047, loss=0.850459098815918
test: epoch 103, loss 1.7980486154556274, acc=0.4833333194255829, loss=1.7980486154556274
train: epoch 104, loss 0.8562244772911072, acc=0.6848888993263245, loss=0.8562244772911072
test: epoch 104, loss 1.638218879699707, acc=0.48055556416511536, loss=1.638218879699707
train: epoch 105, loss 0.8689194321632385, acc=0.6834999918937683, loss=0.8689194321632385
test: epoch 105, loss 1.7136629819869995, acc=0.4694444537162781, loss=1.7136629819869995
train: epoch 106, loss 0.8424672484397888, acc=0.6911110877990723, loss=0.8424672484397888
test: epoch 106, loss 1.7430928945541382, acc=0.44999998807907104, loss=1.7430928945541382
train: epoch 107, loss 0.8436571359634399, acc=0.6897222399711609, loss=0.8436571359634399
test: epoch 107, loss 1.7427124977111816, acc=0.47777777910232544, loss=1.7427124977111816
train: epoch 108, loss 0.8629823327064514, acc=0.6892777681350708, loss=0.8629823327064514
test: epoch 108, loss 1.6789032220840454, acc=0.4694444537162781, loss=1.6789032220840454
train: epoch 109, loss 0.8385646939277649, acc=0.691777765750885, loss=0.8385646939277649
test: epoch 109, loss 1.708536982536316, acc=0.47777777910232544, loss=1.708536982536316
train: epoch 110, loss 0.8264929056167603, acc=0.6972222328186035, loss=0.8264929056167603
test: epoch 110, loss 1.70057213306427, acc=0.48055556416511536, loss=1.70057213306427
train: epoch 111, loss 0.8477015495300293, acc=0.6932222247123718, loss=0.8477015495300293
test: epoch 111, loss 1.8186709880828857, acc=0.4861111044883728, loss=1.8186709880828857
train: epoch 112, loss 0.8432210683822632, acc=0.6926110982894897, loss=0.8432210683822632
test: epoch 112, loss 1.7287540435791016, acc=0.4694444537162781, loss=1.7287540435791016
train: epoch 113, loss 0.8489661812782288, acc=0.6887221932411194, loss=0.8489661812782288
test: epoch 113, loss 1.6726112365722656, acc=0.4833333194255829, loss=1.6726112365722656
train: epoch 114, loss 0.8254711627960205, acc=0.6972222328186035, loss=0.8254711627960205
test: epoch 114, loss 1.759797215461731, acc=0.4722222089767456, loss=1.759797215461731
train: epoch 115, loss 0.8401782512664795, acc=0.694944441318512, loss=0.8401782512664795
test: epoch 115, loss 1.5974996089935303, acc=0.48055556416511536, loss=1.5974996089935303
train: epoch 116, loss 0.8388926982879639, acc=0.6943333148956299, loss=0.8388926982879639
test: epoch 116, loss 1.6180096864700317, acc=0.47777777910232544, loss=1.6180096864700317
train: epoch 117, loss 0.8591038584709167, acc=0.6852777600288391, loss=0.8591038584709167
test: epoch 117, loss 1.5796045064926147, acc=0.4861111044883728, loss=1.5796045064926147
train: epoch 118, loss 0.8204991221427917, acc=0.6966666579246521, loss=0.8204991221427917
test: epoch 118, loss 1.928442120552063, acc=0.4833333194255829, loss=1.928442120552063
train: epoch 119, loss 0.8255058526992798, acc=0.6959999799728394, loss=0.8255058526992798
test: epoch 119, loss 1.7609772682189941, acc=0.49444442987442017, loss=1.7609772682189941
train: epoch 120, loss 0.8348172307014465, acc=0.691944420337677, loss=0.8348172307014465
test: epoch 120, loss 1.7516820430755615, acc=0.4861111044883728, loss=1.7516820430755615
train: epoch 121, loss 0.822107195854187, acc=0.6976666450500488, loss=0.822107195854187
test: epoch 121, loss 1.5663663148880005, acc=0.4888888895511627, loss=1.5663663148880005
train: epoch 122, loss 0.8286657929420471, acc=0.6941111087799072, loss=0.8286657929420471
test: epoch 122, loss 1.8508626222610474, acc=0.4833333194255829, loss=1.8508626222610474
train: epoch 123, loss 0.8338279724121094, acc=0.6947222352027893, loss=0.8338279724121094
test: epoch 123, loss 1.7415419816970825, acc=0.4861111044883728, loss=1.7415419816970825
train: epoch 124, loss 0.8482103943824768, acc=0.6915555596351624, loss=0.8482103943824768
test: epoch 124, loss 1.4501261711120605, acc=0.5222222208976746, loss=1.4501261711120605
train: epoch 125, loss 0.816778838634491, acc=0.7012222409248352, loss=0.816778838634491
test: epoch 125, loss 1.5422861576080322, acc=0.5055555701255798, loss=1.5422861576080322
train: epoch 126, loss 0.821914553642273, acc=0.6976110935211182, loss=0.821914553642273
test: epoch 126, loss 1.4602231979370117, acc=0.5277777910232544, loss=1.4602231979370117
train: epoch 127, loss 0.8343021273612976, acc=0.699222207069397, loss=0.8343021273612976
test: epoch 127, loss 1.5516271591186523, acc=0.519444465637207, loss=1.5516271591186523
train: epoch 128, loss 0.8337898254394531, acc=0.6958333253860474, loss=0.8337898254394531
test: epoch 128, loss 1.580544114112854, acc=0.5305555462837219, loss=1.580544114112854
train: epoch 129, loss 0.8302955031394958, acc=0.6966666579246521, loss=0.8302955031394958
test: epoch 129, loss 1.5429794788360596, acc=0.5111111402511597, loss=1.5429794788360596
train: epoch 130, loss 0.810042142868042, acc=0.7033888697624207, loss=0.810042142868042
test: epoch 130, loss 1.6802948713302612, acc=0.5249999761581421, loss=1.6802948713302612
train: epoch 131, loss 0.8297920227050781, acc=0.699222207069397, loss=0.8297920227050781
test: epoch 131, loss 1.6925863027572632, acc=0.519444465637207, loss=1.6925863027572632
train: epoch 132, loss 0.8296620845794678, acc=0.6980000138282776, loss=0.8296620845794678
test: epoch 132, loss 1.439954161643982, acc=0.5166666507720947, loss=1.439954161643982
train: epoch 133, loss 0.8328638672828674, acc=0.6994444727897644, loss=0.8328638672828674
test: epoch 133, loss 1.524178147315979, acc=0.5277777910232544, loss=1.524178147315979
train: epoch 134, loss 0.8452110290527344, acc=0.6955000162124634, loss=0.8452110290527344
test: epoch 134, loss 1.6452057361602783, acc=0.5083333253860474, loss=1.6452057361602783
train: epoch 135, loss 0.9013306498527527, acc=0.6860555410385132, loss=0.9013306498527527
test: epoch 135, loss 1.5544837713241577, acc=0.5222222208976746, loss=1.5544837713241577
train: epoch 136, loss 0.822418749332428, acc=0.7008888721466064, loss=0.822418749332428
test: epoch 136, loss 1.5783281326293945, acc=0.5166666507720947, loss=1.5783281326293945
train: epoch 137, loss 0.8359875082969666, acc=0.6971111297607422, loss=0.8359875082969666
test: epoch 137, loss 1.6274441480636597, acc=0.5166666507720947, loss=1.6274441480636597
train: epoch 138, loss 0.8250555396080017, acc=0.6970555782318115, loss=0.8250555396080017
test: epoch 138, loss 1.5624313354492188, acc=0.5277777910232544, loss=1.5624313354492188
train: epoch 139, loss 0.8341793417930603, acc=0.6943888664245605, loss=0.8341793417930603
test: epoch 139, loss 1.4182178974151611, acc=0.5361111164093018, loss=1.4182178974151611
train: epoch 140, loss 0.8256127238273621, acc=0.6975555419921875, loss=0.8256127238273621
test: epoch 140, loss 1.4828654527664185, acc=0.5222222208976746, loss=1.4828654527664185
train: epoch 141, loss 0.8196203708648682, acc=0.7006111145019531, loss=0.8196203708648682
test: epoch 141, loss 1.4293054342269897, acc=0.5361111164093018, loss=1.4293054342269897
train: epoch 142, loss 0.7984181046485901, acc=0.7042222023010254, loss=0.7984181046485901
test: epoch 142, loss 1.605745792388916, acc=0.5361111164093018, loss=1.605745792388916
train: epoch 143, loss 0.8150796294212341, acc=0.7022222280502319, loss=0.8150796294212341
test: epoch 143, loss 1.3927148580551147, acc=0.5361111164093018, loss=1.3927148580551147
train: epoch 144, loss 0.8098422288894653, acc=0.7010555267333984, loss=0.8098422288894653
test: epoch 144, loss 1.5859941244125366, acc=0.5305555462837219, loss=1.5859941244125366
train: epoch 145, loss 0.8143166899681091, acc=0.6997777819633484, loss=0.8143166899681091
test: epoch 145, loss 1.4934165477752686, acc=0.5388888716697693, loss=1.4934165477752686
train: epoch 146, loss 0.8131276965141296, acc=0.6997222304344177, loss=0.8131276965141296
test: epoch 146, loss 1.4693454504013062, acc=0.5333333611488342, loss=1.4693454504013062
train: epoch 147, loss 0.8287965059280396, acc=0.6947222352027893, loss=0.8287965059280396
test: epoch 147, loss 1.6907366514205933, acc=0.5305555462837219, loss=1.6907366514205933
train: epoch 148, loss 0.8033283352851868, acc=0.7041666507720947, loss=0.8033283352851868
test: epoch 148, loss 1.6189745664596558, acc=0.5277777910232544, loss=1.6189745664596558
train: epoch 149, loss 0.8273350596427917, acc=0.7032222151756287, loss=0.8273350596427917
test: epoch 149, loss 1.4674899578094482, acc=0.5388888716697693, loss=1.4674899578094482
train: epoch 150, loss 0.8331784009933472, acc=0.6977777481079102, loss=0.8331784009933472
test: epoch 150, loss 1.4124525785446167, acc=0.5333333611488342, loss=1.4124525785446167
