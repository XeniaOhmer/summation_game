# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=1.5", "--temp_decay=1", "--one_hot=true", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=958112322, receiver_embed_dim=128, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.72890567779541, acc=0.12044444680213928, loss=2.72890567779541
test: epoch 1, loss 3.430579662322998, acc=0.10833333432674408, loss=3.430579662322998
train: epoch 2, loss 1.4609951972961426, acc=0.41616666316986084, loss=1.4609951972961426
test: epoch 2, loss 2.4161810874938965, acc=0.19722221791744232, loss=2.4161810874938965
train: epoch 3, loss 1.0149807929992676, acc=0.5786111354827881, loss=1.0149807929992676
test: epoch 3, loss 1.9452552795410156, acc=0.3166666626930237, loss=1.9452552795410156
train: epoch 4, loss 0.8046046495437622, acc=0.6678333282470703, loss=0.8046046495437622
test: epoch 4, loss 1.6214332580566406, acc=0.3722222149372101, loss=1.6214332580566406
train: epoch 5, loss 0.6863715052604675, acc=0.7176666855812073, loss=0.6863715052604675
test: epoch 5, loss 1.7457222938537598, acc=0.4166666567325592, loss=1.7457222938537598
train: epoch 6, loss 0.5827704071998596, acc=0.758388876914978, loss=0.5827704071998596
test: epoch 6, loss 1.6757903099060059, acc=0.42500001192092896, loss=1.6757903099060059
train: epoch 7, loss 0.5154980421066284, acc=0.7934444546699524, loss=0.5154980421066284
test: epoch 7, loss 1.575636863708496, acc=0.4277777671813965, loss=1.575636863708496
train: epoch 8, loss 0.45976483821868896, acc=0.8141111135482788, loss=0.45976483821868896
test: epoch 8, loss 1.7670990228652954, acc=0.43611112236976624, loss=1.7670990228652954
train: epoch 9, loss 0.40703341364860535, acc=0.8323333263397217, loss=0.40703341364860535
test: epoch 9, loss 1.5625190734863281, acc=0.4277777671813965, loss=1.5625190734863281
train: epoch 10, loss 0.3900298774242401, acc=0.839722216129303, loss=0.3900298774242401
test: epoch 10, loss 1.3706355094909668, acc=0.5361111164093018, loss=1.3706355094909668
train: epoch 11, loss 0.351845383644104, acc=0.8587222099304199, loss=0.351845383644104
test: epoch 11, loss 1.7696521282196045, acc=0.4416666626930237, loss=1.7696521282196045
train: epoch 12, loss 0.3249492347240448, acc=0.8688889145851135, loss=0.3249492347240448
test: epoch 12, loss 1.740293025970459, acc=0.4472222328186035, loss=1.740293025970459
train: epoch 13, loss 0.332504004240036, acc=0.8641111254692078, loss=0.332504004240036
test: epoch 13, loss 1.6601994037628174, acc=0.39722222089767456, loss=1.6601994037628174
train: epoch 14, loss 0.28713124990463257, acc=0.8801110982894897, loss=0.28713124990463257
test: epoch 14, loss 2.1483266353607178, acc=0.4055555462837219, loss=2.1483266353607178
train: epoch 15, loss 0.2753981351852417, acc=0.886722207069397, loss=0.2753981351852417
test: epoch 15, loss 1.6525744199752808, acc=0.4472222328186035, loss=1.6525744199752808
train: epoch 16, loss 0.2719232141971588, acc=0.8904444575309753, loss=0.2719232141971588
test: epoch 16, loss 1.7664225101470947, acc=0.43888887763023376, loss=1.7664225101470947
train: epoch 17, loss 0.2589540481567383, acc=0.8912777900695801, loss=0.2589540481567383
test: epoch 17, loss 1.5547709465026855, acc=0.5083333253860474, loss=1.5547709465026855
train: epoch 18, loss 0.2375158965587616, acc=0.8993333578109741, loss=0.2375158965587616
test: epoch 18, loss 1.9879170656204224, acc=0.4055555462837219, loss=1.9879170656204224
train: epoch 19, loss 0.23035220801830292, acc=0.9011666774749756, loss=0.23035220801830292
test: epoch 19, loss 1.8397618532180786, acc=0.42222222685813904, loss=1.8397618532180786
train: epoch 20, loss 0.2301233559846878, acc=0.9013333320617676, loss=0.2301233559846878
test: epoch 20, loss 2.144517660140991, acc=0.4333333373069763, loss=2.144517660140991
train: epoch 21, loss 0.22029797732830048, acc=0.9087777733802795, loss=0.22029797732830048
test: epoch 21, loss 2.2374167442321777, acc=0.45277777314186096, loss=2.2374167442321777
train: epoch 22, loss 0.19899395108222961, acc=0.9139444231987, loss=0.19899395108222961
test: epoch 22, loss 1.7092299461364746, acc=0.4555555582046509, loss=1.7092299461364746
train: epoch 23, loss 0.21253810822963715, acc=0.9082777500152588, loss=0.21253810822963715
test: epoch 23, loss 1.7666208744049072, acc=0.4694444537162781, loss=1.7666208744049072
train: epoch 24, loss 0.19980908930301666, acc=0.9139444231987, loss=0.19980908930301666
test: epoch 24, loss 1.3550071716308594, acc=0.5583333373069763, loss=1.3550071716308594
train: epoch 25, loss 0.1918402463197708, acc=0.913777768611908, loss=0.1918402463197708
test: epoch 25, loss 1.5437219142913818, acc=0.5583333373069763, loss=1.5437219142913818
train: epoch 26, loss 0.18913061916828156, acc=0.9163333177566528, loss=0.18913061916828156
test: epoch 26, loss 1.7386366128921509, acc=0.5166666507720947, loss=1.7386366128921509
train: epoch 27, loss 0.18009889125823975, acc=0.9213888645172119, loss=0.18009889125823975
test: epoch 27, loss 1.3582180738449097, acc=0.6027777791023254, loss=1.3582180738449097
train: epoch 28, loss 0.17029839754104614, acc=0.9235000014305115, loss=0.17029839754104614
test: epoch 28, loss 1.4660749435424805, acc=0.5666666626930237, loss=1.4660749435424805
train: epoch 29, loss 0.1845729649066925, acc=0.9185000061988831, loss=0.1845729649066925
test: epoch 29, loss 1.4440377950668335, acc=0.605555534362793, loss=1.4440377950668335
train: epoch 30, loss 0.16511741280555725, acc=0.9239444732666016, loss=0.16511741280555725
test: epoch 30, loss 1.3349558115005493, acc=0.5805555582046509, loss=1.3349558115005493
train: epoch 31, loss 0.16450484097003937, acc=0.9221110939979553, loss=0.16450484097003937
test: epoch 31, loss 1.3539924621582031, acc=0.5861111283302307, loss=1.3539924621582031
train: epoch 32, loss 0.15450362861156464, acc=0.9270555377006531, loss=0.15450362861156464
test: epoch 32, loss 1.6507385969161987, acc=0.5722222328186035, loss=1.6507385969161987
train: epoch 33, loss 0.15604080259799957, acc=0.9275555610656738, loss=0.15604080259799957
test: epoch 33, loss 1.3434174060821533, acc=0.6499999761581421, loss=1.3434174060821533
train: epoch 34, loss 0.15797802805900574, acc=0.9282777905464172, loss=0.15797802805900574
test: epoch 34, loss 1.5100302696228027, acc=0.644444465637207, loss=1.5100302696228027
train: epoch 35, loss 0.15896613895893097, acc=0.9269444346427917, loss=0.15896613895893097
test: epoch 35, loss 1.235090732574463, acc=0.6722221970558167, loss=1.235090732574463
train: epoch 36, loss 0.14751985669136047, acc=0.9329444169998169, loss=0.14751985669136047
test: epoch 36, loss 1.261000633239746, acc=0.6416666507720947, loss=1.261000633239746
train: epoch 37, loss 0.14990875124931335, acc=0.9317222237586975, loss=0.14990875124931335
test: epoch 37, loss 1.2700490951538086, acc=0.6666666865348816, loss=1.2700490951538086
train: epoch 38, loss 0.13665702939033508, acc=0.9328888654708862, loss=0.13665702939033508
test: epoch 38, loss 1.303209662437439, acc=0.6527777910232544, loss=1.303209662437439
train: epoch 39, loss 0.13087323307991028, acc=0.9353888630867004, loss=0.13087323307991028
test: epoch 39, loss 1.2429057359695435, acc=0.6611111164093018, loss=1.2429057359695435
train: epoch 40, loss 0.14250358939170837, acc=0.9323333501815796, loss=0.14250358939170837
test: epoch 40, loss 1.0491933822631836, acc=0.6972222328186035, loss=1.0491933822631836
train: epoch 41, loss 0.13434527814388275, acc=0.9332777857780457, loss=0.13434527814388275
test: epoch 41, loss 1.3857946395874023, acc=0.675000011920929, loss=1.3857946395874023
train: epoch 42, loss 0.14118734002113342, acc=0.9357777833938599, loss=0.14118734002113342
test: epoch 42, loss 1.0423269271850586, acc=0.7027778029441833, loss=1.0423269271850586
train: epoch 43, loss 0.1348358392715454, acc=0.933722198009491, loss=0.1348358392715454
test: epoch 43, loss 1.0112568140029907, acc=0.7388888597488403, loss=1.0112568140029907
train: epoch 44, loss 0.12654539942741394, acc=0.9338333606719971, loss=0.12654539942741394
test: epoch 44, loss 1.1123521327972412, acc=0.6833333373069763, loss=1.1123521327972412
train: epoch 45, loss 0.13199105858802795, acc=0.9369999766349792, loss=0.13199105858802795
test: epoch 45, loss 0.7989808320999146, acc=0.7444444298744202, loss=0.7989808320999146
train: epoch 46, loss 0.12721313536167145, acc=0.9340000152587891, loss=0.12721313536167145
test: epoch 46, loss 1.1870973110198975, acc=0.7166666388511658, loss=1.1870973110198975
train: epoch 47, loss 0.12581773102283478, acc=0.9387221932411194, loss=0.12581773102283478
test: epoch 47, loss 1.0512861013412476, acc=0.7361111044883728, loss=1.0512861013412476
train: epoch 48, loss 0.12665127217769623, acc=0.9351666569709778, loss=0.12665127217769623
test: epoch 48, loss 0.8726779818534851, acc=0.7527777552604675, loss=0.8726779818534851
train: epoch 49, loss 0.12609906494617462, acc=0.9340555667877197, loss=0.12609906494617462
test: epoch 49, loss 1.0260487794876099, acc=0.7527777552604675, loss=1.0260487794876099
train: epoch 50, loss 0.11917024850845337, acc=0.9369444251060486, loss=0.11917024850845337
test: epoch 50, loss 0.9982398152351379, acc=0.7194444537162781, loss=0.9982398152351379
train: epoch 51, loss 0.12371273338794708, acc=0.9356666803359985, loss=0.12371273338794708
test: epoch 51, loss 0.8599007725715637, acc=0.7250000238418579, loss=0.8599007725715637
train: epoch 52, loss 0.1266109198331833, acc=0.9383888840675354, loss=0.1266109198331833
test: epoch 52, loss 0.9477053284645081, acc=0.7333333492279053, loss=0.9477053284645081
train: epoch 53, loss 0.1144447848200798, acc=0.9384444355964661, loss=0.1144447848200798
test: epoch 53, loss 0.7915285229682922, acc=0.7777777910232544, loss=0.7915285229682922
train: epoch 54, loss 0.1264759600162506, acc=0.9351666569709778, loss=0.1264759600162506
test: epoch 54, loss 0.8045665621757507, acc=0.7361111044883728, loss=0.8045665621757507
train: epoch 55, loss 0.11579710990190506, acc=0.9376111030578613, loss=0.11579710990190506
test: epoch 55, loss 0.7231282591819763, acc=0.7888888716697693, loss=0.7231282591819763
train: epoch 56, loss 0.11261116713285446, acc=0.9434999823570251, loss=0.11261116713285446
test: epoch 56, loss 0.7698990106582642, acc=0.7888888716697693, loss=0.7698990106582642
train: epoch 57, loss 0.1139797791838646, acc=0.9405555725097656, loss=0.1139797791838646
test: epoch 57, loss 0.6886336207389832, acc=0.7861111164093018, loss=0.6886336207389832
train: epoch 58, loss 0.1096654012799263, acc=0.9398888945579529, loss=0.1096654012799263
test: epoch 58, loss 0.9949003458023071, acc=0.7888888716697693, loss=0.9949003458023071
train: epoch 59, loss 0.10291759669780731, acc=0.9412222504615784, loss=0.10291759669780731
test: epoch 59, loss 0.9527777433395386, acc=0.7805555462837219, loss=0.9527777433395386
train: epoch 60, loss 0.11144711077213287, acc=0.9408888816833496, loss=0.11144711077213287
test: epoch 60, loss 0.6604037284851074, acc=0.7972221970558167, loss=0.6604037284851074
train: epoch 61, loss 0.09743119031190872, acc=0.9434444308280945, loss=0.09743119031190872
test: epoch 61, loss 0.7804492712020874, acc=0.7972221970558167, loss=0.7804492712020874
train: epoch 62, loss 0.09894978255033493, acc=0.9403889179229736, loss=0.09894978255033493
test: epoch 62, loss 1.039306640625, acc=0.769444465637207, loss=1.039306640625
train: epoch 63, loss 0.12054853141307831, acc=0.9402222037315369, loss=0.12054853141307831
test: epoch 63, loss 0.6859543323516846, acc=0.8194444179534912, loss=0.6859543323516846
train: epoch 64, loss 0.09758439660072327, acc=0.9417222142219543, loss=0.09758439660072327
test: epoch 64, loss 0.65260249376297, acc=0.8138889074325562, loss=0.65260249376297
train: epoch 65, loss 0.11438355594873428, acc=0.9384999871253967, loss=0.11438355594873428
test: epoch 65, loss 0.7156794667243958, acc=0.8333333134651184, loss=0.7156794667243958
train: epoch 66, loss 0.10846102982759476, acc=0.9424999952316284, loss=0.10846102982759476
test: epoch 66, loss 0.5449924468994141, acc=0.8472222089767456, loss=0.5449924468994141
train: epoch 67, loss 0.09600725024938583, acc=0.9438333511352539, loss=0.09600725024938583
test: epoch 67, loss 0.6548225283622742, acc=0.8361111283302307, loss=0.6548225283622742
train: epoch 68, loss 0.1120079830288887, acc=0.9438889026641846, loss=0.1120079830288887
test: epoch 68, loss 0.6058952212333679, acc=0.8305555582046509, loss=0.6058952212333679
train: epoch 69, loss 0.0929492935538292, acc=0.9441111087799072, loss=0.0929492935538292
test: epoch 69, loss 0.5242596864700317, acc=0.855555534362793, loss=0.5242596864700317
train: epoch 70, loss 0.09283720701932907, acc=0.9480000138282776, loss=0.09283720701932907
test: epoch 70, loss 0.517381489276886, acc=0.8638888597488403, loss=0.517381489276886
train: epoch 71, loss 0.09926760941743851, acc=0.9472222328186035, loss=0.09926760941743851
test: epoch 71, loss 0.44979622960090637, acc=0.8500000238418579, loss=0.44979622960090637
train: epoch 72, loss 0.089244544506073, acc=0.94477778673172, loss=0.089244544506073
test: epoch 72, loss 0.5323072075843811, acc=0.855555534362793, loss=0.5323072075843811
train: epoch 73, loss 0.09522134065628052, acc=0.9468888640403748, loss=0.09522134065628052
test: epoch 73, loss 0.5113683938980103, acc=0.8638888597488403, loss=0.5113683938980103
train: epoch 74, loss 0.08761390298604965, acc=0.9484444260597229, loss=0.08761390298604965
test: epoch 74, loss 0.5430616736412048, acc=0.8694444298744202, loss=0.5430616736412048
train: epoch 75, loss 0.09990134835243225, acc=0.9437777996063232, loss=0.09990134835243225
test: epoch 75, loss 0.4980441629886627, acc=0.8611111044883728, loss=0.4980441629886627
train: epoch 76, loss 0.09498708695173264, acc=0.9422222375869751, loss=0.09498708695173264
test: epoch 76, loss 0.4411035478115082, acc=0.8694444298744202, loss=0.4411035478115082
train: epoch 77, loss 0.09332101047039032, acc=0.9458333253860474, loss=0.09332101047039032
test: epoch 77, loss 0.5834125280380249, acc=0.8583333492279053, loss=0.5834125280380249
train: epoch 78, loss 0.0884857028722763, acc=0.941944420337677, loss=0.0884857028722763
test: epoch 78, loss 0.6626352667808533, acc=0.855555534362793, loss=0.6626352667808533
train: epoch 79, loss 0.09895755350589752, acc=0.9400555491447449, loss=0.09895755350589752
test: epoch 79, loss 0.6398839950561523, acc=0.8611111044883728, loss=0.6398839950561523
train: epoch 80, loss 0.09241358190774918, acc=0.9442222118377686, loss=0.09241358190774918
test: epoch 80, loss 0.44135865569114685, acc=0.8500000238418579, loss=0.44135865569114685
train: epoch 81, loss 0.08990137279033661, acc=0.9468333125114441, loss=0.08990137279033661
test: epoch 81, loss 0.5083162188529968, acc=0.8527777791023254, loss=0.5083162188529968
train: epoch 82, loss 0.09476298838853836, acc=0.9484999775886536, loss=0.09476298838853836
test: epoch 82, loss 0.5050347447395325, acc=0.8666666746139526, loss=0.5050347447395325
train: epoch 83, loss 0.09717924892902374, acc=0.9442222118377686, loss=0.09717924892902374
test: epoch 83, loss 0.5338103175163269, acc=0.8638888597488403, loss=0.5338103175163269
train: epoch 84, loss 0.09842581301927567, acc=0.9439444541931152, loss=0.09842581301927567
test: epoch 84, loss 0.5442757606506348, acc=0.8583333492279053, loss=0.5442757606506348
train: epoch 85, loss 0.09568851441144943, acc=0.9436666369438171, loss=0.09568851441144943
test: epoch 85, loss 0.6121395230293274, acc=0.8277778029441833, loss=0.6121395230293274
train: epoch 86, loss 0.09332701563835144, acc=0.9468888640403748, loss=0.09332701563835144
test: epoch 86, loss 0.5725848078727722, acc=0.8500000238418579, loss=0.5725848078727722
train: epoch 87, loss 0.09021718055009842, acc=0.945722222328186, loss=0.09021718055009842
test: epoch 87, loss 0.6633147597312927, acc=0.8583333492279053, loss=0.6633147597312927
train: epoch 88, loss 0.09111344069242477, acc=0.9485555291175842, loss=0.09111344069242477
test: epoch 88, loss 0.64278644323349, acc=0.8583333492279053, loss=0.64278644323349
train: epoch 89, loss 0.08459430187940598, acc=0.9508888721466064, loss=0.08459430187940598
test: epoch 89, loss 0.6774436831474304, acc=0.8444444537162781, loss=0.6774436831474304
train: epoch 90, loss 0.09830097109079361, acc=0.949055552482605, loss=0.09830097109079361
test: epoch 90, loss 0.527605414390564, acc=0.855555534362793, loss=0.527605414390564
train: epoch 91, loss 0.09008068591356277, acc=0.9455000162124634, loss=0.09008068591356277
test: epoch 91, loss 0.4594140350818634, acc=0.8444444537162781, loss=0.4594140350818634
train: epoch 92, loss 0.08212704211473465, acc=0.949055552482605, loss=0.08212704211473465
test: epoch 92, loss 0.6864632964134216, acc=0.8472222089767456, loss=0.6864632964134216
train: epoch 93, loss 0.09835053980350494, acc=0.9426666498184204, loss=0.09835053980350494
test: epoch 93, loss 0.5211378335952759, acc=0.8666666746139526, loss=0.5211378335952759
train: epoch 94, loss 0.09103331714868546, acc=0.9466666579246521, loss=0.09103331714868546
test: epoch 94, loss 0.5787214040756226, acc=0.8638888597488403, loss=0.5787214040756226
train: epoch 95, loss 0.07861495763063431, acc=0.9466111063957214, loss=0.07861495763063431
test: epoch 95, loss 0.6308086514472961, acc=0.8666666746139526, loss=0.6308086514472961
train: epoch 96, loss 0.09230177104473114, acc=0.9473333358764648, loss=0.09230177104473114
test: epoch 96, loss 0.576227605342865, acc=0.8666666746139526, loss=0.576227605342865
train: epoch 97, loss 0.08777271211147308, acc=0.948722243309021, loss=0.08777271211147308
test: epoch 97, loss 0.584460437297821, acc=0.8500000238418579, loss=0.584460437297821
train: epoch 98, loss 0.08130201697349548, acc=0.9472222328186035, loss=0.08130201697349548
test: epoch 98, loss 0.6142413020133972, acc=0.8666666746139526, loss=0.6142413020133972
train: epoch 99, loss 0.086483433842659, acc=0.945722222328186, loss=0.086483433842659
test: epoch 99, loss 0.5255621075630188, acc=0.8611111044883728, loss=0.5255621075630188
train: epoch 100, loss 0.09327882528305054, acc=0.9482222199440002, loss=0.09327882528305054
test: epoch 100, loss 0.5202685594558716, acc=0.8666666746139526, loss=0.5202685594558716
train: epoch 101, loss 0.09233026951551437, acc=0.9496666789054871, loss=0.09233026951551437
test: epoch 101, loss 0.49710148572921753, acc=0.8638888597488403, loss=0.49710148572921753
train: epoch 102, loss 0.08502206206321716, acc=0.9482777714729309, loss=0.08502206206321716
test: epoch 102, loss 0.5520312786102295, acc=0.8666666746139526, loss=0.5520312786102295
train: epoch 103, loss 0.083492211997509, acc=0.9488333463668823, loss=0.083492211997509
test: epoch 103, loss 0.5208049416542053, acc=0.8666666746139526, loss=0.5208049416542053
train: epoch 104, loss 0.07132276147603989, acc=0.9491111040115356, loss=0.07132276147603989
test: epoch 104, loss 0.8475866913795471, acc=0.8611111044883728, loss=0.8475866913795471
train: epoch 105, loss 0.07334133982658386, acc=0.9465000033378601, loss=0.07334133982658386
test: epoch 105, loss 0.8450546264648438, acc=0.8638888597488403, loss=0.8450546264648438
train: epoch 106, loss 0.07798474282026291, acc=0.9508333206176758, loss=0.07798474282026291
test: epoch 106, loss 0.8026982545852661, acc=0.8500000238418579, loss=0.8026982545852661
train: epoch 107, loss 0.08076348155736923, acc=0.9500555396080017, loss=0.08076348155736923
test: epoch 107, loss 0.4901503026485443, acc=0.8638888597488403, loss=0.4901503026485443
train: epoch 108, loss 0.07100728154182434, acc=0.9510555267333984, loss=0.07100728154182434
test: epoch 108, loss 0.5111929178237915, acc=0.8638888597488403, loss=0.5111929178237915
train: epoch 109, loss 0.06890708953142166, acc=0.9541110992431641, loss=0.06890708953142166
test: epoch 109, loss 0.6805026531219482, acc=0.8694444298744202, loss=0.6805026531219482
train: epoch 110, loss 0.07456671446561813, acc=0.9536666870117188, loss=0.07456671446561813
test: epoch 110, loss 0.4726361632347107, acc=0.8805555701255798, loss=0.4726361632347107
train: epoch 111, loss 0.07866083085536957, acc=0.952833354473114, loss=0.07866083085536957
test: epoch 111, loss 0.541398823261261, acc=0.8694444298744202, loss=0.541398823261261
train: epoch 112, loss 0.07331632822751999, acc=0.953000009059906, loss=0.07331632822751999
test: epoch 112, loss 0.44266584515571594, acc=0.8777777552604675, loss=0.44266584515571594
train: epoch 113, loss 0.07765030115842819, acc=0.9555000066757202, loss=0.07765030115842819
test: epoch 113, loss 0.5804426670074463, acc=0.8722222447395325, loss=0.5804426670074463
train: epoch 114, loss 0.06667265295982361, acc=0.9518888592720032, loss=0.06667265295982361
test: epoch 114, loss 0.6023228764533997, acc=0.8805555701255798, loss=0.6023228764533997
train: epoch 115, loss 0.0722738578915596, acc=0.9508888721466064, loss=0.0722738578915596
test: epoch 115, loss 0.4813493490219116, acc=0.8999999761581421, loss=0.4813493490219116
train: epoch 116, loss 0.07643251866102219, acc=0.953166663646698, loss=0.07643251866102219
test: epoch 116, loss 0.36034414172172546, acc=0.8861111402511597, loss=0.36034414172172546
train: epoch 117, loss 0.06698381900787354, acc=0.9531111121177673, loss=0.06698381900787354
test: epoch 117, loss 0.49127906560897827, acc=0.8694444298744202, loss=0.49127906560897827
train: epoch 118, loss 0.06913338601589203, acc=0.9543889164924622, loss=0.06913338601589203
test: epoch 118, loss 0.3392632305622101, acc=0.9055555462837219, loss=0.3392632305622101
train: epoch 119, loss 0.061438534408807755, acc=0.9521666765213013, loss=0.061438534408807755
test: epoch 119, loss 0.36931025981903076, acc=0.9138888716697693, loss=0.36931025981903076
train: epoch 120, loss 0.07637090981006622, acc=0.9545000195503235, loss=0.07637090981006622
test: epoch 120, loss 0.3647138774394989, acc=0.9083333611488342, loss=0.3647138774394989
train: epoch 121, loss 0.06957951933145523, acc=0.9527222514152527, loss=0.06957951933145523
test: epoch 121, loss 0.3426750600337982, acc=0.9055555462837219, loss=0.3426750600337982
train: epoch 122, loss 0.06936733424663544, acc=0.9529444575309753, loss=0.06936733424663544
test: epoch 122, loss 0.2812175154685974, acc=0.9138888716697693, loss=0.2812175154685974
train: epoch 123, loss 0.055110491812229156, acc=0.9523333311080933, loss=0.055110491812229156
test: epoch 123, loss 0.3631041347980499, acc=0.9138888716697693, loss=0.3631041347980499
train: epoch 124, loss 0.06648938357830048, acc=0.9549444317817688, loss=0.06648938357830048
test: epoch 124, loss 0.30257105827331543, acc=0.9222221970558167, loss=0.30257105827331543
train: epoch 125, loss 0.06286133825778961, acc=0.9527222514152527, loss=0.06286133825778961
test: epoch 125, loss 0.23401851952075958, acc=0.9222221970558167, loss=0.23401851952075958
train: epoch 126, loss 0.06410883367061615, acc=0.9518333077430725, loss=0.06410883367061615
test: epoch 126, loss 0.19002778828144073, acc=0.9277777671813965, loss=0.19002778828144073
train: epoch 127, loss 0.0589398592710495, acc=0.9509999752044678, loss=0.0589398592710495
test: epoch 127, loss 0.3388562500476837, acc=0.9083333611488342, loss=0.3388562500476837
train: epoch 128, loss 0.06463364511728287, acc=0.9509444236755371, loss=0.06463364511728287
test: epoch 128, loss 0.2113720029592514, acc=0.9166666865348816, loss=0.2113720029592514
train: epoch 129, loss 0.05782739073038101, acc=0.9531111121177673, loss=0.05782739073038101
test: epoch 129, loss 0.2454526573419571, acc=0.9222221970558167, loss=0.2454526573419571
train: epoch 130, loss 0.05988488718867302, acc=0.9503889083862305, loss=0.05988488718867302
test: epoch 130, loss 0.27360811829566956, acc=0.9277777671813965, loss=0.27360811829566956
train: epoch 131, loss 0.057750359177589417, acc=0.9559999704360962, loss=0.057750359177589417
test: epoch 131, loss 0.2799949049949646, acc=0.9277777671813965, loss=0.2799949049949646
train: epoch 132, loss 0.07089255750179291, acc=0.9605000019073486, loss=0.07089255750179291
test: epoch 132, loss 0.24176937341690063, acc=0.9277777671813965, loss=0.24176937341690063
train: epoch 133, loss 0.06367984414100647, acc=0.9556666612625122, loss=0.06367984414100647
test: epoch 133, loss 0.27346792817115784, acc=0.9277777671813965, loss=0.27346792817115784
train: epoch 134, loss 0.060687627643346786, acc=0.9642221927642822, loss=0.060687627643346786
test: epoch 134, loss 0.26519322395324707, acc=0.9277777671813965, loss=0.26519322395324707
train: epoch 135, loss 0.057489920407533646, acc=0.9621111154556274, loss=0.057489920407533646
test: epoch 135, loss 0.2787306308746338, acc=0.9277777671813965, loss=0.2787306308746338
train: epoch 136, loss 0.053628090769052505, acc=0.9588888883590698, loss=0.053628090769052505
test: epoch 136, loss 0.2973942458629608, acc=0.9277777671813965, loss=0.2973942458629608
train: epoch 137, loss 0.053208231925964355, acc=0.9653333425521851, loss=0.053208231925964355
test: epoch 137, loss 0.22440345585346222, acc=0.9305555820465088, loss=0.22440345585346222
train: epoch 138, loss 0.05487895756959915, acc=0.9678333401679993, loss=0.05487895756959915
test: epoch 138, loss 0.4325341284275055, acc=0.8972222208976746, loss=0.4325341284275055
train: epoch 139, loss 0.06672391295433044, acc=0.9599999785423279, loss=0.06672391295433044
test: epoch 139, loss 0.3869014084339142, acc=0.9277777671813965, loss=0.3869014084339142
train: epoch 140, loss 0.062187716364860535, acc=0.9696111083030701, loss=0.062187716364860535
test: epoch 140, loss 0.28092801570892334, acc=0.925000011920929, loss=0.28092801570892334
train: epoch 141, loss 0.05440157651901245, acc=0.980388879776001, loss=0.05440157651901245
test: epoch 141, loss 0.21023738384246826, acc=0.949999988079071, loss=0.21023738384246826
train: epoch 142, loss 0.037526290863752365, acc=0.9868888854980469, loss=0.037526290863752365
test: epoch 142, loss 0.23215273022651672, acc=0.9527778029441833, loss=0.23215273022651672
train: epoch 143, loss 0.03473522514104843, acc=0.9893333315849304, loss=0.03473522514104843
test: epoch 143, loss 0.22661855816841125, acc=0.9527778029441833, loss=0.22661855816841125
train: epoch 144, loss 0.033880218863487244, acc=0.988777756690979, loss=0.033880218863487244
test: epoch 144, loss 0.24813686311244965, acc=0.9527778029441833, loss=0.24813686311244965
train: epoch 145, loss 0.022215988487005234, acc=0.9929444193840027, loss=0.022215988487005234
test: epoch 145, loss 0.2537805140018463, acc=0.9555555582046509, loss=0.2537805140018463
train: epoch 146, loss 0.020751869305968285, acc=0.9940000176429749, loss=0.020751869305968285
test: epoch 146, loss 0.20035769045352936, acc=0.9583333134651184, loss=0.20035769045352936
train: epoch 147, loss 0.02051759511232376, acc=0.9946666955947876, loss=0.02051759511232376
test: epoch 147, loss 0.23771147429943085, acc=0.9583333134651184, loss=0.23771147429943085
train: epoch 148, loss 0.01688259467482567, acc=0.9943333268165588, loss=0.01688259467482567
test: epoch 148, loss 0.2572594881057739, acc=0.9583333134651184, loss=0.2572594881057739
train: epoch 149, loss 0.012973636388778687, acc=0.9954444169998169, loss=0.012973636388778687
test: epoch 149, loss 0.18473078310489655, acc=0.9583333134651184, loss=0.18473078310489655
train: epoch 150, loss 0.018323907628655434, acc=0.9946666955947876, loss=0.018323907628655434
test: epoch 150, loss 0.2209281623363495, acc=0.9583333134651184, loss=0.2209281623363495
