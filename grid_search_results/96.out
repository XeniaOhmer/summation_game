# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=0", "--n_layers=1"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=1018646140, receiver_embed_dim=64, save_run=0, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=1018646140, receiver_embed_dim=64, save_run=False, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.0826961994171143, acc=0.08749999850988388, loss=3.0826961994171143
test: epoch 1, loss 5.054286956787109, acc=0.05000000074505806, loss=5.054286956787109
train: epoch 2, loss 2.531606912612915, acc=0.16822221875190735, loss=2.531606912612915
test: epoch 2, loss 6.43808126449585, acc=0.03611111268401146, loss=6.43808126449585
train: epoch 3, loss 2.36960768699646, acc=0.19466666877269745, loss=2.36960768699646
test: epoch 3, loss 7.3516716957092285, acc=0.03888889029622078, loss=7.3516716957092285
train: epoch 4, loss 2.269805908203125, acc=0.21716666221618652, loss=2.269805908203125
test: epoch 4, loss 8.169732093811035, acc=0.0416666679084301, loss=8.169732093811035
train: epoch 5, loss 2.1979660987854004, acc=0.22316665947437286, loss=2.1979660987854004
test: epoch 5, loss 8.761828422546387, acc=0.03888889029622078, loss=8.761828422546387
train: epoch 6, loss 2.141167640686035, acc=0.23327778279781342, loss=2.141167640686035
test: epoch 6, loss 9.177475929260254, acc=0.03888889029622078, loss=9.177475929260254
train: epoch 7, loss 2.1023800373077393, acc=0.2448333352804184, loss=2.1023800373077393
test: epoch 7, loss 9.572999954223633, acc=0.03888889029622078, loss=9.572999954223633
train: epoch 8, loss 2.0681729316711426, acc=0.2493888884782791, loss=2.0681729316711426
test: epoch 8, loss 10.2548828125, acc=0.03611111268401146, loss=10.2548828125
train: epoch 9, loss 2.0496628284454346, acc=0.2591666579246521, loss=2.0496628284454346
test: epoch 9, loss 10.256952285766602, acc=0.03611111268401146, loss=10.256952285766602
train: epoch 10, loss 2.019380569458008, acc=0.2644444406032562, loss=2.019380569458008
test: epoch 10, loss 10.478167533874512, acc=0.03611111268401146, loss=10.478167533874512
train: epoch 11, loss 1.992850422859192, acc=0.2688888907432556, loss=1.992850422859192
test: epoch 11, loss 10.619335174560547, acc=0.03888889029622078, loss=10.619335174560547
train: epoch 12, loss 1.966626763343811, acc=0.27472221851348877, loss=1.966626763343811
test: epoch 12, loss 11.075067520141602, acc=0.03055555559694767, loss=11.075067520141602
train: epoch 13, loss 1.9551180601119995, acc=0.2771666646003723, loss=1.9551180601119995
test: epoch 13, loss 11.191354751586914, acc=0.03888889029622078, loss=11.191354751586914
train: epoch 14, loss 1.9473124742507935, acc=0.27638888359069824, loss=1.9473124742507935
test: epoch 14, loss 11.281574249267578, acc=0.03055555559694767, loss=11.281574249267578
train: epoch 15, loss 1.9326528310775757, acc=0.2781111001968384, loss=1.9326528310775757
test: epoch 15, loss 11.66135311126709, acc=0.02777777798473835, loss=11.66135311126709
train: epoch 16, loss 1.9181342124938965, acc=0.2869444489479065, loss=1.9181342124938965
test: epoch 16, loss 11.301767349243164, acc=0.03888889029622078, loss=11.301767349243164
train: epoch 17, loss 1.9083826541900635, acc=0.29027777910232544, loss=1.9083826541900635
test: epoch 17, loss 11.504530906677246, acc=0.03611111268401146, loss=11.504530906677246
train: epoch 18, loss 1.8895623683929443, acc=0.29649999737739563, loss=1.8895623683929443
test: epoch 18, loss 11.4495210647583, acc=0.03888889029622078, loss=11.4495210647583
train: epoch 19, loss 1.880441427230835, acc=0.292888879776001, loss=1.880441427230835
test: epoch 19, loss 11.539134979248047, acc=0.03888889029622078, loss=11.539134979248047
train: epoch 20, loss 1.881705403327942, acc=0.2962222099304199, loss=1.881705403327942
test: epoch 20, loss 11.55136489868164, acc=0.0416666679084301, loss=11.55136489868164
train: epoch 21, loss 1.8696987628936768, acc=0.30211111903190613, loss=1.8696987628936768
test: epoch 21, loss 11.225985527038574, acc=0.03611111268401146, loss=11.225985527038574
train: epoch 22, loss 1.8638571500778198, acc=0.2996111214160919, loss=1.8638571500778198
test: epoch 22, loss 11.483184814453125, acc=0.03888889029622078, loss=11.483184814453125
train: epoch 23, loss 1.8480435609817505, acc=0.2977222204208374, loss=1.8480435609817505
test: epoch 23, loss 11.60010051727295, acc=0.03888889029622078, loss=11.60010051727295
train: epoch 24, loss 1.8382867574691772, acc=0.308388888835907, loss=1.8382867574691772
test: epoch 24, loss 11.511962890625, acc=0.03888889029622078, loss=11.511962890625
train: epoch 25, loss 1.8441275358200073, acc=0.3093888759613037, loss=1.8441275358200073
test: epoch 25, loss 10.950850486755371, acc=0.0416666679084301, loss=10.950850486755371
train: epoch 26, loss 1.833823323249817, acc=0.3109999895095825, loss=1.833823323249817
test: epoch 26, loss 10.88456916809082, acc=0.04722222313284874, loss=10.88456916809082
train: epoch 27, loss 1.823489785194397, acc=0.31238889694213867, loss=1.823489785194397
test: epoch 27, loss 11.332479476928711, acc=0.04444444552063942, loss=11.332479476928711
train: epoch 28, loss 1.8276293277740479, acc=0.3083333373069763, loss=1.8276293277740479
test: epoch 28, loss 11.049456596374512, acc=0.0416666679084301, loss=11.049456596374512
train: epoch 29, loss 1.809926152229309, acc=0.3108888864517212, loss=1.809926152229309
test: epoch 29, loss 11.120393753051758, acc=0.0416666679084301, loss=11.120393753051758
train: epoch 30, loss 1.8057026863098145, acc=0.3091111183166504, loss=1.8057026863098145
test: epoch 30, loss 11.362255096435547, acc=0.03333333507180214, loss=11.362255096435547
train: epoch 31, loss 1.81643807888031, acc=0.31138888001441956, loss=1.81643807888031
test: epoch 31, loss 11.3356294631958, acc=0.03333333507180214, loss=11.3356294631958
train: epoch 32, loss 1.8137586116790771, acc=0.3113333284854889, loss=1.8137586116790771
test: epoch 32, loss 10.91936206817627, acc=0.03055555559694767, loss=10.91936206817627
train: epoch 33, loss 1.8174524307250977, acc=0.3170555531978607, loss=1.8174524307250977
test: epoch 33, loss 11.055795669555664, acc=0.03888889029622078, loss=11.055795669555664
train: epoch 34, loss 1.7940683364868164, acc=0.32027778029441833, loss=1.7940683364868164
test: epoch 34, loss 11.105159759521484, acc=0.03333333507180214, loss=11.105159759521484
train: epoch 35, loss 1.7978729009628296, acc=0.31744444370269775, loss=1.7978729009628296
test: epoch 35, loss 11.292865753173828, acc=0.03055555559694767, loss=11.292865753173828
train: epoch 36, loss 1.7902482748031616, acc=0.32455554604530334, loss=1.7902482748031616
test: epoch 36, loss 10.645217895507812, acc=0.0416666679084301, loss=10.645217895507812
train: epoch 37, loss 1.7837083339691162, acc=0.324444442987442, loss=1.7837083339691162
test: epoch 37, loss 10.961836814880371, acc=0.03333333507180214, loss=10.961836814880371
train: epoch 38, loss 1.7768728733062744, acc=0.32205554842948914, loss=1.7768728733062744
test: epoch 38, loss 10.860199928283691, acc=0.0416666679084301, loss=10.860199928283691
train: epoch 39, loss 1.7853176593780518, acc=0.32111111283302307, loss=1.7853176593780518
test: epoch 39, loss 10.661958694458008, acc=0.03888889029622078, loss=10.661958694458008
train: epoch 40, loss 1.7745606899261475, acc=0.32288888096809387, loss=1.7745606899261475
test: epoch 40, loss 10.551316261291504, acc=0.03888889029622078, loss=10.551316261291504
train: epoch 41, loss 1.7802355289459229, acc=0.328000009059906, loss=1.7802355289459229
test: epoch 41, loss 10.66197395324707, acc=0.03333333507180214, loss=10.66197395324707
train: epoch 42, loss 1.775464415550232, acc=0.3323333263397217, loss=1.775464415550232
test: epoch 42, loss 10.62147331237793, acc=0.03055555559694767, loss=10.62147331237793
train: epoch 43, loss 1.776868462562561, acc=0.3278333246707916, loss=1.776868462562561
test: epoch 43, loss 10.536303520202637, acc=0.03611111268401146, loss=10.536303520202637
train: epoch 44, loss 1.7731668949127197, acc=0.3243333399295807, loss=1.7731668949127197
test: epoch 44, loss 10.48721981048584, acc=0.03611111268401146, loss=10.48721981048584
train: epoch 45, loss 1.7673877477645874, acc=0.3330555558204651, loss=1.7673877477645874
test: epoch 45, loss 10.401632308959961, acc=0.03055555559694767, loss=10.401632308959961
train: epoch 46, loss 1.7698471546173096, acc=0.33000001311302185, loss=1.7698471546173096
test: epoch 46, loss 10.342148780822754, acc=0.04444444552063942, loss=10.342148780822754
train: epoch 47, loss 1.7623142004013062, acc=0.33116665482521057, loss=1.7623142004013062
test: epoch 47, loss 10.163640022277832, acc=0.0416666679084301, loss=10.163640022277832
train: epoch 48, loss 1.7629034519195557, acc=0.33266666531562805, loss=1.7629034519195557
test: epoch 48, loss 10.297040939331055, acc=0.03888889029622078, loss=10.297040939331055
train: epoch 49, loss 1.7663793563842773, acc=0.3314444422721863, loss=1.7663793563842773
test: epoch 49, loss 9.964489936828613, acc=0.04444444552063942, loss=9.964489936828613
train: epoch 50, loss 1.7735741138458252, acc=0.3327777683734894, loss=1.7735741138458252
test: epoch 50, loss 10.102996826171875, acc=0.02777777798473835, loss=10.102996826171875
train: epoch 51, loss 1.7758809328079224, acc=0.3333333432674408, loss=1.7758809328079224
test: epoch 51, loss 9.578018188476562, acc=0.03333333507180214, loss=9.578018188476562
train: epoch 52, loss 1.7587261199951172, acc=0.3323333263397217, loss=1.7587261199951172
test: epoch 52, loss 9.576737403869629, acc=0.02777777798473835, loss=9.576737403869629
train: epoch 53, loss 1.7697293758392334, acc=0.32544443011283875, loss=1.7697293758392334
test: epoch 53, loss 9.506596565246582, acc=0.0416666679084301, loss=9.506596565246582
train: epoch 54, loss 1.7766780853271484, acc=0.3324444591999054, loss=1.7766780853271484
test: epoch 54, loss 9.352059364318848, acc=0.04444444552063942, loss=9.352059364318848
train: epoch 55, loss 1.7717857360839844, acc=0.3376111090183258, loss=1.7717857360839844
test: epoch 55, loss 9.066421508789062, acc=0.03055555559694767, loss=9.066421508789062
train: epoch 56, loss 1.7689170837402344, acc=0.33338889479637146, loss=1.7689170837402344
test: epoch 56, loss 9.236525535583496, acc=0.04444444552063942, loss=9.236525535583496
train: epoch 57, loss 1.7637722492218018, acc=0.33683332800865173, loss=1.7637722492218018
test: epoch 57, loss 9.276826858520508, acc=0.02777777798473835, loss=9.276826858520508
train: epoch 58, loss 1.7680703401565552, acc=0.3345000147819519, loss=1.7680703401565552
test: epoch 58, loss 9.128095626831055, acc=0.03055555559694767, loss=9.128095626831055
train: epoch 59, loss 1.7666457891464233, acc=0.3352222144603729, loss=1.7666457891464233
test: epoch 59, loss 9.343968391418457, acc=0.03055555559694767, loss=9.343968391418457
train: epoch 60, loss 1.7605435848236084, acc=0.3389444351196289, loss=1.7605435848236084
test: epoch 60, loss 9.148300170898438, acc=0.02500000037252903, loss=9.148300170898438
train: epoch 61, loss 1.7646431922912598, acc=0.3345000147819519, loss=1.7646431922912598
test: epoch 61, loss 9.372629165649414, acc=0.02500000037252903, loss=9.372629165649414
train: epoch 62, loss 1.7700262069702148, acc=0.335833340883255, loss=1.7700262069702148
test: epoch 62, loss 9.171144485473633, acc=0.02500000037252903, loss=9.171144485473633
train: epoch 63, loss 1.7716972827911377, acc=0.34011110663414, loss=1.7716972827911377
test: epoch 63, loss 8.81532096862793, acc=0.02777777798473835, loss=8.81532096862793
train: epoch 64, loss 1.773248314857483, acc=0.3353888988494873, loss=1.773248314857483
test: epoch 64, loss 8.85723876953125, acc=0.02777777798473835, loss=8.85723876953125
train: epoch 65, loss 1.7881284952163696, acc=0.33294445276260376, loss=1.7881284952163696
test: epoch 65, loss 9.011624336242676, acc=0.03055555559694767, loss=9.011624336242676
train: epoch 66, loss 1.7778137922286987, acc=0.3377777636051178, loss=1.7778137922286987
test: epoch 66, loss 8.470610618591309, acc=0.03055555559694767, loss=8.470610618591309
train: epoch 67, loss 1.7782553434371948, acc=0.3390555679798126, loss=1.7782553434371948
test: epoch 67, loss 8.495426177978516, acc=0.02777777798473835, loss=8.495426177978516
train: epoch 68, loss 1.7619211673736572, acc=0.34094443917274475, loss=1.7619211673736572
test: epoch 68, loss 8.477648735046387, acc=0.02777777798473835, loss=8.477648735046387
train: epoch 69, loss 1.7656586170196533, acc=0.3366111218929291, loss=1.7656586170196533
test: epoch 69, loss 8.299120903015137, acc=0.02777777798473835, loss=8.299120903015137
train: epoch 70, loss 1.772584319114685, acc=0.33988890051841736, loss=1.772584319114685
test: epoch 70, loss 8.097344398498535, acc=0.03055555559694767, loss=8.097344398498535
train: epoch 71, loss 1.774917721748352, acc=0.33766666054725647, loss=1.774917721748352
test: epoch 71, loss 7.9409332275390625, acc=0.02777777798473835, loss=7.9409332275390625
train: epoch 72, loss 1.7890924215316772, acc=0.3353888988494873, loss=1.7890924215316772
test: epoch 72, loss 7.709434986114502, acc=0.03055555559694767, loss=7.709434986114502
train: epoch 73, loss 1.7749993801116943, acc=0.3299444317817688, loss=1.7749993801116943
test: epoch 73, loss 8.182954788208008, acc=0.03055555559694767, loss=8.182954788208008
train: epoch 74, loss 1.7861677408218384, acc=0.3336666524410248, loss=1.7861677408218384
test: epoch 74, loss 7.6962995529174805, acc=0.03055555559694767, loss=7.6962995529174805
train: epoch 75, loss 1.7936674356460571, acc=0.33222222328186035, loss=1.7936674356460571
test: epoch 75, loss 7.492233753204346, acc=0.02777777798473835, loss=7.492233753204346
train: epoch 76, loss 1.8035329580307007, acc=0.3382222354412079, loss=1.8035329580307007
test: epoch 76, loss 7.524845600128174, acc=0.03055555559694767, loss=7.524845600128174
train: epoch 77, loss 1.7834502458572388, acc=0.3370000123977661, loss=1.7834502458572388
test: epoch 77, loss 7.774085521697998, acc=0.0416666679084301, loss=7.774085521697998
train: epoch 78, loss 1.801972508430481, acc=0.3308333456516266, loss=1.801972508430481
test: epoch 78, loss 7.132329940795898, acc=0.03055555559694767, loss=7.132329940795898
train: epoch 79, loss 1.7919909954071045, acc=0.32749998569488525, loss=1.7919909954071045
test: epoch 79, loss 7.335357189178467, acc=0.03055555559694767, loss=7.335357189178467
train: epoch 80, loss 1.8116549253463745, acc=0.33594444394111633, loss=1.8116549253463745
test: epoch 80, loss 6.9925947189331055, acc=0.03888889029622078, loss=6.9925947189331055
train: epoch 81, loss 1.8014991283416748, acc=0.3343888819217682, loss=1.8014991283416748
test: epoch 81, loss 7.041232109069824, acc=0.02777777798473835, loss=7.041232109069824
train: epoch 82, loss 1.7971687316894531, acc=0.3302222192287445, loss=1.7971687316894531
test: epoch 82, loss 7.2294135093688965, acc=0.02777777798473835, loss=7.2294135093688965
train: epoch 83, loss 1.7968065738677979, acc=0.32644444704055786, loss=1.7968065738677979
test: epoch 83, loss 7.080237865447998, acc=0.03055555559694767, loss=7.080237865447998
train: epoch 84, loss 1.820696473121643, acc=0.33383333683013916, loss=1.820696473121643
test: epoch 84, loss 6.943724632263184, acc=0.03055555559694767, loss=6.943724632263184
train: epoch 85, loss 1.808205485343933, acc=0.33105555176734924, loss=1.808205485343933
test: epoch 85, loss 6.6315484046936035, acc=0.03333333507180214, loss=6.6315484046936035
train: epoch 86, loss 1.8024804592132568, acc=0.3305000066757202, loss=1.8024804592132568
test: epoch 86, loss 6.756410121917725, acc=0.03055555559694767, loss=6.756410121917725
train: epoch 87, loss 1.8043324947357178, acc=0.328000009059906, loss=1.8043324947357178
test: epoch 87, loss 6.78057336807251, acc=0.03333333507180214, loss=6.78057336807251
train: epoch 88, loss 1.813355803489685, acc=0.32938888669013977, loss=1.813355803489685
test: epoch 88, loss 6.815458297729492, acc=0.02777777798473835, loss=6.815458297729492
train: epoch 89, loss 1.805680513381958, acc=0.3342222273349762, loss=1.805680513381958
test: epoch 89, loss 6.585214138031006, acc=0.03055555559694767, loss=6.585214138031006
train: epoch 90, loss 1.819785714149475, acc=0.3253333270549774, loss=1.819785714149475
test: epoch 90, loss 6.418360710144043, acc=0.02777777798473835, loss=6.418360710144043
train: epoch 91, loss 1.8190335035324097, acc=0.33044445514678955, loss=1.8190335035324097
test: epoch 91, loss 6.222577095031738, acc=0.03888889029622078, loss=6.222577095031738
train: epoch 92, loss 1.8182454109191895, acc=0.3256111145019531, loss=1.8182454109191895
test: epoch 92, loss 6.447808265686035, acc=0.03055555559694767, loss=6.447808265686035
train: epoch 93, loss 1.835530161857605, acc=0.32794445753097534, loss=1.835530161857605
test: epoch 93, loss 6.2320404052734375, acc=0.02777777798473835, loss=6.2320404052734375
train: epoch 94, loss 1.8268282413482666, acc=0.31949999928474426, loss=1.8268282413482666
test: epoch 94, loss 6.3182806968688965, acc=0.02777777798473835, loss=6.3182806968688965
train: epoch 95, loss 1.8249683380126953, acc=0.3253333270549774, loss=1.8249683380126953
test: epoch 95, loss 6.25023889541626, acc=0.02500000037252903, loss=6.25023889541626
train: epoch 96, loss 1.8179999589920044, acc=0.32805556058883667, loss=1.8179999589920044
test: epoch 96, loss 6.016623497009277, acc=0.03055555559694767, loss=6.016623497009277
train: epoch 97, loss 1.8325412273406982, acc=0.32466667890548706, loss=1.8325412273406982
test: epoch 97, loss 6.152874946594238, acc=0.03055555559694767, loss=6.152874946594238
train: epoch 98, loss 1.849581241607666, acc=0.3227222263813019, loss=1.849581241607666
test: epoch 98, loss 6.183726787567139, acc=0.03333333507180214, loss=6.183726787567139
train: epoch 99, loss 1.8471441268920898, acc=0.3258333206176758, loss=1.8471441268920898
test: epoch 99, loss 5.833921432495117, acc=0.03888889029622078, loss=5.833921432495117
train: epoch 100, loss 1.8316845893859863, acc=0.3237222135066986, loss=1.8316845893859863
test: epoch 100, loss 6.20634651184082, acc=0.03055555559694767, loss=6.20634651184082
train: epoch 101, loss 1.8722786903381348, acc=0.31522223353385925, loss=1.8722786903381348
test: epoch 101, loss 5.859649181365967, acc=0.03055555559694767, loss=5.859649181365967
train: epoch 102, loss 1.847367286682129, acc=0.3191666603088379, loss=1.847367286682129
test: epoch 102, loss 5.873795509338379, acc=0.03055555559694767, loss=5.873795509338379
train: epoch 103, loss 1.858156681060791, acc=0.31761109828948975, loss=1.858156681060791
test: epoch 103, loss 5.805454730987549, acc=0.02777777798473835, loss=5.805454730987549
train: epoch 104, loss 1.8479561805725098, acc=0.3175555467605591, loss=1.8479561805725098
test: epoch 104, loss 5.914193630218506, acc=0.03611111268401146, loss=5.914193630218506
train: epoch 105, loss 1.8703562021255493, acc=0.3149999976158142, loss=1.8703562021255493
test: epoch 105, loss 5.8356757164001465, acc=0.02777777798473835, loss=5.8356757164001465
train: epoch 106, loss 1.862023115158081, acc=0.3141111135482788, loss=1.862023115158081
test: epoch 106, loss 5.4799113273620605, acc=0.03611111268401146, loss=5.4799113273620605
train: epoch 107, loss 1.852864384651184, acc=0.3179999887943268, loss=1.852864384651184
test: epoch 107, loss 5.617301940917969, acc=0.03333333507180214, loss=5.617301940917969
train: epoch 108, loss 1.8809682130813599, acc=0.3114444315433502, loss=1.8809682130813599
test: epoch 108, loss 5.272018909454346, acc=0.02777777798473835, loss=5.272018909454346
train: epoch 109, loss 1.8982619047164917, acc=0.3093888759613037, loss=1.8982619047164917
test: epoch 109, loss 5.1391921043396, acc=0.03611111268401146, loss=5.1391921043396
train: epoch 110, loss 1.8618112802505493, acc=0.3158888816833496, loss=1.8618112802505493
test: epoch 110, loss 5.3946919441223145, acc=0.03055555559694767, loss=5.3946919441223145
train: epoch 111, loss 1.8889254331588745, acc=0.3102777898311615, loss=1.8889254331588745
test: epoch 111, loss 5.375736236572266, acc=0.03333333507180214, loss=5.375736236572266
train: epoch 112, loss 1.8776394128799438, acc=0.3132222294807434, loss=1.8776394128799438
test: epoch 112, loss 5.084261417388916, acc=0.04444444552063942, loss=5.084261417388916
train: epoch 113, loss 1.882417917251587, acc=0.3143889009952545, loss=1.882417917251587
test: epoch 113, loss 5.183669567108154, acc=0.02500000037252903, loss=5.183669567108154
train: epoch 114, loss 1.8965425491333008, acc=0.30427777767181396, loss=1.8965425491333008
test: epoch 114, loss 5.012392520904541, acc=0.03055555559694767, loss=5.012392520904541
train: epoch 115, loss 1.8718494176864624, acc=0.304833322763443, loss=1.8718494176864624
test: epoch 115, loss 5.0486369132995605, acc=0.03055555559694767, loss=5.0486369132995605
train: epoch 116, loss 1.8796480894088745, acc=0.3017222285270691, loss=1.8796480894088745
test: epoch 116, loss 5.031538486480713, acc=0.0416666679084301, loss=5.031538486480713
train: epoch 117, loss 1.8954397439956665, acc=0.3092777729034424, loss=1.8954397439956665
test: epoch 117, loss 5.095852375030518, acc=0.02777777798473835, loss=5.095852375030518
train: epoch 118, loss 1.890875220298767, acc=0.3070555627346039, loss=1.890875220298767
test: epoch 118, loss 4.915064334869385, acc=0.03333333507180214, loss=4.915064334869385
train: epoch 119, loss 1.9014185667037964, acc=0.30088889598846436, loss=1.9014185667037964
test: epoch 119, loss 4.910823822021484, acc=0.03888889029622078, loss=4.910823822021484
train: epoch 120, loss 1.884879231452942, acc=0.3037777841091156, loss=1.884879231452942
test: epoch 120, loss 5.004135608673096, acc=0.06111111119389534, loss=5.004135608673096
train: epoch 121, loss 1.9005078077316284, acc=0.30250000953674316, loss=1.9005078077316284
test: epoch 121, loss 5.042717933654785, acc=0.04722222313284874, loss=5.042717933654785
train: epoch 122, loss 1.8979299068450928, acc=0.30161112546920776, loss=1.8979299068450928
test: epoch 122, loss 4.895925521850586, acc=0.03888889029622078, loss=4.895925521850586
train: epoch 123, loss 1.9007766246795654, acc=0.29605555534362793, loss=1.9007766246795654
test: epoch 123, loss 4.878798961639404, acc=0.03888889029622078, loss=4.878798961639404
train: epoch 124, loss 1.9325834512710571, acc=0.29411110281944275, loss=1.9325834512710571
test: epoch 124, loss 4.812023162841797, acc=0.03888889029622078, loss=4.812023162841797
train: epoch 125, loss 1.9124548435211182, acc=0.3000555634498596, loss=1.9124548435211182
test: epoch 125, loss 4.959196090698242, acc=0.03333333507180214, loss=4.959196090698242
train: epoch 126, loss 1.9162620306015015, acc=0.2944999933242798, loss=1.9162620306015015
test: epoch 126, loss 4.577121734619141, acc=0.03888889029622078, loss=4.577121734619141
train: epoch 127, loss 1.9229576587677002, acc=0.2844444513320923, loss=1.9229576587677002
test: epoch 127, loss 4.555398464202881, acc=0.03611111268401146, loss=4.555398464202881
train: epoch 128, loss 1.9375073909759521, acc=0.28777778148651123, loss=1.9375073909759521
test: epoch 128, loss 4.6016435623168945, acc=0.03611111268401146, loss=4.6016435623168945
train: epoch 129, loss 1.9305284023284912, acc=0.29233333468437195, loss=1.9305284023284912
test: epoch 129, loss 4.546266555786133, acc=0.04444444552063942, loss=4.546266555786133
train: epoch 130, loss 1.9245805740356445, acc=0.2956666648387909, loss=1.9245805740356445
test: epoch 130, loss 4.458885192871094, acc=0.04444444552063942, loss=4.458885192871094
train: epoch 131, loss 1.9459675550460815, acc=0.29383334517478943, loss=1.9459675550460815
test: epoch 131, loss 4.642683982849121, acc=0.03333333507180214, loss=4.642683982849121
train: epoch 132, loss 1.9508744478225708, acc=0.2887222170829773, loss=1.9508744478225708
test: epoch 132, loss 4.644972801208496, acc=0.03888889029622078, loss=4.644972801208496
train: epoch 133, loss 1.9618592262268066, acc=0.2925555408000946, loss=1.9618592262268066
test: epoch 133, loss 4.530149936676025, acc=0.05833333358168602, loss=4.530149936676025
train: epoch 134, loss 1.9418939352035522, acc=0.29072222113609314, loss=1.9418939352035522
test: epoch 134, loss 4.335569381713867, acc=0.05833333358168602, loss=4.335569381713867
train: epoch 135, loss 1.9759361743927002, acc=0.28522223234176636, loss=1.9759361743927002
test: epoch 135, loss 4.115969657897949, acc=0.06388889253139496, loss=4.115969657897949
train: epoch 136, loss 1.9682047367095947, acc=0.2809999883174896, loss=1.9682047367095947
test: epoch 136, loss 4.104551315307617, acc=0.05277777835726738, loss=4.104551315307617
train: epoch 137, loss 1.960045337677002, acc=0.285055547952652, loss=1.960045337677002
test: epoch 137, loss 4.118420124053955, acc=0.05277777835726738, loss=4.118420124053955
train: epoch 138, loss 1.9665013551712036, acc=0.2808888852596283, loss=1.9665013551712036
test: epoch 138, loss 4.02249813079834, acc=0.04444444552063942, loss=4.02249813079834
train: epoch 139, loss 1.9883053302764893, acc=0.28038889169692993, loss=1.9883053302764893
test: epoch 139, loss 4.071839332580566, acc=0.0694444477558136, loss=4.071839332580566
train: epoch 140, loss 1.992874264717102, acc=0.27816668152809143, loss=1.992874264717102
test: epoch 140, loss 4.163358688354492, acc=0.05277777835726738, loss=4.163358688354492
train: epoch 141, loss 1.9527394771575928, acc=0.2841666638851166, loss=1.9527394771575928
test: epoch 141, loss 4.196534633636475, acc=0.05000000074505806, loss=4.196534633636475
train: epoch 142, loss 1.9793695211410522, acc=0.28138887882232666, loss=1.9793695211410522
test: epoch 142, loss 4.050129413604736, acc=0.04722222313284874, loss=4.050129413604736
train: epoch 143, loss 1.9838922023773193, acc=0.2781111001968384, loss=1.9838922023773193
test: epoch 143, loss 3.969740629196167, acc=0.05000000074505806, loss=3.969740629196167
train: epoch 144, loss 2.0037808418273926, acc=0.277055561542511, loss=2.0037808418273926
test: epoch 144, loss 4.187093257904053, acc=0.04722222313284874, loss=4.187093257904053
train: epoch 145, loss 1.9739669561386108, acc=0.2755555510520935, loss=1.9739669561386108
test: epoch 145, loss 4.0593438148498535, acc=0.05000000074505806, loss=4.0593438148498535
train: epoch 146, loss 1.985337257385254, acc=0.2779444456100464, loss=1.985337257385254
test: epoch 146, loss 3.9775795936584473, acc=0.05000000074505806, loss=3.9775795936584473
train: epoch 147, loss 1.9860810041427612, acc=0.27783334255218506, loss=1.9860810041427612
test: epoch 147, loss 3.9850974082946777, acc=0.05000000074505806, loss=3.9850974082946777
train: epoch 148, loss 2.0019359588623047, acc=0.273333340883255, loss=2.0019359588623047
test: epoch 148, loss 3.825239896774292, acc=0.0555555559694767, loss=3.825239896774292
train: epoch 149, loss 2.0026144981384277, acc=0.26777777075767517, loss=2.0026144981384277
test: epoch 149, loss 3.825885057449341, acc=0.04722222313284874, loss=3.825885057449341
train: epoch 150, loss 1.9931001663208008, acc=0.2786666750907898, loss=1.9931001663208008
test: epoch 150, loss 3.8093090057373047, acc=0.05277777835726738, loss=3.8093090057373047
