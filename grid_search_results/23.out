# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1.5", "--temp_decay=1", "--one_hot=false", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=2085638780, receiver_embed_dim=32, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.014627695083618, acc=0.07450000196695328, loss=3.014627695083618
test: epoch 1, loss 3.1510233879089355, acc=0.09444444626569748, loss=3.1510233879089355
train: epoch 2, loss 2.0843710899353027, acc=0.1919444501399994, loss=2.0843710899353027
test: epoch 2, loss 2.8336899280548096, acc=0.15000000596046448, loss=2.8336899280548096
train: epoch 3, loss 1.7650096416473389, acc=0.2573888897895813, loss=1.7650096416473389
test: epoch 3, loss 2.3042800426483154, acc=0.21944443881511688, loss=2.3042800426483154
train: epoch 4, loss 1.587788701057434, acc=0.3095000088214874, loss=1.587788701057434
test: epoch 4, loss 2.7221121788024902, acc=0.19166666269302368, loss=2.7221121788024902
train: epoch 5, loss 1.4815846681594849, acc=0.34761109948158264, loss=1.4815846681594849
test: epoch 5, loss 2.473062515258789, acc=0.2222222238779068, loss=2.473062515258789
train: epoch 6, loss 1.3404351472854614, acc=0.4035555422306061, loss=1.3404351472854614
test: epoch 6, loss 2.1610019207000732, acc=0.23333333432674408, loss=2.1610019207000732
train: epoch 7, loss 1.2953578233718872, acc=0.42188888788223267, loss=1.2953578233718872
test: epoch 7, loss 2.1922333240509033, acc=0.2527777850627899, loss=2.1922333240509033
train: epoch 8, loss 1.2024928331375122, acc=0.46238890290260315, loss=1.2024928331375122
test: epoch 8, loss 2.4457736015319824, acc=0.2611111104488373, loss=2.4457736015319824
train: epoch 9, loss 1.1446480751037598, acc=0.49016666412353516, loss=1.1446480751037598
test: epoch 9, loss 2.0851409435272217, acc=0.2944444417953491, loss=2.0851409435272217
train: epoch 10, loss 1.1192797422409058, acc=0.496444433927536, loss=1.1192797422409058
test: epoch 10, loss 2.0801336765289307, acc=0.3222222328186035, loss=2.0801336765289307
train: epoch 11, loss 1.0360465049743652, acc=0.5291110873222351, loss=1.0360465049743652
test: epoch 11, loss 1.7948559522628784, acc=0.3583333194255829, loss=1.7948559522628784
train: epoch 12, loss 1.02839195728302, acc=0.5438888669013977, loss=1.02839195728302
test: epoch 12, loss 1.916703462600708, acc=0.32777777314186096, loss=1.916703462600708
train: epoch 13, loss 0.9629412889480591, acc=0.5762777924537659, loss=0.9629412889480591
test: epoch 13, loss 2.0039026737213135, acc=0.3638888895511627, loss=2.0039026737213135
train: epoch 14, loss 0.9683014154434204, acc=0.5801666378974915, loss=0.9683014154434204
test: epoch 14, loss 2.0545706748962402, acc=0.3305555582046509, loss=2.0545706748962402
train: epoch 15, loss 0.8797820806503296, acc=0.6132222414016724, loss=0.8797820806503296
test: epoch 15, loss 1.600846767425537, acc=0.3777777850627899, loss=1.600846767425537
train: epoch 16, loss 0.8973984122276306, acc=0.6125555634498596, loss=0.8973984122276306
test: epoch 16, loss 1.5233961343765259, acc=0.4166666567325592, loss=1.5233961343765259
train: epoch 17, loss 0.7977462410926819, acc=0.6590555310249329, loss=0.7977462410926819
test: epoch 17, loss 1.9079712629318237, acc=0.36944442987442017, loss=1.9079712629318237
train: epoch 18, loss 0.8148466944694519, acc=0.6507777571678162, loss=0.8148466944694519
test: epoch 18, loss 2.0536048412323, acc=0.3472222089767456, loss=2.0536048412323
train: epoch 19, loss 0.7169085144996643, acc=0.7033888697624207, loss=0.7169085144996643
test: epoch 19, loss 1.7030032873153687, acc=0.35555556416511536, loss=1.7030032873153687
train: epoch 20, loss 0.6596285104751587, acc=0.7314444184303284, loss=0.6596285104751587
test: epoch 20, loss 1.9740241765975952, acc=0.3861111104488373, loss=1.9740241765975952
train: epoch 21, loss 0.5829218626022339, acc=0.7635555267333984, loss=0.5829218626022339
test: epoch 21, loss 1.889611840248108, acc=0.41111111640930176, loss=1.889611840248108
train: epoch 22, loss 0.5679646730422974, acc=0.7700555324554443, loss=0.5679646730422974
test: epoch 22, loss 1.9927502870559692, acc=0.4138889014720917, loss=1.9927502870559692
train: epoch 23, loss 0.5180187225341797, acc=0.7901666760444641, loss=0.5180187225341797
test: epoch 23, loss 1.8062831163406372, acc=0.4166666567325592, loss=1.8062831163406372
train: epoch 24, loss 0.5164933204650879, acc=0.7903888821601868, loss=0.5164933204650879
test: epoch 24, loss 1.6674779653549194, acc=0.4833333194255829, loss=1.6674779653549194
train: epoch 25, loss 0.4756886661052704, acc=0.8081666827201843, loss=0.4756886661052704
test: epoch 25, loss 1.394631028175354, acc=0.4722222089767456, loss=1.394631028175354
train: epoch 26, loss 0.47177818417549133, acc=0.8040555715560913, loss=0.47177818417549133
test: epoch 26, loss 1.2660613059997559, acc=0.5138888955116272, loss=1.2660613059997559
train: epoch 27, loss 0.45457690954208374, acc=0.8122777938842773, loss=0.45457690954208374
test: epoch 27, loss 1.4622251987457275, acc=0.519444465637207, loss=1.4622251987457275
train: epoch 28, loss 0.4334847629070282, acc=0.8186666369438171, loss=0.4334847629070282
test: epoch 28, loss 1.4965189695358276, acc=0.5388888716697693, loss=1.4965189695358276
train: epoch 29, loss 0.398110955953598, acc=0.8363333344459534, loss=0.398110955953598
test: epoch 29, loss 1.8572036027908325, acc=0.5138888955116272, loss=1.8572036027908325
train: epoch 30, loss 0.4363630712032318, acc=0.8238333463668823, loss=0.4363630712032318
test: epoch 30, loss 1.6465871334075928, acc=0.49444442987442017, loss=1.6465871334075928
train: epoch 31, loss 0.40372970700263977, acc=0.8383888602256775, loss=0.40372970700263977
test: epoch 31, loss 1.2336145639419556, acc=0.5805555582046509, loss=1.2336145639419556
train: epoch 32, loss 0.37050122022628784, acc=0.8498333096504211, loss=0.37050122022628784
test: epoch 32, loss 1.3105524778366089, acc=0.5805555582046509, loss=1.3105524778366089
train: epoch 33, loss 0.34914496541023254, acc=0.856166660785675, loss=0.34914496541023254
test: epoch 33, loss 1.4057135581970215, acc=0.5111111402511597, loss=1.4057135581970215
train: epoch 34, loss 0.36951887607574463, acc=0.8516111373901367, loss=0.36951887607574463
test: epoch 34, loss 1.4321236610412598, acc=0.5444444417953491, loss=1.4321236610412598
train: epoch 35, loss 0.31002703309059143, acc=0.8726111054420471, loss=0.31002703309059143
test: epoch 35, loss 1.4290071725845337, acc=0.5972222089767456, loss=1.4290071725845337
train: epoch 36, loss 0.3109970986843109, acc=0.8730000257492065, loss=0.3109970986843109
test: epoch 36, loss 1.522652506828308, acc=0.5972222089767456, loss=1.522652506828308
train: epoch 37, loss 0.317607581615448, acc=0.8698889017105103, loss=0.317607581615448
test: epoch 37, loss 1.3945865631103516, acc=0.5722222328186035, loss=1.3945865631103516
train: epoch 38, loss 0.27738481760025024, acc=0.8820000290870667, loss=0.27738481760025024
test: epoch 38, loss 1.405705213546753, acc=0.6277777552604675, loss=1.405705213546753
train: epoch 39, loss 0.2870957553386688, acc=0.878777801990509, loss=0.2870957553386688
test: epoch 39, loss 1.4710452556610107, acc=0.5888888835906982, loss=1.4710452556610107
train: epoch 40, loss 0.2884159982204437, acc=0.8772777915000916, loss=0.2884159982204437
test: epoch 40, loss 1.1959950923919678, acc=0.5472221970558167, loss=1.1959950923919678
train: epoch 41, loss 0.2894139587879181, acc=0.8799444437026978, loss=0.2894139587879181
test: epoch 41, loss 1.367080569267273, acc=0.5805555582046509, loss=1.367080569267273
train: epoch 42, loss 0.2908274531364441, acc=0.8787222504615784, loss=0.2908274531364441
test: epoch 42, loss 1.3639816045761108, acc=0.605555534362793, loss=1.3639816045761108
train: epoch 43, loss 0.2895359992980957, acc=0.8803333044052124, loss=0.2895359992980957
test: epoch 43, loss 1.4086613655090332, acc=0.5888888835906982, loss=1.4086613655090332
train: epoch 44, loss 0.26948150992393494, acc=0.8845000267028809, loss=0.26948150992393494
test: epoch 44, loss 1.0440441370010376, acc=0.6111111044883728, loss=1.0440441370010376
train: epoch 45, loss 0.2717628479003906, acc=0.8834999799728394, loss=0.2717628479003906
test: epoch 45, loss 0.9718083739280701, acc=0.6305555701255798, loss=0.9718083739280701
train: epoch 46, loss 0.2911231815814972, acc=0.8786110877990723, loss=0.2911231815814972
test: epoch 46, loss 1.1917915344238281, acc=0.6083333492279053, loss=1.1917915344238281
train: epoch 47, loss 0.2740515470504761, acc=0.8834444284439087, loss=0.2740515470504761
test: epoch 47, loss 1.1931138038635254, acc=0.6222222447395325, loss=1.1931138038635254
train: epoch 48, loss 0.2572080194950104, acc=0.8886666893959045, loss=0.2572080194950104
test: epoch 48, loss 1.0425282716751099, acc=0.644444465637207, loss=1.0425282716751099
train: epoch 49, loss 0.2372872680425644, acc=0.8957777619361877, loss=0.2372872680425644
test: epoch 49, loss 1.3704540729522705, acc=0.5666666626930237, loss=1.3704540729522705
train: epoch 50, loss 0.25283074378967285, acc=0.8904444575309753, loss=0.25283074378967285
test: epoch 50, loss 1.2701671123504639, acc=0.6361111402511597, loss=1.2701671123504639
train: epoch 51, loss 0.25701242685317993, acc=0.8907222151756287, loss=0.25701242685317993
test: epoch 51, loss 1.0443589687347412, acc=0.6666666865348816, loss=1.0443589687347412
train: epoch 52, loss 0.2334337830543518, acc=0.8967221975326538, loss=0.2334337830543518
test: epoch 52, loss 1.0542525053024292, acc=0.6361111402511597, loss=1.0542525053024292
train: epoch 53, loss 0.24405260384082794, acc=0.8911111354827881, loss=0.24405260384082794
test: epoch 53, loss 1.1542469263076782, acc=0.6888889074325562, loss=1.1542469263076782
train: epoch 54, loss 0.24017436802387238, acc=0.8933333158493042, loss=0.24017436802387238
test: epoch 54, loss 1.0787429809570312, acc=0.6499999761581421, loss=1.0787429809570312
train: epoch 55, loss 0.23689308762550354, acc=0.8943889141082764, loss=0.23689308762550354
test: epoch 55, loss 1.082763910293579, acc=0.6361111402511597, loss=1.082763910293579
train: epoch 56, loss 0.219463050365448, acc=0.9008888602256775, loss=0.219463050365448
test: epoch 56, loss 1.310655117034912, acc=0.5944444537162781, loss=1.310655117034912
train: epoch 57, loss 0.20106291770935059, acc=0.9065555334091187, loss=0.20106291770935059
test: epoch 57, loss 1.1144347190856934, acc=0.6888889074325562, loss=1.1144347190856934
train: epoch 58, loss 0.22960567474365234, acc=0.8997222185134888, loss=0.22960567474365234
test: epoch 58, loss 0.8821201920509338, acc=0.7333333492279053, loss=0.8821201920509338
train: epoch 59, loss 0.21640267968177795, acc=0.901888906955719, loss=0.21640267968177795
test: epoch 59, loss 1.0888885259628296, acc=0.6972222328186035, loss=1.0888885259628296
train: epoch 60, loss 0.2295660674571991, acc=0.8989444375038147, loss=0.2295660674571991
test: epoch 60, loss 1.0696618556976318, acc=0.730555534362793, loss=1.0696618556976318
train: epoch 61, loss 0.22507470846176147, acc=0.8995555639266968, loss=0.22507470846176147
test: epoch 61, loss 0.8907778859138489, acc=0.7333333492279053, loss=0.8907778859138489
train: epoch 62, loss 0.206148162484169, acc=0.9046666622161865, loss=0.206148162484169
test: epoch 62, loss 0.9452457427978516, acc=0.7083333134651184, loss=0.9452457427978516
train: epoch 63, loss 0.19827555119991302, acc=0.9089444279670715, loss=0.19827555119991302
test: epoch 63, loss 0.864952027797699, acc=0.7472222447395325, loss=0.864952027797699
train: epoch 64, loss 0.23767583072185516, acc=0.8970555663108826, loss=0.23767583072185516
test: epoch 64, loss 0.7560312151908875, acc=0.75, loss=0.7560312151908875
train: epoch 65, loss 0.19732677936553955, acc=0.9076111316680908, loss=0.19732677936553955
test: epoch 65, loss 0.6165114045143127, acc=0.7722222208976746, loss=0.6165114045143127
train: epoch 66, loss 0.193100705742836, acc=0.9099444150924683, loss=0.193100705742836
test: epoch 66, loss 1.091830849647522, acc=0.7416666746139526, loss=1.091830849647522
train: epoch 67, loss 0.22040249407291412, acc=0.9018333554267883, loss=0.22040249407291412
test: epoch 67, loss 0.7316296100616455, acc=0.7555555701255798, loss=0.7316296100616455
train: epoch 68, loss 0.19498887658119202, acc=0.9086666703224182, loss=0.19498887658119202
test: epoch 68, loss 1.1339900493621826, acc=0.7333333492279053, loss=1.1339900493621826
train: epoch 69, loss 0.21510548889636993, acc=0.9026666879653931, loss=0.21510548889636993
test: epoch 69, loss 0.7213431000709534, acc=0.7555555701255798, loss=0.7213431000709534
train: epoch 70, loss 0.2102661430835724, acc=0.9040555357933044, loss=0.2102661430835724
test: epoch 70, loss 0.7236632704734802, acc=0.7749999761581421, loss=0.7236632704734802
train: epoch 71, loss 0.1907041072845459, acc=0.9085555672645569, loss=0.1907041072845459
test: epoch 71, loss 0.9317134022712708, acc=0.7416666746139526, loss=0.9317134022712708
train: epoch 72, loss 0.19029706716537476, acc=0.9110555648803711, loss=0.19029706716537476
test: epoch 72, loss 0.6851464509963989, acc=0.7916666865348816, loss=0.6851464509963989
train: epoch 73, loss 0.19850081205368042, acc=0.9091110825538635, loss=0.19850081205368042
test: epoch 73, loss 0.7798134684562683, acc=0.769444465637207, loss=0.7798134684562683
train: epoch 74, loss 0.19836241006851196, acc=0.9073888659477234, loss=0.19836241006851196
test: epoch 74, loss 0.5804658532142639, acc=0.7861111164093018, loss=0.5804658532142639
train: epoch 75, loss 0.18758022785186768, acc=0.9120000004768372, loss=0.18758022785186768
test: epoch 75, loss 0.8018324375152588, acc=0.7722222208976746, loss=0.8018324375152588
train: epoch 76, loss 0.1939319521188736, acc=0.9118333458900452, loss=0.1939319521188736
test: epoch 76, loss 0.8009214997291565, acc=0.7555555701255798, loss=0.8009214997291565
train: epoch 77, loss 0.20296290516853333, acc=0.9190555810928345, loss=0.20296290516853333
test: epoch 77, loss 0.7388095855712891, acc=0.7666666507720947, loss=0.7388095855712891
train: epoch 78, loss 0.15554450452327728, acc=0.9433333277702332, loss=0.15554450452327728
test: epoch 78, loss 0.7120289206504822, acc=0.7944444417953491, loss=0.7120289206504822
train: epoch 79, loss 0.1263672262430191, acc=0.9514999985694885, loss=0.1263672262430191
test: epoch 79, loss 0.766959547996521, acc=0.7916666865348816, loss=0.766959547996521
train: epoch 80, loss 0.1152115985751152, acc=0.9576666951179504, loss=0.1152115985751152
test: epoch 80, loss 0.872067391872406, acc=0.7666666507720947, loss=0.872067391872406
train: epoch 81, loss 0.1359325498342514, acc=0.9522222280502319, loss=0.1359325498342514
test: epoch 81, loss 0.8045302033424377, acc=0.7472222447395325, loss=0.8045302033424377
train: epoch 82, loss 0.14806368947029114, acc=0.9462222456932068, loss=0.14806368947029114
test: epoch 82, loss 0.8837203979492188, acc=0.7944444417953491, loss=0.8837203979492188
train: epoch 83, loss 0.11661121994256973, acc=0.9549999833106995, loss=0.11661121994256973
test: epoch 83, loss 1.058727502822876, acc=0.7805555462837219, loss=1.058727502822876
train: epoch 84, loss 0.12905751168727875, acc=0.9508333206176758, loss=0.12905751168727875
test: epoch 84, loss 0.8037799000740051, acc=0.7749999761581421, loss=0.8037799000740051
train: epoch 85, loss 0.11564365774393082, acc=0.9556666612625122, loss=0.11564365774393082
test: epoch 85, loss 0.7591333985328674, acc=0.7861111164093018, loss=0.7591333985328674
train: epoch 86, loss 0.12439510971307755, acc=0.952833354473114, loss=0.12439510971307755
test: epoch 86, loss 1.0509647130966187, acc=0.7749999761581421, loss=1.0509647130966187
train: epoch 87, loss 0.13074494898319244, acc=0.9493333101272583, loss=0.13074494898319244
test: epoch 87, loss 0.8098456859588623, acc=0.7944444417953491, loss=0.8098456859588623
train: epoch 88, loss 0.09856828302145004, acc=0.9587777853012085, loss=0.09856828302145004
test: epoch 88, loss 0.8673029541969299, acc=0.7916666865348816, loss=0.8673029541969299
train: epoch 89, loss 0.1227552518248558, acc=0.9537222385406494, loss=0.1227552518248558
test: epoch 89, loss 0.8029044270515442, acc=0.769444465637207, loss=0.8029044270515442
train: epoch 90, loss 0.12353789806365967, acc=0.9539444446563721, loss=0.12353789806365967
test: epoch 90, loss 1.1676105260849, acc=0.7638888955116272, loss=1.1676105260849
train: epoch 91, loss 0.13566753268241882, acc=0.9510555267333984, loss=0.13566753268241882
test: epoch 91, loss 0.6997880339622498, acc=0.7861111164093018, loss=0.6997880339622498
train: epoch 92, loss 0.10199358314275742, acc=0.9584444165229797, loss=0.10199358314275742
test: epoch 92, loss 0.7356836199760437, acc=0.7888888716697693, loss=0.7356836199760437
train: epoch 93, loss 0.13235469162464142, acc=0.9475555419921875, loss=0.13235469162464142
test: epoch 93, loss 0.9927902221679688, acc=0.7722222208976746, loss=0.9927902221679688
train: epoch 94, loss 0.11272795498371124, acc=0.9514444470405579, loss=0.11272795498371124
test: epoch 94, loss 0.8462895750999451, acc=0.7916666865348816, loss=0.8462895750999451
train: epoch 95, loss 0.12961547076702118, acc=0.9470555782318115, loss=0.12961547076702118
test: epoch 95, loss 0.9054869413375854, acc=0.7777777910232544, loss=0.9054869413375854
train: epoch 96, loss 0.10368111729621887, acc=0.9581111073493958, loss=0.10368111729621887
test: epoch 96, loss 0.7969829440116882, acc=0.7944444417953491, loss=0.7969829440116882
train: epoch 97, loss 0.10966137796640396, acc=0.9552222490310669, loss=0.10966137796640396
test: epoch 97, loss 0.7084982991218567, acc=0.8222222328186035, loss=0.7084982991218567
train: epoch 98, loss 0.12039854377508163, acc=0.952833354473114, loss=0.12039854377508163
test: epoch 98, loss 0.7382527589797974, acc=0.7916666865348816, loss=0.7382527589797974
train: epoch 99, loss 0.11374286562204361, acc=0.9562777876853943, loss=0.11374286562204361
test: epoch 99, loss 0.9411990642547607, acc=0.7722222208976746, loss=0.9411990642547607
train: epoch 100, loss 0.10469364374876022, acc=0.960444450378418, loss=0.10469364374876022
test: epoch 100, loss 0.9334401488304138, acc=0.7888888716697693, loss=0.9334401488304138
train: epoch 101, loss 0.1281374990940094, acc=0.9526666402816772, loss=0.1281374990940094
test: epoch 101, loss 0.9003756642341614, acc=0.7888888716697693, loss=0.9003756642341614
train: epoch 102, loss 0.11113068461418152, acc=0.9570000171661377, loss=0.11113068461418152
test: epoch 102, loss 0.7378574013710022, acc=0.800000011920929, loss=0.7378574013710022
train: epoch 103, loss 0.10173594206571579, acc=0.9599444270133972, loss=0.10173594206571579
test: epoch 103, loss 1.2656272649765015, acc=0.730555534362793, loss=1.2656272649765015
train: epoch 104, loss 0.11521292477846146, acc=0.957611083984375, loss=0.11521292477846146
test: epoch 104, loss 0.6421043276786804, acc=0.800000011920929, loss=0.6421043276786804
train: epoch 105, loss 0.1147640123963356, acc=0.9573888778686523, loss=0.1147640123963356
test: epoch 105, loss 0.6659539937973022, acc=0.7805555462837219, loss=0.6659539937973022
train: epoch 106, loss 0.092345230281353, acc=0.9642778038978577, loss=0.092345230281353
test: epoch 106, loss 0.9248060584068298, acc=0.7583333253860474, loss=0.9248060584068298
train: epoch 107, loss 0.09869594871997833, acc=0.9631111025810242, loss=0.09869594871997833
test: epoch 107, loss 0.8432506918907166, acc=0.7805555462837219, loss=0.8432506918907166
train: epoch 108, loss 0.11650818586349487, acc=0.9562777876853943, loss=0.11650818586349487
test: epoch 108, loss 0.7136737704277039, acc=0.7861111164093018, loss=0.7136737704277039
train: epoch 109, loss 0.1101958304643631, acc=0.9588888883590698, loss=0.1101958304643631
test: epoch 109, loss 0.6771589517593384, acc=0.7749999761581421, loss=0.6771589517593384
train: epoch 110, loss 0.11123127490282059, acc=0.9586666822433472, loss=0.11123127490282059
test: epoch 110, loss 0.6308267712593079, acc=0.7944444417953491, loss=0.6308267712593079
train: epoch 111, loss 0.10018567740917206, acc=0.9608888626098633, loss=0.10018567740917206
test: epoch 111, loss 0.8598513603210449, acc=0.7861111164093018, loss=0.8598513603210449
train: epoch 112, loss 0.10036882013082504, acc=0.9586666822433472, loss=0.10036882013082504
test: epoch 112, loss 0.9181603789329529, acc=0.800000011920929, loss=0.9181603789329529
train: epoch 113, loss 0.10466843098402023, acc=0.9596666693687439, loss=0.10466843098402023
test: epoch 113, loss 0.7616580724716187, acc=0.7944444417953491, loss=0.7616580724716187
train: epoch 114, loss 0.11361340433359146, acc=0.9559999704360962, loss=0.11361340433359146
test: epoch 114, loss 0.8456649780273438, acc=0.7944444417953491, loss=0.8456649780273438
train: epoch 115, loss 0.10758263617753983, acc=0.9580555558204651, loss=0.10758263617753983
test: epoch 115, loss 0.830170214176178, acc=0.7944444417953491, loss=0.830170214176178
train: epoch 116, loss 0.1034371629357338, acc=0.9588888883590698, loss=0.1034371629357338
test: epoch 116, loss 0.6468790173530579, acc=0.8222222328186035, loss=0.6468790173530579
train: epoch 117, loss 0.09148143231868744, acc=0.9635555744171143, loss=0.09148143231868744
test: epoch 117, loss 0.761385440826416, acc=0.7972221970558167, loss=0.761385440826416
train: epoch 118, loss 0.12311696261167526, acc=0.9552222490310669, loss=0.12311696261167526
test: epoch 118, loss 0.8288467526435852, acc=0.7722222208976746, loss=0.8288467526435852
train: epoch 119, loss 0.09011135995388031, acc=0.9643333554267883, loss=0.09011135995388031
test: epoch 119, loss 0.6822986006736755, acc=0.8111110925674438, loss=0.6822986006736755
train: epoch 120, loss 0.10275918990373611, acc=0.9601666927337646, loss=0.10275918990373611
test: epoch 120, loss 0.7476934790611267, acc=0.7888888716697693, loss=0.7476934790611267
train: epoch 121, loss 0.11398482322692871, acc=0.9559999704360962, loss=0.11398482322692871
test: epoch 121, loss 0.5962656140327454, acc=0.8027777671813965, loss=0.5962656140327454
train: epoch 122, loss 0.13132578134536743, acc=0.9520000219345093, loss=0.13132578134536743
test: epoch 122, loss 0.66509610414505, acc=0.7833333611488342, loss=0.66509610414505
train: epoch 123, loss 0.09489960968494415, acc=0.9627222418785095, loss=0.09489960968494415
test: epoch 123, loss 0.8180292844772339, acc=0.7861111164093018, loss=0.8180292844772339
train: epoch 124, loss 0.08064223825931549, acc=0.9667778015136719, loss=0.08064223825931549
test: epoch 124, loss 1.0277150869369507, acc=0.7944444417953491, loss=1.0277150869369507
train: epoch 125, loss 0.09792699664831161, acc=0.9610000252723694, loss=0.09792699664831161
test: epoch 125, loss 0.7978729605674744, acc=0.7749999761581421, loss=0.7978729605674744
train: epoch 126, loss 0.08666759729385376, acc=0.9640555381774902, loss=0.08666759729385376
test: epoch 126, loss 0.732353925704956, acc=0.8055555820465088, loss=0.732353925704956
train: epoch 127, loss 0.10221417993307114, acc=0.9610000252723694, loss=0.10221417993307114
test: epoch 127, loss 0.7461842894554138, acc=0.769444465637207, loss=0.7461842894554138
train: epoch 128, loss 0.09873084723949432, acc=0.960444450378418, loss=0.09873084723949432
test: epoch 128, loss 0.7689929604530334, acc=0.7972221970558167, loss=0.7689929604530334
train: epoch 129, loss 0.1087552160024643, acc=0.9572222232818604, loss=0.1087552160024643
test: epoch 129, loss 0.8126417398452759, acc=0.800000011920929, loss=0.8126417398452759
train: epoch 130, loss 0.10172512382268906, acc=0.9581111073493958, loss=0.10172512382268906
test: epoch 130, loss 0.6664287447929382, acc=0.7833333611488342, loss=0.6664287447929382
train: epoch 131, loss 0.11079493165016174, acc=0.9567777514457703, loss=0.11079493165016174
test: epoch 131, loss 0.7883904576301575, acc=0.7944444417953491, loss=0.7883904576301575
train: epoch 132, loss 0.08776233345270157, acc=0.9633888602256775, loss=0.08776233345270157
test: epoch 132, loss 0.7403475642204285, acc=0.8111110925674438, loss=0.7403475642204285
train: epoch 133, loss 0.08892693370580673, acc=0.9632222056388855, loss=0.08892693370580673
test: epoch 133, loss 0.7469571828842163, acc=0.7972221970558167, loss=0.7469571828842163
train: epoch 134, loss 0.10476996004581451, acc=0.9609444737434387, loss=0.10476996004581451
test: epoch 134, loss 0.8350442051887512, acc=0.7916666865348816, loss=0.8350442051887512
train: epoch 135, loss 0.08993891626596451, acc=0.9618333578109741, loss=0.08993891626596451
test: epoch 135, loss 0.8951253294944763, acc=0.8138889074325562, loss=0.8951253294944763
train: epoch 136, loss 0.0833544060587883, acc=0.9651111364364624, loss=0.0833544060587883
test: epoch 136, loss 0.5860335826873779, acc=0.8222222328186035, loss=0.5860335826873779
train: epoch 137, loss 0.09538446366786957, acc=0.9611666798591614, loss=0.09538446366786957
test: epoch 137, loss 0.8179726600646973, acc=0.8166666626930237, loss=0.8179726600646973
train: epoch 138, loss 0.10187222063541412, acc=0.9616110920906067, loss=0.10187222063541412
test: epoch 138, loss 0.6610482931137085, acc=0.8083333373069763, loss=0.6610482931137085
train: epoch 139, loss 0.08590519428253174, acc=0.9634444713592529, loss=0.08590519428253174
test: epoch 139, loss 0.744914710521698, acc=0.7944444417953491, loss=0.744914710521698
train: epoch 140, loss 0.09442553669214249, acc=0.9624444246292114, loss=0.09442553669214249
test: epoch 140, loss 0.6871959567070007, acc=0.8305555582046509, loss=0.6871959567070007
train: epoch 141, loss 0.10076947510242462, acc=0.9601110816001892, loss=0.10076947510242462
test: epoch 141, loss 0.8120060563087463, acc=0.8083333373069763, loss=0.8120060563087463
train: epoch 142, loss 0.09237794578075409, acc=0.9610555768013, loss=0.09237794578075409
test: epoch 142, loss 0.6821543574333191, acc=0.8166666626930237, loss=0.6821543574333191
train: epoch 143, loss 0.09453185647726059, acc=0.9625555276870728, loss=0.09453185647726059
test: epoch 143, loss 0.7309385538101196, acc=0.8138889074325562, loss=0.7309385538101196
train: epoch 144, loss 0.09485522657632828, acc=0.9634444713592529, loss=0.09485522657632828
test: epoch 144, loss 0.7317703366279602, acc=0.7861111164093018, loss=0.7317703366279602
train: epoch 145, loss 0.10126261413097382, acc=0.9607222080230713, loss=0.10126261413097382
test: epoch 145, loss 0.5821983814239502, acc=0.8277778029441833, loss=0.5821983814239502
train: epoch 146, loss 0.0816621333360672, acc=0.9653333425521851, loss=0.0816621333360672
test: epoch 146, loss 0.5680254697799683, acc=0.8083333373069763, loss=0.5680254697799683
train: epoch 147, loss 0.08289176225662231, acc=0.9656111001968384, loss=0.08289176225662231
test: epoch 147, loss 0.9328701496124268, acc=0.7944444417953491, loss=0.9328701496124268
train: epoch 148, loss 0.11298874020576477, acc=0.9595000147819519, loss=0.11298874020576477
test: epoch 148, loss 0.6963587403297424, acc=0.8194444179534912, loss=0.6963587403297424
train: epoch 149, loss 0.07438275963068008, acc=0.9669444561004639, loss=0.07438275963068008
test: epoch 149, loss 0.8596718311309814, acc=0.8166666626930237, loss=0.8596718311309814
train: epoch 150, loss 0.11391958594322205, acc=0.9585000276565552, loss=0.11391958594322205
test: epoch 150, loss 0.713845431804657, acc=0.8416666388511658, loss=0.713845431804657
