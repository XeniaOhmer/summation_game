# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1.5", "--temp_decay=0.99", "--one_hot=true", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=26212712, receiver_embed_dim=32, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.419903039932251, acc=0.046888887882232666, loss=3.419903039932251
test: epoch 1, loss 3.90055513381958, acc=0.03611111268401146, loss=3.90055513381958
train: epoch 2, loss 2.7927281856536865, acc=0.14888888597488403, loss=2.7927281856536865
test: epoch 2, loss 3.3196470737457275, acc=0.1388888955116272, loss=3.3196470737457275
train: epoch 3, loss 1.993377447128296, acc=0.29144445061683655, loss=1.993377447128296
test: epoch 3, loss 2.914459705352783, acc=0.1388888955116272, loss=2.914459705352783
train: epoch 4, loss 1.6741024255752563, acc=0.36888888478279114, loss=1.6741024255752563
test: epoch 4, loss 2.783937454223633, acc=0.1527777761220932, loss=2.783937454223633
train: epoch 5, loss 1.520625114440918, acc=0.4131111204624176, loss=1.520625114440918
test: epoch 5, loss 2.6536266803741455, acc=0.1666666716337204, loss=2.6536266803741455
train: epoch 6, loss 1.4057835340499878, acc=0.4518333375453949, loss=1.4057835340499878
test: epoch 6, loss 2.390977621078491, acc=0.18888889253139496, loss=2.390977621078491
train: epoch 7, loss 1.3191115856170654, acc=0.4891666769981384, loss=1.3191115856170654
test: epoch 7, loss 2.5820326805114746, acc=0.19722221791744232, loss=2.5820326805114746
train: epoch 8, loss 1.2567901611328125, acc=0.5093333125114441, loss=1.2567901611328125
test: epoch 8, loss 2.479335308074951, acc=0.21666666865348816, loss=2.479335308074951
train: epoch 9, loss 1.1985142230987549, acc=0.5342222452163696, loss=1.1985142230987549
test: epoch 9, loss 2.3877837657928467, acc=0.2083333283662796, loss=2.3877837657928467
train: epoch 10, loss 1.1382497549057007, acc=0.5561666488647461, loss=1.1382497549057007
test: epoch 10, loss 2.2629752159118652, acc=0.22777777910232544, loss=2.2629752159118652
train: epoch 11, loss 1.0992077589035034, acc=0.5679444670677185, loss=1.0992077589035034
test: epoch 11, loss 2.2119202613830566, acc=0.23333333432674408, loss=2.2119202613830566
train: epoch 12, loss 1.0538828372955322, acc=0.5920555591583252, loss=1.0538828372955322
test: epoch 12, loss 2.18463134765625, acc=0.2527777850627899, loss=2.18463134765625
train: epoch 13, loss 1.024361252784729, acc=0.6024444699287415, loss=1.024361252784729
test: epoch 13, loss 2.1550021171569824, acc=0.25833332538604736, loss=2.1550021171569824
train: epoch 14, loss 1.0038707256317139, acc=0.6201666593551636, loss=1.0038707256317139
test: epoch 14, loss 2.1118428707122803, acc=0.25555557012557983, loss=2.1118428707122803
train: epoch 15, loss 0.9635993242263794, acc=0.6332777738571167, loss=0.9635993242263794
test: epoch 15, loss 2.047219753265381, acc=0.25833332538604736, loss=2.047219753265381
train: epoch 16, loss 0.9474259614944458, acc=0.6389999985694885, loss=0.9474259614944458
test: epoch 16, loss 1.985260009765625, acc=0.2611111104488373, loss=1.985260009765625
train: epoch 17, loss 0.923716127872467, acc=0.6492778062820435, loss=0.923716127872467
test: epoch 17, loss 2.0914666652679443, acc=0.2638888955116272, loss=2.0914666652679443
train: epoch 18, loss 0.9025477170944214, acc=0.653333306312561, loss=0.9025477170944214
test: epoch 18, loss 2.011383056640625, acc=0.2666666805744171, loss=2.011383056640625
train: epoch 19, loss 0.8793980479240417, acc=0.6663888692855835, loss=0.8793980479240417
test: epoch 19, loss 1.9510242938995361, acc=0.2888889014720917, loss=1.9510242938995361
train: epoch 20, loss 0.8662342429161072, acc=0.6728888750076294, loss=0.8662342429161072
test: epoch 20, loss 1.9673796892166138, acc=0.2777777910232544, loss=1.9673796892166138
train: epoch 21, loss 0.839886486530304, acc=0.6793333292007446, loss=0.839886486530304
test: epoch 21, loss 1.9892202615737915, acc=0.29722222685813904, loss=1.9892202615737915
train: epoch 22, loss 0.8269891142845154, acc=0.6945000290870667, loss=0.8269891142845154
test: epoch 22, loss 1.8742313385009766, acc=0.3027777671813965, loss=1.8742313385009766
train: epoch 23, loss 0.8079304695129395, acc=0.6956666707992554, loss=0.8079304695129395
test: epoch 23, loss 1.906980276107788, acc=0.3027777671813965, loss=1.906980276107788
train: epoch 24, loss 0.8015161156654358, acc=0.6961666941642761, loss=0.8015161156654358
test: epoch 24, loss 1.7834045886993408, acc=0.31388887763023376, loss=1.7834045886993408
train: epoch 25, loss 0.7970128655433655, acc=0.7043333053588867, loss=0.7970128655433655
test: epoch 25, loss 1.7264595031738281, acc=0.3083333373069763, loss=1.7264595031738281
train: epoch 26, loss 0.7824178338050842, acc=0.7003889083862305, loss=0.7824178338050842
test: epoch 26, loss 1.6984704732894897, acc=0.33888888359069824, loss=1.6984704732894897
train: epoch 27, loss 0.7599513530731201, acc=0.7129999995231628, loss=0.7599513530731201
test: epoch 27, loss 1.6999003887176514, acc=0.3305555582046509, loss=1.6999003887176514
train: epoch 28, loss 0.7586268782615662, acc=0.7133888602256775, loss=0.7586268782615662
test: epoch 28, loss 1.7391252517700195, acc=0.32499998807907104, loss=1.7391252517700195
train: epoch 29, loss 0.7496996521949768, acc=0.7144444584846497, loss=0.7496996521949768
test: epoch 29, loss 1.651215672492981, acc=0.34166666865348816, loss=1.651215672492981
train: epoch 30, loss 0.7492971420288086, acc=0.7161111235618591, loss=0.7492971420288086
test: epoch 30, loss 1.655226469039917, acc=0.3222222328186035, loss=1.655226469039917
train: epoch 31, loss 0.7348010540008545, acc=0.7273333072662354, loss=0.7348010540008545
test: epoch 31, loss 1.6532889604568481, acc=0.3444444537162781, loss=1.6532889604568481
train: epoch 32, loss 0.7237750887870789, acc=0.7260555624961853, loss=0.7237750887870789
test: epoch 32, loss 1.640013337135315, acc=0.35555556416511536, loss=1.640013337135315
train: epoch 33, loss 0.7080744504928589, acc=0.725777804851532, loss=0.7080744504928589
test: epoch 33, loss 1.6599074602127075, acc=0.3638888895511627, loss=1.6599074602127075
train: epoch 34, loss 0.7026567459106445, acc=0.731333315372467, loss=0.7026567459106445
test: epoch 34, loss 1.6346968412399292, acc=0.3638888895511627, loss=1.6346968412399292
train: epoch 35, loss 0.6995016932487488, acc=0.7329444289207458, loss=0.6995016932487488
test: epoch 35, loss 1.5740833282470703, acc=0.3638888895511627, loss=1.5740833282470703
train: epoch 36, loss 0.694253146648407, acc=0.7360555529594421, loss=0.694253146648407
test: epoch 36, loss 1.6341514587402344, acc=0.39444443583488464, loss=1.6341514587402344
train: epoch 37, loss 0.6693288087844849, acc=0.7448333501815796, loss=0.6693288087844849
test: epoch 37, loss 1.550228238105774, acc=0.3916666805744171, loss=1.550228238105774
train: epoch 38, loss 0.6718736290931702, acc=0.7453333139419556, loss=0.6718736290931702
test: epoch 38, loss 1.6117069721221924, acc=0.38333332538604736, loss=1.6117069721221924
train: epoch 39, loss 0.6710867881774902, acc=0.7427777647972107, loss=0.6710867881774902
test: epoch 39, loss 1.551077961921692, acc=0.39722222089767456, loss=1.551077961921692
train: epoch 40, loss 0.6560924649238586, acc=0.7446666955947876, loss=0.6560924649238586
test: epoch 40, loss 1.534662127494812, acc=0.4055555462837219, loss=1.534662127494812
train: epoch 41, loss 0.6417656540870667, acc=0.7547777891159058, loss=0.6417656540870667
test: epoch 41, loss 1.524532437324524, acc=0.42500001192092896, loss=1.524532437324524
train: epoch 42, loss 0.6378740668296814, acc=0.7549999952316284, loss=0.6378740668296814
test: epoch 42, loss 1.5646189451217651, acc=0.4166666567325592, loss=1.5646189451217651
train: epoch 43, loss 0.6311773061752319, acc=0.7586110830307007, loss=0.6311773061752319
test: epoch 43, loss 1.4732108116149902, acc=0.41111111640930176, loss=1.4732108116149902
train: epoch 44, loss 0.6379326581954956, acc=0.7608333230018616, loss=0.6379326581954956
test: epoch 44, loss 1.4145320653915405, acc=0.4194444417953491, loss=1.4145320653915405
train: epoch 45, loss 0.6197236776351929, acc=0.762499988079071, loss=0.6197236776351929
test: epoch 45, loss 1.4395408630371094, acc=0.42500001192092896, loss=1.4395408630371094
train: epoch 46, loss 0.6195268630981445, acc=0.762333333492279, loss=0.6195268630981445
test: epoch 46, loss 1.4056062698364258, acc=0.4194444417953491, loss=1.4056062698364258
train: epoch 47, loss 0.5964354872703552, acc=0.7684999704360962, loss=0.5964354872703552
test: epoch 47, loss 1.3290573358535767, acc=0.43611112236976624, loss=1.3290573358535767
train: epoch 48, loss 0.5867260694503784, acc=0.7708333134651184, loss=0.5867260694503784
test: epoch 48, loss 1.4023869037628174, acc=0.4472222328186035, loss=1.4023869037628174
train: epoch 49, loss 0.5835670828819275, acc=0.7761111259460449, loss=0.5835670828819275
test: epoch 49, loss 1.3711447715759277, acc=0.4166666567325592, loss=1.3711447715759277
train: epoch 50, loss 0.5979429483413696, acc=0.7717221975326538, loss=0.5979429483413696
test: epoch 50, loss 1.3127137422561646, acc=0.4194444417953491, loss=1.3127137422561646
train: epoch 51, loss 0.5999388098716736, acc=0.7738333344459534, loss=0.5999388098716736
test: epoch 51, loss 1.408675193786621, acc=0.43888887763023376, loss=1.408675193786621
train: epoch 52, loss 0.5884696841239929, acc=0.7766666412353516, loss=0.5884696841239929
test: epoch 52, loss 1.376652717590332, acc=0.4444444477558136, loss=1.376652717590332
train: epoch 53, loss 0.5689246654510498, acc=0.7874444723129272, loss=0.5689246654510498
test: epoch 53, loss 1.4404305219650269, acc=0.4472222328186035, loss=1.4404305219650269
train: epoch 54, loss 0.5678620934486389, acc=0.7828333377838135, loss=0.5678620934486389
test: epoch 54, loss 1.3363971710205078, acc=0.4583333432674408, loss=1.3363971710205078
train: epoch 55, loss 0.5637908577919006, acc=0.785611093044281, loss=0.5637908577919006
test: epoch 55, loss 1.365700125694275, acc=0.43888887763023376, loss=1.365700125694275
train: epoch 56, loss 0.5540453791618347, acc=0.7911111116409302, loss=0.5540453791618347
test: epoch 56, loss 1.2100114822387695, acc=0.4833333194255829, loss=1.2100114822387695
train: epoch 57, loss 0.549467921257019, acc=0.7928333282470703, loss=0.549467921257019
test: epoch 57, loss 1.3243680000305176, acc=0.4611110985279083, loss=1.3243680000305176
train: epoch 58, loss 0.5377236604690552, acc=0.7950555682182312, loss=0.5377236604690552
test: epoch 58, loss 1.2471061944961548, acc=0.4861111044883728, loss=1.2471061944961548
train: epoch 59, loss 0.5496878027915955, acc=0.7914444208145142, loss=0.5496878027915955
test: epoch 59, loss 1.2706295251846313, acc=0.48055556416511536, loss=1.2706295251846313
train: epoch 60, loss 0.535531222820282, acc=0.7994444370269775, loss=0.535531222820282
test: epoch 60, loss 1.2766393423080444, acc=0.46666666865348816, loss=1.2766393423080444
train: epoch 61, loss 0.5372717976570129, acc=0.796999990940094, loss=0.5372717976570129
test: epoch 61, loss 1.2792388200759888, acc=0.4722222089767456, loss=1.2792388200759888
train: epoch 62, loss 0.5345458984375, acc=0.7984444499015808, loss=0.5345458984375
test: epoch 62, loss 1.2940410375595093, acc=0.4749999940395355, loss=1.2940410375595093
train: epoch 63, loss 0.5388486981391907, acc=0.7978333234786987, loss=0.5388486981391907
test: epoch 63, loss 1.2435880899429321, acc=0.4722222089767456, loss=1.2435880899429321
train: epoch 64, loss 0.5117233395576477, acc=0.8018888831138611, loss=0.5117233395576477
test: epoch 64, loss 1.2380053997039795, acc=0.46666666865348816, loss=1.2380053997039795
train: epoch 65, loss 0.5181360244750977, acc=0.8057777881622314, loss=0.5181360244750977
test: epoch 65, loss 1.1999846696853638, acc=0.4972222149372101, loss=1.1999846696853638
train: epoch 66, loss 0.5111061930656433, acc=0.8063889145851135, loss=0.5111061930656433
test: epoch 66, loss 1.2010056972503662, acc=0.5055555701255798, loss=1.2010056972503662
train: epoch 67, loss 0.5154257416725159, acc=0.8018888831138611, loss=0.5154257416725159
test: epoch 67, loss 1.2288137674331665, acc=0.4722222089767456, loss=1.2288137674331665
train: epoch 68, loss 0.5101021528244019, acc=0.8036110997200012, loss=0.5101021528244019
test: epoch 68, loss 1.224752426147461, acc=0.5222222208976746, loss=1.224752426147461
train: epoch 69, loss 0.5213499069213867, acc=0.7990000247955322, loss=0.5213499069213867
test: epoch 69, loss 1.1425386667251587, acc=0.5138888955116272, loss=1.1425386667251587
train: epoch 70, loss 0.5099409818649292, acc=0.8068333268165588, loss=0.5099409818649292
test: epoch 70, loss 1.177842378616333, acc=0.519444465637207, loss=1.177842378616333
train: epoch 71, loss 0.49688223004341125, acc=0.8114444613456726, loss=0.49688223004341125
test: epoch 71, loss 1.1857578754425049, acc=0.5222222208976746, loss=1.1857578754425049
train: epoch 72, loss 0.49198848009109497, acc=0.8127222061157227, loss=0.49198848009109497
test: epoch 72, loss 1.1813198328018188, acc=0.5277777910232544, loss=1.1813198328018188
train: epoch 73, loss 0.49084141850471497, acc=0.8127777576446533, loss=0.49084141850471497
test: epoch 73, loss 1.0938349962234497, acc=0.5416666865348816, loss=1.0938349962234497
train: epoch 74, loss 0.47349390387535095, acc=0.8199999928474426, loss=0.47349390387535095
test: epoch 74, loss 1.1042391061782837, acc=0.5333333611488342, loss=1.1042391061782837
train: epoch 75, loss 0.4827841818332672, acc=0.8197222352027893, loss=0.4827841818332672
test: epoch 75, loss 1.2354921102523804, acc=0.5277777910232544, loss=1.2354921102523804
train: epoch 76, loss 0.47572481632232666, acc=0.8134444355964661, loss=0.47572481632232666
test: epoch 76, loss 1.1517177820205688, acc=0.550000011920929, loss=1.1517177820205688
train: epoch 77, loss 0.47291070222854614, acc=0.8222222328186035, loss=0.47291070222854614
test: epoch 77, loss 1.14553701877594, acc=0.5166666507720947, loss=1.14553701877594
train: epoch 78, loss 0.4535302519798279, acc=0.8249444365501404, loss=0.4535302519798279
test: epoch 78, loss 1.2160568237304688, acc=0.550000011920929, loss=1.2160568237304688
train: epoch 79, loss 0.4503873586654663, acc=0.8284444212913513, loss=0.4503873586654663
test: epoch 79, loss 1.205214262008667, acc=0.5305555462837219, loss=1.205214262008667
train: epoch 80, loss 0.44033151865005493, acc=0.8293333053588867, loss=0.44033151865005493
test: epoch 80, loss 1.1551384925842285, acc=0.5361111164093018, loss=1.1551384925842285
train: epoch 81, loss 0.4564317464828491, acc=0.8276110887527466, loss=0.4564317464828491
test: epoch 81, loss 1.1391794681549072, acc=0.5444444417953491, loss=1.1391794681549072
train: epoch 82, loss 0.43367066979408264, acc=0.8313888907432556, loss=0.43367066979408264
test: epoch 82, loss 1.2438567876815796, acc=0.5527777671813965, loss=1.2438567876815796
train: epoch 83, loss 0.4231182634830475, acc=0.8360000252723694, loss=0.4231182634830475
test: epoch 83, loss 1.142569661140442, acc=0.5555555820465088, loss=1.142569661140442
train: epoch 84, loss 0.4342830777168274, acc=0.8310555815696716, loss=0.4342830777168274
test: epoch 84, loss 1.0778782367706299, acc=0.5694444179534912, loss=1.0778782367706299
train: epoch 85, loss 0.4324934482574463, acc=0.8341666460037231, loss=0.4324934482574463
test: epoch 85, loss 1.1996022462844849, acc=0.5555555820465088, loss=1.1996022462844849
train: epoch 86, loss 0.44081535935401917, acc=0.8326666951179504, loss=0.44081535935401917
test: epoch 86, loss 1.174000859260559, acc=0.5694444179534912, loss=1.174000859260559
train: epoch 87, loss 0.4238315224647522, acc=0.836222231388092, loss=0.4238315224647522
test: epoch 87, loss 1.0983232259750366, acc=0.5777778029441833, loss=1.0983232259750366
train: epoch 88, loss 0.4154980778694153, acc=0.839388906955719, loss=0.4154980778694153
test: epoch 88, loss 1.2197816371917725, acc=0.574999988079071, loss=1.2197816371917725
train: epoch 89, loss 0.41030457615852356, acc=0.8400555849075317, loss=0.41030457615852356
test: epoch 89, loss 1.1071364879608154, acc=0.5527777671813965, loss=1.1071364879608154
train: epoch 90, loss 0.4115079343318939, acc=0.8408889174461365, loss=0.4115079343318939
test: epoch 90, loss 1.1664543151855469, acc=0.5777778029441833, loss=1.1664543151855469
train: epoch 91, loss 0.407613605260849, acc=0.8409444689750671, loss=0.407613605260849
test: epoch 91, loss 1.1514812707901, acc=0.5722222328186035, loss=1.1514812707901
train: epoch 92, loss 0.4021283686161041, acc=0.8423333168029785, loss=0.4021283686161041
test: epoch 92, loss 1.1783133745193481, acc=0.5805555582046509, loss=1.1783133745193481
train: epoch 93, loss 0.4042235314846039, acc=0.8414444327354431, loss=0.4042235314846039
test: epoch 93, loss 1.1878162622451782, acc=0.5722222328186035, loss=1.1878162622451782
train: epoch 94, loss 0.3969009220600128, acc=0.842555582523346, loss=0.3969009220600128
test: epoch 94, loss 1.0593541860580444, acc=0.5833333134651184, loss=1.0593541860580444
train: epoch 95, loss 0.39375755190849304, acc=0.8421666622161865, loss=0.39375755190849304
test: epoch 95, loss 1.0578593015670776, acc=0.5694444179534912, loss=1.0578593015670776
train: epoch 96, loss 0.39393019676208496, acc=0.8450000286102295, loss=0.39393019676208496
test: epoch 96, loss 1.0800460577011108, acc=0.5916666388511658, loss=1.0800460577011108
train: epoch 97, loss 0.38678061962127686, acc=0.8473333120346069, loss=0.38678061962127686
test: epoch 97, loss 1.0796750783920288, acc=0.5861111283302307, loss=1.0796750783920288
train: epoch 98, loss 0.3929598331451416, acc=0.8435555696487427, loss=0.3929598331451416
test: epoch 98, loss 1.0884531736373901, acc=0.5777778029441833, loss=1.0884531736373901
train: epoch 99, loss 0.3811643123626709, acc=0.8473888635635376, loss=0.3811643123626709
test: epoch 99, loss 1.0830048322677612, acc=0.5805555582046509, loss=1.0830048322677612
train: epoch 100, loss 0.3906175494194031, acc=0.8476666808128357, loss=0.3906175494194031
test: epoch 100, loss 1.1132464408874512, acc=0.5583333373069763, loss=1.1132464408874512
train: epoch 101, loss 0.387471467256546, acc=0.8448333144187927, loss=0.387471467256546
test: epoch 101, loss 1.062674880027771, acc=0.5805555582046509, loss=1.062674880027771
train: epoch 102, loss 0.3857268989086151, acc=0.8521666526794434, loss=0.3857268989086151
test: epoch 102, loss 1.112194538116455, acc=0.5888888835906982, loss=1.112194538116455
train: epoch 103, loss 0.38096073269844055, acc=0.8485000133514404, loss=0.38096073269844055
test: epoch 103, loss 1.0853499174118042, acc=0.6000000238418579, loss=1.0853499174118042
train: epoch 104, loss 0.366923987865448, acc=0.8527777791023254, loss=0.366923987865448
test: epoch 104, loss 1.0623711347579956, acc=0.5916666388511658, loss=1.0623711347579956
train: epoch 105, loss 0.37208467721939087, acc=0.8519999980926514, loss=0.37208467721939087
test: epoch 105, loss 1.0697616338729858, acc=0.6027777791023254, loss=1.0697616338729858
train: epoch 106, loss 0.3635644316673279, acc=0.8549444675445557, loss=0.3635644316673279
test: epoch 106, loss 1.072014331817627, acc=0.6000000238418579, loss=1.072014331817627
train: epoch 107, loss 0.3692517876625061, acc=0.8570555448532104, loss=0.3692517876625061
test: epoch 107, loss 1.0652915239334106, acc=0.6000000238418579, loss=1.0652915239334106
train: epoch 108, loss 0.367156058549881, acc=0.8553333282470703, loss=0.367156058549881
test: epoch 108, loss 1.1013699769973755, acc=0.5861111283302307, loss=1.1013699769973755
train: epoch 109, loss 0.35402196645736694, acc=0.8567222356796265, loss=0.35402196645736694
test: epoch 109, loss 1.1407191753387451, acc=0.5944444537162781, loss=1.1407191753387451
train: epoch 110, loss 0.3679749667644501, acc=0.8541666865348816, loss=0.3679749667644501
test: epoch 110, loss 1.1851115226745605, acc=0.5972222089767456, loss=1.1851115226745605
train: epoch 111, loss 0.35294246673583984, acc=0.8562222123146057, loss=0.35294246673583984
test: epoch 111, loss 1.025130271911621, acc=0.6027777791023254, loss=1.025130271911621
train: epoch 112, loss 0.35528698563575745, acc=0.859499990940094, loss=0.35528698563575745
test: epoch 112, loss 1.1586172580718994, acc=0.6083333492279053, loss=1.1586172580718994
train: epoch 113, loss 0.36782342195510864, acc=0.8580555319786072, loss=0.36782342195510864
test: epoch 113, loss 1.1812999248504639, acc=0.5888888835906982, loss=1.1812999248504639
train: epoch 114, loss 0.3625260591506958, acc=0.8572221994400024, loss=0.3625260591506958
test: epoch 114, loss 1.0671107769012451, acc=0.6000000238418579, loss=1.0671107769012451
train: epoch 115, loss 0.34253230690956116, acc=0.8622221946716309, loss=0.34253230690956116
test: epoch 115, loss 1.0730104446411133, acc=0.605555534362793, loss=1.0730104446411133
train: epoch 116, loss 0.33951735496520996, acc=0.8611111044883728, loss=0.33951735496520996
test: epoch 116, loss 1.1693960428237915, acc=0.6000000238418579, loss=1.1693960428237915
train: epoch 117, loss 0.3565579652786255, acc=0.8604999780654907, loss=0.3565579652786255
test: epoch 117, loss 1.0977691411972046, acc=0.5861111283302307, loss=1.0977691411972046
train: epoch 118, loss 0.3485773801803589, acc=0.8619444370269775, loss=0.3485773801803589
test: epoch 118, loss 1.0583865642547607, acc=0.6111111044883728, loss=1.0583865642547607
train: epoch 119, loss 0.3489965796470642, acc=0.8618333339691162, loss=0.3489965796470642
test: epoch 119, loss 0.9654152989387512, acc=0.6083333492279053, loss=0.9654152989387512
train: epoch 120, loss 0.32813701033592224, acc=0.8663889169692993, loss=0.32813701033592224
test: epoch 120, loss 1.0965150594711304, acc=0.6083333492279053, loss=1.0965150594711304
train: epoch 121, loss 0.3590328097343445, acc=0.8603333234786987, loss=0.3590328097343445
test: epoch 121, loss 1.0228314399719238, acc=0.6083333492279053, loss=1.0228314399719238
train: epoch 122, loss 0.3364957869052887, acc=0.8632222414016724, loss=0.3364957869052887
test: epoch 122, loss 1.0443580150604248, acc=0.6083333492279053, loss=1.0443580150604248
train: epoch 123, loss 0.32482388615608215, acc=0.8682777881622314, loss=0.32482388615608215
test: epoch 123, loss 1.1015428304672241, acc=0.6027777791023254, loss=1.1015428304672241
train: epoch 124, loss 0.3280462920665741, acc=0.866777777671814, loss=0.3280462920665741
test: epoch 124, loss 1.0355011224746704, acc=0.5944444537162781, loss=1.0355011224746704
train: epoch 125, loss 0.32109320163726807, acc=0.8684444427490234, loss=0.32109320163726807
test: epoch 125, loss 1.1883736848831177, acc=0.6111111044883728, loss=1.1883736848831177
train: epoch 126, loss 0.3430785536766052, acc=0.8656666874885559, loss=0.3430785536766052
test: epoch 126, loss 1.0398144721984863, acc=0.6166666746139526, loss=1.0398144721984863
train: epoch 127, loss 0.3523291051387787, acc=0.8661666512489319, loss=0.3523291051387787
test: epoch 127, loss 1.0695674419403076, acc=0.6138888597488403, loss=1.0695674419403076
train: epoch 128, loss 0.32623329758644104, acc=0.8665555715560913, loss=0.32623329758644104
test: epoch 128, loss 1.1378111839294434, acc=0.6194444298744202, loss=1.1378111839294434
train: epoch 129, loss 0.3259975016117096, acc=0.8698889017105103, loss=0.3259975016117096
test: epoch 129, loss 1.1173951625823975, acc=0.6194444298744202, loss=1.1173951625823975
train: epoch 130, loss 0.3335462808609009, acc=0.867388904094696, loss=0.3335462808609009
test: epoch 130, loss 1.160414695739746, acc=0.6083333492279053, loss=1.160414695739746
train: epoch 131, loss 0.3209461271762848, acc=0.8717222213745117, loss=0.3209461271762848
test: epoch 131, loss 1.021693468093872, acc=0.605555534362793, loss=1.021693468093872
train: epoch 132, loss 0.33569106459617615, acc=0.8651111125946045, loss=0.33569106459617615
test: epoch 132, loss 1.0991142988204956, acc=0.6194444298744202, loss=1.0991142988204956
train: epoch 133, loss 0.3289538621902466, acc=0.8654444217681885, loss=0.3289538621902466
test: epoch 133, loss 1.1761837005615234, acc=0.6083333492279053, loss=1.1761837005615234
train: epoch 134, loss 0.3257274627685547, acc=0.8675000071525574, loss=0.3257274627685547
test: epoch 134, loss 1.1484280824661255, acc=0.625, loss=1.1484280824661255
train: epoch 135, loss 0.31971070170402527, acc=0.8691111207008362, loss=0.31971070170402527
test: epoch 135, loss 1.118800163269043, acc=0.6194444298744202, loss=1.118800163269043
train: epoch 136, loss 0.325505793094635, acc=0.8704444169998169, loss=0.325505793094635
test: epoch 136, loss 1.0652202367782593, acc=0.6222222447395325, loss=1.0652202367782593
train: epoch 137, loss 0.3295152485370636, acc=0.8683333396911621, loss=0.3295152485370636
test: epoch 137, loss 0.977347731590271, acc=0.6222222447395325, loss=0.977347731590271
train: epoch 138, loss 0.32590436935424805, acc=0.8652777671813965, loss=0.32590436935424805
test: epoch 138, loss 1.1440304517745972, acc=0.6194444298744202, loss=1.1440304517745972
train: epoch 139, loss 0.31473758816719055, acc=0.8734444379806519, loss=0.31473758816719055
test: epoch 139, loss 1.0336169004440308, acc=0.6333333253860474, loss=1.0336169004440308
train: epoch 140, loss 0.31380388140678406, acc=0.8703888654708862, loss=0.31380388140678406
test: epoch 140, loss 1.1233559846878052, acc=0.6305555701255798, loss=1.1233559846878052
train: epoch 141, loss 0.3176000714302063, acc=0.8730555772781372, loss=0.3176000714302063
test: epoch 141, loss 1.0187956094741821, acc=0.6222222447395325, loss=1.0187956094741821
train: epoch 142, loss 0.30926376581192017, acc=0.8727222084999084, loss=0.30926376581192017
test: epoch 142, loss 1.1292058229446411, acc=0.6333333253860474, loss=1.1292058229446411
train: epoch 143, loss 0.3239106833934784, acc=0.8713333606719971, loss=0.3239106833934784
test: epoch 143, loss 1.0363181829452515, acc=0.6333333253860474, loss=1.0363181829452515
train: epoch 144, loss 0.3225814998149872, acc=0.8763889074325562, loss=0.3225814998149872
test: epoch 144, loss 1.096374750137329, acc=0.6333333253860474, loss=1.096374750137329
train: epoch 145, loss 0.3186483085155487, acc=0.8737778067588806, loss=0.3186483085155487
test: epoch 145, loss 1.190956711769104, acc=0.6333333253860474, loss=1.190956711769104
train: epoch 146, loss 0.3130255937576294, acc=0.8747777938842773, loss=0.3130255937576294
test: epoch 146, loss 1.036311388015747, acc=0.6333333253860474, loss=1.036311388015747
train: epoch 147, loss 0.30397266149520874, acc=0.8749444484710693, loss=0.30397266149520874
test: epoch 147, loss 1.0301415920257568, acc=0.6416666507720947, loss=1.0301415920257568
train: epoch 148, loss 0.30967241525650024, acc=0.8747777938842773, loss=0.30967241525650024
test: epoch 148, loss 1.0577433109283447, acc=0.644444465637207, loss=1.0577433109283447
train: epoch 149, loss 0.30920761823654175, acc=0.8764444589614868, loss=0.30920761823654175
test: epoch 149, loss 0.9997788667678833, acc=0.644444465637207, loss=0.9997788667678833
train: epoch 150, loss 0.3147355020046234, acc=0.8759999871253967, loss=0.3147355020046234
test: epoch 150, loss 1.127044916152954, acc=0.6333333253860474, loss=1.127044916152954
