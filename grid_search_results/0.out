# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=1", "--temp_decay=1", "--one_hot=0", "--n_layers=1"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=883581503, receiver_embed_dim=32, save_run=0, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=883581503, receiver_embed_dim=32, save_run=False, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.275097131729126, acc=0.06805555522441864, loss=3.275097131729126
test: epoch 1, loss 3.619811773300171, acc=0.05000000074505806, loss=3.619811773300171
train: epoch 2, loss 2.922858953475952, acc=0.0989999994635582, loss=2.922858953475952
test: epoch 2, loss 3.756505012512207, acc=0.05277777835726738, loss=3.756505012512207
train: epoch 3, loss 2.8075637817382812, acc=0.11666666716337204, loss=2.8075637817382812
test: epoch 3, loss 3.878770351409912, acc=0.0555555559694767, loss=3.878770351409912
train: epoch 4, loss 2.742091178894043, acc=0.1245555579662323, loss=2.742091178894043
test: epoch 4, loss 4.051502227783203, acc=0.05277777835726738, loss=4.051502227783203
train: epoch 5, loss 2.691427707672119, acc=0.13244444131851196, loss=2.691427707672119
test: epoch 5, loss 4.082963943481445, acc=0.05277777835726738, loss=4.082963943481445
train: epoch 6, loss 2.6652722358703613, acc=0.1306111067533493, loss=2.6652722358703613
test: epoch 6, loss 4.030267238616943, acc=0.05000000074505806, loss=4.030267238616943
train: epoch 7, loss 2.637880325317383, acc=0.1382777839899063, loss=2.637880325317383
test: epoch 7, loss 3.8160605430603027, acc=0.06666667014360428, loss=3.8160605430603027
train: epoch 8, loss 2.61307954788208, acc=0.13894444704055786, loss=2.61307954788208
test: epoch 8, loss 4.012625694274902, acc=0.05277777835726738, loss=4.012625694274902
train: epoch 9, loss 2.59177827835083, acc=0.14588889479637146, loss=2.59177827835083
test: epoch 9, loss 4.107654094696045, acc=0.05277777835726738, loss=4.107654094696045
train: epoch 10, loss 2.574575901031494, acc=0.15049999952316284, loss=2.574575901031494
test: epoch 10, loss 4.094075679779053, acc=0.0555555559694767, loss=4.094075679779053
train: epoch 11, loss 2.5655765533447266, acc=0.15111111104488373, loss=2.5655765533447266
test: epoch 11, loss 3.848238945007324, acc=0.0694444477558136, loss=3.848238945007324
train: epoch 12, loss 2.5453028678894043, acc=0.1527777761220932, loss=2.5453028678894043
test: epoch 12, loss 3.9143073558807373, acc=0.05277777835726738, loss=3.9143073558807373
train: epoch 13, loss 2.5198163986206055, acc=0.15655554831027985, loss=2.5198163986206055
test: epoch 13, loss 3.9032111167907715, acc=0.05833333358168602, loss=3.9032111167907715
train: epoch 14, loss 2.5109336376190186, acc=0.15944445133209229, loss=2.5109336376190186
test: epoch 14, loss 3.9275100231170654, acc=0.05833333358168602, loss=3.9275100231170654
train: epoch 15, loss 2.5039098262786865, acc=0.16050000488758087, loss=2.5039098262786865
test: epoch 15, loss 3.97057843208313, acc=0.05833333358168602, loss=3.97057843208313
train: epoch 16, loss 2.4885005950927734, acc=0.16761110723018646, loss=2.4885005950927734
test: epoch 16, loss 3.9217183589935303, acc=0.05833333358168602, loss=3.9217183589935303
train: epoch 17, loss 2.4836909770965576, acc=0.16172222793102264, loss=2.4836909770965576
test: epoch 17, loss 3.936448335647583, acc=0.05277777835726738, loss=3.936448335647583
train: epoch 18, loss 2.4772417545318604, acc=0.1671111136674881, loss=2.4772417545318604
test: epoch 18, loss 3.9701128005981445, acc=0.0555555559694767, loss=3.9701128005981445
train: epoch 19, loss 2.4460971355438232, acc=0.1673888862133026, loss=2.4460971355438232
test: epoch 19, loss 3.9168288707733154, acc=0.0555555559694767, loss=3.9168288707733154
train: epoch 20, loss 2.458550453186035, acc=0.17216666042804718, loss=2.458550453186035
test: epoch 20, loss 3.9141957759857178, acc=0.06111111119389534, loss=3.9141957759857178
train: epoch 21, loss 2.445960521697998, acc=0.17238888144493103, loss=2.445960521697998
test: epoch 21, loss 4.031483173370361, acc=0.05833333358168602, loss=4.031483173370361
train: epoch 22, loss 2.437769889831543, acc=0.17216666042804718, loss=2.437769889831543
test: epoch 22, loss 3.9752368927001953, acc=0.06111111119389534, loss=3.9752368927001953
train: epoch 23, loss 2.4266061782836914, acc=0.1756666600704193, loss=2.4266061782836914
test: epoch 23, loss 3.948735237121582, acc=0.07500000298023224, loss=3.948735237121582
train: epoch 24, loss 2.4195852279663086, acc=0.1753888875246048, loss=2.4195852279663086
test: epoch 24, loss 4.032266616821289, acc=0.0555555559694767, loss=4.032266616821289
train: epoch 25, loss 2.4189529418945312, acc=0.17811110615730286, loss=2.4189529418945312
test: epoch 25, loss 4.088129997253418, acc=0.05277777835726738, loss=4.088129997253418
train: epoch 26, loss 2.396078109741211, acc=0.17977777123451233, loss=2.396078109741211
test: epoch 26, loss 4.079596519470215, acc=0.05833333358168602, loss=4.079596519470215
train: epoch 27, loss 2.404674530029297, acc=0.1827777773141861, loss=2.404674530029297
test: epoch 27, loss 3.9082181453704834, acc=0.0694444477558136, loss=3.9082181453704834
train: epoch 28, loss 2.3868417739868164, acc=0.18194444477558136, loss=2.3868417739868164
test: epoch 28, loss 3.9508368968963623, acc=0.05277777835726738, loss=3.9508368968963623
train: epoch 29, loss 2.3864991664886475, acc=0.185722216963768, loss=2.3864991664886475
test: epoch 29, loss 3.9724013805389404, acc=0.06111111119389534, loss=3.9724013805389404
train: epoch 30, loss 2.367002487182617, acc=0.18549999594688416, loss=2.367002487182617
test: epoch 30, loss 3.9715888500213623, acc=0.06111111119389534, loss=3.9715888500213623
train: epoch 31, loss 2.3626649379730225, acc=0.18488888442516327, loss=2.3626649379730225
test: epoch 31, loss 3.9912984371185303, acc=0.05833333358168602, loss=3.9912984371185303
train: epoch 32, loss 2.363018751144409, acc=0.185555562376976, loss=2.363018751144409
test: epoch 32, loss 3.98331618309021, acc=0.07222222536802292, loss=3.98331618309021
train: epoch 33, loss 2.3425235748291016, acc=0.18727777898311615, loss=2.3425235748291016
test: epoch 33, loss 4.067774772644043, acc=0.06388889253139496, loss=4.067774772644043
train: epoch 34, loss 2.348297119140625, acc=0.19033333659172058, loss=2.348297119140625
test: epoch 34, loss 4.016829967498779, acc=0.06388889253139496, loss=4.016829967498779
train: epoch 35, loss 2.3394603729248047, acc=0.1875, loss=2.3394603729248047
test: epoch 35, loss 4.045912742614746, acc=0.06111111119389534, loss=4.045912742614746
train: epoch 36, loss 2.320988893508911, acc=0.1960555613040924, loss=2.320988893508911
test: epoch 36, loss 4.139129161834717, acc=0.0694444477558136, loss=4.139129161834717
train: epoch 37, loss 2.3331291675567627, acc=0.18783333897590637, loss=2.3331291675567627
test: epoch 37, loss 4.111311912536621, acc=0.0694444477558136, loss=4.111311912536621
train: epoch 38, loss 2.328808546066284, acc=0.19349999725818634, loss=2.328808546066284
test: epoch 38, loss 3.903533697128296, acc=0.06666667014360428, loss=3.903533697128296
train: epoch 39, loss 2.317833423614502, acc=0.19300000369548798, loss=2.317833423614502
test: epoch 39, loss 3.954371452331543, acc=0.0833333358168602, loss=3.954371452331543
train: epoch 40, loss 2.312049388885498, acc=0.19511111080646515, loss=2.312049388885498
test: epoch 40, loss 4.101592063903809, acc=0.06388889253139496, loss=4.101592063903809
train: epoch 41, loss 2.315063714981079, acc=0.1957777738571167, loss=2.315063714981079
test: epoch 41, loss 4.035075664520264, acc=0.06111111119389534, loss=4.035075664520264
train: epoch 42, loss 2.312873363494873, acc=0.19861111044883728, loss=2.312873363494873
test: epoch 42, loss 3.938476085662842, acc=0.06388889253139496, loss=3.938476085662842
train: epoch 43, loss 2.298394203186035, acc=0.20033332705497742, loss=2.298394203186035
test: epoch 43, loss 3.9099881649017334, acc=0.07777778059244156, loss=3.9099881649017334
train: epoch 44, loss 2.299380302429199, acc=0.20016667246818542, loss=2.299380302429199
test: epoch 44, loss 3.9352316856384277, acc=0.08055555820465088, loss=3.9352316856384277
train: epoch 45, loss 2.3035061359405518, acc=0.19877777993679047, loss=2.3035061359405518
test: epoch 45, loss 3.9192655086517334, acc=0.07500000298023224, loss=3.9192655086517334
train: epoch 46, loss 2.2885818481445312, acc=0.20133332908153534, loss=2.2885818481445312
test: epoch 46, loss 4.0012922286987305, acc=0.0555555559694767, loss=4.0012922286987305
train: epoch 47, loss 2.283397912979126, acc=0.19949999451637268, loss=2.283397912979126
test: epoch 47, loss 4.101870059967041, acc=0.05833333358168602, loss=4.101870059967041
train: epoch 48, loss 2.284236431121826, acc=0.1988888829946518, loss=2.284236431121826
test: epoch 48, loss 4.02628231048584, acc=0.05833333358168602, loss=4.02628231048584
train: epoch 49, loss 2.2782540321350098, acc=0.2047777771949768, loss=2.2782540321350098
test: epoch 49, loss 4.083542346954346, acc=0.06388889253139496, loss=4.083542346954346
train: epoch 50, loss 2.2657313346862793, acc=0.20605555176734924, loss=2.2657313346862793
test: epoch 50, loss 4.11085844039917, acc=0.0555555559694767, loss=4.11085844039917
train: epoch 51, loss 2.277127742767334, acc=0.203166663646698, loss=2.277127742767334
test: epoch 51, loss 3.779052257537842, acc=0.07500000298023224, loss=3.779052257537842
train: epoch 52, loss 2.262319564819336, acc=0.2038888931274414, loss=2.262319564819336
test: epoch 52, loss 4.063149929046631, acc=0.06388889253139496, loss=4.063149929046631
train: epoch 53, loss 2.251574754714966, acc=0.20944444835186005, loss=2.251574754714966
test: epoch 53, loss 4.114891529083252, acc=0.06111111119389534, loss=4.114891529083252
train: epoch 54, loss 2.2660129070281982, acc=0.21072222292423248, loss=2.2660129070281982
test: epoch 54, loss 4.098798751831055, acc=0.05833333358168602, loss=4.098798751831055
train: epoch 55, loss 2.2611494064331055, acc=0.20883333683013916, loss=2.2611494064331055
test: epoch 55, loss 4.102840423583984, acc=0.07777778059244156, loss=4.102840423583984
train: epoch 56, loss 2.2511374950408936, acc=0.20872221887111664, loss=2.2511374950408936
test: epoch 56, loss 3.857865571975708, acc=0.0555555559694767, loss=3.857865571975708
train: epoch 57, loss 2.244436740875244, acc=0.21183332800865173, loss=2.244436740875244
test: epoch 57, loss 4.081888198852539, acc=0.05833333358168602, loss=4.081888198852539
train: epoch 58, loss 2.2404513359069824, acc=0.21238888800144196, loss=2.2404513359069824
test: epoch 58, loss 3.879389524459839, acc=0.05833333358168602, loss=3.879389524459839
train: epoch 59, loss 2.250722885131836, acc=0.21488888561725616, loss=2.250722885131836
test: epoch 59, loss 3.904995918273926, acc=0.06666667014360428, loss=3.904995918273926
train: epoch 60, loss 2.235940456390381, acc=0.2154444456100464, loss=2.235940456390381
test: epoch 60, loss 3.9040586948394775, acc=0.0555555559694767, loss=3.9040586948394775
train: epoch 61, loss 2.2219085693359375, acc=0.2152777761220932, loss=2.2219085693359375
test: epoch 61, loss 3.979825973510742, acc=0.05000000074505806, loss=3.979825973510742
train: epoch 62, loss 2.2193405628204346, acc=0.21994444727897644, loss=2.2193405628204346
test: epoch 62, loss 4.000241756439209, acc=0.07777778059244156, loss=4.000241756439209
train: epoch 63, loss 2.2312073707580566, acc=0.21400000154972076, loss=2.2312073707580566
test: epoch 63, loss 4.0218682289123535, acc=0.07777778059244156, loss=4.0218682289123535
train: epoch 64, loss 2.221055269241333, acc=0.21833333373069763, loss=2.221055269241333
test: epoch 64, loss 3.9192416667938232, acc=0.04722222313284874, loss=3.9192416667938232
train: epoch 65, loss 2.212864875793457, acc=0.22466666996479034, loss=2.212864875793457
test: epoch 65, loss 3.9011428356170654, acc=0.05000000074505806, loss=3.9011428356170654
train: epoch 66, loss 2.223241090774536, acc=0.2161666601896286, loss=2.223241090774536
test: epoch 66, loss 3.971540689468384, acc=0.06388889253139496, loss=3.971540689468384
train: epoch 67, loss 2.2002358436584473, acc=0.2233888953924179, loss=2.2002358436584473
test: epoch 67, loss 4.050454616546631, acc=0.04722222313284874, loss=4.050454616546631
train: epoch 68, loss 2.2058918476104736, acc=0.22233332693576813, loss=2.2058918476104736
test: epoch 68, loss 4.026195049285889, acc=0.07222222536802292, loss=4.026195049285889
train: epoch 69, loss 2.2130212783813477, acc=0.22483333945274353, loss=2.2130212783813477
test: epoch 69, loss 3.9555723667144775, acc=0.07222222536802292, loss=3.9555723667144775
train: epoch 70, loss 2.205338716506958, acc=0.2197222262620926, loss=2.205338716506958
test: epoch 70, loss 4.146812915802002, acc=0.04444444552063942, loss=4.146812915802002
train: epoch 71, loss 2.225473642349243, acc=0.22433333098888397, loss=2.225473642349243
test: epoch 71, loss 3.9762790203094482, acc=0.0694444477558136, loss=3.9762790203094482
train: epoch 72, loss 2.205501079559326, acc=0.22566667199134827, loss=2.205501079559326
test: epoch 72, loss 3.9534411430358887, acc=0.06388889253139496, loss=3.9534411430358887
train: epoch 73, loss 2.1981492042541504, acc=0.23055554926395416, loss=2.1981492042541504
test: epoch 73, loss 4.034206867218018, acc=0.05277777835726738, loss=4.034206867218018
train: epoch 74, loss 2.187303066253662, acc=0.23527777194976807, loss=2.187303066253662
test: epoch 74, loss 3.9908459186553955, acc=0.05000000074505806, loss=3.9908459186553955
train: epoch 75, loss 2.1820688247680664, acc=0.22788888216018677, loss=2.1820688247680664
test: epoch 75, loss 3.8683021068573, acc=0.04722222313284874, loss=3.8683021068573
train: epoch 76, loss 2.189185619354248, acc=0.22733333706855774, loss=2.189185619354248
test: epoch 76, loss 3.8427281379699707, acc=0.06388889253139496, loss=3.8427281379699707
train: epoch 77, loss 2.189465045928955, acc=0.23533333837985992, loss=2.189465045928955
test: epoch 77, loss 3.8980965614318848, acc=0.07222222536802292, loss=3.8980965614318848
train: epoch 78, loss 2.182675361633301, acc=0.23216666281223297, loss=2.182675361633301
test: epoch 78, loss 3.868759870529175, acc=0.06666667014360428, loss=3.868759870529175
train: epoch 79, loss 2.1816930770874023, acc=0.22450000047683716, loss=2.1816930770874023
test: epoch 79, loss 4.078183650970459, acc=0.06666667014360428, loss=4.078183650970459
train: epoch 80, loss 2.177190065383911, acc=0.22805555164813995, loss=2.177190065383911
test: epoch 80, loss 3.875506639480591, acc=0.05833333358168602, loss=3.875506639480591
train: epoch 81, loss 2.167351722717285, acc=0.23061111569404602, loss=2.167351722717285
test: epoch 81, loss 3.9855434894561768, acc=0.04722222313284874, loss=3.9855434894561768
train: epoch 82, loss 2.166058301925659, acc=0.23600000143051147, loss=2.166058301925659
test: epoch 82, loss 3.9134671688079834, acc=0.04444444552063942, loss=3.9134671688079834
train: epoch 83, loss 2.1648108959198, acc=0.23749999701976776, loss=2.1648108959198
test: epoch 83, loss 4.003437042236328, acc=0.05277777835726738, loss=4.003437042236328
train: epoch 84, loss 2.168020248413086, acc=0.2368333339691162, loss=2.168020248413086
test: epoch 84, loss 3.8881144523620605, acc=0.06666667014360428, loss=3.8881144523620605
train: epoch 85, loss 2.156831741333008, acc=0.23927778005599976, loss=2.156831741333008
test: epoch 85, loss 3.944639205932617, acc=0.05000000074505806, loss=3.944639205932617
train: epoch 86, loss 2.1609973907470703, acc=0.23783333599567413, loss=2.1609973907470703
test: epoch 86, loss 3.9561281204223633, acc=0.05000000074505806, loss=3.9561281204223633
train: epoch 87, loss 2.154141426086426, acc=0.2390555590391159, loss=2.154141426086426
test: epoch 87, loss 3.9861984252929688, acc=0.04722222313284874, loss=3.9861984252929688
train: epoch 88, loss 2.158191442489624, acc=0.242166668176651, loss=2.158191442489624
test: epoch 88, loss 3.832228660583496, acc=0.0694444477558136, loss=3.832228660583496
train: epoch 89, loss 2.137697219848633, acc=0.23549999296665192, loss=2.137697219848633
test: epoch 89, loss 3.917088508605957, acc=0.05833333358168602, loss=3.917088508605957
train: epoch 90, loss 2.148726463317871, acc=0.2377222180366516, loss=2.148726463317871
test: epoch 90, loss 3.9767863750457764, acc=0.05833333358168602, loss=3.9767863750457764
train: epoch 91, loss 2.1427035331726074, acc=0.2378888875246048, loss=2.1427035331726074
test: epoch 91, loss 4.0104451179504395, acc=0.0555555559694767, loss=4.0104451179504395
train: epoch 92, loss 2.1415200233459473, acc=0.24199999868869781, loss=2.1415200233459473
test: epoch 92, loss 4.039153575897217, acc=0.05833333358168602, loss=4.039153575897217
train: epoch 93, loss 2.1441071033477783, acc=0.24033333361148834, loss=2.1441071033477783
test: epoch 93, loss 3.8510282039642334, acc=0.06666667014360428, loss=3.8510282039642334
train: epoch 94, loss 2.136385679244995, acc=0.23999999463558197, loss=2.136385679244995
test: epoch 94, loss 3.9754855632781982, acc=0.06388889253139496, loss=3.9754855632781982
train: epoch 95, loss 2.1301467418670654, acc=0.24383333325386047, loss=2.1301467418670654
test: epoch 95, loss 4.014064788818359, acc=0.06666667014360428, loss=4.014064788818359
train: epoch 96, loss 2.1289846897125244, acc=0.2405555546283722, loss=2.1289846897125244
test: epoch 96, loss 3.9613401889801025, acc=0.0694444477558136, loss=3.9613401889801025
train: epoch 97, loss 2.1381399631500244, acc=0.2473333328962326, loss=2.1381399631500244
test: epoch 97, loss 3.914428472518921, acc=0.04722222313284874, loss=3.914428472518921
train: epoch 98, loss 2.126922369003296, acc=0.242166668176651, loss=2.126922369003296
test: epoch 98, loss 4.041872024536133, acc=0.04444444552063942, loss=4.041872024536133
train: epoch 99, loss 2.1394402980804443, acc=0.2430555522441864, loss=2.1394402980804443
test: epoch 99, loss 4.031604290008545, acc=0.05000000074505806, loss=4.031604290008545
train: epoch 100, loss 2.1303179264068604, acc=0.24633333086967468, loss=2.1303179264068604
test: epoch 100, loss 3.8400650024414062, acc=0.05000000074505806, loss=3.8400650024414062
train: epoch 101, loss 2.1142737865448, acc=0.25083333253860474, loss=2.1142737865448
test: epoch 101, loss 3.9564321041107178, acc=0.05000000074505806, loss=3.9564321041107178
train: epoch 102, loss 2.1264700889587402, acc=0.2464444488286972, loss=2.1264700889587402
test: epoch 102, loss 4.051824569702148, acc=0.04444444552063942, loss=4.051824569702148
train: epoch 103, loss 2.1096298694610596, acc=0.24005556106567383, loss=2.1096298694610596
test: epoch 103, loss 3.799727439880371, acc=0.0694444477558136, loss=3.799727439880371
train: epoch 104, loss 2.1163177490234375, acc=0.242166668176651, loss=2.1163177490234375
test: epoch 104, loss 4.081479549407959, acc=0.06388889253139496, loss=4.081479549407959
train: epoch 105, loss 2.114476203918457, acc=0.25038889050483704, loss=2.114476203918457
test: epoch 105, loss 3.945371627807617, acc=0.04722222313284874, loss=3.945371627807617
train: epoch 106, loss 2.0971293449401855, acc=0.248055562376976, loss=2.0971293449401855
test: epoch 106, loss 4.125836372375488, acc=0.04444444552063942, loss=4.125836372375488
train: epoch 107, loss 2.1091480255126953, acc=0.24827778339385986, loss=2.1091480255126953
test: epoch 107, loss 3.9770994186401367, acc=0.04722222313284874, loss=3.9770994186401367
train: epoch 108, loss 2.112412691116333, acc=0.2489444464445114, loss=2.112412691116333
test: epoch 108, loss 3.9774537086486816, acc=0.0694444477558136, loss=3.9774537086486816
train: epoch 109, loss 2.091578960418701, acc=0.24877777695655823, loss=2.091578960418701
test: epoch 109, loss 4.005468368530273, acc=0.04722222313284874, loss=4.005468368530273
train: epoch 110, loss 2.1005160808563232, acc=0.24944444000720978, loss=2.1005160808563232
test: epoch 110, loss 4.085664749145508, acc=0.05000000074505806, loss=4.085664749145508
train: epoch 111, loss 2.098353862762451, acc=0.2508888840675354, loss=2.098353862762451
test: epoch 111, loss 3.9417600631713867, acc=0.06666667014360428, loss=3.9417600631713867
train: epoch 112, loss 2.101663827896118, acc=0.2514444589614868, loss=2.101663827896118
test: epoch 112, loss 3.9677467346191406, acc=0.05000000074505806, loss=3.9677467346191406
train: epoch 113, loss 2.092045783996582, acc=0.2518889009952545, loss=2.092045783996582
test: epoch 113, loss 4.023410320281982, acc=0.0694444477558136, loss=4.023410320281982
train: epoch 114, loss 2.1045830249786377, acc=0.2558888792991638, loss=2.1045830249786377
test: epoch 114, loss 3.861121416091919, acc=0.07222222536802292, loss=3.861121416091919
train: epoch 115, loss 2.091721534729004, acc=0.25866666436195374, loss=2.091721534729004
test: epoch 115, loss 3.996964693069458, acc=0.07222222536802292, loss=3.996964693069458
train: epoch 116, loss 2.076934576034546, acc=0.2529999911785126, loss=2.076934576034546
test: epoch 116, loss 4.141500473022461, acc=0.0555555559694767, loss=4.141500473022461
train: epoch 117, loss 2.072934627532959, acc=0.2545555531978607, loss=2.072934627532959
test: epoch 117, loss 4.068429470062256, acc=0.05277777835726738, loss=4.068429470062256
train: epoch 118, loss 2.073162794113159, acc=0.25822222232818604, loss=2.073162794113159
test: epoch 118, loss 4.152470111846924, acc=0.04722222313284874, loss=4.152470111846924
train: epoch 119, loss 2.074488401412964, acc=0.2554999887943268, loss=2.074488401412964
test: epoch 119, loss 4.174532890319824, acc=0.07222222536802292, loss=4.174532890319824
train: epoch 120, loss 2.0846409797668457, acc=0.2608333230018616, loss=2.0846409797668457
test: epoch 120, loss 4.048325061798096, acc=0.07500000298023224, loss=4.048325061798096
train: epoch 121, loss 2.084495782852173, acc=0.254111111164093, loss=2.084495782852173
test: epoch 121, loss 4.087039947509766, acc=0.0694444477558136, loss=4.087039947509766
train: epoch 122, loss 2.0736892223358154, acc=0.2601666748523712, loss=2.0736892223358154
test: epoch 122, loss 4.073362827301025, acc=0.0694444477558136, loss=4.073362827301025
train: epoch 123, loss 2.0805652141571045, acc=0.25699999928474426, loss=2.0805652141571045
test: epoch 123, loss 3.974306344985962, acc=0.06111111119389534, loss=3.974306344985962
train: epoch 124, loss 2.0636637210845947, acc=0.2581111192703247, loss=2.0636637210845947
test: epoch 124, loss 4.006593704223633, acc=0.05833333358168602, loss=4.006593704223633
train: epoch 125, loss 2.0659878253936768, acc=0.261944442987442, loss=2.0659878253936768
test: epoch 125, loss 4.009150505065918, acc=0.05277777835726738, loss=4.009150505065918
train: epoch 126, loss 2.050509452819824, acc=0.26205554604530334, loss=2.050509452819824
test: epoch 126, loss 4.083685398101807, acc=0.04722222313284874, loss=4.083685398101807
train: epoch 127, loss 2.0709304809570312, acc=0.25894445180892944, loss=2.0709304809570312
test: epoch 127, loss 4.056051254272461, acc=0.07222222536802292, loss=4.056051254272461
train: epoch 128, loss 2.0701537132263184, acc=0.257999986410141, loss=2.0701537132263184
test: epoch 128, loss 3.8349006175994873, acc=0.0694444477558136, loss=3.8349006175994873
train: epoch 129, loss 2.063033103942871, acc=0.25877776741981506, loss=2.063033103942871
test: epoch 129, loss 4.157400131225586, acc=0.05000000074505806, loss=4.157400131225586
train: epoch 130, loss 2.0457355976104736, acc=0.26827776432037354, loss=2.0457355976104736
test: epoch 130, loss 3.956721067428589, acc=0.07222222536802292, loss=3.956721067428589
train: epoch 131, loss 2.048976421356201, acc=0.26144444942474365, loss=2.048976421356201
test: epoch 131, loss 3.91508150100708, acc=0.07500000298023224, loss=3.91508150100708
train: epoch 132, loss 2.0633955001831055, acc=0.2635555565357208, loss=2.0633955001831055
test: epoch 132, loss 3.983785390853882, acc=0.07222222536802292, loss=3.983785390853882
train: epoch 133, loss 2.0377416610717773, acc=0.2686111032962799, loss=2.0377416610717773
test: epoch 133, loss 4.11912727355957, acc=0.07777778059244156, loss=4.11912727355957
train: epoch 134, loss 2.0572550296783447, acc=0.2597777843475342, loss=2.0572550296783447
test: epoch 134, loss 4.09473991394043, acc=0.0694444477558136, loss=4.09473991394043
train: epoch 135, loss 2.0502655506134033, acc=0.26972222328186035, loss=2.0502655506134033
test: epoch 135, loss 3.9753506183624268, acc=0.05000000074505806, loss=3.9753506183624268
train: epoch 136, loss 2.039332866668701, acc=0.2669999897480011, loss=2.039332866668701
test: epoch 136, loss 4.0536274909973145, acc=0.05833333358168602, loss=4.0536274909973145
train: epoch 137, loss 2.045856475830078, acc=0.26544445753097534, loss=2.045856475830078
test: epoch 137, loss 4.213160037994385, acc=0.05277777835726738, loss=4.213160037994385
train: epoch 138, loss 2.041076421737671, acc=0.2681666612625122, loss=2.041076421737671
test: epoch 138, loss 4.174801349639893, acc=0.04444444552063942, loss=4.174801349639893
train: epoch 139, loss 2.0369906425476074, acc=0.2661111056804657, loss=2.0369906425476074
test: epoch 139, loss 4.074244499206543, acc=0.07500000298023224, loss=4.074244499206543
train: epoch 140, loss 2.028597116470337, acc=0.26722222566604614, loss=2.028597116470337
test: epoch 140, loss 4.062350273132324, acc=0.05000000074505806, loss=4.062350273132324
train: epoch 141, loss 2.0330512523651123, acc=0.26427778601646423, loss=2.0330512523651123
test: epoch 141, loss 4.019338130950928, acc=0.05000000074505806, loss=4.019338130950928
train: epoch 142, loss 2.026414155960083, acc=0.26694443821907043, loss=2.026414155960083
test: epoch 142, loss 3.8356094360351562, acc=0.07777778059244156, loss=3.8356094360351562
train: epoch 143, loss 2.0271058082580566, acc=0.2690555453300476, loss=2.0271058082580566
test: epoch 143, loss 4.027377605438232, acc=0.05000000074505806, loss=4.027377605438232
train: epoch 144, loss 2.0218617916107178, acc=0.2717222273349762, loss=2.0218617916107178
test: epoch 144, loss 4.006604194641113, acc=0.07222222536802292, loss=4.006604194641113
train: epoch 145, loss 2.0321497917175293, acc=0.2722777724266052, loss=2.0321497917175293
test: epoch 145, loss 3.876985549926758, acc=0.07500000298023224, loss=3.876985549926758
train: epoch 146, loss 2.008270502090454, acc=0.2690555453300476, loss=2.008270502090454
test: epoch 146, loss 4.018586158752441, acc=0.05833333358168602, loss=4.018586158752441
train: epoch 147, loss 2.0253047943115234, acc=0.2705555558204651, loss=2.0253047943115234
test: epoch 147, loss 3.9447150230407715, acc=0.06111111119389534, loss=3.9447150230407715
train: epoch 148, loss 2.008601427078247, acc=0.2706666588783264, loss=2.008601427078247
test: epoch 148, loss 4.098165512084961, acc=0.05000000074505806, loss=4.098165512084961
train: epoch 149, loss 2.0277082920074463, acc=0.2736666798591614, loss=2.0277082920074463
test: epoch 149, loss 4.081963539123535, acc=0.04444444552063942, loss=4.081963539123535
train: epoch 150, loss 2.0261917114257812, acc=0.2720000147819519, loss=2.0261917114257812
test: epoch 150, loss 3.8857340812683105, acc=0.04444444552063942, loss=3.8857340812683105
