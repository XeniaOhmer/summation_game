# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1", "--temp_decay=1", "--one_hot=true", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1390778297, receiver_embed_dim=32, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.4800984859466553, acc=0.0499444454908371, loss=3.4800984859466553
test: epoch 1, loss 3.580249071121216, acc=0.04722222313284874, loss=3.580249071121216
train: epoch 2, loss 2.952502489089966, acc=0.10305555909872055, loss=2.952502489089966
test: epoch 2, loss 2.5751516819000244, acc=0.12777778506278992, loss=2.5751516819000244
train: epoch 3, loss 2.087775945663452, acc=0.23066666722297668, loss=2.087775945663452
test: epoch 3, loss 2.1150989532470703, acc=0.17222222685813904, loss=2.1150989532470703
train: epoch 4, loss 1.8300148248672485, acc=0.28049999475479126, loss=1.8300148248672485
test: epoch 4, loss 2.122157096862793, acc=0.1805555522441864, loss=2.122157096862793
train: epoch 5, loss 1.6972477436065674, acc=0.32233333587646484, loss=1.6972477436065674
test: epoch 5, loss 2.054311513900757, acc=0.18888889253139496, loss=2.054311513900757
train: epoch 6, loss 1.5965667963027954, acc=0.3587222099304199, loss=1.5965667963027954
test: epoch 6, loss 1.9898700714111328, acc=0.1944444477558136, loss=1.9898700714111328
train: epoch 7, loss 1.5194401741027832, acc=0.39266666769981384, loss=1.5194401741027832
test: epoch 7, loss 2.0216078758239746, acc=0.1944444477558136, loss=2.0216078758239746
train: epoch 8, loss 1.4499472379684448, acc=0.4083888828754425, loss=1.4499472379684448
test: epoch 8, loss 1.938094973564148, acc=0.20000000298023224, loss=1.938094973564148
train: epoch 9, loss 1.3934030532836914, acc=0.43816667795181274, loss=1.3934030532836914
test: epoch 9, loss 1.875793695449829, acc=0.20555555820465088, loss=1.875793695449829
train: epoch 10, loss 1.3521674871444702, acc=0.4560000002384186, loss=1.3521674871444702
test: epoch 10, loss 1.9126440286636353, acc=0.20555555820465088, loss=1.9126440286636353
train: epoch 11, loss 1.312227487564087, acc=0.4639444351196289, loss=1.312227487564087
test: epoch 11, loss 1.9144504070281982, acc=0.21666666865348816, loss=1.9144504070281982
train: epoch 12, loss 1.272550106048584, acc=0.47894445061683655, loss=1.272550106048584
test: epoch 12, loss 1.896421194076538, acc=0.22777777910232544, loss=1.896421194076538
train: epoch 13, loss 1.2399083375930786, acc=0.4987777769565582, loss=1.2399083375930786
test: epoch 13, loss 1.914000153541565, acc=0.2361111044883728, loss=1.914000153541565
train: epoch 14, loss 1.211912989616394, acc=0.5001111030578613, loss=1.211912989616394
test: epoch 14, loss 1.925487995147705, acc=0.24444444477558136, loss=1.925487995147705
train: epoch 15, loss 1.1979893445968628, acc=0.511555552482605, loss=1.1979893445968628
test: epoch 15, loss 1.9476641416549683, acc=0.23055554926395416, loss=1.9476641416549683
train: epoch 16, loss 1.1677603721618652, acc=0.5213888883590698, loss=1.1677603721618652
test: epoch 16, loss 1.8868731260299683, acc=0.25555557012557983, loss=1.8868731260299683
train: epoch 17, loss 1.1556434631347656, acc=0.5225555300712585, loss=1.1556434631347656
test: epoch 17, loss 1.9027022123336792, acc=0.24722221493721008, loss=1.9027022123336792
train: epoch 18, loss 1.1346802711486816, acc=0.5271111130714417, loss=1.1346802711486816
test: epoch 18, loss 1.9232940673828125, acc=0.24444444477558136, loss=1.9232940673828125
train: epoch 19, loss 1.1121459007263184, acc=0.5402222275733948, loss=1.1121459007263184
test: epoch 19, loss 1.9056944847106934, acc=0.24722221493721008, loss=1.9056944847106934
train: epoch 20, loss 1.101493000984192, acc=0.5456110835075378, loss=1.101493000984192
test: epoch 20, loss 1.926361322402954, acc=0.2638888955116272, loss=1.926361322402954
train: epoch 21, loss 1.0855287313461304, acc=0.5514444708824158, loss=1.0855287313461304
test: epoch 21, loss 1.926931619644165, acc=0.25555557012557983, loss=1.926931619644165
train: epoch 22, loss 1.0897616147994995, acc=0.550166666507721, loss=1.0897616147994995
test: epoch 22, loss 1.8999395370483398, acc=0.2527777850627899, loss=1.8999395370483398
train: epoch 23, loss 1.057214617729187, acc=0.5581111311912537, loss=1.057214617729187
test: epoch 23, loss 1.909098505973816, acc=0.25833332538604736, loss=1.909098505973816
train: epoch 24, loss 1.0533312559127808, acc=0.5582777857780457, loss=1.0533312559127808
test: epoch 24, loss 1.8975175619125366, acc=0.2527777850627899, loss=1.8975175619125366
train: epoch 25, loss 1.0445690155029297, acc=0.565833330154419, loss=1.0445690155029297
test: epoch 25, loss 1.9455633163452148, acc=0.25833332538604736, loss=1.9455633163452148
train: epoch 26, loss 1.0341788530349731, acc=0.5672777891159058, loss=1.0341788530349731
test: epoch 26, loss 1.9655450582504272, acc=0.26944443583488464, loss=1.9655450582504272
train: epoch 27, loss 1.0143229961395264, acc=0.5696666836738586, loss=1.0143229961395264
test: epoch 27, loss 1.9529690742492676, acc=0.2527777850627899, loss=1.9529690742492676
train: epoch 28, loss 1.0079325437545776, acc=0.574833333492279, loss=1.0079325437545776
test: epoch 28, loss 2.0385332107543945, acc=0.26944443583488464, loss=2.0385332107543945
train: epoch 29, loss 0.9997581839561462, acc=0.577833354473114, loss=0.9997581839561462
test: epoch 29, loss 2.0332493782043457, acc=0.25833332538604736, loss=2.0332493782043457
train: epoch 30, loss 0.9855929017066956, acc=0.5850555300712585, loss=0.9855929017066956
test: epoch 30, loss 1.9747233390808105, acc=0.25833332538604736, loss=1.9747233390808105
train: epoch 31, loss 0.9849876761436462, acc=0.578499972820282, loss=0.9849876761436462
test: epoch 31, loss 1.9716764688491821, acc=0.2611111104488373, loss=1.9716764688491821
train: epoch 32, loss 0.9805361032485962, acc=0.5844444632530212, loss=0.9805361032485962
test: epoch 32, loss 1.985518217086792, acc=0.2611111104488373, loss=1.985518217086792
train: epoch 33, loss 0.9650894403457642, acc=0.5871111154556274, loss=0.9650894403457642
test: epoch 33, loss 1.991463303565979, acc=0.2638888955116272, loss=1.991463303565979
train: epoch 34, loss 0.9610497355461121, acc=0.5889444351196289, loss=0.9610497355461121
test: epoch 34, loss 1.9900989532470703, acc=0.27222222089767456, loss=1.9900989532470703
train: epoch 35, loss 0.9528502821922302, acc=0.5973888635635376, loss=0.9528502821922302
test: epoch 35, loss 2.008241891860962, acc=0.27222222089767456, loss=2.008241891860962
train: epoch 36, loss 0.9577677249908447, acc=0.5918889045715332, loss=0.9577677249908447
test: epoch 36, loss 2.0593888759613037, acc=0.27222222089767456, loss=2.0593888759613037
train: epoch 37, loss 0.9306641817092896, acc=0.5927222371101379, loss=0.9306641817092896
test: epoch 37, loss 2.0518581867218018, acc=0.26944443583488464, loss=2.0518581867218018
train: epoch 38, loss 0.9110743999481201, acc=0.6014444231987, loss=0.9110743999481201
test: epoch 38, loss 2.0049855709075928, acc=0.2638888955116272, loss=2.0049855709075928
train: epoch 39, loss 0.9200155735015869, acc=0.6042222380638123, loss=0.9200155735015869
test: epoch 39, loss 2.0853450298309326, acc=0.2777777910232544, loss=2.0853450298309326
train: epoch 40, loss 0.9109019041061401, acc=0.6060555577278137, loss=0.9109019041061401
test: epoch 40, loss 1.9798262119293213, acc=0.26944443583488464, loss=1.9798262119293213
train: epoch 41, loss 0.910446047782898, acc=0.6060000061988831, loss=0.910446047782898
test: epoch 41, loss 2.0317177772521973, acc=0.2777777910232544, loss=2.0317177772521973
train: epoch 42, loss 0.9002577662467957, acc=0.6063888669013977, loss=0.9002577662467957
test: epoch 42, loss 1.9648302793502808, acc=0.26944443583488464, loss=1.9648302793502808
train: epoch 43, loss 0.8893515467643738, acc=0.6106111407279968, loss=0.8893515467643738
test: epoch 43, loss 2.0714449882507324, acc=0.2777777910232544, loss=2.0714449882507324
train: epoch 44, loss 0.8906859755516052, acc=0.6086666584014893, loss=0.8906859755516052
test: epoch 44, loss 1.9640432596206665, acc=0.2750000059604645, loss=1.9640432596206665
train: epoch 45, loss 0.8852559924125671, acc=0.6159444451332092, loss=0.8852559924125671
test: epoch 45, loss 1.9940838813781738, acc=0.2666666805744171, loss=1.9940838813781738
train: epoch 46, loss 0.8691939115524292, acc=0.6178333163261414, loss=0.8691939115524292
test: epoch 46, loss 1.9383472204208374, acc=0.2888889014720917, loss=1.9383472204208374
train: epoch 47, loss 0.8792738318443298, acc=0.6150000095367432, loss=0.8792738318443298
test: epoch 47, loss 2.0338945388793945, acc=0.2777777910232544, loss=2.0338945388793945
train: epoch 48, loss 0.8663245439529419, acc=0.6161110997200012, loss=0.8663245439529419
test: epoch 48, loss 2.087573528289795, acc=0.28333333134651184, loss=2.087573528289795
train: epoch 49, loss 0.8585554957389832, acc=0.6209999918937683, loss=0.8585554957389832
test: epoch 49, loss 2.0927412509918213, acc=0.28333333134651184, loss=2.0927412509918213
train: epoch 50, loss 0.8572267889976501, acc=0.6192222237586975, loss=0.8572267889976501
test: epoch 50, loss 1.992466926574707, acc=0.28611111640930176, loss=1.992466926574707
train: epoch 51, loss 0.8537169098854065, acc=0.6241666674613953, loss=0.8537169098854065
test: epoch 51, loss 2.116589307785034, acc=0.2777777910232544, loss=2.116589307785034
train: epoch 52, loss 0.860029399394989, acc=0.6203888654708862, loss=0.860029399394989
test: epoch 52, loss 1.9613590240478516, acc=0.2805555462837219, loss=1.9613590240478516
train: epoch 53, loss 0.8480872511863708, acc=0.625166654586792, loss=0.8480872511863708
test: epoch 53, loss 2.0474627017974854, acc=0.28333333134651184, loss=2.0474627017974854
train: epoch 54, loss 0.8508220911026001, acc=0.621999979019165, loss=0.8508220911026001
test: epoch 54, loss 2.037691354751587, acc=0.2916666567325592, loss=2.037691354751587
train: epoch 55, loss 0.8450427055358887, acc=0.6322222352027893, loss=0.8450427055358887
test: epoch 55, loss 2.054027795791626, acc=0.28333333134651184, loss=2.054027795791626
train: epoch 56, loss 0.8508351445198059, acc=0.6259999871253967, loss=0.8508351445198059
test: epoch 56, loss 2.008920669555664, acc=0.2916666567325592, loss=2.008920669555664
train: epoch 57, loss 0.823294460773468, acc=0.632777750492096, loss=0.823294460773468
test: epoch 57, loss 2.115133285522461, acc=0.2888889014720917, loss=2.115133285522461
train: epoch 58, loss 0.8222520351409912, acc=0.6388888955116272, loss=0.8222520351409912
test: epoch 58, loss 2.047278642654419, acc=0.2944444417953491, loss=2.047278642654419
train: epoch 59, loss 0.8136793375015259, acc=0.6401666402816772, loss=0.8136793375015259
test: epoch 59, loss 2.110996961593628, acc=0.2777777910232544, loss=2.110996961593628
train: epoch 60, loss 0.8289137482643127, acc=0.6422777771949768, loss=0.8289137482643127
test: epoch 60, loss 1.948533296585083, acc=0.28611111640930176, loss=1.948533296585083
train: epoch 61, loss 0.8075461387634277, acc=0.640500009059906, loss=0.8075461387634277
test: epoch 61, loss 2.051208972930908, acc=0.2916666567325592, loss=2.051208972930908
train: epoch 62, loss 0.8033763766288757, acc=0.6426666378974915, loss=0.8033763766288757
test: epoch 62, loss 2.175879955291748, acc=0.28333333134651184, loss=2.175879955291748
train: epoch 63, loss 0.799157440662384, acc=0.6472222208976746, loss=0.799157440662384
test: epoch 63, loss 2.134779691696167, acc=0.2916666567325592, loss=2.134779691696167
train: epoch 64, loss 0.799589991569519, acc=0.6466110944747925, loss=0.799589991569519
test: epoch 64, loss 2.2083423137664795, acc=0.30000001192092896, loss=2.2083423137664795
train: epoch 65, loss 0.8124797344207764, acc=0.6416110992431641, loss=0.8124797344207764
test: epoch 65, loss 2.039027452468872, acc=0.2916666567325592, loss=2.039027452468872
train: epoch 66, loss 0.7932883501052856, acc=0.6513333320617676, loss=0.7932883501052856
test: epoch 66, loss 2.1502578258514404, acc=0.2944444417953491, loss=2.1502578258514404
train: epoch 67, loss 0.7915247678756714, acc=0.6503888964653015, loss=0.7915247678756714
test: epoch 67, loss 2.125605344772339, acc=0.2916666567325592, loss=2.125605344772339
train: epoch 68, loss 0.7976444363594055, acc=0.6520000100135803, loss=0.7976444363594055
test: epoch 68, loss 2.2012202739715576, acc=0.2916666567325592, loss=2.2012202739715576
train: epoch 69, loss 0.7923905253410339, acc=0.6543333530426025, loss=0.7923905253410339
test: epoch 69, loss 2.132904052734375, acc=0.3027777671813965, loss=2.132904052734375
train: epoch 70, loss 0.7837895750999451, acc=0.6568333506584167, loss=0.7837895750999451
test: epoch 70, loss 2.1029765605926514, acc=0.30000001192092896, loss=2.1029765605926514
train: epoch 71, loss 0.7747469544410706, acc=0.6554444432258606, loss=0.7747469544410706
test: epoch 71, loss 2.089226722717285, acc=0.3027777671813965, loss=2.089226722717285
train: epoch 72, loss 0.7722768783569336, acc=0.6622222065925598, loss=0.7722768783569336
test: epoch 72, loss 2.115163564682007, acc=0.2916666567325592, loss=2.115163564682007
train: epoch 73, loss 0.7808485627174377, acc=0.656333327293396, loss=0.7808485627174377
test: epoch 73, loss 2.0764453411102295, acc=0.2944444417953491, loss=2.0764453411102295
train: epoch 74, loss 0.7645894289016724, acc=0.6656110882759094, loss=0.7645894289016724
test: epoch 74, loss 2.1071617603302, acc=0.30000001192092896, loss=2.1071617603302
train: epoch 75, loss 0.770997941493988, acc=0.6661666631698608, loss=0.770997941493988
test: epoch 75, loss 2.0424892902374268, acc=0.30000001192092896, loss=2.0424892902374268
train: epoch 76, loss 0.7616913318634033, acc=0.6717222332954407, loss=0.7616913318634033
test: epoch 76, loss 2.0886447429656982, acc=0.30000001192092896, loss=2.0886447429656982
train: epoch 77, loss 0.7542860507965088, acc=0.6683333516120911, loss=0.7542860507965088
test: epoch 77, loss 2.0148322582244873, acc=0.30000001192092896, loss=2.0148322582244873
train: epoch 78, loss 0.7613021731376648, acc=0.6689444184303284, loss=0.7613021731376648
test: epoch 78, loss 2.123755931854248, acc=0.2888889014720917, loss=2.123755931854248
train: epoch 79, loss 0.7492830157279968, acc=0.6731111407279968, loss=0.7492830157279968
test: epoch 79, loss 2.258321523666382, acc=0.30000001192092896, loss=2.258321523666382
train: epoch 80, loss 0.7550132870674133, acc=0.6710000038146973, loss=0.7550132870674133
test: epoch 80, loss 2.081441879272461, acc=0.3055555522441864, loss=2.081441879272461
train: epoch 81, loss 0.7454504370689392, acc=0.671833336353302, loss=0.7454504370689392
test: epoch 81, loss 2.0897397994995117, acc=0.3083333373069763, loss=2.0897397994995117
train: epoch 82, loss 0.7347531914710999, acc=0.6759999990463257, loss=0.7347531914710999
test: epoch 82, loss 2.064795970916748, acc=0.3083333373069763, loss=2.064795970916748
train: epoch 83, loss 0.7368384003639221, acc=0.6739444732666016, loss=0.7368384003639221
test: epoch 83, loss 2.0410454273223877, acc=0.3083333373069763, loss=2.0410454273223877
train: epoch 84, loss 0.7250499725341797, acc=0.6781666874885559, loss=0.7250499725341797
test: epoch 84, loss 2.269916296005249, acc=0.31111112236976624, loss=2.269916296005249
train: epoch 85, loss 0.7386599183082581, acc=0.6841111183166504, loss=0.7386599183082581
test: epoch 85, loss 2.1490206718444824, acc=0.3083333373069763, loss=2.1490206718444824
train: epoch 86, loss 0.7212396860122681, acc=0.6856111288070679, loss=0.7212396860122681
test: epoch 86, loss 2.078648567199707, acc=0.3166666626930237, loss=2.078648567199707
train: epoch 87, loss 0.7249054312705994, acc=0.6812777519226074, loss=0.7249054312705994
test: epoch 87, loss 2.2249197959899902, acc=0.3083333373069763, loss=2.2249197959899902
train: epoch 88, loss 0.72404944896698, acc=0.6802777647972107, loss=0.72404944896698
test: epoch 88, loss 2.156085968017578, acc=0.3027777671813965, loss=2.156085968017578
train: epoch 89, loss 0.72236567735672, acc=0.6790000200271606, loss=0.72236567735672
test: epoch 89, loss 2.145923376083374, acc=0.3083333373069763, loss=2.145923376083374
train: epoch 90, loss 0.7187378406524658, acc=0.6826111078262329, loss=0.7187378406524658
test: epoch 90, loss 2.251368284225464, acc=0.3194444477558136, loss=2.251368284225464
train: epoch 91, loss 0.716533362865448, acc=0.6845555305480957, loss=0.716533362865448
test: epoch 91, loss 2.2011330127716064, acc=0.31111112236976624, loss=2.2011330127716064
train: epoch 92, loss 0.7078191637992859, acc=0.6897222399711609, loss=0.7078191637992859
test: epoch 92, loss 2.2107486724853516, acc=0.3166666626930237, loss=2.2107486724853516
train: epoch 93, loss 0.7082710266113281, acc=0.6885555386543274, loss=0.7082710266113281
test: epoch 93, loss 2.0894534587860107, acc=0.3083333373069763, loss=2.0894534587860107
train: epoch 94, loss 0.7077645659446716, acc=0.6872777938842773, loss=0.7077645659446716
test: epoch 94, loss 2.138728618621826, acc=0.3222222328186035, loss=2.138728618621826
train: epoch 95, loss 0.7150410413742065, acc=0.6855555772781372, loss=0.7150410413742065
test: epoch 95, loss 2.1010918617248535, acc=0.31111112236976624, loss=2.1010918617248535
train: epoch 96, loss 0.7041465640068054, acc=0.6903889179229736, loss=0.7041465640068054
test: epoch 96, loss 2.1715080738067627, acc=0.3166666626930237, loss=2.1715080738067627
train: epoch 97, loss 0.6994175910949707, acc=0.691944420337677, loss=0.6994175910949707
test: epoch 97, loss 2.012744426727295, acc=0.31388887763023376, loss=2.012744426727295
train: epoch 98, loss 0.6981319785118103, acc=0.6942222118377686, loss=0.6981319785118103
test: epoch 98, loss 2.2281148433685303, acc=0.31111112236976624, loss=2.2281148433685303
train: epoch 99, loss 0.6928493976593018, acc=0.6982222199440002, loss=0.6928493976593018
test: epoch 99, loss 2.1931185722351074, acc=0.3194444477558136, loss=2.1931185722351074
train: epoch 100, loss 0.6891699433326721, acc=0.6934444308280945, loss=0.6891699433326721
test: epoch 100, loss 2.0558559894561768, acc=0.32499998807907104, loss=2.0558559894561768
train: epoch 101, loss 0.6925100088119507, acc=0.6917222142219543, loss=0.6925100088119507
test: epoch 101, loss 2.161229372024536, acc=0.3305555582046509, loss=2.161229372024536
train: epoch 102, loss 0.6938214898109436, acc=0.6944444179534912, loss=0.6938214898109436
test: epoch 102, loss 2.1518735885620117, acc=0.3166666626930237, loss=2.1518735885620117
train: epoch 103, loss 0.683509886264801, acc=0.7034444212913513, loss=0.683509886264801
test: epoch 103, loss 2.233555316925049, acc=0.31388887763023376, loss=2.233555316925049
train: epoch 104, loss 0.6939685344696045, acc=0.6942777633666992, loss=0.6939685344696045
test: epoch 104, loss 2.137594223022461, acc=0.3166666626930237, loss=2.137594223022461
train: epoch 105, loss 0.6848050951957703, acc=0.7007777690887451, loss=0.6848050951957703
test: epoch 105, loss 2.1526296138763428, acc=0.3166666626930237, loss=2.1526296138763428
train: epoch 106, loss 0.6759636998176575, acc=0.7044444680213928, loss=0.6759636998176575
test: epoch 106, loss 2.217676877975464, acc=0.32777777314186096, loss=2.217676877975464
train: epoch 107, loss 0.6682989001274109, acc=0.7043889164924622, loss=0.6682989001274109
test: epoch 107, loss 2.127288579940796, acc=0.32777777314186096, loss=2.127288579940796
train: epoch 108, loss 0.6706326007843018, acc=0.7064444422721863, loss=0.6706326007843018
test: epoch 108, loss 2.2678427696228027, acc=0.32777777314186096, loss=2.2678427696228027
train: epoch 109, loss 0.6834230422973633, acc=0.7026110887527466, loss=0.6834230422973633
test: epoch 109, loss 2.084134340286255, acc=0.3333333432674408, loss=2.084134340286255
train: epoch 110, loss 0.6630714535713196, acc=0.7092777490615845, loss=0.6630714535713196
test: epoch 110, loss 2.1425111293792725, acc=0.3222222328186035, loss=2.1425111293792725
train: epoch 111, loss 0.6602213382720947, acc=0.7066110968589783, loss=0.6602213382720947
test: epoch 111, loss 2.155317544937134, acc=0.3305555582046509, loss=2.155317544937134
train: epoch 112, loss 0.6701428294181824, acc=0.7070555686950684, loss=0.6701428294181824
test: epoch 112, loss 2.2577667236328125, acc=0.3361110985279083, loss=2.2577667236328125
train: epoch 113, loss 0.6567278504371643, acc=0.7113333344459534, loss=0.6567278504371643
test: epoch 113, loss 2.1260101795196533, acc=0.3333333432674408, loss=2.1260101795196533
train: epoch 114, loss 0.6488955616950989, acc=0.7123333215713501, loss=0.6488955616950989
test: epoch 114, loss 2.1297953128814697, acc=0.33888888359069824, loss=2.1297953128814697
train: epoch 115, loss 0.6509039998054504, acc=0.7149999737739563, loss=0.6509039998054504
test: epoch 115, loss 2.2061398029327393, acc=0.3305555582046509, loss=2.2061398029327393
train: epoch 116, loss 0.6552885174751282, acc=0.7131666541099548, loss=0.6552885174751282
test: epoch 116, loss 2.1518325805664062, acc=0.3333333432674408, loss=2.1518325805664062
train: epoch 117, loss 0.6470372676849365, acc=0.7184444665908813, loss=0.6470372676849365
test: epoch 117, loss 2.342823028564453, acc=0.32777777314186096, loss=2.342823028564453
train: epoch 118, loss 0.6420204043388367, acc=0.7176111340522766, loss=0.6420204043388367
test: epoch 118, loss 2.0777673721313477, acc=0.33888888359069824, loss=2.0777673721313477
train: epoch 119, loss 0.637457013130188, acc=0.7179999947547913, loss=0.637457013130188
test: epoch 119, loss 2.2337982654571533, acc=0.33888888359069824, loss=2.2337982654571533
train: epoch 120, loss 0.6399043798446655, acc=0.7187777757644653, loss=0.6399043798446655
test: epoch 120, loss 2.240417718887329, acc=0.3305555582046509, loss=2.240417718887329
train: epoch 121, loss 0.6433297991752625, acc=0.7181666493415833, loss=0.6433297991752625
test: epoch 121, loss 2.2413058280944824, acc=0.34166666865348816, loss=2.2413058280944824
train: epoch 122, loss 0.6434726715087891, acc=0.7186111211776733, loss=0.6434726715087891
test: epoch 122, loss 2.101482629776001, acc=0.3444444537162781, loss=2.101482629776001
train: epoch 123, loss 0.6528060436248779, acc=0.7168333530426025, loss=0.6528060436248779
test: epoch 123, loss 2.0971438884735107, acc=0.3361110985279083, loss=2.0971438884735107
train: epoch 124, loss 0.6284529566764832, acc=0.722777783870697, loss=0.6284529566764832
test: epoch 124, loss 2.2963054180145264, acc=0.3472222089767456, loss=2.2963054180145264
train: epoch 125, loss 0.6302922964096069, acc=0.719944417476654, loss=0.6302922964096069
test: epoch 125, loss 2.0873382091522217, acc=0.3444444537162781, loss=2.0873382091522217
train: epoch 126, loss 0.63486647605896, acc=0.7208333611488342, loss=0.63486647605896
test: epoch 126, loss 2.0306236743927, acc=0.34166666865348816, loss=2.0306236743927
train: epoch 127, loss 0.6285009384155273, acc=0.7232221961021423, loss=0.6285009384155273
test: epoch 127, loss 2.0890090465545654, acc=0.33888888359069824, loss=2.0890090465545654
train: epoch 128, loss 0.6287521719932556, acc=0.7250555753707886, loss=0.6287521719932556
test: epoch 128, loss 2.1679189205169678, acc=0.3499999940395355, loss=2.1679189205169678
train: epoch 129, loss 0.6301565170288086, acc=0.7212777733802795, loss=0.6301565170288086
test: epoch 129, loss 2.037856101989746, acc=0.3444444537162781, loss=2.037856101989746
train: epoch 130, loss 0.6234014630317688, acc=0.7245555520057678, loss=0.6234014630317688
test: epoch 130, loss 2.333801031112671, acc=0.3083333373069763, loss=2.333801031112671
train: epoch 131, loss 0.6214790940284729, acc=0.7228888869285583, loss=0.6214790940284729
test: epoch 131, loss 2.1217617988586426, acc=0.3444444537162781, loss=2.1217617988586426
train: epoch 132, loss 0.6162830591201782, acc=0.7266666889190674, loss=0.6162830591201782
test: epoch 132, loss 2.024653673171997, acc=0.3444444537162781, loss=2.024653673171997
train: epoch 133, loss 0.6104786992073059, acc=0.7251666784286499, loss=0.6104786992073059
test: epoch 133, loss 2.102917194366455, acc=0.3583333194255829, loss=2.102917194366455
train: epoch 134, loss 0.6169654726982117, acc=0.7320555448532104, loss=0.6169654726982117
test: epoch 134, loss 2.208878517150879, acc=0.3444444537162781, loss=2.208878517150879
train: epoch 135, loss 0.6050585508346558, acc=0.7333333492279053, loss=0.6050585508346558
test: epoch 135, loss 2.1722824573516846, acc=0.3444444537162781, loss=2.1722824573516846
train: epoch 136, loss 0.600102424621582, acc=0.7306110858917236, loss=0.600102424621582
test: epoch 136, loss 2.071492910385132, acc=0.3472222089767456, loss=2.071492910385132
train: epoch 137, loss 0.6046002507209778, acc=0.7297222018241882, loss=0.6046002507209778
test: epoch 137, loss 2.0692381858825684, acc=0.33888888359069824, loss=2.0692381858825684
train: epoch 138, loss 0.6048251986503601, acc=0.7322777509689331, loss=0.6048251986503601
test: epoch 138, loss 2.148226022720337, acc=0.35555556416511536, loss=2.148226022720337
train: epoch 139, loss 0.5951816439628601, acc=0.7354444265365601, loss=0.5951816439628601
test: epoch 139, loss 2.1732051372528076, acc=0.3333333432674408, loss=2.1732051372528076
train: epoch 140, loss 0.6024366021156311, acc=0.7321666479110718, loss=0.6024366021156311
test: epoch 140, loss 2.16483473777771, acc=0.3444444537162781, loss=2.16483473777771
train: epoch 141, loss 0.6062192320823669, acc=0.7312777638435364, loss=0.6062192320823669
test: epoch 141, loss 2.1740996837615967, acc=0.3472222089767456, loss=2.1740996837615967
train: epoch 142, loss 0.5946173071861267, acc=0.7359444499015808, loss=0.5946173071861267
test: epoch 142, loss 2.1007204055786133, acc=0.3499999940395355, loss=2.1007204055786133
train: epoch 143, loss 0.6022931933403015, acc=0.7350555658340454, loss=0.6022931933403015
test: epoch 143, loss 2.0871121883392334, acc=0.3611111044883728, loss=2.0871121883392334
train: epoch 144, loss 0.5936558842658997, acc=0.7418888807296753, loss=0.5936558842658997
test: epoch 144, loss 2.1254875659942627, acc=0.34166666865348816, loss=2.1254875659942627
train: epoch 145, loss 0.6032208204269409, acc=0.7365000247955322, loss=0.6032208204269409
test: epoch 145, loss 1.9380992650985718, acc=0.3583333194255829, loss=1.9380992650985718
train: epoch 146, loss 0.5762317180633545, acc=0.7429444193840027, loss=0.5762317180633545
test: epoch 146, loss 2.0296878814697266, acc=0.3444444537162781, loss=2.0296878814697266
train: epoch 147, loss 0.5847176313400269, acc=0.7401666641235352, loss=0.5847176313400269
test: epoch 147, loss 2.2175955772399902, acc=0.3472222089767456, loss=2.2175955772399902
train: epoch 148, loss 0.6044199466705322, acc=0.7346110939979553, loss=0.6044199466705322
test: epoch 148, loss 2.099524974822998, acc=0.35555556416511536, loss=2.099524974822998
train: epoch 149, loss 0.5944855213165283, acc=0.7356111407279968, loss=0.5944855213165283
test: epoch 149, loss 2.2101645469665527, acc=0.3499999940395355, loss=2.2101645469665527
train: epoch 150, loss 0.5807536840438843, acc=0.7420555353164673, loss=0.5807536840438843
test: epoch 150, loss 2.270840883255005, acc=0.35277777910232544, loss=2.270840883255005
