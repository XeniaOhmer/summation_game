# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=1.5", "--temp_decay=0.99", "--one_hot=true", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=216520107, receiver_embed_dim=64, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.276986837387085, acc=0.06583333015441895, loss=3.276986837387085
test: epoch 1, loss 2.9917056560516357, acc=0.09166666865348816, loss=2.9917056560516357
train: epoch 2, loss 1.9490301609039307, acc=0.25244444608688354, loss=1.9490301609039307
test: epoch 2, loss 2.408384323120117, acc=0.16111111640930176, loss=2.408384323120117
train: epoch 3, loss 1.5604945421218872, acc=0.3690555691719055, loss=1.5604945421218872
test: epoch 3, loss 2.3301424980163574, acc=0.1944444477558136, loss=2.3301424980163574
train: epoch 4, loss 1.3832602500915527, acc=0.43461111187934875, loss=1.3832602500915527
test: epoch 4, loss 2.352337598800659, acc=0.19166666269302368, loss=2.352337598800659
train: epoch 5, loss 1.2834079265594482, acc=0.4756111204624176, loss=1.2834079265594482
test: epoch 5, loss 2.2597734928131104, acc=0.18888889253139496, loss=2.2597734928131104
train: epoch 6, loss 1.2035611867904663, acc=0.5093333125114441, loss=1.2035611867904663
test: epoch 6, loss 2.1737215518951416, acc=0.21111111342906952, loss=2.1737215518951416
train: epoch 7, loss 1.1340659856796265, acc=0.5440000295639038, loss=1.1340659856796265
test: epoch 7, loss 2.135749101638794, acc=0.2361111044883728, loss=2.135749101638794
train: epoch 8, loss 1.0731468200683594, acc=0.5698888897895813, loss=1.0731468200683594
test: epoch 8, loss 2.211303234100342, acc=0.23055554926395416, loss=2.211303234100342
train: epoch 9, loss 1.011107325553894, acc=0.590666651725769, loss=1.011107325553894
test: epoch 9, loss 2.0473742485046387, acc=0.24444444477558136, loss=2.0473742485046387
train: epoch 10, loss 0.9726793766021729, acc=0.6098889112472534, loss=0.9726793766021729
test: epoch 10, loss 1.9543392658233643, acc=0.30000001192092896, loss=1.9543392658233643
train: epoch 11, loss 0.9285937547683716, acc=0.628777801990509, loss=0.9285937547683716
test: epoch 11, loss 1.8990079164505005, acc=0.2944444417953491, loss=1.8990079164505005
train: epoch 12, loss 0.8992006778717041, acc=0.6402778029441833, loss=0.8992006778717041
test: epoch 12, loss 2.002802848815918, acc=0.3027777671813965, loss=2.002802848815918
train: epoch 13, loss 0.8627500534057617, acc=0.6568333506584167, loss=0.8627500534057617
test: epoch 13, loss 1.8489265441894531, acc=0.2944444417953491, loss=1.8489265441894531
train: epoch 14, loss 0.8372295498847961, acc=0.6700000166893005, loss=0.8372295498847961
test: epoch 14, loss 1.8500313758850098, acc=0.3194444477558136, loss=1.8500313758850098
train: epoch 15, loss 0.8223928809165955, acc=0.679611086845398, loss=0.8223928809165955
test: epoch 15, loss 1.815112829208374, acc=0.33888888359069824, loss=1.815112829208374
train: epoch 16, loss 0.7840999960899353, acc=0.6913889050483704, loss=0.7840999960899353
test: epoch 16, loss 1.8140257596969604, acc=0.31388887763023376, loss=1.8140257596969604
train: epoch 17, loss 0.7653133273124695, acc=0.7020555734634399, loss=0.7653133273124695
test: epoch 17, loss 1.6909366846084595, acc=0.35277777910232544, loss=1.6909366846084595
train: epoch 18, loss 0.7339550256729126, acc=0.7177222371101379, loss=0.7339550256729126
test: epoch 18, loss 1.7388797998428345, acc=0.32777777314186096, loss=1.7388797998428345
train: epoch 19, loss 0.7210541367530823, acc=0.7160555720329285, loss=0.7210541367530823
test: epoch 19, loss 1.757385492324829, acc=0.3055555522441864, loss=1.757385492324829
train: epoch 20, loss 0.7002324461936951, acc=0.7216110825538635, loss=0.7002324461936951
test: epoch 20, loss 1.6743491888046265, acc=0.375, loss=1.6743491888046265
train: epoch 21, loss 0.681469738483429, acc=0.733222246170044, loss=0.681469738483429
test: epoch 21, loss 1.6784697771072388, acc=0.32777777314186096, loss=1.6784697771072388
train: epoch 22, loss 0.6726565361022949, acc=0.7342777848243713, loss=0.6726565361022949
test: epoch 22, loss 1.6066627502441406, acc=0.375, loss=1.6066627502441406
train: epoch 23, loss 0.6549951434135437, acc=0.7463333606719971, loss=0.6549951434135437
test: epoch 23, loss 1.480601191520691, acc=0.3888888955116272, loss=1.480601191520691
train: epoch 24, loss 0.6255491971969604, acc=0.7559999823570251, loss=0.6255491971969604
test: epoch 24, loss 1.4821996688842773, acc=0.40833333134651184, loss=1.4821996688842773
train: epoch 25, loss 0.6285220384597778, acc=0.7546666860580444, loss=0.6285220384597778
test: epoch 25, loss 1.6693326234817505, acc=0.3638888895511627, loss=1.6693326234817505
train: epoch 26, loss 0.6174365282058716, acc=0.7607777714729309, loss=0.6174365282058716
test: epoch 26, loss 1.4905880689620972, acc=0.40833333134651184, loss=1.4905880689620972
train: epoch 27, loss 0.5897455811500549, acc=0.7718889117240906, loss=0.5897455811500549
test: epoch 27, loss 1.4424872398376465, acc=0.41111111640930176, loss=1.4424872398376465
train: epoch 28, loss 0.5786969661712646, acc=0.7761111259460449, loss=0.5786969661712646
test: epoch 28, loss 1.4640884399414062, acc=0.4138889014720917, loss=1.4640884399414062
train: epoch 29, loss 0.5762042999267578, acc=0.781333327293396, loss=0.5762042999267578
test: epoch 29, loss 1.4781512022018433, acc=0.39722222089767456, loss=1.4781512022018433
train: epoch 30, loss 0.5727633237838745, acc=0.7746111154556274, loss=0.5727633237838745
test: epoch 30, loss 1.3966385126113892, acc=0.42500001192092896, loss=1.3966385126113892
train: epoch 31, loss 0.5636592507362366, acc=0.7848888635635376, loss=0.5636592507362366
test: epoch 31, loss 1.4135438203811646, acc=0.42500001192092896, loss=1.4135438203811646
train: epoch 32, loss 0.5444855690002441, acc=0.7921110987663269, loss=0.5444855690002441
test: epoch 32, loss 1.452294111251831, acc=0.4027777910232544, loss=1.452294111251831
train: epoch 33, loss 0.5334461331367493, acc=0.7952777743339539, loss=0.5334461331367493
test: epoch 33, loss 1.4536948204040527, acc=0.42500001192092896, loss=1.4536948204040527
train: epoch 34, loss 0.5341188311576843, acc=0.7951111197471619, loss=0.5341188311576843
test: epoch 34, loss 1.3108528852462769, acc=0.4444444477558136, loss=1.3108528852462769
train: epoch 35, loss 0.5356264114379883, acc=0.7931110858917236, loss=0.5356264114379883
test: epoch 35, loss 1.289803147315979, acc=0.4166666567325592, loss=1.289803147315979
train: epoch 36, loss 0.5123657584190369, acc=0.8043333292007446, loss=0.5123657584190369
test: epoch 36, loss 1.2839884757995605, acc=0.43611112236976624, loss=1.2839884757995605
train: epoch 37, loss 0.5093581080436707, acc=0.8095555305480957, loss=0.5093581080436707
test: epoch 37, loss 1.2857526540756226, acc=0.4305555522441864, loss=1.2857526540756226
train: epoch 38, loss 0.4972209632396698, acc=0.8153333067893982, loss=0.4972209632396698
test: epoch 38, loss 1.3596739768981934, acc=0.4333333373069763, loss=1.3596739768981934
train: epoch 39, loss 0.4962187707424164, acc=0.8103888630867004, loss=0.4962187707424164
test: epoch 39, loss 1.3646526336669922, acc=0.4694444537162781, loss=1.3646526336669922
train: epoch 40, loss 0.4910571575164795, acc=0.8145555257797241, loss=0.4910571575164795
test: epoch 40, loss 1.37985098361969, acc=0.46388888359069824, loss=1.37985098361969
train: epoch 41, loss 0.4917272627353668, acc=0.8163333535194397, loss=0.4917272627353668
test: epoch 41, loss 1.429711937904358, acc=0.4555555582046509, loss=1.429711937904358
train: epoch 42, loss 0.4732610285282135, acc=0.8238333463668823, loss=0.4732610285282135
test: epoch 42, loss 1.4324076175689697, acc=0.4611110985279083, loss=1.4324076175689697
train: epoch 43, loss 0.48019909858703613, acc=0.8240000009536743, loss=0.48019909858703613
test: epoch 43, loss 1.3055704832077026, acc=0.4722222089767456, loss=1.3055704832077026
train: epoch 44, loss 0.4663458466529846, acc=0.8276110887527466, loss=0.4663458466529846
test: epoch 44, loss 1.3033411502838135, acc=0.4861111044883728, loss=1.3033411502838135
train: epoch 45, loss 0.4659516513347626, acc=0.8287222385406494, loss=0.4659516513347626
test: epoch 45, loss 1.4299910068511963, acc=0.4611110985279083, loss=1.4299910068511963
train: epoch 46, loss 0.4491594731807709, acc=0.832111120223999, loss=0.4491594731807709
test: epoch 46, loss 1.3932511806488037, acc=0.4888888895511627, loss=1.3932511806488037
train: epoch 47, loss 0.4437420070171356, acc=0.8333333134651184, loss=0.4437420070171356
test: epoch 47, loss 1.3904889822006226, acc=0.48055556416511536, loss=1.3904889822006226
train: epoch 48, loss 0.45393073558807373, acc=0.8331666588783264, loss=0.45393073558807373
test: epoch 48, loss 1.342065691947937, acc=0.5, loss=1.342065691947937
train: epoch 49, loss 0.4569927155971527, acc=0.8310555815696716, loss=0.4569927155971527
test: epoch 49, loss 1.3282486200332642, acc=0.5166666507720947, loss=1.3282486200332642
train: epoch 50, loss 0.4542129337787628, acc=0.8305555582046509, loss=0.4542129337787628
test: epoch 50, loss 1.3284355401992798, acc=0.5083333253860474, loss=1.3284355401992798
train: epoch 51, loss 0.43176794052124023, acc=0.8401111364364624, loss=0.43176794052124023
test: epoch 51, loss 1.3996905088424683, acc=0.5166666507720947, loss=1.3996905088424683
train: epoch 52, loss 0.4377634823322296, acc=0.8358333110809326, loss=0.4377634823322296
test: epoch 52, loss 1.3786498308181763, acc=0.5111111402511597, loss=1.3786498308181763
train: epoch 53, loss 0.4290561079978943, acc=0.8418333530426025, loss=0.4290561079978943
test: epoch 53, loss 1.351380467414856, acc=0.5055555701255798, loss=1.351380467414856
train: epoch 54, loss 0.42487606406211853, acc=0.8436111211776733, loss=0.42487606406211853
test: epoch 54, loss 1.3865097761154175, acc=0.5166666507720947, loss=1.3865097761154175
train: epoch 55, loss 0.4359332025051117, acc=0.8428333401679993, loss=0.4359332025051117
test: epoch 55, loss 1.3248224258422852, acc=0.5222222208976746, loss=1.3248224258422852
train: epoch 56, loss 0.4354996383190155, acc=0.8385555744171143, loss=0.4354996383190155
test: epoch 56, loss 1.3314895629882812, acc=0.5166666507720947, loss=1.3314895629882812
train: epoch 57, loss 0.42308729887008667, acc=0.8428888916969299, loss=0.42308729887008667
test: epoch 57, loss 1.2336875200271606, acc=0.5361111164093018, loss=1.2336875200271606
train: epoch 58, loss 0.41767194867134094, acc=0.8429999947547913, loss=0.41767194867134094
test: epoch 58, loss 1.3569008111953735, acc=0.519444465637207, loss=1.3569008111953735
train: epoch 59, loss 0.4291796088218689, acc=0.8430555462837219, loss=0.4291796088218689
test: epoch 59, loss 1.326651692390442, acc=0.5166666507720947, loss=1.326651692390442
train: epoch 60, loss 0.41125279664993286, acc=0.8439444303512573, loss=0.41125279664993286
test: epoch 60, loss 1.4636722803115845, acc=0.5305555462837219, loss=1.4636722803115845
train: epoch 61, loss 0.42625561356544495, acc=0.8376666903495789, loss=0.42625561356544495
test: epoch 61, loss 1.3092674016952515, acc=0.5, loss=1.3092674016952515
train: epoch 62, loss 0.42528650164604187, acc=0.842555582523346, loss=0.42528650164604187
test: epoch 62, loss 1.3238400220870972, acc=0.5166666507720947, loss=1.3238400220870972
train: epoch 63, loss 0.42399534583091736, acc=0.8356666564941406, loss=0.42399534583091736
test: epoch 63, loss 1.1657811403274536, acc=0.5444444417953491, loss=1.1657811403274536
train: epoch 64, loss 0.4142627418041229, acc=0.8438888788223267, loss=0.4142627418041229
test: epoch 64, loss 1.2719942331314087, acc=0.5472221970558167, loss=1.2719942331314087
train: epoch 65, loss 0.42920345067977905, acc=0.8410000205039978, loss=0.42920345067977905
test: epoch 65, loss 1.2501243352890015, acc=0.5527777671813965, loss=1.2501243352890015
train: epoch 66, loss 0.4162663221359253, acc=0.8403333425521851, loss=0.4162663221359253
test: epoch 66, loss 1.1630723476409912, acc=0.5472221970558167, loss=1.1630723476409912
train: epoch 67, loss 0.4201207756996155, acc=0.8418889045715332, loss=0.4201207756996155
test: epoch 67, loss 1.1958917379379272, acc=0.5388888716697693, loss=1.1958917379379272
train: epoch 68, loss 0.4231347143650055, acc=0.8392221927642822, loss=0.4231347143650055
test: epoch 68, loss 1.2793262004852295, acc=0.550000011920929, loss=1.2793262004852295
train: epoch 69, loss 0.40993639826774597, acc=0.8399444222450256, loss=0.40993639826774597
test: epoch 69, loss 1.2774053812026978, acc=0.5444444417953491, loss=1.2774053812026978
train: epoch 70, loss 0.4173556864261627, acc=0.8392221927642822, loss=0.4173556864261627
test: epoch 70, loss 1.1853089332580566, acc=0.5638889074325562, loss=1.1853089332580566
train: epoch 71, loss 0.42265793681144714, acc=0.8388333320617676, loss=0.42265793681144714
test: epoch 71, loss 1.1546255350112915, acc=0.5777778029441833, loss=1.1546255350112915
train: epoch 72, loss 0.4144151210784912, acc=0.8413888812065125, loss=0.4144151210784912
test: epoch 72, loss 1.1719534397125244, acc=0.5833333134651184, loss=1.1719534397125244
train: epoch 73, loss 0.4097355306148529, acc=0.8439444303512573, loss=0.4097355306148529
test: epoch 73, loss 1.1521607637405396, acc=0.5666666626930237, loss=1.1521607637405396
train: epoch 74, loss 0.39623886346817017, acc=0.8480555415153503, loss=0.39623886346817017
test: epoch 74, loss 1.3233715295791626, acc=0.5555555820465088, loss=1.3233715295791626
train: epoch 75, loss 0.4140785038471222, acc=0.8426111340522766, loss=0.4140785038471222
test: epoch 75, loss 1.1284797191619873, acc=0.5583333373069763, loss=1.1284797191619873
train: epoch 76, loss 0.40637561678886414, acc=0.8421111106872559, loss=0.40637561678886414
test: epoch 76, loss 1.30278480052948, acc=0.5416666865348816, loss=1.30278480052948
train: epoch 77, loss 0.38457098603248596, acc=0.8499444723129272, loss=0.38457098603248596
test: epoch 77, loss 1.2706422805786133, acc=0.5555555820465088, loss=1.2706422805786133
train: epoch 78, loss 0.3949802815914154, acc=0.847611129283905, loss=0.3949802815914154
test: epoch 78, loss 1.2035170793533325, acc=0.5666666626930237, loss=1.2035170793533325
train: epoch 79, loss 0.38681262731552124, acc=0.8506110906600952, loss=0.38681262731552124
test: epoch 79, loss 1.1870477199554443, acc=0.5638889074325562, loss=1.1870477199554443
train: epoch 80, loss 0.395563542842865, acc=0.8461666703224182, loss=0.395563542842865
test: epoch 80, loss 1.1769925355911255, acc=0.5916666388511658, loss=1.1769925355911255
train: epoch 81, loss 0.3875899016857147, acc=0.8521666526794434, loss=0.3875899016857147
test: epoch 81, loss 1.1401258707046509, acc=0.5777778029441833, loss=1.1401258707046509
train: epoch 82, loss 0.3934781849384308, acc=0.8464999794960022, loss=0.3934781849384308
test: epoch 82, loss 1.1575119495391846, acc=0.5944444537162781, loss=1.1575119495391846
train: epoch 83, loss 0.3820677697658539, acc=0.8515555262565613, loss=0.3820677697658539
test: epoch 83, loss 1.1427909135818481, acc=0.5694444179534912, loss=1.1427909135818481
train: epoch 84, loss 0.38661402463912964, acc=0.8502222299575806, loss=0.38661402463912964
test: epoch 84, loss 1.1073613166809082, acc=0.5805555582046509, loss=1.1073613166809082
train: epoch 85, loss 0.382906973361969, acc=0.8537777662277222, loss=0.382906973361969
test: epoch 85, loss 1.2165555953979492, acc=0.5777778029441833, loss=1.2165555953979492
train: epoch 86, loss 0.39132657647132874, acc=0.8483889102935791, loss=0.39132657647132874
test: epoch 86, loss 1.1873599290847778, acc=0.5805555582046509, loss=1.1873599290847778
train: epoch 87, loss 0.38678237795829773, acc=0.8527222275733948, loss=0.38678237795829773
test: epoch 87, loss 1.3022232055664062, acc=0.5916666388511658, loss=1.3022232055664062
train: epoch 88, loss 0.37756073474884033, acc=0.8535555601119995, loss=0.37756073474884033
test: epoch 88, loss 1.1794747114181519, acc=0.5611110925674438, loss=1.1794747114181519
train: epoch 89, loss 0.3782725930213928, acc=0.85188889503479, loss=0.3782725930213928
test: epoch 89, loss 1.222266435623169, acc=0.5916666388511658, loss=1.222266435623169
train: epoch 90, loss 0.36906689405441284, acc=0.8551666736602783, loss=0.36906689405441284
test: epoch 90, loss 1.2373379468917847, acc=0.5833333134651184, loss=1.2373379468917847
train: epoch 91, loss 0.37885189056396484, acc=0.8508889079093933, loss=0.37885189056396484
test: epoch 91, loss 1.3043148517608643, acc=0.5833333134651184, loss=1.3043148517608643
train: epoch 92, loss 0.37712329626083374, acc=0.8542777895927429, loss=0.37712329626083374
test: epoch 92, loss 1.2239145040512085, acc=0.605555534362793, loss=1.2239145040512085
train: epoch 93, loss 0.37532612681388855, acc=0.8560000061988831, loss=0.37532612681388855
test: epoch 93, loss 1.1273614168167114, acc=0.5694444179534912, loss=1.1273614168167114
train: epoch 94, loss 0.3745630383491516, acc=0.8553333282470703, loss=0.3745630383491516
test: epoch 94, loss 1.130956768989563, acc=0.6000000238418579, loss=1.130956768989563
train: epoch 95, loss 0.35854247212409973, acc=0.8569999933242798, loss=0.35854247212409973
test: epoch 95, loss 1.177030324935913, acc=0.574999988079071, loss=1.177030324935913
train: epoch 96, loss 0.36501064896583557, acc=0.8557222485542297, loss=0.36501064896583557
test: epoch 96, loss 1.452853798866272, acc=0.6027777791023254, loss=1.452853798866272
train: epoch 97, loss 0.36300143599510193, acc=0.859499990940094, loss=0.36300143599510193
test: epoch 97, loss 1.2036365270614624, acc=0.5694444179534912, loss=1.2036365270614624
train: epoch 98, loss 0.3687714636325836, acc=0.8577777743339539, loss=0.3687714636325836
test: epoch 98, loss 1.1766401529312134, acc=0.5972222089767456, loss=1.1766401529312134
train: epoch 99, loss 0.3708871603012085, acc=0.8560555577278137, loss=0.3708871603012085
test: epoch 99, loss 1.1888138055801392, acc=0.5888888835906982, loss=1.1888138055801392
train: epoch 100, loss 0.36605581641197205, acc=0.8576111197471619, loss=0.36605581641197205
test: epoch 100, loss 1.1637060642242432, acc=0.5722222328186035, loss=1.1637060642242432
train: epoch 101, loss 0.3664708733558655, acc=0.85916668176651, loss=0.3664708733558655
test: epoch 101, loss 1.1355414390563965, acc=0.6083333492279053, loss=1.1355414390563965
train: epoch 102, loss 0.35597604513168335, acc=0.8638333082199097, loss=0.35597604513168335
test: epoch 102, loss 1.1502344608306885, acc=0.5916666388511658, loss=1.1502344608306885
train: epoch 103, loss 0.3533004820346832, acc=0.8619999885559082, loss=0.3533004820346832
test: epoch 103, loss 1.2562713623046875, acc=0.5861111283302307, loss=1.2562713623046875
train: epoch 104, loss 0.3646227717399597, acc=0.8567777872085571, loss=0.3646227717399597
test: epoch 104, loss 1.233426809310913, acc=0.5888888835906982, loss=1.233426809310913
train: epoch 105, loss 0.3520972728729248, acc=0.8624444603919983, loss=0.3520972728729248
test: epoch 105, loss 1.1245146989822388, acc=0.5833333134651184, loss=1.1245146989822388
train: epoch 106, loss 0.34488552808761597, acc=0.8616666793823242, loss=0.34488552808761597
test: epoch 106, loss 1.249652624130249, acc=0.5944444537162781, loss=1.249652624130249
train: epoch 107, loss 0.3518561124801636, acc=0.8649444580078125, loss=0.3518561124801636
test: epoch 107, loss 1.2426515817642212, acc=0.6083333492279053, loss=1.2426515817642212
train: epoch 108, loss 0.3495679199695587, acc=0.8625555634498596, loss=0.3495679199695587
test: epoch 108, loss 1.2085810899734497, acc=0.5861111283302307, loss=1.2085810899734497
train: epoch 109, loss 0.3467659652233124, acc=0.8628888726234436, loss=0.3467659652233124
test: epoch 109, loss 1.1742476224899292, acc=0.5916666388511658, loss=1.1742476224899292
train: epoch 110, loss 0.35286402702331543, acc=0.8604444265365601, loss=0.35286402702331543
test: epoch 110, loss 1.1536424160003662, acc=0.5916666388511658, loss=1.1536424160003662
train: epoch 111, loss 0.35212385654449463, acc=0.8642777800559998, loss=0.35212385654449463
test: epoch 111, loss 1.0395126342773438, acc=0.5916666388511658, loss=1.0395126342773438
train: epoch 112, loss 0.3530271053314209, acc=0.8573333621025085, loss=0.3530271053314209
test: epoch 112, loss 1.1978634595870972, acc=0.5916666388511658, loss=1.1978634595870972
train: epoch 113, loss 0.34894058108329773, acc=0.8666666746139526, loss=0.34894058108329773
test: epoch 113, loss 1.2488003969192505, acc=0.5972222089767456, loss=1.2488003969192505
train: epoch 114, loss 0.3465457558631897, acc=0.8618333339691162, loss=0.3465457558631897
test: epoch 114, loss 1.2819932699203491, acc=0.6000000238418579, loss=1.2819932699203491
train: epoch 115, loss 0.34214508533477783, acc=0.8657222390174866, loss=0.34214508533477783
test: epoch 115, loss 1.2313628196716309, acc=0.5944444537162781, loss=1.2313628196716309
train: epoch 116, loss 0.3356662690639496, acc=0.8674444556236267, loss=0.3356662690639496
test: epoch 116, loss 1.2562320232391357, acc=0.5888888835906982, loss=1.2562320232391357
train: epoch 117, loss 0.3484738767147064, acc=0.8620555400848389, loss=0.3484738767147064
test: epoch 117, loss 1.2354850769042969, acc=0.5777778029441833, loss=1.2354850769042969
train: epoch 118, loss 0.3440578579902649, acc=0.8640000224113464, loss=0.3440578579902649
test: epoch 118, loss 1.2357678413391113, acc=0.5805555582046509, loss=1.2357678413391113
train: epoch 119, loss 0.34632474184036255, acc=0.8627222180366516, loss=0.34632474184036255
test: epoch 119, loss 1.229266881942749, acc=0.5916666388511658, loss=1.229266881942749
train: epoch 120, loss 0.3440861403942108, acc=0.8653888702392578, loss=0.3440861403942108
test: epoch 120, loss 1.1644753217697144, acc=0.5944444537162781, loss=1.1644753217697144
train: epoch 121, loss 0.3460947573184967, acc=0.8627222180366516, loss=0.3460947573184967
test: epoch 121, loss 1.203303337097168, acc=0.5861111283302307, loss=1.203303337097168
train: epoch 122, loss 0.3393229842185974, acc=0.8659999966621399, loss=0.3393229842185974
test: epoch 122, loss 1.173065185546875, acc=0.6000000238418579, loss=1.173065185546875
train: epoch 123, loss 0.34374916553497314, acc=0.8654999732971191, loss=0.34374916553497314
test: epoch 123, loss 1.2833696603775024, acc=0.605555534362793, loss=1.2833696603775024
train: epoch 124, loss 0.33190828561782837, acc=0.8721666932106018, loss=0.33190828561782837
test: epoch 124, loss 1.1898571252822876, acc=0.5888888835906982, loss=1.1898571252822876
train: epoch 125, loss 0.33673837780952454, acc=0.8681666851043701, loss=0.33673837780952454
test: epoch 125, loss 1.272947907447815, acc=0.5805555582046509, loss=1.272947907447815
train: epoch 126, loss 0.3404764235019684, acc=0.8705000281333923, loss=0.3404764235019684
test: epoch 126, loss 1.2813141345977783, acc=0.6083333492279053, loss=1.2813141345977783
train: epoch 127, loss 0.3342472016811371, acc=0.8694444298744202, loss=0.3342472016811371
test: epoch 127, loss 1.2623753547668457, acc=0.6138888597488403, loss=1.2623753547668457
train: epoch 128, loss 0.33783024549484253, acc=0.8694999814033508, loss=0.33783024549484253
test: epoch 128, loss 1.2783243656158447, acc=0.5972222089767456, loss=1.2783243656158447
train: epoch 129, loss 0.3353344202041626, acc=0.8660555481910706, loss=0.3353344202041626
test: epoch 129, loss 1.3268358707427979, acc=0.6000000238418579, loss=1.3268358707427979
train: epoch 130, loss 0.3232707679271698, acc=0.8716111183166504, loss=0.3232707679271698
test: epoch 130, loss 1.2423899173736572, acc=0.6111111044883728, loss=1.2423899173736572
train: epoch 131, loss 0.32745689153671265, acc=0.8686666488647461, loss=0.32745689153671265
test: epoch 131, loss 1.2262884378433228, acc=0.6000000238418579, loss=1.2262884378433228
train: epoch 132, loss 0.3285069167613983, acc=0.8695555329322815, loss=0.3285069167613983
test: epoch 132, loss 1.1437629461288452, acc=0.5944444537162781, loss=1.1437629461288452
train: epoch 133, loss 0.33417844772338867, acc=0.8691111207008362, loss=0.33417844772338867
test: epoch 133, loss 1.278407335281372, acc=0.5861111283302307, loss=1.278407335281372
train: epoch 134, loss 0.3304159641265869, acc=0.8669999837875366, loss=0.3304159641265869
test: epoch 134, loss 1.204313039779663, acc=0.6138888597488403, loss=1.204313039779663
train: epoch 135, loss 0.33465784788131714, acc=0.8706666827201843, loss=0.33465784788131714
test: epoch 135, loss 1.1183078289031982, acc=0.5972222089767456, loss=1.1183078289031982
train: epoch 136, loss 0.3407059609889984, acc=0.8652777671813965, loss=0.3407059609889984
test: epoch 136, loss 1.2182754278182983, acc=0.6027777791023254, loss=1.2182754278182983
train: epoch 137, loss 0.3278845250606537, acc=0.8695555329322815, loss=0.3278845250606537
test: epoch 137, loss 1.3331469297409058, acc=0.5916666388511658, loss=1.3331469297409058
train: epoch 138, loss 0.3262791335582733, acc=0.8686666488647461, loss=0.3262791335582733
test: epoch 138, loss 1.2283216714859009, acc=0.5972222089767456, loss=1.2283216714859009
train: epoch 139, loss 0.3207971453666687, acc=0.8727222084999084, loss=0.3207971453666687
test: epoch 139, loss 1.3047618865966797, acc=0.6083333492279053, loss=1.3047618865966797
train: epoch 140, loss 0.32969576120376587, acc=0.8704444169998169, loss=0.32969576120376587
test: epoch 140, loss 1.2398384809494019, acc=0.6000000238418579, loss=1.2398384809494019
train: epoch 141, loss 0.3220047950744629, acc=0.871833324432373, loss=0.3220047950744629
test: epoch 141, loss 1.0880483388900757, acc=0.6000000238418579, loss=1.0880483388900757
train: epoch 142, loss 0.32828861474990845, acc=0.867888867855072, loss=0.32828861474990845
test: epoch 142, loss 1.1846611499786377, acc=0.5916666388511658, loss=1.1846611499786377
train: epoch 143, loss 0.32480499148368835, acc=0.8738333582878113, loss=0.32480499148368835
test: epoch 143, loss 1.1726369857788086, acc=0.5972222089767456, loss=1.1726369857788086
train: epoch 144, loss 0.326462984085083, acc=0.8701666593551636, loss=0.326462984085083
test: epoch 144, loss 1.2532559633255005, acc=0.6000000238418579, loss=1.2532559633255005
train: epoch 145, loss 0.3321322798728943, acc=0.8696666955947876, loss=0.3321322798728943
test: epoch 145, loss 1.1193978786468506, acc=0.5888888835906982, loss=1.1193978786468506
train: epoch 146, loss 0.31978124380111694, acc=0.8717777729034424, loss=0.31978124380111694
test: epoch 146, loss 1.2669336795806885, acc=0.6083333492279053, loss=1.2669336795806885
train: epoch 147, loss 0.32269904017448425, acc=0.8731111288070679, loss=0.32269904017448425
test: epoch 147, loss 1.2493774890899658, acc=0.5972222089767456, loss=1.2493774890899658
train: epoch 148, loss 0.3285055458545685, acc=0.8701111078262329, loss=0.3285055458545685
test: epoch 148, loss 1.2342654466629028, acc=0.605555534362793, loss=1.2342654466629028
train: epoch 149, loss 0.31810110807418823, acc=0.8711110949516296, loss=0.31810110807418823
test: epoch 149, loss 1.410703182220459, acc=0.5972222089767456, loss=1.410703182220459
train: epoch 150, loss 0.3298051953315735, acc=0.8698889017105103, loss=0.3298051953315735
test: epoch 150, loss 1.1568114757537842, acc=0.6000000238418579, loss=1.1568114757537842
