# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1", "--temp_decay=0.99", "--one_hot=true", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1459345797, receiver_embed_dim=32, temp_decay=0.99, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.477445125579834, acc=0.051055554300546646, loss=3.477445125579834
test: epoch 1, loss 3.763634443283081, acc=0.0555555559694767, loss=3.763634443283081
train: epoch 2, loss 3.161104202270508, acc=0.06611111015081406, loss=3.161104202270508
test: epoch 2, loss 3.2762696743011475, acc=0.0555555559694767, loss=3.2762696743011475
train: epoch 3, loss 2.6930878162384033, acc=0.12288888543844223, loss=2.6930878162384033
test: epoch 3, loss 2.764627695083618, acc=0.125, loss=2.764627695083618
train: epoch 4, loss 2.4130566120147705, acc=0.1832222193479538, loss=2.4130566120147705
test: epoch 4, loss 2.5969414710998535, acc=0.11388888955116272, loss=2.5969414710998535
train: epoch 5, loss 2.1031129360198975, acc=0.25688889622688293, loss=2.1031129360198975
test: epoch 5, loss 2.457880735397339, acc=0.13055555522441864, loss=2.457880735397339
train: epoch 6, loss 1.9224073886871338, acc=0.29055556654930115, loss=1.9224073886871338
test: epoch 6, loss 2.3429477214813232, acc=0.13611111044883728, loss=2.3429477214813232
train: epoch 7, loss 1.808281660079956, acc=0.31511110067367554, loss=1.808281660079956
test: epoch 7, loss 2.2272167205810547, acc=0.14444445073604584, loss=2.2272167205810547
train: epoch 8, loss 1.737104892730713, acc=0.3321666717529297, loss=1.737104892730713
test: epoch 8, loss 2.195047378540039, acc=0.1666666716337204, loss=2.195047378540039
train: epoch 9, loss 1.6793769598007202, acc=0.3488333225250244, loss=1.6793769598007202
test: epoch 9, loss 2.156188726425171, acc=0.1666666716337204, loss=2.156188726425171
train: epoch 10, loss 1.6117427349090576, acc=0.36266666650772095, loss=1.6117427349090576
test: epoch 10, loss 2.093909502029419, acc=0.18333333730697632, loss=2.093909502029419
train: epoch 11, loss 1.5655888319015503, acc=0.3807777762413025, loss=1.5655888319015503
test: epoch 11, loss 2.029130697250366, acc=0.21111111342906952, loss=2.029130697250366
train: epoch 12, loss 1.514972448348999, acc=0.3962777853012085, loss=1.514972448348999
test: epoch 12, loss 2.021927833557129, acc=0.2083333283662796, loss=2.021927833557129
train: epoch 13, loss 1.4781851768493652, acc=0.4078333377838135, loss=1.4781851768493652
test: epoch 13, loss 1.9371179342269897, acc=0.2222222238779068, loss=1.9371179342269897
train: epoch 14, loss 1.4410419464111328, acc=0.41938889026641846, loss=1.4410419464111328
test: epoch 14, loss 1.9284638166427612, acc=0.22499999403953552, loss=1.9284638166427612
train: epoch 15, loss 1.4148542881011963, acc=0.43344444036483765, loss=1.4148542881011963
test: epoch 15, loss 1.952595591545105, acc=0.22777777910232544, loss=1.952595591545105
train: epoch 16, loss 1.378097653388977, acc=0.445499986410141, loss=1.378097653388977
test: epoch 16, loss 1.826736330986023, acc=0.23055554926395416, loss=1.826736330986023
train: epoch 17, loss 1.3675293922424316, acc=0.4543333351612091, loss=1.3675293922424316
test: epoch 17, loss 1.85054612159729, acc=0.23055554926395416, loss=1.85054612159729
train: epoch 18, loss 1.330020785331726, acc=0.46533334255218506, loss=1.330020785331726
test: epoch 18, loss 1.8560833930969238, acc=0.23055554926395416, loss=1.8560833930969238
train: epoch 19, loss 1.310624361038208, acc=0.4664444327354431, loss=1.310624361038208
test: epoch 19, loss 1.8497120141983032, acc=0.23055554926395416, loss=1.8497120141983032
train: epoch 20, loss 1.2967371940612793, acc=0.4790000021457672, loss=1.2967371940612793
test: epoch 20, loss 1.832955002784729, acc=0.23055554926395416, loss=1.832955002784729
train: epoch 21, loss 1.2814675569534302, acc=0.4831666648387909, loss=1.2814675569534302
test: epoch 21, loss 1.898522973060608, acc=0.22499999403953552, loss=1.898522973060608
train: epoch 22, loss 1.2689695358276367, acc=0.4911110997200012, loss=1.2689695358276367
test: epoch 22, loss 1.819709300994873, acc=0.23055554926395416, loss=1.819709300994873
train: epoch 23, loss 1.2451181411743164, acc=0.49533334374427795, loss=1.2451181411743164
test: epoch 23, loss 1.9260902404785156, acc=0.2361111044883728, loss=1.9260902404785156
train: epoch 24, loss 1.225248098373413, acc=0.4959999918937683, loss=1.225248098373413
test: epoch 24, loss 1.843161702156067, acc=0.22499999403953552, loss=1.843161702156067
train: epoch 25, loss 1.2299561500549316, acc=0.4976666569709778, loss=1.2299561500549316
test: epoch 25, loss 1.8179512023925781, acc=0.2361111044883728, loss=1.8179512023925781
train: epoch 26, loss 1.1998990774154663, acc=0.5003888607025146, loss=1.1998990774154663
test: epoch 26, loss 1.7238290309906006, acc=0.24722221493721008, loss=1.7238290309906006
train: epoch 27, loss 1.1984506845474243, acc=0.49916666746139526, loss=1.1984506845474243
test: epoch 27, loss 1.806894302368164, acc=0.25, loss=1.806894302368164
train: epoch 28, loss 1.188788652420044, acc=0.5067777633666992, loss=1.188788652420044
test: epoch 28, loss 1.7632782459259033, acc=0.2611111104488373, loss=1.7632782459259033
train: epoch 29, loss 1.187406301498413, acc=0.5088333487510681, loss=1.187406301498413
test: epoch 29, loss 1.7511723041534424, acc=0.2666666805744171, loss=1.7511723041534424
train: epoch 30, loss 1.1626888513565063, acc=0.5091666579246521, loss=1.1626888513565063
test: epoch 30, loss 1.7589390277862549, acc=0.26944443583488464, loss=1.7589390277862549
train: epoch 31, loss 1.149308443069458, acc=0.5098888874053955, loss=1.149308443069458
test: epoch 31, loss 1.7192426919937134, acc=0.25555557012557983, loss=1.7192426919937134
train: epoch 32, loss 1.1474695205688477, acc=0.5117777585983276, loss=1.1474695205688477
test: epoch 32, loss 1.7488542795181274, acc=0.2666666805744171, loss=1.7488542795181274
train: epoch 33, loss 1.126481056213379, acc=0.5191666483879089, loss=1.126481056213379
test: epoch 33, loss 1.740805745124817, acc=0.25833332538604736, loss=1.740805745124817
train: epoch 34, loss 1.1274949312210083, acc=0.5169444680213928, loss=1.1274949312210083
test: epoch 34, loss 1.7618311643600464, acc=0.2638888955116272, loss=1.7618311643600464
train: epoch 35, loss 1.108513593673706, acc=0.5225555300712585, loss=1.108513593673706
test: epoch 35, loss 1.7610955238342285, acc=0.2805555462837219, loss=1.7610955238342285
train: epoch 36, loss 1.1074433326721191, acc=0.5212777853012085, loss=1.1074433326721191
test: epoch 36, loss 1.7425997257232666, acc=0.2527777850627899, loss=1.7425997257232666
train: epoch 37, loss 1.1023333072662354, acc=0.5267778038978577, loss=1.1023333072662354
test: epoch 37, loss 1.7769598960876465, acc=0.2888889014720917, loss=1.7769598960876465
train: epoch 38, loss 1.086553692817688, acc=0.5276666879653931, loss=1.086553692817688
test: epoch 38, loss 1.7914117574691772, acc=0.26944443583488464, loss=1.7914117574691772
train: epoch 39, loss 1.0754965543746948, acc=0.5352222323417664, loss=1.0754965543746948
test: epoch 39, loss 1.7288994789123535, acc=0.28611111640930176, loss=1.7288994789123535
train: epoch 40, loss 1.074415922164917, acc=0.5370000004768372, loss=1.074415922164917
test: epoch 40, loss 1.6847597360610962, acc=0.2916666567325592, loss=1.6847597360610962
train: epoch 41, loss 1.0576562881469727, acc=0.5417222380638123, loss=1.0576562881469727
test: epoch 41, loss 1.846779704093933, acc=0.2638888955116272, loss=1.846779704093933
train: epoch 42, loss 1.0507481098175049, acc=0.5407778024673462, loss=1.0507481098175049
test: epoch 42, loss 1.8190592527389526, acc=0.28333333134651184, loss=1.8190592527389526
train: epoch 43, loss 1.0506385564804077, acc=0.542388916015625, loss=1.0506385564804077
test: epoch 43, loss 1.6886837482452393, acc=0.3083333373069763, loss=1.6886837482452393
train: epoch 44, loss 1.0419158935546875, acc=0.543055534362793, loss=1.0419158935546875
test: epoch 44, loss 1.712612271308899, acc=0.3027777671813965, loss=1.712612271308899
train: epoch 45, loss 1.0312992334365845, acc=0.5493888854980469, loss=1.0312992334365845
test: epoch 45, loss 1.8019319772720337, acc=0.2944444417953491, loss=1.8019319772720337
train: epoch 46, loss 1.0253149271011353, acc=0.5533333420753479, loss=1.0253149271011353
test: epoch 46, loss 1.7234283685684204, acc=0.30000001192092896, loss=1.7234283685684204
train: epoch 47, loss 1.0256181955337524, acc=0.5494999885559082, loss=1.0256181955337524
test: epoch 47, loss 1.7282429933547974, acc=0.31111112236976624, loss=1.7282429933547974
train: epoch 48, loss 1.0120148658752441, acc=0.5562777519226074, loss=1.0120148658752441
test: epoch 48, loss 1.7862179279327393, acc=0.3055555522441864, loss=1.7862179279327393
train: epoch 49, loss 1.0117425918579102, acc=0.5566666722297668, loss=1.0117425918579102
test: epoch 49, loss 1.7424476146697998, acc=0.3166666626930237, loss=1.7424476146697998
train: epoch 50, loss 1.0073243379592896, acc=0.5598888993263245, loss=1.0073243379592896
test: epoch 50, loss 1.8009015321731567, acc=0.3055555522441864, loss=1.8009015321731567
train: epoch 51, loss 0.9800117015838623, acc=0.5651111006736755, loss=0.9800117015838623
test: epoch 51, loss 1.7608572244644165, acc=0.3055555522441864, loss=1.7608572244644165
train: epoch 52, loss 0.9841971397399902, acc=0.5699999928474426, loss=0.9841971397399902
test: epoch 52, loss 1.7323168516159058, acc=0.3166666626930237, loss=1.7323168516159058
train: epoch 53, loss 0.9725003838539124, acc=0.569944441318512, loss=0.9725003838539124
test: epoch 53, loss 1.699137806892395, acc=0.3166666626930237, loss=1.699137806892395
train: epoch 54, loss 0.9609635472297668, acc=0.5766666531562805, loss=0.9609635472297668
test: epoch 54, loss 1.7018711566925049, acc=0.3222222328186035, loss=1.7018711566925049
train: epoch 55, loss 0.9643858671188354, acc=0.5721111297607422, loss=0.9643858671188354
test: epoch 55, loss 1.7156860828399658, acc=0.3222222328186035, loss=1.7156860828399658
train: epoch 56, loss 0.9642927050590515, acc=0.5716111063957214, loss=0.9642927050590515
test: epoch 56, loss 1.7034705877304077, acc=0.3194444477558136, loss=1.7034705877304077
train: epoch 57, loss 0.9605434536933899, acc=0.5791110992431641, loss=0.9605434536933899
test: epoch 57, loss 1.8378604650497437, acc=0.32499998807907104, loss=1.8378604650497437
train: epoch 58, loss 0.9489283561706543, acc=0.5848888754844666, loss=0.9489283561706543
test: epoch 58, loss 1.6717909574508667, acc=0.3222222328186035, loss=1.6717909574508667
train: epoch 59, loss 0.9309321641921997, acc=0.5882777571678162, loss=0.9309321641921997
test: epoch 59, loss 1.7407145500183105, acc=0.31111112236976624, loss=1.7407145500183105
train: epoch 60, loss 0.9244465231895447, acc=0.5911111235618591, loss=0.9244465231895447
test: epoch 60, loss 1.7412629127502441, acc=0.3027777671813965, loss=1.7412629127502441
train: epoch 61, loss 0.917845606803894, acc=0.5961111187934875, loss=0.917845606803894
test: epoch 61, loss 1.6721305847167969, acc=0.3027777671813965, loss=1.6721305847167969
train: epoch 62, loss 0.9139603972434998, acc=0.5941666960716248, loss=0.9139603972434998
test: epoch 62, loss 1.676177978515625, acc=0.31111112236976624, loss=1.676177978515625
train: epoch 63, loss 0.9032917022705078, acc=0.6025555729866028, loss=0.9032917022705078
test: epoch 63, loss 1.7211395502090454, acc=0.30000001192092896, loss=1.7211395502090454
train: epoch 64, loss 0.9044575095176697, acc=0.5995000004768372, loss=0.9044575095176697
test: epoch 64, loss 1.6432346105575562, acc=0.3222222328186035, loss=1.6432346105575562
train: epoch 65, loss 0.9001662731170654, acc=0.6003888845443726, loss=0.9001662731170654
test: epoch 65, loss 1.6771087646484375, acc=0.3166666626930237, loss=1.6771087646484375
train: epoch 66, loss 0.8906775712966919, acc=0.6059444546699524, loss=0.8906775712966919
test: epoch 66, loss 1.6614570617675781, acc=0.31111112236976624, loss=1.6614570617675781
train: epoch 67, loss 0.8755503296852112, acc=0.6138333082199097, loss=0.8755503296852112
test: epoch 67, loss 1.6872140169143677, acc=0.31388887763023376, loss=1.6872140169143677
train: epoch 68, loss 0.8786646127700806, acc=0.6081666946411133, loss=0.8786646127700806
test: epoch 68, loss 1.8491727113723755, acc=0.31111112236976624, loss=1.8491727113723755
train: epoch 69, loss 0.8844146132469177, acc=0.6071666479110718, loss=0.8844146132469177
test: epoch 69, loss 1.669592022895813, acc=0.3083333373069763, loss=1.669592022895813
train: epoch 70, loss 0.8681406378746033, acc=0.6140000224113464, loss=0.8681406378746033
test: epoch 70, loss 1.7582118511199951, acc=0.31111112236976624, loss=1.7582118511199951
train: epoch 71, loss 0.8626310229301453, acc=0.6144999861717224, loss=0.8626310229301453
test: epoch 71, loss 1.740330696105957, acc=0.31111112236976624, loss=1.740330696105957
train: epoch 72, loss 0.8680518865585327, acc=0.6151111125946045, loss=0.8680518865585327
test: epoch 72, loss 1.7790330648422241, acc=0.31111112236976624, loss=1.7790330648422241
train: epoch 73, loss 0.8526124358177185, acc=0.6163333058357239, loss=0.8526124358177185
test: epoch 73, loss 1.686022162437439, acc=0.3055555522441864, loss=1.686022162437439
train: epoch 74, loss 0.8585946559906006, acc=0.6215555667877197, loss=0.8585946559906006
test: epoch 74, loss 1.7159864902496338, acc=0.31388887763023376, loss=1.7159864902496338
train: epoch 75, loss 0.8437036871910095, acc=0.6241666674613953, loss=0.8437036871910095
test: epoch 75, loss 1.6893137693405151, acc=0.31111112236976624, loss=1.6893137693405151
train: epoch 76, loss 0.8383199572563171, acc=0.6240000128746033, loss=0.8383199572563171
test: epoch 76, loss 1.7123254537582397, acc=0.31111112236976624, loss=1.7123254537582397
train: epoch 77, loss 0.8421365022659302, acc=0.6225000023841858, loss=0.8421365022659302
test: epoch 77, loss 1.7251546382904053, acc=0.3166666626930237, loss=1.7251546382904053
train: epoch 78, loss 0.8181275725364685, acc=0.6307777762413025, loss=0.8181275725364685
test: epoch 78, loss 1.7867865562438965, acc=0.3055555522441864, loss=1.7867865562438965
train: epoch 79, loss 0.8349727988243103, acc=0.6297222375869751, loss=0.8349727988243103
test: epoch 79, loss 1.7583208084106445, acc=0.3083333373069763, loss=1.7583208084106445
train: epoch 80, loss 0.8165538907051086, acc=0.636222243309021, loss=0.8165538907051086
test: epoch 80, loss 1.7497694492340088, acc=0.31111112236976624, loss=1.7497694492340088
train: epoch 81, loss 0.820289671421051, acc=0.632888913154602, loss=0.820289671421051
test: epoch 81, loss 1.7747946977615356, acc=0.3083333373069763, loss=1.7747946977615356
train: epoch 82, loss 0.8163660168647766, acc=0.6342222094535828, loss=0.8163660168647766
test: epoch 82, loss 1.865906834602356, acc=0.3083333373069763, loss=1.865906834602356
train: epoch 83, loss 0.806074321269989, acc=0.6370000243186951, loss=0.806074321269989
test: epoch 83, loss 1.7756366729736328, acc=0.3166666626930237, loss=1.7756366729736328
train: epoch 84, loss 0.8130322098731995, acc=0.6419444680213928, loss=0.8130322098731995
test: epoch 84, loss 1.736115574836731, acc=0.31111112236976624, loss=1.736115574836731
train: epoch 85, loss 0.8121499419212341, acc=0.6407777667045593, loss=0.8121499419212341
test: epoch 85, loss 1.7900736331939697, acc=0.3083333373069763, loss=1.7900736331939697
train: epoch 86, loss 0.7967489957809448, acc=0.6456666588783264, loss=0.7967489957809448
test: epoch 86, loss 1.7741281986236572, acc=0.3222222328186035, loss=1.7741281986236572
train: epoch 87, loss 0.7961015701293945, acc=0.6439999938011169, loss=0.7961015701293945
test: epoch 87, loss 1.6723819971084595, acc=0.31111112236976624, loss=1.6723819971084595
train: epoch 88, loss 0.7938775420188904, acc=0.6414999961853027, loss=0.7938775420188904
test: epoch 88, loss 1.7154946327209473, acc=0.3166666626930237, loss=1.7154946327209473
train: epoch 89, loss 0.7959681153297424, acc=0.6412222385406494, loss=0.7959681153297424
test: epoch 89, loss 1.8580281734466553, acc=0.3055555522441864, loss=1.8580281734466553
train: epoch 90, loss 0.7989423871040344, acc=0.6439999938011169, loss=0.7989423871040344
test: epoch 90, loss 1.8351881504058838, acc=0.31111112236976624, loss=1.8351881504058838
train: epoch 91, loss 0.7995275855064392, acc=0.6439444422721863, loss=0.7995275855064392
test: epoch 91, loss 1.7558828592300415, acc=0.3083333373069763, loss=1.7558828592300415
train: epoch 92, loss 0.7804749608039856, acc=0.6439444422721863, loss=0.7804749608039856
test: epoch 92, loss 1.6493520736694336, acc=0.3055555522441864, loss=1.6493520736694336
train: epoch 93, loss 0.7854121327400208, acc=0.6472777724266052, loss=0.7854121327400208
test: epoch 93, loss 1.750646710395813, acc=0.31111112236976624, loss=1.750646710395813
train: epoch 94, loss 0.7860957980155945, acc=0.6454444527626038, loss=0.7860957980155945
test: epoch 94, loss 1.7466577291488647, acc=0.3083333373069763, loss=1.7466577291488647
train: epoch 95, loss 0.7776826620101929, acc=0.6500555276870728, loss=0.7776826620101929
test: epoch 95, loss 1.7789698839187622, acc=0.3166666626930237, loss=1.7789698839187622
train: epoch 96, loss 0.7791316509246826, acc=0.6462222337722778, loss=0.7791316509246826
test: epoch 96, loss 1.809396743774414, acc=0.31388887763023376, loss=1.809396743774414
train: epoch 97, loss 0.7777780294418335, acc=0.6520000100135803, loss=0.7777780294418335
test: epoch 97, loss 1.9238624572753906, acc=0.31388887763023376, loss=1.9238624572753906
train: epoch 98, loss 0.7758362889289856, acc=0.6552777886390686, loss=0.7758362889289856
test: epoch 98, loss 1.814040184020996, acc=0.3083333373069763, loss=1.814040184020996
train: epoch 99, loss 0.7705547213554382, acc=0.6526666879653931, loss=0.7705547213554382
test: epoch 99, loss 1.897306203842163, acc=0.3083333373069763, loss=1.897306203842163
train: epoch 100, loss 0.7702805399894714, acc=0.6507222056388855, loss=0.7702805399894714
test: epoch 100, loss 1.781693935394287, acc=0.31111112236976624, loss=1.781693935394287
train: epoch 101, loss 0.7685362696647644, acc=0.6575555801391602, loss=0.7685362696647644
test: epoch 101, loss 1.8289917707443237, acc=0.3166666626930237, loss=1.8289917707443237
train: epoch 102, loss 0.768524706363678, acc=0.6511666774749756, loss=0.768524706363678
test: epoch 102, loss 1.9607549905776978, acc=0.3194444477558136, loss=1.9607549905776978
train: epoch 103, loss 0.7598675489425659, acc=0.6547222137451172, loss=0.7598675489425659
test: epoch 103, loss 1.9465065002441406, acc=0.31388887763023376, loss=1.9465065002441406
train: epoch 104, loss 0.7639064788818359, acc=0.6555555462837219, loss=0.7639064788818359
test: epoch 104, loss 1.7459735870361328, acc=0.3194444477558136, loss=1.7459735870361328
train: epoch 105, loss 0.7641847729682922, acc=0.656499981880188, loss=0.7641847729682922
test: epoch 105, loss 1.7622812986373901, acc=0.32777777314186096, loss=1.7622812986373901
train: epoch 106, loss 0.7667615413665771, acc=0.6553333401679993, loss=0.7667615413665771
test: epoch 106, loss 1.8026045560836792, acc=0.31388887763023376, loss=1.8026045560836792
train: epoch 107, loss 0.7436044216156006, acc=0.6597222089767456, loss=0.7436044216156006
test: epoch 107, loss 1.703672170639038, acc=0.32777777314186096, loss=1.703672170639038
train: epoch 108, loss 0.7530466914176941, acc=0.6585000157356262, loss=0.7530466914176941
test: epoch 108, loss 1.8205878734588623, acc=0.31388887763023376, loss=1.8205878734588623
train: epoch 109, loss 0.7560651898384094, acc=0.6578888893127441, loss=0.7560651898384094
test: epoch 109, loss 1.7329068183898926, acc=0.31111112236976624, loss=1.7329068183898926
train: epoch 110, loss 0.7537983655929565, acc=0.6588333249092102, loss=0.7537983655929565
test: epoch 110, loss 1.9022845029830933, acc=0.32777777314186096, loss=1.9022845029830933
train: epoch 111, loss 0.7559816241264343, acc=0.6575000286102295, loss=0.7559816241264343
test: epoch 111, loss 1.8362749814987183, acc=0.3194444477558136, loss=1.8362749814987183
train: epoch 112, loss 0.7496338486671448, acc=0.6578333377838135, loss=0.7496338486671448
test: epoch 112, loss 1.9214481115341187, acc=0.31388887763023376, loss=1.9214481115341187
train: epoch 113, loss 0.7400169968605042, acc=0.6625000238418579, loss=0.7400169968605042
test: epoch 113, loss 1.7330169677734375, acc=0.3333333432674408, loss=1.7330169677734375
train: epoch 114, loss 0.7551738619804382, acc=0.660277783870697, loss=0.7551738619804382
test: epoch 114, loss 1.9187026023864746, acc=0.3333333432674408, loss=1.9187026023864746
train: epoch 115, loss 0.7417362332344055, acc=0.6583333611488342, loss=0.7417362332344055
test: epoch 115, loss 1.8060866594314575, acc=0.3361110985279083, loss=1.8060866594314575
train: epoch 116, loss 0.7467922568321228, acc=0.6585555672645569, loss=0.7467922568321228
test: epoch 116, loss 1.8301711082458496, acc=0.34166666865348816, loss=1.8301711082458496
train: epoch 117, loss 0.7461623549461365, acc=0.6606666445732117, loss=0.7461623549461365
test: epoch 117, loss 1.810284972190857, acc=0.3361110985279083, loss=1.810284972190857
train: epoch 118, loss 0.7504146695137024, acc=0.6604999899864197, loss=0.7504146695137024
test: epoch 118, loss 1.89120352268219, acc=0.3361110985279083, loss=1.89120352268219
train: epoch 119, loss 0.7398665547370911, acc=0.6629444360733032, loss=0.7398665547370911
test: epoch 119, loss 1.9344745874404907, acc=0.3361110985279083, loss=1.9344745874404907
train: epoch 120, loss 0.7352317571640015, acc=0.663611114025116, loss=0.7352317571640015
test: epoch 120, loss 1.8156572580337524, acc=0.3361110985279083, loss=1.8156572580337524
train: epoch 121, loss 0.7302662134170532, acc=0.6635000109672546, loss=0.7302662134170532
test: epoch 121, loss 1.7396085262298584, acc=0.34166666865348816, loss=1.7396085262298584
train: epoch 122, loss 0.7330058217048645, acc=0.6679999828338623, loss=0.7330058217048645
test: epoch 122, loss 1.8477756977081299, acc=0.3444444537162781, loss=1.8477756977081299
train: epoch 123, loss 0.7445018887519836, acc=0.6639444231987, loss=0.7445018887519836
test: epoch 123, loss 1.854433536529541, acc=0.3361110985279083, loss=1.854433536529541
train: epoch 124, loss 0.7248100638389587, acc=0.6692777872085571, loss=0.7248100638389587
test: epoch 124, loss 1.85941743850708, acc=0.3361110985279083, loss=1.85941743850708
train: epoch 125, loss 0.7346519827842712, acc=0.6631666421890259, loss=0.7346519827842712
test: epoch 125, loss 1.8730696439743042, acc=0.3333333432674408, loss=1.8730696439743042
train: epoch 126, loss 0.7242544293403625, acc=0.6696666479110718, loss=0.7242544293403625
test: epoch 126, loss 1.8493499755859375, acc=0.3472222089767456, loss=1.8493499755859375
train: epoch 127, loss 0.734241783618927, acc=0.6679444313049316, loss=0.734241783618927
test: epoch 127, loss 1.8523380756378174, acc=0.3361110985279083, loss=1.8523380756378174
train: epoch 128, loss 0.7224557995796204, acc=0.6711666584014893, loss=0.7224557995796204
test: epoch 128, loss 1.803406000137329, acc=0.33888888359069824, loss=1.803406000137329
train: epoch 129, loss 0.7166577577590942, acc=0.6713333129882812, loss=0.7166577577590942
test: epoch 129, loss 1.8095839023590088, acc=0.3361110985279083, loss=1.8095839023590088
train: epoch 130, loss 0.7262516617774963, acc=0.6714444160461426, loss=0.7262516617774963
test: epoch 130, loss 1.9307700395584106, acc=0.3444444537162781, loss=1.9307700395584106
train: epoch 131, loss 0.7145877480506897, acc=0.6745555400848389, loss=0.7145877480506897
test: epoch 131, loss 1.9237931966781616, acc=0.3444444537162781, loss=1.9237931966781616
train: epoch 132, loss 0.7096314430236816, acc=0.6731111407279968, loss=0.7096314430236816
test: epoch 132, loss 1.840221881866455, acc=0.3361110985279083, loss=1.840221881866455
train: epoch 133, loss 0.7080038189888, acc=0.6750555634498596, loss=0.7080038189888
test: epoch 133, loss 1.8826121091842651, acc=0.3444444537162781, loss=1.8826121091842651
train: epoch 134, loss 0.7113711833953857, acc=0.6736111044883728, loss=0.7113711833953857
test: epoch 134, loss 1.7965742349624634, acc=0.34166666865348816, loss=1.7965742349624634
train: epoch 135, loss 0.713962197303772, acc=0.6724444627761841, loss=0.713962197303772
test: epoch 135, loss 1.8338203430175781, acc=0.34166666865348816, loss=1.8338203430175781
train: epoch 136, loss 0.7154974937438965, acc=0.6704999804496765, loss=0.7154974937438965
test: epoch 136, loss 1.9613124132156372, acc=0.3499999940395355, loss=1.9613124132156372
train: epoch 137, loss 0.7105872631072998, acc=0.6737777590751648, loss=0.7105872631072998
test: epoch 137, loss 1.8305891752243042, acc=0.3499999940395355, loss=1.8305891752243042
train: epoch 138, loss 0.7086676955223083, acc=0.6774444580078125, loss=0.7086676955223083
test: epoch 138, loss 1.8695825338363647, acc=0.3444444537162781, loss=1.8695825338363647
train: epoch 139, loss 0.7006334066390991, acc=0.6798333525657654, loss=0.7006334066390991
test: epoch 139, loss 1.7429137229919434, acc=0.3444444537162781, loss=1.7429137229919434
train: epoch 140, loss 0.6922485828399658, acc=0.6783888936042786, loss=0.6922485828399658
test: epoch 140, loss 1.7958632707595825, acc=0.3444444537162781, loss=1.7958632707595825
train: epoch 141, loss 0.7068811058998108, acc=0.6782222390174866, loss=0.7068811058998108
test: epoch 141, loss 1.879191279411316, acc=0.3499999940395355, loss=1.879191279411316
train: epoch 142, loss 0.7057338356971741, acc=0.6750555634498596, loss=0.7057338356971741
test: epoch 142, loss 2.0141615867614746, acc=0.3444444537162781, loss=2.0141615867614746
train: epoch 143, loss 0.704194962978363, acc=0.6764444708824158, loss=0.704194962978363
test: epoch 143, loss 1.8353053331375122, acc=0.3444444537162781, loss=1.8353053331375122
train: epoch 144, loss 0.7016357779502869, acc=0.675944447517395, loss=0.7016357779502869
test: epoch 144, loss 1.9171180725097656, acc=0.3444444537162781, loss=1.9171180725097656
train: epoch 145, loss 0.7045941352844238, acc=0.6748889088630676, loss=0.7045941352844238
test: epoch 145, loss 1.8508623838424683, acc=0.3444444537162781, loss=1.8508623838424683
train: epoch 146, loss 0.6998488903045654, acc=0.6750555634498596, loss=0.6998488903045654
test: epoch 146, loss 1.9121450185775757, acc=0.3444444537162781, loss=1.9121450185775757
train: epoch 147, loss 0.6953733563423157, acc=0.67894446849823, loss=0.6953733563423157
test: epoch 147, loss 1.8726128339767456, acc=0.3472222089767456, loss=1.8726128339767456
train: epoch 148, loss 0.6979232430458069, acc=0.6778888702392578, loss=0.6979232430458069
test: epoch 148, loss 1.8650034666061401, acc=0.3444444537162781, loss=1.8650034666061401
train: epoch 149, loss 0.6952598094940186, acc=0.680388867855072, loss=0.6952598094940186
test: epoch 149, loss 1.8064007759094238, acc=0.35277777910232544, loss=1.8064007759094238
train: epoch 150, loss 0.6969727873802185, acc=0.6767222285270691, loss=0.6969727873802185
test: epoch 150, loss 1.8077757358551025, acc=0.3472222089767456, loss=1.8077757358551025
