# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=false", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1236187754, receiver_embed_dim=128, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.759690999984741, acc=0.10300000011920929, loss=2.759690999984741
test: epoch 1, loss 3.038684844970703, acc=0.11388888955116272, loss=3.038684844970703
train: epoch 2, loss 1.6409640312194824, acc=0.34077778458595276, loss=1.6409640312194824
test: epoch 2, loss 2.690610408782959, acc=0.1944444477558136, loss=2.690610408782959
train: epoch 3, loss 1.1650959253311157, acc=0.5228888988494873, loss=1.1650959253311157
test: epoch 3, loss 2.368704319000244, acc=0.21666666865348816, loss=2.368704319000244
train: epoch 4, loss 0.907856285572052, acc=0.6206666827201843, loss=0.907856285572052
test: epoch 4, loss 1.9169771671295166, acc=0.31388887763023376, loss=1.9169771671295166
train: epoch 5, loss 0.7324870824813843, acc=0.6991666555404663, loss=0.7324870824813843
test: epoch 5, loss 2.174121141433716, acc=0.3166666626930237, loss=2.174121141433716
train: epoch 6, loss 0.6452073454856873, acc=0.7338333129882812, loss=0.6452073454856873
test: epoch 6, loss 2.0287890434265137, acc=0.3083333373069763, loss=2.0287890434265137
train: epoch 7, loss 0.5669180154800415, acc=0.7621111273765564, loss=0.5669180154800415
test: epoch 7, loss 2.2451279163360596, acc=0.35555556416511536, loss=2.2451279163360596
train: epoch 8, loss 0.527431845664978, acc=0.7810555696487427, loss=0.527431845664978
test: epoch 8, loss 2.0211992263793945, acc=0.375, loss=2.0211992263793945
train: epoch 9, loss 0.46849632263183594, acc=0.7996110916137695, loss=0.46849632263183594
test: epoch 9, loss 1.9900119304656982, acc=0.3333333432674408, loss=1.9900119304656982
train: epoch 10, loss 0.4489748477935791, acc=0.8086666464805603, loss=0.4489748477935791
test: epoch 10, loss 1.664371132850647, acc=0.38055557012557983, loss=1.664371132850647
train: epoch 11, loss 0.42533090710639954, acc=0.8228333592414856, loss=0.42533090710639954
test: epoch 11, loss 1.905678629875183, acc=0.375, loss=1.905678629875183
train: epoch 12, loss 0.37062200903892517, acc=0.8455555438995361, loss=0.37062200903892517
test: epoch 12, loss 2.086012601852417, acc=0.4194444417953491, loss=2.086012601852417
train: epoch 13, loss 0.34433770179748535, acc=0.8585000038146973, loss=0.34433770179748535
test: epoch 13, loss 1.8508487939834595, acc=0.4305555522441864, loss=1.8508487939834595
train: epoch 14, loss 0.32755470275878906, acc=0.8691666722297668, loss=0.32755470275878906
test: epoch 14, loss 1.6902269124984741, acc=0.49444442987442017, loss=1.6902269124984741
train: epoch 15, loss 0.2996763586997986, acc=0.8783888816833496, loss=0.2996763586997986
test: epoch 15, loss 1.7106571197509766, acc=0.4694444537162781, loss=1.7106571197509766
train: epoch 16, loss 0.27118349075317383, acc=0.8882777690887451, loss=0.27118349075317383
test: epoch 16, loss 1.3834609985351562, acc=0.5722222328186035, loss=1.3834609985351562
train: epoch 17, loss 0.26058876514434814, acc=0.8902222514152527, loss=0.26058876514434814
test: epoch 17, loss 1.495869517326355, acc=0.5777778029441833, loss=1.495869517326355
train: epoch 18, loss 0.24458950757980347, acc=0.8970000147819519, loss=0.24458950757980347
test: epoch 18, loss 1.3797205686569214, acc=0.6111111044883728, loss=1.3797205686569214
train: epoch 19, loss 0.23478777706623077, acc=0.9014999866485596, loss=0.23478777706623077
test: epoch 19, loss 1.334646463394165, acc=0.6138888597488403, loss=1.334646463394165
train: epoch 20, loss 0.2221498042345047, acc=0.9056666493415833, loss=0.2221498042345047
test: epoch 20, loss 1.464041829109192, acc=0.5416666865348816, loss=1.464041829109192
train: epoch 21, loss 0.22758960723876953, acc=0.9047777652740479, loss=0.22758960723876953
test: epoch 21, loss 1.339905023574829, acc=0.5805555582046509, loss=1.339905023574829
train: epoch 22, loss 0.21442878246307373, acc=0.909500002861023, loss=0.21442878246307373
test: epoch 22, loss 1.277421474456787, acc=0.675000011920929, loss=1.277421474456787
train: epoch 23, loss 0.20286494493484497, acc=0.9147777557373047, loss=0.20286494493484497
test: epoch 23, loss 1.1739439964294434, acc=0.6583333611488342, loss=1.1739439964294434
train: epoch 24, loss 0.2093994915485382, acc=0.9123333096504211, loss=0.2093994915485382
test: epoch 24, loss 1.0514006614685059, acc=0.6805555820465088, loss=1.0514006614685059
train: epoch 25, loss 0.18029600381851196, acc=0.9210000038146973, loss=0.18029600381851196
test: epoch 25, loss 1.0710774660110474, acc=0.7111111283302307, loss=1.0710774660110474
train: epoch 26, loss 0.1897195726633072, acc=0.9196666479110718, loss=0.1897195726633072
test: epoch 26, loss 1.1690945625305176, acc=0.6888889074325562, loss=1.1690945625305176
train: epoch 27, loss 0.18152181804180145, acc=0.9218888878822327, loss=0.18152181804180145
test: epoch 27, loss 0.7739229798316956, acc=0.7472222447395325, loss=0.7739229798316956
train: epoch 28, loss 0.18775802850723267, acc=0.9194444417953491, loss=0.18775802850723267
test: epoch 28, loss 0.7743562459945679, acc=0.7555555701255798, loss=0.7743562459945679
train: epoch 29, loss 0.17699970304965973, acc=0.9226666688919067, loss=0.17699970304965973
test: epoch 29, loss 1.0001111030578613, acc=0.7277777791023254, loss=1.0001111030578613
train: epoch 30, loss 0.1767978072166443, acc=0.9252777695655823, loss=0.1767978072166443
test: epoch 30, loss 0.9118893146514893, acc=0.7166666388511658, loss=0.9118893146514893
train: epoch 31, loss 0.16436584293842316, acc=0.929722249507904, loss=0.16436584293842316
test: epoch 31, loss 0.8128160238265991, acc=0.7916666865348816, loss=0.8128160238265991
train: epoch 32, loss 0.16231344640254974, acc=0.9319999814033508, loss=0.16231344640254974
test: epoch 32, loss 0.7408447265625, acc=0.8083333373069763, loss=0.7408447265625
train: epoch 33, loss 0.14728684723377228, acc=0.9334444403648376, loss=0.14728684723377228
test: epoch 33, loss 0.6838006973266602, acc=0.7805555462837219, loss=0.6838006973266602
train: epoch 34, loss 0.15886422991752625, acc=0.9298333525657654, loss=0.15886422991752625
test: epoch 34, loss 0.7274873852729797, acc=0.7861111164093018, loss=0.7274873852729797
train: epoch 35, loss 0.15131089091300964, acc=0.9361110925674438, loss=0.15131089091300964
test: epoch 35, loss 0.6393517255783081, acc=0.8194444179534912, loss=0.6393517255783081
train: epoch 36, loss 0.15722985565662384, acc=0.9315555691719055, loss=0.15722985565662384
test: epoch 36, loss 0.6752171516418457, acc=0.8111110925674438, loss=0.6752171516418457
train: epoch 37, loss 0.1306508481502533, acc=0.9409999847412109, loss=0.1306508481502533
test: epoch 37, loss 0.6110628247261047, acc=0.8194444179534912, loss=0.6110628247261047
train: epoch 38, loss 0.16047289967536926, acc=0.9301666617393494, loss=0.16047289967536926
test: epoch 38, loss 0.5446323752403259, acc=0.8222222328186035, loss=0.5446323752403259
train: epoch 39, loss 0.1364854872226715, acc=0.9370555281639099, loss=0.1364854872226715
test: epoch 39, loss 0.5459232330322266, acc=0.8027777671813965, loss=0.5459232330322266
train: epoch 40, loss 0.1494217962026596, acc=0.9362778067588806, loss=0.1494217962026596
test: epoch 40, loss 0.6353723406791687, acc=0.8138889074325562, loss=0.6353723406791687
train: epoch 41, loss 0.13936848938465118, acc=0.9360555410385132, loss=0.13936848938465118
test: epoch 41, loss 0.6841381788253784, acc=0.8222222328186035, loss=0.6841381788253784
train: epoch 42, loss 0.12762324512004852, acc=0.9416666626930237, loss=0.12762324512004852
test: epoch 42, loss 0.6632197499275208, acc=0.8222222328186035, loss=0.6632197499275208
train: epoch 43, loss 0.1317267119884491, acc=0.9393888711929321, loss=0.1317267119884491
test: epoch 43, loss 0.5000091195106506, acc=0.8194444179534912, loss=0.5000091195106506
train: epoch 44, loss 0.13763971626758575, acc=0.9384444355964661, loss=0.13763971626758575
test: epoch 44, loss 0.5684822201728821, acc=0.8111110925674438, loss=0.5684822201728821
train: epoch 45, loss 0.13487908244132996, acc=0.9395555257797241, loss=0.13487908244132996
test: epoch 45, loss 0.710162341594696, acc=0.8222222328186035, loss=0.710162341594696
train: epoch 46, loss 0.1362195909023285, acc=0.937333345413208, loss=0.1362195909023285
test: epoch 46, loss 0.5843161940574646, acc=0.8222222328186035, loss=0.5843161940574646
train: epoch 47, loss 0.12933231890201569, acc=0.9402777552604675, loss=0.12933231890201569
test: epoch 47, loss 0.6583600640296936, acc=0.8222222328186035, loss=0.6583600640296936
train: epoch 48, loss 0.13314096629619598, acc=0.9402777552604675, loss=0.13314096629619598
test: epoch 48, loss 0.6814460158348083, acc=0.8222222328186035, loss=0.6814460158348083
train: epoch 49, loss 0.12481223791837692, acc=0.9421666860580444, loss=0.12481223791837692
test: epoch 49, loss 0.6974471807479858, acc=0.8194444179534912, loss=0.6974471807479858
train: epoch 50, loss 0.13133493065834045, acc=0.9390555620193481, loss=0.13133493065834045
test: epoch 50, loss 0.596620500087738, acc=0.8222222328186035, loss=0.596620500087738
train: epoch 51, loss 0.11849243938922882, acc=0.9439444541931152, loss=0.11849243938922882
test: epoch 51, loss 0.7428523898124695, acc=0.8166666626930237, loss=0.7428523898124695
train: epoch 52, loss 0.1369072049856186, acc=0.9411110877990723, loss=0.1369072049856186
test: epoch 52, loss 0.6558418273925781, acc=0.8222222328186035, loss=0.6558418273925781
train: epoch 53, loss 0.1345118284225464, acc=0.9403889179229736, loss=0.1345118284225464
test: epoch 53, loss 0.5885332822799683, acc=0.8333333134651184, loss=0.5885332822799683
train: epoch 54, loss 0.12936685979366302, acc=0.9424444437026978, loss=0.12936685979366302
test: epoch 54, loss 0.5896897912025452, acc=0.8222222328186035, loss=0.5896897912025452
train: epoch 55, loss 0.1332576721906662, acc=0.9399444460868835, loss=0.1332576721906662
test: epoch 55, loss 0.5854251384735107, acc=0.8305555582046509, loss=0.5854251384735107
train: epoch 56, loss 0.12384330481290817, acc=0.9437222480773926, loss=0.12384330481290817
test: epoch 56, loss 0.5343979597091675, acc=0.8305555582046509, loss=0.5343979597091675
train: epoch 57, loss 0.12699773907661438, acc=0.9421666860580444, loss=0.12699773907661438
test: epoch 57, loss 0.5441041588783264, acc=0.8222222328186035, loss=0.5441041588783264
train: epoch 58, loss 0.13197389245033264, acc=0.9423333406448364, loss=0.13197389245033264
test: epoch 58, loss 0.6766707897186279, acc=0.8333333134651184, loss=0.6766707897186279
train: epoch 59, loss 0.1284506618976593, acc=0.9418888688087463, loss=0.1284506618976593
test: epoch 59, loss 0.5683977603912354, acc=0.8333333134651184, loss=0.5683977603912354
train: epoch 60, loss 0.11999303102493286, acc=0.9451666474342346, loss=0.11999303102493286
test: epoch 60, loss 0.6153870820999146, acc=0.8305555582046509, loss=0.6153870820999146
train: epoch 61, loss 0.12785109877586365, acc=0.9433888792991638, loss=0.12785109877586365
test: epoch 61, loss 0.5043277144432068, acc=0.8333333134651184, loss=0.5043277144432068
train: epoch 62, loss 0.1214827299118042, acc=0.9438333511352539, loss=0.1214827299118042
test: epoch 62, loss 0.5813198089599609, acc=0.8333333134651184, loss=0.5813198089599609
train: epoch 63, loss 0.11703437566757202, acc=0.944944441318512, loss=0.11703437566757202
test: epoch 63, loss 0.6384021639823914, acc=0.8305555582046509, loss=0.6384021639823914
train: epoch 64, loss 0.13061125576496124, acc=0.9433333277702332, loss=0.13061125576496124
test: epoch 64, loss 0.5620131492614746, acc=0.8305555582046509, loss=0.5620131492614746
train: epoch 65, loss 0.11752600222826004, acc=0.945722222328186, loss=0.11752600222826004
test: epoch 65, loss 0.5798285007476807, acc=0.8333333134651184, loss=0.5798285007476807
train: epoch 66, loss 0.12799838185310364, acc=0.9422777891159058, loss=0.12799838185310364
test: epoch 66, loss 0.6524964570999146, acc=0.8333333134651184, loss=0.6524964570999146
train: epoch 67, loss 0.11870364844799042, acc=0.9449999928474426, loss=0.11870364844799042
test: epoch 67, loss 0.5366198420524597, acc=0.8361111283302307, loss=0.5366198420524597
train: epoch 68, loss 0.11497222632169724, acc=0.9463889002799988, loss=0.11497222632169724
test: epoch 68, loss 0.622616171836853, acc=0.8333333134651184, loss=0.622616171836853
train: epoch 69, loss 0.12681354582309723, acc=0.9428889155387878, loss=0.12681354582309723
test: epoch 69, loss 0.5864797234535217, acc=0.8333333134651184, loss=0.5864797234535217
train: epoch 70, loss 0.12015849351882935, acc=0.9447222352027893, loss=0.12015849351882935
test: epoch 70, loss 0.6044750213623047, acc=0.8361111283302307, loss=0.6044750213623047
train: epoch 71, loss 0.12535029649734497, acc=0.9427222013473511, loss=0.12535029649734497
test: epoch 71, loss 0.43670037388801575, acc=0.8333333134651184, loss=0.43670037388801575
train: epoch 72, loss 0.11947399377822876, acc=0.9450555443763733, loss=0.11947399377822876
test: epoch 72, loss 0.6190027594566345, acc=0.8333333134651184, loss=0.6190027594566345
train: epoch 73, loss 0.11867114156484604, acc=0.9443333148956299, loss=0.11867114156484604
test: epoch 73, loss 0.4358769357204437, acc=0.8333333134651184, loss=0.4358769357204437
train: epoch 74, loss 0.12247494608163834, acc=0.9442777633666992, loss=0.12247494608163834
test: epoch 74, loss 0.5111334919929504, acc=0.8333333134651184, loss=0.5111334919929504
train: epoch 75, loss 0.122144415974617, acc=0.9444444179534912, loss=0.122144415974617
test: epoch 75, loss 0.5296412110328674, acc=0.8305555582046509, loss=0.5296412110328674
train: epoch 76, loss 0.12383782863616943, acc=0.9436110854148865, loss=0.12383782863616943
test: epoch 76, loss 0.6681853532791138, acc=0.8333333134651184, loss=0.6681853532791138
train: epoch 77, loss 0.12681066989898682, acc=0.9437777996063232, loss=0.12681066989898682
test: epoch 77, loss 0.42264464497566223, acc=0.824999988079071, loss=0.42264464497566223
train: epoch 78, loss 0.1174057349562645, acc=0.9446666836738586, loss=0.1174057349562645
test: epoch 78, loss 0.560709536075592, acc=0.8333333134651184, loss=0.560709536075592
train: epoch 79, loss 0.11954109370708466, acc=0.9448888897895813, loss=0.11954109370708466
test: epoch 79, loss 0.5317530632019043, acc=0.8333333134651184, loss=0.5317530632019043
train: epoch 80, loss 0.12283753603696823, acc=0.9448888897895813, loss=0.12283753603696823
test: epoch 80, loss 0.5586254000663757, acc=0.8333333134651184, loss=0.5586254000663757
train: epoch 81, loss 0.10674360394477844, acc=0.9481666684150696, loss=0.10674360394477844
test: epoch 81, loss 0.7085623741149902, acc=0.8333333134651184, loss=0.7085623741149902
train: epoch 82, loss 0.11907695233821869, acc=0.944944441318512, loss=0.11907695233821869
test: epoch 82, loss 0.6056289076805115, acc=0.8333333134651184, loss=0.6056289076805115
train: epoch 83, loss 0.11998262256383896, acc=0.9422777891159058, loss=0.11998262256383896
test: epoch 83, loss 0.5635910630226135, acc=0.8333333134651184, loss=0.5635910630226135
train: epoch 84, loss 0.126860111951828, acc=0.9421111345291138, loss=0.126860111951828
test: epoch 84, loss 0.5750836133956909, acc=0.8333333134651184, loss=0.5750836133956909
train: epoch 85, loss 0.11000584065914154, acc=0.9474999904632568, loss=0.11000584065914154
test: epoch 85, loss 0.6550679802894592, acc=0.8333333134651184, loss=0.6550679802894592
train: epoch 86, loss 0.1105404794216156, acc=0.9456111192703247, loss=0.1105404794216156
test: epoch 86, loss 0.6263928413391113, acc=0.8333333134651184, loss=0.6263928413391113
train: epoch 87, loss 0.12691733241081238, acc=0.9436110854148865, loss=0.12691733241081238
test: epoch 87, loss 0.5329013466835022, acc=0.8333333134651184, loss=0.5329013466835022
train: epoch 88, loss 0.12566901743412018, acc=0.9426110982894897, loss=0.12566901743412018
test: epoch 88, loss 0.5587961673736572, acc=0.8333333134651184, loss=0.5587961673736572
train: epoch 89, loss 0.1173388808965683, acc=0.945555567741394, loss=0.1173388808965683
test: epoch 89, loss 0.5642063021659851, acc=0.8333333134651184, loss=0.5642063021659851
train: epoch 90, loss 0.10997837036848068, acc=0.9463889002799988, loss=0.10997837036848068
test: epoch 90, loss 0.615916907787323, acc=0.8333333134651184, loss=0.615916907787323
train: epoch 91, loss 0.13035525381565094, acc=0.940666675567627, loss=0.13035525381565094
test: epoch 91, loss 0.4673077464103699, acc=0.8333333134651184, loss=0.4673077464103699
train: epoch 92, loss 0.11349397152662277, acc=0.9469444155693054, loss=0.11349397152662277
test: epoch 92, loss 0.5367682576179504, acc=0.8333333134651184, loss=0.5367682576179504
train: epoch 93, loss 0.10687568038702011, acc=0.9484999775886536, loss=0.10687568038702011
test: epoch 93, loss 0.4990544021129608, acc=0.8333333134651184, loss=0.4990544021129608
train: epoch 94, loss 0.11528071016073227, acc=0.945277750492096, loss=0.11528071016073227
test: epoch 94, loss 0.5866110920906067, acc=0.8333333134651184, loss=0.5866110920906067
train: epoch 95, loss 0.11460123211145401, acc=0.9467777609825134, loss=0.11460123211145401
test: epoch 95, loss 0.6390970945358276, acc=0.8333333134651184, loss=0.6390970945358276
train: epoch 96, loss 0.1240258514881134, acc=0.9443888664245605, loss=0.1240258514881134
test: epoch 96, loss 0.5773636102676392, acc=0.8333333134651184, loss=0.5773636102676392
train: epoch 97, loss 0.11645947396755219, acc=0.9465555548667908, loss=0.11645947396755219
test: epoch 97, loss 0.7477957010269165, acc=0.8333333134651184, loss=0.7477957010269165
train: epoch 98, loss 0.11521092057228088, acc=0.94605553150177, loss=0.11521092057228088
test: epoch 98, loss 0.5963216423988342, acc=0.8333333134651184, loss=0.5963216423988342
train: epoch 99, loss 0.1215917244553566, acc=0.9442777633666992, loss=0.1215917244553566
test: epoch 99, loss 0.6361491680145264, acc=0.8333333134651184, loss=0.6361491680145264
train: epoch 100, loss 0.11889449506998062, acc=0.9465000033378601, loss=0.11889449506998062
test: epoch 100, loss 0.5800338387489319, acc=0.8277778029441833, loss=0.5800338387489319
train: epoch 101, loss 0.10858016461133957, acc=0.9463333487510681, loss=0.10858016461133957
test: epoch 101, loss 0.5112490653991699, acc=0.8333333134651184, loss=0.5112490653991699
train: epoch 102, loss 0.12951141595840454, acc=0.9426110982894897, loss=0.12951141595840454
test: epoch 102, loss 0.5931734442710876, acc=0.8333333134651184, loss=0.5931734442710876
train: epoch 103, loss 0.12621530890464783, acc=0.9445555806159973, loss=0.12621530890464783
test: epoch 103, loss 0.5360662937164307, acc=0.8333333134651184, loss=0.5360662937164307
train: epoch 104, loss 0.11162685602903366, acc=0.9471666812896729, loss=0.11162685602903366
test: epoch 104, loss 0.5404138565063477, acc=0.8361111283302307, loss=0.5404138565063477
train: epoch 105, loss 0.11580663919448853, acc=0.9461666941642761, loss=0.11580663919448853
test: epoch 105, loss 0.5902398824691772, acc=0.8333333134651184, loss=0.5902398824691772
train: epoch 106, loss 0.12130788713693619, acc=0.9441666603088379, loss=0.12130788713693619
test: epoch 106, loss 0.5821687579154968, acc=0.8416666388511658, loss=0.5821687579154968
train: epoch 107, loss 0.12451432645320892, acc=0.944611132144928, loss=0.12451432645320892
test: epoch 107, loss 0.5275536775588989, acc=0.8444444537162781, loss=0.5275536775588989
train: epoch 108, loss 0.11733715981245041, acc=0.9455000162124634, loss=0.11733715981245041
test: epoch 108, loss 0.5537949800491333, acc=0.8472222089767456, loss=0.5537949800491333
train: epoch 109, loss 0.1196168065071106, acc=0.9454444646835327, loss=0.1196168065071106
test: epoch 109, loss 0.4572468400001526, acc=0.8416666388511658, loss=0.4572468400001526
train: epoch 110, loss 0.11366242915391922, acc=0.9468333125114441, loss=0.11366242915391922
test: epoch 110, loss 0.4771217405796051, acc=0.8472222089767456, loss=0.4771217405796051
train: epoch 111, loss 0.10231365263462067, acc=0.9494444727897644, loss=0.10231365263462067
test: epoch 111, loss 0.48877644538879395, acc=0.8472222089767456, loss=0.48877644538879395
train: epoch 112, loss 0.11065364629030228, acc=0.9462777972221375, loss=0.11065364629030228
test: epoch 112, loss 0.5139310956001282, acc=0.8500000238418579, loss=0.5139310956001282
train: epoch 113, loss 0.10764714330434799, acc=0.948722243309021, loss=0.10764714330434799
test: epoch 113, loss 0.5954688191413879, acc=0.855555534362793, loss=0.5954688191413879
train: epoch 114, loss 0.10743910074234009, acc=0.9483333230018616, loss=0.10743910074234009
test: epoch 114, loss 0.45754358172416687, acc=0.8611111044883728, loss=0.45754358172416687
train: epoch 115, loss 0.10646579414606094, acc=0.9483333230018616, loss=0.10646579414606094
test: epoch 115, loss 0.41329389810562134, acc=0.8611111044883728, loss=0.41329389810562134
train: epoch 116, loss 0.1094411090016365, acc=0.94605553150177, loss=0.1094411090016365
test: epoch 116, loss 0.36354541778564453, acc=0.8611111044883728, loss=0.36354541778564453
train: epoch 117, loss 0.11275829374790192, acc=0.9478889107704163, loss=0.11275829374790192
test: epoch 117, loss 0.3670894205570221, acc=0.8500000238418579, loss=0.3670894205570221
train: epoch 118, loss 0.12325109541416168, acc=0.9434444308280945, loss=0.12325109541416168
test: epoch 118, loss 0.5040897727012634, acc=0.8583333492279053, loss=0.5040897727012634
train: epoch 119, loss 0.11089124530553818, acc=0.945888876914978, loss=0.11089124530553818
test: epoch 119, loss 0.4005434215068817, acc=0.8583333492279053, loss=0.4005434215068817
train: epoch 120, loss 0.12206950038671494, acc=0.9437222480773926, loss=0.12206950038671494
test: epoch 120, loss 0.3442111909389496, acc=0.8583333492279053, loss=0.3442111909389496
train: epoch 121, loss 0.12843096256256104, acc=0.9442777633666992, loss=0.12843096256256104
test: epoch 121, loss 0.4006749093532562, acc=0.8611111044883728, loss=0.4006749093532562
train: epoch 122, loss 0.10943929105997086, acc=0.9481111168861389, loss=0.10943929105997086
test: epoch 122, loss 0.5513370037078857, acc=0.8611111044883728, loss=0.5513370037078857
train: epoch 123, loss 0.11176840215921402, acc=0.9471111297607422, loss=0.11176840215921402
test: epoch 123, loss 0.43031126260757446, acc=0.8583333492279053, loss=0.43031126260757446
train: epoch 124, loss 0.11461909115314484, acc=0.9461110830307007, loss=0.11461909115314484
test: epoch 124, loss 0.42549243569374084, acc=0.8583333492279053, loss=0.42549243569374084
train: epoch 125, loss 0.13321730494499207, acc=0.9412222504615784, loss=0.13321730494499207
test: epoch 125, loss 0.500835120677948, acc=0.855555534362793, loss=0.500835120677948
train: epoch 126, loss 0.12003875523805618, acc=0.9448333382606506, loss=0.12003875523805618
test: epoch 126, loss 0.4234333634376526, acc=0.8583333492279053, loss=0.4234333634376526
train: epoch 127, loss 0.11459071934223175, acc=0.9471666812896729, loss=0.11459071934223175
test: epoch 127, loss 0.46621960401535034, acc=0.8611111044883728, loss=0.46621960401535034
train: epoch 128, loss 0.10553030669689178, acc=0.9477221965789795, loss=0.10553030669689178
test: epoch 128, loss 0.5103328227996826, acc=0.8611111044883728, loss=0.5103328227996826
train: epoch 129, loss 0.10676117986440659, acc=0.9470555782318115, loss=0.10676117986440659
test: epoch 129, loss 0.4850558042526245, acc=0.8611111044883728, loss=0.4850558042526245
train: epoch 130, loss 0.10588373243808746, acc=0.9484444260597229, loss=0.10588373243808746
test: epoch 130, loss 0.6682517528533936, acc=0.8611111044883728, loss=0.6682517528533936
train: epoch 131, loss 0.11137723177671432, acc=0.9470555782318115, loss=0.11137723177671432
test: epoch 131, loss 0.4320787191390991, acc=0.8611111044883728, loss=0.4320787191390991
train: epoch 132, loss 0.10869480669498444, acc=0.9471666812896729, loss=0.10869480669498444
test: epoch 132, loss 0.43466001749038696, acc=0.8611111044883728, loss=0.43466001749038696
train: epoch 133, loss 0.10380716621875763, acc=0.9502221941947937, loss=0.10380716621875763
test: epoch 133, loss 0.35155367851257324, acc=0.8583333492279053, loss=0.35155367851257324
train: epoch 134, loss 0.12487079203128815, acc=0.9437777996063232, loss=0.12487079203128815
test: epoch 134, loss 0.4463273882865906, acc=0.8583333492279053, loss=0.4463273882865906
train: epoch 135, loss 0.11845692247152328, acc=0.9459444284439087, loss=0.11845692247152328
test: epoch 135, loss 0.4874855577945709, acc=0.8583333492279053, loss=0.4874855577945709
train: epoch 136, loss 0.1215115413069725, acc=0.9461110830307007, loss=0.1215115413069725
test: epoch 136, loss 0.3952030837535858, acc=0.8583333492279053, loss=0.3952030837535858
train: epoch 137, loss 0.1170407310128212, acc=0.9438889026641846, loss=0.1170407310128212
test: epoch 137, loss 0.441799134016037, acc=0.8583333492279053, loss=0.441799134016037
train: epoch 138, loss 0.11366784572601318, acc=0.9456666707992554, loss=0.11366784572601318
test: epoch 138, loss 0.3857622742652893, acc=0.8611111044883728, loss=0.3857622742652893
train: epoch 139, loss 0.10394323617219925, acc=0.9486666917800903, loss=0.10394323617219925
test: epoch 139, loss 0.4617767333984375, acc=0.8611111044883728, loss=0.4617767333984375
train: epoch 140, loss 0.10813894867897034, acc=0.9480555653572083, loss=0.10813894867897034
test: epoch 140, loss 0.44103842973709106, acc=0.8611111044883728, loss=0.44103842973709106
train: epoch 141, loss 0.1423545628786087, acc=0.9441111087799072, loss=0.1423545628786087
test: epoch 141, loss 0.4298751950263977, acc=0.8583333492279053, loss=0.4298751950263977
train: epoch 142, loss 0.1202499121427536, acc=0.945277750492096, loss=0.1202499121427536
test: epoch 142, loss 0.45860591530799866, acc=0.8527777791023254, loss=0.45860591530799866
train: epoch 143, loss 0.12852750718593597, acc=0.9407222270965576, loss=0.12852750718593597
test: epoch 143, loss 0.40354692935943604, acc=0.855555534362793, loss=0.40354692935943604
train: epoch 144, loss 0.12335797399282455, acc=0.9409999847412109, loss=0.12335797399282455
test: epoch 144, loss 0.521855354309082, acc=0.855555534362793, loss=0.521855354309082
train: epoch 145, loss 0.12530651688575745, acc=0.9396666884422302, loss=0.12530651688575745
test: epoch 145, loss 0.4670848846435547, acc=0.855555534362793, loss=0.4670848846435547
train: epoch 146, loss 0.12281724065542221, acc=0.9422222375869751, loss=0.12281724065542221
test: epoch 146, loss 0.45580145716667175, acc=0.8611111044883728, loss=0.45580145716667175
train: epoch 147, loss 0.12786170840263367, acc=0.9445000290870667, loss=0.12786170840263367
test: epoch 147, loss 0.41024908423423767, acc=0.8611111044883728, loss=0.41024908423423767
train: epoch 148, loss 0.11553357541561127, acc=0.944944441318512, loss=0.11553357541561127
test: epoch 148, loss 0.47994744777679443, acc=0.875, loss=0.47994744777679443
train: epoch 149, loss 0.11251770704984665, acc=0.9455000162124634, loss=0.11251770704984665
test: epoch 149, loss 0.36194348335266113, acc=0.8861111402511597, loss=0.36194348335266113
train: epoch 150, loss 0.10454649478197098, acc=0.9490000009536743, loss=0.10454649478197098
test: epoch 150, loss 0.27514389157295227, acc=0.8916666507720947, loss=0.27514389157295227
