# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=2.0", "--temp_decay=1", "--one_hot=false", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=328494846, receiver_embed_dim=128, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.7138185501098633, acc=0.11444444209337234, loss=2.7138185501098633
test: epoch 1, loss 5.191498756408691, acc=0.09166666865348816, loss=5.191498756408691
train: epoch 2, loss 1.3473972082138062, acc=0.4469444453716278, loss=1.3473972082138062
test: epoch 2, loss 3.2974343299865723, acc=0.19166666269302368, loss=3.2974343299865723
train: epoch 3, loss 0.8309667110443115, acc=0.6531111001968384, loss=0.8309667110443115
test: epoch 3, loss 4.009031772613525, acc=0.20555555820465088, loss=4.009031772613525
train: epoch 4, loss 0.5980830192565918, acc=0.7592222094535828, loss=0.5980830192565918
test: epoch 4, loss 2.8765463829040527, acc=0.29722222685813904, loss=2.8765463829040527
train: epoch 5, loss 0.43836525082588196, acc=0.8378888964653015, loss=0.43836525082588196
test: epoch 5, loss 2.7641289234161377, acc=0.35277777910232544, loss=2.7641289234161377
train: epoch 6, loss 0.344820499420166, acc=0.8743333220481873, loss=0.344820499420166
test: epoch 6, loss 2.259526014328003, acc=0.3222222328186035, loss=2.259526014328003
train: epoch 7, loss 0.2604246437549591, acc=0.9079999923706055, loss=0.2604246437549591
test: epoch 7, loss 2.6562094688415527, acc=0.31111112236976624, loss=2.6562094688415527
train: epoch 8, loss 0.23613564670085907, acc=0.9198333621025085, loss=0.23613564670085907
test: epoch 8, loss 2.536259412765503, acc=0.3638888895511627, loss=2.536259412765503
train: epoch 9, loss 0.21507170796394348, acc=0.9271110892295837, loss=0.21507170796394348
test: epoch 9, loss 2.6530818939208984, acc=0.34166666865348816, loss=2.6530818939208984
train: epoch 10, loss 0.17548778653144836, acc=0.9433888792991638, loss=0.17548778653144836
test: epoch 10, loss 3.0489261150360107, acc=0.28611111640930176, loss=3.0489261150360107
train: epoch 11, loss 0.15685662627220154, acc=0.9477777481079102, loss=0.15685662627220154
test: epoch 11, loss 2.292999267578125, acc=0.4277777671813965, loss=2.292999267578125
train: epoch 12, loss 0.13447484374046326, acc=0.9558333158493042, loss=0.13447484374046326
test: epoch 12, loss 2.7323596477508545, acc=0.375, loss=2.7323596477508545
train: epoch 13, loss 0.12588413059711456, acc=0.9578889012336731, loss=0.12588413059711456
test: epoch 13, loss 2.8194363117218018, acc=0.375, loss=2.8194363117218018
train: epoch 14, loss 0.11902324855327606, acc=0.9609444737434387, loss=0.11902324855327606
test: epoch 14, loss 2.752559185028076, acc=0.4138889014720917, loss=2.752559185028076
train: epoch 15, loss 0.10625458508729935, acc=0.965499997138977, loss=0.10625458508729935
test: epoch 15, loss 2.3851006031036377, acc=0.38333332538604736, loss=2.3851006031036377
train: epoch 16, loss 0.09578503668308258, acc=0.9696111083030701, loss=0.09578503668308258
test: epoch 16, loss 3.398357629776001, acc=0.4583333432674408, loss=3.398357629776001
train: epoch 17, loss 0.08922509849071503, acc=0.9722777605056763, loss=0.08922509849071503
test: epoch 17, loss 2.792686700820923, acc=0.42222222685813904, loss=2.792686700820923
train: epoch 18, loss 0.09424201399087906, acc=0.9698333144187927, loss=0.09424201399087906
test: epoch 18, loss 3.013688325881958, acc=0.4333333373069763, loss=3.013688325881958
train: epoch 19, loss 0.10379038006067276, acc=0.9682222008705139, loss=0.10379038006067276
test: epoch 19, loss 2.3794071674346924, acc=0.4444444477558136, loss=2.3794071674346924
train: epoch 20, loss 0.08953060209751129, acc=0.972000002861023, loss=0.08953060209751129
test: epoch 20, loss 2.516569137573242, acc=0.42500001192092896, loss=2.516569137573242
train: epoch 21, loss 0.07521814852952957, acc=0.9758889079093933, loss=0.07521814852952957
test: epoch 21, loss 2.717528820037842, acc=0.4861111044883728, loss=2.717528820037842
train: epoch 22, loss 0.07490155845880508, acc=0.9756666421890259, loss=0.07490155845880508
test: epoch 22, loss 2.836085796356201, acc=0.4138889014720917, loss=2.836085796356201
train: epoch 23, loss 0.0773058533668518, acc=0.9751666784286499, loss=0.0773058533668518
test: epoch 23, loss 2.40533185005188, acc=0.43611112236976624, loss=2.40533185005188
train: epoch 24, loss 0.07291249185800552, acc=0.9773889183998108, loss=0.07291249185800552
test: epoch 24, loss 2.686951160430908, acc=0.42222222685813904, loss=2.686951160430908
train: epoch 25, loss 0.07504022121429443, acc=0.977222204208374, loss=0.07504022121429443
test: epoch 25, loss 2.6716740131378174, acc=0.41111111640930176, loss=2.6716740131378174
train: epoch 26, loss 0.06287553906440735, acc=0.9804999828338623, loss=0.06287553906440735
test: epoch 26, loss 2.9483542442321777, acc=0.4583333432674408, loss=2.9483542442321777
train: epoch 27, loss 0.0669620931148529, acc=0.9787222146987915, loss=0.0669620931148529
test: epoch 27, loss 3.866213321685791, acc=0.3222222328186035, loss=3.866213321685791
train: epoch 28, loss 0.076667420566082, acc=0.9778333306312561, loss=0.076667420566082
test: epoch 28, loss 2.619345188140869, acc=0.5027777552604675, loss=2.619345188140869
train: epoch 29, loss 0.06065750867128372, acc=0.9822777509689331, loss=0.06065750867128372
test: epoch 29, loss 2.3338510990142822, acc=0.4833333194255829, loss=2.3338510990142822
train: epoch 30, loss 0.0646960437297821, acc=0.9808889031410217, loss=0.0646960437297821
test: epoch 30, loss 2.6331369876861572, acc=0.5111111402511597, loss=2.6331369876861572
train: epoch 31, loss 0.05078812316060066, acc=0.9837777614593506, loss=0.05078812316060066
test: epoch 31, loss 2.506254196166992, acc=0.519444465637207, loss=2.506254196166992
train: epoch 32, loss 0.05941781401634216, acc=0.9817777872085571, loss=0.05941781401634216
test: epoch 32, loss 2.5523390769958496, acc=0.5694444179534912, loss=2.5523390769958496
train: epoch 33, loss 0.052222128957509995, acc=0.9843888878822327, loss=0.052222128957509995
test: epoch 33, loss 1.9238715171813965, acc=0.5638889074325562, loss=1.9238715171813965
train: epoch 34, loss 0.0557674802839756, acc=0.9837222099304199, loss=0.0557674802839756
test: epoch 34, loss 2.0848116874694824, acc=0.5916666388511658, loss=2.0848116874694824
train: epoch 35, loss 0.05609515681862831, acc=0.9828888773918152, loss=0.05609515681862831
test: epoch 35, loss 1.532283902168274, acc=0.6277777552604675, loss=1.532283902168274
train: epoch 36, loss 0.04391875118017197, acc=0.987500011920929, loss=0.04391875118017197
test: epoch 36, loss 2.570219039916992, acc=0.4749999940395355, loss=2.570219039916992
train: epoch 37, loss 0.053928159177303314, acc=0.9849444627761841, loss=0.053928159177303314
test: epoch 37, loss 2.234201192855835, acc=0.5722222328186035, loss=2.234201192855835
train: epoch 38, loss 0.047992367297410965, acc=0.9862222075462341, loss=0.047992367297410965
test: epoch 38, loss 1.921796202659607, acc=0.5666666626930237, loss=1.921796202659607
train: epoch 39, loss 0.048413123935461044, acc=0.9854999780654907, loss=0.048413123935461044
test: epoch 39, loss 1.9715996980667114, acc=0.5972222089767456, loss=1.9715996980667114
train: epoch 40, loss 0.034553807228803635, acc=0.9900000095367432, loss=0.034553807228803635
test: epoch 40, loss 2.469726324081421, acc=0.6277777552604675, loss=2.469726324081421
train: epoch 41, loss 0.04887349531054497, acc=0.9866111278533936, loss=0.04887349531054497
test: epoch 41, loss 1.7683647871017456, acc=0.6472222208976746, loss=1.7683647871017456
train: epoch 42, loss 0.03371948003768921, acc=0.9900555610656738, loss=0.03371948003768921
test: epoch 42, loss 2.100118398666382, acc=0.6305555701255798, loss=2.100118398666382
train: epoch 43, loss 0.04398871585726738, acc=0.9867222309112549, loss=0.04398871585726738
test: epoch 43, loss 1.8100396394729614, acc=0.644444465637207, loss=1.8100396394729614
train: epoch 44, loss 0.040128063410520554, acc=0.9888333082199097, loss=0.040128063410520554
test: epoch 44, loss 1.6792012453079224, acc=0.5694444179534912, loss=1.6792012453079224
train: epoch 45, loss 0.04836167022585869, acc=0.9868888854980469, loss=0.04836167022585869
test: epoch 45, loss 1.6181594133377075, acc=0.5777778029441833, loss=1.6181594133377075
train: epoch 46, loss 0.03291402384638786, acc=0.9904444217681885, loss=0.03291402384638786
test: epoch 46, loss 1.7749892473220825, acc=0.6666666865348816, loss=1.7749892473220825
train: epoch 47, loss 0.04689794033765793, acc=0.9887222051620483, loss=0.04689794033765793
test: epoch 47, loss 1.3930881023406982, acc=0.6777777671813965, loss=1.3930881023406982
train: epoch 48, loss 0.035549864172935486, acc=0.9899444580078125, loss=0.035549864172935486
test: epoch 48, loss 1.1956214904785156, acc=0.7388888597488403, loss=1.1956214904785156
train: epoch 49, loss 0.040540650486946106, acc=0.988611102104187, loss=0.040540650486946106
test: epoch 49, loss 2.213573932647705, acc=0.5527777671813965, loss=2.213573932647705
train: epoch 50, loss 0.03351471200585365, acc=0.9909444451332092, loss=0.03351471200585365
test: epoch 50, loss 1.4859107732772827, acc=0.730555534362793, loss=1.4859107732772827
train: epoch 51, loss 0.03839495778083801, acc=0.9890555739402771, loss=0.03839495778083801
test: epoch 51, loss 1.4697763919830322, acc=0.7027778029441833, loss=1.4697763919830322
train: epoch 52, loss 0.030078886076807976, acc=0.9923333525657654, loss=0.030078886076807976
test: epoch 52, loss 1.1843464374542236, acc=0.769444465637207, loss=1.1843464374542236
train: epoch 53, loss 0.04078062251210213, acc=0.988444447517395, loss=0.04078062251210213
test: epoch 53, loss 1.367464542388916, acc=0.7749999761581421, loss=1.367464542388916
train: epoch 54, loss 0.030326109379529953, acc=0.9922778010368347, loss=0.030326109379529953
test: epoch 54, loss 0.9687244296073914, acc=0.769444465637207, loss=0.9687244296073914
train: epoch 55, loss 0.03515440225601196, acc=0.9907222390174866, loss=0.03515440225601196
test: epoch 55, loss 1.4317905902862549, acc=0.7861111164093018, loss=1.4317905902862549
train: epoch 56, loss 0.030666256323456764, acc=0.9922778010368347, loss=0.030666256323456764
test: epoch 56, loss 0.9772294759750366, acc=0.8138889074325562, loss=0.9772294759750366
train: epoch 57, loss 0.026027338579297066, acc=0.9932222366333008, loss=0.026027338579297066
test: epoch 57, loss 0.8074133992195129, acc=0.8416666388511658, loss=0.8074133992195129
train: epoch 58, loss 0.0349835604429245, acc=0.99144446849823, loss=0.0349835604429245
test: epoch 58, loss 1.1742924451828003, acc=0.7583333253860474, loss=1.1742924451828003
train: epoch 59, loss 0.036019887775182724, acc=0.9906111359596252, loss=0.036019887775182724
test: epoch 59, loss 0.8099543452262878, acc=0.8444444537162781, loss=0.8099543452262878
train: epoch 60, loss 0.018554041162133217, acc=0.9953333139419556, loss=0.018554041162133217
test: epoch 60, loss 0.36890891194343567, acc=0.9055555462837219, loss=0.36890891194343567
train: epoch 61, loss 0.023021914064884186, acc=0.9941111207008362, loss=0.023021914064884186
test: epoch 61, loss 0.8097278475761414, acc=0.8777777552604675, loss=0.8097278475761414
train: epoch 62, loss 0.026951411738991737, acc=0.9931111335754395, loss=0.026951411738991737
test: epoch 62, loss 0.8629696369171143, acc=0.8305555582046509, loss=0.8629696369171143
train: epoch 63, loss 0.022875871509313583, acc=0.9938889145851135, loss=0.022875871509313583
test: epoch 63, loss 0.842613935470581, acc=0.8361111283302307, loss=0.842613935470581
train: epoch 64, loss 0.0157517921179533, acc=0.9956111311912537, loss=0.0157517921179533
test: epoch 64, loss 0.6889693737030029, acc=0.8222222328186035, loss=0.6889693737030029
train: epoch 65, loss 0.024909544736146927, acc=0.9936666488647461, loss=0.024909544736146927
test: epoch 65, loss 0.6283233165740967, acc=0.8777777552604675, loss=0.6283233165740967
train: epoch 66, loss 0.017932547256350517, acc=0.9947222471237183, loss=0.017932547256350517
test: epoch 66, loss 0.36139392852783203, acc=0.9055555462837219, loss=0.36139392852783203
train: epoch 67, loss 0.024043163284659386, acc=0.9941666722297668, loss=0.024043163284659386
test: epoch 67, loss 0.5351009964942932, acc=0.894444465637207, loss=0.5351009964942932
train: epoch 68, loss 0.018754281103610992, acc=0.9951666593551636, loss=0.018754281103610992
test: epoch 68, loss 0.37531980872154236, acc=0.9027777910232544, loss=0.37531980872154236
train: epoch 69, loss 0.02438993938267231, acc=0.9941666722297668, loss=0.02438993938267231
test: epoch 69, loss 0.6873421669006348, acc=0.8888888955116272, loss=0.6873421669006348
train: epoch 70, loss 0.01274818740785122, acc=0.996833324432373, loss=0.01274818740785122
test: epoch 70, loss 0.2880724370479584, acc=0.925000011920929, loss=0.2880724370479584
train: epoch 71, loss 0.019403865560889244, acc=0.9952777624130249, loss=0.019403865560889244
test: epoch 71, loss 0.24813736975193024, acc=0.9583333134651184, loss=0.24813736975193024
train: epoch 72, loss 0.021545371040701866, acc=0.9946110844612122, loss=0.021545371040701866
test: epoch 72, loss 0.3949553370475769, acc=0.8861111402511597, loss=0.3949553370475769
train: epoch 73, loss 0.012482034973800182, acc=0.9973333477973938, loss=0.012482034973800182
test: epoch 73, loss 0.3894239366054535, acc=0.9222221970558167, loss=0.3894239366054535
train: epoch 74, loss 0.018757492303848267, acc=0.9956666827201843, loss=0.018757492303848267
test: epoch 74, loss 0.44571706652641296, acc=0.9138888716697693, loss=0.44571706652641296
train: epoch 75, loss 0.016642866656184196, acc=0.9955000281333923, loss=0.016642866656184196
test: epoch 75, loss 0.44860976934432983, acc=0.9277777671813965, loss=0.44860976934432983
train: epoch 76, loss 0.015544241294264793, acc=0.9963333606719971, loss=0.015544241294264793
test: epoch 76, loss 0.22158432006835938, acc=0.9333333373069763, loss=0.22158432006835938
train: epoch 77, loss 0.01215128879994154, acc=0.9968888759613037, loss=0.01215128879994154
test: epoch 77, loss 0.2755284309387207, acc=0.9527778029441833, loss=0.2755284309387207
train: epoch 78, loss 0.021472077816724777, acc=0.9958333373069763, loss=0.021472077816724777
test: epoch 78, loss 0.3002792298793793, acc=0.9527778029441833, loss=0.3002792298793793
train: epoch 79, loss 0.008941826410591602, acc=0.9979444742202759, loss=0.008941826410591602
test: epoch 79, loss 0.23467233777046204, acc=0.9555555582046509, loss=0.23467233777046204
train: epoch 80, loss 0.018135294318199158, acc=0.9958333373069763, loss=0.018135294318199158
test: epoch 80, loss 0.42469584941864014, acc=0.9416666626930237, loss=0.42469584941864014
train: epoch 81, loss 0.01525314711034298, acc=0.9965000152587891, loss=0.01525314711034298
test: epoch 81, loss 0.10968068987131119, acc=0.9750000238418579, loss=0.10968068987131119
train: epoch 82, loss 0.013013502582907677, acc=0.9977777600288391, loss=0.013013502582907677
test: epoch 82, loss 0.24418236315250397, acc=0.949999988079071, loss=0.24418236315250397
train: epoch 83, loss 0.015534858219325542, acc=0.996999979019165, loss=0.015534858219325542
test: epoch 83, loss 0.1224491074681282, acc=0.9750000238418579, loss=0.1224491074681282
train: epoch 84, loss 0.01946382410824299, acc=0.995888888835907, loss=0.01946382410824299
test: epoch 84, loss 0.12021517753601074, acc=0.9611111283302307, loss=0.12021517753601074
train: epoch 85, loss 0.0076316059567034245, acc=0.9980555772781372, loss=0.0076316059567034245
test: epoch 85, loss 0.14516706764698029, acc=0.9666666388511658, loss=0.14516706764698029
train: epoch 86, loss 0.007898718118667603, acc=0.9979444742202759, loss=0.007898718118667603
test: epoch 86, loss 0.14976637065410614, acc=0.9722222089767456, loss=0.14976637065410614
train: epoch 87, loss 0.010850483551621437, acc=0.9972777962684631, loss=0.010850483551621437
test: epoch 87, loss 0.07483462244272232, acc=0.9777777791023254, loss=0.07483462244272232
train: epoch 88, loss 0.013905922882258892, acc=0.9973888993263245, loss=0.013905922882258892
test: epoch 88, loss 0.1263868659734726, acc=0.9833333492279053, loss=0.1263868659734726
train: epoch 89, loss 0.010848654434084892, acc=0.9973888993263245, loss=0.010848654434084892
test: epoch 89, loss 0.06606398522853851, acc=0.9861111044883728, loss=0.06606398522853851
train: epoch 90, loss 0.00991756934672594, acc=0.9981666803359985, loss=0.00991756934672594
test: epoch 90, loss 0.08392556756734848, acc=0.9861111044883728, loss=0.08392556756734848
train: epoch 91, loss 0.003958455752581358, acc=0.9992777705192566, loss=0.003958455752581358
test: epoch 91, loss 0.2188679575920105, acc=0.980555534362793, loss=0.2188679575920105
train: epoch 92, loss 0.015144250355660915, acc=0.9974444508552551, loss=0.015144250355660915
test: epoch 92, loss 0.09274370968341827, acc=0.980555534362793, loss=0.09274370968341827
train: epoch 93, loss 0.010684833861887455, acc=0.9977222084999084, loss=0.010684833861887455
test: epoch 93, loss 0.09358154237270355, acc=0.980555534362793, loss=0.09358154237270355
train: epoch 94, loss 0.013088331557810307, acc=0.9967777729034424, loss=0.013088331557810307
test: epoch 94, loss 0.028781011700630188, acc=0.9944444298744202, loss=0.028781011700630188
