# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=2.0", "--temp_decay=1", "--one_hot=true", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=235622842, receiver_embed_dim=128, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.644137144088745, acc=0.12244444340467453, loss=2.644137144088745
test: epoch 1, loss 3.9730260372161865, acc=0.10000000149011612, loss=3.9730260372161865
train: epoch 2, loss 1.4658643007278442, acc=0.386944442987442, loss=1.4658643007278442
test: epoch 2, loss 3.646477699279785, acc=0.1666666716337204, loss=3.646477699279785
train: epoch 3, loss 0.881405234336853, acc=0.6422777771949768, loss=0.881405234336853
test: epoch 3, loss 3.029547929763794, acc=0.25555557012557983, loss=3.029547929763794
train: epoch 4, loss 0.6085621118545532, acc=0.7523333430290222, loss=0.6085621118545532
test: epoch 4, loss 3.4708683490753174, acc=0.24166665971279144, loss=3.4708683490753174
train: epoch 5, loss 0.49483349919319153, acc=0.7956110835075378, loss=0.49483349919319153
test: epoch 5, loss 2.3921196460723877, acc=0.30000001192092896, loss=2.3921196460723877
train: epoch 6, loss 0.39796581864356995, acc=0.8351666927337646, loss=0.39796581864356995
test: epoch 6, loss 2.5536699295043945, acc=0.24722221493721008, loss=2.5536699295043945
train: epoch 7, loss 0.33940210938453674, acc=0.8631666898727417, loss=0.33940210938453674
test: epoch 7, loss 2.463484525680542, acc=0.33888888359069824, loss=2.463484525680542
train: epoch 8, loss 0.2984158992767334, acc=0.8798888921737671, loss=0.2984158992767334
test: epoch 8, loss 1.9684728384017944, acc=0.4000000059604645, loss=1.9684728384017944
train: epoch 9, loss 0.2499312460422516, acc=0.9016666412353516, loss=0.2499312460422516
test: epoch 9, loss 2.874876022338867, acc=0.38333332538604736, loss=2.874876022338867
train: epoch 10, loss 0.23502062261104584, acc=0.901888906955719, loss=0.23502062261104584
test: epoch 10, loss 2.7446248531341553, acc=0.31111112236976624, loss=2.7446248531341553
train: epoch 11, loss 0.2045886069536209, acc=0.9192777872085571, loss=0.2045886069536209
test: epoch 11, loss 3.0161261558532715, acc=0.39444443583488464, loss=3.0161261558532715
train: epoch 12, loss 0.19277797639369965, acc=0.9313333630561829, loss=0.19277797639369965
test: epoch 12, loss 2.4362552165985107, acc=0.44999998807907104, loss=2.4362552165985107
train: epoch 13, loss 0.15935657918453217, acc=0.948722243309021, loss=0.15935657918453217
test: epoch 13, loss 2.76249098777771, acc=0.40833333134651184, loss=2.76249098777771
train: epoch 14, loss 0.14320334792137146, acc=0.9531111121177673, loss=0.14320334792137146
test: epoch 14, loss 2.321425199508667, acc=0.3916666805744171, loss=2.321425199508667
train: epoch 15, loss 0.14336585998535156, acc=0.9537222385406494, loss=0.14336585998535156
test: epoch 15, loss 2.334764242172241, acc=0.43888887763023376, loss=2.334764242172241
train: epoch 16, loss 0.1351032704114914, acc=0.9574999809265137, loss=0.1351032704114914
test: epoch 16, loss 2.6774353981018066, acc=0.3888888955116272, loss=2.6774353981018066
train: epoch 17, loss 0.12252088636159897, acc=0.961222231388092, loss=0.12252088636159897
test: epoch 17, loss 2.306262969970703, acc=0.42222222685813904, loss=2.306262969970703
train: epoch 18, loss 0.10768572241067886, acc=0.9664444327354431, loss=0.10768572241067886
test: epoch 18, loss 2.9523050785064697, acc=0.375, loss=2.9523050785064697
train: epoch 19, loss 0.11223707348108292, acc=0.9640555381774902, loss=0.11223707348108292
test: epoch 19, loss 2.2704248428344727, acc=0.4611110985279083, loss=2.2704248428344727
train: epoch 20, loss 0.10330469161272049, acc=0.9672777652740479, loss=0.10330469161272049
test: epoch 20, loss 2.372964859008789, acc=0.48055556416511536, loss=2.372964859008789
train: epoch 21, loss 0.09893134981393814, acc=0.9674999713897705, loss=0.09893134981393814
test: epoch 21, loss 2.568697690963745, acc=0.36666667461395264, loss=2.568697690963745
train: epoch 22, loss 0.09292475879192352, acc=0.9711111187934875, loss=0.09292475879192352
test: epoch 22, loss 3.3195366859436035, acc=0.4333333373069763, loss=3.3195366859436035
train: epoch 23, loss 0.09211575984954834, acc=0.9722777605056763, loss=0.09211575984954834
test: epoch 23, loss 2.3824756145477295, acc=0.43611112236976624, loss=2.3824756145477295
train: epoch 24, loss 0.0918860211968422, acc=0.9697222113609314, loss=0.0918860211968422
test: epoch 24, loss 2.1650872230529785, acc=0.4277777671813965, loss=2.1650872230529785
train: epoch 25, loss 0.0673854649066925, acc=0.9783333539962769, loss=0.0673854649066925
test: epoch 25, loss 3.512439727783203, acc=0.4555555582046509, loss=3.512439727783203
train: epoch 26, loss 0.08534972369670868, acc=0.9752222299575806, loss=0.08534972369670868
test: epoch 26, loss 2.238086700439453, acc=0.4694444537162781, loss=2.238086700439453
train: epoch 27, loss 0.07329900562763214, acc=0.9786111116409302, loss=0.07329900562763214
test: epoch 27, loss 2.690253973007202, acc=0.5083333253860474, loss=2.690253973007202
train: epoch 28, loss 0.07689803093671799, acc=0.9775000214576721, loss=0.07689803093671799
test: epoch 28, loss 2.593670129776001, acc=0.4833333194255829, loss=2.593670129776001
train: epoch 29, loss 0.06158917024731636, acc=0.9821110963821411, loss=0.06158917024731636
test: epoch 29, loss 2.9930543899536133, acc=0.4833333194255829, loss=2.9930543899536133
train: epoch 30, loss 0.07267426699399948, acc=0.9779444336891174, loss=0.07267426699399948
test: epoch 30, loss 2.9921786785125732, acc=0.49444442987442017, loss=2.9921786785125732
train: epoch 31, loss 0.0726839005947113, acc=0.9786666631698608, loss=0.0726839005947113
test: epoch 31, loss 1.9169068336486816, acc=0.5722222328186035, loss=1.9169068336486816
train: epoch 32, loss 0.05643933266401291, acc=0.9824444651603699, loss=0.05643933266401291
test: epoch 32, loss 2.238237142562866, acc=0.4694444537162781, loss=2.238237142562866
train: epoch 33, loss 0.059741176664829254, acc=0.9826111197471619, loss=0.059741176664829254
test: epoch 33, loss 2.3640778064727783, acc=0.550000011920929, loss=2.3640778064727783
train: epoch 34, loss 0.05711934715509415, acc=0.9839444160461426, loss=0.05711934715509415
test: epoch 34, loss 2.1570193767547607, acc=0.519444465637207, loss=2.1570193767547607
train: epoch 35, loss 0.06286749243736267, acc=0.9821666479110718, loss=0.06286749243736267
test: epoch 35, loss 2.2786641120910645, acc=0.5166666507720947, loss=2.2786641120910645
train: epoch 36, loss 0.05120868608355522, acc=0.9847221970558167, loss=0.05120868608355522
test: epoch 36, loss 2.073286771774292, acc=0.5249999761581421, loss=2.073286771774292
train: epoch 37, loss 0.058407049626111984, acc=0.9827777743339539, loss=0.058407049626111984
test: epoch 37, loss 1.9709187746047974, acc=0.519444465637207, loss=1.9709187746047974
train: epoch 38, loss 0.04741128161549568, acc=0.9874444603919983, loss=0.04741128161549568
test: epoch 38, loss 2.8793065547943115, acc=0.5166666507720947, loss=2.8793065547943115
train: epoch 39, loss 0.05519186705350876, acc=0.9835000038146973, loss=0.05519186705350876
test: epoch 39, loss 1.9280704259872437, acc=0.5861111283302307, loss=1.9280704259872437
train: epoch 40, loss 0.04154255613684654, acc=0.9880555272102356, loss=0.04154255613684654
test: epoch 40, loss 2.1811182498931885, acc=0.5833333134651184, loss=2.1811182498931885
train: epoch 41, loss 0.06405942142009735, acc=0.9823889136314392, loss=0.06405942142009735
test: epoch 41, loss 1.9182974100112915, acc=0.5861111283302307, loss=1.9182974100112915
train: epoch 42, loss 0.05318296700716019, acc=0.9843888878822327, loss=0.05318296700716019
test: epoch 42, loss 1.8319041728973389, acc=0.5972222089767456, loss=1.8319041728973389
train: epoch 43, loss 0.04579474404454231, acc=0.9869999885559082, loss=0.04579474404454231
test: epoch 43, loss 1.9947333335876465, acc=0.5888888835906982, loss=1.9947333335876465
train: epoch 44, loss 0.042885977774858475, acc=0.987500011920929, loss=0.042885977774858475
test: epoch 44, loss 1.7100489139556885, acc=0.6666666865348816, loss=1.7100489139556885
train: epoch 45, loss 0.042637862265110016, acc=0.9883888959884644, loss=0.042637862265110016
test: epoch 45, loss 1.940254807472229, acc=0.5861111283302307, loss=1.940254807472229
train: epoch 46, loss 0.046455059200525284, acc=0.9873889088630676, loss=0.046455059200525284
test: epoch 46, loss 2.385150194168091, acc=0.5361111164093018, loss=2.385150194168091
train: epoch 47, loss 0.046835508197546005, acc=0.9860555529594421, loss=0.046835508197546005
test: epoch 47, loss 1.7767829895019531, acc=0.6388888955116272, loss=1.7767829895019531
train: epoch 48, loss 0.04216377064585686, acc=0.9891111254692078, loss=0.04216377064585686
test: epoch 48, loss 2.0353915691375732, acc=0.6083333492279053, loss=2.0353915691375732
train: epoch 49, loss 0.041414208710193634, acc=0.9871110916137695, loss=0.041414208710193634
test: epoch 49, loss 1.749799132347107, acc=0.5861111283302307, loss=1.749799132347107
train: epoch 50, loss 0.04570893943309784, acc=0.9879444241523743, loss=0.04570893943309784
test: epoch 50, loss 1.5971462726593018, acc=0.6222222447395325, loss=1.5971462726593018
train: epoch 51, loss 0.047041986137628555, acc=0.9862777590751648, loss=0.047041986137628555
test: epoch 51, loss 1.579925537109375, acc=0.6833333373069763, loss=1.579925537109375
train: epoch 52, loss 0.03067934699356556, acc=0.9903888702392578, loss=0.03067934699356556
test: epoch 52, loss 1.9021975994110107, acc=0.6666666865348816, loss=1.9021975994110107
train: epoch 53, loss 0.03955434635281563, acc=0.9890000224113464, loss=0.03955434635281563
test: epoch 53, loss 2.2248342037200928, acc=0.6361111402511597, loss=2.2248342037200928
train: epoch 54, loss 0.03871898353099823, acc=0.9892777800559998, loss=0.03871898353099823
test: epoch 54, loss 1.7994364500045776, acc=0.5916666388511658, loss=1.7994364500045776
train: epoch 55, loss 0.04039972648024559, acc=0.9884999990463257, loss=0.04039972648024559
test: epoch 55, loss 1.6412136554718018, acc=0.5944444537162781, loss=1.6412136554718018
train: epoch 56, loss 0.033292241394519806, acc=0.9906111359596252, loss=0.033292241394519806
test: epoch 56, loss 1.577445149421692, acc=0.6666666865348816, loss=1.577445149421692
train: epoch 57, loss 0.03450779989361763, acc=0.9907222390174866, loss=0.03450779989361763
test: epoch 57, loss 1.6437562704086304, acc=0.6666666865348816, loss=1.6437562704086304
train: epoch 58, loss 0.036105021834373474, acc=0.9902222156524658, loss=0.036105021834373474
test: epoch 58, loss 1.4424136877059937, acc=0.7361111044883728, loss=1.4424136877059937
train: epoch 59, loss 0.03539540618658066, acc=0.9897222518920898, loss=0.03539540618658066
test: epoch 59, loss 1.3207073211669922, acc=0.7444444298744202, loss=1.3207073211669922
train: epoch 60, loss 0.02772505208849907, acc=0.9927777647972107, loss=0.02772505208849907
test: epoch 60, loss 1.5003713369369507, acc=0.6972222328186035, loss=1.5003713369369507
train: epoch 61, loss 0.03161050006747246, acc=0.9912777543067932, loss=0.03161050006747246
test: epoch 61, loss 1.471572756767273, acc=0.7111111283302307, loss=1.471572756767273
train: epoch 62, loss 0.025546254590153694, acc=0.9927777647972107, loss=0.025546254590153694
test: epoch 62, loss 1.6760268211364746, acc=0.7388888597488403, loss=1.6760268211364746
train: epoch 63, loss 0.03730056434869766, acc=0.9903888702392578, loss=0.03730056434869766
test: epoch 63, loss 1.4292621612548828, acc=0.7555555701255798, loss=1.4292621612548828
train: epoch 64, loss 0.035064537078142166, acc=0.9906111359596252, loss=0.035064537078142166
test: epoch 64, loss 1.2795565128326416, acc=0.7083333134651184, loss=1.2795565128326416
train: epoch 65, loss 0.022904522716999054, acc=0.9936666488647461, loss=0.022904522716999054
test: epoch 65, loss 1.4072227478027344, acc=0.7111111283302307, loss=1.4072227478027344
train: epoch 66, loss 0.030330322682857513, acc=0.9920555353164673, loss=0.030330322682857513
test: epoch 66, loss 0.9324404001235962, acc=0.8166666626930237, loss=0.9324404001235962
train: epoch 67, loss 0.03193814307451248, acc=0.9911110997200012, loss=0.03193814307451248
test: epoch 67, loss 0.9238186478614807, acc=0.8472222089767456, loss=0.9238186478614807
train: epoch 68, loss 0.025481976568698883, acc=0.9937222003936768, loss=0.025481976568698883
test: epoch 68, loss 0.7572862505912781, acc=0.8333333134651184, loss=0.7572862505912781
train: epoch 69, loss 0.03554766997694969, acc=0.9906111359596252, loss=0.03554766997694969
test: epoch 69, loss 0.6031014323234558, acc=0.8222222328186035, loss=0.6031014323234558
train: epoch 70, loss 0.03191645070910454, acc=0.9915000200271606, loss=0.03191645070910454
test: epoch 70, loss 0.813281774520874, acc=0.8611111044883728, loss=0.813281774520874
train: epoch 71, loss 0.022791940718889236, acc=0.9938333630561829, loss=0.022791940718889236
test: epoch 71, loss 0.66963130235672, acc=0.8472222089767456, loss=0.66963130235672
train: epoch 72, loss 0.028902612626552582, acc=0.9931666851043701, loss=0.028902612626552582
test: epoch 72, loss 0.833339273929596, acc=0.8277778029441833, loss=0.833339273929596
train: epoch 73, loss 0.025775788351893425, acc=0.9940555691719055, loss=0.025775788351893425
test: epoch 73, loss 0.9487480521202087, acc=0.7888888716697693, loss=0.9487480521202087
train: epoch 74, loss 0.01871468499302864, acc=0.9946110844612122, loss=0.01871468499302864
test: epoch 74, loss 0.8257343173027039, acc=0.8722222447395325, loss=0.8257343173027039
train: epoch 75, loss 0.023618338629603386, acc=0.9945555329322815, loss=0.023618338629603386
test: epoch 75, loss 0.6264718174934387, acc=0.8777777552604675, loss=0.6264718174934387
train: epoch 76, loss 0.021897487342357635, acc=0.9934444427490234, loss=0.021897487342357635
test: epoch 76, loss 0.9378443360328674, acc=0.8305555582046509, loss=0.9378443360328674
train: epoch 77, loss 0.02497640997171402, acc=0.9934999942779541, loss=0.02497640997171402
test: epoch 77, loss 0.760490357875824, acc=0.8361111283302307, loss=0.760490357875824
train: epoch 78, loss 0.020748935639858246, acc=0.9944999814033508, loss=0.020748935639858246
test: epoch 78, loss 0.6395590901374817, acc=0.8694444298744202, loss=0.6395590901374817
train: epoch 79, loss 0.028269249945878983, acc=0.992222249507904, loss=0.028269249945878983
test: epoch 79, loss 0.917576789855957, acc=0.8472222089767456, loss=0.917576789855957
train: epoch 80, loss 0.01872926764190197, acc=0.9951111078262329, loss=0.01872926764190197
test: epoch 80, loss 0.748002290725708, acc=0.8833333253860474, loss=0.748002290725708
train: epoch 81, loss 0.01560723315924406, acc=0.9948889017105103, loss=0.01560723315924406
test: epoch 81, loss 0.5704699158668518, acc=0.8916666507720947, loss=0.5704699158668518
train: epoch 82, loss 0.018548155203461647, acc=0.9951111078262329, loss=0.018548155203461647
test: epoch 82, loss 0.5183956623077393, acc=0.9027777910232544, loss=0.5183956623077393
train: epoch 83, loss 0.01605665311217308, acc=0.9962777495384216, loss=0.01605665311217308
test: epoch 83, loss 0.5733089447021484, acc=0.8361111283302307, loss=0.5733089447021484
train: epoch 84, loss 0.01815875992178917, acc=0.9956666827201843, loss=0.01815875992178917
test: epoch 84, loss 0.6122785806655884, acc=0.8805555701255798, loss=0.6122785806655884
train: epoch 85, loss 0.02296416461467743, acc=0.9942222237586975, loss=0.02296416461467743
test: epoch 85, loss 0.7798689007759094, acc=0.8611111044883728, loss=0.7798689007759094
train: epoch 86, loss 0.014854309149086475, acc=0.9964444637298584, loss=0.014854309149086475
test: epoch 86, loss 0.4497618079185486, acc=0.9055555462837219, loss=0.4497618079185486
train: epoch 87, loss 0.01493995264172554, acc=0.9965000152587891, loss=0.01493995264172554
test: epoch 87, loss 0.6253640055656433, acc=0.8694444298744202, loss=0.6253640055656433
train: epoch 88, loss 0.021084915846586227, acc=0.9953888654708862, loss=0.021084915846586227
test: epoch 88, loss 0.8157569169998169, acc=0.8666666746139526, loss=0.8157569169998169
train: epoch 89, loss 0.022377610206604004, acc=0.9946666955947876, loss=0.022377610206604004
test: epoch 89, loss 0.49743255972862244, acc=0.8972222208976746, loss=0.49743255972862244
train: epoch 90, loss 0.018445832654833794, acc=0.995888888835907, loss=0.018445832654833794
test: epoch 90, loss 0.5032030344009399, acc=0.8861111402511597, loss=0.5032030344009399
train: epoch 91, loss 0.018898798152804375, acc=0.9953333139419556, loss=0.018898798152804375
test: epoch 91, loss 0.6191457509994507, acc=0.9027777910232544, loss=0.6191457509994507
train: epoch 92, loss 0.014134836383163929, acc=0.9963889122009277, loss=0.014134836383163929
test: epoch 92, loss 0.5741410851478577, acc=0.8694444298744202, loss=0.5741410851478577
train: epoch 93, loss 0.013418815098702908, acc=0.9968888759613037, loss=0.013418815098702908
test: epoch 93, loss 0.6426595449447632, acc=0.8888888955116272, loss=0.6426595449447632
train: epoch 94, loss 0.009609153494238853, acc=0.9977777600288391, loss=0.009609153494238853
test: epoch 94, loss 0.5112546682357788, acc=0.9027777910232544, loss=0.5112546682357788
train: epoch 95, loss 0.015025664120912552, acc=0.996666669845581, loss=0.015025664120912552
test: epoch 95, loss 0.6791792511940002, acc=0.9083333611488342, loss=0.6791792511940002
train: epoch 96, loss 0.01553462166339159, acc=0.9965555667877197, loss=0.01553462166339159
test: epoch 96, loss 0.5391786694526672, acc=0.894444465637207, loss=0.5391786694526672
train: epoch 97, loss 0.017779534682631493, acc=0.9957777857780457, loss=0.017779534682631493
test: epoch 97, loss 0.5585321187973022, acc=0.9055555462837219, loss=0.5585321187973022
train: epoch 98, loss 0.01909341849386692, acc=0.9942777752876282, loss=0.01909341849386692
test: epoch 98, loss 0.4971098303794861, acc=0.9138888716697693, loss=0.4971098303794861
train: epoch 99, loss 0.011649717576801777, acc=0.9976111054420471, loss=0.011649717576801777
test: epoch 99, loss 0.45651954412460327, acc=0.8861111402511597, loss=0.45651954412460327
train: epoch 100, loss 0.027463559061288834, acc=0.9946666955947876, loss=0.027463559061288834
test: epoch 100, loss 0.5593817234039307, acc=0.9138888716697693, loss=0.5593817234039307
train: epoch 101, loss 0.01235251035541296, acc=0.9966111183166504, loss=0.01235251035541296
test: epoch 101, loss 0.5738257169723511, acc=0.9111111164093018, loss=0.5738257169723511
train: epoch 102, loss 0.015534023754298687, acc=0.9967222213745117, loss=0.015534023754298687
test: epoch 102, loss 0.488558292388916, acc=0.9194444417953491, loss=0.488558292388916
train: epoch 103, loss 0.01351950317621231, acc=0.9967777729034424, loss=0.01351950317621231
test: epoch 103, loss 0.4941239058971405, acc=0.9166666865348816, loss=0.4941239058971405
train: epoch 104, loss 0.011228271760046482, acc=0.9975000023841858, loss=0.011228271760046482
test: epoch 104, loss 0.5006330609321594, acc=0.9111111164093018, loss=0.5006330609321594
train: epoch 105, loss 0.011475211940705776, acc=0.9970555305480957, loss=0.011475211940705776
test: epoch 105, loss 0.4461347162723541, acc=0.9166666865348816, loss=0.4461347162723541
train: epoch 106, loss 0.019547853618860245, acc=0.996055543422699, loss=0.019547853618860245
test: epoch 106, loss 0.20792770385742188, acc=0.9194444417953491, loss=0.20792770385742188
train: epoch 107, loss 0.014419925399124622, acc=0.9975000023841858, loss=0.014419925399124622
test: epoch 107, loss 0.3871137499809265, acc=0.925000011920929, loss=0.3871137499809265
train: epoch 108, loss 0.008682290092110634, acc=0.9981666803359985, loss=0.008682290092110634
test: epoch 108, loss 0.309615820646286, acc=0.925000011920929, loss=0.309615820646286
train: epoch 109, loss 0.005985775962471962, acc=0.9983888864517212, loss=0.005985775962471962
test: epoch 109, loss 0.5609979629516602, acc=0.925000011920929, loss=0.5609979629516602
train: epoch 110, loss 0.018554802983999252, acc=0.9963889122009277, loss=0.018554802983999252
test: epoch 110, loss 0.6086636781692505, acc=0.8972222208976746, loss=0.6086636781692505
train: epoch 111, loss 0.016559820622205734, acc=0.9971110820770264, loss=0.016559820622205734
test: epoch 111, loss 0.3799618184566498, acc=0.9222221970558167, loss=0.3799618184566498
train: epoch 112, loss 0.015362001024186611, acc=0.9973333477973938, loss=0.015362001024186611
test: epoch 112, loss 0.41843926906585693, acc=0.925000011920929, loss=0.41843926906585693
train: epoch 113, loss 0.0060377842746675014, acc=0.9983333349227905, loss=0.0060377842746675014
test: epoch 113, loss 0.5522070527076721, acc=0.8999999761581421, loss=0.5522070527076721
train: epoch 114, loss 0.005227196030318737, acc=0.9990555644035339, loss=0.005227196030318737
test: epoch 114, loss 0.6859884858131409, acc=0.9027777910232544, loss=0.6859884858131409
train: epoch 115, loss 0.01622159034013748, acc=0.996833324432373, loss=0.01622159034013748
test: epoch 115, loss 0.4165791869163513, acc=0.9222221970558167, loss=0.4165791869163513
train: epoch 116, loss 0.01233696099370718, acc=0.9976111054420471, loss=0.01233696099370718
test: epoch 116, loss 0.5103088617324829, acc=0.9194444417953491, loss=0.5103088617324829
train: epoch 117, loss 0.007243029773235321, acc=0.9990555644035339, loss=0.007243029773235321
test: epoch 117, loss 0.45084455609321594, acc=0.9277777671813965, loss=0.45084455609321594
train: epoch 118, loss 0.016157258301973343, acc=0.9969444274902344, loss=0.016157258301973343
test: epoch 118, loss 0.3689756691455841, acc=0.9277777671813965, loss=0.3689756691455841
train: epoch 119, loss 0.005586800631135702, acc=0.9984444379806519, loss=0.005586800631135702
test: epoch 119, loss 0.3861905634403229, acc=0.9333333373069763, loss=0.3861905634403229
train: epoch 120, loss 0.0045508104376494884, acc=0.9992222189903259, loss=0.0045508104376494884
test: epoch 120, loss 0.3345760703086853, acc=0.9277777671813965, loss=0.3345760703086853
train: epoch 121, loss 0.0106934430077672, acc=0.9981111288070679, loss=0.0106934430077672
test: epoch 121, loss 0.34717392921447754, acc=0.925000011920929, loss=0.34717392921447754
train: epoch 122, loss 0.010618172585964203, acc=0.9977777600288391, loss=0.010618172585964203
test: epoch 122, loss 0.518194317817688, acc=0.9277777671813965, loss=0.518194317817688
train: epoch 123, loss 0.007457403000444174, acc=0.9983333349227905, loss=0.007457403000444174
test: epoch 123, loss 0.5615015625953674, acc=0.9138888716697693, loss=0.5615015625953674
train: epoch 124, loss 0.018680457025766373, acc=0.9965555667877197, loss=0.018680457025766373
test: epoch 124, loss 0.4004831910133362, acc=0.9333333373069763, loss=0.4004831910133362
train: epoch 125, loss 0.003025352256372571, acc=0.9993888735771179, loss=0.003025352256372571
test: epoch 125, loss 0.47597745060920715, acc=0.9194444417953491, loss=0.47597745060920715
train: epoch 126, loss 0.00545272883027792, acc=0.9990000128746033, loss=0.00545272883027792
test: epoch 126, loss 0.3510434627532959, acc=0.9333333373069763, loss=0.3510434627532959
train: epoch 127, loss 0.007641696836799383, acc=0.9980000257492065, loss=0.007641696836799383
test: epoch 127, loss 0.2907172441482544, acc=0.9333333373069763, loss=0.2907172441482544
train: epoch 128, loss 0.009449479170143604, acc=0.9978888630867004, loss=0.009449479170143604
test: epoch 128, loss 0.5895017385482788, acc=0.9277777671813965, loss=0.5895017385482788
train: epoch 129, loss 0.009778425097465515, acc=0.9983333349227905, loss=0.009778425097465515
test: epoch 129, loss 0.3109729588031769, acc=0.9333333373069763, loss=0.3109729588031769
train: epoch 130, loss 0.008607436902821064, acc=0.9979444742202759, loss=0.008607436902821064
test: epoch 130, loss 0.521443784236908, acc=0.9361110925674438, loss=0.521443784236908
train: epoch 131, loss 0.004175550304353237, acc=0.9992777705192566, loss=0.004175550304353237
test: epoch 131, loss 0.4673551023006439, acc=0.9333333373069763, loss=0.4673551023006439
train: epoch 132, loss 0.008772185072302818, acc=0.9987778067588806, loss=0.008772185072302818
test: epoch 132, loss 0.47886693477630615, acc=0.9388889074325562, loss=0.47886693477630615
train: epoch 133, loss 0.008312106132507324, acc=0.9987221956253052, loss=0.008312106132507324
test: epoch 133, loss 0.32112839818000793, acc=0.9444444179534912, loss=0.32112839818000793
train: epoch 134, loss 0.003781796433031559, acc=0.9994444251060486, loss=0.003781796433031559
test: epoch 134, loss 0.30411097407341003, acc=0.9444444179534912, loss=0.30411097407341003
train: epoch 135, loss 0.0227816179394722, acc=0.9972222447395325, loss=0.0227816179394722
test: epoch 135, loss 0.5296540260314941, acc=0.9138888716697693, loss=0.5296540260314941
train: epoch 136, loss 0.0066270846873521805, acc=0.9987778067588806, loss=0.0066270846873521805
test: epoch 136, loss 0.3296970725059509, acc=0.9416666626930237, loss=0.3296970725059509
train: epoch 137, loss 0.004883462563157082, acc=0.9990000128746033, loss=0.004883462563157082
test: epoch 137, loss 0.11781932413578033, acc=0.9583333134651184, loss=0.11781932413578033
train: epoch 138, loss 0.002680187113583088, acc=0.9993888735771179, loss=0.002680187113583088
test: epoch 138, loss 0.36251476407051086, acc=0.9555555582046509, loss=0.36251476407051086
train: epoch 139, loss 0.004435996059328318, acc=0.9991111159324646, loss=0.004435996059328318
test: epoch 139, loss 0.17682616412639618, acc=0.9611111283302307, loss=0.17682616412639618
train: epoch 140, loss 0.0012550527462735772, acc=0.9995555281639099, loss=0.0012550527462735772
test: epoch 140, loss 0.03614576533436775, acc=0.9944444298744202, loss=0.03614576533436775
