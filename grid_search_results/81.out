# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=1", "--n_layers=1"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=1540043776, receiver_embed_dim=64, save_run=0, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1540043776, receiver_embed_dim=64, save_run=False, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.5471575260162354, acc=0.04600000008940697, loss=3.5471575260162354
test: epoch 1, loss 3.5709328651428223, acc=0.06666667014360428, loss=3.5709328651428223
train: epoch 2, loss 3.473191261291504, acc=0.050777778029441833, loss=3.473191261291504
test: epoch 2, loss 3.209359884262085, acc=0.08888889104127884, loss=3.209359884262085
train: epoch 3, loss 3.379552125930786, acc=0.05833333358168602, loss=3.379552125930786
test: epoch 3, loss 3.428619146347046, acc=0.07500000298023224, loss=3.428619146347046
train: epoch 4, loss 3.047567129135132, acc=0.09694444388151169, loss=3.047567129135132
test: epoch 4, loss 4.630155563354492, acc=0.04444444552063942, loss=4.630155563354492
train: epoch 5, loss 2.744729518890381, acc=0.1340000033378601, loss=2.744729518890381
test: epoch 5, loss 4.83495569229126, acc=0.03888889029622078, loss=4.83495569229126
train: epoch 6, loss 2.591815948486328, acc=0.15311111509799957, loss=2.591815948486328
test: epoch 6, loss 4.827535629272461, acc=0.0555555559694767, loss=4.827535629272461
train: epoch 7, loss 2.4904873371124268, acc=0.17838889360427856, loss=2.4904873371124268
test: epoch 7, loss 4.845849514007568, acc=0.0694444477558136, loss=4.845849514007568
train: epoch 8, loss 2.4168739318847656, acc=0.1886666715145111, loss=2.4168739318847656
test: epoch 8, loss 5.160675525665283, acc=0.07222222536802292, loss=5.160675525665283
train: epoch 9, loss 2.3584048748016357, acc=0.19744443893432617, loss=2.3584048748016357
test: epoch 9, loss 5.149886131286621, acc=0.04722222313284874, loss=5.149886131286621
train: epoch 10, loss 2.3092520236968994, acc=0.20955555140972137, loss=2.3092520236968994
test: epoch 10, loss 5.102634906768799, acc=0.07222222536802292, loss=5.102634906768799
train: epoch 11, loss 2.2757601737976074, acc=0.2163333296775818, loss=2.2757601737976074
test: epoch 11, loss 4.98803186416626, acc=0.07222222536802292, loss=4.98803186416626
train: epoch 12, loss 2.242102861404419, acc=0.22505556046962738, loss=2.242102861404419
test: epoch 12, loss 5.115153789520264, acc=0.07222222536802292, loss=5.115153789520264
train: epoch 13, loss 2.2063140869140625, acc=0.23561111092567444, loss=2.2063140869140625
test: epoch 13, loss 5.064976215362549, acc=0.07777778059244156, loss=5.064976215362549
train: epoch 14, loss 2.1763041019439697, acc=0.2409999966621399, loss=2.1763041019439697
test: epoch 14, loss 5.11189603805542, acc=0.0694444477558136, loss=5.11189603805542
train: epoch 15, loss 2.1571755409240723, acc=0.24788889288902283, loss=2.1571755409240723
test: epoch 15, loss 4.912428379058838, acc=0.07500000298023224, loss=4.912428379058838
train: epoch 16, loss 2.1298789978027344, acc=0.25083333253860474, loss=2.1298789978027344
test: epoch 16, loss 4.8210673332214355, acc=0.06111111119389534, loss=4.8210673332214355
train: epoch 17, loss 2.105440855026245, acc=0.26072221994400024, loss=2.105440855026245
test: epoch 17, loss 4.707644939422607, acc=0.0694444477558136, loss=4.707644939422607
train: epoch 18, loss 2.086571455001831, acc=0.2690555453300476, loss=2.086571455001831
test: epoch 18, loss 4.477322101593018, acc=0.06388889253139496, loss=4.477322101593018
train: epoch 19, loss 2.0570876598358154, acc=0.26866665482521057, loss=2.0570876598358154
test: epoch 19, loss 4.171774864196777, acc=0.07777778059244156, loss=4.171774864196777
train: epoch 20, loss 2.0307018756866455, acc=0.28349998593330383, loss=2.0307018756866455
test: epoch 20, loss 4.1678690910339355, acc=0.08055555820465088, loss=4.1678690910339355
train: epoch 21, loss 2.0138227939605713, acc=0.2853333353996277, loss=2.0138227939605713
test: epoch 21, loss 3.9188826084136963, acc=0.10000000149011612, loss=3.9188826084136963
train: epoch 22, loss 2.001481771469116, acc=0.293277770280838, loss=2.001481771469116
test: epoch 22, loss 3.741024971008301, acc=0.09166666865348816, loss=3.741024971008301
train: epoch 23, loss 1.9801710844039917, acc=0.29483333230018616, loss=1.9801710844039917
test: epoch 23, loss 3.7739245891571045, acc=0.0972222238779068, loss=3.7739245891571045
train: epoch 24, loss 1.9745301008224487, acc=0.2987777888774872, loss=1.9745301008224487
test: epoch 24, loss 3.6314785480499268, acc=0.0972222238779068, loss=3.6314785480499268
train: epoch 25, loss 1.9533860683441162, acc=0.3064444363117218, loss=1.9533860683441162
test: epoch 25, loss 3.5855154991149902, acc=0.11388888955116272, loss=3.5855154991149902
train: epoch 26, loss 1.92526376247406, acc=0.3223888874053955, loss=1.92526376247406
test: epoch 26, loss 3.4613749980926514, acc=0.11666666716337204, loss=3.4613749980926514
train: epoch 27, loss 1.915717363357544, acc=0.31888890266418457, loss=1.915717363357544
test: epoch 27, loss 3.352033853530884, acc=0.13055555522441864, loss=3.352033853530884
train: epoch 28, loss 1.8946588039398193, acc=0.3259444534778595, loss=1.8946588039398193
test: epoch 28, loss 3.2104697227478027, acc=0.13055555522441864, loss=3.2104697227478027
train: epoch 29, loss 1.868532657623291, acc=0.3288888931274414, loss=1.868532657623291
test: epoch 29, loss 3.2633023262023926, acc=0.12222222238779068, loss=3.2633023262023926
train: epoch 30, loss 1.8541908264160156, acc=0.3380555510520935, loss=1.8541908264160156
test: epoch 30, loss 3.1802878379821777, acc=0.15555556118488312, loss=3.1802878379821777
train: epoch 31, loss 1.845179796218872, acc=0.3411666750907898, loss=1.845179796218872
test: epoch 31, loss 3.155816078186035, acc=0.13611111044883728, loss=3.155816078186035
train: epoch 32, loss 1.8209844827651978, acc=0.3482222259044647, loss=1.8209844827651978
test: epoch 32, loss 3.0628468990325928, acc=0.16388888657093048, loss=3.0628468990325928
train: epoch 33, loss 1.8126314878463745, acc=0.3523888885974884, loss=1.8126314878463745
test: epoch 33, loss 3.0079915523529053, acc=0.15000000596046448, loss=3.0079915523529053
train: epoch 34, loss 1.7893162965774536, acc=0.3606666624546051, loss=1.7893162965774536
test: epoch 34, loss 2.9823861122131348, acc=0.15000000596046448, loss=2.9823861122131348
train: epoch 35, loss 1.788545846939087, acc=0.36694443225860596, loss=1.788545846939087
test: epoch 35, loss 2.9284191131591797, acc=0.16388888657093048, loss=2.9284191131591797
train: epoch 36, loss 1.763120174407959, acc=0.3703888952732086, loss=1.763120174407959
test: epoch 36, loss 2.9546620845794678, acc=0.16944444179534912, loss=2.9546620845794678
train: epoch 37, loss 1.7387322187423706, acc=0.3776666522026062, loss=1.7387322187423706
test: epoch 37, loss 2.9475457668304443, acc=0.1944444477558136, loss=2.9475457668304443
train: epoch 38, loss 1.7263271808624268, acc=0.3911111056804657, loss=1.7263271808624268
test: epoch 38, loss 2.8330729007720947, acc=0.18611110746860504, loss=2.8330729007720947
train: epoch 39, loss 1.7136465311050415, acc=0.3897777795791626, loss=1.7136465311050415
test: epoch 39, loss 2.7651445865631104, acc=0.17777778208255768, loss=2.7651445865631104
train: epoch 40, loss 1.6944570541381836, acc=0.3961111009120941, loss=1.6944570541381836
test: epoch 40, loss 2.729182004928589, acc=0.1805555522441864, loss=2.729182004928589
train: epoch 41, loss 1.6687864065170288, acc=0.40522223711013794, loss=1.6687864065170288
test: epoch 41, loss 2.7238166332244873, acc=0.18611110746860504, loss=2.7238166332244873
train: epoch 42, loss 1.6752078533172607, acc=0.41011109948158264, loss=1.6752078533172607
test: epoch 42, loss 2.6012885570526123, acc=0.19166666269302368, loss=2.6012885570526123
train: epoch 43, loss 1.6596174240112305, acc=0.41588887572288513, loss=1.6596174240112305
test: epoch 43, loss 2.587076425552368, acc=0.20277777314186096, loss=2.587076425552368
train: epoch 44, loss 1.620304822921753, acc=0.425388902425766, loss=1.620304822921753
test: epoch 44, loss 2.4361355304718018, acc=0.20555555820465088, loss=2.4361355304718018
train: epoch 45, loss 1.6334792375564575, acc=0.43022221326828003, loss=1.6334792375564575
test: epoch 45, loss 2.4554946422576904, acc=0.20555555820465088, loss=2.4554946422576904
train: epoch 46, loss 1.6215742826461792, acc=0.4404444396495819, loss=1.6215742826461792
test: epoch 46, loss 2.406536340713501, acc=0.20277777314186096, loss=2.406536340713501
train: epoch 47, loss 1.5927326679229736, acc=0.4416666626930237, loss=1.5927326679229736
test: epoch 47, loss 2.398327589035034, acc=0.21111111342906952, loss=2.398327589035034
train: epoch 48, loss 1.5855225324630737, acc=0.449444442987442, loss=1.5855225324630737
test: epoch 48, loss 2.3444197177886963, acc=0.20277777314186096, loss=2.3444197177886963
train: epoch 49, loss 1.55720055103302, acc=0.44927778840065, loss=1.55720055103302
test: epoch 49, loss 2.349050283432007, acc=0.20555555820465088, loss=2.349050283432007
train: epoch 50, loss 1.5530407428741455, acc=0.4690000116825104, loss=1.5530407428741455
test: epoch 50, loss 2.308291435241699, acc=0.2222222238779068, loss=2.308291435241699
train: epoch 51, loss 1.5273503065109253, acc=0.46738889813423157, loss=1.5273503065109253
test: epoch 51, loss 2.2900874614715576, acc=0.23333333432674408, loss=2.2900874614715576
train: epoch 52, loss 1.5182297229766846, acc=0.47661110758781433, loss=1.5182297229766846
test: epoch 52, loss 2.260540246963501, acc=0.2361111044883728, loss=2.260540246963501
train: epoch 53, loss 1.5161274671554565, acc=0.48355555534362793, loss=1.5161274671554565
test: epoch 53, loss 2.2409279346466064, acc=0.24166665971279144, loss=2.2409279346466064
train: epoch 54, loss 1.4810293912887573, acc=0.491611123085022, loss=1.4810293912887573
test: epoch 54, loss 2.2079508304595947, acc=0.23888888955116272, loss=2.2079508304595947
train: epoch 55, loss 1.487946629524231, acc=0.49638888239860535, loss=1.487946629524231
test: epoch 55, loss 2.165297031402588, acc=0.2527777850627899, loss=2.165297031402588
train: epoch 56, loss 1.4281846284866333, acc=0.5073333382606506, loss=1.4281846284866333
test: epoch 56, loss 2.1642794609069824, acc=0.24722221493721008, loss=2.1642794609069824
train: epoch 57, loss 1.4316767454147339, acc=0.5137222409248352, loss=1.4316767454147339
test: epoch 57, loss 2.153862237930298, acc=0.2527777850627899, loss=2.153862237930298
train: epoch 58, loss 1.4398243427276611, acc=0.5162777900695801, loss=1.4398243427276611
test: epoch 58, loss 2.1296138763427734, acc=0.24722221493721008, loss=2.1296138763427734
train: epoch 59, loss 1.3968803882598877, acc=0.5203333497047424, loss=1.3968803882598877
test: epoch 59, loss 2.0997226238250732, acc=0.25, loss=2.0997226238250732
train: epoch 60, loss 1.389230728149414, acc=0.5271111130714417, loss=1.389230728149414
test: epoch 60, loss 2.109685182571411, acc=0.24166665971279144, loss=2.109685182571411
train: epoch 61, loss 1.3747795820236206, acc=0.5349444150924683, loss=1.3747795820236206
test: epoch 61, loss 2.0642974376678467, acc=0.2666666805744171, loss=2.0642974376678467
train: epoch 62, loss 1.3656270503997803, acc=0.5455555319786072, loss=1.3656270503997803
test: epoch 62, loss 2.0343868732452393, acc=0.2777777910232544, loss=2.0343868732452393
train: epoch 63, loss 1.3374742269515991, acc=0.550166666507721, loss=1.3374742269515991
test: epoch 63, loss 2.0629706382751465, acc=0.2750000059604645, loss=2.0629706382751465
train: epoch 64, loss 1.3220220804214478, acc=0.5607777833938599, loss=1.3220220804214478
test: epoch 64, loss 2.0049033164978027, acc=0.2916666567325592, loss=2.0049033164978027
train: epoch 65, loss 1.3030818700790405, acc=0.5663333535194397, loss=1.3030818700790405
test: epoch 65, loss 1.9586490392684937, acc=0.2944444417953491, loss=1.9586490392684937
train: epoch 66, loss 1.2731560468673706, acc=0.5787222385406494, loss=1.2731560468673706
test: epoch 66, loss 1.9266242980957031, acc=0.3055555522441864, loss=1.9266242980957031
train: epoch 67, loss 1.267327070236206, acc=0.5821666717529297, loss=1.267327070236206
test: epoch 67, loss 1.9048364162445068, acc=0.3055555522441864, loss=1.9048364162445068
train: epoch 68, loss 1.2562907934188843, acc=0.5864444375038147, loss=1.2562907934188843
test: epoch 68, loss 1.810002326965332, acc=0.30000001192092896, loss=1.810002326965332
train: epoch 69, loss 1.2339749336242676, acc=0.5950555801391602, loss=1.2339749336242676
test: epoch 69, loss 1.8310927152633667, acc=0.3166666626930237, loss=1.8310927152633667
train: epoch 70, loss 1.2105662822723389, acc=0.6041666865348816, loss=1.2105662822723389
test: epoch 70, loss 1.7872053384780884, acc=0.3027777671813965, loss=1.7872053384780884
train: epoch 71, loss 1.20756995677948, acc=0.6089444160461426, loss=1.20756995677948
test: epoch 71, loss 1.767181396484375, acc=0.3333333432674408, loss=1.767181396484375
train: epoch 72, loss 1.1930915117263794, acc=0.6191666722297668, loss=1.1930915117263794
test: epoch 72, loss 1.7361079454421997, acc=0.32499998807907104, loss=1.7361079454421997
train: epoch 73, loss 1.1918307542800903, acc=0.629277765750885, loss=1.1918307542800903
test: epoch 73, loss 1.735670566558838, acc=0.3222222328186035, loss=1.735670566558838
train: epoch 74, loss 1.166727900505066, acc=0.6316666603088379, loss=1.166727900505066
test: epoch 74, loss 1.7471641302108765, acc=0.32777777314186096, loss=1.7471641302108765
train: epoch 75, loss 1.1316248178482056, acc=0.6355555653572083, loss=1.1316248178482056
test: epoch 75, loss 1.6993408203125, acc=0.32777777314186096, loss=1.6993408203125
train: epoch 76, loss 1.1248815059661865, acc=0.6470555663108826, loss=1.1248815059661865
test: epoch 76, loss 1.6795939207077026, acc=0.3222222328186035, loss=1.6795939207077026
train: epoch 77, loss 1.110323190689087, acc=0.6513888835906982, loss=1.110323190689087
test: epoch 77, loss 1.7183626890182495, acc=0.31388887763023376, loss=1.7183626890182495
train: epoch 78, loss 1.1028447151184082, acc=0.6560555696487427, loss=1.1028447151184082
test: epoch 78, loss 1.6730947494506836, acc=0.3222222328186035, loss=1.6730947494506836
train: epoch 79, loss 1.078209638595581, acc=0.663777768611908, loss=1.078209638595581
test: epoch 79, loss 1.6135470867156982, acc=0.3166666626930237, loss=1.6135470867156982
train: epoch 80, loss 1.0808956623077393, acc=0.6693888902664185, loss=1.0808956623077393
test: epoch 80, loss 1.6321767568588257, acc=0.34166666865348816, loss=1.6321767568588257
train: epoch 81, loss 1.0577387809753418, acc=0.6735555529594421, loss=1.0577387809753418
test: epoch 81, loss 1.5992246866226196, acc=0.35555556416511536, loss=1.5992246866226196
train: epoch 82, loss 1.0436758995056152, acc=0.6804444193840027, loss=1.0436758995056152
test: epoch 82, loss 1.6211107969284058, acc=0.34166666865348816, loss=1.6211107969284058
train: epoch 83, loss 1.044101357460022, acc=0.6866666674613953, loss=1.044101357460022
test: epoch 83, loss 1.5749359130859375, acc=0.3444444537162781, loss=1.5749359130859375
train: epoch 84, loss 1.0409375429153442, acc=0.6850000023841858, loss=1.0409375429153442
test: epoch 84, loss 1.5638784170150757, acc=0.3611111044883728, loss=1.5638784170150757
train: epoch 85, loss 1.0289921760559082, acc=0.6931111216545105, loss=1.0289921760559082
test: epoch 85, loss 1.5589796304702759, acc=0.34166666865348816, loss=1.5589796304702759
train: epoch 86, loss 0.999002993106842, acc=0.6989444494247437, loss=0.999002993106842
test: epoch 86, loss 1.5597131252288818, acc=0.3444444537162781, loss=1.5597131252288818
train: epoch 87, loss 0.980337381362915, acc=0.7038333415985107, loss=0.980337381362915
test: epoch 87, loss 1.5344535112380981, acc=0.36666667461395264, loss=1.5344535112380981
train: epoch 88, loss 0.97397780418396, acc=0.7116666436195374, loss=0.97397780418396
test: epoch 88, loss 1.5546292066574097, acc=0.3583333194255829, loss=1.5546292066574097
train: epoch 89, loss 0.9722538590431213, acc=0.7128333449363708, loss=0.9722538590431213
test: epoch 89, loss 1.5135654211044312, acc=0.3611111044883728, loss=1.5135654211044312
train: epoch 90, loss 0.9368035793304443, acc=0.7171666622161865, loss=0.9368035793304443
test: epoch 90, loss 1.5130722522735596, acc=0.36666667461395264, loss=1.5130722522735596
train: epoch 91, loss 0.9583394527435303, acc=0.7152222394943237, loss=0.9583394527435303
test: epoch 91, loss 1.5025482177734375, acc=0.3638888895511627, loss=1.5025482177734375
train: epoch 92, loss 0.9506112933158875, acc=0.7221666574478149, loss=0.9506112933158875
test: epoch 92, loss 1.515242338180542, acc=0.36944442987442017, loss=1.515242338180542
train: epoch 93, loss 0.9095012545585632, acc=0.734000027179718, loss=0.9095012545585632
test: epoch 93, loss 1.5079288482666016, acc=0.3611111044883728, loss=1.5079288482666016
train: epoch 94, loss 0.9220318794250488, acc=0.7381666898727417, loss=0.9220318794250488
test: epoch 94, loss 1.4905694723129272, acc=0.36944442987442017, loss=1.4905694723129272
train: epoch 95, loss 0.9055579304695129, acc=0.7352777719497681, loss=0.9055579304695129
test: epoch 95, loss 1.4996135234832764, acc=0.3611111044883728, loss=1.4996135234832764
train: epoch 96, loss 0.8933616280555725, acc=0.742111086845398, loss=0.8933616280555725
test: epoch 96, loss 1.4967073202133179, acc=0.3638888895511627, loss=1.4967073202133179
train: epoch 97, loss 0.8846263885498047, acc=0.7377777695655823, loss=0.8846263885498047
test: epoch 97, loss 1.4761276245117188, acc=0.3638888895511627, loss=1.4761276245117188
train: epoch 98, loss 0.8637335896492004, acc=0.7473333477973938, loss=0.8637335896492004
test: epoch 98, loss 1.446470022201538, acc=0.3861111104488373, loss=1.446470022201538
train: epoch 99, loss 0.8648969531059265, acc=0.7495555281639099, loss=0.8648969531059265
test: epoch 99, loss 1.4195343255996704, acc=0.38333332538604736, loss=1.4195343255996704
train: epoch 100, loss 0.8521804213523865, acc=0.7565555572509766, loss=0.8521804213523865
test: epoch 100, loss 1.4236886501312256, acc=0.38333332538604736, loss=1.4236886501312256
train: epoch 101, loss 0.8675244450569153, acc=0.7545555830001831, loss=0.8675244450569153
test: epoch 101, loss 1.4407603740692139, acc=0.3861111104488373, loss=1.4407603740692139
train: epoch 102, loss 0.8436194658279419, acc=0.7627778053283691, loss=0.8436194658279419
test: epoch 102, loss 1.4157626628875732, acc=0.38333332538604736, loss=1.4157626628875732
train: epoch 103, loss 0.8417453169822693, acc=0.7603333592414856, loss=0.8417453169822693
test: epoch 103, loss 1.4098256826400757, acc=0.3888888955116272, loss=1.4098256826400757
train: epoch 104, loss 0.8252649307250977, acc=0.762666642665863, loss=0.8252649307250977
test: epoch 104, loss 1.4100100994110107, acc=0.3861111104488373, loss=1.4100100994110107
train: epoch 105, loss 0.8120155930519104, acc=0.7695000171661377, loss=0.8120155930519104
test: epoch 105, loss 1.4079004526138306, acc=0.40833333134651184, loss=1.4079004526138306
train: epoch 106, loss 0.7962308526039124, acc=0.7739999890327454, loss=0.7962308526039124
test: epoch 106, loss 1.3978310823440552, acc=0.39444443583488464, loss=1.3978310823440552
train: epoch 107, loss 0.8115727305412292, acc=0.7723333239555359, loss=0.8115727305412292
test: epoch 107, loss 1.3903168439865112, acc=0.4000000059604645, loss=1.3903168439865112
train: epoch 108, loss 0.8108441829681396, acc=0.7704444527626038, loss=0.8108441829681396
test: epoch 108, loss 1.394302248954773, acc=0.4055555462837219, loss=1.394302248954773
train: epoch 109, loss 0.7863292098045349, acc=0.7754999995231628, loss=0.7863292098045349
test: epoch 109, loss 1.3715972900390625, acc=0.4166666567325592, loss=1.3715972900390625
train: epoch 110, loss 0.7875819802284241, acc=0.7778333425521851, loss=0.7875819802284241
test: epoch 110, loss 1.3815484046936035, acc=0.40833333134651184, loss=1.3815484046936035
train: epoch 111, loss 0.7701164484024048, acc=0.7818333506584167, loss=0.7701164484024048
test: epoch 111, loss 1.3933711051940918, acc=0.4277777671813965, loss=1.3933711051940918
train: epoch 112, loss 0.7891189455986023, acc=0.782444417476654, loss=0.7891189455986023
test: epoch 112, loss 1.3577784299850464, acc=0.4277777671813965, loss=1.3577784299850464
train: epoch 113, loss 0.7705573439598083, acc=0.788777768611908, loss=0.7705573439598083
test: epoch 113, loss 1.3483577966690063, acc=0.4166666567325592, loss=1.3483577966690063
train: epoch 114, loss 0.7664589881896973, acc=0.7897777557373047, loss=0.7664589881896973
test: epoch 114, loss 1.3480393886566162, acc=0.42222222685813904, loss=1.3480393886566162
train: epoch 115, loss 0.7601654529571533, acc=0.7882221937179565, loss=0.7601654529571533
test: epoch 115, loss 1.3391594886779785, acc=0.42222222685813904, loss=1.3391594886779785
train: epoch 116, loss 0.746726393699646, acc=0.7940000295639038, loss=0.746726393699646
test: epoch 116, loss 1.3367860317230225, acc=0.4305555522441864, loss=1.3367860317230225
train: epoch 117, loss 0.7410767674446106, acc=0.7946110963821411, loss=0.7410767674446106
test: epoch 117, loss 1.3039578199386597, acc=0.43888887763023376, loss=1.3039578199386597
train: epoch 118, loss 0.7393990159034729, acc=0.7956666946411133, loss=0.7393990159034729
test: epoch 118, loss 1.3496668338775635, acc=0.42500001192092896, loss=1.3496668338775635
train: epoch 119, loss 0.7477529048919678, acc=0.7962222099304199, loss=0.7477529048919678
test: epoch 119, loss 1.3081085681915283, acc=0.4333333373069763, loss=1.3081085681915283
train: epoch 120, loss 0.7478543519973755, acc=0.7944444417953491, loss=0.7478543519973755
test: epoch 120, loss 1.3449313640594482, acc=0.4277777671813965, loss=1.3449313640594482
train: epoch 121, loss 0.715631365776062, acc=0.8014444708824158, loss=0.715631365776062
test: epoch 121, loss 1.2921557426452637, acc=0.43888887763023376, loss=1.2921557426452637
train: epoch 122, loss 0.7243648767471313, acc=0.805055558681488, loss=0.7243648767471313
test: epoch 122, loss 1.3023256063461304, acc=0.43888887763023376, loss=1.3023256063461304
train: epoch 123, loss 0.7241144776344299, acc=0.8000555634498596, loss=0.7241144776344299
test: epoch 123, loss 1.284146785736084, acc=0.4333333373069763, loss=1.284146785736084
train: epoch 124, loss 0.7367528080940247, acc=0.8010555505752563, loss=0.7367528080940247
test: epoch 124, loss 1.3068690299987793, acc=0.4444444477558136, loss=1.3068690299987793
train: epoch 125, loss 0.7203957438468933, acc=0.8066666722297668, loss=0.7203957438468933
test: epoch 125, loss 1.3036168813705444, acc=0.4472222328186035, loss=1.3036168813705444
train: epoch 126, loss 0.717462420463562, acc=0.8017222285270691, loss=0.717462420463562
test: epoch 126, loss 1.2759644985198975, acc=0.4472222328186035, loss=1.2759644985198975
train: epoch 127, loss 0.7029722332954407, acc=0.808555543422699, loss=0.7029722332954407
test: epoch 127, loss 1.2897987365722656, acc=0.43611112236976624, loss=1.2897987365722656
train: epoch 128, loss 0.7312055826187134, acc=0.8077777624130249, loss=0.7312055826187134
test: epoch 128, loss 1.2784290313720703, acc=0.43888887763023376, loss=1.2784290313720703
train: epoch 129, loss 0.7101888060569763, acc=0.8067222237586975, loss=0.7101888060569763
test: epoch 129, loss 1.271476149559021, acc=0.4472222328186035, loss=1.271476149559021
train: epoch 130, loss 0.7117822170257568, acc=0.8068888783454895, loss=0.7117822170257568
test: epoch 130, loss 1.2560523748397827, acc=0.4416666626930237, loss=1.2560523748397827
train: epoch 131, loss 0.6969626545906067, acc=0.8118333220481873, loss=0.6969626545906067
test: epoch 131, loss 1.2686020135879517, acc=0.4472222328186035, loss=1.2686020135879517
train: epoch 132, loss 0.6831893920898438, acc=0.8130000233650208, loss=0.6831893920898438
test: epoch 132, loss 1.25127112865448, acc=0.4444444477558136, loss=1.25127112865448
train: epoch 133, loss 0.7138382792472839, acc=0.8077222108840942, loss=0.7138382792472839
test: epoch 133, loss 1.249671459197998, acc=0.4444444477558136, loss=1.249671459197998
train: epoch 134, loss 0.6727050542831421, acc=0.8134444355964661, loss=0.6727050542831421
test: epoch 134, loss 1.2189351320266724, acc=0.4694444537162781, loss=1.2189351320266724
train: epoch 135, loss 0.7025715112686157, acc=0.8112221956253052, loss=0.7025715112686157
test: epoch 135, loss 1.2046304941177368, acc=0.46666666865348816, loss=1.2046304941177368
train: epoch 136, loss 0.6723107695579529, acc=0.8115000128746033, loss=0.6723107695579529
test: epoch 136, loss 1.2094042301177979, acc=0.4472222328186035, loss=1.2094042301177979
train: epoch 137, loss 0.6929050087928772, acc=0.8123888969421387, loss=0.6929050087928772
test: epoch 137, loss 1.2144211530685425, acc=0.46666666865348816, loss=1.2144211530685425
train: epoch 138, loss 0.6777313947677612, acc=0.8180555701255798, loss=0.6777313947677612
test: epoch 138, loss 1.1958515644073486, acc=0.46388888359069824, loss=1.1958515644073486
train: epoch 139, loss 0.685429036617279, acc=0.8133888840675354, loss=0.685429036617279
test: epoch 139, loss 1.193420648574829, acc=0.46666666865348816, loss=1.193420648574829
train: epoch 140, loss 0.6738417744636536, acc=0.819611132144928, loss=0.6738417744636536
test: epoch 140, loss 1.1945750713348389, acc=0.47777777910232544, loss=1.1945750713348389
train: epoch 141, loss 0.6707723140716553, acc=0.8181111216545105, loss=0.6707723140716553
test: epoch 141, loss 1.1914396286010742, acc=0.4611110985279083, loss=1.1914396286010742
train: epoch 142, loss 0.674656331539154, acc=0.8213333487510681, loss=0.674656331539154
test: epoch 142, loss 1.1895161867141724, acc=0.46666666865348816, loss=1.1895161867141724
train: epoch 143, loss 0.6527804732322693, acc=0.825166642665863, loss=0.6527804732322693
test: epoch 143, loss 1.1929092407226562, acc=0.46666666865348816, loss=1.1929092407226562
train: epoch 144, loss 0.6884233951568604, acc=0.8195000290870667, loss=0.6884233951568604
test: epoch 144, loss 1.2009936571121216, acc=0.47777777910232544, loss=1.2009936571121216
train: epoch 145, loss 0.6368578672409058, acc=0.8281111121177673, loss=0.6368578672409058
test: epoch 145, loss 1.1941717863082886, acc=0.48055556416511536, loss=1.1941717863082886
train: epoch 146, loss 0.6377152800559998, acc=0.8261666893959045, loss=0.6377152800559998
test: epoch 146, loss 1.1554127931594849, acc=0.4833333194255829, loss=1.1554127931594849
train: epoch 147, loss 0.6480165123939514, acc=0.8247222304344177, loss=0.6480165123939514
test: epoch 147, loss 1.1744204759597778, acc=0.4861111044883728, loss=1.1744204759597778
train: epoch 148, loss 0.6273221969604492, acc=0.8315555453300476, loss=0.6273221969604492
test: epoch 148, loss 1.174230694770813, acc=0.48055556416511536, loss=1.174230694770813
train: epoch 149, loss 0.6160404682159424, acc=0.8325555324554443, loss=0.6160404682159424
test: epoch 149, loss 1.1619086265563965, acc=0.4972222149372101, loss=1.1619086265563965
train: epoch 150, loss 0.6158152222633362, acc=0.8331666588783264, loss=0.6158152222633362
test: epoch 150, loss 1.149884581565857, acc=0.4972222149372101, loss=1.149884581565857
