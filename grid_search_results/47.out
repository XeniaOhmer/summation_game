# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=1", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=2099832313, receiver_embed_dim=32, save_run=0, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=2099832313, receiver_embed_dim=32, save_run=False, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.090331554412842, acc=0.07988888770341873, loss=3.090331554412842
test: epoch 1, loss 5.4001545906066895, acc=0.07222222536802292, loss=5.4001545906066895
train: epoch 2, loss 2.083552122116089, acc=0.21922221779823303, loss=2.083552122116089
test: epoch 2, loss 5.503060817718506, acc=0.08888889104127884, loss=5.503060817718506
train: epoch 3, loss 1.6497520208358765, acc=0.3215000033378601, loss=1.6497520208358765
test: epoch 3, loss 4.7584381103515625, acc=0.13611111044883728, loss=4.7584381103515625
train: epoch 4, loss 1.396613359451294, acc=0.4186111092567444, loss=1.396613359451294
test: epoch 4, loss 4.405153751373291, acc=0.1666666716337204, loss=4.405153751373291
train: epoch 5, loss 1.1096760034561157, acc=0.5622777938842773, loss=1.1096760034561157
test: epoch 5, loss 4.598290920257568, acc=0.18611110746860504, loss=4.598290920257568
train: epoch 6, loss 0.8574475049972534, acc=0.6769999861717224, loss=0.8574475049972534
test: epoch 6, loss 4.1778950691223145, acc=0.18888889253139496, loss=4.1778950691223145
train: epoch 7, loss 0.6928398609161377, acc=0.7395555377006531, loss=0.6928398609161377
test: epoch 7, loss 3.7388792037963867, acc=0.19166666269302368, loss=3.7388792037963867
train: epoch 8, loss 0.6104881763458252, acc=0.769944429397583, loss=0.6104881763458252
test: epoch 8, loss 3.5494284629821777, acc=0.2805555462837219, loss=3.5494284629821777
train: epoch 9, loss 0.5419225096702576, acc=0.7985555529594421, loss=0.5419225096702576
test: epoch 9, loss 3.2332651615142822, acc=0.21111111342906952, loss=3.2332651615142822
train: epoch 10, loss 0.4730791747570038, acc=0.8266666531562805, loss=0.4730791747570038
test: epoch 10, loss 2.939394235610962, acc=0.2638888955116272, loss=2.939394235610962
train: epoch 11, loss 0.445332407951355, acc=0.8389999866485596, loss=0.445332407951355
test: epoch 11, loss 2.7630326747894287, acc=0.29722222685813904, loss=2.7630326747894287
train: epoch 12, loss 0.41386690735816956, acc=0.8522777557373047, loss=0.41386690735816956
test: epoch 12, loss 2.6201610565185547, acc=0.32777777314186096, loss=2.6201610565185547
train: epoch 13, loss 0.37501242756843567, acc=0.8681111335754395, loss=0.37501242756843567
test: epoch 13, loss 3.0756125450134277, acc=0.32499998807907104, loss=3.0756125450134277
train: epoch 14, loss 0.34605610370635986, acc=0.8816111087799072, loss=0.34605610370635986
test: epoch 14, loss 3.158440589904785, acc=0.2805555462837219, loss=3.158440589904785
train: epoch 15, loss 0.337465763092041, acc=0.883222222328186, loss=0.337465763092041
test: epoch 15, loss 2.8685011863708496, acc=0.31111112236976624, loss=2.8685011863708496
train: epoch 16, loss 0.32412591576576233, acc=0.8874444365501404, loss=0.32412591576576233
test: epoch 16, loss 2.75307559967041, acc=0.30000001192092896, loss=2.75307559967041
train: epoch 17, loss 0.2960549592971802, acc=0.897944450378418, loss=0.2960549592971802
test: epoch 17, loss 3.003220796585083, acc=0.31111112236976624, loss=3.003220796585083
train: epoch 18, loss 0.2813895046710968, acc=0.9045000076293945, loss=0.2813895046710968
test: epoch 18, loss 3.123530387878418, acc=0.3583333194255829, loss=3.123530387878418
train: epoch 19, loss 0.27086082100868225, acc=0.9084444642066956, loss=0.27086082100868225
test: epoch 19, loss 3.0900025367736816, acc=0.2888889014720917, loss=3.0900025367736816
train: epoch 20, loss 0.2618061900138855, acc=0.9126666784286499, loss=0.2618061900138855
test: epoch 20, loss 2.5025417804718018, acc=0.29722222685813904, loss=2.5025417804718018
train: epoch 21, loss 0.25326699018478394, acc=0.9157222509384155, loss=0.25326699018478394
test: epoch 21, loss 2.6506588459014893, acc=0.3888888955116272, loss=2.6506588459014893
train: epoch 22, loss 0.2582511305809021, acc=0.9154444336891174, loss=0.2582511305809021
test: epoch 22, loss 2.268848180770874, acc=0.38333332538604736, loss=2.268848180770874
train: epoch 23, loss 0.23506686091423035, acc=0.9247221946716309, loss=0.23506686091423035
test: epoch 23, loss 2.053629159927368, acc=0.3722222149372101, loss=2.053629159927368
train: epoch 24, loss 0.22621475160121918, acc=0.9263333082199097, loss=0.22621475160121918
test: epoch 24, loss 2.346735715866089, acc=0.3499999940395355, loss=2.346735715866089
train: epoch 25, loss 0.23498110473155975, acc=0.9238333106040955, loss=0.23498110473155975
test: epoch 25, loss 2.1826677322387695, acc=0.35277777910232544, loss=2.1826677322387695
train: epoch 26, loss 0.20248812437057495, acc=0.9345555305480957, loss=0.20248812437057495
test: epoch 26, loss 2.51973819732666, acc=0.38333332538604736, loss=2.51973819732666
train: epoch 27, loss 0.20129437744617462, acc=0.9329444169998169, loss=0.20129437744617462
test: epoch 27, loss 2.474238872528076, acc=0.3777777850627899, loss=2.474238872528076
train: epoch 28, loss 0.20846718549728394, acc=0.9340555667877197, loss=0.20846718549728394
test: epoch 28, loss 2.1967573165893555, acc=0.36944442987442017, loss=2.1967573165893555
train: epoch 29, loss 0.195161834359169, acc=0.9388333559036255, loss=0.195161834359169
test: epoch 29, loss 2.3423283100128174, acc=0.3583333194255829, loss=2.3423283100128174
train: epoch 30, loss 0.1849978268146515, acc=0.9404444694519043, loss=0.1849978268146515
test: epoch 30, loss 2.605365514755249, acc=0.3777777850627899, loss=2.605365514755249
train: epoch 31, loss 0.18170945346355438, acc=0.9424999952316284, loss=0.18170945346355438
test: epoch 31, loss 2.1839263439178467, acc=0.3333333432674408, loss=2.1839263439178467
train: epoch 32, loss 0.18932640552520752, acc=0.9411110877990723, loss=0.18932640552520752
test: epoch 32, loss 1.957839012145996, acc=0.4000000059604645, loss=1.957839012145996
train: epoch 33, loss 0.16472318768501282, acc=0.9472222328186035, loss=0.16472318768501282
test: epoch 33, loss 2.0198099613189697, acc=0.4000000059604645, loss=2.0198099613189697
train: epoch 34, loss 0.18952158093452454, acc=0.9421666860580444, loss=0.18952158093452454
test: epoch 34, loss 2.1726369857788086, acc=0.3722222149372101, loss=2.1726369857788086
train: epoch 35, loss 0.17669659852981567, acc=0.9438889026641846, loss=0.17669659852981567
test: epoch 35, loss 2.2110705375671387, acc=0.42500001192092896, loss=2.2110705375671387
train: epoch 36, loss 0.1579156070947647, acc=0.9491666555404663, loss=0.1579156070947647
test: epoch 36, loss 2.186065673828125, acc=0.3444444537162781, loss=2.186065673828125
train: epoch 37, loss 0.17339377105236053, acc=0.9458333253860474, loss=0.17339377105236053
test: epoch 37, loss 2.2531614303588867, acc=0.34166666865348816, loss=2.2531614303588867
train: epoch 38, loss 0.16147570312023163, acc=0.9495555758476257, loss=0.16147570312023163
test: epoch 38, loss 1.9001177549362183, acc=0.3861111104488373, loss=1.9001177549362183
train: epoch 39, loss 0.16082903742790222, acc=0.949833333492279, loss=0.16082903742790222
test: epoch 39, loss 2.2263858318328857, acc=0.36666667461395264, loss=2.2263858318328857
train: epoch 40, loss 0.15358054637908936, acc=0.9498888850212097, loss=0.15358054637908936
test: epoch 40, loss 2.0893125534057617, acc=0.44999998807907104, loss=2.0893125534057617
train: epoch 41, loss 0.15150104463100433, acc=0.9512777924537659, loss=0.15150104463100433
test: epoch 41, loss 1.7674639225006104, acc=0.41111111640930176, loss=1.7674639225006104
train: epoch 42, loss 0.15498022735118866, acc=0.9538333415985107, loss=0.15498022735118866
test: epoch 42, loss 1.9073396921157837, acc=0.46666666865348816, loss=1.9073396921157837
train: epoch 43, loss 0.14940275251865387, acc=0.9527778029441833, loss=0.14940275251865387
test: epoch 43, loss 2.2079532146453857, acc=0.4138889014720917, loss=2.2079532146453857
train: epoch 44, loss 0.14935225248336792, acc=0.9512222409248352, loss=0.14935225248336792
test: epoch 44, loss 1.8656772375106812, acc=0.42500001192092896, loss=1.8656772375106812
train: epoch 45, loss 0.1527452915906906, acc=0.9527222514152527, loss=0.1527452915906906
test: epoch 45, loss 1.8449047803878784, acc=0.4694444537162781, loss=1.8449047803878784
train: epoch 46, loss 0.14416582882404327, acc=0.9563888907432556, loss=0.14416582882404327
test: epoch 46, loss 1.6529229879379272, acc=0.42222222685813904, loss=1.6529229879379272
train: epoch 47, loss 0.15412794053554535, acc=0.9533888697624207, loss=0.15412794053554535
test: epoch 47, loss 2.0135746002197266, acc=0.4555555582046509, loss=2.0135746002197266
train: epoch 48, loss 0.14209114015102386, acc=0.9549999833106995, loss=0.14209114015102386
test: epoch 48, loss 1.771604299545288, acc=0.4305555522441864, loss=1.771604299545288
train: epoch 49, loss 0.13945335149765015, acc=0.9566110968589783, loss=0.13945335149765015
test: epoch 49, loss 1.6530121564865112, acc=0.5027777552604675, loss=1.6530121564865112
train: epoch 50, loss 0.12943506240844727, acc=0.9591666460037231, loss=0.12943506240844727
test: epoch 50, loss 1.9092988967895508, acc=0.4611110985279083, loss=1.9092988967895508
train: epoch 51, loss 0.14299225807189941, acc=0.9541110992431641, loss=0.14299225807189941
test: epoch 51, loss 1.5501668453216553, acc=0.4416666626930237, loss=1.5501668453216553
train: epoch 52, loss 0.13868078589439392, acc=0.9564999938011169, loss=0.13868078589439392
test: epoch 52, loss 1.5219340324401855, acc=0.49444442987442017, loss=1.5219340324401855
train: epoch 53, loss 0.1293967068195343, acc=0.9571666717529297, loss=0.1293967068195343
test: epoch 53, loss 1.6700644493103027, acc=0.5, loss=1.6700644493103027
train: epoch 54, loss 0.13199248909950256, acc=0.9577777981758118, loss=0.13199248909950256
test: epoch 54, loss 1.8579304218292236, acc=0.4694444537162781, loss=1.8579304218292236
train: epoch 55, loss 0.13005362451076508, acc=0.9577222466468811, loss=0.13005362451076508
test: epoch 55, loss 1.6952104568481445, acc=0.5305555462837219, loss=1.6952104568481445
train: epoch 56, loss 0.1437177211046219, acc=0.956333339214325, loss=0.1437177211046219
test: epoch 56, loss 1.4448710680007935, acc=0.5944444537162781, loss=1.4448710680007935
train: epoch 57, loss 0.13383933901786804, acc=0.9595555663108826, loss=0.13383933901786804
test: epoch 57, loss 1.5905882120132446, acc=0.5055555701255798, loss=1.5905882120132446
train: epoch 58, loss 0.13667042553424835, acc=0.9580000042915344, loss=0.13667042553424835
test: epoch 58, loss 1.6951316595077515, acc=0.4444444477558136, loss=1.6951316595077515
train: epoch 59, loss 0.12382194399833679, acc=0.9629444479942322, loss=0.12382194399833679
test: epoch 59, loss 1.6941558122634888, acc=0.4861111044883728, loss=1.6941558122634888
train: epoch 60, loss 0.1384366750717163, acc=0.9573333263397217, loss=0.1384366750717163
test: epoch 60, loss 1.823150396347046, acc=0.49166667461395264, loss=1.823150396347046
train: epoch 61, loss 0.12583255767822266, acc=0.9589999914169312, loss=0.12583255767822266
test: epoch 61, loss 1.8046798706054688, acc=0.4694444537162781, loss=1.8046798706054688
train: epoch 62, loss 0.12437272816896439, acc=0.9599999785423279, loss=0.12437272816896439
test: epoch 62, loss 1.550706386566162, acc=0.5416666865348816, loss=1.550706386566162
train: epoch 63, loss 0.1306060254573822, acc=0.9583888649940491, loss=0.1306060254573822
test: epoch 63, loss 1.5192190408706665, acc=0.5666666626930237, loss=1.5192190408706665
train: epoch 64, loss 0.12983521819114685, acc=0.9599444270133972, loss=0.12983521819114685
test: epoch 64, loss 1.74604070186615, acc=0.4305555522441864, loss=1.74604070186615
train: epoch 65, loss 0.13466934859752655, acc=0.9601666927337646, loss=0.13466934859752655
test: epoch 65, loss 1.9265036582946777, acc=0.5222222208976746, loss=1.9265036582946777
train: epoch 66, loss 0.12786023318767548, acc=0.9592221975326538, loss=0.12786023318767548
test: epoch 66, loss 1.6800191402435303, acc=0.4000000059604645, loss=1.6800191402435303
train: epoch 67, loss 0.12871427834033966, acc=0.9586666822433472, loss=0.12871427834033966
test: epoch 67, loss 1.723779320716858, acc=0.5333333611488342, loss=1.723779320716858
train: epoch 68, loss 0.12550745904445648, acc=0.9601110816001892, loss=0.12550745904445648
test: epoch 68, loss 1.5043845176696777, acc=0.5361111164093018, loss=1.5043845176696777
train: epoch 69, loss 0.12502321600914001, acc=0.9611111283302307, loss=0.12502321600914001
test: epoch 69, loss 1.5651289224624634, acc=0.5305555462837219, loss=1.5651289224624634
train: epoch 70, loss 0.12559951841831207, acc=0.9599444270133972, loss=0.12559951841831207
test: epoch 70, loss 1.514939546585083, acc=0.5027777552604675, loss=1.514939546585083
train: epoch 71, loss 0.12817268073558807, acc=0.9614999890327454, loss=0.12817268073558807
test: epoch 71, loss 1.9533096551895142, acc=0.5055555701255798, loss=1.9533096551895142
train: epoch 72, loss 0.13091979920864105, acc=0.9599999785423279, loss=0.13091979920864105
test: epoch 72, loss 1.770793080329895, acc=0.5555555820465088, loss=1.770793080329895
train: epoch 73, loss 0.12759919464588165, acc=0.9601666927337646, loss=0.12759919464588165
test: epoch 73, loss 1.474088430404663, acc=0.5111111402511597, loss=1.474088430404663
train: epoch 74, loss 0.12086357176303864, acc=0.9625555276870728, loss=0.12086357176303864
test: epoch 74, loss 1.6688071489334106, acc=0.5111111402511597, loss=1.6688071489334106
train: epoch 75, loss 0.14091207087039948, acc=0.9575555324554443, loss=0.14091207087039948
test: epoch 75, loss 1.8294589519500732, acc=0.5222222208976746, loss=1.8294589519500732
train: epoch 76, loss 0.11999774724245071, acc=0.9618333578109741, loss=0.11999774724245071
test: epoch 76, loss 1.62748384475708, acc=0.6388888955116272, loss=1.62748384475708
train: epoch 77, loss 0.12810738384723663, acc=0.9601110816001892, loss=0.12810738384723663
test: epoch 77, loss 1.6002960205078125, acc=0.4888888895511627, loss=1.6002960205078125
train: epoch 78, loss 0.12165851891040802, acc=0.9605000019073486, loss=0.12165851891040802
test: epoch 78, loss 1.5981560945510864, acc=0.49166667461395264, loss=1.5981560945510864
train: epoch 79, loss 0.11001094430685043, acc=0.9669444561004639, loss=0.11001094430685043
test: epoch 79, loss 1.469053030014038, acc=0.5361111164093018, loss=1.469053030014038
train: epoch 80, loss 0.12815548479557037, acc=0.9574999809265137, loss=0.12815548479557037
test: epoch 80, loss 1.3791353702545166, acc=0.5333333611488342, loss=1.3791353702545166
train: epoch 81, loss 0.12832635641098022, acc=0.9610555768013, loss=0.12832635641098022
test: epoch 81, loss 1.6795868873596191, acc=0.49166667461395264, loss=1.6795868873596191
train: epoch 82, loss 0.11956530064344406, acc=0.9626111388206482, loss=0.11956530064344406
test: epoch 82, loss 1.773163914680481, acc=0.5277777910232544, loss=1.773163914680481
train: epoch 83, loss 0.11734822392463684, acc=0.9633333086967468, loss=0.11734822392463684
test: epoch 83, loss 1.4688334465026855, acc=0.5555555820465088, loss=1.4688334465026855
train: epoch 84, loss 0.12562723457813263, acc=0.9612777829170227, loss=0.12562723457813263
test: epoch 84, loss 1.561478853225708, acc=0.49166667461395264, loss=1.561478853225708
train: epoch 85, loss 0.11805950105190277, acc=0.9630555510520935, loss=0.11805950105190277
test: epoch 85, loss 1.3323918581008911, acc=0.5361111164093018, loss=1.3323918581008911
train: epoch 86, loss 0.11745965480804443, acc=0.9654444456100464, loss=0.11745965480804443
test: epoch 86, loss 1.319942593574524, acc=0.5222222208976746, loss=1.319942593574524
train: epoch 87, loss 0.11501879245042801, acc=0.9631666541099548, loss=0.11501879245042801
test: epoch 87, loss 1.4028376340866089, acc=0.5944444537162781, loss=1.4028376340866089
train: epoch 88, loss 0.11984578520059586, acc=0.9639444351196289, loss=0.11984578520059586
test: epoch 88, loss 1.4300605058670044, acc=0.574999988079071, loss=1.4300605058670044
train: epoch 89, loss 0.11323386430740356, acc=0.9646111130714417, loss=0.11323386430740356
test: epoch 89, loss 1.2469247579574585, acc=0.625, loss=1.2469247579574585
train: epoch 90, loss 0.12457912415266037, acc=0.9610555768013, loss=0.12457912415266037
test: epoch 90, loss 1.2170486450195312, acc=0.6361111402511597, loss=1.2170486450195312
train: epoch 91, loss 0.11624044179916382, acc=0.9627222418785095, loss=0.11624044179916382
test: epoch 91, loss 1.32925283908844, acc=0.6111111044883728, loss=1.32925283908844
train: epoch 92, loss 0.11240556836128235, acc=0.9652222394943237, loss=0.11240556836128235
test: epoch 92, loss 1.0897626876831055, acc=0.6027777791023254, loss=1.0897626876831055
train: epoch 93, loss 0.11991655081510544, acc=0.9628888964653015, loss=0.11991655081510544
test: epoch 93, loss 1.203706979751587, acc=0.6166666746139526, loss=1.203706979751587
train: epoch 94, loss 0.12272950261831284, acc=0.9641666412353516, loss=0.12272950261831284
test: epoch 94, loss 1.1277096271514893, acc=0.6388888955116272, loss=1.1277096271514893
train: epoch 95, loss 0.11509472876787186, acc=0.9649444222450256, loss=0.11509472876787186
test: epoch 95, loss 1.2977187633514404, acc=0.6000000238418579, loss=1.2977187633514404
train: epoch 96, loss 0.11769384890794754, acc=0.9634444713592529, loss=0.11769384890794754
test: epoch 96, loss 1.4238427877426147, acc=0.6111111044883728, loss=1.4238427877426147
train: epoch 97, loss 0.09989552944898605, acc=0.9678888916969299, loss=0.09989552944898605
test: epoch 97, loss 1.9077186584472656, acc=0.5444444417953491, loss=1.9077186584472656
train: epoch 98, loss 0.11667199432849884, acc=0.9631666541099548, loss=0.11667199432849884
test: epoch 98, loss 1.3629169464111328, acc=0.5888888835906982, loss=1.3629169464111328
train: epoch 99, loss 0.11597460508346558, acc=0.9667222499847412, loss=0.11597460508346558
test: epoch 99, loss 1.4086432456970215, acc=0.5972222089767456, loss=1.4086432456970215
train: epoch 100, loss 0.10796938836574554, acc=0.9673333168029785, loss=0.10796938836574554
test: epoch 100, loss 1.61312735080719, acc=0.574999988079071, loss=1.61312735080719
train: epoch 101, loss 0.11432100832462311, acc=0.965666651725769, loss=0.11432100832462311
test: epoch 101, loss 1.247023582458496, acc=0.6138888597488403, loss=1.247023582458496
train: epoch 102, loss 0.1312456578016281, acc=0.9597222208976746, loss=0.1312456578016281
test: epoch 102, loss 1.1103668212890625, acc=0.6472222208976746, loss=1.1103668212890625
train: epoch 103, loss 0.12649406492710114, acc=0.9618889093399048, loss=0.12649406492710114
test: epoch 103, loss 1.3513634204864502, acc=0.574999988079071, loss=1.3513634204864502
train: epoch 104, loss 0.1073276624083519, acc=0.9668889045715332, loss=0.1073276624083519
test: epoch 104, loss 1.2541098594665527, acc=0.6388888955116272, loss=1.2541098594665527
train: epoch 105, loss 0.1011485904455185, acc=0.9687222242355347, loss=0.1011485904455185
test: epoch 105, loss 1.190652847290039, acc=0.625, loss=1.190652847290039
train: epoch 106, loss 0.11810053884983063, acc=0.9639999866485596, loss=0.11810053884983063
test: epoch 106, loss 1.3577651977539062, acc=0.625, loss=1.3577651977539062
train: epoch 107, loss 0.1070396900177002, acc=0.9674444198608398, loss=0.1070396900177002
test: epoch 107, loss 1.2101415395736694, acc=0.6722221970558167, loss=1.2101415395736694
train: epoch 108, loss 0.10838700085878372, acc=0.9669444561004639, loss=0.10838700085878372
test: epoch 108, loss 1.0559344291687012, acc=0.6833333373069763, loss=1.0559344291687012
train: epoch 109, loss 0.11738114058971405, acc=0.9639444351196289, loss=0.11738114058971405
test: epoch 109, loss 1.2474255561828613, acc=0.6666666865348816, loss=1.2474255561828613
train: epoch 110, loss 0.11282355338335037, acc=0.9653888940811157, loss=0.11282355338335037
test: epoch 110, loss 1.0724475383758545, acc=0.6972222328186035, loss=1.0724475383758545
train: epoch 111, loss 0.10057809948921204, acc=0.9687222242355347, loss=0.10057809948921204
test: epoch 111, loss 1.1441750526428223, acc=0.6972222328186035, loss=1.1441750526428223
train: epoch 112, loss 0.1036459431052208, acc=0.9684444665908813, loss=0.1036459431052208
test: epoch 112, loss 1.0741965770721436, acc=0.6472222208976746, loss=1.0741965770721436
train: epoch 113, loss 0.11352725327014923, acc=0.964555561542511, loss=0.11352725327014923
test: epoch 113, loss 1.098172664642334, acc=0.6972222328186035, loss=1.098172664642334
train: epoch 114, loss 0.12331607192754745, acc=0.9625555276870728, loss=0.12331607192754745
test: epoch 114, loss 0.8102127313613892, acc=0.7194444537162781, loss=0.8102127313613892
train: epoch 115, loss 0.10588070005178452, acc=0.9667222499847412, loss=0.10588070005178452
test: epoch 115, loss 1.049494981765747, acc=0.6583333611488342, loss=1.049494981765747
train: epoch 116, loss 0.1030815988779068, acc=0.9669444561004639, loss=0.1030815988779068
test: epoch 116, loss 1.0049223899841309, acc=0.7083333134651184, loss=1.0049223899841309
train: epoch 117, loss 0.11109818518161774, acc=0.9667222499847412, loss=0.11109818518161774
test: epoch 117, loss 0.9430561065673828, acc=0.6833333373069763, loss=0.9430561065673828
train: epoch 118, loss 0.11202261596918106, acc=0.964388906955719, loss=0.11202261596918106
test: epoch 118, loss 1.1655778884887695, acc=0.7194444537162781, loss=1.1655778884887695
train: epoch 119, loss 0.10237643867731094, acc=0.9690555334091187, loss=0.10237643867731094
test: epoch 119, loss 0.9434312582015991, acc=0.7277777791023254, loss=0.9434312582015991
train: epoch 120, loss 0.10949473828077316, acc=0.9652222394943237, loss=0.10949473828077316
test: epoch 120, loss 0.8608797788619995, acc=0.7083333134651184, loss=0.8608797788619995
train: epoch 121, loss 0.09599512070417404, acc=0.9706110954284668, loss=0.09599512070417404
test: epoch 121, loss 0.6637104749679565, acc=0.8472222089767456, loss=0.6637104749679565
train: epoch 122, loss 0.11315082758665085, acc=0.9667222499847412, loss=0.11315082758665085
test: epoch 122, loss 0.949101448059082, acc=0.7361111044883728, loss=0.949101448059082
train: epoch 123, loss 0.11229927092790604, acc=0.9664999842643738, loss=0.11229927092790604
test: epoch 123, loss 0.8579544425010681, acc=0.7722222208976746, loss=0.8579544425010681
train: epoch 124, loss 0.10735489428043365, acc=0.9676666855812073, loss=0.10735489428043365
test: epoch 124, loss 0.872046947479248, acc=0.7722222208976746, loss=0.872046947479248
train: epoch 125, loss 0.11639293283224106, acc=0.964888870716095, loss=0.11639293283224106
test: epoch 125, loss 0.7238780856132507, acc=0.7611111402511597, loss=0.7238780856132507
train: epoch 126, loss 0.0939345434308052, acc=0.9708889126777649, loss=0.0939345434308052
test: epoch 126, loss 0.7840793132781982, acc=0.7749999761581421, loss=0.7840793132781982
train: epoch 127, loss 0.10005632787942886, acc=0.9708889126777649, loss=0.10005632787942886
test: epoch 127, loss 0.7814152240753174, acc=0.7805555462837219, loss=0.7814152240753174
train: epoch 128, loss 0.09491365402936935, acc=0.9721666574478149, loss=0.09491365402936935
test: epoch 128, loss 0.8869407773017883, acc=0.8138889074325562, loss=0.8869407773017883
train: epoch 129, loss 0.09456421434879303, acc=0.9712222218513489, loss=0.09456421434879303
test: epoch 129, loss 0.7370837330818176, acc=0.7833333611488342, loss=0.7370837330818176
train: epoch 130, loss 0.09917665272951126, acc=0.9694444537162781, loss=0.09917665272951126
test: epoch 130, loss 0.7845149040222168, acc=0.7722222208976746, loss=0.7845149040222168
train: epoch 131, loss 0.09304685890674591, acc=0.9721111059188843, loss=0.09304685890674591
test: epoch 131, loss 0.49143528938293457, acc=0.8388888835906982, loss=0.49143528938293457
train: epoch 132, loss 0.09430468827486038, acc=0.9735555648803711, loss=0.09430468827486038
test: epoch 132, loss 0.41057366132736206, acc=0.8777777552604675, loss=0.41057366132736206
train: epoch 133, loss 0.09336681663990021, acc=0.9711111187934875, loss=0.09336681663990021
test: epoch 133, loss 0.707213282585144, acc=0.8388888835906982, loss=0.707213282585144
train: epoch 134, loss 0.10330341756343842, acc=0.9694444537162781, loss=0.10330341756343842
test: epoch 134, loss 0.5546357035636902, acc=0.8500000238418579, loss=0.5546357035636902
train: epoch 135, loss 0.09411677718162537, acc=0.9715555310249329, loss=0.09411677718162537
test: epoch 135, loss 0.4080484211444855, acc=0.875, loss=0.4080484211444855
train: epoch 136, loss 0.09857024997472763, acc=0.9701111316680908, loss=0.09857024997472763
test: epoch 136, loss 0.466407835483551, acc=0.8638888597488403, loss=0.466407835483551
train: epoch 137, loss 0.07848036289215088, acc=0.9751666784286499, loss=0.07848036289215088
test: epoch 137, loss 0.3139660656452179, acc=0.9111111164093018, loss=0.3139660656452179
train: epoch 138, loss 0.07668331265449524, acc=0.9780555367469788, loss=0.07668331265449524
test: epoch 138, loss 0.3453865945339203, acc=0.8861111402511597, loss=0.3453865945339203
train: epoch 139, loss 0.08183557540178299, acc=0.9756666421890259, loss=0.08183557540178299
test: epoch 139, loss 0.2931024134159088, acc=0.9166666865348816, loss=0.2931024134159088
train: epoch 140, loss 0.07496292889118195, acc=0.9780555367469788, loss=0.07496292889118195
test: epoch 140, loss 0.28673726320266724, acc=0.9194444417953491, loss=0.28673726320266724
train: epoch 141, loss 0.08384427428245544, acc=0.9755555391311646, loss=0.08384427428245544
test: epoch 141, loss 0.49082785844802856, acc=0.9055555462837219, loss=0.49082785844802856
train: epoch 142, loss 0.08283653855323792, acc=0.9757221937179565, loss=0.08283653855323792
test: epoch 142, loss 0.1644349843263626, acc=0.9555555582046509, loss=0.1644349843263626
train: epoch 143, loss 0.07961630821228027, acc=0.9777222275733948, loss=0.07961630821228027
test: epoch 143, loss 0.3634445369243622, acc=0.9083333611488342, loss=0.3634445369243622
train: epoch 144, loss 0.060468923300504684, acc=0.9819999933242798, loss=0.060468923300504684
test: epoch 144, loss 0.1583835482597351, acc=0.9555555582046509, loss=0.1583835482597351
train: epoch 145, loss 0.08079791814088821, acc=0.9761666655540466, loss=0.08079791814088821
test: epoch 145, loss 0.25330254435539246, acc=0.9027777910232544, loss=0.25330254435539246
train: epoch 146, loss 0.06469497084617615, acc=0.9806110858917236, loss=0.06469497084617615
test: epoch 146, loss 0.25156453251838684, acc=0.9222221970558167, loss=0.25156453251838684
train: epoch 147, loss 0.07428806275129318, acc=0.9773889183998108, loss=0.07428806275129318
test: epoch 147, loss 0.13215313851833344, acc=0.9638888835906982, loss=0.13215313851833344
train: epoch 148, loss 0.07423996180295944, acc=0.9787222146987915, loss=0.07423996180295944
test: epoch 148, loss 0.16211894154548645, acc=0.9638888835906982, loss=0.16211894154548645
train: epoch 149, loss 0.061102256178855896, acc=0.9826666712760925, loss=0.061102256178855896
test: epoch 149, loss 0.1436738520860672, acc=0.9583333134651184, loss=0.1436738520860672
train: epoch 150, loss 0.06931812316179276, acc=0.9807222485542297, loss=0.06931812316179276
test: epoch 150, loss 0.11850135028362274, acc=0.9638888835906982, loss=0.11850135028362274
