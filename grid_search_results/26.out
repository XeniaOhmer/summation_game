# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=0", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=1000827971, receiver_embed_dim=32, save_run=0, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=1000827971, receiver_embed_dim=32, save_run=False, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.642606735229492, acc=0.13877777755260468, loss=2.642606735229492
test: epoch 1, loss 5.008464813232422, acc=0.05833333358168602, loss=5.008464813232422
train: epoch 2, loss 1.8495179414749146, acc=0.2814444303512573, loss=1.8495179414749146
test: epoch 2, loss 4.2664642333984375, acc=0.08611111342906952, loss=4.2664642333984375
train: epoch 3, loss 1.5672892332077026, acc=0.3683333396911621, loss=1.5672892332077026
test: epoch 3, loss 3.534292697906494, acc=0.16111111640930176, loss=3.534292697906494
train: epoch 4, loss 1.4233179092407227, acc=0.4216666519641876, loss=1.4233179092407227
test: epoch 4, loss 2.777683734893799, acc=0.2222222238779068, loss=2.777683734893799
train: epoch 5, loss 1.3038192987442017, acc=0.46738889813423157, loss=1.3038192987442017
test: epoch 5, loss 3.461669683456421, acc=0.18611110746860504, loss=3.461669683456421
train: epoch 6, loss 1.2398930788040161, acc=0.5038889050483704, loss=1.2398930788040161
test: epoch 6, loss 3.076033353805542, acc=0.21666666865348816, loss=3.076033353805542
train: epoch 7, loss 1.1584516763687134, acc=0.5333333611488342, loss=1.1584516763687134
test: epoch 7, loss 3.093428373336792, acc=0.18333333730697632, loss=3.093428373336792
train: epoch 8, loss 1.1242811679840088, acc=0.5548333525657654, loss=1.1242811679840088
test: epoch 8, loss 3.3211681842803955, acc=0.17222222685813904, loss=3.3211681842803955
train: epoch 9, loss 1.0717954635620117, acc=0.5713333487510681, loss=1.0717954635620117
test: epoch 9, loss 3.009538173675537, acc=0.19722221791744232, loss=3.009538173675537
train: epoch 10, loss 1.0545380115509033, acc=0.5815555453300476, loss=1.0545380115509033
test: epoch 10, loss 2.628232479095459, acc=0.19722221791744232, loss=2.628232479095459
train: epoch 11, loss 1.012094497680664, acc=0.5938888788223267, loss=1.012094497680664
test: epoch 11, loss 2.839017868041992, acc=0.2083333283662796, loss=2.839017868041992
train: epoch 12, loss 0.9961926341056824, acc=0.6046110987663269, loss=0.9961926341056824
test: epoch 12, loss 2.768578290939331, acc=0.23888888955116272, loss=2.768578290939331
train: epoch 13, loss 0.9749665856361389, acc=0.6121666431427002, loss=0.9749665856361389
test: epoch 13, loss 3.1064915657043457, acc=0.18333333730697632, loss=3.1064915657043457
train: epoch 14, loss 0.950529158115387, acc=0.6242222189903259, loss=0.950529158115387
test: epoch 14, loss 2.9523801803588867, acc=0.2361111044883728, loss=2.9523801803588867
train: epoch 15, loss 0.9443656802177429, acc=0.628333330154419, loss=0.9443656802177429
test: epoch 15, loss 2.7670159339904785, acc=0.23333333432674408, loss=2.7670159339904785
train: epoch 16, loss 0.9209577441215515, acc=0.6341666579246521, loss=0.9209577441215515
test: epoch 16, loss 2.550349712371826, acc=0.25555557012557983, loss=2.550349712371826
train: epoch 17, loss 0.9322105646133423, acc=0.6331666707992554, loss=0.9322105646133423
test: epoch 17, loss 2.421583890914917, acc=0.28611111640930176, loss=2.421583890914917
train: epoch 18, loss 0.885662853717804, acc=0.6568889021873474, loss=0.885662853717804
test: epoch 18, loss 2.307177782058716, acc=0.31111112236976624, loss=2.307177782058716
train: epoch 19, loss 0.8929700255393982, acc=0.6455555558204651, loss=0.8929700255393982
test: epoch 19, loss 2.314561367034912, acc=0.23055554926395416, loss=2.314561367034912
train: epoch 20, loss 0.8870255351066589, acc=0.6567222476005554, loss=0.8870255351066589
test: epoch 20, loss 1.957414150238037, acc=0.3166666626930237, loss=1.957414150238037
train: epoch 21, loss 0.8508896231651306, acc=0.6756666898727417, loss=0.8508896231651306
test: epoch 21, loss 2.2961578369140625, acc=0.2805555462837219, loss=2.2961578369140625
train: epoch 22, loss 0.860573410987854, acc=0.6632221937179565, loss=0.860573410987854
test: epoch 22, loss 2.5813047885894775, acc=0.3055555522441864, loss=2.5813047885894775
train: epoch 23, loss 0.834372878074646, acc=0.6738888621330261, loss=0.834372878074646
test: epoch 23, loss 2.141064167022705, acc=0.2944444417953491, loss=2.141064167022705
train: epoch 24, loss 0.8254764676094055, acc=0.6847222447395325, loss=0.8254764676094055
test: epoch 24, loss 1.965084195137024, acc=0.3222222328186035, loss=1.965084195137024
train: epoch 25, loss 0.8255122900009155, acc=0.6842222213745117, loss=0.8255122900009155
test: epoch 25, loss 1.99778413772583, acc=0.31111112236976624, loss=1.99778413772583
train: epoch 26, loss 0.7865620255470276, acc=0.6938889026641846, loss=0.7865620255470276
test: epoch 26, loss 2.0145950317382812, acc=0.36944442987442017, loss=2.0145950317382812
train: epoch 27, loss 0.7606121897697449, acc=0.7018333077430725, loss=0.7606121897697449
test: epoch 27, loss 2.339768409729004, acc=0.29722222685813904, loss=2.339768409729004
train: epoch 28, loss 0.7640413641929626, acc=0.695277750492096, loss=0.7640413641929626
test: epoch 28, loss 2.055054187774658, acc=0.3611111044883728, loss=2.055054187774658
train: epoch 29, loss 0.7542053461074829, acc=0.7002778053283691, loss=0.7542053461074829
test: epoch 29, loss 1.665335774421692, acc=0.33888888359069824, loss=1.665335774421692
train: epoch 30, loss 0.7231975793838501, acc=0.7169444561004639, loss=0.7231975793838501
test: epoch 30, loss 1.9006385803222656, acc=0.3361110985279083, loss=1.9006385803222656
train: epoch 31, loss 0.7264886498451233, acc=0.7105555534362793, loss=0.7264886498451233
test: epoch 31, loss 1.7186530828475952, acc=0.36666667461395264, loss=1.7186530828475952
train: epoch 32, loss 0.7225185036659241, acc=0.7177777886390686, loss=0.7225185036659241
test: epoch 32, loss 1.611452579498291, acc=0.38055557012557983, loss=1.611452579498291
train: epoch 33, loss 0.7146740555763245, acc=0.7201666831970215, loss=0.7146740555763245
test: epoch 33, loss 2.0206096172332764, acc=0.3777777850627899, loss=2.0206096172332764
train: epoch 34, loss 0.7248163223266602, acc=0.715833306312561, loss=0.7248163223266602
test: epoch 34, loss 2.0862865447998047, acc=0.3583333194255829, loss=2.0862865447998047
train: epoch 35, loss 0.6747565269470215, acc=0.7362222075462341, loss=0.6747565269470215
test: epoch 35, loss 1.6482627391815186, acc=0.39722222089767456, loss=1.6482627391815186
train: epoch 36, loss 0.6804203987121582, acc=0.7351111173629761, loss=0.6804203987121582
test: epoch 36, loss 1.626471996307373, acc=0.35555556416511536, loss=1.626471996307373
train: epoch 37, loss 0.6736787557601929, acc=0.7392777800559998, loss=0.6736787557601929
test: epoch 37, loss 1.9013187885284424, acc=0.38333332538604736, loss=1.9013187885284424
train: epoch 38, loss 0.6841127276420593, acc=0.7319999933242798, loss=0.6841127276420593
test: epoch 38, loss 1.739448070526123, acc=0.31388887763023376, loss=1.739448070526123
train: epoch 39, loss 0.6720571517944336, acc=0.7377777695655823, loss=0.6720571517944336
test: epoch 39, loss 1.9191174507141113, acc=0.34166666865348816, loss=1.9191174507141113
train: epoch 40, loss 0.6603966355323792, acc=0.7437222003936768, loss=0.6603966355323792
test: epoch 40, loss 1.645353078842163, acc=0.42500001192092896, loss=1.645353078842163
train: epoch 41, loss 0.6622906923294067, acc=0.7404999732971191, loss=0.6622906923294067
test: epoch 41, loss 2.0319533348083496, acc=0.41111111640930176, loss=2.0319533348083496
train: epoch 42, loss 0.632634162902832, acc=0.7563889026641846, loss=0.632634162902832
test: epoch 42, loss 1.6411265134811401, acc=0.3638888895511627, loss=1.6411265134811401
train: epoch 43, loss 0.6303133964538574, acc=0.7546666860580444, loss=0.6303133964538574
test: epoch 43, loss 1.8212006092071533, acc=0.3722222149372101, loss=1.8212006092071533
train: epoch 44, loss 0.6403234601020813, acc=0.7469444274902344, loss=0.6403234601020813
test: epoch 44, loss 1.3370182514190674, acc=0.5, loss=1.3370182514190674
train: epoch 45, loss 0.6323076486587524, acc=0.7561666369438171, loss=0.6323076486587524
test: epoch 45, loss 1.521406650543213, acc=0.3777777850627899, loss=1.521406650543213
train: epoch 46, loss 0.6262612342834473, acc=0.7525555491447449, loss=0.6262612342834473
test: epoch 46, loss 1.6394511461257935, acc=0.4416666626930237, loss=1.6394511461257935
train: epoch 47, loss 0.6091428399085999, acc=0.7635555267333984, loss=0.6091428399085999
test: epoch 47, loss 1.706612467765808, acc=0.35555556416511536, loss=1.706612467765808
train: epoch 48, loss 0.6346374750137329, acc=0.7473333477973938, loss=0.6346374750137329
test: epoch 48, loss 1.884368896484375, acc=0.3888888955116272, loss=1.884368896484375
train: epoch 49, loss 0.6389665603637695, acc=0.749666690826416, loss=0.6389665603637695
test: epoch 49, loss 1.3434571027755737, acc=0.5083333253860474, loss=1.3434571027755737
train: epoch 50, loss 0.6081304550170898, acc=0.7646666765213013, loss=0.6081304550170898
test: epoch 50, loss 1.5362242460250854, acc=0.4333333373069763, loss=1.5362242460250854
train: epoch 51, loss 0.596542477607727, acc=0.7675555348396301, loss=0.596542477607727
test: epoch 51, loss 1.5628541707992554, acc=0.40833333134651184, loss=1.5628541707992554
train: epoch 52, loss 0.5971415042877197, acc=0.7683333158493042, loss=0.5971415042877197
test: epoch 52, loss 1.442471981048584, acc=0.4333333373069763, loss=1.442471981048584
train: epoch 53, loss 0.5790812373161316, acc=0.773888885974884, loss=0.5790812373161316
test: epoch 53, loss 1.1766741275787354, acc=0.4861111044883728, loss=1.1766741275787354
train: epoch 54, loss 0.5723277926445007, acc=0.7750555276870728, loss=0.5723277926445007
test: epoch 54, loss 1.3642632961273193, acc=0.4888888895511627, loss=1.3642632961273193
train: epoch 55, loss 0.5840858817100525, acc=0.7713888883590698, loss=0.5840858817100525
test: epoch 55, loss 1.452770709991455, acc=0.4972222149372101, loss=1.452770709991455
train: epoch 56, loss 0.5721078515052795, acc=0.7723333239555359, loss=0.5721078515052795
test: epoch 56, loss 1.303073525428772, acc=0.4027777910232544, loss=1.303073525428772
train: epoch 57, loss 0.5311379432678223, acc=0.7922777533531189, loss=0.5311379432678223
test: epoch 57, loss 1.5663820505142212, acc=0.43611112236976624, loss=1.5663820505142212
train: epoch 58, loss 0.5287514328956604, acc=0.789222240447998, loss=0.5287514328956604
test: epoch 58, loss 1.4437894821166992, acc=0.4416666626930237, loss=1.4437894821166992
train: epoch 59, loss 0.5298959612846375, acc=0.7963888645172119, loss=0.5298959612846375
test: epoch 59, loss 1.2642945051193237, acc=0.4972222149372101, loss=1.2642945051193237
train: epoch 60, loss 0.5300161838531494, acc=0.7881666421890259, loss=0.5300161838531494
test: epoch 60, loss 1.3831785917282104, acc=0.45277777314186096, loss=1.3831785917282104
train: epoch 61, loss 0.5310828685760498, acc=0.7909444570541382, loss=0.5310828685760498
test: epoch 61, loss 1.5117930173873901, acc=0.4861111044883728, loss=1.5117930173873901
train: epoch 62, loss 0.5535770058631897, acc=0.7839999794960022, loss=0.5535770058631897
test: epoch 62, loss 1.3801698684692383, acc=0.5472221970558167, loss=1.3801698684692383
train: epoch 63, loss 0.514744758605957, acc=0.7948333621025085, loss=0.514744758605957
test: epoch 63, loss 1.2490214109420776, acc=0.5166666507720947, loss=1.2490214109420776
train: epoch 64, loss 0.5182834267616272, acc=0.7958889007568359, loss=0.5182834267616272
test: epoch 64, loss 1.2486249208450317, acc=0.5388888716697693, loss=1.2486249208450317
train: epoch 65, loss 0.5274309515953064, acc=0.7846666574478149, loss=0.5274309515953064
test: epoch 65, loss 1.1662263870239258, acc=0.4861111044883728, loss=1.1662263870239258
train: epoch 66, loss 0.5022492408752441, acc=0.8004999756813049, loss=0.5022492408752441
test: epoch 66, loss 1.1460829973220825, acc=0.4722222089767456, loss=1.1460829973220825
train: epoch 67, loss 0.5064899921417236, acc=0.7963888645172119, loss=0.5064899921417236
test: epoch 67, loss 1.4274475574493408, acc=0.48055556416511536, loss=1.4274475574493408
train: epoch 68, loss 0.5202398896217346, acc=0.7876666784286499, loss=0.5202398896217346
test: epoch 68, loss 1.2394429445266724, acc=0.4722222089767456, loss=1.2394429445266724
train: epoch 69, loss 0.4913312792778015, acc=0.8013333082199097, loss=0.4913312792778015
test: epoch 69, loss 1.4081403017044067, acc=0.5083333253860474, loss=1.4081403017044067
train: epoch 70, loss 0.4865172505378723, acc=0.8038889169692993, loss=0.4865172505378723
test: epoch 70, loss 1.0990992784500122, acc=0.550000011920929, loss=1.0990992784500122
train: epoch 71, loss 0.48530229926109314, acc=0.804444432258606, loss=0.48530229926109314
test: epoch 71, loss 1.3006184101104736, acc=0.5416666865348816, loss=1.3006184101104736
train: epoch 72, loss 0.5029742121696472, acc=0.7976111173629761, loss=0.5029742121696472
test: epoch 72, loss 1.217509150505066, acc=0.5138888955116272, loss=1.217509150505066
train: epoch 73, loss 0.47939467430114746, acc=0.8113333582878113, loss=0.47939467430114746
test: epoch 73, loss 0.9799813628196716, acc=0.4888888895511627, loss=0.9799813628196716
train: epoch 74, loss 0.47512927651405334, acc=0.8086666464805603, loss=0.47512927651405334
test: epoch 74, loss 1.4308133125305176, acc=0.5, loss=1.4308133125305176
train: epoch 75, loss 0.46894553303718567, acc=0.8083333373069763, loss=0.46894553303718567
test: epoch 75, loss 1.2372702360153198, acc=0.6138888597488403, loss=1.2372702360153198
train: epoch 76, loss 0.456904798746109, acc=0.8174999952316284, loss=0.456904798746109
test: epoch 76, loss 1.2426904439926147, acc=0.5333333611488342, loss=1.2426904439926147
train: epoch 77, loss 0.4532265365123749, acc=0.8183888792991638, loss=0.4532265365123749
test: epoch 77, loss 1.2127364873886108, acc=0.5583333373069763, loss=1.2127364873886108
train: epoch 78, loss 0.47679823637008667, acc=0.8072777986526489, loss=0.47679823637008667
test: epoch 78, loss 1.2407959699630737, acc=0.5472221970558167, loss=1.2407959699630737
train: epoch 79, loss 0.48486030101776123, acc=0.8027777671813965, loss=0.48486030101776123
test: epoch 79, loss 1.0554078817367554, acc=0.5472221970558167, loss=1.0554078817367554
train: epoch 80, loss 0.463924378156662, acc=0.812333345413208, loss=0.463924378156662
test: epoch 80, loss 1.3065555095672607, acc=0.5416666865348816, loss=1.3065555095672607
train: epoch 81, loss 0.45730775594711304, acc=0.8168888688087463, loss=0.45730775594711304
test: epoch 81, loss 1.1532814502716064, acc=0.5888888835906982, loss=1.1532814502716064
train: epoch 82, loss 0.4875786006450653, acc=0.8035555481910706, loss=0.4875786006450653
test: epoch 82, loss 1.1990653276443481, acc=0.5388888716697693, loss=1.1990653276443481
train: epoch 83, loss 0.4567408859729767, acc=0.8186110854148865, loss=0.4567408859729767
test: epoch 83, loss 1.1118439435958862, acc=0.5638889074325562, loss=1.1118439435958862
train: epoch 84, loss 0.44098711013793945, acc=0.8226110935211182, loss=0.44098711013793945
test: epoch 84, loss 1.2310835123062134, acc=0.46666666865348816, loss=1.2310835123062134
train: epoch 85, loss 0.46275365352630615, acc=0.816944420337677, loss=0.46275365352630615
test: epoch 85, loss 1.0204695463180542, acc=0.5722222328186035, loss=1.0204695463180542
train: epoch 86, loss 0.44480618834495544, acc=0.8232777714729309, loss=0.44480618834495544
test: epoch 86, loss 1.0780858993530273, acc=0.6166666746139526, loss=1.0780858993530273
train: epoch 87, loss 0.4582333564758301, acc=0.8192777633666992, loss=0.4582333564758301
test: epoch 87, loss 1.3016799688339233, acc=0.5305555462837219, loss=1.3016799688339233
train: epoch 88, loss 0.44726788997650146, acc=0.8204444646835327, loss=0.44726788997650146
test: epoch 88, loss 1.2746152877807617, acc=0.4861111044883728, loss=1.2746152877807617
train: epoch 89, loss 0.44921380281448364, acc=0.8171666860580444, loss=0.44921380281448364
test: epoch 89, loss 1.1237549781799316, acc=0.5472221970558167, loss=1.1237549781799316
train: epoch 90, loss 0.4280398488044739, acc=0.8262222409248352, loss=0.4280398488044739
test: epoch 90, loss 1.4667507410049438, acc=0.5138888955116272, loss=1.4667507410049438
train: epoch 91, loss 0.44228073954582214, acc=0.8227221965789795, loss=0.44228073954582214
test: epoch 91, loss 0.9516769051551819, acc=0.6499999761581421, loss=0.9516769051551819
train: epoch 92, loss 0.43794211745262146, acc=0.8221666812896729, loss=0.43794211745262146
test: epoch 92, loss 1.0311509370803833, acc=0.5305555462837219, loss=1.0311509370803833
train: epoch 93, loss 0.453642874956131, acc=0.8102222084999084, loss=0.453642874956131
test: epoch 93, loss 1.48997163772583, acc=0.5027777552604675, loss=1.48997163772583
train: epoch 94, loss 0.43930718302726746, acc=0.820388913154602, loss=0.43930718302726746
test: epoch 94, loss 1.0392895936965942, acc=0.5861111283302307, loss=1.0392895936965942
train: epoch 95, loss 0.4346011281013489, acc=0.8249444365501404, loss=0.4346011281013489
test: epoch 95, loss 1.070709228515625, acc=0.5333333611488342, loss=1.070709228515625
train: epoch 96, loss 0.4236735999584198, acc=0.8287777900695801, loss=0.4236735999584198
test: epoch 96, loss 1.2081066370010376, acc=0.5888888835906982, loss=1.2081066370010376
train: epoch 97, loss 0.4757736027240753, acc=0.8136110901832581, loss=0.4757736027240753
test: epoch 97, loss 1.1007660627365112, acc=0.519444465637207, loss=1.1007660627365112
train: epoch 98, loss 0.4194275140762329, acc=0.8312222361564636, loss=0.4194275140762329
test: epoch 98, loss 1.0523110628128052, acc=0.6000000238418579, loss=1.0523110628128052
train: epoch 99, loss 0.46643131971359253, acc=0.8162222504615784, loss=0.46643131971359253
test: epoch 99, loss 1.002111792564392, acc=0.5972222089767456, loss=1.002111792564392
train: epoch 100, loss 0.43666133284568787, acc=0.828166663646698, loss=0.43666133284568787
test: epoch 100, loss 1.0078253746032715, acc=0.5694444179534912, loss=1.0078253746032715
train: epoch 101, loss 0.42852047085762024, acc=0.8333333134651184, loss=0.42852047085762024
test: epoch 101, loss 1.3491878509521484, acc=0.5416666865348816, loss=1.3491878509521484
train: epoch 102, loss 0.45452335476875305, acc=0.825166642665863, loss=0.45452335476875305
test: epoch 102, loss 1.124253749847412, acc=0.5777778029441833, loss=1.124253749847412
train: epoch 103, loss 0.43761664628982544, acc=0.8312222361564636, loss=0.43761664628982544
test: epoch 103, loss 1.3769738674163818, acc=0.5722222328186035, loss=1.3769738674163818
train: epoch 104, loss 0.4361380636692047, acc=0.8264444470405579, loss=0.4361380636692047
test: epoch 104, loss 1.1309114694595337, acc=0.5888888835906982, loss=1.1309114694595337
train: epoch 105, loss 0.4412572383880615, acc=0.8250555396080017, loss=0.4412572383880615
test: epoch 105, loss 1.135316014289856, acc=0.5611110925674438, loss=1.135316014289856
train: epoch 106, loss 0.43714362382888794, acc=0.8348333239555359, loss=0.43714362382888794
test: epoch 106, loss 1.036604642868042, acc=0.5833333134651184, loss=1.036604642868042
train: epoch 107, loss 0.4367005228996277, acc=0.8321666717529297, loss=0.4367005228996277
test: epoch 107, loss 1.0071964263916016, acc=0.5805555582046509, loss=1.0071964263916016
train: epoch 108, loss 0.43810343742370605, acc=0.831166684627533, loss=0.43810343742370605
test: epoch 108, loss 1.1976999044418335, acc=0.550000011920929, loss=1.1976999044418335
train: epoch 109, loss 0.43771278858184814, acc=0.8308333158493042, loss=0.43771278858184814
test: epoch 109, loss 1.1495258808135986, acc=0.5555555820465088, loss=1.1495258808135986
train: epoch 110, loss 0.4381159245967865, acc=0.8287222385406494, loss=0.4381159245967865
test: epoch 110, loss 1.1192388534545898, acc=0.5861111283302307, loss=1.1192388534545898
train: epoch 111, loss 0.44640398025512695, acc=0.8275555372238159, loss=0.44640398025512695
test: epoch 111, loss 1.0317816734313965, acc=0.5944444537162781, loss=1.0317816734313965
train: epoch 112, loss 0.4297696053981781, acc=0.832611083984375, loss=0.4297696053981781
test: epoch 112, loss 1.1722100973129272, acc=0.5444444417953491, loss=1.1722100973129272
train: epoch 113, loss 0.42753785848617554, acc=0.8367778062820435, loss=0.42753785848617554
test: epoch 113, loss 0.9171450734138489, acc=0.6472222208976746, loss=0.9171450734138489
train: epoch 114, loss 0.44764798879623413, acc=0.8270000219345093, loss=0.44764798879623413
test: epoch 114, loss 1.0799050331115723, acc=0.6166666746139526, loss=1.0799050331115723
train: epoch 115, loss 0.4422125220298767, acc=0.8277778029441833, loss=0.4422125220298767
test: epoch 115, loss 1.0456898212432861, acc=0.5833333134651184, loss=1.0456898212432861
train: epoch 116, loss 0.42834368348121643, acc=0.8364444375038147, loss=0.42834368348121643
test: epoch 116, loss 0.9399078488349915, acc=0.574999988079071, loss=0.9399078488349915
train: epoch 117, loss 0.4520156979560852, acc=0.8276110887527466, loss=0.4520156979560852
test: epoch 117, loss 0.9379530549049377, acc=0.5833333134651184, loss=0.9379530549049377
train: epoch 118, loss 0.43243730068206787, acc=0.8318889141082764, loss=0.43243730068206787
test: epoch 118, loss 1.0904502868652344, acc=0.574999988079071, loss=1.0904502868652344
train: epoch 119, loss 0.43053385615348816, acc=0.8330555558204651, loss=0.43053385615348816
test: epoch 119, loss 1.0163488388061523, acc=0.5833333134651184, loss=1.0163488388061523
train: epoch 120, loss 0.4121015667915344, acc=0.8414999842643738, loss=0.4121015667915344
test: epoch 120, loss 1.068674921989441, acc=0.5833333134651184, loss=1.068674921989441
train: epoch 121, loss 0.4498635530471802, acc=0.8234999775886536, loss=0.4498635530471802
test: epoch 121, loss 1.3102352619171143, acc=0.5666666626930237, loss=1.3102352619171143
train: epoch 122, loss 0.40254655480384827, acc=0.8455555438995361, loss=0.40254655480384827
test: epoch 122, loss 1.1078193187713623, acc=0.605555534362793, loss=1.1078193187713623
train: epoch 123, loss 0.4561976492404938, acc=0.8247222304344177, loss=0.4561976492404938
test: epoch 123, loss 0.9143999218940735, acc=0.574999988079071, loss=0.9143999218940735
train: epoch 124, loss 0.4153089225292206, acc=0.836722195148468, loss=0.4153089225292206
test: epoch 124, loss 1.076865553855896, acc=0.5805555582046509, loss=1.076865553855896
train: epoch 125, loss 0.4409518837928772, acc=0.8283888697624207, loss=0.4409518837928772
test: epoch 125, loss 1.4652411937713623, acc=0.519444465637207, loss=1.4652411937713623
train: epoch 126, loss 0.41632792353630066, acc=0.8398333191871643, loss=0.41632792353630066
test: epoch 126, loss 1.0681103467941284, acc=0.5944444537162781, loss=1.0681103467941284
train: epoch 127, loss 0.44367989897727966, acc=0.8247222304344177, loss=0.44367989897727966
test: epoch 127, loss 0.9402196407318115, acc=0.5888888835906982, loss=0.9402196407318115
train: epoch 128, loss 0.4241645336151123, acc=0.8316666483879089, loss=0.4241645336151123
test: epoch 128, loss 0.9344372153282166, acc=0.6083333492279053, loss=0.9344372153282166
train: epoch 129, loss 0.44100478291511536, acc=0.8282777667045593, loss=0.44100478291511536
test: epoch 129, loss 0.8882787227630615, acc=0.6111111044883728, loss=0.8882787227630615
train: epoch 130, loss 0.42571601271629333, acc=0.832111120223999, loss=0.42571601271629333
test: epoch 130, loss 1.2898597717285156, acc=0.5444444417953491, loss=1.2898597717285156
train: epoch 131, loss 0.40981119871139526, acc=0.8422222137451172, loss=0.40981119871139526
test: epoch 131, loss 0.9004849195480347, acc=0.6027777791023254, loss=0.9004849195480347
train: epoch 132, loss 0.42033302783966064, acc=0.8348333239555359, loss=0.42033302783966064
test: epoch 132, loss 1.0561890602111816, acc=0.5638889074325562, loss=1.0561890602111816
train: epoch 133, loss 0.4400020241737366, acc=0.8271666765213013, loss=0.4400020241737366
test: epoch 133, loss 1.2544212341308594, acc=0.6027777791023254, loss=1.2544212341308594
train: epoch 134, loss 0.4547138810157776, acc=0.8179444670677185, loss=0.4547138810157776
test: epoch 134, loss 0.883263349533081, acc=0.6083333492279053, loss=0.883263349533081
train: epoch 135, loss 0.42344170808792114, acc=0.8318889141082764, loss=0.42344170808792114
test: epoch 135, loss 0.9320505857467651, acc=0.574999988079071, loss=0.9320505857467651
train: epoch 136, loss 0.447424978017807, acc=0.8250555396080017, loss=0.447424978017807
test: epoch 136, loss 0.8347167372703552, acc=0.6027777791023254, loss=0.8347167372703552
train: epoch 137, loss 0.41377997398376465, acc=0.8396111130714417, loss=0.41377997398376465
test: epoch 137, loss 0.886993944644928, acc=0.5944444537162781, loss=0.886993944644928
train: epoch 138, loss 0.4341554343700409, acc=0.8297222256660461, loss=0.4341554343700409
test: epoch 138, loss 0.9252106547355652, acc=0.5916666388511658, loss=0.9252106547355652
train: epoch 139, loss 0.4291107654571533, acc=0.8304444551467896, loss=0.4291107654571533
test: epoch 139, loss 1.0356626510620117, acc=0.574999988079071, loss=1.0356626510620117
train: epoch 140, loss 0.44796043634414673, acc=0.8247222304344177, loss=0.44796043634414673
test: epoch 140, loss 0.8468407988548279, acc=0.6194444298744202, loss=0.8468407988548279
train: epoch 141, loss 0.43046411871910095, acc=0.82833331823349, loss=0.43046411871910095
test: epoch 141, loss 0.9044011831283569, acc=0.6611111164093018, loss=0.9044011831283569
train: epoch 142, loss 0.42482230067253113, acc=0.8294444680213928, loss=0.42482230067253113
test: epoch 142, loss 1.0934993028640747, acc=0.6083333492279053, loss=1.0934993028640747
train: epoch 143, loss 0.4202333986759186, acc=0.835444450378418, loss=0.4202333986759186
test: epoch 143, loss 0.8879426717758179, acc=0.6027777791023254, loss=0.8879426717758179
train: epoch 144, loss 0.4218461811542511, acc=0.8350555300712585, loss=0.4218461811542511
test: epoch 144, loss 0.9912219643592834, acc=0.6083333492279053, loss=0.9912219643592834
train: epoch 145, loss 0.4643074572086334, acc=0.8186110854148865, loss=0.4643074572086334
test: epoch 145, loss 0.9386159777641296, acc=0.6472222208976746, loss=0.9386159777641296
train: epoch 146, loss 0.4387306571006775, acc=0.8254444599151611, loss=0.4387306571006775
test: epoch 146, loss 1.1290473937988281, acc=0.5666666626930237, loss=1.1290473937988281
train: epoch 147, loss 0.40971285104751587, acc=0.8368333578109741, loss=0.40971285104751587
test: epoch 147, loss 1.0074599981307983, acc=0.605555534362793, loss=1.0074599981307983
train: epoch 148, loss 0.4457029104232788, acc=0.8222222328186035, loss=0.4457029104232788
test: epoch 148, loss 0.9119504690170288, acc=0.605555534362793, loss=0.9119504690170288
train: epoch 149, loss 0.44983768463134766, acc=0.8207777738571167, loss=0.44983768463134766
test: epoch 149, loss 0.9410778880119324, acc=0.5611110925674438, loss=0.9410778880119324
train: epoch 150, loss 0.4342760443687439, acc=0.8236666917800903, loss=0.4342760443687439
test: epoch 150, loss 0.9764197468757629, acc=0.5972222089767456, loss=0.9764197468757629
