# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=false", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=473428050, receiver_embed_dim=32, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.4129250049591064, acc=0.047833334654569626, loss=3.4129250049591064
test: epoch 1, loss 3.643583297729492, acc=0.06388889253139496, loss=3.643583297729492
train: epoch 2, loss 2.494691848754883, acc=0.16911111772060394, loss=2.494691848754883
test: epoch 2, loss 2.300710678100586, acc=0.16111111640930176, loss=2.300710678100586
train: epoch 3, loss 1.7950090169906616, acc=0.3111666738986969, loss=1.7950090169906616
test: epoch 3, loss 2.2565975189208984, acc=0.17777778208255768, loss=2.2565975189208984
train: epoch 4, loss 1.5884331464767456, acc=0.3680555522441864, loss=1.5884331464767456
test: epoch 4, loss 2.1023190021514893, acc=0.18333333730697632, loss=2.1023190021514893
train: epoch 5, loss 1.46248197555542, acc=0.417888879776001, loss=1.46248197555542
test: epoch 5, loss 2.18062162399292, acc=0.19166666269302368, loss=2.18062162399292
train: epoch 6, loss 1.3646413087844849, acc=0.45427778363227844, loss=1.3646413087844849
test: epoch 6, loss 2.121797800064087, acc=0.20555555820465088, loss=2.121797800064087
train: epoch 7, loss 1.2992323637008667, acc=0.47911110520362854, loss=1.2992323637008667
test: epoch 7, loss 2.160339832305908, acc=0.20000000298023224, loss=2.160339832305908
train: epoch 8, loss 1.2335318326950073, acc=0.5108888745307922, loss=1.2335318326950073
test: epoch 8, loss 2.0797946453094482, acc=0.1944444477558136, loss=2.0797946453094482
train: epoch 9, loss 1.1652107238769531, acc=0.5429444313049316, loss=1.1652107238769531
test: epoch 9, loss 2.1926722526550293, acc=0.20555555820465088, loss=2.1926722526550293
train: epoch 10, loss 1.1264210939407349, acc=0.5537222027778625, loss=1.1264210939407349
test: epoch 10, loss 2.1661674976348877, acc=0.19722221791744232, loss=2.1661674976348877
train: epoch 11, loss 1.0779809951782227, acc=0.5729444622993469, loss=1.0779809951782227
test: epoch 11, loss 2.1827473640441895, acc=0.19166666269302368, loss=2.1827473640441895
train: epoch 12, loss 1.0531045198440552, acc=0.5917778015136719, loss=1.0531045198440552
test: epoch 12, loss 2.113313674926758, acc=0.2222222238779068, loss=2.113313674926758
train: epoch 13, loss 1.0250526666641235, acc=0.6043888926506042, loss=1.0250526666641235
test: epoch 13, loss 2.2017710208892822, acc=0.21111111342906952, loss=2.2017710208892822
train: epoch 14, loss 0.9814308881759644, acc=0.6212777495384216, loss=0.9814308881759644
test: epoch 14, loss 2.048316240310669, acc=0.25555557012557983, loss=2.048316240310669
train: epoch 15, loss 0.9662511348724365, acc=0.6263889074325562, loss=0.9662511348724365
test: epoch 15, loss 2.059131622314453, acc=0.24166665971279144, loss=2.059131622314453
train: epoch 16, loss 0.9280588626861572, acc=0.6411666870117188, loss=0.9280588626861572
test: epoch 16, loss 1.9928070306777954, acc=0.24444444477558136, loss=1.9928070306777954
train: epoch 17, loss 0.9109851717948914, acc=0.6471111178398132, loss=0.9109851717948914
test: epoch 17, loss 2.038774251937866, acc=0.2666666805744171, loss=2.038774251937866
train: epoch 18, loss 0.8887082934379578, acc=0.6554444432258606, loss=0.8887082934379578
test: epoch 18, loss 1.884130597114563, acc=0.23888888955116272, loss=1.884130597114563
train: epoch 19, loss 0.8759992122650146, acc=0.6623888611793518, loss=0.8759992122650146
test: epoch 19, loss 2.0517706871032715, acc=0.2527777850627899, loss=2.0517706871032715
train: epoch 20, loss 0.8513824343681335, acc=0.6733888983726501, loss=0.8513824343681335
test: epoch 20, loss 2.039419651031494, acc=0.25555557012557983, loss=2.039419651031494
train: epoch 21, loss 0.8367880582809448, acc=0.6747778058052063, loss=0.8367880582809448
test: epoch 21, loss 1.8941220045089722, acc=0.25555557012557983, loss=1.8941220045089722
train: epoch 22, loss 0.8163146376609802, acc=0.6865000128746033, loss=0.8163146376609802
test: epoch 22, loss 1.8442518711090088, acc=0.2611111104488373, loss=1.8442518711090088
train: epoch 23, loss 0.8039358258247375, acc=0.6937777996063232, loss=0.8039358258247375
test: epoch 23, loss 1.8617055416107178, acc=0.2888889014720917, loss=1.8617055416107178
train: epoch 24, loss 0.7965840697288513, acc=0.6971666812896729, loss=0.7965840697288513
test: epoch 24, loss 1.7289905548095703, acc=0.2916666567325592, loss=1.7289905548095703
train: epoch 25, loss 0.7780680656433105, acc=0.7040555477142334, loss=0.7780680656433105
test: epoch 25, loss 1.702689290046692, acc=0.34166666865348816, loss=1.702689290046692
train: epoch 26, loss 0.7596851587295532, acc=0.7093889117240906, loss=0.7596851587295532
test: epoch 26, loss 1.885433316230774, acc=0.28611111640930176, loss=1.885433316230774
train: epoch 27, loss 0.7557772994041443, acc=0.7136666774749756, loss=0.7557772994041443
test: epoch 27, loss 1.7184524536132812, acc=0.2944444417953491, loss=1.7184524536132812
train: epoch 28, loss 0.741814374923706, acc=0.7221666574478149, loss=0.741814374923706
test: epoch 28, loss 1.6944063901901245, acc=0.31388887763023376, loss=1.6944063901901245
train: epoch 29, loss 0.7137051820755005, acc=0.7306666374206543, loss=0.7137051820755005
test: epoch 29, loss 1.7111531496047974, acc=0.32499998807907104, loss=1.7111531496047974
train: epoch 30, loss 0.7072828412055969, acc=0.7317222356796265, loss=0.7072828412055969
test: epoch 30, loss 1.6745929718017578, acc=0.31388887763023376, loss=1.6745929718017578
train: epoch 31, loss 0.6972514986991882, acc=0.7383333444595337, loss=0.6972514986991882
test: epoch 31, loss 1.8454475402832031, acc=0.28611111640930176, loss=1.8454475402832031
train: epoch 32, loss 0.6885844469070435, acc=0.7401666641235352, loss=0.6885844469070435
test: epoch 32, loss 1.7344619035720825, acc=0.31388887763023376, loss=1.7344619035720825
train: epoch 33, loss 0.6862598657608032, acc=0.7390000224113464, loss=0.6862598657608032
test: epoch 33, loss 1.5780701637268066, acc=0.3499999940395355, loss=1.5780701637268066
train: epoch 34, loss 0.6613684296607971, acc=0.7504444718360901, loss=0.6613684296607971
test: epoch 34, loss 1.5790135860443115, acc=0.33888888359069824, loss=1.5790135860443115
train: epoch 35, loss 0.6732848882675171, acc=0.7493888735771179, loss=0.6732848882675171
test: epoch 35, loss 1.6344279050827026, acc=0.32777777314186096, loss=1.6344279050827026
train: epoch 36, loss 0.6548081636428833, acc=0.7573333382606506, loss=0.6548081636428833
test: epoch 36, loss 1.625519871711731, acc=0.3472222089767456, loss=1.625519871711731
train: epoch 37, loss 0.6398499608039856, acc=0.757888913154602, loss=0.6398499608039856
test: epoch 37, loss 1.5423082113265991, acc=0.36944442987442017, loss=1.5423082113265991
train: epoch 38, loss 0.6313895583152771, acc=0.7619444727897644, loss=0.6313895583152771
test: epoch 38, loss 1.5162813663482666, acc=0.3583333194255829, loss=1.5162813663482666
train: epoch 39, loss 0.6161752939224243, acc=0.7664444446563721, loss=0.6161752939224243
test: epoch 39, loss 1.4997525215148926, acc=0.3861111104488373, loss=1.4997525215148926
train: epoch 40, loss 0.6212059259414673, acc=0.7680555582046509, loss=0.6212059259414673
test: epoch 40, loss 1.5622789859771729, acc=0.375, loss=1.5622789859771729
train: epoch 41, loss 0.6132712364196777, acc=0.7665555477142334, loss=0.6132712364196777
test: epoch 41, loss 1.4966546297073364, acc=0.4166666567325592, loss=1.4966546297073364
train: epoch 42, loss 0.5898771286010742, acc=0.7762777805328369, loss=0.5898771286010742
test: epoch 42, loss 1.5551035404205322, acc=0.38055557012557983, loss=1.5551035404205322
train: epoch 43, loss 0.5852360129356384, acc=0.7808889150619507, loss=0.5852360129356384
test: epoch 43, loss 1.583673119544983, acc=0.3777777850627899, loss=1.583673119544983
train: epoch 44, loss 0.5806387066841125, acc=0.7823888659477234, loss=0.5806387066841125
test: epoch 44, loss 1.3683288097381592, acc=0.39722222089767456, loss=1.3683288097381592
train: epoch 45, loss 0.5680366158485413, acc=0.7861111164093018, loss=0.5680366158485413
test: epoch 45, loss 1.4916954040527344, acc=0.36944442987442017, loss=1.4916954040527344
train: epoch 46, loss 0.5708613991737366, acc=0.7879999876022339, loss=0.5708613991737366
test: epoch 46, loss 1.3949522972106934, acc=0.4277777671813965, loss=1.3949522972106934
train: epoch 47, loss 0.5594114065170288, acc=0.7949444651603699, loss=0.5594114065170288
test: epoch 47, loss 1.4703067541122437, acc=0.3611111044883728, loss=1.4703067541122437
train: epoch 48, loss 0.554234504699707, acc=0.7931666374206543, loss=0.554234504699707
test: epoch 48, loss 1.4662089347839355, acc=0.40833333134651184, loss=1.4662089347839355
train: epoch 49, loss 0.5472193956375122, acc=0.7993333339691162, loss=0.5472193956375122
test: epoch 49, loss 1.3277685642242432, acc=0.4305555522441864, loss=1.3277685642242432
train: epoch 50, loss 0.5497446656227112, acc=0.7937777638435364, loss=0.5497446656227112
test: epoch 50, loss 1.4636518955230713, acc=0.3916666805744171, loss=1.4636518955230713
train: epoch 51, loss 0.5294702053070068, acc=0.8012222051620483, loss=0.5294702053070068
test: epoch 51, loss 1.6107523441314697, acc=0.38333332538604736, loss=1.6107523441314697
train: epoch 52, loss 0.5273017883300781, acc=0.8025555610656738, loss=0.5273017883300781
test: epoch 52, loss 1.5501536130905151, acc=0.3722222149372101, loss=1.5501536130905151
train: epoch 53, loss 0.5127993226051331, acc=0.8088333606719971, loss=0.5127993226051331
test: epoch 53, loss 1.4546411037445068, acc=0.4027777910232544, loss=1.4546411037445068
train: epoch 54, loss 0.5114961862564087, acc=0.8122777938842773, loss=0.5114961862564087
test: epoch 54, loss 1.4793630838394165, acc=0.42500001192092896, loss=1.4793630838394165
train: epoch 55, loss 0.500128984451294, acc=0.8100000023841858, loss=0.500128984451294
test: epoch 55, loss 1.4068224430084229, acc=0.42222222685813904, loss=1.4068224430084229
train: epoch 56, loss 0.48941442370414734, acc=0.82105553150177, loss=0.48941442370414734
test: epoch 56, loss 1.5501495599746704, acc=0.40833333134651184, loss=1.5501495599746704
train: epoch 57, loss 0.49497225880622864, acc=0.8156111240386963, loss=0.49497225880622864
test: epoch 57, loss 1.4012815952301025, acc=0.42222222685813904, loss=1.4012815952301025
train: epoch 58, loss 0.4968046545982361, acc=0.8199999928474426, loss=0.4968046545982361
test: epoch 58, loss 1.3714749813079834, acc=0.4277777671813965, loss=1.3714749813079834
train: epoch 59, loss 0.4841077923774719, acc=0.8219444155693054, loss=0.4841077923774719
test: epoch 59, loss 1.611415982246399, acc=0.4000000059604645, loss=1.611415982246399
train: epoch 60, loss 0.4813404977321625, acc=0.8215000033378601, loss=0.4813404977321625
test: epoch 60, loss 1.3391214609146118, acc=0.4472222328186035, loss=1.3391214609146118
train: epoch 61, loss 0.47381630539894104, acc=0.831333339214325, loss=0.47381630539894104
test: epoch 61, loss 1.4117437601089478, acc=0.40833333134651184, loss=1.4117437601089478
train: epoch 62, loss 0.4636411666870117, acc=0.8261111378669739, loss=0.4636411666870117
test: epoch 62, loss 1.4382091760635376, acc=0.3916666805744171, loss=1.4382091760635376
train: epoch 63, loss 0.46869584918022156, acc=0.8301666378974915, loss=0.46869584918022156
test: epoch 63, loss 1.3772550821304321, acc=0.4333333373069763, loss=1.3772550821304321
train: epoch 64, loss 0.44334790110588074, acc=0.8368333578109741, loss=0.44334790110588074
test: epoch 64, loss 1.4639919996261597, acc=0.46388888359069824, loss=1.4639919996261597
train: epoch 65, loss 0.4515177011489868, acc=0.8396111130714417, loss=0.4515177011489868
test: epoch 65, loss 1.4041922092437744, acc=0.4555555582046509, loss=1.4041922092437744
train: epoch 66, loss 0.44230347871780396, acc=0.8396666646003723, loss=0.44230347871780396
test: epoch 66, loss 1.3645727634429932, acc=0.46666666865348816, loss=1.3645727634429932
train: epoch 67, loss 0.43974238634109497, acc=0.8385555744171143, loss=0.43974238634109497
test: epoch 67, loss 1.408510446548462, acc=0.4694444537162781, loss=1.408510446548462
train: epoch 68, loss 0.42183148860931396, acc=0.8431666493415833, loss=0.42183148860931396
test: epoch 68, loss 1.4176377058029175, acc=0.4444444477558136, loss=1.4176377058029175
train: epoch 69, loss 0.43303608894348145, acc=0.842555582523346, loss=0.43303608894348145
test: epoch 69, loss 1.438834547996521, acc=0.4305555522441864, loss=1.438834547996521
train: epoch 70, loss 0.4281165599822998, acc=0.8458889126777649, loss=0.4281165599822998
test: epoch 70, loss 1.335916519165039, acc=0.44999998807907104, loss=1.335916519165039
train: epoch 71, loss 0.42114686965942383, acc=0.8476666808128357, loss=0.42114686965942383
test: epoch 71, loss 1.4005705118179321, acc=0.46666666865348816, loss=1.4005705118179321
train: epoch 72, loss 0.4204184412956238, acc=0.8495000004768372, loss=0.4204184412956238
test: epoch 72, loss 1.3522571325302124, acc=0.4694444537162781, loss=1.3522571325302124
train: epoch 73, loss 0.41776371002197266, acc=0.8485555648803711, loss=0.41776371002197266
test: epoch 73, loss 1.3001312017440796, acc=0.4972222149372101, loss=1.3001312017440796
train: epoch 74, loss 0.4094887971878052, acc=0.8499444723129272, loss=0.4094887971878052
test: epoch 74, loss 1.364259958267212, acc=0.4583333432674408, loss=1.364259958267212
train: epoch 75, loss 0.41671690344810486, acc=0.8444444537162781, loss=0.41671690344810486
test: epoch 75, loss 1.3366702795028687, acc=0.5055555701255798, loss=1.3366702795028687
train: epoch 76, loss 0.409791499376297, acc=0.8531666398048401, loss=0.409791499376297
test: epoch 76, loss 1.4612730741500854, acc=0.49444442987442017, loss=1.4612730741500854
train: epoch 77, loss 0.3970942795276642, acc=0.856166660785675, loss=0.3970942795276642
test: epoch 77, loss 1.3760968446731567, acc=0.4833333194255829, loss=1.3760968446731567
train: epoch 78, loss 0.3890035152435303, acc=0.8594444394111633, loss=0.3890035152435303
test: epoch 78, loss 1.2792716026306152, acc=0.519444465637207, loss=1.2792716026306152
train: epoch 79, loss 0.40146541595458984, acc=0.8573333621025085, loss=0.40146541595458984
test: epoch 79, loss 1.3888487815856934, acc=0.4749999940395355, loss=1.3888487815856934
train: epoch 80, loss 0.39458227157592773, acc=0.8571666479110718, loss=0.39458227157592773
test: epoch 80, loss 1.29096257686615, acc=0.4694444537162781, loss=1.29096257686615
train: epoch 81, loss 0.40228426456451416, acc=0.8539999723434448, loss=0.40228426456451416
test: epoch 81, loss 1.3213833570480347, acc=0.4749999940395355, loss=1.3213833570480347
train: epoch 82, loss 0.37927401065826416, acc=0.8615000247955322, loss=0.37927401065826416
test: epoch 82, loss 1.4003021717071533, acc=0.4833333194255829, loss=1.4003021717071533
train: epoch 83, loss 0.3752206861972809, acc=0.8643888831138611, loss=0.3752206861972809
test: epoch 83, loss 1.3156046867370605, acc=0.5361111164093018, loss=1.3156046867370605
train: epoch 84, loss 0.37836313247680664, acc=0.8674444556236267, loss=0.37836313247680664
test: epoch 84, loss 1.411995768547058, acc=0.4888888895511627, loss=1.411995768547058
train: epoch 85, loss 0.3816632628440857, acc=0.8638888597488403, loss=0.3816632628440857
test: epoch 85, loss 1.4004677534103394, acc=0.5166666507720947, loss=1.4004677534103394
train: epoch 86, loss 0.36765143275260925, acc=0.8676111102104187, loss=0.36765143275260925
test: epoch 86, loss 1.3041037321090698, acc=0.5249999761581421, loss=1.3041037321090698
train: epoch 87, loss 0.37082380056381226, acc=0.8667222261428833, loss=0.37082380056381226
test: epoch 87, loss 1.3879156112670898, acc=0.5166666507720947, loss=1.3879156112670898
train: epoch 88, loss 0.36455830931663513, acc=0.8694999814033508, loss=0.36455830931663513
test: epoch 88, loss 1.2923610210418701, acc=0.5527777671813965, loss=1.2923610210418701
train: epoch 89, loss 0.3778512477874756, acc=0.8627222180366516, loss=0.3778512477874756
test: epoch 89, loss 1.3316556215286255, acc=0.5333333611488342, loss=1.3316556215286255
train: epoch 90, loss 0.3696054518222809, acc=0.8671666383743286, loss=0.3696054518222809
test: epoch 90, loss 1.373567819595337, acc=0.5138888955116272, loss=1.373567819595337
train: epoch 91, loss 0.34856319427490234, acc=0.8721110820770264, loss=0.34856319427490234
test: epoch 91, loss 1.2642240524291992, acc=0.5444444417953491, loss=1.2642240524291992
train: epoch 92, loss 0.35438358783721924, acc=0.8723888993263245, loss=0.35438358783721924
test: epoch 92, loss 1.34844172000885, acc=0.5055555701255798, loss=1.34844172000885
train: epoch 93, loss 0.35016560554504395, acc=0.8728888630867004, loss=0.35016560554504395
test: epoch 93, loss 1.3560311794281006, acc=0.5472221970558167, loss=1.3560311794281006
train: epoch 94, loss 0.3501530885696411, acc=0.874666690826416, loss=0.3501530885696411
test: epoch 94, loss 1.2493232488632202, acc=0.5583333373069763, loss=1.2493232488632202
train: epoch 95, loss 0.35327619314193726, acc=0.8750555515289307, loss=0.35327619314193726
test: epoch 95, loss 1.2822338342666626, acc=0.574999988079071, loss=1.2822338342666626
train: epoch 96, loss 0.3478676676750183, acc=0.8737778067588806, loss=0.3478676676750183
test: epoch 96, loss 1.363106369972229, acc=0.5222222208976746, loss=1.363106369972229
train: epoch 97, loss 0.3551052212715149, acc=0.8763333559036255, loss=0.3551052212715149
test: epoch 97, loss 1.3042501211166382, acc=0.5333333611488342, loss=1.3042501211166382
train: epoch 98, loss 0.34826719760894775, acc=0.8764444589614868, loss=0.34826719760894775
test: epoch 98, loss 1.2997119426727295, acc=0.5527777671813965, loss=1.2997119426727295
train: epoch 99, loss 0.3494657874107361, acc=0.8790555596351624, loss=0.3494657874107361
test: epoch 99, loss 1.3381578922271729, acc=0.5027777552604675, loss=1.3381578922271729
train: epoch 100, loss 0.3544805943965912, acc=0.8745555281639099, loss=0.3544805943965912
test: epoch 100, loss 1.3799446821212769, acc=0.5388888716697693, loss=1.3799446821212769
train: epoch 101, loss 0.3338403105735779, acc=0.882611095905304, loss=0.3338403105735779
test: epoch 101, loss 1.2236407995224, acc=0.5833333134651184, loss=1.2236407995224
train: epoch 102, loss 0.33609727025032043, acc=0.8823333382606506, loss=0.33609727025032043
test: epoch 102, loss 1.273257851600647, acc=0.5805555582046509, loss=1.273257851600647
train: epoch 103, loss 0.3277930021286011, acc=0.882888913154602, loss=0.3277930021286011
test: epoch 103, loss 1.248310923576355, acc=0.5527777671813965, loss=1.248310923576355
train: epoch 104, loss 0.3308251202106476, acc=0.8823888897895813, loss=0.3308251202106476
test: epoch 104, loss 1.1905097961425781, acc=0.5444444417953491, loss=1.1905097961425781
train: epoch 105, loss 0.32918182015419006, acc=0.8876110911369324, loss=0.32918182015419006
test: epoch 105, loss 1.179137110710144, acc=0.5472221970558167, loss=1.179137110710144
train: epoch 106, loss 0.330199271440506, acc=0.88355553150177, loss=0.330199271440506
test: epoch 106, loss 1.2372596263885498, acc=0.5694444179534912, loss=1.2372596263885498
train: epoch 107, loss 0.3200537860393524, acc=0.8886111378669739, loss=0.3200537860393524
test: epoch 107, loss 1.1385380029678345, acc=0.6027777791023254, loss=1.1385380029678345
train: epoch 108, loss 0.3240063190460205, acc=0.8861111402511597, loss=0.3240063190460205
test: epoch 108, loss 1.1426429748535156, acc=0.5805555582046509, loss=1.1426429748535156
train: epoch 109, loss 0.3295624554157257, acc=0.8856111168861389, loss=0.3295624554157257
test: epoch 109, loss 0.9991112947463989, acc=0.6222222447395325, loss=0.9991112947463989
train: epoch 110, loss 0.3290483355522156, acc=0.8871111273765564, loss=0.3290483355522156
test: epoch 110, loss 1.1475732326507568, acc=0.5833333134651184, loss=1.1475732326507568
train: epoch 111, loss 0.3222760260105133, acc=0.8894444704055786, loss=0.3222760260105133
test: epoch 111, loss 1.105828046798706, acc=0.605555534362793, loss=1.105828046798706
train: epoch 112, loss 0.32448291778564453, acc=0.8848333358764648, loss=0.32448291778564453
test: epoch 112, loss 1.0548362731933594, acc=0.5888888835906982, loss=1.0548362731933594
train: epoch 113, loss 0.3181554675102234, acc=0.8907222151756287, loss=0.3181554675102234
test: epoch 113, loss 1.0309526920318604, acc=0.5972222089767456, loss=1.0309526920318604
train: epoch 114, loss 0.30796775221824646, acc=0.8910555839538574, loss=0.30796775221824646
test: epoch 114, loss 1.184019684791565, acc=0.6027777791023254, loss=1.184019684791565
train: epoch 115, loss 0.3245371878147125, acc=0.8896111249923706, loss=0.3245371878147125
test: epoch 115, loss 1.2672022581100464, acc=0.5805555582046509, loss=1.2672022581100464
train: epoch 116, loss 0.312774658203125, acc=0.8924999833106995, loss=0.312774658203125
test: epoch 116, loss 1.0386170148849487, acc=0.5833333134651184, loss=1.0386170148849487
train: epoch 117, loss 0.32002222537994385, acc=0.8930555582046509, loss=0.32002222537994385
test: epoch 117, loss 1.0529887676239014, acc=0.6333333253860474, loss=1.0529887676239014
train: epoch 118, loss 0.30789685249328613, acc=0.8940555453300476, loss=0.30789685249328613
test: epoch 118, loss 1.0639536380767822, acc=0.6222222447395325, loss=1.0639536380767822
train: epoch 119, loss 0.3149931728839874, acc=0.8918889164924622, loss=0.3149931728839874
test: epoch 119, loss 1.011765956878662, acc=0.6138888597488403, loss=1.011765956878662
train: epoch 120, loss 0.2975301146507263, acc=0.8966110944747925, loss=0.2975301146507263
test: epoch 120, loss 0.9757617115974426, acc=0.6472222208976746, loss=0.9757617115974426
train: epoch 121, loss 0.3080039918422699, acc=0.8933888673782349, loss=0.3080039918422699
test: epoch 121, loss 1.0766154527664185, acc=0.6388888955116272, loss=1.0766154527664185
train: epoch 122, loss 0.3090691864490509, acc=0.890666663646698, loss=0.3090691864490509
test: epoch 122, loss 1.008748173713684, acc=0.6305555701255798, loss=1.008748173713684
train: epoch 123, loss 0.31086236238479614, acc=0.890999972820282, loss=0.31086236238479614
test: epoch 123, loss 1.0969607830047607, acc=0.625, loss=1.0969607830047607
train: epoch 124, loss 0.29849743843078613, acc=0.8962777853012085, loss=0.29849743843078613
test: epoch 124, loss 0.979010820388794, acc=0.6361111402511597, loss=0.979010820388794
train: epoch 125, loss 0.3028692305088043, acc=0.8949999809265137, loss=0.3028692305088043
test: epoch 125, loss 0.9826163649559021, acc=0.6416666507720947, loss=0.9826163649559021
train: epoch 126, loss 0.29951485991477966, acc=0.8964999914169312, loss=0.29951485991477966
test: epoch 126, loss 0.9656860828399658, acc=0.6472222208976746, loss=0.9656860828399658
train: epoch 127, loss 0.298562228679657, acc=0.8967777490615845, loss=0.298562228679657
test: epoch 127, loss 0.998884916305542, acc=0.6527777910232544, loss=0.998884916305542
train: epoch 128, loss 0.2888266444206238, acc=0.8981666564941406, loss=0.2888266444206238
test: epoch 128, loss 1.0241036415100098, acc=0.6305555701255798, loss=1.0241036415100098
train: epoch 129, loss 0.2955555319786072, acc=0.899222195148468, loss=0.2955555319786072
test: epoch 129, loss 0.9700066447257996, acc=0.6166666746139526, loss=0.9700066447257996
train: epoch 130, loss 0.2961144745349884, acc=0.89811110496521, loss=0.2961144745349884
test: epoch 130, loss 0.9022379517555237, acc=0.6583333611488342, loss=0.9022379517555237
train: epoch 131, loss 0.29813310503959656, acc=0.8984444737434387, loss=0.29813310503959656
test: epoch 131, loss 0.9072489738464355, acc=0.6583333611488342, loss=0.9072489738464355
train: epoch 132, loss 0.2900383770465851, acc=0.9023333191871643, loss=0.2900383770465851
test: epoch 132, loss 0.904402494430542, acc=0.6499999761581421, loss=0.904402494430542
train: epoch 133, loss 0.2821159362792969, acc=0.8994444608688354, loss=0.2821159362792969
test: epoch 133, loss 0.8037389516830444, acc=0.6777777671813965, loss=0.8037389516830444
train: epoch 134, loss 0.28077834844589233, acc=0.9019444584846497, loss=0.28077834844589233
test: epoch 134, loss 0.8199565410614014, acc=0.6555555462837219, loss=0.8199565410614014
train: epoch 135, loss 0.28308847546577454, acc=0.9049444198608398, loss=0.28308847546577454
test: epoch 135, loss 0.8862314224243164, acc=0.644444465637207, loss=0.8862314224243164
train: epoch 136, loss 0.2819962501525879, acc=0.9018333554267883, loss=0.2819962501525879
test: epoch 136, loss 0.9402071833610535, acc=0.644444465637207, loss=0.9402071833610535
train: epoch 137, loss 0.2868644893169403, acc=0.8986666798591614, loss=0.2868644893169403
test: epoch 137, loss 0.9072049856185913, acc=0.6888889074325562, loss=0.9072049856185913
train: epoch 138, loss 0.2945094406604767, acc=0.9026111364364624, loss=0.2945094406604767
test: epoch 138, loss 0.8755588531494141, acc=0.6499999761581421, loss=0.8755588531494141
train: epoch 139, loss 0.2767559587955475, acc=0.9037777781486511, loss=0.2767559587955475
test: epoch 139, loss 0.9311015009880066, acc=0.6611111164093018, loss=0.9311015009880066
train: epoch 140, loss 0.2744140625, acc=0.9053888916969299, loss=0.2744140625
test: epoch 140, loss 0.8191307187080383, acc=0.6499999761581421, loss=0.8191307187080383
train: epoch 141, loss 0.2799327075481415, acc=0.9045555591583252, loss=0.2799327075481415
test: epoch 141, loss 0.8904587030410767, acc=0.6638888716697693, loss=0.8904587030410767
train: epoch 142, loss 0.26920145750045776, acc=0.9062777757644653, loss=0.26920145750045776
test: epoch 142, loss 0.8571365475654602, acc=0.6638888716697693, loss=0.8571365475654602
train: epoch 143, loss 0.28050515055656433, acc=0.9057222008705139, loss=0.28050515055656433
test: epoch 143, loss 0.9013086557388306, acc=0.6555555462837219, loss=0.9013086557388306
train: epoch 144, loss 0.2693851590156555, acc=0.9048888683319092, loss=0.2693851590156555
test: epoch 144, loss 0.7662155628204346, acc=0.699999988079071, loss=0.7662155628204346
train: epoch 145, loss 0.2638587951660156, acc=0.9096111059188843, loss=0.2638587951660156
test: epoch 145, loss 0.8556614518165588, acc=0.6916666626930237, loss=0.8556614518165588
train: epoch 146, loss 0.25675877928733826, acc=0.9108333587646484, loss=0.25675877928733826
test: epoch 146, loss 0.8523076772689819, acc=0.6861110925674438, loss=0.8523076772689819
train: epoch 147, loss 0.2692019045352936, acc=0.9099444150924683, loss=0.2692019045352936
test: epoch 147, loss 0.918351411819458, acc=0.6611111164093018, loss=0.918351411819458
train: epoch 148, loss 0.2573450803756714, acc=0.9143333435058594, loss=0.2573450803756714
test: epoch 148, loss 0.9625595211982727, acc=0.6777777671813965, loss=0.9625595211982727
train: epoch 149, loss 0.23864175379276276, acc=0.9159444570541382, loss=0.23864175379276276
test: epoch 149, loss 0.9716289043426514, acc=0.6805555820465088, loss=0.9716289043426514
train: epoch 150, loss 0.25863808393478394, acc=0.9107221961021423, loss=0.25863808393478394
test: epoch 150, loss 0.8431082963943481, acc=0.675000011920929, loss=0.8431082963943481
