# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=0.99", "--one_hot=true", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1175552607, receiver_embed_dim=32, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.0109643936157227, acc=0.08361110836267471, loss=3.0109643936157227
test: epoch 1, loss 5.271905422210693, acc=0.04722222313284874, loss=5.271905422210693
train: epoch 2, loss 1.9892452955245972, acc=0.24205555021762848, loss=1.9892452955245972
test: epoch 2, loss 5.055736541748047, acc=0.08888889104127884, loss=5.055736541748047
train: epoch 3, loss 1.6815458536148071, acc=0.32677778601646423, loss=1.6815458536148071
test: epoch 3, loss 4.7319440841674805, acc=0.11666666716337204, loss=4.7319440841674805
train: epoch 4, loss 1.5119400024414062, acc=0.36933332681655884, loss=1.5119400024414062
test: epoch 4, loss 4.263726234436035, acc=0.15555556118488312, loss=4.263726234436035
train: epoch 5, loss 1.3753329515457153, acc=0.4094444513320923, loss=1.3753329515457153
test: epoch 5, loss 4.563541889190674, acc=0.12777778506278992, loss=4.563541889190674
train: epoch 6, loss 1.234427571296692, acc=0.48216667771339417, loss=1.234427571296692
test: epoch 6, loss 5.475471019744873, acc=0.1388888955116272, loss=5.475471019744873
train: epoch 7, loss 0.9748642444610596, acc=0.5972222089767456, loss=0.9748642444610596
test: epoch 7, loss 4.208608627319336, acc=0.20277777314186096, loss=4.208608627319336
train: epoch 8, loss 0.8737267255783081, acc=0.6354444622993469, loss=0.8737267255783081
test: epoch 8, loss 3.8711917400360107, acc=0.19722221791744232, loss=3.8711917400360107
train: epoch 9, loss 0.7774268388748169, acc=0.6766666769981384, loss=0.7774268388748169
test: epoch 9, loss 3.952712059020996, acc=0.20000000298023224, loss=3.952712059020996
train: epoch 10, loss 0.7012897729873657, acc=0.7179999947547913, loss=0.7012897729873657
test: epoch 10, loss 3.3764584064483643, acc=0.24444444477558136, loss=3.3764584064483643
train: epoch 11, loss 0.6074780821800232, acc=0.7563333511352539, loss=0.6074780821800232
test: epoch 11, loss 2.7204484939575195, acc=0.30000001192092896, loss=2.7204484939575195
train: epoch 12, loss 0.5749672055244446, acc=0.7693333625793457, loss=0.5749672055244446
test: epoch 12, loss 2.6042511463165283, acc=0.2916666567325592, loss=2.6042511463165283
train: epoch 13, loss 0.5277469158172607, acc=0.7856666445732117, loss=0.5277469158172607
test: epoch 13, loss 2.719313144683838, acc=0.2916666567325592, loss=2.719313144683838
train: epoch 14, loss 0.5013337731361389, acc=0.7990000247955322, loss=0.5013337731361389
test: epoch 14, loss 2.9822659492492676, acc=0.25555557012557983, loss=2.9822659492492676
train: epoch 15, loss 0.4859367609024048, acc=0.8028888702392578, loss=0.4859367609024048
test: epoch 15, loss 2.759453535079956, acc=0.24166665971279144, loss=2.759453535079956
train: epoch 16, loss 0.4626879096031189, acc=0.8179444670677185, loss=0.4626879096031189
test: epoch 16, loss 2.333545207977295, acc=0.2666666805744171, loss=2.333545207977295
train: epoch 17, loss 0.4331008195877075, acc=0.8264444470405579, loss=0.4331008195877075
test: epoch 17, loss 2.313915967941284, acc=0.3055555522441864, loss=2.313915967941284
train: epoch 18, loss 0.42061445116996765, acc=0.8296111226081848, loss=0.42061445116996765
test: epoch 18, loss 2.4705727100372314, acc=0.2638888955116272, loss=2.4705727100372314
train: epoch 19, loss 0.4157181978225708, acc=0.8341666460037231, loss=0.4157181978225708
test: epoch 19, loss 1.9766013622283936, acc=0.3333333432674408, loss=1.9766013622283936
train: epoch 20, loss 0.3989108204841614, acc=0.835444450378418, loss=0.3989108204841614
test: epoch 20, loss 2.4023067951202393, acc=0.29722222685813904, loss=2.4023067951202393
train: epoch 21, loss 0.40264320373535156, acc=0.8343889117240906, loss=0.40264320373535156
test: epoch 21, loss 2.337736129760742, acc=0.3472222089767456, loss=2.337736129760742
train: epoch 22, loss 0.37854570150375366, acc=0.8451666831970215, loss=0.37854570150375366
test: epoch 22, loss 1.9364495277404785, acc=0.31111112236976624, loss=1.9364495277404785
train: epoch 23, loss 0.371914803981781, acc=0.8495000004768372, loss=0.371914803981781
test: epoch 23, loss 2.07149076461792, acc=0.3361110985279083, loss=2.07149076461792
train: epoch 24, loss 0.3757838308811188, acc=0.8460000157356262, loss=0.3757838308811188
test: epoch 24, loss 1.8636069297790527, acc=0.3361110985279083, loss=1.8636069297790527
train: epoch 25, loss 0.3604748249053955, acc=0.8484444618225098, loss=0.3604748249053955
test: epoch 25, loss 1.864410400390625, acc=0.3916666805744171, loss=1.864410400390625
train: epoch 26, loss 0.36346811056137085, acc=0.8499444723129272, loss=0.36346811056137085
test: epoch 26, loss 2.0450358390808105, acc=0.33888888359069824, loss=2.0450358390808105
train: epoch 27, loss 0.3704216778278351, acc=0.850777804851532, loss=0.3704216778278351
test: epoch 27, loss 2.4047417640686035, acc=0.35277777910232544, loss=2.4047417640686035
train: epoch 28, loss 0.35962149500846863, acc=0.8534444570541382, loss=0.35962149500846863
test: epoch 28, loss 1.7895913124084473, acc=0.32777777314186096, loss=1.7895913124084473
train: epoch 29, loss 0.352350652217865, acc=0.856333315372467, loss=0.352350652217865
test: epoch 29, loss 1.847087025642395, acc=0.3194444477558136, loss=1.847087025642395
train: epoch 30, loss 0.359142005443573, acc=0.8541111350059509, loss=0.359142005443573
test: epoch 30, loss 1.8281890153884888, acc=0.33888888359069824, loss=1.8281890153884888
train: epoch 31, loss 0.3402688503265381, acc=0.856166660785675, loss=0.3402688503265381
test: epoch 31, loss 1.6311304569244385, acc=0.3722222149372101, loss=1.6311304569244385
train: epoch 32, loss 0.3510732054710388, acc=0.8575555682182312, loss=0.3510732054710388
test: epoch 32, loss 1.755317211151123, acc=0.3916666805744171, loss=1.755317211151123
train: epoch 33, loss 0.3420999050140381, acc=0.8585555553436279, loss=0.3420999050140381
test: epoch 33, loss 1.7388581037521362, acc=0.3472222089767456, loss=1.7388581037521362
train: epoch 34, loss 0.3425602316856384, acc=0.8583889007568359, loss=0.3425602316856384
test: epoch 34, loss 1.5123530626296997, acc=0.4166666567325592, loss=1.5123530626296997
train: epoch 35, loss 0.3467978239059448, acc=0.8551666736602783, loss=0.3467978239059448
test: epoch 35, loss 2.132098436355591, acc=0.3222222328186035, loss=2.132098436355591
train: epoch 36, loss 0.32891449332237244, acc=0.8650000095367432, loss=0.32891449332237244
test: epoch 36, loss 1.9233962297439575, acc=0.3722222149372101, loss=1.9233962297439575
train: epoch 37, loss 0.3429969847202301, acc=0.859000027179718, loss=0.3429969847202301
test: epoch 37, loss 1.8336786031723022, acc=0.38055557012557983, loss=1.8336786031723022
train: epoch 38, loss 0.34185144305229187, acc=0.8601666688919067, loss=0.34185144305229187
test: epoch 38, loss 1.9073095321655273, acc=0.39722222089767456, loss=1.9073095321655273
train: epoch 39, loss 0.3344491720199585, acc=0.8571110963821411, loss=0.3344491720199585
test: epoch 39, loss 1.7494454383850098, acc=0.4305555522441864, loss=1.7494454383850098
train: epoch 40, loss 0.3357371389865875, acc=0.8574444651603699, loss=0.3357371389865875
test: epoch 40, loss 1.9501760005950928, acc=0.3861111104488373, loss=1.9501760005950928
train: epoch 41, loss 0.32590317726135254, acc=0.8646666407585144, loss=0.32590317726135254
test: epoch 41, loss 1.8496626615524292, acc=0.3916666805744171, loss=1.8496626615524292
train: epoch 42, loss 0.3425176739692688, acc=0.8566666841506958, loss=0.3425176739692688
test: epoch 42, loss 1.5337399244308472, acc=0.3888888955116272, loss=1.5337399244308472
train: epoch 43, loss 0.323578417301178, acc=0.8642222285270691, loss=0.323578417301178
test: epoch 43, loss 1.7180824279785156, acc=0.4277777671813965, loss=1.7180824279785156
train: epoch 44, loss 0.3323630690574646, acc=0.862500011920929, loss=0.3323630690574646
test: epoch 44, loss 1.733335018157959, acc=0.4444444477558136, loss=1.733335018157959
train: epoch 45, loss 0.3192235231399536, acc=0.8646666407585144, loss=0.3192235231399536
test: epoch 45, loss 1.6760808229446411, acc=0.39722222089767456, loss=1.6760808229446411
train: epoch 46, loss 0.32344579696655273, acc=0.8627222180366516, loss=0.32344579696655273
test: epoch 46, loss 1.6261956691741943, acc=0.39722222089767456, loss=1.6261956691741943
train: epoch 47, loss 0.32894864678382874, acc=0.8642777800559998, loss=0.32894864678382874
test: epoch 47, loss 1.8571733236312866, acc=0.3888888955116272, loss=1.8571733236312866
train: epoch 48, loss 0.3430593013763428, acc=0.8608333468437195, loss=0.3430593013763428
test: epoch 48, loss 1.7393558025360107, acc=0.4277777671813965, loss=1.7393558025360107
train: epoch 49, loss 0.3269128203392029, acc=0.8612777590751648, loss=0.3269128203392029
test: epoch 49, loss 1.4463926553726196, acc=0.49444442987442017, loss=1.4463926553726196
train: epoch 50, loss 0.3110294044017792, acc=0.8709444403648376, loss=0.3110294044017792
test: epoch 50, loss 1.8381893634796143, acc=0.4555555582046509, loss=1.8381893634796143
train: epoch 51, loss 0.32286539673805237, acc=0.8704444169998169, loss=0.32286539673805237
test: epoch 51, loss 1.8410563468933105, acc=0.34166666865348816, loss=1.8410563468933105
train: epoch 52, loss 0.3137263357639313, acc=0.8702777624130249, loss=0.3137263357639313
test: epoch 52, loss 1.3420066833496094, acc=0.5138888955116272, loss=1.3420066833496094
train: epoch 53, loss 0.2979957163333893, acc=0.8777777552604675, loss=0.2979957163333893
test: epoch 53, loss 1.5338445901870728, acc=0.4888888895511627, loss=1.5338445901870728
train: epoch 54, loss 0.32430094480514526, acc=0.871666669845581, loss=0.32430094480514526
test: epoch 54, loss 1.4720449447631836, acc=0.4583333432674408, loss=1.4720449447631836
train: epoch 55, loss 0.30841195583343506, acc=0.8787222504615784, loss=0.30841195583343506
test: epoch 55, loss 1.441137433052063, acc=0.4472222328186035, loss=1.441137433052063
train: epoch 56, loss 0.3084268271923065, acc=0.887333333492279, loss=0.3084268271923065
test: epoch 56, loss 1.8948537111282349, acc=0.4583333432674408, loss=1.8948537111282349
train: epoch 57, loss 0.3058566451072693, acc=0.8871111273765564, loss=0.3058566451072693
test: epoch 57, loss 1.3254708051681519, acc=0.4861111044883728, loss=1.3254708051681519
train: epoch 58, loss 0.2939932346343994, acc=0.8952222466468811, loss=0.2939932346343994
test: epoch 58, loss 1.3448781967163086, acc=0.5027777552604675, loss=1.3448781967163086
train: epoch 59, loss 0.27509164810180664, acc=0.906166672706604, loss=0.27509164810180664
test: epoch 59, loss 1.2515478134155273, acc=0.5111111402511597, loss=1.2515478134155273
train: epoch 60, loss 0.28239405155181885, acc=0.9053333401679993, loss=0.28239405155181885
test: epoch 60, loss 1.5737909078598022, acc=0.47777777910232544, loss=1.5737909078598022
train: epoch 61, loss 0.29152029752731323, acc=0.9009444713592529, loss=0.29152029752731323
test: epoch 61, loss 1.1828067302703857, acc=0.5055555701255798, loss=1.1828067302703857
train: epoch 62, loss 0.2560994327068329, acc=0.9133889079093933, loss=0.2560994327068329
test: epoch 62, loss 1.1547930240631104, acc=0.5638889074325562, loss=1.1547930240631104
train: epoch 63, loss 0.25450024008750916, acc=0.9140555262565613, loss=0.25450024008750916
test: epoch 63, loss 1.3668303489685059, acc=0.5416666865348816, loss=1.3668303489685059
train: epoch 64, loss 0.26896509528160095, acc=0.9113333225250244, loss=0.26896509528160095
test: epoch 64, loss 2.266429901123047, acc=0.4749999940395355, loss=2.266429901123047
train: epoch 65, loss 0.2597131133079529, acc=0.9122222065925598, loss=0.2597131133079529
test: epoch 65, loss 1.2395142316818237, acc=0.5944444537162781, loss=1.2395142316818237
train: epoch 66, loss 0.27137359976768494, acc=0.9066666960716248, loss=0.27137359976768494
test: epoch 66, loss 1.4665144681930542, acc=0.49444442987442017, loss=1.4665144681930542
train: epoch 67, loss 0.25481972098350525, acc=0.9157778024673462, loss=0.25481972098350525
test: epoch 67, loss 1.509943962097168, acc=0.4972222149372101, loss=1.509943962097168
train: epoch 68, loss 0.24727743864059448, acc=0.9158889055252075, loss=0.24727743864059448
test: epoch 68, loss 1.5319687128067017, acc=0.5083333253860474, loss=1.5319687128067017
train: epoch 69, loss 0.25986021757125854, acc=0.913277804851532, loss=0.25986021757125854
test: epoch 69, loss 1.2194193601608276, acc=0.5722222328186035, loss=1.2194193601608276
train: epoch 70, loss 0.23935289680957794, acc=0.918055534362793, loss=0.23935289680957794
test: epoch 70, loss 1.0225543975830078, acc=0.5666666626930237, loss=1.0225543975830078
train: epoch 71, loss 0.23851387202739716, acc=0.9224444627761841, loss=0.23851387202739716
test: epoch 71, loss 1.0116537809371948, acc=0.6583333611488342, loss=1.0116537809371948
train: epoch 72, loss 0.2658165991306305, acc=0.9115555286407471, loss=0.2658165991306305
test: epoch 72, loss 1.2132625579833984, acc=0.574999988079071, loss=1.2132625579833984
train: epoch 73, loss 0.2447652667760849, acc=0.9190000295639038, loss=0.2447652667760849
test: epoch 73, loss 1.0481728315353394, acc=0.6472222208976746, loss=1.0481728315353394
train: epoch 74, loss 0.2534025311470032, acc=0.9129999876022339, loss=0.2534025311470032
test: epoch 74, loss 1.1450988054275513, acc=0.6027777791023254, loss=1.1450988054275513
train: epoch 75, loss 0.26019078493118286, acc=0.9150555729866028, loss=0.26019078493118286
test: epoch 75, loss 1.302579641342163, acc=0.6305555701255798, loss=1.302579641342163
train: epoch 76, loss 0.2221066653728485, acc=0.9254999756813049, loss=0.2221066653728485
test: epoch 76, loss 0.9442993402481079, acc=0.6472222208976746, loss=0.9442993402481079
train: epoch 77, loss 0.23773567378520966, acc=0.9201666712760925, loss=0.23773567378520966
test: epoch 77, loss 0.8380065560340881, acc=0.7250000238418579, loss=0.8380065560340881
train: epoch 78, loss 0.23595230281352997, acc=0.9215555787086487, loss=0.23595230281352997
test: epoch 78, loss 1.1943975687026978, acc=0.6861110925674438, loss=1.1943975687026978
train: epoch 79, loss 0.23826012015342712, acc=0.9240555763244629, loss=0.23826012015342712
test: epoch 79, loss 1.0532174110412598, acc=0.6555555462837219, loss=1.0532174110412598
train: epoch 80, loss 0.23384349048137665, acc=0.9255555272102356, loss=0.23384349048137665
test: epoch 80, loss 0.7083067297935486, acc=0.7250000238418579, loss=0.7083067297935486
train: epoch 81, loss 0.2414274364709854, acc=0.9191666841506958, loss=0.2414274364709854
test: epoch 81, loss 0.9121735095977783, acc=0.6916666626930237, loss=0.9121735095977783
train: epoch 82, loss 0.21783596277236938, acc=0.9297778010368347, loss=0.21783596277236938
test: epoch 82, loss 0.7698906064033508, acc=0.7444444298744202, loss=0.7698906064033508
train: epoch 83, loss 0.24336585402488708, acc=0.920722246170044, loss=0.24336585402488708
test: epoch 83, loss 0.5930622816085815, acc=0.7222222089767456, loss=0.5930622816085815
train: epoch 84, loss 0.2306818664073944, acc=0.9219444394111633, loss=0.2306818664073944
test: epoch 84, loss 0.58437180519104, acc=0.7749999761581421, loss=0.58437180519104
train: epoch 85, loss 0.20310157537460327, acc=0.9309444427490234, loss=0.20310157537460327
test: epoch 85, loss 0.6503462195396423, acc=0.7444444298744202, loss=0.6503462195396423
train: epoch 86, loss 0.21002639830112457, acc=0.9308888912200928, loss=0.21002639830112457
test: epoch 86, loss 0.71065354347229, acc=0.7638888955116272, loss=0.71065354347229
train: epoch 87, loss 0.20834487676620483, acc=0.9309444427490234, loss=0.20834487676620483
test: epoch 87, loss 0.5762782096862793, acc=0.7888888716697693, loss=0.5762782096862793
train: epoch 88, loss 0.21046800911426544, acc=0.9336110949516296, loss=0.21046800911426544
test: epoch 88, loss 0.5587558746337891, acc=0.8194444179534912, loss=0.5587558746337891
train: epoch 89, loss 0.18763436377048492, acc=0.9377222061157227, loss=0.18763436377048492
test: epoch 89, loss 0.426414430141449, acc=0.8222222328186035, loss=0.426414430141449
train: epoch 90, loss 0.20013166964054108, acc=0.9357777833938599, loss=0.20013166964054108
test: epoch 90, loss 0.48521679639816284, acc=0.8194444179534912, loss=0.48521679639816284
train: epoch 91, loss 0.17792311310768127, acc=0.9409444332122803, loss=0.17792311310768127
test: epoch 91, loss 0.4618789851665497, acc=0.7888888716697693, loss=0.4618789851665497
train: epoch 92, loss 0.17586158215999603, acc=0.940666675567627, loss=0.17586158215999603
test: epoch 92, loss 0.4823760688304901, acc=0.8388888835906982, loss=0.4823760688304901
train: epoch 93, loss 0.202269047498703, acc=0.9337777495384216, loss=0.202269047498703
test: epoch 93, loss 0.49892836809158325, acc=0.8194444179534912, loss=0.49892836809158325
train: epoch 94, loss 0.19465813040733337, acc=0.9369444251060486, loss=0.19465813040733337
test: epoch 94, loss 0.3853643834590912, acc=0.8611111044883728, loss=0.3853643834590912
train: epoch 95, loss 0.17434312403202057, acc=0.9436110854148865, loss=0.17434312403202057
test: epoch 95, loss 0.5146777629852295, acc=0.8583333492279053, loss=0.5146777629852295
train: epoch 96, loss 0.15804414451122284, acc=0.9475555419921875, loss=0.15804414451122284
test: epoch 96, loss 0.3490656316280365, acc=0.8666666746139526, loss=0.3490656316280365
train: epoch 97, loss 0.16711731255054474, acc=0.9449999928474426, loss=0.16711731255054474
test: epoch 97, loss 0.4123131036758423, acc=0.8777777552604675, loss=0.4123131036758423
train: epoch 98, loss 0.16376997530460358, acc=0.9437777996063232, loss=0.16376997530460358
test: epoch 98, loss 0.46703454852104187, acc=0.8694444298744202, loss=0.46703454852104187
train: epoch 99, loss 0.16398395597934723, acc=0.9449999928474426, loss=0.16398395597934723
test: epoch 99, loss 0.3672398626804352, acc=0.875, loss=0.3672398626804352
train: epoch 100, loss 0.16071848571300507, acc=0.9459999799728394, loss=0.16071848571300507
test: epoch 100, loss 0.29076412320137024, acc=0.8972222208976746, loss=0.29076412320137024
train: epoch 101, loss 0.14468716084957123, acc=0.9506111145019531, loss=0.14468716084957123
test: epoch 101, loss 0.39784035086631775, acc=0.8833333253860474, loss=0.39784035086631775
train: epoch 102, loss 0.1512720286846161, acc=0.9465555548667908, loss=0.1512720286846161
test: epoch 102, loss 0.31193187832832336, acc=0.9027777910232544, loss=0.31193187832832336
train: epoch 103, loss 0.1378822773694992, acc=0.9527778029441833, loss=0.1378822773694992
test: epoch 103, loss 0.307239294052124, acc=0.8916666507720947, loss=0.307239294052124
train: epoch 104, loss 0.1422571986913681, acc=0.953166663646698, loss=0.1422571986913681
test: epoch 104, loss 0.3114713430404663, acc=0.894444465637207, loss=0.3114713430404663
train: epoch 105, loss 0.12956035137176514, acc=0.9564444422721863, loss=0.12956035137176514
test: epoch 105, loss 0.27504169940948486, acc=0.894444465637207, loss=0.27504169940948486
train: epoch 106, loss 0.1271262764930725, acc=0.9570555686950684, loss=0.1271262764930725
test: epoch 106, loss 0.25962287187576294, acc=0.9027777910232544, loss=0.25962287187576294
train: epoch 107, loss 0.14770559966564178, acc=0.953166663646698, loss=0.14770559966564178
test: epoch 107, loss 0.2851126790046692, acc=0.8972222208976746, loss=0.2851126790046692
train: epoch 108, loss 0.12288013100624084, acc=0.9590555429458618, loss=0.12288013100624084
test: epoch 108, loss 0.2868674695491791, acc=0.894444465637207, loss=0.2868674695491791
train: epoch 109, loss 0.12364107370376587, acc=0.9573333263397217, loss=0.12364107370376587
test: epoch 109, loss 0.2791961133480072, acc=0.9055555462837219, loss=0.2791961133480072
train: epoch 110, loss 0.12701387703418732, acc=0.956166684627533, loss=0.12701387703418732
test: epoch 110, loss 0.31896787881851196, acc=0.8972222208976746, loss=0.31896787881851196
train: epoch 111, loss 0.11221940070390701, acc=0.9626111388206482, loss=0.11221940070390701
test: epoch 111, loss 0.2222069650888443, acc=0.8777777552604675, loss=0.2222069650888443
train: epoch 112, loss 0.11328595131635666, acc=0.9608888626098633, loss=0.11328595131635666
test: epoch 112, loss 0.28296196460723877, acc=0.9027777910232544, loss=0.28296196460723877
train: epoch 113, loss 0.13185429573059082, acc=0.9598888754844666, loss=0.13185429573059082
test: epoch 113, loss 0.3008606731891632, acc=0.9055555462837219, loss=0.3008606731891632
train: epoch 114, loss 0.11215825378894806, acc=0.9610000252723694, loss=0.11215825378894806
test: epoch 114, loss 0.24748541414737701, acc=0.9027777910232544, loss=0.24748541414737701
train: epoch 115, loss 0.10363145917654037, acc=0.9655555486679077, loss=0.10363145917654037
test: epoch 115, loss 0.23604372143745422, acc=0.9083333611488342, loss=0.23604372143745422
train: epoch 116, loss 0.10904821753501892, acc=0.9627222418785095, loss=0.10904821753501892
test: epoch 116, loss 0.255303293466568, acc=0.9138888716697693, loss=0.255303293466568
train: epoch 117, loss 0.10078836977481842, acc=0.9639444351196289, loss=0.10078836977481842
test: epoch 117, loss 0.27609363198280334, acc=0.9111111164093018, loss=0.27609363198280334
train: epoch 118, loss 0.1005086600780487, acc=0.9637222290039062, loss=0.1005086600780487
test: epoch 118, loss 0.22326402366161346, acc=0.9194444417953491, loss=0.22326402366161346
train: epoch 119, loss 0.1107543408870697, acc=0.9598333239555359, loss=0.1107543408870697
test: epoch 119, loss 0.24695070087909698, acc=0.9111111164093018, loss=0.24695070087909698
train: epoch 120, loss 0.11990141123533249, acc=0.9580555558204651, loss=0.11990141123533249
test: epoch 120, loss 0.16990481317043304, acc=0.9083333611488342, loss=0.16990481317043304
train: epoch 121, loss 0.0980171412229538, acc=0.9633333086967468, loss=0.0980171412229538
test: epoch 121, loss 0.2536522448062897, acc=0.9111111164093018, loss=0.2536522448062897
train: epoch 122, loss 0.10212991386651993, acc=0.9640555381774902, loss=0.10212991386651993
test: epoch 122, loss 0.2979466915130615, acc=0.9111111164093018, loss=0.2979466915130615
train: epoch 123, loss 0.12286598235368729, acc=0.9567777514457703, loss=0.12286598235368729
test: epoch 123, loss 0.29624634981155396, acc=0.8861111402511597, loss=0.29624634981155396
train: epoch 124, loss 0.09489467740058899, acc=0.9678888916969299, loss=0.09489467740058899
test: epoch 124, loss 0.25841909646987915, acc=0.9083333611488342, loss=0.25841909646987915
train: epoch 125, loss 0.09221775829792023, acc=0.9666666388511658, loss=0.09221775829792023
test: epoch 125, loss 0.2818411886692047, acc=0.9111111164093018, loss=0.2818411886692047
train: epoch 126, loss 0.09065341204404831, acc=0.9677222371101379, loss=0.09065341204404831
test: epoch 126, loss 0.22427767515182495, acc=0.9111111164093018, loss=0.22427767515182495
train: epoch 127, loss 0.09814191609621048, acc=0.9673333168029785, loss=0.09814191609621048
test: epoch 127, loss 0.2693583369255066, acc=0.9111111164093018, loss=0.2693583369255066
train: epoch 128, loss 0.09758660942316055, acc=0.9661111235618591, loss=0.09758660942316055
test: epoch 128, loss 0.2283981442451477, acc=0.9138888716697693, loss=0.2283981442451477
train: epoch 129, loss 0.10822989791631699, acc=0.9601666927337646, loss=0.10822989791631699
test: epoch 129, loss 0.1915634274482727, acc=0.9166666865348816, loss=0.1915634274482727
train: epoch 130, loss 0.0965440645813942, acc=0.9641666412353516, loss=0.0965440645813942
test: epoch 130, loss 0.2666504383087158, acc=0.9111111164093018, loss=0.2666504383087158
train: epoch 131, loss 0.09493820369243622, acc=0.9663333296775818, loss=0.09493820369243622
test: epoch 131, loss 0.2715603709220886, acc=0.9055555462837219, loss=0.2715603709220886
train: epoch 132, loss 0.08870912343263626, acc=0.9683889150619507, loss=0.08870912343263626
test: epoch 132, loss 0.22610415518283844, acc=0.9111111164093018, loss=0.22610415518283844
train: epoch 133, loss 0.09376703947782516, acc=0.9666110873222351, loss=0.09376703947782516
test: epoch 133, loss 0.26526209712028503, acc=0.9111111164093018, loss=0.26526209712028503
train: epoch 134, loss 0.09933920204639435, acc=0.9638333320617676, loss=0.09933920204639435
test: epoch 134, loss 0.3319171667098999, acc=0.9194444417953491, loss=0.3319171667098999
train: epoch 135, loss 0.08751457184553146, acc=0.9696111083030701, loss=0.08751457184553146
test: epoch 135, loss 0.3623987138271332, acc=0.8694444298744202, loss=0.3623987138271332
train: epoch 136, loss 0.09867607802152634, acc=0.9666666388511658, loss=0.09867607802152634
test: epoch 136, loss 0.19014336168766022, acc=0.9166666865348816, loss=0.19014336168766022
train: epoch 137, loss 0.09051859378814697, acc=0.9685555696487427, loss=0.09051859378814697
test: epoch 137, loss 0.2665966749191284, acc=0.8694444298744202, loss=0.2665966749191284
train: epoch 138, loss 0.09609673172235489, acc=0.9687777757644653, loss=0.09609673172235489
test: epoch 138, loss 0.22294922173023224, acc=0.9138888716697693, loss=0.22294922173023224
train: epoch 139, loss 0.09052899479866028, acc=0.9661666750907898, loss=0.09052899479866028
test: epoch 139, loss 0.1722615510225296, acc=0.9111111164093018, loss=0.1722615510225296
train: epoch 140, loss 0.08694532513618469, acc=0.9685555696487427, loss=0.08694532513618469
test: epoch 140, loss 0.21309712529182434, acc=0.9111111164093018, loss=0.21309712529182434
train: epoch 141, loss 0.08797495812177658, acc=0.9704444408416748, loss=0.08797495812177658
test: epoch 141, loss 0.2562752366065979, acc=0.9111111164093018, loss=0.2562752366065979
train: epoch 142, loss 0.09245725721120834, acc=0.9677777886390686, loss=0.09245725721120834
test: epoch 142, loss 0.2822917699813843, acc=0.9111111164093018, loss=0.2822917699813843
train: epoch 143, loss 0.08781472593545914, acc=0.9693333506584167, loss=0.08781472593545914
test: epoch 143, loss 0.30376556515693665, acc=0.9111111164093018, loss=0.30376556515693665
train: epoch 144, loss 0.09092961251735687, acc=0.9658889174461365, loss=0.09092961251735687
test: epoch 144, loss 0.20529630780220032, acc=0.9083333611488342, loss=0.20529630780220032
train: epoch 145, loss 0.08456983417272568, acc=0.9702777862548828, loss=0.08456983417272568
test: epoch 145, loss 0.2711760699748993, acc=0.9111111164093018, loss=0.2711760699748993
train: epoch 146, loss 0.08228352665901184, acc=0.9707777500152588, loss=0.08228352665901184
test: epoch 146, loss 0.3158421814441681, acc=0.9111111164093018, loss=0.3158421814441681
train: epoch 147, loss 0.08431919664144516, acc=0.9698888659477234, loss=0.08431919664144516
test: epoch 147, loss 0.2488977313041687, acc=0.9166666865348816, loss=0.2488977313041687
train: epoch 148, loss 0.08502068370580673, acc=0.969944417476654, loss=0.08502068370580673
test: epoch 148, loss 0.2859298884868622, acc=0.9111111164093018, loss=0.2859298884868622
train: epoch 149, loss 0.09285201132297516, acc=0.965666651725769, loss=0.09285201132297516
test: epoch 149, loss 0.2853230834007263, acc=0.875, loss=0.2853230834007263
train: epoch 150, loss 0.08599335700273514, acc=0.9687222242355347, loss=0.08599335700273514
test: epoch 150, loss 0.25820639729499817, acc=0.9111111164093018, loss=0.25820639729499817
