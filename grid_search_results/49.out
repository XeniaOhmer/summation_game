# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=0.99", "--one_hot=0", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=408548815, receiver_embed_dim=32, save_run=0, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=408548815, receiver_embed_dim=32, save_run=False, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.647735357284546, acc=0.14755555987358093, loss=2.647735357284546
test: epoch 1, loss 6.914561748504639, acc=0.05277777835726738, loss=6.914561748504639
train: epoch 2, loss 1.9126039743423462, acc=0.2848333418369293, loss=1.9126039743423462
test: epoch 2, loss 7.4540910720825195, acc=0.0555555559694767, loss=7.4540910720825195
train: epoch 3, loss 1.667879581451416, acc=0.35127776861190796, loss=1.667879581451416
test: epoch 3, loss 7.54168701171875, acc=0.06388889253139496, loss=7.54168701171875
train: epoch 4, loss 1.525463342666626, acc=0.3943333327770233, loss=1.525463342666626
test: epoch 4, loss 7.781470775604248, acc=0.06666667014360428, loss=7.781470775604248
train: epoch 5, loss 1.4367315769195557, acc=0.4280555546283722, loss=1.4367315769195557
test: epoch 5, loss 7.268286228179932, acc=0.06666667014360428, loss=7.268286228179932
train: epoch 6, loss 1.3559459447860718, acc=0.4658888876438141, loss=1.3559459447860718
test: epoch 6, loss 7.174076557159424, acc=0.05277777835726738, loss=7.174076557159424
train: epoch 7, loss 1.3041846752166748, acc=0.47761112451553345, loss=1.3041846752166748
test: epoch 7, loss 6.184348106384277, acc=0.06111111119389534, loss=6.184348106384277
train: epoch 8, loss 1.2516859769821167, acc=0.49533334374427795, loss=1.2516859769821167
test: epoch 8, loss 7.862317085266113, acc=0.0694444477558136, loss=7.862317085266113
train: epoch 9, loss 1.227782130241394, acc=0.5157222151756287, loss=1.227782130241394
test: epoch 9, loss 7.923801422119141, acc=0.07777778059244156, loss=7.923801422119141
train: epoch 10, loss 1.1848658323287964, acc=0.5270000100135803, loss=1.1848658323287964
test: epoch 10, loss 7.6269850730896, acc=0.04722222313284874, loss=7.6269850730896
train: epoch 11, loss 1.1544145345687866, acc=0.5427777767181396, loss=1.1544145345687866
test: epoch 11, loss 6.0456342697143555, acc=0.09444444626569748, loss=6.0456342697143555
train: epoch 12, loss 1.1281566619873047, acc=0.5577222108840942, loss=1.1281566619873047
test: epoch 12, loss 6.744808197021484, acc=0.0833333358168602, loss=6.744808197021484
train: epoch 13, loss 1.1179195642471313, acc=0.5608333349227905, loss=1.1179195642471313
test: epoch 13, loss 7.175176620483398, acc=0.0416666679084301, loss=7.175176620483398
train: epoch 14, loss 1.0825446844100952, acc=0.5782777667045593, loss=1.0825446844100952
test: epoch 14, loss 7.139555931091309, acc=0.08611111342906952, loss=7.139555931091309
train: epoch 15, loss 1.0830481052398682, acc=0.5848888754844666, loss=1.0830481052398682
test: epoch 15, loss 6.370334148406982, acc=0.1111111119389534, loss=6.370334148406982
train: epoch 16, loss 1.056160807609558, acc=0.5871111154556274, loss=1.056160807609558
test: epoch 16, loss 6.069009304046631, acc=0.125, loss=6.069009304046631
train: epoch 17, loss 1.0484423637390137, acc=0.5986111164093018, loss=1.0484423637390137
test: epoch 17, loss 5.652113914489746, acc=0.125, loss=5.652113914489746
train: epoch 18, loss 1.0325502157211304, acc=0.5990555286407471, loss=1.0325502157211304
test: epoch 18, loss 6.188560962677002, acc=0.12222222238779068, loss=6.188560962677002
train: epoch 19, loss 1.0287305116653442, acc=0.6039444208145142, loss=1.0287305116653442
test: epoch 19, loss 6.210693359375, acc=0.0972222238779068, loss=6.210693359375
train: epoch 20, loss 1.0050021409988403, acc=0.6107777953147888, loss=1.0050021409988403
test: epoch 20, loss 6.005589485168457, acc=0.14722222089767456, loss=6.005589485168457
train: epoch 21, loss 1.0074504613876343, acc=0.6145555377006531, loss=1.0074504613876343
test: epoch 21, loss 5.5055413246154785, acc=0.12222222238779068, loss=5.5055413246154785
train: epoch 22, loss 1.021358847618103, acc=0.6115555763244629, loss=1.021358847618103
test: epoch 22, loss 5.364591121673584, acc=0.14444445073604584, loss=5.364591121673584
train: epoch 23, loss 0.9891173243522644, acc=0.6211666464805603, loss=0.9891173243522644
test: epoch 23, loss 5.185604572296143, acc=0.0833333358168602, loss=5.185604572296143
train: epoch 24, loss 1.000415325164795, acc=0.616777777671814, loss=1.000415325164795
test: epoch 24, loss 5.1167802810668945, acc=0.1388888955116272, loss=5.1167802810668945
train: epoch 25, loss 0.9773330092430115, acc=0.6277222037315369, loss=0.9773330092430115
test: epoch 25, loss 4.715291500091553, acc=0.13333334028720856, loss=4.715291500091553
train: epoch 26, loss 0.9826714396476746, acc=0.6287222504615784, loss=0.9826714396476746
test: epoch 26, loss 5.726536750793457, acc=0.12222222238779068, loss=5.726536750793457
train: epoch 27, loss 0.9892004728317261, acc=0.6269444227218628, loss=0.9892004728317261
test: epoch 27, loss 4.064380168914795, acc=0.15833333134651184, loss=4.064380168914795
train: epoch 28, loss 0.9809737205505371, acc=0.6300555467605591, loss=0.9809737205505371
test: epoch 28, loss 4.15273904800415, acc=0.16111111640930176, loss=4.15273904800415
train: epoch 29, loss 0.9839866757392883, acc=0.628000020980835, loss=0.9839866757392883
test: epoch 29, loss 4.6063337326049805, acc=0.18333333730697632, loss=4.6063337326049805
train: epoch 30, loss 0.9701148867607117, acc=0.6302777528762817, loss=0.9701148867607117
test: epoch 30, loss 4.52405309677124, acc=0.17499999701976776, loss=4.52405309677124
train: epoch 31, loss 0.9624415040016174, acc=0.6337222456932068, loss=0.9624415040016174
test: epoch 31, loss 3.8369922637939453, acc=0.15555556118488312, loss=3.8369922637939453
train: epoch 32, loss 0.9838554263114929, acc=0.6233333349227905, loss=0.9838554263114929
test: epoch 32, loss 3.6554980278015137, acc=0.17222222685813904, loss=3.6554980278015137
train: epoch 33, loss 0.9739187955856323, acc=0.6298333406448364, loss=0.9739187955856323
test: epoch 33, loss 4.268383026123047, acc=0.15000000596046448, loss=4.268383026123047
train: epoch 34, loss 0.9845139980316162, acc=0.6287222504615784, loss=0.9845139980316162
test: epoch 34, loss 2.9866943359375, acc=0.1944444477558136, loss=2.9866943359375
train: epoch 35, loss 0.9694428443908691, acc=0.6330000162124634, loss=0.9694428443908691
test: epoch 35, loss 3.6757547855377197, acc=0.19166666269302368, loss=3.6757547855377197
train: epoch 36, loss 0.9824967980384827, acc=0.6275555491447449, loss=0.9824967980384827
test: epoch 36, loss 3.075197458267212, acc=0.16111111640930176, loss=3.075197458267212
train: epoch 37, loss 0.9694920778274536, acc=0.6331666707992554, loss=0.9694920778274536
test: epoch 37, loss 3.4087412357330322, acc=0.18333333730697632, loss=3.4087412357330322
train: epoch 38, loss 0.9644727110862732, acc=0.6330000162124634, loss=0.9644727110862732
test: epoch 38, loss 3.3441882133483887, acc=0.20277777314186096, loss=3.3441882133483887
train: epoch 39, loss 0.9607938528060913, acc=0.6386111378669739, loss=0.9607938528060913
test: epoch 39, loss 3.9044041633605957, acc=0.15000000596046448, loss=3.9044041633605957
train: epoch 40, loss 0.9849823117256165, acc=0.6298888921737671, loss=0.9849823117256165
test: epoch 40, loss 3.2221150398254395, acc=0.21388888359069824, loss=3.2221150398254395
train: epoch 41, loss 1.00165593624115, acc=0.6187777519226074, loss=1.00165593624115
test: epoch 41, loss 2.6763198375701904, acc=0.14722222089767456, loss=2.6763198375701904
train: epoch 42, loss 0.9806846380233765, acc=0.6270555257797241, loss=0.9806846380233765
test: epoch 42, loss 2.9892160892486572, acc=0.20000000298023224, loss=2.9892160892486572
train: epoch 43, loss 0.977231502532959, acc=0.629277765750885, loss=0.977231502532959
test: epoch 43, loss 2.5547404289245605, acc=0.1944444477558136, loss=2.5547404289245605
train: epoch 44, loss 0.9807525873184204, acc=0.628000020980835, loss=0.9807525873184204
test: epoch 44, loss 2.863795757293701, acc=0.24444444477558136, loss=2.863795757293701
train: epoch 45, loss 1.0093141794204712, acc=0.6192222237586975, loss=1.0093141794204712
test: epoch 45, loss 2.5462148189544678, acc=0.27222222089767456, loss=2.5462148189544678
train: epoch 46, loss 0.9955272078514099, acc=0.6243333220481873, loss=0.9955272078514099
test: epoch 46, loss 2.442657470703125, acc=0.16111111640930176, loss=2.442657470703125
train: epoch 47, loss 0.9705729484558105, acc=0.628777801990509, loss=0.9705729484558105
test: epoch 47, loss 2.4067306518554688, acc=0.20555555820465088, loss=2.4067306518554688
train: epoch 48, loss 1.0041979551315308, acc=0.6202222108840942, loss=1.0041979551315308
test: epoch 48, loss 2.4103615283966064, acc=0.23888888955116272, loss=2.4103615283966064
train: epoch 49, loss 0.9924931526184082, acc=0.6184444427490234, loss=0.9924931526184082
test: epoch 49, loss 2.6178624629974365, acc=0.1944444477558136, loss=2.6178624629974365
train: epoch 50, loss 0.9913296699523926, acc=0.6257222294807434, loss=0.9913296699523926
test: epoch 50, loss 2.699795961380005, acc=0.19722221791744232, loss=2.699795961380005
train: epoch 51, loss 0.988946259021759, acc=0.6223888993263245, loss=0.988946259021759
test: epoch 51, loss 2.6668941974639893, acc=0.16944444179534912, loss=2.6668941974639893
train: epoch 52, loss 1.007301926612854, acc=0.6161110997200012, loss=1.007301926612854
test: epoch 52, loss 2.1470770835876465, acc=0.20555555820465088, loss=2.1470770835876465
train: epoch 53, loss 0.9954103231430054, acc=0.6209444403648376, loss=0.9954103231430054
test: epoch 53, loss 2.2520227432250977, acc=0.2805555462837219, loss=2.2520227432250977
train: epoch 54, loss 1.002288579940796, acc=0.6199444532394409, loss=1.002288579940796
test: epoch 54, loss 2.2226927280426025, acc=0.21666666865348816, loss=2.2226927280426025
train: epoch 55, loss 1.0002970695495605, acc=0.6167222261428833, loss=1.0002970695495605
test: epoch 55, loss 2.2873668670654297, acc=0.20000000298023224, loss=2.2873668670654297
train: epoch 56, loss 0.9969324469566345, acc=0.6168333292007446, loss=0.9969324469566345
test: epoch 56, loss 2.135327100753784, acc=0.24166665971279144, loss=2.135327100753784
train: epoch 57, loss 0.9988631010055542, acc=0.6154444217681885, loss=0.9988631010055542
test: epoch 57, loss 2.360821485519409, acc=0.2222222238779068, loss=2.360821485519409
train: epoch 58, loss 1.0053068399429321, acc=0.6151111125946045, loss=1.0053068399429321
test: epoch 58, loss 1.9726046323776245, acc=0.2611111104488373, loss=1.9726046323776245
train: epoch 59, loss 1.0017884969711304, acc=0.6140555739402771, loss=1.0017884969711304
test: epoch 59, loss 1.8911359310150146, acc=0.2361111044883728, loss=1.8911359310150146
train: epoch 60, loss 1.0075188875198364, acc=0.6134999990463257, loss=1.0075188875198364
test: epoch 60, loss 2.028639793395996, acc=0.21388888359069824, loss=2.028639793395996
train: epoch 61, loss 1.0086787939071655, acc=0.6123889088630676, loss=1.0086787939071655
test: epoch 61, loss 1.9280385971069336, acc=0.2666666805744171, loss=1.9280385971069336
train: epoch 62, loss 1.0021352767944336, acc=0.6130555272102356, loss=1.0021352767944336
test: epoch 62, loss 2.2017040252685547, acc=0.22499999403953552, loss=2.2017040252685547
train: epoch 63, loss 0.9973397254943848, acc=0.6152222156524658, loss=0.9973397254943848
test: epoch 63, loss 2.0767927169799805, acc=0.2750000059604645, loss=2.0767927169799805
train: epoch 64, loss 1.0309228897094727, acc=0.6035555601119995, loss=1.0309228897094727
test: epoch 64, loss 1.7592631578445435, acc=0.2777777910232544, loss=1.7592631578445435
train: epoch 65, loss 1.0150361061096191, acc=0.6069444417953491, loss=1.0150361061096191
test: epoch 65, loss 1.8728158473968506, acc=0.2666666805744171, loss=1.8728158473968506
train: epoch 66, loss 1.0099858045578003, acc=0.6123889088630676, loss=1.0099858045578003
test: epoch 66, loss 1.7109229564666748, acc=0.28611111640930176, loss=1.7109229564666748
train: epoch 67, loss 1.0130964517593384, acc=0.6018333435058594, loss=1.0130964517593384
test: epoch 67, loss 1.7896883487701416, acc=0.21944443881511688, loss=1.7896883487701416
train: epoch 68, loss 0.997355043888092, acc=0.6057778000831604, loss=0.997355043888092
test: epoch 68, loss 1.8269728422164917, acc=0.2916666567325592, loss=1.8269728422164917
train: epoch 69, loss 1.0082954168319702, acc=0.6129999756813049, loss=1.0082954168319702
test: epoch 69, loss 1.6876826286315918, acc=0.31388887763023376, loss=1.6876826286315918
train: epoch 70, loss 1.004522442817688, acc=0.6100000143051147, loss=1.004522442817688
test: epoch 70, loss 1.788459300994873, acc=0.2638888955116272, loss=1.788459300994873
train: epoch 71, loss 1.0220578908920288, acc=0.6036666631698608, loss=1.0220578908920288
test: epoch 71, loss 1.811774730682373, acc=0.3194444477558136, loss=1.811774730682373
train: epoch 72, loss 1.021974802017212, acc=0.5991111397743225, loss=1.021974802017212
test: epoch 72, loss 1.8201959133148193, acc=0.29722222685813904, loss=1.8201959133148193
train: epoch 73, loss 1.03184974193573, acc=0.594944417476654, loss=1.03184974193573
test: epoch 73, loss 1.6553138494491577, acc=0.3027777671813965, loss=1.6553138494491577
train: epoch 74, loss 1.0252875089645386, acc=0.6002222299575806, loss=1.0252875089645386
test: epoch 74, loss 1.7560580968856812, acc=0.29722222685813904, loss=1.7560580968856812
train: epoch 75, loss 1.0242639780044556, acc=0.5946666598320007, loss=1.0242639780044556
test: epoch 75, loss 1.9285404682159424, acc=0.2805555462837219, loss=1.9285404682159424
train: epoch 76, loss 1.0320483446121216, acc=0.5902777910232544, loss=1.0320483446121216
test: epoch 76, loss 1.8211158514022827, acc=0.36944442987442017, loss=1.8211158514022827
train: epoch 77, loss 1.0112072229385376, acc=0.6035555601119995, loss=1.0112072229385376
test: epoch 77, loss 1.6814770698547363, acc=0.32499998807907104, loss=1.6814770698547363
train: epoch 78, loss 1.0205799341201782, acc=0.5997222065925598, loss=1.0205799341201782
test: epoch 78, loss 1.7446706295013428, acc=0.3361110985279083, loss=1.7446706295013428
train: epoch 79, loss 1.0229730606079102, acc=0.5981666445732117, loss=1.0229730606079102
test: epoch 79, loss 1.6464215517044067, acc=0.31388887763023376, loss=1.6464215517044067
train: epoch 80, loss 1.0288848876953125, acc=0.5957777500152588, loss=1.0288848876953125
test: epoch 80, loss 1.5963897705078125, acc=0.3499999940395355, loss=1.5963897705078125
train: epoch 81, loss 1.0469872951507568, acc=0.5916666388511658, loss=1.0469872951507568
test: epoch 81, loss 1.5868207216262817, acc=0.3333333432674408, loss=1.5868207216262817
train: epoch 82, loss 1.0134860277175903, acc=0.5967777967453003, loss=1.0134860277175903
test: epoch 82, loss 1.6015740633010864, acc=0.4000000059604645, loss=1.6015740633010864
train: epoch 83, loss 1.026048183441162, acc=0.5926111340522766, loss=1.026048183441162
test: epoch 83, loss 1.6644700765609741, acc=0.33888888359069824, loss=1.6644700765609741
train: epoch 84, loss 1.0392143726348877, acc=0.5905555486679077, loss=1.0392143726348877
test: epoch 84, loss 1.5579113960266113, acc=0.3305555582046509, loss=1.5579113960266113
train: epoch 85, loss 1.0365921258926392, acc=0.5863333344459534, loss=1.0365921258926392
test: epoch 85, loss 1.5642024278640747, acc=0.3888888955116272, loss=1.5642024278640747
train: epoch 86, loss 1.0377097129821777, acc=0.5887777805328369, loss=1.0377097129821777
test: epoch 86, loss 1.7748618125915527, acc=0.29722222685813904, loss=1.7748618125915527
train: epoch 87, loss 1.0509237051010132, acc=0.5832777619361877, loss=1.0509237051010132
test: epoch 87, loss 1.5980744361877441, acc=0.33888888359069824, loss=1.5980744361877441
train: epoch 88, loss 1.048601508140564, acc=0.5818333625793457, loss=1.048601508140564
test: epoch 88, loss 1.6036994457244873, acc=0.3166666626930237, loss=1.6036994457244873
train: epoch 89, loss 1.0282318592071533, acc=0.5871111154556274, loss=1.0282318592071533
test: epoch 89, loss 1.4649665355682373, acc=0.4027777910232544, loss=1.4649665355682373
train: epoch 90, loss 1.030665397644043, acc=0.5890555381774902, loss=1.030665397644043
test: epoch 90, loss 1.5879249572753906, acc=0.4000000059604645, loss=1.5879249572753906
train: epoch 91, loss 1.0411263704299927, acc=0.5827222466468811, loss=1.0411263704299927
test: epoch 91, loss 1.601445198059082, acc=0.3222222328186035, loss=1.601445198059082
train: epoch 92, loss 1.0382498502731323, acc=0.5846666693687439, loss=1.0382498502731323
test: epoch 92, loss 1.5214377641677856, acc=0.3444444537162781, loss=1.5214377641677856
train: epoch 93, loss 1.0736967325210571, acc=0.5688333511352539, loss=1.0736967325210571
test: epoch 93, loss 1.4795217514038086, acc=0.3777777850627899, loss=1.4795217514038086
train: epoch 94, loss 1.071479082107544, acc=0.5733888745307922, loss=1.071479082107544
test: epoch 94, loss 1.4649475812911987, acc=0.4027777910232544, loss=1.4649475812911987
train: epoch 95, loss 1.0349935293197632, acc=0.5852222442626953, loss=1.0349935293197632
test: epoch 95, loss 1.5428287982940674, acc=0.3888888955116272, loss=1.5428287982940674
train: epoch 96, loss 1.0491676330566406, acc=0.5771666765213013, loss=1.0491676330566406
test: epoch 96, loss 1.382863998413086, acc=0.3861111104488373, loss=1.382863998413086
train: epoch 97, loss 1.0431855916976929, acc=0.5838333368301392, loss=1.0431855916976929
test: epoch 97, loss 1.62150239944458, acc=0.35555556416511536, loss=1.62150239944458
train: epoch 98, loss 1.0595544576644897, acc=0.5759999752044678, loss=1.0595544576644897
test: epoch 98, loss 1.5220906734466553, acc=0.39722222089767456, loss=1.5220906734466553
train: epoch 99, loss 1.045065999031067, acc=0.578499972820282, loss=1.045065999031067
test: epoch 99, loss 1.528053879737854, acc=0.3916666805744171, loss=1.528053879737854
train: epoch 100, loss 1.0303418636322021, acc=0.582444429397583, loss=1.0303418636322021
test: epoch 100, loss 1.4499725103378296, acc=0.32499998807907104, loss=1.4499725103378296
train: epoch 101, loss 1.0342289209365845, acc=0.5824999809265137, loss=1.0342289209365845
test: epoch 101, loss 1.6714050769805908, acc=0.3444444537162781, loss=1.6714050769805908
train: epoch 102, loss 1.0542501211166382, acc=0.5750555396080017, loss=1.0542501211166382
test: epoch 102, loss 1.9869848489761353, acc=0.3611111044883728, loss=1.9869848489761353
train: epoch 103, loss 1.0728302001953125, acc=0.5752778053283691, loss=1.0728302001953125
test: epoch 103, loss 1.5831550359725952, acc=0.36666667461395264, loss=1.5831550359725952
train: epoch 104, loss 1.0234715938568115, acc=0.5876666903495789, loss=1.0234715938568115
test: epoch 104, loss 1.555568814277649, acc=0.2944444417953491, loss=1.555568814277649
train: epoch 105, loss 1.0305500030517578, acc=0.5795000195503235, loss=1.0305500030517578
test: epoch 105, loss 1.6251580715179443, acc=0.3333333432674408, loss=1.6251580715179443
train: epoch 106, loss 1.0597915649414062, acc=0.5823888778686523, loss=1.0597915649414062
test: epoch 106, loss 1.5752816200256348, acc=0.3472222089767456, loss=1.5752816200256348
train: epoch 107, loss 1.0026687383651733, acc=0.5931110978126526, loss=1.0026687383651733
test: epoch 107, loss 1.4777934551239014, acc=0.3472222089767456, loss=1.4777934551239014
train: epoch 108, loss 1.0067561864852905, acc=0.5947222113609314, loss=1.0067561864852905
test: epoch 108, loss 1.47441828250885, acc=0.38055557012557983, loss=1.47441828250885
train: epoch 109, loss 1.01034677028656, acc=0.5917778015136719, loss=1.01034677028656
test: epoch 109, loss 1.4344404935836792, acc=0.375, loss=1.4344404935836792
train: epoch 110, loss 0.9979919195175171, acc=0.5983889102935791, loss=0.9979919195175171
test: epoch 110, loss 1.3718562126159668, acc=0.4027777910232544, loss=1.3718562126159668
train: epoch 111, loss 0.9832901358604431, acc=0.6043888926506042, loss=0.9832901358604431
test: epoch 111, loss 1.4689266681671143, acc=0.35277777910232544, loss=1.4689266681671143
train: epoch 112, loss 0.977476179599762, acc=0.6057222485542297, loss=0.977476179599762
test: epoch 112, loss 1.3475102186203003, acc=0.3888888955116272, loss=1.3475102186203003
train: epoch 113, loss 1.0153781175613403, acc=0.6033333539962769, loss=1.0153781175613403
test: epoch 113, loss 1.450262427330017, acc=0.39722222089767456, loss=1.450262427330017
train: epoch 114, loss 0.9736679792404175, acc=0.6113888621330261, loss=0.9736679792404175
test: epoch 114, loss 1.4077508449554443, acc=0.39722222089767456, loss=1.4077508449554443
train: epoch 115, loss 0.9878392815589905, acc=0.6066666841506958, loss=0.9878392815589905
test: epoch 115, loss 1.5346381664276123, acc=0.3305555582046509, loss=1.5346381664276123
train: epoch 116, loss 0.9603198170661926, acc=0.6117777824401855, loss=0.9603198170661926
test: epoch 116, loss 1.4594500064849854, acc=0.3722222149372101, loss=1.4594500064849854
train: epoch 117, loss 0.9573413133621216, acc=0.6133888959884644, loss=0.9573413133621216
test: epoch 117, loss 1.3579334020614624, acc=0.3861111104488373, loss=1.3579334020614624
train: epoch 118, loss 0.9399418830871582, acc=0.6225000023841858, loss=0.9399418830871582
test: epoch 118, loss 1.287678599357605, acc=0.4416666626930237, loss=1.287678599357605
train: epoch 119, loss 0.9370031952857971, acc=0.6213889122009277, loss=0.9370031952857971
test: epoch 119, loss 1.6021771430969238, acc=0.35277777910232544, loss=1.6021771430969238
train: epoch 120, loss 0.9432869553565979, acc=0.6218888759613037, loss=0.9432869553565979
test: epoch 120, loss 1.4913650751113892, acc=0.38055557012557983, loss=1.4913650751113892
train: epoch 121, loss 0.938700258731842, acc=0.6243333220481873, loss=0.938700258731842
test: epoch 121, loss 1.3902604579925537, acc=0.40833333134651184, loss=1.3902604579925537
train: epoch 122, loss 0.9404643774032593, acc=0.6196666955947876, loss=0.9404643774032593
test: epoch 122, loss 1.3722496032714844, acc=0.32777777314186096, loss=1.3722496032714844
train: epoch 123, loss 0.9224019050598145, acc=0.6249444484710693, loss=0.9224019050598145
test: epoch 123, loss 1.3348371982574463, acc=0.4583333432674408, loss=1.3348371982574463
train: epoch 124, loss 0.9177032709121704, acc=0.6331111192703247, loss=0.9177032709121704
test: epoch 124, loss 1.4802846908569336, acc=0.3777777850627899, loss=1.4802846908569336
train: epoch 125, loss 0.9037721753120422, acc=0.6356666684150696, loss=0.9037721753120422
test: epoch 125, loss 1.3846077919006348, acc=0.43611112236976624, loss=1.3846077919006348
train: epoch 126, loss 0.9148972630500793, acc=0.632888913154602, loss=0.9148972630500793
test: epoch 126, loss 1.496854305267334, acc=0.3916666805744171, loss=1.496854305267334
train: epoch 127, loss 0.8983691930770874, acc=0.640999972820282, loss=0.8983691930770874
test: epoch 127, loss 1.3549832105636597, acc=0.4055555462837219, loss=1.3549832105636597
train: epoch 128, loss 0.8853944540023804, acc=0.6449999809265137, loss=0.8853944540023804
test: epoch 128, loss 1.2797750234603882, acc=0.4000000059604645, loss=1.2797750234603882
train: epoch 129, loss 0.90193772315979, acc=0.6359444260597229, loss=0.90193772315979
test: epoch 129, loss 1.284718632698059, acc=0.43888887763023376, loss=1.284718632698059
train: epoch 130, loss 0.8876559138298035, acc=0.6422777771949768, loss=0.8876559138298035
test: epoch 130, loss 1.4656579494476318, acc=0.4277777671813965, loss=1.4656579494476318
train: epoch 131, loss 0.8879677057266235, acc=0.6475555300712585, loss=0.8879677057266235
test: epoch 131, loss 1.3287371397018433, acc=0.3472222089767456, loss=1.3287371397018433
train: epoch 132, loss 0.894845724105835, acc=0.6442221999168396, loss=0.894845724105835
test: epoch 132, loss 1.2596735954284668, acc=0.4444444477558136, loss=1.2596735954284668
train: epoch 133, loss 0.8767297863960266, acc=0.6501666903495789, loss=0.8767297863960266
test: epoch 133, loss 1.4012190103530884, acc=0.4555555582046509, loss=1.4012190103530884
train: epoch 134, loss 0.8751279711723328, acc=0.6494444608688354, loss=0.8751279711723328
test: epoch 134, loss 1.2173711061477661, acc=0.4694444537162781, loss=1.2173711061477661
train: epoch 135, loss 0.8746113181114197, acc=0.6561111211776733, loss=0.8746113181114197
test: epoch 135, loss 1.234837532043457, acc=0.4888888895511627, loss=1.234837532043457
train: epoch 136, loss 0.8727630376815796, acc=0.6528333425521851, loss=0.8727630376815796
test: epoch 136, loss 1.256893277168274, acc=0.4000000059604645, loss=1.256893277168274
train: epoch 137, loss 0.8770344257354736, acc=0.6524999737739563, loss=0.8770344257354736
test: epoch 137, loss 1.2366104125976562, acc=0.519444465637207, loss=1.2366104125976562
train: epoch 138, loss 0.8530343174934387, acc=0.6636666655540466, loss=0.8530343174934387
test: epoch 138, loss 1.2652286291122437, acc=0.4138889014720917, loss=1.2652286291122437
train: epoch 139, loss 0.8352577090263367, acc=0.6628333330154419, loss=0.8352577090263367
test: epoch 139, loss 1.4089045524597168, acc=0.42222222685813904, loss=1.4089045524597168
train: epoch 140, loss 0.843087911605835, acc=0.6626666784286499, loss=0.843087911605835
test: epoch 140, loss 1.1594921350479126, acc=0.4694444537162781, loss=1.1594921350479126
train: epoch 141, loss 0.8491628766059875, acc=0.6572222113609314, loss=0.8491628766059875
test: epoch 141, loss 1.2909634113311768, acc=0.4416666626930237, loss=1.2909634113311768
train: epoch 142, loss 0.8323511481285095, acc=0.6672222018241882, loss=0.8323511481285095
test: epoch 142, loss 1.144856572151184, acc=0.5, loss=1.144856572151184
train: epoch 143, loss 0.8268979787826538, acc=0.6652777791023254, loss=0.8268979787826538
test: epoch 143, loss 1.4337654113769531, acc=0.36944442987442017, loss=1.4337654113769531
train: epoch 144, loss 0.8509481549263, acc=0.6599444150924683, loss=0.8509481549263
test: epoch 144, loss 1.2696338891983032, acc=0.4305555522441864, loss=1.2696338891983032
train: epoch 145, loss 0.8241267800331116, acc=0.6691666841506958, loss=0.8241267800331116
test: epoch 145, loss 1.316676378250122, acc=0.4555555582046509, loss=1.316676378250122
train: epoch 146, loss 0.857376754283905, acc=0.6656110882759094, loss=0.857376754283905
test: epoch 146, loss 1.3112502098083496, acc=0.40833333134651184, loss=1.3112502098083496
train: epoch 147, loss 0.8276569843292236, acc=0.6689444184303284, loss=0.8276569843292236
test: epoch 147, loss 1.1952322721481323, acc=0.46388888359069824, loss=1.1952322721481323
train: epoch 148, loss 0.8220282196998596, acc=0.6685555577278137, loss=0.8220282196998596
test: epoch 148, loss 1.2261037826538086, acc=0.42500001192092896, loss=1.2261037826538086
train: epoch 149, loss 0.7972375154495239, acc=0.6793888807296753, loss=0.7972375154495239
test: epoch 149, loss 1.2834233045578003, acc=0.5027777552604675, loss=1.2834233045578003
train: epoch 150, loss 0.8099126815795898, acc=0.6813333630561829, loss=0.8099126815795898
test: epoch 150, loss 1.6193331480026245, acc=0.3888888955116272, loss=1.6193331480026245
