# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=1", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=627541486, receiver_embed_dim=64, save_run=0, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=627541486, receiver_embed_dim=64, save_run=False, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.224844455718994, acc=0.0658888891339302, loss=3.224844455718994
test: epoch 1, loss 5.490293025970459, acc=0.05833333358168602, loss=5.490293025970459
train: epoch 2, loss 2.2803986072540283, acc=0.2523888945579529, loss=2.2803986072540283
test: epoch 2, loss 4.781876087188721, acc=0.11388888955116272, loss=4.781876087188721
train: epoch 3, loss 1.478249430656433, acc=0.4429444372653961, loss=1.478249430656433
test: epoch 3, loss 4.738811492919922, acc=0.125, loss=4.738811492919922
train: epoch 4, loss 1.1348652839660645, acc=0.5540555715560913, loss=1.1348652839660645
test: epoch 4, loss 4.1361212730407715, acc=0.16944444179534912, loss=4.1361212730407715
train: epoch 5, loss 0.9690436124801636, acc=0.6247222423553467, loss=0.9690436124801636
test: epoch 5, loss 3.9269280433654785, acc=0.17222222685813904, loss=3.9269280433654785
train: epoch 6, loss 0.8397612571716309, acc=0.6858333349227905, loss=0.8397612571716309
test: epoch 6, loss 3.7418861389160156, acc=0.1944444477558136, loss=3.7418861389160156
train: epoch 7, loss 0.7490163445472717, acc=0.7185555696487427, loss=0.7490163445472717
test: epoch 7, loss 3.620406150817871, acc=0.23333333432674408, loss=3.620406150817871
train: epoch 8, loss 0.6762171387672424, acc=0.7493333220481873, loss=0.6762171387672424
test: epoch 8, loss 3.5149993896484375, acc=0.23888888955116272, loss=3.5149993896484375
train: epoch 9, loss 0.633773922920227, acc=0.769444465637207, loss=0.633773922920227
test: epoch 9, loss 3.4526143074035645, acc=0.24444444477558136, loss=3.4526143074035645
train: epoch 10, loss 0.5716977715492249, acc=0.7906666398048401, loss=0.5716977715492249
test: epoch 10, loss 3.6208958625793457, acc=0.2361111044883728, loss=3.6208958625793457
train: epoch 11, loss 0.5381360054016113, acc=0.8079444169998169, loss=0.5381360054016113
test: epoch 11, loss 3.5357987880706787, acc=0.2638888955116272, loss=3.5357987880706787
train: epoch 12, loss 0.5141820311546326, acc=0.8192777633666992, loss=0.5141820311546326
test: epoch 12, loss 3.451472043991089, acc=0.2611111104488373, loss=3.451472043991089
train: epoch 13, loss 0.48916080594062805, acc=0.8258333206176758, loss=0.48916080594062805
test: epoch 13, loss 3.536489248275757, acc=0.25, loss=3.536489248275757
train: epoch 14, loss 0.45064854621887207, acc=0.8410555720329285, loss=0.45064854621887207
test: epoch 14, loss 3.069599151611328, acc=0.26944443583488464, loss=3.069599151611328
train: epoch 15, loss 0.4376767873764038, acc=0.8490555286407471, loss=0.4376767873764038
test: epoch 15, loss 3.250227689743042, acc=0.27222222089767456, loss=3.250227689743042
train: epoch 16, loss 0.42413026094436646, acc=0.8561111092567444, loss=0.42413026094436646
test: epoch 16, loss 2.830003261566162, acc=0.2805555462837219, loss=2.830003261566162
train: epoch 17, loss 0.3972732722759247, acc=0.8691111207008362, loss=0.3972732722759247
test: epoch 17, loss 2.7932026386260986, acc=0.27222222089767456, loss=2.7932026386260986
train: epoch 18, loss 0.37868982553482056, acc=0.8752777576446533, loss=0.37868982553482056
test: epoch 18, loss 2.822798728942871, acc=0.2638888955116272, loss=2.822798728942871
train: epoch 19, loss 0.35182973742485046, acc=0.8805000185966492, loss=0.35182973742485046
test: epoch 19, loss 2.8028225898742676, acc=0.2805555462837219, loss=2.8028225898742676
train: epoch 20, loss 0.3434937000274658, acc=0.8878889083862305, loss=0.3434937000274658
test: epoch 20, loss 2.748734951019287, acc=0.2750000059604645, loss=2.748734951019287
train: epoch 21, loss 0.3285306394100189, acc=0.8892777562141418, loss=0.3285306394100189
test: epoch 21, loss 2.496537923812866, acc=0.3083333373069763, loss=2.496537923812866
train: epoch 22, loss 0.3145569860935211, acc=0.8933333158493042, loss=0.3145569860935211
test: epoch 22, loss 2.4287734031677246, acc=0.3305555582046509, loss=2.4287734031677246
train: epoch 23, loss 0.3027568757534027, acc=0.9016666412353516, loss=0.3027568757534027
test: epoch 23, loss 2.557462692260742, acc=0.31111112236976624, loss=2.557462692260742
train: epoch 24, loss 0.3033587634563446, acc=0.902999997138977, loss=0.3033587634563446
test: epoch 24, loss 2.407474994659424, acc=0.29722222685813904, loss=2.407474994659424
train: epoch 25, loss 0.27911078929901123, acc=0.9068333506584167, loss=0.27911078929901123
test: epoch 25, loss 2.389942169189453, acc=0.35555556416511536, loss=2.389942169189453
train: epoch 26, loss 0.28557994961738586, acc=0.910111129283905, loss=0.28557994961738586
test: epoch 26, loss 2.6250972747802734, acc=0.3027777671813965, loss=2.6250972747802734
train: epoch 27, loss 0.2764298617839813, acc=0.9129999876022339, loss=0.2764298617839813
test: epoch 27, loss 2.5061893463134766, acc=0.32777777314186096, loss=2.5061893463134766
train: epoch 28, loss 0.26670318841934204, acc=0.9160555601119995, loss=0.26670318841934204
test: epoch 28, loss 2.267908811569214, acc=0.3333333432674408, loss=2.267908811569214
train: epoch 29, loss 0.24576221406459808, acc=0.9200000166893005, loss=0.24576221406459808
test: epoch 29, loss 2.2547495365142822, acc=0.3333333432674408, loss=2.2547495365142822
train: epoch 30, loss 0.25242188572883606, acc=0.9226111173629761, loss=0.25242188572883606
test: epoch 30, loss 2.4306540489196777, acc=0.3083333373069763, loss=2.4306540489196777
train: epoch 31, loss 0.2530761957168579, acc=0.9212222099304199, loss=0.2530761957168579
test: epoch 31, loss 2.2349307537078857, acc=0.375, loss=2.2349307537078857
train: epoch 32, loss 0.2492547631263733, acc=0.9246666431427002, loss=0.2492547631263733
test: epoch 32, loss 2.1518027782440186, acc=0.33888888359069824, loss=2.1518027782440186
train: epoch 33, loss 0.23164834082126617, acc=0.9296666383743286, loss=0.23164834082126617
test: epoch 33, loss 2.1218605041503906, acc=0.38333332538604736, loss=2.1218605041503906
train: epoch 34, loss 0.22393983602523804, acc=0.9277222156524658, loss=0.22393983602523804
test: epoch 34, loss 2.1112213134765625, acc=0.3722222149372101, loss=2.1112213134765625
train: epoch 35, loss 0.23007899522781372, acc=0.925944447517395, loss=0.23007899522781372
test: epoch 35, loss 2.098626136779785, acc=0.3916666805744171, loss=2.098626136779785
train: epoch 36, loss 0.2127775251865387, acc=0.9302777647972107, loss=0.2127775251865387
test: epoch 36, loss 1.9803831577301025, acc=0.38055557012557983, loss=1.9803831577301025
train: epoch 37, loss 0.2055419236421585, acc=0.9352777600288391, loss=0.2055419236421585
test: epoch 37, loss 2.0865249633789062, acc=0.38333332538604736, loss=2.0865249633789062
train: epoch 38, loss 0.20359615981578827, acc=0.9365555644035339, loss=0.20359615981578827
test: epoch 38, loss 2.2637832164764404, acc=0.4000000059604645, loss=2.2637832164764404
train: epoch 39, loss 0.21319825947284698, acc=0.9344444274902344, loss=0.21319825947284698
test: epoch 39, loss 2.098328113555908, acc=0.35277777910232544, loss=2.098328113555908
train: epoch 40, loss 0.20022830367088318, acc=0.9368333220481873, loss=0.20022830367088318
test: epoch 40, loss 2.1961240768432617, acc=0.3722222149372101, loss=2.1961240768432617
train: epoch 41, loss 0.18542061746120453, acc=0.9417222142219543, loss=0.18542061746120453
test: epoch 41, loss 2.1531786918640137, acc=0.36944442987442017, loss=2.1531786918640137
train: epoch 42, loss 0.1868116706609726, acc=0.941444456577301, loss=0.1868116706609726
test: epoch 42, loss 2.1023287773132324, acc=0.3722222149372101, loss=2.1023287773132324
train: epoch 43, loss 0.19081851840019226, acc=0.9458333253860474, loss=0.19081851840019226
test: epoch 43, loss 2.147365093231201, acc=0.3777777850627899, loss=2.147365093231201
train: epoch 44, loss 0.1871974617242813, acc=0.9421111345291138, loss=0.1871974617242813
test: epoch 44, loss 2.0350775718688965, acc=0.39722222089767456, loss=2.0350775718688965
train: epoch 45, loss 0.1814768761396408, acc=0.9450555443763733, loss=0.1814768761396408
test: epoch 45, loss 2.1949644088745117, acc=0.39444443583488464, loss=2.1949644088745117
train: epoch 46, loss 0.18285715579986572, acc=0.9436666369438171, loss=0.18285715579986572
test: epoch 46, loss 2.075002670288086, acc=0.4138889014720917, loss=2.075002670288086
train: epoch 47, loss 0.16334062814712524, acc=0.9495000243186951, loss=0.16334062814712524
test: epoch 47, loss 1.9567815065383911, acc=0.4055555462837219, loss=1.9567815065383911
train: epoch 48, loss 0.1788938194513321, acc=0.9464444518089294, loss=0.1788938194513321
test: epoch 48, loss 1.9743764400482178, acc=0.4583333432674408, loss=1.9743764400482178
train: epoch 49, loss 0.16286972165107727, acc=0.949833333492279, loss=0.16286972165107727
test: epoch 49, loss 1.9523547887802124, acc=0.4416666626930237, loss=1.9523547887802124
train: epoch 50, loss 0.1694687008857727, acc=0.9466666579246521, loss=0.1694687008857727
test: epoch 50, loss 1.8261091709136963, acc=0.42222222685813904, loss=1.8261091709136963
train: epoch 51, loss 0.17476379871368408, acc=0.9479444622993469, loss=0.17476379871368408
test: epoch 51, loss 1.9659591913223267, acc=0.4194444417953491, loss=1.9659591913223267
train: epoch 52, loss 0.15702249109745026, acc=0.9526666402816772, loss=0.15702249109745026
test: epoch 52, loss 2.1345908641815186, acc=0.41111111640930176, loss=2.1345908641815186
train: epoch 53, loss 0.16474387049674988, acc=0.9496111273765564, loss=0.16474387049674988
test: epoch 53, loss 1.8827565908432007, acc=0.4444444477558136, loss=1.8827565908432007
train: epoch 54, loss 0.17303667962551117, acc=0.9485555291175842, loss=0.17303667962551117
test: epoch 54, loss 1.7289069890975952, acc=0.44999998807907104, loss=1.7289069890975952
train: epoch 55, loss 0.15713715553283691, acc=0.9537777900695801, loss=0.15713715553283691
test: epoch 55, loss 1.7844780683517456, acc=0.4555555582046509, loss=1.7844780683517456
train: epoch 56, loss 0.15899953246116638, acc=0.9517222046852112, loss=0.15899953246116638
test: epoch 56, loss 1.8688615560531616, acc=0.45277777314186096, loss=1.8688615560531616
train: epoch 57, loss 0.15480725467205048, acc=0.9503333568572998, loss=0.15480725467205048
test: epoch 57, loss 1.8266692161560059, acc=0.4861111044883728, loss=1.8266692161560059
train: epoch 58, loss 0.1481322944164276, acc=0.9537222385406494, loss=0.1481322944164276
test: epoch 58, loss 1.8762911558151245, acc=0.45277777314186096, loss=1.8762911558151245
train: epoch 59, loss 0.16664008796215057, acc=0.9516666531562805, loss=0.16664008796215057
test: epoch 59, loss 2.1977627277374268, acc=0.4194444417953491, loss=2.1977627277374268
train: epoch 60, loss 0.14168772101402283, acc=0.9558888673782349, loss=0.14168772101402283
test: epoch 60, loss 1.7092092037200928, acc=0.46666666865348816, loss=1.7092092037200928
train: epoch 61, loss 0.15712693333625793, acc=0.9538333415985107, loss=0.15712693333625793
test: epoch 61, loss 2.067502498626709, acc=0.49444442987442017, loss=2.067502498626709
train: epoch 62, loss 0.15920719504356384, acc=0.9528889060020447, loss=0.15920719504356384
test: epoch 62, loss 1.924331545829773, acc=0.5, loss=1.924331545829773
train: epoch 63, loss 0.1520242989063263, acc=0.956333339214325, loss=0.1520242989063263
test: epoch 63, loss 1.8793033361434937, acc=0.5111111402511597, loss=1.8793033361434937
train: epoch 64, loss 0.15111924707889557, acc=0.9533888697624207, loss=0.15111924707889557
test: epoch 64, loss 1.9328352212905884, acc=0.5111111402511597, loss=1.9328352212905884
train: epoch 65, loss 0.15077899396419525, acc=0.9541110992431641, loss=0.15077899396419525
test: epoch 65, loss 1.614737629890442, acc=0.49166667461395264, loss=1.614737629890442
train: epoch 66, loss 0.12994039058685303, acc=0.9573888778686523, loss=0.12994039058685303
test: epoch 66, loss 1.9056785106658936, acc=0.47777777910232544, loss=1.9056785106658936
train: epoch 67, loss 0.1421002447605133, acc=0.9566666483879089, loss=0.1421002447605133
test: epoch 67, loss 1.678075909614563, acc=0.5166666507720947, loss=1.678075909614563
train: epoch 68, loss 0.15129977464675903, acc=0.9540555477142334, loss=0.15129977464675903
test: epoch 68, loss 1.8187123537063599, acc=0.49166667461395264, loss=1.8187123537063599
train: epoch 69, loss 0.14424727857112885, acc=0.9580000042915344, loss=0.14424727857112885
test: epoch 69, loss 1.821244716644287, acc=0.47777777910232544, loss=1.821244716644287
train: epoch 70, loss 0.1362088918685913, acc=0.9572222232818604, loss=0.1362088918685913
test: epoch 70, loss 1.7426637411117554, acc=0.4888888895511627, loss=1.7426637411117554
train: epoch 71, loss 0.13415859639644623, acc=0.9603333473205566, loss=0.13415859639644623
test: epoch 71, loss 1.5792055130004883, acc=0.5, loss=1.5792055130004883
train: epoch 72, loss 0.13313299417495728, acc=0.9601666927337646, loss=0.13313299417495728
test: epoch 72, loss 1.7488198280334473, acc=0.5083333253860474, loss=1.7488198280334473
train: epoch 73, loss 0.13091181218624115, acc=0.9590555429458618, loss=0.13091181218624115
test: epoch 73, loss 1.7253299951553345, acc=0.5277777910232544, loss=1.7253299951553345
train: epoch 74, loss 0.13250310719013214, acc=0.9598333239555359, loss=0.13250310719013214
test: epoch 74, loss 2.0348029136657715, acc=0.4555555582046509, loss=2.0348029136657715
train: epoch 75, loss 0.12608259916305542, acc=0.9614999890327454, loss=0.12608259916305542
test: epoch 75, loss 1.856110692024231, acc=0.5416666865348816, loss=1.856110692024231
train: epoch 76, loss 0.1213877722620964, acc=0.9616110920906067, loss=0.1213877722620964
test: epoch 76, loss 1.8198137283325195, acc=0.4888888895511627, loss=1.8198137283325195
train: epoch 77, loss 0.1335388720035553, acc=0.9585000276565552, loss=0.1335388720035553
test: epoch 77, loss 1.5371390581130981, acc=0.5583333373069763, loss=1.5371390581130981
train: epoch 78, loss 0.14674542844295502, acc=0.9563888907432556, loss=0.14674542844295502
test: epoch 78, loss 1.763635516166687, acc=0.5388888716697693, loss=1.763635516166687
train: epoch 79, loss 0.1247963011264801, acc=0.9605000019073486, loss=0.1247963011264801
test: epoch 79, loss 1.5672924518585205, acc=0.550000011920929, loss=1.5672924518585205
train: epoch 80, loss 0.12517821788787842, acc=0.9629999995231628, loss=0.12517821788787842
test: epoch 80, loss 1.5083447694778442, acc=0.5472221970558167, loss=1.5083447694778442
train: epoch 81, loss 0.1335620880126953, acc=0.9598888754844666, loss=0.1335620880126953
test: epoch 81, loss 1.4948091506958008, acc=0.550000011920929, loss=1.4948091506958008
train: epoch 82, loss 0.12884078919887543, acc=0.9601110816001892, loss=0.12884078919887543
test: epoch 82, loss 1.6993205547332764, acc=0.5555555820465088, loss=1.6993205547332764
train: epoch 83, loss 0.13251078128814697, acc=0.9605555534362793, loss=0.13251078128814697
test: epoch 83, loss 1.7157562971115112, acc=0.5444444417953491, loss=1.7157562971115112
train: epoch 84, loss 0.12773935496807098, acc=0.9621666669845581, loss=0.12773935496807098
test: epoch 84, loss 1.6403688192367554, acc=0.5416666865348816, loss=1.6403688192367554
train: epoch 85, loss 0.12706175446510315, acc=0.960277795791626, loss=0.12706175446510315
test: epoch 85, loss 1.6776152849197388, acc=0.5472221970558167, loss=1.6776152849197388
train: epoch 86, loss 0.11790727078914642, acc=0.9627777934074402, loss=0.11790727078914642
test: epoch 86, loss 1.5502980947494507, acc=0.6027777791023254, loss=1.5502980947494507
train: epoch 87, loss 0.12540416419506073, acc=0.9616110920906067, loss=0.12540416419506073
test: epoch 87, loss 1.6872249841690063, acc=0.5583333373069763, loss=1.6872249841690063
train: epoch 88, loss 0.12786845862865448, acc=0.961555540561676, loss=0.12786845862865448
test: epoch 88, loss 1.2979756593704224, acc=0.6166666746139526, loss=1.2979756593704224
train: epoch 89, loss 0.1225268691778183, acc=0.9598888754844666, loss=0.1225268691778183
test: epoch 89, loss 1.4606527090072632, acc=0.5888888835906982, loss=1.4606527090072632
train: epoch 90, loss 0.12623868882656097, acc=0.9627777934074402, loss=0.12623868882656097
test: epoch 90, loss 1.6028330326080322, acc=0.5694444179534912, loss=1.6028330326080322
train: epoch 91, loss 0.1329408586025238, acc=0.961555540561676, loss=0.1329408586025238
test: epoch 91, loss 1.35259211063385, acc=0.6305555701255798, loss=1.35259211063385
train: epoch 92, loss 0.1231217086315155, acc=0.9614999890327454, loss=0.1231217086315155
test: epoch 92, loss 1.4749308824539185, acc=0.5611110925674438, loss=1.4749308824539185
train: epoch 93, loss 0.12984664738178253, acc=0.96061110496521, loss=0.12984664738178253
test: epoch 93, loss 1.2580927610397339, acc=0.625, loss=1.2580927610397339
train: epoch 94, loss 0.12071169912815094, acc=0.9616666436195374, loss=0.12071169912815094
test: epoch 94, loss 1.187098503112793, acc=0.6138888597488403, loss=1.187098503112793
train: epoch 95, loss 0.1110609695315361, acc=0.9651666879653931, loss=0.1110609695315361
test: epoch 95, loss 1.339879035949707, acc=0.6527777910232544, loss=1.339879035949707
train: epoch 96, loss 0.12937991321086884, acc=0.9607222080230713, loss=0.12937991321086884
test: epoch 96, loss 1.2646079063415527, acc=0.6388888955116272, loss=1.2646079063415527
train: epoch 97, loss 0.11929774284362793, acc=0.9611111283302307, loss=0.11929774284362793
test: epoch 97, loss 1.3330963850021362, acc=0.6333333253860474, loss=1.3330963850021362
train: epoch 98, loss 0.13016080856323242, acc=0.961555540561676, loss=0.13016080856323242
test: epoch 98, loss 1.3339303731918335, acc=0.6333333253860474, loss=1.3339303731918335
train: epoch 99, loss 0.12204284965991974, acc=0.9626111388206482, loss=0.12204284965991974
test: epoch 99, loss 1.1273936033248901, acc=0.6777777671813965, loss=1.1273936033248901
train: epoch 100, loss 0.1288215070962906, acc=0.9618889093399048, loss=0.1288215070962906
test: epoch 100, loss 1.2323578596115112, acc=0.6638888716697693, loss=1.2323578596115112
train: epoch 101, loss 0.10347688943147659, acc=0.9665555357933044, loss=0.10347688943147659
test: epoch 101, loss 1.2310152053833008, acc=0.6888889074325562, loss=1.2310152053833008
train: epoch 102, loss 0.12927937507629395, acc=0.9648333191871643, loss=0.12927937507629395
test: epoch 102, loss 1.187302827835083, acc=0.6833333373069763, loss=1.187302827835083
train: epoch 103, loss 0.11953388899564743, acc=0.9638333320617676, loss=0.11953388899564743
test: epoch 103, loss 0.9918150305747986, acc=0.7027778029441833, loss=0.9918150305747986
train: epoch 104, loss 0.12459959834814072, acc=0.9607222080230713, loss=0.12459959834814072
test: epoch 104, loss 1.1701366901397705, acc=0.675000011920929, loss=1.1701366901397705
train: epoch 105, loss 0.12349417805671692, acc=0.9614444375038147, loss=0.12349417805671692
test: epoch 105, loss 1.1756479740142822, acc=0.7138888835906982, loss=1.1756479740142822
train: epoch 106, loss 0.12053965032100677, acc=0.964555561542511, loss=0.12053965032100677
test: epoch 106, loss 0.996248722076416, acc=0.7250000238418579, loss=0.996248722076416
train: epoch 107, loss 0.10941756516695023, acc=0.9626666903495789, loss=0.10941756516695023
test: epoch 107, loss 1.1709007024765015, acc=0.7111111283302307, loss=1.1709007024765015
train: epoch 108, loss 0.11709147691726685, acc=0.9633888602256775, loss=0.11709147691726685
test: epoch 108, loss 0.9944826364517212, acc=0.7166666388511658, loss=0.9944826364517212
train: epoch 109, loss 0.10838104039430618, acc=0.9649444222450256, loss=0.10838104039430618
test: epoch 109, loss 0.9977568984031677, acc=0.7333333492279053, loss=0.9977568984031677
train: epoch 110, loss 0.11550843715667725, acc=0.9631666541099548, loss=0.11550843715667725
test: epoch 110, loss 1.13044273853302, acc=0.7416666746139526, loss=1.13044273853302
train: epoch 111, loss 0.11415380984544754, acc=0.9642778038978577, loss=0.11415380984544754
test: epoch 111, loss 1.2349812984466553, acc=0.7055555582046509, loss=1.2349812984466553
train: epoch 112, loss 0.11026187241077423, acc=0.964388906955719, loss=0.11026187241077423
test: epoch 112, loss 0.9244198203086853, acc=0.7416666746139526, loss=0.9244198203086853
train: epoch 113, loss 0.11863969266414642, acc=0.9635555744171143, loss=0.11863969266414642
test: epoch 113, loss 0.9396455883979797, acc=0.7388888597488403, loss=0.9396455883979797
train: epoch 114, loss 0.1245095431804657, acc=0.961722195148468, loss=0.1245095431804657
test: epoch 114, loss 0.8546463251113892, acc=0.7388888597488403, loss=0.8546463251113892
train: epoch 115, loss 0.10997533053159714, acc=0.9632777571678162, loss=0.10997533053159714
test: epoch 115, loss 1.1043459177017212, acc=0.7166666388511658, loss=1.1043459177017212
train: epoch 116, loss 0.10674861073493958, acc=0.9659444689750671, loss=0.10674861073493958
test: epoch 116, loss 0.8051454424858093, acc=0.7916666865348816, loss=0.8051454424858093
train: epoch 117, loss 0.11474370956420898, acc=0.9640555381774902, loss=0.11474370956420898
test: epoch 117, loss 0.840501606464386, acc=0.7916666865348816, loss=0.840501606464386
train: epoch 118, loss 0.10876358300447464, acc=0.9663888812065125, loss=0.10876358300447464
test: epoch 118, loss 0.7244564890861511, acc=0.7972221970558167, loss=0.7244564890861511
train: epoch 119, loss 0.10701017826795578, acc=0.9633888602256775, loss=0.10701017826795578
test: epoch 119, loss 0.8370853066444397, acc=0.7638888955116272, loss=0.8370853066444397
train: epoch 120, loss 0.10463331639766693, acc=0.9666666388511658, loss=0.10463331639766693
test: epoch 120, loss 0.8129923939704895, acc=0.7777777910232544, loss=0.8129923939704895
train: epoch 121, loss 0.10828480869531631, acc=0.9642778038978577, loss=0.10828480869531631
test: epoch 121, loss 0.8517726063728333, acc=0.7722222208976746, loss=0.8517726063728333
train: epoch 122, loss 0.10073669254779816, acc=0.9660000205039978, loss=0.10073669254779816
test: epoch 122, loss 0.7966005206108093, acc=0.7888888716697693, loss=0.7966005206108093
train: epoch 123, loss 0.11151517927646637, acc=0.9658889174461365, loss=0.11151517927646637
test: epoch 123, loss 0.7592338919639587, acc=0.8111110925674438, loss=0.7592338919639587
train: epoch 124, loss 0.10793916136026382, acc=0.965499997138977, loss=0.10793916136026382
test: epoch 124, loss 0.6603975296020508, acc=0.8111110925674438, loss=0.6603975296020508
train: epoch 125, loss 0.11037234961986542, acc=0.9632777571678162, loss=0.11037234961986542
test: epoch 125, loss 0.6830580830574036, acc=0.7944444417953491, loss=0.6830580830574036
train: epoch 126, loss 0.09864545613527298, acc=0.9664444327354431, loss=0.09864545613527298
test: epoch 126, loss 0.5960197448730469, acc=0.8138889074325562, loss=0.5960197448730469
train: epoch 127, loss 0.10859765857458115, acc=0.964555561542511, loss=0.10859765857458115
test: epoch 127, loss 0.5924302339553833, acc=0.8055555820465088, loss=0.5924302339553833
train: epoch 128, loss 0.10901913046836853, acc=0.9664444327354431, loss=0.10901913046836853
test: epoch 128, loss 0.5910051465034485, acc=0.8333333134651184, loss=0.5910051465034485
train: epoch 129, loss 0.10778946429491043, acc=0.9671666622161865, loss=0.10778946429491043
test: epoch 129, loss 0.6893765330314636, acc=0.8277778029441833, loss=0.6893765330314636
train: epoch 130, loss 0.10796570777893066, acc=0.9668333530426025, loss=0.10796570777893066
test: epoch 130, loss 0.6470816731452942, acc=0.8111110925674438, loss=0.6470816731452942
train: epoch 131, loss 0.09616326540708542, acc=0.9682222008705139, loss=0.09616326540708542
test: epoch 131, loss 0.6053422093391418, acc=0.8388888835906982, loss=0.6053422093391418
train: epoch 132, loss 0.09176303446292877, acc=0.9676666855812073, loss=0.09176303446292877
test: epoch 132, loss 0.665074348449707, acc=0.824999988079071, loss=0.665074348449707
train: epoch 133, loss 0.10275446623563766, acc=0.9683333039283752, loss=0.10275446623563766
test: epoch 133, loss 0.6025254130363464, acc=0.8305555582046509, loss=0.6025254130363464
train: epoch 134, loss 0.10013410449028015, acc=0.9661666750907898, loss=0.10013410449028015
test: epoch 134, loss 0.493401437997818, acc=0.8472222089767456, loss=0.493401437997818
train: epoch 135, loss 0.09813348203897476, acc=0.9672777652740479, loss=0.09813348203897476
test: epoch 135, loss 0.6447762846946716, acc=0.8305555582046509, loss=0.6447762846946716
train: epoch 136, loss 0.10289362072944641, acc=0.9683333039283752, loss=0.10289362072944641
test: epoch 136, loss 0.5104796886444092, acc=0.8416666388511658, loss=0.5104796886444092
train: epoch 137, loss 0.08968965709209442, acc=0.9707777500152588, loss=0.08968965709209442
test: epoch 137, loss 0.5960497856140137, acc=0.8527777791023254, loss=0.5960497856140137
train: epoch 138, loss 0.10265813022851944, acc=0.9672222137451172, loss=0.10265813022851944
test: epoch 138, loss 0.49784427881240845, acc=0.8444444537162781, loss=0.49784427881240845
train: epoch 139, loss 0.09165915846824646, acc=0.9690555334091187, loss=0.09165915846824646
test: epoch 139, loss 0.547459602355957, acc=0.8444444537162781, loss=0.547459602355957
train: epoch 140, loss 0.08998320251703262, acc=0.9678333401679993, loss=0.08998320251703262
test: epoch 140, loss 0.4592092037200928, acc=0.8500000238418579, loss=0.4592092037200928
train: epoch 141, loss 0.08787201344966888, acc=0.9693333506584167, loss=0.08787201344966888
test: epoch 141, loss 0.6749122142791748, acc=0.8388888835906982, loss=0.6749122142791748
train: epoch 142, loss 0.08599797636270523, acc=0.9703333377838135, loss=0.08599797636270523
test: epoch 142, loss 0.5470795035362244, acc=0.855555534362793, loss=0.5470795035362244
train: epoch 143, loss 0.08574599772691727, acc=0.9695555567741394, loss=0.08574599772691727
test: epoch 143, loss 0.5355057120323181, acc=0.8611111044883728, loss=0.5355057120323181
train: epoch 144, loss 0.08436412364244461, acc=0.9707221984863281, loss=0.08436412364244461
test: epoch 144, loss 0.5202285647392273, acc=0.8638888597488403, loss=0.5202285647392273
train: epoch 145, loss 0.08561305701732635, acc=0.9695000052452087, loss=0.08561305701732635
test: epoch 145, loss 0.5925461649894714, acc=0.8388888835906982, loss=0.5925461649894714
train: epoch 146, loss 0.08665074408054352, acc=0.9693889021873474, loss=0.08665074408054352
test: epoch 146, loss 0.4551835060119629, acc=0.8611111044883728, loss=0.4551835060119629
train: epoch 147, loss 0.09281356632709503, acc=0.9683333039283752, loss=0.09281356632709503
test: epoch 147, loss 0.5036244988441467, acc=0.855555534362793, loss=0.5036244988441467
train: epoch 148, loss 0.09004411101341248, acc=0.9694444537162781, loss=0.09004411101341248
test: epoch 148, loss 0.38895824551582336, acc=0.8583333492279053, loss=0.38895824551582336
train: epoch 149, loss 0.0830332562327385, acc=0.9693333506584167, loss=0.0830332562327385
test: epoch 149, loss 0.3890708088874817, acc=0.8666666746139526, loss=0.3890708088874817
train: epoch 150, loss 0.09037230163812637, acc=0.9685555696487427, loss=0.09037230163812637
test: epoch 150, loss 0.47301357984542847, acc=0.8722222447395325, loss=0.47301357984542847
