# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=1", "--one_hot=true", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1745167825, receiver_embed_dim=64, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.2294178009033203, acc=0.071222223341465, loss=3.2294178009033203
test: epoch 1, loss 4.286828517913818, acc=0.0972222238779068, loss=4.286828517913818
train: epoch 2, loss 1.9731166362762451, acc=0.3101111054420471, loss=1.9731166362762451
test: epoch 2, loss 3.501638650894165, acc=0.14722222089767456, loss=3.501638650894165
train: epoch 3, loss 1.394498586654663, acc=0.4611666798591614, loss=1.394498586654663
test: epoch 3, loss 3.5297811031341553, acc=0.14166666567325592, loss=3.5297811031341553
train: epoch 4, loss 1.150587797164917, acc=0.5520555377006531, loss=1.150587797164917
test: epoch 4, loss 3.534166097640991, acc=0.16388888657093048, loss=3.534166097640991
train: epoch 5, loss 1.0077857971191406, acc=0.613611102104187, loss=1.0077857971191406
test: epoch 5, loss 3.744960308074951, acc=0.17777778208255768, loss=3.744960308074951
train: epoch 6, loss 0.8899891972541809, acc=0.6652222275733948, loss=0.8899891972541809
test: epoch 6, loss 3.9604175090789795, acc=0.20000000298023224, loss=3.9604175090789795
train: epoch 7, loss 0.8097164034843445, acc=0.6915000081062317, loss=0.8097164034843445
test: epoch 7, loss 3.5270063877105713, acc=0.2222222238779068, loss=3.5270063877105713
train: epoch 8, loss 0.7304245233535767, acc=0.727055549621582, loss=0.7304245233535767
test: epoch 8, loss 3.775848865509033, acc=0.2361111044883728, loss=3.775848865509033
train: epoch 9, loss 0.6728174090385437, acc=0.7530555725097656, loss=0.6728174090385437
test: epoch 9, loss 3.3810479640960693, acc=0.2361111044883728, loss=3.3810479640960693
train: epoch 10, loss 0.6402683258056641, acc=0.7720555663108826, loss=0.6402683258056641
test: epoch 10, loss 3.3348090648651123, acc=0.24444444477558136, loss=3.3348090648651123
train: epoch 11, loss 0.5866822600364685, acc=0.789555549621582, loss=0.5866822600364685
test: epoch 11, loss 3.3692750930786133, acc=0.21666666865348816, loss=3.3692750930786133
train: epoch 12, loss 0.5379678010940552, acc=0.8059999942779541, loss=0.5379678010940552
test: epoch 12, loss 3.4155216217041016, acc=0.2944444417953491, loss=3.4155216217041016
train: epoch 13, loss 0.5020366907119751, acc=0.8187222480773926, loss=0.5020366907119751
test: epoch 13, loss 3.354717493057251, acc=0.25555557012557983, loss=3.354717493057251
train: epoch 14, loss 0.47566112875938416, acc=0.8301666378974915, loss=0.47566112875938416
test: epoch 14, loss 3.554023027420044, acc=0.25, loss=3.554023027420044
train: epoch 15, loss 0.4549846947193146, acc=0.8370000123977661, loss=0.4549846947193146
test: epoch 15, loss 2.985546350479126, acc=0.2777777910232544, loss=2.985546350479126
train: epoch 16, loss 0.4197012186050415, acc=0.8539444208145142, loss=0.4197012186050415
test: epoch 16, loss 2.8603994846343994, acc=0.2666666805744171, loss=2.8603994846343994
train: epoch 17, loss 0.3976476788520813, acc=0.8610555529594421, loss=0.3976476788520813
test: epoch 17, loss 3.058682680130005, acc=0.26944443583488464, loss=3.058682680130005
train: epoch 18, loss 0.38400715589523315, acc=0.862666666507721, loss=0.38400715589523315
test: epoch 18, loss 3.0927369594573975, acc=0.2666666805744171, loss=3.0927369594573975
train: epoch 19, loss 0.37531185150146484, acc=0.871666669845581, loss=0.37531185150146484
test: epoch 19, loss 2.955495595932007, acc=0.2666666805744171, loss=2.955495595932007
train: epoch 20, loss 0.35415443778038025, acc=0.8765000104904175, loss=0.35415443778038025
test: epoch 20, loss 2.756392240524292, acc=0.31388887763023376, loss=2.756392240524292
train: epoch 21, loss 0.3309805989265442, acc=0.8853889107704163, loss=0.3309805989265442
test: epoch 21, loss 3.085502862930298, acc=0.2611111104488373, loss=3.085502862930298
train: epoch 22, loss 0.33073410391807556, acc=0.8858333230018616, loss=0.33073410391807556
test: epoch 22, loss 2.5753839015960693, acc=0.28611111640930176, loss=2.5753839015960693
train: epoch 23, loss 0.3187151253223419, acc=0.8946666717529297, loss=0.3187151253223419
test: epoch 23, loss 2.6624913215637207, acc=0.27222222089767456, loss=2.6624913215637207
train: epoch 24, loss 0.2959713637828827, acc=0.8982222080230713, loss=0.2959713637828827
test: epoch 24, loss 2.430896759033203, acc=0.3444444537162781, loss=2.430896759033203
train: epoch 25, loss 0.2778552770614624, acc=0.9028888940811157, loss=0.2778552770614624
test: epoch 25, loss 2.660078287124634, acc=0.31388887763023376, loss=2.660078287124634
train: epoch 26, loss 0.27124279737472534, acc=0.9073333144187927, loss=0.27124279737472534
test: epoch 26, loss 2.644427537918091, acc=0.3305555582046509, loss=2.644427537918091
train: epoch 27, loss 0.26263001561164856, acc=0.9081666469573975, loss=0.26263001561164856
test: epoch 27, loss 2.8138184547424316, acc=0.32777777314186096, loss=2.8138184547424316
train: epoch 28, loss 0.25857654213905334, acc=0.9120555520057678, loss=0.25857654213905334
test: epoch 28, loss 2.5828559398651123, acc=0.28333333134651184, loss=2.5828559398651123
train: epoch 29, loss 0.24383097887039185, acc=0.9155555367469788, loss=0.24383097887039185
test: epoch 29, loss 2.4371085166931152, acc=0.3305555582046509, loss=2.4371085166931152
train: epoch 30, loss 0.2366892397403717, acc=0.9188888669013977, loss=0.2366892397403717
test: epoch 30, loss 2.5353870391845703, acc=0.3027777671813965, loss=2.5353870391845703
train: epoch 31, loss 0.22883275151252747, acc=0.922166645526886, loss=0.22883275151252747
test: epoch 31, loss 2.7512259483337402, acc=0.32777777314186096, loss=2.7512259483337402
train: epoch 32, loss 0.22760243713855743, acc=0.921833336353302, loss=0.22760243713855743
test: epoch 32, loss 2.5895018577575684, acc=0.3027777671813965, loss=2.5895018577575684
train: epoch 33, loss 0.20324163138866425, acc=0.929444432258606, loss=0.20324163138866425
test: epoch 33, loss 2.8129806518554688, acc=0.3333333432674408, loss=2.8129806518554688
train: epoch 34, loss 0.1947033405303955, acc=0.9316666722297668, loss=0.1947033405303955
test: epoch 34, loss 2.741457223892212, acc=0.3305555582046509, loss=2.741457223892212
train: epoch 35, loss 0.20936672389507294, acc=0.9322222471237183, loss=0.20936672389507294
test: epoch 35, loss 2.7226693630218506, acc=0.31388887763023376, loss=2.7226693630218506
train: epoch 36, loss 0.18995939195156097, acc=0.9367222189903259, loss=0.18995939195156097
test: epoch 36, loss 2.609208583831787, acc=0.34166666865348816, loss=2.609208583831787
train: epoch 37, loss 0.18847762048244476, acc=0.9407777786254883, loss=0.18847762048244476
test: epoch 37, loss 2.341578483581543, acc=0.34166666865348816, loss=2.341578483581543
train: epoch 38, loss 0.1791658252477646, acc=0.9408888816833496, loss=0.1791658252477646
test: epoch 38, loss 2.3657338619232178, acc=0.3611111044883728, loss=2.3657338619232178
train: epoch 39, loss 0.1858820617198944, acc=0.9399444460868835, loss=0.1858820617198944
test: epoch 39, loss 2.614889621734619, acc=0.30000001192092896, loss=2.614889621734619
train: epoch 40, loss 0.17814204096794128, acc=0.9413333535194397, loss=0.17814204096794128
test: epoch 40, loss 2.6144373416900635, acc=0.3333333432674408, loss=2.6144373416900635
train: epoch 41, loss 0.16464225947856903, acc=0.9481111168861389, loss=0.16464225947856903
test: epoch 41, loss 2.461451768875122, acc=0.35277777910232544, loss=2.461451768875122
train: epoch 42, loss 0.16864506900310516, acc=0.9491111040115356, loss=0.16864506900310516
test: epoch 42, loss 2.357792615890503, acc=0.3472222089767456, loss=2.357792615890503
train: epoch 43, loss 0.15712666511535645, acc=0.9507222175598145, loss=0.15712666511535645
test: epoch 43, loss 3.037008762359619, acc=0.3027777671813965, loss=3.037008762359619
train: epoch 44, loss 0.15572404861450195, acc=0.9510555267333984, loss=0.15572404861450195
test: epoch 44, loss 2.4259495735168457, acc=0.3222222328186035, loss=2.4259495735168457
train: epoch 45, loss 0.15150822699069977, acc=0.9493333101272583, loss=0.15150822699069977
test: epoch 45, loss 2.4648549556732178, acc=0.32777777314186096, loss=2.4648549556732178
train: epoch 46, loss 0.13678650557994843, acc=0.9555000066757202, loss=0.13678650557994843
test: epoch 46, loss 2.4298512935638428, acc=0.3194444477558136, loss=2.4298512935638428
train: epoch 47, loss 0.1479577124118805, acc=0.9547777771949768, loss=0.1479577124118805
test: epoch 47, loss 2.6369383335113525, acc=0.3361110985279083, loss=2.6369383335113525
train: epoch 48, loss 0.12625335156917572, acc=0.9592221975326538, loss=0.12625335156917572
test: epoch 48, loss 2.526352643966675, acc=0.35277777910232544, loss=2.526352643966675
train: epoch 49, loss 0.13097836077213287, acc=0.9602222442626953, loss=0.13097836077213287
test: epoch 49, loss 2.51450514793396, acc=0.3333333432674408, loss=2.51450514793396
train: epoch 50, loss 0.13292255997657776, acc=0.9587222337722778, loss=0.13292255997657776
test: epoch 50, loss 2.5882651805877686, acc=0.3499999940395355, loss=2.5882651805877686
train: epoch 51, loss 0.13237184286117554, acc=0.9587777853012085, loss=0.13237184286117554
test: epoch 51, loss 2.686875581741333, acc=0.32777777314186096, loss=2.686875581741333
train: epoch 52, loss 0.12552723288536072, acc=0.9608333110809326, loss=0.12552723288536072
test: epoch 52, loss 2.5070066452026367, acc=0.33888888359069824, loss=2.5070066452026367
train: epoch 53, loss 0.11667215824127197, acc=0.9639999866485596, loss=0.11667215824127197
test: epoch 53, loss 2.8272411823272705, acc=0.3222222328186035, loss=2.8272411823272705
train: epoch 54, loss 0.11899028718471527, acc=0.964555561542511, loss=0.11899028718471527
test: epoch 54, loss 2.4905948638916016, acc=0.4027777910232544, loss=2.4905948638916016
train: epoch 55, loss 0.1087862178683281, acc=0.9657222032546997, loss=0.1087862178683281
test: epoch 55, loss 2.386354684829712, acc=0.42222222685813904, loss=2.386354684829712
train: epoch 56, loss 0.10917589068412781, acc=0.9661666750907898, loss=0.10917589068412781
test: epoch 56, loss 2.8445374965667725, acc=0.3499999940395355, loss=2.8445374965667725
train: epoch 57, loss 0.10334096848964691, acc=0.9676666855812073, loss=0.10334096848964691
test: epoch 57, loss 2.6772255897521973, acc=0.3083333373069763, loss=2.6772255897521973
train: epoch 58, loss 0.1061510443687439, acc=0.9696666598320007, loss=0.1061510443687439
test: epoch 58, loss 2.8264341354370117, acc=0.36944442987442017, loss=2.8264341354370117
train: epoch 59, loss 0.10030077397823334, acc=0.9700000286102295, loss=0.10030077397823334
test: epoch 59, loss 2.6047003269195557, acc=0.4027777910232544, loss=2.6047003269195557
train: epoch 60, loss 0.10001163184642792, acc=0.971666693687439, loss=0.10001163184642792
test: epoch 60, loss 2.559174060821533, acc=0.31388887763023376, loss=2.559174060821533
train: epoch 61, loss 0.0973617285490036, acc=0.9713333249092102, loss=0.0973617285490036
test: epoch 61, loss 2.644364833831787, acc=0.4055555462837219, loss=2.644364833831787
train: epoch 62, loss 0.09098701924085617, acc=0.9717222452163696, loss=0.09098701924085617
test: epoch 62, loss 2.6118080615997314, acc=0.36666667461395264, loss=2.6118080615997314
train: epoch 63, loss 0.08696156740188599, acc=0.9747777581214905, loss=0.08696156740188599
test: epoch 63, loss 2.4178407192230225, acc=0.41111111640930176, loss=2.4178407192230225
train: epoch 64, loss 0.09483864158391953, acc=0.9728888869285583, loss=0.09483864158391953
test: epoch 64, loss 2.8055098056793213, acc=0.3888888955116272, loss=2.8055098056793213
train: epoch 65, loss 0.09046868979930878, acc=0.9746666550636292, loss=0.09046868979930878
test: epoch 65, loss 2.4695098400115967, acc=0.3861111104488373, loss=2.4695098400115967
train: epoch 66, loss 0.08380959928035736, acc=0.9758333563804626, loss=0.08380959928035736
test: epoch 66, loss 2.538968324661255, acc=0.38333332538604736, loss=2.538968324661255
train: epoch 67, loss 0.08323568850755692, acc=0.9746666550636292, loss=0.08323568850755692
test: epoch 67, loss 2.574174642562866, acc=0.41111111640930176, loss=2.574174642562866
train: epoch 68, loss 0.07626038044691086, acc=0.9782222509384155, loss=0.07626038044691086
test: epoch 68, loss 2.3086721897125244, acc=0.4583333432674408, loss=2.3086721897125244
train: epoch 69, loss 0.07707320153713226, acc=0.9775555729866028, loss=0.07707320153713226
test: epoch 69, loss 2.5746636390686035, acc=0.36666667461395264, loss=2.5746636390686035
train: epoch 70, loss 0.08018606901168823, acc=0.9772777557373047, loss=0.08018606901168823
test: epoch 70, loss 2.7027032375335693, acc=0.375, loss=2.7027032375335693
train: epoch 71, loss 0.06941976398229599, acc=0.9783889055252075, loss=0.06941976398229599
test: epoch 71, loss 3.049990177154541, acc=0.36666667461395264, loss=3.049990177154541
train: epoch 72, loss 0.06736388802528381, acc=0.9807222485542297, loss=0.06736388802528381
test: epoch 72, loss 2.5729191303253174, acc=0.3861111104488373, loss=2.5729191303253174
train: epoch 73, loss 0.0722946897149086, acc=0.9787222146987915, loss=0.0722946897149086
test: epoch 73, loss 2.9318997859954834, acc=0.3499999940395355, loss=2.9318997859954834
train: epoch 74, loss 0.061852168291807175, acc=0.9808333516120911, loss=0.061852168291807175
test: epoch 74, loss 2.9731268882751465, acc=0.3611111044883728, loss=2.9731268882751465
train: epoch 75, loss 0.06070372089743614, acc=0.9818888902664185, loss=0.06070372089743614
test: epoch 75, loss 2.442378282546997, acc=0.41111111640930176, loss=2.442378282546997
train: epoch 76, loss 0.06068417802453041, acc=0.9822777509689331, loss=0.06068417802453041
test: epoch 76, loss 2.9617652893066406, acc=0.3583333194255829, loss=2.9617652893066406
train: epoch 77, loss 0.07203792780637741, acc=0.9796666502952576, loss=0.07203792780637741
test: epoch 77, loss 2.5605850219726562, acc=0.3861111104488373, loss=2.5605850219726562
train: epoch 78, loss 0.05941055715084076, acc=0.983222246170044, loss=0.05941055715084076
test: epoch 78, loss 2.8100850582122803, acc=0.39722222089767456, loss=2.8100850582122803
train: epoch 79, loss 0.06501083821058273, acc=0.9812222123146057, loss=0.06501083821058273
test: epoch 79, loss 2.932680368423462, acc=0.36666667461395264, loss=2.932680368423462
train: epoch 80, loss 0.05957690626382828, acc=0.9825000166893005, loss=0.05957690626382828
test: epoch 80, loss 2.7835593223571777, acc=0.375, loss=2.7835593223571777
train: epoch 81, loss 0.05918602645397186, acc=0.9832777976989746, loss=0.05918602645397186
test: epoch 81, loss 2.9202284812927246, acc=0.39722222089767456, loss=2.9202284812927246
train: epoch 82, loss 0.05753928795456886, acc=0.9815000295639038, loss=0.05753928795456886
test: epoch 82, loss 3.0703084468841553, acc=0.3888888955116272, loss=3.0703084468841553
train: epoch 83, loss 0.05485756695270538, acc=0.983222246170044, loss=0.05485756695270538
test: epoch 83, loss 2.887545585632324, acc=0.38055557012557983, loss=2.887545585632324
train: epoch 84, loss 0.05373230203986168, acc=0.9848333597183228, loss=0.05373230203986168
test: epoch 84, loss 2.61896014213562, acc=0.4166666567325592, loss=2.61896014213562
train: epoch 85, loss 0.05749381706118584, acc=0.9844444394111633, loss=0.05749381706118584
test: epoch 85, loss 3.082998275756836, acc=0.38333332538604736, loss=3.082998275756836
train: epoch 86, loss 0.05327296629548073, acc=0.9847221970558167, loss=0.05327296629548073
test: epoch 86, loss 2.9437336921691895, acc=0.39722222089767456, loss=2.9437336921691895
train: epoch 87, loss 0.06091606989502907, acc=0.9836666584014893, loss=0.06091606989502907
test: epoch 87, loss 2.558664083480835, acc=0.4194444417953491, loss=2.558664083480835
train: epoch 88, loss 0.056033164262771606, acc=0.9856666922569275, loss=0.056033164262771606
test: epoch 88, loss 2.9464774131774902, acc=0.3583333194255829, loss=2.9464774131774902
train: epoch 89, loss 0.055680930614471436, acc=0.9851666688919067, loss=0.055680930614471436
test: epoch 89, loss 2.7308034896850586, acc=0.4055555462837219, loss=2.7308034896850586
train: epoch 90, loss 0.05492321774363518, acc=0.9838333129882812, loss=0.05492321774363518
test: epoch 90, loss 2.3168153762817383, acc=0.45277777314186096, loss=2.3168153762817383
train: epoch 91, loss 0.05194712430238724, acc=0.9875555634498596, loss=0.05194712430238724
test: epoch 91, loss 2.661672353744507, acc=0.3888888955116272, loss=2.661672353744507
train: epoch 92, loss 0.048085909336805344, acc=0.9869999885559082, loss=0.048085909336805344
test: epoch 92, loss 2.821423053741455, acc=0.4277777671813965, loss=2.821423053741455
train: epoch 93, loss 0.049888767302036285, acc=0.9851666688919067, loss=0.049888767302036285
test: epoch 93, loss 3.0182323455810547, acc=0.3888888955116272, loss=3.0182323455810547
train: epoch 94, loss 0.04340560734272003, acc=0.9878888726234436, loss=0.04340560734272003
test: epoch 94, loss 2.889302968978882, acc=0.4194444417953491, loss=2.889302968978882
train: epoch 95, loss 0.0431203655898571, acc=0.9873889088630676, loss=0.0431203655898571
test: epoch 95, loss 2.894932746887207, acc=0.4749999940395355, loss=2.894932746887207
train: epoch 96, loss 0.04280434176325798, acc=0.9879444241523743, loss=0.04280434176325798
test: epoch 96, loss 2.681185483932495, acc=0.4305555522441864, loss=2.681185483932495
train: epoch 97, loss 0.051490653306245804, acc=0.9865555763244629, loss=0.051490653306245804
test: epoch 97, loss 2.9087138175964355, acc=0.3916666805744171, loss=2.9087138175964355
train: epoch 98, loss 0.04589523747563362, acc=0.9868888854980469, loss=0.04589523747563362
test: epoch 98, loss 3.0059850215911865, acc=0.4416666626930237, loss=3.0059850215911865
train: epoch 99, loss 0.04255736619234085, acc=0.987666666507721, loss=0.04255736619234085
test: epoch 99, loss 2.8762500286102295, acc=0.45277777314186096, loss=2.8762500286102295
train: epoch 100, loss 0.04651368409395218, acc=0.9863333106040955, loss=0.04651368409395218
test: epoch 100, loss 2.8802664279937744, acc=0.3611111044883728, loss=2.8802664279937744
train: epoch 101, loss 0.04060020670294762, acc=0.9884999990463257, loss=0.04060020670294762
test: epoch 101, loss 2.8979852199554443, acc=0.4305555522441864, loss=2.8979852199554443
train: epoch 102, loss 0.04831542819738388, acc=0.9885555505752563, loss=0.04831542819738388
test: epoch 102, loss 2.9427590370178223, acc=0.4277777671813965, loss=2.9427590370178223
train: epoch 103, loss 0.03412482887506485, acc=0.9903333187103271, loss=0.03412482887506485
test: epoch 103, loss 2.731884717941284, acc=0.4888888895511627, loss=2.731884717941284
train: epoch 104, loss 0.047472383826971054, acc=0.9867222309112549, loss=0.047472383826971054
test: epoch 104, loss 3.2941033840179443, acc=0.42500001192092896, loss=3.2941033840179443
train: epoch 105, loss 0.05365048721432686, acc=0.9855555295944214, loss=0.05365048721432686
test: epoch 105, loss 2.806492567062378, acc=0.4555555582046509, loss=2.806492567062378
train: epoch 106, loss 0.041049350053071976, acc=0.9892777800559998, loss=0.041049350053071976
test: epoch 106, loss 2.7115061283111572, acc=0.46666666865348816, loss=2.7115061283111572
train: epoch 107, loss 0.03830327093601227, acc=0.9896666407585144, loss=0.03830327093601227
test: epoch 107, loss 2.7375271320343018, acc=0.44999998807907104, loss=2.7375271320343018
train: epoch 108, loss 0.042745769023895264, acc=0.988277792930603, loss=0.042745769023895264
test: epoch 108, loss 2.9579713344573975, acc=0.4000000059604645, loss=2.9579713344573975
train: epoch 109, loss 0.04417799413204193, acc=0.9885555505752563, loss=0.04417799413204193
test: epoch 109, loss 2.8633968830108643, acc=0.5027777552604675, loss=2.8633968830108643
train: epoch 110, loss 0.04118920862674713, acc=0.9890000224113464, loss=0.04118920862674713
test: epoch 110, loss 2.917280912399292, acc=0.4472222328186035, loss=2.917280912399292
train: epoch 111, loss 0.03164806216955185, acc=0.9899444580078125, loss=0.03164806216955185
test: epoch 111, loss 2.6379456520080566, acc=0.4694444537162781, loss=2.6379456520080566
train: epoch 112, loss 0.036805160343647, acc=0.9893888831138611, loss=0.036805160343647
test: epoch 112, loss 2.8656182289123535, acc=0.43888887763023376, loss=2.8656182289123535
train: epoch 113, loss 0.03798994794487953, acc=0.9894444346427917, loss=0.03798994794487953
test: epoch 113, loss 2.8680241107940674, acc=0.4333333373069763, loss=2.8680241107940674
train: epoch 114, loss 0.03245507925748825, acc=0.9907777905464172, loss=0.03245507925748825
test: epoch 114, loss 3.2345967292785645, acc=0.45277777314186096, loss=3.2345967292785645
train: epoch 115, loss 0.03764556720852852, acc=0.9891111254692078, loss=0.03764556720852852
test: epoch 115, loss 3.196521043777466, acc=0.4416666626930237, loss=3.196521043777466
train: epoch 116, loss 0.0349746011197567, acc=0.9904444217681885, loss=0.0349746011197567
test: epoch 116, loss 3.125601291656494, acc=0.43611112236976624, loss=3.125601291656494
train: epoch 117, loss 0.04091905057430267, acc=0.9896110892295837, loss=0.04091905057430267
test: epoch 117, loss 2.5992605686187744, acc=0.3861111104488373, loss=2.5992605686187744
train: epoch 118, loss 0.040119897574186325, acc=0.9893888831138611, loss=0.040119897574186325
test: epoch 118, loss 3.2141129970550537, acc=0.4416666626930237, loss=3.2141129970550537
train: epoch 119, loss 0.034152302891016006, acc=0.9906111359596252, loss=0.034152302891016006
test: epoch 119, loss 3.324219226837158, acc=0.39722222089767456, loss=3.324219226837158
train: epoch 120, loss 0.03481179103255272, acc=0.9905555844306946, loss=0.03481179103255272
test: epoch 120, loss 3.045759439468384, acc=0.4749999940395355, loss=3.045759439468384
train: epoch 121, loss 0.037901654839515686, acc=0.9896666407585144, loss=0.037901654839515686
test: epoch 121, loss 3.1432106494903564, acc=0.4444444477558136, loss=3.1432106494903564
train: epoch 122, loss 0.0328562892973423, acc=0.9910555481910706, loss=0.0328562892973423
test: epoch 122, loss 2.906435489654541, acc=0.4583333432674408, loss=2.906435489654541
train: epoch 123, loss 0.03282893821597099, acc=0.9908888936042786, loss=0.03282893821597099
test: epoch 123, loss 3.1373372077941895, acc=0.5111111402511597, loss=3.1373372077941895
train: epoch 124, loss 0.03643330559134483, acc=0.9892222285270691, loss=0.03643330559134483
test: epoch 124, loss 2.7112085819244385, acc=0.46388888359069824, loss=2.7112085819244385
train: epoch 125, loss 0.026642348617315292, acc=0.992888867855072, loss=0.026642348617315292
test: epoch 125, loss 2.764589548110962, acc=0.5083333253860474, loss=2.764589548110962
train: epoch 126, loss 0.031457751989364624, acc=0.9904999732971191, loss=0.031457751989364624
test: epoch 126, loss 3.056194543838501, acc=0.4194444417953491, loss=3.056194543838501
train: epoch 127, loss 0.03651988133788109, acc=0.9897778034210205, loss=0.03651988133788109
test: epoch 127, loss 2.8911099433898926, acc=0.4583333432674408, loss=2.8911099433898926
train: epoch 128, loss 0.028208620846271515, acc=0.992222249507904, loss=0.028208620846271515
test: epoch 128, loss 2.821526050567627, acc=0.4694444537162781, loss=2.821526050567627
train: epoch 129, loss 0.030448930338025093, acc=0.9913333058357239, loss=0.030448930338025093
test: epoch 129, loss 2.8831658363342285, acc=0.4749999940395355, loss=2.8831658363342285
train: epoch 130, loss 0.0369509756565094, acc=0.9894444346427917, loss=0.0369509756565094
test: epoch 130, loss 3.234147787094116, acc=0.4444444477558136, loss=3.234147787094116
train: epoch 131, loss 0.029539579525589943, acc=0.9912222027778625, loss=0.029539579525589943
test: epoch 131, loss 2.892007827758789, acc=0.45277777314186096, loss=2.892007827758789
train: epoch 132, loss 0.03345759958028793, acc=0.9917222261428833, loss=0.03345759958028793
test: epoch 132, loss 2.8028595447540283, acc=0.49166667461395264, loss=2.8028595447540283
train: epoch 133, loss 0.037154365330934525, acc=0.9901111125946045, loss=0.037154365330934525
test: epoch 133, loss 3.235736608505249, acc=0.44999998807907104, loss=3.235736608505249
train: epoch 134, loss 0.036732856184244156, acc=0.9897778034210205, loss=0.036732856184244156
test: epoch 134, loss 3.3288614749908447, acc=0.45277777314186096, loss=3.3288614749908447
train: epoch 135, loss 0.029122209176421165, acc=0.992388904094696, loss=0.029122209176421165
test: epoch 135, loss 3.505154848098755, acc=0.4583333432674408, loss=3.505154848098755
train: epoch 136, loss 0.0317528061568737, acc=0.9916666746139526, loss=0.0317528061568737
test: epoch 136, loss 3.3083925247192383, acc=0.47777777910232544, loss=3.3083925247192383
train: epoch 137, loss 0.02732422761619091, acc=0.9931111335754395, loss=0.02732422761619091
test: epoch 137, loss 3.065502643585205, acc=0.47777777910232544, loss=3.065502643585205
train: epoch 138, loss 0.033468130975961685, acc=0.9912777543067932, loss=0.033468130975961685
test: epoch 138, loss 2.5504310131073, acc=0.4277777671813965, loss=2.5504310131073
train: epoch 139, loss 0.02182508073747158, acc=0.9941111207008362, loss=0.02182508073747158
test: epoch 139, loss 3.087608575820923, acc=0.4722222089767456, loss=3.087608575820923
train: epoch 140, loss 0.03504607081413269, acc=0.9908888936042786, loss=0.03504607081413269
test: epoch 140, loss 3.1632704734802246, acc=0.4694444537162781, loss=3.1632704734802246
train: epoch 141, loss 0.031174466013908386, acc=0.9913889169692993, loss=0.031174466013908386
test: epoch 141, loss 3.3552510738372803, acc=0.49166667461395264, loss=3.3552510738372803
train: epoch 142, loss 0.028778497129678726, acc=0.9926666617393494, loss=0.028778497129678726
test: epoch 142, loss 2.7783565521240234, acc=0.5083333253860474, loss=2.7783565521240234
train: epoch 143, loss 0.032407622784376144, acc=0.9918888807296753, loss=0.032407622784376144
test: epoch 143, loss 2.9163734912872314, acc=0.44999998807907104, loss=2.9163734912872314
train: epoch 144, loss 0.03227285295724869, acc=0.9923333525657654, loss=0.03227285295724869
test: epoch 144, loss 2.8780901432037354, acc=0.46388888359069824, loss=2.8780901432037354
train: epoch 145, loss 0.031526755541563034, acc=0.9909444451332092, loss=0.031526755541563034
test: epoch 145, loss 2.8938961029052734, acc=0.4861111044883728, loss=2.8938961029052734
train: epoch 146, loss 0.028620844706892967, acc=0.9915000200271606, loss=0.028620844706892967
test: epoch 146, loss 2.830899715423584, acc=0.5027777552604675, loss=2.830899715423584
train: epoch 147, loss 0.030835993587970734, acc=0.9920555353164673, loss=0.030835993587970734
test: epoch 147, loss 2.8661255836486816, acc=0.5222222208976746, loss=2.8661255836486816
train: epoch 148, loss 0.026555022224783897, acc=0.9928333163261414, loss=0.026555022224783897
test: epoch 148, loss 3.110476493835449, acc=0.4861111044883728, loss=3.110476493835449
train: epoch 149, loss 0.027391478419303894, acc=0.9919999837875366, loss=0.027391478419303894
test: epoch 149, loss 3.184744119644165, acc=0.47777777910232544, loss=3.184744119644165
train: epoch 150, loss 0.025585133582353592, acc=0.99272221326828, loss=0.025585133582353592
test: epoch 150, loss 3.5515198707580566, acc=0.4694444537162781, loss=3.5515198707580566
