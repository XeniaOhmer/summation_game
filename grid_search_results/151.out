# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=true", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1512146713, receiver_embed_dim=128, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.6506967544555664, acc=0.12950000166893005, loss=2.6506967544555664
test: epoch 1, loss 5.894921779632568, acc=0.08611111342906952, loss=5.894921779632568
train: epoch 2, loss 1.3850880861282349, acc=0.44611111283302307, loss=1.3850880861282349
test: epoch 2, loss 3.7672431468963623, acc=0.18611110746860504, loss=3.7672431468963623
train: epoch 3, loss 0.8082132935523987, acc=0.6764444708824158, loss=0.8082132935523987
test: epoch 3, loss 3.2380521297454834, acc=0.22499999403953552, loss=3.2380521297454834
train: epoch 4, loss 0.5716457962989807, acc=0.7785555720329285, loss=0.5716457962989807
test: epoch 4, loss 2.631730318069458, acc=0.28611111640930176, loss=2.631730318069458
train: epoch 5, loss 0.4641086161136627, acc=0.8214444518089294, loss=0.4641086161136627
test: epoch 5, loss 3.0014684200286865, acc=0.2611111104488373, loss=3.0014684200286865
train: epoch 6, loss 0.39529019594192505, acc=0.8489444255828857, loss=0.39529019594192505
test: epoch 6, loss 2.510927438735962, acc=0.2750000059604645, loss=2.510927438735962
train: epoch 7, loss 0.342497855424881, acc=0.8770555257797241, loss=0.342497855424881
test: epoch 7, loss 2.123596668243408, acc=0.30000001192092896, loss=2.123596668243408
train: epoch 8, loss 0.3018184304237366, acc=0.8879444599151611, loss=0.3018184304237366
test: epoch 8, loss 2.748462200164795, acc=0.2777777910232544, loss=2.748462200164795
train: epoch 9, loss 0.289231538772583, acc=0.894444465637207, loss=0.289231538772583
test: epoch 9, loss 3.2768983840942383, acc=0.3638888895511627, loss=3.2768983840942383
train: epoch 10, loss 0.25792086124420166, acc=0.9076111316680908, loss=0.25792086124420166
test: epoch 10, loss 2.0218262672424316, acc=0.36666667461395264, loss=2.0218262672424316
train: epoch 11, loss 0.23251745104789734, acc=0.9172222018241882, loss=0.23251745104789734
test: epoch 11, loss 1.9053494930267334, acc=0.3777777850627899, loss=1.9053494930267334
train: epoch 12, loss 0.22187970578670502, acc=0.9206110835075378, loss=0.22187970578670502
test: epoch 12, loss 2.074906826019287, acc=0.3722222149372101, loss=2.074906826019287
train: epoch 13, loss 0.19785593450069427, acc=0.9317777752876282, loss=0.19785593450069427
test: epoch 13, loss 2.3998515605926514, acc=0.4583333432674408, loss=2.3998515605926514
train: epoch 14, loss 0.19259513914585114, acc=0.9338889122009277, loss=0.19259513914585114
test: epoch 14, loss 1.5511741638183594, acc=0.4555555582046509, loss=1.5511741638183594
train: epoch 15, loss 0.16638094186782837, acc=0.9433333277702332, loss=0.16638094186782837
test: epoch 15, loss 2.1122281551361084, acc=0.4722222089767456, loss=2.1122281551361084
train: epoch 16, loss 0.18108506500720978, acc=0.9377222061157227, loss=0.18108506500720978
test: epoch 16, loss 1.9491997957229614, acc=0.4749999940395355, loss=1.9491997957229614
train: epoch 17, loss 0.1724967062473297, acc=0.9406111240386963, loss=0.1724967062473297
test: epoch 17, loss 1.7620022296905518, acc=0.4722222089767456, loss=1.7620022296905518
train: epoch 18, loss 0.1686834841966629, acc=0.941611111164093, loss=0.1686834841966629
test: epoch 18, loss 1.646234154701233, acc=0.49166667461395264, loss=1.646234154701233
train: epoch 19, loss 0.15492869913578033, acc=0.9473888874053955, loss=0.15492869913578033
test: epoch 19, loss 2.0765676498413086, acc=0.4305555522441864, loss=2.0765676498413086
train: epoch 20, loss 0.1414806991815567, acc=0.9502778053283691, loss=0.1414806991815567
test: epoch 20, loss 1.5377717018127441, acc=0.5277777910232544, loss=1.5377717018127441
train: epoch 21, loss 0.14088723063468933, acc=0.9520555734634399, loss=0.14088723063468933
test: epoch 21, loss 1.8227241039276123, acc=0.4972222149372101, loss=1.8227241039276123
train: epoch 22, loss 0.1402774602174759, acc=0.9525555372238159, loss=0.1402774602174759
test: epoch 22, loss 1.615378499031067, acc=0.5472221970558167, loss=1.615378499031067
train: epoch 23, loss 0.12983711063861847, acc=0.9553889036178589, loss=0.12983711063861847
test: epoch 23, loss 2.048689603805542, acc=0.5416666865348816, loss=2.048689603805542
train: epoch 24, loss 0.13601186871528625, acc=0.9546111226081848, loss=0.13601186871528625
test: epoch 24, loss 1.4148002862930298, acc=0.5694444179534912, loss=1.4148002862930298
train: epoch 25, loss 0.12055718898773193, acc=0.9599999785423279, loss=0.12055718898773193
test: epoch 25, loss 1.821405053138733, acc=0.5083333253860474, loss=1.821405053138733
train: epoch 26, loss 0.11828761547803879, acc=0.9618333578109741, loss=0.11828761547803879
test: epoch 26, loss 1.9237428903579712, acc=0.5138888955116272, loss=1.9237428903579712
train: epoch 27, loss 0.11966854333877563, acc=0.9616110920906067, loss=0.11966854333877563
test: epoch 27, loss 1.5627248287200928, acc=0.5416666865348816, loss=1.5627248287200928
train: epoch 28, loss 0.11870329827070236, acc=0.9614999890327454, loss=0.11870329827070236
test: epoch 28, loss 1.4385044574737549, acc=0.5805555582046509, loss=1.4385044574737549
train: epoch 29, loss 0.11418962478637695, acc=0.9627777934074402, loss=0.11418962478637695
test: epoch 29, loss 1.3629547357559204, acc=0.5555555820465088, loss=1.3629547357559204
train: epoch 30, loss 0.09971131384372711, acc=0.9665555357933044, loss=0.09971131384372711
test: epoch 30, loss 1.6277353763580322, acc=0.5527777671813965, loss=1.6277353763580322
train: epoch 31, loss 0.10712536424398422, acc=0.9646111130714417, loss=0.10712536424398422
test: epoch 31, loss 1.6037509441375732, acc=0.5249999761581421, loss=1.6037509441375732
train: epoch 32, loss 0.09947573393583298, acc=0.9676666855812073, loss=0.09947573393583298
test: epoch 32, loss 1.5407493114471436, acc=0.5888888835906982, loss=1.5407493114471436
train: epoch 33, loss 0.1024705171585083, acc=0.9667778015136719, loss=0.1024705171585083
test: epoch 33, loss 2.042987108230591, acc=0.5361111164093018, loss=2.042987108230591
train: epoch 34, loss 0.0969691127538681, acc=0.9680555462837219, loss=0.0969691127538681
test: epoch 34, loss 1.4545657634735107, acc=0.6111111044883728, loss=1.4545657634735107
train: epoch 35, loss 0.08738966286182404, acc=0.9728888869285583, loss=0.08738966286182404
test: epoch 35, loss 1.3163154125213623, acc=0.6305555701255798, loss=1.3163154125213623
train: epoch 36, loss 0.07997552305459976, acc=0.9733889102935791, loss=0.07997552305459976
test: epoch 36, loss 1.1399030685424805, acc=0.730555534362793, loss=1.1399030685424805
train: epoch 37, loss 0.09819337725639343, acc=0.9677777886390686, loss=0.09819337725639343
test: epoch 37, loss 1.3727080821990967, acc=0.6277777552604675, loss=1.3727080821990967
train: epoch 38, loss 0.07194509357213974, acc=0.97688889503479, loss=0.07194509357213974
test: epoch 38, loss 1.2867262363433838, acc=0.6277777552604675, loss=1.2867262363433838
train: epoch 39, loss 0.08588995784521103, acc=0.9724444150924683, loss=0.08588995784521103
test: epoch 39, loss 1.4883555173873901, acc=0.5444444417953491, loss=1.4883555173873901
train: epoch 40, loss 0.09263171255588531, acc=0.9710555672645569, loss=0.09263171255588531
test: epoch 40, loss 1.327032446861267, acc=0.5888888835906982, loss=1.327032446861267
train: epoch 41, loss 0.07560673356056213, acc=0.9768333435058594, loss=0.07560673356056213
test: epoch 41, loss 1.0204203128814697, acc=0.7027778029441833, loss=1.0204203128814697
train: epoch 42, loss 0.08010683208703995, acc=0.9745000004768372, loss=0.08010683208703995
test: epoch 42, loss 1.0010956525802612, acc=0.7055555582046509, loss=1.0010956525802612
train: epoch 43, loss 0.07153855264186859, acc=0.9779444336891174, loss=0.07153855264186859
test: epoch 43, loss 1.0011422634124756, acc=0.7194444537162781, loss=1.0011422634124756
train: epoch 44, loss 0.06904755532741547, acc=0.9779999852180481, loss=0.06904755532741547
test: epoch 44, loss 0.8986901640892029, acc=0.7333333492279053, loss=0.8986901640892029
train: epoch 45, loss 0.06508662551641464, acc=0.9788333177566528, loss=0.06508662551641464
test: epoch 45, loss 0.9402644634246826, acc=0.7250000238418579, loss=0.9402644634246826
train: epoch 46, loss 0.0876401886343956, acc=0.9730555415153503, loss=0.0876401886343956
test: epoch 46, loss 1.2499529123306274, acc=0.7222222089767456, loss=1.2499529123306274
train: epoch 47, loss 0.06915554404258728, acc=0.9790555834770203, loss=0.06915554404258728
test: epoch 47, loss 0.8467139601707458, acc=0.7472222447395325, loss=0.8467139601707458
train: epoch 48, loss 0.0639026090502739, acc=0.9797222018241882, loss=0.0639026090502739
test: epoch 48, loss 0.640415608882904, acc=0.75, loss=0.640415608882904
train: epoch 49, loss 0.05904398858547211, acc=0.9816111326217651, loss=0.05904398858547211
test: epoch 49, loss 1.0895378589630127, acc=0.7111111283302307, loss=1.0895378589630127
train: epoch 50, loss 0.05556252598762512, acc=0.983222246170044, loss=0.05556252598762512
test: epoch 50, loss 0.9781421422958374, acc=0.7472222447395325, loss=0.9781421422958374
train: epoch 51, loss 0.0645318254828453, acc=0.9792777895927429, loss=0.0645318254828453
test: epoch 51, loss 0.8052226901054382, acc=0.7833333611488342, loss=0.8052226901054382
train: epoch 52, loss 0.06250004470348358, acc=0.980555534362793, loss=0.06250004470348358
test: epoch 52, loss 0.5979089140892029, acc=0.8416666388511658, loss=0.5979089140892029
train: epoch 53, loss 0.05227703973650932, acc=0.9847777485847473, loss=0.05227703973650932
test: epoch 53, loss 0.6908767819404602, acc=0.7833333611488342, loss=0.6908767819404602
train: epoch 54, loss 0.04681190475821495, acc=0.9859444499015808, loss=0.04681190475821495
test: epoch 54, loss 0.7083507776260376, acc=0.8500000238418579, loss=0.7083507776260376
train: epoch 55, loss 0.06552782654762268, acc=0.9804999828338623, loss=0.06552782654762268
test: epoch 55, loss 0.5863788723945618, acc=0.8583333492279053, loss=0.5863788723945618
train: epoch 56, loss 0.06172148510813713, acc=0.9815555810928345, loss=0.06172148510813713
test: epoch 56, loss 0.5328563451766968, acc=0.894444465637207, loss=0.5328563451766968
train: epoch 57, loss 0.047066450119018555, acc=0.9856666922569275, loss=0.047066450119018555
test: epoch 57, loss 0.3511706292629242, acc=0.9277777671813965, loss=0.3511706292629242
train: epoch 58, loss 0.04570695757865906, acc=0.9868888854980469, loss=0.04570695757865906
test: epoch 58, loss 0.35264718532562256, acc=0.9277777671813965, loss=0.35264718532562256
train: epoch 59, loss 0.04204225167632103, acc=0.9872778058052063, loss=0.04204225167632103
test: epoch 59, loss 0.3317086398601532, acc=0.925000011920929, loss=0.3317086398601532
train: epoch 60, loss 0.04933639243245125, acc=0.9856666922569275, loss=0.04933639243245125
test: epoch 60, loss 0.2719587981700897, acc=0.925000011920929, loss=0.2719587981700897
train: epoch 61, loss 0.04136006534099579, acc=0.9880555272102356, loss=0.04136006534099579
test: epoch 61, loss 0.2774414122104645, acc=0.9388889074325562, loss=0.2774414122104645
train: epoch 62, loss 0.04920442774891853, acc=0.9867222309112549, loss=0.04920442774891853
test: epoch 62, loss 0.2065380960702896, acc=0.9527778029441833, loss=0.2065380960702896
train: epoch 63, loss 0.02590152807533741, acc=0.9925000071525574, loss=0.02590152807533741
test: epoch 63, loss 0.2610805332660675, acc=0.9527778029441833, loss=0.2610805332660675
train: epoch 64, loss 0.041393570601940155, acc=0.9892222285270691, loss=0.041393570601940155
test: epoch 64, loss 0.11448803544044495, acc=0.9527778029441833, loss=0.11448803544044495
train: epoch 65, loss 0.032411929219961166, acc=0.9903888702392578, loss=0.032411929219961166
test: epoch 65, loss 0.2236633002758026, acc=0.949999988079071, loss=0.2236633002758026
train: epoch 66, loss 0.031295597553253174, acc=0.9901111125946045, loss=0.031295597553253174
test: epoch 66, loss 0.19001473486423492, acc=0.9527778029441833, loss=0.19001473486423492
train: epoch 67, loss 0.03451138734817505, acc=0.9898889064788818, loss=0.03451138734817505
test: epoch 67, loss 0.1788049340248108, acc=0.9527778029441833, loss=0.1788049340248108
train: epoch 68, loss 0.038782209157943726, acc=0.9888333082199097, loss=0.038782209157943726
test: epoch 68, loss 0.15417826175689697, acc=0.949999988079071, loss=0.15417826175689697
train: epoch 69, loss 0.04056961461901665, acc=0.9892777800559998, loss=0.04056961461901665
test: epoch 69, loss 0.19594985246658325, acc=0.949999988079071, loss=0.19594985246658325
train: epoch 70, loss 0.024472568184137344, acc=0.9919999837875366, loss=0.024472568184137344
test: epoch 70, loss 0.1872643381357193, acc=0.9527778029441833, loss=0.1872643381357193
train: epoch 71, loss 0.04004918783903122, acc=0.988111138343811, loss=0.04004918783903122
test: epoch 71, loss 0.14867080748081207, acc=0.9527778029441833, loss=0.14867080748081207
train: epoch 72, loss 0.030706575140357018, acc=0.9915555715560913, loss=0.030706575140357018
test: epoch 72, loss 0.20127347111701965, acc=0.9527778029441833, loss=0.20127347111701965
train: epoch 73, loss 0.03938290476799011, acc=0.9902777671813965, loss=0.03938290476799011
test: epoch 73, loss 0.1625276356935501, acc=0.9527778029441833, loss=0.1625276356935501
train: epoch 74, loss 0.03760925307869911, acc=0.9892777800559998, loss=0.03760925307869911
test: epoch 74, loss 0.19988670945167542, acc=0.9527778029441833, loss=0.19988670945167542
train: epoch 75, loss 0.02893124148249626, acc=0.992111086845398, loss=0.02893124148249626
test: epoch 75, loss 0.20839397609233856, acc=0.9527778029441833, loss=0.20839397609233856
train: epoch 76, loss 0.03169833496212959, acc=0.9910555481910706, loss=0.03169833496212959
test: epoch 76, loss 0.24026793241500854, acc=0.9527778029441833, loss=0.24026793241500854
train: epoch 77, loss 0.039944589138031006, acc=0.9897778034210205, loss=0.039944589138031006
test: epoch 77, loss 0.17976298928260803, acc=0.9527778029441833, loss=0.17976298928260803
train: epoch 78, loss 0.026417652145028114, acc=0.9919999837875366, loss=0.026417652145028114
test: epoch 78, loss 0.18289414048194885, acc=0.9555555582046509, loss=0.18289414048194885
train: epoch 79, loss 0.037757210433483124, acc=0.9901111125946045, loss=0.037757210433483124
test: epoch 79, loss 0.14626440405845642, acc=0.9527778029441833, loss=0.14626440405845642
train: epoch 80, loss 0.023484842851758003, acc=0.9913889169692993, loss=0.023484842851758003
test: epoch 80, loss 0.13533982634544373, acc=0.9527778029441833, loss=0.13533982634544373
train: epoch 81, loss 0.027139099314808846, acc=0.9916666746139526, loss=0.027139099314808846
test: epoch 81, loss 0.19654719531536102, acc=0.9527778029441833, loss=0.19654719531536102
train: epoch 82, loss 0.02290261536836624, acc=0.9918888807296753, loss=0.02290261536836624
test: epoch 82, loss 0.1297677457332611, acc=0.9527778029441833, loss=0.1297677457332611
train: epoch 83, loss 0.019319530576467514, acc=0.9937777519226074, loss=0.019319530576467514
test: epoch 83, loss 0.1978062093257904, acc=0.9527778029441833, loss=0.1978062093257904
train: epoch 84, loss 0.029670681804418564, acc=0.9912777543067932, loss=0.029670681804418564
test: epoch 84, loss 0.16470010578632355, acc=0.9527778029441833, loss=0.16470010578632355
train: epoch 85, loss 0.04633292928338051, acc=0.9893888831138611, loss=0.04633292928338051
test: epoch 85, loss 0.29068541526794434, acc=0.9361110925674438, loss=0.29068541526794434
train: epoch 86, loss 0.04686129093170166, acc=0.9880555272102356, loss=0.04686129093170166
test: epoch 86, loss 0.2819993495941162, acc=0.949999988079071, loss=0.2819993495941162
train: epoch 87, loss 0.03374131768941879, acc=0.9897778034210205, loss=0.03374131768941879
test: epoch 87, loss 0.2773778438568115, acc=0.949999988079071, loss=0.2773778438568115
train: epoch 88, loss 0.03671424835920334, acc=0.9893888831138611, loss=0.03671424835920334
test: epoch 88, loss 0.21464641392230988, acc=0.949999988079071, loss=0.21464641392230988
train: epoch 89, loss 0.024884236976504326, acc=0.9936666488647461, loss=0.024884236976504326
test: epoch 89, loss 0.144779235124588, acc=0.9527778029441833, loss=0.144779235124588
train: epoch 90, loss 0.032851267606019974, acc=0.9911666512489319, loss=0.032851267606019974
test: epoch 90, loss 0.23751267790794373, acc=0.9527778029441833, loss=0.23751267790794373
train: epoch 91, loss 0.024768970906734467, acc=0.992555558681488, loss=0.024768970906734467
test: epoch 91, loss 0.22022974491119385, acc=0.9527778029441833, loss=0.22022974491119385
train: epoch 92, loss 0.03177432343363762, acc=0.988611102104187, loss=0.03177432343363762
test: epoch 92, loss 0.16640354692935944, acc=0.9527778029441833, loss=0.16640354692935944
train: epoch 93, loss 0.027222484350204468, acc=0.99272221326828, loss=0.027222484350204468
test: epoch 93, loss 0.24643433094024658, acc=0.9555555582046509, loss=0.24643433094024658
train: epoch 94, loss 0.02397778630256653, acc=0.9932222366333008, loss=0.02397778630256653
test: epoch 94, loss 0.1445256769657135, acc=0.9527778029441833, loss=0.1445256769657135
train: epoch 95, loss 0.0321568064391613, acc=0.9912777543067932, loss=0.0321568064391613
test: epoch 95, loss 0.26742634177207947, acc=0.949999988079071, loss=0.26742634177207947
train: epoch 96, loss 0.0327674001455307, acc=0.9902777671813965, loss=0.0327674001455307
test: epoch 96, loss 0.2125578671693802, acc=0.949999988079071, loss=0.2125578671693802
train: epoch 97, loss 0.05361248180270195, acc=0.9877777695655823, loss=0.05361248180270195
test: epoch 97, loss 0.22501613199710846, acc=0.949999988079071, loss=0.22501613199710846
train: epoch 98, loss 0.037702277302742004, acc=0.9887222051620483, loss=0.037702277302742004
test: epoch 98, loss 0.20661944150924683, acc=0.949999988079071, loss=0.20661944150924683
train: epoch 99, loss 0.029112886637449265, acc=0.9911110997200012, loss=0.029112886637449265
test: epoch 99, loss 0.1907026171684265, acc=0.949999988079071, loss=0.1907026171684265
train: epoch 100, loss 0.026189729571342468, acc=0.9920555353164673, loss=0.026189729571342468
test: epoch 100, loss 0.20496627688407898, acc=0.9555555582046509, loss=0.20496627688407898
train: epoch 101, loss 0.027474677190184593, acc=0.99272221326828, loss=0.027474677190184593
test: epoch 101, loss 0.21534030139446259, acc=0.9527778029441833, loss=0.21534030139446259
train: epoch 102, loss 0.028965558856725693, acc=0.9915000200271606, loss=0.028965558856725693
test: epoch 102, loss 0.18705393373966217, acc=0.9527778029441833, loss=0.18705393373966217
train: epoch 103, loss 0.026966165751218796, acc=0.9921666383743286, loss=0.026966165751218796
test: epoch 103, loss 0.20435020327568054, acc=0.9527778029441833, loss=0.20435020327568054
train: epoch 104, loss 0.02783980593085289, acc=0.9927777647972107, loss=0.02783980593085289
test: epoch 104, loss 0.15371090173721313, acc=0.9527778029441833, loss=0.15371090173721313
train: epoch 105, loss 0.02517860196530819, acc=0.9929999709129333, loss=0.02517860196530819
test: epoch 105, loss 0.2661207914352417, acc=0.9527778029441833, loss=0.2661207914352417
train: epoch 106, loss 0.024573998525738716, acc=0.9928333163261414, loss=0.024573998525738716
test: epoch 106, loss 0.12349099665880203, acc=0.9555555582046509, loss=0.12349099665880203
train: epoch 107, loss 0.01979910023510456, acc=0.9937777519226074, loss=0.01979910023510456
test: epoch 107, loss 0.1992877870798111, acc=0.9527778029441833, loss=0.1992877870798111
train: epoch 108, loss 0.026808300986886024, acc=0.992388904094696, loss=0.026808300986886024
test: epoch 108, loss 0.150502011179924, acc=0.9527778029441833, loss=0.150502011179924
train: epoch 109, loss 0.026668408885598183, acc=0.9923333525657654, loss=0.026668408885598183
test: epoch 109, loss 0.1985226422548294, acc=0.9444444179534912, loss=0.1985226422548294
train: epoch 110, loss 0.02699170634150505, acc=0.9926666617393494, loss=0.02699170634150505
test: epoch 110, loss 0.16822999715805054, acc=0.9527778029441833, loss=0.16822999715805054
train: epoch 111, loss 0.021468734368681908, acc=0.9931111335754395, loss=0.021468734368681908
test: epoch 111, loss 0.19399309158325195, acc=0.9527778029441833, loss=0.19399309158325195
train: epoch 112, loss 0.026842497289180756, acc=0.9931666851043701, loss=0.026842497289180756
test: epoch 112, loss 0.20090605318546295, acc=0.9527778029441833, loss=0.20090605318546295
train: epoch 113, loss 0.02007800154387951, acc=0.9935555458068848, loss=0.02007800154387951
test: epoch 113, loss 0.18067920207977295, acc=0.9527778029441833, loss=0.18067920207977295
train: epoch 114, loss 0.0242549367249012, acc=0.992555558681488, loss=0.0242549367249012
test: epoch 114, loss 0.21764934062957764, acc=0.9527778029441833, loss=0.21764934062957764
train: epoch 115, loss 0.023540636524558067, acc=0.9932222366333008, loss=0.023540636524558067
test: epoch 115, loss 0.18415027856826782, acc=0.9527778029441833, loss=0.18415027856826782
train: epoch 116, loss 0.02957288548350334, acc=0.9928333163261414, loss=0.02957288548350334
test: epoch 116, loss 0.15961313247680664, acc=0.9527778029441833, loss=0.15961313247680664
train: epoch 117, loss 0.017381925135850906, acc=0.9942777752876282, loss=0.017381925135850906
test: epoch 117, loss 0.21495495736598969, acc=0.9527778029441833, loss=0.21495495736598969
train: epoch 118, loss 0.030959419906139374, acc=0.992388904094696, loss=0.030959419906139374
test: epoch 118, loss 0.13880062103271484, acc=0.9527778029441833, loss=0.13880062103271484
train: epoch 119, loss 0.017544753849506378, acc=0.9938889145851135, loss=0.017544753849506378
test: epoch 119, loss 0.20501473546028137, acc=0.9527778029441833, loss=0.20501473546028137
train: epoch 120, loss 0.0258534774184227, acc=0.9920555353164673, loss=0.0258534774184227
test: epoch 120, loss 0.20547522604465485, acc=0.9527778029441833, loss=0.20547522604465485
train: epoch 121, loss 0.02872289903461933, acc=0.9925000071525574, loss=0.02872289903461933
test: epoch 121, loss 0.21306511759757996, acc=0.9527778029441833, loss=0.21306511759757996
train: epoch 122, loss 0.02196520008146763, acc=0.9934444427490234, loss=0.02196520008146763
test: epoch 122, loss 0.14777135848999023, acc=0.9527778029441833, loss=0.14777135848999023
train: epoch 123, loss 0.018368028104305267, acc=0.9940555691719055, loss=0.018368028104305267
test: epoch 123, loss 0.1691172868013382, acc=0.9527778029441833, loss=0.1691172868013382
train: epoch 124, loss 0.024233728647232056, acc=0.9929444193840027, loss=0.024233728647232056
test: epoch 124, loss 0.14783050119876862, acc=0.9527778029441833, loss=0.14783050119876862
train: epoch 125, loss 0.01852729171514511, acc=0.9939444661140442, loss=0.01852729171514511
test: epoch 125, loss 0.2084939330816269, acc=0.9527778029441833, loss=0.2084939330816269
train: epoch 126, loss 0.03430594876408577, acc=0.991777777671814, loss=0.03430594876408577
test: epoch 126, loss 0.2751809060573578, acc=0.9444444179534912, loss=0.2751809060573578
train: epoch 127, loss 0.020398791879415512, acc=0.9933333396911621, loss=0.020398791879415512
test: epoch 127, loss 0.24418462812900543, acc=0.9527778029441833, loss=0.24418462812900543
train: epoch 128, loss 0.02655836194753647, acc=0.99272221326828, loss=0.02655836194753647
test: epoch 128, loss 0.10401857644319534, acc=0.9527778029441833, loss=0.10401857644319534
train: epoch 129, loss 0.024753442034125328, acc=0.992888867855072, loss=0.024753442034125328
test: epoch 129, loss 0.17892920970916748, acc=0.9527778029441833, loss=0.17892920970916748
train: epoch 130, loss 0.022055165842175484, acc=0.9929444193840027, loss=0.022055165842175484
test: epoch 130, loss 0.189139261841774, acc=0.9527778029441833, loss=0.189139261841774
train: epoch 131, loss 0.027678336948156357, acc=0.992222249507904, loss=0.027678336948156357
test: epoch 131, loss 0.16336551308631897, acc=0.9527778029441833, loss=0.16336551308631897
train: epoch 132, loss 0.019823892042040825, acc=0.9936666488647461, loss=0.019823892042040825
test: epoch 132, loss 0.20413413643836975, acc=0.9527778029441833, loss=0.20413413643836975
train: epoch 133, loss 0.026354551315307617, acc=0.992555558681488, loss=0.026354551315307617
test: epoch 133, loss 0.1575319916009903, acc=0.9527778029441833, loss=0.1575319916009903
train: epoch 134, loss 0.02639864571392536, acc=0.992888867855072, loss=0.02639864571392536
test: epoch 134, loss 0.20772849023342133, acc=0.9527778029441833, loss=0.20772849023342133
train: epoch 135, loss 0.035805586725473404, acc=0.9924444556236267, loss=0.035805586725473404
test: epoch 135, loss 0.26127520203590393, acc=0.9527778029441833, loss=0.26127520203590393
train: epoch 136, loss 0.027784012258052826, acc=0.9932222366333008, loss=0.027784012258052826
test: epoch 136, loss 0.1820446103811264, acc=0.9527778029441833, loss=0.1820446103811264
train: epoch 137, loss 0.018856381997466087, acc=0.9944444298744202, loss=0.018856381997466087
test: epoch 137, loss 0.22218281030654907, acc=0.9611111283302307, loss=0.22218281030654907
train: epoch 138, loss 0.020333359017968178, acc=0.9941111207008362, loss=0.020333359017968178
test: epoch 138, loss 0.15023088455200195, acc=0.9611111283302307, loss=0.15023088455200195
train: epoch 139, loss 0.020416157320141792, acc=0.9944999814033508, loss=0.020416157320141792
test: epoch 139, loss 0.18245135247707367, acc=0.9611111283302307, loss=0.18245135247707367
train: epoch 140, loss 0.01615923084318638, acc=0.9948333501815796, loss=0.01615923084318638
test: epoch 140, loss 0.20384174585342407, acc=0.9611111283302307, loss=0.20384174585342407
train: epoch 141, loss 0.03184911981225014, acc=0.992388904094696, loss=0.03184911981225014
test: epoch 141, loss 0.13247963786125183, acc=0.9583333134651184, loss=0.13247963786125183
train: epoch 142, loss 0.026784872636198997, acc=0.9916666746139526, loss=0.026784872636198997
test: epoch 142, loss 0.22013279795646667, acc=0.9583333134651184, loss=0.22013279795646667
train: epoch 143, loss 0.03437088429927826, acc=0.9909999966621399, loss=0.03437088429927826
test: epoch 143, loss 0.13511411845684052, acc=0.9583333134651184, loss=0.13511411845684052
train: epoch 144, loss 0.02429754100739956, acc=0.992888867855072, loss=0.02429754100739956
test: epoch 144, loss 0.1276583969593048, acc=0.9583333134651184, loss=0.1276583969593048
train: epoch 145, loss 0.036530155688524246, acc=0.9910555481910706, loss=0.036530155688524246
test: epoch 145, loss 0.17352554202079773, acc=0.9583333134651184, loss=0.17352554202079773
train: epoch 146, loss 0.02644241228699684, acc=0.9916666746139526, loss=0.02644241228699684
test: epoch 146, loss 0.1346103698015213, acc=0.9611111283302307, loss=0.1346103698015213
train: epoch 147, loss 0.03959628939628601, acc=0.9906111359596252, loss=0.03959628939628601
test: epoch 147, loss 0.17129895091056824, acc=0.9583333134651184, loss=0.17129895091056824
train: epoch 148, loss 0.03577110543847084, acc=0.9894444346427917, loss=0.03577110543847084
test: epoch 148, loss 0.2221038043498993, acc=0.9527778029441833, loss=0.2221038043498993
train: epoch 149, loss 0.041601940989494324, acc=0.988611102104187, loss=0.041601940989494324
test: epoch 149, loss 0.1882387399673462, acc=0.9555555582046509, loss=0.1882387399673462
train: epoch 150, loss 0.043430134654045105, acc=0.9902777671813965, loss=0.043430134654045105
test: epoch 150, loss 0.17779897153377533, acc=0.9583333134651184, loss=0.17779897153377533
