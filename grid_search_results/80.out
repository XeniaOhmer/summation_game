# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=true", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1171816828, receiver_embed_dim=64, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.9156603813171387, acc=0.09011111408472061, loss=2.9156603813171387
test: epoch 1, loss 3.5091824531555176, acc=0.0972222238779068, loss=3.5091824531555176
train: epoch 2, loss 2.0529489517211914, acc=0.20749999582767487, loss=2.0529489517211914
test: epoch 2, loss 2.7487897872924805, acc=0.15833333134651184, loss=2.7487897872924805
train: epoch 3, loss 1.7393375635147095, acc=0.29427778720855713, loss=1.7393375635147095
test: epoch 3, loss 2.513786554336548, acc=0.1944444477558136, loss=2.513786554336548
train: epoch 4, loss 1.3627876043319702, acc=0.4408888816833496, loss=1.3627876043319702
test: epoch 4, loss 2.8643548488616943, acc=0.22499999403953552, loss=2.8643548488616943
train: epoch 5, loss 1.1513609886169434, acc=0.5130555629730225, loss=1.1513609886169434
test: epoch 5, loss 2.8847317695617676, acc=0.2611111104488373, loss=2.8847317695617676
train: epoch 6, loss 0.9484109878540039, acc=0.605055570602417, loss=0.9484109878540039
test: epoch 6, loss 1.9371883869171143, acc=0.3777777850627899, loss=1.9371883869171143
train: epoch 7, loss 0.7889042496681213, acc=0.6782777905464172, loss=0.7889042496681213
test: epoch 7, loss 1.7697601318359375, acc=0.3861111104488373, loss=1.7697601318359375
train: epoch 8, loss 0.6514267325401306, acc=0.7415000200271606, loss=0.6514267325401306
test: epoch 8, loss 1.5102404356002808, acc=0.4583333432674408, loss=1.5102404356002808
train: epoch 9, loss 0.562231183052063, acc=0.7716666460037231, loss=0.562231183052063
test: epoch 9, loss 1.272790551185608, acc=0.5333333611488342, loss=1.272790551185608
train: epoch 10, loss 0.4979921877384186, acc=0.7981666922569275, loss=0.4979921877384186
test: epoch 10, loss 1.3971012830734253, acc=0.5083333253860474, loss=1.3971012830734253
train: epoch 11, loss 0.4693160653114319, acc=0.8054444193840027, loss=0.4693160653114319
test: epoch 11, loss 1.0352457761764526, acc=0.5944444537162781, loss=1.0352457761764526
train: epoch 12, loss 0.4417119026184082, acc=0.8196666836738586, loss=0.4417119026184082
test: epoch 12, loss 1.3128352165222168, acc=0.5388888716697693, loss=1.3128352165222168
train: epoch 13, loss 0.37241432070732117, acc=0.8486111164093018, loss=0.37241432070732117
test: epoch 13, loss 1.3799992799758911, acc=0.5638889074325562, loss=1.3799992799758911
train: epoch 14, loss 0.36202460527420044, acc=0.8554444313049316, loss=0.36202460527420044
test: epoch 14, loss 1.0198156833648682, acc=0.5972222089767456, loss=1.0198156833648682
train: epoch 15, loss 0.31965479254722595, acc=0.8725000023841858, loss=0.31965479254722595
test: epoch 15, loss 1.4163198471069336, acc=0.519444465637207, loss=1.4163198471069336
train: epoch 16, loss 0.3183002769947052, acc=0.8732222318649292, loss=0.3183002769947052
test: epoch 16, loss 1.1544843912124634, acc=0.5611110925674438, loss=1.1544843912124634
train: epoch 17, loss 0.304741770029068, acc=0.8747222423553467, loss=0.304741770029068
test: epoch 17, loss 1.1764857769012451, acc=0.5861111283302307, loss=1.1764857769012451
train: epoch 18, loss 0.3047253489494324, acc=0.8769444227218628, loss=0.3047253489494324
test: epoch 18, loss 0.9030365347862244, acc=0.6138888597488403, loss=0.9030365347862244
train: epoch 19, loss 0.27423667907714844, acc=0.8886666893959045, loss=0.27423667907714844
test: epoch 19, loss 0.8358071446418762, acc=0.6388888955116272, loss=0.8358071446418762
train: epoch 20, loss 0.2813640534877777, acc=0.8839444518089294, loss=0.2813640534877777
test: epoch 20, loss 0.9526610970497131, acc=0.699999988079071, loss=0.9526610970497131
train: epoch 21, loss 0.27233999967575073, acc=0.8864444494247437, loss=0.27233999967575073
test: epoch 21, loss 0.8142176270484924, acc=0.7055555582046509, loss=0.8142176270484924
train: epoch 22, loss 0.2299758344888687, acc=0.8956111073493958, loss=0.2299758344888687
test: epoch 22, loss 1.2601735591888428, acc=0.644444465637207, loss=1.2601735591888428
train: epoch 23, loss 0.25840702652931213, acc=0.8901110887527466, loss=0.25840702652931213
test: epoch 23, loss 0.8079721331596375, acc=0.6944444179534912, loss=0.8079721331596375
train: epoch 24, loss 0.263060599565506, acc=0.8952222466468811, loss=0.263060599565506
test: epoch 24, loss 1.2591078281402588, acc=0.6666666865348816, loss=1.2591078281402588
train: epoch 25, loss 0.23938116431236267, acc=0.9005555510520935, loss=0.23938116431236267
test: epoch 25, loss 0.8414615392684937, acc=0.7111111283302307, loss=0.8414615392684937
train: epoch 26, loss 0.23041124641895294, acc=0.9041110873222351, loss=0.23041124641895294
test: epoch 26, loss 0.9658682942390442, acc=0.7194444537162781, loss=0.9658682942390442
train: epoch 27, loss 0.2344747930765152, acc=0.9019444584846497, loss=0.2344747930765152
test: epoch 27, loss 0.8195410966873169, acc=0.6916666626930237, loss=0.8195410966873169
train: epoch 28, loss 0.23927521705627441, acc=0.8954444527626038, loss=0.23927521705627441
test: epoch 28, loss 0.9508407711982727, acc=0.7194444537162781, loss=0.9508407711982727
train: epoch 29, loss 0.21524177491664886, acc=0.9062222242355347, loss=0.21524177491664886
test: epoch 29, loss 0.7190830707550049, acc=0.7444444298744202, loss=0.7190830707550049
train: epoch 30, loss 0.24943958222866058, acc=0.9005555510520935, loss=0.24943958222866058
test: epoch 30, loss 0.6693353652954102, acc=0.7805555462837219, loss=0.6693353652954102
train: epoch 31, loss 0.20324034988880157, acc=0.9085555672645569, loss=0.20324034988880157
test: epoch 31, loss 0.6511685848236084, acc=0.7555555701255798, loss=0.6511685848236084
train: epoch 32, loss 0.24031758308410645, acc=0.9003888964653015, loss=0.24031758308410645
test: epoch 32, loss 0.5721713304519653, acc=0.7805555462837219, loss=0.5721713304519653
train: epoch 33, loss 0.21560293436050415, acc=0.9052777886390686, loss=0.21560293436050415
test: epoch 33, loss 0.7648425102233887, acc=0.730555534362793, loss=0.7648425102233887
train: epoch 34, loss 0.21461360156536102, acc=0.9070555567741394, loss=0.21461360156536102
test: epoch 34, loss 0.7486655712127686, acc=0.7444444298744202, loss=0.7486655712127686
train: epoch 35, loss 0.23159077763557434, acc=0.9049999713897705, loss=0.23159077763557434
test: epoch 35, loss 0.7973782420158386, acc=0.7361111044883728, loss=0.7973782420158386
train: epoch 36, loss 0.1935853809118271, acc=0.9168888926506042, loss=0.1935853809118271
test: epoch 36, loss 0.6893138885498047, acc=0.7361111044883728, loss=0.6893138885498047
train: epoch 37, loss 0.20565617084503174, acc=0.9107221961021423, loss=0.20565617084503174
test: epoch 37, loss 0.6805758476257324, acc=0.7638888955116272, loss=0.6805758476257324
train: epoch 38, loss 0.21845296025276184, acc=0.907444417476654, loss=0.21845296025276184
test: epoch 38, loss 0.6121084690093994, acc=0.7666666507720947, loss=0.6121084690093994
train: epoch 39, loss 0.20374993979930878, acc=0.9153333306312561, loss=0.20374993979930878
test: epoch 39, loss 0.6255187392234802, acc=0.8083333373069763, loss=0.6255187392234802
train: epoch 40, loss 0.20008274912834167, acc=0.914555549621582, loss=0.20008274912834167
test: epoch 40, loss 0.790359616279602, acc=0.7833333611488342, loss=0.790359616279602
train: epoch 41, loss 0.1765378713607788, acc=0.9185555577278137, loss=0.1765378713607788
test: epoch 41, loss 0.6733109354972839, acc=0.7861111164093018, loss=0.6733109354972839
train: epoch 42, loss 0.2044665813446045, acc=0.9114444255828857, loss=0.2044665813446045
test: epoch 42, loss 0.6553561687469482, acc=0.8055555820465088, loss=0.6553561687469482
train: epoch 43, loss 0.1872672736644745, acc=0.9225000143051147, loss=0.1872672736644745
test: epoch 43, loss 0.6372900605201721, acc=0.7944444417953491, loss=0.6372900605201721
train: epoch 44, loss 0.19790023565292358, acc=0.9190555810928345, loss=0.19790023565292358
test: epoch 44, loss 0.6054753065109253, acc=0.8166666626930237, loss=0.6054753065109253
train: epoch 45, loss 0.17511296272277832, acc=0.9258888959884644, loss=0.17511296272277832
test: epoch 45, loss 0.6103116273880005, acc=0.8027777671813965, loss=0.6103116273880005
train: epoch 46, loss 0.20058967173099518, acc=0.9200555682182312, loss=0.20058967173099518
test: epoch 46, loss 0.5565540790557861, acc=0.8138889074325562, loss=0.5565540790557861
train: epoch 47, loss 0.18320658802986145, acc=0.9189444184303284, loss=0.18320658802986145
test: epoch 47, loss 0.5763041377067566, acc=0.8138889074325562, loss=0.5763041377067566
train: epoch 48, loss 0.1781965047121048, acc=0.921500027179718, loss=0.1781965047121048
test: epoch 48, loss 0.752556562423706, acc=0.7833333611488342, loss=0.752556562423706
train: epoch 49, loss 0.16732189059257507, acc=0.9244444370269775, loss=0.16732189059257507
test: epoch 49, loss 0.6529653072357178, acc=0.8166666626930237, loss=0.6529653072357178
train: epoch 50, loss 0.17941851913928986, acc=0.9225555658340454, loss=0.17941851913928986
test: epoch 50, loss 0.6166853904724121, acc=0.8166666626930237, loss=0.6166853904724121
train: epoch 51, loss 0.1833171397447586, acc=0.9224444627761841, loss=0.1833171397447586
test: epoch 51, loss 0.5942219495773315, acc=0.7972221970558167, loss=0.5942219495773315
train: epoch 52, loss 0.1712762862443924, acc=0.9287222027778625, loss=0.1712762862443924
test: epoch 52, loss 0.7960889339447021, acc=0.7972221970558167, loss=0.7960889339447021
train: epoch 53, loss 0.19507160782814026, acc=0.9177777767181396, loss=0.19507160782814026
test: epoch 53, loss 0.5861223340034485, acc=0.8166666626930237, loss=0.5861223340034485
train: epoch 54, loss 0.16658557951450348, acc=0.9277222156524658, loss=0.16658557951450348
test: epoch 54, loss 0.5728914141654968, acc=0.8055555820465088, loss=0.5728914141654968
train: epoch 55, loss 0.19960759580135345, acc=0.913444459438324, loss=0.19960759580135345
test: epoch 55, loss 0.6591846346855164, acc=0.7972221970558167, loss=0.6591846346855164
train: epoch 56, loss 0.17792777717113495, acc=0.9196666479110718, loss=0.17792777717113495
test: epoch 56, loss 0.5940003395080566, acc=0.8111110925674438, loss=0.5940003395080566
train: epoch 57, loss 0.188412144780159, acc=0.9224444627761841, loss=0.188412144780159
test: epoch 57, loss 0.5600754618644714, acc=0.8111110925674438, loss=0.5600754618644714
train: epoch 58, loss 0.16137848794460297, acc=0.9288889169692993, loss=0.16137848794460297
test: epoch 58, loss 0.6246892213821411, acc=0.8138889074325562, loss=0.6246892213821411
train: epoch 59, loss 0.16505417227745056, acc=0.9243333339691162, loss=0.16505417227745056
test: epoch 59, loss 0.7330402135848999, acc=0.8083333373069763, loss=0.7330402135848999
train: epoch 60, loss 0.16188053786754608, acc=0.9253333210945129, loss=0.16188053786754608
test: epoch 60, loss 0.7010037302970886, acc=0.8166666626930237, loss=0.7010037302970886
train: epoch 61, loss 0.1726687103509903, acc=0.9264444708824158, loss=0.1726687103509903
test: epoch 61, loss 0.605254054069519, acc=0.8138889074325562, loss=0.605254054069519
train: epoch 62, loss 0.16966025531291962, acc=0.9197777509689331, loss=0.16966025531291962
test: epoch 62, loss 0.6538053750991821, acc=0.8166666626930237, loss=0.6538053750991821
train: epoch 63, loss 0.15202413499355316, acc=0.9244999885559082, loss=0.15202413499355316
test: epoch 63, loss 0.6615257263183594, acc=0.800000011920929, loss=0.6615257263183594
train: epoch 64, loss 0.17965944111347198, acc=0.9190555810928345, loss=0.17965944111347198
test: epoch 64, loss 0.6154057383537292, acc=0.8138889074325562, loss=0.6154057383537292
train: epoch 65, loss 0.16504909098148346, acc=0.9234444499015808, loss=0.16504909098148346
test: epoch 65, loss 0.5410522222518921, acc=0.8138889074325562, loss=0.5410522222518921
train: epoch 66, loss 0.16927208006381989, acc=0.9242777824401855, loss=0.16927208006381989
test: epoch 66, loss 0.5993790030479431, acc=0.8166666626930237, loss=0.5993790030479431
train: epoch 67, loss 0.15448252856731415, acc=0.9330000281333923, loss=0.15448252856731415
test: epoch 67, loss 0.6723331212997437, acc=0.8138889074325562, loss=0.6723331212997437
train: epoch 68, loss 0.15064974129199982, acc=0.9304444193840027, loss=0.15064974129199982
test: epoch 68, loss 0.6589603424072266, acc=0.8138889074325562, loss=0.6589603424072266
train: epoch 69, loss 0.1756124645471573, acc=0.922166645526886, loss=0.1756124645471573
test: epoch 69, loss 0.6577994227409363, acc=0.7916666865348816, loss=0.6577994227409363
train: epoch 70, loss 0.17473351955413818, acc=0.925166666507721, loss=0.17473351955413818
test: epoch 70, loss 0.6091298460960388, acc=0.8166666626930237, loss=0.6091298460960388
train: epoch 71, loss 0.16691964864730835, acc=0.9247221946716309, loss=0.16691964864730835
test: epoch 71, loss 0.588271975517273, acc=0.8166666626930237, loss=0.588271975517273
train: epoch 72, loss 0.15832675993442535, acc=0.926277756690979, loss=0.15832675993442535
test: epoch 72, loss 0.6754468679428101, acc=0.8166666626930237, loss=0.6754468679428101
train: epoch 73, loss 0.1643393635749817, acc=0.9297778010368347, loss=0.1643393635749817
test: epoch 73, loss 0.6479965448379517, acc=0.8166666626930237, loss=0.6479965448379517
train: epoch 74, loss 0.16791710257530212, acc=0.9290000200271606, loss=0.16791710257530212
test: epoch 74, loss 0.7404993772506714, acc=0.7916666865348816, loss=0.7404993772506714
train: epoch 75, loss 0.1851147711277008, acc=0.9220555424690247, loss=0.1851147711277008
test: epoch 75, loss 0.60187166929245, acc=0.8138889074325562, loss=0.60187166929245
train: epoch 76, loss 0.16335684061050415, acc=0.9254999756813049, loss=0.16335684061050415
test: epoch 76, loss 0.6034193634986877, acc=0.8166666626930237, loss=0.6034193634986877
train: epoch 77, loss 0.15659619867801666, acc=0.9308888912200928, loss=0.15659619867801666
test: epoch 77, loss 0.6319466829299927, acc=0.8083333373069763, loss=0.6319466829299927
train: epoch 78, loss 0.13961723446846008, acc=0.9315555691719055, loss=0.13961723446846008
test: epoch 78, loss 0.7471256256103516, acc=0.8083333373069763, loss=0.7471256256103516
train: epoch 79, loss 0.17939169704914093, acc=0.9220555424690247, loss=0.17939169704914093
test: epoch 79, loss 0.639220118522644, acc=0.8166666626930237, loss=0.639220118522644
train: epoch 80, loss 0.15401285886764526, acc=0.9279444217681885, loss=0.15401285886764526
test: epoch 80, loss 0.6357539892196655, acc=0.7916666865348816, loss=0.6357539892196655
train: epoch 81, loss 0.14429651200771332, acc=0.9316666722297668, loss=0.14429651200771332
test: epoch 81, loss 0.4709840714931488, acc=0.8138889074325562, loss=0.4709840714931488
train: epoch 82, loss 0.16450145840644836, acc=0.9302777647972107, loss=0.16450145840644836
test: epoch 82, loss 0.7851780652999878, acc=0.8111110925674438, loss=0.7851780652999878
train: epoch 83, loss 0.15822917222976685, acc=0.9255555272102356, loss=0.15822917222976685
test: epoch 83, loss 0.6531703472137451, acc=0.8027777671813965, loss=0.6531703472137451
train: epoch 84, loss 0.16969594359397888, acc=0.9231666922569275, loss=0.16969594359397888
test: epoch 84, loss 0.5978061556816101, acc=0.7972221970558167, loss=0.5978061556816101
train: epoch 85, loss 0.18033133447170258, acc=0.9254999756813049, loss=0.18033133447170258
test: epoch 85, loss 0.6898288726806641, acc=0.7861111164093018, loss=0.6898288726806641
train: epoch 86, loss 0.15694080293178558, acc=0.92894446849823, loss=0.15694080293178558
test: epoch 86, loss 0.883653461933136, acc=0.7861111164093018, loss=0.883653461933136
train: epoch 87, loss 0.16082851588726044, acc=0.9267777800559998, loss=0.16082851588726044
test: epoch 87, loss 0.5317685604095459, acc=0.8111110925674438, loss=0.5317685604095459
train: epoch 88, loss 0.15893666446208954, acc=0.9311666488647461, loss=0.15893666446208954
test: epoch 88, loss 0.743903398513794, acc=0.7888888716697693, loss=0.743903398513794
train: epoch 89, loss 0.13926444947719574, acc=0.930388867855072, loss=0.13926444947719574
test: epoch 89, loss 0.6265650391578674, acc=0.8166666626930237, loss=0.6265650391578674
train: epoch 90, loss 0.18358346819877625, acc=0.9273889064788818, loss=0.18358346819877625
test: epoch 90, loss 0.5538004636764526, acc=0.8138889074325562, loss=0.5538004636764526
train: epoch 91, loss 0.15570920705795288, acc=0.9305555820465088, loss=0.15570920705795288
test: epoch 91, loss 0.5726521611213684, acc=0.8111110925674438, loss=0.5726521611213684
train: epoch 92, loss 0.15765635669231415, acc=0.92894446849823, loss=0.15765635669231415
test: epoch 92, loss 0.6947129368782043, acc=0.8166666626930237, loss=0.6947129368782043
train: epoch 93, loss 0.13077126443386078, acc=0.9365000128746033, loss=0.13077126443386078
test: epoch 93, loss 0.657149612903595, acc=0.8166666626930237, loss=0.657149612903595
train: epoch 94, loss 0.18649841845035553, acc=0.9245555400848389, loss=0.18649841845035553
test: epoch 94, loss 0.7080780267715454, acc=0.7833333611488342, loss=0.7080780267715454
train: epoch 95, loss 0.15757763385772705, acc=0.9278888702392578, loss=0.15757763385772705
test: epoch 95, loss 0.6361854672431946, acc=0.8111110925674438, loss=0.6361854672431946
train: epoch 96, loss 0.15836487710475922, acc=0.9282777905464172, loss=0.15836487710475922
test: epoch 96, loss 0.6406289935112, acc=0.8138889074325562, loss=0.6406289935112
train: epoch 97, loss 0.1713121235370636, acc=0.9238888621330261, loss=0.1713121235370636
test: epoch 97, loss 0.7547416687011719, acc=0.8083333373069763, loss=0.7547416687011719
train: epoch 98, loss 0.1770859658718109, acc=0.9229444265365601, loss=0.1770859658718109
test: epoch 98, loss 0.47747689485549927, acc=0.8138889074325562, loss=0.47747689485549927
train: epoch 99, loss 0.1376785784959793, acc=0.9355555772781372, loss=0.1376785784959793
test: epoch 99, loss 0.7598575353622437, acc=0.7861111164093018, loss=0.7598575353622437
train: epoch 100, loss 0.1582249402999878, acc=0.9330000281333923, loss=0.1582249402999878
test: epoch 100, loss 0.6325900554656982, acc=0.8166666626930237, loss=0.6325900554656982
train: epoch 101, loss 0.13847538828849792, acc=0.9362778067588806, loss=0.13847538828849792
test: epoch 101, loss 0.549011766910553, acc=0.8083333373069763, loss=0.549011766910553
train: epoch 102, loss 0.2044319361448288, acc=0.9244999885559082, loss=0.2044319361448288
test: epoch 102, loss 0.5267499685287476, acc=0.7916666865348816, loss=0.5267499685287476
train: epoch 103, loss 0.166389599442482, acc=0.9260555505752563, loss=0.166389599442482
test: epoch 103, loss 0.7077150940895081, acc=0.8111110925674438, loss=0.7077150940895081
train: epoch 104, loss 0.15722905099391937, acc=0.9319999814033508, loss=0.15722905099391937
test: epoch 104, loss 0.626474142074585, acc=0.8166666626930237, loss=0.626474142074585
train: epoch 105, loss 0.1363474428653717, acc=0.9349444508552551, loss=0.1363474428653717
test: epoch 105, loss 0.8735733032226562, acc=0.800000011920929, loss=0.8735733032226562
train: epoch 106, loss 0.18823735415935516, acc=0.9228333234786987, loss=0.18823735415935516
test: epoch 106, loss 0.7491767406463623, acc=0.8083333373069763, loss=0.7491767406463623
train: epoch 107, loss 0.18024487793445587, acc=0.92166668176651, loss=0.18024487793445587
test: epoch 107, loss 0.5604642629623413, acc=0.8138889074325562, loss=0.5604642629623413
train: epoch 108, loss 0.1747693568468094, acc=0.9264444708824158, loss=0.1747693568468094
test: epoch 108, loss 0.535352349281311, acc=0.8083333373069763, loss=0.535352349281311
train: epoch 109, loss 0.14807796478271484, acc=0.9322777986526489, loss=0.14807796478271484
test: epoch 109, loss 0.5610754489898682, acc=0.8138889074325562, loss=0.5610754489898682
train: epoch 110, loss 0.16241705417633057, acc=0.9308333396911621, loss=0.16241705417633057
test: epoch 110, loss 0.6152327656745911, acc=0.8138889074325562, loss=0.6152327656745911
train: epoch 111, loss 0.15039311349391937, acc=0.9313889145851135, loss=0.15039311349391937
test: epoch 111, loss 0.5889598727226257, acc=0.8138889074325562, loss=0.5889598727226257
train: epoch 112, loss 0.1580428183078766, acc=0.929611086845398, loss=0.1580428183078766
test: epoch 112, loss 0.5336916446685791, acc=0.8083333373069763, loss=0.5336916446685791
train: epoch 113, loss 0.18767106533050537, acc=0.9198333621025085, loss=0.18767106533050537
test: epoch 113, loss 0.7651509642601013, acc=0.8111110925674438, loss=0.7651509642601013
train: epoch 114, loss 0.17271754145622253, acc=0.9279444217681885, loss=0.17271754145622253
test: epoch 114, loss 0.6103261709213257, acc=0.8083333373069763, loss=0.6103261709213257
train: epoch 115, loss 0.17150765657424927, acc=0.9271110892295837, loss=0.17150765657424927
test: epoch 115, loss 0.5949622988700867, acc=0.8083333373069763, loss=0.5949622988700867
train: epoch 116, loss 0.17956143617630005, acc=0.9258333444595337, loss=0.17956143617630005
test: epoch 116, loss 0.48010051250457764, acc=0.8111110925674438, loss=0.48010051250457764
train: epoch 117, loss 0.21252252161502838, acc=0.9230555295944214, loss=0.21252252161502838
test: epoch 117, loss 0.42141878604888916, acc=0.8055555820465088, loss=0.42141878604888916
train: epoch 118, loss 0.18038909137248993, acc=0.9298333525657654, loss=0.18038909137248993
test: epoch 118, loss 0.7408524751663208, acc=0.7777777910232544, loss=0.7408524751663208
train: epoch 119, loss 0.1633291095495224, acc=0.9267222285270691, loss=0.1633291095495224
test: epoch 119, loss 0.46532678604125977, acc=0.8138889074325562, loss=0.46532678604125977
train: epoch 120, loss 0.16477879881858826, acc=0.9307222366333008, loss=0.16477879881858826
test: epoch 120, loss 0.6286851167678833, acc=0.8138889074325562, loss=0.6286851167678833
train: epoch 121, loss 0.17556405067443848, acc=0.9264444708824158, loss=0.17556405067443848
test: epoch 121, loss 0.567316472530365, acc=0.8111110925674438, loss=0.567316472530365
train: epoch 122, loss 0.1627095341682434, acc=0.9275000095367432, loss=0.1627095341682434
test: epoch 122, loss 0.6098604798316956, acc=0.8138889074325562, loss=0.6098604798316956
train: epoch 123, loss 0.17715616524219513, acc=0.9283333420753479, loss=0.17715616524219513
test: epoch 123, loss 0.5966843366622925, acc=0.8111110925674438, loss=0.5966843366622925
train: epoch 124, loss 0.17555904388427734, acc=0.9274444580078125, loss=0.17555904388427734
test: epoch 124, loss 0.6370205283164978, acc=0.8111110925674438, loss=0.6370205283164978
train: epoch 125, loss 0.13930459320545197, acc=0.9348888993263245, loss=0.13930459320545197
test: epoch 125, loss 0.5964068174362183, acc=0.8194444179534912, loss=0.5964068174362183
train: epoch 126, loss 0.15949752926826477, acc=0.933055579662323, loss=0.15949752926826477
test: epoch 126, loss 0.6213619112968445, acc=0.8111110925674438, loss=0.6213619112968445
train: epoch 127, loss 0.1744305044412613, acc=0.9285555481910706, loss=0.1744305044412613
test: epoch 127, loss 0.5976840257644653, acc=0.8111110925674438, loss=0.5976840257644653
train: epoch 128, loss 0.214375838637352, acc=0.9214444160461426, loss=0.214375838637352
test: epoch 128, loss 0.4985019862651825, acc=0.8111110925674438, loss=0.4985019862651825
train: epoch 129, loss 0.17457450926303864, acc=0.9280555844306946, loss=0.17457450926303864
test: epoch 129, loss 0.6723276376724243, acc=0.8055555820465088, loss=0.6723276376724243
train: epoch 130, loss 0.18414117395877838, acc=0.9268333315849304, loss=0.18414117395877838
test: epoch 130, loss 0.6902549266815186, acc=0.8111110925674438, loss=0.6902549266815186
train: epoch 131, loss 0.17099235951900482, acc=0.9279444217681885, loss=0.17099235951900482
test: epoch 131, loss 0.5573171973228455, acc=0.8111110925674438, loss=0.5573171973228455
train: epoch 132, loss 0.1755305677652359, acc=0.9281111359596252, loss=0.1755305677652359
test: epoch 132, loss 0.5838857293128967, acc=0.8083333373069763, loss=0.5838857293128967
train: epoch 133, loss 0.18103347718715668, acc=0.9282777905464172, loss=0.18103347718715668
test: epoch 133, loss 0.5254586935043335, acc=0.8111110925674438, loss=0.5254586935043335
train: epoch 134, loss 0.18439973890781403, acc=0.9266666769981384, loss=0.18439973890781403
test: epoch 134, loss 0.5474069714546204, acc=0.8138889074325562, loss=0.5474069714546204
train: epoch 135, loss 0.18460315465927124, acc=0.9268333315849304, loss=0.18460315465927124
test: epoch 135, loss 0.6891162395477295, acc=0.8083333373069763, loss=0.6891162395477295
train: epoch 136, loss 0.18233171105384827, acc=0.9234444499015808, loss=0.18233171105384827
test: epoch 136, loss 0.5838297009468079, acc=0.8111110925674438, loss=0.5838297009468079
train: epoch 137, loss 0.1725796014070511, acc=0.9264444708824158, loss=0.1725796014070511
test: epoch 137, loss 0.6455604434013367, acc=0.8111110925674438, loss=0.6455604434013367
train: epoch 138, loss 0.19340969622135162, acc=0.9213888645172119, loss=0.19340969622135162
test: epoch 138, loss 0.5787283182144165, acc=0.8111110925674438, loss=0.5787283182144165
train: epoch 139, loss 0.17343614995479584, acc=0.9271666407585144, loss=0.17343614995479584
test: epoch 139, loss 0.5995496511459351, acc=0.8111110925674438, loss=0.5995496511459351
train: epoch 140, loss 0.19869524240493774, acc=0.9210000038146973, loss=0.19869524240493774
test: epoch 140, loss 0.604877233505249, acc=0.8111110925674438, loss=0.604877233505249
train: epoch 141, loss 0.1605556309223175, acc=0.9307777881622314, loss=0.1605556309223175
test: epoch 141, loss 0.6021742820739746, acc=0.8111110925674438, loss=0.6021742820739746
train: epoch 142, loss 0.21235109865665436, acc=0.921999990940094, loss=0.21235109865665436
test: epoch 142, loss 0.6742185950279236, acc=0.7888888716697693, loss=0.6742185950279236
train: epoch 143, loss 0.21155309677124023, acc=0.9208333492279053, loss=0.21155309677124023
test: epoch 143, loss 0.6118074655532837, acc=0.8111110925674438, loss=0.6118074655532837
train: epoch 144, loss 0.18164962530136108, acc=0.9308333396911621, loss=0.18164962530136108
test: epoch 144, loss 0.6324335336685181, acc=0.8111110925674438, loss=0.6324335336685181
train: epoch 145, loss 0.16734671592712402, acc=0.9319999814033508, loss=0.16734671592712402
test: epoch 145, loss 0.6089911460876465, acc=0.8111110925674438, loss=0.6089911460876465
train: epoch 146, loss 0.1841019093990326, acc=0.9306666851043701, loss=0.1841019093990326
test: epoch 146, loss 0.6153438091278076, acc=0.8111110925674438, loss=0.6153438091278076
train: epoch 147, loss 0.21803885698318481, acc=0.9208333492279053, loss=0.21803885698318481
test: epoch 147, loss 0.5680966973304749, acc=0.8138889074325562, loss=0.5680966973304749
train: epoch 148, loss 0.19616228342056274, acc=0.9196666479110718, loss=0.19616228342056274
test: epoch 148, loss 0.5931460857391357, acc=0.8083333373069763, loss=0.5931460857391357
train: epoch 149, loss 0.22568689286708832, acc=0.9185000061988831, loss=0.22568689286708832
test: epoch 149, loss 0.6621078848838806, acc=0.8111110925674438, loss=0.6621078848838806
train: epoch 150, loss 0.21231968700885773, acc=0.9169999957084656, loss=0.21231968700885773
test: epoch 150, loss 0.4437901973724365, acc=0.8333333134651184, loss=0.4437901973724365
