# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=1", "--temp_decay=1", "--one_hot=1", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=362485723, receiver_embed_dim=64, save_run=0, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=362485723, receiver_embed_dim=64, save_run=False, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.438046455383301, acc=0.04777777940034866, loss=3.438046455383301
test: epoch 1, loss 4.009127616882324, acc=0.04444444552063942, loss=4.009127616882324
train: epoch 2, loss 2.9919397830963135, acc=0.09561111032962799, loss=2.9919397830963135
test: epoch 2, loss 2.9881093502044678, acc=0.10277777910232544, loss=2.9881093502044678
train: epoch 3, loss 2.230437994003296, acc=0.21805556118488312, loss=2.230437994003296
test: epoch 3, loss 2.5810086727142334, acc=0.13055555522441864, loss=2.5810086727142334
train: epoch 4, loss 1.9082211256027222, acc=0.2782222330570221, loss=1.9082211256027222
test: epoch 4, loss 2.462373971939087, acc=0.13611111044883728, loss=2.462373971939087
train: epoch 5, loss 1.728914499282837, acc=0.3334999978542328, loss=1.728914499282837
test: epoch 5, loss 2.454801082611084, acc=0.15000000596046448, loss=2.454801082611084
train: epoch 6, loss 1.614343523979187, acc=0.36588889360427856, loss=1.614343523979187
test: epoch 6, loss 2.3678019046783447, acc=0.18611110746860504, loss=2.3678019046783447
train: epoch 7, loss 1.503609538078308, acc=0.4014444351196289, loss=1.503609538078308
test: epoch 7, loss 2.28725004196167, acc=0.17499999701976776, loss=2.28725004196167
train: epoch 8, loss 1.4360722303390503, acc=0.4247777760028839, loss=1.4360722303390503
test: epoch 8, loss 2.21382474899292, acc=0.20000000298023224, loss=2.21382474899292
train: epoch 9, loss 1.3763211965560913, acc=0.4446111023426056, loss=1.3763211965560913
test: epoch 9, loss 2.044567108154297, acc=0.20277777314186096, loss=2.044567108154297
train: epoch 10, loss 1.33333420753479, acc=0.45899999141693115, loss=1.33333420753479
test: epoch 10, loss 2.1257810592651367, acc=0.23055554926395416, loss=2.1257810592651367
train: epoch 11, loss 1.2746468782424927, acc=0.4791666567325592, loss=1.2746468782424927
test: epoch 11, loss 2.023106098175049, acc=0.2361111044883728, loss=2.023106098175049
train: epoch 12, loss 1.2255715131759644, acc=0.4973333477973938, loss=1.2255715131759644
test: epoch 12, loss 1.9897677898406982, acc=0.24444444477558136, loss=1.9897677898406982
train: epoch 13, loss 1.1931426525115967, acc=0.5157222151756287, loss=1.1931426525115967
test: epoch 13, loss 1.9618042707443237, acc=0.25, loss=1.9618042707443237
train: epoch 14, loss 1.1471103429794312, acc=0.5329444408416748, loss=1.1471103429794312
test: epoch 14, loss 1.9517945051193237, acc=0.24444444477558136, loss=1.9517945051193237
train: epoch 15, loss 1.1099748611450195, acc=0.5484444499015808, loss=1.1099748611450195
test: epoch 15, loss 2.0428693294525146, acc=0.27222222089767456, loss=2.0428693294525146
train: epoch 16, loss 1.082597255706787, acc=0.5525000095367432, loss=1.082597255706787
test: epoch 16, loss 1.944617748260498, acc=0.27222222089767456, loss=1.944617748260498
train: epoch 17, loss 1.0518609285354614, acc=0.5652222037315369, loss=1.0518609285354614
test: epoch 17, loss 1.8160532712936401, acc=0.2750000059604645, loss=1.8160532712936401
train: epoch 18, loss 1.0228679180145264, acc=0.5835555791854858, loss=1.0228679180145264
test: epoch 18, loss 1.8207371234893799, acc=0.2777777910232544, loss=1.8207371234893799
train: epoch 19, loss 0.9952834248542786, acc=0.5938888788223267, loss=0.9952834248542786
test: epoch 19, loss 1.872145652770996, acc=0.2805555462837219, loss=1.872145652770996
train: epoch 20, loss 0.9748631715774536, acc=0.6051666736602783, loss=0.9748631715774536
test: epoch 20, loss 1.783097505569458, acc=0.30000001192092896, loss=1.783097505569458
train: epoch 21, loss 0.9516973495483398, acc=0.6100555658340454, loss=0.9516973495483398
test: epoch 21, loss 1.8418185710906982, acc=0.3083333373069763, loss=1.8418185710906982
train: epoch 22, loss 0.9364829063415527, acc=0.6233888864517212, loss=0.9364829063415527
test: epoch 22, loss 1.7135698795318604, acc=0.3194444477558136, loss=1.7135698795318604
train: epoch 23, loss 0.9104120135307312, acc=0.6311110854148865, loss=0.9104120135307312
test: epoch 23, loss 1.6779552698135376, acc=0.3305555582046509, loss=1.6779552698135376
train: epoch 24, loss 0.8888971209526062, acc=0.6432777643203735, loss=0.8888971209526062
test: epoch 24, loss 1.8164435625076294, acc=0.3333333432674408, loss=1.8164435625076294
train: epoch 25, loss 0.862975537776947, acc=0.6588888764381409, loss=0.862975537776947
test: epoch 25, loss 1.7739003896713257, acc=0.3361110985279083, loss=1.7739003896713257
train: epoch 26, loss 0.8411439657211304, acc=0.6633889079093933, loss=0.8411439657211304
test: epoch 26, loss 1.7126575708389282, acc=0.3444444537162781, loss=1.7126575708389282
train: epoch 27, loss 0.8217889070510864, acc=0.6768333315849304, loss=0.8217889070510864
test: epoch 27, loss 1.7617520093917847, acc=0.3499999940395355, loss=1.7617520093917847
train: epoch 28, loss 0.8065141439437866, acc=0.679277777671814, loss=0.8065141439437866
test: epoch 28, loss 1.6634166240692139, acc=0.34166666865348816, loss=1.6634166240692139
train: epoch 29, loss 0.7828558087348938, acc=0.6881111264228821, loss=0.7828558087348938
test: epoch 29, loss 1.7149882316589355, acc=0.35277777910232544, loss=1.7149882316589355
train: epoch 30, loss 0.7688818573951721, acc=0.6946666836738586, loss=0.7688818573951721
test: epoch 30, loss 1.629808783531189, acc=0.36666667461395264, loss=1.629808783531189
train: epoch 31, loss 0.7398964762687683, acc=0.7064444422721863, loss=0.7398964762687683
test: epoch 31, loss 1.6801420450210571, acc=0.36666667461395264, loss=1.6801420450210571
train: epoch 32, loss 0.7345468997955322, acc=0.7086111307144165, loss=0.7345468997955322
test: epoch 32, loss 1.8837283849716187, acc=0.3722222149372101, loss=1.8837283849716187
train: epoch 33, loss 0.7095066905021667, acc=0.7173888683319092, loss=0.7095066905021667
test: epoch 33, loss 1.5830250978469849, acc=0.3722222149372101, loss=1.5830250978469849
train: epoch 34, loss 0.7095246911048889, acc=0.7210000157356262, loss=0.7095246911048889
test: epoch 34, loss 1.7175581455230713, acc=0.3777777850627899, loss=1.7175581455230713
train: epoch 35, loss 0.6849257946014404, acc=0.7310000061988831, loss=0.6849257946014404
test: epoch 35, loss 1.694866418838501, acc=0.3916666805744171, loss=1.694866418838501
train: epoch 36, loss 0.6752037405967712, acc=0.7315555810928345, loss=0.6752037405967712
test: epoch 36, loss 1.6526316404342651, acc=0.39722222089767456, loss=1.6526316404342651
train: epoch 37, loss 0.6738758087158203, acc=0.7350000143051147, loss=0.6738758087158203
test: epoch 37, loss 1.6258800029754639, acc=0.4027777910232544, loss=1.6258800029754639
train: epoch 38, loss 0.6550521850585938, acc=0.7404444217681885, loss=0.6550521850585938
test: epoch 38, loss 1.5371700525283813, acc=0.39444443583488464, loss=1.5371700525283813
train: epoch 39, loss 0.6304500102996826, acc=0.7497777938842773, loss=0.6304500102996826
test: epoch 39, loss 1.6942546367645264, acc=0.4055555462837219, loss=1.6942546367645264
train: epoch 40, loss 0.6424686312675476, acc=0.750333309173584, loss=0.6424686312675476
test: epoch 40, loss 1.6934682130813599, acc=0.3916666805744171, loss=1.6934682130813599
train: epoch 41, loss 0.6148808002471924, acc=0.7603889107704163, loss=0.6148808002471924
test: epoch 41, loss 1.7418606281280518, acc=0.4027777910232544, loss=1.7418606281280518
train: epoch 42, loss 0.6122384071350098, acc=0.7587777972221375, loss=0.6122384071350098
test: epoch 42, loss 1.6708163022994995, acc=0.40833333134651184, loss=1.6708163022994995
train: epoch 43, loss 0.6225072145462036, acc=0.7545555830001831, loss=0.6225072145462036
test: epoch 43, loss 1.7151850461959839, acc=0.38333332538604736, loss=1.7151850461959839
train: epoch 44, loss 0.6056773066520691, acc=0.7610555291175842, loss=0.6056773066520691
test: epoch 44, loss 1.7420613765716553, acc=0.4305555522441864, loss=1.7420613765716553
train: epoch 45, loss 0.5870639085769653, acc=0.7655555605888367, loss=0.5870639085769653
test: epoch 45, loss 1.6904232501983643, acc=0.42500001192092896, loss=1.6904232501983643
train: epoch 46, loss 0.5847824811935425, acc=0.7691666483879089, loss=0.5847824811935425
test: epoch 46, loss 1.6188124418258667, acc=0.42222222685813904, loss=1.6188124418258667
train: epoch 47, loss 0.5794666409492493, acc=0.77311110496521, loss=0.5794666409492493
test: epoch 47, loss 1.720302700996399, acc=0.4166666567325592, loss=1.720302700996399
train: epoch 48, loss 0.5654996037483215, acc=0.7791666388511658, loss=0.5654996037483215
test: epoch 48, loss 1.7098090648651123, acc=0.4472222328186035, loss=1.7098090648651123
train: epoch 49, loss 0.5592163801193237, acc=0.7838333249092102, loss=0.5592163801193237
test: epoch 49, loss 1.7734719514846802, acc=0.43611112236976624, loss=1.7734719514846802
train: epoch 50, loss 0.5563550591468811, acc=0.7820000052452087, loss=0.5563550591468811
test: epoch 50, loss 1.677064061164856, acc=0.42500001192092896, loss=1.677064061164856
train: epoch 51, loss 0.5480812191963196, acc=0.7859444618225098, loss=0.5480812191963196
test: epoch 51, loss 1.6409096717834473, acc=0.4611110985279083, loss=1.6409096717834473
train: epoch 52, loss 0.5359034538269043, acc=0.7900000214576721, loss=0.5359034538269043
test: epoch 52, loss 1.7214728593826294, acc=0.43888887763023376, loss=1.7214728593826294
train: epoch 53, loss 0.5272138118743896, acc=0.7946666479110718, loss=0.5272138118743896
test: epoch 53, loss 1.7215803861618042, acc=0.4583333432674408, loss=1.7215803861618042
train: epoch 54, loss 0.5252300500869751, acc=0.7951111197471619, loss=0.5252300500869751
test: epoch 54, loss 1.7558865547180176, acc=0.44999998807907104, loss=1.7558865547180176
train: epoch 55, loss 0.5203356146812439, acc=0.7976666688919067, loss=0.5203356146812439
test: epoch 55, loss 1.7987403869628906, acc=0.4416666626930237, loss=1.7987403869628906
train: epoch 56, loss 0.515040934085846, acc=0.8015000224113464, loss=0.515040934085846
test: epoch 56, loss 1.5928499698638916, acc=0.43611112236976624, loss=1.5928499698638916
train: epoch 57, loss 0.5040402412414551, acc=0.8014444708824158, loss=0.5040402412414551
test: epoch 57, loss 1.804440975189209, acc=0.45277777314186096, loss=1.804440975189209
train: epoch 58, loss 0.5025192499160767, acc=0.7990555763244629, loss=0.5025192499160767
test: epoch 58, loss 1.7376371622085571, acc=0.44999998807907104, loss=1.7376371622085571
train: epoch 59, loss 0.4978407919406891, acc=0.8018333315849304, loss=0.4978407919406891
test: epoch 59, loss 1.7999602556228638, acc=0.4722222089767456, loss=1.7999602556228638
train: epoch 60, loss 0.49328407645225525, acc=0.8033333420753479, loss=0.49328407645225525
test: epoch 60, loss 1.7642033100128174, acc=0.4749999940395355, loss=1.7642033100128174
train: epoch 61, loss 0.49213704466819763, acc=0.805055558681488, loss=0.49213704466819763
test: epoch 61, loss 1.6231478452682495, acc=0.46388888359069824, loss=1.6231478452682495
train: epoch 62, loss 0.4896685779094696, acc=0.8052777647972107, loss=0.4896685779094696
test: epoch 62, loss 1.8385093212127686, acc=0.4722222089767456, loss=1.8385093212127686
train: epoch 63, loss 0.4809027910232544, acc=0.8069444298744202, loss=0.4809027910232544
test: epoch 63, loss 1.7044250965118408, acc=0.48055556416511536, loss=1.7044250965118408
train: epoch 64, loss 0.47624069452285767, acc=0.8076111078262329, loss=0.47624069452285767
test: epoch 64, loss 1.728973388671875, acc=0.4749999940395355, loss=1.728973388671875
train: epoch 65, loss 0.471797376871109, acc=0.8111666440963745, loss=0.471797376871109
test: epoch 65, loss 1.7029751539230347, acc=0.47777777910232544, loss=1.7029751539230347
train: epoch 66, loss 0.46870529651641846, acc=0.8144999742507935, loss=0.46870529651641846
test: epoch 66, loss 1.6577118635177612, acc=0.46666666865348816, loss=1.6577118635177612
train: epoch 67, loss 0.45371460914611816, acc=0.815666675567627, loss=0.45371460914611816
test: epoch 67, loss 1.8790884017944336, acc=0.4833333194255829, loss=1.8790884017944336
train: epoch 68, loss 0.4670346975326538, acc=0.8112778067588806, loss=0.4670346975326538
test: epoch 68, loss 1.702981948852539, acc=0.4888888895511627, loss=1.702981948852539
train: epoch 69, loss 0.4522045850753784, acc=0.816777765750885, loss=0.4522045850753784
test: epoch 69, loss 1.8340849876403809, acc=0.4722222089767456, loss=1.8340849876403809
train: epoch 70, loss 0.4560438096523285, acc=0.816277801990509, loss=0.4560438096523285
test: epoch 70, loss 1.8001996278762817, acc=0.4749999940395355, loss=1.8001996278762817
train: epoch 71, loss 0.4577280580997467, acc=0.8166666626930237, loss=0.4577280580997467
test: epoch 71, loss 1.763351321220398, acc=0.5, loss=1.763351321220398
train: epoch 72, loss 0.4412950873374939, acc=0.8184444308280945, loss=0.4412950873374939
test: epoch 72, loss 1.7001702785491943, acc=0.5055555701255798, loss=1.7001702785491943
train: epoch 73, loss 0.4536551237106323, acc=0.8192777633666992, loss=0.4536551237106323
test: epoch 73, loss 1.6728254556655884, acc=0.49444442987442017, loss=1.6728254556655884
train: epoch 74, loss 0.45231911540031433, acc=0.8153889179229736, loss=0.45231911540031433
test: epoch 74, loss 1.5716050863265991, acc=0.4972222149372101, loss=1.5716050863265991
train: epoch 75, loss 0.4409124553203583, acc=0.8223888874053955, loss=0.4409124553203583
test: epoch 75, loss 1.703744888305664, acc=0.5138888955116272, loss=1.703744888305664
train: epoch 76, loss 0.4342332184314728, acc=0.8216111063957214, loss=0.4342332184314728
test: epoch 76, loss 1.72639000415802, acc=0.5166666507720947, loss=1.72639000415802
train: epoch 77, loss 0.4438828229904175, acc=0.8206111192703247, loss=0.4438828229904175
test: epoch 77, loss 1.6818722486495972, acc=0.4972222149372101, loss=1.6818722486495972
train: epoch 78, loss 0.4323572814464569, acc=0.8218888640403748, loss=0.4323572814464569
test: epoch 78, loss 1.7693959474563599, acc=0.5249999761581421, loss=1.7693959474563599
train: epoch 79, loss 0.43077218532562256, acc=0.8243333101272583, loss=0.43077218532562256
test: epoch 79, loss 1.8009341955184937, acc=0.5083333253860474, loss=1.8009341955184937
train: epoch 80, loss 0.4337542951107025, acc=0.824833333492279, loss=0.4337542951107025
test: epoch 80, loss 1.5494178533554077, acc=0.519444465637207, loss=1.5494178533554077
train: epoch 81, loss 0.42682045698165894, acc=0.8254444599151611, loss=0.42682045698165894
test: epoch 81, loss 1.701452374458313, acc=0.5166666507720947, loss=1.701452374458313
train: epoch 82, loss 0.4301833510398865, acc=0.8274444341659546, loss=0.4301833510398865
test: epoch 82, loss 1.7183752059936523, acc=0.5222222208976746, loss=1.7183752059936523
train: epoch 83, loss 0.4306953251361847, acc=0.8223333358764648, loss=0.4306953251361847
test: epoch 83, loss 1.7553287744522095, acc=0.5027777552604675, loss=1.7553287744522095
train: epoch 84, loss 0.4321034252643585, acc=0.8259444236755371, loss=0.4321034252643585
test: epoch 84, loss 1.681435227394104, acc=0.5138888955116272, loss=1.681435227394104
train: epoch 85, loss 0.42047134041786194, acc=0.8273333311080933, loss=0.42047134041786194
test: epoch 85, loss 1.7629289627075195, acc=0.5027777552604675, loss=1.7629289627075195
train: epoch 86, loss 0.41342785954475403, acc=0.8282222151756287, loss=0.41342785954475403
test: epoch 86, loss 2.0304903984069824, acc=0.5249999761581421, loss=2.0304903984069824
train: epoch 87, loss 0.4300723671913147, acc=0.8279444575309753, loss=0.4300723671913147
test: epoch 87, loss 1.7313127517700195, acc=0.5222222208976746, loss=1.7313127517700195
train: epoch 88, loss 0.40680041909217834, acc=0.8314999938011169, loss=0.40680041909217834
test: epoch 88, loss 1.7903900146484375, acc=0.5305555462837219, loss=1.7903900146484375
train: epoch 89, loss 0.4127250611782074, acc=0.8304444551467896, loss=0.4127250611782074
test: epoch 89, loss 1.8483693599700928, acc=0.5083333253860474, loss=1.8483693599700928
train: epoch 90, loss 0.41100212931632996, acc=0.8297777771949768, loss=0.41100212931632996
test: epoch 90, loss 1.7220591306686401, acc=0.5166666507720947, loss=1.7220591306686401
train: epoch 91, loss 0.4064600467681885, acc=0.8314999938011169, loss=0.4064600467681885
test: epoch 91, loss 1.8309215307235718, acc=0.5222222208976746, loss=1.8309215307235718
train: epoch 92, loss 0.4127281606197357, acc=0.8301666378974915, loss=0.4127281606197357
test: epoch 92, loss 1.7655915021896362, acc=0.5305555462837219, loss=1.7655915021896362
train: epoch 93, loss 0.39978325366973877, acc=0.8337777853012085, loss=0.39978325366973877
test: epoch 93, loss 1.6883070468902588, acc=0.5277777910232544, loss=1.6883070468902588
train: epoch 94, loss 0.4097421169281006, acc=0.8356666564941406, loss=0.4097421169281006
test: epoch 94, loss 1.7942359447479248, acc=0.5277777910232544, loss=1.7942359447479248
train: epoch 95, loss 0.39490798115730286, acc=0.8370555639266968, loss=0.39490798115730286
test: epoch 95, loss 1.771256923675537, acc=0.5277777910232544, loss=1.771256923675537
train: epoch 96, loss 0.40565168857574463, acc=0.832277774810791, loss=0.40565168857574463
test: epoch 96, loss 1.9138716459274292, acc=0.5166666507720947, loss=1.9138716459274292
train: epoch 97, loss 0.4041442573070526, acc=0.8322222232818604, loss=0.4041442573070526
test: epoch 97, loss 1.6955431699752808, acc=0.5027777552604675, loss=1.6955431699752808
train: epoch 98, loss 0.4028630554676056, acc=0.8342777490615845, loss=0.4028630554676056
test: epoch 98, loss 1.658389687538147, acc=0.5138888955116272, loss=1.658389687538147
train: epoch 99, loss 0.3878466784954071, acc=0.8395000100135803, loss=0.3878466784954071
test: epoch 99, loss 1.948665738105774, acc=0.5249999761581421, loss=1.948665738105774
train: epoch 100, loss 0.41116276383399963, acc=0.8330000042915344, loss=0.41116276383399963
test: epoch 100, loss 1.8738477230072021, acc=0.5083333253860474, loss=1.8738477230072021
train: epoch 101, loss 0.41056206822395325, acc=0.8334444165229797, loss=0.41056206822395325
test: epoch 101, loss 1.776005744934082, acc=0.5166666507720947, loss=1.776005744934082
train: epoch 102, loss 0.3913477957248688, acc=0.8402222394943237, loss=0.3913477957248688
test: epoch 102, loss 1.9652185440063477, acc=0.519444465637207, loss=1.9652185440063477
train: epoch 103, loss 0.3928869366645813, acc=0.8368889093399048, loss=0.3928869366645813
test: epoch 103, loss 1.7923583984375, acc=0.5305555462837219, loss=1.7923583984375
train: epoch 104, loss 0.3896852135658264, acc=0.8403888940811157, loss=0.3896852135658264
test: epoch 104, loss 1.7374768257141113, acc=0.5, loss=1.7374768257141113
train: epoch 105, loss 0.3829081356525421, acc=0.8407222032546997, loss=0.3829081356525421
test: epoch 105, loss 1.8666199445724487, acc=0.5277777910232544, loss=1.8666199445724487
train: epoch 106, loss 0.38949599862098694, acc=0.8407222032546997, loss=0.38949599862098694
test: epoch 106, loss 1.7952148914337158, acc=0.5138888955116272, loss=1.7952148914337158
train: epoch 107, loss 0.390567809343338, acc=0.839555561542511, loss=0.390567809343338
test: epoch 107, loss 1.7916239500045776, acc=0.519444465637207, loss=1.7916239500045776
train: epoch 108, loss 0.39739274978637695, acc=0.8376111388206482, loss=0.39739274978637695
test: epoch 108, loss 1.7589099407196045, acc=0.4972222149372101, loss=1.7589099407196045
train: epoch 109, loss 0.3836464285850525, acc=0.8386111259460449, loss=0.3836464285850525
test: epoch 109, loss 2.0162508487701416, acc=0.5222222208976746, loss=2.0162508487701416
train: epoch 110, loss 0.38982629776000977, acc=0.840499997138977, loss=0.38982629776000977
test: epoch 110, loss 1.8112977743148804, acc=0.5222222208976746, loss=1.8112977743148804
train: epoch 111, loss 0.39592206478118896, acc=0.8394444584846497, loss=0.39592206478118896
test: epoch 111, loss 1.8593391180038452, acc=0.519444465637207, loss=1.8593391180038452
train: epoch 112, loss 0.37533313035964966, acc=0.8436111211776733, loss=0.37533313035964966
test: epoch 112, loss 1.7392480373382568, acc=0.5277777910232544, loss=1.7392480373382568
train: epoch 113, loss 0.39381521940231323, acc=0.8384444713592529, loss=0.39381521940231323
test: epoch 113, loss 1.8940755128860474, acc=0.5361111164093018, loss=1.8940755128860474
train: epoch 114, loss 0.385428249835968, acc=0.8437777757644653, loss=0.385428249835968
test: epoch 114, loss 1.8271536827087402, acc=0.5305555462837219, loss=1.8271536827087402
train: epoch 115, loss 0.38150718808174133, acc=0.8407222032546997, loss=0.38150718808174133
test: epoch 115, loss 1.873879075050354, acc=0.5333333611488342, loss=1.873879075050354
train: epoch 116, loss 0.38455817103385925, acc=0.8418333530426025, loss=0.38455817103385925
test: epoch 116, loss 1.9051902294158936, acc=0.5361111164093018, loss=1.9051902294158936
train: epoch 117, loss 0.3772915005683899, acc=0.8440555334091187, loss=0.3772915005683899
test: epoch 117, loss 1.8616869449615479, acc=0.5277777910232544, loss=1.8616869449615479
train: epoch 118, loss 0.373629093170166, acc=0.8432222008705139, loss=0.373629093170166
test: epoch 118, loss 2.013199806213379, acc=0.5277777910232544, loss=2.013199806213379
train: epoch 119, loss 0.38571038842201233, acc=0.8392778038978577, loss=0.38571038842201233
test: epoch 119, loss 1.7613937854766846, acc=0.5333333611488342, loss=1.7613937854766846
train: epoch 120, loss 0.3844762444496155, acc=0.8410000205039978, loss=0.3844762444496155
test: epoch 120, loss 1.8648251295089722, acc=0.5361111164093018, loss=1.8648251295089722
train: epoch 121, loss 0.377972811460495, acc=0.8427222371101379, loss=0.377972811460495
test: epoch 121, loss 2.0458762645721436, acc=0.5277777910232544, loss=2.0458762645721436
train: epoch 122, loss 0.36684101819992065, acc=0.8477222323417664, loss=0.36684101819992065
test: epoch 122, loss 2.0367681980133057, acc=0.5361111164093018, loss=2.0367681980133057
train: epoch 123, loss 0.37126782536506653, acc=0.8463333249092102, loss=0.37126782536506653
test: epoch 123, loss 1.7388871908187866, acc=0.5277777910232544, loss=1.7388871908187866
train: epoch 124, loss 0.37948063015937805, acc=0.8455555438995361, loss=0.37948063015937805
test: epoch 124, loss 1.9786299467086792, acc=0.5444444417953491, loss=1.9786299467086792
train: epoch 125, loss 0.3735501170158386, acc=0.846666693687439, loss=0.3735501170158386
test: epoch 125, loss 1.865653157234192, acc=0.5361111164093018, loss=1.865653157234192
train: epoch 126, loss 0.37195295095443726, acc=0.8478888869285583, loss=0.37195295095443726
test: epoch 126, loss 1.7253721952438354, acc=0.5361111164093018, loss=1.7253721952438354
train: epoch 127, loss 0.35827210545539856, acc=0.8488333225250244, loss=0.35827210545539856
test: epoch 127, loss 1.6971129179000854, acc=0.5444444417953491, loss=1.6971129179000854
train: epoch 128, loss 0.3799108862876892, acc=0.8413333296775818, loss=0.3799108862876892
test: epoch 128, loss 1.6810321807861328, acc=0.5444444417953491, loss=1.6810321807861328
train: epoch 129, loss 0.37517842650413513, acc=0.8448888659477234, loss=0.37517842650413513
test: epoch 129, loss 1.7467232942581177, acc=0.5444444417953491, loss=1.7467232942581177
train: epoch 130, loss 0.3598536252975464, acc=0.8475555777549744, loss=0.3598536252975464
test: epoch 130, loss 1.6915735006332397, acc=0.5472221970558167, loss=1.6915735006332397
train: epoch 131, loss 0.3781552016735077, acc=0.8442222476005554, loss=0.3781552016735077
test: epoch 131, loss 1.857820987701416, acc=0.5361111164093018, loss=1.857820987701416
train: epoch 132, loss 0.36266976594924927, acc=0.8473888635635376, loss=0.36266976594924927
test: epoch 132, loss 1.9405916929244995, acc=0.550000011920929, loss=1.9405916929244995
train: epoch 133, loss 0.3601013720035553, acc=0.8463888764381409, loss=0.3601013720035553
test: epoch 133, loss 1.9063433408737183, acc=0.5361111164093018, loss=1.9063433408737183
train: epoch 134, loss 0.36179277300834656, acc=0.8503333330154419, loss=0.36179277300834656
test: epoch 134, loss 1.6849489212036133, acc=0.5333333611488342, loss=1.6849489212036133
train: epoch 135, loss 0.3695683181285858, acc=0.8474444150924683, loss=0.3695683181285858
test: epoch 135, loss 1.724997878074646, acc=0.5388888716697693, loss=1.724997878074646
train: epoch 136, loss 0.36433613300323486, acc=0.8493333458900452, loss=0.36433613300323486
test: epoch 136, loss 2.013577938079834, acc=0.550000011920929, loss=2.013577938079834
train: epoch 137, loss 0.36574411392211914, acc=0.8453333377838135, loss=0.36574411392211914
test: epoch 137, loss 1.7376530170440674, acc=0.5249999761581421, loss=1.7376530170440674
train: epoch 138, loss 0.36035972833633423, acc=0.8501666784286499, loss=0.36035972833633423
test: epoch 138, loss 1.912563443183899, acc=0.5472221970558167, loss=1.912563443183899
train: epoch 139, loss 0.3528139591217041, acc=0.8530555367469788, loss=0.3528139591217041
test: epoch 139, loss 1.7086389064788818, acc=0.5527777671813965, loss=1.7086389064788818
train: epoch 140, loss 0.36277827620506287, acc=0.8482221961021423, loss=0.36277827620506287
test: epoch 140, loss 1.7998358011245728, acc=0.550000011920929, loss=1.7998358011245728
train: epoch 141, loss 0.3580382168292999, acc=0.8506666421890259, loss=0.3580382168292999
test: epoch 141, loss 1.7669845819473267, acc=0.550000011920929, loss=1.7669845819473267
train: epoch 142, loss 0.3546830713748932, acc=0.8505555391311646, loss=0.3546830713748932
test: epoch 142, loss 1.6093697547912598, acc=0.5555555820465088, loss=1.6093697547912598
train: epoch 143, loss 0.3566332459449768, acc=0.8501111268997192, loss=0.3566332459449768
test: epoch 143, loss 1.7197028398513794, acc=0.5555555820465088, loss=1.7197028398513794
train: epoch 144, loss 0.35294950008392334, acc=0.851277768611908, loss=0.35294950008392334
test: epoch 144, loss 1.785605549812317, acc=0.5611110925674438, loss=1.785605549812317
train: epoch 145, loss 0.35727041959762573, acc=0.8489444255828857, loss=0.35727041959762573
test: epoch 145, loss 1.7477383613586426, acc=0.5555555820465088, loss=1.7477383613586426
train: epoch 146, loss 0.3453521430492401, acc=0.8532778024673462, loss=0.3453521430492401
test: epoch 146, loss 1.6843605041503906, acc=0.5527777671813965, loss=1.6843605041503906
train: epoch 147, loss 0.3540598154067993, acc=0.8514444231987, loss=0.3540598154067993
test: epoch 147, loss 1.7353836297988892, acc=0.5444444417953491, loss=1.7353836297988892
train: epoch 148, loss 0.3555808365345001, acc=0.8521111011505127, loss=0.3555808365345001
test: epoch 148, loss 1.7782357931137085, acc=0.5555555820465088, loss=1.7782357931137085
train: epoch 149, loss 0.3531363010406494, acc=0.8526666760444641, loss=0.3531363010406494
test: epoch 149, loss 1.726845622062683, acc=0.5555555820465088, loss=1.726845622062683
train: epoch 150, loss 0.3549853265285492, acc=0.8528888821601868, loss=0.3549853265285492
test: epoch 150, loss 1.9027448892593384, acc=0.5388888716697693, loss=1.9027448892593384
