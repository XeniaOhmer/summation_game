# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=1", "--one_hot=true", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=985043804, receiver_embed_dim=32, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.359029769897461, acc=0.055166665464639664, loss=3.359029769897461
test: epoch 1, loss 3.9661865234375, acc=0.06666667014360428, loss=3.9661865234375
train: epoch 2, loss 2.5492982864379883, acc=0.16672222316265106, loss=2.5492982864379883
test: epoch 2, loss 5.32948637008667, acc=0.07500000298023224, loss=5.32948637008667
train: epoch 3, loss 1.8818596601486206, acc=0.3334444463253021, loss=1.8818596601486206
test: epoch 3, loss 4.520956993103027, acc=0.11388888955116272, loss=4.520956993103027
train: epoch 4, loss 1.4858328104019165, acc=0.44866666197776794, loss=1.4858328104019165
test: epoch 4, loss 4.518693923950195, acc=0.14722222089767456, loss=4.518693923950195
train: epoch 5, loss 1.2700470685958862, acc=0.5218889117240906, loss=1.2700470685958862
test: epoch 5, loss 4.062987804412842, acc=0.1527777761220932, loss=4.062987804412842
train: epoch 6, loss 1.1195015907287598, acc=0.5825555324554443, loss=1.1195015907287598
test: epoch 6, loss 3.96901798248291, acc=0.17222222685813904, loss=3.96901798248291
train: epoch 7, loss 0.9800593256950378, acc=0.6380000114440918, loss=0.9800593256950378
test: epoch 7, loss 4.064050674438477, acc=0.15833333134651184, loss=4.064050674438477
train: epoch 8, loss 0.8832502365112305, acc=0.675611138343811, loss=0.8832502365112305
test: epoch 8, loss 3.9745094776153564, acc=0.16111111640930176, loss=3.9745094776153564
train: epoch 9, loss 0.8081029653549194, acc=0.7025555372238159, loss=0.8081029653549194
test: epoch 9, loss 3.9030849933624268, acc=0.1805555522441864, loss=3.9030849933624268
train: epoch 10, loss 0.7384747862815857, acc=0.7306666374206543, loss=0.7384747862815857
test: epoch 10, loss 3.7550530433654785, acc=0.19166666269302368, loss=3.7550530433654785
train: epoch 11, loss 0.6878719329833984, acc=0.7496111392974854, loss=0.6878719329833984
test: epoch 11, loss 3.5503175258636475, acc=0.22499999403953552, loss=3.5503175258636475
train: epoch 12, loss 0.6461003422737122, acc=0.7709444165229797, loss=0.6461003422737122
test: epoch 12, loss 3.5775296688079834, acc=0.21111111342906952, loss=3.5775296688079834
train: epoch 13, loss 0.6009723544120789, acc=0.7878888845443726, loss=0.6009723544120789
test: epoch 13, loss 3.5754294395446777, acc=0.2083333283662796, loss=3.5754294395446777
train: epoch 14, loss 0.5632272958755493, acc=0.8009999990463257, loss=0.5632272958755493
test: epoch 14, loss 3.508387327194214, acc=0.2222222238779068, loss=3.508387327194214
train: epoch 15, loss 0.5390350222587585, acc=0.8117222189903259, loss=0.5390350222587585
test: epoch 15, loss 3.4664318561553955, acc=0.23888888955116272, loss=3.4664318561553955
train: epoch 16, loss 0.5102823972702026, acc=0.8242777585983276, loss=0.5102823972702026
test: epoch 16, loss 3.6149826049804688, acc=0.23333333432674408, loss=3.6149826049804688
train: epoch 17, loss 0.47189489006996155, acc=0.8384444713592529, loss=0.47189489006996155
test: epoch 17, loss 3.6414952278137207, acc=0.22777777910232544, loss=3.6414952278137207
train: epoch 18, loss 0.4484620690345764, acc=0.8460555672645569, loss=0.4484620690345764
test: epoch 18, loss 3.6705174446105957, acc=0.2222222238779068, loss=3.6705174446105957
train: epoch 19, loss 0.4424384534358978, acc=0.8489999771118164, loss=0.4424384534358978
test: epoch 19, loss 3.5995049476623535, acc=0.24444444477558136, loss=3.5995049476623535
train: epoch 20, loss 0.4066286087036133, acc=0.8668333292007446, loss=0.4066286087036133
test: epoch 20, loss 3.473578691482544, acc=0.24444444477558136, loss=3.473578691482544
train: epoch 21, loss 0.3970075249671936, acc=0.8663889169692993, loss=0.3970075249671936
test: epoch 21, loss 3.5113472938537598, acc=0.24444444477558136, loss=3.5113472938537598
train: epoch 22, loss 0.3791021704673767, acc=0.8776111006736755, loss=0.3791021704673767
test: epoch 22, loss 3.4208731651306152, acc=0.2666666805744171, loss=3.4208731651306152
train: epoch 23, loss 0.3756827712059021, acc=0.875, loss=0.3756827712059021
test: epoch 23, loss 3.4230945110321045, acc=0.21944443881511688, loss=3.4230945110321045
train: epoch 24, loss 0.35057884454727173, acc=0.8843333125114441, loss=0.35057884454727173
test: epoch 24, loss 3.173130750656128, acc=0.2666666805744171, loss=3.173130750656128
train: epoch 25, loss 0.34982892870903015, acc=0.8870555758476257, loss=0.34982892870903015
test: epoch 25, loss 3.023055076599121, acc=0.2805555462837219, loss=3.023055076599121
train: epoch 26, loss 0.32137808203697205, acc=0.894777774810791, loss=0.32137808203697205
test: epoch 26, loss 3.0771167278289795, acc=0.2916666567325592, loss=3.0771167278289795
train: epoch 27, loss 0.3073565661907196, acc=0.899055540561676, loss=0.3073565661907196
test: epoch 27, loss 3.3854153156280518, acc=0.2750000059604645, loss=3.3854153156280518
train: epoch 28, loss 0.31511396169662476, acc=0.9005555510520935, loss=0.31511396169662476
test: epoch 28, loss 2.928082227706909, acc=0.26944443583488464, loss=2.928082227706909
train: epoch 29, loss 0.2779170870780945, acc=0.9111111164093018, loss=0.2779170870780945
test: epoch 29, loss 2.906008720397949, acc=0.27222222089767456, loss=2.906008720397949
train: epoch 30, loss 0.3025487959384918, acc=0.9077777862548828, loss=0.3025487959384918
test: epoch 30, loss 3.016667366027832, acc=0.2750000059604645, loss=3.016667366027832
train: epoch 31, loss 0.2771925628185272, acc=0.91438889503479, loss=0.2771925628185272
test: epoch 31, loss 3.1129086017608643, acc=0.2666666805744171, loss=3.1129086017608643
train: epoch 32, loss 0.2597578465938568, acc=0.917888879776001, loss=0.2597578465938568
test: epoch 32, loss 3.2679641246795654, acc=0.2666666805744171, loss=3.2679641246795654
train: epoch 33, loss 0.2604544460773468, acc=0.9182222485542297, loss=0.2604544460773468
test: epoch 33, loss 3.1958694458007812, acc=0.25833332538604736, loss=3.1958694458007812
train: epoch 34, loss 0.2522554099559784, acc=0.9213333129882812, loss=0.2522554099559784
test: epoch 34, loss 3.057279109954834, acc=0.2777777910232544, loss=3.057279109954834
train: epoch 35, loss 0.24060535430908203, acc=0.9272222518920898, loss=0.24060535430908203
test: epoch 35, loss 3.0666375160217285, acc=0.2750000059604645, loss=3.0666375160217285
train: epoch 36, loss 0.23985111713409424, acc=0.9255555272102356, loss=0.23985111713409424
test: epoch 36, loss 2.956193208694458, acc=0.2638888955116272, loss=2.956193208694458
train: epoch 37, loss 0.23523643612861633, acc=0.9269444346427917, loss=0.23523643612861633
test: epoch 37, loss 2.994981527328491, acc=0.28333333134651184, loss=2.994981527328491
train: epoch 38, loss 0.22543413937091827, acc=0.9310555458068848, loss=0.22543413937091827
test: epoch 38, loss 2.8023526668548584, acc=0.2888889014720917, loss=2.8023526668548584
train: epoch 39, loss 0.2146822065114975, acc=0.9339444637298584, loss=0.2146822065114975
test: epoch 39, loss 2.8271665573120117, acc=0.3166666626930237, loss=2.8271665573120117
train: epoch 40, loss 0.20639635622501373, acc=0.9368333220481873, loss=0.20639635622501373
test: epoch 40, loss 2.9703664779663086, acc=0.30000001192092896, loss=2.9703664779663086
train: epoch 41, loss 0.21338579058647156, acc=0.9342777729034424, loss=0.21338579058647156
test: epoch 41, loss 3.038473606109619, acc=0.2638888955116272, loss=3.038473606109619
train: epoch 42, loss 0.2000419646501541, acc=0.9368333220481873, loss=0.2000419646501541
test: epoch 42, loss 2.5916802883148193, acc=0.29722222685813904, loss=2.5916802883148193
train: epoch 43, loss 0.2034372240304947, acc=0.9390555620193481, loss=0.2034372240304947
test: epoch 43, loss 2.715510368347168, acc=0.31388887763023376, loss=2.715510368347168
train: epoch 44, loss 0.20184774696826935, acc=0.9390555620193481, loss=0.20184774696826935
test: epoch 44, loss 2.956453561782837, acc=0.2916666567325592, loss=2.956453561782837
train: epoch 45, loss 0.17815449833869934, acc=0.9452221989631653, loss=0.17815449833869934
test: epoch 45, loss 2.8110387325286865, acc=0.34166666865348816, loss=2.8110387325286865
train: epoch 46, loss 0.18495357036590576, acc=0.9452221989631653, loss=0.18495357036590576
test: epoch 46, loss 3.0081393718719482, acc=0.2944444417953491, loss=3.0081393718719482
train: epoch 47, loss 0.1702386736869812, acc=0.9462777972221375, loss=0.1702386736869812
test: epoch 47, loss 3.2363357543945312, acc=0.2750000059604645, loss=3.2363357543945312
train: epoch 48, loss 0.18020737171173096, acc=0.9482777714729309, loss=0.18020737171173096
test: epoch 48, loss 3.242461919784546, acc=0.3166666626930237, loss=3.242461919784546
train: epoch 49, loss 0.1732184886932373, acc=0.9498888850212097, loss=0.1732184886932373
test: epoch 49, loss 2.6459872722625732, acc=0.3305555582046509, loss=2.6459872722625732
train: epoch 50, loss 0.16701777279376984, acc=0.9498888850212097, loss=0.16701777279376984
test: epoch 50, loss 2.5387489795684814, acc=0.3083333373069763, loss=2.5387489795684814
train: epoch 51, loss 0.153589129447937, acc=0.9537777900695801, loss=0.153589129447937
test: epoch 51, loss 2.5298538208007812, acc=0.3027777671813965, loss=2.5298538208007812
train: epoch 52, loss 0.1612318605184555, acc=0.9512222409248352, loss=0.1612318605184555
test: epoch 52, loss 2.7946979999542236, acc=0.3055555522441864, loss=2.7946979999542236
train: epoch 53, loss 0.15238550305366516, acc=0.9560555815696716, loss=0.15238550305366516
test: epoch 53, loss 2.6174044609069824, acc=0.3194444477558136, loss=2.6174044609069824
train: epoch 54, loss 0.15025265514850616, acc=0.9559999704360962, loss=0.15025265514850616
test: epoch 54, loss 2.3785948753356934, acc=0.3444444537162781, loss=2.3785948753356934
train: epoch 55, loss 0.14878211915493011, acc=0.9583333134651184, loss=0.14878211915493011
test: epoch 55, loss 3.1163582801818848, acc=0.31388887763023376, loss=3.1163582801818848
train: epoch 56, loss 0.14915011823177338, acc=0.9558333158493042, loss=0.14915011823177338
test: epoch 56, loss 2.66420316696167, acc=0.32499998807907104, loss=2.66420316696167
train: epoch 57, loss 0.14288654923439026, acc=0.9574999809265137, loss=0.14288654923439026
test: epoch 57, loss 2.408907890319824, acc=0.32777777314186096, loss=2.408907890319824
train: epoch 58, loss 0.13870300352573395, acc=0.9592777490615845, loss=0.13870300352573395
test: epoch 58, loss 2.4694390296936035, acc=0.3222222328186035, loss=2.4694390296936035
train: epoch 59, loss 0.13115546107292175, acc=0.9616666436195374, loss=0.13115546107292175
test: epoch 59, loss 2.576812505722046, acc=0.35277777910232544, loss=2.576812505722046
train: epoch 60, loss 0.13486889004707336, acc=0.9599444270133972, loss=0.13486889004707336
test: epoch 60, loss 2.4764814376831055, acc=0.31111112236976624, loss=2.4764814376831055
train: epoch 61, loss 0.12860727310180664, acc=0.9623888731002808, loss=0.12860727310180664
test: epoch 61, loss 2.483448028564453, acc=0.3499999940395355, loss=2.483448028564453
train: epoch 62, loss 0.13103057444095612, acc=0.9628888964653015, loss=0.13103057444095612
test: epoch 62, loss 2.3943662643432617, acc=0.3333333432674408, loss=2.3943662643432617
train: epoch 63, loss 0.14161056280136108, acc=0.96061110496521, loss=0.14161056280136108
test: epoch 63, loss 2.4286556243896484, acc=0.35555556416511536, loss=2.4286556243896484
train: epoch 64, loss 0.11724872887134552, acc=0.9656111001968384, loss=0.11724872887134552
test: epoch 64, loss 2.4044740200042725, acc=0.375, loss=2.4044740200042725
train: epoch 65, loss 0.12213357537984848, acc=0.9654444456100464, loss=0.12213357537984848
test: epoch 65, loss 2.514564037322998, acc=0.3361110985279083, loss=2.514564037322998
train: epoch 66, loss 0.12874464690685272, acc=0.9645000100135803, loss=0.12874464690685272
test: epoch 66, loss 2.282780408859253, acc=0.38055557012557983, loss=2.282780408859253
train: epoch 67, loss 0.12225442379713058, acc=0.9667222499847412, loss=0.12225442379713058
test: epoch 67, loss 2.5188918113708496, acc=0.3444444537162781, loss=2.5188918113708496
train: epoch 68, loss 0.11780226975679398, acc=0.9666110873222351, loss=0.11780226975679398
test: epoch 68, loss 2.435011148452759, acc=0.3472222089767456, loss=2.435011148452759
train: epoch 69, loss 0.11027024686336517, acc=0.9673333168029785, loss=0.11027024686336517
test: epoch 69, loss 2.190215587615967, acc=0.3583333194255829, loss=2.190215587615967
train: epoch 70, loss 0.10659746080636978, acc=0.9696666598320007, loss=0.10659746080636978
test: epoch 70, loss 2.4193179607391357, acc=0.35555556416511536, loss=2.4193179607391357
train: epoch 71, loss 0.10630441457033157, acc=0.9696111083030701, loss=0.10630441457033157
test: epoch 71, loss 2.4561588764190674, acc=0.3194444477558136, loss=2.4561588764190674
train: epoch 72, loss 0.11385874450206757, acc=0.9665555357933044, loss=0.11385874450206757
test: epoch 72, loss 2.5244693756103516, acc=0.3333333432674408, loss=2.5244693756103516
train: epoch 73, loss 0.10806247591972351, acc=0.9684444665908813, loss=0.10806247591972351
test: epoch 73, loss 2.3183481693267822, acc=0.35555556416511536, loss=2.3183481693267822
train: epoch 74, loss 0.09320221841335297, acc=0.9718888998031616, loss=0.09320221841335297
test: epoch 74, loss 2.2998175621032715, acc=0.3722222149372101, loss=2.2998175621032715
train: epoch 75, loss 0.1014937162399292, acc=0.971666693687439, loss=0.1014937162399292
test: epoch 75, loss 2.440995454788208, acc=0.33888888359069824, loss=2.440995454788208
train: epoch 76, loss 0.0991729199886322, acc=0.9703333377838135, loss=0.0991729199886322
test: epoch 76, loss 2.5468437671661377, acc=0.3305555582046509, loss=2.5468437671661377
train: epoch 77, loss 0.09155239909887314, acc=0.973111093044281, loss=0.09155239909887314
test: epoch 77, loss 2.341019868850708, acc=0.32499998807907104, loss=2.341019868850708
train: epoch 78, loss 0.09757325798273087, acc=0.969944417476654, loss=0.09757325798273087
test: epoch 78, loss 2.239365339279175, acc=0.375, loss=2.239365339279175
train: epoch 79, loss 0.09682147949934006, acc=0.9723888635635376, loss=0.09682147949934006
test: epoch 79, loss 2.2636048793792725, acc=0.32499998807907104, loss=2.2636048793792725
train: epoch 80, loss 0.09214384108781815, acc=0.9728333353996277, loss=0.09214384108781815
test: epoch 80, loss 2.194685935974121, acc=0.35555556416511536, loss=2.194685935974121
train: epoch 81, loss 0.09164464473724365, acc=0.9751666784286499, loss=0.09164464473724365
test: epoch 81, loss 2.086885690689087, acc=0.38333332538604736, loss=2.086885690689087
train: epoch 82, loss 0.08697507530450821, acc=0.9739444255828857, loss=0.08697507530450821
test: epoch 82, loss 2.0740201473236084, acc=0.38055557012557983, loss=2.0740201473236084
train: epoch 83, loss 0.087073914706707, acc=0.9760000109672546, loss=0.087073914706707
test: epoch 83, loss 2.328904867172241, acc=0.36944442987442017, loss=2.328904867172241
train: epoch 84, loss 0.09481235593557358, acc=0.9732221961021423, loss=0.09481235593557358
test: epoch 84, loss 2.5404434204101562, acc=0.3055555522441864, loss=2.5404434204101562
train: epoch 85, loss 0.08638565987348557, acc=0.9743333458900452, loss=0.08638565987348557
test: epoch 85, loss 2.2323226928710938, acc=0.33888888359069824, loss=2.2323226928710938
train: epoch 86, loss 0.08757345378398895, acc=0.9763333201408386, loss=0.08757345378398895
test: epoch 86, loss 2.155993700027466, acc=0.3611111044883728, loss=2.155993700027466
train: epoch 87, loss 0.08180645853281021, acc=0.9762222170829773, loss=0.08180645853281021
test: epoch 87, loss 2.1030776500701904, acc=0.38055557012557983, loss=2.1030776500701904
train: epoch 88, loss 0.08253392577171326, acc=0.9754444360733032, loss=0.08253392577171326
test: epoch 88, loss 2.4677791595458984, acc=0.3499999940395355, loss=2.4677791595458984
train: epoch 89, loss 0.08016961812973022, acc=0.9764999747276306, loss=0.08016961812973022
test: epoch 89, loss 2.551924467086792, acc=0.3638888895511627, loss=2.551924467086792
train: epoch 90, loss 0.0756494402885437, acc=0.9775555729866028, loss=0.0756494402885437
test: epoch 90, loss 2.335383415222168, acc=0.3305555582046509, loss=2.335383415222168
train: epoch 91, loss 0.0766206681728363, acc=0.9791111350059509, loss=0.0766206681728363
test: epoch 91, loss 2.3022735118865967, acc=0.33888888359069824, loss=2.3022735118865967
train: epoch 92, loss 0.08230085670948029, acc=0.9775000214576721, loss=0.08230085670948029
test: epoch 92, loss 2.6200695037841797, acc=0.3222222328186035, loss=2.6200695037841797
train: epoch 93, loss 0.07135022431612015, acc=0.9807778000831604, loss=0.07135022431612015
test: epoch 93, loss 2.216726064682007, acc=0.39444443583488464, loss=2.216726064682007
train: epoch 94, loss 0.08604761958122253, acc=0.9761666655540466, loss=0.08604761958122253
test: epoch 94, loss 2.0588619709014893, acc=0.34166666865348816, loss=2.0588619709014893
train: epoch 95, loss 0.07349326461553574, acc=0.9784444570541382, loss=0.07349326461553574
test: epoch 95, loss 2.1246542930603027, acc=0.375, loss=2.1246542930603027
train: epoch 96, loss 0.08160775154829025, acc=0.9764444231987, loss=0.08160775154829025
test: epoch 96, loss 2.0683109760284424, acc=0.39444443583488464, loss=2.0683109760284424
train: epoch 97, loss 0.08637482672929764, acc=0.9764999747276306, loss=0.08637482672929764
test: epoch 97, loss 2.2348196506500244, acc=0.3611111044883728, loss=2.2348196506500244
train: epoch 98, loss 0.07419922947883606, acc=0.9793888926506042, loss=0.07419922947883606
test: epoch 98, loss 2.628096342086792, acc=0.3472222089767456, loss=2.628096342086792
train: epoch 99, loss 0.07268767058849335, acc=0.9790555834770203, loss=0.07268767058849335
test: epoch 99, loss 2.1160125732421875, acc=0.3722222149372101, loss=2.1160125732421875
train: epoch 100, loss 0.07467387616634369, acc=0.9794444441795349, loss=0.07467387616634369
test: epoch 100, loss 2.274003267288208, acc=0.3361110985279083, loss=2.274003267288208
train: epoch 101, loss 0.06686621159315109, acc=0.980388879776001, loss=0.06686621159315109
test: epoch 101, loss 2.2650136947631836, acc=0.36944442987442017, loss=2.2650136947631836
train: epoch 102, loss 0.07236254960298538, acc=0.9795555472373962, loss=0.07236254960298538
test: epoch 102, loss 2.5084547996520996, acc=0.34166666865348816, loss=2.5084547996520996
train: epoch 103, loss 0.07105133682489395, acc=0.9823889136314392, loss=0.07105133682489395
test: epoch 103, loss 2.7847800254821777, acc=0.3361110985279083, loss=2.7847800254821777
train: epoch 104, loss 0.06803669780492783, acc=0.9822221994400024, loss=0.06803669780492783
test: epoch 104, loss 2.2429075241088867, acc=0.3861111104488373, loss=2.2429075241088867
train: epoch 105, loss 0.06135687232017517, acc=0.9828333258628845, loss=0.06135687232017517
test: epoch 105, loss 2.1152641773223877, acc=0.3916666805744171, loss=2.1152641773223877
train: epoch 106, loss 0.06920633465051651, acc=0.9806110858917236, loss=0.06920633465051651
test: epoch 106, loss 2.179774761199951, acc=0.38333332538604736, loss=2.179774761199951
train: epoch 107, loss 0.05985603109002113, acc=0.9815000295639038, loss=0.05985603109002113
test: epoch 107, loss 2.0664238929748535, acc=0.4027777910232544, loss=2.0664238929748535
train: epoch 108, loss 0.06459758430719376, acc=0.9818888902664185, loss=0.06459758430719376
test: epoch 108, loss 2.4210526943206787, acc=0.375, loss=2.4210526943206787
train: epoch 109, loss 0.05487265810370445, acc=0.984333336353302, loss=0.05487265810370445
test: epoch 109, loss 2.3267288208007812, acc=0.4138889014720917, loss=2.3267288208007812
train: epoch 110, loss 0.06714196503162384, acc=0.9819999933242798, loss=0.06714196503162384
test: epoch 110, loss 2.425363302230835, acc=0.3638888895511627, loss=2.425363302230835
train: epoch 111, loss 0.06514601409435272, acc=0.9816666841506958, loss=0.06514601409435272
test: epoch 111, loss 2.20554256439209, acc=0.39722222089767456, loss=2.20554256439209
train: epoch 112, loss 0.056808438152074814, acc=0.9835555553436279, loss=0.056808438152074814
test: epoch 112, loss 2.3866472244262695, acc=0.4138889014720917, loss=2.3866472244262695
train: epoch 113, loss 0.056863754987716675, acc=0.9837222099304199, loss=0.056863754987716675
test: epoch 113, loss 2.2256741523742676, acc=0.42222222685813904, loss=2.2256741523742676
train: epoch 114, loss 0.06007416546344757, acc=0.9834444522857666, loss=0.06007416546344757
test: epoch 114, loss 2.540713310241699, acc=0.36666667461395264, loss=2.540713310241699
train: epoch 115, loss 0.056434739381074905, acc=0.98416668176651, loss=0.056434739381074905
test: epoch 115, loss 2.3009231090545654, acc=0.39722222089767456, loss=2.3009231090545654
train: epoch 116, loss 0.061155710369348526, acc=0.9838333129882812, loss=0.061155710369348526
test: epoch 116, loss 2.3574917316436768, acc=0.3861111104488373, loss=2.3574917316436768
train: epoch 117, loss 0.056904591619968414, acc=0.9833889007568359, loss=0.056904591619968414
test: epoch 117, loss 2.4995975494384766, acc=0.38055557012557983, loss=2.4995975494384766
train: epoch 118, loss 0.05637942627072334, acc=0.984000027179718, loss=0.05637942627072334
test: epoch 118, loss 2.388532876968384, acc=0.3916666805744171, loss=2.388532876968384
train: epoch 119, loss 0.05168098956346512, acc=0.9844444394111633, loss=0.05168098956346512
test: epoch 119, loss 2.167198419570923, acc=0.39444443583488464, loss=2.167198419570923
train: epoch 120, loss 0.05000603199005127, acc=0.9861111044883728, loss=0.05000603199005127
test: epoch 120, loss 2.3791615962982178, acc=0.4305555522441864, loss=2.3791615962982178
train: epoch 121, loss 0.05513865500688553, acc=0.9847777485847473, loss=0.05513865500688553
test: epoch 121, loss 2.0588574409484863, acc=0.4333333373069763, loss=2.0588574409484863
train: epoch 122, loss 0.05411913990974426, acc=0.9853888750076294, loss=0.05411913990974426
test: epoch 122, loss 2.388394832611084, acc=0.39722222089767456, loss=2.388394832611084
train: epoch 123, loss 0.055915698409080505, acc=0.9860000014305115, loss=0.055915698409080505
test: epoch 123, loss 2.283057689666748, acc=0.40833333134651184, loss=2.283057689666748
train: epoch 124, loss 0.04918796941637993, acc=0.9858333468437195, loss=0.04918796941637993
test: epoch 124, loss 2.536383628845215, acc=0.3722222149372101, loss=2.536383628845215
train: epoch 125, loss 0.054305970668792725, acc=0.9847221970558167, loss=0.054305970668792725
test: epoch 125, loss 2.367172956466675, acc=0.4027777910232544, loss=2.367172956466675
train: epoch 126, loss 0.05109277740120888, acc=0.9850555658340454, loss=0.05109277740120888
test: epoch 126, loss 2.594266414642334, acc=0.3777777850627899, loss=2.594266414642334
train: epoch 127, loss 0.05377880856394768, acc=0.9851111173629761, loss=0.05377880856394768
test: epoch 127, loss 2.4533379077911377, acc=0.3861111104488373, loss=2.4533379077911377
train: epoch 128, loss 0.05216953903436661, acc=0.9861666560173035, loss=0.05216953903436661
test: epoch 128, loss 2.465315103530884, acc=0.3888888955116272, loss=2.465315103530884
train: epoch 129, loss 0.046576276421546936, acc=0.9869444370269775, loss=0.046576276421546936
test: epoch 129, loss 2.456711530685425, acc=0.3861111104488373, loss=2.456711530685425
train: epoch 130, loss 0.05237835645675659, acc=0.9863333106040955, loss=0.05237835645675659
test: epoch 130, loss 2.0674097537994385, acc=0.4166666567325592, loss=2.0674097537994385
train: epoch 131, loss 0.04910583049058914, acc=0.9861111044883728, loss=0.04910583049058914
test: epoch 131, loss 2.1538846492767334, acc=0.42500001192092896, loss=2.1538846492767334
train: epoch 132, loss 0.0467437319457531, acc=0.9861111044883728, loss=0.0467437319457531
test: epoch 132, loss 2.214430570602417, acc=0.4305555522441864, loss=2.214430570602417
train: epoch 133, loss 0.050836458802223206, acc=0.9861111044883728, loss=0.050836458802223206
test: epoch 133, loss 2.310471296310425, acc=0.4166666567325592, loss=2.310471296310425
train: epoch 134, loss 0.04490560665726662, acc=0.9870555400848389, loss=0.04490560665726662
test: epoch 134, loss 2.286874532699585, acc=0.4055555462837219, loss=2.286874532699585
train: epoch 135, loss 0.05143227428197861, acc=0.9861666560173035, loss=0.05143227428197861
test: epoch 135, loss 2.8574559688568115, acc=0.3361110985279083, loss=2.8574559688568115
train: epoch 136, loss 0.04960344731807709, acc=0.9857222437858582, loss=0.04960344731807709
test: epoch 136, loss 2.005890130996704, acc=0.4277777671813965, loss=2.005890130996704
train: epoch 137, loss 0.0429077185690403, acc=0.988777756690979, loss=0.0429077185690403
test: epoch 137, loss 2.644742965698242, acc=0.38055557012557983, loss=2.644742965698242
train: epoch 138, loss 0.05361297354102135, acc=0.9865555763244629, loss=0.05361297354102135
test: epoch 138, loss 2.3647401332855225, acc=0.41111111640930176, loss=2.3647401332855225
train: epoch 139, loss 0.04252772033214569, acc=0.987666666507721, loss=0.04252772033214569
test: epoch 139, loss 2.516524076461792, acc=0.42500001192092896, loss=2.516524076461792
train: epoch 140, loss 0.04896274954080582, acc=0.9864444732666016, loss=0.04896274954080582
test: epoch 140, loss 2.3385396003723145, acc=0.40833333134651184, loss=2.3385396003723145
train: epoch 141, loss 0.037398338317871094, acc=0.9891666769981384, loss=0.037398338317871094
test: epoch 141, loss 2.5195441246032715, acc=0.42500001192092896, loss=2.5195441246032715
train: epoch 142, loss 0.05015062168240547, acc=0.9862777590751648, loss=0.05015062168240547
test: epoch 142, loss 2.5110602378845215, acc=0.3472222089767456, loss=2.5110602378845215
train: epoch 143, loss 0.045525189489126205, acc=0.9887222051620483, loss=0.045525189489126205
test: epoch 143, loss 2.405463695526123, acc=0.39722222089767456, loss=2.405463695526123
train: epoch 144, loss 0.039008475840091705, acc=0.9889444708824158, loss=0.039008475840091705
test: epoch 144, loss 2.3841960430145264, acc=0.4055555462837219, loss=2.3841960430145264
train: epoch 145, loss 0.04777580499649048, acc=0.9873889088630676, loss=0.04777580499649048
test: epoch 145, loss 2.341489315032959, acc=0.4277777671813965, loss=2.341489315032959
train: epoch 146, loss 0.04797518253326416, acc=0.9869999885559082, loss=0.04797518253326416
test: epoch 146, loss 2.510263204574585, acc=0.38055557012557983, loss=2.510263204574585
train: epoch 147, loss 0.0389995276927948, acc=0.988611102104187, loss=0.0389995276927948
test: epoch 147, loss 2.3713126182556152, acc=0.4027777910232544, loss=2.3713126182556152
train: epoch 148, loss 0.04188515990972519, acc=0.9880555272102356, loss=0.04188515990972519
test: epoch 148, loss 1.9722565412521362, acc=0.4166666567325592, loss=1.9722565412521362
train: epoch 149, loss 0.053389281034469604, acc=0.9890000224113464, loss=0.053389281034469604
test: epoch 149, loss 2.3321914672851562, acc=0.41111111640930176, loss=2.3321914672851562
train: epoch 150, loss 0.041448161005973816, acc=0.988777756690979, loss=0.041448161005973816
test: epoch 150, loss 2.3628785610198975, acc=0.41111111640930176, loss=2.3628785610198975
