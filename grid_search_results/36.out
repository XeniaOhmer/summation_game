# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=1", "--one_hot=0", "--n_layers=1"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=1237492755, receiver_embed_dim=32, save_run=0, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=1237492755, receiver_embed_dim=32, save_run=False, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.195643424987793, acc=0.08138889074325562, loss=3.195643424987793
test: epoch 1, loss 4.562270164489746, acc=0.04722222313284874, loss=4.562270164489746
train: epoch 2, loss 2.633063316345215, acc=0.1507222205400467, loss=2.633063316345215
test: epoch 2, loss 5.787782192230225, acc=0.04722222313284874, loss=5.787782192230225
train: epoch 3, loss 2.433922290802002, acc=0.19633333384990692, loss=2.433922290802002
test: epoch 3, loss 6.678276538848877, acc=0.0416666679084301, loss=6.678276538848877
train: epoch 4, loss 2.3345510959625244, acc=0.19911110401153564, loss=2.3345510959625244
test: epoch 4, loss 7.379005432128906, acc=0.0416666679084301, loss=7.379005432128906
train: epoch 5, loss 2.2502083778381348, acc=0.22111110389232635, loss=2.2502083778381348
test: epoch 5, loss 8.048041343688965, acc=0.0416666679084301, loss=8.048041343688965
train: epoch 6, loss 2.19657826423645, acc=0.23194444179534912, loss=2.19657826423645
test: epoch 6, loss 8.5260591506958, acc=0.04444444552063942, loss=8.5260591506958
train: epoch 7, loss 2.14286732673645, acc=0.24061110615730286, loss=2.14286732673645
test: epoch 7, loss 9.21318531036377, acc=0.04444444552063942, loss=9.21318531036377
train: epoch 8, loss 2.11226224899292, acc=0.24477778375148773, loss=2.11226224899292
test: epoch 8, loss 9.422259330749512, acc=0.04444444552063942, loss=9.422259330749512
train: epoch 9, loss 2.077852725982666, acc=0.25094443559646606, loss=2.077852725982666
test: epoch 9, loss 9.605587005615234, acc=0.0416666679084301, loss=9.605587005615234
train: epoch 10, loss 2.0357131958007812, acc=0.26555556058883667, loss=2.0357131958007812
test: epoch 10, loss 10.095622062683105, acc=0.04444444552063942, loss=10.095622062683105
train: epoch 11, loss 2.019329071044922, acc=0.2658333480358124, loss=2.019329071044922
test: epoch 11, loss 10.45979118347168, acc=0.03333333507180214, loss=10.45979118347168
train: epoch 12, loss 1.9786320924758911, acc=0.27472221851348877, loss=1.9786320924758911
test: epoch 12, loss 10.525362014770508, acc=0.03333333507180214, loss=10.525362014770508
train: epoch 13, loss 1.9712790250778198, acc=0.27477777004241943, loss=1.9712790250778198
test: epoch 13, loss 10.701970100402832, acc=0.03888889029622078, loss=10.701970100402832
train: epoch 14, loss 1.9433659315109253, acc=0.2872222363948822, loss=1.9433659315109253
test: epoch 14, loss 10.89568042755127, acc=0.03611111268401146, loss=10.89568042755127
train: epoch 15, loss 1.9240989685058594, acc=0.29072222113609314, loss=1.9240989685058594
test: epoch 15, loss 11.0452880859375, acc=0.03333333507180214, loss=11.0452880859375
train: epoch 16, loss 1.910753846168518, acc=0.29383334517478943, loss=1.910753846168518
test: epoch 16, loss 11.140159606933594, acc=0.03611111268401146, loss=11.140159606933594
train: epoch 17, loss 1.887332558631897, acc=0.29911109805107117, loss=1.887332558631897
test: epoch 17, loss 11.649198532104492, acc=0.03611111268401146, loss=11.649198532104492
train: epoch 18, loss 1.8784531354904175, acc=0.30177778005599976, loss=1.8784531354904175
test: epoch 18, loss 11.622905731201172, acc=0.03333333507180214, loss=11.622905731201172
train: epoch 19, loss 1.8563518524169922, acc=0.30194443464279175, loss=1.8563518524169922
test: epoch 19, loss 11.718132019042969, acc=0.03055555559694767, loss=11.718132019042969
train: epoch 20, loss 1.8471059799194336, acc=0.3106110990047455, loss=1.8471059799194336
test: epoch 20, loss 12.160785675048828, acc=0.03333333507180214, loss=12.160785675048828
train: epoch 21, loss 1.8247864246368408, acc=0.3156111240386963, loss=1.8247864246368408
test: epoch 21, loss 12.2506103515625, acc=0.03055555559694767, loss=12.2506103515625
train: epoch 22, loss 1.8164863586425781, acc=0.316222220659256, loss=1.8164863586425781
test: epoch 22, loss 11.939831733703613, acc=0.03333333507180214, loss=11.939831733703613
train: epoch 23, loss 1.8035221099853516, acc=0.3263888955116272, loss=1.8035221099853516
test: epoch 23, loss 12.539084434509277, acc=0.03055555559694767, loss=12.539084434509277
train: epoch 24, loss 1.8022754192352295, acc=0.3225555419921875, loss=1.8022754192352295
test: epoch 24, loss 12.4942626953125, acc=0.03055555559694767, loss=12.4942626953125
train: epoch 25, loss 1.783147931098938, acc=0.3265555500984192, loss=1.783147931098938
test: epoch 25, loss 12.49187183380127, acc=0.03333333507180214, loss=12.49187183380127
train: epoch 26, loss 1.7782784700393677, acc=0.3302222192287445, loss=1.7782784700393677
test: epoch 26, loss 12.492693901062012, acc=0.03888889029622078, loss=12.492693901062012
train: epoch 27, loss 1.7561575174331665, acc=0.3355555534362793, loss=1.7561575174331665
test: epoch 27, loss 12.713603973388672, acc=0.03333333507180214, loss=12.713603973388672
train: epoch 28, loss 1.7539918422698975, acc=0.33383333683013916, loss=1.7539918422698975
test: epoch 28, loss 12.625130653381348, acc=0.03888889029622078, loss=12.625130653381348
train: epoch 29, loss 1.7360628843307495, acc=0.3427777886390686, loss=1.7360628843307495
test: epoch 29, loss 12.560462951660156, acc=0.04444444552063942, loss=12.560462951660156
train: epoch 30, loss 1.7200201749801636, acc=0.3442777693271637, loss=1.7200201749801636
test: epoch 30, loss 12.823373794555664, acc=0.04722222313284874, loss=12.823373794555664
train: epoch 31, loss 1.719172716140747, acc=0.3464444577693939, loss=1.719172716140747
test: epoch 31, loss 12.936708450317383, acc=0.03333333507180214, loss=12.936708450317383
train: epoch 32, loss 1.6988816261291504, acc=0.3525555431842804, loss=1.6988816261291504
test: epoch 32, loss 13.162568092346191, acc=0.04444444552063942, loss=13.162568092346191
train: epoch 33, loss 1.701271414756775, acc=0.35511112213134766, loss=1.701271414756775
test: epoch 33, loss 13.34924030303955, acc=0.04444444552063942, loss=13.34924030303955
train: epoch 34, loss 1.7026700973510742, acc=0.35633334517478943, loss=1.7026700973510742
test: epoch 34, loss 13.38573169708252, acc=0.03055555559694767, loss=13.38573169708252
train: epoch 35, loss 1.6890320777893066, acc=0.35811111330986023, loss=1.6890320777893066
test: epoch 35, loss 13.564949989318848, acc=0.03333333507180214, loss=13.564949989318848
train: epoch 36, loss 1.6770257949829102, acc=0.36133334040641785, loss=1.6770257949829102
test: epoch 36, loss 13.677069664001465, acc=0.03333333507180214, loss=13.677069664001465
train: epoch 37, loss 1.6740086078643799, acc=0.3662777841091156, loss=1.6740086078643799
test: epoch 37, loss 13.615448951721191, acc=0.03055555559694767, loss=13.615448951721191
train: epoch 38, loss 1.6597998142242432, acc=0.36677777767181396, loss=1.6597998142242432
test: epoch 38, loss 14.06725025177002, acc=0.03888889029622078, loss=14.06725025177002
train: epoch 39, loss 1.642898678779602, acc=0.3691111207008362, loss=1.642898678779602
test: epoch 39, loss 13.848451614379883, acc=0.03611111268401146, loss=13.848451614379883
train: epoch 40, loss 1.641591191291809, acc=0.37138888239860535, loss=1.641591191291809
test: epoch 40, loss 13.734060287475586, acc=0.03611111268401146, loss=13.734060287475586
train: epoch 41, loss 1.6314425468444824, acc=0.37416666746139526, loss=1.6314425468444824
test: epoch 41, loss 13.782610893249512, acc=0.03611111268401146, loss=13.782610893249512
train: epoch 42, loss 1.6372929811477661, acc=0.3700000047683716, loss=1.6372929811477661
test: epoch 42, loss 13.432931900024414, acc=0.0416666679084301, loss=13.432931900024414
train: epoch 43, loss 1.608542799949646, acc=0.3852222263813019, loss=1.608542799949646
test: epoch 43, loss 13.641305923461914, acc=0.03055555559694767, loss=13.641305923461914
train: epoch 44, loss 1.6075005531311035, acc=0.3866666555404663, loss=1.6075005531311035
test: epoch 44, loss 13.788422584533691, acc=0.03055555559694767, loss=13.788422584533691
train: epoch 45, loss 1.6131824254989624, acc=0.382666677236557, loss=1.6131824254989624
test: epoch 45, loss 13.891317367553711, acc=0.03333333507180214, loss=13.891317367553711
train: epoch 46, loss 1.6006863117218018, acc=0.37994444370269775, loss=1.6006863117218018
test: epoch 46, loss 13.897334098815918, acc=0.03333333507180214, loss=13.897334098815918
train: epoch 47, loss 1.5898802280426025, acc=0.39322221279144287, loss=1.5898802280426025
test: epoch 47, loss 14.135259628295898, acc=0.03611111268401146, loss=14.135259628295898
train: epoch 48, loss 1.5830682516098022, acc=0.38927778601646423, loss=1.5830682516098022
test: epoch 48, loss 14.288018226623535, acc=0.03333333507180214, loss=14.288018226623535
train: epoch 49, loss 1.5777640342712402, acc=0.3991111218929291, loss=1.5777640342712402
test: epoch 49, loss 14.298171997070312, acc=0.03333333507180214, loss=14.298171997070312
train: epoch 50, loss 1.5807297229766846, acc=0.39355555176734924, loss=1.5807297229766846
test: epoch 50, loss 14.707625389099121, acc=0.03333333507180214, loss=14.707625389099121
train: epoch 51, loss 1.569987177848816, acc=0.39899998903274536, loss=1.569987177848816
test: epoch 51, loss 14.559708595275879, acc=0.03333333507180214, loss=14.559708595275879
train: epoch 52, loss 1.5606409311294556, acc=0.3948333263397217, loss=1.5606409311294556
test: epoch 52, loss 14.465970039367676, acc=0.0416666679084301, loss=14.465970039367676
train: epoch 53, loss 1.5462993383407593, acc=0.40905556082725525, loss=1.5462993383407593
test: epoch 53, loss 14.754495620727539, acc=0.04444444552063942, loss=14.754495620727539
train: epoch 54, loss 1.5549254417419434, acc=0.4042222201824188, loss=1.5549254417419434
test: epoch 54, loss 14.726583480834961, acc=0.03611111268401146, loss=14.726583480834961
train: epoch 55, loss 1.5446195602416992, acc=0.4117777645587921, loss=1.5446195602416992
test: epoch 55, loss 14.27391529083252, acc=0.03333333507180214, loss=14.27391529083252
train: epoch 56, loss 1.5411452054977417, acc=0.41183334589004517, loss=1.5411452054977417
test: epoch 56, loss 14.665763854980469, acc=0.03611111268401146, loss=14.665763854980469
train: epoch 57, loss 1.5367292165756226, acc=0.40950000286102295, loss=1.5367292165756226
test: epoch 57, loss 14.509516716003418, acc=0.03333333507180214, loss=14.509516716003418
train: epoch 58, loss 1.5234260559082031, acc=0.4135555624961853, loss=1.5234260559082031
test: epoch 58, loss 14.96518611907959, acc=0.03611111268401146, loss=14.96518611907959
train: epoch 59, loss 1.5337696075439453, acc=0.41894444823265076, loss=1.5337696075439453
test: epoch 59, loss 15.316832542419434, acc=0.03333333507180214, loss=15.316832542419434
train: epoch 60, loss 1.5131897926330566, acc=0.41172221302986145, loss=1.5131897926330566
test: epoch 60, loss 15.550649642944336, acc=0.03333333507180214, loss=15.550649642944336
train: epoch 61, loss 1.5233920812606812, acc=0.4185555577278137, loss=1.5233920812606812
test: epoch 61, loss 15.206446647644043, acc=0.03333333507180214, loss=15.206446647644043
train: epoch 62, loss 1.50690758228302, acc=0.4217222332954407, loss=1.50690758228302
test: epoch 62, loss 15.263031959533691, acc=0.03333333507180214, loss=15.263031959533691
train: epoch 63, loss 1.497382402420044, acc=0.4250555634498596, loss=1.497382402420044
test: epoch 63, loss 15.328747749328613, acc=0.03333333507180214, loss=15.328747749328613
train: epoch 64, loss 1.501086950302124, acc=0.4289444386959076, loss=1.501086950302124
test: epoch 64, loss 15.04269790649414, acc=0.03333333507180214, loss=15.04269790649414
train: epoch 65, loss 1.4965490102767944, acc=0.42188888788223267, loss=1.4965490102767944
test: epoch 65, loss 15.282343864440918, acc=0.03333333507180214, loss=15.282343864440918
train: epoch 66, loss 1.4904617071151733, acc=0.4307222366333008, loss=1.4904617071151733
test: epoch 66, loss 14.792091369628906, acc=0.03333333507180214, loss=14.792091369628906
train: epoch 67, loss 1.4808294773101807, acc=0.42988887429237366, loss=1.4808294773101807
test: epoch 67, loss 15.907556533813477, acc=0.03333333507180214, loss=15.907556533813477
train: epoch 68, loss 1.4848620891571045, acc=0.4272777736186981, loss=1.4848620891571045
test: epoch 68, loss 15.624959945678711, acc=0.03888889029622078, loss=15.624959945678711
train: epoch 69, loss 1.475639820098877, acc=0.43272221088409424, loss=1.475639820098877
test: epoch 69, loss 15.760183334350586, acc=0.03333333507180214, loss=15.760183334350586
train: epoch 70, loss 1.4698063135147095, acc=0.4356110990047455, loss=1.4698063135147095
test: epoch 70, loss 15.476667404174805, acc=0.03333333507180214, loss=15.476667404174805
train: epoch 71, loss 1.463380217552185, acc=0.4400555491447449, loss=1.463380217552185
test: epoch 71, loss 15.734204292297363, acc=0.03333333507180214, loss=15.734204292297363
train: epoch 72, loss 1.4588775634765625, acc=0.43716666102409363, loss=1.4588775634765625
test: epoch 72, loss 15.662210464477539, acc=0.03333333507180214, loss=15.662210464477539
train: epoch 73, loss 1.4550178050994873, acc=0.4398333430290222, loss=1.4550178050994873
test: epoch 73, loss 15.732593536376953, acc=0.03333333507180214, loss=15.732593536376953
train: epoch 74, loss 1.4481958150863647, acc=0.441388875246048, loss=1.4481958150863647
test: epoch 74, loss 15.491954803466797, acc=0.03333333507180214, loss=15.491954803466797
train: epoch 75, loss 1.4472856521606445, acc=0.43844443559646606, loss=1.4472856521606445
test: epoch 75, loss 15.696545600891113, acc=0.03333333507180214, loss=15.696545600891113
train: epoch 76, loss 1.4404536485671997, acc=0.44894444942474365, loss=1.4404536485671997
test: epoch 76, loss 15.900859832763672, acc=0.03333333507180214, loss=15.900859832763672
train: epoch 77, loss 1.4507403373718262, acc=0.4491666555404663, loss=1.4507403373718262
test: epoch 77, loss 15.575178146362305, acc=0.03333333507180214, loss=15.575178146362305
train: epoch 78, loss 1.4395337104797363, acc=0.4468333423137665, loss=1.4395337104797363
test: epoch 78, loss 15.854106903076172, acc=0.03333333507180214, loss=15.854106903076172
train: epoch 79, loss 1.4300780296325684, acc=0.4519444406032562, loss=1.4300780296325684
test: epoch 79, loss 16.222257614135742, acc=0.03333333507180214, loss=16.222257614135742
train: epoch 80, loss 1.4248939752578735, acc=0.4532777667045593, loss=1.4248939752578735
test: epoch 80, loss 16.080059051513672, acc=0.03333333507180214, loss=16.080059051513672
train: epoch 81, loss 1.4263406991958618, acc=0.45249998569488525, loss=1.4263406991958618
test: epoch 81, loss 16.565969467163086, acc=0.03333333507180214, loss=16.565969467163086
train: epoch 82, loss 1.419410228729248, acc=0.4588888883590698, loss=1.419410228729248
test: epoch 82, loss 16.239421844482422, acc=0.03333333507180214, loss=16.239421844482422
train: epoch 83, loss 1.418522596359253, acc=0.45705556869506836, loss=1.418522596359253
test: epoch 83, loss 16.478872299194336, acc=0.03333333507180214, loss=16.478872299194336
train: epoch 84, loss 1.4185537099838257, acc=0.4536111056804657, loss=1.4185537099838257
test: epoch 84, loss 16.266820907592773, acc=0.03333333507180214, loss=16.266820907592773
train: epoch 85, loss 1.3977769613265991, acc=0.4614444375038147, loss=1.3977769613265991
test: epoch 85, loss 16.5096435546875, acc=0.03611111268401146, loss=16.5096435546875
train: epoch 86, loss 1.4041310548782349, acc=0.4584444463253021, loss=1.4041310548782349
test: epoch 86, loss 16.76000213623047, acc=0.03888889029622078, loss=16.76000213623047
train: epoch 87, loss 1.3907347917556763, acc=0.4655555486679077, loss=1.3907347917556763
test: epoch 87, loss 16.84726905822754, acc=0.03611111268401146, loss=16.84726905822754
train: epoch 88, loss 1.3977326154708862, acc=0.4684999883174896, loss=1.3977326154708862
test: epoch 88, loss 16.857736587524414, acc=0.03888889029622078, loss=16.857736587524414
train: epoch 89, loss 1.398785948753357, acc=0.4607222080230713, loss=1.398785948753357
test: epoch 89, loss 16.976289749145508, acc=0.03611111268401146, loss=16.976289749145508
train: epoch 90, loss 1.3928626775741577, acc=0.46122223138809204, loss=1.3928626775741577
test: epoch 90, loss 16.829938888549805, acc=0.03611111268401146, loss=16.829938888549805
train: epoch 91, loss 1.3926600217819214, acc=0.4664444327354431, loss=1.3926600217819214
test: epoch 91, loss 16.446189880371094, acc=0.03611111268401146, loss=16.446189880371094
train: epoch 92, loss 1.3863996267318726, acc=0.47183331847190857, loss=1.3863996267318726
test: epoch 92, loss 16.84483528137207, acc=0.03055555559694767, loss=16.84483528137207
train: epoch 93, loss 1.3769556283950806, acc=0.46594443917274475, loss=1.3769556283950806
test: epoch 93, loss 17.202959060668945, acc=0.03333333507180214, loss=17.202959060668945
train: epoch 94, loss 1.3741557598114014, acc=0.46877777576446533, loss=1.3741557598114014
test: epoch 94, loss 16.757015228271484, acc=0.0416666679084301, loss=16.757015228271484
train: epoch 95, loss 1.37538480758667, acc=0.47200000286102295, loss=1.37538480758667
test: epoch 95, loss 16.39565658569336, acc=0.04444444552063942, loss=16.39565658569336
train: epoch 96, loss 1.3772879838943481, acc=0.47377777099609375, loss=1.3772879838943481
test: epoch 96, loss 16.456926345825195, acc=0.0416666679084301, loss=16.456926345825195
train: epoch 97, loss 1.3663300275802612, acc=0.4786111116409302, loss=1.3663300275802612
test: epoch 97, loss 16.94375228881836, acc=0.02777777798473835, loss=16.94375228881836
train: epoch 98, loss 1.3619070053100586, acc=0.47850000858306885, loss=1.3619070053100586
test: epoch 98, loss 17.254817962646484, acc=0.02500000037252903, loss=17.254817962646484
train: epoch 99, loss 1.3564434051513672, acc=0.4692777693271637, loss=1.3564434051513672
test: epoch 99, loss 17.383197784423828, acc=0.01944444514811039, loss=17.383197784423828
train: epoch 100, loss 1.3631601333618164, acc=0.4760555624961853, loss=1.3631601333618164
test: epoch 100, loss 18.070358276367188, acc=0.01944444514811039, loss=18.070358276367188
train: epoch 101, loss 1.355954647064209, acc=0.47733333706855774, loss=1.355954647064209
test: epoch 101, loss 16.58141326904297, acc=0.01944444514811039, loss=16.58141326904297
train: epoch 102, loss 1.3548212051391602, acc=0.4786111116409302, loss=1.3548212051391602
test: epoch 102, loss 16.626462936401367, acc=0.01944444514811039, loss=16.626462936401367
train: epoch 103, loss 1.3485606908798218, acc=0.48249998688697815, loss=1.3485606908798218
test: epoch 103, loss 18.527103424072266, acc=0.01944444514811039, loss=18.527103424072266
train: epoch 104, loss 1.3527488708496094, acc=0.4861111044883728, loss=1.3527488708496094
test: epoch 104, loss 16.705726623535156, acc=0.02777777798473835, loss=16.705726623535156
train: epoch 105, loss 1.3400503396987915, acc=0.48605555295944214, loss=1.3400503396987915
test: epoch 105, loss 17.171310424804688, acc=0.02777777798473835, loss=17.171310424804688
train: epoch 106, loss 1.3326942920684814, acc=0.4803333282470703, loss=1.3326942920684814
test: epoch 106, loss 17.49332618713379, acc=0.02777777798473835, loss=17.49332618713379
train: epoch 107, loss 1.3390605449676514, acc=0.4864444434642792, loss=1.3390605449676514
test: epoch 107, loss 17.27581214904785, acc=0.0416666679084301, loss=17.27581214904785
train: epoch 108, loss 1.3398560285568237, acc=0.48350000381469727, loss=1.3398560285568237
test: epoch 108, loss 17.23395347595215, acc=0.03888889029622078, loss=17.23395347595215
train: epoch 109, loss 1.328001856803894, acc=0.4909999966621399, loss=1.328001856803894
test: epoch 109, loss 16.8360595703125, acc=0.02500000037252903, loss=16.8360595703125
train: epoch 110, loss 1.326705813407898, acc=0.492333322763443, loss=1.326705813407898
test: epoch 110, loss 17.30964469909668, acc=0.02777777798473835, loss=17.30964469909668
train: epoch 111, loss 1.324581503868103, acc=0.49505555629730225, loss=1.324581503868103
test: epoch 111, loss 17.54774284362793, acc=0.02500000037252903, loss=17.54774284362793
train: epoch 112, loss 1.3288147449493408, acc=0.49016666412353516, loss=1.3288147449493408
test: epoch 112, loss 17.361852645874023, acc=0.02222222276031971, loss=17.361852645874023
train: epoch 113, loss 1.3051459789276123, acc=0.49355554580688477, loss=1.3051459789276123
test: epoch 113, loss 17.464590072631836, acc=0.02222222276031971, loss=17.464590072631836
train: epoch 114, loss 1.3302395343780518, acc=0.4928888976573944, loss=1.3302395343780518
test: epoch 114, loss 17.41811180114746, acc=0.03333333507180214, loss=17.41811180114746
train: epoch 115, loss 1.3179306983947754, acc=0.49827778339385986, loss=1.3179306983947754
test: epoch 115, loss 17.64546775817871, acc=0.01944444514811039, loss=17.64546775817871
train: epoch 116, loss 1.31804358959198, acc=0.4949444532394409, loss=1.31804358959198
test: epoch 116, loss 17.64109230041504, acc=0.03055555559694767, loss=17.64109230041504
train: epoch 117, loss 1.3144787549972534, acc=0.496055543422699, loss=1.3144787549972534
test: epoch 117, loss 17.778013229370117, acc=0.03055555559694767, loss=17.778013229370117
train: epoch 118, loss 1.307152271270752, acc=0.4967222213745117, loss=1.307152271270752
test: epoch 118, loss 18.332176208496094, acc=0.03333333507180214, loss=18.332176208496094
train: epoch 119, loss 1.3047757148742676, acc=0.500166654586792, loss=1.3047757148742676
test: epoch 119, loss 18.545522689819336, acc=0.02777777798473835, loss=18.545522689819336
train: epoch 120, loss 1.2963776588439941, acc=0.5037222504615784, loss=1.2963776588439941
test: epoch 120, loss 18.417638778686523, acc=0.02777777798473835, loss=18.417638778686523
train: epoch 121, loss 1.300012230873108, acc=0.4983333349227905, loss=1.300012230873108
test: epoch 121, loss 17.944406509399414, acc=0.01944444514811039, loss=17.944406509399414
train: epoch 122, loss 1.304017424583435, acc=0.5027222037315369, loss=1.304017424583435
test: epoch 122, loss 17.355871200561523, acc=0.01944444514811039, loss=17.355871200561523
train: epoch 123, loss 1.2915107011795044, acc=0.5113333463668823, loss=1.2915107011795044
test: epoch 123, loss 18.569339752197266, acc=0.01944444514811039, loss=18.569339752197266
train: epoch 124, loss 1.280557632446289, acc=0.5101110935211182, loss=1.280557632446289
test: epoch 124, loss 17.895479202270508, acc=0.01944444514811039, loss=17.895479202270508
train: epoch 125, loss 1.2881337404251099, acc=0.5104444622993469, loss=1.2881337404251099
test: epoch 125, loss 18.227397918701172, acc=0.02222222276031971, loss=18.227397918701172
train: epoch 126, loss 1.2911213636398315, acc=0.5102777481079102, loss=1.2911213636398315
test: epoch 126, loss 18.049720764160156, acc=0.02222222276031971, loss=18.049720764160156
train: epoch 127, loss 1.2793697118759155, acc=0.5136666893959045, loss=1.2793697118759155
test: epoch 127, loss 18.206920623779297, acc=0.02222222276031971, loss=18.206920623779297
train: epoch 128, loss 1.292307734489441, acc=0.5057222247123718, loss=1.292307734489441
test: epoch 128, loss 17.554954528808594, acc=0.02500000037252903, loss=17.554954528808594
train: epoch 129, loss 1.281313419342041, acc=0.5048888921737671, loss=1.281313419342041
test: epoch 129, loss 18.393335342407227, acc=0.02222222276031971, loss=18.393335342407227
train: epoch 130, loss 1.2750829458236694, acc=0.5141111016273499, loss=1.2750829458236694
test: epoch 130, loss 17.88380241394043, acc=0.02222222276031971, loss=17.88380241394043
train: epoch 131, loss 1.268041729927063, acc=0.5156111121177673, loss=1.268041729927063
test: epoch 131, loss 18.213930130004883, acc=0.02222222276031971, loss=18.213930130004883
train: epoch 132, loss 1.2693814039230347, acc=0.5133888721466064, loss=1.2693814039230347
test: epoch 132, loss 18.477048873901367, acc=0.02222222276031971, loss=18.477048873901367
train: epoch 133, loss 1.2638740539550781, acc=0.5111666917800903, loss=1.2638740539550781
test: epoch 133, loss 17.978097915649414, acc=0.03333333507180214, loss=17.978097915649414
train: epoch 134, loss 1.2486188411712646, acc=0.5168889164924622, loss=1.2486188411712646
test: epoch 134, loss 18.516746520996094, acc=0.02222222276031971, loss=18.516746520996094
train: epoch 135, loss 1.2602574825286865, acc=0.5196666717529297, loss=1.2602574825286865
test: epoch 135, loss 18.70539093017578, acc=0.02222222276031971, loss=18.70539093017578
train: epoch 136, loss 1.2708066701889038, acc=0.5106111168861389, loss=1.2708066701889038
test: epoch 136, loss 18.278066635131836, acc=0.03888889029622078, loss=18.278066635131836
train: epoch 137, loss 1.2589010000228882, acc=0.5236666798591614, loss=1.2589010000228882
test: epoch 137, loss 18.473573684692383, acc=0.03888889029622078, loss=18.473573684692383
train: epoch 138, loss 1.2547975778579712, acc=0.5223888754844666, loss=1.2547975778579712
test: epoch 138, loss 19.046682357788086, acc=0.01944444514811039, loss=19.046682357788086
train: epoch 139, loss 1.2582488059997559, acc=0.5165555477142334, loss=1.2582488059997559
test: epoch 139, loss 19.046056747436523, acc=0.02777777798473835, loss=19.046056747436523
train: epoch 140, loss 1.2460598945617676, acc=0.526888906955719, loss=1.2460598945617676
test: epoch 140, loss 18.83345603942871, acc=0.03611111268401146, loss=18.83345603942871
train: epoch 141, loss 1.254338264465332, acc=0.5202777981758118, loss=1.254338264465332
test: epoch 141, loss 19.032575607299805, acc=0.01944444514811039, loss=19.032575607299805
train: epoch 142, loss 1.251161813735962, acc=0.5260555744171143, loss=1.251161813735962
test: epoch 142, loss 19.028478622436523, acc=0.02222222276031971, loss=19.028478622436523
train: epoch 143, loss 1.234821081161499, acc=0.5265555381774902, loss=1.234821081161499
test: epoch 143, loss 19.218692779541016, acc=0.02500000037252903, loss=19.218692779541016
train: epoch 144, loss 1.2445193529129028, acc=0.5224999785423279, loss=1.2445193529129028
test: epoch 144, loss 19.345205307006836, acc=0.03055555559694767, loss=19.345205307006836
train: epoch 145, loss 1.2441227436065674, acc=0.5292222499847412, loss=1.2441227436065674
test: epoch 145, loss 18.87862777709961, acc=0.02777777798473835, loss=18.87862777709961
train: epoch 146, loss 1.2328451871871948, acc=0.5292222499847412, loss=1.2328451871871948
test: epoch 146, loss 20.16903305053711, acc=0.02777777798473835, loss=20.16903305053711
train: epoch 147, loss 1.2388864755630493, acc=0.5334444642066956, loss=1.2388864755630493
test: epoch 147, loss 19.644487380981445, acc=0.02222222276031971, loss=19.644487380981445
train: epoch 148, loss 1.236478567123413, acc=0.5291110873222351, loss=1.236478567123413
test: epoch 148, loss 19.643573760986328, acc=0.02222222276031971, loss=19.643573760986328
train: epoch 149, loss 1.2350562810897827, acc=0.5299999713897705, loss=1.2350562810897827
test: epoch 149, loss 18.744956970214844, acc=0.02222222276031971, loss=18.744956970214844
train: epoch 150, loss 1.218361496925354, acc=0.5312222242355347, loss=1.218361496925354
test: epoch 150, loss 19.32028579711914, acc=0.02222222276031971, loss=19.32028579711914
