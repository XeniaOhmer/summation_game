# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=1", "--temp_decay=1", "--one_hot=0", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=565871093, receiver_embed_dim=64, save_run=0, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=565871093, receiver_embed_dim=64, save_run=False, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.8443150520324707, acc=0.10249999910593033, loss=2.8443150520324707
test: epoch 1, loss 3.770934820175171, acc=0.05277777835726738, loss=3.770934820175171
train: epoch 2, loss 2.168013572692871, acc=0.18844445049762726, loss=2.168013572692871
test: epoch 2, loss 2.7346479892730713, acc=0.17499999701976776, loss=2.7346479892730713
train: epoch 3, loss 1.8796144723892212, acc=0.26544445753097534, loss=1.8796144723892212
test: epoch 3, loss 2.263573408126831, acc=0.21666666865348816, loss=2.263573408126831
train: epoch 4, loss 1.7009246349334717, acc=0.3118889033794403, loss=1.7009246349334717
test: epoch 4, loss 2.208364486694336, acc=0.20277777314186096, loss=2.208364486694336
train: epoch 5, loss 1.5447547435760498, acc=0.36605554819107056, loss=1.5447547435760498
test: epoch 5, loss 1.9507313966751099, acc=0.20277777314186096, loss=1.9507313966751099
train: epoch 6, loss 1.430198073387146, acc=0.4091666638851166, loss=1.430198073387146
test: epoch 6, loss 2.043330669403076, acc=0.20277777314186096, loss=2.043330669403076
train: epoch 7, loss 1.3285962343215942, acc=0.44600000977516174, loss=1.3285962343215942
test: epoch 7, loss 1.7084816694259644, acc=0.25833332538604736, loss=1.7084816694259644
train: epoch 8, loss 1.268114686012268, acc=0.47244444489479065, loss=1.268114686012268
test: epoch 8, loss 1.6914595365524292, acc=0.3027777671813965, loss=1.6914595365524292
train: epoch 9, loss 1.23810613155365, acc=0.4852222204208374, loss=1.23810613155365
test: epoch 9, loss 1.7957106828689575, acc=0.3333333432674408, loss=1.7957106828689575
train: epoch 10, loss 1.1609684228897095, acc=0.5111666917800903, loss=1.1609684228897095
test: epoch 10, loss 1.6943224668502808, acc=0.34166666865348816, loss=1.6943224668502808
train: epoch 11, loss 1.1214196681976318, acc=0.5350555777549744, loss=1.1214196681976318
test: epoch 11, loss 1.7419774532318115, acc=0.3055555522441864, loss=1.7419774532318115
train: epoch 12, loss 1.0760934352874756, acc=0.5519444346427917, loss=1.0760934352874756
test: epoch 12, loss 1.6877139806747437, acc=0.3361110985279083, loss=1.6877139806747437
train: epoch 13, loss 1.0483214855194092, acc=0.566277801990509, loss=1.0483214855194092
test: epoch 13, loss 1.9498554468154907, acc=0.38333332538604736, loss=1.9498554468154907
train: epoch 14, loss 1.0082310438156128, acc=0.5900555849075317, loss=1.0082310438156128
test: epoch 14, loss 1.7384088039398193, acc=0.3166666626930237, loss=1.7384088039398193
train: epoch 15, loss 0.9715099334716797, acc=0.5990555286407471, loss=0.9715099334716797
test: epoch 15, loss 1.7608261108398438, acc=0.2750000059604645, loss=1.7608261108398438
train: epoch 16, loss 0.941750168800354, acc=0.6105555295944214, loss=0.941750168800354
test: epoch 16, loss 1.6314303874969482, acc=0.3638888895511627, loss=1.6314303874969482
train: epoch 17, loss 0.913401186466217, acc=0.6285555362701416, loss=0.913401186466217
test: epoch 17, loss 1.7287774085998535, acc=0.38055557012557983, loss=1.7287774085998535
train: epoch 18, loss 0.9086752533912659, acc=0.6263889074325562, loss=0.9086752533912659
test: epoch 18, loss 1.6619791984558105, acc=0.3583333194255829, loss=1.6619791984558105
train: epoch 19, loss 0.8809928894042969, acc=0.6395555734634399, loss=0.8809928894042969
test: epoch 19, loss 1.7043111324310303, acc=0.4277777671813965, loss=1.7043111324310303
train: epoch 20, loss 0.8487699627876282, acc=0.6500555276870728, loss=0.8487699627876282
test: epoch 20, loss 1.6099976301193237, acc=0.4027777910232544, loss=1.6099976301193237
train: epoch 21, loss 0.8270480036735535, acc=0.6618888974189758, loss=0.8270480036735535
test: epoch 21, loss 1.6970552206039429, acc=0.41111111640930176, loss=1.6970552206039429
train: epoch 22, loss 0.8125268220901489, acc=0.6668888926506042, loss=0.8125268220901489
test: epoch 22, loss 1.594908356666565, acc=0.4027777910232544, loss=1.594908356666565
train: epoch 23, loss 0.7953917384147644, acc=0.6715555787086487, loss=0.7953917384147644
test: epoch 23, loss 1.6901404857635498, acc=0.36666667461395264, loss=1.6901404857635498
train: epoch 24, loss 0.7981584072113037, acc=0.676111102104187, loss=0.7981584072113037
test: epoch 24, loss 1.619378924369812, acc=0.3638888895511627, loss=1.619378924369812
train: epoch 25, loss 0.7642918825149536, acc=0.6891666650772095, loss=0.7642918825149536
test: epoch 25, loss 1.3966245651245117, acc=0.3916666805744171, loss=1.3966245651245117
train: epoch 26, loss 0.7525219321250916, acc=0.6913889050483704, loss=0.7525219321250916
test: epoch 26, loss 1.5350970029830933, acc=0.3888888955116272, loss=1.5350970029830933
train: epoch 27, loss 0.7438251376152039, acc=0.6967777609825134, loss=0.7438251376152039
test: epoch 27, loss 1.5791958570480347, acc=0.39722222089767456, loss=1.5791958570480347
train: epoch 28, loss 0.7259505391120911, acc=0.7053333520889282, loss=0.7259505391120911
test: epoch 28, loss 1.7574348449707031, acc=0.41111111640930176, loss=1.7574348449707031
train: epoch 29, loss 0.7147791385650635, acc=0.7067221999168396, loss=0.7147791385650635
test: epoch 29, loss 1.7414031028747559, acc=0.3722222149372101, loss=1.7414031028747559
train: epoch 30, loss 0.706087589263916, acc=0.7125555276870728, loss=0.706087589263916
test: epoch 30, loss 1.5864125490188599, acc=0.4749999940395355, loss=1.5864125490188599
train: epoch 31, loss 0.7034504413604736, acc=0.7125555276870728, loss=0.7034504413604736
test: epoch 31, loss 1.4637507200241089, acc=0.4027777910232544, loss=1.4637507200241089
train: epoch 32, loss 0.6878839135169983, acc=0.7173333168029785, loss=0.6878839135169983
test: epoch 32, loss 1.4880964756011963, acc=0.39444443583488464, loss=1.4880964756011963
train: epoch 33, loss 0.6566101312637329, acc=0.7326111197471619, loss=0.6566101312637329
test: epoch 33, loss 1.732168436050415, acc=0.32499998807907104, loss=1.732168436050415
train: epoch 34, loss 0.6526927947998047, acc=0.7318333387374878, loss=0.6526927947998047
test: epoch 34, loss 1.689573884010315, acc=0.4472222328186035, loss=1.689573884010315
train: epoch 35, loss 0.6561792492866516, acc=0.7299444675445557, loss=0.6561792492866516
test: epoch 35, loss 1.4300744533538818, acc=0.42500001192092896, loss=1.4300744533538818
train: epoch 36, loss 0.6374121308326721, acc=0.7411666512489319, loss=0.6374121308326721
test: epoch 36, loss 1.7421021461486816, acc=0.42500001192092896, loss=1.7421021461486816
train: epoch 37, loss 0.6312336325645447, acc=0.7411110997200012, loss=0.6312336325645447
test: epoch 37, loss 1.4994392395019531, acc=0.4472222328186035, loss=1.4994392395019531
train: epoch 38, loss 0.6421352028846741, acc=0.7364444732666016, loss=0.6421352028846741
test: epoch 38, loss 1.4034183025360107, acc=0.4277777671813965, loss=1.4034183025360107
train: epoch 39, loss 0.6043313145637512, acc=0.7522777915000916, loss=0.6043313145637512
test: epoch 39, loss 1.3667521476745605, acc=0.4611110985279083, loss=1.3667521476745605
train: epoch 40, loss 0.6119562983512878, acc=0.754277765750885, loss=0.6119562983512878
test: epoch 40, loss 1.3306739330291748, acc=0.38333332538604736, loss=1.3306739330291748
train: epoch 41, loss 0.6225276589393616, acc=0.7461666464805603, loss=0.6225276589393616
test: epoch 41, loss 1.4634859561920166, acc=0.4472222328186035, loss=1.4634859561920166
train: epoch 42, loss 0.603505551815033, acc=0.7526111006736755, loss=0.603505551815033
test: epoch 42, loss 1.3810627460479736, acc=0.5111111402511597, loss=1.3810627460479736
train: epoch 43, loss 0.5898985266685486, acc=0.7630000114440918, loss=0.5898985266685486
test: epoch 43, loss 1.4881924390792847, acc=0.5111111402511597, loss=1.4881924390792847
train: epoch 44, loss 0.5888413190841675, acc=0.7576666474342346, loss=0.5888413190841675
test: epoch 44, loss 1.4560449123382568, acc=0.42222222685813904, loss=1.4560449123382568
train: epoch 45, loss 0.5827286839485168, acc=0.7656111121177673, loss=0.5827286839485168
test: epoch 45, loss 1.2659783363342285, acc=0.5583333373069763, loss=1.2659783363342285
train: epoch 46, loss 0.5792154669761658, acc=0.7638333439826965, loss=0.5792154669761658
test: epoch 46, loss 1.103996753692627, acc=0.5527777671813965, loss=1.103996753692627
train: epoch 47, loss 0.5456817150115967, acc=0.7812777757644653, loss=0.5456817150115967
test: epoch 47, loss 1.254812479019165, acc=0.5333333611488342, loss=1.254812479019165
train: epoch 48, loss 0.5707221031188965, acc=0.7672777771949768, loss=0.5707221031188965
test: epoch 48, loss 1.1926288604736328, acc=0.5916666388511658, loss=1.1926288604736328
train: epoch 49, loss 0.549628734588623, acc=0.7754999995231628, loss=0.549628734588623
test: epoch 49, loss 1.3884536027908325, acc=0.4555555582046509, loss=1.3884536027908325
train: epoch 50, loss 0.5282495021820068, acc=0.7883889079093933, loss=0.5282495021820068
test: epoch 50, loss 1.4773858785629272, acc=0.4055555462837219, loss=1.4773858785629272
train: epoch 51, loss 0.5511479377746582, acc=0.7743333578109741, loss=0.5511479377746582
test: epoch 51, loss 1.444344401359558, acc=0.4444444477558136, loss=1.444344401359558
train: epoch 52, loss 0.5289278030395508, acc=0.7873888611793518, loss=0.5289278030395508
test: epoch 52, loss 1.417091965675354, acc=0.49166667461395264, loss=1.417091965675354
train: epoch 53, loss 0.5218794345855713, acc=0.7867777943611145, loss=0.5218794345855713
test: epoch 53, loss 1.151602864265442, acc=0.5527777671813965, loss=1.151602864265442
train: epoch 54, loss 0.5004612803459167, acc=0.7912777662277222, loss=0.5004612803459167
test: epoch 54, loss 1.2939362525939941, acc=0.5027777552604675, loss=1.2939362525939941
train: epoch 55, loss 0.516648530960083, acc=0.7873333096504211, loss=0.516648530960083
test: epoch 55, loss 1.4702026844024658, acc=0.48055556416511536, loss=1.4702026844024658
train: epoch 56, loss 0.5016738176345825, acc=0.7926111221313477, loss=0.5016738176345825
test: epoch 56, loss 1.1274091005325317, acc=0.5833333134651184, loss=1.1274091005325317
train: epoch 57, loss 0.5017043948173523, acc=0.7947777509689331, loss=0.5017043948173523
test: epoch 57, loss 1.4164037704467773, acc=0.48055556416511536, loss=1.4164037704467773
train: epoch 58, loss 0.49801838397979736, acc=0.793666660785675, loss=0.49801838397979736
test: epoch 58, loss 1.4612960815429688, acc=0.4555555582046509, loss=1.4612960815429688
train: epoch 59, loss 0.49030348658561707, acc=0.7987222075462341, loss=0.49030348658561707
test: epoch 59, loss 1.449533462524414, acc=0.5277777910232544, loss=1.449533462524414
train: epoch 60, loss 0.49659180641174316, acc=0.796500027179718, loss=0.49659180641174316
test: epoch 60, loss 1.2060039043426514, acc=0.5805555582046509, loss=1.2060039043426514
train: epoch 61, loss 0.4709400534629822, acc=0.804722249507904, loss=0.4709400534629822
test: epoch 61, loss 1.2649896144866943, acc=0.5527777671813965, loss=1.2649896144866943
train: epoch 62, loss 0.48787054419517517, acc=0.8007222414016724, loss=0.48787054419517517
test: epoch 62, loss 1.2399590015411377, acc=0.5527777671813965, loss=1.2399590015411377
train: epoch 63, loss 0.4798063635826111, acc=0.8055555820465088, loss=0.4798063635826111
test: epoch 63, loss 1.191911220550537, acc=0.5472221970558167, loss=1.191911220550537
train: epoch 64, loss 0.4859403073787689, acc=0.8009999990463257, loss=0.4859403073787689
test: epoch 64, loss 1.241752028465271, acc=0.5138888955116272, loss=1.241752028465271
train: epoch 65, loss 0.4611305892467499, acc=0.8113889098167419, loss=0.4611305892467499
test: epoch 65, loss 1.1863104104995728, acc=0.574999988079071, loss=1.1863104104995728
train: epoch 66, loss 0.46697691082954407, acc=0.8117777705192566, loss=0.46697691082954407
test: epoch 66, loss 1.2987920045852661, acc=0.5222222208976746, loss=1.2987920045852661
train: epoch 67, loss 0.4694739282131195, acc=0.805055558681488, loss=0.4694739282131195
test: epoch 67, loss 1.3690661191940308, acc=0.5388888716697693, loss=1.3690661191940308
train: epoch 68, loss 0.45776304602622986, acc=0.8130000233650208, loss=0.45776304602622986
test: epoch 68, loss 1.2812254428863525, acc=0.5, loss=1.2812254428863525
train: epoch 69, loss 0.45960724353790283, acc=0.8107777833938599, loss=0.45960724353790283
test: epoch 69, loss 1.251191258430481, acc=0.5222222208976746, loss=1.251191258430481
train: epoch 70, loss 0.4672527611255646, acc=0.8097777962684631, loss=0.4672527611255646
test: epoch 70, loss 1.232910394668579, acc=0.5111111402511597, loss=1.232910394668579
train: epoch 71, loss 0.45326828956604004, acc=0.8081111311912537, loss=0.45326828956604004
test: epoch 71, loss 1.2619764804840088, acc=0.5861111283302307, loss=1.2619764804840088
train: epoch 72, loss 0.4535200595855713, acc=0.8125, loss=0.4535200595855713
test: epoch 72, loss 1.1458971500396729, acc=0.550000011920929, loss=1.1458971500396729
train: epoch 73, loss 0.4592694938182831, acc=0.8121111392974854, loss=0.4592694938182831
test: epoch 73, loss 1.445021629333496, acc=0.5027777552604675, loss=1.445021629333496
train: epoch 74, loss 0.43333351612091064, acc=0.8208333253860474, loss=0.43333351612091064
test: epoch 74, loss 1.7028107643127441, acc=0.5611110925674438, loss=1.7028107643127441
train: epoch 75, loss 0.47194936871528625, acc=0.8068888783454895, loss=0.47194936871528625
test: epoch 75, loss 0.9975446462631226, acc=0.6694444417953491, loss=0.9975446462631226
train: epoch 76, loss 0.47212332487106323, acc=0.7990000247955322, loss=0.47212332487106323
test: epoch 76, loss 1.244637370109558, acc=0.5694444179534912, loss=1.244637370109558
train: epoch 77, loss 0.43612754344940186, acc=0.8232777714729309, loss=0.43612754344940186
test: epoch 77, loss 1.3227890729904175, acc=0.5, loss=1.3227890729904175
train: epoch 78, loss 0.43207213282585144, acc=0.823888897895813, loss=0.43207213282585144
test: epoch 78, loss 1.4208728075027466, acc=0.38333332538604736, loss=1.4208728075027466
train: epoch 79, loss 0.4499097466468811, acc=0.8177222013473511, loss=0.4499097466468811
test: epoch 79, loss 1.1467912197113037, acc=0.5527777671813965, loss=1.1467912197113037
train: epoch 80, loss 0.44124144315719604, acc=0.8189444541931152, loss=0.44124144315719604
test: epoch 80, loss 1.1500639915466309, acc=0.5555555820465088, loss=1.1500639915466309
train: epoch 81, loss 0.42055249214172363, acc=0.8266666531562805, loss=0.42055249214172363
test: epoch 81, loss 1.0953376293182373, acc=0.6333333253860474, loss=1.0953376293182373
train: epoch 82, loss 0.46117764711380005, acc=0.8119999766349792, loss=0.46117764711380005
test: epoch 82, loss 1.3685003519058228, acc=0.4749999940395355, loss=1.3685003519058228
train: epoch 83, loss 0.423580139875412, acc=0.8286111354827881, loss=0.423580139875412
test: epoch 83, loss 1.4736806154251099, acc=0.5611110925674438, loss=1.4736806154251099
train: epoch 84, loss 0.407067209482193, acc=0.8331111073493958, loss=0.407067209482193
test: epoch 84, loss 1.5547407865524292, acc=0.46388888359069824, loss=1.5547407865524292
train: epoch 85, loss 0.4328034818172455, acc=0.8215000033378601, loss=0.4328034818172455
test: epoch 85, loss 1.3546624183654785, acc=0.49444442987442017, loss=1.3546624183654785
train: epoch 86, loss 0.4310629963874817, acc=0.8241666555404663, loss=0.4310629963874817
test: epoch 86, loss 1.3867322206497192, acc=0.5416666865348816, loss=1.3867322206497192
train: epoch 87, loss 0.42739444971084595, acc=0.8299444317817688, loss=0.42739444971084595
test: epoch 87, loss 1.2220900058746338, acc=0.625, loss=1.2220900058746338
train: epoch 88, loss 0.4628816843032837, acc=0.8140555620193481, loss=0.4628816843032837
test: epoch 88, loss 1.1617629528045654, acc=0.6166666746139526, loss=1.1617629528045654
train: epoch 89, loss 0.4001624286174774, acc=0.8383888602256775, loss=0.4001624286174774
test: epoch 89, loss 1.326943278312683, acc=0.5972222089767456, loss=1.326943278312683
train: epoch 90, loss 0.422765851020813, acc=0.8261111378669739, loss=0.422765851020813
test: epoch 90, loss 1.1983489990234375, acc=0.5361111164093018, loss=1.1983489990234375
train: epoch 91, loss 0.41749849915504456, acc=0.8286111354827881, loss=0.41749849915504456
test: epoch 91, loss 1.3559439182281494, acc=0.5388888716697693, loss=1.3559439182281494
train: epoch 92, loss 0.41435256600379944, acc=0.8262222409248352, loss=0.41435256600379944
test: epoch 92, loss 1.1947661638259888, acc=0.574999988079071, loss=1.1947661638259888
train: epoch 93, loss 0.4068819284439087, acc=0.8358333110809326, loss=0.4068819284439087
test: epoch 93, loss 1.254580020904541, acc=0.5944444537162781, loss=1.254580020904541
train: epoch 94, loss 0.4137926697731018, acc=0.8308888673782349, loss=0.4137926697731018
test: epoch 94, loss 1.30754554271698, acc=0.5694444179534912, loss=1.30754554271698
train: epoch 95, loss 0.4223437011241913, acc=0.8297222256660461, loss=0.4223437011241913
test: epoch 95, loss 1.2673231363296509, acc=0.6138888597488403, loss=1.2673231363296509
train: epoch 96, loss 0.4158441424369812, acc=0.8305555582046509, loss=0.4158441424369812
test: epoch 96, loss 1.155625820159912, acc=0.5444444417953491, loss=1.155625820159912
train: epoch 97, loss 0.3830947279930115, acc=0.8434444665908813, loss=0.3830947279930115
test: epoch 97, loss 1.0983213186264038, acc=0.605555534362793, loss=1.0983213186264038
train: epoch 98, loss 0.41685009002685547, acc=0.8336111307144165, loss=0.41685009002685547
test: epoch 98, loss 1.073871374130249, acc=0.5777778029441833, loss=1.073871374130249
train: epoch 99, loss 0.4079626500606537, acc=0.8367778062820435, loss=0.4079626500606537
test: epoch 99, loss 1.1430907249450684, acc=0.5833333134651184, loss=1.1430907249450684
train: epoch 100, loss 0.4131929874420166, acc=0.8313888907432556, loss=0.4131929874420166
test: epoch 100, loss 1.2908010482788086, acc=0.5361111164093018, loss=1.2908010482788086
train: epoch 101, loss 0.3899676203727722, acc=0.843500018119812, loss=0.3899676203727722
test: epoch 101, loss 1.27545166015625, acc=0.5083333253860474, loss=1.27545166015625
train: epoch 102, loss 0.4080786108970642, acc=0.8358333110809326, loss=0.4080786108970642
test: epoch 102, loss 1.2029905319213867, acc=0.5833333134651184, loss=1.2029905319213867
train: epoch 103, loss 0.3978860378265381, acc=0.8381666541099548, loss=0.3978860378265381
test: epoch 103, loss 1.2001084089279175, acc=0.5777778029441833, loss=1.2001084089279175
train: epoch 104, loss 0.4309753179550171, acc=0.8258333206176758, loss=0.4309753179550171
test: epoch 104, loss 1.520879864692688, acc=0.4749999940395355, loss=1.520879864692688
train: epoch 105, loss 0.41588857769966125, acc=0.8337777853012085, loss=0.41588857769966125
test: epoch 105, loss 1.3029972314834595, acc=0.519444465637207, loss=1.3029972314834595
train: epoch 106, loss 0.38327839970588684, acc=0.8451666831970215, loss=0.38327839970588684
test: epoch 106, loss 1.2742751836776733, acc=0.5388888716697693, loss=1.2742751836776733
train: epoch 107, loss 0.37916135787963867, acc=0.848111093044281, loss=0.37916135787963867
test: epoch 107, loss 1.3339065313339233, acc=0.5861111283302307, loss=1.3339065313339233
train: epoch 108, loss 0.4161109924316406, acc=0.832111120223999, loss=0.4161109924316406
test: epoch 108, loss 1.093176245689392, acc=0.6416666507720947, loss=1.093176245689392
train: epoch 109, loss 0.3958031237125397, acc=0.839888870716095, loss=0.3958031237125397
test: epoch 109, loss 1.3940720558166504, acc=0.4861111044883728, loss=1.3940720558166504
train: epoch 110, loss 0.37464627623558044, acc=0.8478333353996277, loss=0.37464627623558044
test: epoch 110, loss 1.24004065990448, acc=0.550000011920929, loss=1.24004065990448
train: epoch 111, loss 0.3821831941604614, acc=0.8440555334091187, loss=0.3821831941604614
test: epoch 111, loss 1.5114812850952148, acc=0.5666666626930237, loss=1.5114812850952148
train: epoch 112, loss 0.40828534960746765, acc=0.8366110920906067, loss=0.40828534960746765
test: epoch 112, loss 1.5709513425827026, acc=0.49444442987442017, loss=1.5709513425827026
train: epoch 113, loss 0.3623836040496826, acc=0.855222225189209, loss=0.3623836040496826
test: epoch 113, loss 1.2425826787948608, acc=0.5861111283302307, loss=1.2425826787948608
train: epoch 114, loss 0.40751221776008606, acc=0.8357222080230713, loss=0.40751221776008606
test: epoch 114, loss 1.3787717819213867, acc=0.5472221970558167, loss=1.3787717819213867
train: epoch 115, loss 0.38527652621269226, acc=0.8435555696487427, loss=0.38527652621269226
test: epoch 115, loss 1.257585883140564, acc=0.5333333611488342, loss=1.257585883140564
train: epoch 116, loss 0.40677472949028015, acc=0.8373888731002808, loss=0.40677472949028015
test: epoch 116, loss 1.2471628189086914, acc=0.5916666388511658, loss=1.2471628189086914
train: epoch 117, loss 0.3734298646450043, acc=0.8488888740539551, loss=0.3734298646450043
test: epoch 117, loss 1.233899474143982, acc=0.5888888835906982, loss=1.233899474143982
train: epoch 118, loss 0.41473907232284546, acc=0.8360555768013, loss=0.41473907232284546
test: epoch 118, loss 1.4640309810638428, acc=0.5333333611488342, loss=1.4640309810638428
train: epoch 119, loss 0.37485048174858093, acc=0.8471666574478149, loss=0.37485048174858093
test: epoch 119, loss 1.3634321689605713, acc=0.5472221970558167, loss=1.3634321689605713
train: epoch 120, loss 0.3753477931022644, acc=0.8460000157356262, loss=0.3753477931022644
test: epoch 120, loss 1.3759723901748657, acc=0.5555555820465088, loss=1.3759723901748657
train: epoch 121, loss 0.39379027485847473, acc=0.8427777886390686, loss=0.39379027485847473
test: epoch 121, loss 1.3513985872268677, acc=0.5638889074325562, loss=1.3513985872268677
train: epoch 122, loss 0.3715874254703522, acc=0.8485555648803711, loss=0.3715874254703522
test: epoch 122, loss 1.3489471673965454, acc=0.5638889074325562, loss=1.3489471673965454
train: epoch 123, loss 0.37982526421546936, acc=0.8461111187934875, loss=0.37982526421546936
test: epoch 123, loss 1.0593222379684448, acc=0.5805555582046509, loss=1.0593222379684448
train: epoch 124, loss 0.3884229362010956, acc=0.8428333401679993, loss=0.3884229362010956
test: epoch 124, loss 1.3615589141845703, acc=0.5833333134651184, loss=1.3615589141845703
train: epoch 125, loss 0.4091795086860657, acc=0.8371666669845581, loss=0.4091795086860657
test: epoch 125, loss 1.1243308782577515, acc=0.5388888716697693, loss=1.1243308782577515
train: epoch 126, loss 0.3766270875930786, acc=0.8452777862548828, loss=0.3766270875930786
test: epoch 126, loss 1.2241325378417969, acc=0.6138888597488403, loss=1.2241325378417969
train: epoch 127, loss 0.38128113746643066, acc=0.8461111187934875, loss=0.38128113746643066
test: epoch 127, loss 1.3746384382247925, acc=0.5333333611488342, loss=1.3746384382247925
train: epoch 128, loss 0.39324435591697693, acc=0.8443889021873474, loss=0.39324435591697693
test: epoch 128, loss 1.1390613317489624, acc=0.5861111283302307, loss=1.1390613317489624
train: epoch 129, loss 0.3648221790790558, acc=0.8506666421890259, loss=0.3648221790790558
test: epoch 129, loss 1.4474784135818481, acc=0.5805555582046509, loss=1.4474784135818481
train: epoch 130, loss 0.3945057988166809, acc=0.8408889174461365, loss=0.3945057988166809
test: epoch 130, loss 1.1697721481323242, acc=0.6277777552604675, loss=1.1697721481323242
train: epoch 131, loss 0.38238489627838135, acc=0.8447777628898621, loss=0.38238489627838135
test: epoch 131, loss 1.2784464359283447, acc=0.5888888835906982, loss=1.2784464359283447
train: epoch 132, loss 0.3940385580062866, acc=0.8392221927642822, loss=0.3940385580062866
test: epoch 132, loss 1.200923204421997, acc=0.6000000238418579, loss=1.200923204421997
train: epoch 133, loss 0.3711029887199402, acc=0.8489999771118164, loss=0.3711029887199402
test: epoch 133, loss 1.4037961959838867, acc=0.5805555582046509, loss=1.4037961959838867
train: epoch 134, loss 0.3657276928424835, acc=0.852222204208374, loss=0.3657276928424835
test: epoch 134, loss 1.372528076171875, acc=0.5583333373069763, loss=1.372528076171875
train: epoch 135, loss 0.39693406224250793, acc=0.8393333554267883, loss=0.39693406224250793
test: epoch 135, loss 1.157712459564209, acc=0.5888888835906982, loss=1.157712459564209
train: epoch 136, loss 0.40044862031936646, acc=0.8363333344459534, loss=0.40044862031936646
test: epoch 136, loss 1.4269250631332397, acc=0.5777778029441833, loss=1.4269250631332397
train: epoch 137, loss 0.415605753660202, acc=0.8339999914169312, loss=0.415605753660202
test: epoch 137, loss 1.1593480110168457, acc=0.6111111044883728, loss=1.1593480110168457
train: epoch 138, loss 0.39431455731391907, acc=0.839555561542511, loss=0.39431455731391907
test: epoch 138, loss 1.4159154891967773, acc=0.5722222328186035, loss=1.4159154891967773
train: epoch 139, loss 0.38557198643684387, acc=0.8440555334091187, loss=0.38557198643684387
test: epoch 139, loss 1.3781872987747192, acc=0.5583333373069763, loss=1.3781872987747192
train: epoch 140, loss 0.37799394130706787, acc=0.8445555567741394, loss=0.37799394130706787
test: epoch 140, loss 1.3725091218948364, acc=0.5916666388511658, loss=1.3725091218948364
train: epoch 141, loss 0.4077199399471283, acc=0.8376666903495789, loss=0.4077199399471283
test: epoch 141, loss 1.2625527381896973, acc=0.5972222089767456, loss=1.2625527381896973
train: epoch 142, loss 0.3714032769203186, acc=0.8485555648803711, loss=0.3714032769203186
test: epoch 142, loss 1.5085029602050781, acc=0.5611110925674438, loss=1.5085029602050781
train: epoch 143, loss 0.36754047870635986, acc=0.8503333330154419, loss=0.36754047870635986
test: epoch 143, loss 1.284706473350525, acc=0.5472221970558167, loss=1.284706473350525
train: epoch 144, loss 0.38102269172668457, acc=0.8450000286102295, loss=0.38102269172668457
test: epoch 144, loss 1.2541351318359375, acc=0.5888888835906982, loss=1.2541351318359375
train: epoch 145, loss 0.38706138730049133, acc=0.8411111235618591, loss=0.38706138730049133
test: epoch 145, loss 1.255548119544983, acc=0.5888888835906982, loss=1.255548119544983
train: epoch 146, loss 0.3612912595272064, acc=0.8538333177566528, loss=0.3612912595272064
test: epoch 146, loss 1.3041245937347412, acc=0.6000000238418579, loss=1.3041245937347412
train: epoch 147, loss 0.36145609617233276, acc=0.8514999747276306, loss=0.36145609617233276
test: epoch 147, loss 1.1897523403167725, acc=0.5916666388511658, loss=1.1897523403167725
train: epoch 148, loss 0.3995138704776764, acc=0.8374999761581421, loss=0.3995138704776764
test: epoch 148, loss 1.4124424457550049, acc=0.5611110925674438, loss=1.4124424457550049
train: epoch 149, loss 0.38062044978141785, acc=0.8467777967453003, loss=0.38062044978141785
test: epoch 149, loss 1.1942138671875, acc=0.6333333253860474, loss=1.1942138671875
train: epoch 150, loss 0.3855603337287903, acc=0.8445000052452087, loss=0.3855603337287903
test: epoch 150, loss 1.2559120655059814, acc=0.550000011920929, loss=1.2559120655059814
