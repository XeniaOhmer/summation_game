# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=1", "--temp_decay=1", "--one_hot=1", "--n_layers=1"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=1435088539, receiver_embed_dim=64, save_run=0, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1435088539, receiver_embed_dim=64, save_run=False, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.5876989364624023, acc=0.04311111196875572, loss=3.5876989364624023
test: epoch 1, loss 3.5972487926483154, acc=0.03333333507180214, loss=3.5972487926483154
train: epoch 2, loss 3.501012086868286, acc=0.05000000074505806, loss=3.501012086868286
test: epoch 2, loss 3.411325454711914, acc=0.04722222313284874, loss=3.411325454711914
train: epoch 3, loss 3.4777631759643555, acc=0.05194444581866264, loss=3.4777631759643555
test: epoch 3, loss 3.1790196895599365, acc=0.05833333358168602, loss=3.1790196895599365
train: epoch 4, loss 3.4193742275238037, acc=0.05255555734038353, loss=3.4193742275238037
test: epoch 4, loss 3.0064046382904053, acc=0.08055555820465088, loss=3.0064046382904053
train: epoch 5, loss 3.2631759643554688, acc=0.0642777755856514, loss=3.2631759643554688
test: epoch 5, loss 3.651947498321533, acc=0.05000000074505806, loss=3.651947498321533
train: epoch 6, loss 3.0580592155456543, acc=0.09055555611848831, loss=3.0580592155456543
test: epoch 6, loss 3.987138032913208, acc=0.04444444552063942, loss=3.987138032913208
train: epoch 7, loss 2.9182260036468506, acc=0.10288888961076736, loss=2.9182260036468506
test: epoch 7, loss 3.9945764541625977, acc=0.05833333358168602, loss=3.9945764541625977
train: epoch 8, loss 2.8108510971069336, acc=0.11044444143772125, loss=2.8108510971069336
test: epoch 8, loss 4.066462993621826, acc=0.05833333358168602, loss=4.066462993621826
train: epoch 9, loss 2.7490155696868896, acc=0.12033333629369736, loss=2.7490155696868896
test: epoch 9, loss 4.01706600189209, acc=0.0555555559694767, loss=4.01706600189209
train: epoch 10, loss 2.6994314193725586, acc=0.1312222182750702, loss=2.6994314193725586
test: epoch 10, loss 3.9180986881256104, acc=0.0555555559694767, loss=3.9180986881256104
train: epoch 11, loss 2.6555278301239014, acc=0.13566666841506958, loss=2.6555278301239014
test: epoch 11, loss 3.8628458976745605, acc=0.06388889253139496, loss=3.8628458976745605
train: epoch 12, loss 2.617285966873169, acc=0.1415555626153946, loss=2.617285966873169
test: epoch 12, loss 3.839637041091919, acc=0.05277777835726738, loss=3.839637041091919
train: epoch 13, loss 2.578300714492798, acc=0.14861111342906952, loss=2.578300714492798
test: epoch 13, loss 3.684650182723999, acc=0.05833333358168602, loss=3.684650182723999
train: epoch 14, loss 2.549978733062744, acc=0.15577778220176697, loss=2.549978733062744
test: epoch 14, loss 3.734010934829712, acc=0.05833333358168602, loss=3.734010934829712
train: epoch 15, loss 2.519463300704956, acc=0.16483333706855774, loss=2.519463300704956
test: epoch 15, loss 3.8753533363342285, acc=0.05833333358168602, loss=3.8753533363342285
train: epoch 16, loss 2.501070499420166, acc=0.1648888885974884, loss=2.501070499420166
test: epoch 16, loss 3.6618094444274902, acc=0.07777778059244156, loss=3.6618094444274902
train: epoch 17, loss 2.4742915630340576, acc=0.1653333306312561, loss=2.4742915630340576
test: epoch 17, loss 3.763270378112793, acc=0.06666667014360428, loss=3.763270378112793
train: epoch 18, loss 2.4549026489257812, acc=0.17216666042804718, loss=2.4549026489257812
test: epoch 18, loss 3.741597890853882, acc=0.0694444477558136, loss=3.741597890853882
train: epoch 19, loss 2.4285247325897217, acc=0.1765555590391159, loss=2.4285247325897217
test: epoch 19, loss 3.789135217666626, acc=0.07777778059244156, loss=3.789135217666626
train: epoch 20, loss 2.414646625518799, acc=0.17961111664772034, loss=2.414646625518799
test: epoch 20, loss 3.7404091358184814, acc=0.07222222536802292, loss=3.7404091358184814
train: epoch 21, loss 2.3977534770965576, acc=0.18877777457237244, loss=2.3977534770965576
test: epoch 21, loss 3.6915273666381836, acc=0.07222222536802292, loss=3.6915273666381836
train: epoch 22, loss 2.3871407508850098, acc=0.18833333253860474, loss=2.3871407508850098
test: epoch 22, loss 3.7478842735290527, acc=0.08055555820465088, loss=3.7478842735290527
train: epoch 23, loss 2.3610918521881104, acc=0.19294443726539612, loss=2.3610918521881104
test: epoch 23, loss 3.757282018661499, acc=0.07500000298023224, loss=3.757282018661499
train: epoch 24, loss 2.340881824493408, acc=0.19227777421474457, loss=2.340881824493408
test: epoch 24, loss 3.7375166416168213, acc=0.08055555820465088, loss=3.7375166416168213
train: epoch 25, loss 2.3299858570098877, acc=0.19838888943195343, loss=2.3299858570098877
test: epoch 25, loss 3.8192224502563477, acc=0.0833333358168602, loss=3.8192224502563477
train: epoch 26, loss 2.31850004196167, acc=0.20294444262981415, loss=2.31850004196167
test: epoch 26, loss 3.7852330207824707, acc=0.0833333358168602, loss=3.7852330207824707
train: epoch 27, loss 2.296067714691162, acc=0.2043333351612091, loss=2.296067714691162
test: epoch 27, loss 3.8283791542053223, acc=0.08055555820465088, loss=3.8283791542053223
train: epoch 28, loss 2.2804527282714844, acc=0.20694445073604584, loss=2.2804527282714844
test: epoch 28, loss 3.783341884613037, acc=0.08611111342906952, loss=3.783341884613037
train: epoch 29, loss 2.260413885116577, acc=0.21061110496520996, loss=2.260413885116577
test: epoch 29, loss 3.910245895385742, acc=0.07777778059244156, loss=3.910245895385742
train: epoch 30, loss 2.247551441192627, acc=0.21505555510520935, loss=2.247551441192627
test: epoch 30, loss 3.906546115875244, acc=0.08055555820465088, loss=3.906546115875244
train: epoch 31, loss 2.242358684539795, acc=0.2163333296775818, loss=2.242358684539795
test: epoch 31, loss 3.818143129348755, acc=0.0833333358168602, loss=3.818143129348755
train: epoch 32, loss 2.2269508838653564, acc=0.2220555543899536, loss=2.2269508838653564
test: epoch 32, loss 3.7409682273864746, acc=0.08611111342906952, loss=3.7409682273864746
train: epoch 33, loss 2.203270435333252, acc=0.22333332896232605, loss=2.203270435333252
test: epoch 33, loss 3.6299526691436768, acc=0.09444444626569748, loss=3.6299526691436768
train: epoch 34, loss 2.1879756450653076, acc=0.2316666692495346, loss=2.1879756450653076
test: epoch 34, loss 3.518923759460449, acc=0.0972222238779068, loss=3.518923759460449
train: epoch 35, loss 2.177481174468994, acc=0.23011110723018646, loss=2.177481174468994
test: epoch 35, loss 3.3941891193389893, acc=0.10000000149011612, loss=3.3941891193389893
train: epoch 36, loss 2.1432533264160156, acc=0.24111111462116241, loss=2.1432533264160156
test: epoch 36, loss 3.1979668140411377, acc=0.0972222238779068, loss=3.1979668140411377
train: epoch 37, loss 2.136049270629883, acc=0.24738888442516327, loss=2.136049270629883
test: epoch 37, loss 3.1055378913879395, acc=0.11388888955116272, loss=3.1055378913879395
train: epoch 38, loss 2.1073741912841797, acc=0.2468888908624649, loss=2.1073741912841797
test: epoch 38, loss 3.029738664627075, acc=0.10555555671453476, loss=3.029738664627075
train: epoch 39, loss 2.0912187099456787, acc=0.253555566072464, loss=2.0912187099456787
test: epoch 39, loss 3.019251823425293, acc=0.10833333432674408, loss=3.019251823425293
train: epoch 40, loss 2.0672855377197266, acc=0.2634444534778595, loss=2.0672855377197266
test: epoch 40, loss 3.0014290809631348, acc=0.11666666716337204, loss=3.0014290809631348
train: epoch 41, loss 2.0524227619171143, acc=0.2666666805744171, loss=2.0524227619171143
test: epoch 41, loss 2.9038925170898438, acc=0.11666666716337204, loss=2.9038925170898438
train: epoch 42, loss 2.029334783554077, acc=0.26866665482521057, loss=2.029334783554077
test: epoch 42, loss 2.7929787635803223, acc=0.13333334028720856, loss=2.7929787635803223
train: epoch 43, loss 2.020533561706543, acc=0.2701111137866974, loss=2.020533561706543
test: epoch 43, loss 2.7167739868164062, acc=0.125, loss=2.7167739868164062
train: epoch 44, loss 1.9976340532302856, acc=0.28272223472595215, loss=1.9976340532302856
test: epoch 44, loss 2.6247189044952393, acc=0.12777778506278992, loss=2.6247189044952393
train: epoch 45, loss 1.9686543941497803, acc=0.28861111402511597, loss=1.9686543941497803
test: epoch 45, loss 2.613229513168335, acc=0.13611111044883728, loss=2.613229513168335
train: epoch 46, loss 1.9554214477539062, acc=0.30061110854148865, loss=1.9554214477539062
test: epoch 46, loss 2.5940096378326416, acc=0.12777778506278992, loss=2.5940096378326416
train: epoch 47, loss 1.9201101064682007, acc=0.30594444274902344, loss=1.9201101064682007
test: epoch 47, loss 2.5050864219665527, acc=0.13055555522441864, loss=2.5050864219665527
train: epoch 48, loss 1.8998631238937378, acc=0.31450000405311584, loss=1.8998631238937378
test: epoch 48, loss 2.4956376552581787, acc=0.13055555522441864, loss=2.4956376552581787
train: epoch 49, loss 1.8955806493759155, acc=0.3181111216545105, loss=1.8955806493759155
test: epoch 49, loss 2.443331480026245, acc=0.13611111044883728, loss=2.443331480026245
train: epoch 50, loss 1.867260217666626, acc=0.3259444534778595, loss=1.867260217666626
test: epoch 50, loss 2.449876546859741, acc=0.1527777761220932, loss=2.449876546859741
train: epoch 51, loss 1.8760509490966797, acc=0.3237777650356293, loss=1.8760509490966797
test: epoch 51, loss 2.409639596939087, acc=0.14722222089767456, loss=2.409639596939087
train: epoch 52, loss 1.8386467695236206, acc=0.3352222144603729, loss=1.8386467695236206
test: epoch 52, loss 2.3967525959014893, acc=0.16388888657093048, loss=2.3967525959014893
train: epoch 53, loss 1.802565097808838, acc=0.34005555510520935, loss=1.802565097808838
test: epoch 53, loss 2.3781561851501465, acc=0.14166666567325592, loss=2.3781561851501465
train: epoch 54, loss 1.8001245260238647, acc=0.3504444360733032, loss=1.8001245260238647
test: epoch 54, loss 2.346527576446533, acc=0.15000000596046448, loss=2.346527576446533
train: epoch 55, loss 1.779180884361267, acc=0.35155555605888367, loss=1.779180884361267
test: epoch 55, loss 2.3332626819610596, acc=0.16944444179534912, loss=2.3332626819610596
train: epoch 56, loss 1.7471933364868164, acc=0.3616666793823242, loss=1.7471933364868164
test: epoch 56, loss 2.3152453899383545, acc=0.16944444179534912, loss=2.3152453899383545
train: epoch 57, loss 1.7422536611557007, acc=0.3667222261428833, loss=1.7422536611557007
test: epoch 57, loss 2.3402750492095947, acc=0.15555556118488312, loss=2.3402750492095947
train: epoch 58, loss 1.7346715927124023, acc=0.36988890171051025, loss=1.7346715927124023
test: epoch 58, loss 2.328207015991211, acc=0.15000000596046448, loss=2.328207015991211
train: epoch 59, loss 1.7108746767044067, acc=0.37316668033599854, loss=1.7108746767044067
test: epoch 59, loss 2.3498318195343018, acc=0.1527777761220932, loss=2.3498318195343018
train: epoch 60, loss 1.6967848539352417, acc=0.3808888792991638, loss=1.6967848539352417
test: epoch 60, loss 2.3338489532470703, acc=0.15833333134651184, loss=2.3338489532470703
train: epoch 61, loss 1.689296841621399, acc=0.3808888792991638, loss=1.689296841621399
test: epoch 61, loss 2.280179500579834, acc=0.1527777761220932, loss=2.280179500579834
train: epoch 62, loss 1.6573811769485474, acc=0.39322221279144287, loss=1.6573811769485474
test: epoch 62, loss 2.292513847351074, acc=0.17777778208255768, loss=2.292513847351074
train: epoch 63, loss 1.6596122980117798, acc=0.39427778124809265, loss=1.6596122980117798
test: epoch 63, loss 2.291781425476074, acc=0.1666666716337204, loss=2.291781425476074
train: epoch 64, loss 1.6346163749694824, acc=0.402444452047348, loss=1.6346163749694824
test: epoch 64, loss 2.2397544384002686, acc=0.18888889253139496, loss=2.2397544384002686
train: epoch 65, loss 1.6364623308181763, acc=0.398333340883255, loss=1.6364623308181763
test: epoch 65, loss 2.257411479949951, acc=0.16944444179534912, loss=2.257411479949951
train: epoch 66, loss 1.602800726890564, acc=0.41322222352027893, loss=1.602800726890564
test: epoch 66, loss 2.2768983840942383, acc=0.17222222685813904, loss=2.2768983840942383
train: epoch 67, loss 1.6025892496109009, acc=0.4138333201408386, loss=1.6025892496109009
test: epoch 67, loss 2.234003782272339, acc=0.1805555522441864, loss=2.234003782272339
train: epoch 68, loss 1.586844563484192, acc=0.4187777638435364, loss=1.586844563484192
test: epoch 68, loss 2.2170634269714355, acc=0.19166666269302368, loss=2.2170634269714355
train: epoch 69, loss 1.5658128261566162, acc=0.421833336353302, loss=1.5658128261566162
test: epoch 69, loss 2.250469446182251, acc=0.18333333730697632, loss=2.250469446182251
train: epoch 70, loss 1.5518980026245117, acc=0.4334999918937683, loss=1.5518980026245117
test: epoch 70, loss 2.2169089317321777, acc=0.1944444477558136, loss=2.2169089317321777
train: epoch 71, loss 1.5342979431152344, acc=0.4347222149372101, loss=1.5342979431152344
test: epoch 71, loss 2.2278459072113037, acc=0.18888889253139496, loss=2.2278459072113037
train: epoch 72, loss 1.5180652141571045, acc=0.4482777714729309, loss=1.5180652141571045
test: epoch 72, loss 2.190786838531494, acc=0.18611110746860504, loss=2.190786838531494
train: epoch 73, loss 1.5139662027359009, acc=0.4454444348812103, loss=1.5139662027359009
test: epoch 73, loss 2.219555616378784, acc=0.18333333730697632, loss=2.219555616378784
train: epoch 74, loss 1.4989840984344482, acc=0.45261111855506897, loss=1.4989840984344482
test: epoch 74, loss 2.1902408599853516, acc=0.20277777314186096, loss=2.1902408599853516
train: epoch 75, loss 1.4898083209991455, acc=0.4569999873638153, loss=1.4898083209991455
test: epoch 75, loss 2.2009968757629395, acc=0.18611110746860504, loss=2.2009968757629395
train: epoch 76, loss 1.4791067838668823, acc=0.4667222201824188, loss=1.4791067838668823
test: epoch 76, loss 2.1641528606414795, acc=0.18611110746860504, loss=2.1641528606414795
train: epoch 77, loss 1.4559988975524902, acc=0.47111111879348755, loss=1.4559988975524902
test: epoch 77, loss 2.152261734008789, acc=0.1944444477558136, loss=2.152261734008789
train: epoch 78, loss 1.4460868835449219, acc=0.4751666784286499, loss=1.4460868835449219
test: epoch 78, loss 2.144552230834961, acc=0.21388888359069824, loss=2.144552230834961
train: epoch 79, loss 1.419018268585205, acc=0.4757777750492096, loss=1.419018268585205
test: epoch 79, loss 2.1496803760528564, acc=0.18888889253139496, loss=2.1496803760528564
train: epoch 80, loss 1.4356547594070435, acc=0.4799444377422333, loss=1.4356547594070435
test: epoch 80, loss 2.1189613342285156, acc=0.20277777314186096, loss=2.1189613342285156
train: epoch 81, loss 1.4147515296936035, acc=0.4852222204208374, loss=1.4147515296936035
test: epoch 81, loss 2.1526098251342773, acc=0.20555555820465088, loss=2.1526098251342773
train: epoch 82, loss 1.4138572216033936, acc=0.48249998688697815, loss=1.4138572216033936
test: epoch 82, loss 2.140246868133545, acc=0.20555555820465088, loss=2.140246868133545
train: epoch 83, loss 1.3947778940200806, acc=0.49566665291786194, loss=1.3947778940200806
test: epoch 83, loss 2.125009298324585, acc=0.2222222238779068, loss=2.125009298324585
train: epoch 84, loss 1.3747085332870483, acc=0.5007777810096741, loss=1.3747085332870483
test: epoch 84, loss 2.1387085914611816, acc=0.21111111342906952, loss=2.1387085914611816
train: epoch 85, loss 1.385937213897705, acc=0.4968888759613037, loss=1.385937213897705
test: epoch 85, loss 2.103199005126953, acc=0.21944443881511688, loss=2.103199005126953
train: epoch 86, loss 1.3576185703277588, acc=0.5056111216545105, loss=1.3576185703277588
test: epoch 86, loss 2.129382371902466, acc=0.21388888359069824, loss=2.129382371902466
train: epoch 87, loss 1.3645477294921875, acc=0.5071666836738586, loss=1.3645477294921875
test: epoch 87, loss 2.1167166233062744, acc=0.22499999403953552, loss=2.1167166233062744
train: epoch 88, loss 1.3457294702529907, acc=0.5137777924537659, loss=1.3457294702529907
test: epoch 88, loss 2.1076018810272217, acc=0.2083333283662796, loss=2.1076018810272217
train: epoch 89, loss 1.3310728073120117, acc=0.5162222385406494, loss=1.3310728073120117
test: epoch 89, loss 2.099135637283325, acc=0.21944443881511688, loss=2.099135637283325
train: epoch 90, loss 1.3187785148620605, acc=0.5241110920906067, loss=1.3187785148620605
test: epoch 90, loss 2.0706725120544434, acc=0.21666666865348816, loss=2.0706725120544434
train: epoch 91, loss 1.300148606300354, acc=0.5245000123977661, loss=1.300148606300354
test: epoch 91, loss 2.038231372833252, acc=0.2222222238779068, loss=2.038231372833252
train: epoch 92, loss 1.2952600717544556, acc=0.5287777781486511, loss=1.2952600717544556
test: epoch 92, loss 2.0420892238616943, acc=0.22499999403953552, loss=2.0420892238616943
train: epoch 93, loss 1.2912944555282593, acc=0.5397777557373047, loss=1.2912944555282593
test: epoch 93, loss 2.0128695964813232, acc=0.21111111342906952, loss=2.0128695964813232
train: epoch 94, loss 1.2802685499191284, acc=0.5394444465637207, loss=1.2802685499191284
test: epoch 94, loss 2.0233540534973145, acc=0.23333333432674408, loss=2.0233540534973145
train: epoch 95, loss 1.2918280363082886, acc=0.5388333201408386, loss=1.2918280363082886
test: epoch 95, loss 1.9562536478042603, acc=0.24166665971279144, loss=1.9562536478042603
train: epoch 96, loss 1.2805722951889038, acc=0.5483333468437195, loss=1.2805722951889038
test: epoch 96, loss 2.0104591846466064, acc=0.22777777910232544, loss=2.0104591846466064
train: epoch 97, loss 1.2383283376693726, acc=0.5544999837875366, loss=1.2383283376693726
test: epoch 97, loss 2.0247292518615723, acc=0.23333333432674408, loss=2.0247292518615723
train: epoch 98, loss 1.2442620992660522, acc=0.55522221326828, loss=1.2442620992660522
test: epoch 98, loss 2.0203888416290283, acc=0.24166665971279144, loss=2.0203888416290283
train: epoch 99, loss 1.244823694229126, acc=0.5558333396911621, loss=1.244823694229126
test: epoch 99, loss 1.9946448802947998, acc=0.23888888955116272, loss=1.9946448802947998
train: epoch 100, loss 1.2329161167144775, acc=0.5551666617393494, loss=1.2329161167144775
test: epoch 100, loss 1.9780558347702026, acc=0.2361111044883728, loss=1.9780558347702026
train: epoch 101, loss 1.2286931276321411, acc=0.5671111345291138, loss=1.2286931276321411
test: epoch 101, loss 1.96633780002594, acc=0.23888888955116272, loss=1.96633780002594
train: epoch 102, loss 1.2135530710220337, acc=0.5636110901832581, loss=1.2135530710220337
test: epoch 102, loss 1.9826182126998901, acc=0.24444444477558136, loss=1.9826182126998901
train: epoch 103, loss 1.2026904821395874, acc=0.5681666731834412, loss=1.2026904821395874
test: epoch 103, loss 1.9709680080413818, acc=0.25, loss=1.9709680080413818
train: epoch 104, loss 1.1768951416015625, acc=0.5807777643203735, loss=1.1768951416015625
test: epoch 104, loss 1.9738576412200928, acc=0.24722221493721008, loss=1.9738576412200928
train: epoch 105, loss 1.2000494003295898, acc=0.5746111273765564, loss=1.2000494003295898
test: epoch 105, loss 1.9502179622650146, acc=0.2527777850627899, loss=1.9502179622650146
train: epoch 106, loss 1.179084062576294, acc=0.5805000066757202, loss=1.179084062576294
test: epoch 106, loss 1.9387333393096924, acc=0.24444444477558136, loss=1.9387333393096924
train: epoch 107, loss 1.1682072877883911, acc=0.5839444398880005, loss=1.1682072877883911
test: epoch 107, loss 1.9524760246276855, acc=0.25555557012557983, loss=1.9524760246276855
train: epoch 108, loss 1.1653571128845215, acc=0.5937222242355347, loss=1.1653571128845215
test: epoch 108, loss 1.9379383325576782, acc=0.2527777850627899, loss=1.9379383325576782
train: epoch 109, loss 1.1372796297073364, acc=0.5913333296775818, loss=1.1372796297073364
test: epoch 109, loss 1.9205682277679443, acc=0.2527777850627899, loss=1.9205682277679443
train: epoch 110, loss 1.1315194368362427, acc=0.5973333120346069, loss=1.1315194368362427
test: epoch 110, loss 1.9438494443893433, acc=0.25, loss=1.9438494443893433
train: epoch 111, loss 1.1086106300354004, acc=0.6047222018241882, loss=1.1086106300354004
test: epoch 111, loss 1.9556020498275757, acc=0.2527777850627899, loss=1.9556020498275757
train: epoch 112, loss 1.1299418210983276, acc=0.6054999828338623, loss=1.1299418210983276
test: epoch 112, loss 1.9562650918960571, acc=0.25, loss=1.9562650918960571
train: epoch 113, loss 1.1086338758468628, acc=0.612666666507721, loss=1.1086338758468628
test: epoch 113, loss 1.9246163368225098, acc=0.2527777850627899, loss=1.9246163368225098
train: epoch 114, loss 1.0778311491012573, acc=0.6193888783454895, loss=1.0778311491012573
test: epoch 114, loss 1.9471940994262695, acc=0.25, loss=1.9471940994262695
train: epoch 115, loss 1.105587124824524, acc=0.6152222156524658, loss=1.105587124824524
test: epoch 115, loss 1.9663840532302856, acc=0.25555557012557983, loss=1.9663840532302856
train: epoch 116, loss 1.0814058780670166, acc=0.621055543422699, loss=1.0814058780670166
test: epoch 116, loss 1.9601787328720093, acc=0.2611111104488373, loss=1.9601787328720093
train: epoch 117, loss 1.0796337127685547, acc=0.6320000290870667, loss=1.0796337127685547
test: epoch 117, loss 1.9399453401565552, acc=0.26944443583488464, loss=1.9399453401565552
train: epoch 118, loss 1.0761630535125732, acc=0.6271666884422302, loss=1.0761630535125732
test: epoch 118, loss 1.9273484945297241, acc=0.25555557012557983, loss=1.9273484945297241
train: epoch 119, loss 1.060084581375122, acc=0.6298888921737671, loss=1.060084581375122
test: epoch 119, loss 1.9365057945251465, acc=0.24444444477558136, loss=1.9365057945251465
train: epoch 120, loss 1.052648663520813, acc=0.6383333206176758, loss=1.052648663520813
test: epoch 120, loss 1.9150148630142212, acc=0.2638888955116272, loss=1.9150148630142212
train: epoch 121, loss 1.0348013639450073, acc=0.6457777619361877, loss=1.0348013639450073
test: epoch 121, loss 1.9343842267990112, acc=0.25833332538604736, loss=1.9343842267990112
train: epoch 122, loss 1.0392069816589355, acc=0.6471666693687439, loss=1.0392069816589355
test: epoch 122, loss 1.9111238718032837, acc=0.2666666805744171, loss=1.9111238718032837
train: epoch 123, loss 1.0255203247070312, acc=0.6545555591583252, loss=1.0255203247070312
test: epoch 123, loss 1.9490395784378052, acc=0.25555557012557983, loss=1.9490395784378052
train: epoch 124, loss 1.0149171352386475, acc=0.6598333120346069, loss=1.0149171352386475
test: epoch 124, loss 1.9054063558578491, acc=0.25555557012557983, loss=1.9054063558578491
train: epoch 125, loss 0.9838534593582153, acc=0.6641111373901367, loss=0.9838534593582153
test: epoch 125, loss 1.924967885017395, acc=0.2666666805744171, loss=1.924967885017395
train: epoch 126, loss 1.0031424760818481, acc=0.660611093044281, loss=1.0031424760818481
test: epoch 126, loss 1.911774754524231, acc=0.25833332538604736, loss=1.911774754524231
train: epoch 127, loss 0.9876163601875305, acc=0.6674444675445557, loss=0.9876163601875305
test: epoch 127, loss 1.9004968404769897, acc=0.25833332538604736, loss=1.9004968404769897
train: epoch 128, loss 0.9979602694511414, acc=0.6679444313049316, loss=0.9979602694511414
test: epoch 128, loss 1.9106160402297974, acc=0.2777777910232544, loss=1.9106160402297974
train: epoch 129, loss 0.9718039631843567, acc=0.6743333339691162, loss=0.9718039631843567
test: epoch 129, loss 1.873101830482483, acc=0.2777777910232544, loss=1.873101830482483
train: epoch 130, loss 0.974897027015686, acc=0.672166645526886, loss=0.974897027015686
test: epoch 130, loss 1.8757857084274292, acc=0.2611111104488373, loss=1.8757857084274292
train: epoch 131, loss 0.969853401184082, acc=0.679277777671814, loss=0.969853401184082
test: epoch 131, loss 1.8876811265945435, acc=0.27222222089767456, loss=1.8876811265945435
train: epoch 132, loss 0.944141685962677, acc=0.6852222084999084, loss=0.944141685962677
test: epoch 132, loss 1.9165972471237183, acc=0.2777777910232544, loss=1.9165972471237183
train: epoch 133, loss 0.9375211596488953, acc=0.6930555701255798, loss=0.9375211596488953
test: epoch 133, loss 1.8891173601150513, acc=0.2750000059604645, loss=1.8891173601150513
train: epoch 134, loss 0.9429662823677063, acc=0.6875, loss=0.9429662823677063
test: epoch 134, loss 1.8973243236541748, acc=0.2750000059604645, loss=1.8973243236541748
train: epoch 135, loss 0.9246737360954285, acc=0.6953333616256714, loss=0.9246737360954285
test: epoch 135, loss 1.8861805200576782, acc=0.26944443583488464, loss=1.8861805200576782
train: epoch 136, loss 0.9339359998703003, acc=0.6926666498184204, loss=0.9339359998703003
test: epoch 136, loss 1.882441759109497, acc=0.2888889014720917, loss=1.882441759109497
train: epoch 137, loss 0.9123888611793518, acc=0.7007222175598145, loss=0.9123888611793518
test: epoch 137, loss 1.8651055097579956, acc=0.26944443583488464, loss=1.8651055097579956
train: epoch 138, loss 0.9069803357124329, acc=0.7013888955116272, loss=0.9069803357124329
test: epoch 138, loss 1.8382009267807007, acc=0.2888889014720917, loss=1.8382009267807007
train: epoch 139, loss 0.9017337560653687, acc=0.7026110887527466, loss=0.9017337560653687
test: epoch 139, loss 1.7899733781814575, acc=0.28333333134651184, loss=1.7899733781814575
train: epoch 140, loss 0.9003428816795349, acc=0.7067777514457703, loss=0.9003428816795349
test: epoch 140, loss 1.8245128393173218, acc=0.2916666567325592, loss=1.8245128393173218
train: epoch 141, loss 0.8993079662322998, acc=0.7151111364364624, loss=0.8993079662322998
test: epoch 141, loss 1.814424991607666, acc=0.2916666567325592, loss=1.814424991607666
train: epoch 142, loss 0.8762961030006409, acc=0.7133333086967468, loss=0.8762961030006409
test: epoch 142, loss 1.7812104225158691, acc=0.30000001192092896, loss=1.7812104225158691
train: epoch 143, loss 0.8586271405220032, acc=0.7231666445732117, loss=0.8586271405220032
test: epoch 143, loss 1.806862473487854, acc=0.2944444417953491, loss=1.806862473487854
train: epoch 144, loss 0.8530078530311584, acc=0.7192777991294861, loss=0.8530078530311584
test: epoch 144, loss 1.8443230390548706, acc=0.2916666567325592, loss=1.8443230390548706
train: epoch 145, loss 0.8631271123886108, acc=0.7203888893127441, loss=0.8631271123886108
test: epoch 145, loss 1.791290283203125, acc=0.3027777671813965, loss=1.791290283203125
train: epoch 146, loss 0.828394889831543, acc=0.7269444465637207, loss=0.828394889831543
test: epoch 146, loss 1.7879809141159058, acc=0.29722222685813904, loss=1.7879809141159058
train: epoch 147, loss 0.8225682377815247, acc=0.731166660785675, loss=0.8225682377815247
test: epoch 147, loss 1.7818031311035156, acc=0.29722222685813904, loss=1.7818031311035156
train: epoch 148, loss 0.8305959701538086, acc=0.7325000166893005, loss=0.8305959701538086
test: epoch 148, loss 1.7908082008361816, acc=0.3055555522441864, loss=1.7908082008361816
train: epoch 149, loss 0.8283746242523193, acc=0.7323889136314392, loss=0.8283746242523193
test: epoch 149, loss 1.747895359992981, acc=0.30000001192092896, loss=1.747895359992981
train: epoch 150, loss 0.8309996128082275, acc=0.7367222309112549, loss=0.8309996128082275
test: epoch 150, loss 1.7412998676300049, acc=0.3055555522441864, loss=1.7412998676300049
