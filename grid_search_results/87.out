# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=1.5", "--temp_decay=0.99", "--one_hot=false", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1487797322, receiver_embed_dim=64, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.3210277557373047, acc=0.055444445461034775, loss=3.3210277557373047
test: epoch 1, loss 3.899049997329712, acc=0.07777778059244156, loss=3.899049997329712
train: epoch 2, loss 2.223573923110962, acc=0.22833333909511566, loss=2.223573923110962
test: epoch 2, loss 2.883148670196533, acc=0.125, loss=2.883148670196533
train: epoch 3, loss 1.6793488264083862, acc=0.3586111068725586, loss=1.6793488264083862
test: epoch 3, loss 2.9831278324127197, acc=0.15000000596046448, loss=2.9831278324127197
train: epoch 4, loss 1.4667892456054688, acc=0.4213888943195343, loss=1.4667892456054688
test: epoch 4, loss 2.767514944076538, acc=0.16388888657093048, loss=2.767514944076538
train: epoch 5, loss 1.3297808170318604, acc=0.47127777338027954, loss=1.3297808170318604
test: epoch 5, loss 2.7713444232940674, acc=0.16944444179534912, loss=2.7713444232940674
train: epoch 6, loss 1.2403286695480347, acc=0.5108888745307922, loss=1.2403286695480347
test: epoch 6, loss 2.642904281616211, acc=0.1805555522441864, loss=2.642904281616211
train: epoch 7, loss 1.145186185836792, acc=0.5563889145851135, loss=1.145186185836792
test: epoch 7, loss 2.8613879680633545, acc=0.21111111342906952, loss=2.8613879680633545
train: epoch 8, loss 1.0789445638656616, acc=0.5723888874053955, loss=1.0789445638656616
test: epoch 8, loss 2.564138412475586, acc=0.2361111044883728, loss=2.564138412475586
train: epoch 9, loss 1.0343691110610962, acc=0.5992222428321838, loss=1.0343691110610962
test: epoch 9, loss 2.4725728034973145, acc=0.2083333283662796, loss=2.4725728034973145
train: epoch 10, loss 0.9984584450721741, acc=0.6106111407279968, loss=0.9984584450721741
test: epoch 10, loss 2.25951886177063, acc=0.24722221493721008, loss=2.25951886177063
train: epoch 11, loss 0.9507037997245789, acc=0.6236666440963745, loss=0.9507037997245789
test: epoch 11, loss 2.1111960411071777, acc=0.23055554926395416, loss=2.1111960411071777
train: epoch 12, loss 0.910248875617981, acc=0.6456666588783264, loss=0.910248875617981
test: epoch 12, loss 2.176691770553589, acc=0.24444444477558136, loss=2.176691770553589
train: epoch 13, loss 0.9000985026359558, acc=0.6539444327354431, loss=0.9000985026359558
test: epoch 13, loss 2.072153329849243, acc=0.24166665971279144, loss=2.072153329849243
train: epoch 14, loss 0.8385997414588928, acc=0.6715555787086487, loss=0.8385997414588928
test: epoch 14, loss 2.215883493423462, acc=0.25, loss=2.215883493423462
train: epoch 15, loss 0.8296974897384644, acc=0.6727222204208374, loss=0.8296974897384644
test: epoch 15, loss 2.096867322921753, acc=0.2805555462837219, loss=2.096867322921753
train: epoch 16, loss 0.8133689165115356, acc=0.6907777786254883, loss=0.8133689165115356
test: epoch 16, loss 1.948032021522522, acc=0.3305555582046509, loss=1.948032021522522
train: epoch 17, loss 0.7946016788482666, acc=0.6913889050483704, loss=0.7946016788482666
test: epoch 17, loss 1.966340184211731, acc=0.3055555522441864, loss=1.966340184211731
train: epoch 18, loss 0.7729953527450562, acc=0.6991666555404663, loss=0.7729953527450562
test: epoch 18, loss 1.904702067375183, acc=0.2888889014720917, loss=1.904702067375183
train: epoch 19, loss 0.752298891544342, acc=0.7087777853012085, loss=0.752298891544342
test: epoch 19, loss 1.9505337476730347, acc=0.2888889014720917, loss=1.9505337476730347
train: epoch 20, loss 0.7368896007537842, acc=0.7110000252723694, loss=0.7368896007537842
test: epoch 20, loss 2.0306601524353027, acc=0.29722222685813904, loss=2.0306601524353027
train: epoch 21, loss 0.7183581590652466, acc=0.7221666574478149, loss=0.7183581590652466
test: epoch 21, loss 1.99443519115448, acc=0.3222222328186035, loss=1.99443519115448
train: epoch 22, loss 0.7221077084541321, acc=0.7246111035346985, loss=0.7221077084541321
test: epoch 22, loss 1.8879077434539795, acc=0.31388887763023376, loss=1.8879077434539795
train: epoch 23, loss 0.6921800374984741, acc=0.7338333129882812, loss=0.6921800374984741
test: epoch 23, loss 1.8843090534210205, acc=0.3472222089767456, loss=1.8843090534210205
train: epoch 24, loss 0.6735038757324219, acc=0.7384999990463257, loss=0.6735038757324219
test: epoch 24, loss 1.7893033027648926, acc=0.3583333194255829, loss=1.7893033027648926
train: epoch 25, loss 0.65834641456604, acc=0.7493888735771179, loss=0.65834641456604
test: epoch 25, loss 1.808834195137024, acc=0.3333333432674408, loss=1.808834195137024
train: epoch 26, loss 0.6388921737670898, acc=0.7532222270965576, loss=0.6388921737670898
test: epoch 26, loss 1.6963858604431152, acc=0.38055557012557983, loss=1.6963858604431152
train: epoch 27, loss 0.6267425417900085, acc=0.7668889164924622, loss=0.6267425417900085
test: epoch 27, loss 1.750967264175415, acc=0.3888888955116272, loss=1.750967264175415
train: epoch 28, loss 0.6130184531211853, acc=0.7675555348396301, loss=0.6130184531211853
test: epoch 28, loss 1.609838604927063, acc=0.4166666567325592, loss=1.609838604927063
train: epoch 29, loss 0.5872012376785278, acc=0.7735000252723694, loss=0.5872012376785278
test: epoch 29, loss 1.6044481992721558, acc=0.40833333134651184, loss=1.6044481992721558
train: epoch 30, loss 0.5871329307556152, acc=0.7730000019073486, loss=0.5871329307556152
test: epoch 30, loss 1.5537302494049072, acc=0.4166666567325592, loss=1.5537302494049072
train: epoch 31, loss 0.555965006351471, acc=0.789222240447998, loss=0.555965006351471
test: epoch 31, loss 1.634106159210205, acc=0.4194444417953491, loss=1.634106159210205
train: epoch 32, loss 0.5594404935836792, acc=0.7902777791023254, loss=0.5594404935836792
test: epoch 32, loss 1.572023868560791, acc=0.4472222328186035, loss=1.572023868560791
train: epoch 33, loss 0.551827073097229, acc=0.7911666631698608, loss=0.551827073097229
test: epoch 33, loss 1.4106931686401367, acc=0.46666666865348816, loss=1.4106931686401367
train: epoch 34, loss 0.5331538915634155, acc=0.7941111326217651, loss=0.5331538915634155
test: epoch 34, loss 1.4146347045898438, acc=0.45277777314186096, loss=1.4146347045898438
train: epoch 35, loss 0.5306233167648315, acc=0.7995555400848389, loss=0.5306233167648315
test: epoch 35, loss 1.5559180974960327, acc=0.4444444477558136, loss=1.5559180974960327
train: epoch 36, loss 0.5140142440795898, acc=0.8041666746139526, loss=0.5140142440795898
test: epoch 36, loss 1.4713674783706665, acc=0.4722222089767456, loss=1.4713674783706665
train: epoch 37, loss 0.5136160850524902, acc=0.8011666536331177, loss=0.5136160850524902
test: epoch 37, loss 1.331612467765808, acc=0.4833333194255829, loss=1.331612467765808
train: epoch 38, loss 0.5106804966926575, acc=0.8018888831138611, loss=0.5106804966926575
test: epoch 38, loss 1.3402398824691772, acc=0.5083333253860474, loss=1.3402398824691772
train: epoch 39, loss 0.49624818563461304, acc=0.8108333349227905, loss=0.49624818563461304
test: epoch 39, loss 1.326377272605896, acc=0.5083333253860474, loss=1.326377272605896
train: epoch 40, loss 0.49127674102783203, acc=0.8090000152587891, loss=0.49127674102783203
test: epoch 40, loss 1.4256172180175781, acc=0.5111111402511597, loss=1.4256172180175781
train: epoch 41, loss 0.48340266942977905, acc=0.8159444332122803, loss=0.48340266942977905
test: epoch 41, loss 1.3769586086273193, acc=0.5111111402511597, loss=1.3769586086273193
train: epoch 42, loss 0.46493709087371826, acc=0.820388913154602, loss=0.46493709087371826
test: epoch 42, loss 1.311279296875, acc=0.5111111402511597, loss=1.311279296875
train: epoch 43, loss 0.46198198199272156, acc=0.8223888874053955, loss=0.46198198199272156
test: epoch 43, loss 1.2387083768844604, acc=0.5555555820465088, loss=1.2387083768844604
train: epoch 44, loss 0.46095383167266846, acc=0.8222777843475342, loss=0.46095383167266846
test: epoch 44, loss 1.1890857219696045, acc=0.5166666507720947, loss=1.1890857219696045
train: epoch 45, loss 0.4534118175506592, acc=0.8236666917800903, loss=0.4534118175506592
test: epoch 45, loss 1.2937477827072144, acc=0.5388888716697693, loss=1.2937477827072144
train: epoch 46, loss 0.44572293758392334, acc=0.8329444527626038, loss=0.44572293758392334
test: epoch 46, loss 1.2034263610839844, acc=0.5361111164093018, loss=1.2034263610839844
train: epoch 47, loss 0.4400734603404999, acc=0.8335000276565552, loss=0.4400734603404999
test: epoch 47, loss 1.2202136516571045, acc=0.5805555582046509, loss=1.2202136516571045
train: epoch 48, loss 0.4272913932800293, acc=0.8353888988494873, loss=0.4272913932800293
test: epoch 48, loss 1.21323561668396, acc=0.5611110925674438, loss=1.21323561668396
train: epoch 49, loss 0.43279188871383667, acc=0.835777759552002, loss=0.43279188871383667
test: epoch 49, loss 1.1444772481918335, acc=0.5638889074325562, loss=1.1444772481918335
train: epoch 50, loss 0.41724079847335815, acc=0.8448333144187927, loss=0.41724079847335815
test: epoch 50, loss 1.1304246187210083, acc=0.5944444537162781, loss=1.1304246187210083
train: epoch 51, loss 0.4064567983150482, acc=0.8442777991294861, loss=0.4064567983150482
test: epoch 51, loss 1.0779433250427246, acc=0.5777778029441833, loss=1.0779433250427246
train: epoch 52, loss 0.41796019673347473, acc=0.8443889021873474, loss=0.41796019673347473
test: epoch 52, loss 1.1216185092926025, acc=0.5722222328186035, loss=1.1216185092926025
train: epoch 53, loss 0.3934016227722168, acc=0.8532222509384155, loss=0.3934016227722168
test: epoch 53, loss 1.0478363037109375, acc=0.6000000238418579, loss=1.0478363037109375
train: epoch 54, loss 0.39230436086654663, acc=0.8506666421890259, loss=0.39230436086654663
test: epoch 54, loss 1.0809906721115112, acc=0.5805555582046509, loss=1.0809906721115112
train: epoch 55, loss 0.38999298214912415, acc=0.854888916015625, loss=0.38999298214912415
test: epoch 55, loss 1.0823372602462769, acc=0.6305555701255798, loss=1.0823372602462769
train: epoch 56, loss 0.37740394473075867, acc=0.8545555472373962, loss=0.37740394473075867
test: epoch 56, loss 1.0289242267608643, acc=0.6222222447395325, loss=1.0289242267608643
train: epoch 57, loss 0.3812331557273865, acc=0.8544999957084656, loss=0.3812331557273865
test: epoch 57, loss 1.0146065950393677, acc=0.6361111402511597, loss=1.0146065950393677
train: epoch 58, loss 0.3795012831687927, acc=0.8542777895927429, loss=0.3795012831687927
test: epoch 58, loss 0.989546000957489, acc=0.6333333253860474, loss=0.989546000957489
train: epoch 59, loss 0.3654593229293823, acc=0.859499990940094, loss=0.3654593229293823
test: epoch 59, loss 0.9398536086082458, acc=0.6194444298744202, loss=0.9398536086082458
train: epoch 60, loss 0.3672582805156708, acc=0.8575000166893005, loss=0.3672582805156708
test: epoch 60, loss 0.9103882908821106, acc=0.6361111402511597, loss=0.9103882908821106
train: epoch 61, loss 0.36477991938591003, acc=0.8576111197471619, loss=0.36477991938591003
test: epoch 61, loss 0.9573764801025391, acc=0.6416666507720947, loss=0.9573764801025391
train: epoch 62, loss 0.3552687466144562, acc=0.8638333082199097, loss=0.3552687466144562
test: epoch 62, loss 1.0848822593688965, acc=0.6388888955116272, loss=1.0848822593688965
train: epoch 63, loss 0.3685193657875061, acc=0.8598889112472534, loss=0.3685193657875061
test: epoch 63, loss 1.0579030513763428, acc=0.6388888955116272, loss=1.0579030513763428
train: epoch 64, loss 0.3601089417934418, acc=0.8615000247955322, loss=0.3601089417934418
test: epoch 64, loss 0.9174964427947998, acc=0.6499999761581421, loss=0.9174964427947998
train: epoch 65, loss 0.34732377529144287, acc=0.8646666407585144, loss=0.34732377529144287
test: epoch 65, loss 0.930120050907135, acc=0.6833333373069763, loss=0.930120050907135
train: epoch 66, loss 0.35170629620552063, acc=0.8602777719497681, loss=0.35170629620552063
test: epoch 66, loss 0.9059489369392395, acc=0.6555555462837219, loss=0.9059489369392395
train: epoch 67, loss 0.35382673144340515, acc=0.8576666712760925, loss=0.35382673144340515
test: epoch 67, loss 0.8524504899978638, acc=0.6777777671813965, loss=0.8524504899978638
train: epoch 68, loss 0.3643609583377838, acc=0.8573889136314392, loss=0.3643609583377838
test: epoch 68, loss 0.8640842437744141, acc=0.6833333373069763, loss=0.8640842437744141
train: epoch 69, loss 0.35382020473480225, acc=0.8616666793823242, loss=0.35382020473480225
test: epoch 69, loss 0.8772399425506592, acc=0.6888889074325562, loss=0.8772399425506592
train: epoch 70, loss 0.34752753376960754, acc=0.8641111254692078, loss=0.34752753376960754
test: epoch 70, loss 0.8543323278427124, acc=0.6833333373069763, loss=0.8543323278427124
train: epoch 71, loss 0.3526494801044464, acc=0.8606111407279968, loss=0.3526494801044464
test: epoch 71, loss 0.7623323202133179, acc=0.6916666626930237, loss=0.7623323202133179
train: epoch 72, loss 0.3475538492202759, acc=0.8638333082199097, loss=0.3475538492202759
test: epoch 72, loss 0.8650809526443481, acc=0.6833333373069763, loss=0.8650809526443481
train: epoch 73, loss 0.3433883786201477, acc=0.8621666431427002, loss=0.3433883786201477
test: epoch 73, loss 0.8406213521957397, acc=0.6861110925674438, loss=0.8406213521957397
train: epoch 74, loss 0.3427291512489319, acc=0.8627222180366516, loss=0.3427291512489319
test: epoch 74, loss 0.8852328062057495, acc=0.6833333373069763, loss=0.8852328062057495
train: epoch 75, loss 0.332187682390213, acc=0.8635555505752563, loss=0.332187682390213
test: epoch 75, loss 0.7986481785774231, acc=0.699999988079071, loss=0.7986481785774231
train: epoch 76, loss 0.33591750264167786, acc=0.8633888959884644, loss=0.33591750264167786
test: epoch 76, loss 0.7754127979278564, acc=0.7055555582046509, loss=0.7754127979278564
train: epoch 77, loss 0.33232882618904114, acc=0.8659999966621399, loss=0.33232882618904114
test: epoch 77, loss 0.9816192984580994, acc=0.6916666626930237, loss=0.9816192984580994
train: epoch 78, loss 0.32578346133232117, acc=0.8657777905464172, loss=0.32578346133232117
test: epoch 78, loss 0.81025630235672, acc=0.6944444179534912, loss=0.81025630235672
train: epoch 79, loss 0.31880059838294983, acc=0.8690555691719055, loss=0.31880059838294983
test: epoch 79, loss 0.8823823928833008, acc=0.7083333134651184, loss=0.8823823928833008
train: epoch 80, loss 0.3284640312194824, acc=0.8653888702392578, loss=0.3284640312194824
test: epoch 80, loss 0.7111532688140869, acc=0.7083333134651184, loss=0.7111532688140869
train: epoch 81, loss 0.31165361404418945, acc=0.8688333630561829, loss=0.31165361404418945
test: epoch 81, loss 0.7942925691604614, acc=0.7027778029441833, loss=0.7942925691604614
train: epoch 82, loss 0.3149259686470032, acc=0.8673333525657654, loss=0.3149259686470032
test: epoch 82, loss 0.8829537630081177, acc=0.6972222328186035, loss=0.8829537630081177
train: epoch 83, loss 0.3240734934806824, acc=0.8658888936042786, loss=0.3240734934806824
test: epoch 83, loss 0.792665958404541, acc=0.7083333134651184, loss=0.792665958404541
train: epoch 84, loss 0.3151318430900574, acc=0.8698333501815796, loss=0.3151318430900574
test: epoch 84, loss 0.8289304971694946, acc=0.699999988079071, loss=0.8289304971694946
train: epoch 85, loss 0.31477421522140503, acc=0.8725000023841858, loss=0.31477421522140503
test: epoch 85, loss 0.8103269934654236, acc=0.699999988079071, loss=0.8103269934654236
train: epoch 86, loss 0.3035966455936432, acc=0.8728888630867004, loss=0.3035966455936432
test: epoch 86, loss 0.7673590779304504, acc=0.7166666388511658, loss=0.7673590779304504
train: epoch 87, loss 0.3027195334434509, acc=0.871666669845581, loss=0.3027195334434509
test: epoch 87, loss 0.8716381788253784, acc=0.6944444179534912, loss=0.8716381788253784
train: epoch 88, loss 0.29919904470443726, acc=0.8713889122009277, loss=0.29919904470443726
test: epoch 88, loss 0.8231375813484192, acc=0.7111111283302307, loss=0.8231375813484192
train: epoch 89, loss 0.3018520176410675, acc=0.874666690826416, loss=0.3018520176410675
test: epoch 89, loss 0.885443389415741, acc=0.7111111283302307, loss=0.885443389415741
train: epoch 90, loss 0.3030737340450287, acc=0.8722777962684631, loss=0.3030737340450287
test: epoch 90, loss 0.8044681549072266, acc=0.7111111283302307, loss=0.8044681549072266
train: epoch 91, loss 0.30657872557640076, acc=0.8738333582878113, loss=0.30657872557640076
test: epoch 91, loss 0.7717066407203674, acc=0.7166666388511658, loss=0.7717066407203674
train: epoch 92, loss 0.2867708206176758, acc=0.8736666440963745, loss=0.2867708206176758
test: epoch 92, loss 0.7910125851631165, acc=0.7083333134651184, loss=0.7910125851631165
train: epoch 93, loss 0.28251174092292786, acc=0.878944456577301, loss=0.28251174092292786
test: epoch 93, loss 0.843146026134491, acc=0.7083333134651184, loss=0.843146026134491
train: epoch 94, loss 0.28537610173225403, acc=0.8779444694519043, loss=0.28537610173225403
test: epoch 94, loss 0.8273044228553772, acc=0.7111111283302307, loss=0.8273044228553772
train: epoch 95, loss 0.28863561153411865, acc=0.8743333220481873, loss=0.28863561153411865
test: epoch 95, loss 0.8271725177764893, acc=0.7083333134651184, loss=0.8271725177764893
train: epoch 96, loss 0.2868657112121582, acc=0.8760555386543274, loss=0.2868657112121582
test: epoch 96, loss 0.8809544444084167, acc=0.7166666388511658, loss=0.8809544444084167
train: epoch 97, loss 0.29141589999198914, acc=0.8750555515289307, loss=0.29141589999198914
test: epoch 97, loss 0.8223404288291931, acc=0.7138888835906982, loss=0.8223404288291931
train: epoch 98, loss 0.28954455256462097, acc=0.878166675567627, loss=0.28954455256462097
test: epoch 98, loss 0.9020134806632996, acc=0.7138888835906982, loss=0.9020134806632996
train: epoch 99, loss 0.277612566947937, acc=0.8781111240386963, loss=0.277612566947937
test: epoch 99, loss 0.7914267182350159, acc=0.7138888835906982, loss=0.7914267182350159
train: epoch 100, loss 0.27247098088264465, acc=0.8813889026641846, loss=0.27247098088264465
test: epoch 100, loss 0.8217648863792419, acc=0.7166666388511658, loss=0.8217648863792419
train: epoch 101, loss 0.2814682424068451, acc=0.8782777786254883, loss=0.2814682424068451
test: epoch 101, loss 0.794001042842865, acc=0.7194444537162781, loss=0.794001042842865
train: epoch 102, loss 0.2701652944087982, acc=0.8820555806159973, loss=0.2701652944087982
test: epoch 102, loss 0.8885573744773865, acc=0.7194444537162781, loss=0.8885573744773865
train: epoch 103, loss 0.2745059132575989, acc=0.8836110830307007, loss=0.2745059132575989
test: epoch 103, loss 0.796371579170227, acc=0.7055555582046509, loss=0.796371579170227
train: epoch 104, loss 0.2679506540298462, acc=0.8814444541931152, loss=0.2679506540298462
test: epoch 104, loss 0.8255140781402588, acc=0.7194444537162781, loss=0.8255140781402588
train: epoch 105, loss 0.277972936630249, acc=0.8803889155387878, loss=0.277972936630249
test: epoch 105, loss 0.81658935546875, acc=0.7138888835906982, loss=0.81658935546875
train: epoch 106, loss 0.26762712001800537, acc=0.8830000162124634, loss=0.26762712001800537
test: epoch 106, loss 0.8547645211219788, acc=0.7194444537162781, loss=0.8547645211219788
train: epoch 107, loss 0.27718260884284973, acc=0.8808333277702332, loss=0.27718260884284973
test: epoch 107, loss 0.7983170747756958, acc=0.7194444537162781, loss=0.7983170747756958
train: epoch 108, loss 0.2660813629627228, acc=0.8832777738571167, loss=0.2660813629627228
test: epoch 108, loss 0.8448861241340637, acc=0.7194444537162781, loss=0.8448861241340637
train: epoch 109, loss 0.26679137349128723, acc=0.8849999904632568, loss=0.26679137349128723
test: epoch 109, loss 0.7928623557090759, acc=0.7194444537162781, loss=0.7928623557090759
train: epoch 110, loss 0.2814927101135254, acc=0.8796111345291138, loss=0.2814927101135254
test: epoch 110, loss 0.8038426041603088, acc=0.7194444537162781, loss=0.8038426041603088
train: epoch 111, loss 0.26839783787727356, acc=0.8812777996063232, loss=0.26839783787727356
test: epoch 111, loss 0.8157296180725098, acc=0.7222222089767456, loss=0.8157296180725098
train: epoch 112, loss 0.2672368884086609, acc=0.8811110854148865, loss=0.2672368884086609
test: epoch 112, loss 0.8964277505874634, acc=0.7194444537162781, loss=0.8964277505874634
train: epoch 113, loss 0.2738192081451416, acc=0.8810555338859558, loss=0.2738192081451416
test: epoch 113, loss 0.8685885071754456, acc=0.7250000238418579, loss=0.8685885071754456
train: epoch 114, loss 0.26289793848991394, acc=0.8853889107704163, loss=0.26289793848991394
test: epoch 114, loss 0.8535202145576477, acc=0.7222222089767456, loss=0.8535202145576477
train: epoch 115, loss 0.26646095514297485, acc=0.8809444308280945, loss=0.26646095514297485
test: epoch 115, loss 0.8818297982215881, acc=0.7222222089767456, loss=0.8818297982215881
train: epoch 116, loss 0.26049649715423584, acc=0.8871666789054871, loss=0.26049649715423584
test: epoch 116, loss 0.812099039554596, acc=0.7166666388511658, loss=0.812099039554596
train: epoch 117, loss 0.269497275352478, acc=0.8836666941642761, loss=0.269497275352478
test: epoch 117, loss 0.7918666005134583, acc=0.7194444537162781, loss=0.7918666005134583
train: epoch 118, loss 0.2652791142463684, acc=0.8824999928474426, loss=0.2652791142463684
test: epoch 118, loss 0.8145316243171692, acc=0.7194444537162781, loss=0.8145316243171692
train: epoch 119, loss 0.26262351870536804, acc=0.8847222328186035, loss=0.26262351870536804
test: epoch 119, loss 0.851987898349762, acc=0.7222222089767456, loss=0.851987898349762
train: epoch 120, loss 0.26429444551467896, acc=0.8823888897895813, loss=0.26429444551467896
test: epoch 120, loss 0.918118417263031, acc=0.7222222089767456, loss=0.918118417263031
train: epoch 121, loss 0.259721577167511, acc=0.8860555291175842, loss=0.259721577167511
test: epoch 121, loss 0.7443698644638062, acc=0.7222222089767456, loss=0.7443698644638062
train: epoch 122, loss 0.2591296136379242, acc=0.8849999904632568, loss=0.2591296136379242
test: epoch 122, loss 0.8423536419868469, acc=0.7222222089767456, loss=0.8423536419868469
train: epoch 123, loss 0.2620861530303955, acc=0.8843888640403748, loss=0.2620861530303955
test: epoch 123, loss 0.8672922849655151, acc=0.7222222089767456, loss=0.8672922849655151
train: epoch 124, loss 0.25519445538520813, acc=0.883222222328186, loss=0.25519445538520813
test: epoch 124, loss 0.8940016031265259, acc=0.7222222089767456, loss=0.8940016031265259
train: epoch 125, loss 0.26025834679603577, acc=0.8859444260597229, loss=0.26025834679603577
test: epoch 125, loss 0.853447675704956, acc=0.7222222089767456, loss=0.853447675704956
train: epoch 126, loss 0.26019367575645447, acc=0.8834999799728394, loss=0.26019367575645447
test: epoch 126, loss 0.8886815309524536, acc=0.7222222089767456, loss=0.8886815309524536
train: epoch 127, loss 0.2545962631702423, acc=0.8857777714729309, loss=0.2545962631702423
test: epoch 127, loss 0.8974857330322266, acc=0.7222222089767456, loss=0.8974857330322266
train: epoch 128, loss 0.2607143819332123, acc=0.8831666707992554, loss=0.2607143819332123
test: epoch 128, loss 0.8239627480506897, acc=0.7138888835906982, loss=0.8239627480506897
train: epoch 129, loss 0.25669434666633606, acc=0.8847222328186035, loss=0.25669434666633606
test: epoch 129, loss 0.8508921265602112, acc=0.7222222089767456, loss=0.8508921265602112
train: epoch 130, loss 0.25513046979904175, acc=0.8847777843475342, loss=0.25513046979904175
test: epoch 130, loss 0.8286755084991455, acc=0.7166666388511658, loss=0.8286755084991455
train: epoch 131, loss 0.2538011968135834, acc=0.8878889083862305, loss=0.2538011968135834
test: epoch 131, loss 0.8509007692337036, acc=0.7222222089767456, loss=0.8509007692337036
train: epoch 132, loss 0.25755712389945984, acc=0.8833333253860474, loss=0.25755712389945984
test: epoch 132, loss 0.8395084738731384, acc=0.7222222089767456, loss=0.8395084738731384
train: epoch 133, loss 0.25464364886283875, acc=0.886388897895813, loss=0.25464364886283875
test: epoch 133, loss 0.8324621319770813, acc=0.7222222089767456, loss=0.8324621319770813
train: epoch 134, loss 0.24939917027950287, acc=0.8875555396080017, loss=0.24939917027950287
test: epoch 134, loss 0.7846964597702026, acc=0.7222222089767456, loss=0.7846964597702026
train: epoch 135, loss 0.24748510122299194, acc=0.8912222385406494, loss=0.24748510122299194
test: epoch 135, loss 0.8724758625030518, acc=0.7222222089767456, loss=0.8724758625030518
train: epoch 136, loss 0.2558908462524414, acc=0.8847777843475342, loss=0.2558908462524414
test: epoch 136, loss 0.8233110308647156, acc=0.7222222089767456, loss=0.8233110308647156
train: epoch 137, loss 0.25634899735450745, acc=0.8881111145019531, loss=0.25634899735450745
test: epoch 137, loss 0.771933913230896, acc=0.7222222089767456, loss=0.771933913230896
train: epoch 138, loss 0.2526788115501404, acc=0.8888333439826965, loss=0.2526788115501404
test: epoch 138, loss 0.9852302074432373, acc=0.7222222089767456, loss=0.9852302074432373
train: epoch 139, loss 0.25884702801704407, acc=0.8848888874053955, loss=0.25884702801704407
test: epoch 139, loss 0.8447967171669006, acc=0.7250000238418579, loss=0.8447967171669006
train: epoch 140, loss 0.24904599785804749, acc=0.8889444470405579, loss=0.24904599785804749
test: epoch 140, loss 0.7613537311553955, acc=0.7222222089767456, loss=0.7613537311553955
train: epoch 141, loss 0.2550932765007019, acc=0.8859444260597229, loss=0.2550932765007019
test: epoch 141, loss 0.8101545572280884, acc=0.7194444537162781, loss=0.8101545572280884
train: epoch 142, loss 0.25199562311172485, acc=0.8865000009536743, loss=0.25199562311172485
test: epoch 142, loss 0.9572203755378723, acc=0.7222222089767456, loss=0.9572203755378723
train: epoch 143, loss 0.25608718395233154, acc=0.8845000267028809, loss=0.25608718395233154
test: epoch 143, loss 0.7597401142120361, acc=0.7194444537162781, loss=0.7597401142120361
train: epoch 144, loss 0.2595350742340088, acc=0.8852777481079102, loss=0.2595350742340088
test: epoch 144, loss 0.8235653638839722, acc=0.7222222089767456, loss=0.8235653638839722
train: epoch 145, loss 0.25200989842414856, acc=0.8865000009536743, loss=0.25200989842414856
test: epoch 145, loss 0.9078960418701172, acc=0.7166666388511658, loss=0.9078960418701172
train: epoch 146, loss 0.25342851877212524, acc=0.8851666450500488, loss=0.25342851877212524
test: epoch 146, loss 0.8994927406311035, acc=0.7222222089767456, loss=0.8994927406311035
train: epoch 147, loss 0.24982166290283203, acc=0.8893333077430725, loss=0.24982166290283203
test: epoch 147, loss 0.8695361614227295, acc=0.7222222089767456, loss=0.8695361614227295
train: epoch 148, loss 0.24792085587978363, acc=0.8877778053283691, loss=0.24792085587978363
test: epoch 148, loss 0.9222185015678406, acc=0.7222222089767456, loss=0.9222185015678406
train: epoch 149, loss 0.24638882279396057, acc=0.8876110911369324, loss=0.24638882279396057
test: epoch 149, loss 0.7841947674751282, acc=0.7222222089767456, loss=0.7841947674751282
train: epoch 150, loss 0.2531282603740692, acc=0.8845555782318115, loss=0.2531282603740692
test: epoch 150, loss 0.7967906594276428, acc=0.7222222089767456, loss=0.7967906594276428
