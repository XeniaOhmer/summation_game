# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1.5", "--temp_decay=1", "--one_hot=true", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=719504590, receiver_embed_dim=32, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.108123302459717, acc=0.07411111146211624, loss=3.108123302459717
test: epoch 1, loss 3.0121352672576904, acc=0.13055555522441864, loss=3.0121352672576904
train: epoch 2, loss 2.139573574066162, acc=0.1951666623353958, loss=2.139573574066162
test: epoch 2, loss 2.9797329902648926, acc=0.125, loss=2.9797329902648926
train: epoch 3, loss 1.8249090909957886, acc=0.2615000009536743, loss=1.8249090909957886
test: epoch 3, loss 3.2332863807678223, acc=0.16111111640930176, loss=3.2332863807678223
train: epoch 4, loss 1.6562929153442383, acc=0.3051111102104187, loss=1.6562929153442383
test: epoch 4, loss 3.011148452758789, acc=0.13333334028720856, loss=3.011148452758789
train: epoch 5, loss 1.524173378944397, acc=0.3537222146987915, loss=1.524173378944397
test: epoch 5, loss 2.883026599884033, acc=0.22777777910232544, loss=2.883026599884033
train: epoch 6, loss 1.358657956123352, acc=0.42233332991600037, loss=1.358657956123352
test: epoch 6, loss 2.704249382019043, acc=0.21666666865348816, loss=2.704249382019043
train: epoch 7, loss 1.133448839187622, acc=0.5252222418785095, loss=1.133448839187622
test: epoch 7, loss 2.738206624984741, acc=0.23333333432674408, loss=2.738206624984741
train: epoch 8, loss 0.9749653935432434, acc=0.5942222476005554, loss=0.9749653935432434
test: epoch 8, loss 2.6257193088531494, acc=0.22777777910232544, loss=2.6257193088531494
train: epoch 9, loss 0.8638916611671448, acc=0.6365000009536743, loss=0.8638916611671448
test: epoch 9, loss 2.832186698913574, acc=0.23888888955116272, loss=2.832186698913574
train: epoch 10, loss 0.7930778861045837, acc=0.6684444546699524, loss=0.7930778861045837
test: epoch 10, loss 2.3600058555603027, acc=0.2777777910232544, loss=2.3600058555603027
train: epoch 11, loss 0.7442921996116638, acc=0.6889444589614868, loss=0.7442921996116638
test: epoch 11, loss 2.5332658290863037, acc=0.27222222089767456, loss=2.5332658290863037
train: epoch 12, loss 0.6983432173728943, acc=0.7055000066757202, loss=0.6983432173728943
test: epoch 12, loss 2.448690414428711, acc=0.25555557012557983, loss=2.448690414428711
train: epoch 13, loss 0.664995551109314, acc=0.7165555357933044, loss=0.664995551109314
test: epoch 13, loss 2.0670900344848633, acc=0.3194444477558136, loss=2.0670900344848633
train: epoch 14, loss 0.63548743724823, acc=0.7350555658340454, loss=0.63548743724823
test: epoch 14, loss 2.443734645843506, acc=0.25, loss=2.443734645843506
train: epoch 15, loss 0.6039904952049255, acc=0.7466111183166504, loss=0.6039904952049255
test: epoch 15, loss 2.0361578464508057, acc=0.3361110985279083, loss=2.0361578464508057
train: epoch 16, loss 0.5811529755592346, acc=0.757111132144928, loss=0.5811529755592346
test: epoch 16, loss 2.1504814624786377, acc=0.30000001192092896, loss=2.1504814624786377
train: epoch 17, loss 0.5711942911148071, acc=0.7603889107704163, loss=0.5711942911148071
test: epoch 17, loss 2.1851089000701904, acc=0.3194444477558136, loss=2.1851089000701904
train: epoch 18, loss 0.5252330899238586, acc=0.7878888845443726, loss=0.5252330899238586
test: epoch 18, loss 2.373420000076294, acc=0.35277777910232544, loss=2.373420000076294
train: epoch 19, loss 0.5128645896911621, acc=0.7912222146987915, loss=0.5128645896911621
test: epoch 19, loss 2.246601104736328, acc=0.3333333432674408, loss=2.246601104736328
train: epoch 20, loss 0.4673120975494385, acc=0.8070555329322815, loss=0.4673120975494385
test: epoch 20, loss 2.30314040184021, acc=0.3444444537162781, loss=2.30314040184021
train: epoch 21, loss 0.4425029754638672, acc=0.8157222270965576, loss=0.4425029754638672
test: epoch 21, loss 2.9116082191467285, acc=0.32499998807907104, loss=2.9116082191467285
train: epoch 22, loss 0.42607349157333374, acc=0.8252221941947937, loss=0.42607349157333374
test: epoch 22, loss 2.5598812103271484, acc=0.3194444477558136, loss=2.5598812103271484
train: epoch 23, loss 0.4277198314666748, acc=0.8206111192703247, loss=0.4277198314666748
test: epoch 23, loss 2.060943603515625, acc=0.33888888359069824, loss=2.060943603515625
train: epoch 24, loss 0.39625653624534607, acc=0.8340555429458618, loss=0.39625653624534607
test: epoch 24, loss 1.9372879266738892, acc=0.36944442987442017, loss=1.9372879266738892
train: epoch 25, loss 0.38846442103385925, acc=0.8384444713592529, loss=0.38846442103385925
test: epoch 25, loss 1.946303129196167, acc=0.3888888955116272, loss=1.946303129196167
train: epoch 26, loss 0.37890174984931946, acc=0.8396111130714417, loss=0.37890174984931946
test: epoch 26, loss 1.8880072832107544, acc=0.39722222089767456, loss=1.8880072832107544
train: epoch 27, loss 0.37094590067863464, acc=0.8482221961021423, loss=0.37094590067863464
test: epoch 27, loss 1.824349284172058, acc=0.38055557012557983, loss=1.824349284172058
train: epoch 28, loss 0.38671058416366577, acc=0.8413333296775818, loss=0.38671058416366577
test: epoch 28, loss 2.0813567638397217, acc=0.32499998807907104, loss=2.0813567638397217
train: epoch 29, loss 0.37235063314437866, acc=0.8473888635635376, loss=0.37235063314437866
test: epoch 29, loss 1.9979902505874634, acc=0.3444444537162781, loss=1.9979902505874634
train: epoch 30, loss 0.35332170128822327, acc=0.8536666631698608, loss=0.35332170128822327
test: epoch 30, loss 1.934610366821289, acc=0.29722222685813904, loss=1.934610366821289
train: epoch 31, loss 0.3445388972759247, acc=0.8600000143051147, loss=0.3445388972759247
test: epoch 31, loss 1.6320509910583496, acc=0.4166666567325592, loss=1.6320509910583496
train: epoch 32, loss 0.34018474817276, acc=0.8617777824401855, loss=0.34018474817276
test: epoch 32, loss 2.148338794708252, acc=0.3722222149372101, loss=2.148338794708252
train: epoch 33, loss 0.3317330479621887, acc=0.8633333444595337, loss=0.3317330479621887
test: epoch 33, loss 1.9386054277420044, acc=0.39722222089767456, loss=1.9386054277420044
train: epoch 34, loss 0.3196201026439667, acc=0.8741666674613953, loss=0.3196201026439667
test: epoch 34, loss 2.0643951892852783, acc=0.3638888895511627, loss=2.0643951892852783
train: epoch 35, loss 0.31876394152641296, acc=0.8717777729034424, loss=0.31876394152641296
test: epoch 35, loss 1.7224663496017456, acc=0.4027777910232544, loss=1.7224663496017456
train: epoch 36, loss 0.3075375258922577, acc=0.8777777552604675, loss=0.3075375258922577
test: epoch 36, loss 2.1753218173980713, acc=0.38333332538604736, loss=2.1753218173980713
train: epoch 37, loss 0.3094216585159302, acc=0.8743888735771179, loss=0.3094216585159302
test: epoch 37, loss 1.9199409484863281, acc=0.3888888955116272, loss=1.9199409484863281
train: epoch 38, loss 0.3134710490703583, acc=0.8761110901832581, loss=0.3134710490703583
test: epoch 38, loss 1.9272866249084473, acc=0.43611112236976624, loss=1.9272866249084473
train: epoch 39, loss 0.29434725642204285, acc=0.8813333511352539, loss=0.29434725642204285
test: epoch 39, loss 1.843808650970459, acc=0.42222222685813904, loss=1.843808650970459
train: epoch 40, loss 0.2836955189704895, acc=0.883222222328186, loss=0.2836955189704895
test: epoch 40, loss 2.141326665878296, acc=0.4333333373069763, loss=2.141326665878296
train: epoch 41, loss 0.2800932824611664, acc=0.8845000267028809, loss=0.2800932824611664
test: epoch 41, loss 2.2284722328186035, acc=0.375, loss=2.2284722328186035
train: epoch 42, loss 0.28435954451560974, acc=0.8834444284439087, loss=0.28435954451560974
test: epoch 42, loss 2.363739252090454, acc=0.3583333194255829, loss=2.363739252090454
train: epoch 43, loss 0.27050429582595825, acc=0.8894444704055786, loss=0.27050429582595825
test: epoch 43, loss 2.1967039108276367, acc=0.4000000059604645, loss=2.1967039108276367
train: epoch 44, loss 0.2888576090335846, acc=0.883055567741394, loss=0.2888576090335846
test: epoch 44, loss 2.46783447265625, acc=0.32777777314186096, loss=2.46783447265625
train: epoch 45, loss 0.261026531457901, acc=0.8928333520889282, loss=0.261026531457901
test: epoch 45, loss 1.993971347808838, acc=0.4305555522441864, loss=1.993971347808838
train: epoch 46, loss 0.2656387686729431, acc=0.8881666660308838, loss=0.2656387686729431
test: epoch 46, loss 1.9444912672042847, acc=0.3916666805744171, loss=1.9444912672042847
train: epoch 47, loss 0.2647860050201416, acc=0.8908888697624207, loss=0.2647860050201416
test: epoch 47, loss 1.8827018737792969, acc=0.39722222089767456, loss=1.8827018737792969
train: epoch 48, loss 0.2589685916900635, acc=0.8915555477142334, loss=0.2589685916900635
test: epoch 48, loss 1.9059662818908691, acc=0.4333333373069763, loss=1.9059662818908691
train: epoch 49, loss 0.2529049515724182, acc=0.8927778005599976, loss=0.2529049515724182
test: epoch 49, loss 2.1026158332824707, acc=0.41111111640930176, loss=2.1026158332824707
train: epoch 50, loss 0.2606249451637268, acc=0.8914444446563721, loss=0.2606249451637268
test: epoch 50, loss 2.008049488067627, acc=0.3861111104488373, loss=2.008049488067627
train: epoch 51, loss 0.2592069208621979, acc=0.8931666612625122, loss=0.2592069208621979
test: epoch 51, loss 1.5800964832305908, acc=0.4749999940395355, loss=1.5800964832305908
train: epoch 52, loss 0.26010996103286743, acc=0.8922222256660461, loss=0.26010996103286743
test: epoch 52, loss 1.9380286931991577, acc=0.43611112236976624, loss=1.9380286931991577
train: epoch 53, loss 0.24610009789466858, acc=0.8971111178398132, loss=0.24610009789466858
test: epoch 53, loss 1.7236884832382202, acc=0.45277777314186096, loss=1.7236884832382202
train: epoch 54, loss 0.24288976192474365, acc=0.8958888649940491, loss=0.24288976192474365
test: epoch 54, loss 2.6421916484832764, acc=0.4472222328186035, loss=2.6421916484832764
train: epoch 55, loss 0.25165876746177673, acc=0.8952222466468811, loss=0.25165876746177673
test: epoch 55, loss 2.189700126647949, acc=0.39722222089767456, loss=2.189700126647949
train: epoch 56, loss 0.23069825768470764, acc=0.8986666798591614, loss=0.23069825768470764
test: epoch 56, loss 2.165198564529419, acc=0.3333333432674408, loss=2.165198564529419
train: epoch 57, loss 0.23856797814369202, acc=0.8985000252723694, loss=0.23856797814369202
test: epoch 57, loss 2.0670135021209717, acc=0.42222222685813904, loss=2.0670135021209717
train: epoch 58, loss 0.24613942205905914, acc=0.8969444632530212, loss=0.24613942205905914
test: epoch 58, loss 2.0508415699005127, acc=0.4861111044883728, loss=2.0508415699005127
train: epoch 59, loss 0.2177257388830185, acc=0.9054444432258606, loss=0.2177257388830185
test: epoch 59, loss 1.800645351409912, acc=0.47777777910232544, loss=1.800645351409912
train: epoch 60, loss 0.24810241162776947, acc=0.8963888883590698, loss=0.24810241162776947
test: epoch 60, loss 2.2463877201080322, acc=0.42500001192092896, loss=2.2463877201080322
train: epoch 61, loss 0.2254977822303772, acc=0.9043333530426025, loss=0.2254977822303772
test: epoch 61, loss 2.130213737487793, acc=0.42222222685813904, loss=2.130213737487793
train: epoch 62, loss 0.2138810008764267, acc=0.9085555672645569, loss=0.2138810008764267
test: epoch 62, loss 2.235957145690918, acc=0.4444444477558136, loss=2.235957145690918
train: epoch 63, loss 0.22867542505264282, acc=0.9022777676582336, loss=0.22867542505264282
test: epoch 63, loss 2.259777307510376, acc=0.4166666567325592, loss=2.259777307510376
train: epoch 64, loss 0.2222663313150406, acc=0.9046666622161865, loss=0.2222663313150406
test: epoch 64, loss 1.9068806171417236, acc=0.4305555522441864, loss=1.9068806171417236
train: epoch 65, loss 0.22004948556423187, acc=0.9032222032546997, loss=0.22004948556423187
test: epoch 65, loss 2.1830482482910156, acc=0.5527777671813965, loss=2.1830482482910156
train: epoch 66, loss 0.21740113198757172, acc=0.9073333144187927, loss=0.21740113198757172
test: epoch 66, loss 2.3550970554351807, acc=0.3638888895511627, loss=2.3550970554351807
train: epoch 67, loss 0.2149745225906372, acc=0.9068333506584167, loss=0.2149745225906372
test: epoch 67, loss 1.9006327390670776, acc=0.5527777671813965, loss=1.9006327390670776
train: epoch 68, loss 0.20999662578105927, acc=0.9091110825538635, loss=0.20999662578105927
test: epoch 68, loss 2.7710835933685303, acc=0.4722222089767456, loss=2.7710835933685303
train: epoch 69, loss 0.2444491684436798, acc=0.8993889093399048, loss=0.2444491684436798
test: epoch 69, loss 1.6208992004394531, acc=0.4833333194255829, loss=1.6208992004394531
train: epoch 70, loss 0.2093222439289093, acc=0.9091110825538635, loss=0.2093222439289093
test: epoch 70, loss 1.8816258907318115, acc=0.49166667461395264, loss=1.8816258907318115
train: epoch 71, loss 0.1954561322927475, acc=0.9149444699287415, loss=0.1954561322927475
test: epoch 71, loss 2.2178895473480225, acc=0.4416666626930237, loss=2.2178895473480225
train: epoch 72, loss 0.20234030485153198, acc=0.9117777943611145, loss=0.20234030485153198
test: epoch 72, loss 1.737887978553772, acc=0.4583333432674408, loss=1.737887978553772
train: epoch 73, loss 0.20420867204666138, acc=0.9103888869285583, loss=0.20420867204666138
test: epoch 73, loss 2.5102169513702393, acc=0.3722222149372101, loss=2.5102169513702393
train: epoch 74, loss 0.2051665335893631, acc=0.9106666445732117, loss=0.2051665335893631
test: epoch 74, loss 2.7226617336273193, acc=0.40833333134651184, loss=2.7226617336273193
train: epoch 75, loss 0.19613540172576904, acc=0.9140555262565613, loss=0.19613540172576904
test: epoch 75, loss 2.0389256477355957, acc=0.5027777552604675, loss=2.0389256477355957
train: epoch 76, loss 0.20006154477596283, acc=0.913611114025116, loss=0.20006154477596283
test: epoch 76, loss 2.444248676300049, acc=0.42500001192092896, loss=2.444248676300049
train: epoch 77, loss 0.20309433341026306, acc=0.9132221937179565, loss=0.20309433341026306
test: epoch 77, loss 1.9691128730773926, acc=0.49166667461395264, loss=1.9691128730773926
train: epoch 78, loss 0.20076674222946167, acc=0.9129444360733032, loss=0.20076674222946167
test: epoch 78, loss 2.5491833686828613, acc=0.4555555582046509, loss=2.5491833686828613
train: epoch 79, loss 0.19207143783569336, acc=0.9151111245155334, loss=0.19207143783569336
test: epoch 79, loss 2.139120578765869, acc=0.5249999761581421, loss=2.139120578765869
train: epoch 80, loss 0.18731006979942322, acc=0.9173333048820496, loss=0.18731006979942322
test: epoch 80, loss 2.101712465286255, acc=0.46666666865348816, loss=2.101712465286255
train: epoch 81, loss 0.19801923632621765, acc=0.9140555262565613, loss=0.19801923632621765
test: epoch 81, loss 1.994662880897522, acc=0.46666666865348816, loss=1.994662880897522
train: epoch 82, loss 0.18774868547916412, acc=0.9161666631698608, loss=0.18774868547916412
test: epoch 82, loss 2.091034412384033, acc=0.4888888895511627, loss=2.091034412384033
train: epoch 83, loss 0.18419446051120758, acc=0.9179999828338623, loss=0.18419446051120758
test: epoch 83, loss 1.5970191955566406, acc=0.46666666865348816, loss=1.5970191955566406
train: epoch 84, loss 0.1873578429222107, acc=0.9171110987663269, loss=0.1873578429222107
test: epoch 84, loss 1.9340940713882446, acc=0.5055555701255798, loss=1.9340940713882446
train: epoch 85, loss 0.17815952003002167, acc=0.9196110963821411, loss=0.17815952003002167
test: epoch 85, loss 1.9781837463378906, acc=0.46388888359069824, loss=1.9781837463378906
train: epoch 86, loss 0.1798125058412552, acc=0.9202222228050232, loss=0.1798125058412552
test: epoch 86, loss 2.425571918487549, acc=0.42222222685813904, loss=2.425571918487549
train: epoch 87, loss 0.18916857242584229, acc=0.9160555601119995, loss=0.18916857242584229
test: epoch 87, loss 1.5365387201309204, acc=0.5027777552604675, loss=1.5365387201309204
train: epoch 88, loss 0.18103602528572083, acc=0.9203333258628845, loss=0.18103602528572083
test: epoch 88, loss 1.9013980627059937, acc=0.4694444537162781, loss=1.9013980627059937
train: epoch 89, loss 0.18224969506263733, acc=0.9190555810928345, loss=0.18224969506263733
test: epoch 89, loss 2.2928738594055176, acc=0.45277777314186096, loss=2.2928738594055176
train: epoch 90, loss 0.20310033857822418, acc=0.9120555520057678, loss=0.20310033857822418
test: epoch 90, loss 1.7693610191345215, acc=0.46666666865348816, loss=1.7693610191345215
train: epoch 91, loss 0.16523559391498566, acc=0.9243333339691162, loss=0.16523559391498566
test: epoch 91, loss 2.515688180923462, acc=0.4444444477558136, loss=2.515688180923462
train: epoch 92, loss 0.1818140149116516, acc=0.9188888669013977, loss=0.1818140149116516
test: epoch 92, loss 1.5449590682983398, acc=0.5666666626930237, loss=1.5449590682983398
train: epoch 93, loss 0.18550318479537964, acc=0.9183333516120911, loss=0.18550318479537964
test: epoch 93, loss 2.344525098800659, acc=0.4583333432674408, loss=2.344525098800659
train: epoch 94, loss 0.18635769188404083, acc=0.918055534362793, loss=0.18635769188404083
test: epoch 94, loss 2.305797815322876, acc=0.4722222089767456, loss=2.305797815322876
train: epoch 95, loss 0.17669817805290222, acc=0.9196666479110718, loss=0.17669817805290222
test: epoch 95, loss 2.253279447555542, acc=0.48055556416511536, loss=2.253279447555542
train: epoch 96, loss 0.1862916797399521, acc=0.9172777533531189, loss=0.1862916797399521
test: epoch 96, loss 2.275885581970215, acc=0.45277777314186096, loss=2.275885581970215
train: epoch 97, loss 0.18195486068725586, acc=0.9182222485542297, loss=0.18195486068725586
test: epoch 97, loss 1.6520625352859497, acc=0.4722222089767456, loss=1.6520625352859497
train: epoch 98, loss 0.17258426547050476, acc=0.9226666688919067, loss=0.17258426547050476
test: epoch 98, loss 2.541106700897217, acc=0.3638888895511627, loss=2.541106700897217
train: epoch 99, loss 0.15644113719463348, acc=0.9262222051620483, loss=0.15644113719463348
test: epoch 99, loss 2.112666130065918, acc=0.49166667461395264, loss=2.112666130065918
train: epoch 100, loss 0.17036233842372894, acc=0.9230555295944214, loss=0.17036233842372894
test: epoch 100, loss 1.7455811500549316, acc=0.5083333253860474, loss=1.7455811500549316
train: epoch 101, loss 0.19563713669776917, acc=0.9155555367469788, loss=0.19563713669776917
test: epoch 101, loss 1.7726986408233643, acc=0.5249999761581421, loss=1.7726986408233643
train: epoch 102, loss 0.15713271498680115, acc=0.9279444217681885, loss=0.15713271498680115
test: epoch 102, loss 2.7358295917510986, acc=0.5222222208976746, loss=2.7358295917510986
train: epoch 103, loss 0.17206287384033203, acc=0.9223333597183228, loss=0.17206287384033203
test: epoch 103, loss 2.1791415214538574, acc=0.4277777671813965, loss=2.1791415214538574
train: epoch 104, loss 0.17725379765033722, acc=0.9203333258628845, loss=0.17725379765033722
test: epoch 104, loss 2.3438525199890137, acc=0.5333333611488342, loss=2.3438525199890137
train: epoch 105, loss 0.1692175418138504, acc=0.9235555529594421, loss=0.1692175418138504
test: epoch 105, loss 2.4449124336242676, acc=0.4333333373069763, loss=2.4449124336242676
train: epoch 106, loss 0.16523276269435883, acc=0.924833357334137, loss=0.16523276269435883
test: epoch 106, loss 2.2794086933135986, acc=0.5083333253860474, loss=2.2794086933135986
train: epoch 107, loss 0.17209957540035248, acc=0.9216111302375793, loss=0.17209957540035248
test: epoch 107, loss 2.0684430599212646, acc=0.5138888955116272, loss=2.0684430599212646
train: epoch 108, loss 0.16690222918987274, acc=0.9232777953147888, loss=0.16690222918987274
test: epoch 108, loss 2.1226065158843994, acc=0.574999988079071, loss=2.1226065158843994
train: epoch 109, loss 0.16010373830795288, acc=0.925611138343811, loss=0.16010373830795288
test: epoch 109, loss 2.083570718765259, acc=0.5888888835906982, loss=2.083570718765259
train: epoch 110, loss 0.1706809401512146, acc=0.9228333234786987, loss=0.1706809401512146
test: epoch 110, loss 1.726558804512024, acc=0.49444442987442017, loss=1.726558804512024
train: epoch 111, loss 0.16235898435115814, acc=0.9267777800559998, loss=0.16235898435115814
test: epoch 111, loss 1.6419037580490112, acc=0.5333333611488342, loss=1.6419037580490112
train: epoch 112, loss 0.16656054556369781, acc=0.9231111407279968, loss=0.16656054556369781
test: epoch 112, loss 2.1657488346099854, acc=0.4749999940395355, loss=2.1657488346099854
train: epoch 113, loss 0.1655052751302719, acc=0.925166666507721, loss=0.1655052751302719
test: epoch 113, loss 1.857337474822998, acc=0.4861111044883728, loss=1.857337474822998
train: epoch 114, loss 0.1576167494058609, acc=0.9272778034210205, loss=0.1576167494058609
test: epoch 114, loss 2.6209170818328857, acc=0.5027777552604675, loss=2.6209170818328857
train: epoch 115, loss 0.17409764230251312, acc=0.9231111407279968, loss=0.17409764230251312
test: epoch 115, loss 2.572565793991089, acc=0.4749999940395355, loss=2.572565793991089
train: epoch 116, loss 0.15095078945159912, acc=0.9303333163261414, loss=0.15095078945159912
test: epoch 116, loss 2.407482862472534, acc=0.4833333194255829, loss=2.407482862472534
train: epoch 117, loss 0.16855527460575104, acc=0.924833357334137, loss=0.16855527460575104
test: epoch 117, loss 1.880887508392334, acc=0.5555555820465088, loss=1.880887508392334
train: epoch 118, loss 0.15588465332984924, acc=0.9281111359596252, loss=0.15588465332984924
test: epoch 118, loss 1.9853980541229248, acc=0.5305555462837219, loss=1.9853980541229248
train: epoch 119, loss 0.1745486557483673, acc=0.9235000014305115, loss=0.1745486557483673
test: epoch 119, loss 2.242692708969116, acc=0.4861111044883728, loss=2.242692708969116
train: epoch 120, loss 0.15266819298267365, acc=0.9277222156524658, loss=0.15266819298267365
test: epoch 120, loss 1.9880863428115845, acc=0.5694444179534912, loss=1.9880863428115845
train: epoch 121, loss 0.15921816229820251, acc=0.9272222518920898, loss=0.15921816229820251
test: epoch 121, loss 1.8466936349868774, acc=0.5527777671813965, loss=1.8466936349868774
train: epoch 122, loss 0.1578245759010315, acc=0.9267222285270691, loss=0.1578245759010315
test: epoch 122, loss 2.488421678543091, acc=0.5388888716697693, loss=2.488421678543091
train: epoch 123, loss 0.16731075942516327, acc=0.926277756690979, loss=0.16731075942516327
test: epoch 123, loss 1.7087774276733398, acc=0.5555555820465088, loss=1.7087774276733398
train: epoch 124, loss 0.15136884152889252, acc=0.9292222261428833, loss=0.15136884152889252
test: epoch 124, loss 2.6970314979553223, acc=0.47777777910232544, loss=2.6970314979553223
train: epoch 125, loss 0.15179817378520966, acc=0.9295555353164673, loss=0.15179817378520966
test: epoch 125, loss 1.8903286457061768, acc=0.519444465637207, loss=1.8903286457061768
train: epoch 126, loss 0.16167744994163513, acc=0.9275000095367432, loss=0.16167744994163513
test: epoch 126, loss 2.0710999965667725, acc=0.5444444417953491, loss=2.0710999965667725
train: epoch 127, loss 0.1520090401172638, acc=0.9287777543067932, loss=0.1520090401172638
test: epoch 127, loss 1.908164143562317, acc=0.5472221970558167, loss=1.908164143562317
train: epoch 128, loss 0.15199972689151764, acc=0.9287222027778625, loss=0.15199972689151764
test: epoch 128, loss 2.1474807262420654, acc=0.4722222089767456, loss=2.1474807262420654
train: epoch 129, loss 0.15401045978069305, acc=0.9300000071525574, loss=0.15401045978069305
test: epoch 129, loss 2.1090197563171387, acc=0.5361111164093018, loss=2.1090197563171387
train: epoch 130, loss 0.15278922021389008, acc=0.9293333292007446, loss=0.15278922021389008
test: epoch 130, loss 1.9224201440811157, acc=0.5305555462837219, loss=1.9224201440811157
train: epoch 131, loss 0.15097568929195404, acc=0.92894446849823, loss=0.15097568929195404
test: epoch 131, loss 1.6748898029327393, acc=0.6194444298744202, loss=1.6748898029327393
train: epoch 132, loss 0.1520410031080246, acc=0.929888904094696, loss=0.1520410031080246
test: epoch 132, loss 1.9738837480545044, acc=0.5222222208976746, loss=1.9738837480545044
train: epoch 133, loss 0.15630440413951874, acc=0.9304444193840027, loss=0.15630440413951874
test: epoch 133, loss 1.393815517425537, acc=0.6138888597488403, loss=1.393815517425537
train: epoch 134, loss 0.1528066247701645, acc=0.9287222027778625, loss=0.1528066247701645
test: epoch 134, loss 2.046252727508545, acc=0.5166666507720947, loss=2.046252727508545
train: epoch 135, loss 0.15282411873340607, acc=0.9290000200271606, loss=0.15282411873340607
test: epoch 135, loss 2.1508917808532715, acc=0.5777778029441833, loss=2.1508917808532715
train: epoch 136, loss 0.15941068530082703, acc=0.9272778034210205, loss=0.15941068530082703
test: epoch 136, loss 1.6907447576522827, acc=0.550000011920929, loss=1.6907447576522827
train: epoch 137, loss 0.1433710753917694, acc=0.9317222237586975, loss=0.1433710753917694
test: epoch 137, loss 2.118316650390625, acc=0.4611110985279083, loss=2.118316650390625
train: epoch 138, loss 0.1521824449300766, acc=0.930388867855072, loss=0.1521824449300766
test: epoch 138, loss 1.896614670753479, acc=0.5888888835906982, loss=1.896614670753479
train: epoch 139, loss 0.1501512974500656, acc=0.9303333163261414, loss=0.1501512974500656
test: epoch 139, loss 1.7311581373214722, acc=0.5611110925674438, loss=1.7311581373214722
train: epoch 140, loss 0.15469609200954437, acc=0.9288889169692993, loss=0.15469609200954437
test: epoch 140, loss 1.689388394355774, acc=0.5888888835906982, loss=1.689388394355774
train: epoch 141, loss 0.15114618837833405, acc=0.9295555353164673, loss=0.15114618837833405
test: epoch 141, loss 1.9274410009384155, acc=0.5305555462837219, loss=1.9274410009384155
train: epoch 142, loss 0.13509583473205566, acc=0.9346110820770264, loss=0.13509583473205566
test: epoch 142, loss 1.7010231018066406, acc=0.5694444179534912, loss=1.7010231018066406
train: epoch 143, loss 0.14921315014362335, acc=0.9310555458068848, loss=0.14921315014362335
test: epoch 143, loss 2.0394527912139893, acc=0.574999988079071, loss=2.0394527912139893
train: epoch 144, loss 0.14364176988601685, acc=0.9323333501815796, loss=0.14364176988601685
test: epoch 144, loss 1.751437783241272, acc=0.6111111044883728, loss=1.751437783241272
train: epoch 145, loss 0.14939749240875244, acc=0.9301111102104187, loss=0.14939749240875244
test: epoch 145, loss 1.9321794509887695, acc=0.5416666865348816, loss=1.9321794509887695
train: epoch 146, loss 0.13440075516700745, acc=0.9347777962684631, loss=0.13440075516700745
test: epoch 146, loss 2.316288709640503, acc=0.5333333611488342, loss=2.316288709640503
train: epoch 147, loss 0.1416957676410675, acc=0.9322222471237183, loss=0.1416957676410675
test: epoch 147, loss 1.7578095197677612, acc=0.5833333134651184, loss=1.7578095197677612
train: epoch 148, loss 0.14786867797374725, acc=0.9306111335754395, loss=0.14786867797374725
test: epoch 148, loss 1.8634133338928223, acc=0.5305555462837219, loss=1.8634133338928223
train: epoch 149, loss 0.13767121732234955, acc=0.9321110844612122, loss=0.13767121732234955
test: epoch 149, loss 1.966574788093567, acc=0.5694444179534912, loss=1.966574788093567
train: epoch 150, loss 0.13925498723983765, acc=0.933388888835907, loss=0.13925498723983765
test: epoch 150, loss 1.6180142164230347, acc=0.5583333373069763, loss=1.6180142164230347
