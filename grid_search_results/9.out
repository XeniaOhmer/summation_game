# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1", "--temp_decay=0.995", "--one_hot=false", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1504503267, receiver_embed_dim=32, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.481630563735962, acc=0.04788888990879059, loss=3.481630563735962
test: epoch 1, loss 3.5497748851776123, acc=0.04444444552063942, loss=3.5497748851776123
train: epoch 2, loss 3.055375814437866, acc=0.08550000190734863, loss=3.055375814437866
test: epoch 2, loss 2.927079439163208, acc=0.1111111119389534, loss=2.927079439163208
train: epoch 3, loss 2.4318554401397705, acc=0.18505555391311646, loss=2.4318554401397705
test: epoch 3, loss 2.5814881324768066, acc=0.11666666716337204, loss=2.5814881324768066
train: epoch 4, loss 2.0509185791015625, acc=0.24683333933353424, loss=2.0509185791015625
test: epoch 4, loss 2.293168067932129, acc=0.15833333134651184, loss=2.293168067932129
train: epoch 5, loss 1.8798490762710571, acc=0.2955000102519989, loss=1.8798490762710571
test: epoch 5, loss 2.1931333541870117, acc=0.1666666716337204, loss=2.1931333541870117
train: epoch 6, loss 1.7733019590377808, acc=0.31933334469795227, loss=1.7733019590377808
test: epoch 6, loss 2.1367433071136475, acc=0.17222222685813904, loss=2.1367433071136475
train: epoch 7, loss 1.6923383474349976, acc=0.33455556631088257, loss=1.6923383474349976
test: epoch 7, loss 2.086409330368042, acc=0.17777778208255768, loss=2.086409330368042
train: epoch 8, loss 1.6192468404769897, acc=0.362888902425766, loss=1.6192468404769897
test: epoch 8, loss 2.0715532302856445, acc=0.18888889253139496, loss=2.0715532302856445
train: epoch 9, loss 1.5472757816314697, acc=0.3823888897895813, loss=1.5472757816314697
test: epoch 9, loss 2.042022705078125, acc=0.1944444477558136, loss=2.042022705078125
train: epoch 10, loss 1.4882885217666626, acc=0.4043888747692108, loss=1.4882885217666626
test: epoch 10, loss 2.063443660736084, acc=0.19722221791744232, loss=2.063443660736084
train: epoch 11, loss 1.4592915773391724, acc=0.4200555682182312, loss=1.4592915773391724
test: epoch 11, loss 2.0666961669921875, acc=0.20277777314186096, loss=2.0666961669921875
train: epoch 12, loss 1.4090794324874878, acc=0.429111123085022, loss=1.4090794324874878
test: epoch 12, loss 2.0589473247528076, acc=0.20555555820465088, loss=2.0589473247528076
train: epoch 13, loss 1.3835254907608032, acc=0.4424999952316284, loss=1.3835254907608032
test: epoch 13, loss 1.9577847719192505, acc=0.21111111342906952, loss=1.9577847719192505
train: epoch 14, loss 1.3521831035614014, acc=0.4472222328186035, loss=1.3521831035614014
test: epoch 14, loss 1.9695892333984375, acc=0.21388888359069824, loss=1.9695892333984375
train: epoch 15, loss 1.3399133682250977, acc=0.45177778601646423, loss=1.3399133682250977
test: epoch 15, loss 1.932909369468689, acc=0.21944443881511688, loss=1.932909369468689
train: epoch 16, loss 1.3017562627792358, acc=0.46372222900390625, loss=1.3017562627792358
test: epoch 16, loss 1.9456678628921509, acc=0.21388888359069824, loss=1.9456678628921509
train: epoch 17, loss 1.2797908782958984, acc=0.4664444327354431, loss=1.2797908782958984
test: epoch 17, loss 1.939011573791504, acc=0.22777777910232544, loss=1.939011573791504
train: epoch 18, loss 1.2632700204849243, acc=0.476500004529953, loss=1.2632700204849243
test: epoch 18, loss 1.9314663410186768, acc=0.23333333432674408, loss=1.9314663410186768
train: epoch 19, loss 1.2424582242965698, acc=0.4877222180366516, loss=1.2424582242965698
test: epoch 19, loss 1.8705638647079468, acc=0.21944443881511688, loss=1.8705638647079468
train: epoch 20, loss 1.2273766994476318, acc=0.48588889837265015, loss=1.2273766994476318
test: epoch 20, loss 1.872314453125, acc=0.24444444477558136, loss=1.872314453125
train: epoch 21, loss 1.2169126272201538, acc=0.49477776885032654, loss=1.2169126272201538
test: epoch 21, loss 1.826515793800354, acc=0.25555557012557983, loss=1.826515793800354
train: epoch 22, loss 1.1821603775024414, acc=0.504444420337677, loss=1.1821603775024414
test: epoch 22, loss 1.8134270906448364, acc=0.25833332538604736, loss=1.8134270906448364
train: epoch 23, loss 1.1640915870666504, acc=0.5127778053283691, loss=1.1640915870666504
test: epoch 23, loss 1.7847014665603638, acc=0.24722221493721008, loss=1.7847014665603638
train: epoch 24, loss 1.1666734218597412, acc=0.5110555291175842, loss=1.1666734218597412
test: epoch 24, loss 1.7675747871398926, acc=0.24722221493721008, loss=1.7675747871398926
train: epoch 25, loss 1.1422094106674194, acc=0.5222777724266052, loss=1.1422094106674194
test: epoch 25, loss 1.6931301355361938, acc=0.2638888955116272, loss=1.6931301355361938
train: epoch 26, loss 1.1170626878738403, acc=0.5319444537162781, loss=1.1170626878738403
test: epoch 26, loss 1.6861735582351685, acc=0.2666666805744171, loss=1.6861735582351685
train: epoch 27, loss 1.1076596975326538, acc=0.5320000052452087, loss=1.1076596975326538
test: epoch 27, loss 1.7400482892990112, acc=0.26944443583488464, loss=1.7400482892990112
train: epoch 28, loss 1.0979342460632324, acc=0.5353333353996277, loss=1.0979342460632324
test: epoch 28, loss 1.7379485368728638, acc=0.2777777910232544, loss=1.7379485368728638
train: epoch 29, loss 1.085096836090088, acc=0.5434444546699524, loss=1.085096836090088
test: epoch 29, loss 1.7825641632080078, acc=0.2805555462837219, loss=1.7825641632080078
train: epoch 30, loss 1.0848041772842407, acc=0.5364999771118164, loss=1.0848041772842407
test: epoch 30, loss 1.6619805097579956, acc=0.2750000059604645, loss=1.6619805097579956
train: epoch 31, loss 1.071767807006836, acc=0.5492222309112549, loss=1.071767807006836
test: epoch 31, loss 1.7256512641906738, acc=0.2805555462837219, loss=1.7256512641906738
train: epoch 32, loss 1.060624361038208, acc=0.5510555505752563, loss=1.060624361038208
test: epoch 32, loss 1.7306369543075562, acc=0.2666666805744171, loss=1.7306369543075562
train: epoch 33, loss 1.047763705253601, acc=0.5512222051620483, loss=1.047763705253601
test: epoch 33, loss 1.7165164947509766, acc=0.2805555462837219, loss=1.7165164947509766
train: epoch 34, loss 1.0281585454940796, acc=0.5562222003936768, loss=1.0281585454940796
test: epoch 34, loss 1.6345402002334595, acc=0.2916666567325592, loss=1.6345402002334595
train: epoch 35, loss 1.0367727279663086, acc=0.5562777519226074, loss=1.0367727279663086
test: epoch 35, loss 1.6771130561828613, acc=0.28333333134651184, loss=1.6771130561828613
train: epoch 36, loss 1.0221399068832397, acc=0.5591111183166504, loss=1.0221399068832397
test: epoch 36, loss 1.7242040634155273, acc=0.2777777910232544, loss=1.7242040634155273
train: epoch 37, loss 1.014884352684021, acc=0.5605555772781372, loss=1.014884352684021
test: epoch 37, loss 1.6637773513793945, acc=0.2888889014720917, loss=1.6637773513793945
train: epoch 38, loss 1.0218639373779297, acc=0.5598333477973938, loss=1.0218639373779297
test: epoch 38, loss 1.7148971557617188, acc=0.2944444417953491, loss=1.7148971557617188
train: epoch 39, loss 1.0178898572921753, acc=0.5636666417121887, loss=1.0178898572921753
test: epoch 39, loss 1.7774391174316406, acc=0.28611111640930176, loss=1.7774391174316406
train: epoch 40, loss 0.9979190826416016, acc=0.5712222456932068, loss=0.9979190826416016
test: epoch 40, loss 1.6700196266174316, acc=0.28611111640930176, loss=1.6700196266174316
train: epoch 41, loss 0.9994838833808899, acc=0.5669999718666077, loss=0.9994838833808899
test: epoch 41, loss 1.6967703104019165, acc=0.2944444417953491, loss=1.6967703104019165
train: epoch 42, loss 0.9921925067901611, acc=0.569944441318512, loss=0.9921925067901611
test: epoch 42, loss 1.6870745420455933, acc=0.29722222685813904, loss=1.6870745420455933
train: epoch 43, loss 0.986696183681488, acc=0.5725555419921875, loss=0.986696183681488
test: epoch 43, loss 1.7372355461120605, acc=0.30000001192092896, loss=1.7372355461120605
train: epoch 44, loss 0.9852795004844666, acc=0.5692222118377686, loss=0.9852795004844666
test: epoch 44, loss 1.7420856952667236, acc=0.2944444417953491, loss=1.7420856952667236
train: epoch 45, loss 0.9752615094184875, acc=0.570888876914978, loss=0.9752615094184875
test: epoch 45, loss 1.7392054796218872, acc=0.29722222685813904, loss=1.7392054796218872
train: epoch 46, loss 0.9699646234512329, acc=0.5764999985694885, loss=0.9699646234512329
test: epoch 46, loss 1.7256863117218018, acc=0.2944444417953491, loss=1.7256863117218018
train: epoch 47, loss 0.9796974062919617, acc=0.5755000114440918, loss=0.9796974062919617
test: epoch 47, loss 1.7182332277297974, acc=0.2944444417953491, loss=1.7182332277297974
train: epoch 48, loss 0.979124128818512, acc=0.5717777609825134, loss=0.979124128818512
test: epoch 48, loss 1.6622637510299683, acc=0.29722222685813904, loss=1.6622637510299683
train: epoch 49, loss 0.9633283019065857, acc=0.5797222256660461, loss=0.9633283019065857
test: epoch 49, loss 1.658486247062683, acc=0.3083333373069763, loss=1.658486247062683
train: epoch 50, loss 0.968856692314148, acc=0.5766666531562805, loss=0.968856692314148
test: epoch 50, loss 1.7051849365234375, acc=0.29722222685813904, loss=1.7051849365234375
train: epoch 51, loss 0.957820475101471, acc=0.578000009059906, loss=0.957820475101471
test: epoch 51, loss 1.6521148681640625, acc=0.31111112236976624, loss=1.6521148681640625
train: epoch 52, loss 0.9590163826942444, acc=0.5764444470405579, loss=0.9590163826942444
test: epoch 52, loss 1.6855756044387817, acc=0.31388887763023376, loss=1.6855756044387817
train: epoch 53, loss 0.9579246640205383, acc=0.5838888883590698, loss=0.9579246640205383
test: epoch 53, loss 1.6798628568649292, acc=0.31111112236976624, loss=1.6798628568649292
train: epoch 54, loss 0.9486364126205444, acc=0.5788333415985107, loss=0.9486364126205444
test: epoch 54, loss 1.6123543977737427, acc=0.31388887763023376, loss=1.6123543977737427
train: epoch 55, loss 0.9451599717140198, acc=0.5772777795791626, loss=0.9451599717140198
test: epoch 55, loss 1.7017449140548706, acc=0.31111112236976624, loss=1.7017449140548706
train: epoch 56, loss 0.9322104454040527, acc=0.5821666717529297, loss=0.9322104454040527
test: epoch 56, loss 1.6646698713302612, acc=0.3166666626930237, loss=1.6646698713302612
train: epoch 57, loss 0.933596670627594, acc=0.586388885974884, loss=0.933596670627594
test: epoch 57, loss 1.6857439279556274, acc=0.31388887763023376, loss=1.6857439279556274
train: epoch 58, loss 0.9456765651702881, acc=0.5830555558204651, loss=0.9456765651702881
test: epoch 58, loss 1.6743491888046265, acc=0.3166666626930237, loss=1.6743491888046265
train: epoch 59, loss 0.9205255508422852, acc=0.5855555534362793, loss=0.9205255508422852
test: epoch 59, loss 1.6486200094223022, acc=0.3166666626930237, loss=1.6486200094223022
train: epoch 60, loss 0.9436895847320557, acc=0.582111120223999, loss=0.9436895847320557
test: epoch 60, loss 1.6485393047332764, acc=0.31388887763023376, loss=1.6485393047332764
train: epoch 61, loss 0.92063969373703, acc=0.5836111307144165, loss=0.92063969373703
test: epoch 61, loss 1.7108256816864014, acc=0.3166666626930237, loss=1.7108256816864014
train: epoch 62, loss 0.9124974012374878, acc=0.5882777571678162, loss=0.9124974012374878
test: epoch 62, loss 1.7320343255996704, acc=0.3194444477558136, loss=1.7320343255996704
train: epoch 63, loss 0.9208401441574097, acc=0.5868333578109741, loss=0.9208401441574097
test: epoch 63, loss 1.6623787879943848, acc=0.3166666626930237, loss=1.6623787879943848
train: epoch 64, loss 0.9126103520393372, acc=0.5874999761581421, loss=0.9126103520393372
test: epoch 64, loss 1.6788870096206665, acc=0.3083333373069763, loss=1.6788870096206665
train: epoch 65, loss 0.9188700914382935, acc=0.5863333344459534, loss=0.9188700914382935
test: epoch 65, loss 1.6835734844207764, acc=0.3194444477558136, loss=1.6835734844207764
train: epoch 66, loss 0.9192153811454773, acc=0.5868333578109741, loss=0.9192153811454773
test: epoch 66, loss 1.6587165594100952, acc=0.32499998807907104, loss=1.6587165594100952
train: epoch 67, loss 0.8962855935096741, acc=0.5931110978126526, loss=0.8962855935096741
test: epoch 67, loss 1.7133504152297974, acc=0.32499998807907104, loss=1.7133504152297974
train: epoch 68, loss 0.9034153819084167, acc=0.5908889174461365, loss=0.9034153819084167
test: epoch 68, loss 1.6935741901397705, acc=0.32499998807907104, loss=1.6935741901397705
train: epoch 69, loss 0.8968581557273865, acc=0.5947777628898621, loss=0.8968581557273865
test: epoch 69, loss 1.768218755722046, acc=0.32499998807907104, loss=1.768218755722046
train: epoch 70, loss 0.9029911756515503, acc=0.5902222394943237, loss=0.9029911756515503
test: epoch 70, loss 1.7251116037368774, acc=0.3194444477558136, loss=1.7251116037368774
train: epoch 71, loss 0.8960394859313965, acc=0.5923333168029785, loss=0.8960394859313965
test: epoch 71, loss 1.7918627262115479, acc=0.3333333432674408, loss=1.7918627262115479
train: epoch 72, loss 0.8933197259902954, acc=0.5913333296775818, loss=0.8933197259902954
test: epoch 72, loss 1.7107735872268677, acc=0.32499998807907104, loss=1.7107735872268677
train: epoch 73, loss 0.8828072547912598, acc=0.5967222452163696, loss=0.8828072547912598
test: epoch 73, loss 1.6945956945419312, acc=0.32499998807907104, loss=1.6945956945419312
train: epoch 74, loss 0.8809105157852173, acc=0.5964999794960022, loss=0.8809105157852173
test: epoch 74, loss 1.744592308998108, acc=0.32777777314186096, loss=1.744592308998108
train: epoch 75, loss 0.8806969523429871, acc=0.5950000286102295, loss=0.8806969523429871
test: epoch 75, loss 1.6646525859832764, acc=0.32499998807907104, loss=1.6646525859832764
train: epoch 76, loss 0.8828508853912354, acc=0.5991111397743225, loss=0.8828508853912354
test: epoch 76, loss 1.8153636455535889, acc=0.32499998807907104, loss=1.8153636455535889
train: epoch 77, loss 0.8674640655517578, acc=0.5999444723129272, loss=0.8674640655517578
test: epoch 77, loss 1.6864088773727417, acc=0.3305555582046509, loss=1.6864088773727417
train: epoch 78, loss 0.883115291595459, acc=0.5978888869285583, loss=0.883115291595459
test: epoch 78, loss 1.6975232362747192, acc=0.32777777314186096, loss=1.6975232362747192
train: epoch 79, loss 0.8763198852539062, acc=0.6000555753707886, loss=0.8763198852539062
test: epoch 79, loss 1.7267009019851685, acc=0.32499998807907104, loss=1.7267009019851685
train: epoch 80, loss 0.8804635405540466, acc=0.597777783870697, loss=0.8804635405540466
test: epoch 80, loss 1.8013273477554321, acc=0.32777777314186096, loss=1.8013273477554321
train: epoch 81, loss 0.8583511710166931, acc=0.6077777743339539, loss=0.8583511710166931
test: epoch 81, loss 1.6986854076385498, acc=0.3361110985279083, loss=1.6986854076385498
train: epoch 82, loss 0.8717088103294373, acc=0.5963888764381409, loss=0.8717088103294373
test: epoch 82, loss 1.7105032205581665, acc=0.32777777314186096, loss=1.7105032205581665
train: epoch 83, loss 0.8644042015075684, acc=0.5990555286407471, loss=0.8644042015075684
test: epoch 83, loss 1.7413465976715088, acc=0.3166666626930237, loss=1.7413465976715088
train: epoch 84, loss 0.8656107187271118, acc=0.6006110906600952, loss=0.8656107187271118
test: epoch 84, loss 1.6823055744171143, acc=0.3305555582046509, loss=1.6823055744171143
train: epoch 85, loss 0.8569564819335938, acc=0.5997777581214905, loss=0.8569564819335938
test: epoch 85, loss 1.7192823886871338, acc=0.3222222328186035, loss=1.7192823886871338
train: epoch 86, loss 0.8616664409637451, acc=0.5997222065925598, loss=0.8616664409637451
test: epoch 86, loss 1.850156307220459, acc=0.3333333432674408, loss=1.850156307220459
train: epoch 87, loss 0.8593944907188416, acc=0.6031110882759094, loss=0.8593944907188416
test: epoch 87, loss 1.6231865882873535, acc=0.3333333432674408, loss=1.6231865882873535
train: epoch 88, loss 0.8552916646003723, acc=0.602222204208374, loss=0.8552916646003723
test: epoch 88, loss 1.7820119857788086, acc=0.32499998807907104, loss=1.7820119857788086
train: epoch 89, loss 0.8654350638389587, acc=0.6023333072662354, loss=0.8654350638389587
test: epoch 89, loss 1.7818561792373657, acc=0.3305555582046509, loss=1.7818561792373657
train: epoch 90, loss 0.8551352024078369, acc=0.6058333516120911, loss=0.8551352024078369
test: epoch 90, loss 1.7175832986831665, acc=0.33888888359069824, loss=1.7175832986831665
train: epoch 91, loss 0.8454108834266663, acc=0.6059444546699524, loss=0.8454108834266663
test: epoch 91, loss 1.7516664266586304, acc=0.3333333432674408, loss=1.7516664266586304
train: epoch 92, loss 0.8462762832641602, acc=0.6078888773918152, loss=0.8462762832641602
test: epoch 92, loss 1.6739921569824219, acc=0.3305555582046509, loss=1.6739921569824219
train: epoch 93, loss 0.8461365699768066, acc=0.6092222332954407, loss=0.8461365699768066
test: epoch 93, loss 1.734354019165039, acc=0.34166666865348816, loss=1.734354019165039
train: epoch 94, loss 0.8389891386032104, acc=0.609000027179718, loss=0.8389891386032104
test: epoch 94, loss 1.814375400543213, acc=0.3333333432674408, loss=1.814375400543213
train: epoch 95, loss 0.8502184748649597, acc=0.6060555577278137, loss=0.8502184748649597
test: epoch 95, loss 1.7551028728485107, acc=0.3333333432674408, loss=1.7551028728485107
train: epoch 96, loss 0.8388514518737793, acc=0.6085555553436279, loss=0.8388514518737793
test: epoch 96, loss 1.7890381813049316, acc=0.34166666865348816, loss=1.7890381813049316
train: epoch 97, loss 0.8435426354408264, acc=0.6060555577278137, loss=0.8435426354408264
test: epoch 97, loss 1.8841787576675415, acc=0.3361110985279083, loss=1.8841787576675415
train: epoch 98, loss 0.845881998538971, acc=0.6075000166893005, loss=0.845881998538971
test: epoch 98, loss 1.802315592765808, acc=0.3444444537162781, loss=1.802315592765808
train: epoch 99, loss 0.8358322978019714, acc=0.6083889007568359, loss=0.8358322978019714
test: epoch 99, loss 1.7677948474884033, acc=0.34166666865348816, loss=1.7677948474884033
train: epoch 100, loss 0.8397139310836792, acc=0.6101666688919067, loss=0.8397139310836792
test: epoch 100, loss 1.7100270986557007, acc=0.3361110985279083, loss=1.7100270986557007
train: epoch 101, loss 0.8329327702522278, acc=0.609499990940094, loss=0.8329327702522278
test: epoch 101, loss 1.7646677494049072, acc=0.3444444537162781, loss=1.7646677494049072
train: epoch 102, loss 0.8300489783287048, acc=0.6104999780654907, loss=0.8300489783287048
test: epoch 102, loss 1.773193120956421, acc=0.33888888359069824, loss=1.773193120956421
train: epoch 103, loss 0.8299937844276428, acc=0.6120555400848389, loss=0.8299937844276428
test: epoch 103, loss 1.8103636503219604, acc=0.33888888359069824, loss=1.8103636503219604
train: epoch 104, loss 0.8385924100875854, acc=0.608222246170044, loss=0.8385924100875854
test: epoch 104, loss 1.6915571689605713, acc=0.3444444537162781, loss=1.6915571689605713
train: epoch 105, loss 0.8256227374076843, acc=0.6129444241523743, loss=0.8256227374076843
test: epoch 105, loss 1.8237888813018799, acc=0.3472222089767456, loss=1.8237888813018799
train: epoch 106, loss 0.8184798955917358, acc=0.616611123085022, loss=0.8184798955917358
test: epoch 106, loss 1.8214339017868042, acc=0.3361110985279083, loss=1.8214339017868042
train: epoch 107, loss 0.8222100138664246, acc=0.6140555739402771, loss=0.8222100138664246
test: epoch 107, loss 1.7644858360290527, acc=0.3472222089767456, loss=1.7644858360290527
train: epoch 108, loss 0.8304473757743835, acc=0.613611102104187, loss=0.8304473757743835
test: epoch 108, loss 1.9022783041000366, acc=0.3444444537162781, loss=1.9022783041000366
train: epoch 109, loss 0.8108205199241638, acc=0.6201666593551636, loss=0.8108205199241638
test: epoch 109, loss 1.8037689924240112, acc=0.35277777910232544, loss=1.8037689924240112
train: epoch 110, loss 0.8055551052093506, acc=0.6203888654708862, loss=0.8055551052093506
test: epoch 110, loss 1.7303581237792969, acc=0.3472222089767456, loss=1.7303581237792969
train: epoch 111, loss 0.8189876675605774, acc=0.6196110844612122, loss=0.8189876675605774
test: epoch 111, loss 1.7829407453536987, acc=0.3472222089767456, loss=1.7829407453536987
train: epoch 112, loss 0.8156791925430298, acc=0.6157777905464172, loss=0.8156791925430298
test: epoch 112, loss 1.68453848361969, acc=0.3472222089767456, loss=1.68453848361969
train: epoch 113, loss 0.8243980407714844, acc=0.6152222156524658, loss=0.8243980407714844
test: epoch 113, loss 1.7978712320327759, acc=0.35277777910232544, loss=1.7978712320327759
train: epoch 114, loss 0.8037126064300537, acc=0.6213333606719971, loss=0.8037126064300537
test: epoch 114, loss 1.8886078596115112, acc=0.3472222089767456, loss=1.8886078596115112
train: epoch 115, loss 0.8207108974456787, acc=0.617222249507904, loss=0.8207108974456787
test: epoch 115, loss 1.7383179664611816, acc=0.3472222089767456, loss=1.7383179664611816
train: epoch 116, loss 0.8125829696655273, acc=0.6194444298744202, loss=0.8125829696655273
test: epoch 116, loss 1.6406301259994507, acc=0.3472222089767456, loss=1.6406301259994507
train: epoch 117, loss 0.8065659403800964, acc=0.6255555748939514, loss=0.8065659403800964
test: epoch 117, loss 1.878380537033081, acc=0.3472222089767456, loss=1.878380537033081
train: epoch 118, loss 0.7988701462745667, acc=0.6242777705192566, loss=0.7988701462745667
test: epoch 118, loss 1.7299150228500366, acc=0.3472222089767456, loss=1.7299150228500366
train: epoch 119, loss 0.7958661317825317, acc=0.6246111392974854, loss=0.7958661317825317
test: epoch 119, loss 1.8664368391036987, acc=0.3444444537162781, loss=1.8664368391036987
train: epoch 120, loss 0.8104845285415649, acc=0.6243333220481873, loss=0.8104845285415649
test: epoch 120, loss 1.7843875885009766, acc=0.3472222089767456, loss=1.7843875885009766
train: epoch 121, loss 0.8009461164474487, acc=0.6203333139419556, loss=0.8009461164474487
test: epoch 121, loss 1.7966880798339844, acc=0.3444444537162781, loss=1.7966880798339844
train: epoch 122, loss 0.8104017972946167, acc=0.6217777729034424, loss=0.8104017972946167
test: epoch 122, loss 1.7733447551727295, acc=0.3499999940395355, loss=1.7733447551727295
train: epoch 123, loss 0.8075267672538757, acc=0.6203333139419556, loss=0.8075267672538757
test: epoch 123, loss 1.5963454246520996, acc=0.35555556416511536, loss=1.5963454246520996
train: epoch 124, loss 0.7972257733345032, acc=0.6194444298744202, loss=0.7972257733345032
test: epoch 124, loss 1.7654350996017456, acc=0.3499999940395355, loss=1.7654350996017456
train: epoch 125, loss 0.7955906987190247, acc=0.6225000023841858, loss=0.7955906987190247
test: epoch 125, loss 1.7958564758300781, acc=0.3499999940395355, loss=1.7958564758300781
train: epoch 126, loss 0.79598069190979, acc=0.6223888993263245, loss=0.79598069190979
test: epoch 126, loss 1.722744107246399, acc=0.35277777910232544, loss=1.722744107246399
train: epoch 127, loss 0.7919458150863647, acc=0.6279444694519043, loss=0.7919458150863647
test: epoch 127, loss 1.7114742994308472, acc=0.35555556416511536, loss=1.7114742994308472
train: epoch 128, loss 0.7966223955154419, acc=0.6301666498184204, loss=0.7966223955154419
test: epoch 128, loss 1.7953875064849854, acc=0.3611111044883728, loss=1.7953875064849854
train: epoch 129, loss 0.7952057123184204, acc=0.6297222375869751, loss=0.7952057123184204
test: epoch 129, loss 1.7767236232757568, acc=0.35277777910232544, loss=1.7767236232757568
train: epoch 130, loss 0.7999553680419922, acc=0.6256666779518127, loss=0.7999553680419922
test: epoch 130, loss 1.7986087799072266, acc=0.35555556416511536, loss=1.7986087799072266
train: epoch 131, loss 0.7977237701416016, acc=0.6230000257492065, loss=0.7977237701416016
test: epoch 131, loss 1.6833313703536987, acc=0.35277777910232544, loss=1.6833313703536987
train: epoch 132, loss 0.7892391681671143, acc=0.6304444670677185, loss=0.7892391681671143
test: epoch 132, loss 1.8771523237228394, acc=0.35277777910232544, loss=1.8771523237228394
train: epoch 133, loss 0.7993478178977966, acc=0.6271111369132996, loss=0.7993478178977966
test: epoch 133, loss 1.7878960371017456, acc=0.35277777910232544, loss=1.7878960371017456
train: epoch 134, loss 0.7932414412498474, acc=0.6272777915000916, loss=0.7932414412498474
test: epoch 134, loss 1.6886186599731445, acc=0.3444444537162781, loss=1.6886186599731445
train: epoch 135, loss 0.7848074436187744, acc=0.6284999847412109, loss=0.7848074436187744
test: epoch 135, loss 1.7780463695526123, acc=0.35277777910232544, loss=1.7780463695526123
train: epoch 136, loss 0.7799127101898193, acc=0.6309444308280945, loss=0.7799127101898193
test: epoch 136, loss 1.6981018781661987, acc=0.35555556416511536, loss=1.6981018781661987
train: epoch 137, loss 0.7866488695144653, acc=0.6274444460868835, loss=0.7866488695144653
test: epoch 137, loss 1.8146321773529053, acc=0.35277777910232544, loss=1.8146321773529053
train: epoch 138, loss 0.7842741012573242, acc=0.6326666474342346, loss=0.7842741012573242
test: epoch 138, loss 1.8039882183074951, acc=0.35277777910232544, loss=1.8039882183074951
train: epoch 139, loss 0.7908354997634888, acc=0.6292222142219543, loss=0.7908354997634888
test: epoch 139, loss 1.8235365152359009, acc=0.35277777910232544, loss=1.8235365152359009
train: epoch 140, loss 0.7836344242095947, acc=0.6284444332122803, loss=0.7836344242095947
test: epoch 140, loss 1.695284366607666, acc=0.35277777910232544, loss=1.695284366607666
train: epoch 141, loss 0.7934371829032898, acc=0.6258888840675354, loss=0.7934371829032898
test: epoch 141, loss 1.7760816812515259, acc=0.35277777910232544, loss=1.7760816812515259
train: epoch 142, loss 0.7834230661392212, acc=0.6271666884422302, loss=0.7834230661392212
test: epoch 142, loss 1.6968750953674316, acc=0.35277777910232544, loss=1.6968750953674316
train: epoch 143, loss 0.7840120196342468, acc=0.6303333044052124, loss=0.7840120196342468
test: epoch 143, loss 1.8760366439819336, acc=0.35277777910232544, loss=1.8760366439819336
train: epoch 144, loss 0.7783129811286926, acc=0.6292222142219543, loss=0.7783129811286926
test: epoch 144, loss 1.9291630983352661, acc=0.35277777910232544, loss=1.9291630983352661
train: epoch 145, loss 0.7798559069633484, acc=0.6272777915000916, loss=0.7798559069633484
test: epoch 145, loss 1.8179103136062622, acc=0.35277777910232544, loss=1.8179103136062622
train: epoch 146, loss 0.7837945818901062, acc=0.6341666579246521, loss=0.7837945818901062
test: epoch 146, loss 1.7920925617218018, acc=0.3499999940395355, loss=1.7920925617218018
train: epoch 147, loss 0.7877082228660583, acc=0.6296666860580444, loss=0.7877082228660583
test: epoch 147, loss 1.7020243406295776, acc=0.35277777910232544, loss=1.7020243406295776
train: epoch 148, loss 0.7750405669212341, acc=0.6318333148956299, loss=0.7750405669212341
test: epoch 148, loss 2.0648281574249268, acc=0.35277777910232544, loss=2.0648281574249268
train: epoch 149, loss 0.7806346416473389, acc=0.6312777996063232, loss=0.7806346416473389
test: epoch 149, loss 1.7875360250473022, acc=0.3583333194255829, loss=1.7875360250473022
train: epoch 150, loss 0.7877070307731628, acc=0.6280555725097656, loss=0.7877070307731628
test: epoch 150, loss 1.7966485023498535, acc=0.35277777910232544, loss=1.7966485023498535
