# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=true", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=697039522, receiver_embed_dim=32, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.9886956214904785, acc=0.08638888597488403, loss=2.9886956214904785
test: epoch 1, loss 4.344715595245361, acc=0.10555555671453476, loss=4.344715595245361
train: epoch 2, loss 1.9447468519210815, acc=0.234333336353302, loss=1.9447468519210815
test: epoch 2, loss 5.037929058074951, acc=0.10833333432674408, loss=5.037929058074951
train: epoch 3, loss 1.593318223953247, acc=0.35527777671813965, loss=1.593318223953247
test: epoch 3, loss 4.531030178070068, acc=0.1805555522441864, loss=4.531030178070068
train: epoch 4, loss 1.2398934364318848, acc=0.5090000033378601, loss=1.2398934364318848
test: epoch 4, loss 4.555205821990967, acc=0.17499999701976776, loss=4.555205821990967
train: epoch 5, loss 0.989509105682373, acc=0.608222246170044, loss=0.989509105682373
test: epoch 5, loss 3.153980255126953, acc=0.2805555462837219, loss=3.153980255126953
train: epoch 6, loss 0.8388465642929077, acc=0.668666660785675, loss=0.8388465642929077
test: epoch 6, loss 3.112260580062866, acc=0.2361111044883728, loss=3.112260580062866
train: epoch 7, loss 0.7317801117897034, acc=0.7123333215713501, loss=0.7317801117897034
test: epoch 7, loss 2.779968023300171, acc=0.2944444417953491, loss=2.779968023300171
train: epoch 8, loss 0.6402427554130554, acc=0.7556111216545105, loss=0.6402427554130554
test: epoch 8, loss 2.8050334453582764, acc=0.2888889014720917, loss=2.8050334453582764
train: epoch 9, loss 0.5716685056686401, acc=0.7872777581214905, loss=0.5716685056686401
test: epoch 9, loss 2.7273616790771484, acc=0.31388887763023376, loss=2.7273616790771484
train: epoch 10, loss 0.5282976031303406, acc=0.8036110997200012, loss=0.5282976031303406
test: epoch 10, loss 2.520853281021118, acc=0.3055555522441864, loss=2.520853281021118
train: epoch 11, loss 0.4865194261074066, acc=0.8233888745307922, loss=0.4865194261074066
test: epoch 11, loss 2.90383243560791, acc=0.3166666626930237, loss=2.90383243560791
train: epoch 12, loss 0.4377155601978302, acc=0.8401111364364624, loss=0.4377155601978302
test: epoch 12, loss 2.894848108291626, acc=0.25833332538604736, loss=2.894848108291626
train: epoch 13, loss 0.41445794701576233, acc=0.8491666913032532, loss=0.41445794701576233
test: epoch 13, loss 2.457812786102295, acc=0.3611111044883728, loss=2.457812786102295
train: epoch 14, loss 0.3625398874282837, acc=0.8678333163261414, loss=0.3625398874282837
test: epoch 14, loss 2.202049970626831, acc=0.3611111044883728, loss=2.202049970626831
train: epoch 15, loss 0.34947407245635986, acc=0.8723888993263245, loss=0.34947407245635986
test: epoch 15, loss 2.4145114421844482, acc=0.375, loss=2.4145114421844482
train: epoch 16, loss 0.3438120186328888, acc=0.8815000057220459, loss=0.3438120186328888
test: epoch 16, loss 2.516127109527588, acc=0.3166666626930237, loss=2.516127109527588
train: epoch 17, loss 0.323520690202713, acc=0.8899999856948853, loss=0.323520690202713
test: epoch 17, loss 2.5713515281677246, acc=0.2916666567325592, loss=2.5713515281677246
train: epoch 18, loss 0.2949243485927582, acc=0.8995555639266968, loss=0.2949243485927582
test: epoch 18, loss 2.765645980834961, acc=0.35555556416511536, loss=2.765645980834961
train: epoch 19, loss 0.2836250364780426, acc=0.901888906955719, loss=0.2836250364780426
test: epoch 19, loss 2.257753372192383, acc=0.2916666567325592, loss=2.257753372192383
train: epoch 20, loss 0.2633436322212219, acc=0.9121111035346985, loss=0.2633436322212219
test: epoch 20, loss 2.673208475112915, acc=0.3638888895511627, loss=2.673208475112915
train: epoch 21, loss 0.26021885871887207, acc=0.9127777814865112, loss=0.26021885871887207
test: epoch 21, loss 2.387516736984253, acc=0.3472222089767456, loss=2.387516736984253
train: epoch 22, loss 0.2534249722957611, acc=0.9158889055252075, loss=0.2534249722957611
test: epoch 22, loss 2.1347496509552, acc=0.40833333134651184, loss=2.1347496509552
train: epoch 23, loss 0.24281039834022522, acc=0.9210000038146973, loss=0.24281039834022522
test: epoch 23, loss 2.5410468578338623, acc=0.3333333432674408, loss=2.5410468578338623
train: epoch 24, loss 0.23012474179267883, acc=0.9248889088630676, loss=0.23012474179267883
test: epoch 24, loss 2.174485206604004, acc=0.35277777910232544, loss=2.174485206604004
train: epoch 25, loss 0.22200588881969452, acc=0.9267777800559998, loss=0.22200588881969452
test: epoch 25, loss 1.7903330326080322, acc=0.3333333432674408, loss=1.7903330326080322
train: epoch 26, loss 0.21086934208869934, acc=0.9288889169692993, loss=0.21086934208869934
test: epoch 26, loss 2.0742011070251465, acc=0.39722222089767456, loss=2.0742011070251465
train: epoch 27, loss 0.2155996412038803, acc=0.9281666874885559, loss=0.2155996412038803
test: epoch 27, loss 1.9851431846618652, acc=0.4277777671813965, loss=1.9851431846618652
train: epoch 28, loss 0.1925535500049591, acc=0.9377777576446533, loss=0.1925535500049591
test: epoch 28, loss 1.989236831665039, acc=0.3722222149372101, loss=1.989236831665039
train: epoch 29, loss 0.21233122050762177, acc=0.9307222366333008, loss=0.21233122050762177
test: epoch 29, loss 1.9039905071258545, acc=0.4138889014720917, loss=1.9039905071258545
train: epoch 30, loss 0.20866431295871735, acc=0.9308888912200928, loss=0.20866431295871735
test: epoch 30, loss 2.3131179809570312, acc=0.3444444537162781, loss=2.3131179809570312
train: epoch 31, loss 0.1894751489162445, acc=0.9403889179229736, loss=0.1894751489162445
test: epoch 31, loss 2.3460521697998047, acc=0.35277777910232544, loss=2.3460521697998047
train: epoch 32, loss 0.19847597181797028, acc=0.9375555515289307, loss=0.19847597181797028
test: epoch 32, loss 1.8490740060806274, acc=0.49444442987442017, loss=1.8490740060806274
train: epoch 33, loss 0.17223715782165527, acc=0.9454444646835327, loss=0.17223715782165527
test: epoch 33, loss 2.111379623413086, acc=0.42500001192092896, loss=2.111379623413086
train: epoch 34, loss 0.1763400137424469, acc=0.9456111192703247, loss=0.1763400137424469
test: epoch 34, loss 2.152880907058716, acc=0.3888888955116272, loss=2.152880907058716
train: epoch 35, loss 0.16914722323417664, acc=0.94605553150177, loss=0.16914722323417664
test: epoch 35, loss 2.038818597793579, acc=0.45277777314186096, loss=2.038818597793579
train: epoch 36, loss 0.16971588134765625, acc=0.9461110830307007, loss=0.16971588134765625
test: epoch 36, loss 1.856223225593567, acc=0.4416666626930237, loss=1.856223225593567
train: epoch 37, loss 0.17530125379562378, acc=0.9434444308280945, loss=0.17530125379562378
test: epoch 37, loss 1.9783128499984741, acc=0.4583333432674408, loss=1.9783128499984741
train: epoch 38, loss 0.1739715337753296, acc=0.9424444437026978, loss=0.1739715337753296
test: epoch 38, loss 1.9457749128341675, acc=0.4416666626930237, loss=1.9457749128341675
train: epoch 39, loss 0.15907523036003113, acc=0.949055552482605, loss=0.15907523036003113
test: epoch 39, loss 2.0065858364105225, acc=0.46388888359069824, loss=2.0065858364105225
train: epoch 40, loss 0.1730813980102539, acc=0.9438889026641846, loss=0.1730813980102539
test: epoch 40, loss 2.2657554149627686, acc=0.3777777850627899, loss=2.2657554149627686
train: epoch 41, loss 0.15966658294200897, acc=0.9523333311080933, loss=0.15966658294200897
test: epoch 41, loss 1.8878018856048584, acc=0.4305555522441864, loss=1.8878018856048584
train: epoch 42, loss 0.15362200140953064, acc=0.9529444575309753, loss=0.15362200140953064
test: epoch 42, loss 2.552030086517334, acc=0.38055557012557983, loss=2.552030086517334
train: epoch 43, loss 0.14593297243118286, acc=0.9528889060020447, loss=0.14593297243118286
test: epoch 43, loss 1.7221328020095825, acc=0.45277777314186096, loss=1.7221328020095825
train: epoch 44, loss 0.1554713398218155, acc=0.9501110911369324, loss=0.1554713398218155
test: epoch 44, loss 1.8380520343780518, acc=0.49166667461395264, loss=1.8380520343780518
train: epoch 45, loss 0.14922025799751282, acc=0.9539444446563721, loss=0.14922025799751282
test: epoch 45, loss 1.7023682594299316, acc=0.47777777910232544, loss=1.7023682594299316
train: epoch 46, loss 0.14854881167411804, acc=0.9524999856948853, loss=0.14854881167411804
test: epoch 46, loss 1.6839470863342285, acc=0.4861111044883728, loss=1.6839470863342285
train: epoch 47, loss 0.1453201323747635, acc=0.9541666507720947, loss=0.1453201323747635
test: epoch 47, loss 1.5545231103897095, acc=0.48055556416511536, loss=1.5545231103897095
train: epoch 48, loss 0.13976867496967316, acc=0.9571666717529297, loss=0.13976867496967316
test: epoch 48, loss 1.9687285423278809, acc=0.4138889014720917, loss=1.9687285423278809
train: epoch 49, loss 0.1609887182712555, acc=0.9495000243186951, loss=0.1609887182712555
test: epoch 49, loss 2.2021119594573975, acc=0.40833333134651184, loss=2.2021119594573975
train: epoch 50, loss 0.1431330293416977, acc=0.95333331823349, loss=0.1431330293416977
test: epoch 50, loss 1.598718523979187, acc=0.519444465637207, loss=1.598718523979187
train: epoch 51, loss 0.1357085108757019, acc=0.9570555686950684, loss=0.1357085108757019
test: epoch 51, loss 1.850468635559082, acc=0.49166667461395264, loss=1.850468635559082
train: epoch 52, loss 0.1404801458120346, acc=0.9560555815696716, loss=0.1404801458120346
test: epoch 52, loss 1.5967568159103394, acc=0.5333333611488342, loss=1.5967568159103394
train: epoch 53, loss 0.1502179056406021, acc=0.953499972820282, loss=0.1502179056406021
test: epoch 53, loss 1.7664690017700195, acc=0.519444465637207, loss=1.7664690017700195
train: epoch 54, loss 0.13390716910362244, acc=0.9579444527626038, loss=0.13390716910362244
test: epoch 54, loss 1.4189435243606567, acc=0.550000011920929, loss=1.4189435243606567
train: epoch 55, loss 0.13150647282600403, acc=0.9579444527626038, loss=0.13150647282600403
test: epoch 55, loss 1.695974588394165, acc=0.43611112236976624, loss=1.695974588394165
train: epoch 56, loss 0.1283300518989563, acc=0.9616110920906067, loss=0.1283300518989563
test: epoch 56, loss 1.495680809020996, acc=0.5972222089767456, loss=1.495680809020996
train: epoch 57, loss 0.11970188468694687, acc=0.9618333578109741, loss=0.11970188468694687
test: epoch 57, loss 1.7402703762054443, acc=0.5249999761581421, loss=1.7402703762054443
train: epoch 58, loss 0.1381390392780304, acc=0.9566666483879089, loss=0.1381390392780304
test: epoch 58, loss 1.6143194437026978, acc=0.4611110985279083, loss=1.6143194437026978
train: epoch 59, loss 0.13399091362953186, acc=0.9591666460037231, loss=0.13399091362953186
test: epoch 59, loss 1.3904377222061157, acc=0.5472221970558167, loss=1.3904377222061157
train: epoch 60, loss 0.13851137459278107, acc=0.9561111330986023, loss=0.13851137459278107
test: epoch 60, loss 2.034290313720703, acc=0.5361111164093018, loss=2.034290313720703
train: epoch 61, loss 0.12958219647407532, acc=0.9593333601951599, loss=0.12958219647407532
test: epoch 61, loss 1.5757557153701782, acc=0.48055556416511536, loss=1.5757557153701782
train: epoch 62, loss 0.12812872231006622, acc=0.9600555300712585, loss=0.12812872231006622
test: epoch 62, loss 1.5507811307907104, acc=0.5944444537162781, loss=1.5507811307907104
train: epoch 63, loss 0.1431112438440323, acc=0.9548888802528381, loss=0.1431112438440323
test: epoch 63, loss 1.4564789533615112, acc=0.5166666507720947, loss=1.4564789533615112
train: epoch 64, loss 0.1172984316945076, acc=0.9618889093399048, loss=0.1172984316945076
test: epoch 64, loss 1.5291229486465454, acc=0.5472221970558167, loss=1.5291229486465454
train: epoch 65, loss 0.12152893841266632, acc=0.9618333578109741, loss=0.12152893841266632
test: epoch 65, loss 1.4104015827178955, acc=0.5916666388511658, loss=1.4104015827178955
train: epoch 66, loss 0.12087421864271164, acc=0.9610000252723694, loss=0.12087421864271164
test: epoch 66, loss 1.5604476928710938, acc=0.5083333253860474, loss=1.5604476928710938
train: epoch 67, loss 0.10640749335289001, acc=0.965499997138977, loss=0.10640749335289001
test: epoch 67, loss 1.3017973899841309, acc=0.6472222208976746, loss=1.3017973899841309
train: epoch 68, loss 0.13497979938983917, acc=0.9563888907432556, loss=0.13497979938983917
test: epoch 68, loss 1.8073399066925049, acc=0.5249999761581421, loss=1.8073399066925049
train: epoch 69, loss 0.11871529370546341, acc=0.961555540561676, loss=0.11871529370546341
test: epoch 69, loss 1.4529465436935425, acc=0.5833333134651184, loss=1.4529465436935425
train: epoch 70, loss 0.1235155239701271, acc=0.9619444608688354, loss=0.1235155239701271
test: epoch 70, loss 1.7118130922317505, acc=0.550000011920929, loss=1.7118130922317505
train: epoch 71, loss 0.13707414269447327, acc=0.9573333263397217, loss=0.13707414269447327
test: epoch 71, loss 1.559897541999817, acc=0.5472221970558167, loss=1.559897541999817
train: epoch 72, loss 0.11830534785985947, acc=0.9603333473205566, loss=0.11830534785985947
test: epoch 72, loss 1.4032227993011475, acc=0.5888888835906982, loss=1.4032227993011475
train: epoch 73, loss 0.11407976597547531, acc=0.9629444479942322, loss=0.11407976597547531
test: epoch 73, loss 1.5653539896011353, acc=0.5388888716697693, loss=1.5653539896011353
train: epoch 74, loss 0.11942245811223984, acc=0.9638888835906982, loss=0.11942245811223984
test: epoch 74, loss 1.6528105735778809, acc=0.5638889074325562, loss=1.6528105735778809
train: epoch 75, loss 0.11012493073940277, acc=0.9636666774749756, loss=0.11012493073940277
test: epoch 75, loss 1.8028442859649658, acc=0.5555555820465088, loss=1.8028442859649658
train: epoch 76, loss 0.12457278370857239, acc=0.9593333601951599, loss=0.12457278370857239
test: epoch 76, loss 1.3935346603393555, acc=0.5972222089767456, loss=1.3935346603393555
train: epoch 77, loss 0.1113838255405426, acc=0.9642778038978577, loss=0.1113838255405426
test: epoch 77, loss 1.8568925857543945, acc=0.5027777552604675, loss=1.8568925857543945
train: epoch 78, loss 0.12391889095306396, acc=0.9608333110809326, loss=0.12391889095306396
test: epoch 78, loss 1.7778785228729248, acc=0.5555555820465088, loss=1.7778785228729248
train: epoch 79, loss 0.11250445991754532, acc=0.9637777805328369, loss=0.11250445991754532
test: epoch 79, loss 1.3481074571609497, acc=0.5722222328186035, loss=1.3481074571609497
train: epoch 80, loss 0.1241927519440651, acc=0.9609444737434387, loss=0.1241927519440651
test: epoch 80, loss 1.578888177871704, acc=0.5249999761581421, loss=1.578888177871704
train: epoch 81, loss 0.11207199841737747, acc=0.9660555720329285, loss=0.11207199841737747
test: epoch 81, loss 1.2458425760269165, acc=0.6083333492279053, loss=1.2458425760269165
train: epoch 82, loss 0.1241689920425415, acc=0.9610000252723694, loss=0.1241689920425415
test: epoch 82, loss 1.543789029121399, acc=0.5888888835906982, loss=1.543789029121399
train: epoch 83, loss 0.10915014892816544, acc=0.9672222137451172, loss=0.10915014892816544
test: epoch 83, loss 1.2681968212127686, acc=0.5722222328186035, loss=1.2681968212127686
train: epoch 84, loss 0.11713313311338425, acc=0.9631666541099548, loss=0.11713313311338425
test: epoch 84, loss 1.445552945137024, acc=0.5805555582046509, loss=1.445552945137024
train: epoch 85, loss 0.12098349630832672, acc=0.960444450378418, loss=0.12098349630832672
test: epoch 85, loss 1.2131426334381104, acc=0.6138888597488403, loss=1.2131426334381104
train: epoch 86, loss 0.1254073679447174, acc=0.9602222442626953, loss=0.1254073679447174
test: epoch 86, loss 1.6078550815582275, acc=0.5722222328186035, loss=1.6078550815582275
train: epoch 87, loss 0.11913347244262695, acc=0.9623333215713501, loss=0.11913347244262695
test: epoch 87, loss 1.212491512298584, acc=0.6111111044883728, loss=1.212491512298584
train: epoch 88, loss 0.10566802322864532, acc=0.9662777781486511, loss=0.10566802322864532
test: epoch 88, loss 1.2479212284088135, acc=0.6472222208976746, loss=1.2479212284088135
train: epoch 89, loss 0.1287662833929062, acc=0.9603888988494873, loss=0.1287662833929062
test: epoch 89, loss 1.1969163417816162, acc=0.605555534362793, loss=1.1969163417816162
train: epoch 90, loss 0.12418673187494278, acc=0.9605000019073486, loss=0.12418673187494278
test: epoch 90, loss 1.028782606124878, acc=0.6027777791023254, loss=1.028782606124878
train: epoch 91, loss 0.11376892030239105, acc=0.9626111388206482, loss=0.11376892030239105
test: epoch 91, loss 1.0712178945541382, acc=0.6388888955116272, loss=1.0712178945541382
train: epoch 92, loss 0.1087869256734848, acc=0.964888870716095, loss=0.1087869256734848
test: epoch 92, loss 1.1778652667999268, acc=0.5833333134651184, loss=1.1778652667999268
train: epoch 93, loss 0.11348312348127365, acc=0.9637222290039062, loss=0.11348312348127365
test: epoch 93, loss 1.0582681894302368, acc=0.6666666865348816, loss=1.0582681894302368
train: epoch 94, loss 0.10409723967313766, acc=0.9654444456100464, loss=0.10409723967313766
test: epoch 94, loss 1.5080493688583374, acc=0.5805555582046509, loss=1.5080493688583374
train: epoch 95, loss 0.11347567290067673, acc=0.9616666436195374, loss=0.11347567290067673
test: epoch 95, loss 1.1756542921066284, acc=0.6388888955116272, loss=1.1756542921066284
train: epoch 96, loss 0.12922918796539307, acc=0.9593333601951599, loss=0.12922918796539307
test: epoch 96, loss 1.1612780094146729, acc=0.6527777910232544, loss=1.1612780094146729
train: epoch 97, loss 0.11658605188131332, acc=0.9638888835906982, loss=0.11658605188131332
test: epoch 97, loss 1.176721215248108, acc=0.6333333253860474, loss=1.176721215248108
train: epoch 98, loss 0.11668693274259567, acc=0.9618333578109741, loss=0.11668693274259567
test: epoch 98, loss 1.0528558492660522, acc=0.6611111164093018, loss=1.0528558492660522
train: epoch 99, loss 0.10989921540021896, acc=0.964888870716095, loss=0.10989921540021896
test: epoch 99, loss 1.333294153213501, acc=0.5916666388511658, loss=1.333294153213501
train: epoch 100, loss 0.1211964339017868, acc=0.9605000019073486, loss=0.1211964339017868
test: epoch 100, loss 1.104859471321106, acc=0.6777777671813965, loss=1.104859471321106
train: epoch 101, loss 0.11854324489831924, acc=0.961555540561676, loss=0.11854324489831924
test: epoch 101, loss 1.214897871017456, acc=0.5722222328186035, loss=1.214897871017456
train: epoch 102, loss 0.10965613275766373, acc=0.9661666750907898, loss=0.10965613275766373
test: epoch 102, loss 0.9529149532318115, acc=0.6944444179534912, loss=0.9529149532318115
train: epoch 103, loss 0.11193989962339401, acc=0.9623888731002808, loss=0.11193989962339401
test: epoch 103, loss 1.268707036972046, acc=0.6166666746139526, loss=1.268707036972046
train: epoch 104, loss 0.1356395035982132, acc=0.9564444422721863, loss=0.1356395035982132
test: epoch 104, loss 1.118565320968628, acc=0.6861110925674438, loss=1.118565320968628
train: epoch 105, loss 0.11220470070838928, acc=0.9646111130714417, loss=0.11220470070838928
test: epoch 105, loss 0.9601883292198181, acc=0.6833333373069763, loss=0.9601883292198181
train: epoch 106, loss 0.10755752772092819, acc=0.9653333425521851, loss=0.10755752772092819
test: epoch 106, loss 0.8458226919174194, acc=0.6944444179534912, loss=0.8458226919174194
train: epoch 107, loss 0.11469554901123047, acc=0.964722216129303, loss=0.11469554901123047
test: epoch 107, loss 0.9416563510894775, acc=0.7027778029441833, loss=0.9416563510894775
train: epoch 108, loss 0.11364281922578812, acc=0.9641666412353516, loss=0.11364281922578812
test: epoch 108, loss 1.2608630657196045, acc=0.6083333492279053, loss=1.2608630657196045
train: epoch 109, loss 0.11185377091169357, acc=0.9647777676582336, loss=0.11185377091169357
test: epoch 109, loss 1.3988157510757446, acc=0.6777777671813965, loss=1.3988157510757446
train: epoch 110, loss 0.12333112955093384, acc=0.9603888988494873, loss=0.12333112955093384
test: epoch 110, loss 1.0265288352966309, acc=0.6722221970558167, loss=1.0265288352966309
train: epoch 111, loss 0.11677079647779465, acc=0.9632777571678162, loss=0.11677079647779465
test: epoch 111, loss 0.9442774653434753, acc=0.699999988079071, loss=0.9442774653434753
train: epoch 112, loss 0.11187855154275894, acc=0.9639444351196289, loss=0.11187855154275894
test: epoch 112, loss 0.8538070917129517, acc=0.7388888597488403, loss=0.8538070917129517
train: epoch 113, loss 0.12086786329746246, acc=0.9616110920906067, loss=0.12086786329746246
test: epoch 113, loss 0.8998822569847107, acc=0.7250000238418579, loss=0.8998822569847107
train: epoch 114, loss 0.10457964986562729, acc=0.967555582523346, loss=0.10457964986562729
test: epoch 114, loss 0.9389025568962097, acc=0.7083333134651184, loss=0.9389025568962097
train: epoch 115, loss 0.12218385934829712, acc=0.9626666903495789, loss=0.12218385934829712
test: epoch 115, loss 1.0701698064804077, acc=0.6944444179534912, loss=1.0701698064804077
train: epoch 116, loss 0.11175968497991562, acc=0.9642778038978577, loss=0.11175968497991562
test: epoch 116, loss 1.0506401062011719, acc=0.7027778029441833, loss=1.0506401062011719
train: epoch 117, loss 0.10097838193178177, acc=0.9691666960716248, loss=0.10097838193178177
test: epoch 117, loss 0.7190167307853699, acc=0.769444465637207, loss=0.7190167307853699
train: epoch 118, loss 0.10562140494585037, acc=0.964388906955719, loss=0.10562140494585037
test: epoch 118, loss 0.7913514971733093, acc=0.7222222089767456, loss=0.7913514971733093
train: epoch 119, loss 0.10449081659317017, acc=0.9657222032546997, loss=0.10449081659317017
test: epoch 119, loss 1.1330032348632812, acc=0.7222222089767456, loss=1.1330032348632812
train: epoch 120, loss 0.11182862520217896, acc=0.9650555849075317, loss=0.11182862520217896
test: epoch 120, loss 0.8137444853782654, acc=0.7444444298744202, loss=0.8137444853782654
train: epoch 121, loss 0.11275281757116318, acc=0.964722216129303, loss=0.11275281757116318
test: epoch 121, loss 0.7160249948501587, acc=0.7916666865348816, loss=0.7160249948501587
train: epoch 122, loss 0.10539396107196808, acc=0.9663333296775818, loss=0.10539396107196808
test: epoch 122, loss 1.0665500164031982, acc=0.7416666746139526, loss=1.0665500164031982
train: epoch 123, loss 0.1201985776424408, acc=0.9622777700424194, loss=0.1201985776424408
test: epoch 123, loss 1.2442525625228882, acc=0.7083333134651184, loss=1.2442525625228882
train: epoch 124, loss 0.12782083451747894, acc=0.9595555663108826, loss=0.12782083451747894
test: epoch 124, loss 0.8100302815437317, acc=0.7555555701255798, loss=0.8100302815437317
train: epoch 125, loss 0.09450499713420868, acc=0.9697222113609314, loss=0.09450499713420868
test: epoch 125, loss 0.8439846634864807, acc=0.7666666507720947, loss=0.8439846634864807
train: epoch 126, loss 0.12615521252155304, acc=0.9609444737434387, loss=0.12615521252155304
test: epoch 126, loss 0.8140455484390259, acc=0.7666666507720947, loss=0.8140455484390259
train: epoch 127, loss 0.10583987087011337, acc=0.9666666388511658, loss=0.10583987087011337
test: epoch 127, loss 0.5878466367721558, acc=0.7972221970558167, loss=0.5878466367721558
train: epoch 128, loss 0.10855565220117569, acc=0.9652222394943237, loss=0.10855565220117569
test: epoch 128, loss 0.9205676913261414, acc=0.7361111044883728, loss=0.9205676913261414
train: epoch 129, loss 0.09629669785499573, acc=0.968999981880188, loss=0.09629669785499573
test: epoch 129, loss 0.6350484490394592, acc=0.7861111164093018, loss=0.6350484490394592
train: epoch 130, loss 0.11463967710733414, acc=0.9632222056388855, loss=0.11463967710733414
test: epoch 130, loss 0.7812130451202393, acc=0.7444444298744202, loss=0.7812130451202393
train: epoch 131, loss 0.10833628475666046, acc=0.9674999713897705, loss=0.10833628475666046
test: epoch 131, loss 0.6588313579559326, acc=0.7888888716697693, loss=0.6588313579559326
train: epoch 132, loss 0.11067789793014526, acc=0.9637777805328369, loss=0.11067789793014526
test: epoch 132, loss 1.0783153772354126, acc=0.7111111283302307, loss=1.0783153772354126
train: epoch 133, loss 0.10331206768751144, acc=0.968833327293396, loss=0.10331206768751144
test: epoch 133, loss 0.5900758504867554, acc=0.8111110925674438, loss=0.5900758504867554
train: epoch 134, loss 0.11343570798635483, acc=0.968500018119812, loss=0.11343570798635483
test: epoch 134, loss 0.7016489505767822, acc=0.7833333611488342, loss=0.7016489505767822
train: epoch 135, loss 0.1190100610256195, acc=0.9636666774749756, loss=0.1190100610256195
test: epoch 135, loss 0.689624547958374, acc=0.7972221970558167, loss=0.689624547958374
train: epoch 136, loss 0.10048580169677734, acc=0.9692777991294861, loss=0.10048580169677734
test: epoch 136, loss 0.8820101022720337, acc=0.7944444417953491, loss=0.8820101022720337
train: epoch 137, loss 0.09442248940467834, acc=0.9696111083030701, loss=0.09442248940467834
test: epoch 137, loss 0.5737593173980713, acc=0.8277778029441833, loss=0.5737593173980713
train: epoch 138, loss 0.11009629815816879, acc=0.9674999713897705, loss=0.11009629815816879
test: epoch 138, loss 0.5835418701171875, acc=0.7972221970558167, loss=0.5835418701171875
train: epoch 139, loss 0.10529286414384842, acc=0.9674444198608398, loss=0.10529286414384842
test: epoch 139, loss 0.6486141085624695, acc=0.7833333611488342, loss=0.6486141085624695
train: epoch 140, loss 0.11193152517080307, acc=0.9636666774749756, loss=0.11193152517080307
test: epoch 140, loss 0.8048701882362366, acc=0.7611111402511597, loss=0.8048701882362366
train: epoch 141, loss 0.09937568753957748, acc=0.9678333401679993, loss=0.09937568753957748
test: epoch 141, loss 0.7751771807670593, acc=0.7833333611488342, loss=0.7751771807670593
train: epoch 142, loss 0.10678750276565552, acc=0.9678333401679993, loss=0.10678750276565552
test: epoch 142, loss 0.5232862830162048, acc=0.7944444417953491, loss=0.5232862830162048
train: epoch 143, loss 0.10626739263534546, acc=0.9680555462837219, loss=0.10626739263534546
test: epoch 143, loss 0.6452234387397766, acc=0.8027777671813965, loss=0.6452234387397766
train: epoch 144, loss 0.08666615188121796, acc=0.9731666445732117, loss=0.08666615188121796
test: epoch 144, loss 0.7559170126914978, acc=0.7777777910232544, loss=0.7559170126914978
train: epoch 145, loss 0.10149064660072327, acc=0.9698333144187927, loss=0.10149064660072327
test: epoch 145, loss 0.6315232515335083, acc=0.824999988079071, loss=0.6315232515335083
train: epoch 146, loss 0.10355853289365768, acc=0.9680555462837219, loss=0.10355853289365768
test: epoch 146, loss 0.7824088335037231, acc=0.8055555820465088, loss=0.7824088335037231
train: epoch 147, loss 0.10911364108324051, acc=0.9669444561004639, loss=0.10911364108324051
test: epoch 147, loss 0.6642196178436279, acc=0.7722222208976746, loss=0.6642196178436279
train: epoch 148, loss 0.09119448065757751, acc=0.9717222452163696, loss=0.09119448065757751
test: epoch 148, loss 0.6253504753112793, acc=0.8111110925674438, loss=0.6253504753112793
train: epoch 149, loss 0.09699203819036484, acc=0.9693889021873474, loss=0.09699203819036484
test: epoch 149, loss 0.7497235536575317, acc=0.8111110925674438, loss=0.7497235536575317
train: epoch 150, loss 0.08851675689220428, acc=0.9719444513320923, loss=0.08851675689220428
test: epoch 150, loss 0.5274301171302795, acc=0.8138889074325562, loss=0.5274301171302795
