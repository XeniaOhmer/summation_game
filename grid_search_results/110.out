# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=1", "--temp_decay=1", "--one_hot=true", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1990319193, receiver_embed_dim=128, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.930675983428955, acc=0.08349999785423279, loss=2.930675983428955
test: epoch 1, loss 2.342722177505493, acc=0.15555556118488312, loss=2.342722177505493
train: epoch 2, loss 1.7803581953048706, acc=0.2819444537162781, loss=1.7803581953048706
test: epoch 2, loss 1.6643531322479248, acc=0.3055555522441864, loss=1.6643531322479248
train: epoch 3, loss 1.414421796798706, acc=0.3962777853012085, loss=1.414421796798706
test: epoch 3, loss 1.5462617874145508, acc=0.35277777910232544, loss=1.5462617874145508
train: epoch 4, loss 1.2823667526245117, acc=0.44316667318344116, loss=1.2823667526245117
test: epoch 4, loss 1.5016727447509766, acc=0.38055557012557983, loss=1.5016727447509766
train: epoch 5, loss 1.2300618886947632, acc=0.45738887786865234, loss=1.2300618886947632
test: epoch 5, loss 1.4466300010681152, acc=0.3777777850627899, loss=1.4466300010681152
train: epoch 6, loss 1.161128044128418, acc=0.4860000014305115, loss=1.161128044128418
test: epoch 6, loss 1.340537428855896, acc=0.39722222089767456, loss=1.340537428855896
train: epoch 7, loss 1.1254093647003174, acc=0.5034999847412109, loss=1.1254093647003174
test: epoch 7, loss 1.7415533065795898, acc=0.32777777314186096, loss=1.7415533065795898
train: epoch 8, loss 1.0930804014205933, acc=0.5154444575309753, loss=1.0930804014205933
test: epoch 8, loss 1.513744831085205, acc=0.40833333134651184, loss=1.513744831085205
train: epoch 9, loss 1.0249550342559814, acc=0.5352222323417664, loss=1.0249550342559814
test: epoch 9, loss 1.581949234008789, acc=0.4000000059604645, loss=1.581949234008789
train: epoch 10, loss 0.9927181005477905, acc=0.5451111197471619, loss=0.9927181005477905
test: epoch 10, loss 1.4523755311965942, acc=0.42222222685813904, loss=1.4523755311965942
train: epoch 11, loss 0.9549197554588318, acc=0.5669999718666077, loss=0.9549197554588318
test: epoch 11, loss 1.5072470903396606, acc=0.4305555522441864, loss=1.5072470903396606
train: epoch 12, loss 0.9057986736297607, acc=0.5873333215713501, loss=0.9057986736297607
test: epoch 12, loss 1.5016655921936035, acc=0.4333333373069763, loss=1.5016655921936035
train: epoch 13, loss 0.9062406420707703, acc=0.5889444351196289, loss=0.9062406420707703
test: epoch 13, loss 1.6273983716964722, acc=0.4305555522441864, loss=1.6273983716964722
train: epoch 14, loss 0.9023122787475586, acc=0.5975000262260437, loss=0.9023122787475586
test: epoch 14, loss 1.6510539054870605, acc=0.4305555522441864, loss=1.6510539054870605
train: epoch 15, loss 0.8829609155654907, acc=0.5993888974189758, loss=0.8829609155654907
test: epoch 15, loss 1.5583980083465576, acc=0.42222222685813904, loss=1.5583980083465576
train: epoch 16, loss 0.8611372113227844, acc=0.6088888645172119, loss=0.8611372113227844
test: epoch 16, loss 1.5469552278518677, acc=0.4277777671813965, loss=1.5469552278518677
train: epoch 17, loss 0.8659921288490295, acc=0.6015555262565613, loss=0.8659921288490295
test: epoch 17, loss 1.578831672668457, acc=0.4333333373069763, loss=1.578831672668457
train: epoch 18, loss 0.8387002944946289, acc=0.6200555562973022, loss=0.8387002944946289
test: epoch 18, loss 1.7041208744049072, acc=0.4333333373069763, loss=1.7041208744049072
train: epoch 19, loss 0.831306517124176, acc=0.6148333549499512, loss=0.831306517124176
test: epoch 19, loss 1.6747432947158813, acc=0.4333333373069763, loss=1.6747432947158813
train: epoch 20, loss 0.8387060165405273, acc=0.6135555505752563, loss=0.8387060165405273
test: epoch 20, loss 1.6883958578109741, acc=0.4333333373069763, loss=1.6883958578109741
train: epoch 21, loss 0.8414773344993591, acc=0.613444447517395, loss=0.8414773344993591
test: epoch 21, loss 1.7467671632766724, acc=0.4305555522441864, loss=1.7467671632766724
train: epoch 22, loss 0.8194929957389832, acc=0.6213333606719971, loss=0.8194929957389832
test: epoch 22, loss 1.5960619449615479, acc=0.4277777671813965, loss=1.5960619449615479
train: epoch 23, loss 0.8089966773986816, acc=0.6153333187103271, loss=0.8089966773986816
test: epoch 23, loss 1.4173188209533691, acc=0.41111111640930176, loss=1.4173188209533691
train: epoch 24, loss 0.7989861965179443, acc=0.6170555353164673, loss=0.7989861965179443
test: epoch 24, loss 1.7269337177276611, acc=0.42500001192092896, loss=1.7269337177276611
train: epoch 25, loss 0.7911005020141602, acc=0.6296111345291138, loss=0.7911005020141602
test: epoch 25, loss 1.5482497215270996, acc=0.4277777671813965, loss=1.5482497215270996
train: epoch 26, loss 0.7679721117019653, acc=0.6378889083862305, loss=0.7679721117019653
test: epoch 26, loss 1.554243564605713, acc=0.4194444417953491, loss=1.554243564605713
train: epoch 27, loss 0.7704107165336609, acc=0.6390555500984192, loss=0.7704107165336609
test: epoch 27, loss 1.5597549676895142, acc=0.4166666567325592, loss=1.5597549676895142
train: epoch 28, loss 0.7749685049057007, acc=0.6323333382606506, loss=0.7749685049057007
test: epoch 28, loss 1.4753570556640625, acc=0.4444444477558136, loss=1.4753570556640625
train: epoch 29, loss 0.7347250580787659, acc=0.6406111121177673, loss=0.7347250580787659
test: epoch 29, loss 1.4351773262023926, acc=0.46388888359069824, loss=1.4351773262023926
train: epoch 30, loss 0.7667356133460999, acc=0.6346666812896729, loss=0.7667356133460999
test: epoch 30, loss 1.4516408443450928, acc=0.4611110985279083, loss=1.4516408443450928
train: epoch 31, loss 0.7473230957984924, acc=0.6442221999168396, loss=0.7473230957984924
test: epoch 31, loss 1.4377529621124268, acc=0.4555555582046509, loss=1.4377529621124268
train: epoch 32, loss 0.7565231919288635, acc=0.6385555267333984, loss=0.7565231919288635
test: epoch 32, loss 1.2850353717803955, acc=0.4972222149372101, loss=1.2850353717803955
train: epoch 33, loss 0.7070517539978027, acc=0.6585000157356262, loss=0.7070517539978027
test: epoch 33, loss 1.3002338409423828, acc=0.4888888895511627, loss=1.3002338409423828
train: epoch 34, loss 0.7106995582580566, acc=0.6545555591583252, loss=0.7106995582580566
test: epoch 34, loss 1.4343940019607544, acc=0.5249999761581421, loss=1.4343940019607544
train: epoch 35, loss 0.6892476677894592, acc=0.668833315372467, loss=0.6892476677894592
test: epoch 35, loss 1.1645861864089966, acc=0.5666666626930237, loss=1.1645861864089966
train: epoch 36, loss 0.6669208407402039, acc=0.6726666688919067, loss=0.6669208407402039
test: epoch 36, loss 1.1846582889556885, acc=0.5638889074325562, loss=1.1846582889556885
train: epoch 37, loss 0.6837658286094666, acc=0.6763888597488403, loss=0.6837658286094666
test: epoch 37, loss 1.2532261610031128, acc=0.5638889074325562, loss=1.2532261610031128
train: epoch 38, loss 0.6623318195343018, acc=0.683388888835907, loss=0.6623318195343018
test: epoch 38, loss 1.0398690700531006, acc=0.5972222089767456, loss=1.0398690700531006
train: epoch 39, loss 0.7157717347145081, acc=0.6741666793823242, loss=0.7157717347145081
test: epoch 39, loss 1.0153177976608276, acc=0.5916666388511658, loss=1.0153177976608276
train: epoch 40, loss 0.6624345779418945, acc=0.6747221946716309, loss=0.6624345779418945
test: epoch 40, loss 0.9454927444458008, acc=0.5944444537162781, loss=0.9454927444458008
train: epoch 41, loss 0.6429639458656311, acc=0.6823333501815796, loss=0.6429639458656311
test: epoch 41, loss 1.0779356956481934, acc=0.5944444537162781, loss=1.0779356956481934
train: epoch 42, loss 0.6712557077407837, acc=0.6840555667877197, loss=0.6712557077407837
test: epoch 42, loss 1.1500391960144043, acc=0.5916666388511658, loss=1.1500391960144043
train: epoch 43, loss 0.6613460779190063, acc=0.6819444298744202, loss=0.6613460779190063
test: epoch 43, loss 0.9542982578277588, acc=0.5916666388511658, loss=0.9542982578277588
train: epoch 44, loss 0.6885745525360107, acc=0.6713333129882812, loss=0.6885745525360107
test: epoch 44, loss 0.9593254923820496, acc=0.5916666388511658, loss=0.9593254923820496
train: epoch 45, loss 0.6613591909408569, acc=0.6772778034210205, loss=0.6613591909408569
test: epoch 45, loss 0.9953963756561279, acc=0.5916666388511658, loss=0.9953963756561279
train: epoch 46, loss 0.6437581181526184, acc=0.683055579662323, loss=0.6437581181526184
test: epoch 46, loss 1.063734769821167, acc=0.5916666388511658, loss=1.063734769821167
train: epoch 47, loss 0.6896453499794006, acc=0.6762222051620483, loss=0.6896453499794006
test: epoch 47, loss 1.1074514389038086, acc=0.5888888835906982, loss=1.1074514389038086
train: epoch 48, loss 0.6508219242095947, acc=0.6763333082199097, loss=0.6508219242095947
test: epoch 48, loss 1.0266036987304688, acc=0.5888888835906982, loss=1.0266036987304688
train: epoch 49, loss 0.6674613356590271, acc=0.6622777581214905, loss=0.6674613356590271
test: epoch 49, loss 1.082964301109314, acc=0.5777778029441833, loss=1.082964301109314
train: epoch 50, loss 0.6620400547981262, acc=0.6623333096504211, loss=0.6620400547981262
test: epoch 50, loss 1.1849719285964966, acc=0.5722222328186035, loss=1.1849719285964966
train: epoch 51, loss 0.6776605844497681, acc=0.6610000133514404, loss=0.6776605844497681
test: epoch 51, loss 1.012896180152893, acc=0.6027777791023254, loss=1.012896180152893
train: epoch 52, loss 0.673564076423645, acc=0.6800000071525574, loss=0.673564076423645
test: epoch 52, loss 1.0549581050872803, acc=0.6166666746139526, loss=1.0549581050872803
train: epoch 53, loss 0.6238276362419128, acc=0.6851666569709778, loss=0.6238276362419128
test: epoch 53, loss 0.988070011138916, acc=0.6194444298744202, loss=0.988070011138916
train: epoch 54, loss 0.6436306834220886, acc=0.6840000152587891, loss=0.6436306834220886
test: epoch 54, loss 0.9171278476715088, acc=0.6138888597488403, loss=0.9171278476715088
train: epoch 55, loss 0.6727493405342102, acc=0.6698333621025085, loss=0.6727493405342102
test: epoch 55, loss 0.8685207962989807, acc=0.605555534362793, loss=0.8685207962989807
train: epoch 56, loss 0.7483974099159241, acc=0.648722231388092, loss=0.7483974099159241
test: epoch 56, loss 0.9998375773429871, acc=0.6000000238418579, loss=0.9998375773429871
train: epoch 57, loss 0.7785753011703491, acc=0.6503888964653015, loss=0.7785753011703491
test: epoch 57, loss 0.9800447225570679, acc=0.6166666746139526, loss=0.9800447225570679
train: epoch 58, loss 0.6921709775924683, acc=0.672166645526886, loss=0.6921709775924683
test: epoch 58, loss 0.8938929438591003, acc=0.6416666507720947, loss=0.8938929438591003
train: epoch 59, loss 0.6549842953681946, acc=0.6818333268165588, loss=0.6549842953681946
test: epoch 59, loss 0.897625744342804, acc=0.644444465637207, loss=0.897625744342804
train: epoch 60, loss 0.6739175915718079, acc=0.6792222261428833, loss=0.6739175915718079
test: epoch 60, loss 0.9400046467781067, acc=0.6222222447395325, loss=0.9400046467781067
train: epoch 61, loss 0.7000294923782349, acc=0.6685555577278137, loss=0.7000294923782349
test: epoch 61, loss 0.8924859166145325, acc=0.6305555701255798, loss=0.8924859166145325
train: epoch 62, loss 0.6704557538032532, acc=0.6629444360733032, loss=0.6704557538032532
test: epoch 62, loss 0.7988397479057312, acc=0.6388888955116272, loss=0.7988397479057312
train: epoch 63, loss 0.6561667323112488, acc=0.6744444370269775, loss=0.6561667323112488
test: epoch 63, loss 0.8119973540306091, acc=0.6388888955116272, loss=0.8119973540306091
train: epoch 64, loss 0.6659388542175293, acc=0.6755555272102356, loss=0.6659388542175293
test: epoch 64, loss 0.9329331517219543, acc=0.6416666507720947, loss=0.9329331517219543
train: epoch 65, loss 0.6659579277038574, acc=0.6771666407585144, loss=0.6659579277038574
test: epoch 65, loss 0.7013691663742065, acc=0.6638888716697693, loss=0.7013691663742065
train: epoch 66, loss 0.617740273475647, acc=0.6811666488647461, loss=0.617740273475647
test: epoch 66, loss 0.7805068492889404, acc=0.6638888716697693, loss=0.7805068492889404
train: epoch 67, loss 0.6313846707344055, acc=0.6882222294807434, loss=0.6313846707344055
test: epoch 67, loss 0.7997674345970154, acc=0.6666666865348816, loss=0.7997674345970154
train: epoch 68, loss 0.6315661072731018, acc=0.6924999952316284, loss=0.6315661072731018
test: epoch 68, loss 0.6497480869293213, acc=0.6944444179534912, loss=0.6497480869293213
train: epoch 69, loss 0.6135574579238892, acc=0.6825000047683716, loss=0.6135574579238892
test: epoch 69, loss 0.662177324295044, acc=0.6944444179534912, loss=0.662177324295044
train: epoch 70, loss 0.6313157081604004, acc=0.6876111030578613, loss=0.6313157081604004
test: epoch 70, loss 0.6465016603469849, acc=0.6944444179534912, loss=0.6465016603469849
train: epoch 71, loss 0.6116089820861816, acc=0.6846666932106018, loss=0.6116089820861816
test: epoch 71, loss 0.6963096857070923, acc=0.6944444179534912, loss=0.6963096857070923
train: epoch 72, loss 0.6133434176445007, acc=0.6866111159324646, loss=0.6133434176445007
test: epoch 72, loss 0.6837489008903503, acc=0.6944444179534912, loss=0.6837489008903503
train: epoch 73, loss 0.6071789860725403, acc=0.6860555410385132, loss=0.6071789860725403
test: epoch 73, loss 0.6598663926124573, acc=0.6944444179534912, loss=0.6598663926124573
train: epoch 74, loss 0.6514783501625061, acc=0.680388867855072, loss=0.6514783501625061
test: epoch 74, loss 0.725552499294281, acc=0.6777777671813965, loss=0.725552499294281
train: epoch 75, loss 0.6430881023406982, acc=0.6754999756813049, loss=0.6430881023406982
test: epoch 75, loss 0.7369654774665833, acc=0.6777777671813965, loss=0.7369654774665833
train: epoch 76, loss 0.6648032069206238, acc=0.6771666407585144, loss=0.6648032069206238
test: epoch 76, loss 0.6737381815910339, acc=0.6916666626930237, loss=0.6737381815910339
train: epoch 77, loss 0.6541330218315125, acc=0.6801111102104187, loss=0.6541330218315125
test: epoch 77, loss 0.6611339449882507, acc=0.6888889074325562, loss=0.6611339449882507
train: epoch 78, loss 0.6361954212188721, acc=0.6800000071525574, loss=0.6361954212188721
test: epoch 78, loss 0.6386907696723938, acc=0.6972222328186035, loss=0.6386907696723938
train: epoch 79, loss 0.6575663685798645, acc=0.6866666674613953, loss=0.6575663685798645
test: epoch 79, loss 0.6496478319168091, acc=0.6972222328186035, loss=0.6496478319168091
train: epoch 80, loss 0.6245200037956238, acc=0.684333324432373, loss=0.6245200037956238
test: epoch 80, loss 0.6170551776885986, acc=0.7027778029441833, loss=0.6170551776885986
train: epoch 81, loss 0.6256294846534729, acc=0.6760555505752563, loss=0.6256294846534729
test: epoch 81, loss 0.625796377658844, acc=0.699999988079071, loss=0.625796377658844
train: epoch 82, loss 0.628376305103302, acc=0.6737222075462341, loss=0.628376305103302
test: epoch 82, loss 0.6256992220878601, acc=0.699999988079071, loss=0.6256992220878601
train: epoch 83, loss 0.7225947976112366, acc=0.6700000166893005, loss=0.7225947976112366
test: epoch 83, loss 0.6365960836410522, acc=0.6944444179534912, loss=0.6365960836410522
train: epoch 84, loss 0.638482391834259, acc=0.6753888726234436, loss=0.638482391834259
test: epoch 84, loss 0.6296268105506897, acc=0.6972222328186035, loss=0.6296268105506897
train: epoch 85, loss 0.6479640007019043, acc=0.6618333458900452, loss=0.6479640007019043
test: epoch 85, loss 0.6323055624961853, acc=0.6944444179534912, loss=0.6323055624961853
train: epoch 86, loss 0.6537951231002808, acc=0.6635000109672546, loss=0.6537951231002808
test: epoch 86, loss 0.7451506853103638, acc=0.6861110925674438, loss=0.7451506853103638
train: epoch 87, loss 0.7355323433876038, acc=0.6625000238418579, loss=0.7355323433876038
test: epoch 87, loss 0.811011791229248, acc=0.6611111164093018, loss=0.811011791229248
train: epoch 88, loss 0.7400919795036316, acc=0.6558333039283752, loss=0.7400919795036316
test: epoch 88, loss 0.7083345651626587, acc=0.675000011920929, loss=0.7083345651626587
train: epoch 89, loss 0.7262254953384399, acc=0.6545555591583252, loss=0.7262254953384399
test: epoch 89, loss 0.6955630779266357, acc=0.6777777671813965, loss=0.6955630779266357
train: epoch 90, loss 0.6981576681137085, acc=0.6560555696487427, loss=0.6981576681137085
test: epoch 90, loss 0.7012250423431396, acc=0.6777777671813965, loss=0.7012250423431396
train: epoch 91, loss 0.6847449541091919, acc=0.6584444642066956, loss=0.6847449541091919
test: epoch 91, loss 0.6618244647979736, acc=0.6833333373069763, loss=0.6618244647979736
train: epoch 92, loss 0.6594918370246887, acc=0.6625555753707886, loss=0.6594918370246887
test: epoch 92, loss 0.6384586691856384, acc=0.6916666626930237, loss=0.6384586691856384
train: epoch 93, loss 0.6595382690429688, acc=0.6717777848243713, loss=0.6595382690429688
test: epoch 93, loss 0.6602082252502441, acc=0.6833333373069763, loss=0.6602082252502441
train: epoch 94, loss 0.6653293371200562, acc=0.6661111116409302, loss=0.6653293371200562
test: epoch 94, loss 0.6596705317497253, acc=0.6833333373069763, loss=0.6596705317497253
train: epoch 95, loss 0.6627228260040283, acc=0.6576666831970215, loss=0.6627228260040283
test: epoch 95, loss 0.6593145728111267, acc=0.6833333373069763, loss=0.6593145728111267
train: epoch 96, loss 0.6646790504455566, acc=0.6575555801391602, loss=0.6646790504455566
test: epoch 96, loss 0.6595767736434937, acc=0.6833333373069763, loss=0.6595767736434937
train: epoch 97, loss 0.8448435664176941, acc=0.5995000004768372, loss=0.8448435664176941
test: epoch 97, loss 0.7947245240211487, acc=0.6194444298744202, loss=0.7947245240211487
train: epoch 98, loss 0.7975113391876221, acc=0.6082777976989746, loss=0.7975113391876221
test: epoch 98, loss 0.7715567946434021, acc=0.6361111402511597, loss=0.7715567946434021
train: epoch 99, loss 0.7733468413352966, acc=0.6237221956253052, loss=0.7733468413352966
test: epoch 99, loss 0.742295503616333, acc=0.6555555462837219, loss=0.742295503616333
train: epoch 100, loss 0.7130494117736816, acc=0.6462222337722778, loss=0.7130494117736816
test: epoch 100, loss 0.6889662742614746, acc=0.6777777671813965, loss=0.6889662742614746
train: epoch 101, loss 0.6912034749984741, acc=0.6525555849075317, loss=0.6912034749984741
test: epoch 101, loss 0.6887553334236145, acc=0.6777777671813965, loss=0.6887553334236145
train: epoch 102, loss 0.691002368927002, acc=0.6528333425521851, loss=0.691002368927002
test: epoch 102, loss 0.6887199878692627, acc=0.6777777671813965, loss=0.6887199878692627
train: epoch 103, loss 0.690877377986908, acc=0.6541666388511658, loss=0.690877377986908
test: epoch 103, loss 0.6886763572692871, acc=0.6777777671813965, loss=0.6886763572692871
train: epoch 104, loss 0.6909484267234802, acc=0.6560555696487427, loss=0.6909484267234802
test: epoch 104, loss 0.6886714100837708, acc=0.6777777671813965, loss=0.6886714100837708
train: epoch 105, loss 0.6908368468284607, acc=0.6580555438995361, loss=0.6908368468284607
test: epoch 105, loss 0.6886588335037231, acc=0.6777777671813965, loss=0.6886588335037231
train: epoch 106, loss 0.6907572746276855, acc=0.6587777733802795, loss=0.6907572746276855
test: epoch 106, loss 0.6886512637138367, acc=0.6777777671813965, loss=0.6886512637138367
train: epoch 107, loss 0.6907202005386353, acc=0.660277783870697, loss=0.6907202005386353
test: epoch 107, loss 0.6886570453643799, acc=0.6777777671813965, loss=0.6886570453643799
train: epoch 108, loss 0.6906703114509583, acc=0.660611093044281, loss=0.6906703114509583
test: epoch 108, loss 0.6886301636695862, acc=0.6777777671813965, loss=0.6886301636695862
train: epoch 109, loss 0.6905011534690857, acc=0.6613333225250244, loss=0.6905011534690857
test: epoch 109, loss 0.6886181235313416, acc=0.6777777671813965, loss=0.6886181235313416
train: epoch 110, loss 0.6905179619789124, acc=0.6617222428321838, loss=0.6905179619789124
test: epoch 110, loss 0.6886066794395447, acc=0.6777777671813965, loss=0.6886066794395447
train: epoch 111, loss 0.6912631392478943, acc=0.6622777581214905, loss=0.6912631392478943
test: epoch 111, loss 0.6886267066001892, acc=0.6777777671813965, loss=0.6886267066001892
train: epoch 112, loss 0.6905878782272339, acc=0.663611114025116, loss=0.6905878782272339
test: epoch 112, loss 0.688603401184082, acc=0.6777777671813965, loss=0.688603401184082
train: epoch 113, loss 0.7743151187896729, acc=0.6578333377838135, loss=0.7743151187896729
test: epoch 113, loss 0.6928558349609375, acc=0.6777777671813965, loss=0.6928558349609375
train: epoch 114, loss 0.6965779662132263, acc=0.6596111059188843, loss=0.6965779662132263
test: epoch 114, loss 0.6956638097763062, acc=0.6777777671813965, loss=0.6956638097763062
train: epoch 115, loss 0.6977458000183105, acc=0.6607778072357178, loss=0.6977458000183105
test: epoch 115, loss 0.6824392676353455, acc=0.6805555820465088, loss=0.6824392676353455
train: epoch 116, loss 0.6965574026107788, acc=0.659166693687439, loss=0.6965574026107788
test: epoch 116, loss 0.6758493781089783, acc=0.6833333373069763, loss=0.6758493781089783
train: epoch 117, loss 0.6778433918952942, acc=0.6607778072357178, loss=0.6778433918952942
test: epoch 117, loss 0.6757235527038574, acc=0.6833333373069763, loss=0.6757235527038574
train: epoch 118, loss 0.6775185465812683, acc=0.6618888974189758, loss=0.6775185465812683
test: epoch 118, loss 0.6756641864776611, acc=0.6833333373069763, loss=0.6756641864776611
train: epoch 119, loss 0.6775191426277161, acc=0.6628888845443726, loss=0.6775191426277161
test: epoch 119, loss 0.6756520867347717, acc=0.6833333373069763, loss=0.6756520867347717
train: epoch 120, loss 0.6774424910545349, acc=0.663277804851532, loss=0.6774424910545349
test: epoch 120, loss 0.6756281852722168, acc=0.6833333373069763, loss=0.6756281852722168
train: epoch 121, loss 0.7225448489189148, acc=0.6622777581214905, loss=0.7225448489189148
test: epoch 121, loss 0.7213789224624634, acc=0.6722221970558167, loss=0.7213789224624634
train: epoch 122, loss 0.7435719966888428, acc=0.6551111340522766, loss=0.7435719966888428
test: epoch 122, loss 0.719002366065979, acc=0.6638888716697693, loss=0.719002366065979
train: epoch 123, loss 0.7102838158607483, acc=0.6603333353996277, loss=0.7102838158607483
test: epoch 123, loss 0.7032926678657532, acc=0.6666666865348816, loss=0.7032926678657532
train: epoch 124, loss 0.7023787498474121, acc=0.655055582523346, loss=0.7023787498474121
test: epoch 124, loss 0.6877257823944092, acc=0.6722221970558167, loss=0.6877257823944092
train: epoch 125, loss 0.7322314381599426, acc=0.6585000157356262, loss=0.7322314381599426
test: epoch 125, loss 0.712019681930542, acc=0.6722221970558167, loss=0.712019681930542
train: epoch 126, loss 0.728328287601471, acc=0.6580555438995361, loss=0.728328287601471
test: epoch 126, loss 0.6965538859367371, acc=0.675000011920929, loss=0.6965538859367371
train: epoch 127, loss 0.700638473033905, acc=0.672166645526886, loss=0.700638473033905
test: epoch 127, loss 0.6748899817466736, acc=0.6805555820465088, loss=0.6748899817466736
train: epoch 128, loss 0.6765769124031067, acc=0.668833315372467, loss=0.6765769124031067
test: epoch 128, loss 0.6743762493133545, acc=0.6805555820465088, loss=0.6743762493133545
train: epoch 129, loss 0.6754931807518005, acc=0.6631666421890259, loss=0.6754931807518005
test: epoch 129, loss 0.6724084615707397, acc=0.6805555820465088, loss=0.6724084615707397
train: epoch 130, loss 0.6774702668190002, acc=0.6581110954284668, loss=0.6774702668190002
test: epoch 130, loss 0.797844648361206, acc=0.6611111164093018, loss=0.797844648361206
train: epoch 131, loss 0.6872581839561462, acc=0.6660000085830688, loss=0.6872581839561462
test: epoch 131, loss 0.6789060235023499, acc=0.6805555820465088, loss=0.6789060235023499
train: epoch 132, loss 0.6809536218643188, acc=0.6663333177566528, loss=0.6809536218643188
test: epoch 132, loss 0.6788315773010254, acc=0.6805555820465088, loss=0.6788315773010254
train: epoch 133, loss 0.6807068586349487, acc=0.6653333306312561, loss=0.6807068586349487
test: epoch 133, loss 0.6787965893745422, acc=0.6805555820465088, loss=0.6787965893745422
train: epoch 134, loss 0.6806272268295288, acc=0.6653333306312561, loss=0.6806272268295288
test: epoch 134, loss 0.6787835955619812, acc=0.6805555820465088, loss=0.6787835955619812
train: epoch 135, loss 0.6806173324584961, acc=0.6653333306312561, loss=0.6806173324584961
test: epoch 135, loss 0.6787685751914978, acc=0.6805555820465088, loss=0.6787685751914978
train: epoch 136, loss 0.6804718971252441, acc=0.6652777791023254, loss=0.6804718971252441
test: epoch 136, loss 0.6787575483322144, acc=0.6805555820465088, loss=0.6787575483322144
train: epoch 137, loss 0.680385947227478, acc=0.6653888821601868, loss=0.680385947227478
test: epoch 137, loss 0.6787481904029846, acc=0.6805555820465088, loss=0.6787481904029846
train: epoch 138, loss 0.6803138852119446, acc=0.6658889055252075, loss=0.6803138852119446
test: epoch 138, loss 0.6787399053573608, acc=0.6805555820465088, loss=0.6787399053573608
train: epoch 139, loss 0.6804990172386169, acc=0.6690000295639038, loss=0.6804990172386169
test: epoch 139, loss 0.6787687540054321, acc=0.6805555820465088, loss=0.6787687540054321
train: epoch 140, loss 0.6804742813110352, acc=0.6663333177566528, loss=0.6804742813110352
test: epoch 140, loss 0.6787293553352356, acc=0.6805555820465088, loss=0.6787293553352356
train: epoch 141, loss 0.7667989134788513, acc=0.6553333401679993, loss=0.7667989134788513
test: epoch 141, loss 0.9228183627128601, acc=0.6277777552604675, loss=0.9228183627128601
train: epoch 142, loss 0.7631857395172119, acc=0.6442777514457703, loss=0.7631857395172119
test: epoch 142, loss 0.7277514934539795, acc=0.6611111164093018, loss=0.7277514934539795
train: epoch 143, loss 0.7287028431892395, acc=0.6432222127914429, loss=0.7287028431892395
test: epoch 143, loss 0.725494921207428, acc=0.6611111164093018, loss=0.725494921207428
train: epoch 144, loss 0.7287085056304932, acc=0.6399444341659546, loss=0.7287085056304932
test: epoch 144, loss 0.7329163551330566, acc=0.6583333611488342, loss=0.7329163551330566
train: epoch 145, loss 0.7417750954627991, acc=0.6438888907432556, loss=0.7417750954627991
test: epoch 145, loss 1.005066990852356, acc=0.6555555462837219, loss=1.005066990852356
train: epoch 146, loss 0.8450379371643066, acc=0.6294999718666077, loss=0.8450379371643066
test: epoch 146, loss 0.7617430090904236, acc=0.6472222208976746, loss=0.7617430090904236
train: epoch 147, loss 0.7885143160820007, acc=0.6255555748939514, loss=0.7885143160820007
test: epoch 147, loss 0.8025402426719666, acc=0.6416666507720947, loss=0.8025402426719666
train: epoch 148, loss 0.7467272281646729, acc=0.6384999752044678, loss=0.7467272281646729
test: epoch 148, loss 0.7194940447807312, acc=0.6583333611488342, loss=0.7194940447807312
train: epoch 149, loss 0.7047024965286255, acc=0.6449999809265137, loss=0.7047024965286255
test: epoch 149, loss 0.6766102313995361, acc=0.6722221970558167, loss=0.6766102313995361
train: epoch 150, loss 0.7221622467041016, acc=0.6528333425521851, loss=0.7221622467041016
test: epoch 150, loss 0.7476773858070374, acc=0.6611111164093018, loss=0.7476773858070374
