# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=1", "--temp_decay=1", "--one_hot=0", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=1161329412, receiver_embed_dim=128, save_run=0, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=1161329412, receiver_embed_dim=128, save_run=False, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.7112600803375244, acc=0.1097777783870697, loss=2.7112600803375244
test: epoch 1, loss 2.959825277328491, acc=0.125, loss=2.959825277328491
train: epoch 2, loss 2.0007264614105225, acc=0.2216111123561859, loss=2.0007264614105225
test: epoch 2, loss 2.487356662750244, acc=0.18888889253139496, loss=2.487356662750244
train: epoch 3, loss 1.6807737350463867, acc=0.30222222208976746, loss=1.6807737350463867
test: epoch 3, loss 2.0582895278930664, acc=0.22777777910232544, loss=2.0582895278930664
train: epoch 4, loss 1.5314456224441528, acc=0.36605554819107056, loss=1.5314456224441528
test: epoch 4, loss 1.790445327758789, acc=0.32499998807907104, loss=1.790445327758789
train: epoch 5, loss 1.4121344089508057, acc=0.4095555543899536, loss=1.4121344089508057
test: epoch 5, loss 1.8122870922088623, acc=0.25833332538604736, loss=1.8122870922088623
train: epoch 6, loss 1.3054473400115967, acc=0.4577222168445587, loss=1.3054473400115967
test: epoch 6, loss 1.9239858388900757, acc=0.25555557012557983, loss=1.9239858388900757
train: epoch 7, loss 1.2519546747207642, acc=0.47566667199134827, loss=1.2519546747207642
test: epoch 7, loss 1.5285719633102417, acc=0.3472222089767456, loss=1.5285719633102417
train: epoch 8, loss 1.1369045972824097, acc=0.5291666388511658, loss=1.1369045972824097
test: epoch 8, loss 1.7057714462280273, acc=0.2944444417953491, loss=1.7057714462280273
train: epoch 9, loss 1.1004655361175537, acc=0.5314444303512573, loss=1.1004655361175537
test: epoch 9, loss 1.7588002681732178, acc=0.31111112236976624, loss=1.7588002681732178
train: epoch 10, loss 1.0517983436584473, acc=0.5568888783454895, loss=1.0517983436584473
test: epoch 10, loss 1.7192044258117676, acc=0.3499999940395355, loss=1.7192044258117676
train: epoch 11, loss 0.9901936054229736, acc=0.5881111025810242, loss=0.9901936054229736
test: epoch 11, loss 1.6187087297439575, acc=0.3472222089767456, loss=1.6187087297439575
train: epoch 12, loss 0.9855344891548157, acc=0.5843889117240906, loss=0.9855344891548157
test: epoch 12, loss 1.453271508216858, acc=0.38333332538604736, loss=1.453271508216858
train: epoch 13, loss 0.945304811000824, acc=0.6072221994400024, loss=0.945304811000824
test: epoch 13, loss 1.4861074686050415, acc=0.4166666567325592, loss=1.4861074686050415
train: epoch 14, loss 0.9268316626548767, acc=0.6159999966621399, loss=0.9268316626548767
test: epoch 14, loss 1.4082483053207397, acc=0.42500001192092896, loss=1.4082483053207397
train: epoch 15, loss 0.9186979532241821, acc=0.620722234249115, loss=0.9186979532241821
test: epoch 15, loss 1.5024285316467285, acc=0.36944442987442017, loss=1.5024285316467285
train: epoch 16, loss 0.8495003581047058, acc=0.6483333110809326, loss=0.8495003581047058
test: epoch 16, loss 1.3831545114517212, acc=0.43611112236976624, loss=1.3831545114517212
train: epoch 17, loss 0.8390464782714844, acc=0.6575000286102295, loss=0.8390464782714844
test: epoch 17, loss 1.5072429180145264, acc=0.4027777910232544, loss=1.5072429180145264
train: epoch 18, loss 0.7921776175498962, acc=0.6735000014305115, loss=0.7921776175498962
test: epoch 18, loss 1.7199223041534424, acc=0.3888888955116272, loss=1.7199223041534424
train: epoch 19, loss 0.8150295615196228, acc=0.664222240447998, loss=0.8150295615196228
test: epoch 19, loss 1.5429168939590454, acc=0.3444444537162781, loss=1.5429168939590454
train: epoch 20, loss 0.7781848311424255, acc=0.6786666512489319, loss=0.7781848311424255
test: epoch 20, loss 1.4739550352096558, acc=0.31388887763023376, loss=1.4739550352096558
train: epoch 21, loss 0.7624029517173767, acc=0.6916666626930237, loss=0.7624029517173767
test: epoch 21, loss 1.5222499370574951, acc=0.375, loss=1.5222499370574951
train: epoch 22, loss 0.7718997597694397, acc=0.6804999709129333, loss=0.7718997597694397
test: epoch 22, loss 1.438879132270813, acc=0.3916666805744171, loss=1.438879132270813
train: epoch 23, loss 0.7446398138999939, acc=0.6929444670677185, loss=0.7446398138999939
test: epoch 23, loss 1.405673623085022, acc=0.42500001192092896, loss=1.405673623085022
train: epoch 24, loss 0.7399865388870239, acc=0.6976110935211182, loss=0.7399865388870239
test: epoch 24, loss 1.3160427808761597, acc=0.5166666507720947, loss=1.3160427808761597
train: epoch 25, loss 0.7327868342399597, acc=0.6972222328186035, loss=0.7327868342399597
test: epoch 25, loss 1.2891613245010376, acc=0.5055555701255798, loss=1.2891613245010376
train: epoch 26, loss 0.7263120412826538, acc=0.7026666402816772, loss=0.7263120412826538
test: epoch 26, loss 1.3672268390655518, acc=0.48055556416511536, loss=1.3672268390655518
train: epoch 27, loss 0.7102429270744324, acc=0.7108888626098633, loss=0.7102429270744324
test: epoch 27, loss 1.2498399019241333, acc=0.44999998807907104, loss=1.2498399019241333
train: epoch 28, loss 0.7179217338562012, acc=0.7059444189071655, loss=0.7179217338562012
test: epoch 28, loss 1.4410812854766846, acc=0.46388888359069824, loss=1.4410812854766846
train: epoch 29, loss 0.694385290145874, acc=0.7179999947547913, loss=0.694385290145874
test: epoch 29, loss 1.3430593013763428, acc=0.4583333432674408, loss=1.3430593013763428
train: epoch 30, loss 0.6555013656616211, acc=0.7308333516120911, loss=0.6555013656616211
test: epoch 30, loss 1.2073955535888672, acc=0.5305555462837219, loss=1.2073955535888672
train: epoch 31, loss 0.6564920544624329, acc=0.734666645526886, loss=0.6564920544624329
test: epoch 31, loss 1.323403239250183, acc=0.4583333432674408, loss=1.323403239250183
train: epoch 32, loss 0.6550019383430481, acc=0.7349444627761841, loss=0.6550019383430481
test: epoch 32, loss 1.1582999229431152, acc=0.5388888716697693, loss=1.1582999229431152
train: epoch 33, loss 0.6453614830970764, acc=0.738777756690979, loss=0.6453614830970764
test: epoch 33, loss 1.230412483215332, acc=0.519444465637207, loss=1.230412483215332
train: epoch 34, loss 0.6335763931274414, acc=0.7410555481910706, loss=0.6335763931274414
test: epoch 34, loss 1.2759040594100952, acc=0.4833333194255829, loss=1.2759040594100952
train: epoch 35, loss 0.6609587073326111, acc=0.7364444732666016, loss=0.6609587073326111
test: epoch 35, loss 1.1659783124923706, acc=0.5027777552604675, loss=1.1659783124923706
train: epoch 36, loss 0.624871551990509, acc=0.7484444379806519, loss=0.624871551990509
test: epoch 36, loss 1.61834716796875, acc=0.4416666626930237, loss=1.61834716796875
train: epoch 37, loss 0.6104980707168579, acc=0.7507777810096741, loss=0.6104980707168579
test: epoch 37, loss 1.3029530048370361, acc=0.47777777910232544, loss=1.3029530048370361
train: epoch 38, loss 0.6240529417991638, acc=0.7471666932106018, loss=0.6240529417991638
test: epoch 38, loss 1.2549011707305908, acc=0.5694444179534912, loss=1.2549011707305908
train: epoch 39, loss 0.6194190979003906, acc=0.7482777833938599, loss=0.6194190979003906
test: epoch 39, loss 1.266854166984558, acc=0.43888887763023376, loss=1.266854166984558
train: epoch 40, loss 0.621806263923645, acc=0.745555579662323, loss=0.621806263923645
test: epoch 40, loss 1.1729402542114258, acc=0.550000011920929, loss=1.1729402542114258
train: epoch 41, loss 0.6035380363464355, acc=0.7526111006736755, loss=0.6035380363464355
test: epoch 41, loss 1.2690331935882568, acc=0.4694444537162781, loss=1.2690331935882568
train: epoch 42, loss 0.5796490907669067, acc=0.761888861656189, loss=0.5796490907669067
test: epoch 42, loss 1.37880277633667, acc=0.5111111402511597, loss=1.37880277633667
train: epoch 43, loss 0.5874444842338562, acc=0.7574999928474426, loss=0.5874444842338562
test: epoch 43, loss 1.197212815284729, acc=0.5277777910232544, loss=1.197212815284729
train: epoch 44, loss 0.5743317008018494, acc=0.7657222151756287, loss=0.5743317008018494
test: epoch 44, loss 1.2635498046875, acc=0.4972222149372101, loss=1.2635498046875
train: epoch 45, loss 0.5800923109054565, acc=0.7616666555404663, loss=0.5800923109054565
test: epoch 45, loss 1.31596040725708, acc=0.45277777314186096, loss=1.31596040725708
train: epoch 46, loss 0.5673660039901733, acc=0.7641666531562805, loss=0.5673660039901733
test: epoch 46, loss 1.2782745361328125, acc=0.4972222149372101, loss=1.2782745361328125
train: epoch 47, loss 0.563315212726593, acc=0.7668889164924622, loss=0.563315212726593
test: epoch 47, loss 1.4343417882919312, acc=0.48055556416511536, loss=1.4343417882919312
train: epoch 48, loss 0.5536783933639526, acc=0.7721111178398132, loss=0.5536783933639526
test: epoch 48, loss 1.3204339742660522, acc=0.4583333432674408, loss=1.3204339742660522
train: epoch 49, loss 0.5523012280464172, acc=0.7762222290039062, loss=0.5523012280464172
test: epoch 49, loss 1.3009358644485474, acc=0.5249999761581421, loss=1.3009358644485474
train: epoch 50, loss 0.5616248250007629, acc=0.7691110968589783, loss=0.5616248250007629
test: epoch 50, loss 1.4302115440368652, acc=0.5138888955116272, loss=1.4302115440368652
train: epoch 51, loss 0.5523676872253418, acc=0.7763888835906982, loss=0.5523676872253418
test: epoch 51, loss 1.4508819580078125, acc=0.46666666865348816, loss=1.4508819580078125
train: epoch 52, loss 0.527678370475769, acc=0.7822777628898621, loss=0.527678370475769
test: epoch 52, loss 1.422235131263733, acc=0.5111111402511597, loss=1.422235131263733
train: epoch 53, loss 0.5438788533210754, acc=0.7771666646003723, loss=0.5438788533210754
test: epoch 53, loss 1.2476752996444702, acc=0.5138888955116272, loss=1.2476752996444702
train: epoch 54, loss 0.5627092719078064, acc=0.7680000066757202, loss=0.5627092719078064
test: epoch 54, loss 1.372420310974121, acc=0.5027777552604675, loss=1.372420310974121
train: epoch 55, loss 0.5402028560638428, acc=0.7785555720329285, loss=0.5402028560638428
test: epoch 55, loss 1.2427598237991333, acc=0.4722222089767456, loss=1.2427598237991333
train: epoch 56, loss 0.5305323600769043, acc=0.7822777628898621, loss=0.5305323600769043
test: epoch 56, loss 1.136223554611206, acc=0.5222222208976746, loss=1.136223554611206
train: epoch 57, loss 0.4969865679740906, acc=0.7980555295944214, loss=0.4969865679740906
test: epoch 57, loss 1.1968835592269897, acc=0.5611110925674438, loss=1.1968835592269897
train: epoch 58, loss 0.5287560820579529, acc=0.7788333296775818, loss=0.5287560820579529
test: epoch 58, loss 1.3643735647201538, acc=0.5, loss=1.3643735647201538
train: epoch 59, loss 0.5059539079666138, acc=0.7905555367469788, loss=0.5059539079666138
test: epoch 59, loss 1.3972527980804443, acc=0.43888887763023376, loss=1.3972527980804443
train: epoch 60, loss 0.49073660373687744, acc=0.796833336353302, loss=0.49073660373687744
test: epoch 60, loss 1.6350796222686768, acc=0.5666666626930237, loss=1.6350796222686768
train: epoch 61, loss 0.5311087369918823, acc=0.7831666469573975, loss=0.5311087369918823
test: epoch 61, loss 1.4520460367202759, acc=0.5305555462837219, loss=1.4520460367202759
train: epoch 62, loss 0.4902099370956421, acc=0.8008333444595337, loss=0.4902099370956421
test: epoch 62, loss 1.3786917924880981, acc=0.5083333253860474, loss=1.3786917924880981
train: epoch 63, loss 0.49779072403907776, acc=0.7993333339691162, loss=0.49779072403907776
test: epoch 63, loss 1.1613894701004028, acc=0.5277777910232544, loss=1.1613894701004028
train: epoch 64, loss 0.4826805591583252, acc=0.8051666617393494, loss=0.4826805591583252
test: epoch 64, loss 1.1086252927780151, acc=0.5694444179534912, loss=1.1086252927780151
train: epoch 65, loss 0.4971117377281189, acc=0.7978333234786987, loss=0.4971117377281189
test: epoch 65, loss 1.2491788864135742, acc=0.4888888895511627, loss=1.2491788864135742
train: epoch 66, loss 0.5125042796134949, acc=0.789555549621582, loss=0.5125042796134949
test: epoch 66, loss 1.5689226388931274, acc=0.4194444417953491, loss=1.5689226388931274
train: epoch 67, loss 0.4770446717739105, acc=0.801111102104187, loss=0.4770446717739105
test: epoch 67, loss 1.228041410446167, acc=0.4555555582046509, loss=1.228041410446167
train: epoch 68, loss 0.48984453082084656, acc=0.799833357334137, loss=0.48984453082084656
test: epoch 68, loss 1.3489360809326172, acc=0.49166667461395264, loss=1.3489360809326172
train: epoch 69, loss 0.4922788441181183, acc=0.796500027179718, loss=0.4922788441181183
test: epoch 69, loss 1.1045056581497192, acc=0.5249999761581421, loss=1.1045056581497192
train: epoch 70, loss 0.49965521693229675, acc=0.7934444546699524, loss=0.49965521693229675
test: epoch 70, loss 1.1595897674560547, acc=0.5472221970558167, loss=1.1595897674560547
train: epoch 71, loss 0.4945777356624603, acc=0.7960000038146973, loss=0.4945777356624603
test: epoch 71, loss 1.1856797933578491, acc=0.49444442987442017, loss=1.1856797933578491
train: epoch 72, loss 0.4913301467895508, acc=0.7999444603919983, loss=0.4913301467895508
test: epoch 72, loss 1.086850881576538, acc=0.5722222328186035, loss=1.086850881576538
train: epoch 73, loss 0.4748587906360626, acc=0.8073889017105103, loss=0.4748587906360626
test: epoch 73, loss 1.2048105001449585, acc=0.5249999761581421, loss=1.2048105001449585
train: epoch 74, loss 0.47598809003829956, acc=0.8066111207008362, loss=0.47598809003829956
test: epoch 74, loss 1.0854597091674805, acc=0.5861111283302307, loss=1.0854597091674805
train: epoch 75, loss 0.43857043981552124, acc=0.8187777996063232, loss=0.43857043981552124
test: epoch 75, loss 1.1218043565750122, acc=0.5527777671813965, loss=1.1218043565750122
train: epoch 76, loss 0.4581308662891388, acc=0.8159999847412109, loss=0.4581308662891388
test: epoch 76, loss 1.1579302549362183, acc=0.5166666507720947, loss=1.1579302549362183
train: epoch 77, loss 0.4666577875614166, acc=0.8086110949516296, loss=0.4666577875614166
test: epoch 77, loss 1.435327172279358, acc=0.4583333432674408, loss=1.435327172279358
train: epoch 78, loss 0.4807899296283722, acc=0.8055555820465088, loss=0.4807899296283722
test: epoch 78, loss 1.159404993057251, acc=0.5944444537162781, loss=1.159404993057251
train: epoch 79, loss 0.4752214848995209, acc=0.8058333396911621, loss=0.4752214848995209
test: epoch 79, loss 1.0610651969909668, acc=0.6388888955116272, loss=1.0610651969909668
train: epoch 80, loss 0.5008230209350586, acc=0.7952777743339539, loss=0.5008230209350586
test: epoch 80, loss 1.2362301349639893, acc=0.49444442987442017, loss=1.2362301349639893
train: epoch 81, loss 0.48622846603393555, acc=0.795722246170044, loss=0.48622846603393555
test: epoch 81, loss 1.2400999069213867, acc=0.5361111164093018, loss=1.2400999069213867
train: epoch 82, loss 0.49140992760658264, acc=0.7936111092567444, loss=0.49140992760658264
test: epoch 82, loss 1.4379717111587524, acc=0.4861111044883728, loss=1.4379717111587524
train: epoch 83, loss 0.4798015356063843, acc=0.7994999885559082, loss=0.4798015356063843
test: epoch 83, loss 1.2917697429656982, acc=0.48055556416511536, loss=1.2917697429656982
train: epoch 84, loss 0.4672323167324066, acc=0.8070555329322815, loss=0.4672323167324066
test: epoch 84, loss 1.177855134010315, acc=0.5611110925674438, loss=1.177855134010315
train: epoch 85, loss 0.472128689289093, acc=0.8043888807296753, loss=0.472128689289093
test: epoch 85, loss 1.2527068853378296, acc=0.5527777671813965, loss=1.2527068853378296
train: epoch 86, loss 0.4732211232185364, acc=0.8034444451332092, loss=0.4732211232185364
test: epoch 86, loss 1.0420881509780884, acc=0.5888888835906982, loss=1.0420881509780884
train: epoch 87, loss 0.4576456844806671, acc=0.8159999847412109, loss=0.4576456844806671
test: epoch 87, loss 1.0491801500320435, acc=0.5388888716697693, loss=1.0491801500320435
train: epoch 88, loss 0.459323912858963, acc=0.808055579662323, loss=0.459323912858963
test: epoch 88, loss 1.2342671155929565, acc=0.5388888716697693, loss=1.2342671155929565
train: epoch 89, loss 0.47201451659202576, acc=0.808222234249115, loss=0.47201451659202576
test: epoch 89, loss 1.6375302076339722, acc=0.48055556416511536, loss=1.6375302076339722
train: epoch 90, loss 0.4601481854915619, acc=0.8116666674613953, loss=0.4601481854915619
test: epoch 90, loss 1.4319216012954712, acc=0.5416666865348816, loss=1.4319216012954712
train: epoch 91, loss 0.4646550118923187, acc=0.8107777833938599, loss=0.4646550118923187
test: epoch 91, loss 0.9980732798576355, acc=0.5472221970558167, loss=0.9980732798576355
train: epoch 92, loss 0.48026055097579956, acc=0.8045555353164673, loss=0.48026055097579956
test: epoch 92, loss 1.1897001266479492, acc=0.5333333611488342, loss=1.1897001266479492
train: epoch 93, loss 0.44703057408332825, acc=0.816277801990509, loss=0.44703057408332825
test: epoch 93, loss 1.2967098951339722, acc=0.5388888716697693, loss=1.2967098951339722
train: epoch 94, loss 0.45610982179641724, acc=0.8152222037315369, loss=0.45610982179641724
test: epoch 94, loss 1.1397868394851685, acc=0.574999988079071, loss=1.1397868394851685
train: epoch 95, loss 0.429860383272171, acc=0.8268333077430725, loss=0.429860383272171
test: epoch 95, loss 1.005477786064148, acc=0.5916666388511658, loss=1.005477786064148
train: epoch 96, loss 0.4574696719646454, acc=0.8151111006736755, loss=0.4574696719646454
test: epoch 96, loss 1.2253211736679077, acc=0.5388888716697693, loss=1.2253211736679077
train: epoch 97, loss 0.47496530413627625, acc=0.8096666932106018, loss=0.47496530413627625
test: epoch 97, loss 1.1988967657089233, acc=0.5444444417953491, loss=1.1988967657089233
train: epoch 98, loss 0.4612572193145752, acc=0.8100555539131165, loss=0.4612572193145752
test: epoch 98, loss 1.277532935142517, acc=0.5583333373069763, loss=1.277532935142517
train: epoch 99, loss 0.45988544821739197, acc=0.8140555620193481, loss=0.45988544821739197
test: epoch 99, loss 1.3002859354019165, acc=0.5666666626930237, loss=1.3002859354019165
train: epoch 100, loss 0.4212144613265991, acc=0.8311111330986023, loss=0.4212144613265991
test: epoch 100, loss 1.1903002262115479, acc=0.6138888597488403, loss=1.1903002262115479
train: epoch 101, loss 0.44978445768356323, acc=0.8192222118377686, loss=0.44978445768356323
test: epoch 101, loss 1.3152809143066406, acc=0.4888888895511627, loss=1.3152809143066406
train: epoch 102, loss 0.43410348892211914, acc=0.8249444365501404, loss=0.43410348892211914
test: epoch 102, loss 1.1451764106750488, acc=0.6000000238418579, loss=1.1451764106750488
train: epoch 103, loss 0.42953982949256897, acc=0.8289444446563721, loss=0.42953982949256897
test: epoch 103, loss 1.2460670471191406, acc=0.5777778029441833, loss=1.2460670471191406
train: epoch 104, loss 0.4695112705230713, acc=0.8056666851043701, loss=0.4695112705230713
test: epoch 104, loss 1.2322585582733154, acc=0.574999988079071, loss=1.2322585582733154
train: epoch 105, loss 0.47349220514297485, acc=0.809333324432373, loss=0.47349220514297485
test: epoch 105, loss 1.2069164514541626, acc=0.5666666626930237, loss=1.2069164514541626
train: epoch 106, loss 0.4304977357387543, acc=0.8217222094535828, loss=0.4304977357387543
test: epoch 106, loss 1.0796241760253906, acc=0.5611110925674438, loss=1.0796241760253906
train: epoch 107, loss 0.44454413652420044, acc=0.8223888874053955, loss=0.44454413652420044
test: epoch 107, loss 0.9854278564453125, acc=0.5861111283302307, loss=0.9854278564453125
train: epoch 108, loss 0.43617841601371765, acc=0.8204444646835327, loss=0.43617841601371765
test: epoch 108, loss 1.051389217376709, acc=0.644444465637207, loss=1.051389217376709
train: epoch 109, loss 0.4345419108867645, acc=0.8253333568572998, loss=0.4345419108867645
test: epoch 109, loss 1.4101219177246094, acc=0.5388888716697693, loss=1.4101219177246094
train: epoch 110, loss 0.4021317958831787, acc=0.8377222418785095, loss=0.4021317958831787
test: epoch 110, loss 1.1879386901855469, acc=0.5944444537162781, loss=1.1879386901855469
train: epoch 111, loss 0.4787790775299072, acc=0.808222234249115, loss=0.4787790775299072
test: epoch 111, loss 1.1410351991653442, acc=0.6416666507720947, loss=1.1410351991653442
train: epoch 112, loss 0.42319101095199585, acc=0.8323333263397217, loss=0.42319101095199585
test: epoch 112, loss 1.1804065704345703, acc=0.5944444537162781, loss=1.1804065704345703
train: epoch 113, loss 0.4135798513889313, acc=0.8337222337722778, loss=0.4135798513889313
test: epoch 113, loss 1.2941991090774536, acc=0.5555555820465088, loss=1.2941991090774536
train: epoch 114, loss 0.4552060663700104, acc=0.8182222247123718, loss=0.4552060663700104
test: epoch 114, loss 1.5251917839050293, acc=0.5111111402511597, loss=1.5251917839050293
train: epoch 115, loss 0.4243382215499878, acc=0.8286666870117188, loss=0.4243382215499878
test: epoch 115, loss 1.219844937324524, acc=0.5611110925674438, loss=1.219844937324524
train: epoch 116, loss 0.4149094223976135, acc=0.8342221975326538, loss=0.4149094223976135
test: epoch 116, loss 1.0210282802581787, acc=0.5888888835906982, loss=1.0210282802581787
train: epoch 117, loss 0.47150397300720215, acc=0.8147777915000916, loss=0.47150397300720215
test: epoch 117, loss 1.0008999109268188, acc=0.5972222089767456, loss=1.0008999109268188
train: epoch 118, loss 0.39768660068511963, acc=0.8375555276870728, loss=0.39768660068511963
test: epoch 118, loss 1.3592898845672607, acc=0.5138888955116272, loss=1.3592898845672607
train: epoch 119, loss 0.43435588479042053, acc=0.8231666684150696, loss=0.43435588479042053
test: epoch 119, loss 1.223410964012146, acc=0.6111111044883728, loss=1.223410964012146
train: epoch 120, loss 0.451261043548584, acc=0.8195000290870667, loss=0.451261043548584
test: epoch 120, loss 1.2734726667404175, acc=0.5111111402511597, loss=1.2734726667404175
train: epoch 121, loss 0.4494633376598358, acc=0.8209444284439087, loss=0.4494633376598358
test: epoch 121, loss 1.0912796258926392, acc=0.5888888835906982, loss=1.0912796258926392
train: epoch 122, loss 0.4724501669406891, acc=0.8088333606719971, loss=0.4724501669406891
test: epoch 122, loss 1.1293953657150269, acc=0.605555534362793, loss=1.1293953657150269
train: epoch 123, loss 0.42776674032211304, acc=0.8247777819633484, loss=0.42776674032211304
test: epoch 123, loss 1.2140741348266602, acc=0.5972222089767456, loss=1.2140741348266602
train: epoch 124, loss 0.45893386006355286, acc=0.8138333559036255, loss=0.45893386006355286
test: epoch 124, loss 1.3501390218734741, acc=0.5888888835906982, loss=1.3501390218734741
train: epoch 125, loss 0.48929911851882935, acc=0.8011666536331177, loss=0.48929911851882935
test: epoch 125, loss 1.1260781288146973, acc=0.6361111402511597, loss=1.1260781288146973
train: epoch 126, loss 0.44653165340423584, acc=0.8207777738571167, loss=0.44653165340423584
test: epoch 126, loss 0.9909610748291016, acc=0.6388888955116272, loss=0.9909610748291016
train: epoch 127, loss 0.4096173644065857, acc=0.8329444527626038, loss=0.4096173644065857
test: epoch 127, loss 1.3684985637664795, acc=0.5694444179534912, loss=1.3684985637664795
train: epoch 128, loss 0.48902472853660583, acc=0.8026666641235352, loss=0.48902472853660583
test: epoch 128, loss 1.1263985633850098, acc=0.5611110925674438, loss=1.1263985633850098
train: epoch 129, loss 0.41756710410118103, acc=0.8305555582046509, loss=0.41756710410118103
test: epoch 129, loss 1.0453674793243408, acc=0.6194444298744202, loss=1.0453674793243408
train: epoch 130, loss 0.43683335185050964, acc=0.8228333592414856, loss=0.43683335185050964
test: epoch 130, loss 1.2502355575561523, acc=0.5888888835906982, loss=1.2502355575561523
train: epoch 131, loss 0.42324140667915344, acc=0.825166642665863, loss=0.42324140667915344
test: epoch 131, loss 1.0609016418457031, acc=0.5916666388511658, loss=1.0609016418457031
train: epoch 132, loss 0.4141339063644409, acc=0.8276110887527466, loss=0.4141339063644409
test: epoch 132, loss 1.2938951253890991, acc=0.5972222089767456, loss=1.2938951253890991
train: epoch 133, loss 0.47663816809654236, acc=0.8091111183166504, loss=0.47663816809654236
test: epoch 133, loss 1.2566587924957275, acc=0.5888888835906982, loss=1.2566587924957275
train: epoch 134, loss 0.39803236722946167, acc=0.8326666951179504, loss=0.39803236722946167
test: epoch 134, loss 1.2686107158660889, acc=0.5694444179534912, loss=1.2686107158660889
train: epoch 135, loss 0.4179064929485321, acc=0.8294444680213928, loss=0.4179064929485321
test: epoch 135, loss 1.3994028568267822, acc=0.5777778029441833, loss=1.3994028568267822
train: epoch 136, loss 0.42557138204574585, acc=0.8256666660308838, loss=0.42557138204574585
test: epoch 136, loss 1.1558233499526978, acc=0.6416666507720947, loss=1.1558233499526978
train: epoch 137, loss 0.42681342363357544, acc=0.8265555500984192, loss=0.42681342363357544
test: epoch 137, loss 1.1170512437820435, acc=0.6027777791023254, loss=1.1170512437820435
train: epoch 138, loss 0.42255935072898865, acc=0.8286111354827881, loss=0.42255935072898865
test: epoch 138, loss 1.0394728183746338, acc=0.625, loss=1.0394728183746338
train: epoch 139, loss 0.4086470901966095, acc=0.8332222104072571, loss=0.4086470901966095
test: epoch 139, loss 0.9721729159355164, acc=0.675000011920929, loss=0.9721729159355164
train: epoch 140, loss 0.4283352196216583, acc=0.8264999985694885, loss=0.4283352196216583
test: epoch 140, loss 1.2447155714035034, acc=0.5888888835906982, loss=1.2447155714035034
train: epoch 141, loss 0.39932993054389954, acc=0.8389999866485596, loss=0.39932993054389954
test: epoch 141, loss 1.207259178161621, acc=0.5861111283302307, loss=1.207259178161621
train: epoch 142, loss 0.44542714953422546, acc=0.8226666450500488, loss=0.44542714953422546
test: epoch 142, loss 1.2491704225540161, acc=0.5444444417953491, loss=1.2491704225540161
train: epoch 143, loss 0.4322146773338318, acc=0.8231111168861389, loss=0.4322146773338318
test: epoch 143, loss 1.411787748336792, acc=0.5777778029441833, loss=1.411787748336792
train: epoch 144, loss 0.4448011815547943, acc=0.820388913154602, loss=0.4448011815547943
test: epoch 144, loss 1.4481241703033447, acc=0.5638889074325562, loss=1.4481241703033447
train: epoch 145, loss 0.5089823603630066, acc=0.7983333468437195, loss=0.5089823603630066
test: epoch 145, loss 1.200673222541809, acc=0.5972222089767456, loss=1.200673222541809
train: epoch 146, loss 0.4302508234977722, acc=0.8267777562141418, loss=0.4302508234977722
test: epoch 146, loss 1.2763375043869019, acc=0.5972222089767456, loss=1.2763375043869019
train: epoch 147, loss 0.4458141624927521, acc=0.8211666941642761, loss=0.4458141624927521
test: epoch 147, loss 1.2521064281463623, acc=0.5944444537162781, loss=1.2521064281463623
train: epoch 148, loss 0.4545114040374756, acc=0.8248888850212097, loss=0.4545114040374756
test: epoch 148, loss 1.2422899007797241, acc=0.5722222328186035, loss=1.2422899007797241
train: epoch 149, loss 0.6652949452400208, acc=0.7011666893959045, loss=0.6652949452400208
test: epoch 149, loss 1.3227777481079102, acc=0.5249999761581421, loss=1.3227777481079102
train: epoch 150, loss 0.7992247939109802, acc=0.6855000257492065, loss=0.7992247939109802
test: epoch 150, loss 1.5461132526397705, acc=0.5166666507720947, loss=1.5461132526397705
