# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=1.5", "--temp_decay=0.99", "--one_hot=false", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1109981355, receiver_embed_dim=128, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.997562885284424, acc=0.09399999678134918, loss=2.997562885284424
test: epoch 1, loss 2.8142471313476562, acc=0.11944444477558136, loss=2.8142471313476562
train: epoch 2, loss 1.7598257064819336, acc=0.2885555624961853, loss=1.7598257064819336
test: epoch 2, loss 2.3941233158111572, acc=0.15833333134651184, loss=2.3941233158111572
train: epoch 3, loss 1.4320927858352661, acc=0.40522223711013794, loss=1.4320927858352661
test: epoch 3, loss 2.5358245372772217, acc=0.16944444179534912, loss=2.5358245372772217
train: epoch 4, loss 1.2651365995407104, acc=0.47644445300102234, loss=1.2651365995407104
test: epoch 4, loss 2.464101791381836, acc=0.1805555522441864, loss=2.464101791381836
train: epoch 5, loss 1.1678475141525269, acc=0.5174444317817688, loss=1.1678475141525269
test: epoch 5, loss 2.4030959606170654, acc=0.21111111342906952, loss=2.4030959606170654
train: epoch 6, loss 1.0661481618881226, acc=0.5622777938842773, loss=1.0661481618881226
test: epoch 6, loss 2.0703206062316895, acc=0.25833332538604736, loss=2.0703206062316895
train: epoch 7, loss 0.9931971430778503, acc=0.5901666879653931, loss=0.9931971430778503
test: epoch 7, loss 2.008129835128784, acc=0.2777777910232544, loss=2.008129835128784
train: epoch 8, loss 0.9425860047340393, acc=0.6146666407585144, loss=0.9425860047340393
test: epoch 8, loss 1.8810042142868042, acc=0.2944444417953491, loss=1.8810042142868042
train: epoch 9, loss 0.8787212371826172, acc=0.6464444398880005, loss=0.8787212371826172
test: epoch 9, loss 1.9826393127441406, acc=0.28611111640930176, loss=1.9826393127441406
train: epoch 10, loss 0.8364349007606506, acc=0.6610555648803711, loss=0.8364349007606506
test: epoch 10, loss 2.0704638957977295, acc=0.32499998807907104, loss=2.0704638957977295
train: epoch 11, loss 0.7941720485687256, acc=0.680388867855072, loss=0.7941720485687256
test: epoch 11, loss 1.7428865432739258, acc=0.32777777314186096, loss=1.7428865432739258
train: epoch 12, loss 0.7655858397483826, acc=0.6945555806159973, loss=0.7655858397483826
test: epoch 12, loss 1.8549638986587524, acc=0.3083333373069763, loss=1.8549638986587524
train: epoch 13, loss 0.7390357851982117, acc=0.703000009059906, loss=0.7390357851982117
test: epoch 13, loss 1.9522013664245605, acc=0.3305555582046509, loss=1.9522013664245605
train: epoch 14, loss 0.6996815204620361, acc=0.7162222266197205, loss=0.6996815204620361
test: epoch 14, loss 1.7823086977005005, acc=0.3499999940395355, loss=1.7823086977005005
train: epoch 15, loss 0.6569480895996094, acc=0.7336666584014893, loss=0.6569480895996094
test: epoch 15, loss 1.8219321966171265, acc=0.3444444537162781, loss=1.8219321966171265
train: epoch 16, loss 0.656836986541748, acc=0.7387222051620483, loss=0.656836986541748
test: epoch 16, loss 1.7172540426254272, acc=0.35555556416511536, loss=1.7172540426254272
train: epoch 17, loss 0.6328047513961792, acc=0.7510555386543274, loss=0.6328047513961792
test: epoch 17, loss 1.616416335105896, acc=0.3888888955116272, loss=1.616416335105896
train: epoch 18, loss 0.6096464395523071, acc=0.7529444694519043, loss=0.6096464395523071
test: epoch 18, loss 1.775328278541565, acc=0.38055557012557983, loss=1.775328278541565
train: epoch 19, loss 0.5981802940368652, acc=0.7573333382606506, loss=0.5981802940368652
test: epoch 19, loss 1.662550926208496, acc=0.3777777850627899, loss=1.662550926208496
train: epoch 20, loss 0.5832808613777161, acc=0.766777753829956, loss=0.5832808613777161
test: epoch 20, loss 1.7584396600723267, acc=0.3861111104488373, loss=1.7584396600723267
train: epoch 21, loss 0.5884377956390381, acc=0.7618333101272583, loss=0.5884377956390381
test: epoch 21, loss 1.725083827972412, acc=0.38055557012557983, loss=1.725083827972412
train: epoch 22, loss 0.559667706489563, acc=0.7734444737434387, loss=0.559667706489563
test: epoch 22, loss 1.934296727180481, acc=0.38333332538604736, loss=1.934296727180481
train: epoch 23, loss 0.5682295560836792, acc=0.7730000019073486, loss=0.5682295560836792
test: epoch 23, loss 1.6550934314727783, acc=0.3861111104488373, loss=1.6550934314727783
train: epoch 24, loss 0.544153094291687, acc=0.7808889150619507, loss=0.544153094291687
test: epoch 24, loss 1.6273187398910522, acc=0.42500001192092896, loss=1.6273187398910522
train: epoch 25, loss 0.5440037250518799, acc=0.7848333120346069, loss=0.5440037250518799
test: epoch 25, loss 1.7577394247055054, acc=0.46388888359069824, loss=1.7577394247055054
train: epoch 26, loss 0.5340282320976257, acc=0.7869444489479065, loss=0.5340282320976257
test: epoch 26, loss 1.6197540760040283, acc=0.4416666626930237, loss=1.6197540760040283
train: epoch 27, loss 0.5189971327781677, acc=0.7953333258628845, loss=0.5189971327781677
test: epoch 27, loss 1.640647053718567, acc=0.4055555462837219, loss=1.640647053718567
train: epoch 28, loss 0.5186487436294556, acc=0.7913888692855835, loss=0.5186487436294556
test: epoch 28, loss 1.5886719226837158, acc=0.43888887763023376, loss=1.5886719226837158
train: epoch 29, loss 0.5170366764068604, acc=0.7941666841506958, loss=0.5170366764068604
test: epoch 29, loss 1.6560391187667847, acc=0.4166666567325592, loss=1.6560391187667847
train: epoch 30, loss 0.5040034055709839, acc=0.7966111302375793, loss=0.5040034055709839
test: epoch 30, loss 1.5798732042312622, acc=0.4472222328186035, loss=1.5798732042312622
train: epoch 31, loss 0.5034742951393127, acc=0.7962222099304199, loss=0.5034742951393127
test: epoch 31, loss 1.7994592189788818, acc=0.4444444477558136, loss=1.7994592189788818
train: epoch 32, loss 0.4979759752750397, acc=0.8002777695655823, loss=0.4979759752750397
test: epoch 32, loss 1.8150492906570435, acc=0.41111111640930176, loss=1.8150492906570435
train: epoch 33, loss 0.49295228719711304, acc=0.80394446849823, loss=0.49295228719711304
test: epoch 33, loss 1.5834418535232544, acc=0.4472222328186035, loss=1.5834418535232544
train: epoch 34, loss 0.4905208647251129, acc=0.8022778034210205, loss=0.4905208647251129
test: epoch 34, loss 1.7164053916931152, acc=0.4888888895511627, loss=1.7164053916931152
train: epoch 35, loss 0.4750708341598511, acc=0.8115555644035339, loss=0.4750708341598511
test: epoch 35, loss 1.785050868988037, acc=0.4416666626930237, loss=1.785050868988037
train: epoch 36, loss 0.46872881054878235, acc=0.8102777600288391, loss=0.46872881054878235
test: epoch 36, loss 1.575519323348999, acc=0.4611110985279083, loss=1.575519323348999
train: epoch 37, loss 0.48824119567871094, acc=0.8075555562973022, loss=0.48824119567871094
test: epoch 37, loss 1.6967793703079224, acc=0.4416666626930237, loss=1.6967793703079224
train: epoch 38, loss 0.4816264808177948, acc=0.8115555644035339, loss=0.4816264808177948
test: epoch 38, loss 1.6924045085906982, acc=0.4749999940395355, loss=1.6924045085906982
train: epoch 39, loss 0.4614697992801666, acc=0.8184444308280945, loss=0.4614697992801666
test: epoch 39, loss 1.8194947242736816, acc=0.4583333432674408, loss=1.8194947242736816
train: epoch 40, loss 0.4743484556674957, acc=0.8111666440963745, loss=0.4743484556674957
test: epoch 40, loss 1.514404296875, acc=0.49166667461395264, loss=1.514404296875
train: epoch 41, loss 0.46527740359306335, acc=0.8158888816833496, loss=0.46527740359306335
test: epoch 41, loss 1.8539657592773438, acc=0.4611110985279083, loss=1.8539657592773438
train: epoch 42, loss 0.46120646595954895, acc=0.8172222375869751, loss=0.46120646595954895
test: epoch 42, loss 1.7553755044937134, acc=0.42500001192092896, loss=1.7553755044937134
train: epoch 43, loss 0.46834054589271545, acc=0.8141666650772095, loss=0.46834054589271545
test: epoch 43, loss 1.5734843015670776, acc=0.49166667461395264, loss=1.5734843015670776
train: epoch 44, loss 0.45276108384132385, acc=0.8174999952316284, loss=0.45276108384132385
test: epoch 44, loss 1.7395681142807007, acc=0.5055555701255798, loss=1.7395681142807007
train: epoch 45, loss 0.4549131989479065, acc=0.8165555596351624, loss=0.4549131989479065
test: epoch 45, loss 1.712896466255188, acc=0.5027777552604675, loss=1.712896466255188
train: epoch 46, loss 0.469422310590744, acc=0.8095555305480957, loss=0.469422310590744
test: epoch 46, loss 1.4227608442306519, acc=0.46388888359069824, loss=1.4227608442306519
train: epoch 47, loss 0.4602430462837219, acc=0.8142222166061401, loss=0.4602430462837219
test: epoch 47, loss 1.7541885375976562, acc=0.4611110985279083, loss=1.7541885375976562
train: epoch 48, loss 0.46743059158325195, acc=0.8140000104904175, loss=0.46743059158325195
test: epoch 48, loss 1.5883069038391113, acc=0.46666666865348816, loss=1.5883069038391113
train: epoch 49, loss 0.46217918395996094, acc=0.8120555281639099, loss=0.46217918395996094
test: epoch 49, loss 1.617043375968933, acc=0.4749999940395355, loss=1.617043375968933
train: epoch 50, loss 0.4654552638530731, acc=0.809333324432373, loss=0.4654552638530731
test: epoch 50, loss 1.6197834014892578, acc=0.49444442987442017, loss=1.6197834014892578
train: epoch 51, loss 0.46324220299720764, acc=0.812333345413208, loss=0.46324220299720764
test: epoch 51, loss 1.864202618598938, acc=0.4888888895511627, loss=1.864202618598938
train: epoch 52, loss 0.44947704672813416, acc=0.8208333253860474, loss=0.44947704672813416
test: epoch 52, loss 1.6443127393722534, acc=0.5055555701255798, loss=1.6443127393722534
train: epoch 53, loss 0.4612148702144623, acc=0.8148333430290222, loss=0.4612148702144623
test: epoch 53, loss 1.5761560201644897, acc=0.4972222149372101, loss=1.5761560201644897
train: epoch 54, loss 0.46270567178726196, acc=0.8157222270965576, loss=0.46270567178726196
test: epoch 54, loss 1.5162127017974854, acc=0.4972222149372101, loss=1.5162127017974854
train: epoch 55, loss 0.4690600633621216, acc=0.8151111006736755, loss=0.4690600633621216
test: epoch 55, loss 1.4905660152435303, acc=0.5, loss=1.4905660152435303
train: epoch 56, loss 0.46910157799720764, acc=0.8109444379806519, loss=0.46910157799720764
test: epoch 56, loss 1.5835459232330322, acc=0.46666666865348816, loss=1.5835459232330322
train: epoch 57, loss 0.47197940945625305, acc=0.8081666827201843, loss=0.47197940945625305
test: epoch 57, loss 1.5938750505447388, acc=0.4861111044883728, loss=1.5938750505447388
train: epoch 58, loss 0.4660472869873047, acc=0.8113889098167419, loss=0.4660472869873047
test: epoch 58, loss 1.673399567604065, acc=0.4722222089767456, loss=1.673399567604065
train: epoch 59, loss 0.48159635066986084, acc=0.8081666827201843, loss=0.48159635066986084
test: epoch 59, loss 1.5282278060913086, acc=0.4583333432674408, loss=1.5282278060913086
train: epoch 60, loss 0.46578529477119446, acc=0.8141666650772095, loss=0.46578529477119446
test: epoch 60, loss 1.7012587785720825, acc=0.4555555582046509, loss=1.7012587785720825
train: epoch 61, loss 0.47357824444770813, acc=0.8098333477973938, loss=0.47357824444770813
test: epoch 61, loss 1.5685275793075562, acc=0.4722222089767456, loss=1.5685275793075562
train: epoch 62, loss 0.477236270904541, acc=0.808722198009491, loss=0.477236270904541
test: epoch 62, loss 1.5272983312606812, acc=0.4722222089767456, loss=1.5272983312606812
train: epoch 63, loss 0.4801824390888214, acc=0.8057777881622314, loss=0.4801824390888214
test: epoch 63, loss 1.5451072454452515, acc=0.48055556416511536, loss=1.5451072454452515
train: epoch 64, loss 0.47913581132888794, acc=0.805388867855072, loss=0.47913581132888794
test: epoch 64, loss 1.7567840814590454, acc=0.46388888359069824, loss=1.7567840814590454
train: epoch 65, loss 0.48175695538520813, acc=0.8065555691719055, loss=0.48175695538520813
test: epoch 65, loss 1.4261952638626099, acc=0.4861111044883728, loss=1.4261952638626099
train: epoch 66, loss 0.48000746965408325, acc=0.8063333630561829, loss=0.48000746965408325
test: epoch 66, loss 1.506127953529358, acc=0.4694444537162781, loss=1.506127953529358
train: epoch 67, loss 0.48736318945884705, acc=0.8031666874885559, loss=0.48736318945884705
test: epoch 67, loss 1.675552248954773, acc=0.4861111044883728, loss=1.675552248954773
train: epoch 68, loss 0.48423027992248535, acc=0.804277777671814, loss=0.48423027992248535
test: epoch 68, loss 1.5177627801895142, acc=0.49166667461395264, loss=1.5177627801895142
train: epoch 69, loss 0.4882100820541382, acc=0.8022222518920898, loss=0.4882100820541382
test: epoch 69, loss 1.7155210971832275, acc=0.46666666865348816, loss=1.7155210971832275
train: epoch 70, loss 0.4944211542606354, acc=0.7993888854980469, loss=0.4944211542606354
test: epoch 70, loss 1.576690673828125, acc=0.48055556416511536, loss=1.576690673828125
train: epoch 71, loss 0.5007351636886597, acc=0.7992222309112549, loss=0.5007351636886597
test: epoch 71, loss 1.4194185733795166, acc=0.4888888895511627, loss=1.4194185733795166
train: epoch 72, loss 0.4922366142272949, acc=0.799833357334137, loss=0.4922366142272949
test: epoch 72, loss 1.5444663763046265, acc=0.4861111044883728, loss=1.5444663763046265
train: epoch 73, loss 0.4941588044166565, acc=0.8012222051620483, loss=0.4941588044166565
test: epoch 73, loss 1.579795002937317, acc=0.5027777552604675, loss=1.579795002937317
train: epoch 74, loss 0.47468891739845276, acc=0.8037777543067932, loss=0.47468891739845276
test: epoch 74, loss 1.5437923669815063, acc=0.46388888359069824, loss=1.5437923669815063
train: epoch 75, loss 0.48685702681541443, acc=0.8032222390174866, loss=0.48685702681541443
test: epoch 75, loss 1.4082099199295044, acc=0.5, loss=1.4082099199295044
train: epoch 76, loss 0.4854104816913605, acc=0.800944447517395, loss=0.4854104816913605
test: epoch 76, loss 1.3941128253936768, acc=0.4722222089767456, loss=1.3941128253936768
train: epoch 77, loss 0.4843234121799469, acc=0.8021666407585144, loss=0.4843234121799469
test: epoch 77, loss 1.4293694496154785, acc=0.5, loss=1.4293694496154785
train: epoch 78, loss 0.47735005617141724, acc=0.8032222390174866, loss=0.47735005617141724
test: epoch 78, loss 1.4702767133712769, acc=0.5111111402511597, loss=1.4702767133712769
train: epoch 79, loss 0.47383198142051697, acc=0.80522221326828, loss=0.47383198142051697
test: epoch 79, loss 1.4050793647766113, acc=0.4972222149372101, loss=1.4050793647766113
train: epoch 80, loss 0.4931398034095764, acc=0.7993888854980469, loss=0.4931398034095764
test: epoch 80, loss 1.326542854309082, acc=0.4861111044883728, loss=1.326542854309082
train: epoch 81, loss 0.484557181596756, acc=0.8008888959884644, loss=0.484557181596756
test: epoch 81, loss 1.4082651138305664, acc=0.4888888895511627, loss=1.4082651138305664
train: epoch 82, loss 0.48175710439682007, acc=0.8031666874885559, loss=0.48175710439682007
test: epoch 82, loss 1.4368284940719604, acc=0.47777777910232544, loss=1.4368284940719604
train: epoch 83, loss 0.4804246425628662, acc=0.8027777671813965, loss=0.4804246425628662
test: epoch 83, loss 1.4975050687789917, acc=0.4972222149372101, loss=1.4975050687789917
train: epoch 84, loss 0.4718680679798126, acc=0.8065000176429749, loss=0.4718680679798126
test: epoch 84, loss 1.5297123193740845, acc=0.5138888955116272, loss=1.5297123193740845
train: epoch 85, loss 0.4654659926891327, acc=0.8065555691719055, loss=0.4654659926891327
test: epoch 85, loss 1.4956448078155518, acc=0.4972222149372101, loss=1.4956448078155518
train: epoch 86, loss 0.46971097588539124, acc=0.8078888654708862, loss=0.46971097588539124
test: epoch 86, loss 1.5615322589874268, acc=0.5055555701255798, loss=1.5615322589874268
train: epoch 87, loss 0.4790150225162506, acc=0.8059999942779541, loss=0.4790150225162506
test: epoch 87, loss 1.539341926574707, acc=0.4861111044883728, loss=1.539341926574707
train: epoch 88, loss 0.4763336479663849, acc=0.8036110997200012, loss=0.4763336479663849
test: epoch 88, loss 1.5939198732376099, acc=0.5055555701255798, loss=1.5939198732376099
train: epoch 89, loss 0.4747467339038849, acc=0.8029999732971191, loss=0.4747467339038849
test: epoch 89, loss 1.5129414796829224, acc=0.5083333253860474, loss=1.5129414796829224
train: epoch 90, loss 0.46283257007598877, acc=0.8059999942779541, loss=0.46283257007598877
test: epoch 90, loss 1.4907511472702026, acc=0.5083333253860474, loss=1.4907511472702026
train: epoch 91, loss 0.4710554778575897, acc=0.8057777881622314, loss=0.4710554778575897
test: epoch 91, loss 1.5974394083023071, acc=0.5083333253860474, loss=1.5974394083023071
train: epoch 92, loss 0.46804186701774597, acc=0.8077777624130249, loss=0.46804186701774597
test: epoch 92, loss 1.4928687810897827, acc=0.5027777552604675, loss=1.4928687810897827
train: epoch 93, loss 0.47179293632507324, acc=0.8024444580078125, loss=0.47179293632507324
test: epoch 93, loss 1.5773338079452515, acc=0.47777777910232544, loss=1.5773338079452515
train: epoch 94, loss 0.4551800489425659, acc=0.8100000023841858, loss=0.4551800489425659
test: epoch 94, loss 1.3969956636428833, acc=0.4972222149372101, loss=1.3969956636428833
train: epoch 95, loss 0.4657515287399292, acc=0.8065000176429749, loss=0.4657515287399292
test: epoch 95, loss 1.6166605949401855, acc=0.5, loss=1.6166605949401855
train: epoch 96, loss 0.46957117319107056, acc=0.805055558681488, loss=0.46957117319107056
test: epoch 96, loss 1.475213646888733, acc=0.5222222208976746, loss=1.475213646888733
train: epoch 97, loss 0.46456602215766907, acc=0.8059999942779541, loss=0.46456602215766907
test: epoch 97, loss 1.5344150066375732, acc=0.5138888955116272, loss=1.5344150066375732
train: epoch 98, loss 0.456821471452713, acc=0.812166690826416, loss=0.456821471452713
test: epoch 98, loss 1.43724524974823, acc=0.5222222208976746, loss=1.43724524974823
train: epoch 99, loss 0.45809194445610046, acc=0.8094444274902344, loss=0.45809194445610046
test: epoch 99, loss 1.4263464212417603, acc=0.49444442987442017, loss=1.4263464212417603
train: epoch 100, loss 0.4599337875843048, acc=0.8092222213745117, loss=0.4599337875843048
test: epoch 100, loss 1.537272334098816, acc=0.5111111402511597, loss=1.537272334098816
train: epoch 101, loss 0.4637067914009094, acc=0.8076666593551636, loss=0.4637067914009094
test: epoch 101, loss 1.4973890781402588, acc=0.5083333253860474, loss=1.4973890781402588
train: epoch 102, loss 0.4553893804550171, acc=0.808722198009491, loss=0.4553893804550171
test: epoch 102, loss 1.47008216381073, acc=0.5055555701255798, loss=1.47008216381073
train: epoch 103, loss 0.4501487612724304, acc=0.8098888993263245, loss=0.4501487612724304
test: epoch 103, loss 1.478799819946289, acc=0.5111111402511597, loss=1.478799819946289
train: epoch 104, loss 0.45848509669303894, acc=0.8088889122009277, loss=0.45848509669303894
test: epoch 104, loss 1.5306347608566284, acc=0.5111111402511597, loss=1.5306347608566284
train: epoch 105, loss 0.45536044239997864, acc=0.8149444460868835, loss=0.45536044239997864
test: epoch 105, loss 1.599856972694397, acc=0.5277777910232544, loss=1.599856972694397
train: epoch 106, loss 0.4597300887107849, acc=0.8115555644035339, loss=0.4597300887107849
test: epoch 106, loss 1.4003275632858276, acc=0.5111111402511597, loss=1.4003275632858276
train: epoch 107, loss 0.45152103900909424, acc=0.8138333559036255, loss=0.45152103900909424
test: epoch 107, loss 1.4215624332427979, acc=0.49444442987442017, loss=1.4215624332427979
train: epoch 108, loss 0.45513278245925903, acc=0.8143888711929321, loss=0.45513278245925903
test: epoch 108, loss 1.399177074432373, acc=0.5055555701255798, loss=1.399177074432373
train: epoch 109, loss 0.4594433307647705, acc=0.8092222213745117, loss=0.4594433307647705
test: epoch 109, loss 1.5017694234848022, acc=0.5222222208976746, loss=1.5017694234848022
train: epoch 110, loss 0.45118117332458496, acc=0.8120555281639099, loss=0.45118117332458496
test: epoch 110, loss 1.5357439517974854, acc=0.5249999761581421, loss=1.5357439517974854
train: epoch 111, loss 0.465152770280838, acc=0.8097777962684631, loss=0.465152770280838
test: epoch 111, loss 1.3937057256698608, acc=0.5055555701255798, loss=1.3937057256698608
train: epoch 112, loss 0.45944443345069885, acc=0.8107222318649292, loss=0.45944443345069885
test: epoch 112, loss 1.5204507112503052, acc=0.5222222208976746, loss=1.5204507112503052
train: epoch 113, loss 0.4473460018634796, acc=0.8184444308280945, loss=0.4473460018634796
test: epoch 113, loss 1.5773658752441406, acc=0.5277777910232544, loss=1.5773658752441406
train: epoch 114, loss 0.4467487335205078, acc=0.8149999976158142, loss=0.4467487335205078
test: epoch 114, loss 1.583703637123108, acc=0.5249999761581421, loss=1.583703637123108
train: epoch 115, loss 0.45392581820487976, acc=0.8156111240386963, loss=0.45392581820487976
test: epoch 115, loss 1.2980648279190063, acc=0.5222222208976746, loss=1.2980648279190063
train: epoch 116, loss 0.4472934603691101, acc=0.8142777681350708, loss=0.4472934603691101
test: epoch 116, loss 1.5001012086868286, acc=0.5388888716697693, loss=1.5001012086868286
train: epoch 117, loss 0.44555971026420593, acc=0.8144999742507935, loss=0.44555971026420593
test: epoch 117, loss 1.6379859447479248, acc=0.5361111164093018, loss=1.6379859447479248
train: epoch 118, loss 0.4429602026939392, acc=0.8183888792991638, loss=0.4429602026939392
test: epoch 118, loss 1.5213221311569214, acc=0.5277777910232544, loss=1.5213221311569214
train: epoch 119, loss 0.44634541869163513, acc=0.8185555338859558, loss=0.44634541869163513
test: epoch 119, loss 1.4389387369155884, acc=0.5277777910232544, loss=1.4389387369155884
train: epoch 120, loss 0.4436854422092438, acc=0.8176666498184204, loss=0.4436854422092438
test: epoch 120, loss 1.3982853889465332, acc=0.5361111164093018, loss=1.3982853889465332
train: epoch 121, loss 0.4421970546245575, acc=0.8159999847412109, loss=0.4421970546245575
test: epoch 121, loss 1.4598050117492676, acc=0.5249999761581421, loss=1.4598050117492676
train: epoch 122, loss 0.4390905797481537, acc=0.8151666522026062, loss=0.4390905797481537
test: epoch 122, loss 1.5421326160430908, acc=0.5361111164093018, loss=1.5421326160430908
train: epoch 123, loss 0.4382369816303253, acc=0.8153333067893982, loss=0.4382369816303253
test: epoch 123, loss 1.423020839691162, acc=0.5277777910232544, loss=1.423020839691162
train: epoch 124, loss 0.4516146183013916, acc=0.8149999976158142, loss=0.4516146183013916
test: epoch 124, loss 1.5035403966903687, acc=0.5361111164093018, loss=1.5035403966903687
train: epoch 125, loss 0.45028483867645264, acc=0.8141666650772095, loss=0.45028483867645264
test: epoch 125, loss 1.3800084590911865, acc=0.5361111164093018, loss=1.3800084590911865
train: epoch 126, loss 0.45335254073143005, acc=0.8147222399711609, loss=0.45335254073143005
test: epoch 126, loss 1.4514013528823853, acc=0.5333333611488342, loss=1.4514013528823853
train: epoch 127, loss 0.44452959299087524, acc=0.8158888816833496, loss=0.44452959299087524
test: epoch 127, loss 1.4509745836257935, acc=0.5388888716697693, loss=1.4509745836257935
train: epoch 128, loss 0.4425520598888397, acc=0.8180555701255798, loss=0.4425520598888397
test: epoch 128, loss 1.3402302265167236, acc=0.5388888716697693, loss=1.3402302265167236
train: epoch 129, loss 0.4276038110256195, acc=0.8197222352027893, loss=0.4276038110256195
test: epoch 129, loss 1.4389489889144897, acc=0.5305555462837219, loss=1.4389489889144897
train: epoch 130, loss 0.44024279713630676, acc=0.819944441318512, loss=0.44024279713630676
test: epoch 130, loss 1.6569324731826782, acc=0.5444444417953491, loss=1.6569324731826782
train: epoch 131, loss 0.4449183940887451, acc=0.8175555467605591, loss=0.4449183940887451
test: epoch 131, loss 1.5971943140029907, acc=0.5249999761581421, loss=1.5971943140029907
train: epoch 132, loss 0.44446325302124023, acc=0.8205000162124634, loss=0.44446325302124023
test: epoch 132, loss 1.468016266822815, acc=0.5305555462837219, loss=1.468016266822815
train: epoch 133, loss 0.43337708711624146, acc=0.820111095905304, loss=0.43337708711624146
test: epoch 133, loss 1.4722568988800049, acc=0.5277777910232544, loss=1.4722568988800049
train: epoch 134, loss 0.43735310435295105, acc=0.8224444389343262, loss=0.43735310435295105
test: epoch 134, loss 1.3385765552520752, acc=0.5444444417953491, loss=1.3385765552520752
train: epoch 135, loss 0.43928372859954834, acc=0.82105553150177, loss=0.43928372859954834
test: epoch 135, loss 1.4089138507843018, acc=0.5416666865348816, loss=1.4089138507843018
train: epoch 136, loss 0.4443472921848297, acc=0.8206666707992554, loss=0.4443472921848297
test: epoch 136, loss 1.4863098859786987, acc=0.5305555462837219, loss=1.4863098859786987
train: epoch 137, loss 0.44150876998901367, acc=0.8197222352027893, loss=0.44150876998901367
test: epoch 137, loss 1.4711334705352783, acc=0.5333333611488342, loss=1.4711334705352783
train: epoch 138, loss 0.426937460899353, acc=0.8220000267028809, loss=0.426937460899353
test: epoch 138, loss 1.3776293992996216, acc=0.5361111164093018, loss=1.3776293992996216
train: epoch 139, loss 0.43040889501571655, acc=0.8218333125114441, loss=0.43040889501571655
test: epoch 139, loss 1.3847057819366455, acc=0.5388888716697693, loss=1.3847057819366455
train: epoch 140, loss 0.43496161699295044, acc=0.8215555548667908, loss=0.43496161699295044
test: epoch 140, loss 1.3747230768203735, acc=0.5416666865348816, loss=1.3747230768203735
train: epoch 141, loss 0.4363403022289276, acc=0.820722222328186, loss=0.4363403022289276
test: epoch 141, loss 1.513432502746582, acc=0.5472221970558167, loss=1.513432502746582
train: epoch 142, loss 0.42535439133644104, acc=0.8271666765213013, loss=0.42535439133644104
test: epoch 142, loss 1.5782270431518555, acc=0.5361111164093018, loss=1.5782270431518555
train: epoch 143, loss 0.4273145794868469, acc=0.8279444575309753, loss=0.4273145794868469
test: epoch 143, loss 1.4033849239349365, acc=0.5166666507720947, loss=1.4033849239349365
train: epoch 144, loss 0.4428975582122803, acc=0.8192777633666992, loss=0.4428975582122803
test: epoch 144, loss 1.3886685371398926, acc=0.5249999761581421, loss=1.3886685371398926
train: epoch 145, loss 0.42385005950927734, acc=0.8264999985694885, loss=0.42385005950927734
test: epoch 145, loss 1.4096544981002808, acc=0.5388888716697693, loss=1.4096544981002808
train: epoch 146, loss 0.4411209523677826, acc=0.8192777633666992, loss=0.4411209523677826
test: epoch 146, loss 1.375106930732727, acc=0.5249999761581421, loss=1.375106930732727
train: epoch 147, loss 0.42988821864128113, acc=0.8224999904632568, loss=0.42988821864128113
test: epoch 147, loss 1.512242317199707, acc=0.5388888716697693, loss=1.512242317199707
train: epoch 148, loss 0.4181159436702728, acc=0.8272777795791626, loss=0.4181159436702728
test: epoch 148, loss 1.5891188383102417, acc=0.5277777910232544, loss=1.5891188383102417
train: epoch 149, loss 0.4281388819217682, acc=0.8221111297607422, loss=0.4281388819217682
test: epoch 149, loss 1.3556113243103027, acc=0.5416666865348816, loss=1.3556113243103027
train: epoch 150, loss 0.4224485158920288, acc=0.8249444365501404, loss=0.4224485158920288
test: epoch 150, loss 1.4772661924362183, acc=0.5444444417953491, loss=1.4772661924362183
