# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=1", "--one_hot=1", "--n_layers=1"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=1763889869, receiver_embed_dim=32, save_run=0, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1763889869, receiver_embed_dim=32, save_run=False, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.5370371341705322, acc=0.04716666787862778, loss=3.5370371341705322
test: epoch 1, loss 3.5566365718841553, acc=0.04444444552063942, loss=3.5566365718841553
train: epoch 2, loss 3.448134183883667, acc=0.052444443106651306, loss=3.448134183883667
test: epoch 2, loss 3.0436084270477295, acc=0.07500000298023224, loss=3.0436084270477295
train: epoch 3, loss 3.1788015365600586, acc=0.08316666632890701, loss=3.1788015365600586
test: epoch 3, loss 4.836634159088135, acc=0.03611111268401146, loss=4.836634159088135
train: epoch 4, loss 2.699904680252075, acc=0.15933333337306976, loss=2.699904680252075
test: epoch 4, loss 6.154046058654785, acc=0.03333333507180214, loss=6.154046058654785
train: epoch 5, loss 2.4323174953460693, acc=0.20044444501399994, loss=2.4323174953460693
test: epoch 5, loss 6.869915962219238, acc=0.03333333507180214, loss=6.869915962219238
train: epoch 6, loss 2.278156042098999, acc=0.22744444012641907, loss=2.278156042098999
test: epoch 6, loss 6.908936977386475, acc=0.0416666679084301, loss=6.908936977386475
train: epoch 7, loss 2.1724019050598145, acc=0.25049999356269836, loss=2.1724019050598145
test: epoch 7, loss 7.194661617279053, acc=0.03611111268401146, loss=7.194661617279053
train: epoch 8, loss 2.085867404937744, acc=0.27727776765823364, loss=2.085867404937744
test: epoch 8, loss 7.231159210205078, acc=0.05000000074505806, loss=7.231159210205078
train: epoch 9, loss 2.0206687450408936, acc=0.29555556178092957, loss=2.0206687450408936
test: epoch 9, loss 7.132913589477539, acc=0.0555555559694767, loss=7.132913589477539
train: epoch 10, loss 1.968468189239502, acc=0.2975555658340454, loss=1.968468189239502
test: epoch 10, loss 6.934037208557129, acc=0.05000000074505806, loss=6.934037208557129
train: epoch 11, loss 1.9221035242080688, acc=0.3181111216545105, loss=1.9221035242080688
test: epoch 11, loss 6.6891889572143555, acc=0.0694444477558136, loss=6.6891889572143555
train: epoch 12, loss 1.8727585077285767, acc=0.33283331990242004, loss=1.8727585077285767
test: epoch 12, loss 6.488659858703613, acc=0.06666667014360428, loss=6.488659858703613
train: epoch 13, loss 1.8316266536712646, acc=0.34388887882232666, loss=1.8316266536712646
test: epoch 13, loss 6.002264022827148, acc=0.07222222536802292, loss=6.002264022827148
train: epoch 14, loss 1.7892836332321167, acc=0.3587222099304199, loss=1.7892836332321167
test: epoch 14, loss 5.536125659942627, acc=0.09444444626569748, loss=5.536125659942627
train: epoch 15, loss 1.7452590465545654, acc=0.3692222237586975, loss=1.7452590465545654
test: epoch 15, loss 5.338325500488281, acc=0.09444444626569748, loss=5.338325500488281
train: epoch 16, loss 1.710342526435852, acc=0.38688889145851135, loss=1.710342526435852
test: epoch 16, loss 5.311985969543457, acc=0.10000000149011612, loss=5.311985969543457
train: epoch 17, loss 1.6864131689071655, acc=0.3912777900695801, loss=1.6864131689071655
test: epoch 17, loss 5.133448600769043, acc=0.10277777910232544, loss=5.133448600769043
train: epoch 18, loss 1.6469453573226929, acc=0.40761110186576843, loss=1.6469453573226929
test: epoch 18, loss 5.078587055206299, acc=0.09166666865348816, loss=5.078587055206299
train: epoch 19, loss 1.6158912181854248, acc=0.41688889265060425, loss=1.6158912181854248
test: epoch 19, loss 5.019670009613037, acc=0.11666666716337204, loss=5.019670009613037
train: epoch 20, loss 1.5898454189300537, acc=0.42972221970558167, loss=1.5898454189300537
test: epoch 20, loss 4.981227397918701, acc=0.11388888955116272, loss=4.981227397918701
train: epoch 21, loss 1.5522104501724243, acc=0.4386666715145111, loss=1.5522104501724243
test: epoch 21, loss 5.048299789428711, acc=0.10833333432674408, loss=5.048299789428711
train: epoch 22, loss 1.5317885875701904, acc=0.45533332228660583, loss=1.5317885875701904
test: epoch 22, loss 4.972252368927002, acc=0.10833333432674408, loss=4.972252368927002
train: epoch 23, loss 1.4978164434432983, acc=0.46283334493637085, loss=1.4978164434432983
test: epoch 23, loss 4.977701187133789, acc=0.11388888955116272, loss=4.977701187133789
train: epoch 24, loss 1.47140371799469, acc=0.4715000092983246, loss=1.47140371799469
test: epoch 24, loss 5.02785587310791, acc=0.11666666716337204, loss=5.02785587310791
train: epoch 25, loss 1.4450393915176392, acc=0.48633334040641785, loss=1.4450393915176392
test: epoch 25, loss 5.0244221687316895, acc=0.11388888955116272, loss=5.0244221687316895
train: epoch 26, loss 1.4295769929885864, acc=0.4983333349227905, loss=1.4295769929885864
test: epoch 26, loss 5.01796817779541, acc=0.11388888955116272, loss=5.01796817779541
train: epoch 27, loss 1.3935269117355347, acc=0.5051666498184204, loss=1.3935269117355347
test: epoch 27, loss 4.96073055267334, acc=0.125, loss=4.96073055267334
train: epoch 28, loss 1.3633625507354736, acc=0.5127778053283691, loss=1.3633625507354736
test: epoch 28, loss 4.854444980621338, acc=0.13611111044883728, loss=4.854444980621338
train: epoch 29, loss 1.345585584640503, acc=0.5249999761581421, loss=1.345585584640503
test: epoch 29, loss 4.817123889923096, acc=0.1388888955116272, loss=4.817123889923096
train: epoch 30, loss 1.3224915266036987, acc=0.5328888893127441, loss=1.3224915266036987
test: epoch 30, loss 4.751926898956299, acc=0.1388888955116272, loss=4.751926898956299
train: epoch 31, loss 1.3030813932418823, acc=0.5436111092567444, loss=1.3030813932418823
test: epoch 31, loss 4.662936687469482, acc=0.1527777761220932, loss=4.662936687469482
train: epoch 32, loss 1.2799972295761108, acc=0.5527222156524658, loss=1.2799972295761108
test: epoch 32, loss 4.573970317840576, acc=0.15000000596046448, loss=4.573970317840576
train: epoch 33, loss 1.243212342262268, acc=0.565833330154419, loss=1.243212342262268
test: epoch 33, loss 4.467926979064941, acc=0.15555556118488312, loss=4.467926979064941
train: epoch 34, loss 1.2153044939041138, acc=0.5780555605888367, loss=1.2153044939041138
test: epoch 34, loss 4.4812235832214355, acc=0.16111111640930176, loss=4.4812235832214355
train: epoch 35, loss 1.2017185688018799, acc=0.5888333320617676, loss=1.2017185688018799
test: epoch 35, loss 4.3499345779418945, acc=0.17499999701976776, loss=4.3499345779418945
train: epoch 36, loss 1.179273009300232, acc=0.60188889503479, loss=1.179273009300232
test: epoch 36, loss 4.281875133514404, acc=0.17777778208255768, loss=4.281875133514404
train: epoch 37, loss 1.1568418741226196, acc=0.6104999780654907, loss=1.1568418741226196
test: epoch 37, loss 4.338383197784424, acc=0.1805555522441864, loss=4.338383197784424
train: epoch 38, loss 1.1348682641983032, acc=0.621055543422699, loss=1.1348682641983032
test: epoch 38, loss 4.471284866333008, acc=0.17777778208255768, loss=4.471284866333008
train: epoch 39, loss 1.1092944145202637, acc=0.629277765750885, loss=1.1092944145202637
test: epoch 39, loss 4.509638786315918, acc=0.18611110746860504, loss=4.509638786315918
train: epoch 40, loss 1.0847584009170532, acc=0.6426110863685608, loss=1.0847584009170532
test: epoch 40, loss 4.523763179779053, acc=0.20277777314186096, loss=4.523763179779053
train: epoch 41, loss 1.0687397718429565, acc=0.6459444165229797, loss=1.0687397718429565
test: epoch 41, loss 4.678621768951416, acc=0.18611110746860504, loss=4.678621768951416
train: epoch 42, loss 1.0284295082092285, acc=0.664722204208374, loss=1.0284295082092285
test: epoch 42, loss 4.688457489013672, acc=0.18888889253139496, loss=4.688457489013672
train: epoch 43, loss 1.0102537870407104, acc=0.668833315372467, loss=1.0102537870407104
test: epoch 43, loss 4.676675319671631, acc=0.2083333283662796, loss=4.676675319671631
train: epoch 44, loss 0.9865713119506836, acc=0.6848888993263245, loss=0.9865713119506836
test: epoch 44, loss 4.7290425300598145, acc=0.20277777314186096, loss=4.7290425300598145
train: epoch 45, loss 0.9657958149909973, acc=0.6873888969421387, loss=0.9657958149909973
test: epoch 45, loss 4.621003150939941, acc=0.21388888359069824, loss=4.621003150939941
train: epoch 46, loss 0.9423987865447998, acc=0.7085000276565552, loss=0.9423987865447998
test: epoch 46, loss 4.667588233947754, acc=0.2361111044883728, loss=4.667588233947754
train: epoch 47, loss 0.9161664247512817, acc=0.7141110897064209, loss=0.9161664247512817
test: epoch 47, loss 4.788732528686523, acc=0.2361111044883728, loss=4.788732528686523
train: epoch 48, loss 0.8857405781745911, acc=0.7228888869285583, loss=0.8857405781745911
test: epoch 48, loss 4.7257819175720215, acc=0.24444444477558136, loss=4.7257819175720215
train: epoch 49, loss 0.8627034425735474, acc=0.7296666502952576, loss=0.8627034425735474
test: epoch 49, loss 4.852044105529785, acc=0.25555557012557983, loss=4.852044105529785
train: epoch 50, loss 0.8380879759788513, acc=0.7461666464805603, loss=0.8380879759788513
test: epoch 50, loss 4.604626178741455, acc=0.25833332538604736, loss=4.604626178741455
train: epoch 51, loss 0.8011218309402466, acc=0.7618333101272583, loss=0.8011218309402466
test: epoch 51, loss 4.858419418334961, acc=0.2611111104488373, loss=4.858419418334961
train: epoch 52, loss 0.7878719568252563, acc=0.7717777490615845, loss=0.7878719568252563
test: epoch 52, loss 4.885605812072754, acc=0.2777777910232544, loss=4.885605812072754
train: epoch 53, loss 0.740270733833313, acc=0.785444438457489, loss=0.740270733833313
test: epoch 53, loss 4.7866530418396, acc=0.2944444417953491, loss=4.7866530418396
train: epoch 54, loss 0.7345273494720459, acc=0.7911111116409302, loss=0.7345273494720459
test: epoch 54, loss 4.751413345336914, acc=0.30000001192092896, loss=4.751413345336914
train: epoch 55, loss 0.6981010437011719, acc=0.8026111125946045, loss=0.6981010437011719
test: epoch 55, loss 4.63746976852417, acc=0.31111112236976624, loss=4.63746976852417
train: epoch 56, loss 0.6715167760848999, acc=0.8092222213745117, loss=0.6715167760848999
test: epoch 56, loss 4.695005893707275, acc=0.31388887763023376, loss=4.695005893707275
train: epoch 57, loss 0.6545220613479614, acc=0.8157222270965576, loss=0.6545220613479614
test: epoch 57, loss 4.634969711303711, acc=0.3166666626930237, loss=4.634969711303711
train: epoch 58, loss 0.6203691959381104, acc=0.8330000042915344, loss=0.6203691959381104
test: epoch 58, loss 4.562957763671875, acc=0.32777777314186096, loss=4.562957763671875
train: epoch 59, loss 0.6098617315292358, acc=0.8395000100135803, loss=0.6098617315292358
test: epoch 59, loss 4.734447002410889, acc=0.32777777314186096, loss=4.734447002410889
train: epoch 60, loss 0.5763230919837952, acc=0.8482778072357178, loss=0.5763230919837952
test: epoch 60, loss 4.672823905944824, acc=0.32777777314186096, loss=4.672823905944824
train: epoch 61, loss 0.559848427772522, acc=0.8570555448532104, loss=0.559848427772522
test: epoch 61, loss 4.648036956787109, acc=0.33888888359069824, loss=4.648036956787109
train: epoch 62, loss 0.5125566124916077, acc=0.8700000047683716, loss=0.5125566124916077
test: epoch 62, loss 4.62271785736084, acc=0.32777777314186096, loss=4.62271785736084
train: epoch 63, loss 0.5133263468742371, acc=0.8684444427490234, loss=0.5133263468742371
test: epoch 63, loss 4.470080852508545, acc=0.3361110985279083, loss=4.470080852508545
train: epoch 64, loss 0.4845055341720581, acc=0.8771111369132996, loss=0.4845055341720581
test: epoch 64, loss 4.417585849761963, acc=0.3305555582046509, loss=4.417585849761963
train: epoch 65, loss 0.4586004614830017, acc=0.8865000009536743, loss=0.4586004614830017
test: epoch 65, loss 4.298380374908447, acc=0.3361110985279083, loss=4.298380374908447
train: epoch 66, loss 0.4375755488872528, acc=0.894944429397583, loss=0.4375755488872528
test: epoch 66, loss 4.30333137512207, acc=0.33888888359069824, loss=4.30333137512207
train: epoch 67, loss 0.4221281111240387, acc=0.8999999761581421, loss=0.4221281111240387
test: epoch 67, loss 4.3305158615112305, acc=0.3499999940395355, loss=4.3305158615112305
train: epoch 68, loss 0.4020024240016937, acc=0.9072777628898621, loss=0.4020024240016937
test: epoch 68, loss 4.337547779083252, acc=0.35277777910232544, loss=4.337547779083252
train: epoch 69, loss 0.37748226523399353, acc=0.9135000109672546, loss=0.37748226523399353
test: epoch 69, loss 4.285667896270752, acc=0.3444444537162781, loss=4.285667896270752
train: epoch 70, loss 0.36732596158981323, acc=0.9151111245155334, loss=0.36732596158981323
test: epoch 70, loss 4.15082311630249, acc=0.3583333194255829, loss=4.15082311630249
train: epoch 71, loss 0.35231250524520874, acc=0.9212222099304199, loss=0.35231250524520874
test: epoch 71, loss 4.005481243133545, acc=0.3583333194255829, loss=4.005481243133545
train: epoch 72, loss 0.3312779664993286, acc=0.9281111359596252, loss=0.3312779664993286
test: epoch 72, loss 3.9672913551330566, acc=0.35555556416511536, loss=3.9672913551330566
train: epoch 73, loss 0.31722012162208557, acc=0.929111123085022, loss=0.31722012162208557
test: epoch 73, loss 4.040111064910889, acc=0.34166666865348816, loss=4.040111064910889
train: epoch 74, loss 0.31441447138786316, acc=0.9334444403648376, loss=0.31441447138786316
test: epoch 74, loss 3.9579086303710938, acc=0.3499999940395355, loss=3.9579086303710938
train: epoch 75, loss 0.29454538226127625, acc=0.9365555644035339, loss=0.29454538226127625
test: epoch 75, loss 3.9414589405059814, acc=0.3333333432674408, loss=3.9414589405059814
train: epoch 76, loss 0.28264927864074707, acc=0.9391111135482788, loss=0.28264927864074707
test: epoch 76, loss 3.9180848598480225, acc=0.33888888359069824, loss=3.9180848598480225
train: epoch 77, loss 0.2780066430568695, acc=0.941277801990509, loss=0.2780066430568695
test: epoch 77, loss 3.868640184402466, acc=0.3472222089767456, loss=3.868640184402466
train: epoch 78, loss 0.2522236704826355, acc=0.94605553150177, loss=0.2522236704826355
test: epoch 78, loss 3.7286455631256104, acc=0.3499999940395355, loss=3.7286455631256104
train: epoch 79, loss 0.2564828395843506, acc=0.9445000290870667, loss=0.2564828395843506
test: epoch 79, loss 3.791468381881714, acc=0.33888888359069824, loss=3.791468381881714
train: epoch 80, loss 0.23984678089618683, acc=0.9504444599151611, loss=0.23984678089618683
test: epoch 80, loss 3.6735029220581055, acc=0.3499999940395355, loss=3.6735029220581055
train: epoch 81, loss 0.21919502317905426, acc=0.952833354473114, loss=0.21919502317905426
test: epoch 81, loss 3.6761415004730225, acc=0.3472222089767456, loss=3.6761415004730225
train: epoch 82, loss 0.2247740924358368, acc=0.9515555500984192, loss=0.2247740924358368
test: epoch 82, loss 3.582826852798462, acc=0.3472222089767456, loss=3.582826852798462
train: epoch 83, loss 0.21123284101486206, acc=0.9566666483879089, loss=0.21123284101486206
test: epoch 83, loss 3.5709376335144043, acc=0.35277777910232544, loss=3.5709376335144043
train: epoch 84, loss 0.2082173079252243, acc=0.956333339214325, loss=0.2082173079252243
test: epoch 84, loss 3.3911173343658447, acc=0.35555556416511536, loss=3.3911173343658447
train: epoch 85, loss 0.19870948791503906, acc=0.9601110816001892, loss=0.19870948791503906
test: epoch 85, loss 3.326596260070801, acc=0.3472222089767456, loss=3.326596260070801
train: epoch 86, loss 0.1986437439918518, acc=0.9585000276565552, loss=0.1986437439918518
test: epoch 86, loss 3.3624913692474365, acc=0.3583333194255829, loss=3.3624913692474365
train: epoch 87, loss 0.18359839916229248, acc=0.9618333578109741, loss=0.18359839916229248
test: epoch 87, loss 3.2530410289764404, acc=0.35277777910232544, loss=3.2530410289764404
train: epoch 88, loss 0.18246661126613617, acc=0.9625555276870728, loss=0.18246661126613617
test: epoch 88, loss 3.4190409183502197, acc=0.3472222089767456, loss=3.4190409183502197
train: epoch 89, loss 0.18102724850177765, acc=0.964888870716095, loss=0.18102724850177765
test: epoch 89, loss 3.457026958465576, acc=0.34166666865348816, loss=3.457026958465576
train: epoch 90, loss 0.17205841839313507, acc=0.9653333425521851, loss=0.17205841839313507
test: epoch 90, loss 3.331773042678833, acc=0.33888888359069824, loss=3.331773042678833
train: epoch 91, loss 0.16269466280937195, acc=0.9674999713897705, loss=0.16269466280937195
test: epoch 91, loss 3.4040145874023438, acc=0.35277777910232544, loss=3.4040145874023438
train: epoch 92, loss 0.16240905225276947, acc=0.967555582523346, loss=0.16240905225276947
test: epoch 92, loss 3.3698647022247314, acc=0.35555556416511536, loss=3.3698647022247314
train: epoch 93, loss 0.15496189892292023, acc=0.9692222476005554, loss=0.15496189892292023
test: epoch 93, loss 3.1793854236602783, acc=0.36666667461395264, loss=3.1793854236602783
train: epoch 94, loss 0.14419084787368774, acc=0.9715555310249329, loss=0.14419084787368774
test: epoch 94, loss 3.1996231079101562, acc=0.3611111044883728, loss=3.1996231079101562
train: epoch 95, loss 0.15205442905426025, acc=0.9691666960716248, loss=0.15205442905426025
test: epoch 95, loss 3.3228275775909424, acc=0.3472222089767456, loss=3.3228275775909424
train: epoch 96, loss 0.14085586369037628, acc=0.9712777733802795, loss=0.14085586369037628
test: epoch 96, loss 3.1996514797210693, acc=0.3499999940395355, loss=3.1996514797210693
train: epoch 97, loss 0.13622556626796722, acc=0.972000002861023, loss=0.13622556626796722
test: epoch 97, loss 3.1819398403167725, acc=0.35277777910232544, loss=3.1819398403167725
train: epoch 98, loss 0.1278219223022461, acc=0.9731666445732117, loss=0.1278219223022461
test: epoch 98, loss 3.152494430541992, acc=0.3472222089767456, loss=3.152494430541992
train: epoch 99, loss 0.11075954884290695, acc=0.976722240447998, loss=0.11075954884290695
test: epoch 99, loss 3.0916213989257812, acc=0.3611111044883728, loss=3.0916213989257812
train: epoch 100, loss 0.12234953790903091, acc=0.9747777581214905, loss=0.12234953790903091
test: epoch 100, loss 3.071662425994873, acc=0.3472222089767456, loss=3.071662425994873
train: epoch 101, loss 0.12400426715612411, acc=0.9755555391311646, loss=0.12400426715612411
test: epoch 101, loss 3.142542839050293, acc=0.35555556416511536, loss=3.142542839050293
train: epoch 102, loss 0.11944427341222763, acc=0.9757221937179565, loss=0.11944427341222763
test: epoch 102, loss 3.1047203540802, acc=0.3583333194255829, loss=3.1047203540802
train: epoch 103, loss 0.12211272865533829, acc=0.9744444489479065, loss=0.12211272865533829
test: epoch 103, loss 3.0163087844848633, acc=0.3472222089767456, loss=3.0163087844848633
train: epoch 104, loss 0.11202516406774521, acc=0.9772777557373047, loss=0.11202516406774521
test: epoch 104, loss 2.947504997253418, acc=0.36666667461395264, loss=2.947504997253418
train: epoch 105, loss 0.11032667011022568, acc=0.9773889183998108, loss=0.11032667011022568
test: epoch 105, loss 2.916898012161255, acc=0.35555556416511536, loss=2.916898012161255
train: epoch 106, loss 0.11425541341304779, acc=0.9769444465637207, loss=0.11425541341304779
test: epoch 106, loss 2.9021902084350586, acc=0.3444444537162781, loss=2.9021902084350586
train: epoch 107, loss 0.11077037453651428, acc=0.9784444570541382, loss=0.11077037453651428
test: epoch 107, loss 2.8728692531585693, acc=0.3583333194255829, loss=2.8728692531585693
train: epoch 108, loss 0.10790889710187912, acc=0.9795555472373962, loss=0.10790889710187912
test: epoch 108, loss 2.7999355792999268, acc=0.35277777910232544, loss=2.7999355792999268
train: epoch 109, loss 0.10514110326766968, acc=0.9796110987663269, loss=0.10514110326766968
test: epoch 109, loss 2.7909047603607178, acc=0.3499999940395355, loss=2.7909047603607178
train: epoch 110, loss 0.10426944494247437, acc=0.9798333048820496, loss=0.10426944494247437
test: epoch 110, loss 2.848411798477173, acc=0.3499999940395355, loss=2.848411798477173
train: epoch 111, loss 0.09648460894823074, acc=0.9815000295639038, loss=0.09648460894823074
test: epoch 111, loss 2.8228042125701904, acc=0.3333333432674408, loss=2.8228042125701904
train: epoch 112, loss 0.09539516270160675, acc=0.9815555810928345, loss=0.09539516270160675
test: epoch 112, loss 2.8656110763549805, acc=0.3638888895511627, loss=2.8656110763549805
train: epoch 113, loss 0.09492328017950058, acc=0.9801666736602783, loss=0.09492328017950058
test: epoch 113, loss 2.8732354640960693, acc=0.3472222089767456, loss=2.8732354640960693
train: epoch 114, loss 0.100956030189991, acc=0.9809444546699524, loss=0.100956030189991
test: epoch 114, loss 2.7351224422454834, acc=0.35277777910232544, loss=2.7351224422454834
train: epoch 115, loss 0.08799052983522415, acc=0.983222246170044, loss=0.08799052983522415
test: epoch 115, loss 2.7907943725585938, acc=0.3583333194255829, loss=2.7907943725585938
train: epoch 116, loss 0.09705763310194016, acc=0.9810555577278137, loss=0.09705763310194016
test: epoch 116, loss 2.6981773376464844, acc=0.35277777910232544, loss=2.6981773376464844
train: epoch 117, loss 0.09126538038253784, acc=0.9828333258628845, loss=0.09126538038253784
test: epoch 117, loss 2.6593635082244873, acc=0.35277777910232544, loss=2.6593635082244873
train: epoch 118, loss 0.09918086975812912, acc=0.9806666374206543, loss=0.09918086975812912
test: epoch 118, loss 2.7442009449005127, acc=0.35277777910232544, loss=2.7442009449005127
train: epoch 119, loss 0.07874587178230286, acc=0.9832777976989746, loss=0.07874587178230286
test: epoch 119, loss 2.751084566116333, acc=0.35277777910232544, loss=2.751084566116333
train: epoch 120, loss 0.07701291143894196, acc=0.984499990940094, loss=0.07701291143894196
test: epoch 120, loss 2.777987003326416, acc=0.3611111044883728, loss=2.777987003326416
train: epoch 121, loss 0.08004338294267654, acc=0.9850555658340454, loss=0.08004338294267654
test: epoch 121, loss 2.7183120250701904, acc=0.3499999940395355, loss=2.7183120250701904
train: epoch 122, loss 0.08358561247587204, acc=0.9844444394111633, loss=0.08358561247587204
test: epoch 122, loss 2.7276439666748047, acc=0.35555556416511536, loss=2.7276439666748047
train: epoch 123, loss 0.08178911358118057, acc=0.98416668176651, loss=0.08178911358118057
test: epoch 123, loss 2.7084078788757324, acc=0.36944442987442017, loss=2.7084078788757324
train: epoch 124, loss 0.07614217698574066, acc=0.9842222332954407, loss=0.07614217698574066
test: epoch 124, loss 2.5925955772399902, acc=0.3638888895511627, loss=2.5925955772399902
train: epoch 125, loss 0.07307112962007523, acc=0.9844444394111633, loss=0.07307112962007523
test: epoch 125, loss 2.608884334564209, acc=0.3583333194255829, loss=2.608884334564209
train: epoch 126, loss 0.07777772098779678, acc=0.9837777614593506, loss=0.07777772098779678
test: epoch 126, loss 2.601367235183716, acc=0.375, loss=2.601367235183716
train: epoch 127, loss 0.06548183411359787, acc=0.9871110916137695, loss=0.06548183411359787
test: epoch 127, loss 2.5972695350646973, acc=0.3583333194255829, loss=2.5972695350646973
train: epoch 128, loss 0.08288856595754623, acc=0.9847777485847473, loss=0.08288856595754623
test: epoch 128, loss 2.5915210247039795, acc=0.35555556416511536, loss=2.5915210247039795
train: epoch 129, loss 0.06748846173286438, acc=0.9866666793823242, loss=0.06748846173286438
test: epoch 129, loss 2.504469633102417, acc=0.3777777850627899, loss=2.504469633102417
train: epoch 130, loss 0.07708192616701126, acc=0.984000027179718, loss=0.07708192616701126
test: epoch 130, loss 2.4955391883850098, acc=0.3638888895511627, loss=2.4955391883850098
train: epoch 131, loss 0.06966584175825119, acc=0.9866111278533936, loss=0.06966584175825119
test: epoch 131, loss 2.437429189682007, acc=0.3611111044883728, loss=2.437429189682007
train: epoch 132, loss 0.07579006999731064, acc=0.9857777953147888, loss=0.07579006999731064
test: epoch 132, loss 2.5118744373321533, acc=0.38055557012557983, loss=2.5118744373321533
train: epoch 133, loss 0.06732456386089325, acc=0.9878888726234436, loss=0.06732456386089325
test: epoch 133, loss 2.5224552154541016, acc=0.36666667461395264, loss=2.5224552154541016
train: epoch 134, loss 0.06617923080921173, acc=0.9862777590751648, loss=0.06617923080921173
test: epoch 134, loss 2.5316648483276367, acc=0.3638888895511627, loss=2.5316648483276367
train: epoch 135, loss 0.07290513068437576, acc=0.9859444499015808, loss=0.07290513068437576
test: epoch 135, loss 2.374768018722534, acc=0.38055557012557983, loss=2.374768018722534
train: epoch 136, loss 0.057624444365501404, acc=0.988611102104187, loss=0.057624444365501404
test: epoch 136, loss 2.415174722671509, acc=0.375, loss=2.415174722671509
train: epoch 137, loss 0.06326194107532501, acc=0.9878888726234436, loss=0.06326194107532501
test: epoch 137, loss 2.402405261993408, acc=0.38055557012557983, loss=2.402405261993408
train: epoch 138, loss 0.05945385992527008, acc=0.988611102104187, loss=0.05945385992527008
test: epoch 138, loss 2.3902835845947266, acc=0.3499999940395355, loss=2.3902835845947266
train: epoch 139, loss 0.054500430822372437, acc=0.9878333210945129, loss=0.054500430822372437
test: epoch 139, loss 2.3123297691345215, acc=0.38333332538604736, loss=2.3123297691345215
train: epoch 140, loss 0.059974394738674164, acc=0.9886666536331177, loss=0.059974394738674164
test: epoch 140, loss 2.188572883605957, acc=0.375, loss=2.188572883605957
train: epoch 141, loss 0.05797164514660835, acc=0.9888888597488403, loss=0.05797164514660835
test: epoch 141, loss 2.2638678550720215, acc=0.36944442987442017, loss=2.2638678550720215
train: epoch 142, loss 0.06097499653697014, acc=0.9883888959884644, loss=0.06097499653697014
test: epoch 142, loss 2.234206199645996, acc=0.3888888955116272, loss=2.234206199645996
train: epoch 143, loss 0.062069591134786606, acc=0.9877222180366516, loss=0.062069591134786606
test: epoch 143, loss 2.322713613510132, acc=0.3722222149372101, loss=2.322713613510132
train: epoch 144, loss 0.06698284298181534, acc=0.9874444603919983, loss=0.06698284298181534
test: epoch 144, loss 2.2718727588653564, acc=0.3888888955116272, loss=2.2718727588653564
train: epoch 145, loss 0.049986064434051514, acc=0.9902777671813965, loss=0.049986064434051514
test: epoch 145, loss 2.2723758220672607, acc=0.4027777910232544, loss=2.2723758220672607
train: epoch 146, loss 0.05817602574825287, acc=0.9884999990463257, loss=0.05817602574825287
test: epoch 146, loss 2.1723437309265137, acc=0.375, loss=2.1723437309265137
train: epoch 147, loss 0.053355228155851364, acc=0.9894999861717224, loss=0.053355228155851364
test: epoch 147, loss 2.1747477054595947, acc=0.375, loss=2.1747477054595947
train: epoch 148, loss 0.05511767417192459, acc=0.9890555739402771, loss=0.05511767417192459
test: epoch 148, loss 2.2461140155792236, acc=0.3611111044883728, loss=2.2461140155792236
train: epoch 149, loss 0.05981072783470154, acc=0.9891666769981384, loss=0.05981072783470154
test: epoch 149, loss 2.136234998703003, acc=0.38055557012557983, loss=2.136234998703003
train: epoch 150, loss 0.0476890429854393, acc=0.9899444580078125, loss=0.0476890429854393
test: epoch 150, loss 2.2326290607452393, acc=0.375, loss=2.2326290607452393
