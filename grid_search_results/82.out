# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=1", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=1598375949, receiver_embed_dim=64, save_run=0, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1598375949, receiver_embed_dim=64, save_run=False, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.317159652709961, acc=0.061888888478279114, loss=3.317159652709961
test: epoch 1, loss 3.9391067028045654, acc=0.0694444477558136, loss=3.9391067028045654
train: epoch 2, loss 2.0885400772094727, acc=0.2485000044107437, loss=2.0885400772094727
test: epoch 2, loss 3.3284642696380615, acc=0.10277777910232544, loss=3.3284642696380615
train: epoch 3, loss 1.5966607332229614, acc=0.3717777729034424, loss=1.5966607332229614
test: epoch 3, loss 2.917970895767212, acc=0.14722222089767456, loss=2.917970895767212
train: epoch 4, loss 1.4102691411972046, acc=0.4314444363117218, loss=1.4102691411972046
test: epoch 4, loss 2.8026533126831055, acc=0.15000000596046448, loss=2.8026533126831055
train: epoch 5, loss 1.2781563997268677, acc=0.4907222092151642, loss=1.2781563997268677
test: epoch 5, loss 2.9033420085906982, acc=0.16111111640930176, loss=2.9033420085906982
train: epoch 6, loss 1.184205412864685, acc=0.5275555849075317, loss=1.184205412864685
test: epoch 6, loss 2.812039613723755, acc=0.16111111640930176, loss=2.812039613723755
train: epoch 7, loss 1.121751070022583, acc=0.5512222051620483, loss=1.121751070022583
test: epoch 7, loss 2.7283942699432373, acc=0.17777778208255768, loss=2.7283942699432373
train: epoch 8, loss 1.0615791082382202, acc=0.5803333520889282, loss=1.0615791082382202
test: epoch 8, loss 2.6817643642425537, acc=0.18888889253139496, loss=2.6817643642425537
train: epoch 9, loss 0.9968081116676331, acc=0.6083333492279053, loss=0.9968081116676331
test: epoch 9, loss 2.5765371322631836, acc=0.21111111342906952, loss=2.5765371322631836
train: epoch 10, loss 0.9568741917610168, acc=0.6288889050483704, loss=0.9568741917610168
test: epoch 10, loss 2.5181896686553955, acc=0.21388888359069824, loss=2.5181896686553955
train: epoch 11, loss 0.9182410836219788, acc=0.6435555815696716, loss=0.9182410836219788
test: epoch 11, loss 2.440913200378418, acc=0.23055554926395416, loss=2.440913200378418
train: epoch 12, loss 0.8748797178268433, acc=0.6637222170829773, loss=0.8748797178268433
test: epoch 12, loss 2.557847261428833, acc=0.24722221493721008, loss=2.557847261428833
train: epoch 13, loss 0.8303804397583008, acc=0.6791666746139526, loss=0.8303804397583008
test: epoch 13, loss 2.3799686431884766, acc=0.25, loss=2.3799686431884766
train: epoch 14, loss 0.7965639233589172, acc=0.6965000033378601, loss=0.7965639233589172
test: epoch 14, loss 2.286827325820923, acc=0.2611111104488373, loss=2.286827325820923
train: epoch 15, loss 0.7790498733520508, acc=0.6997777819633484, loss=0.7790498733520508
test: epoch 15, loss 2.3815360069274902, acc=0.26944443583488464, loss=2.3815360069274902
train: epoch 16, loss 0.7488754391670227, acc=0.7173888683319092, loss=0.7488754391670227
test: epoch 16, loss 2.164865493774414, acc=0.2750000059604645, loss=2.164865493774414
train: epoch 17, loss 0.7101752758026123, acc=0.7303333282470703, loss=0.7101752758026123
test: epoch 17, loss 2.1193394660949707, acc=0.3333333432674408, loss=2.1193394660949707
train: epoch 18, loss 0.6943873763084412, acc=0.7366111278533936, loss=0.6943873763084412
test: epoch 18, loss 2.177428960800171, acc=0.2916666567325592, loss=2.177428960800171
train: epoch 19, loss 0.6746649146080017, acc=0.7432777881622314, loss=0.6746649146080017
test: epoch 19, loss 2.0149240493774414, acc=0.32499998807907104, loss=2.0149240493774414
train: epoch 20, loss 0.6504794359207153, acc=0.749833345413208, loss=0.6504794359207153
test: epoch 20, loss 2.0678887367248535, acc=0.3194444477558136, loss=2.0678887367248535
train: epoch 21, loss 0.6345269083976746, acc=0.7609999775886536, loss=0.6345269083976746
test: epoch 21, loss 2.0340867042541504, acc=0.31111112236976624, loss=2.0340867042541504
train: epoch 22, loss 0.60977703332901, acc=0.7693889141082764, loss=0.60977703332901
test: epoch 22, loss 2.07747220993042, acc=0.31111112236976624, loss=2.07747220993042
train: epoch 23, loss 0.6051706075668335, acc=0.7735000252723694, loss=0.6051706075668335
test: epoch 23, loss 1.951141119003296, acc=0.34166666865348816, loss=1.951141119003296
train: epoch 24, loss 0.5857265591621399, acc=0.7810555696487427, loss=0.5857265591621399
test: epoch 24, loss 1.9579485654830933, acc=0.3361110985279083, loss=1.9579485654830933
train: epoch 25, loss 0.5662561655044556, acc=0.789722204208374, loss=0.5662561655044556
test: epoch 25, loss 2.081677198410034, acc=0.34166666865348816, loss=2.081677198410034
train: epoch 26, loss 0.5499905347824097, acc=0.7968888878822327, loss=0.5499905347824097
test: epoch 26, loss 1.8421460390090942, acc=0.3305555582046509, loss=1.8421460390090942
train: epoch 27, loss 0.5301946401596069, acc=0.8057222366333008, loss=0.5301946401596069
test: epoch 27, loss 1.8085297346115112, acc=0.35277777910232544, loss=1.8085297346115112
train: epoch 28, loss 0.5360763072967529, acc=0.8016666769981384, loss=0.5360763072967529
test: epoch 28, loss 1.7717726230621338, acc=0.38055557012557983, loss=1.7717726230621338
train: epoch 29, loss 0.5121735334396362, acc=0.8146666884422302, loss=0.5121735334396362
test: epoch 29, loss 1.735256314277649, acc=0.3583333194255829, loss=1.735256314277649
train: epoch 30, loss 0.49533358216285706, acc=0.820555567741394, loss=0.49533358216285706
test: epoch 30, loss 1.706184983253479, acc=0.3638888895511627, loss=1.706184983253479
train: epoch 31, loss 0.49302032589912415, acc=0.8180555701255798, loss=0.49302032589912415
test: epoch 31, loss 1.7762985229492188, acc=0.3722222149372101, loss=1.7762985229492188
train: epoch 32, loss 0.4766547679901123, acc=0.8211110830307007, loss=0.4766547679901123
test: epoch 32, loss 1.683903694152832, acc=0.3861111104488373, loss=1.683903694152832
train: epoch 33, loss 0.4684559404850006, acc=0.8273888826370239, loss=0.4684559404850006
test: epoch 33, loss 1.7452491521835327, acc=0.41111111640930176, loss=1.7452491521835327
train: epoch 34, loss 0.4679732620716095, acc=0.8291110992431641, loss=0.4679732620716095
test: epoch 34, loss 1.5784590244293213, acc=0.43888887763023376, loss=1.5784590244293213
train: epoch 35, loss 0.4493989646434784, acc=0.8332222104072571, loss=0.4493989646434784
test: epoch 35, loss 1.589088797569275, acc=0.44999998807907104, loss=1.589088797569275
train: epoch 36, loss 0.4337334632873535, acc=0.8420555591583252, loss=0.4337334632873535
test: epoch 36, loss 1.617120385169983, acc=0.4444444477558136, loss=1.617120385169983
train: epoch 37, loss 0.41462844610214233, acc=0.8503333330154419, loss=0.41462844610214233
test: epoch 37, loss 1.7524429559707642, acc=0.43888887763023376, loss=1.7524429559707642
train: epoch 38, loss 0.4260936379432678, acc=0.8456666469573975, loss=0.4260936379432678
test: epoch 38, loss 1.65122652053833, acc=0.4555555582046509, loss=1.65122652053833
train: epoch 39, loss 0.41524413228034973, acc=0.847611129283905, loss=0.41524413228034973
test: epoch 39, loss 1.612237572669983, acc=0.46666666865348816, loss=1.612237572669983
train: epoch 40, loss 0.4095171093940735, acc=0.8538333177566528, loss=0.4095171093940735
test: epoch 40, loss 1.5938180685043335, acc=0.4472222328186035, loss=1.5938180685043335
train: epoch 41, loss 0.40260207653045654, acc=0.8577222228050232, loss=0.40260207653045654
test: epoch 41, loss 1.6300625801086426, acc=0.4722222089767456, loss=1.6300625801086426
train: epoch 42, loss 0.379334032535553, acc=0.8617777824401855, loss=0.379334032535553
test: epoch 42, loss 1.4371650218963623, acc=0.48055556416511536, loss=1.4371650218963623
train: epoch 43, loss 0.385900616645813, acc=0.8588333129882812, loss=0.385900616645813
test: epoch 43, loss 1.533083438873291, acc=0.47777777910232544, loss=1.533083438873291
train: epoch 44, loss 0.3818746507167816, acc=0.8636666536331177, loss=0.3818746507167816
test: epoch 44, loss 1.570404052734375, acc=0.4611110985279083, loss=1.570404052734375
train: epoch 45, loss 0.3666399121284485, acc=0.8672778010368347, loss=0.3666399121284485
test: epoch 45, loss 1.5554920434951782, acc=0.4722222089767456, loss=1.5554920434951782
train: epoch 46, loss 0.35616427659988403, acc=0.8700000047683716, loss=0.35616427659988403
test: epoch 46, loss 1.6476929187774658, acc=0.4888888895511627, loss=1.6476929187774658
train: epoch 47, loss 0.3483532667160034, acc=0.8730555772781372, loss=0.3483532667160034
test: epoch 47, loss 1.5269721746444702, acc=0.4888888895511627, loss=1.5269721746444702
train: epoch 48, loss 0.35125020146369934, acc=0.8741111159324646, loss=0.35125020146369934
test: epoch 48, loss 1.4032238721847534, acc=0.4861111044883728, loss=1.4032238721847534
train: epoch 49, loss 0.34198442101478577, acc=0.8819444179534912, loss=0.34198442101478577
test: epoch 49, loss 1.4532506465911865, acc=0.49166667461395264, loss=1.4532506465911865
train: epoch 50, loss 0.3277302086353302, acc=0.8816111087799072, loss=0.3277302086353302
test: epoch 50, loss 1.332924723625183, acc=0.5, loss=1.332924723625183
train: epoch 51, loss 0.32315024733543396, acc=0.8866666555404663, loss=0.32315024733543396
test: epoch 51, loss 1.5165531635284424, acc=0.5416666865348816, loss=1.5165531635284424
train: epoch 52, loss 0.3174183666706085, acc=0.8897777795791626, loss=0.3174183666706085
test: epoch 52, loss 1.4070590734481812, acc=0.5138888955116272, loss=1.4070590734481812
train: epoch 53, loss 0.31596580147743225, acc=0.8898333311080933, loss=0.31596580147743225
test: epoch 53, loss 1.5541974306106567, acc=0.5277777910232544, loss=1.5541974306106567
train: epoch 54, loss 0.29946839809417725, acc=0.8933333158493042, loss=0.29946839809417725
test: epoch 54, loss 1.4603039026260376, acc=0.5472221970558167, loss=1.4603039026260376
train: epoch 55, loss 0.2969079315662384, acc=0.8934444189071655, loss=0.2969079315662384
test: epoch 55, loss 1.5517380237579346, acc=0.5138888955116272, loss=1.5517380237579346
train: epoch 56, loss 0.3001253306865692, acc=0.8964999914169312, loss=0.3001253306865692
test: epoch 56, loss 1.3808085918426514, acc=0.5416666865348816, loss=1.3808085918426514
train: epoch 57, loss 0.30135998129844666, acc=0.8921666741371155, loss=0.30135998129844666
test: epoch 57, loss 1.355450987815857, acc=0.5444444417953491, loss=1.355450987815857
train: epoch 58, loss 0.2885777950286865, acc=0.8996666669845581, loss=0.2885777950286865
test: epoch 58, loss 1.4329471588134766, acc=0.574999988079071, loss=1.4329471588134766
train: epoch 59, loss 0.29569610953330994, acc=0.8950555324554443, loss=0.29569610953330994
test: epoch 59, loss 1.4952633380889893, acc=0.5722222328186035, loss=1.4952633380889893
train: epoch 60, loss 0.2793710231781006, acc=0.9010555744171143, loss=0.2793710231781006
test: epoch 60, loss 1.394450068473816, acc=0.5277777910232544, loss=1.394450068473816
train: epoch 61, loss 0.27542760968208313, acc=0.9024444222450256, loss=0.27542760968208313
test: epoch 61, loss 1.3179616928100586, acc=0.5833333134651184, loss=1.3179616928100586
train: epoch 62, loss 0.282974511384964, acc=0.9013888835906982, loss=0.282974511384964
test: epoch 62, loss 1.3075288534164429, acc=0.5666666626930237, loss=1.3075288534164429
train: epoch 63, loss 0.2729475796222687, acc=0.9066666960716248, loss=0.2729475796222687
test: epoch 63, loss 1.2611504793167114, acc=0.5694444179534912, loss=1.2611504793167114
train: epoch 64, loss 0.26693961024284363, acc=0.9103888869285583, loss=0.26693961024284363
test: epoch 64, loss 1.3242679834365845, acc=0.5833333134651184, loss=1.3242679834365845
train: epoch 65, loss 0.2617354989051819, acc=0.9081666469573975, loss=0.2617354989051819
test: epoch 65, loss 1.1944133043289185, acc=0.5833333134651184, loss=1.1944133043289185
train: epoch 66, loss 0.2651813328266144, acc=0.9086666703224182, loss=0.2651813328266144
test: epoch 66, loss 1.4795936346054077, acc=0.5861111283302307, loss=1.4795936346054077
train: epoch 67, loss 0.2683590054512024, acc=0.9083333611488342, loss=0.2683590054512024
test: epoch 67, loss 1.1007782220840454, acc=0.5972222089767456, loss=1.1007782220840454
train: epoch 68, loss 0.2515694200992584, acc=0.913777768611908, loss=0.2515694200992584
test: epoch 68, loss 1.192179560661316, acc=0.6166666746139526, loss=1.192179560661316
train: epoch 69, loss 0.2482069432735443, acc=0.913444459438324, loss=0.2482069432735443
test: epoch 69, loss 1.3098691701889038, acc=0.5833333134651184, loss=1.3098691701889038
train: epoch 70, loss 0.2595388889312744, acc=0.9097777605056763, loss=0.2595388889312744
test: epoch 70, loss 1.2307683229446411, acc=0.5888888835906982, loss=1.2307683229446411
train: epoch 71, loss 0.23532798886299133, acc=0.9170555472373962, loss=0.23532798886299133
test: epoch 71, loss 1.3831123113632202, acc=0.5861111283302307, loss=1.3831123113632202
train: epoch 72, loss 0.25429123640060425, acc=0.9129444360733032, loss=0.25429123640060425
test: epoch 72, loss 1.2047723531723022, acc=0.625, loss=1.2047723531723022
train: epoch 73, loss 0.24707448482513428, acc=0.9171110987663269, loss=0.24707448482513428
test: epoch 73, loss 1.2562456130981445, acc=0.6194444298744202, loss=1.2562456130981445
train: epoch 74, loss 0.2533835172653198, acc=0.9163333177566528, loss=0.2533835172653198
test: epoch 74, loss 1.2430769205093384, acc=0.6277777552604675, loss=1.2430769205093384
train: epoch 75, loss 0.24459506571292877, acc=0.9193333387374878, loss=0.24459506571292877
test: epoch 75, loss 1.2324020862579346, acc=0.6277777552604675, loss=1.2324020862579346
train: epoch 76, loss 0.2366369366645813, acc=0.918833315372467, loss=0.2366369366645813
test: epoch 76, loss 1.2699893712997437, acc=0.6222222447395325, loss=1.2699893712997437
train: epoch 77, loss 0.21641989052295685, acc=0.9224444627761841, loss=0.21641989052295685
test: epoch 77, loss 1.101288914680481, acc=0.6388888955116272, loss=1.101288914680481
train: epoch 78, loss 0.23064479231834412, acc=0.921999990940094, loss=0.23064479231834412
test: epoch 78, loss 1.2715976238250732, acc=0.6361111402511597, loss=1.2715976238250732
train: epoch 79, loss 0.2348816692829132, acc=0.9193888902664185, loss=0.2348816692829132
test: epoch 79, loss 1.110748291015625, acc=0.6138888597488403, loss=1.110748291015625
train: epoch 80, loss 0.22836242616176605, acc=0.9228333234786987, loss=0.22836242616176605
test: epoch 80, loss 1.033813714981079, acc=0.675000011920929, loss=1.033813714981079
train: epoch 81, loss 0.2202308475971222, acc=0.9230555295944214, loss=0.2202308475971222
test: epoch 81, loss 1.2126001119613647, acc=0.6277777552604675, loss=1.2126001119613647
train: epoch 82, loss 0.23012308776378632, acc=0.92166668176651, loss=0.23012308776378632
test: epoch 82, loss 1.2349289655685425, acc=0.6583333611488342, loss=1.2349289655685425
train: epoch 83, loss 0.22058016061782837, acc=0.92166668176651, loss=0.22058016061782837
test: epoch 83, loss 1.264954686164856, acc=0.6499999761581421, loss=1.264954686164856
train: epoch 84, loss 0.22576197981834412, acc=0.9201666712760925, loss=0.22576197981834412
test: epoch 84, loss 1.0672218799591064, acc=0.6527777910232544, loss=1.0672218799591064
train: epoch 85, loss 0.22156544029712677, acc=0.9240000247955322, loss=0.22156544029712677
test: epoch 85, loss 1.1417690515518188, acc=0.6861110925674438, loss=1.1417690515518188
train: epoch 86, loss 0.21897993981838226, acc=0.9242222309112549, loss=0.21897993981838226
test: epoch 86, loss 1.064204216003418, acc=0.6805555820465088, loss=1.064204216003418
train: epoch 87, loss 0.22118663787841797, acc=0.9252777695655823, loss=0.22118663787841797
test: epoch 87, loss 1.0413243770599365, acc=0.6861110925674438, loss=1.0413243770599365
train: epoch 88, loss 0.22036010026931763, acc=0.9252777695655823, loss=0.22036010026931763
test: epoch 88, loss 0.9295859932899475, acc=0.7083333134651184, loss=0.9295859932899475
train: epoch 89, loss 0.210134357213974, acc=0.9244999885559082, loss=0.210134357213974
test: epoch 89, loss 1.0280158519744873, acc=0.699999988079071, loss=1.0280158519744873
train: epoch 90, loss 0.20930612087249756, acc=0.9266111254692078, loss=0.20930612087249756
test: epoch 90, loss 0.9835624098777771, acc=0.6944444179534912, loss=0.9835624098777771
train: epoch 91, loss 0.20789523422718048, acc=0.925611138343811, loss=0.20789523422718048
test: epoch 91, loss 0.9601198434829712, acc=0.6972222328186035, loss=0.9601198434829712
train: epoch 92, loss 0.20668311417102814, acc=0.9276111125946045, loss=0.20668311417102814
test: epoch 92, loss 1.1050845384597778, acc=0.6972222328186035, loss=1.1050845384597778
train: epoch 93, loss 0.2184852510690689, acc=0.9247221946716309, loss=0.2184852510690689
test: epoch 93, loss 1.1713391542434692, acc=0.6916666626930237, loss=1.1713391542434692
train: epoch 94, loss 0.2154330313205719, acc=0.9277222156524658, loss=0.2154330313205719
test: epoch 94, loss 1.028018593788147, acc=0.699999988079071, loss=1.028018593788147
train: epoch 95, loss 0.21560180187225342, acc=0.9235555529594421, loss=0.21560180187225342
test: epoch 95, loss 1.052452564239502, acc=0.7027778029441833, loss=1.052452564239502
train: epoch 96, loss 0.20900201797485352, acc=0.9272778034210205, loss=0.20900201797485352
test: epoch 96, loss 0.8307854533195496, acc=0.6944444179534912, loss=0.8307854533195496
train: epoch 97, loss 0.2061312198638916, acc=0.9286110997200012, loss=0.2061312198638916
test: epoch 97, loss 1.0824153423309326, acc=0.7083333134651184, loss=1.0824153423309326
train: epoch 98, loss 0.21266575157642365, acc=0.9259999990463257, loss=0.21266575157642365
test: epoch 98, loss 0.9640958309173584, acc=0.7222222089767456, loss=0.9640958309173584
train: epoch 99, loss 0.20536074042320251, acc=0.929111123085022, loss=0.20536074042320251
test: epoch 99, loss 1.045357584953308, acc=0.7166666388511658, loss=1.045357584953308
train: epoch 100, loss 0.20530997216701508, acc=0.929277777671814, loss=0.20530997216701508
test: epoch 100, loss 0.9908962845802307, acc=0.7194444537162781, loss=0.9908962845802307
train: epoch 101, loss 0.21434098482131958, acc=0.9262222051620483, loss=0.21434098482131958
test: epoch 101, loss 0.9100058674812317, acc=0.7222222089767456, loss=0.9100058674812317
train: epoch 102, loss 0.21014909446239471, acc=0.9271110892295837, loss=0.21014909446239471
test: epoch 102, loss 0.8852062225341797, acc=0.7250000238418579, loss=0.8852062225341797
train: epoch 103, loss 0.2059611827135086, acc=0.9276666641235352, loss=0.2059611827135086
test: epoch 103, loss 0.8914576172828674, acc=0.7277777791023254, loss=0.8914576172828674
train: epoch 104, loss 0.19583061337471008, acc=0.929111123085022, loss=0.19583061337471008
test: epoch 104, loss 1.048214077949524, acc=0.7250000238418579, loss=1.048214077949524
train: epoch 105, loss 0.20626796782016754, acc=0.926277756690979, loss=0.20626796782016754
test: epoch 105, loss 0.9758299589157104, acc=0.7333333492279053, loss=0.9758299589157104
train: epoch 106, loss 0.2091248333454132, acc=0.9271110892295837, loss=0.2091248333454132
test: epoch 106, loss 0.9399063587188721, acc=0.7333333492279053, loss=0.9399063587188721
train: epoch 107, loss 0.2153993844985962, acc=0.9276111125946045, loss=0.2153993844985962
test: epoch 107, loss 0.8100475072860718, acc=0.7388888597488403, loss=0.8100475072860718
train: epoch 108, loss 0.20181283354759216, acc=0.930055558681488, loss=0.20181283354759216
test: epoch 108, loss 0.9701621532440186, acc=0.7361111044883728, loss=0.9701621532440186
train: epoch 109, loss 0.1972191333770752, acc=0.9306666851043701, loss=0.1972191333770752
test: epoch 109, loss 0.85312420129776, acc=0.75, loss=0.85312420129776
train: epoch 110, loss 0.2023719996213913, acc=0.9293333292007446, loss=0.2023719996213913
test: epoch 110, loss 0.8644547462463379, acc=0.7638888955116272, loss=0.8644547462463379
train: epoch 111, loss 0.19929294288158417, acc=0.93022221326828, loss=0.19929294288158417
test: epoch 111, loss 0.9613057971000671, acc=0.7388888597488403, loss=0.9613057971000671
train: epoch 112, loss 0.20166271924972534, acc=0.9304444193840027, loss=0.20166271924972534
test: epoch 112, loss 1.0211288928985596, acc=0.7333333492279053, loss=1.0211288928985596
train: epoch 113, loss 0.20679745078086853, acc=0.9287777543067932, loss=0.20679745078086853
test: epoch 113, loss 0.8341096043586731, acc=0.7611111402511597, loss=0.8341096043586731
train: epoch 114, loss 0.2012520432472229, acc=0.9318333268165588, loss=0.2012520432472229
test: epoch 114, loss 0.8983219861984253, acc=0.7388888597488403, loss=0.8983219861984253
train: epoch 115, loss 0.1941041201353073, acc=0.9294999837875366, loss=0.1941041201353073
test: epoch 115, loss 0.9206080436706543, acc=0.7416666746139526, loss=0.9206080436706543
train: epoch 116, loss 0.19915606081485748, acc=0.9287222027778625, loss=0.19915606081485748
test: epoch 116, loss 0.9310106039047241, acc=0.7472222447395325, loss=0.9310106039047241
train: epoch 117, loss 0.1927407681941986, acc=0.9323889017105103, loss=0.1927407681941986
test: epoch 117, loss 1.0006388425827026, acc=0.7333333492279053, loss=1.0006388425827026
train: epoch 118, loss 0.20481644570827484, acc=0.9284999966621399, loss=0.20481644570827484
test: epoch 118, loss 0.8748801350593567, acc=0.7583333253860474, loss=0.8748801350593567
train: epoch 119, loss 0.20492394268512726, acc=0.9306111335754395, loss=0.20492394268512726
test: epoch 119, loss 0.8330156207084656, acc=0.7416666746139526, loss=0.8330156207084656
train: epoch 120, loss 0.19750750064849854, acc=0.9293333292007446, loss=0.19750750064849854
test: epoch 120, loss 0.8746194243431091, acc=0.7444444298744202, loss=0.8746194243431091
train: epoch 121, loss 0.23345717787742615, acc=0.9278333187103271, loss=0.23345717787742615
test: epoch 121, loss 0.8667044043540955, acc=0.7388888597488403, loss=0.8667044043540955
train: epoch 122, loss 0.19966410100460052, acc=0.9286110997200012, loss=0.19966410100460052
test: epoch 122, loss 0.9459870457649231, acc=0.7416666746139526, loss=0.9459870457649231
train: epoch 123, loss 0.2028251588344574, acc=0.9290555715560913, loss=0.2028251588344574
test: epoch 123, loss 1.0144926309585571, acc=0.7444444298744202, loss=1.0144926309585571
train: epoch 124, loss 0.2044314742088318, acc=0.9298333525657654, loss=0.2044314742088318
test: epoch 124, loss 0.7092807292938232, acc=0.7444444298744202, loss=0.7092807292938232
train: epoch 125, loss 0.1957569122314453, acc=0.9318333268165588, loss=0.1957569122314453
test: epoch 125, loss 0.9238793253898621, acc=0.7555555701255798, loss=0.9238793253898621
train: epoch 126, loss 0.2010076642036438, acc=0.9307222366333008, loss=0.2010076642036438
test: epoch 126, loss 0.9476120471954346, acc=0.7416666746139526, loss=0.9476120471954346
train: epoch 127, loss 0.19725178182125092, acc=0.9326666593551636, loss=0.19725178182125092
test: epoch 127, loss 0.8607074618339539, acc=0.769444465637207, loss=0.8607074618339539
train: epoch 128, loss 0.19477315247058868, acc=0.9324444532394409, loss=0.19477315247058868
test: epoch 128, loss 0.8816347718238831, acc=0.7611111402511597, loss=0.8816347718238831
train: epoch 129, loss 0.20427730679512024, acc=0.9284444451332092, loss=0.20427730679512024
test: epoch 129, loss 0.9183846712112427, acc=0.7472222447395325, loss=0.9183846712112427
train: epoch 130, loss 0.20576076209545135, acc=0.9287777543067932, loss=0.20576076209545135
test: epoch 130, loss 0.9189173579216003, acc=0.75, loss=0.9189173579216003
train: epoch 131, loss 0.2052103579044342, acc=0.9295555353164673, loss=0.2052103579044342
test: epoch 131, loss 0.7822464108467102, acc=0.769444465637207, loss=0.7822464108467102
train: epoch 132, loss 0.20092719793319702, acc=0.930388867855072, loss=0.20092719793319702
test: epoch 132, loss 0.8151730298995972, acc=0.75, loss=0.8151730298995972
train: epoch 133, loss 0.20453232526779175, acc=0.9283333420753479, loss=0.20453232526779175
test: epoch 133, loss 0.8454762697219849, acc=0.75, loss=0.8454762697219849
train: epoch 134, loss 0.21982167661190033, acc=0.9303333163261414, loss=0.21982167661190033
test: epoch 134, loss 0.8648542761802673, acc=0.75, loss=0.8648542761802673
train: epoch 135, loss 0.20264114439487457, acc=0.9280555844306946, loss=0.20264114439487457
test: epoch 135, loss 0.8071509599685669, acc=0.7666666507720947, loss=0.8071509599685669
train: epoch 136, loss 0.20051716268062592, acc=0.9290000200271606, loss=0.20051716268062592
test: epoch 136, loss 0.7126597166061401, acc=0.7777777910232544, loss=0.7126597166061401
train: epoch 137, loss 0.20172277092933655, acc=0.9282222390174866, loss=0.20172277092933655
test: epoch 137, loss 0.7501656413078308, acc=0.75, loss=0.7501656413078308
train: epoch 138, loss 0.20895421504974365, acc=0.9288333058357239, loss=0.20895421504974365
test: epoch 138, loss 0.882102906703949, acc=0.769444465637207, loss=0.882102906703949
train: epoch 139, loss 0.20023810863494873, acc=0.9291666746139526, loss=0.20023810863494873
test: epoch 139, loss 0.9088007807731628, acc=0.769444465637207, loss=0.9088007807731628
train: epoch 140, loss 0.21097202599048615, acc=0.9281666874885559, loss=0.21097202599048615
test: epoch 140, loss 0.8073434829711914, acc=0.7611111402511597, loss=0.8073434829711914
train: epoch 141, loss 0.1925451010465622, acc=0.9318333268165588, loss=0.1925451010465622
test: epoch 141, loss 0.7306028604507446, acc=0.7805555462837219, loss=0.7306028604507446
train: epoch 142, loss 0.19649995863437653, acc=0.92894446849823, loss=0.19649995863437653
test: epoch 142, loss 0.7743666172027588, acc=0.769444465637207, loss=0.7743666172027588
train: epoch 143, loss 0.19852960109710693, acc=0.9301666617393494, loss=0.19852960109710693
test: epoch 143, loss 0.7854876518249512, acc=0.7583333253860474, loss=0.7854876518249512
train: epoch 144, loss 0.2058270126581192, acc=0.9283333420753479, loss=0.2058270126581192
test: epoch 144, loss 0.9006666541099548, acc=0.7722222208976746, loss=0.9006666541099548
train: epoch 145, loss 0.208285391330719, acc=0.9312222003936768, loss=0.208285391330719
test: epoch 145, loss 0.7709815502166748, acc=0.7527777552604675, loss=0.7709815502166748
train: epoch 146, loss 0.20209139585494995, acc=0.9314444661140442, loss=0.20209139585494995
test: epoch 146, loss 0.872742235660553, acc=0.7722222208976746, loss=0.872742235660553
train: epoch 147, loss 0.18642497062683105, acc=0.933055579662323, loss=0.18642497062683105
test: epoch 147, loss 0.8432032465934753, acc=0.7527777552604675, loss=0.8432032465934753
train: epoch 148, loss 0.20377863943576813, acc=0.930055558681488, loss=0.20377863943576813
test: epoch 148, loss 0.8342831134796143, acc=0.7722222208976746, loss=0.8342831134796143
train: epoch 149, loss 0.19473429024219513, acc=0.9309444427490234, loss=0.19473429024219513
test: epoch 149, loss 0.7790892720222473, acc=0.7527777552604675, loss=0.7790892720222473
train: epoch 150, loss 0.19696946442127228, acc=0.9313333630561829, loss=0.19696946442127228
test: epoch 150, loss 0.971418559551239, acc=0.7666666507720947, loss=0.971418559551239
