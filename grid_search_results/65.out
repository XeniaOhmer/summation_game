# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=1", "--temp_decay=0.995", "--one_hot=false", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=393010063, receiver_embed_dim=64, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.014836311340332, acc=0.07672221958637238, loss=3.014836311340332
test: epoch 1, loss 2.8092451095581055, acc=0.11666666716337204, loss=2.8092451095581055
train: epoch 2, loss 2.0889155864715576, acc=0.20505554974079132, loss=2.0889155864715576
test: epoch 2, loss 2.3383586406707764, acc=0.18611110746860504, loss=2.3383586406707764
train: epoch 3, loss 1.649476408958435, acc=0.3209444582462311, loss=1.649476408958435
test: epoch 3, loss 2.1029577255249023, acc=0.23888888955116272, loss=2.1029577255249023
train: epoch 4, loss 1.318867564201355, acc=0.41100001335144043, loss=1.318867564201355
test: epoch 4, loss 1.6240648031234741, acc=0.3499999940395355, loss=1.6240648031234741
train: epoch 5, loss 1.1823166608810425, acc=0.4698333442211151, loss=1.1823166608810425
test: epoch 5, loss 1.503892421722412, acc=0.3472222089767456, loss=1.503892421722412
train: epoch 6, loss 1.0459482669830322, acc=0.5252777934074402, loss=1.0459482669830322
test: epoch 6, loss 1.4486331939697266, acc=0.36666667461395264, loss=1.4486331939697266
train: epoch 7, loss 0.9856705069541931, acc=0.5526111125946045, loss=0.9856705069541931
test: epoch 7, loss 1.3562287092208862, acc=0.3916666805744171, loss=1.3562287092208862
train: epoch 8, loss 0.9163500666618347, acc=0.5866110920906067, loss=0.9163500666618347
test: epoch 8, loss 1.3257678747177124, acc=0.4194444417953491, loss=1.3257678747177124
train: epoch 9, loss 0.8474465012550354, acc=0.6206111311912537, loss=0.8474465012550354
test: epoch 9, loss 1.4241684675216675, acc=0.43888887763023376, loss=1.4241684675216675
train: epoch 10, loss 0.8323135375976562, acc=0.6238333582878113, loss=0.8323135375976562
test: epoch 10, loss 1.305605411529541, acc=0.4305555522441864, loss=1.305605411529541
train: epoch 11, loss 0.7930346131324768, acc=0.6341111063957214, loss=0.7930346131324768
test: epoch 11, loss 1.291155219078064, acc=0.46388888359069824, loss=1.291155219078064
train: epoch 12, loss 0.7793852686882019, acc=0.6428889036178589, loss=0.7793852686882019
test: epoch 12, loss 1.235642910003662, acc=0.46388888359069824, loss=1.235642910003662
train: epoch 13, loss 0.7741912603378296, acc=0.6462222337722778, loss=0.7741912603378296
test: epoch 13, loss 1.1538361310958862, acc=0.4749999940395355, loss=1.1538361310958862
train: epoch 14, loss 0.7420839071273804, acc=0.6537777781486511, loss=0.7420839071273804
test: epoch 14, loss 1.1887649297714233, acc=0.4833333194255829, loss=1.1887649297714233
train: epoch 15, loss 0.7118240594863892, acc=0.6669999957084656, loss=0.7118240594863892
test: epoch 15, loss 1.4169243574142456, acc=0.4861111044883728, loss=1.4169243574142456
train: epoch 16, loss 0.7296895384788513, acc=0.6577777862548828, loss=0.7296895384788513
test: epoch 16, loss 1.2139924764633179, acc=0.4861111044883728, loss=1.2139924764633179
train: epoch 17, loss 0.7340267896652222, acc=0.6629444360733032, loss=0.7340267896652222
test: epoch 17, loss 1.258325219154358, acc=0.4861111044883728, loss=1.258325219154358
train: epoch 18, loss 0.7115594744682312, acc=0.6639999747276306, loss=0.7115594744682312
test: epoch 18, loss 1.41573965549469, acc=0.4888888895511627, loss=1.41573965549469
train: epoch 19, loss 0.7134749889373779, acc=0.6650000214576721, loss=0.7134749889373779
test: epoch 19, loss 1.1678967475891113, acc=0.4861111044883728, loss=1.1678967475891113
train: epoch 20, loss 0.7180368304252625, acc=0.6592222452163696, loss=0.7180368304252625
test: epoch 20, loss 1.2025196552276611, acc=0.4833333194255829, loss=1.2025196552276611
train: epoch 21, loss 0.7040880918502808, acc=0.6702222228050232, loss=0.7040880918502808
test: epoch 21, loss 1.214334487915039, acc=0.49444442987442017, loss=1.214334487915039
train: epoch 22, loss 0.7050668597221375, acc=0.670722246170044, loss=0.7050668597221375
test: epoch 22, loss 1.3177040815353394, acc=0.5, loss=1.3177040815353394
train: epoch 23, loss 0.7008659839630127, acc=0.6698333621025085, loss=0.7008659839630127
test: epoch 23, loss 1.2250089645385742, acc=0.5, loss=1.2250089645385742
train: epoch 24, loss 0.6829128265380859, acc=0.683555543422699, loss=0.6829128265380859
test: epoch 24, loss 1.2179080247879028, acc=0.5, loss=1.2179080247879028
train: epoch 25, loss 0.6889386773109436, acc=0.6801666617393494, loss=0.6889386773109436
test: epoch 25, loss 1.146390676498413, acc=0.5, loss=1.146390676498413
train: epoch 26, loss 0.6914530396461487, acc=0.6754444241523743, loss=0.6914530396461487
test: epoch 26, loss 1.4059200286865234, acc=0.4972222149372101, loss=1.4059200286865234
train: epoch 27, loss 0.6651644110679626, acc=0.690500020980835, loss=0.6651644110679626
test: epoch 27, loss 1.3793314695358276, acc=0.4972222149372101, loss=1.3793314695358276
train: epoch 28, loss 0.6633313894271851, acc=0.6879444718360901, loss=0.6633313894271851
test: epoch 28, loss 1.2190337181091309, acc=0.5, loss=1.2190337181091309
train: epoch 29, loss 0.6798743605613708, acc=0.6825000047683716, loss=0.6798743605613708
test: epoch 29, loss 1.2556549310684204, acc=0.4972222149372101, loss=1.2556549310684204
train: epoch 30, loss 0.6516104340553284, acc=0.6889444589614868, loss=0.6516104340553284
test: epoch 30, loss 1.185610294342041, acc=0.49444442987442017, loss=1.185610294342041
train: epoch 31, loss 0.6814920902252197, acc=0.6826666593551636, loss=0.6814920902252197
test: epoch 31, loss 1.267762541770935, acc=0.49444442987442017, loss=1.267762541770935
train: epoch 32, loss 0.6709420084953308, acc=0.684166669845581, loss=0.6709420084953308
test: epoch 32, loss 1.1472563743591309, acc=0.5, loss=1.1472563743591309
train: epoch 33, loss 0.6527842283248901, acc=0.6935555338859558, loss=0.6527842283248901
test: epoch 33, loss 1.3355823755264282, acc=0.5, loss=1.3355823755264282
train: epoch 34, loss 0.6538033485412598, acc=0.6911110877990723, loss=0.6538033485412598
test: epoch 34, loss 1.2716156244277954, acc=0.4972222149372101, loss=1.2716156244277954
train: epoch 35, loss 0.656843900680542, acc=0.6947222352027893, loss=0.656843900680542
test: epoch 35, loss 1.1868966817855835, acc=0.5, loss=1.1868966817855835
train: epoch 36, loss 0.6845468282699585, acc=0.6770555377006531, loss=0.6845468282699585
test: epoch 36, loss 1.1137573719024658, acc=0.4972222149372101, loss=1.1137573719024658
train: epoch 37, loss 0.6538397073745728, acc=0.6896111369132996, loss=0.6538397073745728
test: epoch 37, loss 1.293784260749817, acc=0.5, loss=1.293784260749817
train: epoch 38, loss 0.635930597782135, acc=0.6936666369438171, loss=0.635930597782135
test: epoch 38, loss 1.2978910207748413, acc=0.5, loss=1.2978910207748413
train: epoch 39, loss 0.630519449710846, acc=0.7002778053283691, loss=0.630519449710846
test: epoch 39, loss 1.2401182651519775, acc=0.5027777552604675, loss=1.2401182651519775
train: epoch 40, loss 0.6318562626838684, acc=0.6976110935211182, loss=0.6318562626838684
test: epoch 40, loss 1.3271902799606323, acc=0.4972222149372101, loss=1.3271902799606323
train: epoch 41, loss 0.6570743918418884, acc=0.6930000185966492, loss=0.6570743918418884
test: epoch 41, loss 1.2947956323623657, acc=0.5, loss=1.2947956323623657
train: epoch 42, loss 0.6437973380088806, acc=0.6970555782318115, loss=0.6437973380088806
test: epoch 42, loss 1.218514084815979, acc=0.49166667461395264, loss=1.218514084815979
train: epoch 43, loss 0.6309890747070312, acc=0.7032777667045593, loss=0.6309890747070312
test: epoch 43, loss 1.0834026336669922, acc=0.5277777910232544, loss=1.0834026336669922
train: epoch 44, loss 0.6464767456054688, acc=0.6953333616256714, loss=0.6464767456054688
test: epoch 44, loss 1.24730384349823, acc=0.5277777910232544, loss=1.24730384349823
train: epoch 45, loss 0.6219029426574707, acc=0.70333331823349, loss=0.6219029426574707
test: epoch 45, loss 1.313884973526001, acc=0.5361111164093018, loss=1.313884973526001
train: epoch 46, loss 0.6318960189819336, acc=0.6986111402511597, loss=0.6318960189819336
test: epoch 46, loss 1.2029494047164917, acc=0.5333333611488342, loss=1.2029494047164917
train: epoch 47, loss 0.6142823696136475, acc=0.7027222514152527, loss=0.6142823696136475
test: epoch 47, loss 1.257849097251892, acc=0.5305555462837219, loss=1.257849097251892
train: epoch 48, loss 0.6288976073265076, acc=0.7005000114440918, loss=0.6288976073265076
test: epoch 48, loss 1.1270045042037964, acc=0.5361111164093018, loss=1.1270045042037964
train: epoch 49, loss 0.6441436409950256, acc=0.6965555548667908, loss=0.6441436409950256
test: epoch 49, loss 1.1718562841415405, acc=0.5333333611488342, loss=1.1718562841415405
train: epoch 50, loss 0.6673800945281982, acc=0.6883333325386047, loss=0.6673800945281982
test: epoch 50, loss 1.1298158168792725, acc=0.5388888716697693, loss=1.1298158168792725
train: epoch 51, loss 0.6210672855377197, acc=0.7037222385406494, loss=0.6210672855377197
test: epoch 51, loss 1.1904903650283813, acc=0.5361111164093018, loss=1.1904903650283813
train: epoch 52, loss 0.6218780875205994, acc=0.7034444212913513, loss=0.6218780875205994
test: epoch 52, loss 1.0684086084365845, acc=0.5361111164093018, loss=1.0684086084365845
train: epoch 53, loss 0.6502518653869629, acc=0.6947222352027893, loss=0.6502518653869629
test: epoch 53, loss 1.2534406185150146, acc=0.5361111164093018, loss=1.2534406185150146
train: epoch 54, loss 0.6191082000732422, acc=0.7039999961853027, loss=0.6191082000732422
test: epoch 54, loss 1.145160436630249, acc=0.5361111164093018, loss=1.145160436630249
train: epoch 55, loss 0.6345763802528381, acc=0.7005555629730225, loss=0.6345763802528381
test: epoch 55, loss 1.1346769332885742, acc=0.5361111164093018, loss=1.1346769332885742
train: epoch 56, loss 0.6219624280929565, acc=0.7055000066757202, loss=0.6219624280929565
test: epoch 56, loss 1.1850336790084839, acc=0.5333333611488342, loss=1.1850336790084839
train: epoch 57, loss 0.5981187224388123, acc=0.711388885974884, loss=0.5981187224388123
test: epoch 57, loss 1.22953200340271, acc=0.5361111164093018, loss=1.22953200340271
train: epoch 58, loss 0.64235520362854, acc=0.6988333463668823, loss=0.64235520362854
test: epoch 58, loss 1.1346396207809448, acc=0.5305555462837219, loss=1.1346396207809448
train: epoch 59, loss 0.6205209493637085, acc=0.7055000066757202, loss=0.6205209493637085
test: epoch 59, loss 1.2350081205368042, acc=0.5333333611488342, loss=1.2350081205368042
train: epoch 60, loss 0.5914177894592285, acc=0.7121666669845581, loss=0.5914177894592285
test: epoch 60, loss 1.1862667798995972, acc=0.5333333611488342, loss=1.1862667798995972
train: epoch 61, loss 0.629885196685791, acc=0.7034444212913513, loss=0.629885196685791
test: epoch 61, loss 1.2180209159851074, acc=0.5277777910232544, loss=1.2180209159851074
train: epoch 62, loss 0.622008204460144, acc=0.7078889012336731, loss=0.622008204460144
test: epoch 62, loss 1.1985124349594116, acc=0.5361111164093018, loss=1.1985124349594116
train: epoch 63, loss 0.5979907512664795, acc=0.7148333191871643, loss=0.5979907512664795
test: epoch 63, loss 1.1735955476760864, acc=0.5361111164093018, loss=1.1735955476760864
train: epoch 64, loss 0.5869845747947693, acc=0.7192777991294861, loss=0.5869845747947693
test: epoch 64, loss 1.1743190288543701, acc=0.5361111164093018, loss=1.1743190288543701
train: epoch 65, loss 0.5986440181732178, acc=0.7149444222450256, loss=0.5986440181732178
test: epoch 65, loss 1.1785420179367065, acc=0.5388888716697693, loss=1.1785420179367065
train: epoch 66, loss 0.6085590124130249, acc=0.7151666879653931, loss=0.6085590124130249
test: epoch 66, loss 1.0704965591430664, acc=0.5388888716697693, loss=1.0704965591430664
train: epoch 67, loss 0.5861312747001648, acc=0.7206666469573975, loss=0.5861312747001648
test: epoch 67, loss 1.3422163724899292, acc=0.5388888716697693, loss=1.3422163724899292
train: epoch 68, loss 0.5969088077545166, acc=0.721833348274231, loss=0.5969088077545166
test: epoch 68, loss 1.2359505891799927, acc=0.5388888716697693, loss=1.2359505891799927
train: epoch 69, loss 0.609611451625824, acc=0.7174444198608398, loss=0.609611451625824
test: epoch 69, loss 1.1226122379302979, acc=0.5388888716697693, loss=1.1226122379302979
train: epoch 70, loss 0.5934889316558838, acc=0.719944417476654, loss=0.5934889316558838
test: epoch 70, loss 1.1364974975585938, acc=0.5388888716697693, loss=1.1364974975585938
train: epoch 71, loss 0.6069522500038147, acc=0.7136666774749756, loss=0.6069522500038147
test: epoch 71, loss 1.0413202047348022, acc=0.5361111164093018, loss=1.0413202047348022
train: epoch 72, loss 0.5848479270935059, acc=0.715499997138977, loss=0.5848479270935059
test: epoch 72, loss 1.270790934562683, acc=0.5305555462837219, loss=1.270790934562683
train: epoch 73, loss 0.606967568397522, acc=0.7132222056388855, loss=0.606967568397522
test: epoch 73, loss 1.2797244787216187, acc=0.5305555462837219, loss=1.2797244787216187
train: epoch 74, loss 0.6218526363372803, acc=0.7128888964653015, loss=0.6218526363372803
test: epoch 74, loss 1.2277365922927856, acc=0.5249999761581421, loss=1.2277365922927856
train: epoch 75, loss 0.6098368167877197, acc=0.7170555591583252, loss=0.6098368167877197
test: epoch 75, loss 1.299269437789917, acc=0.5305555462837219, loss=1.299269437789917
train: epoch 76, loss 0.5901792049407959, acc=0.7206110954284668, loss=0.5901792049407959
test: epoch 76, loss 1.2666306495666504, acc=0.5277777910232544, loss=1.2666306495666504
train: epoch 77, loss 0.5803300142288208, acc=0.7289444208145142, loss=0.5803300142288208
test: epoch 77, loss 1.2651305198669434, acc=0.5277777910232544, loss=1.2651305198669434
train: epoch 78, loss 0.5521460175514221, acc=0.7383333444595337, loss=0.5521460175514221
test: epoch 78, loss 1.2382224798202515, acc=0.5305555462837219, loss=1.2382224798202515
train: epoch 79, loss 0.5514017343521118, acc=0.746055543422699, loss=0.5514017343521118
test: epoch 79, loss 1.271569013595581, acc=0.5333333611488342, loss=1.271569013595581
train: epoch 80, loss 0.5177965760231018, acc=0.753333330154419, loss=0.5177965760231018
test: epoch 80, loss 1.3289108276367188, acc=0.5333333611488342, loss=1.3289108276367188
train: epoch 81, loss 0.5106256604194641, acc=0.7548333406448364, loss=0.5106256604194641
test: epoch 81, loss 1.3232381343841553, acc=0.5305555462837219, loss=1.3232381343841553
train: epoch 82, loss 0.5325202941894531, acc=0.749666690826416, loss=0.5325202941894531
test: epoch 82, loss 1.2299405336380005, acc=0.5333333611488342, loss=1.2299405336380005
train: epoch 83, loss 0.5359826683998108, acc=0.7481111288070679, loss=0.5359826683998108
test: epoch 83, loss 1.188747525215149, acc=0.5305555462837219, loss=1.188747525215149
train: epoch 84, loss 0.5780768990516663, acc=0.7372221946716309, loss=0.5780768990516663
test: epoch 84, loss 1.3617701530456543, acc=0.5305555462837219, loss=1.3617701530456543
train: epoch 85, loss 0.5097418427467346, acc=0.7547777891159058, loss=0.5097418427467346
test: epoch 85, loss 1.2444865703582764, acc=0.5305555462837219, loss=1.2444865703582764
train: epoch 86, loss 0.5212242007255554, acc=0.7497777938842773, loss=0.5212242007255554
test: epoch 86, loss 1.4160631895065308, acc=0.5305555462837219, loss=1.4160631895065308
train: epoch 87, loss 0.5193248391151428, acc=0.750166654586792, loss=0.5193248391151428
test: epoch 87, loss 1.3017122745513916, acc=0.5305555462837219, loss=1.3017122745513916
train: epoch 88, loss 0.5089779496192932, acc=0.7549444437026978, loss=0.5089779496192932
test: epoch 88, loss 1.5213918685913086, acc=0.5305555462837219, loss=1.5213918685913086
train: epoch 89, loss 0.5188090801239014, acc=0.7514444589614868, loss=0.5188090801239014
test: epoch 89, loss 1.3306970596313477, acc=0.5333333611488342, loss=1.3306970596313477
train: epoch 90, loss 0.4845562279224396, acc=0.7670000195503235, loss=0.4845562279224396
test: epoch 90, loss 1.371642827987671, acc=0.5333333611488342, loss=1.371642827987671
train: epoch 91, loss 0.5450962781906128, acc=0.7540000081062317, loss=0.5450962781906128
test: epoch 91, loss 1.453352928161621, acc=0.5277777910232544, loss=1.453352928161621
train: epoch 92, loss 0.5261104106903076, acc=0.7575555443763733, loss=0.5261104106903076
test: epoch 92, loss 1.4129024744033813, acc=0.5333333611488342, loss=1.4129024744033813
train: epoch 93, loss 0.5025846362113953, acc=0.7601666450500488, loss=0.5025846362113953
test: epoch 93, loss 1.3782240152359009, acc=0.5333333611488342, loss=1.3782240152359009
train: epoch 94, loss 0.49012094736099243, acc=0.757888913154602, loss=0.49012094736099243
test: epoch 94, loss 1.2757538557052612, acc=0.5333333611488342, loss=1.2757538557052612
train: epoch 95, loss 0.45764482021331787, acc=0.769777774810791, loss=0.45764482021331787
test: epoch 95, loss 1.3599497079849243, acc=0.5777778029441833, loss=1.3599497079849243
train: epoch 96, loss 0.4936390221118927, acc=0.7589444518089294, loss=0.4936390221118927
test: epoch 96, loss 1.149538278579712, acc=0.5805555582046509, loss=1.149538278579712
train: epoch 97, loss 0.48213139176368713, acc=0.7651110887527466, loss=0.48213139176368713
test: epoch 97, loss 1.2441831827163696, acc=0.574999988079071, loss=1.2441831827163696
train: epoch 98, loss 0.47000810503959656, acc=0.770111083984375, loss=0.47000810503959656
test: epoch 98, loss 1.3200407028198242, acc=0.5777778029441833, loss=1.3200407028198242
train: epoch 99, loss 0.4824514389038086, acc=0.7646666765213013, loss=0.4824514389038086
test: epoch 99, loss 1.2648029327392578, acc=0.5777778029441833, loss=1.2648029327392578
train: epoch 100, loss 0.5419093370437622, acc=0.7531111240386963, loss=0.5419093370437622
test: epoch 100, loss 1.0767077207565308, acc=0.5694444179534912, loss=1.0767077207565308
train: epoch 101, loss 0.4764748513698578, acc=0.768666684627533, loss=0.4764748513698578
test: epoch 101, loss 1.1944384574890137, acc=0.574999988079071, loss=1.1944384574890137
train: epoch 102, loss 0.480621337890625, acc=0.7697222232818604, loss=0.480621337890625
test: epoch 102, loss 1.2043734788894653, acc=0.5805555582046509, loss=1.2043734788894653
train: epoch 103, loss 0.4732036888599396, acc=0.7732222080230713, loss=0.4732036888599396
test: epoch 103, loss 1.1662752628326416, acc=0.5722222328186035, loss=1.1662752628326416
train: epoch 104, loss 0.46301957964897156, acc=0.7759444713592529, loss=0.46301957964897156
test: epoch 104, loss 1.3332970142364502, acc=0.5583333373069763, loss=1.3332970142364502
train: epoch 105, loss 0.4740925431251526, acc=0.7725555300712585, loss=0.4740925431251526
test: epoch 105, loss 1.1244264841079712, acc=0.5805555582046509, loss=1.1244264841079712
train: epoch 106, loss 0.49505069851875305, acc=0.7663888931274414, loss=0.49505069851875305
test: epoch 106, loss 1.2738851308822632, acc=0.5805555582046509, loss=1.2738851308822632
train: epoch 107, loss 0.4936617314815521, acc=0.7702222466468811, loss=0.4936617314815521
test: epoch 107, loss 1.137196660041809, acc=0.5777778029441833, loss=1.137196660041809
train: epoch 108, loss 0.4725678563117981, acc=0.77311110496521, loss=0.4725678563117981
test: epoch 108, loss 1.360560417175293, acc=0.5722222328186035, loss=1.360560417175293
train: epoch 109, loss 0.46774378418922424, acc=0.7743889093399048, loss=0.46774378418922424
test: epoch 109, loss 1.2573391199111938, acc=0.574999988079071, loss=1.2573391199111938
train: epoch 110, loss 0.4824157655239105, acc=0.7714999914169312, loss=0.4824157655239105
test: epoch 110, loss 1.1675540208816528, acc=0.574999988079071, loss=1.1675540208816528
train: epoch 111, loss 0.4777890145778656, acc=0.7721111178398132, loss=0.4777890145778656
test: epoch 111, loss 1.2419477701187134, acc=0.574999988079071, loss=1.2419477701187134
train: epoch 112, loss 0.4767442047595978, acc=0.7726110816001892, loss=0.4767442047595978
test: epoch 112, loss 1.3177882432937622, acc=0.574999988079071, loss=1.3177882432937622
train: epoch 113, loss 0.5121241211891174, acc=0.7623888850212097, loss=0.5121241211891174
test: epoch 113, loss 1.1606333255767822, acc=0.5694444179534912, loss=1.1606333255767822
train: epoch 114, loss 0.4978020489215851, acc=0.7686111330986023, loss=0.4978020489215851
test: epoch 114, loss 1.1907939910888672, acc=0.5694444179534912, loss=1.1907939910888672
train: epoch 115, loss 0.49288395047187805, acc=0.7668889164924622, loss=0.49288395047187805
test: epoch 115, loss 1.1404993534088135, acc=0.574999988079071, loss=1.1404993534088135
train: epoch 116, loss 0.509044349193573, acc=0.7648333311080933, loss=0.509044349193573
test: epoch 116, loss 1.1174702644348145, acc=0.5722222328186035, loss=1.1174702644348145
train: epoch 117, loss 0.4916796088218689, acc=0.7656111121177673, loss=0.4916796088218689
test: epoch 117, loss 1.253793716430664, acc=0.574999988079071, loss=1.253793716430664
train: epoch 118, loss 0.478507936000824, acc=0.774222195148468, loss=0.478507936000824
test: epoch 118, loss 1.2422044277191162, acc=0.5861111283302307, loss=1.2422044277191162
train: epoch 119, loss 0.488768994808197, acc=0.7751666903495789, loss=0.488768994808197
test: epoch 119, loss 1.154109001159668, acc=0.5861111283302307, loss=1.154109001159668
train: epoch 120, loss 0.4361158013343811, acc=0.792388916015625, loss=0.4361158013343811
test: epoch 120, loss 1.1758489608764648, acc=0.605555534362793, loss=1.1758489608764648
train: epoch 121, loss 0.4220798909664154, acc=0.8023333549499512, loss=0.4220798909664154
test: epoch 121, loss 1.0796966552734375, acc=0.605555534362793, loss=1.0796966552734375
train: epoch 122, loss 0.425926148891449, acc=0.8042222261428833, loss=0.425926148891449
test: epoch 122, loss 1.133456826210022, acc=0.6027777791023254, loss=1.133456826210022
train: epoch 123, loss 0.46450236439704895, acc=0.7944444417953491, loss=0.46450236439704895
test: epoch 123, loss 1.200290560722351, acc=0.5916666388511658, loss=1.200290560722351
train: epoch 124, loss 0.43015390634536743, acc=0.8071110844612122, loss=0.43015390634536743
test: epoch 124, loss 1.299261212348938, acc=0.5805555582046509, loss=1.299261212348938
train: epoch 125, loss 0.4761066436767578, acc=0.7977222204208374, loss=0.4761066436767578
test: epoch 125, loss 1.2280758619308472, acc=0.605555534362793, loss=1.2280758619308472
train: epoch 126, loss 0.40828779339790344, acc=0.8153889179229736, loss=0.40828779339790344
test: epoch 126, loss 1.1862988471984863, acc=0.5972222089767456, loss=1.1862988471984863
train: epoch 127, loss 0.41740065813064575, acc=0.8149999976158142, loss=0.41740065813064575
test: epoch 127, loss 1.143677830696106, acc=0.5944444537162781, loss=1.143677830696106
train: epoch 128, loss 0.4038766920566559, acc=0.8174999952316284, loss=0.4038766920566559
test: epoch 128, loss 1.1776483058929443, acc=0.6111111044883728, loss=1.1776483058929443
train: epoch 129, loss 0.39915478229522705, acc=0.8181666731834412, loss=0.39915478229522705
test: epoch 129, loss 1.1430658102035522, acc=0.625, loss=1.1430658102035522
train: epoch 130, loss 0.3778674304485321, acc=0.824055552482605, loss=0.3778674304485321
test: epoch 130, loss 1.1691211462020874, acc=0.625, loss=1.1691211462020874
train: epoch 131, loss 0.3837663233280182, acc=0.8239444494247437, loss=0.3837663233280182
test: epoch 131, loss 1.1886417865753174, acc=0.5972222089767456, loss=1.1886417865753174
train: epoch 132, loss 0.43438583612442017, acc=0.8111110925674438, loss=0.43438583612442017
test: epoch 132, loss 1.1015411615371704, acc=0.625, loss=1.1015411615371704
train: epoch 133, loss 0.43732136487960815, acc=0.8084444403648376, loss=0.43732136487960815
test: epoch 133, loss 1.130864143371582, acc=0.625, loss=1.130864143371582
train: epoch 134, loss 0.41685599088668823, acc=0.8135555386543274, loss=0.41685599088668823
test: epoch 134, loss 1.1705169677734375, acc=0.6222222447395325, loss=1.1705169677734375
train: epoch 135, loss 0.46024173498153687, acc=0.804444432258606, loss=0.46024173498153687
test: epoch 135, loss 1.0830012559890747, acc=0.625, loss=1.0830012559890747
train: epoch 136, loss 0.40367385745048523, acc=0.8163889050483704, loss=0.40367385745048523
test: epoch 136, loss 1.1514674425125122, acc=0.625, loss=1.1514674425125122
train: epoch 137, loss 0.41792744398117065, acc=0.8128888607025146, loss=0.41792744398117065
test: epoch 137, loss 0.9342243075370789, acc=0.6277777552604675, loss=0.9342243075370789
train: epoch 138, loss 0.37863850593566895, acc=0.816777765750885, loss=0.37863850593566895
test: epoch 138, loss 1.3227685689926147, acc=0.6361111402511597, loss=1.3227685689926147
train: epoch 139, loss 0.40051573514938354, acc=0.8118333220481873, loss=0.40051573514938354
test: epoch 139, loss 0.9803019165992737, acc=0.6305555701255798, loss=0.9803019165992737
train: epoch 140, loss 0.4039260149002075, acc=0.8123888969421387, loss=0.4039260149002075
test: epoch 140, loss 1.0528563261032104, acc=0.625, loss=1.0528563261032104
train: epoch 141, loss 0.4094650149345398, acc=0.8130000233650208, loss=0.4094650149345398
test: epoch 141, loss 1.13971745967865, acc=0.6361111402511597, loss=1.13971745967865
train: epoch 142, loss 0.4102359414100647, acc=0.8097222447395325, loss=0.4102359414100647
test: epoch 142, loss 1.0761891603469849, acc=0.6277777552604675, loss=1.0761891603469849
train: epoch 143, loss 0.3815440237522125, acc=0.816277801990509, loss=0.3815440237522125
test: epoch 143, loss 1.1428513526916504, acc=0.6361111402511597, loss=1.1428513526916504
train: epoch 144, loss 0.3756565451622009, acc=0.8153333067893982, loss=0.3756565451622009
test: epoch 144, loss 1.0672578811645508, acc=0.6361111402511597, loss=1.0672578811645508
train: epoch 145, loss 0.41312044858932495, acc=0.8174444437026978, loss=0.41312044858932495
test: epoch 145, loss 1.2568390369415283, acc=0.6333333253860474, loss=1.2568390369415283
train: epoch 146, loss 0.38154491782188416, acc=0.8191666603088379, loss=0.38154491782188416
test: epoch 146, loss 1.165830135345459, acc=0.6333333253860474, loss=1.165830135345459
train: epoch 147, loss 0.39343416690826416, acc=0.820111095905304, loss=0.39343416690826416
test: epoch 147, loss 1.0652437210083008, acc=0.6583333611488342, loss=1.0652437210083008
train: epoch 148, loss 0.4272254705429077, acc=0.8118333220481873, loss=0.4272254705429077
test: epoch 148, loss 0.9794001579284668, acc=0.6527777910232544, loss=0.9794001579284668
train: epoch 149, loss 0.39381739497184753, acc=0.8233888745307922, loss=0.39381739497184753
test: epoch 149, loss 1.139752745628357, acc=0.675000011920929, loss=1.139752745628357
train: epoch 150, loss 0.35551416873931885, acc=0.8295000195503235, loss=0.35551416873931885
test: epoch 150, loss 0.9168285131454468, acc=0.6861110925674438, loss=0.9168285131454468
