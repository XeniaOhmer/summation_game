# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=1.5", "--temp_decay=1", "--one_hot=true", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=2014004949, receiver_embed_dim=64, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.305331230163574, acc=0.06355555355548859, loss=3.305331230163574
test: epoch 1, loss 3.592268228530884, acc=0.0833333358168602, loss=3.592268228530884
train: epoch 2, loss 2.176199436187744, acc=0.21511110663414001, loss=2.176199436187744
test: epoch 2, loss 2.9193778038024902, acc=0.10000000149011612, loss=2.9193778038024902
train: epoch 3, loss 1.677832841873169, acc=0.33472222089767456, loss=1.677832841873169
test: epoch 3, loss 2.662661075592041, acc=0.1388888955116272, loss=2.662661075592041
train: epoch 4, loss 1.4826401472091675, acc=0.3976111114025116, loss=1.4826401472091675
test: epoch 4, loss 2.5190305709838867, acc=0.1666666716337204, loss=2.5190305709838867
train: epoch 5, loss 1.3408766984939575, acc=0.46033334732055664, loss=1.3408766984939575
test: epoch 5, loss 2.61871337890625, acc=0.1805555522441864, loss=2.61871337890625
train: epoch 6, loss 1.2238010168075562, acc=0.508388876914978, loss=1.2238010168075562
test: epoch 6, loss 2.5701491832733154, acc=0.16944444179534912, loss=2.5701491832733154
train: epoch 7, loss 1.1446669101715088, acc=0.5381110906600952, loss=1.1446669101715088
test: epoch 7, loss 2.479556083679199, acc=0.21388888359069824, loss=2.479556083679199
train: epoch 8, loss 1.0681601762771606, acc=0.5700555443763733, loss=1.0681601762771606
test: epoch 8, loss 2.488062858581543, acc=0.20555555820465088, loss=2.488062858581543
train: epoch 9, loss 1.006057858467102, acc=0.6001111268997192, loss=1.006057858467102
test: epoch 9, loss 2.5648152828216553, acc=0.24166665971279144, loss=2.5648152828216553
train: epoch 10, loss 0.952548623085022, acc=0.6232222318649292, loss=0.952548623085022
test: epoch 10, loss 2.391503095626831, acc=0.23888888955116272, loss=2.391503095626831
train: epoch 11, loss 0.9049279689788818, acc=0.6461111307144165, loss=0.9049279689788818
test: epoch 11, loss 2.546802520751953, acc=0.22777777910232544, loss=2.546802520751953
train: epoch 12, loss 0.8660044074058533, acc=0.6627777814865112, loss=0.8660044074058533
test: epoch 12, loss 2.350285530090332, acc=0.2361111044883728, loss=2.350285530090332
train: epoch 13, loss 0.8252953290939331, acc=0.6818888783454895, loss=0.8252953290939331
test: epoch 13, loss 2.2106821537017822, acc=0.25555557012557983, loss=2.2106821537017822
train: epoch 14, loss 0.793328583240509, acc=0.6974444389343262, loss=0.793328583240509
test: epoch 14, loss 2.3327598571777344, acc=0.25555557012557983, loss=2.3327598571777344
train: epoch 15, loss 0.7589070796966553, acc=0.7067777514457703, loss=0.7589070796966553
test: epoch 15, loss 2.1697347164154053, acc=0.2638888955116272, loss=2.1697347164154053
train: epoch 16, loss 0.7246206998825073, acc=0.7215555310249329, loss=0.7246206998825073
test: epoch 16, loss 2.1592044830322266, acc=0.26944443583488464, loss=2.1592044830322266
train: epoch 17, loss 0.7091273069381714, acc=0.7296666502952576, loss=0.7091273069381714
test: epoch 17, loss 2.2600820064544678, acc=0.2777777910232544, loss=2.2600820064544678
train: epoch 18, loss 0.6746601462364197, acc=0.7434444427490234, loss=0.6746601462364197
test: epoch 18, loss 2.2508442401885986, acc=0.2777777910232544, loss=2.2508442401885986
train: epoch 19, loss 0.6507649421691895, acc=0.7523888945579529, loss=0.6507649421691895
test: epoch 19, loss 2.1609177589416504, acc=0.2777777910232544, loss=2.1609177589416504
train: epoch 20, loss 0.6404498815536499, acc=0.7542222142219543, loss=0.6404498815536499
test: epoch 20, loss 2.0315001010894775, acc=0.31111112236976624, loss=2.0315001010894775
train: epoch 21, loss 0.6154090762138367, acc=0.7663888931274414, loss=0.6154090762138367
test: epoch 21, loss 2.1037516593933105, acc=0.30000001192092896, loss=2.1037516593933105
train: epoch 22, loss 0.5972850918769836, acc=0.7730000019073486, loss=0.5972850918769836
test: epoch 22, loss 2.103086471557617, acc=0.28333333134651184, loss=2.103086471557617
train: epoch 23, loss 0.6006529927253723, acc=0.7712222337722778, loss=0.6006529927253723
test: epoch 23, loss 2.0118231773376465, acc=0.3222222328186035, loss=2.0118231773376465
train: epoch 24, loss 0.5694496631622314, acc=0.7842777967453003, loss=0.5694496631622314
test: epoch 24, loss 2.0830209255218506, acc=0.3027777671813965, loss=2.0830209255218506
train: epoch 25, loss 0.5557505488395691, acc=0.7914444208145142, loss=0.5557505488395691
test: epoch 25, loss 2.111259937286377, acc=0.3333333432674408, loss=2.111259937286377
train: epoch 26, loss 0.5293182134628296, acc=0.7988888621330261, loss=0.5293182134628296
test: epoch 26, loss 2.0964152812957764, acc=0.33888888359069824, loss=2.0964152812957764
train: epoch 27, loss 0.5199624300003052, acc=0.8045555353164673, loss=0.5199624300003052
test: epoch 27, loss 2.0378079414367676, acc=0.35555556416511536, loss=2.0378079414367676
train: epoch 28, loss 0.5014054179191589, acc=0.8098333477973938, loss=0.5014054179191589
test: epoch 28, loss 2.248051643371582, acc=0.33888888359069824, loss=2.248051643371582
train: epoch 29, loss 0.48823902010917664, acc=0.8185555338859558, loss=0.48823902010917664
test: epoch 29, loss 2.1110751628875732, acc=0.35555556416511536, loss=2.1110751628875732
train: epoch 30, loss 0.4917069673538208, acc=0.8171111345291138, loss=0.4917069673538208
test: epoch 30, loss 2.0394890308380127, acc=0.33888888359069824, loss=2.0394890308380127
train: epoch 31, loss 0.46831944584846497, acc=0.8208333253860474, loss=0.46831944584846497
test: epoch 31, loss 2.1834335327148438, acc=0.35277777910232544, loss=2.1834335327148438
train: epoch 32, loss 0.4597000479698181, acc=0.8288888931274414, loss=0.4597000479698181
test: epoch 32, loss 2.2097487449645996, acc=0.375, loss=2.2097487449645996
train: epoch 33, loss 0.44970911741256714, acc=0.8333333134651184, loss=0.44970911741256714
test: epoch 33, loss 2.181485414505005, acc=0.3444444537162781, loss=2.181485414505005
train: epoch 34, loss 0.43907326459884644, acc=0.8361111283302307, loss=0.43907326459884644
test: epoch 34, loss 2.1656806468963623, acc=0.38333332538604736, loss=2.1656806468963623
train: epoch 35, loss 0.42045846581459045, acc=0.8421111106872559, loss=0.42045846581459045
test: epoch 35, loss 2.151679039001465, acc=0.38333332538604736, loss=2.151679039001465
train: epoch 36, loss 0.4157017171382904, acc=0.8443889021873474, loss=0.4157017171382904
test: epoch 36, loss 2.2148990631103516, acc=0.375, loss=2.2148990631103516
train: epoch 37, loss 0.4058362543582916, acc=0.8503333330154419, loss=0.4058362543582916
test: epoch 37, loss 2.223116397857666, acc=0.3888888955116272, loss=2.223116397857666
train: epoch 38, loss 0.3936147093772888, acc=0.8529999852180481, loss=0.3936147093772888
test: epoch 38, loss 2.2565035820007324, acc=0.3444444537162781, loss=2.2565035820007324
train: epoch 39, loss 0.38655200600624084, acc=0.8542777895927429, loss=0.38655200600624084
test: epoch 39, loss 2.2519114017486572, acc=0.3638888895511627, loss=2.2519114017486572
train: epoch 40, loss 0.37543997168540955, acc=0.8626111149787903, loss=0.37543997168540955
test: epoch 40, loss 2.029165744781494, acc=0.39722222089767456, loss=2.029165744781494
train: epoch 41, loss 0.36972543597221375, acc=0.8633888959884644, loss=0.36972543597221375
test: epoch 41, loss 2.164687156677246, acc=0.38055557012557983, loss=2.164687156677246
train: epoch 42, loss 0.35491475462913513, acc=0.8696110844612122, loss=0.35491475462913513
test: epoch 42, loss 2.05595326423645, acc=0.36666667461395264, loss=2.05595326423645
train: epoch 43, loss 0.3496991693973541, acc=0.8682777881622314, loss=0.3496991693973541
test: epoch 43, loss 2.10109806060791, acc=0.41111111640930176, loss=2.10109806060791
train: epoch 44, loss 0.33894896507263184, acc=0.8740000128746033, loss=0.33894896507263184
test: epoch 44, loss 1.98728609085083, acc=0.39722222089767456, loss=1.98728609085083
train: epoch 45, loss 0.3236261010169983, acc=0.8793333172798157, loss=0.3236261010169983
test: epoch 45, loss 1.978129267692566, acc=0.4194444417953491, loss=1.978129267692566
train: epoch 46, loss 0.3129628300666809, acc=0.8886111378669739, loss=0.3129628300666809
test: epoch 46, loss 2.0327742099761963, acc=0.41111111640930176, loss=2.0327742099761963
train: epoch 47, loss 0.3045285642147064, acc=0.8877221941947937, loss=0.3045285642147064
test: epoch 47, loss 1.983109951019287, acc=0.40833333134651184, loss=1.983109951019287
train: epoch 48, loss 0.30530819296836853, acc=0.8904444575309753, loss=0.30530819296836853
test: epoch 48, loss 2.175021171569824, acc=0.36666667461395264, loss=2.175021171569824
train: epoch 49, loss 0.29713767766952515, acc=0.8921666741371155, loss=0.29713767766952515
test: epoch 49, loss 2.0752975940704346, acc=0.4444444477558136, loss=2.0752975940704346
train: epoch 50, loss 0.29112744331359863, acc=0.8927778005599976, loss=0.29112744331359863
test: epoch 50, loss 2.216668128967285, acc=0.39722222089767456, loss=2.216668128967285
train: epoch 51, loss 0.2756083309650421, acc=0.8992778062820435, loss=0.2756083309650421
test: epoch 51, loss 2.075190782546997, acc=0.42500001192092896, loss=2.075190782546997
train: epoch 52, loss 0.26962223649024963, acc=0.901888906955719, loss=0.26962223649024963
test: epoch 52, loss 2.1411430835723877, acc=0.4027777910232544, loss=2.1411430835723877
train: epoch 53, loss 0.2673645615577698, acc=0.9019444584846497, loss=0.2673645615577698
test: epoch 53, loss 2.0500104427337646, acc=0.4166666567325592, loss=2.0500104427337646
train: epoch 54, loss 0.2585501968860626, acc=0.9073888659477234, loss=0.2585501968860626
test: epoch 54, loss 2.2627532482147217, acc=0.4194444417953491, loss=2.2627532482147217
train: epoch 55, loss 0.25830215215682983, acc=0.9062777757644653, loss=0.25830215215682983
test: epoch 55, loss 2.2058703899383545, acc=0.43888887763023376, loss=2.2058703899383545
train: epoch 56, loss 0.24766527116298676, acc=0.9099444150924683, loss=0.24766527116298676
test: epoch 56, loss 2.2615137100219727, acc=0.4333333373069763, loss=2.2615137100219727
train: epoch 57, loss 0.2412189096212387, acc=0.9116666913032532, loss=0.2412189096212387
test: epoch 57, loss 2.162755012512207, acc=0.41111111640930176, loss=2.162755012512207
train: epoch 58, loss 0.24299253523349762, acc=0.9127222299575806, loss=0.24299253523349762
test: epoch 58, loss 2.049192428588867, acc=0.4277777671813965, loss=2.049192428588867
train: epoch 59, loss 0.2239927053451538, acc=0.9176666736602783, loss=0.2239927053451538
test: epoch 59, loss 2.2165558338165283, acc=0.4277777671813965, loss=2.2165558338165283
train: epoch 60, loss 0.2257494181394577, acc=0.917888879776001, loss=0.2257494181394577
test: epoch 60, loss 2.3253049850463867, acc=0.43888887763023376, loss=2.3253049850463867
train: epoch 61, loss 0.23396793007850647, acc=0.914555549621582, loss=0.23396793007850647
test: epoch 61, loss 2.1183085441589355, acc=0.4722222089767456, loss=2.1183085441589355
train: epoch 62, loss 0.22524584829807281, acc=0.9165555834770203, loss=0.22524584829807281
test: epoch 62, loss 2.3830342292785645, acc=0.4027777910232544, loss=2.3830342292785645
train: epoch 63, loss 0.2147865742444992, acc=0.921833336353302, loss=0.2147865742444992
test: epoch 63, loss 2.372854232788086, acc=0.4305555522441864, loss=2.372854232788086
train: epoch 64, loss 0.2035146951675415, acc=0.9243888854980469, loss=0.2035146951675415
test: epoch 64, loss 2.2102575302124023, acc=0.44999998807907104, loss=2.2102575302124023
train: epoch 65, loss 0.2174723893404007, acc=0.9223889112472534, loss=0.2174723893404007
test: epoch 65, loss 2.1742947101593018, acc=0.4166666567325592, loss=2.1742947101593018
train: epoch 66, loss 0.21298417448997498, acc=0.9225000143051147, loss=0.21298417448997498
test: epoch 66, loss 2.213768482208252, acc=0.42222222685813904, loss=2.213768482208252
train: epoch 67, loss 0.19609308242797852, acc=0.9269444346427917, loss=0.19609308242797852
test: epoch 67, loss 2.1137452125549316, acc=0.4722222089767456, loss=2.1137452125549316
train: epoch 68, loss 0.1989738643169403, acc=0.9260555505752563, loss=0.1989738643169403
test: epoch 68, loss 2.460702896118164, acc=0.4472222328186035, loss=2.460702896118164
train: epoch 69, loss 0.19696712493896484, acc=0.9287777543067932, loss=0.19696712493896484
test: epoch 69, loss 2.337186336517334, acc=0.4611110985279083, loss=2.337186336517334
train: epoch 70, loss 0.1950777918100357, acc=0.9317777752876282, loss=0.1950777918100357
test: epoch 70, loss 2.3076202869415283, acc=0.4305555522441864, loss=2.3076202869415283
train: epoch 71, loss 0.18417173624038696, acc=0.9329444169998169, loss=0.18417173624038696
test: epoch 71, loss 2.214287281036377, acc=0.4444444477558136, loss=2.214287281036377
train: epoch 72, loss 0.18888302147388458, acc=0.9331666827201843, loss=0.18888302147388458
test: epoch 72, loss 2.3206698894500732, acc=0.46388888359069824, loss=2.3206698894500732
train: epoch 73, loss 0.20115002989768982, acc=0.9273333549499512, loss=0.20115002989768982
test: epoch 73, loss 2.062136173248291, acc=0.4611110985279083, loss=2.062136173248291
train: epoch 74, loss 0.18088847398757935, acc=0.934166669845581, loss=0.18088847398757935
test: epoch 74, loss 2.592411756515503, acc=0.46388888359069824, loss=2.592411756515503
train: epoch 75, loss 0.17958368360996246, acc=0.9342222213745117, loss=0.17958368360996246
test: epoch 75, loss 2.416670083999634, acc=0.4194444417953491, loss=2.416670083999634
train: epoch 76, loss 0.18888118863105774, acc=0.9332777857780457, loss=0.18888118863105774
test: epoch 76, loss 2.3337454795837402, acc=0.4555555582046509, loss=2.3337454795837402
train: epoch 77, loss 0.18495911359786987, acc=0.9374444484710693, loss=0.18495911359786987
test: epoch 77, loss 2.3107988834381104, acc=0.5055555701255798, loss=2.3107988834381104
train: epoch 78, loss 0.18319711089134216, acc=0.9359444379806519, loss=0.18319711089134216
test: epoch 78, loss 2.3607747554779053, acc=0.4694444537162781, loss=2.3607747554779053
train: epoch 79, loss 0.17554886639118195, acc=0.9388889074325562, loss=0.17554886639118195
test: epoch 79, loss 2.2971103191375732, acc=0.5333333611488342, loss=2.2971103191375732
train: epoch 80, loss 0.18108712136745453, acc=0.9349444508552551, loss=0.18108712136745453
test: epoch 80, loss 2.3387818336486816, acc=0.45277777314186096, loss=2.3387818336486816
train: epoch 81, loss 0.16606396436691284, acc=0.9420555830001831, loss=0.16606396436691284
test: epoch 81, loss 2.0749967098236084, acc=0.5027777552604675, loss=2.0749967098236084
train: epoch 82, loss 0.17334984242916107, acc=0.9424999952316284, loss=0.17334984242916107
test: epoch 82, loss 2.4009649753570557, acc=0.4694444537162781, loss=2.4009649753570557
train: epoch 83, loss 0.17017337679862976, acc=0.941444456577301, loss=0.17017337679862976
test: epoch 83, loss 2.3123722076416016, acc=0.4833333194255829, loss=2.3123722076416016
train: epoch 84, loss 0.17334513366222382, acc=0.9422777891159058, loss=0.17334513366222382
test: epoch 84, loss 2.2935092449188232, acc=0.4888888895511627, loss=2.2935092449188232
train: epoch 85, loss 0.1560128778219223, acc=0.9448888897895813, loss=0.1560128778219223
test: epoch 85, loss 2.288400173187256, acc=0.48055556416511536, loss=2.288400173187256
train: epoch 86, loss 0.17745377123355865, acc=0.9432222247123718, loss=0.17745377123355865
test: epoch 86, loss 2.132338523864746, acc=0.5055555701255798, loss=2.132338523864746
train: epoch 87, loss 0.15327492356300354, acc=0.9485555291175842, loss=0.15327492356300354
test: epoch 87, loss 1.9410655498504639, acc=0.49444442987442017, loss=1.9410655498504639
train: epoch 88, loss 0.14772894978523254, acc=0.948888897895813, loss=0.14772894978523254
test: epoch 88, loss 2.2109131813049316, acc=0.49166667461395264, loss=2.2109131813049316
train: epoch 89, loss 0.1598784327507019, acc=0.9472777843475342, loss=0.1598784327507019
test: epoch 89, loss 2.427727222442627, acc=0.5055555701255798, loss=2.427727222442627
train: epoch 90, loss 0.1665647178888321, acc=0.9475555419921875, loss=0.1665647178888321
test: epoch 90, loss 2.4154114723205566, acc=0.5138888955116272, loss=2.4154114723205566
train: epoch 91, loss 0.15339058637619019, acc=0.9480555653572083, loss=0.15339058637619019
test: epoch 91, loss 2.6168618202209473, acc=0.5055555701255798, loss=2.6168618202209473
train: epoch 92, loss 0.1485268771648407, acc=0.9486666917800903, loss=0.1485268771648407
test: epoch 92, loss 2.1558914184570312, acc=0.5416666865348816, loss=2.1558914184570312
train: epoch 93, loss 0.14939351379871368, acc=0.9462777972221375, loss=0.14939351379871368
test: epoch 93, loss 2.3840835094451904, acc=0.5249999761581421, loss=2.3840835094451904
train: epoch 94, loss 0.1514270156621933, acc=0.9477221965789795, loss=0.1514270156621933
test: epoch 94, loss 2.3849544525146484, acc=0.5249999761581421, loss=2.3849544525146484
train: epoch 95, loss 0.15454533696174622, acc=0.949055552482605, loss=0.15454533696174622
test: epoch 95, loss 2.2930171489715576, acc=0.5083333253860474, loss=2.2930171489715576
train: epoch 96, loss 0.14328663051128387, acc=0.9511666893959045, loss=0.14328663051128387
test: epoch 96, loss 2.232832908630371, acc=0.5333333611488342, loss=2.232832908630371
train: epoch 97, loss 0.14167208969593048, acc=0.9519444704055786, loss=0.14167208969593048
test: epoch 97, loss 2.3299014568328857, acc=0.5527777671813965, loss=2.3299014568328857
train: epoch 98, loss 0.1341972053050995, acc=0.9506666660308838, loss=0.1341972053050995
test: epoch 98, loss 2.3184309005737305, acc=0.5222222208976746, loss=2.3184309005737305
train: epoch 99, loss 0.1441262811422348, acc=0.9514999985694885, loss=0.1441262811422348
test: epoch 99, loss 2.2158043384552, acc=0.5388888716697693, loss=2.2158043384552
train: epoch 100, loss 0.13590595126152039, acc=0.9544444680213928, loss=0.13590595126152039
test: epoch 100, loss 2.2533891201019287, acc=0.5222222208976746, loss=2.2533891201019287
train: epoch 101, loss 0.13490119576454163, acc=0.954277753829956, loss=0.13490119576454163
test: epoch 101, loss 2.090364933013916, acc=0.550000011920929, loss=2.090364933013916
train: epoch 102, loss 0.14243806898593903, acc=0.9521111249923706, loss=0.14243806898593903
test: epoch 102, loss 2.001704454421997, acc=0.5583333373069763, loss=2.001704454421997
train: epoch 103, loss 0.14749294519424438, acc=0.9508333206176758, loss=0.14749294519424438
test: epoch 103, loss 2.205810785293579, acc=0.5361111164093018, loss=2.205810785293579
train: epoch 104, loss 0.13678309321403503, acc=0.9542222023010254, loss=0.13678309321403503
test: epoch 104, loss 2.1680376529693604, acc=0.5527777671813965, loss=2.1680376529693604
train: epoch 105, loss 0.1183566004037857, acc=0.9608333110809326, loss=0.1183566004037857
test: epoch 105, loss 2.24444580078125, acc=0.5305555462837219, loss=2.24444580078125
train: epoch 106, loss 0.12936967611312866, acc=0.9554444551467896, loss=0.12936967611312866
test: epoch 106, loss 2.316929817199707, acc=0.5722222328186035, loss=2.316929817199707
train: epoch 107, loss 0.13922978937625885, acc=0.9547222256660461, loss=0.13922978937625885
test: epoch 107, loss 2.2979464530944824, acc=0.5472221970558167, loss=2.2979464530944824
train: epoch 108, loss 0.1318970024585724, acc=0.9556666612625122, loss=0.1318970024585724
test: epoch 108, loss 2.3261525630950928, acc=0.5666666626930237, loss=2.3261525630950928
train: epoch 109, loss 0.12893877923488617, acc=0.9576666951179504, loss=0.12893877923488617
test: epoch 109, loss 2.2450246810913086, acc=0.5722222328186035, loss=2.2450246810913086
train: epoch 110, loss 0.12106365710496902, acc=0.9586666822433472, loss=0.12106365710496902
test: epoch 110, loss 2.096017599105835, acc=0.5833333134651184, loss=2.096017599105835
train: epoch 111, loss 0.13219955563545227, acc=0.956333339214325, loss=0.13219955563545227
test: epoch 111, loss 2.3076250553131104, acc=0.574999988079071, loss=2.3076250553131104
train: epoch 112, loss 0.13115006685256958, acc=0.9581666588783264, loss=0.13115006685256958
test: epoch 112, loss 2.2963201999664307, acc=0.5638889074325562, loss=2.2963201999664307
train: epoch 113, loss 0.12463051080703735, acc=0.9579444527626038, loss=0.12463051080703735
test: epoch 113, loss 2.450394868850708, acc=0.5694444179534912, loss=2.450394868850708
train: epoch 114, loss 0.14069464802742004, acc=0.9553889036178589, loss=0.14069464802742004
test: epoch 114, loss 1.9720306396484375, acc=0.5472221970558167, loss=1.9720306396484375
train: epoch 115, loss 0.1332988291978836, acc=0.9576666951179504, loss=0.1332988291978836
test: epoch 115, loss 2.0814242362976074, acc=0.5805555582046509, loss=2.0814242362976074
train: epoch 116, loss 0.1200910210609436, acc=0.9596666693687439, loss=0.1200910210609436
test: epoch 116, loss 1.9107331037521362, acc=0.5777778029441833, loss=1.9107331037521362
train: epoch 117, loss 0.12261396646499634, acc=0.9598888754844666, loss=0.12261396646499634
test: epoch 117, loss 2.0961575508117676, acc=0.5916666388511658, loss=2.0961575508117676
train: epoch 118, loss 0.1287088394165039, acc=0.9575555324554443, loss=0.1287088394165039
test: epoch 118, loss 2.1191294193267822, acc=0.5638889074325562, loss=2.1191294193267822
train: epoch 119, loss 0.11530325561761856, acc=0.9595000147819519, loss=0.11530325561761856
test: epoch 119, loss 2.1259026527404785, acc=0.6027777791023254, loss=2.1259026527404785
train: epoch 120, loss 0.11868054419755936, acc=0.9614444375038147, loss=0.11868054419755936
test: epoch 120, loss 2.315716028213501, acc=0.5416666865348816, loss=2.315716028213501
train: epoch 121, loss 0.12214905023574829, acc=0.9589444398880005, loss=0.12214905023574829
test: epoch 121, loss 2.1277599334716797, acc=0.6194444298744202, loss=2.1277599334716797
train: epoch 122, loss 0.12010041624307632, acc=0.9610555768013, loss=0.12010041624307632
test: epoch 122, loss 2.04124116897583, acc=0.5833333134651184, loss=2.04124116897583
train: epoch 123, loss 0.11187130957841873, acc=0.9599444270133972, loss=0.11187130957841873
test: epoch 123, loss 2.109632730484009, acc=0.5805555582046509, loss=2.109632730484009
train: epoch 124, loss 0.10923217982053757, acc=0.9627222418785095, loss=0.10923217982053757
test: epoch 124, loss 1.9537427425384521, acc=0.5888888835906982, loss=1.9537427425384521
train: epoch 125, loss 0.11387768387794495, acc=0.9608888626098633, loss=0.11387768387794495
test: epoch 125, loss 2.1625688076019287, acc=0.6027777791023254, loss=2.1625688076019287
train: epoch 126, loss 0.10614828020334244, acc=0.9652222394943237, loss=0.10614828020334244
test: epoch 126, loss 2.467932939529419, acc=0.5666666626930237, loss=2.467932939529419
train: epoch 127, loss 0.12489885836839676, acc=0.9596666693687439, loss=0.12489885836839676
test: epoch 127, loss 2.1890432834625244, acc=0.574999988079071, loss=2.1890432834625244
train: epoch 128, loss 0.11579211056232452, acc=0.9608333110809326, loss=0.11579211056232452
test: epoch 128, loss 2.2829573154449463, acc=0.5861111283302307, loss=2.2829573154449463
train: epoch 129, loss 0.10679762810468674, acc=0.9646666646003723, loss=0.10679762810468674
test: epoch 129, loss 1.8090647459030151, acc=0.6277777552604675, loss=1.8090647459030151
train: epoch 130, loss 0.10102525353431702, acc=0.9658889174461365, loss=0.10102525353431702
test: epoch 130, loss 1.7339026927947998, acc=0.6361111402511597, loss=1.7339026927947998
train: epoch 131, loss 0.10605799406766891, acc=0.9643333554267883, loss=0.10605799406766891
test: epoch 131, loss 1.927455186843872, acc=0.625, loss=1.927455186843872
train: epoch 132, loss 0.10846282541751862, acc=0.9636111259460449, loss=0.10846282541751862
test: epoch 132, loss 2.1260783672332764, acc=0.605555534362793, loss=2.1260783672332764
train: epoch 133, loss 0.10743792355060577, acc=0.9646111130714417, loss=0.10743792355060577
test: epoch 133, loss 1.9627386331558228, acc=0.6027777791023254, loss=1.9627386331558228
train: epoch 134, loss 0.13257582485675812, acc=0.9620000123977661, loss=0.13257582485675812
test: epoch 134, loss 2.1073179244995117, acc=0.5972222089767456, loss=2.1073179244995117
train: epoch 135, loss 0.11510462313890457, acc=0.9639999866485596, loss=0.11510462313890457
test: epoch 135, loss 2.2463996410369873, acc=0.5944444537162781, loss=2.2463996410369873
train: epoch 136, loss 0.10303475707769394, acc=0.9651111364364624, loss=0.10303475707769394
test: epoch 136, loss 2.0611207485198975, acc=0.6111111044883728, loss=2.0611207485198975
train: epoch 137, loss 0.11324851959943771, acc=0.961222231388092, loss=0.11324851959943771
test: epoch 137, loss 2.090383291244507, acc=0.605555534362793, loss=2.090383291244507
train: epoch 138, loss 0.09957639873027802, acc=0.9648333191871643, loss=0.09957639873027802
test: epoch 138, loss 2.1498565673828125, acc=0.605555534362793, loss=2.1498565673828125
train: epoch 139, loss 0.10924457013607025, acc=0.964555561542511, loss=0.10924457013607025
test: epoch 139, loss 2.2247543334960938, acc=0.6138888597488403, loss=2.2247543334960938
train: epoch 140, loss 0.10992658138275146, acc=0.9639999866485596, loss=0.10992658138275146
test: epoch 140, loss 2.4017958641052246, acc=0.6166666746139526, loss=2.4017958641052246
train: epoch 141, loss 0.09433864802122116, acc=0.9678888916969299, loss=0.09433864802122116
test: epoch 141, loss 2.0473978519439697, acc=0.6305555701255798, loss=2.0473978519439697
train: epoch 142, loss 0.10123790055513382, acc=0.9646111130714417, loss=0.10123790055513382
test: epoch 142, loss 2.1644058227539062, acc=0.6361111402511597, loss=2.1644058227539062
train: epoch 143, loss 0.1072661355137825, acc=0.9653333425521851, loss=0.1072661355137825
test: epoch 143, loss 2.298787832260132, acc=0.5944444537162781, loss=2.298787832260132
train: epoch 144, loss 0.10737066715955734, acc=0.9655555486679077, loss=0.10737066715955734
test: epoch 144, loss 2.1591737270355225, acc=0.6333333253860474, loss=2.1591737270355225
train: epoch 145, loss 0.10234517604112625, acc=0.9664999842643738, loss=0.10234517604112625
test: epoch 145, loss 2.018944263458252, acc=0.6361111402511597, loss=2.018944263458252
train: epoch 146, loss 0.10258001834154129, acc=0.9661111235618591, loss=0.10258001834154129
test: epoch 146, loss 1.8190845251083374, acc=0.6472222208976746, loss=1.8190845251083374
train: epoch 147, loss 0.10082968324422836, acc=0.9658889174461365, loss=0.10082968324422836
test: epoch 147, loss 2.0202393531799316, acc=0.6472222208976746, loss=2.0202393531799316
train: epoch 148, loss 0.11147401481866837, acc=0.9632777571678162, loss=0.11147401481866837
test: epoch 148, loss 1.9454516172409058, acc=0.6222222447395325, loss=1.9454516172409058
train: epoch 149, loss 0.10780145227909088, acc=0.9670000076293945, loss=0.10780145227909088
test: epoch 149, loss 1.9852534532546997, acc=0.644444465637207, loss=1.9852534532546997
train: epoch 150, loss 0.09909127652645111, acc=0.9664999842643738, loss=0.09909127652645111
test: epoch 150, loss 1.9703688621520996, acc=0.6499999761581421, loss=1.9703688621520996
