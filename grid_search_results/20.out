# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=1.5", "--temp_decay=1", "--one_hot=0", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=951025128, receiver_embed_dim=32, save_run=0, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=951025128, receiver_embed_dim=32, save_run=False, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.7621400356292725, acc=0.12361110746860504, loss=2.7621400356292725
test: epoch 1, loss 5.799351692199707, acc=0.03888889029622078, loss=5.799351692199707
train: epoch 2, loss 1.9599997997283936, acc=0.24266666173934937, loss=1.9599997997283936
test: epoch 2, loss 4.442000389099121, acc=0.08888889104127884, loss=4.442000389099121
train: epoch 3, loss 1.6580599546432495, acc=0.33411112427711487, loss=1.6580599546432495
test: epoch 3, loss 4.669663906097412, acc=0.1388888955116272, loss=4.669663906097412
train: epoch 4, loss 1.4871631860733032, acc=0.3973333239555359, loss=1.4871631860733032
test: epoch 4, loss 4.611885070800781, acc=0.11666666716337204, loss=4.611885070800781
train: epoch 5, loss 1.3740826845169067, acc=0.4387222230434418, loss=1.3740826845169067
test: epoch 5, loss 3.749056816101074, acc=0.17499999701976776, loss=3.749056816101074
train: epoch 6, loss 1.2969450950622559, acc=0.47405555844306946, loss=1.2969450950622559
test: epoch 6, loss 3.5768015384674072, acc=0.1944444477558136, loss=3.5768015384674072
train: epoch 7, loss 1.2142727375030518, acc=0.5058333277702332, loss=1.2142727375030518
test: epoch 7, loss 2.7034623622894287, acc=0.23055554926395416, loss=2.7034623622894287
train: epoch 8, loss 1.1299467086791992, acc=0.5510555505752563, loss=1.1299467086791992
test: epoch 8, loss 3.0418148040771484, acc=0.22777777910232544, loss=3.0418148040771484
train: epoch 9, loss 1.1029601097106934, acc=0.5561110973358154, loss=1.1029601097106934
test: epoch 9, loss 2.8286874294281006, acc=0.23333333432674408, loss=2.8286874294281006
train: epoch 10, loss 1.0341562032699585, acc=0.5873333215713501, loss=1.0341562032699585
test: epoch 10, loss 3.361636161804199, acc=0.24166665971279144, loss=3.361636161804199
train: epoch 11, loss 1.0057871341705322, acc=0.6004999876022339, loss=1.0057871341705322
test: epoch 11, loss 3.1471714973449707, acc=0.22777777910232544, loss=3.1471714973449707
train: epoch 12, loss 0.9761386513710022, acc=0.6147778034210205, loss=0.9761386513710022
test: epoch 12, loss 2.6285948753356934, acc=0.25, loss=2.6285948753356934
train: epoch 13, loss 0.9348551034927368, acc=0.6324999928474426, loss=0.9348551034927368
test: epoch 13, loss 2.802440643310547, acc=0.2666666805744171, loss=2.802440643310547
train: epoch 14, loss 0.9100258350372314, acc=0.6443333625793457, loss=0.9100258350372314
test: epoch 14, loss 3.025336503982544, acc=0.2666666805744171, loss=3.025336503982544
train: epoch 15, loss 0.8791416883468628, acc=0.6548888683319092, loss=0.8791416883468628
test: epoch 15, loss 2.355149507522583, acc=0.2916666567325592, loss=2.355149507522583
train: epoch 16, loss 0.8735352754592896, acc=0.6555555462837219, loss=0.8735352754592896
test: epoch 16, loss 2.3971736431121826, acc=0.28333333134651184, loss=2.3971736431121826
train: epoch 17, loss 0.8212202787399292, acc=0.6781111359596252, loss=0.8212202787399292
test: epoch 17, loss 3.2883081436157227, acc=0.2083333283662796, loss=3.2883081436157227
train: epoch 18, loss 0.8122413754463196, acc=0.6863889098167419, loss=0.8122413754463196
test: epoch 18, loss 2.9290199279785156, acc=0.2777777910232544, loss=2.9290199279785156
train: epoch 19, loss 0.7983271479606628, acc=0.6880000233650208, loss=0.7983271479606628
test: epoch 19, loss 2.734981060028076, acc=0.3472222089767456, loss=2.734981060028076
train: epoch 20, loss 0.7825730443000793, acc=0.6946666836738586, loss=0.7825730443000793
test: epoch 20, loss 2.4020907878875732, acc=0.25, loss=2.4020907878875732
train: epoch 21, loss 0.7477948069572449, acc=0.7130555510520935, loss=0.7477948069572449
test: epoch 21, loss 3.6790168285369873, acc=0.21111111342906952, loss=3.6790168285369873
train: epoch 22, loss 0.7355599403381348, acc=0.714555561542511, loss=0.7355599403381348
test: epoch 22, loss 3.237624168395996, acc=0.2611111104488373, loss=3.237624168395996
train: epoch 23, loss 0.7343268394470215, acc=0.7177222371101379, loss=0.7343268394470215
test: epoch 23, loss 2.2321078777313232, acc=0.22499999403953552, loss=2.2321078777313232
train: epoch 24, loss 0.7072309851646423, acc=0.7254999876022339, loss=0.7072309851646423
test: epoch 24, loss 2.992255449295044, acc=0.31111112236976624, loss=2.992255449295044
train: epoch 25, loss 0.6935804486274719, acc=0.734333336353302, loss=0.6935804486274719
test: epoch 25, loss 2.271045207977295, acc=0.3444444537162781, loss=2.271045207977295
train: epoch 26, loss 0.6863411068916321, acc=0.7347777485847473, loss=0.6863411068916321
test: epoch 26, loss 2.5225257873535156, acc=0.2944444417953491, loss=2.5225257873535156
train: epoch 27, loss 0.6520460844039917, acc=0.7492222189903259, loss=0.6520460844039917
test: epoch 27, loss 2.2731685638427734, acc=0.3888888955116272, loss=2.2731685638427734
train: epoch 28, loss 0.6667172908782959, acc=0.7404999732971191, loss=0.6667172908782959
test: epoch 28, loss 2.345301628112793, acc=0.3583333194255829, loss=2.345301628112793
train: epoch 29, loss 0.633653998374939, acc=0.7563889026641846, loss=0.633653998374939
test: epoch 29, loss 2.6058759689331055, acc=0.3361110985279083, loss=2.6058759689331055
train: epoch 30, loss 0.6347141861915588, acc=0.7521111369132996, loss=0.6347141861915588
test: epoch 30, loss 2.586238384246826, acc=0.38333332538604736, loss=2.586238384246826
train: epoch 31, loss 0.6345016360282898, acc=0.7566666603088379, loss=0.6345016360282898
test: epoch 31, loss 2.474095106124878, acc=0.31388887763023376, loss=2.474095106124878
train: epoch 32, loss 0.609546422958374, acc=0.7630000114440918, loss=0.609546422958374
test: epoch 32, loss 2.6363742351531982, acc=0.3222222328186035, loss=2.6363742351531982
train: epoch 33, loss 0.6137169599533081, acc=0.7667222023010254, loss=0.6137169599533081
test: epoch 33, loss 2.414977788925171, acc=0.3222222328186035, loss=2.414977788925171
train: epoch 34, loss 0.6123027205467224, acc=0.7598888874053955, loss=0.6123027205467224
test: epoch 34, loss 2.2181804180145264, acc=0.3027777671813965, loss=2.2181804180145264
train: epoch 35, loss 0.5797255635261536, acc=0.7770000100135803, loss=0.5797255635261536
test: epoch 35, loss 2.4027137756347656, acc=0.31111112236976624, loss=2.4027137756347656
train: epoch 36, loss 0.5771179795265198, acc=0.7790555357933044, loss=0.5771179795265198
test: epoch 36, loss 2.311408519744873, acc=0.3722222149372101, loss=2.311408519744873
train: epoch 37, loss 0.5794436931610107, acc=0.7785555720329285, loss=0.5794436931610107
test: epoch 37, loss 2.038594961166382, acc=0.3361110985279083, loss=2.038594961166382
train: epoch 38, loss 0.5502810478210449, acc=0.7902777791023254, loss=0.5502810478210449
test: epoch 38, loss 2.0500264167785645, acc=0.4027777910232544, loss=2.0500264167785645
train: epoch 39, loss 0.5351593494415283, acc=0.7956110835075378, loss=0.5351593494415283
test: epoch 39, loss 2.3767073154449463, acc=0.3777777850627899, loss=2.3767073154449463
train: epoch 40, loss 0.528910756111145, acc=0.8003333210945129, loss=0.528910756111145
test: epoch 40, loss 2.3285648822784424, acc=0.3083333373069763, loss=2.3285648822784424
train: epoch 41, loss 0.5271909832954407, acc=0.8018333315849304, loss=0.5271909832954407
test: epoch 41, loss 2.4344184398651123, acc=0.3027777671813965, loss=2.4344184398651123
train: epoch 42, loss 0.5166317820549011, acc=0.8027222156524658, loss=0.5166317820549011
test: epoch 42, loss 2.600348711013794, acc=0.2638888955116272, loss=2.600348711013794
train: epoch 43, loss 0.5131322741508484, acc=0.8020555377006531, loss=0.5131322741508484
test: epoch 43, loss 2.315991163253784, acc=0.36666667461395264, loss=2.315991163253784
train: epoch 44, loss 0.5222232341766357, acc=0.8028888702392578, loss=0.5222232341766357
test: epoch 44, loss 2.715461015701294, acc=0.29722222685813904, loss=2.715461015701294
train: epoch 45, loss 0.5176312327384949, acc=0.8034999966621399, loss=0.5176312327384949
test: epoch 45, loss 2.5225610733032227, acc=0.33888888359069824, loss=2.5225610733032227
train: epoch 46, loss 0.5154405236244202, acc=0.800777792930603, loss=0.5154405236244202
test: epoch 46, loss 2.416947603225708, acc=0.3611111044883728, loss=2.416947603225708
train: epoch 47, loss 0.4819642901420593, acc=0.8161110877990723, loss=0.4819642901420593
test: epoch 47, loss 2.2040627002716064, acc=0.36666667461395264, loss=2.2040627002716064
train: epoch 48, loss 0.47022196650505066, acc=0.8221666812896729, loss=0.47022196650505066
test: epoch 48, loss 2.3956298828125, acc=0.30000001192092896, loss=2.3956298828125
train: epoch 49, loss 0.5060616731643677, acc=0.8069444298744202, loss=0.5060616731643677
test: epoch 49, loss 2.3483126163482666, acc=0.2805555462837219, loss=2.3483126163482666
train: epoch 50, loss 0.4769324064254761, acc=0.815833330154419, loss=0.4769324064254761
test: epoch 50, loss 2.4030091762542725, acc=0.375, loss=2.4030091762542725
train: epoch 51, loss 0.4740199148654938, acc=0.8182777762413025, loss=0.4740199148654938
test: epoch 51, loss 2.830476760864258, acc=0.34166666865348816, loss=2.830476760864258
train: epoch 52, loss 0.4772009551525116, acc=0.8178889155387878, loss=0.4772009551525116
test: epoch 52, loss 2.887092113494873, acc=0.3444444537162781, loss=2.887092113494873
train: epoch 53, loss 0.47271278500556946, acc=0.8145555257797241, loss=0.47271278500556946
test: epoch 53, loss 2.2107365131378174, acc=0.3222222328186035, loss=2.2107365131378174
train: epoch 54, loss 0.4785727262496948, acc=0.8159444332122803, loss=0.4785727262496948
test: epoch 54, loss 2.4819164276123047, acc=0.28333333134651184, loss=2.4819164276123047
train: epoch 55, loss 0.44843655824661255, acc=0.8296111226081848, loss=0.44843655824661255
test: epoch 55, loss 2.0709640979766846, acc=0.4166666567325592, loss=2.0709640979766846
train: epoch 56, loss 0.45118409395217896, acc=0.8240000009536743, loss=0.45118409395217896
test: epoch 56, loss 2.657256841659546, acc=0.41111111640930176, loss=2.657256841659546
train: epoch 57, loss 0.4392346143722534, acc=0.8309444189071655, loss=0.4392346143722534
test: epoch 57, loss 2.445301055908203, acc=0.3472222089767456, loss=2.445301055908203
train: epoch 58, loss 0.4652235209941864, acc=0.8244444727897644, loss=0.4652235209941864
test: epoch 58, loss 2.206613779067993, acc=0.4166666567325592, loss=2.206613779067993
train: epoch 59, loss 0.4635072350502014, acc=0.8235555291175842, loss=0.4635072350502014
test: epoch 59, loss 2.7202553749084473, acc=0.38333332538604736, loss=2.7202553749084473
train: epoch 60, loss 0.42710328102111816, acc=0.8306666612625122, loss=0.42710328102111816
test: epoch 60, loss 2.289813280105591, acc=0.39444443583488464, loss=2.289813280105591
train: epoch 61, loss 0.441829115152359, acc=0.8331111073493958, loss=0.441829115152359
test: epoch 61, loss 2.2952945232391357, acc=0.375, loss=2.2952945232391357
train: epoch 62, loss 0.4316950738430023, acc=0.8358333110809326, loss=0.4316950738430023
test: epoch 62, loss 2.4880378246307373, acc=0.38333332538604736, loss=2.4880378246307373
train: epoch 63, loss 0.4362828731536865, acc=0.8307777643203735, loss=0.4362828731536865
test: epoch 63, loss 2.5625576972961426, acc=0.3638888895511627, loss=2.5625576972961426
train: epoch 64, loss 0.42498594522476196, acc=0.8361111283302307, loss=0.42498594522476196
test: epoch 64, loss 2.51485538482666, acc=0.3305555582046509, loss=2.51485538482666
train: epoch 65, loss 0.4157078266143799, acc=0.8431666493415833, loss=0.4157078266143799
test: epoch 65, loss 2.0948009490966797, acc=0.3333333432674408, loss=2.0948009490966797
train: epoch 66, loss 0.412987619638443, acc=0.839888870716095, loss=0.412987619638443
test: epoch 66, loss 2.3664157390594482, acc=0.3444444537162781, loss=2.3664157390594482
train: epoch 67, loss 0.4195238947868347, acc=0.8396666646003723, loss=0.4195238947868347
test: epoch 67, loss 2.4227023124694824, acc=0.3333333432674408, loss=2.4227023124694824
train: epoch 68, loss 0.4457903504371643, acc=0.8293889164924622, loss=0.4457903504371643
test: epoch 68, loss 1.823913335800171, acc=0.4138889014720917, loss=1.823913335800171
train: epoch 69, loss 0.4013976454734802, acc=0.8422222137451172, loss=0.4013976454734802
test: epoch 69, loss 2.040353298187256, acc=0.33888888359069824, loss=2.040353298187256
train: epoch 70, loss 0.40616509318351746, acc=0.8443333506584167, loss=0.40616509318351746
test: epoch 70, loss 1.9771596193313599, acc=0.3777777850627899, loss=1.9771596193313599
train: epoch 71, loss 0.41651201248168945, acc=0.8422777652740479, loss=0.41651201248168945
test: epoch 71, loss 1.9601109027862549, acc=0.3722222149372101, loss=1.9601109027862549
train: epoch 72, loss 0.3934699296951294, acc=0.8473333120346069, loss=0.3934699296951294
test: epoch 72, loss 2.233537435531616, acc=0.29722222685813904, loss=2.233537435531616
train: epoch 73, loss 0.3819429874420166, acc=0.8539444208145142, loss=0.3819429874420166
test: epoch 73, loss 2.963815689086914, acc=0.35555556416511536, loss=2.963815689086914
train: epoch 74, loss 0.4014425575733185, acc=0.8478888869285583, loss=0.4014425575733185
test: epoch 74, loss 2.357396125793457, acc=0.3583333194255829, loss=2.357396125793457
train: epoch 75, loss 0.3933478891849518, acc=0.8508889079093933, loss=0.3933478891849518
test: epoch 75, loss 2.5084245204925537, acc=0.39444443583488464, loss=2.5084245204925537
train: epoch 76, loss 0.3869023621082306, acc=0.8512222170829773, loss=0.3869023621082306
test: epoch 76, loss 2.333390951156616, acc=0.38333332538604736, loss=2.333390951156616
train: epoch 77, loss 0.3812617361545563, acc=0.8550000190734863, loss=0.3812617361545563
test: epoch 77, loss 2.5336928367614746, acc=0.3583333194255829, loss=2.5336928367614746
train: epoch 78, loss 0.38069552183151245, acc=0.8529444336891174, loss=0.38069552183151245
test: epoch 78, loss 2.6389694213867188, acc=0.30000001192092896, loss=2.6389694213867188
train: epoch 79, loss 0.43239083886146545, acc=0.8329444527626038, loss=0.43239083886146545
test: epoch 79, loss 2.8805294036865234, acc=0.2611111104488373, loss=2.8805294036865234
train: epoch 80, loss 0.400532603263855, acc=0.8462222218513489, loss=0.400532603263855
test: epoch 80, loss 2.0648298263549805, acc=0.35555556416511536, loss=2.0648298263549805
train: epoch 81, loss 0.3609403371810913, acc=0.8602222204208374, loss=0.3609403371810913
test: epoch 81, loss 2.2120611667633057, acc=0.35555556416511536, loss=2.2120611667633057
train: epoch 82, loss 0.3799719214439392, acc=0.8524444699287415, loss=0.3799719214439392
test: epoch 82, loss 1.8659383058547974, acc=0.41111111640930176, loss=1.8659383058547974
train: epoch 83, loss 0.377931147813797, acc=0.8552777767181396, loss=0.377931147813797
test: epoch 83, loss 2.438499689102173, acc=0.375, loss=2.438499689102173
train: epoch 84, loss 0.3646838963031769, acc=0.8589444160461426, loss=0.3646838963031769
test: epoch 84, loss 2.8017618656158447, acc=0.3916666805744171, loss=2.8017618656158447
train: epoch 85, loss 0.36504632234573364, acc=0.8597777485847473, loss=0.36504632234573364
test: epoch 85, loss 2.407846689224243, acc=0.43611112236976624, loss=2.407846689224243
train: epoch 86, loss 0.38158488273620605, acc=0.8557778000831604, loss=0.38158488273620605
test: epoch 86, loss 2.4391489028930664, acc=0.4055555462837219, loss=2.4391489028930664
train: epoch 87, loss 0.35954877734184265, acc=0.8612777590751648, loss=0.35954877734184265
test: epoch 87, loss 3.0483999252319336, acc=0.3722222149372101, loss=3.0483999252319336
train: epoch 88, loss 0.3854629397392273, acc=0.8592222332954407, loss=0.3854629397392273
test: epoch 88, loss 2.3549163341522217, acc=0.3583333194255829, loss=2.3549163341522217
train: epoch 89, loss 0.37791842222213745, acc=0.8570555448532104, loss=0.37791842222213745
test: epoch 89, loss 1.7881677150726318, acc=0.3499999940395355, loss=1.7881677150726318
train: epoch 90, loss 0.36270081996917725, acc=0.8656666874885559, loss=0.36270081996917725
test: epoch 90, loss 1.6358661651611328, acc=0.43611112236976624, loss=1.6358661651611328
train: epoch 91, loss 0.3494284152984619, acc=0.8656111359596252, loss=0.3494284152984619
test: epoch 91, loss 2.320995807647705, acc=0.3722222149372101, loss=2.320995807647705
train: epoch 92, loss 0.35513797402381897, acc=0.8634999990463257, loss=0.35513797402381897
test: epoch 92, loss 2.4156370162963867, acc=0.3305555582046509, loss=2.4156370162963867
train: epoch 93, loss 0.3496392071247101, acc=0.867222249507904, loss=0.3496392071247101
test: epoch 93, loss 2.4025356769561768, acc=0.36944442987442017, loss=2.4025356769561768
train: epoch 94, loss 0.3438757359981537, acc=0.8684444427490234, loss=0.3438757359981537
test: epoch 94, loss 2.2056357860565186, acc=0.4277777671813965, loss=2.2056357860565186
train: epoch 95, loss 0.3471571207046509, acc=0.86772221326828, loss=0.3471571207046509
test: epoch 95, loss 1.5310381650924683, acc=0.44999998807907104, loss=1.5310381650924683
train: epoch 96, loss 0.33706948161125183, acc=0.8738889098167419, loss=0.33706948161125183
test: epoch 96, loss 1.6446199417114258, acc=0.46666666865348816, loss=1.6446199417114258
train: epoch 97, loss 0.31703758239746094, acc=0.8805000185966492, loss=0.31703758239746094
test: epoch 97, loss 1.9963024854660034, acc=0.3777777850627899, loss=1.9963024854660034
train: epoch 98, loss 0.32799801230430603, acc=0.8796111345291138, loss=0.32799801230430603
test: epoch 98, loss 1.8343223333358765, acc=0.4027777910232544, loss=1.8343223333358765
train: epoch 99, loss 0.3234494626522064, acc=0.879111111164093, loss=0.3234494626522064
test: epoch 99, loss 2.2190420627593994, acc=0.35555556416511536, loss=2.2190420627593994
train: epoch 100, loss 0.3244994878768921, acc=0.8784999847412109, loss=0.3244994878768921
test: epoch 100, loss 2.5155551433563232, acc=0.3861111104488373, loss=2.5155551433563232
train: epoch 101, loss 0.3274765908718109, acc=0.8791666626930237, loss=0.3274765908718109
test: epoch 101, loss 1.7163825035095215, acc=0.4611110985279083, loss=1.7163825035095215
train: epoch 102, loss 0.3164564073085785, acc=0.8798888921737671, loss=0.3164564073085785
test: epoch 102, loss 2.026658058166504, acc=0.4194444417953491, loss=2.026658058166504
train: epoch 103, loss 0.2975366413593292, acc=0.8885555267333984, loss=0.2975366413593292
test: epoch 103, loss 1.693892478942871, acc=0.5, loss=1.693892478942871
train: epoch 104, loss 0.30817487835884094, acc=0.8858888745307922, loss=0.30817487835884094
test: epoch 104, loss 2.0266273021698, acc=0.3722222149372101, loss=2.0266273021698
train: epoch 105, loss 0.2996012270450592, acc=0.887499988079071, loss=0.2996012270450592
test: epoch 105, loss 2.0738325119018555, acc=0.42500001192092896, loss=2.0738325119018555
train: epoch 106, loss 0.3358246386051178, acc=0.8766111135482788, loss=0.3358246386051178
test: epoch 106, loss 2.1311285495758057, acc=0.46666666865348816, loss=2.1311285495758057
train: epoch 107, loss 0.29024961590766907, acc=0.8894444704055786, loss=0.29024961590766907
test: epoch 107, loss 2.2903242111206055, acc=0.35555556416511536, loss=2.2903242111206055
train: epoch 108, loss 0.3111168146133423, acc=0.8862777948379517, loss=0.3111168146133423
test: epoch 108, loss 1.8868205547332764, acc=0.42500001192092896, loss=1.8868205547332764
train: epoch 109, loss 0.2885841131210327, acc=0.8902222514152527, loss=0.2885841131210327
test: epoch 109, loss 2.2382540702819824, acc=0.40833333134651184, loss=2.2382540702819824
train: epoch 110, loss 0.282258003950119, acc=0.8943333625793457, loss=0.282258003950119
test: epoch 110, loss 2.181049108505249, acc=0.4555555582046509, loss=2.181049108505249
train: epoch 111, loss 0.3211193382740021, acc=0.8823333382606506, loss=0.3211193382740021
test: epoch 111, loss 1.943617343902588, acc=0.4194444417953491, loss=1.943617343902588
train: epoch 112, loss 0.2985084354877472, acc=0.887666642665863, loss=0.2985084354877472
test: epoch 112, loss 2.1298816204071045, acc=0.46388888359069824, loss=2.1298816204071045
train: epoch 113, loss 0.29070767760276794, acc=0.8941110968589783, loss=0.29070767760276794
test: epoch 113, loss 1.68649160861969, acc=0.38333332538604736, loss=1.68649160861969
train: epoch 114, loss 0.3031391501426697, acc=0.8871666789054871, loss=0.3031391501426697
test: epoch 114, loss 2.4818594455718994, acc=0.38055557012557983, loss=2.4818594455718994
train: epoch 115, loss 0.2987617552280426, acc=0.8910555839538574, loss=0.2987617552280426
test: epoch 115, loss 1.8456462621688843, acc=0.5138888955116272, loss=1.8456462621688843
train: epoch 116, loss 0.3025062382221222, acc=0.8892777562141418, loss=0.3025062382221222
test: epoch 116, loss 2.2337422370910645, acc=0.3888888955116272, loss=2.2337422370910645
train: epoch 117, loss 0.29218485951423645, acc=0.8958333134651184, loss=0.29218485951423645
test: epoch 117, loss 1.8774387836456299, acc=0.4555555582046509, loss=1.8774387836456299
train: epoch 118, loss 0.29912132024765015, acc=0.886722207069397, loss=0.29912132024765015
test: epoch 118, loss 1.8534393310546875, acc=0.3888888955116272, loss=1.8534393310546875
train: epoch 119, loss 0.298667848110199, acc=0.8922222256660461, loss=0.298667848110199
test: epoch 119, loss 2.3407044410705566, acc=0.3638888895511627, loss=2.3407044410705566
train: epoch 120, loss 0.2744560241699219, acc=0.898722231388092, loss=0.2744560241699219
test: epoch 120, loss 1.814704418182373, acc=0.4166666567325592, loss=1.814704418182373
train: epoch 121, loss 0.27299752831459045, acc=0.9006666541099548, loss=0.27299752831459045
test: epoch 121, loss 1.7283732891082764, acc=0.4166666567325592, loss=1.7283732891082764
train: epoch 122, loss 0.268902987241745, acc=0.901888906955719, loss=0.268902987241745
test: epoch 122, loss 1.8324944972991943, acc=0.44999998807907104, loss=1.8324944972991943
train: epoch 123, loss 0.2860434651374817, acc=0.8957222104072571, loss=0.2860434651374817
test: epoch 123, loss 1.9304349422454834, acc=0.4333333373069763, loss=1.9304349422454834
train: epoch 124, loss 0.2930750846862793, acc=0.8920000195503235, loss=0.2930750846862793
test: epoch 124, loss 1.8176273107528687, acc=0.4722222089767456, loss=1.8176273107528687
train: epoch 125, loss 0.2838429808616638, acc=0.8942777514457703, loss=0.2838429808616638
test: epoch 125, loss 2.357448101043701, acc=0.3888888955116272, loss=2.357448101043701
train: epoch 126, loss 0.2624436020851135, acc=0.9007222056388855, loss=0.2624436020851135
test: epoch 126, loss 2.0852138996124268, acc=0.42222222685813904, loss=2.0852138996124268
train: epoch 127, loss 0.28282469511032104, acc=0.8928333520889282, loss=0.28282469511032104
test: epoch 127, loss 1.991277813911438, acc=0.46666666865348816, loss=1.991277813911438
train: epoch 128, loss 0.27311140298843384, acc=0.8967221975326538, loss=0.27311140298843384
test: epoch 128, loss 1.7955173254013062, acc=0.4749999940395355, loss=1.7955173254013062
train: epoch 129, loss 0.2684618830680847, acc=0.8998888731002808, loss=0.2684618830680847
test: epoch 129, loss 2.107733964920044, acc=0.4166666567325592, loss=2.107733964920044
train: epoch 130, loss 0.26102524995803833, acc=0.9067222476005554, loss=0.26102524995803833
test: epoch 130, loss 2.4710888862609863, acc=0.3888888955116272, loss=2.4710888862609863
train: epoch 131, loss 0.2942701578140259, acc=0.8930000066757202, loss=0.2942701578140259
test: epoch 131, loss 2.0220787525177, acc=0.4333333373069763, loss=2.0220787525177
train: epoch 132, loss 0.2606912851333618, acc=0.9039444327354431, loss=0.2606912851333618
test: epoch 132, loss 1.5119740962982178, acc=0.519444465637207, loss=1.5119740962982178
train: epoch 133, loss 0.26887378096580505, acc=0.899055540561676, loss=0.26887378096580505
test: epoch 133, loss 2.135673999786377, acc=0.42222222685813904, loss=2.135673999786377
train: epoch 134, loss 0.26222464442253113, acc=0.9030555486679077, loss=0.26222464442253113
test: epoch 134, loss 1.99772310256958, acc=0.4444444477558136, loss=1.99772310256958
train: epoch 135, loss 0.2979636788368225, acc=0.8897777795791626, loss=0.2979636788368225
test: epoch 135, loss 1.755301594734192, acc=0.4027777910232544, loss=1.755301594734192
train: epoch 136, loss 0.2595166265964508, acc=0.9031111001968384, loss=0.2595166265964508
test: epoch 136, loss 2.2086195945739746, acc=0.41111111640930176, loss=2.2086195945739746
train: epoch 137, loss 0.27259528636932373, acc=0.899222195148468, loss=0.27259528636932373
test: epoch 137, loss 1.7402833700180054, acc=0.4305555522441864, loss=1.7402833700180054
train: epoch 138, loss 0.271947979927063, acc=0.9012777805328369, loss=0.271947979927063
test: epoch 138, loss 1.8098219633102417, acc=0.4444444477558136, loss=1.8098219633102417
train: epoch 139, loss 0.2734406292438507, acc=0.8983888626098633, loss=0.2734406292438507
test: epoch 139, loss 2.137582540512085, acc=0.4000000059604645, loss=2.137582540512085
train: epoch 140, loss 0.25185254216194153, acc=0.9084444642066956, loss=0.25185254216194153
test: epoch 140, loss 1.8908361196517944, acc=0.4333333373069763, loss=1.8908361196517944
train: epoch 141, loss 0.29937610030174255, acc=0.890999972820282, loss=0.29937610030174255
test: epoch 141, loss 2.274677276611328, acc=0.4166666567325592, loss=2.274677276611328
train: epoch 142, loss 0.2578921616077423, acc=0.9061111211776733, loss=0.2578921616077423
test: epoch 142, loss 1.9314725399017334, acc=0.4138889014720917, loss=1.9314725399017334
train: epoch 143, loss 0.24752098321914673, acc=0.9086666703224182, loss=0.24752098321914673
test: epoch 143, loss 2.262822151184082, acc=0.4749999940395355, loss=2.262822151184082
train: epoch 144, loss 0.2642481029033661, acc=0.9042222499847412, loss=0.2642481029033661
test: epoch 144, loss 1.54891037940979, acc=0.44999998807907104, loss=1.54891037940979
train: epoch 145, loss 0.25377073884010315, acc=0.9041110873222351, loss=0.25377073884010315
test: epoch 145, loss 2.6282787322998047, acc=0.44999998807907104, loss=2.6282787322998047
train: epoch 146, loss 0.2865273654460907, acc=0.8950555324554443, loss=0.2865273654460907
test: epoch 146, loss 2.254551649093628, acc=0.4749999940395355, loss=2.254551649093628
train: epoch 147, loss 0.2474498301744461, acc=0.9115555286407471, loss=0.2474498301744461
test: epoch 147, loss 1.8801478147506714, acc=0.42500001192092896, loss=1.8801478147506714
train: epoch 148, loss 0.24943293631076813, acc=0.9067222476005554, loss=0.24943293631076813
test: epoch 148, loss 1.7945747375488281, acc=0.4861111044883728, loss=1.7945747375488281
train: epoch 149, loss 0.2586165964603424, acc=0.9038888812065125, loss=0.2586165964603424
test: epoch 149, loss 1.8447721004486084, acc=0.5055555701255798, loss=1.8447721004486084
train: epoch 150, loss 0.27667996287345886, acc=0.9002222418785095, loss=0.27667996287345886
test: epoch 150, loss 2.016263961791992, acc=0.4749999940395355, loss=2.016263961791992
