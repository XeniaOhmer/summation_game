# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1.5", "--temp_decay=1", "--one_hot=false", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1318525393, receiver_embed_dim=32, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.417036294937134, acc=0.048944443464279175, loss=3.417036294937134
test: epoch 1, loss 3.7888381481170654, acc=0.05000000074505806, loss=3.7888381481170654
train: epoch 2, loss 2.7275326251983643, acc=0.14544443786144257, loss=2.7275326251983643
test: epoch 2, loss 3.2428395748138428, acc=0.0972222238779068, loss=3.2428395748138428
train: epoch 3, loss 1.9241924285888672, acc=0.28877776861190796, loss=1.9241924285888672
test: epoch 3, loss 3.075117826461792, acc=0.11944444477558136, loss=3.075117826461792
train: epoch 4, loss 1.6507667303085327, acc=0.36077776551246643, loss=1.6507667303085327
test: epoch 4, loss 2.9009358882904053, acc=0.13611111044883728, loss=2.9009358882904053
train: epoch 5, loss 1.5123885869979858, acc=0.4058888852596283, loss=1.5123885869979858
test: epoch 5, loss 2.791722059249878, acc=0.15555556118488312, loss=2.791722059249878
train: epoch 6, loss 1.4257582426071167, acc=0.43461111187934875, loss=1.4257582426071167
test: epoch 6, loss 2.814382553100586, acc=0.15555556118488312, loss=2.814382553100586
train: epoch 7, loss 1.3441722393035889, acc=0.4659999907016754, loss=1.3441722393035889
test: epoch 7, loss 2.8101766109466553, acc=0.15000000596046448, loss=2.8101766109466553
train: epoch 8, loss 1.2690742015838623, acc=0.4971666634082794, loss=1.2690742015838623
test: epoch 8, loss 2.6513237953186035, acc=0.15555556118488312, loss=2.6513237953186035
train: epoch 9, loss 1.2080597877502441, acc=0.5196666717529297, loss=1.2080597877502441
test: epoch 9, loss 2.8013722896575928, acc=0.1666666716337204, loss=2.8013722896575928
train: epoch 10, loss 1.1510173082351685, acc=0.5425000190734863, loss=1.1510173082351685
test: epoch 10, loss 2.8318722248077393, acc=0.16111111640930176, loss=2.8318722248077393
train: epoch 11, loss 1.1153788566589355, acc=0.5606111288070679, loss=1.1153788566589355
test: epoch 11, loss 2.8293964862823486, acc=0.18333333730697632, loss=2.8293964862823486
train: epoch 12, loss 1.0838595628738403, acc=0.5758888721466064, loss=1.0838595628738403
test: epoch 12, loss 2.9012973308563232, acc=0.17222222685813904, loss=2.9012973308563232
train: epoch 13, loss 1.020709753036499, acc=0.6040555834770203, loss=1.020709753036499
test: epoch 13, loss 2.8092305660247803, acc=0.18333333730697632, loss=2.8092305660247803
train: epoch 14, loss 0.9921427369117737, acc=0.6139444708824158, loss=0.9921427369117737
test: epoch 14, loss 2.7271859645843506, acc=0.1944444477558136, loss=2.7271859645843506
train: epoch 15, loss 0.9704875349998474, acc=0.6234444379806519, loss=0.9704875349998474
test: epoch 15, loss 2.960404634475708, acc=0.18888889253139496, loss=2.960404634475708
train: epoch 16, loss 0.9276241660118103, acc=0.6465555429458618, loss=0.9276241660118103
test: epoch 16, loss 2.668151378631592, acc=0.21388888359069824, loss=2.668151378631592
train: epoch 17, loss 0.906588077545166, acc=0.6512777805328369, loss=0.906588077545166
test: epoch 17, loss 2.7600958347320557, acc=0.19722221791744232, loss=2.7600958347320557
train: epoch 18, loss 0.8557165861129761, acc=0.6710000038146973, loss=0.8557165861129761
test: epoch 18, loss 2.778395414352417, acc=0.1944444477558136, loss=2.778395414352417
train: epoch 19, loss 0.8490651249885559, acc=0.6801111102104187, loss=0.8490651249885559
test: epoch 19, loss 2.6049954891204834, acc=0.22499999403953552, loss=2.6049954891204834
train: epoch 20, loss 0.8189804553985596, acc=0.6939444541931152, loss=0.8189804553985596
test: epoch 20, loss 2.542245864868164, acc=0.23055554926395416, loss=2.542245864868164
train: epoch 21, loss 0.7898165583610535, acc=0.7014999985694885, loss=0.7898165583610535
test: epoch 21, loss 2.67506742477417, acc=0.2222222238779068, loss=2.67506742477417
train: epoch 22, loss 0.7726324200630188, acc=0.7077777981758118, loss=0.7726324200630188
test: epoch 22, loss 2.5717737674713135, acc=0.2361111044883728, loss=2.5717737674713135
train: epoch 23, loss 0.7416755557060242, acc=0.7179999947547913, loss=0.7416755557060242
test: epoch 23, loss 2.4451122283935547, acc=0.2527777850627899, loss=2.4451122283935547
train: epoch 24, loss 0.7368180751800537, acc=0.7219444513320923, loss=0.7368180751800537
test: epoch 24, loss 2.474249839782715, acc=0.23888888955116272, loss=2.474249839782715
train: epoch 25, loss 0.7196061611175537, acc=0.7335000038146973, loss=0.7196061611175537
test: epoch 25, loss 2.5090830326080322, acc=0.21111111342906952, loss=2.5090830326080322
train: epoch 26, loss 0.6887355446815491, acc=0.7446666955947876, loss=0.6887355446815491
test: epoch 26, loss 2.4047274589538574, acc=0.24722221493721008, loss=2.4047274589538574
train: epoch 27, loss 0.6745885610580444, acc=0.7489444613456726, loss=0.6745885610580444
test: epoch 27, loss 2.419833183288574, acc=0.24722221493721008, loss=2.419833183288574
train: epoch 28, loss 0.6619274616241455, acc=0.7557777762413025, loss=0.6619274616241455
test: epoch 28, loss 2.3197574615478516, acc=0.24444444477558136, loss=2.3197574615478516
train: epoch 29, loss 0.6529338955879211, acc=0.7638888955116272, loss=0.6529338955879211
test: epoch 29, loss 2.317744016647339, acc=0.25555557012557983, loss=2.317744016647339
train: epoch 30, loss 0.6280755400657654, acc=0.7707222104072571, loss=0.6280755400657654
test: epoch 30, loss 2.3412508964538574, acc=0.2805555462837219, loss=2.3412508964538574
train: epoch 31, loss 0.6131714582443237, acc=0.7823333144187927, loss=0.6131714582443237
test: epoch 31, loss 2.378340721130371, acc=0.2611111104488373, loss=2.378340721130371
train: epoch 32, loss 0.6026336550712585, acc=0.7836111187934875, loss=0.6026336550712585
test: epoch 32, loss 2.1023149490356445, acc=0.3055555522441864, loss=2.1023149490356445
train: epoch 33, loss 0.58057701587677, acc=0.7816110849380493, loss=0.58057701587677
test: epoch 33, loss 2.3520569801330566, acc=0.29722222685813904, loss=2.3520569801330566
train: epoch 34, loss 0.5843462347984314, acc=0.7885000109672546, loss=0.5843462347984314
test: epoch 34, loss 2.0072550773620605, acc=0.29722222685813904, loss=2.0072550773620605
train: epoch 35, loss 0.5645207166671753, acc=0.7950555682182312, loss=0.5645207166671753
test: epoch 35, loss 2.007242202758789, acc=0.31388887763023376, loss=2.007242202758789
train: epoch 36, loss 0.5405741333961487, acc=0.8034444451332092, loss=0.5405741333961487
test: epoch 36, loss 2.1972155570983887, acc=0.34166666865348816, loss=2.1972155570983887
train: epoch 37, loss 0.5288466215133667, acc=0.8104444742202759, loss=0.5288466215133667
test: epoch 37, loss 2.1340396404266357, acc=0.3194444477558136, loss=2.1340396404266357
train: epoch 38, loss 0.5260074138641357, acc=0.8088889122009277, loss=0.5260074138641357
test: epoch 38, loss 1.9749034643173218, acc=0.30000001192092896, loss=1.9749034643173218
train: epoch 39, loss 0.5157539248466492, acc=0.8128888607025146, loss=0.5157539248466492
test: epoch 39, loss 2.025007963180542, acc=0.31111112236976624, loss=2.025007963180542
train: epoch 40, loss 0.5024042725563049, acc=0.8187777996063232, loss=0.5024042725563049
test: epoch 40, loss 2.17372465133667, acc=0.3472222089767456, loss=2.17372465133667
train: epoch 41, loss 0.4855750501155853, acc=0.8300555348396301, loss=0.4855750501155853
test: epoch 41, loss 2.005610942840576, acc=0.3611111044883728, loss=2.005610942840576
train: epoch 42, loss 0.47411027550697327, acc=0.8313888907432556, loss=0.47411027550697327
test: epoch 42, loss 1.9869869947433472, acc=0.3777777850627899, loss=1.9869869947433472
train: epoch 43, loss 0.4736439883708954, acc=0.8316110968589783, loss=0.4736439883708954
test: epoch 43, loss 1.9083099365234375, acc=0.3583333194255829, loss=1.9083099365234375
train: epoch 44, loss 0.4650847613811493, acc=0.8337777853012085, loss=0.4650847613811493
test: epoch 44, loss 2.0059893131256104, acc=0.3638888895511627, loss=2.0059893131256104
train: epoch 45, loss 0.4645262360572815, acc=0.8370555639266968, loss=0.4645262360572815
test: epoch 45, loss 2.1350796222686768, acc=0.3361110985279083, loss=2.1350796222686768
train: epoch 46, loss 0.43508318066596985, acc=0.8421111106872559, loss=0.43508318066596985
test: epoch 46, loss 2.057652473449707, acc=0.32499998807907104, loss=2.057652473449707
train: epoch 47, loss 0.43840861320495605, acc=0.8426666855812073, loss=0.43840861320495605
test: epoch 47, loss 1.9051384925842285, acc=0.3472222089767456, loss=1.9051384925842285
train: epoch 48, loss 0.4112071096897125, acc=0.85188889503479, loss=0.4112071096897125
test: epoch 48, loss 2.079089641571045, acc=0.3333333432674408, loss=2.079089641571045
train: epoch 49, loss 0.4195171296596527, acc=0.8478333353996277, loss=0.4195171296596527
test: epoch 49, loss 2.1462440490722656, acc=0.33888888359069824, loss=2.1462440490722656
train: epoch 50, loss 0.42123472690582275, acc=0.8501111268997192, loss=0.42123472690582275
test: epoch 50, loss 1.9774404764175415, acc=0.32499998807907104, loss=1.9774404764175415
train: epoch 51, loss 0.4174414575099945, acc=0.8558333516120911, loss=0.4174414575099945
test: epoch 51, loss 1.8510138988494873, acc=0.3499999940395355, loss=1.8510138988494873
train: epoch 52, loss 0.396968275308609, acc=0.8646110892295837, loss=0.396968275308609
test: epoch 52, loss 1.925401210784912, acc=0.35555556416511536, loss=1.925401210784912
train: epoch 53, loss 0.393524706363678, acc=0.85916668176651, loss=0.393524706363678
test: epoch 53, loss 1.9740411043167114, acc=0.3611111044883728, loss=1.9740411043167114
train: epoch 54, loss 0.40249237418174744, acc=0.8603333234786987, loss=0.40249237418174744
test: epoch 54, loss 2.023048162460327, acc=0.3722222149372101, loss=2.023048162460327
train: epoch 55, loss 0.3916405439376831, acc=0.8654999732971191, loss=0.3916405439376831
test: epoch 55, loss 1.8773244619369507, acc=0.4000000059604645, loss=1.8773244619369507
train: epoch 56, loss 0.3655964136123657, acc=0.8685555458068848, loss=0.3655964136123657
test: epoch 56, loss 1.9780930280685425, acc=0.40833333134651184, loss=1.9780930280685425
train: epoch 57, loss 0.3731256425380707, acc=0.8667222261428833, loss=0.3731256425380707
test: epoch 57, loss 2.005547523498535, acc=0.3861111104488373, loss=2.005547523498535
train: epoch 58, loss 0.35851889848709106, acc=0.8738889098167419, loss=0.35851889848709106
test: epoch 58, loss 1.9530309438705444, acc=0.36666667461395264, loss=1.9530309438705444
train: epoch 59, loss 0.3505719304084778, acc=0.8770555257797241, loss=0.3505719304084778
test: epoch 59, loss 1.9174174070358276, acc=0.38055557012557983, loss=1.9174174070358276
train: epoch 60, loss 0.35602816939353943, acc=0.8735555410385132, loss=0.35602816939353943
test: epoch 60, loss 1.9157146215438843, acc=0.4166666567325592, loss=1.9157146215438843
train: epoch 61, loss 0.34581050276756287, acc=0.8774444460868835, loss=0.34581050276756287
test: epoch 61, loss 1.9009660482406616, acc=0.3777777850627899, loss=1.9009660482406616
train: epoch 62, loss 0.3316570222377777, acc=0.882888913154602, loss=0.3316570222377777
test: epoch 62, loss 2.0962369441986084, acc=0.4027777910232544, loss=2.0962369441986084
train: epoch 63, loss 0.3250499963760376, acc=0.8872222304344177, loss=0.3250499963760376
test: epoch 63, loss 1.967008113861084, acc=0.3916666805744171, loss=1.967008113861084
train: epoch 64, loss 0.3349436819553375, acc=0.8787222504615784, loss=0.3349436819553375
test: epoch 64, loss 1.890183925628662, acc=0.3861111104488373, loss=1.890183925628662
train: epoch 65, loss 0.3224635422229767, acc=0.886555552482605, loss=0.3224635422229767
test: epoch 65, loss 2.0823192596435547, acc=0.39722222089767456, loss=2.0823192596435547
train: epoch 66, loss 0.31615346670150757, acc=0.8898888826370239, loss=0.31615346670150757
test: epoch 66, loss 1.9639791250228882, acc=0.38333332538604736, loss=1.9639791250228882
train: epoch 67, loss 0.3240126073360443, acc=0.8923333287239075, loss=0.3240126073360443
test: epoch 67, loss 1.9214386940002441, acc=0.3888888955116272, loss=1.9214386940002441
train: epoch 68, loss 0.32137033343315125, acc=0.8864444494247437, loss=0.32137033343315125
test: epoch 68, loss 1.9794117212295532, acc=0.39722222089767456, loss=1.9794117212295532
train: epoch 69, loss 0.31357473134994507, acc=0.8927222490310669, loss=0.31357473134994507
test: epoch 69, loss 1.8948217630386353, acc=0.3777777850627899, loss=1.8948217630386353
train: epoch 70, loss 0.3017086088657379, acc=0.8932222127914429, loss=0.3017086088657379
test: epoch 70, loss 2.0353689193725586, acc=0.4055555462837219, loss=2.0353689193725586
train: epoch 71, loss 0.297510027885437, acc=0.8956666588783264, loss=0.297510027885437
test: epoch 71, loss 2.1011533737182617, acc=0.39444443583488464, loss=2.1011533737182617
train: epoch 72, loss 0.28528809547424316, acc=0.9044444561004639, loss=0.28528809547424316
test: epoch 72, loss 1.9938346147537231, acc=0.36944442987442017, loss=1.9938346147537231
train: epoch 73, loss 0.2865823209285736, acc=0.9043889045715332, loss=0.2865823209285736
test: epoch 73, loss 1.939946174621582, acc=0.36666667461395264, loss=1.939946174621582
train: epoch 74, loss 0.2859199643135071, acc=0.8980000019073486, loss=0.2859199643135071
test: epoch 74, loss 2.08077335357666, acc=0.3583333194255829, loss=2.08077335357666
train: epoch 75, loss 0.2838999032974243, acc=0.9047777652740479, loss=0.2838999032974243
test: epoch 75, loss 2.1461844444274902, acc=0.3861111104488373, loss=2.1461844444274902
train: epoch 76, loss 0.28341034054756165, acc=0.9017778038978577, loss=0.28341034054756165
test: epoch 76, loss 1.9174429178237915, acc=0.4138889014720917, loss=1.9174429178237915
train: epoch 77, loss 0.2584454119205475, acc=0.9104999899864197, loss=0.2584454119205475
test: epoch 77, loss 1.964398741722107, acc=0.3611111044883728, loss=1.964398741722107
train: epoch 78, loss 0.2617399990558624, acc=0.9088333249092102, loss=0.2617399990558624
test: epoch 78, loss 1.9750651121139526, acc=0.4194444417953491, loss=1.9750651121139526
train: epoch 79, loss 0.26226773858070374, acc=0.9103333353996277, loss=0.26226773858070374
test: epoch 79, loss 2.077092170715332, acc=0.3777777850627899, loss=2.077092170715332
train: epoch 80, loss 0.2701270878314972, acc=0.9127222299575806, loss=0.2701270878314972
test: epoch 80, loss 1.9171797037124634, acc=0.3916666805744171, loss=1.9171797037124634
train: epoch 81, loss 0.26544901728630066, acc=0.9126111268997192, loss=0.26544901728630066
test: epoch 81, loss 1.8007779121398926, acc=0.40833333134651184, loss=1.8007779121398926
train: epoch 82, loss 0.2523401975631714, acc=0.9147777557373047, loss=0.2523401975631714
test: epoch 82, loss 2.0544590950012207, acc=0.4027777910232544, loss=2.0544590950012207
train: epoch 83, loss 0.2514171898365021, acc=0.9170555472373962, loss=0.2514171898365021
test: epoch 83, loss 2.1866326332092285, acc=0.375, loss=2.1866326332092285
train: epoch 84, loss 0.2527172267436981, acc=0.9133333563804626, loss=0.2527172267436981
test: epoch 84, loss 1.9490591287612915, acc=0.4138889014720917, loss=1.9490591287612915
train: epoch 85, loss 0.24963973462581635, acc=0.918055534362793, loss=0.24963973462581635
test: epoch 85, loss 2.3550209999084473, acc=0.4138889014720917, loss=2.3550209999084473
train: epoch 86, loss 0.22640720009803772, acc=0.9253333210945129, loss=0.22640720009803772
test: epoch 86, loss 1.8295135498046875, acc=0.4166666567325592, loss=1.8295135498046875
train: epoch 87, loss 0.22951339185237885, acc=0.9230555295944214, loss=0.22951339185237885
test: epoch 87, loss 1.9525855779647827, acc=0.4305555522441864, loss=1.9525855779647827
train: epoch 88, loss 0.22962407767772675, acc=0.9240555763244629, loss=0.22962407767772675
test: epoch 88, loss 1.9954332113265991, acc=0.39722222089767456, loss=1.9954332113265991
train: epoch 89, loss 0.22660216689109802, acc=0.9260555505752563, loss=0.22660216689109802
test: epoch 89, loss 1.9913747310638428, acc=0.42222222685813904, loss=1.9913747310638428
train: epoch 90, loss 0.22633232176303864, acc=0.9244444370269775, loss=0.22633232176303864
test: epoch 90, loss 1.8263083696365356, acc=0.4583333432674408, loss=1.8263083696365356
train: epoch 91, loss 0.21296371519565582, acc=0.9309444427490234, loss=0.21296371519565582
test: epoch 91, loss 2.0396888256073, acc=0.4555555582046509, loss=2.0396888256073
train: epoch 92, loss 0.21591073274612427, acc=0.9290555715560913, loss=0.21591073274612427
test: epoch 92, loss 1.981967568397522, acc=0.4555555582046509, loss=1.981967568397522
train: epoch 93, loss 0.1991286426782608, acc=0.9340000152587891, loss=0.1991286426782608
test: epoch 93, loss 1.8035475015640259, acc=0.43888887763023376, loss=1.8035475015640259
train: epoch 94, loss 0.2028011977672577, acc=0.9326111078262329, loss=0.2028011977672577
test: epoch 94, loss 2.0496559143066406, acc=0.4583333432674408, loss=2.0496559143066406
train: epoch 95, loss 0.19136923551559448, acc=0.9381111264228821, loss=0.19136923551559448
test: epoch 95, loss 2.132399559020996, acc=0.4444444477558136, loss=2.132399559020996
train: epoch 96, loss 0.19446292519569397, acc=0.9344444274902344, loss=0.19446292519569397
test: epoch 96, loss 1.9297852516174316, acc=0.4333333373069763, loss=1.9297852516174316
train: epoch 97, loss 0.20551997423171997, acc=0.9329444169998169, loss=0.20551997423171997
test: epoch 97, loss 2.1844472885131836, acc=0.4611110985279083, loss=2.1844472885131836
train: epoch 98, loss 0.1989692747592926, acc=0.9362221956253052, loss=0.1989692747592926
test: epoch 98, loss 2.3361239433288574, acc=0.4000000059604645, loss=2.3361239433288574
train: epoch 99, loss 0.20139938592910767, acc=0.9329444169998169, loss=0.20139938592910767
test: epoch 99, loss 1.9297744035720825, acc=0.4472222328186035, loss=1.9297744035720825
train: epoch 100, loss 0.1913934201002121, acc=0.9375555515289307, loss=0.1913934201002121
test: epoch 100, loss 1.9346861839294434, acc=0.42222222685813904, loss=1.9346861839294434
train: epoch 101, loss 0.1992797702550888, acc=0.9372222423553467, loss=0.1992797702550888
test: epoch 101, loss 1.9055302143096924, acc=0.46666666865348816, loss=1.9055302143096924
train: epoch 102, loss 0.19722338020801544, acc=0.9344444274902344, loss=0.19722338020801544
test: epoch 102, loss 2.094316244125366, acc=0.4277777671813965, loss=2.094316244125366
train: epoch 103, loss 0.19025245308876038, acc=0.9389444589614868, loss=0.19025245308876038
test: epoch 103, loss 1.9148766994476318, acc=0.44999998807907104, loss=1.9148766994476318
train: epoch 104, loss 0.180873304605484, acc=0.9406111240386963, loss=0.180873304605484
test: epoch 104, loss 2.120256185531616, acc=0.4555555582046509, loss=2.120256185531616
train: epoch 105, loss 0.18131543695926666, acc=0.9406111240386963, loss=0.18131543695926666
test: epoch 105, loss 2.201812744140625, acc=0.4444444477558136, loss=2.201812744140625
train: epoch 106, loss 0.18092630803585052, acc=0.941944420337677, loss=0.18092630803585052
test: epoch 106, loss 1.866080641746521, acc=0.49166667461395264, loss=1.866080641746521
train: epoch 107, loss 0.18238255381584167, acc=0.9416666626930237, loss=0.18238255381584167
test: epoch 107, loss 1.9098867177963257, acc=0.46666666865348816, loss=1.9098867177963257
train: epoch 108, loss 0.17087842524051666, acc=0.9442222118377686, loss=0.17087842524051666
test: epoch 108, loss 1.8849965333938599, acc=0.4694444537162781, loss=1.8849965333938599
train: epoch 109, loss 0.16203555464744568, acc=0.9482777714729309, loss=0.16203555464744568
test: epoch 109, loss 2.0666940212249756, acc=0.4833333194255829, loss=2.0666940212249756
train: epoch 110, loss 0.18574847280979156, acc=0.9433333277702332, loss=0.18574847280979156
test: epoch 110, loss 1.9106413125991821, acc=0.4722222089767456, loss=1.9106413125991821
train: epoch 111, loss 0.17050252854824066, acc=0.9433888792991638, loss=0.17050252854824066
test: epoch 111, loss 2.0956361293792725, acc=0.4416666626930237, loss=2.0956361293792725
train: epoch 112, loss 0.1735360026359558, acc=0.945555567741394, loss=0.1735360026359558
test: epoch 112, loss 2.3196611404418945, acc=0.46388888359069824, loss=2.3196611404418945
train: epoch 113, loss 0.17458544671535492, acc=0.9459999799728394, loss=0.17458544671535492
test: epoch 113, loss 2.2698798179626465, acc=0.46388888359069824, loss=2.2698798179626465
train: epoch 114, loss 0.17638079822063446, acc=0.9448888897895813, loss=0.17638079822063446
test: epoch 114, loss 2.1436996459960938, acc=0.4611110985279083, loss=2.1436996459960938
train: epoch 115, loss 0.16412004828453064, acc=0.9455000162124634, loss=0.16412004828453064
test: epoch 115, loss 1.8742188215255737, acc=0.4833333194255829, loss=1.8742188215255737
train: epoch 116, loss 0.1566660851240158, acc=0.9493333101272583, loss=0.1566660851240158
test: epoch 116, loss 2.1345033645629883, acc=0.5249999761581421, loss=2.1345033645629883
train: epoch 117, loss 0.16026902198791504, acc=0.9470555782318115, loss=0.16026902198791504
test: epoch 117, loss 2.167370557785034, acc=0.4972222149372101, loss=2.167370557785034
train: epoch 118, loss 0.1619471162557602, acc=0.9478889107704163, loss=0.1619471162557602
test: epoch 118, loss 2.211498975753784, acc=0.4611110985279083, loss=2.211498975753784
train: epoch 119, loss 0.1513330638408661, acc=0.9495555758476257, loss=0.1513330638408661
test: epoch 119, loss 2.0853123664855957, acc=0.46666666865348816, loss=2.0853123664855957
train: epoch 120, loss 0.16960440576076508, acc=0.9456666707992554, loss=0.16960440576076508
test: epoch 120, loss 1.9365872144699097, acc=0.4833333194255829, loss=1.9365872144699097
train: epoch 121, loss 0.15653397142887115, acc=0.9518333077430725, loss=0.15653397142887115
test: epoch 121, loss 1.8578264713287354, acc=0.5, loss=1.8578264713287354
train: epoch 122, loss 0.1535329818725586, acc=0.9512222409248352, loss=0.1535329818725586
test: epoch 122, loss 2.1196582317352295, acc=0.4861111044883728, loss=2.1196582317352295
train: epoch 123, loss 0.14082254469394684, acc=0.9545555710792542, loss=0.14082254469394684
test: epoch 123, loss 2.05294132232666, acc=0.46388888359069824, loss=2.05294132232666
train: epoch 124, loss 0.14354531466960907, acc=0.9547222256660461, loss=0.14354531466960907
test: epoch 124, loss 2.0259339809417725, acc=0.48055556416511536, loss=2.0259339809417725
train: epoch 125, loss 0.15001988410949707, acc=0.9541110992431641, loss=0.15001988410949707
test: epoch 125, loss 2.0049853324890137, acc=0.5111111402511597, loss=2.0049853324890137
train: epoch 126, loss 0.1447867900133133, acc=0.9537222385406494, loss=0.1447867900133133
test: epoch 126, loss 2.0900330543518066, acc=0.4833333194255829, loss=2.0900330543518066
train: epoch 127, loss 0.13927613198757172, acc=0.9547777771949768, loss=0.13927613198757172
test: epoch 127, loss 2.150522470474243, acc=0.47777777910232544, loss=2.150522470474243
train: epoch 128, loss 0.13448144495487213, acc=0.9564444422721863, loss=0.13448144495487213
test: epoch 128, loss 2.1580281257629395, acc=0.49444442987442017, loss=2.1580281257629395
train: epoch 129, loss 0.1477605551481247, acc=0.9540555477142334, loss=0.1477605551481247
test: epoch 129, loss 1.9852522611618042, acc=0.49444442987442017, loss=1.9852522611618042
train: epoch 130, loss 0.12898941338062286, acc=0.9597222208976746, loss=0.12898941338062286
test: epoch 130, loss 2.0484066009521484, acc=0.5277777910232544, loss=2.0484066009521484
train: epoch 131, loss 0.1275167614221573, acc=0.9599999785423279, loss=0.1275167614221573
test: epoch 131, loss 2.0132498741149902, acc=0.519444465637207, loss=2.0132498741149902
train: epoch 132, loss 0.13800260424613953, acc=0.957611083984375, loss=0.13800260424613953
test: epoch 132, loss 1.8979624509811401, acc=0.5027777552604675, loss=1.8979624509811401
train: epoch 133, loss 0.14295189082622528, acc=0.954277753829956, loss=0.14295189082622528
test: epoch 133, loss 2.1445422172546387, acc=0.5333333611488342, loss=2.1445422172546387
train: epoch 134, loss 0.14108288288116455, acc=0.9568333625793457, loss=0.14108288288116455
test: epoch 134, loss 2.077063798904419, acc=0.5277777910232544, loss=2.077063798904419
train: epoch 135, loss 0.12613199651241302, acc=0.9593333601951599, loss=0.12613199651241302
test: epoch 135, loss 2.2364253997802734, acc=0.49166667461395264, loss=2.2364253997802734
train: epoch 136, loss 0.12486273050308228, acc=0.9620555639266968, loss=0.12486273050308228
test: epoch 136, loss 1.9288544654846191, acc=0.5166666507720947, loss=1.9288544654846191
train: epoch 137, loss 0.13270200788974762, acc=0.9611666798591614, loss=0.13270200788974762
test: epoch 137, loss 1.9279305934906006, acc=0.5055555701255798, loss=1.9279305934906006
train: epoch 138, loss 0.12265749275684357, acc=0.961388885974884, loss=0.12265749275684357
test: epoch 138, loss 2.0773892402648926, acc=0.5055555701255798, loss=2.0773892402648926
train: epoch 139, loss 0.1354023665189743, acc=0.9592777490615845, loss=0.1354023665189743
test: epoch 139, loss 2.0619540214538574, acc=0.5472221970558167, loss=2.0619540214538574
train: epoch 140, loss 0.12954393029212952, acc=0.9606666564941406, loss=0.12954393029212952
test: epoch 140, loss 2.0197205543518066, acc=0.5333333611488342, loss=2.0197205543518066
train: epoch 141, loss 0.12146634608507156, acc=0.9605000019073486, loss=0.12146634608507156
test: epoch 141, loss 2.0498414039611816, acc=0.5277777910232544, loss=2.0498414039611816
train: epoch 142, loss 0.12582378089427948, acc=0.9649444222450256, loss=0.12582378089427948
test: epoch 142, loss 1.900285243988037, acc=0.5249999761581421, loss=1.900285243988037
train: epoch 143, loss 0.11276999115943909, acc=0.9651111364364624, loss=0.11276999115943909
test: epoch 143, loss 1.851112723350525, acc=0.550000011920929, loss=1.851112723350525
train: epoch 144, loss 0.11729191243648529, acc=0.9626111388206482, loss=0.11729191243648529
test: epoch 144, loss 2.0801467895507812, acc=0.5138888955116272, loss=2.0801467895507812
train: epoch 145, loss 0.10652626305818558, acc=0.9669444561004639, loss=0.10652626305818558
test: epoch 145, loss 2.1798341274261475, acc=0.4861111044883728, loss=2.1798341274261475
train: epoch 146, loss 0.10844182223081589, acc=0.9662777781486511, loss=0.10844182223081589
test: epoch 146, loss 2.0434587001800537, acc=0.5111111402511597, loss=2.0434587001800537
train: epoch 147, loss 0.11131532490253448, acc=0.9656111001968384, loss=0.11131532490253448
test: epoch 147, loss 2.051854133605957, acc=0.5305555462837219, loss=2.051854133605957
train: epoch 148, loss 0.10971168428659439, acc=0.9664444327354431, loss=0.10971168428659439
test: epoch 148, loss 1.635145664215088, acc=0.5722222328186035, loss=1.635145664215088
train: epoch 149, loss 0.11076421290636063, acc=0.9671666622161865, loss=0.11076421290636063
test: epoch 149, loss 1.7128652334213257, acc=0.550000011920929, loss=1.7128652334213257
train: epoch 150, loss 0.11545781046152115, acc=0.9673333168029785, loss=0.11545781046152115
test: epoch 150, loss 1.8413901329040527, acc=0.5527777671813965, loss=1.8413901329040527
