# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=1", "--temp_decay=1", "--one_hot=false", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=275934351, receiver_embed_dim=128, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.416386365890503, acc=0.04916666820645332, loss=3.416386365890503
test: epoch 1, loss 3.1570096015930176, acc=0.09166666865348816, loss=3.1570096015930176
train: epoch 2, loss 2.234675407409668, acc=0.17416666448116302, loss=2.234675407409668
test: epoch 2, loss 2.338003158569336, acc=0.14166666567325592, loss=2.338003158569336
train: epoch 3, loss 1.7856007814407349, acc=0.27338889241218567, loss=1.7856007814407349
test: epoch 3, loss 2.3073079586029053, acc=0.16944444179534912, loss=2.3073079586029053
train: epoch 4, loss 1.6043261289596558, acc=0.328166663646698, loss=1.6043261289596558
test: epoch 4, loss 2.133962392807007, acc=0.19722221791744232, loss=2.133962392807007
train: epoch 5, loss 1.4946849346160889, acc=0.3638888895511627, loss=1.4946849346160889
test: epoch 5, loss 2.1292355060577393, acc=0.21388888359069824, loss=2.1292355060577393
train: epoch 6, loss 1.4086264371871948, acc=0.4051666557788849, loss=1.4086264371871948
test: epoch 6, loss 2.154606580734253, acc=0.21666666865348816, loss=2.154606580734253
train: epoch 7, loss 1.3514817953109741, acc=0.43238890171051025, loss=1.3514817953109741
test: epoch 7, loss 2.210797071456909, acc=0.21944443881511688, loss=2.210797071456909
train: epoch 8, loss 1.2918685674667358, acc=0.46005555987358093, loss=1.2918685674667358
test: epoch 8, loss 2.0789201259613037, acc=0.23333333432674408, loss=2.0789201259613037
train: epoch 9, loss 1.2621997594833374, acc=0.47155556082725525, loss=1.2621997594833374
test: epoch 9, loss 2.0951931476593018, acc=0.24166665971279144, loss=2.0951931476593018
train: epoch 10, loss 1.2022349834442139, acc=0.4925000071525574, loss=1.2022349834442139
test: epoch 10, loss 2.1089794635772705, acc=0.25555557012557983, loss=2.1089794635772705
train: epoch 11, loss 1.1589889526367188, acc=0.5097222328186035, loss=1.1589889526367188
test: epoch 11, loss 2.107280969619751, acc=0.2611111104488373, loss=2.107280969619751
train: epoch 12, loss 1.1222738027572632, acc=0.5329999923706055, loss=1.1222738027572632
test: epoch 12, loss 2.1032156944274902, acc=0.2611111104488373, loss=2.1032156944274902
train: epoch 13, loss 1.0726608037948608, acc=0.5419444441795349, loss=1.0726608037948608
test: epoch 13, loss 2.0991387367248535, acc=0.25833332538604736, loss=2.0991387367248535
train: epoch 14, loss 1.0475633144378662, acc=0.5581666827201843, loss=1.0475633144378662
test: epoch 14, loss 2.0301005840301514, acc=0.26944443583488464, loss=2.0301005840301514
train: epoch 15, loss 1.0233408212661743, acc=0.5629444718360901, loss=1.0233408212661743
test: epoch 15, loss 2.193235397338867, acc=0.2805555462837219, loss=2.193235397338867
train: epoch 16, loss 1.001096487045288, acc=0.5730555653572083, loss=1.001096487045288
test: epoch 16, loss 2.0478873252868652, acc=0.2750000059604645, loss=2.0478873252868652
train: epoch 17, loss 0.9732385277748108, acc=0.5831111073493958, loss=0.9732385277748108
test: epoch 17, loss 2.1076436042785645, acc=0.2666666805744171, loss=2.1076436042785645
train: epoch 18, loss 0.9604071974754333, acc=0.5881111025810242, loss=0.9604071974754333
test: epoch 18, loss 2.0583977699279785, acc=0.2750000059604645, loss=2.0583977699279785
train: epoch 19, loss 0.9478064775466919, acc=0.5946111083030701, loss=0.9478064775466919
test: epoch 19, loss 2.0900049209594727, acc=0.2750000059604645, loss=2.0900049209594727
train: epoch 20, loss 0.9371002316474915, acc=0.5971666574478149, loss=0.9371002316474915
test: epoch 20, loss 2.1285369396209717, acc=0.28333333134651184, loss=2.1285369396209717
train: epoch 21, loss 0.9241014719009399, acc=0.6049444675445557, loss=0.9241014719009399
test: epoch 21, loss 2.212663412094116, acc=0.2777777910232544, loss=2.212663412094116
train: epoch 22, loss 0.9008603692054749, acc=0.6094444394111633, loss=0.9008603692054749
test: epoch 22, loss 2.293217420578003, acc=0.2805555462837219, loss=2.293217420578003
train: epoch 23, loss 0.8841262459754944, acc=0.6139444708824158, loss=0.8841262459754944
test: epoch 23, loss 2.181349992752075, acc=0.28333333134651184, loss=2.181349992752075
train: epoch 24, loss 0.8821513056755066, acc=0.6223888993263245, loss=0.8821513056755066
test: epoch 24, loss 2.1602747440338135, acc=0.2805555462837219, loss=2.1602747440338135
train: epoch 25, loss 0.8873772621154785, acc=0.6195555329322815, loss=0.8873772621154785
test: epoch 25, loss 2.280179023742676, acc=0.28333333134651184, loss=2.280179023742676
train: epoch 26, loss 0.8624700307846069, acc=0.6255000233650208, loss=0.8624700307846069
test: epoch 26, loss 2.17472243309021, acc=0.2888889014720917, loss=2.17472243309021
train: epoch 27, loss 0.8516827821731567, acc=0.6308888792991638, loss=0.8516827821731567
test: epoch 27, loss 2.1623921394348145, acc=0.29722222685813904, loss=2.1623921394348145
train: epoch 28, loss 0.8395196795463562, acc=0.6367777585983276, loss=0.8395196795463562
test: epoch 28, loss 2.20098876953125, acc=0.2888889014720917, loss=2.20098876953125
train: epoch 29, loss 0.8358678817749023, acc=0.6286666393280029, loss=0.8358678817749023
test: epoch 29, loss 2.225881814956665, acc=0.2944444417953491, loss=2.225881814956665
train: epoch 30, loss 0.8416836857795715, acc=0.6325555443763733, loss=0.8416836857795715
test: epoch 30, loss 2.3370842933654785, acc=0.30000001192092896, loss=2.3370842933654785
train: epoch 31, loss 0.8384232521057129, acc=0.6306111216545105, loss=0.8384232521057129
test: epoch 31, loss 2.1767029762268066, acc=0.2777777910232544, loss=2.1767029762268066
train: epoch 32, loss 0.8263240456581116, acc=0.6336666941642761, loss=0.8263240456581116
test: epoch 32, loss 2.2621266841888428, acc=0.29722222685813904, loss=2.2621266841888428
train: epoch 33, loss 0.8266514539718628, acc=0.6382222175598145, loss=0.8266514539718628
test: epoch 33, loss 2.422536611557007, acc=0.2916666567325592, loss=2.422536611557007
train: epoch 34, loss 0.8158249855041504, acc=0.6447222232818604, loss=0.8158249855041504
test: epoch 34, loss 2.4361915588378906, acc=0.3055555522441864, loss=2.4361915588378906
train: epoch 35, loss 0.8096438050270081, acc=0.6384999752044678, loss=0.8096438050270081
test: epoch 35, loss 2.508930206298828, acc=0.2888889014720917, loss=2.508930206298828
train: epoch 36, loss 0.8010421991348267, acc=0.6425555348396301, loss=0.8010421991348267
test: epoch 36, loss 2.4433815479278564, acc=0.2944444417953491, loss=2.4433815479278564
train: epoch 37, loss 0.8027869462966919, acc=0.6421666741371155, loss=0.8027869462966919
test: epoch 37, loss 2.1445322036743164, acc=0.2944444417953491, loss=2.1445322036743164
train: epoch 38, loss 0.7936524748802185, acc=0.6456111073493958, loss=0.7936524748802185
test: epoch 38, loss 2.424769401550293, acc=0.28611111640930176, loss=2.424769401550293
train: epoch 39, loss 0.801913321018219, acc=0.6449999809265137, loss=0.801913321018219
test: epoch 39, loss 2.398386001586914, acc=0.3027777671813965, loss=2.398386001586914
train: epoch 40, loss 0.80063396692276, acc=0.6439999938011169, loss=0.80063396692276
test: epoch 40, loss 2.2708168029785156, acc=0.2916666567325592, loss=2.2708168029785156
train: epoch 41, loss 0.7835654020309448, acc=0.6476666927337646, loss=0.7835654020309448
test: epoch 41, loss 2.324489116668701, acc=0.3055555522441864, loss=2.324489116668701
train: epoch 42, loss 0.7858983278274536, acc=0.6501111388206482, loss=0.7858983278274536
test: epoch 42, loss 2.369525909423828, acc=0.31111112236976624, loss=2.369525909423828
train: epoch 43, loss 0.7592229843139648, acc=0.6549444198608398, loss=0.7592229843139648
test: epoch 43, loss 2.270312547683716, acc=0.32777777314186096, loss=2.270312547683716
train: epoch 44, loss 0.7741526961326599, acc=0.6532777547836304, loss=0.7741526961326599
test: epoch 44, loss 2.4082047939300537, acc=0.3083333373069763, loss=2.4082047939300537
train: epoch 45, loss 0.7732354998588562, acc=0.6511666774749756, loss=0.7732354998588562
test: epoch 45, loss 2.3176076412200928, acc=0.30000001192092896, loss=2.3176076412200928
train: epoch 46, loss 0.7778865694999695, acc=0.653333306312561, loss=0.7778865694999695
test: epoch 46, loss 2.3553624153137207, acc=0.31388887763023376, loss=2.3553624153137207
train: epoch 47, loss 0.758041501045227, acc=0.6602222323417664, loss=0.758041501045227
test: epoch 47, loss 2.3056488037109375, acc=0.2944444417953491, loss=2.3056488037109375
train: epoch 48, loss 0.7711623311042786, acc=0.6521111130714417, loss=0.7711623311042786
test: epoch 48, loss 2.2333931922912598, acc=0.3055555522441864, loss=2.2333931922912598
train: epoch 49, loss 0.7554664015769958, acc=0.6586111187934875, loss=0.7554664015769958
test: epoch 49, loss 2.5214271545410156, acc=0.2944444417953491, loss=2.5214271545410156
train: epoch 50, loss 0.7672343254089355, acc=0.6543889045715332, loss=0.7672343254089355
test: epoch 50, loss 2.383357524871826, acc=0.31111112236976624, loss=2.383357524871826
train: epoch 51, loss 0.7599451541900635, acc=0.6587777733802795, loss=0.7599451541900635
test: epoch 51, loss 2.4186062812805176, acc=0.32777777314186096, loss=2.4186062812805176
train: epoch 52, loss 0.7457349896430969, acc=0.6601666808128357, loss=0.7457349896430969
test: epoch 52, loss 2.2286059856414795, acc=0.3027777671813965, loss=2.2286059856414795
train: epoch 53, loss 0.7428398132324219, acc=0.6620555520057678, loss=0.7428398132324219
test: epoch 53, loss 2.2633888721466064, acc=0.2944444417953491, loss=2.2633888721466064
train: epoch 54, loss 0.7645716667175293, acc=0.6587777733802795, loss=0.7645716667175293
test: epoch 54, loss 2.5207440853118896, acc=0.3305555582046509, loss=2.5207440853118896
train: epoch 55, loss 0.750001072883606, acc=0.6600000262260437, loss=0.750001072883606
test: epoch 55, loss 2.4827516078948975, acc=0.3222222328186035, loss=2.4827516078948975
train: epoch 56, loss 0.7537107467651367, acc=0.6570000052452087, loss=0.7537107467651367
test: epoch 56, loss 2.4839253425598145, acc=0.3222222328186035, loss=2.4839253425598145
train: epoch 57, loss 0.742591917514801, acc=0.6611111164093018, loss=0.742591917514801
test: epoch 57, loss 2.4505162239074707, acc=0.32777777314186096, loss=2.4505162239074707
train: epoch 58, loss 0.7415735125541687, acc=0.663277804851532, loss=0.7415735125541687
test: epoch 58, loss 2.6087050437927246, acc=0.3166666626930237, loss=2.6087050437927246
train: epoch 59, loss 0.7454103231430054, acc=0.6612777709960938, loss=0.7454103231430054
test: epoch 59, loss 2.4389686584472656, acc=0.31111112236976624, loss=2.4389686584472656
train: epoch 60, loss 0.7366706132888794, acc=0.6646111011505127, loss=0.7366706132888794
test: epoch 60, loss 2.4567112922668457, acc=0.32777777314186096, loss=2.4567112922668457
train: epoch 61, loss 0.7205504775047302, acc=0.6660000085830688, loss=0.7205504775047302
test: epoch 61, loss 2.1954643726348877, acc=0.3333333432674408, loss=2.1954643726348877
train: epoch 62, loss 0.7205802202224731, acc=0.6688888669013977, loss=0.7205802202224731
test: epoch 62, loss 2.3728725910186768, acc=0.3194444477558136, loss=2.3728725910186768
train: epoch 63, loss 0.7198581099510193, acc=0.6682778000831604, loss=0.7198581099510193
test: epoch 63, loss 2.169997453689575, acc=0.32777777314186096, loss=2.169997453689575
train: epoch 64, loss 0.7221865057945251, acc=0.6674444675445557, loss=0.7221865057945251
test: epoch 64, loss 2.3364198207855225, acc=0.3333333432674408, loss=2.3364198207855225
train: epoch 65, loss 0.7163481116294861, acc=0.6699444651603699, loss=0.7163481116294861
test: epoch 65, loss 2.500030994415283, acc=0.3361110985279083, loss=2.500030994415283
train: epoch 66, loss 0.7240772843360901, acc=0.6655555367469788, loss=0.7240772843360901
test: epoch 66, loss 2.4700992107391357, acc=0.3166666626930237, loss=2.4700992107391357
train: epoch 67, loss 0.7112974524497986, acc=0.6710000038146973, loss=0.7112974524497986
test: epoch 67, loss 2.5513086318969727, acc=0.3305555582046509, loss=2.5513086318969727
train: epoch 68, loss 0.7294758558273315, acc=0.6665555834770203, loss=0.7294758558273315
test: epoch 68, loss 2.7665441036224365, acc=0.3027777671813965, loss=2.7665441036224365
train: epoch 69, loss 0.7174453735351562, acc=0.6639999747276306, loss=0.7174453735351562
test: epoch 69, loss 2.268022060394287, acc=0.3305555582046509, loss=2.268022060394287
train: epoch 70, loss 0.7193009853363037, acc=0.6690555810928345, loss=0.7193009853363037
test: epoch 70, loss 2.4270524978637695, acc=0.3222222328186035, loss=2.4270524978637695
train: epoch 71, loss 0.7164047360420227, acc=0.6711111068725586, loss=0.7164047360420227
test: epoch 71, loss 2.2448956966400146, acc=0.32499998807907104, loss=2.2448956966400146
train: epoch 72, loss 0.6899603605270386, acc=0.6807777881622314, loss=0.6899603605270386
test: epoch 72, loss 2.3182671070098877, acc=0.32499998807907104, loss=2.3182671070098877
train: epoch 73, loss 0.7022206783294678, acc=0.6742222309112549, loss=0.7022206783294678
test: epoch 73, loss 2.2528109550476074, acc=0.33888888359069824, loss=2.2528109550476074
train: epoch 74, loss 0.710305392742157, acc=0.6721110939979553, loss=0.710305392742157
test: epoch 74, loss 2.3668220043182373, acc=0.3444444537162781, loss=2.3668220043182373
train: epoch 75, loss 0.7059036493301392, acc=0.668666660785675, loss=0.7059036493301392
test: epoch 75, loss 2.4261364936828613, acc=0.3333333432674408, loss=2.4261364936828613
train: epoch 76, loss 0.7004858255386353, acc=0.6733333468437195, loss=0.7004858255386353
test: epoch 76, loss 2.3671796321868896, acc=0.3583333194255829, loss=2.3671796321868896
train: epoch 77, loss 0.6974234580993652, acc=0.6720555424690247, loss=0.6974234580993652
test: epoch 77, loss 2.5521843433380127, acc=0.35555556416511536, loss=2.5521843433380127
train: epoch 78, loss 0.6997239589691162, acc=0.6738888621330261, loss=0.6997239589691162
test: epoch 78, loss 2.349912643432617, acc=0.3444444537162781, loss=2.349912643432617
train: epoch 79, loss 0.6963142156600952, acc=0.674833357334137, loss=0.6963142156600952
test: epoch 79, loss 2.2143476009368896, acc=0.3444444537162781, loss=2.2143476009368896
train: epoch 80, loss 0.7046664357185364, acc=0.6743888854980469, loss=0.7046664357185364
test: epoch 80, loss 2.4565446376800537, acc=0.3305555582046509, loss=2.4565446376800537
train: epoch 81, loss 0.7000983357429504, acc=0.6742777824401855, loss=0.7000983357429504
test: epoch 81, loss 2.40138578414917, acc=0.3444444537162781, loss=2.40138578414917
train: epoch 82, loss 0.6872349381446838, acc=0.6831666827201843, loss=0.6872349381446838
test: epoch 82, loss 2.3115234375, acc=0.3472222089767456, loss=2.3115234375
train: epoch 83, loss 0.6941297650337219, acc=0.6786666512489319, loss=0.6941297650337219
test: epoch 83, loss 2.228762626647949, acc=0.33888888359069824, loss=2.228762626647949
train: epoch 84, loss 0.6921066641807556, acc=0.6758888959884644, loss=0.6921066641807556
test: epoch 84, loss 2.3508100509643555, acc=0.3499999940395355, loss=2.3508100509643555
train: epoch 85, loss 0.6875367164611816, acc=0.6784444451332092, loss=0.6875367164611816
test: epoch 85, loss 2.5552706718444824, acc=0.3361110985279083, loss=2.5552706718444824
train: epoch 86, loss 0.6681752800941467, acc=0.6888333559036255, loss=0.6681752800941467
test: epoch 86, loss 2.391087532043457, acc=0.3333333432674408, loss=2.391087532043457
train: epoch 87, loss 0.6851796507835388, acc=0.6842222213745117, loss=0.6851796507835388
test: epoch 87, loss 2.399723529815674, acc=0.34166666865348816, loss=2.399723529815674
train: epoch 88, loss 0.6817302107810974, acc=0.6807777881622314, loss=0.6817302107810974
test: epoch 88, loss 2.256166934967041, acc=0.3333333432674408, loss=2.256166934967041
train: epoch 89, loss 0.691475510597229, acc=0.6775555610656738, loss=0.691475510597229
test: epoch 89, loss 2.377394437789917, acc=0.3499999940395355, loss=2.377394437789917
train: epoch 90, loss 0.6824597120285034, acc=0.6821666955947876, loss=0.6824597120285034
test: epoch 90, loss 2.318202495574951, acc=0.3361110985279083, loss=2.318202495574951
train: epoch 91, loss 0.6866416335105896, acc=0.679722249507904, loss=0.6866416335105896
test: epoch 91, loss 2.032344341278076, acc=0.35277777910232544, loss=2.032344341278076
train: epoch 92, loss 0.6713480353355408, acc=0.6861666440963745, loss=0.6713480353355408
test: epoch 92, loss 2.3908722400665283, acc=0.3361110985279083, loss=2.3908722400665283
train: epoch 93, loss 0.6783813834190369, acc=0.6818333268165588, loss=0.6783813834190369
test: epoch 93, loss 2.29569673538208, acc=0.35277777910232544, loss=2.29569673538208
train: epoch 94, loss 0.6781077980995178, acc=0.6822222471237183, loss=0.6781077980995178
test: epoch 94, loss 2.455508232116699, acc=0.3583333194255829, loss=2.455508232116699
train: epoch 95, loss 0.6906242370605469, acc=0.6809999942779541, loss=0.6906242370605469
test: epoch 95, loss 2.4333159923553467, acc=0.3499999940395355, loss=2.4333159923553467
train: epoch 96, loss 0.6720974445343018, acc=0.6859444379806519, loss=0.6720974445343018
test: epoch 96, loss 2.3717293739318848, acc=0.3583333194255829, loss=2.3717293739318848
train: epoch 97, loss 0.6739027500152588, acc=0.684333324432373, loss=0.6739027500152588
test: epoch 97, loss 2.4013381004333496, acc=0.375, loss=2.4013381004333496
train: epoch 98, loss 0.6659101843833923, acc=0.6882222294807434, loss=0.6659101843833923
test: epoch 98, loss 2.4366776943206787, acc=0.3722222149372101, loss=2.4366776943206787
train: epoch 99, loss 0.6570226550102234, acc=0.6899444460868835, loss=0.6570226550102234
test: epoch 99, loss 2.6842877864837646, acc=0.3638888895511627, loss=2.6842877864837646
train: epoch 100, loss 0.6642359495162964, acc=0.6902777552604675, loss=0.6642359495162964
test: epoch 100, loss 2.2869255542755127, acc=0.35555556416511536, loss=2.2869255542755127
train: epoch 101, loss 0.6765114665031433, acc=0.684166669845581, loss=0.6765114665031433
test: epoch 101, loss 2.446956157684326, acc=0.34166666865348816, loss=2.446956157684326
train: epoch 102, loss 0.6550173163414001, acc=0.6927222013473511, loss=0.6550173163414001
test: epoch 102, loss 2.4801979064941406, acc=0.36666667461395264, loss=2.4801979064941406
train: epoch 103, loss 0.6630558967590332, acc=0.6876111030578613, loss=0.6630558967590332
test: epoch 103, loss 2.219146728515625, acc=0.3444444537162781, loss=2.219146728515625
train: epoch 104, loss 0.6566459536552429, acc=0.6936110854148865, loss=0.6566459536552429
test: epoch 104, loss 2.6074154376983643, acc=0.35277777910232544, loss=2.6074154376983643
train: epoch 105, loss 0.6707670092582703, acc=0.687166690826416, loss=0.6707670092582703
test: epoch 105, loss 2.2468013763427734, acc=0.3583333194255829, loss=2.2468013763427734
train: epoch 106, loss 0.651775062084198, acc=0.694611132144928, loss=0.651775062084198
test: epoch 106, loss 2.2830915451049805, acc=0.3722222149372101, loss=2.2830915451049805
train: epoch 107, loss 0.6637063026428223, acc=0.6921111345291138, loss=0.6637063026428223
test: epoch 107, loss 2.229121685028076, acc=0.35277777910232544, loss=2.229121685028076
train: epoch 108, loss 0.667570948600769, acc=0.6895555257797241, loss=0.667570948600769
test: epoch 108, loss 2.280564069747925, acc=0.34166666865348816, loss=2.280564069747925
train: epoch 109, loss 0.641187310218811, acc=0.6963889002799988, loss=0.641187310218811
test: epoch 109, loss 2.3606133460998535, acc=0.375, loss=2.3606133460998535
train: epoch 110, loss 0.6728487610816956, acc=0.6859999895095825, loss=0.6728487610816956
test: epoch 110, loss 2.324882984161377, acc=0.36944442987442017, loss=2.324882984161377
train: epoch 111, loss 0.6581205725669861, acc=0.6893333196640015, loss=0.6581205725669861
test: epoch 111, loss 2.190483570098877, acc=0.3611111044883728, loss=2.190483570098877
train: epoch 112, loss 0.6602283120155334, acc=0.6894999742507935, loss=0.6602283120155334
test: epoch 112, loss 2.593623638153076, acc=0.3722222149372101, loss=2.593623638153076
train: epoch 113, loss 0.6441031694412231, acc=0.6934444308280945, loss=0.6441031694412231
test: epoch 113, loss 2.1539175510406494, acc=0.3722222149372101, loss=2.1539175510406494
train: epoch 114, loss 0.6457083225250244, acc=0.6934999823570251, loss=0.6457083225250244
test: epoch 114, loss 2.5748229026794434, acc=0.36944442987442017, loss=2.5748229026794434
train: epoch 115, loss 0.6542618870735168, acc=0.6925555467605591, loss=0.6542618870735168
test: epoch 115, loss 2.555001974105835, acc=0.3722222149372101, loss=2.555001974105835
train: epoch 116, loss 0.6683540940284729, acc=0.6875555515289307, loss=0.6683540940284729
test: epoch 116, loss 2.4767630100250244, acc=0.36944442987442017, loss=2.4767630100250244
train: epoch 117, loss 0.6417807936668396, acc=0.6965555548667908, loss=0.6417807936668396
test: epoch 117, loss 2.1598756313323975, acc=0.3722222149372101, loss=2.1598756313323975
train: epoch 118, loss 0.6430854201316833, acc=0.6943333148956299, loss=0.6430854201316833
test: epoch 118, loss 2.554079532623291, acc=0.3777777850627899, loss=2.554079532623291
train: epoch 119, loss 0.6352255940437317, acc=0.6996666789054871, loss=0.6352255940437317
test: epoch 119, loss 2.482114553451538, acc=0.3722222149372101, loss=2.482114553451538
train: epoch 120, loss 0.6410676836967468, acc=0.6943333148956299, loss=0.6410676836967468
test: epoch 120, loss 2.3373234272003174, acc=0.36944442987442017, loss=2.3373234272003174
train: epoch 121, loss 0.6494482159614563, acc=0.6942777633666992, loss=0.6494482159614563
test: epoch 121, loss 2.4370598793029785, acc=0.3777777850627899, loss=2.4370598793029785
train: epoch 122, loss 0.6531765460968018, acc=0.6916666626930237, loss=0.6531765460968018
test: epoch 122, loss 2.421041250228882, acc=0.375, loss=2.421041250228882
train: epoch 123, loss 0.6480531096458435, acc=0.6961666941642761, loss=0.6480531096458435
test: epoch 123, loss 2.2253575325012207, acc=0.36666667461395264, loss=2.2253575325012207
train: epoch 124, loss 0.6435484290122986, acc=0.6915000081062317, loss=0.6435484290122986
test: epoch 124, loss 2.4117729663848877, acc=0.375, loss=2.4117729663848877
train: epoch 125, loss 0.6456122994422913, acc=0.6949999928474426, loss=0.6456122994422913
test: epoch 125, loss 2.3902499675750732, acc=0.3638888895511627, loss=2.3902499675750732
train: epoch 126, loss 0.6471226811408997, acc=0.6972777843475342, loss=0.6471226811408997
test: epoch 126, loss 2.6047463417053223, acc=0.36944442987442017, loss=2.6047463417053223
train: epoch 127, loss 0.653400719165802, acc=0.6933333277702332, loss=0.653400719165802
test: epoch 127, loss 2.42014479637146, acc=0.36944442987442017, loss=2.42014479637146
train: epoch 128, loss 0.6320685148239136, acc=0.7000555396080017, loss=0.6320685148239136
test: epoch 128, loss 2.5017952919006348, acc=0.3777777850627899, loss=2.5017952919006348
train: epoch 129, loss 0.638985276222229, acc=0.7008333206176758, loss=0.638985276222229
test: epoch 129, loss 2.1892142295837402, acc=0.38055557012557983, loss=2.1892142295837402
train: epoch 130, loss 0.6435210704803467, acc=0.6963889002799988, loss=0.6435210704803467
test: epoch 130, loss 2.4568028450012207, acc=0.3638888895511627, loss=2.4568028450012207
train: epoch 131, loss 0.6392934322357178, acc=0.6992777585983276, loss=0.6392934322357178
test: epoch 131, loss 2.2288687229156494, acc=0.36944442987442017, loss=2.2288687229156494
train: epoch 132, loss 0.6288774609565735, acc=0.7082777619361877, loss=0.6288774609565735
test: epoch 132, loss 2.4122583866119385, acc=0.375, loss=2.4122583866119385
train: epoch 133, loss 0.6220210194587708, acc=0.7098888754844666, loss=0.6220210194587708
test: epoch 133, loss 2.181320905685425, acc=0.3861111104488373, loss=2.181320905685425
train: epoch 134, loss 0.6277672648429871, acc=0.7077222466468811, loss=0.6277672648429871
test: epoch 134, loss 2.6725656986236572, acc=0.38055557012557983, loss=2.6725656986236572
train: epoch 135, loss 0.616594135761261, acc=0.7080555558204651, loss=0.616594135761261
test: epoch 135, loss 2.323646068572998, acc=0.38333332538604736, loss=2.323646068572998
train: epoch 136, loss 0.6171174049377441, acc=0.7145000100135803, loss=0.6171174049377441
test: epoch 136, loss 2.5783960819244385, acc=0.3638888895511627, loss=2.5783960819244385
train: epoch 137, loss 0.6144294142723083, acc=0.7131666541099548, loss=0.6144294142723083
test: epoch 137, loss 2.4585225582122803, acc=0.36944442987442017, loss=2.4585225582122803
train: epoch 138, loss 0.6201810836791992, acc=0.7151111364364624, loss=0.6201810836791992
test: epoch 138, loss 2.239274740219116, acc=0.3777777850627899, loss=2.239274740219116
train: epoch 139, loss 0.6023842096328735, acc=0.7177222371101379, loss=0.6023842096328735
test: epoch 139, loss 2.4452247619628906, acc=0.36944442987442017, loss=2.4452247619628906
train: epoch 140, loss 0.6085492968559265, acc=0.718833327293396, loss=0.6085492968559265
test: epoch 140, loss 2.2773754596710205, acc=0.38055557012557983, loss=2.2773754596710205
train: epoch 141, loss 0.6215739250183105, acc=0.7114444375038147, loss=0.6215739250183105
test: epoch 141, loss 2.6037228107452393, acc=0.3861111104488373, loss=2.6037228107452393
train: epoch 142, loss 0.6105508208274841, acc=0.7183889150619507, loss=0.6105508208274841
test: epoch 142, loss 2.2021756172180176, acc=0.3777777850627899, loss=2.2021756172180176
train: epoch 143, loss 0.5953201055526733, acc=0.7203888893127441, loss=0.5953201055526733
test: epoch 143, loss 2.3598785400390625, acc=0.38333332538604736, loss=2.3598785400390625
train: epoch 144, loss 0.6256800293922424, acc=0.7146111130714417, loss=0.6256800293922424
test: epoch 144, loss 2.3893063068389893, acc=0.38333332538604736, loss=2.3893063068389893
train: epoch 145, loss 0.6016420125961304, acc=0.721666693687439, loss=0.6016420125961304
test: epoch 145, loss 2.3055148124694824, acc=0.38333332538604736, loss=2.3055148124694824
train: epoch 146, loss 0.6090579628944397, acc=0.7158889174461365, loss=0.6090579628944397
test: epoch 146, loss 2.3552749156951904, acc=0.3777777850627899, loss=2.3552749156951904
train: epoch 147, loss 0.6007902026176453, acc=0.7210555672645569, loss=0.6007902026176453
test: epoch 147, loss 2.3782992362976074, acc=0.3777777850627899, loss=2.3782992362976074
train: epoch 148, loss 0.607303261756897, acc=0.7206110954284668, loss=0.607303261756897
test: epoch 148, loss 2.2915871143341064, acc=0.38333332538604736, loss=2.2915871143341064
train: epoch 149, loss 0.6016243696212769, acc=0.7222777605056763, loss=0.6016243696212769
test: epoch 149, loss 2.0994129180908203, acc=0.36944442987442017, loss=2.0994129180908203
train: epoch 150, loss 0.5995839238166809, acc=0.7229999899864197, loss=0.5995839238166809
test: epoch 150, loss 2.203084707260132, acc=0.375, loss=2.203084707260132
