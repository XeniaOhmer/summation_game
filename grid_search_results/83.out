# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=false", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1665409041, receiver_embed_dim=64, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.8869309425354004, acc=0.09961111098527908, loss=2.8869309425354004
test: epoch 1, loss 3.235645055770874, acc=0.10000000149011612, loss=3.235645055770874
train: epoch 2, loss 1.946640133857727, acc=0.24266666173934937, loss=1.946640133857727
test: epoch 2, loss 3.3221042156219482, acc=0.17777778208255768, loss=3.3221042156219482
train: epoch 3, loss 1.4848843812942505, acc=0.38483333587646484, loss=1.4848843812942505
test: epoch 3, loss 2.874509334564209, acc=0.21388888359069824, loss=2.874509334564209
train: epoch 4, loss 1.194427728652954, acc=0.4906666576862335, loss=1.194427728652954
test: epoch 4, loss 2.1181044578552246, acc=0.2916666567325592, loss=2.1181044578552246
train: epoch 5, loss 1.05722177028656, acc=0.5421110987663269, loss=1.05722177028656
test: epoch 5, loss 2.0349347591400146, acc=0.3305555582046509, loss=2.0349347591400146
train: epoch 6, loss 0.9474108219146729, acc=0.5932222008705139, loss=0.9474108219146729
test: epoch 6, loss 1.5948612689971924, acc=0.4000000059604645, loss=1.5948612689971924
train: epoch 7, loss 0.8107517957687378, acc=0.6668333411216736, loss=0.8107517957687378
test: epoch 7, loss 1.7619374990463257, acc=0.41111111640930176, loss=1.7619374990463257
train: epoch 8, loss 0.7094204425811768, acc=0.7140555381774902, loss=0.7094204425811768
test: epoch 8, loss 1.438014268875122, acc=0.4722222089767456, loss=1.438014268875122
train: epoch 9, loss 0.5819595456123352, acc=0.7576666474342346, loss=0.5819595456123352
test: epoch 9, loss 1.6696202754974365, acc=0.4138889014720917, loss=1.6696202754974365
train: epoch 10, loss 0.5640421509742737, acc=0.7657777667045593, loss=0.5640421509742737
test: epoch 10, loss 1.5030239820480347, acc=0.4583333432674408, loss=1.5030239820480347
train: epoch 11, loss 0.5077662467956543, acc=0.7907778024673462, loss=0.5077662467956543
test: epoch 11, loss 1.6496597528457642, acc=0.4416666626930237, loss=1.6496597528457642
train: epoch 12, loss 0.499128133058548, acc=0.7944444417953491, loss=0.499128133058548
test: epoch 12, loss 1.6218607425689697, acc=0.4861111044883728, loss=1.6218607425689697
train: epoch 13, loss 0.44966959953308105, acc=0.8166666626930237, loss=0.44966959953308105
test: epoch 13, loss 1.9788659811019897, acc=0.5, loss=1.9788659811019897
train: epoch 14, loss 0.4610109031200409, acc=0.8123888969421387, loss=0.4610109031200409
test: epoch 14, loss 1.6913185119628906, acc=0.49166667461395264, loss=1.6913185119628906
train: epoch 15, loss 0.43156224489212036, acc=0.8228333592414856, loss=0.43156224489212036
test: epoch 15, loss 1.373827338218689, acc=0.5305555462837219, loss=1.373827338218689
train: epoch 16, loss 0.43354713916778564, acc=0.8251110911369324, loss=0.43354713916778564
test: epoch 16, loss 1.547929286956787, acc=0.519444465637207, loss=1.547929286956787
train: epoch 17, loss 0.4093845784664154, acc=0.8344444632530212, loss=0.4093845784664154
test: epoch 17, loss 1.5350894927978516, acc=0.5111111402511597, loss=1.5350894927978516
train: epoch 18, loss 0.4302053451538086, acc=0.8274444341659546, loss=0.4302053451538086
test: epoch 18, loss 1.254643440246582, acc=0.519444465637207, loss=1.254643440246582
train: epoch 19, loss 0.401167094707489, acc=0.8382777571678162, loss=0.401167094707489
test: epoch 19, loss 1.4760169982910156, acc=0.5222222208976746, loss=1.4760169982910156
train: epoch 20, loss 0.41056281328201294, acc=0.8361111283302307, loss=0.41056281328201294
test: epoch 20, loss 1.5630607604980469, acc=0.4694444537162781, loss=1.5630607604980469
train: epoch 21, loss 0.37565216422080994, acc=0.8457777500152588, loss=0.37565216422080994
test: epoch 21, loss 1.327670931816101, acc=0.5249999761581421, loss=1.327670931816101
train: epoch 22, loss 0.3903827667236328, acc=0.8407222032546997, loss=0.3903827667236328
test: epoch 22, loss 1.2537559270858765, acc=0.574999988079071, loss=1.2537559270858765
train: epoch 23, loss 0.3663470149040222, acc=0.8513888716697693, loss=0.3663470149040222
test: epoch 23, loss 1.4414724111557007, acc=0.5555555820465088, loss=1.4414724111557007
train: epoch 24, loss 0.37792670726776123, acc=0.8451666831970215, loss=0.37792670726776123
test: epoch 24, loss 1.3852479457855225, acc=0.5888888835906982, loss=1.3852479457855225
train: epoch 25, loss 0.3586329519748688, acc=0.8521111011505127, loss=0.3586329519748688
test: epoch 25, loss 1.334592342376709, acc=0.5361111164093018, loss=1.334592342376709
train: epoch 26, loss 0.3452233076095581, acc=0.854888916015625, loss=0.3452233076095581
test: epoch 26, loss 1.4371353387832642, acc=0.5666666626930237, loss=1.4371353387832642
train: epoch 27, loss 0.33346161246299744, acc=0.8619999885559082, loss=0.33346161246299744
test: epoch 27, loss 1.4943654537200928, acc=0.5611110925674438, loss=1.4943654537200928
train: epoch 28, loss 0.33405178785324097, acc=0.862333357334137, loss=0.33405178785324097
test: epoch 28, loss 1.1181422472000122, acc=0.605555534362793, loss=1.1181422472000122
train: epoch 29, loss 0.33562466502189636, acc=0.863111138343811, loss=0.33562466502189636
test: epoch 29, loss 1.5642976760864258, acc=0.5472221970558167, loss=1.5642976760864258
train: epoch 30, loss 0.34257179498672485, acc=0.8604444265365601, loss=0.34257179498672485
test: epoch 30, loss 1.2264512777328491, acc=0.605555534362793, loss=1.2264512777328491
train: epoch 31, loss 0.3212016820907593, acc=0.8675000071525574, loss=0.3212016820907593
test: epoch 31, loss 1.3081072568893433, acc=0.6277777552604675, loss=1.3081072568893433
train: epoch 32, loss 0.339699923992157, acc=0.8593888878822327, loss=0.339699923992157
test: epoch 32, loss 0.9651613831520081, acc=0.6638888716697693, loss=0.9651613831520081
train: epoch 33, loss 0.30820149183273315, acc=0.8707777857780457, loss=0.30820149183273315
test: epoch 33, loss 1.1784530878067017, acc=0.5777778029441833, loss=1.1784530878067017
train: epoch 34, loss 0.3168267011642456, acc=0.8691111207008362, loss=0.3168267011642456
test: epoch 34, loss 1.253529667854309, acc=0.6111111044883728, loss=1.253529667854309
train: epoch 35, loss 0.32784369587898254, acc=0.8657222390174866, loss=0.32784369587898254
test: epoch 35, loss 0.8942771553993225, acc=0.6583333611488342, loss=0.8942771553993225
train: epoch 36, loss 0.33216118812561035, acc=0.8619444370269775, loss=0.33216118812561035
test: epoch 36, loss 1.054619550704956, acc=0.6888889074325562, loss=1.054619550704956
train: epoch 37, loss 0.32281848788261414, acc=0.8672778010368347, loss=0.32281848788261414
test: epoch 37, loss 0.9751851558685303, acc=0.699999988079071, loss=0.9751851558685303
train: epoch 38, loss 0.3121960163116455, acc=0.867222249507904, loss=0.3121960163116455
test: epoch 38, loss 0.9097548127174377, acc=0.675000011920929, loss=0.9097548127174377
train: epoch 39, loss 0.2890856862068176, acc=0.8776111006736755, loss=0.2890856862068176
test: epoch 39, loss 0.9701696038246155, acc=0.6722221970558167, loss=0.9701696038246155
train: epoch 40, loss 0.31926998496055603, acc=0.8668333292007446, loss=0.31926998496055603
test: epoch 40, loss 0.8641154170036316, acc=0.6833333373069763, loss=0.8641154170036316
train: epoch 41, loss 0.3150039613246918, acc=0.8718888759613037, loss=0.3150039613246918
test: epoch 41, loss 0.9285080432891846, acc=0.6833333373069763, loss=0.9285080432891846
train: epoch 42, loss 0.2997240722179413, acc=0.8759999871253967, loss=0.2997240722179413
test: epoch 42, loss 0.8373019099235535, acc=0.6944444179534912, loss=0.8373019099235535
train: epoch 43, loss 0.2914676070213318, acc=0.8795555830001831, loss=0.2914676070213318
test: epoch 43, loss 0.8042092323303223, acc=0.7055555582046509, loss=0.8042092323303223
train: epoch 44, loss 0.2975383698940277, acc=0.88227778673172, loss=0.2975383698940277
test: epoch 44, loss 0.8715655207633972, acc=0.699999988079071, loss=0.8715655207633972
train: epoch 45, loss 0.27135229110717773, acc=0.894777774810791, loss=0.27135229110717773
test: epoch 45, loss 1.0390204191207886, acc=0.6888889074325562, loss=1.0390204191207886
train: epoch 46, loss 0.237683966755867, acc=0.9067222476005554, loss=0.237683966755867
test: epoch 46, loss 1.0395523309707642, acc=0.699999988079071, loss=1.0395523309707642
train: epoch 47, loss 0.2262929081916809, acc=0.9096111059188843, loss=0.2262929081916809
test: epoch 47, loss 1.0779056549072266, acc=0.7138888835906982, loss=1.0779056549072266
train: epoch 48, loss 0.252768337726593, acc=0.9003333449363708, loss=0.252768337726593
test: epoch 48, loss 1.0408906936645508, acc=0.6972222328186035, loss=1.0408906936645508
train: epoch 49, loss 0.21345607936382294, acc=0.9146111011505127, loss=0.21345607936382294
test: epoch 49, loss 0.9166843295097351, acc=0.7055555582046509, loss=0.9166843295097351
train: epoch 50, loss 0.21395643055438995, acc=0.9154999852180481, loss=0.21395643055438995
test: epoch 50, loss 1.1077319383621216, acc=0.7027778029441833, loss=1.1077319383621216
train: epoch 51, loss 0.22944669425487518, acc=0.9088888764381409, loss=0.22944669425487518
test: epoch 51, loss 0.9788910746574402, acc=0.7027778029441833, loss=0.9788910746574402
train: epoch 52, loss 0.2219051867723465, acc=0.9116111397743225, loss=0.2219051867723465
test: epoch 52, loss 1.1304476261138916, acc=0.7055555582046509, loss=1.1304476261138916
train: epoch 53, loss 0.21593044698238373, acc=0.9126666784286499, loss=0.21593044698238373
test: epoch 53, loss 0.9139120578765869, acc=0.7027778029441833, loss=0.9139120578765869
train: epoch 54, loss 0.26297032833099365, acc=0.8974999785423279, loss=0.26297032833099365
test: epoch 54, loss 0.9193048477172852, acc=0.7138888835906982, loss=0.9193048477172852
train: epoch 55, loss 0.2049272060394287, acc=0.9155555367469788, loss=0.2049272060394287
test: epoch 55, loss 0.9437479972839355, acc=0.7138888835906982, loss=0.9437479972839355
train: epoch 56, loss 0.2239995002746582, acc=0.9096666574478149, loss=0.2239995002746582
test: epoch 56, loss 0.7757160067558289, acc=0.7055555582046509, loss=0.7757160067558289
train: epoch 57, loss 0.23080211877822876, acc=0.9068889021873474, loss=0.23080211877822876
test: epoch 57, loss 1.0556937456130981, acc=0.6777777671813965, loss=1.0556937456130981
train: epoch 58, loss 0.21262699365615845, acc=0.9159444570541382, loss=0.21262699365615845
test: epoch 58, loss 0.9820785522460938, acc=0.7111111283302307, loss=0.9820785522460938
train: epoch 59, loss 0.22415630519390106, acc=0.9102222323417664, loss=0.22415630519390106
test: epoch 59, loss 0.9786866307258606, acc=0.699999988079071, loss=0.9786866307258606
train: epoch 60, loss 0.23436972498893738, acc=0.9111111164093018, loss=0.23436972498893738
test: epoch 60, loss 0.9794284701347351, acc=0.7083333134651184, loss=0.9794284701347351
train: epoch 61, loss 0.19856496155261993, acc=0.9200555682182312, loss=0.19856496155261993
test: epoch 61, loss 1.0804269313812256, acc=0.7083333134651184, loss=1.0804269313812256
train: epoch 62, loss 0.21302159130573273, acc=0.9163333177566528, loss=0.21302159130573273
test: epoch 62, loss 1.1175559759140015, acc=0.7083333134651184, loss=1.1175559759140015
train: epoch 63, loss 0.21020954847335815, acc=0.9156666398048401, loss=0.21020954847335815
test: epoch 63, loss 1.0245678424835205, acc=0.7027778029441833, loss=1.0245678424835205
train: epoch 64, loss 0.22795584797859192, acc=0.9130555391311646, loss=0.22795584797859192
test: epoch 64, loss 0.9607673287391663, acc=0.7027778029441833, loss=0.9607673287391663
train: epoch 65, loss 0.210314080119133, acc=0.9175000190734863, loss=0.210314080119133
test: epoch 65, loss 0.9039474129676819, acc=0.7083333134651184, loss=0.9039474129676819
train: epoch 66, loss 0.20478689670562744, acc=0.9175000190734863, loss=0.20478689670562744
test: epoch 66, loss 0.8917239904403687, acc=0.7083333134651184, loss=0.8917239904403687
train: epoch 67, loss 0.21349233388900757, acc=0.9169444441795349, loss=0.21349233388900757
test: epoch 67, loss 0.9558846354484558, acc=0.7083333134651184, loss=0.9558846354484558
train: epoch 68, loss 0.18744461238384247, acc=0.9242222309112549, loss=0.18744461238384247
test: epoch 68, loss 1.1243133544921875, acc=0.7083333134651184, loss=1.1243133544921875
train: epoch 69, loss 0.21359415352344513, acc=0.9168333411216736, loss=0.21359415352344513
test: epoch 69, loss 0.9900863766670227, acc=0.7027778029441833, loss=0.9900863766670227
train: epoch 70, loss 0.2279995083808899, acc=0.9090555310249329, loss=0.2279995083808899
test: epoch 70, loss 1.028118371963501, acc=0.7055555582046509, loss=1.028118371963501
train: epoch 71, loss 0.18031327426433563, acc=0.9276111125946045, loss=0.18031327426433563
test: epoch 71, loss 0.9147226214408875, acc=0.7083333134651184, loss=0.9147226214408875
train: epoch 72, loss 0.21767717599868774, acc=0.9154999852180481, loss=0.21767717599868774
test: epoch 72, loss 0.9479652047157288, acc=0.7083333134651184, loss=0.9479652047157288
train: epoch 73, loss 0.1966031789779663, acc=0.9209444522857666, loss=0.1966031789779663
test: epoch 73, loss 1.0685256719589233, acc=0.7083333134651184, loss=1.0685256719589233
train: epoch 74, loss 0.23031364381313324, acc=0.9097777605056763, loss=0.23031364381313324
test: epoch 74, loss 1.012790560722351, acc=0.7055555582046509, loss=1.012790560722351
train: epoch 75, loss 0.21225985884666443, acc=0.9160555601119995, loss=0.21225985884666443
test: epoch 75, loss 1.0975879430770874, acc=0.7083333134651184, loss=1.0975879430770874
train: epoch 76, loss 0.2122042179107666, acc=0.9201111197471619, loss=0.2122042179107666
test: epoch 76, loss 0.8350403904914856, acc=0.7055555582046509, loss=0.8350403904914856
train: epoch 77, loss 0.19351758062839508, acc=0.9224444627761841, loss=0.19351758062839508
test: epoch 77, loss 0.9294410347938538, acc=0.7083333134651184, loss=0.9294410347938538
train: epoch 78, loss 0.22871030867099762, acc=0.9122222065925598, loss=0.22871030867099762
test: epoch 78, loss 1.1093153953552246, acc=0.7083333134651184, loss=1.1093153953552246
train: epoch 79, loss 0.21174116432666779, acc=0.9185000061988831, loss=0.21174116432666779
test: epoch 79, loss 1.081129789352417, acc=0.7083333134651184, loss=1.081129789352417
train: epoch 80, loss 0.21057724952697754, acc=0.9196666479110718, loss=0.21057724952697754
test: epoch 80, loss 1.2697563171386719, acc=0.7111111283302307, loss=1.2697563171386719
train: epoch 81, loss 0.2045108675956726, acc=0.9187222123146057, loss=0.2045108675956726
test: epoch 81, loss 1.1184239387512207, acc=0.7055555582046509, loss=1.1184239387512207
train: epoch 82, loss 0.203861802816391, acc=0.9210000038146973, loss=0.203861802816391
test: epoch 82, loss 1.0468305349349976, acc=0.7083333134651184, loss=1.0468305349349976
train: epoch 83, loss 0.20826175808906555, acc=0.9194444417953491, loss=0.20826175808906555
test: epoch 83, loss 0.9745625853538513, acc=0.6888889074325562, loss=0.9745625853538513
train: epoch 84, loss 0.2163403332233429, acc=0.9157222509384155, loss=0.2163403332233429
test: epoch 84, loss 1.127817153930664, acc=0.7083333134651184, loss=1.127817153930664
train: epoch 85, loss 0.18875887989997864, acc=0.9240000247955322, loss=0.18875887989997864
test: epoch 85, loss 0.9823023080825806, acc=0.7083333134651184, loss=0.9823023080825806
train: epoch 86, loss 0.20367515087127686, acc=0.9214444160461426, loss=0.20367515087127686
test: epoch 86, loss 0.9842422604560852, acc=0.7083333134651184, loss=0.9842422604560852
train: epoch 87, loss 0.1940341740846634, acc=0.9225555658340454, loss=0.1940341740846634
test: epoch 87, loss 1.2221853733062744, acc=0.6972222328186035, loss=1.2221853733062744
train: epoch 88, loss 0.21791355311870575, acc=0.9144999980926514, loss=0.21791355311870575
test: epoch 88, loss 0.9172994494438171, acc=0.7083333134651184, loss=0.9172994494438171
train: epoch 89, loss 0.19605910778045654, acc=0.9231666922569275, loss=0.19605910778045654
test: epoch 89, loss 1.0155912637710571, acc=0.7083333134651184, loss=1.0155912637710571
train: epoch 90, loss 0.2244463562965393, acc=0.9129999876022339, loss=0.2244463562965393
test: epoch 90, loss 0.9879194498062134, acc=0.7083333134651184, loss=0.9879194498062134
train: epoch 91, loss 0.21579845249652863, acc=0.9162222146987915, loss=0.21579845249652863
test: epoch 91, loss 1.002879023551941, acc=0.7055555582046509, loss=1.002879023551941
train: epoch 92, loss 0.22351081669330597, acc=0.9131666421890259, loss=0.22351081669330597
test: epoch 92, loss 0.8815132975578308, acc=0.7083333134651184, loss=0.8815132975578308
train: epoch 93, loss 0.18524496257305145, acc=0.9277222156524658, loss=0.18524496257305145
test: epoch 93, loss 1.061468482017517, acc=0.7111111283302307, loss=1.061468482017517
train: epoch 94, loss 0.19688497483730316, acc=0.9234444499015808, loss=0.19688497483730316
test: epoch 94, loss 0.9891418814659119, acc=0.7083333134651184, loss=0.9891418814659119
train: epoch 95, loss 0.19626384973526, acc=0.9247221946716309, loss=0.19626384973526
test: epoch 95, loss 0.9524543285369873, acc=0.7083333134651184, loss=0.9524543285369873
train: epoch 96, loss 0.1982639729976654, acc=0.9211111068725586, loss=0.1982639729976654
test: epoch 96, loss 1.0363086462020874, acc=0.7027778029441833, loss=1.0363086462020874
train: epoch 97, loss 0.19903944432735443, acc=0.9212222099304199, loss=0.19903944432735443
test: epoch 97, loss 1.1868648529052734, acc=0.7083333134651184, loss=1.1868648529052734
train: epoch 98, loss 0.1987002193927765, acc=0.9223889112472534, loss=0.1987002193927765
test: epoch 98, loss 1.0425317287445068, acc=0.7027778029441833, loss=1.0425317287445068
train: epoch 99, loss 0.20136113464832306, acc=0.9208889007568359, loss=0.20136113464832306
test: epoch 99, loss 1.1533031463623047, acc=0.7083333134651184, loss=1.1533031463623047
train: epoch 100, loss 0.19940465688705444, acc=0.9220555424690247, loss=0.19940465688705444
test: epoch 100, loss 0.964844286441803, acc=0.7083333134651184, loss=0.964844286441803
train: epoch 101, loss 0.19681867957115173, acc=0.9210555553436279, loss=0.19681867957115173
test: epoch 101, loss 0.857244610786438, acc=0.7083333134651184, loss=0.857244610786438
train: epoch 102, loss 0.19340436160564423, acc=0.921999990940094, loss=0.19340436160564423
test: epoch 102, loss 1.0941815376281738, acc=0.7083333134651184, loss=1.0941815376281738
train: epoch 103, loss 0.207299143075943, acc=0.918833315372467, loss=0.207299143075943
test: epoch 103, loss 0.8614034056663513, acc=0.7055555582046509, loss=0.8614034056663513
train: epoch 104, loss 0.17889544367790222, acc=0.9292222261428833, loss=0.17889544367790222
test: epoch 104, loss 0.8878358602523804, acc=0.7083333134651184, loss=0.8878358602523804
train: epoch 105, loss 0.19264797866344452, acc=0.9244444370269775, loss=0.19264797866344452
test: epoch 105, loss 0.9915062785148621, acc=0.7083333134651184, loss=0.9915062785148621
train: epoch 106, loss 0.22206024825572968, acc=0.9165555834770203, loss=0.22206024825572968
test: epoch 106, loss 1.0605008602142334, acc=0.7027778029441833, loss=1.0605008602142334
train: epoch 107, loss 0.20502734184265137, acc=0.9147777557373047, loss=0.20502734184265137
test: epoch 107, loss 0.9600145220756531, acc=0.7055555582046509, loss=0.9600145220756531
train: epoch 108, loss 0.21959149837493896, acc=0.917388916015625, loss=0.21959149837493896
test: epoch 108, loss 0.9539509415626526, acc=0.7027778029441833, loss=0.9539509415626526
train: epoch 109, loss 0.23898543417453766, acc=0.9118888974189758, loss=0.23898543417453766
test: epoch 109, loss 1.0238018035888672, acc=0.7055555582046509, loss=1.0238018035888672
train: epoch 110, loss 0.18691520392894745, acc=0.9241111278533936, loss=0.18691520392894745
test: epoch 110, loss 1.0593457221984863, acc=0.7055555582046509, loss=1.0593457221984863
train: epoch 111, loss 0.20069389045238495, acc=0.921999990940094, loss=0.20069389045238495
test: epoch 111, loss 0.9253232479095459, acc=0.7361111044883728, loss=0.9253232479095459
train: epoch 112, loss 0.18143029510974884, acc=0.9275555610656738, loss=0.18143029510974884
test: epoch 112, loss 0.9601479768753052, acc=0.7388888597488403, loss=0.9601479768753052
train: epoch 113, loss 0.21423839032649994, acc=0.9196666479110718, loss=0.21423839032649994
test: epoch 113, loss 0.8248913288116455, acc=0.7361111044883728, loss=0.8248913288116455
train: epoch 114, loss 0.20566745102405548, acc=0.9196666479110718, loss=0.20566745102405548
test: epoch 114, loss 0.991868257522583, acc=0.7361111044883728, loss=0.991868257522583
train: epoch 115, loss 0.2262708842754364, acc=0.9065555334091187, loss=0.2262708842754364
test: epoch 115, loss 0.7072131633758545, acc=0.7388888597488403, loss=0.7072131633758545
train: epoch 116, loss 0.19791318476200104, acc=0.917388916015625, loss=0.19791318476200104
test: epoch 116, loss 0.9598494172096252, acc=0.7361111044883728, loss=0.9598494172096252
train: epoch 117, loss 0.1918201595544815, acc=0.9219444394111633, loss=0.1918201595544815
test: epoch 117, loss 0.8813760876655579, acc=0.7361111044883728, loss=0.8813760876655579
train: epoch 118, loss 0.2330351620912552, acc=0.9135000109672546, loss=0.2330351620912552
test: epoch 118, loss 0.9863120317459106, acc=0.7388888597488403, loss=0.9863120317459106
train: epoch 119, loss 0.20906484127044678, acc=0.9227777719497681, loss=0.20906484127044678
test: epoch 119, loss 0.8208655714988708, acc=0.7333333492279053, loss=0.8208655714988708
train: epoch 120, loss 0.2323741465806961, acc=0.9163888692855835, loss=0.2323741465806961
test: epoch 120, loss 0.862770676612854, acc=0.730555534362793, loss=0.862770676612854
train: epoch 121, loss 0.21722917258739471, acc=0.9161666631698608, loss=0.21722917258739471
test: epoch 121, loss 0.9909329414367676, acc=0.730555534362793, loss=0.9909329414367676
train: epoch 122, loss 0.22376130521297455, acc=0.9144444465637207, loss=0.22376130521297455
test: epoch 122, loss 0.9427602291107178, acc=0.730555534362793, loss=0.9427602291107178
train: epoch 123, loss 0.22314497828483582, acc=0.9153888821601868, loss=0.22314497828483582
test: epoch 123, loss 0.9169020056724548, acc=0.7250000238418579, loss=0.9169020056724548
train: epoch 124, loss 0.22064313292503357, acc=0.9168333411216736, loss=0.22064313292503357
test: epoch 124, loss 0.8915625810623169, acc=0.730555534362793, loss=0.8915625810623169
train: epoch 125, loss 0.2392912060022354, acc=0.9099444150924683, loss=0.2392912060022354
test: epoch 125, loss 0.9249638319015503, acc=0.7083333134651184, loss=0.9249638319015503
train: epoch 126, loss 0.27114513516426086, acc=0.9047777652740479, loss=0.27114513516426086
test: epoch 126, loss 0.8917974233627319, acc=0.730555534362793, loss=0.8917974233627319
train: epoch 127, loss 0.21868029236793518, acc=0.9186111092567444, loss=0.21868029236793518
test: epoch 127, loss 0.9616032242774963, acc=0.730555534362793, loss=0.9616032242774963
train: epoch 128, loss 0.22958670556545258, acc=0.9135000109672546, loss=0.22958670556545258
test: epoch 128, loss 0.9293743968009949, acc=0.730555534362793, loss=0.9293743968009949
train: epoch 129, loss 0.20303088426589966, acc=0.9203333258628845, loss=0.20303088426589966
test: epoch 129, loss 0.9190834164619446, acc=0.7333333492279053, loss=0.9190834164619446
train: epoch 130, loss 0.23598474264144897, acc=0.9153333306312561, loss=0.23598474264144897
test: epoch 130, loss 0.9182329177856445, acc=0.7277777791023254, loss=0.9182329177856445
train: epoch 131, loss 0.21882295608520508, acc=0.9166111350059509, loss=0.21882295608520508
test: epoch 131, loss 0.813737690448761, acc=0.7277777791023254, loss=0.813737690448761
train: epoch 132, loss 0.22482730448246002, acc=0.9121666550636292, loss=0.22482730448246002
test: epoch 132, loss 0.7971662878990173, acc=0.7222222089767456, loss=0.7971662878990173
train: epoch 133, loss 0.2716149687767029, acc=0.8996111154556274, loss=0.2716149687767029
test: epoch 133, loss 0.828676700592041, acc=0.7222222089767456, loss=0.828676700592041
train: epoch 134, loss 0.2440364509820938, acc=0.9054999947547913, loss=0.2440364509820938
test: epoch 134, loss 0.87556391954422, acc=0.7250000238418579, loss=0.87556391954422
train: epoch 135, loss 0.24342401325702667, acc=0.9087777733802795, loss=0.24342401325702667
test: epoch 135, loss 0.9569605588912964, acc=0.7222222089767456, loss=0.9569605588912964
train: epoch 136, loss 0.2431938499212265, acc=0.909166693687439, loss=0.2431938499212265
test: epoch 136, loss 0.9050639271736145, acc=0.7194444537162781, loss=0.9050639271736145
train: epoch 137, loss 0.3148495852947235, acc=0.8858333230018616, loss=0.3148495852947235
test: epoch 137, loss 0.7630231976509094, acc=0.7166666388511658, loss=0.7630231976509094
train: epoch 138, loss 0.24575155973434448, acc=0.9058889150619507, loss=0.24575155973434448
test: epoch 138, loss 0.9385130405426025, acc=0.7194444537162781, loss=0.9385130405426025
train: epoch 139, loss 0.24754177033901215, acc=0.9062222242355347, loss=0.24754177033901215
test: epoch 139, loss 0.9708130359649658, acc=0.7166666388511658, loss=0.9708130359649658
train: epoch 140, loss 0.3430400490760803, acc=0.88227778673172, loss=0.3430400490760803
test: epoch 140, loss 1.015953779220581, acc=0.6916666626930237, loss=1.015953779220581
train: epoch 141, loss 0.28615421056747437, acc=0.8966110944747925, loss=0.28615421056747437
test: epoch 141, loss 0.9023981690406799, acc=0.7111111283302307, loss=0.9023981690406799
train: epoch 142, loss 0.270134299993515, acc=0.8993889093399048, loss=0.270134299993515
test: epoch 142, loss 0.9743266105651855, acc=0.7055555582046509, loss=0.9743266105651855
train: epoch 143, loss 0.2907864451408386, acc=0.8937222361564636, loss=0.2907864451408386
test: epoch 143, loss 0.8120039105415344, acc=0.7138888835906982, loss=0.8120039105415344
train: epoch 144, loss 0.4198281764984131, acc=0.8537222146987915, loss=0.4198281764984131
test: epoch 144, loss 0.8714768290519714, acc=0.6916666626930237, loss=0.8714768290519714
train: epoch 145, loss 0.3156605660915375, acc=0.8813333511352539, loss=0.3156605660915375
test: epoch 145, loss 0.8602237701416016, acc=0.7055555582046509, loss=0.8602237701416016
train: epoch 146, loss 0.2932150065898895, acc=0.8916666507720947, loss=0.2932150065898895
test: epoch 146, loss 0.9443278908729553, acc=0.7027778029441833, loss=0.9443278908729553
train: epoch 147, loss 0.3161853849887848, acc=0.887666642665863, loss=0.3161853849887848
test: epoch 147, loss 0.9240788817405701, acc=0.7027778029441833, loss=0.9240788817405701
train: epoch 148, loss 0.30909404158592224, acc=0.8891666531562805, loss=0.30909404158592224
test: epoch 148, loss 0.9842381477355957, acc=0.699999988079071, loss=0.9842381477355957
train: epoch 149, loss 0.3690737783908844, acc=0.8778889179229736, loss=0.3690737783908844
test: epoch 149, loss 0.874150812625885, acc=0.7083333134651184, loss=0.874150812625885
train: epoch 150, loss 0.3162437379360199, acc=0.8823333382606506, loss=0.3162437379360199
test: epoch 150, loss 0.9223871231079102, acc=0.6972222328186035, loss=0.9223871231079102
