# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=1", "--one_hot=1", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=1104564466, receiver_embed_dim=32, save_run=0, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1104564466, receiver_embed_dim=32, save_run=False, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.369859218597412, acc=0.050999999046325684, loss=3.369859218597412
test: epoch 1, loss 4.540802955627441, acc=0.06111111119389534, loss=4.540802955627441
train: epoch 2, loss 2.5499989986419678, acc=0.19261111319065094, loss=2.5499989986419678
test: epoch 2, loss 5.972085952758789, acc=0.09166666865348816, loss=5.972085952758789
train: epoch 3, loss 1.7133231163024902, acc=0.38172221183776855, loss=1.7133231163024902
test: epoch 3, loss 5.041868686676025, acc=0.13333334028720856, loss=5.041868686676025
train: epoch 4, loss 1.3601006269454956, acc=0.49227777123451233, loss=1.3601006269454956
test: epoch 4, loss 4.624227523803711, acc=0.15555556118488312, loss=4.624227523803711
train: epoch 5, loss 1.1366443634033203, acc=0.5753889083862305, loss=1.1366443634033203
test: epoch 5, loss 4.345499515533447, acc=0.17222222685813904, loss=4.345499515533447
train: epoch 6, loss 0.9566459655761719, acc=0.648277759552002, loss=0.9566459655761719
test: epoch 6, loss 4.038050174713135, acc=0.18888889253139496, loss=4.038050174713135
train: epoch 7, loss 0.8541614413261414, acc=0.695555567741394, loss=0.8541614413261414
test: epoch 7, loss 4.212194919586182, acc=0.18611110746860504, loss=4.212194919586182
train: epoch 8, loss 0.7525396943092346, acc=0.731333315372467, loss=0.7525396943092346
test: epoch 8, loss 4.356626033782959, acc=0.1805555522441864, loss=4.356626033782959
train: epoch 9, loss 0.6854915618896484, acc=0.7562777996063232, loss=0.6854915618896484
test: epoch 9, loss 4.22590970993042, acc=0.1805555522441864, loss=4.22590970993042
train: epoch 10, loss 0.622657060623169, acc=0.7842222452163696, loss=0.622657060623169
test: epoch 10, loss 4.308609962463379, acc=0.20277777314186096, loss=4.308609962463379
train: epoch 11, loss 0.5752528309822083, acc=0.8027222156524658, loss=0.5752528309822083
test: epoch 11, loss 4.22017765045166, acc=0.23055554926395416, loss=4.22017765045166
train: epoch 12, loss 0.5276745557785034, acc=0.8155555725097656, loss=0.5276745557785034
test: epoch 12, loss 4.1963276863098145, acc=0.21111111342906952, loss=4.1963276863098145
train: epoch 13, loss 0.5118053555488586, acc=0.8281111121177673, loss=0.5118053555488586
test: epoch 13, loss 3.966230630874634, acc=0.23888888955116272, loss=3.966230630874634
train: epoch 14, loss 0.46641457080841064, acc=0.8397777676582336, loss=0.46641457080841064
test: epoch 14, loss 4.153750896453857, acc=0.24166665971279144, loss=4.153750896453857
train: epoch 15, loss 0.4381943941116333, acc=0.8491111397743225, loss=0.4381943941116333
test: epoch 15, loss 4.5728278160095215, acc=0.22777777910232544, loss=4.5728278160095215
train: epoch 16, loss 0.4197055697441101, acc=0.8573333621025085, loss=0.4197055697441101
test: epoch 16, loss 4.476065635681152, acc=0.26944443583488464, loss=4.476065635681152
train: epoch 17, loss 0.39904889464378357, acc=0.8659999966621399, loss=0.39904889464378357
test: epoch 17, loss 4.258635997772217, acc=0.2527777850627899, loss=4.258635997772217
train: epoch 18, loss 0.3763178288936615, acc=0.8721666932106018, loss=0.3763178288936615
test: epoch 18, loss 3.705770254135132, acc=0.3027777671813965, loss=3.705770254135132
train: epoch 19, loss 0.35389676690101624, acc=0.8809444308280945, loss=0.35389676690101624
test: epoch 19, loss 4.122625827789307, acc=0.24166665971279144, loss=4.122625827789307
train: epoch 20, loss 0.34715235233306885, acc=0.8865000009536743, loss=0.34715235233306885
test: epoch 20, loss 4.297359943389893, acc=0.24166665971279144, loss=4.297359943389893
train: epoch 21, loss 0.3382904529571533, acc=0.886555552482605, loss=0.3382904529571533
test: epoch 21, loss 4.246281147003174, acc=0.25, loss=4.246281147003174
train: epoch 22, loss 0.32685935497283936, acc=0.8908888697624207, loss=0.32685935497283936
test: epoch 22, loss 3.917672872543335, acc=0.25833332538604736, loss=3.917672872543335
train: epoch 23, loss 0.30358222126960754, acc=0.8989444375038147, loss=0.30358222126960754
test: epoch 23, loss 3.8253324031829834, acc=0.27222222089767456, loss=3.8253324031829834
train: epoch 24, loss 0.29618948698043823, acc=0.902999997138977, loss=0.29618948698043823
test: epoch 24, loss 3.8118155002593994, acc=0.2666666805744171, loss=3.8118155002593994
train: epoch 25, loss 0.289631187915802, acc=0.9047222137451172, loss=0.289631187915802
test: epoch 25, loss 3.6224706172943115, acc=0.30000001192092896, loss=3.6224706172943115
train: epoch 26, loss 0.2788686454296112, acc=0.9106666445732117, loss=0.2788686454296112
test: epoch 26, loss 3.542591094970703, acc=0.2944444417953491, loss=3.542591094970703
train: epoch 27, loss 0.2643466591835022, acc=0.9138333201408386, loss=0.2643466591835022
test: epoch 27, loss 3.4719066619873047, acc=0.30000001192092896, loss=3.4719066619873047
train: epoch 28, loss 0.27154541015625, acc=0.9103333353996277, loss=0.27154541015625
test: epoch 28, loss 3.5096211433410645, acc=0.28333333134651184, loss=3.5096211433410645
train: epoch 29, loss 0.2470574975013733, acc=0.918666660785675, loss=0.2470574975013733
test: epoch 29, loss 3.556267261505127, acc=0.28333333134651184, loss=3.556267261505127
train: epoch 30, loss 0.24594780802726746, acc=0.921500027179718, loss=0.24594780802726746
test: epoch 30, loss 3.3557522296905518, acc=0.3222222328186035, loss=3.3557522296905518
train: epoch 31, loss 0.2388949990272522, acc=0.9240555763244629, loss=0.2388949990272522
test: epoch 31, loss 3.0281858444213867, acc=0.3583333194255829, loss=3.0281858444213867
train: epoch 32, loss 0.23337356746196747, acc=0.9258888959884644, loss=0.23337356746196747
test: epoch 32, loss 3.083327293395996, acc=0.34166666865348816, loss=3.083327293395996
train: epoch 33, loss 0.21661314368247986, acc=0.9306111335754395, loss=0.21661314368247986
test: epoch 33, loss 3.2774956226348877, acc=0.31111112236976624, loss=3.2774956226348877
train: epoch 34, loss 0.2203834354877472, acc=0.9302777647972107, loss=0.2203834354877472
test: epoch 34, loss 3.1262197494506836, acc=0.3222222328186035, loss=3.1262197494506836
train: epoch 35, loss 0.20108194649219513, acc=0.9388889074325562, loss=0.20108194649219513
test: epoch 35, loss 3.07369327545166, acc=0.3194444477558136, loss=3.07369327545166
train: epoch 36, loss 0.2145961970090866, acc=0.9341111183166504, loss=0.2145961970090866
test: epoch 36, loss 2.6255297660827637, acc=0.36666667461395264, loss=2.6255297660827637
train: epoch 37, loss 0.20239922404289246, acc=0.9345555305480957, loss=0.20239922404289246
test: epoch 37, loss 2.9335107803344727, acc=0.3444444537162781, loss=2.9335107803344727
train: epoch 38, loss 0.18445494771003723, acc=0.9441111087799072, loss=0.18445494771003723
test: epoch 38, loss 2.7648918628692627, acc=0.3638888895511627, loss=2.7648918628692627
train: epoch 39, loss 0.1819460242986679, acc=0.9447222352027893, loss=0.1819460242986679
test: epoch 39, loss 3.135105848312378, acc=0.3499999940395355, loss=3.135105848312378
train: epoch 40, loss 0.18211115896701813, acc=0.9458333253860474, loss=0.18211115896701813
test: epoch 40, loss 3.070639133453369, acc=0.3361110985279083, loss=3.070639133453369
train: epoch 41, loss 0.1809059977531433, acc=0.9461666941642761, loss=0.1809059977531433
test: epoch 41, loss 3.1574599742889404, acc=0.34166666865348816, loss=3.1574599742889404
train: epoch 42, loss 0.17316578328609467, acc=0.9482222199440002, loss=0.17316578328609467
test: epoch 42, loss 3.0625181198120117, acc=0.3444444537162781, loss=3.0625181198120117
train: epoch 43, loss 0.17059682309627533, acc=0.9501110911369324, loss=0.17059682309627533
test: epoch 43, loss 2.9634575843811035, acc=0.3027777671813965, loss=2.9634575843811035
train: epoch 44, loss 0.1701202094554901, acc=0.9495555758476257, loss=0.1701202094554901
test: epoch 44, loss 2.599350690841675, acc=0.3361110985279083, loss=2.599350690841675
train: epoch 45, loss 0.17677760124206543, acc=0.9478333592414856, loss=0.17677760124206543
test: epoch 45, loss 3.1144931316375732, acc=0.32777777314186096, loss=3.1144931316375732
train: epoch 46, loss 0.15868224203586578, acc=0.9537777900695801, loss=0.15868224203586578
test: epoch 46, loss 2.886823892593384, acc=0.3583333194255829, loss=2.886823892593384
train: epoch 47, loss 0.14832189679145813, acc=0.9573333263397217, loss=0.14832189679145813
test: epoch 47, loss 2.856213331222534, acc=0.3444444537162781, loss=2.856213331222534
train: epoch 48, loss 0.15276627242565155, acc=0.9554444551467896, loss=0.15276627242565155
test: epoch 48, loss 2.877673387527466, acc=0.3638888895511627, loss=2.877673387527466
train: epoch 49, loss 0.14882762730121613, acc=0.9558888673782349, loss=0.14882762730121613
test: epoch 49, loss 2.7804763317108154, acc=0.38333332538604736, loss=2.7804763317108154
train: epoch 50, loss 0.1544508934020996, acc=0.9567777514457703, loss=0.1544508934020996
test: epoch 50, loss 2.6836557388305664, acc=0.375, loss=2.6836557388305664
train: epoch 51, loss 0.14302366971969604, acc=0.9586666822433472, loss=0.14302366971969604
test: epoch 51, loss 2.7244184017181396, acc=0.3444444537162781, loss=2.7244184017181396
train: epoch 52, loss 0.13443142175674438, acc=0.961555540561676, loss=0.13443142175674438
test: epoch 52, loss 2.7932636737823486, acc=0.35555556416511536, loss=2.7932636737823486
train: epoch 53, loss 0.13700073957443237, acc=0.9626666903495789, loss=0.13700073957443237
test: epoch 53, loss 2.7458713054656982, acc=0.3916666805744171, loss=2.7458713054656982
train: epoch 54, loss 0.12925994396209717, acc=0.9637777805328369, loss=0.12925994396209717
test: epoch 54, loss 3.1200525760650635, acc=0.3361110985279083, loss=3.1200525760650635
train: epoch 55, loss 0.1439039558172226, acc=0.960444450378418, loss=0.1439039558172226
test: epoch 55, loss 2.846257209777832, acc=0.3638888895511627, loss=2.846257209777832
train: epoch 56, loss 0.12422347068786621, acc=0.9638333320617676, loss=0.12422347068786621
test: epoch 56, loss 2.4255659580230713, acc=0.4027777910232544, loss=2.4255659580230713
train: epoch 57, loss 0.12138459086418152, acc=0.9644444584846497, loss=0.12138459086418152
test: epoch 57, loss 2.3992767333984375, acc=0.38333332538604736, loss=2.3992767333984375
train: epoch 58, loss 0.12103024125099182, acc=0.9629444479942322, loss=0.12103024125099182
test: epoch 58, loss 2.902740478515625, acc=0.3638888895511627, loss=2.902740478515625
train: epoch 59, loss 0.12212017178535461, acc=0.964722216129303, loss=0.12212017178535461
test: epoch 59, loss 2.364577531814575, acc=0.38333332538604736, loss=2.364577531814575
train: epoch 60, loss 0.11754909157752991, acc=0.9667778015136719, loss=0.11754909157752991
test: epoch 60, loss 2.4687795639038086, acc=0.375, loss=2.4687795639038086
train: epoch 61, loss 0.12102147191762924, acc=0.9651666879653931, loss=0.12102147191762924
test: epoch 61, loss 2.613673210144043, acc=0.375, loss=2.613673210144043
train: epoch 62, loss 0.11747130751609802, acc=0.9670000076293945, loss=0.11747130751609802
test: epoch 62, loss 2.7174293994903564, acc=0.38333332538604736, loss=2.7174293994903564
train: epoch 63, loss 0.11577822268009186, acc=0.9689444303512573, loss=0.11577822268009186
test: epoch 63, loss 2.565019369125366, acc=0.38055557012557983, loss=2.565019369125366
train: epoch 64, loss 0.11316545307636261, acc=0.9679444432258606, loss=0.11316545307636261
test: epoch 64, loss 2.433824300765991, acc=0.3888888955116272, loss=2.433824300765991
train: epoch 65, loss 0.10234494507312775, acc=0.9700555801391602, loss=0.10234494507312775
test: epoch 65, loss 2.638662815093994, acc=0.38055557012557983, loss=2.638662815093994
train: epoch 66, loss 0.10776498913764954, acc=0.9687222242355347, loss=0.10776498913764954
test: epoch 66, loss 2.3261258602142334, acc=0.4138889014720917, loss=2.3261258602142334
train: epoch 67, loss 0.10326094925403595, acc=0.9718888998031616, loss=0.10326094925403595
test: epoch 67, loss 2.3227343559265137, acc=0.41111111640930176, loss=2.3227343559265137
train: epoch 68, loss 0.10051531344652176, acc=0.9719444513320923, loss=0.10051531344652176
test: epoch 68, loss 2.2924270629882812, acc=0.36944442987442017, loss=2.2924270629882812
train: epoch 69, loss 0.09534180164337158, acc=0.9716110825538635, loss=0.09534180164337158
test: epoch 69, loss 2.2365169525146484, acc=0.36666667461395264, loss=2.2365169525146484
train: epoch 70, loss 0.09921654313802719, acc=0.971666693687439, loss=0.09921654313802719
test: epoch 70, loss 2.371452808380127, acc=0.39444443583488464, loss=2.371452808380127
train: epoch 71, loss 0.09101176261901855, acc=0.9748333096504211, loss=0.09101176261901855
test: epoch 71, loss 2.3054685592651367, acc=0.3777777850627899, loss=2.3054685592651367
train: epoch 72, loss 0.10117936879396439, acc=0.9720555543899536, loss=0.10117936879396439
test: epoch 72, loss 2.313009023666382, acc=0.39444443583488464, loss=2.313009023666382
train: epoch 73, loss 0.0952557772397995, acc=0.9732221961021423, loss=0.0952557772397995
test: epoch 73, loss 2.161482810974121, acc=0.4138889014720917, loss=2.161482810974121
train: epoch 74, loss 0.08882790058851242, acc=0.9745000004768372, loss=0.08882790058851242
test: epoch 74, loss 2.5681827068328857, acc=0.40833333134651184, loss=2.5681827068328857
train: epoch 75, loss 0.08950073271989822, acc=0.9742222428321838, loss=0.08950073271989822
test: epoch 75, loss 2.2790589332580566, acc=0.3638888895511627, loss=2.2790589332580566
train: epoch 76, loss 0.0959775298833847, acc=0.9733333587646484, loss=0.0959775298833847
test: epoch 76, loss 2.1109488010406494, acc=0.4305555522441864, loss=2.1109488010406494
train: epoch 77, loss 0.09475549310445786, acc=0.9735000133514404, loss=0.09475549310445786
test: epoch 77, loss 2.437556743621826, acc=0.3861111104488373, loss=2.437556743621826
train: epoch 78, loss 0.08967456221580505, acc=0.9746111035346985, loss=0.08967456221580505
test: epoch 78, loss 2.3812575340270996, acc=0.38055557012557983, loss=2.3812575340270996
train: epoch 79, loss 0.08922073990106583, acc=0.9767777919769287, loss=0.08922073990106583
test: epoch 79, loss 2.369211435317993, acc=0.4000000059604645, loss=2.369211435317993
train: epoch 80, loss 0.09703243523836136, acc=0.9744444489479065, loss=0.09703243523836136
test: epoch 80, loss 2.5405032634735107, acc=0.38333332538604736, loss=2.5405032634735107
train: epoch 81, loss 0.10145509988069534, acc=0.972944438457489, loss=0.10145509988069534
test: epoch 81, loss 2.3602538108825684, acc=0.3638888895511627, loss=2.3602538108825684
train: epoch 82, loss 0.08699880540370941, acc=0.9781110882759094, loss=0.08699880540370941
test: epoch 82, loss 2.1264243125915527, acc=0.38333332538604736, loss=2.1264243125915527
train: epoch 83, loss 0.07681777328252792, acc=0.9771111011505127, loss=0.07681777328252792
test: epoch 83, loss 2.6138463020324707, acc=0.3888888955116272, loss=2.6138463020324707
train: epoch 84, loss 0.07579459249973297, acc=0.9794999957084656, loss=0.07579459249973297
test: epoch 84, loss 2.5781166553497314, acc=0.42222222685813904, loss=2.5781166553497314
train: epoch 85, loss 0.08340996503829956, acc=0.9771666526794434, loss=0.08340996503829956
test: epoch 85, loss 2.524158239364624, acc=0.4055555462837219, loss=2.524158239364624
train: epoch 86, loss 0.09123020619153976, acc=0.9779999852180481, loss=0.09123020619153976
test: epoch 86, loss 2.1042871475219727, acc=0.39722222089767456, loss=2.1042871475219727
train: epoch 87, loss 0.06913228332996368, acc=0.9810555577278137, loss=0.06913228332996368
test: epoch 87, loss 1.8425873517990112, acc=0.46388888359069824, loss=1.8425873517990112
train: epoch 88, loss 0.06865769624710083, acc=0.981333315372467, loss=0.06865769624710083
test: epoch 88, loss 1.9740102291107178, acc=0.45277777314186096, loss=1.9740102291107178
train: epoch 89, loss 0.06935298442840576, acc=0.9802777767181396, loss=0.06935298442840576
test: epoch 89, loss 1.9547069072723389, acc=0.44999998807907104, loss=1.9547069072723389
train: epoch 90, loss 0.08150158822536469, acc=0.9783333539962769, loss=0.08150158822536469
test: epoch 90, loss 2.494642496109009, acc=0.39722222089767456, loss=2.494642496109009
train: epoch 91, loss 0.07554705440998077, acc=0.9786666631698608, loss=0.07554705440998077
test: epoch 91, loss 2.2457244396209717, acc=0.4166666567325592, loss=2.2457244396209717
train: epoch 92, loss 0.062106240540742874, acc=0.9818333387374878, loss=0.062106240540742874
test: epoch 92, loss 1.9051862955093384, acc=0.46388888359069824, loss=1.9051862955093384
train: epoch 93, loss 0.07973059266805649, acc=0.9789444208145142, loss=0.07973059266805649
test: epoch 93, loss 2.2319986820220947, acc=0.39444443583488464, loss=2.2319986820220947
train: epoch 94, loss 0.060450486838817596, acc=0.9822221994400024, loss=0.060450486838817596
test: epoch 94, loss 2.3830437660217285, acc=0.4555555582046509, loss=2.3830437660217285
train: epoch 95, loss 0.06139833480119705, acc=0.9835555553436279, loss=0.06139833480119705
test: epoch 95, loss 2.1055872440338135, acc=0.4555555582046509, loss=2.1055872440338135
train: epoch 96, loss 0.07829319685697556, acc=0.9806110858917236, loss=0.07829319685697556
test: epoch 96, loss 2.008887767791748, acc=0.46388888359069824, loss=2.008887767791748
train: epoch 97, loss 0.06229841336607933, acc=0.9819444417953491, loss=0.06229841336607933
test: epoch 97, loss 2.109069585800171, acc=0.4749999940395355, loss=2.109069585800171
train: epoch 98, loss 0.06813085824251175, acc=0.9812222123146057, loss=0.06813085824251175
test: epoch 98, loss 2.2323544025421143, acc=0.4444444477558136, loss=2.2323544025421143
train: epoch 99, loss 0.0635027214884758, acc=0.9830555319786072, loss=0.0635027214884758
test: epoch 99, loss 2.24745512008667, acc=0.42222222685813904, loss=2.24745512008667
train: epoch 100, loss 0.060127802193164825, acc=0.9842777848243713, loss=0.060127802193164825
test: epoch 100, loss 2.0840086936950684, acc=0.41111111640930176, loss=2.0840086936950684
train: epoch 101, loss 0.0644795149564743, acc=0.9823333621025085, loss=0.0644795149564743
test: epoch 101, loss 2.081052780151367, acc=0.45277777314186096, loss=2.081052780151367
train: epoch 102, loss 0.05609538033604622, acc=0.984666645526886, loss=0.05609538033604622
test: epoch 102, loss 2.0503456592559814, acc=0.45277777314186096, loss=2.0503456592559814
train: epoch 103, loss 0.06234697252511978, acc=0.9837777614593506, loss=0.06234697252511978
test: epoch 103, loss 2.1337647438049316, acc=0.4166666567325592, loss=2.1337647438049316
train: epoch 104, loss 0.06280864775180817, acc=0.9843888878822327, loss=0.06280864775180817
test: epoch 104, loss 2.1758244037628174, acc=0.43888887763023376, loss=2.1758244037628174
train: epoch 105, loss 0.06189370155334473, acc=0.9852222204208374, loss=0.06189370155334473
test: epoch 105, loss 1.9793622493743896, acc=0.43888887763023376, loss=1.9793622493743896
train: epoch 106, loss 0.06152719259262085, acc=0.984333336353302, loss=0.06152719259262085
test: epoch 106, loss 2.2997212409973145, acc=0.4583333432674408, loss=2.2997212409973145
train: epoch 107, loss 0.054368484765291214, acc=0.9847777485847473, loss=0.054368484765291214
test: epoch 107, loss 1.9400709867477417, acc=0.4888888895511627, loss=1.9400709867477417
train: epoch 108, loss 0.05509083718061447, acc=0.9856666922569275, loss=0.05509083718061447
test: epoch 108, loss 1.9197932481765747, acc=0.46666666865348816, loss=1.9197932481765747
train: epoch 109, loss 0.058566879481077194, acc=0.9845555424690247, loss=0.058566879481077194
test: epoch 109, loss 2.0977206230163574, acc=0.4277777671813965, loss=2.0977206230163574
train: epoch 110, loss 0.06063542887568474, acc=0.9836666584014893, loss=0.06063542887568474
test: epoch 110, loss 2.312817096710205, acc=0.4472222328186035, loss=2.312817096710205
train: epoch 111, loss 0.05779256299138069, acc=0.9836666584014893, loss=0.05779256299138069
test: epoch 111, loss 2.0835211277008057, acc=0.4444444477558136, loss=2.0835211277008057
train: epoch 112, loss 0.051940806210041046, acc=0.9862777590751648, loss=0.051940806210041046
test: epoch 112, loss 2.258608818054199, acc=0.4749999940395355, loss=2.258608818054199
train: epoch 113, loss 0.054951734840869904, acc=0.9863333106040955, loss=0.054951734840869904
test: epoch 113, loss 1.9026421308517456, acc=0.4722222089767456, loss=1.9026421308517456
train: epoch 114, loss 0.06456055492162704, acc=0.984666645526886, loss=0.06456055492162704
test: epoch 114, loss 2.1418142318725586, acc=0.46388888359069824, loss=2.1418142318725586
train: epoch 115, loss 0.04358801245689392, acc=0.987666666507721, loss=0.04358801245689392
test: epoch 115, loss 1.9446651935577393, acc=0.4555555582046509, loss=1.9446651935577393
train: epoch 116, loss 0.05135328322649002, acc=0.9871666431427002, loss=0.05135328322649002
test: epoch 116, loss 2.0609042644500732, acc=0.49166667461395264, loss=2.0609042644500732
train: epoch 117, loss 0.04198480397462845, acc=0.988111138343811, loss=0.04198480397462845
test: epoch 117, loss 2.253161907196045, acc=0.43611112236976624, loss=2.253161907196045
train: epoch 118, loss 0.05502985790371895, acc=0.9853888750076294, loss=0.05502985790371895
test: epoch 118, loss 2.2435131072998047, acc=0.49166667461395264, loss=2.2435131072998047
train: epoch 119, loss 0.04827307537198067, acc=0.9871666431427002, loss=0.04827307537198067
test: epoch 119, loss 2.3389322757720947, acc=0.4555555582046509, loss=2.3389322757720947
train: epoch 120, loss 0.05430698022246361, acc=0.9854999780654907, loss=0.05430698022246361
test: epoch 120, loss 2.0743093490600586, acc=0.46666666865348816, loss=2.0743093490600586
train: epoch 121, loss 0.05540057271718979, acc=0.9863888621330261, loss=0.05540057271718979
test: epoch 121, loss 2.0815391540527344, acc=0.5, loss=2.0815391540527344
train: epoch 122, loss 0.05196268856525421, acc=0.9851666688919067, loss=0.05196268856525421
test: epoch 122, loss 2.4706196784973145, acc=0.4611110985279083, loss=2.4706196784973145
train: epoch 123, loss 0.044808901846408844, acc=0.9872221946716309, loss=0.044808901846408844
test: epoch 123, loss 2.2210922241210938, acc=0.44999998807907104, loss=2.2210922241210938
train: epoch 124, loss 0.048078592866659164, acc=0.9872778058052063, loss=0.048078592866659164
test: epoch 124, loss 2.231335401535034, acc=0.4722222089767456, loss=2.231335401535034
train: epoch 125, loss 0.04949105158448219, acc=0.9880555272102356, loss=0.04949105158448219
test: epoch 125, loss 1.9346325397491455, acc=0.49166667461395264, loss=1.9346325397491455
train: epoch 126, loss 0.04495949670672417, acc=0.9890555739402771, loss=0.04495949670672417
test: epoch 126, loss 1.799038052558899, acc=0.5138888955116272, loss=1.799038052558899
train: epoch 127, loss 0.04944729804992676, acc=0.9883888959884644, loss=0.04944729804992676
test: epoch 127, loss 2.2763805389404297, acc=0.49166667461395264, loss=2.2763805389404297
train: epoch 128, loss 0.044062770903110504, acc=0.9878888726234436, loss=0.044062770903110504
test: epoch 128, loss 2.082993507385254, acc=0.4972222149372101, loss=2.082993507385254
train: epoch 129, loss 0.04809839278459549, acc=0.9885555505752563, loss=0.04809839278459549
test: epoch 129, loss 2.288947582244873, acc=0.4694444537162781, loss=2.288947582244873
train: epoch 130, loss 0.042826976627111435, acc=0.9895555377006531, loss=0.042826976627111435
test: epoch 130, loss 2.162722110748291, acc=0.4694444537162781, loss=2.162722110748291
train: epoch 131, loss 0.04481714963912964, acc=0.9890555739402771, loss=0.04481714963912964
test: epoch 131, loss 2.3493075370788574, acc=0.4888888895511627, loss=2.3493075370788574
train: epoch 132, loss 0.04959256947040558, acc=0.9879444241523743, loss=0.04959256947040558
test: epoch 132, loss 1.9176161289215088, acc=0.4583333432674408, loss=1.9176161289215088
train: epoch 133, loss 0.048195064067840576, acc=0.988277792930603, loss=0.048195064067840576
test: epoch 133, loss 2.3194429874420166, acc=0.46388888359069824, loss=2.3194429874420166
train: epoch 134, loss 0.05234814062714577, acc=0.988111138343811, loss=0.05234814062714577
test: epoch 134, loss 2.3766367435455322, acc=0.46388888359069824, loss=2.3766367435455322
train: epoch 135, loss 0.03960554301738739, acc=0.9898889064788818, loss=0.03960554301738739
test: epoch 135, loss 2.183178424835205, acc=0.44999998807907104, loss=2.183178424835205
train: epoch 136, loss 0.0476839505136013, acc=0.9878333210945129, loss=0.0476839505136013
test: epoch 136, loss 2.232452392578125, acc=0.49166667461395264, loss=2.232452392578125
train: epoch 137, loss 0.04789450019598007, acc=0.9883333444595337, loss=0.04789450019598007
test: epoch 137, loss 2.3295540809631348, acc=0.45277777314186096, loss=2.3295540809631348
train: epoch 138, loss 0.046985723078250885, acc=0.988777756690979, loss=0.046985723078250885
test: epoch 138, loss 2.104144811630249, acc=0.5027777552604675, loss=2.104144811630249
train: epoch 139, loss 0.035955432802438736, acc=0.9898889064788818, loss=0.035955432802438736
test: epoch 139, loss 2.2819840908050537, acc=0.4749999940395355, loss=2.2819840908050537
train: epoch 140, loss 0.036773327738046646, acc=0.9898333549499512, loss=0.036773327738046646
test: epoch 140, loss 2.2888598442077637, acc=0.4888888895511627, loss=2.2888598442077637
train: epoch 141, loss 0.03690362349152565, acc=0.9906666874885559, loss=0.03690362349152565
test: epoch 141, loss 2.1753339767456055, acc=0.46666666865348816, loss=2.1753339767456055
train: epoch 142, loss 0.03807787969708443, acc=0.9902777671813965, loss=0.03807787969708443
test: epoch 142, loss 2.315512180328369, acc=0.49166667461395264, loss=2.315512180328369
train: epoch 143, loss 0.03940607234835625, acc=0.9893333315849304, loss=0.03940607234835625
test: epoch 143, loss 2.080395221710205, acc=0.4972222149372101, loss=2.080395221710205
train: epoch 144, loss 0.03798898309469223, acc=0.9893888831138611, loss=0.03798898309469223
test: epoch 144, loss 2.1792571544647217, acc=0.4833333194255829, loss=2.1792571544647217
train: epoch 145, loss 0.03791461139917374, acc=0.9913889169692993, loss=0.03791461139917374
test: epoch 145, loss 2.379739999771118, acc=0.4888888895511627, loss=2.379739999771118
train: epoch 146, loss 0.039574768394231796, acc=0.9896110892295837, loss=0.039574768394231796
test: epoch 146, loss 2.2777798175811768, acc=0.47777777910232544, loss=2.2777798175811768
train: epoch 147, loss 0.03982546925544739, acc=0.9896110892295837, loss=0.03982546925544739
test: epoch 147, loss 2.3274614810943604, acc=0.4722222089767456, loss=2.3274614810943604
train: epoch 148, loss 0.03891659900546074, acc=0.9902777671813965, loss=0.03891659900546074
test: epoch 148, loss 2.325829029083252, acc=0.4888888895511627, loss=2.325829029083252
train: epoch 149, loss 0.036412592977285385, acc=0.9906666874885559, loss=0.036412592977285385
test: epoch 149, loss 2.118581771850586, acc=0.5333333611488342, loss=2.118581771850586
train: epoch 150, loss 0.035851992666721344, acc=0.9913333058357239, loss=0.035851992666721344
test: epoch 150, loss 2.174920082092285, acc=0.4888888895511627, loss=2.174920082092285
