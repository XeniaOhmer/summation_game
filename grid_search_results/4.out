# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1", "--temp_decay=1", "--one_hot=false", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1753727700, receiver_embed_dim=32, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.262465238571167, acc=0.05627777799963951, loss=3.262465238571167
test: epoch 1, loss 2.857455253601074, acc=0.11666666716337204, loss=2.857455253601074
train: epoch 2, loss 2.419506072998047, acc=0.14472222328186035, loss=2.419506072998047
test: epoch 2, loss 2.5604894161224365, acc=0.14722222089767456, loss=2.5604894161224365
train: epoch 3, loss 2.1287713050842285, acc=0.19505555927753448, loss=2.1287713050842285
test: epoch 3, loss 2.3862338066101074, acc=0.13333334028720856, loss=2.3862338066101074
train: epoch 4, loss 1.982262372970581, acc=0.22388888895511627, loss=1.982262372970581
test: epoch 4, loss 2.3589959144592285, acc=0.1666666716337204, loss=2.3589959144592285
train: epoch 5, loss 1.895232081413269, acc=0.24122221767902374, loss=1.895232081413269
test: epoch 5, loss 2.5013980865478516, acc=0.16388888657093048, loss=2.5013980865478516
train: epoch 6, loss 1.791237235069275, acc=0.2693333327770233, loss=1.791237235069275
test: epoch 6, loss 2.2539196014404297, acc=0.16111111640930176, loss=2.2539196014404297
train: epoch 7, loss 1.719107985496521, acc=0.2857222259044647, loss=1.719107985496521
test: epoch 7, loss 2.6343820095062256, acc=0.1805555522441864, loss=2.6343820095062256
train: epoch 8, loss 1.6649771928787231, acc=0.29750001430511475, loss=1.6649771928787231
test: epoch 8, loss 2.217771530151367, acc=0.18888889253139496, loss=2.217771530151367
train: epoch 9, loss 1.6145589351654053, acc=0.3169444501399994, loss=1.6145589351654053
test: epoch 9, loss 2.0869140625, acc=0.21666666865348816, loss=2.0869140625
train: epoch 10, loss 1.5300698280334473, acc=0.3862222135066986, loss=1.5300698280334473
test: epoch 10, loss 2.200881242752075, acc=0.21666666865348816, loss=2.200881242752075
train: epoch 11, loss 1.3512600660324097, acc=0.4625000059604645, loss=1.3512600660324097
test: epoch 11, loss 1.8911361694335938, acc=0.26944443583488464, loss=1.8911361694335938
train: epoch 12, loss 1.223793625831604, acc=0.5034444332122803, loss=1.223793625831604
test: epoch 12, loss 1.8398311138153076, acc=0.27222222089767456, loss=1.8398311138153076
train: epoch 13, loss 1.1704579591751099, acc=0.5193333625793457, loss=1.1704579591751099
test: epoch 13, loss 1.6337782144546509, acc=0.3083333373069763, loss=1.6337782144546509
train: epoch 14, loss 1.1164878606796265, acc=0.5332777500152588, loss=1.1164878606796265
test: epoch 14, loss 1.6333436965942383, acc=0.3222222328186035, loss=1.6333436965942383
train: epoch 15, loss 1.083656668663025, acc=0.5520555377006531, loss=1.083656668663025
test: epoch 15, loss 1.775124430656433, acc=0.2666666805744171, loss=1.775124430656433
train: epoch 16, loss 1.045058012008667, acc=0.5634999871253967, loss=1.045058012008667
test: epoch 16, loss 1.786784291267395, acc=0.31388887763023376, loss=1.786784291267395
train: epoch 17, loss 1.0146501064300537, acc=0.5753333568572998, loss=1.0146501064300537
test: epoch 17, loss 1.7578442096710205, acc=0.31111112236976624, loss=1.7578442096710205
train: epoch 18, loss 0.9779127836227417, acc=0.596833348274231, loss=0.9779127836227417
test: epoch 18, loss 1.6437486410140991, acc=0.31388887763023376, loss=1.6437486410140991
train: epoch 19, loss 0.9209057092666626, acc=0.6192222237586975, loss=0.9209057092666626
test: epoch 19, loss 1.7257360219955444, acc=0.31111112236976624, loss=1.7257360219955444
train: epoch 20, loss 0.8907748460769653, acc=0.6284999847412109, loss=0.8907748460769653
test: epoch 20, loss 1.6964824199676514, acc=0.3444444537162781, loss=1.6964824199676514
train: epoch 21, loss 0.8457227945327759, acc=0.6431666612625122, loss=0.8457227945327759
test: epoch 21, loss 1.7803993225097656, acc=0.3222222328186035, loss=1.7803993225097656
train: epoch 22, loss 0.8409534692764282, acc=0.6421111226081848, loss=0.8409534692764282
test: epoch 22, loss 1.7790567874908447, acc=0.3305555582046509, loss=1.7790567874908447
train: epoch 23, loss 0.8106293678283691, acc=0.6598888635635376, loss=0.8106293678283691
test: epoch 23, loss 1.6669998168945312, acc=0.3333333432674408, loss=1.6669998168945312
train: epoch 24, loss 0.788144588470459, acc=0.6683333516120911, loss=0.788144588470459
test: epoch 24, loss 1.6943897008895874, acc=0.34166666865348816, loss=1.6943897008895874
train: epoch 25, loss 0.7670115828514099, acc=0.675000011920929, loss=0.7670115828514099
test: epoch 25, loss 1.7041734457015991, acc=0.35277777910232544, loss=1.7041734457015991
train: epoch 26, loss 0.7275939583778381, acc=0.6936666369438171, loss=0.7275939583778381
test: epoch 26, loss 1.5234073400497437, acc=0.4305555522441864, loss=1.5234073400497437
train: epoch 27, loss 0.6955739855766296, acc=0.7043889164924622, loss=0.6955739855766296
test: epoch 27, loss 1.4996898174285889, acc=0.3861111104488373, loss=1.4996898174285889
train: epoch 28, loss 0.6899519562721252, acc=0.7047222256660461, loss=0.6899519562721252
test: epoch 28, loss 1.404969573020935, acc=0.4444444477558136, loss=1.404969573020935
train: epoch 29, loss 0.646513819694519, acc=0.7239999771118164, loss=0.646513819694519
test: epoch 29, loss 1.8439146280288696, acc=0.3638888895511627, loss=1.8439146280288696
train: epoch 30, loss 0.6417685151100159, acc=0.7210555672645569, loss=0.6417685151100159
test: epoch 30, loss 1.477906346321106, acc=0.4194444417953491, loss=1.477906346321106
train: epoch 31, loss 0.6419997215270996, acc=0.7291666865348816, loss=0.6419997215270996
test: epoch 31, loss 1.4820990562438965, acc=0.4277777671813965, loss=1.4820990562438965
train: epoch 32, loss 0.6388275623321533, acc=0.7248333096504211, loss=0.6388275623321533
test: epoch 32, loss 1.6960581541061401, acc=0.40833333134651184, loss=1.6960581541061401
train: epoch 33, loss 0.6159315705299377, acc=0.7343888878822327, loss=0.6159315705299377
test: epoch 33, loss 1.637853741645813, acc=0.4472222328186035, loss=1.637853741645813
train: epoch 34, loss 0.6198329925537109, acc=0.7280555367469788, loss=0.6198329925537109
test: epoch 34, loss 1.6200165748596191, acc=0.4055555462837219, loss=1.6200165748596191
train: epoch 35, loss 0.5906482338905334, acc=0.7394999861717224, loss=0.5906482338905334
test: epoch 35, loss 1.7224889993667603, acc=0.4444444477558136, loss=1.7224889993667603
train: epoch 36, loss 0.5947113037109375, acc=0.7347777485847473, loss=0.5947113037109375
test: epoch 36, loss 1.5461524724960327, acc=0.4611110985279083, loss=1.5461524724960327
train: epoch 37, loss 0.584528923034668, acc=0.7413889169692993, loss=0.584528923034668
test: epoch 37, loss 1.5093140602111816, acc=0.4555555582046509, loss=1.5093140602111816
train: epoch 38, loss 0.5848344564437866, acc=0.7402777671813965, loss=0.5848344564437866
test: epoch 38, loss 1.4736210107803345, acc=0.4333333373069763, loss=1.4736210107803345
train: epoch 39, loss 0.5587090849876404, acc=0.7468888759613037, loss=0.5587090849876404
test: epoch 39, loss 1.5078047513961792, acc=0.41111111640930176, loss=1.5078047513961792
train: epoch 40, loss 0.5627530813217163, acc=0.749666690826416, loss=0.5627530813217163
test: epoch 40, loss 1.730663776397705, acc=0.46666666865348816, loss=1.730663776397705
train: epoch 41, loss 0.5585062503814697, acc=0.7517222166061401, loss=0.5585062503814697
test: epoch 41, loss 1.8090322017669678, acc=0.4277777671813965, loss=1.8090322017669678
train: epoch 42, loss 0.5486128330230713, acc=0.7587222456932068, loss=0.5486128330230713
test: epoch 42, loss 1.5866165161132812, acc=0.4166666567325592, loss=1.5866165161132812
train: epoch 43, loss 0.5299345850944519, acc=0.7663888931274414, loss=0.5299345850944519
test: epoch 43, loss 1.5469247102737427, acc=0.43611112236976624, loss=1.5469247102737427
train: epoch 44, loss 0.5302581191062927, acc=0.761388897895813, loss=0.5302581191062927
test: epoch 44, loss 1.8634380102157593, acc=0.4444444477558136, loss=1.8634380102157593
train: epoch 45, loss 0.5311112403869629, acc=0.7668889164924622, loss=0.5311112403869629
test: epoch 45, loss 1.8999006748199463, acc=0.3777777850627899, loss=1.8999006748199463
train: epoch 46, loss 0.5088203549385071, acc=0.7714999914169312, loss=0.5088203549385071
test: epoch 46, loss 1.559989333152771, acc=0.4694444537162781, loss=1.559989333152771
train: epoch 47, loss 0.5045264363288879, acc=0.7764444351196289, loss=0.5045264363288879
test: epoch 47, loss 1.7154005765914917, acc=0.4583333432674408, loss=1.7154005765914917
train: epoch 48, loss 0.5125240087509155, acc=0.7735000252723694, loss=0.5125240087509155
test: epoch 48, loss 1.758463740348816, acc=0.42500001192092896, loss=1.758463740348816
train: epoch 49, loss 0.49355554580688477, acc=0.7737777829170227, loss=0.49355554580688477
test: epoch 49, loss 1.625353217124939, acc=0.4416666626930237, loss=1.625353217124939
train: epoch 50, loss 0.49912986159324646, acc=0.7742778062820435, loss=0.49912986159324646
test: epoch 50, loss 1.5051100254058838, acc=0.4611110985279083, loss=1.5051100254058838
train: epoch 51, loss 0.47436296939849854, acc=0.7832221984863281, loss=0.47436296939849854
test: epoch 51, loss 1.540669322013855, acc=0.4749999940395355, loss=1.540669322013855
train: epoch 52, loss 0.49804362654685974, acc=0.7772777676582336, loss=0.49804362654685974
test: epoch 52, loss 1.617235541343689, acc=0.4333333373069763, loss=1.617235541343689
train: epoch 53, loss 0.4767754375934601, acc=0.7834444642066956, loss=0.4767754375934601
test: epoch 53, loss 1.4994386434555054, acc=0.47777777910232544, loss=1.4994386434555054
train: epoch 54, loss 0.478257954120636, acc=0.784500002861023, loss=0.478257954120636
test: epoch 54, loss 1.8715683221817017, acc=0.4416666626930237, loss=1.8715683221817017
train: epoch 55, loss 0.4823266565799713, acc=0.7861666679382324, loss=0.4823266565799713
test: epoch 55, loss 1.5254918336868286, acc=0.4472222328186035, loss=1.5254918336868286
train: epoch 56, loss 0.46120762825012207, acc=0.788611114025116, loss=0.46120762825012207
test: epoch 56, loss 1.7280114889144897, acc=0.43888887763023376, loss=1.7280114889144897
train: epoch 57, loss 0.46258264780044556, acc=0.7913888692855835, loss=0.46258264780044556
test: epoch 57, loss 1.5367883443832397, acc=0.47777777910232544, loss=1.5367883443832397
train: epoch 58, loss 0.45661887526512146, acc=0.7924444675445557, loss=0.45661887526512146
test: epoch 58, loss 1.580230951309204, acc=0.48055556416511536, loss=1.580230951309204
train: epoch 59, loss 0.4621509909629822, acc=0.7910555601119995, loss=0.4621509909629822
test: epoch 59, loss 1.7718350887298584, acc=0.4472222328186035, loss=1.7718350887298584
train: epoch 60, loss 0.4508945941925049, acc=0.7919999957084656, loss=0.4508945941925049
test: epoch 60, loss 1.887964129447937, acc=0.46388888359069824, loss=1.887964129447937
train: epoch 61, loss 0.44072017073631287, acc=0.7952222228050232, loss=0.44072017073631287
test: epoch 61, loss 1.8055888414382935, acc=0.4472222328186035, loss=1.8055888414382935
train: epoch 62, loss 0.4435104727745056, acc=0.7964444160461426, loss=0.4435104727745056
test: epoch 62, loss 1.4403568506240845, acc=0.4749999940395355, loss=1.4403568506240845
train: epoch 63, loss 0.4365725517272949, acc=0.7981111407279968, loss=0.4365725517272949
test: epoch 63, loss 1.890089750289917, acc=0.4694444537162781, loss=1.890089750289917
train: epoch 64, loss 0.4459313750267029, acc=0.7964444160461426, loss=0.4459313750267029
test: epoch 64, loss 1.8453617095947266, acc=0.4722222089767456, loss=1.8453617095947266
train: epoch 65, loss 0.444436252117157, acc=0.7963888645172119, loss=0.444436252117157
test: epoch 65, loss 1.89277184009552, acc=0.4749999940395355, loss=1.89277184009552
train: epoch 66, loss 0.43609583377838135, acc=0.8013888597488403, loss=0.43609583377838135
test: epoch 66, loss 1.7455427646636963, acc=0.4416666626930237, loss=1.7455427646636963
train: epoch 67, loss 0.43682706356048584, acc=0.8016666769981384, loss=0.43682706356048584
test: epoch 67, loss 1.6521598100662231, acc=0.47777777910232544, loss=1.6521598100662231
train: epoch 68, loss 0.4114145040512085, acc=0.8078333139419556, loss=0.4114145040512085
test: epoch 68, loss 1.682712197303772, acc=0.46666666865348816, loss=1.682712197303772
train: epoch 69, loss 0.4363192021846771, acc=0.8034444451332092, loss=0.4363192021846771
test: epoch 69, loss 1.5855869054794312, acc=0.4694444537162781, loss=1.5855869054794312
train: epoch 70, loss 0.4366395175457001, acc=0.7987777590751648, loss=0.4366395175457001
test: epoch 70, loss 1.8851567506790161, acc=0.4305555522441864, loss=1.8851567506790161
train: epoch 71, loss 0.44239717721939087, acc=0.8009999990463257, loss=0.44239717721939087
test: epoch 71, loss 1.624131441116333, acc=0.4749999940395355, loss=1.624131441116333
train: epoch 72, loss 0.42292237281799316, acc=0.8041666746139526, loss=0.42292237281799316
test: epoch 72, loss 1.7020713090896606, acc=0.4583333432674408, loss=1.7020713090896606
train: epoch 73, loss 0.4188250005245209, acc=0.805055558681488, loss=0.4188250005245209
test: epoch 73, loss 1.9444348812103271, acc=0.4583333432674408, loss=1.9444348812103271
train: epoch 74, loss 0.4251747131347656, acc=0.8027222156524658, loss=0.4251747131347656
test: epoch 74, loss 1.8754290342330933, acc=0.47777777910232544, loss=1.8754290342330933
train: epoch 75, loss 0.4123082756996155, acc=0.808388888835907, loss=0.4123082756996155
test: epoch 75, loss 1.752821445465088, acc=0.4749999940395355, loss=1.752821445465088
train: epoch 76, loss 0.4164001941680908, acc=0.808388888835907, loss=0.4164001941680908
test: epoch 76, loss 1.9544583559036255, acc=0.47777777910232544, loss=1.9544583559036255
train: epoch 77, loss 0.42090675234794617, acc=0.8043333292007446, loss=0.42090675234794617
test: epoch 77, loss 1.7432644367218018, acc=0.46666666865348816, loss=1.7432644367218018
train: epoch 78, loss 0.4160272777080536, acc=0.808222234249115, loss=0.4160272777080536
test: epoch 78, loss 1.689181923866272, acc=0.4611110985279083, loss=1.689181923866272
train: epoch 79, loss 0.42313623428344727, acc=0.8065000176429749, loss=0.42313623428344727
test: epoch 79, loss 1.7372612953186035, acc=0.4416666626930237, loss=1.7372612953186035
train: epoch 80, loss 0.41576558351516724, acc=0.8098888993263245, loss=0.41576558351516724
test: epoch 80, loss 1.819526195526123, acc=0.45277777314186096, loss=1.819526195526123
train: epoch 81, loss 0.42299026250839233, acc=0.8049444556236267, loss=0.42299026250839233
test: epoch 81, loss 1.5964837074279785, acc=0.46666666865348816, loss=1.5964837074279785
train: epoch 82, loss 0.3959640562534332, acc=0.8125555515289307, loss=0.3959640562534332
test: epoch 82, loss 1.969609260559082, acc=0.43888887763023376, loss=1.969609260559082
train: epoch 83, loss 0.414551705121994, acc=0.8070555329322815, loss=0.414551705121994
test: epoch 83, loss 1.9103754758834839, acc=0.4555555582046509, loss=1.9103754758834839
train: epoch 84, loss 0.41482850909233093, acc=0.8079444169998169, loss=0.41482850909233093
test: epoch 84, loss 1.8293637037277222, acc=0.4749999940395355, loss=1.8293637037277222
train: epoch 85, loss 0.4061708450317383, acc=0.8097777962684631, loss=0.4061708450317383
test: epoch 85, loss 1.5435227155685425, acc=0.48055556416511536, loss=1.5435227155685425
train: epoch 86, loss 0.41709351539611816, acc=0.8073889017105103, loss=0.41709351539611816
test: epoch 86, loss 1.9314593076705933, acc=0.4722222089767456, loss=1.9314593076705933
train: epoch 87, loss 0.4236065149307251, acc=0.8078888654708862, loss=0.4236065149307251
test: epoch 87, loss 1.8654121160507202, acc=0.4722222089767456, loss=1.8654121160507202
train: epoch 88, loss 0.3973665237426758, acc=0.8136110901832581, loss=0.3973665237426758
test: epoch 88, loss 2.003221273422241, acc=0.4444444477558136, loss=2.003221273422241
train: epoch 89, loss 0.4107154905796051, acc=0.8061666488647461, loss=0.4107154905796051
test: epoch 89, loss 1.7227518558502197, acc=0.4749999940395355, loss=1.7227518558502197
train: epoch 90, loss 0.3950332999229431, acc=0.8161666393280029, loss=0.3950332999229431
test: epoch 90, loss 1.901687502861023, acc=0.4333333373069763, loss=1.901687502861023
train: epoch 91, loss 0.4040299654006958, acc=0.8116111159324646, loss=0.4040299654006958
test: epoch 91, loss 1.8642746210098267, acc=0.4722222089767456, loss=1.8642746210098267
train: epoch 92, loss 0.3993091881275177, acc=0.8138889074325562, loss=0.3993091881275177
test: epoch 92, loss 1.9145277738571167, acc=0.47777777910232544, loss=1.9145277738571167
train: epoch 93, loss 0.3989713788032532, acc=0.8129444718360901, loss=0.3989713788032532
test: epoch 93, loss 1.67006516456604, acc=0.4749999940395355, loss=1.67006516456604
train: epoch 94, loss 0.40056273341178894, acc=0.8127222061157227, loss=0.40056273341178894
test: epoch 94, loss 1.7502950429916382, acc=0.4749999940395355, loss=1.7502950429916382
train: epoch 95, loss 0.39202558994293213, acc=0.8157777786254883, loss=0.39202558994293213
test: epoch 95, loss 1.9326571226119995, acc=0.46388888359069824, loss=1.9326571226119995
train: epoch 96, loss 0.40241584181785583, acc=0.812833309173584, loss=0.40241584181785583
test: epoch 96, loss 2.0722548961639404, acc=0.46388888359069824, loss=2.0722548961639404
train: epoch 97, loss 0.40735605359077454, acc=0.8097222447395325, loss=0.40735605359077454
test: epoch 97, loss 2.2932772636413574, acc=0.43888887763023376, loss=2.2932772636413574
train: epoch 98, loss 0.3977714478969574, acc=0.8134999871253967, loss=0.3977714478969574
test: epoch 98, loss 1.7067962884902954, acc=0.47777777910232544, loss=1.7067962884902954
train: epoch 99, loss 0.3991662859916687, acc=0.8118333220481873, loss=0.3991662859916687
test: epoch 99, loss 2.104069948196411, acc=0.45277777314186096, loss=2.104069948196411
train: epoch 100, loss 0.40783926844596863, acc=0.8077222108840942, loss=0.40783926844596863
test: epoch 100, loss 1.884583592414856, acc=0.4722222089767456, loss=1.884583592414856
train: epoch 101, loss 0.3977224826812744, acc=0.8149999976158142, loss=0.3977224826812744
test: epoch 101, loss 1.5952564477920532, acc=0.4749999940395355, loss=1.5952564477920532
train: epoch 102, loss 0.4020930230617523, acc=0.8109999895095825, loss=0.4020930230617523
test: epoch 102, loss 1.8483049869537354, acc=0.4749999940395355, loss=1.8483049869537354
train: epoch 103, loss 0.387180358171463, acc=0.8157222270965576, loss=0.387180358171463
test: epoch 103, loss 1.7039622068405151, acc=0.44999998807907104, loss=1.7039622068405151
train: epoch 104, loss 0.39600691199302673, acc=0.8153333067893982, loss=0.39600691199302673
test: epoch 104, loss 1.9995934963226318, acc=0.4555555582046509, loss=1.9995934963226318
train: epoch 105, loss 0.3871895968914032, acc=0.8184999823570251, loss=0.3871895968914032
test: epoch 105, loss 1.889276146888733, acc=0.4583333432674408, loss=1.889276146888733
train: epoch 106, loss 0.3880826234817505, acc=0.8159444332122803, loss=0.3880826234817505
test: epoch 106, loss 1.9743828773498535, acc=0.43888887763023376, loss=1.9743828773498535
train: epoch 107, loss 0.3856797516345978, acc=0.8184999823570251, loss=0.3856797516345978
test: epoch 107, loss 1.7962942123413086, acc=0.4694444537162781, loss=1.7962942123413086
train: epoch 108, loss 0.3930474817752838, acc=0.8150555491447449, loss=0.3930474817752838
test: epoch 108, loss 1.952853798866272, acc=0.47777777910232544, loss=1.952853798866272
train: epoch 109, loss 0.3922745883464813, acc=0.8161110877990723, loss=0.3922745883464813
test: epoch 109, loss 1.9810529947280884, acc=0.4749999940395355, loss=1.9810529947280884
train: epoch 110, loss 0.3849872946739197, acc=0.8157222270965576, loss=0.3849872946739197
test: epoch 110, loss 1.9470670223236084, acc=0.43611112236976624, loss=1.9470670223236084
train: epoch 111, loss 0.40143150091171265, acc=0.8127222061157227, loss=0.40143150091171265
test: epoch 111, loss 1.8481075763702393, acc=0.4749999940395355, loss=1.8481075763702393
train: epoch 112, loss 0.38380271196365356, acc=0.8157777786254883, loss=0.38380271196365356
test: epoch 112, loss 2.0705952644348145, acc=0.4583333432674408, loss=2.0705952644348145
train: epoch 113, loss 0.39117467403411865, acc=0.8126111030578613, loss=0.39117467403411865
test: epoch 113, loss 1.755657434463501, acc=0.47777777910232544, loss=1.755657434463501
train: epoch 114, loss 0.3863973319530487, acc=0.8171111345291138, loss=0.3863973319530487
test: epoch 114, loss 2.0402209758758545, acc=0.46388888359069824, loss=2.0402209758758545
train: epoch 115, loss 0.380137175321579, acc=0.8178889155387878, loss=0.380137175321579
test: epoch 115, loss 1.8278961181640625, acc=0.4694444537162781, loss=1.8278961181640625
train: epoch 116, loss 0.38515931367874146, acc=0.8177222013473511, loss=0.38515931367874146
test: epoch 116, loss 1.8512388467788696, acc=0.47777777910232544, loss=1.8512388467788696
train: epoch 117, loss 0.38613831996917725, acc=0.8172777891159058, loss=0.38613831996917725
test: epoch 117, loss 1.8498268127441406, acc=0.46666666865348816, loss=1.8498268127441406
train: epoch 118, loss 0.3877127766609192, acc=0.8154444694519043, loss=0.3877127766609192
test: epoch 118, loss 1.6015539169311523, acc=0.47777777910232544, loss=1.6015539169311523
train: epoch 119, loss 0.4195099174976349, acc=0.8088333606719971, loss=0.4195099174976349
test: epoch 119, loss 1.5988153219223022, acc=0.4722222089767456, loss=1.5988153219223022
train: epoch 120, loss 0.38207319378852844, acc=0.8183333277702332, loss=0.38207319378852844
test: epoch 120, loss 1.7505580186843872, acc=0.4333333373069763, loss=1.7505580186843872
train: epoch 121, loss 0.3837871253490448, acc=0.815833330154419, loss=0.3837871253490448
test: epoch 121, loss 1.8103307485580444, acc=0.47777777910232544, loss=1.8103307485580444
train: epoch 122, loss 0.3823651373386383, acc=0.8180555701255798, loss=0.3823651373386383
test: epoch 122, loss 1.8335679769515991, acc=0.4583333432674408, loss=1.8335679769515991
train: epoch 123, loss 0.39720645546913147, acc=0.8129444718360901, loss=0.39720645546913147
test: epoch 123, loss 1.8504550457000732, acc=0.4694444537162781, loss=1.8504550457000732
train: epoch 124, loss 0.3805212378501892, acc=0.8187777996063232, loss=0.3805212378501892
test: epoch 124, loss 1.5981158018112183, acc=0.4749999940395355, loss=1.5981158018112183
train: epoch 125, loss 0.37600934505462646, acc=0.8198888897895813, loss=0.37600934505462646
test: epoch 125, loss 1.7485181093215942, acc=0.46666666865348816, loss=1.7485181093215942
train: epoch 126, loss 0.38965657353401184, acc=0.8184444308280945, loss=0.38965657353401184
test: epoch 126, loss 1.6548432111740112, acc=0.47777777910232544, loss=1.6548432111740112
train: epoch 127, loss 0.3871638774871826, acc=0.8151666522026062, loss=0.3871638774871826
test: epoch 127, loss 1.570221185684204, acc=0.4749999940395355, loss=1.570221185684204
train: epoch 128, loss 0.37743809819221497, acc=0.8198333382606506, loss=0.37743809819221497
test: epoch 128, loss 1.7560733556747437, acc=0.4694444537162781, loss=1.7560733556747437
train: epoch 129, loss 0.371675044298172, acc=0.8216111063957214, loss=0.371675044298172
test: epoch 129, loss 1.821044921875, acc=0.4694444537162781, loss=1.821044921875
train: epoch 130, loss 0.38339462876319885, acc=0.8188333511352539, loss=0.38339462876319885
test: epoch 130, loss 1.8554555177688599, acc=0.4722222089767456, loss=1.8554555177688599
train: epoch 131, loss 0.39100730419158936, acc=0.8146111369132996, loss=0.39100730419158936
test: epoch 131, loss 1.8701272010803223, acc=0.4694444537162781, loss=1.8701272010803223
train: epoch 132, loss 0.38452446460723877, acc=0.8178333044052124, loss=0.38452446460723877
test: epoch 132, loss 1.940951943397522, acc=0.4416666626930237, loss=1.940951943397522
train: epoch 133, loss 0.3737243115901947, acc=0.8230000138282776, loss=0.3737243115901947
test: epoch 133, loss 2.089764356613159, acc=0.46666666865348816, loss=2.089764356613159
train: epoch 134, loss 0.37040480971336365, acc=0.8240000009536743, loss=0.37040480971336365
test: epoch 134, loss 2.0240535736083984, acc=0.4472222328186035, loss=2.0240535736083984
train: epoch 135, loss 0.3741461932659149, acc=0.8216666579246521, loss=0.3741461932659149
test: epoch 135, loss 1.789811372756958, acc=0.44999998807907104, loss=1.789811372756958
train: epoch 136, loss 0.37760409712791443, acc=0.8209999799728394, loss=0.37760409712791443
test: epoch 136, loss 1.5740299224853516, acc=0.4749999940395355, loss=1.5740299224853516
train: epoch 137, loss 0.37632134556770325, acc=0.819944441318512, loss=0.37632134556770325
test: epoch 137, loss 1.9666486978530884, acc=0.38333332538604736, loss=1.9666486978530884
train: epoch 138, loss 0.3822651505470276, acc=0.8157777786254883, loss=0.3822651505470276
test: epoch 138, loss 2.384648084640503, acc=0.46666666865348816, loss=2.384648084640503
train: epoch 139, loss 0.3738863170146942, acc=0.8208333253860474, loss=0.3738863170146942
test: epoch 139, loss 2.0236213207244873, acc=0.4694444537162781, loss=2.0236213207244873
train: epoch 140, loss 0.3716332018375397, acc=0.8187777996063232, loss=0.3716332018375397
test: epoch 140, loss 1.9321680068969727, acc=0.4749999940395355, loss=1.9321680068969727
train: epoch 141, loss 0.375936359167099, acc=0.8191111087799072, loss=0.375936359167099
test: epoch 141, loss 2.0994226932525635, acc=0.44999998807907104, loss=2.0994226932525635
train: epoch 142, loss 0.36236199736595154, acc=0.8264999985694885, loss=0.36236199736595154
test: epoch 142, loss 2.021435022354126, acc=0.4583333432674408, loss=2.021435022354126
train: epoch 143, loss 0.3771986961364746, acc=0.8221111297607422, loss=0.3771986961364746
test: epoch 143, loss 1.8362876176834106, acc=0.4333333373069763, loss=1.8362876176834106
train: epoch 144, loss 0.36895719170570374, acc=0.8228333592414856, loss=0.36895719170570374
test: epoch 144, loss 1.655287265777588, acc=0.46666666865348816, loss=1.655287265777588
train: epoch 145, loss 0.3868599832057953, acc=0.8179444670677185, loss=0.3868599832057953
test: epoch 145, loss 1.745897650718689, acc=0.4416666626930237, loss=1.745897650718689
train: epoch 146, loss 0.3760061264038086, acc=0.82105553150177, loss=0.3760061264038086
test: epoch 146, loss 1.8522369861602783, acc=0.4555555582046509, loss=1.8522369861602783
train: epoch 147, loss 0.3597853481769562, acc=0.8222222328186035, loss=0.3597853481769562
test: epoch 147, loss 2.0075759887695312, acc=0.4749999940395355, loss=2.0075759887695312
train: epoch 148, loss 0.38480204343795776, acc=0.8186666369438171, loss=0.38480204343795776
test: epoch 148, loss 1.8671396970748901, acc=0.46666666865348816, loss=1.8671396970748901
train: epoch 149, loss 0.3519025444984436, acc=0.8277778029441833, loss=0.3519025444984436
test: epoch 149, loss 1.7797693014144897, acc=0.4722222089767456, loss=1.7797693014144897
train: epoch 150, loss 0.3712649345397949, acc=0.8213889002799988, loss=0.3712649345397949
test: epoch 150, loss 1.6893582344055176, acc=0.4722222089767456, loss=1.6893582344055176
