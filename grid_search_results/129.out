# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=1.5", "--temp_decay=1", "--one_hot=false", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=476553507, receiver_embed_dim=128, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.0998945236206055, acc=0.09355555474758148, loss=3.0998945236206055
test: epoch 1, loss 2.706817388534546, acc=0.12222222238779068, loss=2.706817388534546
train: epoch 2, loss 1.7012447118759155, acc=0.3171111047267914, loss=1.7012447118759155
test: epoch 2, loss 2.696070671081543, acc=0.16111111640930176, loss=2.696070671081543
train: epoch 3, loss 1.365366816520691, acc=0.44227778911590576, loss=1.365366816520691
test: epoch 3, loss 2.4709596633911133, acc=0.21666666865348816, loss=2.4709596633911133
train: epoch 4, loss 1.1779755353927612, acc=0.5167222023010254, loss=1.1779755353927612
test: epoch 4, loss 2.4162633419036865, acc=0.21111111342906952, loss=2.4162633419036865
train: epoch 5, loss 1.0407048463821411, acc=0.575166642665863, loss=1.0407048463821411
test: epoch 5, loss 2.400789260864258, acc=0.24166665971279144, loss=2.400789260864258
train: epoch 6, loss 0.947543203830719, acc=0.6183888912200928, loss=0.947543203830719
test: epoch 6, loss 2.330031633377075, acc=0.24722221493721008, loss=2.330031633377075
train: epoch 7, loss 0.8617644309997559, acc=0.6549444198608398, loss=0.8617644309997559
test: epoch 7, loss 2.273024797439575, acc=0.2611111104488373, loss=2.273024797439575
train: epoch 8, loss 0.7979739904403687, acc=0.6825000047683716, loss=0.7979739904403687
test: epoch 8, loss 2.1208372116088867, acc=0.2888889014720917, loss=2.1208372116088867
train: epoch 9, loss 0.7350977063179016, acc=0.7073888778686523, loss=0.7350977063179016
test: epoch 9, loss 2.1618540287017822, acc=0.2916666567325592, loss=2.1618540287017822
train: epoch 10, loss 0.691813051700592, acc=0.7316111326217651, loss=0.691813051700592
test: epoch 10, loss 2.2042317390441895, acc=0.29722222685813904, loss=2.2042317390441895
train: epoch 11, loss 0.6465039849281311, acc=0.7451111078262329, loss=0.6465039849281311
test: epoch 11, loss 2.3131966590881348, acc=0.24444444477558136, loss=2.3131966590881348
train: epoch 12, loss 0.6176952719688416, acc=0.7606666684150696, loss=0.6176952719688416
test: epoch 12, loss 2.0898444652557373, acc=0.3027777671813965, loss=2.0898444652557373
train: epoch 13, loss 0.5723969340324402, acc=0.7787222266197205, loss=0.5723969340324402
test: epoch 13, loss 2.224407911300659, acc=0.3166666626930237, loss=2.224407911300659
train: epoch 14, loss 0.5495967864990234, acc=0.7866666913032532, loss=0.5495967864990234
test: epoch 14, loss 2.1087498664855957, acc=0.31388887763023376, loss=2.1087498664855957
train: epoch 15, loss 0.5317692756652832, acc=0.7923333048820496, loss=0.5317692756652832
test: epoch 15, loss 2.108950614929199, acc=0.3638888895511627, loss=2.108950614929199
train: epoch 16, loss 0.5105095505714417, acc=0.7992777824401855, loss=0.5105095505714417
test: epoch 16, loss 2.1365103721618652, acc=0.3472222089767456, loss=2.1365103721618652
train: epoch 17, loss 0.4788159430027008, acc=0.8143888711929321, loss=0.4788159430027008
test: epoch 17, loss 2.115037441253662, acc=0.36666667461395264, loss=2.115037441253662
train: epoch 18, loss 0.46862468123435974, acc=0.8206111192703247, loss=0.46862468123435974
test: epoch 18, loss 1.8633760213851929, acc=0.38055557012557983, loss=1.8633760213851929
train: epoch 19, loss 0.4633285105228424, acc=0.8241111040115356, loss=0.4633285105228424
test: epoch 19, loss 2.2060964107513428, acc=0.36944442987442017, loss=2.2060964107513428
train: epoch 20, loss 0.43184226751327515, acc=0.8295555710792542, loss=0.43184226751327515
test: epoch 20, loss 2.0650634765625, acc=0.3222222328186035, loss=2.0650634765625
train: epoch 21, loss 0.4162188768386841, acc=0.8413333296775818, loss=0.4162188768386841
test: epoch 21, loss 1.9007731676101685, acc=0.3444444537162781, loss=1.9007731676101685
train: epoch 22, loss 0.39237502217292786, acc=0.8473333120346069, loss=0.39237502217292786
test: epoch 22, loss 1.9898024797439575, acc=0.3499999940395355, loss=1.9898024797439575
train: epoch 23, loss 0.38838598132133484, acc=0.8506110906600952, loss=0.38838598132133484
test: epoch 23, loss 1.981137752532959, acc=0.3861111104488373, loss=1.981137752532959
train: epoch 24, loss 0.37362322211265564, acc=0.8584444522857666, loss=0.37362322211265564
test: epoch 24, loss 1.8424445390701294, acc=0.4583333432674408, loss=1.8424445390701294
train: epoch 25, loss 0.3676009178161621, acc=0.8577222228050232, loss=0.3676009178161621
test: epoch 25, loss 1.9566786289215088, acc=0.3472222089767456, loss=1.9566786289215088
train: epoch 26, loss 0.35526353120803833, acc=0.8645555377006531, loss=0.35526353120803833
test: epoch 26, loss 1.9808757305145264, acc=0.42500001192092896, loss=1.9808757305145264
train: epoch 27, loss 0.35111287236213684, acc=0.86772221326828, loss=0.35111287236213684
test: epoch 27, loss 2.087851047515869, acc=0.35555556416511536, loss=2.087851047515869
train: epoch 28, loss 0.3308413028717041, acc=0.8721666932106018, loss=0.3308413028717041
test: epoch 28, loss 2.2047317028045654, acc=0.4000000059604645, loss=2.2047317028045654
train: epoch 29, loss 0.3300025165081024, acc=0.8742222189903259, loss=0.3300025165081024
test: epoch 29, loss 2.016125440597534, acc=0.4305555522441864, loss=2.016125440597534
train: epoch 30, loss 0.31749439239501953, acc=0.878000020980835, loss=0.31749439239501953
test: epoch 30, loss 1.9617854356765747, acc=0.4138889014720917, loss=1.9617854356765747
train: epoch 31, loss 0.311362087726593, acc=0.8806111216545105, loss=0.311362087726593
test: epoch 31, loss 1.9225294589996338, acc=0.3777777850627899, loss=1.9225294589996338
train: epoch 32, loss 0.3063638210296631, acc=0.8830000162124634, loss=0.3063638210296631
test: epoch 32, loss 1.9746794700622559, acc=0.4000000059604645, loss=1.9746794700622559
train: epoch 33, loss 0.29336655139923096, acc=0.8872222304344177, loss=0.29336655139923096
test: epoch 33, loss 2.1321563720703125, acc=0.4694444537162781, loss=2.1321563720703125
train: epoch 34, loss 0.29659274220466614, acc=0.8846666812896729, loss=0.29659274220466614
test: epoch 34, loss 2.234915256500244, acc=0.42500001192092896, loss=2.234915256500244
train: epoch 35, loss 0.27315542101860046, acc=0.8934444189071655, loss=0.27315542101860046
test: epoch 35, loss 2.366865873336792, acc=0.4333333373069763, loss=2.366865873336792
train: epoch 36, loss 0.2880151867866516, acc=0.8878333568572998, loss=0.2880151867866516
test: epoch 36, loss 2.491994857788086, acc=0.42500001192092896, loss=2.491994857788086
train: epoch 37, loss 0.27325037121772766, acc=0.8941666483879089, loss=0.27325037121772766
test: epoch 37, loss 2.2986373901367188, acc=0.4166666567325592, loss=2.2986373901367188
train: epoch 38, loss 0.2705630660057068, acc=0.8959444165229797, loss=0.2705630660057068
test: epoch 38, loss 2.1913564205169678, acc=0.43611112236976624, loss=2.1913564205169678
train: epoch 39, loss 0.252666175365448, acc=0.9028333425521851, loss=0.252666175365448
test: epoch 39, loss 2.568079948425293, acc=0.38055557012557983, loss=2.568079948425293
train: epoch 40, loss 0.2637780010700226, acc=0.8993889093399048, loss=0.2637780010700226
test: epoch 40, loss 2.5954442024230957, acc=0.4194444417953491, loss=2.5954442024230957
train: epoch 41, loss 0.26135095953941345, acc=0.8999444246292114, loss=0.26135095953941345
test: epoch 41, loss 2.3402068614959717, acc=0.4611110985279083, loss=2.3402068614959717
train: epoch 42, loss 0.2516523003578186, acc=0.9026666879653931, loss=0.2516523003578186
test: epoch 42, loss 2.1454861164093018, acc=0.4694444537162781, loss=2.1454861164093018
train: epoch 43, loss 0.26559099555015564, acc=0.901888906955719, loss=0.26559099555015564
test: epoch 43, loss 2.4301421642303467, acc=0.4277777671813965, loss=2.4301421642303467
train: epoch 44, loss 0.24397264420986176, acc=0.9081110954284668, loss=0.24397264420986176
test: epoch 44, loss 2.298102378845215, acc=0.4555555582046509, loss=2.298102378845215
train: epoch 45, loss 0.24436040222644806, acc=0.9068333506584167, loss=0.24436040222644806
test: epoch 45, loss 2.3105854988098145, acc=0.4611110985279083, loss=2.3105854988098145
train: epoch 46, loss 0.2501201927661896, acc=0.9088333249092102, loss=0.2501201927661896
test: epoch 46, loss 2.5640628337860107, acc=0.42222222685813904, loss=2.5640628337860107
train: epoch 47, loss 0.2352895885705948, acc=0.9103333353996277, loss=0.2352895885705948
test: epoch 47, loss 2.7796108722686768, acc=0.4555555582046509, loss=2.7796108722686768
train: epoch 48, loss 0.22702927887439728, acc=0.9153888821601868, loss=0.22702927887439728
test: epoch 48, loss 2.354675769805908, acc=0.46666666865348816, loss=2.354675769805908
train: epoch 49, loss 0.22303712368011475, acc=0.917388916015625, loss=0.22303712368011475
test: epoch 49, loss 2.6414334774017334, acc=0.4555555582046509, loss=2.6414334774017334
train: epoch 50, loss 0.22193074226379395, acc=0.9151666760444641, loss=0.22193074226379395
test: epoch 50, loss 2.6104276180267334, acc=0.4722222089767456, loss=2.6104276180267334
train: epoch 51, loss 0.22888658940792084, acc=0.91438889503479, loss=0.22888658940792084
test: epoch 51, loss 2.069655418395996, acc=0.4611110985279083, loss=2.069655418395996
train: epoch 52, loss 0.2134183645248413, acc=0.9191666841506958, loss=0.2134183645248413
test: epoch 52, loss 2.3947269916534424, acc=0.44999998807907104, loss=2.3947269916534424
train: epoch 53, loss 0.2113780528306961, acc=0.9228333234786987, loss=0.2113780528306961
test: epoch 53, loss 2.363982677459717, acc=0.4611110985279083, loss=2.363982677459717
train: epoch 54, loss 0.21850445866584778, acc=0.9221110939979553, loss=0.21850445866584778
test: epoch 54, loss 2.888862133026123, acc=0.4583333432674408, loss=2.888862133026123
train: epoch 55, loss 0.2019382268190384, acc=0.9292222261428833, loss=0.2019382268190384
test: epoch 55, loss 2.3731977939605713, acc=0.4861111044883728, loss=2.3731977939605713
train: epoch 56, loss 0.20898829400539398, acc=0.9264444708824158, loss=0.20898829400539398
test: epoch 56, loss 2.7740230560302734, acc=0.46666666865348816, loss=2.7740230560302734
train: epoch 57, loss 0.20431090891361237, acc=0.9266666769981384, loss=0.20431090891361237
test: epoch 57, loss 2.7707326412200928, acc=0.4444444477558136, loss=2.7707326412200928
train: epoch 58, loss 0.19507327675819397, acc=0.9311110973358154, loss=0.19507327675819397
test: epoch 58, loss 2.698199510574341, acc=0.43888887763023376, loss=2.698199510574341
train: epoch 59, loss 0.1887936294078827, acc=0.9325000047683716, loss=0.1887936294078827
test: epoch 59, loss 2.487645149230957, acc=0.42500001192092896, loss=2.487645149230957
train: epoch 60, loss 0.19094768166542053, acc=0.9318888783454895, loss=0.19094768166542053
test: epoch 60, loss 2.6329572200775146, acc=0.4833333194255829, loss=2.6329572200775146
train: epoch 61, loss 0.18891863524913788, acc=0.9339444637298584, loss=0.18891863524913788
test: epoch 61, loss 2.389047861099243, acc=0.49166667461395264, loss=2.389047861099243
train: epoch 62, loss 0.20594549179077148, acc=0.92894446849823, loss=0.20594549179077148
test: epoch 62, loss 2.460596799850464, acc=0.5, loss=2.460596799850464
train: epoch 63, loss 0.18807917833328247, acc=0.9340555667877197, loss=0.18807917833328247
test: epoch 63, loss 2.593571424484253, acc=0.43611112236976624, loss=2.593571424484253
train: epoch 64, loss 0.18778106570243835, acc=0.9331666827201843, loss=0.18778106570243835
test: epoch 64, loss 2.5884780883789062, acc=0.5027777552604675, loss=2.5884780883789062
train: epoch 65, loss 0.1742205023765564, acc=0.9373888969421387, loss=0.1742205023765564
test: epoch 65, loss 2.5925517082214355, acc=0.519444465637207, loss=2.5925517082214355
train: epoch 66, loss 0.18293976783752441, acc=0.9367777705192566, loss=0.18293976783752441
test: epoch 66, loss 2.6196069717407227, acc=0.4833333194255829, loss=2.6196069717407227
train: epoch 67, loss 0.19063739478588104, acc=0.9334999918937683, loss=0.19063739478588104
test: epoch 67, loss 2.219964027404785, acc=0.5166666507720947, loss=2.219964027404785
train: epoch 68, loss 0.18322913348674774, acc=0.933722198009491, loss=0.18322913348674774
test: epoch 68, loss 2.3448076248168945, acc=0.4694444537162781, loss=2.3448076248168945
train: epoch 69, loss 0.17271198332309723, acc=0.9386666417121887, loss=0.17271198332309723
test: epoch 69, loss 2.683431625366211, acc=0.4861111044883728, loss=2.683431625366211
train: epoch 70, loss 0.1767124980688095, acc=0.9365555644035339, loss=0.1767124980688095
test: epoch 70, loss 2.660496234893799, acc=0.5138888955116272, loss=2.660496234893799
train: epoch 71, loss 0.16765208542346954, acc=0.9382777810096741, loss=0.16765208542346954
test: epoch 71, loss 2.5953941345214844, acc=0.5083333253860474, loss=2.5953941345214844
train: epoch 72, loss 0.17890359461307526, acc=0.9363889098167419, loss=0.17890359461307526
test: epoch 72, loss 2.446789026260376, acc=0.5, loss=2.446789026260376
train: epoch 73, loss 0.17663417756557465, acc=0.9386110901832581, loss=0.17663417756557465
test: epoch 73, loss 2.700038194656372, acc=0.4972222149372101, loss=2.700038194656372
train: epoch 74, loss 0.17680345475673676, acc=0.9357777833938599, loss=0.17680345475673676
test: epoch 74, loss 2.615107536315918, acc=0.4749999940395355, loss=2.615107536315918
train: epoch 75, loss 0.16616173088550568, acc=0.9405555725097656, loss=0.16616173088550568
test: epoch 75, loss 2.5365614891052246, acc=0.47777777910232544, loss=2.5365614891052246
train: epoch 76, loss 0.1690504252910614, acc=0.9397777915000916, loss=0.1690504252910614
test: epoch 76, loss 2.6199100017547607, acc=0.519444465637207, loss=2.6199100017547607
train: epoch 77, loss 0.16064795851707458, acc=0.9425555467605591, loss=0.16064795851707458
test: epoch 77, loss 2.6444778442382812, acc=0.5166666507720947, loss=2.6444778442382812
train: epoch 78, loss 0.16818243265151978, acc=0.941944420337677, loss=0.16818243265151978
test: epoch 78, loss 2.527665615081787, acc=0.5333333611488342, loss=2.527665615081787
train: epoch 79, loss 0.16742311418056488, acc=0.9415555596351624, loss=0.16742311418056488
test: epoch 79, loss 2.529419183731079, acc=0.5055555701255798, loss=2.529419183731079
train: epoch 80, loss 0.17196586728096008, acc=0.9391666650772095, loss=0.17196586728096008
test: epoch 80, loss 2.3090031147003174, acc=0.49444442987442017, loss=2.3090031147003174
train: epoch 81, loss 0.1620268076658249, acc=0.941777765750885, loss=0.1620268076658249
test: epoch 81, loss 2.6359751224517822, acc=0.4972222149372101, loss=2.6359751224517822
train: epoch 82, loss 0.1650230437517166, acc=0.9425555467605591, loss=0.1650230437517166
test: epoch 82, loss 2.522963523864746, acc=0.5361111164093018, loss=2.522963523864746
train: epoch 83, loss 0.17071424424648285, acc=0.9401666522026062, loss=0.17071424424648285
test: epoch 83, loss 2.711381196975708, acc=0.519444465637207, loss=2.711381196975708
train: epoch 84, loss 0.16503506898880005, acc=0.9427777528762817, loss=0.16503506898880005
test: epoch 84, loss 2.7562639713287354, acc=0.5388888716697693, loss=2.7562639713287354
train: epoch 85, loss 0.15924441814422607, acc=0.9432222247123718, loss=0.15924441814422607
test: epoch 85, loss 2.4493565559387207, acc=0.5388888716697693, loss=2.4493565559387207
train: epoch 86, loss 0.15511690080165863, acc=0.9443888664245605, loss=0.15511690080165863
test: epoch 86, loss 2.153752088546753, acc=0.5166666507720947, loss=2.153752088546753
train: epoch 87, loss 0.1627010852098465, acc=0.9431666731834412, loss=0.1627010852098465
test: epoch 87, loss 2.605144500732422, acc=0.5277777910232544, loss=2.605144500732422
train: epoch 88, loss 0.15191680192947388, acc=0.9479444622993469, loss=0.15191680192947388
test: epoch 88, loss 2.552802562713623, acc=0.5138888955116272, loss=2.552802562713623
train: epoch 89, loss 0.1578913778066635, acc=0.944611132144928, loss=0.1578913778066635
test: epoch 89, loss 2.740271806716919, acc=0.5277777910232544, loss=2.740271806716919
train: epoch 90, loss 0.1485319435596466, acc=0.9465555548667908, loss=0.1485319435596466
test: epoch 90, loss 2.370594024658203, acc=0.5472221970558167, loss=2.370594024658203
train: epoch 91, loss 0.1532478630542755, acc=0.9478333592414856, loss=0.1532478630542755
test: epoch 91, loss 2.312624216079712, acc=0.5666666626930237, loss=2.312624216079712
train: epoch 92, loss 0.15556327998638153, acc=0.9478333592414856, loss=0.15556327998638153
test: epoch 92, loss 2.3345797061920166, acc=0.5361111164093018, loss=2.3345797061920166
train: epoch 93, loss 0.15337473154067993, acc=0.9465000033378601, loss=0.15337473154067993
test: epoch 93, loss 2.2707018852233887, acc=0.5611110925674438, loss=2.2707018852233887
train: epoch 94, loss 0.13610467314720154, acc=0.9516666531562805, loss=0.13610467314720154
test: epoch 94, loss 2.1118714809417725, acc=0.5833333134651184, loss=2.1118714809417725
train: epoch 95, loss 0.14331504702568054, acc=0.949388861656189, loss=0.14331504702568054
test: epoch 95, loss 2.245138168334961, acc=0.5361111164093018, loss=2.245138168334961
train: epoch 96, loss 0.14549565315246582, acc=0.9492777585983276, loss=0.14549565315246582
test: epoch 96, loss 2.363539695739746, acc=0.5722222328186035, loss=2.363539695739746
train: epoch 97, loss 0.14737550914287567, acc=0.9492777585983276, loss=0.14737550914287567
test: epoch 97, loss 2.2633161544799805, acc=0.5583333373069763, loss=2.2633161544799805
train: epoch 98, loss 0.13806240260601044, acc=0.9524444341659546, loss=0.13806240260601044
test: epoch 98, loss 2.367213249206543, acc=0.5694444179534912, loss=2.367213249206543
train: epoch 99, loss 0.1429973542690277, acc=0.950166642665863, loss=0.1429973542690277
test: epoch 99, loss 2.363784074783325, acc=0.5805555582046509, loss=2.363784074783325
train: epoch 100, loss 0.13744331896305084, acc=0.9511111378669739, loss=0.13744331896305084
test: epoch 100, loss 2.157938241958618, acc=0.6000000238418579, loss=2.157938241958618
train: epoch 101, loss 0.1455851048231125, acc=0.9507777690887451, loss=0.1455851048231125
test: epoch 101, loss 2.572080612182617, acc=0.5833333134651184, loss=2.572080612182617
train: epoch 102, loss 0.13186992704868317, acc=0.9539444446563721, loss=0.13186992704868317
test: epoch 102, loss 2.2145230770111084, acc=0.574999988079071, loss=2.2145230770111084
train: epoch 103, loss 0.13931505382061005, acc=0.9514444470405579, loss=0.13931505382061005
test: epoch 103, loss 2.341674327850342, acc=0.6111111044883728, loss=2.341674327850342
train: epoch 104, loss 0.13410454988479614, acc=0.9533888697624207, loss=0.13410454988479614
test: epoch 104, loss 2.029261589050293, acc=0.5861111283302307, loss=2.029261589050293
train: epoch 105, loss 0.13182669878005981, acc=0.9548888802528381, loss=0.13182669878005981
test: epoch 105, loss 2.388331174850464, acc=0.574999988079071, loss=2.388331174850464
train: epoch 106, loss 0.12828771770000458, acc=0.9567777514457703, loss=0.12828771770000458
test: epoch 106, loss 2.43127703666687, acc=0.5916666388511658, loss=2.43127703666687
train: epoch 107, loss 0.1333688348531723, acc=0.9553889036178589, loss=0.1333688348531723
test: epoch 107, loss 2.3072597980499268, acc=0.6166666746139526, loss=2.3072597980499268
train: epoch 108, loss 0.1265350729227066, acc=0.9571666717529297, loss=0.1265350729227066
test: epoch 108, loss 2.2502856254577637, acc=0.605555534362793, loss=2.2502856254577637
train: epoch 109, loss 0.12251003831624985, acc=0.9585555791854858, loss=0.12251003831624985
test: epoch 109, loss 2.352156162261963, acc=0.5916666388511658, loss=2.352156162261963
train: epoch 110, loss 0.11908665299415588, acc=0.9597222208976746, loss=0.11908665299415588
test: epoch 110, loss 2.1533074378967285, acc=0.6194444298744202, loss=2.1533074378967285
train: epoch 111, loss 0.1214292123913765, acc=0.9570555686950684, loss=0.1214292123913765
test: epoch 111, loss 2.1093900203704834, acc=0.5972222089767456, loss=2.1093900203704834
train: epoch 112, loss 0.12361645698547363, acc=0.9574999809265137, loss=0.12361645698547363
test: epoch 112, loss 2.1472160816192627, acc=0.6027777791023254, loss=2.1472160816192627
train: epoch 113, loss 0.12567299604415894, acc=0.9577777981758118, loss=0.12567299604415894
test: epoch 113, loss 2.194432020187378, acc=0.6027777791023254, loss=2.194432020187378
train: epoch 114, loss 0.11407026648521423, acc=0.9620000123977661, loss=0.11407026648521423
test: epoch 114, loss 2.0022356510162354, acc=0.6138888597488403, loss=2.0022356510162354
train: epoch 115, loss 0.12373925745487213, acc=0.9584444165229797, loss=0.12373925745487213
test: epoch 115, loss 2.054708957672119, acc=0.5916666388511658, loss=2.054708957672119
train: epoch 116, loss 0.11326034367084503, acc=0.9594444632530212, loss=0.11326034367084503
test: epoch 116, loss 2.2236032485961914, acc=0.6027777791023254, loss=2.2236032485961914
train: epoch 117, loss 0.11190138757228851, acc=0.96061110496521, loss=0.11190138757228851
test: epoch 117, loss 2.77046275138855, acc=0.6083333492279053, loss=2.77046275138855
train: epoch 118, loss 0.11965154111385345, acc=0.9586111307144165, loss=0.11965154111385345
test: epoch 118, loss 2.435236692428589, acc=0.6277777552604675, loss=2.435236692428589
train: epoch 119, loss 0.12211090326309204, acc=0.9585555791854858, loss=0.12211090326309204
test: epoch 119, loss 2.2055575847625732, acc=0.6027777791023254, loss=2.2055575847625732
train: epoch 120, loss 0.11727897077798843, acc=0.9605000019073486, loss=0.11727897077798843
test: epoch 120, loss 2.1743080615997314, acc=0.6111111044883728, loss=2.1743080615997314
train: epoch 121, loss 0.12157396972179413, acc=0.9598888754844666, loss=0.12157396972179413
test: epoch 121, loss 2.118178129196167, acc=0.5861111283302307, loss=2.118178129196167
train: epoch 122, loss 0.11287590116262436, acc=0.9586111307144165, loss=0.11287590116262436
test: epoch 122, loss 2.231673002243042, acc=0.6111111044883728, loss=2.231673002243042
train: epoch 123, loss 0.11290180683135986, acc=0.9593889117240906, loss=0.11290180683135986
test: epoch 123, loss 2.7443010807037354, acc=0.5583333373069763, loss=2.7443010807037354
train: epoch 124, loss 0.11210750788450241, acc=0.9607222080230713, loss=0.11210750788450241
test: epoch 124, loss 2.022909641265869, acc=0.6166666746139526, loss=2.022909641265869
train: epoch 125, loss 0.11079525202512741, acc=0.9622777700424194, loss=0.11079525202512741
test: epoch 125, loss 2.0185282230377197, acc=0.6305555701255798, loss=2.0185282230377197
train: epoch 126, loss 0.11299841850996017, acc=0.9596111178398132, loss=0.11299841850996017
test: epoch 126, loss 1.9424268007278442, acc=0.6333333253860474, loss=1.9424268007278442
train: epoch 127, loss 0.11094390600919724, acc=0.9598333239555359, loss=0.11094390600919724
test: epoch 127, loss 2.453623056411743, acc=0.605555534362793, loss=2.453623056411743
train: epoch 128, loss 0.11204803735017776, acc=0.9613333344459534, loss=0.11204803735017776
test: epoch 128, loss 2.3074886798858643, acc=0.6305555701255798, loss=2.3074886798858643
train: epoch 129, loss 0.1128634363412857, acc=0.960444450378418, loss=0.1128634363412857
test: epoch 129, loss 2.5721633434295654, acc=0.605555534362793, loss=2.5721633434295654
train: epoch 130, loss 0.11220761388540268, acc=0.9605555534362793, loss=0.11220761388540268
test: epoch 130, loss 2.2528436183929443, acc=0.6333333253860474, loss=2.2528436183929443
train: epoch 131, loss 0.1040131151676178, acc=0.9627222418785095, loss=0.1040131151676178
test: epoch 131, loss 2.2220492362976074, acc=0.625, loss=2.2220492362976074
train: epoch 132, loss 0.10896899551153183, acc=0.9608888626098633, loss=0.10896899551153183
test: epoch 132, loss 2.0782551765441895, acc=0.6361111402511597, loss=2.0782551765441895
train: epoch 133, loss 0.12611569464206696, acc=0.9556111097335815, loss=0.12611569464206696
test: epoch 133, loss 2.1731011867523193, acc=0.605555534362793, loss=2.1731011867523193
train: epoch 134, loss 0.11397623270750046, acc=0.960444450378418, loss=0.11397623270750046
test: epoch 134, loss 2.1290621757507324, acc=0.6305555701255798, loss=2.1290621757507324
train: epoch 135, loss 0.10635435581207275, acc=0.9631666541099548, loss=0.10635435581207275
test: epoch 135, loss 2.267322540283203, acc=0.5944444537162781, loss=2.267322540283203
train: epoch 136, loss 0.1163516417145729, acc=0.9605555534362793, loss=0.1163516417145729
test: epoch 136, loss 2.053572177886963, acc=0.6083333492279053, loss=2.053572177886963
train: epoch 137, loss 0.10941502451896667, acc=0.96061110496521, loss=0.10941502451896667
test: epoch 137, loss 2.5408999919891357, acc=0.6000000238418579, loss=2.5408999919891357
train: epoch 138, loss 0.11274798214435577, acc=0.9610555768013, loss=0.11274798214435577
test: epoch 138, loss 1.8841408491134644, acc=0.6277777552604675, loss=1.8841408491134644
train: epoch 139, loss 0.11680691689252853, acc=0.9583333134651184, loss=0.11680691689252853
test: epoch 139, loss 2.2697248458862305, acc=0.625, loss=2.2697248458862305
train: epoch 140, loss 0.10634945333003998, acc=0.9620555639266968, loss=0.10634945333003998
test: epoch 140, loss 2.111812114715576, acc=0.6138888597488403, loss=2.111812114715576
train: epoch 141, loss 0.10697904974222183, acc=0.961722195148468, loss=0.10697904974222183
test: epoch 141, loss 2.3117635250091553, acc=0.6166666746139526, loss=2.3117635250091553
train: epoch 142, loss 0.112026147544384, acc=0.9619444608688354, loss=0.112026147544384
test: epoch 142, loss 1.866459846496582, acc=0.6222222447395325, loss=1.866459846496582
train: epoch 143, loss 0.10411296784877777, acc=0.9627777934074402, loss=0.10411296784877777
test: epoch 143, loss 1.9730184078216553, acc=0.644444465637207, loss=1.9730184078216553
train: epoch 144, loss 0.11438111960887909, acc=0.960444450378418, loss=0.11438111960887909
test: epoch 144, loss 2.198695659637451, acc=0.5916666388511658, loss=2.198695659637451
train: epoch 145, loss 0.11034385114908218, acc=0.9614999890327454, loss=0.11034385114908218
test: epoch 145, loss 1.9635539054870605, acc=0.6416666507720947, loss=1.9635539054870605
train: epoch 146, loss 0.10653667151927948, acc=0.9644444584846497, loss=0.10653667151927948
test: epoch 146, loss 1.9363166093826294, acc=0.6305555701255798, loss=1.9363166093826294
train: epoch 147, loss 0.11459128558635712, acc=0.9603888988494873, loss=0.11459128558635712
test: epoch 147, loss 2.236395835876465, acc=0.6305555701255798, loss=2.236395835876465
train: epoch 148, loss 0.10601238161325455, acc=0.9630555510520935, loss=0.10601238161325455
test: epoch 148, loss 2.3744215965270996, acc=0.6277777552604675, loss=2.3744215965270996
train: epoch 149, loss 0.10229416936635971, acc=0.9639999866485596, loss=0.10229416936635971
test: epoch 149, loss 2.1044559478759766, acc=0.6277777552604675, loss=2.1044559478759766
train: epoch 150, loss 0.10825678706169128, acc=0.9640555381774902, loss=0.10825678706169128
test: epoch 150, loss 2.0959811210632324, acc=0.6416666507720947, loss=2.0959811210632324
