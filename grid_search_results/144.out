# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=2.0", "--temp_decay=1", "--one_hot=0", "--n_layers=1"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=1149603066, receiver_embed_dim=128, save_run=0, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=1149603066, receiver_embed_dim=128, save_run=False, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.9388999938964844, acc=0.1077222228050232, loss=2.9388999938964844
test: epoch 1, loss 6.229104518890381, acc=0.03888889029622078, loss=6.229104518890381
train: epoch 2, loss 2.4661786556243896, acc=0.17161111533641815, loss=2.4661786556243896
test: epoch 2, loss 7.853144645690918, acc=0.02777777798473835, loss=7.853144645690918
train: epoch 3, loss 2.3126468658447266, acc=0.19988888502120972, loss=2.3126468658447266
test: epoch 3, loss 8.933229446411133, acc=0.03055555559694767, loss=8.933229446411133
train: epoch 4, loss 2.21944522857666, acc=0.2152777761220932, loss=2.21944522857666
test: epoch 4, loss 9.574023246765137, acc=0.03333333507180214, loss=9.574023246765137
train: epoch 5, loss 2.1510961055755615, acc=0.23322221636772156, loss=2.1510961055755615
test: epoch 5, loss 10.12467098236084, acc=0.03055555559694767, loss=10.12467098236084
train: epoch 6, loss 2.101153612136841, acc=0.24088889360427856, loss=2.101153612136841
test: epoch 6, loss 10.83376407623291, acc=0.03333333507180214, loss=10.83376407623291
train: epoch 7, loss 2.065720796585083, acc=0.24455556273460388, loss=2.065720796585083
test: epoch 7, loss 11.121545791625977, acc=0.03611111268401146, loss=11.121545791625977
train: epoch 8, loss 2.025919198989868, acc=0.24861110746860504, loss=2.025919198989868
test: epoch 8, loss 11.759273529052734, acc=0.02777777798473835, loss=11.759273529052734
train: epoch 9, loss 1.986532211303711, acc=0.26644444465637207, loss=1.986532211303711
test: epoch 9, loss 11.975775718688965, acc=0.03611111268401146, loss=11.975775718688965
train: epoch 10, loss 1.9667991399765015, acc=0.2669999897480011, loss=1.9667991399765015
test: epoch 10, loss 12.317619323730469, acc=0.03055555559694767, loss=12.317619323730469
train: epoch 11, loss 1.9366716146469116, acc=0.27772220969200134, loss=1.9366716146469116
test: epoch 11, loss 12.545188903808594, acc=0.03611111268401146, loss=12.545188903808594
train: epoch 12, loss 1.9214396476745605, acc=0.27533334493637085, loss=1.9214396476745605
test: epoch 12, loss 12.938096046447754, acc=0.03055555559694767, loss=12.938096046447754
train: epoch 13, loss 1.894014835357666, acc=0.2841111123561859, loss=1.894014835357666
test: epoch 13, loss 13.108478546142578, acc=0.02777777798473835, loss=13.108478546142578
train: epoch 14, loss 1.8765794038772583, acc=0.29088887572288513, loss=1.8765794038772583
test: epoch 14, loss 13.142683029174805, acc=0.02777777798473835, loss=13.142683029174805
train: epoch 15, loss 1.8698261976242065, acc=0.28833332657814026, loss=1.8698261976242065
test: epoch 15, loss 13.004131317138672, acc=0.02777777798473835, loss=13.004131317138672
train: epoch 16, loss 1.8394626379013062, acc=0.296999990940094, loss=1.8394626379013062
test: epoch 16, loss 13.367247581481934, acc=0.02500000037252903, loss=13.367247581481934
train: epoch 17, loss 1.8149470090866089, acc=0.3076666593551636, loss=1.8149470090866089
test: epoch 17, loss 13.76536750793457, acc=0.02500000037252903, loss=13.76536750793457
train: epoch 18, loss 1.8078707456588745, acc=0.31122222542762756, loss=1.8078707456588745
test: epoch 18, loss 13.920808792114258, acc=0.02222222276031971, loss=13.920808792114258
train: epoch 19, loss 1.79180908203125, acc=0.3108888864517212, loss=1.79180908203125
test: epoch 19, loss 13.82198429107666, acc=0.02500000037252903, loss=13.82198429107666
train: epoch 20, loss 1.7785876989364624, acc=0.3150555491447449, loss=1.7785876989364624
test: epoch 20, loss 13.72598934173584, acc=0.03333333507180214, loss=13.72598934173584
train: epoch 21, loss 1.7675120830535889, acc=0.3184444308280945, loss=1.7675120830535889
test: epoch 21, loss 14.012910842895508, acc=0.03333333507180214, loss=14.012910842895508
train: epoch 22, loss 1.7593052387237549, acc=0.31788888573646545, loss=1.7593052387237549
test: epoch 22, loss 14.332916259765625, acc=0.02777777798473835, loss=14.332916259765625
train: epoch 23, loss 1.7425670623779297, acc=0.3263888955116272, loss=1.7425670623779297
test: epoch 23, loss 14.233580589294434, acc=0.03333333507180214, loss=14.233580589294434
train: epoch 24, loss 1.726597547531128, acc=0.3366111218929291, loss=1.726597547531128
test: epoch 24, loss 14.587003707885742, acc=0.03333333507180214, loss=14.587003707885742
train: epoch 25, loss 1.723574161529541, acc=0.3334999978542328, loss=1.723574161529541
test: epoch 25, loss 14.574021339416504, acc=0.02222222276031971, loss=14.574021339416504
train: epoch 26, loss 1.7114099264144897, acc=0.34361112117767334, loss=1.7114099264144897
test: epoch 26, loss 14.795806884765625, acc=0.02500000037252903, loss=14.795806884765625
train: epoch 27, loss 1.7056727409362793, acc=0.34599998593330383, loss=1.7056727409362793
test: epoch 27, loss 15.059597969055176, acc=0.03333333507180214, loss=15.059597969055176
train: epoch 28, loss 1.6832237243652344, acc=0.34700000286102295, loss=1.6832237243652344
test: epoch 28, loss 15.253133773803711, acc=0.03333333507180214, loss=15.253133773803711
train: epoch 29, loss 1.6814334392547607, acc=0.3488333225250244, loss=1.6814334392547607
test: epoch 29, loss 15.138954162597656, acc=0.02222222276031971, loss=15.138954162597656
train: epoch 30, loss 1.6783595085144043, acc=0.35216665267944336, loss=1.6783595085144043
test: epoch 30, loss 14.885278701782227, acc=0.02222222276031971, loss=14.885278701782227
train: epoch 31, loss 1.6630128622055054, acc=0.3562777638435364, loss=1.6630128622055054
test: epoch 31, loss 15.715703964233398, acc=0.02222222276031971, loss=15.715703964233398
train: epoch 32, loss 1.6464166641235352, acc=0.36044445633888245, loss=1.6464166641235352
test: epoch 32, loss 15.254085540771484, acc=0.02222222276031971, loss=15.254085540771484
train: epoch 33, loss 1.6412296295166016, acc=0.36149999499320984, loss=1.6412296295166016
test: epoch 33, loss 15.723166465759277, acc=0.02222222276031971, loss=15.723166465759277
train: epoch 34, loss 1.6474202871322632, acc=0.36283332109451294, loss=1.6474202871322632
test: epoch 34, loss 15.467290878295898, acc=0.02222222276031971, loss=15.467290878295898
train: epoch 35, loss 1.6277499198913574, acc=0.3612777888774872, loss=1.6277499198913574
test: epoch 35, loss 15.546523094177246, acc=0.01944444514811039, loss=15.546523094177246
train: epoch 36, loss 1.62238347530365, acc=0.3726666569709778, loss=1.62238347530365
test: epoch 36, loss 15.938636779785156, acc=0.01944444514811039, loss=15.938636779785156
train: epoch 37, loss 1.6009933948516846, acc=0.3736666738986969, loss=1.6009933948516846
test: epoch 37, loss 15.894979476928711, acc=0.01944444514811039, loss=15.894979476928711
train: epoch 38, loss 1.6013083457946777, acc=0.3723333477973938, loss=1.6013083457946777
test: epoch 38, loss 15.860913276672363, acc=0.02222222276031971, loss=15.860913276672363
train: epoch 39, loss 1.5967553853988647, acc=0.3804999887943268, loss=1.5967553853988647
test: epoch 39, loss 16.100826263427734, acc=0.01944444514811039, loss=16.100826263427734
train: epoch 40, loss 1.5745866298675537, acc=0.38538888096809387, loss=1.5745866298675537
test: epoch 40, loss 15.978388786315918, acc=0.01944444514811039, loss=15.978388786315918
train: epoch 41, loss 1.5735886096954346, acc=0.3852222263813019, loss=1.5735886096954346
test: epoch 41, loss 16.165267944335938, acc=0.01944444514811039, loss=16.165267944335938
train: epoch 42, loss 1.5841459035873413, acc=0.3853333294391632, loss=1.5841459035873413
test: epoch 42, loss 16.37444496154785, acc=0.02222222276031971, loss=16.37444496154785
train: epoch 43, loss 1.5487494468688965, acc=0.38894444704055786, loss=1.5487494468688965
test: epoch 43, loss 16.28611946105957, acc=0.02222222276031971, loss=16.28611946105957
train: epoch 44, loss 1.5637779235839844, acc=0.3869999945163727, loss=1.5637779235839844
test: epoch 44, loss 16.154647827148438, acc=0.02777777798473835, loss=16.154647827148438
train: epoch 45, loss 1.5593667030334473, acc=0.3937777876853943, loss=1.5593667030334473
test: epoch 45, loss 15.630935668945312, acc=0.02500000037252903, loss=15.630935668945312
train: epoch 46, loss 1.5430408716201782, acc=0.40005555748939514, loss=1.5430408716201782
test: epoch 46, loss 16.019168853759766, acc=0.02500000037252903, loss=16.019168853759766
train: epoch 47, loss 1.5284993648529053, acc=0.40594443678855896, loss=1.5284993648529053
test: epoch 47, loss 16.22772789001465, acc=0.02500000037252903, loss=16.22772789001465
train: epoch 48, loss 1.5255130529403687, acc=0.4097222089767456, loss=1.5255130529403687
test: epoch 48, loss 16.407350540161133, acc=0.02500000037252903, loss=16.407350540161133
train: epoch 49, loss 1.5284777879714966, acc=0.4009999930858612, loss=1.5284777879714966
test: epoch 49, loss 16.50570297241211, acc=0.02500000037252903, loss=16.50570297241211
train: epoch 50, loss 1.5205546617507935, acc=0.40833333134651184, loss=1.5205546617507935
test: epoch 50, loss 16.565244674682617, acc=0.03055555559694767, loss=16.565244674682617
train: epoch 51, loss 1.514342188835144, acc=0.4108888804912567, loss=1.514342188835144
test: epoch 51, loss 16.92672348022461, acc=0.02500000037252903, loss=16.92672348022461
train: epoch 52, loss 1.4975852966308594, acc=0.41188889741897583, loss=1.4975852966308594
test: epoch 52, loss 16.841140747070312, acc=0.03611111268401146, loss=16.841140747070312
train: epoch 53, loss 1.4912229776382446, acc=0.41022223234176636, loss=1.4912229776382446
test: epoch 53, loss 16.962129592895508, acc=0.02500000037252903, loss=16.962129592895508
train: epoch 54, loss 1.4888170957565308, acc=0.41716668009757996, loss=1.4888170957565308
test: epoch 54, loss 16.876266479492188, acc=0.02222222276031971, loss=16.876266479492188
train: epoch 55, loss 1.4977662563323975, acc=0.41661110520362854, loss=1.4977662563323975
test: epoch 55, loss 17.031858444213867, acc=0.02222222276031971, loss=17.031858444213867
train: epoch 56, loss 1.4811475276947021, acc=0.42116665840148926, loss=1.4811475276947021
test: epoch 56, loss 17.613004684448242, acc=0.03055555559694767, loss=17.613004684448242
train: epoch 57, loss 1.4753583669662476, acc=0.42027777433395386, loss=1.4753583669662476
test: epoch 57, loss 17.100955963134766, acc=0.02777777798473835, loss=17.100955963134766
train: epoch 58, loss 1.463290810585022, acc=0.4264444410800934, loss=1.463290810585022
test: epoch 58, loss 16.428123474121094, acc=0.03055555559694767, loss=16.428123474121094
train: epoch 59, loss 1.4627549648284912, acc=0.4256666600704193, loss=1.4627549648284912
test: epoch 59, loss 17.263221740722656, acc=0.02500000037252903, loss=17.263221740722656
train: epoch 60, loss 1.4649136066436768, acc=0.42750000953674316, loss=1.4649136066436768
test: epoch 60, loss 16.978885650634766, acc=0.02777777798473835, loss=16.978885650634766
train: epoch 61, loss 1.4513200521469116, acc=0.4293888807296753, loss=1.4513200521469116
test: epoch 61, loss 17.169639587402344, acc=0.02777777798473835, loss=17.169639587402344
train: epoch 62, loss 1.4441227912902832, acc=0.433555543422699, loss=1.4441227912902832
test: epoch 62, loss 17.270715713500977, acc=0.03333333507180214, loss=17.270715713500977
train: epoch 63, loss 1.445216417312622, acc=0.4357222318649292, loss=1.445216417312622
test: epoch 63, loss 17.657094955444336, acc=0.02777777798473835, loss=17.657094955444336
train: epoch 64, loss 1.4415053129196167, acc=0.4391111135482788, loss=1.4415053129196167
test: epoch 64, loss 16.9965877532959, acc=0.02500000037252903, loss=16.9965877532959
train: epoch 65, loss 1.4324074983596802, acc=0.4398333430290222, loss=1.4324074983596802
test: epoch 65, loss 17.590059280395508, acc=0.02222222276031971, loss=17.590059280395508
train: epoch 66, loss 1.4222404956817627, acc=0.4454444348812103, loss=1.4222404956817627
test: epoch 66, loss 17.6888370513916, acc=0.02222222276031971, loss=17.6888370513916
train: epoch 67, loss 1.4317432641983032, acc=0.44272223114967346, loss=1.4317432641983032
test: epoch 67, loss 17.787418365478516, acc=0.02222222276031971, loss=17.787418365478516
train: epoch 68, loss 1.4162559509277344, acc=0.4506666660308838, loss=1.4162559509277344
test: epoch 68, loss 17.4808406829834, acc=0.01666666753590107, loss=17.4808406829834
train: epoch 69, loss 1.4269917011260986, acc=0.44627776741981506, loss=1.4269917011260986
test: epoch 69, loss 17.357311248779297, acc=0.02222222276031971, loss=17.357311248779297
train: epoch 70, loss 1.4058774709701538, acc=0.44699999690055847, loss=1.4058774709701538
test: epoch 70, loss 17.9508056640625, acc=0.01666666753590107, loss=17.9508056640625
train: epoch 71, loss 1.3958858251571655, acc=0.4586666524410248, loss=1.3958858251571655
test: epoch 71, loss 18.265663146972656, acc=0.02222222276031971, loss=18.265663146972656
train: epoch 72, loss 1.4095385074615479, acc=0.45027777552604675, loss=1.4095385074615479
test: epoch 72, loss 18.139429092407227, acc=0.01666666753590107, loss=18.139429092407227
train: epoch 73, loss 1.3967252969741821, acc=0.4580000042915344, loss=1.3967252969741821
test: epoch 73, loss 18.29596710205078, acc=0.01944444514811039, loss=18.29596710205078
train: epoch 74, loss 1.3864622116088867, acc=0.4577777683734894, loss=1.3864622116088867
test: epoch 74, loss 18.555828094482422, acc=0.01944444514811039, loss=18.555828094482422
train: epoch 75, loss 1.399267315864563, acc=0.4544999897480011, loss=1.399267315864563
test: epoch 75, loss 18.758840560913086, acc=0.013888888992369175, loss=18.758840560913086
train: epoch 76, loss 1.386444091796875, acc=0.45927777886390686, loss=1.386444091796875
test: epoch 76, loss 18.708759307861328, acc=0.01944444514811039, loss=18.708759307861328
train: epoch 77, loss 1.383589506149292, acc=0.4562222361564636, loss=1.383589506149292
test: epoch 77, loss 18.59076690673828, acc=0.01666666753590107, loss=18.59076690673828
train: epoch 78, loss 1.3776397705078125, acc=0.46316665410995483, loss=1.3776397705078125
test: epoch 78, loss 19.24856185913086, acc=0.01666666753590107, loss=19.24856185913086
train: epoch 79, loss 1.378928780555725, acc=0.4614444375038147, loss=1.378928780555725
test: epoch 79, loss 18.7288818359375, acc=0.01666666753590107, loss=18.7288818359375
train: epoch 80, loss 1.3809443712234497, acc=0.4629444479942322, loss=1.3809443712234497
test: epoch 80, loss 18.881925582885742, acc=0.01666666753590107, loss=18.881925582885742
train: epoch 81, loss 1.3689833879470825, acc=0.46594443917274475, loss=1.3689833879470825
test: epoch 81, loss 19.2614803314209, acc=0.013888888992369175, loss=19.2614803314209
train: epoch 82, loss 1.361164927482605, acc=0.4645000100135803, loss=1.361164927482605
test: epoch 82, loss 19.13616371154785, acc=0.013888888992369175, loss=19.13616371154785
train: epoch 83, loss 1.3580663204193115, acc=0.46622222661972046, loss=1.3580663204193115
test: epoch 83, loss 19.792985916137695, acc=0.013888888992369175, loss=19.792985916137695
train: epoch 84, loss 1.353955626487732, acc=0.47227779030799866, loss=1.353955626487732
test: epoch 84, loss 19.56550407409668, acc=0.01944444514811039, loss=19.56550407409668
train: epoch 85, loss 1.3463103771209717, acc=0.47405555844306946, loss=1.3463103771209717
test: epoch 85, loss 20.359182357788086, acc=0.01666666753590107, loss=20.359182357788086
train: epoch 86, loss 1.3354955911636353, acc=0.47644445300102234, loss=1.3354955911636353
test: epoch 86, loss 20.183414459228516, acc=0.01666666753590107, loss=20.183414459228516
train: epoch 87, loss 1.3425483703613281, acc=0.4731111228466034, loss=1.3425483703613281
test: epoch 87, loss 20.127788543701172, acc=0.013888888992369175, loss=20.127788543701172
train: epoch 88, loss 1.358535885810852, acc=0.47055554389953613, loss=1.358535885810852
test: epoch 88, loss 20.43809700012207, acc=0.01666666753590107, loss=20.43809700012207
train: epoch 89, loss 1.3327860832214355, acc=0.47138887643814087, loss=1.3327860832214355
test: epoch 89, loss 19.656736373901367, acc=0.01666666753590107, loss=19.656736373901367
train: epoch 90, loss 1.3294631242752075, acc=0.480777770280838, loss=1.3294631242752075
test: epoch 90, loss 20.030101776123047, acc=0.013888888992369175, loss=20.030101776123047
train: epoch 91, loss 1.322016954421997, acc=0.4810555577278137, loss=1.322016954421997
test: epoch 91, loss 20.120561599731445, acc=0.013888888992369175, loss=20.120561599731445
train: epoch 92, loss 1.3287878036499023, acc=0.4861111044883728, loss=1.3287878036499023
test: epoch 92, loss 20.394207000732422, acc=0.01666666753590107, loss=20.394207000732422
train: epoch 93, loss 1.333045482635498, acc=0.47966668009757996, loss=1.333045482635498
test: epoch 93, loss 20.644075393676758, acc=0.013888888992369175, loss=20.644075393676758
train: epoch 94, loss 1.3149704933166504, acc=0.4872777760028839, loss=1.3149704933166504
test: epoch 94, loss 20.08535385131836, acc=0.01666666753590107, loss=20.08535385131836
train: epoch 95, loss 1.3286834955215454, acc=0.4833333194255829, loss=1.3286834955215454
test: epoch 95, loss 19.591073989868164, acc=0.013888888992369175, loss=19.591073989868164
train: epoch 96, loss 1.3134936094284058, acc=0.48649999499320984, loss=1.3134936094284058
test: epoch 96, loss 20.191417694091797, acc=0.013888888992369175, loss=20.191417694091797
train: epoch 97, loss 1.304033637046814, acc=0.49183332920074463, loss=1.304033637046814
test: epoch 97, loss 19.432096481323242, acc=0.013888888992369175, loss=19.432096481323242
train: epoch 98, loss 1.3109349012374878, acc=0.4928888976573944, loss=1.3109349012374878
test: epoch 98, loss 20.48855209350586, acc=0.013888888992369175, loss=20.48855209350586
train: epoch 99, loss 1.3031847476959229, acc=0.4865555465221405, loss=1.3031847476959229
test: epoch 99, loss 20.435388565063477, acc=0.01666666753590107, loss=20.435388565063477
train: epoch 100, loss 1.2992714643478394, acc=0.49549999833106995, loss=1.2992714643478394
test: epoch 100, loss 20.67788314819336, acc=0.01666666753590107, loss=20.67788314819336
train: epoch 101, loss 1.3014163970947266, acc=0.4932222366333008, loss=1.3014163970947266
test: epoch 101, loss 20.670034408569336, acc=0.013888888992369175, loss=20.670034408569336
train: epoch 102, loss 1.2941559553146362, acc=0.4932222366333008, loss=1.2941559553146362
test: epoch 102, loss 20.624309539794922, acc=0.01666666753590107, loss=20.624309539794922
train: epoch 103, loss 1.299250841140747, acc=0.4952777922153473, loss=1.299250841140747
test: epoch 103, loss 20.13813018798828, acc=0.01666666753590107, loss=20.13813018798828
train: epoch 104, loss 1.2984751462936401, acc=0.4975000023841858, loss=1.2984751462936401
test: epoch 104, loss 21.50417709350586, acc=0.01666666753590107, loss=21.50417709350586
train: epoch 105, loss 1.2766493558883667, acc=0.49961110949516296, loss=1.2766493558883667
test: epoch 105, loss 21.65461540222168, acc=0.01666666753590107, loss=21.65461540222168
train: epoch 106, loss 1.2831014394760132, acc=0.4970000088214874, loss=1.2831014394760132
test: epoch 106, loss 21.3255615234375, acc=0.01666666753590107, loss=21.3255615234375
train: epoch 107, loss 1.2851356267929077, acc=0.495888888835907, loss=1.2851356267929077
test: epoch 107, loss 21.107383728027344, acc=0.013888888992369175, loss=21.107383728027344
train: epoch 108, loss 1.2799396514892578, acc=0.5043888688087463, loss=1.2799396514892578
test: epoch 108, loss 20.624286651611328, acc=0.01666666753590107, loss=20.624286651611328
train: epoch 109, loss 1.2756850719451904, acc=0.5047222375869751, loss=1.2756850719451904
test: epoch 109, loss 21.133407592773438, acc=0.01666666753590107, loss=21.133407592773438
train: epoch 110, loss 1.2718892097473145, acc=0.5010555386543274, loss=1.2718892097473145
test: epoch 110, loss 20.82171630859375, acc=0.01666666753590107, loss=20.82171630859375
train: epoch 111, loss 1.2689520120620728, acc=0.5073888897895813, loss=1.2689520120620728
test: epoch 111, loss 20.937490463256836, acc=0.01666666753590107, loss=20.937490463256836
train: epoch 112, loss 1.2677135467529297, acc=0.5053333044052124, loss=1.2677135467529297
test: epoch 112, loss 21.194189071655273, acc=0.01666666753590107, loss=21.194189071655273
train: epoch 113, loss 1.2743940353393555, acc=0.5036666393280029, loss=1.2743940353393555
test: epoch 113, loss 21.470510482788086, acc=0.01666666753590107, loss=21.470510482788086
train: epoch 114, loss 1.2551932334899902, acc=0.5083333253860474, loss=1.2551932334899902
test: epoch 114, loss 21.77704429626465, acc=0.01666666753590107, loss=21.77704429626465
train: epoch 115, loss 1.259332299232483, acc=0.5092777609825134, loss=1.259332299232483
test: epoch 115, loss 22.1375732421875, acc=0.01666666753590107, loss=22.1375732421875
train: epoch 116, loss 1.255623698234558, acc=0.5086666941642761, loss=1.255623698234558
test: epoch 116, loss 21.977933883666992, acc=0.01666666753590107, loss=21.977933883666992
train: epoch 117, loss 1.2504949569702148, acc=0.51583331823349, loss=1.2504949569702148
test: epoch 117, loss 21.972665786743164, acc=0.01666666753590107, loss=21.972665786743164
train: epoch 118, loss 1.2400577068328857, acc=0.5129444599151611, loss=1.2400577068328857
test: epoch 118, loss 21.15854263305664, acc=0.01666666753590107, loss=21.15854263305664
train: epoch 119, loss 1.2467159032821655, acc=0.5181666612625122, loss=1.2467159032821655
test: epoch 119, loss 21.430025100708008, acc=0.01666666753590107, loss=21.430025100708008
train: epoch 120, loss 1.237349510192871, acc=0.5141666531562805, loss=1.237349510192871
test: epoch 120, loss 21.705053329467773, acc=0.01666666753590107, loss=21.705053329467773
train: epoch 121, loss 1.2311723232269287, acc=0.5211666822433472, loss=1.2311723232269287
test: epoch 121, loss 22.190073013305664, acc=0.01666666753590107, loss=22.190073013305664
train: epoch 122, loss 1.241493821144104, acc=0.5209444165229797, loss=1.241493821144104
test: epoch 122, loss 21.982757568359375, acc=0.01666666753590107, loss=21.982757568359375
train: epoch 123, loss 1.2391223907470703, acc=0.5176110863685608, loss=1.2391223907470703
test: epoch 123, loss 21.872304916381836, acc=0.01666666753590107, loss=21.872304916381836
train: epoch 124, loss 1.2358065843582153, acc=0.5183333158493042, loss=1.2358065843582153
test: epoch 124, loss 22.391817092895508, acc=0.01666666753590107, loss=22.391817092895508
train: epoch 125, loss 1.2272979021072388, acc=0.5212222337722778, loss=1.2272979021072388
test: epoch 125, loss 21.742599487304688, acc=0.01666666753590107, loss=21.742599487304688
train: epoch 126, loss 1.232051134109497, acc=0.5198333263397217, loss=1.232051134109497
test: epoch 126, loss 21.240690231323242, acc=0.01666666753590107, loss=21.240690231323242
train: epoch 127, loss 1.2321453094482422, acc=0.5210555791854858, loss=1.2321453094482422
test: epoch 127, loss 21.273210525512695, acc=0.01666666753590107, loss=21.273210525512695
train: epoch 128, loss 1.2179782390594482, acc=0.5278888940811157, loss=1.2179782390594482
test: epoch 128, loss 21.120956420898438, acc=0.01666666753590107, loss=21.120956420898438
train: epoch 129, loss 1.2335702180862427, acc=0.5227222442626953, loss=1.2335702180862427
test: epoch 129, loss 21.691301345825195, acc=0.01666666753590107, loss=21.691301345825195
train: epoch 130, loss 1.2225770950317383, acc=0.5241666436195374, loss=1.2225770950317383
test: epoch 130, loss 22.026519775390625, acc=0.01666666753590107, loss=22.026519775390625
train: epoch 131, loss 1.2197082042694092, acc=0.5289444327354431, loss=1.2197082042694092
test: epoch 131, loss 22.28077507019043, acc=0.01666666753590107, loss=22.28077507019043
train: epoch 132, loss 1.2187451124191284, acc=0.5262777805328369, loss=1.2187451124191284
test: epoch 132, loss 21.84968376159668, acc=0.01666666753590107, loss=21.84968376159668
train: epoch 133, loss 1.2029167413711548, acc=0.5252222418785095, loss=1.2029167413711548
test: epoch 133, loss 22.608999252319336, acc=0.02222222276031971, loss=22.608999252319336
train: epoch 134, loss 1.2151623964309692, acc=0.5258333086967468, loss=1.2151623964309692
test: epoch 134, loss 22.33818244934082, acc=0.01666666753590107, loss=22.33818244934082
train: epoch 135, loss 1.212012529373169, acc=0.5379444360733032, loss=1.212012529373169
test: epoch 135, loss 22.32610511779785, acc=0.01666666753590107, loss=22.32610511779785
train: epoch 136, loss 1.2051328420639038, acc=0.5318889021873474, loss=1.2051328420639038
test: epoch 136, loss 22.888187408447266, acc=0.01666666753590107, loss=22.888187408447266
train: epoch 137, loss 1.2113271951675415, acc=0.5360000133514404, loss=1.2113271951675415
test: epoch 137, loss 22.157108306884766, acc=0.01666666753590107, loss=22.157108306884766
train: epoch 138, loss 1.2007100582122803, acc=0.5280555486679077, loss=1.2007100582122803
test: epoch 138, loss 22.452444076538086, acc=0.01666666753590107, loss=22.452444076538086
train: epoch 139, loss 1.1959950923919678, acc=0.5350555777549744, loss=1.1959950923919678
test: epoch 139, loss 22.819782257080078, acc=0.01666666753590107, loss=22.819782257080078
train: epoch 140, loss 1.2120646238327026, acc=0.5312222242355347, loss=1.2120646238327026
test: epoch 140, loss 22.178787231445312, acc=0.01666666753590107, loss=22.178787231445312
train: epoch 141, loss 1.2048181295394897, acc=0.5339999794960022, loss=1.2048181295394897
test: epoch 141, loss 21.713228225708008, acc=0.01666666753590107, loss=21.713228225708008
train: epoch 142, loss 1.1872005462646484, acc=0.5348333120346069, loss=1.1872005462646484
test: epoch 142, loss 21.55881690979004, acc=0.01666666753590107, loss=21.55881690979004
train: epoch 143, loss 1.192620873451233, acc=0.5439444184303284, loss=1.192620873451233
test: epoch 143, loss 22.742727279663086, acc=0.01666666753590107, loss=22.742727279663086
train: epoch 144, loss 1.178443193435669, acc=0.5372222065925598, loss=1.178443193435669
test: epoch 144, loss 23.62745475769043, acc=0.01666666753590107, loss=23.62745475769043
train: epoch 145, loss 1.1779536008834839, acc=0.5413888692855835, loss=1.1779536008834839
test: epoch 145, loss 22.761690139770508, acc=0.01666666753590107, loss=22.761690139770508
train: epoch 146, loss 1.1814011335372925, acc=0.543055534362793, loss=1.1814011335372925
test: epoch 146, loss 22.147890090942383, acc=0.01666666753590107, loss=22.147890090942383
train: epoch 147, loss 1.1897199153900146, acc=0.5398333072662354, loss=1.1897199153900146
test: epoch 147, loss 22.953065872192383, acc=0.01666666753590107, loss=22.953065872192383
train: epoch 148, loss 1.1789993047714233, acc=0.5479999780654907, loss=1.1789993047714233
test: epoch 148, loss 22.6497745513916, acc=0.01666666753590107, loss=22.6497745513916
train: epoch 149, loss 1.193585753440857, acc=0.5388333201408386, loss=1.193585753440857
test: epoch 149, loss 23.572607040405273, acc=0.01666666753590107, loss=23.572607040405273
train: epoch 150, loss 1.1859805583953857, acc=0.5407778024673462, loss=1.1859805583953857
test: epoch 150, loss 23.0344295501709, acc=0.01666666753590107, loss=23.0344295501709
