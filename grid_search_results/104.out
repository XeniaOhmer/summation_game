# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.99", "--one_hot=0", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=1719218587, receiver_embed_dim=64, save_run=0, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=1719218587, receiver_embed_dim=64, save_run=False, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.3019917011260986, acc=0.1839444488286972, loss=2.3019917011260986
test: epoch 1, loss 7.030738830566406, acc=0.05833333358168602, loss=7.030738830566406
train: epoch 2, loss 1.5668270587921143, acc=0.3498888909816742, loss=1.5668270587921143
test: epoch 2, loss 6.8942179679870605, acc=0.07777778059244156, loss=6.8942179679870605
train: epoch 3, loss 1.3036555051803589, acc=0.4546111226081848, loss=1.3036555051803589
test: epoch 3, loss 5.707979679107666, acc=0.11388888955116272, loss=5.707979679107666
train: epoch 4, loss 1.1623408794403076, acc=0.5151110887527466, loss=1.1623408794403076
test: epoch 4, loss 5.1303815841674805, acc=0.11944444477558136, loss=5.1303815841674805
train: epoch 5, loss 1.0456429719924927, acc=0.5747222304344177, loss=1.0456429719924927
test: epoch 5, loss 6.00084114074707, acc=0.1527777761220932, loss=6.00084114074707
train: epoch 6, loss 0.9453884363174438, acc=0.6180555820465088, loss=0.9453884363174438
test: epoch 6, loss 5.1534647941589355, acc=0.21111111342906952, loss=5.1534647941589355
train: epoch 7, loss 0.8842803239822388, acc=0.6362777948379517, loss=0.8842803239822388
test: epoch 7, loss 4.136175155639648, acc=0.2777777910232544, loss=4.136175155639648
train: epoch 8, loss 0.8400638699531555, acc=0.6562777757644653, loss=0.8400638699531555
test: epoch 8, loss 2.999444007873535, acc=0.21388888359069824, loss=2.999444007873535
train: epoch 9, loss 0.8088908791542053, acc=0.6743888854980469, loss=0.8088908791542053
test: epoch 9, loss 2.887176513671875, acc=0.28611111640930176, loss=2.887176513671875
train: epoch 10, loss 0.7513547539710999, acc=0.6964444518089294, loss=0.7513547539710999
test: epoch 10, loss 4.097456455230713, acc=0.17777778208255768, loss=4.097456455230713
train: epoch 11, loss 0.7194117903709412, acc=0.7126111388206482, loss=0.7194117903709412
test: epoch 11, loss 2.9494988918304443, acc=0.3222222328186035, loss=2.9494988918304443
train: epoch 12, loss 0.6848947405815125, acc=0.7271111011505127, loss=0.6848947405815125
test: epoch 12, loss 2.203763484954834, acc=0.27222222089767456, loss=2.203763484954834
train: epoch 13, loss 0.6668460369110107, acc=0.7347221970558167, loss=0.6668460369110107
test: epoch 13, loss 2.4874212741851807, acc=0.29722222685813904, loss=2.4874212741851807
train: epoch 14, loss 0.6417875289916992, acc=0.7447777986526489, loss=0.6417875289916992
test: epoch 14, loss 2.685302734375, acc=0.3166666626930237, loss=2.685302734375
train: epoch 15, loss 0.6142966151237488, acc=0.7605000138282776, loss=0.6142966151237488
test: epoch 15, loss 2.492379903793335, acc=0.2638888955116272, loss=2.492379903793335
train: epoch 16, loss 0.6055434942245483, acc=0.7602221965789795, loss=0.6055434942245483
test: epoch 16, loss 2.2659945487976074, acc=0.34166666865348816, loss=2.2659945487976074
train: epoch 17, loss 0.584852933883667, acc=0.7717221975326538, loss=0.584852933883667
test: epoch 17, loss 2.7966201305389404, acc=0.2638888955116272, loss=2.7966201305389404
train: epoch 18, loss 0.5813614726066589, acc=0.7748888731002808, loss=0.5813614726066589
test: epoch 18, loss 2.63989520072937, acc=0.2944444417953491, loss=2.63989520072937
train: epoch 19, loss 0.561317503452301, acc=0.7805555462837219, loss=0.561317503452301
test: epoch 19, loss 2.7255847454071045, acc=0.3027777671813965, loss=2.7255847454071045
train: epoch 20, loss 0.5732578039169312, acc=0.7739999890327454, loss=0.5732578039169312
test: epoch 20, loss 2.4167799949645996, acc=0.3777777850627899, loss=2.4167799949645996
train: epoch 21, loss 0.5736499428749084, acc=0.7766110897064209, loss=0.5736499428749084
test: epoch 21, loss 2.0043962001800537, acc=0.39444443583488464, loss=2.0043962001800537
train: epoch 22, loss 0.527474045753479, acc=0.7937777638435364, loss=0.527474045753479
test: epoch 22, loss 2.5513756275177, acc=0.3583333194255829, loss=2.5513756275177
train: epoch 23, loss 0.5267850756645203, acc=0.793833315372467, loss=0.5267850756645203
test: epoch 23, loss 2.2344353199005127, acc=0.2750000059604645, loss=2.2344353199005127
train: epoch 24, loss 0.5318698287010193, acc=0.7916666865348816, loss=0.5318698287010193
test: epoch 24, loss 1.95547354221344, acc=0.28333333134651184, loss=1.95547354221344
train: epoch 25, loss 0.5318832397460938, acc=0.7907778024673462, loss=0.5318832397460938
test: epoch 25, loss 2.147850513458252, acc=0.28333333134651184, loss=2.147850513458252
train: epoch 26, loss 0.5490617752075195, acc=0.7806666493415833, loss=0.5490617752075195
test: epoch 26, loss 2.253737688064575, acc=0.35277777910232544, loss=2.253737688064575
train: epoch 27, loss 0.4947354197502136, acc=0.8121111392974854, loss=0.4947354197502136
test: epoch 27, loss 2.0999338626861572, acc=0.36944442987442017, loss=2.0999338626861572
train: epoch 28, loss 0.5098913311958313, acc=0.8072222471237183, loss=0.5098913311958313
test: epoch 28, loss 1.7295912504196167, acc=0.4861111044883728, loss=1.7295912504196167
train: epoch 29, loss 0.5028051733970642, acc=0.8003333210945129, loss=0.5028051733970642
test: epoch 29, loss 1.3494246006011963, acc=0.4555555582046509, loss=1.3494246006011963
train: epoch 30, loss 0.5128405690193176, acc=0.7954444289207458, loss=0.5128405690193176
test: epoch 30, loss 2.151867151260376, acc=0.36944442987442017, loss=2.151867151260376
train: epoch 31, loss 0.5078077912330627, acc=0.801111102104187, loss=0.5078077912330627
test: epoch 31, loss 2.0036935806274414, acc=0.38055557012557983, loss=2.0036935806274414
train: epoch 32, loss 0.4934747815132141, acc=0.8078333139419556, loss=0.4934747815132141
test: epoch 32, loss 1.5940991640090942, acc=0.4055555462837219, loss=1.5940991640090942
train: epoch 33, loss 0.47524964809417725, acc=0.8177222013473511, loss=0.47524964809417725
test: epoch 33, loss 2.1503798961639404, acc=0.36944442987442017, loss=2.1503798961639404
train: epoch 34, loss 0.4697710871696472, acc=0.8176110982894897, loss=0.4697710871696472
test: epoch 34, loss 1.7134596109390259, acc=0.4055555462837219, loss=1.7134596109390259
train: epoch 35, loss 0.4681409001350403, acc=0.8127222061157227, loss=0.4681409001350403
test: epoch 35, loss 1.8668042421340942, acc=0.4138889014720917, loss=1.8668042421340942
train: epoch 36, loss 0.5101679563522339, acc=0.800944447517395, loss=0.5101679563522339
test: epoch 36, loss 2.022212266921997, acc=0.375, loss=2.022212266921997
train: epoch 37, loss 0.47512292861938477, acc=0.8112778067588806, loss=0.47512292861938477
test: epoch 37, loss 1.2994312047958374, acc=0.5305555462837219, loss=1.2994312047958374
train: epoch 38, loss 0.4555869996547699, acc=0.8233888745307922, loss=0.4555869996547699
test: epoch 38, loss 2.154817819595337, acc=0.3305555582046509, loss=2.154817819595337
train: epoch 39, loss 0.46918967366218567, acc=0.8169999718666077, loss=0.46918967366218567
test: epoch 39, loss 1.6498764753341675, acc=0.4000000059604645, loss=1.6498764753341675
train: epoch 40, loss 0.47279319167137146, acc=0.8118888735771179, loss=0.47279319167137146
test: epoch 40, loss 1.7652513980865479, acc=0.3583333194255829, loss=1.7652513980865479
train: epoch 41, loss 0.4504075348377228, acc=0.8226110935211182, loss=0.4504075348377228
test: epoch 41, loss 1.4109535217285156, acc=0.4749999940395355, loss=1.4109535217285156
train: epoch 42, loss 0.44428956508636475, acc=0.8236666917800903, loss=0.44428956508636475
test: epoch 42, loss 1.6470973491668701, acc=0.4749999940395355, loss=1.6470973491668701
train: epoch 43, loss 0.44955524802207947, acc=0.8264999985694885, loss=0.44955524802207947
test: epoch 43, loss 1.1274923086166382, acc=0.5638889074325562, loss=1.1274923086166382
train: epoch 44, loss 0.4735095500946045, acc=0.8147777915000916, loss=0.4735095500946045
test: epoch 44, loss 1.6539723873138428, acc=0.4611110985279083, loss=1.6539723873138428
train: epoch 45, loss 0.4399385154247284, acc=0.8301110863685608, loss=0.4399385154247284
test: epoch 45, loss 1.168985366821289, acc=0.5611110925674438, loss=1.168985366821289
train: epoch 46, loss 0.4587942957878113, acc=0.820888876914978, loss=0.4587942957878113
test: epoch 46, loss 1.2326254844665527, acc=0.5166666507720947, loss=1.2326254844665527
train: epoch 47, loss 0.4331513047218323, acc=0.8293333053588867, loss=0.4331513047218323
test: epoch 47, loss 1.549360990524292, acc=0.375, loss=1.549360990524292
train: epoch 48, loss 0.43440356850624084, acc=0.831944465637207, loss=0.43440356850624084
test: epoch 48, loss 1.262149453163147, acc=0.4416666626930237, loss=1.262149453163147
train: epoch 49, loss 0.4616169333457947, acc=0.8165000081062317, loss=0.4616169333457947
test: epoch 49, loss 1.3671283721923828, acc=0.5249999761581421, loss=1.3671283721923828
train: epoch 50, loss 0.43931469321250916, acc=0.8293889164924622, loss=0.43931469321250916
test: epoch 50, loss 1.2011404037475586, acc=0.5666666626930237, loss=1.2011404037475586
train: epoch 51, loss 0.4380878508090973, acc=0.8308333158493042, loss=0.4380878508090973
test: epoch 51, loss 1.5151433944702148, acc=0.4722222089767456, loss=1.5151433944702148
train: epoch 52, loss 0.4176715910434723, acc=0.8374999761581421, loss=0.4176715910434723
test: epoch 52, loss 1.3106900453567505, acc=0.5222222208976746, loss=1.3106900453567505
train: epoch 53, loss 0.4403958320617676, acc=0.8264444470405579, loss=0.4403958320617676
test: epoch 53, loss 1.0871772766113281, acc=0.5722222328186035, loss=1.0871772766113281
train: epoch 54, loss 0.428011953830719, acc=0.8334444165229797, loss=0.428011953830719
test: epoch 54, loss 1.1676169633865356, acc=0.5222222208976746, loss=1.1676169633865356
train: epoch 55, loss 0.41852807998657227, acc=0.8382777571678162, loss=0.41852807998657227
test: epoch 55, loss 1.5769565105438232, acc=0.4305555522441864, loss=1.5769565105438232
train: epoch 56, loss 0.40370973944664, acc=0.8412222266197205, loss=0.40370973944664
test: epoch 56, loss 1.0304917097091675, acc=0.5972222089767456, loss=1.0304917097091675
train: epoch 57, loss 0.4050438404083252, acc=0.8420000076293945, loss=0.4050438404083252
test: epoch 57, loss 1.3204950094223022, acc=0.5555555820465088, loss=1.3204950094223022
train: epoch 58, loss 0.4326872229576111, acc=0.8270555734634399, loss=0.4326872229576111
test: epoch 58, loss 0.963675856590271, acc=0.5666666626930237, loss=0.963675856590271
train: epoch 59, loss 0.4023682177066803, acc=0.8417778015136719, loss=0.4023682177066803
test: epoch 59, loss 0.9341400265693665, acc=0.5833333134651184, loss=0.9341400265693665
train: epoch 60, loss 0.43044808506965637, acc=0.8293333053588867, loss=0.43044808506965637
test: epoch 60, loss 0.8567994236946106, acc=0.5722222328186035, loss=0.8567994236946106
train: epoch 61, loss 0.3991292417049408, acc=0.8469444513320923, loss=0.3991292417049408
test: epoch 61, loss 0.8504708409309387, acc=0.6583333611488342, loss=0.8504708409309387
train: epoch 62, loss 0.39845675230026245, acc=0.8427222371101379, loss=0.39845675230026245
test: epoch 62, loss 1.1049302816390991, acc=0.5111111402511597, loss=1.1049302816390991
train: epoch 63, loss 0.406464546918869, acc=0.8386666774749756, loss=0.406464546918869
test: epoch 63, loss 0.8723183870315552, acc=0.5861111283302307, loss=0.8723183870315552
train: epoch 64, loss 0.4113004803657532, acc=0.8422222137451172, loss=0.4113004803657532
test: epoch 64, loss 0.8359941244125366, acc=0.6638888716697693, loss=0.8359941244125366
train: epoch 65, loss 0.39074045419692993, acc=0.8484444618225098, loss=0.39074045419692993
test: epoch 65, loss 1.1431089639663696, acc=0.550000011920929, loss=1.1431089639663696
train: epoch 66, loss 0.39378079771995544, acc=0.8453333377838135, loss=0.39378079771995544
test: epoch 66, loss 0.8445936441421509, acc=0.6694444417953491, loss=0.8445936441421509
train: epoch 67, loss 0.4135688245296478, acc=0.8383888602256775, loss=0.4135688245296478
test: epoch 67, loss 1.0034383535385132, acc=0.5444444417953491, loss=1.0034383535385132
train: epoch 68, loss 0.38167351484298706, acc=0.8497222065925598, loss=0.38167351484298706
test: epoch 68, loss 1.0709359645843506, acc=0.6111111044883728, loss=1.0709359645843506
train: epoch 69, loss 0.43224745988845825, acc=0.8301110863685608, loss=0.43224745988845825
test: epoch 69, loss 1.0980428457260132, acc=0.5944444537162781, loss=1.0980428457260132
train: epoch 70, loss 0.37679803371429443, acc=0.8527777791023254, loss=0.37679803371429443
test: epoch 70, loss 0.9858910441398621, acc=0.5833333134651184, loss=0.9858910441398621
train: epoch 71, loss 0.4193730652332306, acc=0.8368889093399048, loss=0.4193730652332306
test: epoch 71, loss 1.09761643409729, acc=0.5805555582046509, loss=1.09761643409729
train: epoch 72, loss 0.39565858244895935, acc=0.8457777500152588, loss=0.39565858244895935
test: epoch 72, loss 1.1410902738571167, acc=0.6111111044883728, loss=1.1410902738571167
train: epoch 73, loss 0.3958778381347656, acc=0.8491111397743225, loss=0.3958778381347656
test: epoch 73, loss 1.1050045490264893, acc=0.6944444179534912, loss=1.1050045490264893
train: epoch 74, loss 0.4088696837425232, acc=0.8391666412353516, loss=0.4088696837425232
test: epoch 74, loss 0.9412373900413513, acc=0.6416666507720947, loss=0.9412373900413513
train: epoch 75, loss 0.38835471868515015, acc=0.8495555520057678, loss=0.38835471868515015
test: epoch 75, loss 0.8206349015235901, acc=0.6833333373069763, loss=0.8206349015235901
train: epoch 76, loss 0.39131486415863037, acc=0.8482221961021423, loss=0.39131486415863037
test: epoch 76, loss 1.2178627252578735, acc=0.5833333134651184, loss=1.2178627252578735
train: epoch 77, loss 0.41047799587249756, acc=0.8406111001968384, loss=0.41047799587249756
test: epoch 77, loss 0.9904054403305054, acc=0.6305555701255798, loss=0.9904054403305054
train: epoch 78, loss 0.4026186466217041, acc=0.8414444327354431, loss=0.4026186466217041
test: epoch 78, loss 0.8192259073257446, acc=0.675000011920929, loss=0.8192259073257446
train: epoch 79, loss 0.4110938012599945, acc=0.8426111340522766, loss=0.4110938012599945
test: epoch 79, loss 0.7707874178886414, acc=0.625, loss=0.7707874178886414
train: epoch 80, loss 0.39199724793434143, acc=0.846666693687439, loss=0.39199724793434143
test: epoch 80, loss 0.8039228916168213, acc=0.6305555701255798, loss=0.8039228916168213
train: epoch 81, loss 0.3841628432273865, acc=0.8491111397743225, loss=0.3841628432273865
test: epoch 81, loss 0.8893867135047913, acc=0.6111111044883728, loss=0.8893867135047913
train: epoch 82, loss 0.38938629627227783, acc=0.8438888788223267, loss=0.38938629627227783
test: epoch 82, loss 0.7709949016571045, acc=0.6361111402511597, loss=0.7709949016571045
train: epoch 83, loss 0.40444302558898926, acc=0.8442777991294861, loss=0.40444302558898926
test: epoch 83, loss 0.8564185500144958, acc=0.6638888716697693, loss=0.8564185500144958
train: epoch 84, loss 0.38040992617607117, acc=0.851722240447998, loss=0.38040992617607117
test: epoch 84, loss 1.0081839561462402, acc=0.6111111044883728, loss=1.0081839561462402
train: epoch 85, loss 0.38671866059303284, acc=0.8485555648803711, loss=0.38671866059303284
test: epoch 85, loss 0.7713530659675598, acc=0.6833333373069763, loss=0.7713530659675598
train: epoch 86, loss 0.3900497853755951, acc=0.847944438457489, loss=0.3900497853755951
test: epoch 86, loss 0.6908865571022034, acc=0.6666666865348816, loss=0.6908865571022034
train: epoch 87, loss 0.3858230412006378, acc=0.8506666421890259, loss=0.3858230412006378
test: epoch 87, loss 0.7556743621826172, acc=0.6472222208976746, loss=0.7556743621826172
train: epoch 88, loss 0.3834981620311737, acc=0.8462222218513489, loss=0.3834981620311737
test: epoch 88, loss 0.9074756503105164, acc=0.6861110925674438, loss=0.9074756503105164
train: epoch 89, loss 0.3994142413139343, acc=0.843666672706604, loss=0.3994142413139343
test: epoch 89, loss 0.938581109046936, acc=0.6111111044883728, loss=0.938581109046936
train: epoch 90, loss 0.3835543692111969, acc=0.8504444360733032, loss=0.3835543692111969
test: epoch 90, loss 0.902533769607544, acc=0.6277777552604675, loss=0.902533769607544
train: epoch 91, loss 0.385794073343277, acc=0.8531110882759094, loss=0.385794073343277
test: epoch 91, loss 0.8028971552848816, acc=0.6472222208976746, loss=0.8028971552848816
train: epoch 92, loss 0.3833256959915161, acc=0.8522777557373047, loss=0.3833256959915161
test: epoch 92, loss 0.7981769442558289, acc=0.7055555582046509, loss=0.7981769442558289
train: epoch 93, loss 0.377352774143219, acc=0.8554999828338623, loss=0.377352774143219
test: epoch 93, loss 0.8391225337982178, acc=0.675000011920929, loss=0.8391225337982178
train: epoch 94, loss 0.38042333722114563, acc=0.8535555601119995, loss=0.38042333722114563
test: epoch 94, loss 0.9418764114379883, acc=0.6333333253860474, loss=0.9418764114379883
train: epoch 95, loss 0.4334789216518402, acc=0.8302222490310669, loss=0.4334789216518402
test: epoch 95, loss 0.7558990716934204, acc=0.7083333134651184, loss=0.7558990716934204
train: epoch 96, loss 0.3851272463798523, acc=0.851111114025116, loss=0.3851272463798523
test: epoch 96, loss 0.6983441710472107, acc=0.7194444537162781, loss=0.6983441710472107
train: epoch 97, loss 0.4047169089317322, acc=0.8434444665908813, loss=0.4047169089317322
test: epoch 97, loss 0.8221083283424377, acc=0.6694444417953491, loss=0.8221083283424377
train: epoch 98, loss 0.41430744528770447, acc=0.8377222418785095, loss=0.41430744528770447
test: epoch 98, loss 0.7968310117721558, acc=0.6861110925674438, loss=0.7968310117721558
train: epoch 99, loss 0.37987884879112244, acc=0.85188889503479, loss=0.37987884879112244
test: epoch 99, loss 0.6836415529251099, acc=0.6833333373069763, loss=0.6836415529251099
train: epoch 100, loss 0.37640535831451416, acc=0.8530555367469788, loss=0.37640535831451416
test: epoch 100, loss 0.8055782914161682, acc=0.6944444179534912, loss=0.8055782914161682
train: epoch 101, loss 0.40208178758621216, acc=0.8452222347259521, loss=0.40208178758621216
test: epoch 101, loss 0.7531085014343262, acc=0.6861110925674438, loss=0.7531085014343262
train: epoch 102, loss 0.38014695048332214, acc=0.8547222018241882, loss=0.38014695048332214
test: epoch 102, loss 0.6974926590919495, acc=0.7027778029441833, loss=0.6974926590919495
train: epoch 103, loss 0.3814186155796051, acc=0.8553333282470703, loss=0.3814186155796051
test: epoch 103, loss 0.8337100744247437, acc=0.6527777910232544, loss=0.8337100744247437
train: epoch 104, loss 0.3576447367668152, acc=0.8628888726234436, loss=0.3576447367668152
test: epoch 104, loss 0.8047875761985779, acc=0.6972222328186035, loss=0.8047875761985779
train: epoch 105, loss 0.38752004504203796, acc=0.8517777919769287, loss=0.38752004504203796
test: epoch 105, loss 0.7075138688087463, acc=0.6916666626930237, loss=0.7075138688087463
train: epoch 106, loss 0.3716799020767212, acc=0.8579444289207458, loss=0.3716799020767212
test: epoch 106, loss 0.9506105184555054, acc=0.6888889074325562, loss=0.9506105184555054
train: epoch 107, loss 0.39084282517433167, acc=0.8454444408416748, loss=0.39084282517433167
test: epoch 107, loss 0.7316599488258362, acc=0.699999988079071, loss=0.7316599488258362
train: epoch 108, loss 0.3935212194919586, acc=0.8504999876022339, loss=0.3935212194919586
test: epoch 108, loss 0.6937428712844849, acc=0.7194444537162781, loss=0.6937428712844849
train: epoch 109, loss 0.35066765546798706, acc=0.8663333058357239, loss=0.35066765546798706
test: epoch 109, loss 0.7539684772491455, acc=0.6388888955116272, loss=0.7539684772491455
train: epoch 110, loss 0.4105268120765686, acc=0.8402777910232544, loss=0.4105268120765686
test: epoch 110, loss 0.8567476272583008, acc=0.6944444179534912, loss=0.8567476272583008
train: epoch 111, loss 0.35954833030700684, acc=0.8661110997200012, loss=0.35954833030700684
test: epoch 111, loss 0.7405238151550293, acc=0.7055555582046509, loss=0.7405238151550293
train: epoch 112, loss 0.38787373900413513, acc=0.8544999957084656, loss=0.38787373900413513
test: epoch 112, loss 0.8682754635810852, acc=0.6555555462837219, loss=0.8682754635810852
train: epoch 113, loss 0.3425520360469818, acc=0.8703888654708862, loss=0.3425520360469818
test: epoch 113, loss 0.6250256299972534, acc=0.7527777552604675, loss=0.6250256299972534
train: epoch 114, loss 0.3875267207622528, acc=0.8499444723129272, loss=0.3875267207622528
test: epoch 114, loss 0.9053627252578735, acc=0.6666666865348816, loss=0.9053627252578735
train: epoch 115, loss 0.3713850975036621, acc=0.8548333048820496, loss=0.3713850975036621
test: epoch 115, loss 0.7623772621154785, acc=0.6722221970558167, loss=0.7623772621154785
train: epoch 116, loss 0.36562228202819824, acc=0.8593888878822327, loss=0.36562228202819824
test: epoch 116, loss 0.7576994895935059, acc=0.699999988079071, loss=0.7576994895935059
train: epoch 117, loss 0.33505910634994507, acc=0.8751111030578613, loss=0.33505910634994507
test: epoch 117, loss 0.8269885778427124, acc=0.7055555582046509, loss=0.8269885778427124
train: epoch 118, loss 0.377303808927536, acc=0.8575000166893005, loss=0.377303808927536
test: epoch 118, loss 0.7969251871109009, acc=0.6888889074325562, loss=0.7969251871109009
train: epoch 119, loss 0.3512241542339325, acc=0.8638333082199097, loss=0.3512241542339325
test: epoch 119, loss 0.5763106942176819, acc=0.7472222447395325, loss=0.5763106942176819
train: epoch 120, loss 0.3745696246623993, acc=0.8507221937179565, loss=0.3745696246623993
test: epoch 120, loss 0.8725496530532837, acc=0.7138888835906982, loss=0.8725496530532837
train: epoch 121, loss 0.37112072110176086, acc=0.8572221994400024, loss=0.37112072110176086
test: epoch 121, loss 0.6701192259788513, acc=0.7444444298744202, loss=0.6701192259788513
train: epoch 122, loss 0.36500290036201477, acc=0.8612777590751648, loss=0.36500290036201477
test: epoch 122, loss 0.5748240947723389, acc=0.7027778029441833, loss=0.5748240947723389
train: epoch 123, loss 0.40410271286964417, acc=0.8223888874053955, loss=0.40410271286964417
test: epoch 123, loss 0.8199653029441833, acc=0.6638888716697693, loss=0.8199653029441833
train: epoch 124, loss 0.3608701825141907, acc=0.8481666445732117, loss=0.3608701825141907
test: epoch 124, loss 0.9218947887420654, acc=0.6611111164093018, loss=0.9218947887420654
train: epoch 125, loss 0.3675633668899536, acc=0.8592222332954407, loss=0.3675633668899536
test: epoch 125, loss 0.6130812168121338, acc=0.7472222447395325, loss=0.6130812168121338
train: epoch 126, loss 0.34087368845939636, acc=0.8705000281333923, loss=0.34087368845939636
test: epoch 126, loss 0.6791367530822754, acc=0.75, loss=0.6791367530822754
train: epoch 127, loss 0.38120773434638977, acc=0.8529444336891174, loss=0.38120773434638977
test: epoch 127, loss 0.6841645836830139, acc=0.7055555582046509, loss=0.6841645836830139
train: epoch 128, loss 0.3241271376609802, acc=0.8753888607025146, loss=0.3241271376609802
test: epoch 128, loss 0.6878031492233276, acc=0.75, loss=0.6878031492233276
train: epoch 129, loss 0.37480422854423523, acc=0.8556110858917236, loss=0.37480422854423523
test: epoch 129, loss 0.6252470016479492, acc=0.7472222447395325, loss=0.6252470016479492
train: epoch 130, loss 0.32122698426246643, acc=0.8771666884422302, loss=0.32122698426246643
test: epoch 130, loss 0.6050856113433838, acc=0.75, loss=0.6050856113433838
train: epoch 131, loss 0.36253422498703003, acc=0.8581110835075378, loss=0.36253422498703003
test: epoch 131, loss 0.6754508018493652, acc=0.7361111044883728, loss=0.6754508018493652
train: epoch 132, loss 0.35194456577301025, acc=0.8644999861717224, loss=0.35194456577301025
test: epoch 132, loss 0.633726954460144, acc=0.7416666746139526, loss=0.633726954460144
train: epoch 133, loss 0.3091326355934143, acc=0.8817222118377686, loss=0.3091326355934143
test: epoch 133, loss 0.7029340267181396, acc=0.7388888597488403, loss=0.7029340267181396
train: epoch 134, loss 0.3196926414966583, acc=0.8811666369438171, loss=0.3196926414966583
test: epoch 134, loss 0.7092155814170837, acc=0.7472222447395325, loss=0.7092155814170837
train: epoch 135, loss 0.3305227756500244, acc=0.878777801990509, loss=0.3305227756500244
test: epoch 135, loss 0.7086830139160156, acc=0.75, loss=0.7086830139160156
train: epoch 136, loss 0.36063358187675476, acc=0.8607222437858582, loss=0.36063358187675476
test: epoch 136, loss 0.6360134482383728, acc=0.75, loss=0.6360134482383728
train: epoch 137, loss 0.36702778935432434, acc=0.8585555553436279, loss=0.36702778935432434
test: epoch 137, loss 0.5906969308853149, acc=0.7527777552604675, loss=0.5906969308853149
train: epoch 138, loss 0.3636898398399353, acc=0.8655555844306946, loss=0.3636898398399353
test: epoch 138, loss 0.8190955519676208, acc=0.7250000238418579, loss=0.8190955519676208
train: epoch 139, loss 0.3811300992965698, acc=0.8562222123146057, loss=0.3811300992965698
test: epoch 139, loss 0.6230602264404297, acc=0.75, loss=0.6230602264404297
train: epoch 140, loss 0.3589918911457062, acc=0.8605555295944214, loss=0.3589918911457062
test: epoch 140, loss 0.5199741721153259, acc=0.7583333253860474, loss=0.5199741721153259
train: epoch 141, loss 0.33813410997390747, acc=0.8698889017105103, loss=0.33813410997390747
test: epoch 141, loss 0.663752019405365, acc=0.7388888597488403, loss=0.663752019405365
train: epoch 142, loss 0.31430771946907043, acc=0.8808333277702332, loss=0.31430771946907043
test: epoch 142, loss 0.6042253375053406, acc=0.7444444298744202, loss=0.6042253375053406
train: epoch 143, loss 0.3432101309299469, acc=0.8681111335754395, loss=0.3432101309299469
test: epoch 143, loss 0.640735924243927, acc=0.7416666746139526, loss=0.640735924243927
train: epoch 144, loss 0.3321329951286316, acc=0.8754444718360901, loss=0.3321329951286316
test: epoch 144, loss 0.641834557056427, acc=0.7444444298744202, loss=0.641834557056427
train: epoch 145, loss 0.3138699531555176, acc=0.8791666626930237, loss=0.3138699531555176
test: epoch 145, loss 0.6038596034049988, acc=0.75, loss=0.6038596034049988
train: epoch 146, loss 0.3587745726108551, acc=0.8532778024673462, loss=0.3587745726108551
test: epoch 146, loss 0.8159064650535583, acc=0.6666666865348816, loss=0.8159064650535583
train: epoch 147, loss 0.37217387557029724, acc=0.8411666750907898, loss=0.37217387557029724
test: epoch 147, loss 0.5903298258781433, acc=0.7277777791023254, loss=0.5903298258781433
train: epoch 148, loss 0.3822040557861328, acc=0.8370555639266968, loss=0.3822040557861328
test: epoch 148, loss 0.641962468624115, acc=0.7166666388511658, loss=0.641962468624115
train: epoch 149, loss 0.38334953784942627, acc=0.8390555381774902, loss=0.38334953784942627
test: epoch 149, loss 1.125831127166748, acc=0.6666666865348816, loss=1.125831127166748
train: epoch 150, loss 0.3894539177417755, acc=0.8389999866485596, loss=0.3894539177417755
test: epoch 150, loss 0.6698220372200012, acc=0.7194444537162781, loss=0.6698220372200012
