# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=1", "--temp_decay=0.995", "--one_hot=true", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1024462418, receiver_embed_dim=128, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.0619139671325684, acc=0.06422222405672073, loss=3.0619139671325684
test: epoch 1, loss 2.7005982398986816, acc=0.08611111342906952, loss=2.7005982398986816
train: epoch 2, loss 2.337453603744507, acc=0.1591111123561859, loss=2.337453603744507
test: epoch 2, loss 2.1337730884552, acc=0.20277777314186096, loss=2.1337730884552
train: epoch 3, loss 2.0557141304016113, acc=0.20783333480358124, loss=2.0557141304016113
test: epoch 3, loss 2.0256829261779785, acc=0.21388888359069824, loss=2.0256829261779785
train: epoch 4, loss 1.9426065683364868, acc=0.2452777773141861, loss=1.9426065683364868
test: epoch 4, loss 1.9797208309173584, acc=0.2611111104488373, loss=1.9797208309173584
train: epoch 5, loss 1.8851351737976074, acc=0.2587222158908844, loss=1.8851351737976074
test: epoch 5, loss 1.9509155750274658, acc=0.25833332538604736, loss=1.9509155750274658
train: epoch 6, loss 1.8397349119186401, acc=0.26466667652130127, loss=1.8397349119186401
test: epoch 6, loss 1.9023969173431396, acc=0.2666666805744171, loss=1.9023969173431396
train: epoch 7, loss 1.7853262424468994, acc=0.28922221064567566, loss=1.7853262424468994
test: epoch 7, loss 1.8039569854736328, acc=0.30000001192092896, loss=1.8039569854736328
train: epoch 8, loss 1.7484896183013916, acc=0.30177778005599976, loss=1.7484896183013916
test: epoch 8, loss 1.8078620433807373, acc=0.3027777671813965, loss=1.8078620433807373
train: epoch 9, loss 1.7095646858215332, acc=0.3137222230434418, loss=1.7095646858215332
test: epoch 9, loss 1.7886773347854614, acc=0.3027777671813965, loss=1.7886773347854614
train: epoch 10, loss 1.7085744142532349, acc=0.31238889694213867, loss=1.7085744142532349
test: epoch 10, loss 1.7323238849639893, acc=0.30000001192092896, loss=1.7323238849639893
train: epoch 11, loss 1.6643770933151245, acc=0.31938889622688293, loss=1.6643770933151245
test: epoch 11, loss 1.7195807695388794, acc=0.3055555522441864, loss=1.7195807695388794
train: epoch 12, loss 1.6427209377288818, acc=0.33327779173851013, loss=1.6427209377288818
test: epoch 12, loss 1.8010647296905518, acc=0.31111112236976624, loss=1.8010647296905518
train: epoch 13, loss 1.5876392126083374, acc=0.351666659116745, loss=1.5876392126083374
test: epoch 13, loss 1.8594655990600586, acc=0.3027777671813965, loss=1.8594655990600586
train: epoch 14, loss 1.5046638250350952, acc=0.3803333342075348, loss=1.5046638250350952
test: epoch 14, loss 1.9597591161727905, acc=0.3027777671813965, loss=1.9597591161727905
train: epoch 15, loss 1.453813910484314, acc=0.3918333351612091, loss=1.453813910484314
test: epoch 15, loss 2.1558144092559814, acc=0.2888889014720917, loss=2.1558144092559814
train: epoch 16, loss 1.4179171323776245, acc=0.39561110734939575, loss=1.4179171323776245
test: epoch 16, loss 1.813415765762329, acc=0.3333333432674408, loss=1.813415765762329
train: epoch 17, loss 1.3477578163146973, acc=0.41366666555404663, loss=1.3477578163146973
test: epoch 17, loss 1.5359752178192139, acc=0.36666667461395264, loss=1.5359752178192139
train: epoch 18, loss 1.2743421792984009, acc=0.4247777760028839, loss=1.2743421792984009
test: epoch 18, loss 1.6038110256195068, acc=0.36944442987442017, loss=1.6038110256195068
train: epoch 19, loss 1.2266781330108643, acc=0.4397222101688385, loss=1.2266781330108643
test: epoch 19, loss 1.4786580801010132, acc=0.3888888955116272, loss=1.4786580801010132
train: epoch 20, loss 1.186876893043518, acc=0.4460555613040924, loss=1.186876893043518
test: epoch 20, loss 1.3077101707458496, acc=0.4138889014720917, loss=1.3077101707458496
train: epoch 21, loss 1.1176552772521973, acc=0.4741111099720001, loss=1.1176552772521973
test: epoch 21, loss 1.3950802087783813, acc=0.42222222685813904, loss=1.3950802087783813
train: epoch 22, loss 1.0188603401184082, acc=0.5160555839538574, loss=1.0188603401184082
test: epoch 22, loss 1.4471485614776611, acc=0.4138889014720917, loss=1.4471485614776611
train: epoch 23, loss 1.0256521701812744, acc=0.5138888955116272, loss=1.0256521701812744
test: epoch 23, loss 1.2497864961624146, acc=0.43611112236976624, loss=1.2497864961624146
train: epoch 24, loss 0.9387218952178955, acc=0.5461111068725586, loss=0.9387218952178955
test: epoch 24, loss 1.135231375694275, acc=0.4694444537162781, loss=1.135231375694275
train: epoch 25, loss 0.8827447295188904, acc=0.565666675567627, loss=0.8827447295188904
test: epoch 25, loss 1.0187660455703735, acc=0.5055555701255798, loss=1.0187660455703735
train: epoch 26, loss 0.8679106831550598, acc=0.5757777690887451, loss=0.8679106831550598
test: epoch 26, loss 1.1451469659805298, acc=0.4972222149372101, loss=1.1451469659805298
train: epoch 27, loss 0.8296284675598145, acc=0.5858888626098633, loss=0.8296284675598145
test: epoch 27, loss 1.1253236532211304, acc=0.5, loss=1.1253236532211304
train: epoch 28, loss 0.8046255111694336, acc=0.5957777500152588, loss=0.8046255111694336
test: epoch 28, loss 1.1129419803619385, acc=0.5138888955116272, loss=1.1129419803619385
train: epoch 29, loss 0.8165539503097534, acc=0.5906111001968384, loss=0.8165539503097534
test: epoch 29, loss 1.0100144147872925, acc=0.5249999761581421, loss=1.0100144147872925
train: epoch 30, loss 0.7917831540107727, acc=0.5983889102935791, loss=0.7917831540107727
test: epoch 30, loss 0.98431795835495, acc=0.5333333611488342, loss=0.98431795835495
train: epoch 31, loss 0.7712106108665466, acc=0.604888916015625, loss=0.7712106108665466
test: epoch 31, loss 1.030337929725647, acc=0.5388888716697693, loss=1.030337929725647
train: epoch 32, loss 0.8015508055686951, acc=0.6013333201408386, loss=0.8015508055686951
test: epoch 32, loss 0.9739958047866821, acc=0.5305555462837219, loss=0.9739958047866821
train: epoch 33, loss 0.7936697006225586, acc=0.6033333539962769, loss=0.7936697006225586
test: epoch 33, loss 1.0334066152572632, acc=0.5249999761581421, loss=1.0334066152572632
train: epoch 34, loss 0.819154679775238, acc=0.5977222323417664, loss=0.819154679775238
test: epoch 34, loss 0.9607914686203003, acc=0.5361111164093018, loss=0.9607914686203003
train: epoch 35, loss 0.7511071562767029, acc=0.6148333549499512, loss=0.7511071562767029
test: epoch 35, loss 0.9857181310653687, acc=0.550000011920929, loss=0.9857181310653687
train: epoch 36, loss 0.7337272763252258, acc=0.6106111407279968, loss=0.7337272763252258
test: epoch 36, loss 0.8559560179710388, acc=0.5611110925674438, loss=0.8559560179710388
train: epoch 37, loss 0.7407662272453308, acc=0.616944432258606, loss=0.7407662272453308
test: epoch 37, loss 0.904430091381073, acc=0.5583333373069763, loss=0.904430091381073
train: epoch 38, loss 0.7451541423797607, acc=0.6181111335754395, loss=0.7451541423797607
test: epoch 38, loss 0.913935124874115, acc=0.5638889074325562, loss=0.913935124874115
train: epoch 39, loss 0.7339224815368652, acc=0.6186666488647461, loss=0.7339224815368652
test: epoch 39, loss 0.9543170928955078, acc=0.5666666626930237, loss=0.9543170928955078
train: epoch 40, loss 0.724185585975647, acc=0.6240555644035339, loss=0.724185585975647
test: epoch 40, loss 0.9657685160636902, acc=0.5666666626930237, loss=0.9657685160636902
train: epoch 41, loss 0.6969287991523743, acc=0.6265000104904175, loss=0.6969287991523743
test: epoch 41, loss 0.9059329628944397, acc=0.5666666626930237, loss=0.9059329628944397
train: epoch 42, loss 0.6916736364364624, acc=0.6226111054420471, loss=0.6916736364364624
test: epoch 42, loss 0.8506252765655518, acc=0.5666666626930237, loss=0.8506252765655518
train: epoch 43, loss 0.7047411203384399, acc=0.6143333315849304, loss=0.7047411203384399
test: epoch 43, loss 0.8935583829879761, acc=0.5666666626930237, loss=0.8935583829879761
train: epoch 44, loss 0.7597758173942566, acc=0.605222225189209, loss=0.7597758173942566
test: epoch 44, loss 0.9391617178916931, acc=0.5472221970558167, loss=0.9391617178916931
train: epoch 45, loss 0.7543820738792419, acc=0.6073889136314392, loss=0.7543820738792419
test: epoch 45, loss 0.9225477576255798, acc=0.5583333373069763, loss=0.9225477576255798
train: epoch 46, loss 0.6978363394737244, acc=0.6208333373069763, loss=0.6978363394737244
test: epoch 46, loss 0.8721901774406433, acc=0.5888888835906982, loss=0.8721901774406433
train: epoch 47, loss 0.6795748472213745, acc=0.628777801990509, loss=0.6795748472213745
test: epoch 47, loss 0.8475686311721802, acc=0.5972222089767456, loss=0.8475686311721802
train: epoch 48, loss 0.656700074672699, acc=0.6375555396080017, loss=0.656700074672699
test: epoch 48, loss 0.8006561398506165, acc=0.6027777791023254, loss=0.8006561398506165
train: epoch 49, loss 0.6931003332138062, acc=0.6372777819633484, loss=0.6931003332138062
test: epoch 49, loss 0.7401970028877258, acc=0.625, loss=0.7401970028877258
train: epoch 50, loss 0.6554884910583496, acc=0.6436111330986023, loss=0.6554884910583496
test: epoch 50, loss 0.7791573405265808, acc=0.6222222447395325, loss=0.7791573405265808
train: epoch 51, loss 0.7048361301422119, acc=0.6401666402816772, loss=0.7048361301422119
test: epoch 51, loss 0.6676448583602905, acc=0.6472222208976746, loss=0.6676448583602905
train: epoch 52, loss 0.6224195957183838, acc=0.6460555791854858, loss=0.6224195957183838
test: epoch 52, loss 0.6994742155075073, acc=0.6472222208976746, loss=0.6994742155075073
train: epoch 53, loss 0.6272535920143127, acc=0.6495000123977661, loss=0.6272535920143127
test: epoch 53, loss 0.6812833547592163, acc=0.6472222208976746, loss=0.6812833547592163
train: epoch 54, loss 0.6214839220046997, acc=0.6491110920906067, loss=0.6214839220046997
test: epoch 54, loss 0.6362816691398621, acc=0.6555555462837219, loss=0.6362816691398621
train: epoch 55, loss 0.6710929274559021, acc=0.6371111273765564, loss=0.6710929274559021
test: epoch 55, loss 0.6742755174636841, acc=0.6388888955116272, loss=0.6742755174636841
train: epoch 56, loss 0.6063541769981384, acc=0.6491110920906067, loss=0.6063541769981384
test: epoch 56, loss 0.610830545425415, acc=0.6666666865348816, loss=0.610830545425415
train: epoch 57, loss 0.6543703079223633, acc=0.6416110992431641, loss=0.6543703079223633
test: epoch 57, loss 0.6604822278022766, acc=0.6583333611488342, loss=0.6604822278022766
train: epoch 58, loss 0.6363030076026917, acc=0.655055582523346, loss=0.6363030076026917
test: epoch 58, loss 0.6301626563072205, acc=0.6638888716697693, loss=0.6301626563072205
train: epoch 59, loss 0.6655374765396118, acc=0.6466110944747925, loss=0.6655374765396118
test: epoch 59, loss 0.7204099893569946, acc=0.6472222208976746, loss=0.7204099893569946
train: epoch 60, loss 0.6947664022445679, acc=0.6415555477142334, loss=0.6947664022445679
test: epoch 60, loss 0.6826906800270081, acc=0.6583333611488342, loss=0.6826906800270081
train: epoch 61, loss 0.63906329870224, acc=0.6580555438995361, loss=0.63906329870224
test: epoch 61, loss 0.6302390098571777, acc=0.6666666865348816, loss=0.6302390098571777
train: epoch 62, loss 0.641259491443634, acc=0.6669444441795349, loss=0.641259491443634
test: epoch 62, loss 0.6581218242645264, acc=0.6638888716697693, loss=0.6581218242645264
train: epoch 63, loss 0.6200689077377319, acc=0.66438889503479, loss=0.6200689077377319
test: epoch 63, loss 0.6571868062019348, acc=0.6638888716697693, loss=0.6571868062019348
train: epoch 64, loss 0.6720412969589233, acc=0.6400555372238159, loss=0.6720412969589233
test: epoch 64, loss 0.6846203207969666, acc=0.6499999761581421, loss=0.6846203207969666
train: epoch 65, loss 0.6488968133926392, acc=0.6426666378974915, loss=0.6488968133926392
test: epoch 65, loss 0.6317283511161804, acc=0.6611111164093018, loss=0.6317283511161804
train: epoch 66, loss 0.6222413182258606, acc=0.6512222290039062, loss=0.6222413182258606
test: epoch 66, loss 0.6445342898368835, acc=0.6611111164093018, loss=0.6445342898368835
train: epoch 67, loss 0.6305997967720032, acc=0.6468889117240906, loss=0.6305997967720032
test: epoch 67, loss 0.7064898610115051, acc=0.6555555462837219, loss=0.7064898610115051
train: epoch 68, loss 0.7052645087242126, acc=0.6311110854148865, loss=0.7052645087242126
test: epoch 68, loss 0.763852059841156, acc=0.625, loss=0.763852059841156
train: epoch 69, loss 0.6543276906013489, acc=0.6185555458068848, loss=0.6543276906013489
test: epoch 69, loss 0.6737914681434631, acc=0.6361111402511597, loss=0.6737914681434631
train: epoch 70, loss 0.6568570137023926, acc=0.6304444670677185, loss=0.6568570137023926
test: epoch 70, loss 0.7249253392219543, acc=0.6416666507720947, loss=0.7249253392219543
train: epoch 71, loss 0.6775105595588684, acc=0.6407777667045593, loss=0.6775105595588684
test: epoch 71, loss 0.7298550009727478, acc=0.6305555701255798, loss=0.7298550009727478
train: epoch 72, loss 0.6622128486633301, acc=0.6361666917800903, loss=0.6622128486633301
test: epoch 72, loss 0.6914738416671753, acc=0.6527777910232544, loss=0.6914738416671753
train: epoch 73, loss 0.6763896942138672, acc=0.6498333215713501, loss=0.6763896942138672
test: epoch 73, loss 0.6997475624084473, acc=0.6638888716697693, loss=0.6997475624084473
train: epoch 74, loss 0.6644268035888672, acc=0.649055540561676, loss=0.6644268035888672
test: epoch 74, loss 0.7218918204307556, acc=0.6583333611488342, loss=0.7218918204307556
train: epoch 75, loss 0.7640079855918884, acc=0.6311110854148865, loss=0.7640079855918884
test: epoch 75, loss 0.6923934817314148, acc=0.6583333611488342, loss=0.6923934817314148
train: epoch 76, loss 0.6773399710655212, acc=0.6388333439826965, loss=0.6773399710655212
test: epoch 76, loss 0.7075429558753967, acc=0.6499999761581421, loss=0.7075429558753967
train: epoch 77, loss 0.6521428227424622, acc=0.643666684627533, loss=0.6521428227424622
test: epoch 77, loss 0.6439433097839355, acc=0.6666666865348816, loss=0.6439433097839355
train: epoch 78, loss 0.6610925197601318, acc=0.6357222199440002, loss=0.6610925197601318
test: epoch 78, loss 0.6589230895042419, acc=0.6638888716697693, loss=0.6589230895042419
train: epoch 79, loss 0.6816611886024475, acc=0.6388888955116272, loss=0.6816611886024475
test: epoch 79, loss 0.6675378680229187, acc=0.6611111164093018, loss=0.6675378680229187
train: epoch 80, loss 0.6966163516044617, acc=0.6395555734634399, loss=0.6966163516044617
test: epoch 80, loss 0.6526607871055603, acc=0.6666666865348816, loss=0.6526607871055603
train: epoch 81, loss 0.640877366065979, acc=0.6498333215713501, loss=0.640877366065979
test: epoch 81, loss 0.6730983257293701, acc=0.6583333611488342, loss=0.6730983257293701
train: epoch 82, loss 0.6373034119606018, acc=0.6531111001968384, loss=0.6373034119606018
test: epoch 82, loss 0.6418594717979431, acc=0.6611111164093018, loss=0.6418594717979431
train: epoch 83, loss 0.6144586801528931, acc=0.6639444231987, loss=0.6144586801528931
test: epoch 83, loss 0.6431037187576294, acc=0.6638888716697693, loss=0.6431037187576294
train: epoch 84, loss 0.6139892339706421, acc=0.6702222228050232, loss=0.6139892339706421
test: epoch 84, loss 0.6265260577201843, acc=0.675000011920929, loss=0.6265260577201843
train: epoch 85, loss 0.6159701943397522, acc=0.6570000052452087, loss=0.6159701943397522
test: epoch 85, loss 0.6218106150627136, acc=0.6638888716697693, loss=0.6218106150627136
train: epoch 86, loss 0.5814775824546814, acc=0.6573888659477234, loss=0.5814775824546814
test: epoch 86, loss 0.5952337980270386, acc=0.675000011920929, loss=0.5952337980270386
train: epoch 87, loss 0.5833428502082825, acc=0.6561111211776733, loss=0.5833428502082825
test: epoch 87, loss 0.6075969338417053, acc=0.675000011920929, loss=0.6075969338417053
train: epoch 88, loss 0.7083953022956848, acc=0.6449999809265137, loss=0.7083953022956848
test: epoch 88, loss 0.7034252882003784, acc=0.644444465637207, loss=0.7034252882003784
train: epoch 89, loss 0.6717380881309509, acc=0.6412222385406494, loss=0.6717380881309509
test: epoch 89, loss 0.7097991108894348, acc=0.6527777910232544, loss=0.7097991108894348
train: epoch 90, loss 0.661257803440094, acc=0.6398888826370239, loss=0.661257803440094
test: epoch 90, loss 0.6793890595436096, acc=0.6527777910232544, loss=0.6793890595436096
train: epoch 91, loss 0.6664942502975464, acc=0.6453889012336731, loss=0.6664942502975464
test: epoch 91, loss 0.6820069551467896, acc=0.6527777910232544, loss=0.6820069551467896
train: epoch 92, loss 0.6656202077865601, acc=0.6405555605888367, loss=0.6656202077865601
test: epoch 92, loss 0.6771875619888306, acc=0.6527777910232544, loss=0.6771875619888306
train: epoch 93, loss 0.6602028012275696, acc=0.6448333263397217, loss=0.6602028012275696
test: epoch 93, loss 0.6530340313911438, acc=0.6638888716697693, loss=0.6530340313911438
train: epoch 94, loss 0.7979854345321655, acc=0.6305555701255798, loss=0.7979854345321655
test: epoch 94, loss 0.9878394603729248, acc=0.5972222089767456, loss=0.9878394603729248
train: epoch 95, loss 0.8680633902549744, acc=0.6169999837875366, loss=0.8680633902549744
test: epoch 95, loss 0.7940530776977539, acc=0.6361111402511597, loss=0.7940530776977539
train: epoch 96, loss 0.8300737738609314, acc=0.60916668176651, loss=0.8300737738609314
test: epoch 96, loss 0.8296003937721252, acc=0.6138888597488403, loss=0.8296003937721252
train: epoch 97, loss 0.8234939575195312, acc=0.5930555462837219, loss=0.8234939575195312
test: epoch 97, loss 0.8490578532218933, acc=0.6138888597488403, loss=0.8490578532218933
train: epoch 98, loss 0.8005760312080383, acc=0.6144444346427917, loss=0.8005760312080383
test: epoch 98, loss 0.7658033967018127, acc=0.6361111402511597, loss=0.7658033967018127
train: epoch 99, loss 0.7697747349739075, acc=0.6209999918937683, loss=0.7697747349739075
test: epoch 99, loss 0.7548887729644775, acc=0.644444465637207, loss=0.7548887729644775
train: epoch 100, loss 0.757307231426239, acc=0.6259999871253967, loss=0.757307231426239
test: epoch 100, loss 0.7531384229660034, acc=0.644444465637207, loss=0.7531384229660034
train: epoch 101, loss 0.7567509412765503, acc=0.6256666779518127, loss=0.7567509412765503
test: epoch 101, loss 0.7530750036239624, acc=0.644444465637207, loss=0.7530750036239624
train: epoch 102, loss 0.7566901445388794, acc=0.6263889074325562, loss=0.7566901445388794
test: epoch 102, loss 0.7530055046081543, acc=0.644444465637207, loss=0.7530055046081543
train: epoch 103, loss 0.7652075886726379, acc=0.6258888840675354, loss=0.7652075886726379
test: epoch 103, loss 0.7707858681678772, acc=0.6388888955116272, loss=0.7707858681678772
train: epoch 104, loss 0.854249894618988, acc=0.6128333210945129, loss=0.854249894618988
test: epoch 104, loss 0.6994611024856567, acc=0.6472222208976746, loss=0.6994611024856567
train: epoch 105, loss 0.7341917753219604, acc=0.6239444613456726, loss=0.7341917753219604
test: epoch 105, loss 0.7195572257041931, acc=0.6388888955116272, loss=0.7195572257041931
train: epoch 106, loss 0.7142741680145264, acc=0.6217777729034424, loss=0.7142741680145264
test: epoch 106, loss 0.6995397806167603, acc=0.644444465637207, loss=0.6995397806167603
train: epoch 107, loss 0.7102189660072327, acc=0.6227222084999084, loss=0.7102189660072327
test: epoch 107, loss 0.8048157095909119, acc=0.6194444298744202, loss=0.8048157095909119
train: epoch 108, loss 0.7589237689971924, acc=0.6106111407279968, loss=0.7589237689971924
test: epoch 108, loss 0.7382563352584839, acc=0.6305555701255798, loss=0.7382563352584839
train: epoch 109, loss 0.7521538138389587, acc=0.6111111044883728, loss=0.7521538138389587
test: epoch 109, loss 0.7555235028266907, acc=0.6277777552604675, loss=0.7555235028266907
train: epoch 110, loss 0.8327028751373291, acc=0.6128333210945129, loss=0.8327028751373291
test: epoch 110, loss 0.8171833753585815, acc=0.6194444298744202, loss=0.8171833753585815
train: epoch 111, loss 0.8277803063392639, acc=0.6123889088630676, loss=0.8277803063392639
test: epoch 111, loss 0.8331031799316406, acc=0.625, loss=0.8331031799316406
train: epoch 112, loss 0.8527005314826965, acc=0.6163889169692993, loss=0.8527005314826965
test: epoch 112, loss 0.8239380121231079, acc=0.625, loss=0.8239380121231079
train: epoch 113, loss 0.7995598316192627, acc=0.6265555620193481, loss=0.7995598316192627
test: epoch 113, loss 0.7545341849327087, acc=0.6388888955116272, loss=0.7545341849327087
train: epoch 114, loss 0.7550137042999268, acc=0.6340000033378601, loss=0.7550137042999268
test: epoch 114, loss 0.745985746383667, acc=0.6416666507720947, loss=0.745985746383667
train: epoch 115, loss 0.7491003274917603, acc=0.6298333406448364, loss=0.7491003274917603
test: epoch 115, loss 0.7378784418106079, acc=0.644444465637207, loss=0.7378784418106079
train: epoch 116, loss 0.7422014474868774, acc=0.6347777843475342, loss=0.7422014474868774
test: epoch 116, loss 0.7148025631904602, acc=0.6499999761581421, loss=0.7148025631904602
train: epoch 117, loss 0.7185763120651245, acc=0.6316666603088379, loss=0.7185763120651245
test: epoch 117, loss 0.7177274227142334, acc=0.6499999761581421, loss=0.7177274227142334
train: epoch 118, loss 0.7678270936012268, acc=0.6231666803359985, loss=0.7678270936012268
test: epoch 118, loss 0.7316733002662659, acc=0.6472222208976746, loss=0.7316733002662659
train: epoch 119, loss 0.7746425867080688, acc=0.628166675567627, loss=0.7746425867080688
test: epoch 119, loss 0.7272433042526245, acc=0.6472222208976746, loss=0.7272433042526245
train: epoch 120, loss 0.7274203896522522, acc=0.6206111311912537, loss=0.7274203896522522
test: epoch 120, loss 0.7204105257987976, acc=0.6472222208976746, loss=0.7204105257987976
train: epoch 121, loss 0.768311083316803, acc=0.620722234249115, loss=0.768311083316803
test: epoch 121, loss 0.7614814043045044, acc=0.6388888955116272, loss=0.7614814043045044
train: epoch 122, loss 0.757565975189209, acc=0.6143333315849304, loss=0.757565975189209
test: epoch 122, loss 0.7463496923446655, acc=0.6416666507720947, loss=0.7463496923446655
train: epoch 123, loss 0.7505537271499634, acc=0.6057778000831604, loss=0.7505537271499634
test: epoch 123, loss 0.7360788583755493, acc=0.644444465637207, loss=0.7360788583755493
train: epoch 124, loss 0.7544054388999939, acc=0.6076111197471619, loss=0.7544054388999939
test: epoch 124, loss 0.7464432716369629, acc=0.6333333253860474, loss=0.7464432716369629
train: epoch 125, loss 0.8208957314491272, acc=0.6115000247955322, loss=0.8208957314491272
test: epoch 125, loss 0.7755694389343262, acc=0.6333333253860474, loss=0.7755694389343262
train: epoch 126, loss 0.7584938406944275, acc=0.6073889136314392, loss=0.7584938406944275
test: epoch 126, loss 0.7380812168121338, acc=0.6416666507720947, loss=0.7380812168121338
train: epoch 127, loss 0.743110179901123, acc=0.6062222123146057, loss=0.743110179901123
test: epoch 127, loss 0.7372304201126099, acc=0.6416666507720947, loss=0.7372304201126099
train: epoch 128, loss 0.7460913062095642, acc=0.6000000238418579, loss=0.7460913062095642
test: epoch 128, loss 0.7426319718360901, acc=0.6388888955116272, loss=0.7426319718360901
train: epoch 129, loss 0.7467750310897827, acc=0.5999444723129272, loss=0.7467750310897827
test: epoch 129, loss 0.7388309836387634, acc=0.6416666507720947, loss=0.7388309836387634
train: epoch 130, loss 0.7960697412490845, acc=0.602055549621582, loss=0.7960697412490845
test: epoch 130, loss 0.7985427379608154, acc=0.6222222447395325, loss=0.7985427379608154
train: epoch 131, loss 0.9069206714630127, acc=0.5937222242355347, loss=0.9069206714630127
test: epoch 131, loss 0.8447225689888, acc=0.6111111044883728, loss=0.8447225689888
train: epoch 132, loss 0.8431786894798279, acc=0.5781111121177673, loss=0.8431786894798279
test: epoch 132, loss 0.8176881670951843, acc=0.6138888597488403, loss=0.8176881670951843
train: epoch 133, loss 0.8225041627883911, acc=0.5687222480773926, loss=0.8225041627883911
test: epoch 133, loss 0.8165113925933838, acc=0.6138888597488403, loss=0.8165113925933838
train: epoch 134, loss 0.828995406627655, acc=0.570111095905304, loss=0.828995406627655
test: epoch 134, loss 0.827726423740387, acc=0.6111111044883728, loss=0.827726423740387
train: epoch 135, loss 0.8324812054634094, acc=0.5653333067893982, loss=0.8324812054634094
test: epoch 135, loss 0.8272714018821716, acc=0.6111111044883728, loss=0.8272714018821716
train: epoch 136, loss 0.825998067855835, acc=0.5674444437026978, loss=0.825998067855835
test: epoch 136, loss 0.8179627656936646, acc=0.6138888597488403, loss=0.8179627656936646
train: epoch 137, loss 0.8223715424537659, acc=0.5691111087799072, loss=0.8223715424537659
test: epoch 137, loss 0.8178863525390625, acc=0.6138888597488403, loss=0.8178863525390625
train: epoch 138, loss 0.8221267461776733, acc=0.5692222118377686, loss=0.8221267461776733
test: epoch 138, loss 0.8178370594978333, acc=0.6138888597488403, loss=0.8178370594978333
train: epoch 139, loss 0.8221616744995117, acc=0.5742777585983276, loss=0.8221616744995117
test: epoch 139, loss 0.8178224563598633, acc=0.6138888597488403, loss=0.8178224563598633
train: epoch 140, loss 0.8220176100730896, acc=0.5741111040115356, loss=0.8220176100730896
test: epoch 140, loss 0.8177999258041382, acc=0.6138888597488403, loss=0.8177999258041382
train: epoch 141, loss 0.8306127786636353, acc=0.5728333592414856, loss=0.8306127786636353
test: epoch 141, loss 1.0292906761169434, acc=0.5833333134651184, loss=1.0292906761169434
train: epoch 142, loss 0.9093941450119019, acc=0.5851666927337646, loss=0.9093941450119019
test: epoch 142, loss 0.8697718381881714, acc=0.6000000238418579, loss=0.8697718381881714
train: epoch 143, loss 0.8517374992370605, acc=0.5844444632530212, loss=0.8517374992370605
test: epoch 143, loss 0.8413345813751221, acc=0.605555534362793, loss=0.8413345813751221
train: epoch 144, loss 0.8487676978111267, acc=0.5763333439826965, loss=0.8487676978111267
test: epoch 144, loss 0.841066837310791, acc=0.605555534362793, loss=0.841066837310791
train: epoch 145, loss 0.8457575440406799, acc=0.5734444260597229, loss=0.8457575440406799
test: epoch 145, loss 0.8406660556793213, acc=0.605555534362793, loss=0.8406660556793213
train: epoch 146, loss 0.8453471660614014, acc=0.570888876914978, loss=0.8453471660614014
test: epoch 146, loss 0.8405694365501404, acc=0.605555534362793, loss=0.8405694365501404
train: epoch 147, loss 0.845129668712616, acc=0.5723888874053955, loss=0.845129668712616
test: epoch 147, loss 0.8404784798622131, acc=0.605555534362793, loss=0.8404784798622131
train: epoch 148, loss 0.8448895812034607, acc=0.570277750492096, loss=0.8448895812034607
test: epoch 148, loss 0.8404436111450195, acc=0.605555534362793, loss=0.8404436111450195
train: epoch 149, loss 0.8449071049690247, acc=0.5712222456932068, loss=0.8449071049690247
test: epoch 149, loss 0.8404474854469299, acc=0.605555534362793, loss=0.8404474854469299
train: epoch 150, loss 0.9331177473068237, acc=0.575166642665863, loss=0.9331177473068237
test: epoch 150, loss 1.3723461627960205, acc=0.5416666865348816, loss=1.3723461627960205
