# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=false", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=2077525613, receiver_embed_dim=32, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.096217393875122, acc=0.07405555248260498, loss=3.096217393875122
test: epoch 1, loss 3.3317015171051025, acc=0.09166666865348816, loss=3.3317015171051025
train: epoch 2, loss 2.1494851112365723, acc=0.1827777773141861, loss=2.1494851112365723
test: epoch 2, loss 3.042614221572876, acc=0.13055555522441864, loss=3.042614221572876
train: epoch 3, loss 1.8745436668395996, acc=0.242166668176651, loss=1.8745436668395996
test: epoch 3, loss 3.2615058422088623, acc=0.14444445073604584, loss=3.2615058422088623
train: epoch 4, loss 1.7249888181686401, acc=0.2776666581630707, loss=1.7249888181686401
test: epoch 4, loss 2.8638391494750977, acc=0.1527777761220932, loss=2.8638391494750977
train: epoch 5, loss 1.5962270498275757, acc=0.3051111102104187, loss=1.5962270498275757
test: epoch 5, loss 3.2305679321289062, acc=0.13333334028720856, loss=3.2305679321289062
train: epoch 6, loss 1.5174331665039062, acc=0.324611097574234, loss=1.5174331665039062
test: epoch 6, loss 3.067488670349121, acc=0.16111111640930176, loss=3.067488670349121
train: epoch 7, loss 1.4421312808990479, acc=0.3467777669429779, loss=1.4421312808990479
test: epoch 7, loss 3.3287086486816406, acc=0.16111111640930176, loss=3.3287086486816406
train: epoch 8, loss 1.3849080801010132, acc=0.37066665291786194, loss=1.3849080801010132
test: epoch 8, loss 3.0966484546661377, acc=0.16111111640930176, loss=3.0966484546661377
train: epoch 9, loss 1.3430930376052856, acc=0.3856666684150696, loss=1.3430930376052856
test: epoch 9, loss 3.122763156890869, acc=0.16388888657093048, loss=3.122763156890869
train: epoch 10, loss 1.3214821815490723, acc=0.4035555422306061, loss=1.3214821815490723
test: epoch 10, loss 2.7598934173583984, acc=0.14722222089767456, loss=2.7598934173583984
train: epoch 11, loss 1.2778524160385132, acc=0.42677778005599976, loss=1.2778524160385132
test: epoch 11, loss 2.5921437740325928, acc=0.19166666269302368, loss=2.5921437740325928
train: epoch 12, loss 1.2345623970031738, acc=0.4484444558620453, loss=1.2345623970031738
test: epoch 12, loss 2.4905412197113037, acc=0.17222222685813904, loss=2.4905412197113037
train: epoch 13, loss 1.1929298639297485, acc=0.47138887643814087, loss=1.1929298639297485
test: epoch 13, loss 2.5602264404296875, acc=0.23055554926395416, loss=2.5602264404296875
train: epoch 14, loss 1.1925954818725586, acc=0.47555556893348694, loss=1.1925954818725586
test: epoch 14, loss 2.4764175415039062, acc=0.17777778208255768, loss=2.4764175415039062
train: epoch 15, loss 1.1508173942565918, acc=0.49316665530204773, loss=1.1508173942565918
test: epoch 15, loss 2.542863130569458, acc=0.19722221791744232, loss=2.542863130569458
train: epoch 16, loss 1.1182639598846436, acc=0.5101110935211182, loss=1.1182639598846436
test: epoch 16, loss 2.185826063156128, acc=0.24444444477558136, loss=2.185826063156128
train: epoch 17, loss 1.0672698020935059, acc=0.5382221937179565, loss=1.0672698020935059
test: epoch 17, loss 2.517843008041382, acc=0.23055554926395416, loss=2.517843008041382
train: epoch 18, loss 1.007980465888977, acc=0.5717777609825134, loss=1.007980465888977
test: epoch 18, loss 2.1254239082336426, acc=0.24444444477558136, loss=2.1254239082336426
train: epoch 19, loss 0.9038121104240417, acc=0.6261110901832581, loss=0.9038121104240417
test: epoch 19, loss 2.147869825363159, acc=0.31388887763023376, loss=2.147869825363159
train: epoch 20, loss 0.7536560297012329, acc=0.6941111087799072, loss=0.7536560297012329
test: epoch 20, loss 2.3986809253692627, acc=0.2611111104488373, loss=2.3986809253692627
train: epoch 21, loss 0.6865736246109009, acc=0.7182777523994446, loss=0.6865736246109009
test: epoch 21, loss 2.338716506958008, acc=0.3361110985279083, loss=2.338716506958008
train: epoch 22, loss 0.6657336950302124, acc=0.7272777557373047, loss=0.6657336950302124
test: epoch 22, loss 1.9910902976989746, acc=0.35277777910232544, loss=1.9910902976989746
train: epoch 23, loss 0.6365638375282288, acc=0.7404999732971191, loss=0.6365638375282288
test: epoch 23, loss 1.9109752178192139, acc=0.34166666865348816, loss=1.9109752178192139
train: epoch 24, loss 0.5936052203178406, acc=0.7513889074325562, loss=0.5936052203178406
test: epoch 24, loss 2.21974515914917, acc=0.2944444417953491, loss=2.21974515914917
train: epoch 25, loss 0.564298152923584, acc=0.7627221941947937, loss=0.564298152923584
test: epoch 25, loss 2.0799663066864014, acc=0.3222222328186035, loss=2.0799663066864014
train: epoch 26, loss 0.565485954284668, acc=0.7609444260597229, loss=0.565485954284668
test: epoch 26, loss 1.978102684020996, acc=0.3361110985279083, loss=1.978102684020996
train: epoch 27, loss 0.5384843349456787, acc=0.7743889093399048, loss=0.5384843349456787
test: epoch 27, loss 1.9509810209274292, acc=0.35277777910232544, loss=1.9509810209274292
train: epoch 28, loss 0.5366976261138916, acc=0.7782222032546997, loss=0.5366976261138916
test: epoch 28, loss 1.8775148391723633, acc=0.3777777850627899, loss=1.8775148391723633
train: epoch 29, loss 0.5223430395126343, acc=0.7802777886390686, loss=0.5223430395126343
test: epoch 29, loss 1.7712328433990479, acc=0.3361110985279083, loss=1.7712328433990479
train: epoch 30, loss 0.5176495909690857, acc=0.7835000157356262, loss=0.5176495909690857
test: epoch 30, loss 1.8129477500915527, acc=0.34166666865348816, loss=1.8129477500915527
train: epoch 31, loss 0.4897119998931885, acc=0.7916111350059509, loss=0.4897119998931885
test: epoch 31, loss 1.9780809879302979, acc=0.375, loss=1.9780809879302979
train: epoch 32, loss 0.496794193983078, acc=0.7878888845443726, loss=0.496794193983078
test: epoch 32, loss 1.8127214908599854, acc=0.39722222089767456, loss=1.8127214908599854
train: epoch 33, loss 0.48694172501564026, acc=0.7933333516120911, loss=0.48694172501564026
test: epoch 33, loss 1.5545130968093872, acc=0.3777777850627899, loss=1.5545130968093872
train: epoch 34, loss 0.49028480052948, acc=0.7912777662277222, loss=0.49028480052948
test: epoch 34, loss 1.6952718496322632, acc=0.35277777910232544, loss=1.6952718496322632
train: epoch 35, loss 0.4706132113933563, acc=0.7994444370269775, loss=0.4706132113933563
test: epoch 35, loss 1.5125218629837036, acc=0.3888888955116272, loss=1.5125218629837036
train: epoch 36, loss 0.47471004724502563, acc=0.7894444465637207, loss=0.47471004724502563
test: epoch 36, loss 1.8619636297225952, acc=0.4333333373069763, loss=1.8619636297225952
train: epoch 37, loss 0.456480473279953, acc=0.7982222437858582, loss=0.456480473279953
test: epoch 37, loss 1.7292450666427612, acc=0.4277777671813965, loss=1.7292450666427612
train: epoch 38, loss 0.4647481441497803, acc=0.7976111173629761, loss=0.4647481441497803
test: epoch 38, loss 1.8072171211242676, acc=0.47777777910232544, loss=1.8072171211242676
train: epoch 39, loss 0.4525144100189209, acc=0.8054999709129333, loss=0.4525144100189209
test: epoch 39, loss 1.690837025642395, acc=0.4972222149372101, loss=1.690837025642395
train: epoch 40, loss 0.4521563649177551, acc=0.8027777671813965, loss=0.4521563649177551
test: epoch 40, loss 1.7436676025390625, acc=0.4472222328186035, loss=1.7436676025390625
train: epoch 41, loss 0.45551303029060364, acc=0.8026666641235352, loss=0.45551303029060364
test: epoch 41, loss 1.4521647691726685, acc=0.4749999940395355, loss=1.4521647691726685
train: epoch 42, loss 0.44334766268730164, acc=0.8054999709129333, loss=0.44334766268730164
test: epoch 42, loss 1.527216911315918, acc=0.46388888359069824, loss=1.527216911315918
train: epoch 43, loss 0.43118003010749817, acc=0.8097222447395325, loss=0.43118003010749817
test: epoch 43, loss 1.7225128412246704, acc=0.4194444417953491, loss=1.7225128412246704
train: epoch 44, loss 0.43025627732276917, acc=0.8108333349227905, loss=0.43025627732276917
test: epoch 44, loss 1.570794939994812, acc=0.43888887763023376, loss=1.570794939994812
train: epoch 45, loss 0.42335933446884155, acc=0.8130000233650208, loss=0.42335933446884155
test: epoch 45, loss 1.4654165506362915, acc=0.4305555522441864, loss=1.4654165506362915
train: epoch 46, loss 0.4189474880695343, acc=0.8133333325386047, loss=0.4189474880695343
test: epoch 46, loss 1.5737955570220947, acc=0.5222222208976746, loss=1.5737955570220947
train: epoch 47, loss 0.4267332851886749, acc=0.8138333559036255, loss=0.4267332851886749
test: epoch 47, loss 1.4617923498153687, acc=0.5416666865348816, loss=1.4617923498153687
train: epoch 48, loss 0.4082247018814087, acc=0.8179444670677185, loss=0.4082247018814087
test: epoch 48, loss 1.42159104347229, acc=0.5083333253860474, loss=1.42159104347229
train: epoch 49, loss 0.4125019311904907, acc=0.8144999742507935, loss=0.4125019311904907
test: epoch 49, loss 1.4387125968933105, acc=0.49166667461395264, loss=1.4387125968933105
train: epoch 50, loss 0.39924928545951843, acc=0.8218888640403748, loss=0.39924928545951843
test: epoch 50, loss 1.8026009798049927, acc=0.5333333611488342, loss=1.8026009798049927
train: epoch 51, loss 0.40794456005096436, acc=0.8196666836738586, loss=0.40794456005096436
test: epoch 51, loss 1.2885345220565796, acc=0.46666666865348816, loss=1.2885345220565796
train: epoch 52, loss 0.3934149146080017, acc=0.8257777690887451, loss=0.3934149146080017
test: epoch 52, loss 1.3594884872436523, acc=0.4972222149372101, loss=1.3594884872436523
train: epoch 53, loss 0.3862437903881073, acc=0.8266666531562805, loss=0.3862437903881073
test: epoch 53, loss 1.5307711362838745, acc=0.5249999761581421, loss=1.5307711362838745
train: epoch 54, loss 0.38518744707107544, acc=0.8287222385406494, loss=0.38518744707107544
test: epoch 54, loss 1.519670009613037, acc=0.43888887763023376, loss=1.519670009613037
train: epoch 55, loss 0.394258588552475, acc=0.824055552482605, loss=0.394258588552475
test: epoch 55, loss 1.5979268550872803, acc=0.5083333253860474, loss=1.5979268550872803
train: epoch 56, loss 0.39119449257850647, acc=0.8257222175598145, loss=0.39119449257850647
test: epoch 56, loss 1.3094784021377563, acc=0.5388888716697693, loss=1.3094784021377563
train: epoch 57, loss 0.3792518675327301, acc=0.8317221999168396, loss=0.3792518675327301
test: epoch 57, loss 1.428941011428833, acc=0.5111111402511597, loss=1.428941011428833
train: epoch 58, loss 0.3859657049179077, acc=0.8303333520889282, loss=0.3859657049179077
test: epoch 58, loss 1.596657395362854, acc=0.5083333253860474, loss=1.596657395362854
train: epoch 59, loss 0.3739158511161804, acc=0.8312222361564636, loss=0.3739158511161804
test: epoch 59, loss 1.3468037843704224, acc=0.5666666626930237, loss=1.3468037843704224
train: epoch 60, loss 0.37284719944000244, acc=0.8347777724266052, loss=0.37284719944000244
test: epoch 60, loss 1.567021369934082, acc=0.5138888955116272, loss=1.567021369934082
train: epoch 61, loss 0.3807658553123474, acc=0.8295000195503235, loss=0.3807658553123474
test: epoch 61, loss 1.2256547212600708, acc=0.5444444417953491, loss=1.2256547212600708
train: epoch 62, loss 0.3733929693698883, acc=0.8329444527626038, loss=0.3733929693698883
test: epoch 62, loss 1.6469533443450928, acc=0.5222222208976746, loss=1.6469533443450928
train: epoch 63, loss 0.3617889881134033, acc=0.8360555768013, loss=0.3617889881134033
test: epoch 63, loss 1.5172725915908813, acc=0.5, loss=1.5172725915908813
train: epoch 64, loss 0.37891101837158203, acc=0.8334444165229797, loss=0.37891101837158203
test: epoch 64, loss 1.2794101238250732, acc=0.5694444179534912, loss=1.2794101238250732
train: epoch 65, loss 0.3635430932044983, acc=0.8361666798591614, loss=0.3635430932044983
test: epoch 65, loss 1.3150984048843384, acc=0.5166666507720947, loss=1.3150984048843384
train: epoch 66, loss 0.3678639829158783, acc=0.8337222337722778, loss=0.3678639829158783
test: epoch 66, loss 1.552332878112793, acc=0.5694444179534912, loss=1.552332878112793
train: epoch 67, loss 0.3642917573451996, acc=0.8381111025810242, loss=0.3642917573451996
test: epoch 67, loss 1.4131008386611938, acc=0.5555555820465088, loss=1.4131008386611938
train: epoch 68, loss 0.3707464337348938, acc=0.8364444375038147, loss=0.3707464337348938
test: epoch 68, loss 1.5508960485458374, acc=0.519444465637207, loss=1.5508960485458374
train: epoch 69, loss 0.36157870292663574, acc=0.8385555744171143, loss=0.36157870292663574
test: epoch 69, loss 1.1810964345932007, acc=0.5805555582046509, loss=1.1810964345932007
train: epoch 70, loss 0.3687223196029663, acc=0.8351110816001892, loss=0.3687223196029663
test: epoch 70, loss 1.3769220113754272, acc=0.5138888955116272, loss=1.3769220113754272
train: epoch 71, loss 0.350769966840744, acc=0.8410555720329285, loss=0.350769966840744
test: epoch 71, loss 1.3237745761871338, acc=0.6111111044883728, loss=1.3237745761871338
train: epoch 72, loss 0.3496413230895996, acc=0.8420000076293945, loss=0.3496413230895996
test: epoch 72, loss 1.239376187324524, acc=0.5527777671813965, loss=1.239376187324524
train: epoch 73, loss 0.35452985763549805, acc=0.8429444432258606, loss=0.35452985763549805
test: epoch 73, loss 1.214955449104309, acc=0.519444465637207, loss=1.214955449104309
train: epoch 74, loss 0.350806325674057, acc=0.8401666879653931, loss=0.350806325674057
test: epoch 74, loss 1.1695632934570312, acc=0.5416666865348816, loss=1.1695632934570312
train: epoch 75, loss 0.3389824628829956, acc=0.8453888893127441, loss=0.3389824628829956
test: epoch 75, loss 1.2073675394058228, acc=0.5444444417953491, loss=1.2073675394058228
train: epoch 76, loss 0.3493584394454956, acc=0.8412222266197205, loss=0.3493584394454956
test: epoch 76, loss 1.367041826248169, acc=0.5222222208976746, loss=1.367041826248169
train: epoch 77, loss 0.3412320613861084, acc=0.8453333377838135, loss=0.3412320613861084
test: epoch 77, loss 1.2622239589691162, acc=0.5638889074325562, loss=1.2622239589691162
train: epoch 78, loss 0.34267735481262207, acc=0.8451666831970215, loss=0.34267735481262207
test: epoch 78, loss 1.2414178848266602, acc=0.5222222208976746, loss=1.2414178848266602
train: epoch 79, loss 0.3432122766971588, acc=0.8460555672645569, loss=0.3432122766971588
test: epoch 79, loss 1.1940407752990723, acc=0.5555555820465088, loss=1.1940407752990723
train: epoch 80, loss 0.35784316062927246, acc=0.8399999737739563, loss=0.35784316062927246
test: epoch 80, loss 1.2556474208831787, acc=0.5777778029441833, loss=1.2556474208831787
train: epoch 81, loss 0.32646793127059937, acc=0.8496666550636292, loss=0.32646793127059937
test: epoch 81, loss 1.1922996044158936, acc=0.5694444179534912, loss=1.1922996044158936
train: epoch 82, loss 0.3349710702896118, acc=0.8461111187934875, loss=0.3349710702896118
test: epoch 82, loss 1.3113677501678467, acc=0.5583333373069763, loss=1.3113677501678467
train: epoch 83, loss 0.3363015055656433, acc=0.8452222347259521, loss=0.3363015055656433
test: epoch 83, loss 1.166982650756836, acc=0.5944444537162781, loss=1.166982650756836
train: epoch 84, loss 0.34653499722480774, acc=0.8420555591583252, loss=0.34653499722480774
test: epoch 84, loss 0.9697818756103516, acc=0.6222222447395325, loss=0.9697818756103516
train: epoch 85, loss 0.3310684561729431, acc=0.8469444513320923, loss=0.3310684561729431
test: epoch 85, loss 1.2619049549102783, acc=0.5666666626930237, loss=1.2619049549102783
train: epoch 86, loss 0.34570732712745667, acc=0.8473333120346069, loss=0.34570732712745667
test: epoch 86, loss 0.9422096610069275, acc=0.6111111044883728, loss=0.9422096610069275
train: epoch 87, loss 0.3243555724620819, acc=0.850777804851532, loss=0.3243555724620819
test: epoch 87, loss 0.9339842200279236, acc=0.6305555701255798, loss=0.9339842200279236
train: epoch 88, loss 0.3512764573097229, acc=0.8399999737739563, loss=0.3512764573097229
test: epoch 88, loss 1.0226548910140991, acc=0.6166666746139526, loss=1.0226548910140991
train: epoch 89, loss 0.32958731055259705, acc=0.8490555286407471, loss=0.32958731055259705
test: epoch 89, loss 1.314439058303833, acc=0.574999988079071, loss=1.314439058303833
train: epoch 90, loss 0.32448670268058777, acc=0.8499444723129272, loss=0.32448670268058777
test: epoch 90, loss 1.1899088621139526, acc=0.625, loss=1.1899088621139526
train: epoch 91, loss 0.3615202307701111, acc=0.8378888964653015, loss=0.3615202307701111
test: epoch 91, loss 0.8304720520973206, acc=0.6722221970558167, loss=0.8304720520973206
train: epoch 92, loss 0.32070258259773254, acc=0.8521111011505127, loss=0.32070258259773254
test: epoch 92, loss 1.020236849784851, acc=0.5944444537162781, loss=1.020236849784851
train: epoch 93, loss 0.33691465854644775, acc=0.8456666469573975, loss=0.33691465854644775
test: epoch 93, loss 0.9679440855979919, acc=0.6194444298744202, loss=0.9679440855979919
train: epoch 94, loss 0.32232001423835754, acc=0.8507221937179565, loss=0.32232001423835754
test: epoch 94, loss 1.1437890529632568, acc=0.6361111402511597, loss=1.1437890529632568
train: epoch 95, loss 0.320553719997406, acc=0.8489444255828857, loss=0.320553719997406
test: epoch 95, loss 1.173675537109375, acc=0.6111111044883728, loss=1.173675537109375
train: epoch 96, loss 0.3269663453102112, acc=0.8517777919769287, loss=0.3269663453102112
test: epoch 96, loss 0.8541052937507629, acc=0.6583333611488342, loss=0.8541052937507629
train: epoch 97, loss 0.3328004479408264, acc=0.848111093044281, loss=0.3328004479408264
test: epoch 97, loss 0.8331653475761414, acc=0.6611111164093018, loss=0.8331653475761414
train: epoch 98, loss 0.3189956545829773, acc=0.8517777919769287, loss=0.3189956545829773
test: epoch 98, loss 0.8641713857650757, acc=0.6722221970558167, loss=0.8641713857650757
train: epoch 99, loss 0.3380393385887146, acc=0.8484444618225098, loss=0.3380393385887146
test: epoch 99, loss 1.0432870388031006, acc=0.625, loss=1.0432870388031006
train: epoch 100, loss 0.3207343816757202, acc=0.8523333072662354, loss=0.3207343816757202
test: epoch 100, loss 0.9280309081077576, acc=0.699999988079071, loss=0.9280309081077576
train: epoch 101, loss 0.32052725553512573, acc=0.8528333306312561, loss=0.32052725553512573
test: epoch 101, loss 0.8696461915969849, acc=0.6638888716697693, loss=0.8696461915969849
train: epoch 102, loss 0.34314823150634766, acc=0.846833348274231, loss=0.34314823150634766
test: epoch 102, loss 0.8649359941482544, acc=0.7027778029441833, loss=0.8649359941482544
train: epoch 103, loss 0.321839302778244, acc=0.8523333072662354, loss=0.321839302778244
test: epoch 103, loss 0.8386764526367188, acc=0.6722221970558167, loss=0.8386764526367188
train: epoch 104, loss 0.3306875228881836, acc=0.8487777709960938, loss=0.3306875228881836
test: epoch 104, loss 1.0391381978988647, acc=0.6777777671813965, loss=1.0391381978988647
train: epoch 105, loss 0.33560872077941895, acc=0.8484444618225098, loss=0.33560872077941895
test: epoch 105, loss 0.7857300639152527, acc=0.7250000238418579, loss=0.7857300639152527
train: epoch 106, loss 0.327038049697876, acc=0.851277768611908, loss=0.327038049697876
test: epoch 106, loss 0.6180799007415771, acc=0.7583333253860474, loss=0.6180799007415771
train: epoch 107, loss 0.3264230489730835, acc=0.8515555262565613, loss=0.3264230489730835
test: epoch 107, loss 0.9117855429649353, acc=0.6916666626930237, loss=0.9117855429649353
train: epoch 108, loss 0.30941155552864075, acc=0.8566666841506958, loss=0.30941155552864075
test: epoch 108, loss 0.8117653131484985, acc=0.75, loss=0.8117653131484985
train: epoch 109, loss 0.3226165771484375, acc=0.851722240447998, loss=0.3226165771484375
test: epoch 109, loss 0.7565587759017944, acc=0.7444444298744202, loss=0.7565587759017944
train: epoch 110, loss 0.3272680938243866, acc=0.8496111035346985, loss=0.3272680938243866
test: epoch 110, loss 0.7904579639434814, acc=0.7222222089767456, loss=0.7904579639434814
train: epoch 111, loss 0.32047396898269653, acc=0.8543333411216736, loss=0.32047396898269653
test: epoch 111, loss 0.7594819068908691, acc=0.7333333492279053, loss=0.7594819068908691
train: epoch 112, loss 0.32020482420921326, acc=0.8552777767181396, loss=0.32020482420921326
test: epoch 112, loss 0.6218931078910828, acc=0.7611111402511597, loss=0.6218931078910828
train: epoch 113, loss 0.31658244132995605, acc=0.8561111092567444, loss=0.31658244132995605
test: epoch 113, loss 0.7096589803695679, acc=0.7416666746139526, loss=0.7096589803695679
train: epoch 114, loss 0.3174515962600708, acc=0.8539999723434448, loss=0.3174515962600708
test: epoch 114, loss 0.6391966342926025, acc=0.7361111044883728, loss=0.6391966342926025
train: epoch 115, loss 0.3222391605377197, acc=0.854888916015625, loss=0.3222391605377197
test: epoch 115, loss 0.8074544668197632, acc=0.7194444537162781, loss=0.8074544668197632
train: epoch 116, loss 0.31982168555259705, acc=0.8561111092567444, loss=0.31982168555259705
test: epoch 116, loss 0.6614164113998413, acc=0.7527777552604675, loss=0.6614164113998413
train: epoch 117, loss 0.31502199172973633, acc=0.856333315372467, loss=0.31502199172973633
test: epoch 117, loss 0.7655414342880249, acc=0.7222222089767456, loss=0.7655414342880249
train: epoch 118, loss 0.31048476696014404, acc=0.8586666584014893, loss=0.31048476696014404
test: epoch 118, loss 0.5757707357406616, acc=0.7833333611488342, loss=0.5757707357406616
train: epoch 119, loss 0.3101598024368286, acc=0.8569444417953491, loss=0.3101598024368286
test: epoch 119, loss 0.6381102204322815, acc=0.7666666507720947, loss=0.6381102204322815
train: epoch 120, loss 0.3045661151409149, acc=0.8607222437858582, loss=0.3045661151409149
test: epoch 120, loss 0.594771146774292, acc=0.7722222208976746, loss=0.594771146774292
train: epoch 121, loss 0.3073558807373047, acc=0.858222246170044, loss=0.3073558807373047
test: epoch 121, loss 0.6698992848396301, acc=0.7611111402511597, loss=0.6698992848396301
train: epoch 122, loss 0.31552210450172424, acc=0.8580555319786072, loss=0.31552210450172424
test: epoch 122, loss 0.6373358368873596, acc=0.7777777910232544, loss=0.6373358368873596
train: epoch 123, loss 0.2935498356819153, acc=0.8623889088630676, loss=0.2935498356819153
test: epoch 123, loss 0.6191322207450867, acc=0.7777777910232544, loss=0.6191322207450867
train: epoch 124, loss 0.31579676270484924, acc=0.8549444675445557, loss=0.31579676270484924
test: epoch 124, loss 0.5578747987747192, acc=0.7583333253860474, loss=0.5578747987747192
train: epoch 125, loss 0.31792712211608887, acc=0.8541666865348816, loss=0.31792712211608887
test: epoch 125, loss 0.658147931098938, acc=0.800000011920929, loss=0.658147931098938
train: epoch 126, loss 0.2998603284358978, acc=0.8606666922569275, loss=0.2998603284358978
test: epoch 126, loss 0.5539442300796509, acc=0.7777777910232544, loss=0.5539442300796509
train: epoch 127, loss 0.293916255235672, acc=0.8614444732666016, loss=0.293916255235672
test: epoch 127, loss 0.6663055419921875, acc=0.7611111402511597, loss=0.6663055419921875
train: epoch 128, loss 0.31059131026268005, acc=0.8587777614593506, loss=0.31059131026268005
test: epoch 128, loss 0.6272966265678406, acc=0.7777777910232544, loss=0.6272966265678406
train: epoch 129, loss 0.30180174112319946, acc=0.8601666688919067, loss=0.30180174112319946
test: epoch 129, loss 0.5855316519737244, acc=0.7777777910232544, loss=0.5855316519737244
train: epoch 130, loss 0.2957613170146942, acc=0.8615000247955322, loss=0.2957613170146942
test: epoch 130, loss 0.5623764395713806, acc=0.7777777910232544, loss=0.5623764395713806
train: epoch 131, loss 0.2949451506137848, acc=0.8616666793823242, loss=0.2949451506137848
test: epoch 131, loss 0.6209716200828552, acc=0.7638888955116272, loss=0.6209716200828552
train: epoch 132, loss 0.30826374888420105, acc=0.855222225189209, loss=0.30826374888420105
test: epoch 132, loss 0.5416149497032166, acc=0.7888888716697693, loss=0.5416149497032166
train: epoch 133, loss 0.2874363660812378, acc=0.8641111254692078, loss=0.2874363660812378
test: epoch 133, loss 0.5274691581726074, acc=0.7777777910232544, loss=0.5274691581726074
train: epoch 134, loss 0.2961018979549408, acc=0.8607222437858582, loss=0.2961018979549408
test: epoch 134, loss 0.48719555139541626, acc=0.8194444179534912, loss=0.48719555139541626
train: epoch 135, loss 0.30094435811042786, acc=0.8576111197471619, loss=0.30094435811042786
test: epoch 135, loss 0.6005831360816956, acc=0.7805555462837219, loss=0.6005831360816956
train: epoch 136, loss 0.30861547589302063, acc=0.8564444184303284, loss=0.30861547589302063
test: epoch 136, loss 0.614525556564331, acc=0.7777777910232544, loss=0.614525556564331
train: epoch 137, loss 0.2894173264503479, acc=0.8629444241523743, loss=0.2894173264503479
test: epoch 137, loss 0.4992762506008148, acc=0.7777777910232544, loss=0.4992762506008148
train: epoch 138, loss 0.280223548412323, acc=0.8651111125946045, loss=0.280223548412323
test: epoch 138, loss 0.5636110305786133, acc=0.8111110925674438, loss=0.5636110305786133
train: epoch 139, loss 0.2845652103424072, acc=0.8647222518920898, loss=0.2845652103424072
test: epoch 139, loss 0.6106380820274353, acc=0.800000011920929, loss=0.6106380820274353
train: epoch 140, loss 0.2878030836582184, acc=0.863611102104187, loss=0.2878030836582184
test: epoch 140, loss 0.45419880747795105, acc=0.8222222328186035, loss=0.45419880747795105
train: epoch 141, loss 0.29044902324676514, acc=0.8626111149787903, loss=0.29044902324676514
test: epoch 141, loss 0.4326416850090027, acc=0.8166666626930237, loss=0.4326416850090027
train: epoch 142, loss 0.2885110080242157, acc=0.8640000224113464, loss=0.2885110080242157
test: epoch 142, loss 0.5203160643577576, acc=0.7777777910232544, loss=0.5203160643577576
train: epoch 143, loss 0.27975600957870483, acc=0.8632222414016724, loss=0.27975600957870483
test: epoch 143, loss 0.4327608048915863, acc=0.8222222328186035, loss=0.4327608048915863
train: epoch 144, loss 0.27175676822662354, acc=0.8716111183166504, loss=0.27175676822662354
test: epoch 144, loss 0.49969691038131714, acc=0.8194444179534912, loss=0.49969691038131714
train: epoch 145, loss 0.27029621601104736, acc=0.8798888921737671, loss=0.27029621601104736
test: epoch 145, loss 0.4838937520980835, acc=0.8194444179534912, loss=0.4838937520980835
train: epoch 146, loss 0.24617314338684082, acc=0.893833339214325, loss=0.24617314338684082
test: epoch 146, loss 0.47608932852745056, acc=0.8194444179534912, loss=0.47608932852745056
train: epoch 147, loss 0.23445111513137817, acc=0.9001666903495789, loss=0.23445111513137817
test: epoch 147, loss 0.574700117111206, acc=0.8194444179534912, loss=0.574700117111206
train: epoch 148, loss 0.21907232701778412, acc=0.9063888788223267, loss=0.21907232701778412
test: epoch 148, loss 0.5342534780502319, acc=0.8166666626930237, loss=0.5342534780502319
train: epoch 149, loss 0.22023913264274597, acc=0.9075555801391602, loss=0.22023913264274597
test: epoch 149, loss 0.5431257486343384, acc=0.8194444179534912, loss=0.5431257486343384
train: epoch 150, loss 0.2123410552740097, acc=0.9064444303512573, loss=0.2123410552740097
test: epoch 150, loss 0.48958903551101685, acc=0.8194444179534912, loss=0.48958903551101685
