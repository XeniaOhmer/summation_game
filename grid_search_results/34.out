# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1.5", "--temp_decay=0.99", "--one_hot=false", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=637172066, receiver_embed_dim=32, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.123838424682617, acc=0.06511110812425613, loss=3.123838424682617
test: epoch 1, loss 3.225292444229126, acc=0.10000000149011612, loss=3.225292444229126
train: epoch 2, loss 2.1661486625671387, acc=0.18816666305065155, loss=2.1661486625671387
test: epoch 2, loss 3.0630717277526855, acc=0.10555555671453476, loss=3.0630717277526855
train: epoch 3, loss 1.8552544116973877, acc=0.24566666781902313, loss=1.8552544116973877
test: epoch 3, loss 3.3703689575195312, acc=0.14166666567325592, loss=3.3703689575195312
train: epoch 4, loss 1.6992733478546143, acc=0.28511109948158264, loss=1.6992733478546143
test: epoch 4, loss 3.3211162090301514, acc=0.1527777761220932, loss=3.3211162090301514
train: epoch 5, loss 1.5864698886871338, acc=0.3133888840675354, loss=1.5864698886871338
test: epoch 5, loss 3.5756030082702637, acc=0.125, loss=3.5756030082702637
train: epoch 6, loss 1.508283019065857, acc=0.347555547952652, loss=1.508283019065857
test: epoch 6, loss 3.4597208499908447, acc=0.12777778506278992, loss=3.4597208499908447
train: epoch 7, loss 1.4377390146255493, acc=0.3949444591999054, loss=1.4377390146255493
test: epoch 7, loss 3.591433525085449, acc=0.16388888657093048, loss=3.591433525085449
train: epoch 8, loss 1.3383755683898926, acc=0.4413333237171173, loss=1.3383755683898926
test: epoch 8, loss 3.6235029697418213, acc=0.1388888955116272, loss=3.6235029697418213
train: epoch 9, loss 1.216015100479126, acc=0.5163333415985107, loss=1.216015100479126
test: epoch 9, loss 3.162308931350708, acc=0.17222222685813904, loss=3.162308931350708
train: epoch 10, loss 1.1101680994033813, acc=0.5527222156524658, loss=1.1101680994033813
test: epoch 10, loss 2.7417876720428467, acc=0.24444444477558136, loss=2.7417876720428467
train: epoch 11, loss 1.003410816192627, acc=0.5911666750907898, loss=1.003410816192627
test: epoch 11, loss 3.20015025138855, acc=0.23055554926395416, loss=3.20015025138855
train: epoch 12, loss 0.9162951111793518, acc=0.6206666827201843, loss=0.9162951111793518
test: epoch 12, loss 2.2046847343444824, acc=0.2638888955116272, loss=2.2046847343444824
train: epoch 13, loss 0.8663442134857178, acc=0.6421666741371155, loss=0.8663442134857178
test: epoch 13, loss 2.414128541946411, acc=0.27222222089767456, loss=2.414128541946411
train: epoch 14, loss 0.8150380849838257, acc=0.6590555310249329, loss=0.8150380849838257
test: epoch 14, loss 2.4270758628845215, acc=0.25833332538604736, loss=2.4270758628845215
train: epoch 15, loss 0.7907118201255798, acc=0.6746666431427002, loss=0.7907118201255798
test: epoch 15, loss 1.8708018064498901, acc=0.2750000059604645, loss=1.8708018064498901
train: epoch 16, loss 0.7468175292015076, acc=0.6883333325386047, loss=0.7468175292015076
test: epoch 16, loss 1.9621840715408325, acc=0.3222222328186035, loss=1.9621840715408325
train: epoch 17, loss 0.7356653809547424, acc=0.6980555653572083, loss=0.7356653809547424
test: epoch 17, loss 1.8945002555847168, acc=0.3305555582046509, loss=1.8945002555847168
train: epoch 18, loss 0.7002729773521423, acc=0.7121666669845581, loss=0.7002729773521423
test: epoch 18, loss 1.6864969730377197, acc=0.3638888895511627, loss=1.6864969730377197
train: epoch 19, loss 0.671454131603241, acc=0.7217222452163696, loss=0.671454131603241
test: epoch 19, loss 1.7829949855804443, acc=0.33888888359069824, loss=1.7829949855804443
train: epoch 20, loss 0.6419277787208557, acc=0.7313888669013977, loss=0.6419277787208557
test: epoch 20, loss 1.6519578695297241, acc=0.3722222149372101, loss=1.6519578695297241
train: epoch 21, loss 0.6229931712150574, acc=0.7397778034210205, loss=0.6229931712150574
test: epoch 21, loss 1.7660027742385864, acc=0.33888888359069824, loss=1.7660027742385864
train: epoch 22, loss 0.6129993200302124, acc=0.7438333630561829, loss=0.6129993200302124
test: epoch 22, loss 1.7080130577087402, acc=0.3722222149372101, loss=1.7080130577087402
train: epoch 23, loss 0.6137380003929138, acc=0.7405555844306946, loss=0.6137380003929138
test: epoch 23, loss 1.7966700792312622, acc=0.3611111044883728, loss=1.7966700792312622
train: epoch 24, loss 0.5914061665534973, acc=0.7496111392974854, loss=0.5914061665534973
test: epoch 24, loss 1.6309672594070435, acc=0.3888888955116272, loss=1.6309672594070435
train: epoch 25, loss 0.5937292575836182, acc=0.7536666393280029, loss=0.5937292575836182
test: epoch 25, loss 1.7712056636810303, acc=0.3777777850627899, loss=1.7712056636810303
train: epoch 26, loss 0.5893222093582153, acc=0.7481111288070679, loss=0.5893222093582153
test: epoch 26, loss 1.6807993650436401, acc=0.42222222685813904, loss=1.6807993650436401
train: epoch 27, loss 0.5671865344047546, acc=0.7591666579246521, loss=0.5671865344047546
test: epoch 27, loss 1.5762372016906738, acc=0.4305555522441864, loss=1.5762372016906738
train: epoch 28, loss 0.5721249580383301, acc=0.757611095905304, loss=0.5721249580383301
test: epoch 28, loss 1.5447062253952026, acc=0.4194444417953491, loss=1.5447062253952026
train: epoch 29, loss 0.5583683848381042, acc=0.7590000033378601, loss=0.5583683848381042
test: epoch 29, loss 1.5090378522872925, acc=0.45277777314186096, loss=1.5090378522872925
train: epoch 30, loss 0.5349693298339844, acc=0.7716110944747925, loss=0.5349693298339844
test: epoch 30, loss 1.5734351873397827, acc=0.4305555522441864, loss=1.5734351873397827
train: epoch 31, loss 0.544061541557312, acc=0.769777774810791, loss=0.544061541557312
test: epoch 31, loss 1.7599525451660156, acc=0.3722222149372101, loss=1.7599525451660156
train: epoch 32, loss 0.5251729488372803, acc=0.7736666798591614, loss=0.5251729488372803
test: epoch 32, loss 1.6695640087127686, acc=0.42222222685813904, loss=1.6695640087127686
train: epoch 33, loss 0.542327344417572, acc=0.7703333497047424, loss=0.542327344417572
test: epoch 33, loss 1.5388977527618408, acc=0.48055556416511536, loss=1.5388977527618408
train: epoch 34, loss 0.5337494611740112, acc=0.7723333239555359, loss=0.5337494611740112
test: epoch 34, loss 1.5622572898864746, acc=0.49166667461395264, loss=1.5622572898864746
train: epoch 35, loss 0.5229271650314331, acc=0.778166651725769, loss=0.5229271650314331
test: epoch 35, loss 1.6913821697235107, acc=0.4472222328186035, loss=1.6913821697235107
train: epoch 36, loss 0.5068759918212891, acc=0.7804444432258606, loss=0.5068759918212891
test: epoch 36, loss 1.3639237880706787, acc=0.4416666626930237, loss=1.3639237880706787
train: epoch 37, loss 0.5141531825065613, acc=0.7815555334091187, loss=0.5141531825065613
test: epoch 37, loss 1.4162505865097046, acc=0.4583333432674408, loss=1.4162505865097046
train: epoch 38, loss 0.510589063167572, acc=0.781333327293396, loss=0.510589063167572
test: epoch 38, loss 1.5784189701080322, acc=0.42500001192092896, loss=1.5784189701080322
train: epoch 39, loss 0.5097148418426514, acc=0.7825000286102295, loss=0.5097148418426514
test: epoch 39, loss 1.4752825498580933, acc=0.4000000059604645, loss=1.4752825498580933
train: epoch 40, loss 0.5024603605270386, acc=0.785444438457489, loss=0.5024603605270386
test: epoch 40, loss 1.478107213973999, acc=0.41111111640930176, loss=1.478107213973999
train: epoch 41, loss 0.4896470606327057, acc=0.7901111245155334, loss=0.4896470606327057
test: epoch 41, loss 1.5157643556594849, acc=0.4305555522441864, loss=1.5157643556594849
train: epoch 42, loss 0.4771604537963867, acc=0.7943888902664185, loss=0.4771604537963867
test: epoch 42, loss 1.5049337148666382, acc=0.4694444537162781, loss=1.5049337148666382
train: epoch 43, loss 0.48658278584480286, acc=0.7926666736602783, loss=0.48658278584480286
test: epoch 43, loss 1.4398711919784546, acc=0.46666666865348816, loss=1.4398711919784546
train: epoch 44, loss 0.480890154838562, acc=0.7951111197471619, loss=0.480890154838562
test: epoch 44, loss 1.408052682876587, acc=0.4888888895511627, loss=1.408052682876587
train: epoch 45, loss 0.4879525601863861, acc=0.7935555577278137, loss=0.4879525601863861
test: epoch 45, loss 1.4457882642745972, acc=0.4611110985279083, loss=1.4457882642745972
train: epoch 46, loss 0.49942994117736816, acc=0.7850000262260437, loss=0.49942994117736816
test: epoch 46, loss 1.345786452293396, acc=0.4694444537162781, loss=1.345786452293396
train: epoch 47, loss 0.48025161027908325, acc=0.7947221994400024, loss=0.48025161027908325
test: epoch 47, loss 1.5832806825637817, acc=0.4749999940395355, loss=1.5832806825637817
train: epoch 48, loss 0.48813459277153015, acc=0.7941666841506958, loss=0.48813459277153015
test: epoch 48, loss 1.4778995513916016, acc=0.45277777314186096, loss=1.4778995513916016
train: epoch 49, loss 0.46709534525871277, acc=0.7974444627761841, loss=0.46709534525871277
test: epoch 49, loss 1.397107481956482, acc=0.4444444477558136, loss=1.397107481956482
train: epoch 50, loss 0.4827994108200073, acc=0.793833315372467, loss=0.4827994108200073
test: epoch 50, loss 1.3837573528289795, acc=0.4722222089767456, loss=1.3837573528289795
train: epoch 51, loss 0.4881827235221863, acc=0.7922222018241882, loss=0.4881827235221863
test: epoch 51, loss 1.206446647644043, acc=0.46666666865348816, loss=1.206446647644043
train: epoch 52, loss 0.477169930934906, acc=0.7934444546699524, loss=0.477169930934906
test: epoch 52, loss 1.291585922241211, acc=0.5138888955116272, loss=1.291585922241211
train: epoch 53, loss 0.47298067808151245, acc=0.7976111173629761, loss=0.47298067808151245
test: epoch 53, loss 1.3748080730438232, acc=0.49444442987442017, loss=1.3748080730438232
train: epoch 54, loss 0.48178476095199585, acc=0.7911666631698608, loss=0.48178476095199585
test: epoch 54, loss 1.128929853439331, acc=0.5111111402511597, loss=1.128929853439331
train: epoch 55, loss 0.482019305229187, acc=0.7980555295944214, loss=0.482019305229187
test: epoch 55, loss 1.3936842679977417, acc=0.46388888359069824, loss=1.3936842679977417
train: epoch 56, loss 0.470180481672287, acc=0.7983333468437195, loss=0.470180481672287
test: epoch 56, loss 1.5465528964996338, acc=0.5055555701255798, loss=1.5465528964996338
train: epoch 57, loss 0.4948354959487915, acc=0.7909444570541382, loss=0.4948354959487915
test: epoch 57, loss 1.2886441946029663, acc=0.5111111402511597, loss=1.2886441946029663
train: epoch 58, loss 0.47879430651664734, acc=0.7958889007568359, loss=0.47879430651664734
test: epoch 58, loss 1.2096301317214966, acc=0.5361111164093018, loss=1.2096301317214966
train: epoch 59, loss 0.47046077251434326, acc=0.8020555377006531, loss=0.47046077251434326
test: epoch 59, loss 1.1677294969558716, acc=0.5027777552604675, loss=1.1677294969558716
train: epoch 60, loss 0.4715307354927063, acc=0.7970555424690247, loss=0.4715307354927063
test: epoch 60, loss 1.3227758407592773, acc=0.519444465637207, loss=1.3227758407592773
train: epoch 61, loss 0.48616936802864075, acc=0.7921110987663269, loss=0.48616936802864075
test: epoch 61, loss 1.4315862655639648, acc=0.5055555701255798, loss=1.4315862655639648
train: epoch 62, loss 0.4777109622955322, acc=0.7950000166893005, loss=0.4777109622955322
test: epoch 62, loss 1.3262168169021606, acc=0.4861111044883728, loss=1.3262168169021606
train: epoch 63, loss 0.47539645433425903, acc=0.7965555787086487, loss=0.47539645433425903
test: epoch 63, loss 1.2207480669021606, acc=0.5305555462837219, loss=1.2207480669021606
train: epoch 64, loss 0.4798666536808014, acc=0.7951111197471619, loss=0.4798666536808014
test: epoch 64, loss 1.4162390232086182, acc=0.5166666507720947, loss=1.4162390232086182
train: epoch 65, loss 0.47490638494491577, acc=0.7944444417953491, loss=0.47490638494491577
test: epoch 65, loss 1.162442684173584, acc=0.5166666507720947, loss=1.162442684173584
train: epoch 66, loss 0.46348169445991516, acc=0.7974444627761841, loss=0.46348169445991516
test: epoch 66, loss 1.4609788656234741, acc=0.5277777910232544, loss=1.4609788656234741
train: epoch 67, loss 0.47051942348480225, acc=0.7993333339691162, loss=0.47051942348480225
test: epoch 67, loss 1.1708803176879883, acc=0.5472221970558167, loss=1.1708803176879883
train: epoch 68, loss 0.46186506748199463, acc=0.8018888831138611, loss=0.46186506748199463
test: epoch 68, loss 0.9166997671127319, acc=0.6166666746139526, loss=0.9166997671127319
train: epoch 69, loss 0.475361704826355, acc=0.7932222485542297, loss=0.475361704826355
test: epoch 69, loss 1.1033573150634766, acc=0.5833333134651184, loss=1.1033573150634766
train: epoch 70, loss 0.4746858775615692, acc=0.7954999804496765, loss=0.4746858775615692
test: epoch 70, loss 0.9177191853523254, acc=0.5888888835906982, loss=0.9177191853523254
train: epoch 71, loss 0.4737873673439026, acc=0.796999990940094, loss=0.4737873673439026
test: epoch 71, loss 0.9254633188247681, acc=0.574999988079071, loss=0.9254633188247681
train: epoch 72, loss 0.45709776878356934, acc=0.7999444603919983, loss=0.45709776878356934
test: epoch 72, loss 0.9824780225753784, acc=0.5666666626930237, loss=0.9824780225753784
train: epoch 73, loss 0.45718422532081604, acc=0.8028888702392578, loss=0.45718422532081604
test: epoch 73, loss 1.1444381475448608, acc=0.5833333134651184, loss=1.1444381475448608
train: epoch 74, loss 0.4692135155200958, acc=0.7943333387374878, loss=0.4692135155200958
test: epoch 74, loss 0.8489535450935364, acc=0.5888888835906982, loss=0.8489535450935364
train: epoch 75, loss 0.4631878435611725, acc=0.7975555658340454, loss=0.4631878435611725
test: epoch 75, loss 0.9134936928749084, acc=0.605555534362793, loss=0.9134936928749084
train: epoch 76, loss 0.4489572048187256, acc=0.8029444217681885, loss=0.4489572048187256
test: epoch 76, loss 0.9037862420082092, acc=0.6111111044883728, loss=0.9037862420082092
train: epoch 77, loss 0.44646793603897095, acc=0.8057777881622314, loss=0.44646793603897095
test: epoch 77, loss 0.8335316181182861, acc=0.5972222089767456, loss=0.8335316181182861
train: epoch 78, loss 0.4271761476993561, acc=0.812666654586792, loss=0.4271761476993561
test: epoch 78, loss 0.9125251173973083, acc=0.6499999761581421, loss=0.9125251173973083
train: epoch 79, loss 0.44836077094078064, acc=0.8057222366333008, loss=0.44836077094078064
test: epoch 79, loss 0.9462518095970154, acc=0.6166666746139526, loss=0.9462518095970154
train: epoch 80, loss 0.4354248344898224, acc=0.8105555772781372, loss=0.4354248344898224
test: epoch 80, loss 0.8706855773925781, acc=0.6527777910232544, loss=0.8706855773925781
train: epoch 81, loss 0.4392765760421753, acc=0.809166669845581, loss=0.4392765760421753
test: epoch 81, loss 0.9168319702148438, acc=0.6111111044883728, loss=0.9168319702148438
train: epoch 82, loss 0.44661375880241394, acc=0.8063333630561829, loss=0.44661375880241394
test: epoch 82, loss 0.9392848014831543, acc=0.6361111402511597, loss=0.9392848014831543
train: epoch 83, loss 0.4212239980697632, acc=0.8150555491447449, loss=0.4212239980697632
test: epoch 83, loss 0.8154834508895874, acc=0.644444465637207, loss=0.8154834508895874
train: epoch 84, loss 0.43089568614959717, acc=0.812166690826416, loss=0.43089568614959717
test: epoch 84, loss 1.027896523475647, acc=0.5694444179534912, loss=1.027896523475647
train: epoch 85, loss 0.4356043040752411, acc=0.809499979019165, loss=0.4356043040752411
test: epoch 85, loss 0.9983513355255127, acc=0.6194444298744202, loss=0.9983513355255127
train: epoch 86, loss 0.42060577869415283, acc=0.8141666650772095, loss=0.42060577869415283
test: epoch 86, loss 0.9004629850387573, acc=0.5972222089767456, loss=0.9004629850387573
train: epoch 87, loss 0.41006404161453247, acc=0.8200555443763733, loss=0.41006404161453247
test: epoch 87, loss 0.9510951638221741, acc=0.6194444298744202, loss=0.9510951638221741
train: epoch 88, loss 0.42476046085357666, acc=0.8140000104904175, loss=0.42476046085357666
test: epoch 88, loss 0.8717719316482544, acc=0.6694444417953491, loss=0.8717719316482544
train: epoch 89, loss 0.40933018922805786, acc=0.8191666603088379, loss=0.40933018922805786
test: epoch 89, loss 1.0214320421218872, acc=0.6138888597488403, loss=1.0214320421218872
train: epoch 90, loss 0.4060720205307007, acc=0.8180555701255798, loss=0.4060720205307007
test: epoch 90, loss 0.8693429827690125, acc=0.625, loss=0.8693429827690125
train: epoch 91, loss 0.4019779860973358, acc=0.8209999799728394, loss=0.4019779860973358
test: epoch 91, loss 0.9201002717018127, acc=0.6527777910232544, loss=0.9201002717018127
train: epoch 92, loss 0.42052435874938965, acc=0.8168888688087463, loss=0.42052435874938965
test: epoch 92, loss 0.8948476314544678, acc=0.6388888955116272, loss=0.8948476314544678
train: epoch 93, loss 0.39945194125175476, acc=0.8185555338859558, loss=0.39945194125175476
test: epoch 93, loss 0.8974590301513672, acc=0.6499999761581421, loss=0.8974590301513672
train: epoch 94, loss 0.40304630994796753, acc=0.8228333592414856, loss=0.40304630994796753
test: epoch 94, loss 0.7940889596939087, acc=0.6388888955116272, loss=0.7940889596939087
train: epoch 95, loss 0.41552022099494934, acc=0.8142222166061401, loss=0.41552022099494934
test: epoch 95, loss 0.7800779938697815, acc=0.6499999761581421, loss=0.7800779938697815
train: epoch 96, loss 0.385964959859848, acc=0.8284444212913513, loss=0.385964959859848
test: epoch 96, loss 0.8370352983474731, acc=0.6805555820465088, loss=0.8370352983474731
train: epoch 97, loss 0.3761354684829712, acc=0.8277222514152527, loss=0.3761354684829712
test: epoch 97, loss 0.7893271446228027, acc=0.6861110925674438, loss=0.7893271446228027
train: epoch 98, loss 0.3914873003959656, acc=0.8261666893959045, loss=0.3914873003959656
test: epoch 98, loss 0.7684387564659119, acc=0.644444465637207, loss=0.7684387564659119
train: epoch 99, loss 0.38856789469718933, acc=0.8237777948379517, loss=0.38856789469718933
test: epoch 99, loss 0.8887326717376709, acc=0.6638888716697693, loss=0.8887326717376709
train: epoch 100, loss 0.382953405380249, acc=0.8291666507720947, loss=0.382953405380249
test: epoch 100, loss 0.7886488437652588, acc=0.6416666507720947, loss=0.7886488437652588
train: epoch 101, loss 0.38919901847839355, acc=0.8286111354827881, loss=0.38919901847839355
test: epoch 101, loss 0.8074631094932556, acc=0.675000011920929, loss=0.8074631094932556
train: epoch 102, loss 0.37467989325523376, acc=0.8288888931274414, loss=0.37467989325523376
test: epoch 102, loss 0.7866001129150391, acc=0.6916666626930237, loss=0.7866001129150391
train: epoch 103, loss 0.3792102336883545, acc=0.8308333158493042, loss=0.3792102336883545
test: epoch 103, loss 0.8437678217887878, acc=0.6916666626930237, loss=0.8437678217887878
train: epoch 104, loss 0.3755914568901062, acc=0.8312777876853943, loss=0.3755914568901062
test: epoch 104, loss 0.6994727253913879, acc=0.6916666626930237, loss=0.6994727253913879
train: epoch 105, loss 0.37696459889411926, acc=0.8306666612625122, loss=0.37696459889411926
test: epoch 105, loss 0.7461819052696228, acc=0.7027778029441833, loss=0.7461819052696228
train: epoch 106, loss 0.3662094175815582, acc=0.8337222337722778, loss=0.3662094175815582
test: epoch 106, loss 0.6916889548301697, acc=0.6722221970558167, loss=0.6916889548301697
train: epoch 107, loss 0.3733179271221161, acc=0.8330000042915344, loss=0.3733179271221161
test: epoch 107, loss 0.7854694128036499, acc=0.699999988079071, loss=0.7854694128036499
train: epoch 108, loss 0.360740065574646, acc=0.8345000147819519, loss=0.360740065574646
test: epoch 108, loss 0.835386335849762, acc=0.6611111164093018, loss=0.835386335849762
train: epoch 109, loss 0.3706347346305847, acc=0.8298333287239075, loss=0.3706347346305847
test: epoch 109, loss 0.813845694065094, acc=0.6861110925674438, loss=0.813845694065094
train: epoch 110, loss 0.35708460211753845, acc=0.8404444456100464, loss=0.35708460211753845
test: epoch 110, loss 0.8540985584259033, acc=0.6499999761581421, loss=0.8540985584259033
train: epoch 111, loss 0.37856525182724, acc=0.8294444680213928, loss=0.37856525182724
test: epoch 111, loss 0.7874740958213806, acc=0.6861110925674438, loss=0.7874740958213806
train: epoch 112, loss 0.35586637258529663, acc=0.8381666541099548, loss=0.35586637258529663
test: epoch 112, loss 0.7465243935585022, acc=0.6888889074325562, loss=0.7465243935585022
train: epoch 113, loss 0.3628152310848236, acc=0.8344444632530212, loss=0.3628152310848236
test: epoch 113, loss 0.7467381954193115, acc=0.6972222328186035, loss=0.7467381954193115
train: epoch 114, loss 0.36930447816848755, acc=0.8323333263397217, loss=0.36930447816848755
test: epoch 114, loss 0.645107090473175, acc=0.6861110925674438, loss=0.645107090473175
train: epoch 115, loss 0.3606545329093933, acc=0.8373333215713501, loss=0.3606545329093933
test: epoch 115, loss 0.7354928255081177, acc=0.6777777671813965, loss=0.7354928255081177
train: epoch 116, loss 0.35173869132995605, acc=0.839888870716095, loss=0.35173869132995605
test: epoch 116, loss 0.719914436340332, acc=0.6944444179534912, loss=0.719914436340332
train: epoch 117, loss 0.3608507215976715, acc=0.8374999761581421, loss=0.3608507215976715
test: epoch 117, loss 0.7916311621665955, acc=0.6972222328186035, loss=0.7916311621665955
train: epoch 118, loss 0.3563215136528015, acc=0.8391666412353516, loss=0.3563215136528015
test: epoch 118, loss 0.7215774655342102, acc=0.6833333373069763, loss=0.7215774655342102
train: epoch 119, loss 0.34807777404785156, acc=0.8399999737739563, loss=0.34807777404785156
test: epoch 119, loss 0.852169394493103, acc=0.6777777671813965, loss=0.852169394493103
train: epoch 120, loss 0.35590970516204834, acc=0.8388888835906982, loss=0.35590970516204834
test: epoch 120, loss 0.8840318918228149, acc=0.6916666626930237, loss=0.8840318918228149
train: epoch 121, loss 0.3446038067340851, acc=0.8411111235618591, loss=0.3446038067340851
test: epoch 121, loss 0.6958166360855103, acc=0.7027778029441833, loss=0.6958166360855103
train: epoch 122, loss 0.33878058195114136, acc=0.8445000052452087, loss=0.33878058195114136
test: epoch 122, loss 0.7313799858093262, acc=0.7055555582046509, loss=0.7313799858093262
train: epoch 123, loss 0.35744529962539673, acc=0.8385000228881836, loss=0.35744529962539673
test: epoch 123, loss 0.9997579455375671, acc=0.6972222328186035, loss=0.9997579455375671
train: epoch 124, loss 0.34679096937179565, acc=0.839888870716095, loss=0.34679096937179565
test: epoch 124, loss 0.8190241456031799, acc=0.6694444417953491, loss=0.8190241456031799
train: epoch 125, loss 0.34603533148765564, acc=0.8426666855812073, loss=0.34603533148765564
test: epoch 125, loss 0.8854142427444458, acc=0.6888889074325562, loss=0.8854142427444458
train: epoch 126, loss 0.345396488904953, acc=0.8493888974189758, loss=0.345396488904953
test: epoch 126, loss 0.8629751801490784, acc=0.6916666626930237, loss=0.8629751801490784
train: epoch 127, loss 0.33360525965690613, acc=0.8567777872085571, loss=0.33360525965690613
test: epoch 127, loss 0.7751649022102356, acc=0.6944444179534912, loss=0.7751649022102356
train: epoch 128, loss 0.32987070083618164, acc=0.8622221946716309, loss=0.32987070083618164
test: epoch 128, loss 0.8372390866279602, acc=0.6888889074325562, loss=0.8372390866279602
train: epoch 129, loss 0.31844428181648254, acc=0.8746111392974854, loss=0.31844428181648254
test: epoch 129, loss 0.9396011829376221, acc=0.6861110925674438, loss=0.9396011829376221
train: epoch 130, loss 0.2967393696308136, acc=0.8869444727897644, loss=0.2967393696308136
test: epoch 130, loss 0.917723536491394, acc=0.7055555582046509, loss=0.917723536491394
train: epoch 131, loss 0.30039432644844055, acc=0.8877778053283691, loss=0.30039432644844055
test: epoch 131, loss 0.7392721772193909, acc=0.6888889074325562, loss=0.7392721772193909
train: epoch 132, loss 0.2889265716075897, acc=0.8925555348396301, loss=0.2889265716075897
test: epoch 132, loss 0.8792250752449036, acc=0.6861110925674438, loss=0.8792250752449036
train: epoch 133, loss 0.27879083156585693, acc=0.8978888988494873, loss=0.27879083156585693
test: epoch 133, loss 0.7691784501075745, acc=0.699999988079071, loss=0.7691784501075745
train: epoch 134, loss 0.28809282183647156, acc=0.8974444270133972, loss=0.28809282183647156
test: epoch 134, loss 0.8009514808654785, acc=0.7138888835906982, loss=0.8009514808654785
train: epoch 135, loss 0.24863669276237488, acc=0.9119444489479065, loss=0.24863669276237488
test: epoch 135, loss 0.7679558992385864, acc=0.7166666388511658, loss=0.7679558992385864
train: epoch 136, loss 0.25981956720352173, acc=0.9049444198608398, loss=0.25981956720352173
test: epoch 136, loss 0.8137662410736084, acc=0.6972222328186035, loss=0.8137662410736084
train: epoch 137, loss 0.25630152225494385, acc=0.9096111059188843, loss=0.25630152225494385
test: epoch 137, loss 0.868766725063324, acc=0.7083333134651184, loss=0.868766725063324
train: epoch 138, loss 0.23776830732822418, acc=0.9174444675445557, loss=0.23776830732822418
test: epoch 138, loss 0.6660044193267822, acc=0.7083333134651184, loss=0.6660044193267822
train: epoch 139, loss 0.2535843849182129, acc=0.9115555286407471, loss=0.2535843849182129
test: epoch 139, loss 0.8194271922111511, acc=0.7166666388511658, loss=0.8194271922111511
train: epoch 140, loss 0.23561860620975494, acc=0.9197777509689331, loss=0.23561860620975494
test: epoch 140, loss 0.7606991529464722, acc=0.7277777791023254, loss=0.7606991529464722
train: epoch 141, loss 0.24103689193725586, acc=0.9152777791023254, loss=0.24103689193725586
test: epoch 141, loss 0.7838948965072632, acc=0.7416666746139526, loss=0.7838948965072632
train: epoch 142, loss 0.2453172653913498, acc=0.9138888716697693, loss=0.2453172653913498
test: epoch 142, loss 0.7321255207061768, acc=0.75, loss=0.7321255207061768
train: epoch 143, loss 0.25849664211273193, acc=0.9105555415153503, loss=0.25849664211273193
test: epoch 143, loss 0.8985877633094788, acc=0.7472222447395325, loss=0.8985877633094788
train: epoch 144, loss 0.24012573063373566, acc=0.9156110882759094, loss=0.24012573063373566
test: epoch 144, loss 0.5975055694580078, acc=0.7555555701255798, loss=0.5975055694580078
train: epoch 145, loss 0.2384851723909378, acc=0.9185000061988831, loss=0.2384851723909378
test: epoch 145, loss 0.7431013584136963, acc=0.7583333253860474, loss=0.7431013584136963
train: epoch 146, loss 0.22038386762142181, acc=0.921833336353302, loss=0.22038386762142181
test: epoch 146, loss 0.8000710606575012, acc=0.7583333253860474, loss=0.8000710606575012
train: epoch 147, loss 0.2211003601551056, acc=0.9234444499015808, loss=0.2211003601551056
test: epoch 147, loss 0.7629514336585999, acc=0.7472222447395325, loss=0.7629514336585999
train: epoch 148, loss 0.23207227885723114, acc=0.9201666712760925, loss=0.23207227885723114
test: epoch 148, loss 0.7583655714988708, acc=0.75, loss=0.7583655714988708
train: epoch 149, loss 0.2110624462366104, acc=0.9262222051620483, loss=0.2110624462366104
test: epoch 149, loss 0.9148615002632141, acc=0.7277777791023254, loss=0.9148615002632141
train: epoch 150, loss 0.23199690878391266, acc=0.9199444651603699, loss=0.23199690878391266
test: epoch 150, loss 0.8079895973205566, acc=0.7527777552604675, loss=0.8079895973205566
