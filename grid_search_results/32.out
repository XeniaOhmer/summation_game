# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=1.5", "--temp_decay=0.99", "--one_hot=0", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=1653363470, receiver_embed_dim=32, save_run=0, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=1653363470, receiver_embed_dim=32, save_run=False, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.7179248332977295, acc=0.12427777796983719, loss=2.7179248332977295
test: epoch 1, loss 5.005092620849609, acc=0.07777778059244156, loss=5.005092620849609
train: epoch 2, loss 1.9477840662002563, acc=0.2532777786254883, loss=1.9477840662002563
test: epoch 2, loss 4.857425212860107, acc=0.09166666865348816, loss=4.857425212860107
train: epoch 3, loss 1.6449781656265259, acc=0.34288889169692993, loss=1.6449781656265259
test: epoch 3, loss 4.854819297790527, acc=0.0833333358168602, loss=4.854819297790527
train: epoch 4, loss 1.4903398752212524, acc=0.39011111855506897, loss=1.4903398752212524
test: epoch 4, loss 3.9387476444244385, acc=0.11944444477558136, loss=3.9387476444244385
train: epoch 5, loss 1.3807533979415894, acc=0.433944433927536, loss=1.3807533979415894
test: epoch 5, loss 3.1624231338500977, acc=0.1666666716337204, loss=3.1624231338500977
train: epoch 6, loss 1.301253318786621, acc=0.4803333282470703, loss=1.301253318786621
test: epoch 6, loss 3.0162038803100586, acc=0.1805555522441864, loss=3.0162038803100586
train: epoch 7, loss 1.2564167976379395, acc=0.49522221088409424, loss=1.2564167976379395
test: epoch 7, loss 3.32671856880188, acc=0.1944444477558136, loss=3.32671856880188
train: epoch 8, loss 1.1948975324630737, acc=0.5225555300712585, loss=1.1948975324630737
test: epoch 8, loss 3.135352373123169, acc=0.21666666865348816, loss=3.135352373123169
train: epoch 9, loss 1.1582698822021484, acc=0.5376666784286499, loss=1.1582698822021484
test: epoch 9, loss 3.0666511058807373, acc=0.19722221791744232, loss=3.0666511058807373
train: epoch 10, loss 1.1036162376403809, acc=0.5612221956253052, loss=1.1036162376403809
test: epoch 10, loss 2.643681287765503, acc=0.2527777850627899, loss=2.643681287765503
train: epoch 11, loss 1.1077557802200317, acc=0.5607777833938599, loss=1.1077557802200317
test: epoch 11, loss 2.900739908218384, acc=0.23333333432674408, loss=2.900739908218384
train: epoch 12, loss 1.064141035079956, acc=0.5731111168861389, loss=1.064141035079956
test: epoch 12, loss 2.434572458267212, acc=0.2888889014720917, loss=2.434572458267212
train: epoch 13, loss 1.0618330240249634, acc=0.5841666460037231, loss=1.0618330240249634
test: epoch 13, loss 2.5034103393554688, acc=0.23055554926395416, loss=2.5034103393554688
train: epoch 14, loss 1.0167179107666016, acc=0.6007221937179565, loss=1.0167179107666016
test: epoch 14, loss 2.1277005672454834, acc=0.30000001192092896, loss=2.1277005672454834
train: epoch 15, loss 1.0006382465362549, acc=0.6037222146987915, loss=1.0006382465362549
test: epoch 15, loss 1.9044698476791382, acc=0.3055555522441864, loss=1.9044698476791382
train: epoch 16, loss 0.9869512915611267, acc=0.6121666431427002, loss=0.9869512915611267
test: epoch 16, loss 2.923891544342041, acc=0.25555557012557983, loss=2.923891544342041
train: epoch 17, loss 0.9815566539764404, acc=0.616944432258606, loss=0.9815566539764404
test: epoch 17, loss 2.0310218334198, acc=0.25833332538604736, loss=2.0310218334198
train: epoch 18, loss 0.9527077674865723, acc=0.6244444251060486, loss=0.9527077674865723
test: epoch 18, loss 2.1755173206329346, acc=0.2611111104488373, loss=2.1755173206329346
train: epoch 19, loss 0.9607147574424744, acc=0.6235555410385132, loss=0.9607147574424744
test: epoch 19, loss 1.8922641277313232, acc=0.3027777671813965, loss=1.8922641277313232
train: epoch 20, loss 0.9387180209159851, acc=0.6274999976158142, loss=0.9387180209159851
test: epoch 20, loss 2.059497833251953, acc=0.2916666567325592, loss=2.059497833251953
train: epoch 21, loss 0.9391651153564453, acc=0.6337777972221375, loss=0.9391651153564453
test: epoch 21, loss 1.7978644371032715, acc=0.30000001192092896, loss=1.7978644371032715
train: epoch 22, loss 0.9266895055770874, acc=0.6373888850212097, loss=0.9266895055770874
test: epoch 22, loss 1.8513299226760864, acc=0.3222222328186035, loss=1.8513299226760864
train: epoch 23, loss 0.8853526711463928, acc=0.6506111025810242, loss=0.8853526711463928
test: epoch 23, loss 1.754159927368164, acc=0.3222222328186035, loss=1.754159927368164
train: epoch 24, loss 0.9013667106628418, acc=0.6470000147819519, loss=0.9013667106628418
test: epoch 24, loss 1.960121750831604, acc=0.32499998807907104, loss=1.960121750831604
train: epoch 25, loss 0.8693097233772278, acc=0.6575000286102295, loss=0.8693097233772278
test: epoch 25, loss 1.7878408432006836, acc=0.30000001192092896, loss=1.7878408432006836
train: epoch 26, loss 0.8663594722747803, acc=0.6572222113609314, loss=0.8663594722747803
test: epoch 26, loss 1.7312427759170532, acc=0.34166666865348816, loss=1.7312427759170532
train: epoch 27, loss 0.8794291615486145, acc=0.6480000019073486, loss=0.8794291615486145
test: epoch 27, loss 1.8668959140777588, acc=0.3222222328186035, loss=1.8668959140777588
train: epoch 28, loss 0.8653852939605713, acc=0.6598333120346069, loss=0.8653852939605713
test: epoch 28, loss 1.5235005617141724, acc=0.3638888895511627, loss=1.5235005617141724
train: epoch 29, loss 0.8154118657112122, acc=0.6770555377006531, loss=0.8154118657112122
test: epoch 29, loss 1.7621500492095947, acc=0.32499998807907104, loss=1.7621500492095947
train: epoch 30, loss 0.838013768196106, acc=0.6703333258628845, loss=0.838013768196106
test: epoch 30, loss 1.5673332214355469, acc=0.3611111044883728, loss=1.5673332214355469
train: epoch 31, loss 0.8241996169090271, acc=0.6700555682182312, loss=0.8241996169090271
test: epoch 31, loss 1.5911571979522705, acc=0.32777777314186096, loss=1.5911571979522705
train: epoch 32, loss 0.8167165517807007, acc=0.6772778034210205, loss=0.8167165517807007
test: epoch 32, loss 1.6804126501083374, acc=0.3305555582046509, loss=1.6804126501083374
train: epoch 33, loss 0.8163529634475708, acc=0.674833357334137, loss=0.8163529634475708
test: epoch 33, loss 1.5571835041046143, acc=0.3861111104488373, loss=1.5571835041046143
train: epoch 34, loss 0.7907273173332214, acc=0.6850000023841858, loss=0.7907273173332214
test: epoch 34, loss 1.7250702381134033, acc=0.34166666865348816, loss=1.7250702381134033
train: epoch 35, loss 0.8072857856750488, acc=0.6752777695655823, loss=0.8072857856750488
test: epoch 35, loss 1.7691247463226318, acc=0.35277777910232544, loss=1.7691247463226318
train: epoch 36, loss 0.7923228740692139, acc=0.6827222108840942, loss=0.7923228740692139
test: epoch 36, loss 1.7978538274765015, acc=0.35555556416511536, loss=1.7978538274765015
train: epoch 37, loss 0.767227292060852, acc=0.6933888792991638, loss=0.767227292060852
test: epoch 37, loss 1.7509284019470215, acc=0.3861111104488373, loss=1.7509284019470215
train: epoch 38, loss 0.7733739614486694, acc=0.6919999718666077, loss=0.7733739614486694
test: epoch 38, loss 1.5821541547775269, acc=0.39444443583488464, loss=1.5821541547775269
train: epoch 39, loss 0.7767869234085083, acc=0.6889444589614868, loss=0.7767869234085083
test: epoch 39, loss 1.7769980430603027, acc=0.36666667461395264, loss=1.7769980430603027
train: epoch 40, loss 0.7567146420478821, acc=0.6983888745307922, loss=0.7567146420478821
test: epoch 40, loss 1.5218158960342407, acc=0.3583333194255829, loss=1.5218158960342407
train: epoch 41, loss 0.7524460554122925, acc=0.7019444704055786, loss=0.7524460554122925
test: epoch 41, loss 1.596710205078125, acc=0.39444443583488464, loss=1.596710205078125
train: epoch 42, loss 0.7552766799926758, acc=0.6994444727897644, loss=0.7552766799926758
test: epoch 42, loss 1.8604167699813843, acc=0.36944442987442017, loss=1.8604167699813843
train: epoch 43, loss 0.7320778965950012, acc=0.7067777514457703, loss=0.7320778965950012
test: epoch 43, loss 1.6180980205535889, acc=0.3777777850627899, loss=1.6180980205535889
train: epoch 44, loss 0.7450733780860901, acc=0.7056111097335815, loss=0.7450733780860901
test: epoch 44, loss 1.5338984727859497, acc=0.38333332538604736, loss=1.5338984727859497
train: epoch 45, loss 0.7458754777908325, acc=0.7050555348396301, loss=0.7458754777908325
test: epoch 45, loss 1.67989182472229, acc=0.3888888955116272, loss=1.67989182472229
train: epoch 46, loss 0.7513566613197327, acc=0.7004444599151611, loss=0.7513566613197327
test: epoch 46, loss 1.4848694801330566, acc=0.3916666805744171, loss=1.4848694801330566
train: epoch 47, loss 0.752374529838562, acc=0.7009999752044678, loss=0.752374529838562
test: epoch 47, loss 1.5797885656356812, acc=0.4333333373069763, loss=1.5797885656356812
train: epoch 48, loss 0.7542722225189209, acc=0.6983333230018616, loss=0.7542722225189209
test: epoch 48, loss 1.8064446449279785, acc=0.38333332538604736, loss=1.8064446449279785
train: epoch 49, loss 0.7066856622695923, acc=0.7161111235618591, loss=0.7066856622695923
test: epoch 49, loss 1.507814884185791, acc=0.3777777850627899, loss=1.507814884185791
train: epoch 50, loss 0.7215999960899353, acc=0.7133888602256775, loss=0.7215999960899353
test: epoch 50, loss 1.4660212993621826, acc=0.42500001192092896, loss=1.4660212993621826
train: epoch 51, loss 0.7468978762626648, acc=0.7038333415985107, loss=0.7468978762626648
test: epoch 51, loss 1.4447225332260132, acc=0.4194444417953491, loss=1.4447225332260132
train: epoch 52, loss 0.7456210255622864, acc=0.7013888955116272, loss=0.7456210255622864
test: epoch 52, loss 1.5492808818817139, acc=0.4000000059604645, loss=1.5492808818817139
train: epoch 53, loss 0.7271279096603394, acc=0.7052222490310669, loss=0.7271279096603394
test: epoch 53, loss 1.689609169960022, acc=0.39722222089767456, loss=1.689609169960022
train: epoch 54, loss 0.7470075488090515, acc=0.6923888921737671, loss=0.7470075488090515
test: epoch 54, loss 1.4550551176071167, acc=0.39444443583488464, loss=1.4550551176071167
train: epoch 55, loss 0.7412039041519165, acc=0.7037777900695801, loss=0.7412039041519165
test: epoch 55, loss 1.6508216857910156, acc=0.4138889014720917, loss=1.6508216857910156
train: epoch 56, loss 0.7460646629333496, acc=0.6956111192703247, loss=0.7460646629333496
test: epoch 56, loss 1.5874440670013428, acc=0.39722222089767456, loss=1.5874440670013428
train: epoch 57, loss 0.7384514212608337, acc=0.6986666917800903, loss=0.7384514212608337
test: epoch 57, loss 1.6229729652404785, acc=0.36666667461395264, loss=1.6229729652404785
train: epoch 58, loss 0.7349948883056641, acc=0.6992777585983276, loss=0.7349948883056641
test: epoch 58, loss 1.5739117860794067, acc=0.3444444537162781, loss=1.5739117860794067
train: epoch 59, loss 0.7554377317428589, acc=0.6911110877990723, loss=0.7554377317428589
test: epoch 59, loss 1.5346581935882568, acc=0.3861111104488373, loss=1.5346581935882568
train: epoch 60, loss 0.7503277659416199, acc=0.6949999928474426, loss=0.7503277659416199
test: epoch 60, loss 1.6387648582458496, acc=0.43611112236976624, loss=1.6387648582458496
train: epoch 61, loss 0.7365621328353882, acc=0.703499972820282, loss=0.7365621328353882
test: epoch 61, loss 1.560969352722168, acc=0.4027777910232544, loss=1.560969352722168
train: epoch 62, loss 0.7500817775726318, acc=0.690833330154419, loss=0.7500817775726318
test: epoch 62, loss 1.4883003234863281, acc=0.43611112236976624, loss=1.4883003234863281
train: epoch 63, loss 0.7385144829750061, acc=0.7024999856948853, loss=0.7385144829750061
test: epoch 63, loss 1.4538054466247559, acc=0.4416666626930237, loss=1.4538054466247559
train: epoch 64, loss 0.7534441947937012, acc=0.6926110982894897, loss=0.7534441947937012
test: epoch 64, loss 1.3891457319259644, acc=0.4694444537162781, loss=1.3891457319259644
train: epoch 65, loss 0.7637881636619568, acc=0.6896666884422302, loss=0.7637881636619568
test: epoch 65, loss 1.4170130491256714, acc=0.43888887763023376, loss=1.4170130491256714
train: epoch 66, loss 0.7494394183158875, acc=0.6952221989631653, loss=0.7494394183158875
test: epoch 66, loss 1.4843171834945679, acc=0.4166666567325592, loss=1.4843171834945679
train: epoch 67, loss 0.7438869476318359, acc=0.6972222328186035, loss=0.7438869476318359
test: epoch 67, loss 1.2235559225082397, acc=0.4444444477558136, loss=1.2235559225082397
train: epoch 68, loss 0.714384913444519, acc=0.7096111178398132, loss=0.714384913444519
test: epoch 68, loss 1.354789137840271, acc=0.4583333432674408, loss=1.354789137840271
train: epoch 69, loss 0.7470300197601318, acc=0.6928889155387878, loss=0.7470300197601318
test: epoch 69, loss 1.485247015953064, acc=0.4611110985279083, loss=1.485247015953064
train: epoch 70, loss 0.7452691793441772, acc=0.6982777714729309, loss=0.7452691793441772
test: epoch 70, loss 1.366405725479126, acc=0.4749999940395355, loss=1.366405725479126
train: epoch 71, loss 0.7221915125846863, acc=0.7078333497047424, loss=0.7221915125846863
test: epoch 71, loss 1.3276073932647705, acc=0.5027777552604675, loss=1.3276073932647705
train: epoch 72, loss 0.7235937714576721, acc=0.7049999833106995, loss=0.7235937714576721
test: epoch 72, loss 1.428964614868164, acc=0.4749999940395355, loss=1.428964614868164
train: epoch 73, loss 0.7189700603485107, acc=0.7085555791854858, loss=0.7189700603485107
test: epoch 73, loss 1.4406335353851318, acc=0.44999998807907104, loss=1.4406335353851318
train: epoch 74, loss 0.7117907404899597, acc=0.7159444689750671, loss=0.7117907404899597
test: epoch 74, loss 1.235012173652649, acc=0.4722222089767456, loss=1.235012173652649
train: epoch 75, loss 0.6977172493934631, acc=0.7201666831970215, loss=0.6977172493934631
test: epoch 75, loss 1.3822635412216187, acc=0.4305555522441864, loss=1.3822635412216187
train: epoch 76, loss 0.6883824467658997, acc=0.7204444408416748, loss=0.6883824467658997
test: epoch 76, loss 1.3924130201339722, acc=0.4722222089767456, loss=1.3924130201339722
train: epoch 77, loss 0.7293243408203125, acc=0.7108333110809326, loss=0.7293243408203125
test: epoch 77, loss 1.476752758026123, acc=0.519444465637207, loss=1.476752758026123
train: epoch 78, loss 0.67314213514328, acc=0.7287777662277222, loss=0.67314213514328
test: epoch 78, loss 1.4011160135269165, acc=0.46666666865348816, loss=1.4011160135269165
train: epoch 79, loss 0.6868661642074585, acc=0.7211111187934875, loss=0.6868661642074585
test: epoch 79, loss 1.361958622932434, acc=0.4555555582046509, loss=1.361958622932434
train: epoch 80, loss 0.6725232005119324, acc=0.7273889183998108, loss=0.6725232005119324
test: epoch 80, loss 1.371410608291626, acc=0.4416666626930237, loss=1.371410608291626
train: epoch 81, loss 0.6761123538017273, acc=0.729888916015625, loss=0.6761123538017273
test: epoch 81, loss 1.4766736030578613, acc=0.4472222328186035, loss=1.4766736030578613
train: epoch 82, loss 0.6745932102203369, acc=0.7277777791023254, loss=0.6745932102203369
test: epoch 82, loss 1.4085930585861206, acc=0.49444442987442017, loss=1.4085930585861206
train: epoch 83, loss 0.6514753699302673, acc=0.738111138343811, loss=0.6514753699302673
test: epoch 83, loss 1.3467241525650024, acc=0.4472222328186035, loss=1.3467241525650024
train: epoch 84, loss 0.6499864459037781, acc=0.7393888831138611, loss=0.6499864459037781
test: epoch 84, loss 1.3234349489212036, acc=0.4722222089767456, loss=1.3234349489212036
train: epoch 85, loss 0.6611490249633789, acc=0.7352777719497681, loss=0.6611490249633789
test: epoch 85, loss 1.5689728260040283, acc=0.4055555462837219, loss=1.5689728260040283
train: epoch 86, loss 0.6831645965576172, acc=0.7307222485542297, loss=0.6831645965576172
test: epoch 86, loss 1.4254727363586426, acc=0.4444444477558136, loss=1.4254727363586426
train: epoch 87, loss 0.6531798839569092, acc=0.7372221946716309, loss=0.6531798839569092
test: epoch 87, loss 1.3181813955307007, acc=0.5083333253860474, loss=1.3181813955307007
train: epoch 88, loss 0.6420646905899048, acc=0.7406666874885559, loss=0.6420646905899048
test: epoch 88, loss 1.452103853225708, acc=0.5138888955116272, loss=1.452103853225708
train: epoch 89, loss 0.6429734826087952, acc=0.7424444556236267, loss=0.6429734826087952
test: epoch 89, loss 1.2619385719299316, acc=0.5166666507720947, loss=1.2619385719299316
train: epoch 90, loss 0.6282333135604858, acc=0.7479444742202759, loss=0.6282333135604858
test: epoch 90, loss 1.2914834022521973, acc=0.4694444537162781, loss=1.2914834022521973
train: epoch 91, loss 0.6520017385482788, acc=0.738777756690979, loss=0.6520017385482788
test: epoch 91, loss 1.1518715620040894, acc=0.46666666865348816, loss=1.1518715620040894
train: epoch 92, loss 0.6171978116035461, acc=0.7503888607025146, loss=0.6171978116035461
test: epoch 92, loss 1.247825026512146, acc=0.49444442987442017, loss=1.247825026512146
train: epoch 93, loss 0.6181639432907104, acc=0.7522222399711609, loss=0.6181639432907104
test: epoch 93, loss 1.3888369798660278, acc=0.46388888359069824, loss=1.3888369798660278
train: epoch 94, loss 0.5965802073478699, acc=0.7702777981758118, loss=0.5965802073478699
test: epoch 94, loss 1.2884407043457031, acc=0.4694444537162781, loss=1.2884407043457031
train: epoch 95, loss 0.6043508052825928, acc=0.7648888826370239, loss=0.6043508052825928
test: epoch 95, loss 1.2394710779190063, acc=0.5027777552604675, loss=1.2394710779190063
train: epoch 96, loss 0.6312839388847351, acc=0.7546111345291138, loss=0.6312839388847351
test: epoch 96, loss 1.2821297645568848, acc=0.4861111044883728, loss=1.2821297645568848
train: epoch 97, loss 0.5872985124588013, acc=0.7749999761581421, loss=0.5872985124588013
test: epoch 97, loss 1.3209542036056519, acc=0.519444465637207, loss=1.3209542036056519
train: epoch 98, loss 0.5856427550315857, acc=0.7730000019073486, loss=0.5856427550315857
test: epoch 98, loss 1.2922241687774658, acc=0.4749999940395355, loss=1.2922241687774658
train: epoch 99, loss 0.6251787543296814, acc=0.7620555758476257, loss=0.6251787543296814
test: epoch 99, loss 1.4000530242919922, acc=0.47777777910232544, loss=1.4000530242919922
train: epoch 100, loss 0.6021153926849365, acc=0.7667222023010254, loss=0.6021153926849365
test: epoch 100, loss 1.5035374164581299, acc=0.5055555701255798, loss=1.5035374164581299
train: epoch 101, loss 0.5886449217796326, acc=0.7760000228881836, loss=0.5886449217796326
test: epoch 101, loss 1.4344472885131836, acc=0.5166666507720947, loss=1.4344472885131836
train: epoch 102, loss 0.5803357362747192, acc=0.7743889093399048, loss=0.5803357362747192
test: epoch 102, loss 1.5793274641036987, acc=0.47777777910232544, loss=1.5793274641036987
train: epoch 103, loss 0.5913751721382141, acc=0.7737777829170227, loss=0.5913751721382141
test: epoch 103, loss 1.3375569581985474, acc=0.5111111402511597, loss=1.3375569581985474
train: epoch 104, loss 0.5926591157913208, acc=0.772777795791626, loss=0.5926591157913208
test: epoch 104, loss 1.619708776473999, acc=0.4972222149372101, loss=1.619708776473999
train: epoch 105, loss 0.5750676989555359, acc=0.7778888940811157, loss=0.5750676989555359
test: epoch 105, loss 1.389604091644287, acc=0.5111111402511597, loss=1.389604091644287
train: epoch 106, loss 0.5771964192390442, acc=0.7764444351196289, loss=0.5771964192390442
test: epoch 106, loss 1.2075831890106201, acc=0.5111111402511597, loss=1.2075831890106201
train: epoch 107, loss 0.6104391813278198, acc=0.7633333206176758, loss=0.6104391813278198
test: epoch 107, loss 1.3720982074737549, acc=0.4305555522441864, loss=1.3720982074737549
train: epoch 108, loss 0.5563411116600037, acc=0.7870555520057678, loss=0.5563411116600037
test: epoch 108, loss 1.4740383625030518, acc=0.4888888895511627, loss=1.4740383625030518
train: epoch 109, loss 0.5849727392196655, acc=0.7709444165229797, loss=0.5849727392196655
test: epoch 109, loss 1.3419374227523804, acc=0.5111111402511597, loss=1.3419374227523804
train: epoch 110, loss 0.5700127482414246, acc=0.7799999713897705, loss=0.5700127482414246
test: epoch 110, loss 1.269900918006897, acc=0.5138888955116272, loss=1.269900918006897
train: epoch 111, loss 0.5648761987686157, acc=0.7818889021873474, loss=0.5648761987686157
test: epoch 111, loss 1.3129597902297974, acc=0.5444444417953491, loss=1.3129597902297974
train: epoch 112, loss 0.60167396068573, acc=0.765500009059906, loss=0.60167396068573
test: epoch 112, loss 1.4050114154815674, acc=0.4694444537162781, loss=1.4050114154815674
train: epoch 113, loss 0.5447927713394165, acc=0.7885555624961853, loss=0.5447927713394165
test: epoch 113, loss 1.615592122077942, acc=0.4555555582046509, loss=1.615592122077942
train: epoch 114, loss 0.5418825149536133, acc=0.7917222380638123, loss=0.5418825149536133
test: epoch 114, loss 1.2965564727783203, acc=0.519444465637207, loss=1.2965564727783203
train: epoch 115, loss 0.5536951422691345, acc=0.789222240447998, loss=0.5536951422691345
test: epoch 115, loss 1.4567878246307373, acc=0.5055555701255798, loss=1.4567878246307373
train: epoch 116, loss 0.5463737845420837, acc=0.7891111373901367, loss=0.5463737845420837
test: epoch 116, loss 1.4125291109085083, acc=0.49166667461395264, loss=1.4125291109085083
train: epoch 117, loss 0.5436984300613403, acc=0.7918333411216736, loss=0.5436984300613403
test: epoch 117, loss 1.5960427522659302, acc=0.36944442987442017, loss=1.5960427522659302
train: epoch 118, loss 0.5675339698791504, acc=0.7806110978126526, loss=0.5675339698791504
test: epoch 118, loss 1.241382122039795, acc=0.5388888716697693, loss=1.241382122039795
train: epoch 119, loss 0.5671684145927429, acc=0.7808333039283752, loss=0.5671684145927429
test: epoch 119, loss 1.5762617588043213, acc=0.42222222685813904, loss=1.5762617588043213
train: epoch 120, loss 0.55560302734375, acc=0.785277783870697, loss=0.55560302734375
test: epoch 120, loss 1.1824121475219727, acc=0.5277777910232544, loss=1.1824121475219727
train: epoch 121, loss 0.5514914393424988, acc=0.7861111164093018, loss=0.5514914393424988
test: epoch 121, loss 1.3268948793411255, acc=0.5027777552604675, loss=1.3268948793411255
train: epoch 122, loss 0.5566227436065674, acc=0.7820000052452087, loss=0.5566227436065674
test: epoch 122, loss 1.1684988737106323, acc=0.47777777910232544, loss=1.1684988737106323
train: epoch 123, loss 0.5438182950019836, acc=0.7914999723434448, loss=0.5438182950019836
test: epoch 123, loss 1.2741310596466064, acc=0.5, loss=1.2741310596466064
train: epoch 124, loss 0.5545459985733032, acc=0.7889444231987, loss=0.5545459985733032
test: epoch 124, loss 1.2727309465408325, acc=0.519444465637207, loss=1.2727309465408325
train: epoch 125, loss 0.5286693572998047, acc=0.7984444499015808, loss=0.5286693572998047
test: epoch 125, loss 1.1380884647369385, acc=0.5055555701255798, loss=1.1380884647369385
train: epoch 126, loss 0.5308982133865356, acc=0.7923333048820496, loss=0.5308982133865356
test: epoch 126, loss 1.2402586936950684, acc=0.5111111402511597, loss=1.2402586936950684
train: epoch 127, loss 0.5460774302482605, acc=0.78938889503479, loss=0.5460774302482605
test: epoch 127, loss 1.2451967000961304, acc=0.5777778029441833, loss=1.2451967000961304
train: epoch 128, loss 0.5224002599716187, acc=0.7973889112472534, loss=0.5224002599716187
test: epoch 128, loss 1.0867910385131836, acc=0.5138888955116272, loss=1.0867910385131836
train: epoch 129, loss 0.5397648215293884, acc=0.7917222380638123, loss=0.5397648215293884
test: epoch 129, loss 1.4165542125701904, acc=0.550000011920929, loss=1.4165542125701904
train: epoch 130, loss 0.5406409502029419, acc=0.7911666631698608, loss=0.5406409502029419
test: epoch 130, loss 1.117360234260559, acc=0.5805555582046509, loss=1.117360234260559
train: epoch 131, loss 0.5234923958778381, acc=0.7961111068725586, loss=0.5234923958778381
test: epoch 131, loss 1.1470825672149658, acc=0.5833333134651184, loss=1.1470825672149658
train: epoch 132, loss 0.5267341136932373, acc=0.7958889007568359, loss=0.5267341136932373
test: epoch 132, loss 1.1102200746536255, acc=0.4694444537162781, loss=1.1102200746536255
train: epoch 133, loss 0.5159892439842224, acc=0.804111123085022, loss=0.5159892439842224
test: epoch 133, loss 1.1331281661987305, acc=0.5527777671813965, loss=1.1331281661987305
train: epoch 134, loss 0.5168716907501221, acc=0.799833357334137, loss=0.5168716907501221
test: epoch 134, loss 1.2764426469802856, acc=0.5722222328186035, loss=1.2764426469802856
train: epoch 135, loss 0.6439210176467896, acc=0.7412777543067932, loss=0.6439210176467896
test: epoch 135, loss 1.0926954746246338, acc=0.5055555701255798, loss=1.0926954746246338
train: epoch 136, loss 0.5551344752311707, acc=0.785111129283905, loss=0.5551344752311707
test: epoch 136, loss 1.224339485168457, acc=0.5305555462837219, loss=1.224339485168457
train: epoch 137, loss 0.5209558606147766, acc=0.8008888959884644, loss=0.5209558606147766
test: epoch 137, loss 1.1404297351837158, acc=0.6305555701255798, loss=1.1404297351837158
train: epoch 138, loss 0.5097522735595703, acc=0.8023889064788818, loss=0.5097522735595703
test: epoch 138, loss 0.9626631140708923, acc=0.6583333611488342, loss=0.9626631140708923
train: epoch 139, loss 0.5083602070808411, acc=0.8008333444595337, loss=0.5083602070808411
test: epoch 139, loss 1.2491507530212402, acc=0.5583333373069763, loss=1.2491507530212402
train: epoch 140, loss 0.5006126165390015, acc=0.8032777905464172, loss=0.5006126165390015
test: epoch 140, loss 0.9455505609512329, acc=0.6305555701255798, loss=0.9455505609512329
train: epoch 141, loss 0.4924947917461395, acc=0.8078888654708862, loss=0.4924947917461395
test: epoch 141, loss 1.0841233730316162, acc=0.5972222089767456, loss=1.0841233730316162
train: epoch 142, loss 0.5111055970191956, acc=0.8033888936042786, loss=0.5111055970191956
test: epoch 142, loss 1.0075381994247437, acc=0.5833333134651184, loss=1.0075381994247437
train: epoch 143, loss 0.526542067527771, acc=0.7943888902664185, loss=0.526542067527771
test: epoch 143, loss 1.2749983072280884, acc=0.519444465637207, loss=1.2749983072280884
train: epoch 144, loss 0.5056542158126831, acc=0.8036666512489319, loss=0.5056542158126831
test: epoch 144, loss 1.0343716144561768, acc=0.5777778029441833, loss=1.0343716144561768
train: epoch 145, loss 0.4910711646080017, acc=0.8118333220481873, loss=0.4910711646080017
test: epoch 145, loss 1.158735990524292, acc=0.5416666865348816, loss=1.158735990524292
train: epoch 146, loss 0.5525447726249695, acc=0.7862777709960938, loss=0.5525447726249695
test: epoch 146, loss 1.1961722373962402, acc=0.5166666507720947, loss=1.1961722373962402
train: epoch 147, loss 0.5121957063674927, acc=0.8054999709129333, loss=0.5121957063674927
test: epoch 147, loss 0.9737323522567749, acc=0.5916666388511658, loss=0.9737323522567749
train: epoch 148, loss 0.47379955649375916, acc=0.8192222118377686, loss=0.47379955649375916
test: epoch 148, loss 1.223771572113037, acc=0.5638889074325562, loss=1.223771572113037
train: epoch 149, loss 0.5034709572792053, acc=0.8036666512489319, loss=0.5034709572792053
test: epoch 149, loss 1.092612862586975, acc=0.5277777910232544, loss=1.092612862586975
train: epoch 150, loss 0.505260169506073, acc=0.8043888807296753, loss=0.505260169506073
test: epoch 150, loss 1.0158854722976685, acc=0.5666666626930237, loss=1.0158854722976685
