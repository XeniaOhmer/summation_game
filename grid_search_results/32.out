# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1.5", "--temp_decay=0.99", "--one_hot=true", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1670198876, receiver_embed_dim=32, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.0224790573120117, acc=0.07322221994400024, loss=3.0224790573120117
test: epoch 1, loss 3.2129504680633545, acc=0.07777778059244156, loss=3.2129504680633545
train: epoch 2, loss 2.04433536529541, acc=0.21255555748939514, loss=2.04433536529541
test: epoch 2, loss 2.603904962539673, acc=0.17222222685813904, loss=2.603904962539673
train: epoch 3, loss 1.7260764837265015, acc=0.2785555422306061, loss=1.7260764837265015
test: epoch 3, loss 2.9117846488952637, acc=0.1805555522441864, loss=2.9117846488952637
train: epoch 4, loss 1.5362870693206787, acc=0.32777777314186096, loss=1.5362870693206787
test: epoch 4, loss 2.627873182296753, acc=0.20555555820465088, loss=2.627873182296753
train: epoch 5, loss 1.3752282857894897, acc=0.3937777876853943, loss=1.3752282857894897
test: epoch 5, loss 2.329885959625244, acc=0.27222222089767456, loss=2.329885959625244
train: epoch 6, loss 1.2287694215774536, acc=0.4607222080230713, loss=1.2287694215774536
test: epoch 6, loss 2.4534807205200195, acc=0.2638888955116272, loss=2.4534807205200195
train: epoch 7, loss 1.10221266746521, acc=0.5201666951179504, loss=1.10221266746521
test: epoch 7, loss 2.0171921253204346, acc=0.2638888955116272, loss=2.0171921253204346
train: epoch 8, loss 0.9468297362327576, acc=0.5930555462837219, loss=0.9468297362327576
test: epoch 8, loss 2.1294775009155273, acc=0.3055555522441864, loss=2.1294775009155273
train: epoch 9, loss 0.8423144221305847, acc=0.6356111168861389, loss=0.8423144221305847
test: epoch 9, loss 2.1831142902374268, acc=0.36666667461395264, loss=2.1831142902374268
train: epoch 10, loss 0.7396181225776672, acc=0.6872222423553467, loss=0.7396181225776672
test: epoch 10, loss 1.9436442852020264, acc=0.4055555462837219, loss=1.9436442852020264
train: epoch 11, loss 0.67374587059021, acc=0.7119444608688354, loss=0.67374587059021
test: epoch 11, loss 1.8300849199295044, acc=0.4333333373069763, loss=1.8300849199295044
train: epoch 12, loss 0.616776168346405, acc=0.7337222099304199, loss=0.616776168346405
test: epoch 12, loss 1.7161425352096558, acc=0.4555555582046509, loss=1.7161425352096558
train: epoch 13, loss 0.5942647457122803, acc=0.7506666779518127, loss=0.5942647457122803
test: epoch 13, loss 1.2056021690368652, acc=0.4972222149372101, loss=1.2056021690368652
train: epoch 14, loss 0.5315169095993042, acc=0.7762222290039062, loss=0.5315169095993042
test: epoch 14, loss 1.478492259979248, acc=0.5166666507720947, loss=1.478492259979248
train: epoch 15, loss 0.491531640291214, acc=0.7992222309112549, loss=0.491531640291214
test: epoch 15, loss 1.3837485313415527, acc=0.5083333253860474, loss=1.3837485313415527
train: epoch 16, loss 0.49236488342285156, acc=0.8008333444595337, loss=0.49236488342285156
test: epoch 16, loss 1.454870581626892, acc=0.519444465637207, loss=1.454870581626892
train: epoch 17, loss 0.4456641972064972, acc=0.8192777633666992, loss=0.4456641972064972
test: epoch 17, loss 1.588712453842163, acc=0.4472222328186035, loss=1.588712453842163
train: epoch 18, loss 0.43291226029396057, acc=0.8234444260597229, loss=0.43291226029396057
test: epoch 18, loss 1.4356944561004639, acc=0.4861111044883728, loss=1.4356944561004639
train: epoch 19, loss 0.4392656981945038, acc=0.8187222480773926, loss=0.4392656981945038
test: epoch 19, loss 1.1603102684020996, acc=0.5361111164093018, loss=1.1603102684020996
train: epoch 20, loss 0.42280375957489014, acc=0.8272222280502319, loss=0.42280375957489014
test: epoch 20, loss 1.19879150390625, acc=0.5333333611488342, loss=1.19879150390625
train: epoch 21, loss 0.38393211364746094, acc=0.839888870716095, loss=0.38393211364746094
test: epoch 21, loss 1.0002418756484985, acc=0.6138888597488403, loss=1.0002418756484985
train: epoch 22, loss 0.4269477128982544, acc=0.8291666507720947, loss=0.4269477128982544
test: epoch 22, loss 1.038983702659607, acc=0.6388888955116272, loss=1.038983702659607
train: epoch 23, loss 0.34188270568847656, acc=0.8572777509689331, loss=0.34188270568847656
test: epoch 23, loss 1.1262205839157104, acc=0.5694444179534912, loss=1.1262205839157104
train: epoch 24, loss 0.35948580503463745, acc=0.8512222170829773, loss=0.35948580503463745
test: epoch 24, loss 0.957365870475769, acc=0.6361111402511597, loss=0.957365870475769
train: epoch 25, loss 0.3430018126964569, acc=0.8566666841506958, loss=0.3430018126964569
test: epoch 25, loss 1.1448204517364502, acc=0.6333333253860474, loss=1.1448204517364502
train: epoch 26, loss 0.3365165889263153, acc=0.8632222414016724, loss=0.3365165889263153
test: epoch 26, loss 0.9304594397544861, acc=0.6944444179534912, loss=0.9304594397544861
train: epoch 27, loss 0.30710655450820923, acc=0.8730555772781372, loss=0.30710655450820923
test: epoch 27, loss 1.1012606620788574, acc=0.6722221970558167, loss=1.1012606620788574
train: epoch 28, loss 0.33015522360801697, acc=0.8616111278533936, loss=0.33015522360801697
test: epoch 28, loss 0.9720593094825745, acc=0.7027778029441833, loss=0.9720593094825745
train: epoch 29, loss 0.31535887718200684, acc=0.8682222366333008, loss=0.31535887718200684
test: epoch 29, loss 0.8920994997024536, acc=0.6722221970558167, loss=0.8920994997024536
train: epoch 30, loss 0.30663812160491943, acc=0.8706666827201843, loss=0.30663812160491943
test: epoch 30, loss 0.8896566033363342, acc=0.6944444179534912, loss=0.8896566033363342
train: epoch 31, loss 0.31545644998550415, acc=0.8678333163261414, loss=0.31545644998550415
test: epoch 31, loss 0.7775467038154602, acc=0.6916666626930237, loss=0.7775467038154602
train: epoch 32, loss 0.31827548146247864, acc=0.8683333396911621, loss=0.31827548146247864
test: epoch 32, loss 0.8952664732933044, acc=0.6666666865348816, loss=0.8952664732933044
train: epoch 33, loss 0.3067534267902374, acc=0.8715555667877197, loss=0.3067534267902374
test: epoch 33, loss 0.7839961051940918, acc=0.7027778029441833, loss=0.7839961051940918
train: epoch 34, loss 0.27610471844673157, acc=0.8928333520889282, loss=0.27610471844673157
test: epoch 34, loss 0.9367933869361877, acc=0.7055555582046509, loss=0.9367933869361877
train: epoch 35, loss 0.3019019067287445, acc=0.8837777972221375, loss=0.3019019067287445
test: epoch 35, loss 0.8418628573417664, acc=0.7277777791023254, loss=0.8418628573417664
train: epoch 36, loss 0.27563148736953735, acc=0.9020000100135803, loss=0.27563148736953735
test: epoch 36, loss 0.8957692384719849, acc=0.7277777791023254, loss=0.8957692384719849
train: epoch 37, loss 0.2630905508995056, acc=0.906000018119812, loss=0.2630905508995056
test: epoch 37, loss 0.8711410760879517, acc=0.7277777791023254, loss=0.8711410760879517
train: epoch 38, loss 0.2898751199245453, acc=0.8934999704360962, loss=0.2898751199245453
test: epoch 38, loss 0.7511736750602722, acc=0.7166666388511658, loss=0.7511736750602722
train: epoch 39, loss 0.23997268080711365, acc=0.9144999980926514, loss=0.23997268080711365
test: epoch 39, loss 0.7017443180084229, acc=0.7388888597488403, loss=0.7017443180084229
train: epoch 40, loss 0.25299039483070374, acc=0.9095555543899536, loss=0.25299039483070374
test: epoch 40, loss 0.8057049512863159, acc=0.7527777552604675, loss=0.8057049512863159
train: epoch 41, loss 0.2354767620563507, acc=0.918055534362793, loss=0.2354767620563507
test: epoch 41, loss 0.9199025630950928, acc=0.7333333492279053, loss=0.9199025630950928
train: epoch 42, loss 0.2387280911207199, acc=0.9150555729866028, loss=0.2387280911207199
test: epoch 42, loss 0.874164342880249, acc=0.75, loss=0.874164342880249
train: epoch 43, loss 0.24587124586105347, acc=0.9150000214576721, loss=0.24587124586105347
test: epoch 43, loss 0.7423703670501709, acc=0.7527777552604675, loss=0.7423703670501709
train: epoch 44, loss 0.22572538256645203, acc=0.9222221970558167, loss=0.22572538256645203
test: epoch 44, loss 0.9172385334968567, acc=0.7222222089767456, loss=0.9172385334968567
train: epoch 45, loss 0.25579917430877686, acc=0.910277783870697, loss=0.25579917430877686
test: epoch 45, loss 0.7568697929382324, acc=0.7388888597488403, loss=0.7568697929382324
train: epoch 46, loss 0.22744280099868774, acc=0.9176666736602783, loss=0.22744280099868774
test: epoch 46, loss 0.7442371845245361, acc=0.7555555701255798, loss=0.7442371845245361
train: epoch 47, loss 0.23587608337402344, acc=0.9177777767181396, loss=0.23587608337402344
test: epoch 47, loss 0.8122172355651855, acc=0.7388888597488403, loss=0.8122172355651855
train: epoch 48, loss 0.23823130130767822, acc=0.9162777662277222, loss=0.23823130130767822
test: epoch 48, loss 0.713966965675354, acc=0.7583333253860474, loss=0.713966965675354
train: epoch 49, loss 0.2533382773399353, acc=0.9116111397743225, loss=0.2533382773399353
test: epoch 49, loss 0.8055663704872131, acc=0.7472222447395325, loss=0.8055663704872131
train: epoch 50, loss 0.2213391214609146, acc=0.9222221970558167, loss=0.2213391214609146
test: epoch 50, loss 0.8016191720962524, acc=0.7416666746139526, loss=0.8016191720962524
train: epoch 51, loss 0.23294848203659058, acc=0.9181110858917236, loss=0.23294848203659058
test: epoch 51, loss 0.820942223072052, acc=0.7416666746139526, loss=0.820942223072052
train: epoch 52, loss 0.2738458216190338, acc=0.9053888916969299, loss=0.2738458216190338
test: epoch 52, loss 0.6789244413375854, acc=0.7555555701255798, loss=0.6789244413375854
train: epoch 53, loss 0.22697849571704865, acc=0.9229999780654907, loss=0.22697849571704865
test: epoch 53, loss 0.9333718419075012, acc=0.7361111044883728, loss=0.9333718419075012
train: epoch 54, loss 0.23177160322666168, acc=0.9182778000831604, loss=0.23177160322666168
test: epoch 54, loss 0.7689666748046875, acc=0.75, loss=0.7689666748046875
train: epoch 55, loss 0.24421437084674835, acc=0.9130555391311646, loss=0.24421437084674835
test: epoch 55, loss 0.7426905632019043, acc=0.75, loss=0.7426905632019043
train: epoch 56, loss 0.23721858859062195, acc=0.9185000061988831, loss=0.23721858859062195
test: epoch 56, loss 0.7952053546905518, acc=0.7416666746139526, loss=0.7952053546905518
train: epoch 57, loss 0.2428179681301117, acc=0.9167222380638123, loss=0.2428179681301117
test: epoch 57, loss 0.6653562784194946, acc=0.7527777552604675, loss=0.6653562784194946
train: epoch 58, loss 0.22527527809143066, acc=0.9225000143051147, loss=0.22527527809143066
test: epoch 58, loss 0.7186606526374817, acc=0.7555555701255798, loss=0.7186606526374817
train: epoch 59, loss 0.24716095626354218, acc=0.9148889183998108, loss=0.24716095626354218
test: epoch 59, loss 0.7072567343711853, acc=0.75, loss=0.7072567343711853
train: epoch 60, loss 0.23478278517723083, acc=0.9198889136314392, loss=0.23478278517723083
test: epoch 60, loss 0.6805307269096375, acc=0.7527777552604675, loss=0.6805307269096375
train: epoch 61, loss 0.24743184447288513, acc=0.9117777943611145, loss=0.24743184447288513
test: epoch 61, loss 0.7967168092727661, acc=0.7583333253860474, loss=0.7967168092727661
train: epoch 62, loss 0.23344986140727997, acc=0.9184444546699524, loss=0.23344986140727997
test: epoch 62, loss 0.8079952597618103, acc=0.7555555701255798, loss=0.8079952597618103
train: epoch 63, loss 0.2418031096458435, acc=0.9171110987663269, loss=0.2418031096458435
test: epoch 63, loss 0.7076022028923035, acc=0.7611111402511597, loss=0.7076022028923035
train: epoch 64, loss 0.2775757610797882, acc=0.906166672706604, loss=0.2775757610797882
test: epoch 64, loss 2.382478952407837, acc=0.5277777910232544, loss=2.382478952407837
train: epoch 65, loss 0.3006499409675598, acc=0.8938888907432556, loss=0.3006499409675598
test: epoch 65, loss 0.5826290845870972, acc=0.7583333253860474, loss=0.5826290845870972
train: epoch 66, loss 0.2382579743862152, acc=0.914222240447998, loss=0.2382579743862152
test: epoch 66, loss 0.6424011588096619, acc=0.7527777552604675, loss=0.6424011588096619
train: epoch 67, loss 0.2292926013469696, acc=0.920722246170044, loss=0.2292926013469696
test: epoch 67, loss 0.6646026968955994, acc=0.7638888955116272, loss=0.6646026968955994
train: epoch 68, loss 0.24197380244731903, acc=0.9141111373901367, loss=0.24197380244731903
test: epoch 68, loss 0.5648598670959473, acc=0.7555555701255798, loss=0.5648598670959473
train: epoch 69, loss 0.24936062097549438, acc=0.9118333458900452, loss=0.24936062097549438
test: epoch 69, loss 0.6120084524154663, acc=0.7666666507720947, loss=0.6120084524154663
train: epoch 70, loss 0.22993846237659454, acc=0.9203888773918152, loss=0.22993846237659454
test: epoch 70, loss 0.6248905658721924, acc=0.7722222208976746, loss=0.6248905658721924
train: epoch 71, loss 0.22432918846607208, acc=0.9205555319786072, loss=0.22432918846607208
test: epoch 71, loss 0.6011480093002319, acc=0.7666666507720947, loss=0.6011480093002319
train: epoch 72, loss 0.24701310694217682, acc=0.9131666421890259, loss=0.24701310694217682
test: epoch 72, loss 0.6788491010665894, acc=0.7555555701255798, loss=0.6788491010665894
train: epoch 73, loss 0.23770540952682495, acc=0.918666660785675, loss=0.23770540952682495
test: epoch 73, loss 0.61663419008255, acc=0.7722222208976746, loss=0.61663419008255
train: epoch 74, loss 0.23467622697353363, acc=0.9187222123146057, loss=0.23467622697353363
test: epoch 74, loss 0.7189649939537048, acc=0.7611111402511597, loss=0.7189649939537048
train: epoch 75, loss 0.23475182056427002, acc=0.9168333411216736, loss=0.23475182056427002
test: epoch 75, loss 0.706466794013977, acc=0.769444465637207, loss=0.706466794013977
train: epoch 76, loss 0.2633059024810791, acc=0.906499981880188, loss=0.2633059024810791
test: epoch 76, loss 0.6343164443969727, acc=0.769444465637207, loss=0.6343164443969727
train: epoch 77, loss 0.24055877327919006, acc=0.9150555729866028, loss=0.24055877327919006
test: epoch 77, loss 0.623826801776886, acc=0.7722222208976746, loss=0.623826801776886
train: epoch 78, loss 0.21643902361392975, acc=0.9257222414016724, loss=0.21643902361392975
test: epoch 78, loss 0.6995931267738342, acc=0.7666666507720947, loss=0.6995931267738342
train: epoch 79, loss 0.25247490406036377, acc=0.91438889503479, loss=0.25247490406036377
test: epoch 79, loss 0.6391068696975708, acc=0.7638888955116272, loss=0.6391068696975708
train: epoch 80, loss 0.21966515481472015, acc=0.9262222051620483, loss=0.21966515481472015
test: epoch 80, loss 0.628391683101654, acc=0.7722222208976746, loss=0.628391683101654
train: epoch 81, loss 0.2179928719997406, acc=0.9241666793823242, loss=0.2179928719997406
test: epoch 81, loss 0.6448853611946106, acc=0.7583333253860474, loss=0.6448853611946106
train: epoch 82, loss 0.23490770161151886, acc=0.9162222146987915, loss=0.23490770161151886
test: epoch 82, loss 0.6395745277404785, acc=0.7722222208976746, loss=0.6395745277404785
train: epoch 83, loss 0.21564221382141113, acc=0.9257222414016724, loss=0.21564221382141113
test: epoch 83, loss 0.6379944086074829, acc=0.7666666507720947, loss=0.6379944086074829
train: epoch 84, loss 0.23736515641212463, acc=0.9112777709960938, loss=0.23736515641212463
test: epoch 84, loss 0.572107195854187, acc=0.7638888955116272, loss=0.572107195854187
train: epoch 85, loss 0.23396505415439606, acc=0.9184444546699524, loss=0.23396505415439606
test: epoch 85, loss 0.5825870037078857, acc=0.7666666507720947, loss=0.5825870037078857
train: epoch 86, loss 0.21004678308963776, acc=0.9254444241523743, loss=0.21004678308963776
test: epoch 86, loss 0.7447671890258789, acc=0.7611111402511597, loss=0.7447671890258789
train: epoch 87, loss 0.24385371804237366, acc=0.9155555367469788, loss=0.24385371804237366
test: epoch 87, loss 0.6264727711677551, acc=0.7638888955116272, loss=0.6264727711677551
train: epoch 88, loss 0.22098927199840546, acc=0.9203888773918152, loss=0.22098927199840546
test: epoch 88, loss 0.7210727334022522, acc=0.769444465637207, loss=0.7210727334022522
train: epoch 89, loss 0.2686937749385834, acc=0.9044444561004639, loss=0.2686937749385834
test: epoch 89, loss 0.6303153038024902, acc=0.7666666507720947, loss=0.6303153038024902
train: epoch 90, loss 0.21757283806800842, acc=0.9216111302375793, loss=0.21757283806800842
test: epoch 90, loss 0.6484197378158569, acc=0.7666666507720947, loss=0.6484197378158569
train: epoch 91, loss 0.22232991456985474, acc=0.9232777953147888, loss=0.22232991456985474
test: epoch 91, loss 0.6090410351753235, acc=0.7611111402511597, loss=0.6090410351753235
train: epoch 92, loss 0.20520462095737457, acc=0.9281666874885559, loss=0.20520462095737457
test: epoch 92, loss 0.7377053499221802, acc=0.7666666507720947, loss=0.7377053499221802
train: epoch 93, loss 0.2255440354347229, acc=0.9200555682182312, loss=0.2255440354347229
test: epoch 93, loss 0.6845429539680481, acc=0.7722222208976746, loss=0.6845429539680481
train: epoch 94, loss 0.2137865573167801, acc=0.9241111278533936, loss=0.2137865573167801
test: epoch 94, loss 0.6117474436759949, acc=0.7666666507720947, loss=0.6117474436759949
train: epoch 95, loss 0.21012277901172638, acc=0.926111102104187, loss=0.21012277901172638
test: epoch 95, loss 0.6866962313652039, acc=0.7666666507720947, loss=0.6866962313652039
train: epoch 96, loss 0.20150908827781677, acc=0.9275000095367432, loss=0.20150908827781677
test: epoch 96, loss 0.658938467502594, acc=0.7638888955116272, loss=0.658938467502594
train: epoch 97, loss 0.19828934967517853, acc=0.9291666746139526, loss=0.19828934967517853
test: epoch 97, loss 0.6885399222373962, acc=0.7666666507720947, loss=0.6885399222373962
train: epoch 98, loss 0.21743619441986084, acc=0.918833315372467, loss=0.21743619441986084
test: epoch 98, loss 0.6077607870101929, acc=0.7666666507720947, loss=0.6077607870101929
train: epoch 99, loss 0.22846242785453796, acc=0.9211111068725586, loss=0.22846242785453796
test: epoch 99, loss 0.7139356732368469, acc=0.7555555701255798, loss=0.7139356732368469
train: epoch 100, loss 0.22130173444747925, acc=0.9186111092567444, loss=0.22130173444747925
test: epoch 100, loss 0.6984249949455261, acc=0.7666666507720947, loss=0.6984249949455261
train: epoch 101, loss 0.19682852923870087, acc=0.9266111254692078, loss=0.19682852923870087
test: epoch 101, loss 0.8081893920898438, acc=0.7638888955116272, loss=0.8081893920898438
train: epoch 102, loss 0.1930406540632248, acc=0.9322777986526489, loss=0.1930406540632248
test: epoch 102, loss 0.7711979746818542, acc=0.7638888955116272, loss=0.7711979746818542
train: epoch 103, loss 0.2111765295267105, acc=0.9296666383743286, loss=0.2111765295267105
test: epoch 103, loss 0.7921658754348755, acc=0.7555555701255798, loss=0.7921658754348755
train: epoch 104, loss 0.18650853633880615, acc=0.9325555562973022, loss=0.18650853633880615
test: epoch 104, loss 0.7529462575912476, acc=0.7666666507720947, loss=0.7529462575912476
train: epoch 105, loss 0.2037878930568695, acc=0.9272222518920898, loss=0.2037878930568695
test: epoch 105, loss 0.7411824464797974, acc=0.7666666507720947, loss=0.7411824464797974
train: epoch 106, loss 0.20313137769699097, acc=0.9323889017105103, loss=0.20313137769699097
test: epoch 106, loss 0.632163941860199, acc=0.7666666507720947, loss=0.632163941860199
train: epoch 107, loss 0.19823190569877625, acc=0.9325000047683716, loss=0.19823190569877625
test: epoch 107, loss 0.7899442911148071, acc=0.7666666507720947, loss=0.7899442911148071
train: epoch 108, loss 0.17772650718688965, acc=0.9393333196640015, loss=0.17772650718688965
test: epoch 108, loss 0.7538660764694214, acc=0.7666666507720947, loss=0.7538660764694214
train: epoch 109, loss 0.20305097103118896, acc=0.9313333630561829, loss=0.20305097103118896
test: epoch 109, loss 0.7104549407958984, acc=0.7666666507720947, loss=0.7104549407958984
train: epoch 110, loss 0.21354985237121582, acc=0.929111123085022, loss=0.21354985237121582
test: epoch 110, loss 0.7352403402328491, acc=0.7666666507720947, loss=0.7352403402328491
train: epoch 111, loss 0.19329510629177094, acc=0.9348888993263245, loss=0.19329510629177094
test: epoch 111, loss 0.6305510997772217, acc=0.7555555701255798, loss=0.6305510997772217
train: epoch 112, loss 0.18908575177192688, acc=0.9362778067588806, loss=0.18908575177192688
test: epoch 112, loss 0.7293897867202759, acc=0.7666666507720947, loss=0.7293897867202759
train: epoch 113, loss 0.18307775259017944, acc=0.9397222399711609, loss=0.18307775259017944
test: epoch 113, loss 0.6497323513031006, acc=0.7666666507720947, loss=0.6497323513031006
train: epoch 114, loss 0.2141345590353012, acc=0.9314444661140442, loss=0.2141345590353012
test: epoch 114, loss 0.5731233358383179, acc=0.7638888955116272, loss=0.5731233358383179
train: epoch 115, loss 0.20755241811275482, acc=0.9302777647972107, loss=0.20755241811275482
test: epoch 115, loss 0.699073076248169, acc=0.7611111402511597, loss=0.699073076248169
train: epoch 116, loss 0.19408255815505981, acc=0.933555543422699, loss=0.19408255815505981
test: epoch 116, loss 0.7316721677780151, acc=0.7666666507720947, loss=0.7316721677780151
train: epoch 117, loss 0.16723781824111938, acc=0.94477778673172, loss=0.16723781824111938
test: epoch 117, loss 0.7065560221672058, acc=0.7666666507720947, loss=0.7065560221672058
train: epoch 118, loss 0.21561190485954285, acc=0.9276111125946045, loss=0.21561190485954285
test: epoch 118, loss 0.8098481893539429, acc=0.7444444298744202, loss=0.8098481893539429
train: epoch 119, loss 0.17603766918182373, acc=0.9425555467605591, loss=0.17603766918182373
test: epoch 119, loss 0.7147658467292786, acc=0.7666666507720947, loss=0.7147658467292786
train: epoch 120, loss 0.1782860904932022, acc=0.9393333196640015, loss=0.1782860904932022
test: epoch 120, loss 0.7768243551254272, acc=0.7611111402511597, loss=0.7768243551254272
train: epoch 121, loss 0.19086095690727234, acc=0.9368333220481873, loss=0.19086095690727234
test: epoch 121, loss 0.6760056018829346, acc=0.7666666507720947, loss=0.6760056018829346
train: epoch 122, loss 0.19510634243488312, acc=0.9382777810096741, loss=0.19510634243488312
test: epoch 122, loss 0.7524946331977844, acc=0.7611111402511597, loss=0.7524946331977844
train: epoch 123, loss 0.18317987024784088, acc=0.9351111054420471, loss=0.18317987024784088
test: epoch 123, loss 0.6966231465339661, acc=0.7666666507720947, loss=0.6966231465339661
train: epoch 124, loss 0.19844067096710205, acc=0.9307222366333008, loss=0.19844067096710205
test: epoch 124, loss 0.6678582429885864, acc=0.7583333253860474, loss=0.6678582429885864
train: epoch 125, loss 0.22835911810398102, acc=0.9252222180366516, loss=0.22835911810398102
test: epoch 125, loss 0.5557289123535156, acc=0.7638888955116272, loss=0.5557289123535156
train: epoch 126, loss 0.1601671278476715, acc=0.945388913154602, loss=0.1601671278476715
test: epoch 126, loss 0.7229375243186951, acc=0.7666666507720947, loss=0.7229375243186951
train: epoch 127, loss 0.18457646667957306, acc=0.940833330154419, loss=0.18457646667957306
test: epoch 127, loss 0.6299198269844055, acc=0.7666666507720947, loss=0.6299198269844055
train: epoch 128, loss 0.1807624101638794, acc=0.9419999718666077, loss=0.1807624101638794
test: epoch 128, loss 0.6961351037025452, acc=0.7666666507720947, loss=0.6961351037025452
train: epoch 129, loss 0.17439815402030945, acc=0.941277801990509, loss=0.17439815402030945
test: epoch 129, loss 0.8428041338920593, acc=0.7638888955116272, loss=0.8428041338920593
train: epoch 130, loss 0.18163873255252838, acc=0.9403889179229736, loss=0.18163873255252838
test: epoch 130, loss 0.7210538983345032, acc=0.7611111402511597, loss=0.7210538983345032
train: epoch 131, loss 0.19465547800064087, acc=0.9384444355964661, loss=0.19465547800064087
test: epoch 131, loss 0.7103815078735352, acc=0.7583333253860474, loss=0.7103815078735352
train: epoch 132, loss 0.181263267993927, acc=0.9377777576446533, loss=0.181263267993927
test: epoch 132, loss 0.6933816075325012, acc=0.7666666507720947, loss=0.6933816075325012
train: epoch 133, loss 0.17485982179641724, acc=0.9450555443763733, loss=0.17485982179641724
test: epoch 133, loss 0.7955135703086853, acc=0.7666666507720947, loss=0.7955135703086853
train: epoch 134, loss 0.19070862233638763, acc=0.9391666650772095, loss=0.19070862233638763
test: epoch 134, loss 0.6823891401290894, acc=0.7583333253860474, loss=0.6823891401290894
train: epoch 135, loss 0.1992250680923462, acc=0.9366111159324646, loss=0.1992250680923462
test: epoch 135, loss 0.7023378014564514, acc=0.7638888955116272, loss=0.7023378014564514
train: epoch 136, loss 0.15195631980895996, acc=0.9503333568572998, loss=0.15195631980895996
test: epoch 136, loss 0.7415244579315186, acc=0.7666666507720947, loss=0.7415244579315186
train: epoch 137, loss 0.17337961494922638, acc=0.9415000081062317, loss=0.17337961494922638
test: epoch 137, loss 0.6488795280456543, acc=0.7638888955116272, loss=0.6488795280456543
train: epoch 138, loss 0.15747225284576416, acc=0.9478889107704163, loss=0.15747225284576416
test: epoch 138, loss 0.7318665385246277, acc=0.7777777910232544, loss=0.7318665385246277
train: epoch 139, loss 0.1843767762184143, acc=0.9387221932411194, loss=0.1843767762184143
test: epoch 139, loss 0.5852468609809875, acc=0.7888888716697693, loss=0.5852468609809875
train: epoch 140, loss 0.15631911158561707, acc=0.949833333492279, loss=0.15631911158561707
test: epoch 140, loss 0.738882303237915, acc=0.7861111164093018, loss=0.738882303237915
train: epoch 141, loss 0.16026629507541656, acc=0.9456111192703247, loss=0.16026629507541656
test: epoch 141, loss 0.5667304992675781, acc=0.7861111164093018, loss=0.5667304992675781
train: epoch 142, loss 0.15760570764541626, acc=0.9481666684150696, loss=0.15760570764541626
test: epoch 142, loss 0.6593037843704224, acc=0.7888888716697693, loss=0.6593037843704224
train: epoch 143, loss 0.15344159305095673, acc=0.9480555653572083, loss=0.15344159305095673
test: epoch 143, loss 0.5688594579696655, acc=0.7888888716697693, loss=0.5688594579696655
train: epoch 144, loss 0.1522367149591446, acc=0.9491111040115356, loss=0.1522367149591446
test: epoch 144, loss 0.7248027324676514, acc=0.7805555462837219, loss=0.7248027324676514
train: epoch 145, loss 0.21801456809043884, acc=0.9284444451332092, loss=0.21801456809043884
test: epoch 145, loss 0.7129945755004883, acc=0.7916666865348816, loss=0.7129945755004883
train: epoch 146, loss 0.16423644125461578, acc=0.9427222013473511, loss=0.16423644125461578
test: epoch 146, loss 0.6121098399162292, acc=0.7861111164093018, loss=0.6121098399162292
train: epoch 147, loss 0.14900729060173035, acc=0.9507222175598145, loss=0.14900729060173035
test: epoch 147, loss 0.6550261378288269, acc=0.7888888716697693, loss=0.6550261378288269
train: epoch 148, loss 0.15729829668998718, acc=0.9482222199440002, loss=0.15729829668998718
test: epoch 148, loss 0.5980606079101562, acc=0.7888888716697693, loss=0.5980606079101562
train: epoch 149, loss 0.17064118385314941, acc=0.945388913154602, loss=0.17064118385314941
test: epoch 149, loss 0.6476154327392578, acc=0.7861111164093018, loss=0.6476154327392578
train: epoch 150, loss 0.1417239010334015, acc=0.9514444470405579, loss=0.1417239010334015
test: epoch 150, loss 0.6019420027732849, acc=0.7888888716697693, loss=0.6019420027732849
