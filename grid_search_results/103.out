# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.99", "--one_hot=0", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=2063851082, receiver_embed_dim=64, save_run=0, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=2063851082, receiver_embed_dim=64, save_run=False, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.4720802307128906, acc=0.16261111199855804, loss=2.4720802307128906
test: epoch 1, loss 6.966660022735596, acc=0.0555555559694767, loss=6.966660022735596
train: epoch 2, loss 1.8013774156570435, acc=0.29722222685813904, loss=1.8013774156570435
test: epoch 2, loss 6.5254597663879395, acc=0.05833333358168602, loss=6.5254597663879395
train: epoch 3, loss 1.5837234258651733, acc=0.3610000014305115, loss=1.5837234258651733
test: epoch 3, loss 5.886974334716797, acc=0.04722222313284874, loss=5.886974334716797
train: epoch 4, loss 1.4422396421432495, acc=0.41922223567962646, loss=1.4422396421432495
test: epoch 4, loss 6.0190229415893555, acc=0.07500000298023224, loss=6.0190229415893555
train: epoch 5, loss 1.3607438802719116, acc=0.4528888761997223, loss=1.3607438802719116
test: epoch 5, loss 6.612459659576416, acc=0.07222222536802292, loss=6.612459659576416
train: epoch 6, loss 1.2734414339065552, acc=0.47688889503479004, loss=1.2734414339065552
test: epoch 6, loss 5.896716594696045, acc=0.06666667014360428, loss=5.896716594696045
train: epoch 7, loss 1.240424633026123, acc=0.5016666650772095, loss=1.240424633026123
test: epoch 7, loss 5.877821922302246, acc=0.10833333432674408, loss=5.877821922302246
train: epoch 8, loss 1.1848129034042358, acc=0.5172222256660461, loss=1.1848129034042358
test: epoch 8, loss 5.712970733642578, acc=0.05277777835726738, loss=5.712970733642578
train: epoch 9, loss 1.150151014328003, acc=0.5331110954284668, loss=1.150151014328003
test: epoch 9, loss 5.364284515380859, acc=0.07222222536802292, loss=5.364284515380859
train: epoch 10, loss 1.0985316038131714, acc=0.5490000247955322, loss=1.0985316038131714
test: epoch 10, loss 5.990316390991211, acc=0.08888889104127884, loss=5.990316390991211
train: epoch 11, loss 1.0674052238464355, acc=0.5708333253860474, loss=1.0674052238464355
test: epoch 11, loss 5.383573055267334, acc=0.0833333358168602, loss=5.383573055267334
train: epoch 12, loss 1.0546551942825317, acc=0.578166663646698, loss=1.0546551942825317
test: epoch 12, loss 5.747518539428711, acc=0.0555555559694767, loss=5.747518539428711
train: epoch 13, loss 1.0289087295532227, acc=0.5868889093399048, loss=1.0289087295532227
test: epoch 13, loss 5.422086238861084, acc=0.08888889104127884, loss=5.422086238861084
train: epoch 14, loss 1.0105926990509033, acc=0.5980555415153503, loss=1.0105926990509033
test: epoch 14, loss 5.254094123840332, acc=0.10000000149011612, loss=5.254094123840332
train: epoch 15, loss 0.9888967275619507, acc=0.6059444546699524, loss=0.9888967275619507
test: epoch 15, loss 5.6272969245910645, acc=0.05277777835726738, loss=5.6272969245910645
train: epoch 16, loss 0.9779812693595886, acc=0.6157777905464172, loss=0.9779812693595886
test: epoch 16, loss 4.580419540405273, acc=0.0972222238779068, loss=4.580419540405273
train: epoch 17, loss 0.9574936628341675, acc=0.6250555515289307, loss=0.9574936628341675
test: epoch 17, loss 5.276206016540527, acc=0.1111111119389534, loss=5.276206016540527
train: epoch 18, loss 0.954463005065918, acc=0.6268888711929321, loss=0.954463005065918
test: epoch 18, loss 4.0333051681518555, acc=0.14722222089767456, loss=4.0333051681518555
train: epoch 19, loss 0.9320122599601746, acc=0.6316111087799072, loss=0.9320122599601746
test: epoch 19, loss 3.9366748332977295, acc=0.05277777835726738, loss=3.9366748332977295
train: epoch 20, loss 0.9155438542366028, acc=0.6426666378974915, loss=0.9155438542366028
test: epoch 20, loss 3.757789134979248, acc=0.11666666716337204, loss=3.757789134979248
train: epoch 21, loss 0.9111539721488953, acc=0.6453333497047424, loss=0.9111539721488953
test: epoch 21, loss 3.7134501934051514, acc=0.15000000596046448, loss=3.7134501934051514
train: epoch 22, loss 0.8805687427520752, acc=0.6554999947547913, loss=0.8805687427520752
test: epoch 22, loss 3.6885769367218018, acc=0.13055555522441864, loss=3.6885769367218018
train: epoch 23, loss 0.8959837555885315, acc=0.6540555357933044, loss=0.8959837555885315
test: epoch 23, loss 3.3985753059387207, acc=0.11666666716337204, loss=3.3985753059387207
train: epoch 24, loss 0.8813360929489136, acc=0.6585000157356262, loss=0.8813360929489136
test: epoch 24, loss 4.023837566375732, acc=0.1111111119389534, loss=4.023837566375732
train: epoch 25, loss 0.869469404220581, acc=0.6641666889190674, loss=0.869469404220581
test: epoch 25, loss 3.1591248512268066, acc=0.1805555522441864, loss=3.1591248512268066
train: epoch 26, loss 0.8560829758644104, acc=0.6700000166893005, loss=0.8560829758644104
test: epoch 26, loss 2.8896265029907227, acc=0.125, loss=2.8896265029907227
train: epoch 27, loss 0.8554497957229614, acc=0.6687222123146057, loss=0.8554497957229614
test: epoch 27, loss 4.464108943939209, acc=0.0972222238779068, loss=4.464108943939209
train: epoch 28, loss 0.8742294907569885, acc=0.663611114025116, loss=0.8742294907569885
test: epoch 28, loss 3.05376935005188, acc=0.14722222089767456, loss=3.05376935005188
train: epoch 29, loss 0.8701939582824707, acc=0.6643333435058594, loss=0.8701939582824707
test: epoch 29, loss 3.1605567932128906, acc=0.17777778208255768, loss=3.1605567932128906
train: epoch 30, loss 0.8402302861213684, acc=0.6709444522857666, loss=0.8402302861213684
test: epoch 30, loss 3.1140334606170654, acc=0.13333334028720856, loss=3.1140334606170654
train: epoch 31, loss 0.8454617857933044, acc=0.6736111044883728, loss=0.8454617857933044
test: epoch 31, loss 3.2485744953155518, acc=0.13333334028720856, loss=3.2485744953155518
train: epoch 32, loss 0.8470520973205566, acc=0.6744999885559082, loss=0.8470520973205566
test: epoch 32, loss 2.9536595344543457, acc=0.15555556118488312, loss=2.9536595344543457
train: epoch 33, loss 0.8518711924552917, acc=0.6718888878822327, loss=0.8518711924552917
test: epoch 33, loss 2.494814157485962, acc=0.16111111640930176, loss=2.494814157485962
train: epoch 34, loss 0.836786687374115, acc=0.6773333549499512, loss=0.836786687374115
test: epoch 34, loss 2.9886152744293213, acc=0.16111111640930176, loss=2.9886152744293213
train: epoch 35, loss 0.8302502632141113, acc=0.6781111359596252, loss=0.8302502632141113
test: epoch 35, loss 2.601818561553955, acc=0.20000000298023224, loss=2.601818561553955
train: epoch 36, loss 0.8282016515731812, acc=0.6806111335754395, loss=0.8282016515731812
test: epoch 36, loss 2.5738115310668945, acc=0.1666666716337204, loss=2.5738115310668945
train: epoch 37, loss 0.8157161474227905, acc=0.6826111078262329, loss=0.8157161474227905
test: epoch 37, loss 2.7116544246673584, acc=0.1527777761220932, loss=2.7116544246673584
train: epoch 38, loss 0.8331617712974548, acc=0.6808888912200928, loss=0.8331617712974548
test: epoch 38, loss 2.495774507522583, acc=0.15555556118488312, loss=2.495774507522583
train: epoch 39, loss 0.837912917137146, acc=0.6755555272102356, loss=0.837912917137146
test: epoch 39, loss 2.8637855052948, acc=0.125, loss=2.8637855052948
train: epoch 40, loss 0.8267349004745483, acc=0.6740555763244629, loss=0.8267349004745483
test: epoch 40, loss 2.3851194381713867, acc=0.23055554926395416, loss=2.3851194381713867
train: epoch 41, loss 0.8238080143928528, acc=0.6787777543067932, loss=0.8238080143928528
test: epoch 41, loss 2.3319950103759766, acc=0.22499999403953552, loss=2.3319950103759766
train: epoch 42, loss 0.8096087574958801, acc=0.6855555772781372, loss=0.8096087574958801
test: epoch 42, loss 2.062751293182373, acc=0.2638888955116272, loss=2.062751293182373
train: epoch 43, loss 0.8338996767997742, acc=0.6813333630561829, loss=0.8338996767997742
test: epoch 43, loss 3.3165276050567627, acc=0.14444445073604584, loss=3.3165276050567627
train: epoch 44, loss 0.8344384431838989, acc=0.671999990940094, loss=0.8344384431838989
test: epoch 44, loss 2.9794411659240723, acc=0.18888889253139496, loss=2.9794411659240723
train: epoch 45, loss 0.8428173065185547, acc=0.6775555610656738, loss=0.8428173065185547
test: epoch 45, loss 2.2132976055145264, acc=0.22777777910232544, loss=2.2132976055145264
train: epoch 46, loss 0.8582524657249451, acc=0.6686111092567444, loss=0.8582524657249451
test: epoch 46, loss 2.2446320056915283, acc=0.20277777314186096, loss=2.2446320056915283
train: epoch 47, loss 0.8271307349205017, acc=0.6767777800559998, loss=0.8271307349205017
test: epoch 47, loss 2.2492635250091553, acc=0.23888888955116272, loss=2.2492635250091553
train: epoch 48, loss 0.8452621102333069, acc=0.6782777905464172, loss=0.8452621102333069
test: epoch 48, loss 2.209698438644409, acc=0.20277777314186096, loss=2.209698438644409
train: epoch 49, loss 0.8420109748840332, acc=0.6764444708824158, loss=0.8420109748840332
test: epoch 49, loss 2.3699841499328613, acc=0.20000000298023224, loss=2.3699841499328613
train: epoch 50, loss 0.8308296203613281, acc=0.6758333444595337, loss=0.8308296203613281
test: epoch 50, loss 2.340820074081421, acc=0.20277777314186096, loss=2.340820074081421
train: epoch 51, loss 0.8521263599395752, acc=0.6744444370269775, loss=0.8521263599395752
test: epoch 51, loss 2.122523069381714, acc=0.2361111044883728, loss=2.122523069381714
train: epoch 52, loss 0.8497851490974426, acc=0.6674444675445557, loss=0.8497851490974426
test: epoch 52, loss 2.538658618927002, acc=0.1388888955116272, loss=2.538658618927002
train: epoch 53, loss 0.8358345627784729, acc=0.6747221946716309, loss=0.8358345627784729
test: epoch 53, loss 2.4006690979003906, acc=0.23055554926395416, loss=2.4006690979003906
train: epoch 54, loss 0.8578920960426331, acc=0.6633333563804626, loss=0.8578920960426331
test: epoch 54, loss 2.2244811058044434, acc=0.2222222238779068, loss=2.2244811058044434
train: epoch 55, loss 0.8309267163276672, acc=0.6768333315849304, loss=0.8309267163276672
test: epoch 55, loss 1.947799563407898, acc=0.2638888955116272, loss=1.947799563407898
train: epoch 56, loss 0.8420543670654297, acc=0.6728333234786987, loss=0.8420543670654297
test: epoch 56, loss 2.013021469116211, acc=0.2361111044883728, loss=2.013021469116211
train: epoch 57, loss 0.854464590549469, acc=0.6690555810928345, loss=0.854464590549469
test: epoch 57, loss 2.1994192600250244, acc=0.2611111104488373, loss=2.1994192600250244
train: epoch 58, loss 0.8446906208992004, acc=0.6712222099304199, loss=0.8446906208992004
test: epoch 58, loss 2.020707845687866, acc=0.1944444477558136, loss=2.020707845687866
train: epoch 59, loss 0.8567402958869934, acc=0.6638888716697693, loss=0.8567402958869934
test: epoch 59, loss 2.0077807903289795, acc=0.2750000059604645, loss=2.0077807903289795
train: epoch 60, loss 0.8696454763412476, acc=0.6707777976989746, loss=0.8696454763412476
test: epoch 60, loss 2.6351945400238037, acc=0.20277777314186096, loss=2.6351945400238037
train: epoch 61, loss 0.8682956099510193, acc=0.6620000004768372, loss=0.8682956099510193
test: epoch 61, loss 2.082826852798462, acc=0.24444444477558136, loss=2.082826852798462
train: epoch 62, loss 0.8699734807014465, acc=0.6556666493415833, loss=0.8699734807014465
test: epoch 62, loss 1.8909331560134888, acc=0.3444444537162781, loss=1.8909331560134888
train: epoch 63, loss 0.847825825214386, acc=0.6695555448532104, loss=0.847825825214386
test: epoch 63, loss 2.223571538925171, acc=0.3083333373069763, loss=2.223571538925171
train: epoch 64, loss 0.8561940789222717, acc=0.6608333587646484, loss=0.8561940789222717
test: epoch 64, loss 2.17141056060791, acc=0.2888889014720917, loss=2.17141056060791
train: epoch 65, loss 0.8765489459037781, acc=0.6577777862548828, loss=0.8765489459037781
test: epoch 65, loss 2.1922130584716797, acc=0.2888889014720917, loss=2.1922130584716797
train: epoch 66, loss 0.8793436288833618, acc=0.6604999899864197, loss=0.8793436288833618
test: epoch 66, loss 2.169794797897339, acc=0.2527777850627899, loss=2.169794797897339
train: epoch 67, loss 0.8744855523109436, acc=0.6581110954284668, loss=0.8744855523109436
test: epoch 67, loss 2.13224720954895, acc=0.2611111104488373, loss=2.13224720954895
train: epoch 68, loss 0.871306836605072, acc=0.6610000133514404, loss=0.871306836605072
test: epoch 68, loss 1.920485496520996, acc=0.3194444477558136, loss=1.920485496520996
train: epoch 69, loss 0.8803870677947998, acc=0.6528888940811157, loss=0.8803870677947998
test: epoch 69, loss 2.0664312839508057, acc=0.28611111640930176, loss=2.0664312839508057
train: epoch 70, loss 0.8691929578781128, acc=0.6548333168029785, loss=0.8691929578781128
test: epoch 70, loss 2.072084665298462, acc=0.24722221493721008, loss=2.072084665298462
train: epoch 71, loss 0.8723337650299072, acc=0.6532222032546997, loss=0.8723337650299072
test: epoch 71, loss 1.8789029121398926, acc=0.32499998807907104, loss=1.8789029121398926
train: epoch 72, loss 0.8761196732521057, acc=0.6562777757644653, loss=0.8761196732521057
test: epoch 72, loss 1.8607585430145264, acc=0.29722222685813904, loss=1.8607585430145264
train: epoch 73, loss 0.8864346146583557, acc=0.6496111154556274, loss=0.8864346146583557
test: epoch 73, loss 1.8724043369293213, acc=0.3444444537162781, loss=1.8724043369293213
train: epoch 74, loss 0.9084894061088562, acc=0.6419444680213928, loss=0.9084894061088562
test: epoch 74, loss 2.0620598793029785, acc=0.24722221493721008, loss=2.0620598793029785
train: epoch 75, loss 0.8977339267730713, acc=0.6428889036178589, loss=0.8977339267730713
test: epoch 75, loss 1.7231075763702393, acc=0.2888889014720917, loss=1.7231075763702393
train: epoch 76, loss 0.902571439743042, acc=0.6454444527626038, loss=0.902571439743042
test: epoch 76, loss 1.6465797424316406, acc=0.35277777910232544, loss=1.6465797424316406
train: epoch 77, loss 0.9114709496498108, acc=0.6384999752044678, loss=0.9114709496498108
test: epoch 77, loss 1.9556163549423218, acc=0.3361110985279083, loss=1.9556163549423218
train: epoch 78, loss 0.8958288431167603, acc=0.6428889036178589, loss=0.8958288431167603
test: epoch 78, loss 1.782529354095459, acc=0.31111112236976624, loss=1.782529354095459
train: epoch 79, loss 0.9135884642601013, acc=0.6387777924537659, loss=0.9135884642601013
test: epoch 79, loss 1.6460288763046265, acc=0.3472222089767456, loss=1.6460288763046265
train: epoch 80, loss 0.8986583948135376, acc=0.6455000042915344, loss=0.8986583948135376
test: epoch 80, loss 1.766179084777832, acc=0.33888888359069824, loss=1.766179084777832
train: epoch 81, loss 0.8821595907211304, acc=0.6527777910232544, loss=0.8821595907211304
test: epoch 81, loss 1.774041771888733, acc=0.3444444537162781, loss=1.774041771888733
train: epoch 82, loss 0.9123013019561768, acc=0.641777753829956, loss=0.9123013019561768
test: epoch 82, loss 1.7556276321411133, acc=0.32777777314186096, loss=1.7556276321411133
train: epoch 83, loss 0.8922749161720276, acc=0.6427222490310669, loss=0.8922749161720276
test: epoch 83, loss 1.6776340007781982, acc=0.3583333194255829, loss=1.6776340007781982
train: epoch 84, loss 0.9093108773231506, acc=0.6385555267333984, loss=0.9093108773231506
test: epoch 84, loss 1.6688785552978516, acc=0.375, loss=1.6688785552978516
train: epoch 85, loss 0.9100843667984009, acc=0.6337777972221375, loss=0.9100843667984009
test: epoch 85, loss 1.5772559642791748, acc=0.3638888895511627, loss=1.5772559642791748
train: epoch 86, loss 0.8919694423675537, acc=0.6453889012336731, loss=0.8919694423675537
test: epoch 86, loss 1.7884007692337036, acc=0.33888888359069824, loss=1.7884007692337036
train: epoch 87, loss 0.9022722840309143, acc=0.6464999914169312, loss=0.9022722840309143
test: epoch 87, loss 1.4599106311798096, acc=0.3611111044883728, loss=1.4599106311798096
train: epoch 88, loss 0.8755910396575928, acc=0.64811110496521, loss=0.8755910396575928
test: epoch 88, loss 1.875773310661316, acc=0.3305555582046509, loss=1.875773310661316
train: epoch 89, loss 0.8809915781021118, acc=0.6406111121177673, loss=0.8809915781021118
test: epoch 89, loss 1.6487312316894531, acc=0.33888888359069824, loss=1.6487312316894531
train: epoch 90, loss 0.8756592273712158, acc=0.6458888649940491, loss=0.8756592273712158
test: epoch 90, loss 1.5965427160263062, acc=0.4694444537162781, loss=1.5965427160263062
train: epoch 91, loss 0.8843256235122681, acc=0.6431111097335815, loss=0.8843256235122681
test: epoch 91, loss 1.4861831665039062, acc=0.3583333194255829, loss=1.4861831665039062
train: epoch 92, loss 0.8841152191162109, acc=0.6439444422721863, loss=0.8841152191162109
test: epoch 92, loss 1.5050228834152222, acc=0.3055555522441864, loss=1.5050228834152222
train: epoch 93, loss 0.9023993015289307, acc=0.636555552482605, loss=0.9023993015289307
test: epoch 93, loss 1.4245645999908447, acc=0.3611111044883728, loss=1.4245645999908447
train: epoch 94, loss 0.8726673722267151, acc=0.6493889093399048, loss=0.8726673722267151
test: epoch 94, loss 1.4763931035995483, acc=0.39444443583488464, loss=1.4763931035995483
train: epoch 95, loss 0.8588686585426331, acc=0.656000018119812, loss=0.8588686585426331
test: epoch 95, loss 1.6505659818649292, acc=0.4055555462837219, loss=1.6505659818649292
train: epoch 96, loss 0.8654395341873169, acc=0.6511666774749756, loss=0.8654395341873169
test: epoch 96, loss 1.3496397733688354, acc=0.42500001192092896, loss=1.3496397733688354
train: epoch 97, loss 0.8625615239143372, acc=0.6585000157356262, loss=0.8625615239143372
test: epoch 97, loss 1.3314895629882812, acc=0.4611110985279083, loss=1.3314895629882812
train: epoch 98, loss 0.8646509051322937, acc=0.6508888602256775, loss=0.8646509051322937
test: epoch 98, loss 1.4059698581695557, acc=0.4333333373069763, loss=1.4059698581695557
train: epoch 99, loss 0.8558709621429443, acc=0.6567222476005554, loss=0.8558709621429443
test: epoch 99, loss 1.246437430381775, acc=0.5222222208976746, loss=1.246437430381775
train: epoch 100, loss 0.8490524888038635, acc=0.6572777628898621, loss=0.8490524888038635
test: epoch 100, loss 1.5855640172958374, acc=0.4027777910232544, loss=1.5855640172958374
train: epoch 101, loss 0.826767086982727, acc=0.6642777919769287, loss=0.826767086982727
test: epoch 101, loss 1.4508837461471558, acc=0.3166666626930237, loss=1.4508837461471558
train: epoch 102, loss 0.850753903388977, acc=0.6567222476005554, loss=0.850753903388977
test: epoch 102, loss 1.558427333831787, acc=0.35277777910232544, loss=1.558427333831787
train: epoch 103, loss 0.8371442556381226, acc=0.6630555391311646, loss=0.8371442556381226
test: epoch 103, loss 1.2871644496917725, acc=0.3611111044883728, loss=1.2871644496917725
train: epoch 104, loss 0.8271698355674744, acc=0.664555549621582, loss=0.8271698355674744
test: epoch 104, loss 1.3715429306030273, acc=0.4138889014720917, loss=1.3715429306030273
train: epoch 105, loss 0.8249513506889343, acc=0.6649444699287415, loss=0.8249513506889343
test: epoch 105, loss 1.5677075386047363, acc=0.32499998807907104, loss=1.5677075386047363
train: epoch 106, loss 0.7979967594146729, acc=0.676111102104187, loss=0.7979967594146729
test: epoch 106, loss 1.3205456733703613, acc=0.4416666626930237, loss=1.3205456733703613
train: epoch 107, loss 0.8108489513397217, acc=0.6728888750076294, loss=0.8108489513397217
test: epoch 107, loss 1.4456548690795898, acc=0.4055555462837219, loss=1.4456548690795898
train: epoch 108, loss 0.8102572560310364, acc=0.6702222228050232, loss=0.8102572560310364
test: epoch 108, loss 1.313456416130066, acc=0.35277777910232544, loss=1.313456416130066
train: epoch 109, loss 0.8109549880027771, acc=0.6744444370269775, loss=0.8109549880027771
test: epoch 109, loss 1.4157295227050781, acc=0.3611111044883728, loss=1.4157295227050781
train: epoch 110, loss 0.7991336584091187, acc=0.6732222437858582, loss=0.7991336584091187
test: epoch 110, loss 1.485482096672058, acc=0.3583333194255829, loss=1.485482096672058
train: epoch 111, loss 0.7902519702911377, acc=0.6827777624130249, loss=0.7902519702911377
test: epoch 111, loss 1.4646798372268677, acc=0.35277777910232544, loss=1.4646798372268677
train: epoch 112, loss 0.7827003598213196, acc=0.6857777833938599, loss=0.7827003598213196
test: epoch 112, loss 1.4996027946472168, acc=0.39722222089767456, loss=1.4996027946472168
train: epoch 113, loss 0.7844796776771545, acc=0.6816666722297668, loss=0.7844796776771545
test: epoch 113, loss 1.2880535125732422, acc=0.4138889014720917, loss=1.2880535125732422
train: epoch 114, loss 0.7715648412704468, acc=0.6884999871253967, loss=0.7715648412704468
test: epoch 114, loss 1.3977556228637695, acc=0.3861111104488373, loss=1.3977556228637695
train: epoch 115, loss 0.7573959231376648, acc=0.6900555491447449, loss=0.7573959231376648
test: epoch 115, loss 1.3599700927734375, acc=0.36944442987442017, loss=1.3599700927734375
train: epoch 116, loss 0.7577285766601562, acc=0.6910555362701416, loss=0.7577285766601562
test: epoch 116, loss 1.3829251527786255, acc=0.3888888955116272, loss=1.3829251527786255
train: epoch 117, loss 0.7663145065307617, acc=0.6846110820770264, loss=0.7663145065307617
test: epoch 117, loss 1.2669475078582764, acc=0.45277777314186096, loss=1.2669475078582764
train: epoch 118, loss 0.7473258972167969, acc=0.6962777972221375, loss=0.7473258972167969
test: epoch 118, loss 1.2102112770080566, acc=0.47777777910232544, loss=1.2102112770080566
train: epoch 119, loss 0.7429513335227966, acc=0.7003889083862305, loss=0.7429513335227966
test: epoch 119, loss 1.4620637893676758, acc=0.3888888955116272, loss=1.4620637893676758
train: epoch 120, loss 0.7553494572639465, acc=0.695277750492096, loss=0.7553494572639465
test: epoch 120, loss 1.3608678579330444, acc=0.3722222149372101, loss=1.3608678579330444
train: epoch 121, loss 0.7573725581169128, acc=0.695111095905304, loss=0.7573725581169128
test: epoch 121, loss 1.4776554107666016, acc=0.35277777910232544, loss=1.4776554107666016
train: epoch 122, loss 0.8407495617866516, acc=0.6529444456100464, loss=0.8407495617866516
test: epoch 122, loss 1.4292182922363281, acc=0.4277777671813965, loss=1.4292182922363281
train: epoch 123, loss 0.773762047290802, acc=0.6893333196640015, loss=0.773762047290802
test: epoch 123, loss 1.3976593017578125, acc=0.4027777910232544, loss=1.3976593017578125
train: epoch 124, loss 0.7132710814476013, acc=0.7152777910232544, loss=0.7132710814476013
test: epoch 124, loss 1.4059503078460693, acc=0.3861111104488373, loss=1.4059503078460693
train: epoch 125, loss 0.7358636856079102, acc=0.706333339214325, loss=0.7358636856079102
test: epoch 125, loss 1.1333786249160767, acc=0.5305555462837219, loss=1.1333786249160767
train: epoch 126, loss 0.7117917537689209, acc=0.7161666750907898, loss=0.7117917537689209
test: epoch 126, loss 1.4156203269958496, acc=0.375, loss=1.4156203269958496
train: epoch 127, loss 0.7172417044639587, acc=0.7052222490310669, loss=0.7172417044639587
test: epoch 127, loss 1.2760310173034668, acc=0.5222222208976746, loss=1.2760310173034668
train: epoch 128, loss 0.704842746257782, acc=0.7166666388511658, loss=0.704842746257782
test: epoch 128, loss 1.4433248043060303, acc=0.43611112236976624, loss=1.4433248043060303
train: epoch 129, loss 0.7058919072151184, acc=0.7187777757644653, loss=0.7058919072151184
test: epoch 129, loss 1.3795777559280396, acc=0.3916666805744171, loss=1.3795777559280396
train: epoch 130, loss 0.7030060291290283, acc=0.7231666445732117, loss=0.7030060291290283
test: epoch 130, loss 1.2242825031280518, acc=0.46388888359069824, loss=1.2242825031280518
train: epoch 131, loss 0.6908360719680786, acc=0.7218888998031616, loss=0.6908360719680786
test: epoch 131, loss 1.2939534187316895, acc=0.49444442987442017, loss=1.2939534187316895
train: epoch 132, loss 0.6952329277992249, acc=0.7231666445732117, loss=0.6952329277992249
test: epoch 132, loss 1.3332724571228027, acc=0.4583333432674408, loss=1.3332724571228027
train: epoch 133, loss 0.6883413195610046, acc=0.7246666550636292, loss=0.6883413195610046
test: epoch 133, loss 1.203696608543396, acc=0.5333333611488342, loss=1.203696608543396
train: epoch 134, loss 0.6851701140403748, acc=0.7297222018241882, loss=0.6851701140403748
test: epoch 134, loss 1.3852124214172363, acc=0.4583333432674408, loss=1.3852124214172363
train: epoch 135, loss 0.6918433904647827, acc=0.7273889183998108, loss=0.6918433904647827
test: epoch 135, loss 1.1814677715301514, acc=0.49166667461395264, loss=1.1814677715301514
train: epoch 136, loss 0.6892171502113342, acc=0.7222777605056763, loss=0.6892171502113342
test: epoch 136, loss 1.3082116842269897, acc=0.4277777671813965, loss=1.3082116842269897
train: epoch 137, loss 0.6777769327163696, acc=0.7288333177566528, loss=0.6777769327163696
test: epoch 137, loss 1.1779437065124512, acc=0.5138888955116272, loss=1.1779437065124512
train: epoch 138, loss 0.6800110936164856, acc=0.7302777767181396, loss=0.6800110936164856
test: epoch 138, loss 1.1168243885040283, acc=0.5388888716697693, loss=1.1168243885040283
train: epoch 139, loss 0.6630338430404663, acc=0.7338888645172119, loss=0.6630338430404663
test: epoch 139, loss 1.2405198812484741, acc=0.44999998807907104, loss=1.2405198812484741
train: epoch 140, loss 0.6718400716781616, acc=0.7325000166893005, loss=0.6718400716781616
test: epoch 140, loss 1.2969872951507568, acc=0.42500001192092896, loss=1.2969872951507568
train: epoch 141, loss 0.6545748710632324, acc=0.7402222156524658, loss=0.6545748710632324
test: epoch 141, loss 1.2792472839355469, acc=0.35277777910232544, loss=1.2792472839355469
train: epoch 142, loss 0.6704797744750977, acc=0.7396110892295837, loss=0.6704797744750977
test: epoch 142, loss 1.2921955585479736, acc=0.45277777314186096, loss=1.2921955585479736
train: epoch 143, loss 0.6826533675193787, acc=0.7280555367469788, loss=0.6826533675193787
test: epoch 143, loss 1.3324946165084839, acc=0.46666666865348816, loss=1.3324946165084839
train: epoch 144, loss 0.6797322630882263, acc=0.7322777509689331, loss=0.6797322630882263
test: epoch 144, loss 1.2829328775405884, acc=0.39444443583488464, loss=1.2829328775405884
train: epoch 145, loss 0.6576998829841614, acc=0.7386666536331177, loss=0.6576998829841614
test: epoch 145, loss 1.1277551651000977, acc=0.5333333611488342, loss=1.1277551651000977
train: epoch 146, loss 0.6453940868377686, acc=0.7438333630561829, loss=0.6453940868377686
test: epoch 146, loss 1.0877138376235962, acc=0.5361111164093018, loss=1.0877138376235962
train: epoch 147, loss 0.6427996158599854, acc=0.7504444718360901, loss=0.6427996158599854
test: epoch 147, loss 1.2954671382904053, acc=0.4166666567325592, loss=1.2954671382904053
train: epoch 148, loss 0.6379135251045227, acc=0.7481666803359985, loss=0.6379135251045227
test: epoch 148, loss 1.1136081218719482, acc=0.49444442987442017, loss=1.1136081218719482
train: epoch 149, loss 0.6434733867645264, acc=0.7422778010368347, loss=0.6434733867645264
test: epoch 149, loss 1.2501088380813599, acc=0.49444442987442017, loss=1.2501088380813599
train: epoch 150, loss 0.6415214538574219, acc=0.7431666851043701, loss=0.6415214538574219
test: epoch 150, loss 1.421667456626892, acc=0.4416666626930237, loss=1.421667456626892
