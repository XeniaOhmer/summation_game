# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=1.5", "--temp_decay=1", "--one_hot=true", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=491333192, receiver_embed_dim=128, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.9484329223632812, acc=0.09883332997560501, loss=2.9484329223632812
test: epoch 1, loss 2.5706238746643066, acc=0.10555555671453476, loss=2.5706238746643066
train: epoch 2, loss 1.6748017072677612, acc=0.31805557012557983, loss=1.6748017072677612
test: epoch 2, loss 2.2380104064941406, acc=0.20000000298023224, loss=2.2380104064941406
train: epoch 3, loss 1.387021780014038, acc=0.41277778148651123, loss=1.387021780014038
test: epoch 3, loss 2.2786407470703125, acc=0.21388888359069824, loss=2.2786407470703125
train: epoch 4, loss 1.2235183715820312, acc=0.4883333444595337, loss=1.2235183715820312
test: epoch 4, loss 2.0346944332122803, acc=0.24166665971279144, loss=2.0346944332122803
train: epoch 5, loss 1.0989751815795898, acc=0.5476666688919067, loss=1.0989751815795898
test: epoch 5, loss 1.9730994701385498, acc=0.24722221493721008, loss=1.9730994701385498
train: epoch 6, loss 1.0144822597503662, acc=0.5902777910232544, loss=1.0144822597503662
test: epoch 6, loss 2.0934298038482666, acc=0.2750000059604645, loss=2.0934298038482666
train: epoch 7, loss 0.9409120082855225, acc=0.6149444580078125, loss=0.9409120082855225
test: epoch 7, loss 1.9061520099639893, acc=0.2805555462837219, loss=1.9061520099639893
train: epoch 8, loss 0.8692288398742676, acc=0.6539999842643738, loss=0.8692288398742676
test: epoch 8, loss 1.990173578262329, acc=0.2361111044883728, loss=1.990173578262329
train: epoch 9, loss 0.809030294418335, acc=0.6823889017105103, loss=0.809030294418335
test: epoch 9, loss 1.8083642721176147, acc=0.31111112236976624, loss=1.8083642721176147
train: epoch 10, loss 0.7541401982307434, acc=0.7048888802528381, loss=0.7541401982307434
test: epoch 10, loss 1.7795478105545044, acc=0.3083333373069763, loss=1.7795478105545044
train: epoch 11, loss 0.702100396156311, acc=0.7295555472373962, loss=0.702100396156311
test: epoch 11, loss 1.9899119138717651, acc=0.2916666567325592, loss=1.9899119138717651
train: epoch 12, loss 0.6579321026802063, acc=0.7452222108840942, loss=0.6579321026802063
test: epoch 12, loss 2.061363458633423, acc=0.3055555522441864, loss=2.061363458633423
train: epoch 13, loss 0.6292902231216431, acc=0.7561110854148865, loss=0.6292902231216431
test: epoch 13, loss 1.8060059547424316, acc=0.35277777910232544, loss=1.8060059547424316
train: epoch 14, loss 0.5767694711685181, acc=0.7799999713897705, loss=0.5767694711685181
test: epoch 14, loss 1.9801052808761597, acc=0.31388887763023376, loss=1.9801052808761597
train: epoch 15, loss 0.5468131303787231, acc=0.7925000190734863, loss=0.5468131303787231
test: epoch 15, loss 1.8997647762298584, acc=0.3305555582046509, loss=1.8997647762298584
train: epoch 16, loss 0.5288492441177368, acc=0.799833357334137, loss=0.5288492441177368
test: epoch 16, loss 1.8808987140655518, acc=0.3333333432674408, loss=1.8808987140655518
train: epoch 17, loss 0.5003174543380737, acc=0.8151111006736755, loss=0.5003174543380737
test: epoch 17, loss 1.9633957147598267, acc=0.33888888359069824, loss=1.9633957147598267
train: epoch 18, loss 0.4590963125228882, acc=0.8299444317817688, loss=0.4590963125228882
test: epoch 18, loss 1.961238145828247, acc=0.3499999940395355, loss=1.961238145828247
train: epoch 19, loss 0.43161529302597046, acc=0.8424444198608398, loss=0.43161529302597046
test: epoch 19, loss 2.093357801437378, acc=0.36666667461395264, loss=2.093357801437378
train: epoch 20, loss 0.4201573431491852, acc=0.8453333377838135, loss=0.4201573431491852
test: epoch 20, loss 2.0121207237243652, acc=0.35277777910232544, loss=2.0121207237243652
train: epoch 21, loss 0.39868414402008057, acc=0.8541666865348816, loss=0.39868414402008057
test: epoch 21, loss 2.1940412521362305, acc=0.38055557012557983, loss=2.1940412521362305
train: epoch 22, loss 0.3845084309577942, acc=0.8622778058052063, loss=0.3845084309577942
test: epoch 22, loss 2.14968204498291, acc=0.35555556416511536, loss=2.14968204498291
train: epoch 23, loss 0.36330193281173706, acc=0.870888888835907, loss=0.36330193281173706
test: epoch 23, loss 2.103929281234741, acc=0.3611111044883728, loss=2.103929281234741
train: epoch 24, loss 0.3555324077606201, acc=0.8728888630867004, loss=0.3555324077606201
test: epoch 24, loss 2.1965787410736084, acc=0.35277777910232544, loss=2.1965787410736084
train: epoch 25, loss 0.33083778619766235, acc=0.8831111192703247, loss=0.33083778619766235
test: epoch 25, loss 2.1164615154266357, acc=0.3861111104488373, loss=2.1164615154266357
train: epoch 26, loss 0.3278965353965759, acc=0.8870000243186951, loss=0.3278965353965759
test: epoch 26, loss 2.1618480682373047, acc=0.3583333194255829, loss=2.1618480682373047
train: epoch 27, loss 0.30422282218933105, acc=0.8938888907432556, loss=0.30422282218933105
test: epoch 27, loss 2.1699540615081787, acc=0.3583333194255829, loss=2.1699540615081787
train: epoch 28, loss 0.2895001769065857, acc=0.9002222418785095, loss=0.2895001769065857
test: epoch 28, loss 2.274808168411255, acc=0.3777777850627899, loss=2.274808168411255
train: epoch 29, loss 0.27419164776802063, acc=0.9053333401679993, loss=0.27419164776802063
test: epoch 29, loss 2.4350574016571045, acc=0.3777777850627899, loss=2.4350574016571045
train: epoch 30, loss 0.26711565256118774, acc=0.9054444432258606, loss=0.26711565256118774
test: epoch 30, loss 2.41206693649292, acc=0.4055555462837219, loss=2.41206693649292
train: epoch 31, loss 0.2606821060180664, acc=0.9112222194671631, loss=0.2606821060180664
test: epoch 31, loss 2.4919302463531494, acc=0.4000000059604645, loss=2.4919302463531494
train: epoch 32, loss 0.25078678131103516, acc=0.9122222065925598, loss=0.25078678131103516
test: epoch 32, loss 2.358832597732544, acc=0.43888887763023376, loss=2.358832597732544
train: epoch 33, loss 0.24937154352664948, acc=0.9131666421890259, loss=0.24937154352664948
test: epoch 33, loss 2.387967586517334, acc=0.4027777910232544, loss=2.387967586517334
train: epoch 34, loss 0.24218226969242096, acc=0.9164444208145142, loss=0.24218226969242096
test: epoch 34, loss 2.600097894668579, acc=0.4166666567325592, loss=2.600097894668579
train: epoch 35, loss 0.2370496541261673, acc=0.9181666374206543, loss=0.2370496541261673
test: epoch 35, loss 2.2561869621276855, acc=0.4444444477558136, loss=2.2561869621276855
train: epoch 36, loss 0.23437578976154327, acc=0.921500027179718, loss=0.23437578976154327
test: epoch 36, loss 2.4729506969451904, acc=0.42222222685813904, loss=2.4729506969451904
train: epoch 37, loss 0.22394977509975433, acc=0.9258333444595337, loss=0.22394977509975433
test: epoch 37, loss 2.4585142135620117, acc=0.44999998807907104, loss=2.4585142135620117
train: epoch 38, loss 0.21053865551948547, acc=0.9267777800559998, loss=0.21053865551948547
test: epoch 38, loss 2.5215413570404053, acc=0.43888887763023376, loss=2.5215413570404053
train: epoch 39, loss 0.21750201284885406, acc=0.9267777800559998, loss=0.21750201284885406
test: epoch 39, loss 2.574674606323242, acc=0.42500001192092896, loss=2.574674606323242
train: epoch 40, loss 0.21102800965309143, acc=0.929722249507904, loss=0.21102800965309143
test: epoch 40, loss 2.4849069118499756, acc=0.4416666626930237, loss=2.4849069118499756
train: epoch 41, loss 0.20855170488357544, acc=0.9278888702392578, loss=0.20855170488357544
test: epoch 41, loss 2.486853837966919, acc=0.4194444417953491, loss=2.486853837966919
train: epoch 42, loss 0.20642024278640747, acc=0.9301666617393494, loss=0.20642024278640747
test: epoch 42, loss 2.523923397064209, acc=0.4583333432674408, loss=2.523923397064209
train: epoch 43, loss 0.19249485433101654, acc=0.9350555539131165, loss=0.19249485433101654
test: epoch 43, loss 2.6354169845581055, acc=0.42500001192092896, loss=2.6354169845581055
train: epoch 44, loss 0.19295723736286163, acc=0.9338889122009277, loss=0.19295723736286163
test: epoch 44, loss 2.792694330215454, acc=0.4611110985279083, loss=2.792694330215454
train: epoch 45, loss 0.19768984615802765, acc=0.9342222213745117, loss=0.19768984615802765
test: epoch 45, loss 2.4810538291931152, acc=0.4472222328186035, loss=2.4810538291931152
train: epoch 46, loss 0.19489341974258423, acc=0.934499979019165, loss=0.19489341974258423
test: epoch 46, loss 2.7273876667022705, acc=0.4583333432674408, loss=2.7273876667022705
train: epoch 47, loss 0.19002722203731537, acc=0.9377222061157227, loss=0.19002722203731537
test: epoch 47, loss 2.5718393325805664, acc=0.45277777314186096, loss=2.5718393325805664
train: epoch 48, loss 0.1930941641330719, acc=0.9351111054420471, loss=0.1930941641330719
test: epoch 48, loss 2.9531853199005127, acc=0.46666666865348816, loss=2.9531853199005127
train: epoch 49, loss 0.1807146519422531, acc=0.9391111135482788, loss=0.1807146519422531
test: epoch 49, loss 2.488616943359375, acc=0.4583333432674408, loss=2.488616943359375
train: epoch 50, loss 0.1850115954875946, acc=0.9392222166061401, loss=0.1850115954875946
test: epoch 50, loss 2.7158408164978027, acc=0.45277777314186096, loss=2.7158408164978027
train: epoch 51, loss 0.18950526416301727, acc=0.9388889074325562, loss=0.18950526416301727
test: epoch 51, loss 2.4014315605163574, acc=0.46388888359069824, loss=2.4014315605163574
train: epoch 52, loss 0.1759181022644043, acc=0.941611111164093, loss=0.1759181022644043
test: epoch 52, loss 2.8537209033966064, acc=0.4472222328186035, loss=2.8537209033966064
train: epoch 53, loss 0.17494282126426697, acc=0.9401666522026062, loss=0.17494282126426697
test: epoch 53, loss 2.920353889465332, acc=0.46388888359069824, loss=2.920353889465332
train: epoch 54, loss 0.18477147817611694, acc=0.9399444460868835, loss=0.18477147817611694
test: epoch 54, loss 2.8082692623138428, acc=0.4416666626930237, loss=2.8082692623138428
train: epoch 55, loss 0.1953224539756775, acc=0.9373888969421387, loss=0.1953224539756775
test: epoch 55, loss 2.6433968544006348, acc=0.4583333432674408, loss=2.6433968544006348
train: epoch 56, loss 0.17176277935504913, acc=0.9429444670677185, loss=0.17176277935504913
test: epoch 56, loss 2.658432722091675, acc=0.45277777314186096, loss=2.658432722091675
train: epoch 57, loss 0.18246476352214813, acc=0.9392222166061401, loss=0.18246476352214813
test: epoch 57, loss 2.433675527572632, acc=0.4722222089767456, loss=2.433675527572632
train: epoch 58, loss 0.16068637371063232, acc=0.9444444179534912, loss=0.16068637371063232
test: epoch 58, loss 2.4701876640319824, acc=0.4472222328186035, loss=2.4701876640319824
train: epoch 59, loss 0.1637134552001953, acc=0.945722222328186, loss=0.1637134552001953
test: epoch 59, loss 2.580660343170166, acc=0.48055556416511536, loss=2.580660343170166
train: epoch 60, loss 0.17039360105991364, acc=0.9443333148956299, loss=0.17039360105991364
test: epoch 60, loss 2.527503490447998, acc=0.47777777910232544, loss=2.527503490447998
train: epoch 61, loss 0.1711575984954834, acc=0.9441666603088379, loss=0.1711575984954834
test: epoch 61, loss 2.6451244354248047, acc=0.4694444537162781, loss=2.6451244354248047
train: epoch 62, loss 0.17317481338977814, acc=0.9428889155387878, loss=0.17317481338977814
test: epoch 62, loss 2.9537858963012695, acc=0.4583333432674408, loss=2.9537858963012695
train: epoch 63, loss 0.1597580462694168, acc=0.9471666812896729, loss=0.1597580462694168
test: epoch 63, loss 2.653327465057373, acc=0.4555555582046509, loss=2.653327465057373
train: epoch 64, loss 0.15240755677223206, acc=0.9471111297607422, loss=0.15240755677223206
test: epoch 64, loss 3.162048816680908, acc=0.44999998807907104, loss=3.162048816680908
train: epoch 65, loss 0.1636679470539093, acc=0.9454444646835327, loss=0.1636679470539093
test: epoch 65, loss 3.199946403503418, acc=0.4416666626930237, loss=3.199946403503418
train: epoch 66, loss 0.1532668024301529, acc=0.9494444727897644, loss=0.1532668024301529
test: epoch 66, loss 2.6480610370635986, acc=0.5, loss=2.6480610370635986
train: epoch 67, loss 0.16460451483726501, acc=0.9450555443763733, loss=0.16460451483726501
test: epoch 67, loss 2.635941743850708, acc=0.4611110985279083, loss=2.635941743850708
train: epoch 68, loss 0.15883812308311462, acc=0.9475555419921875, loss=0.15883812308311462
test: epoch 68, loss 2.4317219257354736, acc=0.48055556416511536, loss=2.4317219257354736
train: epoch 69, loss 0.16814254224300385, acc=0.9443333148956299, loss=0.16814254224300385
test: epoch 69, loss 2.859731435775757, acc=0.4888888895511627, loss=2.859731435775757
train: epoch 70, loss 0.14921852946281433, acc=0.9525555372238159, loss=0.14921852946281433
test: epoch 70, loss 2.6274983882904053, acc=0.5027777552604675, loss=2.6274983882904053
train: epoch 71, loss 0.14679868519306183, acc=0.9514444470405579, loss=0.14679868519306183
test: epoch 71, loss 2.3273820877075195, acc=0.4972222149372101, loss=2.3273820877075195
train: epoch 72, loss 0.15167798101902008, acc=0.949222207069397, loss=0.15167798101902008
test: epoch 72, loss 2.7275338172912598, acc=0.4749999940395355, loss=2.7275338172912598
train: epoch 73, loss 0.1517767310142517, acc=0.948888897895813, loss=0.1517767310142517
test: epoch 73, loss 2.40726900100708, acc=0.5, loss=2.40726900100708
train: epoch 74, loss 0.14707185328006744, acc=0.9482777714729309, loss=0.14707185328006744
test: epoch 74, loss 2.5020010471343994, acc=0.5, loss=2.5020010471343994
train: epoch 75, loss 0.15720659494400024, acc=0.945888876914978, loss=0.15720659494400024
test: epoch 75, loss 2.8462975025177, acc=0.5027777552604675, loss=2.8462975025177
train: epoch 76, loss 0.15603169798851013, acc=0.9497777819633484, loss=0.15603169798851013
test: epoch 76, loss 2.3749380111694336, acc=0.49166667461395264, loss=2.3749380111694336
train: epoch 77, loss 0.140129953622818, acc=0.9523888826370239, loss=0.140129953622818
test: epoch 77, loss 2.5918378829956055, acc=0.4749999940395355, loss=2.5918378829956055
train: epoch 78, loss 0.14212803542613983, acc=0.9527778029441833, loss=0.14212803542613983
test: epoch 78, loss 2.8119513988494873, acc=0.4722222089767456, loss=2.8119513988494873
train: epoch 79, loss 0.13696952164173126, acc=0.9541110992431641, loss=0.13696952164173126
test: epoch 79, loss 2.6954898834228516, acc=0.4833333194255829, loss=2.6954898834228516
train: epoch 80, loss 0.15030750632286072, acc=0.9528889060020447, loss=0.15030750632286072
test: epoch 80, loss 2.9080634117126465, acc=0.4722222089767456, loss=2.9080634117126465
train: epoch 81, loss 0.13546478748321533, acc=0.9570000171661377, loss=0.13546478748321533
test: epoch 81, loss 2.7114675045013428, acc=0.5166666507720947, loss=2.7114675045013428
train: epoch 82, loss 0.13682901859283447, acc=0.9548888802528381, loss=0.13682901859283447
test: epoch 82, loss 2.6300876140594482, acc=0.49166667461395264, loss=2.6300876140594482
train: epoch 83, loss 0.13805629312992096, acc=0.9557222127914429, loss=0.13805629312992096
test: epoch 83, loss 2.3420090675354004, acc=0.5083333253860474, loss=2.3420090675354004
train: epoch 84, loss 0.13038796186447144, acc=0.9581666588783264, loss=0.13038796186447144
test: epoch 84, loss 2.583885669708252, acc=0.5166666507720947, loss=2.583885669708252
train: epoch 85, loss 0.13806623220443726, acc=0.9533888697624207, loss=0.13806623220443726
test: epoch 85, loss 2.7144134044647217, acc=0.48055556416511536, loss=2.7144134044647217
train: epoch 86, loss 0.1331554353237152, acc=0.956166684627533, loss=0.1331554353237152
test: epoch 86, loss 2.713406801223755, acc=0.5333333611488342, loss=2.713406801223755
train: epoch 87, loss 0.13577350974082947, acc=0.956333339214325, loss=0.13577350974082947
test: epoch 87, loss 2.8181397914886475, acc=0.5, loss=2.8181397914886475
train: epoch 88, loss 0.13223056495189667, acc=0.9555555582046509, loss=0.13223056495189667
test: epoch 88, loss 2.7880876064300537, acc=0.5055555701255798, loss=2.7880876064300537
train: epoch 89, loss 0.1352461576461792, acc=0.957611083984375, loss=0.1352461576461792
test: epoch 89, loss 2.596907615661621, acc=0.5416666865348816, loss=2.596907615661621
train: epoch 90, loss 0.13521221280097961, acc=0.9570000171661377, loss=0.13521221280097961
test: epoch 90, loss 2.8109700679779053, acc=0.5027777552604675, loss=2.8109700679779053
train: epoch 91, loss 0.12088280916213989, acc=0.9583333134651184, loss=0.12088280916213989
test: epoch 91, loss 2.3279776573181152, acc=0.519444465637207, loss=2.3279776573181152
train: epoch 92, loss 0.1368580311536789, acc=0.9557222127914429, loss=0.1368580311536789
test: epoch 92, loss 2.886488914489746, acc=0.4888888895511627, loss=2.886488914489746
train: epoch 93, loss 0.12846003472805023, acc=0.9578333497047424, loss=0.12846003472805023
test: epoch 93, loss 2.730717897415161, acc=0.5027777552604675, loss=2.730717897415161
train: epoch 94, loss 0.1323077231645584, acc=0.9580000042915344, loss=0.1323077231645584
test: epoch 94, loss 2.4418938159942627, acc=0.5305555462837219, loss=2.4418938159942627
train: epoch 95, loss 0.12721040844917297, acc=0.9592221975326538, loss=0.12721040844917297
test: epoch 95, loss 2.4721181392669678, acc=0.5333333611488342, loss=2.4721181392669678
train: epoch 96, loss 0.1285189986228943, acc=0.9595000147819519, loss=0.1285189986228943
test: epoch 96, loss 2.699387788772583, acc=0.5333333611488342, loss=2.699387788772583
train: epoch 97, loss 0.12124010920524597, acc=0.9610000252723694, loss=0.12124010920524597
test: epoch 97, loss 2.690985918045044, acc=0.5444444417953491, loss=2.690985918045044
train: epoch 98, loss 0.11916447430849075, acc=0.9614444375038147, loss=0.11916447430849075
test: epoch 98, loss 2.6350255012512207, acc=0.4833333194255829, loss=2.6350255012512207
train: epoch 99, loss 0.11112886667251587, acc=0.9642778038978577, loss=0.11112886667251587
test: epoch 99, loss 2.740947961807251, acc=0.5166666507720947, loss=2.740947961807251
train: epoch 100, loss 0.11786654591560364, acc=0.9620555639266968, loss=0.11786654591560364
test: epoch 100, loss 2.2607178688049316, acc=0.5361111164093018, loss=2.2607178688049316
train: epoch 101, loss 0.11880486458539963, acc=0.9621666669845581, loss=0.11880486458539963
test: epoch 101, loss 2.897183656692505, acc=0.5166666507720947, loss=2.897183656692505
train: epoch 102, loss 0.11524322628974915, acc=0.961388885974884, loss=0.11524322628974915
test: epoch 102, loss 3.0807137489318848, acc=0.5249999761581421, loss=3.0807137489318848
train: epoch 103, loss 0.10844574868679047, acc=0.964388906955719, loss=0.10844574868679047
test: epoch 103, loss 3.034806489944458, acc=0.519444465637207, loss=3.034806489944458
train: epoch 104, loss 0.1166437566280365, acc=0.9624999761581421, loss=0.1166437566280365
test: epoch 104, loss 3.0699808597564697, acc=0.5111111402511597, loss=3.0699808597564697
train: epoch 105, loss 0.10455809533596039, acc=0.9667778015136719, loss=0.10455809533596039
test: epoch 105, loss 3.2499797344207764, acc=0.519444465637207, loss=3.2499797344207764
train: epoch 106, loss 0.1095622181892395, acc=0.9662777781486511, loss=0.1095622181892395
test: epoch 106, loss 2.5078296661376953, acc=0.5333333611488342, loss=2.5078296661376953
train: epoch 107, loss 0.10828625410795212, acc=0.9642778038978577, loss=0.10828625410795212
test: epoch 107, loss 2.734321117401123, acc=0.5166666507720947, loss=2.734321117401123
train: epoch 108, loss 0.1068478524684906, acc=0.9658889174461365, loss=0.1068478524684906
test: epoch 108, loss 2.6591193675994873, acc=0.5249999761581421, loss=2.6591193675994873
train: epoch 109, loss 0.10790137946605682, acc=0.9651666879653931, loss=0.10790137946605682
test: epoch 109, loss 3.116255044937134, acc=0.5388888716697693, loss=3.116255044937134
train: epoch 110, loss 0.10840766131877899, acc=0.964388906955719, loss=0.10840766131877899
test: epoch 110, loss 2.833712577819824, acc=0.5222222208976746, loss=2.833712577819824
train: epoch 111, loss 0.106037437915802, acc=0.9666666388511658, loss=0.106037437915802
test: epoch 111, loss 2.695064067840576, acc=0.550000011920929, loss=2.695064067840576
train: epoch 112, loss 0.11626619100570679, acc=0.9638888835906982, loss=0.11626619100570679
test: epoch 112, loss 2.9533116817474365, acc=0.5444444417953491, loss=2.9533116817474365
train: epoch 113, loss 0.10342799127101898, acc=0.9673888683319092, loss=0.10342799127101898
test: epoch 113, loss 2.400479555130005, acc=0.5611110925674438, loss=2.400479555130005
train: epoch 114, loss 0.09976472705602646, acc=0.9665555357933044, loss=0.09976472705602646
test: epoch 114, loss 2.7073299884796143, acc=0.5555555820465088, loss=2.7073299884796143
train: epoch 115, loss 0.0987151637673378, acc=0.9684444665908813, loss=0.0987151637673378
test: epoch 115, loss 2.8894498348236084, acc=0.5416666865348816, loss=2.8894498348236084
train: epoch 116, loss 0.09853076934814453, acc=0.9669444561004639, loss=0.09853076934814453
test: epoch 116, loss 2.949960708618164, acc=0.5527777671813965, loss=2.949960708618164
train: epoch 117, loss 0.10912290215492249, acc=0.9673333168029785, loss=0.10912290215492249
test: epoch 117, loss 2.435861349105835, acc=0.5472221970558167, loss=2.435861349105835
train: epoch 118, loss 0.10007285326719284, acc=0.9667778015136719, loss=0.10007285326719284
test: epoch 118, loss 3.148348093032837, acc=0.5333333611488342, loss=3.148348093032837
train: epoch 119, loss 0.11263244599103928, acc=0.9660000205039978, loss=0.11263244599103928
test: epoch 119, loss 2.644196033477783, acc=0.5249999761581421, loss=2.644196033477783
train: epoch 120, loss 0.09747806191444397, acc=0.9679999947547913, loss=0.09747806191444397
test: epoch 120, loss 2.660238742828369, acc=0.5777778029441833, loss=2.660238742828369
train: epoch 121, loss 0.10928433388471603, acc=0.9663888812065125, loss=0.10928433388471603
test: epoch 121, loss 2.8463239669799805, acc=0.5361111164093018, loss=2.8463239669799805
train: epoch 122, loss 0.0949636846780777, acc=0.9691110849380493, loss=0.0949636846780777
test: epoch 122, loss 2.6527340412139893, acc=0.5416666865348816, loss=2.6527340412139893
train: epoch 123, loss 0.09571971744298935, acc=0.9687222242355347, loss=0.09571971744298935
test: epoch 123, loss 2.7522430419921875, acc=0.5611110925674438, loss=2.7522430419921875
train: epoch 124, loss 0.09351634234189987, acc=0.9693889021873474, loss=0.09351634234189987
test: epoch 124, loss 2.9402737617492676, acc=0.574999988079071, loss=2.9402737617492676
train: epoch 125, loss 0.11244657635688782, acc=0.9642778038978577, loss=0.11244657635688782
test: epoch 125, loss 2.790088653564453, acc=0.5583333373069763, loss=2.790088653564453
train: epoch 126, loss 0.09310536831617355, acc=0.9700000286102295, loss=0.09310536831617355
test: epoch 126, loss 2.293246269226074, acc=0.5944444537162781, loss=2.293246269226074
train: epoch 127, loss 0.0953732281923294, acc=0.9697222113609314, loss=0.0953732281923294
test: epoch 127, loss 2.5780837535858154, acc=0.5583333373069763, loss=2.5780837535858154
train: epoch 128, loss 0.09449157863855362, acc=0.9692777991294861, loss=0.09449157863855362
test: epoch 128, loss 2.7112226486206055, acc=0.5861111283302307, loss=2.7112226486206055
train: epoch 129, loss 0.0942719429731369, acc=0.9670555591583252, loss=0.0942719429731369
test: epoch 129, loss 2.5999178886413574, acc=0.5972222089767456, loss=2.5999178886413574
train: epoch 130, loss 0.10086727142333984, acc=0.9683333039283752, loss=0.10086727142333984
test: epoch 130, loss 2.347815990447998, acc=0.6138888597488403, loss=2.347815990447998
train: epoch 131, loss 0.09376232326030731, acc=0.9701666831970215, loss=0.09376232326030731
test: epoch 131, loss 2.2965006828308105, acc=0.5805555582046509, loss=2.2965006828308105
train: epoch 132, loss 0.08969492465257645, acc=0.9716110825538635, loss=0.08969492465257645
test: epoch 132, loss 2.990865707397461, acc=0.5416666865348816, loss=2.990865707397461
train: epoch 133, loss 0.09587161988019943, acc=0.9702222347259521, loss=0.09587161988019943
test: epoch 133, loss 2.816157341003418, acc=0.5805555582046509, loss=2.816157341003418
train: epoch 134, loss 0.09516754001379013, acc=0.9693333506584167, loss=0.09516754001379013
test: epoch 134, loss 2.901378870010376, acc=0.6027777791023254, loss=2.901378870010376
train: epoch 135, loss 0.09195929020643234, acc=0.9701666831970215, loss=0.09195929020643234
test: epoch 135, loss 2.6033713817596436, acc=0.5916666388511658, loss=2.6033713817596436
train: epoch 136, loss 0.07673732936382294, acc=0.9743888974189758, loss=0.07673732936382294
test: epoch 136, loss 2.8017284870147705, acc=0.5833333134651184, loss=2.8017284870147705
train: epoch 137, loss 0.08003496378660202, acc=0.9739444255828857, loss=0.08003496378660202
test: epoch 137, loss 3.1206047534942627, acc=0.5638889074325562, loss=3.1206047534942627
train: epoch 138, loss 0.08888830989599228, acc=0.9714444279670715, loss=0.08888830989599228
test: epoch 138, loss 2.4377644062042236, acc=0.574999988079071, loss=2.4377644062042236
train: epoch 139, loss 0.08084211498498917, acc=0.9746666550636292, loss=0.08084211498498917
test: epoch 139, loss 2.281684637069702, acc=0.5833333134651184, loss=2.281684637069702
train: epoch 140, loss 0.08059196919202805, acc=0.9740555286407471, loss=0.08059196919202805
test: epoch 140, loss 2.55027437210083, acc=0.6027777791023254, loss=2.55027437210083
train: epoch 141, loss 0.07540540397167206, acc=0.9773333072662354, loss=0.07540540397167206
test: epoch 141, loss 2.4675028324127197, acc=0.5777778029441833, loss=2.4675028324127197
train: epoch 142, loss 0.07985831797122955, acc=0.9742222428321838, loss=0.07985831797122955
test: epoch 142, loss 2.6728415489196777, acc=0.5861111283302307, loss=2.6728415489196777
train: epoch 143, loss 0.07856886833906174, acc=0.977055549621582, loss=0.07856886833906174
test: epoch 143, loss 2.865586996078491, acc=0.5611110925674438, loss=2.865586996078491
train: epoch 144, loss 0.08037781715393066, acc=0.9748333096504211, loss=0.08037781715393066
test: epoch 144, loss 2.5721371173858643, acc=0.5694444179534912, loss=2.5721371173858643
train: epoch 145, loss 0.08264908194541931, acc=0.9738888740539551, loss=0.08264908194541931
test: epoch 145, loss 2.762317419052124, acc=0.5833333134651184, loss=2.762317419052124
train: epoch 146, loss 0.07863938808441162, acc=0.9745000004768372, loss=0.07863938808441162
test: epoch 146, loss 2.4495415687561035, acc=0.5972222089767456, loss=2.4495415687561035
train: epoch 147, loss 0.07968466728925705, acc=0.9754444360733032, loss=0.07968466728925705
test: epoch 147, loss 2.2704460620880127, acc=0.5972222089767456, loss=2.2704460620880127
train: epoch 148, loss 0.07132910937070847, acc=0.97688889503479, loss=0.07132910937070847
test: epoch 148, loss 2.7850124835968018, acc=0.6000000238418579, loss=2.7850124835968018
train: epoch 149, loss 0.07687068730592728, acc=0.9760555624961853, loss=0.07687068730592728
test: epoch 149, loss 2.676046371459961, acc=0.5944444537162781, loss=2.676046371459961
train: epoch 150, loss 0.07138270884752274, acc=0.9774444699287415, loss=0.07138270884752274
test: epoch 150, loss 3.072998046875, acc=0.574999988079071, loss=3.072998046875
