# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=1", "--temp_decay=0.99", "--one_hot=1", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=281410216, receiver_embed_dim=128, save_run=0, temp_decay=0.99, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=281410216, receiver_embed_dim=128, save_run=False, temp_decay=0.99, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.0329275131225586, acc=0.0741666629910469, loss=3.0329275131225586
test: epoch 1, loss 2.7443294525146484, acc=0.1111111119389534, loss=2.7443294525146484
train: epoch 2, loss 2.1766414642333984, acc=0.1817222237586975, loss=2.1766414642333984
test: epoch 2, loss 2.334257125854492, acc=0.15000000596046448, loss=2.334257125854492
train: epoch 3, loss 1.6805906295776367, acc=0.3371666669845581, loss=1.6805906295776367
test: epoch 3, loss 1.7894002199172974, acc=0.25555557012557983, loss=1.7894002199172974
train: epoch 4, loss 1.3735523223876953, acc=0.4221666753292084, loss=1.3735523223876953
test: epoch 4, loss 1.864835262298584, acc=0.2666666805744171, loss=1.864835262298584
train: epoch 5, loss 1.204599142074585, acc=0.47527778148651123, loss=1.204599142074585
test: epoch 5, loss 1.7821282148361206, acc=0.3166666626930237, loss=1.7821282148361206
train: epoch 6, loss 1.0897752046585083, acc=0.5176666378974915, loss=1.0897752046585083
test: epoch 6, loss 1.529380202293396, acc=0.3444444537162781, loss=1.529380202293396
train: epoch 7, loss 0.9886193871498108, acc=0.5558333396911621, loss=0.9886193871498108
test: epoch 7, loss 1.5766615867614746, acc=0.36666667461395264, loss=1.5766615867614746
train: epoch 8, loss 0.930547297000885, acc=0.5832777619361877, loss=0.930547297000885
test: epoch 8, loss 1.7257652282714844, acc=0.3472222089767456, loss=1.7257652282714844
train: epoch 9, loss 0.8927654027938843, acc=0.5968888998031616, loss=0.8927654027938843
test: epoch 9, loss 1.7309156656265259, acc=0.3333333432674408, loss=1.7309156656265259
train: epoch 10, loss 0.8506784439086914, acc=0.6152222156524658, loss=0.8506784439086914
test: epoch 10, loss 1.6267069578170776, acc=0.3861111104488373, loss=1.6267069578170776
train: epoch 11, loss 0.8433141112327576, acc=0.621833324432373, loss=0.8433141112327576
test: epoch 11, loss 1.6506106853485107, acc=0.3583333194255829, loss=1.6506106853485107
train: epoch 12, loss 0.8149787187576294, acc=0.629111111164093, loss=0.8149787187576294
test: epoch 12, loss 1.7186801433563232, acc=0.35555556416511536, loss=1.7186801433563232
train: epoch 13, loss 0.8007943630218506, acc=0.6400555372238159, loss=0.8007943630218506
test: epoch 13, loss 1.7010866403579712, acc=0.3888888955116272, loss=1.7010866403579712
train: epoch 14, loss 0.8367680907249451, acc=0.6239444613456726, loss=0.8367680907249451
test: epoch 14, loss 1.5620880126953125, acc=0.3777777850627899, loss=1.5620880126953125
train: epoch 15, loss 0.79875248670578, acc=0.6432222127914429, loss=0.79875248670578
test: epoch 15, loss 1.7249163389205933, acc=0.3777777850627899, loss=1.7249163389205933
train: epoch 16, loss 0.7998021245002747, acc=0.6412777900695801, loss=0.7998021245002747
test: epoch 16, loss 1.5662635564804077, acc=0.4027777910232544, loss=1.5662635564804077
train: epoch 17, loss 0.781701922416687, acc=0.644777774810791, loss=0.781701922416687
test: epoch 17, loss 1.5515086650848389, acc=0.42222222685813904, loss=1.5515086650848389
train: epoch 18, loss 0.7769946455955505, acc=0.6495000123977661, loss=0.7769946455955505
test: epoch 18, loss 1.480155110359192, acc=0.4333333373069763, loss=1.480155110359192
train: epoch 19, loss 0.7814766764640808, acc=0.6492778062820435, loss=0.7814766764640808
test: epoch 19, loss 1.5885652303695679, acc=0.4305555522441864, loss=1.5885652303695679
train: epoch 20, loss 0.774979829788208, acc=0.6545000076293945, loss=0.774979829788208
test: epoch 20, loss 1.5746653079986572, acc=0.43888887763023376, loss=1.5746653079986572
train: epoch 21, loss 0.7796230316162109, acc=0.648888885974884, loss=0.7796230316162109
test: epoch 21, loss 1.704250454902649, acc=0.4166666567325592, loss=1.704250454902649
train: epoch 22, loss 0.77284175157547, acc=0.6520000100135803, loss=0.77284175157547
test: epoch 22, loss 1.4585148096084595, acc=0.43888887763023376, loss=1.4585148096084595
train: epoch 23, loss 0.7475095987319946, acc=0.6590555310249329, loss=0.7475095987319946
test: epoch 23, loss 1.5120002031326294, acc=0.42500001192092896, loss=1.5120002031326294
train: epoch 24, loss 0.7386120557785034, acc=0.6615555286407471, loss=0.7386120557785034
test: epoch 24, loss 1.5966365337371826, acc=0.4472222328186035, loss=1.5966365337371826
train: epoch 25, loss 0.7587211728096008, acc=0.6571111083030701, loss=0.7587211728096008
test: epoch 25, loss 1.4896914958953857, acc=0.4583333432674408, loss=1.4896914958953857
train: epoch 26, loss 0.7716248631477356, acc=0.6496666669845581, loss=0.7716248631477356
test: epoch 26, loss 1.5554189682006836, acc=0.4472222328186035, loss=1.5554189682006836
train: epoch 27, loss 0.7696421146392822, acc=0.651888906955719, loss=0.7696421146392822
test: epoch 27, loss 1.5151857137680054, acc=0.4472222328186035, loss=1.5151857137680054
train: epoch 28, loss 0.7676439881324768, acc=0.6524999737739563, loss=0.7676439881324768
test: epoch 28, loss 1.5068141222000122, acc=0.4444444477558136, loss=1.5068141222000122
train: epoch 29, loss 0.7580342888832092, acc=0.6528333425521851, loss=0.7580342888832092
test: epoch 29, loss 1.6492630243301392, acc=0.4472222328186035, loss=1.6492630243301392
train: epoch 30, loss 0.7523357272148132, acc=0.6566110849380493, loss=0.7523357272148132
test: epoch 30, loss 1.5198471546173096, acc=0.4472222328186035, loss=1.5198471546173096
train: epoch 31, loss 0.7420305013656616, acc=0.6620000004768372, loss=0.7420305013656616
test: epoch 31, loss 1.5332123041152954, acc=0.4472222328186035, loss=1.5332123041152954
train: epoch 32, loss 0.7348852753639221, acc=0.6613888740539551, loss=0.7348852753639221
test: epoch 32, loss 1.6241273880004883, acc=0.4444444477558136, loss=1.6241273880004883
train: epoch 33, loss 0.7537188529968262, acc=0.6548888683319092, loss=0.7537188529968262
test: epoch 33, loss 1.5015686750411987, acc=0.4416666626930237, loss=1.5015686750411987
train: epoch 34, loss 0.7277990579605103, acc=0.6592222452163696, loss=0.7277990579605103
test: epoch 34, loss 1.4909694194793701, acc=0.4472222328186035, loss=1.4909694194793701
train: epoch 35, loss 0.7147757411003113, acc=0.6643333435058594, loss=0.7147757411003113
test: epoch 35, loss 1.4804661273956299, acc=0.4472222328186035, loss=1.4804661273956299
train: epoch 36, loss 0.72547447681427, acc=0.6657222509384155, loss=0.72547447681427
test: epoch 36, loss 1.5048543214797974, acc=0.4472222328186035, loss=1.5048543214797974
train: epoch 37, loss 0.7282376289367676, acc=0.663611114025116, loss=0.7282376289367676
test: epoch 37, loss 1.535697102546692, acc=0.4472222328186035, loss=1.535697102546692
train: epoch 38, loss 0.7065811157226562, acc=0.6744444370269775, loss=0.7065811157226562
test: epoch 38, loss 1.6102787256240845, acc=0.4472222328186035, loss=1.6102787256240845
train: epoch 39, loss 0.7155048847198486, acc=0.6661666631698608, loss=0.7155048847198486
test: epoch 39, loss 1.5644372701644897, acc=0.4416666626930237, loss=1.5644372701644897
train: epoch 40, loss 0.7537500858306885, acc=0.6608889102935791, loss=0.7537500858306885
test: epoch 40, loss 1.487423062324524, acc=0.4472222328186035, loss=1.487423062324524
train: epoch 41, loss 0.719433605670929, acc=0.6653333306312561, loss=0.719433605670929
test: epoch 41, loss 1.713495135307312, acc=0.4472222328186035, loss=1.713495135307312
train: epoch 42, loss 0.7151221036911011, acc=0.6692777872085571, loss=0.7151221036911011
test: epoch 42, loss 1.5787208080291748, acc=0.4472222328186035, loss=1.5787208080291748
train: epoch 43, loss 0.7357824444770813, acc=0.6661666631698608, loss=0.7357824444770813
test: epoch 43, loss 1.5972785949707031, acc=0.43611112236976624, loss=1.5972785949707031
train: epoch 44, loss 0.6847694516181946, acc=0.680055558681488, loss=0.6847694516181946
test: epoch 44, loss 1.4886209964752197, acc=0.4444444477558136, loss=1.4886209964752197
train: epoch 45, loss 0.698328971862793, acc=0.6738888621330261, loss=0.698328971862793
test: epoch 45, loss 1.5417211055755615, acc=0.4555555582046509, loss=1.5417211055755615
train: epoch 46, loss 0.7012341618537903, acc=0.6713333129882812, loss=0.7012341618537903
test: epoch 46, loss 1.4579435586929321, acc=0.4555555582046509, loss=1.4579435586929321
train: epoch 47, loss 0.7035486698150635, acc=0.676111102104187, loss=0.7035486698150635
test: epoch 47, loss 1.5782382488250732, acc=0.45277777314186096, loss=1.5782382488250732
train: epoch 48, loss 0.6769521236419678, acc=0.6828888654708862, loss=0.6769521236419678
test: epoch 48, loss 1.6866167783737183, acc=0.4555555582046509, loss=1.6866167783737183
train: epoch 49, loss 0.6883766651153564, acc=0.679111123085022, loss=0.6883766651153564
test: epoch 49, loss 1.6945401430130005, acc=0.4555555582046509, loss=1.6945401430130005
train: epoch 50, loss 0.6773668527603149, acc=0.6901111006736755, loss=0.6773668527603149
test: epoch 50, loss 1.4275518655776978, acc=0.4583333432674408, loss=1.4275518655776978
train: epoch 51, loss 0.6725466847419739, acc=0.691944420337677, loss=0.6725466847419739
test: epoch 51, loss 1.5050181150436401, acc=0.45277777314186096, loss=1.5050181150436401
train: epoch 52, loss 0.6892620325088501, acc=0.6899444460868835, loss=0.6892620325088501
test: epoch 52, loss 1.60134756565094, acc=0.44999998807907104, loss=1.60134756565094
train: epoch 53, loss 0.6721848845481873, acc=0.6904444694519043, loss=0.6721848845481873
test: epoch 53, loss 1.755284309387207, acc=0.4583333432674408, loss=1.755284309387207
train: epoch 54, loss 0.671774685382843, acc=0.6896111369132996, loss=0.671774685382843
test: epoch 54, loss 1.462257981300354, acc=0.4583333432674408, loss=1.462257981300354
train: epoch 55, loss 0.6624165773391724, acc=0.69477778673172, loss=0.6624165773391724
test: epoch 55, loss 1.4263569116592407, acc=0.4583333432674408, loss=1.4263569116592407
train: epoch 56, loss 0.6806507706642151, acc=0.6825555562973022, loss=0.6806507706642151
test: epoch 56, loss 1.6833361387252808, acc=0.4583333432674408, loss=1.6833361387252808
train: epoch 57, loss 0.6568496823310852, acc=0.6930555701255798, loss=0.6568496823310852
test: epoch 57, loss 1.5340973138809204, acc=0.44999998807907104, loss=1.5340973138809204
train: epoch 58, loss 0.6490230560302734, acc=0.694611132144928, loss=0.6490230560302734
test: epoch 58, loss 1.5018366575241089, acc=0.4583333432674408, loss=1.5018366575241089
train: epoch 59, loss 0.6556448340415955, acc=0.694944441318512, loss=0.6556448340415955
test: epoch 59, loss 1.654240608215332, acc=0.4583333432674408, loss=1.654240608215332
train: epoch 60, loss 0.66190505027771, acc=0.6921111345291138, loss=0.66190505027771
test: epoch 60, loss 1.5957856178283691, acc=0.4583333432674408, loss=1.5957856178283691
train: epoch 61, loss 0.668465793132782, acc=0.6917222142219543, loss=0.668465793132782
test: epoch 61, loss 1.6195685863494873, acc=0.45277777314186096, loss=1.6195685863494873
train: epoch 62, loss 0.6530513763427734, acc=0.7018888592720032, loss=0.6530513763427734
test: epoch 62, loss 1.5691261291503906, acc=0.4722222089767456, loss=1.5691261291503906
train: epoch 63, loss 0.6470666527748108, acc=0.7034444212913513, loss=0.6470666527748108
test: epoch 63, loss 1.5700677633285522, acc=0.4722222089767456, loss=1.5700677633285522
train: epoch 64, loss 0.6323461532592773, acc=0.7089999914169312, loss=0.6323461532592773
test: epoch 64, loss 1.4356749057769775, acc=0.4888888895511627, loss=1.4356749057769775
train: epoch 65, loss 0.6129787564277649, acc=0.7187777757644653, loss=0.6129787564277649
test: epoch 65, loss 1.4478634595870972, acc=0.5055555701255798, loss=1.4478634595870972
train: epoch 66, loss 0.6048649549484253, acc=0.7204999923706055, loss=0.6048649549484253
test: epoch 66, loss 1.5094387531280518, acc=0.5055555701255798, loss=1.5094387531280518
train: epoch 67, loss 0.61287522315979, acc=0.7170555591583252, loss=0.61287522315979
test: epoch 67, loss 1.336363673210144, acc=0.5027777552604675, loss=1.336363673210144
train: epoch 68, loss 0.6099025011062622, acc=0.714388906955719, loss=0.6099025011062622
test: epoch 68, loss 1.5623769760131836, acc=0.4972222149372101, loss=1.5623769760131836
train: epoch 69, loss 0.635469377040863, acc=0.7094444632530212, loss=0.635469377040863
test: epoch 69, loss 1.5241657495498657, acc=0.5027777552604675, loss=1.5241657495498657
train: epoch 70, loss 0.6130794882774353, acc=0.715666651725769, loss=0.6130794882774353
test: epoch 70, loss 1.5457526445388794, acc=0.5055555701255798, loss=1.5457526445388794
train: epoch 71, loss 0.6010865569114685, acc=0.7177222371101379, loss=0.6010865569114685
test: epoch 71, loss 1.3360017538070679, acc=0.5027777552604675, loss=1.3360017538070679
train: epoch 72, loss 0.5990608334541321, acc=0.7176666855812073, loss=0.5990608334541321
test: epoch 72, loss 1.498645544052124, acc=0.5055555701255798, loss=1.498645544052124
train: epoch 73, loss 0.6160120964050293, acc=0.7166110873222351, loss=0.6160120964050293
test: epoch 73, loss 1.4310650825500488, acc=0.49166667461395264, loss=1.4310650825500488
train: epoch 74, loss 0.6122816801071167, acc=0.7120000123977661, loss=0.6122816801071167
test: epoch 74, loss 1.4885221719741821, acc=0.5, loss=1.4885221719741821
train: epoch 75, loss 0.6014873385429382, acc=0.7208333611488342, loss=0.6014873385429382
test: epoch 75, loss 1.4786198139190674, acc=0.5027777552604675, loss=1.4786198139190674
train: epoch 76, loss 0.6136217713356018, acc=0.7208889126777649, loss=0.6136217713356018
test: epoch 76, loss 1.5331095457077026, acc=0.5, loss=1.5331095457077026
train: epoch 77, loss 0.6133428812026978, acc=0.7210555672645569, loss=0.6133428812026978
test: epoch 77, loss 1.2687782049179077, acc=0.5083333253860474, loss=1.2687782049179077
train: epoch 78, loss 0.5778278112411499, acc=0.7307778000831604, loss=0.5778278112411499
test: epoch 78, loss 1.6789413690567017, acc=0.5111111402511597, loss=1.6789413690567017
train: epoch 79, loss 0.5829359292984009, acc=0.7328333258628845, loss=0.5829359292984009
test: epoch 79, loss 1.4122943878173828, acc=0.5166666507720947, loss=1.4122943878173828
train: epoch 80, loss 0.5833262801170349, acc=0.7358333468437195, loss=0.5833262801170349
test: epoch 80, loss 1.3588738441467285, acc=0.519444465637207, loss=1.3588738441467285
train: epoch 81, loss 0.5830273628234863, acc=0.7383888959884644, loss=0.5830273628234863
test: epoch 81, loss 1.5055187940597534, acc=0.5416666865348816, loss=1.5055187940597534
train: epoch 82, loss 0.5710535645484924, acc=0.7410555481910706, loss=0.5710535645484924
test: epoch 82, loss 1.4262797832489014, acc=0.5472221970558167, loss=1.4262797832489014
train: epoch 83, loss 0.5686410069465637, acc=0.7433333396911621, loss=0.5686410069465637
test: epoch 83, loss 1.3479522466659546, acc=0.5527777671813965, loss=1.3479522466659546
train: epoch 84, loss 0.5404706001281738, acc=0.7531111240386963, loss=0.5404706001281738
test: epoch 84, loss 1.494019627571106, acc=0.5583333373069763, loss=1.494019627571106
train: epoch 85, loss 0.5669602155685425, acc=0.7472777962684631, loss=0.5669602155685425
test: epoch 85, loss 1.234561562538147, acc=0.5555555820465088, loss=1.234561562538147
train: epoch 86, loss 0.5570537447929382, acc=0.7464444637298584, loss=0.5570537447929382
test: epoch 86, loss 1.3722554445266724, acc=0.5555555820465088, loss=1.3722554445266724
train: epoch 87, loss 0.5510846376419067, acc=0.7487778067588806, loss=0.5510846376419067
test: epoch 87, loss 1.2220829725265503, acc=0.5527777671813965, loss=1.2220829725265503
train: epoch 88, loss 0.5375795960426331, acc=0.754111111164093, loss=0.5375795960426331
test: epoch 88, loss 1.2883039712905884, acc=0.5722222328186035, loss=1.2883039712905884
train: epoch 89, loss 0.5398194193840027, acc=0.762333333492279, loss=0.5398194193840027
test: epoch 89, loss 1.2628545761108398, acc=0.5805555582046509, loss=1.2628545761108398
train: epoch 90, loss 0.53411465883255, acc=0.7716666460037231, loss=0.53411465883255
test: epoch 90, loss 1.2402619123458862, acc=0.6194444298744202, loss=1.2402619123458862
train: epoch 91, loss 0.5074641108512878, acc=0.7817777991294861, loss=0.5074641108512878
test: epoch 91, loss 1.0763012170791626, acc=0.6222222447395325, loss=1.0763012170791626
train: epoch 92, loss 0.48623502254486084, acc=0.7914999723434448, loss=0.48623502254486084
test: epoch 92, loss 1.1123600006103516, acc=0.6361111402511597, loss=1.1123600006103516
train: epoch 93, loss 0.47897806763648987, acc=0.7945555448532104, loss=0.47897806763648987
test: epoch 93, loss 0.962501049041748, acc=0.6611111164093018, loss=0.962501049041748
train: epoch 94, loss 0.4527909457683563, acc=0.8040555715560913, loss=0.4527909457683563
test: epoch 94, loss 0.8835234045982361, acc=0.6611111164093018, loss=0.8835234045982361
train: epoch 95, loss 0.44874104857444763, acc=0.8053333163261414, loss=0.44874104857444763
test: epoch 95, loss 0.984176516532898, acc=0.6611111164093018, loss=0.984176516532898
train: epoch 96, loss 0.46691471338272095, acc=0.7956666946411133, loss=0.46691471338272095
test: epoch 96, loss 0.9017446041107178, acc=0.6611111164093018, loss=0.9017446041107178
train: epoch 97, loss 0.46038737893104553, acc=0.7961666584014893, loss=0.46038737893104553
test: epoch 97, loss 0.9825926423072815, acc=0.6638888716697693, loss=0.9825926423072815
train: epoch 98, loss 0.44186100363731384, acc=0.8017777800559998, loss=0.44186100363731384
test: epoch 98, loss 0.9864451885223389, acc=0.6638888716697693, loss=0.9864451885223389
train: epoch 99, loss 0.45702341198921204, acc=0.8025555610656738, loss=0.45702341198921204
test: epoch 99, loss 0.9363335967063904, acc=0.6611111164093018, loss=0.9363335967063904
train: epoch 100, loss 0.46218711137771606, acc=0.8017222285270691, loss=0.46218711137771606
test: epoch 100, loss 0.9681673049926758, acc=0.6611111164093018, loss=0.9681673049926758
train: epoch 101, loss 0.4478793740272522, acc=0.8037222027778625, loss=0.4478793740272522
test: epoch 101, loss 0.880520761013031, acc=0.6555555462837219, loss=0.880520761013031
train: epoch 102, loss 0.4553978443145752, acc=0.8024444580078125, loss=0.4553978443145752
test: epoch 102, loss 0.8885439038276672, acc=0.6638888716697693, loss=0.8885439038276672
train: epoch 103, loss 0.46858277916908264, acc=0.7954444289207458, loss=0.46858277916908264
test: epoch 103, loss 0.7668133974075317, acc=0.6972222328186035, loss=0.7668133974075317
train: epoch 104, loss 0.4393559992313385, acc=0.8071666955947876, loss=0.4393559992313385
test: epoch 104, loss 0.8391929268836975, acc=0.6972222328186035, loss=0.8391929268836975
train: epoch 105, loss 0.4292234182357788, acc=0.8135555386543274, loss=0.4292234182357788
test: epoch 105, loss 0.6161553263664246, acc=0.7388888597488403, loss=0.6161553263664246
train: epoch 106, loss 0.4052017629146576, acc=0.8277222514152527, loss=0.4052017629146576
test: epoch 106, loss 0.6773079037666321, acc=0.7444444298744202, loss=0.6773079037666321
train: epoch 107, loss 0.3934301733970642, acc=0.8327222466468811, loss=0.3934301733970642
test: epoch 107, loss 0.6771267652511597, acc=0.7583333253860474, loss=0.6771267652511597
train: epoch 108, loss 0.3970833420753479, acc=0.8330555558204651, loss=0.3970833420753479
test: epoch 108, loss 0.5798913240432739, acc=0.7861111164093018, loss=0.5798913240432739
train: epoch 109, loss 0.3566584885120392, acc=0.8482221961021423, loss=0.3566584885120392
test: epoch 109, loss 0.5917661786079407, acc=0.7916666865348816, loss=0.5917661786079407
train: epoch 110, loss 0.3294227719306946, acc=0.8519999980926514, loss=0.3294227719306946
test: epoch 110, loss 0.5679577589035034, acc=0.7944444417953491, loss=0.5679577589035034
train: epoch 111, loss 0.3375227153301239, acc=0.850777804851532, loss=0.3375227153301239
test: epoch 111, loss 0.4733584225177765, acc=0.7805555462837219, loss=0.4733584225177765
train: epoch 112, loss 0.35018932819366455, acc=0.8478888869285583, loss=0.35018932819366455
test: epoch 112, loss 0.5440833568572998, acc=0.7972221970558167, loss=0.5440833568572998
train: epoch 113, loss 0.33713194727897644, acc=0.8497222065925598, loss=0.33713194727897644
test: epoch 113, loss 0.5090952515602112, acc=0.8111110925674438, loss=0.5090952515602112
train: epoch 114, loss 0.3456686735153198, acc=0.8464444279670715, loss=0.3456686735153198
test: epoch 114, loss 0.5679019689559937, acc=0.7833333611488342, loss=0.5679019689559937
train: epoch 115, loss 0.3571648597717285, acc=0.8370555639266968, loss=0.3571648597717285
test: epoch 115, loss 0.5435389876365662, acc=0.7805555462837219, loss=0.5435389876365662
train: epoch 116, loss 0.3614296019077301, acc=0.8344444632530212, loss=0.3614296019077301
test: epoch 116, loss 0.5956663489341736, acc=0.7777777910232544, loss=0.5956663489341736
train: epoch 117, loss 0.35700535774230957, acc=0.8407222032546997, loss=0.35700535774230957
test: epoch 117, loss 0.6635340452194214, acc=0.7805555462837219, loss=0.6635340452194214
train: epoch 118, loss 0.3467535078525543, acc=0.8376111388206482, loss=0.3467535078525543
test: epoch 118, loss 0.608808159828186, acc=0.7805555462837219, loss=0.608808159828186
train: epoch 119, loss 0.35098397731781006, acc=0.8348888754844666, loss=0.35098397731781006
test: epoch 119, loss 0.578214168548584, acc=0.7805555462837219, loss=0.578214168548584
train: epoch 120, loss 0.35704976320266724, acc=0.8345000147819519, loss=0.35704976320266724
test: epoch 120, loss 0.5775933861732483, acc=0.7805555462837219, loss=0.5775933861732483
train: epoch 121, loss 0.37069109082221985, acc=0.8353333473205566, loss=0.37069109082221985
test: epoch 121, loss 0.6227021813392639, acc=0.7777777910232544, loss=0.6227021813392639
train: epoch 122, loss 0.35041922330856323, acc=0.8355000019073486, loss=0.35041922330856323
test: epoch 122, loss 0.5726568698883057, acc=0.7805555462837219, loss=0.5726568698883057
train: epoch 123, loss 0.34592023491859436, acc=0.8373888731002808, loss=0.34592023491859436
test: epoch 123, loss 0.5937240719795227, acc=0.7861111164093018, loss=0.5937240719795227
train: epoch 124, loss 0.3408769965171814, acc=0.8343889117240906, loss=0.3408769965171814
test: epoch 124, loss 0.6479451060295105, acc=0.7861111164093018, loss=0.6479451060295105
train: epoch 125, loss 0.34347134828567505, acc=0.8446666598320007, loss=0.34347134828567505
test: epoch 125, loss 0.5951688885688782, acc=0.7944444417953491, loss=0.5951688885688782
train: epoch 126, loss 0.34019553661346436, acc=0.8486666679382324, loss=0.34019553661346436
test: epoch 126, loss 0.5637074708938599, acc=0.8027777671813965, loss=0.5637074708938599
train: epoch 127, loss 0.31893476843833923, acc=0.8532222509384155, loss=0.31893476843833923
test: epoch 127, loss 0.4779438078403473, acc=0.8055555820465088, loss=0.4779438078403473
train: epoch 128, loss 0.3314844071865082, acc=0.8534444570541382, loss=0.3314844071865082
test: epoch 128, loss 0.3610987961292267, acc=0.8388888835906982, loss=0.3610987961292267
train: epoch 129, loss 0.3114369511604309, acc=0.8572777509689331, loss=0.3114369511604309
test: epoch 129, loss 0.34849557280540466, acc=0.8472222089767456, loss=0.34849557280540466
train: epoch 130, loss 0.30319252610206604, acc=0.8592777848243713, loss=0.30319252610206604
test: epoch 130, loss 0.31802669167518616, acc=0.8500000238418579, loss=0.31802669167518616
train: epoch 131, loss 0.30828016996383667, acc=0.8586666584014893, loss=0.30828016996383667
test: epoch 131, loss 0.35550329089164734, acc=0.8472222089767456, loss=0.35550329089164734
train: epoch 132, loss 0.3041563034057617, acc=0.8590555787086487, loss=0.3041563034057617
test: epoch 132, loss 0.34166091680526733, acc=0.8500000238418579, loss=0.34166091680526733
train: epoch 133, loss 0.30577531456947327, acc=0.859333336353302, loss=0.30577531456947327
test: epoch 133, loss 0.3263300657272339, acc=0.8500000238418579, loss=0.3263300657272339
train: epoch 134, loss 0.3141700029373169, acc=0.8578888773918152, loss=0.3141700029373169
test: epoch 134, loss 0.3457062840461731, acc=0.8500000238418579, loss=0.3457062840461731
train: epoch 135, loss 0.30144408345222473, acc=0.8588888645172119, loss=0.30144408345222473
test: epoch 135, loss 0.3601391017436981, acc=0.8500000238418579, loss=0.3601391017436981
train: epoch 136, loss 0.3054923415184021, acc=0.8583333492279053, loss=0.3054923415184021
test: epoch 136, loss 0.33115556836128235, acc=0.8500000238418579, loss=0.33115556836128235
train: epoch 137, loss 0.30005693435668945, acc=0.859499990940094, loss=0.30005693435668945
test: epoch 137, loss 0.3515019714832306, acc=0.8500000238418579, loss=0.3515019714832306
train: epoch 138, loss 0.30370625853538513, acc=0.8592222332954407, loss=0.30370625853538513
test: epoch 138, loss 0.3534461259841919, acc=0.8472222089767456, loss=0.3534461259841919
train: epoch 139, loss 0.31579330563545227, acc=0.8566111326217651, loss=0.31579330563545227
test: epoch 139, loss 0.35425934195518494, acc=0.8472222089767456, loss=0.35425934195518494
train: epoch 140, loss 0.32611072063446045, acc=0.8551666736602783, loss=0.32611072063446045
test: epoch 140, loss 0.33252033591270447, acc=0.8472222089767456, loss=0.33252033591270447
train: epoch 141, loss 0.31244751811027527, acc=0.8566111326217651, loss=0.31244751811027527
test: epoch 141, loss 0.3475662171840668, acc=0.8472222089767456, loss=0.3475662171840668
train: epoch 142, loss 0.3138805031776428, acc=0.8560555577278137, loss=0.3138805031776428
test: epoch 142, loss 0.35854730010032654, acc=0.8444444537162781, loss=0.35854730010032654
train: epoch 143, loss 0.3148323595523834, acc=0.8550000190734863, loss=0.3148323595523834
test: epoch 143, loss 0.3405466079711914, acc=0.8472222089767456, loss=0.3405466079711914
train: epoch 144, loss 0.3092164099216461, acc=0.8569444417953491, loss=0.3092164099216461
test: epoch 144, loss 0.3418847322463989, acc=0.8472222089767456, loss=0.3418847322463989
train: epoch 145, loss 0.30434921383857727, acc=0.8577222228050232, loss=0.30434921383857727
test: epoch 145, loss 0.3173011541366577, acc=0.8500000238418579, loss=0.3173011541366577
train: epoch 146, loss 0.2989952266216278, acc=0.8597221970558167, loss=0.2989952266216278
test: epoch 146, loss 0.33194947242736816, acc=0.8500000238418579, loss=0.33194947242736816
train: epoch 147, loss 0.29867249727249146, acc=0.8601666688919067, loss=0.29867249727249146
test: epoch 147, loss 0.3658143877983093, acc=0.8472222089767456, loss=0.3658143877983093
train: epoch 148, loss 0.3032546937465668, acc=0.8588888645172119, loss=0.3032546937465668
test: epoch 148, loss 0.3441418707370758, acc=0.8500000238418579, loss=0.3441418707370758
train: epoch 149, loss 0.3107481896877289, acc=0.8575000166893005, loss=0.3107481896877289
test: epoch 149, loss 0.3448786735534668, acc=0.8472222089767456, loss=0.3448786735534668
train: epoch 150, loss 0.3297809958457947, acc=0.8527222275733948, loss=0.3297809958457947
test: epoch 150, loss 0.3575384318828583, acc=0.8416666388511658, loss=0.3575384318828583
