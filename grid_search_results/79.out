# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=0", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=993773104, receiver_embed_dim=64, save_run=0, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=993773104, receiver_embed_dim=64, save_run=False, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.640738010406494, acc=0.12733332812786102, loss=2.640738010406494
test: epoch 1, loss 4.442363262176514, acc=0.05277777835726738, loss=4.442363262176514
train: epoch 2, loss 2.075836181640625, acc=0.2298888862133026, loss=2.075836181640625
test: epoch 2, loss 4.489181041717529, acc=0.07777778059244156, loss=4.489181041717529
train: epoch 3, loss 1.841194987297058, acc=0.2913333475589752, loss=1.841194987297058
test: epoch 3, loss 4.006856441497803, acc=0.1111111119389534, loss=4.006856441497803
train: epoch 4, loss 1.6894118785858154, acc=0.3374444544315338, loss=1.6894118785858154
test: epoch 4, loss 4.117437839508057, acc=0.11944444477558136, loss=4.117437839508057
train: epoch 5, loss 1.5769098997116089, acc=0.36861109733581543, loss=1.5769098997116089
test: epoch 5, loss 3.9229302406311035, acc=0.11666666716337204, loss=3.9229302406311035
train: epoch 6, loss 1.517066478729248, acc=0.3936111032962799, loss=1.517066478729248
test: epoch 6, loss 3.3102128505706787, acc=0.1388888955116272, loss=3.3102128505706787
train: epoch 7, loss 1.4653913974761963, acc=0.4131111204624176, loss=1.4653913974761963
test: epoch 7, loss 3.473956346511841, acc=0.12777778506278992, loss=3.473956346511841
train: epoch 8, loss 1.408504843711853, acc=0.43650001287460327, loss=1.408504843711853
test: epoch 8, loss 3.5414681434631348, acc=0.18611110746860504, loss=3.5414681434631348
train: epoch 9, loss 1.3677269220352173, acc=0.45911112427711487, loss=1.3677269220352173
test: epoch 9, loss 3.538762092590332, acc=0.125, loss=3.538762092590332
train: epoch 10, loss 1.3214802742004395, acc=0.4721111059188843, loss=1.3214802742004395
test: epoch 10, loss 2.976522445678711, acc=0.1666666716337204, loss=2.976522445678711
train: epoch 11, loss 1.283883810043335, acc=0.49061110615730286, loss=1.283883810043335
test: epoch 11, loss 2.8884875774383545, acc=0.1388888955116272, loss=2.8884875774383545
train: epoch 12, loss 1.2404321432113647, acc=0.5084999799728394, loss=1.2404321432113647
test: epoch 12, loss 3.0687601566314697, acc=0.1527777761220932, loss=3.0687601566314697
train: epoch 13, loss 1.2231968641281128, acc=0.5210555791854858, loss=1.2231968641281128
test: epoch 13, loss 2.5801055431365967, acc=0.125, loss=2.5801055431365967
train: epoch 14, loss 1.195369839668274, acc=0.5325555801391602, loss=1.195369839668274
test: epoch 14, loss 2.8420722484588623, acc=0.1666666716337204, loss=2.8420722484588623
train: epoch 15, loss 1.1706877946853638, acc=0.5482777953147888, loss=1.1706877946853638
test: epoch 15, loss 2.546163320541382, acc=0.16388888657093048, loss=2.546163320541382
train: epoch 16, loss 1.1302307844161987, acc=0.5528333187103271, loss=1.1302307844161987
test: epoch 16, loss 2.6354072093963623, acc=0.21111111342906952, loss=2.6354072093963623
train: epoch 17, loss 1.1355915069580078, acc=0.5602777600288391, loss=1.1355915069580078
test: epoch 17, loss 2.774245023727417, acc=0.18333333730697632, loss=2.774245023727417
train: epoch 18, loss 1.1189284324645996, acc=0.5577777624130249, loss=1.1189284324645996
test: epoch 18, loss 2.3103575706481934, acc=0.20555555820465088, loss=2.3103575706481934
train: epoch 19, loss 1.0896605253219604, acc=0.5722777843475342, loss=1.0896605253219604
test: epoch 19, loss 2.8064181804656982, acc=0.17499999701976776, loss=2.8064181804656982
train: epoch 20, loss 1.0695699453353882, acc=0.5793333053588867, loss=1.0695699453353882
test: epoch 20, loss 2.6797828674316406, acc=0.14722222089767456, loss=2.6797828674316406
train: epoch 21, loss 1.0537574291229248, acc=0.5882222056388855, loss=1.0537574291229248
test: epoch 21, loss 2.8103346824645996, acc=0.15555556118488312, loss=2.8103346824645996
train: epoch 22, loss 1.0286000967025757, acc=0.596833348274231, loss=1.0286000967025757
test: epoch 22, loss 2.5268173217773438, acc=0.14166666567325592, loss=2.5268173217773438
train: epoch 23, loss 1.0031051635742188, acc=0.6042777895927429, loss=1.0031051635742188
test: epoch 23, loss 2.601607322692871, acc=0.13333334028720856, loss=2.601607322692871
train: epoch 24, loss 0.99956214427948, acc=0.6082777976989746, loss=0.99956214427948
test: epoch 24, loss 2.4144580364227295, acc=0.21944443881511688, loss=2.4144580364227295
train: epoch 25, loss 1.0085010528564453, acc=0.5985000133514404, loss=1.0085010528564453
test: epoch 25, loss 2.852764844894409, acc=0.14722222089767456, loss=2.852764844894409
train: epoch 26, loss 0.9836466908454895, acc=0.6085555553436279, loss=0.9836466908454895
test: epoch 26, loss 2.2064924240112305, acc=0.23333333432674408, loss=2.2064924240112305
train: epoch 27, loss 0.9735687375068665, acc=0.61644446849823, loss=0.9735687375068665
test: epoch 27, loss 2.6572012901306152, acc=0.16944444179534912, loss=2.6572012901306152
train: epoch 28, loss 0.9659996628761292, acc=0.6158333420753479, loss=0.9659996628761292
test: epoch 28, loss 2.3002989292144775, acc=0.1944444477558136, loss=2.3002989292144775
train: epoch 29, loss 0.9656478762626648, acc=0.6237221956253052, loss=0.9656478762626648
test: epoch 29, loss 2.3183810710906982, acc=0.2222222238779068, loss=2.3183810710906982
train: epoch 30, loss 0.9317396283149719, acc=0.6312777996063232, loss=0.9317396283149719
test: epoch 30, loss 2.579601526260376, acc=0.17222222685813904, loss=2.579601526260376
train: epoch 31, loss 0.9475327730178833, acc=0.6348888874053955, loss=0.9475327730178833
test: epoch 31, loss 2.7604663372039795, acc=0.16111111640930176, loss=2.7604663372039795
train: epoch 32, loss 0.9252909421920776, acc=0.6346666812896729, loss=0.9252909421920776
test: epoch 32, loss 2.2938408851623535, acc=0.18611110746860504, loss=2.2938408851623535
train: epoch 33, loss 0.9182885885238647, acc=0.6377221941947937, loss=0.9182885885238647
test: epoch 33, loss 2.3243353366851807, acc=0.21111111342906952, loss=2.3243353366851807
train: epoch 34, loss 0.9021055698394775, acc=0.6436111330986023, loss=0.9021055698394775
test: epoch 34, loss 2.2114744186401367, acc=0.25555557012557983, loss=2.2114744186401367
train: epoch 35, loss 0.9075872898101807, acc=0.6470555663108826, loss=0.9075872898101807
test: epoch 35, loss 2.065089225769043, acc=0.25555557012557983, loss=2.065089225769043
train: epoch 36, loss 0.891446590423584, acc=0.6530555486679077, loss=0.891446590423584
test: epoch 36, loss 2.292736768722534, acc=0.1805555522441864, loss=2.292736768722534
train: epoch 37, loss 0.8830050826072693, acc=0.6584444642066956, loss=0.8830050826072693
test: epoch 37, loss 2.062370538711548, acc=0.23055554926395416, loss=2.062370538711548
train: epoch 38, loss 0.8944024443626404, acc=0.6483333110809326, loss=0.8944024443626404
test: epoch 38, loss 2.104792356491089, acc=0.21388888359069824, loss=2.104792356491089
train: epoch 39, loss 0.8810170292854309, acc=0.6549444198608398, loss=0.8810170292854309
test: epoch 39, loss 2.1780264377593994, acc=0.21666666865348816, loss=2.1780264377593994
train: epoch 40, loss 0.8798660635948181, acc=0.6577777862548828, loss=0.8798660635948181
test: epoch 40, loss 2.169783353805542, acc=0.30000001192092896, loss=2.169783353805542
train: epoch 41, loss 0.874147355556488, acc=0.6569444537162781, loss=0.874147355556488
test: epoch 41, loss 2.059931993484497, acc=0.21666666865348816, loss=2.059931993484497
train: epoch 42, loss 0.8610007762908936, acc=0.6626666784286499, loss=0.8610007762908936
test: epoch 42, loss 2.1776156425476074, acc=0.23333333432674408, loss=2.1776156425476074
train: epoch 43, loss 0.8557484149932861, acc=0.6656110882759094, loss=0.8557484149932861
test: epoch 43, loss 2.0866408348083496, acc=0.2666666805744171, loss=2.0866408348083496
train: epoch 44, loss 0.8713132739067078, acc=0.6636666655540466, loss=0.8713132739067078
test: epoch 44, loss 2.433915376663208, acc=0.16388888657093048, loss=2.433915376663208
train: epoch 45, loss 0.8394728302955627, acc=0.6689444184303284, loss=0.8394728302955627
test: epoch 45, loss 2.043463945388794, acc=0.19166666269302368, loss=2.043463945388794
train: epoch 46, loss 0.8577995896339417, acc=0.664555549621582, loss=0.8577995896339417
test: epoch 46, loss 2.0655136108398438, acc=0.18888889253139496, loss=2.0655136108398438
train: epoch 47, loss 0.8524048924446106, acc=0.6670555472373962, loss=0.8524048924446106
test: epoch 47, loss 2.1637790203094482, acc=0.1805555522441864, loss=2.1637790203094482
train: epoch 48, loss 0.8288218379020691, acc=0.6763888597488403, loss=0.8288218379020691
test: epoch 48, loss 2.0385098457336426, acc=0.2805555462837219, loss=2.0385098457336426
train: epoch 49, loss 0.8239787220954895, acc=0.6758888959884644, loss=0.8239787220954895
test: epoch 49, loss 1.955208420753479, acc=0.2361111044883728, loss=1.955208420753479
train: epoch 50, loss 0.8143498301506042, acc=0.6813333630561829, loss=0.8143498301506042
test: epoch 50, loss 1.979508876800537, acc=0.32499998807907104, loss=1.979508876800537
train: epoch 51, loss 0.8319264650344849, acc=0.6721110939979553, loss=0.8319264650344849
test: epoch 51, loss 1.7391798496246338, acc=0.2527777850627899, loss=1.7391798496246338
train: epoch 52, loss 0.8170772790908813, acc=0.675944447517395, loss=0.8170772790908813
test: epoch 52, loss 1.993117332458496, acc=0.23333333432674408, loss=1.993117332458496
train: epoch 53, loss 0.8127403259277344, acc=0.6763333082199097, loss=0.8127403259277344
test: epoch 53, loss 2.3857500553131104, acc=0.23055554926395416, loss=2.3857500553131104
train: epoch 54, loss 0.820532500743866, acc=0.6791666746139526, loss=0.820532500743866
test: epoch 54, loss 2.0912981033325195, acc=0.31111112236976624, loss=2.0912981033325195
train: epoch 55, loss 0.818956196308136, acc=0.6787777543067932, loss=0.818956196308136
test: epoch 55, loss 1.935847520828247, acc=0.30000001192092896, loss=1.935847520828247
train: epoch 56, loss 0.80474853515625, acc=0.6779444217681885, loss=0.80474853515625
test: epoch 56, loss 1.9762784242630005, acc=0.2222222238779068, loss=1.9762784242630005
train: epoch 57, loss 0.8007146716117859, acc=0.6848888993263245, loss=0.8007146716117859
test: epoch 57, loss 2.078052282333374, acc=0.32777777314186096, loss=2.078052282333374
train: epoch 58, loss 0.8094755411148071, acc=0.6755555272102356, loss=0.8094755411148071
test: epoch 58, loss 1.8344279527664185, acc=0.3083333373069763, loss=1.8344279527664185
train: epoch 59, loss 0.7975416779518127, acc=0.6858333349227905, loss=0.7975416779518127
test: epoch 59, loss 1.9019826650619507, acc=0.3166666626930237, loss=1.9019826650619507
train: epoch 60, loss 0.8026247024536133, acc=0.6823889017105103, loss=0.8026247024536133
test: epoch 60, loss 2.0367541313171387, acc=0.23055554926395416, loss=2.0367541313171387
train: epoch 61, loss 0.7930622696876526, acc=0.6892222166061401, loss=0.7930622696876526
test: epoch 61, loss 2.20317006111145, acc=0.25, loss=2.20317006111145
train: epoch 62, loss 0.7894431948661804, acc=0.687166690826416, loss=0.7894431948661804
test: epoch 62, loss 2.011235475540161, acc=0.21111111342906952, loss=2.011235475540161
train: epoch 63, loss 0.7921357154846191, acc=0.6880555748939514, loss=0.7921357154846191
test: epoch 63, loss 1.6555193662643433, acc=0.3583333194255829, loss=1.6555193662643433
train: epoch 64, loss 0.8079530000686646, acc=0.6807222366333008, loss=0.8079530000686646
test: epoch 64, loss 1.9681636095046997, acc=0.32777777314186096, loss=1.9681636095046997
train: epoch 65, loss 0.7723230123519897, acc=0.6942777633666992, loss=0.7723230123519897
test: epoch 65, loss 2.086069107055664, acc=0.18611110746860504, loss=2.086069107055664
train: epoch 66, loss 0.8029093742370605, acc=0.687666654586792, loss=0.8029093742370605
test: epoch 66, loss 1.980697512626648, acc=0.25, loss=1.980697512626648
train: epoch 67, loss 0.7797311544418335, acc=0.691944420337677, loss=0.7797311544418335
test: epoch 67, loss 1.8153862953186035, acc=0.2750000059604645, loss=1.8153862953186035
train: epoch 68, loss 0.787934422492981, acc=0.6875555515289307, loss=0.787934422492981
test: epoch 68, loss 1.7840800285339355, acc=0.3611111044883728, loss=1.7840800285339355
train: epoch 69, loss 0.7799481749534607, acc=0.6915000081062317, loss=0.7799481749534607
test: epoch 69, loss 1.7691473960876465, acc=0.26944443583488464, loss=1.7691473960876465
train: epoch 70, loss 0.7988621592521667, acc=0.6861666440963745, loss=0.7988621592521667
test: epoch 70, loss 1.8405816555023193, acc=0.32777777314186096, loss=1.8405816555023193
train: epoch 71, loss 0.7699581980705261, acc=0.6941666603088379, loss=0.7699581980705261
test: epoch 71, loss 1.7811188697814941, acc=0.3055555522441864, loss=1.7811188697814941
train: epoch 72, loss 0.7838923335075378, acc=0.690833330154419, loss=0.7838923335075378
test: epoch 72, loss 1.9254710674285889, acc=0.3499999940395355, loss=1.9254710674285889
train: epoch 73, loss 0.7664094567298889, acc=0.6926666498184204, loss=0.7664094567298889
test: epoch 73, loss 1.618409276008606, acc=0.2805555462837219, loss=1.618409276008606
train: epoch 74, loss 0.77806156873703, acc=0.6946666836738586, loss=0.77806156873703
test: epoch 74, loss 1.6942158937454224, acc=0.38055557012557983, loss=1.6942158937454224
train: epoch 75, loss 0.7640719413757324, acc=0.6989444494247437, loss=0.7640719413757324
test: epoch 75, loss 1.6432338953018188, acc=0.30000001192092896, loss=1.6432338953018188
train: epoch 76, loss 0.7817497253417969, acc=0.6902222037315369, loss=0.7817497253417969
test: epoch 76, loss 2.013766288757324, acc=0.25833332538604736, loss=2.013766288757324
train: epoch 77, loss 0.7720688581466675, acc=0.6962777972221375, loss=0.7720688581466675
test: epoch 77, loss 1.7457743883132935, acc=0.3083333373069763, loss=1.7457743883132935
train: epoch 78, loss 0.7880831956863403, acc=0.6923333406448364, loss=0.7880831956863403
test: epoch 78, loss 2.0174481868743896, acc=0.3444444537162781, loss=2.0174481868743896
train: epoch 79, loss 0.7868155837059021, acc=0.6893333196640015, loss=0.7868155837059021
test: epoch 79, loss 1.6588480472564697, acc=0.28611111640930176, loss=1.6588480472564697
train: epoch 80, loss 0.7676604986190796, acc=0.6981111168861389, loss=0.7676604986190796
test: epoch 80, loss 1.5359045267105103, acc=0.3722222149372101, loss=1.5359045267105103
train: epoch 81, loss 0.7804883718490601, acc=0.6916666626930237, loss=0.7804883718490601
test: epoch 81, loss 1.749268651008606, acc=0.3305555582046509, loss=1.749268651008606
train: epoch 82, loss 0.7438446283340454, acc=0.7032222151756287, loss=0.7438446283340454
test: epoch 82, loss 1.5593513250350952, acc=0.35277777910232544, loss=1.5593513250350952
train: epoch 83, loss 0.7859179973602295, acc=0.6931111216545105, loss=0.7859179973602295
test: epoch 83, loss 1.7611445188522339, acc=0.3333333432674408, loss=1.7611445188522339
train: epoch 84, loss 0.8122527599334717, acc=0.679722249507904, loss=0.8122527599334717
test: epoch 84, loss 1.5739957094192505, acc=0.4027777910232544, loss=1.5739957094192505
train: epoch 85, loss 0.7483389973640442, acc=0.7053889036178589, loss=0.7483389973640442
test: epoch 85, loss 1.7317206859588623, acc=0.3611111044883728, loss=1.7317206859588623
train: epoch 86, loss 0.7711037397384644, acc=0.6959444284439087, loss=0.7711037397384644
test: epoch 86, loss 1.9174888134002686, acc=0.31111112236976624, loss=1.9174888134002686
train: epoch 87, loss 0.7277094125747681, acc=0.7122222185134888, loss=0.7277094125747681
test: epoch 87, loss 1.7031735181808472, acc=0.33888888359069824, loss=1.7031735181808472
train: epoch 88, loss 0.7420054078102112, acc=0.7060555815696716, loss=0.7420054078102112
test: epoch 88, loss 1.6506807804107666, acc=0.3583333194255829, loss=1.6506807804107666
train: epoch 89, loss 0.7440775632858276, acc=0.7026110887527466, loss=0.7440775632858276
test: epoch 89, loss 1.40773606300354, acc=0.4333333373069763, loss=1.40773606300354
train: epoch 90, loss 0.7630584239959717, acc=0.6984444260597229, loss=0.7630584239959717
test: epoch 90, loss 1.7129381895065308, acc=0.29722222685813904, loss=1.7129381895065308
train: epoch 91, loss 0.7332720756530762, acc=0.7065555453300476, loss=0.7332720756530762
test: epoch 91, loss 1.6866824626922607, acc=0.2750000059604645, loss=1.6866824626922607
train: epoch 92, loss 0.7591964602470398, acc=0.7002221941947937, loss=0.7591964602470398
test: epoch 92, loss 1.5185565948486328, acc=0.375, loss=1.5185565948486328
train: epoch 93, loss 0.7368322014808655, acc=0.7041110992431641, loss=0.7368322014808655
test: epoch 93, loss 1.5001027584075928, acc=0.39722222089767456, loss=1.5001027584075928
train: epoch 94, loss 0.7314788103103638, acc=0.7046666741371155, loss=0.7314788103103638
test: epoch 94, loss 1.3545807600021362, acc=0.3305555582046509, loss=1.3545807600021362
train: epoch 95, loss 0.7326134443283081, acc=0.7095555663108826, loss=0.7326134443283081
test: epoch 95, loss 1.3967845439910889, acc=0.4305555522441864, loss=1.3967845439910889
train: epoch 96, loss 0.7676689028739929, acc=0.7020555734634399, loss=0.7676689028739929
test: epoch 96, loss 1.4811103343963623, acc=0.3777777850627899, loss=1.4811103343963623
train: epoch 97, loss 0.7790986895561218, acc=0.6885555386543274, loss=0.7790986895561218
test: epoch 97, loss 1.4994874000549316, acc=0.5027777552604675, loss=1.4994874000549316
train: epoch 98, loss 0.7329639196395874, acc=0.7046111226081848, loss=0.7329639196395874
test: epoch 98, loss 1.359857201576233, acc=0.38055557012557983, loss=1.359857201576233
train: epoch 99, loss 0.7532880306243896, acc=0.7052778005599976, loss=0.7532880306243896
test: epoch 99, loss 1.4657725095748901, acc=0.375, loss=1.4657725095748901
train: epoch 100, loss 0.7407030463218689, acc=0.7067221999168396, loss=0.7407030463218689
test: epoch 100, loss 1.301687479019165, acc=0.4416666626930237, loss=1.301687479019165
train: epoch 101, loss 0.7300868630409241, acc=0.714722216129303, loss=0.7300868630409241
test: epoch 101, loss 1.5388109683990479, acc=0.43888887763023376, loss=1.5388109683990479
train: epoch 102, loss 0.7334730625152588, acc=0.7087222337722778, loss=0.7334730625152588
test: epoch 102, loss 1.522221565246582, acc=0.3361110985279083, loss=1.522221565246582
train: epoch 103, loss 0.7174777984619141, acc=0.7133333086967468, loss=0.7174777984619141
test: epoch 103, loss 1.7838480472564697, acc=0.38055557012557983, loss=1.7838480472564697
train: epoch 104, loss 0.7256569862365723, acc=0.7108888626098633, loss=0.7256569862365723
test: epoch 104, loss 1.3634490966796875, acc=0.42222222685813904, loss=1.3634490966796875
train: epoch 105, loss 0.7328693270683289, acc=0.7088333368301392, loss=0.7328693270683289
test: epoch 105, loss 1.492774486541748, acc=0.4722222089767456, loss=1.492774486541748
train: epoch 106, loss 0.7379356026649475, acc=0.7123333215713501, loss=0.7379356026649475
test: epoch 106, loss 1.6427257061004639, acc=0.38055557012557983, loss=1.6427257061004639
train: epoch 107, loss 0.7179238796234131, acc=0.715833306312561, loss=0.7179238796234131
test: epoch 107, loss 1.3508379459381104, acc=0.3861111104488373, loss=1.3508379459381104
train: epoch 108, loss 0.7114185094833374, acc=0.7213333249092102, loss=0.7114185094833374
test: epoch 108, loss 1.5247136354446411, acc=0.3499999940395355, loss=1.5247136354446411
train: epoch 109, loss 0.7072021961212158, acc=0.7193889021873474, loss=0.7072021961212158
test: epoch 109, loss 1.3694080114364624, acc=0.40833333134651184, loss=1.3694080114364624
train: epoch 110, loss 0.7165042757987976, acc=0.7195555567741394, loss=0.7165042757987976
test: epoch 110, loss 1.491843819618225, acc=0.4027777910232544, loss=1.491843819618225
train: epoch 111, loss 0.7213155031204224, acc=0.7130555510520935, loss=0.7213155031204224
test: epoch 111, loss 1.5205943584442139, acc=0.3861111104488373, loss=1.5205943584442139
train: epoch 112, loss 0.705284059047699, acc=0.7154444456100464, loss=0.705284059047699
test: epoch 112, loss 1.747010350227356, acc=0.3583333194255829, loss=1.747010350227356
train: epoch 113, loss 0.696822464466095, acc=0.7221666574478149, loss=0.696822464466095
test: epoch 113, loss 1.4133789539337158, acc=0.39444443583488464, loss=1.4133789539337158
train: epoch 114, loss 0.7086539268493652, acc=0.7164999842643738, loss=0.7086539268493652
test: epoch 114, loss 1.484629511833191, acc=0.43611112236976624, loss=1.484629511833191
train: epoch 115, loss 0.716574490070343, acc=0.7159444689750671, loss=0.716574490070343
test: epoch 115, loss 1.3716940879821777, acc=0.42500001192092896, loss=1.3716940879821777
train: epoch 116, loss 0.7109637260437012, acc=0.7197222113609314, loss=0.7109637260437012
test: epoch 116, loss 1.6571695804595947, acc=0.3638888895511627, loss=1.6571695804595947
train: epoch 117, loss 0.7010226249694824, acc=0.7222222089767456, loss=0.7010226249694824
test: epoch 117, loss 1.5147713422775269, acc=0.4055555462837219, loss=1.5147713422775269
train: epoch 118, loss 0.701138436794281, acc=0.7211111187934875, loss=0.701138436794281
test: epoch 118, loss 1.6404178142547607, acc=0.3194444477558136, loss=1.6404178142547607
train: epoch 119, loss 0.7142163515090942, acc=0.7168889045715332, loss=0.7142163515090942
test: epoch 119, loss 1.2727595567703247, acc=0.4555555582046509, loss=1.2727595567703247
train: epoch 120, loss 0.7092998623847961, acc=0.7147777676582336, loss=0.7092998623847961
test: epoch 120, loss 1.304880142211914, acc=0.4583333432674408, loss=1.304880142211914
train: epoch 121, loss 0.7113741636276245, acc=0.7169444561004639, loss=0.7113741636276245
test: epoch 121, loss 1.4019163846969604, acc=0.3861111104488373, loss=1.4019163846969604
train: epoch 122, loss 0.6966355443000793, acc=0.7207221984863281, loss=0.6966355443000793
test: epoch 122, loss 1.1547504663467407, acc=0.5222222208976746, loss=1.1547504663467407
train: epoch 123, loss 0.7092464566230774, acc=0.7179444432258606, loss=0.7092464566230774
test: epoch 123, loss 1.2071675062179565, acc=0.5861111283302307, loss=1.2071675062179565
train: epoch 124, loss 0.7087172865867615, acc=0.7193333506584167, loss=0.7087172865867615
test: epoch 124, loss 1.4077732563018799, acc=0.42222222685813904, loss=1.4077732563018799
train: epoch 125, loss 0.6732525825500488, acc=0.7288333177566528, loss=0.6732525825500488
test: epoch 125, loss 1.4548603296279907, acc=0.4277777671813965, loss=1.4548603296279907
train: epoch 126, loss 0.7104557156562805, acc=0.718999981880188, loss=0.7104557156562805
test: epoch 126, loss 1.4042996168136597, acc=0.39444443583488464, loss=1.4042996168136597
train: epoch 127, loss 0.6954746246337891, acc=0.7196111083030701, loss=0.6954746246337891
test: epoch 127, loss 1.5196908712387085, acc=0.43611112236976624, loss=1.5196908712387085
train: epoch 128, loss 0.6910628080368042, acc=0.7277777791023254, loss=0.6910628080368042
test: epoch 128, loss 1.4746618270874023, acc=0.46388888359069824, loss=1.4746618270874023
train: epoch 129, loss 0.6961060166358948, acc=0.7241111397743225, loss=0.6961060166358948
test: epoch 129, loss 1.286374807357788, acc=0.4333333373069763, loss=1.286374807357788
train: epoch 130, loss 0.7024454474449158, acc=0.7197222113609314, loss=0.7024454474449158
test: epoch 130, loss 1.2840986251831055, acc=0.45277777314186096, loss=1.2840986251831055
train: epoch 131, loss 0.6992824673652649, acc=0.7196111083030701, loss=0.6992824673652649
test: epoch 131, loss 1.2192409038543701, acc=0.4305555522441864, loss=1.2192409038543701
train: epoch 132, loss 0.6963599324226379, acc=0.7190555334091187, loss=0.6963599324226379
test: epoch 132, loss 1.1073869466781616, acc=0.4833333194255829, loss=1.1073869466781616
train: epoch 133, loss 0.7086114287376404, acc=0.719944417476654, loss=0.7086114287376404
test: epoch 133, loss 1.42405366897583, acc=0.4472222328186035, loss=1.42405366897583
train: epoch 134, loss 0.6950966119766235, acc=0.7225000262260437, loss=0.6950966119766235
test: epoch 134, loss 1.2190419435501099, acc=0.4694444537162781, loss=1.2190419435501099
train: epoch 135, loss 0.6940170526504517, acc=0.7244444489479065, loss=0.6940170526504517
test: epoch 135, loss 1.3761482238769531, acc=0.48055556416511536, loss=1.3761482238769531
train: epoch 136, loss 0.6950405240058899, acc=0.7191110849380493, loss=0.6950405240058899
test: epoch 136, loss 1.3747235536575317, acc=0.4305555522441864, loss=1.3747235536575317
train: epoch 137, loss 0.7031866908073425, acc=0.7211111187934875, loss=0.7031866908073425
test: epoch 137, loss 1.311822533607483, acc=0.4722222089767456, loss=1.311822533607483
train: epoch 138, loss 0.7177047729492188, acc=0.7098333239555359, loss=0.7177047729492188
test: epoch 138, loss 1.3031903505325317, acc=0.5027777552604675, loss=1.3031903505325317
train: epoch 139, loss 0.7009323835372925, acc=0.723111093044281, loss=0.7009323835372925
test: epoch 139, loss 1.3978239297866821, acc=0.4444444477558136, loss=1.3978239297866821
train: epoch 140, loss 0.7117266058921814, acc=0.7151111364364624, loss=0.7117266058921814
test: epoch 140, loss 1.4304853677749634, acc=0.4416666626930237, loss=1.4304853677749634
train: epoch 141, loss 0.7161603569984436, acc=0.715499997138977, loss=0.7161603569984436
test: epoch 141, loss 1.1516377925872803, acc=0.4722222089767456, loss=1.1516377925872803
train: epoch 142, loss 0.7045201659202576, acc=0.7172777652740479, loss=0.7045201659202576
test: epoch 142, loss 1.2661131620407104, acc=0.44999998807907104, loss=1.2661131620407104
train: epoch 143, loss 0.6922192573547363, acc=0.7235000133514404, loss=0.6922192573547363
test: epoch 143, loss 1.3107903003692627, acc=0.4416666626930237, loss=1.3107903003692627
train: epoch 144, loss 0.6948926448822021, acc=0.7190555334091187, loss=0.6948926448822021
test: epoch 144, loss 1.2281919717788696, acc=0.4555555582046509, loss=1.2281919717788696
train: epoch 145, loss 0.6847454905509949, acc=0.7265555262565613, loss=0.6847454905509949
test: epoch 145, loss 1.2502326965332031, acc=0.45277777314186096, loss=1.2502326965332031
train: epoch 146, loss 0.6825136542320251, acc=0.7282222509384155, loss=0.6825136542320251
test: epoch 146, loss 1.1803219318389893, acc=0.5166666507720947, loss=1.1803219318389893
train: epoch 147, loss 0.6766988635063171, acc=0.7295555472373962, loss=0.6766988635063171
test: epoch 147, loss 1.3648757934570312, acc=0.4583333432674408, loss=1.3648757934570312
train: epoch 148, loss 0.6612166166305542, acc=0.7315555810928345, loss=0.6612166166305542
test: epoch 148, loss 1.2674695253372192, acc=0.44999998807907104, loss=1.2674695253372192
train: epoch 149, loss 0.6656978726387024, acc=0.7308333516120911, loss=0.6656978726387024
test: epoch 149, loss 1.308006763458252, acc=0.4749999940395355, loss=1.308006763458252
train: epoch 150, loss 0.6780198216438293, acc=0.7281666398048401, loss=0.6780198216438293
test: epoch 150, loss 1.4254531860351562, acc=0.39444443583488464, loss=1.4254531860351562
