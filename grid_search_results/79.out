# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=true", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=583496851, receiver_embed_dim=64, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.9060091972351074, acc=0.1023888885974884, loss=2.9060091972351074
test: epoch 1, loss 3.1324286460876465, acc=0.14722222089767456, loss=3.1324286460876465
train: epoch 2, loss 1.6968432664871216, acc=0.3451666533946991, loss=1.6968432664871216
test: epoch 2, loss 2.8059942722320557, acc=0.21388888359069824, loss=2.8059942722320557
train: epoch 3, loss 1.2429019212722778, acc=0.5057222247123718, loss=1.2429019212722778
test: epoch 3, loss 2.4860315322875977, acc=0.21666666865348816, loss=2.4860315322875977
train: epoch 4, loss 1.0248044729232788, acc=0.5859444737434387, loss=1.0248044729232788
test: epoch 4, loss 2.323662281036377, acc=0.25, loss=2.323662281036377
train: epoch 5, loss 0.8815966248512268, acc=0.6449999809265137, loss=0.8815966248512268
test: epoch 5, loss 2.074355363845825, acc=0.2888889014720917, loss=2.074355363845825
train: epoch 6, loss 0.7765711545944214, acc=0.6857222318649292, loss=0.7765711545944214
test: epoch 6, loss 2.0694119930267334, acc=0.30000001192092896, loss=2.0694119930267334
train: epoch 7, loss 0.689949631690979, acc=0.7239999771118164, loss=0.689949631690979
test: epoch 7, loss 2.0151405334472656, acc=0.2638888955116272, loss=2.0151405334472656
train: epoch 8, loss 0.6244319677352905, acc=0.7566666603088379, loss=0.6244319677352905
test: epoch 8, loss 1.8066926002502441, acc=0.3722222149372101, loss=1.8066926002502441
train: epoch 9, loss 0.5572898387908936, acc=0.7771111130714417, loss=0.5572898387908936
test: epoch 9, loss 2.1487677097320557, acc=0.3444444537162781, loss=2.1487677097320557
train: epoch 10, loss 0.542637288570404, acc=0.7838333249092102, loss=0.542637288570404
test: epoch 10, loss 1.9179043769836426, acc=0.3333333432674408, loss=1.9179043769836426
train: epoch 11, loss 0.5080380439758301, acc=0.7952777743339539, loss=0.5080380439758301
test: epoch 11, loss 1.72805655002594, acc=0.38055557012557983, loss=1.72805655002594
train: epoch 12, loss 0.47516384720802307, acc=0.8093888759613037, loss=0.47516384720802307
test: epoch 12, loss 1.9751689434051514, acc=0.3916666805744171, loss=1.9751689434051514
train: epoch 13, loss 0.44655609130859375, acc=0.820277750492096, loss=0.44655609130859375
test: epoch 13, loss 1.6963436603546143, acc=0.39444443583488464, loss=1.6963436603546143
train: epoch 14, loss 0.40885353088378906, acc=0.8379999995231628, loss=0.40885353088378906
test: epoch 14, loss 1.9428616762161255, acc=0.3888888955116272, loss=1.9428616762161255
train: epoch 15, loss 0.394900381565094, acc=0.8423333168029785, loss=0.394900381565094
test: epoch 15, loss 1.4583889245986938, acc=0.4444444477558136, loss=1.4583889245986938
train: epoch 16, loss 0.36920756101608276, acc=0.8500555753707886, loss=0.36920756101608276
test: epoch 16, loss 1.98958420753479, acc=0.39444443583488464, loss=1.98958420753479
train: epoch 17, loss 0.36408835649490356, acc=0.8524444699287415, loss=0.36408835649490356
test: epoch 17, loss 1.96451997756958, acc=0.4166666567325592, loss=1.96451997756958
train: epoch 18, loss 0.32796192169189453, acc=0.8670555353164673, loss=0.32796192169189453
test: epoch 18, loss 1.7199774980545044, acc=0.4555555582046509, loss=1.7199774980545044
train: epoch 19, loss 0.32644030451774597, acc=0.8680555820465088, loss=0.32644030451774597
test: epoch 19, loss 1.2780331373214722, acc=0.5, loss=1.2780331373214722
train: epoch 20, loss 0.30062708258628845, acc=0.8766666650772095, loss=0.30062708258628845
test: epoch 20, loss 1.7533719539642334, acc=0.4888888895511627, loss=1.7533719539642334
train: epoch 21, loss 0.28302058577537537, acc=0.882611095905304, loss=0.28302058577537537
test: epoch 21, loss 1.787999153137207, acc=0.4555555582046509, loss=1.787999153137207
train: epoch 22, loss 0.27627870440483093, acc=0.8845555782318115, loss=0.27627870440483093
test: epoch 22, loss 1.3874832391738892, acc=0.5416666865348816, loss=1.3874832391738892
train: epoch 23, loss 0.26726967096328735, acc=0.887666642665863, loss=0.26726967096328735
test: epoch 23, loss 1.4854786396026611, acc=0.5111111402511597, loss=1.4854786396026611
train: epoch 24, loss 0.25596845149993896, acc=0.887666642665863, loss=0.25596845149993896
test: epoch 24, loss 1.5368232727050781, acc=0.519444465637207, loss=1.5368232727050781
train: epoch 25, loss 0.23438061773777008, acc=0.8963333368301392, loss=0.23438061773777008
test: epoch 25, loss 2.25227689743042, acc=0.42500001192092896, loss=2.25227689743042
train: epoch 26, loss 0.2482602596282959, acc=0.8913333415985107, loss=0.2482602596282959
test: epoch 26, loss 2.1199605464935303, acc=0.5277777910232544, loss=2.1199605464935303
train: epoch 27, loss 0.24088113009929657, acc=0.8934999704360962, loss=0.24088113009929657
test: epoch 27, loss 1.851199746131897, acc=0.47777777910232544, loss=1.851199746131897
train: epoch 28, loss 0.23009777069091797, acc=0.898277759552002, loss=0.23009777069091797
test: epoch 28, loss 1.6754117012023926, acc=0.5111111402511597, loss=1.6754117012023926
train: epoch 29, loss 0.22163133323192596, acc=0.9009444713592529, loss=0.22163133323192596
test: epoch 29, loss 1.1564884185791016, acc=0.6138888597488403, loss=1.1564884185791016
train: epoch 30, loss 0.22226271033287048, acc=0.9013888835906982, loss=0.22226271033287048
test: epoch 30, loss 1.7049206495285034, acc=0.5361111164093018, loss=1.7049206495285034
train: epoch 31, loss 0.22619983553886414, acc=0.9000555276870728, loss=0.22619983553886414
test: epoch 31, loss 1.5074001550674438, acc=0.5527777671813965, loss=1.5074001550674438
train: epoch 32, loss 0.20062214136123657, acc=0.9088333249092102, loss=0.20062214136123657
test: epoch 32, loss 0.9733020663261414, acc=0.6777777671813965, loss=0.9733020663261414
train: epoch 33, loss 0.2136685699224472, acc=0.9028888940811157, loss=0.2136685699224472
test: epoch 33, loss 1.4560238122940063, acc=0.6000000238418579, loss=1.4560238122940063
train: epoch 34, loss 0.2118866741657257, acc=0.9056110978126526, loss=0.2118866741657257
test: epoch 34, loss 1.343680739402771, acc=0.6527777910232544, loss=1.343680739402771
train: epoch 35, loss 0.20968493819236755, acc=0.9044444561004639, loss=0.20968493819236755
test: epoch 35, loss 1.2628028392791748, acc=0.6000000238418579, loss=1.2628028392791748
train: epoch 36, loss 0.21995164453983307, acc=0.9003333449363708, loss=0.21995164453983307
test: epoch 36, loss 1.1374690532684326, acc=0.6555555462837219, loss=1.1374690532684326
train: epoch 37, loss 0.1967579424381256, acc=0.9096666574478149, loss=0.1967579424381256
test: epoch 37, loss 0.8618564605712891, acc=0.644444465637207, loss=0.8618564605712891
train: epoch 38, loss 0.1999506950378418, acc=0.909166693687439, loss=0.1999506950378418
test: epoch 38, loss 1.3875948190689087, acc=0.6027777791023254, loss=1.3875948190689087
train: epoch 39, loss 0.20078979432582855, acc=0.9072777628898621, loss=0.20078979432582855
test: epoch 39, loss 1.1095820665359497, acc=0.6777777671813965, loss=1.1095820665359497
train: epoch 40, loss 0.19469960033893585, acc=0.9120000004768372, loss=0.19469960033893585
test: epoch 40, loss 1.0149003267288208, acc=0.7055555582046509, loss=1.0149003267288208
train: epoch 41, loss 0.20063696801662445, acc=0.910111129283905, loss=0.20063696801662445
test: epoch 41, loss 0.8833836913108826, acc=0.7388888597488403, loss=0.8833836913108826
train: epoch 42, loss 0.1981031447649002, acc=0.9101666808128357, loss=0.1981031447649002
test: epoch 42, loss 0.7799561023712158, acc=0.7250000238418579, loss=0.7799561023712158
train: epoch 43, loss 0.191201314330101, acc=0.9119444489479065, loss=0.191201314330101
test: epoch 43, loss 1.0468612909317017, acc=0.7333333492279053, loss=1.0468612909317017
train: epoch 44, loss 0.19287116825580597, acc=0.9146111011505127, loss=0.19287116825580597
test: epoch 44, loss 0.6875400543212891, acc=0.7777777910232544, loss=0.6875400543212891
train: epoch 45, loss 0.17702728509902954, acc=0.9152777791023254, loss=0.17702728509902954
test: epoch 45, loss 1.0256965160369873, acc=0.7555555701255798, loss=1.0256965160369873
train: epoch 46, loss 0.17981237173080444, acc=0.914722204208374, loss=0.17981237173080444
test: epoch 46, loss 0.9224501252174377, acc=0.7472222447395325, loss=0.9224501252174377
train: epoch 47, loss 0.17170371115207672, acc=0.9185555577278137, loss=0.17170371115207672
test: epoch 47, loss 0.7356048822402954, acc=0.7944444417953491, loss=0.7356048822402954
train: epoch 48, loss 0.17864581942558289, acc=0.9150555729866028, loss=0.17864581942558289
test: epoch 48, loss 0.9945523142814636, acc=0.7444444298744202, loss=0.9945523142814636
train: epoch 49, loss 0.18203528225421906, acc=0.9141111373901367, loss=0.18203528225421906
test: epoch 49, loss 0.8806780576705933, acc=0.7472222447395325, loss=0.8806780576705933
train: epoch 50, loss 0.17455966770648956, acc=0.9163888692855835, loss=0.17455966770648956
test: epoch 50, loss 0.7239529490470886, acc=0.7555555701255798, loss=0.7239529490470886
train: epoch 51, loss 0.1761411726474762, acc=0.9130555391311646, loss=0.1761411726474762
test: epoch 51, loss 0.7211182713508606, acc=0.7805555462837219, loss=0.7211182713508606
train: epoch 52, loss 0.1561432033777237, acc=0.9218888878822327, loss=0.1561432033777237
test: epoch 52, loss 1.0045256614685059, acc=0.7444444298744202, loss=1.0045256614685059
train: epoch 53, loss 0.17595207691192627, acc=0.9169999957084656, loss=0.17595207691192627
test: epoch 53, loss 0.5937283635139465, acc=0.800000011920929, loss=0.5937283635139465
train: epoch 54, loss 0.16781553626060486, acc=0.9192777872085571, loss=0.16781553626060486
test: epoch 54, loss 0.6976786255836487, acc=0.7916666865348816, loss=0.6976786255836487
train: epoch 55, loss 0.1648688167333603, acc=0.9208333492279053, loss=0.1648688167333603
test: epoch 55, loss 0.6388332843780518, acc=0.8305555582046509, loss=0.6388332843780518
train: epoch 56, loss 0.16863751411437988, acc=0.9202222228050232, loss=0.16863751411437988
test: epoch 56, loss 0.57701575756073, acc=0.824999988079071, loss=0.57701575756073
train: epoch 57, loss 0.14793425798416138, acc=0.9257222414016724, loss=0.14793425798416138
test: epoch 57, loss 0.6793116331100464, acc=0.8166666626930237, loss=0.6793116331100464
train: epoch 58, loss 0.16343799233436584, acc=0.9223889112472534, loss=0.16343799233436584
test: epoch 58, loss 0.5211386680603027, acc=0.824999988079071, loss=0.5211386680603027
train: epoch 59, loss 0.1486595869064331, acc=0.9271110892295837, loss=0.1486595869064331
test: epoch 59, loss 0.515605628490448, acc=0.8527777791023254, loss=0.515605628490448
train: epoch 60, loss 0.14041143655776978, acc=0.9404444694519043, loss=0.14041143655776978
test: epoch 60, loss 0.54345703125, acc=0.8388888835906982, loss=0.54345703125
train: epoch 61, loss 0.11589354276657104, acc=0.9563888907432556, loss=0.11589354276657104
test: epoch 61, loss 0.3308261036872864, acc=0.8666666746139526, loss=0.3308261036872864
train: epoch 62, loss 0.11418312042951584, acc=0.9549444317817688, loss=0.11418312042951584
test: epoch 62, loss 0.37608176469802856, acc=0.894444465637207, loss=0.37608176469802856
train: epoch 63, loss 0.11627647280693054, acc=0.9558333158493042, loss=0.11627647280693054
test: epoch 63, loss 0.4413694143295288, acc=0.8972222208976746, loss=0.4413694143295288
train: epoch 64, loss 0.10584741830825806, acc=0.9586666822433472, loss=0.10584741830825806
test: epoch 64, loss 0.33136168122291565, acc=0.8805555701255798, loss=0.33136168122291565
train: epoch 65, loss 0.08868309110403061, acc=0.9627222418785095, loss=0.08868309110403061
test: epoch 65, loss 0.3047601282596588, acc=0.9055555462837219, loss=0.3047601282596588
train: epoch 66, loss 0.10660888254642487, acc=0.9577222466468811, loss=0.10660888254642487
test: epoch 66, loss 0.43552449345588684, acc=0.8833333253860474, loss=0.43552449345588684
train: epoch 67, loss 0.08954782783985138, acc=0.9641666412353516, loss=0.08954782783985138
test: epoch 67, loss 0.3245639503002167, acc=0.8694444298744202, loss=0.3245639503002167
train: epoch 68, loss 0.10032659769058228, acc=0.9609444737434387, loss=0.10032659769058228
test: epoch 68, loss 0.3843451738357544, acc=0.894444465637207, loss=0.3843451738357544
train: epoch 69, loss 0.08756029605865479, acc=0.9633333086967468, loss=0.08756029605865479
test: epoch 69, loss 0.4280693233013153, acc=0.8861111402511597, loss=0.4280693233013153
train: epoch 70, loss 0.09109459072351456, acc=0.9636111259460449, loss=0.09109459072351456
test: epoch 70, loss 0.3000915050506592, acc=0.9055555462837219, loss=0.3000915050506592
train: epoch 71, loss 0.09740544855594635, acc=0.9612777829170227, loss=0.09740544855594635
test: epoch 71, loss 0.2819611132144928, acc=0.9027777910232544, loss=0.2819611132144928
train: epoch 72, loss 0.09083365648984909, acc=0.9618889093399048, loss=0.09083365648984909
test: epoch 72, loss 0.3309934139251709, acc=0.9027777910232544, loss=0.3309934139251709
train: epoch 73, loss 0.08866821229457855, acc=0.964722216129303, loss=0.08866821229457855
test: epoch 73, loss 0.27897360920906067, acc=0.9055555462837219, loss=0.27897360920906067
train: epoch 74, loss 0.07834785431623459, acc=0.9689444303512573, loss=0.07834785431623459
test: epoch 74, loss 0.2739531993865967, acc=0.9083333611488342, loss=0.2739531993865967
train: epoch 75, loss 0.0744149386882782, acc=0.9693889021873474, loss=0.0744149386882782
test: epoch 75, loss 0.3748616576194763, acc=0.9083333611488342, loss=0.3748616576194763
train: epoch 76, loss 0.08168929815292358, acc=0.9635555744171143, loss=0.08168929815292358
test: epoch 76, loss 0.2813186049461365, acc=0.9055555462837219, loss=0.2813186049461365
train: epoch 77, loss 0.09647771716117859, acc=0.9614444375038147, loss=0.09647771716117859
test: epoch 77, loss 0.3470017910003662, acc=0.9055555462837219, loss=0.3470017910003662
train: epoch 78, loss 0.07985149323940277, acc=0.9671666622161865, loss=0.07985149323940277
test: epoch 78, loss 0.3687358498573303, acc=0.9083333611488342, loss=0.3687358498573303
train: epoch 79, loss 0.07640598714351654, acc=0.9632222056388855, loss=0.07640598714351654
test: epoch 79, loss 0.24227109551429749, acc=0.9083333611488342, loss=0.24227109551429749
train: epoch 80, loss 0.08191320300102234, acc=0.968500018119812, loss=0.08191320300102234
test: epoch 80, loss 0.2901860177516937, acc=0.9083333611488342, loss=0.2901860177516937
train: epoch 81, loss 0.08840636163949966, acc=0.9657777547836304, loss=0.08840636163949966
test: epoch 81, loss 0.3075668513774872, acc=0.9083333611488342, loss=0.3075668513774872
train: epoch 82, loss 0.07466424256563187, acc=0.9671111106872559, loss=0.07466424256563187
test: epoch 82, loss 0.2903573215007782, acc=0.9083333611488342, loss=0.2903573215007782
train: epoch 83, loss 0.09099280089139938, acc=0.961388885974884, loss=0.09099280089139938
test: epoch 83, loss 0.32212844491004944, acc=0.9027777910232544, loss=0.32212844491004944
train: epoch 84, loss 0.07182750105857849, acc=0.9670000076293945, loss=0.07182750105857849
test: epoch 84, loss 0.33524423837661743, acc=0.9083333611488342, loss=0.33524423837661743
train: epoch 85, loss 0.08375860750675201, acc=0.9619444608688354, loss=0.08375860750675201
test: epoch 85, loss 0.21828533709049225, acc=0.9083333611488342, loss=0.21828533709049225
train: epoch 86, loss 0.08485466241836548, acc=0.964888870716095, loss=0.08485466241836548
test: epoch 86, loss 0.28125202655792236, acc=0.9083333611488342, loss=0.28125202655792236
train: epoch 87, loss 0.08158344775438309, acc=0.9646666646003723, loss=0.08158344775438309
test: epoch 87, loss 0.2633115351200104, acc=0.9083333611488342, loss=0.2633115351200104
train: epoch 88, loss 0.08252856135368347, acc=0.9647777676582336, loss=0.08252856135368347
test: epoch 88, loss 0.3396969139575958, acc=0.9083333611488342, loss=0.3396969139575958
train: epoch 89, loss 0.07559634745121002, acc=0.9680555462837219, loss=0.07559634745121002
test: epoch 89, loss 0.2509783208370209, acc=0.9083333611488342, loss=0.2509783208370209
train: epoch 90, loss 0.08468423038721085, acc=0.9663333296775818, loss=0.08468423038721085
test: epoch 90, loss 0.2716395854949951, acc=0.9083333611488342, loss=0.2716395854949951
train: epoch 91, loss 0.08021722733974457, acc=0.9671666622161865, loss=0.08021722733974457
test: epoch 91, loss 0.3673560321331024, acc=0.9083333611488342, loss=0.3673560321331024
train: epoch 92, loss 0.0845494344830513, acc=0.9680555462837219, loss=0.0845494344830513
test: epoch 92, loss 0.28538933396339417, acc=0.9083333611488342, loss=0.28538933396339417
train: epoch 93, loss 0.0872630625963211, acc=0.9677777886390686, loss=0.0872630625963211
test: epoch 93, loss 0.32673218846321106, acc=0.9083333611488342, loss=0.32673218846321106
train: epoch 94, loss 0.08437307178974152, acc=0.961722195148468, loss=0.08437307178974152
test: epoch 94, loss 0.25922444462776184, acc=0.9083333611488342, loss=0.25922444462776184
train: epoch 95, loss 0.07317833602428436, acc=0.9633888602256775, loss=0.07317833602428436
test: epoch 95, loss 0.3111025393009186, acc=0.9083333611488342, loss=0.3111025393009186
train: epoch 96, loss 0.08556055277585983, acc=0.9649999737739563, loss=0.08556055277585983
test: epoch 96, loss 0.32984596490859985, acc=0.8972222208976746, loss=0.32984596490859985
train: epoch 97, loss 0.07942525297403336, acc=0.9660000205039978, loss=0.07942525297403336
test: epoch 97, loss 0.3191652297973633, acc=0.9083333611488342, loss=0.3191652297973633
train: epoch 98, loss 0.08011223375797272, acc=0.9631111025810242, loss=0.08011223375797272
test: epoch 98, loss 0.23716457188129425, acc=0.9083333611488342, loss=0.23716457188129425
train: epoch 99, loss 0.0794931948184967, acc=0.9622222185134888, loss=0.0794931948184967
test: epoch 99, loss 0.30063992738723755, acc=0.9083333611488342, loss=0.30063992738723755
train: epoch 100, loss 0.08383127301931381, acc=0.965499997138977, loss=0.08383127301931381
test: epoch 100, loss 0.20938284695148468, acc=0.9083333611488342, loss=0.20938284695148468
train: epoch 101, loss 0.08847001940011978, acc=0.9594444632530212, loss=0.08847001940011978
test: epoch 101, loss 0.2867639362812042, acc=0.9083333611488342, loss=0.2867639362812042
train: epoch 102, loss 0.07836676388978958, acc=0.961388885974884, loss=0.07836676388978958
test: epoch 102, loss 0.25425079464912415, acc=0.9083333611488342, loss=0.25425079464912415
train: epoch 103, loss 0.08528546988964081, acc=0.9601666927337646, loss=0.08528546988964081
test: epoch 103, loss 0.3521309792995453, acc=0.9083333611488342, loss=0.3521309792995453
train: epoch 104, loss 0.07862155884504318, acc=0.9641666412353516, loss=0.07862155884504318
test: epoch 104, loss 0.34052884578704834, acc=0.9083333611488342, loss=0.34052884578704834
train: epoch 105, loss 0.09007037431001663, acc=0.9600555300712585, loss=0.09007037431001663
test: epoch 105, loss 0.329624742269516, acc=0.9083333611488342, loss=0.329624742269516
train: epoch 106, loss 0.07709049433469772, acc=0.9639999866485596, loss=0.07709049433469772
test: epoch 106, loss 0.3493179380893707, acc=0.9083333611488342, loss=0.3493179380893707
train: epoch 107, loss 0.08844426274299622, acc=0.9610000252723694, loss=0.08844426274299622
test: epoch 107, loss 0.24129192531108856, acc=0.9111111164093018, loss=0.24129192531108856
train: epoch 108, loss 0.09037323296070099, acc=0.9564999938011169, loss=0.09037323296070099
test: epoch 108, loss 0.2509201467037201, acc=0.9083333611488342, loss=0.2509201467037201
train: epoch 109, loss 0.07408753782510757, acc=0.9631111025810242, loss=0.07408753782510757
test: epoch 109, loss 0.26952823996543884, acc=0.9083333611488342, loss=0.26952823996543884
train: epoch 110, loss 0.08330391347408295, acc=0.9614444375038147, loss=0.08330391347408295
test: epoch 110, loss 0.3425723612308502, acc=0.9027777910232544, loss=0.3425723612308502
train: epoch 111, loss 0.08661385625600815, acc=0.9648333191871643, loss=0.08661385625600815
test: epoch 111, loss 0.3463039994239807, acc=0.9083333611488342, loss=0.3463039994239807
train: epoch 112, loss 0.08654357492923737, acc=0.9622222185134888, loss=0.08654357492923737
test: epoch 112, loss 0.30128389596939087, acc=0.9083333611488342, loss=0.30128389596939087
train: epoch 113, loss 0.08409793674945831, acc=0.9601666927337646, loss=0.08409793674945831
test: epoch 113, loss 0.24675624072551727, acc=0.9027777910232544, loss=0.24675624072551727
train: epoch 114, loss 0.08040617406368256, acc=0.9622777700424194, loss=0.08040617406368256
test: epoch 114, loss 0.2833090126514435, acc=0.9083333611488342, loss=0.2833090126514435
train: epoch 115, loss 0.07633747905492783, acc=0.9617778062820435, loss=0.07633747905492783
test: epoch 115, loss 0.2964968979358673, acc=0.9083333611488342, loss=0.2964968979358673
train: epoch 116, loss 0.0795704796910286, acc=0.961722195148468, loss=0.0795704796910286
test: epoch 116, loss 0.38035252690315247, acc=0.9083333611488342, loss=0.38035252690315247
train: epoch 117, loss 0.08907578885555267, acc=0.961222231388092, loss=0.08907578885555267
test: epoch 117, loss 0.2501666247844696, acc=0.9083333611488342, loss=0.2501666247844696
train: epoch 118, loss 0.07738792151212692, acc=0.964555561542511, loss=0.07738792151212692
test: epoch 118, loss 0.34399765729904175, acc=0.9083333611488342, loss=0.34399765729904175
train: epoch 119, loss 0.07809830456972122, acc=0.9625555276870728, loss=0.07809830456972122
test: epoch 119, loss 0.26313942670822144, acc=0.9083333611488342, loss=0.26313942670822144
train: epoch 120, loss 0.08484803140163422, acc=0.9624444246292114, loss=0.08484803140163422
test: epoch 120, loss 0.21858274936676025, acc=0.9083333611488342, loss=0.21858274936676025
train: epoch 121, loss 0.09327872097492218, acc=0.9575555324554443, loss=0.09327872097492218
test: epoch 121, loss 0.21584489941596985, acc=0.9083333611488342, loss=0.21584489941596985
train: epoch 122, loss 0.08382266014814377, acc=0.9594444632530212, loss=0.08382266014814377
test: epoch 122, loss 0.2435133308172226, acc=0.9083333611488342, loss=0.2435133308172226
train: epoch 123, loss 0.088551826775074, acc=0.9610000252723694, loss=0.088551826775074
test: epoch 123, loss 0.2858681082725525, acc=0.9111111164093018, loss=0.2858681082725525
train: epoch 124, loss 0.0799749568104744, acc=0.9641110897064209, loss=0.0799749568104744
test: epoch 124, loss 0.2872898280620575, acc=0.9111111164093018, loss=0.2872898280620575
train: epoch 125, loss 0.08582521229982376, acc=0.9597777724266052, loss=0.08582521229982376
test: epoch 125, loss 0.24229483306407928, acc=0.9083333611488342, loss=0.24229483306407928
train: epoch 126, loss 0.08040124177932739, acc=0.9619444608688354, loss=0.08040124177932739
test: epoch 126, loss 0.36171409487724304, acc=0.9083333611488342, loss=0.36171409487724304
train: epoch 127, loss 0.0718756839632988, acc=0.9633333086967468, loss=0.0718756839632988
test: epoch 127, loss 0.28121674060821533, acc=0.9083333611488342, loss=0.28121674060821533
train: epoch 128, loss 0.09495116770267487, acc=0.9578889012336731, loss=0.09495116770267487
test: epoch 128, loss 0.259480744600296, acc=0.9055555462837219, loss=0.259480744600296
train: epoch 129, loss 0.08150333911180496, acc=0.9649444222450256, loss=0.08150333911180496
test: epoch 129, loss 0.2880066931247711, acc=0.9083333611488342, loss=0.2880066931247711
train: epoch 130, loss 0.08215256780385971, acc=0.9626111388206482, loss=0.08215256780385971
test: epoch 130, loss 0.27204152941703796, acc=0.9083333611488342, loss=0.27204152941703796
train: epoch 131, loss 0.09269576519727707, acc=0.9646666646003723, loss=0.09269576519727707
test: epoch 131, loss 0.2356109619140625, acc=0.9083333611488342, loss=0.2356109619140625
train: epoch 132, loss 0.07900585979223251, acc=0.9655555486679077, loss=0.07900585979223251
test: epoch 132, loss 0.3179662525653839, acc=0.9083333611488342, loss=0.3179662525653839
train: epoch 133, loss 0.0815003290772438, acc=0.9623333215713501, loss=0.0815003290772438
test: epoch 133, loss 0.2521789073944092, acc=0.9083333611488342, loss=0.2521789073944092
train: epoch 134, loss 0.08530334383249283, acc=0.9647777676582336, loss=0.08530334383249283
test: epoch 134, loss 0.2947210669517517, acc=0.9083333611488342, loss=0.2947210669517517
train: epoch 135, loss 0.09274233877658844, acc=0.9593333601951599, loss=0.09274233877658844
test: epoch 135, loss 0.24018067121505737, acc=0.9083333611488342, loss=0.24018067121505737
train: epoch 136, loss 0.07443778961896896, acc=0.9642778038978577, loss=0.07443778961896896
test: epoch 136, loss 0.2366296797990799, acc=0.8999999761581421, loss=0.2366296797990799
train: epoch 137, loss 0.10653875023126602, acc=0.9549999833106995, loss=0.10653875023126602
test: epoch 137, loss 0.26318708062171936, acc=0.8861111402511597, loss=0.26318708062171936
train: epoch 138, loss 0.08169583231210709, acc=0.9622222185134888, loss=0.08169583231210709
test: epoch 138, loss 0.24699868261814117, acc=0.9083333611488342, loss=0.24699868261814117
train: epoch 139, loss 0.08431334793567657, acc=0.9622777700424194, loss=0.08431334793567657
test: epoch 139, loss 0.2511236369609833, acc=0.9083333611488342, loss=0.2511236369609833
train: epoch 140, loss 0.08382643014192581, acc=0.9591110944747925, loss=0.08382643014192581
test: epoch 140, loss 0.3097898066043854, acc=0.9083333611488342, loss=0.3097898066043854
train: epoch 141, loss 0.08851435035467148, acc=0.960444450378418, loss=0.08851435035467148
test: epoch 141, loss 0.2983286678791046, acc=0.9055555462837219, loss=0.2983286678791046
train: epoch 142, loss 0.09042500704526901, acc=0.9622222185134888, loss=0.09042500704526901
test: epoch 142, loss 0.23966921865940094, acc=0.9083333611488342, loss=0.23966921865940094
train: epoch 143, loss 0.08848373591899872, acc=0.960277795791626, loss=0.08848373591899872
test: epoch 143, loss 0.23143836855888367, acc=0.9083333611488342, loss=0.23143836855888367
train: epoch 144, loss 0.07128547132015228, acc=0.9638888835906982, loss=0.07128547132015228
test: epoch 144, loss 0.26655855774879456, acc=0.9083333611488342, loss=0.26655855774879456
train: epoch 145, loss 0.07927940040826797, acc=0.9605000019073486, loss=0.07927940040826797
test: epoch 145, loss 0.36393001675605774, acc=0.9055555462837219, loss=0.36393001675605774
train: epoch 146, loss 0.0895264595746994, acc=0.9616666436195374, loss=0.0895264595746994
test: epoch 146, loss 0.36174216866493225, acc=0.9083333611488342, loss=0.36174216866493225
train: epoch 147, loss 0.08993371576070786, acc=0.9601110816001892, loss=0.08993371576070786
test: epoch 147, loss 0.3464304804801941, acc=0.9027777910232544, loss=0.3464304804801941
train: epoch 148, loss 0.0863286480307579, acc=0.9597777724266052, loss=0.0863286480307579
test: epoch 148, loss 0.24713847041130066, acc=0.9111111164093018, loss=0.24713847041130066
train: epoch 149, loss 0.08056063205003738, acc=0.9620555639266968, loss=0.08056063205003738
test: epoch 149, loss 0.27918094396591187, acc=0.9083333611488342, loss=0.27918094396591187
train: epoch 150, loss 0.09288758784532547, acc=0.9564444422721863, loss=0.09288758784532547
test: epoch 150, loss 0.2231069803237915, acc=0.9083333611488342, loss=0.2231069803237915
