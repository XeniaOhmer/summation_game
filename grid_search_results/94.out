# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=1", "--one_hot=1", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=73603685, receiver_embed_dim=64, save_run=0, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=73603685, receiver_embed_dim=64, save_run=False, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.2146239280700684, acc=0.07072222232818604, loss=3.2146239280700684
test: epoch 1, loss 5.480937957763672, acc=0.06111111119389534, loss=5.480937957763672
train: epoch 2, loss 2.0734143257141113, acc=0.28761109709739685, loss=2.0734143257141113
test: epoch 2, loss 3.8709757328033447, acc=0.14166666567325592, loss=3.8709757328033447
train: epoch 3, loss 1.3292615413665771, acc=0.47822222113609314, loss=1.3292615413665771
test: epoch 3, loss 3.425776481628418, acc=0.16944444179534912, loss=3.425776481628418
train: epoch 4, loss 1.0444376468658447, acc=0.5953888893127441, loss=1.0444376468658447
test: epoch 4, loss 3.6922872066497803, acc=0.1666666716337204, loss=3.6922872066497803
train: epoch 5, loss 0.8828344345092773, acc=0.6692777872085571, loss=0.8828344345092773
test: epoch 5, loss 3.5109426975250244, acc=0.20277777314186096, loss=3.5109426975250244
train: epoch 6, loss 0.765690803527832, acc=0.7140555381774902, loss=0.765690803527832
test: epoch 6, loss 3.3501274585723877, acc=0.21944443881511688, loss=3.3501274585723877
train: epoch 7, loss 0.6779535412788391, acc=0.7496111392974854, loss=0.6779535412788391
test: epoch 7, loss 3.4121854305267334, acc=0.23055554926395416, loss=3.4121854305267334
train: epoch 8, loss 0.5950477123260498, acc=0.7823333144187927, loss=0.5950477123260498
test: epoch 8, loss 3.0904603004455566, acc=0.21111111342906952, loss=3.0904603004455566
train: epoch 9, loss 0.5387188196182251, acc=0.8076666593551636, loss=0.5387188196182251
test: epoch 9, loss 3.4606738090515137, acc=0.22499999403953552, loss=3.4606738090515137
train: epoch 10, loss 0.48671412467956543, acc=0.8259444236755371, loss=0.48671412467956543
test: epoch 10, loss 3.452674388885498, acc=0.23055554926395416, loss=3.452674388885498
train: epoch 11, loss 0.45230013132095337, acc=0.8403888940811157, loss=0.45230013132095337
test: epoch 11, loss 3.815938711166382, acc=0.22777777910232544, loss=3.815938711166382
train: epoch 12, loss 0.423658162355423, acc=0.8554444313049316, loss=0.423658162355423
test: epoch 12, loss 3.6206533908843994, acc=0.25555557012557983, loss=3.6206533908843994
train: epoch 13, loss 0.38720446825027466, acc=0.8657777905464172, loss=0.38720446825027466
test: epoch 13, loss 3.4715523719787598, acc=0.2750000059604645, loss=3.4715523719787598
train: epoch 14, loss 0.3619775176048279, acc=0.8747777938842773, loss=0.3619775176048279
test: epoch 14, loss 3.241241216659546, acc=0.2611111104488373, loss=3.241241216659546
train: epoch 15, loss 0.3318844437599182, acc=0.8855000138282776, loss=0.3318844437599182
test: epoch 15, loss 3.3456666469573975, acc=0.2666666805744171, loss=3.3456666469573975
train: epoch 16, loss 0.3228108584880829, acc=0.8886666893959045, loss=0.3228108584880829
test: epoch 16, loss 3.286069869995117, acc=0.2666666805744171, loss=3.286069869995117
train: epoch 17, loss 0.31182238459587097, acc=0.8941666483879089, loss=0.31182238459587097
test: epoch 17, loss 3.4430007934570312, acc=0.27222222089767456, loss=3.4430007934570312
train: epoch 18, loss 0.28602170944213867, acc=0.9073333144187927, loss=0.28602170944213867
test: epoch 18, loss 3.1823248863220215, acc=0.27222222089767456, loss=3.1823248863220215
train: epoch 19, loss 0.281908243894577, acc=0.9067777991294861, loss=0.281908243894577
test: epoch 19, loss 2.982271432876587, acc=0.31388887763023376, loss=2.982271432876587
train: epoch 20, loss 0.27070578932762146, acc=0.9093888998031616, loss=0.27070578932762146
test: epoch 20, loss 2.939389705657959, acc=0.3055555522441864, loss=2.939389705657959
train: epoch 21, loss 0.25302404165267944, acc=0.9158333539962769, loss=0.25302404165267944
test: epoch 21, loss 3.1455769538879395, acc=0.3166666626930237, loss=3.1455769538879395
train: epoch 22, loss 0.24760185182094574, acc=0.9175000190734863, loss=0.24760185182094574
test: epoch 22, loss 2.7622945308685303, acc=0.28333333134651184, loss=2.7622945308685303
train: epoch 23, loss 0.22942855954170227, acc=0.9275000095367432, loss=0.22942855954170227
test: epoch 23, loss 2.880098819732666, acc=0.2916666567325592, loss=2.880098819732666
train: epoch 24, loss 0.2314242571592331, acc=0.9253333210945129, loss=0.2314242571592331
test: epoch 24, loss 2.4875335693359375, acc=0.35555556416511536, loss=2.4875335693359375
train: epoch 25, loss 0.2209378331899643, acc=0.9299444556236267, loss=0.2209378331899643
test: epoch 25, loss 2.728642702102661, acc=0.35555556416511536, loss=2.728642702102661
train: epoch 26, loss 0.20803551375865936, acc=0.9326111078262329, loss=0.20803551375865936
test: epoch 26, loss 2.6311306953430176, acc=0.32777777314186096, loss=2.6311306953430176
train: epoch 27, loss 0.19339650869369507, acc=0.9386110901832581, loss=0.19339650869369507
test: epoch 27, loss 2.5119287967681885, acc=0.3194444477558136, loss=2.5119287967681885
train: epoch 28, loss 0.1906341165304184, acc=0.9409999847412109, loss=0.1906341165304184
test: epoch 28, loss 2.571584463119507, acc=0.34166666865348816, loss=2.571584463119507
train: epoch 29, loss 0.18280160427093506, acc=0.9399999976158142, loss=0.18280160427093506
test: epoch 29, loss 2.8903446197509766, acc=0.35555556416511536, loss=2.8903446197509766
train: epoch 30, loss 0.1730373054742813, acc=0.9462777972221375, loss=0.1730373054742813
test: epoch 30, loss 3.0669326782226562, acc=0.32777777314186096, loss=3.0669326782226562
train: epoch 31, loss 0.1722223311662674, acc=0.9434999823570251, loss=0.1722223311662674
test: epoch 31, loss 2.9170258045196533, acc=0.34166666865348816, loss=2.9170258045196533
train: epoch 32, loss 0.16550929844379425, acc=0.9483888745307922, loss=0.16550929844379425
test: epoch 32, loss 2.655719757080078, acc=0.3472222089767456, loss=2.655719757080078
train: epoch 33, loss 0.16745878756046295, acc=0.9478333592414856, loss=0.16745878756046295
test: epoch 33, loss 2.5032505989074707, acc=0.3305555582046509, loss=2.5032505989074707
train: epoch 34, loss 0.16180147230625153, acc=0.9514444470405579, loss=0.16180147230625153
test: epoch 34, loss 2.8806374073028564, acc=0.3499999940395355, loss=2.8806374073028564
train: epoch 35, loss 0.15855932235717773, acc=0.9493333101272583, loss=0.15855932235717773
test: epoch 35, loss 2.8159115314483643, acc=0.32499998807907104, loss=2.8159115314483643
train: epoch 36, loss 0.14950841665267944, acc=0.9517222046852112, loss=0.14950841665267944
test: epoch 36, loss 2.6359963417053223, acc=0.3444444537162781, loss=2.6359963417053223
train: epoch 37, loss 0.13934297859668732, acc=0.9541666507720947, loss=0.13934297859668732
test: epoch 37, loss 2.4656693935394287, acc=0.36944442987442017, loss=2.4656693935394287
train: epoch 38, loss 0.14410755038261414, acc=0.9553889036178589, loss=0.14410755038261414
test: epoch 38, loss 2.99504017829895, acc=0.2805555462837219, loss=2.99504017829895
train: epoch 39, loss 0.14196787774562836, acc=0.9559999704360962, loss=0.14196787774562836
test: epoch 39, loss 2.503998279571533, acc=0.4027777910232544, loss=2.503998279571533
train: epoch 40, loss 0.13341104984283447, acc=0.9579444527626038, loss=0.13341104984283447
test: epoch 40, loss 2.823810577392578, acc=0.3333333432674408, loss=2.823810577392578
train: epoch 41, loss 0.13180041313171387, acc=0.9585000276565552, loss=0.13180041313171387
test: epoch 41, loss 2.6556994915008545, acc=0.35277777910232544, loss=2.6556994915008545
train: epoch 42, loss 0.12462704628705978, acc=0.9628333449363708, loss=0.12462704628705978
test: epoch 42, loss 2.838101863861084, acc=0.32499998807907104, loss=2.838101863861084
train: epoch 43, loss 0.13735023140907288, acc=0.9601110816001892, loss=0.13735023140907288
test: epoch 43, loss 2.598816394805908, acc=0.35277777910232544, loss=2.598816394805908
train: epoch 44, loss 0.13469800353050232, acc=0.9589444398880005, loss=0.13469800353050232
test: epoch 44, loss 2.7799506187438965, acc=0.35555556416511536, loss=2.7799506187438965
train: epoch 45, loss 0.13180936872959137, acc=0.9611111283302307, loss=0.13180936872959137
test: epoch 45, loss 2.6846911907196045, acc=0.3083333373069763, loss=2.6846911907196045
train: epoch 46, loss 0.11521760374307632, acc=0.964888870716095, loss=0.11521760374307632
test: epoch 46, loss 2.3685925006866455, acc=0.3722222149372101, loss=2.3685925006866455
train: epoch 47, loss 0.1257755607366562, acc=0.9639999866485596, loss=0.1257755607366562
test: epoch 47, loss 2.3056507110595703, acc=0.3777777850627899, loss=2.3056507110595703
train: epoch 48, loss 0.12123122066259384, acc=0.9638888835906982, loss=0.12123122066259384
test: epoch 48, loss 2.409538984298706, acc=0.38055557012557983, loss=2.409538984298706
train: epoch 49, loss 0.11597254872322083, acc=0.9627777934074402, loss=0.11597254872322083
test: epoch 49, loss 2.3275814056396484, acc=0.3638888895511627, loss=2.3275814056396484
train: epoch 50, loss 0.10849401354789734, acc=0.9667778015136719, loss=0.10849401354789734
test: epoch 50, loss 2.4400393962860107, acc=0.40833333134651184, loss=2.4400393962860107
train: epoch 51, loss 0.11085180193185806, acc=0.9680555462837219, loss=0.11085180193185806
test: epoch 51, loss 2.3972771167755127, acc=0.4305555522441864, loss=2.3972771167755127
train: epoch 52, loss 0.10381519049406052, acc=0.9679444432258606, loss=0.10381519049406052
test: epoch 52, loss 2.2526323795318604, acc=0.4138889014720917, loss=2.2526323795318604
train: epoch 53, loss 0.10196805745363235, acc=0.9697222113609314, loss=0.10196805745363235
test: epoch 53, loss 2.6255064010620117, acc=0.3722222149372101, loss=2.6255064010620117
train: epoch 54, loss 0.09634605050086975, acc=0.9710555672645569, loss=0.09634605050086975
test: epoch 54, loss 2.654738187789917, acc=0.3777777850627899, loss=2.654738187789917
train: epoch 55, loss 0.0944000631570816, acc=0.9698888659477234, loss=0.0944000631570816
test: epoch 55, loss 2.7402966022491455, acc=0.4000000059604645, loss=2.7402966022491455
train: epoch 56, loss 0.10581011325120926, acc=0.9680555462837219, loss=0.10581011325120926
test: epoch 56, loss 2.6723945140838623, acc=0.3916666805744171, loss=2.6723945140838623
train: epoch 57, loss 0.10054346174001694, acc=0.9716110825538635, loss=0.10054346174001694
test: epoch 57, loss 2.209169626235962, acc=0.3916666805744171, loss=2.209169626235962
train: epoch 58, loss 0.10283862799406052, acc=0.9693333506584167, loss=0.10283862799406052
test: epoch 58, loss 2.562302350997925, acc=0.3722222149372101, loss=2.562302350997925
train: epoch 59, loss 0.09233582019805908, acc=0.972611129283905, loss=0.09233582019805908
test: epoch 59, loss 2.5403599739074707, acc=0.3916666805744171, loss=2.5403599739074707
train: epoch 60, loss 0.09477370977401733, acc=0.9719444513320923, loss=0.09477370977401733
test: epoch 60, loss 2.526919364929199, acc=0.4000000059604645, loss=2.526919364929199
train: epoch 61, loss 0.08984757959842682, acc=0.972944438457489, loss=0.08984757959842682
test: epoch 61, loss 2.053131103515625, acc=0.4583333432674408, loss=2.053131103515625
train: epoch 62, loss 0.08669567108154297, acc=0.9740555286407471, loss=0.08669567108154297
test: epoch 62, loss 2.381150245666504, acc=0.4305555522441864, loss=2.381150245666504
train: epoch 63, loss 0.08643194288015366, acc=0.9737777709960938, loss=0.08643194288015366
test: epoch 63, loss 2.296603202819824, acc=0.4333333373069763, loss=2.296603202819824
train: epoch 64, loss 0.07980548590421677, acc=0.9760555624961853, loss=0.07980548590421677
test: epoch 64, loss 2.4703097343444824, acc=0.40833333134651184, loss=2.4703097343444824
train: epoch 65, loss 0.0890280082821846, acc=0.9727222323417664, loss=0.0890280082821846
test: epoch 65, loss 2.6723015308380127, acc=0.42222222685813904, loss=2.6723015308380127
train: epoch 66, loss 0.08866745978593826, acc=0.9735000133514404, loss=0.08866745978593826
test: epoch 66, loss 2.4868345260620117, acc=0.43888887763023376, loss=2.4868345260620117
train: epoch 67, loss 0.08320876210927963, acc=0.9737222194671631, loss=0.08320876210927963
test: epoch 67, loss 2.0462489128112793, acc=0.4416666626930237, loss=2.0462489128112793
train: epoch 68, loss 0.09014622122049332, acc=0.9713888764381409, loss=0.09014622122049332
test: epoch 68, loss 2.4014041423797607, acc=0.41111111640930176, loss=2.4014041423797607
train: epoch 69, loss 0.07697945088148117, acc=0.9761666655540466, loss=0.07697945088148117
test: epoch 69, loss 2.2557950019836426, acc=0.45277777314186096, loss=2.2557950019836426
train: epoch 70, loss 0.07590681314468384, acc=0.977222204208374, loss=0.07590681314468384
test: epoch 70, loss 2.317741870880127, acc=0.4583333432674408, loss=2.317741870880127
train: epoch 71, loss 0.08419870585203171, acc=0.9761666655540466, loss=0.08419870585203171
test: epoch 71, loss 2.998134136199951, acc=0.39444443583488464, loss=2.998134136199951
train: epoch 72, loss 0.08118288218975067, acc=0.9765555262565613, loss=0.08118288218975067
test: epoch 72, loss 2.3602218627929688, acc=0.4555555582046509, loss=2.3602218627929688
train: epoch 73, loss 0.07593470066785812, acc=0.9778888821601868, loss=0.07593470066785812
test: epoch 73, loss 2.480851411819458, acc=0.4138889014720917, loss=2.480851411819458
train: epoch 74, loss 0.07788445055484772, acc=0.9771666526794434, loss=0.07788445055484772
test: epoch 74, loss 2.5134735107421875, acc=0.44999998807907104, loss=2.5134735107421875
train: epoch 75, loss 0.0759018138051033, acc=0.9775555729866028, loss=0.0759018138051033
test: epoch 75, loss 2.6271400451660156, acc=0.43611112236976624, loss=2.6271400451660156
train: epoch 76, loss 0.075231172144413, acc=0.9781666398048401, loss=0.075231172144413
test: epoch 76, loss 2.197110414505005, acc=0.4583333432674408, loss=2.197110414505005
train: epoch 77, loss 0.06394685059785843, acc=0.9804999828338623, loss=0.06394685059785843
test: epoch 77, loss 2.381356716156006, acc=0.45277777314186096, loss=2.381356716156006
train: epoch 78, loss 0.08186890929937363, acc=0.977222204208374, loss=0.08186890929937363
test: epoch 78, loss 2.0926358699798584, acc=0.4583333432674408, loss=2.0926358699798584
train: epoch 79, loss 0.07553297281265259, acc=0.9766666889190674, loss=0.07553297281265259
test: epoch 79, loss 2.3428549766540527, acc=0.4611110985279083, loss=2.3428549766540527
train: epoch 80, loss 0.07450438290834427, acc=0.9793333411216736, loss=0.07450438290834427
test: epoch 80, loss 2.2914321422576904, acc=0.45277777314186096, loss=2.2914321422576904
train: epoch 81, loss 0.07097728550434113, acc=0.9766666889190674, loss=0.07097728550434113
test: epoch 81, loss 2.4012274742126465, acc=0.4583333432674408, loss=2.4012274742126465
train: epoch 82, loss 0.06861758977174759, acc=0.9796666502952576, loss=0.06861758977174759
test: epoch 82, loss 2.8508224487304688, acc=0.4333333373069763, loss=2.8508224487304688
train: epoch 83, loss 0.07020353525876999, acc=0.9778333306312561, loss=0.07020353525876999
test: epoch 83, loss 2.5533154010772705, acc=0.43611112236976624, loss=2.5533154010772705
train: epoch 84, loss 0.07086336612701416, acc=0.9785555601119995, loss=0.07086336612701416
test: epoch 84, loss 2.2240467071533203, acc=0.49166667461395264, loss=2.2240467071533203
train: epoch 85, loss 0.0704619437456131, acc=0.9806110858917236, loss=0.0704619437456131
test: epoch 85, loss 2.5758824348449707, acc=0.4722222089767456, loss=2.5758824348449707
train: epoch 86, loss 0.0653817281126976, acc=0.9807222485542297, loss=0.0653817281126976
test: epoch 86, loss 2.4805893898010254, acc=0.4749999940395355, loss=2.4805893898010254
train: epoch 87, loss 0.06279976665973663, acc=0.9818888902664185, loss=0.06279976665973663
test: epoch 87, loss 2.4602138996124268, acc=0.46666666865348816, loss=2.4602138996124268
train: epoch 88, loss 0.06351079791784286, acc=0.9817222356796265, loss=0.06351079791784286
test: epoch 88, loss 2.6943836212158203, acc=0.42500001192092896, loss=2.6943836212158203
train: epoch 89, loss 0.06696175783872604, acc=0.9806110858917236, loss=0.06696175783872604
test: epoch 89, loss 2.5064754486083984, acc=0.46666666865348816, loss=2.5064754486083984
train: epoch 90, loss 0.07728777825832367, acc=0.9797777533531189, loss=0.07728777825832367
test: epoch 90, loss 2.2407851219177246, acc=0.48055556416511536, loss=2.2407851219177246
train: epoch 91, loss 0.05746748670935631, acc=0.9837222099304199, loss=0.05746748670935631
test: epoch 91, loss 2.5429000854492188, acc=0.43888887763023376, loss=2.5429000854492188
train: epoch 92, loss 0.06846197694540024, acc=0.9814444184303284, loss=0.06846197694540024
test: epoch 92, loss 2.3540802001953125, acc=0.4749999940395355, loss=2.3540802001953125
train: epoch 93, loss 0.05718977376818657, acc=0.9831110835075378, loss=0.05718977376818657
test: epoch 93, loss 2.8475072383880615, acc=0.4194444417953491, loss=2.8475072383880615
train: epoch 94, loss 0.059785615652799606, acc=0.983222246170044, loss=0.059785615652799606
test: epoch 94, loss 2.3912503719329834, acc=0.4972222149372101, loss=2.3912503719329834
train: epoch 95, loss 0.057847749441862106, acc=0.9838888645172119, loss=0.057847749441862106
test: epoch 95, loss 2.28594970703125, acc=0.49166667461395264, loss=2.28594970703125
train: epoch 96, loss 0.05591963976621628, acc=0.9860000014305115, loss=0.05591963976621628
test: epoch 96, loss 2.65395450592041, acc=0.4888888895511627, loss=2.65395450592041
train: epoch 97, loss 0.05754022300243378, acc=0.9846110939979553, loss=0.05754022300243378
test: epoch 97, loss 2.5584352016448975, acc=0.4722222089767456, loss=2.5584352016448975
train: epoch 98, loss 0.04937227815389633, acc=0.9850000143051147, loss=0.04937227815389633
test: epoch 98, loss 2.559584856033325, acc=0.4972222149372101, loss=2.559584856033325
train: epoch 99, loss 0.07078881561756134, acc=0.9831110835075378, loss=0.07078881561756134
test: epoch 99, loss 2.624249219894409, acc=0.47777777910232544, loss=2.624249219894409
train: epoch 100, loss 0.05412759631872177, acc=0.9851666688919067, loss=0.05412759631872177
test: epoch 100, loss 2.3628957271575928, acc=0.49166667461395264, loss=2.3628957271575928
train: epoch 101, loss 0.05484509468078613, acc=0.9851666688919067, loss=0.05484509468078613
test: epoch 101, loss 2.519364356994629, acc=0.4749999940395355, loss=2.519364356994629
train: epoch 102, loss 0.05132265016436577, acc=0.9851111173629761, loss=0.05132265016436577
test: epoch 102, loss 2.3953967094421387, acc=0.49166667461395264, loss=2.3953967094421387
train: epoch 103, loss 0.05415596440434456, acc=0.9844444394111633, loss=0.05415596440434456
test: epoch 103, loss 2.4822916984558105, acc=0.5, loss=2.4822916984558105
train: epoch 104, loss 0.04710542410612106, acc=0.9878333210945129, loss=0.04710542410612106
test: epoch 104, loss 2.88718581199646, acc=0.45277777314186096, loss=2.88718581199646
train: epoch 105, loss 0.051750630140304565, acc=0.9842777848243713, loss=0.051750630140304565
test: epoch 105, loss 2.2750842571258545, acc=0.5166666507720947, loss=2.2750842571258545
train: epoch 106, loss 0.041337285190820694, acc=0.9884999990463257, loss=0.041337285190820694
test: epoch 106, loss 2.2931182384490967, acc=0.5, loss=2.2931182384490967
train: epoch 107, loss 0.041252948343753815, acc=0.9879999756813049, loss=0.041252948343753815
test: epoch 107, loss 2.675321578979492, acc=0.4888888895511627, loss=2.675321578979492
train: epoch 108, loss 0.049833256751298904, acc=0.9871110916137695, loss=0.049833256751298904
test: epoch 108, loss 2.4936461448669434, acc=0.4888888895511627, loss=2.4936461448669434
train: epoch 109, loss 0.04963971674442291, acc=0.9866111278533936, loss=0.04963971674442291
test: epoch 109, loss 2.5310568809509277, acc=0.5333333611488342, loss=2.5310568809509277
train: epoch 110, loss 0.04746077209711075, acc=0.9860000014305115, loss=0.04746077209711075
test: epoch 110, loss 2.462639093399048, acc=0.5083333253860474, loss=2.462639093399048
train: epoch 111, loss 0.05353686586022377, acc=0.9857777953147888, loss=0.05353686586022377
test: epoch 111, loss 2.466930866241455, acc=0.49166667461395264, loss=2.466930866241455
train: epoch 112, loss 0.04352647438645363, acc=0.9881666898727417, loss=0.04352647438645363
test: epoch 112, loss 2.4135851860046387, acc=0.5277777910232544, loss=2.4135851860046387
train: epoch 113, loss 0.05342860519886017, acc=0.9865555763244629, loss=0.05342860519886017
test: epoch 113, loss 2.318859338760376, acc=0.5416666865348816, loss=2.318859338760376
train: epoch 114, loss 0.04704379290342331, acc=0.9877222180366516, loss=0.04704379290342331
test: epoch 114, loss 2.5143473148345947, acc=0.4888888895511627, loss=2.5143473148345947
train: epoch 115, loss 0.05684030428528786, acc=0.9865000247955322, loss=0.05684030428528786
test: epoch 115, loss 2.356945514678955, acc=0.5333333611488342, loss=2.356945514678955
train: epoch 116, loss 0.03866569325327873, acc=0.988444447517395, loss=0.03866569325327873
test: epoch 116, loss 2.541851758956909, acc=0.5249999761581421, loss=2.541851758956909
train: epoch 117, loss 0.04774702340364456, acc=0.9871110916137695, loss=0.04774702340364456
test: epoch 117, loss 2.568880319595337, acc=0.5444444417953491, loss=2.568880319595337
train: epoch 118, loss 0.041044931858778, acc=0.988277792930603, loss=0.041044931858778
test: epoch 118, loss 2.177025318145752, acc=0.5361111164093018, loss=2.177025318145752
train: epoch 119, loss 0.04407826066017151, acc=0.9877222180366516, loss=0.04407826066017151
test: epoch 119, loss 2.1553962230682373, acc=0.5638889074325562, loss=2.1553962230682373
train: epoch 120, loss 0.0369761660695076, acc=0.9894444346427917, loss=0.0369761660695076
test: epoch 120, loss 1.9659987688064575, acc=0.574999988079071, loss=1.9659987688064575
train: epoch 121, loss 0.049438588321208954, acc=0.9868333339691162, loss=0.049438588321208954
test: epoch 121, loss 2.61277437210083, acc=0.5249999761581421, loss=2.61277437210083
train: epoch 122, loss 0.04173804447054863, acc=0.9892777800559998, loss=0.04173804447054863
test: epoch 122, loss 2.637347459793091, acc=0.5444444417953491, loss=2.637347459793091
train: epoch 123, loss 0.040267664939165115, acc=0.9893333315849304, loss=0.040267664939165115
test: epoch 123, loss 2.5015273094177246, acc=0.5249999761581421, loss=2.5015273094177246
train: epoch 124, loss 0.051290158182382584, acc=0.9869999885559082, loss=0.051290158182382584
test: epoch 124, loss 2.3305985927581787, acc=0.5722222328186035, loss=2.3305985927581787
train: epoch 125, loss 0.03691547363996506, acc=0.9894999861717224, loss=0.03691547363996506
test: epoch 125, loss 2.362891912460327, acc=0.5083333253860474, loss=2.362891912460327
train: epoch 126, loss 0.04132143408060074, acc=0.9890000224113464, loss=0.04132143408060074
test: epoch 126, loss 2.801145076751709, acc=0.5083333253860474, loss=2.801145076751709
train: epoch 127, loss 0.03945046663284302, acc=0.9900000095367432, loss=0.03945046663284302
test: epoch 127, loss 2.9764955043792725, acc=0.5444444417953491, loss=2.9764955043792725
train: epoch 128, loss 0.04038356617093086, acc=0.9882222414016724, loss=0.04038356617093086
test: epoch 128, loss 2.5070929527282715, acc=0.49444442987442017, loss=2.5070929527282715
train: epoch 129, loss 0.03624612092971802, acc=0.9892777800559998, loss=0.03624612092971802
test: epoch 129, loss 2.343656539916992, acc=0.5249999761581421, loss=2.343656539916992
train: epoch 130, loss 0.036629609763622284, acc=0.9886666536331177, loss=0.036629609763622284
test: epoch 130, loss 2.4430792331695557, acc=0.5111111402511597, loss=2.4430792331695557
train: epoch 131, loss 0.03728446736931801, acc=0.9900555610656738, loss=0.03728446736931801
test: epoch 131, loss 2.1824753284454346, acc=0.5333333611488342, loss=2.1824753284454346
train: epoch 132, loss 0.03695005178451538, acc=0.9909444451332092, loss=0.03695005178451538
test: epoch 132, loss 2.4159514904022217, acc=0.5333333611488342, loss=2.4159514904022217
train: epoch 133, loss 0.03947680816054344, acc=0.9900000095367432, loss=0.03947680816054344
test: epoch 133, loss 2.5811820030212402, acc=0.5277777910232544, loss=2.5811820030212402
train: epoch 134, loss 0.037054434418678284, acc=0.9896666407585144, loss=0.037054434418678284
test: epoch 134, loss 2.251908779144287, acc=0.49444442987442017, loss=2.251908779144287
train: epoch 135, loss 0.04457419738173485, acc=0.9877222180366516, loss=0.04457419738173485
test: epoch 135, loss 2.7347729206085205, acc=0.5083333253860474, loss=2.7347729206085205
train: epoch 136, loss 0.03663143143057823, acc=0.988777756690979, loss=0.03663143143057823
test: epoch 136, loss 2.5669901371002197, acc=0.5527777671813965, loss=2.5669901371002197
train: epoch 137, loss 0.03646974265575409, acc=0.9902222156524658, loss=0.03646974265575409
test: epoch 137, loss 2.894167900085449, acc=0.5472221970558167, loss=2.894167900085449
train: epoch 138, loss 0.03624005615711212, acc=0.9898333549499512, loss=0.03624005615711212
test: epoch 138, loss 2.3445420265197754, acc=0.5611110925674438, loss=2.3445420265197754
train: epoch 139, loss 0.03682389482855797, acc=0.9906111359596252, loss=0.03682389482855797
test: epoch 139, loss 2.2917518615722656, acc=0.5055555701255798, loss=2.2917518615722656
train: epoch 140, loss 0.03778187930583954, acc=0.9889444708824158, loss=0.03778187930583954
test: epoch 140, loss 2.2947583198547363, acc=0.5472221970558167, loss=2.2947583198547363
train: epoch 141, loss 0.04042494297027588, acc=0.9891666769981384, loss=0.04042494297027588
test: epoch 141, loss 2.1067826747894287, acc=0.5638889074325562, loss=2.1067826747894287
train: epoch 142, loss 0.03545597568154335, acc=0.9904999732971191, loss=0.03545597568154335
test: epoch 142, loss 2.1664321422576904, acc=0.5611110925674438, loss=2.1664321422576904
train: epoch 143, loss 0.030694253742694855, acc=0.9915555715560913, loss=0.030694253742694855
test: epoch 143, loss 2.45902419090271, acc=0.5666666626930237, loss=2.45902419090271
train: epoch 144, loss 0.0363871268928051, acc=0.9901111125946045, loss=0.0363871268928051
test: epoch 144, loss 2.2654457092285156, acc=0.5444444417953491, loss=2.2654457092285156
train: epoch 145, loss 0.0368015356361866, acc=0.9897778034210205, loss=0.0368015356361866
test: epoch 145, loss 2.282878875732422, acc=0.5555555820465088, loss=2.282878875732422
train: epoch 146, loss 0.03150380030274391, acc=0.9913889169692993, loss=0.03150380030274391
test: epoch 146, loss 2.1100735664367676, acc=0.5805555582046509, loss=2.1100735664367676
train: epoch 147, loss 0.03829128295183182, acc=0.9894999861717224, loss=0.03829128295183182
test: epoch 147, loss 2.6688923835754395, acc=0.5388888716697693, loss=2.6688923835754395
train: epoch 148, loss 0.038932912051677704, acc=0.9903888702392578, loss=0.038932912051677704
test: epoch 148, loss 2.638052463531494, acc=0.550000011920929, loss=2.638052463531494
train: epoch 149, loss 0.03965475782752037, acc=0.9896110892295837, loss=0.03965475782752037
test: epoch 149, loss 2.5350253582000732, acc=0.5555555820465088, loss=2.5350253582000732
train: epoch 150, loss 0.03864634409546852, acc=0.9907222390174866, loss=0.03864634409546852
test: epoch 150, loss 2.22737193107605, acc=0.5638889074325562, loss=2.22737193107605
