# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=1", "--one_hot=false", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=403065473, receiver_embed_dim=64, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.8077199459075928, acc=0.10805555433034897, loss=2.8077199459075928
test: epoch 1, loss 3.832699775695801, acc=0.10000000149011612, loss=3.832699775695801
train: epoch 2, loss 1.6009864807128906, acc=0.36322221159935, loss=1.6009864807128906
test: epoch 2, loss 4.347148895263672, acc=0.1805555522441864, loss=4.347148895263672
train: epoch 3, loss 1.070862889289856, acc=0.5645555257797241, loss=1.070862889289856
test: epoch 3, loss 3.52789306640625, acc=0.20277777314186096, loss=3.52789306640625
train: epoch 4, loss 0.8126370310783386, acc=0.6809999942779541, loss=0.8126370310783386
test: epoch 4, loss 2.661221742630005, acc=0.33888888359069824, loss=2.661221742630005
train: epoch 5, loss 0.6317517757415771, acc=0.7541666626930237, loss=0.6317517757415771
test: epoch 5, loss 2.726491928100586, acc=0.3333333432674408, loss=2.726491928100586
train: epoch 6, loss 0.5290107131004333, acc=0.7918333411216736, loss=0.5290107131004333
test: epoch 6, loss 2.8064920902252197, acc=0.3361110985279083, loss=2.8064920902252197
train: epoch 7, loss 0.46989351511001587, acc=0.8177222013473511, loss=0.46989351511001587
test: epoch 7, loss 2.561908006668091, acc=0.31111112236976624, loss=2.561908006668091
train: epoch 8, loss 0.4039178788661957, acc=0.8474444150924683, loss=0.4039178788661957
test: epoch 8, loss 2.3541715145111084, acc=0.3222222328186035, loss=2.3541715145111084
train: epoch 9, loss 0.38249439001083374, acc=0.8576666712760925, loss=0.38249439001083374
test: epoch 9, loss 2.1013171672821045, acc=0.38333332538604736, loss=2.1013171672821045
train: epoch 10, loss 0.3217005133628845, acc=0.8823333382606506, loss=0.3217005133628845
test: epoch 10, loss 2.493440866470337, acc=0.34166666865348816, loss=2.493440866470337
train: epoch 11, loss 0.2910313010215759, acc=0.9017778038978577, loss=0.2910313010215759
test: epoch 11, loss 2.793288230895996, acc=0.32777777314186096, loss=2.793288230895996
train: epoch 12, loss 0.26277393102645874, acc=0.9105555415153503, loss=0.26277393102645874
test: epoch 12, loss 2.647573232650757, acc=0.33888888359069824, loss=2.647573232650757
train: epoch 13, loss 0.24944782257080078, acc=0.9148333072662354, loss=0.24944782257080078
test: epoch 13, loss 2.0715513229370117, acc=0.38333332538604736, loss=2.0715513229370117
train: epoch 14, loss 0.25914955139160156, acc=0.9100000262260437, loss=0.25914955139160156
test: epoch 14, loss 2.7300662994384766, acc=0.34166666865348816, loss=2.7300662994384766
train: epoch 15, loss 0.21547283232212067, acc=0.9268333315849304, loss=0.21547283232212067
test: epoch 15, loss 2.2697248458862305, acc=0.42222222685813904, loss=2.2697248458862305
train: epoch 16, loss 0.21190094947814941, acc=0.926111102104187, loss=0.21190094947814941
test: epoch 16, loss 2.021906852722168, acc=0.3861111104488373, loss=2.021906852722168
train: epoch 17, loss 0.1773441582918167, acc=0.9361110925674438, loss=0.1773441582918167
test: epoch 17, loss 1.8999390602111816, acc=0.36666667461395264, loss=1.8999390602111816
train: epoch 18, loss 0.1968306452035904, acc=0.9316666722297668, loss=0.1968306452035904
test: epoch 18, loss 2.1396138668060303, acc=0.43888887763023376, loss=2.1396138668060303
train: epoch 19, loss 0.18025358021259308, acc=0.9373888969421387, loss=0.18025358021259308
test: epoch 19, loss 1.681697964668274, acc=0.4305555522441864, loss=1.681697964668274
train: epoch 20, loss 0.16831068694591522, acc=0.9423333406448364, loss=0.16831068694591522
test: epoch 20, loss 2.1041910648345947, acc=0.4305555522441864, loss=2.1041910648345947
train: epoch 21, loss 0.1637212634086609, acc=0.9459444284439087, loss=0.1637212634086609
test: epoch 21, loss 2.062892436981201, acc=0.42222222685813904, loss=2.062892436981201
train: epoch 22, loss 0.1710204929113388, acc=0.9396666884422302, loss=0.1710204929113388
test: epoch 22, loss 2.826676607131958, acc=0.38333332538604736, loss=2.826676607131958
train: epoch 23, loss 0.14544405043125153, acc=0.9508888721466064, loss=0.14544405043125153
test: epoch 23, loss 1.6174308061599731, acc=0.39444443583488464, loss=1.6174308061599731
train: epoch 24, loss 0.1551196277141571, acc=0.9456666707992554, loss=0.1551196277141571
test: epoch 24, loss 2.2168667316436768, acc=0.3472222089767456, loss=2.2168667316436768
train: epoch 25, loss 0.13329988718032837, acc=0.9523333311080933, loss=0.13329988718032837
test: epoch 25, loss 2.3435747623443604, acc=0.39444443583488464, loss=2.3435747623443604
train: epoch 26, loss 0.13672518730163574, acc=0.9558333158493042, loss=0.13672518730163574
test: epoch 26, loss 2.3766722679138184, acc=0.375, loss=2.3766722679138184
train: epoch 27, loss 0.13004377484321594, acc=0.9568889141082764, loss=0.13004377484321594
test: epoch 27, loss 2.756899118423462, acc=0.3583333194255829, loss=2.756899118423462
train: epoch 28, loss 0.11098466068506241, acc=0.9632777571678162, loss=0.11098466068506241
test: epoch 28, loss 2.5042498111724854, acc=0.44999998807907104, loss=2.5042498111724854
train: epoch 29, loss 0.12628166377544403, acc=0.956944465637207, loss=0.12628166377544403
test: epoch 29, loss 2.6620445251464844, acc=0.375, loss=2.6620445251464844
train: epoch 30, loss 0.11501641571521759, acc=0.9607222080230713, loss=0.11501641571521759
test: epoch 30, loss 3.1110217571258545, acc=0.38333332538604736, loss=3.1110217571258545
train: epoch 31, loss 0.10515954345464706, acc=0.9648333191871643, loss=0.10515954345464706
test: epoch 31, loss 2.927795171737671, acc=0.4027777910232544, loss=2.927795171737671
train: epoch 32, loss 0.09510251879692078, acc=0.9686111211776733, loss=0.09510251879692078
test: epoch 32, loss 1.8441269397735596, acc=0.4472222328186035, loss=1.8441269397735596
train: epoch 33, loss 0.10616903752088547, acc=0.9657777547836304, loss=0.10616903752088547
test: epoch 33, loss 2.3523311614990234, acc=0.4055555462837219, loss=2.3523311614990234
train: epoch 34, loss 0.09933634102344513, acc=0.9664999842643738, loss=0.09933634102344513
test: epoch 34, loss 2.9294841289520264, acc=0.4138889014720917, loss=2.9294841289520264
train: epoch 35, loss 0.09129414707422256, acc=0.969944417476654, loss=0.09129414707422256
test: epoch 35, loss 2.3065924644470215, acc=0.46666666865348816, loss=2.3065924644470215
train: epoch 36, loss 0.08297298848628998, acc=0.9739444255828857, loss=0.08297298848628998
test: epoch 36, loss 2.0917131900787354, acc=0.4972222149372101, loss=2.0917131900787354
train: epoch 37, loss 0.08376101404428482, acc=0.9721666574478149, loss=0.08376101404428482
test: epoch 37, loss 2.9751360416412354, acc=0.4305555522441864, loss=2.9751360416412354
train: epoch 38, loss 0.08282468467950821, acc=0.9739999771118164, loss=0.08282468467950821
test: epoch 38, loss 2.6922357082366943, acc=0.39444443583488464, loss=2.6922357082366943
train: epoch 39, loss 0.08362702280282974, acc=0.9725555777549744, loss=0.08362702280282974
test: epoch 39, loss 2.535020351409912, acc=0.42222222685813904, loss=2.535020351409912
train: epoch 40, loss 0.07250114530324936, acc=0.9765555262565613, loss=0.07250114530324936
test: epoch 40, loss 2.461712598800659, acc=0.3722222149372101, loss=2.461712598800659
train: epoch 41, loss 0.07118495553731918, acc=0.9787222146987915, loss=0.07118495553731918
test: epoch 41, loss 2.5264973640441895, acc=0.4277777671813965, loss=2.5264973640441895
train: epoch 42, loss 0.06832113116979599, acc=0.9793333411216736, loss=0.06832113116979599
test: epoch 42, loss 2.5044894218444824, acc=0.49166667461395264, loss=2.5044894218444824
train: epoch 43, loss 0.07276894897222519, acc=0.9779999852180481, loss=0.07276894897222519
test: epoch 43, loss 2.871533155441284, acc=0.42222222685813904, loss=2.871533155441284
train: epoch 44, loss 0.07080285996198654, acc=0.9784444570541382, loss=0.07080285996198654
test: epoch 44, loss 2.0155186653137207, acc=0.5277777910232544, loss=2.0155186653137207
train: epoch 45, loss 0.05792522430419922, acc=0.9821110963821411, loss=0.05792522430419922
test: epoch 45, loss 2.802276134490967, acc=0.4055555462837219, loss=2.802276134490967
train: epoch 46, loss 0.05910876765847206, acc=0.981166660785675, loss=0.05910876765847206
test: epoch 46, loss 2.7470476627349854, acc=0.38333332538604736, loss=2.7470476627349854
train: epoch 47, loss 0.05139490216970444, acc=0.9837222099304199, loss=0.05139490216970444
test: epoch 47, loss 2.3158960342407227, acc=0.4444444477558136, loss=2.3158960342407227
train: epoch 48, loss 0.06859215348958969, acc=0.9787222146987915, loss=0.06859215348958969
test: epoch 48, loss 2.6921727657318115, acc=0.4722222089767456, loss=2.6921727657318115
train: epoch 49, loss 0.05843948945403099, acc=0.9835000038146973, loss=0.05843948945403099
test: epoch 49, loss 2.7476019859313965, acc=0.4583333432674408, loss=2.7476019859313965
train: epoch 50, loss 0.05976037681102753, acc=0.9821110963821411, loss=0.05976037681102753
test: epoch 50, loss 2.5551199913024902, acc=0.4972222149372101, loss=2.5551199913024902
train: epoch 51, loss 0.05098014697432518, acc=0.9854999780654907, loss=0.05098014697432518
test: epoch 51, loss 2.4856419563293457, acc=0.49166667461395264, loss=2.4856419563293457
train: epoch 52, loss 0.04837401211261749, acc=0.9858888983726501, loss=0.04837401211261749
test: epoch 52, loss 2.311317205429077, acc=0.5333333611488342, loss=2.311317205429077
train: epoch 53, loss 0.0449497252702713, acc=0.9866666793823242, loss=0.0449497252702713
test: epoch 53, loss 2.613461971282959, acc=0.49166667461395264, loss=2.613461971282959
train: epoch 54, loss 0.04996239393949509, acc=0.98416668176651, loss=0.04996239393949509
test: epoch 54, loss 2.677675724029541, acc=0.47777777910232544, loss=2.677675724029541
train: epoch 55, loss 0.05051888898015022, acc=0.9854999780654907, loss=0.05051888898015022
test: epoch 55, loss 2.80741548538208, acc=0.5388888716697693, loss=2.80741548538208
train: epoch 56, loss 0.044371284544467926, acc=0.9877777695655823, loss=0.044371284544467926
test: epoch 56, loss 2.4979851245880127, acc=0.4972222149372101, loss=2.4979851245880127
train: epoch 57, loss 0.04348627105355263, acc=0.987333357334137, loss=0.04348627105355263
test: epoch 57, loss 2.859443187713623, acc=0.5305555462837219, loss=2.859443187713623
train: epoch 58, loss 0.04953037574887276, acc=0.9858888983726501, loss=0.04953037574887276
test: epoch 58, loss 2.1347928047180176, acc=0.5805555582046509, loss=2.1347928047180176
train: epoch 59, loss 0.03451251611113548, acc=0.9900000095367432, loss=0.03451251611113548
test: epoch 59, loss 2.3923819065093994, acc=0.5805555582046509, loss=2.3923819065093994
train: epoch 60, loss 0.049427181482315063, acc=0.9857222437858582, loss=0.049427181482315063
test: epoch 60, loss 2.0121681690216064, acc=0.5694444179534912, loss=2.0121681690216064
train: epoch 61, loss 0.03026406653225422, acc=0.9903333187103271, loss=0.03026406653225422
test: epoch 61, loss 1.9636988639831543, acc=0.625, loss=1.9636988639831543
train: epoch 62, loss 0.03788037225604057, acc=0.988777756690979, loss=0.03788037225604057
test: epoch 62, loss 2.169464111328125, acc=0.5333333611488342, loss=2.169464111328125
train: epoch 63, loss 0.035763051360845566, acc=0.9896110892295837, loss=0.035763051360845566
test: epoch 63, loss 2.3812220096588135, acc=0.5805555582046509, loss=2.3812220096588135
train: epoch 64, loss 0.03106302209198475, acc=0.9912777543067932, loss=0.03106302209198475
test: epoch 64, loss 2.2496182918548584, acc=0.6000000238418579, loss=2.2496182918548584
train: epoch 65, loss 0.035408828407526016, acc=0.9912777543067932, loss=0.035408828407526016
test: epoch 65, loss 2.2120118141174316, acc=0.574999988079071, loss=2.2120118141174316
train: epoch 66, loss 0.042500097304582596, acc=0.9870555400848389, loss=0.042500097304582596
test: epoch 66, loss 2.4440338611602783, acc=0.5055555701255798, loss=2.4440338611602783
train: epoch 67, loss 0.039716579020023346, acc=0.988111138343811, loss=0.039716579020023346
test: epoch 67, loss 1.8668460845947266, acc=0.6333333253860474, loss=1.8668460845947266
train: epoch 68, loss 0.030426297336816788, acc=0.9909444451332092, loss=0.030426297336816788
test: epoch 68, loss 2.3666815757751465, acc=0.5527777671813965, loss=2.3666815757751465
train: epoch 69, loss 0.030793720856308937, acc=0.9912222027778625, loss=0.030793720856308937
test: epoch 69, loss 1.8875027894973755, acc=0.5277777910232544, loss=1.8875027894973755
train: epoch 70, loss 0.028647813946008682, acc=0.9918333292007446, loss=0.028647813946008682
test: epoch 70, loss 1.8422590494155884, acc=0.6333333253860474, loss=1.8422590494155884
train: epoch 71, loss 0.041322726756334305, acc=0.988611102104187, loss=0.041322726756334305
test: epoch 71, loss 2.0175187587738037, acc=0.5777778029441833, loss=2.0175187587738037
train: epoch 72, loss 0.02862260863184929, acc=0.9911666512489319, loss=0.02862260863184929
test: epoch 72, loss 1.7981654405593872, acc=0.6194444298744202, loss=1.7981654405593872
train: epoch 73, loss 0.02672998234629631, acc=0.9925000071525574, loss=0.02672998234629631
test: epoch 73, loss 2.253425121307373, acc=0.5944444537162781, loss=2.253425121307373
train: epoch 74, loss 0.024886731058359146, acc=0.99272221326828, loss=0.024886731058359146
test: epoch 74, loss 2.143150806427002, acc=0.6111111044883728, loss=2.143150806427002
train: epoch 75, loss 0.033102426677942276, acc=0.9907222390174866, loss=0.033102426677942276
test: epoch 75, loss 2.710517644882202, acc=0.5111111402511597, loss=2.710517644882202
train: epoch 76, loss 0.035434540361166, acc=0.9902222156524658, loss=0.035434540361166
test: epoch 76, loss 2.398876905441284, acc=0.5916666388511658, loss=2.398876905441284
train: epoch 77, loss 0.02447204664349556, acc=0.9926111102104187, loss=0.02447204664349556
test: epoch 77, loss 2.229588270187378, acc=0.5111111402511597, loss=2.229588270187378
train: epoch 78, loss 0.03179396688938141, acc=0.9917222261428833, loss=0.03179396688938141
test: epoch 78, loss 1.528914451599121, acc=0.6777777671813965, loss=1.528914451599121
train: epoch 79, loss 0.028737682849168777, acc=0.9915000200271606, loss=0.028737682849168777
test: epoch 79, loss 2.0365631580352783, acc=0.5583333373069763, loss=2.0365631580352783
train: epoch 80, loss 0.03067130409181118, acc=0.9915000200271606, loss=0.03067130409181118
test: epoch 80, loss 1.3146998882293701, acc=0.6833333373069763, loss=1.3146998882293701
train: epoch 81, loss 0.03593021258711815, acc=0.9897778034210205, loss=0.03593021258711815
test: epoch 81, loss 2.2226691246032715, acc=0.625, loss=2.2226691246032715
train: epoch 82, loss 0.026598244905471802, acc=0.9929444193840027, loss=0.026598244905471802
test: epoch 82, loss 1.2542133331298828, acc=0.699999988079071, loss=1.2542133331298828
train: epoch 83, loss 0.03601286560297012, acc=0.9903888702392578, loss=0.03601286560297012
test: epoch 83, loss 1.583803653717041, acc=0.6527777910232544, loss=1.583803653717041
train: epoch 84, loss 0.01801093854010105, acc=0.9945555329322815, loss=0.01801093854010105
test: epoch 84, loss 1.534544587135315, acc=0.644444465637207, loss=1.534544587135315
train: epoch 85, loss 0.026814043521881104, acc=0.992388904094696, loss=0.026814043521881104
test: epoch 85, loss 1.6726047992706299, acc=0.6388888955116272, loss=1.6726047992706299
train: epoch 86, loss 0.022900251671671867, acc=0.992555558681488, loss=0.022900251671671867
test: epoch 86, loss 1.322229266166687, acc=0.7194444537162781, loss=1.322229266166687
train: epoch 87, loss 0.027818553149700165, acc=0.9925000071525574, loss=0.027818553149700165
test: epoch 87, loss 1.0810742378234863, acc=0.7555555701255798, loss=1.0810742378234863
train: epoch 88, loss 0.021427877247333527, acc=0.9935555458068848, loss=0.021427877247333527
test: epoch 88, loss 1.3268682956695557, acc=0.6916666626930237, loss=1.3268682956695557
train: epoch 89, loss 0.031894173473119736, acc=0.9909444451332092, loss=0.031894173473119736
test: epoch 89, loss 1.357722282409668, acc=0.7277777791023254, loss=1.357722282409668
train: epoch 90, loss 0.016481120139360428, acc=0.995888888835907, loss=0.016481120139360428
test: epoch 90, loss 1.3549081087112427, acc=0.7027778029441833, loss=1.3549081087112427
train: epoch 91, loss 0.026615116745233536, acc=0.992222249507904, loss=0.026615116745233536
test: epoch 91, loss 1.7869422435760498, acc=0.6777777671813965, loss=1.7869422435760498
train: epoch 92, loss 0.02457926794886589, acc=0.9924444556236267, loss=0.02457926794886589
test: epoch 92, loss 1.5237467288970947, acc=0.699999988079071, loss=1.5237467288970947
train: epoch 93, loss 0.026273315772414207, acc=0.992111086845398, loss=0.026273315772414207
test: epoch 93, loss 0.9471439123153687, acc=0.8138889074325562, loss=0.9471439123153687
train: epoch 94, loss 0.03021065890789032, acc=0.992388904094696, loss=0.03021065890789032
test: epoch 94, loss 1.1589354276657104, acc=0.7666666507720947, loss=1.1589354276657104
train: epoch 95, loss 0.014810328371822834, acc=0.9957777857780457, loss=0.014810328371822834
test: epoch 95, loss 1.2854673862457275, acc=0.7361111044883728, loss=1.2854673862457275
train: epoch 96, loss 0.02857879363000393, acc=0.9926111102104187, loss=0.02857879363000393
test: epoch 96, loss 1.2364497184753418, acc=0.675000011920929, loss=1.2364497184753418
train: epoch 97, loss 0.01977466605603695, acc=0.9943888783454895, loss=0.01977466605603695
test: epoch 97, loss 1.1520687341690063, acc=0.7416666746139526, loss=1.1520687341690063
train: epoch 98, loss 0.021512391045689583, acc=0.9944999814033508, loss=0.021512391045689583
test: epoch 98, loss 1.6885982751846313, acc=0.7583333253860474, loss=1.6885982751846313
train: epoch 99, loss 0.01986980251967907, acc=0.9950555562973022, loss=0.01986980251967907
test: epoch 99, loss 0.8001011610031128, acc=0.8194444179534912, loss=0.8001011610031128
train: epoch 100, loss 0.024921830743551254, acc=0.9936110973358154, loss=0.024921830743551254
test: epoch 100, loss 1.278226375579834, acc=0.7777777910232544, loss=1.278226375579834
train: epoch 101, loss 0.024512704461812973, acc=0.9934444427490234, loss=0.024512704461812973
test: epoch 101, loss 1.2104450464248657, acc=0.7666666507720947, loss=1.2104450464248657
train: epoch 102, loss 0.018349066376686096, acc=0.9952222108840942, loss=0.018349066376686096
test: epoch 102, loss 1.5655850172042847, acc=0.7333333492279053, loss=1.5655850172042847
train: epoch 103, loss 0.023039570078253746, acc=0.9933888912200928, loss=0.023039570078253746
test: epoch 103, loss 0.9309093952178955, acc=0.8111110925674438, loss=0.9309093952178955
train: epoch 104, loss 0.014355539344251156, acc=0.9959999918937683, loss=0.014355539344251156
test: epoch 104, loss 1.2987922430038452, acc=0.7972221970558167, loss=1.2987922430038452
train: epoch 105, loss 0.024831660091876984, acc=0.9931111335754395, loss=0.024831660091876984
test: epoch 105, loss 1.3196555376052856, acc=0.7638888955116272, loss=1.3196555376052856
train: epoch 106, loss 0.0233777929097414, acc=0.9941111207008362, loss=0.0233777929097414
test: epoch 106, loss 0.9947673678398132, acc=0.800000011920929, loss=0.9947673678398132
train: epoch 107, loss 0.020234154537320137, acc=0.9948333501815796, loss=0.020234154537320137
test: epoch 107, loss 1.0449702739715576, acc=0.8444444537162781, loss=1.0449702739715576
train: epoch 108, loss 0.013896838761866093, acc=0.995888888835907, loss=0.013896838761866093
test: epoch 108, loss 0.9227773547172546, acc=0.8222222328186035, loss=0.9227773547172546
train: epoch 109, loss 0.014096632599830627, acc=0.996055543422699, loss=0.014096632599830627
test: epoch 109, loss 0.5942777395248413, acc=0.8666666746139526, loss=0.5942777395248413
train: epoch 110, loss 0.00959663838148117, acc=0.9973888993263245, loss=0.00959663838148117
test: epoch 110, loss 0.9154397249221802, acc=0.8805555701255798, loss=0.9154397249221802
train: epoch 111, loss 0.024047726765275, acc=0.9945555329322815, loss=0.024047726765275
test: epoch 111, loss 0.864844799041748, acc=0.8472222089767456, loss=0.864844799041748
train: epoch 112, loss 0.020438455045223236, acc=0.9939444661140442, loss=0.020438455045223236
test: epoch 112, loss 0.6593208312988281, acc=0.8999999761581421, loss=0.6593208312988281
train: epoch 113, loss 0.017146212980151176, acc=0.995555579662323, loss=0.017146212980151176
test: epoch 113, loss 0.5971544981002808, acc=0.8722222447395325, loss=0.5971544981002808
train: epoch 114, loss 0.015435588546097279, acc=0.9961666464805603, loss=0.015435588546097279
test: epoch 114, loss 0.8794813752174377, acc=0.8472222089767456, loss=0.8794813752174377
train: epoch 115, loss 0.018181191757321358, acc=0.9957777857780457, loss=0.018181191757321358
test: epoch 115, loss 0.720567524433136, acc=0.8805555701255798, loss=0.720567524433136
train: epoch 116, loss 0.020055266097187996, acc=0.9944444298744202, loss=0.020055266097187996
test: epoch 116, loss 0.6006620526313782, acc=0.894444465637207, loss=0.6006620526313782
train: epoch 117, loss 0.016417846083641052, acc=0.9957777857780457, loss=0.016417846083641052
test: epoch 117, loss 0.657168984413147, acc=0.8888888955116272, loss=0.657168984413147
train: epoch 118, loss 0.017054524272680283, acc=0.9959444403648376, loss=0.017054524272680283
test: epoch 118, loss 0.6737255454063416, acc=0.8916666507720947, loss=0.6737255454063416
train: epoch 119, loss 0.01706063747406006, acc=0.9951111078262329, loss=0.01706063747406006
test: epoch 119, loss 0.6353615522384644, acc=0.8861111402511597, loss=0.6353615522384644
train: epoch 120, loss 0.013971621170639992, acc=0.996666669845581, loss=0.013971621170639992
test: epoch 120, loss 0.5221215486526489, acc=0.9055555462837219, loss=0.5221215486526489
train: epoch 121, loss 0.02001805789768696, acc=0.9951111078262329, loss=0.02001805789768696
test: epoch 121, loss 1.350096344947815, acc=0.8388888835906982, loss=1.350096344947815
train: epoch 122, loss 0.015961043536663055, acc=0.996222198009491, loss=0.015961043536663055
test: epoch 122, loss 0.7535373568534851, acc=0.894444465637207, loss=0.7535373568534851
train: epoch 123, loss 0.012979619204998016, acc=0.996666669845581, loss=0.012979619204998016
test: epoch 123, loss 0.5421985387802124, acc=0.9305555820465088, loss=0.5421985387802124
train: epoch 124, loss 0.01114453561604023, acc=0.996833324432373, loss=0.01114453561604023
test: epoch 124, loss 0.8326290845870972, acc=0.8722222447395325, loss=0.8326290845870972
train: epoch 125, loss 0.011202081106603146, acc=0.9975000023841858, loss=0.011202081106603146
test: epoch 125, loss 0.6290339231491089, acc=0.8722222447395325, loss=0.6290339231491089
train: epoch 126, loss 0.011755202896893024, acc=0.9970555305480957, loss=0.011755202896893024
test: epoch 126, loss 0.6181755065917969, acc=0.9027777910232544, loss=0.6181755065917969
train: epoch 127, loss 0.013675804249942303, acc=0.9963889122009277, loss=0.013675804249942303
test: epoch 127, loss 0.6858394145965576, acc=0.8888888955116272, loss=0.6858394145965576
train: epoch 128, loss 0.01077056024223566, acc=0.9971666932106018, loss=0.01077056024223566
test: epoch 128, loss 0.4057179093360901, acc=0.9166666865348816, loss=0.4057179093360901
train: epoch 129, loss 0.020034056156873703, acc=0.9951666593551636, loss=0.020034056156873703
test: epoch 129, loss 0.7334601879119873, acc=0.8805555701255798, loss=0.7334601879119873
train: epoch 130, loss 0.016829341650009155, acc=0.996222198009491, loss=0.016829341650009155
test: epoch 130, loss 0.6923425793647766, acc=0.8500000238418579, loss=0.6923425793647766
train: epoch 131, loss 0.008492209948599339, acc=0.9976666569709778, loss=0.008492209948599339
test: epoch 131, loss 0.4708404541015625, acc=0.9388889074325562, loss=0.4708404541015625
train: epoch 132, loss 0.007521953899413347, acc=0.9980000257492065, loss=0.007521953899413347
test: epoch 132, loss 0.44136396050453186, acc=0.9222221970558167, loss=0.44136396050453186
train: epoch 133, loss 0.01608610711991787, acc=0.9965555667877197, loss=0.01608610711991787
test: epoch 133, loss 0.4630637466907501, acc=0.9138888716697693, loss=0.4630637466907501
train: epoch 134, loss 0.01024700328707695, acc=0.9972222447395325, loss=0.01024700328707695
test: epoch 134, loss 0.6874969601631165, acc=0.9166666865348816, loss=0.6874969601631165
train: epoch 135, loss 0.010749618522822857, acc=0.996833324432373, loss=0.010749618522822857
test: epoch 135, loss 0.502914547920227, acc=0.925000011920929, loss=0.502914547920227
train: epoch 136, loss 0.011959816329181194, acc=0.9969444274902344, loss=0.011959816329181194
test: epoch 136, loss 0.7603568434715271, acc=0.8833333253860474, loss=0.7603568434715271
train: epoch 137, loss 0.007842312566936016, acc=0.9977777600288391, loss=0.007842312566936016
test: epoch 137, loss 0.5719735622406006, acc=0.9138888716697693, loss=0.5719735622406006
train: epoch 138, loss 0.017159540206193924, acc=0.996666669845581, loss=0.017159540206193924
test: epoch 138, loss 0.6168718338012695, acc=0.9222221970558167, loss=0.6168718338012695
train: epoch 139, loss 0.00973776075989008, acc=0.9975000023841858, loss=0.00973776075989008
test: epoch 139, loss 0.5434994101524353, acc=0.9194444417953491, loss=0.5434994101524353
train: epoch 140, loss 0.016458017751574516, acc=0.9958333373069763, loss=0.016458017751574516
test: epoch 140, loss 0.5943052768707275, acc=0.9166666865348816, loss=0.5943052768707275
train: epoch 141, loss 0.01067843846976757, acc=0.9971666932106018, loss=0.01067843846976757
test: epoch 141, loss 0.3451451361179352, acc=0.9277777671813965, loss=0.3451451361179352
train: epoch 142, loss 0.009059811942279339, acc=0.9979444742202759, loss=0.009059811942279339
test: epoch 142, loss 0.44690772891044617, acc=0.9138888716697693, loss=0.44690772891044617
train: epoch 143, loss 0.011841108091175556, acc=0.9972777962684631, loss=0.011841108091175556
test: epoch 143, loss 0.5497653484344482, acc=0.9222221970558167, loss=0.5497653484344482
train: epoch 144, loss 0.010030119679868221, acc=0.9974444508552551, loss=0.010030119679868221
test: epoch 144, loss 0.4997016191482544, acc=0.9277777671813965, loss=0.4997016191482544
train: epoch 145, loss 0.016435181722044945, acc=0.9961110949516296, loss=0.016435181722044945
test: epoch 145, loss 0.34223636984825134, acc=0.9527778029441833, loss=0.34223636984825134
train: epoch 146, loss 0.009114577434957027, acc=0.9978333115577698, loss=0.009114577434957027
test: epoch 146, loss 0.36660635471343994, acc=0.9111111164093018, loss=0.36660635471343994
train: epoch 147, loss 0.009975587949156761, acc=0.9976111054420471, loss=0.009975587949156761
test: epoch 147, loss 0.3363857567310333, acc=0.9333333373069763, loss=0.3363857567310333
train: epoch 148, loss 0.004994276445358992, acc=0.9992222189903259, loss=0.004994276445358992
test: epoch 148, loss 0.4671638607978821, acc=0.9194444417953491, loss=0.4671638607978821
train: epoch 149, loss 0.009548231959342957, acc=0.9978888630867004, loss=0.009548231959342957
test: epoch 149, loss 0.4739733636379242, acc=0.9361110925674438, loss=0.4739733636379242
train: epoch 150, loss 0.007395247463136911, acc=0.9976666569709778, loss=0.007395247463136911
test: epoch 150, loss 0.518502950668335, acc=0.9194444417953491, loss=0.518502950668335
