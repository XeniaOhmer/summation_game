# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=1", "--temp_decay=1", "--one_hot=0", "--n_layers=1"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=1077603975, receiver_embed_dim=128, save_run=0, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=1077603975, receiver_embed_dim=128, save_run=False, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.189887285232544, acc=0.07083333283662796, loss=3.189887285232544
test: epoch 1, loss 3.7043166160583496, acc=0.0555555559694767, loss=3.7043166160583496
train: epoch 2, loss 2.862602710723877, acc=0.10672222077846527, loss=2.862602710723877
test: epoch 2, loss 3.883835554122925, acc=0.05277777835726738, loss=3.883835554122925
train: epoch 3, loss 2.74994158744812, acc=0.11977777630090714, loss=2.74994158744812
test: epoch 3, loss 3.8356313705444336, acc=0.05277777835726738, loss=3.8356313705444336
train: epoch 4, loss 2.6947662830352783, acc=0.12955555319786072, loss=2.6947662830352783
test: epoch 4, loss 3.9833011627197266, acc=0.05833333358168602, loss=3.9833011627197266
train: epoch 5, loss 2.6534228324890137, acc=0.13433332741260529, loss=2.6534228324890137
test: epoch 5, loss 4.048736095428467, acc=0.05277777835726738, loss=4.048736095428467
train: epoch 6, loss 2.6210739612579346, acc=0.1391666680574417, loss=2.6210739612579346
test: epoch 6, loss 4.137693881988525, acc=0.0555555559694767, loss=4.137693881988525
train: epoch 7, loss 2.5953221321105957, acc=0.1449444442987442, loss=2.5953221321105957
test: epoch 7, loss 4.09370756149292, acc=0.0555555559694767, loss=4.09370756149292
train: epoch 8, loss 2.5724411010742188, acc=0.14305555820465088, loss=2.5724411010742188
test: epoch 8, loss 4.2520527839660645, acc=0.05277777835726738, loss=4.2520527839660645
train: epoch 9, loss 2.547945499420166, acc=0.15000000596046448, loss=2.547945499420166
test: epoch 9, loss 4.1527628898620605, acc=0.0555555559694767, loss=4.1527628898620605
train: epoch 10, loss 2.5341360569000244, acc=0.1518888920545578, loss=2.5341360569000244
test: epoch 10, loss 4.188540935516357, acc=0.05833333358168602, loss=4.188540935516357
train: epoch 11, loss 2.529127836227417, acc=0.15166667103767395, loss=2.529127836227417
test: epoch 11, loss 4.136495590209961, acc=0.05277777835726738, loss=4.136495590209961
train: epoch 12, loss 2.5043869018554688, acc=0.15494444966316223, loss=2.5043869018554688
test: epoch 12, loss 4.176919460296631, acc=0.05000000074505806, loss=4.176919460296631
train: epoch 13, loss 2.4858946800231934, acc=0.15805555880069733, loss=2.4858946800231934
test: epoch 13, loss 4.25044059753418, acc=0.05000000074505806, loss=4.25044059753418
train: epoch 14, loss 2.480975389480591, acc=0.1583888828754425, loss=2.480975389480591
test: epoch 14, loss 4.19279146194458, acc=0.05000000074505806, loss=4.19279146194458
train: epoch 15, loss 2.4646944999694824, acc=0.16583333909511566, loss=2.4646944999694824
test: epoch 15, loss 4.316608428955078, acc=0.05000000074505806, loss=4.316608428955078
train: epoch 16, loss 2.4686806201934814, acc=0.1631111055612564, loss=2.4686806201934814
test: epoch 16, loss 4.254986763000488, acc=0.06666667014360428, loss=4.254986763000488
train: epoch 17, loss 2.4557852745056152, acc=0.16483333706855774, loss=2.4557852745056152
test: epoch 17, loss 4.214344501495361, acc=0.04444444552063942, loss=4.214344501495361
train: epoch 18, loss 2.440528631210327, acc=0.165944442152977, loss=2.440528631210327
test: epoch 18, loss 4.2038068771362305, acc=0.05000000074505806, loss=4.2038068771362305
train: epoch 19, loss 2.424548864364624, acc=0.16644445061683655, loss=2.424548864364624
test: epoch 19, loss 4.236745357513428, acc=0.05277777835726738, loss=4.236745357513428
train: epoch 20, loss 2.4226739406585693, acc=0.16883333027362823, loss=2.4226739406585693
test: epoch 20, loss 4.337281227111816, acc=0.0416666679084301, loss=4.337281227111816
train: epoch 21, loss 2.426577568054199, acc=0.17011110484600067, loss=2.426577568054199
test: epoch 21, loss 4.189568996429443, acc=0.04722222313284874, loss=4.189568996429443
train: epoch 22, loss 2.3926360607147217, acc=0.17322222888469696, loss=2.3926360607147217
test: epoch 22, loss 4.308648586273193, acc=0.05000000074505806, loss=4.308648586273193
train: epoch 23, loss 2.401250123977661, acc=0.17594444751739502, loss=2.401250123977661
test: epoch 23, loss 4.312638282775879, acc=0.04444444552063942, loss=4.312638282775879
train: epoch 24, loss 2.394364356994629, acc=0.17533333599567413, loss=2.394364356994629
test: epoch 24, loss 4.282817840576172, acc=0.04444444552063942, loss=4.282817840576172
train: epoch 25, loss 2.391904354095459, acc=0.17977777123451233, loss=2.391904354095459
test: epoch 25, loss 4.14883279800415, acc=0.04444444552063942, loss=4.14883279800415
train: epoch 26, loss 2.369032382965088, acc=0.18383333086967468, loss=2.369032382965088
test: epoch 26, loss 4.370604515075684, acc=0.0416666679084301, loss=4.370604515075684
train: epoch 27, loss 2.3547472953796387, acc=0.1883888840675354, loss=2.3547472953796387
test: epoch 27, loss 4.2998948097229, acc=0.0416666679084301, loss=4.2998948097229
train: epoch 28, loss 2.363621950149536, acc=0.1807222217321396, loss=2.363621950149536
test: epoch 28, loss 4.178262233734131, acc=0.04444444552063942, loss=4.178262233734131
train: epoch 29, loss 2.357363224029541, acc=0.1854444444179535, loss=2.357363224029541
test: epoch 29, loss 4.186404228210449, acc=0.04722222313284874, loss=4.186404228210449
train: epoch 30, loss 2.3522298336029053, acc=0.1818888932466507, loss=2.3522298336029053
test: epoch 30, loss 4.167595386505127, acc=0.0416666679084301, loss=4.167595386505127
train: epoch 31, loss 2.347640037536621, acc=0.18727777898311615, loss=2.347640037536621
test: epoch 31, loss 4.330791473388672, acc=0.0416666679084301, loss=4.330791473388672
train: epoch 32, loss 2.3232476711273193, acc=0.19144444167613983, loss=2.3232476711273193
test: epoch 32, loss 4.245328426361084, acc=0.04444444552063942, loss=4.245328426361084
train: epoch 33, loss 2.338761568069458, acc=0.18783333897590637, loss=2.338761568069458
test: epoch 33, loss 4.137793064117432, acc=0.0416666679084301, loss=4.137793064117432
train: epoch 34, loss 2.3270840644836426, acc=0.19744443893432617, loss=2.3270840644836426
test: epoch 34, loss 4.2090253829956055, acc=0.0555555559694767, loss=4.2090253829956055
train: epoch 35, loss 2.332080841064453, acc=0.1932777762413025, loss=2.332080841064453
test: epoch 35, loss 4.155670166015625, acc=0.0416666679084301, loss=4.155670166015625
train: epoch 36, loss 2.315338373184204, acc=0.19316667318344116, loss=2.315338373184204
test: epoch 36, loss 4.319133758544922, acc=0.04722222313284874, loss=4.319133758544922
train: epoch 37, loss 2.293757677078247, acc=0.19672222435474396, loss=2.293757677078247
test: epoch 37, loss 4.286382675170898, acc=0.04722222313284874, loss=4.286382675170898
train: epoch 38, loss 2.3068289756774902, acc=0.19483333826065063, loss=2.3068289756774902
test: epoch 38, loss 4.220513820648193, acc=0.03611111268401146, loss=4.220513820648193
train: epoch 39, loss 2.2983384132385254, acc=0.19361111521720886, loss=2.2983384132385254
test: epoch 39, loss 4.2384934425354, acc=0.04722222313284874, loss=4.2384934425354
train: epoch 40, loss 2.304194927215576, acc=0.19583334028720856, loss=2.304194927215576
test: epoch 40, loss 4.062460899353027, acc=0.03888889029622078, loss=4.062460899353027
train: epoch 41, loss 2.2821149826049805, acc=0.2021111100912094, loss=2.2821149826049805
test: epoch 41, loss 4.30184268951416, acc=0.03888889029622078, loss=4.30184268951416
train: epoch 42, loss 2.2792959213256836, acc=0.19911110401153564, loss=2.2792959213256836
test: epoch 42, loss 4.307219982147217, acc=0.06111111119389534, loss=4.307219982147217
train: epoch 43, loss 2.2814204692840576, acc=0.20261111855506897, loss=2.2814204692840576
test: epoch 43, loss 4.1659836769104, acc=0.0555555559694767, loss=4.1659836769104
train: epoch 44, loss 2.2758448123931885, acc=0.20494444668293, loss=2.2758448123931885
test: epoch 44, loss 4.088128566741943, acc=0.05277777835726738, loss=4.088128566741943
train: epoch 45, loss 2.283135175704956, acc=0.1988888829946518, loss=2.283135175704956
test: epoch 45, loss 4.215744495391846, acc=0.04444444552063942, loss=4.215744495391846
train: epoch 46, loss 2.2711591720581055, acc=0.21177777647972107, loss=2.2711591720581055
test: epoch 46, loss 4.217206954956055, acc=0.05277777835726738, loss=4.217206954956055
train: epoch 47, loss 2.2518057823181152, acc=0.20711110532283783, loss=2.2518057823181152
test: epoch 47, loss 4.358319282531738, acc=0.0416666679084301, loss=4.358319282531738
train: epoch 48, loss 2.2670106887817383, acc=0.2087777704000473, loss=2.2670106887817383
test: epoch 48, loss 4.26493501663208, acc=0.04444444552063942, loss=4.26493501663208
train: epoch 49, loss 2.262911081314087, acc=0.21050000190734863, loss=2.262911081314087
test: epoch 49, loss 4.095823287963867, acc=0.04722222313284874, loss=4.095823287963867
train: epoch 50, loss 2.2591114044189453, acc=0.20466665923595428, loss=2.2591114044189453
test: epoch 50, loss 4.112789154052734, acc=0.05833333358168602, loss=4.112789154052734
train: epoch 51, loss 2.257251501083374, acc=0.20988889038562775, loss=2.257251501083374
test: epoch 51, loss 4.184668064117432, acc=0.03888889029622078, loss=4.184668064117432
train: epoch 52, loss 2.2420871257781982, acc=0.2133333384990692, loss=2.2420871257781982
test: epoch 52, loss 4.285066604614258, acc=0.03888889029622078, loss=4.285066604614258
train: epoch 53, loss 2.232341766357422, acc=0.21138888597488403, loss=2.232341766357422
test: epoch 53, loss 4.152236461639404, acc=0.03888889029622078, loss=4.152236461639404
train: epoch 54, loss 2.21988844871521, acc=0.2179444432258606, loss=2.21988844871521
test: epoch 54, loss 4.112743377685547, acc=0.04444444552063942, loss=4.112743377685547
train: epoch 55, loss 2.228236675262451, acc=0.21211111545562744, loss=2.228236675262451
test: epoch 55, loss 4.267451286315918, acc=0.03611111268401146, loss=4.267451286315918
train: epoch 56, loss 2.237682342529297, acc=0.2152777761220932, loss=2.237682342529297
test: epoch 56, loss 4.004405498504639, acc=0.03888889029622078, loss=4.004405498504639
train: epoch 57, loss 2.2437667846679688, acc=0.21538889408111572, loss=2.2437667846679688
test: epoch 57, loss 4.106306552886963, acc=0.03611111268401146, loss=4.106306552886963
train: epoch 58, loss 2.2381510734558105, acc=0.2134999930858612, loss=2.2381510734558105
test: epoch 58, loss 4.054091930389404, acc=0.03611111268401146, loss=4.054091930389404
train: epoch 59, loss 2.2194983959198, acc=0.2179444432258606, loss=2.2194983959198
test: epoch 59, loss 4.121509552001953, acc=0.04722222313284874, loss=4.121509552001953
train: epoch 60, loss 2.218668222427368, acc=0.2158888876438141, loss=2.218668222427368
test: epoch 60, loss 4.121020793914795, acc=0.0416666679084301, loss=4.121020793914795
train: epoch 61, loss 2.203228712081909, acc=0.2179444432258606, loss=2.203228712081909
test: epoch 61, loss 4.176530838012695, acc=0.03888889029622078, loss=4.176530838012695
train: epoch 62, loss 2.233618974685669, acc=0.21755555272102356, loss=2.233618974685669
test: epoch 62, loss 4.124822616577148, acc=0.0416666679084301, loss=4.124822616577148
train: epoch 63, loss 2.21250581741333, acc=0.21722222864627838, loss=2.21250581741333
test: epoch 63, loss 3.953394651412964, acc=0.03333333507180214, loss=3.953394651412964
train: epoch 64, loss 2.2061667442321777, acc=0.22038888931274414, loss=2.2061667442321777
test: epoch 64, loss 3.9175586700439453, acc=0.04722222313284874, loss=3.9175586700439453
train: epoch 65, loss 2.182914972305298, acc=0.21994444727897644, loss=2.182914972305298
test: epoch 65, loss 4.1493353843688965, acc=0.03888889029622078, loss=4.1493353843688965
train: epoch 66, loss 2.1881635189056396, acc=0.22122222185134888, loss=2.1881635189056396
test: epoch 66, loss 4.127562522888184, acc=0.04444444552063942, loss=4.127562522888184
train: epoch 67, loss 2.195236921310425, acc=0.2201666682958603, loss=2.195236921310425
test: epoch 67, loss 3.835564613342285, acc=0.03888889029622078, loss=3.835564613342285
train: epoch 68, loss 2.1975479125976562, acc=0.22288888692855835, loss=2.1975479125976562
test: epoch 68, loss 4.052780628204346, acc=0.06388889253139496, loss=4.052780628204346
train: epoch 69, loss 2.1805171966552734, acc=0.2260555624961853, loss=2.1805171966552734
test: epoch 69, loss 4.041975975036621, acc=0.06388889253139496, loss=4.041975975036621
train: epoch 70, loss 2.190753698348999, acc=0.22166666388511658, loss=2.190753698348999
test: epoch 70, loss 4.0556206703186035, acc=0.06388889253139496, loss=4.0556206703186035
train: epoch 71, loss 2.17360782623291, acc=0.2238333374261856, loss=2.17360782623291
test: epoch 71, loss 3.940279960632324, acc=0.04722222313284874, loss=3.940279960632324
train: epoch 72, loss 2.1649835109710693, acc=0.2248888909816742, loss=2.1649835109710693
test: epoch 72, loss 4.092833042144775, acc=0.04444444552063942, loss=4.092833042144775
train: epoch 73, loss 2.170409917831421, acc=0.2296111136674881, loss=2.170409917831421
test: epoch 73, loss 4.2249040603637695, acc=0.04444444552063942, loss=4.2249040603637695
train: epoch 74, loss 2.181878089904785, acc=0.22216667234897614, loss=2.181878089904785
test: epoch 74, loss 4.0622477531433105, acc=0.04444444552063942, loss=4.0622477531433105
train: epoch 75, loss 2.1790387630462646, acc=0.22599999606609344, loss=2.1790387630462646
test: epoch 75, loss 3.8818469047546387, acc=0.04444444552063942, loss=3.8818469047546387
train: epoch 76, loss 2.162457227706909, acc=0.2285555601119995, loss=2.162457227706909
test: epoch 76, loss 4.121692657470703, acc=0.0416666679084301, loss=4.121692657470703
train: epoch 77, loss 2.1632587909698486, acc=0.22611111402511597, loss=2.1632587909698486
test: epoch 77, loss 3.9850423336029053, acc=0.0416666679084301, loss=3.9850423336029053
train: epoch 78, loss 2.158064126968384, acc=0.23105555772781372, loss=2.158064126968384
test: epoch 78, loss 4.329715251922607, acc=0.06388889253139496, loss=4.329715251922607
train: epoch 79, loss 2.1569061279296875, acc=0.2304999977350235, loss=2.1569061279296875
test: epoch 79, loss 4.137084484100342, acc=0.05277777835726738, loss=4.137084484100342
train: epoch 80, loss 2.1767990589141846, acc=0.2303333282470703, loss=2.1767990589141846
test: epoch 80, loss 3.9417519569396973, acc=0.05000000074505806, loss=3.9417519569396973
train: epoch 81, loss 2.1546664237976074, acc=0.22733333706855774, loss=2.1546664237976074
test: epoch 81, loss 4.129513263702393, acc=0.04444444552063942, loss=4.129513263702393
train: epoch 82, loss 2.161149024963379, acc=0.2291666716337204, loss=2.161149024963379
test: epoch 82, loss 4.105799198150635, acc=0.0416666679084301, loss=4.105799198150635
train: epoch 83, loss 2.140338182449341, acc=0.23527777194976807, loss=2.140338182449341
test: epoch 83, loss 4.237996578216553, acc=0.03888889029622078, loss=4.237996578216553
train: epoch 84, loss 2.143186092376709, acc=0.23294444382190704, loss=2.143186092376709
test: epoch 84, loss 4.163822650909424, acc=0.04444444552063942, loss=4.163822650909424
train: epoch 85, loss 2.1426761150360107, acc=0.23372222483158112, loss=2.1426761150360107
test: epoch 85, loss 4.10971736907959, acc=0.03611111268401146, loss=4.10971736907959
train: epoch 86, loss 2.1733462810516357, acc=0.2318333387374878, loss=2.1733462810516357
test: epoch 86, loss 4.096554756164551, acc=0.05000000074505806, loss=4.096554756164551
train: epoch 87, loss 2.150784730911255, acc=0.23466666042804718, loss=2.150784730911255
test: epoch 87, loss 4.095855712890625, acc=0.0416666679084301, loss=4.095855712890625
train: epoch 88, loss 2.1321229934692383, acc=0.23505555093288422, loss=2.1321229934692383
test: epoch 88, loss 3.9899444580078125, acc=0.03888889029622078, loss=3.9899444580078125
train: epoch 89, loss 2.1323156356811523, acc=0.23688888549804688, loss=2.1323156356811523
test: epoch 89, loss 4.17828369140625, acc=0.04444444552063942, loss=4.17828369140625
train: epoch 90, loss 2.1399648189544678, acc=0.23694443702697754, loss=2.1399648189544678
test: epoch 90, loss 4.09022855758667, acc=0.04444444552063942, loss=4.09022855758667
train: epoch 91, loss 2.1288070678710938, acc=0.23394444584846497, loss=2.1288070678710938
test: epoch 91, loss 4.113746643066406, acc=0.0416666679084301, loss=4.113746643066406
train: epoch 92, loss 2.1251916885375977, acc=0.2377222180366516, loss=2.1251916885375977
test: epoch 92, loss 3.970479726791382, acc=0.04444444552063942, loss=3.970479726791382
train: epoch 93, loss 2.1199843883514404, acc=0.23944444954395294, loss=2.1199843883514404
test: epoch 93, loss 3.991281509399414, acc=0.0555555559694767, loss=3.991281509399414
train: epoch 94, loss 2.136957883834839, acc=0.2390555590391159, loss=2.136957883834839
test: epoch 94, loss 4.086528301239014, acc=0.04444444552063942, loss=4.086528301239014
train: epoch 95, loss 2.13096284866333, acc=0.23766666650772095, loss=2.13096284866333
test: epoch 95, loss 3.9915196895599365, acc=0.04444444552063942, loss=3.9915196895599365
train: epoch 96, loss 2.1123440265655518, acc=0.23972222208976746, loss=2.1123440265655518
test: epoch 96, loss 3.995417594909668, acc=0.04444444552063942, loss=3.995417594909668
train: epoch 97, loss 2.116680145263672, acc=0.24072222411632538, loss=2.116680145263672
test: epoch 97, loss 4.04910945892334, acc=0.0416666679084301, loss=4.04910945892334
train: epoch 98, loss 2.1167609691619873, acc=0.23766666650772095, loss=2.1167609691619873
test: epoch 98, loss 4.195971965789795, acc=0.04444444552063942, loss=4.195971965789795
train: epoch 99, loss 2.111299514770508, acc=0.23827777802944183, loss=2.111299514770508
test: epoch 99, loss 4.119874000549316, acc=0.0416666679084301, loss=4.119874000549316
train: epoch 100, loss 2.1152288913726807, acc=0.2412777841091156, loss=2.1152288913726807
test: epoch 100, loss 3.9790525436401367, acc=0.04722222313284874, loss=3.9790525436401367
train: epoch 101, loss 2.1042566299438477, acc=0.2367222160100937, loss=2.1042566299438477
test: epoch 101, loss 4.164302825927734, acc=0.0416666679084301, loss=4.164302825927734
train: epoch 102, loss 2.117523431777954, acc=0.23761111497879028, loss=2.117523431777954
test: epoch 102, loss 3.948878765106201, acc=0.07222222536802292, loss=3.948878765106201
train: epoch 103, loss 2.105555534362793, acc=0.2426111102104187, loss=2.105555534362793
test: epoch 103, loss 4.034539222717285, acc=0.04722222313284874, loss=4.034539222717285
train: epoch 104, loss 2.099231004714966, acc=0.24405555427074432, loss=2.099231004714966
test: epoch 104, loss 4.212313652038574, acc=0.05833333358168602, loss=4.212313652038574
train: epoch 105, loss 2.111145496368408, acc=0.24416667222976685, loss=2.111145496368408
test: epoch 105, loss 3.9249885082244873, acc=0.04444444552063942, loss=3.9249885082244873
train: epoch 106, loss 2.08571457862854, acc=0.24672222137451172, loss=2.08571457862854
test: epoch 106, loss 4.049480438232422, acc=0.03333333507180214, loss=4.049480438232422
train: epoch 107, loss 2.0976064205169678, acc=0.24288888275623322, loss=2.0976064205169678
test: epoch 107, loss 4.070303916931152, acc=0.0416666679084301, loss=4.070303916931152
train: epoch 108, loss 2.103315591812134, acc=0.24044445157051086, loss=2.103315591812134
test: epoch 108, loss 4.194724082946777, acc=0.05000000074505806, loss=4.194724082946777
train: epoch 109, loss 2.0729782581329346, acc=0.2466111183166504, loss=2.0729782581329346
test: epoch 109, loss 4.224452018737793, acc=0.04444444552063942, loss=4.224452018737793
train: epoch 110, loss 2.0866329669952393, acc=0.24477778375148773, loss=2.0866329669952393
test: epoch 110, loss 4.1430983543396, acc=0.06388889253139496, loss=4.1430983543396
train: epoch 111, loss 2.086498737335205, acc=0.244111105799675, loss=2.086498737335205
test: epoch 111, loss 4.1957478523254395, acc=0.04444444552063942, loss=4.1957478523254395
train: epoch 112, loss 2.0847699642181396, acc=0.24672222137451172, loss=2.0847699642181396
test: epoch 112, loss 4.157970905303955, acc=0.03888889029622078, loss=4.157970905303955
train: epoch 113, loss 2.0779006481170654, acc=0.248222216963768, loss=2.0779006481170654
test: epoch 113, loss 4.104700088500977, acc=0.06388889253139496, loss=4.104700088500977
train: epoch 114, loss 2.0852553844451904, acc=0.24833333492279053, loss=2.0852553844451904
test: epoch 114, loss 4.189340591430664, acc=0.03888889029622078, loss=4.189340591430664
train: epoch 115, loss 2.0874977111816406, acc=0.25200000405311584, loss=2.0874977111816406
test: epoch 115, loss 4.092034816741943, acc=0.04722222313284874, loss=4.092034816741943
train: epoch 116, loss 2.0726635456085205, acc=0.24638888239860535, loss=2.0726635456085205
test: epoch 116, loss 4.154155731201172, acc=0.04444444552063942, loss=4.154155731201172
train: epoch 117, loss 2.0812723636627197, acc=0.2475000023841858, loss=2.0812723636627197
test: epoch 117, loss 4.09751033782959, acc=0.0555555559694767, loss=4.09751033782959
train: epoch 118, loss 2.068279504776001, acc=0.25522223114967346, loss=2.068279504776001
test: epoch 118, loss 4.0782470703125, acc=0.03888889029622078, loss=4.0782470703125
train: epoch 119, loss 2.0724639892578125, acc=0.24766667187213898, loss=2.0724639892578125
test: epoch 119, loss 4.009852886199951, acc=0.04722222313284874, loss=4.009852886199951
train: epoch 120, loss 2.0631396770477295, acc=0.25005555152893066, loss=2.0631396770477295
test: epoch 120, loss 4.058568000793457, acc=0.04444444552063942, loss=4.058568000793457
train: epoch 121, loss 2.0824265480041504, acc=0.2543888986110687, loss=2.0824265480041504
test: epoch 121, loss 4.144817352294922, acc=0.05277777835726738, loss=4.144817352294922
train: epoch 122, loss 2.0873310565948486, acc=0.24533332884311676, loss=2.0873310565948486
test: epoch 122, loss 4.047494888305664, acc=0.06388889253139496, loss=4.047494888305664
train: epoch 123, loss 2.068755626678467, acc=0.24816666543483734, loss=2.068755626678467
test: epoch 123, loss 3.8863532543182373, acc=0.04444444552063942, loss=3.8863532543182373
train: epoch 124, loss 2.064490795135498, acc=0.2518889009952545, loss=2.064490795135498
test: epoch 124, loss 4.1395368576049805, acc=0.04444444552063942, loss=4.1395368576049805
train: epoch 125, loss 2.062281370162964, acc=0.25005555152893066, loss=2.062281370162964
test: epoch 125, loss 4.06050968170166, acc=0.05833333358168602, loss=4.06050968170166
train: epoch 126, loss 2.0516903400421143, acc=0.25433334708213806, loss=2.0516903400421143
test: epoch 126, loss 4.167727470397949, acc=0.05277777835726738, loss=4.167727470397949
train: epoch 127, loss 2.044318914413452, acc=0.25183331966400146, loss=2.044318914413452
test: epoch 127, loss 4.276575565338135, acc=0.03888889029622078, loss=4.276575565338135
train: epoch 128, loss 2.065133571624756, acc=0.2523888945579529, loss=2.065133571624756
test: epoch 128, loss 4.277523040771484, acc=0.03888889029622078, loss=4.277523040771484
train: epoch 129, loss 2.051030397415161, acc=0.2594444453716278, loss=2.051030397415161
test: epoch 129, loss 3.9064440727233887, acc=0.04444444552063942, loss=3.9064440727233887
train: epoch 130, loss 2.0492637157440186, acc=0.253555566072464, loss=2.0492637157440186
test: epoch 130, loss 4.048431396484375, acc=0.04722222313284874, loss=4.048431396484375
train: epoch 131, loss 2.0533792972564697, acc=0.2524999976158142, loss=2.0533792972564697
test: epoch 131, loss 3.8052098751068115, acc=0.0416666679084301, loss=3.8052098751068115
train: epoch 132, loss 2.0433602333068848, acc=0.25272223353385925, loss=2.0433602333068848
test: epoch 132, loss 4.20372200012207, acc=0.05833333358168602, loss=4.20372200012207
train: epoch 133, loss 2.0445456504821777, acc=0.2596110999584198, loss=2.0445456504821777
test: epoch 133, loss 4.07474422454834, acc=0.0555555559694767, loss=4.07474422454834
train: epoch 134, loss 2.0471744537353516, acc=0.257666677236557, loss=2.0471744537353516
test: epoch 134, loss 4.194715976715088, acc=0.0555555559694767, loss=4.194715976715088
train: epoch 135, loss 2.0431559085845947, acc=0.2546111047267914, loss=2.0431559085845947
test: epoch 135, loss 4.0647382736206055, acc=0.07222222536802292, loss=4.0647382736206055
train: epoch 136, loss 2.049741268157959, acc=0.24916666746139526, loss=2.049741268157959
test: epoch 136, loss 4.150794982910156, acc=0.04722222313284874, loss=4.150794982910156
train: epoch 137, loss 2.045753240585327, acc=0.25688889622688293, loss=2.045753240585327
test: epoch 137, loss 4.034481048583984, acc=0.05277777835726738, loss=4.034481048583984
train: epoch 138, loss 2.0456602573394775, acc=0.25611111521720886, loss=2.0456602573394775
test: epoch 138, loss 4.097615718841553, acc=0.05277777835726738, loss=4.097615718841553
train: epoch 139, loss 2.043346405029297, acc=0.2611111104488373, loss=2.043346405029297
test: epoch 139, loss 4.0404744148254395, acc=0.0416666679084301, loss=4.0404744148254395
train: epoch 140, loss 2.0439107418060303, acc=0.2557222247123718, loss=2.0439107418060303
test: epoch 140, loss 4.088947772979736, acc=0.04444444552063942, loss=4.088947772979736
train: epoch 141, loss 2.043458938598633, acc=0.25611111521720886, loss=2.043458938598633
test: epoch 141, loss 4.061026573181152, acc=0.05277777835726738, loss=4.061026573181152
train: epoch 142, loss 2.0304930210113525, acc=0.2632777690887451, loss=2.0304930210113525
test: epoch 142, loss 4.165663242340088, acc=0.05000000074505806, loss=4.165663242340088
train: epoch 143, loss 2.0331971645355225, acc=0.25699999928474426, loss=2.0331971645355225
test: epoch 143, loss 4.118746280670166, acc=0.04722222313284874, loss=4.118746280670166
train: epoch 144, loss 2.036055564880371, acc=0.261388897895813, loss=2.036055564880371
test: epoch 144, loss 3.9264650344848633, acc=0.05000000074505806, loss=3.9264650344848633
train: epoch 145, loss 2.009105682373047, acc=0.2594444453716278, loss=2.009105682373047
test: epoch 145, loss 4.152933120727539, acc=0.06111111119389534, loss=4.152933120727539
train: epoch 146, loss 2.017124891281128, acc=0.2666666805744171, loss=2.017124891281128
test: epoch 146, loss 4.065981864929199, acc=0.05277777835726738, loss=4.065981864929199
train: epoch 147, loss 2.033872365951538, acc=0.26249998807907104, loss=2.033872365951538
test: epoch 147, loss 4.28964900970459, acc=0.06388889253139496, loss=4.28964900970459
train: epoch 148, loss 2.0360090732574463, acc=0.2615000009536743, loss=2.0360090732574463
test: epoch 148, loss 4.0085248947143555, acc=0.06666667014360428, loss=4.0085248947143555
train: epoch 149, loss 2.034148693084717, acc=0.2633333206176758, loss=2.034148693084717
test: epoch 149, loss 4.209047794342041, acc=0.06111111119389534, loss=4.209047794342041
train: epoch 150, loss 2.0228424072265625, acc=0.2634444534778595, loss=2.0228424072265625
test: epoch 150, loss 4.0907063484191895, acc=0.04722222313284874, loss=4.0907063484191895
