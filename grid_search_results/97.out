# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=true", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=327898236, receiver_embed_dim=64, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.872037649154663, acc=0.09605555236339569, loss=2.872037649154663
test: epoch 1, loss 3.705003023147583, acc=0.10277777910232544, loss=3.705003023147583
train: epoch 2, loss 1.6853647232055664, acc=0.3465000092983246, loss=1.6853647232055664
test: epoch 2, loss 4.777322292327881, acc=0.12777778506278992, loss=4.777322292327881
train: epoch 3, loss 1.1240825653076172, acc=0.5529999732971191, loss=1.1240825653076172
test: epoch 3, loss 4.027339935302734, acc=0.15000000596046448, loss=4.027339935302734
train: epoch 4, loss 0.8334499597549438, acc=0.6737222075462341, loss=0.8334499597549438
test: epoch 4, loss 3.8436226844787598, acc=0.1666666716337204, loss=3.8436226844787598
train: epoch 5, loss 0.6724365949630737, acc=0.734666645526886, loss=0.6724365949630737
test: epoch 5, loss 3.463458299636841, acc=0.18611110746860504, loss=3.463458299636841
train: epoch 6, loss 0.5665912628173828, acc=0.7806666493415833, loss=0.5665912628173828
test: epoch 6, loss 3.264484167098999, acc=0.24722221493721008, loss=3.264484167098999
train: epoch 7, loss 0.49209335446357727, acc=0.8095555305480957, loss=0.49209335446357727
test: epoch 7, loss 3.312711000442505, acc=0.28611111640930176, loss=3.312711000442505
train: epoch 8, loss 0.43514305353164673, acc=0.8308888673782349, loss=0.43514305353164673
test: epoch 8, loss 2.949803352355957, acc=0.2666666805744171, loss=2.949803352355957
train: epoch 9, loss 0.42513373494148254, acc=0.8399999737739563, loss=0.42513373494148254
test: epoch 9, loss 2.4078097343444824, acc=0.3722222149372101, loss=2.4078097343444824
train: epoch 10, loss 0.3697851002216339, acc=0.859666645526886, loss=0.3697851002216339
test: epoch 10, loss 2.591695785522461, acc=0.2527777850627899, loss=2.591695785522461
train: epoch 11, loss 0.3213108479976654, acc=0.8807222247123718, loss=0.3213108479976654
test: epoch 11, loss 3.20577073097229, acc=0.27222222089767456, loss=3.20577073097229
train: epoch 12, loss 0.31943944096565247, acc=0.8865000009536743, loss=0.31943944096565247
test: epoch 12, loss 2.265062093734741, acc=0.3166666626930237, loss=2.265062093734741
train: epoch 13, loss 0.3031836152076721, acc=0.8920000195503235, loss=0.3031836152076721
test: epoch 13, loss 2.288858652114868, acc=0.3916666805744171, loss=2.288858652114868
train: epoch 14, loss 0.2653329074382782, acc=0.9089444279670715, loss=0.2653329074382782
test: epoch 14, loss 2.85784649848938, acc=0.32499998807907104, loss=2.85784649848938
train: epoch 15, loss 0.2552120089530945, acc=0.9120000004768372, loss=0.2552120089530945
test: epoch 15, loss 2.356429100036621, acc=0.3222222328186035, loss=2.356429100036621
train: epoch 16, loss 0.23259484767913818, acc=0.922166645526886, loss=0.23259484767913818
test: epoch 16, loss 2.0676944255828857, acc=0.42222222685813904, loss=2.0676944255828857
train: epoch 17, loss 0.23416119813919067, acc=0.9206666946411133, loss=0.23416119813919067
test: epoch 17, loss 2.1497302055358887, acc=0.35277777910232544, loss=2.1497302055358887
train: epoch 18, loss 0.20876121520996094, acc=0.9304999709129333, loss=0.20876121520996094
test: epoch 18, loss 1.8688087463378906, acc=0.3777777850627899, loss=1.8688087463378906
train: epoch 19, loss 0.2023136466741562, acc=0.9338889122009277, loss=0.2023136466741562
test: epoch 19, loss 2.6979598999023438, acc=0.4166666567325592, loss=2.6979598999023438
train: epoch 20, loss 0.2130497545003891, acc=0.9276666641235352, loss=0.2130497545003891
test: epoch 20, loss 2.0128512382507324, acc=0.3861111104488373, loss=2.0128512382507324
train: epoch 21, loss 0.17374244332313538, acc=0.9403333067893982, loss=0.17374244332313538
test: epoch 21, loss 2.1400251388549805, acc=0.4166666567325592, loss=2.1400251388549805
train: epoch 22, loss 0.17917056381702423, acc=0.9424999952316284, loss=0.17917056381702423
test: epoch 22, loss 1.943930745124817, acc=0.39444443583488464, loss=1.943930745124817
train: epoch 23, loss 0.19236961007118225, acc=0.9365555644035339, loss=0.19236961007118225
test: epoch 23, loss 1.9022126197814941, acc=0.38333332538604736, loss=1.9022126197814941
train: epoch 24, loss 0.16465546190738678, acc=0.944611132144928, loss=0.16465546190738678
test: epoch 24, loss 2.194636106491089, acc=0.4194444417953491, loss=2.194636106491089
train: epoch 25, loss 0.16987144947052002, acc=0.9450555443763733, loss=0.16987144947052002
test: epoch 25, loss 2.2544665336608887, acc=0.35555556416511536, loss=2.2544665336608887
train: epoch 26, loss 0.16323834657669067, acc=0.9467222094535828, loss=0.16323834657669067
test: epoch 26, loss 2.3770837783813477, acc=0.4333333373069763, loss=2.3770837783813477
train: epoch 27, loss 0.16112880408763885, acc=0.9481666684150696, loss=0.16112880408763885
test: epoch 27, loss 1.9528076648712158, acc=0.43888887763023376, loss=1.9528076648712158
train: epoch 28, loss 0.15158703923225403, acc=0.9497777819633484, loss=0.15158703923225403
test: epoch 28, loss 2.132899761199951, acc=0.44999998807907104, loss=2.132899761199951
train: epoch 29, loss 0.15311752259731293, acc=0.9499444365501404, loss=0.15311752259731293
test: epoch 29, loss 1.8497170209884644, acc=0.4861111044883728, loss=1.8497170209884644
train: epoch 30, loss 0.15038996934890747, acc=0.9483333230018616, loss=0.15038996934890747
test: epoch 30, loss 1.8827564716339111, acc=0.4444444477558136, loss=1.8827564716339111
train: epoch 31, loss 0.1401999145746231, acc=0.9527778029441833, loss=0.1401999145746231
test: epoch 31, loss 1.774084210395813, acc=0.4694444537162781, loss=1.774084210395813
train: epoch 32, loss 0.14373928308486938, acc=0.9538888931274414, loss=0.14373928308486938
test: epoch 32, loss 2.259018898010254, acc=0.4611110985279083, loss=2.259018898010254
train: epoch 33, loss 0.14615805447101593, acc=0.9527222514152527, loss=0.14615805447101593
test: epoch 33, loss 2.4147400856018066, acc=0.4749999940395355, loss=2.4147400856018066
train: epoch 34, loss 0.12175058573484421, acc=0.9574999809265137, loss=0.12175058573484421
test: epoch 34, loss 2.020474910736084, acc=0.4138889014720917, loss=2.020474910736084
train: epoch 35, loss 0.1252666562795639, acc=0.9585555791854858, loss=0.1252666562795639
test: epoch 35, loss 1.7956393957138062, acc=0.4277777671813965, loss=1.7956393957138062
train: epoch 36, loss 0.13014768064022064, acc=0.9580000042915344, loss=0.13014768064022064
test: epoch 36, loss 1.770555019378662, acc=0.4972222149372101, loss=1.770555019378662
train: epoch 37, loss 0.12934236228466034, acc=0.9585555791854858, loss=0.12934236228466034
test: epoch 37, loss 1.8997958898544312, acc=0.43611112236976624, loss=1.8997958898544312
train: epoch 38, loss 0.12142040580511093, acc=0.9582777619361877, loss=0.12142040580511093
test: epoch 38, loss 1.7246599197387695, acc=0.4277777671813965, loss=1.7246599197387695
train: epoch 39, loss 0.11404076218605042, acc=0.9618889093399048, loss=0.11404076218605042
test: epoch 39, loss 1.7888576984405518, acc=0.4972222149372101, loss=1.7888576984405518
train: epoch 40, loss 0.12477419525384903, acc=0.9607222080230713, loss=0.12477419525384903
test: epoch 40, loss 1.8479492664337158, acc=0.550000011920929, loss=1.8479492664337158
train: epoch 41, loss 0.11225657910108566, acc=0.9641110897064209, loss=0.11225657910108566
test: epoch 41, loss 2.536578893661499, acc=0.34166666865348816, loss=2.536578893661499
train: epoch 42, loss 0.11151647567749023, acc=0.964555561542511, loss=0.11151647567749023
test: epoch 42, loss 1.5548479557037354, acc=0.4972222149372101, loss=1.5548479557037354
train: epoch 43, loss 0.11591105163097382, acc=0.9624999761581421, loss=0.11591105163097382
test: epoch 43, loss 1.8000249862670898, acc=0.5027777552604675, loss=1.8000249862670898
train: epoch 44, loss 0.12409523874521255, acc=0.9605000019073486, loss=0.12409523874521255
test: epoch 44, loss 2.152872323989868, acc=0.48055556416511536, loss=2.152872323989868
train: epoch 45, loss 0.11270049959421158, acc=0.9623888731002808, loss=0.11270049959421158
test: epoch 45, loss 1.4067935943603516, acc=0.5611110925674438, loss=1.4067935943603516
train: epoch 46, loss 0.11762124300003052, acc=0.960444450378418, loss=0.11762124300003052
test: epoch 46, loss 1.9109843969345093, acc=0.519444465637207, loss=1.9109843969345093
train: epoch 47, loss 0.11056123673915863, acc=0.9641666412353516, loss=0.11056123673915863
test: epoch 47, loss 1.876108169555664, acc=0.574999988079071, loss=1.876108169555664
train: epoch 48, loss 0.0997694879770279, acc=0.9660000205039978, loss=0.0997694879770279
test: epoch 48, loss 1.6900337934494019, acc=0.4611110985279083, loss=1.6900337934494019
train: epoch 49, loss 0.1093398779630661, acc=0.9640555381774902, loss=0.1093398779630661
test: epoch 49, loss 1.4839359521865845, acc=0.5444444417953491, loss=1.4839359521865845
train: epoch 50, loss 0.09280771017074585, acc=0.9696111083030701, loss=0.09280771017074585
test: epoch 50, loss 1.5042290687561035, acc=0.5444444417953491, loss=1.5042290687561035
train: epoch 51, loss 0.11452049016952515, acc=0.9624999761581421, loss=0.11452049016952515
test: epoch 51, loss 1.5153758525848389, acc=0.550000011920929, loss=1.5153758525848389
train: epoch 52, loss 0.0954226553440094, acc=0.9688888788223267, loss=0.0954226553440094
test: epoch 52, loss 2.0166053771972656, acc=0.47777777910232544, loss=2.0166053771972656
train: epoch 53, loss 0.10754721611738205, acc=0.9646111130714417, loss=0.10754721611738205
test: epoch 53, loss 1.7218470573425293, acc=0.5361111164093018, loss=1.7218470573425293
train: epoch 54, loss 0.09430456906557083, acc=0.968500018119812, loss=0.09430456906557083
test: epoch 54, loss 2.0860755443573, acc=0.4972222149372101, loss=2.0860755443573
train: epoch 55, loss 0.1035466343164444, acc=0.9660555720329285, loss=0.1035466343164444
test: epoch 55, loss 1.4534472227096558, acc=0.550000011920929, loss=1.4534472227096558
train: epoch 56, loss 0.09325908869504929, acc=0.968833327293396, loss=0.09325908869504929
test: epoch 56, loss 1.7293996810913086, acc=0.5388888716697693, loss=1.7293996810913086
train: epoch 57, loss 0.09995417296886444, acc=0.9665555357933044, loss=0.09995417296886444
test: epoch 57, loss 1.4163635969161987, acc=0.5861111283302307, loss=1.4163635969161987
train: epoch 58, loss 0.10239469259977341, acc=0.9689444303512573, loss=0.10239469259977341
test: epoch 58, loss 1.419298768043518, acc=0.6166666746139526, loss=1.419298768043518
train: epoch 59, loss 0.0848812535405159, acc=0.9720555543899536, loss=0.0848812535405159
test: epoch 59, loss 1.3462411165237427, acc=0.5583333373069763, loss=1.3462411165237427
train: epoch 60, loss 0.11732576787471771, acc=0.9629999995231628, loss=0.11732576787471771
test: epoch 60, loss 1.102192759513855, acc=0.6305555701255798, loss=1.102192759513855
train: epoch 61, loss 0.08138999342918396, acc=0.9733889102935791, loss=0.08138999342918396
test: epoch 61, loss 1.4734348058700562, acc=0.5222222208976746, loss=1.4734348058700562
train: epoch 62, loss 0.10690900683403015, acc=0.9657777547836304, loss=0.10690900683403015
test: epoch 62, loss 1.5106472969055176, acc=0.6194444298744202, loss=1.5106472969055176
train: epoch 63, loss 0.10194157063961029, acc=0.9671666622161865, loss=0.10194157063961029
test: epoch 63, loss 1.0114219188690186, acc=0.6222222447395325, loss=1.0114219188690186
train: epoch 64, loss 0.08730369806289673, acc=0.9712777733802795, loss=0.08730369806289673
test: epoch 64, loss 1.2977044582366943, acc=0.6583333611488342, loss=1.2977044582366943
train: epoch 65, loss 0.09210540354251862, acc=0.9710555672645569, loss=0.09210540354251862
test: epoch 65, loss 1.3820772171020508, acc=0.6527777910232544, loss=1.3820772171020508
train: epoch 66, loss 0.08735513687133789, acc=0.971666693687439, loss=0.08735513687133789
test: epoch 66, loss 1.2017223834991455, acc=0.6777777671813965, loss=1.2017223834991455
train: epoch 67, loss 0.09186439961194992, acc=0.9702777862548828, loss=0.09186439961194992
test: epoch 67, loss 1.3735523223876953, acc=0.6305555701255798, loss=1.3735523223876953
train: epoch 68, loss 0.07914792001247406, acc=0.9746111035346985, loss=0.07914792001247406
test: epoch 68, loss 1.0966280698776245, acc=0.6194444298744202, loss=1.0966280698776245
train: epoch 69, loss 0.09784981608390808, acc=0.9679444432258606, loss=0.09784981608390808
test: epoch 69, loss 1.3228265047073364, acc=0.675000011920929, loss=1.3228265047073364
train: epoch 70, loss 0.08762896060943604, acc=0.9711111187934875, loss=0.08762896060943604
test: epoch 70, loss 1.2034143209457397, acc=0.6833333373069763, loss=1.2034143209457397
train: epoch 71, loss 0.09116511791944504, acc=0.9700555801391602, loss=0.09116511791944504
test: epoch 71, loss 1.5210981369018555, acc=0.625, loss=1.5210981369018555
train: epoch 72, loss 0.07876912504434586, acc=0.9749444723129272, loss=0.07876912504434586
test: epoch 72, loss 0.8493390679359436, acc=0.769444465637207, loss=0.8493390679359436
train: epoch 73, loss 0.09208162128925323, acc=0.9708889126777649, loss=0.09208162128925323
test: epoch 73, loss 0.9065421223640442, acc=0.7361111044883728, loss=0.9065421223640442
train: epoch 74, loss 0.08274902403354645, acc=0.9726666808128357, loss=0.08274902403354645
test: epoch 74, loss 0.7658155560493469, acc=0.6972222328186035, loss=0.7658155560493469
train: epoch 75, loss 0.07927336543798447, acc=0.975944459438324, loss=0.07927336543798447
test: epoch 75, loss 0.690204381942749, acc=0.769444465637207, loss=0.690204381942749
train: epoch 76, loss 0.0816240981221199, acc=0.9736666679382324, loss=0.0816240981221199
test: epoch 76, loss 0.7785987854003906, acc=0.7861111164093018, loss=0.7785987854003906
train: epoch 77, loss 0.07942253351211548, acc=0.9741111397743225, loss=0.07942253351211548
test: epoch 77, loss 0.7377209067344666, acc=0.7888888716697693, loss=0.7377209067344666
train: epoch 78, loss 0.07137064635753632, acc=0.9769999980926514, loss=0.07137064635753632
test: epoch 78, loss 0.8340160846710205, acc=0.75, loss=0.8340160846710205
train: epoch 79, loss 0.07984855771064758, acc=0.9746111035346985, loss=0.07984855771064758
test: epoch 79, loss 0.5598901510238647, acc=0.7916666865348816, loss=0.5598901510238647
train: epoch 80, loss 0.0746203362941742, acc=0.977055549621582, loss=0.0746203362941742
test: epoch 80, loss 0.7823610305786133, acc=0.7749999761581421, loss=0.7823610305786133
train: epoch 81, loss 0.0687214583158493, acc=0.9792777895927429, loss=0.0687214583158493
test: epoch 81, loss 0.6225824952125549, acc=0.7805555462837219, loss=0.6225824952125549
train: epoch 82, loss 0.07213815301656723, acc=0.9777777791023254, loss=0.07213815301656723
test: epoch 82, loss 0.5256641507148743, acc=0.8777777552604675, loss=0.5256641507148743
train: epoch 83, loss 0.06384892761707306, acc=0.9796110987663269, loss=0.06384892761707306
test: epoch 83, loss 0.4247150123119354, acc=0.894444465637207, loss=0.4247150123119354
train: epoch 84, loss 0.06091795116662979, acc=0.981166660785675, loss=0.06091795116662979
test: epoch 84, loss 0.501717746257782, acc=0.9027777910232544, loss=0.501717746257782
train: epoch 85, loss 0.06167050451040268, acc=0.9812777638435364, loss=0.06167050451040268
test: epoch 85, loss 0.3825197219848633, acc=0.9111111164093018, loss=0.3825197219848633
train: epoch 86, loss 0.049456991255283356, acc=0.9856666922569275, loss=0.049456991255283356
test: epoch 86, loss 0.35057321190834045, acc=0.9138888716697693, loss=0.35057321190834045
train: epoch 87, loss 0.054390374571084976, acc=0.9848889112472534, loss=0.054390374571084976
test: epoch 87, loss 0.4107777178287506, acc=0.9055555462837219, loss=0.4107777178287506
train: epoch 88, loss 0.0671730488538742, acc=0.9793888926506042, loss=0.0671730488538742
test: epoch 88, loss 0.3662203252315521, acc=0.9083333611488342, loss=0.3662203252315521
train: epoch 89, loss 0.05393712595105171, acc=0.9830555319786072, loss=0.05393712595105171
test: epoch 89, loss 0.28542882204055786, acc=0.925000011920929, loss=0.28542882204055786
train: epoch 90, loss 0.05383484438061714, acc=0.9846110939979553, loss=0.05383484438061714
test: epoch 90, loss 0.32257094979286194, acc=0.894444465637207, loss=0.32257094979286194
train: epoch 91, loss 0.048136334866285324, acc=0.9865000247955322, loss=0.048136334866285324
test: epoch 91, loss 0.4000338017940521, acc=0.9111111164093018, loss=0.4000338017940521
train: epoch 92, loss 0.06182576343417168, acc=0.9821110963821411, loss=0.06182576343417168
test: epoch 92, loss 0.2879914343357086, acc=0.9111111164093018, loss=0.2879914343357086
train: epoch 93, loss 0.04674212634563446, acc=0.9860555529594421, loss=0.04674212634563446
test: epoch 93, loss 0.3009887933731079, acc=0.9333333373069763, loss=0.3009887933731079
train: epoch 94, loss 0.051145605742931366, acc=0.9861666560173035, loss=0.051145605742931366
test: epoch 94, loss 0.3419877588748932, acc=0.8888888955116272, loss=0.3419877588748932
train: epoch 95, loss 0.045351285487413406, acc=0.9855555295944214, loss=0.045351285487413406
test: epoch 95, loss 0.40016183257102966, acc=0.9194444417953491, loss=0.40016183257102966
train: epoch 96, loss 0.047679439187049866, acc=0.9852777719497681, loss=0.047679439187049866
test: epoch 96, loss 0.2575628161430359, acc=0.9277777671813965, loss=0.2575628161430359
train: epoch 97, loss 0.044236913323402405, acc=0.9877222180366516, loss=0.044236913323402405
test: epoch 97, loss 0.31107085943222046, acc=0.9277777671813965, loss=0.31107085943222046
train: epoch 98, loss 0.04112085700035095, acc=0.9878333210945129, loss=0.04112085700035095
test: epoch 98, loss 0.2727293372154236, acc=0.9333333373069763, loss=0.2727293372154236
train: epoch 99, loss 0.03781197592616081, acc=0.988111138343811, loss=0.03781197592616081
test: epoch 99, loss 0.2905466556549072, acc=0.8972222208976746, loss=0.2905466556549072
train: epoch 100, loss 0.04472487047314644, acc=0.9869999885559082, loss=0.04472487047314644
test: epoch 100, loss 0.2797665596008301, acc=0.9333333373069763, loss=0.2797665596008301
train: epoch 101, loss 0.0314529687166214, acc=0.9901666641235352, loss=0.0314529687166214
test: epoch 101, loss 0.3850640654563904, acc=0.9333333373069763, loss=0.3850640654563904
train: epoch 102, loss 0.04999009519815445, acc=0.9854444265365601, loss=0.04999009519815445
test: epoch 102, loss 0.49333617091178894, acc=0.9277777671813965, loss=0.49333617091178894
train: epoch 103, loss 0.04207446053624153, acc=0.9879999756813049, loss=0.04207446053624153
test: epoch 103, loss 0.2612314522266388, acc=0.9333333373069763, loss=0.2612314522266388
train: epoch 104, loss 0.03837800398468971, acc=0.9890000224113464, loss=0.03837800398468971
test: epoch 104, loss 0.35935458540916443, acc=0.925000011920929, loss=0.35935458540916443
train: epoch 105, loss 0.041221823543310165, acc=0.9880555272102356, loss=0.041221823543310165
test: epoch 105, loss 0.27390339970588684, acc=0.9333333373069763, loss=0.27390339970588684
train: epoch 106, loss 0.03579828515648842, acc=0.9885555505752563, loss=0.03579828515648842
test: epoch 106, loss 0.2869540750980377, acc=0.9333333373069763, loss=0.2869540750980377
train: epoch 107, loss 0.03930314630270004, acc=0.988277792930603, loss=0.03930314630270004
test: epoch 107, loss 0.31614479422569275, acc=0.9333333373069763, loss=0.31614479422569275
train: epoch 108, loss 0.03958165645599365, acc=0.9891666769981384, loss=0.03958165645599365
test: epoch 108, loss 0.274964839220047, acc=0.925000011920929, loss=0.274964839220047
train: epoch 109, loss 0.038965947926044464, acc=0.9881666898727417, loss=0.038965947926044464
test: epoch 109, loss 0.2366250902414322, acc=0.9333333373069763, loss=0.2366250902414322
train: epoch 110, loss 0.04433341324329376, acc=0.9871110916137695, loss=0.04433341324329376
test: epoch 110, loss 0.23827223479747772, acc=0.9444444179534912, loss=0.23827223479747772
train: epoch 111, loss 0.03718823194503784, acc=0.9901111125946045, loss=0.03718823194503784
test: epoch 111, loss 0.2500516176223755, acc=0.9416666626930237, loss=0.2500516176223755
train: epoch 112, loss 0.027700211852788925, acc=0.9911666512489319, loss=0.027700211852788925
test: epoch 112, loss 0.3254799246788025, acc=0.9416666626930237, loss=0.3254799246788025
train: epoch 113, loss 0.047481436282396317, acc=0.9868333339691162, loss=0.047481436282396317
test: epoch 113, loss 0.24643227458000183, acc=0.9416666626930237, loss=0.24643227458000183
train: epoch 114, loss 0.029144741594791412, acc=0.9911666512489319, loss=0.029144741594791412
test: epoch 114, loss 0.25162819027900696, acc=0.9444444179534912, loss=0.25162819027900696
train: epoch 115, loss 0.044786565005779266, acc=0.9883888959884644, loss=0.044786565005779266
test: epoch 115, loss 0.2788214087486267, acc=0.9388889074325562, loss=0.2788214087486267
train: epoch 116, loss 0.04152064025402069, acc=0.9879999756813049, loss=0.04152064025402069
test: epoch 116, loss 0.2032954841852188, acc=0.9444444179534912, loss=0.2032954841852188
train: epoch 117, loss 0.03238227963447571, acc=0.9906666874885559, loss=0.03238227963447571
test: epoch 117, loss 0.20781025290489197, acc=0.9444444179534912, loss=0.20781025290489197
train: epoch 118, loss 0.03787709027528763, acc=0.9888333082199097, loss=0.03787709027528763
test: epoch 118, loss 0.22444699704647064, acc=0.9444444179534912, loss=0.22444699704647064
train: epoch 119, loss 0.03391711413860321, acc=0.9898889064788818, loss=0.03391711413860321
test: epoch 119, loss 0.23866641521453857, acc=0.9444444179534912, loss=0.23866641521453857
train: epoch 120, loss 0.028212787583470345, acc=0.9907222390174866, loss=0.028212787583470345
test: epoch 120, loss 0.27533772587776184, acc=0.9444444179534912, loss=0.27533772587776184
train: epoch 121, loss 0.038600239902734756, acc=0.9890555739402771, loss=0.038600239902734756
test: epoch 121, loss 0.2506599426269531, acc=0.9444444179534912, loss=0.2506599426269531
train: epoch 122, loss 0.032417524605989456, acc=0.9909444451332092, loss=0.032417524605989456
test: epoch 122, loss 0.2805323004722595, acc=0.9444444179534912, loss=0.2805323004722595
train: epoch 123, loss 0.0390482135117054, acc=0.9886666536331177, loss=0.0390482135117054
test: epoch 123, loss 0.24306681752204895, acc=0.9444444179534912, loss=0.24306681752204895
train: epoch 124, loss 0.037967048585414886, acc=0.9896110892295837, loss=0.037967048585414886
test: epoch 124, loss 0.2138795554637909, acc=0.9444444179534912, loss=0.2138795554637909
train: epoch 125, loss 0.04089336097240448, acc=0.9891666769981384, loss=0.04089336097240448
test: epoch 125, loss 0.18980436027050018, acc=0.9444444179534912, loss=0.18980436027050018
train: epoch 126, loss 0.03196144476532936, acc=0.9904999732971191, loss=0.03196144476532936
test: epoch 126, loss 0.24000388383865356, acc=0.9444444179534912, loss=0.24000388383865356
train: epoch 127, loss 0.02799919992685318, acc=0.991611123085022, loss=0.02799919992685318
test: epoch 127, loss 0.25370627641677856, acc=0.9416666626930237, loss=0.25370627641677856
train: epoch 128, loss 0.023404497653245926, acc=0.992555558681488, loss=0.023404497653245926
test: epoch 128, loss 0.2250734567642212, acc=0.9444444179534912, loss=0.2250734567642212
train: epoch 129, loss 0.0329972505569458, acc=0.9899444580078125, loss=0.0329972505569458
test: epoch 129, loss 0.2155894935131073, acc=0.9444444179534912, loss=0.2155894935131073
train: epoch 130, loss 0.03614823520183563, acc=0.9899444580078125, loss=0.03614823520183563
test: epoch 130, loss 0.21255731582641602, acc=0.9416666626930237, loss=0.21255731582641602
train: epoch 131, loss 0.03849130496382713, acc=0.9889444708824158, loss=0.03849130496382713
test: epoch 131, loss 0.1847320795059204, acc=0.9444444179534912, loss=0.1847320795059204
train: epoch 132, loss 0.031038077548146248, acc=0.9909999966621399, loss=0.031038077548146248
test: epoch 132, loss 0.22482037544250488, acc=0.9416666626930237, loss=0.22482037544250488
train: epoch 133, loss 0.04116276651620865, acc=0.9886666536331177, loss=0.04116276651620865
test: epoch 133, loss 0.18933328986167908, acc=0.9444444179534912, loss=0.18933328986167908
train: epoch 134, loss 0.036671824753284454, acc=0.9903888702392578, loss=0.036671824753284454
test: epoch 134, loss 0.2298160195350647, acc=0.9444444179534912, loss=0.2298160195350647
train: epoch 135, loss 0.033013008534908295, acc=0.9898889064788818, loss=0.033013008534908295
test: epoch 135, loss 0.2354653775691986, acc=0.9388889074325562, loss=0.2354653775691986
train: epoch 136, loss 0.05449249967932701, acc=0.9858888983726501, loss=0.05449249967932701
test: epoch 136, loss 0.26072701811790466, acc=0.9444444179534912, loss=0.26072701811790466
train: epoch 137, loss 0.028964433819055557, acc=0.9912777543067932, loss=0.028964433819055557
test: epoch 137, loss 0.2679966986179352, acc=0.9444444179534912, loss=0.2679966986179352
train: epoch 138, loss 0.034363456070423126, acc=0.9887222051620483, loss=0.034363456070423126
test: epoch 138, loss 0.18428120017051697, acc=0.9444444179534912, loss=0.18428120017051697
train: epoch 139, loss 0.029917540028691292, acc=0.9910555481910706, loss=0.029917540028691292
test: epoch 139, loss 0.20648151636123657, acc=0.9444444179534912, loss=0.20648151636123657
train: epoch 140, loss 0.03848792240023613, acc=0.9904444217681885, loss=0.03848792240023613
test: epoch 140, loss 0.2127390205860138, acc=0.9416666626930237, loss=0.2127390205860138
train: epoch 141, loss 0.0336088202893734, acc=0.9904999732971191, loss=0.0336088202893734
test: epoch 141, loss 0.18544116616249084, acc=0.9444444179534912, loss=0.18544116616249084
train: epoch 142, loss 0.029405556619167328, acc=0.9920555353164673, loss=0.029405556619167328
test: epoch 142, loss 0.2442278116941452, acc=0.9444444179534912, loss=0.2442278116941452
train: epoch 143, loss 0.04289299622178078, acc=0.9868333339691162, loss=0.04289299622178078
test: epoch 143, loss 0.2298290878534317, acc=0.9444444179534912, loss=0.2298290878534317
train: epoch 144, loss 0.03201792389154434, acc=0.9912222027778625, loss=0.03201792389154434
test: epoch 144, loss 0.2359076887369156, acc=0.9444444179534912, loss=0.2359076887369156
train: epoch 145, loss 0.041408490389585495, acc=0.987333357334137, loss=0.041408490389585495
test: epoch 145, loss 0.16330938041210175, acc=0.9444444179534912, loss=0.16330938041210175
train: epoch 146, loss 0.036984823644161224, acc=0.9904444217681885, loss=0.036984823644161224
test: epoch 146, loss 0.23102493584156036, acc=0.9444444179534912, loss=0.23102493584156036
train: epoch 147, loss 0.03812200948596001, acc=0.9894999861717224, loss=0.03812200948596001
test: epoch 147, loss 0.2621546685695648, acc=0.9444444179534912, loss=0.2621546685695648
train: epoch 148, loss 0.04087867960333824, acc=0.9891666769981384, loss=0.04087867960333824
test: epoch 148, loss 0.20189596712589264, acc=0.9444444179534912, loss=0.20189596712589264
train: epoch 149, loss 0.03331848606467247, acc=0.9900555610656738, loss=0.03331848606467247
test: epoch 149, loss 0.23470225930213928, acc=0.9444444179534912, loss=0.23470225930213928
train: epoch 150, loss 0.03343021497130394, acc=0.9901111125946045, loss=0.03343021497130394
test: epoch 150, loss 0.1808345466852188, acc=0.9444444179534912, loss=0.1808345466852188
