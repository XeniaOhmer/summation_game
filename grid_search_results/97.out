# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=0", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=27915910, receiver_embed_dim=64, save_run=0, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=27915910, receiver_embed_dim=64, save_run=False, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.4614269733428955, acc=0.16699999570846558, loss=2.4614269733428955
test: epoch 1, loss 7.560254096984863, acc=0.03611111268401146, loss=7.560254096984863
train: epoch 2, loss 1.8278861045837402, acc=0.2878333330154419, loss=1.8278861045837402
test: epoch 2, loss 7.428391933441162, acc=0.05277777835726738, loss=7.428391933441162
train: epoch 3, loss 1.6171637773513794, acc=0.35161110758781433, loss=1.6171637773513794
test: epoch 3, loss 8.413809776306152, acc=0.05277777835726738, loss=8.413809776306152
train: epoch 4, loss 1.4650131464004517, acc=0.40861111879348755, loss=1.4650131464004517
test: epoch 4, loss 7.679771900177002, acc=0.07777778059244156, loss=7.679771900177002
train: epoch 5, loss 1.3628541231155396, acc=0.4432777762413025, loss=1.3628541231155396
test: epoch 5, loss 8.49444580078125, acc=0.0555555559694767, loss=8.49444580078125
train: epoch 6, loss 1.2909647226333618, acc=0.4778333306312561, loss=1.2909647226333618
test: epoch 6, loss 8.697962760925293, acc=0.09166666865348816, loss=8.697962760925293
train: epoch 7, loss 1.2104436159133911, acc=0.5092222094535828, loss=1.2104436159133911
test: epoch 7, loss 7.931929588317871, acc=0.07222222536802292, loss=7.931929588317871
train: epoch 8, loss 1.163860559463501, acc=0.5318333506584167, loss=1.163860559463501
test: epoch 8, loss 7.717188835144043, acc=0.07500000298023224, loss=7.717188835144043
train: epoch 9, loss 1.1074554920196533, acc=0.5541666746139526, loss=1.1074554920196533
test: epoch 9, loss 5.988103866577148, acc=0.10000000149011612, loss=5.988103866577148
train: epoch 10, loss 1.0728756189346313, acc=0.5651111006736755, loss=1.0728756189346313
test: epoch 10, loss 5.849241256713867, acc=0.08055555820465088, loss=5.849241256713867
train: epoch 11, loss 1.0405473709106445, acc=0.5803889036178589, loss=1.0405473709106445
test: epoch 11, loss 6.827973365783691, acc=0.0694444477558136, loss=6.827973365783691
train: epoch 12, loss 1.013608694076538, acc=0.5963333249092102, loss=1.013608694076538
test: epoch 12, loss 7.019261360168457, acc=0.05000000074505806, loss=7.019261360168457
train: epoch 13, loss 0.9771685600280762, acc=0.6127777695655823, loss=0.9771685600280762
test: epoch 13, loss 6.1471991539001465, acc=0.0972222238779068, loss=6.1471991539001465
train: epoch 14, loss 0.9459931254386902, acc=0.6256111264228821, loss=0.9459931254386902
test: epoch 14, loss 5.64377498626709, acc=0.09444444626569748, loss=5.64377498626709
train: epoch 15, loss 0.9392849802970886, acc=0.6359999775886536, loss=0.9392849802970886
test: epoch 15, loss 5.570647716522217, acc=0.11666666716337204, loss=5.570647716522217
train: epoch 16, loss 0.9063088297843933, acc=0.640333354473114, loss=0.9063088297843933
test: epoch 16, loss 6.522878646850586, acc=0.10277777910232544, loss=6.522878646850586
train: epoch 17, loss 0.8761245012283325, acc=0.6558333039283752, loss=0.8761245012283325
test: epoch 17, loss 5.463927745819092, acc=0.11944444477558136, loss=5.463927745819092
train: epoch 18, loss 0.8764392137527466, acc=0.6602222323417664, loss=0.8764392137527466
test: epoch 18, loss 5.2394304275512695, acc=0.14722222089767456, loss=5.2394304275512695
train: epoch 19, loss 0.8442485928535461, acc=0.6681666374206543, loss=0.8442485928535461
test: epoch 19, loss 7.04271125793457, acc=0.12222222238779068, loss=7.04271125793457
train: epoch 20, loss 0.8141517639160156, acc=0.6850555539131165, loss=0.8141517639160156
test: epoch 20, loss 5.302243709564209, acc=0.11388888955116272, loss=5.302243709564209
train: epoch 21, loss 0.8306283950805664, acc=0.6786110997200012, loss=0.8306283950805664
test: epoch 21, loss 5.994353771209717, acc=0.11944444477558136, loss=5.994353771209717
train: epoch 22, loss 0.81861811876297, acc=0.6839444637298584, loss=0.81861811876297
test: epoch 22, loss 5.183854103088379, acc=0.14166666567325592, loss=5.183854103088379
train: epoch 23, loss 0.7968682646751404, acc=0.6946666836738586, loss=0.7968682646751404
test: epoch 23, loss 4.766198635101318, acc=0.1388888955116272, loss=4.766198635101318
train: epoch 24, loss 0.7832974195480347, acc=0.6961110830307007, loss=0.7832974195480347
test: epoch 24, loss 5.623062610626221, acc=0.11666666716337204, loss=5.623062610626221
train: epoch 25, loss 0.7672611474990845, acc=0.7093333601951599, loss=0.7672611474990845
test: epoch 25, loss 4.358621597290039, acc=0.11666666716337204, loss=4.358621597290039
train: epoch 26, loss 0.7514810562133789, acc=0.7158889174461365, loss=0.7514810562133789
test: epoch 26, loss 5.224947452545166, acc=0.11666666716337204, loss=5.224947452545166
train: epoch 27, loss 0.7483081221580505, acc=0.7131111025810242, loss=0.7483081221580505
test: epoch 27, loss 4.608770370483398, acc=0.1666666716337204, loss=4.608770370483398
train: epoch 28, loss 0.7388917803764343, acc=0.7196666598320007, loss=0.7388917803764343
test: epoch 28, loss 3.932957649230957, acc=0.15000000596046448, loss=3.932957649230957
train: epoch 29, loss 0.7304084897041321, acc=0.7195000052452087, loss=0.7304084897041321
test: epoch 29, loss 4.760838508605957, acc=0.10277777910232544, loss=4.760838508605957
train: epoch 30, loss 0.7086368203163147, acc=0.7325000166893005, loss=0.7086368203163147
test: epoch 30, loss 4.76486873626709, acc=0.13611111044883728, loss=4.76486873626709
train: epoch 31, loss 0.7039514780044556, acc=0.7320555448532104, loss=0.7039514780044556
test: epoch 31, loss 5.255730152130127, acc=0.11388888955116272, loss=5.255730152130127
train: epoch 32, loss 0.6919881105422974, acc=0.7378333210945129, loss=0.6919881105422974
test: epoch 32, loss 4.478525161743164, acc=0.1527777761220932, loss=4.478525161743164
train: epoch 33, loss 0.6857748031616211, acc=0.7385555505752563, loss=0.6857748031616211
test: epoch 33, loss 4.68964147567749, acc=0.11388888955116272, loss=4.68964147567749
train: epoch 34, loss 0.6930283904075623, acc=0.7380555272102356, loss=0.6930283904075623
test: epoch 34, loss 4.744291305541992, acc=0.12777778506278992, loss=4.744291305541992
train: epoch 35, loss 0.6839300394058228, acc=0.7418888807296753, loss=0.6839300394058228
test: epoch 35, loss 4.159219264984131, acc=0.18888889253139496, loss=4.159219264984131
train: epoch 36, loss 0.6901974081993103, acc=0.738444447517395, loss=0.6901974081993103
test: epoch 36, loss 3.5026674270629883, acc=0.13333334028720856, loss=3.5026674270629883
train: epoch 37, loss 0.688435435295105, acc=0.7368888854980469, loss=0.688435435295105
test: epoch 37, loss 4.419409275054932, acc=0.13611111044883728, loss=4.419409275054932
train: epoch 38, loss 0.6818684935569763, acc=0.742111086845398, loss=0.6818684935569763
test: epoch 38, loss 4.19825553894043, acc=0.15555556118488312, loss=4.19825553894043
train: epoch 39, loss 0.6461427807807922, acc=0.7572222352027893, loss=0.6461427807807922
test: epoch 39, loss 4.939053535461426, acc=0.1527777761220932, loss=4.939053535461426
train: epoch 40, loss 0.6558948755264282, acc=0.7540000081062317, loss=0.6558948755264282
test: epoch 40, loss 4.095636367797852, acc=0.1388888955116272, loss=4.095636367797852
train: epoch 41, loss 0.6728386282920837, acc=0.7508888840675354, loss=0.6728386282920837
test: epoch 41, loss 3.934133768081665, acc=0.1805555522441864, loss=3.934133768081665
train: epoch 42, loss 0.6658366918563843, acc=0.7551666498184204, loss=0.6658366918563843
test: epoch 42, loss 3.7408506870269775, acc=0.15555556118488312, loss=3.7408506870269775
train: epoch 43, loss 0.6700090765953064, acc=0.7488333582878113, loss=0.6700090765953064
test: epoch 43, loss 3.0871975421905518, acc=0.19166666269302368, loss=3.0871975421905518
train: epoch 44, loss 0.637328028678894, acc=0.7584999799728394, loss=0.637328028678894
test: epoch 44, loss 3.4297525882720947, acc=0.16111111640930176, loss=3.4297525882720947
train: epoch 45, loss 0.6286405324935913, acc=0.7637222409248352, loss=0.6286405324935913
test: epoch 45, loss 3.4866442680358887, acc=0.1388888955116272, loss=3.4866442680358887
train: epoch 46, loss 0.6525859236717224, acc=0.7599999904632568, loss=0.6525859236717224
test: epoch 46, loss 3.1420722007751465, acc=0.13333334028720856, loss=3.1420722007751465
train: epoch 47, loss 0.6440790295600891, acc=0.7569444179534912, loss=0.6440790295600891
test: epoch 47, loss 3.43467378616333, acc=0.23888888955116272, loss=3.43467378616333
train: epoch 48, loss 0.6218279004096985, acc=0.7667222023010254, loss=0.6218279004096985
test: epoch 48, loss 3.785759925842285, acc=0.17499999701976776, loss=3.785759925842285
train: epoch 49, loss 0.6317223906517029, acc=0.7649999856948853, loss=0.6317223906517029
test: epoch 49, loss 3.1755852699279785, acc=0.17222222685813904, loss=3.1755852699279785
train: epoch 50, loss 0.6202410459518433, acc=0.7651110887527466, loss=0.6202410459518433
test: epoch 50, loss 2.9171648025512695, acc=0.14166666567325592, loss=2.9171648025512695
train: epoch 51, loss 0.6119614243507385, acc=0.7701666951179504, loss=0.6119614243507385
test: epoch 51, loss 3.4739739894866943, acc=0.12222222238779068, loss=3.4739739894866943
train: epoch 52, loss 0.6354091167449951, acc=0.757611095905304, loss=0.6354091167449951
test: epoch 52, loss 2.776350975036621, acc=0.2083333283662796, loss=2.776350975036621
train: epoch 53, loss 0.6098374724388123, acc=0.7730000019073486, loss=0.6098374724388123
test: epoch 53, loss 2.5834131240844727, acc=0.25, loss=2.5834131240844727
train: epoch 54, loss 0.619996964931488, acc=0.7670555710792542, loss=0.619996964931488
test: epoch 54, loss 2.4464287757873535, acc=0.22777777910232544, loss=2.4464287757873535
train: epoch 55, loss 0.6218751668930054, acc=0.7689999938011169, loss=0.6218751668930054
test: epoch 55, loss 2.9771382808685303, acc=0.21111111342906952, loss=2.9771382808685303
train: epoch 56, loss 0.6174958944320679, acc=0.765333354473114, loss=0.6174958944320679
test: epoch 56, loss 2.4187352657318115, acc=0.20277777314186096, loss=2.4187352657318115
train: epoch 57, loss 0.6108608245849609, acc=0.7724444270133972, loss=0.6108608245849609
test: epoch 57, loss 3.7204935550689697, acc=0.16944444179534912, loss=3.7204935550689697
train: epoch 58, loss 0.6028045415878296, acc=0.7701666951179504, loss=0.6028045415878296
test: epoch 58, loss 2.9445436000823975, acc=0.17222222685813904, loss=2.9445436000823975
train: epoch 59, loss 0.5889040231704712, acc=0.7779444456100464, loss=0.5889040231704712
test: epoch 59, loss 3.4190256595611572, acc=0.11944444477558136, loss=3.4190256595611572
train: epoch 60, loss 0.5937413573265076, acc=0.7797222137451172, loss=0.5937413573265076
test: epoch 60, loss 2.7797868251800537, acc=0.19166666269302368, loss=2.7797868251800537
train: epoch 61, loss 0.607908308506012, acc=0.7733888626098633, loss=0.607908308506012
test: epoch 61, loss 2.816178798675537, acc=0.11944444477558136, loss=2.816178798675537
train: epoch 62, loss 0.6041703820228577, acc=0.7750555276870728, loss=0.6041703820228577
test: epoch 62, loss 3.3455984592437744, acc=0.21666666865348816, loss=3.3455984592437744
train: epoch 63, loss 0.6096934676170349, acc=0.7676666378974915, loss=0.6096934676170349
test: epoch 63, loss 3.245422124862671, acc=0.13055555522441864, loss=3.245422124862671
train: epoch 64, loss 0.6005170345306396, acc=0.7701666951179504, loss=0.6005170345306396
test: epoch 64, loss 3.3266637325286865, acc=0.1944444477558136, loss=3.3266637325286865
train: epoch 65, loss 0.598301112651825, acc=0.7791666388511658, loss=0.598301112651825
test: epoch 65, loss 2.545644760131836, acc=0.18333333730697632, loss=2.545644760131836
train: epoch 66, loss 0.5913305282592773, acc=0.7794444561004639, loss=0.5913305282592773
test: epoch 66, loss 3.041470766067505, acc=0.12222222238779068, loss=3.041470766067505
train: epoch 67, loss 0.5907045006752014, acc=0.7751111388206482, loss=0.5907045006752014
test: epoch 67, loss 3.2333853244781494, acc=0.2083333283662796, loss=3.2333853244781494
train: epoch 68, loss 0.590522825717926, acc=0.7778888940811157, loss=0.590522825717926
test: epoch 68, loss 2.668827533721924, acc=0.22777777910232544, loss=2.668827533721924
train: epoch 69, loss 0.5745398998260498, acc=0.7816666960716248, loss=0.5745398998260498
test: epoch 69, loss 2.713261365890503, acc=0.24166665971279144, loss=2.713261365890503
train: epoch 70, loss 0.6001530289649963, acc=0.7755555510520935, loss=0.6001530289649963
test: epoch 70, loss 2.3462047576904297, acc=0.21944443881511688, loss=2.3462047576904297
train: epoch 71, loss 0.5830915570259094, acc=0.7822222113609314, loss=0.5830915570259094
test: epoch 71, loss 3.202927827835083, acc=0.18888889253139496, loss=3.202927827835083
train: epoch 72, loss 0.6041191816329956, acc=0.7789999842643738, loss=0.6041191816329956
test: epoch 72, loss 2.725924015045166, acc=0.18611110746860504, loss=2.725924015045166
train: epoch 73, loss 0.5719817876815796, acc=0.7829999923706055, loss=0.5719817876815796
test: epoch 73, loss 2.2179136276245117, acc=0.2805555462837219, loss=2.2179136276245117
train: epoch 74, loss 0.6050346493721008, acc=0.774222195148468, loss=0.6050346493721008
test: epoch 74, loss 2.239323616027832, acc=0.21111111342906952, loss=2.239323616027832
train: epoch 75, loss 0.5771140456199646, acc=0.7809444665908813, loss=0.5771140456199646
test: epoch 75, loss 2.561953067779541, acc=0.18611110746860504, loss=2.561953067779541
train: epoch 76, loss 0.5897353887557983, acc=0.7780555486679077, loss=0.5897353887557983
test: epoch 76, loss 2.5483806133270264, acc=0.16388888657093048, loss=2.5483806133270264
train: epoch 77, loss 0.6086272597312927, acc=0.7714999914169312, loss=0.6086272597312927
test: epoch 77, loss 2.7844982147216797, acc=0.20000000298023224, loss=2.7844982147216797
train: epoch 78, loss 0.5706969499588013, acc=0.7845555543899536, loss=0.5706969499588013
test: epoch 78, loss 2.3918542861938477, acc=0.17499999701976776, loss=2.3918542861938477
train: epoch 79, loss 0.5934529304504395, acc=0.7786111235618591, loss=0.5934529304504395
test: epoch 79, loss 2.3559560775756836, acc=0.20555555820465088, loss=2.3559560775756836
train: epoch 80, loss 0.6020938754081726, acc=0.7771666646003723, loss=0.6020938754081726
test: epoch 80, loss 2.116899013519287, acc=0.2666666805744171, loss=2.116899013519287
train: epoch 81, loss 0.6214785575866699, acc=0.766777753829956, loss=0.6214785575866699
test: epoch 81, loss 2.9092695713043213, acc=0.22499999403953552, loss=2.9092695713043213
train: epoch 82, loss 0.6122437715530396, acc=0.768833339214325, loss=0.6122437715530396
test: epoch 82, loss 2.7791175842285156, acc=0.17222222685813904, loss=2.7791175842285156
train: epoch 83, loss 0.605279266834259, acc=0.7730555534362793, loss=0.605279266834259
test: epoch 83, loss 2.6219301223754883, acc=0.21944443881511688, loss=2.6219301223754883
train: epoch 84, loss 0.591001033782959, acc=0.7767778038978577, loss=0.591001033782959
test: epoch 84, loss 2.8359949588775635, acc=0.23888888955116272, loss=2.8359949588775635
train: epoch 85, loss 0.5875887274742126, acc=0.7784444689750671, loss=0.5875887274742126
test: epoch 85, loss 2.2797744274139404, acc=0.20000000298023224, loss=2.2797744274139404
train: epoch 86, loss 0.6217548251152039, acc=0.7703889012336731, loss=0.6217548251152039
test: epoch 86, loss 2.30806040763855, acc=0.2083333283662796, loss=2.30806040763855
train: epoch 87, loss 0.6050502061843872, acc=0.7701666951179504, loss=0.6050502061843872
test: epoch 87, loss 2.5055646896362305, acc=0.2361111044883728, loss=2.5055646896362305
train: epoch 88, loss 0.5843999981880188, acc=0.7797777652740479, loss=0.5843999981880188
test: epoch 88, loss 2.389401912689209, acc=0.2777777910232544, loss=2.389401912689209
train: epoch 89, loss 0.5842815637588501, acc=0.7805555462837219, loss=0.5842815637588501
test: epoch 89, loss 2.2094366550445557, acc=0.21388888359069824, loss=2.2094366550445557
train: epoch 90, loss 0.6038393974304199, acc=0.7803333401679993, loss=0.6038393974304199
test: epoch 90, loss 2.4664456844329834, acc=0.2361111044883728, loss=2.4664456844329834
train: epoch 91, loss 0.5977335572242737, acc=0.7741110920906067, loss=0.5977335572242737
test: epoch 91, loss 2.8065366744995117, acc=0.2083333283662796, loss=2.8065366744995117
train: epoch 92, loss 0.5915734171867371, acc=0.776888906955719, loss=0.5915734171867371
test: epoch 92, loss 1.9705134630203247, acc=0.2777777910232544, loss=1.9705134630203247
train: epoch 93, loss 0.5993375778198242, acc=0.7713333368301392, loss=0.5993375778198242
test: epoch 93, loss 1.9553711414337158, acc=0.27222222089767456, loss=1.9553711414337158
train: epoch 94, loss 0.5872577428817749, acc=0.7760000228881836, loss=0.5872577428817749
test: epoch 94, loss 2.38100528717041, acc=0.25555557012557983, loss=2.38100528717041
train: epoch 95, loss 0.5908775925636292, acc=0.7757777571678162, loss=0.5908775925636292
test: epoch 95, loss 1.88373863697052, acc=0.2638888955116272, loss=1.88373863697052
train: epoch 96, loss 0.6039274334907532, acc=0.7698888778686523, loss=0.6039274334907532
test: epoch 96, loss 2.6470720767974854, acc=0.28333333134651184, loss=2.6470720767974854
train: epoch 97, loss 0.5843943953514099, acc=0.7812777757644653, loss=0.5843943953514099
test: epoch 97, loss 1.9781838655471802, acc=0.26944443583488464, loss=1.9781838655471802
train: epoch 98, loss 0.6113961935043335, acc=0.7728888988494873, loss=0.6113961935043335
test: epoch 98, loss 2.095928907394409, acc=0.24444444477558136, loss=2.095928907394409
train: epoch 99, loss 0.6134815812110901, acc=0.7698888778686523, loss=0.6134815812110901
test: epoch 99, loss 1.8543654680252075, acc=0.28611111640930176, loss=1.8543654680252075
train: epoch 100, loss 0.6106119751930237, acc=0.7725555300712585, loss=0.6106119751930237
test: epoch 100, loss 1.8355296850204468, acc=0.3222222328186035, loss=1.8355296850204468
train: epoch 101, loss 0.5890031456947327, acc=0.7722777724266052, loss=0.5890031456947327
test: epoch 101, loss 1.795005202293396, acc=0.2527777850627899, loss=1.795005202293396
train: epoch 102, loss 0.5728309750556946, acc=0.7829444408416748, loss=0.5728309750556946
test: epoch 102, loss 1.8781872987747192, acc=0.32777777314186096, loss=1.8781872987747192
train: epoch 103, loss 0.5875542163848877, acc=0.7797222137451172, loss=0.5875542163848877
test: epoch 103, loss 1.9599403142929077, acc=0.2666666805744171, loss=1.9599403142929077
train: epoch 104, loss 0.5837804079055786, acc=0.7756111025810242, loss=0.5837804079055786
test: epoch 104, loss 2.0482563972473145, acc=0.29722222685813904, loss=2.0482563972473145
train: epoch 105, loss 0.6029443144798279, acc=0.7718333601951599, loss=0.6029443144798279
test: epoch 105, loss 1.859715461730957, acc=0.33888888359069824, loss=1.859715461730957
train: epoch 106, loss 0.5974599719047546, acc=0.7731666564941406, loss=0.5974599719047546
test: epoch 106, loss 1.7710171937942505, acc=0.34166666865348816, loss=1.7710171937942505
train: epoch 107, loss 0.5840067267417908, acc=0.7764999866485596, loss=0.5840067267417908
test: epoch 107, loss 2.274862766265869, acc=0.20000000298023224, loss=2.274862766265869
train: epoch 108, loss 0.5848969221115112, acc=0.7757222056388855, loss=0.5848969221115112
test: epoch 108, loss 1.8053524494171143, acc=0.2777777910232544, loss=1.8053524494171143
train: epoch 109, loss 0.5860264897346497, acc=0.7766666412353516, loss=0.5860264897346497
test: epoch 109, loss 2.1100034713745117, acc=0.21388888359069824, loss=2.1100034713745117
train: epoch 110, loss 0.5977955460548401, acc=0.7734444737434387, loss=0.5977955460548401
test: epoch 110, loss 2.231433868408203, acc=0.22499999403953552, loss=2.231433868408203
train: epoch 111, loss 0.6125786304473877, acc=0.7695000171661377, loss=0.6125786304473877
test: epoch 111, loss 1.7514827251434326, acc=0.3611111044883728, loss=1.7514827251434326
train: epoch 112, loss 0.5640841126441956, acc=0.7802222371101379, loss=0.5640841126441956
test: epoch 112, loss 2.065524101257324, acc=0.2777777910232544, loss=2.065524101257324
train: epoch 113, loss 0.5846710205078125, acc=0.7780555486679077, loss=0.5846710205078125
test: epoch 113, loss 2.023198366165161, acc=0.23888888955116272, loss=2.023198366165161
train: epoch 114, loss 0.5774663090705872, acc=0.7771111130714417, loss=0.5774663090705872
test: epoch 114, loss 1.775331974029541, acc=0.3166666626930237, loss=1.775331974029541
train: epoch 115, loss 0.5778313279151917, acc=0.7766110897064209, loss=0.5778313279151917
test: epoch 115, loss 2.0176634788513184, acc=0.2916666567325592, loss=2.0176634788513184
train: epoch 116, loss 0.5837063193321228, acc=0.7743333578109741, loss=0.5837063193321228
test: epoch 116, loss 2.0038979053497314, acc=0.31111112236976624, loss=2.0038979053497314
train: epoch 117, loss 0.5629743933677673, acc=0.7875000238418579, loss=0.5629743933677673
test: epoch 117, loss 2.106095552444458, acc=0.25833332538604736, loss=2.106095552444458
train: epoch 118, loss 0.6005257368087769, acc=0.7745555639266968, loss=0.6005257368087769
test: epoch 118, loss 1.726992130279541, acc=0.35555556416511536, loss=1.726992130279541
train: epoch 119, loss 0.6069856286048889, acc=0.7716110944747925, loss=0.6069856286048889
test: epoch 119, loss 2.201564311981201, acc=0.2777777910232544, loss=2.201564311981201
train: epoch 120, loss 0.5710679888725281, acc=0.7826666831970215, loss=0.5710679888725281
test: epoch 120, loss 1.8839199542999268, acc=0.26944443583488464, loss=1.8839199542999268
train: epoch 121, loss 0.5713386535644531, acc=0.7808333039283752, loss=0.5713386535644531
test: epoch 121, loss 2.020482063293457, acc=0.3083333373069763, loss=2.020482063293457
train: epoch 122, loss 0.5755781531333923, acc=0.7799999713897705, loss=0.5755781531333923
test: epoch 122, loss 1.8468824625015259, acc=0.28611111640930176, loss=1.8468824625015259
train: epoch 123, loss 0.5950636267662048, acc=0.7723333239555359, loss=0.5950636267662048
test: epoch 123, loss 1.6646788120269775, acc=0.3916666805744171, loss=1.6646788120269775
train: epoch 124, loss 0.5835649967193604, acc=0.7749444246292114, loss=0.5835649967193604
test: epoch 124, loss 1.9791884422302246, acc=0.2638888955116272, loss=1.9791884422302246
train: epoch 125, loss 0.5913944840431213, acc=0.7697222232818604, loss=0.5913944840431213
test: epoch 125, loss 2.0364840030670166, acc=0.2805555462837219, loss=2.0364840030670166
train: epoch 126, loss 0.5889970064163208, acc=0.7705555558204651, loss=0.5889970064163208
test: epoch 126, loss 2.172933340072632, acc=0.26944443583488464, loss=2.172933340072632
train: epoch 127, loss 0.5757237672805786, acc=0.7773333191871643, loss=0.5757237672805786
test: epoch 127, loss 2.05198335647583, acc=0.35555556416511536, loss=2.05198335647583
train: epoch 128, loss 0.5593231320381165, acc=0.7857778072357178, loss=0.5593231320381165
test: epoch 128, loss 1.8162555694580078, acc=0.3472222089767456, loss=1.8162555694580078
train: epoch 129, loss 0.5612572431564331, acc=0.7829444408416748, loss=0.5612572431564331
test: epoch 129, loss 1.8223531246185303, acc=0.36666667461395264, loss=1.8223531246185303
train: epoch 130, loss 0.5693057775497437, acc=0.7808333039283752, loss=0.5693057775497437
test: epoch 130, loss 1.7612524032592773, acc=0.3444444537162781, loss=1.7612524032592773
train: epoch 131, loss 0.5531325340270996, acc=0.7876666784286499, loss=0.5531325340270996
test: epoch 131, loss 1.8018019199371338, acc=0.33888888359069824, loss=1.8018019199371338
train: epoch 132, loss 0.5687370300292969, acc=0.781166672706604, loss=0.5687370300292969
test: epoch 132, loss 1.973842740058899, acc=0.3194444477558136, loss=1.973842740058899
train: epoch 133, loss 0.5740794539451599, acc=0.7832221984863281, loss=0.5740794539451599
test: epoch 133, loss 1.8026880025863647, acc=0.38333332538604736, loss=1.8026880025863647
train: epoch 134, loss 0.5742834806442261, acc=0.7802777886390686, loss=0.5742834806442261
test: epoch 134, loss 1.9730629920959473, acc=0.3499999940395355, loss=1.9730629920959473
train: epoch 135, loss 0.5573976039886475, acc=0.7844444513320923, loss=0.5573976039886475
test: epoch 135, loss 1.572401523590088, acc=0.4444444477558136, loss=1.572401523590088
train: epoch 136, loss 0.5692428350448608, acc=0.7790555357933044, loss=0.5692428350448608
test: epoch 136, loss 1.7436883449554443, acc=0.3583333194255829, loss=1.7436883449554443
train: epoch 137, loss 0.5880420207977295, acc=0.773722231388092, loss=0.5880420207977295
test: epoch 137, loss 1.66713547706604, acc=0.3166666626930237, loss=1.66713547706604
train: epoch 138, loss 0.582126796245575, acc=0.7796111106872559, loss=0.582126796245575
test: epoch 138, loss 1.7723139524459839, acc=0.3499999940395355, loss=1.7723139524459839
train: epoch 139, loss 0.5522012710571289, acc=0.7878888845443726, loss=0.5522012710571289
test: epoch 139, loss 1.2610517740249634, acc=0.4277777671813965, loss=1.2610517740249634
train: epoch 140, loss 0.5530073046684265, acc=0.7889444231987, loss=0.5530073046684265
test: epoch 140, loss 1.7011654376983643, acc=0.3611111044883728, loss=1.7011654376983643
train: epoch 141, loss 0.5673398375511169, acc=0.7854999899864197, loss=0.5673398375511169
test: epoch 141, loss 1.598555326461792, acc=0.2638888955116272, loss=1.598555326461792
train: epoch 142, loss 0.5850026607513428, acc=0.7706666588783264, loss=0.5850026607513428
test: epoch 142, loss 1.9666742086410522, acc=0.24722221493721008, loss=1.9666742086410522
train: epoch 143, loss 0.5542529225349426, acc=0.7846111059188843, loss=0.5542529225349426
test: epoch 143, loss 2.299828052520752, acc=0.35555556416511536, loss=2.299828052520752
train: epoch 144, loss 0.5497673153877258, acc=0.7883333563804626, loss=0.5497673153877258
test: epoch 144, loss 1.5033091306686401, acc=0.4055555462837219, loss=1.5033091306686401
train: epoch 145, loss 0.5427154898643494, acc=0.7846111059188843, loss=0.5427154898643494
test: epoch 145, loss 1.3744451999664307, acc=0.35555556416511536, loss=1.3744451999664307
train: epoch 146, loss 0.5693303942680359, acc=0.7819444537162781, loss=0.5693303942680359
test: epoch 146, loss 1.939212441444397, acc=0.3305555582046509, loss=1.939212441444397
train: epoch 147, loss 0.5358194708824158, acc=0.793055534362793, loss=0.5358194708824158
test: epoch 147, loss 1.3312106132507324, acc=0.4194444417953491, loss=1.3312106132507324
train: epoch 148, loss 0.581104576587677, acc=0.7792778015136719, loss=0.581104576587677
test: epoch 148, loss 1.6692237854003906, acc=0.32499998807907104, loss=1.6692237854003906
train: epoch 149, loss 0.5695429444313049, acc=0.7821111083030701, loss=0.5695429444313049
test: epoch 149, loss 1.5579631328582764, acc=0.4277777671813965, loss=1.5579631328582764
train: epoch 150, loss 0.5815843939781189, acc=0.7717777490615845, loss=0.5815843939781189
test: epoch 150, loss 1.7008675336837769, acc=0.4333333373069763, loss=1.7008675336837769
