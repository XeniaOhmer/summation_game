# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1", "--temp_decay=0.995", "--one_hot=true", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1674360436, receiver_embed_dim=32, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.2945168018341064, acc=0.055888887494802475, loss=3.2945168018341064
test: epoch 1, loss 2.99859619140625, acc=0.08055555820465088, loss=2.99859619140625
train: epoch 2, loss 2.4598302841186523, acc=0.1582222282886505, loss=2.4598302841186523
test: epoch 2, loss 2.6627347469329834, acc=0.10277777910232544, loss=2.6627347469329834
train: epoch 3, loss 1.929328441619873, acc=0.25644445419311523, loss=1.929328441619873
test: epoch 3, loss 2.651156425476074, acc=0.1527777761220932, loss=2.651156425476074
train: epoch 4, loss 1.6980384588241577, acc=0.31672221422195435, loss=1.6980384588241577
test: epoch 4, loss 1.9626860618591309, acc=0.24166665971279144, loss=1.9626860618591309
train: epoch 5, loss 1.5097471475601196, acc=0.36722221970558167, loss=1.5097471475601196
test: epoch 5, loss 1.8622030019760132, acc=0.2750000059604645, loss=1.8622030019760132
train: epoch 6, loss 1.389129638671875, acc=0.4018888771533966, loss=1.389129638671875
test: epoch 6, loss 1.73851478099823, acc=0.26944443583488464, loss=1.73851478099823
train: epoch 7, loss 1.305707335472107, acc=0.43566668033599854, loss=1.305707335472107
test: epoch 7, loss 1.803041934967041, acc=0.2944444417953491, loss=1.803041934967041
train: epoch 8, loss 1.2315493822097778, acc=0.4646666646003723, loss=1.2315493822097778
test: epoch 8, loss 1.7454655170440674, acc=0.2944444417953491, loss=1.7454655170440674
train: epoch 9, loss 1.1654859781265259, acc=0.49227777123451233, loss=1.1654859781265259
test: epoch 9, loss 1.5657994747161865, acc=0.29722222685813904, loss=1.5657994747161865
train: epoch 10, loss 1.0859962701797485, acc=0.5271111130714417, loss=1.0859962701797485
test: epoch 10, loss 1.6126682758331299, acc=0.28611111640930176, loss=1.6126682758331299
train: epoch 11, loss 1.0583534240722656, acc=0.5274444222450256, loss=1.0583534240722656
test: epoch 11, loss 1.6980373859405518, acc=0.30000001192092896, loss=1.6980373859405518
train: epoch 12, loss 1.0235347747802734, acc=0.5391666889190674, loss=1.0235347747802734
test: epoch 12, loss 1.6246955394744873, acc=0.3027777671813965, loss=1.6246955394744873
train: epoch 13, loss 0.9934428930282593, acc=0.550777792930603, loss=0.9934428930282593
test: epoch 13, loss 1.6136635541915894, acc=0.31388887763023376, loss=1.6136635541915894
train: epoch 14, loss 0.9633421897888184, acc=0.5648888945579529, loss=0.9633421897888184
test: epoch 14, loss 1.7252153158187866, acc=0.3222222328186035, loss=1.7252153158187866
train: epoch 15, loss 0.9497886896133423, acc=0.5685555338859558, loss=0.9497886896133423
test: epoch 15, loss 1.7250810861587524, acc=0.3027777671813965, loss=1.7250810861587524
train: epoch 16, loss 0.950123131275177, acc=0.566444456577301, loss=0.950123131275177
test: epoch 16, loss 1.7512987852096558, acc=0.3222222328186035, loss=1.7512987852096558
train: epoch 17, loss 0.9009835124015808, acc=0.5837777853012085, loss=0.9009835124015808
test: epoch 17, loss 1.6376217603683472, acc=0.35555556416511536, loss=1.6376217603683472
train: epoch 18, loss 0.9061535000801086, acc=0.5816110968589783, loss=0.9061535000801086
test: epoch 18, loss 1.4962338209152222, acc=0.39722222089767456, loss=1.4962338209152222
train: epoch 19, loss 0.8856974840164185, acc=0.5914999842643738, loss=0.8856974840164185
test: epoch 19, loss 1.57754385471344, acc=0.3638888895511627, loss=1.57754385471344
train: epoch 20, loss 0.8637886047363281, acc=0.5987222194671631, loss=0.8637886047363281
test: epoch 20, loss 1.6561110019683838, acc=0.35277777910232544, loss=1.6561110019683838
train: epoch 21, loss 0.8464693427085876, acc=0.6059444546699524, loss=0.8464693427085876
test: epoch 21, loss 1.4932526350021362, acc=0.38055557012557983, loss=1.4932526350021362
train: epoch 22, loss 0.8330625891685486, acc=0.6124444603919983, loss=0.8330625891685486
test: epoch 22, loss 1.52264404296875, acc=0.3888888955116272, loss=1.52264404296875
train: epoch 23, loss 0.8346266746520996, acc=0.612666666507721, loss=0.8346266746520996
test: epoch 23, loss 1.6465189456939697, acc=0.40833333134651184, loss=1.6465189456939697
train: epoch 24, loss 0.8009729385375977, acc=0.6228333115577698, loss=0.8009729385375977
test: epoch 24, loss 1.536563515663147, acc=0.4194444417953491, loss=1.536563515663147
train: epoch 25, loss 0.7990970611572266, acc=0.6266666650772095, loss=0.7990970611572266
test: epoch 25, loss 1.6550031900405884, acc=0.39722222089767456, loss=1.6550031900405884
train: epoch 26, loss 0.7797893285751343, acc=0.6334444284439087, loss=0.7797893285751343
test: epoch 26, loss 1.576743721961975, acc=0.38055557012557983, loss=1.576743721961975
train: epoch 27, loss 0.7538329362869263, acc=0.6412222385406494, loss=0.7538329362869263
test: epoch 27, loss 1.5746829509735107, acc=0.4027777910232544, loss=1.5746829509735107
train: epoch 28, loss 0.7425127625465393, acc=0.649222195148468, loss=0.7425127625465393
test: epoch 28, loss 1.4921977519989014, acc=0.4138889014720917, loss=1.4921977519989014
train: epoch 29, loss 0.7440908551216125, acc=0.6473333239555359, loss=0.7440908551216125
test: epoch 29, loss 1.4245970249176025, acc=0.4277777671813965, loss=1.4245970249176025
train: epoch 30, loss 0.7506841421127319, acc=0.6465555429458618, loss=0.7506841421127319
test: epoch 30, loss 1.4777398109436035, acc=0.3888888955116272, loss=1.4777398109436035
train: epoch 31, loss 0.7205841541290283, acc=0.6543889045715332, loss=0.7205841541290283
test: epoch 31, loss 1.5775648355484009, acc=0.42500001192092896, loss=1.5775648355484009
train: epoch 32, loss 0.7235928773880005, acc=0.6610000133514404, loss=0.7235928773880005
test: epoch 32, loss 1.5495346784591675, acc=0.4277777671813965, loss=1.5495346784591675
train: epoch 33, loss 0.7035498023033142, acc=0.663777768611908, loss=0.7035498023033142
test: epoch 33, loss 1.508233666419983, acc=0.4333333373069763, loss=1.508233666419983
train: epoch 34, loss 0.6795735359191895, acc=0.6687222123146057, loss=0.6795735359191895
test: epoch 34, loss 1.5876528024673462, acc=0.4444444477558136, loss=1.5876528024673462
train: epoch 35, loss 0.679354727268219, acc=0.679277777671814, loss=0.679354727268219
test: epoch 35, loss 1.6350274085998535, acc=0.42500001192092896, loss=1.6350274085998535
train: epoch 36, loss 0.6899918913841248, acc=0.6685555577278137, loss=0.6899918913841248
test: epoch 36, loss 1.6522469520568848, acc=0.4305555522441864, loss=1.6522469520568848
train: epoch 37, loss 0.6704189777374268, acc=0.6785555481910706, loss=0.6704189777374268
test: epoch 37, loss 1.5418237447738647, acc=0.4472222328186035, loss=1.5418237447738647
train: epoch 38, loss 0.6663823127746582, acc=0.6796666383743286, loss=0.6663823127746582
test: epoch 38, loss 1.6479285955429077, acc=0.4333333373069763, loss=1.6479285955429077
train: epoch 39, loss 0.6720757484436035, acc=0.6751111149787903, loss=0.6720757484436035
test: epoch 39, loss 1.4222177267074585, acc=0.4000000059604645, loss=1.4222177267074585
train: epoch 40, loss 0.6681406497955322, acc=0.6808333396911621, loss=0.6681406497955322
test: epoch 40, loss 1.4765669107437134, acc=0.4277777671813965, loss=1.4765669107437134
train: epoch 41, loss 0.6685009598731995, acc=0.6775555610656738, loss=0.6685009598731995
test: epoch 41, loss 1.596330165863037, acc=0.4027777910232544, loss=1.596330165863037
train: epoch 42, loss 0.6503109931945801, acc=0.6876111030578613, loss=0.6503109931945801
test: epoch 42, loss 1.6053931713104248, acc=0.43888887763023376, loss=1.6053931713104248
train: epoch 43, loss 0.6367942690849304, acc=0.6910555362701416, loss=0.6367942690849304
test: epoch 43, loss 1.4916388988494873, acc=0.4277777671813965, loss=1.4916388988494873
train: epoch 44, loss 0.6519358158111572, acc=0.6855000257492065, loss=0.6519358158111572
test: epoch 44, loss 1.6044725179672241, acc=0.4611110985279083, loss=1.6044725179672241
train: epoch 45, loss 0.6480768918991089, acc=0.6885555386543274, loss=0.6480768918991089
test: epoch 45, loss 1.5837517976760864, acc=0.4611110985279083, loss=1.5837517976760864
train: epoch 46, loss 0.6634970903396606, acc=0.6831666827201843, loss=0.6634970903396606
test: epoch 46, loss 1.889172911643982, acc=0.4611110985279083, loss=1.889172911643982
train: epoch 47, loss 0.655606210231781, acc=0.6902222037315369, loss=0.655606210231781
test: epoch 47, loss 1.4957337379455566, acc=0.4611110985279083, loss=1.4957337379455566
train: epoch 48, loss 0.6435071229934692, acc=0.6937777996063232, loss=0.6435071229934692
test: epoch 48, loss 1.655523419380188, acc=0.4611110985279083, loss=1.655523419380188
train: epoch 49, loss 0.629163384437561, acc=0.6996666789054871, loss=0.629163384437561
test: epoch 49, loss 1.5852290391921997, acc=0.43611112236976624, loss=1.5852290391921997
train: epoch 50, loss 0.6226742267608643, acc=0.703499972820282, loss=0.6226742267608643
test: epoch 50, loss 1.453611969947815, acc=0.46388888359069824, loss=1.453611969947815
train: epoch 51, loss 0.6314017176628113, acc=0.6961666941642761, loss=0.6314017176628113
test: epoch 51, loss 1.548259973526001, acc=0.4694444537162781, loss=1.548259973526001
train: epoch 52, loss 0.6332268118858337, acc=0.6983888745307922, loss=0.6332268118858337
test: epoch 52, loss 1.5549196004867554, acc=0.46666666865348816, loss=1.5549196004867554
train: epoch 53, loss 0.6379765868186951, acc=0.6968333125114441, loss=0.6379765868186951
test: epoch 53, loss 1.6355643272399902, acc=0.4416666626930237, loss=1.6355643272399902
train: epoch 54, loss 0.6251489520072937, acc=0.7059444189071655, loss=0.6251489520072937
test: epoch 54, loss 1.5272139310836792, acc=0.4694444537162781, loss=1.5272139310836792
train: epoch 55, loss 0.6434378027915955, acc=0.6945555806159973, loss=0.6434378027915955
test: epoch 55, loss 1.4500632286071777, acc=0.46388888359069824, loss=1.4500632286071777
train: epoch 56, loss 0.626551628112793, acc=0.70333331823349, loss=0.626551628112793
test: epoch 56, loss 1.5005700588226318, acc=0.4694444537162781, loss=1.5005700588226318
train: epoch 57, loss 0.6162317395210266, acc=0.7083333134651184, loss=0.6162317395210266
test: epoch 57, loss 1.7123844623565674, acc=0.4277777671813965, loss=1.7123844623565674
train: epoch 58, loss 0.6283125877380371, acc=0.7035555839538574, loss=0.6283125877380371
test: epoch 58, loss 1.3462550640106201, acc=0.4749999940395355, loss=1.3462550640106201
train: epoch 59, loss 0.627868115901947, acc=0.7057222127914429, loss=0.627868115901947
test: epoch 59, loss 1.4719133377075195, acc=0.5055555701255798, loss=1.4719133377075195
train: epoch 60, loss 0.611312985420227, acc=0.7079444527626038, loss=0.611312985420227
test: epoch 60, loss 1.5292645692825317, acc=0.4722222089767456, loss=1.5292645692825317
train: epoch 61, loss 0.6202404499053955, acc=0.711388885974884, loss=0.6202404499053955
test: epoch 61, loss 1.405638337135315, acc=0.4861111044883728, loss=1.405638337135315
train: epoch 62, loss 0.6192970275878906, acc=0.7129444479942322, loss=0.6192970275878906
test: epoch 62, loss 1.486657738685608, acc=0.49166667461395264, loss=1.486657738685608
train: epoch 63, loss 0.6029883623123169, acc=0.7195555567741394, loss=0.6029883623123169
test: epoch 63, loss 1.814408540725708, acc=0.4583333432674408, loss=1.814408540725708
train: epoch 64, loss 0.6154814958572388, acc=0.7120000123977661, loss=0.6154814958572388
test: epoch 64, loss 1.4336084127426147, acc=0.49166667461395264, loss=1.4336084127426147
train: epoch 65, loss 0.6223296523094177, acc=0.7141666412353516, loss=0.6223296523094177
test: epoch 65, loss 1.268667459487915, acc=0.49166667461395264, loss=1.268667459487915
train: epoch 66, loss 0.5974131226539612, acc=0.7208889126777649, loss=0.5974131226539612
test: epoch 66, loss 1.4916094541549683, acc=0.5277777910232544, loss=1.4916094541549683
train: epoch 67, loss 0.6077378988265991, acc=0.7198888659477234, loss=0.6077378988265991
test: epoch 67, loss 1.3607784509658813, acc=0.49444442987442017, loss=1.3607784509658813
train: epoch 68, loss 0.6039875149726868, acc=0.7152222394943237, loss=0.6039875149726868
test: epoch 68, loss 1.2749046087265015, acc=0.5166666507720947, loss=1.2749046087265015
train: epoch 69, loss 0.5990829467773438, acc=0.7151666879653931, loss=0.5990829467773438
test: epoch 69, loss 1.4630876779556274, acc=0.5083333253860474, loss=1.4630876779556274
train: epoch 70, loss 0.5921679139137268, acc=0.722777783870697, loss=0.5921679139137268
test: epoch 70, loss 1.708381175994873, acc=0.49444442987442017, loss=1.708381175994873
train: epoch 71, loss 0.5935956239700317, acc=0.7281110882759094, loss=0.5935956239700317
test: epoch 71, loss 1.4513119459152222, acc=0.5111111402511597, loss=1.4513119459152222
train: epoch 72, loss 0.6028223633766174, acc=0.7287777662277222, loss=0.6028223633766174
test: epoch 72, loss 1.3940678834915161, acc=0.4888888895511627, loss=1.3940678834915161
train: epoch 73, loss 0.5840261578559875, acc=0.7308333516120911, loss=0.5840261578559875
test: epoch 73, loss 1.4068735837936401, acc=0.49444442987442017, loss=1.4068735837936401
train: epoch 74, loss 0.5808362364768982, acc=0.7287222146987915, loss=0.5808362364768982
test: epoch 74, loss 1.420060634613037, acc=0.49166667461395264, loss=1.420060634613037
train: epoch 75, loss 0.5846841931343079, acc=0.7273333072662354, loss=0.5846841931343079
test: epoch 75, loss 1.2442668676376343, acc=0.5277777910232544, loss=1.2442668676376343
train: epoch 76, loss 0.5892622470855713, acc=0.7276111245155334, loss=0.5892622470855713
test: epoch 76, loss 1.4547758102416992, acc=0.5055555701255798, loss=1.4547758102416992
train: epoch 77, loss 0.5868788361549377, acc=0.7257221937179565, loss=0.5868788361549377
test: epoch 77, loss 1.550584316253662, acc=0.5416666865348816, loss=1.550584316253662
train: epoch 78, loss 0.579876184463501, acc=0.7273889183998108, loss=0.579876184463501
test: epoch 78, loss 1.3541516065597534, acc=0.5361111164093018, loss=1.3541516065597534
train: epoch 79, loss 0.5768485069274902, acc=0.7283333539962769, loss=0.5768485069274902
test: epoch 79, loss 1.2039120197296143, acc=0.5472221970558167, loss=1.2039120197296143
train: epoch 80, loss 0.5776615142822266, acc=0.7307778000831604, loss=0.5776615142822266
test: epoch 80, loss 1.4671777486801147, acc=0.519444465637207, loss=1.4671777486801147
train: epoch 81, loss 0.5650340914726257, acc=0.7303333282470703, loss=0.5650340914726257
test: epoch 81, loss 1.3606020212173462, acc=0.5277777910232544, loss=1.3606020212173462
train: epoch 82, loss 0.564390242099762, acc=0.7335000038146973, loss=0.564390242099762
test: epoch 82, loss 1.4192230701446533, acc=0.5416666865348816, loss=1.4192230701446533
train: epoch 83, loss 0.5735755562782288, acc=0.7318333387374878, loss=0.5735755562782288
test: epoch 83, loss 1.4404619932174683, acc=0.5444444417953491, loss=1.4404619932174683
train: epoch 84, loss 0.5752196907997131, acc=0.7316111326217651, loss=0.5752196907997131
test: epoch 84, loss 1.280896544456482, acc=0.5361111164093018, loss=1.280896544456482
train: epoch 85, loss 0.5746148824691772, acc=0.7262222170829773, loss=0.5746148824691772
test: epoch 85, loss 1.40700101852417, acc=0.5138888955116272, loss=1.40700101852417
train: epoch 86, loss 0.5663663148880005, acc=0.7365555763244629, loss=0.5663663148880005
test: epoch 86, loss 1.4550886154174805, acc=0.49444442987442017, loss=1.4550886154174805
train: epoch 87, loss 0.5656600594520569, acc=0.733222246170044, loss=0.5656600594520569
test: epoch 87, loss 1.5781623125076294, acc=0.5333333611488342, loss=1.5781623125076294
train: epoch 88, loss 0.5641183853149414, acc=0.7381666898727417, loss=0.5641183853149414
test: epoch 88, loss 1.4344942569732666, acc=0.5388888716697693, loss=1.4344942569732666
train: epoch 89, loss 0.5690340995788574, acc=0.7342222332954407, loss=0.5690340995788574
test: epoch 89, loss 1.4021103382110596, acc=0.4972222149372101, loss=1.4021103382110596
train: epoch 90, loss 0.5674771070480347, acc=0.7352777719497681, loss=0.5674771070480347
test: epoch 90, loss 1.3689202070236206, acc=0.5166666507720947, loss=1.3689202070236206
train: epoch 91, loss 0.5606251955032349, acc=0.7367777824401855, loss=0.5606251955032349
test: epoch 91, loss 1.1297154426574707, acc=0.5333333611488342, loss=1.1297154426574707
train: epoch 92, loss 0.5569636821746826, acc=0.7431111335754395, loss=0.5569636821746826
test: epoch 92, loss 1.463578701019287, acc=0.5138888955116272, loss=1.463578701019287
train: epoch 93, loss 0.556847333908081, acc=0.7360000014305115, loss=0.556847333908081
test: epoch 93, loss 1.5019710063934326, acc=0.5444444417953491, loss=1.5019710063934326
train: epoch 94, loss 0.5599254369735718, acc=0.7395555377006531, loss=0.5599254369735718
test: epoch 94, loss 1.6053438186645508, acc=0.5388888716697693, loss=1.6053438186645508
train: epoch 95, loss 0.5563435554504395, acc=0.7353333234786987, loss=0.5563435554504395
test: epoch 95, loss 1.3699606657028198, acc=0.5055555701255798, loss=1.3699606657028198
train: epoch 96, loss 0.5550022721290588, acc=0.7379444241523743, loss=0.5550022721290588
test: epoch 96, loss 1.1933786869049072, acc=0.5361111164093018, loss=1.1933786869049072
train: epoch 97, loss 0.5683246850967407, acc=0.7328888773918152, loss=0.5683246850967407
test: epoch 97, loss 1.3354192972183228, acc=0.5249999761581421, loss=1.3354192972183228
train: epoch 98, loss 0.5541937947273254, acc=0.7409444451332092, loss=0.5541937947273254
test: epoch 98, loss 1.2628344297409058, acc=0.5305555462837219, loss=1.2628344297409058
train: epoch 99, loss 0.5534994602203369, acc=0.7408333420753479, loss=0.5534994602203369
test: epoch 99, loss 1.2136383056640625, acc=0.5277777910232544, loss=1.2136383056640625
train: epoch 100, loss 0.557630181312561, acc=0.7380555272102356, loss=0.557630181312561
test: epoch 100, loss 1.4344910383224487, acc=0.5361111164093018, loss=1.4344910383224487
train: epoch 101, loss 0.5570175647735596, acc=0.7356111407279968, loss=0.5570175647735596
test: epoch 101, loss 1.4381968975067139, acc=0.5166666507720947, loss=1.4381968975067139
train: epoch 102, loss 0.5505948066711426, acc=0.7438889145851135, loss=0.5505948066711426
test: epoch 102, loss 1.4307606220245361, acc=0.5333333611488342, loss=1.4307606220245361
train: epoch 103, loss 0.5482779145240784, acc=0.7426111102104187, loss=0.5482779145240784
test: epoch 103, loss 1.3080030679702759, acc=0.5333333611488342, loss=1.3080030679702759
train: epoch 104, loss 0.53301602602005, acc=0.7507777810096741, loss=0.53301602602005
test: epoch 104, loss 1.522300362586975, acc=0.5277777910232544, loss=1.522300362586975
train: epoch 105, loss 0.545676589012146, acc=0.7486666440963745, loss=0.545676589012146
test: epoch 105, loss 1.295789122581482, acc=0.519444465637207, loss=1.295789122581482
train: epoch 106, loss 0.5417989492416382, acc=0.7476666569709778, loss=0.5417989492416382
test: epoch 106, loss 1.4427313804626465, acc=0.5416666865348816, loss=1.4427313804626465
train: epoch 107, loss 0.5556309819221497, acc=0.7431666851043701, loss=0.5556309819221497
test: epoch 107, loss 1.5667996406555176, acc=0.5, loss=1.5667996406555176
train: epoch 108, loss 0.5413175821304321, acc=0.745555579662323, loss=0.5413175821304321
test: epoch 108, loss 1.357155680656433, acc=0.5333333611488342, loss=1.357155680656433
train: epoch 109, loss 0.5567477345466614, acc=0.7391666769981384, loss=0.5567477345466614
test: epoch 109, loss 1.3582080602645874, acc=0.5472221970558167, loss=1.3582080602645874
train: epoch 110, loss 0.5459462404251099, acc=0.745722234249115, loss=0.5459462404251099
test: epoch 110, loss 1.4503889083862305, acc=0.5333333611488342, loss=1.4503889083862305
train: epoch 111, loss 0.5406774282455444, acc=0.7474444508552551, loss=0.5406774282455444
test: epoch 111, loss 1.4018834829330444, acc=0.5333333611488342, loss=1.4018834829330444
train: epoch 112, loss 0.5361069440841675, acc=0.7503888607025146, loss=0.5361069440841675
test: epoch 112, loss 1.2777464389801025, acc=0.5361111164093018, loss=1.2777464389801025
train: epoch 113, loss 0.5565515160560608, acc=0.74144446849823, loss=0.5565515160560608
test: epoch 113, loss 1.4758716821670532, acc=0.49444442987442017, loss=1.4758716821670532
train: epoch 114, loss 0.5389649271965027, acc=0.7427777647972107, loss=0.5389649271965027
test: epoch 114, loss 1.3446526527404785, acc=0.5222222208976746, loss=1.3446526527404785
train: epoch 115, loss 0.5439256429672241, acc=0.7472777962684631, loss=0.5439256429672241
test: epoch 115, loss 1.3511741161346436, acc=0.5222222208976746, loss=1.3511741161346436
train: epoch 116, loss 0.5264809727668762, acc=0.7463889122009277, loss=0.5264809727668762
test: epoch 116, loss 1.4362660646438599, acc=0.5361111164093018, loss=1.4362660646438599
train: epoch 117, loss 0.5364862084388733, acc=0.7481666803359985, loss=0.5364862084388733
test: epoch 117, loss 1.3477163314819336, acc=0.519444465637207, loss=1.3477163314819336
train: epoch 118, loss 0.5512898564338684, acc=0.741777777671814, loss=0.5512898564338684
test: epoch 118, loss 1.3383406400680542, acc=0.5333333611488342, loss=1.3383406400680542
train: epoch 119, loss 0.5322839021682739, acc=0.7471666932106018, loss=0.5322839021682739
test: epoch 119, loss 1.2769232988357544, acc=0.5388888716697693, loss=1.2769232988357544
train: epoch 120, loss 0.5431923866271973, acc=0.7463889122009277, loss=0.5431923866271973
test: epoch 120, loss 1.5009077787399292, acc=0.5305555462837219, loss=1.5009077787399292
train: epoch 121, loss 0.5380936861038208, acc=0.7467777729034424, loss=0.5380936861038208
test: epoch 121, loss 1.453549861907959, acc=0.5333333611488342, loss=1.453549861907959
train: epoch 122, loss 0.5292386412620544, acc=0.7516666650772095, loss=0.5292386412620544
test: epoch 122, loss 1.3764721155166626, acc=0.5388888716697693, loss=1.3764721155166626
train: epoch 123, loss 0.5419666171073914, acc=0.7477777600288391, loss=0.5419666171073914
test: epoch 123, loss 1.4423935413360596, acc=0.5361111164093018, loss=1.4423935413360596
train: epoch 124, loss 0.5428840517997742, acc=0.7483888864517212, loss=0.5428840517997742
test: epoch 124, loss 1.3186177015304565, acc=0.5249999761581421, loss=1.3186177015304565
train: epoch 125, loss 0.5209630131721497, acc=0.7545555830001831, loss=0.5209630131721497
test: epoch 125, loss 1.4423373937606812, acc=0.5333333611488342, loss=1.4423373937606812
train: epoch 126, loss 0.5265711545944214, acc=0.7528333067893982, loss=0.5265711545944214
test: epoch 126, loss 1.543107271194458, acc=0.5388888716697693, loss=1.543107271194458
train: epoch 127, loss 0.5392143130302429, acc=0.7471666932106018, loss=0.5392143130302429
test: epoch 127, loss 1.6756172180175781, acc=0.4972222149372101, loss=1.6756172180175781
train: epoch 128, loss 0.5329106450080872, acc=0.7461666464805603, loss=0.5329106450080872
test: epoch 128, loss 1.3509730100631714, acc=0.5333333611488342, loss=1.3509730100631714
train: epoch 129, loss 0.5440636873245239, acc=0.7430555820465088, loss=0.5440636873245239
test: epoch 129, loss 1.3595713376998901, acc=0.5333333611488342, loss=1.3595713376998901
train: epoch 130, loss 0.538095235824585, acc=0.7493888735771179, loss=0.538095235824585
test: epoch 130, loss 1.521714448928833, acc=0.5388888716697693, loss=1.521714448928833
train: epoch 131, loss 0.5248897671699524, acc=0.7530555725097656, loss=0.5248897671699524
test: epoch 131, loss 1.3856483697891235, acc=0.5416666865348816, loss=1.3856483697891235
train: epoch 132, loss 0.5301424860954285, acc=0.7519999742507935, loss=0.5301424860954285
test: epoch 132, loss 1.3832861185073853, acc=0.5361111164093018, loss=1.3832861185073853
train: epoch 133, loss 0.532821774482727, acc=0.750333309173584, loss=0.532821774482727
test: epoch 133, loss 1.514980435371399, acc=0.5277777910232544, loss=1.514980435371399
train: epoch 134, loss 0.5184440016746521, acc=0.7571666836738586, loss=0.5184440016746521
test: epoch 134, loss 1.4456417560577393, acc=0.5472221970558167, loss=1.4456417560577393
train: epoch 135, loss 0.5302357077598572, acc=0.7517777681350708, loss=0.5302357077598572
test: epoch 135, loss 1.435727834701538, acc=0.5222222208976746, loss=1.435727834701538
train: epoch 136, loss 0.5327708721160889, acc=0.7510555386543274, loss=0.5327708721160889
test: epoch 136, loss 1.3809515237808228, acc=0.5472221970558167, loss=1.3809515237808228
train: epoch 137, loss 0.5207061171531677, acc=0.7556666731834412, loss=0.5207061171531677
test: epoch 137, loss 1.419898509979248, acc=0.5305555462837219, loss=1.419898509979248
train: epoch 138, loss 0.5285165905952454, acc=0.7492222189903259, loss=0.5285165905952454
test: epoch 138, loss 1.3054871559143066, acc=0.5361111164093018, loss=1.3054871559143066
train: epoch 139, loss 0.5254227519035339, acc=0.7525555491447449, loss=0.5254227519035339
test: epoch 139, loss 1.4653390645980835, acc=0.5138888955116272, loss=1.4653390645980835
train: epoch 140, loss 0.531420111656189, acc=0.7534999847412109, loss=0.531420111656189
test: epoch 140, loss 1.4461909532546997, acc=0.5361111164093018, loss=1.4461909532546997
train: epoch 141, loss 0.5302853584289551, acc=0.7557777762413025, loss=0.5302853584289551
test: epoch 141, loss 1.4843624830245972, acc=0.5361111164093018, loss=1.4843624830245972
train: epoch 142, loss 0.5312246680259705, acc=0.7535555362701416, loss=0.5312246680259705
test: epoch 142, loss 1.4735419750213623, acc=0.5277777910232544, loss=1.4735419750213623
train: epoch 143, loss 0.5231973528862, acc=0.7579444646835327, loss=0.5231973528862
test: epoch 143, loss 1.4826176166534424, acc=0.5027777552604675, loss=1.4826176166534424
train: epoch 144, loss 0.5132136940956116, acc=0.7591666579246521, loss=0.5132136940956116
test: epoch 144, loss 1.310613751411438, acc=0.5361111164093018, loss=1.310613751411438
train: epoch 145, loss 0.5340259671211243, acc=0.7511110901832581, loss=0.5340259671211243
test: epoch 145, loss 1.327260971069336, acc=0.5416666865348816, loss=1.327260971069336
train: epoch 146, loss 0.5174030661582947, acc=0.7564444541931152, loss=0.5174030661582947
test: epoch 146, loss 1.277390718460083, acc=0.5388888716697693, loss=1.277390718460083
train: epoch 147, loss 0.5080458521842957, acc=0.7624444365501404, loss=0.5080458521842957
test: epoch 147, loss 1.4727027416229248, acc=0.5222222208976746, loss=1.4727027416229248
train: epoch 148, loss 0.526980996131897, acc=0.757111132144928, loss=0.526980996131897
test: epoch 148, loss 1.4709141254425049, acc=0.5027777552604675, loss=1.4709141254425049
train: epoch 149, loss 0.5184100270271301, acc=0.7526666522026062, loss=0.5184100270271301
test: epoch 149, loss 1.3437273502349854, acc=0.5361111164093018, loss=1.3437273502349854
train: epoch 150, loss 0.5224071145057678, acc=0.7564444541931152, loss=0.5224071145057678
test: epoch 150, loss 1.4453930854797363, acc=0.5277777910232544, loss=1.4453930854797363
