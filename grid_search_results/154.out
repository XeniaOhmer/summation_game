# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=1", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=126774899, receiver_embed_dim=128, save_run=0, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=126774899, receiver_embed_dim=128, save_run=False, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.900010824203491, acc=0.1245555579662323, loss=2.900010824203491
test: epoch 1, loss 3.8636128902435303, acc=0.12777778506278992, loss=3.8636128902435303
train: epoch 2, loss 1.421614408493042, acc=0.42133334279060364, loss=1.421614408493042
test: epoch 2, loss 3.973968982696533, acc=0.12222222238779068, loss=3.973968982696533
train: epoch 3, loss 1.0510501861572266, acc=0.5791666507720947, loss=1.0510501861572266
test: epoch 3, loss 3.9498026371002197, acc=0.16111111640930176, loss=3.9498026371002197
train: epoch 4, loss 0.8582956790924072, acc=0.667555570602417, loss=0.8582956790924072
test: epoch 4, loss 4.030603885650635, acc=0.18888889253139496, loss=4.030603885650635
train: epoch 5, loss 0.725020170211792, acc=0.7253888845443726, loss=0.725020170211792
test: epoch 5, loss 4.033980369567871, acc=0.18611110746860504, loss=4.033980369567871
train: epoch 6, loss 0.6164363622665405, acc=0.7686111330986023, loss=0.6164363622665405
test: epoch 6, loss 3.550016403198242, acc=0.16944444179534912, loss=3.550016403198242
train: epoch 7, loss 0.5538233518600464, acc=0.7979444265365601, loss=0.5538233518600464
test: epoch 7, loss 3.696662187576294, acc=0.18333333730697632, loss=3.696662187576294
train: epoch 8, loss 0.5030918121337891, acc=0.8177777528762817, loss=0.5030918121337891
test: epoch 8, loss 3.8555381298065186, acc=0.23055554926395416, loss=3.8555381298065186
train: epoch 9, loss 0.45948442816734314, acc=0.8371111154556274, loss=0.45948442816734314
test: epoch 9, loss 3.3893556594848633, acc=0.24166665971279144, loss=3.3893556594848633
train: epoch 10, loss 0.436853289604187, acc=0.847777783870697, loss=0.436853289604187
test: epoch 10, loss 2.8220860958099365, acc=0.21944443881511688, loss=2.8220860958099365
train: epoch 11, loss 0.3779560327529907, acc=0.8666666746139526, loss=0.3779560327529907
test: epoch 11, loss 3.27689528465271, acc=0.25555557012557983, loss=3.27689528465271
train: epoch 12, loss 0.3755814731121063, acc=0.866611123085022, loss=0.3755814731121063
test: epoch 12, loss 3.0293376445770264, acc=0.28333333134651184, loss=3.0293376445770264
train: epoch 13, loss 0.344102680683136, acc=0.8781111240386963, loss=0.344102680683136
test: epoch 13, loss 2.9639787673950195, acc=0.2888889014720917, loss=2.9639787673950195
train: epoch 14, loss 0.32831355929374695, acc=0.8856666684150696, loss=0.32831355929374695
test: epoch 14, loss 2.756347417831421, acc=0.2666666805744171, loss=2.756347417831421
train: epoch 15, loss 0.3159772753715515, acc=0.8958888649940491, loss=0.3159772753715515
test: epoch 15, loss 2.5801782608032227, acc=0.28333333134651184, loss=2.5801782608032227
train: epoch 16, loss 0.2886980175971985, acc=0.9019444584846497, loss=0.2886980175971985
test: epoch 16, loss 2.6163623332977295, acc=0.32777777314186096, loss=2.6163623332977295
train: epoch 17, loss 0.2857455909252167, acc=0.9037222266197205, loss=0.2857455909252167
test: epoch 17, loss 2.1628057956695557, acc=0.36666667461395264, loss=2.1628057956695557
train: epoch 18, loss 0.25937169790267944, acc=0.9125000238418579, loss=0.25937169790267944
test: epoch 18, loss 2.4956023693084717, acc=0.32777777314186096, loss=2.4956023693084717
train: epoch 19, loss 0.25617721676826477, acc=0.9164999723434448, loss=0.25617721676826477
test: epoch 19, loss 2.725911855697632, acc=0.3333333432674408, loss=2.725911855697632
train: epoch 20, loss 0.22484885156154633, acc=0.9256666898727417, loss=0.22484885156154633
test: epoch 20, loss 2.5021848678588867, acc=0.3472222089767456, loss=2.5021848678588867
train: epoch 21, loss 0.2158958464860916, acc=0.9282222390174866, loss=0.2158958464860916
test: epoch 21, loss 2.71867299079895, acc=0.3055555522441864, loss=2.71867299079895
train: epoch 22, loss 0.21963167190551758, acc=0.9291666746139526, loss=0.21963167190551758
test: epoch 22, loss 2.5335419178009033, acc=0.32499998807907104, loss=2.5335419178009033
train: epoch 23, loss 0.2108730524778366, acc=0.9311666488647461, loss=0.2108730524778366
test: epoch 23, loss 2.793046712875366, acc=0.30000001192092896, loss=2.793046712875366
train: epoch 24, loss 0.20207442343235016, acc=0.9371111392974854, loss=0.20207442343235016
test: epoch 24, loss 3.324864387512207, acc=0.3166666626930237, loss=3.324864387512207
train: epoch 25, loss 0.1929241269826889, acc=0.9390555620193481, loss=0.1929241269826889
test: epoch 25, loss 2.811007022857666, acc=0.3333333432674408, loss=2.811007022857666
train: epoch 26, loss 0.17144863307476044, acc=0.945277750492096, loss=0.17144863307476044
test: epoch 26, loss 2.7931079864501953, acc=0.3361110985279083, loss=2.7931079864501953
train: epoch 27, loss 0.17507773637771606, acc=0.9467777609825134, loss=0.17507773637771606
test: epoch 27, loss 2.9609322547912598, acc=0.34166666865348816, loss=2.9609322547912598
train: epoch 28, loss 0.15956461429595947, acc=0.9499444365501404, loss=0.15956461429595947
test: epoch 28, loss 2.475323438644409, acc=0.36944442987442017, loss=2.475323438644409
train: epoch 29, loss 0.15647923946380615, acc=0.9503889083862305, loss=0.15647923946380615
test: epoch 29, loss 2.6560981273651123, acc=0.35555556416511536, loss=2.6560981273651123
train: epoch 30, loss 0.16402830183506012, acc=0.9503889083862305, loss=0.16402830183506012
test: epoch 30, loss 2.8424015045166016, acc=0.3361110985279083, loss=2.8424015045166016
train: epoch 31, loss 0.14084917306900024, acc=0.9557777643203735, loss=0.14084917306900024
test: epoch 31, loss 2.9975638389587402, acc=0.375, loss=2.9975638389587402
train: epoch 32, loss 0.14834345877170563, acc=0.9560555815696716, loss=0.14834345877170563
test: epoch 32, loss 2.2102813720703125, acc=0.43888887763023376, loss=2.2102813720703125
train: epoch 33, loss 0.13918907940387726, acc=0.9573888778686523, loss=0.13918907940387726
test: epoch 33, loss 2.4618191719055176, acc=0.38055557012557983, loss=2.4618191719055176
train: epoch 34, loss 0.14916032552719116, acc=0.9546666741371155, loss=0.14916032552719116
test: epoch 34, loss 2.4256703853607178, acc=0.4166666567325592, loss=2.4256703853607178
train: epoch 35, loss 0.1445838212966919, acc=0.9575555324554443, loss=0.1445838212966919
test: epoch 35, loss 2.178375244140625, acc=0.4472222328186035, loss=2.178375244140625
train: epoch 36, loss 0.12892304360866547, acc=0.9599999785423279, loss=0.12892304360866547
test: epoch 36, loss 2.5581483840942383, acc=0.4305555522441864, loss=2.5581483840942383
train: epoch 37, loss 0.13805298507213593, acc=0.960444450378418, loss=0.13805298507213593
test: epoch 37, loss 2.3329074382781982, acc=0.4694444537162781, loss=2.3329074382781982
train: epoch 38, loss 0.13058482110500336, acc=0.9627222418785095, loss=0.13058482110500336
test: epoch 38, loss 2.043255567550659, acc=0.4444444477558136, loss=2.043255567550659
train: epoch 39, loss 0.11644377559423447, acc=0.9655555486679077, loss=0.11644377559423447
test: epoch 39, loss 2.5138349533081055, acc=0.4833333194255829, loss=2.5138349533081055
train: epoch 40, loss 0.12994849681854248, acc=0.9648333191871643, loss=0.12994849681854248
test: epoch 40, loss 2.4905433654785156, acc=0.4444444477558136, loss=2.4905433654785156
train: epoch 41, loss 0.12007693201303482, acc=0.9666110873222351, loss=0.12007693201303482
test: epoch 41, loss 2.625004768371582, acc=0.4333333373069763, loss=2.625004768371582
train: epoch 42, loss 0.12495547533035278, acc=0.9660000205039978, loss=0.12495547533035278
test: epoch 42, loss 2.464113473892212, acc=0.47777777910232544, loss=2.464113473892212
train: epoch 43, loss 0.11790412664413452, acc=0.9661111235618591, loss=0.11790412664413452
test: epoch 43, loss 2.387188673019409, acc=0.5027777552604675, loss=2.387188673019409
train: epoch 44, loss 0.10770027339458466, acc=0.9687777757644653, loss=0.10770027339458466
test: epoch 44, loss 2.160863161087036, acc=0.5111111402511597, loss=2.160863161087036
train: epoch 45, loss 0.11012148857116699, acc=0.9691666960716248, loss=0.11012148857116699
test: epoch 45, loss 2.2806546688079834, acc=0.4861111044883728, loss=2.2806546688079834
train: epoch 46, loss 0.10397404432296753, acc=0.9693889021873474, loss=0.10397404432296753
test: epoch 46, loss 2.3751060962677, acc=0.5, loss=2.3751060962677
train: epoch 47, loss 0.10847095400094986, acc=0.9724444150924683, loss=0.10847095400094986
test: epoch 47, loss 2.516798257827759, acc=0.4055555462837219, loss=2.516798257827759
train: epoch 48, loss 0.1071089655160904, acc=0.9712777733802795, loss=0.1071089655160904
test: epoch 48, loss 2.274445056915283, acc=0.5166666507720947, loss=2.274445056915283
train: epoch 49, loss 0.09743383526802063, acc=0.9722777605056763, loss=0.09743383526802063
test: epoch 49, loss 1.6649231910705566, acc=0.5583333373069763, loss=1.6649231910705566
train: epoch 50, loss 0.0988169014453888, acc=0.9708333611488342, loss=0.0988169014453888
test: epoch 50, loss 2.033997058868408, acc=0.550000011920929, loss=2.033997058868408
train: epoch 51, loss 0.09909645467996597, acc=0.9708333611488342, loss=0.09909645467996597
test: epoch 51, loss 2.029463529586792, acc=0.550000011920929, loss=2.029463529586792
train: epoch 52, loss 0.09617527574300766, acc=0.9732778072357178, loss=0.09617527574300766
test: epoch 52, loss 1.704214334487915, acc=0.5888888835906982, loss=1.704214334487915
train: epoch 53, loss 0.09424038976430893, acc=0.9744444489479065, loss=0.09424038976430893
test: epoch 53, loss 2.0102484226226807, acc=0.5166666507720947, loss=2.0102484226226807
train: epoch 54, loss 0.09316577017307281, acc=0.973111093044281, loss=0.09316577017307281
test: epoch 54, loss 1.798250675201416, acc=0.5444444417953491, loss=1.798250675201416
train: epoch 55, loss 0.09013094753026962, acc=0.9738333225250244, loss=0.09013094753026962
test: epoch 55, loss 1.7619619369506836, acc=0.5527777671813965, loss=1.7619619369506836
train: epoch 56, loss 0.10647914558649063, acc=0.9706110954284668, loss=0.10647914558649063
test: epoch 56, loss 1.9531898498535156, acc=0.5444444417953491, loss=1.9531898498535156
train: epoch 57, loss 0.09559639543294907, acc=0.9736666679382324, loss=0.09559639543294907
test: epoch 57, loss 1.6804434061050415, acc=0.605555534362793, loss=1.6804434061050415
train: epoch 58, loss 0.09875376522541046, acc=0.9738888740539551, loss=0.09875376522541046
test: epoch 58, loss 1.787054181098938, acc=0.6000000238418579, loss=1.787054181098938
train: epoch 59, loss 0.07932440936565399, acc=0.9781110882759094, loss=0.07932440936565399
test: epoch 59, loss 1.9895342588424683, acc=0.6083333492279053, loss=1.9895342588424683
train: epoch 60, loss 0.10110883414745331, acc=0.9728888869285583, loss=0.10110883414745331
test: epoch 60, loss 1.948380947113037, acc=0.6333333253860474, loss=1.948380947113037
train: epoch 61, loss 0.08295401930809021, acc=0.9769999980926514, loss=0.08295401930809021
test: epoch 61, loss 1.8641513586044312, acc=0.5833333134651184, loss=1.8641513586044312
train: epoch 62, loss 0.09597469866275787, acc=0.9717777967453003, loss=0.09597469866275787
test: epoch 62, loss 1.5715878009796143, acc=0.6027777791023254, loss=1.5715878009796143
train: epoch 63, loss 0.08581680059432983, acc=0.9754444360733032, loss=0.08581680059432983
test: epoch 63, loss 1.6415003538131714, acc=0.5944444537162781, loss=1.6415003538131714
train: epoch 64, loss 0.08418400585651398, acc=0.9765555262565613, loss=0.08418400585651398
test: epoch 64, loss 1.533204197883606, acc=0.625, loss=1.533204197883606
train: epoch 65, loss 0.09738269448280334, acc=0.9734444618225098, loss=0.09738269448280334
test: epoch 65, loss 1.3944194316864014, acc=0.6333333253860474, loss=1.3944194316864014
train: epoch 66, loss 0.0827479213476181, acc=0.9772777557373047, loss=0.0827479213476181
test: epoch 66, loss 1.6121097803115845, acc=0.6583333611488342, loss=1.6121097803115845
train: epoch 67, loss 0.08238096535205841, acc=0.9783889055252075, loss=0.08238096535205841
test: epoch 67, loss 1.5217750072479248, acc=0.6416666507720947, loss=1.5217750072479248
train: epoch 68, loss 0.09579256922006607, acc=0.9748888611793518, loss=0.09579256922006607
test: epoch 68, loss 1.4230302572250366, acc=0.675000011920929, loss=1.4230302572250366
train: epoch 69, loss 0.08191199600696564, acc=0.9773889183998108, loss=0.08191199600696564
test: epoch 69, loss 1.5172933340072632, acc=0.6277777552604675, loss=1.5172933340072632
train: epoch 70, loss 0.06817168742418289, acc=0.9804999828338623, loss=0.06817168742418289
test: epoch 70, loss 1.229724645614624, acc=0.7250000238418579, loss=1.229724645614624
train: epoch 71, loss 0.09084425121545792, acc=0.9764999747276306, loss=0.09084425121545792
test: epoch 71, loss 1.548104166984558, acc=0.6888889074325562, loss=1.548104166984558
train: epoch 72, loss 0.08909162878990173, acc=0.9763888716697693, loss=0.08909162878990173
test: epoch 72, loss 1.153824806213379, acc=0.7138888835906982, loss=1.153824806213379
train: epoch 73, loss 0.07339875400066376, acc=0.9791111350059509, loss=0.07339875400066376
test: epoch 73, loss 1.2448301315307617, acc=0.7277777791023254, loss=1.2448301315307617
train: epoch 74, loss 0.0757041722536087, acc=0.9781666398048401, loss=0.0757041722536087
test: epoch 74, loss 1.3268964290618896, acc=0.7194444537162781, loss=1.3268964290618896
train: epoch 75, loss 0.07621797919273376, acc=0.9787777662277222, loss=0.07621797919273376
test: epoch 75, loss 1.2339645624160767, acc=0.7194444537162781, loss=1.2339645624160767
train: epoch 76, loss 0.09185735136270523, acc=0.9760000109672546, loss=0.09185735136270523
test: epoch 76, loss 1.211085319519043, acc=0.7444444298744202, loss=1.211085319519043
train: epoch 77, loss 0.07314904034137726, acc=0.9808333516120911, loss=0.07314904034137726
test: epoch 77, loss 1.3672391176223755, acc=0.7361111044883728, loss=1.3672391176223755
train: epoch 78, loss 0.08064382523298264, acc=0.9788333177566528, loss=0.08064382523298264
test: epoch 78, loss 1.1753184795379639, acc=0.7027778029441833, loss=1.1753184795379639
train: epoch 79, loss 0.08133217692375183, acc=0.9783333539962769, loss=0.08133217692375183
test: epoch 79, loss 1.1575002670288086, acc=0.7722222208976746, loss=1.1575002670288086
train: epoch 80, loss 0.07400630414485931, acc=0.9789999723434448, loss=0.07400630414485931
test: epoch 80, loss 1.1787440776824951, acc=0.7527777552604675, loss=1.1787440776824951
train: epoch 81, loss 0.08282154053449631, acc=0.9771111011505127, loss=0.08282154053449631
test: epoch 81, loss 0.8997274041175842, acc=0.769444465637207, loss=0.8997274041175842
train: epoch 82, loss 0.06428886950016022, acc=0.9816666841506958, loss=0.06428886950016022
test: epoch 82, loss 0.8465840220451355, acc=0.7722222208976746, loss=0.8465840220451355
train: epoch 83, loss 0.06988932937383652, acc=0.9807778000831604, loss=0.06988932937383652
test: epoch 83, loss 0.8452934622764587, acc=0.7888888716697693, loss=0.8452934622764587
train: epoch 84, loss 0.07085709273815155, acc=0.9803333282470703, loss=0.07085709273815155
test: epoch 84, loss 1.014970302581787, acc=0.7861111164093018, loss=1.014970302581787
train: epoch 85, loss 0.0767291784286499, acc=0.9816666841506958, loss=0.0767291784286499
test: epoch 85, loss 0.8972819447517395, acc=0.8055555820465088, loss=0.8972819447517395
train: epoch 86, loss 0.07375915348529816, acc=0.9793888926506042, loss=0.07375915348529816
test: epoch 86, loss 0.934454619884491, acc=0.7861111164093018, loss=0.934454619884491
train: epoch 87, loss 0.06933591514825821, acc=0.9818333387374878, loss=0.06933591514825821
test: epoch 87, loss 0.7723149657249451, acc=0.8111110925674438, loss=0.7723149657249451
train: epoch 88, loss 0.06550870090723038, acc=0.9827777743339539, loss=0.06550870090723038
test: epoch 88, loss 0.8673692941665649, acc=0.8027777671813965, loss=0.8673692941665649
train: epoch 89, loss 0.0713455006480217, acc=0.9808889031410217, loss=0.0713455006480217
test: epoch 89, loss 0.7857313752174377, acc=0.824999988079071, loss=0.7857313752174377
train: epoch 90, loss 0.07318008691072464, acc=0.980388879776001, loss=0.07318008691072464
test: epoch 90, loss 0.7912139892578125, acc=0.8055555820465088, loss=0.7912139892578125
train: epoch 91, loss 0.06794041395187378, acc=0.981166660785675, loss=0.06794041395187378
test: epoch 91, loss 0.7579304575920105, acc=0.8305555582046509, loss=0.7579304575920105
train: epoch 92, loss 0.06294041126966476, acc=0.9828333258628845, loss=0.06294041126966476
test: epoch 92, loss 0.7256724238395691, acc=0.8388888835906982, loss=0.7256724238395691
train: epoch 93, loss 0.05823931470513344, acc=0.98416668176651, loss=0.05823931470513344
test: epoch 93, loss 0.6118058562278748, acc=0.8527777791023254, loss=0.6118058562278748
train: epoch 94, loss 0.06331530958414078, acc=0.9817222356796265, loss=0.06331530958414078
test: epoch 94, loss 0.7380069494247437, acc=0.8444444537162781, loss=0.7380069494247437
train: epoch 95, loss 0.06294608116149902, acc=0.9827222228050232, loss=0.06294608116149902
test: epoch 95, loss 0.7940056920051575, acc=0.8305555582046509, loss=0.7940056920051575
train: epoch 96, loss 0.06700421869754791, acc=0.9822221994400024, loss=0.06700421869754791
test: epoch 96, loss 0.6820243000984192, acc=0.8444444537162781, loss=0.6820243000984192
train: epoch 97, loss 0.06021301820874214, acc=0.9827777743339539, loss=0.06021301820874214
test: epoch 97, loss 0.8130115270614624, acc=0.8222222328186035, loss=0.8130115270614624
train: epoch 98, loss 0.06139754876494408, acc=0.984000027179718, loss=0.06139754876494408
test: epoch 98, loss 0.5222852826118469, acc=0.8361111283302307, loss=0.5222852826118469
train: epoch 99, loss 0.05721678212285042, acc=0.9844444394111633, loss=0.05721678212285042
test: epoch 99, loss 0.7362730503082275, acc=0.8638888597488403, loss=0.7362730503082275
train: epoch 100, loss 0.06147811561822891, acc=0.9821666479110718, loss=0.06147811561822891
test: epoch 100, loss 0.6528142690658569, acc=0.8444444537162781, loss=0.6528142690658569
train: epoch 101, loss 0.055362965911626816, acc=0.9836111068725586, loss=0.055362965911626816
test: epoch 101, loss 0.5440249443054199, acc=0.8694444298744202, loss=0.5440249443054199
train: epoch 102, loss 0.05587261915206909, acc=0.9842222332954407, loss=0.05587261915206909
test: epoch 102, loss 0.5848069787025452, acc=0.8583333492279053, loss=0.5848069787025452
train: epoch 103, loss 0.056633953005075455, acc=0.9854444265365601, loss=0.056633953005075455
test: epoch 103, loss 0.5384293794631958, acc=0.8861111402511597, loss=0.5384293794631958
train: epoch 104, loss 0.05329769849777222, acc=0.9843888878822327, loss=0.05329769849777222
test: epoch 104, loss 0.612700879573822, acc=0.8777777552604675, loss=0.612700879573822
train: epoch 105, loss 0.05683813989162445, acc=0.9855555295944214, loss=0.05683813989162445
test: epoch 105, loss 0.5576232075691223, acc=0.8666666746139526, loss=0.5576232075691223
train: epoch 106, loss 0.05530573055148125, acc=0.9851111173629761, loss=0.05530573055148125
test: epoch 106, loss 0.5428032279014587, acc=0.8666666746139526, loss=0.5428032279014587
train: epoch 107, loss 0.06535600870847702, acc=0.983222246170044, loss=0.06535600870847702
test: epoch 107, loss 0.46546700596809387, acc=0.8777777552604675, loss=0.46546700596809387
train: epoch 108, loss 0.0515991672873497, acc=0.9847777485847473, loss=0.0515991672873497
test: epoch 108, loss 0.3839484751224518, acc=0.8888888955116272, loss=0.3839484751224518
train: epoch 109, loss 0.055614158511161804, acc=0.9852777719497681, loss=0.055614158511161804
test: epoch 109, loss 0.45115357637405396, acc=0.8916666507720947, loss=0.45115357637405396
train: epoch 110, loss 0.054361019283533096, acc=0.9841111302375793, loss=0.054361019283533096
test: epoch 110, loss 0.4701124131679535, acc=0.8833333253860474, loss=0.4701124131679535
train: epoch 111, loss 0.04635409265756607, acc=0.9865000247955322, loss=0.04635409265756607
test: epoch 111, loss 0.37089675664901733, acc=0.9027777910232544, loss=0.37089675664901733
train: epoch 112, loss 0.04379808530211449, acc=0.988611102104187, loss=0.04379808530211449
test: epoch 112, loss 0.42172589898109436, acc=0.8972222208976746, loss=0.42172589898109436
train: epoch 113, loss 0.054452572017908096, acc=0.9860555529594421, loss=0.054452572017908096
test: epoch 113, loss 0.4529365599155426, acc=0.8916666507720947, loss=0.4529365599155426
train: epoch 114, loss 0.0479033887386322, acc=0.9861111044883728, loss=0.0479033887386322
test: epoch 114, loss 0.42532235383987427, acc=0.8972222208976746, loss=0.42532235383987427
train: epoch 115, loss 0.054950032383203506, acc=0.9872778058052063, loss=0.054950032383203506
test: epoch 115, loss 0.4029228687286377, acc=0.9055555462837219, loss=0.4029228687286377
train: epoch 116, loss 0.050953157246112823, acc=0.9845555424690247, loss=0.050953157246112823
test: epoch 116, loss 0.3771229684352875, acc=0.9055555462837219, loss=0.3771229684352875
train: epoch 117, loss 0.05261608958244324, acc=0.9866666793823242, loss=0.05261608958244324
test: epoch 117, loss 0.3350369930267334, acc=0.9166666865348816, loss=0.3350369930267334
train: epoch 118, loss 0.043802376836538315, acc=0.9880555272102356, loss=0.043802376836538315
test: epoch 118, loss 0.31686362624168396, acc=0.9083333611488342, loss=0.31686362624168396
train: epoch 119, loss 0.04553944990038872, acc=0.9856666922569275, loss=0.04553944990038872
test: epoch 119, loss 0.3267734944820404, acc=0.9083333611488342, loss=0.3267734944820404
train: epoch 120, loss 0.04402503743767738, acc=0.9868888854980469, loss=0.04402503743767738
test: epoch 120, loss 0.4028550982475281, acc=0.9111111164093018, loss=0.4028550982475281
train: epoch 121, loss 0.047934580594301224, acc=0.9857777953147888, loss=0.047934580594301224
test: epoch 121, loss 0.43181127309799194, acc=0.8999999761581421, loss=0.43181127309799194
train: epoch 122, loss 0.04373861849308014, acc=0.9871110916137695, loss=0.04373861849308014
test: epoch 122, loss 0.4793355464935303, acc=0.8999999761581421, loss=0.4793355464935303
train: epoch 123, loss 0.04867889732122421, acc=0.9861666560173035, loss=0.04867889732122421
test: epoch 123, loss 0.4658019244670868, acc=0.9083333611488342, loss=0.4658019244670868
train: epoch 124, loss 0.04333416372537613, acc=0.9865000247955322, loss=0.04333416372537613
test: epoch 124, loss 0.34709012508392334, acc=0.9138888716697693, loss=0.34709012508392334
train: epoch 125, loss 0.04566538706421852, acc=0.9862222075462341, loss=0.04566538706421852
test: epoch 125, loss 0.30408546328544617, acc=0.9111111164093018, loss=0.30408546328544617
train: epoch 126, loss 0.0426400788128376, acc=0.9867222309112549, loss=0.0426400788128376
test: epoch 126, loss 0.3229098916053772, acc=0.9055555462837219, loss=0.3229098916053772
train: epoch 127, loss 0.04291301220655441, acc=0.987500011920929, loss=0.04291301220655441
test: epoch 127, loss 0.4329723119735718, acc=0.9166666865348816, loss=0.4329723119735718
train: epoch 128, loss 0.046356912702322006, acc=0.9860555529594421, loss=0.046356912702322006
test: epoch 128, loss 0.29865819215774536, acc=0.9194444417953491, loss=0.29865819215774536
train: epoch 129, loss 0.03636905178427696, acc=0.9894444346427917, loss=0.03636905178427696
test: epoch 129, loss 0.36054205894470215, acc=0.9055555462837219, loss=0.36054205894470215
train: epoch 130, loss 0.048256415873765945, acc=0.9860555529594421, loss=0.048256415873765945
test: epoch 130, loss 0.3378280699253082, acc=0.9166666865348816, loss=0.3378280699253082
train: epoch 131, loss 0.041973777115345, acc=0.988611102104187, loss=0.041973777115345
test: epoch 131, loss 0.3042845129966736, acc=0.9111111164093018, loss=0.3042845129966736
train: epoch 132, loss 0.0494212843477726, acc=0.9854999780654907, loss=0.0494212843477726
test: epoch 132, loss 0.27280864119529724, acc=0.9166666865348816, loss=0.27280864119529724
train: epoch 133, loss 0.044959552586078644, acc=0.9861111044883728, loss=0.044959552586078644
test: epoch 133, loss 0.26561084389686584, acc=0.9138888716697693, loss=0.26561084389686584
train: epoch 134, loss 0.036302350461483, acc=0.9876111149787903, loss=0.036302350461483
test: epoch 134, loss 0.34030383825302124, acc=0.9194444417953491, loss=0.34030383825302124
train: epoch 135, loss 0.04466231167316437, acc=0.9869999885559082, loss=0.04466231167316437
test: epoch 135, loss 0.2694433033466339, acc=0.9138888716697693, loss=0.2694433033466339
train: epoch 136, loss 0.041108276695013046, acc=0.9883333444595337, loss=0.041108276695013046
test: epoch 136, loss 0.2497733235359192, acc=0.9277777671813965, loss=0.2497733235359192
train: epoch 137, loss 0.041339389979839325, acc=0.987666666507721, loss=0.041339389979839325
test: epoch 137, loss 0.2459821105003357, acc=0.9138888716697693, loss=0.2459821105003357
train: epoch 138, loss 0.045492950826883316, acc=0.9865000247955322, loss=0.045492950826883316
test: epoch 138, loss 0.36707794666290283, acc=0.9222221970558167, loss=0.36707794666290283
train: epoch 139, loss 0.04353143274784088, acc=0.9858888983726501, loss=0.04353143274784088
test: epoch 139, loss 0.29247474670410156, acc=0.9166666865348816, loss=0.29247474670410156
train: epoch 140, loss 0.04183884337544441, acc=0.987500011920929, loss=0.04183884337544441
test: epoch 140, loss 0.2429029941558838, acc=0.925000011920929, loss=0.2429029941558838
train: epoch 141, loss 0.034776415675878525, acc=0.9891111254692078, loss=0.034776415675878525
test: epoch 141, loss 0.26233500242233276, acc=0.9305555820465088, loss=0.26233500242233276
train: epoch 142, loss 0.041856925934553146, acc=0.9863888621330261, loss=0.041856925934553146
test: epoch 142, loss 0.23100556433200836, acc=0.925000011920929, loss=0.23100556433200836
train: epoch 143, loss 0.0440492257475853, acc=0.9866666793823242, loss=0.0440492257475853
test: epoch 143, loss 0.26653599739074707, acc=0.9305555820465088, loss=0.26653599739074707
train: epoch 144, loss 0.041257262229919434, acc=0.9867777824401855, loss=0.041257262229919434
test: epoch 144, loss 0.1787988245487213, acc=0.9305555820465088, loss=0.1787988245487213
train: epoch 145, loss 0.0459735281765461, acc=0.9863333106040955, loss=0.0459735281765461
test: epoch 145, loss 0.32936081290245056, acc=0.925000011920929, loss=0.32936081290245056
train: epoch 146, loss 0.04184146225452423, acc=0.988444447517395, loss=0.04184146225452423
test: epoch 146, loss 0.28528374433517456, acc=0.9194444417953491, loss=0.28528374433517456
train: epoch 147, loss 0.04768408462405205, acc=0.9854444265365601, loss=0.04768408462405205
test: epoch 147, loss 0.22111698985099792, acc=0.9083333611488342, loss=0.22111698985099792
train: epoch 148, loss 0.04093335568904877, acc=0.9882222414016724, loss=0.04093335568904877
test: epoch 148, loss 0.22890596091747284, acc=0.9222221970558167, loss=0.22890596091747284
train: epoch 149, loss 0.04116479307413101, acc=0.9871110916137695, loss=0.04116479307413101
test: epoch 149, loss 0.24538269639015198, acc=0.925000011920929, loss=0.24538269639015198
train: epoch 150, loss 0.04229673743247986, acc=0.9870555400848389, loss=0.04229673743247986
test: epoch 150, loss 0.23359587788581848, acc=0.9194444417953491, loss=0.23359587788581848
