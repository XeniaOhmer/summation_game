# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=1", "--temp_decay=0.995", "--one_hot=0", "--n_layers=1"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=1959905216, receiver_embed_dim=128, save_run=0, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=1959905216, receiver_embed_dim=128, save_run=False, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.1780588626861572, acc=0.07266666740179062, loss=3.1780588626861572
test: epoch 1, loss 3.7315874099731445, acc=0.05277777835726738, loss=3.7315874099731445
train: epoch 2, loss 2.8481509685516357, acc=0.10466666519641876, loss=2.8481509685516357
test: epoch 2, loss 3.922316551208496, acc=0.05277777835726738, loss=3.922316551208496
train: epoch 3, loss 2.7475483417510986, acc=0.12177778035402298, loss=2.7475483417510986
test: epoch 3, loss 4.008711338043213, acc=0.05277777835726738, loss=4.008711338043213
train: epoch 4, loss 2.707698345184326, acc=0.12655556201934814, loss=2.707698345184326
test: epoch 4, loss 4.061603546142578, acc=0.0555555559694767, loss=4.061603546142578
train: epoch 5, loss 2.664837121963501, acc=0.13466666638851166, loss=2.664837121963501
test: epoch 5, loss 4.17006254196167, acc=0.0555555559694767, loss=4.17006254196167
train: epoch 6, loss 2.636276960372925, acc=0.13611111044883728, loss=2.636276960372925
test: epoch 6, loss 4.094753265380859, acc=0.0555555559694767, loss=4.094753265380859
train: epoch 7, loss 2.6140990257263184, acc=0.13422222435474396, loss=2.6140990257263184
test: epoch 7, loss 4.17155647277832, acc=0.05277777835726738, loss=4.17155647277832
train: epoch 8, loss 2.5961039066314697, acc=0.14383333921432495, loss=2.5961039066314697
test: epoch 8, loss 4.1658124923706055, acc=0.05277777835726738, loss=4.1658124923706055
train: epoch 9, loss 2.592763900756836, acc=0.13777777552604675, loss=2.592763900756836
test: epoch 9, loss 4.198517799377441, acc=0.05277777835726738, loss=4.198517799377441
train: epoch 10, loss 2.571915626525879, acc=0.1449444442987442, loss=2.571915626525879
test: epoch 10, loss 4.165383815765381, acc=0.05000000074505806, loss=4.165383815765381
train: epoch 11, loss 2.5577337741851807, acc=0.14705555140972137, loss=2.5577337741851807
test: epoch 11, loss 4.129371166229248, acc=0.0555555559694767, loss=4.129371166229248
train: epoch 12, loss 2.549191474914551, acc=0.14683333039283752, loss=2.549191474914551
test: epoch 12, loss 4.1562886238098145, acc=0.05833333358168602, loss=4.1562886238098145
train: epoch 13, loss 2.5402610301971436, acc=0.14794445037841797, loss=2.5402610301971436
test: epoch 13, loss 4.158985614776611, acc=0.0555555559694767, loss=4.158985614776611
train: epoch 14, loss 2.528804063796997, acc=0.15016666054725647, loss=2.528804063796997
test: epoch 14, loss 4.177094459533691, acc=0.0555555559694767, loss=4.177094459533691
train: epoch 15, loss 2.521388530731201, acc=0.15111111104488373, loss=2.521388530731201
test: epoch 15, loss 4.29038143157959, acc=0.0416666679084301, loss=4.29038143157959
train: epoch 16, loss 2.5230798721313477, acc=0.14933332800865173, loss=2.5230798721313477
test: epoch 16, loss 3.918670177459717, acc=0.06388889253139496, loss=3.918670177459717
train: epoch 17, loss 2.505300521850586, acc=0.15755555033683777, loss=2.505300521850586
test: epoch 17, loss 4.1343183517456055, acc=0.0555555559694767, loss=4.1343183517456055
train: epoch 18, loss 2.5068013668060303, acc=0.15127778053283691, loss=2.5068013668060303
test: epoch 18, loss 4.09235143661499, acc=0.05277777835726738, loss=4.09235143661499
train: epoch 19, loss 2.495741605758667, acc=0.156166672706604, loss=2.495741605758667
test: epoch 19, loss 3.9751174449920654, acc=0.0694444477558136, loss=3.9751174449920654
train: epoch 20, loss 2.489166259765625, acc=0.15649999678134918, loss=2.489166259765625
test: epoch 20, loss 3.982835292816162, acc=0.05000000074505806, loss=3.982835292816162
train: epoch 21, loss 2.491624355316162, acc=0.15694443881511688, loss=2.491624355316162
test: epoch 21, loss 3.991682767868042, acc=0.05833333358168602, loss=3.991682767868042
train: epoch 22, loss 2.4827423095703125, acc=0.15727777779102325, loss=2.4827423095703125
test: epoch 22, loss 3.8726677894592285, acc=0.05833333358168602, loss=3.8726677894592285
train: epoch 23, loss 2.4881904125213623, acc=0.15755555033683777, loss=2.4881904125213623
test: epoch 23, loss 4.009265899658203, acc=0.04444444552063942, loss=4.009265899658203
train: epoch 24, loss 2.482074022293091, acc=0.162222221493721, loss=2.482074022293091
test: epoch 24, loss 4.010798454284668, acc=0.05000000074505806, loss=4.010798454284668
train: epoch 25, loss 2.4638805389404297, acc=0.16027778387069702, loss=2.4638805389404297
test: epoch 25, loss 3.9794769287109375, acc=0.0694444477558136, loss=3.9794769287109375
train: epoch 26, loss 2.462742328643799, acc=0.16099999845027924, loss=2.462742328643799
test: epoch 26, loss 3.7825982570648193, acc=0.06388889253139496, loss=3.7825982570648193
train: epoch 27, loss 2.468086004257202, acc=0.1597222238779068, loss=2.468086004257202
test: epoch 27, loss 3.718773126602173, acc=0.0555555559694767, loss=3.718773126602173
train: epoch 28, loss 2.4548187255859375, acc=0.1608888953924179, loss=2.4548187255859375
test: epoch 28, loss 3.9387130737304688, acc=0.06388889253139496, loss=3.9387130737304688
train: epoch 29, loss 2.452043294906616, acc=0.16322222352027893, loss=2.452043294906616
test: epoch 29, loss 3.928219795227051, acc=0.04722222313284874, loss=3.928219795227051
train: epoch 30, loss 2.458911895751953, acc=0.16183333098888397, loss=2.458911895751953
test: epoch 30, loss 3.846102714538574, acc=0.05000000074505806, loss=3.846102714538574
train: epoch 31, loss 2.4443459510803223, acc=0.16777777671813965, loss=2.4443459510803223
test: epoch 31, loss 3.7466773986816406, acc=0.05833333358168602, loss=3.7466773986816406
train: epoch 32, loss 2.4574973583221436, acc=0.160444438457489, loss=2.4574973583221436
test: epoch 32, loss 3.7744545936584473, acc=0.05000000074505806, loss=3.7744545936584473
train: epoch 33, loss 2.4451873302459717, acc=0.1628333330154419, loss=2.4451873302459717
test: epoch 33, loss 3.6556520462036133, acc=0.0694444477558136, loss=3.6556520462036133
train: epoch 34, loss 2.441795825958252, acc=0.1631111055612564, loss=2.441795825958252
test: epoch 34, loss 3.751032829284668, acc=0.05833333358168602, loss=3.751032829284668
train: epoch 35, loss 2.4518227577209473, acc=0.1632777750492096, loss=2.4518227577209473
test: epoch 35, loss 3.6030943393707275, acc=0.08055555820465088, loss=3.6030943393707275
train: epoch 36, loss 2.4598276615142822, acc=0.16366666555404663, loss=2.4598276615142822
test: epoch 36, loss 3.665430784225464, acc=0.05277777835726738, loss=3.665430784225464
train: epoch 37, loss 2.453054189682007, acc=0.15872222185134888, loss=2.453054189682007
test: epoch 37, loss 3.627145767211914, acc=0.0555555559694767, loss=3.627145767211914
train: epoch 38, loss 2.4422550201416016, acc=0.16261111199855804, loss=2.4422550201416016
test: epoch 38, loss 3.648308038711548, acc=0.0555555559694767, loss=3.648308038711548
train: epoch 39, loss 2.447911262512207, acc=0.16005556285381317, loss=2.447911262512207
test: epoch 39, loss 3.5881457328796387, acc=0.0555555559694767, loss=3.5881457328796387
train: epoch 40, loss 2.446976661682129, acc=0.16288888454437256, loss=2.446976661682129
test: epoch 40, loss 3.559479236602783, acc=0.0555555559694767, loss=3.559479236602783
train: epoch 41, loss 2.4374358654022217, acc=0.16383333504199982, loss=2.4374358654022217
test: epoch 41, loss 3.4960436820983887, acc=0.06111111119389534, loss=3.4960436820983887
train: epoch 42, loss 2.4325973987579346, acc=0.16344444453716278, loss=2.4325973987579346
test: epoch 42, loss 3.4812114238739014, acc=0.06388889253139496, loss=3.4812114238739014
train: epoch 43, loss 2.4342098236083984, acc=0.16288888454437256, loss=2.4342098236083984
test: epoch 43, loss 3.50295352935791, acc=0.05277777835726738, loss=3.50295352935791
train: epoch 44, loss 2.445781707763672, acc=0.1637222170829773, loss=2.445781707763672
test: epoch 44, loss 3.4615676403045654, acc=0.07777778059244156, loss=3.4615676403045654
train: epoch 45, loss 2.4478063583374023, acc=0.16377778351306915, loss=2.4478063583374023
test: epoch 45, loss 3.4614293575286865, acc=0.06388889253139496, loss=3.4614293575286865
train: epoch 46, loss 2.4343504905700684, acc=0.16211111843585968, loss=2.4343504905700684
test: epoch 46, loss 3.5571060180664062, acc=0.05833333358168602, loss=3.5571060180664062
train: epoch 47, loss 2.4290668964385986, acc=0.1570555567741394, loss=2.4290668964385986
test: epoch 47, loss 3.4733164310455322, acc=0.04444444552063942, loss=3.4733164310455322
train: epoch 48, loss 2.4474270343780518, acc=0.16205555200576782, loss=2.4474270343780518
test: epoch 48, loss 3.4615654945373535, acc=0.05833333358168602, loss=3.4615654945373535
train: epoch 49, loss 2.440244674682617, acc=0.1592777818441391, loss=2.440244674682617
test: epoch 49, loss 3.4808948040008545, acc=0.05000000074505806, loss=3.4808948040008545
train: epoch 50, loss 2.4300971031188965, acc=0.15994444489479065, loss=2.4300971031188965
test: epoch 50, loss 3.3370847702026367, acc=0.05277777835726738, loss=3.3370847702026367
train: epoch 51, loss 2.427001714706421, acc=0.1601666659116745, loss=2.427001714706421
test: epoch 51, loss 3.4274556636810303, acc=0.08055555820465088, loss=3.4274556636810303
train: epoch 52, loss 2.434159517288208, acc=0.16172222793102264, loss=2.434159517288208
test: epoch 52, loss 3.384073257446289, acc=0.07222222536802292, loss=3.384073257446289
train: epoch 53, loss 2.4269678592681885, acc=0.1623888909816742, loss=2.4269678592681885
test: epoch 53, loss 3.3437447547912598, acc=0.06666667014360428, loss=3.3437447547912598
train: epoch 54, loss 2.4285881519317627, acc=0.16338889300823212, loss=2.4285881519317627
test: epoch 54, loss 3.314807653427124, acc=0.05277777835726738, loss=3.314807653427124
train: epoch 55, loss 2.4277679920196533, acc=0.16005556285381317, loss=2.4277679920196533
test: epoch 55, loss 3.351923942565918, acc=0.05833333358168602, loss=3.351923942565918
train: epoch 56, loss 2.4196791648864746, acc=0.16005556285381317, loss=2.4196791648864746
test: epoch 56, loss 3.38021183013916, acc=0.0694444477558136, loss=3.38021183013916
train: epoch 57, loss 2.4413745403289795, acc=0.1567777842283249, loss=2.4413745403289795
test: epoch 57, loss 3.2423741817474365, acc=0.0694444477558136, loss=3.2423741817474365
train: epoch 58, loss 2.430501937866211, acc=0.16099999845027924, loss=2.430501937866211
test: epoch 58, loss 3.225447654724121, acc=0.08055555820465088, loss=3.225447654724121
train: epoch 59, loss 2.4461185932159424, acc=0.16244444251060486, loss=2.4461185932159424
test: epoch 59, loss 3.2123806476593018, acc=0.07777778059244156, loss=3.2123806476593018
train: epoch 60, loss 2.421060562133789, acc=0.16394443809986115, loss=2.421060562133789
test: epoch 60, loss 3.2725939750671387, acc=0.06111111119389534, loss=3.2725939750671387
train: epoch 61, loss 2.428715944290161, acc=0.16116666793823242, loss=2.428715944290161
test: epoch 61, loss 3.268890142440796, acc=0.06388889253139496, loss=3.268890142440796
train: epoch 62, loss 2.4244253635406494, acc=0.1623888909816742, loss=2.4244253635406494
test: epoch 62, loss 3.281391143798828, acc=0.06388889253139496, loss=3.281391143798828
train: epoch 63, loss 2.4302115440368652, acc=0.16127777099609375, loss=2.4302115440368652
test: epoch 63, loss 3.429811954498291, acc=0.07222222536802292, loss=3.429811954498291
train: epoch 64, loss 2.4169607162475586, acc=0.1617777794599533, loss=2.4169607162475586
test: epoch 64, loss 3.285407543182373, acc=0.08055555820465088, loss=3.285407543182373
train: epoch 65, loss 2.4086599349975586, acc=0.16394443809986115, loss=2.4086599349975586
test: epoch 65, loss 3.2275218963623047, acc=0.06666667014360428, loss=3.2275218963623047
train: epoch 66, loss 2.4107704162597656, acc=0.1623888909816742, loss=2.4107704162597656
test: epoch 66, loss 3.271038293838501, acc=0.0833333358168602, loss=3.271038293838501
train: epoch 67, loss 2.405555248260498, acc=0.16477777063846588, loss=2.405555248260498
test: epoch 67, loss 3.293017625808716, acc=0.07777778059244156, loss=3.293017625808716
train: epoch 68, loss 2.396811008453369, acc=0.162222221493721, loss=2.396811008453369
test: epoch 68, loss 3.2857506275177, acc=0.06666667014360428, loss=3.2857506275177
train: epoch 69, loss 2.4136884212493896, acc=0.1709444373846054, loss=2.4136884212493896
test: epoch 69, loss 3.2015163898468018, acc=0.07222222536802292, loss=3.2015163898468018
train: epoch 70, loss 2.4174764156341553, acc=0.1660555601119995, loss=2.4174764156341553
test: epoch 70, loss 3.33158540725708, acc=0.0555555559694767, loss=3.33158540725708
train: epoch 71, loss 2.3986668586730957, acc=0.1678333282470703, loss=2.3986668586730957
test: epoch 71, loss 3.2437262535095215, acc=0.07222222536802292, loss=3.2437262535095215
train: epoch 72, loss 2.3888816833496094, acc=0.16705556213855743, loss=2.3888816833496094
test: epoch 72, loss 3.202871799468994, acc=0.07777778059244156, loss=3.202871799468994
train: epoch 73, loss 2.3987841606140137, acc=0.1722777783870697, loss=2.3987841606140137
test: epoch 73, loss 3.268376350402832, acc=0.07777778059244156, loss=3.268376350402832
train: epoch 74, loss 2.3934876918792725, acc=0.16811111569404602, loss=2.3934876918792725
test: epoch 74, loss 3.2418558597564697, acc=0.05000000074505806, loss=3.2418558597564697
train: epoch 75, loss 2.3957104682922363, acc=0.1665000021457672, loss=2.3957104682922363
test: epoch 75, loss 3.3368611335754395, acc=0.05277777835726738, loss=3.3368611335754395
train: epoch 76, loss 2.4035534858703613, acc=0.17027777433395386, loss=2.4035534858703613
test: epoch 76, loss 3.2364909648895264, acc=0.08055555820465088, loss=3.2364909648895264
train: epoch 77, loss 2.3742730617523193, acc=0.171833336353302, loss=2.3742730617523193
test: epoch 77, loss 3.251357078552246, acc=0.0694444477558136, loss=3.251357078552246
train: epoch 78, loss 2.404634475708008, acc=0.1736111044883728, loss=2.404634475708008
test: epoch 78, loss 3.3460516929626465, acc=0.06111111119389534, loss=3.3460516929626465
train: epoch 79, loss 2.3770458698272705, acc=0.1734444499015808, loss=2.3770458698272705
test: epoch 79, loss 3.2864577770233154, acc=0.04722222313284874, loss=3.2864577770233154
train: epoch 80, loss 2.3926522731781006, acc=0.1767222285270691, loss=2.3926522731781006
test: epoch 80, loss 3.1723625659942627, acc=0.07500000298023224, loss=3.1723625659942627
train: epoch 81, loss 2.3810408115386963, acc=0.17166666686534882, loss=2.3810408115386963
test: epoch 81, loss 3.219120740890503, acc=0.0694444477558136, loss=3.219120740890503
train: epoch 82, loss 2.38212251663208, acc=0.1682777851819992, loss=2.38212251663208
test: epoch 82, loss 3.2036349773406982, acc=0.07500000298023224, loss=3.2036349773406982
train: epoch 83, loss 2.3671720027923584, acc=0.17383334040641785, loss=2.3671720027923584
test: epoch 83, loss 3.3278632164001465, acc=0.07500000298023224, loss=3.3278632164001465
train: epoch 84, loss 2.364335775375366, acc=0.17088888585567474, loss=2.364335775375366
test: epoch 84, loss 3.2498908042907715, acc=0.07777778059244156, loss=3.2498908042907715
train: epoch 85, loss 2.373919725418091, acc=0.17105555534362793, loss=2.373919725418091
test: epoch 85, loss 3.3000130653381348, acc=0.07500000298023224, loss=3.3000130653381348
train: epoch 86, loss 2.3738739490509033, acc=0.16988888382911682, loss=2.3738739490509033
test: epoch 86, loss 3.0940518379211426, acc=0.07777778059244156, loss=3.0940518379211426
train: epoch 87, loss 2.376338481903076, acc=0.1753888875246048, loss=2.376338481903076
test: epoch 87, loss 3.18813419342041, acc=0.0694444477558136, loss=3.18813419342041
train: epoch 88, loss 2.371351718902588, acc=0.17283333837985992, loss=2.371351718902588
test: epoch 88, loss 3.259880304336548, acc=0.06111111119389534, loss=3.259880304336548
train: epoch 89, loss 2.365891695022583, acc=0.17505554854869843, loss=2.365891695022583
test: epoch 89, loss 3.180459976196289, acc=0.07222222536802292, loss=3.180459976196289
train: epoch 90, loss 2.362377643585205, acc=0.1738888919353485, loss=2.362377643585205
test: epoch 90, loss 3.2007265090942383, acc=0.07222222536802292, loss=3.2007265090942383
train: epoch 91, loss 2.353404998779297, acc=0.17461110651493073, loss=2.353404998779297
test: epoch 91, loss 3.2348954677581787, acc=0.0555555559694767, loss=3.2348954677581787
train: epoch 92, loss 2.3665871620178223, acc=0.18244443833827972, loss=2.3665871620178223
test: epoch 92, loss 3.1487772464752197, acc=0.07222222536802292, loss=3.1487772464752197
train: epoch 93, loss 2.352372884750366, acc=0.17972221970558167, loss=2.352372884750366
test: epoch 93, loss 3.249746084213257, acc=0.05833333358168602, loss=3.249746084213257
train: epoch 94, loss 2.3444693088531494, acc=0.17866666615009308, loss=2.3444693088531494
test: epoch 94, loss 3.185971736907959, acc=0.07222222536802292, loss=3.185971736907959
train: epoch 95, loss 2.338549852371216, acc=0.18088889122009277, loss=2.338549852371216
test: epoch 95, loss 3.271259069442749, acc=0.0555555559694767, loss=3.271259069442749
train: epoch 96, loss 2.3636863231658936, acc=0.17649999260902405, loss=2.3636863231658936
test: epoch 96, loss 3.160036325454712, acc=0.07222222536802292, loss=3.160036325454712
train: epoch 97, loss 2.3654189109802246, acc=0.17483332753181458, loss=2.3654189109802246
test: epoch 97, loss 3.238416910171509, acc=0.07500000298023224, loss=3.238416910171509
train: epoch 98, loss 2.3328542709350586, acc=0.179666668176651, loss=2.3328542709350586
test: epoch 98, loss 3.124830484390259, acc=0.07222222536802292, loss=3.124830484390259
train: epoch 99, loss 2.347271680831909, acc=0.17733334004878998, loss=2.347271680831909
test: epoch 99, loss 3.224846839904785, acc=0.06111111119389534, loss=3.224846839904785
train: epoch 100, loss 2.336486339569092, acc=0.17888888716697693, loss=2.336486339569092
test: epoch 100, loss 3.2766778469085693, acc=0.07222222536802292, loss=3.2766778469085693
train: epoch 101, loss 2.34580659866333, acc=0.18111111223697662, loss=2.34580659866333
test: epoch 101, loss 3.3472840785980225, acc=0.07222222536802292, loss=3.3472840785980225
train: epoch 102, loss 2.314725399017334, acc=0.18183332681655884, loss=2.314725399017334
test: epoch 102, loss 3.4004111289978027, acc=0.06388889253139496, loss=3.4004111289978027
train: epoch 103, loss 2.329645872116089, acc=0.18777777254581451, loss=2.329645872116089
test: epoch 103, loss 3.289360284805298, acc=0.0694444477558136, loss=3.289360284805298
train: epoch 104, loss 2.321479082107544, acc=0.1841111183166504, loss=2.321479082107544
test: epoch 104, loss 3.4578583240509033, acc=0.06111111119389534, loss=3.4578583240509033
train: epoch 105, loss 2.326446533203125, acc=0.18038888275623322, loss=2.326446533203125
test: epoch 105, loss 3.222094774246216, acc=0.06388889253139496, loss=3.222094774246216
train: epoch 106, loss 2.3207948207855225, acc=0.181611105799675, loss=2.3207948207855225
test: epoch 106, loss 3.3087565898895264, acc=0.06666667014360428, loss=3.3087565898895264
train: epoch 107, loss 2.3255488872528076, acc=0.18816666305065155, loss=2.3255488872528076
test: epoch 107, loss 3.3622090816497803, acc=0.05277777835726738, loss=3.3622090816497803
train: epoch 108, loss 2.3028035163879395, acc=0.1852777749300003, loss=2.3028035163879395
test: epoch 108, loss 3.2318830490112305, acc=0.06666667014360428, loss=3.2318830490112305
train: epoch 109, loss 2.330108404159546, acc=0.18400000035762787, loss=2.330108404159546
test: epoch 109, loss 3.1902101039886475, acc=0.07500000298023224, loss=3.1902101039886475
train: epoch 110, loss 2.311521291732788, acc=0.1821666657924652, loss=2.311521291732788
test: epoch 110, loss 3.273146867752075, acc=0.0694444477558136, loss=3.273146867752075
train: epoch 111, loss 2.3133108615875244, acc=0.18961110711097717, loss=2.3133108615875244
test: epoch 111, loss 3.2182488441467285, acc=0.06666667014360428, loss=3.2182488441467285
train: epoch 112, loss 2.3222196102142334, acc=0.18227778375148773, loss=2.3222196102142334
test: epoch 112, loss 3.1981313228607178, acc=0.07500000298023224, loss=3.1981313228607178
train: epoch 113, loss 2.2965378761291504, acc=0.1885555535554886, loss=2.2965378761291504
test: epoch 113, loss 3.201406240463257, acc=0.07222222536802292, loss=3.201406240463257
train: epoch 114, loss 2.2925989627838135, acc=0.19122222065925598, loss=2.2925989627838135
test: epoch 114, loss 3.250784158706665, acc=0.0694444477558136, loss=3.250784158706665
train: epoch 115, loss 2.292823553085327, acc=0.19027778506278992, loss=2.292823553085327
test: epoch 115, loss 3.3580269813537598, acc=0.0694444477558136, loss=3.3580269813537598
train: epoch 116, loss 2.2987375259399414, acc=0.18666666746139526, loss=2.2987375259399414
test: epoch 116, loss 3.289846897125244, acc=0.0694444477558136, loss=3.289846897125244
train: epoch 117, loss 2.3114686012268066, acc=0.18744444847106934, loss=2.3114686012268066
test: epoch 117, loss 3.216160535812378, acc=0.07500000298023224, loss=3.216160535812378
train: epoch 118, loss 2.301175594329834, acc=0.1867777705192566, loss=2.301175594329834
test: epoch 118, loss 3.1555593013763428, acc=0.0833333358168602, loss=3.1555593013763428
train: epoch 119, loss 2.291407585144043, acc=0.1870555579662323, loss=2.291407585144043
test: epoch 119, loss 3.143939256668091, acc=0.07777778059244156, loss=3.143939256668091
train: epoch 120, loss 2.289512872695923, acc=0.18966667354106903, loss=2.289512872695923
test: epoch 120, loss 3.356809139251709, acc=0.06666667014360428, loss=3.356809139251709
train: epoch 121, loss 2.285861015319824, acc=0.19211110472679138, loss=2.285861015319824
test: epoch 121, loss 3.3355236053466797, acc=0.07222222536802292, loss=3.3355236053466797
train: epoch 122, loss 2.283609390258789, acc=0.19005554914474487, loss=2.283609390258789
test: epoch 122, loss 3.264937162399292, acc=0.06111111119389534, loss=3.264937162399292
train: epoch 123, loss 2.286613941192627, acc=0.19494444131851196, loss=2.286613941192627
test: epoch 123, loss 3.2756524085998535, acc=0.07222222536802292, loss=3.2756524085998535
train: epoch 124, loss 2.283677339553833, acc=0.19249999523162842, loss=2.283677339553833
test: epoch 124, loss 3.191398859024048, acc=0.05833333358168602, loss=3.191398859024048
train: epoch 125, loss 2.2752792835235596, acc=0.19538888335227966, loss=2.2752792835235596
test: epoch 125, loss 3.2628872394561768, acc=0.07777778059244156, loss=3.2628872394561768
train: epoch 126, loss 2.2767984867095947, acc=0.19616666436195374, loss=2.2767984867095947
test: epoch 126, loss 3.2593133449554443, acc=0.06388889253139496, loss=3.2593133449554443
train: epoch 127, loss 2.2786874771118164, acc=0.19655555486679077, loss=2.2786874771118164
test: epoch 127, loss 3.2860922813415527, acc=0.07500000298023224, loss=3.2860922813415527
train: epoch 128, loss 2.254272222518921, acc=0.19683332741260529, loss=2.254272222518921
test: epoch 128, loss 3.220573663711548, acc=0.07777778059244156, loss=3.220573663711548
train: epoch 129, loss 2.273380756378174, acc=0.19366666674613953, loss=2.273380756378174
test: epoch 129, loss 3.341160774230957, acc=0.0694444477558136, loss=3.341160774230957
train: epoch 130, loss 2.2552077770233154, acc=0.19349999725818634, loss=2.2552077770233154
test: epoch 130, loss 3.347411870956421, acc=0.07500000298023224, loss=3.347411870956421
train: epoch 131, loss 2.267371892929077, acc=0.19594444334506989, loss=2.267371892929077
test: epoch 131, loss 3.301408052444458, acc=0.0555555559694767, loss=3.301408052444458
train: epoch 132, loss 2.281845808029175, acc=0.19394443929195404, loss=2.281845808029175
test: epoch 132, loss 3.292759895324707, acc=0.05833333358168602, loss=3.292759895324707
train: epoch 133, loss 2.2759928703308105, acc=0.19805555045604706, loss=2.2759928703308105
test: epoch 133, loss 3.2955126762390137, acc=0.07222222536802292, loss=3.2955126762390137
train: epoch 134, loss 2.2558228969573975, acc=0.19894444942474365, loss=2.2558228969573975
test: epoch 134, loss 3.2986912727355957, acc=0.06111111119389534, loss=3.2986912727355957
train: epoch 135, loss 2.2578938007354736, acc=0.20038889348506927, loss=2.2578938007354736
test: epoch 135, loss 3.370593309402466, acc=0.05833333358168602, loss=3.370593309402466
train: epoch 136, loss 2.256364345550537, acc=0.19200000166893005, loss=2.256364345550537
test: epoch 136, loss 3.2810444831848145, acc=0.08055555820465088, loss=3.2810444831848145
train: epoch 137, loss 2.2504923343658447, acc=0.2006666660308838, loss=2.2504923343658447
test: epoch 137, loss 3.3334479331970215, acc=0.07500000298023224, loss=3.3334479331970215
train: epoch 138, loss 2.2534215450286865, acc=0.203166663646698, loss=2.2534215450286865
test: epoch 138, loss 3.3048110008239746, acc=0.0833333358168602, loss=3.3048110008239746
train: epoch 139, loss 2.241335868835449, acc=0.20483332872390747, loss=2.241335868835449
test: epoch 139, loss 3.295682191848755, acc=0.07222222536802292, loss=3.295682191848755
train: epoch 140, loss 2.2504074573516846, acc=0.20377777516841888, loss=2.2504074573516846
test: epoch 140, loss 3.204317569732666, acc=0.07222222536802292, loss=3.204317569732666
train: epoch 141, loss 2.257218599319458, acc=0.19522222876548767, loss=2.257218599319458
test: epoch 141, loss 3.2526612281799316, acc=0.0555555559694767, loss=3.2526612281799316
train: epoch 142, loss 2.2359774112701416, acc=0.2025555521249771, loss=2.2359774112701416
test: epoch 142, loss 3.3039679527282715, acc=0.05833333358168602, loss=3.3039679527282715
train: epoch 143, loss 2.246692657470703, acc=0.20233333110809326, loss=2.246692657470703
test: epoch 143, loss 3.285374402999878, acc=0.07222222536802292, loss=3.285374402999878
train: epoch 144, loss 2.231856346130371, acc=0.19922222197055817, loss=2.231856346130371
test: epoch 144, loss 3.280747652053833, acc=0.05833333358168602, loss=3.280747652053833
train: epoch 145, loss 2.2164835929870605, acc=0.2038888931274414, loss=2.2164835929870605
test: epoch 145, loss 3.3495962619781494, acc=0.07222222536802292, loss=3.3495962619781494
train: epoch 146, loss 2.2275874614715576, acc=0.20161111652851105, loss=2.2275874614715576
test: epoch 146, loss 3.1780800819396973, acc=0.0833333358168602, loss=3.1780800819396973
train: epoch 147, loss 2.2441956996917725, acc=0.19861111044883728, loss=2.2441956996917725
test: epoch 147, loss 3.4952492713928223, acc=0.05833333358168602, loss=3.4952492713928223
train: epoch 148, loss 2.2351067066192627, acc=0.20000000298023224, loss=2.2351067066192627
test: epoch 148, loss 3.3322947025299072, acc=0.07222222536802292, loss=3.3322947025299072
train: epoch 149, loss 2.219411611557007, acc=0.20505554974079132, loss=2.219411611557007
test: epoch 149, loss 3.2930657863616943, acc=0.05277777835726738, loss=3.2930657863616943
train: epoch 150, loss 2.227159023284912, acc=0.19822221994400024, loss=2.227159023284912
test: epoch 150, loss 3.27276611328125, acc=0.06666667014360428, loss=3.27276611328125
