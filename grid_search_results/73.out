# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=1.5", "--temp_decay=1", "--one_hot=true", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=986759884, receiver_embed_dim=64, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.895433187484741, acc=0.09777777642011642, loss=2.895433187484741
test: epoch 1, loss 2.86257266998291, acc=0.0972222238779068, loss=2.86257266998291
train: epoch 2, loss 1.9266513586044312, acc=0.24177777767181396, loss=1.9266513586044312
test: epoch 2, loss 3.4118802547454834, acc=0.16111111640930176, loss=3.4118802547454834
train: epoch 3, loss 1.5391491651535034, acc=0.38405555486679077, loss=1.5391491651535034
test: epoch 3, loss 3.285825729370117, acc=0.18888889253139496, loss=3.285825729370117
train: epoch 4, loss 1.1839702129364014, acc=0.5152222514152527, loss=1.1839702129364014
test: epoch 4, loss 2.43914794921875, acc=0.21111111342906952, loss=2.43914794921875
train: epoch 5, loss 0.9656946659088135, acc=0.6041111350059509, loss=0.9656946659088135
test: epoch 5, loss 2.413130521774292, acc=0.27222222089767456, loss=2.413130521774292
train: epoch 6, loss 0.8585429191589355, acc=0.6520000100135803, loss=0.8585429191589355
test: epoch 6, loss 2.3072307109832764, acc=0.3055555522441864, loss=2.3072307109832764
train: epoch 7, loss 0.7518651485443115, acc=0.694611132144928, loss=0.7518651485443115
test: epoch 7, loss 2.2695302963256836, acc=0.3166666626930237, loss=2.2695302963256836
train: epoch 8, loss 0.6590168476104736, acc=0.7321666479110718, loss=0.6590168476104736
test: epoch 8, loss 2.355943441390991, acc=0.3083333373069763, loss=2.355943441390991
train: epoch 9, loss 0.6006765365600586, acc=0.7565555572509766, loss=0.6006765365600586
test: epoch 9, loss 1.8633378744125366, acc=0.3611111044883728, loss=1.8633378744125366
train: epoch 10, loss 0.5494064688682556, acc=0.7788888812065125, loss=0.5494064688682556
test: epoch 10, loss 1.7688966989517212, acc=0.35555556416511536, loss=1.7688966989517212
train: epoch 11, loss 0.5060872435569763, acc=0.7973889112472534, loss=0.5060872435569763
test: epoch 11, loss 2.1104133129119873, acc=0.31111112236976624, loss=2.1104133129119873
train: epoch 12, loss 0.460866779088974, acc=0.8174444437026978, loss=0.460866779088974
test: epoch 12, loss 1.9493504762649536, acc=0.3777777850627899, loss=1.9493504762649536
train: epoch 13, loss 0.4201726019382477, acc=0.8295555710792542, loss=0.4201726019382477
test: epoch 13, loss 2.0809059143066406, acc=0.3861111104488373, loss=2.0809059143066406
train: epoch 14, loss 0.4011881649494171, acc=0.8372222185134888, loss=0.4011881649494171
test: epoch 14, loss 1.863816738128662, acc=0.39722222089767456, loss=1.863816738128662
train: epoch 15, loss 0.36300426721572876, acc=0.852055549621582, loss=0.36300426721572876
test: epoch 15, loss 2.510866403579712, acc=0.31388887763023376, loss=2.510866403579712
train: epoch 16, loss 0.3691060543060303, acc=0.8492222428321838, loss=0.3691060543060303
test: epoch 16, loss 2.2518107891082764, acc=0.3888888955116272, loss=2.2518107891082764
train: epoch 17, loss 0.3502963185310364, acc=0.8556110858917236, loss=0.3502963185310364
test: epoch 17, loss 1.7604212760925293, acc=0.4166666567325592, loss=1.7604212760925293
train: epoch 18, loss 0.3241170644760132, acc=0.8633888959884644, loss=0.3241170644760132
test: epoch 18, loss 1.8441672325134277, acc=0.3916666805744171, loss=1.8441672325134277
train: epoch 19, loss 0.3124346137046814, acc=0.8684999942779541, loss=0.3124346137046814
test: epoch 19, loss 2.1263113021850586, acc=0.35555556416511536, loss=2.1263113021850586
train: epoch 20, loss 0.30145832896232605, acc=0.8741666674613953, loss=0.30145832896232605
test: epoch 20, loss 1.6228585243225098, acc=0.4861111044883728, loss=1.6228585243225098
train: epoch 21, loss 0.280608594417572, acc=0.8799444437026978, loss=0.280608594417572
test: epoch 21, loss 1.781561017036438, acc=0.40833333134651184, loss=1.781561017036438
train: epoch 22, loss 0.2690136432647705, acc=0.8852777481079102, loss=0.2690136432647705
test: epoch 22, loss 1.6548969745635986, acc=0.46388888359069824, loss=1.6548969745635986
train: epoch 23, loss 0.26088476181030273, acc=0.8878333568572998, loss=0.26088476181030273
test: epoch 23, loss 1.7688612937927246, acc=0.4749999940395355, loss=1.7688612937927246
train: epoch 24, loss 0.26086562871932983, acc=0.890999972820282, loss=0.26086562871932983
test: epoch 24, loss 2.483381986618042, acc=0.4055555462837219, loss=2.483381986618042
train: epoch 25, loss 0.2593952417373657, acc=0.8923888802528381, loss=0.2593952417373657
test: epoch 25, loss 1.8956618309020996, acc=0.5, loss=1.8956618309020996
train: epoch 26, loss 0.2351052314043045, acc=0.9012222290039062, loss=0.2351052314043045
test: epoch 26, loss 2.4513750076293945, acc=0.49166667461395264, loss=2.4513750076293945
train: epoch 27, loss 0.22035783529281616, acc=0.9051666855812073, loss=0.22035783529281616
test: epoch 27, loss 1.828081488609314, acc=0.4972222149372101, loss=1.828081488609314
train: epoch 28, loss 0.20920200645923615, acc=0.9082777500152588, loss=0.20920200645923615
test: epoch 28, loss 2.300812244415283, acc=0.4000000059604645, loss=2.300812244415283
train: epoch 29, loss 0.23013752698898315, acc=0.9052777886390686, loss=0.23013752698898315
test: epoch 29, loss 1.9931684732437134, acc=0.5111111402511597, loss=1.9931684732437134
train: epoch 30, loss 0.2187938094139099, acc=0.9080555438995361, loss=0.2187938094139099
test: epoch 30, loss 1.7303663492202759, acc=0.4749999940395355, loss=1.7303663492202759
train: epoch 31, loss 0.19928644597530365, acc=0.9146666526794434, loss=0.19928644597530365
test: epoch 31, loss 1.4028304815292358, acc=0.5416666865348816, loss=1.4028304815292358
train: epoch 32, loss 0.21761932969093323, acc=0.9091110825538635, loss=0.21761932969093323
test: epoch 32, loss 1.5841548442840576, acc=0.5444444417953491, loss=1.5841548442840576
train: epoch 33, loss 0.19181619584560394, acc=0.9177777767181396, loss=0.19181619584560394
test: epoch 33, loss 1.9053150415420532, acc=0.5249999761581421, loss=1.9053150415420532
train: epoch 34, loss 0.18536688387393951, acc=0.9187777638435364, loss=0.18536688387393951
test: epoch 34, loss 1.7476149797439575, acc=0.5277777910232544, loss=1.7476149797439575
train: epoch 35, loss 0.18595311045646667, acc=0.9167222380638123, loss=0.18595311045646667
test: epoch 35, loss 1.7713935375213623, acc=0.4749999940395355, loss=1.7713935375213623
train: epoch 36, loss 0.169921875, acc=0.9223333597183228, loss=0.169921875
test: epoch 36, loss 2.129815101623535, acc=0.46388888359069824, loss=2.129815101623535
train: epoch 37, loss 0.18267735838890076, acc=0.9213888645172119, loss=0.18267735838890076
test: epoch 37, loss 1.26872980594635, acc=0.5472221970558167, loss=1.26872980594635
train: epoch 38, loss 0.17926722764968872, acc=0.9229444265365601, loss=0.17926722764968872
test: epoch 38, loss 1.705438256263733, acc=0.5027777552604675, loss=1.705438256263733
train: epoch 39, loss 0.16738268733024597, acc=0.925611138343811, loss=0.16738268733024597
test: epoch 39, loss 1.4064197540283203, acc=0.5472221970558167, loss=1.4064197540283203
train: epoch 40, loss 0.1808680146932602, acc=0.9228888750076294, loss=0.1808680146932602
test: epoch 40, loss 1.8708784580230713, acc=0.5444444417953491, loss=1.8708784580230713
train: epoch 41, loss 0.17227931320667267, acc=0.9268888831138611, loss=0.17227931320667267
test: epoch 41, loss 1.7228256464004517, acc=0.5083333253860474, loss=1.7228256464004517
train: epoch 42, loss 0.16774001717567444, acc=0.9288333058357239, loss=0.16774001717567444
test: epoch 42, loss 1.9066306352615356, acc=0.49444442987442017, loss=1.9066306352615356
train: epoch 43, loss 0.14706197381019592, acc=0.9456111192703247, loss=0.14706197381019592
test: epoch 43, loss 1.4680651426315308, acc=0.5972222089767456, loss=1.4680651426315308
train: epoch 44, loss 0.12673674523830414, acc=0.9585000276565552, loss=0.12673674523830414
test: epoch 44, loss 1.8320095539093018, acc=0.5611110925674438, loss=1.8320095539093018
train: epoch 45, loss 0.11364031583070755, acc=0.9618889093399048, loss=0.11364031583070755
test: epoch 45, loss 1.5495936870574951, acc=0.5916666388511658, loss=1.5495936870574951
train: epoch 46, loss 0.12336058914661407, acc=0.9595000147819519, loss=0.12336058914661407
test: epoch 46, loss 1.6513421535491943, acc=0.5666666626930237, loss=1.6513421535491943
train: epoch 47, loss 0.10355707257986069, acc=0.9660555720329285, loss=0.10355707257986069
test: epoch 47, loss 1.371329426765442, acc=0.5666666626930237, loss=1.371329426765442
train: epoch 48, loss 0.10391249507665634, acc=0.965499997138977, loss=0.10391249507665634
test: epoch 48, loss 1.6638258695602417, acc=0.5305555462837219, loss=1.6638258695602417
train: epoch 49, loss 0.11489424109458923, acc=0.9617778062820435, loss=0.11489424109458923
test: epoch 49, loss 1.728276252746582, acc=0.5805555582046509, loss=1.728276252746582
train: epoch 50, loss 0.10431018471717834, acc=0.9650555849075317, loss=0.10431018471717834
test: epoch 50, loss 1.6202030181884766, acc=0.6305555701255798, loss=1.6202030181884766
train: epoch 51, loss 0.1049557700753212, acc=0.9668889045715332, loss=0.1049557700753212
test: epoch 51, loss 1.7714152336120605, acc=0.5916666388511658, loss=1.7714152336120605
train: epoch 52, loss 0.10588341951370239, acc=0.9645000100135803, loss=0.10588341951370239
test: epoch 52, loss 1.3386049270629883, acc=0.5888888835906982, loss=1.3386049270629883
train: epoch 53, loss 0.09225375205278397, acc=0.9691666960716248, loss=0.09225375205278397
test: epoch 53, loss 1.6504229307174683, acc=0.5861111283302307, loss=1.6504229307174683
train: epoch 54, loss 0.08984458446502686, acc=0.9694444537162781, loss=0.08984458446502686
test: epoch 54, loss 1.8347378969192505, acc=0.5694444179534912, loss=1.8347378969192505
train: epoch 55, loss 0.09305939078330994, acc=0.9702777862548828, loss=0.09305939078330994
test: epoch 55, loss 1.2408183813095093, acc=0.6194444298744202, loss=1.2408183813095093
train: epoch 56, loss 0.09898541122674942, acc=0.9692222476005554, loss=0.09898541122674942
test: epoch 56, loss 1.6889832019805908, acc=0.5916666388511658, loss=1.6889832019805908
train: epoch 57, loss 0.08941767364740372, acc=0.9700555801391602, loss=0.08941767364740372
test: epoch 57, loss 1.6361162662506104, acc=0.605555534362793, loss=1.6361162662506104
train: epoch 58, loss 0.0802471861243248, acc=0.9723333120346069, loss=0.0802471861243248
test: epoch 58, loss 1.6972702741622925, acc=0.6194444298744202, loss=1.6972702741622925
train: epoch 59, loss 0.08921263366937637, acc=0.969944417476654, loss=0.08921263366937637
test: epoch 59, loss 1.1493743658065796, acc=0.6555555462837219, loss=1.1493743658065796
train: epoch 60, loss 0.0948040559887886, acc=0.9672222137451172, loss=0.0948040559887886
test: epoch 60, loss 1.0580724477767944, acc=0.6583333611488342, loss=1.0580724477767944
train: epoch 61, loss 0.09392808377742767, acc=0.9697222113609314, loss=0.09392808377742767
test: epoch 61, loss 1.2493189573287964, acc=0.6555555462837219, loss=1.2493189573287964
train: epoch 62, loss 0.07634174823760986, acc=0.9748333096504211, loss=0.07634174823760986
test: epoch 62, loss 1.2037866115570068, acc=0.6555555462837219, loss=1.2037866115570068
train: epoch 63, loss 0.08585856854915619, acc=0.9730555415153503, loss=0.08585856854915619
test: epoch 63, loss 1.4495086669921875, acc=0.6000000238418579, loss=1.4495086669921875
train: epoch 64, loss 0.08408276736736298, acc=0.9716110825538635, loss=0.08408276736736298
test: epoch 64, loss 1.6717548370361328, acc=0.6472222208976746, loss=1.6717548370361328
train: epoch 65, loss 0.07526767253875732, acc=0.9744444489479065, loss=0.07526767253875732
test: epoch 65, loss 1.117468237876892, acc=0.6944444179534912, loss=1.117468237876892
train: epoch 66, loss 0.08250156044960022, acc=0.9731666445732117, loss=0.08250156044960022
test: epoch 66, loss 1.315102219581604, acc=0.6777777671813965, loss=1.315102219581604
train: epoch 67, loss 0.07461530715227127, acc=0.9757221937179565, loss=0.07461530715227127
test: epoch 67, loss 1.1332767009735107, acc=0.6166666746139526, loss=1.1332767009735107
train: epoch 68, loss 0.0733887255191803, acc=0.9748888611793518, loss=0.0733887255191803
test: epoch 68, loss 1.2012319564819336, acc=0.7472222447395325, loss=1.2012319564819336
train: epoch 69, loss 0.07870697230100632, acc=0.9742777943611145, loss=0.07870697230100632
test: epoch 69, loss 1.0485543012619019, acc=0.6555555462837219, loss=1.0485543012619019
train: epoch 70, loss 0.08147139847278595, acc=0.9718888998031616, loss=0.08147139847278595
test: epoch 70, loss 1.351021409034729, acc=0.6916666626930237, loss=1.351021409034729
train: epoch 71, loss 0.06914765387773514, acc=0.9765555262565613, loss=0.06914765387773514
test: epoch 71, loss 1.1043682098388672, acc=0.7055555582046509, loss=1.1043682098388672
train: epoch 72, loss 0.06440021097660065, acc=0.9782778024673462, loss=0.06440021097660065
test: epoch 72, loss 1.0865517854690552, acc=0.7083333134651184, loss=1.0865517854690552
train: epoch 73, loss 0.07249729335308075, acc=0.9762222170829773, loss=0.07249729335308075
test: epoch 73, loss 1.1274524927139282, acc=0.7222222089767456, loss=1.1274524927139282
train: epoch 74, loss 0.07842081040143967, acc=0.9735555648803711, loss=0.07842081040143967
test: epoch 74, loss 1.0621261596679688, acc=0.7444444298744202, loss=1.0621261596679688
train: epoch 75, loss 0.07465068995952606, acc=0.9751111268997192, loss=0.07465068995952606
test: epoch 75, loss 1.055495023727417, acc=0.7027778029441833, loss=1.055495023727417
train: epoch 76, loss 0.052322790026664734, acc=0.9814444184303284, loss=0.052322790026664734
test: epoch 76, loss 0.9171069860458374, acc=0.8083333373069763, loss=0.9171069860458374
train: epoch 77, loss 0.06774724274873734, acc=0.9771666526794434, loss=0.06774724274873734
test: epoch 77, loss 1.2056770324707031, acc=0.7138888835906982, loss=1.2056770324707031
train: epoch 78, loss 0.06640966981649399, acc=0.9780555367469788, loss=0.06640966981649399
test: epoch 78, loss 0.983476459980011, acc=0.7916666865348816, loss=0.983476459980011
train: epoch 79, loss 0.06446406245231628, acc=0.9785555601119995, loss=0.06446406245231628
test: epoch 79, loss 0.9092730283737183, acc=0.7861111164093018, loss=0.9092730283737183
train: epoch 80, loss 0.060978010296821594, acc=0.9789444208145142, loss=0.060978010296821594
test: epoch 80, loss 0.8593377470970154, acc=0.8138889074325562, loss=0.8593377470970154
train: epoch 81, loss 0.058113690465688705, acc=0.9793888926506042, loss=0.058113690465688705
test: epoch 81, loss 0.6657406091690063, acc=0.8500000238418579, loss=0.6657406091690063
train: epoch 82, loss 0.0726478099822998, acc=0.9756666421890259, loss=0.0726478099822998
test: epoch 82, loss 0.9376624226570129, acc=0.8027777671813965, loss=0.9376624226570129
train: epoch 83, loss 0.056431759148836136, acc=0.981333315372467, loss=0.056431759148836136
test: epoch 83, loss 0.6875864863395691, acc=0.8277778029441833, loss=0.6875864863395691
train: epoch 84, loss 0.062075886875391006, acc=0.9796110987663269, loss=0.062075886875391006
test: epoch 84, loss 0.8182451128959656, acc=0.8361111283302307, loss=0.8182451128959656
train: epoch 85, loss 0.06539719551801682, acc=0.9792777895927429, loss=0.06539719551801682
test: epoch 85, loss 0.7689160108566284, acc=0.8083333373069763, loss=0.7689160108566284
train: epoch 86, loss 0.06148676201701164, acc=0.9789444208145142, loss=0.06148676201701164
test: epoch 86, loss 0.6407144069671631, acc=0.875, loss=0.6407144069671631
train: epoch 87, loss 0.05493975803256035, acc=0.9818333387374878, loss=0.05493975803256035
test: epoch 87, loss 0.7227436900138855, acc=0.855555534362793, loss=0.7227436900138855
train: epoch 88, loss 0.04929957166314125, acc=0.9831110835075378, loss=0.04929957166314125
test: epoch 88, loss 0.8233102560043335, acc=0.8333333134651184, loss=0.8233102560043335
train: epoch 89, loss 0.055038463324308395, acc=0.9814444184303284, loss=0.055038463324308395
test: epoch 89, loss 0.6526371836662292, acc=0.8444444537162781, loss=0.6526371836662292
train: epoch 90, loss 0.059600356966257095, acc=0.9807778000831604, loss=0.059600356966257095
test: epoch 90, loss 0.6578571796417236, acc=0.8999999761581421, loss=0.6578571796417236
train: epoch 91, loss 0.053863685578107834, acc=0.9810555577278137, loss=0.053863685578107834
test: epoch 91, loss 0.5949288010597229, acc=0.8500000238418579, loss=0.5949288010597229
train: epoch 92, loss 0.04812672361731529, acc=0.9826666712760925, loss=0.04812672361731529
test: epoch 92, loss 0.6682300567626953, acc=0.8277778029441833, loss=0.6682300567626953
train: epoch 93, loss 0.057188019156455994, acc=0.9804999828338623, loss=0.057188019156455994
test: epoch 93, loss 0.5054933428764343, acc=0.8861111402511597, loss=0.5054933428764343
train: epoch 94, loss 0.054554831236600876, acc=0.9825555682182312, loss=0.054554831236600876
test: epoch 94, loss 0.44706302881240845, acc=0.8833333253860474, loss=0.44706302881240845
train: epoch 95, loss 0.042696356773376465, acc=0.9848333597183228, loss=0.042696356773376465
test: epoch 95, loss 0.515739381313324, acc=0.9083333611488342, loss=0.515739381313324
train: epoch 96, loss 0.056937120854854584, acc=0.9806666374206543, loss=0.056937120854854584
test: epoch 96, loss 0.4468231201171875, acc=0.9027777910232544, loss=0.4468231201171875
train: epoch 97, loss 0.04528094455599785, acc=0.9847221970558167, loss=0.04528094455599785
test: epoch 97, loss 0.35955581068992615, acc=0.9027777910232544, loss=0.35955581068992615
train: epoch 98, loss 0.04548155143857002, acc=0.9835555553436279, loss=0.04548155143857002
test: epoch 98, loss 0.35514315962791443, acc=0.9166666865348816, loss=0.35514315962791443
train: epoch 99, loss 0.04886626824736595, acc=0.9833333492279053, loss=0.04886626824736595
test: epoch 99, loss 0.453540563583374, acc=0.9138888716697693, loss=0.453540563583374
train: epoch 100, loss 0.04626072198152542, acc=0.9849444627761841, loss=0.04626072198152542
test: epoch 100, loss 0.451738566160202, acc=0.9083333611488342, loss=0.451738566160202
train: epoch 101, loss 0.04201750457286835, acc=0.9852777719497681, loss=0.04201750457286835
test: epoch 101, loss 0.35497838258743286, acc=0.925000011920929, loss=0.35497838258743286
train: epoch 102, loss 0.04900471121072769, acc=0.9835000038146973, loss=0.04900471121072769
test: epoch 102, loss 0.4142082631587982, acc=0.9027777910232544, loss=0.4142082631587982
train: epoch 103, loss 0.04482240602374077, acc=0.9843888878822327, loss=0.04482240602374077
test: epoch 103, loss 0.4926985204219818, acc=0.9194444417953491, loss=0.4926985204219818
train: epoch 104, loss 0.04216332361102104, acc=0.9856666922569275, loss=0.04216332361102104
test: epoch 104, loss 0.4500037729740143, acc=0.9222221970558167, loss=0.4500037729740143
train: epoch 105, loss 0.04442790150642395, acc=0.984333336353302, loss=0.04442790150642395
test: epoch 105, loss 0.35135915875434875, acc=0.9277777671813965, loss=0.35135915875434875
train: epoch 106, loss 0.036155205219984055, acc=0.9872778058052063, loss=0.036155205219984055
test: epoch 106, loss 0.27666783332824707, acc=0.9416666626930237, loss=0.27666783332824707
train: epoch 107, loss 0.04070465266704559, acc=0.9881666898727417, loss=0.04070465266704559
test: epoch 107, loss 0.26296886801719666, acc=0.9388889074325562, loss=0.26296886801719666
train: epoch 108, loss 0.033933304250240326, acc=0.9898889064788818, loss=0.033933304250240326
test: epoch 108, loss 0.20084363222122192, acc=0.9388889074325562, loss=0.20084363222122192
train: epoch 109, loss 0.03419914096593857, acc=0.9899444580078125, loss=0.03419914096593857
test: epoch 109, loss 0.2842133045196533, acc=0.9361110925674438, loss=0.2842133045196533
train: epoch 110, loss 0.022462008520960808, acc=0.9921666383743286, loss=0.022462008520960808
test: epoch 110, loss 0.3997536599636078, acc=0.9361110925674438, loss=0.3997536599636078
train: epoch 111, loss 0.033222224563360214, acc=0.9898333549499512, loss=0.033222224563360214
test: epoch 111, loss 0.39869681000709534, acc=0.9361110925674438, loss=0.39869681000709534
train: epoch 112, loss 0.03058353252708912, acc=0.9904444217681885, loss=0.03058353252708912
test: epoch 112, loss 0.3886295557022095, acc=0.9361110925674438, loss=0.3886295557022095
train: epoch 113, loss 0.039455607533454895, acc=0.9862222075462341, loss=0.039455607533454895
test: epoch 113, loss 0.3276462256908417, acc=0.9361110925674438, loss=0.3276462256908417
train: epoch 114, loss 0.03683934360742569, acc=0.9878888726234436, loss=0.03683934360742569
test: epoch 114, loss 0.3677651286125183, acc=0.9305555820465088, loss=0.3677651286125183
train: epoch 115, loss 0.03281678259372711, acc=0.988111138343811, loss=0.03281678259372711
test: epoch 115, loss 0.33592700958251953, acc=0.9388889074325562, loss=0.33592700958251953
train: epoch 116, loss 0.033132098615169525, acc=0.9897222518920898, loss=0.033132098615169525
test: epoch 116, loss 0.29429489374160767, acc=0.9444444179534912, loss=0.29429489374160767
train: epoch 117, loss 0.024676505476236343, acc=0.991611123085022, loss=0.024676505476236343
test: epoch 117, loss 0.2878006100654602, acc=0.9583333134651184, loss=0.2878006100654602
train: epoch 118, loss 0.029635297134518623, acc=0.9913333058357239, loss=0.029635297134518623
test: epoch 118, loss 0.551826000213623, acc=0.9194444417953491, loss=0.551826000213623
train: epoch 119, loss 0.03620229661464691, acc=0.9896666407585144, loss=0.03620229661464691
test: epoch 119, loss 0.32899466156959534, acc=0.9361110925674438, loss=0.32899466156959534
train: epoch 120, loss 0.031237520277500153, acc=0.9897778034210205, loss=0.031237520277500153
test: epoch 120, loss 0.36258023977279663, acc=0.9305555820465088, loss=0.36258023977279663
train: epoch 121, loss 0.030151482671499252, acc=0.9910555481910706, loss=0.030151482671499252
test: epoch 121, loss 0.31933528184890747, acc=0.9388889074325562, loss=0.31933528184890747
train: epoch 122, loss 0.03582848608493805, acc=0.9889444708824158, loss=0.03582848608493805
test: epoch 122, loss 0.2378411442041397, acc=0.9388889074325562, loss=0.2378411442041397
train: epoch 123, loss 0.024628978222608566, acc=0.9923333525657654, loss=0.024628978222608566
test: epoch 123, loss 0.3754023611545563, acc=0.9416666626930237, loss=0.3754023611545563
train: epoch 124, loss 0.019160527735948563, acc=0.9938333630561829, loss=0.019160527735948563
test: epoch 124, loss 0.2994913160800934, acc=0.9527778029441833, loss=0.2994913160800934
train: epoch 125, loss 0.026300940662622452, acc=0.991777777671814, loss=0.026300940662622452
test: epoch 125, loss 0.22520862519741058, acc=0.9694444537162781, loss=0.22520862519741058
train: epoch 126, loss 0.02648746594786644, acc=0.9916666746139526, loss=0.02648746594786644
test: epoch 126, loss 0.179830402135849, acc=0.9694444537162781, loss=0.179830402135849
train: epoch 127, loss 0.021825170144438744, acc=0.9933333396911621, loss=0.021825170144438744
test: epoch 127, loss 0.20503735542297363, acc=0.9722222089767456, loss=0.20503735542297363
train: epoch 128, loss 0.021302927285432816, acc=0.992888867855072, loss=0.021302927285432816
test: epoch 128, loss 0.1422300636768341, acc=0.9722222089767456, loss=0.1422300636768341
train: epoch 129, loss 0.029851747676730156, acc=0.9915000200271606, loss=0.029851747676730156
test: epoch 129, loss 0.12739448249340057, acc=0.9777777791023254, loss=0.12739448249340057
train: epoch 130, loss 0.01964661106467247, acc=0.9938333630561829, loss=0.01964661106467247
test: epoch 130, loss 0.44399160146713257, acc=0.9416666626930237, loss=0.44399160146713257
train: epoch 131, loss 0.02757609263062477, acc=0.9917222261428833, loss=0.02757609263062477
test: epoch 131, loss 0.15230731666088104, acc=0.9694444537162781, loss=0.15230731666088104
train: epoch 132, loss 0.024438077583909035, acc=0.9931666851043701, loss=0.024438077583909035
test: epoch 132, loss 0.1003936231136322, acc=0.9750000238418579, loss=0.1003936231136322
train: epoch 133, loss 0.021760357543826103, acc=0.9933888912200928, loss=0.021760357543826103
test: epoch 133, loss 0.08792506158351898, acc=0.9833333492279053, loss=0.08792506158351898
train: epoch 134, loss 0.01533856987953186, acc=0.9946666955947876, loss=0.01533856987953186
test: epoch 134, loss 0.08981772512197495, acc=0.9833333492279053, loss=0.08981772512197495
train: epoch 135, loss 0.014710349962115288, acc=0.9950555562973022, loss=0.014710349962115288
test: epoch 135, loss 0.09404147416353226, acc=0.9833333492279053, loss=0.09404147416353226
train: epoch 136, loss 0.02029305323958397, acc=0.9935555458068848, loss=0.02029305323958397
test: epoch 136, loss 0.09117183089256287, acc=0.980555534362793, loss=0.09117183089256287
train: epoch 137, loss 0.022444335743784904, acc=0.9929999709129333, loss=0.022444335743784904
test: epoch 137, loss 0.08302271366119385, acc=0.9833333492279053, loss=0.08302271366119385
train: epoch 138, loss 0.01367576327174902, acc=0.9949444532394409, loss=0.01367576327174902
test: epoch 138, loss 0.11161281168460846, acc=0.9833333492279053, loss=0.11161281168460846
train: epoch 139, loss 0.015033955685794353, acc=0.9948889017105103, loss=0.015033955685794353
test: epoch 139, loss 0.09061842411756516, acc=0.9833333492279053, loss=0.09061842411756516
train: epoch 140, loss 0.01454591378569603, acc=0.9956111311912537, loss=0.01454591378569603
test: epoch 140, loss 0.09969107806682587, acc=0.9833333492279053, loss=0.09969107806682587
train: epoch 141, loss 0.016837231814861298, acc=0.9944444298744202, loss=0.016837231814861298
test: epoch 141, loss 0.09227064996957779, acc=0.9833333492279053, loss=0.09227064996957779
train: epoch 142, loss 0.026412351056933403, acc=0.9911110997200012, loss=0.026412351056933403
test: epoch 142, loss 0.04645602032542229, acc=0.9833333492279053, loss=0.04645602032542229
train: epoch 143, loss 0.018000351265072823, acc=0.9939444661140442, loss=0.018000351265072823
test: epoch 143, loss 0.06428145617246628, acc=0.9833333492279053, loss=0.06428145617246628
train: epoch 144, loss 0.01383418682962656, acc=0.9950555562973022, loss=0.01383418682962656
test: epoch 144, loss 0.060529906302690506, acc=0.9861111044883728, loss=0.060529906302690506
train: epoch 145, loss 0.025538727641105652, acc=0.9920555353164673, loss=0.025538727641105652
test: epoch 145, loss 0.07375208288431168, acc=0.9833333492279053, loss=0.07375208288431168
train: epoch 146, loss 0.01791355386376381, acc=0.9944444298744202, loss=0.01791355386376381
test: epoch 146, loss 0.09908449649810791, acc=0.9833333492279053, loss=0.09908449649810791
train: epoch 147, loss 0.020118901506066322, acc=0.9936110973358154, loss=0.020118901506066322
test: epoch 147, loss 0.10150573402643204, acc=0.9611111283302307, loss=0.10150573402643204
train: epoch 148, loss 0.012864166870713234, acc=0.9957777857780457, loss=0.012864166870713234
test: epoch 148, loss 0.09235884249210358, acc=0.9833333492279053, loss=0.09235884249210358
train: epoch 149, loss 0.01278702262789011, acc=0.9952777624130249, loss=0.01278702262789011
test: epoch 149, loss 0.12383811920881271, acc=0.9833333492279053, loss=0.12383811920881271
train: epoch 150, loss 0.017627932131290436, acc=0.9948889017105103, loss=0.017627932131290436
test: epoch 150, loss 0.22541385889053345, acc=0.9750000238418579, loss=0.22541385889053345
