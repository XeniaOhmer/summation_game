# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=1", "--temp_decay=0.99", "--one_hot=1", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=1988134072, receiver_embed_dim=32, save_run=0, temp_decay=0.99, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1988134072, receiver_embed_dim=32, save_run=False, temp_decay=0.99, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.4843811988830566, acc=0.0486111119389534, loss=3.4843811988830566
test: epoch 1, loss 3.6677703857421875, acc=0.0555555559694767, loss=3.6677703857421875
train: epoch 2, loss 3.023103713989258, acc=0.09149999916553497, loss=3.023103713989258
test: epoch 2, loss 2.977497100830078, acc=0.0972222238779068, loss=2.977497100830078
train: epoch 3, loss 2.4104201793670654, acc=0.1641666740179062, loss=2.4104201793670654
test: epoch 3, loss 2.484891176223755, acc=0.14444445073604584, loss=2.484891176223755
train: epoch 4, loss 2.1312615871429443, acc=0.20772221684455872, loss=2.1312615871429443
test: epoch 4, loss 2.3315951824188232, acc=0.13611111044883728, loss=2.3315951824188232
train: epoch 5, loss 1.9502907991409302, acc=0.25672221183776855, loss=1.9502907991409302
test: epoch 5, loss 2.200697898864746, acc=0.14444445073604584, loss=2.200697898864746
train: epoch 6, loss 1.7894597053527832, acc=0.30300000309944153, loss=1.7894597053527832
test: epoch 6, loss 2.2026681900024414, acc=0.16388888657093048, loss=2.2026681900024414
train: epoch 7, loss 1.6949135065078735, acc=0.33205556869506836, loss=1.6949135065078735
test: epoch 7, loss 2.204559326171875, acc=0.15833333134651184, loss=2.204559326171875
train: epoch 8, loss 1.633682370185852, acc=0.34272223711013794, loss=1.633682370185852
test: epoch 8, loss 2.1045358180999756, acc=0.17499999701976776, loss=2.1045358180999756
train: epoch 9, loss 1.5822644233703613, acc=0.36133334040641785, loss=1.5822644233703613
test: epoch 9, loss 2.1150126457214355, acc=0.17777778208255768, loss=2.1150126457214355
train: epoch 10, loss 1.5333640575408936, acc=0.3727777898311615, loss=1.5333640575408936
test: epoch 10, loss 2.0676558017730713, acc=0.19166666269302368, loss=2.0676558017730713
train: epoch 11, loss 1.4912391901016235, acc=0.38733333349227905, loss=1.4912391901016235
test: epoch 11, loss 2.003586769104004, acc=0.21111111342906952, loss=2.003586769104004
train: epoch 12, loss 1.4593467712402344, acc=0.402222216129303, loss=1.4593467712402344
test: epoch 12, loss 1.9914727210998535, acc=0.21388888359069824, loss=1.9914727210998535
train: epoch 13, loss 1.4269801378250122, acc=0.41644445061683655, loss=1.4269801378250122
test: epoch 13, loss 1.991448998451233, acc=0.2222222238779068, loss=1.991448998451233
train: epoch 14, loss 1.3813061714172363, acc=0.43566668033599854, loss=1.3813061714172363
test: epoch 14, loss 1.946516752243042, acc=0.22777777910232544, loss=1.946516752243042
train: epoch 15, loss 1.3656948804855347, acc=0.43622222542762756, loss=1.3656948804855347
test: epoch 15, loss 1.8932437896728516, acc=0.23888888955116272, loss=1.8932437896728516
train: epoch 16, loss 1.3353497982025146, acc=0.4434444308280945, loss=1.3353497982025146
test: epoch 16, loss 1.8952786922454834, acc=0.2361111044883728, loss=1.8952786922454834
train: epoch 17, loss 1.3172791004180908, acc=0.45722222328186035, loss=1.3172791004180908
test: epoch 17, loss 1.8757535219192505, acc=0.24722221493721008, loss=1.8757535219192505
train: epoch 18, loss 1.3069427013397217, acc=0.45988887548446655, loss=1.3069427013397217
test: epoch 18, loss 1.8569518327713013, acc=0.2750000059604645, loss=1.8569518327713013
train: epoch 19, loss 1.2822586297988892, acc=0.47083333134651184, loss=1.2822586297988892
test: epoch 19, loss 1.7839298248291016, acc=0.25833332538604736, loss=1.7839298248291016
train: epoch 20, loss 1.2625635862350464, acc=0.4799444377422333, loss=1.2625635862350464
test: epoch 20, loss 1.7640082836151123, acc=0.2805555462837219, loss=1.7640082836151123
train: epoch 21, loss 1.2484673261642456, acc=0.48249998688697815, loss=1.2484673261642456
test: epoch 21, loss 1.7583600282669067, acc=0.2777777910232544, loss=1.7583600282669067
train: epoch 22, loss 1.217109203338623, acc=0.5018333196640015, loss=1.217109203338623
test: epoch 22, loss 1.7022664546966553, acc=0.2944444417953491, loss=1.7022664546966553
train: epoch 23, loss 1.2083625793457031, acc=0.507611095905304, loss=1.2083625793457031
test: epoch 23, loss 1.6679866313934326, acc=0.28333333134651184, loss=1.6679866313934326
train: epoch 24, loss 1.1928683519363403, acc=0.5084999799728394, loss=1.1928683519363403
test: epoch 24, loss 1.69674551486969, acc=0.2944444417953491, loss=1.69674551486969
train: epoch 25, loss 1.1742100715637207, acc=0.5144444704055786, loss=1.1742100715637207
test: epoch 25, loss 1.6324100494384766, acc=0.3083333373069763, loss=1.6324100494384766
train: epoch 26, loss 1.1563175916671753, acc=0.5266666412353516, loss=1.1563175916671753
test: epoch 26, loss 1.677323579788208, acc=0.3222222328186035, loss=1.677323579788208
train: epoch 27, loss 1.150191307067871, acc=0.5220555663108826, loss=1.150191307067871
test: epoch 27, loss 1.6053308248519897, acc=0.3055555522441864, loss=1.6053308248519897
train: epoch 28, loss 1.125801920890808, acc=0.531000018119812, loss=1.125801920890808
test: epoch 28, loss 1.596315860748291, acc=0.30000001192092896, loss=1.596315860748291
train: epoch 29, loss 1.1263420581817627, acc=0.5288333296775818, loss=1.1263420581817627
test: epoch 29, loss 1.5953319072723389, acc=0.3055555522441864, loss=1.5953319072723389
train: epoch 30, loss 1.103061318397522, acc=0.5370000004768372, loss=1.103061318397522
test: epoch 30, loss 1.58232843875885, acc=0.31111112236976624, loss=1.58232843875885
train: epoch 31, loss 1.0981184244155884, acc=0.5348888635635376, loss=1.0981184244155884
test: epoch 31, loss 1.566355586051941, acc=0.31388887763023376, loss=1.566355586051941
train: epoch 32, loss 1.0839289426803589, acc=0.5383889079093933, loss=1.0839289426803589
test: epoch 32, loss 1.5963894128799438, acc=0.3222222328186035, loss=1.5963894128799438
train: epoch 33, loss 1.0680197477340698, acc=0.5458889007568359, loss=1.0680197477340698
test: epoch 33, loss 1.5903950929641724, acc=0.3166666626930237, loss=1.5903950929641724
train: epoch 34, loss 1.0648584365844727, acc=0.5488888621330261, loss=1.0648584365844727
test: epoch 34, loss 1.5873874425888062, acc=0.32499998807907104, loss=1.5873874425888062
train: epoch 35, loss 1.0424309968948364, acc=0.550000011920929, loss=1.0424309968948364
test: epoch 35, loss 1.5581685304641724, acc=0.3333333432674408, loss=1.5581685304641724
train: epoch 36, loss 1.0238958597183228, acc=0.5604444742202759, loss=1.0238958597183228
test: epoch 36, loss 1.5827656984329224, acc=0.3361110985279083, loss=1.5827656984329224
train: epoch 37, loss 1.0300781726837158, acc=0.5589444637298584, loss=1.0300781726837158
test: epoch 37, loss 1.5808557271957397, acc=0.3333333432674408, loss=1.5808557271957397
train: epoch 38, loss 1.0139695405960083, acc=0.558388888835907, loss=1.0139695405960083
test: epoch 38, loss 1.5815098285675049, acc=0.3166666626930237, loss=1.5815098285675049
train: epoch 39, loss 1.0129514932632446, acc=0.5599444508552551, loss=1.0129514932632446
test: epoch 39, loss 1.5985972881317139, acc=0.32777777314186096, loss=1.5985972881317139
train: epoch 40, loss 1.0046322345733643, acc=0.5656111240386963, loss=1.0046322345733643
test: epoch 40, loss 1.5801453590393066, acc=0.3305555582046509, loss=1.5801453590393066
train: epoch 41, loss 0.9924006462097168, acc=0.5693888664245605, loss=0.9924006462097168
test: epoch 41, loss 1.6500431299209595, acc=0.34166666865348816, loss=1.6500431299209595
train: epoch 42, loss 0.9826619029045105, acc=0.5733333230018616, loss=0.9826619029045105
test: epoch 42, loss 1.5843557119369507, acc=0.3444444537162781, loss=1.5843557119369507
train: epoch 43, loss 0.9672535061836243, acc=0.5808888673782349, loss=0.9672535061836243
test: epoch 43, loss 1.6140204668045044, acc=0.3444444537162781, loss=1.6140204668045044
train: epoch 44, loss 0.9538958072662354, acc=0.5817221999168396, loss=0.9538958072662354
test: epoch 44, loss 1.5754332542419434, acc=0.33888888359069824, loss=1.5754332542419434
train: epoch 45, loss 0.953122615814209, acc=0.5879444479942322, loss=0.953122615814209
test: epoch 45, loss 1.5768641233444214, acc=0.3333333432674408, loss=1.5768641233444214
train: epoch 46, loss 0.9450499415397644, acc=0.5870000123977661, loss=0.9450499415397644
test: epoch 46, loss 1.6357982158660889, acc=0.33888888359069824, loss=1.6357982158660889
train: epoch 47, loss 0.933636486530304, acc=0.5933889150619507, loss=0.933636486530304
test: epoch 47, loss 1.6292330026626587, acc=0.3499999940395355, loss=1.6292330026626587
train: epoch 48, loss 0.9368500113487244, acc=0.5887222290039062, loss=0.9368500113487244
test: epoch 48, loss 1.5901192426681519, acc=0.34166666865348816, loss=1.5901192426681519
train: epoch 49, loss 0.9283815026283264, acc=0.5941666960716248, loss=0.9283815026283264
test: epoch 49, loss 1.5967295169830322, acc=0.3499999940395355, loss=1.5967295169830322
train: epoch 50, loss 0.9208712577819824, acc=0.5941666960716248, loss=0.9208712577819824
test: epoch 50, loss 1.64309561252594, acc=0.3472222089767456, loss=1.64309561252594
train: epoch 51, loss 0.9141159653663635, acc=0.6024444699287415, loss=0.9141159653663635
test: epoch 51, loss 1.641257643699646, acc=0.3499999940395355, loss=1.641257643699646
train: epoch 52, loss 0.8976505398750305, acc=0.6047222018241882, loss=0.8976505398750305
test: epoch 52, loss 1.6597442626953125, acc=0.33888888359069824, loss=1.6597442626953125
train: epoch 53, loss 0.8909719586372375, acc=0.605388879776001, loss=0.8909719586372375
test: epoch 53, loss 1.6515828371047974, acc=0.35277777910232544, loss=1.6515828371047974
train: epoch 54, loss 0.8856543302536011, acc=0.6061111092567444, loss=0.8856543302536011
test: epoch 54, loss 1.6360403299331665, acc=0.35277777910232544, loss=1.6360403299331665
train: epoch 55, loss 0.8751704096794128, acc=0.6107222437858582, loss=0.8751704096794128
test: epoch 55, loss 1.663659691810608, acc=0.3499999940395355, loss=1.663659691810608
train: epoch 56, loss 0.8790697455406189, acc=0.6071666479110718, loss=0.8790697455406189
test: epoch 56, loss 1.6336290836334229, acc=0.35277777910232544, loss=1.6336290836334229
train: epoch 57, loss 0.8854976892471313, acc=0.6141666769981384, loss=0.8854976892471313
test: epoch 57, loss 1.7346787452697754, acc=0.3472222089767456, loss=1.7346787452697754
train: epoch 58, loss 0.879582941532135, acc=0.6069444417953491, loss=0.879582941532135
test: epoch 58, loss 1.6133365631103516, acc=0.35277777910232544, loss=1.6133365631103516
train: epoch 59, loss 0.8795739412307739, acc=0.6112777590751648, loss=0.8795739412307739
test: epoch 59, loss 1.667791485786438, acc=0.3499999940395355, loss=1.667791485786438
train: epoch 60, loss 0.8622117638587952, acc=0.6137222051620483, loss=0.8622117638587952
test: epoch 60, loss 1.6306955814361572, acc=0.35555556416511536, loss=1.6306955814361572
train: epoch 61, loss 0.8623908758163452, acc=0.6162222027778625, loss=0.8623908758163452
test: epoch 61, loss 1.654473900794983, acc=0.35277777910232544, loss=1.654473900794983
train: epoch 62, loss 0.849888801574707, acc=0.6179444193840027, loss=0.849888801574707
test: epoch 62, loss 1.6548570394515991, acc=0.3611111044883728, loss=1.6548570394515991
train: epoch 63, loss 0.8464675545692444, acc=0.6184444427490234, loss=0.8464675545692444
test: epoch 63, loss 1.6171561479568481, acc=0.3611111044883728, loss=1.6171561479568481
train: epoch 64, loss 0.8401362895965576, acc=0.6234444379806519, loss=0.8401362895965576
test: epoch 64, loss 1.5948395729064941, acc=0.35277777910232544, loss=1.5948395729064941
train: epoch 65, loss 0.8439350128173828, acc=0.6199444532394409, loss=0.8439350128173828
test: epoch 65, loss 1.746669054031372, acc=0.36666667461395264, loss=1.746669054031372
train: epoch 66, loss 0.8400169610977173, acc=0.6198333501815796, loss=0.8400169610977173
test: epoch 66, loss 1.7395561933517456, acc=0.3583333194255829, loss=1.7395561933517456
train: epoch 67, loss 0.8284156918525696, acc=0.6271666884422302, loss=0.8284156918525696
test: epoch 67, loss 1.6883106231689453, acc=0.35277777910232544, loss=1.6883106231689453
train: epoch 68, loss 0.8251064419746399, acc=0.6273888945579529, loss=0.8251064419746399
test: epoch 68, loss 1.678773045539856, acc=0.35277777910232544, loss=1.678773045539856
train: epoch 69, loss 0.827886700630188, acc=0.6269999742507935, loss=0.827886700630188
test: epoch 69, loss 1.7139627933502197, acc=0.35555556416511536, loss=1.7139627933502197
train: epoch 70, loss 0.8257631659507751, acc=0.628166675567627, loss=0.8257631659507751
test: epoch 70, loss 1.6517882347106934, acc=0.35277777910232544, loss=1.6517882347106934
train: epoch 71, loss 0.8292537927627563, acc=0.6257777810096741, loss=0.8292537927627563
test: epoch 71, loss 1.711510419845581, acc=0.35555556416511536, loss=1.711510419845581
train: epoch 72, loss 0.8263070583343506, acc=0.625333309173584, loss=0.8263070583343506
test: epoch 72, loss 1.7158254384994507, acc=0.35555556416511536, loss=1.7158254384994507
train: epoch 73, loss 0.8173938393592834, acc=0.6307222247123718, loss=0.8173938393592834
test: epoch 73, loss 1.6710649728775024, acc=0.3611111044883728, loss=1.6710649728775024
train: epoch 74, loss 0.8040055632591248, acc=0.6342777609825134, loss=0.8040055632591248
test: epoch 74, loss 1.7055505514144897, acc=0.35555556416511536, loss=1.7055505514144897
train: epoch 75, loss 0.8092997670173645, acc=0.6299999952316284, loss=0.8092997670173645
test: epoch 75, loss 1.7079956531524658, acc=0.3611111044883728, loss=1.7079956531524658
train: epoch 76, loss 0.8053563833236694, acc=0.6278333067893982, loss=0.8053563833236694
test: epoch 76, loss 1.7423768043518066, acc=0.35277777910232544, loss=1.7423768043518066
train: epoch 77, loss 0.7996969819068909, acc=0.6331666707992554, loss=0.7996969819068909
test: epoch 77, loss 1.7851260900497437, acc=0.35277777910232544, loss=1.7851260900497437
train: epoch 78, loss 0.7936124801635742, acc=0.6334999799728394, loss=0.7936124801635742
test: epoch 78, loss 1.681135892868042, acc=0.3638888895511627, loss=1.681135892868042
train: epoch 79, loss 0.8017226457595825, acc=0.6302777528762817, loss=0.8017226457595825
test: epoch 79, loss 1.7225741147994995, acc=0.3499999940395355, loss=1.7225741147994995
train: epoch 80, loss 0.7885816693305969, acc=0.6349444389343262, loss=0.7885816693305969
test: epoch 80, loss 1.7458949089050293, acc=0.3611111044883728, loss=1.7458949089050293
train: epoch 81, loss 0.7950924038887024, acc=0.6345555782318115, loss=0.7950924038887024
test: epoch 81, loss 1.729471206665039, acc=0.3583333194255829, loss=1.729471206665039
train: epoch 82, loss 0.7885361313819885, acc=0.6315000057220459, loss=0.7885361313819885
test: epoch 82, loss 1.6668386459350586, acc=0.3499999940395355, loss=1.6668386459350586
train: epoch 83, loss 0.7939189672470093, acc=0.63227778673172, loss=0.7939189672470093
test: epoch 83, loss 1.7264384031295776, acc=0.3611111044883728, loss=1.7264384031295776
train: epoch 84, loss 0.7818177342414856, acc=0.6361666917800903, loss=0.7818177342414856
test: epoch 84, loss 1.8441051244735718, acc=0.36666667461395264, loss=1.8441051244735718
train: epoch 85, loss 0.7802498936653137, acc=0.6349999904632568, loss=0.7802498936653137
test: epoch 85, loss 1.687996506690979, acc=0.3638888895511627, loss=1.687996506690979
train: epoch 86, loss 0.7889124751091003, acc=0.637333333492279, loss=0.7889124751091003
test: epoch 86, loss 1.7778557538986206, acc=0.3611111044883728, loss=1.7778557538986206
train: epoch 87, loss 0.7819119691848755, acc=0.6337222456932068, loss=0.7819119691848755
test: epoch 87, loss 1.8142791986465454, acc=0.3638888895511627, loss=1.8142791986465454
train: epoch 88, loss 0.7925785779953003, acc=0.6380000114440918, loss=0.7925785779953003
test: epoch 88, loss 1.7713544368743896, acc=0.36666667461395264, loss=1.7713544368743896
train: epoch 89, loss 0.7761833667755127, acc=0.6390555500984192, loss=0.7761833667755127
test: epoch 89, loss 1.8038767576217651, acc=0.36666667461395264, loss=1.8038767576217651
train: epoch 90, loss 0.781212329864502, acc=0.643833339214325, loss=0.781212329864502
test: epoch 90, loss 1.7851245403289795, acc=0.36944442987442017, loss=1.7851245403289795
train: epoch 91, loss 0.7768082022666931, acc=0.6389444470405579, loss=0.7768082022666931
test: epoch 91, loss 1.7594765424728394, acc=0.3638888895511627, loss=1.7594765424728394
train: epoch 92, loss 0.7769240140914917, acc=0.6411111354827881, loss=0.7769240140914917
test: epoch 92, loss 1.797608494758606, acc=0.3611111044883728, loss=1.797608494758606
train: epoch 93, loss 0.7716357111930847, acc=0.6370555758476257, loss=0.7716357111930847
test: epoch 93, loss 1.7102270126342773, acc=0.3611111044883728, loss=1.7102270126342773
train: epoch 94, loss 0.7601162791252136, acc=0.6437222361564636, loss=0.7601162791252136
test: epoch 94, loss 1.6570007801055908, acc=0.36944442987442017, loss=1.6570007801055908
train: epoch 95, loss 0.7646886706352234, acc=0.6436111330986023, loss=0.7646886706352234
test: epoch 95, loss 1.8676581382751465, acc=0.3638888895511627, loss=1.8676581382751465
train: epoch 96, loss 0.7652121782302856, acc=0.6410555839538574, loss=0.7652121782302856
test: epoch 96, loss 1.796974539756775, acc=0.36944442987442017, loss=1.796974539756775
train: epoch 97, loss 0.7555938363075256, acc=0.6460555791854858, loss=0.7555938363075256
test: epoch 97, loss 1.754862904548645, acc=0.3722222149372101, loss=1.754862904548645
train: epoch 98, loss 0.7611591219902039, acc=0.6411666870117188, loss=0.7611591219902039
test: epoch 98, loss 1.723237156867981, acc=0.36944442987442017, loss=1.723237156867981
train: epoch 99, loss 0.7540090084075928, acc=0.6434444189071655, loss=0.7540090084075928
test: epoch 99, loss 1.6784329414367676, acc=0.3722222149372101, loss=1.6784329414367676
train: epoch 100, loss 0.7621697187423706, acc=0.6436111330986023, loss=0.7621697187423706
test: epoch 100, loss 1.7225444316864014, acc=0.36944442987442017, loss=1.7225444316864014
train: epoch 101, loss 0.7490905523300171, acc=0.6489999890327454, loss=0.7490905523300171
test: epoch 101, loss 1.7235013246536255, acc=0.375, loss=1.7235013246536255
train: epoch 102, loss 0.7633845210075378, acc=0.641777753829956, loss=0.7633845210075378
test: epoch 102, loss 1.7466450929641724, acc=0.375, loss=1.7466450929641724
train: epoch 103, loss 0.7697274088859558, acc=0.6442221999168396, loss=0.7697274088859558
test: epoch 103, loss 1.8333678245544434, acc=0.3722222149372101, loss=1.8333678245544434
train: epoch 104, loss 0.7457335591316223, acc=0.648277759552002, loss=0.7457335591316223
test: epoch 104, loss 1.6833279132843018, acc=0.3888888955116272, loss=1.6833279132843018
train: epoch 105, loss 0.7518802285194397, acc=0.6474444270133972, loss=0.7518802285194397
test: epoch 105, loss 1.802077054977417, acc=0.3777777850627899, loss=1.802077054977417
train: epoch 106, loss 0.7507818937301636, acc=0.6445000171661377, loss=0.7507818937301636
test: epoch 106, loss 1.8497328758239746, acc=0.3638888895511627, loss=1.8497328758239746
train: epoch 107, loss 0.7401984333992004, acc=0.6495000123977661, loss=0.7401984333992004
test: epoch 107, loss 1.7443946599960327, acc=0.3777777850627899, loss=1.7443946599960327
train: epoch 108, loss 0.760491669178009, acc=0.6478333473205566, loss=0.760491669178009
test: epoch 108, loss 1.7331032752990723, acc=0.3861111104488373, loss=1.7331032752990723
train: epoch 109, loss 0.749743640422821, acc=0.6510555744171143, loss=0.749743640422821
test: epoch 109, loss 1.7906687259674072, acc=0.3777777850627899, loss=1.7906687259674072
train: epoch 110, loss 0.7532192468643188, acc=0.6465555429458618, loss=0.7532192468643188
test: epoch 110, loss 1.773016095161438, acc=0.3722222149372101, loss=1.773016095161438
train: epoch 111, loss 0.736513078212738, acc=0.6514444351196289, loss=0.736513078212738
test: epoch 111, loss 1.7957404851913452, acc=0.3861111104488373, loss=1.7957404851913452
train: epoch 112, loss 0.7310143709182739, acc=0.6553888916969299, loss=0.7310143709182739
test: epoch 112, loss 1.7364833354949951, acc=0.38055557012557983, loss=1.7364833354949951
train: epoch 113, loss 0.7334465384483337, acc=0.6564444303512573, loss=0.7334465384483337
test: epoch 113, loss 1.7464752197265625, acc=0.38055557012557983, loss=1.7464752197265625
train: epoch 114, loss 0.7394310832023621, acc=0.6544444561004639, loss=0.7394310832023621
test: epoch 114, loss 1.7580196857452393, acc=0.3777777850627899, loss=1.7580196857452393
train: epoch 115, loss 0.7367168068885803, acc=0.6491110920906067, loss=0.7367168068885803
test: epoch 115, loss 1.6959689855575562, acc=0.3888888955116272, loss=1.6959689855575562
train: epoch 116, loss 0.7239331603050232, acc=0.6570000052452087, loss=0.7239331603050232
test: epoch 116, loss 1.8581669330596924, acc=0.3777777850627899, loss=1.8581669330596924
train: epoch 117, loss 0.7401683926582336, acc=0.652388870716095, loss=0.7401683926582336
test: epoch 117, loss 1.6638538837432861, acc=0.38333332538604736, loss=1.6638538837432861
train: epoch 118, loss 0.7328659892082214, acc=0.6531111001968384, loss=0.7328659892082214
test: epoch 118, loss 1.6922988891601562, acc=0.3888888955116272, loss=1.6922988891601562
train: epoch 119, loss 0.7447358965873718, acc=0.6504999995231628, loss=0.7447358965873718
test: epoch 119, loss 1.8194060325622559, acc=0.3916666805744171, loss=1.8194060325622559
train: epoch 120, loss 0.732952892780304, acc=0.6545000076293945, loss=0.732952892780304
test: epoch 120, loss 1.7649097442626953, acc=0.38333332538604736, loss=1.7649097442626953
train: epoch 121, loss 0.7358199954032898, acc=0.6564444303512573, loss=0.7358199954032898
test: epoch 121, loss 1.7918542623519897, acc=0.38055557012557983, loss=1.7918542623519897
train: epoch 122, loss 0.7267098426818848, acc=0.6534444689750671, loss=0.7267098426818848
test: epoch 122, loss 1.8559083938598633, acc=0.3916666805744171, loss=1.8559083938598633
train: epoch 123, loss 0.7256855964660645, acc=0.6531111001968384, loss=0.7256855964660645
test: epoch 123, loss 1.853887677192688, acc=0.38055557012557983, loss=1.853887677192688
train: epoch 124, loss 0.7314221858978271, acc=0.6515555381774902, loss=0.7314221858978271
test: epoch 124, loss 1.7729116678237915, acc=0.38055557012557983, loss=1.7729116678237915
train: epoch 125, loss 0.7292494773864746, acc=0.6537777781486511, loss=0.7292494773864746
test: epoch 125, loss 1.733084797859192, acc=0.38333332538604736, loss=1.733084797859192
train: epoch 126, loss 0.725373387336731, acc=0.6535555720329285, loss=0.725373387336731
test: epoch 126, loss 1.8177117109298706, acc=0.38333332538604736, loss=1.8177117109298706
train: epoch 127, loss 0.7247709631919861, acc=0.6533889174461365, loss=0.7247709631919861
test: epoch 127, loss 1.65833580493927, acc=0.3916666805744171, loss=1.65833580493927
train: epoch 128, loss 0.7250082492828369, acc=0.6552777886390686, loss=0.7250082492828369
test: epoch 128, loss 1.7784013748168945, acc=0.3861111104488373, loss=1.7784013748168945
train: epoch 129, loss 0.7223752737045288, acc=0.6540555357933044, loss=0.7223752737045288
test: epoch 129, loss 1.6487047672271729, acc=0.3916666805744171, loss=1.6487047672271729
train: epoch 130, loss 0.714570164680481, acc=0.6571666598320007, loss=0.714570164680481
test: epoch 130, loss 1.7525743246078491, acc=0.3861111104488373, loss=1.7525743246078491
train: epoch 131, loss 0.7225742936134338, acc=0.6553888916969299, loss=0.7225742936134338
test: epoch 131, loss 1.743599772453308, acc=0.3916666805744171, loss=1.743599772453308
train: epoch 132, loss 0.7307564616203308, acc=0.656166672706604, loss=0.7307564616203308
test: epoch 132, loss 1.7042326927185059, acc=0.3861111104488373, loss=1.7042326927185059
train: epoch 133, loss 0.7233880162239075, acc=0.6547777652740479, loss=0.7233880162239075
test: epoch 133, loss 1.824442744255066, acc=0.38333332538604736, loss=1.824442744255066
train: epoch 134, loss 0.7119507193565369, acc=0.6597222089767456, loss=0.7119507193565369
test: epoch 134, loss 1.7973992824554443, acc=0.3916666805744171, loss=1.7973992824554443
train: epoch 135, loss 0.7158344984054565, acc=0.6611666679382324, loss=0.7158344984054565
test: epoch 135, loss 1.7654979228973389, acc=0.3916666805744171, loss=1.7654979228973389
train: epoch 136, loss 0.7338864803314209, acc=0.6551111340522766, loss=0.7338864803314209
test: epoch 136, loss 1.7651225328445435, acc=0.3888888955116272, loss=1.7651225328445435
train: epoch 137, loss 0.7189407348632812, acc=0.6551666855812073, loss=0.7189407348632812
test: epoch 137, loss 1.7339122295379639, acc=0.3888888955116272, loss=1.7339122295379639
train: epoch 138, loss 0.716437578201294, acc=0.6548333168029785, loss=0.716437578201294
test: epoch 138, loss 1.724733829498291, acc=0.3916666805744171, loss=1.724733829498291
train: epoch 139, loss 0.7150137424468994, acc=0.656166672706604, loss=0.7150137424468994
test: epoch 139, loss 1.8653395175933838, acc=0.3888888955116272, loss=1.8653395175933838
train: epoch 140, loss 0.7190930247306824, acc=0.6560555696487427, loss=0.7190930247306824
test: epoch 140, loss 1.7963078022003174, acc=0.3916666805744171, loss=1.7963078022003174
train: epoch 141, loss 0.700736939907074, acc=0.6602222323417664, loss=0.700736939907074
test: epoch 141, loss 1.8494430780410767, acc=0.3861111104488373, loss=1.8494430780410767
train: epoch 142, loss 0.7072463035583496, acc=0.6604999899864197, loss=0.7072463035583496
test: epoch 142, loss 1.793800950050354, acc=0.3888888955116272, loss=1.793800950050354
train: epoch 143, loss 0.717685878276825, acc=0.6605555415153503, loss=0.717685878276825
test: epoch 143, loss 1.7213134765625, acc=0.39722222089767456, loss=1.7213134765625
train: epoch 144, loss 0.7084340453147888, acc=0.6588888764381409, loss=0.7084340453147888
test: epoch 144, loss 1.9031301736831665, acc=0.4000000059604645, loss=1.9031301736831665
train: epoch 145, loss 0.7143059968948364, acc=0.6575000286102295, loss=0.7143059968948364
test: epoch 145, loss 1.7854039669036865, acc=0.39722222089767456, loss=1.7854039669036865
train: epoch 146, loss 0.7140531539916992, acc=0.6551111340522766, loss=0.7140531539916992
test: epoch 146, loss 1.7781486511230469, acc=0.39722222089767456, loss=1.7781486511230469
train: epoch 147, loss 0.7067665457725525, acc=0.6597222089767456, loss=0.7067665457725525
test: epoch 147, loss 1.7877496480941772, acc=0.39722222089767456, loss=1.7877496480941772
train: epoch 148, loss 0.710030198097229, acc=0.6582221984863281, loss=0.710030198097229
test: epoch 148, loss 1.6348360776901245, acc=0.39444443583488464, loss=1.6348360776901245
train: epoch 149, loss 0.7122619152069092, acc=0.6575555801391602, loss=0.7122619152069092
test: epoch 149, loss 1.81232488155365, acc=0.39444443583488464, loss=1.81232488155365
train: epoch 150, loss 0.7180048227310181, acc=0.6607778072357178, loss=0.7180048227310181
test: epoch 150, loss 1.7962247133255005, acc=0.3888888955116272, loss=1.7962247133255005
