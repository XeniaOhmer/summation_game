# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=1", "--temp_decay=0.995", "--one_hot=true", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1030963639, receiver_embed_dim=64, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.0756072998046875, acc=0.07066666334867477, loss=3.0756072998046875
test: epoch 1, loss 2.479703664779663, acc=0.11944444477558136, loss=2.479703664779663
train: epoch 2, loss 2.1900522708892822, acc=0.16722221672534943, loss=2.1900522708892822
test: epoch 2, loss 2.419795513153076, acc=0.13611111044883728, loss=2.419795513153076
train: epoch 3, loss 1.8970592021942139, acc=0.22588889300823212, loss=1.8970592021942139
test: epoch 3, loss 2.293595790863037, acc=0.1527777761220932, loss=2.293595790863037
train: epoch 4, loss 1.763636589050293, acc=0.25049999356269836, loss=1.763636589050293
test: epoch 4, loss 2.063293933868408, acc=0.20000000298023224, loss=2.063293933868408
train: epoch 5, loss 1.6488609313964844, acc=0.2851666808128357, loss=1.6488609313964844
test: epoch 5, loss 1.9879518747329712, acc=0.22499999403953552, loss=1.9879518747329712
train: epoch 6, loss 1.5492422580718994, acc=0.32205554842948914, loss=1.5492422580718994
test: epoch 6, loss 2.119377374649048, acc=0.2527777850627899, loss=2.119377374649048
train: epoch 7, loss 1.4896118640899658, acc=0.3523888885974884, loss=1.4896118640899658
test: epoch 7, loss 1.936316967010498, acc=0.25833332538604736, loss=1.936316967010498
train: epoch 8, loss 1.3753598928451538, acc=0.4208333194255829, loss=1.3753598928451538
test: epoch 8, loss 2.027550220489502, acc=0.2750000059604645, loss=2.027550220489502
train: epoch 9, loss 1.2487683296203613, acc=0.4836111068725586, loss=1.2487683296203613
test: epoch 9, loss 1.931221604347229, acc=0.31388887763023376, loss=1.931221604347229
train: epoch 10, loss 1.1297134160995483, acc=0.538277804851532, loss=1.1297134160995483
test: epoch 10, loss 2.017723560333252, acc=0.30000001192092896, loss=2.017723560333252
train: epoch 11, loss 1.0562167167663574, acc=0.5629444718360901, loss=1.0562167167663574
test: epoch 11, loss 1.8758643865585327, acc=0.3166666626930237, loss=1.8758643865585327
train: epoch 12, loss 1.016111135482788, acc=0.5782777667045593, loss=1.016111135482788
test: epoch 12, loss 1.902171015739441, acc=0.31388887763023376, loss=1.902171015739441
train: epoch 13, loss 0.9976152181625366, acc=0.585444450378418, loss=0.9976152181625366
test: epoch 13, loss 1.8660587072372437, acc=0.3055555522441864, loss=1.8660587072372437
train: epoch 14, loss 0.9635059833526611, acc=0.6002222299575806, loss=0.9635059833526611
test: epoch 14, loss 1.814300537109375, acc=0.31388887763023376, loss=1.814300537109375
train: epoch 15, loss 0.9197263121604919, acc=0.613777756690979, loss=0.9197263121604919
test: epoch 15, loss 2.1182892322540283, acc=0.2916666567325592, loss=2.1182892322540283
train: epoch 16, loss 0.9049037098884583, acc=0.6158333420753479, loss=0.9049037098884583
test: epoch 16, loss 1.907403588294983, acc=0.31388887763023376, loss=1.907403588294983
train: epoch 17, loss 0.9009534120559692, acc=0.6167222261428833, loss=0.9009534120559692
test: epoch 17, loss 1.8667436838150024, acc=0.31388887763023376, loss=1.8667436838150024
train: epoch 18, loss 0.8649111390113831, acc=0.6285555362701416, loss=0.8649111390113831
test: epoch 18, loss 1.9089076519012451, acc=0.31388887763023376, loss=1.9089076519012451
train: epoch 19, loss 0.8659209609031677, acc=0.6315000057220459, loss=0.8659209609031677
test: epoch 19, loss 1.9891544580459595, acc=0.32499998807907104, loss=1.9891544580459595
train: epoch 20, loss 0.8588616847991943, acc=0.6316111087799072, loss=0.8588616847991943
test: epoch 20, loss 2.0050344467163086, acc=0.31388887763023376, loss=2.0050344467163086
train: epoch 21, loss 0.8499610424041748, acc=0.6300555467605591, loss=0.8499610424041748
test: epoch 21, loss 1.9098187685012817, acc=0.31388887763023376, loss=1.9098187685012817
train: epoch 22, loss 0.8328946828842163, acc=0.6462777853012085, loss=0.8328946828842163
test: epoch 22, loss 1.9984186887741089, acc=0.3083333373069763, loss=1.9984186887741089
train: epoch 23, loss 0.8602645397186279, acc=0.6309999823570251, loss=0.8602645397186279
test: epoch 23, loss 1.9990088939666748, acc=0.3083333373069763, loss=1.9990088939666748
train: epoch 24, loss 0.8381524085998535, acc=0.641777753829956, loss=0.8381524085998535
test: epoch 24, loss 1.9279303550720215, acc=0.3027777671813965, loss=1.9279303550720215
train: epoch 25, loss 0.828254222869873, acc=0.6483333110809326, loss=0.828254222869873
test: epoch 25, loss 2.0277161598205566, acc=0.31388887763023376, loss=2.0277161598205566
train: epoch 26, loss 0.8133791089057922, acc=0.6585000157356262, loss=0.8133791089057922
test: epoch 26, loss 1.9890074729919434, acc=0.33888888359069824, loss=1.9890074729919434
train: epoch 27, loss 0.7920952439308167, acc=0.6688888669013977, loss=0.7920952439308167
test: epoch 27, loss 2.0199954509735107, acc=0.34166666865348816, loss=2.0199954509735107
train: epoch 28, loss 0.7878252267837524, acc=0.6731111407279968, loss=0.7878252267837524
test: epoch 28, loss 2.036189556121826, acc=0.34166666865348816, loss=2.036189556121826
train: epoch 29, loss 0.7913916110992432, acc=0.6708333492279053, loss=0.7913916110992432
test: epoch 29, loss 2.046586036682129, acc=0.3333333432674408, loss=2.046586036682129
train: epoch 30, loss 0.7813612818717957, acc=0.6746666431427002, loss=0.7813612818717957
test: epoch 30, loss 1.963525414466858, acc=0.3444444537162781, loss=1.963525414466858
train: epoch 31, loss 0.7673251032829285, acc=0.6792222261428833, loss=0.7673251032829285
test: epoch 31, loss 1.9064470529556274, acc=0.3444444537162781, loss=1.9064470529556274
train: epoch 32, loss 0.7565625905990601, acc=0.6860555410385132, loss=0.7565625905990601
test: epoch 32, loss 1.9970550537109375, acc=0.34166666865348816, loss=1.9970550537109375
train: epoch 33, loss 0.7369042038917542, acc=0.6931666731834412, loss=0.7369042038917542
test: epoch 33, loss 2.0599160194396973, acc=0.35555556416511536, loss=2.0599160194396973
train: epoch 34, loss 0.7671465873718262, acc=0.6806666851043701, loss=0.7671465873718262
test: epoch 34, loss 1.876521348953247, acc=0.3583333194255829, loss=1.876521348953247
train: epoch 35, loss 0.7419342398643494, acc=0.6919999718666077, loss=0.7419342398643494
test: epoch 35, loss 2.054379940032959, acc=0.3638888895511627, loss=2.054379940032959
train: epoch 36, loss 0.7331058979034424, acc=0.6915000081062317, loss=0.7331058979034424
test: epoch 36, loss 1.8074296712875366, acc=0.3611111044883728, loss=1.8074296712875366
train: epoch 37, loss 0.7458180785179138, acc=0.687666654586792, loss=0.7458180785179138
test: epoch 37, loss 1.907901406288147, acc=0.35555556416511536, loss=1.907901406288147
train: epoch 38, loss 0.723452627658844, acc=0.695277750492096, loss=0.723452627658844
test: epoch 38, loss 1.873080849647522, acc=0.36666667461395264, loss=1.873080849647522
train: epoch 39, loss 0.7243303060531616, acc=0.6980555653572083, loss=0.7243303060531616
test: epoch 39, loss 1.834782600402832, acc=0.3638888895511627, loss=1.834782600402832
train: epoch 40, loss 0.7297370433807373, acc=0.6956111192703247, loss=0.7297370433807373
test: epoch 40, loss 2.2272183895111084, acc=0.3444444537162781, loss=2.2272183895111084
train: epoch 41, loss 0.7150617837905884, acc=0.6996666789054871, loss=0.7150617837905884
test: epoch 41, loss 1.8519206047058105, acc=0.3722222149372101, loss=1.8519206047058105
train: epoch 42, loss 0.7428082227706909, acc=0.6929444670677185, loss=0.7428082227706909
test: epoch 42, loss 1.790486216545105, acc=0.36944442987442017, loss=1.790486216545105
train: epoch 43, loss 0.7286301255226135, acc=0.6962777972221375, loss=0.7286301255226135
test: epoch 43, loss 1.8556337356567383, acc=0.36944442987442017, loss=1.8556337356567383
train: epoch 44, loss 0.7179344296455383, acc=0.7006666660308838, loss=0.7179344296455383
test: epoch 44, loss 1.9340378046035767, acc=0.3722222149372101, loss=1.9340378046035767
train: epoch 45, loss 0.7370973229408264, acc=0.6922222375869751, loss=0.7370973229408264
test: epoch 45, loss 1.9168949127197266, acc=0.3472222089767456, loss=1.9168949127197266
train: epoch 46, loss 0.7310476303100586, acc=0.6971666812896729, loss=0.7310476303100586
test: epoch 46, loss 1.916894555091858, acc=0.3722222149372101, loss=1.916894555091858
train: epoch 47, loss 0.7369109392166138, acc=0.690666675567627, loss=0.7369109392166138
test: epoch 47, loss 1.714714765548706, acc=0.3638888895511627, loss=1.714714765548706
train: epoch 48, loss 0.7279430031776428, acc=0.6940555572509766, loss=0.7279430031776428
test: epoch 48, loss 1.6890085935592651, acc=0.36944442987442017, loss=1.6890085935592651
train: epoch 49, loss 0.7125577926635742, acc=0.7044444680213928, loss=0.7125577926635742
test: epoch 49, loss 1.9606218338012695, acc=0.3611111044883728, loss=1.9606218338012695
train: epoch 50, loss 0.7336428761482239, acc=0.6955000162124634, loss=0.7336428761482239
test: epoch 50, loss 1.919103741645813, acc=0.3611111044883728, loss=1.919103741645813
train: epoch 51, loss 0.7362097501754761, acc=0.6927222013473511, loss=0.7362097501754761
test: epoch 51, loss 1.9199327230453491, acc=0.3722222149372101, loss=1.9199327230453491
train: epoch 52, loss 0.7222281098365784, acc=0.6979444622993469, loss=0.7222281098365784
test: epoch 52, loss 1.7513471841812134, acc=0.3722222149372101, loss=1.7513471841812134
train: epoch 53, loss 0.708216667175293, acc=0.703000009059906, loss=0.708216667175293
test: epoch 53, loss 1.7905288934707642, acc=0.36944442987442017, loss=1.7905288934707642
train: epoch 54, loss 0.7317950129508972, acc=0.6926666498184204, loss=0.7317950129508972
test: epoch 54, loss 1.7926028966903687, acc=0.36666667461395264, loss=1.7926028966903687
train: epoch 55, loss 0.7230862975120544, acc=0.6976666450500488, loss=0.7230862975120544
test: epoch 55, loss 1.9797072410583496, acc=0.3722222149372101, loss=1.9797072410583496
train: epoch 56, loss 0.7115655541419983, acc=0.695388913154602, loss=0.7115655541419983
test: epoch 56, loss 1.8144422769546509, acc=0.36666667461395264, loss=1.8144422769546509
train: epoch 57, loss 0.7113312482833862, acc=0.6951666474342346, loss=0.7113312482833862
test: epoch 57, loss 2.1222901344299316, acc=0.3722222149372101, loss=2.1222901344299316
train: epoch 58, loss 0.725902795791626, acc=0.6930000185966492, loss=0.725902795791626
test: epoch 58, loss 1.7078847885131836, acc=0.3638888895511627, loss=1.7078847885131836
train: epoch 59, loss 0.7264035940170288, acc=0.6909999847412109, loss=0.7264035940170288
test: epoch 59, loss 2.02634859085083, acc=0.3611111044883728, loss=2.02634859085083
train: epoch 60, loss 0.7323674559593201, acc=0.6899444460868835, loss=0.7323674559593201
test: epoch 60, loss 1.864284634590149, acc=0.3638888895511627, loss=1.864284634590149
train: epoch 61, loss 0.7116103172302246, acc=0.6928889155387878, loss=0.7116103172302246
test: epoch 61, loss 1.7849063873291016, acc=0.3722222149372101, loss=1.7849063873291016
train: epoch 62, loss 0.7124221324920654, acc=0.6990000009536743, loss=0.7124221324920654
test: epoch 62, loss 1.8311946392059326, acc=0.3916666805744171, loss=1.8311946392059326
train: epoch 63, loss 0.7074074745178223, acc=0.6985555291175842, loss=0.7074074745178223
test: epoch 63, loss 1.9854915142059326, acc=0.36666667461395264, loss=1.9854915142059326
train: epoch 64, loss 0.6951652765274048, acc=0.7023333311080933, loss=0.6951652765274048
test: epoch 64, loss 1.693841576576233, acc=0.3861111104488373, loss=1.693841576576233
train: epoch 65, loss 0.7064908742904663, acc=0.6967222094535828, loss=0.7064908742904663
test: epoch 65, loss 1.8771759271621704, acc=0.3861111104488373, loss=1.8771759271621704
train: epoch 66, loss 0.7019705176353455, acc=0.6991111040115356, loss=0.7019705176353455
test: epoch 66, loss 1.7852375507354736, acc=0.3861111104488373, loss=1.7852375507354736
train: epoch 67, loss 0.7012299299240112, acc=0.7014444470405579, loss=0.7012299299240112
test: epoch 67, loss 1.894723892211914, acc=0.3888888955116272, loss=1.894723892211914
train: epoch 68, loss 0.7147416472434998, acc=0.6966111063957214, loss=0.7147416472434998
test: epoch 68, loss 1.912779450416565, acc=0.38055557012557983, loss=1.912779450416565
train: epoch 69, loss 0.7003568410873413, acc=0.7029444575309753, loss=0.7003568410873413
test: epoch 69, loss 1.7255520820617676, acc=0.3888888955116272, loss=1.7255520820617676
train: epoch 70, loss 0.6812810301780701, acc=0.7079444527626038, loss=0.6812810301780701
test: epoch 70, loss 1.6908332109451294, acc=0.3916666805744171, loss=1.6908332109451294
train: epoch 71, loss 0.6965155005455017, acc=0.7032777667045593, loss=0.6965155005455017
test: epoch 71, loss 1.5427314043045044, acc=0.4027777910232544, loss=1.5427314043045044
train: epoch 72, loss 0.7066450119018555, acc=0.699833333492279, loss=0.7066450119018555
test: epoch 72, loss 1.6903544664382935, acc=0.39722222089767456, loss=1.6903544664382935
train: epoch 73, loss 0.7150883674621582, acc=0.6991666555404663, loss=0.7150883674621582
test: epoch 73, loss 1.6927114725112915, acc=0.39722222089767456, loss=1.6927114725112915
train: epoch 74, loss 0.6822692155838013, acc=0.7098888754844666, loss=0.6822692155838013
test: epoch 74, loss 1.7622337341308594, acc=0.4000000059604645, loss=1.7622337341308594
train: epoch 75, loss 0.6861962080001831, acc=0.7020555734634399, loss=0.6861962080001831
test: epoch 75, loss 1.720354437828064, acc=0.41111111640930176, loss=1.720354437828064
train: epoch 76, loss 0.6851165890693665, acc=0.7060555815696716, loss=0.6851165890693665
test: epoch 76, loss 1.7422465085983276, acc=0.41111111640930176, loss=1.7422465085983276
train: epoch 77, loss 0.6944388151168823, acc=0.7046111226081848, loss=0.6944388151168823
test: epoch 77, loss 1.591927170753479, acc=0.4138889014720917, loss=1.591927170753479
train: epoch 78, loss 0.6830217242240906, acc=0.7114999890327454, loss=0.6830217242240906
test: epoch 78, loss 1.7204850912094116, acc=0.4138889014720917, loss=1.7204850912094116
train: epoch 79, loss 0.6992336511611938, acc=0.7057222127914429, loss=0.6992336511611938
test: epoch 79, loss 1.6891578435897827, acc=0.4055555462837219, loss=1.6891578435897827
train: epoch 80, loss 0.6715652346611023, acc=0.7101666927337646, loss=0.6715652346611023
test: epoch 80, loss 1.9299089908599854, acc=0.4055555462837219, loss=1.9299089908599854
train: epoch 81, loss 0.6922237873077393, acc=0.7057222127914429, loss=0.6922237873077393
test: epoch 81, loss 1.766032099723816, acc=0.41111111640930176, loss=1.766032099723816
train: epoch 82, loss 0.6697701215744019, acc=0.7103333473205566, loss=0.6697701215744019
test: epoch 82, loss 1.7616311311721802, acc=0.40833333134651184, loss=1.7616311311721802
train: epoch 83, loss 0.6750822067260742, acc=0.7090555429458618, loss=0.6750822067260742
test: epoch 83, loss 1.7697328329086304, acc=0.41111111640930176, loss=1.7697328329086304
train: epoch 84, loss 0.6701497435569763, acc=0.710277795791626, loss=0.6701497435569763
test: epoch 84, loss 1.5790314674377441, acc=0.41111111640930176, loss=1.5790314674377441
train: epoch 85, loss 0.6623674631118774, acc=0.7147777676582336, loss=0.6623674631118774
test: epoch 85, loss 1.6796576976776123, acc=0.4138889014720917, loss=1.6796576976776123
train: epoch 86, loss 0.6699590086936951, acc=0.7108888626098633, loss=0.6699590086936951
test: epoch 86, loss 1.795107364654541, acc=0.4138889014720917, loss=1.795107364654541
train: epoch 87, loss 0.6808101534843445, acc=0.7067221999168396, loss=0.6808101534843445
test: epoch 87, loss 1.9723745584487915, acc=0.4138889014720917, loss=1.9723745584487915
train: epoch 88, loss 0.6742967367172241, acc=0.7082777619361877, loss=0.6742967367172241
test: epoch 88, loss 1.799631118774414, acc=0.4138889014720917, loss=1.799631118774414
train: epoch 89, loss 0.6822887063026428, acc=0.7058333158493042, loss=0.6822887063026428
test: epoch 89, loss 1.7023385763168335, acc=0.41111111640930176, loss=1.7023385763168335
train: epoch 90, loss 0.6683240532875061, acc=0.7118333578109741, loss=0.6683240532875061
test: epoch 90, loss 1.6644752025604248, acc=0.4194444417953491, loss=1.6644752025604248
train: epoch 91, loss 0.670733630657196, acc=0.7129444479942322, loss=0.670733630657196
test: epoch 91, loss 1.6278700828552246, acc=0.4138889014720917, loss=1.6278700828552246
train: epoch 92, loss 0.6702628135681152, acc=0.7162777781486511, loss=0.6702628135681152
test: epoch 92, loss 1.847689151763916, acc=0.4166666567325592, loss=1.847689151763916
train: epoch 93, loss 0.6578924059867859, acc=0.7164999842643738, loss=0.6578924059867859
test: epoch 93, loss 1.7030736207962036, acc=0.4166666567325592, loss=1.7030736207962036
train: epoch 94, loss 0.6662922501564026, acc=0.7101666927337646, loss=0.6662922501564026
test: epoch 94, loss 1.7866967916488647, acc=0.4166666567325592, loss=1.7866967916488647
train: epoch 95, loss 0.6781135201454163, acc=0.7098888754844666, loss=0.6781135201454163
test: epoch 95, loss 1.946643590927124, acc=0.4138889014720917, loss=1.946643590927124
train: epoch 96, loss 0.669688880443573, acc=0.7133888602256775, loss=0.669688880443573
test: epoch 96, loss 1.666542410850525, acc=0.4138889014720917, loss=1.666542410850525
train: epoch 97, loss 0.6718904376029968, acc=0.7110000252723694, loss=0.6718904376029968
test: epoch 97, loss 1.7827332019805908, acc=0.4166666567325592, loss=1.7827332019805908
train: epoch 98, loss 0.6691943407058716, acc=0.7096666693687439, loss=0.6691943407058716
test: epoch 98, loss 1.7499020099639893, acc=0.4166666567325592, loss=1.7499020099639893
train: epoch 99, loss 0.6576514840126038, acc=0.714722216129303, loss=0.6576514840126038
test: epoch 99, loss 1.6546180248260498, acc=0.40833333134651184, loss=1.6546180248260498
train: epoch 100, loss 0.6722375750541687, acc=0.7116110920906067, loss=0.6722375750541687
test: epoch 100, loss 1.7104151248931885, acc=0.4194444417953491, loss=1.7104151248931885
train: epoch 101, loss 0.6741966605186462, acc=0.7127777934074402, loss=0.6741966605186462
test: epoch 101, loss 1.7001513242721558, acc=0.41111111640930176, loss=1.7001513242721558
train: epoch 102, loss 0.6605653166770935, acc=0.7174999713897705, loss=0.6605653166770935
test: epoch 102, loss 1.6862342357635498, acc=0.4166666567325592, loss=1.6862342357635498
train: epoch 103, loss 0.6487924456596375, acc=0.7201111316680908, loss=0.6487924456596375
test: epoch 103, loss 1.7883528470993042, acc=0.4166666567325592, loss=1.7883528470993042
train: epoch 104, loss 0.6545897722244263, acc=0.7167778015136719, loss=0.6545897722244263
test: epoch 104, loss 1.7805074453353882, acc=0.4194444417953491, loss=1.7805074453353882
train: epoch 105, loss 0.6497454643249512, acc=0.7216110825538635, loss=0.6497454643249512
test: epoch 105, loss 1.855779767036438, acc=0.4166666567325592, loss=1.855779767036438
train: epoch 106, loss 0.646898627281189, acc=0.7228333353996277, loss=0.646898627281189
test: epoch 106, loss 1.668428897857666, acc=0.4194444417953491, loss=1.668428897857666
train: epoch 107, loss 0.6614094376564026, acc=0.7163888812065125, loss=0.6614094376564026
test: epoch 107, loss 1.830389142036438, acc=0.4166666567325592, loss=1.830389142036438
train: epoch 108, loss 0.6545960307121277, acc=0.7204444408416748, loss=0.6545960307121277
test: epoch 108, loss 1.7843523025512695, acc=0.4166666567325592, loss=1.7843523025512695
train: epoch 109, loss 0.6507019996643066, acc=0.7197222113609314, loss=0.6507019996643066
test: epoch 109, loss 1.6953513622283936, acc=0.4166666567325592, loss=1.6953513622283936
train: epoch 110, loss 0.6514753699302673, acc=0.7212222218513489, loss=0.6514753699302673
test: epoch 110, loss 1.6404802799224854, acc=0.4194444417953491, loss=1.6404802799224854
train: epoch 111, loss 0.6445469856262207, acc=0.719944417476654, loss=0.6445469856262207
test: epoch 111, loss 1.6874154806137085, acc=0.4166666567325592, loss=1.6874154806137085
train: epoch 112, loss 0.6611219048500061, acc=0.7123333215713501, loss=0.6611219048500061
test: epoch 112, loss 1.6928532123565674, acc=0.4194444417953491, loss=1.6928532123565674
train: epoch 113, loss 0.6344538331031799, acc=0.7248333096504211, loss=0.6344538331031799
test: epoch 113, loss 1.6981303691864014, acc=0.4194444417953491, loss=1.6981303691864014
train: epoch 114, loss 0.652950644493103, acc=0.719944417476654, loss=0.652950644493103
test: epoch 114, loss 1.5772383213043213, acc=0.4166666567325592, loss=1.5772383213043213
train: epoch 115, loss 0.6484777927398682, acc=0.7197222113609314, loss=0.6484777927398682
test: epoch 115, loss 1.7425237894058228, acc=0.4194444417953491, loss=1.7425237894058228
train: epoch 116, loss 0.6414110660552979, acc=0.7232778072357178, loss=0.6414110660552979
test: epoch 116, loss 1.6659678220748901, acc=0.4194444417953491, loss=1.6659678220748901
train: epoch 117, loss 0.6476573944091797, acc=0.7208333611488342, loss=0.6476573944091797
test: epoch 117, loss 1.5806585550308228, acc=0.4166666567325592, loss=1.5806585550308228
train: epoch 118, loss 0.6475206017494202, acc=0.7177777886390686, loss=0.6475206017494202
test: epoch 118, loss 1.6596653461456299, acc=0.4194444417953491, loss=1.6596653461456299
train: epoch 119, loss 0.6359899044036865, acc=0.7232778072357178, loss=0.6359899044036865
test: epoch 119, loss 1.8332386016845703, acc=0.4166666567325592, loss=1.8332386016845703
train: epoch 120, loss 0.6372026205062866, acc=0.7212777733802795, loss=0.6372026205062866
test: epoch 120, loss 1.831943154335022, acc=0.4166666567325592, loss=1.831943154335022
train: epoch 121, loss 0.6391773223876953, acc=0.7246111035346985, loss=0.6391773223876953
test: epoch 121, loss 1.6456739902496338, acc=0.4194444417953491, loss=1.6456739902496338
train: epoch 122, loss 0.6406481862068176, acc=0.7232221961021423, loss=0.6406481862068176
test: epoch 122, loss 1.841940999031067, acc=0.4166666567325592, loss=1.841940999031067
train: epoch 123, loss 0.6289559602737427, acc=0.7251111268997192, loss=0.6289559602737427
test: epoch 123, loss 1.8322604894638062, acc=0.40833333134651184, loss=1.8322604894638062
train: epoch 124, loss 0.6268434524536133, acc=0.7287222146987915, loss=0.6268434524536133
test: epoch 124, loss 1.7865334749221802, acc=0.4194444417953491, loss=1.7865334749221802
train: epoch 125, loss 0.6461502909660339, acc=0.7196666598320007, loss=0.6461502909660339
test: epoch 125, loss 1.842613935470581, acc=0.42500001192092896, loss=1.842613935470581
train: epoch 126, loss 0.6350091099739075, acc=0.7239444255828857, loss=0.6350091099739075
test: epoch 126, loss 1.666640281677246, acc=0.42222222685813904, loss=1.666640281677246
train: epoch 127, loss 0.6405190825462341, acc=0.7216110825538635, loss=0.6405190825462341
test: epoch 127, loss 1.8245514631271362, acc=0.4166666567325592, loss=1.8245514631271362
train: epoch 128, loss 0.6345646381378174, acc=0.7256110906600952, loss=0.6345646381378174
test: epoch 128, loss 2.027360677719116, acc=0.3888888955116272, loss=2.027360677719116
train: epoch 129, loss 0.622535765171051, acc=0.7293333411216736, loss=0.622535765171051
test: epoch 129, loss 1.7655060291290283, acc=0.4277777671813965, loss=1.7655060291290283
train: epoch 130, loss 0.6539676785469055, acc=0.7174999713897705, loss=0.6539676785469055
test: epoch 130, loss 1.8277242183685303, acc=0.4277777671813965, loss=1.8277242183685303
train: epoch 131, loss 0.6328250169754028, acc=0.7238333225250244, loss=0.6328250169754028
test: epoch 131, loss 1.8950432538986206, acc=0.43611112236976624, loss=1.8950432538986206
train: epoch 132, loss 0.6458597779273987, acc=0.7206666469573975, loss=0.6458597779273987
test: epoch 132, loss 1.6452821493148804, acc=0.43611112236976624, loss=1.6452821493148804
train: epoch 133, loss 0.63884037733078, acc=0.7276111245155334, loss=0.63884037733078
test: epoch 133, loss 1.7373090982437134, acc=0.43611112236976624, loss=1.7373090982437134
train: epoch 134, loss 0.6320437788963318, acc=0.7260555624961853, loss=0.6320437788963318
test: epoch 134, loss 1.6740370988845825, acc=0.4444444477558136, loss=1.6740370988845825
train: epoch 135, loss 0.6184327006340027, acc=0.7292777895927429, loss=0.6184327006340027
test: epoch 135, loss 1.6190191507339478, acc=0.4416666626930237, loss=1.6190191507339478
train: epoch 136, loss 0.6184074282646179, acc=0.7296666502952576, loss=0.6184074282646179
test: epoch 136, loss 1.6718652248382568, acc=0.4416666626930237, loss=1.6718652248382568
train: epoch 137, loss 0.6400939226150513, acc=0.725777804851532, loss=0.6400939226150513
test: epoch 137, loss 1.51617431640625, acc=0.4444444477558136, loss=1.51617431640625
train: epoch 138, loss 0.6241669058799744, acc=0.7277222275733948, loss=0.6241669058799744
test: epoch 138, loss 1.5774034261703491, acc=0.43611112236976624, loss=1.5774034261703491
train: epoch 139, loss 0.6139826774597168, acc=0.7293333411216736, loss=0.6139826774597168
test: epoch 139, loss 1.591829776763916, acc=0.4416666626930237, loss=1.591829776763916
train: epoch 140, loss 0.6296218037605286, acc=0.7246111035346985, loss=0.6296218037605286
test: epoch 140, loss 1.7072604894638062, acc=0.4472222328186035, loss=1.7072604894638062
train: epoch 141, loss 0.6173699498176575, acc=0.7309444546699524, loss=0.6173699498176575
test: epoch 141, loss 1.785961627960205, acc=0.4444444477558136, loss=1.785961627960205
train: epoch 142, loss 0.6268266439437866, acc=0.7282778024673462, loss=0.6268266439437866
test: epoch 142, loss 1.7031655311584473, acc=0.4472222328186035, loss=1.7031655311584473
train: epoch 143, loss 0.610346794128418, acc=0.7332777976989746, loss=0.610346794128418
test: epoch 143, loss 1.8000245094299316, acc=0.4472222328186035, loss=1.8000245094299316
train: epoch 144, loss 0.6210317611694336, acc=0.7285000085830688, loss=0.6210317611694336
test: epoch 144, loss 1.6951128244400024, acc=0.4472222328186035, loss=1.6951128244400024
train: epoch 145, loss 0.6196430921554565, acc=0.7251666784286499, loss=0.6196430921554565
test: epoch 145, loss 1.7501734495162964, acc=0.4472222328186035, loss=1.7501734495162964
train: epoch 146, loss 0.6207040548324585, acc=0.7267777919769287, loss=0.6207040548324585
test: epoch 146, loss 1.5516332387924194, acc=0.4472222328186035, loss=1.5516332387924194
train: epoch 147, loss 0.6149479150772095, acc=0.7316111326217651, loss=0.6149479150772095
test: epoch 147, loss 1.6811537742614746, acc=0.4444444477558136, loss=1.6811537742614746
train: epoch 148, loss 0.6153014302253723, acc=0.7315555810928345, loss=0.6153014302253723
test: epoch 148, loss 1.5521018505096436, acc=0.4472222328186035, loss=1.5521018505096436
train: epoch 149, loss 0.60759437084198, acc=0.7335000038146973, loss=0.60759437084198
test: epoch 149, loss 1.6699330806732178, acc=0.44999998807907104, loss=1.6699330806732178
train: epoch 150, loss 0.6197304129600525, acc=0.730055570602417, loss=0.6197304129600525
test: epoch 150, loss 1.7640286684036255, acc=0.4472222328186035, loss=1.7640286684036255
