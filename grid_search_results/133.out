# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=0", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=1575050734, receiver_embed_dim=128, save_run=0, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=1575050734, receiver_embed_dim=128, save_run=False, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.5682594776153564, acc=0.13455554842948914, loss=2.5682594776153564
test: epoch 1, loss 3.694627523422241, acc=0.08055555820465088, loss=3.694627523422241
train: epoch 2, loss 2.038707733154297, acc=0.22788888216018677, loss=2.038707733154297
test: epoch 2, loss 3.2482409477233887, acc=0.09166666865348816, loss=3.2482409477233887
train: epoch 3, loss 1.81472909450531, acc=0.2815000116825104, loss=1.81472909450531
test: epoch 3, loss 3.0613296031951904, acc=0.1388888955116272, loss=3.0613296031951904
train: epoch 4, loss 1.6828252077102661, acc=0.31922221183776855, loss=1.6828252077102661
test: epoch 4, loss 2.4869863986968994, acc=0.15555556118488312, loss=2.4869863986968994
train: epoch 5, loss 1.5954875946044922, acc=0.3574444353580475, loss=1.5954875946044922
test: epoch 5, loss 2.722393751144409, acc=0.11944444477558136, loss=2.722393751144409
train: epoch 6, loss 1.4766548871994019, acc=0.39105555415153503, loss=1.4766548871994019
test: epoch 6, loss 3.318636894226074, acc=0.10277777910232544, loss=3.318636894226074
train: epoch 7, loss 1.430067777633667, acc=0.40994444489479065, loss=1.430067777633667
test: epoch 7, loss 2.672913074493408, acc=0.11666666716337204, loss=2.672913074493408
train: epoch 8, loss 1.3720157146453857, acc=0.4350000023841858, loss=1.3720157146453857
test: epoch 8, loss 2.6214935779571533, acc=0.14444445073604584, loss=2.6214935779571533
train: epoch 9, loss 1.326816201210022, acc=0.45261111855506897, loss=1.326816201210022
test: epoch 9, loss 2.655696392059326, acc=0.14444445073604584, loss=2.655696392059326
train: epoch 10, loss 1.2883068323135376, acc=0.47127777338027954, loss=1.2883068323135376
test: epoch 10, loss 2.535156488418579, acc=0.12777778506278992, loss=2.535156488418579
train: epoch 11, loss 1.2615938186645508, acc=0.4847777783870697, loss=1.2615938186645508
test: epoch 11, loss 3.3685531616210938, acc=0.14444445073604584, loss=3.3685531616210938
train: epoch 12, loss 1.2262353897094727, acc=0.5003888607025146, loss=1.2262353897094727
test: epoch 12, loss 2.7252962589263916, acc=0.13055555522441864, loss=2.7252962589263916
train: epoch 13, loss 1.1973451375961304, acc=0.5091111063957214, loss=1.1973451375961304
test: epoch 13, loss 2.6566989421844482, acc=0.17777778208255768, loss=2.6566989421844482
train: epoch 14, loss 1.1582496166229248, acc=0.5212777853012085, loss=1.1582496166229248
test: epoch 14, loss 2.6605887413024902, acc=0.14166666567325592, loss=2.6605887413024902
train: epoch 15, loss 1.1242245435714722, acc=0.5417777895927429, loss=1.1242245435714722
test: epoch 15, loss 2.88680362701416, acc=0.16388888657093048, loss=2.88680362701416
train: epoch 16, loss 1.109568476676941, acc=0.5449444651603699, loss=1.109568476676941
test: epoch 16, loss 3.0631513595581055, acc=0.11944444477558136, loss=3.0631513595581055
train: epoch 17, loss 1.0955137014389038, acc=0.5554444193840027, loss=1.0955137014389038
test: epoch 17, loss 2.5839126110076904, acc=0.17222222685813904, loss=2.5839126110076904
train: epoch 18, loss 1.0499886274337769, acc=0.5753889083862305, loss=1.0499886274337769
test: epoch 18, loss 2.6473453044891357, acc=0.15000000596046448, loss=2.6473453044891357
train: epoch 19, loss 1.0350314378738403, acc=0.5764444470405579, loss=1.0350314378738403
test: epoch 19, loss 3.063987970352173, acc=0.18611110746860504, loss=3.063987970352173
train: epoch 20, loss 1.0317261219024658, acc=0.5826666951179504, loss=1.0317261219024658
test: epoch 20, loss 2.8180220127105713, acc=0.19166666269302368, loss=2.8180220127105713
train: epoch 21, loss 1.0223788022994995, acc=0.5847222208976746, loss=1.0223788022994995
test: epoch 21, loss 3.290468692779541, acc=0.17499999701976776, loss=3.290468692779541
train: epoch 22, loss 1.0039353370666504, acc=0.5927777886390686, loss=1.0039353370666504
test: epoch 22, loss 2.7618865966796875, acc=0.18333333730697632, loss=2.7618865966796875
train: epoch 23, loss 0.9918440580368042, acc=0.5920000076293945, loss=0.9918440580368042
test: epoch 23, loss 2.7368838787078857, acc=0.1666666716337204, loss=2.7368838787078857
train: epoch 24, loss 0.9571951031684875, acc=0.6151111125946045, loss=0.9571951031684875
test: epoch 24, loss 2.9476685523986816, acc=0.19166666269302368, loss=2.9476685523986816
train: epoch 25, loss 0.943339467048645, acc=0.6180555820465088, loss=0.943339467048645
test: epoch 25, loss 2.4666993618011475, acc=0.18333333730697632, loss=2.4666993618011475
train: epoch 26, loss 0.950531542301178, acc=0.6128888726234436, loss=0.950531542301178
test: epoch 26, loss 2.6002604961395264, acc=0.16111111640930176, loss=2.6002604961395264
train: epoch 27, loss 0.9250226020812988, acc=0.6292222142219543, loss=0.9250226020812988
test: epoch 27, loss 2.9146804809570312, acc=0.16111111640930176, loss=2.9146804809570312
train: epoch 28, loss 0.9328258037567139, acc=0.6274444460868835, loss=0.9328258037567139
test: epoch 28, loss 2.950725793838501, acc=0.16388888657093048, loss=2.950725793838501
train: epoch 29, loss 0.9188735485076904, acc=0.6309444308280945, loss=0.9188735485076904
test: epoch 29, loss 2.6714413166046143, acc=0.20277777314186096, loss=2.6714413166046143
train: epoch 30, loss 0.9319248795509338, acc=0.6279444694519043, loss=0.9319248795509338
test: epoch 30, loss 2.912334680557251, acc=0.14722222089767456, loss=2.912334680557251
train: epoch 31, loss 0.9276832342147827, acc=0.6296111345291138, loss=0.9276832342147827
test: epoch 31, loss 2.42220401763916, acc=0.2083333283662796, loss=2.42220401763916
train: epoch 32, loss 0.8957728147506714, acc=0.6401666402816772, loss=0.8957728147506714
test: epoch 32, loss 2.286625862121582, acc=0.24444444477558136, loss=2.286625862121582
train: epoch 33, loss 0.8976048231124878, acc=0.6457777619361877, loss=0.8976048231124878
test: epoch 33, loss 2.4055566787719727, acc=0.1805555522441864, loss=2.4055566787719727
train: epoch 34, loss 0.8957477807998657, acc=0.6467221975326538, loss=0.8957477807998657
test: epoch 34, loss 2.710526943206787, acc=0.1805555522441864, loss=2.710526943206787
train: epoch 35, loss 0.8705877661705017, acc=0.6468333601951599, loss=0.8705877661705017
test: epoch 35, loss 2.6656203269958496, acc=0.18888889253139496, loss=2.6656203269958496
train: epoch 36, loss 0.8662441372871399, acc=0.6566666960716248, loss=0.8662441372871399
test: epoch 36, loss 2.707345724105835, acc=0.20555555820465088, loss=2.707345724105835
train: epoch 37, loss 0.8558573126792908, acc=0.6538888812065125, loss=0.8558573126792908
test: epoch 37, loss 2.4456799030303955, acc=0.18333333730697632, loss=2.4456799030303955
train: epoch 38, loss 0.8486693501472473, acc=0.6619444489479065, loss=0.8486693501472473
test: epoch 38, loss 2.4125282764434814, acc=0.2222222238779068, loss=2.4125282764434814
train: epoch 39, loss 0.8556427955627441, acc=0.6607778072357178, loss=0.8556427955627441
test: epoch 39, loss 2.8184123039245605, acc=0.21388888359069824, loss=2.8184123039245605
train: epoch 40, loss 0.8419457674026489, acc=0.6666111350059509, loss=0.8419457674026489
test: epoch 40, loss 2.7554256916046143, acc=0.24166665971279144, loss=2.7554256916046143
train: epoch 41, loss 0.83831387758255, acc=0.6694999933242798, loss=0.83831387758255
test: epoch 41, loss 2.3302557468414307, acc=0.2222222238779068, loss=2.3302557468414307
train: epoch 42, loss 0.8491657972335815, acc=0.6685555577278137, loss=0.8491657972335815
test: epoch 42, loss 2.599428653717041, acc=0.20555555820465088, loss=2.599428653717041
train: epoch 43, loss 0.8242682218551636, acc=0.6724444627761841, loss=0.8242682218551636
test: epoch 43, loss 2.258255958557129, acc=0.24722221493721008, loss=2.258255958557129
train: epoch 44, loss 0.8253023028373718, acc=0.6737777590751648, loss=0.8253023028373718
test: epoch 44, loss 3.2002296447753906, acc=0.13611111044883728, loss=3.2002296447753906
train: epoch 45, loss 0.8101458549499512, acc=0.6768333315849304, loss=0.8101458549499512
test: epoch 45, loss 2.285595178604126, acc=0.22777777910232544, loss=2.285595178604126
train: epoch 46, loss 0.8099159002304077, acc=0.675000011920929, loss=0.8099159002304077
test: epoch 46, loss 2.0696797370910645, acc=0.24166665971279144, loss=2.0696797370910645
train: epoch 47, loss 0.8279677033424377, acc=0.6735000014305115, loss=0.8279677033424377
test: epoch 47, loss 2.476356029510498, acc=0.20277777314186096, loss=2.476356029510498
train: epoch 48, loss 0.8008843064308167, acc=0.6819444298744202, loss=0.8008843064308167
test: epoch 48, loss 2.517434597015381, acc=0.24166665971279144, loss=2.517434597015381
train: epoch 49, loss 0.8070375323295593, acc=0.6828888654708862, loss=0.8070375323295593
test: epoch 49, loss 2.666166305541992, acc=0.10833333432674408, loss=2.666166305541992
train: epoch 50, loss 0.8155695796012878, acc=0.6783333420753479, loss=0.8155695796012878
test: epoch 50, loss 2.4176082611083984, acc=0.20000000298023224, loss=2.4176082611083984
train: epoch 51, loss 0.7986772060394287, acc=0.6811110973358154, loss=0.7986772060394287
test: epoch 51, loss 2.6278839111328125, acc=0.24722221493721008, loss=2.6278839111328125
train: epoch 52, loss 0.792747974395752, acc=0.6899999976158142, loss=0.792747974395752
test: epoch 52, loss 2.0286452770233154, acc=0.26944443583488464, loss=2.0286452770233154
train: epoch 53, loss 0.7993550896644592, acc=0.6859444379806519, loss=0.7993550896644592
test: epoch 53, loss 2.280543327331543, acc=0.23888888955116272, loss=2.280543327331543
train: epoch 54, loss 0.8034691214561462, acc=0.6834444403648376, loss=0.8034691214561462
test: epoch 54, loss 2.369920253753662, acc=0.20555555820465088, loss=2.369920253753662
train: epoch 55, loss 0.8055412769317627, acc=0.6826111078262329, loss=0.8055412769317627
test: epoch 55, loss 2.5784857273101807, acc=0.20277777314186096, loss=2.5784857273101807
train: epoch 56, loss 0.7985040545463562, acc=0.6831666827201843, loss=0.7985040545463562
test: epoch 56, loss 1.8844060897827148, acc=0.28333333134651184, loss=1.8844060897827148
train: epoch 57, loss 0.8005571961402893, acc=0.6884999871253967, loss=0.8005571961402893
test: epoch 57, loss 2.4079949855804443, acc=0.17222222685813904, loss=2.4079949855804443
train: epoch 58, loss 0.7834566235542297, acc=0.6893888711929321, loss=0.7834566235542297
test: epoch 58, loss 2.2301793098449707, acc=0.24722221493721008, loss=2.2301793098449707
train: epoch 59, loss 0.7856744527816772, acc=0.6887221932411194, loss=0.7856744527816772
test: epoch 59, loss 2.022312879562378, acc=0.23888888955116272, loss=2.022312879562378
train: epoch 60, loss 0.7755010724067688, acc=0.6899444460868835, loss=0.7755010724067688
test: epoch 60, loss 1.8150871992111206, acc=0.32777777314186096, loss=1.8150871992111206
train: epoch 61, loss 0.7718139886856079, acc=0.6956111192703247, loss=0.7718139886856079
test: epoch 61, loss 2.139857769012451, acc=0.21111111342906952, loss=2.139857769012451
train: epoch 62, loss 0.7703779935836792, acc=0.6982777714729309, loss=0.7703779935836792
test: epoch 62, loss 2.243591785430908, acc=0.24166665971279144, loss=2.243591785430908
train: epoch 63, loss 0.8034688830375671, acc=0.6892777681350708, loss=0.8034688830375671
test: epoch 63, loss 1.8923929929733276, acc=0.28611111640930176, loss=1.8923929929733276
train: epoch 64, loss 0.7719103097915649, acc=0.6977221965789795, loss=0.7719103097915649
test: epoch 64, loss 1.762176513671875, acc=0.3305555582046509, loss=1.762176513671875
train: epoch 65, loss 0.7650442719459534, acc=0.6940555572509766, loss=0.7650442719459534
test: epoch 65, loss 2.2196156978607178, acc=0.2638888955116272, loss=2.2196156978607178
train: epoch 66, loss 0.7462402582168579, acc=0.7099999785423279, loss=0.7462402582168579
test: epoch 66, loss 1.724769115447998, acc=0.3222222328186035, loss=1.724769115447998
train: epoch 67, loss 0.7437121272087097, acc=0.7052778005599976, loss=0.7437121272087097
test: epoch 67, loss 2.230808973312378, acc=0.23888888955116272, loss=2.230808973312378
train: epoch 68, loss 0.7625797390937805, acc=0.70333331823349, loss=0.7625797390937805
test: epoch 68, loss 2.093932867050171, acc=0.3361110985279083, loss=2.093932867050171
train: epoch 69, loss 0.7399093508720398, acc=0.707611083984375, loss=0.7399093508720398
test: epoch 69, loss 1.9590661525726318, acc=0.23333333432674408, loss=1.9590661525726318
train: epoch 70, loss 0.7671542167663574, acc=0.6984444260597229, loss=0.7671542167663574
test: epoch 70, loss 1.9956543445587158, acc=0.28333333134651184, loss=1.9956543445587158
train: epoch 71, loss 0.7477551698684692, acc=0.7025555372238159, loss=0.7477551698684692
test: epoch 71, loss 2.1709372997283936, acc=0.28333333134651184, loss=2.1709372997283936
train: epoch 72, loss 0.7262974381446838, acc=0.7103888988494873, loss=0.7262974381446838
test: epoch 72, loss 1.9473474025726318, acc=0.3499999940395355, loss=1.9473474025726318
train: epoch 73, loss 0.7270957827568054, acc=0.7098888754844666, loss=0.7270957827568054
test: epoch 73, loss 2.574582576751709, acc=0.3444444537162781, loss=2.574582576751709
train: epoch 74, loss 0.7439886927604675, acc=0.706944465637207, loss=0.7439886927604675
test: epoch 74, loss 2.183091878890991, acc=0.375, loss=2.183091878890991
train: epoch 75, loss 0.718721866607666, acc=0.7176111340522766, loss=0.718721866607666
test: epoch 75, loss 2.2938897609710693, acc=0.3194444477558136, loss=2.2938897609710693
train: epoch 76, loss 0.735825777053833, acc=0.7125555276870728, loss=0.735825777053833
test: epoch 76, loss 1.887071132659912, acc=0.32777777314186096, loss=1.887071132659912
train: epoch 77, loss 0.7090847492218018, acc=0.7203333377838135, loss=0.7090847492218018
test: epoch 77, loss 1.5399553775787354, acc=0.3888888955116272, loss=1.5399553775787354
train: epoch 78, loss 0.7304813265800476, acc=0.7088333368301392, loss=0.7304813265800476
test: epoch 78, loss 2.196410894393921, acc=0.35555556416511536, loss=2.196410894393921
train: epoch 79, loss 0.7249819040298462, acc=0.7087777853012085, loss=0.7249819040298462
test: epoch 79, loss 1.8826429843902588, acc=0.33888888359069824, loss=1.8826429843902588
train: epoch 80, loss 0.7180694937705994, acc=0.714888870716095, loss=0.7180694937705994
test: epoch 80, loss 1.8595491647720337, acc=0.36666667461395264, loss=1.8595491647720337
train: epoch 81, loss 0.6970643997192383, acc=0.7288888692855835, loss=0.6970643997192383
test: epoch 81, loss 2.223248243331909, acc=0.35555556416511536, loss=2.223248243331909
train: epoch 82, loss 0.6981038451194763, acc=0.7248888611793518, loss=0.6981038451194763
test: epoch 82, loss 1.7082550525665283, acc=0.35277777910232544, loss=1.7082550525665283
train: epoch 83, loss 0.7215113639831543, acc=0.7153333425521851, loss=0.7215113639831543
test: epoch 83, loss 1.9341373443603516, acc=0.31388887763023376, loss=1.9341373443603516
train: epoch 84, loss 0.7105107307434082, acc=0.7151111364364624, loss=0.7105107307434082
test: epoch 84, loss 1.7313929796218872, acc=0.3222222328186035, loss=1.7313929796218872
train: epoch 85, loss 0.6907250285148621, acc=0.7265555262565613, loss=0.6907250285148621
test: epoch 85, loss 2.1087381839752197, acc=0.3472222089767456, loss=2.1087381839752197
train: epoch 86, loss 0.6829252243041992, acc=0.7246111035346985, loss=0.6829252243041992
test: epoch 86, loss 2.1946167945861816, acc=0.31111112236976624, loss=2.1946167945861816
train: epoch 87, loss 0.6944712996482849, acc=0.7262222170829773, loss=0.6944712996482849
test: epoch 87, loss 2.042020797729492, acc=0.3583333194255829, loss=2.042020797729492
train: epoch 88, loss 0.6722369194030762, acc=0.7361111044883728, loss=0.6722369194030762
test: epoch 88, loss 2.1883647441864014, acc=0.3305555582046509, loss=2.1883647441864014
train: epoch 89, loss 0.6806238293647766, acc=0.7313888669013977, loss=0.6806238293647766
test: epoch 89, loss 1.9809640645980835, acc=0.3222222328186035, loss=1.9809640645980835
train: epoch 90, loss 0.7037484049797058, acc=0.7201666831970215, loss=0.7037484049797058
test: epoch 90, loss 1.9951937198638916, acc=0.2916666567325592, loss=1.9951937198638916
train: epoch 91, loss 0.6875444650650024, acc=0.7311111092567444, loss=0.6875444650650024
test: epoch 91, loss 1.799013614654541, acc=0.34166666865348816, loss=1.799013614654541
train: epoch 92, loss 0.6736125349998474, acc=0.7316666841506958, loss=0.6736125349998474
test: epoch 92, loss 2.214553117752075, acc=0.3194444477558136, loss=2.214553117752075
train: epoch 93, loss 0.6836734414100647, acc=0.7280555367469788, loss=0.6836734414100647
test: epoch 93, loss 2.264613151550293, acc=0.3055555522441864, loss=2.264613151550293
train: epoch 94, loss 0.6767027378082275, acc=0.733222246170044, loss=0.6767027378082275
test: epoch 94, loss 1.9508545398712158, acc=0.39722222089767456, loss=1.9508545398712158
train: epoch 95, loss 0.6939646005630493, acc=0.7248888611793518, loss=0.6939646005630493
test: epoch 95, loss 1.6956894397735596, acc=0.36944442987442017, loss=1.6956894397735596
train: epoch 96, loss 0.6778108477592468, acc=0.7336666584014893, loss=0.6778108477592468
test: epoch 96, loss 1.9786854982376099, acc=0.35277777910232544, loss=1.9786854982376099
train: epoch 97, loss 0.6719346642494202, acc=0.7381666898727417, loss=0.6719346642494202
test: epoch 97, loss 1.7103418111801147, acc=0.42500001192092896, loss=1.7103418111801147
train: epoch 98, loss 0.6497835516929626, acc=0.7436666488647461, loss=0.6497835516929626
test: epoch 98, loss 1.8280723094940186, acc=0.3361110985279083, loss=1.8280723094940186
train: epoch 99, loss 0.6716933250427246, acc=0.7400555610656738, loss=0.6716933250427246
test: epoch 99, loss 1.8149687051773071, acc=0.38333332538604736, loss=1.8149687051773071
train: epoch 100, loss 0.6649481654167175, acc=0.7402777671813965, loss=0.6649481654167175
test: epoch 100, loss 1.7970788478851318, acc=0.36944442987442017, loss=1.7970788478851318
train: epoch 101, loss 0.6599534749984741, acc=0.7379444241523743, loss=0.6599534749984741
test: epoch 101, loss 1.6495029926300049, acc=0.4333333373069763, loss=1.6495029926300049
train: epoch 102, loss 0.6620714068412781, acc=0.7362777590751648, loss=0.6620714068412781
test: epoch 102, loss 2.0054004192352295, acc=0.36944442987442017, loss=2.0054004192352295
train: epoch 103, loss 0.6569962501525879, acc=0.7432777881622314, loss=0.6569962501525879
test: epoch 103, loss 1.8958876132965088, acc=0.38055557012557983, loss=1.8958876132965088
train: epoch 104, loss 0.6545898914337158, acc=0.7432777881622314, loss=0.6545898914337158
test: epoch 104, loss 2.005558490753174, acc=0.3305555582046509, loss=2.005558490753174
train: epoch 105, loss 0.6566258072853088, acc=0.7398333549499512, loss=0.6566258072853088
test: epoch 105, loss 1.5317904949188232, acc=0.36944442987442017, loss=1.5317904949188232
train: epoch 106, loss 0.6737017035484314, acc=0.7336111068725586, loss=0.6737017035484314
test: epoch 106, loss 2.076967477798462, acc=0.38055557012557983, loss=2.076967477798462
train: epoch 107, loss 0.6620166897773743, acc=0.7361111044883728, loss=0.6620166897773743
test: epoch 107, loss 1.7252516746520996, acc=0.3861111104488373, loss=1.7252516746520996
train: epoch 108, loss 0.664739191532135, acc=0.7349444627761841, loss=0.664739191532135
test: epoch 108, loss 2.0753369331359863, acc=0.36944442987442017, loss=2.0753369331359863
train: epoch 109, loss 0.6585391163825989, acc=0.7372778058052063, loss=0.6585391163825989
test: epoch 109, loss 1.8500549793243408, acc=0.3583333194255829, loss=1.8500549793243408
train: epoch 110, loss 0.6596547961235046, acc=0.742555558681488, loss=0.6596547961235046
test: epoch 110, loss 1.5014278888702393, acc=0.3611111044883728, loss=1.5014278888702393
train: epoch 111, loss 0.6733917593955994, acc=0.7363888621330261, loss=0.6733917593955994
test: epoch 111, loss 1.8364288806915283, acc=0.31111112236976624, loss=1.8364288806915283
train: epoch 112, loss 0.6548447012901306, acc=0.7444444298744202, loss=0.6548447012901306
test: epoch 112, loss 1.6958242654800415, acc=0.4277777671813965, loss=1.6958242654800415
train: epoch 113, loss 0.646183431148529, acc=0.746833324432373, loss=0.646183431148529
test: epoch 113, loss 1.9145538806915283, acc=0.3611111044883728, loss=1.9145538806915283
train: epoch 114, loss 0.652657687664032, acc=0.741777777671814, loss=0.652657687664032
test: epoch 114, loss 1.8792599439620972, acc=0.2527777850627899, loss=1.8792599439620972
train: epoch 115, loss 0.6607796549797058, acc=0.7366111278533936, loss=0.6607796549797058
test: epoch 115, loss 1.6801033020019531, acc=0.4611110985279083, loss=1.6801033020019531
train: epoch 116, loss 0.6436894536018372, acc=0.7448333501815796, loss=0.6436894536018372
test: epoch 116, loss 1.5330467224121094, acc=0.41111111640930176, loss=1.5330467224121094
train: epoch 117, loss 0.6457070112228394, acc=0.7457777857780457, loss=0.6457070112228394
test: epoch 117, loss 1.7613359689712524, acc=0.3583333194255829, loss=1.7613359689712524
train: epoch 118, loss 0.6585081815719604, acc=0.737333357334137, loss=0.6585081815719604
test: epoch 118, loss 1.421370506286621, acc=0.4277777671813965, loss=1.421370506286621
train: epoch 119, loss 0.6546412110328674, acc=0.7412222027778625, loss=0.6546412110328674
test: epoch 119, loss 1.7022066116333008, acc=0.42500001192092896, loss=1.7022066116333008
train: epoch 120, loss 0.6551650166511536, acc=0.7376111149787903, loss=0.6551650166511536
test: epoch 120, loss 1.6117945909500122, acc=0.3472222089767456, loss=1.6117945909500122
train: epoch 121, loss 0.6391293406486511, acc=0.745555579662323, loss=0.6391293406486511
test: epoch 121, loss 1.4691972732543945, acc=0.3444444537162781, loss=1.4691972732543945
train: epoch 122, loss 0.6335639953613281, acc=0.7480000257492065, loss=0.6335639953613281
test: epoch 122, loss 1.478650450706482, acc=0.4861111044883728, loss=1.478650450706482
train: epoch 123, loss 0.6536091566085815, acc=0.7403888702392578, loss=0.6536091566085815
test: epoch 123, loss 1.450404405593872, acc=0.4333333373069763, loss=1.450404405593872
train: epoch 124, loss 0.641562283039093, acc=0.7463333606719971, loss=0.641562283039093
test: epoch 124, loss 1.5144758224487305, acc=0.42500001192092896, loss=1.5144758224487305
train: epoch 125, loss 0.6392300128936768, acc=0.7497777938842773, loss=0.6392300128936768
test: epoch 125, loss 1.4640237092971802, acc=0.41111111640930176, loss=1.4640237092971802
train: epoch 126, loss 0.6470199227333069, acc=0.7418888807296753, loss=0.6470199227333069
test: epoch 126, loss 2.2643773555755615, acc=0.3333333432674408, loss=2.2643773555755615
train: epoch 127, loss 0.6508123278617859, acc=0.7448889017105103, loss=0.6508123278617859
test: epoch 127, loss 1.499469518661499, acc=0.4611110985279083, loss=1.499469518661499
train: epoch 128, loss 0.6624963879585266, acc=0.7379999756813049, loss=0.6624963879585266
test: epoch 128, loss 1.3339091539382935, acc=0.4861111044883728, loss=1.3339091539382935
train: epoch 129, loss 0.6440118551254272, acc=0.7464444637298584, loss=0.6440118551254272
test: epoch 129, loss 1.6506158113479614, acc=0.35555556416511536, loss=1.6506158113479614
train: epoch 130, loss 0.6300029158592224, acc=0.7523333430290222, loss=0.6300029158592224
test: epoch 130, loss 1.5587024688720703, acc=0.3611111044883728, loss=1.5587024688720703
train: epoch 131, loss 0.6381140947341919, acc=0.749833345413208, loss=0.6381140947341919
test: epoch 131, loss 1.6282539367675781, acc=0.43888887763023376, loss=1.6282539367675781
train: epoch 132, loss 0.6524502038955688, acc=0.7451666593551636, loss=0.6524502038955688
test: epoch 132, loss 1.797739028930664, acc=0.3638888895511627, loss=1.797739028930664
train: epoch 133, loss 0.6500660181045532, acc=0.737333357334137, loss=0.6500660181045532
test: epoch 133, loss 1.7956149578094482, acc=0.4027777910232544, loss=1.7956149578094482
train: epoch 134, loss 0.6557334661483765, acc=0.7363888621330261, loss=0.6557334661483765
test: epoch 134, loss 1.4404757022857666, acc=0.44999998807907104, loss=1.4404757022857666
train: epoch 135, loss 0.6554823517799377, acc=0.738444447517395, loss=0.6554823517799377
test: epoch 135, loss 1.4146013259887695, acc=0.4444444477558136, loss=1.4146013259887695
train: epoch 136, loss 0.6375420093536377, acc=0.7467777729034424, loss=0.6375420093536377
test: epoch 136, loss 1.3575609922409058, acc=0.43888887763023376, loss=1.3575609922409058
train: epoch 137, loss 0.6661767959594727, acc=0.7377222180366516, loss=0.6661767959594727
test: epoch 137, loss 2.0108399391174316, acc=0.3888888955116272, loss=2.0108399391174316
train: epoch 138, loss 0.6325858235359192, acc=0.7495555281639099, loss=0.6325858235359192
test: epoch 138, loss 1.5085405111312866, acc=0.4055555462837219, loss=1.5085405111312866
train: epoch 139, loss 0.6613289713859558, acc=0.7376111149787903, loss=0.6613289713859558
test: epoch 139, loss 1.5169219970703125, acc=0.3861111104488373, loss=1.5169219970703125
train: epoch 140, loss 0.645156741142273, acc=0.7426666617393494, loss=0.645156741142273
test: epoch 140, loss 1.416648268699646, acc=0.4027777910232544, loss=1.416648268699646
train: epoch 141, loss 0.6581562757492065, acc=0.7366111278533936, loss=0.6581562757492065
test: epoch 141, loss 1.5092309713363647, acc=0.43888887763023376, loss=1.5092309713363647
train: epoch 142, loss 0.6513367295265198, acc=0.7439444661140442, loss=0.6513367295265198
test: epoch 142, loss 1.5888116359710693, acc=0.39722222089767456, loss=1.5888116359710693
train: epoch 143, loss 0.649581789970398, acc=0.7466111183166504, loss=0.649581789970398
test: epoch 143, loss 1.3258671760559082, acc=0.4722222089767456, loss=1.3258671760559082
train: epoch 144, loss 0.634736180305481, acc=0.7448889017105103, loss=0.634736180305481
test: epoch 144, loss 1.4272288084030151, acc=0.4472222328186035, loss=1.4272288084030151
train: epoch 145, loss 0.6359602212905884, acc=0.7463889122009277, loss=0.6359602212905884
test: epoch 145, loss 1.282204508781433, acc=0.48055556416511536, loss=1.282204508781433
train: epoch 146, loss 0.6332674026489258, acc=0.7470555305480957, loss=0.6332674026489258
test: epoch 146, loss 1.3985610008239746, acc=0.4277777671813965, loss=1.3985610008239746
train: epoch 147, loss 0.6341827511787415, acc=0.7453333139419556, loss=0.6341827511787415
test: epoch 147, loss 1.596719741821289, acc=0.4749999940395355, loss=1.596719741821289
train: epoch 148, loss 0.6433255076408386, acc=0.7419999837875366, loss=0.6433255076408386
test: epoch 148, loss 1.3862695693969727, acc=0.4555555582046509, loss=1.3862695693969727
train: epoch 149, loss 0.6186522245407104, acc=0.7509999871253967, loss=0.6186522245407104
test: epoch 149, loss 1.3801542520523071, acc=0.4000000059604645, loss=1.3801542520523071
train: epoch 150, loss 0.6426759958267212, acc=0.7437777519226074, loss=0.6426759958267212
test: epoch 150, loss 1.2383414506912231, acc=0.4694444537162781, loss=1.2383414506912231
