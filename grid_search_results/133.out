# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=true", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=415912898, receiver_embed_dim=128, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.8104777336120605, acc=0.10188888758420944, loss=2.8104777336120605
test: epoch 1, loss 3.054065704345703, acc=0.15000000596046448, loss=3.054065704345703
train: epoch 2, loss 1.6291296482086182, acc=0.35988888144493103, loss=1.6291296482086182
test: epoch 2, loss 2.312972068786621, acc=0.24722221493721008, loss=2.312972068786621
train: epoch 3, loss 1.1099190711975098, acc=0.5508888959884644, loss=1.1099190711975098
test: epoch 3, loss 2.4687507152557373, acc=0.2805555462837219, loss=2.4687507152557373
train: epoch 4, loss 0.8574831485748291, acc=0.6496666669845581, loss=0.8574831485748291
test: epoch 4, loss 1.8839892148971558, acc=0.35277777910232544, loss=1.8839892148971558
train: epoch 5, loss 0.7155866622924805, acc=0.7103333473205566, loss=0.7155866622924805
test: epoch 5, loss 1.538206696510315, acc=0.3861111104488373, loss=1.538206696510315
train: epoch 6, loss 0.6158221364021301, acc=0.7512778043746948, loss=0.6158221364021301
test: epoch 6, loss 1.7413556575775146, acc=0.4000000059604645, loss=1.7413556575775146
train: epoch 7, loss 0.5517653822898865, acc=0.7802777886390686, loss=0.5517653822898865
test: epoch 7, loss 1.8539938926696777, acc=0.4277777671813965, loss=1.8539938926696777
train: epoch 8, loss 0.49339064955711365, acc=0.8059999942779541, loss=0.49339064955711365
test: epoch 8, loss 1.5304070711135864, acc=0.4027777910232544, loss=1.5304070711135864
train: epoch 9, loss 0.46376511454582214, acc=0.8196666836738586, loss=0.46376511454582214
test: epoch 9, loss 1.5885006189346313, acc=0.46388888359069824, loss=1.5885006189346313
train: epoch 10, loss 0.425525963306427, acc=0.8330555558204651, loss=0.425525963306427
test: epoch 10, loss 1.3889299631118774, acc=0.5527777671813965, loss=1.3889299631118774
train: epoch 11, loss 0.37726685404777527, acc=0.8523889183998108, loss=0.37726685404777527
test: epoch 11, loss 1.509716510772705, acc=0.5138888955116272, loss=1.509716510772705
train: epoch 12, loss 0.3724338710308075, acc=0.8523333072662354, loss=0.3724338710308075
test: epoch 12, loss 1.384141445159912, acc=0.5249999761581421, loss=1.384141445159912
train: epoch 13, loss 0.35410112142562866, acc=0.8607222437858582, loss=0.35410112142562866
test: epoch 13, loss 1.5704851150512695, acc=0.4722222089767456, loss=1.5704851150512695
train: epoch 14, loss 0.3425074517726898, acc=0.8656666874885559, loss=0.3425074517726898
test: epoch 14, loss 1.3346198797225952, acc=0.5222222208976746, loss=1.3346198797225952
train: epoch 15, loss 0.32958996295928955, acc=0.8715555667877197, loss=0.32958996295928955
test: epoch 15, loss 1.491958498954773, acc=0.5083333253860474, loss=1.491958498954773
train: epoch 16, loss 0.32583820819854736, acc=0.8737778067588806, loss=0.32583820819854736
test: epoch 16, loss 1.254561424255371, acc=0.5138888955116272, loss=1.254561424255371
train: epoch 17, loss 0.30568280816078186, acc=0.878166675567627, loss=0.30568280816078186
test: epoch 17, loss 1.386413812637329, acc=0.5388888716697693, loss=1.386413812637329
train: epoch 18, loss 0.300528883934021, acc=0.8842222094535828, loss=0.300528883934021
test: epoch 18, loss 1.3159412145614624, acc=0.5666666626930237, loss=1.3159412145614624
train: epoch 19, loss 0.28643766045570374, acc=0.8891666531562805, loss=0.28643766045570374
test: epoch 19, loss 1.3847028017044067, acc=0.5472221970558167, loss=1.3847028017044067
train: epoch 20, loss 0.2671234905719757, acc=0.8964444398880005, loss=0.2671234905719757
test: epoch 20, loss 1.4939641952514648, acc=0.5611110925674438, loss=1.4939641952514648
train: epoch 21, loss 0.25778090953826904, acc=0.8987777829170227, loss=0.25778090953826904
test: epoch 21, loss 1.4148166179656982, acc=0.5694444179534912, loss=1.4148166179656982
train: epoch 22, loss 0.24431641399860382, acc=0.9032222032546997, loss=0.24431641399860382
test: epoch 22, loss 1.339438796043396, acc=0.5916666388511658, loss=1.339438796043396
train: epoch 23, loss 0.23384802043437958, acc=0.9076666831970215, loss=0.23384802043437958
test: epoch 23, loss 1.2291669845581055, acc=0.6333333253860474, loss=1.2291669845581055
train: epoch 24, loss 0.23027269542217255, acc=0.9082777500152588, loss=0.23027269542217255
test: epoch 24, loss 1.424737811088562, acc=0.6083333492279053, loss=1.424737811088562
train: epoch 25, loss 0.23620544373989105, acc=0.9083333611488342, loss=0.23620544373989105
test: epoch 25, loss 0.7319061160087585, acc=0.7277777791023254, loss=0.7319061160087585
train: epoch 26, loss 0.21851810812950134, acc=0.9133889079093933, loss=0.21851810812950134
test: epoch 26, loss 1.0973737239837646, acc=0.6888889074325562, loss=1.0973737239837646
train: epoch 27, loss 0.20279090106487274, acc=0.9176666736602783, loss=0.20279090106487274
test: epoch 27, loss 0.892690896987915, acc=0.7166666388511658, loss=0.892690896987915
train: epoch 28, loss 0.20724335312843323, acc=0.9156110882759094, loss=0.20724335312843323
test: epoch 28, loss 0.9145212173461914, acc=0.730555534362793, loss=0.9145212173461914
train: epoch 29, loss 0.19704881310462952, acc=0.9207777976989746, loss=0.19704881310462952
test: epoch 29, loss 0.9599713683128357, acc=0.730555534362793, loss=0.9599713683128357
train: epoch 30, loss 0.2020362913608551, acc=0.9193333387374878, loss=0.2020362913608551
test: epoch 30, loss 0.6413732767105103, acc=0.7777777910232544, loss=0.6413732767105103
train: epoch 31, loss 0.19357365369796753, acc=0.9195555448532104, loss=0.19357365369796753
test: epoch 31, loss 0.7163296341896057, acc=0.7722222208976746, loss=0.7163296341896057
train: epoch 32, loss 0.18442200124263763, acc=0.9242777824401855, loss=0.18442200124263763
test: epoch 32, loss 0.6575517654418945, acc=0.8083333373069763, loss=0.6575517654418945
train: epoch 33, loss 0.17651870846748352, acc=0.9271666407585144, loss=0.17651870846748352
test: epoch 33, loss 0.7759023308753967, acc=0.8083333373069763, loss=0.7759023308753967
train: epoch 34, loss 0.18322071433067322, acc=0.9266666769981384, loss=0.18322071433067322
test: epoch 34, loss 0.6662589311599731, acc=0.8194444179534912, loss=0.6662589311599731
train: epoch 35, loss 0.1729043573141098, acc=0.9297778010368347, loss=0.1729043573141098
test: epoch 35, loss 0.5856212377548218, acc=0.824999988079071, loss=0.5856212377548218
train: epoch 36, loss 0.1613217145204544, acc=0.9340555667877197, loss=0.1613217145204544
test: epoch 36, loss 0.662207305431366, acc=0.8361111283302307, loss=0.662207305431366
train: epoch 37, loss 0.16362398862838745, acc=0.929722249507904, loss=0.16362398862838745
test: epoch 37, loss 0.4990304112434387, acc=0.8388888835906982, loss=0.4990304112434387
train: epoch 38, loss 0.15816472470760345, acc=0.9332777857780457, loss=0.15816472470760345
test: epoch 38, loss 0.40429893136024475, acc=0.8361111283302307, loss=0.40429893136024475
train: epoch 39, loss 0.14854204654693604, acc=0.9373888969421387, loss=0.14854204654693604
test: epoch 39, loss 0.5810279846191406, acc=0.8416666388511658, loss=0.5810279846191406
train: epoch 40, loss 0.14914028346538544, acc=0.9377222061157227, loss=0.14914028346538544
test: epoch 40, loss 0.5751004219055176, acc=0.8444444537162781, loss=0.5751004219055176
train: epoch 41, loss 0.15159742534160614, acc=0.934333324432373, loss=0.15159742534160614
test: epoch 41, loss 0.5294426679611206, acc=0.8333333134651184, loss=0.5294426679611206
train: epoch 42, loss 0.13719843327999115, acc=0.9431111216545105, loss=0.13719843327999115
test: epoch 42, loss 0.5577623248100281, acc=0.8388888835906982, loss=0.5577623248100281
train: epoch 43, loss 0.1510878950357437, acc=0.9384999871253967, loss=0.1510878950357437
test: epoch 43, loss 0.5342613458633423, acc=0.8472222089767456, loss=0.5342613458633423
train: epoch 44, loss 0.1455085277557373, acc=0.9380555748939514, loss=0.1455085277557373
test: epoch 44, loss 0.5376479029655457, acc=0.8472222089767456, loss=0.5376479029655457
train: epoch 45, loss 0.15303610265254974, acc=0.9375555515289307, loss=0.15303610265254974
test: epoch 45, loss 0.519316554069519, acc=0.8416666388511658, loss=0.519316554069519
train: epoch 46, loss 0.14097630977630615, acc=0.9412222504615784, loss=0.14097630977630615
test: epoch 46, loss 0.5994123816490173, acc=0.8305555582046509, loss=0.5994123816490173
train: epoch 47, loss 0.1334906816482544, acc=0.9426110982894897, loss=0.1334906816482544
test: epoch 47, loss 0.4708077907562256, acc=0.8444444537162781, loss=0.4708077907562256
train: epoch 48, loss 0.13720163702964783, acc=0.9413333535194397, loss=0.13720163702964783
test: epoch 48, loss 0.5342347621917725, acc=0.8472222089767456, loss=0.5342347621917725
train: epoch 49, loss 0.13470754027366638, acc=0.9427222013473511, loss=0.13470754027366638
test: epoch 49, loss 0.5496038198471069, acc=0.8388888835906982, loss=0.5496038198471069
train: epoch 50, loss 0.13084563612937927, acc=0.9436110854148865, loss=0.13084563612937927
test: epoch 50, loss 0.662446141242981, acc=0.8472222089767456, loss=0.662446141242981
train: epoch 51, loss 0.13370278477668762, acc=0.9424444437026978, loss=0.13370278477668762
test: epoch 51, loss 0.5621670484542847, acc=0.8472222089767456, loss=0.5621670484542847
train: epoch 52, loss 0.13330042362213135, acc=0.9441666603088379, loss=0.13330042362213135
test: epoch 52, loss 0.4854747951030731, acc=0.8472222089767456, loss=0.4854747951030731
train: epoch 53, loss 0.13747577369213104, acc=0.9427777528762817, loss=0.13747577369213104
test: epoch 53, loss 0.6381257176399231, acc=0.8333333134651184, loss=0.6381257176399231
train: epoch 54, loss 0.15602752566337585, acc=0.9367222189903259, loss=0.15602752566337585
test: epoch 54, loss 0.5469643473625183, acc=0.8472222089767456, loss=0.5469643473625183
train: epoch 55, loss 0.12825746834278107, acc=0.9443888664245605, loss=0.12825746834278107
test: epoch 55, loss 0.5380891561508179, acc=0.8472222089767456, loss=0.5380891561508179
train: epoch 56, loss 0.13886526226997375, acc=0.9428889155387878, loss=0.13886526226997375
test: epoch 56, loss 0.4307871460914612, acc=0.8472222089767456, loss=0.4307871460914612
train: epoch 57, loss 0.1279831975698471, acc=0.9427222013473511, loss=0.1279831975698471
test: epoch 57, loss 0.35678356885910034, acc=0.8472222089767456, loss=0.35678356885910034
train: epoch 58, loss 0.12179472297430038, acc=0.9472222328186035, loss=0.12179472297430038
test: epoch 58, loss 0.4905407428741455, acc=0.8472222089767456, loss=0.4905407428741455
train: epoch 59, loss 0.1369960904121399, acc=0.945555567741394, loss=0.1369960904121399
test: epoch 59, loss 0.5509419441223145, acc=0.8472222089767456, loss=0.5509419441223145
train: epoch 60, loss 0.12770043313503265, acc=0.9448888897895813, loss=0.12770043313503265
test: epoch 60, loss 0.5213992595672607, acc=0.8472222089767456, loss=0.5213992595672607
train: epoch 61, loss 0.13228295743465424, acc=0.9434444308280945, loss=0.13228295743465424
test: epoch 61, loss 0.5315130352973938, acc=0.8444444537162781, loss=0.5315130352973938
train: epoch 62, loss 0.14163647592067719, acc=0.9419999718666077, loss=0.14163647592067719
test: epoch 62, loss 0.5011124610900879, acc=0.8472222089767456, loss=0.5011124610900879
train: epoch 63, loss 0.1235562339425087, acc=0.945555567741394, loss=0.1235562339425087
test: epoch 63, loss 0.4582936763763428, acc=0.8472222089767456, loss=0.4582936763763428
train: epoch 64, loss 0.13003595173358917, acc=0.9449999928474426, loss=0.13003595173358917
test: epoch 64, loss 0.575003981590271, acc=0.8472222089767456, loss=0.575003981590271
train: epoch 65, loss 0.1407165825366974, acc=0.9416666626930237, loss=0.1407165825366974
test: epoch 65, loss 0.42119815945625305, acc=0.8472222089767456, loss=0.42119815945625305
train: epoch 66, loss 0.12080071866512299, acc=0.94605553150177, loss=0.12080071866512299
test: epoch 66, loss 0.4853041172027588, acc=0.8472222089767456, loss=0.4853041172027588
train: epoch 67, loss 0.12916530668735504, acc=0.9452221989631653, loss=0.12916530668735504
test: epoch 67, loss 0.4422258734703064, acc=0.8472222089767456, loss=0.4422258734703064
train: epoch 68, loss 0.1240411251783371, acc=0.9471666812896729, loss=0.1240411251783371
test: epoch 68, loss 0.5900479555130005, acc=0.8472222089767456, loss=0.5900479555130005
train: epoch 69, loss 0.12497290223836899, acc=0.94605553150177, loss=0.12497290223836899
test: epoch 69, loss 0.5328908562660217, acc=0.8472222089767456, loss=0.5328908562660217
train: epoch 70, loss 0.13926421105861664, acc=0.9432222247123718, loss=0.13926421105861664
test: epoch 70, loss 0.5088269114494324, acc=0.8472222089767456, loss=0.5088269114494324
train: epoch 71, loss 0.12382771819829941, acc=0.9470555782318115, loss=0.12382771819829941
test: epoch 71, loss 0.5226292014122009, acc=0.8472222089767456, loss=0.5226292014122009
train: epoch 72, loss 0.11676765233278275, acc=0.9477777481079102, loss=0.11676765233278275
test: epoch 72, loss 0.523221492767334, acc=0.8500000238418579, loss=0.523221492767334
train: epoch 73, loss 0.12343864887952805, acc=0.9469444155693054, loss=0.12343864887952805
test: epoch 73, loss 0.46691039204597473, acc=0.855555534362793, loss=0.46691039204597473
train: epoch 74, loss 0.13554227352142334, acc=0.9452221989631653, loss=0.13554227352142334
test: epoch 74, loss 0.4590202569961548, acc=0.855555534362793, loss=0.4590202569961548
train: epoch 75, loss 0.11733321845531464, acc=0.9490000009536743, loss=0.11733321845531464
test: epoch 75, loss 0.40684765577316284, acc=0.8611111044883728, loss=0.40684765577316284
train: epoch 76, loss 0.1199447512626648, acc=0.9472777843475342, loss=0.1199447512626648
test: epoch 76, loss 0.4204026162624359, acc=0.855555534362793, loss=0.4204026162624359
train: epoch 77, loss 0.12276487797498703, acc=0.9480000138282776, loss=0.12276487797498703
test: epoch 77, loss 0.4576781094074249, acc=0.855555534362793, loss=0.4576781094074249
train: epoch 78, loss 0.12370964884757996, acc=0.9468888640403748, loss=0.12370964884757996
test: epoch 78, loss 0.5104896426200867, acc=0.8611111044883728, loss=0.5104896426200867
train: epoch 79, loss 0.11290580034255981, acc=0.9498888850212097, loss=0.11290580034255981
test: epoch 79, loss 0.40794509649276733, acc=0.8611111044883728, loss=0.40794509649276733
train: epoch 80, loss 0.11405584961175919, acc=0.948888897895813, loss=0.11405584961175919
test: epoch 80, loss 0.48322728276252747, acc=0.8611111044883728, loss=0.48322728276252747
train: epoch 81, loss 0.11125259846448898, acc=0.950166642665863, loss=0.11125259846448898
test: epoch 81, loss 0.5882850289344788, acc=0.855555534362793, loss=0.5882850289344788
train: epoch 82, loss 0.11812594532966614, acc=0.9491111040115356, loss=0.11812594532966614
test: epoch 82, loss 0.37376922369003296, acc=0.8611111044883728, loss=0.37376922369003296
train: epoch 83, loss 0.11435866355895996, acc=0.9500555396080017, loss=0.11435866355895996
test: epoch 83, loss 0.4273425340652466, acc=0.8611111044883728, loss=0.4273425340652466
train: epoch 84, loss 0.12236913293600082, acc=0.9483888745307922, loss=0.12236913293600082
test: epoch 84, loss 0.4970269203186035, acc=0.8583333492279053, loss=0.4970269203186035
train: epoch 85, loss 0.13146436214447021, acc=0.945722222328186, loss=0.13146436214447021
test: epoch 85, loss 0.43834471702575684, acc=0.8611111044883728, loss=0.43834471702575684
train: epoch 86, loss 0.12032906711101532, acc=0.9466111063957214, loss=0.12032906711101532
test: epoch 86, loss 0.4367709755897522, acc=0.8611111044883728, loss=0.4367709755897522
train: epoch 87, loss 0.10227258503437042, acc=0.9502778053283691, loss=0.10227258503437042
test: epoch 87, loss 0.5290040969848633, acc=0.8611111044883728, loss=0.5290040969848633
train: epoch 88, loss 0.11152573674917221, acc=0.949833333492279, loss=0.11152573674917221
test: epoch 88, loss 0.4412067234516144, acc=0.8611111044883728, loss=0.4412067234516144
train: epoch 89, loss 0.11900860071182251, acc=0.9480000138282776, loss=0.11900860071182251
test: epoch 89, loss 0.43396568298339844, acc=0.8611111044883728, loss=0.43396568298339844
train: epoch 90, loss 0.11460113525390625, acc=0.9495000243186951, loss=0.11460113525390625
test: epoch 90, loss 0.5270328521728516, acc=0.8611111044883728, loss=0.5270328521728516
train: epoch 91, loss 0.11144008487462997, acc=0.9514999985694885, loss=0.11144008487462997
test: epoch 91, loss 0.41296958923339844, acc=0.8611111044883728, loss=0.41296958923339844
train: epoch 92, loss 0.1150139793753624, acc=0.9496666789054871, loss=0.1150139793753624
test: epoch 92, loss 0.4871504306793213, acc=0.8611111044883728, loss=0.4871504306793213
train: epoch 93, loss 0.11227116733789444, acc=0.9496666789054871, loss=0.11227116733789444
test: epoch 93, loss 0.41435709595680237, acc=0.8611111044883728, loss=0.41435709595680237
train: epoch 94, loss 0.10393553972244263, acc=0.9518888592720032, loss=0.10393553972244263
test: epoch 94, loss 0.4274110794067383, acc=0.8611111044883728, loss=0.4274110794067383
train: epoch 95, loss 0.10934392362833023, acc=0.9505000114440918, loss=0.10934392362833023
test: epoch 95, loss 0.47874921560287476, acc=0.8611111044883728, loss=0.47874921560287476
train: epoch 96, loss 0.11405526101589203, acc=0.9495000243186951, loss=0.11405526101589203
test: epoch 96, loss 0.4785936772823334, acc=0.8611111044883728, loss=0.4785936772823334
train: epoch 97, loss 0.11373928934335709, acc=0.9507777690887451, loss=0.11373928934335709
test: epoch 97, loss 0.3850560486316681, acc=0.8611111044883728, loss=0.3850560486316681
train: epoch 98, loss 0.11765699088573456, acc=0.9511111378669739, loss=0.11765699088573456
test: epoch 98, loss 0.5362624526023865, acc=0.8611111044883728, loss=0.5362624526023865
train: epoch 99, loss 0.10673730820417404, acc=0.9515555500984192, loss=0.10673730820417404
test: epoch 99, loss 0.45436936616897583, acc=0.8611111044883728, loss=0.45436936616897583
train: epoch 100, loss 0.11796456575393677, acc=0.9494444727897644, loss=0.11796456575393677
test: epoch 100, loss 0.43226850032806396, acc=0.8527777791023254, loss=0.43226850032806396
train: epoch 101, loss 0.10997463017702103, acc=0.950166642665863, loss=0.10997463017702103
test: epoch 101, loss 0.5367788672447205, acc=0.8611111044883728, loss=0.5367788672447205
train: epoch 102, loss 0.11483413726091385, acc=0.9476666450500488, loss=0.11483413726091385
test: epoch 102, loss 0.4288783371448517, acc=0.8611111044883728, loss=0.4288783371448517
train: epoch 103, loss 0.11353347450494766, acc=0.9486111402511597, loss=0.11353347450494766
test: epoch 103, loss 0.5230078101158142, acc=0.8611111044883728, loss=0.5230078101158142
train: epoch 104, loss 0.10627792775630951, acc=0.9514999985694885, loss=0.10627792775630951
test: epoch 104, loss 0.382151335477829, acc=0.8611111044883728, loss=0.382151335477829
train: epoch 105, loss 0.11990571022033691, acc=0.9490000009536743, loss=0.11990571022033691
test: epoch 105, loss 0.49846699833869934, acc=0.8611111044883728, loss=0.49846699833869934
train: epoch 106, loss 0.10144811868667603, acc=0.9526666402816772, loss=0.10144811868667603
test: epoch 106, loss 0.4400453567504883, acc=0.8611111044883728, loss=0.4400453567504883
train: epoch 107, loss 0.11572601646184921, acc=0.9470555782318115, loss=0.11572601646184921
test: epoch 107, loss 0.4226529002189636, acc=0.8638888597488403, loss=0.4226529002189636
train: epoch 108, loss 0.0993591696023941, acc=0.9514999985694885, loss=0.0993591696023941
test: epoch 108, loss 0.4922344386577606, acc=0.8638888597488403, loss=0.4922344386577606
train: epoch 109, loss 0.10556016862392426, acc=0.953000009059906, loss=0.10556016862392426
test: epoch 109, loss 0.4293603301048279, acc=0.8638888597488403, loss=0.4293603301048279
train: epoch 110, loss 0.11050264537334442, acc=0.9508888721466064, loss=0.11050264537334442
test: epoch 110, loss 0.4220634996891022, acc=0.8638888597488403, loss=0.4220634996891022
train: epoch 111, loss 0.11066874861717224, acc=0.9521666765213013, loss=0.11066874861717224
test: epoch 111, loss 0.4971775710582733, acc=0.8638888597488403, loss=0.4971775710582733
train: epoch 112, loss 0.10572534799575806, acc=0.9518333077430725, loss=0.10572534799575806
test: epoch 112, loss 0.4352176785469055, acc=0.8638888597488403, loss=0.4352176785469055
train: epoch 113, loss 0.1021285355091095, acc=0.9520000219345093, loss=0.1021285355091095
test: epoch 113, loss 0.502193808555603, acc=0.8638888597488403, loss=0.502193808555603
train: epoch 114, loss 0.13318148255348206, acc=0.9503333568572998, loss=0.13318148255348206
test: epoch 114, loss 0.41313573718070984, acc=0.8638888597488403, loss=0.41313573718070984
train: epoch 115, loss 0.1114279255270958, acc=0.9510555267333984, loss=0.1114279255270958
test: epoch 115, loss 0.4151638448238373, acc=0.8638888597488403, loss=0.4151638448238373
train: epoch 116, loss 0.10964341461658478, acc=0.9510555267333984, loss=0.10964341461658478
test: epoch 116, loss 0.5806732177734375, acc=0.8611111044883728, loss=0.5806732177734375
train: epoch 117, loss 0.10969464480876923, acc=0.9513333439826965, loss=0.10969464480876923
test: epoch 117, loss 0.42441603541374207, acc=0.8638888597488403, loss=0.42441603541374207
train: epoch 118, loss 0.11373810470104218, acc=0.9512222409248352, loss=0.11373810470104218
test: epoch 118, loss 0.5265955924987793, acc=0.8666666746139526, loss=0.5265955924987793
train: epoch 119, loss 0.10900920629501343, acc=0.9507777690887451, loss=0.10900920629501343
test: epoch 119, loss 0.44110408425331116, acc=0.8611111044883728, loss=0.44110408425331116
train: epoch 120, loss 0.10694003850221634, acc=0.9514999985694885, loss=0.10694003850221634
test: epoch 120, loss 0.4295506179332733, acc=0.8666666746139526, loss=0.4295506179332733
train: epoch 121, loss 0.10218992084264755, acc=0.9526110887527466, loss=0.10218992084264755
test: epoch 121, loss 0.5266785621643066, acc=0.8666666746139526, loss=0.5266785621643066
train: epoch 122, loss 0.10281243175268173, acc=0.9516111016273499, loss=0.10281243175268173
test: epoch 122, loss 0.4094141721725464, acc=0.8666666746139526, loss=0.4094141721725464
train: epoch 123, loss 0.10703682899475098, acc=0.9511666893959045, loss=0.10703682899475098
test: epoch 123, loss 0.4131271541118622, acc=0.8694444298744202, loss=0.4131271541118622
train: epoch 124, loss 0.11887793242931366, acc=0.9492777585983276, loss=0.11887793242931366
test: epoch 124, loss 0.3843870162963867, acc=0.8722222447395325, loss=0.3843870162963867
train: epoch 125, loss 0.13553248345851898, acc=0.9411666393280029, loss=0.13553248345851898
test: epoch 125, loss 0.3353034555912018, acc=0.8722222447395325, loss=0.3353034555912018
train: epoch 126, loss 0.12642917037010193, acc=0.9424999952316284, loss=0.12642917037010193
test: epoch 126, loss 0.3778236508369446, acc=0.8777777552604675, loss=0.3778236508369446
train: epoch 127, loss 0.12585341930389404, acc=0.94605553150177, loss=0.12585341930389404
test: epoch 127, loss 0.406852126121521, acc=0.8777777552604675, loss=0.406852126121521
train: epoch 128, loss 0.12319587171077728, acc=0.9438333511352539, loss=0.12319587171077728
test: epoch 128, loss 0.3451797664165497, acc=0.8833333253860474, loss=0.3451797664165497
train: epoch 129, loss 0.11172344535589218, acc=0.9491111040115356, loss=0.11172344535589218
test: epoch 129, loss 0.43596428632736206, acc=0.8888888955116272, loss=0.43596428632736206
train: epoch 130, loss 0.10501453280448914, acc=0.9516111016273499, loss=0.10501453280448914
test: epoch 130, loss 0.38492223620414734, acc=0.8888888955116272, loss=0.38492223620414734
train: epoch 131, loss 0.1021474078297615, acc=0.9520000219345093, loss=0.1021474078297615
test: epoch 131, loss 0.3333052694797516, acc=0.8888888955116272, loss=0.3333052694797516
train: epoch 132, loss 0.10524868220090866, acc=0.9511666893959045, loss=0.10524868220090866
test: epoch 132, loss 0.29898107051849365, acc=0.8916666507720947, loss=0.29898107051849365
train: epoch 133, loss 0.11443925648927689, acc=0.949833333492279, loss=0.11443925648927689
test: epoch 133, loss 0.33012646436691284, acc=0.8888888955116272, loss=0.33012646436691284
train: epoch 134, loss 0.11732596904039383, acc=0.9481111168861389, loss=0.11732596904039383
test: epoch 134, loss 0.32387077808380127, acc=0.8916666507720947, loss=0.32387077808380127
train: epoch 135, loss 0.11909684538841248, acc=0.949055552482605, loss=0.11909684538841248
test: epoch 135, loss 0.35442042350769043, acc=0.8888888955116272, loss=0.35442042350769043
train: epoch 136, loss 0.12295718491077423, acc=0.9478333592414856, loss=0.12295718491077423
test: epoch 136, loss 0.41135916113853455, acc=0.8861111402511597, loss=0.41135916113853455
train: epoch 137, loss 0.1201833039522171, acc=0.9487777948379517, loss=0.1201833039522171
test: epoch 137, loss 0.27948641777038574, acc=0.8916666507720947, loss=0.27948641777038574
train: epoch 138, loss 0.11113108694553375, acc=0.9505000114440918, loss=0.11113108694553375
test: epoch 138, loss 0.3321179449558258, acc=0.8916666507720947, loss=0.3321179449558258
train: epoch 139, loss 0.1121259555220604, acc=0.9502778053283691, loss=0.1121259555220604
test: epoch 139, loss 0.26580810546875, acc=0.9055555462837219, loss=0.26580810546875
train: epoch 140, loss 0.10376840084791183, acc=0.9509444236755371, loss=0.10376840084791183
test: epoch 140, loss 0.2898279130458832, acc=0.8999999761581421, loss=0.2898279130458832
train: epoch 141, loss 0.11545173078775406, acc=0.949055552482605, loss=0.11545173078775406
test: epoch 141, loss 0.2812884747982025, acc=0.9138888716697693, loss=0.2812884747982025
train: epoch 142, loss 0.10353829711675644, acc=0.9524999856948853, loss=0.10353829711675644
test: epoch 142, loss 0.20744605362415314, acc=0.9194444417953491, loss=0.20744605362415314
train: epoch 143, loss 0.09494151175022125, acc=0.9539444446563721, loss=0.09494151175022125
test: epoch 143, loss 0.24267816543579102, acc=0.9194444417953491, loss=0.24267816543579102
train: epoch 144, loss 0.09571826457977295, acc=0.9539999961853027, loss=0.09571826457977295
test: epoch 144, loss 0.25331348180770874, acc=0.9194444417953491, loss=0.25331348180770874
train: epoch 145, loss 0.10360901802778244, acc=0.952833354473114, loss=0.10360901802778244
test: epoch 145, loss 0.20976591110229492, acc=0.9194444417953491, loss=0.20976591110229492
train: epoch 146, loss 0.09799424558877945, acc=0.9540555477142334, loss=0.09799424558877945
test: epoch 146, loss 0.216042622923851, acc=0.9194444417953491, loss=0.216042622923851
train: epoch 147, loss 0.10402970016002655, acc=0.9522777795791626, loss=0.10402970016002655
test: epoch 147, loss 0.1785069853067398, acc=0.9194444417953491, loss=0.1785069853067398
train: epoch 148, loss 0.09206703305244446, acc=0.9544444680213928, loss=0.09206703305244446
test: epoch 148, loss 0.21268236637115479, acc=0.9194444417953491, loss=0.21268236637115479
train: epoch 149, loss 0.09231528639793396, acc=0.9549999833106995, loss=0.09231528639793396
test: epoch 149, loss 0.2846566438674927, acc=0.9194444417953491, loss=0.2846566438674927
train: epoch 150, loss 0.0944080576300621, acc=0.953499972820282, loss=0.0944080576300621
test: epoch 150, loss 0.24487945437431335, acc=0.9166666865348816, loss=0.24487945437431335
