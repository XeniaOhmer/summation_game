# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1.5", "--temp_decay=0.99", "--one_hot=false", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=393929934, receiver_embed_dim=32, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.020791530609131, acc=0.07649999856948853, loss=3.020791530609131
test: epoch 1, loss 3.051245927810669, acc=0.1111111119389534, loss=3.051245927810669
train: epoch 2, loss 2.1165716648101807, acc=0.2007777839899063, loss=2.1165716648101807
test: epoch 2, loss 3.030440330505371, acc=0.18611110746860504, loss=3.030440330505371
train: epoch 3, loss 1.7457913160324097, acc=0.27577778697013855, loss=1.7457913160324097
test: epoch 3, loss 3.1976261138916016, acc=0.13055555522441864, loss=3.1976261138916016
train: epoch 4, loss 1.5546507835388184, acc=0.3251666724681854, loss=1.5546507835388184
test: epoch 4, loss 2.6393814086914062, acc=0.23888888955116272, loss=2.6393814086914062
train: epoch 5, loss 1.418832778930664, acc=0.3782222270965576, loss=1.418832778930664
test: epoch 5, loss 2.4850571155548096, acc=0.3194444477558136, loss=2.4850571155548096
train: epoch 6, loss 1.3459341526031494, acc=0.39827778935432434, loss=1.3459341526031494
test: epoch 6, loss 2.3807995319366455, acc=0.29722222685813904, loss=2.3807995319366455
train: epoch 7, loss 1.275830864906311, acc=0.4316111207008362, loss=1.275830864906311
test: epoch 7, loss 2.1661784648895264, acc=0.2916666567325592, loss=2.1661784648895264
train: epoch 8, loss 1.1873137950897217, acc=0.4632222354412079, loss=1.1873137950897217
test: epoch 8, loss 2.28818941116333, acc=0.2666666805744171, loss=2.28818941116333
train: epoch 9, loss 1.1718411445617676, acc=0.48100000619888306, loss=1.1718411445617676
test: epoch 9, loss 2.0036323070526123, acc=0.3305555582046509, loss=2.0036323070526123
train: epoch 10, loss 1.0837255716323853, acc=0.5062777996063232, loss=1.0837255716323853
test: epoch 10, loss 2.293687582015991, acc=0.2944444417953491, loss=2.293687582015991
train: epoch 11, loss 1.0128285884857178, acc=0.5407778024673462, loss=1.0128285884857178
test: epoch 11, loss 2.0690276622772217, acc=0.2750000059604645, loss=2.0690276622772217
train: epoch 12, loss 1.0080491304397583, acc=0.5521666407585144, loss=1.0080491304397583
test: epoch 12, loss 2.08412504196167, acc=0.33888888359069824, loss=2.08412504196167
train: epoch 13, loss 0.9311953783035278, acc=0.5929444432258606, loss=0.9311953783035278
test: epoch 13, loss 1.7144172191619873, acc=0.4000000059604645, loss=1.7144172191619873
train: epoch 14, loss 0.8619924783706665, acc=0.6293333172798157, loss=0.8619924783706665
test: epoch 14, loss 1.903506875038147, acc=0.3888888955116272, loss=1.903506875038147
train: epoch 15, loss 0.8676388263702393, acc=0.6272777915000916, loss=0.8676388263702393
test: epoch 15, loss 1.4698541164398193, acc=0.4277777671813965, loss=1.4698541164398193
train: epoch 16, loss 0.7851184010505676, acc=0.6658333539962769, loss=0.7851184010505676
test: epoch 16, loss 1.8173590898513794, acc=0.36666667461395264, loss=1.8173590898513794
train: epoch 17, loss 0.7346549034118652, acc=0.6859999895095825, loss=0.7346549034118652
test: epoch 17, loss 1.4703854322433472, acc=0.4333333373069763, loss=1.4703854322433472
train: epoch 18, loss 0.6707020401954651, acc=0.7161111235618591, loss=0.6707020401954651
test: epoch 18, loss 1.401877999305725, acc=0.4722222089767456, loss=1.401877999305725
train: epoch 19, loss 0.64690101146698, acc=0.727055549621582, loss=0.64690101146698
test: epoch 19, loss 1.5311225652694702, acc=0.46388888359069824, loss=1.5311225652694702
train: epoch 20, loss 0.6295191645622253, acc=0.7384999990463257, loss=0.6295191645622253
test: epoch 20, loss 1.1841260194778442, acc=0.4749999940395355, loss=1.1841260194778442
train: epoch 21, loss 0.5566039681434631, acc=0.7681666612625122, loss=0.5566039681434631
test: epoch 21, loss 1.1570554971694946, acc=0.5805555582046509, loss=1.1570554971694946
train: epoch 22, loss 0.5507318377494812, acc=0.7652222514152527, loss=0.5507318377494812
test: epoch 22, loss 1.188887357711792, acc=0.5083333253860474, loss=1.188887357711792
train: epoch 23, loss 0.5417211055755615, acc=0.7739444375038147, loss=0.5417211055755615
test: epoch 23, loss 1.1393665075302124, acc=0.5611110925674438, loss=1.1393665075302124
train: epoch 24, loss 0.5386223793029785, acc=0.7766110897064209, loss=0.5386223793029785
test: epoch 24, loss 1.2375177145004272, acc=0.5222222208976746, loss=1.2375177145004272
train: epoch 25, loss 0.4801952838897705, acc=0.7954999804496765, loss=0.4801952838897705
test: epoch 25, loss 1.2194119691848755, acc=0.5833333134651184, loss=1.2194119691848755
train: epoch 26, loss 0.4874415695667267, acc=0.7957777976989746, loss=0.4874415695667267
test: epoch 26, loss 0.7985016107559204, acc=0.6888889074325562, loss=0.7985016107559204
train: epoch 27, loss 0.4689149558544159, acc=0.8005555272102356, loss=0.4689149558544159
test: epoch 27, loss 0.907440721988678, acc=0.6722221970558167, loss=0.907440721988678
train: epoch 28, loss 0.4589688777923584, acc=0.8028888702392578, loss=0.4589688777923584
test: epoch 28, loss 0.9065124988555908, acc=0.6666666865348816, loss=0.9065124988555908
train: epoch 29, loss 0.4377962052822113, acc=0.8109444379806519, loss=0.4377962052822113
test: epoch 29, loss 0.7595377564430237, acc=0.6777777671813965, loss=0.7595377564430237
train: epoch 30, loss 0.4420824944972992, acc=0.8132777810096741, loss=0.4420824944972992
test: epoch 30, loss 0.7985451817512512, acc=0.6722221970558167, loss=0.7985451817512512
train: epoch 31, loss 0.42410552501678467, acc=0.828166663646698, loss=0.42410552501678467
test: epoch 31, loss 0.9212655425071716, acc=0.6638888716697693, loss=0.9212655425071716
train: epoch 32, loss 0.3847408890724182, acc=0.8402222394943237, loss=0.3847408890724182
test: epoch 32, loss 0.7385343909263611, acc=0.6972222328186035, loss=0.7385343909263611
train: epoch 33, loss 0.3596496284008026, acc=0.8485555648803711, loss=0.3596496284008026
test: epoch 33, loss 0.890426516532898, acc=0.7111111283302307, loss=0.890426516532898
train: epoch 34, loss 0.38148069381713867, acc=0.8417778015136719, loss=0.38148069381713867
test: epoch 34, loss 0.6573821902275085, acc=0.7555555701255798, loss=0.6573821902275085
train: epoch 35, loss 0.3386872410774231, acc=0.8539444208145142, loss=0.3386872410774231
test: epoch 35, loss 0.8232271075248718, acc=0.6861110925674438, loss=0.8232271075248718
train: epoch 36, loss 0.3419111371040344, acc=0.8521111011505127, loss=0.3419111371040344
test: epoch 36, loss 0.7304843068122864, acc=0.7472222447395325, loss=0.7304843068122864
train: epoch 37, loss 0.3241803050041199, acc=0.859000027179718, loss=0.3241803050041199
test: epoch 37, loss 0.6742419004440308, acc=0.7138888835906982, loss=0.6742419004440308
train: epoch 38, loss 0.32491013407707214, acc=0.8577222228050232, loss=0.32491013407707214
test: epoch 38, loss 0.5797250866889954, acc=0.769444465637207, loss=0.5797250866889954
train: epoch 39, loss 0.3255278766155243, acc=0.8570555448532104, loss=0.3255278766155243
test: epoch 39, loss 0.6727625727653503, acc=0.7749999761581421, loss=0.6727625727653503
train: epoch 40, loss 0.31540027260780334, acc=0.8615000247955322, loss=0.31540027260780334
test: epoch 40, loss 0.6638500094413757, acc=0.7638888955116272, loss=0.6638500094413757
train: epoch 41, loss 0.30854910612106323, acc=0.8630555272102356, loss=0.30854910612106323
test: epoch 41, loss 0.6429088115692139, acc=0.7749999761581421, loss=0.6429088115692139
train: epoch 42, loss 0.3278163969516754, acc=0.8600555658340454, loss=0.3278163969516754
test: epoch 42, loss 0.7411872148513794, acc=0.769444465637207, loss=0.7411872148513794
train: epoch 43, loss 0.34018105268478394, acc=0.8583889007568359, loss=0.34018105268478394
test: epoch 43, loss 0.7754498720169067, acc=0.75, loss=0.7754498720169067
train: epoch 44, loss 0.32178059220314026, acc=0.8632222414016724, loss=0.32178059220314026
test: epoch 44, loss 0.5911017060279846, acc=0.7555555701255798, loss=0.5911017060279846
train: epoch 45, loss 0.3085525929927826, acc=0.8679999709129333, loss=0.3085525929927826
test: epoch 45, loss 0.6857166290283203, acc=0.7666666507720947, loss=0.6857166290283203
train: epoch 46, loss 0.31863826513290405, acc=0.8633888959884644, loss=0.31863826513290405
test: epoch 46, loss 0.5802075862884521, acc=0.7638888955116272, loss=0.5802075862884521
train: epoch 47, loss 0.31413665413856506, acc=0.8648889064788818, loss=0.31413665413856506
test: epoch 47, loss 0.676807165145874, acc=0.7555555701255798, loss=0.676807165145874
train: epoch 48, loss 0.30545157194137573, acc=0.8674444556236267, loss=0.30545157194137573
test: epoch 48, loss 0.616607666015625, acc=0.7749999761581421, loss=0.616607666015625
train: epoch 49, loss 0.3252846896648407, acc=0.859333336353302, loss=0.3252846896648407
test: epoch 49, loss 0.5108087658882141, acc=0.7722222208976746, loss=0.5108087658882141
train: epoch 50, loss 0.3205774426460266, acc=0.8644444346427917, loss=0.3205774426460266
test: epoch 50, loss 0.5943334102630615, acc=0.769444465637207, loss=0.5943334102630615
train: epoch 51, loss 0.31505319476127625, acc=0.8627777695655823, loss=0.31505319476127625
test: epoch 51, loss 0.6532703042030334, acc=0.769444465637207, loss=0.6532703042030334
train: epoch 52, loss 0.3231718838214874, acc=0.8602222204208374, loss=0.3231718838214874
test: epoch 52, loss 0.5375441908836365, acc=0.7749999761581421, loss=0.5375441908836365
train: epoch 53, loss 0.31676366925239563, acc=0.8647222518920898, loss=0.31676366925239563
test: epoch 53, loss 0.6316490173339844, acc=0.7638888955116272, loss=0.6316490173339844
train: epoch 54, loss 0.30158424377441406, acc=0.8671666383743286, loss=0.30158424377441406
test: epoch 54, loss 0.7107870578765869, acc=0.7527777552604675, loss=0.7107870578765869
train: epoch 55, loss 0.31007689237594604, acc=0.8663333058357239, loss=0.31007689237594604
test: epoch 55, loss 0.6286208629608154, acc=0.7638888955116272, loss=0.6286208629608154
train: epoch 56, loss 0.33049193024635315, acc=0.8612777590751648, loss=0.33049193024635315
test: epoch 56, loss 0.5999066829681396, acc=0.7722222208976746, loss=0.5999066829681396
train: epoch 57, loss 0.31311678886413574, acc=0.866611123085022, loss=0.31311678886413574
test: epoch 57, loss 0.6766480207443237, acc=0.7527777552604675, loss=0.6766480207443237
train: epoch 58, loss 0.2887890338897705, acc=0.8732222318649292, loss=0.2887890338897705
test: epoch 58, loss 0.6313320994377136, acc=0.7749999761581421, loss=0.6313320994377136
train: epoch 59, loss 0.3173321783542633, acc=0.863111138343811, loss=0.3173321783542633
test: epoch 59, loss 0.5900177955627441, acc=0.7722222208976746, loss=0.5900177955627441
train: epoch 60, loss 0.33011817932128906, acc=0.8611666560173035, loss=0.33011817932128906
test: epoch 60, loss 0.6125141978263855, acc=0.7638888955116272, loss=0.6125141978263855
train: epoch 61, loss 0.2925145924091339, acc=0.870722234249115, loss=0.2925145924091339
test: epoch 61, loss 0.629183828830719, acc=0.7583333253860474, loss=0.629183828830719
train: epoch 62, loss 0.3103538155555725, acc=0.8648889064788818, loss=0.3103538155555725
test: epoch 62, loss 0.5659576058387756, acc=0.7749999761581421, loss=0.5659576058387756
train: epoch 63, loss 0.32594922184944153, acc=0.8640000224113464, loss=0.32594922184944153
test: epoch 63, loss 0.570065438747406, acc=0.7722222208976746, loss=0.570065438747406
train: epoch 64, loss 0.3158636689186096, acc=0.8657777905464172, loss=0.3158636689186096
test: epoch 64, loss 0.6272318363189697, acc=0.7749999761581421, loss=0.6272318363189697
train: epoch 65, loss 0.3127526342868805, acc=0.866611123085022, loss=0.3127526342868805
test: epoch 65, loss 0.6238850951194763, acc=0.7666666507720947, loss=0.6238850951194763
train: epoch 66, loss 0.35731378197669983, acc=0.8583333492279053, loss=0.35731378197669983
test: epoch 66, loss 0.6317561864852905, acc=0.7749999761581421, loss=0.6317561864852905
train: epoch 67, loss 0.32919609546661377, acc=0.8607222437858582, loss=0.32919609546661377
test: epoch 67, loss 0.5107609629631042, acc=0.7722222208976746, loss=0.5107609629631042
train: epoch 68, loss 0.31119704246520996, acc=0.867111086845398, loss=0.31119704246520996
test: epoch 68, loss 0.6066873073577881, acc=0.7722222208976746, loss=0.6066873073577881
train: epoch 69, loss 0.31726303696632385, acc=0.8651666641235352, loss=0.31726303696632385
test: epoch 69, loss 0.651037335395813, acc=0.7749999761581421, loss=0.651037335395813
train: epoch 70, loss 0.299850195646286, acc=0.8715000152587891, loss=0.299850195646286
test: epoch 70, loss 0.5115490555763245, acc=0.7749999761581421, loss=0.5115490555763245
train: epoch 71, loss 0.31595268845558167, acc=0.8636666536331177, loss=0.31595268845558167
test: epoch 71, loss 0.526821494102478, acc=0.7749999761581421, loss=0.526821494102478
train: epoch 72, loss 0.3286614716053009, acc=0.863611102104187, loss=0.3286614716053009
test: epoch 72, loss 0.600079357624054, acc=0.7749999761581421, loss=0.600079357624054
train: epoch 73, loss 0.3246648907661438, acc=0.862500011920929, loss=0.3246648907661438
test: epoch 73, loss 0.6658266186714172, acc=0.7611111402511597, loss=0.6658266186714172
train: epoch 74, loss 0.3227454423904419, acc=0.8615555763244629, loss=0.3227454423904419
test: epoch 74, loss 0.5126010775566101, acc=0.7749999761581421, loss=0.5126010775566101
train: epoch 75, loss 0.3142322897911072, acc=0.8648889064788818, loss=0.3142322897911072
test: epoch 75, loss 0.5573664307594299, acc=0.7749999761581421, loss=0.5573664307594299
train: epoch 76, loss 0.3086615800857544, acc=0.8686666488647461, loss=0.3086615800857544
test: epoch 76, loss 0.6206695437431335, acc=0.769444465637207, loss=0.6206695437431335
train: epoch 77, loss 0.31669875979423523, acc=0.8661110997200012, loss=0.31669875979423523
test: epoch 77, loss 0.6194236278533936, acc=0.7749999761581421, loss=0.6194236278533936
train: epoch 78, loss 0.3045421540737152, acc=0.867555558681488, loss=0.3045421540737152
test: epoch 78, loss 0.6075233817100525, acc=0.7722222208976746, loss=0.6075233817100525
train: epoch 79, loss 0.3171314299106598, acc=0.863444447517395, loss=0.3171314299106598
test: epoch 79, loss 0.6909605264663696, acc=0.7583333253860474, loss=0.6909605264663696
train: epoch 80, loss 0.3242942988872528, acc=0.862666666507721, loss=0.3242942988872528
test: epoch 80, loss 0.6438714265823364, acc=0.7749999761581421, loss=0.6438714265823364
train: epoch 81, loss 0.3157366216182709, acc=0.8662222027778625, loss=0.3157366216182709
test: epoch 81, loss 0.5612572431564331, acc=0.7749999761581421, loss=0.5612572431564331
train: epoch 82, loss 0.3037404417991638, acc=0.8698333501815796, loss=0.3037404417991638
test: epoch 82, loss 0.5192314982414246, acc=0.7749999761581421, loss=0.5192314982414246
train: epoch 83, loss 0.31198129057884216, acc=0.8670555353164673, loss=0.31198129057884216
test: epoch 83, loss 0.6075659394264221, acc=0.7666666507720947, loss=0.6075659394264221
train: epoch 84, loss 0.2846565246582031, acc=0.8748888969421387, loss=0.2846565246582031
test: epoch 84, loss 0.5628376007080078, acc=0.7749999761581421, loss=0.5628376007080078
train: epoch 85, loss 0.34894928336143494, acc=0.8442222476005554, loss=0.34894928336143494
test: epoch 85, loss 0.5387699007987976, acc=0.7777777910232544, loss=0.5387699007987976
train: epoch 86, loss 0.34549480676651, acc=0.8451666831970215, loss=0.34549480676651
test: epoch 86, loss 0.4918115437030792, acc=0.769444465637207, loss=0.4918115437030792
train: epoch 87, loss 0.31307652592658997, acc=0.867222249507904, loss=0.31307652592658997
test: epoch 87, loss 0.5405789017677307, acc=0.769444465637207, loss=0.5405789017677307
train: epoch 88, loss 0.34457921981811523, acc=0.8587777614593506, loss=0.34457921981811523
test: epoch 88, loss 0.6221429109573364, acc=0.7611111402511597, loss=0.6221429109573364
train: epoch 89, loss 0.3038618266582489, acc=0.8713889122009277, loss=0.3038618266582489
test: epoch 89, loss 0.534675121307373, acc=0.7749999761581421, loss=0.534675121307373
train: epoch 90, loss 0.31800076365470886, acc=0.8651111125946045, loss=0.31800076365470886
test: epoch 90, loss 0.5822275280952454, acc=0.7749999761581421, loss=0.5822275280952454
train: epoch 91, loss 0.3029559552669525, acc=0.8701111078262329, loss=0.3029559552669525
test: epoch 91, loss 0.5850496292114258, acc=0.7749999761581421, loss=0.5850496292114258
train: epoch 92, loss 0.3055753707885742, acc=0.8686666488647461, loss=0.3055753707885742
test: epoch 92, loss 0.6056114435195923, acc=0.7472222447395325, loss=0.6056114435195923
train: epoch 93, loss 0.32309356331825256, acc=0.8665000200271606, loss=0.32309356331825256
test: epoch 93, loss 0.5440268516540527, acc=0.769444465637207, loss=0.5440268516540527
train: epoch 94, loss 0.33222198486328125, acc=0.8598333597183228, loss=0.33222198486328125
test: epoch 94, loss 0.5777006149291992, acc=0.7749999761581421, loss=0.5777006149291992
train: epoch 95, loss 0.30111178755760193, acc=0.8736666440963745, loss=0.30111178755760193
test: epoch 95, loss 0.6003063917160034, acc=0.769444465637207, loss=0.6003063917160034
train: epoch 96, loss 0.3372591435909271, acc=0.8576666712760925, loss=0.3372591435909271
test: epoch 96, loss 0.6238444447517395, acc=0.7722222208976746, loss=0.6238444447517395
train: epoch 97, loss 0.29598307609558105, acc=0.8726666569709778, loss=0.29598307609558105
test: epoch 97, loss 0.6229497790336609, acc=0.7722222208976746, loss=0.6229497790336609
train: epoch 98, loss 0.3069334626197815, acc=0.8638888597488403, loss=0.3069334626197815
test: epoch 98, loss 0.5758053660392761, acc=0.7749999761581421, loss=0.5758053660392761
train: epoch 99, loss 0.34626880288124084, acc=0.8600000143051147, loss=0.34626880288124084
test: epoch 99, loss 0.5626599192619324, acc=0.7749999761581421, loss=0.5626599192619324
train: epoch 100, loss 0.29132166504859924, acc=0.8715000152587891, loss=0.29132166504859924
test: epoch 100, loss 0.5561560988426208, acc=0.7833333611488342, loss=0.5561560988426208
train: epoch 101, loss 0.31391093134880066, acc=0.8614444732666016, loss=0.31391093134880066
test: epoch 101, loss 0.5418018102645874, acc=0.7749999761581421, loss=0.5418018102645874
train: epoch 102, loss 0.283488929271698, acc=0.8727222084999084, loss=0.283488929271698
test: epoch 102, loss 0.6002996563911438, acc=0.7749999761581421, loss=0.6002996563911438
train: epoch 103, loss 0.30392804741859436, acc=0.8721110820770264, loss=0.30392804741859436
test: epoch 103, loss 0.6361812353134155, acc=0.7749999761581421, loss=0.6361812353134155
train: epoch 104, loss 0.3131846487522125, acc=0.8613888621330261, loss=0.3131846487522125
test: epoch 104, loss 0.518172562122345, acc=0.7749999761581421, loss=0.518172562122345
train: epoch 105, loss 0.2699874937534332, acc=0.8802222013473511, loss=0.2699874937534332
test: epoch 105, loss 0.5967277884483337, acc=0.7749999761581421, loss=0.5967277884483337
train: epoch 106, loss 0.3147478401660919, acc=0.8640555739402771, loss=0.3147478401660919
test: epoch 106, loss 0.554991602897644, acc=0.7722222208976746, loss=0.554991602897644
train: epoch 107, loss 0.304338663816452, acc=0.8683888912200928, loss=0.304338663816452
test: epoch 107, loss 0.5595874190330505, acc=0.7749999761581421, loss=0.5595874190330505
train: epoch 108, loss 0.3030327558517456, acc=0.8709999918937683, loss=0.3030327558517456
test: epoch 108, loss 0.6319658160209656, acc=0.769444465637207, loss=0.6319658160209656
train: epoch 109, loss 0.311773419380188, acc=0.8658888936042786, loss=0.311773419380188
test: epoch 109, loss 0.5896263122558594, acc=0.7722222208976746, loss=0.5896263122558594
train: epoch 110, loss 0.3442022502422333, acc=0.8523889183998108, loss=0.3442022502422333
test: epoch 110, loss 0.5799688100814819, acc=0.7666666507720947, loss=0.5799688100814819
train: epoch 111, loss 0.28360438346862793, acc=0.8761666417121887, loss=0.28360438346862793
test: epoch 111, loss 0.6680177450180054, acc=0.769444465637207, loss=0.6680177450180054
train: epoch 112, loss 0.27805814146995544, acc=0.8761110901832581, loss=0.27805814146995544
test: epoch 112, loss 0.5685073733329773, acc=0.7833333611488342, loss=0.5685073733329773
train: epoch 113, loss 0.3382508456707001, acc=0.8483333587646484, loss=0.3382508456707001
test: epoch 113, loss 0.701298713684082, acc=0.730555534362793, loss=0.701298713684082
train: epoch 114, loss 0.35095345973968506, acc=0.8341110944747925, loss=0.35095345973968506
test: epoch 114, loss 0.6450890302658081, acc=0.7333333492279053, loss=0.6450890302658081
train: epoch 115, loss 0.36741602420806885, acc=0.8298888802528381, loss=0.36741602420806885
test: epoch 115, loss 0.679719090461731, acc=0.7166666388511658, loss=0.679719090461731
train: epoch 116, loss 0.312411367893219, acc=0.867888867855072, loss=0.312411367893219
test: epoch 116, loss 0.6540026664733887, acc=0.7749999761581421, loss=0.6540026664733887
train: epoch 117, loss 0.2896052300930023, acc=0.8767222166061401, loss=0.2896052300930023
test: epoch 117, loss 0.5893859267234802, acc=0.769444465637207, loss=0.5893859267234802
train: epoch 118, loss 0.2862538695335388, acc=0.8752777576446533, loss=0.2862538695335388
test: epoch 118, loss 0.5953071713447571, acc=0.7749999761581421, loss=0.5953071713447571
train: epoch 119, loss 0.28679075837135315, acc=0.8760555386543274, loss=0.28679075837135315
test: epoch 119, loss 0.5618384480476379, acc=0.7777777910232544, loss=0.5618384480476379
train: epoch 120, loss 0.29997679591178894, acc=0.8701666593551636, loss=0.29997679591178894
test: epoch 120, loss 0.6440718173980713, acc=0.7805555462837219, loss=0.6440718173980713
train: epoch 121, loss 0.29758909344673157, acc=0.8744444251060486, loss=0.29758909344673157
test: epoch 121, loss 0.5823131799697876, acc=0.7833333611488342, loss=0.5823131799697876
train: epoch 122, loss 0.3108462989330292, acc=0.8690555691719055, loss=0.3108462989330292
test: epoch 122, loss 0.6221925020217896, acc=0.7583333253860474, loss=0.6221925020217896
train: epoch 123, loss 0.3194082975387573, acc=0.8690555691719055, loss=0.3194082975387573
test: epoch 123, loss 0.5857369303703308, acc=0.7555555701255798, loss=0.5857369303703308
train: epoch 124, loss 0.29186010360717773, acc=0.8724444508552551, loss=0.29186010360717773
test: epoch 124, loss 0.5605801343917847, acc=0.7833333611488342, loss=0.5605801343917847
train: epoch 125, loss 0.2637920677661896, acc=0.8836666941642761, loss=0.2637920677661896
test: epoch 125, loss 0.8214905858039856, acc=0.7638888955116272, loss=0.8214905858039856
train: epoch 126, loss 0.29387134313583374, acc=0.8756111264228821, loss=0.29387134313583374
test: epoch 126, loss 0.6250300407409668, acc=0.7833333611488342, loss=0.6250300407409668
train: epoch 127, loss 0.32330620288848877, acc=0.8708333373069763, loss=0.32330620288848877
test: epoch 127, loss 0.5970984101295471, acc=0.7805555462837219, loss=0.5970984101295471
train: epoch 128, loss 0.3084007501602173, acc=0.870555579662323, loss=0.3084007501602173
test: epoch 128, loss 0.5396080017089844, acc=0.7666666507720947, loss=0.5396080017089844
train: epoch 129, loss 0.27729472517967224, acc=0.8802222013473511, loss=0.27729472517967224
test: epoch 129, loss 0.6150516867637634, acc=0.7777777910232544, loss=0.6150516867637634
train: epoch 130, loss 0.3107820153236389, acc=0.8704444169998169, loss=0.3107820153236389
test: epoch 130, loss 0.576711118221283, acc=0.7805555462837219, loss=0.576711118221283
train: epoch 131, loss 0.3186629116535187, acc=0.8677777647972107, loss=0.3186629116535187
test: epoch 131, loss 0.6650587320327759, acc=0.7749999761581421, loss=0.6650587320327759
train: epoch 132, loss 0.28121474385261536, acc=0.8782222270965576, loss=0.28121474385261536
test: epoch 132, loss 0.6856818199157715, acc=0.7805555462837219, loss=0.6856818199157715
train: epoch 133, loss 0.3215102553367615, acc=0.8649444580078125, loss=0.3215102553367615
test: epoch 133, loss 0.6492799520492554, acc=0.769444465637207, loss=0.6492799520492554
train: epoch 134, loss 0.32693445682525635, acc=0.8642777800559998, loss=0.32693445682525635
test: epoch 134, loss 0.6023468971252441, acc=0.769444465637207, loss=0.6023468971252441
train: epoch 135, loss 0.3181058466434479, acc=0.8616666793823242, loss=0.3181058466434479
test: epoch 135, loss 0.6777185201644897, acc=0.7611111402511597, loss=0.6777185201644897
train: epoch 136, loss 0.30291855335235596, acc=0.870555579662323, loss=0.30291855335235596
test: epoch 136, loss 0.6263673901557922, acc=0.769444465637207, loss=0.6263673901557922
train: epoch 137, loss 0.29850608110427856, acc=0.871999979019165, loss=0.29850608110427856
test: epoch 137, loss 0.5844018459320068, acc=0.7749999761581421, loss=0.5844018459320068
train: epoch 138, loss 0.269941121339798, acc=0.8798888921737671, loss=0.269941121339798
test: epoch 138, loss 0.5969632267951965, acc=0.7777777910232544, loss=0.5969632267951965
train: epoch 139, loss 0.30889078974723816, acc=0.8695555329322815, loss=0.30889078974723816
test: epoch 139, loss 0.5577136278152466, acc=0.7805555462837219, loss=0.5577136278152466
train: epoch 140, loss 0.30429190397262573, acc=0.8728333115577698, loss=0.30429190397262573
test: epoch 140, loss 0.5482022762298584, acc=0.7777777910232544, loss=0.5482022762298584
train: epoch 141, loss 0.27641600370407104, acc=0.8798888921737671, loss=0.27641600370407104
test: epoch 141, loss 0.5575852394104004, acc=0.7805555462837219, loss=0.5575852394104004
train: epoch 142, loss 0.2745908796787262, acc=0.8792222142219543, loss=0.2745908796787262
test: epoch 142, loss 0.6043283343315125, acc=0.7805555462837219, loss=0.6043283343315125
train: epoch 143, loss 0.2838329076766968, acc=0.8767777681350708, loss=0.2838329076766968
test: epoch 143, loss 0.6141697764396667, acc=0.7777777910232544, loss=0.6141697764396667
train: epoch 144, loss 0.3198889195919037, acc=0.8668888807296753, loss=0.3198889195919037
test: epoch 144, loss 0.5172203183174133, acc=0.7805555462837219, loss=0.5172203183174133
train: epoch 145, loss 0.29227569699287415, acc=0.8723333477973938, loss=0.29227569699287415
test: epoch 145, loss 0.58758145570755, acc=0.7805555462837219, loss=0.58758145570755
train: epoch 146, loss 0.2869288921356201, acc=0.8761110901832581, loss=0.2869288921356201
test: epoch 146, loss 0.6098862886428833, acc=0.7444444298744202, loss=0.6098862886428833
train: epoch 147, loss 0.3157653212547302, acc=0.8642222285270691, loss=0.3157653212547302
test: epoch 147, loss 0.6138207912445068, acc=0.7805555462837219, loss=0.6138207912445068
train: epoch 148, loss 0.28803375363349915, acc=0.8731666803359985, loss=0.28803375363349915
test: epoch 148, loss 0.5752905011177063, acc=0.7805555462837219, loss=0.5752905011177063
train: epoch 149, loss 0.2896299958229065, acc=0.8737778067588806, loss=0.2896299958229065
test: epoch 149, loss 0.5941755771636963, acc=0.7777777910232544, loss=0.5941755771636963
train: epoch 150, loss 0.32156333327293396, acc=0.8665000200271606, loss=0.32156333327293396
test: epoch 150, loss 0.5877330303192139, acc=0.7805555462837219, loss=0.5877330303192139
