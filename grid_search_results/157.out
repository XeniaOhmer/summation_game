# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=2.0", "--temp_decay=0.99", "--one_hot=true", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1429649872, receiver_embed_dim=128, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.7143309116363525, acc=0.1149444431066513, loss=2.7143309116363525
test: epoch 1, loss 4.262495517730713, acc=0.0972222238779068, loss=4.262495517730713
train: epoch 2, loss 1.464255690574646, acc=0.4180000126361847, loss=1.464255690574646
test: epoch 2, loss 3.222660779953003, acc=0.21111111342906952, loss=3.222660779953003
train: epoch 3, loss 0.8856881260871887, acc=0.6413888931274414, loss=0.8856881260871887
test: epoch 3, loss 3.4521031379699707, acc=0.2083333283662796, loss=3.4521031379699707
train: epoch 4, loss 0.6526492834091187, acc=0.7401666641235352, loss=0.6526492834091187
test: epoch 4, loss 2.43851637840271, acc=0.28333333134651184, loss=2.43851637840271
train: epoch 5, loss 0.5234159231185913, acc=0.792722225189209, loss=0.5234159231185913
test: epoch 5, loss 2.751032590866089, acc=0.25555557012557983, loss=2.751032590866089
train: epoch 6, loss 0.4353434145450592, acc=0.8351110816001892, loss=0.4353434145450592
test: epoch 6, loss 2.864805221557617, acc=0.2611111104488373, loss=2.864805221557617
train: epoch 7, loss 0.3570980727672577, acc=0.8631666898727417, loss=0.3570980727672577
test: epoch 7, loss 2.3205690383911133, acc=0.29722222685813904, loss=2.3205690383911133
train: epoch 8, loss 0.33025068044662476, acc=0.8757777810096741, loss=0.33025068044662476
test: epoch 8, loss 1.8063334226608276, acc=0.39722222089767456, loss=1.8063334226608276
train: epoch 9, loss 0.3107677698135376, acc=0.8822222352027893, loss=0.3107677698135376
test: epoch 9, loss 2.2733914852142334, acc=0.3361110985279083, loss=2.2733914852142334
train: epoch 10, loss 0.2595163881778717, acc=0.9006111025810242, loss=0.2595163881778717
test: epoch 10, loss 1.916922688484192, acc=0.40833333134651184, loss=1.916922688484192
train: epoch 11, loss 0.25698772072792053, acc=0.9007222056388855, loss=0.25698772072792053
test: epoch 11, loss 2.110194206237793, acc=0.4611110985279083, loss=2.110194206237793
train: epoch 12, loss 0.2547474801540375, acc=0.9057222008705139, loss=0.2547474801540375
test: epoch 12, loss 2.357988119125366, acc=0.4055555462837219, loss=2.357988119125366
train: epoch 13, loss 0.2318868190050125, acc=0.914555549621582, loss=0.2318868190050125
test: epoch 13, loss 1.7621924877166748, acc=0.49444442987442017, loss=1.7621924877166748
train: epoch 14, loss 0.20945671200752258, acc=0.9258333444595337, loss=0.20945671200752258
test: epoch 14, loss 1.940678596496582, acc=0.4138889014720917, loss=1.940678596496582
train: epoch 15, loss 0.2035931497812271, acc=0.9307777881622314, loss=0.2035931497812271
test: epoch 15, loss 2.2029178142547607, acc=0.4027777910232544, loss=2.2029178142547607
train: epoch 16, loss 0.1967364102602005, acc=0.9310555458068848, loss=0.1967364102602005
test: epoch 16, loss 2.253613233566284, acc=0.41111111640930176, loss=2.253613233566284
train: epoch 17, loss 0.17604663968086243, acc=0.9391111135482788, loss=0.17604663968086243
test: epoch 17, loss 2.729095458984375, acc=0.4611110985279083, loss=2.729095458984375
train: epoch 18, loss 0.18287955224514008, acc=0.9365000128746033, loss=0.18287955224514008
test: epoch 18, loss 2.2911808490753174, acc=0.3638888895511627, loss=2.2911808490753174
train: epoch 19, loss 0.17127591371536255, acc=0.9415000081062317, loss=0.17127591371536255
test: epoch 19, loss 2.1727828979492188, acc=0.41111111640930176, loss=2.1727828979492188
train: epoch 20, loss 0.1663631796836853, acc=0.9434999823570251, loss=0.1663631796836853
test: epoch 20, loss 2.8277804851531982, acc=0.34166666865348816, loss=2.8277804851531982
train: epoch 21, loss 0.1837579756975174, acc=0.9352777600288391, loss=0.1837579756975174
test: epoch 21, loss 2.234297752380371, acc=0.42222222685813904, loss=2.234297752380371
train: epoch 22, loss 0.16299867630004883, acc=0.9445555806159973, loss=0.16299867630004883
test: epoch 22, loss 2.334258556365967, acc=0.39444443583488464, loss=2.334258556365967
train: epoch 23, loss 0.16363683342933655, acc=0.9482777714729309, loss=0.16363683342933655
test: epoch 23, loss 2.359678268432617, acc=0.4138889014720917, loss=2.359678268432617
train: epoch 24, loss 0.14015227556228638, acc=0.9536666870117188, loss=0.14015227556228638
test: epoch 24, loss 2.2317497730255127, acc=0.42500001192092896, loss=2.2317497730255127
train: epoch 25, loss 0.15477436780929565, acc=0.9491666555404663, loss=0.15477436780929565
test: epoch 25, loss 1.9219251871109009, acc=0.4305555522441864, loss=1.9219251871109009
train: epoch 26, loss 0.1708204299211502, acc=0.945722222328186, loss=0.1708204299211502
test: epoch 26, loss 2.030658721923828, acc=0.47777777910232544, loss=2.030658721923828
train: epoch 27, loss 0.15087875723838806, acc=0.9479444622993469, loss=0.15087875723838806
test: epoch 27, loss 1.8661526441574097, acc=0.4861111044883728, loss=1.8661526441574097
train: epoch 28, loss 0.1457339972257614, acc=0.9532777667045593, loss=0.1457339972257614
test: epoch 28, loss 1.9955512285232544, acc=0.4833333194255829, loss=1.9955512285232544
train: epoch 29, loss 0.1454906314611435, acc=0.9525555372238159, loss=0.1454906314611435
test: epoch 29, loss 1.8969062566757202, acc=0.45277777314186096, loss=1.8969062566757202
train: epoch 30, loss 0.13450446724891663, acc=0.9556666612625122, loss=0.13450446724891663
test: epoch 30, loss 1.8419119119644165, acc=0.5111111402511597, loss=1.8419119119644165
train: epoch 31, loss 0.14100250601768494, acc=0.9534444212913513, loss=0.14100250601768494
test: epoch 31, loss 1.579108715057373, acc=0.5833333134651184, loss=1.579108715057373
train: epoch 32, loss 0.16044102609157562, acc=0.9481666684150696, loss=0.16044102609157562
test: epoch 32, loss 2.291039228439331, acc=0.4833333194255829, loss=2.291039228439331
train: epoch 33, loss 0.12784291803836823, acc=0.9578333497047424, loss=0.12784291803836823
test: epoch 33, loss 1.5039145946502686, acc=0.6000000238418579, loss=1.5039145946502686
train: epoch 34, loss 0.15008516609668732, acc=0.9497222304344177, loss=0.15008516609668732
test: epoch 34, loss 1.6115543842315674, acc=0.5305555462837219, loss=1.6115543842315674
train: epoch 35, loss 0.1367350071668625, acc=0.9560555815696716, loss=0.1367350071668625
test: epoch 35, loss 1.453710675239563, acc=0.574999988079071, loss=1.453710675239563
train: epoch 36, loss 0.1311022937297821, acc=0.957611083984375, loss=0.1311022937297821
test: epoch 36, loss 1.3967763185501099, acc=0.6027777791023254, loss=1.3967763185501099
train: epoch 37, loss 0.14507707953453064, acc=0.9523888826370239, loss=0.14507707953453064
test: epoch 37, loss 1.4489893913269043, acc=0.6138888597488403, loss=1.4489893913269043
train: epoch 38, loss 0.1346392035484314, acc=0.9557777643203735, loss=0.1346392035484314
test: epoch 38, loss 1.2842620611190796, acc=0.6138888597488403, loss=1.2842620611190796
train: epoch 39, loss 0.135260671377182, acc=0.9562222361564636, loss=0.135260671377182
test: epoch 39, loss 1.172243595123291, acc=0.6694444417953491, loss=1.172243595123291
train: epoch 40, loss 0.12939704954624176, acc=0.9601110816001892, loss=0.12939704954624176
test: epoch 40, loss 1.253269076347351, acc=0.6944444179534912, loss=1.253269076347351
train: epoch 41, loss 0.12003340572118759, acc=0.9627222418785095, loss=0.12003340572118759
test: epoch 41, loss 0.8899634480476379, acc=0.7194444537162781, loss=0.8899634480476379
train: epoch 42, loss 0.12531115114688873, acc=0.9601110816001892, loss=0.12531115114688873
test: epoch 42, loss 0.977608323097229, acc=0.7416666746139526, loss=0.977608323097229
train: epoch 43, loss 0.1251261681318283, acc=0.9608888626098633, loss=0.1251261681318283
test: epoch 43, loss 0.6889098286628723, acc=0.7888888716697693, loss=0.6889098286628723
train: epoch 44, loss 0.12315323948860168, acc=0.9611111283302307, loss=0.12315323948860168
test: epoch 44, loss 0.606941819190979, acc=0.8138889074325562, loss=0.606941819190979
train: epoch 45, loss 0.11645729094743729, acc=0.9641110897064209, loss=0.11645729094743729
test: epoch 45, loss 0.842958927154541, acc=0.7777777910232544, loss=0.842958927154541
train: epoch 46, loss 0.12452159821987152, acc=0.9603888988494873, loss=0.12452159821987152
test: epoch 46, loss 0.6647518873214722, acc=0.824999988079071, loss=0.6647518873214722
train: epoch 47, loss 0.11240921169519424, acc=0.9631666541099548, loss=0.11240921169519424
test: epoch 47, loss 0.5929296612739563, acc=0.8277778029441833, loss=0.5929296612739563
train: epoch 48, loss 0.09863868355751038, acc=0.9678888916969299, loss=0.09863868355751038
test: epoch 48, loss 0.6379157900810242, acc=0.8388888835906982, loss=0.6379157900810242
train: epoch 49, loss 0.10910779982805252, acc=0.965666651725769, loss=0.10910779982805252
test: epoch 49, loss 0.6078115701675415, acc=0.8361111283302307, loss=0.6078115701675415
train: epoch 50, loss 0.08800703287124634, acc=0.971833348274231, loss=0.08800703287124634
test: epoch 50, loss 0.487775593996048, acc=0.8611111044883728, loss=0.487775593996048
train: epoch 51, loss 0.0932883769273758, acc=0.9706110954284668, loss=0.0932883769273758
test: epoch 51, loss 0.4913053512573242, acc=0.8333333134651184, loss=0.4913053512573242
train: epoch 52, loss 0.09436007589101791, acc=0.9698333144187927, loss=0.09436007589101791
test: epoch 52, loss 0.5577130913734436, acc=0.8444444537162781, loss=0.5577130913734436
train: epoch 53, loss 0.09535057097673416, acc=0.9697777628898621, loss=0.09535057097673416
test: epoch 53, loss 0.4574698805809021, acc=0.8666666746139526, loss=0.4574698805809021
train: epoch 54, loss 0.10614794492721558, acc=0.9668889045715332, loss=0.10614794492721558
test: epoch 54, loss 0.42681533098220825, acc=0.875, loss=0.42681533098220825
train: epoch 55, loss 0.08924362808465958, acc=0.9710555672645569, loss=0.08924362808465958
test: epoch 55, loss 0.3036535680294037, acc=0.9194444417953491, loss=0.3036535680294037
train: epoch 56, loss 0.08348961919546127, acc=0.9710555672645569, loss=0.08348961919546127
test: epoch 56, loss 0.27931684255599976, acc=0.8999999761581421, loss=0.27931684255599976
train: epoch 57, loss 0.08110890537500381, acc=0.9738333225250244, loss=0.08110890537500381
test: epoch 57, loss 0.4710201919078827, acc=0.8888888955116272, loss=0.4710201919078827
train: epoch 58, loss 0.08687026053667068, acc=0.9710555672645569, loss=0.08687026053667068
test: epoch 58, loss 0.27204570174217224, acc=0.9194444417953491, loss=0.27204570174217224
train: epoch 59, loss 0.07293274998664856, acc=0.9763333201408386, loss=0.07293274998664856
test: epoch 59, loss 0.2456732988357544, acc=0.9361110925674438, loss=0.2456732988357544
train: epoch 60, loss 0.07476875931024551, acc=0.9742222428321838, loss=0.07476875931024551
test: epoch 60, loss 0.19624951481819153, acc=0.9222221970558167, loss=0.19624951481819153
train: epoch 61, loss 0.08087041229009628, acc=0.9733333587646484, loss=0.08087041229009628
test: epoch 61, loss 0.24028244614601135, acc=0.9222221970558167, loss=0.24028244614601135
train: epoch 62, loss 0.08210553973913193, acc=0.9706666469573975, loss=0.08210553973913193
test: epoch 62, loss 0.26191970705986023, acc=0.9222221970558167, loss=0.26191970705986023
train: epoch 63, loss 0.0677567720413208, acc=0.9777777791023254, loss=0.0677567720413208
test: epoch 63, loss 0.23363398015499115, acc=0.925000011920929, loss=0.23363398015499115
train: epoch 64, loss 0.06828165799379349, acc=0.9772777557373047, loss=0.06828165799379349
test: epoch 64, loss 0.20273645222187042, acc=0.9277777671813965, loss=0.20273645222187042
train: epoch 65, loss 0.06419312953948975, acc=0.9768333435058594, loss=0.06419312953948975
test: epoch 65, loss 0.16865472495555878, acc=0.9388889074325562, loss=0.16865472495555878
train: epoch 66, loss 0.07104368507862091, acc=0.977055549621582, loss=0.07104368507862091
test: epoch 66, loss 0.17119765281677246, acc=0.9388889074325562, loss=0.17119765281677246
train: epoch 67, loss 0.07330292463302612, acc=0.9753888845443726, loss=0.07330292463302612
test: epoch 67, loss 0.14821836352348328, acc=0.9388889074325562, loss=0.14821836352348328
train: epoch 68, loss 0.08109065145254135, acc=0.9731666445732117, loss=0.08109065145254135
test: epoch 68, loss 0.17830856144428253, acc=0.9305555820465088, loss=0.17830856144428253
train: epoch 69, loss 0.059194400906562805, acc=0.9789444208145142, loss=0.059194400906562805
test: epoch 69, loss 0.16602469980716705, acc=0.9388889074325562, loss=0.16602469980716705
train: epoch 70, loss 0.07242800295352936, acc=0.9743333458900452, loss=0.07242800295352936
test: epoch 70, loss 0.15512029826641083, acc=0.9388889074325562, loss=0.15512029826641083
train: epoch 71, loss 0.06971706449985504, acc=0.9783889055252075, loss=0.06971706449985504
test: epoch 71, loss 0.17012596130371094, acc=0.9361110925674438, loss=0.17012596130371094
train: epoch 72, loss 0.05490516126155853, acc=0.9801666736602783, loss=0.05490516126155853
test: epoch 72, loss 0.22402000427246094, acc=0.9361110925674438, loss=0.22402000427246094
train: epoch 73, loss 0.07025976479053497, acc=0.9751111268997192, loss=0.07025976479053497
test: epoch 73, loss 0.24537214636802673, acc=0.925000011920929, loss=0.24537214636802673
train: epoch 74, loss 0.08572755753993988, acc=0.971833348274231, loss=0.08572755753993988
test: epoch 74, loss 0.16916629672050476, acc=0.9361110925674438, loss=0.16916629672050476
train: epoch 75, loss 0.07147417962551117, acc=0.9751666784286499, loss=0.07147417962551117
test: epoch 75, loss 0.21384017169475555, acc=0.9361110925674438, loss=0.21384017169475555
train: epoch 76, loss 0.07895953953266144, acc=0.976277768611908, loss=0.07895953953266144
test: epoch 76, loss 0.23536856472492218, acc=0.9361110925674438, loss=0.23536856472492218
train: epoch 77, loss 0.06201614439487457, acc=0.9786111116409302, loss=0.06201614439487457
test: epoch 77, loss 0.2135762870311737, acc=0.9361110925674438, loss=0.2135762870311737
train: epoch 78, loss 0.06779883801937103, acc=0.9765555262565613, loss=0.06779883801937103
test: epoch 78, loss 0.20155568420886993, acc=0.9361110925674438, loss=0.20155568420886993
train: epoch 79, loss 0.07000405341386795, acc=0.9746111035346985, loss=0.07000405341386795
test: epoch 79, loss 0.18417759239673615, acc=0.9361110925674438, loss=0.18417759239673615
train: epoch 80, loss 0.0653022900223732, acc=0.9776111245155334, loss=0.0653022900223732
test: epoch 80, loss 0.1760583072900772, acc=0.9388889074325562, loss=0.1760583072900772
train: epoch 81, loss 0.07157139480113983, acc=0.9743333458900452, loss=0.07157139480113983
test: epoch 81, loss 0.2994410991668701, acc=0.9333333373069763, loss=0.2994410991668701
train: epoch 82, loss 0.08168590068817139, acc=0.973111093044281, loss=0.08168590068817139
test: epoch 82, loss 0.2038823962211609, acc=0.9333333373069763, loss=0.2038823962211609
train: epoch 83, loss 0.08293189108371735, acc=0.9716110825538635, loss=0.08293189108371735
test: epoch 83, loss 0.1670810878276825, acc=0.9333333373069763, loss=0.1670810878276825
train: epoch 84, loss 0.07881758362054825, acc=0.972777783870697, loss=0.07881758362054825
test: epoch 84, loss 0.15748973190784454, acc=0.9333333373069763, loss=0.15748973190784454
train: epoch 85, loss 0.07012264430522919, acc=0.9764444231987, loss=0.07012264430522919
test: epoch 85, loss 0.17007684707641602, acc=0.9333333373069763, loss=0.17007684707641602
train: epoch 86, loss 0.07464373111724854, acc=0.9752777814865112, loss=0.07464373111724854
test: epoch 86, loss 0.15662948787212372, acc=0.9388889074325562, loss=0.15662948787212372
train: epoch 87, loss 0.06373601406812668, acc=0.977222204208374, loss=0.06373601406812668
test: epoch 87, loss 0.15582124888896942, acc=0.9361110925674438, loss=0.15582124888896942
train: epoch 88, loss 0.07369761914014816, acc=0.9756666421890259, loss=0.07369761914014816
test: epoch 88, loss 0.1721714287996292, acc=0.9361110925674438, loss=0.1721714287996292
train: epoch 89, loss 0.06495707482099533, acc=0.976111114025116, loss=0.06495707482099533
test: epoch 89, loss 0.18396127223968506, acc=0.9361110925674438, loss=0.18396127223968506
train: epoch 90, loss 0.07265482097864151, acc=0.9743333458900452, loss=0.07265482097864151
test: epoch 90, loss 0.22581401467323303, acc=0.9361110925674438, loss=0.22581401467323303
train: epoch 91, loss 0.07409942895174026, acc=0.9727222323417664, loss=0.07409942895174026
test: epoch 91, loss 0.21134917438030243, acc=0.9361110925674438, loss=0.21134917438030243
train: epoch 92, loss 0.07021825760602951, acc=0.975777804851532, loss=0.07021825760602951
test: epoch 92, loss 0.1797148585319519, acc=0.9361110925674438, loss=0.1797148585319519
train: epoch 93, loss 0.06580386310815811, acc=0.9735555648803711, loss=0.06580386310815811
test: epoch 93, loss 0.1904478520154953, acc=0.9361110925674438, loss=0.1904478520154953
train: epoch 94, loss 0.0698108822107315, acc=0.9721666574478149, loss=0.0698108822107315
test: epoch 94, loss 0.16907724738121033, acc=0.9361110925674438, loss=0.16907724738121033
train: epoch 95, loss 0.07022538036108017, acc=0.9734444618225098, loss=0.07022538036108017
test: epoch 95, loss 0.16580289602279663, acc=0.9388889074325562, loss=0.16580289602279663
train: epoch 96, loss 0.07044190913438797, acc=0.9722222089767456, loss=0.07044190913438797
test: epoch 96, loss 0.14852218329906464, acc=0.9361110925674438, loss=0.14852218329906464
train: epoch 97, loss 0.07920726388692856, acc=0.9730555415153503, loss=0.07920726388692856
test: epoch 97, loss 0.1629067361354828, acc=0.9333333373069763, loss=0.1629067361354828
train: epoch 98, loss 0.0721215084195137, acc=0.9746111035346985, loss=0.0721215084195137
test: epoch 98, loss 0.2189255654811859, acc=0.9361110925674438, loss=0.2189255654811859
train: epoch 99, loss 0.0728069394826889, acc=0.9735555648803711, loss=0.0728069394826889
test: epoch 99, loss 0.1684265434741974, acc=0.9388889074325562, loss=0.1684265434741974
train: epoch 100, loss 0.08623160421848297, acc=0.9705555438995361, loss=0.08623160421848297
test: epoch 100, loss 0.17842566967010498, acc=0.9361110925674438, loss=0.17842566967010498
train: epoch 101, loss 0.06383183598518372, acc=0.9744444489479065, loss=0.06383183598518372
test: epoch 101, loss 0.17133551836013794, acc=0.9361110925674438, loss=0.17133551836013794
train: epoch 102, loss 0.0690489187836647, acc=0.9741666913032532, loss=0.0690489187836647
test: epoch 102, loss 0.18969114124774933, acc=0.9361110925674438, loss=0.18969114124774933
train: epoch 103, loss 0.07502254843711853, acc=0.9722222089767456, loss=0.07502254843711853
test: epoch 103, loss 0.23769737780094147, acc=0.9194444417953491, loss=0.23769737780094147
train: epoch 104, loss 0.06817077100276947, acc=0.9744444489479065, loss=0.06817077100276947
test: epoch 104, loss 0.1686284989118576, acc=0.9361110925674438, loss=0.1686284989118576
train: epoch 105, loss 0.05781660974025726, acc=0.9783333539962769, loss=0.05781660974025726
test: epoch 105, loss 0.18729515373706818, acc=0.9361110925674438, loss=0.18729515373706818
train: epoch 106, loss 0.08485004305839539, acc=0.9742222428321838, loss=0.08485004305839539
test: epoch 106, loss 0.18184204399585724, acc=0.9361110925674438, loss=0.18184204399585724
train: epoch 107, loss 0.066893570125103, acc=0.9765555262565613, loss=0.066893570125103
test: epoch 107, loss 0.18640704452991486, acc=0.9361110925674438, loss=0.18640704452991486
train: epoch 108, loss 0.0681164339184761, acc=0.9733333587646484, loss=0.0681164339184761
test: epoch 108, loss 0.13954651355743408, acc=0.9361110925674438, loss=0.13954651355743408
train: epoch 109, loss 0.06290675699710846, acc=0.9762222170829773, loss=0.06290675699710846
test: epoch 109, loss 0.14684632420539856, acc=0.9361110925674438, loss=0.14684632420539856
train: epoch 110, loss 0.06614436954259872, acc=0.9736111164093018, loss=0.06614436954259872
test: epoch 110, loss 0.14171935617923737, acc=0.9361110925674438, loss=0.14171935617923737
train: epoch 111, loss 0.0667516440153122, acc=0.9774444699287415, loss=0.0667516440153122
test: epoch 111, loss 0.1949891597032547, acc=0.9361110925674438, loss=0.1949891597032547
train: epoch 112, loss 0.0637524351477623, acc=0.9778888821601868, loss=0.0637524351477623
test: epoch 112, loss 0.14940199255943298, acc=0.9388889074325562, loss=0.14940199255943298
train: epoch 113, loss 0.06423857063055038, acc=0.9768333435058594, loss=0.06423857063055038
test: epoch 113, loss 0.15257416665554047, acc=0.9361110925674438, loss=0.15257416665554047
train: epoch 114, loss 0.06764882057905197, acc=0.9736666679382324, loss=0.06764882057905197
test: epoch 114, loss 0.18078206479549408, acc=0.9361110925674438, loss=0.18078206479549408
train: epoch 115, loss 0.08089777082204819, acc=0.9739444255828857, loss=0.08089777082204819
test: epoch 115, loss 0.17420493066310883, acc=0.9194444417953491, loss=0.17420493066310883
train: epoch 116, loss 0.12186656892299652, acc=0.9568889141082764, loss=0.12186656892299652
test: epoch 116, loss 0.21744313836097717, acc=0.9166666865348816, loss=0.21744313836097717
train: epoch 117, loss 0.10213455557823181, acc=0.9589999914169312, loss=0.10213455557823181
test: epoch 117, loss 0.17562489211559296, acc=0.9222221970558167, loss=0.17562489211559296
train: epoch 118, loss 0.10278118401765823, acc=0.9614999890327454, loss=0.10278118401765823
test: epoch 118, loss 0.17242783308029175, acc=0.9305555820465088, loss=0.17242783308029175
train: epoch 119, loss 0.08459369093179703, acc=0.9716110825538635, loss=0.08459369093179703
test: epoch 119, loss 0.16863186657428741, acc=0.9277777671813965, loss=0.16863186657428741
train: epoch 120, loss 0.0751352310180664, acc=0.9735000133514404, loss=0.0751352310180664
test: epoch 120, loss 0.23091310262680054, acc=0.9305555820465088, loss=0.23091310262680054
train: epoch 121, loss 0.07796771824359894, acc=0.9714999794960022, loss=0.07796771824359894
test: epoch 121, loss 0.14986228942871094, acc=0.9333333373069763, loss=0.14986228942871094
train: epoch 122, loss 0.06974538415670395, acc=0.976111114025116, loss=0.06974538415670395
test: epoch 122, loss 0.19896987080574036, acc=0.9333333373069763, loss=0.19896987080574036
train: epoch 123, loss 0.06794634461402893, acc=0.9751666784286499, loss=0.06794634461402893
test: epoch 123, loss 0.16628947854042053, acc=0.9333333373069763, loss=0.16628947854042053
train: epoch 124, loss 0.06714053452014923, acc=0.9750555753707886, loss=0.06714053452014923
test: epoch 124, loss 0.18256036937236786, acc=0.9333333373069763, loss=0.18256036937236786
train: epoch 125, loss 0.06912446022033691, acc=0.9750000238418579, loss=0.06912446022033691
test: epoch 125, loss 0.2122437059879303, acc=0.9333333373069763, loss=0.2122437059879303
train: epoch 126, loss 0.0694149062037468, acc=0.9767777919769287, loss=0.0694149062037468
test: epoch 126, loss 0.19306327402591705, acc=0.9333333373069763, loss=0.19306327402591705
train: epoch 127, loss 0.07541529089212418, acc=0.9743333458900452, loss=0.07541529089212418
test: epoch 127, loss 0.1518273949623108, acc=0.9361110925674438, loss=0.1518273949623108
train: epoch 128, loss 0.07247225940227509, acc=0.9752222299575806, loss=0.07247225940227509
test: epoch 128, loss 0.13277700543403625, acc=0.9333333373069763, loss=0.13277700543403625
train: epoch 129, loss 0.06982987374067307, acc=0.9751111268997192, loss=0.06982987374067307
test: epoch 129, loss 0.1374703198671341, acc=0.9333333373069763, loss=0.1374703198671341
train: epoch 130, loss 0.06789325177669525, acc=0.9752777814865112, loss=0.06789325177669525
test: epoch 130, loss 0.12432778626680374, acc=0.9333333373069763, loss=0.12432778626680374
train: epoch 131, loss 0.06387925148010254, acc=0.9775555729866028, loss=0.06387925148010254
test: epoch 131, loss 0.15687300264835358, acc=0.9333333373069763, loss=0.15687300264835358
train: epoch 132, loss 0.0657302662730217, acc=0.9771666526794434, loss=0.0657302662730217
test: epoch 132, loss 0.1811681091785431, acc=0.9333333373069763, loss=0.1811681091785431
train: epoch 133, loss 0.06143698841333389, acc=0.9783333539962769, loss=0.06143698841333389
test: epoch 133, loss 0.20223301649093628, acc=0.9333333373069763, loss=0.20223301649093628
train: epoch 134, loss 0.06618589162826538, acc=0.9778888821601868, loss=0.06618589162826538
test: epoch 134, loss 0.14879262447357178, acc=0.9333333373069763, loss=0.14879262447357178
train: epoch 135, loss 0.06366721540689468, acc=0.9775555729866028, loss=0.06366721540689468
test: epoch 135, loss 0.1797659993171692, acc=0.9333333373069763, loss=0.1797659993171692
train: epoch 136, loss 0.08002031594514847, acc=0.9750000238418579, loss=0.08002031594514847
test: epoch 136, loss 0.2463635802268982, acc=0.9277777671813965, loss=0.2463635802268982
train: epoch 137, loss 0.08529637008905411, acc=0.9709444642066956, loss=0.08529637008905411
test: epoch 137, loss 0.19081883132457733, acc=0.9305555820465088, loss=0.19081883132457733
train: epoch 138, loss 0.07568469643592834, acc=0.9736111164093018, loss=0.07568469643592834
test: epoch 138, loss 0.2035897672176361, acc=0.9305555820465088, loss=0.2035897672176361
train: epoch 139, loss 0.08600915968418121, acc=0.972611129283905, loss=0.08600915968418121
test: epoch 139, loss 0.18018124997615814, acc=0.9277777671813965, loss=0.18018124997615814
train: epoch 140, loss 0.08909640461206436, acc=0.9725000262260437, loss=0.08909640461206436
test: epoch 140, loss 0.18340066075325012, acc=0.9305555820465088, loss=0.18340066075325012
train: epoch 141, loss 0.08409402519464493, acc=0.9724444150924683, loss=0.08409402519464493
test: epoch 141, loss 0.20559680461883545, acc=0.9305555820465088, loss=0.20559680461883545
train: epoch 142, loss 0.07623268663883209, acc=0.9735555648803711, loss=0.07623268663883209
test: epoch 142, loss 0.16627249121665955, acc=0.9305555820465088, loss=0.16627249121665955
train: epoch 143, loss 0.09219930320978165, acc=0.9713333249092102, loss=0.09219930320978165
test: epoch 143, loss 0.18951119482517242, acc=0.9305555820465088, loss=0.18951119482517242
train: epoch 144, loss 0.07854282855987549, acc=0.9728333353996277, loss=0.07854282855987549
test: epoch 144, loss 0.19847317039966583, acc=0.9305555820465088, loss=0.19847317039966583
train: epoch 145, loss 0.07276953011751175, acc=0.9748333096504211, loss=0.07276953011751175
test: epoch 145, loss 0.17422275245189667, acc=0.9305555820465088, loss=0.17422275245189667
train: epoch 146, loss 0.08261896669864655, acc=0.9713333249092102, loss=0.08261896669864655
test: epoch 146, loss 0.17215891182422638, acc=0.9305555820465088, loss=0.17215891182422638
train: epoch 147, loss 0.11295976489782333, acc=0.9680555462837219, loss=0.11295976489782333
test: epoch 147, loss 0.18367843329906464, acc=0.9305555820465088, loss=0.18367843329906464
train: epoch 148, loss 0.09723559767007828, acc=0.9710000157356262, loss=0.09723559767007828
test: epoch 148, loss 0.1871359944343567, acc=0.9305555820465088, loss=0.1871359944343567
train: epoch 149, loss 0.07759754359722137, acc=0.973111093044281, loss=0.07759754359722137
test: epoch 149, loss 0.1517888456583023, acc=0.9305555820465088, loss=0.1517888456583023
train: epoch 150, loss 0.07925444841384888, acc=0.9717222452163696, loss=0.07925444841384888
test: epoch 150, loss 0.1451510637998581, acc=0.9333333373069763, loss=0.1451510637998581
