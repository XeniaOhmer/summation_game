# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=1.5", "--temp_decay=0.99", "--one_hot=true", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=635655521, receiver_embed_dim=128, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.741274833679199, acc=0.11144444346427917, loss=2.741274833679199
test: epoch 1, loss 3.207367420196533, acc=0.13055555522441864, loss=3.207367420196533
train: epoch 2, loss 1.620758295059204, acc=0.36077776551246643, loss=1.620758295059204
test: epoch 2, loss 2.6365256309509277, acc=0.20555555820465088, loss=2.6365256309509277
train: epoch 3, loss 1.083807110786438, acc=0.5636666417121887, loss=1.083807110786438
test: epoch 3, loss 2.173152446746826, acc=0.2611111104488373, loss=2.173152446746826
train: epoch 4, loss 0.8548281788825989, acc=0.6464999914169312, loss=0.8548281788825989
test: epoch 4, loss 2.010671615600586, acc=0.29722222685813904, loss=2.010671615600586
train: epoch 5, loss 0.7377496957778931, acc=0.7012222409248352, loss=0.7377496957778931
test: epoch 5, loss 1.756664752960205, acc=0.32777777314186096, loss=1.756664752960205
train: epoch 6, loss 0.653870701789856, acc=0.7353888750076294, loss=0.653870701789856
test: epoch 6, loss 1.7760196924209595, acc=0.39444443583488464, loss=1.7760196924209595
train: epoch 7, loss 0.5932936668395996, acc=0.7586110830307007, loss=0.5932936668395996
test: epoch 7, loss 1.9297312498092651, acc=0.2638888955116272, loss=1.9297312498092651
train: epoch 8, loss 0.5305833220481873, acc=0.7853888869285583, loss=0.5305833220481873
test: epoch 8, loss 1.8036850690841675, acc=0.35277777910232544, loss=1.8036850690841675
train: epoch 9, loss 0.483910471200943, acc=0.8014444708824158, loss=0.483910471200943
test: epoch 9, loss 1.838351845741272, acc=0.44999998807907104, loss=1.838351845741272
train: epoch 10, loss 0.46537357568740845, acc=0.8087777495384216, loss=0.46537357568740845
test: epoch 10, loss 1.3712372779846191, acc=0.5055555701255798, loss=1.3712372779846191
train: epoch 11, loss 0.4223886728286743, acc=0.8247222304344177, loss=0.4223886728286743
test: epoch 11, loss 1.5504120588302612, acc=0.4416666626930237, loss=1.5504120588302612
train: epoch 12, loss 0.38585972785949707, acc=0.8397777676582336, loss=0.38585972785949707
test: epoch 12, loss 1.6119143962860107, acc=0.46388888359069824, loss=1.6119143962860107
train: epoch 13, loss 0.38541004061698914, acc=0.8417778015136719, loss=0.38541004061698914
test: epoch 13, loss 1.5460612773895264, acc=0.4749999940395355, loss=1.5460612773895264
train: epoch 14, loss 0.3622148931026459, acc=0.8486111164093018, loss=0.3622148931026459
test: epoch 14, loss 1.6729217767715454, acc=0.46388888359069824, loss=1.6729217767715454
train: epoch 15, loss 0.34681394696235657, acc=0.8535000085830688, loss=0.34681394696235657
test: epoch 15, loss 1.8495965003967285, acc=0.4444444477558136, loss=1.8495965003967285
train: epoch 16, loss 0.32620102167129517, acc=0.8648333549499512, loss=0.32620102167129517
test: epoch 16, loss 1.8992221355438232, acc=0.4694444537162781, loss=1.8992221355438232
train: epoch 17, loss 0.31276389956474304, acc=0.86772221326828, loss=0.31276389956474304
test: epoch 17, loss 1.6097965240478516, acc=0.5638889074325562, loss=1.6097965240478516
train: epoch 18, loss 0.290719598531723, acc=0.8793333172798157, loss=0.290719598531723
test: epoch 18, loss 1.5228121280670166, acc=0.5416666865348816, loss=1.5228121280670166
train: epoch 19, loss 0.3086702227592468, acc=0.8733333349227905, loss=0.3086702227592468
test: epoch 19, loss 1.5652750730514526, acc=0.5555555820465088, loss=1.5652750730514526
train: epoch 20, loss 0.26417747139930725, acc=0.8865000009536743, loss=0.26417747139930725
test: epoch 20, loss 1.4660743474960327, acc=0.5249999761581421, loss=1.4660743474960327
train: epoch 21, loss 0.2899092137813568, acc=0.8809999823570251, loss=0.2899092137813568
test: epoch 21, loss 1.1969982385635376, acc=0.6194444298744202, loss=1.1969982385635376
train: epoch 22, loss 0.2561028301715851, acc=0.8919444680213928, loss=0.2561028301715851
test: epoch 22, loss 1.3185412883758545, acc=0.6305555701255798, loss=1.3185412883758545
train: epoch 23, loss 0.25151410698890686, acc=0.8933888673782349, loss=0.25151410698890686
test: epoch 23, loss 1.7434260845184326, acc=0.605555534362793, loss=1.7434260845184326
train: epoch 24, loss 0.23556160926818848, acc=0.8986111283302307, loss=0.23556160926818848
test: epoch 24, loss 0.90810227394104, acc=0.6833333373069763, loss=0.90810227394104
train: epoch 25, loss 0.24499017000198364, acc=0.8964444398880005, loss=0.24499017000198364
test: epoch 25, loss 1.1905800104141235, acc=0.6416666507720947, loss=1.1905800104141235
train: epoch 26, loss 0.22792592644691467, acc=0.9013888835906982, loss=0.22792592644691467
test: epoch 26, loss 1.2628300189971924, acc=0.6833333373069763, loss=1.2628300189971924
train: epoch 27, loss 0.21959258615970612, acc=0.9052777886390686, loss=0.21959258615970612
test: epoch 27, loss 1.0369997024536133, acc=0.7222222089767456, loss=1.0369997024536133
train: epoch 28, loss 0.22904053330421448, acc=0.9044444561004639, loss=0.22904053330421448
test: epoch 28, loss 0.8029742240905762, acc=0.75, loss=0.8029742240905762
train: epoch 29, loss 0.21240895986557007, acc=0.9089444279670715, loss=0.21240895986557007
test: epoch 29, loss 0.6705370545387268, acc=0.769444465637207, loss=0.6705370545387268
train: epoch 30, loss 0.20145317912101746, acc=0.9131666421890259, loss=0.20145317912101746
test: epoch 30, loss 1.0138493776321411, acc=0.7861111164093018, loss=1.0138493776321411
train: epoch 31, loss 0.19877511262893677, acc=0.9146111011505127, loss=0.19877511262893677
test: epoch 31, loss 0.6799908876419067, acc=0.800000011920929, loss=0.6799908876419067
train: epoch 32, loss 0.19454367458820343, acc=0.9146111011505127, loss=0.19454367458820343
test: epoch 32, loss 0.8745231032371521, acc=0.7972221970558167, loss=0.8745231032371521
train: epoch 33, loss 0.18902301788330078, acc=0.9164444208145142, loss=0.18902301788330078
test: epoch 33, loss 0.7751799821853638, acc=0.7972221970558167, loss=0.7751799821853638
train: epoch 34, loss 0.18961560726165771, acc=0.9177777767181396, loss=0.18961560726165771
test: epoch 34, loss 0.635021984577179, acc=0.7944444417953491, loss=0.635021984577179
train: epoch 35, loss 0.19032375514507294, acc=0.9166666865348816, loss=0.19032375514507294
test: epoch 35, loss 0.8649412393569946, acc=0.7888888716697693, loss=0.8649412393569946
train: epoch 36, loss 0.1990601122379303, acc=0.914722204208374, loss=0.1990601122379303
test: epoch 36, loss 0.6919564008712769, acc=0.7861111164093018, loss=0.6919564008712769
train: epoch 37, loss 0.1850813925266266, acc=0.9192777872085571, loss=0.1850813925266266
test: epoch 37, loss 0.6797901391983032, acc=0.7972221970558167, loss=0.6797901391983032
train: epoch 38, loss 0.1815386563539505, acc=0.9183333516120911, loss=0.1815386563539505
test: epoch 38, loss 0.7413169145584106, acc=0.7916666865348816, loss=0.7413169145584106
train: epoch 39, loss 0.17751355469226837, acc=0.9181110858917236, loss=0.17751355469226837
test: epoch 39, loss 0.7508653402328491, acc=0.8027777671813965, loss=0.7508653402328491
train: epoch 40, loss 0.16271153092384338, acc=0.9228333234786987, loss=0.16271153092384338
test: epoch 40, loss 0.6725220084190369, acc=0.800000011920929, loss=0.6725220084190369
train: epoch 41, loss 0.17939575016498566, acc=0.9201111197471619, loss=0.17939575016498566
test: epoch 41, loss 0.830959141254425, acc=0.8083333373069763, loss=0.830959141254425
train: epoch 42, loss 0.19424448907375336, acc=0.9138888716697693, loss=0.19424448907375336
test: epoch 42, loss 0.5868785381317139, acc=0.8111110925674438, loss=0.5868785381317139
train: epoch 43, loss 0.1721721738576889, acc=0.9208889007568359, loss=0.1721721738576889
test: epoch 43, loss 0.6081326603889465, acc=0.8055555820465088, loss=0.6081326603889465
train: epoch 44, loss 0.1862819343805313, acc=0.9186111092567444, loss=0.1862819343805313
test: epoch 44, loss 0.44797852635383606, acc=0.800000011920929, loss=0.44797852635383606
train: epoch 45, loss 0.1868061125278473, acc=0.9196666479110718, loss=0.1868061125278473
test: epoch 45, loss 0.6160564422607422, acc=0.8055555820465088, loss=0.6160564422607422
train: epoch 46, loss 0.1785569190979004, acc=0.9220555424690247, loss=0.1785569190979004
test: epoch 46, loss 0.6986063718795776, acc=0.8111110925674438, loss=0.6986063718795776
train: epoch 47, loss 0.17243550717830658, acc=0.922166645526886, loss=0.17243550717830658
test: epoch 47, loss 0.6241665482521057, acc=0.8111110925674438, loss=0.6241665482521057
train: epoch 48, loss 0.18696531653404236, acc=0.9197221994400024, loss=0.18696531653404236
test: epoch 48, loss 0.5844643712043762, acc=0.8083333373069763, loss=0.5844643712043762
train: epoch 49, loss 0.18288162350654602, acc=0.9184444546699524, loss=0.18288162350654602
test: epoch 49, loss 0.5702829957008362, acc=0.8111110925674438, loss=0.5702829957008362
train: epoch 50, loss 0.1736093908548355, acc=0.9221110939979553, loss=0.1736093908548355
test: epoch 50, loss 0.5721997022628784, acc=0.8111110925674438, loss=0.5721997022628784
train: epoch 51, loss 0.17756228148937225, acc=0.9226111173629761, loss=0.17756228148937225
test: epoch 51, loss 0.5473670363426208, acc=0.8111110925674438, loss=0.5473670363426208
train: epoch 52, loss 0.17914292216300964, acc=0.9229444265365601, loss=0.17914292216300964
test: epoch 52, loss 0.5161895155906677, acc=0.8166666626930237, loss=0.5161895155906677
train: epoch 53, loss 0.1729251593351364, acc=0.9219444394111633, loss=0.1729251593351364
test: epoch 53, loss 0.6437445282936096, acc=0.8111110925674438, loss=0.6437445282936096
train: epoch 54, loss 0.17706529796123505, acc=0.9213333129882812, loss=0.17706529796123505
test: epoch 54, loss 0.6772376894950867, acc=0.8083333373069763, loss=0.6772376894950867
train: epoch 55, loss 0.18143410980701447, acc=0.920722246170044, loss=0.18143410980701447
test: epoch 55, loss 0.49940404295921326, acc=0.8111110925674438, loss=0.49940404295921326
train: epoch 56, loss 0.17487138509750366, acc=0.9217222332954407, loss=0.17487138509750366
test: epoch 56, loss 0.5787214040756226, acc=0.8111110925674438, loss=0.5787214040756226
train: epoch 57, loss 0.18046504259109497, acc=0.9208333492279053, loss=0.18046504259109497
test: epoch 57, loss 0.6022529006004333, acc=0.8111110925674438, loss=0.6022529006004333
train: epoch 58, loss 0.17548289895057678, acc=0.9202222228050232, loss=0.17548289895057678
test: epoch 58, loss 0.6143099069595337, acc=0.8111110925674438, loss=0.6143099069595337
train: epoch 59, loss 0.18198345601558685, acc=0.9218888878822327, loss=0.18198345601558685
test: epoch 59, loss 0.604999303817749, acc=0.8111110925674438, loss=0.604999303817749
train: epoch 60, loss 0.17416992783546448, acc=0.9237222075462341, loss=0.17416992783546448
test: epoch 60, loss 0.6032451391220093, acc=0.8111110925674438, loss=0.6032451391220093
train: epoch 61, loss 0.1725022941827774, acc=0.921833336353302, loss=0.1725022941827774
test: epoch 61, loss 0.6420308351516724, acc=0.8083333373069763, loss=0.6420308351516724
train: epoch 62, loss 0.1830325722694397, acc=0.9192777872085571, loss=0.1830325722694397
test: epoch 62, loss 0.6872624158859253, acc=0.8055555820465088, loss=0.6872624158859253
train: epoch 63, loss 0.18323148787021637, acc=0.9197777509689331, loss=0.18323148787021637
test: epoch 63, loss 0.5195711851119995, acc=0.8111110925674438, loss=0.5195711851119995
train: epoch 64, loss 0.18328943848609924, acc=0.9186111092567444, loss=0.18328943848609924
test: epoch 64, loss 0.5073183178901672, acc=0.8111110925674438, loss=0.5073183178901672
train: epoch 65, loss 0.1853179931640625, acc=0.9191666841506958, loss=0.1853179931640625
test: epoch 65, loss 0.5639929175376892, acc=0.8111110925674438, loss=0.5639929175376892
train: epoch 66, loss 0.18226854503154755, acc=0.9202777743339539, loss=0.18226854503154755
test: epoch 66, loss 0.5961569547653198, acc=0.8166666626930237, loss=0.5961569547653198
train: epoch 67, loss 0.1962154656648636, acc=0.9148333072662354, loss=0.1962154656648636
test: epoch 67, loss 0.517575740814209, acc=0.8111110925674438, loss=0.517575740814209
train: epoch 68, loss 0.1857793629169464, acc=0.917388916015625, loss=0.1857793629169464
test: epoch 68, loss 0.5448305010795593, acc=0.8111110925674438, loss=0.5448305010795593
train: epoch 69, loss 0.17865292727947235, acc=0.9192222356796265, loss=0.17865292727947235
test: epoch 69, loss 0.5327343344688416, acc=0.8111110925674438, loss=0.5327343344688416
train: epoch 70, loss 0.17628544569015503, acc=0.9200000166893005, loss=0.17628544569015503
test: epoch 70, loss 0.6172985434532166, acc=0.8055555820465088, loss=0.6172985434532166
train: epoch 71, loss 0.18289539217948914, acc=0.9187222123146057, loss=0.18289539217948914
test: epoch 71, loss 0.49811792373657227, acc=0.8083333373069763, loss=0.49811792373657227
train: epoch 72, loss 0.1850818395614624, acc=0.9169999957084656, loss=0.1850818395614624
test: epoch 72, loss 0.5417624115943909, acc=0.8111110925674438, loss=0.5417624115943909
train: epoch 73, loss 0.17672860622406006, acc=0.9206666946411133, loss=0.17672860622406006
test: epoch 73, loss 0.6738901734352112, acc=0.8111110925674438, loss=0.6738901734352112
train: epoch 74, loss 0.17631106078624725, acc=0.9196666479110718, loss=0.17631106078624725
test: epoch 74, loss 0.6155765056610107, acc=0.8166666626930237, loss=0.6155765056610107
train: epoch 75, loss 0.16729478538036346, acc=0.9233333468437195, loss=0.16729478538036346
test: epoch 75, loss 0.5368714332580566, acc=0.8111110925674438, loss=0.5368714332580566
train: epoch 76, loss 0.166965052485466, acc=0.9243333339691162, loss=0.166965052485466
test: epoch 76, loss 0.544417679309845, acc=0.8111110925674438, loss=0.544417679309845
train: epoch 77, loss 0.1629343181848526, acc=0.925944447517395, loss=0.1629343181848526
test: epoch 77, loss 0.5304781794548035, acc=0.8166666626930237, loss=0.5304781794548035
train: epoch 78, loss 0.17914369702339172, acc=0.9235000014305115, loss=0.17914369702339172
test: epoch 78, loss 0.6366204023361206, acc=0.8111110925674438, loss=0.6366204023361206
train: epoch 79, loss 0.18096743524074554, acc=0.9182222485542297, loss=0.18096743524074554
test: epoch 79, loss 0.5968649983406067, acc=0.8055555820465088, loss=0.5968649983406067
train: epoch 80, loss 0.15844309329986572, acc=0.9271110892295837, loss=0.15844309329986572
test: epoch 80, loss 0.6325998306274414, acc=0.8111110925674438, loss=0.6325998306274414
train: epoch 81, loss 0.1803462654352188, acc=0.9228333234786987, loss=0.1803462654352188
test: epoch 81, loss 0.4826945960521698, acc=0.8111110925674438, loss=0.4826945960521698
train: epoch 82, loss 0.17172008752822876, acc=0.9228888750076294, loss=0.17172008752822876
test: epoch 82, loss 0.6179997324943542, acc=0.8111110925674438, loss=0.6179997324943542
train: epoch 83, loss 0.1592140644788742, acc=0.9244999885559082, loss=0.1592140644788742
test: epoch 83, loss 0.6912193298339844, acc=0.8083333373069763, loss=0.6912193298339844
train: epoch 84, loss 0.16596762835979462, acc=0.9229999780654907, loss=0.16596762835979462
test: epoch 84, loss 0.5099950432777405, acc=0.8111110925674438, loss=0.5099950432777405
train: epoch 85, loss 0.17031072080135345, acc=0.9209444522857666, loss=0.17031072080135345
test: epoch 85, loss 0.566299557685852, acc=0.8111110925674438, loss=0.566299557685852
train: epoch 86, loss 0.15504847466945648, acc=0.9262222051620483, loss=0.15504847466945648
test: epoch 86, loss 0.6629176735877991, acc=0.8111110925674438, loss=0.6629176735877991
train: epoch 87, loss 0.16026556491851807, acc=0.9263888597488403, loss=0.16026556491851807
test: epoch 87, loss 0.6297951936721802, acc=0.8111110925674438, loss=0.6297951936721802
train: epoch 88, loss 0.16660413146018982, acc=0.9256666898727417, loss=0.16660413146018982
test: epoch 88, loss 0.6533626317977905, acc=0.8111110925674438, loss=0.6533626317977905
train: epoch 89, loss 0.1776863932609558, acc=0.9208889007568359, loss=0.1776863932609558
test: epoch 89, loss 0.5642147660255432, acc=0.8055555820465088, loss=0.5642147660255432
train: epoch 90, loss 0.15672682225704193, acc=0.9294999837875366, loss=0.15672682225704193
test: epoch 90, loss 0.6275944113731384, acc=0.8055555820465088, loss=0.6275944113731384
train: epoch 91, loss 0.15160109102725983, acc=0.9502221941947937, loss=0.15160109102725983
test: epoch 91, loss 0.6134785413742065, acc=0.800000011920929, loss=0.6134785413742065
train: epoch 92, loss 0.12539207935333252, acc=0.9578889012336731, loss=0.12539207935333252
test: epoch 92, loss 0.714205265045166, acc=0.8055555820465088, loss=0.714205265045166
train: epoch 93, loss 0.1321505755186081, acc=0.9549999833106995, loss=0.1321505755186081
test: epoch 93, loss 0.6121656894683838, acc=0.8055555820465088, loss=0.6121656894683838
train: epoch 94, loss 0.13725322484970093, acc=0.9524444341659546, loss=0.13725322484970093
test: epoch 94, loss 0.7078161835670471, acc=0.8055555820465088, loss=0.7078161835670471
train: epoch 95, loss 0.12441031634807587, acc=0.9582222104072571, loss=0.12441031634807587
test: epoch 95, loss 0.6908764839172363, acc=0.8027777671813965, loss=0.6908764839172363
train: epoch 96, loss 0.1349610835313797, acc=0.9539999961853027, loss=0.1349610835313797
test: epoch 96, loss 0.6446471214294434, acc=0.800000011920929, loss=0.6446471214294434
train: epoch 97, loss 0.13381463289260864, acc=0.9539999961853027, loss=0.13381463289260864
test: epoch 97, loss 0.6649336218833923, acc=0.8055555820465088, loss=0.6649336218833923
train: epoch 98, loss 0.1133231520652771, acc=0.9601110816001892, loss=0.1133231520652771
test: epoch 98, loss 0.7630476355552673, acc=0.8055555820465088, loss=0.7630476355552673
train: epoch 99, loss 0.11537127196788788, acc=0.9596111178398132, loss=0.11537127196788788
test: epoch 99, loss 0.6603590250015259, acc=0.8027777671813965, loss=0.6603590250015259
train: epoch 100, loss 0.11723420023918152, acc=0.9581111073493958, loss=0.11723420023918152
test: epoch 100, loss 0.6251412630081177, acc=0.8055555820465088, loss=0.6251412630081177
train: epoch 101, loss 0.10700284689664841, acc=0.9636666774749756, loss=0.10700284689664841
test: epoch 101, loss 0.5959442257881165, acc=0.8111110925674438, loss=0.5959442257881165
train: epoch 102, loss 0.12255401909351349, acc=0.9579444527626038, loss=0.12255401909351349
test: epoch 102, loss 0.5840895771980286, acc=0.8055555820465088, loss=0.5840895771980286
train: epoch 103, loss 0.12683701515197754, acc=0.9555000066757202, loss=0.12683701515197754
test: epoch 103, loss 0.6610104441642761, acc=0.8083333373069763, loss=0.6610104441642761
train: epoch 104, loss 0.1307164877653122, acc=0.9555000066757202, loss=0.1307164877653122
test: epoch 104, loss 0.836499035358429, acc=0.8027777671813965, loss=0.836499035358429
train: epoch 105, loss 0.12078047543764114, acc=0.9603888988494873, loss=0.12078047543764114
test: epoch 105, loss 0.5969836115837097, acc=0.8027777671813965, loss=0.5969836115837097
train: epoch 106, loss 0.11984071880578995, acc=0.9581666588783264, loss=0.11984071880578995
test: epoch 106, loss 0.6830536127090454, acc=0.8027777671813965, loss=0.6830536127090454
train: epoch 107, loss 0.1211957260966301, acc=0.956944465637207, loss=0.1211957260966301
test: epoch 107, loss 0.6037538647651672, acc=0.8027777671813965, loss=0.6037538647651672
train: epoch 108, loss 0.11645388603210449, acc=0.9599444270133972, loss=0.11645388603210449
test: epoch 108, loss 0.6432012319564819, acc=0.8027777671813965, loss=0.6432012319564819
train: epoch 109, loss 0.12890319526195526, acc=0.9548333287239075, loss=0.12890319526195526
test: epoch 109, loss 0.5598998069763184, acc=0.8027777671813965, loss=0.5598998069763184
train: epoch 110, loss 0.12553517520427704, acc=0.9560555815696716, loss=0.12553517520427704
test: epoch 110, loss 0.6597892642021179, acc=0.8027777671813965, loss=0.6597892642021179
train: epoch 111, loss 0.12711142003536224, acc=0.9550555348396301, loss=0.12711142003536224
test: epoch 111, loss 0.6391003131866455, acc=0.8027777671813965, loss=0.6391003131866455
train: epoch 112, loss 0.11432632803916931, acc=0.9608888626098633, loss=0.11432632803916931
test: epoch 112, loss 0.781802237033844, acc=0.8027777671813965, loss=0.781802237033844
train: epoch 113, loss 0.1128803938627243, acc=0.9601110816001892, loss=0.1128803938627243
test: epoch 113, loss 0.6189644932746887, acc=0.8027777671813965, loss=0.6189644932746887
train: epoch 114, loss 0.1281971037387848, acc=0.9588333368301392, loss=0.1281971037387848
test: epoch 114, loss 0.6772634983062744, acc=0.8111110925674438, loss=0.6772634983062744
train: epoch 115, loss 0.13085268437862396, acc=0.9570555686950684, loss=0.13085268437862396
test: epoch 115, loss 0.6787062287330627, acc=0.8027777671813965, loss=0.6787062287330627
train: epoch 116, loss 0.1184593066573143, acc=0.9593889117240906, loss=0.1184593066573143
test: epoch 116, loss 0.6684842109680176, acc=0.8027777671813965, loss=0.6684842109680176
train: epoch 117, loss 0.15795594453811646, acc=0.9492777585983276, loss=0.15795594453811646
test: epoch 117, loss 0.6967835426330566, acc=0.7944444417953491, loss=0.6967835426330566
train: epoch 118, loss 0.11689876765012741, acc=0.9600555300712585, loss=0.11689876765012741
test: epoch 118, loss 0.6662778258323669, acc=0.8027777671813965, loss=0.6662778258323669
train: epoch 119, loss 0.12797288596630096, acc=0.9545000195503235, loss=0.12797288596630096
test: epoch 119, loss 0.6172116994857788, acc=0.8138889074325562, loss=0.6172116994857788
train: epoch 120, loss 0.10935544967651367, acc=0.9599444270133972, loss=0.10935544967651367
test: epoch 120, loss 0.6545326113700867, acc=0.8305555582046509, loss=0.6545326113700867
train: epoch 121, loss 0.10788634419441223, acc=0.9618333578109741, loss=0.10788634419441223
test: epoch 121, loss 0.6016305088996887, acc=0.8333333134651184, loss=0.6016305088996887
train: epoch 122, loss 0.10870546847581863, acc=0.9617778062820435, loss=0.10870546847581863
test: epoch 122, loss 0.62965989112854, acc=0.8333333134651184, loss=0.62965989112854
train: epoch 123, loss 0.11404340714216232, acc=0.9618889093399048, loss=0.11404340714216232
test: epoch 123, loss 0.5726247429847717, acc=0.8333333134651184, loss=0.5726247429847717
train: epoch 124, loss 0.1099526435136795, acc=0.9594444632530212, loss=0.1099526435136795
test: epoch 124, loss 0.671654999256134, acc=0.8388888835906982, loss=0.671654999256134
train: epoch 125, loss 0.11204454302787781, acc=0.9591110944747925, loss=0.11204454302787781
test: epoch 125, loss 0.5440654754638672, acc=0.8305555582046509, loss=0.5440654754638672
train: epoch 126, loss 0.10935012251138687, acc=0.9614999890327454, loss=0.10935012251138687
test: epoch 126, loss 0.6593466401100159, acc=0.8333333134651184, loss=0.6593466401100159
train: epoch 127, loss 0.10430063307285309, acc=0.9601666927337646, loss=0.10430063307285309
test: epoch 127, loss 0.6376714110374451, acc=0.8333333134651184, loss=0.6376714110374451
train: epoch 128, loss 0.10199443250894547, acc=0.9637777805328369, loss=0.10199443250894547
test: epoch 128, loss 0.5442957878112793, acc=0.8361111283302307, loss=0.5442957878112793
train: epoch 129, loss 0.0916438102722168, acc=0.9660555720329285, loss=0.0916438102722168
test: epoch 129, loss 0.6168900728225708, acc=0.8361111283302307, loss=0.6168900728225708
train: epoch 130, loss 0.09759461134672165, acc=0.9616666436195374, loss=0.09759461134672165
test: epoch 130, loss 0.5896207690238953, acc=0.8361111283302307, loss=0.5896207690238953
train: epoch 131, loss 0.13784387707710266, acc=0.9562777876853943, loss=0.13784387707710266
test: epoch 131, loss 0.4518578052520752, acc=0.8333333134651184, loss=0.4518578052520752
train: epoch 132, loss 0.11833839118480682, acc=0.9632222056388855, loss=0.11833839118480682
test: epoch 132, loss 0.5983619689941406, acc=0.8361111283302307, loss=0.5983619689941406
train: epoch 133, loss 0.11966006457805634, acc=0.9621111154556274, loss=0.11966006457805634
test: epoch 133, loss 0.5399438142776489, acc=0.8388888835906982, loss=0.5399438142776489
train: epoch 134, loss 0.11276846379041672, acc=0.9631666541099548, loss=0.11276846379041672
test: epoch 134, loss 0.5071157217025757, acc=0.8333333134651184, loss=0.5071157217025757
train: epoch 135, loss 0.12196573615074158, acc=0.960777759552002, loss=0.12196573615074158
test: epoch 135, loss 0.6343353986740112, acc=0.8333333134651184, loss=0.6343353986740112
train: epoch 136, loss 0.10464689135551453, acc=0.9656111001968384, loss=0.10464689135551453
test: epoch 136, loss 0.6110095977783203, acc=0.8333333134651184, loss=0.6110095977783203
train: epoch 137, loss 0.10989697277545929, acc=0.9644444584846497, loss=0.10989697277545929
test: epoch 137, loss 0.5165356993675232, acc=0.8333333134651184, loss=0.5165356993675232
train: epoch 138, loss 0.11145101487636566, acc=0.9618889093399048, loss=0.11145101487636566
test: epoch 138, loss 0.6230096220970154, acc=0.8333333134651184, loss=0.6230096220970154
train: epoch 139, loss 0.09648483246564865, acc=0.9641666412353516, loss=0.09648483246564865
test: epoch 139, loss 0.5741727948188782, acc=0.8333333134651184, loss=0.5741727948188782
train: epoch 140, loss 0.1129487007856369, acc=0.9603888988494873, loss=0.1129487007856369
test: epoch 140, loss 0.4728269875049591, acc=0.8333333134651184, loss=0.4728269875049591
train: epoch 141, loss 0.10790878534317017, acc=0.9625555276870728, loss=0.10790878534317017
test: epoch 141, loss 0.5486501455307007, acc=0.8333333134651184, loss=0.5486501455307007
train: epoch 142, loss 0.12992869317531586, acc=0.961388885974884, loss=0.12992869317531586
test: epoch 142, loss 0.5956674218177795, acc=0.8361111283302307, loss=0.5956674218177795
train: epoch 143, loss 0.10491635650396347, acc=0.9638888835906982, loss=0.10491635650396347
test: epoch 143, loss 0.6554383635520935, acc=0.8388888835906982, loss=0.6554383635520935
train: epoch 144, loss 0.11435533314943314, acc=0.9621111154556274, loss=0.11435533314943314
test: epoch 144, loss 0.5346559882164001, acc=0.8361111283302307, loss=0.5346559882164001
train: epoch 145, loss 0.11220136284828186, acc=0.9644444584846497, loss=0.11220136284828186
test: epoch 145, loss 0.6670160889625549, acc=0.8444444537162781, loss=0.6670160889625549
train: epoch 146, loss 0.11524620652198792, acc=0.9613333344459534, loss=0.11524620652198792
test: epoch 146, loss 0.537193775177002, acc=0.8666666746139526, loss=0.537193775177002
train: epoch 147, loss 0.1225481629371643, acc=0.9574999809265137, loss=0.1225481629371643
test: epoch 147, loss 0.36866694688796997, acc=0.8666666746139526, loss=0.36866694688796997
train: epoch 148, loss 0.11414871364831924, acc=0.9599999785423279, loss=0.11414871364831924
test: epoch 148, loss 0.4724658727645874, acc=0.8722222447395325, loss=0.4724658727645874
train: epoch 149, loss 0.11638014018535614, acc=0.9635555744171143, loss=0.11638014018535614
test: epoch 149, loss 0.4473682940006256, acc=0.8694444298744202, loss=0.4473682940006256
train: epoch 150, loss 0.10771676152944565, acc=0.9637777805328369, loss=0.10771676152944565
test: epoch 150, loss 0.42712488770484924, acc=0.8694444298744202, loss=0.42712488770484924
