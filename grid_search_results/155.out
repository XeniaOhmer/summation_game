# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=false", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1626271313, receiver_embed_dim=128, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.717688798904419, acc=0.11283333599567413, loss=2.717688798904419
test: epoch 1, loss 3.7771646976470947, acc=0.10555555671453476, loss=3.7771646976470947
train: epoch 2, loss 1.7085072994232178, acc=0.2823333442211151, loss=1.7085072994232178
test: epoch 2, loss 2.5676984786987305, acc=0.19166666269302368, loss=2.5676984786987305
train: epoch 3, loss 1.371462345123291, acc=0.4012777805328369, loss=1.371462345123291
test: epoch 3, loss 3.037569522857666, acc=0.23333333432674408, loss=3.037569522857666
train: epoch 4, loss 1.0489333868026733, acc=0.542722225189209, loss=1.0489333868026733
test: epoch 4, loss 3.017416000366211, acc=0.28333333134651184, loss=3.017416000366211
train: epoch 5, loss 0.8536170125007629, acc=0.6277777552604675, loss=0.8536170125007629
test: epoch 5, loss 2.4630260467529297, acc=0.32499998807907104, loss=2.4630260467529297
train: epoch 6, loss 0.7201945781707764, acc=0.6888333559036255, loss=0.7201945781707764
test: epoch 6, loss 2.0683953762054443, acc=0.38333332538604736, loss=2.0683953762054443
train: epoch 7, loss 0.6196634769439697, acc=0.7391666769981384, loss=0.6196634769439697
test: epoch 7, loss 1.7507660388946533, acc=0.4694444537162781, loss=1.7507660388946533
train: epoch 8, loss 0.4823251962661743, acc=0.7912222146987915, loss=0.4823251962661743
test: epoch 8, loss 1.9888197183609009, acc=0.46388888359069824, loss=1.9888197183609009
train: epoch 9, loss 0.45094776153564453, acc=0.8023333549499512, loss=0.45094776153564453
test: epoch 9, loss 1.335186243057251, acc=0.5944444537162781, loss=1.335186243057251
train: epoch 10, loss 0.4192761182785034, acc=0.8165000081062317, loss=0.4192761182785034
test: epoch 10, loss 1.3928889036178589, acc=0.5694444179534912, loss=1.3928889036178589
train: epoch 11, loss 0.35288119316101074, acc=0.8452222347259521, loss=0.35288119316101074
test: epoch 11, loss 1.1792820692062378, acc=0.6027777791023254, loss=1.1792820692062378
train: epoch 12, loss 0.327096551656723, acc=0.856166660785675, loss=0.327096551656723
test: epoch 12, loss 0.9909546971321106, acc=0.7138888835906982, loss=0.9909546971321106
train: epoch 13, loss 0.2844325304031372, acc=0.871222198009491, loss=0.2844325304031372
test: epoch 13, loss 1.12905752658844, acc=0.6305555701255798, loss=1.12905752658844
train: epoch 14, loss 0.2860051691532135, acc=0.8750555515289307, loss=0.2860051691532135
test: epoch 14, loss 1.1115819215774536, acc=0.6777777671813965, loss=1.1115819215774536
train: epoch 15, loss 0.2415294200181961, acc=0.8850555419921875, loss=0.2415294200181961
test: epoch 15, loss 1.294612169265747, acc=0.7111111283302307, loss=1.294612169265747
train: epoch 16, loss 0.25153642892837524, acc=0.8878333568572998, loss=0.25153642892837524
test: epoch 16, loss 0.9901748895645142, acc=0.7083333134651184, loss=0.9901748895645142
train: epoch 17, loss 0.2569178342819214, acc=0.8857222199440002, loss=0.2569178342819214
test: epoch 17, loss 0.9910512566566467, acc=0.7472222447395325, loss=0.9910512566566467
train: epoch 18, loss 0.2300070822238922, acc=0.8926110863685608, loss=0.2300070822238922
test: epoch 18, loss 0.6247321963310242, acc=0.7638888955116272, loss=0.6247321963310242
train: epoch 19, loss 0.2444116324186325, acc=0.8880555629730225, loss=0.2444116324186325
test: epoch 19, loss 0.5383761525154114, acc=0.7916666865348816, loss=0.5383761525154114
train: epoch 20, loss 0.22209659218788147, acc=0.8913888931274414, loss=0.22209659218788147
test: epoch 20, loss 0.7171337604522705, acc=0.7972221970558167, loss=0.7171337604522705
train: epoch 21, loss 0.23421022295951843, acc=0.891777753829956, loss=0.23421022295951843
test: epoch 21, loss 0.49945876002311707, acc=0.8416666388511658, loss=0.49945876002311707
train: epoch 22, loss 0.22382573783397675, acc=0.8964999914169312, loss=0.22382573783397675
test: epoch 22, loss 0.5299957990646362, acc=0.8472222089767456, loss=0.5299957990646362
train: epoch 23, loss 0.20854924619197845, acc=0.898277759552002, loss=0.20854924619197845
test: epoch 23, loss 0.35403332114219666, acc=0.8722222447395325, loss=0.35403332114219666
train: epoch 24, loss 0.25345301628112793, acc=0.8878333568572998, loss=0.25345301628112793
test: epoch 24, loss 0.46687495708465576, acc=0.824999988079071, loss=0.46687495708465576
train: epoch 25, loss 0.2184060662984848, acc=0.8976666927337646, loss=0.2184060662984848
test: epoch 25, loss 0.2343466430902481, acc=0.8777777552604675, loss=0.2343466430902481
train: epoch 26, loss 0.18341408669948578, acc=0.9027222394943237, loss=0.18341408669948578
test: epoch 26, loss 0.2522037923336029, acc=0.8888888955116272, loss=0.2522037923336029
train: epoch 27, loss 0.23692932724952698, acc=0.8937777876853943, loss=0.23692932724952698
test: epoch 27, loss 0.45217904448509216, acc=0.8444444537162781, loss=0.45217904448509216
train: epoch 28, loss 0.24098823964595795, acc=0.8877221941947937, loss=0.24098823964595795
test: epoch 28, loss 0.2673299014568329, acc=0.8805555701255798, loss=0.2673299014568329
train: epoch 29, loss 0.17916768789291382, acc=0.906166672706604, loss=0.17916768789291382
test: epoch 29, loss 0.314309686422348, acc=0.8722222447395325, loss=0.314309686422348
train: epoch 30, loss 0.2102413922548294, acc=0.8993333578109741, loss=0.2102413922548294
test: epoch 30, loss 0.2861156761646271, acc=0.8805555701255798, loss=0.2861156761646271
train: epoch 31, loss 0.1985524296760559, acc=0.9030555486679077, loss=0.1985524296760559
test: epoch 31, loss 0.333060622215271, acc=0.875, loss=0.333060622215271
train: epoch 32, loss 0.19662249088287354, acc=0.9066666960716248, loss=0.19662249088287354
test: epoch 32, loss 0.43265029788017273, acc=0.8666666746139526, loss=0.43265029788017273
train: epoch 33, loss 0.1925022304058075, acc=0.9088333249092102, loss=0.1925022304058075
test: epoch 33, loss 0.302528977394104, acc=0.8833333253860474, loss=0.302528977394104
train: epoch 34, loss 0.19980040192604065, acc=0.903333306312561, loss=0.19980040192604065
test: epoch 34, loss 0.31238463521003723, acc=0.8833333253860474, loss=0.31238463521003723
train: epoch 35, loss 0.16857223212718964, acc=0.9058889150619507, loss=0.16857223212718964
test: epoch 35, loss 0.2341533899307251, acc=0.8888888955116272, loss=0.2341533899307251
train: epoch 36, loss 0.22940592467784882, acc=0.8900555372238159, loss=0.22940592467784882
test: epoch 36, loss 0.3270168900489807, acc=0.8833333253860474, loss=0.3270168900489807
train: epoch 37, loss 0.17301595211029053, acc=0.9053888916969299, loss=0.17301595211029053
test: epoch 37, loss 0.30878186225891113, acc=0.8888888955116272, loss=0.30878186225891113
train: epoch 38, loss 0.17928358912467957, acc=0.9068333506584167, loss=0.17928358912467957
test: epoch 38, loss 0.28101876378059387, acc=0.8861111402511597, loss=0.28101876378059387
train: epoch 39, loss 0.22617202997207642, acc=0.9004999995231628, loss=0.22617202997207642
test: epoch 39, loss 0.33612558245658875, acc=0.8777777552604675, loss=0.33612558245658875
train: epoch 40, loss 0.16522324085235596, acc=0.9107778072357178, loss=0.16522324085235596
test: epoch 40, loss 0.3846210241317749, acc=0.8861111402511597, loss=0.3846210241317749
train: epoch 41, loss 0.20099729299545288, acc=0.9011111259460449, loss=0.20099729299545288
test: epoch 41, loss 0.33742350339889526, acc=0.8833333253860474, loss=0.33742350339889526
train: epoch 42, loss 0.19892361760139465, acc=0.9051666855812073, loss=0.19892361760139465
test: epoch 42, loss 0.3904246985912323, acc=0.8805555701255798, loss=0.3904246985912323
train: epoch 43, loss 0.16674023866653442, acc=0.9075000286102295, loss=0.16674023866653442
test: epoch 43, loss 0.2869608998298645, acc=0.8888888955116272, loss=0.2869608998298645
train: epoch 44, loss 0.18959979712963104, acc=0.9023333191871643, loss=0.18959979712963104
test: epoch 44, loss 0.29026997089385986, acc=0.8888888955116272, loss=0.29026997089385986
train: epoch 45, loss 0.14515312016010284, acc=0.910277783870697, loss=0.14515312016010284
test: epoch 45, loss 0.2719116806983948, acc=0.8888888955116272, loss=0.2719116806983948
train: epoch 46, loss 0.18480700254440308, acc=0.9075555801391602, loss=0.18480700254440308
test: epoch 46, loss 0.2676098644733429, acc=0.8888888955116272, loss=0.2676098644733429
train: epoch 47, loss 0.1877603381872177, acc=0.9087222218513489, loss=0.1877603381872177
test: epoch 47, loss 0.3307639956474304, acc=0.8833333253860474, loss=0.3307639956474304
train: epoch 48, loss 0.2164880931377411, acc=0.902388870716095, loss=0.2164880931377411
test: epoch 48, loss 0.33947089314460754, acc=0.8805555701255798, loss=0.33947089314460754
train: epoch 49, loss 0.18518248200416565, acc=0.9013888835906982, loss=0.18518248200416565
test: epoch 49, loss 0.30434778332710266, acc=0.8833333253860474, loss=0.30434778332710266
train: epoch 50, loss 0.1840958595275879, acc=0.902222216129303, loss=0.1840958595275879
test: epoch 50, loss 0.33403095602989197, acc=0.8805555701255798, loss=0.33403095602989197
train: epoch 51, loss 0.15984566509723663, acc=0.9062222242355347, loss=0.15984566509723663
test: epoch 51, loss 0.39828014373779297, acc=0.8833333253860474, loss=0.39828014373779297
train: epoch 52, loss 0.20939119160175323, acc=0.8966666460037231, loss=0.20939119160175323
test: epoch 52, loss 0.36666855216026306, acc=0.8805555701255798, loss=0.36666855216026306
train: epoch 53, loss 0.20647263526916504, acc=0.8995555639266968, loss=0.20647263526916504
test: epoch 53, loss 0.3366923928260803, acc=0.8861111402511597, loss=0.3366923928260803
train: epoch 54, loss 0.17898036539554596, acc=0.9068333506584167, loss=0.17898036539554596
test: epoch 54, loss 0.3616349995136261, acc=0.8861111402511597, loss=0.3616349995136261
train: epoch 55, loss 0.20652063190937042, acc=0.9016666412353516, loss=0.20652063190937042
test: epoch 55, loss 0.4313085973262787, acc=0.8722222447395325, loss=0.4313085973262787
train: epoch 56, loss 0.17257410287857056, acc=0.9068889021873474, loss=0.17257410287857056
test: epoch 56, loss 0.35404306650161743, acc=0.8805555701255798, loss=0.35404306650161743
train: epoch 57, loss 0.2172091156244278, acc=0.9008333086967468, loss=0.2172091156244278
test: epoch 57, loss 0.337514728307724, acc=0.8805555701255798, loss=0.337514728307724
train: epoch 58, loss 0.170164093375206, acc=0.9017778038978577, loss=0.170164093375206
test: epoch 58, loss 0.27393317222595215, acc=0.8861111402511597, loss=0.27393317222595215
train: epoch 59, loss 0.19839276373386383, acc=0.9053333401679993, loss=0.19839276373386383
test: epoch 59, loss 0.36434048414230347, acc=0.8833333253860474, loss=0.36434048414230347
train: epoch 60, loss 0.18994876742362976, acc=0.9068333506584167, loss=0.18994876742362976
test: epoch 60, loss 0.3898671567440033, acc=0.8722222447395325, loss=0.3898671567440033
train: epoch 61, loss 0.1965683102607727, acc=0.9025555849075317, loss=0.1965683102607727
test: epoch 61, loss 0.5649242997169495, acc=0.8305555582046509, loss=0.5649242997169495
train: epoch 62, loss 0.23524917662143707, acc=0.8920555710792542, loss=0.23524917662143707
test: epoch 62, loss 0.44221362471580505, acc=0.8694444298744202, loss=0.44221362471580505
train: epoch 63, loss 0.1775081604719162, acc=0.9025555849075317, loss=0.1775081604719162
test: epoch 63, loss 0.359765887260437, acc=0.8777777552604675, loss=0.359765887260437
train: epoch 64, loss 0.20153208076953888, acc=0.8978888988494873, loss=0.20153208076953888
test: epoch 64, loss 0.37965071201324463, acc=0.8777777552604675, loss=0.37965071201324463
train: epoch 65, loss 0.18301717936992645, acc=0.9021666646003723, loss=0.18301717936992645
test: epoch 65, loss 0.3869754374027252, acc=0.8805555701255798, loss=0.3869754374027252
train: epoch 66, loss 0.16863900423049927, acc=0.9025555849075317, loss=0.16863900423049927
test: epoch 66, loss 0.32490092515945435, acc=0.8888888955116272, loss=0.32490092515945435
train: epoch 67, loss 0.16243769228458405, acc=0.9113888740539551, loss=0.16243769228458405
test: epoch 67, loss 0.4203602373600006, acc=0.8805555701255798, loss=0.4203602373600006
train: epoch 68, loss 0.14581358432769775, acc=0.9112222194671631, loss=0.14581358432769775
test: epoch 68, loss 0.3040267825126648, acc=0.8888888955116272, loss=0.3040267825126648
train: epoch 69, loss 0.15212079882621765, acc=0.9077222347259521, loss=0.15212079882621765
test: epoch 69, loss 0.40035876631736755, acc=0.875, loss=0.40035876631736755
train: epoch 70, loss 0.1728038787841797, acc=0.9111111164093018, loss=0.1728038787841797
test: epoch 70, loss 0.31664034724235535, acc=0.8861111402511597, loss=0.31664034724235535
train: epoch 71, loss 0.16617973148822784, acc=0.906166672706604, loss=0.16617973148822784
test: epoch 71, loss 0.29396599531173706, acc=0.8888888955116272, loss=0.29396599531173706
train: epoch 72, loss 0.14410823583602905, acc=0.9087222218513489, loss=0.14410823583602905
test: epoch 72, loss 0.4978272318840027, acc=0.8805555701255798, loss=0.4978272318840027
train: epoch 73, loss 0.14771929383277893, acc=0.9096666574478149, loss=0.14771929383277893
test: epoch 73, loss 0.3600112497806549, acc=0.875, loss=0.3600112497806549
train: epoch 74, loss 0.17430661618709564, acc=0.9056666493415833, loss=0.17430661618709564
test: epoch 74, loss 0.3950060307979584, acc=0.875, loss=0.3950060307979584
train: epoch 75, loss 0.20253372192382812, acc=0.8928333520889282, loss=0.20253372192382812
test: epoch 75, loss 0.4352639615535736, acc=0.8722222447395325, loss=0.4352639615535736
train: epoch 76, loss 0.16273340582847595, acc=0.8887222409248352, loss=0.16273340582847595
test: epoch 76, loss 0.3447990417480469, acc=0.875, loss=0.3447990417480469
train: epoch 77, loss 0.15673163533210754, acc=0.8918889164924622, loss=0.15673163533210754
test: epoch 77, loss 0.3568274974822998, acc=0.8777777552604675, loss=0.3568274974822998
train: epoch 78, loss 0.20378410816192627, acc=0.8878889083862305, loss=0.20378410816192627
test: epoch 78, loss 0.3559987545013428, acc=0.8666666746139526, loss=0.3559987545013428
train: epoch 79, loss 0.18158164620399475, acc=0.8828333616256714, loss=0.18158164620399475
test: epoch 79, loss 0.3416704535484314, acc=0.8694444298744202, loss=0.3416704535484314
train: epoch 80, loss 0.2253970056772232, acc=0.8848888874053955, loss=0.2253970056772232
test: epoch 80, loss 0.3633614182472229, acc=0.8694444298744202, loss=0.3633614182472229
train: epoch 81, loss 0.19419905543327332, acc=0.8897777795791626, loss=0.19419905543327332
test: epoch 81, loss 0.406024694442749, acc=0.8722222447395325, loss=0.406024694442749
train: epoch 82, loss 0.18101783096790314, acc=0.8898888826370239, loss=0.18101783096790314
test: epoch 82, loss 0.37705883383750916, acc=0.8722222447395325, loss=0.37705883383750916
train: epoch 83, loss 0.21655425429344177, acc=0.8838333487510681, loss=0.21655425429344177
test: epoch 83, loss 0.3442034423351288, acc=0.8694444298744202, loss=0.3442034423351288
train: epoch 84, loss 0.2151527851819992, acc=0.8813333511352539, loss=0.2151527851819992
test: epoch 84, loss 0.3956863582134247, acc=0.8666666746139526, loss=0.3956863582134247
train: epoch 85, loss 0.20008493959903717, acc=0.8866111040115356, loss=0.20008493959903717
test: epoch 85, loss 0.3608066141605377, acc=0.8611111044883728, loss=0.3608066141605377
train: epoch 86, loss 0.2057984620332718, acc=0.8761666417121887, loss=0.2057984620332718
test: epoch 86, loss 0.39784470200538635, acc=0.8638888597488403, loss=0.39784470200538635
train: epoch 87, loss 0.21040095388889313, acc=0.8713333606719971, loss=0.21040095388889313
test: epoch 87, loss 0.28280627727508545, acc=0.8666666746139526, loss=0.28280627727508545
train: epoch 88, loss 0.21432176232337952, acc=0.8693888783454895, loss=0.21432176232337952
test: epoch 88, loss 0.4485398232936859, acc=0.8583333492279053, loss=0.4485398232936859
train: epoch 89, loss 0.2516903579235077, acc=0.8681666851043701, loss=0.2516903579235077
test: epoch 89, loss 0.40614092350006104, acc=0.8583333492279053, loss=0.40614092350006104
train: epoch 90, loss 0.22672371566295624, acc=0.8731111288070679, loss=0.22672371566295624
test: epoch 90, loss 0.3318668305873871, acc=0.8611111044883728, loss=0.3318668305873871
train: epoch 91, loss 0.19401855766773224, acc=0.871999979019165, loss=0.19401855766773224
test: epoch 91, loss 0.40880200266838074, acc=0.8638888597488403, loss=0.40880200266838074
train: epoch 92, loss 0.20769372582435608, acc=0.8736110925674438, loss=0.20769372582435608
test: epoch 92, loss 0.3744148313999176, acc=0.8638888597488403, loss=0.3744148313999176
train: epoch 93, loss 0.19016657769680023, acc=0.8855555653572083, loss=0.19016657769680023
test: epoch 93, loss 0.4385918974876404, acc=0.8694444298744202, loss=0.4385918974876404
train: epoch 94, loss 0.2642180621623993, acc=0.8781111240386963, loss=0.2642180621623993
test: epoch 94, loss 0.4703461527824402, acc=0.8527777791023254, loss=0.4703461527824402
train: epoch 95, loss 0.23281724750995636, acc=0.8722777962684631, loss=0.23281724750995636
test: epoch 95, loss 0.38526540994644165, acc=0.855555534362793, loss=0.38526540994644165
train: epoch 96, loss 0.2215682417154312, acc=0.867888867855072, loss=0.2215682417154312
test: epoch 96, loss 0.3616492748260498, acc=0.8666666746139526, loss=0.3616492748260498
train: epoch 97, loss 0.23348145186901093, acc=0.8721666932106018, loss=0.23348145186901093
test: epoch 97, loss 0.20596027374267578, acc=0.894444465637207, loss=0.20596027374267578
train: epoch 98, loss 0.2233992964029312, acc=0.8688889145851135, loss=0.2233992964029312
test: epoch 98, loss 0.3134048581123352, acc=0.8722222447395325, loss=0.3134048581123352
train: epoch 99, loss 0.21891923248767853, acc=0.8709999918937683, loss=0.21891923248767853
test: epoch 99, loss 0.23029661178588867, acc=0.8888888955116272, loss=0.23029661178588867
train: epoch 100, loss 0.2508390247821808, acc=0.8659444451332092, loss=0.2508390247821808
test: epoch 100, loss 0.23135493695735931, acc=0.8861111402511597, loss=0.23135493695735931
train: epoch 101, loss 0.2339135855436325, acc=0.8598889112472534, loss=0.2339135855436325
test: epoch 101, loss 0.23092243075370789, acc=0.8861111402511597, loss=0.23092243075370789
train: epoch 102, loss 0.23152361810207367, acc=0.8629444241523743, loss=0.23152361810207367
test: epoch 102, loss 0.2221718281507492, acc=0.8888888955116272, loss=0.2221718281507492
train: epoch 103, loss 0.27982333302497864, acc=0.8581666946411133, loss=0.27982333302497864
test: epoch 103, loss 0.2767643928527832, acc=0.875, loss=0.2767643928527832
train: epoch 104, loss 0.24069051444530487, acc=0.8683333396911621, loss=0.24069051444530487
test: epoch 104, loss 0.2189398556947708, acc=0.8888888955116272, loss=0.2189398556947708
train: epoch 105, loss 0.22051113843917847, acc=0.8708333373069763, loss=0.22051113843917847
test: epoch 105, loss 0.21866536140441895, acc=0.8888888955116272, loss=0.21866536140441895
train: epoch 106, loss 0.2087598592042923, acc=0.8742777705192566, loss=0.2087598592042923
test: epoch 106, loss 0.20618097484111786, acc=0.8916666507720947, loss=0.20618097484111786
train: epoch 107, loss 0.2506237328052521, acc=0.8660555481910706, loss=0.2506237328052521
test: epoch 107, loss 0.2503841817378998, acc=0.875, loss=0.2503841817378998
train: epoch 108, loss 0.3135417401790619, acc=0.8510555624961853, loss=0.3135417401790619
test: epoch 108, loss 0.21621541678905487, acc=0.8833333253860474, loss=0.21621541678905487
train: epoch 109, loss 0.21894055604934692, acc=0.8649444580078125, loss=0.21894055604934692
test: epoch 109, loss 0.21911168098449707, acc=0.8833333253860474, loss=0.21911168098449707
train: epoch 110, loss 0.22077655792236328, acc=0.8609444499015808, loss=0.22077655792236328
test: epoch 110, loss 0.2186465859413147, acc=0.8833333253860474, loss=0.2186465859413147
train: epoch 111, loss 0.22017590701580048, acc=0.8585555553436279, loss=0.22017590701580048
test: epoch 111, loss 0.2185630053281784, acc=0.8833333253860474, loss=0.2185630053281784
train: epoch 112, loss 0.21999044716358185, acc=0.8586666584014893, loss=0.21999044716358185
test: epoch 112, loss 0.21852761507034302, acc=0.8833333253860474, loss=0.21852761507034302
train: epoch 113, loss 0.21988841891288757, acc=0.8566666841506958, loss=0.21988841891288757
test: epoch 113, loss 0.21850770711898804, acc=0.8833333253860474, loss=0.21850770711898804
train: epoch 114, loss 0.21980364620685577, acc=0.8565555810928345, loss=0.21980364620685577
test: epoch 114, loss 0.21849536895751953, acc=0.8833333253860474, loss=0.21849536895751953
train: epoch 115, loss 0.3370305299758911, acc=0.8542777895927429, loss=0.3370305299758911
test: epoch 115, loss 0.22076180577278137, acc=0.8888888955116272, loss=0.22076180577278137
train: epoch 116, loss 0.21100306510925293, acc=0.8799444437026978, loss=0.21100306510925293
test: epoch 116, loss 0.3174622654914856, acc=0.8833333253860474, loss=0.3174622654914856
train: epoch 117, loss 0.21460165083408356, acc=0.8775555491447449, loss=0.21460165083408356
test: epoch 117, loss 0.21649911999702454, acc=0.8861111402511597, loss=0.21649911999702454
train: epoch 118, loss 0.24483583867549896, acc=0.8592222332954407, loss=0.24483583867549896
test: epoch 118, loss 0.23973427712917328, acc=0.8805555701255798, loss=0.23973427712917328
train: epoch 119, loss 0.24615421891212463, acc=0.86644446849823, loss=0.24615421891212463
test: epoch 119, loss 0.22962498664855957, acc=0.8833333253860474, loss=0.22962498664855957
train: epoch 120, loss 0.22141753137111664, acc=0.8736110925674438, loss=0.22141753137111664
test: epoch 120, loss 0.18759028613567352, acc=0.8972222208976746, loss=0.18759028613567352
train: epoch 121, loss 0.2199239432811737, acc=0.8666666746139526, loss=0.2199239432811737
test: epoch 121, loss 0.2132343202829361, acc=0.8888888955116272, loss=0.2132343202829361
train: epoch 122, loss 0.21592295169830322, acc=0.8628333210945129, loss=0.21592295169830322
test: epoch 122, loss 0.21181726455688477, acc=0.8888888955116272, loss=0.21181726455688477
train: epoch 123, loss 0.2143809050321579, acc=0.863111138343811, loss=0.2143809050321579
test: epoch 123, loss 0.21165505051612854, acc=0.8888888955116272, loss=0.21165505051612854
train: epoch 124, loss 0.21368078887462616, acc=0.867555558681488, loss=0.21368078887462616
test: epoch 124, loss 0.1990145444869995, acc=0.894444465637207, loss=0.1990145444869995
train: epoch 125, loss 0.17657819390296936, acc=0.8933888673782349, loss=0.17657819390296936
test: epoch 125, loss 0.16275790333747864, acc=0.9138888716697693, loss=0.16275790333747864
train: epoch 126, loss 0.1648918241262436, acc=0.9016110897064209, loss=0.1648918241262436
test: epoch 126, loss 0.1626538783311844, acc=0.9138888716697693, loss=0.1626538783311844
train: epoch 127, loss 0.38002362847328186, acc=0.8513333201408386, loss=0.38002362847328186
test: epoch 127, loss 0.4055902361869812, acc=0.8305555582046509, loss=0.4055902361869812
train: epoch 128, loss 0.3740524351596832, acc=0.8209999799728394, loss=0.3740524351596832
test: epoch 128, loss 0.3462212383747101, acc=0.8444444537162781, loss=0.3462212383747101
train: epoch 129, loss 0.3720821738243103, acc=0.8327222466468811, loss=0.3720821738243103
test: epoch 129, loss 0.3095267713069916, acc=0.8583333492279053, loss=0.3095267713069916
train: epoch 130, loss 0.28911352157592773, acc=0.859666645526886, loss=0.28911352157592773
test: epoch 130, loss 0.2793580889701843, acc=0.8666666746139526, loss=0.2793580889701843
train: epoch 131, loss 0.28330937027931213, acc=0.8515555262565613, loss=0.28330937027931213
test: epoch 131, loss 0.27906444668769836, acc=0.8666666746139526, loss=0.27906444668769836
train: epoch 132, loss 0.2830798029899597, acc=0.8493888974189758, loss=0.2830798029899597
test: epoch 132, loss 0.28344014286994934, acc=0.8666666746139526, loss=0.28344014286994934
train: epoch 133, loss 0.3277911841869354, acc=0.855555534362793, loss=0.3277911841869354
test: epoch 133, loss 0.2782706022262573, acc=0.875, loss=0.2782706022262573
train: epoch 134, loss 0.2804037928581238, acc=0.8826666474342346, loss=0.2804037928581238
test: epoch 134, loss 0.25101739168167114, acc=0.8861111402511597, loss=0.25101739168167114
train: epoch 135, loss 0.2488270103931427, acc=0.8763333559036255, loss=0.2488270103931427
test: epoch 135, loss 0.24013859033584595, acc=0.8916666507720947, loss=0.24013859033584595
train: epoch 136, loss 0.2266485095024109, acc=0.8805555701255798, loss=0.2266485095024109
test: epoch 136, loss 0.21332845091819763, acc=0.8972222208976746, loss=0.21332845091819763
train: epoch 137, loss 0.21602390706539154, acc=0.8831666707992554, loss=0.21602390706539154
test: epoch 137, loss 0.21320071816444397, acc=0.8972222208976746, loss=0.21320071816444397
train: epoch 138, loss 0.20878735184669495, acc=0.8852221965789795, loss=0.20878735184669495
test: epoch 138, loss 0.20490725338459015, acc=0.8999999761581421, loss=0.20490725338459015
train: epoch 139, loss 0.20739272236824036, acc=0.8857777714729309, loss=0.20739272236824036
test: epoch 139, loss 0.20478478074073792, acc=0.8999999761581421, loss=0.20478478074073792
train: epoch 140, loss 0.19848306477069855, acc=0.8877778053283691, loss=0.19848306477069855
test: epoch 140, loss 0.19469821453094482, acc=0.9027777910232544, loss=0.19469821453094482
train: epoch 141, loss 0.1968710720539093, acc=0.8882222175598145, loss=0.1968710720539093
test: epoch 141, loss 0.19470661878585815, acc=0.9027777910232544, loss=0.19470661878585815
train: epoch 142, loss 0.35828641057014465, acc=0.8647778034210205, loss=0.35828641057014465
test: epoch 142, loss 0.2922764718532562, acc=0.8722222447395325, loss=0.2922764718532562
train: epoch 143, loss 0.2736796736717224, acc=0.8678333163261414, loss=0.2736796736717224
test: epoch 143, loss 0.2624411880970001, acc=0.8805555701255798, loss=0.2624411880970001
train: epoch 144, loss 0.26007527112960815, acc=0.870888888835907, loss=0.26007527112960815
test: epoch 144, loss 0.2502965033054352, acc=0.8861111402511597, loss=0.2502965033054352
train: epoch 145, loss 0.2520589530467987, acc=0.8782777786254883, loss=0.2520589530467987
test: epoch 145, loss 0.24892807006835938, acc=0.8861111402511597, loss=0.24892807006835938
train: epoch 146, loss 0.2512355148792267, acc=0.8762778043746948, loss=0.2512355148792267
test: epoch 146, loss 0.24876275658607483, acc=0.8861111402511597, loss=0.24876275658607483
train: epoch 147, loss 0.25106698274612427, acc=0.8756111264228821, loss=0.25106698274612427
test: epoch 147, loss 0.24871878325939178, acc=0.8861111402511597, loss=0.24871878325939178
train: epoch 148, loss 0.25093966722488403, acc=0.8752777576446533, loss=0.25093966722488403
test: epoch 148, loss 0.24865876138210297, acc=0.8861111402511597, loss=0.24865876138210297
train: epoch 149, loss 0.4303666651248932, acc=0.8418333530426025, loss=0.4303666651248932
test: epoch 149, loss 0.344116747379303, acc=0.8611111044883728, loss=0.344116747379303
train: epoch 150, loss 0.33177435398101807, acc=0.8500000238418579, loss=0.33177435398101807
test: epoch 150, loss 0.32090482115745544, acc=0.8638888597488403, loss=0.32090482115745544
