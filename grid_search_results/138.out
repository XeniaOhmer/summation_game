# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=1.5", "--temp_decay=0.99", "--one_hot=true", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=553732232, receiver_embed_dim=128, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.968759059906006, acc=0.10388889163732529, loss=2.968759059906006
test: epoch 1, loss 2.8404738903045654, acc=0.13055555522441864, loss=2.8404738903045654
train: epoch 2, loss 1.650363564491272, acc=0.3303889036178589, loss=1.650363564491272
test: epoch 2, loss 2.551325798034668, acc=0.16111111640930176, loss=2.551325798034668
train: epoch 3, loss 1.3558698892593384, acc=0.43727776408195496, loss=1.3558698892593384
test: epoch 3, loss 2.3775806427001953, acc=0.20000000298023224, loss=2.3775806427001953
train: epoch 4, loss 1.19566810131073, acc=0.5061110854148865, loss=1.19566810131073
test: epoch 4, loss 2.1456029415130615, acc=0.26944443583488464, loss=2.1456029415130615
train: epoch 5, loss 1.0888949632644653, acc=0.5501111149787903, loss=1.0888949632644653
test: epoch 5, loss 2.1802244186401367, acc=0.26944443583488464, loss=2.1802244186401367
train: epoch 6, loss 1.0014387369155884, acc=0.5926666855812073, loss=1.0014387369155884
test: epoch 6, loss 2.0992238521575928, acc=0.27222222089767456, loss=2.0992238521575928
train: epoch 7, loss 0.9230513572692871, acc=0.6250555515289307, loss=0.9230513572692871
test: epoch 7, loss 1.9561400413513184, acc=0.2944444417953491, loss=1.9561400413513184
train: epoch 8, loss 0.858367919921875, acc=0.6568889021873474, loss=0.858367919921875
test: epoch 8, loss 1.9470371007919312, acc=0.27222222089767456, loss=1.9470371007919312
train: epoch 9, loss 0.8222924470901489, acc=0.6714444160461426, loss=0.8222924470901489
test: epoch 9, loss 1.8753846883773804, acc=0.31111112236976624, loss=1.8753846883773804
train: epoch 10, loss 0.7648077011108398, acc=0.6906111240386963, loss=0.7648077011108398
test: epoch 10, loss 1.9042209386825562, acc=0.28333333134651184, loss=1.9042209386825562
train: epoch 11, loss 0.7272666096687317, acc=0.7128888964653015, loss=0.7272666096687317
test: epoch 11, loss 1.8231347799301147, acc=0.3333333432674408, loss=1.8231347799301147
train: epoch 12, loss 0.6863897442817688, acc=0.7282222509384155, loss=0.6863897442817688
test: epoch 12, loss 1.724269986152649, acc=0.35277777910232544, loss=1.724269986152649
train: epoch 13, loss 0.658471405506134, acc=0.7398889064788818, loss=0.658471405506134
test: epoch 13, loss 1.8454543352127075, acc=0.35277777910232544, loss=1.8454543352127075
train: epoch 14, loss 0.609444797039032, acc=0.7598333358764648, loss=0.609444797039032
test: epoch 14, loss 1.668658971786499, acc=0.4027777910232544, loss=1.668658971786499
train: epoch 15, loss 0.6076557040214539, acc=0.7669444680213928, loss=0.6076557040214539
test: epoch 15, loss 1.5951921939849854, acc=0.3861111104488373, loss=1.5951921939849854
train: epoch 16, loss 0.5695858001708984, acc=0.7778333425521851, loss=0.5695858001708984
test: epoch 16, loss 1.7818779945373535, acc=0.3194444477558136, loss=1.7818779945373535
train: epoch 17, loss 0.5469505786895752, acc=0.7883889079093933, loss=0.5469505786895752
test: epoch 17, loss 1.5206102132797241, acc=0.41111111640930176, loss=1.5206102132797241
train: epoch 18, loss 0.5262628197669983, acc=0.7994444370269775, loss=0.5262628197669983
test: epoch 18, loss 1.6033343076705933, acc=0.42500001192092896, loss=1.6033343076705933
train: epoch 19, loss 0.5035033226013184, acc=0.8100555539131165, loss=0.5035033226013184
test: epoch 19, loss 1.6228649616241455, acc=0.4027777910232544, loss=1.6228649616241455
train: epoch 20, loss 0.49487245082855225, acc=0.8144444227218628, loss=0.49487245082855225
test: epoch 20, loss 1.6368120908737183, acc=0.4333333373069763, loss=1.6368120908737183
train: epoch 21, loss 0.47948646545410156, acc=0.820277750492096, loss=0.47948646545410156
test: epoch 21, loss 1.5798274278640747, acc=0.4305555522441864, loss=1.5798274278640747
train: epoch 22, loss 0.4557306468486786, acc=0.8274444341659546, loss=0.4557306468486786
test: epoch 22, loss 1.3259599208831787, acc=0.4833333194255829, loss=1.3259599208831787
train: epoch 23, loss 0.44191184639930725, acc=0.8364999890327454, loss=0.44191184639930725
test: epoch 23, loss 1.6145355701446533, acc=0.4194444417953491, loss=1.6145355701446533
train: epoch 24, loss 0.43162739276885986, acc=0.8328889012336731, loss=0.43162739276885986
test: epoch 24, loss 1.4840419292449951, acc=0.4583333432674408, loss=1.4840419292449951
train: epoch 25, loss 0.4129551649093628, acc=0.8448333144187927, loss=0.4129551649093628
test: epoch 25, loss 1.4640063047409058, acc=0.4583333432674408, loss=1.4640063047409058
train: epoch 26, loss 0.40145426988601685, acc=0.850944459438324, loss=0.40145426988601685
test: epoch 26, loss 1.5667582750320435, acc=0.4694444537162781, loss=1.5667582750320435
train: epoch 27, loss 0.38559970259666443, acc=0.8568888902664185, loss=0.38559970259666443
test: epoch 27, loss 1.6503914594650269, acc=0.4749999940395355, loss=1.6503914594650269
train: epoch 28, loss 0.37988439202308655, acc=0.863111138343811, loss=0.37988439202308655
test: epoch 28, loss 1.5493203401565552, acc=0.49166667461395264, loss=1.5493203401565552
train: epoch 29, loss 0.35916057229042053, acc=0.8724444508552551, loss=0.35916057229042053
test: epoch 29, loss 1.5879836082458496, acc=0.4833333194255829, loss=1.5879836082458496
train: epoch 30, loss 0.35687053203582764, acc=0.8676111102104187, loss=0.35687053203582764
test: epoch 30, loss 1.6949456930160522, acc=0.47777777910232544, loss=1.6949456930160522
train: epoch 31, loss 0.3480401337146759, acc=0.8740555644035339, loss=0.3480401337146759
test: epoch 31, loss 1.710412621498108, acc=0.4861111044883728, loss=1.710412621498108
train: epoch 32, loss 0.33963820338249207, acc=0.8715000152587891, loss=0.33963820338249207
test: epoch 32, loss 1.671237587928772, acc=0.5277777910232544, loss=1.671237587928772
train: epoch 33, loss 0.31650447845458984, acc=0.8839444518089294, loss=0.31650447845458984
test: epoch 33, loss 1.65626060962677, acc=0.5138888955116272, loss=1.65626060962677
train: epoch 34, loss 0.31857141852378845, acc=0.882611095905304, loss=0.31857141852378845
test: epoch 34, loss 1.8032197952270508, acc=0.4972222149372101, loss=1.8032197952270508
train: epoch 35, loss 0.3162462115287781, acc=0.8837777972221375, loss=0.3162462115287781
test: epoch 35, loss 1.5503791570663452, acc=0.550000011920929, loss=1.5503791570663452
train: epoch 36, loss 0.303946852684021, acc=0.8879444599151611, loss=0.303946852684021
test: epoch 36, loss 1.446036696434021, acc=0.5527777671813965, loss=1.446036696434021
train: epoch 37, loss 0.296537309885025, acc=0.8889999985694885, loss=0.296537309885025
test: epoch 37, loss 1.39568030834198, acc=0.550000011920929, loss=1.39568030834198
train: epoch 38, loss 0.28317341208457947, acc=0.8930555582046509, loss=0.28317341208457947
test: epoch 38, loss 1.4728807210922241, acc=0.5777778029441833, loss=1.4728807210922241
train: epoch 39, loss 0.28509142994880676, acc=0.8935555815696716, loss=0.28509142994880676
test: epoch 39, loss 1.3619780540466309, acc=0.5805555582046509, loss=1.3619780540466309
train: epoch 40, loss 0.28521090745925903, acc=0.8945555686950684, loss=0.28521090745925903
test: epoch 40, loss 1.4380460977554321, acc=0.5972222089767456, loss=1.4380460977554321
train: epoch 41, loss 0.29182168841362, acc=0.8942221999168396, loss=0.29182168841362
test: epoch 41, loss 1.6928707361221313, acc=0.5305555462837219, loss=1.6928707361221313
train: epoch 42, loss 0.2694055736064911, acc=0.8974444270133972, loss=0.2694055736064911
test: epoch 42, loss 1.5282559394836426, acc=0.5805555582046509, loss=1.5282559394836426
train: epoch 43, loss 0.28058215975761414, acc=0.894777774810791, loss=0.28058215975761414
test: epoch 43, loss 1.417647361755371, acc=0.5916666388511658, loss=1.417647361755371
train: epoch 44, loss 0.2745417654514313, acc=0.897777795791626, loss=0.2745417654514313
test: epoch 44, loss 1.3371508121490479, acc=0.5722222328186035, loss=1.3371508121490479
train: epoch 45, loss 0.28433069586753845, acc=0.894777774810791, loss=0.28433069586753845
test: epoch 45, loss 1.4401735067367554, acc=0.6111111044883728, loss=1.4401735067367554
train: epoch 46, loss 0.26810258626937866, acc=0.8980555534362793, loss=0.26810258626937866
test: epoch 46, loss 1.489200234413147, acc=0.6138888597488403, loss=1.489200234413147
train: epoch 47, loss 0.2761078178882599, acc=0.8976110816001892, loss=0.2761078178882599
test: epoch 47, loss 1.3470220565795898, acc=0.5972222089767456, loss=1.3470220565795898
train: epoch 48, loss 0.278340220451355, acc=0.8963888883590698, loss=0.278340220451355
test: epoch 48, loss 1.1946959495544434, acc=0.6305555701255798, loss=1.1946959495544434
train: epoch 49, loss 0.2567886710166931, acc=0.9027777910232544, loss=0.2567886710166931
test: epoch 49, loss 1.3858922719955444, acc=0.6166666746139526, loss=1.3858922719955444
train: epoch 50, loss 0.2752881348133087, acc=0.8967221975326538, loss=0.2752881348133087
test: epoch 50, loss 1.2548692226409912, acc=0.6388888955116272, loss=1.2548692226409912
train: epoch 51, loss 0.2693456709384918, acc=0.8985000252723694, loss=0.2693456709384918
test: epoch 51, loss 1.2566473484039307, acc=0.6333333253860474, loss=1.2566473484039307
train: epoch 52, loss 0.2754548490047455, acc=0.8976110816001892, loss=0.2754548490047455
test: epoch 52, loss 1.1239951848983765, acc=0.644444465637207, loss=1.1239951848983765
train: epoch 53, loss 0.2772350609302521, acc=0.8956666588783264, loss=0.2772350609302521
test: epoch 53, loss 1.2020844221115112, acc=0.6416666507720947, loss=1.2020844221115112
train: epoch 54, loss 0.2587364912033081, acc=0.902999997138977, loss=0.2587364912033081
test: epoch 54, loss 1.252083420753479, acc=0.6388888955116272, loss=1.252083420753479
train: epoch 55, loss 0.270600289106369, acc=0.8971111178398132, loss=0.270600289106369
test: epoch 55, loss 1.2646007537841797, acc=0.6499999761581421, loss=1.2646007537841797
train: epoch 56, loss 0.2632272243499756, acc=0.9014999866485596, loss=0.2632272243499756
test: epoch 56, loss 1.1928731203079224, acc=0.6361111402511597, loss=1.1928731203079224
train: epoch 57, loss 0.2616356313228607, acc=0.9017778038978577, loss=0.2616356313228607
test: epoch 57, loss 1.12559175491333, acc=0.6555555462837219, loss=1.12559175491333
train: epoch 58, loss 0.26847031712532043, acc=0.8965555429458618, loss=0.26847031712532043
test: epoch 58, loss 1.0500988960266113, acc=0.6722221970558167, loss=1.0500988960266113
train: epoch 59, loss 0.2700316309928894, acc=0.8980555534362793, loss=0.2700316309928894
test: epoch 59, loss 1.2461671829223633, acc=0.6527777910232544, loss=1.2461671829223633
train: epoch 60, loss 0.2634096145629883, acc=0.9003888964653015, loss=0.2634096145629883
test: epoch 60, loss 1.122848391532898, acc=0.6388888955116272, loss=1.122848391532898
train: epoch 61, loss 0.27066904306411743, acc=0.8989999890327454, loss=0.27066904306411743
test: epoch 61, loss 1.2001895904541016, acc=0.6638888716697693, loss=1.2001895904541016
train: epoch 62, loss 0.2724197208881378, acc=0.8970000147819519, loss=0.2724197208881378
test: epoch 62, loss 1.1594347953796387, acc=0.6361111402511597, loss=1.1594347953796387
train: epoch 63, loss 0.27068132162094116, acc=0.8992778062820435, loss=0.27068132162094116
test: epoch 63, loss 1.2070082426071167, acc=0.6472222208976746, loss=1.2070082426071167
train: epoch 64, loss 0.28030338883399963, acc=0.8972777724266052, loss=0.28030338883399963
test: epoch 64, loss 1.2439627647399902, acc=0.6638888716697693, loss=1.2439627647399902
train: epoch 65, loss 0.2794397473335266, acc=0.8939999938011169, loss=0.2794397473335266
test: epoch 65, loss 1.1101202964782715, acc=0.6583333611488342, loss=1.1101202964782715
train: epoch 66, loss 0.283194363117218, acc=0.8943333625793457, loss=0.283194363117218
test: epoch 66, loss 1.3555927276611328, acc=0.6611111164093018, loss=1.3555927276611328
train: epoch 67, loss 0.29101860523223877, acc=0.8918889164924622, loss=0.29101860523223877
test: epoch 67, loss 1.0091092586517334, acc=0.6833333373069763, loss=1.0091092586517334
train: epoch 68, loss 0.27972733974456787, acc=0.8960000276565552, loss=0.27972733974456787
test: epoch 68, loss 1.0498591661453247, acc=0.6555555462837219, loss=1.0498591661453247
train: epoch 69, loss 0.2804555594921112, acc=0.8922222256660461, loss=0.2804555594921112
test: epoch 69, loss 1.0505660772323608, acc=0.6555555462837219, loss=1.0505660772323608
train: epoch 70, loss 0.28547289967536926, acc=0.8907222151756287, loss=0.28547289967536926
test: epoch 70, loss 1.216501235961914, acc=0.6805555820465088, loss=1.216501235961914
train: epoch 71, loss 0.28697970509529114, acc=0.8912777900695801, loss=0.28697970509529114
test: epoch 71, loss 0.8862984776496887, acc=0.6861110925674438, loss=0.8862984776496887
train: epoch 72, loss 0.2740684151649475, acc=0.8963333368301392, loss=0.2740684151649475
test: epoch 72, loss 1.0109376907348633, acc=0.675000011920929, loss=1.0109376907348633
train: epoch 73, loss 0.2781423330307007, acc=0.8923888802528381, loss=0.2781423330307007
test: epoch 73, loss 1.0670053958892822, acc=0.6722221970558167, loss=1.0670053958892822
train: epoch 74, loss 0.28716185688972473, acc=0.8920000195503235, loss=0.28716185688972473
test: epoch 74, loss 0.9607259631156921, acc=0.6777777671813965, loss=0.9607259631156921
train: epoch 75, loss 0.27283358573913574, acc=0.8972777724266052, loss=0.27283358573913574
test: epoch 75, loss 1.0547106266021729, acc=0.6861110925674438, loss=1.0547106266021729
train: epoch 76, loss 0.27282828092575073, acc=0.8953889012336731, loss=0.27282828092575073
test: epoch 76, loss 1.0511995553970337, acc=0.6861110925674438, loss=1.0511995553970337
train: epoch 77, loss 0.27056413888931274, acc=0.8989444375038147, loss=0.27056413888931274
test: epoch 77, loss 1.0584725141525269, acc=0.6888889074325562, loss=1.0584725141525269
train: epoch 78, loss 0.27045655250549316, acc=0.8967777490615845, loss=0.27045655250549316
test: epoch 78, loss 1.0389010906219482, acc=0.6861110925674438, loss=1.0389010906219482
train: epoch 79, loss 0.26109185814857483, acc=0.8999444246292114, loss=0.26109185814857483
test: epoch 79, loss 1.0473095178604126, acc=0.675000011920929, loss=1.0473095178604126
train: epoch 80, loss 0.27018657326698303, acc=0.8976666927337646, loss=0.27018657326698303
test: epoch 80, loss 1.00895094871521, acc=0.6861110925674438, loss=1.00895094871521
train: epoch 81, loss 0.2725396454334259, acc=0.8983333110809326, loss=0.2725396454334259
test: epoch 81, loss 1.1201263666152954, acc=0.6722221970558167, loss=1.1201263666152954
train: epoch 82, loss 0.2692318856716156, acc=0.8970555663108826, loss=0.2692318856716156
test: epoch 82, loss 1.1709312200546265, acc=0.6861110925674438, loss=1.1709312200546265
train: epoch 83, loss 0.25559210777282715, acc=0.9011666774749756, loss=0.25559210777282715
test: epoch 83, loss 1.0093036890029907, acc=0.6833333373069763, loss=1.0093036890029907
train: epoch 84, loss 0.262734979391098, acc=0.9002777934074402, loss=0.262734979391098
test: epoch 84, loss 1.1365045309066772, acc=0.6722221970558167, loss=1.1365045309066772
train: epoch 85, loss 0.26059409976005554, acc=0.898888885974884, loss=0.26059409976005554
test: epoch 85, loss 1.212844729423523, acc=0.6805555820465088, loss=1.212844729423523
train: epoch 86, loss 0.2642229497432709, acc=0.9010000228881836, loss=0.2642229497432709
test: epoch 86, loss 1.0234111547470093, acc=0.6861110925674438, loss=1.0234111547470093
train: epoch 87, loss 0.256202757358551, acc=0.9008888602256775, loss=0.256202757358551
test: epoch 87, loss 1.1498448848724365, acc=0.6861110925674438, loss=1.1498448848724365
train: epoch 88, loss 0.2621835768222809, acc=0.9011666774749756, loss=0.2621835768222809
test: epoch 88, loss 1.0751924514770508, acc=0.675000011920929, loss=1.0751924514770508
train: epoch 89, loss 0.2502298057079315, acc=0.9038333296775818, loss=0.2502298057079315
test: epoch 89, loss 1.0219645500183105, acc=0.6861110925674438, loss=1.0219645500183105
train: epoch 90, loss 0.2507202923297882, acc=0.9052222371101379, loss=0.2507202923297882
test: epoch 90, loss 1.1272310018539429, acc=0.6861110925674438, loss=1.1272310018539429
train: epoch 91, loss 0.2612258493900299, acc=0.8996111154556274, loss=0.2612258493900299
test: epoch 91, loss 1.1522703170776367, acc=0.6694444417953491, loss=1.1522703170776367
train: epoch 92, loss 0.25550901889801025, acc=0.9032222032546997, loss=0.25550901889801025
test: epoch 92, loss 1.1394098997116089, acc=0.6861110925674438, loss=1.1394098997116089
train: epoch 93, loss 0.2593466341495514, acc=0.9017221927642822, loss=0.2593466341495514
test: epoch 93, loss 1.1532642841339111, acc=0.6861110925674438, loss=1.1532642841339111
train: epoch 94, loss 0.257565975189209, acc=0.902055561542511, loss=0.257565975189209
test: epoch 94, loss 0.9826671481132507, acc=0.6861110925674438, loss=0.9826671481132507
train: epoch 95, loss 0.2572706937789917, acc=0.9018333554267883, loss=0.2572706937789917
test: epoch 95, loss 1.0480279922485352, acc=0.6861110925674438, loss=1.0480279922485352
train: epoch 96, loss 0.25415655970573425, acc=0.9036111235618591, loss=0.25415655970573425
test: epoch 96, loss 1.0193709135055542, acc=0.6861110925674438, loss=1.0193709135055542
train: epoch 97, loss 0.24599021673202515, acc=0.9036666750907898, loss=0.24599021673202515
test: epoch 97, loss 1.0985053777694702, acc=0.6805555820465088, loss=1.0985053777694702
train: epoch 98, loss 0.25243934988975525, acc=0.906499981880188, loss=0.25243934988975525
test: epoch 98, loss 1.0166075229644775, acc=0.6888889074325562, loss=1.0166075229644775
train: epoch 99, loss 0.24937587976455688, acc=0.9053888916969299, loss=0.24937587976455688
test: epoch 99, loss 0.9977819323539734, acc=0.675000011920929, loss=0.9977819323539734
train: epoch 100, loss 0.2517388164997101, acc=0.9013333320617676, loss=0.2517388164997101
test: epoch 100, loss 1.0185842514038086, acc=0.6861110925674438, loss=1.0185842514038086
train: epoch 101, loss 0.24665451049804688, acc=0.9056110978126526, loss=0.24665451049804688
test: epoch 101, loss 1.2242457866668701, acc=0.6777777671813965, loss=1.2242457866668701
train: epoch 102, loss 0.2530531585216522, acc=0.9054444432258606, loss=0.2530531585216522
test: epoch 102, loss 1.076974630355835, acc=0.6861110925674438, loss=1.076974630355835
train: epoch 103, loss 0.2529175281524658, acc=0.9036111235618591, loss=0.2529175281524658
test: epoch 103, loss 1.0850863456726074, acc=0.6638888716697693, loss=1.0850863456726074
train: epoch 104, loss 0.2554473280906677, acc=0.9057222008705139, loss=0.2554473280906677
test: epoch 104, loss 1.113169550895691, acc=0.6861110925674438, loss=1.113169550895691
train: epoch 105, loss 0.24053643643856049, acc=0.909333348274231, loss=0.24053643643856049
test: epoch 105, loss 1.065278172492981, acc=0.6833333373069763, loss=1.065278172492981
train: epoch 106, loss 0.2460474669933319, acc=0.9079444408416748, loss=0.2460474669933319
test: epoch 106, loss 1.07290518283844, acc=0.6888889074325562, loss=1.07290518283844
train: epoch 107, loss 0.2552849054336548, acc=0.9042222499847412, loss=0.2552849054336548
test: epoch 107, loss 1.0486801862716675, acc=0.6805555820465088, loss=1.0486801862716675
train: epoch 108, loss 0.2418994903564453, acc=0.9086666703224182, loss=0.2418994903564453
test: epoch 108, loss 0.9536551833152771, acc=0.6861110925674438, loss=0.9536551833152771
train: epoch 109, loss 0.2484603077173233, acc=0.9057222008705139, loss=0.2484603077173233
test: epoch 109, loss 1.0183557271957397, acc=0.6694444417953491, loss=1.0183557271957397
train: epoch 110, loss 0.25447192788124084, acc=0.9040555357933044, loss=0.25447192788124084
test: epoch 110, loss 1.1175442934036255, acc=0.6888889074325562, loss=1.1175442934036255
train: epoch 111, loss 0.2432321161031723, acc=0.9065555334091187, loss=0.2432321161031723
test: epoch 111, loss 1.0657081604003906, acc=0.6805555820465088, loss=1.0657081604003906
train: epoch 112, loss 0.2538851499557495, acc=0.9051111340522766, loss=0.2538851499557495
test: epoch 112, loss 1.1745246648788452, acc=0.675000011920929, loss=1.1745246648788452
train: epoch 113, loss 0.24798639118671417, acc=0.9044444561004639, loss=0.24798639118671417
test: epoch 113, loss 1.0689458847045898, acc=0.6722221970558167, loss=1.0689458847045898
train: epoch 114, loss 0.24782060086727142, acc=0.906000018119812, loss=0.24782060086727142
test: epoch 114, loss 1.0249826908111572, acc=0.6861110925674438, loss=1.0249826908111572
train: epoch 115, loss 0.24691441655158997, acc=0.9082221984863281, loss=0.24691441655158997
test: epoch 115, loss 0.967429518699646, acc=0.6833333373069763, loss=0.967429518699646
train: epoch 116, loss 0.2373494654893875, acc=0.9098888635635376, loss=0.2373494654893875
test: epoch 116, loss 1.0841516256332397, acc=0.6861110925674438, loss=1.0841516256332397
train: epoch 117, loss 0.23978616297245026, acc=0.9104999899864197, loss=0.23978616297245026
test: epoch 117, loss 1.0119531154632568, acc=0.6666666865348816, loss=1.0119531154632568
train: epoch 118, loss 0.243877112865448, acc=0.9103888869285583, loss=0.243877112865448
test: epoch 118, loss 1.0820350646972656, acc=0.6861110925674438, loss=1.0820350646972656
train: epoch 119, loss 0.24906322360038757, acc=0.9062222242355347, loss=0.24906322360038757
test: epoch 119, loss 0.9771043062210083, acc=0.6638888716697693, loss=0.9771043062210083
train: epoch 120, loss 0.239848330616951, acc=0.9086666703224182, loss=0.239848330616951
test: epoch 120, loss 1.1665695905685425, acc=0.6805555820465088, loss=1.1665695905685425
train: epoch 121, loss 0.25063931941986084, acc=0.9065555334091187, loss=0.25063931941986084
test: epoch 121, loss 1.108422875404358, acc=0.675000011920929, loss=1.108422875404358
train: epoch 122, loss 0.23818260431289673, acc=0.9078333377838135, loss=0.23818260431289673
test: epoch 122, loss 1.1814442873001099, acc=0.6861110925674438, loss=1.1814442873001099
train: epoch 123, loss 0.24210898578166962, acc=0.9077777862548828, loss=0.24210898578166962
test: epoch 123, loss 1.0433475971221924, acc=0.6833333373069763, loss=1.0433475971221924
train: epoch 124, loss 0.24322572350502014, acc=0.9076666831970215, loss=0.24322572350502014
test: epoch 124, loss 1.189023494720459, acc=0.6666666865348816, loss=1.189023494720459
train: epoch 125, loss 0.24822308123111725, acc=0.9052777886390686, loss=0.24822308123111725
test: epoch 125, loss 1.1530475616455078, acc=0.6805555820465088, loss=1.1530475616455078
train: epoch 126, loss 0.24083435535430908, acc=0.909500002861023, loss=0.24083435535430908
test: epoch 126, loss 1.075236201286316, acc=0.6861110925674438, loss=1.075236201286316
train: epoch 127, loss 0.23431700468063354, acc=0.9111666679382324, loss=0.23431700468063354
test: epoch 127, loss 0.9971698522567749, acc=0.6861110925674438, loss=0.9971698522567749
train: epoch 128, loss 0.24226723611354828, acc=0.9073888659477234, loss=0.24226723611354828
test: epoch 128, loss 1.1682125329971313, acc=0.6861110925674438, loss=1.1682125329971313
train: epoch 129, loss 0.24529387056827545, acc=0.9065555334091187, loss=0.24529387056827545
test: epoch 129, loss 1.0717023611068726, acc=0.6833333373069763, loss=1.0717023611068726
train: epoch 130, loss 0.23109428584575653, acc=0.9116666913032532, loss=0.23109428584575653
test: epoch 130, loss 1.0790941715240479, acc=0.6638888716697693, loss=1.0790941715240479
train: epoch 131, loss 0.24592576920986176, acc=0.903166651725769, loss=0.24592576920986176
test: epoch 131, loss 0.9806285500526428, acc=0.6694444417953491, loss=0.9806285500526428
train: epoch 132, loss 0.23096172511577606, acc=0.9143333435058594, loss=0.23096172511577606
test: epoch 132, loss 1.0531179904937744, acc=0.6777777671813965, loss=1.0531179904937744
train: epoch 133, loss 0.23924565315246582, acc=0.9075000286102295, loss=0.23924565315246582
test: epoch 133, loss 1.089447259902954, acc=0.675000011920929, loss=1.089447259902954
train: epoch 134, loss 0.23710182309150696, acc=0.9057777523994446, loss=0.23710182309150696
test: epoch 134, loss 1.1433833837509155, acc=0.6777777671813965, loss=1.1433833837509155
train: epoch 135, loss 0.23488469421863556, acc=0.909500002861023, loss=0.23488469421863556
test: epoch 135, loss 1.1226962804794312, acc=0.6833333373069763, loss=1.1226962804794312
train: epoch 136, loss 0.2365526556968689, acc=0.9087777733802795, loss=0.2365526556968689
test: epoch 136, loss 0.9809823036193848, acc=0.6722221970558167, loss=0.9809823036193848
train: epoch 137, loss 0.24197377264499664, acc=0.9076666831970215, loss=0.24197377264499664
test: epoch 137, loss 1.0594027042388916, acc=0.6805555820465088, loss=1.0594027042388916
train: epoch 138, loss 0.24530164897441864, acc=0.9067777991294861, loss=0.24530164897441864
test: epoch 138, loss 1.0431286096572876, acc=0.6861110925674438, loss=1.0431286096572876
train: epoch 139, loss 0.23357021808624268, acc=0.9122777581214905, loss=0.23357021808624268
test: epoch 139, loss 1.248103380203247, acc=0.6805555820465088, loss=1.248103380203247
train: epoch 140, loss 0.23717641830444336, acc=0.9095555543899536, loss=0.23717641830444336
test: epoch 140, loss 1.0025982856750488, acc=0.6888889074325562, loss=1.0025982856750488
train: epoch 141, loss 0.23665845394134521, acc=0.9111111164093018, loss=0.23665845394134521
test: epoch 141, loss 1.0192062854766846, acc=0.6861110925674438, loss=1.0192062854766846
train: epoch 142, loss 0.23818297684192657, acc=0.9112777709960938, loss=0.23818297684192657
test: epoch 142, loss 1.003899335861206, acc=0.6861110925674438, loss=1.003899335861206
train: epoch 143, loss 0.224452942609787, acc=0.9146111011505127, loss=0.224452942609787
test: epoch 143, loss 1.1340923309326172, acc=0.6861110925674438, loss=1.1340923309326172
train: epoch 144, loss 0.2426508516073227, acc=0.906166672706604, loss=0.2426508516073227
test: epoch 144, loss 1.1174272298812866, acc=0.6722221970558167, loss=1.1174272298812866
train: epoch 145, loss 0.2399820238351822, acc=0.9097222089767456, loss=0.2399820238351822
test: epoch 145, loss 1.2261353731155396, acc=0.6777777671813965, loss=1.2261353731155396
train: epoch 146, loss 0.24264833331108093, acc=0.9097222089767456, loss=0.24264833331108093
test: epoch 146, loss 1.1097739934921265, acc=0.6833333373069763, loss=1.1097739934921265
train: epoch 147, loss 0.2368897795677185, acc=0.9094444513320923, loss=0.2368897795677185
test: epoch 147, loss 1.0606286525726318, acc=0.6805555820465088, loss=1.0606286525726318
train: epoch 148, loss 0.23714101314544678, acc=0.9101666808128357, loss=0.23714101314544678
test: epoch 148, loss 1.098105549812317, acc=0.6694444417953491, loss=1.098105549812317
train: epoch 149, loss 0.23017309606075287, acc=0.9118333458900452, loss=0.23017309606075287
test: epoch 149, loss 1.2399195432662964, acc=0.6666666865348816, loss=1.2399195432662964
train: epoch 150, loss 0.22822655737400055, acc=0.9097222089767456, loss=0.22822655737400055
test: epoch 150, loss 1.2806310653686523, acc=0.675000011920929, loss=1.2806310653686523
