# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=1.5", "--temp_decay=0.99", "--one_hot=1", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=643424603, receiver_embed_dim=64, save_run=0, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=643424603, receiver_embed_dim=64, save_run=False, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.3208515644073486, acc=0.060777775943279266, loss=3.3208515644073486
test: epoch 1, loss 4.247804164886475, acc=0.06388889253139496, loss=4.247804164886475
train: epoch 2, loss 2.1531927585601807, acc=0.25333333015441895, loss=2.1531927585601807
test: epoch 2, loss 2.898440361022949, acc=0.15833333134651184, loss=2.898440361022949
train: epoch 3, loss 1.557268738746643, acc=0.3888888955116272, loss=1.557268738746643
test: epoch 3, loss 2.5757768154144287, acc=0.16111111640930176, loss=2.5757768154144287
train: epoch 4, loss 1.3401020765304565, acc=0.47261109948158264, loss=1.3401020765304565
test: epoch 4, loss 2.4505269527435303, acc=0.17777778208255768, loss=2.4505269527435303
train: epoch 5, loss 1.195343017578125, acc=0.5256111025810242, loss=1.195343017578125
test: epoch 5, loss 2.2654125690460205, acc=0.2083333283662796, loss=2.2654125690460205
train: epoch 6, loss 1.0799758434295654, acc=0.5693333148956299, loss=1.0799758434295654
test: epoch 6, loss 2.266940116882324, acc=0.24722221493721008, loss=2.266940116882324
train: epoch 7, loss 1.0180975198745728, acc=0.6047777533531189, loss=1.0180975198745728
test: epoch 7, loss 2.309340715408325, acc=0.2361111044883728, loss=2.309340715408325
train: epoch 8, loss 0.9399808645248413, acc=0.6359999775886536, loss=0.9399808645248413
test: epoch 8, loss 2.1668131351470947, acc=0.24722221493721008, loss=2.1668131351470947
train: epoch 9, loss 0.8894843459129333, acc=0.6538888812065125, loss=0.8894843459129333
test: epoch 9, loss 2.128967761993408, acc=0.2777777910232544, loss=2.128967761993408
train: epoch 10, loss 0.8446019887924194, acc=0.675611138343811, loss=0.8446019887924194
test: epoch 10, loss 1.947637677192688, acc=0.29722222685813904, loss=1.947637677192688
train: epoch 11, loss 0.7895795702934265, acc=0.7028889060020447, loss=0.7895795702934265
test: epoch 11, loss 1.9549939632415771, acc=0.28333333134651184, loss=1.9549939632415771
train: epoch 12, loss 0.7555141448974609, acc=0.7132222056388855, loss=0.7555141448974609
test: epoch 12, loss 1.8896608352661133, acc=0.2916666567325592, loss=1.8896608352661133
train: epoch 13, loss 0.7209619283676147, acc=0.7271111011505127, loss=0.7209619283676147
test: epoch 13, loss 1.8238149881362915, acc=0.3222222328186035, loss=1.8238149881362915
train: epoch 14, loss 0.6874855160713196, acc=0.7393888831138611, loss=0.6874855160713196
test: epoch 14, loss 1.8307546377182007, acc=0.3305555582046509, loss=1.8307546377182007
train: epoch 15, loss 0.6695465445518494, acc=0.7443333268165588, loss=0.6695465445518494
test: epoch 15, loss 1.6708264350891113, acc=0.375, loss=1.6708264350891113
train: epoch 16, loss 0.6445605754852295, acc=0.7573888897895813, loss=0.6445605754852295
test: epoch 16, loss 1.6691603660583496, acc=0.34166666865348816, loss=1.6691603660583496
train: epoch 17, loss 0.6235276460647583, acc=0.769777774810791, loss=0.6235276460647583
test: epoch 17, loss 1.54784095287323, acc=0.3777777850627899, loss=1.54784095287323
train: epoch 18, loss 0.598503589630127, acc=0.7764444351196289, loss=0.598503589630127
test: epoch 18, loss 1.6442854404449463, acc=0.36944442987442017, loss=1.6442854404449463
train: epoch 19, loss 0.57821124792099, acc=0.7817777991294861, loss=0.57821124792099
test: epoch 19, loss 1.5305335521697998, acc=0.3861111104488373, loss=1.5305335521697998
train: epoch 20, loss 0.5554842948913574, acc=0.7937777638435364, loss=0.5554842948913574
test: epoch 20, loss 1.6053085327148438, acc=0.4027777910232544, loss=1.6053085327148438
train: epoch 21, loss 0.5465107560157776, acc=0.8033333420753479, loss=0.5465107560157776
test: epoch 21, loss 1.5248476266860962, acc=0.4138889014720917, loss=1.5248476266860962
train: epoch 22, loss 0.5100289583206177, acc=0.8123888969421387, loss=0.5100289583206177
test: epoch 22, loss 1.5135207176208496, acc=0.4472222328186035, loss=1.5135207176208496
train: epoch 23, loss 0.5004982352256775, acc=0.8133888840675354, loss=0.5004982352256775
test: epoch 23, loss 1.5184803009033203, acc=0.4583333432674408, loss=1.5184803009033203
train: epoch 24, loss 0.501090407371521, acc=0.8153333067893982, loss=0.501090407371521
test: epoch 24, loss 1.5512346029281616, acc=0.42222222685813904, loss=1.5512346029281616
train: epoch 25, loss 0.4801485240459442, acc=0.8230555653572083, loss=0.4801485240459442
test: epoch 25, loss 1.497712254524231, acc=0.4444444477558136, loss=1.497712254524231
train: epoch 26, loss 0.46683478355407715, acc=0.8255555629730225, loss=0.46683478355407715
test: epoch 26, loss 1.581827163696289, acc=0.4611110985279083, loss=1.581827163696289
train: epoch 27, loss 0.456626832485199, acc=0.8320000171661377, loss=0.456626832485199
test: epoch 27, loss 1.5417234897613525, acc=0.4444444477558136, loss=1.5417234897613525
train: epoch 28, loss 0.4361777603626251, acc=0.8412777781486511, loss=0.4361777603626251
test: epoch 28, loss 1.43219792842865, acc=0.4583333432674408, loss=1.43219792842865
train: epoch 29, loss 0.43518000841140747, acc=0.8413888812065125, loss=0.43518000841140747
test: epoch 29, loss 1.3166158199310303, acc=0.4611110985279083, loss=1.3166158199310303
train: epoch 30, loss 0.4110485911369324, acc=0.8508333563804626, loss=0.4110485911369324
test: epoch 30, loss 1.4274624586105347, acc=0.4722222089767456, loss=1.4274624586105347
train: epoch 31, loss 0.39830511808395386, acc=0.8528888821601868, loss=0.39830511808395386
test: epoch 31, loss 1.4224193096160889, acc=0.4888888895511627, loss=1.4224193096160889
train: epoch 32, loss 0.39950546622276306, acc=0.851722240447998, loss=0.39950546622276306
test: epoch 32, loss 1.3309510946273804, acc=0.5, loss=1.3309510946273804
train: epoch 33, loss 0.3785669207572937, acc=0.8611666560173035, loss=0.3785669207572937
test: epoch 33, loss 1.2483471632003784, acc=0.5, loss=1.2483471632003784
train: epoch 34, loss 0.3747393786907196, acc=0.8611111044883728, loss=0.3747393786907196
test: epoch 34, loss 1.2635133266448975, acc=0.5138888955116272, loss=1.2635133266448975
train: epoch 35, loss 0.3768327534198761, acc=0.8647778034210205, loss=0.3768327534198761
test: epoch 35, loss 1.2209117412567139, acc=0.5138888955116272, loss=1.2209117412567139
train: epoch 36, loss 0.3518054187297821, acc=0.8715000152587891, loss=0.3518054187297821
test: epoch 36, loss 1.2805863618850708, acc=0.5277777910232544, loss=1.2805863618850708
train: epoch 37, loss 0.351519912481308, acc=0.8703888654708862, loss=0.351519912481308
test: epoch 37, loss 1.1344760656356812, acc=0.550000011920929, loss=1.1344760656356812
train: epoch 38, loss 0.34832656383514404, acc=0.8759999871253967, loss=0.34832656383514404
test: epoch 38, loss 1.178809404373169, acc=0.5611110925674438, loss=1.178809404373169
train: epoch 39, loss 0.3360028564929962, acc=0.8828333616256714, loss=0.3360028564929962
test: epoch 39, loss 1.313932180404663, acc=0.5277777910232544, loss=1.313932180404663
train: epoch 40, loss 0.329839825630188, acc=0.8831111192703247, loss=0.329839825630188
test: epoch 40, loss 1.3417840003967285, acc=0.5416666865348816, loss=1.3417840003967285
train: epoch 41, loss 0.3130224645137787, acc=0.8892222046852112, loss=0.3130224645137787
test: epoch 41, loss 1.199055790901184, acc=0.5722222328186035, loss=1.199055790901184
train: epoch 42, loss 0.31580060720443726, acc=0.8889444470405579, loss=0.31580060720443726
test: epoch 42, loss 1.1633485555648804, acc=0.5666666626930237, loss=1.1633485555648804
train: epoch 43, loss 0.30255645513534546, acc=0.8937777876853943, loss=0.30255645513534546
test: epoch 43, loss 1.194588303565979, acc=0.5722222328186035, loss=1.194588303565979
train: epoch 44, loss 0.31114596128463745, acc=0.8899444341659546, loss=0.31114596128463745
test: epoch 44, loss 1.0871539115905762, acc=0.5916666388511658, loss=1.0871539115905762
train: epoch 45, loss 0.3048151731491089, acc=0.8896666765213013, loss=0.3048151731491089
test: epoch 45, loss 1.1347978115081787, acc=0.5972222089767456, loss=1.1347978115081787
train: epoch 46, loss 0.2897345721721649, acc=0.894611120223999, loss=0.2897345721721649
test: epoch 46, loss 1.0417544841766357, acc=0.6222222447395325, loss=1.0417544841766357
train: epoch 47, loss 0.2884266674518585, acc=0.8952222466468811, loss=0.2884266674518585
test: epoch 47, loss 1.0457156896591187, acc=0.6166666746139526, loss=1.0457156896591187
train: epoch 48, loss 0.2879081070423126, acc=0.898277759552002, loss=0.2879081070423126
test: epoch 48, loss 1.0065836906433105, acc=0.6305555701255798, loss=1.0065836906433105
train: epoch 49, loss 0.29071035981178284, acc=0.8959444165229797, loss=0.29071035981178284
test: epoch 49, loss 1.0053246021270752, acc=0.6222222447395325, loss=1.0053246021270752
train: epoch 50, loss 0.2822837829589844, acc=0.8981666564941406, loss=0.2822837829589844
test: epoch 50, loss 1.0398271083831787, acc=0.6361111402511597, loss=1.0398271083831787
train: epoch 51, loss 0.28187164664268494, acc=0.8961111307144165, loss=0.28187164664268494
test: epoch 51, loss 1.0172467231750488, acc=0.6499999761581421, loss=1.0172467231750488
train: epoch 52, loss 0.2627570331096649, acc=0.9057222008705139, loss=0.2627570331096649
test: epoch 52, loss 0.9530490636825562, acc=0.6416666507720947, loss=0.9530490636825562
train: epoch 53, loss 0.27232274413108826, acc=0.9013888835906982, loss=0.27232274413108826
test: epoch 53, loss 0.9940487742424011, acc=0.6722221970558167, loss=0.9940487742424011
train: epoch 54, loss 0.2634950876235962, acc=0.9014444351196289, loss=0.2634950876235962
test: epoch 54, loss 0.8857713937759399, acc=0.6777777671813965, loss=0.8857713937759399
train: epoch 55, loss 0.2655395567417145, acc=0.8988333344459534, loss=0.2655395567417145
test: epoch 55, loss 0.9320633411407471, acc=0.6833333373069763, loss=0.9320633411407471
train: epoch 56, loss 0.2662150263786316, acc=0.9008333086967468, loss=0.2662150263786316
test: epoch 56, loss 0.8580765128135681, acc=0.6888889074325562, loss=0.8580765128135681
train: epoch 57, loss 0.26679280400276184, acc=0.901888906955719, loss=0.26679280400276184
test: epoch 57, loss 0.9301974773406982, acc=0.6833333373069763, loss=0.9301974773406982
train: epoch 58, loss 0.26804712414741516, acc=0.901888906955719, loss=0.26804712414741516
test: epoch 58, loss 0.9007983803749084, acc=0.6944444179534912, loss=0.9007983803749084
train: epoch 59, loss 0.26115649938583374, acc=0.9037777781486511, loss=0.26115649938583374
test: epoch 59, loss 0.8548553586006165, acc=0.699999988079071, loss=0.8548553586006165
train: epoch 60, loss 0.25737887620925903, acc=0.9021111130714417, loss=0.25737887620925903
test: epoch 60, loss 0.870874285697937, acc=0.7055555582046509, loss=0.870874285697937
train: epoch 61, loss 0.2760133147239685, acc=0.8993333578109741, loss=0.2760133147239685
test: epoch 61, loss 0.8115765452384949, acc=0.6972222328186035, loss=0.8115765452384949
train: epoch 62, loss 0.25974583625793457, acc=0.9021111130714417, loss=0.25974583625793457
test: epoch 62, loss 0.7828009724617004, acc=0.7055555582046509, loss=0.7828009724617004
train: epoch 63, loss 0.2547858655452728, acc=0.9043889045715332, loss=0.2547858655452728
test: epoch 63, loss 0.7964382171630859, acc=0.699999988079071, loss=0.7964382171630859
train: epoch 64, loss 0.25125542283058167, acc=0.9046666622161865, loss=0.25125542283058167
test: epoch 64, loss 0.7631849646568298, acc=0.7138888835906982, loss=0.7631849646568298
train: epoch 65, loss 0.26082292199134827, acc=0.9012222290039062, loss=0.26082292199134827
test: epoch 65, loss 0.7516671419143677, acc=0.7277777791023254, loss=0.7516671419143677
train: epoch 66, loss 0.2669261693954468, acc=0.9036111235618591, loss=0.2669261693954468
test: epoch 66, loss 0.7544131875038147, acc=0.7194444537162781, loss=0.7544131875038147
train: epoch 67, loss 0.2547464370727539, acc=0.9035000205039978, loss=0.2547464370727539
test: epoch 67, loss 0.707205593585968, acc=0.7416666746139526, loss=0.707205593585968
train: epoch 68, loss 0.2616102993488312, acc=0.9068333506584167, loss=0.2616102993488312
test: epoch 68, loss 0.7693688273429871, acc=0.7361111044883728, loss=0.7693688273429871
train: epoch 69, loss 0.254951536655426, acc=0.9039999842643738, loss=0.254951536655426
test: epoch 69, loss 0.7061592936515808, acc=0.7416666746139526, loss=0.7061592936515808
train: epoch 70, loss 0.24550405144691467, acc=0.9062222242355347, loss=0.24550405144691467
test: epoch 70, loss 0.7276623249053955, acc=0.7472222447395325, loss=0.7276623249053955
train: epoch 71, loss 0.243501678109169, acc=0.9055555462837219, loss=0.243501678109169
test: epoch 71, loss 0.730638325214386, acc=0.7277777791023254, loss=0.730638325214386
train: epoch 72, loss 0.24166716635227203, acc=0.9101666808128357, loss=0.24166716635227203
test: epoch 72, loss 0.7264986634254456, acc=0.7611111402511597, loss=0.7264986634254456
train: epoch 73, loss 0.23557518422603607, acc=0.9091110825538635, loss=0.23557518422603607
test: epoch 73, loss 0.6677204370498657, acc=0.7722222208976746, loss=0.6677204370498657
train: epoch 74, loss 0.23446273803710938, acc=0.9098888635635376, loss=0.23446273803710938
test: epoch 74, loss 0.652655303478241, acc=0.7638888955116272, loss=0.652655303478241
train: epoch 75, loss 0.23717400431632996, acc=0.910611093044281, loss=0.23717400431632996
test: epoch 75, loss 0.6512947082519531, acc=0.7749999761581421, loss=0.6512947082519531
train: epoch 76, loss 0.2315939962863922, acc=0.9112222194671631, loss=0.2315939962863922
test: epoch 76, loss 0.60603928565979, acc=0.7777777910232544, loss=0.60603928565979
train: epoch 77, loss 0.2229013890028, acc=0.9133889079093933, loss=0.2229013890028
test: epoch 77, loss 0.6263445019721985, acc=0.7583333253860474, loss=0.6263445019721985
train: epoch 78, loss 0.21714921295642853, acc=0.9162777662277222, loss=0.21714921295642853
test: epoch 78, loss 0.6088851094245911, acc=0.7861111164093018, loss=0.6088851094245911
train: epoch 79, loss 0.23317785561084747, acc=0.9122777581214905, loss=0.23317785561084747
test: epoch 79, loss 0.587525486946106, acc=0.7805555462837219, loss=0.587525486946106
train: epoch 80, loss 0.217186838388443, acc=0.9160555601119995, loss=0.217186838388443
test: epoch 80, loss 0.6353779435157776, acc=0.7722222208976746, loss=0.6353779435157776
train: epoch 81, loss 0.2202402502298355, acc=0.9142777919769287, loss=0.2202402502298355
test: epoch 81, loss 0.5890112519264221, acc=0.7944444417953491, loss=0.5890112519264221
train: epoch 82, loss 0.2125891000032425, acc=0.9191666841506958, loss=0.2125891000032425
test: epoch 82, loss 0.6000649333000183, acc=0.7805555462837219, loss=0.6000649333000183
train: epoch 83, loss 0.2074393481016159, acc=0.9220555424690247, loss=0.2074393481016159
test: epoch 83, loss 0.6030450463294983, acc=0.7861111164093018, loss=0.6030450463294983
train: epoch 84, loss 0.19770419597625732, acc=0.9228888750076294, loss=0.19770419597625732
test: epoch 84, loss 0.6165875792503357, acc=0.7861111164093018, loss=0.6165875792503357
train: epoch 85, loss 0.20526018738746643, acc=0.9208333492279053, loss=0.20526018738746643
test: epoch 85, loss 0.6295715570449829, acc=0.7916666865348816, loss=0.6295715570449829
train: epoch 86, loss 0.20479342341423035, acc=0.9203333258628845, loss=0.20479342341423035
test: epoch 86, loss 0.6216773390769958, acc=0.7888888716697693, loss=0.6216773390769958
train: epoch 87, loss 0.21323896944522858, acc=0.9173333048820496, loss=0.21323896944522858
test: epoch 87, loss 0.6400007605552673, acc=0.7944444417953491, loss=0.6400007605552673
train: epoch 88, loss 0.2041490226984024, acc=0.9220555424690247, loss=0.2041490226984024
test: epoch 88, loss 0.5931444764137268, acc=0.7916666865348816, loss=0.5931444764137268
train: epoch 89, loss 0.18923579156398773, acc=0.9261666536331177, loss=0.18923579156398773
test: epoch 89, loss 0.6323533058166504, acc=0.7916666865348816, loss=0.6323533058166504
train: epoch 90, loss 0.19153337180614471, acc=0.9269444346427917, loss=0.19153337180614471
test: epoch 90, loss 0.6277047991752625, acc=0.7944444417953491, loss=0.6277047991752625
train: epoch 91, loss 0.19078759849071503, acc=0.9253333210945129, loss=0.19078759849071503
test: epoch 91, loss 0.5436220765113831, acc=0.800000011920929, loss=0.5436220765113831
train: epoch 92, loss 0.20432592928409576, acc=0.922166645526886, loss=0.20432592928409576
test: epoch 92, loss 0.5976999402046204, acc=0.7972221970558167, loss=0.5976999402046204
train: epoch 93, loss 0.1894589066505432, acc=0.9251111149787903, loss=0.1894589066505432
test: epoch 93, loss 0.636345624923706, acc=0.7944444417953491, loss=0.636345624923706
train: epoch 94, loss 0.18669380247592926, acc=0.9292222261428833, loss=0.18669380247592926
test: epoch 94, loss 0.6246833801269531, acc=0.7972221970558167, loss=0.6246833801269531
train: epoch 95, loss 0.19345316290855408, acc=0.925166666507721, loss=0.19345316290855408
test: epoch 95, loss 0.6023685336112976, acc=0.800000011920929, loss=0.6023685336112976
train: epoch 96, loss 0.18864299356937408, acc=0.9247221946716309, loss=0.18864299356937408
test: epoch 96, loss 0.6564154028892517, acc=0.8027777671813965, loss=0.6564154028892517
train: epoch 97, loss 0.18853415548801422, acc=0.9275000095367432, loss=0.18853415548801422
test: epoch 97, loss 0.5524019002914429, acc=0.8083333373069763, loss=0.5524019002914429
train: epoch 98, loss 0.1894880086183548, acc=0.9236111044883728, loss=0.1894880086183548
test: epoch 98, loss 0.5588250756263733, acc=0.8027777671813965, loss=0.5588250756263733
train: epoch 99, loss 0.18789884448051453, acc=0.9270555377006531, loss=0.18789884448051453
test: epoch 99, loss 0.5853310823440552, acc=0.8027777671813965, loss=0.5853310823440552
train: epoch 100, loss 0.18352358043193817, acc=0.9273889064788818, loss=0.18352358043193817
test: epoch 100, loss 0.6029371023178101, acc=0.8027777671813965, loss=0.6029371023178101
train: epoch 101, loss 0.18797388672828674, acc=0.9272222518920898, loss=0.18797388672828674
test: epoch 101, loss 0.6378641128540039, acc=0.8027777671813965, loss=0.6378641128540039
train: epoch 102, loss 0.1810721904039383, acc=0.9273889064788818, loss=0.1810721904039383
test: epoch 102, loss 0.6078011393547058, acc=0.8027777671813965, loss=0.6078011393547058
train: epoch 103, loss 0.18304531276226044, acc=0.9263888597488403, loss=0.18304531276226044
test: epoch 103, loss 0.6057450175285339, acc=0.8027777671813965, loss=0.6057450175285339
train: epoch 104, loss 0.18311309814453125, acc=0.9257222414016724, loss=0.18311309814453125
test: epoch 104, loss 0.5857677459716797, acc=0.8027777671813965, loss=0.5857677459716797
train: epoch 105, loss 0.17817771434783936, acc=0.9268333315849304, loss=0.17817771434783936
test: epoch 105, loss 0.5409554839134216, acc=0.8027777671813965, loss=0.5409554839134216
train: epoch 106, loss 0.18929357826709747, acc=0.9273889064788818, loss=0.18929357826709747
test: epoch 106, loss 0.5459855794906616, acc=0.8055555820465088, loss=0.5459855794906616
train: epoch 107, loss 0.18191301822662354, acc=0.9277222156524658, loss=0.18191301822662354
test: epoch 107, loss 0.5970107316970825, acc=0.8027777671813965, loss=0.5970107316970825
train: epoch 108, loss 0.17800793051719666, acc=0.9287222027778625, loss=0.17800793051719666
test: epoch 108, loss 0.6188569068908691, acc=0.8055555820465088, loss=0.6188569068908691
train: epoch 109, loss 0.1792803257703781, acc=0.929722249507904, loss=0.1792803257703781
test: epoch 109, loss 0.6492329239845276, acc=0.8055555820465088, loss=0.6492329239845276
train: epoch 110, loss 0.18014560639858246, acc=0.9275000095367432, loss=0.18014560639858246
test: epoch 110, loss 0.55543452501297, acc=0.8055555820465088, loss=0.55543452501297
train: epoch 111, loss 0.1750982701778412, acc=0.9294999837875366, loss=0.1750982701778412
test: epoch 111, loss 0.5747999548912048, acc=0.8111110925674438, loss=0.5747999548912048
train: epoch 112, loss 0.17904508113861084, acc=0.9307777881622314, loss=0.17904508113861084
test: epoch 112, loss 0.6223564147949219, acc=0.8083333373069763, loss=0.6223564147949219
train: epoch 113, loss 0.18147079646587372, acc=0.9297778010368347, loss=0.18147079646587372
test: epoch 113, loss 0.6472657918930054, acc=0.8027777671813965, loss=0.6472657918930054
train: epoch 114, loss 0.17592619359493256, acc=0.9307222366333008, loss=0.17592619359493256
test: epoch 114, loss 0.6034773588180542, acc=0.8083333373069763, loss=0.6034773588180542
train: epoch 115, loss 0.17135654389858246, acc=0.93022221326828, loss=0.17135654389858246
test: epoch 115, loss 0.6027313470840454, acc=0.8111110925674438, loss=0.6027313470840454
train: epoch 116, loss 0.17753726243972778, acc=0.9308333396911621, loss=0.17753726243972778
test: epoch 116, loss 0.6128447651863098, acc=0.8138889074325562, loss=0.6128447651863098
train: epoch 117, loss 0.1712014079093933, acc=0.9303333163261414, loss=0.1712014079093933
test: epoch 117, loss 0.6066574454307556, acc=0.8055555820465088, loss=0.6066574454307556
train: epoch 118, loss 0.1715993583202362, acc=0.9306111335754395, loss=0.1715993583202362
test: epoch 118, loss 0.5095507502555847, acc=0.8166666626930237, loss=0.5095507502555847
train: epoch 119, loss 0.17264318466186523, acc=0.9315000176429749, loss=0.17264318466186523
test: epoch 119, loss 0.5573379397392273, acc=0.8055555820465088, loss=0.5573379397392273
train: epoch 120, loss 0.16429293155670166, acc=0.9319444298744202, loss=0.16429293155670166
test: epoch 120, loss 0.5636140704154968, acc=0.8083333373069763, loss=0.5636140704154968
train: epoch 121, loss 0.16256801784038544, acc=0.9345555305480957, loss=0.16256801784038544
test: epoch 121, loss 0.5243058800697327, acc=0.8138889074325562, loss=0.5243058800697327
train: epoch 122, loss 0.18052852153778076, acc=0.9290000200271606, loss=0.18052852153778076
test: epoch 122, loss 0.6033767461776733, acc=0.8138889074325562, loss=0.6033767461776733
train: epoch 123, loss 0.16190284490585327, acc=0.9347777962684631, loss=0.16190284490585327
test: epoch 123, loss 0.4991043210029602, acc=0.8083333373069763, loss=0.4991043210029602
train: epoch 124, loss 0.16491025686264038, acc=0.9345555305480957, loss=0.16491025686264038
test: epoch 124, loss 0.5952206254005432, acc=0.8083333373069763, loss=0.5952206254005432
train: epoch 125, loss 0.16752468049526215, acc=0.9326666593551636, loss=0.16752468049526215
test: epoch 125, loss 0.5239402055740356, acc=0.8083333373069763, loss=0.5239402055740356
train: epoch 126, loss 0.1679888516664505, acc=0.9318333268165588, loss=0.1679888516664505
test: epoch 126, loss 0.5826202630996704, acc=0.8083333373069763, loss=0.5826202630996704
train: epoch 127, loss 0.16216561198234558, acc=0.9322777986526489, loss=0.16216561198234558
test: epoch 127, loss 0.547812819480896, acc=0.8083333373069763, loss=0.547812819480896
train: epoch 128, loss 0.1610645353794098, acc=0.9324444532394409, loss=0.1610645353794098
test: epoch 128, loss 0.5770459771156311, acc=0.8083333373069763, loss=0.5770459771156311
train: epoch 129, loss 0.1682373732328415, acc=0.9307222366333008, loss=0.1682373732328415
test: epoch 129, loss 0.48239973187446594, acc=0.8111110925674438, loss=0.48239973187446594
train: epoch 130, loss 0.16353558003902435, acc=0.9315555691719055, loss=0.16353558003902435
test: epoch 130, loss 0.5991042852401733, acc=0.8111110925674438, loss=0.5991042852401733
train: epoch 131, loss 0.16244976222515106, acc=0.9329444169998169, loss=0.16244976222515106
test: epoch 131, loss 0.6699591279029846, acc=0.8083333373069763, loss=0.6699591279029846
train: epoch 132, loss 0.15836109220981598, acc=0.9352777600288391, loss=0.15836109220981598
test: epoch 132, loss 0.5956021547317505, acc=0.8055555820465088, loss=0.5956021547317505
train: epoch 133, loss 0.17168401181697845, acc=0.9313333630561829, loss=0.17168401181697845
test: epoch 133, loss 0.5687522888183594, acc=0.8083333373069763, loss=0.5687522888183594
train: epoch 134, loss 0.16630370914936066, acc=0.933055579662323, loss=0.16630370914936066
test: epoch 134, loss 0.6109200716018677, acc=0.8083333373069763, loss=0.6109200716018677
train: epoch 135, loss 0.16293983161449432, acc=0.9340000152587891, loss=0.16293983161449432
test: epoch 135, loss 0.585423469543457, acc=0.8111110925674438, loss=0.585423469543457
train: epoch 136, loss 0.16510653495788574, acc=0.9338333606719971, loss=0.16510653495788574
test: epoch 136, loss 0.6276627779006958, acc=0.8083333373069763, loss=0.6276627779006958
train: epoch 137, loss 0.15405747294425964, acc=0.9368333220481873, loss=0.15405747294425964
test: epoch 137, loss 0.6291416883468628, acc=0.8083333373069763, loss=0.6291416883468628
train: epoch 138, loss 0.15891095995903015, acc=0.9348333477973938, loss=0.15891095995903015
test: epoch 138, loss 0.5687562227249146, acc=0.8083333373069763, loss=0.5687562227249146
train: epoch 139, loss 0.16271986067295074, acc=0.9338333606719971, loss=0.16271986067295074
test: epoch 139, loss 0.6091877818107605, acc=0.8138889074325562, loss=0.6091877818107605
train: epoch 140, loss 0.15460766851902008, acc=0.9362778067588806, loss=0.15460766851902008
test: epoch 140, loss 0.598544180393219, acc=0.8111110925674438, loss=0.598544180393219
train: epoch 141, loss 0.15644101798534393, acc=0.934499979019165, loss=0.15644101798534393
test: epoch 141, loss 0.5555629730224609, acc=0.8083333373069763, loss=0.5555629730224609
train: epoch 142, loss 0.1572231948375702, acc=0.933055579662323, loss=0.1572231948375702
test: epoch 142, loss 0.5740669369697571, acc=0.8083333373069763, loss=0.5740669369697571
train: epoch 143, loss 0.16026826202869415, acc=0.9337777495384216, loss=0.16026826202869415
test: epoch 143, loss 0.5638776421546936, acc=0.8083333373069763, loss=0.5638776421546936
train: epoch 144, loss 0.16039220988750458, acc=0.9345555305480957, loss=0.16039220988750458
test: epoch 144, loss 0.5116252303123474, acc=0.8083333373069763, loss=0.5116252303123474
train: epoch 145, loss 0.15624332427978516, acc=0.9351666569709778, loss=0.15624332427978516
test: epoch 145, loss 0.6149523258209229, acc=0.8111110925674438, loss=0.6149523258209229
train: epoch 146, loss 0.15999524295330048, acc=0.9338889122009277, loss=0.15999524295330048
test: epoch 146, loss 0.6044637560844421, acc=0.8083333373069763, loss=0.6044637560844421
train: epoch 147, loss 0.15873967111110687, acc=0.9336666464805603, loss=0.15873967111110687
test: epoch 147, loss 0.5833767652511597, acc=0.8111110925674438, loss=0.5833767652511597
train: epoch 148, loss 0.15938812494277954, acc=0.9346110820770264, loss=0.15938812494277954
test: epoch 148, loss 0.5235457420349121, acc=0.8083333373069763, loss=0.5235457420349121
train: epoch 149, loss 0.1624511480331421, acc=0.9342222213745117, loss=0.1624511480331421
test: epoch 149, loss 0.5101395845413208, acc=0.8055555820465088, loss=0.5101395845413208
train: epoch 150, loss 0.15404531359672546, acc=0.9363889098167419, loss=0.15404531359672546
test: epoch 150, loss 0.5777295827865601, acc=0.8083333373069763, loss=0.5777295827865601
