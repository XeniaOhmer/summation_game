# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=1", "--n_layers=1"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=142196004, receiver_embed_dim=32, save_run=0, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=142196004, receiver_embed_dim=32, save_run=False, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.5363967418670654, acc=0.050111111253499985, loss=3.5363967418670654
test: epoch 1, loss 3.445817708969116, acc=0.0555555559694767, loss=3.445817708969116
train: epoch 2, loss 3.4548773765563965, acc=0.05344444513320923, loss=3.4548773765563965
test: epoch 2, loss 3.119464874267578, acc=0.0972222238779068, loss=3.119464874267578
train: epoch 3, loss 3.2339701652526855, acc=0.07677777856588364, loss=3.2339701652526855
test: epoch 3, loss 4.7423319816589355, acc=0.06666667014360428, loss=4.7423319816589355
train: epoch 4, loss 2.7420167922973633, acc=0.14777778089046478, loss=2.7420167922973633
test: epoch 4, loss 6.725706577301025, acc=0.04444444552063942, loss=6.725706577301025
train: epoch 5, loss 2.4582765102386475, acc=0.1951666623353958, loss=2.4582765102386475
test: epoch 5, loss 7.06096076965332, acc=0.05000000074505806, loss=7.06096076965332
train: epoch 6, loss 2.2967450618743896, acc=0.22333332896232605, loss=2.2967450618743896
test: epoch 6, loss 7.2606520652771, acc=0.0555555559694767, loss=7.2606520652771
train: epoch 7, loss 2.191953182220459, acc=0.24488888680934906, loss=2.191953182220459
test: epoch 7, loss 7.343130111694336, acc=0.06111111119389534, loss=7.343130111694336
train: epoch 8, loss 2.117487668991089, acc=0.25866666436195374, loss=2.117487668991089
test: epoch 8, loss 7.0489888191223145, acc=0.06111111119389534, loss=7.0489888191223145
train: epoch 9, loss 2.0580546855926514, acc=0.27783334255218506, loss=2.0580546855926514
test: epoch 9, loss 7.369011878967285, acc=0.06388889253139496, loss=7.369011878967285
train: epoch 10, loss 2.0063750743865967, acc=0.2903333306312561, loss=2.0063750743865967
test: epoch 10, loss 7.430792331695557, acc=0.07222222536802292, loss=7.430792331695557
train: epoch 11, loss 1.962385654449463, acc=0.2986111044883728, loss=1.962385654449463
test: epoch 11, loss 7.483541488647461, acc=0.07500000298023224, loss=7.483541488647461
train: epoch 12, loss 1.9260364770889282, acc=0.31361111998558044, loss=1.9260364770889282
test: epoch 12, loss 7.541799545288086, acc=0.0694444477558136, loss=7.541799545288086
train: epoch 13, loss 1.8996388912200928, acc=0.31450000405311584, loss=1.8996388912200928
test: epoch 13, loss 7.633265495300293, acc=0.0694444477558136, loss=7.633265495300293
train: epoch 14, loss 1.8656100034713745, acc=0.33205556869506836, loss=1.8656100034713745
test: epoch 14, loss 7.48427152633667, acc=0.08888889104127884, loss=7.48427152633667
train: epoch 15, loss 1.8322231769561768, acc=0.34372222423553467, loss=1.8322231769561768
test: epoch 15, loss 7.377328872680664, acc=0.08611111342906952, loss=7.377328872680664
train: epoch 16, loss 1.8058563470840454, acc=0.34522223472595215, loss=1.8058563470840454
test: epoch 16, loss 7.526650905609131, acc=0.07777778059244156, loss=7.526650905609131
train: epoch 17, loss 1.7703503370285034, acc=0.3630000054836273, loss=1.7703503370285034
test: epoch 17, loss 7.437618255615234, acc=0.0694444477558136, loss=7.437618255615234
train: epoch 18, loss 1.743484377861023, acc=0.3715555667877197, loss=1.743484377861023
test: epoch 18, loss 7.080770015716553, acc=0.06666667014360428, loss=7.080770015716553
train: epoch 19, loss 1.7258808612823486, acc=0.37700000405311584, loss=1.7258808612823486
test: epoch 19, loss 6.783087253570557, acc=0.06388889253139496, loss=6.783087253570557
train: epoch 20, loss 1.6905601024627686, acc=0.38588887453079224, loss=1.6905601024627686
test: epoch 20, loss 6.511321544647217, acc=0.07500000298023224, loss=6.511321544647217
train: epoch 21, loss 1.67943274974823, acc=0.39827778935432434, loss=1.67943274974823
test: epoch 21, loss 6.2453532218933105, acc=0.08055555820465088, loss=6.2453532218933105
train: epoch 22, loss 1.6565144062042236, acc=0.4076666533946991, loss=1.6565144062042236
test: epoch 22, loss 5.86607551574707, acc=0.0972222238779068, loss=5.86607551574707
train: epoch 23, loss 1.6143996715545654, acc=0.4166666567325592, loss=1.6143996715545654
test: epoch 23, loss 5.717479705810547, acc=0.0972222238779068, loss=5.717479705810547
train: epoch 24, loss 1.6092627048492432, acc=0.42072221636772156, loss=1.6092627048492432
test: epoch 24, loss 5.499985694885254, acc=0.10833333432674408, loss=5.499985694885254
train: epoch 25, loss 1.5774779319763184, acc=0.42888888716697693, loss=1.5774779319763184
test: epoch 25, loss 5.210768222808838, acc=0.11666666716337204, loss=5.210768222808838
train: epoch 26, loss 1.5587347745895386, acc=0.43372222781181335, loss=1.5587347745895386
test: epoch 26, loss 5.132455825805664, acc=0.11666666716337204, loss=5.132455825805664
train: epoch 27, loss 1.5365774631500244, acc=0.44555556774139404, loss=1.5365774631500244
test: epoch 27, loss 4.93503475189209, acc=0.11944444477558136, loss=4.93503475189209
train: epoch 28, loss 1.5184766054153442, acc=0.45455554127693176, loss=1.5184766054153442
test: epoch 28, loss 4.812618732452393, acc=0.13611111044883728, loss=4.812618732452393
train: epoch 29, loss 1.5031567811965942, acc=0.46000000834465027, loss=1.5031567811965942
test: epoch 29, loss 4.651108264923096, acc=0.13611111044883728, loss=4.651108264923096
train: epoch 30, loss 1.4809778928756714, acc=0.4698333442211151, loss=1.4809778928756714
test: epoch 30, loss 4.474273204803467, acc=0.14722222089767456, loss=4.474273204803467
train: epoch 31, loss 1.4484155178070068, acc=0.47955554723739624, loss=1.4484155178070068
test: epoch 31, loss 4.259300708770752, acc=0.15833333134651184, loss=4.259300708770752
train: epoch 32, loss 1.430436372756958, acc=0.4860000014305115, loss=1.430436372756958
test: epoch 32, loss 4.104863166809082, acc=0.17777778208255768, loss=4.104863166809082
train: epoch 33, loss 1.4258171319961548, acc=0.49177777767181396, loss=1.4258171319961548
test: epoch 33, loss 4.035722732543945, acc=0.16944444179534912, loss=4.035722732543945
train: epoch 34, loss 1.3972551822662354, acc=0.49994444847106934, loss=1.3972551822662354
test: epoch 34, loss 4.058943748474121, acc=0.1805555522441864, loss=4.058943748474121
train: epoch 35, loss 1.3701809644699097, acc=0.5135555267333984, loss=1.3701809644699097
test: epoch 35, loss 4.023564338684082, acc=0.18611110746860504, loss=4.023564338684082
train: epoch 36, loss 1.3689649105072021, acc=0.518833339214325, loss=1.3689649105072021
test: epoch 36, loss 4.058166027069092, acc=0.18333333730697632, loss=4.058166027069092
train: epoch 37, loss 1.3536791801452637, acc=0.5209444165229797, loss=1.3536791801452637
test: epoch 37, loss 4.0248613357543945, acc=0.18611110746860504, loss=4.0248613357543945
train: epoch 38, loss 1.3329781293869019, acc=0.5356666445732117, loss=1.3329781293869019
test: epoch 38, loss 3.9076085090637207, acc=0.20000000298023224, loss=3.9076085090637207
train: epoch 39, loss 1.3180843591690063, acc=0.5393333435058594, loss=1.3180843591690063
test: epoch 39, loss 3.8494350910186768, acc=0.20000000298023224, loss=3.8494350910186768
train: epoch 40, loss 1.2874635457992554, acc=0.5522778034210205, loss=1.2874635457992554
test: epoch 40, loss 3.7559144496917725, acc=0.20000000298023224, loss=3.7559144496917725
train: epoch 41, loss 1.2844659090042114, acc=0.5501111149787903, loss=1.2844659090042114
test: epoch 41, loss 3.6772990226745605, acc=0.1944444477558136, loss=3.6772990226745605
train: epoch 42, loss 1.2577242851257324, acc=0.566611111164093, loss=1.2577242851257324
test: epoch 42, loss 3.6104185581207275, acc=0.20277777314186096, loss=3.6104185581207275
train: epoch 43, loss 1.2506524324417114, acc=0.5770555734634399, loss=1.2506524324417114
test: epoch 43, loss 3.5988776683807373, acc=0.21388888359069824, loss=3.5988776683807373
train: epoch 44, loss 1.2341943979263306, acc=0.5813888907432556, loss=1.2341943979263306
test: epoch 44, loss 3.4370639324188232, acc=0.2361111044883728, loss=3.4370639324188232
train: epoch 45, loss 1.216019630432129, acc=0.5883888602256775, loss=1.216019630432129
test: epoch 45, loss 3.3638134002685547, acc=0.2361111044883728, loss=3.3638134002685547
train: epoch 46, loss 1.1855272054672241, acc=0.5972777605056763, loss=1.1855272054672241
test: epoch 46, loss 3.3337044715881348, acc=0.22499999403953552, loss=3.3337044715881348
train: epoch 47, loss 1.1764283180236816, acc=0.6094444394111633, loss=1.1764283180236816
test: epoch 47, loss 3.277703285217285, acc=0.24444444477558136, loss=3.277703285217285
train: epoch 48, loss 1.147197961807251, acc=0.6216111183166504, loss=1.147197961807251
test: epoch 48, loss 3.230029344558716, acc=0.23055554926395416, loss=3.230029344558716
train: epoch 49, loss 1.137047529220581, acc=0.6259444355964661, loss=1.137047529220581
test: epoch 49, loss 3.0907301902770996, acc=0.23888888955116272, loss=3.0907301902770996
train: epoch 50, loss 1.1273635625839233, acc=0.637499988079071, loss=1.1273635625839233
test: epoch 50, loss 3.061784505844116, acc=0.25555557012557983, loss=3.061784505844116
train: epoch 51, loss 1.1068049669265747, acc=0.6370555758476257, loss=1.1068049669265747
test: epoch 51, loss 3.0463995933532715, acc=0.24444444477558136, loss=3.0463995933532715
train: epoch 52, loss 1.098017930984497, acc=0.6470000147819519, loss=1.098017930984497
test: epoch 52, loss 3.007352828979492, acc=0.2638888955116272, loss=3.007352828979492
train: epoch 53, loss 1.0693089962005615, acc=0.6573333144187927, loss=1.0693089962005615
test: epoch 53, loss 2.9465763568878174, acc=0.2527777850627899, loss=2.9465763568878174
train: epoch 54, loss 1.0545982122421265, acc=0.6664444208145142, loss=1.0545982122421265
test: epoch 54, loss 2.912189245223999, acc=0.25555557012557983, loss=2.912189245223999
train: epoch 55, loss 1.0264856815338135, acc=0.6731666922569275, loss=1.0264856815338135
test: epoch 55, loss 2.894775390625, acc=0.2750000059604645, loss=2.894775390625
train: epoch 56, loss 1.009812593460083, acc=0.6812222003936768, loss=1.009812593460083
test: epoch 56, loss 2.7501168251037598, acc=0.26944443583488464, loss=2.7501168251037598
train: epoch 57, loss 0.9905356764793396, acc=0.6936110854148865, loss=0.9905356764793396
test: epoch 57, loss 2.7356350421905518, acc=0.2777777910232544, loss=2.7356350421905518
train: epoch 58, loss 0.9817678332328796, acc=0.7002221941947937, loss=0.9817678332328796
test: epoch 58, loss 2.638090133666992, acc=0.2777777910232544, loss=2.638090133666992
train: epoch 59, loss 0.9509331583976746, acc=0.710277795791626, loss=0.9509331583976746
test: epoch 59, loss 2.641589403152466, acc=0.2805555462837219, loss=2.641589403152466
train: epoch 60, loss 0.9262968897819519, acc=0.7188888788223267, loss=0.9262968897819519
test: epoch 60, loss 2.517775535583496, acc=0.28333333134651184, loss=2.517775535583496
train: epoch 61, loss 0.8968148231506348, acc=0.7328333258628845, loss=0.8968148231506348
test: epoch 61, loss 2.462817430496216, acc=0.28611111640930176, loss=2.462817430496216
train: epoch 62, loss 0.8941140174865723, acc=0.7350555658340454, loss=0.8941140174865723
test: epoch 62, loss 2.3809475898742676, acc=0.2888889014720917, loss=2.3809475898742676
train: epoch 63, loss 0.8760775327682495, acc=0.7450555562973022, loss=0.8760775327682495
test: epoch 63, loss 2.3987326622009277, acc=0.2916666567325592, loss=2.3987326622009277
train: epoch 64, loss 0.8779144287109375, acc=0.7483888864517212, loss=0.8779144287109375
test: epoch 64, loss 2.3093202114105225, acc=0.30000001192092896, loss=2.3093202114105225
train: epoch 65, loss 0.8191184997558594, acc=0.761222243309021, loss=0.8191184997558594
test: epoch 65, loss 2.302244186401367, acc=0.30000001192092896, loss=2.302244186401367
train: epoch 66, loss 0.8391119241714478, acc=0.7676666378974915, loss=0.8391119241714478
test: epoch 66, loss 2.2009804248809814, acc=0.31111112236976624, loss=2.2009804248809814
train: epoch 67, loss 0.8085901141166687, acc=0.7760000228881836, loss=0.8085901141166687
test: epoch 67, loss 2.221816301345825, acc=0.3083333373069763, loss=2.221816301345825
train: epoch 68, loss 0.796468198299408, acc=0.7828888893127441, loss=0.796468198299408
test: epoch 68, loss 2.1018049716949463, acc=0.31111112236976624, loss=2.1018049716949463
train: epoch 69, loss 0.7919159531593323, acc=0.7816666960716248, loss=0.7919159531593323
test: epoch 69, loss 2.149886131286621, acc=0.31111112236976624, loss=2.149886131286621
train: epoch 70, loss 0.7609023451805115, acc=0.7944444417953491, loss=0.7609023451805115
test: epoch 70, loss 2.1661376953125, acc=0.3083333373069763, loss=2.1661376953125
train: epoch 71, loss 0.7565217018127441, acc=0.8015000224113464, loss=0.7565217018127441
test: epoch 71, loss 2.08901309967041, acc=0.32499998807907104, loss=2.08901309967041
train: epoch 72, loss 0.7240925431251526, acc=0.8058888912200928, loss=0.7240925431251526
test: epoch 72, loss 2.0839483737945557, acc=0.3305555582046509, loss=2.0839483737945557
train: epoch 73, loss 0.725517213344574, acc=0.8112221956253052, loss=0.725517213344574
test: epoch 73, loss 2.0377063751220703, acc=0.33888888359069824, loss=2.0377063751220703
train: epoch 74, loss 0.7161963582038879, acc=0.8138333559036255, loss=0.7161963582038879
test: epoch 74, loss 2.054621458053589, acc=0.33888888359069824, loss=2.054621458053589
train: epoch 75, loss 0.6874169707298279, acc=0.8188889026641846, loss=0.6874169707298279
test: epoch 75, loss 1.9496935606002808, acc=0.3499999940395355, loss=1.9496935606002808
train: epoch 76, loss 0.6902373433113098, acc=0.8266666531562805, loss=0.6902373433113098
test: epoch 76, loss 1.9679979085922241, acc=0.3499999940395355, loss=1.9679979085922241
train: epoch 77, loss 0.6633127331733704, acc=0.8279444575309753, loss=0.6633127331733704
test: epoch 77, loss 1.937045693397522, acc=0.33888888359069824, loss=1.937045693397522
train: epoch 78, loss 0.6667235493659973, acc=0.835444450378418, loss=0.6667235493659973
test: epoch 78, loss 1.914008617401123, acc=0.35555556416511536, loss=1.914008617401123
train: epoch 79, loss 0.6447778940200806, acc=0.8396111130714417, loss=0.6447778940200806
test: epoch 79, loss 1.9896605014801025, acc=0.3444444537162781, loss=1.9896605014801025
train: epoch 80, loss 0.6333736777305603, acc=0.8417222499847412, loss=0.6333736777305603
test: epoch 80, loss 1.933672308921814, acc=0.35277777910232544, loss=1.933672308921814
train: epoch 81, loss 0.6446729302406311, acc=0.8461666703224182, loss=0.6446729302406311
test: epoch 81, loss 1.902923345565796, acc=0.35277777910232544, loss=1.902923345565796
train: epoch 82, loss 0.6081074476242065, acc=0.8478333353996277, loss=0.6081074476242065
test: epoch 82, loss 1.9092419147491455, acc=0.3472222089767456, loss=1.9092419147491455
train: epoch 83, loss 0.6001138091087341, acc=0.8514999747276306, loss=0.6001138091087341
test: epoch 83, loss 1.858897089958191, acc=0.3472222089767456, loss=1.858897089958191
train: epoch 84, loss 0.6018039584159851, acc=0.8516111373901367, loss=0.6018039584159851
test: epoch 84, loss 1.8645777702331543, acc=0.36944442987442017, loss=1.8645777702331543
train: epoch 85, loss 0.6035501956939697, acc=0.8573333621025085, loss=0.6035501956939697
test: epoch 85, loss 1.817872166633606, acc=0.36666667461395264, loss=1.817872166633606
train: epoch 86, loss 0.5661649107933044, acc=0.8616666793823242, loss=0.5661649107933044
test: epoch 86, loss 1.7781972885131836, acc=0.36666667461395264, loss=1.7781972885131836
train: epoch 87, loss 0.5389528274536133, acc=0.8671666383743286, loss=0.5389528274536133
test: epoch 87, loss 1.7904947996139526, acc=0.38055557012557983, loss=1.7904947996139526
train: epoch 88, loss 0.5602648854255676, acc=0.8695555329322815, loss=0.5602648854255676
test: epoch 88, loss 1.76311194896698, acc=0.38055557012557983, loss=1.76311194896698
train: epoch 89, loss 0.5529465675354004, acc=0.8684999942779541, loss=0.5529465675354004
test: epoch 89, loss 1.7580626010894775, acc=0.3722222149372101, loss=1.7580626010894775
train: epoch 90, loss 0.5375696420669556, acc=0.8690000176429749, loss=0.5375696420669556
test: epoch 90, loss 1.7672255039215088, acc=0.36666667461395264, loss=1.7672255039215088
train: epoch 91, loss 0.5379136800765991, acc=0.8730000257492065, loss=0.5379136800765991
test: epoch 91, loss 1.7417365312576294, acc=0.3638888895511627, loss=1.7417365312576294
train: epoch 92, loss 0.5097078084945679, acc=0.8762221932411194, loss=0.5097078084945679
test: epoch 92, loss 1.7397788763046265, acc=0.375, loss=1.7397788763046265
train: epoch 93, loss 0.5091899037361145, acc=0.8765555620193481, loss=0.5091899037361145
test: epoch 93, loss 1.735196590423584, acc=0.3777777850627899, loss=1.735196590423584
train: epoch 94, loss 0.509985625743866, acc=0.8788889050483704, loss=0.509985625743866
test: epoch 94, loss 1.7129768133163452, acc=0.3861111104488373, loss=1.7129768133163452
train: epoch 95, loss 0.5056723952293396, acc=0.8811666369438171, loss=0.5056723952293396
test: epoch 95, loss 1.7340078353881836, acc=0.375, loss=1.7340078353881836
train: epoch 96, loss 0.5015758872032166, acc=0.8836666941642761, loss=0.5015758872032166
test: epoch 96, loss 1.697940468788147, acc=0.3888888955116272, loss=1.697940468788147
train: epoch 97, loss 0.482503205537796, acc=0.8882222175598145, loss=0.482503205537796
test: epoch 97, loss 1.651816725730896, acc=0.3888888955116272, loss=1.651816725730896
train: epoch 98, loss 0.48194488883018494, acc=0.8866666555404663, loss=0.48194488883018494
test: epoch 98, loss 1.6401551961898804, acc=0.39722222089767456, loss=1.6401551961898804
train: epoch 99, loss 0.4772615432739258, acc=0.8892222046852112, loss=0.4772615432739258
test: epoch 99, loss 1.6305115222930908, acc=0.3888888955116272, loss=1.6305115222930908
train: epoch 100, loss 0.4864313304424286, acc=0.8887222409248352, loss=0.4864313304424286
test: epoch 100, loss 1.6245657205581665, acc=0.3916666805744171, loss=1.6245657205581665
train: epoch 101, loss 0.4651866555213928, acc=0.8920555710792542, loss=0.4651866555213928
test: epoch 101, loss 1.5992403030395508, acc=0.39444443583488464, loss=1.5992403030395508
train: epoch 102, loss 0.4946961998939514, acc=0.8880555629730225, loss=0.4946961998939514
test: epoch 102, loss 1.6082619428634644, acc=0.39722222089767456, loss=1.6082619428634644
train: epoch 103, loss 0.4621359407901764, acc=0.8920000195503235, loss=0.4621359407901764
test: epoch 103, loss 1.6091837882995605, acc=0.39722222089767456, loss=1.6091837882995605
train: epoch 104, loss 0.4756573438644409, acc=0.893833339214325, loss=0.4756573438644409
test: epoch 104, loss 1.5715503692626953, acc=0.40833333134651184, loss=1.5715503692626953
train: epoch 105, loss 0.46020129323005676, acc=0.8983333110809326, loss=0.46020129323005676
test: epoch 105, loss 1.5808727741241455, acc=0.41111111640930176, loss=1.5808727741241455
train: epoch 106, loss 0.4643423557281494, acc=0.893833339214325, loss=0.4643423557281494
test: epoch 106, loss 1.5776338577270508, acc=0.40833333134651184, loss=1.5776338577270508
train: epoch 107, loss 0.44004586338996887, acc=0.8995000123977661, loss=0.44004586338996887
test: epoch 107, loss 1.5732598304748535, acc=0.40833333134651184, loss=1.5732598304748535
train: epoch 108, loss 0.4542132616043091, acc=0.8996666669845581, loss=0.4542132616043091
test: epoch 108, loss 1.545662760734558, acc=0.4055555462837219, loss=1.545662760734558
train: epoch 109, loss 0.43073204159736633, acc=0.8991666436195374, loss=0.43073204159736633
test: epoch 109, loss 1.5223455429077148, acc=0.41111111640930176, loss=1.5223455429077148
train: epoch 110, loss 0.44260919094085693, acc=0.8993889093399048, loss=0.44260919094085693
test: epoch 110, loss 1.5164915323257446, acc=0.4166666567325592, loss=1.5164915323257446
train: epoch 111, loss 0.4438289403915405, acc=0.8955555558204651, loss=0.4438289403915405
test: epoch 111, loss 1.5148417949676514, acc=0.4138889014720917, loss=1.5148417949676514
train: epoch 112, loss 0.4209499657154083, acc=0.9004999995231628, loss=0.4209499657154083
test: epoch 112, loss 1.4790139198303223, acc=0.4333333373069763, loss=1.4790139198303223
train: epoch 113, loss 0.4539046585559845, acc=0.9006666541099548, loss=0.4539046585559845
test: epoch 113, loss 1.454529881477356, acc=0.43611112236976624, loss=1.454529881477356
train: epoch 114, loss 0.4361317753791809, acc=0.9051111340522766, loss=0.4361317753791809
test: epoch 114, loss 1.4517697095870972, acc=0.4444444477558136, loss=1.4517697095870972
train: epoch 115, loss 0.4407411515712738, acc=0.902222216129303, loss=0.4407411515712738
test: epoch 115, loss 1.4401428699493408, acc=0.42500001192092896, loss=1.4401428699493408
train: epoch 116, loss 0.4297389090061188, acc=0.9073888659477234, loss=0.4297389090061188
test: epoch 116, loss 1.4329464435577393, acc=0.42222222685813904, loss=1.4329464435577393
train: epoch 117, loss 0.4079979956150055, acc=0.9092777967453003, loss=0.4079979956150055
test: epoch 117, loss 1.406254768371582, acc=0.4416666626930237, loss=1.406254768371582
train: epoch 118, loss 0.4216298758983612, acc=0.9052777886390686, loss=0.4216298758983612
test: epoch 118, loss 1.3928029537200928, acc=0.4416666626930237, loss=1.3928029537200928
train: epoch 119, loss 0.42318621277809143, acc=0.9037777781486511, loss=0.42318621277809143
test: epoch 119, loss 1.3735889196395874, acc=0.4583333432674408, loss=1.3735889196395874
train: epoch 120, loss 0.41887161135673523, acc=0.9037222266197205, loss=0.41887161135673523
test: epoch 120, loss 1.4087073802947998, acc=0.4583333432674408, loss=1.4087073802947998
train: epoch 121, loss 0.41987061500549316, acc=0.9057777523994446, loss=0.41987061500549316
test: epoch 121, loss 1.3856133222579956, acc=0.43888887763023376, loss=1.3856133222579956
train: epoch 122, loss 0.41862818598747253, acc=0.9096666574478149, loss=0.41862818598747253
test: epoch 122, loss 1.4110496044158936, acc=0.4333333373069763, loss=1.4110496044158936
train: epoch 123, loss 0.4180109202861786, acc=0.9085555672645569, loss=0.4180109202861786
test: epoch 123, loss 1.3612219095230103, acc=0.4583333432674408, loss=1.3612219095230103
train: epoch 124, loss 0.4145320653915405, acc=0.9076666831970215, loss=0.4145320653915405
test: epoch 124, loss 1.3657704591751099, acc=0.46388888359069824, loss=1.3657704591751099
train: epoch 125, loss 0.4314970374107361, acc=0.905055582523346, loss=0.4314970374107361
test: epoch 125, loss 1.336969256401062, acc=0.4444444477558136, loss=1.336969256401062
train: epoch 126, loss 0.4318913519382477, acc=0.9067777991294861, loss=0.4318913519382477
test: epoch 126, loss 1.3331609964370728, acc=0.46388888359069824, loss=1.3331609964370728
train: epoch 127, loss 0.4223387837409973, acc=0.9073333144187927, loss=0.4223387837409973
test: epoch 127, loss 1.3446195125579834, acc=0.4694444537162781, loss=1.3446195125579834
train: epoch 128, loss 0.4153633713722229, acc=0.9097222089767456, loss=0.4153633713722229
test: epoch 128, loss 1.3465219736099243, acc=0.4722222089767456, loss=1.3465219736099243
train: epoch 129, loss 0.39986452460289, acc=0.9088333249092102, loss=0.39986452460289
test: epoch 129, loss 1.3265511989593506, acc=0.4722222089767456, loss=1.3265511989593506
train: epoch 130, loss 0.4020560383796692, acc=0.9079444408416748, loss=0.4020560383796692
test: epoch 130, loss 1.3281162977218628, acc=0.4611110985279083, loss=1.3281162977218628
train: epoch 131, loss 0.40894263982772827, acc=0.9056110978126526, loss=0.40894263982772827
test: epoch 131, loss 1.3329161405563354, acc=0.4555555582046509, loss=1.3329161405563354
train: epoch 132, loss 0.4243282377719879, acc=0.9066110849380493, loss=0.4243282377719879
test: epoch 132, loss 1.3067752122879028, acc=0.46388888359069824, loss=1.3067752122879028
train: epoch 133, loss 0.4240019917488098, acc=0.9099444150924683, loss=0.4240019917488098
test: epoch 133, loss 1.3029029369354248, acc=0.4472222328186035, loss=1.3029029369354248
train: epoch 134, loss 0.414235383272171, acc=0.9078333377838135, loss=0.414235383272171
test: epoch 134, loss 1.3113006353378296, acc=0.4694444537162781, loss=1.3113006353378296
train: epoch 135, loss 0.3912687301635742, acc=0.9087777733802795, loss=0.3912687301635742
test: epoch 135, loss 1.2754913568496704, acc=0.4583333432674408, loss=1.2754913568496704
train: epoch 136, loss 0.41290929913520813, acc=0.9097222089767456, loss=0.41290929913520813
test: epoch 136, loss 1.2748677730560303, acc=0.4694444537162781, loss=1.2748677730560303
train: epoch 137, loss 0.402204692363739, acc=0.9082221984863281, loss=0.402204692363739
test: epoch 137, loss 1.2610321044921875, acc=0.47777777910232544, loss=1.2610321044921875
train: epoch 138, loss 0.3729502558708191, acc=0.9104999899864197, loss=0.3729502558708191
test: epoch 138, loss 1.285133957862854, acc=0.4749999940395355, loss=1.285133957862854
train: epoch 139, loss 0.4126831889152527, acc=0.9089444279670715, loss=0.4126831889152527
test: epoch 139, loss 1.273599624633789, acc=0.4833333194255829, loss=1.273599624633789
train: epoch 140, loss 0.4249648153781891, acc=0.9097222089767456, loss=0.4249648153781891
test: epoch 140, loss 1.2440115213394165, acc=0.4749999940395355, loss=1.2440115213394165
train: epoch 141, loss 0.4079242944717407, acc=0.9113333225250244, loss=0.4079242944717407
test: epoch 141, loss 1.2435215711593628, acc=0.4749999940395355, loss=1.2435215711593628
train: epoch 142, loss 0.41055992245674133, acc=0.9036666750907898, loss=0.41055992245674133
test: epoch 142, loss 1.2320377826690674, acc=0.48055556416511536, loss=1.2320377826690674
train: epoch 143, loss 0.37639787793159485, acc=0.9122777581214905, loss=0.37639787793159485
test: epoch 143, loss 1.2673550844192505, acc=0.4749999940395355, loss=1.2673550844192505
train: epoch 144, loss 0.38740482926368713, acc=0.9112777709960938, loss=0.38740482926368713
test: epoch 144, loss 1.2466322183609009, acc=0.4888888895511627, loss=1.2466322183609009
train: epoch 145, loss 0.41763225197792053, acc=0.910611093044281, loss=0.41763225197792053
test: epoch 145, loss 1.255210518836975, acc=0.4972222149372101, loss=1.255210518836975
train: epoch 146, loss 0.40225496888160706, acc=0.9077222347259521, loss=0.40225496888160706
test: epoch 146, loss 1.246310830116272, acc=0.4833333194255829, loss=1.246310830116272
train: epoch 147, loss 0.4172309339046478, acc=0.905055582523346, loss=0.4172309339046478
test: epoch 147, loss 1.2447538375854492, acc=0.4861111044883728, loss=1.2447538375854492
train: epoch 148, loss 0.40596264600753784, acc=0.9068333506584167, loss=0.40596264600753784
test: epoch 148, loss 1.211430549621582, acc=0.5, loss=1.211430549621582
train: epoch 149, loss 0.39815160632133484, acc=0.9097222089767456, loss=0.39815160632133484
test: epoch 149, loss 1.2043941020965576, acc=0.49444442987442017, loss=1.2043941020965576
train: epoch 150, loss 0.39378470182418823, acc=0.9078888893127441, loss=0.39378470182418823
test: epoch 150, loss 1.209917426109314, acc=0.5166666507720947, loss=1.209917426109314
