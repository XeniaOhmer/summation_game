# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=1", "--one_hot=false", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=181913360, receiver_embed_dim=32, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.017599105834961, acc=0.07277777791023254, loss=3.017599105834961
test: epoch 1, loss 4.356077671051025, acc=0.08055555820465088, loss=4.356077671051025
train: epoch 2, loss 2.108186960220337, acc=0.18183332681655884, loss=2.108186960220337
test: epoch 2, loss 3.4620141983032227, acc=0.1388888955116272, loss=3.4620141983032227
train: epoch 3, loss 1.7474876642227173, acc=0.2609444558620453, loss=1.7474876642227173
test: epoch 3, loss 3.062946319580078, acc=0.19166666269302368, loss=3.062946319580078
train: epoch 4, loss 1.5734153985977173, acc=0.31194445490837097, loss=1.5734153985977173
test: epoch 4, loss 2.991499900817871, acc=0.1805555522441864, loss=2.991499900817871
train: epoch 5, loss 1.3629772663116455, acc=0.39238888025283813, loss=1.3629772663116455
test: epoch 5, loss 3.12007999420166, acc=0.21388888359069824, loss=3.12007999420166
train: epoch 6, loss 1.297337293624878, acc=0.42322221398353577, loss=1.297337293624878
test: epoch 6, loss 3.203331232070923, acc=0.20555555820465088, loss=3.203331232070923
train: epoch 7, loss 1.2056416273117065, acc=0.4577222168445587, loss=1.2056416273117065
test: epoch 7, loss 2.6934409141540527, acc=0.2222222238779068, loss=2.6934409141540527
train: epoch 8, loss 1.1069003343582153, acc=0.503944456577301, loss=1.1069003343582153
test: epoch 8, loss 2.822906970977783, acc=0.20555555820465088, loss=2.822906970977783
train: epoch 9, loss 1.0523444414138794, acc=0.5266110897064209, loss=1.0523444414138794
test: epoch 9, loss 2.9458870887756348, acc=0.20000000298023224, loss=2.9458870887756348
train: epoch 10, loss 0.9796658754348755, acc=0.5590555667877197, loss=0.9796658754348755
test: epoch 10, loss 3.480311870574951, acc=0.2638888955116272, loss=3.480311870574951
train: epoch 11, loss 0.9686010479927063, acc=0.5633888840675354, loss=0.9686010479927063
test: epoch 11, loss 2.87296724319458, acc=0.24722221493721008, loss=2.87296724319458
train: epoch 12, loss 0.8909522294998169, acc=0.6067777872085571, loss=0.8909522294998169
test: epoch 12, loss 3.272451639175415, acc=0.2361111044883728, loss=3.272451639175415
train: epoch 13, loss 0.9109888672828674, acc=0.5861666798591614, loss=0.9109888672828674
test: epoch 13, loss 2.836651563644409, acc=0.2527777850627899, loss=2.836651563644409
train: epoch 14, loss 0.8131758570671082, acc=0.6407222151756287, loss=0.8131758570671082
test: epoch 14, loss 2.7305428981781006, acc=0.21388888359069824, loss=2.7305428981781006
train: epoch 15, loss 0.7890835404396057, acc=0.6474999785423279, loss=0.7890835404396057
test: epoch 15, loss 3.0519423484802246, acc=0.2222222238779068, loss=3.0519423484802246
train: epoch 16, loss 0.71091228723526, acc=0.6886666417121887, loss=0.71091228723526
test: epoch 16, loss 3.3544793128967285, acc=0.23888888955116272, loss=3.3544793128967285
train: epoch 17, loss 0.7262619733810425, acc=0.6823889017105103, loss=0.7262619733810425
test: epoch 17, loss 3.5040416717529297, acc=0.25833332538604736, loss=3.5040416717529297
train: epoch 18, loss 0.6973448991775513, acc=0.6970555782318115, loss=0.6973448991775513
test: epoch 18, loss 3.9607486724853516, acc=0.22777777910232544, loss=3.9607486724853516
train: epoch 19, loss 0.6307782530784607, acc=0.726111114025116, loss=0.6307782530784607
test: epoch 19, loss 2.403949737548828, acc=0.3611111044883728, loss=2.403949737548828
train: epoch 20, loss 0.5737177133560181, acc=0.7518888711929321, loss=0.5737177133560181
test: epoch 20, loss 3.7936856746673584, acc=0.30000001192092896, loss=3.7936856746673584
train: epoch 21, loss 0.5595139265060425, acc=0.765500009059906, loss=0.5595139265060425
test: epoch 21, loss 3.384507417678833, acc=0.3361110985279083, loss=3.384507417678833
train: epoch 22, loss 0.4831693768501282, acc=0.7996666431427002, loss=0.4831693768501282
test: epoch 22, loss 2.787888765335083, acc=0.3194444477558136, loss=2.787888765335083
train: epoch 23, loss 0.4020782709121704, acc=0.8282222151756287, loss=0.4020782709121704
test: epoch 23, loss 2.1142148971557617, acc=0.4166666567325592, loss=2.1142148971557617
train: epoch 24, loss 0.38257724046707153, acc=0.8351666927337646, loss=0.38257724046707153
test: epoch 24, loss 2.459355115890503, acc=0.4333333373069763, loss=2.459355115890503
train: epoch 25, loss 0.37353479862213135, acc=0.8414999842643738, loss=0.37353479862213135
test: epoch 25, loss 2.6545560359954834, acc=0.4000000059604645, loss=2.6545560359954834
train: epoch 26, loss 0.33646780252456665, acc=0.855388879776001, loss=0.33646780252456665
test: epoch 26, loss 2.1064248085021973, acc=0.4611110985279083, loss=2.1064248085021973
train: epoch 27, loss 0.3254043459892273, acc=0.8585000038146973, loss=0.3254043459892273
test: epoch 27, loss 2.526654005050659, acc=0.40833333134651184, loss=2.526654005050659
train: epoch 28, loss 0.32098808884620667, acc=0.8622778058052063, loss=0.32098808884620667
test: epoch 28, loss 2.2110705375671387, acc=0.4972222149372101, loss=2.2110705375671387
train: epoch 29, loss 0.2896606922149658, acc=0.8797777891159058, loss=0.2896606922149658
test: epoch 29, loss 2.2247042655944824, acc=0.44999998807907104, loss=2.2247042655944824
train: epoch 30, loss 0.2846097946166992, acc=0.8891111016273499, loss=0.2846097946166992
test: epoch 30, loss 2.135828971862793, acc=0.48055556416511536, loss=2.135828971862793
train: epoch 31, loss 0.24768181145191193, acc=0.9095555543899536, loss=0.24768181145191193
test: epoch 31, loss 2.1239848136901855, acc=0.49166667461395264, loss=2.1239848136901855
train: epoch 32, loss 0.23340359330177307, acc=0.9144444465637207, loss=0.23340359330177307
test: epoch 32, loss 2.6231610774993896, acc=0.4583333432674408, loss=2.6231610774993896
train: epoch 33, loss 0.2137465626001358, acc=0.9217777848243713, loss=0.2137465626001358
test: epoch 33, loss 2.156374216079712, acc=0.5111111402511597, loss=2.156374216079712
train: epoch 34, loss 0.20433677732944489, acc=0.9277222156524658, loss=0.20433677732944489
test: epoch 34, loss 1.9040321111679077, acc=0.4722222089767456, loss=1.9040321111679077
train: epoch 35, loss 0.2049603909254074, acc=0.9231111407279968, loss=0.2049603909254074
test: epoch 35, loss 1.849837064743042, acc=0.519444465637207, loss=1.849837064743042
train: epoch 36, loss 0.17902056872844696, acc=0.9332777857780457, loss=0.17902056872844696
test: epoch 36, loss 2.473809242248535, acc=0.4583333432674408, loss=2.473809242248535
train: epoch 37, loss 0.2124929428100586, acc=0.9242222309112549, loss=0.2124929428100586
test: epoch 37, loss 2.5403618812561035, acc=0.4749999940395355, loss=2.5403618812561035
train: epoch 38, loss 0.1937166452407837, acc=0.9301666617393494, loss=0.1937166452407837
test: epoch 38, loss 1.7705403566360474, acc=0.519444465637207, loss=1.7705403566360474
train: epoch 39, loss 0.19336450099945068, acc=0.929111123085022, loss=0.19336450099945068
test: epoch 39, loss 1.9833722114562988, acc=0.5305555462837219, loss=1.9833722114562988
train: epoch 40, loss 0.17579664289951324, acc=0.9360555410385132, loss=0.17579664289951324
test: epoch 40, loss 1.670478343963623, acc=0.5305555462837219, loss=1.670478343963623
train: epoch 41, loss 0.15864264965057373, acc=0.9435555338859558, loss=0.15864264965057373
test: epoch 41, loss 1.312034249305725, acc=0.5833333134651184, loss=1.312034249305725
train: epoch 42, loss 0.18051952123641968, acc=0.9352222084999084, loss=0.18051952123641968
test: epoch 42, loss 2.05702543258667, acc=0.5638889074325562, loss=2.05702543258667
train: epoch 43, loss 0.15535441040992737, acc=0.9421666860580444, loss=0.15535441040992737
test: epoch 43, loss 1.5522615909576416, acc=0.5388888716697693, loss=1.5522615909576416
train: epoch 44, loss 0.16157221794128418, acc=0.9404444694519043, loss=0.16157221794128418
test: epoch 44, loss 1.5736664533615112, acc=0.5666666626930237, loss=1.5736664533615112
train: epoch 45, loss 0.15747299790382385, acc=0.9430000185966492, loss=0.15747299790382385
test: epoch 45, loss 1.8754619359970093, acc=0.4972222149372101, loss=1.8754619359970093
train: epoch 46, loss 0.14304876327514648, acc=0.9481111168861389, loss=0.14304876327514648
test: epoch 46, loss 1.4780051708221436, acc=0.5249999761581421, loss=1.4780051708221436
train: epoch 47, loss 0.1579754501581192, acc=0.9423333406448364, loss=0.1579754501581192
test: epoch 47, loss 1.9159801006317139, acc=0.519444465637207, loss=1.9159801006317139
train: epoch 48, loss 0.141023188829422, acc=0.9498888850212097, loss=0.141023188829422
test: epoch 48, loss 2.1062514781951904, acc=0.46666666865348816, loss=2.1062514781951904
train: epoch 49, loss 0.13876983523368835, acc=0.9520555734634399, loss=0.13876983523368835
test: epoch 49, loss 1.3615918159484863, acc=0.5638889074325562, loss=1.3615918159484863
train: epoch 50, loss 0.1269400417804718, acc=0.9567221999168396, loss=0.1269400417804718
test: epoch 50, loss 1.7112749814987183, acc=0.5166666507720947, loss=1.7112749814987183
train: epoch 51, loss 0.12899066507816315, acc=0.9561111330986023, loss=0.12899066507816315
test: epoch 51, loss 1.612790584564209, acc=0.5388888716697693, loss=1.612790584564209
train: epoch 52, loss 0.12085659056901932, acc=0.9605555534362793, loss=0.12085659056901932
test: epoch 52, loss 1.777809739112854, acc=0.5416666865348816, loss=1.777809739112854
train: epoch 53, loss 0.0948687270283699, acc=0.9674999713897705, loss=0.0948687270283699
test: epoch 53, loss 1.401048183441162, acc=0.5833333134651184, loss=1.401048183441162
train: epoch 54, loss 0.17044095695018768, acc=0.9486666917800903, loss=0.17044095695018768
test: epoch 54, loss 1.2964720726013184, acc=0.5833333134651184, loss=1.2964720726013184
train: epoch 55, loss 0.07722703367471695, acc=0.9738888740539551, loss=0.07722703367471695
test: epoch 55, loss 1.564844012260437, acc=0.5611110925674438, loss=1.564844012260437
train: epoch 56, loss 0.10530482232570648, acc=0.964888870716095, loss=0.10530482232570648
test: epoch 56, loss 1.756596565246582, acc=0.5861111283302307, loss=1.756596565246582
train: epoch 57, loss 0.07862543314695358, acc=0.9736111164093018, loss=0.07862543314695358
test: epoch 57, loss 1.5731042623519897, acc=0.5611110925674438, loss=1.5731042623519897
train: epoch 58, loss 0.1247251033782959, acc=0.9597777724266052, loss=0.1247251033782959
test: epoch 58, loss 1.3291620016098022, acc=0.625, loss=1.3291620016098022
train: epoch 59, loss 0.09520843625068665, acc=0.968666672706604, loss=0.09520843625068665
test: epoch 59, loss 1.8292423486709595, acc=0.5472221970558167, loss=1.8292423486709595
train: epoch 60, loss 0.10983436554670334, acc=0.9633333086967468, loss=0.10983436554670334
test: epoch 60, loss 1.2962857484817505, acc=0.6083333492279053, loss=1.2962857484817505
train: epoch 61, loss 0.07162091881036758, acc=0.9758333563804626, loss=0.07162091881036758
test: epoch 61, loss 1.3874939680099487, acc=0.6000000238418579, loss=1.3874939680099487
train: epoch 62, loss 0.09318368136882782, acc=0.9703888893127441, loss=0.09318368136882782
test: epoch 62, loss 1.5961053371429443, acc=0.5527777671813965, loss=1.5961053371429443
train: epoch 63, loss 0.08437016606330872, acc=0.9723888635635376, loss=0.08437016606330872
test: epoch 63, loss 0.9927987456321716, acc=0.6499999761581421, loss=0.9927987456321716
train: epoch 64, loss 0.08195889741182327, acc=0.972777783870697, loss=0.08195889741182327
test: epoch 64, loss 1.8698171377182007, acc=0.6305555701255798, loss=1.8698171377182007
train: epoch 65, loss 0.09019193798303604, acc=0.9720555543899536, loss=0.09019193798303604
test: epoch 65, loss 1.248416543006897, acc=0.5972222089767456, loss=1.248416543006897
train: epoch 66, loss 0.0761791542172432, acc=0.9752777814865112, loss=0.0761791542172432
test: epoch 66, loss 1.8782235383987427, acc=0.6583333611488342, loss=1.8782235383987427
train: epoch 67, loss 0.08852468430995941, acc=0.9703333377838135, loss=0.08852468430995941
test: epoch 67, loss 1.2444766759872437, acc=0.6666666865348816, loss=1.2444766759872437
train: epoch 68, loss 0.08936517685651779, acc=0.972611129283905, loss=0.08936517685651779
test: epoch 68, loss 1.4944727420806885, acc=0.6138888597488403, loss=1.4944727420806885
train: epoch 69, loss 0.08420789241790771, acc=0.9733333587646484, loss=0.08420789241790771
test: epoch 69, loss 1.3170335292816162, acc=0.6638888716697693, loss=1.3170335292816162
train: epoch 70, loss 0.08249872177839279, acc=0.9724444150924683, loss=0.08249872177839279
test: epoch 70, loss 1.477463960647583, acc=0.5833333134651184, loss=1.477463960647583
train: epoch 71, loss 0.0756952092051506, acc=0.976111114025116, loss=0.0756952092051506
test: epoch 71, loss 2.282792568206787, acc=0.6611111164093018, loss=2.282792568206787
train: epoch 72, loss 0.08789437264204025, acc=0.9717777967453003, loss=0.08789437264204025
test: epoch 72, loss 1.6580698490142822, acc=0.6472222208976746, loss=1.6580698490142822
train: epoch 73, loss 0.06739926338195801, acc=0.9776111245155334, loss=0.06739926338195801
test: epoch 73, loss 1.7563809156417847, acc=0.6083333492279053, loss=1.7563809156417847
train: epoch 74, loss 0.07795843482017517, acc=0.9754444360733032, loss=0.07795843482017517
test: epoch 74, loss 1.143013834953308, acc=0.6527777910232544, loss=1.143013834953308
train: epoch 75, loss 0.06570712476968765, acc=0.9778888821601868, loss=0.06570712476968765
test: epoch 75, loss 1.732001781463623, acc=0.5472221970558167, loss=1.732001781463623
train: epoch 76, loss 0.07784277200698853, acc=0.9751111268997192, loss=0.07784277200698853
test: epoch 76, loss 1.9336000680923462, acc=0.5527777671813965, loss=1.9336000680923462
train: epoch 77, loss 0.08099699765443802, acc=0.9741666913032532, loss=0.08099699765443802
test: epoch 77, loss 1.877557396888733, acc=0.5861111283302307, loss=1.877557396888733
train: epoch 78, loss 0.08916787058115005, acc=0.972611129283905, loss=0.08916787058115005
test: epoch 78, loss 1.9351544380187988, acc=0.5777778029441833, loss=1.9351544380187988
train: epoch 79, loss 0.051714297384023666, acc=0.9838888645172119, loss=0.051714297384023666
test: epoch 79, loss 0.8973121047019958, acc=0.7250000238418579, loss=0.8973121047019958
train: epoch 80, loss 0.06798318773508072, acc=0.9793333411216736, loss=0.06798318773508072
test: epoch 80, loss 1.3307300806045532, acc=0.6305555701255798, loss=1.3307300806045532
train: epoch 81, loss 0.06145462393760681, acc=0.9810555577278137, loss=0.06145462393760681
test: epoch 81, loss 1.5706112384796143, acc=0.5777778029441833, loss=1.5706112384796143
train: epoch 82, loss 0.061239246279001236, acc=0.9798333048820496, loss=0.061239246279001236
test: epoch 82, loss 1.7866567373275757, acc=0.5444444417953491, loss=1.7866567373275757
train: epoch 83, loss 0.07192665338516235, acc=0.9764444231987, loss=0.07192665338516235
test: epoch 83, loss 1.7347139120101929, acc=0.5694444179534912, loss=1.7347139120101929
train: epoch 84, loss 0.06338672339916229, acc=0.9797777533531189, loss=0.06338672339916229
test: epoch 84, loss 1.6007901430130005, acc=0.6083333492279053, loss=1.6007901430130005
train: epoch 85, loss 0.07758515328168869, acc=0.9776111245155334, loss=0.07758515328168869
test: epoch 85, loss 2.027207374572754, acc=0.5833333134651184, loss=2.027207374572754
train: epoch 86, loss 0.0632704421877861, acc=0.9811111092567444, loss=0.0632704421877861
test: epoch 86, loss 1.2229820489883423, acc=0.5777778029441833, loss=1.2229820489883423
train: epoch 87, loss 0.06614469736814499, acc=0.9789999723434448, loss=0.06614469736814499
test: epoch 87, loss 1.4025062322616577, acc=0.5777778029441833, loss=1.4025062322616577
train: epoch 88, loss 0.05962125211954117, acc=0.9816666841506958, loss=0.05962125211954117
test: epoch 88, loss 1.0176987648010254, acc=0.6833333373069763, loss=1.0176987648010254
train: epoch 89, loss 0.05170300230383873, acc=0.9826111197471619, loss=0.05170300230383873
test: epoch 89, loss 1.403159260749817, acc=0.6083333492279053, loss=1.403159260749817
train: epoch 90, loss 0.053286101669073105, acc=0.9830555319786072, loss=0.053286101669073105
test: epoch 90, loss 1.222205638885498, acc=0.7277777791023254, loss=1.222205638885498
train: epoch 91, loss 0.051683712750673294, acc=0.9835555553436279, loss=0.051683712750673294
test: epoch 91, loss 1.7357960939407349, acc=0.5277777910232544, loss=1.7357960939407349
train: epoch 92, loss 0.06385432183742523, acc=0.9792777895927429, loss=0.06385432183742523
test: epoch 92, loss 1.2623540163040161, acc=0.6527777910232544, loss=1.2623540163040161
train: epoch 93, loss 0.07092539221048355, acc=0.9774444699287415, loss=0.07092539221048355
test: epoch 93, loss 1.1455790996551514, acc=0.6805555820465088, loss=1.1455790996551514
train: epoch 94, loss 0.050919074565172195, acc=0.9833333492279053, loss=0.050919074565172195
test: epoch 94, loss 1.1383490562438965, acc=0.7166666388511658, loss=1.1383490562438965
train: epoch 95, loss 0.08185508102178574, acc=0.9749444723129272, loss=0.08185508102178574
test: epoch 95, loss 1.2400717735290527, acc=0.6944444179534912, loss=1.2400717735290527
train: epoch 96, loss 0.04213307797908783, acc=0.9857222437858582, loss=0.04213307797908783
test: epoch 96, loss 1.5526307821273804, acc=0.644444465637207, loss=1.5526307821273804
train: epoch 97, loss 0.05478719621896744, acc=0.9836666584014893, loss=0.05478719621896744
test: epoch 97, loss 1.348917841911316, acc=0.6166666746139526, loss=1.348917841911316
train: epoch 98, loss 0.050009701400995255, acc=0.984000027179718, loss=0.050009701400995255
test: epoch 98, loss 0.7368569374084473, acc=0.769444465637207, loss=0.7368569374084473
train: epoch 99, loss 0.05975790321826935, acc=0.981166660785675, loss=0.05975790321826935
test: epoch 99, loss 1.1676390171051025, acc=0.6722221970558167, loss=1.1676390171051025
train: epoch 100, loss 0.05745787173509598, acc=0.9806666374206543, loss=0.05745787173509598
test: epoch 100, loss 1.0831305980682373, acc=0.7055555582046509, loss=1.0831305980682373
train: epoch 101, loss 0.040088724344968796, acc=0.9873889088630676, loss=0.040088724344968796
test: epoch 101, loss 2.3980588912963867, acc=0.5944444537162781, loss=2.3980588912963867
train: epoch 102, loss 0.05757696181535721, acc=0.9826111197471619, loss=0.05757696181535721
test: epoch 102, loss 0.9529675245285034, acc=0.7111111283302307, loss=0.9529675245285034
train: epoch 103, loss 0.05177239328622818, acc=0.9838333129882812, loss=0.05177239328622818
test: epoch 103, loss 1.3391157388687134, acc=0.6527777910232544, loss=1.3391157388687134
train: epoch 104, loss 0.03817141056060791, acc=0.9891666769981384, loss=0.03817141056060791
test: epoch 104, loss 1.3803839683532715, acc=0.6888889074325562, loss=1.3803839683532715
train: epoch 105, loss 0.05985257402062416, acc=0.9810000061988831, loss=0.05985257402062416
test: epoch 105, loss 1.666683316230774, acc=0.5888888835906982, loss=1.666683316230774
train: epoch 106, loss 0.04369440674781799, acc=0.9869444370269775, loss=0.04369440674781799
test: epoch 106, loss 2.689966917037964, acc=0.5249999761581421, loss=2.689966917037964
train: epoch 107, loss 0.05851205810904503, acc=0.9819999933242798, loss=0.05851205810904503
test: epoch 107, loss 0.6983498930931091, acc=0.7111111283302307, loss=0.6983498930931091
train: epoch 108, loss 0.045670751482248306, acc=0.9863888621330261, loss=0.045670751482248306
test: epoch 108, loss 1.167790174484253, acc=0.7250000238418579, loss=1.167790174484253
train: epoch 109, loss 0.05349403992295265, acc=0.9837222099304199, loss=0.05349403992295265
test: epoch 109, loss 1.2891745567321777, acc=0.6000000238418579, loss=1.2891745567321777
train: epoch 110, loss 0.050676919519901276, acc=0.9853333234786987, loss=0.050676919519901276
test: epoch 110, loss 1.3080302476882935, acc=0.6416666507720947, loss=1.3080302476882935
train: epoch 111, loss 0.06304971128702164, acc=0.9826111197471619, loss=0.06304971128702164
test: epoch 111, loss 1.2796506881713867, acc=0.7166666388511658, loss=1.2796506881713867
train: epoch 112, loss 0.033184975385665894, acc=0.9897778034210205, loss=0.033184975385665894
test: epoch 112, loss 1.100216269493103, acc=0.7555555701255798, loss=1.100216269493103
train: epoch 113, loss 0.042927589267492294, acc=0.9864444732666016, loss=0.042927589267492294
test: epoch 113, loss 1.079787254333496, acc=0.7611111402511597, loss=1.079787254333496
train: epoch 114, loss 0.04891447350382805, acc=0.9852777719497681, loss=0.04891447350382805
test: epoch 114, loss 1.0520987510681152, acc=0.7194444537162781, loss=1.0520987510681152
train: epoch 115, loss 0.03124433010816574, acc=0.9902777671813965, loss=0.03124433010816574
test: epoch 115, loss 0.8568004965782166, acc=0.7555555701255798, loss=0.8568004965782166
train: epoch 116, loss 0.060359109193086624, acc=0.9819999933242798, loss=0.060359109193086624
test: epoch 116, loss 1.0077394247055054, acc=0.8222222328186035, loss=1.0077394247055054
train: epoch 117, loss 0.0523393489420414, acc=0.9834444522857666, loss=0.0523393489420414
test: epoch 117, loss 0.5323025584220886, acc=0.8361111283302307, loss=0.5323025584220886
train: epoch 118, loss 0.04550373926758766, acc=0.9850555658340454, loss=0.04550373926758766
test: epoch 118, loss 1.0036625862121582, acc=0.769444465637207, loss=1.0036625862121582
train: epoch 119, loss 0.039866041392087936, acc=0.9881666898727417, loss=0.039866041392087936
test: epoch 119, loss 0.8364006280899048, acc=0.7611111402511597, loss=0.8364006280899048
train: epoch 120, loss 0.04192987084388733, acc=0.987333357334137, loss=0.04192987084388733
test: epoch 120, loss 1.1488988399505615, acc=0.7222222089767456, loss=1.1488988399505615
train: epoch 121, loss 0.037939660251140594, acc=0.9879444241523743, loss=0.037939660251140594
test: epoch 121, loss 1.6202545166015625, acc=0.6777777671813965, loss=1.6202545166015625
train: epoch 122, loss 0.061918336898088455, acc=0.9818888902664185, loss=0.061918336898088455
test: epoch 122, loss 1.1964716911315918, acc=0.6805555820465088, loss=1.1964716911315918
train: epoch 123, loss 0.037792183458805084, acc=0.9883333444595337, loss=0.037792183458805084
test: epoch 123, loss 1.1483631134033203, acc=0.7138888835906982, loss=1.1483631134033203
train: epoch 124, loss 0.03378027677536011, acc=0.9890000224113464, loss=0.03378027677536011
test: epoch 124, loss 1.1835042238235474, acc=0.699999988079071, loss=1.1835042238235474
train: epoch 125, loss 0.04345058277249336, acc=0.9859444499015808, loss=0.04345058277249336
test: epoch 125, loss 0.9141622185707092, acc=0.7250000238418579, loss=0.9141622185707092
train: epoch 126, loss 0.03469642996788025, acc=0.9896666407585144, loss=0.03469642996788025
test: epoch 126, loss 1.076129674911499, acc=0.7138888835906982, loss=1.076129674911499
train: epoch 127, loss 0.045306067913770676, acc=0.9860555529594421, loss=0.045306067913770676
test: epoch 127, loss 1.3584022521972656, acc=0.7388888597488403, loss=1.3584022521972656
train: epoch 128, loss 0.035546671599149704, acc=0.988611102104187, loss=0.035546671599149704
test: epoch 128, loss 1.0928165912628174, acc=0.7138888835906982, loss=1.0928165912628174
train: epoch 129, loss 0.05614437162876129, acc=0.984333336353302, loss=0.05614437162876129
test: epoch 129, loss 0.7714650630950928, acc=0.7638888955116272, loss=0.7714650630950928
train: epoch 130, loss 0.030042072758078575, acc=0.9890555739402771, loss=0.030042072758078575
test: epoch 130, loss 1.1030300855636597, acc=0.7194444537162781, loss=1.1030300855636597
train: epoch 131, loss 0.03595518693327904, acc=0.9907777905464172, loss=0.03595518693327904
test: epoch 131, loss 1.0486868619918823, acc=0.769444465637207, loss=1.0486868619918823
train: epoch 132, loss 0.04162205010652542, acc=0.9888888597488403, loss=0.04162205010652542
test: epoch 132, loss 1.352102518081665, acc=0.7111111283302307, loss=1.352102518081665
train: epoch 133, loss 0.03491954877972603, acc=0.9901666641235352, loss=0.03491954877972603
test: epoch 133, loss 0.9122661352157593, acc=0.7333333492279053, loss=0.9122661352157593
train: epoch 134, loss 0.03805889934301376, acc=0.9893888831138611, loss=0.03805889934301376
test: epoch 134, loss 0.7846096754074097, acc=0.7833333611488342, loss=0.7846096754074097
train: epoch 135, loss 0.0388718843460083, acc=0.9897778034210205, loss=0.0388718843460083
test: epoch 135, loss 1.258731484413147, acc=0.7194444537162781, loss=1.258731484413147
train: epoch 136, loss 0.03325905650854111, acc=0.9911110997200012, loss=0.03325905650854111
test: epoch 136, loss 0.8299319744110107, acc=0.7333333492279053, loss=0.8299319744110107
train: epoch 137, loss 0.030114253982901573, acc=0.9919999837875366, loss=0.030114253982901573
test: epoch 137, loss 0.8913806676864624, acc=0.7250000238418579, loss=0.8913806676864624
train: epoch 138, loss 0.027134841307997704, acc=0.992222249507904, loss=0.027134841307997704
test: epoch 138, loss 1.3910921812057495, acc=0.7472222447395325, loss=1.3910921812057495
train: epoch 139, loss 0.030495623126626015, acc=0.9923333525657654, loss=0.030495623126626015
test: epoch 139, loss 0.9039856195449829, acc=0.7250000238418579, loss=0.9039856195449829
train: epoch 140, loss 0.04445701465010643, acc=0.9876111149787903, loss=0.04445701465010643
test: epoch 140, loss 0.7853085994720459, acc=0.7749999761581421, loss=0.7853085994720459
train: epoch 141, loss 0.04131774231791496, acc=0.9892777800559998, loss=0.04131774231791496
test: epoch 141, loss 0.7007128000259399, acc=0.8388888835906982, loss=0.7007128000259399
train: epoch 142, loss 0.02404630184173584, acc=0.9933333396911621, loss=0.02404630184173584
test: epoch 142, loss 1.315730094909668, acc=0.7916666865348816, loss=1.315730094909668
train: epoch 143, loss 0.025322388857603073, acc=0.9936110973358154, loss=0.025322388857603073
test: epoch 143, loss 0.7439878582954407, acc=0.8472222089767456, loss=0.7439878582954407
train: epoch 144, loss 0.03257603570818901, acc=0.991944432258606, loss=0.03257603570818901
test: epoch 144, loss 0.4228171408176422, acc=0.8444444537162781, loss=0.4228171408176422
train: epoch 145, loss 0.015652483329176903, acc=0.995722234249115, loss=0.015652483329176903
test: epoch 145, loss 0.5113627910614014, acc=0.769444465637207, loss=0.5113627910614014
train: epoch 146, loss 0.06164082884788513, acc=0.9826666712760925, loss=0.06164082884788513
test: epoch 146, loss 0.8023646473884583, acc=0.7833333611488342, loss=0.8023646473884583
train: epoch 147, loss 0.010532242245972157, acc=0.996999979019165, loss=0.010532242245972157
test: epoch 147, loss 0.8819605708122253, acc=0.7833333611488342, loss=0.8819605708122253
train: epoch 148, loss 0.02700057253241539, acc=0.9924444556236267, loss=0.02700057253241539
test: epoch 148, loss 0.6016027927398682, acc=0.8138889074325562, loss=0.6016027927398682
train: epoch 149, loss 0.03474220633506775, acc=0.9896666407585144, loss=0.03474220633506775
test: epoch 149, loss 0.97342449426651, acc=0.8111110925674438, loss=0.97342449426651
train: epoch 150, loss 0.02071584202349186, acc=0.9937222003936768, loss=0.02071584202349186
test: epoch 150, loss 0.4459027647972107, acc=0.8416666388511658, loss=0.4459027647972107
