# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=1.5", "--temp_decay=1", "--one_hot=1", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=1080736225, receiver_embed_dim=128, save_run=0, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1080736225, receiver_embed_dim=128, save_run=False, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.7772884368896484, acc=0.10311111062765121, loss=2.7772884368896484
test: epoch 1, loss 3.094496011734009, acc=0.10833333432674408, loss=3.094496011734009
train: epoch 2, loss 1.6202951669692993, acc=0.34344443678855896, loss=1.6202951669692993
test: epoch 2, loss 2.7896370887756348, acc=0.21111111342906952, loss=2.7896370887756348
train: epoch 3, loss 1.0757896900177002, acc=0.5718888640403748, loss=1.0757896900177002
test: epoch 3, loss 2.3512496948242188, acc=0.23888888955116272, loss=2.3512496948242188
train: epoch 4, loss 0.8034146428108215, acc=0.6777777671813965, loss=0.8034146428108215
test: epoch 4, loss 2.140774965286255, acc=0.24166665971279144, loss=2.140774965286255
train: epoch 5, loss 0.676794171333313, acc=0.7294999957084656, loss=0.676794171333313
test: epoch 5, loss 2.191336154937744, acc=0.2944444417953491, loss=2.191336154937744
train: epoch 6, loss 0.5961608290672302, acc=0.761222243309021, loss=0.5961608290672302
test: epoch 6, loss 1.6668457984924316, acc=0.4277777671813965, loss=1.6668457984924316
train: epoch 7, loss 0.5186434984207153, acc=0.7982222437858582, loss=0.5186434984207153
test: epoch 7, loss 1.9624298810958862, acc=0.34166666865348816, loss=1.9624298810958862
train: epoch 8, loss 0.44856828451156616, acc=0.8221111297607422, loss=0.44856828451156616
test: epoch 8, loss 1.907789707183838, acc=0.3333333432674408, loss=1.907789707183838
train: epoch 9, loss 0.41026750206947327, acc=0.8383888602256775, loss=0.41026750206947327
test: epoch 9, loss 1.7427432537078857, acc=0.43611112236976624, loss=1.7427432537078857
train: epoch 10, loss 0.37347671389579773, acc=0.8511666655540466, loss=0.37347671389579773
test: epoch 10, loss 1.876354694366455, acc=0.3888888955116272, loss=1.876354694366455
train: epoch 11, loss 0.34343451261520386, acc=0.8597777485847473, loss=0.34343451261520386
test: epoch 11, loss 1.7893483638763428, acc=0.40833333134651184, loss=1.7893483638763428
train: epoch 12, loss 0.32400259375572205, acc=0.8686666488647461, loss=0.32400259375572205
test: epoch 12, loss 1.9480814933776855, acc=0.4694444537162781, loss=1.9480814933776855
train: epoch 13, loss 0.28467971086502075, acc=0.8828333616256714, loss=0.28467971086502075
test: epoch 13, loss 1.9336357116699219, acc=0.4611110985279083, loss=1.9336357116699219
train: epoch 14, loss 0.28302690386772156, acc=0.8857777714729309, loss=0.28302690386772156
test: epoch 14, loss 1.8867655992507935, acc=0.4749999940395355, loss=1.8867655992507935
train: epoch 15, loss 0.24941019713878632, acc=0.8964444398880005, loss=0.24941019713878632
test: epoch 15, loss 1.8448803424835205, acc=0.4833333194255829, loss=1.8448803424835205
train: epoch 16, loss 0.254071980714798, acc=0.8978333473205566, loss=0.254071980714798
test: epoch 16, loss 1.8608019351959229, acc=0.519444465637207, loss=1.8608019351959229
train: epoch 17, loss 0.24072059988975525, acc=0.9015555381774902, loss=0.24072059988975525
test: epoch 17, loss 1.6664395332336426, acc=0.519444465637207, loss=1.6664395332336426
train: epoch 18, loss 0.22180064022541046, acc=0.909166693687439, loss=0.22180064022541046
test: epoch 18, loss 2.016897678375244, acc=0.5027777552604675, loss=2.016897678375244
train: epoch 19, loss 0.23390600085258484, acc=0.9057777523994446, loss=0.23390600085258484
test: epoch 19, loss 1.576572060585022, acc=0.5861111283302307, loss=1.576572060585022
train: epoch 20, loss 0.2174941599369049, acc=0.9095555543899536, loss=0.2174941599369049
test: epoch 20, loss 1.5386817455291748, acc=0.4861111044883728, loss=1.5386817455291748
train: epoch 21, loss 0.21728476881980896, acc=0.9130555391311646, loss=0.21728476881980896
test: epoch 21, loss 1.755307912826538, acc=0.5138888955116272, loss=1.755307912826538
train: epoch 22, loss 0.20823125541210175, acc=0.9155555367469788, loss=0.20823125541210175
test: epoch 22, loss 1.5226560831069946, acc=0.6166666746139526, loss=1.5226560831069946
train: epoch 23, loss 0.19256240129470825, acc=0.9197221994400024, loss=0.19256240129470825
test: epoch 23, loss 1.8965415954589844, acc=0.5111111402511597, loss=1.8965415954589844
train: epoch 24, loss 0.19094479084014893, acc=0.9212222099304199, loss=0.19094479084014893
test: epoch 24, loss 1.53062105178833, acc=0.6333333253860474, loss=1.53062105178833
train: epoch 25, loss 0.19497056305408478, acc=0.9205555319786072, loss=0.19497056305408478
test: epoch 25, loss 1.6402828693389893, acc=0.6111111044883728, loss=1.6402828693389893
train: epoch 26, loss 0.18860968947410583, acc=0.9215555787086487, loss=0.18860968947410583
test: epoch 26, loss 1.5405914783477783, acc=0.625, loss=1.5405914783477783
train: epoch 27, loss 0.18157486617565155, acc=0.9251111149787903, loss=0.18157486617565155
test: epoch 27, loss 1.1661051511764526, acc=0.6472222208976746, loss=1.1661051511764526
train: epoch 28, loss 0.17067252099514008, acc=0.9288889169692993, loss=0.17067252099514008
test: epoch 28, loss 1.5478277206420898, acc=0.5722222328186035, loss=1.5478277206420898
train: epoch 29, loss 0.16543559730052948, acc=0.929111123085022, loss=0.16543559730052948
test: epoch 29, loss 1.2965669631958008, acc=0.6777777671813965, loss=1.2965669631958008
train: epoch 30, loss 0.17080743610858917, acc=0.929722249507904, loss=0.17080743610858917
test: epoch 30, loss 1.2459100484848022, acc=0.6916666626930237, loss=1.2459100484848022
train: epoch 31, loss 0.1653425544500351, acc=0.9312777519226074, loss=0.1653425544500351
test: epoch 31, loss 1.5309085845947266, acc=0.6333333253860474, loss=1.5309085845947266
train: epoch 32, loss 0.16289658844470978, acc=0.9316111207008362, loss=0.16289658844470978
test: epoch 32, loss 1.4192003011703491, acc=0.6388888955116272, loss=1.4192003011703491
train: epoch 33, loss 0.1624564826488495, acc=0.9306111335754395, loss=0.1624564826488495
test: epoch 33, loss 1.4253710508346558, acc=0.6833333373069763, loss=1.4253710508346558
train: epoch 34, loss 0.14477412402629852, acc=0.9360555410385132, loss=0.14477412402629852
test: epoch 34, loss 1.0374215841293335, acc=0.769444465637207, loss=1.0374215841293335
train: epoch 35, loss 0.14676380157470703, acc=0.9354444742202759, loss=0.14676380157470703
test: epoch 35, loss 1.2004433870315552, acc=0.7444444298744202, loss=1.2004433870315552
train: epoch 36, loss 0.14520543813705444, acc=0.9374444484710693, loss=0.14520543813705444
test: epoch 36, loss 0.964706301689148, acc=0.7361111044883728, loss=0.964706301689148
train: epoch 37, loss 0.1441425234079361, acc=0.937166690826416, loss=0.1441425234079361
test: epoch 37, loss 0.8926459550857544, acc=0.7972221970558167, loss=0.8926459550857544
train: epoch 38, loss 0.14304015040397644, acc=0.9390555620193481, loss=0.14304015040397644
test: epoch 38, loss 0.7696992754936218, acc=0.7805555462837219, loss=0.7696992754936218
train: epoch 39, loss 0.12056215107440948, acc=0.9440555572509766, loss=0.12056215107440948
test: epoch 39, loss 0.9753507971763611, acc=0.7972221970558167, loss=0.9753507971763611
train: epoch 40, loss 0.14495569467544556, acc=0.9381666779518127, loss=0.14495569467544556
test: epoch 40, loss 0.7352846264839172, acc=0.8166666626930237, loss=0.7352846264839172
train: epoch 41, loss 0.1260606050491333, acc=0.9433888792991638, loss=0.1260606050491333
test: epoch 41, loss 0.710751473903656, acc=0.8222222328186035, loss=0.710751473903656
train: epoch 42, loss 0.11871670186519623, acc=0.9451666474342346, loss=0.11871670186519623
test: epoch 42, loss 0.7147354483604431, acc=0.800000011920929, loss=0.7147354483604431
train: epoch 43, loss 0.1290193796157837, acc=0.9431111216545105, loss=0.1290193796157837
test: epoch 43, loss 0.7173959612846375, acc=0.8222222328186035, loss=0.7173959612846375
train: epoch 44, loss 0.1326502114534378, acc=0.9428333044052124, loss=0.1326502114534378
test: epoch 44, loss 0.7550086379051208, acc=0.8194444179534912, loss=0.7550086379051208
train: epoch 45, loss 0.11468140035867691, acc=0.9474999904632568, loss=0.11468140035867691
test: epoch 45, loss 0.6000415682792664, acc=0.8416666388511658, loss=0.6000415682792664
train: epoch 46, loss 0.1085367277264595, acc=0.9486666917800903, loss=0.1085367277264595
test: epoch 46, loss 0.8090004920959473, acc=0.7888888716697693, loss=0.8090004920959473
train: epoch 47, loss 0.11847547441720963, acc=0.9465555548667908, loss=0.11847547441720963
test: epoch 47, loss 0.731425940990448, acc=0.8416666388511658, loss=0.731425940990448
train: epoch 48, loss 0.11331988871097565, acc=0.9482222199440002, loss=0.11331988871097565
test: epoch 48, loss 0.6557910442352295, acc=0.8277778029441833, loss=0.6557910442352295
train: epoch 49, loss 0.11729473620653152, acc=0.9472777843475342, loss=0.11729473620653152
test: epoch 49, loss 0.7232996225357056, acc=0.8388888835906982, loss=0.7232996225357056
train: epoch 50, loss 0.10567177087068558, acc=0.9498888850212097, loss=0.10567177087068558
test: epoch 50, loss 0.5742400884628296, acc=0.8444444537162781, loss=0.5742400884628296
train: epoch 51, loss 0.10443340986967087, acc=0.9508888721466064, loss=0.10443340986967087
test: epoch 51, loss 0.7250574231147766, acc=0.8416666388511658, loss=0.7250574231147766
train: epoch 52, loss 0.10937296599149704, acc=0.9482222199440002, loss=0.10937296599149704
test: epoch 52, loss 0.7406489253044128, acc=0.8361111283302307, loss=0.7406489253044128
train: epoch 53, loss 0.09551039338111877, acc=0.9526666402816772, loss=0.09551039338111877
test: epoch 53, loss 0.699124276638031, acc=0.8444444537162781, loss=0.699124276638031
train: epoch 54, loss 0.10939139127731323, acc=0.9497777819633484, loss=0.10939139127731323
test: epoch 54, loss 0.6679846048355103, acc=0.8444444537162781, loss=0.6679846048355103
train: epoch 55, loss 0.10599208623170853, acc=0.9502778053283691, loss=0.10599208623170853
test: epoch 55, loss 0.7050845623016357, acc=0.8388888835906982, loss=0.7050845623016357
train: epoch 56, loss 0.10304570198059082, acc=0.9567777514457703, loss=0.10304570198059082
test: epoch 56, loss 0.7237806916236877, acc=0.8388888835906982, loss=0.7237806916236877
train: epoch 57, loss 0.08684558421373367, acc=0.9673333168029785, loss=0.08684558421373367
test: epoch 57, loss 0.7316294312477112, acc=0.8416666388511658, loss=0.7316294312477112
train: epoch 58, loss 0.07404682785272598, acc=0.9754444360733032, loss=0.07404682785272598
test: epoch 58, loss 0.7888389825820923, acc=0.8472222089767456, loss=0.7888389825820923
train: epoch 59, loss 0.07362261414527893, acc=0.9748333096504211, loss=0.07362261414527893
test: epoch 59, loss 0.8485329151153564, acc=0.8416666388511658, loss=0.8485329151153564
train: epoch 60, loss 0.06583384424448013, acc=0.9790555834770203, loss=0.06583384424448013
test: epoch 60, loss 0.769467830657959, acc=0.8500000238418579, loss=0.769467830657959
train: epoch 61, loss 0.07791907340288162, acc=0.9763333201408386, loss=0.07791907340288162
test: epoch 61, loss 0.8086430430412292, acc=0.8472222089767456, loss=0.8086430430412292
train: epoch 62, loss 0.06034797057509422, acc=0.9808889031410217, loss=0.06034797057509422
test: epoch 62, loss 0.6250138282775879, acc=0.8472222089767456, loss=0.6250138282775879
train: epoch 63, loss 0.05340679734945297, acc=0.9822777509689331, loss=0.05340679734945297
test: epoch 63, loss 0.807391881942749, acc=0.8500000238418579, loss=0.807391881942749
train: epoch 64, loss 0.04246196150779724, acc=0.9850000143051147, loss=0.04246196150779724
test: epoch 64, loss 0.7497935891151428, acc=0.8500000238418579, loss=0.7497935891151428
train: epoch 65, loss 0.053561147302389145, acc=0.9826111197471619, loss=0.053561147302389145
test: epoch 65, loss 0.7079350352287292, acc=0.8444444537162781, loss=0.7079350352287292
train: epoch 66, loss 0.06467387825250626, acc=0.9804999828338623, loss=0.06467387825250626
test: epoch 66, loss 0.6782088279724121, acc=0.8500000238418579, loss=0.6782088279724121
train: epoch 67, loss 0.059148989617824554, acc=0.9806666374206543, loss=0.059148989617824554
test: epoch 67, loss 0.6996375918388367, acc=0.8500000238418579, loss=0.6996375918388367
train: epoch 68, loss 0.04845890775322914, acc=0.984333336353302, loss=0.04845890775322914
test: epoch 68, loss 0.7783789038658142, acc=0.8472222089767456, loss=0.7783789038658142
train: epoch 69, loss 0.053061872720718384, acc=0.9826111197471619, loss=0.053061872720718384
test: epoch 69, loss 0.5667676329612732, acc=0.8833333253860474, loss=0.5667676329612732
train: epoch 70, loss 0.04760807007551193, acc=0.9839444160461426, loss=0.04760807007551193
test: epoch 70, loss 0.7244968414306641, acc=0.8583333492279053, loss=0.7244968414306641
train: epoch 71, loss 0.05993945896625519, acc=0.9801666736602783, loss=0.05993945896625519
test: epoch 71, loss 0.4140579402446747, acc=0.855555534362793, loss=0.4140579402446747
train: epoch 72, loss 0.056353211402893066, acc=0.9822777509689331, loss=0.056353211402893066
test: epoch 72, loss 0.6155447363853455, acc=0.8888888955116272, loss=0.6155447363853455
train: epoch 73, loss 0.039489295333623886, acc=0.9865000247955322, loss=0.039489295333623886
test: epoch 73, loss 0.5841937065124512, acc=0.8861111402511597, loss=0.5841937065124512
train: epoch 74, loss 0.03477039188146591, acc=0.9879444241523743, loss=0.03477039188146591
test: epoch 74, loss 0.6436173319816589, acc=0.8805555701255798, loss=0.6436173319816589
train: epoch 75, loss 0.0461110919713974, acc=0.9856111407279968, loss=0.0461110919713974
test: epoch 75, loss 0.3844979405403137, acc=0.8972222208976746, loss=0.3844979405403137
train: epoch 76, loss 0.04074474796652794, acc=0.9858888983726501, loss=0.04074474796652794
test: epoch 76, loss 0.6038362383842468, acc=0.894444465637207, loss=0.6038362383842468
train: epoch 77, loss 0.046021703630685806, acc=0.9844444394111633, loss=0.046021703630685806
test: epoch 77, loss 0.536835789680481, acc=0.8999999761581421, loss=0.536835789680481
train: epoch 78, loss 0.0528365820646286, acc=0.9845555424690247, loss=0.0528365820646286
test: epoch 78, loss 0.4859040379524231, acc=0.8972222208976746, loss=0.4859040379524231
train: epoch 79, loss 0.03361303731799126, acc=0.9877777695655823, loss=0.03361303731799126
test: epoch 79, loss 0.5847585797309875, acc=0.8972222208976746, loss=0.5847585797309875
train: epoch 80, loss 0.03932727500796318, acc=0.9862222075462341, loss=0.03932727500796318
test: epoch 80, loss 0.4454910457134247, acc=0.8999999761581421, loss=0.4454910457134247
train: epoch 81, loss 0.0392327681183815, acc=0.9860555529594421, loss=0.0392327681183815
test: epoch 81, loss 0.5307714939117432, acc=0.8999999761581421, loss=0.5307714939117432
train: epoch 82, loss 0.0330330915749073, acc=0.9880555272102356, loss=0.0330330915749073
test: epoch 82, loss 0.5550292134284973, acc=0.8999999761581421, loss=0.5550292134284973
train: epoch 83, loss 0.03537049889564514, acc=0.9875555634498596, loss=0.03537049889564514
test: epoch 83, loss 0.4541805684566498, acc=0.8972222208976746, loss=0.4541805684566498
train: epoch 84, loss 0.04682338237762451, acc=0.9862222075462341, loss=0.04682338237762451
test: epoch 84, loss 0.6434962749481201, acc=0.8972222208976746, loss=0.6434962749481201
train: epoch 85, loss 0.046767693012952805, acc=0.9848333597183228, loss=0.046767693012952805
test: epoch 85, loss 0.5039359331130981, acc=0.8999999761581421, loss=0.5039359331130981
train: epoch 86, loss 0.037334151566028595, acc=0.9878333210945129, loss=0.037334151566028595
test: epoch 86, loss 0.5574790239334106, acc=0.8999999761581421, loss=0.5574790239334106
train: epoch 87, loss 0.0359589047729969, acc=0.9876111149787903, loss=0.0359589047729969
test: epoch 87, loss 0.4503098130226135, acc=0.8999999761581421, loss=0.4503098130226135
train: epoch 88, loss 0.0409868098795414, acc=0.9860000014305115, loss=0.0409868098795414
test: epoch 88, loss 0.4662855565547943, acc=0.8999999761581421, loss=0.4662855565547943
train: epoch 89, loss 0.03494720160961151, acc=0.9874444603919983, loss=0.03494720160961151
test: epoch 89, loss 0.5091906785964966, acc=0.8999999761581421, loss=0.5091906785964966
train: epoch 90, loss 0.03627772629261017, acc=0.9873889088630676, loss=0.03627772629261017
test: epoch 90, loss 0.4623422920703888, acc=0.8999999761581421, loss=0.4623422920703888
train: epoch 91, loss 0.03988385573029518, acc=0.9870555400848389, loss=0.03988385573029518
test: epoch 91, loss 0.486047625541687, acc=0.8972222208976746, loss=0.486047625541687
train: epoch 92, loss 0.03414157032966614, acc=0.9881666898727417, loss=0.03414157032966614
test: epoch 92, loss 0.5061947703361511, acc=0.9055555462837219, loss=0.5061947703361511
train: epoch 93, loss 0.032509174197912216, acc=0.988277792930603, loss=0.032509174197912216
test: epoch 93, loss 0.5232908725738525, acc=0.8999999761581421, loss=0.5232908725738525
train: epoch 94, loss 0.03548218682408333, acc=0.987666666507721, loss=0.03548218682408333
test: epoch 94, loss 0.4171648621559143, acc=0.8999999761581421, loss=0.4171648621559143
train: epoch 95, loss 0.04033960402011871, acc=0.9859444499015808, loss=0.04033960402011871
test: epoch 95, loss 0.4517190456390381, acc=0.8999999761581421, loss=0.4517190456390381
train: epoch 96, loss 0.03870747610926628, acc=0.9875555634498596, loss=0.03870747610926628
test: epoch 96, loss 0.536558985710144, acc=0.9027777910232544, loss=0.536558985710144
train: epoch 97, loss 0.03722931072115898, acc=0.9862222075462341, loss=0.03722931072115898
test: epoch 97, loss 0.3774762451648712, acc=0.8999999761581421, loss=0.3774762451648712
train: epoch 98, loss 0.033443354070186615, acc=0.988444447517395, loss=0.033443354070186615
test: epoch 98, loss 0.402080237865448, acc=0.9027777910232544, loss=0.402080237865448
train: epoch 99, loss 0.05839594081044197, acc=0.984666645526886, loss=0.05839594081044197
test: epoch 99, loss 0.5097892880439758, acc=0.8972222208976746, loss=0.5097892880439758
train: epoch 100, loss 0.04949402064085007, acc=0.9851666688919067, loss=0.04949402064085007
test: epoch 100, loss 0.5385521054267883, acc=0.8999999761581421, loss=0.5385521054267883
train: epoch 101, loss 0.033016812056303024, acc=0.9880555272102356, loss=0.033016812056303024
test: epoch 101, loss 0.6054604649543762, acc=0.9027777910232544, loss=0.6054604649543762
train: epoch 102, loss 0.0334959477186203, acc=0.9877222180366516, loss=0.0334959477186203
test: epoch 102, loss 0.47424355149269104, acc=0.9027777910232544, loss=0.47424355149269104
train: epoch 103, loss 0.02852674014866352, acc=0.988611102104187, loss=0.02852674014866352
test: epoch 103, loss 0.5640939474105835, acc=0.9027777910232544, loss=0.5640939474105835
train: epoch 104, loss 0.032060351222753525, acc=0.9877222180366516, loss=0.032060351222753525
test: epoch 104, loss 0.5033209323883057, acc=0.9027777910232544, loss=0.5033209323883057
train: epoch 105, loss 0.038144052028656006, acc=0.9878333210945129, loss=0.038144052028656006
test: epoch 105, loss 0.5047381520271301, acc=0.9027777910232544, loss=0.5047381520271301
train: epoch 106, loss 0.034416455775499344, acc=0.9876111149787903, loss=0.034416455775499344
test: epoch 106, loss 0.38536813855171204, acc=0.9083333611488342, loss=0.38536813855171204
train: epoch 107, loss 0.04143557697534561, acc=0.9846110939979553, loss=0.04143557697534561
test: epoch 107, loss 0.3882664740085602, acc=0.9055555462837219, loss=0.3882664740085602
train: epoch 108, loss 0.0308526661247015, acc=0.9890555739402771, loss=0.0308526661247015
test: epoch 108, loss 0.5373847484588623, acc=0.9083333611488342, loss=0.5373847484588623
train: epoch 109, loss 0.03640441969037056, acc=0.9880555272102356, loss=0.03640441969037056
test: epoch 109, loss 0.4446864426136017, acc=0.9083333611488342, loss=0.4446864426136017
train: epoch 110, loss 0.04840536415576935, acc=0.9866666793823242, loss=0.04840536415576935
test: epoch 110, loss 0.47622916102409363, acc=0.9055555462837219, loss=0.47622916102409363
train: epoch 111, loss 0.026322290301322937, acc=0.9898333549499512, loss=0.026322290301322937
test: epoch 111, loss 0.3115091025829315, acc=0.9083333611488342, loss=0.3115091025829315
train: epoch 112, loss 0.041243020445108414, acc=0.9883333444595337, loss=0.041243020445108414
test: epoch 112, loss 0.44930487871170044, acc=0.9083333611488342, loss=0.44930487871170044
train: epoch 113, loss 0.02843431383371353, acc=0.9884999990463257, loss=0.02843431383371353
test: epoch 113, loss 0.42307332158088684, acc=0.9083333611488342, loss=0.42307332158088684
train: epoch 114, loss 0.024287132546305656, acc=0.9901666641235352, loss=0.024287132546305656
test: epoch 114, loss 0.5753979086875916, acc=0.9055555462837219, loss=0.5753979086875916
train: epoch 115, loss 0.03792921081185341, acc=0.9876111149787903, loss=0.03792921081185341
test: epoch 115, loss 0.5738629102706909, acc=0.9027777910232544, loss=0.5738629102706909
train: epoch 116, loss 0.029662199318408966, acc=0.9893333315849304, loss=0.029662199318408966
test: epoch 116, loss 0.48709386587142944, acc=0.9138888716697693, loss=0.48709386587142944
train: epoch 117, loss 0.030472036451101303, acc=0.9887222051620483, loss=0.030472036451101303
test: epoch 117, loss 0.5073004364967346, acc=0.9083333611488342, loss=0.5073004364967346
train: epoch 118, loss 0.0419551320374012, acc=0.9882222414016724, loss=0.0419551320374012
test: epoch 118, loss 0.4535406827926636, acc=0.9138888716697693, loss=0.4535406827926636
train: epoch 119, loss 0.03513219952583313, acc=0.988277792930603, loss=0.03513219952583313
test: epoch 119, loss 0.35673683881759644, acc=0.9138888716697693, loss=0.35673683881759644
train: epoch 120, loss 0.027503306046128273, acc=0.9894444346427917, loss=0.027503306046128273
test: epoch 120, loss 0.49310651421546936, acc=0.9138888716697693, loss=0.49310651421546936
train: epoch 121, loss 0.029034040868282318, acc=0.9890555739402771, loss=0.029034040868282318
test: epoch 121, loss 0.42489683628082275, acc=0.9194444417953491, loss=0.42489683628082275
train: epoch 122, loss 0.02878562919795513, acc=0.9892222285270691, loss=0.02878562919795513
test: epoch 122, loss 0.4213081896305084, acc=0.925000011920929, loss=0.4213081896305084
train: epoch 123, loss 0.03423905372619629, acc=0.9883888959884644, loss=0.03423905372619629
test: epoch 123, loss 0.31310388445854187, acc=0.9416666626930237, loss=0.31310388445854187
train: epoch 124, loss 0.023477323353290558, acc=0.9907777905464172, loss=0.023477323353290558
test: epoch 124, loss 0.4223116338253021, acc=0.9388889074325562, loss=0.4223116338253021
train: epoch 125, loss 0.02792518027126789, acc=0.9900555610656738, loss=0.02792518027126789
test: epoch 125, loss 0.6773974895477295, acc=0.9138888716697693, loss=0.6773974895477295
train: epoch 126, loss 0.027683375403285027, acc=0.9890000224113464, loss=0.027683375403285027
test: epoch 126, loss 0.27394455671310425, acc=0.949999988079071, loss=0.27394455671310425
train: epoch 127, loss 0.028818883001804352, acc=0.9893888831138611, loss=0.028818883001804352
test: epoch 127, loss 0.24531860649585724, acc=0.9472222328186035, loss=0.24531860649585724
train: epoch 128, loss 0.02327803522348404, acc=0.9903333187103271, loss=0.02327803522348404
test: epoch 128, loss 0.25431153178215027, acc=0.9583333134651184, loss=0.25431153178215027
train: epoch 129, loss 0.02894899621605873, acc=0.9897778034210205, loss=0.02894899621605873
test: epoch 129, loss 0.29982462525367737, acc=0.9527778029441833, loss=0.29982462525367737
train: epoch 130, loss 0.03070376068353653, acc=0.9892777800559998, loss=0.03070376068353653
test: epoch 130, loss 0.20517133176326752, acc=0.9583333134651184, loss=0.20517133176326752
train: epoch 131, loss 0.036150142550468445, acc=0.9874444603919983, loss=0.036150142550468445
test: epoch 131, loss 0.25255319476127625, acc=0.9555555582046509, loss=0.25255319476127625
train: epoch 132, loss 0.032425589859485626, acc=0.9891666769981384, loss=0.032425589859485626
test: epoch 132, loss 0.27523112297058105, acc=0.9583333134651184, loss=0.27523112297058105
train: epoch 133, loss 0.025862302631139755, acc=0.9903333187103271, loss=0.025862302631139755
test: epoch 133, loss 0.15614207088947296, acc=0.9611111283302307, loss=0.15614207088947296
train: epoch 134, loss 0.018608925864100456, acc=0.9913333058357239, loss=0.018608925864100456
test: epoch 134, loss 0.23938579857349396, acc=0.9611111283302307, loss=0.23938579857349396
train: epoch 135, loss 0.019629700109362602, acc=0.9911666512489319, loss=0.019629700109362602
test: epoch 135, loss 0.2502361238002777, acc=0.9638888835906982, loss=0.2502361238002777
train: epoch 136, loss 0.02461416833102703, acc=0.9906666874885559, loss=0.02461416833102703
test: epoch 136, loss 0.2954389750957489, acc=0.9638888835906982, loss=0.2954389750957489
train: epoch 137, loss 0.02884124033153057, acc=0.9903333187103271, loss=0.02884124033153057
test: epoch 137, loss 0.0724230632185936, acc=0.9833333492279053, loss=0.0724230632185936
train: epoch 138, loss 0.029138993471860886, acc=0.9898889064788818, loss=0.029138993471860886
test: epoch 138, loss 0.16219498217105865, acc=0.9777777791023254, loss=0.16219498217105865
train: epoch 139, loss 0.039245590567588806, acc=0.987333357334137, loss=0.039245590567588806
test: epoch 139, loss 0.253133624792099, acc=0.9638888835906982, loss=0.253133624792099
train: epoch 140, loss 0.03319310024380684, acc=0.9878888726234436, loss=0.03319310024380684
test: epoch 140, loss 0.11472565680742264, acc=0.9777777791023254, loss=0.11472565680742264
train: epoch 141, loss 0.030612556263804436, acc=0.988277792930603, loss=0.030612556263804436
test: epoch 141, loss 0.1681973785161972, acc=0.9722222089767456, loss=0.1681973785161972
train: epoch 142, loss 0.03690188750624657, acc=0.9873889088630676, loss=0.03690188750624657
test: epoch 142, loss 0.0698065534234047, acc=0.9833333492279053, loss=0.0698065534234047
train: epoch 143, loss 0.026506107300519943, acc=0.9891111254692078, loss=0.026506107300519943
test: epoch 143, loss 0.038923684507608414, acc=0.9888888597488403, loss=0.038923684507608414
train: epoch 144, loss 0.023566044867038727, acc=0.9906666874885559, loss=0.023566044867038727
test: epoch 144, loss 0.09903115034103394, acc=0.9833333492279053, loss=0.09903115034103394
train: epoch 145, loss 0.02990218624472618, acc=0.9900000095367432, loss=0.02990218624472618
test: epoch 145, loss 0.1115562692284584, acc=0.9777777791023254, loss=0.1115562692284584
train: epoch 146, loss 0.022124052047729492, acc=0.9908888936042786, loss=0.022124052047729492
test: epoch 146, loss 0.03692314401268959, acc=0.9888888597488403, loss=0.03692314401268959
train: epoch 147, loss 0.03943713381886482, acc=0.9871666431427002, loss=0.03943713381886482
test: epoch 147, loss 0.03982517495751381, acc=0.9861111044883728, loss=0.03982517495751381
train: epoch 148, loss 0.0387100987136364, acc=0.9867222309112549, loss=0.0387100987136364
test: epoch 148, loss 0.03739984333515167, acc=0.9861111044883728, loss=0.03739984333515167
train: epoch 149, loss 0.029033329337835312, acc=0.9890000224113464, loss=0.029033329337835312
test: epoch 149, loss 0.02708754874765873, acc=0.9888888597488403, loss=0.02708754874765873
train: epoch 150, loss 0.021258529275655746, acc=0.9905555844306946, loss=0.021258529275655746
test: epoch 150, loss 0.03442445024847984, acc=0.9888888597488403, loss=0.03442445024847984
