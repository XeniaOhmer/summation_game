# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=1", "--temp_decay=1", "--one_hot=false", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1393645300, receiver_embed_dim=128, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.0921099185943604, acc=0.05955555662512779, loss=3.0921099185943604
test: epoch 1, loss 2.7892696857452393, acc=0.10833333432674408, loss=2.7892696857452393
train: epoch 2, loss 2.364964008331299, acc=0.15549999475479126, loss=2.364964008331299
test: epoch 2, loss 2.161497116088867, acc=0.18611110746860504, loss=2.161497116088867
train: epoch 3, loss 1.935794711112976, acc=0.23888888955116272, loss=1.935794711112976
test: epoch 3, loss 1.9516844749450684, acc=0.22777777910232544, loss=1.9516844749450684
train: epoch 4, loss 1.6159415245056152, acc=0.3243333399295807, loss=1.6159415245056152
test: epoch 4, loss 1.7061476707458496, acc=0.28611111640930176, loss=1.7061476707458496
train: epoch 5, loss 1.3702102899551392, acc=0.4068889021873474, loss=1.3702102899551392
test: epoch 5, loss 1.5549947023391724, acc=0.3305555582046509, loss=1.5549947023391724
train: epoch 6, loss 1.2333000898361206, acc=0.4593333303928375, loss=1.2333000898361206
test: epoch 6, loss 1.5360203981399536, acc=0.3722222149372101, loss=1.5360203981399536
train: epoch 7, loss 1.1678136587142944, acc=0.4846111238002777, loss=1.1678136587142944
test: epoch 7, loss 1.4904996156692505, acc=0.3777777850627899, loss=1.4904996156692505
train: epoch 8, loss 1.1077033281326294, acc=0.5051666498184204, loss=1.1077033281326294
test: epoch 8, loss 1.4377034902572632, acc=0.38333332538604736, loss=1.4377034902572632
train: epoch 9, loss 1.069894790649414, acc=0.5225555300712585, loss=1.069894790649414
test: epoch 9, loss 1.6109524965286255, acc=0.3861111104488373, loss=1.6109524965286255
train: epoch 10, loss 1.0038928985595703, acc=0.5394444465637207, loss=1.0038928985595703
test: epoch 10, loss 1.7374796867370605, acc=0.3861111104488373, loss=1.7374796867370605
train: epoch 11, loss 1.0140360593795776, acc=0.5325000286102295, loss=1.0140360593795776
test: epoch 11, loss 1.6038788557052612, acc=0.39444443583488464, loss=1.6038788557052612
train: epoch 12, loss 0.9693461656570435, acc=0.5491666793823242, loss=0.9693461656570435
test: epoch 12, loss 1.5253334045410156, acc=0.39444443583488464, loss=1.5253334045410156
train: epoch 13, loss 0.9636551737785339, acc=0.5519444346427917, loss=0.9636551737785339
test: epoch 13, loss 1.7550476789474487, acc=0.39444443583488464, loss=1.7550476789474487
train: epoch 14, loss 0.9072275161743164, acc=0.5693333148956299, loss=0.9072275161743164
test: epoch 14, loss 1.8069478273391724, acc=0.39444443583488464, loss=1.8069478273391724
train: epoch 15, loss 0.9328140616416931, acc=0.558222234249115, loss=0.9328140616416931
test: epoch 15, loss 1.7567323446273804, acc=0.4027777910232544, loss=1.7567323446273804
train: epoch 16, loss 0.9208805561065674, acc=0.5641666650772095, loss=0.9208805561065674
test: epoch 16, loss 1.607659101486206, acc=0.4027777910232544, loss=1.607659101486206
train: epoch 17, loss 0.8730615377426147, acc=0.5744444727897644, loss=0.8730615377426147
test: epoch 17, loss 1.6585266590118408, acc=0.4055555462837219, loss=1.6585266590118408
train: epoch 18, loss 0.8622187972068787, acc=0.5746111273765564, loss=0.8622187972068787
test: epoch 18, loss 1.7083646059036255, acc=0.41111111640930176, loss=1.7083646059036255
train: epoch 19, loss 0.8818023204803467, acc=0.574833333492279, loss=0.8818023204803467
test: epoch 19, loss 1.5188565254211426, acc=0.4055555462837219, loss=1.5188565254211426
train: epoch 20, loss 0.8297693133354187, acc=0.5902222394943237, loss=0.8297693133354187
test: epoch 20, loss 1.6956156492233276, acc=0.4027777910232544, loss=1.6956156492233276
train: epoch 21, loss 0.8424099087715149, acc=0.5960555672645569, loss=0.8424099087715149
test: epoch 21, loss 1.7736836671829224, acc=0.4138889014720917, loss=1.7736836671829224
train: epoch 22, loss 0.8249785304069519, acc=0.5975555777549744, loss=0.8249785304069519
test: epoch 22, loss 1.8259162902832031, acc=0.4138889014720917, loss=1.8259162902832031
train: epoch 23, loss 0.8219449520111084, acc=0.5953888893127441, loss=0.8219449520111084
test: epoch 23, loss 1.7156872749328613, acc=0.41111111640930176, loss=1.7156872749328613
train: epoch 24, loss 0.8104055523872375, acc=0.5967222452163696, loss=0.8104055523872375
test: epoch 24, loss 1.7212128639221191, acc=0.38055557012557983, loss=1.7212128639221191
train: epoch 25, loss 0.8418839573860168, acc=0.5836111307144165, loss=0.8418839573860168
test: epoch 25, loss 1.5886555910110474, acc=0.43611112236976624, loss=1.5886555910110474
train: epoch 26, loss 0.8172937631607056, acc=0.5864999890327454, loss=0.8172937631607056
test: epoch 26, loss 1.4265028238296509, acc=0.47777777910232544, loss=1.4265028238296509
train: epoch 27, loss 0.7711479067802429, acc=0.6073889136314392, loss=0.7711479067802429
test: epoch 27, loss 1.4903550148010254, acc=0.49444442987442017, loss=1.4903550148010254
train: epoch 28, loss 0.7390971183776855, acc=0.6242777705192566, loss=0.7390971183776855
test: epoch 28, loss 1.2887763977050781, acc=0.5138888955116272, loss=1.2887763977050781
train: epoch 29, loss 0.711458146572113, acc=0.6507777571678162, loss=0.711458146572113
test: epoch 29, loss 1.1074861288070679, acc=0.5694444179534912, loss=1.1074861288070679
train: epoch 30, loss 0.6687425971031189, acc=0.6622222065925598, loss=0.6687425971031189
test: epoch 30, loss 1.07079017162323, acc=0.5805555582046509, loss=1.07079017162323
train: epoch 31, loss 0.6798245310783386, acc=0.656499981880188, loss=0.6798245310783386
test: epoch 31, loss 1.1153870820999146, acc=0.574999988079071, loss=1.1153870820999146
train: epoch 32, loss 0.6736026406288147, acc=0.6598333120346069, loss=0.6736026406288147
test: epoch 32, loss 0.9748123288154602, acc=0.5805555582046509, loss=0.9748123288154602
train: epoch 33, loss 0.6831942200660706, acc=0.6579444408416748, loss=0.6831942200660706
test: epoch 33, loss 1.0255582332611084, acc=0.5861111283302307, loss=1.0255582332611084
train: epoch 34, loss 0.6497318148612976, acc=0.6641666889190674, loss=0.6497318148612976
test: epoch 34, loss 1.1657201051712036, acc=0.574999988079071, loss=1.1657201051712036
train: epoch 35, loss 0.6551584005355835, acc=0.6665555834770203, loss=0.6551584005355835
test: epoch 35, loss 1.132371187210083, acc=0.5861111283302307, loss=1.132371187210083
train: epoch 36, loss 0.6315562129020691, acc=0.6705555319786072, loss=0.6315562129020691
test: epoch 36, loss 1.170481562614441, acc=0.5916666388511658, loss=1.170481562614441
train: epoch 37, loss 0.6598516702651978, acc=0.6666666865348816, loss=0.6598516702651978
test: epoch 37, loss 0.9277499914169312, acc=0.5944444537162781, loss=0.9277499914169312
train: epoch 38, loss 0.6758698225021362, acc=0.6582777500152588, loss=0.6758698225021362
test: epoch 38, loss 1.08961021900177, acc=0.5638889074325562, loss=1.08961021900177
train: epoch 39, loss 0.6681955456733704, acc=0.6596111059188843, loss=0.6681955456733704
test: epoch 39, loss 1.1694916486740112, acc=0.6083333492279053, loss=1.1694916486740112
train: epoch 40, loss 0.6624809503555298, acc=0.6552777886390686, loss=0.6624809503555298
test: epoch 40, loss 1.077805757522583, acc=0.6305555701255798, loss=1.077805757522583
train: epoch 41, loss 0.66208815574646, acc=0.6596666574478149, loss=0.66208815574646
test: epoch 41, loss 1.0855777263641357, acc=0.6138888597488403, loss=1.0855777263641357
train: epoch 42, loss 0.6206896901130676, acc=0.6821110844612122, loss=0.6206896901130676
test: epoch 42, loss 0.8399065136909485, acc=0.6583333611488342, loss=0.8399065136909485
train: epoch 43, loss 0.6017541289329529, acc=0.7048888802528381, loss=0.6017541289329529
test: epoch 43, loss 0.6821783185005188, acc=0.6777777671813965, loss=0.6821783185005188
train: epoch 44, loss 0.576587438583374, acc=0.714388906955719, loss=0.576587438583374
test: epoch 44, loss 0.7110664248466492, acc=0.6805555820465088, loss=0.7110664248466492
train: epoch 45, loss 0.5625559687614441, acc=0.7155555486679077, loss=0.5625559687614441
test: epoch 45, loss 0.6503110527992249, acc=0.6722221970558167, loss=0.6503110527992249
train: epoch 46, loss 0.587546169757843, acc=0.7097777724266052, loss=0.587546169757843
test: epoch 46, loss 0.7945502400398254, acc=0.675000011920929, loss=0.7945502400398254
train: epoch 47, loss 0.5694192051887512, acc=0.7127777934074402, loss=0.5694192051887512
test: epoch 47, loss 0.7830093502998352, acc=0.6777777671813965, loss=0.7830093502998352
train: epoch 48, loss 0.5677978992462158, acc=0.7116666436195374, loss=0.5677978992462158
test: epoch 48, loss 0.5244068503379822, acc=0.7222222089767456, loss=0.5244068503379822
train: epoch 49, loss 0.5765873789787292, acc=0.71061110496521, loss=0.5765873789787292
test: epoch 49, loss 0.6837286353111267, acc=0.6777777671813965, loss=0.6837286353111267
train: epoch 50, loss 0.5897810459136963, acc=0.7070555686950684, loss=0.5897810459136963
test: epoch 50, loss 0.6559821963310242, acc=0.6944444179534912, loss=0.6559821963310242
train: epoch 51, loss 0.5341627597808838, acc=0.7210000157356262, loss=0.5341627597808838
test: epoch 51, loss 0.5126655697822571, acc=0.7250000238418579, loss=0.5126655697822571
train: epoch 52, loss 0.514617919921875, acc=0.7249444723129272, loss=0.514617919921875
test: epoch 52, loss 0.5128705501556396, acc=0.7250000238418579, loss=0.5128705501556396
train: epoch 53, loss 0.5162553191184998, acc=0.7245555520057678, loss=0.5162553191184998
test: epoch 53, loss 0.512342095375061, acc=0.7250000238418579, loss=0.512342095375061
train: epoch 54, loss 0.5518205761909485, acc=0.7205555438995361, loss=0.5518205761909485
test: epoch 54, loss 0.5566683411598206, acc=0.7138888835906982, loss=0.5566683411598206
train: epoch 55, loss 0.5890844464302063, acc=0.7112777829170227, loss=0.5890844464302063
test: epoch 55, loss 0.531654953956604, acc=0.7222222089767456, loss=0.531654953956604
train: epoch 56, loss 0.5405565500259399, acc=0.7202222347259521, loss=0.5405565500259399
test: epoch 56, loss 0.5309736728668213, acc=0.7222222089767456, loss=0.5309736728668213
train: epoch 57, loss 0.5343315005302429, acc=0.7217222452163696, loss=0.5343315005302429
test: epoch 57, loss 0.534995973110199, acc=0.7194444537162781, loss=0.534995973110199
train: epoch 58, loss 0.5528808236122131, acc=0.7172777652740479, loss=0.5528808236122131
test: epoch 58, loss 0.5679049491882324, acc=0.7138888835906982, loss=0.5679049491882324
train: epoch 59, loss 0.5683128833770752, acc=0.7139444351196289, loss=0.5683128833770752
test: epoch 59, loss 0.5956457257270813, acc=0.7166666388511658, loss=0.5956457257270813
train: epoch 60, loss 0.5694129467010498, acc=0.7118889093399048, loss=0.5694129467010498
test: epoch 60, loss 0.5524327158927917, acc=0.7138888835906982, loss=0.5524327158927917
train: epoch 61, loss 0.555543065071106, acc=0.7132777571678162, loss=0.555543065071106
test: epoch 61, loss 0.5985801219940186, acc=0.7083333134651184, loss=0.5985801219940186
train: epoch 62, loss 0.5910248160362244, acc=0.7051110863685608, loss=0.5910248160362244
test: epoch 62, loss 0.5453650951385498, acc=0.7166666388511658, loss=0.5453650951385498
train: epoch 63, loss 0.5611287951469421, acc=0.7021111249923706, loss=0.5611287951469421
test: epoch 63, loss 0.5405446290969849, acc=0.7138888835906982, loss=0.5405446290969849
train: epoch 64, loss 0.5430690050125122, acc=0.7057222127914429, loss=0.5430690050125122
test: epoch 64, loss 0.5403010845184326, acc=0.7138888835906982, loss=0.5403010845184326
train: epoch 65, loss 0.5438936948776245, acc=0.7053333520889282, loss=0.5438936948776245
test: epoch 65, loss 0.5402825474739075, acc=0.7138888835906982, loss=0.5402825474739075
train: epoch 66, loss 0.542232096195221, acc=0.7056111097335815, loss=0.542232096195221
test: epoch 66, loss 0.5402284264564514, acc=0.7138888835906982, loss=0.5402284264564514
train: epoch 67, loss 0.5420807003974915, acc=0.7056111097335815, loss=0.5420807003974915
test: epoch 67, loss 0.5402050614356995, acc=0.7138888835906982, loss=0.5402050614356995
train: epoch 68, loss 0.6212108135223389, acc=0.694611132144928, loss=0.6212108135223389
test: epoch 68, loss 0.7681930065155029, acc=0.6638888716697693, loss=0.7681930065155029
train: epoch 69, loss 0.6137891411781311, acc=0.6952221989631653, loss=0.6137891411781311
test: epoch 69, loss 0.5794194936752319, acc=0.7055555582046509, loss=0.5794194936752319
train: epoch 70, loss 0.5492247939109802, acc=0.7095555663108826, loss=0.5492247939109802
test: epoch 70, loss 0.5404847860336304, acc=0.7138888835906982, loss=0.5404847860336304
train: epoch 71, loss 0.5385659337043762, acc=0.714888870716095, loss=0.5385659337043762
test: epoch 71, loss 0.5305669903755188, acc=0.7166666388511658, loss=0.5305669903755188
train: epoch 72, loss 0.560987114906311, acc=0.7135000228881836, loss=0.560987114906311
test: epoch 72, loss 0.5366316437721252, acc=0.7166666388511658, loss=0.5366316437721252
train: epoch 73, loss 0.5486618876457214, acc=0.7166110873222351, loss=0.5486618876457214
test: epoch 73, loss 0.5448907613754272, acc=0.7166666388511658, loss=0.5448907613754272
train: epoch 74, loss 0.5562431216239929, acc=0.7149444222450256, loss=0.5562431216239929
test: epoch 74, loss 0.5583491325378418, acc=0.7166666388511658, loss=0.5583491325378418
train: epoch 75, loss 0.5549992322921753, acc=0.7159444689750671, loss=0.5549992322921753
test: epoch 75, loss 0.5357651710510254, acc=0.7194444537162781, loss=0.5357651710510254
train: epoch 76, loss 0.5358946919441223, acc=0.7194444537162781, loss=0.5358946919441223
test: epoch 76, loss 0.5342096090316772, acc=0.7194444537162781, loss=0.5342096090316772
train: epoch 77, loss 0.5355477333068848, acc=0.7194444537162781, loss=0.5355477333068848
test: epoch 77, loss 0.5341744422912598, acc=0.7194444537162781, loss=0.5341744422912598
train: epoch 78, loss 0.5354458093643188, acc=0.7194444537162781, loss=0.5354458093643188
test: epoch 78, loss 0.534162700176239, acc=0.7194444537162781, loss=0.534162700176239
train: epoch 79, loss 0.669941782951355, acc=0.6918888688087463, loss=0.669941782951355
test: epoch 79, loss 0.5872737765312195, acc=0.7083333134651184, loss=0.5872737765312195
train: epoch 80, loss 0.5564330220222473, acc=0.7110555768013, loss=0.5564330220222473
test: epoch 80, loss 0.5415623188018799, acc=0.7194444537162781, loss=0.5415623188018799
train: epoch 81, loss 0.5422746539115906, acc=0.7137777805328369, loss=0.5422746539115906
test: epoch 81, loss 0.5302666425704956, acc=0.7222222089767456, loss=0.5302666425704956
train: epoch 82, loss 0.532806396484375, acc=0.7153333425521851, loss=0.532806396484375
test: epoch 82, loss 0.5308331847190857, acc=0.7222222089767456, loss=0.5308331847190857
train: epoch 83, loss 0.6382500529289246, acc=0.6943333148956299, loss=0.6382500529289246
test: epoch 83, loss 0.5824467539787292, acc=0.7055555582046509, loss=0.5824467539787292
train: epoch 84, loss 0.5739793181419373, acc=0.7042222023010254, loss=0.5739793181419373
test: epoch 84, loss 0.5603440999984741, acc=0.7083333134651184, loss=0.5603440999984741
train: epoch 85, loss 0.59334796667099, acc=0.7003333568572998, loss=0.59334796667099
test: epoch 85, loss 0.5764632225036621, acc=0.7083333134651184, loss=0.5764632225036621
train: epoch 86, loss 0.5402597784996033, acc=0.7132777571678162, loss=0.5402597784996033
test: epoch 86, loss 0.534574031829834, acc=0.7166666388511658, loss=0.534574031829834
train: epoch 87, loss 0.5280380249023438, acc=0.7203888893127441, loss=0.5280380249023438
test: epoch 87, loss 0.5310930013656616, acc=0.7194444537162781, loss=0.5310930013656616
train: epoch 88, loss 0.6557340025901794, acc=0.6887221932411194, loss=0.6557340025901794
test: epoch 88, loss 0.6124250888824463, acc=0.6972222328186035, loss=0.6124250888824463
train: epoch 89, loss 0.5879343748092651, acc=0.6953333616256714, loss=0.5879343748092651
test: epoch 89, loss 0.5786659121513367, acc=0.7055555582046509, loss=0.5786659121513367
train: epoch 90, loss 0.5810568928718567, acc=0.6928333044052124, loss=0.5810568928718567
test: epoch 90, loss 0.5785303711891174, acc=0.7055555582046509, loss=0.5785303711891174
train: epoch 91, loss 0.5854765176773071, acc=0.6913333535194397, loss=0.5854765176773071
test: epoch 91, loss 0.57647705078125, acc=0.7055555582046509, loss=0.57647705078125
train: epoch 92, loss 0.6483058929443359, acc=0.7004444599151611, loss=0.6483058929443359
test: epoch 92, loss 0.5670974254608154, acc=0.7138888835906982, loss=0.5670974254608154
train: epoch 93, loss 0.5687142014503479, acc=0.7176111340522766, loss=0.5687142014503479
test: epoch 93, loss 0.5671798586845398, acc=0.7194444537162781, loss=0.5671798586845398
train: epoch 94, loss 0.5639102458953857, acc=0.7196111083030701, loss=0.5639102458953857
test: epoch 94, loss 0.558941125869751, acc=0.7194444537162781, loss=0.558941125869751
train: epoch 95, loss 0.560989499092102, acc=0.7194444537162781, loss=0.560989499092102
test: epoch 95, loss 0.5588476061820984, acc=0.7194444537162781, loss=0.5588476061820984
train: epoch 96, loss 0.5587611794471741, acc=0.7194444537162781, loss=0.5587611794471741
test: epoch 96, loss 0.5513744950294495, acc=0.7194444537162781, loss=0.5513744950294495
train: epoch 97, loss 0.5823255777359009, acc=0.7167778015136719, loss=0.5823255777359009
test: epoch 97, loss 0.5831946730613708, acc=0.7055555582046509, loss=0.5831946730613708
train: epoch 98, loss 0.5879415273666382, acc=0.7100555300712585, loss=0.5879415273666382
test: epoch 98, loss 0.550140380859375, acc=0.7166666388511658, loss=0.550140380859375
train: epoch 99, loss 0.5502881407737732, acc=0.7166666388511658, loss=0.5502881407737732
test: epoch 99, loss 0.5474477410316467, acc=0.7166666388511658, loss=0.5474477410316467
train: epoch 100, loss 0.5505984425544739, acc=0.7164444327354431, loss=0.5505984425544739
test: epoch 100, loss 0.5438814759254456, acc=0.7166666388511658, loss=0.5438814759254456
train: epoch 101, loss 0.5764579772949219, acc=0.707611083984375, loss=0.5764579772949219
test: epoch 101, loss 0.7617705464363098, acc=0.6833333373069763, loss=0.7617705464363098
train: epoch 102, loss 0.7132915258407593, acc=0.6713888645172119, loss=0.7132915258407593
test: epoch 102, loss 0.6870387196540833, acc=0.6777777671813965, loss=0.6870387196540833
train: epoch 103, loss 0.6917377710342407, acc=0.676277756690979, loss=0.6917377710342407
test: epoch 103, loss 0.6566438674926758, acc=0.6861110925674438, loss=0.6566438674926758
train: epoch 104, loss 0.6571153998374939, acc=0.6827222108840942, loss=0.6571153998374939
test: epoch 104, loss 0.6504707336425781, acc=0.6888889074325562, loss=0.6504707336425781
train: epoch 105, loss 0.634414792060852, acc=0.6930000185966492, loss=0.634414792060852
test: epoch 105, loss 0.6275429129600525, acc=0.6944444179534912, loss=0.6275429129600525
train: epoch 106, loss 0.6494637727737427, acc=0.6926666498184204, loss=0.6494637727737427
test: epoch 106, loss 0.562278687953949, acc=0.7083333134651184, loss=0.562278687953949
train: epoch 107, loss 0.563964307308197, acc=0.7048888802528381, loss=0.563964307308197
test: epoch 107, loss 0.5608241558074951, acc=0.7083333134651184, loss=0.5608241558074951
train: epoch 108, loss 0.5626716017723083, acc=0.7061111330986023, loss=0.5626716017723083
test: epoch 108, loss 0.5606980323791504, acc=0.7083333134651184, loss=0.5606980323791504
train: epoch 109, loss 0.5612279176712036, acc=0.7053889036178589, loss=0.5612279176712036
test: epoch 109, loss 0.5511215925216675, acc=0.7111111283302307, loss=0.5511215925216675
train: epoch 110, loss 0.552977442741394, acc=0.7076666951179504, loss=0.552977442741394
test: epoch 110, loss 0.5510426759719849, acc=0.7111111283302307, loss=0.5510426759719849
train: epoch 111, loss 0.5533965229988098, acc=0.7077222466468811, loss=0.5533965229988098
test: epoch 111, loss 0.5510306358337402, acc=0.7111111283302307, loss=0.5510306358337402
train: epoch 112, loss 0.7013133764266968, acc=0.6840555667877197, loss=0.7013133764266968
test: epoch 112, loss 0.6293676495552063, acc=0.6916666626930237, loss=0.6293676495552063
train: epoch 113, loss 0.6219086050987244, acc=0.6915000081062317, loss=0.6219086050987244
test: epoch 113, loss 0.6165944337844849, acc=0.6972222328186035, loss=0.6165944337844849
train: epoch 114, loss 0.6186745762825012, acc=0.691277801990509, loss=0.6186745762825012
test: epoch 114, loss 0.6098583340644836, acc=0.6972222328186035, loss=0.6098583340644836
train: epoch 115, loss 0.7794565558433533, acc=0.6486666798591614, loss=0.7794565558433533
test: epoch 115, loss 0.716091513633728, acc=0.6527777910232544, loss=0.716091513633728
train: epoch 116, loss 0.6854711174964905, acc=0.663777768611908, loss=0.6854711174964905
test: epoch 116, loss 0.6555148363113403, acc=0.6722221970558167, loss=0.6555148363113403
train: epoch 117, loss 0.6604548096656799, acc=0.6722221970558167, loss=0.6604548096656799
test: epoch 117, loss 0.6549694538116455, acc=0.6722221970558167, loss=0.6549694538116455
train: epoch 118, loss 0.659023642539978, acc=0.6722221970558167, loss=0.659023642539978
test: epoch 118, loss 0.6553764343261719, acc=0.6722221970558167, loss=0.6553764343261719
train: epoch 119, loss 0.6587034463882446, acc=0.6722221970558167, loss=0.6587034463882446
test: epoch 119, loss 0.6553142666816711, acc=0.6722221970558167, loss=0.6553142666816711
train: epoch 120, loss 0.6584843397140503, acc=0.6722221970558167, loss=0.6584843397140503
test: epoch 120, loss 0.6552648544311523, acc=0.6722221970558167, loss=0.6552648544311523
train: epoch 121, loss 0.6583535671234131, acc=0.6722221970558167, loss=0.6583535671234131
test: epoch 121, loss 0.6552573442459106, acc=0.6722221970558167, loss=0.6552573442459106
train: epoch 122, loss 0.6582457423210144, acc=0.6722221970558167, loss=0.6582457423210144
test: epoch 122, loss 0.6552190184593201, acc=0.6722221970558167, loss=0.6552190184593201
train: epoch 123, loss 0.6581143140792847, acc=0.6722221970558167, loss=0.6581143140792847
test: epoch 123, loss 0.655194878578186, acc=0.6722221970558167, loss=0.655194878578186
train: epoch 124, loss 0.8119345307350159, acc=0.6358333230018616, loss=0.8119345307350159
test: epoch 124, loss 0.8101527094841003, acc=0.6194444298744202, loss=0.8101527094841003
train: epoch 125, loss 0.7733062505722046, acc=0.6209999918937683, loss=0.7733062505722046
test: epoch 125, loss 0.7514262795448303, acc=0.6305555701255798, loss=0.7514262795448303
train: epoch 126, loss 0.8943870067596436, acc=0.5965555310249329, loss=0.8943870067596436
test: epoch 126, loss 1.0483754873275757, acc=0.5555555820465088, loss=1.0483754873275757
train: epoch 127, loss 1.0422117710113525, acc=0.5554999709129333, loss=1.0422117710113525
test: epoch 127, loss 1.0261849164962769, acc=0.5611110925674438, loss=1.0261849164962769
train: epoch 128, loss 1.0927006006240845, acc=0.5518333315849304, loss=1.0927006006240845
test: epoch 128, loss 1.0233988761901855, acc=0.5638889074325562, loss=1.0233988761901855
train: epoch 129, loss 0.9954147934913635, acc=0.5686110854148865, loss=0.9954147934913635
test: epoch 129, loss 0.982273280620575, acc=0.5777778029441833, loss=0.982273280620575
train: epoch 130, loss 0.9871624708175659, acc=0.5739444494247437, loss=0.9871624708175659
test: epoch 130, loss 0.9883555173873901, acc=0.574999988079071, loss=0.9883555173873901
train: epoch 131, loss 0.9822986125946045, acc=0.5805555582046509, loss=0.9822986125946045
test: epoch 131, loss 0.9686115980148315, acc=0.5805555582046509, loss=0.9686115980148315
train: epoch 132, loss 1.0306514501571655, acc=0.5626111030578613, loss=1.0306514501571655
test: epoch 132, loss 0.9741951823234558, acc=0.5694444179534912, loss=0.9741951823234558
train: epoch 133, loss 0.9718519449234009, acc=0.5721666812896729, loss=0.9718519449234009
test: epoch 133, loss 0.918164849281311, acc=0.5833333134651184, loss=0.918164849281311
train: epoch 134, loss 0.9328295588493347, acc=0.574388861656189, loss=0.9328295588493347
test: epoch 134, loss 0.927814781665802, acc=0.5777778029441833, loss=0.927814781665802
train: epoch 135, loss 0.9268798232078552, acc=0.5729444622993469, loss=0.9268798232078552
test: epoch 135, loss 0.9205753803253174, acc=0.5777778029441833, loss=0.9205753803253174
train: epoch 136, loss 0.9253520965576172, acc=0.5732777714729309, loss=0.9253520965576172
test: epoch 136, loss 0.9203093647956848, acc=0.5777778029441833, loss=0.9203093647956848
train: epoch 137, loss 0.995244562625885, acc=0.5502222180366516, loss=0.995244562625885
test: epoch 137, loss 0.9892101287841797, acc=0.5555555820465088, loss=0.9892101287841797
train: epoch 138, loss 0.995836615562439, acc=0.5307222008705139, loss=0.995836615562439
test: epoch 138, loss 0.9853866100311279, acc=0.5583333373069763, loss=0.9853866100311279
train: epoch 139, loss 1.0325573682785034, acc=0.559499979019165, loss=1.0325573682785034
test: epoch 139, loss 0.9514782428741455, acc=0.5888888835906982, loss=0.9514782428741455
train: epoch 140, loss 0.9509109258651733, acc=0.5862777829170227, loss=0.9509109258651733
test: epoch 140, loss 0.939132571220398, acc=0.5888888835906982, loss=0.939132571220398
train: epoch 141, loss 0.9438403844833374, acc=0.593833327293396, loss=0.9438403844833374
test: epoch 141, loss 0.9033262729644775, acc=0.6083333492279053, loss=0.9033262729644775
train: epoch 142, loss 0.8828902244567871, acc=0.6156111359596252, loss=0.8828902244567871
test: epoch 142, loss 0.865166425704956, acc=0.6194444298744202, loss=0.865166425704956
train: epoch 143, loss 0.8696115612983704, acc=0.6192777752876282, loss=0.8696115612983704
test: epoch 143, loss 0.8643121123313904, acc=0.6194444298744202, loss=0.8643121123313904
train: epoch 144, loss 0.8723049163818359, acc=0.6194444298744202, loss=0.8723049163818359
test: epoch 144, loss 0.8219515085220337, acc=0.6416666507720947, loss=0.8219515085220337
train: epoch 145, loss 0.8666676878929138, acc=0.6393333077430725, loss=0.8666676878929138
test: epoch 145, loss 0.8207586407661438, acc=0.644444465637207, loss=0.8207586407661438
train: epoch 146, loss 0.9398886561393738, acc=0.6115555763244629, loss=0.9398886561393738
test: epoch 146, loss 0.901249885559082, acc=0.6194444298744202, loss=0.901249885559082
train: epoch 147, loss 0.8630790114402771, acc=0.6344444155693054, loss=0.8630790114402771
test: epoch 147, loss 0.8402338027954102, acc=0.6388888955116272, loss=0.8402338027954102
train: epoch 148, loss 0.8430398106575012, acc=0.6387777924537659, loss=0.8430398106575012
test: epoch 148, loss 0.8360986113548279, acc=0.6388888955116272, loss=0.8360986113548279
train: epoch 149, loss 0.894952654838562, acc=0.6247222423553467, loss=0.894952654838562
test: epoch 149, loss 0.8709625601768494, acc=0.6222222447395325, loss=0.8709625601768494
train: epoch 150, loss 0.8742356896400452, acc=0.6222222447395325, loss=0.8742356896400452
test: epoch 150, loss 0.8658589124679565, acc=0.6222222447395325, loss=0.8658589124679565
