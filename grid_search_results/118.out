# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=1", "--temp_decay=0.995", "--one_hot=false", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=254931997, receiver_embed_dim=128, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.016458034515381, acc=0.07844444364309311, loss=3.016458034515381
test: epoch 1, loss 2.6059253215789795, acc=0.10833333432674408, loss=2.6059253215789795
train: epoch 2, loss 2.0463449954986572, acc=0.22033333778381348, loss=2.0463449954986572
test: epoch 2, loss 2.358041286468506, acc=0.1944444477558136, loss=2.358041286468506
train: epoch 3, loss 1.5769195556640625, acc=0.3522777855396271, loss=1.5769195556640625
test: epoch 3, loss 1.8565680980682373, acc=0.2666666805744171, loss=1.8565680980682373
train: epoch 4, loss 1.3257426023483276, acc=0.44172221422195435, loss=1.3257426023483276
test: epoch 4, loss 1.580785870552063, acc=0.31111112236976624, loss=1.580785870552063
train: epoch 5, loss 1.1637071371078491, acc=0.49933332204818726, loss=1.1637071371078491
test: epoch 5, loss 1.685136318206787, acc=0.3222222328186035, loss=1.685136318206787
train: epoch 6, loss 1.04279363155365, acc=0.5509999990463257, loss=1.04279363155365
test: epoch 6, loss 1.855884313583374, acc=0.33888888359069824, loss=1.855884313583374
train: epoch 7, loss 0.9471647143363953, acc=0.5751110911369324, loss=0.9471647143363953
test: epoch 7, loss 1.6621495485305786, acc=0.3499999940395355, loss=1.6621495485305786
train: epoch 8, loss 0.8896313905715942, acc=0.5966110825538635, loss=0.8896313905715942
test: epoch 8, loss 1.4303981065750122, acc=0.3916666805744171, loss=1.4303981065750122
train: epoch 9, loss 0.8412026166915894, acc=0.6230555772781372, loss=0.8412026166915894
test: epoch 9, loss 1.3530336618423462, acc=0.3916666805744171, loss=1.3530336618423462
train: epoch 10, loss 0.8073669672012329, acc=0.6397777795791626, loss=0.8073669672012329
test: epoch 10, loss 1.591783046722412, acc=0.38333332538604736, loss=1.591783046722412
train: epoch 11, loss 0.7447855472564697, acc=0.668666660785675, loss=0.7447855472564697
test: epoch 11, loss 1.5742194652557373, acc=0.375, loss=1.5742194652557373
train: epoch 12, loss 0.714352011680603, acc=0.6852777600288391, loss=0.714352011680603
test: epoch 12, loss 1.5726488828659058, acc=0.42222222685813904, loss=1.5726488828659058
train: epoch 13, loss 0.6767744421958923, acc=0.7053333520889282, loss=0.6767744421958923
test: epoch 13, loss 1.5262473821640015, acc=0.42500001192092896, loss=1.5262473821640015
train: epoch 14, loss 0.627834141254425, acc=0.7281110882759094, loss=0.627834141254425
test: epoch 14, loss 1.5991157293319702, acc=0.4472222328186035, loss=1.5991157293319702
train: epoch 15, loss 0.6287766695022583, acc=0.7280555367469788, loss=0.6287766695022583
test: epoch 15, loss 1.3319436311721802, acc=0.4583333432674408, loss=1.3319436311721802
train: epoch 16, loss 0.6088901162147522, acc=0.7357222437858582, loss=0.6088901162147522
test: epoch 16, loss 1.49884831905365, acc=0.47777777910232544, loss=1.49884831905365
train: epoch 17, loss 0.5998809337615967, acc=0.7452222108840942, loss=0.5998809337615967
test: epoch 17, loss 1.318554401397705, acc=0.46666666865348816, loss=1.318554401397705
train: epoch 18, loss 0.5875212550163269, acc=0.7471110820770264, loss=0.5875212550163269
test: epoch 18, loss 1.510064721107483, acc=0.4722222089767456, loss=1.510064721107483
train: epoch 19, loss 0.5891701579093933, acc=0.7428333163261414, loss=0.5891701579093933
test: epoch 19, loss 1.4245916604995728, acc=0.46666666865348816, loss=1.4245916604995728
train: epoch 20, loss 0.5745271444320679, acc=0.7536110877990723, loss=0.5745271444320679
test: epoch 20, loss 1.288077473640442, acc=0.5111111402511597, loss=1.288077473640442
train: epoch 21, loss 0.565971314907074, acc=0.7540000081062317, loss=0.565971314907074
test: epoch 21, loss 1.468975305557251, acc=0.48055556416511536, loss=1.468975305557251
train: epoch 22, loss 0.5885156393051147, acc=0.7390555739402771, loss=0.5885156393051147
test: epoch 22, loss 1.3488922119140625, acc=0.49444442987442017, loss=1.3488922119140625
train: epoch 23, loss 0.5613698959350586, acc=0.7486110925674438, loss=0.5613698959350586
test: epoch 23, loss 1.4138396978378296, acc=0.5027777552604675, loss=1.4138396978378296
train: epoch 24, loss 0.5629374384880066, acc=0.7507777810096741, loss=0.5629374384880066
test: epoch 24, loss 1.2678558826446533, acc=0.5, loss=1.2678558826446533
train: epoch 25, loss 0.5520910024642944, acc=0.7512778043746948, loss=0.5520910024642944
test: epoch 25, loss 1.3839110136032104, acc=0.4888888895511627, loss=1.3839110136032104
train: epoch 26, loss 0.5551538467407227, acc=0.7454444169998169, loss=0.5551538467407227
test: epoch 26, loss 1.2422746419906616, acc=0.5416666865348816, loss=1.2422746419906616
train: epoch 27, loss 0.578468918800354, acc=0.7424444556236267, loss=0.578468918800354
test: epoch 27, loss 1.142831563949585, acc=0.5305555462837219, loss=1.142831563949585
train: epoch 28, loss 0.5566063523292542, acc=0.7468888759613037, loss=0.5566063523292542
test: epoch 28, loss 1.2170181274414062, acc=0.5333333611488342, loss=1.2170181274414062
train: epoch 29, loss 0.5525439381599426, acc=0.7465000152587891, loss=0.5525439381599426
test: epoch 29, loss 1.1988167762756348, acc=0.5416666865348816, loss=1.1988167762756348
train: epoch 30, loss 0.5424579381942749, acc=0.7506666779518127, loss=0.5424579381942749
test: epoch 30, loss 1.199192762374878, acc=0.5361111164093018, loss=1.199192762374878
train: epoch 31, loss 0.549933135509491, acc=0.7476111054420471, loss=0.549933135509491
test: epoch 31, loss 1.2184938192367554, acc=0.5388888716697693, loss=1.2184938192367554
train: epoch 32, loss 0.5330220460891724, acc=0.7538889050483704, loss=0.5330220460891724
test: epoch 32, loss 1.1992913484573364, acc=0.5388888716697693, loss=1.1992913484573364
train: epoch 33, loss 0.5255993008613586, acc=0.758055567741394, loss=0.5255993008613586
test: epoch 33, loss 1.2824677228927612, acc=0.5333333611488342, loss=1.2824677228927612
train: epoch 34, loss 0.5391680598258972, acc=0.7555000185966492, loss=0.5391680598258972
test: epoch 34, loss 1.3437484502792358, acc=0.5277777910232544, loss=1.3437484502792358
train: epoch 35, loss 0.5379623174667358, acc=0.7575555443763733, loss=0.5379623174667358
test: epoch 35, loss 1.1690171957015991, acc=0.5416666865348816, loss=1.1690171957015991
train: epoch 36, loss 0.5230053067207336, acc=0.7638333439826965, loss=0.5230053067207336
test: epoch 36, loss 1.3671314716339111, acc=0.5277777910232544, loss=1.3671314716339111
train: epoch 37, loss 0.5560891032218933, acc=0.7509999871253967, loss=0.5560891032218933
test: epoch 37, loss 1.2234916687011719, acc=0.5361111164093018, loss=1.2234916687011719
train: epoch 38, loss 0.5241020917892456, acc=0.7636111378669739, loss=0.5241020917892456
test: epoch 38, loss 1.154632806777954, acc=0.5361111164093018, loss=1.154632806777954
train: epoch 39, loss 0.5352590680122375, acc=0.7597222328186035, loss=0.5352590680122375
test: epoch 39, loss 1.135711669921875, acc=0.5388888716697693, loss=1.135711669921875
train: epoch 40, loss 0.5152046084403992, acc=0.7711666822433472, loss=0.5152046084403992
test: epoch 40, loss 1.1525344848632812, acc=0.5444444417953491, loss=1.1525344848632812
train: epoch 41, loss 0.5278866291046143, acc=0.7657777667045593, loss=0.5278866291046143
test: epoch 41, loss 1.1896051168441772, acc=0.550000011920929, loss=1.1896051168441772
train: epoch 42, loss 0.5131892561912537, acc=0.7728333473205566, loss=0.5131892561912537
test: epoch 42, loss 1.1917800903320312, acc=0.5472221970558167, loss=1.1917800903320312
train: epoch 43, loss 0.5358457565307617, acc=0.7611111402511597, loss=0.5358457565307617
test: epoch 43, loss 1.1561118364334106, acc=0.5444444417953491, loss=1.1561118364334106
train: epoch 44, loss 0.5207828283309937, acc=0.7705000042915344, loss=0.5207828283309937
test: epoch 44, loss 1.2147995233535767, acc=0.550000011920929, loss=1.2147995233535767
train: epoch 45, loss 0.5310297012329102, acc=0.7653889060020447, loss=0.5310297012329102
test: epoch 45, loss 1.2181836366653442, acc=0.5472221970558167, loss=1.2181836366653442
train: epoch 46, loss 0.515722930431366, acc=0.7703889012336731, loss=0.515722930431366
test: epoch 46, loss 1.2539690732955933, acc=0.550000011920929, loss=1.2539690732955933
train: epoch 47, loss 0.5065061450004578, acc=0.7753888964653015, loss=0.5065061450004578
test: epoch 47, loss 1.20863938331604, acc=0.550000011920929, loss=1.20863938331604
train: epoch 48, loss 0.5128214955329895, acc=0.7705000042915344, loss=0.5128214955329895
test: epoch 48, loss 1.3281121253967285, acc=0.5472221970558167, loss=1.3281121253967285
train: epoch 49, loss 0.5192722082138062, acc=0.7702222466468811, loss=0.5192722082138062
test: epoch 49, loss 1.2194424867630005, acc=0.5333333611488342, loss=1.2194424867630005
train: epoch 50, loss 0.5108473300933838, acc=0.7706111073493958, loss=0.5108473300933838
test: epoch 50, loss 1.233731985092163, acc=0.5416666865348816, loss=1.233731985092163
train: epoch 51, loss 0.5178136825561523, acc=0.7697222232818604, loss=0.5178136825561523
test: epoch 51, loss 1.3170703649520874, acc=0.5388888716697693, loss=1.3170703649520874
train: epoch 52, loss 0.5048007369041443, acc=0.7725555300712585, loss=0.5048007369041443
test: epoch 52, loss 1.0827069282531738, acc=0.550000011920929, loss=1.0827069282531738
train: epoch 53, loss 0.4870714545249939, acc=0.7804999947547913, loss=0.4870714545249939
test: epoch 53, loss 1.232214093208313, acc=0.5444444417953491, loss=1.232214093208313
train: epoch 54, loss 0.5001745223999023, acc=0.7776111364364624, loss=0.5001745223999023
test: epoch 54, loss 1.3011996746063232, acc=0.5444444417953491, loss=1.3011996746063232
train: epoch 55, loss 0.49034154415130615, acc=0.778166651725769, loss=0.49034154415130615
test: epoch 55, loss 1.2199288606643677, acc=0.5361111164093018, loss=1.2199288606643677
train: epoch 56, loss 0.49645358324050903, acc=0.777222216129303, loss=0.49645358324050903
test: epoch 56, loss 1.2919291257858276, acc=0.550000011920929, loss=1.2919291257858276
train: epoch 57, loss 0.5046798586845398, acc=0.7760000228881836, loss=0.5046798586845398
test: epoch 57, loss 1.1943358182907104, acc=0.550000011920929, loss=1.1943358182907104
train: epoch 58, loss 0.4946945011615753, acc=0.7815555334091187, loss=0.4946945011615753
test: epoch 58, loss 1.3664116859436035, acc=0.5444444417953491, loss=1.3664116859436035
train: epoch 59, loss 0.49103114008903503, acc=0.7778333425521851, loss=0.49103114008903503
test: epoch 59, loss 1.341243863105774, acc=0.5444444417953491, loss=1.341243863105774
train: epoch 60, loss 0.4950667917728424, acc=0.7787222266197205, loss=0.4950667917728424
test: epoch 60, loss 1.231534719467163, acc=0.5472221970558167, loss=1.231534719467163
train: epoch 61, loss 0.48982611298561096, acc=0.7831666469573975, loss=0.48982611298561096
test: epoch 61, loss 1.2766087055206299, acc=0.550000011920929, loss=1.2766087055206299
train: epoch 62, loss 0.5105852484703064, acc=0.773888885974884, loss=0.5105852484703064
test: epoch 62, loss 1.2937730550765991, acc=0.5444444417953491, loss=1.2937730550765991
train: epoch 63, loss 0.4995831251144409, acc=0.7770000100135803, loss=0.4995831251144409
test: epoch 63, loss 1.1254245042800903, acc=0.5444444417953491, loss=1.1254245042800903
train: epoch 64, loss 0.5002750158309937, acc=0.7752222418785095, loss=0.5002750158309937
test: epoch 64, loss 1.2589908838272095, acc=0.5444444417953491, loss=1.2589908838272095
train: epoch 65, loss 0.4940374195575714, acc=0.777388870716095, loss=0.4940374195575714
test: epoch 65, loss 1.1348780393600464, acc=0.5472221970558167, loss=1.1348780393600464
train: epoch 66, loss 0.49934858083724976, acc=0.7735555768013, loss=0.49934858083724976
test: epoch 66, loss 1.325313687324524, acc=0.5416666865348816, loss=1.325313687324524
train: epoch 67, loss 0.4739900827407837, acc=0.7839999794960022, loss=0.4739900827407837
test: epoch 67, loss 1.264784574508667, acc=0.550000011920929, loss=1.264784574508667
train: epoch 68, loss 0.4818324148654938, acc=0.7830555438995361, loss=0.4818324148654938
test: epoch 68, loss 1.2262662649154663, acc=0.550000011920929, loss=1.2262662649154663
train: epoch 69, loss 0.47581616044044495, acc=0.785277783870697, loss=0.47581616044044495
test: epoch 69, loss 1.256461501121521, acc=0.5472221970558167, loss=1.256461501121521
train: epoch 70, loss 0.4895350933074951, acc=0.7827777862548828, loss=0.4895350933074951
test: epoch 70, loss 1.2348666191101074, acc=0.550000011920929, loss=1.2348666191101074
train: epoch 71, loss 0.47926443815231323, acc=0.7870555520057678, loss=0.47926443815231323
test: epoch 71, loss 1.307054042816162, acc=0.5416666865348816, loss=1.307054042816162
train: epoch 72, loss 0.4705011546611786, acc=0.7870000004768372, loss=0.4705011546611786
test: epoch 72, loss 1.2872192859649658, acc=0.5444444417953491, loss=1.2872192859649658
train: epoch 73, loss 0.48330408334732056, acc=0.7835000157356262, loss=0.48330408334732056
test: epoch 73, loss 1.3276077508926392, acc=0.5444444417953491, loss=1.3276077508926392
train: epoch 74, loss 0.4688587486743927, acc=0.789222240447998, loss=0.4688587486743927
test: epoch 74, loss 1.256135106086731, acc=0.5472221970558167, loss=1.256135106086731
train: epoch 75, loss 0.4607601463794708, acc=0.792555570602417, loss=0.4607601463794708
test: epoch 75, loss 1.2345408201217651, acc=0.5472221970558167, loss=1.2345408201217651
train: epoch 76, loss 0.4695589244365692, acc=0.7883333563804626, loss=0.4695589244365692
test: epoch 76, loss 1.226370930671692, acc=0.5555555820465088, loss=1.226370930671692
train: epoch 77, loss 0.4700576663017273, acc=0.7908889055252075, loss=0.4700576663017273
test: epoch 77, loss 1.2217944860458374, acc=0.5472221970558167, loss=1.2217944860458374
train: epoch 78, loss 0.4557584524154663, acc=0.7945555448532104, loss=0.4557584524154663
test: epoch 78, loss 1.3625155687332153, acc=0.5555555820465088, loss=1.3625155687332153
train: epoch 79, loss 0.45717594027519226, acc=0.7941666841506958, loss=0.45717594027519226
test: epoch 79, loss 1.2646410465240479, acc=0.5527777671813965, loss=1.2646410465240479
train: epoch 80, loss 0.44782599806785583, acc=0.7950000166893005, loss=0.44782599806785583
test: epoch 80, loss 1.413547158241272, acc=0.5444444417953491, loss=1.413547158241272
train: epoch 81, loss 0.44219309091567993, acc=0.7972777485847473, loss=0.44219309091567993
test: epoch 81, loss 1.3324936628341675, acc=0.5472221970558167, loss=1.3324936628341675
train: epoch 82, loss 0.44671007990837097, acc=0.7943888902664185, loss=0.44671007990837097
test: epoch 82, loss 1.47630774974823, acc=0.5249999761581421, loss=1.47630774974823
train: epoch 83, loss 0.46238934993743896, acc=0.7918888926506042, loss=0.46238934993743896
test: epoch 83, loss 1.412128210067749, acc=0.5472221970558167, loss=1.412128210067749
train: epoch 84, loss 0.45355769991874695, acc=0.7909444570541382, loss=0.45355769991874695
test: epoch 84, loss 1.347633957862854, acc=0.5444444417953491, loss=1.347633957862854
train: epoch 85, loss 0.44275709986686707, acc=0.797166645526886, loss=0.44275709986686707
test: epoch 85, loss 1.3131436109542847, acc=0.5472221970558167, loss=1.3131436109542847
train: epoch 86, loss 0.44595223665237427, acc=0.7950555682182312, loss=0.44595223665237427
test: epoch 86, loss 1.3488355875015259, acc=0.550000011920929, loss=1.3488355875015259
train: epoch 87, loss 0.4251345694065094, acc=0.801111102104187, loss=0.4251345694065094
test: epoch 87, loss 1.314780354499817, acc=0.5722222328186035, loss=1.314780354499817
train: epoch 88, loss 0.4306962788105011, acc=0.7994999885559082, loss=0.4306962788105011
test: epoch 88, loss 1.2169479131698608, acc=0.5833333134651184, loss=1.2169479131698608
train: epoch 89, loss 0.4242560565471649, acc=0.8057222366333008, loss=0.4242560565471649
test: epoch 89, loss 1.1840236186981201, acc=0.5833333134651184, loss=1.1840236186981201
train: epoch 90, loss 0.414915531873703, acc=0.8068333268165588, loss=0.414915531873703
test: epoch 90, loss 1.1818565130233765, acc=0.5861111283302307, loss=1.1818565130233765
train: epoch 91, loss 0.41632911562919617, acc=0.80522221326828, loss=0.41632911562919617
test: epoch 91, loss 1.2409007549285889, acc=0.5916666388511658, loss=1.2409007549285889
train: epoch 92, loss 0.42867764830589294, acc=0.8021110892295837, loss=0.42867764830589294
test: epoch 92, loss 1.1185411214828491, acc=0.5916666388511658, loss=1.1185411214828491
train: epoch 93, loss 0.4182538688182831, acc=0.8050000071525574, loss=0.4182538688182831
test: epoch 93, loss 1.0521345138549805, acc=0.6027777791023254, loss=1.0521345138549805
train: epoch 94, loss 0.4176667630672455, acc=0.80394446849823, loss=0.4176667630672455
test: epoch 94, loss 1.2555086612701416, acc=0.605555534362793, loss=1.2555086612701416
train: epoch 95, loss 0.3895491361618042, acc=0.8127222061157227, loss=0.3895491361618042
test: epoch 95, loss 1.1411213874816895, acc=0.605555534362793, loss=1.1411213874816895
train: epoch 96, loss 0.3999383747577667, acc=0.8100000023841858, loss=0.3999383747577667
test: epoch 96, loss 1.0849494934082031, acc=0.6111111044883728, loss=1.0849494934082031
train: epoch 97, loss 0.40138933062553406, acc=0.8079444169998169, loss=0.40138933062553406
test: epoch 97, loss 1.0331882238388062, acc=0.6138888597488403, loss=1.0331882238388062
train: epoch 98, loss 0.39241382479667664, acc=0.809499979019165, loss=0.39241382479667664
test: epoch 98, loss 1.1248332262039185, acc=0.6305555701255798, loss=1.1248332262039185
train: epoch 99, loss 0.40955063700675964, acc=0.808722198009491, loss=0.40955063700675964
test: epoch 99, loss 1.1162810325622559, acc=0.6333333253860474, loss=1.1162810325622559
train: epoch 100, loss 0.39317500591278076, acc=0.8100555539131165, loss=0.39317500591278076
test: epoch 100, loss 0.9804659485816956, acc=0.6472222208976746, loss=0.9804659485816956
train: epoch 101, loss 0.3865615129470825, acc=0.8115000128746033, loss=0.3865615129470825
test: epoch 101, loss 0.9488279223442078, acc=0.6499999761581421, loss=0.9488279223442078
train: epoch 102, loss 0.38020122051239014, acc=0.8159444332122803, loss=0.38020122051239014
test: epoch 102, loss 1.0743789672851562, acc=0.644444465637207, loss=1.0743789672851562
train: epoch 103, loss 0.38646429777145386, acc=0.812333345413208, loss=0.38646429777145386
test: epoch 103, loss 1.0388790369033813, acc=0.6388888955116272, loss=1.0388790369033813
train: epoch 104, loss 0.37120091915130615, acc=0.8172777891159058, loss=0.37120091915130615
test: epoch 104, loss 0.9800699353218079, acc=0.6472222208976746, loss=0.9800699353218079
train: epoch 105, loss 0.3722725212574005, acc=0.8147222399711609, loss=0.3722725212574005
test: epoch 105, loss 0.8974694609642029, acc=0.6527777910232544, loss=0.8974694609642029
train: epoch 106, loss 0.3921636641025543, acc=0.8127222061157227, loss=0.3921636641025543
test: epoch 106, loss 0.9951699376106262, acc=0.6527777910232544, loss=0.9951699376106262
train: epoch 107, loss 0.38286468386650085, acc=0.8125, loss=0.38286468386650085
test: epoch 107, loss 0.9952426552772522, acc=0.6555555462837219, loss=0.9952426552772522
train: epoch 108, loss 0.3729126453399658, acc=0.8162222504615784, loss=0.3729126453399658
test: epoch 108, loss 0.9895420670509338, acc=0.644444465637207, loss=0.9895420670509338
train: epoch 109, loss 0.36838874220848083, acc=0.8163889050483704, loss=0.36838874220848083
test: epoch 109, loss 1.0005871057510376, acc=0.6555555462837219, loss=1.0005871057510376
train: epoch 110, loss 0.37244799733161926, acc=0.816777765750885, loss=0.37244799733161926
test: epoch 110, loss 0.9932300448417664, acc=0.6722221970558167, loss=0.9932300448417664
train: epoch 111, loss 0.36924275755882263, acc=0.8184999823570251, loss=0.36924275755882263
test: epoch 111, loss 0.8939471244812012, acc=0.675000011920929, loss=0.8939471244812012
train: epoch 112, loss 0.3666563630104065, acc=0.8221666812896729, loss=0.3666563630104065
test: epoch 112, loss 0.9023805856704712, acc=0.6805555820465088, loss=0.9023805856704712
train: epoch 113, loss 0.405124306678772, acc=0.8121111392974854, loss=0.405124306678772
test: epoch 113, loss 0.9938451647758484, acc=0.6416666507720947, loss=0.9938451647758484
train: epoch 114, loss 0.3841729760169983, acc=0.8115000128746033, loss=0.3841729760169983
test: epoch 114, loss 0.8857076168060303, acc=0.6805555820465088, loss=0.8857076168060303
train: epoch 115, loss 0.37553250789642334, acc=0.8159999847412109, loss=0.37553250789642334
test: epoch 115, loss 0.9405388832092285, acc=0.6805555820465088, loss=0.9405388832092285
train: epoch 116, loss 0.37666866183280945, acc=0.8194444179534912, loss=0.37666866183280945
test: epoch 116, loss 0.9128168225288391, acc=0.6833333373069763, loss=0.9128168225288391
train: epoch 117, loss 0.3642231523990631, acc=0.8209999799728394, loss=0.3642231523990631
test: epoch 117, loss 1.113434910774231, acc=0.6833333373069763, loss=1.113434910774231
train: epoch 118, loss 0.35779938101768494, acc=0.8241111040115356, loss=0.35779938101768494
test: epoch 118, loss 0.9098402261734009, acc=0.6833333373069763, loss=0.9098402261734009
train: epoch 119, loss 0.3615948557853699, acc=0.8236666917800903, loss=0.3615948557853699
test: epoch 119, loss 1.0278888940811157, acc=0.6805555820465088, loss=1.0278888940811157
train: epoch 120, loss 0.36601608991622925, acc=0.8222222328186035, loss=0.36601608991622925
test: epoch 120, loss 0.9340845942497253, acc=0.6833333373069763, loss=0.9340845942497253
train: epoch 121, loss 0.39455413818359375, acc=0.820277750492096, loss=0.39455413818359375
test: epoch 121, loss 0.8652568459510803, acc=0.6833333373069763, loss=0.8652568459510803
train: epoch 122, loss 0.37480419874191284, acc=0.8224999904632568, loss=0.37480419874191284
test: epoch 122, loss 0.9638755321502686, acc=0.6805555820465088, loss=0.9638755321502686
train: epoch 123, loss 0.37910714745521545, acc=0.8208333253860474, loss=0.37910714745521545
test: epoch 123, loss 0.9604088068008423, acc=0.6805555820465088, loss=0.9604088068008423
train: epoch 124, loss 0.41633179783821106, acc=0.8102222084999084, loss=0.41633179783821106
test: epoch 124, loss 0.974150538444519, acc=0.6777777671813965, loss=0.974150538444519
train: epoch 125, loss 0.41303473711013794, acc=0.8116666674613953, loss=0.41303473711013794
test: epoch 125, loss 0.9869050979614258, acc=0.6777777671813965, loss=0.9869050979614258
train: epoch 126, loss 0.3903034031391144, acc=0.8145555257797241, loss=0.3903034031391144
test: epoch 126, loss 0.9550912976264954, acc=0.6777777671813965, loss=0.9550912976264954
train: epoch 127, loss 0.3841083347797394, acc=0.8147222399711609, loss=0.3841083347797394
test: epoch 127, loss 1.026646375656128, acc=0.6777777671813965, loss=1.026646375656128
train: epoch 128, loss 0.3821389973163605, acc=0.8165000081062317, loss=0.3821389973163605
test: epoch 128, loss 1.0068436861038208, acc=0.6805555820465088, loss=1.0068436861038208
train: epoch 129, loss 0.3869421184062958, acc=0.8155555725097656, loss=0.3869421184062958
test: epoch 129, loss 0.9047675728797913, acc=0.6888889074325562, loss=0.9047675728797913
train: epoch 130, loss 0.40361616015434265, acc=0.8272777795791626, loss=0.40361616015434265
test: epoch 130, loss 0.8873344659805298, acc=0.699999988079071, loss=0.8873344659805298
train: epoch 131, loss 0.34307706356048584, acc=0.8436111211776733, loss=0.34307706356048584
test: epoch 131, loss 0.8972440958023071, acc=0.7138888835906982, loss=0.8972440958023071
train: epoch 132, loss 0.3311680257320404, acc=0.846833348274231, loss=0.3311680257320404
test: epoch 132, loss 0.9415332674980164, acc=0.7138888835906982, loss=0.9415332674980164
train: epoch 133, loss 0.32882440090179443, acc=0.8457221984863281, loss=0.32882440090179443
test: epoch 133, loss 0.7990973591804504, acc=0.7138888835906982, loss=0.7990973591804504
train: epoch 134, loss 0.3201214075088501, acc=0.8523889183998108, loss=0.3201214075088501
test: epoch 134, loss 0.7988537549972534, acc=0.7277777791023254, loss=0.7988537549972534
train: epoch 135, loss 0.32060474157333374, acc=0.856166660785675, loss=0.32060474157333374
test: epoch 135, loss 0.7528300881385803, acc=0.7472222447395325, loss=0.7528300881385803
train: epoch 136, loss 0.3084750473499298, acc=0.8589444160461426, loss=0.3084750473499298
test: epoch 136, loss 0.798578679561615, acc=0.7416666746139526, loss=0.798578679561615
train: epoch 137, loss 0.3093840479850769, acc=0.8576111197471619, loss=0.3093840479850769
test: epoch 137, loss 0.6696979403495789, acc=0.7444444298744202, loss=0.6696979403495789
train: epoch 138, loss 0.30928951501846313, acc=0.8588888645172119, loss=0.30928951501846313
test: epoch 138, loss 0.681340217590332, acc=0.7416666746139526, loss=0.681340217590332
train: epoch 139, loss 0.31930840015411377, acc=0.8544444441795349, loss=0.31930840015411377
test: epoch 139, loss 0.7446080446243286, acc=0.7527777552604675, loss=0.7446080446243286
train: epoch 140, loss 0.304717481136322, acc=0.8585000038146973, loss=0.304717481136322
test: epoch 140, loss 0.5996310710906982, acc=0.7833333611488342, loss=0.5996310710906982
train: epoch 141, loss 0.3191663920879364, acc=0.8572777509689331, loss=0.3191663920879364
test: epoch 141, loss 0.556369423866272, acc=0.7805555462837219, loss=0.556369423866272
train: epoch 142, loss 0.2912747859954834, acc=0.8621666431427002, loss=0.2912747859954834
test: epoch 142, loss 0.6550849676132202, acc=0.7888888716697693, loss=0.6550849676132202
train: epoch 143, loss 0.277975857257843, acc=0.8651666641235352, loss=0.277975857257843
test: epoch 143, loss 0.5496581792831421, acc=0.7916666865348816, loss=0.5496581792831421
train: epoch 144, loss 0.28541868925094604, acc=0.863444447517395, loss=0.28541868925094604
test: epoch 144, loss 0.6048628091812134, acc=0.7888888716697693, loss=0.6048628091812134
train: epoch 145, loss 0.278882771730423, acc=0.8640000224113464, loss=0.278882771730423
test: epoch 145, loss 0.5415884256362915, acc=0.7916666865348816, loss=0.5415884256362915
train: epoch 146, loss 0.27876344323158264, acc=0.8607777953147888, loss=0.27876344323158264
test: epoch 146, loss 0.5510215163230896, acc=0.7916666865348816, loss=0.5510215163230896
train: epoch 147, loss 0.2718775272369385, acc=0.8648333549499512, loss=0.2718775272369385
test: epoch 147, loss 0.5611964464187622, acc=0.7972221970558167, loss=0.5611964464187622
train: epoch 148, loss 0.27840369939804077, acc=0.8632222414016724, loss=0.27840369939804077
test: epoch 148, loss 0.574434220790863, acc=0.7916666865348816, loss=0.574434220790863
train: epoch 149, loss 0.275885671377182, acc=0.8646666407585144, loss=0.275885671377182
test: epoch 149, loss 0.5884233713150024, acc=0.7916666865348816, loss=0.5884233713150024
train: epoch 150, loss 0.27916574478149414, acc=0.8662222027778625, loss=0.27916574478149414
test: epoch 150, loss 0.5381099581718445, acc=0.7916666865348816, loss=0.5381099581718445
