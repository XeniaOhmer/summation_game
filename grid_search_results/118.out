# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=1", "--temp_decay=0.995", "--one_hot=1", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=1199471099, receiver_embed_dim=128, save_run=0, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1199471099, receiver_embed_dim=128, save_run=False, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.411872625350952, acc=0.05155555531382561, loss=3.411872625350952
test: epoch 1, loss 3.21189546585083, acc=0.07500000298023224, loss=3.21189546585083
train: epoch 2, loss 2.2298996448516846, acc=0.17972221970558167, loss=2.2298996448516846
test: epoch 2, loss 2.270644187927246, acc=0.14722222089767456, loss=2.270644187927246
train: epoch 3, loss 1.7724703550338745, acc=0.28022223711013794, loss=1.7724703550338745
test: epoch 3, loss 2.199023485183716, acc=0.17777778208255768, loss=2.199023485183716
train: epoch 4, loss 1.5855462551116943, acc=0.3408888876438141, loss=1.5855462551116943
test: epoch 4, loss 2.0100536346435547, acc=0.20555555820465088, loss=2.0100536346435547
train: epoch 5, loss 1.4569605588912964, acc=0.3869999945163727, loss=1.4569605588912964
test: epoch 5, loss 2.0141336917877197, acc=0.2361111044883728, loss=2.0141336917877197
train: epoch 6, loss 1.3507521152496338, acc=0.4284999966621399, loss=1.3507521152496338
test: epoch 6, loss 1.9811480045318604, acc=0.23888888955116272, loss=1.9811480045318604
train: epoch 7, loss 1.2575185298919678, acc=0.46638888120651245, loss=1.2575185298919678
test: epoch 7, loss 1.8651074171066284, acc=0.2527777850627899, loss=1.8651074171066284
train: epoch 8, loss 1.2216429710388184, acc=0.48444443941116333, loss=1.2216429710388184
test: epoch 8, loss 1.8426693677902222, acc=0.2638888955116272, loss=1.8426693677902222
train: epoch 9, loss 1.1555005311965942, acc=0.5098888874053955, loss=1.1555005311965942
test: epoch 9, loss 1.9407548904418945, acc=0.25555557012557983, loss=1.9407548904418945
train: epoch 10, loss 1.1185150146484375, acc=0.5262222290039062, loss=1.1185150146484375
test: epoch 10, loss 1.9236332178115845, acc=0.2638888955116272, loss=1.9236332178115845
train: epoch 11, loss 1.090869665145874, acc=0.5390555262565613, loss=1.090869665145874
test: epoch 11, loss 1.9565984010696411, acc=0.2666666805744171, loss=1.9565984010696411
train: epoch 12, loss 1.0551409721374512, acc=0.5534999966621399, loss=1.0551409721374512
test: epoch 12, loss 1.9646164178848267, acc=0.2666666805744171, loss=1.9646164178848267
train: epoch 13, loss 1.024721622467041, acc=0.559333324432373, loss=1.024721622467041
test: epoch 13, loss 2.007120370864868, acc=0.26944443583488464, loss=2.007120370864868
train: epoch 14, loss 1.0056796073913574, acc=0.5648333430290222, loss=1.0056796073913574
test: epoch 14, loss 2.047391176223755, acc=0.27222222089767456, loss=2.047391176223755
train: epoch 15, loss 0.9961714744567871, acc=0.5718333125114441, loss=0.9961714744567871
test: epoch 15, loss 1.9810072183609009, acc=0.26944443583488464, loss=1.9810072183609009
train: epoch 16, loss 0.9746711850166321, acc=0.5778889060020447, loss=0.9746711850166321
test: epoch 16, loss 1.9253811836242676, acc=0.28333333134651184, loss=1.9253811836242676
train: epoch 17, loss 0.9588298201560974, acc=0.5845000147819519, loss=0.9588298201560974
test: epoch 17, loss 1.9669122695922852, acc=0.28333333134651184, loss=1.9669122695922852
train: epoch 18, loss 0.9465665221214294, acc=0.5920000076293945, loss=0.9465665221214294
test: epoch 18, loss 2.0509586334228516, acc=0.30000001192092896, loss=2.0509586334228516
train: epoch 19, loss 0.9386682510375977, acc=0.5985555648803711, loss=0.9386682510375977
test: epoch 19, loss 2.016836166381836, acc=0.29722222685813904, loss=2.016836166381836
train: epoch 20, loss 0.9256340265274048, acc=0.6036111116409302, loss=0.9256340265274048
test: epoch 20, loss 1.9929945468902588, acc=0.29722222685813904, loss=1.9929945468902588
train: epoch 21, loss 0.9110531210899353, acc=0.6116111278533936, loss=0.9110531210899353
test: epoch 21, loss 2.153703212738037, acc=0.31111112236976624, loss=2.153703212738037
train: epoch 22, loss 0.8999937772750854, acc=0.6112222075462341, loss=0.8999937772750854
test: epoch 22, loss 2.0272743701934814, acc=0.3027777671813965, loss=2.0272743701934814
train: epoch 23, loss 0.8915576338768005, acc=0.6144999861717224, loss=0.8915576338768005
test: epoch 23, loss 2.215579032897949, acc=0.30000001192092896, loss=2.215579032897949
train: epoch 24, loss 0.8784085512161255, acc=0.6191666722297668, loss=0.8784085512161255
test: epoch 24, loss 2.2045488357543945, acc=0.3083333373069763, loss=2.2045488357543945
train: epoch 25, loss 0.877955973148346, acc=0.6215000152587891, loss=0.877955973148346
test: epoch 25, loss 2.057695150375366, acc=0.30000001192092896, loss=2.057695150375366
train: epoch 26, loss 0.8564614057540894, acc=0.6249444484710693, loss=0.8564614057540894
test: epoch 26, loss 2.1779448986053467, acc=0.31388887763023376, loss=2.1779448986053467
train: epoch 27, loss 0.8552178144454956, acc=0.6247222423553467, loss=0.8552178144454956
test: epoch 27, loss 2.1215689182281494, acc=0.31111112236976624, loss=2.1215689182281494
train: epoch 28, loss 0.8678821325302124, acc=0.6196666955947876, loss=0.8678821325302124
test: epoch 28, loss 2.136497735977173, acc=0.31388887763023376, loss=2.136497735977173
train: epoch 29, loss 0.8397240042686462, acc=0.6323888897895813, loss=0.8397240042686462
test: epoch 29, loss 2.1615660190582275, acc=0.3166666626930237, loss=2.1615660190582275
train: epoch 30, loss 0.8470250368118286, acc=0.6313333511352539, loss=0.8470250368118286
test: epoch 30, loss 2.231001615524292, acc=0.31388887763023376, loss=2.231001615524292
train: epoch 31, loss 0.8484968543052673, acc=0.6274444460868835, loss=0.8484968543052673
test: epoch 31, loss 2.1887240409851074, acc=0.3083333373069763, loss=2.1887240409851074
train: epoch 32, loss 0.8364909887313843, acc=0.632611095905304, loss=0.8364909887313843
test: epoch 32, loss 2.070786476135254, acc=0.31111112236976624, loss=2.070786476135254
train: epoch 33, loss 0.8404619097709656, acc=0.6319444179534912, loss=0.8404619097709656
test: epoch 33, loss 2.047936201095581, acc=0.31388887763023376, loss=2.047936201095581
train: epoch 34, loss 0.8261145353317261, acc=0.637666642665863, loss=0.8261145353317261
test: epoch 34, loss 2.3231406211853027, acc=0.31388887763023376, loss=2.3231406211853027
train: epoch 35, loss 0.8261747360229492, acc=0.6366111040115356, loss=0.8261747360229492
test: epoch 35, loss 2.2031772136688232, acc=0.3166666626930237, loss=2.2031772136688232
train: epoch 36, loss 0.8216913938522339, acc=0.637499988079071, loss=0.8216913938522339
test: epoch 36, loss 2.022204875946045, acc=0.31111112236976624, loss=2.022204875946045
train: epoch 37, loss 0.8300421833992004, acc=0.6374444365501404, loss=0.8300421833992004
test: epoch 37, loss 2.2886769771575928, acc=0.3166666626930237, loss=2.2886769771575928
train: epoch 38, loss 0.8381689190864563, acc=0.6308888792991638, loss=0.8381689190864563
test: epoch 38, loss 2.072406768798828, acc=0.3194444477558136, loss=2.072406768798828
train: epoch 39, loss 0.8304327130317688, acc=0.6313889026641846, loss=0.8304327130317688
test: epoch 39, loss 2.143531560897827, acc=0.3166666626930237, loss=2.143531560897827
train: epoch 40, loss 0.8202407956123352, acc=0.6361666917800903, loss=0.8202407956123352
test: epoch 40, loss 2.3407094478607178, acc=0.3305555582046509, loss=2.3407094478607178
train: epoch 41, loss 0.8235246539115906, acc=0.63355553150177, loss=0.8235246539115906
test: epoch 41, loss 2.1497325897216797, acc=0.3222222328186035, loss=2.1497325897216797
train: epoch 42, loss 0.8190673589706421, acc=0.6371111273765564, loss=0.8190673589706421
test: epoch 42, loss 2.2042360305786133, acc=0.3194444477558136, loss=2.2042360305786133
train: epoch 43, loss 0.8203312158584595, acc=0.6359999775886536, loss=0.8203312158584595
test: epoch 43, loss 2.169436454772949, acc=0.32499998807907104, loss=2.169436454772949
train: epoch 44, loss 0.8114736676216125, acc=0.6365000009536743, loss=0.8114736676216125
test: epoch 44, loss 2.1548550128936768, acc=0.3333333432674408, loss=2.1548550128936768
train: epoch 45, loss 0.8177260160446167, acc=0.640666663646698, loss=0.8177260160446167
test: epoch 45, loss 2.1805813312530518, acc=0.32499998807907104, loss=2.1805813312530518
train: epoch 46, loss 0.817274808883667, acc=0.6320555806159973, loss=0.817274808883667
test: epoch 46, loss 2.187049150466919, acc=0.3305555582046509, loss=2.187049150466919
train: epoch 47, loss 0.8189873099327087, acc=0.6307777762413025, loss=0.8189873099327087
test: epoch 47, loss 2.114375114440918, acc=0.32777777314186096, loss=2.114375114440918
train: epoch 48, loss 0.8306921124458313, acc=0.6286666393280029, loss=0.8306921124458313
test: epoch 48, loss 2.2547876834869385, acc=0.3333333432674408, loss=2.2547876834869385
train: epoch 49, loss 0.8280860185623169, acc=0.6241666674613953, loss=0.8280860185623169
test: epoch 49, loss 2.1460890769958496, acc=0.32777777314186096, loss=2.1460890769958496
train: epoch 50, loss 0.8127665519714355, acc=0.63227778673172, loss=0.8127665519714355
test: epoch 50, loss 2.303767442703247, acc=0.3333333432674408, loss=2.303767442703247
train: epoch 51, loss 0.8118170499801636, acc=0.6290000081062317, loss=0.8118170499801636
test: epoch 51, loss 2.0642902851104736, acc=0.3361110985279083, loss=2.0642902851104736
train: epoch 52, loss 0.8073111772537231, acc=0.6343888640403748, loss=0.8073111772537231
test: epoch 52, loss 2.221275568008423, acc=0.3305555582046509, loss=2.221275568008423
train: epoch 53, loss 0.8116841316223145, acc=0.6312222480773926, loss=0.8116841316223145
test: epoch 53, loss 2.1552412509918213, acc=0.32499998807907104, loss=2.1552412509918213
train: epoch 54, loss 0.8120192885398865, acc=0.6320555806159973, loss=0.8120192885398865
test: epoch 54, loss 2.2554094791412354, acc=0.3222222328186035, loss=2.2554094791412354
train: epoch 55, loss 0.823339581489563, acc=0.6284444332122803, loss=0.823339581489563
test: epoch 55, loss 2.137465715408325, acc=0.33888888359069824, loss=2.137465715408325
train: epoch 56, loss 0.8198091387748718, acc=0.632111132144928, loss=0.8198091387748718
test: epoch 56, loss 2.1389212608337402, acc=0.33888888359069824, loss=2.1389212608337402
train: epoch 57, loss 0.8271734118461609, acc=0.6278889179229736, loss=0.8271734118461609
test: epoch 57, loss 1.9450594186782837, acc=0.3305555582046509, loss=1.9450594186782837
train: epoch 58, loss 0.8147068619728088, acc=0.6317777633666992, loss=0.8147068619728088
test: epoch 58, loss 1.9188295602798462, acc=0.3444444537162781, loss=1.9188295602798462
train: epoch 59, loss 0.8306488394737244, acc=0.624833345413208, loss=0.8306488394737244
test: epoch 59, loss 2.008784294128418, acc=0.33888888359069824, loss=2.008784294128418
train: epoch 60, loss 0.807213544845581, acc=0.6359444260597229, loss=0.807213544845581
test: epoch 60, loss 2.186816692352295, acc=0.3499999940395355, loss=2.186816692352295
train: epoch 61, loss 0.8104168772697449, acc=0.6287222504615784, loss=0.8104168772697449
test: epoch 61, loss 2.10282301902771, acc=0.35277777910232544, loss=2.10282301902771
train: epoch 62, loss 0.8104864954948425, acc=0.6302222013473511, loss=0.8104864954948425
test: epoch 62, loss 2.2152161598205566, acc=0.35277777910232544, loss=2.2152161598205566
train: epoch 63, loss 0.8117164969444275, acc=0.6311666369438171, loss=0.8117164969444275
test: epoch 63, loss 2.073707103729248, acc=0.3499999940395355, loss=2.073707103729248
train: epoch 64, loss 0.8052483797073364, acc=0.6296666860580444, loss=0.8052483797073364
test: epoch 64, loss 2.0680246353149414, acc=0.3638888895511627, loss=2.0680246353149414
train: epoch 65, loss 0.8046658635139465, acc=0.6278889179229736, loss=0.8046658635139465
test: epoch 65, loss 2.040445566177368, acc=0.35277777910232544, loss=2.040445566177368
train: epoch 66, loss 0.8037276864051819, acc=0.6308333277702332, loss=0.8037276864051819
test: epoch 66, loss 2.271364688873291, acc=0.3499999940395355, loss=2.271364688873291
train: epoch 67, loss 0.7963016033172607, acc=0.6353889107704163, loss=0.7963016033172607
test: epoch 67, loss 2.034719467163086, acc=0.35555556416511536, loss=2.034719467163086
train: epoch 68, loss 0.8024103045463562, acc=0.6298888921737671, loss=0.8024103045463562
test: epoch 68, loss 2.0081865787506104, acc=0.3472222089767456, loss=2.0081865787506104
train: epoch 69, loss 0.7936844825744629, acc=0.6356111168861389, loss=0.7936844825744629
test: epoch 69, loss 2.0351924896240234, acc=0.35555556416511536, loss=2.0351924896240234
train: epoch 70, loss 0.7968186736106873, acc=0.6318333148956299, loss=0.7968186736106873
test: epoch 70, loss 2.137789726257324, acc=0.3472222089767456, loss=2.137789726257324
train: epoch 71, loss 0.7888520359992981, acc=0.637333333492279, loss=0.7888520359992981
test: epoch 71, loss 2.163086414337158, acc=0.35277777910232544, loss=2.163086414337158
train: epoch 72, loss 0.7893601059913635, acc=0.6372222304344177, loss=0.7893601059913635
test: epoch 72, loss 1.984674096107483, acc=0.3444444537162781, loss=1.984674096107483
train: epoch 73, loss 0.8009633421897888, acc=0.6297222375869751, loss=0.8009633421897888
test: epoch 73, loss 2.0859949588775635, acc=0.35555556416511536, loss=2.0859949588775635
train: epoch 74, loss 0.7989558577537537, acc=0.6315555572509766, loss=0.7989558577537537
test: epoch 74, loss 2.201392412185669, acc=0.3583333194255829, loss=2.201392412185669
train: epoch 75, loss 0.7918400764465332, acc=0.63355553150177, loss=0.7918400764465332
test: epoch 75, loss 2.2564032077789307, acc=0.3583333194255829, loss=2.2564032077789307
train: epoch 76, loss 0.7852144241333008, acc=0.6396111249923706, loss=0.7852144241333008
test: epoch 76, loss 2.0248098373413086, acc=0.375, loss=2.0248098373413086
train: epoch 77, loss 0.794549822807312, acc=0.6308888792991638, loss=0.794549822807312
test: epoch 77, loss 2.1033377647399902, acc=0.35555556416511536, loss=2.1033377647399902
train: epoch 78, loss 0.7922312617301941, acc=0.6344444155693054, loss=0.7922312617301941
test: epoch 78, loss 2.054203748703003, acc=0.34166666865348816, loss=2.054203748703003
train: epoch 79, loss 0.7902782559394836, acc=0.6347777843475342, loss=0.7902782559394836
test: epoch 79, loss 2.177622079849243, acc=0.35277777910232544, loss=2.177622079849243
train: epoch 80, loss 0.785279393196106, acc=0.637333333492279, loss=0.785279393196106
test: epoch 80, loss 2.0588324069976807, acc=0.3499999940395355, loss=2.0588324069976807
train: epoch 81, loss 0.7749437093734741, acc=0.6387222409248352, loss=0.7749437093734741
test: epoch 81, loss 1.9738041162490845, acc=0.35277777910232544, loss=1.9738041162490845
train: epoch 82, loss 0.7865803241729736, acc=0.6397222280502319, loss=0.7865803241729736
test: epoch 82, loss 2.123368263244629, acc=0.3638888895511627, loss=2.123368263244629
train: epoch 83, loss 0.7787103056907654, acc=0.6386666893959045, loss=0.7787103056907654
test: epoch 83, loss 1.979063630104065, acc=0.35277777910232544, loss=1.979063630104065
train: epoch 84, loss 0.7794845700263977, acc=0.6419444680213928, loss=0.7794845700263977
test: epoch 84, loss 2.1203250885009766, acc=0.3499999940395355, loss=2.1203250885009766
train: epoch 85, loss 0.7749343514442444, acc=0.6412222385406494, loss=0.7749343514442444
test: epoch 85, loss 2.1499977111816406, acc=0.3444444537162781, loss=2.1499977111816406
train: epoch 86, loss 0.7797451615333557, acc=0.6373888850212097, loss=0.7797451615333557
test: epoch 86, loss 2.3211658000946045, acc=0.3499999940395355, loss=2.3211658000946045
train: epoch 87, loss 0.7815210223197937, acc=0.6394444704055786, loss=0.7815210223197937
test: epoch 87, loss 1.8693393468856812, acc=0.3583333194255829, loss=1.8693393468856812
train: epoch 88, loss 0.7850837707519531, acc=0.6440555453300476, loss=0.7850837707519531
test: epoch 88, loss 1.9816932678222656, acc=0.35555556416511536, loss=1.9816932678222656
train: epoch 89, loss 0.7696391940116882, acc=0.6425555348396301, loss=0.7696391940116882
test: epoch 89, loss 2.36134672164917, acc=0.3638888895511627, loss=2.36134672164917
train: epoch 90, loss 0.765712320804596, acc=0.6427222490310669, loss=0.765712320804596
test: epoch 90, loss 2.0144875049591064, acc=0.3611111044883728, loss=2.0144875049591064
train: epoch 91, loss 0.7695025205612183, acc=0.6410555839538574, loss=0.7695025205612183
test: epoch 91, loss 2.2260706424713135, acc=0.3499999940395355, loss=2.2260706424713135
train: epoch 92, loss 0.7819015383720398, acc=0.6358333230018616, loss=0.7819015383720398
test: epoch 92, loss 2.004915475845337, acc=0.35555556416511536, loss=2.004915475845337
train: epoch 93, loss 0.7695959806442261, acc=0.640500009059906, loss=0.7695959806442261
test: epoch 93, loss 2.10262131690979, acc=0.3583333194255829, loss=2.10262131690979
train: epoch 94, loss 0.764714777469635, acc=0.6441110968589783, loss=0.764714777469635
test: epoch 94, loss 2.0278213024139404, acc=0.35277777910232544, loss=2.0278213024139404
train: epoch 95, loss 0.772350549697876, acc=0.6462222337722778, loss=0.772350549697876
test: epoch 95, loss 2.0687880516052246, acc=0.3499999940395355, loss=2.0687880516052246
train: epoch 96, loss 0.7728621363639832, acc=0.6433888673782349, loss=0.7728621363639832
test: epoch 96, loss 2.1849100589752197, acc=0.35555556416511536, loss=2.1849100589752197
train: epoch 97, loss 0.7606726884841919, acc=0.644611120223999, loss=0.7606726884841919
test: epoch 97, loss 2.089151382446289, acc=0.3583333194255829, loss=2.089151382446289
train: epoch 98, loss 0.7567786574363708, acc=0.6424999833106995, loss=0.7567786574363708
test: epoch 98, loss 2.027669906616211, acc=0.375, loss=2.027669906616211
train: epoch 99, loss 0.7632975578308105, acc=0.6461111307144165, loss=0.7632975578308105
test: epoch 99, loss 2.173928737640381, acc=0.35555556416511536, loss=2.173928737640381
train: epoch 100, loss 0.7696695327758789, acc=0.6431111097335815, loss=0.7696695327758789
test: epoch 100, loss 2.0659806728363037, acc=0.3638888895511627, loss=2.0659806728363037
train: epoch 101, loss 0.7748011350631714, acc=0.6424444317817688, loss=0.7748011350631714
test: epoch 101, loss 1.8919742107391357, acc=0.36944442987442017, loss=1.8919742107391357
train: epoch 102, loss 0.765364944934845, acc=0.6441110968589783, loss=0.765364944934845
test: epoch 102, loss 1.9467066526412964, acc=0.3611111044883728, loss=1.9467066526412964
train: epoch 103, loss 0.758794367313385, acc=0.6458333134651184, loss=0.758794367313385
test: epoch 103, loss 2.3676462173461914, acc=0.3583333194255829, loss=2.3676462173461914
train: epoch 104, loss 0.7494408488273621, acc=0.6484444737434387, loss=0.7494408488273621
test: epoch 104, loss 2.3346750736236572, acc=0.3611111044883728, loss=2.3346750736236572
train: epoch 105, loss 0.7664541006088257, acc=0.6426110863685608, loss=0.7664541006088257
test: epoch 105, loss 2.062793254852295, acc=0.3638888895511627, loss=2.062793254852295
train: epoch 106, loss 0.7559927105903625, acc=0.6428889036178589, loss=0.7559927105903625
test: epoch 106, loss 2.08638072013855, acc=0.375, loss=2.08638072013855
train: epoch 107, loss 0.755592405796051, acc=0.6429444551467896, loss=0.755592405796051
test: epoch 107, loss 2.119793176651001, acc=0.36666667461395264, loss=2.119793176651001
train: epoch 108, loss 0.7600110173225403, acc=0.6431666612625122, loss=0.7600110173225403
test: epoch 108, loss 1.9865525960922241, acc=0.3638888895511627, loss=1.9865525960922241
train: epoch 109, loss 0.7603926658630371, acc=0.64083331823349, loss=0.7603926658630371
test: epoch 109, loss 2.3155744075775146, acc=0.375, loss=2.3155744075775146
train: epoch 110, loss 0.7519814968109131, acc=0.6474444270133972, loss=0.7519814968109131
test: epoch 110, loss 2.229112148284912, acc=0.36666667461395264, loss=2.229112148284912
train: epoch 111, loss 0.7663200497627258, acc=0.6445555686950684, loss=0.7663200497627258
test: epoch 111, loss 1.9773356914520264, acc=0.3722222149372101, loss=1.9773356914520264
train: epoch 112, loss 0.7597083449363708, acc=0.643833339214325, loss=0.7597083449363708
test: epoch 112, loss 1.986271858215332, acc=0.3611111044883728, loss=1.986271858215332
train: epoch 113, loss 0.7550243139266968, acc=0.6474999785423279, loss=0.7550243139266968
test: epoch 113, loss 2.450328826904297, acc=0.3638888895511627, loss=2.450328826904297
train: epoch 114, loss 0.7450860738754272, acc=0.6508333086967468, loss=0.7450860738754272
test: epoch 114, loss 2.0811126232147217, acc=0.36666667461395264, loss=2.0811126232147217
train: epoch 115, loss 0.7394216060638428, acc=0.6495555639266968, loss=0.7394216060638428
test: epoch 115, loss 2.0676703453063965, acc=0.36944442987442017, loss=2.0676703453063965
train: epoch 116, loss 0.7521628737449646, acc=0.64811110496521, loss=0.7521628737449646
test: epoch 116, loss 1.99598228931427, acc=0.3583333194255829, loss=1.99598228931427
train: epoch 117, loss 0.7523375749588013, acc=0.6477222442626953, loss=0.7523375749588013
test: epoch 117, loss 1.8702057600021362, acc=0.3638888895511627, loss=1.8702057600021362
train: epoch 118, loss 0.7557722330093384, acc=0.6507777571678162, loss=0.7557722330093384
test: epoch 118, loss 2.015812635421753, acc=0.3611111044883728, loss=2.015812635421753
train: epoch 119, loss 0.7399250268936157, acc=0.6497222185134888, loss=0.7399250268936157
test: epoch 119, loss 2.1290740966796875, acc=0.3638888895511627, loss=2.1290740966796875
train: epoch 120, loss 0.7508115172386169, acc=0.6527222394943237, loss=0.7508115172386169
test: epoch 120, loss 1.9986423254013062, acc=0.38055557012557983, loss=1.9986423254013062
train: epoch 121, loss 0.7392091155052185, acc=0.651888906955719, loss=0.7392091155052185
test: epoch 121, loss 2.099534034729004, acc=0.3638888895511627, loss=2.099534034729004
train: epoch 122, loss 0.7542750835418701, acc=0.6483888626098633, loss=0.7542750835418701
test: epoch 122, loss 2.153529167175293, acc=0.375, loss=2.153529167175293
train: epoch 123, loss 0.7434344291687012, acc=0.6503888964653015, loss=0.7434344291687012
test: epoch 123, loss 2.0823006629943848, acc=0.3722222149372101, loss=2.0823006629943848
train: epoch 124, loss 0.7517459392547607, acc=0.6513333320617676, loss=0.7517459392547607
test: epoch 124, loss 2.360628604888916, acc=0.36666667461395264, loss=2.360628604888916
train: epoch 125, loss 0.736961841583252, acc=0.6508333086967468, loss=0.736961841583252
test: epoch 125, loss 2.193845272064209, acc=0.36944442987442017, loss=2.193845272064209
train: epoch 126, loss 0.7465496063232422, acc=0.6496111154556274, loss=0.7465496063232422
test: epoch 126, loss 2.1273486614227295, acc=0.3722222149372101, loss=2.1273486614227295
train: epoch 127, loss 0.7352527379989624, acc=0.6575000286102295, loss=0.7352527379989624
test: epoch 127, loss 2.078552484512329, acc=0.36666667461395264, loss=2.078552484512329
train: epoch 128, loss 0.7414265871047974, acc=0.649222195148468, loss=0.7414265871047974
test: epoch 128, loss 2.075902223587036, acc=0.36666667461395264, loss=2.075902223587036
train: epoch 129, loss 0.7371183037757874, acc=0.6525555849075317, loss=0.7371183037757874
test: epoch 129, loss 2.087428092956543, acc=0.36944442987442017, loss=2.087428092956543
train: epoch 130, loss 0.7348700761795044, acc=0.6525555849075317, loss=0.7348700761795044
test: epoch 130, loss 1.9358690977096558, acc=0.36944442987442017, loss=1.9358690977096558
train: epoch 131, loss 0.7387804985046387, acc=0.6552222371101379, loss=0.7387804985046387
test: epoch 131, loss 2.086167812347412, acc=0.3777777850627899, loss=2.086167812347412
train: epoch 132, loss 0.719671905040741, acc=0.6536666750907898, loss=0.719671905040741
test: epoch 132, loss 2.021273612976074, acc=0.375, loss=2.021273612976074
train: epoch 133, loss 0.7280123233795166, acc=0.6577777862548828, loss=0.7280123233795166
test: epoch 133, loss 2.012300729751587, acc=0.3722222149372101, loss=2.012300729751587
train: epoch 134, loss 0.723887026309967, acc=0.657444417476654, loss=0.723887026309967
test: epoch 134, loss 2.0860166549682617, acc=0.3777777850627899, loss=2.0860166549682617
train: epoch 135, loss 0.7267957329750061, acc=0.6573333144187927, loss=0.7267957329750061
test: epoch 135, loss 2.341837167739868, acc=0.38055557012557983, loss=2.341837167739868
train: epoch 136, loss 0.7212902903556824, acc=0.6611111164093018, loss=0.7212902903556824
test: epoch 136, loss 2.314380407333374, acc=0.38333332538604736, loss=2.314380407333374
train: epoch 137, loss 0.7411561608314514, acc=0.653166651725769, loss=0.7411561608314514
test: epoch 137, loss 2.165675640106201, acc=0.38055557012557983, loss=2.165675640106201
train: epoch 138, loss 0.7210022807121277, acc=0.6603888869285583, loss=0.7210022807121277
test: epoch 138, loss 1.9177366495132446, acc=0.39444443583488464, loss=1.9177366495132446
train: epoch 139, loss 0.7110819220542908, acc=0.6651666760444641, loss=0.7110819220542908
test: epoch 139, loss 2.1013975143432617, acc=0.3777777850627899, loss=2.1013975143432617
train: epoch 140, loss 0.7206025123596191, acc=0.6616111397743225, loss=0.7206025123596191
test: epoch 140, loss 2.070207357406616, acc=0.38055557012557983, loss=2.070207357406616
train: epoch 141, loss 0.7047402262687683, acc=0.6658889055252075, loss=0.7047402262687683
test: epoch 141, loss 1.7645888328552246, acc=0.38333332538604736, loss=1.7645888328552246
train: epoch 142, loss 0.7122913599014282, acc=0.6646666526794434, loss=0.7122913599014282
test: epoch 142, loss 2.040266275405884, acc=0.38333332538604736, loss=2.040266275405884
train: epoch 143, loss 0.7034201622009277, acc=0.6651111245155334, loss=0.7034201622009277
test: epoch 143, loss 2.2212483882904053, acc=0.3861111104488373, loss=2.2212483882904053
train: epoch 144, loss 0.7132477760314941, acc=0.6611666679382324, loss=0.7132477760314941
test: epoch 144, loss 2.2452051639556885, acc=0.38333332538604736, loss=2.2452051639556885
train: epoch 145, loss 0.7041932344436646, acc=0.6669444441795349, loss=0.7041932344436646
test: epoch 145, loss 2.161531925201416, acc=0.38055557012557983, loss=2.161531925201416
train: epoch 146, loss 0.7175942659378052, acc=0.6633333563804626, loss=0.7175942659378052
test: epoch 146, loss 2.133068323135376, acc=0.3888888955116272, loss=2.133068323135376
train: epoch 147, loss 0.7021859884262085, acc=0.6711111068725586, loss=0.7021859884262085
test: epoch 147, loss 2.1771433353424072, acc=0.3861111104488373, loss=2.1771433353424072
train: epoch 148, loss 0.7039487361907959, acc=0.6659444570541382, loss=0.7039487361907959
test: epoch 148, loss 1.9727624654769897, acc=0.3916666805744171, loss=1.9727624654769897
train: epoch 149, loss 0.7041535377502441, acc=0.6666111350059509, loss=0.7041535377502441
test: epoch 149, loss 2.116997718811035, acc=0.39722222089767456, loss=2.116997718811035
train: epoch 150, loss 0.7047808170318604, acc=0.6678333282470703, loss=0.7047808170318604
test: epoch 150, loss 2.1226511001586914, acc=0.39444443583488464, loss=2.1226511001586914
