# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1", "--temp_decay=0.995", "--one_hot=true", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=847096413, receiver_embed_dim=32, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.4756884574890137, acc=0.04694444313645363, loss=3.4756884574890137
test: epoch 1, loss 3.67987060546875, acc=0.04722222313284874, loss=3.67987060546875
train: epoch 2, loss 3.138063907623291, acc=0.07527777552604675, loss=3.138063907623291
test: epoch 2, loss 3.1713685989379883, acc=0.0833333358168602, loss=3.1713685989379883
train: epoch 3, loss 2.482682704925537, acc=0.18094444274902344, loss=2.482682704925537
test: epoch 3, loss 2.517651081085205, acc=0.13611111044883728, loss=2.517651081085205
train: epoch 4, loss 2.011141777038574, acc=0.25555557012557983, loss=2.011141777038574
test: epoch 4, loss 2.3295509815216064, acc=0.14722222089767456, loss=2.3295509815216064
train: epoch 5, loss 1.8456394672393799, acc=0.28955554962158203, loss=1.8456394672393799
test: epoch 5, loss 2.2471439838409424, acc=0.1527777761220932, loss=2.2471439838409424
train: epoch 6, loss 1.743895411491394, acc=0.32205554842948914, loss=1.743895411491394
test: epoch 6, loss 2.1298491954803467, acc=0.1666666716337204, loss=2.1298491954803467
train: epoch 7, loss 1.6685465574264526, acc=0.3433888852596283, loss=1.6685465574264526
test: epoch 7, loss 2.1621274948120117, acc=0.17499999701976776, loss=2.1621274948120117
train: epoch 8, loss 1.6129224300384521, acc=0.3638888895511627, loss=1.6129224300384521
test: epoch 8, loss 2.1476616859436035, acc=0.17777778208255768, loss=2.1476616859436035
train: epoch 9, loss 1.5757006406784058, acc=0.3756110966205597, loss=1.5757006406784058
test: epoch 9, loss 2.2112178802490234, acc=0.17777778208255768, loss=2.2112178802490234
train: epoch 10, loss 1.527584195137024, acc=0.3900555670261383, loss=1.527584195137024
test: epoch 10, loss 2.1681950092315674, acc=0.18888889253139496, loss=2.1681950092315674
train: epoch 11, loss 1.4918458461761475, acc=0.4032222330570221, loss=1.4918458461761475
test: epoch 11, loss 2.1531870365142822, acc=0.1944444477558136, loss=2.1531870365142822
train: epoch 12, loss 1.4558500051498413, acc=0.4169999957084656, loss=1.4558500051498413
test: epoch 12, loss 2.146460771560669, acc=0.1944444477558136, loss=2.146460771560669
train: epoch 13, loss 1.4283556938171387, acc=0.4252777695655823, loss=1.4283556938171387
test: epoch 13, loss 2.08003830909729, acc=0.2083333283662796, loss=2.08003830909729
train: epoch 14, loss 1.4007630348205566, acc=0.43799999356269836, loss=1.4007630348205566
test: epoch 14, loss 2.0647459030151367, acc=0.20277777314186096, loss=2.0647459030151367
train: epoch 15, loss 1.377158522605896, acc=0.4437222182750702, loss=1.377158522605896
test: epoch 15, loss 2.0654401779174805, acc=0.21388888359069824, loss=2.0654401779174805
train: epoch 16, loss 1.357181429862976, acc=0.45366665720939636, loss=1.357181429862976
test: epoch 16, loss 2.061988353729248, acc=0.21666666865348816, loss=2.061988353729248
train: epoch 17, loss 1.3371899127960205, acc=0.4615555703639984, loss=1.3371899127960205
test: epoch 17, loss 2.0438108444213867, acc=0.21944443881511688, loss=2.0438108444213867
train: epoch 18, loss 1.303361415863037, acc=0.46977776288986206, loss=1.303361415863037
test: epoch 18, loss 1.9723056554794312, acc=0.21388888359069824, loss=1.9723056554794312
train: epoch 19, loss 1.3014332056045532, acc=0.46727776527404785, loss=1.3014332056045532
test: epoch 19, loss 2.026506185531616, acc=0.22499999403953552, loss=2.026506185531616
train: epoch 20, loss 1.2912817001342773, acc=0.4723333418369293, loss=1.2912817001342773
test: epoch 20, loss 1.9174519777297974, acc=0.21666666865348816, loss=1.9174519777297974
train: epoch 21, loss 1.2786048650741577, acc=0.4776666760444641, loss=1.2786048650741577
test: epoch 21, loss 1.9678657054901123, acc=0.23333333432674408, loss=1.9678657054901123
train: epoch 22, loss 1.2581157684326172, acc=0.480388879776001, loss=1.2581157684326172
test: epoch 22, loss 2.008145332336426, acc=0.2222222238779068, loss=2.008145332336426
train: epoch 23, loss 1.2422446012496948, acc=0.4887777864933014, loss=1.2422446012496948
test: epoch 23, loss 1.9735386371612549, acc=0.23888888955116272, loss=1.9735386371612549
train: epoch 24, loss 1.2363998889923096, acc=0.4838888943195343, loss=1.2363998889923096
test: epoch 24, loss 2.0670902729034424, acc=0.21944443881511688, loss=2.0670902729034424
train: epoch 25, loss 1.218826413154602, acc=0.49316665530204773, loss=1.218826413154602
test: epoch 25, loss 1.9579957723617554, acc=0.22777777910232544, loss=1.9579957723617554
train: epoch 26, loss 1.212547779083252, acc=0.49255555868148804, loss=1.212547779083252
test: epoch 26, loss 1.985514760017395, acc=0.24166665971279144, loss=1.985514760017395
train: epoch 27, loss 1.2032864093780518, acc=0.4956111013889313, loss=1.2032864093780518
test: epoch 27, loss 1.9433470964431763, acc=0.22777777910232544, loss=1.9433470964431763
train: epoch 28, loss 1.1982256174087524, acc=0.4972222149372101, loss=1.1982256174087524
test: epoch 28, loss 2.004638195037842, acc=0.24166665971279144, loss=2.004638195037842
train: epoch 29, loss 1.1881011724472046, acc=0.4975000023841858, loss=1.1881011724472046
test: epoch 29, loss 1.9461820125579834, acc=0.24722221493721008, loss=1.9461820125579834
train: epoch 30, loss 1.1850043535232544, acc=0.5023888945579529, loss=1.1850043535232544
test: epoch 30, loss 1.9808024168014526, acc=0.25, loss=1.9808024168014526
train: epoch 31, loss 1.1845076084136963, acc=0.5017777681350708, loss=1.1845076084136963
test: epoch 31, loss 1.9343783855438232, acc=0.25, loss=1.9343783855438232
train: epoch 32, loss 1.1675105094909668, acc=0.5013889074325562, loss=1.1675105094909668
test: epoch 32, loss 1.979156732559204, acc=0.25555557012557983, loss=1.979156732559204
train: epoch 33, loss 1.1620585918426514, acc=0.5052777528762817, loss=1.1620585918426514
test: epoch 33, loss 1.910958170890808, acc=0.25555557012557983, loss=1.910958170890808
train: epoch 34, loss 1.1495661735534668, acc=0.5091111063957214, loss=1.1495661735534668
test: epoch 34, loss 1.959922194480896, acc=0.25, loss=1.959922194480896
train: epoch 35, loss 1.1602394580841064, acc=0.5081111192703247, loss=1.1602394580841064
test: epoch 35, loss 1.918912410736084, acc=0.2638888955116272, loss=1.918912410736084
train: epoch 36, loss 1.1429762840270996, acc=0.5103333592414856, loss=1.1429762840270996
test: epoch 36, loss 1.920634150505066, acc=0.2611111104488373, loss=1.920634150505066
train: epoch 37, loss 1.1319596767425537, acc=0.5236111283302307, loss=1.1319596767425537
test: epoch 37, loss 1.9377940893173218, acc=0.2638888955116272, loss=1.9377940893173218
train: epoch 38, loss 1.1323249340057373, acc=0.5138333439826965, loss=1.1323249340057373
test: epoch 38, loss 1.9592726230621338, acc=0.2527777850627899, loss=1.9592726230621338
train: epoch 39, loss 1.1347377300262451, acc=0.5135555267333984, loss=1.1347377300262451
test: epoch 39, loss 1.9569387435913086, acc=0.2666666805744171, loss=1.9569387435913086
train: epoch 40, loss 1.1114190816879272, acc=0.5251111388206482, loss=1.1114190816879272
test: epoch 40, loss 1.8984330892562866, acc=0.2611111104488373, loss=1.8984330892562866
train: epoch 41, loss 1.1208921670913696, acc=0.5186111330986023, loss=1.1208921670913696
test: epoch 41, loss 1.883872151374817, acc=0.2750000059604645, loss=1.883872151374817
train: epoch 42, loss 1.1030131578445435, acc=0.5268333554267883, loss=1.1030131578445435
test: epoch 42, loss 1.9284260272979736, acc=0.2777777910232544, loss=1.9284260272979736
train: epoch 43, loss 1.1100116968154907, acc=0.5248333215713501, loss=1.1100116968154907
test: epoch 43, loss 1.8209118843078613, acc=0.28611111640930176, loss=1.8209118843078613
train: epoch 44, loss 1.0994560718536377, acc=0.526888906955719, loss=1.0994560718536377
test: epoch 44, loss 1.7766703367233276, acc=0.28611111640930176, loss=1.7766703367233276
train: epoch 45, loss 1.0967334508895874, acc=0.5246111154556274, loss=1.0967334508895874
test: epoch 45, loss 1.8186475038528442, acc=0.28333333134651184, loss=1.8186475038528442
train: epoch 46, loss 1.091215968132019, acc=0.531166672706604, loss=1.091215968132019
test: epoch 46, loss 1.8607778549194336, acc=0.2777777910232544, loss=1.8607778549194336
train: epoch 47, loss 1.0864334106445312, acc=0.5297777652740479, loss=1.0864334106445312
test: epoch 47, loss 1.818581223487854, acc=0.28333333134651184, loss=1.818581223487854
train: epoch 48, loss 1.0910078287124634, acc=0.5289999842643738, loss=1.0910078287124634
test: epoch 48, loss 1.8400371074676514, acc=0.2888889014720917, loss=1.8400371074676514
train: epoch 49, loss 1.0870310068130493, acc=0.5253333449363708, loss=1.0870310068130493
test: epoch 49, loss 1.8874832391738892, acc=0.28333333134651184, loss=1.8874832391738892
train: epoch 50, loss 1.0833889245986938, acc=0.5296666622161865, loss=1.0833889245986938
test: epoch 50, loss 1.9714515209197998, acc=0.2805555462837219, loss=1.9714515209197998
train: epoch 51, loss 1.0715025663375854, acc=0.5308333039283752, loss=1.0715025663375854
test: epoch 51, loss 1.798732876777649, acc=0.28333333134651184, loss=1.798732876777649
train: epoch 52, loss 1.0784999132156372, acc=0.5316110849380493, loss=1.0784999132156372
test: epoch 52, loss 1.8919246196746826, acc=0.28333333134651184, loss=1.8919246196746826
train: epoch 53, loss 1.0739139318466187, acc=0.535444438457489, loss=1.0739139318466187
test: epoch 53, loss 1.8548061847686768, acc=0.28611111640930176, loss=1.8548061847686768
train: epoch 54, loss 1.068569302558899, acc=0.5341110825538635, loss=1.068569302558899
test: epoch 54, loss 1.829677700996399, acc=0.3027777671813965, loss=1.829677700996399
train: epoch 55, loss 1.073344349861145, acc=0.5311111211776733, loss=1.073344349861145
test: epoch 55, loss 1.8553718328475952, acc=0.3027777671813965, loss=1.8553718328475952
train: epoch 56, loss 1.0721042156219482, acc=0.5332777500152588, loss=1.0721042156219482
test: epoch 56, loss 1.8119100332260132, acc=0.3027777671813965, loss=1.8119100332260132
train: epoch 57, loss 1.0610191822052002, acc=0.5369444489479065, loss=1.0610191822052002
test: epoch 57, loss 1.825507640838623, acc=0.31388887763023376, loss=1.825507640838623
train: epoch 58, loss 1.0563344955444336, acc=0.538277804851532, loss=1.0563344955444336
test: epoch 58, loss 1.8781592845916748, acc=0.3083333373069763, loss=1.8781592845916748
train: epoch 59, loss 1.0619596242904663, acc=0.5316110849380493, loss=1.0619596242904663
test: epoch 59, loss 1.7956727743148804, acc=0.3083333373069763, loss=1.7956727743148804
train: epoch 60, loss 1.0487618446350098, acc=0.534166693687439, loss=1.0487618446350098
test: epoch 60, loss 1.8583662509918213, acc=0.31111112236976624, loss=1.8583662509918213
train: epoch 61, loss 1.044095516204834, acc=0.5397777557373047, loss=1.044095516204834
test: epoch 61, loss 1.8556281328201294, acc=0.31388887763023376, loss=1.8556281328201294
train: epoch 62, loss 1.0456982851028442, acc=0.5421110987663269, loss=1.0456982851028442
test: epoch 62, loss 1.8314718008041382, acc=0.3194444477558136, loss=1.8314718008041382
train: epoch 63, loss 1.0485608577728271, acc=0.5353333353996277, loss=1.0485608577728271
test: epoch 63, loss 1.903212547302246, acc=0.31111112236976624, loss=1.903212547302246
train: epoch 64, loss 1.0433566570281982, acc=0.5394999980926514, loss=1.0433566570281982
test: epoch 64, loss 1.8698798418045044, acc=0.31388887763023376, loss=1.8698798418045044
train: epoch 65, loss 1.0367224216461182, acc=0.5419999957084656, loss=1.0367224216461182
test: epoch 65, loss 1.806240200996399, acc=0.31388887763023376, loss=1.806240200996399
train: epoch 66, loss 1.01796555519104, acc=0.5472221970558167, loss=1.01796555519104
test: epoch 66, loss 1.8074039220809937, acc=0.31111112236976624, loss=1.8074039220809937
train: epoch 67, loss 1.0255566835403442, acc=0.5442777872085571, loss=1.0255566835403442
test: epoch 67, loss 1.9573203325271606, acc=0.3166666626930237, loss=1.9573203325271606
train: epoch 68, loss 1.0123265981674194, acc=0.5456666946411133, loss=1.0123265981674194
test: epoch 68, loss 1.73980712890625, acc=0.3083333373069763, loss=1.73980712890625
train: epoch 69, loss 1.0179271697998047, acc=0.5471110939979553, loss=1.0179271697998047
test: epoch 69, loss 1.9379764795303345, acc=0.3194444477558136, loss=1.9379764795303345
train: epoch 70, loss 1.0101484060287476, acc=0.5454999804496765, loss=1.0101484060287476
test: epoch 70, loss 1.940829873085022, acc=0.3222222328186035, loss=1.940829873085022
train: epoch 71, loss 1.0099854469299316, acc=0.5553333163261414, loss=1.0099854469299316
test: epoch 71, loss 1.897106647491455, acc=0.3222222328186035, loss=1.897106647491455
train: epoch 72, loss 1.0082379579544067, acc=0.5515000224113464, loss=1.0082379579544067
test: epoch 72, loss 1.8105950355529785, acc=0.3166666626930237, loss=1.8105950355529785
train: epoch 73, loss 1.0013498067855835, acc=0.5518888831138611, loss=1.0013498067855835
test: epoch 73, loss 1.8362120389938354, acc=0.3222222328186035, loss=1.8362120389938354
train: epoch 74, loss 1.0107643604278564, acc=0.5487222075462341, loss=1.0107643604278564
test: epoch 74, loss 1.7810767889022827, acc=0.31388887763023376, loss=1.7810767889022827
train: epoch 75, loss 0.9988729953765869, acc=0.5536666512489319, loss=0.9988729953765869
test: epoch 75, loss 1.7535415887832642, acc=0.3222222328186035, loss=1.7535415887832642
train: epoch 76, loss 0.9923116564750671, acc=0.5549444556236267, loss=0.9923116564750671
test: epoch 76, loss 1.8368862867355347, acc=0.3166666626930237, loss=1.8368862867355347
train: epoch 77, loss 0.9848852157592773, acc=0.5648888945579529, loss=0.9848852157592773
test: epoch 77, loss 1.7873491048812866, acc=0.3222222328186035, loss=1.7873491048812866
train: epoch 78, loss 0.9766582250595093, acc=0.5642222166061401, loss=0.9766582250595093
test: epoch 78, loss 1.801356554031372, acc=0.3194444477558136, loss=1.801356554031372
train: epoch 79, loss 0.9910408854484558, acc=0.5598888993263245, loss=0.9910408854484558
test: epoch 79, loss 1.7786146402359009, acc=0.31388887763023376, loss=1.7786146402359009
train: epoch 80, loss 0.9783163070678711, acc=0.5601666569709778, loss=0.9783163070678711
test: epoch 80, loss 1.8247700929641724, acc=0.3166666626930237, loss=1.8247700929641724
train: epoch 81, loss 0.9887551069259644, acc=0.5609999895095825, loss=0.9887551069259644
test: epoch 81, loss 1.7179348468780518, acc=0.32499998807907104, loss=1.7179348468780518
train: epoch 82, loss 0.972236156463623, acc=0.5676666498184204, loss=0.972236156463623
test: epoch 82, loss 1.871626853942871, acc=0.3194444477558136, loss=1.871626853942871
train: epoch 83, loss 0.9736154675483704, acc=0.5641111135482788, loss=0.9736154675483704
test: epoch 83, loss 1.8014572858810425, acc=0.3166666626930237, loss=1.8014572858810425
train: epoch 84, loss 0.9729476571083069, acc=0.5685555338859558, loss=0.9729476571083069
test: epoch 84, loss 1.8193775415420532, acc=0.31388887763023376, loss=1.8193775415420532
train: epoch 85, loss 0.9676204919815063, acc=0.5681111216545105, loss=0.9676204919815063
test: epoch 85, loss 1.848766803741455, acc=0.32499998807907104, loss=1.848766803741455
train: epoch 86, loss 0.967877209186554, acc=0.5672222375869751, loss=0.967877209186554
test: epoch 86, loss 1.7565463781356812, acc=0.32499998807907104, loss=1.7565463781356812
train: epoch 87, loss 0.9567416906356812, acc=0.5720000267028809, loss=0.9567416906356812
test: epoch 87, loss 1.80819571018219, acc=0.32499998807907104, loss=1.80819571018219
train: epoch 88, loss 0.9610018134117126, acc=0.5759999752044678, loss=0.9610018134117126
test: epoch 88, loss 1.8470333814620972, acc=0.3222222328186035, loss=1.8470333814620972
train: epoch 89, loss 0.9532231092453003, acc=0.5725555419921875, loss=0.9532231092453003
test: epoch 89, loss 1.8267062902450562, acc=0.3194444477558136, loss=1.8267062902450562
train: epoch 90, loss 0.9499839544296265, acc=0.575166642665863, loss=0.9499839544296265
test: epoch 90, loss 1.8654755353927612, acc=0.32777777314186096, loss=1.8654755353927612
train: epoch 91, loss 0.940115749835968, acc=0.5812222361564636, loss=0.940115749835968
test: epoch 91, loss 1.8928290605545044, acc=0.32499998807907104, loss=1.8928290605545044
train: epoch 92, loss 0.9455814957618713, acc=0.5766666531562805, loss=0.9455814957618713
test: epoch 92, loss 1.8239444494247437, acc=0.3222222328186035, loss=1.8239444494247437
train: epoch 93, loss 0.9453688859939575, acc=0.5727777481079102, loss=0.9453688859939575
test: epoch 93, loss 1.916690468788147, acc=0.3222222328186035, loss=1.916690468788147
train: epoch 94, loss 0.9339097738265991, acc=0.5814444422721863, loss=0.9339097738265991
test: epoch 94, loss 1.7948096990585327, acc=0.32499998807907104, loss=1.7948096990585327
train: epoch 95, loss 0.9394242167472839, acc=0.5798333287239075, loss=0.9394242167472839
test: epoch 95, loss 1.850223183631897, acc=0.33888888359069824, loss=1.850223183631897
train: epoch 96, loss 0.9380135536193848, acc=0.5797222256660461, loss=0.9380135536193848
test: epoch 96, loss 1.9006843566894531, acc=0.3333333432674408, loss=1.9006843566894531
train: epoch 97, loss 0.9302876591682434, acc=0.5849444270133972, loss=0.9302876591682434
test: epoch 97, loss 1.9168647527694702, acc=0.3333333432674408, loss=1.9168647527694702
train: epoch 98, loss 0.9291092753410339, acc=0.589722216129303, loss=0.9291092753410339
test: epoch 98, loss 1.7984775304794312, acc=0.3361110985279083, loss=1.7984775304794312
train: epoch 99, loss 0.9353464245796204, acc=0.5826666951179504, loss=0.9353464245796204
test: epoch 99, loss 1.8948382139205933, acc=0.3333333432674408, loss=1.8948382139205933
train: epoch 100, loss 0.9227359294891357, acc=0.5879999995231628, loss=0.9227359294891357
test: epoch 100, loss 1.8521250486373901, acc=0.3361110985279083, loss=1.8521250486373901
train: epoch 101, loss 0.9202557802200317, acc=0.582111120223999, loss=0.9202557802200317
test: epoch 101, loss 1.9552181959152222, acc=0.3361110985279083, loss=1.9552181959152222
train: epoch 102, loss 0.9229721426963806, acc=0.5833888649940491, loss=0.9229721426963806
test: epoch 102, loss 1.9130524396896362, acc=0.33888888359069824, loss=1.9130524396896362
train: epoch 103, loss 0.9268335103988647, acc=0.5831111073493958, loss=0.9268335103988647
test: epoch 103, loss 1.9054679870605469, acc=0.33888888359069824, loss=1.9054679870605469
train: epoch 104, loss 0.9191828370094299, acc=0.5849444270133972, loss=0.9191828370094299
test: epoch 104, loss 1.9038699865341187, acc=0.3305555582046509, loss=1.9038699865341187
train: epoch 105, loss 0.9140816926956177, acc=0.5881666541099548, loss=0.9140816926956177
test: epoch 105, loss 1.8589732646942139, acc=0.3444444537162781, loss=1.8589732646942139
train: epoch 106, loss 0.9168950915336609, acc=0.5905555486679077, loss=0.9168950915336609
test: epoch 106, loss 1.771207571029663, acc=0.34166666865348816, loss=1.771207571029663
train: epoch 107, loss 0.9209288358688354, acc=0.5847777724266052, loss=0.9209288358688354
test: epoch 107, loss 1.7866435050964355, acc=0.3361110985279083, loss=1.7866435050964355
train: epoch 108, loss 0.926908552646637, acc=0.582611083984375, loss=0.926908552646637
test: epoch 108, loss 1.7990458011627197, acc=0.3361110985279083, loss=1.7990458011627197
train: epoch 109, loss 0.9089978933334351, acc=0.5915555357933044, loss=0.9089978933334351
test: epoch 109, loss 1.792230248451233, acc=0.3333333432674408, loss=1.792230248451233
train: epoch 110, loss 0.9080061316490173, acc=0.5917222499847412, loss=0.9080061316490173
test: epoch 110, loss 1.8097120523452759, acc=0.3499999940395355, loss=1.8097120523452759
train: epoch 111, loss 0.9108700156211853, acc=0.5903333425521851, loss=0.9108700156211853
test: epoch 111, loss 1.895206093788147, acc=0.34166666865348816, loss=1.895206093788147
train: epoch 112, loss 0.9180747866630554, acc=0.5891666412353516, loss=0.9180747866630554
test: epoch 112, loss 1.7758941650390625, acc=0.3305555582046509, loss=1.7758941650390625
train: epoch 113, loss 0.9024362564086914, acc=0.5899444222450256, loss=0.9024362564086914
test: epoch 113, loss 1.8274849653244019, acc=0.3444444537162781, loss=1.8274849653244019
train: epoch 114, loss 0.9156749248504639, acc=0.5867778062820435, loss=0.9156749248504639
test: epoch 114, loss 1.8785213232040405, acc=0.3499999940395355, loss=1.8785213232040405
train: epoch 115, loss 0.903714120388031, acc=0.5946666598320007, loss=0.903714120388031
test: epoch 115, loss 1.8339576721191406, acc=0.35277777910232544, loss=1.8339576721191406
train: epoch 116, loss 0.9046337008476257, acc=0.5903333425521851, loss=0.9046337008476257
test: epoch 116, loss 1.6930116415023804, acc=0.35555556416511536, loss=1.6930116415023804
train: epoch 117, loss 0.891788125038147, acc=0.5976666808128357, loss=0.891788125038147
test: epoch 117, loss 1.8152741193771362, acc=0.35555556416511536, loss=1.8152741193771362
train: epoch 118, loss 0.9133315086364746, acc=0.5880555510520935, loss=0.9133315086364746
test: epoch 118, loss 1.6867672204971313, acc=0.3638888895511627, loss=1.6867672204971313
train: epoch 119, loss 0.9102545976638794, acc=0.589388906955719, loss=0.9102545976638794
test: epoch 119, loss 1.8642958402633667, acc=0.3611111044883728, loss=1.8642958402633667
train: epoch 120, loss 0.894846498966217, acc=0.5943333506584167, loss=0.894846498966217
test: epoch 120, loss 1.723833441734314, acc=0.3638888895511627, loss=1.723833441734314
train: epoch 121, loss 0.8973745107650757, acc=0.5967222452163696, loss=0.8973745107650757
test: epoch 121, loss 1.7357791662216187, acc=0.3611111044883728, loss=1.7357791662216187
train: epoch 122, loss 0.8898268938064575, acc=0.5984444618225098, loss=0.8898268938064575
test: epoch 122, loss 1.7608897686004639, acc=0.3611111044883728, loss=1.7608897686004639
train: epoch 123, loss 0.8864482641220093, acc=0.593833327293396, loss=0.8864482641220093
test: epoch 123, loss 1.8652490377426147, acc=0.3611111044883728, loss=1.8652490377426147
train: epoch 124, loss 0.8962590098381042, acc=0.5961111187934875, loss=0.8962590098381042
test: epoch 124, loss 1.8882769346237183, acc=0.3638888895511627, loss=1.8882769346237183
train: epoch 125, loss 0.8883922696113586, acc=0.5968888998031616, loss=0.8883922696113586
test: epoch 125, loss 1.8357443809509277, acc=0.3611111044883728, loss=1.8357443809509277
train: epoch 126, loss 0.8951455950737, acc=0.5927222371101379, loss=0.8951455950737
test: epoch 126, loss 1.8239037990570068, acc=0.3638888895511627, loss=1.8239037990570068
train: epoch 127, loss 0.880072295665741, acc=0.6005555391311646, loss=0.880072295665741
test: epoch 127, loss 1.807690143585205, acc=0.36666667461395264, loss=1.807690143585205
train: epoch 128, loss 0.8750361204147339, acc=0.6033889055252075, loss=0.8750361204147339
test: epoch 128, loss 1.7788007259368896, acc=0.3638888895511627, loss=1.7788007259368896
train: epoch 129, loss 0.8835766315460205, acc=0.5954444408416748, loss=0.8835766315460205
test: epoch 129, loss 1.8540958166122437, acc=0.3611111044883728, loss=1.8540958166122437
train: epoch 130, loss 0.8862017393112183, acc=0.5991111397743225, loss=0.8862017393112183
test: epoch 130, loss 1.697954535484314, acc=0.3611111044883728, loss=1.697954535484314
train: epoch 131, loss 0.883815348148346, acc=0.6013888716697693, loss=0.883815348148346
test: epoch 131, loss 1.8501300811767578, acc=0.3638888895511627, loss=1.8501300811767578
train: epoch 132, loss 0.8824541568756104, acc=0.5994444489479065, loss=0.8824541568756104
test: epoch 132, loss 1.6652361154556274, acc=0.3611111044883728, loss=1.6652361154556274
train: epoch 133, loss 0.8772128820419312, acc=0.6023333072662354, loss=0.8772128820419312
test: epoch 133, loss 1.7364519834518433, acc=0.3638888895511627, loss=1.7364519834518433
train: epoch 134, loss 0.8788267374038696, acc=0.6023889183998108, loss=0.8788267374038696
test: epoch 134, loss 1.788673758506775, acc=0.3611111044883728, loss=1.788673758506775
train: epoch 135, loss 0.8812540769577026, acc=0.5985555648803711, loss=0.8812540769577026
test: epoch 135, loss 1.7718051671981812, acc=0.3722222149372101, loss=1.7718051671981812
train: epoch 136, loss 0.8787201642990112, acc=0.6016111373901367, loss=0.8787201642990112
test: epoch 136, loss 1.9905362129211426, acc=0.3638888895511627, loss=1.9905362129211426
train: epoch 137, loss 0.8688639998435974, acc=0.6036666631698608, loss=0.8688639998435974
test: epoch 137, loss 1.860629677772522, acc=0.3638888895511627, loss=1.860629677772522
train: epoch 138, loss 0.8647280335426331, acc=0.6042222380638123, loss=0.8647280335426331
test: epoch 138, loss 1.8071730136871338, acc=0.36944442987442017, loss=1.8071730136871338
train: epoch 139, loss 0.8696620464324951, acc=0.6043888926506042, loss=0.8696620464324951
test: epoch 139, loss 1.8993208408355713, acc=0.3638888895511627, loss=1.8993208408355713
train: epoch 140, loss 0.8769579529762268, acc=0.60188889503479, loss=0.8769579529762268
test: epoch 140, loss 1.7809380292892456, acc=0.36944442987442017, loss=1.7809380292892456
train: epoch 141, loss 0.8683863282203674, acc=0.6073333621025085, loss=0.8683863282203674
test: epoch 141, loss 1.786224126815796, acc=0.3638888895511627, loss=1.786224126815796
train: epoch 142, loss 0.8733920454978943, acc=0.6064444184303284, loss=0.8733920454978943
test: epoch 142, loss 1.8704482316970825, acc=0.3611111044883728, loss=1.8704482316970825
train: epoch 143, loss 0.8678656816482544, acc=0.6083889007568359, loss=0.8678656816482544
test: epoch 143, loss 1.9944285154342651, acc=0.3638888895511627, loss=1.9944285154342651
train: epoch 144, loss 0.8676018118858337, acc=0.6129444241523743, loss=0.8676018118858337
test: epoch 144, loss 1.8393453359603882, acc=0.36944442987442017, loss=1.8393453359603882
train: epoch 145, loss 0.8606956005096436, acc=0.613611102104187, loss=0.8606956005096436
test: epoch 145, loss 1.8758087158203125, acc=0.3638888895511627, loss=1.8758087158203125
train: epoch 146, loss 0.8638320565223694, acc=0.6087777614593506, loss=0.8638320565223694
test: epoch 146, loss 1.8111318349838257, acc=0.36666667461395264, loss=1.8111318349838257
train: epoch 147, loss 0.8682094216346741, acc=0.6121110916137695, loss=0.8682094216346741
test: epoch 147, loss 1.9709150791168213, acc=0.3611111044883728, loss=1.9709150791168213
train: epoch 148, loss 0.8579393625259399, acc=0.6165555715560913, loss=0.8579393625259399
test: epoch 148, loss 1.955072045326233, acc=0.3722222149372101, loss=1.955072045326233
train: epoch 149, loss 0.85821133852005, acc=0.6147222518920898, loss=0.85821133852005
test: epoch 149, loss 1.8757139444351196, acc=0.375, loss=1.8757139444351196
train: epoch 150, loss 0.8591956496238708, acc=0.6178333163261414, loss=0.8591956496238708
test: epoch 150, loss 1.9579675197601318, acc=0.36944442987442017, loss=1.9579675197601318
