# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=false", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=179178991, receiver_embed_dim=64, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.7589359283447266, acc=0.10861111432313919, loss=2.7589359283447266
test: epoch 1, loss 2.714329481124878, acc=0.125, loss=2.714329481124878
train: epoch 2, loss 1.8277356624603271, acc=0.266222208738327, loss=1.8277356624603271
test: epoch 2, loss 3.618074655532837, acc=0.1666666716337204, loss=3.618074655532837
train: epoch 3, loss 1.524754524230957, acc=0.3426111042499542, loss=1.524754524230957
test: epoch 3, loss 3.0423998832702637, acc=0.21666666865348816, loss=3.0423998832702637
train: epoch 4, loss 1.3015940189361572, acc=0.41277778148651123, loss=1.3015940189361572
test: epoch 4, loss 2.8615574836730957, acc=0.24722221493721008, loss=2.8615574836730957
train: epoch 5, loss 1.1901799440383911, acc=0.4653888940811157, loss=1.1901799440383911
test: epoch 5, loss 2.8514931201934814, acc=0.2638888955116272, loss=2.8514931201934814
train: epoch 6, loss 1.038913369178772, acc=0.5361666679382324, loss=1.038913369178772
test: epoch 6, loss 2.9748454093933105, acc=0.21111111342906952, loss=2.9748454093933105
train: epoch 7, loss 0.9407442212104797, acc=0.5989444255828857, loss=0.9407442212104797
test: epoch 7, loss 1.807186245918274, acc=0.3722222149372101, loss=1.807186245918274
train: epoch 8, loss 0.6653214693069458, acc=0.7204444408416748, loss=0.6653214693069458
test: epoch 8, loss 3.048496961593628, acc=0.2916666567325592, loss=3.048496961593628
train: epoch 9, loss 0.5872336626052856, acc=0.7513333559036255, loss=0.5872336626052856
test: epoch 9, loss 2.219006061553955, acc=0.3888888955116272, loss=2.219006061553955
train: epoch 10, loss 0.44560620188713074, acc=0.8140555620193481, loss=0.44560620188713074
test: epoch 10, loss 2.306273937225342, acc=0.4027777910232544, loss=2.306273937225342
train: epoch 11, loss 0.3537416458129883, acc=0.8501111268997192, loss=0.3537416458129883
test: epoch 11, loss 1.8629615306854248, acc=0.4722222089767456, loss=1.8629615306854248
train: epoch 12, loss 0.3253593444824219, acc=0.8630555272102356, loss=0.3253593444824219
test: epoch 12, loss 1.7214196920394897, acc=0.4972222149372101, loss=1.7214196920394897
train: epoch 13, loss 0.28906047344207764, acc=0.8769444227218628, loss=0.28906047344207764
test: epoch 13, loss 1.849032998085022, acc=0.45277777314186096, loss=1.849032998085022
train: epoch 14, loss 0.32556280493736267, acc=0.866777777671814, loss=0.32556280493736267
test: epoch 14, loss 1.4224193096160889, acc=0.5027777552604675, loss=1.4224193096160889
train: epoch 15, loss 0.2755907475948334, acc=0.8796666860580444, loss=0.2755907475948334
test: epoch 15, loss 1.3744722604751587, acc=0.5166666507720947, loss=1.3744722604751587
train: epoch 16, loss 0.27913862466812134, acc=0.8817222118377686, loss=0.27913862466812134
test: epoch 16, loss 1.3698463439941406, acc=0.5888888835906982, loss=1.3698463439941406
train: epoch 17, loss 0.2677661180496216, acc=0.8845555782318115, loss=0.2677661180496216
test: epoch 17, loss 2.2381601333618164, acc=0.4611110985279083, loss=2.2381601333618164
train: epoch 18, loss 0.2465250939130783, acc=0.8922777771949768, loss=0.2465250939130783
test: epoch 18, loss 1.2215169668197632, acc=0.5111111402511597, loss=1.2215169668197632
train: epoch 19, loss 0.28050151467323303, acc=0.8803889155387878, loss=0.28050151467323303
test: epoch 19, loss 1.9184077978134155, acc=0.46666666865348816, loss=1.9184077978134155
train: epoch 20, loss 0.23888814449310303, acc=0.894944429397583, loss=0.23888814449310303
test: epoch 20, loss 1.340600848197937, acc=0.5527777671813965, loss=1.340600848197937
train: epoch 21, loss 0.2416444718837738, acc=0.8942221999168396, loss=0.2416444718837738
test: epoch 21, loss 1.9359498023986816, acc=0.5138888955116272, loss=1.9359498023986816
train: epoch 22, loss 0.2493003010749817, acc=0.89083331823349, loss=0.2493003010749817
test: epoch 22, loss 1.532090663909912, acc=0.4861111044883728, loss=1.532090663909912
train: epoch 23, loss 0.22617802023887634, acc=0.899222195148468, loss=0.22617802023887634
test: epoch 23, loss 1.5549898147583008, acc=0.4055555462837219, loss=1.5549898147583008
train: epoch 24, loss 0.23422640562057495, acc=0.8984444737434387, loss=0.23422640562057495
test: epoch 24, loss 1.9419641494750977, acc=0.4277777671813965, loss=1.9419641494750977
train: epoch 25, loss 0.2215641736984253, acc=0.9016110897064209, loss=0.2215641736984253
test: epoch 25, loss 1.7885074615478516, acc=0.5083333253860474, loss=1.7885074615478516
train: epoch 26, loss 0.23064430058002472, acc=0.8978888988494873, loss=0.23064430058002472
test: epoch 26, loss 1.3372480869293213, acc=0.5111111402511597, loss=1.3372480869293213
train: epoch 27, loss 0.2383096069097519, acc=0.8952777981758118, loss=0.2383096069097519
test: epoch 27, loss 0.9644066095352173, acc=0.6138888597488403, loss=0.9644066095352173
train: epoch 28, loss 0.21496474742889404, acc=0.9049999713897705, loss=0.21496474742889404
test: epoch 28, loss 1.2756017446517944, acc=0.5805555582046509, loss=1.2756017446517944
train: epoch 29, loss 0.20878738164901733, acc=0.9064444303512573, loss=0.20878738164901733
test: epoch 29, loss 1.405795693397522, acc=0.5138888955116272, loss=1.405795693397522
train: epoch 30, loss 0.19925911724567413, acc=0.9164999723434448, loss=0.19925911724567413
test: epoch 30, loss 1.673087477684021, acc=0.5555555820465088, loss=1.673087477684021
train: epoch 31, loss 0.16337431967258453, acc=0.9434444308280945, loss=0.16337431967258453
test: epoch 31, loss 1.5506654977798462, acc=0.5694444179534912, loss=1.5506654977798462
train: epoch 32, loss 0.18107721209526062, acc=0.9356111288070679, loss=0.18107721209526062
test: epoch 32, loss 1.3024455308914185, acc=0.574999988079071, loss=1.3024455308914185
train: epoch 33, loss 0.14576610922813416, acc=0.949999988079071, loss=0.14576610922813416
test: epoch 33, loss 1.1755213737487793, acc=0.6166666746139526, loss=1.1755213737487793
train: epoch 34, loss 0.14880988001823425, acc=0.949055552482605, loss=0.14880988001823425
test: epoch 34, loss 1.263648271560669, acc=0.5833333134651184, loss=1.263648271560669
train: epoch 35, loss 0.14572253823280334, acc=0.9517222046852112, loss=0.14572253823280334
test: epoch 35, loss 1.2253823280334473, acc=0.6499999761581421, loss=1.2253823280334473
train: epoch 36, loss 0.13462449610233307, acc=0.952833354473114, loss=0.13462449610233307
test: epoch 36, loss 1.0113682746887207, acc=0.6527777910232544, loss=1.0113682746887207
train: epoch 37, loss 0.1370336264371872, acc=0.9532222151756287, loss=0.1370336264371872
test: epoch 37, loss 1.1054848432540894, acc=0.6583333611488342, loss=1.1054848432540894
train: epoch 38, loss 0.15732181072235107, acc=0.9467222094535828, loss=0.15732181072235107
test: epoch 38, loss 1.0585370063781738, acc=0.699999988079071, loss=1.0585370063781738
train: epoch 39, loss 0.1258545219898224, acc=0.9583888649940491, loss=0.1258545219898224
test: epoch 39, loss 1.4550844430923462, acc=0.6888889074325562, loss=1.4550844430923462
train: epoch 40, loss 0.14101137220859528, acc=0.9541666507720947, loss=0.14101137220859528
test: epoch 40, loss 1.3166943788528442, acc=0.6305555701255798, loss=1.3166943788528442
train: epoch 41, loss 0.14352338016033173, acc=0.9514999985694885, loss=0.14352338016033173
test: epoch 41, loss 0.8353967070579529, acc=0.7388888597488403, loss=0.8353967070579529
train: epoch 42, loss 0.12010538578033447, acc=0.9592221975326538, loss=0.12010538578033447
test: epoch 42, loss 1.1880550384521484, acc=0.7083333134651184, loss=1.1880550384521484
train: epoch 43, loss 0.12382950633764267, acc=0.9575555324554443, loss=0.12382950633764267
test: epoch 43, loss 0.8758096098899841, acc=0.7416666746139526, loss=0.8758096098899841
train: epoch 44, loss 0.12592388689517975, acc=0.9579444527626038, loss=0.12592388689517975
test: epoch 44, loss 0.6937713623046875, acc=0.7777777910232544, loss=0.6937713623046875
train: epoch 45, loss 0.11925161629915237, acc=0.9595555663108826, loss=0.11925161629915237
test: epoch 45, loss 0.7491077184677124, acc=0.8027777671813965, loss=0.7491077184677124
train: epoch 46, loss 0.11605691909790039, acc=0.9616666436195374, loss=0.11605691909790039
test: epoch 46, loss 0.8479878902435303, acc=0.7888888716697693, loss=0.8479878902435303
train: epoch 47, loss 0.11165616661310196, acc=0.9651666879653931, loss=0.11165616661310196
test: epoch 47, loss 0.9691388010978699, acc=0.7666666507720947, loss=0.9691388010978699
train: epoch 48, loss 0.12740296125411987, acc=0.9580000042915344, loss=0.12740296125411987
test: epoch 48, loss 0.975161075592041, acc=0.7388888597488403, loss=0.975161075592041
train: epoch 49, loss 0.11914921551942825, acc=0.9589444398880005, loss=0.11914921551942825
test: epoch 49, loss 0.945425271987915, acc=0.7666666507720947, loss=0.945425271987915
train: epoch 50, loss 0.09897716343402863, acc=0.9672777652740479, loss=0.09897716343402863
test: epoch 50, loss 0.5634652972221375, acc=0.8361111283302307, loss=0.5634652972221375
train: epoch 51, loss 0.10823029279708862, acc=0.9666666388511658, loss=0.10823029279708862
test: epoch 51, loss 0.4547487199306488, acc=0.855555534362793, loss=0.4547487199306488
train: epoch 52, loss 0.10838646441698074, acc=0.9633888602256775, loss=0.10838646441698074
test: epoch 52, loss 0.39993125200271606, acc=0.8500000238418579, loss=0.39993125200271606
train: epoch 53, loss 0.09093212336301804, acc=0.9702222347259521, loss=0.09093212336301804
test: epoch 53, loss 0.6284539103507996, acc=0.8444444537162781, loss=0.6284539103507996
train: epoch 54, loss 0.09310600906610489, acc=0.969944417476654, loss=0.09310600906610489
test: epoch 54, loss 1.0363134145736694, acc=0.7583333253860474, loss=1.0363134145736694
train: epoch 55, loss 0.12766538560390472, acc=0.9583333134651184, loss=0.12766538560390472
test: epoch 55, loss 0.4349972605705261, acc=0.8361111283302307, loss=0.4349972605705261
train: epoch 56, loss 0.09400048851966858, acc=0.9696111083030701, loss=0.09400048851966858
test: epoch 56, loss 0.31126388907432556, acc=0.8861111402511597, loss=0.31126388907432556
train: epoch 57, loss 0.10871657729148865, acc=0.9631666541099548, loss=0.10871657729148865
test: epoch 57, loss 0.6326862573623657, acc=0.8083333373069763, loss=0.6326862573623657
train: epoch 58, loss 0.08864117413759232, acc=0.9711111187934875, loss=0.08864117413759232
test: epoch 58, loss 0.5497693419456482, acc=0.8416666388511658, loss=0.5497693419456482
train: epoch 59, loss 0.08366064727306366, acc=0.9716110825538635, loss=0.08366064727306366
test: epoch 59, loss 0.37846285104751587, acc=0.8805555701255798, loss=0.37846285104751587
train: epoch 60, loss 0.07466049492359161, acc=0.9764999747276306, loss=0.07466049492359161
test: epoch 60, loss 1.0174498558044434, acc=0.8166666626930237, loss=1.0174498558044434
train: epoch 61, loss 0.11089349538087845, acc=0.9640555381774902, loss=0.11089349538087845
test: epoch 61, loss 0.4424629211425781, acc=0.855555534362793, loss=0.4424629211425781
train: epoch 62, loss 0.08446979522705078, acc=0.9711111187934875, loss=0.08446979522705078
test: epoch 62, loss 0.6856594085693359, acc=0.8444444537162781, loss=0.6856594085693359
train: epoch 63, loss 0.11011205613613129, acc=0.9632222056388855, loss=0.11011205613613129
test: epoch 63, loss 0.5832957029342651, acc=0.8111110925674438, loss=0.5832957029342651
train: epoch 64, loss 0.08237571269273758, acc=0.9708333611488342, loss=0.08237571269273758
test: epoch 64, loss 0.4973369836807251, acc=0.8305555582046509, loss=0.4973369836807251
train: epoch 65, loss 0.07052085548639297, acc=0.9762222170829773, loss=0.07052085548639297
test: epoch 65, loss 0.5661355257034302, acc=0.8472222089767456, loss=0.5661355257034302
train: epoch 66, loss 0.07789194583892822, acc=0.9741111397743225, loss=0.07789194583892822
test: epoch 66, loss 0.5981071591377258, acc=0.8722222447395325, loss=0.5981071591377258
train: epoch 67, loss 0.09874691069126129, acc=0.9695000052452087, loss=0.09874691069126129
test: epoch 67, loss 0.5929709672927856, acc=0.8805555701255798, loss=0.5929709672927856
train: epoch 68, loss 0.09494569897651672, acc=0.9707221984863281, loss=0.09494569897651672
test: epoch 68, loss 0.5262408256530762, acc=0.8722222447395325, loss=0.5262408256530762
train: epoch 69, loss 0.08162257075309753, acc=0.9742222428321838, loss=0.08162257075309753
test: epoch 69, loss 0.6028455495834351, acc=0.875, loss=0.6028455495834351
train: epoch 70, loss 0.058524131774902344, acc=0.9802777767181396, loss=0.058524131774902344
test: epoch 70, loss 0.4595542252063751, acc=0.8694444298744202, loss=0.4595542252063751
train: epoch 71, loss 0.09251508861780167, acc=0.9707777500152588, loss=0.09251508861780167
test: epoch 71, loss 0.4722730815410614, acc=0.8694444298744202, loss=0.4722730815410614
train: epoch 72, loss 0.09225940704345703, acc=0.9738888740539551, loss=0.09225940704345703
test: epoch 72, loss 0.47858065366744995, acc=0.8805555701255798, loss=0.47858065366744995
train: epoch 73, loss 0.09210022538900375, acc=0.972611129283905, loss=0.09210022538900375
test: epoch 73, loss 0.4289802610874176, acc=0.8611111044883728, loss=0.4289802610874176
train: epoch 74, loss 0.06244726479053497, acc=0.9789999723434448, loss=0.06244726479053497
test: epoch 74, loss 0.756519079208374, acc=0.875, loss=0.756519079208374
train: epoch 75, loss 0.09412240236997604, acc=0.9704999923706055, loss=0.09412240236997604
test: epoch 75, loss 0.3224482834339142, acc=0.8694444298744202, loss=0.3224482834339142
train: epoch 76, loss 0.07985042035579681, acc=0.975777804851532, loss=0.07985042035579681
test: epoch 76, loss 0.8187243938446045, acc=0.8361111283302307, loss=0.8187243938446045
train: epoch 77, loss 0.07712720334529877, acc=0.9751666784286499, loss=0.07712720334529877
test: epoch 77, loss 0.5654882192611694, acc=0.824999988079071, loss=0.5654882192611694
train: epoch 78, loss 0.07075484097003937, acc=0.9763333201408386, loss=0.07075484097003937
test: epoch 78, loss 0.32275861501693726, acc=0.8861111402511597, loss=0.32275861501693726
train: epoch 79, loss 0.07218801975250244, acc=0.9773333072662354, loss=0.07218801975250244
test: epoch 79, loss 0.3671412169933319, acc=0.894444465637207, loss=0.3671412169933319
train: epoch 80, loss 0.10137642920017242, acc=0.9682222008705139, loss=0.10137642920017242
test: epoch 80, loss 0.34474533796310425, acc=0.9027777910232544, loss=0.34474533796310425
train: epoch 81, loss 0.06480498611927032, acc=0.9772777557373047, loss=0.06480498611927032
test: epoch 81, loss 0.686599850654602, acc=0.8583333492279053, loss=0.686599850654602
train: epoch 82, loss 0.09194540232419968, acc=0.972944438457489, loss=0.09194540232419968
test: epoch 82, loss 0.2809390425682068, acc=0.9138888716697693, loss=0.2809390425682068
train: epoch 83, loss 0.060425449162721634, acc=0.9785555601119995, loss=0.060425449162721634
test: epoch 83, loss 0.40394747257232666, acc=0.8833333253860474, loss=0.40394747257232666
train: epoch 84, loss 0.06769111752510071, acc=0.9783333539962769, loss=0.06769111752510071
test: epoch 84, loss 0.40239980816841125, acc=0.9055555462837219, loss=0.40239980816841125
train: epoch 85, loss 0.11673703044652939, acc=0.9653333425521851, loss=0.11673703044652939
test: epoch 85, loss 0.40535229444503784, acc=0.8916666507720947, loss=0.40535229444503784
train: epoch 86, loss 0.07556913048028946, acc=0.975777804851532, loss=0.07556913048028946
test: epoch 86, loss 0.5550978183746338, acc=0.8611111044883728, loss=0.5550978183746338
train: epoch 87, loss 0.09049542993307114, acc=0.9739999771118164, loss=0.09049542993307114
test: epoch 87, loss 0.2926860451698303, acc=0.9083333611488342, loss=0.2926860451698303
train: epoch 88, loss 0.10047191381454468, acc=0.968666672706604, loss=0.10047191381454468
test: epoch 88, loss 0.3165348172187805, acc=0.9055555462837219, loss=0.3165348172187805
train: epoch 89, loss 0.06337771564722061, acc=0.9783333539962769, loss=0.06337771564722061
test: epoch 89, loss 0.20576536655426025, acc=0.9222221970558167, loss=0.20576536655426025
train: epoch 90, loss 0.051316775381565094, acc=0.9826666712760925, loss=0.051316775381565094
test: epoch 90, loss 0.15829205513000488, acc=0.949999988079071, loss=0.15829205513000488
train: epoch 91, loss 0.08437300473451614, acc=0.9764444231987, loss=0.08437300473451614
test: epoch 91, loss 0.1102311760187149, acc=0.9638888835906982, loss=0.1102311760187149
train: epoch 92, loss 0.04889993369579315, acc=0.9829444289207458, loss=0.04889993369579315
test: epoch 92, loss 0.05462539941072464, acc=0.980555534362793, loss=0.05462539941072464
train: epoch 93, loss 0.03816741704940796, acc=0.9864444732666016, loss=0.03816741704940796
test: epoch 93, loss 0.17117781937122345, acc=0.9527778029441833, loss=0.17117781937122345
train: epoch 94, loss 0.09915851056575775, acc=0.9628888964653015, loss=0.09915851056575775
test: epoch 94, loss 0.15967318415641785, acc=0.9305555820465088, loss=0.15967318415641785
train: epoch 95, loss 0.11268362402915955, acc=0.9651111364364624, loss=0.11268362402915955
test: epoch 95, loss 0.04748813807964325, acc=0.980555534362793, loss=0.04748813807964325
train: epoch 96, loss 0.04231826961040497, acc=0.9836111068725586, loss=0.04231826961040497
test: epoch 96, loss 0.06397824734449387, acc=0.980555534362793, loss=0.06397824734449387
train: epoch 97, loss 0.05548745021224022, acc=0.9818333387374878, loss=0.05548745021224022
test: epoch 97, loss 0.09872104227542877, acc=0.9750000238418579, loss=0.09872104227542877
train: epoch 98, loss 0.06413240730762482, acc=0.9791666865348816, loss=0.06413240730762482
test: epoch 98, loss 0.08318699151277542, acc=0.9777777791023254, loss=0.08318699151277542
train: epoch 99, loss 0.03510076552629471, acc=0.9856666922569275, loss=0.03510076552629471
test: epoch 99, loss 0.04840254411101341, acc=0.980555534362793, loss=0.04840254411101341
train: epoch 100, loss 0.08619848638772964, acc=0.9743888974189758, loss=0.08619848638772964
test: epoch 100, loss 0.06268968433141708, acc=0.980555534362793, loss=0.06268968433141708
train: epoch 101, loss 0.03626378998160362, acc=0.9856111407279968, loss=0.03626378998160362
test: epoch 101, loss 0.06554066389799118, acc=0.980555534362793, loss=0.06554066389799118
train: epoch 102, loss 0.05807312950491905, acc=0.9804444313049316, loss=0.05807312950491905
test: epoch 102, loss 0.047365300357341766, acc=0.980555534362793, loss=0.047365300357341766
train: epoch 103, loss 0.07013700157403946, acc=0.979888916015625, loss=0.07013700157403946
test: epoch 103, loss 0.04025573283433914, acc=0.980555534362793, loss=0.04025573283433914
train: epoch 104, loss 0.0739579126238823, acc=0.9782778024673462, loss=0.0739579126238823
test: epoch 104, loss 0.05445840582251549, acc=0.980555534362793, loss=0.05445840582251549
train: epoch 105, loss 0.04545172303915024, acc=0.983222246170044, loss=0.04545172303915024
test: epoch 105, loss 0.05340978875756264, acc=0.980555534362793, loss=0.05340978875756264
train: epoch 106, loss 0.04141521453857422, acc=0.9836111068725586, loss=0.04141521453857422
test: epoch 106, loss 0.055106036365032196, acc=0.980555534362793, loss=0.055106036365032196
train: epoch 107, loss 0.034541741013526917, acc=0.9850555658340454, loss=0.034541741013526917
test: epoch 107, loss 0.04679279401898384, acc=0.980555534362793, loss=0.04679279401898384
train: epoch 108, loss 0.12429037690162659, acc=0.9646111130714417, loss=0.12429037690162659
test: epoch 108, loss 0.06953705102205276, acc=0.9750000238418579, loss=0.06953705102205276
train: epoch 109, loss 0.04243474081158638, acc=0.9833889007568359, loss=0.04243474081158638
test: epoch 109, loss 0.0829857736825943, acc=0.9750000238418579, loss=0.0829857736825943
train: epoch 110, loss 0.11636539548635483, acc=0.968666672706604, loss=0.11636539548635483
test: epoch 110, loss 0.08873472362756729, acc=0.9694444537162781, loss=0.08873472362756729
train: epoch 111, loss 0.051139842718839645, acc=0.9815000295639038, loss=0.051139842718839645
test: epoch 111, loss 0.08773539215326309, acc=0.9750000238418579, loss=0.08773539215326309
train: epoch 112, loss 0.06339004635810852, acc=0.9790555834770203, loss=0.06339004635810852
test: epoch 112, loss 0.19897830486297607, acc=0.9583333134651184, loss=0.19897830486297607
train: epoch 113, loss 0.08843304216861725, acc=0.973111093044281, loss=0.08843304216861725
test: epoch 113, loss 0.08453189581632614, acc=0.9722222089767456, loss=0.08453189581632614
train: epoch 114, loss 0.06399129331111908, acc=0.9768333435058594, loss=0.06399129331111908
test: epoch 114, loss 0.040194280445575714, acc=0.980555534362793, loss=0.040194280445575714
train: epoch 115, loss 0.08976201713085175, acc=0.9763888716697693, loss=0.08976201713085175
test: epoch 115, loss 0.07307174801826477, acc=0.9777777791023254, loss=0.07307174801826477
train: epoch 116, loss 0.05701792985200882, acc=0.9817777872085571, loss=0.05701792985200882
test: epoch 116, loss 0.06414777785539627, acc=0.9777777791023254, loss=0.06414777785539627
train: epoch 117, loss 0.033985212445259094, acc=0.9863888621330261, loss=0.033985212445259094
test: epoch 117, loss 0.06438535451889038, acc=0.980555534362793, loss=0.06438535451889038
train: epoch 118, loss 0.04665552079677582, acc=0.9842777848243713, loss=0.04665552079677582
test: epoch 118, loss 0.06864789128303528, acc=0.9777777791023254, loss=0.06864789128303528
train: epoch 119, loss 0.06686893105506897, acc=0.9788888692855835, loss=0.06686893105506897
test: epoch 119, loss 0.08217207342386246, acc=0.9750000238418579, loss=0.08217207342386246
train: epoch 120, loss 0.06064324826002121, acc=0.9807222485542297, loss=0.06064324826002121
test: epoch 120, loss 0.1826115995645523, acc=0.949999988079071, loss=0.1826115995645523
train: epoch 121, loss 0.09407588839530945, acc=0.9676111340522766, loss=0.09407588839530945
test: epoch 121, loss 0.08935581892728806, acc=0.9666666388511658, loss=0.08935581892728806
train: epoch 122, loss 0.09799110889434814, acc=0.9676666855812073, loss=0.09799110889434814
test: epoch 122, loss 0.1481647789478302, acc=0.9527778029441833, loss=0.1481647789478302
train: epoch 123, loss 0.10358434915542603, acc=0.9671666622161865, loss=0.10358434915542603
test: epoch 123, loss 0.08594781160354614, acc=0.9666666388511658, loss=0.08594781160354614
train: epoch 124, loss 0.05594503507018089, acc=0.9783333539962769, loss=0.05594503507018089
test: epoch 124, loss 0.07184255868196487, acc=0.9750000238418579, loss=0.07184255868196487
train: epoch 125, loss 0.050902727991342545, acc=0.980555534362793, loss=0.050902727991342545
test: epoch 125, loss 0.0805569589138031, acc=0.9750000238418579, loss=0.0805569589138031
train: epoch 126, loss 0.09798867255449295, acc=0.9676111340522766, loss=0.09798867255449295
test: epoch 126, loss 0.0863732323050499, acc=0.9694444537162781, loss=0.0863732323050499
train: epoch 127, loss 0.08441769331693649, acc=0.9732778072357178, loss=0.08441769331693649
test: epoch 127, loss 0.07679835706949234, acc=0.9750000238418579, loss=0.07679835706949234
train: epoch 128, loss 0.04281522333621979, acc=0.981166660785675, loss=0.04281522333621979
test: epoch 128, loss 0.06898251175880432, acc=0.9750000238418579, loss=0.06898251175880432
train: epoch 129, loss 0.044253285974264145, acc=0.976722240447998, loss=0.044253285974264145
test: epoch 129, loss 0.0703643187880516, acc=0.9750000238418579, loss=0.0703643187880516
train: epoch 130, loss 0.08050952106714249, acc=0.9738333225250244, loss=0.08050952106714249
test: epoch 130, loss 0.06486473232507706, acc=0.9750000238418579, loss=0.06486473232507706
train: epoch 131, loss 0.03623390570282936, acc=0.9781110882759094, loss=0.03623390570282936
test: epoch 131, loss 0.0725518986582756, acc=0.9750000238418579, loss=0.0725518986582756
train: epoch 132, loss 0.03793317824602127, acc=0.9772777557373047, loss=0.03793317824602127
test: epoch 132, loss 0.06712441146373749, acc=0.9750000238418579, loss=0.06712441146373749
train: epoch 133, loss 0.036221954971551895, acc=0.9783333539962769, loss=0.036221954971551895
test: epoch 133, loss 0.06981389969587326, acc=0.9750000238418579, loss=0.06981389969587326
train: epoch 134, loss 0.19677627086639404, acc=0.9532777667045593, loss=0.19677627086639404
test: epoch 134, loss 0.16031062602996826, acc=0.949999988079071, loss=0.16031062602996826
train: epoch 135, loss 0.16983065009117126, acc=0.9402222037315369, loss=0.16983065009117126
test: epoch 135, loss 0.16824771463871002, acc=0.9305555820465088, loss=0.16824771463871002
train: epoch 136, loss 0.1605394184589386, acc=0.9308333396911621, loss=0.1605394184589386
test: epoch 136, loss 0.2211015820503235, acc=0.9055555462837219, loss=0.2211015820503235
train: epoch 137, loss 0.1955062747001648, acc=0.9169444441795349, loss=0.1955062747001648
test: epoch 137, loss 0.21387624740600586, acc=0.9166666865348816, loss=0.21387624740600586
train: epoch 138, loss 0.19405561685562134, acc=0.9245555400848389, loss=0.19405561685562134
test: epoch 138, loss 0.12233179062604904, acc=0.9611111283302307, loss=0.12233179062604904
train: epoch 139, loss 0.11885131895542145, acc=0.9596111178398132, loss=0.11885131895542145
test: epoch 139, loss 0.12556754052639008, acc=0.9583333134651184, loss=0.12556754052639008
train: epoch 140, loss 0.09736388176679611, acc=0.961222231388092, loss=0.09736388176679611
test: epoch 140, loss 0.1276673525571823, acc=0.9583333134651184, loss=0.1276673525571823
train: epoch 141, loss 0.10023781657218933, acc=0.9617778062820435, loss=0.10023781657218933
test: epoch 141, loss 0.09871547669172287, acc=0.9666666388511658, loss=0.09871547669172287
train: epoch 142, loss 0.07022149860858917, acc=0.9697222113609314, loss=0.07022149860858917
test: epoch 142, loss 0.09432470798492432, acc=0.9666666388511658, loss=0.09432470798492432
train: epoch 143, loss 0.08481229841709137, acc=0.9684444665908813, loss=0.08481229841709137
test: epoch 143, loss 0.14504040777683258, acc=0.9638888835906982, loss=0.14504040777683258
train: epoch 144, loss 0.06196422129869461, acc=0.9752222299575806, loss=0.06196422129869461
test: epoch 144, loss 0.0875641405582428, acc=0.9694444537162781, loss=0.0875641405582428
train: epoch 145, loss 0.059224896132946014, acc=0.9728333353996277, loss=0.059224896132946014
test: epoch 145, loss 0.08047697693109512, acc=0.9694444537162781, loss=0.08047697693109512
train: epoch 146, loss 0.14873380959033966, acc=0.954277753829956, loss=0.14873380959033966
test: epoch 146, loss 0.14353765547275543, acc=0.949999988079071, loss=0.14353765547275543
train: epoch 147, loss 0.12196111679077148, acc=0.953000009059906, loss=0.12196111679077148
test: epoch 147, loss 0.11151207983493805, acc=0.9583333134651184, loss=0.11151207983493805
train: epoch 148, loss 0.075507752597332, acc=0.9639444351196289, loss=0.075507752597332
test: epoch 148, loss 0.10379760712385178, acc=0.9638888835906982, loss=0.10379760712385178
train: epoch 149, loss 0.08756149560213089, acc=0.9636111259460449, loss=0.08756149560213089
test: epoch 149, loss 0.10188386589288712, acc=0.9638888835906982, loss=0.10188386589288712
train: epoch 150, loss 0.1254623830318451, acc=0.9578333497047424, loss=0.1254623830318451
test: epoch 150, loss 0.154515340924263, acc=0.9527778029441833, loss=0.154515340924263
