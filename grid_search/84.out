# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=1.5", "--temp_decay=0.99", "--one_hot=0", "--n_layers=1"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=1049029271, receiver_embed_dim=64, save_run=0, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=1049029271, receiver_embed_dim=64, save_run=False, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.146787405014038, acc=0.07955555617809296, loss=3.146787405014038
test: epoch 1, loss 4.436451435089111, acc=0.04444444552063942, loss=4.436451435089111
train: epoch 2, loss 2.6966867446899414, acc=0.1371111124753952, loss=2.6966867446899414
test: epoch 2, loss 5.1481428146362305, acc=0.04722222313284874, loss=5.1481428146362305
train: epoch 3, loss 2.546902894973755, acc=0.1505555510520935, loss=2.546902894973755
test: epoch 3, loss 5.664671897888184, acc=0.03611111268401146, loss=5.664671897888184
train: epoch 4, loss 2.482313632965088, acc=0.1606111079454422, loss=2.482313632965088
test: epoch 4, loss 5.846425533294678, acc=0.0416666679084301, loss=5.846425533294678
train: epoch 5, loss 2.424715518951416, acc=0.1762777715921402, loss=2.424715518951416
test: epoch 5, loss 6.0418524742126465, acc=0.0416666679084301, loss=6.0418524742126465
train: epoch 6, loss 2.3902430534362793, acc=0.17916665971279144, loss=2.3902430534362793
test: epoch 6, loss 6.193202018737793, acc=0.03888889029622078, loss=6.193202018737793
train: epoch 7, loss 2.3559136390686035, acc=0.1866111159324646, loss=2.3559136390686035
test: epoch 7, loss 6.385229587554932, acc=0.03888889029622078, loss=6.385229587554932
train: epoch 8, loss 2.338881015777588, acc=0.1908888816833496, loss=2.338881015777588
test: epoch 8, loss 6.156774997711182, acc=0.04722222313284874, loss=6.156774997711182
train: epoch 9, loss 2.316689968109131, acc=0.19661110639572144, loss=2.316689968109131
test: epoch 9, loss 6.16096830368042, acc=0.0416666679084301, loss=6.16096830368042
train: epoch 10, loss 2.304769515991211, acc=0.19716666638851166, loss=2.304769515991211
test: epoch 10, loss 6.286111831665039, acc=0.03888889029622078, loss=6.286111831665039
train: epoch 11, loss 2.294253349304199, acc=0.2022777795791626, loss=2.294253349304199
test: epoch 11, loss 6.112959861755371, acc=0.03888889029622078, loss=6.112959861755371
train: epoch 12, loss 2.286769151687622, acc=0.20083333551883698, loss=2.286769151687622
test: epoch 12, loss 6.120485782623291, acc=0.0416666679084301, loss=6.120485782623291
train: epoch 13, loss 2.2812232971191406, acc=0.20444443821907043, loss=2.2812232971191406
test: epoch 13, loss 6.093260288238525, acc=0.04722222313284874, loss=6.093260288238525
train: epoch 14, loss 2.260404586791992, acc=0.21194444596767426, loss=2.260404586791992
test: epoch 14, loss 6.160856246948242, acc=0.0416666679084301, loss=6.160856246948242
train: epoch 15, loss 2.262944221496582, acc=0.20322221517562866, loss=2.262944221496582
test: epoch 15, loss 6.178567409515381, acc=0.0416666679084301, loss=6.178567409515381
train: epoch 16, loss 2.257866859436035, acc=0.20666666328907013, loss=2.257866859436035
test: epoch 16, loss 5.828546047210693, acc=0.04444444552063942, loss=5.828546047210693
train: epoch 17, loss 2.241692066192627, acc=0.21494443714618683, loss=2.241692066192627
test: epoch 17, loss 5.949958324432373, acc=0.04444444552063942, loss=5.949958324432373
train: epoch 18, loss 2.2484936714172363, acc=0.20772221684455872, loss=2.2484936714172363
test: epoch 18, loss 5.614482879638672, acc=0.04444444552063942, loss=5.614482879638672
train: epoch 19, loss 2.2409920692443848, acc=0.2141111046075821, loss=2.2409920692443848
test: epoch 19, loss 5.70226526260376, acc=0.04444444552063942, loss=5.70226526260376
train: epoch 20, loss 2.250223159790039, acc=0.21066667139530182, loss=2.250223159790039
test: epoch 20, loss 5.450535774230957, acc=0.0555555559694767, loss=5.450535774230957
train: epoch 21, loss 2.2549498081207275, acc=0.212777778506279, loss=2.2549498081207275
test: epoch 21, loss 5.227190017700195, acc=0.05833333358168602, loss=5.227190017700195
train: epoch 22, loss 2.2417781352996826, acc=0.21150000393390656, loss=2.2417781352996826
test: epoch 22, loss 5.207395076751709, acc=0.03888889029622078, loss=5.207395076751709
train: epoch 23, loss 2.236379623413086, acc=0.21605555713176727, loss=2.236379623413086
test: epoch 23, loss 5.225160121917725, acc=0.03888889029622078, loss=5.225160121917725
train: epoch 24, loss 2.2604877948760986, acc=0.2150000035762787, loss=2.2604877948760986
test: epoch 24, loss 5.1532487869262695, acc=0.0416666679084301, loss=5.1532487869262695
train: epoch 25, loss 2.234677791595459, acc=0.21983332931995392, loss=2.234677791595459
test: epoch 25, loss 5.294292449951172, acc=0.0416666679084301, loss=5.294292449951172
train: epoch 26, loss 2.2409720420837402, acc=0.21988889575004578, loss=2.2409720420837402
test: epoch 26, loss 5.153888702392578, acc=0.0416666679084301, loss=5.153888702392578
train: epoch 27, loss 2.2322213649749756, acc=0.21538889408111572, loss=2.2322213649749756
test: epoch 27, loss 5.185800075531006, acc=0.03888889029622078, loss=5.185800075531006
train: epoch 28, loss 2.2210264205932617, acc=0.22022221982479095, loss=2.2210264205932617
test: epoch 28, loss 4.999999523162842, acc=0.0416666679084301, loss=4.999999523162842
train: epoch 29, loss 2.2390356063842773, acc=0.21983332931995392, loss=2.2390356063842773
test: epoch 29, loss 5.003836631774902, acc=0.0416666679084301, loss=5.003836631774902
train: epoch 30, loss 2.245042085647583, acc=0.21683333814144135, loss=2.245042085647583
test: epoch 30, loss 4.890408992767334, acc=0.0416666679084301, loss=4.890408992767334
train: epoch 31, loss 2.24033260345459, acc=0.2167777717113495, loss=2.24033260345459
test: epoch 31, loss 4.880258560180664, acc=0.0416666679084301, loss=4.880258560180664
train: epoch 32, loss 2.2373640537261963, acc=0.21638889610767365, loss=2.2373640537261963
test: epoch 32, loss 4.859667778015137, acc=0.05000000074505806, loss=4.859667778015137
train: epoch 33, loss 2.251455783843994, acc=0.21538889408111572, loss=2.251455783843994
test: epoch 33, loss 4.939074993133545, acc=0.0416666679084301, loss=4.939074993133545
train: epoch 34, loss 2.2587897777557373, acc=0.21477778255939484, loss=2.2587897777557373
test: epoch 34, loss 4.831847667694092, acc=0.0416666679084301, loss=4.831847667694092
train: epoch 35, loss 2.2628560066223145, acc=0.21283333003520966, loss=2.2628560066223145
test: epoch 35, loss 4.509377479553223, acc=0.05000000074505806, loss=4.509377479553223
train: epoch 36, loss 2.256761074066162, acc=0.21416667103767395, loss=2.256761074066162
test: epoch 36, loss 4.602258205413818, acc=0.04444444552063942, loss=4.602258205413818
train: epoch 37, loss 2.2580416202545166, acc=0.21583333611488342, loss=2.2580416202545166
test: epoch 37, loss 4.622167587280273, acc=0.03888889029622078, loss=4.622167587280273
train: epoch 38, loss 2.2637529373168945, acc=0.21111111342906952, loss=2.2637529373168945
test: epoch 38, loss 4.467148303985596, acc=0.05000000074505806, loss=4.467148303985596
train: epoch 39, loss 2.251758575439453, acc=0.2081666737794876, loss=2.251758575439453
test: epoch 39, loss 4.56715726852417, acc=0.05000000074505806, loss=4.56715726852417
train: epoch 40, loss 2.25018572807312, acc=0.21494443714618683, loss=2.25018572807312
test: epoch 40, loss 4.4783525466918945, acc=0.05000000074505806, loss=4.4783525466918945
train: epoch 41, loss 2.2748115062713623, acc=0.2108333259820938, loss=2.2748115062713623
test: epoch 41, loss 4.210566520690918, acc=0.04722222313284874, loss=4.210566520690918
train: epoch 42, loss 2.2828540802001953, acc=0.2070000022649765, loss=2.2828540802001953
test: epoch 42, loss 4.107320785522461, acc=0.04444444552063942, loss=4.107320785522461
train: epoch 43, loss 2.288193702697754, acc=0.20972222089767456, loss=2.288193702697754
test: epoch 43, loss 4.097954273223877, acc=0.04444444552063942, loss=4.097954273223877
train: epoch 44, loss 2.276815176010132, acc=0.20399999618530273, loss=2.276815176010132
test: epoch 44, loss 4.098120212554932, acc=0.06111111119389534, loss=4.098120212554932
train: epoch 45, loss 2.278653621673584, acc=0.20766666531562805, loss=2.278653621673584
test: epoch 45, loss 4.092523097991943, acc=0.05000000074505806, loss=4.092523097991943
train: epoch 46, loss 2.2965948581695557, acc=0.2052222192287445, loss=2.2965948581695557
test: epoch 46, loss 4.026710510253906, acc=0.05277777835726738, loss=4.026710510253906
train: epoch 47, loss 2.292351484298706, acc=0.2062777727842331, loss=2.292351484298706
test: epoch 47, loss 4.073810577392578, acc=0.05833333358168602, loss=4.073810577392578
train: epoch 48, loss 2.2800190448760986, acc=0.2108333259820938, loss=2.2800190448760986
test: epoch 48, loss 4.06058406829834, acc=0.04722222313284874, loss=4.06058406829834
train: epoch 49, loss 2.2985265254974365, acc=0.20411111414432526, loss=2.2985265254974365
test: epoch 49, loss 3.8462586402893066, acc=0.05277777835726738, loss=3.8462586402893066
train: epoch 50, loss 2.303995132446289, acc=0.1996111124753952, loss=2.303995132446289
test: epoch 50, loss 3.899203300476074, acc=0.05277777835726738, loss=3.899203300476074
train: epoch 51, loss 2.303107976913452, acc=0.20488889515399933, loss=2.303107976913452
test: epoch 51, loss 3.767606019973755, acc=0.07222222536802292, loss=3.767606019973755
train: epoch 52, loss 2.3077452182769775, acc=0.20638889074325562, loss=2.3077452182769775
test: epoch 52, loss 3.8072235584259033, acc=0.0555555559694767, loss=3.8072235584259033
train: epoch 53, loss 2.3223013877868652, acc=0.19794444739818573, loss=2.3223013877868652
test: epoch 53, loss 3.645575761795044, acc=0.06666667014360428, loss=3.645575761795044
train: epoch 54, loss 2.31419038772583, acc=0.20061111450195312, loss=2.31419038772583
test: epoch 54, loss 3.736011505126953, acc=0.04722222313284874, loss=3.736011505126953
train: epoch 55, loss 2.321561574935913, acc=0.19616666436195374, loss=2.321561574935913
test: epoch 55, loss 3.6774697303771973, acc=0.06388889253139496, loss=3.6774697303771973
train: epoch 56, loss 2.321445941925049, acc=0.19344444572925568, loss=2.321445941925049
test: epoch 56, loss 3.7978944778442383, acc=0.05277777835726738, loss=3.7978944778442383
train: epoch 57, loss 2.3051512241363525, acc=0.19305555522441864, loss=2.3051512241363525
test: epoch 57, loss 3.7364420890808105, acc=0.0555555559694767, loss=3.7364420890808105
train: epoch 58, loss 2.3361432552337646, acc=0.19116666913032532, loss=2.3361432552337646
test: epoch 58, loss 3.6714587211608887, acc=0.05277777835726738, loss=3.6714587211608887
train: epoch 59, loss 2.336575984954834, acc=0.1923888921737671, loss=2.336575984954834
test: epoch 59, loss 3.7259926795959473, acc=0.05277777835726738, loss=3.7259926795959473
train: epoch 60, loss 2.3334789276123047, acc=0.19116666913032532, loss=2.3334789276123047
test: epoch 60, loss 3.7137272357940674, acc=0.05000000074505806, loss=3.7137272357940674
train: epoch 61, loss 2.32926082611084, acc=0.1875, loss=2.32926082611084
test: epoch 61, loss 3.5596654415130615, acc=0.06111111119389534, loss=3.5596654415130615
train: epoch 62, loss 2.3462939262390137, acc=0.19405555725097656, loss=2.3462939262390137
test: epoch 62, loss 3.4819798469543457, acc=0.05833333358168602, loss=3.4819798469543457
train: epoch 63, loss 2.346097230911255, acc=0.18716666102409363, loss=2.346097230911255
test: epoch 63, loss 3.6132311820983887, acc=0.05000000074505806, loss=3.6132311820983887
train: epoch 64, loss 2.365952253341675, acc=0.189277783036232, loss=2.365952253341675
test: epoch 64, loss 3.5512330532073975, acc=0.06111111119389534, loss=3.5512330532073975
train: epoch 65, loss 2.3629541397094727, acc=0.18344444036483765, loss=2.3629541397094727
test: epoch 65, loss 3.4387710094451904, acc=0.06111111119389534, loss=3.4387710094451904
train: epoch 66, loss 2.3589513301849365, acc=0.18666666746139526, loss=2.3589513301849365
test: epoch 66, loss 3.61395263671875, acc=0.0555555559694767, loss=3.61395263671875
train: epoch 67, loss 2.3494811058044434, acc=0.18655554950237274, loss=2.3494811058044434
test: epoch 67, loss 3.380805253982544, acc=0.06111111119389534, loss=3.380805253982544
train: epoch 68, loss 2.3684606552124023, acc=0.18316666781902313, loss=2.3684606552124023
test: epoch 68, loss 3.4128506183624268, acc=0.07777778059244156, loss=3.4128506183624268
train: epoch 69, loss 2.3681488037109375, acc=0.177888885140419, loss=2.3681488037109375
test: epoch 69, loss 3.3802809715270996, acc=0.05833333358168602, loss=3.3802809715270996
train: epoch 70, loss 2.3777122497558594, acc=0.18033333122730255, loss=2.3777122497558594
test: epoch 70, loss 3.3044626712799072, acc=0.07222222536802292, loss=3.3044626712799072
train: epoch 71, loss 2.3666443824768066, acc=0.18088889122009277, loss=2.3666443824768066
test: epoch 71, loss 3.311030387878418, acc=0.0555555559694767, loss=3.311030387878418
train: epoch 72, loss 2.372044563293457, acc=0.18044444918632507, loss=2.372044563293457
test: epoch 72, loss 3.2247133255004883, acc=0.07222222536802292, loss=3.2247133255004883
train: epoch 73, loss 2.3664660453796387, acc=0.1770000010728836, loss=2.3664660453796387
test: epoch 73, loss 3.3617615699768066, acc=0.07777778059244156, loss=3.3617615699768066
train: epoch 74, loss 2.3822507858276367, acc=0.17961111664772034, loss=2.3822507858276367
test: epoch 74, loss 3.3379034996032715, acc=0.0694444477558136, loss=3.3379034996032715
train: epoch 75, loss 2.359558582305908, acc=0.1793888956308365, loss=2.359558582305908
test: epoch 75, loss 3.3586511611938477, acc=0.0694444477558136, loss=3.3586511611938477
train: epoch 76, loss 2.373445510864258, acc=0.18611110746860504, loss=2.373445510864258
test: epoch 76, loss 3.367704391479492, acc=0.0555555559694767, loss=3.367704391479492
train: epoch 77, loss 2.368161916732788, acc=0.17766666412353516, loss=2.368161916732788
test: epoch 77, loss 3.2639424800872803, acc=0.06666667014360428, loss=3.2639424800872803
train: epoch 78, loss 2.357686996459961, acc=0.17872221767902374, loss=2.357686996459961
test: epoch 78, loss 3.2650539875030518, acc=0.06111111119389534, loss=3.2650539875030518
train: epoch 79, loss 2.360114336013794, acc=0.18061110377311707, loss=2.360114336013794
test: epoch 79, loss 3.330721855163574, acc=0.0694444477558136, loss=3.330721855163574
train: epoch 80, loss 2.355780601501465, acc=0.1821666657924652, loss=2.355780601501465
test: epoch 80, loss 3.2543153762817383, acc=0.0555555559694767, loss=3.2543153762817383
train: epoch 81, loss 2.363530158996582, acc=0.17438888549804688, loss=2.363530158996582
test: epoch 81, loss 3.1997315883636475, acc=0.07222222536802292, loss=3.1997315883636475
train: epoch 82, loss 2.347862482070923, acc=0.18405555188655853, loss=2.347862482070923
test: epoch 82, loss 3.2063634395599365, acc=0.08055555820465088, loss=3.2063634395599365
train: epoch 83, loss 2.3437564373016357, acc=0.18372222781181335, loss=2.3437564373016357
test: epoch 83, loss 3.2561333179473877, acc=0.0555555559694767, loss=3.2561333179473877
train: epoch 84, loss 2.3471338748931885, acc=0.1826111078262329, loss=2.3471338748931885
test: epoch 84, loss 3.3650124073028564, acc=0.0694444477558136, loss=3.3650124073028564
train: epoch 85, loss 2.3629705905914307, acc=0.1817222237586975, loss=2.3629705905914307
test: epoch 85, loss 3.2795839309692383, acc=0.07500000298023224, loss=3.2795839309692383
train: epoch 86, loss 2.3434157371520996, acc=0.18472221493721008, loss=2.3434157371520996
test: epoch 86, loss 3.2590484619140625, acc=0.0694444477558136, loss=3.2590484619140625
train: epoch 87, loss 2.344665050506592, acc=0.18594443798065186, loss=2.344665050506592
test: epoch 87, loss 3.3067567348480225, acc=0.0694444477558136, loss=3.3067567348480225
train: epoch 88, loss 2.3486578464508057, acc=0.18549999594688416, loss=2.3486578464508057
test: epoch 88, loss 3.35323166847229, acc=0.05277777835726738, loss=3.35323166847229
train: epoch 89, loss 2.333750009536743, acc=0.18477778136730194, loss=2.333750009536743
test: epoch 89, loss 3.2798147201538086, acc=0.05277777835726738, loss=3.2798147201538086
train: epoch 90, loss 2.3102469444274902, acc=0.1901666671037674, loss=2.3102469444274902
test: epoch 90, loss 3.3551623821258545, acc=0.0694444477558136, loss=3.3551623821258545
train: epoch 91, loss 2.3267457485198975, acc=0.1889999955892563, loss=2.3267457485198975
test: epoch 91, loss 3.2834854125976562, acc=0.06666667014360428, loss=3.2834854125976562
train: epoch 92, loss 2.326570510864258, acc=0.18938888609409332, loss=2.326570510864258
test: epoch 92, loss 3.274444580078125, acc=0.06666667014360428, loss=3.274444580078125
train: epoch 93, loss 2.330721378326416, acc=0.18799999356269836, loss=2.330721378326416
test: epoch 93, loss 3.186922311782837, acc=0.0694444477558136, loss=3.186922311782837
train: epoch 94, loss 2.327458143234253, acc=0.18722222745418549, loss=2.327458143234253
test: epoch 94, loss 3.2107083797454834, acc=0.05000000074505806, loss=3.2107083797454834
train: epoch 95, loss 2.3234901428222656, acc=0.18788889050483704, loss=2.3234901428222656
test: epoch 95, loss 3.2056102752685547, acc=0.0555555559694767, loss=3.2056102752685547
train: epoch 96, loss 2.328190326690674, acc=0.18738888204097748, loss=2.328190326690674
test: epoch 96, loss 3.1390023231506348, acc=0.06666667014360428, loss=3.1390023231506348
train: epoch 97, loss 2.320195436477661, acc=0.18977777659893036, loss=2.320195436477661
test: epoch 97, loss 3.17763614654541, acc=0.08055555820465088, loss=3.17763614654541
train: epoch 98, loss 2.304265022277832, acc=0.19188888370990753, loss=2.304265022277832
test: epoch 98, loss 3.2513129711151123, acc=0.0694444477558136, loss=3.2513129711151123
train: epoch 99, loss 2.3132078647613525, acc=0.18966667354106903, loss=2.3132078647613525
test: epoch 99, loss 3.200761556625366, acc=0.06388889253139496, loss=3.200761556625366
train: epoch 100, loss 2.3239004611968994, acc=0.1886666715145111, loss=2.3239004611968994
test: epoch 100, loss 3.2711968421936035, acc=0.07222222536802292, loss=3.2711968421936035
train: epoch 101, loss 2.294217348098755, acc=0.19161111116409302, loss=2.294217348098755
test: epoch 101, loss 3.2966854572296143, acc=0.06388889253139496, loss=3.2966854572296143
train: epoch 102, loss 2.3179619312286377, acc=0.19388888776302338, loss=2.3179619312286377
test: epoch 102, loss 3.247429847717285, acc=0.05000000074505806, loss=3.247429847717285
train: epoch 103, loss 2.3292386531829834, acc=0.1914999932050705, loss=2.3292386531829834
test: epoch 103, loss 3.2314107418060303, acc=0.07222222536802292, loss=3.2314107418060303
train: epoch 104, loss 2.307853937149048, acc=0.18983332812786102, loss=2.307853937149048
test: epoch 104, loss 3.287278890609741, acc=0.07222222536802292, loss=3.287278890609741
train: epoch 105, loss 2.3176934719085693, acc=0.1960555613040924, loss=2.3176934719085693
test: epoch 105, loss 3.2156026363372803, acc=0.07222222536802292, loss=3.2156026363372803
train: epoch 106, loss 2.3146185874938965, acc=0.19205555319786072, loss=2.3146185874938965
test: epoch 106, loss 3.376054286956787, acc=0.0555555559694767, loss=3.376054286956787
train: epoch 107, loss 2.2909677028656006, acc=0.19333332777023315, loss=2.2909677028656006
test: epoch 107, loss 3.230390787124634, acc=0.07777778059244156, loss=3.230390787124634
train: epoch 108, loss 2.3010246753692627, acc=0.1932777762413025, loss=2.3010246753692627
test: epoch 108, loss 3.3059096336364746, acc=0.05277777835726738, loss=3.3059096336364746
train: epoch 109, loss 2.286167860031128, acc=0.1940000057220459, loss=2.286167860031128
test: epoch 109, loss 3.2461087703704834, acc=0.08055555820465088, loss=3.2461087703704834
train: epoch 110, loss 2.2924790382385254, acc=0.1951666623353958, loss=2.2924790382385254
test: epoch 110, loss 3.326106071472168, acc=0.05277777835726738, loss=3.326106071472168
train: epoch 111, loss 2.287649393081665, acc=0.19205555319786072, loss=2.287649393081665
test: epoch 111, loss 3.2190840244293213, acc=0.07222222536802292, loss=3.2190840244293213
train: epoch 112, loss 2.290527105331421, acc=0.19850000739097595, loss=2.290527105331421
test: epoch 112, loss 3.242182493209839, acc=0.06666667014360428, loss=3.242182493209839
train: epoch 113, loss 2.2942276000976562, acc=0.1917777806520462, loss=2.2942276000976562
test: epoch 113, loss 3.2566452026367188, acc=0.0555555559694767, loss=3.2566452026367188
train: epoch 114, loss 2.275865316390991, acc=0.19111111760139465, loss=2.275865316390991
test: epoch 114, loss 3.1975772380828857, acc=0.07222222536802292, loss=3.1975772380828857
train: epoch 115, loss 2.285839080810547, acc=0.19227777421474457, loss=2.285839080810547
test: epoch 115, loss 3.281064987182617, acc=0.0694444477558136, loss=3.281064987182617
train: epoch 116, loss 2.2844936847686768, acc=0.1919444501399994, loss=2.2844936847686768
test: epoch 116, loss 3.172625780105591, acc=0.07777778059244156, loss=3.172625780105591
train: epoch 117, loss 2.2671477794647217, acc=0.1991666704416275, loss=2.2671477794647217
test: epoch 117, loss 3.3353397846221924, acc=0.05833333358168602, loss=3.3353397846221924
train: epoch 118, loss 2.285961627960205, acc=0.20216666162014008, loss=2.285961627960205
test: epoch 118, loss 3.2763307094573975, acc=0.0694444477558136, loss=3.2763307094573975
train: epoch 119, loss 2.267169713973999, acc=0.1996111124753952, loss=2.267169713973999
test: epoch 119, loss 3.26763653755188, acc=0.05833333358168602, loss=3.26763653755188
train: epoch 120, loss 2.2773287296295166, acc=0.20127777755260468, loss=2.2773287296295166
test: epoch 120, loss 3.160595178604126, acc=0.0694444477558136, loss=3.160595178604126
train: epoch 121, loss 2.2575862407684326, acc=0.195333331823349, loss=2.2575862407684326
test: epoch 121, loss 3.171658515930176, acc=0.05833333358168602, loss=3.171658515930176
train: epoch 122, loss 2.2697505950927734, acc=0.2018333375453949, loss=2.2697505950927734
test: epoch 122, loss 3.0983269214630127, acc=0.08055555820465088, loss=3.0983269214630127
train: epoch 123, loss 2.2474470138549805, acc=0.2006666660308838, loss=2.2474470138549805
test: epoch 123, loss 3.19401216506958, acc=0.08055555820465088, loss=3.19401216506958
train: epoch 124, loss 2.2623279094696045, acc=0.19983333349227905, loss=2.2623279094696045
test: epoch 124, loss 3.2895257472991943, acc=0.0694444477558136, loss=3.2895257472991943
train: epoch 125, loss 2.2650046348571777, acc=0.1978333294391632, loss=2.2650046348571777
test: epoch 125, loss 3.1228346824645996, acc=0.07500000298023224, loss=3.1228346824645996
train: epoch 126, loss 2.2518301010131836, acc=0.20105555653572083, loss=2.2518301010131836
test: epoch 126, loss 3.1897048950195312, acc=0.06666667014360428, loss=3.1897048950195312
train: epoch 127, loss 2.2544424533843994, acc=0.20533333718776703, loss=2.2544424533843994
test: epoch 127, loss 3.187483787536621, acc=0.0694444477558136, loss=3.187483787536621
train: epoch 128, loss 2.255560874938965, acc=0.20194444060325623, loss=2.255560874938965
test: epoch 128, loss 3.2074878215789795, acc=0.07777778059244156, loss=3.2074878215789795
train: epoch 129, loss 2.274312734603882, acc=0.19894444942474365, loss=2.274312734603882
test: epoch 129, loss 3.2474803924560547, acc=0.07222222536802292, loss=3.2474803924560547
train: epoch 130, loss 2.254673480987549, acc=0.2027222216129303, loss=2.254673480987549
test: epoch 130, loss 3.1838972568511963, acc=0.0694444477558136, loss=3.1838972568511963
train: epoch 131, loss 2.2416372299194336, acc=0.20250000059604645, loss=2.2416372299194336
test: epoch 131, loss 3.201225519180298, acc=0.07777778059244156, loss=3.201225519180298
train: epoch 132, loss 2.2445027828216553, acc=0.19766665995121002, loss=2.2445027828216553
test: epoch 132, loss 3.1770265102386475, acc=0.08888889104127884, loss=3.1770265102386475
train: epoch 133, loss 2.2335503101348877, acc=0.20677778124809265, loss=2.2335503101348877
test: epoch 133, loss 3.3341755867004395, acc=0.06666667014360428, loss=3.3341755867004395
train: epoch 134, loss 2.212658166885376, acc=0.20577777922153473, loss=2.212658166885376
test: epoch 134, loss 3.2636666297912598, acc=0.0694444477558136, loss=3.2636666297912598
train: epoch 135, loss 2.2318077087402344, acc=0.20350000262260437, loss=2.2318077087402344
test: epoch 135, loss 3.252610921859741, acc=0.06666667014360428, loss=3.252610921859741
train: epoch 136, loss 2.252551317214966, acc=0.1947222203016281, loss=2.252551317214966
test: epoch 136, loss 3.1234514713287354, acc=0.07500000298023224, loss=3.1234514713287354
train: epoch 137, loss 2.238661050796509, acc=0.2011111080646515, loss=2.238661050796509
test: epoch 137, loss 3.1652519702911377, acc=0.06111111119389534, loss=3.1652519702911377
train: epoch 138, loss 2.240766763687134, acc=0.2058333307504654, loss=2.240766763687134
test: epoch 138, loss 3.1099672317504883, acc=0.0555555559694767, loss=3.1099672317504883
train: epoch 139, loss 2.2356114387512207, acc=0.21244443953037262, loss=2.2356114387512207
test: epoch 139, loss 3.210472583770752, acc=0.07777778059244156, loss=3.210472583770752
train: epoch 140, loss 2.229231119155884, acc=0.2081666737794876, loss=2.229231119155884
test: epoch 140, loss 3.253253221511841, acc=0.0555555559694767, loss=3.253253221511841
train: epoch 141, loss 2.235583782196045, acc=0.20494444668293, loss=2.235583782196045
test: epoch 141, loss 3.1340296268463135, acc=0.07777778059244156, loss=3.1340296268463135
train: epoch 142, loss 2.2370448112487793, acc=0.20327778160572052, loss=2.2370448112487793
test: epoch 142, loss 3.101011276245117, acc=0.07500000298023224, loss=3.101011276245117
train: epoch 143, loss 2.239562749862671, acc=0.20727777481079102, loss=2.239562749862671
test: epoch 143, loss 3.1388063430786133, acc=0.06666667014360428, loss=3.1388063430786133
train: epoch 144, loss 2.2105612754821777, acc=0.2123333364725113, loss=2.2105612754821777
test: epoch 144, loss 3.1194519996643066, acc=0.07500000298023224, loss=3.1194519996643066
train: epoch 145, loss 2.2125189304351807, acc=0.20711110532283783, loss=2.2125189304351807
test: epoch 145, loss 3.2015814781188965, acc=0.07777778059244156, loss=3.2015814781188965
train: epoch 146, loss 2.2194173336029053, acc=0.21372222900390625, loss=2.2194173336029053
test: epoch 146, loss 3.105881929397583, acc=0.0694444477558136, loss=3.105881929397583
train: epoch 147, loss 2.2283883094787598, acc=0.21061110496520996, loss=2.2283883094787598
test: epoch 147, loss 3.165482759475708, acc=0.07222222536802292, loss=3.165482759475708
train: epoch 148, loss 2.2267906665802, acc=0.20438888669013977, loss=2.2267906665802
test: epoch 148, loss 3.092496156692505, acc=0.07222222536802292, loss=3.092496156692505
train: epoch 149, loss 2.1999738216400146, acc=0.21433334052562714, loss=2.1999738216400146
test: epoch 149, loss 3.0778605937957764, acc=0.0555555559694767, loss=3.0778605937957764
train: epoch 150, loss 2.2259600162506104, acc=0.21594443917274475, loss=2.2259600162506104
test: epoch 150, loss 3.008207321166992, acc=0.08055555820465088, loss=3.008207321166992
