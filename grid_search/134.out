# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=0", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=620434871, receiver_embed_dim=128, save_run=0, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=620434871, receiver_embed_dim=128, save_run=False, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.4489035606384277, acc=0.1471666693687439, loss=2.4489035606384277
test: epoch 1, loss 5.898782730102539, acc=0.07222222536802292, loss=5.898782730102539
train: epoch 2, loss 1.759123682975769, acc=0.2930000126361847, loss=1.759123682975769
test: epoch 2, loss 4.222538948059082, acc=0.08888889104127884, loss=4.222538948059082
train: epoch 3, loss 1.4763761758804321, acc=0.38616666197776794, loss=1.4763761758804321
test: epoch 3, loss 2.465815544128418, acc=0.2638888955116272, loss=2.465815544128418
train: epoch 4, loss 1.3155947923660278, acc=0.4576111137866974, loss=1.3155947923660278
test: epoch 4, loss 2.601715087890625, acc=0.23055554926395416, loss=2.601715087890625
train: epoch 5, loss 1.1674572229385376, acc=0.5206666588783264, loss=1.1674572229385376
test: epoch 5, loss 2.59657621383667, acc=0.18888889253139496, loss=2.59657621383667
train: epoch 6, loss 1.081368088722229, acc=0.5581111311912537, loss=1.081368088722229
test: epoch 6, loss 2.9046828746795654, acc=0.1944444477558136, loss=2.9046828746795654
train: epoch 7, loss 0.988585889339447, acc=0.593500018119812, loss=0.988585889339447
test: epoch 7, loss 2.4128310680389404, acc=0.23888888955116272, loss=2.4128310680389404
train: epoch 8, loss 0.9253072738647461, acc=0.6194444298744202, loss=0.9253072738647461
test: epoch 8, loss 2.6151604652404785, acc=0.28611111640930176, loss=2.6151604652404785
train: epoch 9, loss 0.8876025676727295, acc=0.6366666555404663, loss=0.8876025676727295
test: epoch 9, loss 2.2638251781463623, acc=0.28333333134651184, loss=2.2638251781463623
train: epoch 10, loss 0.8367781639099121, acc=0.6618333458900452, loss=0.8367781639099121
test: epoch 10, loss 2.1013522148132324, acc=0.33888888359069824, loss=2.1013522148132324
train: epoch 11, loss 0.8207365274429321, acc=0.6684444546699524, loss=0.8207365274429321
test: epoch 11, loss 1.8101983070373535, acc=0.2916666567325592, loss=1.8101983070373535
train: epoch 12, loss 0.744962751865387, acc=0.6977777481079102, loss=0.744962751865387
test: epoch 12, loss 1.9936467409133911, acc=0.3055555522441864, loss=1.9936467409133911
train: epoch 13, loss 0.7479532957077026, acc=0.6940555572509766, loss=0.7479532957077026
test: epoch 13, loss 1.671286940574646, acc=0.3611111044883728, loss=1.671286940574646
train: epoch 14, loss 0.7155766487121582, acc=0.7051110863685608, loss=0.7155766487121582
test: epoch 14, loss 1.8622864484786987, acc=0.35555556416511536, loss=1.8622864484786987
train: epoch 15, loss 0.7304821610450745, acc=0.7059444189071655, loss=0.7304821610450745
test: epoch 15, loss 1.7618944644927979, acc=0.3499999940395355, loss=1.7618944644927979
train: epoch 16, loss 0.646156907081604, acc=0.7378888726234436, loss=0.646156907081604
test: epoch 16, loss 2.364462375640869, acc=0.3361110985279083, loss=2.364462375640869
train: epoch 17, loss 0.6548892855644226, acc=0.7327777743339539, loss=0.6548892855644226
test: epoch 17, loss 1.9691706895828247, acc=0.31388887763023376, loss=1.9691706895828247
train: epoch 18, loss 0.6372238993644714, acc=0.7383888959884644, loss=0.6372238993644714
test: epoch 18, loss 1.7564623355865479, acc=0.38055557012557983, loss=1.7564623355865479
train: epoch 19, loss 0.6121031045913696, acc=0.749666690826416, loss=0.6121031045913696
test: epoch 19, loss 1.9957647323608398, acc=0.2888889014720917, loss=1.9957647323608398
train: epoch 20, loss 0.6415502429008484, acc=0.7366111278533936, loss=0.6415502429008484
test: epoch 20, loss 1.7203824520111084, acc=0.3166666626930237, loss=1.7203824520111084
train: epoch 21, loss 0.5714786052703857, acc=0.7665555477142334, loss=0.5714786052703857
test: epoch 21, loss 2.2336788177490234, acc=0.30000001192092896, loss=2.2336788177490234
train: epoch 22, loss 0.5913657546043396, acc=0.7580000162124634, loss=0.5913657546043396
test: epoch 22, loss 1.5252087116241455, acc=0.38333332538604736, loss=1.5252087116241455
train: epoch 23, loss 0.5881726145744324, acc=0.75855553150177, loss=0.5881726145744324
test: epoch 23, loss 1.6195588111877441, acc=0.4194444417953491, loss=1.6195588111877441
train: epoch 24, loss 0.5606265068054199, acc=0.7717221975326538, loss=0.5606265068054199
test: epoch 24, loss 1.5846832990646362, acc=0.32499998807907104, loss=1.5846832990646362
train: epoch 25, loss 0.5390365719795227, acc=0.7831110954284668, loss=0.5390365719795227
test: epoch 25, loss 1.6882151365280151, acc=0.3444444537162781, loss=1.6882151365280151
train: epoch 26, loss 0.5787692070007324, acc=0.7608333230018616, loss=0.5787692070007324
test: epoch 26, loss 1.5134913921356201, acc=0.42222222685813904, loss=1.5134913921356201
train: epoch 27, loss 0.5330250859260559, acc=0.7831666469573975, loss=0.5330250859260559
test: epoch 27, loss 1.3363494873046875, acc=0.44999998807907104, loss=1.3363494873046875
train: epoch 28, loss 0.5207400321960449, acc=0.7860555648803711, loss=0.5207400321960449
test: epoch 28, loss 1.6939629316329956, acc=0.41111111640930176, loss=1.6939629316329956
train: epoch 29, loss 0.5167226195335388, acc=0.7898333072662354, loss=0.5167226195335388
test: epoch 29, loss 1.711530089378357, acc=0.42500001192092896, loss=1.711530089378357
train: epoch 30, loss 0.5786545872688293, acc=0.7640555500984192, loss=0.5786545872688293
test: epoch 30, loss 1.4015270471572876, acc=0.4888888895511627, loss=1.4015270471572876
train: epoch 31, loss 0.4913162589073181, acc=0.8040000200271606, loss=0.4913162589073181
test: epoch 31, loss 1.3330167531967163, acc=0.43611112236976624, loss=1.3330167531967163
train: epoch 32, loss 0.4863995313644409, acc=0.801277756690979, loss=0.4863995313644409
test: epoch 32, loss 1.4432073831558228, acc=0.45277777314186096, loss=1.4432073831558228
train: epoch 33, loss 0.4895375669002533, acc=0.8027777671813965, loss=0.4895375669002533
test: epoch 33, loss 1.376451849937439, acc=0.4027777910232544, loss=1.376451849937439
train: epoch 34, loss 0.4813025891780853, acc=0.805388867855072, loss=0.4813025891780853
test: epoch 34, loss 1.2051365375518799, acc=0.4888888895511627, loss=1.2051365375518799
train: epoch 35, loss 0.4879702925682068, acc=0.8014444708824158, loss=0.4879702925682068
test: epoch 35, loss 1.1610904932022095, acc=0.5555555820465088, loss=1.1610904932022095
train: epoch 36, loss 0.4740205407142639, acc=0.8096110820770264, loss=0.4740205407142639
test: epoch 36, loss 1.4363834857940674, acc=0.44999998807907104, loss=1.4363834857940674
train: epoch 37, loss 0.47864535450935364, acc=0.8066666722297668, loss=0.47864535450935364
test: epoch 37, loss 1.2198480367660522, acc=0.4166666567325592, loss=1.2198480367660522
train: epoch 38, loss 0.4522932469844818, acc=0.816611111164093, loss=0.4522932469844818
test: epoch 38, loss 1.8358538150787354, acc=0.43611112236976624, loss=1.8358538150787354
train: epoch 39, loss 0.4484618902206421, acc=0.8202221989631653, loss=0.4484618902206421
test: epoch 39, loss 1.2731939554214478, acc=0.5333333611488342, loss=1.2731939554214478
train: epoch 40, loss 0.4564690887928009, acc=0.8147222399711609, loss=0.4564690887928009
test: epoch 40, loss 1.1282655000686646, acc=0.5305555462837219, loss=1.1282655000686646
train: epoch 41, loss 0.4679669141769409, acc=0.812833309173584, loss=0.4679669141769409
test: epoch 41, loss 1.2453237771987915, acc=0.550000011920929, loss=1.2453237771987915
train: epoch 42, loss 0.4341989755630493, acc=0.8225555419921875, loss=0.4341989755630493
test: epoch 42, loss 1.22166907787323, acc=0.4972222149372101, loss=1.22166907787323
train: epoch 43, loss 0.4368208944797516, acc=0.8246666789054871, loss=0.4368208944797516
test: epoch 43, loss 1.1205087900161743, acc=0.5166666507720947, loss=1.1205087900161743
train: epoch 44, loss 0.4231291115283966, acc=0.8332777619361877, loss=0.4231291115283966
test: epoch 44, loss 1.352945327758789, acc=0.4972222149372101, loss=1.352945327758789
train: epoch 45, loss 0.45877668261528015, acc=0.8171111345291138, loss=0.45877668261528015
test: epoch 45, loss 1.1059048175811768, acc=0.519444465637207, loss=1.1059048175811768
train: epoch 46, loss 0.4111637473106384, acc=0.8355555534362793, loss=0.4111637473106384
test: epoch 46, loss 1.2087322473526, acc=0.5166666507720947, loss=1.2087322473526
train: epoch 47, loss 0.40128928422927856, acc=0.8405555486679077, loss=0.40128928422927856
test: epoch 47, loss 1.226513385772705, acc=0.4611110985279083, loss=1.226513385772705
train: epoch 48, loss 0.4256337583065033, acc=0.8292222023010254, loss=0.4256337583065033
test: epoch 48, loss 1.2842509746551514, acc=0.5222222208976746, loss=1.2842509746551514
train: epoch 49, loss 0.40153229236602783, acc=0.8391110897064209, loss=0.40153229236602783
test: epoch 49, loss 1.18903648853302, acc=0.5111111402511597, loss=1.18903648853302
train: epoch 50, loss 0.42863965034484863, acc=0.8314444422721863, loss=0.42863965034484863
test: epoch 50, loss 1.1806570291519165, acc=0.5694444179534912, loss=1.1806570291519165
train: epoch 51, loss 0.3920397460460663, acc=0.8429999947547913, loss=0.3920397460460663
test: epoch 51, loss 1.4133533239364624, acc=0.4749999940395355, loss=1.4133533239364624
train: epoch 52, loss 0.4123026132583618, acc=0.8364444375038147, loss=0.4123026132583618
test: epoch 52, loss 1.0172650814056396, acc=0.625, loss=1.0172650814056396
train: epoch 53, loss 0.3961853086948395, acc=0.8432777523994446, loss=0.3961853086948395
test: epoch 53, loss 1.195440649986267, acc=0.5138888955116272, loss=1.195440649986267
train: epoch 54, loss 0.37003713846206665, acc=0.8536666631698608, loss=0.37003713846206665
test: epoch 54, loss 1.1050111055374146, acc=0.48055556416511536, loss=1.1050111055374146
train: epoch 55, loss 0.40395641326904297, acc=0.8433889150619507, loss=0.40395641326904297
test: epoch 55, loss 1.024658441543579, acc=0.6138888597488403, loss=1.024658441543579
train: epoch 56, loss 0.3832825720310211, acc=0.8490555286407471, loss=0.3832825720310211
test: epoch 56, loss 1.1791558265686035, acc=0.5722222328186035, loss=1.1791558265686035
train: epoch 57, loss 0.38268613815307617, acc=0.851277768611908, loss=0.38268613815307617
test: epoch 57, loss 1.4154205322265625, acc=0.550000011920929, loss=1.4154205322265625
train: epoch 58, loss 0.3785533010959625, acc=0.8510555624961853, loss=0.3785533010959625
test: epoch 58, loss 1.3058468103408813, acc=0.4888888895511627, loss=1.3058468103408813
train: epoch 59, loss 0.3752278685569763, acc=0.8538333177566528, loss=0.3752278685569763
test: epoch 59, loss 1.0133553743362427, acc=0.6499999761581421, loss=1.0133553743362427
train: epoch 60, loss 0.3778947591781616, acc=0.8544444441795349, loss=0.3778947591781616
test: epoch 60, loss 1.1892849206924438, acc=0.5083333253860474, loss=1.1892849206924438
train: epoch 61, loss 0.38706904649734497, acc=0.8473888635635376, loss=0.38706904649734497
test: epoch 61, loss 0.9366747140884399, acc=0.625, loss=0.9366747140884399
train: epoch 62, loss 0.38396385312080383, acc=0.8497777581214905, loss=0.38396385312080383
test: epoch 62, loss 0.9454379677772522, acc=0.6722221970558167, loss=0.9454379677772522
train: epoch 63, loss 0.36036062240600586, acc=0.8576666712760925, loss=0.36036062240600586
test: epoch 63, loss 0.8928468823432922, acc=0.5611110925674438, loss=0.8928468823432922
train: epoch 64, loss 0.35759955644607544, acc=0.8615000247955322, loss=0.35759955644607544
test: epoch 64, loss 1.0424309968948364, acc=0.5444444417953491, loss=1.0424309968948364
train: epoch 65, loss 0.3460978865623474, acc=0.8622221946716309, loss=0.3460978865623474
test: epoch 65, loss 0.9452381134033203, acc=0.6222222447395325, loss=0.9452381134033203
train: epoch 66, loss 0.3657885193824768, acc=0.8598333597183228, loss=0.3657885193824768
test: epoch 66, loss 0.9094000458717346, acc=0.625, loss=0.9094000458717346
train: epoch 67, loss 0.33807599544525146, acc=0.8679444193840027, loss=0.33807599544525146
test: epoch 67, loss 1.196250319480896, acc=0.6027777791023254, loss=1.196250319480896
train: epoch 68, loss 0.3563377857208252, acc=0.8631666898727417, loss=0.3563377857208252
test: epoch 68, loss 1.1726901531219482, acc=0.5166666507720947, loss=1.1726901531219482
train: epoch 69, loss 0.3544633686542511, acc=0.8611666560173035, loss=0.3544633686542511
test: epoch 69, loss 1.0160799026489258, acc=0.5888888835906982, loss=1.0160799026489258
train: epoch 70, loss 0.36260712146759033, acc=0.8541666865348816, loss=0.36260712146759033
test: epoch 70, loss 0.9491783380508423, acc=0.5944444537162781, loss=0.9491783380508423
train: epoch 71, loss 0.3523179888725281, acc=0.8623889088630676, loss=0.3523179888725281
test: epoch 71, loss 1.0158196687698364, acc=0.6333333253860474, loss=1.0158196687698364
train: epoch 72, loss 0.3355740010738373, acc=0.8700555562973022, loss=0.3355740010738373
test: epoch 72, loss 0.8194943070411682, acc=0.625, loss=0.8194943070411682
train: epoch 73, loss 0.34879282116889954, acc=0.8613333106040955, loss=0.34879282116889954
test: epoch 73, loss 1.012891173362732, acc=0.6472222208976746, loss=1.012891173362732
train: epoch 74, loss 0.32433193922042847, acc=0.8732777833938599, loss=0.32433193922042847
test: epoch 74, loss 0.9951721429824829, acc=0.6499999761581421, loss=0.9951721429824829
train: epoch 75, loss 0.3664557933807373, acc=0.8598889112472534, loss=0.3664557933807373
test: epoch 75, loss 1.008313536643982, acc=0.6388888955116272, loss=1.008313536643982
train: epoch 76, loss 0.34253281354904175, acc=0.866777777671814, loss=0.34253281354904175
test: epoch 76, loss 0.8079211711883545, acc=0.6361111402511597, loss=0.8079211711883545
train: epoch 77, loss 0.33309248089790344, acc=0.8697222471237183, loss=0.33309248089790344
test: epoch 77, loss 0.8796175122261047, acc=0.6666666865348816, loss=0.8796175122261047
train: epoch 78, loss 0.3627080023288727, acc=0.8597777485847473, loss=0.3627080023288727
test: epoch 78, loss 1.16093909740448, acc=0.550000011920929, loss=1.16093909740448
train: epoch 79, loss 0.3314668536186218, acc=0.8711110949516296, loss=0.3314668536186218
test: epoch 79, loss 0.8760220408439636, acc=0.5694444179534912, loss=0.8760220408439636
train: epoch 80, loss 0.30929017066955566, acc=0.8799444437026978, loss=0.30929017066955566
test: epoch 80, loss 0.9202723503112793, acc=0.6694444417953491, loss=0.9202723503112793
train: epoch 81, loss 0.3534872531890869, acc=0.8621110916137695, loss=0.3534872531890869
test: epoch 81, loss 0.9319883584976196, acc=0.6222222447395325, loss=0.9319883584976196
train: epoch 82, loss 0.3196871876716614, acc=0.8752222061157227, loss=0.3196871876716614
test: epoch 82, loss 1.4132276773452759, acc=0.46666666865348816, loss=1.4132276773452759
train: epoch 83, loss 0.323434442281723, acc=0.8790555596351624, loss=0.323434442281723
test: epoch 83, loss 1.0312895774841309, acc=0.5111111402511597, loss=1.0312895774841309
train: epoch 84, loss 0.336712121963501, acc=0.870722234249115, loss=0.336712121963501
test: epoch 84, loss 0.9169130325317383, acc=0.6194444298744202, loss=0.9169130325317383
train: epoch 85, loss 0.31412145495414734, acc=0.8806666731834412, loss=0.31412145495414734
test: epoch 85, loss 1.1905584335327148, acc=0.605555534362793, loss=1.1905584335327148
train: epoch 86, loss 0.3186889886856079, acc=0.8784444332122803, loss=0.3186889886856079
test: epoch 86, loss 0.9125905632972717, acc=0.6388888955116272, loss=0.9125905632972717
train: epoch 87, loss 0.3302328586578369, acc=0.8739444613456726, loss=0.3302328586578369
test: epoch 87, loss 0.9412645101547241, acc=0.6333333253860474, loss=0.9412645101547241
train: epoch 88, loss 0.31261777877807617, acc=0.878944456577301, loss=0.31261777877807617
test: epoch 88, loss 1.014432668685913, acc=0.6472222208976746, loss=1.014432668685913
train: epoch 89, loss 0.3095361292362213, acc=0.8786110877990723, loss=0.3095361292362213
test: epoch 89, loss 1.372735857963562, acc=0.550000011920929, loss=1.372735857963562
train: epoch 90, loss 0.3576928675174713, acc=0.8652222156524658, loss=0.3576928675174713
test: epoch 90, loss 0.7536996006965637, acc=0.7222222089767456, loss=0.7536996006965637
train: epoch 91, loss 0.3049905598163605, acc=0.8803333044052124, loss=0.3049905598163605
test: epoch 91, loss 0.9074774384498596, acc=0.7083333134651184, loss=0.9074774384498596
train: epoch 92, loss 0.34638193249702454, acc=0.8683888912200928, loss=0.34638193249702454
test: epoch 92, loss 0.8289927244186401, acc=0.7027778029441833, loss=0.8289927244186401
train: epoch 93, loss 0.33754414319992065, acc=0.8730000257492065, loss=0.33754414319992065
test: epoch 93, loss 0.8891858458518982, acc=0.6333333253860474, loss=0.8891858458518982
train: epoch 94, loss 0.316574364900589, acc=0.8777222037315369, loss=0.316574364900589
test: epoch 94, loss 0.9149799942970276, acc=0.5916666388511658, loss=0.9149799942970276
train: epoch 95, loss 0.343334436416626, acc=0.871055543422699, loss=0.343334436416626
test: epoch 95, loss 1.144686222076416, acc=0.5388888716697693, loss=1.144686222076416
train: epoch 96, loss 0.2986333966255188, acc=0.8880555629730225, loss=0.2986333966255188
test: epoch 96, loss 1.0333187580108643, acc=0.5777778029441833, loss=1.0333187580108643
train: epoch 97, loss 0.33023974299430847, acc=0.8738333582878113, loss=0.33023974299430847
test: epoch 97, loss 0.8174448013305664, acc=0.6833333373069763, loss=0.8174448013305664
train: epoch 98, loss 0.2903365194797516, acc=0.8905555605888367, loss=0.2903365194797516
test: epoch 98, loss 0.6755132079124451, acc=0.7416666746139526, loss=0.6755132079124451
train: epoch 99, loss 0.324336439371109, acc=0.8770555257797241, loss=0.324336439371109
test: epoch 99, loss 0.7277258038520813, acc=0.7083333134651184, loss=0.7277258038520813
train: epoch 100, loss 0.3304619789123535, acc=0.874833345413208, loss=0.3304619789123535
test: epoch 100, loss 0.7497404217720032, acc=0.730555534362793, loss=0.7497404217720032
train: epoch 101, loss 0.30063068866729736, acc=0.8857777714729309, loss=0.30063068866729736
test: epoch 101, loss 0.6954729557037354, acc=0.7194444537162781, loss=0.6954729557037354
train: epoch 102, loss 0.33877497911453247, acc=0.8674444556236267, loss=0.33877497911453247
test: epoch 102, loss 0.7603304982185364, acc=0.7138888835906982, loss=0.7603304982185364
train: epoch 103, loss 0.2923586070537567, acc=0.8898888826370239, loss=0.2923586070537567
test: epoch 103, loss 0.9594087600708008, acc=0.605555534362793, loss=0.9594087600708008
train: epoch 104, loss 0.3293161988258362, acc=0.8749444484710693, loss=0.3293161988258362
test: epoch 104, loss 1.064267873764038, acc=0.6555555462837219, loss=1.064267873764038
train: epoch 105, loss 0.3256906569004059, acc=0.8761110901832581, loss=0.3256906569004059
test: epoch 105, loss 0.7606934905052185, acc=0.6944444179534912, loss=0.7606934905052185
train: epoch 106, loss 0.3202285170555115, acc=0.88227778673172, loss=0.3202285170555115
test: epoch 106, loss 0.8803355097770691, acc=0.6666666865348816, loss=0.8803355097770691
train: epoch 107, loss 0.30370181798934937, acc=0.8859444260597229, loss=0.30370181798934937
test: epoch 107, loss 0.7599135637283325, acc=0.6888889074325562, loss=0.7599135637283325
train: epoch 108, loss 0.3360935151576996, acc=0.8728888630867004, loss=0.3360935151576996
test: epoch 108, loss 0.674147367477417, acc=0.699999988079071, loss=0.674147367477417
train: epoch 109, loss 0.3712078332901001, acc=0.8569444417953491, loss=0.3712078332901001
test: epoch 109, loss 0.7977270483970642, acc=0.7055555582046509, loss=0.7977270483970642
train: epoch 110, loss 0.32554417848587036, acc=0.8772222399711609, loss=0.32554417848587036
test: epoch 110, loss 0.8456878066062927, acc=0.7333333492279053, loss=0.8456878066062927
train: epoch 111, loss 0.3176320195198059, acc=0.8778889179229736, loss=0.3176320195198059
test: epoch 111, loss 1.1397868394851685, acc=0.6499999761581421, loss=1.1397868394851685
train: epoch 112, loss 0.35346412658691406, acc=0.8651666641235352, loss=0.35346412658691406
test: epoch 112, loss 0.8770859837532043, acc=0.6777777671813965, loss=0.8770859837532043
train: epoch 113, loss 0.3305935561656952, acc=0.8741111159324646, loss=0.3305935561656952
test: epoch 113, loss 0.6578028202056885, acc=0.7333333492279053, loss=0.6578028202056885
train: epoch 114, loss 0.3088519275188446, acc=0.8849444389343262, loss=0.3088519275188446
test: epoch 114, loss 0.7109043002128601, acc=0.7111111283302307, loss=0.7109043002128601
train: epoch 115, loss 0.33099567890167236, acc=0.8735555410385132, loss=0.33099567890167236
test: epoch 115, loss 0.7580535411834717, acc=0.7361111044883728, loss=0.7580535411834717
train: epoch 116, loss 0.31247568130493164, acc=0.879277765750885, loss=0.31247568130493164
test: epoch 116, loss 0.671076238155365, acc=0.7388888597488403, loss=0.671076238155365
train: epoch 117, loss 0.33360376954078674, acc=0.8739444613456726, loss=0.33360376954078674
test: epoch 117, loss 0.9057921171188354, acc=0.6388888955116272, loss=0.9057921171188354
train: epoch 118, loss 0.35446950793266296, acc=0.8657777905464172, loss=0.35446950793266296
test: epoch 118, loss 0.781845211982727, acc=0.7222222089767456, loss=0.781845211982727
train: epoch 119, loss 0.34603896737098694, acc=0.867888867855072, loss=0.34603896737098694
test: epoch 119, loss 0.799087643623352, acc=0.6861110925674438, loss=0.799087643623352
train: epoch 120, loss 0.3034132421016693, acc=0.8850555419921875, loss=0.3034132421016693
test: epoch 120, loss 0.5960996150970459, acc=0.7416666746139526, loss=0.5960996150970459
train: epoch 121, loss 0.3605252206325531, acc=0.8610000014305115, loss=0.3605252206325531
test: epoch 121, loss 0.6041213870048523, acc=0.7749999761581421, loss=0.6041213870048523
train: epoch 122, loss 0.3842894732952118, acc=0.8526666760444641, loss=0.3842894732952118
test: epoch 122, loss 0.7994762063026428, acc=0.6666666865348816, loss=0.7994762063026428
train: epoch 123, loss 0.33777451515197754, acc=0.8717777729034424, loss=0.33777451515197754
test: epoch 123, loss 0.7848625183105469, acc=0.7027778029441833, loss=0.7848625183105469
train: epoch 124, loss 0.39977383613586426, acc=0.8492222428321838, loss=0.39977383613586426
test: epoch 124, loss 0.7802827954292297, acc=0.6583333611488342, loss=0.7802827954292297
train: epoch 125, loss 0.3427046239376068, acc=0.8645555377006531, loss=0.3427046239376068
test: epoch 125, loss 0.6977912187576294, acc=0.6972222328186035, loss=0.6977912187576294
train: epoch 126, loss 0.37143954634666443, acc=0.8476666808128357, loss=0.37143954634666443
test: epoch 126, loss 0.8562237620353699, acc=0.6722221970558167, loss=0.8562237620353699
train: epoch 127, loss 0.3631860315799713, acc=0.8578888773918152, loss=0.3631860315799713
test: epoch 127, loss 0.5802509188652039, acc=0.7638888955116272, loss=0.5802509188652039
train: epoch 128, loss 0.306092768907547, acc=0.8823888897895813, loss=0.306092768907547
test: epoch 128, loss 0.6094154715538025, acc=0.7666666507720947, loss=0.6094154715538025
train: epoch 129, loss 0.3231998383998871, acc=0.8777222037315369, loss=0.3231998383998871
test: epoch 129, loss 0.8661259412765503, acc=0.7638888955116272, loss=0.8661259412765503
train: epoch 130, loss 0.34652507305145264, acc=0.8692777752876282, loss=0.34652507305145264
test: epoch 130, loss 0.6432453989982605, acc=0.7416666746139526, loss=0.6432453989982605
train: epoch 131, loss 0.33542028069496155, acc=0.8663333058357239, loss=0.33542028069496155
test: epoch 131, loss 0.4942530393600464, acc=0.7749999761581421, loss=0.4942530393600464
train: epoch 132, loss 0.31648796796798706, acc=0.8723888993263245, loss=0.31648796796798706
test: epoch 132, loss 0.5927173495292664, acc=0.7638888955116272, loss=0.5927173495292664
train: epoch 133, loss 0.33669885993003845, acc=0.8681666851043701, loss=0.33669885993003845
test: epoch 133, loss 0.5347509980201721, acc=0.7777777910232544, loss=0.5347509980201721
train: epoch 134, loss 0.3314962387084961, acc=0.8685555458068848, loss=0.3314962387084961
test: epoch 134, loss 0.4916636645793915, acc=0.7805555462837219, loss=0.4916636645793915
train: epoch 135, loss 0.34038612246513367, acc=0.8645555377006531, loss=0.34038612246513367
test: epoch 135, loss 0.544253408908844, acc=0.7749999761581421, loss=0.544253408908844
train: epoch 136, loss 0.44955554604530334, acc=0.8143888711929321, loss=0.44955554604530334
test: epoch 136, loss 0.673603355884552, acc=0.7388888597488403, loss=0.673603355884552
train: epoch 137, loss 0.35711055994033813, acc=0.8529999852180481, loss=0.35711055994033813
test: epoch 137, loss 0.45819318294525146, acc=0.7749999761581421, loss=0.45819318294525146
train: epoch 138, loss 0.37960103154182434, acc=0.8502777814865112, loss=0.37960103154182434
test: epoch 138, loss 0.5278415679931641, acc=0.769444465637207, loss=0.5278415679931641
train: epoch 139, loss 0.3474372923374176, acc=0.8592222332954407, loss=0.3474372923374176
test: epoch 139, loss 0.6921021938323975, acc=0.7527777552604675, loss=0.6921021938323975
train: epoch 140, loss 0.3681544065475464, acc=0.8414999842643738, loss=0.3681544065475464
test: epoch 140, loss 0.6476979851722717, acc=0.7388888597488403, loss=0.6476979851722717
train: epoch 141, loss 0.31983843445777893, acc=0.8669999837875366, loss=0.31983843445777893
test: epoch 141, loss 0.5444359183311462, acc=0.7722222208976746, loss=0.5444359183311462
train: epoch 142, loss 0.356169730424881, acc=0.8542777895927429, loss=0.356169730424881
test: epoch 142, loss 0.5796694755554199, acc=0.7583333253860474, loss=0.5796694755554199
train: epoch 143, loss 0.33803504705429077, acc=0.8610555529594421, loss=0.33803504705429077
test: epoch 143, loss 0.601317286491394, acc=0.7722222208976746, loss=0.601317286491394
train: epoch 144, loss 0.35502225160598755, acc=0.8571110963821411, loss=0.35502225160598755
test: epoch 144, loss 0.7689844369888306, acc=0.7277777791023254, loss=0.7689844369888306
train: epoch 145, loss 0.3446599245071411, acc=0.8643888831138611, loss=0.3446599245071411
test: epoch 145, loss 0.6312286257743835, acc=0.7638888955116272, loss=0.6312286257743835
train: epoch 146, loss 0.3098667562007904, acc=0.8702777624130249, loss=0.3098667562007904
test: epoch 146, loss 0.638769805431366, acc=0.7722222208976746, loss=0.638769805431366
train: epoch 147, loss 0.3412322402000427, acc=0.8604444265365601, loss=0.3412322402000427
test: epoch 147, loss 0.6425884962081909, acc=0.7638888955116272, loss=0.6425884962081909
train: epoch 148, loss 0.33215758204460144, acc=0.8669999837875366, loss=0.33215758204460144
test: epoch 148, loss 0.6876841187477112, acc=0.7222222089767456, loss=0.6876841187477112
train: epoch 149, loss 0.3551580607891083, acc=0.8541666865348816, loss=0.3551580607891083
test: epoch 149, loss 0.4964215159416199, acc=0.7749999761581421, loss=0.4964215159416199
train: epoch 150, loss 0.32555633783340454, acc=0.8708333373069763, loss=0.32555633783340454
test: epoch 150, loss 0.6756001114845276, acc=0.7583333253860474, loss=0.6756001114845276
