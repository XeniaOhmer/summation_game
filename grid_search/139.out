# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=1.5", "--temp_decay=0.99", "--one_hot=0", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=1341051227, receiver_embed_dim=128, save_run=0, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=1341051227, receiver_embed_dim=128, save_run=False, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.559434175491333, acc=0.13233333826065063, loss=2.559434175491333
test: epoch 1, loss 3.9669790267944336, acc=0.0694444477558136, loss=3.9669790267944336
train: epoch 2, loss 2.023686408996582, acc=0.22499999403953552, loss=2.023686408996582
test: epoch 2, loss 3.186682939529419, acc=0.11944444477558136, loss=3.186682939529419
train: epoch 3, loss 1.8014737367630005, acc=0.28833332657814026, loss=1.8014737367630005
test: epoch 3, loss 2.8517532348632812, acc=0.1666666716337204, loss=2.8517532348632812
train: epoch 4, loss 1.6523828506469727, acc=0.33666667342185974, loss=1.6523828506469727
test: epoch 4, loss 3.0490164756774902, acc=0.13611111044883728, loss=3.0490164756774902
train: epoch 5, loss 1.5483602285385132, acc=0.371055543422699, loss=1.5483602285385132
test: epoch 5, loss 2.9559032917022705, acc=0.13611111044883728, loss=2.9559032917022705
train: epoch 6, loss 1.4718579053878784, acc=0.3982222080230713, loss=1.4718579053878784
test: epoch 6, loss 2.8948283195495605, acc=0.0972222238779068, loss=2.8948283195495605
train: epoch 7, loss 1.4298008680343628, acc=0.41627776622772217, loss=1.4298008680343628
test: epoch 7, loss 2.779207706451416, acc=0.12777778506278992, loss=2.779207706451416
train: epoch 8, loss 1.3892302513122559, acc=0.43805554509162903, loss=1.3892302513122559
test: epoch 8, loss 2.646843671798706, acc=0.16388888657093048, loss=2.646843671798706
train: epoch 9, loss 1.3098814487457275, acc=0.4703333377838135, loss=1.3098814487457275
test: epoch 9, loss 2.86529541015625, acc=0.1666666716337204, loss=2.86529541015625
train: epoch 10, loss 1.3017688989639282, acc=0.47600001096725464, loss=1.3017688989639282
test: epoch 10, loss 2.720959186553955, acc=0.15833333134651184, loss=2.720959186553955
train: epoch 11, loss 1.2413448095321655, acc=0.49594444036483765, loss=1.2413448095321655
test: epoch 11, loss 2.533193349838257, acc=0.1666666716337204, loss=2.533193349838257
train: epoch 12, loss 1.2189854383468628, acc=0.4995555579662323, loss=1.2189854383468628
test: epoch 12, loss 2.6002001762390137, acc=0.13611111044883728, loss=2.6002001762390137
train: epoch 13, loss 1.1940672397613525, acc=0.5183888673782349, loss=1.1940672397613525
test: epoch 13, loss 2.5559170246124268, acc=0.15555556118488312, loss=2.5559170246124268
train: epoch 14, loss 1.1696642637252808, acc=0.5258333086967468, loss=1.1696642637252808
test: epoch 14, loss 2.664954662322998, acc=0.19722221791744232, loss=2.664954662322998
train: epoch 15, loss 1.1573737859725952, acc=0.5333889126777649, loss=1.1573737859725952
test: epoch 15, loss 2.8454489707946777, acc=0.15000000596046448, loss=2.8454489707946777
train: epoch 16, loss 1.1340997219085693, acc=0.5394999980926514, loss=1.1340997219085693
test: epoch 16, loss 2.508960008621216, acc=0.14444445073604584, loss=2.508960008621216
train: epoch 17, loss 1.1193568706512451, acc=0.547166645526886, loss=1.1193568706512451
test: epoch 17, loss 2.6746156215667725, acc=0.15555556118488312, loss=2.6746156215667725
train: epoch 18, loss 1.0934228897094727, acc=0.5576666593551636, loss=1.0934228897094727
test: epoch 18, loss 2.4955785274505615, acc=0.15000000596046448, loss=2.4955785274505615
train: epoch 19, loss 1.0816408395767212, acc=0.5556666851043701, loss=1.0816408395767212
test: epoch 19, loss 2.2879233360290527, acc=0.23333333432674408, loss=2.2879233360290527
train: epoch 20, loss 1.063227653503418, acc=0.5721666812896729, loss=1.063227653503418
test: epoch 20, loss 2.185286521911621, acc=0.21944443881511688, loss=2.185286521911621
train: epoch 21, loss 1.0371448993682861, acc=0.5776666402816772, loss=1.0371448993682861
test: epoch 21, loss 2.298992872238159, acc=0.21666666865348816, loss=2.298992872238159
train: epoch 22, loss 1.0387909412384033, acc=0.5801666378974915, loss=1.0387909412384033
test: epoch 22, loss 2.481534481048584, acc=0.18611110746860504, loss=2.481534481048584
train: epoch 23, loss 1.0361816883087158, acc=0.5860000252723694, loss=1.0361816883087158
test: epoch 23, loss 2.6089580059051514, acc=0.1527777761220932, loss=2.6089580059051514
train: epoch 24, loss 1.0108768939971924, acc=0.5913333296775818, loss=1.0108768939971924
test: epoch 24, loss 2.6629443168640137, acc=0.17222222685813904, loss=2.6629443168640137
train: epoch 25, loss 1.0013809204101562, acc=0.5948333144187927, loss=1.0013809204101562
test: epoch 25, loss 2.284010648727417, acc=0.17777778208255768, loss=2.284010648727417
train: epoch 26, loss 0.9854426383972168, acc=0.6100555658340454, loss=0.9854426383972168
test: epoch 26, loss 2.5761916637420654, acc=0.18888889253139496, loss=2.5761916637420654
train: epoch 27, loss 0.9966684579849243, acc=0.5969444513320923, loss=0.9966684579849243
test: epoch 27, loss 2.346378803253174, acc=0.2361111044883728, loss=2.346378803253174
train: epoch 28, loss 0.9917778372764587, acc=0.6022777557373047, loss=0.9917778372764587
test: epoch 28, loss 2.053335189819336, acc=0.2916666567325592, loss=2.053335189819336
train: epoch 29, loss 0.9841883182525635, acc=0.6038888692855835, loss=0.9841883182525635
test: epoch 29, loss 2.402991771697998, acc=0.21111111342906952, loss=2.402991771697998
train: epoch 30, loss 0.9366490244865417, acc=0.6204444169998169, loss=0.9366490244865417
test: epoch 30, loss 2.103550910949707, acc=0.24722221493721008, loss=2.103550910949707
train: epoch 31, loss 0.9525430798530579, acc=0.6129444241523743, loss=0.9525430798530579
test: epoch 31, loss 2.3611056804656982, acc=0.23333333432674408, loss=2.3611056804656982
train: epoch 32, loss 0.9346246719360352, acc=0.6273333430290222, loss=0.9346246719360352
test: epoch 32, loss 2.168999195098877, acc=0.16944444179534912, loss=2.168999195098877
train: epoch 33, loss 0.9297508597373962, acc=0.6270555257797241, loss=0.9297508597373962
test: epoch 33, loss 2.448230266571045, acc=0.18611110746860504, loss=2.448230266571045
train: epoch 34, loss 0.9397199153900146, acc=0.6255555748939514, loss=0.9397199153900146
test: epoch 34, loss 1.9509145021438599, acc=0.2805555462837219, loss=1.9509145021438599
train: epoch 35, loss 0.9214017987251282, acc=0.6224444508552551, loss=0.9214017987251282
test: epoch 35, loss 2.4193155765533447, acc=0.1944444477558136, loss=2.4193155765533447
train: epoch 36, loss 0.9233747720718384, acc=0.6285555362701416, loss=0.9233747720718384
test: epoch 36, loss 1.804870367050171, acc=0.28611111640930176, loss=1.804870367050171
train: epoch 37, loss 0.9031081795692444, acc=0.6377778053283691, loss=0.9031081795692444
test: epoch 37, loss 2.0436480045318604, acc=0.3166666626930237, loss=2.0436480045318604
train: epoch 38, loss 0.9072957634925842, acc=0.6338333487510681, loss=0.9072957634925842
test: epoch 38, loss 2.1875505447387695, acc=0.23333333432674408, loss=2.1875505447387695
train: epoch 39, loss 0.8920725584030151, acc=0.6397222280502319, loss=0.8920725584030151
test: epoch 39, loss 2.136892080307007, acc=0.2611111104488373, loss=2.136892080307007
train: epoch 40, loss 0.8759271502494812, acc=0.6420000195503235, loss=0.8759271502494812
test: epoch 40, loss 2.1468920707702637, acc=0.25833332538604736, loss=2.1468920707702637
train: epoch 41, loss 0.8938903212547302, acc=0.6413333415985107, loss=0.8938903212547302
test: epoch 41, loss 1.954033613204956, acc=0.2916666567325592, loss=1.954033613204956
train: epoch 42, loss 0.8661556243896484, acc=0.6511111259460449, loss=0.8661556243896484
test: epoch 42, loss 1.6753009557724, acc=0.31111112236976624, loss=1.6753009557724
train: epoch 43, loss 0.8609218597412109, acc=0.6541110873222351, loss=0.8609218597412109
test: epoch 43, loss 1.776544213294983, acc=0.3027777671813965, loss=1.776544213294983
train: epoch 44, loss 0.9064108729362488, acc=0.6345000267028809, loss=0.9064108729362488
test: epoch 44, loss 1.7477021217346191, acc=0.3027777671813965, loss=1.7477021217346191
train: epoch 45, loss 0.8734539151191711, acc=0.6489999890327454, loss=0.8734539151191711
test: epoch 45, loss 1.8400676250457764, acc=0.32777777314186096, loss=1.8400676250457764
train: epoch 46, loss 0.8666693568229675, acc=0.6514999866485596, loss=0.8666693568229675
test: epoch 46, loss 1.9249141216278076, acc=0.3055555522441864, loss=1.9249141216278076
train: epoch 47, loss 0.8943319320678711, acc=0.6458888649940491, loss=0.8943319320678711
test: epoch 47, loss 2.0715434551239014, acc=0.25833332538604736, loss=2.0715434551239014
train: epoch 48, loss 0.8637259602546692, acc=0.6493333578109741, loss=0.8637259602546692
test: epoch 48, loss 1.8585296869277954, acc=0.2611111104488373, loss=1.8585296869277954
train: epoch 49, loss 0.8832671642303467, acc=0.6461111307144165, loss=0.8832671642303467
test: epoch 49, loss 2.08548903465271, acc=0.32777777314186096, loss=2.08548903465271
train: epoch 50, loss 0.855265200138092, acc=0.6598333120346069, loss=0.855265200138092
test: epoch 50, loss 1.6070936918258667, acc=0.3472222089767456, loss=1.6070936918258667
train: epoch 51, loss 0.8588317632675171, acc=0.6535000205039978, loss=0.8588317632675171
test: epoch 51, loss 1.6982059478759766, acc=0.3861111104488373, loss=1.6982059478759766
train: epoch 52, loss 0.8618587851524353, acc=0.6466110944747925, loss=0.8618587851524353
test: epoch 52, loss 1.9428644180297852, acc=0.2527777850627899, loss=1.9428644180297852
train: epoch 53, loss 0.8543397188186646, acc=0.652222216129303, loss=0.8543397188186646
test: epoch 53, loss 1.654628872871399, acc=0.36944442987442017, loss=1.654628872871399
train: epoch 54, loss 0.8682325482368469, acc=0.6489444375038147, loss=0.8682325482368469
test: epoch 54, loss 1.7963556051254272, acc=0.2888889014720917, loss=1.7963556051254272
train: epoch 55, loss 0.8436803221702576, acc=0.6621111035346985, loss=0.8436803221702576
test: epoch 55, loss 1.7066224813461304, acc=0.31388887763023376, loss=1.7066224813461304
train: epoch 56, loss 0.8574546575546265, acc=0.6485000252723694, loss=0.8574546575546265
test: epoch 56, loss 1.641915202140808, acc=0.29722222685813904, loss=1.641915202140808
train: epoch 57, loss 0.8364677429199219, acc=0.657444417476654, loss=0.8364677429199219
test: epoch 57, loss 1.9342654943466187, acc=0.3361110985279083, loss=1.9342654943466187
train: epoch 58, loss 0.8550715446472168, acc=0.6543889045715332, loss=0.8550715446472168
test: epoch 58, loss 1.781106948852539, acc=0.30000001192092896, loss=1.781106948852539
train: epoch 59, loss 0.8525598049163818, acc=0.6523333191871643, loss=0.8525598049163818
test: epoch 59, loss 1.8152759075164795, acc=0.3194444477558136, loss=1.8152759075164795
train: epoch 60, loss 0.845461905002594, acc=0.6604999899864197, loss=0.845461905002594
test: epoch 60, loss 1.689782738685608, acc=0.31111112236976624, loss=1.689782738685608
train: epoch 61, loss 0.834388792514801, acc=0.6605555415153503, loss=0.834388792514801
test: epoch 61, loss 1.7528457641601562, acc=0.2777777910232544, loss=1.7528457641601562
train: epoch 62, loss 0.8472895622253418, acc=0.6565555334091187, loss=0.8472895622253418
test: epoch 62, loss 1.6601122617721558, acc=0.2611111104488373, loss=1.6601122617721558
train: epoch 63, loss 0.8491658568382263, acc=0.6567777991294861, loss=0.8491658568382263
test: epoch 63, loss 1.8223927021026611, acc=0.31111112236976624, loss=1.8223927021026611
train: epoch 64, loss 0.8369463682174683, acc=0.6615555286407471, loss=0.8369463682174683
test: epoch 64, loss 1.569888710975647, acc=0.36666667461395264, loss=1.569888710975647
train: epoch 65, loss 0.8360008597373962, acc=0.659166693687439, loss=0.8360008597373962
test: epoch 65, loss 1.6716936826705933, acc=0.38333332538604736, loss=1.6716936826705933
train: epoch 66, loss 0.8464942574501038, acc=0.6513888835906982, loss=0.8464942574501038
test: epoch 66, loss 1.6568795442581177, acc=0.28333333134651184, loss=1.6568795442581177
train: epoch 67, loss 0.8604553937911987, acc=0.6549999713897705, loss=0.8604553937911987
test: epoch 67, loss 1.4660289287567139, acc=0.3305555582046509, loss=1.4660289287567139
train: epoch 68, loss 0.8382583856582642, acc=0.660444438457489, loss=0.8382583856582642
test: epoch 68, loss 1.8992159366607666, acc=0.3611111044883728, loss=1.8992159366607666
train: epoch 69, loss 0.8523966670036316, acc=0.6572222113609314, loss=0.8523966670036316
test: epoch 69, loss 1.5591492652893066, acc=0.35277777910232544, loss=1.5591492652893066
train: epoch 70, loss 0.840447187423706, acc=0.6547777652740479, loss=0.840447187423706
test: epoch 70, loss 1.674168586730957, acc=0.3222222328186035, loss=1.674168586730957
train: epoch 71, loss 0.8521720767021179, acc=0.6562222242355347, loss=0.8521720767021179
test: epoch 71, loss 1.4987417459487915, acc=0.3638888895511627, loss=1.4987417459487915
train: epoch 72, loss 0.8242591619491577, acc=0.6625000238418579, loss=0.8242591619491577
test: epoch 72, loss 1.48358154296875, acc=0.3361110985279083, loss=1.48358154296875
train: epoch 73, loss 0.8302467465400696, acc=0.6673333048820496, loss=0.8302467465400696
test: epoch 73, loss 1.5273891687393188, acc=0.3888888955116272, loss=1.5273891687393188
train: epoch 74, loss 0.8142003417015076, acc=0.6706666946411133, loss=0.8142003417015076
test: epoch 74, loss 1.8687466382980347, acc=0.38333332538604736, loss=1.8687466382980347
train: epoch 75, loss 0.8184065818786621, acc=0.6698889136314392, loss=0.8184065818786621
test: epoch 75, loss 1.6444505453109741, acc=0.3472222089767456, loss=1.6444505453109741
train: epoch 76, loss 0.8175348043441772, acc=0.6729999780654907, loss=0.8175348043441772
test: epoch 76, loss 1.4433836936950684, acc=0.4444444477558136, loss=1.4433836936950684
train: epoch 77, loss 0.802574098110199, acc=0.6750555634498596, loss=0.802574098110199
test: epoch 77, loss 1.6279293298721313, acc=0.3777777850627899, loss=1.6279293298721313
train: epoch 78, loss 0.8025571703910828, acc=0.6779444217681885, loss=0.8025571703910828
test: epoch 78, loss 1.571664810180664, acc=0.3916666805744171, loss=1.571664810180664
train: epoch 79, loss 0.7925129532814026, acc=0.6768333315849304, loss=0.7925129532814026
test: epoch 79, loss 1.6042917966842651, acc=0.38333332538604736, loss=1.6042917966842651
train: epoch 80, loss 0.8008464574813843, acc=0.6798333525657654, loss=0.8008464574813843
test: epoch 80, loss 1.5991945266723633, acc=0.35277777910232544, loss=1.5991945266723633
train: epoch 81, loss 0.7708156704902649, acc=0.6885555386543274, loss=0.7708156704902649
test: epoch 81, loss 1.7061203718185425, acc=0.32777777314186096, loss=1.7061203718185425
train: epoch 82, loss 0.7921468019485474, acc=0.6813889145851135, loss=0.7921468019485474
test: epoch 82, loss 1.4498884677886963, acc=0.35555556416511536, loss=1.4498884677886963
train: epoch 83, loss 0.8190774917602539, acc=0.6729444265365601, loss=0.8190774917602539
test: epoch 83, loss 1.395862340927124, acc=0.4277777671813965, loss=1.395862340927124
train: epoch 84, loss 0.7862374186515808, acc=0.6883888840675354, loss=0.7862374186515808
test: epoch 84, loss 1.5485060214996338, acc=0.41111111640930176, loss=1.5485060214996338
train: epoch 85, loss 0.7700362801551819, acc=0.6913333535194397, loss=0.7700362801551819
test: epoch 85, loss 1.3931978940963745, acc=0.3611111044883728, loss=1.3931978940963745
train: epoch 86, loss 0.7639159560203552, acc=0.6926666498184204, loss=0.7639159560203552
test: epoch 86, loss 1.684938907623291, acc=0.36666667461395264, loss=1.684938907623291
train: epoch 87, loss 0.7832203507423401, acc=0.6859999895095825, loss=0.7832203507423401
test: epoch 87, loss 1.3964704275131226, acc=0.4555555582046509, loss=1.3964704275131226
train: epoch 88, loss 0.7691734433174133, acc=0.6874444484710693, loss=0.7691734433174133
test: epoch 88, loss 1.3253532648086548, acc=0.4333333373069763, loss=1.3253532648086548
train: epoch 89, loss 0.7548717260360718, acc=0.6918333172798157, loss=0.7548717260360718
test: epoch 89, loss 1.5673534870147705, acc=0.35555556416511536, loss=1.5673534870147705
train: epoch 90, loss 0.7677993774414062, acc=0.6902777552604675, loss=0.7677993774414062
test: epoch 90, loss 1.3661606311798096, acc=0.40833333134651184, loss=1.3661606311798096
train: epoch 91, loss 0.7483274936676025, acc=0.7012777924537659, loss=0.7483274936676025
test: epoch 91, loss 1.444619059562683, acc=0.3472222089767456, loss=1.444619059562683
train: epoch 92, loss 0.7639265656471252, acc=0.6938889026641846, loss=0.7639265656471252
test: epoch 92, loss 1.401171088218689, acc=0.4416666626930237, loss=1.401171088218689
train: epoch 93, loss 0.7449048757553101, acc=0.6999444365501404, loss=0.7449048757553101
test: epoch 93, loss 1.3950001001358032, acc=0.4861111044883728, loss=1.3950001001358032
train: epoch 94, loss 0.7562499642372131, acc=0.6998888850212097, loss=0.7562499642372131
test: epoch 94, loss 1.437497854232788, acc=0.4138889014720917, loss=1.437497854232788
train: epoch 95, loss 0.7474220991134644, acc=0.699222207069397, loss=0.7474220991134644
test: epoch 95, loss 1.357019305229187, acc=0.4416666626930237, loss=1.357019305229187
train: epoch 96, loss 0.7311305999755859, acc=0.7099999785423279, loss=0.7311305999755859
test: epoch 96, loss 1.334039330482483, acc=0.45277777314186096, loss=1.334039330482483
train: epoch 97, loss 0.7329683899879456, acc=0.7048888802528381, loss=0.7329683899879456
test: epoch 97, loss 1.339825987815857, acc=0.4749999940395355, loss=1.339825987815857
train: epoch 98, loss 0.7174521088600159, acc=0.7092221975326538, loss=0.7174521088600159
test: epoch 98, loss 1.3900891542434692, acc=0.3861111104488373, loss=1.3900891542434692
train: epoch 99, loss 0.7264065742492676, acc=0.7094444632530212, loss=0.7264065742492676
test: epoch 99, loss 1.5760078430175781, acc=0.42222222685813904, loss=1.5760078430175781
train: epoch 100, loss 0.7499387860298157, acc=0.7032222151756287, loss=0.7499387860298157
test: epoch 100, loss 1.4199579954147339, acc=0.46388888359069824, loss=1.4199579954147339
train: epoch 101, loss 0.7061049342155457, acc=0.7160000205039978, loss=0.7061049342155457
test: epoch 101, loss 1.3335740566253662, acc=0.4888888895511627, loss=1.3335740566253662
train: epoch 102, loss 0.7133392691612244, acc=0.7151111364364624, loss=0.7133392691612244
test: epoch 102, loss 1.4058781862258911, acc=0.4444444477558136, loss=1.4058781862258911
train: epoch 103, loss 0.7190291881561279, acc=0.7134444713592529, loss=0.7190291881561279
test: epoch 103, loss 1.455471158027649, acc=0.3722222149372101, loss=1.455471158027649
train: epoch 104, loss 0.7029311060905457, acc=0.7166110873222351, loss=0.7029311060905457
test: epoch 104, loss 1.3122667074203491, acc=0.4472222328186035, loss=1.3122667074203491
train: epoch 105, loss 0.723275363445282, acc=0.7128333449363708, loss=0.723275363445282
test: epoch 105, loss 1.3313195705413818, acc=0.4583333432674408, loss=1.3313195705413818
train: epoch 106, loss 0.6949504613876343, acc=0.7187777757644653, loss=0.6949504613876343
test: epoch 106, loss 1.312220573425293, acc=0.4138889014720917, loss=1.312220573425293
train: epoch 107, loss 0.7083829045295715, acc=0.7160555720329285, loss=0.7083829045295715
test: epoch 107, loss 1.5866365432739258, acc=0.4000000059604645, loss=1.5866365432739258
train: epoch 108, loss 0.7056087851524353, acc=0.7161111235618591, loss=0.7056087851524353
test: epoch 108, loss 1.4876269102096558, acc=0.4749999940395355, loss=1.4876269102096558
train: epoch 109, loss 0.7170739769935608, acc=0.7134444713592529, loss=0.7170739769935608
test: epoch 109, loss 1.4713389873504639, acc=0.46388888359069824, loss=1.4713389873504639
train: epoch 110, loss 0.6840368509292603, acc=0.7243333458900452, loss=0.6840368509292603
test: epoch 110, loss 1.3111772537231445, acc=0.4722222089767456, loss=1.3111772537231445
train: epoch 111, loss 0.6824156045913696, acc=0.7251666784286499, loss=0.6824156045913696
test: epoch 111, loss 1.2654383182525635, acc=0.5166666507720947, loss=1.2654383182525635
train: epoch 112, loss 0.700554370880127, acc=0.7189444303512573, loss=0.700554370880127
test: epoch 112, loss 1.3657286167144775, acc=0.4277777671813965, loss=1.3657286167144775
train: epoch 113, loss 0.692908525466919, acc=0.726722240447998, loss=0.692908525466919
test: epoch 113, loss 1.4178084135055542, acc=0.43888887763023376, loss=1.4178084135055542
train: epoch 114, loss 0.6895722150802612, acc=0.7253333330154419, loss=0.6895722150802612
test: epoch 114, loss 1.3382062911987305, acc=0.46666666865348816, loss=1.3382062911987305
train: epoch 115, loss 0.69710773229599, acc=0.7208889126777649, loss=0.69710773229599
test: epoch 115, loss 1.8162603378295898, acc=0.35277777910232544, loss=1.8162603378295898
train: epoch 116, loss 0.6966749429702759, acc=0.7211111187934875, loss=0.6966749429702759
test: epoch 116, loss 1.271867036819458, acc=0.46388888359069824, loss=1.271867036819458
train: epoch 117, loss 0.681208610534668, acc=0.7294999957084656, loss=0.681208610534668
test: epoch 117, loss 1.3853106498718262, acc=0.48055556416511536, loss=1.3853106498718262
train: epoch 118, loss 0.6884485483169556, acc=0.7246111035346985, loss=0.6884485483169556
test: epoch 118, loss 1.3622863292694092, acc=0.4694444537162781, loss=1.3622863292694092
train: epoch 119, loss 0.6771061420440674, acc=0.7295555472373962, loss=0.6771061420440674
test: epoch 119, loss 1.3917244672775269, acc=0.43888887763023376, loss=1.3917244672775269
train: epoch 120, loss 0.6759822368621826, acc=0.7307778000831604, loss=0.6759822368621826
test: epoch 120, loss 1.5733178853988647, acc=0.4194444417953491, loss=1.5733178853988647
train: epoch 121, loss 0.6784905195236206, acc=0.7251666784286499, loss=0.6784905195236206
test: epoch 121, loss 1.43994140625, acc=0.4305555522441864, loss=1.43994140625
train: epoch 122, loss 0.6569058895111084, acc=0.7389444708824158, loss=0.6569058895111084
test: epoch 122, loss 1.31795334815979, acc=0.4583333432674408, loss=1.31795334815979
train: epoch 123, loss 0.6720260381698608, acc=0.7322777509689331, loss=0.6720260381698608
test: epoch 123, loss 1.3382083177566528, acc=0.4333333373069763, loss=1.3382083177566528
train: epoch 124, loss 0.6611620783805847, acc=0.7309444546699524, loss=0.6611620783805847
test: epoch 124, loss 1.2827893495559692, acc=0.5138888955116272, loss=1.2827893495559692
train: epoch 125, loss 0.6811783313751221, acc=0.7280555367469788, loss=0.6811783313751221
test: epoch 125, loss 1.5547770261764526, acc=0.4722222089767456, loss=1.5547770261764526
train: epoch 126, loss 0.6522343158721924, acc=0.7410555481910706, loss=0.6522343158721924
test: epoch 126, loss 1.3239150047302246, acc=0.4888888895511627, loss=1.3239150047302246
train: epoch 127, loss 0.650127649307251, acc=0.7392222285270691, loss=0.650127649307251
test: epoch 127, loss 1.3711124658584595, acc=0.46388888359069824, loss=1.3711124658584595
train: epoch 128, loss 0.6707403659820557, acc=0.7339444160461426, loss=0.6707403659820557
test: epoch 128, loss 1.2443228960037231, acc=0.48055556416511536, loss=1.2443228960037231
train: epoch 129, loss 0.6469168663024902, acc=0.7399444580078125, loss=0.6469168663024902
test: epoch 129, loss 1.3516223430633545, acc=0.46666666865348816, loss=1.3516223430633545
train: epoch 130, loss 0.6852275729179382, acc=0.7310555577278137, loss=0.6852275729179382
test: epoch 130, loss 1.627113938331604, acc=0.4416666626930237, loss=1.627113938331604
train: epoch 131, loss 0.6809633374214172, acc=0.7355555295944214, loss=0.6809633374214172
test: epoch 131, loss 1.3713961839675903, acc=0.4027777910232544, loss=1.3713961839675903
train: epoch 132, loss 0.6486244797706604, acc=0.7454444169998169, loss=0.6486244797706604
test: epoch 132, loss 1.2426772117614746, acc=0.4833333194255829, loss=1.2426772117614746
train: epoch 133, loss 0.6405745148658752, acc=0.7436666488647461, loss=0.6405745148658752
test: epoch 133, loss 1.3404408693313599, acc=0.44999998807907104, loss=1.3404408693313599
train: epoch 134, loss 0.6546890139579773, acc=0.7388888597488403, loss=0.6546890139579773
test: epoch 134, loss 1.2380907535552979, acc=0.4833333194255829, loss=1.2380907535552979
train: epoch 135, loss 0.6574322581291199, acc=0.7382222414016724, loss=0.6574322581291199
test: epoch 135, loss 1.3546558618545532, acc=0.4833333194255829, loss=1.3546558618545532
train: epoch 136, loss 0.6348952651023865, acc=0.7465555667877197, loss=0.6348952651023865
test: epoch 136, loss 1.4799144268035889, acc=0.4749999940395355, loss=1.4799144268035889
train: epoch 137, loss 0.6398906111717224, acc=0.7443888783454895, loss=0.6398906111717224
test: epoch 137, loss 1.4106853008270264, acc=0.4694444537162781, loss=1.4106853008270264
train: epoch 138, loss 0.628697395324707, acc=0.7508333325386047, loss=0.628697395324707
test: epoch 138, loss 1.5796078443527222, acc=0.4000000059604645, loss=1.5796078443527222
train: epoch 139, loss 0.6517717242240906, acc=0.7418333292007446, loss=0.6517717242240906
test: epoch 139, loss 1.503373622894287, acc=0.43611112236976624, loss=1.503373622894287
train: epoch 140, loss 0.6695283055305481, acc=0.7333889007568359, loss=0.6695283055305481
test: epoch 140, loss 1.2298651933670044, acc=0.4888888895511627, loss=1.2298651933670044
train: epoch 141, loss 0.6334933042526245, acc=0.7456666827201843, loss=0.6334933042526245
test: epoch 141, loss 1.2224290370941162, acc=0.4972222149372101, loss=1.2224290370941162
train: epoch 142, loss 0.6578309535980225, acc=0.7466111183166504, loss=0.6578309535980225
test: epoch 142, loss 1.1578415632247925, acc=0.4555555582046509, loss=1.1578415632247925
train: epoch 143, loss 0.6376767158508301, acc=0.7488889098167419, loss=0.6376767158508301
test: epoch 143, loss 1.2977286577224731, acc=0.49444442987442017, loss=1.2977286577224731
train: epoch 144, loss 0.6420544981956482, acc=0.7484444379806519, loss=0.6420544981956482
test: epoch 144, loss 1.1897798776626587, acc=0.5472221970558167, loss=1.1897798776626587
train: epoch 145, loss 0.6216094493865967, acc=0.7517777681350708, loss=0.6216094493865967
test: epoch 145, loss 1.3607182502746582, acc=0.49444442987442017, loss=1.3607182502746582
train: epoch 146, loss 0.6288792490959167, acc=0.7479444742202759, loss=0.6288792490959167
test: epoch 146, loss 1.538036584854126, acc=0.42500001192092896, loss=1.538036584854126
train: epoch 147, loss 0.6214177012443542, acc=0.7526666522026062, loss=0.6214177012443542
test: epoch 147, loss 1.2528541088104248, acc=0.5111111402511597, loss=1.2528541088104248
train: epoch 148, loss 0.6256991624832153, acc=0.7476111054420471, loss=0.6256991624832153
test: epoch 148, loss 1.2626043558120728, acc=0.5083333253860474, loss=1.2626043558120728
train: epoch 149, loss 0.6351646184921265, acc=0.7478333115577698, loss=0.6351646184921265
test: epoch 149, loss 1.3413134813308716, acc=0.5166666507720947, loss=1.3413134813308716
train: epoch 150, loss 0.6451058983802795, acc=0.7476666569709778, loss=0.6451058983802795
test: epoch 150, loss 1.3004807233810425, acc=0.5083333253860474, loss=1.3004807233810425
