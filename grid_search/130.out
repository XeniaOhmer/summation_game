# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=1.5", "--temp_decay=1", "--one_hot=1", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=1552952953, receiver_embed_dim=128, save_run=0, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1552952953, receiver_embed_dim=128, save_run=False, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.120162010192871, acc=0.09144444763660431, loss=3.120162010192871
test: epoch 1, loss 3.0132839679718018, acc=0.13055555522441864, loss=3.0132839679718018
train: epoch 2, loss 1.7186263799667358, acc=0.31983333826065063, loss=1.7186263799667358
test: epoch 2, loss 2.7097530364990234, acc=0.11944444477558136, loss=2.7097530364990234
train: epoch 3, loss 1.337182879447937, acc=0.4601111114025116, loss=1.337182879447937
test: epoch 3, loss 2.4632840156555176, acc=0.21111111342906952, loss=2.4632840156555176
train: epoch 4, loss 1.134942650794983, acc=0.5441666841506958, loss=1.134942650794983
test: epoch 4, loss 2.317497491836548, acc=0.23333333432674408, loss=2.317497491836548
train: epoch 5, loss 0.9892606735229492, acc=0.6067777872085571, loss=0.9892606735229492
test: epoch 5, loss 2.41336989402771, acc=0.2527777850627899, loss=2.41336989402771
train: epoch 6, loss 0.8856543898582458, acc=0.6524444222450256, loss=0.8856543898582458
test: epoch 6, loss 2.2465336322784424, acc=0.27222222089767456, loss=2.2465336322784424
train: epoch 7, loss 0.8043531775474548, acc=0.6890000104904175, loss=0.8043531775474548
test: epoch 7, loss 2.3415560722351074, acc=0.2944444417953491, loss=2.3415560722351074
train: epoch 8, loss 0.7240187525749207, acc=0.7190555334091187, loss=0.7240187525749207
test: epoch 8, loss 2.163572311401367, acc=0.3055555522441864, loss=2.163572311401367
train: epoch 9, loss 0.6623191237449646, acc=0.7442222237586975, loss=0.6623191237449646
test: epoch 9, loss 1.9899146556854248, acc=0.31388887763023376, loss=1.9899146556854248
train: epoch 10, loss 0.6206066012382507, acc=0.7664999961853027, loss=0.6206066012382507
test: epoch 10, loss 2.0033044815063477, acc=0.3777777850627899, loss=2.0033044815063477
train: epoch 11, loss 0.5680261850357056, acc=0.7852222323417664, loss=0.5680261850357056
test: epoch 11, loss 1.8771992921829224, acc=0.34166666865348816, loss=1.8771992921829224
train: epoch 12, loss 0.5398174524307251, acc=0.7919444441795349, loss=0.5398174524307251
test: epoch 12, loss 1.9408797025680542, acc=0.375, loss=1.9408797025680542
train: epoch 13, loss 0.4882272779941559, acc=0.8182777762413025, loss=0.4882272779941559
test: epoch 13, loss 1.9715932607650757, acc=0.375, loss=1.9715932607650757
train: epoch 14, loss 0.48139551281929016, acc=0.8224444389343262, loss=0.48139551281929016
test: epoch 14, loss 1.9830797910690308, acc=0.3444444537162781, loss=1.9830797910690308
train: epoch 15, loss 0.43800750374794006, acc=0.8371111154556274, loss=0.43800750374794006
test: epoch 15, loss 1.9543941020965576, acc=0.40833333134651184, loss=1.9543941020965576
train: epoch 16, loss 0.41460707783699036, acc=0.8447777628898621, loss=0.41460707783699036
test: epoch 16, loss 2.2253825664520264, acc=0.375, loss=2.2253825664520264
train: epoch 17, loss 0.39429542422294617, acc=0.8577777743339539, loss=0.39429542422294617
test: epoch 17, loss 2.0515451431274414, acc=0.4027777910232544, loss=2.0515451431274414
train: epoch 18, loss 0.36120760440826416, acc=0.8698333501815796, loss=0.36120760440826416
test: epoch 18, loss 1.847710371017456, acc=0.4166666567325592, loss=1.847710371017456
train: epoch 19, loss 0.3453565239906311, acc=0.8740000128746033, loss=0.3453565239906311
test: epoch 19, loss 1.9302504062652588, acc=0.4055555462837219, loss=1.9302504062652588
train: epoch 20, loss 0.3351866900920868, acc=0.8805555701255798, loss=0.3351866900920868
test: epoch 20, loss 1.9300700426101685, acc=0.4166666567325592, loss=1.9300700426101685
train: epoch 21, loss 0.3064613342285156, acc=0.8892777562141418, loss=0.3064613342285156
test: epoch 21, loss 2.1526405811309814, acc=0.4277777671813965, loss=2.1526405811309814
train: epoch 22, loss 0.2834203839302063, acc=0.8986666798591614, loss=0.2834203839302063
test: epoch 22, loss 1.956679344177246, acc=0.43611112236976624, loss=1.956679344177246
train: epoch 23, loss 0.28897058963775635, acc=0.8958888649940491, loss=0.28897058963775635
test: epoch 23, loss 1.9212934970855713, acc=0.4583333432674408, loss=1.9212934970855713
train: epoch 24, loss 0.26191967725753784, acc=0.909166693687439, loss=0.26191967725753784
test: epoch 24, loss 1.8575953245162964, acc=0.44999998807907104, loss=1.8575953245162964
train: epoch 25, loss 0.24932274222373962, acc=0.9110000133514404, loss=0.24932274222373962
test: epoch 25, loss 1.8869202136993408, acc=0.4888888895511627, loss=1.8869202136993408
train: epoch 26, loss 0.2451445609331131, acc=0.9141111373901367, loss=0.2451445609331131
test: epoch 26, loss 1.7249830961227417, acc=0.5027777552604675, loss=1.7249830961227417
train: epoch 27, loss 0.2359447032213211, acc=0.9173333048820496, loss=0.2359447032213211
test: epoch 27, loss 1.9272054433822632, acc=0.47777777910232544, loss=1.9272054433822632
train: epoch 28, loss 0.21682141721248627, acc=0.9270555377006531, loss=0.21682141721248627
test: epoch 28, loss 2.1033763885498047, acc=0.4888888895511627, loss=2.1033763885498047
train: epoch 29, loss 0.200187087059021, acc=0.9326666593551636, loss=0.200187087059021
test: epoch 29, loss 1.9535833597183228, acc=0.5138888955116272, loss=1.9535833597183228
train: epoch 30, loss 0.1907559484243393, acc=0.9345555305480957, loss=0.1907559484243393
test: epoch 30, loss 1.9537303447723389, acc=0.5222222208976746, loss=1.9537303447723389
train: epoch 31, loss 0.19471783936023712, acc=0.9347777962684631, loss=0.19471783936023712
test: epoch 31, loss 1.8194553852081299, acc=0.49166667461395264, loss=1.8194553852081299
train: epoch 32, loss 0.1755487620830536, acc=0.9397777915000916, loss=0.1755487620830536
test: epoch 32, loss 2.1755504608154297, acc=0.5166666507720947, loss=2.1755504608154297
train: epoch 33, loss 0.17461664974689484, acc=0.9440555572509766, loss=0.17461664974689484
test: epoch 33, loss 1.9054099321365356, acc=0.4749999940395355, loss=1.9054099321365356
train: epoch 34, loss 0.16200707852840424, acc=0.9491111040115356, loss=0.16200707852840424
test: epoch 34, loss 1.8470598459243774, acc=0.49444442987442017, loss=1.8470598459243774
train: epoch 35, loss 0.1506788730621338, acc=0.9518333077430725, loss=0.1506788730621338
test: epoch 35, loss 1.7822496891021729, acc=0.5611110925674438, loss=1.7822496891021729
train: epoch 36, loss 0.1586073935031891, acc=0.9486111402511597, loss=0.1586073935031891
test: epoch 36, loss 2.030496835708618, acc=0.5333333611488342, loss=2.030496835708618
train: epoch 37, loss 0.1524239182472229, acc=0.9509999752044678, loss=0.1524239182472229
test: epoch 37, loss 1.9556854963302612, acc=0.5222222208976746, loss=1.9556854963302612
train: epoch 38, loss 0.1439146250486374, acc=0.9537222385406494, loss=0.1439146250486374
test: epoch 38, loss 1.7589672803878784, acc=0.5333333611488342, loss=1.7589672803878784
train: epoch 39, loss 0.14366047084331512, acc=0.9517777562141418, loss=0.14366047084331512
test: epoch 39, loss 1.9639164209365845, acc=0.5138888955116272, loss=1.9639164209365845
train: epoch 40, loss 0.13267561793327332, acc=0.9568889141082764, loss=0.13267561793327332
test: epoch 40, loss 1.8820157051086426, acc=0.5583333373069763, loss=1.8820157051086426
train: epoch 41, loss 0.14132052659988403, acc=0.9548888802528381, loss=0.14132052659988403
test: epoch 41, loss 1.9680842161178589, acc=0.5083333253860474, loss=1.9680842161178589
train: epoch 42, loss 0.1264057159423828, acc=0.9589444398880005, loss=0.1264057159423828
test: epoch 42, loss 1.9618542194366455, acc=0.5444444417953491, loss=1.9618542194366455
train: epoch 43, loss 0.1251092255115509, acc=0.9588888883590698, loss=0.1251092255115509
test: epoch 43, loss 1.8525474071502686, acc=0.5666666626930237, loss=1.8525474071502686
train: epoch 44, loss 0.12257976084947586, acc=0.9583333134651184, loss=0.12257976084947586
test: epoch 44, loss 1.6314805746078491, acc=0.5888888835906982, loss=1.6314805746078491
train: epoch 45, loss 0.12297189980745316, acc=0.9603888988494873, loss=0.12297189980745316
test: epoch 45, loss 1.8591861724853516, acc=0.5916666388511658, loss=1.8591861724853516
train: epoch 46, loss 0.12972553074359894, acc=0.9600555300712585, loss=0.12972553074359894
test: epoch 46, loss 1.8197999000549316, acc=0.5833333134651184, loss=1.8197999000549316
train: epoch 47, loss 0.11188719421625137, acc=0.9644444584846497, loss=0.11188719421625137
test: epoch 47, loss 1.9336755275726318, acc=0.5916666388511658, loss=1.9336755275726318
train: epoch 48, loss 0.1106192097067833, acc=0.9628333449363708, loss=0.1106192097067833
test: epoch 48, loss 2.3017423152923584, acc=0.5583333373069763, loss=2.3017423152923584
train: epoch 49, loss 0.11219605803489685, acc=0.9634444713592529, loss=0.11219605803489685
test: epoch 49, loss 1.9674136638641357, acc=0.5888888835906982, loss=1.9674136638641357
train: epoch 50, loss 0.1103903204202652, acc=0.9634444713592529, loss=0.1103903204202652
test: epoch 50, loss 1.7212836742401123, acc=0.5972222089767456, loss=1.7212836742401123
train: epoch 51, loss 0.11001494526863098, acc=0.9655555486679077, loss=0.11001494526863098
test: epoch 51, loss 2.499302625656128, acc=0.5694444179534912, loss=2.499302625656128
train: epoch 52, loss 0.11152411997318268, acc=0.9647777676582336, loss=0.11152411997318268
test: epoch 52, loss 2.1349501609802246, acc=0.5888888835906982, loss=2.1349501609802246
train: epoch 53, loss 0.09505496919155121, acc=0.9677777886390686, loss=0.09505496919155121
test: epoch 53, loss 2.0040504932403564, acc=0.5833333134651184, loss=2.0040504932403564
train: epoch 54, loss 0.1049576923251152, acc=0.9670000076293945, loss=0.1049576923251152
test: epoch 54, loss 1.9872372150421143, acc=0.5916666388511658, loss=1.9872372150421143
train: epoch 55, loss 0.10241365432739258, acc=0.9706110954284668, loss=0.10241365432739258
test: epoch 55, loss 1.9858275651931763, acc=0.5888888835906982, loss=1.9858275651931763
train: epoch 56, loss 0.09927927702665329, acc=0.9697222113609314, loss=0.09927927702665329
test: epoch 56, loss 1.79592764377594, acc=0.6388888955116272, loss=1.79592764377594
train: epoch 57, loss 0.08462893217802048, acc=0.9751666784286499, loss=0.08462893217802048
test: epoch 57, loss 1.5526177883148193, acc=0.5972222089767456, loss=1.5526177883148193
train: epoch 58, loss 0.08789505064487457, acc=0.972777783870697, loss=0.08789505064487457
test: epoch 58, loss 1.9428452253341675, acc=0.6194444298744202, loss=1.9428452253341675
train: epoch 59, loss 0.10097494721412659, acc=0.9736666679382324, loss=0.10097494721412659
test: epoch 59, loss 1.9671926498413086, acc=0.6138888597488403, loss=1.9671926498413086
train: epoch 60, loss 0.08552132546901703, acc=0.9765555262565613, loss=0.08552132546901703
test: epoch 60, loss 1.525425910949707, acc=0.6499999761581421, loss=1.525425910949707
train: epoch 61, loss 0.07520557194948196, acc=0.9783333539962769, loss=0.07520557194948196
test: epoch 61, loss 2.228266954421997, acc=0.6083333492279053, loss=2.228266954421997
train: epoch 62, loss 0.08591070026159286, acc=0.9758333563804626, loss=0.08591070026159286
test: epoch 62, loss 1.7145558595657349, acc=0.5916666388511658, loss=1.7145558595657349
train: epoch 63, loss 0.07205193489789963, acc=0.9782778024673462, loss=0.07205193489789963
test: epoch 63, loss 1.5715888738632202, acc=0.6277777552604675, loss=1.5715888738632202
train: epoch 64, loss 0.07716143876314163, acc=0.9776111245155334, loss=0.07716143876314163
test: epoch 64, loss 1.6019880771636963, acc=0.625, loss=1.6019880771636963
train: epoch 65, loss 0.07510452717542648, acc=0.9786111116409302, loss=0.07510452717542648
test: epoch 65, loss 1.9769437313079834, acc=0.6166666746139526, loss=1.9769437313079834
train: epoch 66, loss 0.07538902759552002, acc=0.9782778024673462, loss=0.07538902759552002
test: epoch 66, loss 1.7347321510314941, acc=0.675000011920929, loss=1.7347321510314941
train: epoch 67, loss 0.07801605015993118, acc=0.9783889055252075, loss=0.07801605015993118
test: epoch 67, loss 1.7151342630386353, acc=0.6638888716697693, loss=1.7151342630386353
train: epoch 68, loss 0.07560241222381592, acc=0.9783333539962769, loss=0.07560241222381592
test: epoch 68, loss 1.4048199653625488, acc=0.699999988079071, loss=1.4048199653625488
train: epoch 69, loss 0.07921713590621948, acc=0.9771666526794434, loss=0.07921713590621948
test: epoch 69, loss 1.664870262145996, acc=0.675000011920929, loss=1.664870262145996
train: epoch 70, loss 0.06377700716257095, acc=0.9816111326217651, loss=0.06377700716257095
test: epoch 70, loss 1.7441545724868774, acc=0.6583333611488342, loss=1.7441545724868774
train: epoch 71, loss 0.06732766330242157, acc=0.9803333282470703, loss=0.06732766330242157
test: epoch 71, loss 1.480007290840149, acc=0.6944444179534912, loss=1.480007290840149
train: epoch 72, loss 0.07168705761432648, acc=0.9798333048820496, loss=0.07168705761432648
test: epoch 72, loss 1.4196105003356934, acc=0.6888889074325562, loss=1.4196105003356934
train: epoch 73, loss 0.06193356215953827, acc=0.9811111092567444, loss=0.06193356215953827
test: epoch 73, loss 1.6220195293426514, acc=0.6666666865348816, loss=1.6220195293426514
train: epoch 74, loss 0.06742699444293976, acc=0.9808889031410217, loss=0.06742699444293976
test: epoch 74, loss 1.5856170654296875, acc=0.6972222328186035, loss=1.5856170654296875
train: epoch 75, loss 0.06358815729618073, acc=0.9818333387374878, loss=0.06358815729618073
test: epoch 75, loss 1.7072842121124268, acc=0.6833333373069763, loss=1.7072842121124268
train: epoch 76, loss 0.06320127844810486, acc=0.9816111326217651, loss=0.06320127844810486
test: epoch 76, loss 1.5864906311035156, acc=0.675000011920929, loss=1.5864906311035156
train: epoch 77, loss 0.06811320036649704, acc=0.9810000061988831, loss=0.06811320036649704
test: epoch 77, loss 1.5272339582443237, acc=0.7222222089767456, loss=1.5272339582443237
train: epoch 78, loss 0.05437728390097618, acc=0.9847221970558167, loss=0.05437728390097618
test: epoch 78, loss 1.7228899002075195, acc=0.7138888835906982, loss=1.7228899002075195
train: epoch 79, loss 0.0678163543343544, acc=0.9816111326217651, loss=0.0678163543343544
test: epoch 79, loss 1.5429247617721558, acc=0.7250000238418579, loss=1.5429247617721558
train: epoch 80, loss 0.05773995816707611, acc=0.9836666584014893, loss=0.05773995816707611
test: epoch 80, loss 1.4021536111831665, acc=0.7416666746139526, loss=1.4021536111831665
train: epoch 81, loss 0.05572120472788811, acc=0.9837777614593506, loss=0.05572120472788811
test: epoch 81, loss 1.4475442171096802, acc=0.730555534362793, loss=1.4475442171096802
train: epoch 82, loss 0.0659765973687172, acc=0.9821666479110718, loss=0.0659765973687172
test: epoch 82, loss 1.685837984085083, acc=0.7083333134651184, loss=1.685837984085083
train: epoch 83, loss 0.06226711347699165, acc=0.9827222228050232, loss=0.06226711347699165
test: epoch 83, loss 1.4949625730514526, acc=0.7333333492279053, loss=1.4949625730514526
train: epoch 84, loss 0.04946757107973099, acc=0.9851666688919067, loss=0.04946757107973099
test: epoch 84, loss 1.2132569551467896, acc=0.7611111402511597, loss=1.2132569551467896
train: epoch 85, loss 0.0628383606672287, acc=0.9823889136314392, loss=0.0628383606672287
test: epoch 85, loss 1.2750120162963867, acc=0.7555555701255798, loss=1.2750120162963867
train: epoch 86, loss 0.053588371723890305, acc=0.9853888750076294, loss=0.053588371723890305
test: epoch 86, loss 1.3617527484893799, acc=0.7583333253860474, loss=1.3617527484893799
train: epoch 87, loss 0.05346590280532837, acc=0.9848333597183228, loss=0.05346590280532837
test: epoch 87, loss 1.393096685409546, acc=0.75, loss=1.393096685409546
train: epoch 88, loss 0.05472400784492493, acc=0.9848889112472534, loss=0.05472400784492493
test: epoch 88, loss 1.4508377313613892, acc=0.7555555701255798, loss=1.4508377313613892
train: epoch 89, loss 0.05916224420070648, acc=0.9841111302375793, loss=0.05916224420070648
test: epoch 89, loss 1.288636326789856, acc=0.7361111044883728, loss=1.288636326789856
train: epoch 90, loss 0.05274438485503197, acc=0.9856666922569275, loss=0.05274438485503197
test: epoch 90, loss 1.2431913614273071, acc=0.7555555701255798, loss=1.2431913614273071
train: epoch 91, loss 0.05703766644001007, acc=0.9850555658340454, loss=0.05703766644001007
test: epoch 91, loss 1.1175259351730347, acc=0.7861111164093018, loss=1.1175259351730347
train: epoch 92, loss 0.04501013830304146, acc=0.9876111149787903, loss=0.04501013830304146
test: epoch 92, loss 1.3678805828094482, acc=0.7638888955116272, loss=1.3678805828094482
train: epoch 93, loss 0.05471236631274223, acc=0.9851111173629761, loss=0.05471236631274223
test: epoch 93, loss 1.3766008615493774, acc=0.7611111402511597, loss=1.3766008615493774
train: epoch 94, loss 0.05339783802628517, acc=0.9846110939979553, loss=0.05339783802628517
test: epoch 94, loss 1.1353685855865479, acc=0.8166666626930237, loss=1.1353685855865479
train: epoch 95, loss 0.05949713662266731, acc=0.9847777485847473, loss=0.05949713662266731
test: epoch 95, loss 1.2174851894378662, acc=0.769444465637207, loss=1.2174851894378662
train: epoch 96, loss 0.04366739094257355, acc=0.9875555634498596, loss=0.04366739094257355
test: epoch 96, loss 1.149086833000183, acc=0.8083333373069763, loss=1.149086833000183
train: epoch 97, loss 0.04495079815387726, acc=0.9868888854980469, loss=0.04495079815387726
test: epoch 97, loss 1.3425617218017578, acc=0.7749999761581421, loss=1.3425617218017578
train: epoch 98, loss 0.0464058518409729, acc=0.9865555763244629, loss=0.0464058518409729
test: epoch 98, loss 1.1468420028686523, acc=0.7972221970558167, loss=1.1468420028686523
train: epoch 99, loss 0.05230620130896568, acc=0.9852777719497681, loss=0.05230620130896568
test: epoch 99, loss 1.2487155199050903, acc=0.7888888716697693, loss=1.2487155199050903
train: epoch 100, loss 0.05141826346516609, acc=0.987500011920929, loss=0.05141826346516609
test: epoch 100, loss 1.289415717124939, acc=0.7777777910232544, loss=1.289415717124939
train: epoch 101, loss 0.04767351225018501, acc=0.9869999885559082, loss=0.04767351225018501
test: epoch 101, loss 1.2320468425750732, acc=0.7805555462837219, loss=1.2320468425750732
train: epoch 102, loss 0.04585547000169754, acc=0.9882222414016724, loss=0.04585547000169754
test: epoch 102, loss 1.5215034484863281, acc=0.7722222208976746, loss=1.5215034484863281
train: epoch 103, loss 0.04467105120420456, acc=0.9878333210945129, loss=0.04467105120420456
test: epoch 103, loss 1.172968864440918, acc=0.7888888716697693, loss=1.172968864440918
train: epoch 104, loss 0.051571350544691086, acc=0.9854444265365601, loss=0.051571350544691086
test: epoch 104, loss 1.0407896041870117, acc=0.8138889074325562, loss=1.0407896041870117
train: epoch 105, loss 0.0445648692548275, acc=0.9880555272102356, loss=0.0445648692548275
test: epoch 105, loss 1.2837339639663696, acc=0.8083333373069763, loss=1.2837339639663696
train: epoch 106, loss 0.041647426784038544, acc=0.988777756690979, loss=0.041647426784038544
test: epoch 106, loss 1.329167366027832, acc=0.7749999761581421, loss=1.329167366027832
train: epoch 107, loss 0.04749879986047745, acc=0.9881666898727417, loss=0.04749879986047745
test: epoch 107, loss 1.026037335395813, acc=0.8027777671813965, loss=1.026037335395813
train: epoch 108, loss 0.04561213403940201, acc=0.9874444603919983, loss=0.04561213403940201
test: epoch 108, loss 1.0550954341888428, acc=0.8055555820465088, loss=1.0550954341888428
train: epoch 109, loss 0.04090599715709686, acc=0.9890000224113464, loss=0.04090599715709686
test: epoch 109, loss 1.1549447774887085, acc=0.7916666865348816, loss=1.1549447774887085
train: epoch 110, loss 0.047861237078905106, acc=0.9861111044883728, loss=0.047861237078905106
test: epoch 110, loss 0.9741196036338806, acc=0.8083333373069763, loss=0.9741196036338806
train: epoch 111, loss 0.04533281922340393, acc=0.988277792930603, loss=0.04533281922340393
test: epoch 111, loss 1.1851701736450195, acc=0.7666666507720947, loss=1.1851701736450195
train: epoch 112, loss 0.05125237628817558, acc=0.9867777824401855, loss=0.05125237628817558
test: epoch 112, loss 1.0635472536087036, acc=0.8055555820465088, loss=1.0635472536087036
train: epoch 113, loss 0.043656740337610245, acc=0.987333357334137, loss=0.043656740337610245
test: epoch 113, loss 1.0599592924118042, acc=0.8027777671813965, loss=1.0599592924118042
train: epoch 114, loss 0.0358111709356308, acc=0.9898889064788818, loss=0.0358111709356308
test: epoch 114, loss 1.156865119934082, acc=0.8305555582046509, loss=1.156865119934082
train: epoch 115, loss 0.03857757896184921, acc=0.9889444708824158, loss=0.03857757896184921
test: epoch 115, loss 0.9338655471801758, acc=0.8277778029441833, loss=0.9338655471801758
train: epoch 116, loss 0.03893163055181503, acc=0.9888333082199097, loss=0.03893163055181503
test: epoch 116, loss 1.3852344751358032, acc=0.8027777671813965, loss=1.3852344751358032
train: epoch 117, loss 0.03873395919799805, acc=0.9893333315849304, loss=0.03873395919799805
test: epoch 117, loss 1.1237173080444336, acc=0.7972221970558167, loss=1.1237173080444336
train: epoch 118, loss 0.043108560144901276, acc=0.9878888726234436, loss=0.043108560144901276
test: epoch 118, loss 1.126284122467041, acc=0.8111110925674438, loss=1.126284122467041
train: epoch 119, loss 0.03658205270767212, acc=0.9896110892295837, loss=0.03658205270767212
test: epoch 119, loss 1.1196855306625366, acc=0.8194444179534912, loss=1.1196855306625366
train: epoch 120, loss 0.04330892488360405, acc=0.9892222285270691, loss=0.04330892488360405
test: epoch 120, loss 1.0555919408798218, acc=0.8111110925674438, loss=1.0555919408798218
train: epoch 121, loss 0.05035041645169258, acc=0.9878888726234436, loss=0.05035041645169258
test: epoch 121, loss 1.143538236618042, acc=0.824999988079071, loss=1.143538236618042
train: epoch 122, loss 0.03869783505797386, acc=0.9900555610656738, loss=0.03869783505797386
test: epoch 122, loss 0.7795449495315552, acc=0.8333333134651184, loss=0.7795449495315552
train: epoch 123, loss 0.034596413373947144, acc=0.9903888702392578, loss=0.034596413373947144
test: epoch 123, loss 1.0672446489334106, acc=0.8305555582046509, loss=1.0672446489334106
train: epoch 124, loss 0.03626931831240654, acc=0.9906111359596252, loss=0.03626931831240654
test: epoch 124, loss 1.1247777938842773, acc=0.8166666626930237, loss=1.1247777938842773
train: epoch 125, loss 0.04763661324977875, acc=0.9868333339691162, loss=0.04763661324977875
test: epoch 125, loss 0.9135010838508606, acc=0.8333333134651184, loss=0.9135010838508606
train: epoch 126, loss 0.03228597715497017, acc=0.9899444580078125, loss=0.03228597715497017
test: epoch 126, loss 1.021288514137268, acc=0.8277778029441833, loss=1.021288514137268
train: epoch 127, loss 0.03628845140337944, acc=0.9901111125946045, loss=0.03628845140337944
test: epoch 127, loss 0.9455379843711853, acc=0.8333333134651184, loss=0.9455379843711853
train: epoch 128, loss 0.04311294108629227, acc=0.9882222414016724, loss=0.04311294108629227
test: epoch 128, loss 0.8648937940597534, acc=0.8277778029441833, loss=0.8648937940597534
train: epoch 129, loss 0.03748286888003349, acc=0.9908333420753479, loss=0.03748286888003349
test: epoch 129, loss 0.8692782521247864, acc=0.8361111283302307, loss=0.8692782521247864
train: epoch 130, loss 0.034513164311647415, acc=0.9906111359596252, loss=0.034513164311647415
test: epoch 130, loss 1.222085952758789, acc=0.8277778029441833, loss=1.222085952758789
train: epoch 131, loss 0.03489692509174347, acc=0.9907777905464172, loss=0.03489692509174347
test: epoch 131, loss 1.017886757850647, acc=0.8388888835906982, loss=1.017886757850647
train: epoch 132, loss 0.03547326847910881, acc=0.9895555377006531, loss=0.03547326847910881
test: epoch 132, loss 0.8616067171096802, acc=0.8416666388511658, loss=0.8616067171096802
train: epoch 133, loss 0.03213619440793991, acc=0.9904999732971191, loss=0.03213619440793991
test: epoch 133, loss 0.9090246558189392, acc=0.8333333134651184, loss=0.9090246558189392
train: epoch 134, loss 0.04167741537094116, acc=0.988777756690979, loss=0.04167741537094116
test: epoch 134, loss 0.8928184509277344, acc=0.8472222089767456, loss=0.8928184509277344
train: epoch 135, loss 0.036448556929826736, acc=0.9902777671813965, loss=0.036448556929826736
test: epoch 135, loss 0.853492021560669, acc=0.8444444537162781, loss=0.853492021560669
train: epoch 136, loss 0.03414624556899071, acc=0.9906111359596252, loss=0.03414624556899071
test: epoch 136, loss 1.061579942703247, acc=0.8361111283302307, loss=1.061579942703247
train: epoch 137, loss 0.028718162328004837, acc=0.9925000071525574, loss=0.028718162328004837
test: epoch 137, loss 0.880109429359436, acc=0.8305555582046509, loss=0.880109429359436
train: epoch 138, loss 0.04210803285241127, acc=0.9894444346427917, loss=0.04210803285241127
test: epoch 138, loss 0.8926441669464111, acc=0.8388888835906982, loss=0.8926441669464111
train: epoch 139, loss 0.036469943821430206, acc=0.9897222518920898, loss=0.036469943821430206
test: epoch 139, loss 1.011447548866272, acc=0.8416666388511658, loss=1.011447548866272
train: epoch 140, loss 0.03262922540307045, acc=0.9907222390174866, loss=0.03262922540307045
test: epoch 140, loss 1.1298502683639526, acc=0.8500000238418579, loss=1.1298502683639526
train: epoch 141, loss 0.035459090024232864, acc=0.9904444217681885, loss=0.035459090024232864
test: epoch 141, loss 0.8736171722412109, acc=0.8444444537162781, loss=0.8736171722412109
train: epoch 142, loss 0.03532017022371292, acc=0.9913333058357239, loss=0.03532017022371292
test: epoch 142, loss 1.0043601989746094, acc=0.8388888835906982, loss=1.0043601989746094
train: epoch 143, loss 0.03305622190237045, acc=0.9906111359596252, loss=0.03305622190237045
test: epoch 143, loss 0.9193461537361145, acc=0.8277778029441833, loss=0.9193461537361145
train: epoch 144, loss 0.029371783137321472, acc=0.9911110997200012, loss=0.029371783137321472
test: epoch 144, loss 0.8613386750221252, acc=0.8472222089767456, loss=0.8613386750221252
train: epoch 145, loss 0.03288986533880234, acc=0.991777777671814, loss=0.03288986533880234
test: epoch 145, loss 1.0144845247268677, acc=0.8416666388511658, loss=1.0144845247268677
train: epoch 146, loss 0.037806734442710876, acc=0.9903333187103271, loss=0.037806734442710876
test: epoch 146, loss 0.7765538692474365, acc=0.8444444537162781, loss=0.7765538692474365
train: epoch 147, loss 0.0239285659044981, acc=0.9932222366333008, loss=0.0239285659044981
test: epoch 147, loss 0.9261083006858826, acc=0.8388888835906982, loss=0.9261083006858826
train: epoch 148, loss 0.02952229604125023, acc=0.9921666383743286, loss=0.02952229604125023
test: epoch 148, loss 0.9808366894721985, acc=0.8472222089767456, loss=0.9808366894721985
train: epoch 149, loss 0.033656489104032516, acc=0.9912777543067932, loss=0.033656489104032516
test: epoch 149, loss 0.9858190417289734, acc=0.8388888835906982, loss=0.9858190417289734
train: epoch 150, loss 0.033304210752248764, acc=0.9894999861717224, loss=0.033304210752248764
test: epoch 150, loss 1.0720669031143188, acc=0.8416666388511658, loss=1.0720669031143188
