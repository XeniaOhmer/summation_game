# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=1", "--one_hot=0", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=696628071, receiver_embed_dim=32, save_run=0, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=696628071, receiver_embed_dim=32, save_run=False, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.4810805320739746, acc=0.17322222888469696, loss=2.4810805320739746
test: epoch 1, loss 7.665515422821045, acc=0.06111111119389534, loss=7.665515422821045
train: epoch 2, loss 1.6060174703598022, acc=0.3481111228466034, loss=1.6060174703598022
test: epoch 2, loss 6.414526462554932, acc=0.0694444477558136, loss=6.414526462554932
train: epoch 3, loss 1.3522922992706299, acc=0.441611111164093, loss=1.3522922992706299
test: epoch 3, loss 6.409611225128174, acc=0.11666666716337204, loss=6.409611225128174
train: epoch 4, loss 1.1900991201400757, acc=0.5110555291175842, loss=1.1900991201400757
test: epoch 4, loss 6.919234275817871, acc=0.13055555522441864, loss=6.919234275817871
train: epoch 5, loss 1.050480842590332, acc=0.5723888874053955, loss=1.050480842590332
test: epoch 5, loss 6.013935089111328, acc=0.14166666567325592, loss=6.013935089111328
train: epoch 6, loss 0.9578898549079895, acc=0.6161666512489319, loss=0.9578898549079895
test: epoch 6, loss 5.983345031738281, acc=0.15833333134651184, loss=5.983345031738281
train: epoch 7, loss 0.901176393032074, acc=0.6377221941947937, loss=0.901176393032074
test: epoch 7, loss 5.374403476715088, acc=0.15833333134651184, loss=5.374403476715088
train: epoch 8, loss 0.8372050523757935, acc=0.664222240447998, loss=0.8372050523757935
test: epoch 8, loss 6.695677280426025, acc=0.15000000596046448, loss=6.695677280426025
train: epoch 9, loss 0.8000210523605347, acc=0.6779999732971191, loss=0.8000210523605347
test: epoch 9, loss 5.426772594451904, acc=0.1944444477558136, loss=5.426772594451904
train: epoch 10, loss 0.7745093703269958, acc=0.6971666812896729, loss=0.7745093703269958
test: epoch 10, loss 5.4884161949157715, acc=0.2083333283662796, loss=5.4884161949157715
train: epoch 11, loss 0.7366678714752197, acc=0.7124999761581421, loss=0.7366678714752197
test: epoch 11, loss 4.083681106567383, acc=0.32499998807907104, loss=4.083681106567383
train: epoch 12, loss 0.6829836368560791, acc=0.7333889007568359, loss=0.6829836368560791
test: epoch 12, loss 5.554053783416748, acc=0.19166666269302368, loss=5.554053783416748
train: epoch 13, loss 0.6779277920722961, acc=0.7328333258628845, loss=0.6779277920722961
test: epoch 13, loss 6.111520767211914, acc=0.16388888657093048, loss=6.111520767211914
train: epoch 14, loss 0.6372157335281372, acc=0.7454444169998169, loss=0.6372157335281372
test: epoch 14, loss 4.510595321655273, acc=0.2638888955116272, loss=4.510595321655273
train: epoch 15, loss 0.6263517737388611, acc=0.7557222247123718, loss=0.6263517737388611
test: epoch 15, loss 4.089738845825195, acc=0.23333333432674408, loss=4.089738845825195
train: epoch 16, loss 0.5710777640342712, acc=0.7745555639266968, loss=0.5710777640342712
test: epoch 16, loss 3.5869364738464355, acc=0.28611111640930176, loss=3.5869364738464355
train: epoch 17, loss 0.5982939600944519, acc=0.7618333101272583, loss=0.5982939600944519
test: epoch 17, loss 2.9418227672576904, acc=0.3333333432674408, loss=2.9418227672576904
train: epoch 18, loss 0.5599557161331177, acc=0.7785555720329285, loss=0.5599557161331177
test: epoch 18, loss 3.6914756298065186, acc=0.2805555462837219, loss=3.6914756298065186
train: epoch 19, loss 0.5386351943016052, acc=0.7894999980926514, loss=0.5386351943016052
test: epoch 19, loss 3.2469301223754883, acc=0.3638888895511627, loss=3.2469301223754883
train: epoch 20, loss 0.5329191088676453, acc=0.7911111116409302, loss=0.5329191088676453
test: epoch 20, loss 4.350790023803711, acc=0.29722222685813904, loss=4.350790023803711
train: epoch 21, loss 0.5149945020675659, acc=0.7992777824401855, loss=0.5149945020675659
test: epoch 21, loss 3.656913995742798, acc=0.3444444537162781, loss=3.656913995742798
train: epoch 22, loss 0.5093455910682678, acc=0.8013333082199097, loss=0.5093455910682678
test: epoch 22, loss 4.059284687042236, acc=0.23333333432674408, loss=4.059284687042236
train: epoch 23, loss 0.4601232409477234, acc=0.8213333487510681, loss=0.4601232409477234
test: epoch 23, loss 3.961357355117798, acc=0.21388888359069824, loss=3.961357355117798
train: epoch 24, loss 0.46660116314888, acc=0.8230000138282776, loss=0.46660116314888
test: epoch 24, loss 3.4921786785125732, acc=0.2805555462837219, loss=3.4921786785125732
train: epoch 25, loss 0.4428878128528595, acc=0.8309999704360962, loss=0.4428878128528595
test: epoch 25, loss 3.5905768871307373, acc=0.32499998807907104, loss=3.5905768871307373
train: epoch 26, loss 0.45732760429382324, acc=0.8242777585983276, loss=0.45732760429382324
test: epoch 26, loss 3.3066980838775635, acc=0.3472222089767456, loss=3.3066980838775635
train: epoch 27, loss 0.4414038360118866, acc=0.8296111226081848, loss=0.4414038360118866
test: epoch 27, loss 2.7873330116271973, acc=0.25555557012557983, loss=2.7873330116271973
train: epoch 28, loss 0.4203907549381256, acc=0.8374999761581421, loss=0.4203907549381256
test: epoch 28, loss 3.615206003189087, acc=0.2944444417953491, loss=3.615206003189087
train: epoch 29, loss 0.3944782316684723, acc=0.8468888998031616, loss=0.3944782316684723
test: epoch 29, loss 4.180832862854004, acc=0.2611111104488373, loss=4.180832862854004
train: epoch 30, loss 0.4188723564147949, acc=0.8387222290039062, loss=0.4188723564147949
test: epoch 30, loss 2.830312967300415, acc=0.2888889014720917, loss=2.830312967300415
train: epoch 31, loss 0.38607659935951233, acc=0.8537777662277222, loss=0.38607659935951233
test: epoch 31, loss 3.9868175983428955, acc=0.25555557012557983, loss=3.9868175983428955
train: epoch 32, loss 0.38786324858665466, acc=0.8557222485542297, loss=0.38786324858665466
test: epoch 32, loss 4.243488788604736, acc=0.25833332538604736, loss=4.243488788604736
train: epoch 33, loss 0.40367263555526733, acc=0.8445555567741394, loss=0.40367263555526733
test: epoch 33, loss 3.9756369590759277, acc=0.3027777671813965, loss=3.9756369590759277
train: epoch 34, loss 0.37498047947883606, acc=0.8583333492279053, loss=0.37498047947883606
test: epoch 34, loss 3.8680503368377686, acc=0.29722222685813904, loss=3.8680503368377686
train: epoch 35, loss 0.3892005980014801, acc=0.8531666398048401, loss=0.3892005980014801
test: epoch 35, loss 3.183749198913574, acc=0.2750000059604645, loss=3.183749198913574
train: epoch 36, loss 0.36050447821617126, acc=0.8620555400848389, loss=0.36050447821617126
test: epoch 36, loss 4.423986434936523, acc=0.26944443583488464, loss=4.423986434936523
train: epoch 37, loss 0.3576948344707489, acc=0.8659999966621399, loss=0.3576948344707489
test: epoch 37, loss 4.321746826171875, acc=0.2083333283662796, loss=4.321746826171875
train: epoch 38, loss 0.3695136606693268, acc=0.8583333492279053, loss=0.3695136606693268
test: epoch 38, loss 3.7760112285614014, acc=0.3305555582046509, loss=3.7760112285614014
train: epoch 39, loss 0.3743950426578522, acc=0.8596110939979553, loss=0.3743950426578522
test: epoch 39, loss 3.613588809967041, acc=0.3444444537162781, loss=3.613588809967041
train: epoch 40, loss 0.34096255898475647, acc=0.870555579662323, loss=0.34096255898475647
test: epoch 40, loss 3.040292501449585, acc=0.36944442987442017, loss=3.040292501449585
train: epoch 41, loss 0.36458703875541687, acc=0.8604444265365601, loss=0.36458703875541687
test: epoch 41, loss 4.44602108001709, acc=0.2916666567325592, loss=4.44602108001709
train: epoch 42, loss 0.3351246118545532, acc=0.8746111392974854, loss=0.3351246118545532
test: epoch 42, loss 3.1008965969085693, acc=0.3333333432674408, loss=3.1008965969085693
train: epoch 43, loss 0.34505048394203186, acc=0.8712777495384216, loss=0.34505048394203186
test: epoch 43, loss 2.7477316856384277, acc=0.3583333194255829, loss=2.7477316856384277
train: epoch 44, loss 0.34175971150398254, acc=0.8754444718360901, loss=0.34175971150398254
test: epoch 44, loss 3.8907523155212402, acc=0.3472222089767456, loss=3.8907523155212402
train: epoch 45, loss 0.32234442234039307, acc=0.8788333535194397, loss=0.32234442234039307
test: epoch 45, loss 3.9408533573150635, acc=0.30000001192092896, loss=3.9408533573150635
train: epoch 46, loss 0.31439051032066345, acc=0.8820555806159973, loss=0.31439051032066345
test: epoch 46, loss 3.663648843765259, acc=0.3305555582046509, loss=3.663648843765259
train: epoch 47, loss 0.32520341873168945, acc=0.8772222399711609, loss=0.32520341873168945
test: epoch 47, loss 3.8069722652435303, acc=0.3083333373069763, loss=3.8069722652435303
train: epoch 48, loss 0.30601298809051514, acc=0.8866666555404663, loss=0.30601298809051514
test: epoch 48, loss 2.891594886779785, acc=0.39444443583488464, loss=2.891594886779785
train: epoch 49, loss 0.31480276584625244, acc=0.886388897895813, loss=0.31480276584625244
test: epoch 49, loss 4.248112678527832, acc=0.24166665971279144, loss=4.248112678527832
train: epoch 50, loss 0.30658018589019775, acc=0.8848888874053955, loss=0.30658018589019775
test: epoch 50, loss 3.721954822540283, acc=0.31111112236976624, loss=3.721954822540283
train: epoch 51, loss 0.30869752168655396, acc=0.8849999904632568, loss=0.30869752168655396
test: epoch 51, loss 3.9785633087158203, acc=0.2805555462837219, loss=3.9785633087158203
train: epoch 52, loss 0.3141440153121948, acc=0.883222222328186, loss=0.3141440153121948
test: epoch 52, loss 2.929347038269043, acc=0.3444444537162781, loss=2.929347038269043
train: epoch 53, loss 0.30179280042648315, acc=0.8856666684150696, loss=0.30179280042648315
test: epoch 53, loss 4.761176109313965, acc=0.26944443583488464, loss=4.761176109313965
train: epoch 54, loss 0.29239267110824585, acc=0.8898888826370239, loss=0.29239267110824585
test: epoch 54, loss 3.1095290184020996, acc=0.29722222685813904, loss=3.1095290184020996
train: epoch 55, loss 0.33374854922294617, acc=0.8767777681350708, loss=0.33374854922294617
test: epoch 55, loss 3.130225658416748, acc=0.2916666567325592, loss=3.130225658416748
train: epoch 56, loss 0.266440212726593, acc=0.9016666412353516, loss=0.266440212726593
test: epoch 56, loss 2.9226319789886475, acc=0.3194444477558136, loss=2.9226319789886475
train: epoch 57, loss 0.2884092628955841, acc=0.8937777876853943, loss=0.2884092628955841
test: epoch 57, loss 2.6100423336029053, acc=0.3499999940395355, loss=2.6100423336029053
train: epoch 58, loss 0.2800311744213104, acc=0.8953333497047424, loss=0.2800311744213104
test: epoch 58, loss 3.0813403129577637, acc=0.3333333432674408, loss=3.0813403129577637
train: epoch 59, loss 0.26357486844062805, acc=0.9036111235618591, loss=0.26357486844062805
test: epoch 59, loss 3.1562938690185547, acc=0.30000001192092896, loss=3.1562938690185547
train: epoch 60, loss 0.2836489975452423, acc=0.8948333263397217, loss=0.2836489975452423
test: epoch 60, loss 1.7298598289489746, acc=0.38055557012557983, loss=1.7298598289489746
train: epoch 61, loss 0.2859199345111847, acc=0.8947222232818604, loss=0.2859199345111847
test: epoch 61, loss 2.183363199234009, acc=0.4555555582046509, loss=2.183363199234009
train: epoch 62, loss 0.29561489820480347, acc=0.8912777900695801, loss=0.29561489820480347
test: epoch 62, loss 2.1663544178009033, acc=0.3166666626930237, loss=2.1663544178009033
train: epoch 63, loss 0.2594650983810425, acc=0.9020000100135803, loss=0.2594650983810425
test: epoch 63, loss 2.1886281967163086, acc=0.3222222328186035, loss=2.1886281967163086
train: epoch 64, loss 0.27105480432510376, acc=0.9000555276870728, loss=0.27105480432510376
test: epoch 64, loss 2.3809919357299805, acc=0.4000000059604645, loss=2.3809919357299805
train: epoch 65, loss 0.2582952380180359, acc=0.9039999842643738, loss=0.2582952380180359
test: epoch 65, loss 2.8363006114959717, acc=0.3638888895511627, loss=2.8363006114959717
train: epoch 66, loss 0.25269708037376404, acc=0.9055555462837219, loss=0.25269708037376404
test: epoch 66, loss 3.4107248783111572, acc=0.3055555522441864, loss=3.4107248783111572
train: epoch 67, loss 0.24655821919441223, acc=0.9101666808128357, loss=0.24655821919441223
test: epoch 67, loss 2.6065196990966797, acc=0.4166666567325592, loss=2.6065196990966797
train: epoch 68, loss 0.2644538879394531, acc=0.9042222499847412, loss=0.2644538879394531
test: epoch 68, loss 1.6730883121490479, acc=0.4305555522441864, loss=1.6730883121490479
train: epoch 69, loss 0.26874876022338867, acc=0.9005555510520935, loss=0.26874876022338867
test: epoch 69, loss 1.9681005477905273, acc=0.3888888955116272, loss=1.9681005477905273
train: epoch 70, loss 0.24639686942100525, acc=0.9098888635635376, loss=0.24639686942100525
test: epoch 70, loss 2.7158379554748535, acc=0.4166666567325592, loss=2.7158379554748535
train: epoch 71, loss 0.25086456537246704, acc=0.9072777628898621, loss=0.25086456537246704
test: epoch 71, loss 2.292168140411377, acc=0.3777777850627899, loss=2.292168140411377
train: epoch 72, loss 0.2463865727186203, acc=0.9108333587646484, loss=0.2463865727186203
test: epoch 72, loss 2.912525177001953, acc=0.32777777314186096, loss=2.912525177001953
train: epoch 73, loss 0.2390705943107605, acc=0.9106666445732117, loss=0.2390705943107605
test: epoch 73, loss 3.1420018672943115, acc=0.36944442987442017, loss=3.1420018672943115
train: epoch 74, loss 0.22516439855098724, acc=0.9194999933242798, loss=0.22516439855098724
test: epoch 74, loss 1.8641718626022339, acc=0.44999998807907104, loss=1.8641718626022339
train: epoch 75, loss 0.23846060037612915, acc=0.9128888845443726, loss=0.23846060037612915
test: epoch 75, loss 3.1227567195892334, acc=0.3361110985279083, loss=3.1227567195892334
train: epoch 76, loss 0.22945955395698547, acc=0.9179999828338623, loss=0.22945955395698547
test: epoch 76, loss 1.9190465211868286, acc=0.40833333134651184, loss=1.9190465211868286
train: epoch 77, loss 0.2524353265762329, acc=0.9067777991294861, loss=0.2524353265762329
test: epoch 77, loss 2.6564443111419678, acc=0.31111112236976624, loss=2.6564443111419678
train: epoch 78, loss 0.23572541773319244, acc=0.9153333306312561, loss=0.23572541773319244
test: epoch 78, loss 2.4386398792266846, acc=0.36944442987442017, loss=2.4386398792266846
train: epoch 79, loss 0.23285411298274994, acc=0.9154999852180481, loss=0.23285411298274994
test: epoch 79, loss 3.2454824447631836, acc=0.2666666805744171, loss=3.2454824447631836
train: epoch 80, loss 0.2176956981420517, acc=0.9192222356796265, loss=0.2176956981420517
test: epoch 80, loss 2.512098789215088, acc=0.3861111104488373, loss=2.512098789215088
train: epoch 81, loss 0.21627044677734375, acc=0.9237222075462341, loss=0.21627044677734375
test: epoch 81, loss 2.3589093685150146, acc=0.3499999940395355, loss=2.3589093685150146
train: epoch 82, loss 0.2276608645915985, acc=0.9148333072662354, loss=0.2276608645915985
test: epoch 82, loss 2.3220484256744385, acc=0.42222222685813904, loss=2.3220484256744385
train: epoch 83, loss 0.20914119482040405, acc=0.9252777695655823, loss=0.20914119482040405
test: epoch 83, loss 2.0241644382476807, acc=0.4555555582046509, loss=2.0241644382476807
train: epoch 84, loss 0.23052573204040527, acc=0.9182222485542297, loss=0.23052573204040527
test: epoch 84, loss 2.8911378383636475, acc=0.31388887763023376, loss=2.8911378383636475
train: epoch 85, loss 0.2395172417163849, acc=0.9151666760444641, loss=0.2395172417163849
test: epoch 85, loss 2.6089868545532227, acc=0.45277777314186096, loss=2.6089868545532227
train: epoch 86, loss 0.2003147304058075, acc=0.9276666641235352, loss=0.2003147304058075
test: epoch 86, loss 2.9790592193603516, acc=0.3638888895511627, loss=2.9790592193603516
train: epoch 87, loss 0.21111245453357697, acc=0.921999990940094, loss=0.21111245453357697
test: epoch 87, loss 1.960571050643921, acc=0.3722222149372101, loss=1.960571050643921
train: epoch 88, loss 0.21850089728832245, acc=0.9216111302375793, loss=0.21850089728832245
test: epoch 88, loss 2.611706256866455, acc=0.38333332538604736, loss=2.611706256866455
train: epoch 89, loss 0.21330328285694122, acc=0.9227222204208374, loss=0.21330328285694122
test: epoch 89, loss 1.6886799335479736, acc=0.5222222208976746, loss=1.6886799335479736
train: epoch 90, loss 0.23043349385261536, acc=0.9149444699287415, loss=0.23043349385261536
test: epoch 90, loss 2.4768552780151367, acc=0.3583333194255829, loss=2.4768552780151367
train: epoch 91, loss 0.20234425365924835, acc=0.9283888936042786, loss=0.20234425365924835
test: epoch 91, loss 2.8940675258636475, acc=0.4749999940395355, loss=2.8940675258636475
train: epoch 92, loss 0.21259261667728424, acc=0.9207777976989746, loss=0.21259261667728424
test: epoch 92, loss 1.7746986150741577, acc=0.519444465637207, loss=1.7746986150741577
train: epoch 93, loss 0.19245977699756622, acc=0.9305555820465088, loss=0.19245977699756622
test: epoch 93, loss 1.863908290863037, acc=0.3777777850627899, loss=1.863908290863037
train: epoch 94, loss 0.19015006721019745, acc=0.9308333396911621, loss=0.19015006721019745
test: epoch 94, loss 2.589879035949707, acc=0.4416666626930237, loss=2.589879035949707
train: epoch 95, loss 0.2000780701637268, acc=0.9274444580078125, loss=0.2000780701637268
test: epoch 95, loss 1.508500337600708, acc=0.46388888359069824, loss=1.508500337600708
train: epoch 96, loss 0.19862836599349976, acc=0.929111123085022, loss=0.19862836599349976
test: epoch 96, loss 1.8586111068725586, acc=0.5083333253860474, loss=1.8586111068725586
train: epoch 97, loss 0.2132258117198944, acc=0.9258888959884644, loss=0.2132258117198944
test: epoch 97, loss 3.2867825031280518, acc=0.4416666626930237, loss=3.2867825031280518
train: epoch 98, loss 0.19070270657539368, acc=0.9299444556236267, loss=0.19070270657539368
test: epoch 98, loss 2.8964896202087402, acc=0.4194444417953491, loss=2.8964896202087402
train: epoch 99, loss 0.18811513483524323, acc=0.9319444298744202, loss=0.18811513483524323
test: epoch 99, loss 2.811211109161377, acc=0.375, loss=2.811211109161377
train: epoch 100, loss 0.1666823923587799, acc=0.9406111240386963, loss=0.1666823923587799
test: epoch 100, loss 1.9692912101745605, acc=0.44999998807907104, loss=1.9692912101745605
train: epoch 101, loss 0.18229462206363678, acc=0.9330000281333923, loss=0.18229462206363678
test: epoch 101, loss 1.8644191026687622, acc=0.4472222328186035, loss=1.8644191026687622
train: epoch 102, loss 0.1841641068458557, acc=0.9337777495384216, loss=0.1841641068458557
test: epoch 102, loss 2.4636669158935547, acc=0.35555556416511536, loss=2.4636669158935547
train: epoch 103, loss 0.18671318888664246, acc=0.9315000176429749, loss=0.18671318888664246
test: epoch 103, loss 2.3713488578796387, acc=0.4055555462837219, loss=2.3713488578796387
train: epoch 104, loss 0.18855129182338715, acc=0.9323889017105103, loss=0.18855129182338715
test: epoch 104, loss 2.4784905910491943, acc=0.39722222089767456, loss=2.4784905910491943
train: epoch 105, loss 0.18292763829231262, acc=0.9356111288070679, loss=0.18292763829231262
test: epoch 105, loss 1.9389739036560059, acc=0.4444444477558136, loss=1.9389739036560059
train: epoch 106, loss 0.1891564428806305, acc=0.929722249507904, loss=0.1891564428806305
test: epoch 106, loss 1.8843122720718384, acc=0.39722222089767456, loss=1.8843122720718384
train: epoch 107, loss 0.19414515793323517, acc=0.9299444556236267, loss=0.19414515793323517
test: epoch 107, loss 2.0490949153900146, acc=0.4305555522441864, loss=2.0490949153900146
train: epoch 108, loss 0.16404344141483307, acc=0.9417222142219543, loss=0.16404344141483307
test: epoch 108, loss 2.5458059310913086, acc=0.43888887763023376, loss=2.5458059310913086
train: epoch 109, loss 0.19048504531383514, acc=0.9282777905464172, loss=0.19048504531383514
test: epoch 109, loss 2.1583449840545654, acc=0.41111111640930176, loss=2.1583449840545654
train: epoch 110, loss 0.18067191541194916, acc=0.9327222108840942, loss=0.18067191541194916
test: epoch 110, loss 2.4482860565185547, acc=0.39722222089767456, loss=2.4482860565185547
train: epoch 111, loss 0.1761813759803772, acc=0.933555543422699, loss=0.1761813759803772
test: epoch 111, loss 1.9768019914627075, acc=0.42500001192092896, loss=1.9768019914627075
train: epoch 112, loss 0.1768224537372589, acc=0.9362221956253052, loss=0.1768224537372589
test: epoch 112, loss 2.893141031265259, acc=0.24722221493721008, loss=2.893141031265259
train: epoch 113, loss 0.1637948602437973, acc=0.9415555596351624, loss=0.1637948602437973
test: epoch 113, loss 2.7469072341918945, acc=0.375, loss=2.7469072341918945
train: epoch 114, loss 0.18828023970127106, acc=0.9322222471237183, loss=0.18828023970127106
test: epoch 114, loss 2.0489683151245117, acc=0.4833333194255829, loss=2.0489683151245117
train: epoch 115, loss 0.17134881019592285, acc=0.9402777552604675, loss=0.17134881019592285
test: epoch 115, loss 2.394859552383423, acc=0.4416666626930237, loss=2.394859552383423
train: epoch 116, loss 0.18939030170440674, acc=0.9311110973358154, loss=0.18939030170440674
test: epoch 116, loss 2.3131070137023926, acc=0.4055555462837219, loss=2.3131070137023926
train: epoch 117, loss 0.15687589347362518, acc=0.9415555596351624, loss=0.15687589347362518
test: epoch 117, loss 2.1155781745910645, acc=0.4833333194255829, loss=2.1155781745910645
train: epoch 118, loss 0.16644804179668427, acc=0.9418333172798157, loss=0.16644804179668427
test: epoch 118, loss 3.4633841514587402, acc=0.3916666805744171, loss=3.4633841514587402
train: epoch 119, loss 0.18008707463741302, acc=0.9342777729034424, loss=0.18008707463741302
test: epoch 119, loss 1.9885808229446411, acc=0.3361110985279083, loss=1.9885808229446411
train: epoch 120, loss 0.1614793986082077, acc=0.9412222504615784, loss=0.1614793986082077
test: epoch 120, loss 2.3182764053344727, acc=0.4000000059604645, loss=2.3182764053344727
train: epoch 121, loss 0.17279265820980072, acc=0.9388333559036255, loss=0.17279265820980072
test: epoch 121, loss 2.3616716861724854, acc=0.3861111104488373, loss=2.3616716861724854
train: epoch 122, loss 0.1505603939294815, acc=0.9444444179534912, loss=0.1505603939294815
test: epoch 122, loss 1.5702630281448364, acc=0.5555555820465088, loss=1.5702630281448364
train: epoch 123, loss 0.1727626621723175, acc=0.9382777810096741, loss=0.1727626621723175
test: epoch 123, loss 2.3648922443389893, acc=0.3916666805744171, loss=2.3648922443389893
train: epoch 124, loss 0.14105255901813507, acc=0.9497777819633484, loss=0.14105255901813507
test: epoch 124, loss 2.0729823112487793, acc=0.4138889014720917, loss=2.0729823112487793
train: epoch 125, loss 0.16290467977523804, acc=0.9423888921737671, loss=0.16290467977523804
test: epoch 125, loss 2.2473697662353516, acc=0.4861111044883728, loss=2.2473697662353516
train: epoch 126, loss 0.1636923998594284, acc=0.940500020980835, loss=0.1636923998594284
test: epoch 126, loss 2.6791675090789795, acc=0.3777777850627899, loss=2.6791675090789795
train: epoch 127, loss 0.1567973792552948, acc=0.9447222352027893, loss=0.1567973792552948
test: epoch 127, loss 3.047837495803833, acc=0.4472222328186035, loss=3.047837495803833
train: epoch 128, loss 0.1584685891866684, acc=0.941777765750885, loss=0.1584685891866684
test: epoch 128, loss 1.6024783849716187, acc=0.5222222208976746, loss=1.6024783849716187
train: epoch 129, loss 0.15087510645389557, acc=0.9469444155693054, loss=0.15087510645389557
test: epoch 129, loss 1.536051630973816, acc=0.5083333253860474, loss=1.536051630973816
train: epoch 130, loss 0.14022348821163177, acc=0.9487777948379517, loss=0.14022348821163177
test: epoch 130, loss 2.647707462310791, acc=0.3916666805744171, loss=2.647707462310791
train: epoch 131, loss 0.16204135119915009, acc=0.9422222375869751, loss=0.16204135119915009
test: epoch 131, loss 1.591828465461731, acc=0.4694444537162781, loss=1.591828465461731
train: epoch 132, loss 0.1704530566930771, acc=0.9391666650772095, loss=0.1704530566930771
test: epoch 132, loss 2.872189998626709, acc=0.45277777314186096, loss=2.872189998626709
train: epoch 133, loss 0.139777272939682, acc=0.9489444494247437, loss=0.139777272939682
test: epoch 133, loss 2.5935981273651123, acc=0.3861111104488373, loss=2.5935981273651123
train: epoch 134, loss 0.14342805743217468, acc=0.9480555653572083, loss=0.14342805743217468
test: epoch 134, loss 2.40350341796875, acc=0.46666666865348816, loss=2.40350341796875
train: epoch 135, loss 0.16141276061534882, acc=0.9420555830001831, loss=0.16141276061534882
test: epoch 135, loss 2.0671050548553467, acc=0.46388888359069824, loss=2.0671050548553467
train: epoch 136, loss 0.13720442354679108, acc=0.9511666893959045, loss=0.13720442354679108
test: epoch 136, loss 2.304251194000244, acc=0.4194444417953491, loss=2.304251194000244
train: epoch 137, loss 0.14762769639492035, acc=0.9490000009536743, loss=0.14762769639492035
test: epoch 137, loss 1.6369554996490479, acc=0.4749999940395355, loss=1.6369554996490479
train: epoch 138, loss 0.14867009222507477, acc=0.9476666450500488, loss=0.14867009222507477
test: epoch 138, loss 1.986861228942871, acc=0.49166667461395264, loss=1.986861228942871
train: epoch 139, loss 0.13100935518741608, acc=0.9514999985694885, loss=0.13100935518741608
test: epoch 139, loss 2.3493330478668213, acc=0.3916666805744171, loss=2.3493330478668213
train: epoch 140, loss 0.16185593605041504, acc=0.9424999952316284, loss=0.16185593605041504
test: epoch 140, loss 1.295035719871521, acc=0.5305555462837219, loss=1.295035719871521
train: epoch 141, loss 0.14359264075756073, acc=0.9484444260597229, loss=0.14359264075756073
test: epoch 141, loss 2.43556547164917, acc=0.3888888955116272, loss=2.43556547164917
train: epoch 142, loss 0.13665707409381866, acc=0.9504444599151611, loss=0.13665707409381866
test: epoch 142, loss 1.7651804685592651, acc=0.45277777314186096, loss=1.7651804685592651
train: epoch 143, loss 0.14313115179538727, acc=0.9507777690887451, loss=0.14313115179538727
test: epoch 143, loss 2.570793867111206, acc=0.45277777314186096, loss=2.570793867111206
train: epoch 144, loss 0.15232130885124207, acc=0.9459444284439087, loss=0.15232130885124207
test: epoch 144, loss 1.9519709348678589, acc=0.4833333194255829, loss=1.9519709348678589
train: epoch 145, loss 0.13356705009937286, acc=0.9523888826370239, loss=0.13356705009937286
test: epoch 145, loss 2.668595552444458, acc=0.5, loss=2.668595552444458
train: epoch 146, loss 0.13767699897289276, acc=0.9515555500984192, loss=0.13767699897289276
test: epoch 146, loss 1.8539340496063232, acc=0.5583333373069763, loss=1.8539340496063232
train: epoch 147, loss 0.13309556245803833, acc=0.9534444212913513, loss=0.13309556245803833
test: epoch 147, loss 1.8686481714248657, acc=0.4833333194255829, loss=1.8686481714248657
train: epoch 148, loss 0.13187158107757568, acc=0.9523888826370239, loss=0.13187158107757568
test: epoch 148, loss 3.50600528717041, acc=0.46666666865348816, loss=3.50600528717041
train: epoch 149, loss 0.1426684558391571, acc=0.9534444212913513, loss=0.1426684558391571
test: epoch 149, loss 1.858873724937439, acc=0.5027777552604675, loss=1.858873724937439
train: epoch 150, loss 0.13932034373283386, acc=0.9505000114440918, loss=0.13932034373283386
test: epoch 150, loss 2.685076951980591, acc=0.3861111104488373, loss=2.685076951980591
