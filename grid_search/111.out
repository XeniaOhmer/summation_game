# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=1", "--temp_decay=1", "--one_hot=1", "--n_layers=1"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=1666560808, receiver_embed_dim=128, save_run=0, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1666560808, receiver_embed_dim=128, save_run=False, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.5599029064178467, acc=0.04677777737379074, loss=3.5599029064178467
test: epoch 1, loss 3.496837854385376, acc=0.04722222313284874, loss=3.496837854385376
train: epoch 2, loss 3.497671604156494, acc=0.05005555599927902, loss=3.497671604156494
test: epoch 2, loss 3.2685914039611816, acc=0.06388889253139496, loss=3.2685914039611816
train: epoch 3, loss 3.4781901836395264, acc=0.05255555734038353, loss=3.4781901836395264
test: epoch 3, loss 3.0689728260040283, acc=0.0833333358168602, loss=3.0689728260040283
train: epoch 4, loss 3.415806531906128, acc=0.05305555462837219, loss=3.415806531906128
test: epoch 4, loss 3.2404608726501465, acc=0.03611111268401146, loss=3.2404608726501465
train: epoch 5, loss 3.26009464263916, acc=0.06611111015081406, loss=3.26009464263916
test: epoch 5, loss 3.885899543762207, acc=0.04722222313284874, loss=3.885899543762207
train: epoch 6, loss 3.067187786102295, acc=0.08638888597488403, loss=3.067187786102295
test: epoch 6, loss 4.2494215965271, acc=0.0416666679084301, loss=4.2494215965271
train: epoch 7, loss 2.9431774616241455, acc=0.09877777844667435, loss=2.9431774616241455
test: epoch 7, loss 4.092345714569092, acc=0.02777777798473835, loss=4.092345714569092
train: epoch 8, loss 2.8522374629974365, acc=0.1102222204208374, loss=2.8522374629974365
test: epoch 8, loss 4.232306957244873, acc=0.03333333507180214, loss=4.232306957244873
train: epoch 9, loss 2.761685371398926, acc=0.12227778136730194, loss=2.761685371398926
test: epoch 9, loss 4.072790145874023, acc=0.03333333507180214, loss=4.072790145874023
train: epoch 10, loss 2.695953369140625, acc=0.1316666603088379, loss=2.695953369140625
test: epoch 10, loss 4.109842300415039, acc=0.03333333507180214, loss=4.109842300415039
train: epoch 11, loss 2.660065174102783, acc=0.1335555613040924, loss=2.660065174102783
test: epoch 11, loss 3.999856948852539, acc=0.05833333358168602, loss=3.999856948852539
train: epoch 12, loss 2.6252784729003906, acc=0.14344444870948792, loss=2.6252784729003906
test: epoch 12, loss 4.255792140960693, acc=0.02222222276031971, loss=4.255792140960693
train: epoch 13, loss 2.577470302581787, acc=0.14572222530841827, loss=2.577470302581787
test: epoch 13, loss 4.043707370758057, acc=0.02222222276031971, loss=4.043707370758057
train: epoch 14, loss 2.5501463413238525, acc=0.14933332800865173, loss=2.5501463413238525
test: epoch 14, loss 4.022543907165527, acc=0.03055555559694767, loss=4.022543907165527
train: epoch 15, loss 2.524829387664795, acc=0.1588333398103714, loss=2.524829387664795
test: epoch 15, loss 3.9351627826690674, acc=0.0416666679084301, loss=3.9351627826690674
train: epoch 16, loss 2.4953627586364746, acc=0.16705556213855743, loss=2.4953627586364746
test: epoch 16, loss 3.9846231937408447, acc=0.04444444552063942, loss=3.9846231937408447
train: epoch 17, loss 2.4730305671691895, acc=0.1666666716337204, loss=2.4730305671691895
test: epoch 17, loss 4.005947589874268, acc=0.04444444552063942, loss=4.005947589874268
train: epoch 18, loss 2.4593513011932373, acc=0.16883333027362823, loss=2.4593513011932373
test: epoch 18, loss 3.9270179271698, acc=0.05833333358168602, loss=3.9270179271698
train: epoch 19, loss 2.4345762729644775, acc=0.17455555498600006, loss=2.4345762729644775
test: epoch 19, loss 4.055037975311279, acc=0.05000000074505806, loss=4.055037975311279
train: epoch 20, loss 2.4245922565460205, acc=0.17755556106567383, loss=2.4245922565460205
test: epoch 20, loss 3.9617116451263428, acc=0.0555555559694767, loss=3.9617116451263428
train: epoch 21, loss 2.402270555496216, acc=0.17594444751739502, loss=2.402270555496216
test: epoch 21, loss 3.793708086013794, acc=0.05833333358168602, loss=3.793708086013794
train: epoch 22, loss 2.3839292526245117, acc=0.18066667020320892, loss=2.3839292526245117
test: epoch 22, loss 3.923375129699707, acc=0.06388889253139496, loss=3.923375129699707
train: epoch 23, loss 2.373192071914673, acc=0.18850000202655792, loss=2.373192071914673
test: epoch 23, loss 3.8662896156311035, acc=0.05833333358168602, loss=3.8662896156311035
train: epoch 24, loss 2.351719856262207, acc=0.1879444420337677, loss=2.351719856262207
test: epoch 24, loss 3.904778242111206, acc=0.04444444552063942, loss=3.904778242111206
train: epoch 25, loss 2.3339662551879883, acc=0.19116666913032532, loss=2.3339662551879883
test: epoch 25, loss 3.9499452114105225, acc=0.0555555559694767, loss=3.9499452114105225
train: epoch 26, loss 2.328166961669922, acc=0.19699999690055847, loss=2.328166961669922
test: epoch 26, loss 3.9774529933929443, acc=0.0555555559694767, loss=3.9774529933929443
train: epoch 27, loss 2.321049213409424, acc=0.1982777714729309, loss=2.321049213409424
test: epoch 27, loss 4.052450180053711, acc=0.06111111119389534, loss=4.052450180053711
train: epoch 28, loss 2.3054873943328857, acc=0.19894444942474365, loss=2.3054873943328857
test: epoch 28, loss 3.907820701599121, acc=0.07222222536802292, loss=3.907820701599121
train: epoch 29, loss 2.280543565750122, acc=0.2009444385766983, loss=2.280543565750122
test: epoch 29, loss 3.9582157135009766, acc=0.07777778059244156, loss=3.9582157135009766
train: epoch 30, loss 2.2755677700042725, acc=0.21016666293144226, loss=2.2755677700042725
test: epoch 30, loss 3.9097723960876465, acc=0.0694444477558136, loss=3.9097723960876465
train: epoch 31, loss 2.263476848602295, acc=0.21105556190013885, loss=2.263476848602295
test: epoch 31, loss 3.9573299884796143, acc=0.06666667014360428, loss=3.9573299884796143
train: epoch 32, loss 2.256845712661743, acc=0.2133333384990692, loss=2.256845712661743
test: epoch 32, loss 4.03720235824585, acc=0.06388889253139496, loss=4.03720235824585
train: epoch 33, loss 2.2387185096740723, acc=0.21899999678134918, loss=2.2387185096740723
test: epoch 33, loss 3.9191648960113525, acc=0.08055555820465088, loss=3.9191648960113525
train: epoch 34, loss 2.2225029468536377, acc=0.22366666793823242, loss=2.2225029468536377
test: epoch 34, loss 3.9796791076660156, acc=0.07222222536802292, loss=3.9796791076660156
train: epoch 35, loss 2.2129056453704834, acc=0.22638888657093048, loss=2.2129056453704834
test: epoch 35, loss 3.936187744140625, acc=0.07500000298023224, loss=3.936187744140625
train: epoch 36, loss 2.2135727405548096, acc=0.23083333671092987, loss=2.2135727405548096
test: epoch 36, loss 3.94952130317688, acc=0.07222222536802292, loss=3.94952130317688
train: epoch 37, loss 2.1834828853607178, acc=0.23105555772781372, loss=2.1834828853607178
test: epoch 37, loss 3.779374361038208, acc=0.0833333358168602, loss=3.779374361038208
train: epoch 38, loss 2.176621198654175, acc=0.23733332753181458, loss=2.176621198654175
test: epoch 38, loss 3.7542548179626465, acc=0.09444444626569748, loss=3.7542548179626465
train: epoch 39, loss 2.162886619567871, acc=0.23944444954395294, loss=2.162886619567871
test: epoch 39, loss 3.7519009113311768, acc=0.10555555671453476, loss=3.7519009113311768
train: epoch 40, loss 2.1309919357299805, acc=0.2455555498600006, loss=2.1309919357299805
test: epoch 40, loss 3.6406633853912354, acc=0.10833333432674408, loss=3.6406633853912354
train: epoch 41, loss 2.1314892768859863, acc=0.24238888919353485, loss=2.1314892768859863
test: epoch 41, loss 3.6081700325012207, acc=0.11666666716337204, loss=3.6081700325012207
train: epoch 42, loss 2.1211087703704834, acc=0.2507222294807434, loss=2.1211087703704834
test: epoch 42, loss 3.60603928565979, acc=0.10277777910232544, loss=3.60603928565979
train: epoch 43, loss 2.098484992980957, acc=0.26044443249702454, loss=2.098484992980957
test: epoch 43, loss 3.3939249515533447, acc=0.11944444477558136, loss=3.3939249515533447
train: epoch 44, loss 2.1038198471069336, acc=0.2533888816833496, loss=2.1038198471069336
test: epoch 44, loss 3.3731229305267334, acc=0.11666666716337204, loss=3.3731229305267334
train: epoch 45, loss 2.070577383041382, acc=0.25922220945358276, loss=2.070577383041382
test: epoch 45, loss 3.249107837677002, acc=0.13055555522441864, loss=3.249107837677002
train: epoch 46, loss 2.043180465698242, acc=0.26766666769981384, loss=2.043180465698242
test: epoch 46, loss 3.2933878898620605, acc=0.11388888955116272, loss=3.2933878898620605
train: epoch 47, loss 2.027691125869751, acc=0.2709444463253021, loss=2.027691125869751
test: epoch 47, loss 3.1309754848480225, acc=0.125, loss=3.1309754848480225
train: epoch 48, loss 2.0238475799560547, acc=0.27816668152809143, loss=2.0238475799560547
test: epoch 48, loss 3.1986241340637207, acc=0.13055555522441864, loss=3.1986241340637207
train: epoch 49, loss 2.007650136947632, acc=0.2827777862548828, loss=2.007650136947632
test: epoch 49, loss 3.1063907146453857, acc=0.13611111044883728, loss=3.1063907146453857
train: epoch 50, loss 1.9748581647872925, acc=0.2949444353580475, loss=1.9748581647872925
test: epoch 50, loss 3.031935930252075, acc=0.1388888955116272, loss=3.031935930252075
train: epoch 51, loss 1.9610283374786377, acc=0.28788888454437256, loss=1.9610283374786377
test: epoch 51, loss 3.0143942832946777, acc=0.14444445073604584, loss=3.0143942832946777
train: epoch 52, loss 1.9550049304962158, acc=0.2916666567325592, loss=1.9550049304962158
test: epoch 52, loss 2.924717664718628, acc=0.1527777761220932, loss=2.924717664718628
train: epoch 53, loss 1.9181804656982422, acc=0.3067777752876282, loss=1.9181804656982422
test: epoch 53, loss 2.881002426147461, acc=0.1666666716337204, loss=2.881002426147461
train: epoch 54, loss 1.9023919105529785, acc=0.3129444420337677, loss=1.9023919105529785
test: epoch 54, loss 2.8732516765594482, acc=0.15555556118488312, loss=2.8732516765594482
train: epoch 55, loss 1.8859822750091553, acc=0.3143889009952545, loss=1.8859822750091553
test: epoch 55, loss 2.833338499069214, acc=0.15555556118488312, loss=2.833338499069214
train: epoch 56, loss 1.8683371543884277, acc=0.320499986410141, loss=1.8683371543884277
test: epoch 56, loss 2.8418993949890137, acc=0.16111111640930176, loss=2.8418993949890137
train: epoch 57, loss 1.8583351373672485, acc=0.3303889036178589, loss=1.8583351373672485
test: epoch 57, loss 2.7584710121154785, acc=0.1666666716337204, loss=2.7584710121154785
train: epoch 58, loss 1.8617056608200073, acc=0.33266666531562805, loss=1.8617056608200073
test: epoch 58, loss 2.747791051864624, acc=0.16944444179534912, loss=2.747791051864624
train: epoch 59, loss 1.799117088317871, acc=0.34344443678855896, loss=1.799117088317871
test: epoch 59, loss 2.7642791271209717, acc=0.16388888657093048, loss=2.7642791271209717
train: epoch 60, loss 1.797865629196167, acc=0.3442777693271637, loss=1.797865629196167
test: epoch 60, loss 2.726715564727783, acc=0.16388888657093048, loss=2.726715564727783
train: epoch 61, loss 1.7913342714309692, acc=0.34672221541404724, loss=1.7913342714309692
test: epoch 61, loss 2.6494343280792236, acc=0.16944444179534912, loss=2.6494343280792236
train: epoch 62, loss 1.7687050104141235, acc=0.3626111149787903, loss=1.7687050104141235
test: epoch 62, loss 2.7043097019195557, acc=0.17777778208255768, loss=2.7043097019195557
train: epoch 63, loss 1.7452155351638794, acc=0.36294445395469666, loss=1.7452155351638794
test: epoch 63, loss 2.6810591220855713, acc=0.15555556118488312, loss=2.6810591220855713
train: epoch 64, loss 1.7257736921310425, acc=0.3706111013889313, loss=1.7257736921310425
test: epoch 64, loss 2.6526386737823486, acc=0.17499999701976776, loss=2.6526386737823486
train: epoch 65, loss 1.7263027429580688, acc=0.3778333365917206, loss=1.7263027429580688
test: epoch 65, loss 2.646535873413086, acc=0.1666666716337204, loss=2.646535873413086
train: epoch 66, loss 1.715623140335083, acc=0.37094444036483765, loss=1.715623140335083
test: epoch 66, loss 2.5856006145477295, acc=0.17777778208255768, loss=2.5856006145477295
train: epoch 67, loss 1.687861442565918, acc=0.38672223687171936, loss=1.687861442565918
test: epoch 67, loss 2.59696364402771, acc=0.1805555522441864, loss=2.59696364402771
train: epoch 68, loss 1.6795496940612793, acc=0.3840000033378601, loss=1.6795496940612793
test: epoch 68, loss 2.5402979850769043, acc=0.17222222685813904, loss=2.5402979850769043
train: epoch 69, loss 1.6441657543182373, acc=0.4012777805328369, loss=1.6441657543182373
test: epoch 69, loss 2.597644567489624, acc=0.1666666716337204, loss=2.597644567489624
train: epoch 70, loss 1.6483129262924194, acc=0.39899998903274536, loss=1.6483129262924194
test: epoch 70, loss 2.5279221534729004, acc=0.18333333730697632, loss=2.5279221534729004
train: epoch 71, loss 1.632866621017456, acc=0.4043888747692108, loss=1.632866621017456
test: epoch 71, loss 2.559920072555542, acc=0.17777778208255768, loss=2.559920072555542
train: epoch 72, loss 1.621751308441162, acc=0.41055554151535034, loss=1.621751308441162
test: epoch 72, loss 2.5218441486358643, acc=0.18888889253139496, loss=2.5218441486358643
train: epoch 73, loss 1.612770915031433, acc=0.4159444570541382, loss=1.612770915031433
test: epoch 73, loss 2.4353115558624268, acc=0.17499999701976776, loss=2.4353115558624268
train: epoch 74, loss 1.5972141027450562, acc=0.42061111330986023, loss=1.5972141027450562
test: epoch 74, loss 2.421375274658203, acc=0.1805555522441864, loss=2.421375274658203
train: epoch 75, loss 1.5660297870635986, acc=0.43138888478279114, loss=1.5660297870635986
test: epoch 75, loss 2.451688289642334, acc=0.18333333730697632, loss=2.451688289642334
train: epoch 76, loss 1.5426244735717773, acc=0.441055566072464, loss=1.5426244735717773
test: epoch 76, loss 2.408224105834961, acc=0.19166666269302368, loss=2.408224105834961
train: epoch 77, loss 1.5453474521636963, acc=0.4422222077846527, loss=1.5453474521636963
test: epoch 77, loss 2.3657593727111816, acc=0.18611110746860504, loss=2.3657593727111816
train: epoch 78, loss 1.5222247838974, acc=0.4427777826786041, loss=1.5222247838974
test: epoch 78, loss 2.372246265411377, acc=0.1944444477558136, loss=2.372246265411377
train: epoch 79, loss 1.5081533193588257, acc=0.44966667890548706, loss=1.5081533193588257
test: epoch 79, loss 2.407435178756714, acc=0.18333333730697632, loss=2.407435178756714
train: epoch 80, loss 1.4975451231002808, acc=0.4590555429458618, loss=1.4975451231002808
test: epoch 80, loss 2.42175555229187, acc=0.19166666269302368, loss=2.42175555229187
train: epoch 81, loss 1.48478364944458, acc=0.46299999952316284, loss=1.48478364944458
test: epoch 81, loss 2.336535692214966, acc=0.18611110746860504, loss=2.336535692214966
train: epoch 82, loss 1.4729244709014893, acc=0.4694444537162781, loss=1.4729244709014893
test: epoch 82, loss 2.334937572479248, acc=0.18611110746860504, loss=2.334937572479248
train: epoch 83, loss 1.4511189460754395, acc=0.47744444012641907, loss=1.4511189460754395
test: epoch 83, loss 2.3284833431243896, acc=0.18611110746860504, loss=2.3284833431243896
train: epoch 84, loss 1.4438852071762085, acc=0.47838887572288513, loss=1.4438852071762085
test: epoch 84, loss 2.3592517375946045, acc=0.1944444477558136, loss=2.3592517375946045
train: epoch 85, loss 1.435431718826294, acc=0.4819444417953491, loss=1.435431718826294
test: epoch 85, loss 2.2859792709350586, acc=0.21944443881511688, loss=2.2859792709350586
train: epoch 86, loss 1.4185822010040283, acc=0.48855555057525635, loss=1.4185822010040283
test: epoch 86, loss 2.266209363937378, acc=0.21666666865348816, loss=2.266209363937378
train: epoch 87, loss 1.4086402654647827, acc=0.4951111078262329, loss=1.4086402654647827
test: epoch 87, loss 2.16879940032959, acc=0.21111111342906952, loss=2.16879940032959
train: epoch 88, loss 1.3953230381011963, acc=0.5011110901832581, loss=1.3953230381011963
test: epoch 88, loss 2.1954896450042725, acc=0.21666666865348816, loss=2.1954896450042725
train: epoch 89, loss 1.3754140138626099, acc=0.5116666555404663, loss=1.3754140138626099
test: epoch 89, loss 2.2411022186279297, acc=0.21666666865348816, loss=2.2411022186279297
train: epoch 90, loss 1.3712161779403687, acc=0.5211111307144165, loss=1.3712161779403687
test: epoch 90, loss 2.195713996887207, acc=0.21666666865348816, loss=2.195713996887207
train: epoch 91, loss 1.3567171096801758, acc=0.5215555429458618, loss=1.3567171096801758
test: epoch 91, loss 2.1686317920684814, acc=0.22499999403953552, loss=2.1686317920684814
train: epoch 92, loss 1.3436822891235352, acc=0.5292778015136719, loss=1.3436822891235352
test: epoch 92, loss 2.1435177326202393, acc=0.21388888359069824, loss=2.1435177326202393
train: epoch 93, loss 1.3268986940383911, acc=0.5350555777549744, loss=1.3268986940383911
test: epoch 93, loss 2.133335828781128, acc=0.22777777910232544, loss=2.133335828781128
train: epoch 94, loss 1.305516242980957, acc=0.5438888669013977, loss=1.305516242980957
test: epoch 94, loss 2.1394336223602295, acc=0.20555555820465088, loss=2.1394336223602295
train: epoch 95, loss 1.2913109064102173, acc=0.5484444499015808, loss=1.2913109064102173
test: epoch 95, loss 2.105426788330078, acc=0.22499999403953552, loss=2.105426788330078
train: epoch 96, loss 1.2941125631332397, acc=0.5504444241523743, loss=1.2941125631332397
test: epoch 96, loss 2.1152150630950928, acc=0.23055554926395416, loss=2.1152150630950928
train: epoch 97, loss 1.2666513919830322, acc=0.5580000281333923, loss=1.2666513919830322
test: epoch 97, loss 2.1404361724853516, acc=0.22777777910232544, loss=2.1404361724853516
train: epoch 98, loss 1.2692270278930664, acc=0.5622222423553467, loss=1.2692270278930664
test: epoch 98, loss 2.072299003601074, acc=0.22499999403953552, loss=2.072299003601074
train: epoch 99, loss 1.2232824563980103, acc=0.5727777481079102, loss=1.2232824563980103
test: epoch 99, loss 2.1243467330932617, acc=0.23333333432674408, loss=2.1243467330932617
train: epoch 100, loss 1.2138614654541016, acc=0.5805555582046509, loss=1.2138614654541016
test: epoch 100, loss 2.107123851776123, acc=0.23888888955116272, loss=2.107123851776123
train: epoch 101, loss 1.1922026872634888, acc=0.5877777934074402, loss=1.1922026872634888
test: epoch 101, loss 2.1335904598236084, acc=0.23055554926395416, loss=2.1335904598236084
train: epoch 102, loss 1.1843581199645996, acc=0.5930555462837219, loss=1.1843581199645996
test: epoch 102, loss 2.0493252277374268, acc=0.23055554926395416, loss=2.0493252277374268
train: epoch 103, loss 1.191935658454895, acc=0.5995555520057678, loss=1.191935658454895
test: epoch 103, loss 2.085554361343384, acc=0.21944443881511688, loss=2.085554361343384
train: epoch 104, loss 1.1727184057235718, acc=0.6067777872085571, loss=1.1727184057235718
test: epoch 104, loss 2.098477840423584, acc=0.22777777910232544, loss=2.098477840423584
train: epoch 105, loss 1.155202865600586, acc=0.6051666736602783, loss=1.155202865600586
test: epoch 105, loss 2.0762686729431152, acc=0.23055554926395416, loss=2.0762686729431152
train: epoch 106, loss 1.1446176767349243, acc=0.61772221326828, loss=1.1446176767349243
test: epoch 106, loss 2.058797836303711, acc=0.23333333432674408, loss=2.058797836303711
train: epoch 107, loss 1.129138708114624, acc=0.6145555377006531, loss=1.129138708114624
test: epoch 107, loss 2.0532281398773193, acc=0.24166665971279144, loss=2.0532281398773193
train: epoch 108, loss 1.1160120964050293, acc=0.6259444355964661, loss=1.1160120964050293
test: epoch 108, loss 1.989154577255249, acc=0.2527777850627899, loss=1.989154577255249
train: epoch 109, loss 1.1120152473449707, acc=0.6288889050483704, loss=1.1120152473449707
test: epoch 109, loss 1.996766209602356, acc=0.27222222089767456, loss=1.996766209602356
train: epoch 110, loss 1.0914692878723145, acc=0.636888861656189, loss=1.0914692878723145
test: epoch 110, loss 1.9994144439697266, acc=0.24166665971279144, loss=1.9994144439697266
train: epoch 111, loss 1.0834970474243164, acc=0.6433333158493042, loss=1.0834970474243164
test: epoch 111, loss 1.9740655422210693, acc=0.2666666805744171, loss=1.9740655422210693
train: epoch 112, loss 1.0634084939956665, acc=0.6452222466468811, loss=1.0634084939956665
test: epoch 112, loss 1.9989736080169678, acc=0.25833332538604736, loss=1.9989736080169678
train: epoch 113, loss 1.0579651594161987, acc=0.6513333320617676, loss=1.0579651594161987
test: epoch 113, loss 1.9768282175064087, acc=0.26944443583488464, loss=1.9768282175064087
train: epoch 114, loss 1.0416918992996216, acc=0.6567222476005554, loss=1.0416918992996216
test: epoch 114, loss 1.9751217365264893, acc=0.24166665971279144, loss=1.9751217365264893
train: epoch 115, loss 1.0332697629928589, acc=0.6650000214576721, loss=1.0332697629928589
test: epoch 115, loss 1.9467285871505737, acc=0.25833332538604736, loss=1.9467285871505737
train: epoch 116, loss 1.0137336254119873, acc=0.6679999828338623, loss=1.0137336254119873
test: epoch 116, loss 1.9071614742279053, acc=0.28333333134651184, loss=1.9071614742279053
train: epoch 117, loss 1.0053813457489014, acc=0.6677777767181396, loss=1.0053813457489014
test: epoch 117, loss 1.8722819089889526, acc=0.2777777910232544, loss=1.8722819089889526
train: epoch 118, loss 1.0053163766860962, acc=0.6744444370269775, loss=1.0053163766860962
test: epoch 118, loss 1.8943464756011963, acc=0.2805555462837219, loss=1.8943464756011963
train: epoch 119, loss 0.9559578895568848, acc=0.6892222166061401, loss=0.9559578895568848
test: epoch 119, loss 1.897741436958313, acc=0.2805555462837219, loss=1.897741436958313
train: epoch 120, loss 0.9680280089378357, acc=0.6788333058357239, loss=0.9680280089378357
test: epoch 120, loss 1.8788014650344849, acc=0.2888889014720917, loss=1.8788014650344849
train: epoch 121, loss 0.9548280239105225, acc=0.6931111216545105, loss=0.9548280239105225
test: epoch 121, loss 1.866801142692566, acc=0.2888889014720917, loss=1.866801142692566
train: epoch 122, loss 0.972288966178894, acc=0.6890555620193481, loss=0.972288966178894
test: epoch 122, loss 1.8367801904678345, acc=0.2888889014720917, loss=1.8367801904678345
train: epoch 123, loss 0.9324029088020325, acc=0.6958333253860474, loss=0.9324029088020325
test: epoch 123, loss 1.8495063781738281, acc=0.30000001192092896, loss=1.8495063781738281
train: epoch 124, loss 0.932905912399292, acc=0.6996666789054871, loss=0.932905912399292
test: epoch 124, loss 1.8527741432189941, acc=0.29722222685813904, loss=1.8527741432189941
train: epoch 125, loss 0.9331695437431335, acc=0.699055552482605, loss=0.9331695437431335
test: epoch 125, loss 1.866607427597046, acc=0.3055555522441864, loss=1.866607427597046
train: epoch 126, loss 0.9013964533805847, acc=0.7078333497047424, loss=0.9013964533805847
test: epoch 126, loss 1.8387386798858643, acc=0.29722222685813904, loss=1.8387386798858643
train: epoch 127, loss 0.9022955894470215, acc=0.7083888649940491, loss=0.9022955894470215
test: epoch 127, loss 1.795724868774414, acc=0.30000001192092896, loss=1.795724868774414
train: epoch 128, loss 0.8868771195411682, acc=0.710277795791626, loss=0.8868771195411682
test: epoch 128, loss 1.753117561340332, acc=0.3166666626930237, loss=1.753117561340332
train: epoch 129, loss 0.8894997239112854, acc=0.7179444432258606, loss=0.8894997239112854
test: epoch 129, loss 1.8051981925964355, acc=0.30000001192092896, loss=1.8051981925964355
train: epoch 130, loss 0.857568621635437, acc=0.7272777557373047, loss=0.857568621635437
test: epoch 130, loss 1.8203349113464355, acc=0.31111112236976624, loss=1.8203349113464355
train: epoch 131, loss 0.8642024993896484, acc=0.722777783870697, loss=0.8642024993896484
test: epoch 131, loss 1.7779945135116577, acc=0.3194444477558136, loss=1.7779945135116577
train: epoch 132, loss 0.8353406190872192, acc=0.7330555319786072, loss=0.8353406190872192
test: epoch 132, loss 1.7792377471923828, acc=0.3055555522441864, loss=1.7792377471923828
train: epoch 133, loss 0.8468987941741943, acc=0.7310000061988831, loss=0.8468987941741943
test: epoch 133, loss 1.794619083404541, acc=0.31111112236976624, loss=1.794619083404541
train: epoch 134, loss 0.8222198486328125, acc=0.7412222027778625, loss=0.8222198486328125
test: epoch 134, loss 1.802717685699463, acc=0.29722222685813904, loss=1.802717685699463
train: epoch 135, loss 0.8350731730461121, acc=0.7409999966621399, loss=0.8350731730461121
test: epoch 135, loss 1.7461961507797241, acc=0.31111112236976624, loss=1.7461961507797241
train: epoch 136, loss 0.8241850733757019, acc=0.7418888807296753, loss=0.8241850733757019
test: epoch 136, loss 1.7328369617462158, acc=0.31388887763023376, loss=1.7328369617462158
train: epoch 137, loss 0.7992799878120422, acc=0.7476666569709778, loss=0.7992799878120422
test: epoch 137, loss 1.7447357177734375, acc=0.3222222328186035, loss=1.7447357177734375
train: epoch 138, loss 0.8041244745254517, acc=0.7478888630867004, loss=0.8041244745254517
test: epoch 138, loss 1.7742533683776855, acc=0.32777777314186096, loss=1.7742533683776855
train: epoch 139, loss 0.8171684741973877, acc=0.7450555562973022, loss=0.8171684741973877
test: epoch 139, loss 1.7609326839447021, acc=0.32499998807907104, loss=1.7609326839447021
train: epoch 140, loss 0.7894548177719116, acc=0.7559444308280945, loss=0.7894548177719116
test: epoch 140, loss 1.7515989542007446, acc=0.32777777314186096, loss=1.7515989542007446
train: epoch 141, loss 0.772191047668457, acc=0.7599999904632568, loss=0.772191047668457
test: epoch 141, loss 1.7832163572311401, acc=0.32499998807907104, loss=1.7832163572311401
train: epoch 142, loss 0.7788833379745483, acc=0.7599999904632568, loss=0.7788833379745483
test: epoch 142, loss 1.7396572828292847, acc=0.3361110985279083, loss=1.7396572828292847
train: epoch 143, loss 0.7614852786064148, acc=0.7626110911369324, loss=0.7614852786064148
test: epoch 143, loss 1.699899673461914, acc=0.32777777314186096, loss=1.699899673461914
train: epoch 144, loss 0.7293989658355713, acc=0.7715555429458618, loss=0.7293989658355713
test: epoch 144, loss 1.734009027481079, acc=0.3194444477558136, loss=1.734009027481079
train: epoch 145, loss 0.7434736490249634, acc=0.7705000042915344, loss=0.7434736490249634
test: epoch 145, loss 1.7647355794906616, acc=0.32777777314186096, loss=1.7647355794906616
train: epoch 146, loss 0.747047483921051, acc=0.776888906955719, loss=0.747047483921051
test: epoch 146, loss 1.7305773496627808, acc=0.3361110985279083, loss=1.7305773496627808
train: epoch 147, loss 0.7282132506370544, acc=0.7777222394943237, loss=0.7282132506370544
test: epoch 147, loss 1.737241268157959, acc=0.3305555582046509, loss=1.737241268157959
train: epoch 148, loss 0.7240667939186096, acc=0.7792778015136719, loss=0.7240667939186096
test: epoch 148, loss 1.743330717086792, acc=0.3305555582046509, loss=1.743330717086792
train: epoch 149, loss 0.7088019847869873, acc=0.7838888764381409, loss=0.7088019847869873
test: epoch 149, loss 1.7615817785263062, acc=0.3305555582046509, loss=1.7615817785263062
train: epoch 150, loss 0.7286635637283325, acc=0.7799444198608398, loss=0.7286635637283325
test: epoch 150, loss 1.6834646463394165, acc=0.33888888359069824, loss=1.6834646463394165
