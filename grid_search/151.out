# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=0", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=642630802, receiver_embed_dim=128, save_run=0, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=642630802, receiver_embed_dim=128, save_run=False, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.3484597206115723, acc=0.16761110723018646, loss=2.3484597206115723
test: epoch 1, loss 6.855392932891846, acc=0.03611111268401146, loss=6.855392932891846
train: epoch 2, loss 1.7945854663848877, acc=0.2835555672645569, loss=1.7945854663848877
test: epoch 2, loss 6.634982585906982, acc=0.06388889253139496, loss=6.634982585906982
train: epoch 3, loss 1.5973654985427856, acc=0.3479999899864197, loss=1.5973654985427856
test: epoch 3, loss 5.600331783294678, acc=0.07777778059244156, loss=5.600331783294678
train: epoch 4, loss 1.4475346803665161, acc=0.3956666588783264, loss=1.4475346803665161
test: epoch 4, loss 5.882605075836182, acc=0.06111111119389534, loss=5.882605075836182
train: epoch 5, loss 1.3388445377349854, acc=0.448888897895813, loss=1.3388445377349854
test: epoch 5, loss 6.024811744689941, acc=0.10555555671453476, loss=6.024811744689941
train: epoch 6, loss 1.251854658126831, acc=0.47611111402511597, loss=1.251854658126831
test: epoch 6, loss 5.708664417266846, acc=0.07777778059244156, loss=5.708664417266846
train: epoch 7, loss 1.1610801219940186, acc=0.5247777700424194, loss=1.1610801219940186
test: epoch 7, loss 6.5446577072143555, acc=0.0694444477558136, loss=6.5446577072143555
train: epoch 8, loss 1.118825912475586, acc=0.5411666631698608, loss=1.118825912475586
test: epoch 8, loss 4.8120903968811035, acc=0.07777778059244156, loss=4.8120903968811035
train: epoch 9, loss 1.0597904920578003, acc=0.566777765750885, loss=1.0597904920578003
test: epoch 9, loss 5.081169605255127, acc=0.10555555671453476, loss=5.081169605255127
train: epoch 10, loss 1.0130621194839478, acc=0.5881111025810242, loss=1.0130621194839478
test: epoch 10, loss 5.032271385192871, acc=0.07222222536802292, loss=5.032271385192871
train: epoch 11, loss 0.9907295107841492, acc=0.6031666398048401, loss=0.9907295107841492
test: epoch 11, loss 4.784810543060303, acc=0.125, loss=4.784810543060303
train: epoch 12, loss 0.9385297894477844, acc=0.6215000152587891, loss=0.9385297894477844
test: epoch 12, loss 4.555656909942627, acc=0.11666666716337204, loss=4.555656909942627
train: epoch 13, loss 0.896676242351532, acc=0.6393888592720032, loss=0.896676242351532
test: epoch 13, loss 4.171903610229492, acc=0.09166666865348816, loss=4.171903610229492
train: epoch 14, loss 0.8814360499382019, acc=0.6497777700424194, loss=0.8814360499382019
test: epoch 14, loss 5.089724063873291, acc=0.10833333432674408, loss=5.089724063873291
train: epoch 15, loss 0.869074285030365, acc=0.6587777733802795, loss=0.869074285030365
test: epoch 15, loss 6.5689377784729, acc=0.10000000149011612, loss=6.5689377784729
train: epoch 16, loss 0.8305800557136536, acc=0.6731111407279968, loss=0.8305800557136536
test: epoch 16, loss 4.978818416595459, acc=0.11388888955116272, loss=4.978818416595459
train: epoch 17, loss 0.8027116656303406, acc=0.6825000047683716, loss=0.8027116656303406
test: epoch 17, loss 4.605982780456543, acc=0.125, loss=4.605982780456543
train: epoch 18, loss 0.7727848291397095, acc=0.6943333148956299, loss=0.7727848291397095
test: epoch 18, loss 6.118022918701172, acc=0.04722222313284874, loss=6.118022918701172
train: epoch 19, loss 0.78629469871521, acc=0.695555567741394, loss=0.78629469871521
test: epoch 19, loss 4.290452003479004, acc=0.11388888955116272, loss=4.290452003479004
train: epoch 20, loss 0.7486443519592285, acc=0.7085555791854858, loss=0.7486443519592285
test: epoch 20, loss 5.7565226554870605, acc=0.08888889104127884, loss=5.7565226554870605
train: epoch 21, loss 0.760945737361908, acc=0.7065555453300476, loss=0.760945737361908
test: epoch 21, loss 4.848501205444336, acc=0.09166666865348816, loss=4.848501205444336
train: epoch 22, loss 0.7369354963302612, acc=0.711722195148468, loss=0.7369354963302612
test: epoch 22, loss 4.507443904876709, acc=0.16388888657093048, loss=4.507443904876709
train: epoch 23, loss 0.7146674990653992, acc=0.7192777991294861, loss=0.7146674990653992
test: epoch 23, loss 4.004627704620361, acc=0.17499999701976776, loss=4.004627704620361
train: epoch 24, loss 0.7077450156211853, acc=0.7265555262565613, loss=0.7077450156211853
test: epoch 24, loss 3.560699939727783, acc=0.13055555522441864, loss=3.560699939727783
train: epoch 25, loss 0.6936965584754944, acc=0.7341111302375793, loss=0.6936965584754944
test: epoch 25, loss 3.371021032333374, acc=0.1805555522441864, loss=3.371021032333374
train: epoch 26, loss 0.6878405213356018, acc=0.7366111278533936, loss=0.6878405213356018
test: epoch 26, loss 4.416419982910156, acc=0.14722222089767456, loss=4.416419982910156
train: epoch 27, loss 0.687362551689148, acc=0.7362222075462341, loss=0.687362551689148
test: epoch 27, loss 3.7212836742401123, acc=0.17222222685813904, loss=3.7212836742401123
train: epoch 28, loss 0.6648271679878235, acc=0.7432777881622314, loss=0.6648271679878235
test: epoch 28, loss 4.4354634284973145, acc=0.08611111342906952, loss=4.4354634284973145
train: epoch 29, loss 0.6567791700363159, acc=0.7442777752876282, loss=0.6567791700363159
test: epoch 29, loss 3.3848559856414795, acc=0.16388888657093048, loss=3.3848559856414795
train: epoch 30, loss 0.6565372943878174, acc=0.7441111207008362, loss=0.6565372943878174
test: epoch 30, loss 4.282703876495361, acc=0.12222222238779068, loss=4.282703876495361
train: epoch 31, loss 0.645665168762207, acc=0.750333309173584, loss=0.645665168762207
test: epoch 31, loss 4.593142986297607, acc=0.14444445073604584, loss=4.593142986297607
train: epoch 32, loss 0.6465429663658142, acc=0.7571666836738586, loss=0.6465429663658142
test: epoch 32, loss 3.4947750568389893, acc=0.11666666716337204, loss=3.4947750568389893
train: epoch 33, loss 0.6105950474739075, acc=0.7651666402816772, loss=0.6105950474739075
test: epoch 33, loss 3.131464958190918, acc=0.15000000596046448, loss=3.131464958190918
train: epoch 34, loss 0.6278828382492065, acc=0.7592222094535828, loss=0.6278828382492065
test: epoch 34, loss 3.6293728351593018, acc=0.13055555522441864, loss=3.6293728351593018
train: epoch 35, loss 0.614778459072113, acc=0.7627221941947937, loss=0.614778459072113
test: epoch 35, loss 4.4404778480529785, acc=0.08055555820465088, loss=4.4404778480529785
train: epoch 36, loss 0.6265121102333069, acc=0.7618333101272583, loss=0.6265121102333069
test: epoch 36, loss 3.692206859588623, acc=0.15555556118488312, loss=3.692206859588623
train: epoch 37, loss 0.6025081872940063, acc=0.772944450378418, loss=0.6025081872940063
test: epoch 37, loss 3.4726617336273193, acc=0.18888889253139496, loss=3.4726617336273193
train: epoch 38, loss 0.621204137802124, acc=0.7671666741371155, loss=0.621204137802124
test: epoch 38, loss 4.009313106536865, acc=0.16111111640930176, loss=4.009313106536865
train: epoch 39, loss 0.5967281460762024, acc=0.7757222056388855, loss=0.5967281460762024
test: epoch 39, loss 4.216426849365234, acc=0.1388888955116272, loss=4.216426849365234
train: epoch 40, loss 0.6038035154342651, acc=0.7693889141082764, loss=0.6038035154342651
test: epoch 40, loss 3.8742127418518066, acc=0.09166666865348816, loss=3.8742127418518066
train: epoch 41, loss 0.5819941759109497, acc=0.780055582523346, loss=0.5819941759109497
test: epoch 41, loss 3.3745157718658447, acc=0.19166666269302368, loss=3.3745157718658447
train: epoch 42, loss 0.5981686115264893, acc=0.7771666646003723, loss=0.5981686115264893
test: epoch 42, loss 3.6439759731292725, acc=0.0833333358168602, loss=3.6439759731292725
train: epoch 43, loss 0.5701145529747009, acc=0.7811111211776733, loss=0.5701145529747009
test: epoch 43, loss 3.540479898452759, acc=0.14444445073604584, loss=3.540479898452759
train: epoch 44, loss 0.571612536907196, acc=0.7862777709960938, loss=0.571612536907196
test: epoch 44, loss 5.129124641418457, acc=0.08055555820465088, loss=5.129124641418457
train: epoch 45, loss 0.5858528017997742, acc=0.7765555381774902, loss=0.5858528017997742
test: epoch 45, loss 3.4824540615081787, acc=0.1527777761220932, loss=3.4824540615081787
train: epoch 46, loss 0.5813666582107544, acc=0.7803888916969299, loss=0.5813666582107544
test: epoch 46, loss 3.3914883136749268, acc=0.17499999701976776, loss=3.3914883136749268
train: epoch 47, loss 0.5819247961044312, acc=0.7793889045715332, loss=0.5819247961044312
test: epoch 47, loss 3.526341199874878, acc=0.1805555522441864, loss=3.526341199874878
train: epoch 48, loss 0.5649533271789551, acc=0.7882221937179565, loss=0.5649533271789551
test: epoch 48, loss 3.3512139320373535, acc=0.14444445073604584, loss=3.3512139320373535
train: epoch 49, loss 0.5652036070823669, acc=0.7857221961021423, loss=0.5652036070823669
test: epoch 49, loss 2.734468460083008, acc=0.16944444179534912, loss=2.734468460083008
train: epoch 50, loss 0.5332788228988647, acc=0.7991666793823242, loss=0.5332788228988647
test: epoch 50, loss 3.2299270629882812, acc=0.21666666865348816, loss=3.2299270629882812
train: epoch 51, loss 0.5430629253387451, acc=0.7935555577278137, loss=0.5430629253387451
test: epoch 51, loss 3.364018201828003, acc=0.11388888955116272, loss=3.364018201828003
train: epoch 52, loss 0.5562617778778076, acc=0.789555549621582, loss=0.5562617778778076
test: epoch 52, loss 3.008328676223755, acc=0.18333333730697632, loss=3.008328676223755
train: epoch 53, loss 0.5479555130004883, acc=0.7933889031410217, loss=0.5479555130004883
test: epoch 53, loss 3.343275785446167, acc=0.21111111342906952, loss=3.343275785446167
train: epoch 54, loss 0.5618214011192322, acc=0.7876666784286499, loss=0.5618214011192322
test: epoch 54, loss 2.8945393562316895, acc=0.20000000298023224, loss=2.8945393562316895
train: epoch 55, loss 0.5600709915161133, acc=0.7857221961021423, loss=0.5600709915161133
test: epoch 55, loss 3.6794261932373047, acc=0.2083333283662796, loss=3.6794261932373047
train: epoch 56, loss 0.5384630560874939, acc=0.7972777485847473, loss=0.5384630560874939
test: epoch 56, loss 3.1934571266174316, acc=0.22499999403953552, loss=3.1934571266174316
train: epoch 57, loss 0.5244573950767517, acc=0.800166666507721, loss=0.5244573950767517
test: epoch 57, loss 3.3383336067199707, acc=0.20000000298023224, loss=3.3383336067199707
train: epoch 58, loss 0.5526643991470337, acc=0.789222240447998, loss=0.5526643991470337
test: epoch 58, loss 2.887942314147949, acc=0.3083333373069763, loss=2.887942314147949
train: epoch 59, loss 0.5295743346214294, acc=0.8017777800559998, loss=0.5295743346214294
test: epoch 59, loss 3.3783059120178223, acc=0.24166665971279144, loss=3.3783059120178223
train: epoch 60, loss 0.5302363038063049, acc=0.8008333444595337, loss=0.5302363038063049
test: epoch 60, loss 3.7421069145202637, acc=0.10000000149011612, loss=3.7421069145202637
train: epoch 61, loss 0.5323801040649414, acc=0.796999990940094, loss=0.5323801040649414
test: epoch 61, loss 3.0021004676818848, acc=0.22499999403953552, loss=3.0021004676818848
train: epoch 62, loss 0.5392228364944458, acc=0.7972221970558167, loss=0.5392228364944458
test: epoch 62, loss 2.9010138511657715, acc=0.2527777850627899, loss=2.9010138511657715
train: epoch 63, loss 0.5362678170204163, acc=0.7979999780654907, loss=0.5362678170204163
test: epoch 63, loss 3.0308923721313477, acc=0.24444444477558136, loss=3.0308923721313477
train: epoch 64, loss 0.5260519981384277, acc=0.804111123085022, loss=0.5260519981384277
test: epoch 64, loss 2.476686716079712, acc=0.19722221791744232, loss=2.476686716079712
train: epoch 65, loss 0.5374991297721863, acc=0.7996110916137695, loss=0.5374991297721863
test: epoch 65, loss 2.879457950592041, acc=0.1944444477558136, loss=2.879457950592041
train: epoch 66, loss 0.5446142554283142, acc=0.7941111326217651, loss=0.5446142554283142
test: epoch 66, loss 2.8667232990264893, acc=0.28611111640930176, loss=2.8667232990264893
train: epoch 67, loss 0.5290414690971375, acc=0.8030555844306946, loss=0.5290414690971375
test: epoch 67, loss 2.6991498470306396, acc=0.28333333134651184, loss=2.6991498470306396
train: epoch 68, loss 0.516352117061615, acc=0.804722249507904, loss=0.516352117061615
test: epoch 68, loss 3.378882884979248, acc=0.22777777910232544, loss=3.378882884979248
train: epoch 69, loss 0.5290223956108093, acc=0.7993333339691162, loss=0.5290223956108093
test: epoch 69, loss 2.3477652072906494, acc=0.35277777910232544, loss=2.3477652072906494
train: epoch 70, loss 0.5239701867103577, acc=0.8017222285270691, loss=0.5239701867103577
test: epoch 70, loss 2.485912561416626, acc=0.2777777910232544, loss=2.485912561416626
train: epoch 71, loss 0.5250087976455688, acc=0.8057777881622314, loss=0.5250087976455688
test: epoch 71, loss 4.157938003540039, acc=0.16111111640930176, loss=4.157938003540039
train: epoch 72, loss 0.533463180065155, acc=0.7982222437858582, loss=0.533463180065155
test: epoch 72, loss 2.8331055641174316, acc=0.3055555522441864, loss=2.8331055641174316
train: epoch 73, loss 0.5042493343353271, acc=0.8100000023841858, loss=0.5042493343353271
test: epoch 73, loss 4.411775588989258, acc=0.18888889253139496, loss=4.411775588989258
train: epoch 74, loss 0.5336111187934875, acc=0.7987222075462341, loss=0.5336111187934875
test: epoch 74, loss 2.4194142818450928, acc=0.3083333373069763, loss=2.4194142818450928
train: epoch 75, loss 0.5184075832366943, acc=0.80522221326828, loss=0.5184075832366943
test: epoch 75, loss 3.1825664043426514, acc=0.18333333730697632, loss=3.1825664043426514
train: epoch 76, loss 0.4976290762424469, acc=0.8111666440963745, loss=0.4976290762424469
test: epoch 76, loss 3.316967487335205, acc=0.1805555522441864, loss=3.316967487335205
train: epoch 77, loss 0.5182511210441589, acc=0.8003888726234436, loss=0.5182511210441589
test: epoch 77, loss 2.248788595199585, acc=0.2361111044883728, loss=2.248788595199585
train: epoch 78, loss 0.49853163957595825, acc=0.808722198009491, loss=0.49853163957595825
test: epoch 78, loss 2.02048659324646, acc=0.3444444537162781, loss=2.02048659324646
train: epoch 79, loss 0.5351723432540894, acc=0.8024444580078125, loss=0.5351723432540894
test: epoch 79, loss 2.7830557823181152, acc=0.10277777910232544, loss=2.7830557823181152
train: epoch 80, loss 0.520954966545105, acc=0.8028888702392578, loss=0.520954966545105
test: epoch 80, loss 3.198957681655884, acc=0.23055554926395416, loss=3.198957681655884
train: epoch 81, loss 0.5255151987075806, acc=0.8051666617393494, loss=0.5255151987075806
test: epoch 81, loss 2.990530014038086, acc=0.27222222089767456, loss=2.990530014038086
train: epoch 82, loss 0.5009117722511292, acc=0.8093888759613037, loss=0.5009117722511292
test: epoch 82, loss 2.4367690086364746, acc=0.24722221493721008, loss=2.4367690086364746
train: epoch 83, loss 0.5168218016624451, acc=0.8036666512489319, loss=0.5168218016624451
test: epoch 83, loss 2.3090155124664307, acc=0.3222222328186035, loss=2.3090155124664307
train: epoch 84, loss 0.4919804334640503, acc=0.816444456577301, loss=0.4919804334640503
test: epoch 84, loss 2.111987590789795, acc=0.3333333432674408, loss=2.111987590789795
train: epoch 85, loss 0.5108586549758911, acc=0.8074444532394409, loss=0.5108586549758911
test: epoch 85, loss 2.531459093093872, acc=0.16944444179534912, loss=2.531459093093872
train: epoch 86, loss 0.5160807371139526, acc=0.8077777624130249, loss=0.5160807371139526
test: epoch 86, loss 2.3715403079986572, acc=0.25555557012557983, loss=2.3715403079986572
train: epoch 87, loss 0.4950201213359833, acc=0.8099444508552551, loss=0.4950201213359833
test: epoch 87, loss 3.0460877418518066, acc=0.15555556118488312, loss=3.0460877418518066
train: epoch 88, loss 0.5017620325088501, acc=0.8088889122009277, loss=0.5017620325088501
test: epoch 88, loss 2.8068289756774902, acc=0.3222222328186035, loss=2.8068289756774902
train: epoch 89, loss 0.5032541751861572, acc=0.809333324432373, loss=0.5032541751861572
test: epoch 89, loss 2.6795101165771484, acc=0.28333333134651184, loss=2.6795101165771484
train: epoch 90, loss 0.5029931664466858, acc=0.8067777752876282, loss=0.5029931664466858
test: epoch 90, loss 2.3548574447631836, acc=0.3305555582046509, loss=2.3548574447631836
train: epoch 91, loss 0.48664793372154236, acc=0.8170555830001831, loss=0.48664793372154236
test: epoch 91, loss 3.1068122386932373, acc=0.2666666805744171, loss=3.1068122386932373
train: epoch 92, loss 0.5012688636779785, acc=0.8098888993263245, loss=0.5012688636779785
test: epoch 92, loss 2.3208582401275635, acc=0.24722221493721008, loss=2.3208582401275635
train: epoch 93, loss 0.49864470958709717, acc=0.8101666569709778, loss=0.49864470958709717
test: epoch 93, loss 2.2085578441619873, acc=0.25, loss=2.2085578441619873
train: epoch 94, loss 0.511348307132721, acc=0.8062777519226074, loss=0.511348307132721
test: epoch 94, loss 2.170841693878174, acc=0.3472222089767456, loss=2.170841693878174
train: epoch 95, loss 0.5063463449478149, acc=0.8128888607025146, loss=0.5063463449478149
test: epoch 95, loss 2.721863031387329, acc=0.3333333432674408, loss=2.721863031387329
train: epoch 96, loss 0.4930022060871124, acc=0.812333345413208, loss=0.4930022060871124
test: epoch 96, loss 1.8044172525405884, acc=0.2916666567325592, loss=1.8044172525405884
train: epoch 97, loss 0.5164475440979004, acc=0.8081111311912537, loss=0.5164475440979004
test: epoch 97, loss 2.583095073699951, acc=0.20277777314186096, loss=2.583095073699951
train: epoch 98, loss 0.4989407956600189, acc=0.8096110820770264, loss=0.4989407956600189
test: epoch 98, loss 2.339500904083252, acc=0.3055555522441864, loss=2.339500904083252
train: epoch 99, loss 0.4943672716617584, acc=0.8142777681350708, loss=0.4943672716617584
test: epoch 99, loss 2.613680839538574, acc=0.30000001192092896, loss=2.613680839538574
train: epoch 100, loss 0.4962904751300812, acc=0.8133333325386047, loss=0.4962904751300812
test: epoch 100, loss 2.0438640117645264, acc=0.29722222685813904, loss=2.0438640117645264
train: epoch 101, loss 0.49076998233795166, acc=0.8121111392974854, loss=0.49076998233795166
test: epoch 101, loss 2.292719602584839, acc=0.24722221493721008, loss=2.292719602584839
train: epoch 102, loss 0.5085734724998474, acc=0.8054999709129333, loss=0.5085734724998474
test: epoch 102, loss 2.393993377685547, acc=0.36666667461395264, loss=2.393993377685547
train: epoch 103, loss 0.49015921354293823, acc=0.8111110925674438, loss=0.49015921354293823
test: epoch 103, loss 2.0425503253936768, acc=0.28333333134651184, loss=2.0425503253936768
train: epoch 104, loss 0.5129530429840088, acc=0.8023889064788818, loss=0.5129530429840088
test: epoch 104, loss 1.7410662174224854, acc=0.3611111044883728, loss=1.7410662174224854
train: epoch 105, loss 0.5019720196723938, acc=0.8083333373069763, loss=0.5019720196723938
test: epoch 105, loss 2.2273848056793213, acc=0.2666666805744171, loss=2.2273848056793213
train: epoch 106, loss 0.4802328646183014, acc=0.8182777762413025, loss=0.4802328646183014
test: epoch 106, loss 1.8963793516159058, acc=0.3444444537162781, loss=1.8963793516159058
train: epoch 107, loss 0.49391335248947144, acc=0.8093888759613037, loss=0.49391335248947144
test: epoch 107, loss 2.2488279342651367, acc=0.25, loss=2.2488279342651367
train: epoch 108, loss 0.48669683933258057, acc=0.8162222504615784, loss=0.48669683933258057
test: epoch 108, loss 1.578644871711731, acc=0.36944442987442017, loss=1.578644871711731
train: epoch 109, loss 0.4850535988807678, acc=0.8137778043746948, loss=0.4850535988807678
test: epoch 109, loss 1.6510027647018433, acc=0.4416666626930237, loss=1.6510027647018433
train: epoch 110, loss 0.5057228207588196, acc=0.8088333606719971, loss=0.5057228207588196
test: epoch 110, loss 2.098055124282837, acc=0.3305555582046509, loss=2.098055124282837
train: epoch 111, loss 0.4963671863079071, acc=0.8081111311912537, loss=0.4963671863079071
test: epoch 111, loss 2.087132215499878, acc=0.3305555582046509, loss=2.087132215499878
train: epoch 112, loss 0.4836845397949219, acc=0.8184444308280945, loss=0.4836845397949219
test: epoch 112, loss 1.95508873462677, acc=0.3499999940395355, loss=1.95508873462677
train: epoch 113, loss 0.5180414915084839, acc=0.8018333315849304, loss=0.5180414915084839
test: epoch 113, loss 1.7855669260025024, acc=0.39444443583488464, loss=1.7855669260025024
train: epoch 114, loss 0.48331594467163086, acc=0.8178333044052124, loss=0.48331594467163086
test: epoch 114, loss 2.332584857940674, acc=0.375, loss=2.332584857940674
train: epoch 115, loss 0.5030338764190674, acc=0.809499979019165, loss=0.5030338764190674
test: epoch 115, loss 2.0246055126190186, acc=0.3361110985279083, loss=2.0246055126190186
train: epoch 116, loss 0.5090884566307068, acc=0.8112778067588806, loss=0.5090884566307068
test: epoch 116, loss 2.0177359580993652, acc=0.42500001192092896, loss=2.0177359580993652
train: epoch 117, loss 0.4839521050453186, acc=0.8176666498184204, loss=0.4839521050453186
test: epoch 117, loss 2.171685218811035, acc=0.29722222685813904, loss=2.171685218811035
train: epoch 118, loss 0.5005170702934265, acc=0.8098333477973938, loss=0.5005170702934265
test: epoch 118, loss 1.884621500968933, acc=0.35277777910232544, loss=1.884621500968933
train: epoch 119, loss 0.5046722888946533, acc=0.8089444637298584, loss=0.5046722888946533
test: epoch 119, loss 1.8590881824493408, acc=0.3222222328186035, loss=1.8590881824493408
train: epoch 120, loss 0.4947279393672943, acc=0.8089444637298584, loss=0.4947279393672943
test: epoch 120, loss 2.2332146167755127, acc=0.27222222089767456, loss=2.2332146167755127
train: epoch 121, loss 0.5012282133102417, acc=0.8090000152587891, loss=0.5012282133102417
test: epoch 121, loss 1.8847726583480835, acc=0.4055555462837219, loss=1.8847726583480835
train: epoch 122, loss 0.5043034553527832, acc=0.8115555644035339, loss=0.5043034553527832
test: epoch 122, loss 1.8038357496261597, acc=0.39444443583488464, loss=1.8038357496261597
train: epoch 123, loss 0.48364731669425964, acc=0.8115555644035339, loss=0.48364731669425964
test: epoch 123, loss 1.8116730451583862, acc=0.39444443583488464, loss=1.8116730451583862
train: epoch 124, loss 0.4992770850658417, acc=0.812333345413208, loss=0.4992770850658417
test: epoch 124, loss 1.6171174049377441, acc=0.4749999940395355, loss=1.6171174049377441
train: epoch 125, loss 0.49532365798950195, acc=0.8117222189903259, loss=0.49532365798950195
test: epoch 125, loss 1.8285597562789917, acc=0.5027777552604675, loss=1.8285597562789917
train: epoch 126, loss 0.48984041810035706, acc=0.8123888969421387, loss=0.48984041810035706
test: epoch 126, loss 1.5437480211257935, acc=0.4138889014720917, loss=1.5437480211257935
train: epoch 127, loss 0.49050477147102356, acc=0.815833330154419, loss=0.49050477147102356
test: epoch 127, loss 1.7217462062835693, acc=0.375, loss=1.7217462062835693
train: epoch 128, loss 0.493154913187027, acc=0.8108333349227905, loss=0.493154913187027
test: epoch 128, loss 1.4091575145721436, acc=0.4305555522441864, loss=1.4091575145721436
train: epoch 129, loss 0.48516005277633667, acc=0.8107777833938599, loss=0.48516005277633667
test: epoch 129, loss 1.7263362407684326, acc=0.4722222089767456, loss=1.7263362407684326
train: epoch 130, loss 0.4801831543445587, acc=0.8138333559036255, loss=0.4801831543445587
test: epoch 130, loss 1.607058048248291, acc=0.3583333194255829, loss=1.607058048248291
train: epoch 131, loss 0.48063722252845764, acc=0.8119999766349792, loss=0.48063722252845764
test: epoch 131, loss 1.7593824863433838, acc=0.3722222149372101, loss=1.7593824863433838
train: epoch 132, loss 0.47485098242759705, acc=0.8139444589614868, loss=0.47485098242759705
test: epoch 132, loss 3.0275843143463135, acc=0.3888888955116272, loss=3.0275843143463135
train: epoch 133, loss 0.48466381430625916, acc=0.8086110949516296, loss=0.48466381430625916
test: epoch 133, loss 1.7702932357788086, acc=0.3722222149372101, loss=1.7702932357788086
train: epoch 134, loss 0.48922133445739746, acc=0.8135555386543274, loss=0.48922133445739746
test: epoch 134, loss 1.744706630706787, acc=0.43888887763023376, loss=1.744706630706787
train: epoch 135, loss 0.48211541771888733, acc=0.8172777891159058, loss=0.48211541771888733
test: epoch 135, loss 1.7476725578308105, acc=0.5388888716697693, loss=1.7476725578308105
train: epoch 136, loss 0.47590452432632446, acc=0.8134999871253967, loss=0.47590452432632446
test: epoch 136, loss 1.4800411462783813, acc=0.38055557012557983, loss=1.4800411462783813
train: epoch 137, loss 0.49009615182876587, acc=0.8128888607025146, loss=0.49009615182876587
test: epoch 137, loss 1.8270765542984009, acc=0.41111111640930176, loss=1.8270765542984009
train: epoch 138, loss 0.48535802960395813, acc=0.8163333535194397, loss=0.48535802960395813
test: epoch 138, loss 1.9798061847686768, acc=0.43888887763023376, loss=1.9798061847686768
train: epoch 139, loss 0.5087409615516663, acc=0.808388888835907, loss=0.5087409615516663
test: epoch 139, loss 1.5376390218734741, acc=0.4166666567325592, loss=1.5376390218734741
train: epoch 140, loss 0.4830169081687927, acc=0.8156111240386963, loss=0.4830169081687927
test: epoch 140, loss 1.6987563371658325, acc=0.4416666626930237, loss=1.6987563371658325
train: epoch 141, loss 0.4765923321247101, acc=0.8178889155387878, loss=0.4765923321247101
test: epoch 141, loss 1.5975894927978516, acc=0.375, loss=1.5975894927978516
train: epoch 142, loss 0.4881964921951294, acc=0.8122222423553467, loss=0.4881964921951294
test: epoch 142, loss 1.8502397537231445, acc=0.31388887763023376, loss=1.8502397537231445
train: epoch 143, loss 0.4863666296005249, acc=0.8096666932106018, loss=0.4863666296005249
test: epoch 143, loss 1.7564808130264282, acc=0.38055557012557983, loss=1.7564808130264282
train: epoch 144, loss 0.4864422380924225, acc=0.8081111311912537, loss=0.4864422380924225
test: epoch 144, loss 1.2200698852539062, acc=0.49444442987442017, loss=1.2200698852539062
train: epoch 145, loss 0.48958277702331543, acc=0.812166690826416, loss=0.48958277702331543
test: epoch 145, loss 2.210007667541504, acc=0.3361110985279083, loss=2.210007667541504
train: epoch 146, loss 0.48872074484825134, acc=0.8087777495384216, loss=0.48872074484825134
test: epoch 146, loss 1.3453617095947266, acc=0.5027777552604675, loss=1.3453617095947266
train: epoch 147, loss 0.48475608229637146, acc=0.8131666779518127, loss=0.48475608229637146
test: epoch 147, loss 1.3617302179336548, acc=0.43888887763023376, loss=1.3617302179336548
train: epoch 148, loss 0.4838023781776428, acc=0.8118888735771179, loss=0.4838023781776428
test: epoch 148, loss 1.4066487550735474, acc=0.46388888359069824, loss=1.4066487550735474
train: epoch 149, loss 0.49476659297943115, acc=0.80522221326828, loss=0.49476659297943115
test: epoch 149, loss 1.6570972204208374, acc=0.35277777910232544, loss=1.6570972204208374
train: epoch 150, loss 0.4817311465740204, acc=0.8141111135482788, loss=0.4817311465740204
test: epoch 150, loss 1.4576741456985474, acc=0.44999998807907104, loss=1.4576741456985474
