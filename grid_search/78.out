# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=0", "--n_layers=1"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=2053826756, receiver_embed_dim=64, save_run=0, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=2053826756, receiver_embed_dim=64, save_run=False, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.0857622623443604, acc=0.08322222530841827, loss=3.0857622623443604
test: epoch 1, loss 4.31900691986084, acc=0.05000000074505806, loss=4.31900691986084
train: epoch 2, loss 2.652994155883789, acc=0.1420000046491623, loss=2.652994155883789
test: epoch 2, loss 4.947045803070068, acc=0.05277777835726738, loss=4.947045803070068
train: epoch 3, loss 2.5209813117980957, acc=0.1574999988079071, loss=2.5209813117980957
test: epoch 3, loss 5.378396511077881, acc=0.0555555559694767, loss=5.378396511077881
train: epoch 4, loss 2.447204351425171, acc=0.1682777851819992, loss=2.447204351425171
test: epoch 4, loss 5.751199722290039, acc=0.03888889029622078, loss=5.751199722290039
train: epoch 5, loss 2.39556884765625, acc=0.17705555260181427, loss=2.39556884765625
test: epoch 5, loss 6.0245442390441895, acc=0.04444444552063942, loss=6.0245442390441895
train: epoch 6, loss 2.3483152389526367, acc=0.18594443798065186, loss=2.3483152389526367
test: epoch 6, loss 6.396610736846924, acc=0.04444444552063942, loss=6.396610736846924
train: epoch 7, loss 2.331876039505005, acc=0.1926666647195816, loss=2.331876039505005
test: epoch 7, loss 6.4928059577941895, acc=0.04722222313284874, loss=6.4928059577941895
train: epoch 8, loss 2.2969980239868164, acc=0.20027777552604675, loss=2.2969980239868164
test: epoch 8, loss 6.461319923400879, acc=0.05000000074505806, loss=6.461319923400879
train: epoch 9, loss 2.2704482078552246, acc=0.2047777771949768, loss=2.2704482078552246
test: epoch 9, loss 6.589563369750977, acc=0.04444444552063942, loss=6.589563369750977
train: epoch 10, loss 2.2581846714019775, acc=0.21016666293144226, loss=2.2581846714019775
test: epoch 10, loss 6.4863715171813965, acc=0.04722222313284874, loss=6.4863715171813965
train: epoch 11, loss 2.2539734840393066, acc=0.2076111137866974, loss=2.2539734840393066
test: epoch 11, loss 6.281796932220459, acc=0.04444444552063942, loss=6.281796932220459
train: epoch 12, loss 2.225891590118408, acc=0.21783334016799927, loss=2.225891590118408
test: epoch 12, loss 6.573227882385254, acc=0.05000000074505806, loss=6.573227882385254
train: epoch 13, loss 2.2132225036621094, acc=0.2108333259820938, loss=2.2132225036621094
test: epoch 13, loss 6.620540618896484, acc=0.0416666679084301, loss=6.620540618896484
train: epoch 14, loss 2.1997201442718506, acc=0.21988889575004578, loss=2.1997201442718506
test: epoch 14, loss 6.652097702026367, acc=0.03888889029622078, loss=6.652097702026367
train: epoch 15, loss 2.1827824115753174, acc=0.2195555567741394, loss=2.1827824115753174
test: epoch 15, loss 6.3438520431518555, acc=0.0416666679084301, loss=6.3438520431518555
train: epoch 16, loss 2.1729586124420166, acc=0.22483333945274353, loss=2.1729586124420166
test: epoch 16, loss 6.428842067718506, acc=0.04444444552063942, loss=6.428842067718506
train: epoch 17, loss 2.18074631690979, acc=0.2275555580854416, loss=2.18074631690979
test: epoch 17, loss 6.506008625030518, acc=0.04444444552063942, loss=6.506008625030518
train: epoch 18, loss 2.159426212310791, acc=0.2285555601119995, loss=2.159426212310791
test: epoch 18, loss 6.529308795928955, acc=0.04444444552063942, loss=6.529308795928955
train: epoch 19, loss 2.154686212539673, acc=0.22627778351306915, loss=2.154686212539673
test: epoch 19, loss 6.40617561340332, acc=0.04444444552063942, loss=6.40617561340332
train: epoch 20, loss 2.142871379852295, acc=0.2322777807712555, loss=2.142871379852295
test: epoch 20, loss 6.523758888244629, acc=0.0416666679084301, loss=6.523758888244629
train: epoch 21, loss 2.1510918140411377, acc=0.23155555129051208, loss=2.1510918140411377
test: epoch 21, loss 6.266668319702148, acc=0.0416666679084301, loss=6.266668319702148
train: epoch 22, loss 2.1428887844085693, acc=0.2338888943195343, loss=2.1428887844085693
test: epoch 22, loss 6.248133182525635, acc=0.03888889029622078, loss=6.248133182525635
train: epoch 23, loss 2.144866704940796, acc=0.23233333230018616, loss=2.144866704940796
test: epoch 23, loss 6.28749942779541, acc=0.03055555559694767, loss=6.28749942779541
train: epoch 24, loss 2.1320345401763916, acc=0.22972221672534943, loss=2.1320345401763916
test: epoch 24, loss 6.248511791229248, acc=0.05000000074505806, loss=6.248511791229248
train: epoch 25, loss 2.125037670135498, acc=0.24022221565246582, loss=2.125037670135498
test: epoch 25, loss 6.079242706298828, acc=0.05000000074505806, loss=6.079242706298828
train: epoch 26, loss 2.1313624382019043, acc=0.23800000548362732, loss=2.1313624382019043
test: epoch 26, loss 5.976815700531006, acc=0.03333333507180214, loss=5.976815700531006
train: epoch 27, loss 2.1087167263031006, acc=0.2395000010728836, loss=2.1087167263031006
test: epoch 27, loss 6.177118301391602, acc=0.0416666679084301, loss=6.177118301391602
train: epoch 28, loss 2.105170965194702, acc=0.23972222208976746, loss=2.105170965194702
test: epoch 28, loss 6.173666000366211, acc=0.0416666679084301, loss=6.173666000366211
train: epoch 29, loss 2.104759454727173, acc=0.24461111426353455, loss=2.104759454727173
test: epoch 29, loss 5.925461769104004, acc=0.04444444552063942, loss=5.925461769104004
train: epoch 30, loss 2.1013240814208984, acc=0.23977777361869812, loss=2.1013240814208984
test: epoch 30, loss 5.7980523109436035, acc=0.04722222313284874, loss=5.7980523109436035
train: epoch 31, loss 2.091526985168457, acc=0.24461111426353455, loss=2.091526985168457
test: epoch 31, loss 6.067451000213623, acc=0.03888889029622078, loss=6.067451000213623
train: epoch 32, loss 2.0964195728302, acc=0.24166665971279144, loss=2.0964195728302
test: epoch 32, loss 5.949409008026123, acc=0.04444444552063942, loss=5.949409008026123
train: epoch 33, loss 2.0851552486419678, acc=0.24444444477558136, loss=2.0851552486419678
test: epoch 33, loss 5.9478912353515625, acc=0.04444444552063942, loss=5.9478912353515625
train: epoch 34, loss 2.0795438289642334, acc=0.2491111159324646, loss=2.0795438289642334
test: epoch 34, loss 5.868775844573975, acc=0.03888889029622078, loss=5.868775844573975
train: epoch 35, loss 2.0987560749053955, acc=0.24544444680213928, loss=2.0987560749053955
test: epoch 35, loss 6.030036449432373, acc=0.03611111268401146, loss=6.030036449432373
train: epoch 36, loss 2.084239959716797, acc=0.24905554950237274, loss=2.084239959716797
test: epoch 36, loss 5.826287746429443, acc=0.03611111268401146, loss=5.826287746429443
train: epoch 37, loss 2.085446834564209, acc=0.24611110985279083, loss=2.085446834564209
test: epoch 37, loss 5.638189792633057, acc=0.02777777798473835, loss=5.638189792633057
train: epoch 38, loss 2.0852112770080566, acc=0.2451111078262329, loss=2.0852112770080566
test: epoch 38, loss 5.6022467613220215, acc=0.03888889029622078, loss=5.6022467613220215
train: epoch 39, loss 2.083883285522461, acc=0.25055554509162903, loss=2.083883285522461
test: epoch 39, loss 5.7357964515686035, acc=0.03611111268401146, loss=5.7357964515686035
train: epoch 40, loss 2.0987422466278076, acc=0.2485000044107437, loss=2.0987422466278076
test: epoch 40, loss 5.385968208312988, acc=0.04444444552063942, loss=5.385968208312988
train: epoch 41, loss 2.067624092102051, acc=0.2536666691303253, loss=2.067624092102051
test: epoch 41, loss 5.413204193115234, acc=0.0416666679084301, loss=5.413204193115234
train: epoch 42, loss 2.0798566341400146, acc=0.2548888921737671, loss=2.0798566341400146
test: epoch 42, loss 5.388857364654541, acc=0.04444444552063942, loss=5.388857364654541
train: epoch 43, loss 2.0811712741851807, acc=0.24922221899032593, loss=2.0811712741851807
test: epoch 43, loss 5.451098918914795, acc=0.04722222313284874, loss=5.451098918914795
train: epoch 44, loss 2.0776593685150146, acc=0.24816666543483734, loss=2.0776593685150146
test: epoch 44, loss 5.558260440826416, acc=0.03888889029622078, loss=5.558260440826416
train: epoch 45, loss 2.089686870574951, acc=0.2518889009952545, loss=2.089686870574951
test: epoch 45, loss 5.570009231567383, acc=0.03888889029622078, loss=5.570009231567383
train: epoch 46, loss 2.078791856765747, acc=0.24622222781181335, loss=2.078791856765747
test: epoch 46, loss 5.571484565734863, acc=0.05000000074505806, loss=5.571484565734863
train: epoch 47, loss 2.077697992324829, acc=0.2523888945579529, loss=2.077697992324829
test: epoch 47, loss 5.379919528961182, acc=0.03611111268401146, loss=5.379919528961182
train: epoch 48, loss 2.0852291584014893, acc=0.2520555555820465, loss=2.0852291584014893
test: epoch 48, loss 5.263190269470215, acc=0.05000000074505806, loss=5.263190269470215
train: epoch 49, loss 2.0859200954437256, acc=0.25094443559646606, loss=2.0859200954437256
test: epoch 49, loss 5.383523464202881, acc=0.03333333507180214, loss=5.383523464202881
train: epoch 50, loss 2.078416347503662, acc=0.25288888812065125, loss=2.078416347503662
test: epoch 50, loss 5.301823616027832, acc=0.03055555559694767, loss=5.301823616027832
train: epoch 51, loss 2.068206548690796, acc=0.2520555555820465, loss=2.068206548690796
test: epoch 51, loss 5.31038236618042, acc=0.0416666679084301, loss=5.31038236618042
train: epoch 52, loss 2.0734424591064453, acc=0.24650000035762787, loss=2.0734424591064453
test: epoch 52, loss 5.115655899047852, acc=0.0416666679084301, loss=5.115655899047852
train: epoch 53, loss 2.083446502685547, acc=0.2566111087799072, loss=2.083446502685547
test: epoch 53, loss 5.076914310455322, acc=0.0416666679084301, loss=5.076914310455322
train: epoch 54, loss 2.084336280822754, acc=0.2452777773141861, loss=2.084336280822754
test: epoch 54, loss 5.022733211517334, acc=0.0416666679084301, loss=5.022733211517334
train: epoch 55, loss 2.082023859024048, acc=0.24827778339385986, loss=2.082023859024048
test: epoch 55, loss 5.077866554260254, acc=0.03611111268401146, loss=5.077866554260254
train: epoch 56, loss 2.0882961750030518, acc=0.24594444036483765, loss=2.0882961750030518
test: epoch 56, loss 4.857126235961914, acc=0.05000000074505806, loss=4.857126235961914
train: epoch 57, loss 2.076838731765747, acc=0.2554999887943268, loss=2.076838731765747
test: epoch 57, loss 4.852952003479004, acc=0.05000000074505806, loss=4.852952003479004
train: epoch 58, loss 2.088426351547241, acc=0.2574999928474426, loss=2.088426351547241
test: epoch 58, loss 4.919459342956543, acc=0.03611111268401146, loss=4.919459342956543
train: epoch 59, loss 2.082063913345337, acc=0.2475000023841858, loss=2.082063913345337
test: epoch 59, loss 4.904277801513672, acc=0.04444444552063942, loss=4.904277801513672
train: epoch 60, loss 2.078784704208374, acc=0.25333333015441895, loss=2.078784704208374
test: epoch 60, loss 4.8794331550598145, acc=0.03333333507180214, loss=4.8794331550598145
train: epoch 61, loss 2.0822598934173584, acc=0.2511666715145111, loss=2.0822598934173584
test: epoch 61, loss 4.851988792419434, acc=0.0416666679084301, loss=4.851988792419434
train: epoch 62, loss 2.089090347290039, acc=0.2506110966205597, loss=2.089090347290039
test: epoch 62, loss 4.887628078460693, acc=0.04444444552063942, loss=4.887628078460693
train: epoch 63, loss 2.0885233879089355, acc=0.2511666715145111, loss=2.0885233879089355
test: epoch 63, loss 4.6912031173706055, acc=0.0555555559694767, loss=4.6912031173706055
train: epoch 64, loss 2.0742721557617188, acc=0.2507222294807434, loss=2.0742721557617188
test: epoch 64, loss 4.6585869789123535, acc=0.0416666679084301, loss=4.6585869789123535
train: epoch 65, loss 2.0926597118377686, acc=0.2507222294807434, loss=2.0926597118377686
test: epoch 65, loss 4.513805389404297, acc=0.03611111268401146, loss=4.513805389404297
train: epoch 66, loss 2.072904109954834, acc=0.24799999594688416, loss=2.072904109954834
test: epoch 66, loss 4.439914226531982, acc=0.0416666679084301, loss=4.439914226531982
train: epoch 67, loss 2.0851364135742188, acc=0.2506110966205597, loss=2.0851364135742188
test: epoch 67, loss 4.4502692222595215, acc=0.03888889029622078, loss=4.4502692222595215
train: epoch 68, loss 2.087031841278076, acc=0.2588889002799988, loss=2.087031841278076
test: epoch 68, loss 4.426298141479492, acc=0.03611111268401146, loss=4.426298141479492
train: epoch 69, loss 2.091607093811035, acc=0.24994444847106934, loss=2.091607093811035
test: epoch 69, loss 4.527894020080566, acc=0.04444444552063942, loss=4.527894020080566
train: epoch 70, loss 2.1025304794311523, acc=0.24844443798065186, loss=2.1025304794311523
test: epoch 70, loss 4.530297756195068, acc=0.03888889029622078, loss=4.530297756195068
train: epoch 71, loss 2.0941646099090576, acc=0.25272223353385925, loss=2.0941646099090576
test: epoch 71, loss 4.297589302062988, acc=0.04722222313284874, loss=4.297589302062988
train: epoch 72, loss 2.1015045642852783, acc=0.2492777705192566, loss=2.1015045642852783
test: epoch 72, loss 4.386733055114746, acc=0.03611111268401146, loss=4.386733055114746
train: epoch 73, loss 2.0993995666503906, acc=0.2470555603504181, loss=2.0993995666503906
test: epoch 73, loss 4.372824668884277, acc=0.0416666679084301, loss=4.372824668884277
train: epoch 74, loss 2.1043739318847656, acc=0.2466111183166504, loss=2.1043739318847656
test: epoch 74, loss 4.115902423858643, acc=0.04444444552063942, loss=4.115902423858643
train: epoch 75, loss 2.109936475753784, acc=0.24666666984558105, loss=2.109936475753784
test: epoch 75, loss 4.212343215942383, acc=0.0555555559694767, loss=4.212343215942383
train: epoch 76, loss 2.092738389968872, acc=0.24666666984558105, loss=2.092738389968872
test: epoch 76, loss 4.335386753082275, acc=0.0416666679084301, loss=4.335386753082275
train: epoch 77, loss 2.1150264739990234, acc=0.24844443798065186, loss=2.1150264739990234
test: epoch 77, loss 3.978219985961914, acc=0.05277777835726738, loss=3.978219985961914
train: epoch 78, loss 2.132453441619873, acc=0.24238888919353485, loss=2.132453441619873
test: epoch 78, loss 4.084364891052246, acc=0.0555555559694767, loss=4.084364891052246
train: epoch 79, loss 2.1095077991485596, acc=0.24500000476837158, loss=2.1095077991485596
test: epoch 79, loss 4.21876859664917, acc=0.07500000298023224, loss=4.21876859664917
train: epoch 80, loss 2.109605073928833, acc=0.2418888956308365, loss=2.109605073928833
test: epoch 80, loss 4.260073661804199, acc=0.06388889253139496, loss=4.260073661804199
train: epoch 81, loss 2.1238646507263184, acc=0.24294444918632507, loss=2.1238646507263184
test: epoch 81, loss 4.1428022384643555, acc=0.05833333358168602, loss=4.1428022384643555
train: epoch 82, loss 2.117598295211792, acc=0.24327777326107025, loss=2.117598295211792
test: epoch 82, loss 4.106708526611328, acc=0.05000000074505806, loss=4.106708526611328
train: epoch 83, loss 2.109980583190918, acc=0.2432222217321396, loss=2.109980583190918
test: epoch 83, loss 4.076336860656738, acc=0.06111111119389534, loss=4.076336860656738
train: epoch 84, loss 2.1205313205718994, acc=0.24611110985279083, loss=2.1205313205718994
test: epoch 84, loss 3.9981906414031982, acc=0.06666667014360428, loss=3.9981906414031982
train: epoch 85, loss 2.1403968334198, acc=0.2412777841091156, loss=2.1403968334198
test: epoch 85, loss 3.887874126434326, acc=0.05833333358168602, loss=3.887874126434326
train: epoch 86, loss 2.113713264465332, acc=0.24138888716697693, loss=2.113713264465332
test: epoch 86, loss 4.056919574737549, acc=0.04444444552063942, loss=4.056919574737549
train: epoch 87, loss 2.155820846557617, acc=0.2399444431066513, loss=2.155820846557617
test: epoch 87, loss 3.992046594619751, acc=0.04722222313284874, loss=3.992046594619751
train: epoch 88, loss 2.1232528686523438, acc=0.2430555522441864, loss=2.1232528686523438
test: epoch 88, loss 3.935763359069824, acc=0.0833333358168602, loss=3.935763359069824
train: epoch 89, loss 2.163947820663452, acc=0.23766666650772095, loss=2.163947820663452
test: epoch 89, loss 4.028928756713867, acc=0.05000000074505806, loss=4.028928756713867
train: epoch 90, loss 2.1269333362579346, acc=0.23827777802944183, loss=2.1269333362579346
test: epoch 90, loss 3.913353204727173, acc=0.06388889253139496, loss=3.913353204727173
train: epoch 91, loss 2.134169816970825, acc=0.24133333563804626, loss=2.134169816970825
test: epoch 91, loss 3.8073348999023438, acc=0.06666667014360428, loss=3.8073348999023438
train: epoch 92, loss 2.1389107704162598, acc=0.23411111533641815, loss=2.1389107704162598
test: epoch 92, loss 3.83091402053833, acc=0.07500000298023224, loss=3.83091402053833
train: epoch 93, loss 2.1524994373321533, acc=0.23372222483158112, loss=2.1524994373321533
test: epoch 93, loss 3.843332290649414, acc=0.04722222313284874, loss=3.843332290649414
train: epoch 94, loss 2.1440539360046387, acc=0.2386111170053482, loss=2.1440539360046387
test: epoch 94, loss 3.7086563110351562, acc=0.06666667014360428, loss=3.7086563110351562
train: epoch 95, loss 2.151790142059326, acc=0.23422221839427948, loss=2.151790142059326
test: epoch 95, loss 3.774503707885742, acc=0.06666667014360428, loss=3.774503707885742
train: epoch 96, loss 2.135669708251953, acc=0.24072222411632538, loss=2.135669708251953
test: epoch 96, loss 3.899946451187134, acc=0.05277777835726738, loss=3.899946451187134
train: epoch 97, loss 2.137472629547119, acc=0.2378888875246048, loss=2.137472629547119
test: epoch 97, loss 3.8572564125061035, acc=0.04444444552063942, loss=3.8572564125061035
train: epoch 98, loss 2.1521685123443604, acc=0.234333336353302, loss=2.1521685123443604
test: epoch 98, loss 3.9342739582061768, acc=0.06388889253139496, loss=3.9342739582061768
train: epoch 99, loss 2.158045530319214, acc=0.22977778315544128, loss=2.158045530319214
test: epoch 99, loss 3.711963653564453, acc=0.07777778059244156, loss=3.711963653564453
train: epoch 100, loss 2.1735846996307373, acc=0.23244445025920868, loss=2.1735846996307373
test: epoch 100, loss 3.624315023422241, acc=0.06388889253139496, loss=3.624315023422241
train: epoch 101, loss 2.1637396812438965, acc=0.2282777726650238, loss=2.1637396812438965
test: epoch 101, loss 3.5540072917938232, acc=0.0694444477558136, loss=3.5540072917938232
train: epoch 102, loss 2.1769919395446777, acc=0.2331666648387909, loss=2.1769919395446777
test: epoch 102, loss 3.669253349304199, acc=0.05000000074505806, loss=3.669253349304199
train: epoch 103, loss 2.167968988418579, acc=0.2304999977350235, loss=2.167968988418579
test: epoch 103, loss 3.716005563735962, acc=0.05277777835726738, loss=3.716005563735962
train: epoch 104, loss 2.1650240421295166, acc=0.23177777230739594, loss=2.1650240421295166
test: epoch 104, loss 3.669344902038574, acc=0.06666667014360428, loss=3.669344902038574
train: epoch 105, loss 2.164165496826172, acc=0.23333333432674408, loss=2.164165496826172
test: epoch 105, loss 3.683992624282837, acc=0.05277777835726738, loss=3.683992624282837
train: epoch 106, loss 2.175840139389038, acc=0.22955556213855743, loss=2.175840139389038
test: epoch 106, loss 3.633547306060791, acc=0.05833333358168602, loss=3.633547306060791
train: epoch 107, loss 2.170814275741577, acc=0.22411110997200012, loss=2.170814275741577
test: epoch 107, loss 3.602520227432251, acc=0.05277777835726738, loss=3.602520227432251
train: epoch 108, loss 2.1657395362854004, acc=0.22611111402511597, loss=2.1657395362854004
test: epoch 108, loss 3.4738993644714355, acc=0.06666667014360428, loss=3.4738993644714355
train: epoch 109, loss 2.1870880126953125, acc=0.22538888454437256, loss=2.1870880126953125
test: epoch 109, loss 3.418753147125244, acc=0.05833333358168602, loss=3.418753147125244
train: epoch 110, loss 2.1809897422790527, acc=0.21877777576446533, loss=2.1809897422790527
test: epoch 110, loss 3.5595104694366455, acc=0.05833333358168602, loss=3.5595104694366455
train: epoch 111, loss 2.1944737434387207, acc=0.22022221982479095, loss=2.1944737434387207
test: epoch 111, loss 3.43648362159729, acc=0.08055555820465088, loss=3.43648362159729
train: epoch 112, loss 2.1959807872772217, acc=0.2224999964237213, loss=2.1959807872772217
test: epoch 112, loss 3.4789035320281982, acc=0.06388889253139496, loss=3.4789035320281982
train: epoch 113, loss 2.1853067874908447, acc=0.22066666185855865, loss=2.1853067874908447
test: epoch 113, loss 3.438692331314087, acc=0.07500000298023224, loss=3.438692331314087
train: epoch 114, loss 2.1947968006134033, acc=0.2248888909816742, loss=2.1947968006134033
test: epoch 114, loss 3.4303202629089355, acc=0.07777778059244156, loss=3.4303202629089355
train: epoch 115, loss 2.196699619293213, acc=0.21566666662693024, loss=2.196699619293213
test: epoch 115, loss 3.366278886795044, acc=0.08055555820465088, loss=3.366278886795044
train: epoch 116, loss 2.2011427879333496, acc=0.2183888852596283, loss=2.2011427879333496
test: epoch 116, loss 3.2443976402282715, acc=0.06666667014360428, loss=3.2443976402282715
train: epoch 117, loss 2.202989339828491, acc=0.21561111509799957, loss=2.202989339828491
test: epoch 117, loss 3.3539347648620605, acc=0.06388889253139496, loss=3.3539347648620605
train: epoch 118, loss 2.195664405822754, acc=0.21583333611488342, loss=2.195664405822754
test: epoch 118, loss 3.3568813800811768, acc=0.06666667014360428, loss=3.3568813800811768
train: epoch 119, loss 2.192452907562256, acc=0.218666672706604, loss=2.192452907562256
test: epoch 119, loss 3.401536703109741, acc=0.07222222536802292, loss=3.401536703109741
train: epoch 120, loss 2.208623170852661, acc=0.21494443714618683, loss=2.208623170852661
test: epoch 120, loss 3.329918146133423, acc=0.07777778059244156, loss=3.329918146133423
train: epoch 121, loss 2.215594530105591, acc=0.2126111090183258, loss=2.215594530105591
test: epoch 121, loss 3.3556573390960693, acc=0.0694444477558136, loss=3.3556573390960693
train: epoch 122, loss 2.2052040100097656, acc=0.21538889408111572, loss=2.2052040100097656
test: epoch 122, loss 3.3611552715301514, acc=0.0694444477558136, loss=3.3611552715301514
train: epoch 123, loss 2.19500470161438, acc=0.2132222205400467, loss=2.19500470161438
test: epoch 123, loss 3.2851786613464355, acc=0.08611111342906952, loss=3.2851786613464355
train: epoch 124, loss 2.205721378326416, acc=0.2132222205400467, loss=2.205721378326416
test: epoch 124, loss 3.3958516120910645, acc=0.0555555559694767, loss=3.3958516120910645
train: epoch 125, loss 2.221168279647827, acc=0.2150000035762787, loss=2.221168279647827
test: epoch 125, loss 3.406787633895874, acc=0.05833333358168602, loss=3.406787633895874
train: epoch 126, loss 2.2259888648986816, acc=0.21199999749660492, loss=2.2259888648986816
test: epoch 126, loss 3.369551420211792, acc=0.07777778059244156, loss=3.369551420211792
train: epoch 127, loss 2.2160511016845703, acc=0.20694445073604584, loss=2.2160511016845703
test: epoch 127, loss 3.197643518447876, acc=0.07777778059244156, loss=3.197643518447876
train: epoch 128, loss 2.2311952114105225, acc=0.21466666460037231, loss=2.2311952114105225
test: epoch 128, loss 3.2660346031188965, acc=0.08611111342906952, loss=3.2660346031188965
train: epoch 129, loss 2.2322518825531006, acc=0.21094444394111633, loss=2.2322518825531006
test: epoch 129, loss 3.3022515773773193, acc=0.07500000298023224, loss=3.3022515773773193
train: epoch 130, loss 2.2339065074920654, acc=0.20644444227218628, loss=2.2339065074920654
test: epoch 130, loss 3.2538094520568848, acc=0.06666667014360428, loss=3.2538094520568848
train: epoch 131, loss 2.2222018241882324, acc=0.21044445037841797, loss=2.2222018241882324
test: epoch 131, loss 3.2206473350524902, acc=0.0833333358168602, loss=3.2206473350524902
train: epoch 132, loss 2.242422580718994, acc=0.2123333364725113, loss=2.242422580718994
test: epoch 132, loss 3.191838264465332, acc=0.07222222536802292, loss=3.191838264465332
train: epoch 133, loss 2.2197728157043457, acc=0.21027778089046478, loss=2.2197728157043457
test: epoch 133, loss 3.301650047302246, acc=0.06666667014360428, loss=3.301650047302246
train: epoch 134, loss 2.2299180030822754, acc=0.20644444227218628, loss=2.2299180030822754
test: epoch 134, loss 3.267631769180298, acc=0.07500000298023224, loss=3.267631769180298
train: epoch 135, loss 2.2386181354522705, acc=0.20483332872390747, loss=2.2386181354522705
test: epoch 135, loss 3.2064545154571533, acc=0.05277777835726738, loss=3.2064545154571533
train: epoch 136, loss 2.243852138519287, acc=0.2067222148180008, loss=2.243852138519287
test: epoch 136, loss 3.2504332065582275, acc=0.08055555820465088, loss=3.2504332065582275
train: epoch 137, loss 2.26338267326355, acc=0.20561110973358154, loss=2.26338267326355
test: epoch 137, loss 3.3064379692077637, acc=0.07500000298023224, loss=3.3064379692077637
train: epoch 138, loss 2.2364039421081543, acc=0.20216666162014008, loss=2.2364039421081543
test: epoch 138, loss 3.2019402980804443, acc=0.06111111119389534, loss=3.2019402980804443
train: epoch 139, loss 2.243175745010376, acc=0.20488889515399933, loss=2.243175745010376
test: epoch 139, loss 3.1810648441314697, acc=0.0694444477558136, loss=3.1810648441314697
train: epoch 140, loss 2.2422423362731934, acc=0.2080555558204651, loss=2.2422423362731934
test: epoch 140, loss 3.1574923992156982, acc=0.08055555820465088, loss=3.1574923992156982
train: epoch 141, loss 2.250093936920166, acc=0.2062777727842331, loss=2.250093936920166
test: epoch 141, loss 3.2745137214660645, acc=0.07222222536802292, loss=3.2745137214660645
train: epoch 142, loss 2.2331783771514893, acc=0.20633333921432495, loss=2.2331783771514893
test: epoch 142, loss 3.3213188648223877, acc=0.08055555820465088, loss=3.3213188648223877
train: epoch 143, loss 2.234548330307007, acc=0.20755556225776672, loss=2.234548330307007
test: epoch 143, loss 3.221644401550293, acc=0.07222222536802292, loss=3.221644401550293
train: epoch 144, loss 2.210392475128174, acc=0.20577777922153473, loss=2.210392475128174
test: epoch 144, loss 3.3167006969451904, acc=0.0694444477558136, loss=3.3167006969451904
train: epoch 145, loss 2.2404987812042236, acc=0.20422221720218658, loss=2.2404987812042236
test: epoch 145, loss 3.2614827156066895, acc=0.07222222536802292, loss=3.2614827156066895
train: epoch 146, loss 2.228329658508301, acc=0.20727777481079102, loss=2.228329658508301
test: epoch 146, loss 3.1406304836273193, acc=0.09166666865348816, loss=3.1406304836273193
train: epoch 147, loss 2.2326571941375732, acc=0.20527777075767517, loss=2.2326571941375732
test: epoch 147, loss 3.1870334148406982, acc=0.05277777835726738, loss=3.1870334148406982
train: epoch 148, loss 2.2417032718658447, acc=0.2038888931274414, loss=2.2417032718658447
test: epoch 148, loss 3.0903172492980957, acc=0.07500000298023224, loss=3.0903172492980957
train: epoch 149, loss 2.2427754402160645, acc=0.20472222566604614, loss=2.2427754402160645
test: epoch 149, loss 3.131223678588867, acc=0.0694444477558136, loss=3.131223678588867
train: epoch 150, loss 2.2519216537475586, acc=0.20838889479637146, loss=2.2519216537475586
test: epoch 150, loss 3.309793472290039, acc=0.07222222536802292, loss=3.309793472290039
