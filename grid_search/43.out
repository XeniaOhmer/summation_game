# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=0", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=666017634, receiver_embed_dim=32, save_run=0, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=666017634, receiver_embed_dim=32, save_run=False, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.6440017223358154, acc=0.152055561542511, loss=2.6440017223358154
test: epoch 1, loss 6.731692790985107, acc=0.0416666679084301, loss=6.731692790985107
train: epoch 2, loss 1.8777304887771606, acc=0.2917777895927429, loss=1.8777304887771606
test: epoch 2, loss 8.159392356872559, acc=0.02500000037252903, loss=8.159392356872559
train: epoch 3, loss 1.6472663879394531, acc=0.3562222123146057, loss=1.6472663879394531
test: epoch 3, loss 8.238781929016113, acc=0.03611111268401146, loss=8.238781929016113
train: epoch 4, loss 1.5142441987991333, acc=0.4041111171245575, loss=1.5142441987991333
test: epoch 4, loss 8.707925796508789, acc=0.02500000037252903, loss=8.707925796508789
train: epoch 5, loss 1.3968311548233032, acc=0.4450555443763733, loss=1.3968311548233032
test: epoch 5, loss 8.130722999572754, acc=0.06666667014360428, loss=8.130722999572754
train: epoch 6, loss 1.3179513216018677, acc=0.4708888828754425, loss=1.3179513216018677
test: epoch 6, loss 8.482260704040527, acc=0.03888889029622078, loss=8.482260704040527
train: epoch 7, loss 1.2620216608047485, acc=0.4965555667877197, loss=1.2620216608047485
test: epoch 7, loss 8.599699020385742, acc=0.0416666679084301, loss=8.599699020385742
train: epoch 8, loss 1.2161606550216675, acc=0.5160555839538574, loss=1.2161606550216675
test: epoch 8, loss 7.9233317375183105, acc=0.04444444552063942, loss=7.9233317375183105
train: epoch 9, loss 1.1644222736358643, acc=0.539222240447998, loss=1.1644222736358643
test: epoch 9, loss 7.682483196258545, acc=0.0833333358168602, loss=7.682483196258545
train: epoch 10, loss 1.1369445323944092, acc=0.5577222108840942, loss=1.1369445323944092
test: epoch 10, loss 8.104466438293457, acc=0.0833333358168602, loss=8.104466438293457
train: epoch 11, loss 1.0986675024032593, acc=0.5688333511352539, loss=1.0986675024032593
test: epoch 11, loss 7.77183723449707, acc=0.07500000298023224, loss=7.77183723449707
train: epoch 12, loss 1.0608232021331787, acc=0.5829444527626038, loss=1.0608232021331787
test: epoch 12, loss 8.287908554077148, acc=0.09444444626569748, loss=8.287908554077148
train: epoch 13, loss 1.033861517906189, acc=0.6017777919769287, loss=1.033861517906189
test: epoch 13, loss 8.116120338439941, acc=0.06388889253139496, loss=8.116120338439941
train: epoch 14, loss 1.0105092525482178, acc=0.6057778000831604, loss=1.0105092525482178
test: epoch 14, loss 7.7912821769714355, acc=0.0972222238779068, loss=7.7912821769714355
train: epoch 15, loss 0.987124502658844, acc=0.6157222390174866, loss=0.987124502658844
test: epoch 15, loss 8.064231872558594, acc=0.0972222238779068, loss=8.064231872558594
train: epoch 16, loss 0.9654268026351929, acc=0.6288889050483704, loss=0.9654268026351929
test: epoch 16, loss 7.991681098937988, acc=0.125, loss=7.991681098937988
train: epoch 17, loss 0.9554949998855591, acc=0.6316666603088379, loss=0.9554949998855591
test: epoch 17, loss 7.885606288909912, acc=0.14166666567325592, loss=7.885606288909912
train: epoch 18, loss 0.9503699541091919, acc=0.636555552482605, loss=0.9503699541091919
test: epoch 18, loss 8.140610694885254, acc=0.09444444626569748, loss=8.140610694885254
train: epoch 19, loss 0.9152461290359497, acc=0.644611120223999, loss=0.9152461290359497
test: epoch 19, loss 6.828481674194336, acc=0.10833333432674408, loss=6.828481674194336
train: epoch 20, loss 0.9103594422340393, acc=0.6541666388511658, loss=0.9103594422340393
test: epoch 20, loss 5.750908851623535, acc=0.12222222238779068, loss=5.750908851623535
train: epoch 21, loss 0.8899641036987305, acc=0.6600555777549744, loss=0.8899641036987305
test: epoch 21, loss 6.984498500823975, acc=0.13611111044883728, loss=6.984498500823975
train: epoch 22, loss 0.8902958631515503, acc=0.6627777814865112, loss=0.8902958631515503
test: epoch 22, loss 6.623525142669678, acc=0.12777778506278992, loss=6.623525142669678
train: epoch 23, loss 0.8735615015029907, acc=0.6706110835075378, loss=0.8735615015029907
test: epoch 23, loss 6.934030055999756, acc=0.14722222089767456, loss=6.934030055999756
train: epoch 24, loss 0.8604691028594971, acc=0.6779999732971191, loss=0.8604691028594971
test: epoch 24, loss 7.742193222045898, acc=0.08888889104127884, loss=7.742193222045898
train: epoch 25, loss 0.8526582717895508, acc=0.6785555481910706, loss=0.8526582717895508
test: epoch 25, loss 6.329409599304199, acc=0.1527777761220932, loss=6.329409599304199
train: epoch 26, loss 0.8418275117874146, acc=0.6831111311912537, loss=0.8418275117874146
test: epoch 26, loss 6.4012227058410645, acc=0.12777778506278992, loss=6.4012227058410645
train: epoch 27, loss 0.8269412517547607, acc=0.6909999847412109, loss=0.8269412517547607
test: epoch 27, loss 5.330333709716797, acc=0.15833333134651184, loss=5.330333709716797
train: epoch 28, loss 0.8281363248825073, acc=0.6896666884422302, loss=0.8281363248825073
test: epoch 28, loss 5.703083038330078, acc=0.08055555820465088, loss=5.703083038330078
train: epoch 29, loss 0.8146123290061951, acc=0.6936666369438171, loss=0.8146123290061951
test: epoch 29, loss 6.781448841094971, acc=0.10555555671453476, loss=6.781448841094971
train: epoch 30, loss 0.8072811365127563, acc=0.7000555396080017, loss=0.8072811365127563
test: epoch 30, loss 6.160891532897949, acc=0.16388888657093048, loss=6.160891532897949
train: epoch 31, loss 0.8090242743492126, acc=0.6968333125114441, loss=0.8090242743492126
test: epoch 31, loss 5.257197856903076, acc=0.14166666567325592, loss=5.257197856903076
train: epoch 32, loss 0.7844105958938599, acc=0.710277795791626, loss=0.7844105958938599
test: epoch 32, loss 6.0619940757751465, acc=0.11388888955116272, loss=6.0619940757751465
train: epoch 33, loss 0.7866610288619995, acc=0.7086111307144165, loss=0.7866610288619995
test: epoch 33, loss 6.612246513366699, acc=0.13611111044883728, loss=6.612246513366699
train: epoch 34, loss 0.7797132134437561, acc=0.710444450378418, loss=0.7797132134437561
test: epoch 34, loss 6.217075824737549, acc=0.15000000596046448, loss=6.217075824737549
train: epoch 35, loss 0.7760382890701294, acc=0.7073333263397217, loss=0.7760382890701294
test: epoch 35, loss 4.99873685836792, acc=0.14166666567325592, loss=4.99873685836792
train: epoch 36, loss 0.7963088750839233, acc=0.7059999704360962, loss=0.7963088750839233
test: epoch 36, loss 6.202432155609131, acc=0.14166666567325592, loss=6.202432155609131
train: epoch 37, loss 0.7704191207885742, acc=0.7148333191871643, loss=0.7704191207885742
test: epoch 37, loss 5.5840349197387695, acc=0.15555556118488312, loss=5.5840349197387695
train: epoch 38, loss 0.7727388739585876, acc=0.7103333473205566, loss=0.7727388739585876
test: epoch 38, loss 5.2049150466918945, acc=0.12777778506278992, loss=5.2049150466918945
train: epoch 39, loss 0.7585370540618896, acc=0.7220555543899536, loss=0.7585370540618896
test: epoch 39, loss 4.7854228019714355, acc=0.14722222089767456, loss=4.7854228019714355
train: epoch 40, loss 0.7597649097442627, acc=0.7178333401679993, loss=0.7597649097442627
test: epoch 40, loss 5.0532450675964355, acc=0.13333334028720856, loss=5.0532450675964355
train: epoch 41, loss 0.7657499313354492, acc=0.7142221927642822, loss=0.7657499313354492
test: epoch 41, loss 5.044894695281982, acc=0.15833333134651184, loss=5.044894695281982
train: epoch 42, loss 0.7472094893455505, acc=0.7223333120346069, loss=0.7472094893455505
test: epoch 42, loss 6.1652655601501465, acc=0.14722222089767456, loss=6.1652655601501465
train: epoch 43, loss 0.7625151872634888, acc=0.7241666913032532, loss=0.7625151872634888
test: epoch 43, loss 4.802267074584961, acc=0.10555555671453476, loss=4.802267074584961
train: epoch 44, loss 0.7479880452156067, acc=0.7247222065925598, loss=0.7479880452156067
test: epoch 44, loss 5.186545372009277, acc=0.1527777761220932, loss=5.186545372009277
train: epoch 45, loss 0.7389160990715027, acc=0.7296110987663269, loss=0.7389160990715027
test: epoch 45, loss 5.127190589904785, acc=0.13055555522441864, loss=5.127190589904785
train: epoch 46, loss 0.7542201280593872, acc=0.7322777509689331, loss=0.7542201280593872
test: epoch 46, loss 4.4865288734436035, acc=0.16388888657093048, loss=4.4865288734436035
train: epoch 47, loss 0.7501572966575623, acc=0.7250000238418579, loss=0.7501572966575623
test: epoch 47, loss 4.520237445831299, acc=0.18611110746860504, loss=4.520237445831299
train: epoch 48, loss 0.7629480957984924, acc=0.7224444150924683, loss=0.7629480957984924
test: epoch 48, loss 4.476221561431885, acc=0.14444445073604584, loss=4.476221561431885
train: epoch 49, loss 0.7483040690422058, acc=0.7246666550636292, loss=0.7483040690422058
test: epoch 49, loss 3.958240509033203, acc=0.15000000596046448, loss=3.958240509033203
train: epoch 50, loss 0.7370913624763489, acc=0.7319444417953491, loss=0.7370913624763489
test: epoch 50, loss 4.707194805145264, acc=0.12222222238779068, loss=4.707194805145264
train: epoch 51, loss 0.7351797223091125, acc=0.7325555682182312, loss=0.7351797223091125
test: epoch 51, loss 4.9596848487854, acc=0.12777778506278992, loss=4.9596848487854
train: epoch 52, loss 0.7363263368606567, acc=0.7282222509384155, loss=0.7363263368606567
test: epoch 52, loss 4.630902290344238, acc=0.15555556118488312, loss=4.630902290344238
train: epoch 53, loss 0.7449462413787842, acc=0.7308333516120911, loss=0.7449462413787842
test: epoch 53, loss 4.935684680938721, acc=0.15000000596046448, loss=4.935684680938721
train: epoch 54, loss 0.7384918928146362, acc=0.7302777767181396, loss=0.7384918928146362
test: epoch 54, loss 4.796815395355225, acc=0.17499999701976776, loss=4.796815395355225
train: epoch 55, loss 0.7412056922912598, acc=0.731166660785675, loss=0.7412056922912598
test: epoch 55, loss 3.696406364440918, acc=0.18611110746860504, loss=3.696406364440918
train: epoch 56, loss 0.7359817624092102, acc=0.7330555319786072, loss=0.7359817624092102
test: epoch 56, loss 4.296237468719482, acc=0.11666666716337204, loss=4.296237468719482
train: epoch 57, loss 0.7498828172683716, acc=0.7315000295639038, loss=0.7498828172683716
test: epoch 57, loss 4.078700065612793, acc=0.15555556118488312, loss=4.078700065612793
train: epoch 58, loss 0.7505627274513245, acc=0.7225000262260437, loss=0.7505627274513245
test: epoch 58, loss 4.002890586853027, acc=0.2083333283662796, loss=4.002890586853027
train: epoch 59, loss 0.7594408392906189, acc=0.7217777967453003, loss=0.7594408392906189
test: epoch 59, loss 4.1316046714782715, acc=0.21111111342906952, loss=4.1316046714782715
train: epoch 60, loss 0.7471970319747925, acc=0.7290555834770203, loss=0.7471970319747925
test: epoch 60, loss 3.9508209228515625, acc=0.1527777761220932, loss=3.9508209228515625
train: epoch 61, loss 0.7576251029968262, acc=0.7251666784286499, loss=0.7576251029968262
test: epoch 61, loss 3.411905288696289, acc=0.14166666567325592, loss=3.411905288696289
train: epoch 62, loss 0.7489417791366577, acc=0.725944459438324, loss=0.7489417791366577
test: epoch 62, loss 4.123451232910156, acc=0.17777778208255768, loss=4.123451232910156
train: epoch 63, loss 0.728223443031311, acc=0.7278888821601868, loss=0.728223443031311
test: epoch 63, loss 3.5046544075012207, acc=0.17499999701976776, loss=3.5046544075012207
train: epoch 64, loss 0.7288025617599487, acc=0.7297222018241882, loss=0.7288025617599487
test: epoch 64, loss 3.317409038543701, acc=0.18888889253139496, loss=3.317409038543701
train: epoch 65, loss 0.7424283623695374, acc=0.7281666398048401, loss=0.7424283623695374
test: epoch 65, loss 4.007754325866699, acc=0.14444445073604584, loss=4.007754325866699
train: epoch 66, loss 0.7378242611885071, acc=0.7276666760444641, loss=0.7378242611885071
test: epoch 66, loss 2.9500174522399902, acc=0.15000000596046448, loss=2.9500174522399902
train: epoch 67, loss 0.7490708231925964, acc=0.7243888974189758, loss=0.7490708231925964
test: epoch 67, loss 3.2341926097869873, acc=0.17222222685813904, loss=3.2341926097869873
train: epoch 68, loss 0.7592362761497498, acc=0.7236111164093018, loss=0.7592362761497498
test: epoch 68, loss 3.339198112487793, acc=0.17222222685813904, loss=3.339198112487793
train: epoch 69, loss 0.7474642395973206, acc=0.7279444336891174, loss=0.7474642395973206
test: epoch 69, loss 3.6457390785217285, acc=0.1805555522441864, loss=3.6457390785217285
train: epoch 70, loss 0.7516759634017944, acc=0.7273889183998108, loss=0.7516759634017944
test: epoch 70, loss 3.5200138092041016, acc=0.1944444477558136, loss=3.5200138092041016
train: epoch 71, loss 0.7578043341636658, acc=0.7238888740539551, loss=0.7578043341636658
test: epoch 71, loss 3.479464530944824, acc=0.14722222089767456, loss=3.479464530944824
train: epoch 72, loss 0.7403168082237244, acc=0.726722240447998, loss=0.7403168082237244
test: epoch 72, loss 3.40543794631958, acc=0.21388888359069824, loss=3.40543794631958
train: epoch 73, loss 0.7423415184020996, acc=0.7277222275733948, loss=0.7423415184020996
test: epoch 73, loss 2.841449499130249, acc=0.17499999701976776, loss=2.841449499130249
train: epoch 74, loss 0.7442271113395691, acc=0.7272777557373047, loss=0.7442271113395691
test: epoch 74, loss 2.800016164779663, acc=0.15555556118488312, loss=2.800016164779663
train: epoch 75, loss 0.7658336162567139, acc=0.7202777862548828, loss=0.7658336162567139
test: epoch 75, loss 3.3250930309295654, acc=0.14722222089767456, loss=3.3250930309295654
train: epoch 76, loss 0.7770553827285767, acc=0.7183333039283752, loss=0.7770553827285767
test: epoch 76, loss 3.8408923149108887, acc=0.15555556118488312, loss=3.8408923149108887
train: epoch 77, loss 0.7575985193252563, acc=0.7272777557373047, loss=0.7575985193252563
test: epoch 77, loss 3.0145726203918457, acc=0.15000000596046448, loss=3.0145726203918457
train: epoch 78, loss 0.757904052734375, acc=0.715499997138977, loss=0.757904052734375
test: epoch 78, loss 3.081939458847046, acc=0.20277777314186096, loss=3.081939458847046
train: epoch 79, loss 0.7634056210517883, acc=0.7173333168029785, loss=0.7634056210517883
test: epoch 79, loss 3.0891716480255127, acc=0.22499999403953552, loss=3.0891716480255127
train: epoch 80, loss 0.7632846832275391, acc=0.717555582523346, loss=0.7632846832275391
test: epoch 80, loss 3.2770094871520996, acc=0.14444445073604584, loss=3.2770094871520996
train: epoch 81, loss 0.763992190361023, acc=0.7260555624961853, loss=0.763992190361023
test: epoch 81, loss 2.569875478744507, acc=0.1944444477558136, loss=2.569875478744507
train: epoch 82, loss 0.7612970471382141, acc=0.7261666655540466, loss=0.7612970471382141
test: epoch 82, loss 2.6846213340759277, acc=0.24722221493721008, loss=2.6846213340759277
train: epoch 83, loss 0.7523185014724731, acc=0.7203888893127441, loss=0.7523185014724731
test: epoch 83, loss 3.092308282852173, acc=0.15833333134651184, loss=3.092308282852173
train: epoch 84, loss 0.7635380625724792, acc=0.7217777967453003, loss=0.7635380625724792
test: epoch 84, loss 2.4727160930633545, acc=0.23055554926395416, loss=2.4727160930633545
train: epoch 85, loss 0.7586017847061157, acc=0.726722240447998, loss=0.7586017847061157
test: epoch 85, loss 2.939908981323242, acc=0.21944443881511688, loss=2.939908981323242
train: epoch 86, loss 0.7636104822158813, acc=0.7235000133514404, loss=0.7636104822158813
test: epoch 86, loss 2.3152077198028564, acc=0.2527777850627899, loss=2.3152077198028564
train: epoch 87, loss 0.7644368410110474, acc=0.7223333120346069, loss=0.7644368410110474
test: epoch 87, loss 2.245654821395874, acc=0.23333333432674408, loss=2.245654821395874
train: epoch 88, loss 0.7842761874198914, acc=0.714555561542511, loss=0.7842761874198914
test: epoch 88, loss 2.0888402462005615, acc=0.23055554926395416, loss=2.0888402462005615
train: epoch 89, loss 0.7695630788803101, acc=0.7212777733802795, loss=0.7695630788803101
test: epoch 89, loss 2.332628011703491, acc=0.26944443583488464, loss=2.332628011703491
train: epoch 90, loss 0.7510136961936951, acc=0.7228333353996277, loss=0.7510136961936951
test: epoch 90, loss 2.3803603649139404, acc=0.2361111044883728, loss=2.3803603649139404
train: epoch 91, loss 0.7726742029190063, acc=0.7162777781486511, loss=0.7726742029190063
test: epoch 91, loss 2.301999092102051, acc=0.2083333283662796, loss=2.301999092102051
train: epoch 92, loss 0.763357400894165, acc=0.7173888683319092, loss=0.763357400894165
test: epoch 92, loss 2.250002145767212, acc=0.3166666626930237, loss=2.250002145767212
train: epoch 93, loss 0.7631838321685791, acc=0.7182222008705139, loss=0.7631838321685791
test: epoch 93, loss 2.48502516746521, acc=0.17222222685813904, loss=2.48502516746521
train: epoch 94, loss 0.7579196691513062, acc=0.7256110906600952, loss=0.7579196691513062
test: epoch 94, loss 2.2017533779144287, acc=0.24444444477558136, loss=2.2017533779144287
train: epoch 95, loss 0.7602981328964233, acc=0.7185555696487427, loss=0.7602981328964233
test: epoch 95, loss 2.2645199298858643, acc=0.25833332538604736, loss=2.2645199298858643
train: epoch 96, loss 0.7543066740036011, acc=0.7193889021873474, loss=0.7543066740036011
test: epoch 96, loss 2.8124823570251465, acc=0.21666666865348816, loss=2.8124823570251465
train: epoch 97, loss 0.7790130376815796, acc=0.7153888940811157, loss=0.7790130376815796
test: epoch 97, loss 2.508608102798462, acc=0.22777777910232544, loss=2.508608102798462
train: epoch 98, loss 0.7610445022583008, acc=0.7233889102935791, loss=0.7610445022583008
test: epoch 98, loss 2.4694480895996094, acc=0.25833332538604736, loss=2.4694480895996094
train: epoch 99, loss 0.7929905652999878, acc=0.7089444398880005, loss=0.7929905652999878
test: epoch 99, loss 2.265170097351074, acc=0.24444444477558136, loss=2.265170097351074
train: epoch 100, loss 0.7666953206062317, acc=0.7160000205039978, loss=0.7666953206062317
test: epoch 100, loss 2.2128241062164307, acc=0.28333333134651184, loss=2.2128241062164307
train: epoch 101, loss 0.7598912715911865, acc=0.7174999713897705, loss=0.7598912715911865
test: epoch 101, loss 2.153456449508667, acc=0.2638888955116272, loss=2.153456449508667
train: epoch 102, loss 0.7811782360076904, acc=0.7094444632530212, loss=0.7811782360076904
test: epoch 102, loss 1.8585768938064575, acc=0.2666666805744171, loss=1.8585768938064575
train: epoch 103, loss 0.7686662077903748, acc=0.7122777700424194, loss=0.7686662077903748
test: epoch 103, loss 2.0795912742614746, acc=0.2777777910232544, loss=2.0795912742614746
train: epoch 104, loss 0.7617972493171692, acc=0.7210000157356262, loss=0.7617972493171692
test: epoch 104, loss 2.1234469413757324, acc=0.2805555462837219, loss=2.1234469413757324
train: epoch 105, loss 0.7506959438323975, acc=0.7200555801391602, loss=0.7506959438323975
test: epoch 105, loss 2.203026056289673, acc=0.24722221493721008, loss=2.203026056289673
train: epoch 106, loss 0.7606006264686584, acc=0.7220555543899536, loss=0.7606006264686584
test: epoch 106, loss 2.061612129211426, acc=0.2638888955116272, loss=2.061612129211426
train: epoch 107, loss 0.7746489644050598, acc=0.7135000228881836, loss=0.7746489644050598
test: epoch 107, loss 2.071432590484619, acc=0.3361110985279083, loss=2.071432590484619
train: epoch 108, loss 0.753718376159668, acc=0.7211111187934875, loss=0.753718376159668
test: epoch 108, loss 2.0075347423553467, acc=0.25, loss=2.0075347423553467
train: epoch 109, loss 0.770358681678772, acc=0.7221111059188843, loss=0.770358681678772
test: epoch 109, loss 2.0268568992614746, acc=0.26944443583488464, loss=2.0268568992614746
train: epoch 110, loss 0.7769432663917542, acc=0.7143333554267883, loss=0.7769432663917542
test: epoch 110, loss 2.2134978771209717, acc=0.31111112236976624, loss=2.2134978771209717
train: epoch 111, loss 0.7637439370155334, acc=0.7194444537162781, loss=0.7637439370155334
test: epoch 111, loss 2.458005428314209, acc=0.2527777850627899, loss=2.458005428314209
train: epoch 112, loss 0.7913959622383118, acc=0.7078889012336731, loss=0.7913959622383118
test: epoch 112, loss 2.0981547832489014, acc=0.24444444477558136, loss=2.0981547832489014
train: epoch 113, loss 0.7654150724411011, acc=0.714388906955719, loss=0.7654150724411011
test: epoch 113, loss 1.6049330234527588, acc=0.3222222328186035, loss=1.6049330234527588
train: epoch 114, loss 0.7576296925544739, acc=0.7142221927642822, loss=0.7576296925544739
test: epoch 114, loss 1.5300724506378174, acc=0.4055555462837219, loss=1.5300724506378174
train: epoch 115, loss 0.7490443587303162, acc=0.7153888940811157, loss=0.7490443587303162
test: epoch 115, loss 1.8127882480621338, acc=0.3722222149372101, loss=1.8127882480621338
train: epoch 116, loss 0.7830737829208374, acc=0.7096111178398132, loss=0.7830737829208374
test: epoch 116, loss 1.9827780723571777, acc=0.3305555582046509, loss=1.9827780723571777
train: epoch 117, loss 0.7756497859954834, acc=0.7117778062820435, loss=0.7756497859954834
test: epoch 117, loss 2.0335988998413086, acc=0.2666666805744171, loss=2.0335988998413086
train: epoch 118, loss 0.7710546851158142, acc=0.7148333191871643, loss=0.7710546851158142
test: epoch 118, loss 2.043149471282959, acc=0.2888889014720917, loss=2.043149471282959
train: epoch 119, loss 0.761441707611084, acc=0.7147777676582336, loss=0.761441707611084
test: epoch 119, loss 2.4973158836364746, acc=0.25, loss=2.4973158836364746
train: epoch 120, loss 0.7832912802696228, acc=0.7052222490310669, loss=0.7832912802696228
test: epoch 120, loss 2.285196542739868, acc=0.23055554926395416, loss=2.285196542739868
train: epoch 121, loss 0.7965224385261536, acc=0.7012777924537659, loss=0.7965224385261536
test: epoch 121, loss 2.232067823410034, acc=0.31111112236976624, loss=2.232067823410034
train: epoch 122, loss 0.8174434900283813, acc=0.6959444284439087, loss=0.8174434900283813
test: epoch 122, loss 1.9632298946380615, acc=0.28333333134651184, loss=1.9632298946380615
train: epoch 123, loss 0.7912072539329529, acc=0.7046666741371155, loss=0.7912072539329529
test: epoch 123, loss 1.6099904775619507, acc=0.28611111640930176, loss=1.6099904775619507
train: epoch 124, loss 0.8046209216117859, acc=0.7004444599151611, loss=0.8046209216117859
test: epoch 124, loss 1.583310842514038, acc=0.36944442987442017, loss=1.583310842514038
train: epoch 125, loss 0.774073600769043, acc=0.7114444375038147, loss=0.774073600769043
test: epoch 125, loss 1.927126407623291, acc=0.4055555462837219, loss=1.927126407623291
train: epoch 126, loss 0.8063028454780579, acc=0.7005555629730225, loss=0.8063028454780579
test: epoch 126, loss 1.9135164022445679, acc=0.26944443583488464, loss=1.9135164022445679
train: epoch 127, loss 0.7960335612297058, acc=0.7038888931274414, loss=0.7960335612297058
test: epoch 127, loss 1.706998348236084, acc=0.3472222089767456, loss=1.706998348236084
train: epoch 128, loss 0.7862116694450378, acc=0.7039999961853027, loss=0.7862116694450378
test: epoch 128, loss 1.8456571102142334, acc=0.27222222089767456, loss=1.8456571102142334
train: epoch 129, loss 0.8017403483390808, acc=0.6971111297607422, loss=0.8017403483390808
test: epoch 129, loss 2.4127981662750244, acc=0.21111111342906952, loss=2.4127981662750244
train: epoch 130, loss 0.7689776420593262, acc=0.7071666717529297, loss=0.7689776420593262
test: epoch 130, loss 1.7736750841140747, acc=0.3222222328186035, loss=1.7736750841140747
train: epoch 131, loss 0.7801769971847534, acc=0.7012777924537659, loss=0.7801769971847534
test: epoch 131, loss 1.8314019441604614, acc=0.3333333432674408, loss=1.8314019441604614
train: epoch 132, loss 0.7779697179794312, acc=0.7048888802528381, loss=0.7779697179794312
test: epoch 132, loss 2.094543933868408, acc=0.31388887763023376, loss=2.094543933868408
train: epoch 133, loss 0.7775127291679382, acc=0.7105000019073486, loss=0.7775127291679382
test: epoch 133, loss 1.8592129945755005, acc=0.3083333373069763, loss=1.8592129945755005
train: epoch 134, loss 0.8120470643043518, acc=0.6962222456932068, loss=0.8120470643043518
test: epoch 134, loss 1.7193222045898438, acc=0.3222222328186035, loss=1.7193222045898438
train: epoch 135, loss 0.7752063870429993, acc=0.7008888721466064, loss=0.7752063870429993
test: epoch 135, loss 1.9965486526489258, acc=0.3055555522441864, loss=1.9965486526489258
train: epoch 136, loss 0.783434271812439, acc=0.7023333311080933, loss=0.783434271812439
test: epoch 136, loss 1.7349005937576294, acc=0.2888889014720917, loss=1.7349005937576294
train: epoch 137, loss 0.8221560120582581, acc=0.6935555338859558, loss=0.8221560120582581
test: epoch 137, loss 1.8748843669891357, acc=0.3194444477558136, loss=1.8748843669891357
train: epoch 138, loss 0.7824246287345886, acc=0.7039999961853027, loss=0.7824246287345886
test: epoch 138, loss 1.8261789083480835, acc=0.31111112236976624, loss=1.8261789083480835
train: epoch 139, loss 0.7859000563621521, acc=0.6979444622993469, loss=0.7859000563621521
test: epoch 139, loss 1.8753191232681274, acc=0.31111112236976624, loss=1.8753191232681274
train: epoch 140, loss 0.7941383719444275, acc=0.7070555686950684, loss=0.7941383719444275
test: epoch 140, loss 1.7761932611465454, acc=0.40833333134651184, loss=1.7761932611465454
train: epoch 141, loss 0.8115792870521545, acc=0.6917222142219543, loss=0.8115792870521545
test: epoch 141, loss 1.6629774570465088, acc=0.4027777910232544, loss=1.6629774570465088
train: epoch 142, loss 0.8076849579811096, acc=0.6921111345291138, loss=0.8076849579811096
test: epoch 142, loss 1.9916914701461792, acc=0.2750000059604645, loss=1.9916914701461792
train: epoch 143, loss 0.7866479158401489, acc=0.6931111216545105, loss=0.7866479158401489
test: epoch 143, loss 1.955474615097046, acc=0.3027777671813965, loss=1.955474615097046
train: epoch 144, loss 0.7784467339515686, acc=0.7067777514457703, loss=0.7784467339515686
test: epoch 144, loss 1.624815583229065, acc=0.35555556416511536, loss=1.624815583229065
train: epoch 145, loss 0.7768698930740356, acc=0.7003333568572998, loss=0.7768698930740356
test: epoch 145, loss 1.6038198471069336, acc=0.5, loss=1.6038198471069336
train: epoch 146, loss 0.7910552620887756, acc=0.700166642665863, loss=0.7910552620887756
test: epoch 146, loss 1.7608517408370972, acc=0.3638888895511627, loss=1.7608517408370972
train: epoch 147, loss 0.7837303876876831, acc=0.6993333101272583, loss=0.7837303876876831
test: epoch 147, loss 1.6913361549377441, acc=0.3638888895511627, loss=1.6913361549377441
train: epoch 148, loss 0.7990375757217407, acc=0.6977777481079102, loss=0.7990375757217407
test: epoch 148, loss 1.832796573638916, acc=0.33888888359069824, loss=1.832796573638916
train: epoch 149, loss 0.8078093528747559, acc=0.694611132144928, loss=0.8078093528747559
test: epoch 149, loss 1.8585673570632935, acc=0.3055555522441864, loss=1.8585673570632935
train: epoch 150, loss 0.776651918888092, acc=0.7049999833106995, loss=0.776651918888092
test: epoch 150, loss 1.6137199401855469, acc=0.3305555582046509, loss=1.6137199401855469
