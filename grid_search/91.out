# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=1", "--one_hot=0", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=1572136135, receiver_embed_dim=64, save_run=0, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=1572136135, receiver_embed_dim=64, save_run=False, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.4678614139556885, acc=0.16427777707576752, loss=2.4678614139556885
test: epoch 1, loss 7.1946587562561035, acc=0.03611111268401146, loss=7.1946587562561035
train: epoch 2, loss 1.7785651683807373, acc=0.3081111013889313, loss=1.7785651683807373
test: epoch 2, loss 6.670938491821289, acc=0.04444444552063942, loss=6.670938491821289
train: epoch 3, loss 1.560019850730896, acc=0.378555566072464, loss=1.560019850730896
test: epoch 3, loss 6.543638706207275, acc=0.08055555820465088, loss=6.543638706207275
train: epoch 4, loss 1.4286986589431763, acc=0.42194443941116333, loss=1.4286986589431763
test: epoch 4, loss 7.072830677032471, acc=0.07777778059244156, loss=7.072830677032471
train: epoch 5, loss 1.3144006729125977, acc=0.4658888876438141, loss=1.3144006729125977
test: epoch 5, loss 7.2421674728393555, acc=0.10833333432674408, loss=7.2421674728393555
train: epoch 6, loss 1.2357103824615479, acc=0.500333309173584, loss=1.2357103824615479
test: epoch 6, loss 6.128300189971924, acc=0.10000000149011612, loss=6.128300189971924
train: epoch 7, loss 1.1682806015014648, acc=0.528333306312561, loss=1.1682806015014648
test: epoch 7, loss 6.78312873840332, acc=0.11388888955116272, loss=6.78312873840332
train: epoch 8, loss 1.1120911836624146, acc=0.5520555377006531, loss=1.1120911836624146
test: epoch 8, loss 7.4232401847839355, acc=0.10555555671453476, loss=7.4232401847839355
train: epoch 9, loss 1.0670329332351685, acc=0.5657777786254883, loss=1.0670329332351685
test: epoch 9, loss 7.897961616516113, acc=0.0694444477558136, loss=7.897961616516113
train: epoch 10, loss 1.023497223854065, acc=0.5967777967453003, loss=1.023497223854065
test: epoch 10, loss 7.241783618927002, acc=0.13333334028720856, loss=7.241783618927002
train: epoch 11, loss 0.9777560234069824, acc=0.6068888902664185, loss=0.9777560234069824
test: epoch 11, loss 7.562232494354248, acc=0.11388888955116272, loss=7.562232494354248
train: epoch 12, loss 0.9515100121498108, acc=0.6217222213745117, loss=0.9515100121498108
test: epoch 12, loss 6.3557891845703125, acc=0.1111111119389534, loss=6.3557891845703125
train: epoch 13, loss 0.9195610880851746, acc=0.6418889164924622, loss=0.9195610880851746
test: epoch 13, loss 7.589507579803467, acc=0.11944444477558136, loss=7.589507579803467
train: epoch 14, loss 0.8886194825172424, acc=0.6486666798591614, loss=0.8886194825172424
test: epoch 14, loss 7.529097080230713, acc=0.10000000149011612, loss=7.529097080230713
train: epoch 15, loss 0.8711588382720947, acc=0.6560555696487427, loss=0.8711588382720947
test: epoch 15, loss 6.789616107940674, acc=0.12777778506278992, loss=6.789616107940674
train: epoch 16, loss 0.826170027256012, acc=0.6781666874885559, loss=0.826170027256012
test: epoch 16, loss 7.469837188720703, acc=0.11944444477558136, loss=7.469837188720703
train: epoch 17, loss 0.8099556565284729, acc=0.6855000257492065, loss=0.8099556565284729
test: epoch 17, loss 6.928275108337402, acc=0.10277777910232544, loss=6.928275108337402
train: epoch 18, loss 0.7881426215171814, acc=0.6936666369438171, loss=0.7881426215171814
test: epoch 18, loss 6.007044315338135, acc=0.13333334028720856, loss=6.007044315338135
train: epoch 19, loss 0.7626499533653259, acc=0.7108333110809326, loss=0.7626499533653259
test: epoch 19, loss 6.573330402374268, acc=0.16111111640930176, loss=6.573330402374268
train: epoch 20, loss 0.7447485327720642, acc=0.7142221927642822, loss=0.7447485327720642
test: epoch 20, loss 6.9318037033081055, acc=0.10555555671453476, loss=6.9318037033081055
train: epoch 21, loss 0.7175828218460083, acc=0.722611129283905, loss=0.7175828218460083
test: epoch 21, loss 6.721814155578613, acc=0.13333334028720856, loss=6.721814155578613
train: epoch 22, loss 0.7022770047187805, acc=0.7304999828338623, loss=0.7022770047187805
test: epoch 22, loss 6.8367180824279785, acc=0.12222222238779068, loss=6.8367180824279785
train: epoch 23, loss 0.6859367489814758, acc=0.7363333106040955, loss=0.6859367489814758
test: epoch 23, loss 7.662067413330078, acc=0.11944444477558136, loss=7.662067413330078
train: epoch 24, loss 0.6911211609840393, acc=0.7391111254692078, loss=0.6911211609840393
test: epoch 24, loss 6.9265828132629395, acc=0.08055555820465088, loss=6.9265828132629395
train: epoch 25, loss 0.656933069229126, acc=0.7497777938842773, loss=0.656933069229126
test: epoch 25, loss 6.889437198638916, acc=0.10000000149011612, loss=6.889437198638916
train: epoch 26, loss 0.6486389636993408, acc=0.7528889179229736, loss=0.6486389636993408
test: epoch 26, loss 8.100594520568848, acc=0.12222222238779068, loss=8.100594520568848
train: epoch 27, loss 0.6313155293464661, acc=0.762333333492279, loss=0.6313155293464661
test: epoch 27, loss 5.639151096343994, acc=0.11666666716337204, loss=5.639151096343994
train: epoch 28, loss 0.6249675154685974, acc=0.7630555629730225, loss=0.6249675154685974
test: epoch 28, loss 7.911450386047363, acc=0.11666666716337204, loss=7.911450386047363
train: epoch 29, loss 0.6151431202888489, acc=0.7641111016273499, loss=0.6151431202888489
test: epoch 29, loss 6.348886013031006, acc=0.0972222238779068, loss=6.348886013031006
train: epoch 30, loss 0.5956204533576965, acc=0.7753888964653015, loss=0.5956204533576965
test: epoch 30, loss 5.541055679321289, acc=0.10555555671453476, loss=5.541055679321289
train: epoch 31, loss 0.5860334038734436, acc=0.7756111025810242, loss=0.5860334038734436
test: epoch 31, loss 6.664282321929932, acc=0.13333334028720856, loss=6.664282321929932
train: epoch 32, loss 0.5746257901191711, acc=0.7815555334091187, loss=0.5746257901191711
test: epoch 32, loss 7.222140312194824, acc=0.0972222238779068, loss=7.222140312194824
train: epoch 33, loss 0.566518247127533, acc=0.7902777791023254, loss=0.566518247127533
test: epoch 33, loss 6.558199405670166, acc=0.13055555522441864, loss=6.558199405670166
train: epoch 34, loss 0.5530675053596497, acc=0.795722246170044, loss=0.5530675053596497
test: epoch 34, loss 8.880109786987305, acc=0.15000000596046448, loss=8.880109786987305
train: epoch 35, loss 0.5486090779304504, acc=0.792555570602417, loss=0.5486090779304504
test: epoch 35, loss 7.7343831062316895, acc=0.16111111640930176, loss=7.7343831062316895
train: epoch 36, loss 0.5470379590988159, acc=0.7955555319786072, loss=0.5470379590988159
test: epoch 36, loss 8.591355323791504, acc=0.06666667014360428, loss=8.591355323791504
train: epoch 37, loss 0.5280050039291382, acc=0.7982777953147888, loss=0.5280050039291382
test: epoch 37, loss 8.127628326416016, acc=0.11388888955116272, loss=8.127628326416016
train: epoch 38, loss 0.5303901433944702, acc=0.8027222156524658, loss=0.5303901433944702
test: epoch 38, loss 5.122142314910889, acc=0.10000000149011612, loss=5.122142314910889
train: epoch 39, loss 0.5163637399673462, acc=0.8084999918937683, loss=0.5163637399673462
test: epoch 39, loss 6.587614059448242, acc=0.14444445073604584, loss=6.587614059448242
train: epoch 40, loss 0.5073650479316711, acc=0.8082777857780457, loss=0.5073650479316711
test: epoch 40, loss 6.777246475219727, acc=0.12222222238779068, loss=6.777246475219727
train: epoch 41, loss 0.50006103515625, acc=0.8119444251060486, loss=0.50006103515625
test: epoch 41, loss 8.667838096618652, acc=0.03611111268401146, loss=8.667838096618652
train: epoch 42, loss 0.48610302805900574, acc=0.8179444670677185, loss=0.48610302805900574
test: epoch 42, loss 7.8241496086120605, acc=0.0833333358168602, loss=7.8241496086120605
train: epoch 43, loss 0.49271249771118164, acc=0.8167222142219543, loss=0.49271249771118164
test: epoch 43, loss 4.765165328979492, acc=0.14722222089767456, loss=4.765165328979492
train: epoch 44, loss 0.471153199672699, acc=0.8297222256660461, loss=0.471153199672699
test: epoch 44, loss 6.135145664215088, acc=0.10277777910232544, loss=6.135145664215088
train: epoch 45, loss 0.4872298836708069, acc=0.8204444646835327, loss=0.4872298836708069
test: epoch 45, loss 5.72664737701416, acc=0.11944444477558136, loss=5.72664737701416
train: epoch 46, loss 0.47869136929512024, acc=0.8256111145019531, loss=0.47869136929512024
test: epoch 46, loss 5.669159889221191, acc=0.1527777761220932, loss=5.669159889221191
train: epoch 47, loss 0.46931737661361694, acc=0.828166663646698, loss=0.46931737661361694
test: epoch 47, loss 6.462399959564209, acc=0.1388888955116272, loss=6.462399959564209
train: epoch 48, loss 0.45792433619499207, acc=0.832611083984375, loss=0.45792433619499207
test: epoch 48, loss 5.837292671203613, acc=0.14444445073604584, loss=5.837292671203613
train: epoch 49, loss 0.46677011251449585, acc=0.8253333568572998, loss=0.46677011251449585
test: epoch 49, loss 5.527047634124756, acc=0.125, loss=5.527047634124756
train: epoch 50, loss 0.4352477490901947, acc=0.8371111154556274, loss=0.4352477490901947
test: epoch 50, loss 5.880871772766113, acc=0.17499999701976776, loss=5.880871772766113
train: epoch 51, loss 0.4563848674297333, acc=0.8342777490615845, loss=0.4563848674297333
test: epoch 51, loss 6.262637615203857, acc=0.12777778506278992, loss=6.262637615203857
train: epoch 52, loss 0.43679890036582947, acc=0.8370000123977661, loss=0.43679890036582947
test: epoch 52, loss 5.603032112121582, acc=0.10555555671453476, loss=5.603032112121582
train: epoch 53, loss 0.4396090805530548, acc=0.8411111235618591, loss=0.4396090805530548
test: epoch 53, loss 8.197413444519043, acc=0.13611111044883728, loss=8.197413444519043
train: epoch 54, loss 0.42300426959991455, acc=0.844944417476654, loss=0.42300426959991455
test: epoch 54, loss 7.623510837554932, acc=0.07222222536802292, loss=7.623510837554932
train: epoch 55, loss 0.42663249373435974, acc=0.8437777757644653, loss=0.42663249373435974
test: epoch 55, loss 7.300439834594727, acc=0.125, loss=7.300439834594727
train: epoch 56, loss 0.4284781515598297, acc=0.8383333086967468, loss=0.4284781515598297
test: epoch 56, loss 6.854940414428711, acc=0.10555555671453476, loss=6.854940414428711
train: epoch 57, loss 0.4264266788959503, acc=0.8383333086967468, loss=0.4264266788959503
test: epoch 57, loss 5.938826084136963, acc=0.10555555671453476, loss=5.938826084136963
train: epoch 58, loss 0.40261605381965637, acc=0.8489999771118164, loss=0.40261605381965637
test: epoch 58, loss 5.448488712310791, acc=0.09166666865348816, loss=5.448488712310791
train: epoch 59, loss 0.411912739276886, acc=0.8512222170829773, loss=0.411912739276886
test: epoch 59, loss 6.0011749267578125, acc=0.10277777910232544, loss=6.0011749267578125
train: epoch 60, loss 0.408026784658432, acc=0.8453333377838135, loss=0.408026784658432
test: epoch 60, loss 6.076535701751709, acc=0.13055555522441864, loss=6.076535701751709
train: epoch 61, loss 0.4062485992908478, acc=0.8501111268997192, loss=0.4062485992908478
test: epoch 61, loss 6.293344497680664, acc=0.08055555820465088, loss=6.293344497680664
train: epoch 62, loss 0.3894795775413513, acc=0.8544999957084656, loss=0.3894795775413513
test: epoch 62, loss 6.135100841522217, acc=0.125, loss=6.135100841522217
train: epoch 63, loss 0.3888944089412689, acc=0.8551111221313477, loss=0.3888944089412689
test: epoch 63, loss 4.124727725982666, acc=0.14444445073604584, loss=4.124727725982666
train: epoch 64, loss 0.3951442539691925, acc=0.8562777638435364, loss=0.3951442539691925
test: epoch 64, loss 5.289849758148193, acc=0.13333334028720856, loss=5.289849758148193
train: epoch 65, loss 0.39333218336105347, acc=0.8575555682182312, loss=0.39333218336105347
test: epoch 65, loss 5.317952632904053, acc=0.13055555522441864, loss=5.317952632904053
train: epoch 66, loss 0.37464720010757446, acc=0.8638888597488403, loss=0.37464720010757446
test: epoch 66, loss 7.713667869567871, acc=0.1111111119389534, loss=7.713667869567871
train: epoch 67, loss 0.3745517432689667, acc=0.8636666536331177, loss=0.3745517432689667
test: epoch 67, loss 7.929351329803467, acc=0.11388888955116272, loss=7.929351329803467
train: epoch 68, loss 0.3661072552204132, acc=0.8673333525657654, loss=0.3661072552204132
test: epoch 68, loss 5.8010334968566895, acc=0.11388888955116272, loss=5.8010334968566895
train: epoch 69, loss 0.36754488945007324, acc=0.8674444556236267, loss=0.36754488945007324
test: epoch 69, loss 7.663951396942139, acc=0.07500000298023224, loss=7.663951396942139
train: epoch 70, loss 0.3581602871417999, acc=0.8679444193840027, loss=0.3581602871417999
test: epoch 70, loss 7.691534042358398, acc=0.06111111119389534, loss=7.691534042358398
train: epoch 71, loss 0.36259520053863525, acc=0.8684999942779541, loss=0.36259520053863525
test: epoch 71, loss 4.526098251342773, acc=0.0972222238779068, loss=4.526098251342773
train: epoch 72, loss 0.36824363470077515, acc=0.8653333187103271, loss=0.36824363470077515
test: epoch 72, loss 6.219464302062988, acc=0.14166666567325592, loss=6.219464302062988
train: epoch 73, loss 0.36392804980278015, acc=0.8661666512489319, loss=0.36392804980278015
test: epoch 73, loss 7.8490095138549805, acc=0.11666666716337204, loss=7.8490095138549805
train: epoch 74, loss 0.33766937255859375, acc=0.8774999976158142, loss=0.33766937255859375
test: epoch 74, loss 6.271986484527588, acc=0.09166666865348816, loss=6.271986484527588
train: epoch 75, loss 0.34872499108314514, acc=0.8750555515289307, loss=0.34872499108314514
test: epoch 75, loss 6.989085674285889, acc=0.0833333358168602, loss=6.989085674285889
train: epoch 76, loss 0.34727415442466736, acc=0.8741666674613953, loss=0.34727415442466736
test: epoch 76, loss 6.200008392333984, acc=0.12777778506278992, loss=6.200008392333984
train: epoch 77, loss 0.33175209164619446, acc=0.8798888921737671, loss=0.33175209164619446
test: epoch 77, loss 5.791649341583252, acc=0.1527777761220932, loss=5.791649341583252
train: epoch 78, loss 0.344994455575943, acc=0.8737778067588806, loss=0.344994455575943
test: epoch 78, loss 6.135701656341553, acc=0.125, loss=6.135701656341553
train: epoch 79, loss 0.35492682456970215, acc=0.871666669845581, loss=0.35492682456970215
test: epoch 79, loss 4.6653923988342285, acc=0.14722222089767456, loss=4.6653923988342285
train: epoch 80, loss 0.33479824662208557, acc=0.8813889026641846, loss=0.33479824662208557
test: epoch 80, loss 5.17177152633667, acc=0.14722222089767456, loss=5.17177152633667
train: epoch 81, loss 0.33198511600494385, acc=0.8805000185966492, loss=0.33198511600494385
test: epoch 81, loss 5.971380710601807, acc=0.06111111119389534, loss=5.971380710601807
train: epoch 82, loss 0.3261493444442749, acc=0.8813889026641846, loss=0.3261493444442749
test: epoch 82, loss 7.297752857208252, acc=0.0416666679084301, loss=7.297752857208252
train: epoch 83, loss 0.30548474192619324, acc=0.8906111121177673, loss=0.30548474192619324
test: epoch 83, loss 6.789215087890625, acc=0.0833333358168602, loss=6.789215087890625
train: epoch 84, loss 0.3197599947452545, acc=0.88355553150177, loss=0.3197599947452545
test: epoch 84, loss 6.548217296600342, acc=0.0972222238779068, loss=6.548217296600342
train: epoch 85, loss 0.3053557574748993, acc=0.8857222199440002, loss=0.3053557574748993
test: epoch 85, loss 7.034582614898682, acc=0.1111111119389534, loss=7.034582614898682
train: epoch 86, loss 0.32224926352500916, acc=0.8855000138282776, loss=0.32224926352500916
test: epoch 86, loss 4.920907497406006, acc=0.16111111640930176, loss=4.920907497406006
train: epoch 87, loss 0.3355582058429718, acc=0.882444441318512, loss=0.3355582058429718
test: epoch 87, loss 4.794968605041504, acc=0.16111111640930176, loss=4.794968605041504
train: epoch 88, loss 0.2996078133583069, acc=0.8946666717529297, loss=0.2996078133583069
test: epoch 88, loss 6.406792640686035, acc=0.18888889253139496, loss=6.406792640686035
train: epoch 89, loss 0.30633798241615295, acc=0.8899999856948853, loss=0.30633798241615295
test: epoch 89, loss 4.843320369720459, acc=0.14166666567325592, loss=4.843320369720459
train: epoch 90, loss 0.29845285415649414, acc=0.8918889164924622, loss=0.29845285415649414
test: epoch 90, loss 5.900868892669678, acc=0.13055555522441864, loss=5.900868892669678
train: epoch 91, loss 0.300528883934021, acc=0.8973333239555359, loss=0.300528883934021
test: epoch 91, loss 6.160441875457764, acc=0.09166666865348816, loss=6.160441875457764
train: epoch 92, loss 0.30096855759620667, acc=0.8927778005599976, loss=0.30096855759620667
test: epoch 92, loss 3.802518367767334, acc=0.15555556118488312, loss=3.802518367767334
train: epoch 93, loss 0.2989872395992279, acc=0.8938888907432556, loss=0.2989872395992279
test: epoch 93, loss 4.349157810211182, acc=0.18333333730697632, loss=4.349157810211182
train: epoch 94, loss 0.29854416847229004, acc=0.8974444270133972, loss=0.29854416847229004
test: epoch 94, loss 6.529956340789795, acc=0.12777778506278992, loss=6.529956340789795
train: epoch 95, loss 0.2891389727592468, acc=0.898722231388092, loss=0.2891389727592468
test: epoch 95, loss 6.651889324188232, acc=0.16944444179534912, loss=6.651889324188232
train: epoch 96, loss 0.29394957423210144, acc=0.8940555453300476, loss=0.29394957423210144
test: epoch 96, loss 5.165144920349121, acc=0.1388888955116272, loss=5.165144920349121
train: epoch 97, loss 0.2750518023967743, acc=0.8987777829170227, loss=0.2750518023967743
test: epoch 97, loss 6.2275471687316895, acc=0.15000000596046448, loss=6.2275471687316895
train: epoch 98, loss 0.2657584846019745, acc=0.902055561542511, loss=0.2657584846019745
test: epoch 98, loss 4.036046028137207, acc=0.12222222238779068, loss=4.036046028137207
train: epoch 99, loss 0.27063488960266113, acc=0.9047222137451172, loss=0.27063488960266113
test: epoch 99, loss 7.392127990722656, acc=0.10277777910232544, loss=7.392127990722656
train: epoch 100, loss 0.29267069697380066, acc=0.8978333473205566, loss=0.29267069697380066
test: epoch 100, loss 6.066277503967285, acc=0.21388888359069824, loss=6.066277503967285
train: epoch 101, loss 0.26562806963920593, acc=0.906499981880188, loss=0.26562806963920593
test: epoch 101, loss 6.3231987953186035, acc=0.16944444179534912, loss=6.3231987953186035
train: epoch 102, loss 0.27485936880111694, acc=0.9034444689750671, loss=0.27485936880111694
test: epoch 102, loss 4.892543792724609, acc=0.14444445073604584, loss=4.892543792724609
train: epoch 103, loss 0.27142295241355896, acc=0.9046666622161865, loss=0.27142295241355896
test: epoch 103, loss 5.10556173324585, acc=0.18611110746860504, loss=5.10556173324585
train: epoch 104, loss 0.2696467638015747, acc=0.9048888683319092, loss=0.2696467638015747
test: epoch 104, loss 6.410459518432617, acc=0.0972222238779068, loss=6.410459518432617
train: epoch 105, loss 0.2751651406288147, acc=0.9042222499847412, loss=0.2751651406288147
test: epoch 105, loss 3.933389663696289, acc=0.18888889253139496, loss=3.933389663696289
train: epoch 106, loss 0.2663942873477936, acc=0.9067777991294861, loss=0.2663942873477936
test: epoch 106, loss 7.227492332458496, acc=0.1805555522441864, loss=7.227492332458496
train: epoch 107, loss 0.2702990770339966, acc=0.9069444537162781, loss=0.2702990770339966
test: epoch 107, loss 7.064036846160889, acc=0.1805555522441864, loss=7.064036846160889
train: epoch 108, loss 0.26316437125205994, acc=0.909333348274231, loss=0.26316437125205994
test: epoch 108, loss 5.939274311065674, acc=0.10555555671453476, loss=5.939274311065674
train: epoch 109, loss 0.2679579257965088, acc=0.9046666622161865, loss=0.2679579257965088
test: epoch 109, loss 4.940089225769043, acc=0.13333334028720856, loss=4.940089225769043
train: epoch 110, loss 0.2514779269695282, acc=0.9094444513320923, loss=0.2514779269695282
test: epoch 110, loss 4.691624641418457, acc=0.12222222238779068, loss=4.691624641418457
train: epoch 111, loss 0.27549904584884644, acc=0.9057777523994446, loss=0.27549904584884644
test: epoch 111, loss 6.425758361816406, acc=0.10277777910232544, loss=6.425758361816406
train: epoch 112, loss 0.24929557740688324, acc=0.9133889079093933, loss=0.24929557740688324
test: epoch 112, loss 5.0700273513793945, acc=0.1388888955116272, loss=5.0700273513793945
train: epoch 113, loss 0.24097490310668945, acc=0.9154444336891174, loss=0.24097490310668945
test: epoch 113, loss 5.389421463012695, acc=0.1666666716337204, loss=5.389421463012695
train: epoch 114, loss 0.24235546588897705, acc=0.9129999876022339, loss=0.24235546588897705
test: epoch 114, loss 6.787573337554932, acc=0.0555555559694767, loss=6.787573337554932
train: epoch 115, loss 0.246711865067482, acc=0.9139444231987, loss=0.246711865067482
test: epoch 115, loss 7.619174480438232, acc=0.10277777910232544, loss=7.619174480438232
train: epoch 116, loss 0.24234351515769958, acc=0.9135000109672546, loss=0.24234351515769958
test: epoch 116, loss 5.6531453132629395, acc=0.15833333134651184, loss=5.6531453132629395
train: epoch 117, loss 0.23023079335689545, acc=0.9200000166893005, loss=0.23023079335689545
test: epoch 117, loss 6.18643045425415, acc=0.02777777798473835, loss=6.18643045425415
train: epoch 118, loss 0.24566864967346191, acc=0.9147777557373047, loss=0.24566864967346191
test: epoch 118, loss 4.536030292510986, acc=0.20000000298023224, loss=4.536030292510986
train: epoch 119, loss 0.2600192725658417, acc=0.9120000004768372, loss=0.2600192725658417
test: epoch 119, loss 5.7333879470825195, acc=0.18333333730697632, loss=5.7333879470825195
train: epoch 120, loss 0.23156915605068207, acc=0.9183333516120911, loss=0.23156915605068207
test: epoch 120, loss 6.3697590827941895, acc=0.12777778506278992, loss=6.3697590827941895
train: epoch 121, loss 0.22851422429084778, acc=0.918666660785675, loss=0.22851422429084778
test: epoch 121, loss 5.111714839935303, acc=0.16111111640930176, loss=5.111714839935303
train: epoch 122, loss 0.22107143700122833, acc=0.9237777590751648, loss=0.22107143700122833
test: epoch 122, loss 4.848578453063965, acc=0.1666666716337204, loss=4.848578453063965
train: epoch 123, loss 0.23271629214286804, acc=0.9178333282470703, loss=0.23271629214286804
test: epoch 123, loss 7.9004597663879395, acc=0.13333334028720856, loss=7.9004597663879395
train: epoch 124, loss 0.2306041568517685, acc=0.9164999723434448, loss=0.2306041568517685
test: epoch 124, loss 4.190978527069092, acc=0.2083333283662796, loss=4.190978527069092
train: epoch 125, loss 0.22110949456691742, acc=0.9201111197471619, loss=0.22110949456691742
test: epoch 125, loss 7.766129016876221, acc=0.07777778059244156, loss=7.766129016876221
train: epoch 126, loss 0.23477447032928467, acc=0.918666660785675, loss=0.23477447032928467
test: epoch 126, loss 6.863248348236084, acc=0.13611111044883728, loss=6.863248348236084
train: epoch 127, loss 0.2117876410484314, acc=0.9268333315849304, loss=0.2117876410484314
test: epoch 127, loss 4.830221652984619, acc=0.16944444179534912, loss=4.830221652984619
train: epoch 128, loss 0.21132580935955048, acc=0.9250555634498596, loss=0.21132580935955048
test: epoch 128, loss 8.747538566589355, acc=0.13611111044883728, loss=8.747538566589355
train: epoch 129, loss 0.23916277289390564, acc=0.9179999828338623, loss=0.23916277289390564
test: epoch 129, loss 5.5937910079956055, acc=0.11944444477558136, loss=5.5937910079956055
train: epoch 130, loss 0.2234530746936798, acc=0.9231666922569275, loss=0.2234530746936798
test: epoch 130, loss 7.830894947052002, acc=0.14722222089767456, loss=7.830894947052002
train: epoch 131, loss 0.23039937019348145, acc=0.9206110835075378, loss=0.23039937019348145
test: epoch 131, loss 4.903103351593018, acc=0.1666666716337204, loss=4.903103351593018
train: epoch 132, loss 0.2177230715751648, acc=0.9240555763244629, loss=0.2177230715751648
test: epoch 132, loss 6.589673042297363, acc=0.11944444477558136, loss=6.589673042297363
train: epoch 133, loss 0.21011579036712646, acc=0.9266111254692078, loss=0.21011579036712646
test: epoch 133, loss 6.433924674987793, acc=0.09444444626569748, loss=6.433924674987793
train: epoch 134, loss 0.22638265788555145, acc=0.9223333597183228, loss=0.22638265788555145
test: epoch 134, loss 5.422120094299316, acc=0.17777778208255768, loss=5.422120094299316
train: epoch 135, loss 0.22868098318576813, acc=0.9208889007568359, loss=0.22868098318576813
test: epoch 135, loss 6.3008551597595215, acc=0.17222222685813904, loss=6.3008551597595215
train: epoch 136, loss 0.21280695497989655, acc=0.9268888831138611, loss=0.21280695497989655
test: epoch 136, loss 6.946022033691406, acc=0.08611111342906952, loss=6.946022033691406
train: epoch 137, loss 0.2141796350479126, acc=0.9252222180366516, loss=0.2141796350479126
test: epoch 137, loss 4.904768466949463, acc=0.22499999403953552, loss=4.904768466949463
train: epoch 138, loss 0.2070665806531906, acc=0.9258888959884644, loss=0.2070665806531906
test: epoch 138, loss 8.17648696899414, acc=0.125, loss=8.17648696899414
train: epoch 139, loss 0.2120417207479477, acc=0.9272778034210205, loss=0.2120417207479477
test: epoch 139, loss 5.423130512237549, acc=0.15833333134651184, loss=5.423130512237549
train: epoch 140, loss 0.20722271502017975, acc=0.9283333420753479, loss=0.20722271502017975
test: epoch 140, loss 7.9562811851501465, acc=0.13055555522441864, loss=7.9562811851501465
train: epoch 141, loss 0.21409083902835846, acc=0.9272778034210205, loss=0.21409083902835846
test: epoch 141, loss 7.608489036560059, acc=0.13333334028720856, loss=7.608489036560059
train: epoch 142, loss 0.20637936890125275, acc=0.929111123085022, loss=0.20637936890125275
test: epoch 142, loss 7.7101359367370605, acc=0.13333334028720856, loss=7.7101359367370605
train: epoch 143, loss 0.214462548494339, acc=0.9276111125946045, loss=0.214462548494339
test: epoch 143, loss 5.884685039520264, acc=0.10000000149011612, loss=5.884685039520264
train: epoch 144, loss 0.20108351111412048, acc=0.9298333525657654, loss=0.20108351111412048
test: epoch 144, loss 5.55185079574585, acc=0.16388888657093048, loss=5.55185079574585
train: epoch 145, loss 0.20946532487869263, acc=0.9268888831138611, loss=0.20946532487869263
test: epoch 145, loss 4.464999675750732, acc=0.23333333432674408, loss=4.464999675750732
train: epoch 146, loss 0.21640895307064056, acc=0.929277777671814, loss=0.21640895307064056
test: epoch 146, loss 5.212202548980713, acc=0.11666666716337204, loss=5.212202548980713
train: epoch 147, loss 0.1994575709104538, acc=0.9303333163261414, loss=0.1994575709104538
test: epoch 147, loss 5.943044185638428, acc=0.19722221791744232, loss=5.943044185638428
train: epoch 148, loss 0.20207107067108154, acc=0.9314444661140442, loss=0.20207107067108154
test: epoch 148, loss 7.640542984008789, acc=0.16944444179534912, loss=7.640542984008789
train: epoch 149, loss 0.2024604231119156, acc=0.9301666617393494, loss=0.2024604231119156
test: epoch 149, loss 8.139779090881348, acc=0.0833333358168602, loss=8.139779090881348
train: epoch 150, loss 0.19454218447208405, acc=0.9346110820770264, loss=0.19454218447208405
test: epoch 150, loss 7.43613862991333, acc=0.16388888657093048, loss=7.43613862991333
