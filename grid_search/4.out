# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=1", "--temp_decay=1", "--one_hot=1", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=882164781, receiver_embed_dim=32, save_run=0, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=882164781, receiver_embed_dim=32, save_run=False, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.480266571044922, acc=0.046888887882232666, loss=3.480266571044922
test: epoch 1, loss 3.7698192596435547, acc=0.05277777835726738, loss=3.7698192596435547
train: epoch 2, loss 3.1074323654174805, acc=0.07855555415153503, loss=3.1074323654174805
test: epoch 2, loss 3.4096198081970215, acc=0.0694444477558136, loss=3.4096198081970215
train: epoch 3, loss 2.505117177963257, acc=0.17550000548362732, loss=2.505117177963257
test: epoch 3, loss 2.6474392414093018, acc=0.13055555522441864, loss=2.6474392414093018
train: epoch 4, loss 2.0423061847686768, acc=0.2597222328186035, loss=2.0423061847686768
test: epoch 4, loss 2.5128862857818604, acc=0.14444445073604584, loss=2.5128862857818604
train: epoch 5, loss 1.8545268774032593, acc=0.3018333315849304, loss=1.8545268774032593
test: epoch 5, loss 2.435645580291748, acc=0.14166666567325592, loss=2.435645580291748
train: epoch 6, loss 1.7610328197479248, acc=0.32544443011283875, loss=1.7610328197479248
test: epoch 6, loss 2.4471144676208496, acc=0.15000000596046448, loss=2.4471144676208496
train: epoch 7, loss 1.691529393196106, acc=0.3469444513320923, loss=1.691529393196106
test: epoch 7, loss 2.4442667961120605, acc=0.1388888955116272, loss=2.4442667961120605
train: epoch 8, loss 1.6346515417099, acc=0.362888902425766, loss=1.6346515417099
test: epoch 8, loss 2.2931244373321533, acc=0.16388888657093048, loss=2.2931244373321533
train: epoch 9, loss 1.5718460083007812, acc=0.38322222232818604, loss=1.5718460083007812
test: epoch 9, loss 2.3036508560180664, acc=0.18611110746860504, loss=2.3036508560180664
train: epoch 10, loss 1.5241122245788574, acc=0.39838889241218567, loss=1.5241122245788574
test: epoch 10, loss 2.1371448040008545, acc=0.19166666269302368, loss=2.1371448040008545
train: epoch 11, loss 1.4599984884262085, acc=0.41322222352027893, loss=1.4599984884262085
test: epoch 11, loss 2.093024969100952, acc=0.18611110746860504, loss=2.093024969100952
train: epoch 12, loss 1.4293278455734253, acc=0.4266666769981384, loss=1.4293278455734253
test: epoch 12, loss 2.1193976402282715, acc=0.18333333730697632, loss=2.1193976402282715
train: epoch 13, loss 1.3851268291473389, acc=0.44749999046325684, loss=1.3851268291473389
test: epoch 13, loss 2.149764060974121, acc=0.19166666269302368, loss=2.149764060974121
train: epoch 14, loss 1.359063982963562, acc=0.4483333230018616, loss=1.359063982963562
test: epoch 14, loss 2.195587635040283, acc=0.19722221791744232, loss=2.195587635040283
train: epoch 15, loss 1.3201336860656738, acc=0.46916666626930237, loss=1.3201336860656738
test: epoch 15, loss 2.1322383880615234, acc=0.1944444477558136, loss=2.1322383880615234
train: epoch 16, loss 1.2975778579711914, acc=0.47966668009757996, loss=1.2975778579711914
test: epoch 16, loss 2.1159911155700684, acc=0.21388888359069824, loss=2.1159911155700684
train: epoch 17, loss 1.25959050655365, acc=0.4875555634498596, loss=1.25959050655365
test: epoch 17, loss 2.0425376892089844, acc=0.23888888955116272, loss=2.0425376892089844
train: epoch 18, loss 1.2313896417617798, acc=0.5040000081062317, loss=1.2313896417617798
test: epoch 18, loss 1.9982287883758545, acc=0.23055554926395416, loss=1.9982287883758545
train: epoch 19, loss 1.2073907852172852, acc=0.5130555629730225, loss=1.2073907852172852
test: epoch 19, loss 2.088564872741699, acc=0.23333333432674408, loss=2.088564872741699
train: epoch 20, loss 1.1930840015411377, acc=0.5122777819633484, loss=1.1930840015411377
test: epoch 20, loss 1.9616365432739258, acc=0.2361111044883728, loss=1.9616365432739258
train: epoch 21, loss 1.1565704345703125, acc=0.5306666493415833, loss=1.1565704345703125
test: epoch 21, loss 1.8732069730758667, acc=0.24722221493721008, loss=1.8732069730758667
train: epoch 22, loss 1.1308335065841675, acc=0.5419999957084656, loss=1.1308335065841675
test: epoch 22, loss 1.9483387470245361, acc=0.2361111044883728, loss=1.9483387470245361
train: epoch 23, loss 1.1260610818862915, acc=0.5452222228050232, loss=1.1260610818862915
test: epoch 23, loss 1.8950040340423584, acc=0.24444444477558136, loss=1.8950040340423584
train: epoch 24, loss 1.0941085815429688, acc=0.5568333268165588, loss=1.0941085815429688
test: epoch 24, loss 2.041555166244507, acc=0.23888888955116272, loss=2.041555166244507
train: epoch 25, loss 1.080639362335205, acc=0.5638333559036255, loss=1.080639362335205
test: epoch 25, loss 1.9143096208572388, acc=0.25833332538604736, loss=1.9143096208572388
train: epoch 26, loss 1.0749881267547607, acc=0.5684999823570251, loss=1.0749881267547607
test: epoch 26, loss 1.8970893621444702, acc=0.2361111044883728, loss=1.8970893621444702
train: epoch 27, loss 1.046114206314087, acc=0.5718333125114441, loss=1.046114206314087
test: epoch 27, loss 1.953238606452942, acc=0.23888888955116272, loss=1.953238606452942
train: epoch 28, loss 1.0284409523010254, acc=0.582444429397583, loss=1.0284409523010254
test: epoch 28, loss 1.8870724439620972, acc=0.24722221493721008, loss=1.8870724439620972
train: epoch 29, loss 1.0151914358139038, acc=0.5881666541099548, loss=1.0151914358139038
test: epoch 29, loss 1.944785237312317, acc=0.24722221493721008, loss=1.944785237312317
train: epoch 30, loss 0.9890021085739136, acc=0.5971666574478149, loss=0.9890021085739136
test: epoch 30, loss 1.9018863439559937, acc=0.2611111104488373, loss=1.9018863439559937
train: epoch 31, loss 0.9793095588684082, acc=0.6032778024673462, loss=0.9793095588684082
test: epoch 31, loss 1.860758662223816, acc=0.2527777850627899, loss=1.860758662223816
train: epoch 32, loss 0.9714657068252563, acc=0.6044444441795349, loss=0.9714657068252563
test: epoch 32, loss 1.8956948518753052, acc=0.2638888955116272, loss=1.8956948518753052
train: epoch 33, loss 0.9518439173698425, acc=0.6151666641235352, loss=0.9518439173698425
test: epoch 33, loss 1.9639561176300049, acc=0.2527777850627899, loss=1.9639561176300049
train: epoch 34, loss 0.9368129968643188, acc=0.6163889169692993, loss=0.9368129968643188
test: epoch 34, loss 1.8859421014785767, acc=0.26944443583488464, loss=1.8859421014785767
train: epoch 35, loss 0.9165554046630859, acc=0.6296666860580444, loss=0.9165554046630859
test: epoch 35, loss 1.7923792600631714, acc=0.2750000059604645, loss=1.7923792600631714
train: epoch 36, loss 0.924171507358551, acc=0.6232777833938599, loss=0.924171507358551
test: epoch 36, loss 1.8994303941726685, acc=0.2750000059604645, loss=1.8994303941726685
train: epoch 37, loss 0.8928079009056091, acc=0.6313889026641846, loss=0.8928079009056091
test: epoch 37, loss 1.8177534341812134, acc=0.2888889014720917, loss=1.8177534341812134
train: epoch 38, loss 0.8855043649673462, acc=0.6316111087799072, loss=0.8855043649673462
test: epoch 38, loss 1.8932225704193115, acc=0.28333333134651184, loss=1.8932225704193115
train: epoch 39, loss 0.8842665553092957, acc=0.6397777795791626, loss=0.8842665553092957
test: epoch 39, loss 1.8485456705093384, acc=0.31111112236976624, loss=1.8485456705093384
train: epoch 40, loss 0.8597728610038757, acc=0.6442777514457703, loss=0.8597728610038757
test: epoch 40, loss 1.8519668579101562, acc=0.3027777671813965, loss=1.8519668579101562
train: epoch 41, loss 0.8443890810012817, acc=0.652222216129303, loss=0.8443890810012817
test: epoch 41, loss 1.786710500717163, acc=0.31111112236976624, loss=1.786710500717163
train: epoch 42, loss 0.8277959227561951, acc=0.6537222266197205, loss=0.8277959227561951
test: epoch 42, loss 1.896733283996582, acc=0.29722222685813904, loss=1.896733283996582
train: epoch 43, loss 0.8260939717292786, acc=0.6613333225250244, loss=0.8260939717292786
test: epoch 43, loss 1.705153465270996, acc=0.3083333373069763, loss=1.705153465270996
train: epoch 44, loss 0.8200795650482178, acc=0.6614444255828857, loss=0.8200795650482178
test: epoch 44, loss 1.7536873817443848, acc=0.3194444477558136, loss=1.7536873817443848
train: epoch 45, loss 0.806769609451294, acc=0.663777768611908, loss=0.806769609451294
test: epoch 45, loss 1.7591158151626587, acc=0.3361110985279083, loss=1.7591158151626587
train: epoch 46, loss 0.7996214628219604, acc=0.6709444522857666, loss=0.7996214628219604
test: epoch 46, loss 1.818155288696289, acc=0.33888888359069824, loss=1.818155288696289
train: epoch 47, loss 0.7979338765144348, acc=0.6731111407279968, loss=0.7979338765144348
test: epoch 47, loss 1.7640268802642822, acc=0.3222222328186035, loss=1.7640268802642822
train: epoch 48, loss 0.7801123261451721, acc=0.6815555691719055, loss=0.7801123261451721
test: epoch 48, loss 1.6745800971984863, acc=0.33888888359069824, loss=1.6745800971984863
train: epoch 49, loss 0.7667608857154846, acc=0.6852222084999084, loss=0.7667608857154846
test: epoch 49, loss 1.7022675275802612, acc=0.3583333194255829, loss=1.7022675275802612
train: epoch 50, loss 0.7550001740455627, acc=0.6906111240386963, loss=0.7550001740455627
test: epoch 50, loss 1.692318081855774, acc=0.3444444537162781, loss=1.692318081855774
train: epoch 51, loss 0.7562521696090698, acc=0.6894999742507935, loss=0.7562521696090698
test: epoch 51, loss 1.6771565675735474, acc=0.3472222089767456, loss=1.6771565675735474
train: epoch 52, loss 0.7396929264068604, acc=0.6963889002799988, loss=0.7396929264068604
test: epoch 52, loss 1.6254215240478516, acc=0.33888888359069824, loss=1.6254215240478516
train: epoch 53, loss 0.7275637984275818, acc=0.7016111016273499, loss=0.7275637984275818
test: epoch 53, loss 1.7104054689407349, acc=0.36666667461395264, loss=1.7104054689407349
train: epoch 54, loss 0.7154834866523743, acc=0.7064444422721863, loss=0.7154834866523743
test: epoch 54, loss 1.6370623111724854, acc=0.35277777910232544, loss=1.6370623111724854
train: epoch 55, loss 0.7209557890892029, acc=0.7026666402816772, loss=0.7209557890892029
test: epoch 55, loss 1.6765809059143066, acc=0.36944442987442017, loss=1.6765809059143066
train: epoch 56, loss 0.6995027661323547, acc=0.706944465637207, loss=0.6995027661323547
test: epoch 56, loss 1.6560708284378052, acc=0.36666667461395264, loss=1.6560708284378052
train: epoch 57, loss 0.6889083385467529, acc=0.7120000123977661, loss=0.6889083385467529
test: epoch 57, loss 1.7232319116592407, acc=0.3888888955116272, loss=1.7232319116592407
train: epoch 58, loss 0.671728253364563, acc=0.7208333611488342, loss=0.671728253364563
test: epoch 58, loss 1.6008226871490479, acc=0.3916666805744171, loss=1.6008226871490479
train: epoch 59, loss 0.6676649451255798, acc=0.7222777605056763, loss=0.6676649451255798
test: epoch 59, loss 1.6947455406188965, acc=0.36944442987442017, loss=1.6947455406188965
train: epoch 60, loss 0.6788194179534912, acc=0.7173888683319092, loss=0.6788194179534912
test: epoch 60, loss 1.530759334564209, acc=0.375, loss=1.530759334564209
train: epoch 61, loss 0.673062801361084, acc=0.7260000109672546, loss=0.673062801361084
test: epoch 61, loss 1.6297333240509033, acc=0.4027777910232544, loss=1.6297333240509033
train: epoch 62, loss 0.6491998434066772, acc=0.7286111116409302, loss=0.6491998434066772
test: epoch 62, loss 1.5778133869171143, acc=0.4000000059604645, loss=1.5778133869171143
train: epoch 63, loss 0.6452879905700684, acc=0.7314444184303284, loss=0.6452879905700684
test: epoch 63, loss 1.5439441204071045, acc=0.4166666567325592, loss=1.5439441204071045
train: epoch 64, loss 0.6361027956008911, acc=0.7357222437858582, loss=0.6361027956008911
test: epoch 64, loss 1.6074738502502441, acc=0.40833333134651184, loss=1.6074738502502441
train: epoch 65, loss 0.6230528354644775, acc=0.7356666922569275, loss=0.6230528354644775
test: epoch 65, loss 1.5689966678619385, acc=0.4166666567325592, loss=1.5689966678619385
train: epoch 66, loss 0.6226188540458679, acc=0.738111138343811, loss=0.6226188540458679
test: epoch 66, loss 1.6244744062423706, acc=0.3861111104488373, loss=1.6244744062423706
train: epoch 67, loss 0.6280044913291931, acc=0.7326666712760925, loss=0.6280044913291931
test: epoch 67, loss 1.6907925605773926, acc=0.4055555462837219, loss=1.6907925605773926
train: epoch 68, loss 0.6099051237106323, acc=0.7405555844306946, loss=0.6099051237106323
test: epoch 68, loss 1.6075453758239746, acc=0.40833333134651184, loss=1.6075453758239746
train: epoch 69, loss 0.6162210702896118, acc=0.7418888807296753, loss=0.6162210702896118
test: epoch 69, loss 1.5371270179748535, acc=0.4166666567325592, loss=1.5371270179748535
train: epoch 70, loss 0.5957614779472351, acc=0.7443333268165588, loss=0.5957614779472351
test: epoch 70, loss 1.6127768754959106, acc=0.40833333134651184, loss=1.6127768754959106
train: epoch 71, loss 0.5756669640541077, acc=0.7515000104904175, loss=0.5756669640541077
test: epoch 71, loss 1.6628658771514893, acc=0.3916666805744171, loss=1.6628658771514893
train: epoch 72, loss 0.5843276977539062, acc=0.7494444251060486, loss=0.5843276977539062
test: epoch 72, loss 1.6730611324310303, acc=0.4027777910232544, loss=1.6730611324310303
train: epoch 73, loss 0.5762403011322021, acc=0.7522222399711609, loss=0.5762403011322021
test: epoch 73, loss 1.5895745754241943, acc=0.4194444417953491, loss=1.5895745754241943
train: epoch 74, loss 0.5761574506759644, acc=0.7548333406448364, loss=0.5761574506759644
test: epoch 74, loss 1.5599100589752197, acc=0.42222222685813904, loss=1.5599100589752197
train: epoch 75, loss 0.5635896921157837, acc=0.7562222480773926, loss=0.5635896921157837
test: epoch 75, loss 1.6460931301116943, acc=0.42500001192092896, loss=1.6460931301116943
train: epoch 76, loss 0.5656068325042725, acc=0.7622222304344177, loss=0.5656068325042725
test: epoch 76, loss 1.60807466506958, acc=0.39444443583488464, loss=1.60807466506958
train: epoch 77, loss 0.5703451633453369, acc=0.7545555830001831, loss=0.5703451633453369
test: epoch 77, loss 1.6746894121170044, acc=0.4333333373069763, loss=1.6746894121170044
train: epoch 78, loss 0.5639223456382751, acc=0.7630555629730225, loss=0.5639223456382751
test: epoch 78, loss 1.6109918355941772, acc=0.4305555522441864, loss=1.6109918355941772
train: epoch 79, loss 0.5407878756523132, acc=0.7634999752044678, loss=0.5407878756523132
test: epoch 79, loss 1.7114149332046509, acc=0.4305555522441864, loss=1.7114149332046509
train: epoch 80, loss 0.5546585917472839, acc=0.7592222094535828, loss=0.5546585917472839
test: epoch 80, loss 1.6728459596633911, acc=0.4000000059604645, loss=1.6728459596633911
train: epoch 81, loss 0.5467692017555237, acc=0.7617777585983276, loss=0.5467692017555237
test: epoch 81, loss 1.5845832824707031, acc=0.42500001192092896, loss=1.5845832824707031
train: epoch 82, loss 0.5307899713516235, acc=0.7696666717529297, loss=0.5307899713516235
test: epoch 82, loss 1.7246754169464111, acc=0.42500001192092896, loss=1.7246754169464111
train: epoch 83, loss 0.5301684737205505, acc=0.7679444551467896, loss=0.5301684737205505
test: epoch 83, loss 1.7060370445251465, acc=0.4166666567325592, loss=1.7060370445251465
train: epoch 84, loss 0.5271328687667847, acc=0.7721111178398132, loss=0.5271328687667847
test: epoch 84, loss 1.666663646697998, acc=0.4027777910232544, loss=1.666663646697998
train: epoch 85, loss 0.5126704573631287, acc=0.7746666669845581, loss=0.5126704573631287
test: epoch 85, loss 1.6641472578048706, acc=0.4333333373069763, loss=1.6641472578048706
train: epoch 86, loss 0.5175444483757019, acc=0.7728333473205566, loss=0.5175444483757019
test: epoch 86, loss 1.7298381328582764, acc=0.4333333373069763, loss=1.7298381328582764
train: epoch 87, loss 0.516502320766449, acc=0.7772777676582336, loss=0.516502320766449
test: epoch 87, loss 1.6591410636901855, acc=0.4277777671813965, loss=1.6591410636901855
train: epoch 88, loss 0.5149526000022888, acc=0.7750555276870728, loss=0.5149526000022888
test: epoch 88, loss 1.6599931716918945, acc=0.43611112236976624, loss=1.6599931716918945
train: epoch 89, loss 0.5136951804161072, acc=0.7795000076293945, loss=0.5136951804161072
test: epoch 89, loss 1.6718239784240723, acc=0.4277777671813965, loss=1.6718239784240723
train: epoch 90, loss 0.4991137981414795, acc=0.7803333401679993, loss=0.4991137981414795
test: epoch 90, loss 1.7105939388275146, acc=0.4027777910232544, loss=1.7105939388275146
train: epoch 91, loss 0.4913686215877533, acc=0.7816110849380493, loss=0.4913686215877533
test: epoch 91, loss 1.5844262838363647, acc=0.4694444537162781, loss=1.5844262838363647
train: epoch 92, loss 0.4961202144622803, acc=0.7829444408416748, loss=0.4961202144622803
test: epoch 92, loss 1.675723671913147, acc=0.44999998807907104, loss=1.675723671913147
train: epoch 93, loss 0.4946940243244171, acc=0.7845555543899536, loss=0.4946940243244171
test: epoch 93, loss 1.7265751361846924, acc=0.4416666626930237, loss=1.7265751361846924
train: epoch 94, loss 0.4836553931236267, acc=0.7848333120346069, loss=0.4836553931236267
test: epoch 94, loss 1.6610163450241089, acc=0.4305555522441864, loss=1.6610163450241089
train: epoch 95, loss 0.479851633310318, acc=0.789222240447998, loss=0.479851633310318
test: epoch 95, loss 1.6517702341079712, acc=0.44999998807907104, loss=1.6517702341079712
train: epoch 96, loss 0.4907262325286865, acc=0.785444438457489, loss=0.4907262325286865
test: epoch 96, loss 1.618709683418274, acc=0.4472222328186035, loss=1.618709683418274
train: epoch 97, loss 0.47738850116729736, acc=0.7882221937179565, loss=0.47738850116729736
test: epoch 97, loss 1.6309893131256104, acc=0.4583333432674408, loss=1.6309893131256104
train: epoch 98, loss 0.48904284834861755, acc=0.7910555601119995, loss=0.48904284834861755
test: epoch 98, loss 1.532591462135315, acc=0.4555555582046509, loss=1.532591462135315
train: epoch 99, loss 0.48645758628845215, acc=0.7917222380638123, loss=0.48645758628845215
test: epoch 99, loss 1.6440353393554688, acc=0.4444444477558136, loss=1.6440353393554688
train: epoch 100, loss 0.4732789695262909, acc=0.7925000190734863, loss=0.4732789695262909
test: epoch 100, loss 1.6967040300369263, acc=0.4416666626930237, loss=1.6967040300369263
train: epoch 101, loss 0.46781161427497864, acc=0.792722225189209, loss=0.46781161427497864
test: epoch 101, loss 1.6077300310134888, acc=0.4472222328186035, loss=1.6077300310134888
train: epoch 102, loss 0.47941386699676514, acc=0.7948889136314392, loss=0.47941386699676514
test: epoch 102, loss 1.6504045724868774, acc=0.4583333432674408, loss=1.6504045724868774
train: epoch 103, loss 0.4543868899345398, acc=0.8002777695655823, loss=0.4543868899345398
test: epoch 103, loss 1.6545926332473755, acc=0.4333333373069763, loss=1.6545926332473755
train: epoch 104, loss 0.4668984115123749, acc=0.7997778058052063, loss=0.4668984115123749
test: epoch 104, loss 1.6325775384902954, acc=0.4694444537162781, loss=1.6325775384902954
train: epoch 105, loss 0.4635670483112335, acc=0.8022222518920898, loss=0.4635670483112335
test: epoch 105, loss 1.6381585597991943, acc=0.4749999940395355, loss=1.6381585597991943
train: epoch 106, loss 0.4503074288368225, acc=0.8054999709129333, loss=0.4503074288368225
test: epoch 106, loss 1.5937690734863281, acc=0.4722222089767456, loss=1.5937690734863281
train: epoch 107, loss 0.4482971429824829, acc=0.8092222213745117, loss=0.4482971429824829
test: epoch 107, loss 1.6214218139648438, acc=0.4416666626930237, loss=1.6214218139648438
train: epoch 108, loss 0.46904999017715454, acc=0.8037222027778625, loss=0.46904999017715454
test: epoch 108, loss 1.502111554145813, acc=0.4694444537162781, loss=1.502111554145813
train: epoch 109, loss 0.44819504022598267, acc=0.8098888993263245, loss=0.44819504022598267
test: epoch 109, loss 1.6362565755844116, acc=0.48055556416511536, loss=1.6362565755844116
train: epoch 110, loss 0.4477273225784302, acc=0.8073333501815796, loss=0.4477273225784302
test: epoch 110, loss 1.5962036848068237, acc=0.47777777910232544, loss=1.5962036848068237
train: epoch 111, loss 0.4351552426815033, acc=0.8111666440963745, loss=0.4351552426815033
test: epoch 111, loss 1.5188887119293213, acc=0.4833333194255829, loss=1.5188887119293213
train: epoch 112, loss 0.44504019618034363, acc=0.8078888654708862, loss=0.44504019618034363
test: epoch 112, loss 1.5244437456130981, acc=0.49166667461395264, loss=1.5244437456130981
train: epoch 113, loss 0.455502986907959, acc=0.8170555830001831, loss=0.455502986907959
test: epoch 113, loss 1.635254144668579, acc=0.47777777910232544, loss=1.635254144668579
train: epoch 114, loss 0.4336724579334259, acc=0.8145555257797241, loss=0.4336724579334259
test: epoch 114, loss 1.554460048675537, acc=0.4472222328186035, loss=1.554460048675537
train: epoch 115, loss 0.4384346604347229, acc=0.8081666827201843, loss=0.4384346604347229
test: epoch 115, loss 1.613693118095398, acc=0.4888888895511627, loss=1.613693118095398
train: epoch 116, loss 0.4270118474960327, acc=0.816777765750885, loss=0.4270118474960327
test: epoch 116, loss 1.7534949779510498, acc=0.4694444537162781, loss=1.7534949779510498
train: epoch 117, loss 0.42798906564712524, acc=0.8163889050483704, loss=0.42798906564712524
test: epoch 117, loss 1.5867674350738525, acc=0.4888888895511627, loss=1.5867674350738525
train: epoch 118, loss 0.43121421337127686, acc=0.8154444694519043, loss=0.43121421337127686
test: epoch 118, loss 1.6172218322753906, acc=0.49166667461395264, loss=1.6172218322753906
train: epoch 119, loss 0.4375160038471222, acc=0.8122777938842773, loss=0.4375160038471222
test: epoch 119, loss 1.5366894006729126, acc=0.46666666865348816, loss=1.5366894006729126
train: epoch 120, loss 0.41728708148002625, acc=0.8173333406448364, loss=0.41728708148002625
test: epoch 120, loss 1.5213890075683594, acc=0.5138888955116272, loss=1.5213890075683594
train: epoch 121, loss 0.42065873742103577, acc=0.8182222247123718, loss=0.42065873742103577
test: epoch 121, loss 1.5765961408615112, acc=0.49444442987442017, loss=1.5765961408615112
train: epoch 122, loss 0.4246158003807068, acc=0.816944420337677, loss=0.4246158003807068
test: epoch 122, loss 1.5914286375045776, acc=0.5055555701255798, loss=1.5914286375045776
train: epoch 123, loss 0.4136315882205963, acc=0.8221666812896729, loss=0.4136315882205963
test: epoch 123, loss 1.4275315999984741, acc=0.5138888955116272, loss=1.4275315999984741
train: epoch 124, loss 0.42914557456970215, acc=0.8180555701255798, loss=0.42914557456970215
test: epoch 124, loss 1.4981499910354614, acc=0.5222222208976746, loss=1.4981499910354614
train: epoch 125, loss 0.41035178303718567, acc=0.8200555443763733, loss=0.41035178303718567
test: epoch 125, loss 1.416037917137146, acc=0.5166666507720947, loss=1.416037917137146
train: epoch 126, loss 0.4144073724746704, acc=0.8200555443763733, loss=0.4144073724746704
test: epoch 126, loss 1.5683729648590088, acc=0.5, loss=1.5683729648590088
train: epoch 127, loss 0.41004595160484314, acc=0.8208333253860474, loss=0.41004595160484314
test: epoch 127, loss 1.771124005317688, acc=0.5111111402511597, loss=1.771124005317688
train: epoch 128, loss 0.406148225069046, acc=0.823888897895813, loss=0.406148225069046
test: epoch 128, loss 1.5933115482330322, acc=0.5055555701255798, loss=1.5933115482330322
train: epoch 129, loss 0.4007284343242645, acc=0.8277778029441833, loss=0.4007284343242645
test: epoch 129, loss 1.5773203372955322, acc=0.5083333253860474, loss=1.5773203372955322
train: epoch 130, loss 0.3995516300201416, acc=0.8257777690887451, loss=0.3995516300201416
test: epoch 130, loss 1.5039299726486206, acc=0.5166666507720947, loss=1.5039299726486206
train: epoch 131, loss 0.4076211154460907, acc=0.824999988079071, loss=0.4076211154460907
test: epoch 131, loss 1.6160469055175781, acc=0.5166666507720947, loss=1.6160469055175781
train: epoch 132, loss 0.40728759765625, acc=0.8206111192703247, loss=0.40728759765625
test: epoch 132, loss 1.5494437217712402, acc=0.5138888955116272, loss=1.5494437217712402
train: epoch 133, loss 0.40278300642967224, acc=0.8235555291175842, loss=0.40278300642967224
test: epoch 133, loss 1.5089668035507202, acc=0.5222222208976746, loss=1.5089668035507202
train: epoch 134, loss 0.3983987867832184, acc=0.8234999775886536, loss=0.3983987867832184
test: epoch 134, loss 1.559659481048584, acc=0.5111111402511597, loss=1.559659481048584
train: epoch 135, loss 0.4031640589237213, acc=0.8209999799728394, loss=0.4031640589237213
test: epoch 135, loss 1.4535272121429443, acc=0.5249999761581421, loss=1.4535272121429443
train: epoch 136, loss 0.40550345182418823, acc=0.8257777690887451, loss=0.40550345182418823
test: epoch 136, loss 1.5773764848709106, acc=0.519444465637207, loss=1.5773764848709106
train: epoch 137, loss 0.3941505551338196, acc=0.829277753829956, loss=0.3941505551338196
test: epoch 137, loss 1.516815185546875, acc=0.5027777552604675, loss=1.516815185546875
train: epoch 138, loss 0.4125460982322693, acc=0.8253333568572998, loss=0.4125460982322693
test: epoch 138, loss 1.572272777557373, acc=0.519444465637207, loss=1.572272777557373
train: epoch 139, loss 0.4095538854598999, acc=0.8287777900695801, loss=0.4095538854598999
test: epoch 139, loss 1.446958065032959, acc=0.519444465637207, loss=1.446958065032959
train: epoch 140, loss 0.38445743918418884, acc=0.8349444270133972, loss=0.38445743918418884
test: epoch 140, loss 1.606976866722107, acc=0.5277777910232544, loss=1.606976866722107
train: epoch 141, loss 0.3897456228733063, acc=0.8304444551467896, loss=0.3897456228733063
test: epoch 141, loss 1.5472559928894043, acc=0.5111111402511597, loss=1.5472559928894043
train: epoch 142, loss 0.39525026082992554, acc=0.8322222232818604, loss=0.39525026082992554
test: epoch 142, loss 1.4551714658737183, acc=0.5305555462837219, loss=1.4551714658737183
train: epoch 143, loss 0.39606764912605286, acc=0.8332222104072571, loss=0.39606764912605286
test: epoch 143, loss 1.5646398067474365, acc=0.5166666507720947, loss=1.5646398067474365
train: epoch 144, loss 0.3891785144805908, acc=0.8341110944747925, loss=0.3891785144805908
test: epoch 144, loss 1.5600870847702026, acc=0.5138888955116272, loss=1.5600870847702026
train: epoch 145, loss 0.3846879005432129, acc=0.831944465637207, loss=0.3846879005432129
test: epoch 145, loss 1.5510329008102417, acc=0.5444444417953491, loss=1.5510329008102417
train: epoch 146, loss 0.3947547674179077, acc=0.8333333134651184, loss=0.3947547674179077
test: epoch 146, loss 1.5005042552947998, acc=0.5333333611488342, loss=1.5005042552947998
train: epoch 147, loss 0.38201794028282166, acc=0.8336666822433472, loss=0.38201794028282166
test: epoch 147, loss 1.5556073188781738, acc=0.5222222208976746, loss=1.5556073188781738
train: epoch 148, loss 0.37856459617614746, acc=0.8352222442626953, loss=0.37856459617614746
test: epoch 148, loss 1.5864040851593018, acc=0.5166666507720947, loss=1.5864040851593018
train: epoch 149, loss 0.37535718083381653, acc=0.8360555768013, loss=0.37535718083381653
test: epoch 149, loss 1.4193804264068604, acc=0.5472221970558167, loss=1.4193804264068604
train: epoch 150, loss 0.3764285147190094, acc=0.8353888988494873, loss=0.3764285147190094
test: epoch 150, loss 1.4112340211868286, acc=0.5388888716697693, loss=1.4112340211868286
