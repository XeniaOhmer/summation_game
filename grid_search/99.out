# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=1", "--n_layers=1"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=446964009, receiver_embed_dim=64, save_run=0, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=446964009, receiver_embed_dim=64, save_run=False, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.5249691009521484, acc=0.05027777701616287, loss=3.5249691009521484
test: epoch 1, loss 3.511383056640625, acc=0.03611111268401146, loss=3.511383056640625
train: epoch 2, loss 3.437623977661133, acc=0.054055556654930115, loss=3.437623977661133
test: epoch 2, loss 3.1209208965301514, acc=0.09166666865348816, loss=3.1209208965301514
train: epoch 3, loss 3.053725004196167, acc=0.1010555550456047, loss=3.053725004196167
test: epoch 3, loss 6.0869035720825195, acc=0.0416666679084301, loss=6.0869035720825195
train: epoch 4, loss 2.594095230102539, acc=0.16838888823986053, loss=2.594095230102539
test: epoch 4, loss 7.995603561401367, acc=0.03333333507180214, loss=7.995603561401367
train: epoch 5, loss 2.3614859580993652, acc=0.20488889515399933, loss=2.3614859580993652
test: epoch 5, loss 8.45358943939209, acc=0.05277777835726738, loss=8.45358943939209
train: epoch 6, loss 2.220257520675659, acc=0.22588889300823212, loss=2.220257520675659
test: epoch 6, loss 8.510468482971191, acc=0.05000000074505806, loss=8.510468482971191
train: epoch 7, loss 2.124922275543213, acc=0.25433334708213806, loss=2.124922275543213
test: epoch 7, loss 8.370600700378418, acc=0.05277777835726738, loss=8.370600700378418
train: epoch 8, loss 2.059788227081299, acc=0.2746666669845581, loss=2.059788227081299
test: epoch 8, loss 8.637454986572266, acc=0.04722222313284874, loss=8.637454986572266
train: epoch 9, loss 2.0057597160339355, acc=0.28466665744781494, loss=2.0057597160339355
test: epoch 9, loss 8.739029884338379, acc=0.0416666679084301, loss=8.739029884338379
train: epoch 10, loss 1.9566349983215332, acc=0.3070000112056732, loss=1.9566349983215332
test: epoch 10, loss 8.899859428405762, acc=0.04722222313284874, loss=8.899859428405762
train: epoch 11, loss 1.9147969484329224, acc=0.31183332204818726, loss=1.9147969484329224
test: epoch 11, loss 8.998759269714355, acc=0.04444444552063942, loss=8.998759269714355
train: epoch 12, loss 1.8710129261016846, acc=0.3249444365501404, loss=1.8710129261016846
test: epoch 12, loss 8.723868370056152, acc=0.05833333358168602, loss=8.723868370056152
train: epoch 13, loss 1.8356359004974365, acc=0.3349444568157196, loss=1.8356359004974365
test: epoch 13, loss 8.846586227416992, acc=0.05833333358168602, loss=8.846586227416992
train: epoch 14, loss 1.807127833366394, acc=0.3433888852596283, loss=1.807127833366394
test: epoch 14, loss 8.753570556640625, acc=0.06388889253139496, loss=8.753570556640625
train: epoch 15, loss 1.7835841178894043, acc=0.3568333387374878, loss=1.7835841178894043
test: epoch 15, loss 8.754069328308105, acc=0.07500000298023224, loss=8.754069328308105
train: epoch 16, loss 1.7415601015090942, acc=0.36872223019599915, loss=1.7415601015090942
test: epoch 16, loss 8.765636444091797, acc=0.06666667014360428, loss=8.765636444091797
train: epoch 17, loss 1.728073000907898, acc=0.3733333349227905, loss=1.728073000907898
test: epoch 17, loss 8.508047103881836, acc=0.08611111342906952, loss=8.508047103881836
train: epoch 18, loss 1.6943025588989258, acc=0.37922221422195435, loss=1.6943025588989258
test: epoch 18, loss 8.520424842834473, acc=0.08055555820465088, loss=8.520424842834473
train: epoch 19, loss 1.6617379188537598, acc=0.3962777853012085, loss=1.6617379188537598
test: epoch 19, loss 8.154134750366211, acc=0.0833333358168602, loss=8.154134750366211
train: epoch 20, loss 1.6501295566558838, acc=0.3963888883590698, loss=1.6501295566558838
test: epoch 20, loss 7.72883939743042, acc=0.08888889104127884, loss=7.72883939743042
train: epoch 21, loss 1.6190189123153687, acc=0.4113888740539551, loss=1.6190189123153687
test: epoch 21, loss 7.312488079071045, acc=0.10277777910232544, loss=7.312488079071045
train: epoch 22, loss 1.6059257984161377, acc=0.4137222170829773, loss=1.6059257984161377
test: epoch 22, loss 7.131963729858398, acc=0.0972222238779068, loss=7.131963729858398
train: epoch 23, loss 1.5831021070480347, acc=0.4280555546283722, loss=1.5831021070480347
test: epoch 23, loss 6.844886302947998, acc=0.10555555671453476, loss=6.844886302947998
train: epoch 24, loss 1.5587477684020996, acc=0.43461111187934875, loss=1.5587477684020996
test: epoch 24, loss 6.545838832855225, acc=0.10555555671453476, loss=6.545838832855225
train: epoch 25, loss 1.5347354412078857, acc=0.4418888986110687, loss=1.5347354412078857
test: epoch 25, loss 6.179459571838379, acc=0.11388888955116272, loss=6.179459571838379
train: epoch 26, loss 1.5112833976745605, acc=0.4457777738571167, loss=1.5112833976745605
test: epoch 26, loss 5.920915603637695, acc=0.10555555671453476, loss=5.920915603637695
train: epoch 27, loss 1.4929157495498657, acc=0.46005555987358093, loss=1.4929157495498657
test: epoch 27, loss 5.667838096618652, acc=0.10555555671453476, loss=5.667838096618652
train: epoch 28, loss 1.470118522644043, acc=0.47022223472595215, loss=1.470118522644043
test: epoch 28, loss 5.414801597595215, acc=0.12777778506278992, loss=5.414801597595215
train: epoch 29, loss 1.463282823562622, acc=0.4781111180782318, loss=1.463282823562622
test: epoch 29, loss 5.02406644821167, acc=0.14166666567325592, loss=5.02406644821167
train: epoch 30, loss 1.4315146207809448, acc=0.4834444522857666, loss=1.4315146207809448
test: epoch 30, loss 4.723442077636719, acc=0.14444445073604584, loss=4.723442077636719
train: epoch 31, loss 1.409186601638794, acc=0.49783334136009216, loss=1.409186601638794
test: epoch 31, loss 4.650742053985596, acc=0.13611111044883728, loss=4.650742053985596
train: epoch 32, loss 1.385810375213623, acc=0.5070000290870667, loss=1.385810375213623
test: epoch 32, loss 4.3970627784729, acc=0.15833333134651184, loss=4.3970627784729
train: epoch 33, loss 1.3617478609085083, acc=0.5164999961853027, loss=1.3617478609085083
test: epoch 33, loss 4.364512920379639, acc=0.1666666716337204, loss=4.364512920379639
train: epoch 34, loss 1.3440884351730347, acc=0.5225555300712585, loss=1.3440884351730347
test: epoch 34, loss 4.231779098510742, acc=0.16111111640930176, loss=4.231779098510742
train: epoch 35, loss 1.3273900747299194, acc=0.535444438457489, loss=1.3273900747299194
test: epoch 35, loss 3.949517250061035, acc=0.18333333730697632, loss=3.949517250061035
train: epoch 36, loss 1.3101561069488525, acc=0.5412222146987915, loss=1.3101561069488525
test: epoch 36, loss 3.8213794231414795, acc=0.18333333730697632, loss=3.8213794231414795
train: epoch 37, loss 1.287973165512085, acc=0.5615555644035339, loss=1.287973165512085
test: epoch 37, loss 3.807630777359009, acc=0.21388888359069824, loss=3.807630777359009
train: epoch 38, loss 1.2566853761672974, acc=0.5678889155387878, loss=1.2566853761672974
test: epoch 38, loss 3.7263503074645996, acc=0.1944444477558136, loss=3.7263503074645996
train: epoch 39, loss 1.2597841024398804, acc=0.5784444212913513, loss=1.2597841024398804
test: epoch 39, loss 3.6601295471191406, acc=0.2083333283662796, loss=3.6601295471191406
train: epoch 40, loss 1.209542155265808, acc=0.5917222499847412, loss=1.209542155265808
test: epoch 40, loss 3.697023630142212, acc=0.22499999403953552, loss=3.697023630142212
train: epoch 41, loss 1.1973233222961426, acc=0.6005555391311646, loss=1.1973233222961426
test: epoch 41, loss 3.550048828125, acc=0.22499999403953552, loss=3.550048828125
train: epoch 42, loss 1.1917442083358765, acc=0.6076111197471619, loss=1.1917442083358765
test: epoch 42, loss 3.5543675422668457, acc=0.22777777910232544, loss=3.5543675422668457
train: epoch 43, loss 1.1499600410461426, acc=0.6239444613456726, loss=1.1499600410461426
test: epoch 43, loss 3.426466703414917, acc=0.2527777850627899, loss=3.426466703414917
train: epoch 44, loss 1.1338878870010376, acc=0.6354444622993469, loss=1.1338878870010376
test: epoch 44, loss 3.2596516609191895, acc=0.24722221493721008, loss=3.2596516609191895
train: epoch 45, loss 1.092610478401184, acc=0.6467221975326538, loss=1.092610478401184
test: epoch 45, loss 3.1174371242523193, acc=0.2750000059604645, loss=3.1174371242523193
train: epoch 46, loss 1.0786174535751343, acc=0.6523333191871643, loss=1.0786174535751343
test: epoch 46, loss 3.142561674118042, acc=0.2666666805744171, loss=3.142561674118042
train: epoch 47, loss 1.0523098707199097, acc=0.6681666374206543, loss=1.0523098707199097
test: epoch 47, loss 3.04854679107666, acc=0.2666666805744171, loss=3.04854679107666
train: epoch 48, loss 1.029834270477295, acc=0.6801666617393494, loss=1.029834270477295
test: epoch 48, loss 2.989609956741333, acc=0.2777777910232544, loss=2.989609956741333
train: epoch 49, loss 1.0138332843780518, acc=0.6863333582878113, loss=1.0138332843780518
test: epoch 49, loss 3.013218879699707, acc=0.27222222089767456, loss=3.013218879699707
train: epoch 50, loss 0.9800297021865845, acc=0.7033888697624207, loss=0.9800297021865845
test: epoch 50, loss 3.0539145469665527, acc=0.2666666805744171, loss=3.0539145469665527
train: epoch 51, loss 0.9684830904006958, acc=0.7089444398880005, loss=0.9684830904006958
test: epoch 51, loss 3.0718886852264404, acc=0.27222222089767456, loss=3.0718886852264404
train: epoch 52, loss 0.9336690306663513, acc=0.7209444642066956, loss=0.9336690306663513
test: epoch 52, loss 3.1322944164276123, acc=0.28333333134651184, loss=3.1322944164276123
train: epoch 53, loss 0.9047064781188965, acc=0.7345555424690247, loss=0.9047064781188965
test: epoch 53, loss 2.938467502593994, acc=0.28611111640930176, loss=2.938467502593994
train: epoch 54, loss 0.9009484052658081, acc=0.7445555329322815, loss=0.9009484052658081
test: epoch 54, loss 2.9108855724334717, acc=0.2916666567325592, loss=2.9108855724334717
train: epoch 55, loss 0.8602810502052307, acc=0.7547777891159058, loss=0.8602810502052307
test: epoch 55, loss 2.8512609004974365, acc=0.2916666567325592, loss=2.8512609004974365
train: epoch 56, loss 0.846153736114502, acc=0.7598333358764648, loss=0.846153736114502
test: epoch 56, loss 2.799427032470703, acc=0.30000001192092896, loss=2.799427032470703
train: epoch 57, loss 0.8010497689247131, acc=0.7767778038978577, loss=0.8010497689247131
test: epoch 57, loss 2.701988935470581, acc=0.2916666567325592, loss=2.701988935470581
train: epoch 58, loss 0.791742742061615, acc=0.7821111083030701, loss=0.791742742061615
test: epoch 58, loss 2.63739275932312, acc=0.2916666567325592, loss=2.63739275932312
train: epoch 59, loss 0.7780154347419739, acc=0.7848888635635376, loss=0.7780154347419739
test: epoch 59, loss 2.639390468597412, acc=0.2916666567325592, loss=2.639390468597412
train: epoch 60, loss 0.7692030072212219, acc=0.7911666631698608, loss=0.7692030072212219
test: epoch 60, loss 2.6058754920959473, acc=0.2805555462837219, loss=2.6058754920959473
train: epoch 61, loss 0.7206435799598694, acc=0.8079444169998169, loss=0.7206435799598694
test: epoch 61, loss 2.5290043354034424, acc=0.28611111640930176, loss=2.5290043354034424
train: epoch 62, loss 0.7165314555168152, acc=0.8119999766349792, loss=0.7165314555168152
test: epoch 62, loss 2.628403663635254, acc=0.28611111640930176, loss=2.628403663635254
train: epoch 63, loss 0.6861423254013062, acc=0.8239444494247437, loss=0.6861423254013062
test: epoch 63, loss 2.591066837310791, acc=0.28611111640930176, loss=2.591066837310791
train: epoch 64, loss 0.6743700504302979, acc=0.8276110887527466, loss=0.6743700504302979
test: epoch 64, loss 2.5447733402252197, acc=0.28333333134651184, loss=2.5447733402252197
train: epoch 65, loss 0.6655446290969849, acc=0.8347777724266052, loss=0.6655446290969849
test: epoch 65, loss 2.477421760559082, acc=0.28611111640930176, loss=2.477421760559082
train: epoch 66, loss 0.634912371635437, acc=0.8427777886390686, loss=0.634912371635437
test: epoch 66, loss 2.4519076347351074, acc=0.3027777671813965, loss=2.4519076347351074
train: epoch 67, loss 0.6011039018630981, acc=0.8479999899864197, loss=0.6011039018630981
test: epoch 67, loss 2.3727972507476807, acc=0.3083333373069763, loss=2.3727972507476807
train: epoch 68, loss 0.610462486743927, acc=0.8492777943611145, loss=0.610462486743927
test: epoch 68, loss 2.319164752960205, acc=0.3166666626930237, loss=2.319164752960205
train: epoch 69, loss 0.604844331741333, acc=0.8539444208145142, loss=0.604844331741333
test: epoch 69, loss 2.2558209896087646, acc=0.3055555522441864, loss=2.2558209896087646
train: epoch 70, loss 0.5912984609603882, acc=0.8626111149787903, loss=0.5912984609603882
test: epoch 70, loss 2.2284352779388428, acc=0.3055555522441864, loss=2.2284352779388428
train: epoch 71, loss 0.5803986191749573, acc=0.8654999732971191, loss=0.5803986191749573
test: epoch 71, loss 2.170867919921875, acc=0.3083333373069763, loss=2.170867919921875
train: epoch 72, loss 0.54425048828125, acc=0.8676666617393494, loss=0.54425048828125
test: epoch 72, loss 2.128995418548584, acc=0.3166666626930237, loss=2.128995418548584
train: epoch 73, loss 0.5749503374099731, acc=0.866611123085022, loss=0.5749503374099731
test: epoch 73, loss 2.156540632247925, acc=0.3194444477558136, loss=2.156540632247925
train: epoch 74, loss 0.5160855650901794, acc=0.878000020980835, loss=0.5160855650901794
test: epoch 74, loss 2.1250834465026855, acc=0.3194444477558136, loss=2.1250834465026855
train: epoch 75, loss 0.5173215866088867, acc=0.8786110877990723, loss=0.5173215866088867
test: epoch 75, loss 2.0861213207244873, acc=0.3166666626930237, loss=2.0861213207244873
train: epoch 76, loss 0.525322675704956, acc=0.8809999823570251, loss=0.525322675704956
test: epoch 76, loss 2.1098079681396484, acc=0.3055555522441864, loss=2.1098079681396484
train: epoch 77, loss 0.5241854190826416, acc=0.88227778673172, loss=0.5241854190826416
test: epoch 77, loss 2.008594512939453, acc=0.3166666626930237, loss=2.008594512939453
train: epoch 78, loss 0.5095430016517639, acc=0.8853889107704163, loss=0.5095430016517639
test: epoch 78, loss 2.071138620376587, acc=0.3166666626930237, loss=2.071138620376587
train: epoch 79, loss 0.49455177783966064, acc=0.8872222304344177, loss=0.49455177783966064
test: epoch 79, loss 2.005922794342041, acc=0.3222222328186035, loss=2.005922794342041
train: epoch 80, loss 0.48182666301727295, acc=0.8914999961853027, loss=0.48182666301727295
test: epoch 80, loss 1.971093773841858, acc=0.3166666626930237, loss=1.971093773841858
train: epoch 81, loss 0.49130934476852417, acc=0.8908888697624207, loss=0.49130934476852417
test: epoch 81, loss 1.9499081373214722, acc=0.3194444477558136, loss=1.9499081373214722
train: epoch 82, loss 0.46333664655685425, acc=0.8942777514457703, loss=0.46333664655685425
test: epoch 82, loss 1.9897841215133667, acc=0.32499998807907104, loss=1.9897841215133667
train: epoch 83, loss 0.4579439163208008, acc=0.8980555534362793, loss=0.4579439163208008
test: epoch 83, loss 1.9343452453613281, acc=0.31388887763023376, loss=1.9343452453613281
train: epoch 84, loss 0.44498705863952637, acc=0.9000555276870728, loss=0.44498705863952637
test: epoch 84, loss 1.9031448364257812, acc=0.3333333432674408, loss=1.9031448364257812
train: epoch 85, loss 0.44567805528640747, acc=0.899222195148468, loss=0.44567805528640747
test: epoch 85, loss 1.9015896320343018, acc=0.3194444477558136, loss=1.9015896320343018
train: epoch 86, loss 0.43594440817832947, acc=0.9034444689750671, loss=0.43594440817832947
test: epoch 86, loss 1.8734805583953857, acc=0.3361110985279083, loss=1.8734805583953857
train: epoch 87, loss 0.4398985803127289, acc=0.9028888940811157, loss=0.4398985803127289
test: epoch 87, loss 1.8176897764205933, acc=0.3305555582046509, loss=1.8176897764205933
train: epoch 88, loss 0.4361097812652588, acc=0.9031111001968384, loss=0.4361097812652588
test: epoch 88, loss 1.8792915344238281, acc=0.3222222328186035, loss=1.8792915344238281
train: epoch 89, loss 0.41219934821128845, acc=0.9068889021873474, loss=0.41219934821128845
test: epoch 89, loss 1.8788942098617554, acc=0.3333333432674408, loss=1.8788942098617554
train: epoch 90, loss 0.4368654787540436, acc=0.9058889150619507, loss=0.4368654787540436
test: epoch 90, loss 1.810640811920166, acc=0.3444444537162781, loss=1.810640811920166
train: epoch 91, loss 0.4470531642436981, acc=0.9058889150619507, loss=0.4470531642436981
test: epoch 91, loss 1.8246548175811768, acc=0.3333333432674408, loss=1.8246548175811768
train: epoch 92, loss 0.41328296065330505, acc=0.9055555462837219, loss=0.41328296065330505
test: epoch 92, loss 1.7847802639007568, acc=0.3305555582046509, loss=1.7847802639007568
train: epoch 93, loss 0.39773625135421753, acc=0.9128888845443726, loss=0.39773625135421753
test: epoch 93, loss 1.8171356916427612, acc=0.3222222328186035, loss=1.8171356916427612
train: epoch 94, loss 0.40424713492393494, acc=0.9121111035346985, loss=0.40424713492393494
test: epoch 94, loss 1.7592672109603882, acc=0.34166666865348816, loss=1.7592672109603882
train: epoch 95, loss 0.4051867127418518, acc=0.9114444255828857, loss=0.4051867127418518
test: epoch 95, loss 1.7362148761749268, acc=0.3361110985279083, loss=1.7362148761749268
train: epoch 96, loss 0.41758596897125244, acc=0.9114444255828857, loss=0.41758596897125244
test: epoch 96, loss 1.7482177019119263, acc=0.3444444537162781, loss=1.7482177019119263
train: epoch 97, loss 0.3971989154815674, acc=0.9140555262565613, loss=0.3971989154815674
test: epoch 97, loss 1.6842097043991089, acc=0.3472222089767456, loss=1.6842097043991089
train: epoch 98, loss 0.43018487095832825, acc=0.9102222323417664, loss=0.43018487095832825
test: epoch 98, loss 1.749521255493164, acc=0.3611111044883728, loss=1.749521255493164
train: epoch 99, loss 0.40235811471939087, acc=0.9174444675445557, loss=0.40235811471939087
test: epoch 99, loss 1.7330682277679443, acc=0.35277777910232544, loss=1.7330682277679443
train: epoch 100, loss 0.39480680227279663, acc=0.9125000238418579, loss=0.39480680227279663
test: epoch 100, loss 1.6907637119293213, acc=0.3611111044883728, loss=1.6907637119293213
train: epoch 101, loss 0.3781191408634186, acc=0.9183333516120911, loss=0.3781191408634186
test: epoch 101, loss 1.7094535827636719, acc=0.35555556416511536, loss=1.7094535827636719
train: epoch 102, loss 0.40666043758392334, acc=0.9131110906600952, loss=0.40666043758392334
test: epoch 102, loss 1.6338996887207031, acc=0.36944442987442017, loss=1.6338996887207031
train: epoch 103, loss 0.39098191261291504, acc=0.917555570602417, loss=0.39098191261291504
test: epoch 103, loss 1.6500929594039917, acc=0.3722222149372101, loss=1.6500929594039917
train: epoch 104, loss 0.3854617774486542, acc=0.9155555367469788, loss=0.3854617774486542
test: epoch 104, loss 1.6436342000961304, acc=0.36666667461395264, loss=1.6436342000961304
train: epoch 105, loss 0.39287424087524414, acc=0.9183889031410217, loss=0.39287424087524414
test: epoch 105, loss 1.6423450708389282, acc=0.375, loss=1.6423450708389282
train: epoch 106, loss 0.3722932040691376, acc=0.9182778000831604, loss=0.3722932040691376
test: epoch 106, loss 1.5977779626846313, acc=0.36666667461395264, loss=1.5977779626846313
train: epoch 107, loss 0.39034759998321533, acc=0.917388916015625, loss=0.39034759998321533
test: epoch 107, loss 1.6080176830291748, acc=0.375, loss=1.6080176830291748
train: epoch 108, loss 0.386338472366333, acc=0.9170555472373962, loss=0.386338472366333
test: epoch 108, loss 1.6364095211029053, acc=0.38055557012557983, loss=1.6364095211029053
train: epoch 109, loss 0.37934574484825134, acc=0.9190000295639038, loss=0.37934574484825134
test: epoch 109, loss 1.6392720937728882, acc=0.38333332538604736, loss=1.6392720937728882
train: epoch 110, loss 0.3971251845359802, acc=0.9164999723434448, loss=0.3971251845359802
test: epoch 110, loss 1.630859613418579, acc=0.38333332538604736, loss=1.630859613418579
train: epoch 111, loss 0.37435266375541687, acc=0.9208889007568359, loss=0.37435266375541687
test: epoch 111, loss 1.603467345237732, acc=0.3777777850627899, loss=1.603467345237732
train: epoch 112, loss 0.3914583623409271, acc=0.9181110858917236, loss=0.3914583623409271
test: epoch 112, loss 1.5858365297317505, acc=0.38055557012557983, loss=1.5858365297317505
train: epoch 113, loss 0.37043482065200806, acc=0.9212777614593506, loss=0.37043482065200806
test: epoch 113, loss 1.563720941543579, acc=0.39722222089767456, loss=1.563720941543579
train: epoch 114, loss 0.34791094064712524, acc=0.9242222309112549, loss=0.34791094064712524
test: epoch 114, loss 1.549849510192871, acc=0.4194444417953491, loss=1.549849510192871
train: epoch 115, loss 0.370807945728302, acc=0.9198333621025085, loss=0.370807945728302
test: epoch 115, loss 1.5456337928771973, acc=0.38333332538604736, loss=1.5456337928771973
train: epoch 116, loss 0.3600707948207855, acc=0.9256666898727417, loss=0.3600707948207855
test: epoch 116, loss 1.5532859563827515, acc=0.39444443583488464, loss=1.5532859563827515
train: epoch 117, loss 0.3746945261955261, acc=0.9176111221313477, loss=0.3746945261955261
test: epoch 117, loss 1.5458903312683105, acc=0.3888888955116272, loss=1.5458903312683105
train: epoch 118, loss 0.378750741481781, acc=0.9207777976989746, loss=0.378750741481781
test: epoch 118, loss 1.5060802698135376, acc=0.39722222089767456, loss=1.5060802698135376
train: epoch 119, loss 0.3984370529651642, acc=0.9178333282470703, loss=0.3984370529651642
test: epoch 119, loss 1.5430192947387695, acc=0.3916666805744171, loss=1.5430192947387695
train: epoch 120, loss 0.35635000467300415, acc=0.9223333597183228, loss=0.35635000467300415
test: epoch 120, loss 1.5109974145889282, acc=0.4000000059604645, loss=1.5109974145889282
train: epoch 121, loss 0.34668436646461487, acc=0.9241666793823242, loss=0.34668436646461487
test: epoch 121, loss 1.5516070127487183, acc=0.39444443583488464, loss=1.5516070127487183
train: epoch 122, loss 0.36660701036453247, acc=0.9226111173629761, loss=0.36660701036453247
test: epoch 122, loss 1.5578944683074951, acc=0.3861111104488373, loss=1.5578944683074951
train: epoch 123, loss 0.3836889863014221, acc=0.9205555319786072, loss=0.3836889863014221
test: epoch 123, loss 1.490319848060608, acc=0.42222222685813904, loss=1.490319848060608
train: epoch 124, loss 0.3641471862792969, acc=0.918055534362793, loss=0.3641471862792969
test: epoch 124, loss 1.4528300762176514, acc=0.42500001192092896, loss=1.4528300762176514
train: epoch 125, loss 0.36560574173927307, acc=0.9227222204208374, loss=0.36560574173927307
test: epoch 125, loss 1.4965152740478516, acc=0.40833333134651184, loss=1.4965152740478516
train: epoch 126, loss 0.37045520544052124, acc=0.9210000038146973, loss=0.37045520544052124
test: epoch 126, loss 1.4414315223693848, acc=0.4333333373069763, loss=1.4414315223693848
train: epoch 127, loss 0.368619829416275, acc=0.92166668176651, loss=0.368619829416275
test: epoch 127, loss 1.497156023979187, acc=0.4055555462837219, loss=1.497156023979187
train: epoch 128, loss 0.34440216422080994, acc=0.9253333210945129, loss=0.34440216422080994
test: epoch 128, loss 1.478962779045105, acc=0.42500001192092896, loss=1.478962779045105
train: epoch 129, loss 0.3869417905807495, acc=0.9228888750076294, loss=0.3869417905807495
test: epoch 129, loss 1.4189071655273438, acc=0.42222222685813904, loss=1.4189071655273438
train: epoch 130, loss 0.3700103163719177, acc=0.921500027179718, loss=0.3700103163719177
test: epoch 130, loss 1.4705336093902588, acc=0.4138889014720917, loss=1.4705336093902588
train: epoch 131, loss 0.3493044376373291, acc=0.9224444627761841, loss=0.3493044376373291
test: epoch 131, loss 1.4552680253982544, acc=0.4194444417953491, loss=1.4552680253982544
train: epoch 132, loss 0.3655689060688019, acc=0.9226666688919067, loss=0.3655689060688019
test: epoch 132, loss 1.4807369709014893, acc=0.4138889014720917, loss=1.4807369709014893
train: epoch 133, loss 0.3786882758140564, acc=0.9218888878822327, loss=0.3786882758140564
test: epoch 133, loss 1.4503581523895264, acc=0.4333333373069763, loss=1.4503581523895264
train: epoch 134, loss 0.3861989974975586, acc=0.9196666479110718, loss=0.3861989974975586
test: epoch 134, loss 1.4346140623092651, acc=0.42500001192092896, loss=1.4346140623092651
train: epoch 135, loss 0.3620513081550598, acc=0.9193333387374878, loss=0.3620513081550598
test: epoch 135, loss 1.4398369789123535, acc=0.42500001192092896, loss=1.4398369789123535
train: epoch 136, loss 0.37920716404914856, acc=0.9228888750076294, loss=0.37920716404914856
test: epoch 136, loss 1.4096271991729736, acc=0.42222222685813904, loss=1.4096271991729736
train: epoch 137, loss 0.38023585081100464, acc=0.9171666502952576, loss=0.38023585081100464
test: epoch 137, loss 1.4095927476882935, acc=0.4305555522441864, loss=1.4095927476882935
train: epoch 138, loss 0.3636626601219177, acc=0.9162777662277222, loss=0.3636626601219177
test: epoch 138, loss 1.4051735401153564, acc=0.43888887763023376, loss=1.4051735401153564
train: epoch 139, loss 0.3632853925228119, acc=0.9184444546699524, loss=0.3632853925228119
test: epoch 139, loss 1.416953682899475, acc=0.4194444417953491, loss=1.416953682899475
train: epoch 140, loss 0.36047807335853577, acc=0.9194999933242798, loss=0.36047807335853577
test: epoch 140, loss 1.4177080392837524, acc=0.44999998807907104, loss=1.4177080392837524
train: epoch 141, loss 0.38634562492370605, acc=0.9177777767181396, loss=0.38634562492370605
test: epoch 141, loss 1.3934903144836426, acc=0.43888887763023376, loss=1.3934903144836426
train: epoch 142, loss 0.3786063492298126, acc=0.9187777638435364, loss=0.3786063492298126
test: epoch 142, loss 1.435117244720459, acc=0.42222222685813904, loss=1.435117244720459
train: epoch 143, loss 0.3702707886695862, acc=0.9199444651603699, loss=0.3702707886695862
test: epoch 143, loss 1.4286606311798096, acc=0.4277777671813965, loss=1.4286606311798096
train: epoch 144, loss 0.3889620304107666, acc=0.9179444313049316, loss=0.3889620304107666
test: epoch 144, loss 1.4161081314086914, acc=0.43888887763023376, loss=1.4161081314086914
train: epoch 145, loss 0.36674582958221436, acc=0.9196110963821411, loss=0.36674582958221436
test: epoch 145, loss 1.4054306745529175, acc=0.43888887763023376, loss=1.4054306745529175
train: epoch 146, loss 0.37347644567489624, acc=0.9194444417953491, loss=0.37347644567489624
test: epoch 146, loss 1.3919378519058228, acc=0.44999998807907104, loss=1.3919378519058228
train: epoch 147, loss 0.34565094113349915, acc=0.9190000295639038, loss=0.34565094113349915
test: epoch 147, loss 1.36833655834198, acc=0.4444444477558136, loss=1.36833655834198
train: epoch 148, loss 0.3652501106262207, acc=0.9192777872085571, loss=0.3652501106262207
test: epoch 148, loss 1.3470226526260376, acc=0.44999998807907104, loss=1.3470226526260376
train: epoch 149, loss 0.3597184121608734, acc=0.9182778000831604, loss=0.3597184121608734
test: epoch 149, loss 1.3309707641601562, acc=0.46666666865348816, loss=1.3309707641601562
train: epoch 150, loss 0.37023982405662537, acc=0.9182222485542297, loss=0.37023982405662537
test: epoch 150, loss 1.3581056594848633, acc=0.45277777314186096, loss=1.3581056594848633
