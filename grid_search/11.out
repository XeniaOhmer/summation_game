# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=1", "--temp_decay=0.995", "--one_hot=1", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=1747714063, receiver_embed_dim=32, save_run=0, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1747714063, receiver_embed_dim=32, save_run=False, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.276069164276123, acc=0.05744444578886032, loss=3.276069164276123
test: epoch 1, loss 3.3584752082824707, acc=0.05833333358168602, loss=3.3584752082824707
train: epoch 2, loss 2.535306453704834, acc=0.13561111688613892, loss=2.535306453704834
test: epoch 2, loss 2.546379566192627, acc=0.13333334028720856, loss=2.546379566192627
train: epoch 3, loss 2.241000175476074, acc=0.18333333730697632, loss=2.241000175476074
test: epoch 3, loss 2.3348915576934814, acc=0.16111111640930176, loss=2.3348915576934814
train: epoch 4, loss 2.0218842029571533, acc=0.21938888728618622, loss=2.0218842029571533
test: epoch 4, loss 2.3853535652160645, acc=0.16111111640930176, loss=2.3853535652160645
train: epoch 5, loss 1.8750991821289062, acc=0.25833332538604736, loss=1.8750991821289062
test: epoch 5, loss 2.2420833110809326, acc=0.20555555820465088, loss=2.2420833110809326
train: epoch 6, loss 1.7528252601623535, acc=0.29872220754623413, loss=1.7528252601623535
test: epoch 6, loss 2.234182357788086, acc=0.2083333283662796, loss=2.234182357788086
train: epoch 7, loss 1.604990005493164, acc=0.3670555651187897, loss=1.604990005493164
test: epoch 7, loss 2.0332157611846924, acc=0.26944443583488464, loss=2.0332157611846924
train: epoch 8, loss 1.4516141414642334, acc=0.41438889503479004, loss=1.4516141414642334
test: epoch 8, loss 2.0077595710754395, acc=0.2611111104488373, loss=2.0077595710754395
train: epoch 9, loss 1.3651814460754395, acc=0.4536111056804657, loss=1.3651814460754395
test: epoch 9, loss 1.9177473783493042, acc=0.2777777910232544, loss=1.9177473783493042
train: epoch 10, loss 1.2308340072631836, acc=0.5029444694519043, loss=1.2308340072631836
test: epoch 10, loss 1.8034471273422241, acc=0.3027777671813965, loss=1.8034471273422241
train: epoch 11, loss 1.139710783958435, acc=0.535611093044281, loss=1.139710783958435
test: epoch 11, loss 1.7704631090164185, acc=0.3305555582046509, loss=1.7704631090164185
train: epoch 12, loss 1.0705721378326416, acc=0.5615555644035339, loss=1.0705721378326416
test: epoch 12, loss 1.5291450023651123, acc=0.3638888895511627, loss=1.5291450023651123
train: epoch 13, loss 1.0257993936538696, acc=0.5743333101272583, loss=1.0257993936538696
test: epoch 13, loss 1.7101490497589111, acc=0.3361110985279083, loss=1.7101490497589111
train: epoch 14, loss 0.9849984049797058, acc=0.5888888835906982, loss=0.9849984049797058
test: epoch 14, loss 1.552725911140442, acc=0.35277777910232544, loss=1.552725911140442
train: epoch 15, loss 0.9425452351570129, acc=0.6141111254692078, loss=0.9425452351570129
test: epoch 15, loss 1.6471378803253174, acc=0.3888888955116272, loss=1.6471378803253174
train: epoch 16, loss 0.9178746938705444, acc=0.6237778067588806, loss=0.9178746938705444
test: epoch 16, loss 1.4672845602035522, acc=0.43611112236976624, loss=1.4672845602035522
train: epoch 17, loss 0.8656659126281738, acc=0.6428889036178589, loss=0.8656659126281738
test: epoch 17, loss 1.3820465803146362, acc=0.4194444417953491, loss=1.3820465803146362
train: epoch 18, loss 0.8135638236999512, acc=0.6586111187934875, loss=0.8135638236999512
test: epoch 18, loss 1.560021996498108, acc=0.43888887763023376, loss=1.560021996498108
train: epoch 19, loss 0.8100494146347046, acc=0.6556666493415833, loss=0.8100494146347046
test: epoch 19, loss 1.3801600933074951, acc=0.4444444477558136, loss=1.3801600933074951
train: epoch 20, loss 0.7762061953544617, acc=0.6722777485847473, loss=0.7762061953544617
test: epoch 20, loss 1.5539685487747192, acc=0.40833333134651184, loss=1.5539685487747192
train: epoch 21, loss 0.766667366027832, acc=0.6768333315849304, loss=0.766667366027832
test: epoch 21, loss 1.4022122621536255, acc=0.4333333373069763, loss=1.4022122621536255
train: epoch 22, loss 0.7429603934288025, acc=0.6858888864517212, loss=0.7429603934288025
test: epoch 22, loss 1.1824091672897339, acc=0.4861111044883728, loss=1.1824091672897339
train: epoch 23, loss 0.6994767785072327, acc=0.7018333077430725, loss=0.6994767785072327
test: epoch 23, loss 1.4635285139083862, acc=0.4416666626930237, loss=1.4635285139083862
train: epoch 24, loss 0.6868991851806641, acc=0.7066666483879089, loss=0.6868991851806641
test: epoch 24, loss 1.3306838274002075, acc=0.4972222149372101, loss=1.3306838274002075
train: epoch 25, loss 0.6607262492179871, acc=0.7168889045715332, loss=0.6607262492179871
test: epoch 25, loss 1.5228402614593506, acc=0.46666666865348816, loss=1.5228402614593506
train: epoch 26, loss 0.6446051597595215, acc=0.7234444618225098, loss=0.6446051597595215
test: epoch 26, loss 1.4199507236480713, acc=0.43611112236976624, loss=1.4199507236480713
train: epoch 27, loss 0.6273064613342285, acc=0.730222225189209, loss=0.6273064613342285
test: epoch 27, loss 1.3603302240371704, acc=0.4722222089767456, loss=1.3603302240371704
train: epoch 28, loss 0.6190632581710815, acc=0.7325555682182312, loss=0.6190632581710815
test: epoch 28, loss 1.3361401557922363, acc=0.5083333253860474, loss=1.3361401557922363
train: epoch 29, loss 0.6093096137046814, acc=0.738277792930603, loss=0.6093096137046814
test: epoch 29, loss 1.3800837993621826, acc=0.49444442987442017, loss=1.3800837993621826
train: epoch 30, loss 0.6147446632385254, acc=0.7422778010368347, loss=0.6147446632385254
test: epoch 30, loss 1.2851519584655762, acc=0.4694444537162781, loss=1.2851519584655762
train: epoch 31, loss 0.5670221447944641, acc=0.7531111240386963, loss=0.5670221447944641
test: epoch 31, loss 1.407795786857605, acc=0.47777777910232544, loss=1.407795786857605
train: epoch 32, loss 0.6050694584846497, acc=0.7408888936042786, loss=0.6050694584846497
test: epoch 32, loss 1.2859439849853516, acc=0.4888888895511627, loss=1.2859439849853516
train: epoch 33, loss 0.5722401142120361, acc=0.7564444541931152, loss=0.5722401142120361
test: epoch 33, loss 1.250537395477295, acc=0.5, loss=1.250537395477295
train: epoch 34, loss 0.5713783502578735, acc=0.7570000290870667, loss=0.5713783502578735
test: epoch 34, loss 1.3510102033615112, acc=0.4833333194255829, loss=1.3510102033615112
train: epoch 35, loss 0.5538939833641052, acc=0.7713888883590698, loss=0.5538939833641052
test: epoch 35, loss 1.1991254091262817, acc=0.5138888955116272, loss=1.1991254091262817
train: epoch 36, loss 0.5448591113090515, acc=0.7717221975326538, loss=0.5448591113090515
test: epoch 36, loss 1.3141931295394897, acc=0.5111111402511597, loss=1.3141931295394897
train: epoch 37, loss 0.5263540744781494, acc=0.7788888812065125, loss=0.5263540744781494
test: epoch 37, loss 1.2756221294403076, acc=0.49166667461395264, loss=1.2756221294403076
train: epoch 38, loss 0.541118323802948, acc=0.7707222104072571, loss=0.541118323802948
test: epoch 38, loss 1.3551546335220337, acc=0.5083333253860474, loss=1.3551546335220337
train: epoch 39, loss 0.5455778241157532, acc=0.765500009059906, loss=0.5455778241157532
test: epoch 39, loss 1.337304949760437, acc=0.4861111044883728, loss=1.337304949760437
train: epoch 40, loss 0.5116768479347229, acc=0.781166672706604, loss=0.5116768479347229
test: epoch 40, loss 1.3796186447143555, acc=0.5305555462837219, loss=1.3796186447143555
train: epoch 41, loss 0.5265084505081177, acc=0.7756111025810242, loss=0.5265084505081177
test: epoch 41, loss 1.2192795276641846, acc=0.49444442987442017, loss=1.2192795276641846
train: epoch 42, loss 0.520948588848114, acc=0.7745555639266968, loss=0.520948588848114
test: epoch 42, loss 1.4886703491210938, acc=0.49444442987442017, loss=1.4886703491210938
train: epoch 43, loss 0.4933563470840454, acc=0.7854999899864197, loss=0.4933563470840454
test: epoch 43, loss 1.2519232034683228, acc=0.5249999761581421, loss=1.2519232034683228
train: epoch 44, loss 0.5139098167419434, acc=0.7778333425521851, loss=0.5139098167419434
test: epoch 44, loss 1.1028938293457031, acc=0.519444465637207, loss=1.1028938293457031
train: epoch 45, loss 0.5107137560844421, acc=0.7827222347259521, loss=0.5107137560844421
test: epoch 45, loss 1.3427525758743286, acc=0.5444444417953491, loss=1.3427525758743286
train: epoch 46, loss 0.4962938725948334, acc=0.7879444360733032, loss=0.4962938725948334
test: epoch 46, loss 1.2617747783660889, acc=0.5527777671813965, loss=1.2617747783660889
train: epoch 47, loss 0.48374542593955994, acc=0.7916666865348816, loss=0.48374542593955994
test: epoch 47, loss 1.1656968593597412, acc=0.5444444417953491, loss=1.1656968593597412
train: epoch 48, loss 0.4902472198009491, acc=0.7932222485542297, loss=0.4902472198009491
test: epoch 48, loss 1.2855188846588135, acc=0.5416666865348816, loss=1.2855188846588135
train: epoch 49, loss 0.4633769690990448, acc=0.8023889064788818, loss=0.4633769690990448
test: epoch 49, loss 1.2307302951812744, acc=0.5333333611488342, loss=1.2307302951812744
train: epoch 50, loss 0.48228272795677185, acc=0.7962222099304199, loss=0.48228272795677185
test: epoch 50, loss 1.2363046407699585, acc=0.5638889074325562, loss=1.2363046407699585
train: epoch 51, loss 0.46253201365470886, acc=0.7994999885559082, loss=0.46253201365470886
test: epoch 51, loss 1.1822665929794312, acc=0.5555555820465088, loss=1.1822665929794312
train: epoch 52, loss 0.4616985023021698, acc=0.8041666746139526, loss=0.4616985023021698
test: epoch 52, loss 1.328336477279663, acc=0.5611110925674438, loss=1.328336477279663
train: epoch 53, loss 0.4607682228088379, acc=0.8054999709129333, loss=0.4607682228088379
test: epoch 53, loss 1.2418041229248047, acc=0.5722222328186035, loss=1.2418041229248047
train: epoch 54, loss 0.4634268879890442, acc=0.8015000224113464, loss=0.4634268879890442
test: epoch 54, loss 1.1220110654830933, acc=0.5805555582046509, loss=1.1220110654830933
train: epoch 55, loss 0.47488877177238464, acc=0.8013333082199097, loss=0.47488877177238464
test: epoch 55, loss 1.1084688901901245, acc=0.5222222208976746, loss=1.1084688901901245
train: epoch 56, loss 0.45026782155036926, acc=0.8070555329322815, loss=0.45026782155036926
test: epoch 56, loss 1.1385905742645264, acc=0.5833333134651184, loss=1.1385905742645264
train: epoch 57, loss 0.4634948670864105, acc=0.8045555353164673, loss=0.4634948670864105
test: epoch 57, loss 1.1697349548339844, acc=0.5555555820465088, loss=1.1697349548339844
train: epoch 58, loss 0.4487060606479645, acc=0.8100555539131165, loss=0.4487060606479645
test: epoch 58, loss 1.2427223920822144, acc=0.5805555582046509, loss=1.2427223920822144
train: epoch 59, loss 0.45880091190338135, acc=0.8063889145851135, loss=0.45880091190338135
test: epoch 59, loss 1.1321405172348022, acc=0.5777778029441833, loss=1.1321405172348022
train: epoch 60, loss 0.44693776965141296, acc=0.8141111135482788, loss=0.44693776965141296
test: epoch 60, loss 1.0866672992706299, acc=0.5916666388511658, loss=1.0866672992706299
train: epoch 61, loss 0.4221269190311432, acc=0.8185555338859558, loss=0.4221269190311432
test: epoch 61, loss 1.082313895225525, acc=0.5722222328186035, loss=1.082313895225525
train: epoch 62, loss 0.4426642656326294, acc=0.8137221932411194, loss=0.4426642656326294
test: epoch 62, loss 1.040589451789856, acc=0.5944444537162781, loss=1.040589451789856
train: epoch 63, loss 0.44224298000335693, acc=0.8134999871253967, loss=0.44224298000335693
test: epoch 63, loss 1.0823286771774292, acc=0.605555534362793, loss=1.0823286771774292
train: epoch 64, loss 0.42490607500076294, acc=0.8177222013473511, loss=0.42490607500076294
test: epoch 64, loss 1.2033747434616089, acc=0.5972222089767456, loss=1.2033747434616089
train: epoch 65, loss 0.4264102578163147, acc=0.8212777972221375, loss=0.4264102578163147
test: epoch 65, loss 1.128596305847168, acc=0.605555534362793, loss=1.128596305847168
train: epoch 66, loss 0.4030303359031677, acc=0.8303333520889282, loss=0.4030303359031677
test: epoch 66, loss 1.1511180400848389, acc=0.6277777552604675, loss=1.1511180400848389
train: epoch 67, loss 0.435193806886673, acc=0.8181111216545105, loss=0.435193806886673
test: epoch 67, loss 1.0603725910186768, acc=0.6111111044883728, loss=1.0603725910186768
train: epoch 68, loss 0.4109087288379669, acc=0.8256666660308838, loss=0.4109087288379669
test: epoch 68, loss 0.9726375341415405, acc=0.605555534362793, loss=0.9726375341415405
train: epoch 69, loss 0.4327056407928467, acc=0.8162222504615784, loss=0.4327056407928467
test: epoch 69, loss 1.2145036458969116, acc=0.6166666746139526, loss=1.2145036458969116
train: epoch 70, loss 0.41784921288490295, acc=0.8250555396080017, loss=0.41784921288490295
test: epoch 70, loss 1.0518758296966553, acc=0.6333333253860474, loss=1.0518758296966553
train: epoch 71, loss 0.4207962453365326, acc=0.8230000138282776, loss=0.4207962453365326
test: epoch 71, loss 0.9842000603675842, acc=0.6555555462837219, loss=0.9842000603675842
train: epoch 72, loss 0.4035133123397827, acc=0.82833331823349, loss=0.4035133123397827
test: epoch 72, loss 1.1962724924087524, acc=0.5777778029441833, loss=1.1962724924087524
train: epoch 73, loss 0.41056540608406067, acc=0.8258888721466064, loss=0.41056540608406067
test: epoch 73, loss 1.2704716920852661, acc=0.6083333492279053, loss=1.2704716920852661
train: epoch 74, loss 0.41070425510406494, acc=0.8255000114440918, loss=0.41070425510406494
test: epoch 74, loss 1.119093894958496, acc=0.6111111044883728, loss=1.119093894958496
train: epoch 75, loss 0.3977949619293213, acc=0.8335555791854858, loss=0.3977949619293213
test: epoch 75, loss 1.1353718042373657, acc=0.6000000238418579, loss=1.1353718042373657
train: epoch 76, loss 0.403891384601593, acc=0.8286111354827881, loss=0.403891384601593
test: epoch 76, loss 1.1196833848953247, acc=0.5944444537162781, loss=1.1196833848953247
train: epoch 77, loss 0.3907889127731323, acc=0.8339999914169312, loss=0.3907889127731323
test: epoch 77, loss 0.9316548705101013, acc=0.6499999761581421, loss=0.9316548705101013
train: epoch 78, loss 0.43512675166130066, acc=0.8174444437026978, loss=0.43512675166130066
test: epoch 78, loss 1.2154557704925537, acc=0.574999988079071, loss=1.2154557704925537
train: epoch 79, loss 0.3992551267147064, acc=0.8307777643203735, loss=0.3992551267147064
test: epoch 79, loss 1.350774884223938, acc=0.5861111283302307, loss=1.350774884223938
train: epoch 80, loss 0.3828284740447998, acc=0.8360555768013, loss=0.3828284740447998
test: epoch 80, loss 1.081494688987732, acc=0.625, loss=1.081494688987732
train: epoch 81, loss 0.3830535411834717, acc=0.8373888731002808, loss=0.3830535411834717
test: epoch 81, loss 1.317571997642517, acc=0.6166666746139526, loss=1.317571997642517
train: epoch 82, loss 0.394379585981369, acc=0.8313888907432556, loss=0.394379585981369
test: epoch 82, loss 1.0662829875946045, acc=0.6499999761581421, loss=1.0662829875946045
train: epoch 83, loss 0.42010360956192017, acc=0.8209444284439087, loss=0.42010360956192017
test: epoch 83, loss 1.0268434286117554, acc=0.6194444298744202, loss=1.0268434286117554
train: epoch 84, loss 0.3850952684879303, acc=0.835777759552002, loss=0.3850952684879303
test: epoch 84, loss 1.071028709411621, acc=0.6222222447395325, loss=1.071028709411621
train: epoch 85, loss 0.38936710357666016, acc=0.8353888988494873, loss=0.38936710357666016
test: epoch 85, loss 1.1254321336746216, acc=0.6555555462837219, loss=1.1254321336746216
train: epoch 86, loss 0.39305010437965393, acc=0.8321666717529297, loss=0.39305010437965393
test: epoch 86, loss 1.0989181995391846, acc=0.6305555701255798, loss=1.0989181995391846
train: epoch 87, loss 0.3849066495895386, acc=0.8343333601951599, loss=0.3849066495895386
test: epoch 87, loss 1.1040118932724, acc=0.6138888597488403, loss=1.1040118932724
train: epoch 88, loss 0.381828635931015, acc=0.8325555324554443, loss=0.381828635931015
test: epoch 88, loss 1.0911482572555542, acc=0.6111111044883728, loss=1.0911482572555542
train: epoch 89, loss 0.3669261336326599, acc=0.8407222032546997, loss=0.3669261336326599
test: epoch 89, loss 1.1744533777236938, acc=0.6277777552604675, loss=1.1744533777236938
train: epoch 90, loss 0.3797077238559723, acc=0.8377777934074402, loss=0.3797077238559723
test: epoch 90, loss 1.1404807567596436, acc=0.6527777910232544, loss=1.1404807567596436
train: epoch 91, loss 0.38581782579421997, acc=0.8330555558204651, loss=0.38581782579421997
test: epoch 91, loss 1.173030138015747, acc=0.6194444298744202, loss=1.173030138015747
train: epoch 92, loss 0.36020609736442566, acc=0.8443889021873474, loss=0.36020609736442566
test: epoch 92, loss 1.1172503232955933, acc=0.6583333611488342, loss=1.1172503232955933
train: epoch 93, loss 0.3811206817626953, acc=0.8358333110809326, loss=0.3811206817626953
test: epoch 93, loss 1.0428675413131714, acc=0.6499999761581421, loss=1.0428675413131714
train: epoch 94, loss 0.3720014691352844, acc=0.839888870716095, loss=0.3720014691352844
test: epoch 94, loss 1.1802878379821777, acc=0.644444465637207, loss=1.1802878379821777
train: epoch 95, loss 0.36189785599708557, acc=0.8453333377838135, loss=0.36189785599708557
test: epoch 95, loss 1.1223293542861938, acc=0.6583333611488342, loss=1.1223293542861938
train: epoch 96, loss 0.3561874330043793, acc=0.8450000286102295, loss=0.3561874330043793
test: epoch 96, loss 1.4503965377807617, acc=0.6000000238418579, loss=1.4503965377807617
train: epoch 97, loss 0.39081403613090515, acc=0.835277795791626, loss=0.39081403613090515
test: epoch 97, loss 1.0799615383148193, acc=0.6333333253860474, loss=1.0799615383148193
train: epoch 98, loss 0.36250030994415283, acc=0.8434444665908813, loss=0.36250030994415283
test: epoch 98, loss 1.0164477825164795, acc=0.6333333253860474, loss=1.0164477825164795
train: epoch 99, loss 0.3545185625553131, acc=0.8451111316680908, loss=0.3545185625553131
test: epoch 99, loss 1.1077622175216675, acc=0.6416666507720947, loss=1.1077622175216675
train: epoch 100, loss 0.3565727174282074, acc=0.8475555777549744, loss=0.3565727174282074
test: epoch 100, loss 1.0809333324432373, acc=0.6583333611488342, loss=1.0809333324432373
train: epoch 101, loss 0.37042438983917236, acc=0.8402777910232544, loss=0.37042438983917236
test: epoch 101, loss 0.9920656085014343, acc=0.6583333611488342, loss=0.9920656085014343
train: epoch 102, loss 0.36621755361557007, acc=0.8414444327354431, loss=0.36621755361557007
test: epoch 102, loss 1.1260759830474854, acc=0.6416666507720947, loss=1.1260759830474854
train: epoch 103, loss 0.3716610372066498, acc=0.8383888602256775, loss=0.3716610372066498
test: epoch 103, loss 0.8800089955329895, acc=0.6472222208976746, loss=0.8800089955329895
train: epoch 104, loss 0.3679181635379791, acc=0.8429999947547913, loss=0.3679181635379791
test: epoch 104, loss 0.8961731195449829, acc=0.6583333611488342, loss=0.8961731195449829
train: epoch 105, loss 0.3510779142379761, acc=0.8447222113609314, loss=0.3510779142379761
test: epoch 105, loss 0.9822493195533752, acc=0.6583333611488342, loss=0.9822493195533752
train: epoch 106, loss 0.36295086145401, acc=0.8433333039283752, loss=0.36295086145401
test: epoch 106, loss 1.1606903076171875, acc=0.6277777552604675, loss=1.1606903076171875
train: epoch 107, loss 0.3647578954696655, acc=0.8420000076293945, loss=0.3647578954696655
test: epoch 107, loss 0.9605264067649841, acc=0.6472222208976746, loss=0.9605264067649841
train: epoch 108, loss 0.34472140669822693, acc=0.8469444513320923, loss=0.34472140669822693
test: epoch 108, loss 0.9465233683586121, acc=0.6583333611488342, loss=0.9465233683586121
train: epoch 109, loss 0.34428638219833374, acc=0.8473888635635376, loss=0.34428638219833374
test: epoch 109, loss 1.0454521179199219, acc=0.644444465637207, loss=1.0454521179199219
train: epoch 110, loss 0.3491048812866211, acc=0.8502777814865112, loss=0.3491048812866211
test: epoch 110, loss 1.316164493560791, acc=0.644444465637207, loss=1.316164493560791
train: epoch 111, loss 0.3737028241157532, acc=0.8419444561004639, loss=0.3737028241157532
test: epoch 111, loss 1.1091079711914062, acc=0.6305555701255798, loss=1.1091079711914062
train: epoch 112, loss 0.35580891370773315, acc=0.8461666703224182, loss=0.35580891370773315
test: epoch 112, loss 0.9660443663597107, acc=0.6527777910232544, loss=0.9660443663597107
train: epoch 113, loss 0.3636183738708496, acc=0.8405555486679077, loss=0.3636183738708496
test: epoch 113, loss 1.0867714881896973, acc=0.6416666507720947, loss=1.0867714881896973
train: epoch 114, loss 0.34546756744384766, acc=0.8485555648803711, loss=0.34546756744384766
test: epoch 114, loss 1.0175663232803345, acc=0.6583333611488342, loss=1.0175663232803345
train: epoch 115, loss 0.35971903800964355, acc=0.8430555462837219, loss=0.35971903800964355
test: epoch 115, loss 0.9871319532394409, acc=0.6555555462837219, loss=0.9871319532394409
train: epoch 116, loss 0.35212942957878113, acc=0.8477222323417664, loss=0.35212942957878113
test: epoch 116, loss 1.0272799730300903, acc=0.6583333611488342, loss=1.0272799730300903
train: epoch 117, loss 0.35720470547676086, acc=0.8429444432258606, loss=0.35720470547676086
test: epoch 117, loss 1.0834800004959106, acc=0.6583333611488342, loss=1.0834800004959106
train: epoch 118, loss 0.35100629925727844, acc=0.8444444537162781, loss=0.35100629925727844
test: epoch 118, loss 1.0245574712753296, acc=0.6611111164093018, loss=1.0245574712753296
train: epoch 119, loss 0.35626640915870667, acc=0.8453333377838135, loss=0.35626640915870667
test: epoch 119, loss 0.9058482050895691, acc=0.6583333611488342, loss=0.9058482050895691
train: epoch 120, loss 0.35578083992004395, acc=0.8430555462837219, loss=0.35578083992004395
test: epoch 120, loss 0.980107307434082, acc=0.6583333611488342, loss=0.980107307434082
train: epoch 121, loss 0.35444891452789307, acc=0.8460000157356262, loss=0.35444891452789307
test: epoch 121, loss 0.9299580454826355, acc=0.6583333611488342, loss=0.9299580454826355
train: epoch 122, loss 0.35237252712249756, acc=0.8454444408416748, loss=0.35237252712249756
test: epoch 122, loss 0.9506753087043762, acc=0.6583333611488342, loss=0.9506753087043762
train: epoch 123, loss 0.34362155199050903, acc=0.8495555520057678, loss=0.34362155199050903
test: epoch 123, loss 1.0259469747543335, acc=0.6583333611488342, loss=1.0259469747543335
train: epoch 124, loss 0.32854825258255005, acc=0.8539444208145142, loss=0.32854825258255005
test: epoch 124, loss 0.9462963938713074, acc=0.6583333611488342, loss=0.9462963938713074
train: epoch 125, loss 0.35173460841178894, acc=0.8481666445732117, loss=0.35173460841178894
test: epoch 125, loss 1.0014013051986694, acc=0.6555555462837219, loss=1.0014013051986694
train: epoch 126, loss 0.3381618559360504, acc=0.8514444231987, loss=0.3381618559360504
test: epoch 126, loss 1.1619644165039062, acc=0.6583333611488342, loss=1.1619644165039062
train: epoch 127, loss 0.34034615755081177, acc=0.8510555624961853, loss=0.34034615755081177
test: epoch 127, loss 1.0742287635803223, acc=0.6583333611488342, loss=1.0742287635803223
train: epoch 128, loss 0.3609418272972107, acc=0.8429999947547913, loss=0.3609418272972107
test: epoch 128, loss 0.9655493497848511, acc=0.6583333611488342, loss=0.9655493497848511
train: epoch 129, loss 0.3355669677257538, acc=0.8516111373901367, loss=0.3355669677257538
test: epoch 129, loss 1.1884773969650269, acc=0.6583333611488342, loss=1.1884773969650269
train: epoch 130, loss 0.34018445014953613, acc=0.8510555624961853, loss=0.34018445014953613
test: epoch 130, loss 1.0074515342712402, acc=0.6583333611488342, loss=1.0074515342712402
train: epoch 131, loss 0.350894033908844, acc=0.846833348274231, loss=0.350894033908844
test: epoch 131, loss 1.019514560699463, acc=0.6583333611488342, loss=1.019514560699463
train: epoch 132, loss 0.3448195159435272, acc=0.8476666808128357, loss=0.3448195159435272
test: epoch 132, loss 1.0625922679901123, acc=0.6583333611488342, loss=1.0625922679901123
train: epoch 133, loss 0.3370053172111511, acc=0.8517777919769287, loss=0.3370053172111511
test: epoch 133, loss 0.9558801651000977, acc=0.6666666865348816, loss=0.9558801651000977
train: epoch 134, loss 0.32840511202812195, acc=0.8531110882759094, loss=0.32840511202812195
test: epoch 134, loss 1.1077792644500732, acc=0.6583333611488342, loss=1.1077792644500732
train: epoch 135, loss 0.3374893367290497, acc=0.850944459438324, loss=0.3374893367290497
test: epoch 135, loss 0.9763225317001343, acc=0.6555555462837219, loss=0.9763225317001343
train: epoch 136, loss 0.3338709771633148, acc=0.8525555729866028, loss=0.3338709771633148
test: epoch 136, loss 1.1417559385299683, acc=0.6583333611488342, loss=1.1417559385299683
train: epoch 137, loss 0.3312491476535797, acc=0.8522777557373047, loss=0.3312491476535797
test: epoch 137, loss 1.0039414167404175, acc=0.6583333611488342, loss=1.0039414167404175
train: epoch 138, loss 0.34869185090065, acc=0.8467777967453003, loss=0.34869185090065
test: epoch 138, loss 0.9377492666244507, acc=0.6583333611488342, loss=0.9377492666244507
train: epoch 139, loss 0.33286252617836, acc=0.8538888692855835, loss=0.33286252617836
test: epoch 139, loss 1.0745444297790527, acc=0.6583333611488342, loss=1.0745444297790527
train: epoch 140, loss 0.33323389291763306, acc=0.8515555262565613, loss=0.33323389291763306
test: epoch 140, loss 1.075669765472412, acc=0.6583333611488342, loss=1.075669765472412
train: epoch 141, loss 0.3408612906932831, acc=0.8491111397743225, loss=0.3408612906932831
test: epoch 141, loss 1.0665147304534912, acc=0.6583333611488342, loss=1.0665147304534912
train: epoch 142, loss 0.3251509666442871, acc=0.8556666374206543, loss=0.3251509666442871
test: epoch 142, loss 1.0839581489562988, acc=0.6555555462837219, loss=1.0839581489562988
train: epoch 143, loss 0.33276012539863586, acc=0.8532778024673462, loss=0.33276012539863586
test: epoch 143, loss 1.0572500228881836, acc=0.6583333611488342, loss=1.0572500228881836
train: epoch 144, loss 0.33444488048553467, acc=0.852222204208374, loss=0.33444488048553467
test: epoch 144, loss 0.9542268514633179, acc=0.6666666865348816, loss=0.9542268514633179
train: epoch 145, loss 0.3298453092575073, acc=0.8528888821601868, loss=0.3298453092575073
test: epoch 145, loss 0.9843058586120605, acc=0.6583333611488342, loss=0.9843058586120605
train: epoch 146, loss 0.33726248145103455, acc=0.8502777814865112, loss=0.33726248145103455
test: epoch 146, loss 1.0776066780090332, acc=0.6583333611488342, loss=1.0776066780090332
train: epoch 147, loss 0.33030804991722107, acc=0.8552777767181396, loss=0.33030804991722107
test: epoch 147, loss 1.0146366357803345, acc=0.6583333611488342, loss=1.0146366357803345
train: epoch 148, loss 0.3331192135810852, acc=0.8515555262565613, loss=0.3331192135810852
test: epoch 148, loss 1.062689185142517, acc=0.6583333611488342, loss=1.062689185142517
train: epoch 149, loss 0.3272848427295685, acc=0.8543888926506042, loss=0.3272848427295685
test: epoch 149, loss 1.107667088508606, acc=0.6583333611488342, loss=1.107667088508606
train: epoch 150, loss 0.32945215702056885, acc=0.8543333411216736, loss=0.32945215702056885
test: epoch 150, loss 1.0702043771743774, acc=0.6583333611488342, loss=1.0702043771743774
