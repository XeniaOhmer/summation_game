# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=1", "--one_hot=0", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=1395800558, receiver_embed_dim=32, save_run=0, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=1395800558, receiver_embed_dim=32, save_run=False, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.6306979656219482, acc=0.14933332800865173, loss=2.6306979656219482
test: epoch 1, loss 6.879855632781982, acc=0.05000000074505806, loss=6.879855632781982
train: epoch 2, loss 1.9293334484100342, acc=0.2789444327354431, loss=1.9293334484100342
test: epoch 2, loss 7.96129846572876, acc=0.03888889029622078, loss=7.96129846572876
train: epoch 3, loss 1.6721198558807373, acc=0.3488888740539551, loss=1.6721198558807373
test: epoch 3, loss 7.696338653564453, acc=0.06111111119389534, loss=7.696338653564453
train: epoch 4, loss 1.510385274887085, acc=0.40261110663414, loss=1.510385274887085
test: epoch 4, loss 8.051342010498047, acc=0.04444444552063942, loss=8.051342010498047
train: epoch 5, loss 1.3993569612503052, acc=0.4368889033794403, loss=1.3993569612503052
test: epoch 5, loss 8.664436340332031, acc=0.04444444552063942, loss=8.664436340332031
train: epoch 6, loss 1.308194875717163, acc=0.4754444360733032, loss=1.308194875717163
test: epoch 6, loss 8.679828643798828, acc=0.06111111119389534, loss=8.679828643798828
train: epoch 7, loss 1.2369364500045776, acc=0.507888913154602, loss=1.2369364500045776
test: epoch 7, loss 8.994776725769043, acc=0.05277777835726738, loss=8.994776725769043
train: epoch 8, loss 1.167720913887024, acc=0.5355555415153503, loss=1.167720913887024
test: epoch 8, loss 7.987586975097656, acc=0.10000000149011612, loss=7.987586975097656
train: epoch 9, loss 1.1196072101593018, acc=0.5531111359596252, loss=1.1196072101593018
test: epoch 9, loss 9.020374298095703, acc=0.06666667014360428, loss=9.020374298095703
train: epoch 10, loss 1.0775655508041382, acc=0.5747777819633484, loss=1.0775655508041382
test: epoch 10, loss 7.938316822052002, acc=0.10000000149011612, loss=7.938316822052002
train: epoch 11, loss 1.0442602634429932, acc=0.5855000019073486, loss=1.0442602634429932
test: epoch 11, loss 9.120840072631836, acc=0.09444444626569748, loss=9.120840072631836
train: epoch 12, loss 1.006925344467163, acc=0.6049444675445557, loss=1.006925344467163
test: epoch 12, loss 9.289626121520996, acc=0.0694444477558136, loss=9.289626121520996
train: epoch 13, loss 0.9737691879272461, acc=0.6232777833938599, loss=0.9737691879272461
test: epoch 13, loss 9.089109420776367, acc=0.09166666865348816, loss=9.089109420776367
train: epoch 14, loss 0.9506021738052368, acc=0.6297222375869751, loss=0.9506021738052368
test: epoch 14, loss 8.968667030334473, acc=0.1111111119389534, loss=8.968667030334473
train: epoch 15, loss 0.9281442165374756, acc=0.6409444212913513, loss=0.9281442165374756
test: epoch 15, loss 9.920852661132812, acc=0.0833333358168602, loss=9.920852661132812
train: epoch 16, loss 0.8919110894203186, acc=0.6557777523994446, loss=0.8919110894203186
test: epoch 16, loss 9.612467765808105, acc=0.08888889104127884, loss=9.612467765808105
train: epoch 17, loss 0.8694350123405457, acc=0.6612222194671631, loss=0.8694350123405457
test: epoch 17, loss 10.174832344055176, acc=0.09444444626569748, loss=10.174832344055176
train: epoch 18, loss 0.8478167653083801, acc=0.6738333106040955, loss=0.8478167653083801
test: epoch 18, loss 8.534894943237305, acc=0.0972222238779068, loss=8.534894943237305
train: epoch 19, loss 0.8308720588684082, acc=0.6784999966621399, loss=0.8308720588684082
test: epoch 19, loss 10.046134948730469, acc=0.11944444477558136, loss=10.046134948730469
train: epoch 20, loss 0.8275891542434692, acc=0.6869999766349792, loss=0.8275891542434692
test: epoch 20, loss 9.126603126525879, acc=0.08055555820465088, loss=9.126603126525879
train: epoch 21, loss 0.7917128801345825, acc=0.6971111297607422, loss=0.7917128801345825
test: epoch 21, loss 10.34715747833252, acc=0.09444444626569748, loss=10.34715747833252
train: epoch 22, loss 0.7674195170402527, acc=0.7109444737434387, loss=0.7674195170402527
test: epoch 22, loss 10.374640464782715, acc=0.11388888955116272, loss=10.374640464782715
train: epoch 23, loss 0.756157636642456, acc=0.7088888883590698, loss=0.756157636642456
test: epoch 23, loss 9.768458366394043, acc=0.0972222238779068, loss=9.768458366394043
train: epoch 24, loss 0.7433717250823975, acc=0.7131111025810242, loss=0.7433717250823975
test: epoch 24, loss 9.454821586608887, acc=0.07777778059244156, loss=9.454821586608887
train: epoch 25, loss 0.7207390666007996, acc=0.7289999723434448, loss=0.7207390666007996
test: epoch 25, loss 9.595528602600098, acc=0.10833333432674408, loss=9.595528602600098
train: epoch 26, loss 0.7025327086448669, acc=0.7316666841506958, loss=0.7025327086448669
test: epoch 26, loss 9.249692916870117, acc=0.08888889104127884, loss=9.249692916870117
train: epoch 27, loss 0.7032071352005005, acc=0.7353333234786987, loss=0.7032071352005005
test: epoch 27, loss 9.166332244873047, acc=0.10833333432674408, loss=9.166332244873047
train: epoch 28, loss 0.6794869303703308, acc=0.7424444556236267, loss=0.6794869303703308
test: epoch 28, loss 10.710914611816406, acc=0.05833333358168602, loss=10.710914611816406
train: epoch 29, loss 0.6695164442062378, acc=0.7447777986526489, loss=0.6695164442062378
test: epoch 29, loss 10.140915870666504, acc=0.09444444626569748, loss=10.140915870666504
train: epoch 30, loss 0.6680863499641418, acc=0.7510555386543274, loss=0.6680863499641418
test: epoch 30, loss 8.951180458068848, acc=0.12777778506278992, loss=8.951180458068848
train: epoch 31, loss 0.6819884181022644, acc=0.7514444589614868, loss=0.6819884181022644
test: epoch 31, loss 9.095806121826172, acc=0.0833333358168602, loss=9.095806121826172
train: epoch 32, loss 0.6415358185768127, acc=0.7638333439826965, loss=0.6415358185768127
test: epoch 32, loss 10.14023208618164, acc=0.07777778059244156, loss=10.14023208618164
train: epoch 33, loss 0.6312615275382996, acc=0.7630555629730225, loss=0.6312615275382996
test: epoch 33, loss 10.26672077178955, acc=0.14444445073604584, loss=10.26672077178955
train: epoch 34, loss 0.6215708255767822, acc=0.769444465637207, loss=0.6215708255767822
test: epoch 34, loss 9.160113334655762, acc=0.07777778059244156, loss=9.160113334655762
train: epoch 35, loss 0.6081136465072632, acc=0.7726110816001892, loss=0.6081136465072632
test: epoch 35, loss 8.621179580688477, acc=0.08611111342906952, loss=8.621179580688477
train: epoch 36, loss 0.6038137078285217, acc=0.773722231388092, loss=0.6038137078285217
test: epoch 36, loss 9.360315322875977, acc=0.10833333432674408, loss=9.360315322875977
train: epoch 37, loss 0.5983834266662598, acc=0.7803888916969299, loss=0.5983834266662598
test: epoch 37, loss 10.179025650024414, acc=0.07500000298023224, loss=10.179025650024414
train: epoch 38, loss 0.5985753536224365, acc=0.7757777571678162, loss=0.5985753536224365
test: epoch 38, loss 8.897933006286621, acc=0.0972222238779068, loss=8.897933006286621
train: epoch 39, loss 0.5870122313499451, acc=0.7851666808128357, loss=0.5870122313499451
test: epoch 39, loss 9.108951568603516, acc=0.11388888955116272, loss=9.108951568603516
train: epoch 40, loss 0.5765852332115173, acc=0.7926666736602783, loss=0.5765852332115173
test: epoch 40, loss 9.354125022888184, acc=0.13611111044883728, loss=9.354125022888184
train: epoch 41, loss 0.5634554624557495, acc=0.7933333516120911, loss=0.5634554624557495
test: epoch 41, loss 8.895423889160156, acc=0.14444445073604584, loss=8.895423889160156
train: epoch 42, loss 0.5564245581626892, acc=0.7933889031410217, loss=0.5564245581626892
test: epoch 42, loss 9.052961349487305, acc=0.11388888955116272, loss=9.052961349487305
train: epoch 43, loss 0.5670576095581055, acc=0.7915555834770203, loss=0.5670576095581055
test: epoch 43, loss 9.388471603393555, acc=0.13333334028720856, loss=9.388471603393555
train: epoch 44, loss 0.5471869111061096, acc=0.7974444627761841, loss=0.5471869111061096
test: epoch 44, loss 9.99993896484375, acc=0.12222222238779068, loss=9.99993896484375
train: epoch 45, loss 0.5441204905509949, acc=0.7991666793823242, loss=0.5441204905509949
test: epoch 45, loss 10.037178993225098, acc=0.04444444552063942, loss=10.037178993225098
train: epoch 46, loss 0.5303645730018616, acc=0.8060555458068848, loss=0.5303645730018616
test: epoch 46, loss 9.991072654724121, acc=0.10000000149011612, loss=9.991072654724121
train: epoch 47, loss 0.5472348928451538, acc=0.800166666507721, loss=0.5472348928451538
test: epoch 47, loss 9.910720825195312, acc=0.0833333358168602, loss=9.910720825195312
train: epoch 48, loss 0.5144472122192383, acc=0.8116111159324646, loss=0.5144472122192383
test: epoch 48, loss 8.744271278381348, acc=0.07777778059244156, loss=8.744271278381348
train: epoch 49, loss 0.5188856720924377, acc=0.8075000047683716, loss=0.5188856720924377
test: epoch 49, loss 10.323509216308594, acc=0.07500000298023224, loss=10.323509216308594
train: epoch 50, loss 0.5215213298797607, acc=0.805388867855072, loss=0.5215213298797607
test: epoch 50, loss 8.89827823638916, acc=0.08611111342906952, loss=8.89827823638916
train: epoch 51, loss 0.5127624273300171, acc=0.8119444251060486, loss=0.5127624273300171
test: epoch 51, loss 7.958279132843018, acc=0.0555555559694767, loss=7.958279132843018
train: epoch 52, loss 0.5119889378547668, acc=0.8138333559036255, loss=0.5119889378547668
test: epoch 52, loss 9.107566833496094, acc=0.10277777910232544, loss=9.107566833496094
train: epoch 53, loss 0.4856410324573517, acc=0.8254444599151611, loss=0.4856410324573517
test: epoch 53, loss 8.561641693115234, acc=0.0972222238779068, loss=8.561641693115234
train: epoch 54, loss 0.49471235275268555, acc=0.81977778673172, loss=0.49471235275268555
test: epoch 54, loss 10.327526092529297, acc=0.11666666716337204, loss=10.327526092529297
train: epoch 55, loss 0.48903390765190125, acc=0.8213889002799988, loss=0.48903390765190125
test: epoch 55, loss 9.700525283813477, acc=0.08888889104127884, loss=9.700525283813477
train: epoch 56, loss 0.49652978777885437, acc=0.8253333568572998, loss=0.49652978777885437
test: epoch 56, loss 9.894149780273438, acc=0.09166666865348816, loss=9.894149780273438
train: epoch 57, loss 0.48220518231391907, acc=0.824055552482605, loss=0.48220518231391907
test: epoch 57, loss 8.979989051818848, acc=0.09166666865348816, loss=8.979989051818848
train: epoch 58, loss 0.46445298194885254, acc=0.832111120223999, loss=0.46445298194885254
test: epoch 58, loss 7.910928249359131, acc=0.17222222685813904, loss=7.910928249359131
train: epoch 59, loss 0.47494447231292725, acc=0.8292222023010254, loss=0.47494447231292725
test: epoch 59, loss 9.02127456665039, acc=0.09166666865348816, loss=9.02127456665039
train: epoch 60, loss 0.470600426197052, acc=0.8320000171661377, loss=0.470600426197052
test: epoch 60, loss 8.639605522155762, acc=0.05000000074505806, loss=8.639605522155762
train: epoch 61, loss 0.4606013894081116, acc=0.8362777829170227, loss=0.4606013894081116
test: epoch 61, loss 7.0300703048706055, acc=0.10000000149011612, loss=7.0300703048706055
train: epoch 62, loss 0.4776102304458618, acc=0.8277222514152527, loss=0.4776102304458618
test: epoch 62, loss 7.966424942016602, acc=0.10000000149011612, loss=7.966424942016602
train: epoch 63, loss 0.45085468888282776, acc=0.8386111259460449, loss=0.45085468888282776
test: epoch 63, loss 8.972725868225098, acc=0.13055555522441864, loss=8.972725868225098
train: epoch 64, loss 0.4431000351905823, acc=0.8388888835906982, loss=0.4431000351905823
test: epoch 64, loss 7.5856242179870605, acc=0.10277777910232544, loss=7.5856242179870605
train: epoch 65, loss 0.4472757577896118, acc=0.8350555300712585, loss=0.4472757577896118
test: epoch 65, loss 9.638489723205566, acc=0.08888889104127884, loss=9.638489723205566
train: epoch 66, loss 0.44711294770240784, acc=0.8397777676582336, loss=0.44711294770240784
test: epoch 66, loss 8.252936363220215, acc=0.15555556118488312, loss=8.252936363220215
train: epoch 67, loss 0.4320860803127289, acc=0.8437222242355347, loss=0.4320860803127289
test: epoch 67, loss 8.218721389770508, acc=0.11666666716337204, loss=8.218721389770508
train: epoch 68, loss 0.42268475890159607, acc=0.8468888998031616, loss=0.42268475890159607
test: epoch 68, loss 7.475236892700195, acc=0.10000000149011612, loss=7.475236892700195
train: epoch 69, loss 0.426148384809494, acc=0.8445555567741394, loss=0.426148384809494
test: epoch 69, loss 7.264368057250977, acc=0.10555555671453476, loss=7.264368057250977
train: epoch 70, loss 0.43099337816238403, acc=0.8444444537162781, loss=0.43099337816238403
test: epoch 70, loss 12.402083396911621, acc=0.1111111119389534, loss=12.402083396911621
train: epoch 71, loss 0.4235471189022064, acc=0.8504999876022339, loss=0.4235471189022064
test: epoch 71, loss 7.616715908050537, acc=0.06388889253139496, loss=7.616715908050537
train: epoch 72, loss 0.4185768961906433, acc=0.848111093044281, loss=0.4185768961906433
test: epoch 72, loss 7.712917804718018, acc=0.09166666865348816, loss=7.712917804718018
train: epoch 73, loss 0.4188220500946045, acc=0.8473888635635376, loss=0.4188220500946045
test: epoch 73, loss 8.265528678894043, acc=0.09444444626569748, loss=8.265528678894043
train: epoch 74, loss 0.4183960556983948, acc=0.847611129283905, loss=0.4183960556983948
test: epoch 74, loss 7.766908168792725, acc=0.0694444477558136, loss=7.766908168792725
train: epoch 75, loss 0.416299968957901, acc=0.8488333225250244, loss=0.416299968957901
test: epoch 75, loss 8.475616455078125, acc=0.08055555820465088, loss=8.475616455078125
train: epoch 76, loss 0.4120695888996124, acc=0.8510000109672546, loss=0.4120695888996124
test: epoch 76, loss 9.550065040588379, acc=0.04444444552063942, loss=9.550065040588379
train: epoch 77, loss 0.414485901594162, acc=0.8557778000831604, loss=0.414485901594162
test: epoch 77, loss 8.436944961547852, acc=0.10833333432674408, loss=8.436944961547852
train: epoch 78, loss 0.4070329964160919, acc=0.855055570602417, loss=0.4070329964160919
test: epoch 78, loss 8.3572998046875, acc=0.0416666679084301, loss=8.3572998046875
train: epoch 79, loss 0.4032599925994873, acc=0.8563888669013977, loss=0.4032599925994873
test: epoch 79, loss 6.605926036834717, acc=0.09166666865348816, loss=6.605926036834717
train: epoch 80, loss 0.38958653807640076, acc=0.8649444580078125, loss=0.38958653807640076
test: epoch 80, loss 8.746356010437012, acc=0.08055555820465088, loss=8.746356010437012
train: epoch 81, loss 0.3830428123474121, acc=0.8619444370269775, loss=0.3830428123474121
test: epoch 81, loss 6.568307876586914, acc=0.08888889104127884, loss=6.568307876586914
train: epoch 82, loss 0.39695075154304504, acc=0.8573889136314392, loss=0.39695075154304504
test: epoch 82, loss 8.7327241897583, acc=0.13611111044883728, loss=8.7327241897583
train: epoch 83, loss 0.3813782036304474, acc=0.8637222051620483, loss=0.3813782036304474
test: epoch 83, loss 8.459375381469727, acc=0.07222222536802292, loss=8.459375381469727
train: epoch 84, loss 0.3867131173610687, acc=0.8627222180366516, loss=0.3867131173610687
test: epoch 84, loss 4.948465347290039, acc=0.17222222685813904, loss=4.948465347290039
train: epoch 85, loss 0.3776644468307495, acc=0.8629999756813049, loss=0.3776644468307495
test: epoch 85, loss 7.849035739898682, acc=0.12777778506278992, loss=7.849035739898682
train: epoch 86, loss 0.3736003339290619, acc=0.8672778010368347, loss=0.3736003339290619
test: epoch 86, loss 7.904778003692627, acc=0.10555555671453476, loss=7.904778003692627
train: epoch 87, loss 0.37532564997673035, acc=0.8699444532394409, loss=0.37532564997673035
test: epoch 87, loss 7.190832614898682, acc=0.13055555522441864, loss=7.190832614898682
train: epoch 88, loss 0.35587170720100403, acc=0.8737221956253052, loss=0.35587170720100403
test: epoch 88, loss 6.518025875091553, acc=0.13055555522441864, loss=6.518025875091553
train: epoch 89, loss 0.37602102756500244, acc=0.866944432258606, loss=0.37602102756500244
test: epoch 89, loss 8.25648021697998, acc=0.12222222238779068, loss=8.25648021697998
train: epoch 90, loss 0.3600641191005707, acc=0.8739444613456726, loss=0.3600641191005707
test: epoch 90, loss 6.76127815246582, acc=0.10833333432674408, loss=6.76127815246582
train: epoch 91, loss 0.35749533772468567, acc=0.8717777729034424, loss=0.35749533772468567
test: epoch 91, loss 7.906166076660156, acc=0.125, loss=7.906166076660156
train: epoch 92, loss 0.3579096794128418, acc=0.8732777833938599, loss=0.3579096794128418
test: epoch 92, loss 7.252251625061035, acc=0.08055555820465088, loss=7.252251625061035
train: epoch 93, loss 0.34953978657722473, acc=0.8782777786254883, loss=0.34953978657722473
test: epoch 93, loss 5.838802814483643, acc=0.14444445073604584, loss=5.838802814483643
train: epoch 94, loss 0.33507370948791504, acc=0.8777222037315369, loss=0.33507370948791504
test: epoch 94, loss 9.937904357910156, acc=0.10277777910232544, loss=9.937904357910156
train: epoch 95, loss 0.34448865056037903, acc=0.8757222294807434, loss=0.34448865056037903
test: epoch 95, loss 6.024855613708496, acc=0.08611111342906952, loss=6.024855613708496
train: epoch 96, loss 0.35248851776123047, acc=0.8777777552604675, loss=0.35248851776123047
test: epoch 96, loss 5.097174644470215, acc=0.11388888955116272, loss=5.097174644470215
train: epoch 97, loss 0.3294997811317444, acc=0.8827221989631653, loss=0.3294997811317444
test: epoch 97, loss 6.226531505584717, acc=0.10555555671453476, loss=6.226531505584717
train: epoch 98, loss 0.34635481238365173, acc=0.879111111164093, loss=0.34635481238365173
test: epoch 98, loss 8.44917106628418, acc=0.07222222536802292, loss=8.44917106628418
train: epoch 99, loss 0.3367299735546112, acc=0.8821666836738586, loss=0.3367299735546112
test: epoch 99, loss 7.271399021148682, acc=0.06111111119389534, loss=7.271399021148682
train: epoch 100, loss 0.326111763715744, acc=0.8841111063957214, loss=0.326111763715744
test: epoch 100, loss 6.618143081665039, acc=0.1388888955116272, loss=6.618143081665039
train: epoch 101, loss 0.3318740129470825, acc=0.8847222328186035, loss=0.3318740129470825
test: epoch 101, loss 6.747030258178711, acc=0.0694444477558136, loss=6.747030258178711
train: epoch 102, loss 0.3205088675022125, acc=0.8872222304344177, loss=0.3205088675022125
test: epoch 102, loss 6.9412336349487305, acc=0.13333334028720856, loss=6.9412336349487305
train: epoch 103, loss 0.3201526701450348, acc=0.8846111297607422, loss=0.3201526701450348
test: epoch 103, loss 6.8434553146362305, acc=0.0833333358168602, loss=6.8434553146362305
train: epoch 104, loss 0.31166690587997437, acc=0.8902222514152527, loss=0.31166690587997437
test: epoch 104, loss 6.674241065979004, acc=0.0972222238779068, loss=6.674241065979004
train: epoch 105, loss 0.3250824511051178, acc=0.882444441318512, loss=0.3250824511051178
test: epoch 105, loss 5.806373596191406, acc=0.07222222536802292, loss=5.806373596191406
train: epoch 106, loss 0.30280816555023193, acc=0.8903889060020447, loss=0.30280816555023193
test: epoch 106, loss 6.45940637588501, acc=0.06388889253139496, loss=6.45940637588501
train: epoch 107, loss 0.3057843744754791, acc=0.891777753829956, loss=0.3057843744754791
test: epoch 107, loss 7.110598564147949, acc=0.06111111119389534, loss=7.110598564147949
train: epoch 108, loss 0.31056132912635803, acc=0.8891666531562805, loss=0.31056132912635803
test: epoch 108, loss 7.13897180557251, acc=0.12222222238779068, loss=7.13897180557251
train: epoch 109, loss 0.30270496010780334, acc=0.8945000171661377, loss=0.30270496010780334
test: epoch 109, loss 7.348847389221191, acc=0.06388889253139496, loss=7.348847389221191
train: epoch 110, loss 0.30254682898521423, acc=0.8941110968589783, loss=0.30254682898521423
test: epoch 110, loss 7.750762462615967, acc=0.05000000074505806, loss=7.750762462615967
train: epoch 111, loss 0.29728931188583374, acc=0.8960000276565552, loss=0.29728931188583374
test: epoch 111, loss 7.036303997039795, acc=0.12222222238779068, loss=7.036303997039795
train: epoch 112, loss 0.3123028576374054, acc=0.8911666870117188, loss=0.3123028576374054
test: epoch 112, loss 6.595198631286621, acc=0.07500000298023224, loss=6.595198631286621
train: epoch 113, loss 0.3084292411804199, acc=0.8923888802528381, loss=0.3084292411804199
test: epoch 113, loss 4.827015399932861, acc=0.13333334028720856, loss=4.827015399932861
train: epoch 114, loss 0.3031764030456543, acc=0.8949999809265137, loss=0.3031764030456543
test: epoch 114, loss 6.557569980621338, acc=0.1388888955116272, loss=6.557569980621338
train: epoch 115, loss 0.2947739064693451, acc=0.8984444737434387, loss=0.2947739064693451
test: epoch 115, loss 7.973995208740234, acc=0.06111111119389534, loss=7.973995208740234
train: epoch 116, loss 0.2945029139518738, acc=0.8994444608688354, loss=0.2945029139518738
test: epoch 116, loss 6.287067413330078, acc=0.10277777910232544, loss=6.287067413330078
train: epoch 117, loss 0.2937031388282776, acc=0.8993889093399048, loss=0.2937031388282776
test: epoch 117, loss 5.876661777496338, acc=0.125, loss=5.876661777496338
train: epoch 118, loss 0.29180797934532166, acc=0.8987777829170227, loss=0.29180797934532166
test: epoch 118, loss 7.298794269561768, acc=0.14722222089767456, loss=7.298794269561768
train: epoch 119, loss 0.2869119346141815, acc=0.9005555510520935, loss=0.2869119346141815
test: epoch 119, loss 5.061712741851807, acc=0.18611110746860504, loss=5.061712741851807
train: epoch 120, loss 0.27801913022994995, acc=0.9051666855812073, loss=0.27801913022994995
test: epoch 120, loss 8.916933059692383, acc=0.05833333358168602, loss=8.916933059692383
train: epoch 121, loss 0.2924789488315582, acc=0.8980000019073486, loss=0.2924789488315582
test: epoch 121, loss 7.18065071105957, acc=0.11666666716337204, loss=7.18065071105957
train: epoch 122, loss 0.2760993242263794, acc=0.9070000052452087, loss=0.2760993242263794
test: epoch 122, loss 5.263682842254639, acc=0.13333334028720856, loss=5.263682842254639
train: epoch 123, loss 0.2850438356399536, acc=0.9032777547836304, loss=0.2850438356399536
test: epoch 123, loss 7.575033187866211, acc=0.07777778059244156, loss=7.575033187866211
train: epoch 124, loss 0.27427515387535095, acc=0.9033889174461365, loss=0.27427515387535095
test: epoch 124, loss 6.804614543914795, acc=0.14166666567325592, loss=6.804614543914795
train: epoch 125, loss 0.2738223373889923, acc=0.905055582523346, loss=0.2738223373889923
test: epoch 125, loss 4.390322208404541, acc=0.20277777314186096, loss=4.390322208404541
train: epoch 126, loss 0.27620428800582886, acc=0.9053333401679993, loss=0.27620428800582886
test: epoch 126, loss 6.8430070877075195, acc=0.1666666716337204, loss=6.8430070877075195
train: epoch 127, loss 0.25252586603164673, acc=0.9123333096504211, loss=0.25252586603164673
test: epoch 127, loss 6.493967056274414, acc=0.13611111044883728, loss=6.493967056274414
train: epoch 128, loss 0.2557315528392792, acc=0.9130555391311646, loss=0.2557315528392792
test: epoch 128, loss 5.087021350860596, acc=0.13055555522441864, loss=5.087021350860596
train: epoch 129, loss 0.261152446269989, acc=0.9083333611488342, loss=0.261152446269989
test: epoch 129, loss 9.255928993225098, acc=0.14166666567325592, loss=9.255928993225098
train: epoch 130, loss 0.2632490396499634, acc=0.9113333225250244, loss=0.2632490396499634
test: epoch 130, loss 5.211864471435547, acc=0.17222222685813904, loss=5.211864471435547
train: epoch 131, loss 0.25664475560188293, acc=0.9113888740539551, loss=0.25664475560188293
test: epoch 131, loss 4.807342529296875, acc=0.19166666269302368, loss=4.807342529296875
train: epoch 132, loss 0.2611151933670044, acc=0.9092222452163696, loss=0.2611151933670044
test: epoch 132, loss 8.36949348449707, acc=0.06111111119389534, loss=8.36949348449707
train: epoch 133, loss 0.28283312916755676, acc=0.9055555462837219, loss=0.28283312916755676
test: epoch 133, loss 6.3470964431762695, acc=0.14722222089767456, loss=6.3470964431762695
train: epoch 134, loss 0.23338226974010468, acc=0.9199444651603699, loss=0.23338226974010468
test: epoch 134, loss 7.497321605682373, acc=0.15000000596046448, loss=7.497321605682373
train: epoch 135, loss 0.2589564025402069, acc=0.909333348274231, loss=0.2589564025402069
test: epoch 135, loss 5.171167850494385, acc=0.1388888955116272, loss=5.171167850494385
train: epoch 136, loss 0.2759602665901184, acc=0.9108889102935791, loss=0.2759602665901184
test: epoch 136, loss 5.522069931030273, acc=0.13333334028720856, loss=5.522069931030273
train: epoch 137, loss 0.24523624777793884, acc=0.9162222146987915, loss=0.24523624777793884
test: epoch 137, loss 6.257283687591553, acc=0.1944444477558136, loss=6.257283687591553
train: epoch 138, loss 0.24931834638118744, acc=0.9160000085830688, loss=0.24931834638118744
test: epoch 138, loss 7.932576656341553, acc=0.10277777910232544, loss=7.932576656341553
train: epoch 139, loss 0.24985703825950623, acc=0.9146111011505127, loss=0.24985703825950623
test: epoch 139, loss 6.172883033752441, acc=0.125, loss=6.172883033752441
train: epoch 140, loss 0.25931403040885925, acc=0.9121111035346985, loss=0.25931403040885925
test: epoch 140, loss 6.2535400390625, acc=0.16944444179534912, loss=6.2535400390625
train: epoch 141, loss 0.23547227680683136, acc=0.9208889007568359, loss=0.23547227680683136
test: epoch 141, loss 8.339715957641602, acc=0.10833333432674408, loss=8.339715957641602
train: epoch 142, loss 0.2534571588039398, acc=0.913611114025116, loss=0.2534571588039398
test: epoch 142, loss 8.905725479125977, acc=0.11944444477558136, loss=8.905725479125977
train: epoch 143, loss 0.24148333072662354, acc=0.9186111092567444, loss=0.24148333072662354
test: epoch 143, loss 9.843106269836426, acc=0.0972222238779068, loss=9.843106269836426
train: epoch 144, loss 0.24267548322677612, acc=0.9192777872085571, loss=0.24267548322677612
test: epoch 144, loss 9.340693473815918, acc=0.10833333432674408, loss=9.340693473815918
train: epoch 145, loss 0.24202166497707367, acc=0.9173333048820496, loss=0.24202166497707367
test: epoch 145, loss 5.008842468261719, acc=0.17222222685813904, loss=5.008842468261719
train: epoch 146, loss 0.2306559830904007, acc=0.9217222332954407, loss=0.2306559830904007
test: epoch 146, loss 5.733836650848389, acc=0.1666666716337204, loss=5.733836650848389
train: epoch 147, loss 0.26054373383522034, acc=0.9100555777549744, loss=0.26054373383522034
test: epoch 147, loss 8.49740219116211, acc=0.13611111044883728, loss=8.49740219116211
train: epoch 148, loss 0.24032920598983765, acc=0.9186111092567444, loss=0.24032920598983765
test: epoch 148, loss 6.744757175445557, acc=0.09444444626569748, loss=6.744757175445557
train: epoch 149, loss 0.22469565272331238, acc=0.922166645526886, loss=0.22469565272331238
test: epoch 149, loss 7.302206993103027, acc=0.08888889104127884, loss=7.302206993103027
train: epoch 150, loss 0.24428977072238922, acc=0.9171666502952576, loss=0.24428977072238922
test: epoch 150, loss 9.124253273010254, acc=0.07500000298023224, loss=9.124253273010254
