# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=0.99", "--one_hot=1", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=125570178, receiver_embed_dim=32, save_run=0, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=125570178, receiver_embed_dim=32, save_run=False, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.3727376461029053, acc=0.05188889056444168, loss=3.3727376461029053
test: epoch 1, loss 5.047313690185547, acc=0.0555555559694767, loss=5.047313690185547
train: epoch 2, loss 2.611259698867798, acc=0.1492222249507904, loss=2.611259698867798
test: epoch 2, loss 7.32299280166626, acc=0.0555555559694767, loss=7.32299280166626
train: epoch 3, loss 2.048799991607666, acc=0.26827776432037354, loss=2.048799991607666
test: epoch 3, loss 7.888393878936768, acc=0.06388889253139496, loss=7.888393878936768
train: epoch 4, loss 1.736372947692871, acc=0.3916666805744171, loss=1.736372947692871
test: epoch 4, loss 8.789205551147461, acc=0.09166666865348816, loss=8.789205551147461
train: epoch 5, loss 1.470598816871643, acc=0.47749999165534973, loss=1.470598816871643
test: epoch 5, loss 6.360232353210449, acc=0.08611111342906952, loss=6.360232353210449
train: epoch 6, loss 1.2432548999786377, acc=0.5432778000831604, loss=1.2432548999786377
test: epoch 6, loss 6.563755989074707, acc=0.13333334028720856, loss=6.563755989074707
train: epoch 7, loss 1.09768807888031, acc=0.5877222418785095, loss=1.09768807888031
test: epoch 7, loss 6.53621244430542, acc=0.11944444477558136, loss=6.53621244430542
train: epoch 8, loss 1.0140103101730347, acc=0.6218888759613037, loss=1.0140103101730347
test: epoch 8, loss 5.729512691497803, acc=0.19166666269302368, loss=5.729512691497803
train: epoch 9, loss 0.9374881982803345, acc=0.6544444561004639, loss=0.9374881982803345
test: epoch 9, loss 5.225700855255127, acc=0.16111111640930176, loss=5.225700855255127
train: epoch 10, loss 0.8733532428741455, acc=0.6812222003936768, loss=0.8733532428741455
test: epoch 10, loss 5.3512163162231445, acc=0.20000000298023224, loss=5.3512163162231445
train: epoch 11, loss 0.8214635848999023, acc=0.6989444494247437, loss=0.8214635848999023
test: epoch 11, loss 4.815488338470459, acc=0.1666666716337204, loss=4.815488338470459
train: epoch 12, loss 0.79192054271698, acc=0.7166666388511658, loss=0.79192054271698
test: epoch 12, loss 4.65585994720459, acc=0.20555555820465088, loss=4.65585994720459
train: epoch 13, loss 0.7613999247550964, acc=0.7282778024673462, loss=0.7613999247550964
test: epoch 13, loss 4.333428859710693, acc=0.23888888955116272, loss=4.333428859710693
train: epoch 14, loss 0.7330138087272644, acc=0.7440000176429749, loss=0.7330138087272644
test: epoch 14, loss 4.335818767547607, acc=0.20277777314186096, loss=4.335818767547607
train: epoch 15, loss 0.7042635083198547, acc=0.7519999742507935, loss=0.7042635083198547
test: epoch 15, loss 4.119354248046875, acc=0.2666666805744171, loss=4.119354248046875
train: epoch 16, loss 0.6763008832931519, acc=0.7714999914169312, loss=0.6763008832931519
test: epoch 16, loss 3.84104585647583, acc=0.2750000059604645, loss=3.84104585647583
train: epoch 17, loss 0.6650794744491577, acc=0.7701666951179504, loss=0.6650794744491577
test: epoch 17, loss 3.6980063915252686, acc=0.23055554926395416, loss=3.6980063915252686
train: epoch 18, loss 0.6224872469902039, acc=0.7803333401679993, loss=0.6224872469902039
test: epoch 18, loss 3.6197898387908936, acc=0.2222222238779068, loss=3.6197898387908936
train: epoch 19, loss 0.621812641620636, acc=0.7847222089767456, loss=0.621812641620636
test: epoch 19, loss 3.2679543495178223, acc=0.26944443583488464, loss=3.2679543495178223
train: epoch 20, loss 0.5942411422729492, acc=0.8008333444595337, loss=0.5942411422729492
test: epoch 20, loss 3.3874146938323975, acc=0.23055554926395416, loss=3.3874146938323975
train: epoch 21, loss 0.5972187519073486, acc=0.7971110939979553, loss=0.5972187519073486
test: epoch 21, loss 3.4309768676757812, acc=0.23055554926395416, loss=3.4309768676757812
train: epoch 22, loss 0.5895659923553467, acc=0.8037222027778625, loss=0.5895659923553467
test: epoch 22, loss 3.2490923404693604, acc=0.2527777850627899, loss=3.2490923404693604
train: epoch 23, loss 0.5586733818054199, acc=0.8134999871253967, loss=0.5586733818054199
test: epoch 23, loss 3.1428823471069336, acc=0.2361111044883728, loss=3.1428823471069336
train: epoch 24, loss 0.5636962056159973, acc=0.8105000257492065, loss=0.5636962056159973
test: epoch 24, loss 2.912672996520996, acc=0.2777777910232544, loss=2.912672996520996
train: epoch 25, loss 0.5428245663642883, acc=0.8234444260597229, loss=0.5428245663642883
test: epoch 25, loss 3.0928807258605957, acc=0.27222222089767456, loss=3.0928807258605957
train: epoch 26, loss 0.5465092658996582, acc=0.8198333382606506, loss=0.5465092658996582
test: epoch 26, loss 2.825671434402466, acc=0.24444444477558136, loss=2.825671434402466
train: epoch 27, loss 0.536139190196991, acc=0.8231111168861389, loss=0.536139190196991
test: epoch 27, loss 2.818974256515503, acc=0.2527777850627899, loss=2.818974256515503
train: epoch 28, loss 0.5050735473632812, acc=0.8329444527626038, loss=0.5050735473632812
test: epoch 28, loss 2.898057460784912, acc=0.2805555462837219, loss=2.898057460784912
train: epoch 29, loss 0.5321881175041199, acc=0.8270000219345093, loss=0.5321881175041199
test: epoch 29, loss 2.699138879776001, acc=0.2666666805744171, loss=2.699138879776001
train: epoch 30, loss 0.5083062648773193, acc=0.8312777876853943, loss=0.5083062648773193
test: epoch 30, loss 2.5588178634643555, acc=0.3083333373069763, loss=2.5588178634643555
train: epoch 31, loss 0.5045638084411621, acc=0.8328333497047424, loss=0.5045638084411621
test: epoch 31, loss 2.348299980163574, acc=0.3055555522441864, loss=2.348299980163574
train: epoch 32, loss 0.5007933378219604, acc=0.8379999995231628, loss=0.5007933378219604
test: epoch 32, loss 2.3458359241485596, acc=0.28611111640930176, loss=2.3458359241485596
train: epoch 33, loss 0.49828651547431946, acc=0.8361666798591614, loss=0.49828651547431946
test: epoch 33, loss 2.421359062194824, acc=0.2777777910232544, loss=2.421359062194824
train: epoch 34, loss 0.48675230145454407, acc=0.8427777886390686, loss=0.48675230145454407
test: epoch 34, loss 2.442305326461792, acc=0.31111112236976624, loss=2.442305326461792
train: epoch 35, loss 0.4812126159667969, acc=0.8416666388511658, loss=0.4812126159667969
test: epoch 35, loss 2.3743655681610107, acc=0.29722222685813904, loss=2.3743655681610107
train: epoch 36, loss 0.4764786958694458, acc=0.840833306312561, loss=0.4764786958694458
test: epoch 36, loss 2.113433837890625, acc=0.2750000059604645, loss=2.113433837890625
train: epoch 37, loss 0.4778587222099304, acc=0.8415555357933044, loss=0.4778587222099304
test: epoch 37, loss 2.2045557498931885, acc=0.3166666626930237, loss=2.2045557498931885
train: epoch 38, loss 0.4661032259464264, acc=0.847944438457489, loss=0.4661032259464264
test: epoch 38, loss 2.032135486602783, acc=0.3194444477558136, loss=2.032135486602783
train: epoch 39, loss 0.4664895534515381, acc=0.8435555696487427, loss=0.4664895534515381
test: epoch 39, loss 2.2935707569122314, acc=0.3027777671813965, loss=2.2935707569122314
train: epoch 40, loss 0.46565142273902893, acc=0.8492777943611145, loss=0.46565142273902893
test: epoch 40, loss 1.8828247785568237, acc=0.3333333432674408, loss=1.8828247785568237
train: epoch 41, loss 0.46023988723754883, acc=0.8527222275733948, loss=0.46023988723754883
test: epoch 41, loss 1.9776546955108643, acc=0.3499999940395355, loss=1.9776546955108643
train: epoch 42, loss 0.4538663625717163, acc=0.8532778024673462, loss=0.4538663625717163
test: epoch 42, loss 1.8820326328277588, acc=0.35555556416511536, loss=1.8820326328277588
train: epoch 43, loss 0.46653345227241516, acc=0.8528333306312561, loss=0.46653345227241516
test: epoch 43, loss 1.8509492874145508, acc=0.3777777850627899, loss=1.8509492874145508
train: epoch 44, loss 0.44097238779067993, acc=0.8535555601119995, loss=0.44097238779067993
test: epoch 44, loss 1.8332194089889526, acc=0.3777777850627899, loss=1.8332194089889526
train: epoch 45, loss 0.4529535174369812, acc=0.8529999852180481, loss=0.4529535174369812
test: epoch 45, loss 1.861889362335205, acc=0.3722222149372101, loss=1.861889362335205
train: epoch 46, loss 0.440555602312088, acc=0.8557778000831604, loss=0.440555602312088
test: epoch 46, loss 1.721121907234192, acc=0.4027777910232544, loss=1.721121907234192
train: epoch 47, loss 0.45383819937705994, acc=0.8511666655540466, loss=0.45383819937705994
test: epoch 47, loss 1.5747743844985962, acc=0.40833333134651184, loss=1.5747743844985962
train: epoch 48, loss 0.44611960649490356, acc=0.8546666502952576, loss=0.44611960649490356
test: epoch 48, loss 1.5565534830093384, acc=0.4055555462837219, loss=1.5565534830093384
train: epoch 49, loss 0.427748441696167, acc=0.8604444265365601, loss=0.427748441696167
test: epoch 49, loss 1.670253872871399, acc=0.4027777910232544, loss=1.670253872871399
train: epoch 50, loss 0.43424955010414124, acc=0.8603888750076294, loss=0.43424955010414124
test: epoch 50, loss 1.5533967018127441, acc=0.41111111640930176, loss=1.5533967018127441
train: epoch 51, loss 0.43934524059295654, acc=0.8572221994400024, loss=0.43934524059295654
test: epoch 51, loss 1.4596797227859497, acc=0.39722222089767456, loss=1.4596797227859497
train: epoch 52, loss 0.43105465173721313, acc=0.8610000014305115, loss=0.43105465173721313
test: epoch 52, loss 1.4815171957015991, acc=0.4305555522441864, loss=1.4815171957015991
train: epoch 53, loss 0.43829017877578735, acc=0.8573889136314392, loss=0.43829017877578735
test: epoch 53, loss 1.5372155904769897, acc=0.40833333134651184, loss=1.5372155904769897
train: epoch 54, loss 0.4192391633987427, acc=0.8643888831138611, loss=0.4192391633987427
test: epoch 54, loss 1.512930989265442, acc=0.4333333373069763, loss=1.512930989265442
train: epoch 55, loss 0.4274802505970001, acc=0.8590555787086487, loss=0.4274802505970001
test: epoch 55, loss 1.4757798910140991, acc=0.4055555462837219, loss=1.4757798910140991
train: epoch 56, loss 0.42522940039634705, acc=0.8603888750076294, loss=0.42522940039634705
test: epoch 56, loss 1.4499250650405884, acc=0.4333333373069763, loss=1.4499250650405884
train: epoch 57, loss 0.4218749403953552, acc=0.8653333187103271, loss=0.4218749403953552
test: epoch 57, loss 1.4848217964172363, acc=0.41111111640930176, loss=1.4848217964172363
train: epoch 58, loss 0.41595715284347534, acc=0.8656111359596252, loss=0.41595715284347534
test: epoch 58, loss 1.3488314151763916, acc=0.4305555522441864, loss=1.3488314151763916
train: epoch 59, loss 0.41454383730888367, acc=0.8598889112472534, loss=0.41454383730888367
test: epoch 59, loss 1.27639639377594, acc=0.4694444537162781, loss=1.27639639377594
train: epoch 60, loss 0.41832679510116577, acc=0.8647778034210205, loss=0.41832679510116577
test: epoch 60, loss 1.4179661273956299, acc=0.46666666865348816, loss=1.4179661273956299
train: epoch 61, loss 0.4243885576725006, acc=0.8658888936042786, loss=0.4243885576725006
test: epoch 61, loss 1.360270619392395, acc=0.44999998807907104, loss=1.360270619392395
train: epoch 62, loss 0.41944620013237, acc=0.866611123085022, loss=0.41944620013237
test: epoch 62, loss 1.3539927005767822, acc=0.47777777910232544, loss=1.3539927005767822
train: epoch 63, loss 0.3891310691833496, acc=0.871055543422699, loss=0.3891310691833496
test: epoch 63, loss 1.443976879119873, acc=0.44999998807907104, loss=1.443976879119873
train: epoch 64, loss 0.41698676347732544, acc=0.8658888936042786, loss=0.41698676347732544
test: epoch 64, loss 1.3146069049835205, acc=0.46666666865348816, loss=1.3146069049835205
train: epoch 65, loss 0.3981468081474304, acc=0.8668333292007446, loss=0.3981468081474304
test: epoch 65, loss 1.322354793548584, acc=0.47777777910232544, loss=1.322354793548584
train: epoch 66, loss 0.3955445885658264, acc=0.8692222237586975, loss=0.3955445885658264
test: epoch 66, loss 1.2582005262374878, acc=0.4833333194255829, loss=1.2582005262374878
train: epoch 67, loss 0.3957635462284088, acc=0.8707777857780457, loss=0.3957635462284088
test: epoch 67, loss 1.2315385341644287, acc=0.4749999940395355, loss=1.2315385341644287
train: epoch 68, loss 0.3829485774040222, acc=0.8753888607025146, loss=0.3829485774040222
test: epoch 68, loss 1.3054414987564087, acc=0.4972222149372101, loss=1.3054414987564087
train: epoch 69, loss 0.36936768889427185, acc=0.8764444589614868, loss=0.36936768889427185
test: epoch 69, loss 1.2722123861312866, acc=0.5, loss=1.2722123861312866
train: epoch 70, loss 0.38082045316696167, acc=0.8725000023841858, loss=0.38082045316696167
test: epoch 70, loss 1.2129350900650024, acc=0.5166666507720947, loss=1.2129350900650024
train: epoch 71, loss 0.39187681674957275, acc=0.8696110844612122, loss=0.39187681674957275
test: epoch 71, loss 1.2076661586761475, acc=0.5027777552604675, loss=1.2076661586761475
train: epoch 72, loss 0.37973544001579285, acc=0.8746111392974854, loss=0.37973544001579285
test: epoch 72, loss 1.1944215297698975, acc=0.5222222208976746, loss=1.1944215297698975
train: epoch 73, loss 0.3720690608024597, acc=0.8745555281639099, loss=0.3720690608024597
test: epoch 73, loss 1.1242902278900146, acc=0.5472221970558167, loss=1.1242902278900146
train: epoch 74, loss 0.36543160676956177, acc=0.8772777915000916, loss=0.36543160676956177
test: epoch 74, loss 1.0492435693740845, acc=0.550000011920929, loss=1.0492435693740845
train: epoch 75, loss 0.37297236919403076, acc=0.8728333115577698, loss=0.37297236919403076
test: epoch 75, loss 1.071874976158142, acc=0.550000011920929, loss=1.071874976158142
train: epoch 76, loss 0.3641510605812073, acc=0.8792222142219543, loss=0.3641510605812073
test: epoch 76, loss 1.0918604135513306, acc=0.5444444417953491, loss=1.0918604135513306
train: epoch 77, loss 0.38554397225379944, acc=0.8737778067588806, loss=0.38554397225379944
test: epoch 77, loss 1.1364433765411377, acc=0.550000011920929, loss=1.1364433765411377
train: epoch 78, loss 0.374760240316391, acc=0.8750555515289307, loss=0.374760240316391
test: epoch 78, loss 1.0943459272384644, acc=0.5472221970558167, loss=1.0943459272384644
train: epoch 79, loss 0.36281704902648926, acc=0.879111111164093, loss=0.36281704902648926
test: epoch 79, loss 1.0995241403579712, acc=0.5666666626930237, loss=1.0995241403579712
train: epoch 80, loss 0.3482070863246918, acc=0.8808888792991638, loss=0.3482070863246918
test: epoch 80, loss 1.0382822751998901, acc=0.5888888835906982, loss=1.0382822751998901
train: epoch 81, loss 0.3623770475387573, acc=0.8784444332122803, loss=0.3623770475387573
test: epoch 81, loss 1.045446515083313, acc=0.605555534362793, loss=1.045446515083313
train: epoch 82, loss 0.3419875502586365, acc=0.8807222247123718, loss=0.3419875502586365
test: epoch 82, loss 1.0559355020523071, acc=0.5972222089767456, loss=1.0559355020523071
train: epoch 83, loss 0.35202908515930176, acc=0.8801666498184204, loss=0.35202908515930176
test: epoch 83, loss 0.9640295505523682, acc=0.6000000238418579, loss=0.9640295505523682
train: epoch 84, loss 0.338644802570343, acc=0.8833333253860474, loss=0.338644802570343
test: epoch 84, loss 0.9728643298149109, acc=0.6166666746139526, loss=0.9728643298149109
train: epoch 85, loss 0.36026158928871155, acc=0.8798888921737671, loss=0.36026158928871155
test: epoch 85, loss 0.9453386068344116, acc=0.625, loss=0.9453386068344116
train: epoch 86, loss 0.3414807617664337, acc=0.8806111216545105, loss=0.3414807617664337
test: epoch 86, loss 0.9550132751464844, acc=0.644444465637207, loss=0.9550132751464844
train: epoch 87, loss 0.34423041343688965, acc=0.8851110935211182, loss=0.34423041343688965
test: epoch 87, loss 0.8990733027458191, acc=0.6416666507720947, loss=0.8990733027458191
train: epoch 88, loss 0.33451980352401733, acc=0.8856666684150696, loss=0.33451980352401733
test: epoch 88, loss 0.9181371331214905, acc=0.6361111402511597, loss=0.9181371331214905
train: epoch 89, loss 0.347250759601593, acc=0.8821666836738586, loss=0.347250759601593
test: epoch 89, loss 0.9395971894264221, acc=0.6166666746139526, loss=0.9395971894264221
train: epoch 90, loss 0.33999380469322205, acc=0.8838333487510681, loss=0.33999380469322205
test: epoch 90, loss 0.8802558183670044, acc=0.6583333611488342, loss=0.8802558183670044
train: epoch 91, loss 0.32798752188682556, acc=0.8845555782318115, loss=0.32798752188682556
test: epoch 91, loss 0.8038745522499084, acc=0.6666666865348816, loss=0.8038745522499084
train: epoch 92, loss 0.3220864534378052, acc=0.8887777924537659, loss=0.3220864534378052
test: epoch 92, loss 0.7239078879356384, acc=0.6833333373069763, loss=0.7239078879356384
train: epoch 93, loss 0.3252239227294922, acc=0.8888888955116272, loss=0.3252239227294922
test: epoch 93, loss 0.8407520055770874, acc=0.6694444417953491, loss=0.8407520055770874
train: epoch 94, loss 0.3110581636428833, acc=0.8928333520889282, loss=0.3110581636428833
test: epoch 94, loss 0.7488771677017212, acc=0.6833333373069763, loss=0.7488771677017212
train: epoch 95, loss 0.3102405071258545, acc=0.891777753829956, loss=0.3102405071258545
test: epoch 95, loss 0.8626973032951355, acc=0.6833333373069763, loss=0.8626973032951355
train: epoch 96, loss 0.3110545873641968, acc=0.8934999704360962, loss=0.3110545873641968
test: epoch 96, loss 0.7692286372184753, acc=0.6972222328186035, loss=0.7692286372184753
train: epoch 97, loss 0.29765141010284424, acc=0.8941666483879089, loss=0.29765141010284424
test: epoch 97, loss 0.682660698890686, acc=0.7111111283302307, loss=0.682660698890686
train: epoch 98, loss 0.2991146743297577, acc=0.8943889141082764, loss=0.2991146743297577
test: epoch 98, loss 0.7184398174285889, acc=0.7250000238418579, loss=0.7184398174285889
train: epoch 99, loss 0.30603936314582825, acc=0.8943889141082764, loss=0.30603936314582825
test: epoch 99, loss 0.6380627155303955, acc=0.7277777791023254, loss=0.6380627155303955
train: epoch 100, loss 0.29230690002441406, acc=0.9003888964653015, loss=0.29230690002441406
test: epoch 100, loss 0.6641735434532166, acc=0.7222222089767456, loss=0.6641735434532166
train: epoch 101, loss 0.29599133133888245, acc=0.8993889093399048, loss=0.29599133133888245
test: epoch 101, loss 0.6805460453033447, acc=0.7333333492279053, loss=0.6805460453033447
train: epoch 102, loss 0.2841756045818329, acc=0.8994444608688354, loss=0.2841756045818329
test: epoch 102, loss 0.652668297290802, acc=0.7277777791023254, loss=0.652668297290802
train: epoch 103, loss 0.2758071720600128, acc=0.902999997138977, loss=0.2758071720600128
test: epoch 103, loss 0.587634265422821, acc=0.7277777791023254, loss=0.587634265422821
train: epoch 104, loss 0.26132166385650635, acc=0.9087777733802795, loss=0.26132166385650635
test: epoch 104, loss 0.5556451678276062, acc=0.7416666746139526, loss=0.5556451678276062
train: epoch 105, loss 0.24893595278263092, acc=0.9095555543899536, loss=0.24893595278263092
test: epoch 105, loss 0.5256478190422058, acc=0.7527777552604675, loss=0.5256478190422058
train: epoch 106, loss 0.2630612552165985, acc=0.9085000157356262, loss=0.2630612552165985
test: epoch 106, loss 0.5592439770698547, acc=0.7722222208976746, loss=0.5592439770698547
train: epoch 107, loss 0.2730482518672943, acc=0.9083889126777649, loss=0.2730482518672943
test: epoch 107, loss 0.574623167514801, acc=0.7749999761581421, loss=0.574623167514801
train: epoch 108, loss 0.2528936564922333, acc=0.9144444465637207, loss=0.2528936564922333
test: epoch 108, loss 0.5660545229911804, acc=0.7583333253860474, loss=0.5660545229911804
train: epoch 109, loss 0.2406870722770691, acc=0.9179999828338623, loss=0.2406870722770691
test: epoch 109, loss 0.5575907230377197, acc=0.7555555701255798, loss=0.5575907230377197
train: epoch 110, loss 0.2425488382577896, acc=0.9166111350059509, loss=0.2425488382577896
test: epoch 110, loss 0.5781161785125732, acc=0.7777777910232544, loss=0.5781161785125732
train: epoch 111, loss 0.23790065944194794, acc=0.9203888773918152, loss=0.23790065944194794
test: epoch 111, loss 0.5234121680259705, acc=0.7777777910232544, loss=0.5234121680259705
train: epoch 112, loss 0.23221909999847412, acc=0.9213888645172119, loss=0.23221909999847412
test: epoch 112, loss 0.586603581905365, acc=0.7833333611488342, loss=0.586603581905365
train: epoch 113, loss 0.23476655781269073, acc=0.9193333387374878, loss=0.23476655781269073
test: epoch 113, loss 0.5148413777351379, acc=0.7861111164093018, loss=0.5148413777351379
train: epoch 114, loss 0.21491405367851257, acc=0.9237222075462341, loss=0.21491405367851257
test: epoch 114, loss 0.5547512769699097, acc=0.7861111164093018, loss=0.5547512769699097
train: epoch 115, loss 0.23316292464733124, acc=0.9229444265365601, loss=0.23316292464733124
test: epoch 115, loss 0.4674365222454071, acc=0.7888888716697693, loss=0.4674365222454071
train: epoch 116, loss 0.21171358227729797, acc=0.924833357334137, loss=0.21171358227729797
test: epoch 116, loss 0.5494007468223572, acc=0.7972221970558167, loss=0.5494007468223572
train: epoch 117, loss 0.20753216743469238, acc=0.9286666512489319, loss=0.20753216743469238
test: epoch 117, loss 0.49066439270973206, acc=0.7972221970558167, loss=0.49066439270973206
train: epoch 118, loss 0.20310193300247192, acc=0.9267777800559998, loss=0.20310193300247192
test: epoch 118, loss 0.48894205689430237, acc=0.7861111164093018, loss=0.48894205689430237
train: epoch 119, loss 0.19585442543029785, acc=0.9319444298744202, loss=0.19585442543029785
test: epoch 119, loss 0.5182259678840637, acc=0.8027777671813965, loss=0.5182259678840637
train: epoch 120, loss 0.19461466372013092, acc=0.9301666617393494, loss=0.19461466372013092
test: epoch 120, loss 0.4967764616012573, acc=0.7944444417953491, loss=0.4967764616012573
train: epoch 121, loss 0.1993607133626938, acc=0.9328888654708862, loss=0.1993607133626938
test: epoch 121, loss 0.5533258318901062, acc=0.7916666865348816, loss=0.5533258318901062
train: epoch 122, loss 0.2017248570919037, acc=0.9323333501815796, loss=0.2017248570919037
test: epoch 122, loss 0.4617593288421631, acc=0.7972221970558167, loss=0.4617593288421631
train: epoch 123, loss 0.19028021395206451, acc=0.9342777729034424, loss=0.19028021395206451
test: epoch 123, loss 0.48669564723968506, acc=0.7972221970558167, loss=0.48669564723968506
train: epoch 124, loss 0.18629680573940277, acc=0.9326666593551636, loss=0.18629680573940277
test: epoch 124, loss 0.4662885069847107, acc=0.8166666626930237, loss=0.4662885069847107
train: epoch 125, loss 0.19157332181930542, acc=0.933388888835907, loss=0.19157332181930542
test: epoch 125, loss 0.46089741587638855, acc=0.8027777671813965, loss=0.46089741587638855
train: epoch 126, loss 0.18525175750255585, acc=0.9356111288070679, loss=0.18525175750255585
test: epoch 126, loss 0.5230916738510132, acc=0.8166666626930237, loss=0.5230916738510132
train: epoch 127, loss 0.18878422677516937, acc=0.9307777881622314, loss=0.18878422677516937
test: epoch 127, loss 0.514731764793396, acc=0.7944444417953491, loss=0.514731764793396
train: epoch 128, loss 0.19291694462299347, acc=0.9326111078262329, loss=0.19291694462299347
test: epoch 128, loss 0.503821849822998, acc=0.8083333373069763, loss=0.503821849822998
train: epoch 129, loss 0.181141197681427, acc=0.9375555515289307, loss=0.181141197681427
test: epoch 129, loss 0.5132908225059509, acc=0.8083333373069763, loss=0.5132908225059509
train: epoch 130, loss 0.1738242357969284, acc=0.9370555281639099, loss=0.1738242357969284
test: epoch 130, loss 0.41728338599205017, acc=0.8111110925674438, loss=0.41728338599205017
train: epoch 131, loss 0.16889870166778564, acc=0.9391111135482788, loss=0.16889870166778564
test: epoch 131, loss 0.5129890441894531, acc=0.8111110925674438, loss=0.5129890441894531
train: epoch 132, loss 0.18078774213790894, acc=0.9357777833938599, loss=0.18078774213790894
test: epoch 132, loss 0.4781772196292877, acc=0.8083333373069763, loss=0.4781772196292877
train: epoch 133, loss 0.17208722233772278, acc=0.9402222037315369, loss=0.17208722233772278
test: epoch 133, loss 0.49619439244270325, acc=0.824999988079071, loss=0.49619439244270325
train: epoch 134, loss 0.1787864714860916, acc=0.9361110925674438, loss=0.1787864714860916
test: epoch 134, loss 0.5557094216346741, acc=0.8111110925674438, loss=0.5557094216346741
train: epoch 135, loss 0.16984280943870544, acc=0.9406111240386963, loss=0.16984280943870544
test: epoch 135, loss 0.4301678538322449, acc=0.824999988079071, loss=0.4301678538322449
train: epoch 136, loss 0.1738690733909607, acc=0.9392222166061401, loss=0.1738690733909607
test: epoch 136, loss 0.47785237431526184, acc=0.8138889074325562, loss=0.47785237431526184
train: epoch 137, loss 0.16230356693267822, acc=0.9388333559036255, loss=0.16230356693267822
test: epoch 137, loss 0.4240485429763794, acc=0.8166666626930237, loss=0.4240485429763794
train: epoch 138, loss 0.1678122580051422, acc=0.9394999742507935, loss=0.1678122580051422
test: epoch 138, loss 0.3952080011367798, acc=0.8138889074325562, loss=0.3952080011367798
train: epoch 139, loss 0.1691848635673523, acc=0.9397777915000916, loss=0.1691848635673523
test: epoch 139, loss 0.41675323247909546, acc=0.8277778029441833, loss=0.41675323247909546
train: epoch 140, loss 0.16995258629322052, acc=0.9393888711929321, loss=0.16995258629322052
test: epoch 140, loss 0.4570220112800598, acc=0.8388888835906982, loss=0.4570220112800598
train: epoch 141, loss 0.15518169105052948, acc=0.9418888688087463, loss=0.15518169105052948
test: epoch 141, loss 0.42815569043159485, acc=0.8111110925674438, loss=0.42815569043159485
train: epoch 142, loss 0.15893447399139404, acc=0.941611111164093, loss=0.15893447399139404
test: epoch 142, loss 0.45882704854011536, acc=0.8138889074325562, loss=0.45882704854011536
train: epoch 143, loss 0.16488344967365265, acc=0.9408888816833496, loss=0.16488344967365265
test: epoch 143, loss 0.45398882031440735, acc=0.8138889074325562, loss=0.45398882031440735
train: epoch 144, loss 0.16540247201919556, acc=0.9418888688087463, loss=0.16540247201919556
test: epoch 144, loss 0.4608384072780609, acc=0.824999988079071, loss=0.4608384072780609
train: epoch 145, loss 0.15610134601593018, acc=0.941277801990509, loss=0.15610134601593018
test: epoch 145, loss 0.49125510454177856, acc=0.8138889074325562, loss=0.49125510454177856
train: epoch 146, loss 0.15542908012866974, acc=0.9413889050483704, loss=0.15542908012866974
test: epoch 146, loss 0.4498106837272644, acc=0.8305555582046509, loss=0.4498106837272644
train: epoch 147, loss 0.15676939487457275, acc=0.9434444308280945, loss=0.15676939487457275
test: epoch 147, loss 0.45131081342697144, acc=0.8138889074325562, loss=0.45131081342697144
train: epoch 148, loss 0.1563420295715332, acc=0.9415000081062317, loss=0.1563420295715332
test: epoch 148, loss 0.42748767137527466, acc=0.8444444537162781, loss=0.42748767137527466
train: epoch 149, loss 0.1474391669034958, acc=0.9461110830307007, loss=0.1474391669034958
test: epoch 149, loss 0.34620654582977295, acc=0.8444444537162781, loss=0.34620654582977295
train: epoch 150, loss 0.1561669111251831, acc=0.9442222118377686, loss=0.1561669111251831
test: epoch 150, loss 0.4238834083080292, acc=0.8388888835906982, loss=0.4238834083080292
