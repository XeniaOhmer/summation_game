# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.99", "--one_hot=1", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=1048638869, receiver_embed_dim=64, save_run=0, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1048638869, receiver_embed_dim=64, save_run=False, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.2299609184265137, acc=0.07394444197416306, loss=3.2299609184265137
test: epoch 1, loss 5.162938594818115, acc=0.06666667014360428, loss=5.162938594818115
train: epoch 2, loss 1.9921190738677979, acc=0.30311110615730286, loss=1.9921190738677979
test: epoch 2, loss 4.9474287033081055, acc=0.125, loss=4.9474287033081055
train: epoch 3, loss 1.297255039215088, acc=0.5087777972221375, loss=1.297255039215088
test: epoch 3, loss 5.7624921798706055, acc=0.15000000596046448, loss=5.7624921798706055
train: epoch 4, loss 1.0009534358978271, acc=0.6241111159324646, loss=1.0009534358978271
test: epoch 4, loss 4.827010631561279, acc=0.18333333730697632, loss=4.827010631561279
train: epoch 5, loss 0.8428499102592468, acc=0.6893888711929321, loss=0.8428499102592468
test: epoch 5, loss 4.062901020050049, acc=0.18888889253139496, loss=4.062901020050049
train: epoch 6, loss 0.7418909668922424, acc=0.7298333048820496, loss=0.7418909668922424
test: epoch 6, loss 4.0416579246521, acc=0.19722221791744232, loss=4.0416579246521
train: epoch 7, loss 0.6573501825332642, acc=0.7621111273765564, loss=0.6573501825332642
test: epoch 7, loss 3.485867738723755, acc=0.2527777850627899, loss=3.485867738723755
train: epoch 8, loss 0.5951299667358398, acc=0.7871111035346985, loss=0.5951299667358398
test: epoch 8, loss 3.573155164718628, acc=0.26944443583488464, loss=3.573155164718628
train: epoch 9, loss 0.5535898208618164, acc=0.8065555691719055, loss=0.5535898208618164
test: epoch 9, loss 3.7037880420684814, acc=0.21666666865348816, loss=3.7037880420684814
train: epoch 10, loss 0.5083593130111694, acc=0.8177222013473511, loss=0.5083593130111694
test: epoch 10, loss 3.289482355117798, acc=0.2777777910232544, loss=3.289482355117798
train: epoch 11, loss 0.48412972688674927, acc=0.832611083984375, loss=0.48412972688674927
test: epoch 11, loss 3.246659517288208, acc=0.28333333134651184, loss=3.246659517288208
train: epoch 12, loss 0.4586731493473053, acc=0.8446666598320007, loss=0.4586731493473053
test: epoch 12, loss 3.276393413543701, acc=0.29722222685813904, loss=3.276393413543701
train: epoch 13, loss 0.4313318133354187, acc=0.8516111373901367, loss=0.4313318133354187
test: epoch 13, loss 2.893671989440918, acc=0.3027777671813965, loss=2.893671989440918
train: epoch 14, loss 0.44463911652565, acc=0.8534444570541382, loss=0.44463911652565
test: epoch 14, loss 2.7852635383605957, acc=0.3361110985279083, loss=2.7852635383605957
train: epoch 15, loss 0.3947986364364624, acc=0.8698889017105103, loss=0.3947986364364624
test: epoch 15, loss 2.7729156017303467, acc=0.3305555582046509, loss=2.7729156017303467
train: epoch 16, loss 0.39769333600997925, acc=0.8655555844306946, loss=0.39769333600997925
test: epoch 16, loss 2.646326780319214, acc=0.3472222089767456, loss=2.646326780319214
train: epoch 17, loss 0.39134588837623596, acc=0.8731111288070679, loss=0.39134588837623596
test: epoch 17, loss 2.468146562576294, acc=0.3361110985279083, loss=2.468146562576294
train: epoch 18, loss 0.3681476414203644, acc=0.8806111216545105, loss=0.3681476414203644
test: epoch 18, loss 2.4674642086029053, acc=0.3499999940395355, loss=2.4674642086029053
train: epoch 19, loss 0.35658296942710876, acc=0.8836110830307007, loss=0.35658296942710876
test: epoch 19, loss 2.246635913848877, acc=0.375, loss=2.246635913848877
train: epoch 20, loss 0.3363167345523834, acc=0.8922777771949768, loss=0.3363167345523834
test: epoch 20, loss 2.056008815765381, acc=0.3888888955116272, loss=2.056008815765381
train: epoch 21, loss 0.3316937983036041, acc=0.891777753829956, loss=0.3316937983036041
test: epoch 21, loss 2.259044647216797, acc=0.36944442987442017, loss=2.259044647216797
train: epoch 22, loss 0.3300979733467102, acc=0.8898333311080933, loss=0.3300979733467102
test: epoch 22, loss 1.9836080074310303, acc=0.3861111104488373, loss=1.9836080074310303
train: epoch 23, loss 0.3174888789653778, acc=0.8984444737434387, loss=0.3174888789653778
test: epoch 23, loss 1.9340229034423828, acc=0.39722222089767456, loss=1.9340229034423828
train: epoch 24, loss 0.32861649990081787, acc=0.8930555582046509, loss=0.32861649990081787
test: epoch 24, loss 1.7691484689712524, acc=0.4138889014720917, loss=1.7691484689712524
train: epoch 25, loss 0.3014175593852997, acc=0.9029444456100464, loss=0.3014175593852997
test: epoch 25, loss 1.8116718530654907, acc=0.4027777910232544, loss=1.8116718530654907
train: epoch 26, loss 0.30213314294815063, acc=0.9030555486679077, loss=0.30213314294815063
test: epoch 26, loss 1.7326948642730713, acc=0.4027777910232544, loss=1.7326948642730713
train: epoch 27, loss 0.29433107376098633, acc=0.9079444408416748, loss=0.29433107376098633
test: epoch 27, loss 1.9893053770065308, acc=0.3777777850627899, loss=1.9893053770065308
train: epoch 28, loss 0.2934792637825012, acc=0.9054444432258606, loss=0.2934792637825012
test: epoch 28, loss 1.7330830097198486, acc=0.42500001192092896, loss=1.7330830097198486
train: epoch 29, loss 0.28775590658187866, acc=0.9117222428321838, loss=0.28775590658187866
test: epoch 29, loss 1.8390382528305054, acc=0.4194444417953491, loss=1.8390382528305054
train: epoch 30, loss 0.2922568619251251, acc=0.9083333611488342, loss=0.2922568619251251
test: epoch 30, loss 1.8008887767791748, acc=0.40833333134651184, loss=1.8008887767791748
train: epoch 31, loss 0.2849656939506531, acc=0.909333348274231, loss=0.2849656939506531
test: epoch 31, loss 1.7749063968658447, acc=0.4138889014720917, loss=1.7749063968658447
train: epoch 32, loss 0.2688593864440918, acc=0.9110555648803711, loss=0.2688593864440918
test: epoch 32, loss 1.5922085046768188, acc=0.45277777314186096, loss=1.5922085046768188
train: epoch 33, loss 0.2788413166999817, acc=0.9113333225250244, loss=0.2788413166999817
test: epoch 33, loss 1.478403091430664, acc=0.49166667461395264, loss=1.478403091430664
train: epoch 34, loss 0.27187979221343994, acc=0.9135555624961853, loss=0.27187979221343994
test: epoch 34, loss 1.626291275024414, acc=0.41111111640930176, loss=1.626291275024414
train: epoch 35, loss 0.27114376425743103, acc=0.9116666913032532, loss=0.27114376425743103
test: epoch 35, loss 1.5057475566864014, acc=0.4555555582046509, loss=1.5057475566864014
train: epoch 36, loss 0.258385568857193, acc=0.9172222018241882, loss=0.258385568857193
test: epoch 36, loss 1.6666187047958374, acc=0.4166666567325592, loss=1.6666187047958374
train: epoch 37, loss 0.250127375125885, acc=0.9167777895927429, loss=0.250127375125885
test: epoch 37, loss 1.5548492670059204, acc=0.4694444537162781, loss=1.5548492670059204
train: epoch 38, loss 0.25989678502082825, acc=0.9171666502952576, loss=0.25989678502082825
test: epoch 38, loss 1.5064287185668945, acc=0.49166667461395264, loss=1.5064287185668945
train: epoch 39, loss 0.2556731104850769, acc=0.9192222356796265, loss=0.2556731104850769
test: epoch 39, loss 1.276578664779663, acc=0.49444442987442017, loss=1.276578664779663
train: epoch 40, loss 0.27285709977149963, acc=0.9139444231987, loss=0.27285709977149963
test: epoch 40, loss 1.358147144317627, acc=0.47777777910232544, loss=1.358147144317627
train: epoch 41, loss 0.23811832070350647, acc=0.9202222228050232, loss=0.23811832070350647
test: epoch 41, loss 1.3204983472824097, acc=0.5027777552604675, loss=1.3204983472824097
train: epoch 42, loss 0.24658818542957306, acc=0.9187222123146057, loss=0.24658818542957306
test: epoch 42, loss 1.4001331329345703, acc=0.5111111402511597, loss=1.4001331329345703
train: epoch 43, loss 0.24393370747566223, acc=0.9201666712760925, loss=0.24393370747566223
test: epoch 43, loss 1.4978573322296143, acc=0.5222222208976746, loss=1.4978573322296143
train: epoch 44, loss 0.2375750094652176, acc=0.9202222228050232, loss=0.2375750094652176
test: epoch 44, loss 1.2958370447158813, acc=0.5166666507720947, loss=1.2958370447158813
train: epoch 45, loss 0.24958395957946777, acc=0.9204999804496765, loss=0.24958395957946777
test: epoch 45, loss 1.2731918096542358, acc=0.519444465637207, loss=1.2731918096542358
train: epoch 46, loss 0.22249552607536316, acc=0.925166666507721, loss=0.22249552607536316
test: epoch 46, loss 1.167454719543457, acc=0.519444465637207, loss=1.167454719543457
train: epoch 47, loss 0.23249071836471558, acc=0.9234444499015808, loss=0.23249071836471558
test: epoch 47, loss 1.2773889303207397, acc=0.5222222208976746, loss=1.2773889303207397
train: epoch 48, loss 0.2439352124929428, acc=0.9207777976989746, loss=0.2439352124929428
test: epoch 48, loss 1.2395826578140259, acc=0.550000011920929, loss=1.2395826578140259
train: epoch 49, loss 0.21869537234306335, acc=0.929722249507904, loss=0.21869537234306335
test: epoch 49, loss 1.281399130821228, acc=0.5277777910232544, loss=1.281399130821228
train: epoch 50, loss 0.22139735519886017, acc=0.9268333315849304, loss=0.22139735519886017
test: epoch 50, loss 1.1646286249160767, acc=0.5527777671813965, loss=1.1646286249160767
train: epoch 51, loss 0.23433861136436462, acc=0.9247221946716309, loss=0.23433861136436462
test: epoch 51, loss 1.2096408605575562, acc=0.5583333373069763, loss=1.2096408605575562
train: epoch 52, loss 0.21786488592624664, acc=0.929277777671814, loss=0.21786488592624664
test: epoch 52, loss 1.2165318727493286, acc=0.5861111283302307, loss=1.2165318727493286
train: epoch 53, loss 0.21299996972084045, acc=0.9305555820465088, loss=0.21299996972084045
test: epoch 53, loss 1.2783839702606201, acc=0.5277777910232544, loss=1.2783839702606201
train: epoch 54, loss 0.2180059850215912, acc=0.9287222027778625, loss=0.2180059850215912
test: epoch 54, loss 1.1731452941894531, acc=0.5861111283302307, loss=1.1731452941894531
train: epoch 55, loss 0.20475609600543976, acc=0.9320555329322815, loss=0.20475609600543976
test: epoch 55, loss 1.09481942653656, acc=0.6027777791023254, loss=1.09481942653656
train: epoch 56, loss 0.20062284171581268, acc=0.9338333606719971, loss=0.20062284171581268
test: epoch 56, loss 1.0098421573638916, acc=0.6305555701255798, loss=1.0098421573638916
train: epoch 57, loss 0.2117680162191391, acc=0.9315555691719055, loss=0.2117680162191391
test: epoch 57, loss 1.2439143657684326, acc=0.5611110925674438, loss=1.2439143657684326
train: epoch 58, loss 0.2099343240261078, acc=0.9306666851043701, loss=0.2099343240261078
test: epoch 58, loss 1.0468330383300781, acc=0.6000000238418579, loss=1.0468330383300781
train: epoch 59, loss 0.20025219023227692, acc=0.9321666955947876, loss=0.20025219023227692
test: epoch 59, loss 1.025903582572937, acc=0.5944444537162781, loss=1.025903582572937
train: epoch 60, loss 0.20007377862930298, acc=0.9328888654708862, loss=0.20007377862930298
test: epoch 60, loss 1.1103216409683228, acc=0.6083333492279053, loss=1.1103216409683228
train: epoch 61, loss 0.20078738033771515, acc=0.9353333115577698, loss=0.20078738033771515
test: epoch 61, loss 0.9914697408676147, acc=0.6194444298744202, loss=0.9914697408676147
train: epoch 62, loss 0.19797971844673157, acc=0.9357222318649292, loss=0.19797971844673157
test: epoch 62, loss 0.8549182415008545, acc=0.6583333611488342, loss=0.8549182415008545
train: epoch 63, loss 0.18983766436576843, acc=0.9366666674613953, loss=0.18983766436576843
test: epoch 63, loss 1.0314342975616455, acc=0.6361111402511597, loss=1.0314342975616455
train: epoch 64, loss 0.1853291392326355, acc=0.9369999766349792, loss=0.1853291392326355
test: epoch 64, loss 0.9071077108383179, acc=0.6777777671813965, loss=0.9071077108383179
train: epoch 65, loss 0.19373047351837158, acc=0.9369444251060486, loss=0.19373047351837158
test: epoch 65, loss 0.9049766063690186, acc=0.675000011920929, loss=0.9049766063690186
train: epoch 66, loss 0.171805739402771, acc=0.9431111216545105, loss=0.171805739402771
test: epoch 66, loss 0.75214022397995, acc=0.7166666388511658, loss=0.75214022397995
train: epoch 67, loss 0.19376146793365479, acc=0.9368333220481873, loss=0.19376146793365479
test: epoch 67, loss 0.9131190180778503, acc=0.6888889074325562, loss=0.9131190180778503
train: epoch 68, loss 0.1784622073173523, acc=0.9387778043746948, loss=0.1784622073173523
test: epoch 68, loss 0.817855179309845, acc=0.7027778029441833, loss=0.817855179309845
train: epoch 69, loss 0.18815581500530243, acc=0.937333345413208, loss=0.18815581500530243
test: epoch 69, loss 0.7510142922401428, acc=0.7138888835906982, loss=0.7510142922401428
train: epoch 70, loss 0.1677730828523636, acc=0.9452221989631653, loss=0.1677730828523636
test: epoch 70, loss 0.7330800294876099, acc=0.730555534362793, loss=0.7330800294876099
train: epoch 71, loss 0.1595625877380371, acc=0.9444444179534912, loss=0.1595625877380371
test: epoch 71, loss 0.7479848265647888, acc=0.7583333253860474, loss=0.7479848265647888
train: epoch 72, loss 0.17472995817661285, acc=0.9430000185966492, loss=0.17472995817661285
test: epoch 72, loss 0.7836142778396606, acc=0.7444444298744202, loss=0.7836142778396606
train: epoch 73, loss 0.1737366020679474, acc=0.9430000185966492, loss=0.1737366020679474
test: epoch 73, loss 0.5899078249931335, acc=0.7833333611488342, loss=0.5899078249931335
train: epoch 74, loss 0.1739664077758789, acc=0.9440000057220459, loss=0.1739664077758789
test: epoch 74, loss 0.6223626136779785, acc=0.7972221970558167, loss=0.6223626136779785
train: epoch 75, loss 0.1618255376815796, acc=0.9438333511352539, loss=0.1618255376815796
test: epoch 75, loss 0.5740550756454468, acc=0.7722222208976746, loss=0.5740550756454468
train: epoch 76, loss 0.15559059381484985, acc=0.945888876914978, loss=0.15559059381484985
test: epoch 76, loss 0.536243200302124, acc=0.8111110925674438, loss=0.536243200302124
train: epoch 77, loss 0.1624675691127777, acc=0.9467222094535828, loss=0.1624675691127777
test: epoch 77, loss 0.5378210544586182, acc=0.7888888716697693, loss=0.5378210544586182
train: epoch 78, loss 0.15832427144050598, acc=0.9466666579246521, loss=0.15832427144050598
test: epoch 78, loss 0.5483484268188477, acc=0.8277778029441833, loss=0.5483484268188477
train: epoch 79, loss 0.14478830993175507, acc=0.9515555500984192, loss=0.14478830993175507
test: epoch 79, loss 0.4396444261074066, acc=0.8388888835906982, loss=0.4396444261074066
train: epoch 80, loss 0.14097368717193604, acc=0.9516666531562805, loss=0.14097368717193604
test: epoch 80, loss 0.4666670262813568, acc=0.8500000238418579, loss=0.4666670262813568
train: epoch 81, loss 0.15041445195674896, acc=0.949055552482605, loss=0.15041445195674896
test: epoch 81, loss 0.44122472405433655, acc=0.8111110925674438, loss=0.44122472405433655
train: epoch 82, loss 0.144685298204422, acc=0.9502221941947937, loss=0.144685298204422
test: epoch 82, loss 0.3665040135383606, acc=0.855555534362793, loss=0.3665040135383606
train: epoch 83, loss 0.14075152575969696, acc=0.949055552482605, loss=0.14075152575969696
test: epoch 83, loss 0.37764105200767517, acc=0.8527777791023254, loss=0.37764105200767517
train: epoch 84, loss 0.12980453670024872, acc=0.9525555372238159, loss=0.12980453670024872
test: epoch 84, loss 0.3367653489112854, acc=0.8611111044883728, loss=0.3367653489112854
train: epoch 85, loss 0.12622123956680298, acc=0.9545000195503235, loss=0.12622123956680298
test: epoch 85, loss 0.4054822325706482, acc=0.8583333492279053, loss=0.4054822325706482
train: epoch 86, loss 0.1322035789489746, acc=0.9547777771949768, loss=0.1322035789489746
test: epoch 86, loss 0.3488353192806244, acc=0.8805555701255798, loss=0.3488353192806244
train: epoch 87, loss 0.12781906127929688, acc=0.9577777981758118, loss=0.12781906127929688
test: epoch 87, loss 0.33843207359313965, acc=0.875, loss=0.33843207359313965
train: epoch 88, loss 0.12735916674137115, acc=0.9572222232818604, loss=0.12735916674137115
test: epoch 88, loss 0.4160427749156952, acc=0.8722222447395325, loss=0.4160427749156952
train: epoch 89, loss 0.13319186866283417, acc=0.9532222151756287, loss=0.13319186866283417
test: epoch 89, loss 0.34244483709335327, acc=0.8722222447395325, loss=0.34244483709335327
train: epoch 90, loss 0.11721078306436539, acc=0.9605555534362793, loss=0.11721078306436539
test: epoch 90, loss 0.2977873980998993, acc=0.894444465637207, loss=0.2977873980998993
train: epoch 91, loss 0.11252877116203308, acc=0.9601110816001892, loss=0.11252877116203308
test: epoch 91, loss 0.34909626841545105, acc=0.8833333253860474, loss=0.34909626841545105
train: epoch 92, loss 0.12023971974849701, acc=0.9592221975326538, loss=0.12023971974849701
test: epoch 92, loss 0.3391035497188568, acc=0.8888888955116272, loss=0.3391035497188568
train: epoch 93, loss 0.11651705205440521, acc=0.9597222208976746, loss=0.11651705205440521
test: epoch 93, loss 0.3230937123298645, acc=0.8861111402511597, loss=0.3230937123298645
train: epoch 94, loss 0.12613990902900696, acc=0.956333339214325, loss=0.12613990902900696
test: epoch 94, loss 0.31677690148353577, acc=0.8805555701255798, loss=0.31677690148353577
train: epoch 95, loss 0.1180691346526146, acc=0.9586111307144165, loss=0.1180691346526146
test: epoch 95, loss 0.23603461682796478, acc=0.9083333611488342, loss=0.23603461682796478
train: epoch 96, loss 0.12158692628145218, acc=0.9585000276565552, loss=0.12158692628145218
test: epoch 96, loss 0.27298030257225037, acc=0.9083333611488342, loss=0.27298030257225037
train: epoch 97, loss 0.11054431647062302, acc=0.9623888731002808, loss=0.11054431647062302
test: epoch 97, loss 0.27005699276924133, acc=0.8999999761581421, loss=0.27005699276924133
train: epoch 98, loss 0.10727430880069733, acc=0.9619444608688354, loss=0.10727430880069733
test: epoch 98, loss 0.2516753673553467, acc=0.9138888716697693, loss=0.2516753673553467
train: epoch 99, loss 0.13480472564697266, acc=0.9570000171661377, loss=0.13480472564697266
test: epoch 99, loss 0.25988298654556274, acc=0.9083333611488342, loss=0.25988298654556274
train: epoch 100, loss 0.10402736067771912, acc=0.9616110920906067, loss=0.10402736067771912
test: epoch 100, loss 0.2323703020811081, acc=0.9138888716697693, loss=0.2323703020811081
train: epoch 101, loss 0.10698583722114563, acc=0.9629444479942322, loss=0.10698583722114563
test: epoch 101, loss 0.225145161151886, acc=0.9138888716697693, loss=0.225145161151886
train: epoch 102, loss 0.10218629986047745, acc=0.9624444246292114, loss=0.10218629986047745
test: epoch 102, loss 0.24823006987571716, acc=0.9083333611488342, loss=0.24823006987571716
train: epoch 103, loss 0.09806070476770401, acc=0.9647777676582336, loss=0.09806070476770401
test: epoch 103, loss 0.2211941033601761, acc=0.9194444417953491, loss=0.2211941033601761
train: epoch 104, loss 0.10265711694955826, acc=0.9635000228881836, loss=0.10265711694955826
test: epoch 104, loss 0.20094327628612518, acc=0.9138888716697693, loss=0.20094327628612518
train: epoch 105, loss 0.10138645023107529, acc=0.9628888964653015, loss=0.10138645023107529
test: epoch 105, loss 0.23933027684688568, acc=0.9138888716697693, loss=0.23933027684688568
train: epoch 106, loss 0.09593231230974197, acc=0.9652222394943237, loss=0.09593231230974197
test: epoch 106, loss 0.21117109060287476, acc=0.9138888716697693, loss=0.21117109060287476
train: epoch 107, loss 0.09431750327348709, acc=0.965666651725769, loss=0.09431750327348709
test: epoch 107, loss 0.2614385783672333, acc=0.9138888716697693, loss=0.2614385783672333
train: epoch 108, loss 0.09267391264438629, acc=0.9649444222450256, loss=0.09267391264438629
test: epoch 108, loss 0.23145167529582977, acc=0.9138888716697693, loss=0.23145167529582977
train: epoch 109, loss 0.09535133838653564, acc=0.9651666879653931, loss=0.09535133838653564
test: epoch 109, loss 0.27500852942466736, acc=0.9083333611488342, loss=0.27500852942466736
train: epoch 110, loss 0.09055251628160477, acc=0.965833306312561, loss=0.09055251628160477
test: epoch 110, loss 0.23439089953899384, acc=0.9166666865348816, loss=0.23439089953899384
train: epoch 111, loss 0.09590113908052444, acc=0.9645000100135803, loss=0.09590113908052444
test: epoch 111, loss 0.2259042114019394, acc=0.9055555462837219, loss=0.2259042114019394
train: epoch 112, loss 0.08379165828227997, acc=0.9656111001968384, loss=0.08379165828227997
test: epoch 112, loss 0.212062805891037, acc=0.9194444417953491, loss=0.212062805891037
train: epoch 113, loss 0.08925873786211014, acc=0.9666110873222351, loss=0.08925873786211014
test: epoch 113, loss 0.23319505155086517, acc=0.9138888716697693, loss=0.23319505155086517
train: epoch 114, loss 0.08737006783485413, acc=0.9665555357933044, loss=0.08737006783485413
test: epoch 114, loss 0.2553851306438446, acc=0.9138888716697693, loss=0.2553851306438446
train: epoch 115, loss 0.08702018111944199, acc=0.9667222499847412, loss=0.08702018111944199
test: epoch 115, loss 0.3151068687438965, acc=0.9138888716697693, loss=0.3151068687438965
train: epoch 116, loss 0.0908609926700592, acc=0.967555582523346, loss=0.0908609926700592
test: epoch 116, loss 0.24711300432682037, acc=0.9138888716697693, loss=0.24711300432682037
train: epoch 117, loss 0.08102897554636002, acc=0.9695000052452087, loss=0.08102897554636002
test: epoch 117, loss 0.21474559605121613, acc=0.9194444417953491, loss=0.21474559605121613
train: epoch 118, loss 0.08574461191892624, acc=0.967555582523346, loss=0.08574461191892624
test: epoch 118, loss 0.22367611527442932, acc=0.9138888716697693, loss=0.22367611527442932
train: epoch 119, loss 0.08777440339326859, acc=0.9671666622161865, loss=0.08777440339326859
test: epoch 119, loss 0.2602633535861969, acc=0.9138888716697693, loss=0.2602633535861969
train: epoch 120, loss 0.08738511800765991, acc=0.9674444198608398, loss=0.08738511800765991
test: epoch 120, loss 0.22225002944469452, acc=0.9138888716697693, loss=0.22225002944469452
train: epoch 121, loss 0.08321385085582733, acc=0.9667222499847412, loss=0.08321385085582733
test: epoch 121, loss 0.2661576569080353, acc=0.9138888716697693, loss=0.2661576569080353
train: epoch 122, loss 0.08502107858657837, acc=0.9679999947547913, loss=0.08502107858657837
test: epoch 122, loss 0.20991940796375275, acc=0.9138888716697693, loss=0.20991940796375275
train: epoch 123, loss 0.08345939964056015, acc=0.968666672706604, loss=0.08345939964056015
test: epoch 123, loss 0.2140243798494339, acc=0.9138888716697693, loss=0.2140243798494339
train: epoch 124, loss 0.08810137957334518, acc=0.9690555334091187, loss=0.08810137957334518
test: epoch 124, loss 0.293765127658844, acc=0.9138888716697693, loss=0.293765127658844
train: epoch 125, loss 0.07817161828279495, acc=0.9691666960716248, loss=0.07817161828279495
test: epoch 125, loss 0.2665799856185913, acc=0.9138888716697693, loss=0.2665799856185913
train: epoch 126, loss 0.080197274684906, acc=0.968999981880188, loss=0.080197274684906
test: epoch 126, loss 0.27995651960372925, acc=0.9138888716697693, loss=0.27995651960372925
train: epoch 127, loss 0.08682189136743546, acc=0.9672222137451172, loss=0.08682189136743546
test: epoch 127, loss 0.25880521535873413, acc=0.9138888716697693, loss=0.25880521535873413
train: epoch 128, loss 0.0779818668961525, acc=0.9702777862548828, loss=0.0779818668961525
test: epoch 128, loss 0.2528277039527893, acc=0.9138888716697693, loss=0.2528277039527893
train: epoch 129, loss 0.08010338991880417, acc=0.9691666960716248, loss=0.08010338991880417
test: epoch 129, loss 0.24161291122436523, acc=0.9138888716697693, loss=0.24161291122436523
train: epoch 130, loss 0.08720917999744415, acc=0.9697777628898621, loss=0.08720917999744415
test: epoch 130, loss 0.2689662575721741, acc=0.9138888716697693, loss=0.2689662575721741
train: epoch 131, loss 0.07473500072956085, acc=0.9712777733802795, loss=0.07473500072956085
test: epoch 131, loss 0.2700307369232178, acc=0.9138888716697693, loss=0.2700307369232178
train: epoch 132, loss 0.07810328900814056, acc=0.9703888893127441, loss=0.07810328900814056
test: epoch 132, loss 0.2814325988292694, acc=0.9138888716697693, loss=0.2814325988292694
train: epoch 133, loss 0.08524621278047562, acc=0.9682777523994446, loss=0.08524621278047562
test: epoch 133, loss 0.24748054146766663, acc=0.9138888716697693, loss=0.24748054146766663
train: epoch 134, loss 0.08100695163011551, acc=0.9693889021873474, loss=0.08100695163011551
test: epoch 134, loss 0.29827290773391724, acc=0.9138888716697693, loss=0.29827290773391724
train: epoch 135, loss 0.08272092789411545, acc=0.9696666598320007, loss=0.08272092789411545
test: epoch 135, loss 0.2593168020248413, acc=0.9138888716697693, loss=0.2593168020248413
train: epoch 136, loss 0.08579796552658081, acc=0.9682777523994446, loss=0.08579796552658081
test: epoch 136, loss 0.22403916716575623, acc=0.9194444417953491, loss=0.22403916716575623
train: epoch 137, loss 0.07570834457874298, acc=0.9705555438995361, loss=0.07570834457874298
test: epoch 137, loss 0.2916572690010071, acc=0.9138888716697693, loss=0.2916572690010071
train: epoch 138, loss 0.08338206261396408, acc=0.9697777628898621, loss=0.08338206261396408
test: epoch 138, loss 0.23925788700580597, acc=0.9138888716697693, loss=0.23925788700580597
train: epoch 139, loss 0.07629822194576263, acc=0.9691110849380493, loss=0.07629822194576263
test: epoch 139, loss 0.20195885002613068, acc=0.9138888716697693, loss=0.20195885002613068
train: epoch 140, loss 0.08516347408294678, acc=0.9698333144187927, loss=0.08516347408294678
test: epoch 140, loss 0.23097623884677887, acc=0.9194444417953491, loss=0.23097623884677887
train: epoch 141, loss 0.07830651849508286, acc=0.9691110849380493, loss=0.07830651849508286
test: epoch 141, loss 0.28336575627326965, acc=0.9138888716697693, loss=0.28336575627326965
train: epoch 142, loss 0.07938170433044434, acc=0.9693889021873474, loss=0.07938170433044434
test: epoch 142, loss 0.28431957960128784, acc=0.9138888716697693, loss=0.28431957960128784
train: epoch 143, loss 0.08768748492002487, acc=0.9682222008705139, loss=0.08768748492002487
test: epoch 143, loss 0.2761988639831543, acc=0.9138888716697693, loss=0.2761988639831543
train: epoch 144, loss 0.07729288190603256, acc=0.9715555310249329, loss=0.07729288190603256
test: epoch 144, loss 0.2668367326259613, acc=0.9138888716697693, loss=0.2668367326259613
train: epoch 145, loss 0.07418148964643478, acc=0.9717777967453003, loss=0.07418148964643478
test: epoch 145, loss 0.21977819502353668, acc=0.9138888716697693, loss=0.21977819502353668
train: epoch 146, loss 0.07800958305597305, acc=0.9698333144187927, loss=0.07800958305597305
test: epoch 146, loss 0.2531905472278595, acc=0.9194444417953491, loss=0.2531905472278595
train: epoch 147, loss 0.08012747019529343, acc=0.9711666703224182, loss=0.08012747019529343
test: epoch 147, loss 0.253939688205719, acc=0.9138888716697693, loss=0.253939688205719
train: epoch 148, loss 0.07470149546861649, acc=0.9704444408416748, loss=0.07470149546861649
test: epoch 148, loss 0.2660202980041504, acc=0.9138888716697693, loss=0.2660202980041504
train: epoch 149, loss 0.08027004450559616, acc=0.9696111083030701, loss=0.08027004450559616
test: epoch 149, loss 0.3055626451969147, acc=0.9138888716697693, loss=0.3055626451969147
train: epoch 150, loss 0.07579272240400314, acc=0.9708333611488342, loss=0.07579272240400314
test: epoch 150, loss 0.25940725207328796, acc=0.9138888716697693, loss=0.25940725207328796
