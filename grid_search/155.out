# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=1", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=300695789, receiver_embed_dim=128, save_run=0, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=300695789, receiver_embed_dim=128, save_run=False, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.683899164199829, acc=0.10838888585567474, loss=2.683899164199829
test: epoch 1, loss 4.614344596862793, acc=0.1111111119389534, loss=4.614344596862793
train: epoch 2, loss 1.4787983894348145, acc=0.3970000147819519, loss=1.4787983894348145
test: epoch 2, loss 4.917900562286377, acc=0.17777778208255768, loss=4.917900562286377
train: epoch 3, loss 0.9239799380302429, acc=0.6238333582878113, loss=0.9239799380302429
test: epoch 3, loss 4.546484470367432, acc=0.23055554926395416, loss=4.546484470367432
train: epoch 4, loss 0.654854416847229, acc=0.742388904094696, loss=0.654854416847229
test: epoch 4, loss 3.8209121227264404, acc=0.23333333432674408, loss=3.8209121227264404
train: epoch 5, loss 0.5007379651069641, acc=0.8058333396911621, loss=0.5007379651069641
test: epoch 5, loss 3.436394691467285, acc=0.23055554926395416, loss=3.436394691467285
train: epoch 6, loss 0.4174838066101074, acc=0.8412222266197205, loss=0.4174838066101074
test: epoch 6, loss 2.5550618171691895, acc=0.38333332538604736, loss=2.5550618171691895
train: epoch 7, loss 0.3514397442340851, acc=0.8670555353164673, loss=0.3514397442340851
test: epoch 7, loss 2.5120010375976562, acc=0.3444444537162781, loss=2.5120010375976562
train: epoch 8, loss 0.30542075634002686, acc=0.8840555548667908, loss=0.30542075634002686
test: epoch 8, loss 2.300593852996826, acc=0.3361110985279083, loss=2.300593852996826
train: epoch 9, loss 0.2980985939502716, acc=0.8860555291175842, loss=0.2980985939502716
test: epoch 9, loss 2.305692195892334, acc=0.3027777671813965, loss=2.305692195892334
train: epoch 10, loss 0.27891042828559875, acc=0.8929444551467896, loss=0.27891042828559875
test: epoch 10, loss 2.6886820793151855, acc=0.36666667461395264, loss=2.6886820793151855
train: epoch 11, loss 0.2389148324728012, acc=0.9096666574478149, loss=0.2389148324728012
test: epoch 11, loss 2.2872426509857178, acc=0.3861111104488373, loss=2.2872426509857178
train: epoch 12, loss 0.22941887378692627, acc=0.913611114025116, loss=0.22941887378692627
test: epoch 12, loss 2.8755745887756348, acc=0.30000001192092896, loss=2.8755745887756348
train: epoch 13, loss 0.20743121206760406, acc=0.9269444346427917, loss=0.20743121206760406
test: epoch 13, loss 2.600334882736206, acc=0.40833333134651184, loss=2.600334882736206
train: epoch 14, loss 0.1975516527891159, acc=0.9336110949516296, loss=0.1975516527891159
test: epoch 14, loss 3.187354564666748, acc=0.3333333432674408, loss=3.187354564666748
train: epoch 15, loss 0.17823420464992523, acc=0.9399999976158142, loss=0.17823420464992523
test: epoch 15, loss 2.456000328063965, acc=0.40833333134651184, loss=2.456000328063965
train: epoch 16, loss 0.1617070883512497, acc=0.9469444155693054, loss=0.1617070883512497
test: epoch 16, loss 2.493309497833252, acc=0.34166666865348816, loss=2.493309497833252
train: epoch 17, loss 0.16746293008327484, acc=0.9445000290870667, loss=0.16746293008327484
test: epoch 17, loss 2.3022942543029785, acc=0.3472222089767456, loss=2.3022942543029785
train: epoch 18, loss 0.15708494186401367, acc=0.9478333592414856, loss=0.15708494186401367
test: epoch 18, loss 2.6459531784057617, acc=0.4333333373069763, loss=2.6459531784057617
train: epoch 19, loss 0.1470927894115448, acc=0.9527778029441833, loss=0.1470927894115448
test: epoch 19, loss 2.0561394691467285, acc=0.5138888955116272, loss=2.0561394691467285
train: epoch 20, loss 0.13424880802631378, acc=0.9547222256660461, loss=0.13424880802631378
test: epoch 20, loss 2.5481531620025635, acc=0.42222222685813904, loss=2.5481531620025635
train: epoch 21, loss 0.14102107286453247, acc=0.9557777643203735, loss=0.14102107286453247
test: epoch 21, loss 2.3767199516296387, acc=0.4583333432674408, loss=2.3767199516296387
train: epoch 22, loss 0.14000888168811798, acc=0.9548333287239075, loss=0.14000888168811798
test: epoch 22, loss 1.8065574169158936, acc=0.4749999940395355, loss=1.8065574169158936
train: epoch 23, loss 0.14195449650287628, acc=0.9529444575309753, loss=0.14195449650287628
test: epoch 23, loss 2.8193511962890625, acc=0.4472222328186035, loss=2.8193511962890625
train: epoch 24, loss 0.1236819475889206, acc=0.9602222442626953, loss=0.1236819475889206
test: epoch 24, loss 2.9190824031829834, acc=0.40833333134651184, loss=2.9190824031829834
train: epoch 25, loss 0.1293557584285736, acc=0.9608333110809326, loss=0.1293557584285736
test: epoch 25, loss 1.8939039707183838, acc=0.5111111402511597, loss=1.8939039707183838
train: epoch 26, loss 0.10782775282859802, acc=0.964888870716095, loss=0.10782775282859802
test: epoch 26, loss 2.1637465953826904, acc=0.4972222149372101, loss=2.1637465953826904
train: epoch 27, loss 0.12257911264896393, acc=0.961555540561676, loss=0.12257911264896393
test: epoch 27, loss 1.7770426273345947, acc=0.5388888716697693, loss=1.7770426273345947
train: epoch 28, loss 0.10073785483837128, acc=0.968999981880188, loss=0.10073785483837128
test: epoch 28, loss 2.2302908897399902, acc=0.42500001192092896, loss=2.2302908897399902
train: epoch 29, loss 0.11280331015586853, acc=0.9649999737739563, loss=0.11280331015586853
test: epoch 29, loss 1.8742344379425049, acc=0.49444442987442017, loss=1.8742344379425049
train: epoch 30, loss 0.10194216668605804, acc=0.9678888916969299, loss=0.10194216668605804
test: epoch 30, loss 1.4840803146362305, acc=0.550000011920929, loss=1.4840803146362305
train: epoch 31, loss 0.09332094341516495, acc=0.9708889126777649, loss=0.09332094341516495
test: epoch 31, loss 1.7742743492126465, acc=0.5249999761581421, loss=1.7742743492126465
train: epoch 32, loss 0.09507092833518982, acc=0.9690555334091187, loss=0.09507092833518982
test: epoch 32, loss 1.7338982820510864, acc=0.5694444179534912, loss=1.7338982820510864
train: epoch 33, loss 0.08994794636964798, acc=0.9744444489479065, loss=0.08994794636964798
test: epoch 33, loss 1.9317795038223267, acc=0.5305555462837219, loss=1.9317795038223267
train: epoch 34, loss 0.09126278012990952, acc=0.971833348274231, loss=0.09126278012990952
test: epoch 34, loss 1.4498423337936401, acc=0.5527777671813965, loss=1.4498423337936401
train: epoch 35, loss 0.08818630874156952, acc=0.973111093044281, loss=0.08818630874156952
test: epoch 35, loss 1.2440866231918335, acc=0.6305555701255798, loss=1.2440866231918335
train: epoch 36, loss 0.08238686621189117, acc=0.9761666655540466, loss=0.08238686621189117
test: epoch 36, loss 1.4051834344863892, acc=0.605555534362793, loss=1.4051834344863892
train: epoch 37, loss 0.07820481061935425, acc=0.9765555262565613, loss=0.07820481061935425
test: epoch 37, loss 1.6879299879074097, acc=0.625, loss=1.6879299879074097
train: epoch 38, loss 0.07552021741867065, acc=0.976722240447998, loss=0.07552021741867065
test: epoch 38, loss 1.5650051832199097, acc=0.5861111283302307, loss=1.5650051832199097
train: epoch 39, loss 0.07143275439739227, acc=0.9793888926506042, loss=0.07143275439739227
test: epoch 39, loss 1.1501290798187256, acc=0.730555534362793, loss=1.1501290798187256
train: epoch 40, loss 0.07723823189735413, acc=0.975944459438324, loss=0.07723823189735413
test: epoch 40, loss 1.1796660423278809, acc=0.7055555582046509, loss=1.1796660423278809
train: epoch 41, loss 0.06826192140579224, acc=0.980555534362793, loss=0.06826192140579224
test: epoch 41, loss 1.358764886856079, acc=0.6833333373069763, loss=1.358764886856079
train: epoch 42, loss 0.07608775049448013, acc=0.9782222509384155, loss=0.07608775049448013
test: epoch 42, loss 0.9368149042129517, acc=0.7055555582046509, loss=0.9368149042129517
train: epoch 43, loss 0.07242725044488907, acc=0.9786111116409302, loss=0.07242725044488907
test: epoch 43, loss 1.046256422996521, acc=0.75, loss=1.046256422996521
train: epoch 44, loss 0.05552152171730995, acc=0.9836666584014893, loss=0.05552152171730995
test: epoch 44, loss 0.7569176554679871, acc=0.7972221970558167, loss=0.7569176554679871
train: epoch 45, loss 0.06326449662446976, acc=0.9816111326217651, loss=0.06326449662446976
test: epoch 45, loss 0.9040331840515137, acc=0.7944444417953491, loss=0.9040331840515137
train: epoch 46, loss 0.06309641897678375, acc=0.9821666479110718, loss=0.06309641897678375
test: epoch 46, loss 0.5535794496536255, acc=0.8138889074325562, loss=0.5535794496536255
train: epoch 47, loss 0.05354631692171097, acc=0.9850555658340454, loss=0.05354631692171097
test: epoch 47, loss 0.6481369733810425, acc=0.8805555701255798, loss=0.6481369733810425
train: epoch 48, loss 0.06646178662776947, acc=0.9817777872085571, loss=0.06646178662776947
test: epoch 48, loss 0.6983698010444641, acc=0.8500000238418579, loss=0.6983698010444641
train: epoch 49, loss 0.03855564072728157, acc=0.9890555739402771, loss=0.03855564072728157
test: epoch 49, loss 0.6161617636680603, acc=0.8888888955116272, loss=0.6161617636680603
train: epoch 50, loss 0.05119014158844948, acc=0.9872221946716309, loss=0.05119014158844948
test: epoch 50, loss 0.5691916942596436, acc=0.8472222089767456, loss=0.5691916942596436
train: epoch 51, loss 0.05687212944030762, acc=0.9862222075462341, loss=0.05687212944030762
test: epoch 51, loss 0.46081557869911194, acc=0.8833333253860474, loss=0.46081557869911194
train: epoch 52, loss 0.04411269351840019, acc=0.988444447517395, loss=0.04411269351840019
test: epoch 52, loss 0.48340854048728943, acc=0.8999999761581421, loss=0.48340854048728943
train: epoch 53, loss 0.04144199192523956, acc=0.988277792930603, loss=0.04144199192523956
test: epoch 53, loss 0.3972928524017334, acc=0.8999999761581421, loss=0.3972928524017334
train: epoch 54, loss 0.04264656454324722, acc=0.9884999990463257, loss=0.04264656454324722
test: epoch 54, loss 0.29244327545166016, acc=0.9305555820465088, loss=0.29244327545166016
train: epoch 55, loss 0.03802986070513725, acc=0.9898889064788818, loss=0.03802986070513725
test: epoch 55, loss 0.3962317705154419, acc=0.9194444417953491, loss=0.3962317705154419
train: epoch 56, loss 0.034920983016490936, acc=0.9909444451332092, loss=0.034920983016490936
test: epoch 56, loss 0.38293448090553284, acc=0.9305555820465088, loss=0.38293448090553284
train: epoch 57, loss 0.04828619584441185, acc=0.9858333468437195, loss=0.04828619584441185
test: epoch 57, loss 0.36529669165611267, acc=0.9277777671813965, loss=0.36529669165611267
train: epoch 58, loss 0.04580804333090782, acc=0.9879444241523743, loss=0.04580804333090782
test: epoch 58, loss 0.34809815883636475, acc=0.9388889074325562, loss=0.34809815883636475
train: epoch 59, loss 0.027863461524248123, acc=0.9927777647972107, loss=0.027863461524248123
test: epoch 59, loss 0.27398863434791565, acc=0.9333333373069763, loss=0.27398863434791565
train: epoch 60, loss 0.033391304314136505, acc=0.9912777543067932, loss=0.033391304314136505
test: epoch 60, loss 0.23516108095645905, acc=0.9444444179534912, loss=0.23516108095645905
train: epoch 61, loss 0.031125664710998535, acc=0.9930555820465088, loss=0.031125664710998535
test: epoch 61, loss 0.20714938640594482, acc=0.9305555820465088, loss=0.20714938640594482
train: epoch 62, loss 0.038372669368982315, acc=0.9908888936042786, loss=0.038372669368982315
test: epoch 62, loss 0.16375760734081268, acc=0.9694444537162781, loss=0.16375760734081268
train: epoch 63, loss 0.02321130968630314, acc=0.9938889145851135, loss=0.02321130968630314
test: epoch 63, loss 0.2809266448020935, acc=0.9472222328186035, loss=0.2809266448020935
train: epoch 64, loss 0.02055840753018856, acc=0.9948333501815796, loss=0.02055840753018856
test: epoch 64, loss 0.2332204282283783, acc=0.9666666388511658, loss=0.2332204282283783
train: epoch 65, loss 0.029508069157600403, acc=0.992555558681488, loss=0.029508069157600403
test: epoch 65, loss 0.11545662581920624, acc=0.9722222089767456, loss=0.11545662581920624
train: epoch 66, loss 0.017352161929011345, acc=0.9962777495384216, loss=0.017352161929011345
test: epoch 66, loss 0.16956137120723724, acc=0.9750000238418579, loss=0.16956137120723724
train: epoch 67, loss 0.027597112581133842, acc=0.9938333630561829, loss=0.027597112581133842
test: epoch 67, loss 0.18139714002609253, acc=0.9722222089767456, loss=0.18139714002609253
train: epoch 68, loss 0.018474387004971504, acc=0.995888888835907, loss=0.018474387004971504
test: epoch 68, loss 0.17421045899391174, acc=0.9722222089767456, loss=0.17421045899391174
train: epoch 69, loss 0.026394706219434738, acc=0.9937777519226074, loss=0.026394706219434738
test: epoch 69, loss 0.14481960237026215, acc=0.9750000238418579, loss=0.14481960237026215
train: epoch 70, loss 0.029023122042417526, acc=0.9941111207008362, loss=0.029023122042417526
test: epoch 70, loss 0.08220863342285156, acc=0.9750000238418579, loss=0.08220863342285156
train: epoch 71, loss 0.02147192880511284, acc=0.9946666955947876, loss=0.02147192880511284
test: epoch 71, loss 0.16324292123317719, acc=0.9750000238418579, loss=0.16324292123317719
train: epoch 72, loss 0.02388153038918972, acc=0.9948889017105103, loss=0.02388153038918972
test: epoch 72, loss 0.09751057624816895, acc=0.9750000238418579, loss=0.09751057624816895
train: epoch 73, loss 0.009082776494324207, acc=0.9979444742202759, loss=0.009082776494324207
test: epoch 73, loss 0.14547964930534363, acc=0.9750000238418579, loss=0.14547964930534363
train: epoch 74, loss 0.02902098000049591, acc=0.9937777519226074, loss=0.02902098000049591
test: epoch 74, loss 0.12167873978614807, acc=0.9750000238418579, loss=0.12167873978614807
train: epoch 75, loss 0.016895029693841934, acc=0.9963333606719971, loss=0.016895029693841934
test: epoch 75, loss 0.12812523543834686, acc=0.9750000238418579, loss=0.12812523543834686
train: epoch 76, loss 0.011929716914892197, acc=0.9973888993263245, loss=0.011929716914892197
test: epoch 76, loss 0.09646085649728775, acc=0.9750000238418579, loss=0.09646085649728775
train: epoch 77, loss 0.01966371200978756, acc=0.9959999918937683, loss=0.01966371200978756
test: epoch 77, loss 0.12259145826101303, acc=0.9750000238418579, loss=0.12259145826101303
train: epoch 78, loss 0.02022557333111763, acc=0.9953333139419556, loss=0.02022557333111763
test: epoch 78, loss 0.10581982880830765, acc=0.9750000238418579, loss=0.10581982880830765
train: epoch 79, loss 0.01580228842794895, acc=0.996666669845581, loss=0.01580228842794895
test: epoch 79, loss 0.10414934158325195, acc=0.9750000238418579, loss=0.10414934158325195
train: epoch 80, loss 0.01677161641418934, acc=0.9961666464805603, loss=0.01677161641418934
test: epoch 80, loss 0.11430104821920395, acc=0.9750000238418579, loss=0.11430104821920395
train: epoch 81, loss 0.012295132502913475, acc=0.9971110820770264, loss=0.012295132502913475
test: epoch 81, loss 0.1856791228055954, acc=0.9750000238418579, loss=0.1856791228055954
train: epoch 82, loss 0.009176879189908504, acc=0.9977777600288391, loss=0.009176879189908504
test: epoch 82, loss 0.14683611690998077, acc=0.9750000238418579, loss=0.14683611690998077
train: epoch 83, loss 0.01804829016327858, acc=0.9963889122009277, loss=0.01804829016327858
test: epoch 83, loss 0.11291337013244629, acc=0.9750000238418579, loss=0.11291337013244629
train: epoch 84, loss 0.017456572502851486, acc=0.9966111183166504, loss=0.017456572502851486
test: epoch 84, loss 0.1117633655667305, acc=0.9750000238418579, loss=0.1117633655667305
train: epoch 85, loss 0.021314464509487152, acc=0.996055543422699, loss=0.021314464509487152
test: epoch 85, loss 0.1301283836364746, acc=0.9750000238418579, loss=0.1301283836364746
train: epoch 86, loss 0.01496370229870081, acc=0.9970555305480957, loss=0.01496370229870081
test: epoch 86, loss 0.11067091673612595, acc=0.9750000238418579, loss=0.11067091673612595
train: epoch 87, loss 0.016082866117358208, acc=0.9967222213745117, loss=0.016082866117358208
test: epoch 87, loss 0.12795114517211914, acc=0.9750000238418579, loss=0.12795114517211914
train: epoch 88, loss 0.014332040213048458, acc=0.9974444508552551, loss=0.014332040213048458
test: epoch 88, loss 0.1766742765903473, acc=0.9750000238418579, loss=0.1766742765903473
train: epoch 89, loss 0.021856512874364853, acc=0.9957777857780457, loss=0.021856512874364853
test: epoch 89, loss 0.12063871324062347, acc=0.9750000238418579, loss=0.12063871324062347
train: epoch 90, loss 0.01168040744960308, acc=0.9972222447395325, loss=0.01168040744960308
test: epoch 90, loss 0.1474762111902237, acc=0.9722222089767456, loss=0.1474762111902237
train: epoch 91, loss 0.013630947098135948, acc=0.9967777729034424, loss=0.013630947098135948
test: epoch 91, loss 0.11277152597904205, acc=0.9750000238418579, loss=0.11277152597904205
train: epoch 92, loss 0.008653821423649788, acc=0.9977777600288391, loss=0.008653821423649788
test: epoch 92, loss 0.11562328785657883, acc=0.9750000238418579, loss=0.11562328785657883
train: epoch 93, loss 0.008425046689808369, acc=0.9972222447395325, loss=0.008425046689808369
test: epoch 93, loss 0.14053097367286682, acc=0.9750000238418579, loss=0.14053097367286682
train: epoch 94, loss 0.009196634404361248, acc=0.9980555772781372, loss=0.009196634404361248
test: epoch 94, loss 0.13809803128242493, acc=0.9750000238418579, loss=0.13809803128242493
train: epoch 95, loss 0.03910074755549431, acc=0.9922778010368347, loss=0.03910074755549431
test: epoch 95, loss 0.03529253229498863, acc=0.9916666746139526, loss=0.03529253229498863
