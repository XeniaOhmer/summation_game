# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=0", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=1403363654, receiver_embed_dim=64, save_run=0, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=1403363654, receiver_embed_dim=64, save_run=False, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.5026984214782715, acc=0.14522221684455872, loss=2.5026984214782715
test: epoch 1, loss 4.577264785766602, acc=0.0694444477558136, loss=4.577264785766602
train: epoch 2, loss 1.761675477027893, acc=0.2913888990879059, loss=1.761675477027893
test: epoch 2, loss 3.90990948677063, acc=0.0833333358168602, loss=3.90990948677063
train: epoch 3, loss 1.517340064048767, acc=0.3742777705192566, loss=1.517340064048767
test: epoch 3, loss 3.738572359085083, acc=0.13055555522441864, loss=3.738572359085083
train: epoch 4, loss 1.3716343641281128, acc=0.4317222237586975, loss=1.3716343641281128
test: epoch 4, loss 3.045656442642212, acc=0.13055555522441864, loss=3.045656442642212
train: epoch 5, loss 1.249088168144226, acc=0.48394444584846497, loss=1.249088168144226
test: epoch 5, loss 3.5175869464874268, acc=0.1944444477558136, loss=3.5175869464874268
train: epoch 6, loss 1.1630938053131104, acc=0.5209444165229797, loss=1.1630938053131104
test: epoch 6, loss 2.51530122756958, acc=0.1944444477558136, loss=2.51530122756958
train: epoch 7, loss 1.0836542844772339, acc=0.5566111207008362, loss=1.0836542844772339
test: epoch 7, loss 2.2812771797180176, acc=0.2361111044883728, loss=2.2812771797180176
train: epoch 8, loss 1.0296412706375122, acc=0.5820000171661377, loss=1.0296412706375122
test: epoch 8, loss 2.455106258392334, acc=0.25555557012557983, loss=2.455106258392334
train: epoch 9, loss 0.967926561832428, acc=0.602222204208374, loss=0.967926561832428
test: epoch 9, loss 1.9596006870269775, acc=0.33888888359069824, loss=1.9596006870269775
train: epoch 10, loss 0.9392445683479309, acc=0.6192777752876282, loss=0.9392445683479309
test: epoch 10, loss 2.3257949352264404, acc=0.24444444477558136, loss=2.3257949352264404
train: epoch 11, loss 0.8932263255119324, acc=0.6422777771949768, loss=0.8932263255119324
test: epoch 11, loss 2.1047897338867188, acc=0.2666666805744171, loss=2.1047897338867188
train: epoch 12, loss 0.8687198758125305, acc=0.6570000052452087, loss=0.8687198758125305
test: epoch 12, loss 1.818215250968933, acc=0.35555556416511536, loss=1.818215250968933
train: epoch 13, loss 0.823834240436554, acc=0.6728888750076294, loss=0.823834240436554
test: epoch 13, loss 1.6946860551834106, acc=0.4472222328186035, loss=1.6946860551834106
train: epoch 14, loss 0.7726718187332153, acc=0.6958333253860474, loss=0.7726718187332153
test: epoch 14, loss 1.8706811666488647, acc=0.3055555522441864, loss=1.8706811666488647
train: epoch 15, loss 0.7943958044052124, acc=0.683722198009491, loss=0.7943958044052124
test: epoch 15, loss 2.1529510021209717, acc=0.3472222089767456, loss=2.1529510021209717
train: epoch 16, loss 0.7610720992088318, acc=0.7036111354827881, loss=0.7610720992088318
test: epoch 16, loss 2.3398642539978027, acc=0.24722221493721008, loss=2.3398642539978027
train: epoch 17, loss 0.7221842408180237, acc=0.7174999713897705, loss=0.7221842408180237
test: epoch 17, loss 2.106397867202759, acc=0.3472222089767456, loss=2.106397867202759
train: epoch 18, loss 0.7194879651069641, acc=0.7183889150619507, loss=0.7194879651069641
test: epoch 18, loss 1.9998881816864014, acc=0.3333333432674408, loss=1.9998881816864014
train: epoch 19, loss 0.7257207036018372, acc=0.7088888883590698, loss=0.7257207036018372
test: epoch 19, loss 1.8573949337005615, acc=0.2750000059604645, loss=1.8573949337005615
train: epoch 20, loss 0.6865496039390564, acc=0.7306666374206543, loss=0.6865496039390564
test: epoch 20, loss 1.6825090646743774, acc=0.3361110985279083, loss=1.6825090646743774
train: epoch 21, loss 0.663584291934967, acc=0.7351111173629761, loss=0.663584291934967
test: epoch 21, loss 1.5680162906646729, acc=0.3499999940395355, loss=1.5680162906646729
train: epoch 22, loss 0.6693077683448792, acc=0.7360555529594421, loss=0.6693077683448792
test: epoch 22, loss 2.1705832481384277, acc=0.3333333432674408, loss=2.1705832481384277
train: epoch 23, loss 0.6648074984550476, acc=0.734000027179718, loss=0.6648074984550476
test: epoch 23, loss 2.022711753845215, acc=0.26944443583488464, loss=2.022711753845215
train: epoch 24, loss 0.6223501563072205, acc=0.753944456577301, loss=0.6223501563072205
test: epoch 24, loss 1.738403558731079, acc=0.3722222149372101, loss=1.738403558731079
train: epoch 25, loss 0.6602880358695984, acc=0.738611102104187, loss=0.6602880358695984
test: epoch 25, loss 1.7580955028533936, acc=0.3583333194255829, loss=1.7580955028533936
train: epoch 26, loss 0.6073774695396423, acc=0.7584444284439087, loss=0.6073774695396423
test: epoch 26, loss 1.6186296939849854, acc=0.3166666626930237, loss=1.6186296939849854
train: epoch 27, loss 0.5985890030860901, acc=0.7631666660308838, loss=0.5985890030860901
test: epoch 27, loss 1.9909892082214355, acc=0.33888888359069824, loss=1.9909892082214355
train: epoch 28, loss 0.5944764614105225, acc=0.757777750492096, loss=0.5944764614105225
test: epoch 28, loss 1.5436596870422363, acc=0.36666667461395264, loss=1.5436596870422363
train: epoch 29, loss 0.5847228765487671, acc=0.7653889060020447, loss=0.5847228765487671
test: epoch 29, loss 2.1907811164855957, acc=0.34166666865348816, loss=2.1907811164855957
train: epoch 30, loss 0.5955300331115723, acc=0.7623888850212097, loss=0.5955300331115723
test: epoch 30, loss 1.779252529144287, acc=0.3861111104488373, loss=1.779252529144287
train: epoch 31, loss 0.5627110004425049, acc=0.774222195148468, loss=0.5627110004425049
test: epoch 31, loss 1.597176432609558, acc=0.43888887763023376, loss=1.597176432609558
train: epoch 32, loss 0.578005850315094, acc=0.7683333158493042, loss=0.578005850315094
test: epoch 32, loss 1.7532503604888916, acc=0.38333332538604736, loss=1.7532503604888916
train: epoch 33, loss 0.5661224126815796, acc=0.7726666927337646, loss=0.5661224126815796
test: epoch 33, loss 1.9558967351913452, acc=0.3055555522441864, loss=1.9558967351913452
train: epoch 34, loss 0.5509496927261353, acc=0.782444417476654, loss=0.5509496927261353
test: epoch 34, loss 1.502263069152832, acc=0.4749999940395355, loss=1.502263069152832
train: epoch 35, loss 0.5319948196411133, acc=0.7900000214576721, loss=0.5319948196411133
test: epoch 35, loss 1.4888248443603516, acc=0.4444444477558136, loss=1.4888248443603516
train: epoch 36, loss 0.5604395866394043, acc=0.7734444737434387, loss=0.5604395866394043
test: epoch 36, loss 1.6324502229690552, acc=0.36666667461395264, loss=1.6324502229690552
train: epoch 37, loss 0.5277733206748962, acc=0.7903888821601868, loss=0.5277733206748962
test: epoch 37, loss 1.7132389545440674, acc=0.375, loss=1.7132389545440674
train: epoch 38, loss 0.5277156829833984, acc=0.7903888821601868, loss=0.5277156829833984
test: epoch 38, loss 1.5716090202331543, acc=0.38055557012557983, loss=1.5716090202331543
train: epoch 39, loss 0.5279896855354309, acc=0.7821666598320007, loss=0.5279896855354309
test: epoch 39, loss 1.946719765663147, acc=0.3611111044883728, loss=1.946719765663147
train: epoch 40, loss 0.5095401406288147, acc=0.7941666841506958, loss=0.5095401406288147
test: epoch 40, loss 1.5633518695831299, acc=0.4722222089767456, loss=1.5633518695831299
train: epoch 41, loss 0.5137316584587097, acc=0.7931110858917236, loss=0.5137316584587097
test: epoch 41, loss 1.4767415523529053, acc=0.44999998807907104, loss=1.4767415523529053
train: epoch 42, loss 0.5251894593238831, acc=0.7894999980926514, loss=0.5251894593238831
test: epoch 42, loss 1.6640498638153076, acc=0.3638888895511627, loss=1.6640498638153076
train: epoch 43, loss 0.5211136341094971, acc=0.7891666889190674, loss=0.5211136341094971
test: epoch 43, loss 1.3875460624694824, acc=0.43611112236976624, loss=1.3875460624694824
train: epoch 44, loss 0.49476560950279236, acc=0.8031111359596252, loss=0.49476560950279236
test: epoch 44, loss 1.6453983783721924, acc=0.4138889014720917, loss=1.6453983783721924
train: epoch 45, loss 0.5332903265953064, acc=0.7876666784286499, loss=0.5332903265953064
test: epoch 45, loss 1.597297191619873, acc=0.4861111044883728, loss=1.597297191619873
train: epoch 46, loss 0.47706446051597595, acc=0.8108333349227905, loss=0.47706446051597595
test: epoch 46, loss 1.3552268743515015, acc=0.49166667461395264, loss=1.3552268743515015
train: epoch 47, loss 0.4992806017398834, acc=0.7975555658340454, loss=0.4992806017398834
test: epoch 47, loss 1.6913548707962036, acc=0.3888888955116272, loss=1.6913548707962036
train: epoch 48, loss 0.4679633378982544, acc=0.8126111030578613, loss=0.4679633378982544
test: epoch 48, loss 1.6466126441955566, acc=0.4277777671813965, loss=1.6466126441955566
train: epoch 49, loss 0.5015134215354919, acc=0.800166666507721, loss=0.5015134215354919
test: epoch 49, loss 1.8755500316619873, acc=0.3611111044883728, loss=1.8755500316619873
train: epoch 50, loss 0.4885480999946594, acc=0.8013333082199097, loss=0.4885480999946594
test: epoch 50, loss 1.728797435760498, acc=0.46388888359069824, loss=1.728797435760498
train: epoch 51, loss 0.4743237793445587, acc=0.808222234249115, loss=0.4743237793445587
test: epoch 51, loss 1.5989238023757935, acc=0.33888888359069824, loss=1.5989238023757935
train: epoch 52, loss 0.49461597204208374, acc=0.8024444580078125, loss=0.49461597204208374
test: epoch 52, loss 1.5196387767791748, acc=0.43888887763023376, loss=1.5196387767791748
train: epoch 53, loss 0.4706398844718933, acc=0.8114444613456726, loss=0.4706398844718933
test: epoch 53, loss 1.4386695623397827, acc=0.5222222208976746, loss=1.4386695623397827
train: epoch 54, loss 0.467704176902771, acc=0.8122222423553467, loss=0.467704176902771
test: epoch 54, loss 1.4038478136062622, acc=0.49166667461395264, loss=1.4038478136062622
train: epoch 55, loss 0.4686465859413147, acc=0.8136666417121887, loss=0.4686465859413147
test: epoch 55, loss 1.274407148361206, acc=0.5166666507720947, loss=1.274407148361206
train: epoch 56, loss 0.4620903432369232, acc=0.8152222037315369, loss=0.4620903432369232
test: epoch 56, loss 1.3038445711135864, acc=0.4611110985279083, loss=1.3038445711135864
train: epoch 57, loss 0.464169979095459, acc=0.815666675567627, loss=0.464169979095459
test: epoch 57, loss 1.3618154525756836, acc=0.4027777910232544, loss=1.3618154525756836
train: epoch 58, loss 0.4653761088848114, acc=0.8163889050483704, loss=0.4653761088848114
test: epoch 58, loss 1.566064715385437, acc=0.4833333194255829, loss=1.566064715385437
train: epoch 59, loss 0.4395660161972046, acc=0.8258333206176758, loss=0.4395660161972046
test: epoch 59, loss 1.364530086517334, acc=0.4972222149372101, loss=1.364530086517334
train: epoch 60, loss 0.44994455575942993, acc=0.8218888640403748, loss=0.44994455575942993
test: epoch 60, loss 1.4263811111450195, acc=0.4749999940395355, loss=1.4263811111450195
train: epoch 61, loss 0.4491519033908844, acc=0.8219444155693054, loss=0.4491519033908844
test: epoch 61, loss 1.1305900812149048, acc=0.5083333253860474, loss=1.1305900812149048
train: epoch 62, loss 0.4442000091075897, acc=0.824999988079071, loss=0.4442000091075897
test: epoch 62, loss 1.4376919269561768, acc=0.5027777552604675, loss=1.4376919269561768
train: epoch 63, loss 0.44630366563796997, acc=0.8263333439826965, loss=0.44630366563796997
test: epoch 63, loss 1.1831576824188232, acc=0.5111111402511597, loss=1.1831576824188232
train: epoch 64, loss 0.43236416578292847, acc=0.8250555396080017, loss=0.43236416578292847
test: epoch 64, loss 1.4537990093231201, acc=0.5638889074325562, loss=1.4537990093231201
train: epoch 65, loss 0.4652694761753082, acc=0.8104444742202759, loss=0.4652694761753082
test: epoch 65, loss 1.9141169786453247, acc=0.4472222328186035, loss=1.9141169786453247
train: epoch 66, loss 0.4599124789237976, acc=0.8181111216545105, loss=0.4599124789237976
test: epoch 66, loss 1.5289133787155151, acc=0.49444442987442017, loss=1.5289133787155151
train: epoch 67, loss 0.45486998558044434, acc=0.8191666603088379, loss=0.45486998558044434
test: epoch 67, loss 1.4930769205093384, acc=0.4194444417953491, loss=1.4930769205093384
train: epoch 68, loss 0.43816179037094116, acc=0.8270000219345093, loss=0.43816179037094116
test: epoch 68, loss 1.2430901527404785, acc=0.5111111402511597, loss=1.2430901527404785
train: epoch 69, loss 0.4251791536808014, acc=0.8328333497047424, loss=0.4251791536808014
test: epoch 69, loss 1.5443238019943237, acc=0.4555555582046509, loss=1.5443238019943237
train: epoch 70, loss 0.4620804190635681, acc=0.8169999718666077, loss=0.4620804190635681
test: epoch 70, loss 1.6868107318878174, acc=0.3916666805744171, loss=1.6868107318878174
train: epoch 71, loss 0.4765304625034332, acc=0.8110555410385132, loss=0.4765304625034332
test: epoch 71, loss 0.9313113689422607, acc=0.6722221970558167, loss=0.9313113689422607
train: epoch 72, loss 0.44594618678092957, acc=0.8231666684150696, loss=0.44594618678092957
test: epoch 72, loss 1.0773195028305054, acc=0.5777778029441833, loss=1.0773195028305054
train: epoch 73, loss 0.4363242983818054, acc=0.8318333625793457, loss=0.4363242983818054
test: epoch 73, loss 1.2118456363677979, acc=0.5111111402511597, loss=1.2118456363677979
train: epoch 74, loss 0.44451215863227844, acc=0.8250555396080017, loss=0.44451215863227844
test: epoch 74, loss 1.3478859663009644, acc=0.5444444417953491, loss=1.3478859663009644
train: epoch 75, loss 0.4517267942428589, acc=0.8209444284439087, loss=0.4517267942428589
test: epoch 75, loss 1.2792530059814453, acc=0.49444442987442017, loss=1.2792530059814453
train: epoch 76, loss 0.45074254274368286, acc=0.8220555782318115, loss=0.45074254274368286
test: epoch 76, loss 1.307122826576233, acc=0.6138888597488403, loss=1.307122826576233
train: epoch 77, loss 0.4282263219356537, acc=0.8280555605888367, loss=0.4282263219356537
test: epoch 77, loss 1.4134823083877563, acc=0.4888888895511627, loss=1.4134823083877563
train: epoch 78, loss 0.4409112334251404, acc=0.8262222409248352, loss=0.4409112334251404
test: epoch 78, loss 1.2497533559799194, acc=0.5083333253860474, loss=1.2497533559799194
train: epoch 79, loss 0.4513987600803375, acc=0.8208333253860474, loss=0.4513987600803375
test: epoch 79, loss 1.0375083684921265, acc=0.5527777671813965, loss=1.0375083684921265
train: epoch 80, loss 0.4117090702056885, acc=0.8388333320617676, loss=0.4117090702056885
test: epoch 80, loss 1.6337002515792847, acc=0.5444444417953491, loss=1.6337002515792847
train: epoch 81, loss 0.456440806388855, acc=0.8150555491447449, loss=0.456440806388855
test: epoch 81, loss 1.2313416004180908, acc=0.5277777910232544, loss=1.2313416004180908
train: epoch 82, loss 0.4403134882450104, acc=0.8272222280502319, loss=0.4403134882450104
test: epoch 82, loss 1.4813814163208008, acc=0.4583333432674408, loss=1.4813814163208008
train: epoch 83, loss 0.47527876496315, acc=0.8131666779518127, loss=0.47527876496315
test: epoch 83, loss 1.3627225160598755, acc=0.5138888955116272, loss=1.3627225160598755
train: epoch 84, loss 0.4348292946815491, acc=0.8255555629730225, loss=0.4348292946815491
test: epoch 84, loss 1.5067089796066284, acc=0.48055556416511536, loss=1.5067089796066284
train: epoch 85, loss 0.42896807193756104, acc=0.832611083984375, loss=0.42896807193756104
test: epoch 85, loss 1.4606014490127563, acc=0.5222222208976746, loss=1.4606014490127563
train: epoch 86, loss 0.44209179282188416, acc=0.831333339214325, loss=0.44209179282188416
test: epoch 86, loss 1.354797601699829, acc=0.5444444417953491, loss=1.354797601699829
train: epoch 87, loss 0.446848601102829, acc=0.8237777948379517, loss=0.446848601102829
test: epoch 87, loss 1.3041191101074219, acc=0.5111111402511597, loss=1.3041191101074219
train: epoch 88, loss 0.44426029920578003, acc=0.8215555548667908, loss=0.44426029920578003
test: epoch 88, loss 1.4233067035675049, acc=0.49444442987442017, loss=1.4233067035675049
train: epoch 89, loss 0.4465377628803253, acc=0.8224444389343262, loss=0.4465377628803253
test: epoch 89, loss 1.2892966270446777, acc=0.4583333432674408, loss=1.2892966270446777
train: epoch 90, loss 0.4184286594390869, acc=0.8351666927337646, loss=0.4184286594390869
test: epoch 90, loss 1.1868523359298706, acc=0.5611110925674438, loss=1.1868523359298706
train: epoch 91, loss 0.4223271906375885, acc=0.8275555372238159, loss=0.4223271906375885
test: epoch 91, loss 1.267706274986267, acc=0.550000011920929, loss=1.267706274986267
train: epoch 92, loss 0.4165639877319336, acc=0.8371666669845581, loss=0.4165639877319336
test: epoch 92, loss 1.2403889894485474, acc=0.5583333373069763, loss=1.2403889894485474
train: epoch 93, loss 0.45874789357185364, acc=0.8190555572509766, loss=0.45874789357185364
test: epoch 93, loss 1.1505944728851318, acc=0.5527777671813965, loss=1.1505944728851318
train: epoch 94, loss 0.4324701428413391, acc=0.82833331823349, loss=0.4324701428413391
test: epoch 94, loss 1.1905041933059692, acc=0.5388888716697693, loss=1.1905041933059692
train: epoch 95, loss 0.41316577792167664, acc=0.8395000100135803, loss=0.41316577792167664
test: epoch 95, loss 1.2694584131240845, acc=0.5777778029441833, loss=1.2694584131240845
train: epoch 96, loss 0.40951693058013916, acc=0.8403333425521851, loss=0.40951693058013916
test: epoch 96, loss 0.9619352221488953, acc=0.5888888835906982, loss=0.9619352221488953
train: epoch 97, loss 0.43081140518188477, acc=0.8290555477142334, loss=0.43081140518188477
test: epoch 97, loss 1.2986412048339844, acc=0.5805555582046509, loss=1.2986412048339844
train: epoch 98, loss 0.4415738582611084, acc=0.831333339214325, loss=0.4415738582611084
test: epoch 98, loss 0.9853185415267944, acc=0.5861111283302307, loss=0.9853185415267944
train: epoch 99, loss 0.41861292719841003, acc=0.8410000205039978, loss=0.41861292719841003
test: epoch 99, loss 0.9870353937149048, acc=0.5916666388511658, loss=0.9870353937149048
train: epoch 100, loss 0.4079378545284271, acc=0.8451111316680908, loss=0.4079378545284271
test: epoch 100, loss 1.2511235475540161, acc=0.5888888835906982, loss=1.2511235475540161
train: epoch 101, loss 0.432086706161499, acc=0.8335555791854858, loss=0.432086706161499
test: epoch 101, loss 1.1794244050979614, acc=0.5777778029441833, loss=1.1794244050979614
train: epoch 102, loss 0.40933799743652344, acc=0.8436111211776733, loss=0.40933799743652344
test: epoch 102, loss 1.2645432949066162, acc=0.5888888835906982, loss=1.2645432949066162
train: epoch 103, loss 0.4183959364891052, acc=0.8401111364364624, loss=0.4183959364891052
test: epoch 103, loss 0.9458440542221069, acc=0.625, loss=0.9458440542221069
train: epoch 104, loss 0.4101026952266693, acc=0.8403333425521851, loss=0.4101026952266693
test: epoch 104, loss 1.2943822145462036, acc=0.5361111164093018, loss=1.2943822145462036
train: epoch 105, loss 0.41055989265441895, acc=0.843666672706604, loss=0.41055989265441895
test: epoch 105, loss 0.9415305256843567, acc=0.6555555462837219, loss=0.9415305256843567
train: epoch 106, loss 0.4088038504123688, acc=0.8428888916969299, loss=0.4088038504123688
test: epoch 106, loss 1.0452128648757935, acc=0.605555534362793, loss=1.0452128648757935
train: epoch 107, loss 0.4094739854335785, acc=0.8404444456100464, loss=0.4094739854335785
test: epoch 107, loss 1.0503770112991333, acc=0.6305555701255798, loss=1.0503770112991333
train: epoch 108, loss 0.4014063775539398, acc=0.8470555543899536, loss=0.4014063775539398
test: epoch 108, loss 1.1799203157424927, acc=0.6277777552604675, loss=1.1799203157424927
train: epoch 109, loss 0.43967917561531067, acc=0.8300555348396301, loss=0.43967917561531067
test: epoch 109, loss 0.8838872313499451, acc=0.675000011920929, loss=0.8838872313499451
train: epoch 110, loss 0.40713346004486084, acc=0.8423888683319092, loss=0.40713346004486084
test: epoch 110, loss 0.9793221354484558, acc=0.6611111164093018, loss=0.9793221354484558
train: epoch 111, loss 0.434416800737381, acc=0.8343889117240906, loss=0.434416800737381
test: epoch 111, loss 1.2597935199737549, acc=0.5777778029441833, loss=1.2597935199737549
train: epoch 112, loss 0.44599679112434387, acc=0.8310555815696716, loss=0.44599679112434387
test: epoch 112, loss 0.9878189563751221, acc=0.6277777552604675, loss=0.9878189563751221
train: epoch 113, loss 0.4116998314857483, acc=0.8422222137451172, loss=0.4116998314857483
test: epoch 113, loss 1.1131305694580078, acc=0.574999988079071, loss=1.1131305694580078
train: epoch 114, loss 0.41099151968955994, acc=0.8441666960716248, loss=0.41099151968955994
test: epoch 114, loss 0.9101947546005249, acc=0.6305555701255798, loss=0.9101947546005249
train: epoch 115, loss 0.4112475514411926, acc=0.8416110873222351, loss=0.4112475514411926
test: epoch 115, loss 1.0694503784179688, acc=0.5916666388511658, loss=1.0694503784179688
train: epoch 116, loss 0.4402325451374054, acc=0.8305000066757202, loss=0.4402325451374054
test: epoch 116, loss 0.9857020378112793, acc=0.6305555701255798, loss=0.9857020378112793
train: epoch 117, loss 0.41607972979545593, acc=0.8391666412353516, loss=0.41607972979545593
test: epoch 117, loss 1.0458252429962158, acc=0.605555534362793, loss=1.0458252429962158
train: epoch 118, loss 0.3883083462715149, acc=0.8501666784286499, loss=0.3883083462715149
test: epoch 118, loss 1.3187525272369385, acc=0.6111111044883728, loss=1.3187525272369385
train: epoch 119, loss 0.4114944338798523, acc=0.8364444375038147, loss=0.4114944338798523
test: epoch 119, loss 1.0489156246185303, acc=0.6638888716697693, loss=1.0489156246185303
train: epoch 120, loss 0.40802904963493347, acc=0.8390555381774902, loss=0.40802904963493347
test: epoch 120, loss 1.1190615892410278, acc=0.6583333611488342, loss=1.1190615892410278
train: epoch 121, loss 0.3998167812824249, acc=0.8432777523994446, loss=0.3998167812824249
test: epoch 121, loss 0.959263801574707, acc=0.6277777552604675, loss=0.959263801574707
train: epoch 122, loss 0.38193148374557495, acc=0.8523333072662354, loss=0.38193148374557495
test: epoch 122, loss 0.9472864270210266, acc=0.6083333492279053, loss=0.9472864270210266
train: epoch 123, loss 0.41095438599586487, acc=0.8437222242355347, loss=0.41095438599586487
test: epoch 123, loss 1.1662083864212036, acc=0.644444465637207, loss=1.1662083864212036
train: epoch 124, loss 0.41025564074516296, acc=0.8390555381774902, loss=0.41025564074516296
test: epoch 124, loss 0.9268812537193298, acc=0.6583333611488342, loss=0.9268812537193298
train: epoch 125, loss 0.42706409096717834, acc=0.8392778038978577, loss=0.42706409096717834
test: epoch 125, loss 0.8131337761878967, acc=0.7083333134651184, loss=0.8131337761878967
train: epoch 126, loss 0.39897337555885315, acc=0.8457777500152588, loss=0.39897337555885315
test: epoch 126, loss 0.8525311350822449, acc=0.6583333611488342, loss=0.8525311350822449
train: epoch 127, loss 0.4349340498447418, acc=0.8339999914169312, loss=0.4349340498447418
test: epoch 127, loss 1.036132574081421, acc=0.6305555701255798, loss=1.036132574081421
train: epoch 128, loss 0.41886985301971436, acc=0.8381111025810242, loss=0.41886985301971436
test: epoch 128, loss 1.0065361261367798, acc=0.625, loss=1.0065361261367798
train: epoch 129, loss 0.4150294065475464, acc=0.8374999761581421, loss=0.4150294065475464
test: epoch 129, loss 0.7718280553817749, acc=0.6638888716697693, loss=0.7718280553817749
train: epoch 130, loss 0.39350709319114685, acc=0.8448888659477234, loss=0.39350709319114685
test: epoch 130, loss 1.0767114162445068, acc=0.6305555701255798, loss=1.0767114162445068
train: epoch 131, loss 0.41744181513786316, acc=0.8367778062820435, loss=0.41744181513786316
test: epoch 131, loss 0.8937034606933594, acc=0.6583333611488342, loss=0.8937034606933594
train: epoch 132, loss 0.4021247923374176, acc=0.8444444537162781, loss=0.4021247923374176
test: epoch 132, loss 0.845461368560791, acc=0.7027778029441833, loss=0.845461368560791
train: epoch 133, loss 0.4185292422771454, acc=0.8380555510520935, loss=0.4185292422771454
test: epoch 133, loss 0.9380136728286743, acc=0.6333333253860474, loss=0.9380136728286743
train: epoch 134, loss 0.4242163598537445, acc=0.8336111307144165, loss=0.4242163598537445
test: epoch 134, loss 0.8105151653289795, acc=0.6555555462837219, loss=0.8105151653289795
train: epoch 135, loss 0.4087067246437073, acc=0.8403888940811157, loss=0.4087067246437073
test: epoch 135, loss 0.9943513870239258, acc=0.6333333253860474, loss=0.9943513870239258
train: epoch 136, loss 0.3877715766429901, acc=0.8488888740539551, loss=0.3877715766429901
test: epoch 136, loss 0.9376989006996155, acc=0.6361111402511597, loss=0.9376989006996155
train: epoch 137, loss 0.4185027778148651, acc=0.8368333578109741, loss=0.4185027778148651
test: epoch 137, loss 1.0277174711227417, acc=0.6555555462837219, loss=1.0277174711227417
train: epoch 138, loss 0.4405474364757538, acc=0.8275555372238159, loss=0.4405474364757538
test: epoch 138, loss 0.8755337595939636, acc=0.6638888716697693, loss=0.8755337595939636
train: epoch 139, loss 0.38287878036499023, acc=0.8489444255828857, loss=0.38287878036499023
test: epoch 139, loss 0.9343694448471069, acc=0.6333333253860474, loss=0.9343694448471069
train: epoch 140, loss 0.41285619139671326, acc=0.8392778038978577, loss=0.41285619139671326
test: epoch 140, loss 0.7940540909767151, acc=0.6638888716697693, loss=0.7940540909767151
train: epoch 141, loss 0.44134098291397095, acc=0.8302222490310669, loss=0.44134098291397095
test: epoch 141, loss 0.7630378007888794, acc=0.7083333134651184, loss=0.7630378007888794
train: epoch 142, loss 0.4219356179237366, acc=0.8336666822433472, loss=0.4219356179237366
test: epoch 142, loss 0.8311917781829834, acc=0.6638888716697693, loss=0.8311917781829834
train: epoch 143, loss 0.40357232093811035, acc=0.8456666469573975, loss=0.40357232093811035
test: epoch 143, loss 0.9818480014801025, acc=0.6805555820465088, loss=0.9818480014801025
train: epoch 144, loss 0.4203438460826874, acc=0.8355555534362793, loss=0.4203438460826874
test: epoch 144, loss 0.7930371165275574, acc=0.7055555582046509, loss=0.7930371165275574
train: epoch 145, loss 0.38580548763275146, acc=0.8513333201408386, loss=0.38580548763275146
test: epoch 145, loss 1.049267053604126, acc=0.6527777910232544, loss=1.049267053604126
train: epoch 146, loss 0.43731677532196045, acc=0.8314444422721863, loss=0.43731677532196045
test: epoch 146, loss 0.9865468740463257, acc=0.625, loss=0.9865468740463257
train: epoch 147, loss 0.3938359320163727, acc=0.8498888611793518, loss=0.3938359320163727
test: epoch 147, loss 1.0081467628479004, acc=0.6333333253860474, loss=1.0081467628479004
train: epoch 148, loss 0.4324914216995239, acc=0.8230555653572083, loss=0.4324914216995239
test: epoch 148, loss 0.9052818417549133, acc=0.6722221970558167, loss=0.9052818417549133
train: epoch 149, loss 0.4465624690055847, acc=0.8166666626930237, loss=0.4465624690055847
test: epoch 149, loss 0.8472169041633606, acc=0.6666666865348816, loss=0.8472169041633606
train: epoch 150, loss 0.42660316824913025, acc=0.8335555791854858, loss=0.42660316824913025
test: epoch 150, loss 0.9919784665107727, acc=0.6222222447395325, loss=0.9919784665107727
