# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=1", "--temp_decay=0.995", "--one_hot=0", "--n_layers=1"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=1656233100, receiver_embed_dim=64, save_run=0, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=1656233100, receiver_embed_dim=64, save_run=False, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.249830961227417, acc=0.06511110812425613, loss=3.249830961227417
test: epoch 1, loss 3.637974739074707, acc=0.0555555559694767, loss=3.637974739074707
train: epoch 2, loss 2.8946831226348877, acc=0.1068333312869072, loss=2.8946831226348877
test: epoch 2, loss 3.829058885574341, acc=0.06111111119389534, loss=3.829058885574341
train: epoch 3, loss 2.7824835777282715, acc=0.11972222477197647, loss=2.7824835777282715
test: epoch 3, loss 3.923064947128296, acc=0.0555555559694767, loss=3.923064947128296
train: epoch 4, loss 2.7228193283081055, acc=0.1281111091375351, loss=2.7228193283081055
test: epoch 4, loss 3.9349536895751953, acc=0.0555555559694767, loss=3.9349536895751953
train: epoch 5, loss 2.6819169521331787, acc=0.12977777421474457, loss=2.6819169521331787
test: epoch 5, loss 3.9611856937408447, acc=0.0555555559694767, loss=3.9611856937408447
train: epoch 6, loss 2.654752731323242, acc=0.1326666623353958, loss=2.654752731323242
test: epoch 6, loss 4.015565395355225, acc=0.05833333358168602, loss=4.015565395355225
train: epoch 7, loss 2.6394033432006836, acc=0.13483333587646484, loss=2.6394033432006836
test: epoch 7, loss 4.027297496795654, acc=0.05833333358168602, loss=4.027297496795654
train: epoch 8, loss 2.610332489013672, acc=0.13883332908153534, loss=2.610332489013672
test: epoch 8, loss 4.040189266204834, acc=0.05833333358168602, loss=4.040189266204834
train: epoch 9, loss 2.591271162033081, acc=0.14350000023841858, loss=2.591271162033081
test: epoch 9, loss 3.972458600997925, acc=0.05833333358168602, loss=3.972458600997925
train: epoch 10, loss 2.581005096435547, acc=0.1459999978542328, loss=2.581005096435547
test: epoch 10, loss 4.081155776977539, acc=0.0555555559694767, loss=4.081155776977539
train: epoch 11, loss 2.561703681945801, acc=0.14661110937595367, loss=2.561703681945801
test: epoch 11, loss 4.020036697387695, acc=0.05277777835726738, loss=4.020036697387695
train: epoch 12, loss 2.562037467956543, acc=0.14949999749660492, loss=2.562037467956543
test: epoch 12, loss 4.040278911590576, acc=0.05833333358168602, loss=4.040278911590576
train: epoch 13, loss 2.5479066371917725, acc=0.1505555510520935, loss=2.5479066371917725
test: epoch 13, loss 3.9900248050689697, acc=0.0555555559694767, loss=3.9900248050689697
train: epoch 14, loss 2.5394210815429688, acc=0.1542777717113495, loss=2.5394210815429688
test: epoch 14, loss 4.007625102996826, acc=0.06388889253139496, loss=4.007625102996826
train: epoch 15, loss 2.5258495807647705, acc=0.15172222256660461, loss=2.5258495807647705
test: epoch 15, loss 3.8822379112243652, acc=0.06388889253139496, loss=3.8822379112243652
train: epoch 16, loss 2.5209805965423584, acc=0.15472222864627838, loss=2.5209805965423584
test: epoch 16, loss 3.835848331451416, acc=0.0694444477558136, loss=3.835848331451416
train: epoch 17, loss 2.50763201713562, acc=0.15688888728618622, loss=2.50763201713562
test: epoch 17, loss 3.8888022899627686, acc=0.07222222536802292, loss=3.8888022899627686
train: epoch 18, loss 2.5144424438476562, acc=0.15777777135372162, loss=2.5144424438476562
test: epoch 18, loss 3.835745096206665, acc=0.05833333358168602, loss=3.835745096206665
train: epoch 19, loss 2.505585193634033, acc=0.1583888828754425, loss=2.505585193634033
test: epoch 19, loss 3.925016403198242, acc=0.0694444477558136, loss=3.925016403198242
train: epoch 20, loss 2.4875359535217285, acc=0.1586666703224182, loss=2.4875359535217285
test: epoch 20, loss 4.023682117462158, acc=0.0694444477558136, loss=4.023682117462158
train: epoch 21, loss 2.4909305572509766, acc=0.16338889300823212, loss=2.4909305572509766
test: epoch 21, loss 3.768252372741699, acc=0.05277777835726738, loss=3.768252372741699
train: epoch 22, loss 2.483473062515259, acc=0.16172222793102264, loss=2.483473062515259
test: epoch 22, loss 3.7183568477630615, acc=0.06666667014360428, loss=3.7183568477630615
train: epoch 23, loss 2.484318971633911, acc=0.15744444727897644, loss=2.484318971633911
test: epoch 23, loss 3.8016138076782227, acc=0.05277777835726738, loss=3.8016138076782227
train: epoch 24, loss 2.465019464492798, acc=0.16272221505641937, loss=2.465019464492798
test: epoch 24, loss 3.7512547969818115, acc=0.05277777835726738, loss=3.7512547969818115
train: epoch 25, loss 2.4818220138549805, acc=0.16394443809986115, loss=2.4818220138549805
test: epoch 25, loss 3.7428596019744873, acc=0.08055555820465088, loss=3.7428596019744873
train: epoch 26, loss 2.4703872203826904, acc=0.1617777794599533, loss=2.4703872203826904
test: epoch 26, loss 3.706237316131592, acc=0.07222222536802292, loss=3.706237316131592
train: epoch 27, loss 2.470999240875244, acc=0.16083332896232605, loss=2.470999240875244
test: epoch 27, loss 3.6562888622283936, acc=0.0833333358168602, loss=3.6562888622283936
train: epoch 28, loss 2.461699962615967, acc=0.16661110520362854, loss=2.461699962615967
test: epoch 28, loss 3.7872447967529297, acc=0.07500000298023224, loss=3.7872447967529297
train: epoch 29, loss 2.451718807220459, acc=0.16522222757339478, loss=2.451718807220459
test: epoch 29, loss 3.66756272315979, acc=0.04722222313284874, loss=3.66756272315979
train: epoch 30, loss 2.4557573795318604, acc=0.17055556178092957, loss=2.4557573795318604
test: epoch 30, loss 3.7023696899414062, acc=0.05833333358168602, loss=3.7023696899414062
train: epoch 31, loss 2.451793670654297, acc=0.16944444179534912, loss=2.451793670654297
test: epoch 31, loss 3.6991970539093018, acc=0.05000000074505806, loss=3.6991970539093018
train: epoch 32, loss 2.4346354007720947, acc=0.17083333432674408, loss=2.4346354007720947
test: epoch 32, loss 3.6152126789093018, acc=0.06666667014360428, loss=3.6152126789093018
train: epoch 33, loss 2.4490365982055664, acc=0.16850000619888306, loss=2.4490365982055664
test: epoch 33, loss 3.63747239112854, acc=0.06666667014360428, loss=3.63747239112854
train: epoch 34, loss 2.447357177734375, acc=0.17044444382190704, loss=2.447357177734375
test: epoch 34, loss 3.634935140609741, acc=0.06666667014360428, loss=3.634935140609741
train: epoch 35, loss 2.434372663497925, acc=0.16966666281223297, loss=2.434372663497925
test: epoch 35, loss 3.549726724624634, acc=0.06666667014360428, loss=3.549726724624634
train: epoch 36, loss 2.4348721504211426, acc=0.16072222590446472, loss=2.4348721504211426
test: epoch 36, loss 3.5898995399475098, acc=0.06388889253139496, loss=3.5898995399475098
train: epoch 37, loss 2.445533037185669, acc=0.1608888953924179, loss=2.445533037185669
test: epoch 37, loss 3.519953727722168, acc=0.06111111119389534, loss=3.519953727722168
train: epoch 38, loss 2.4335741996765137, acc=0.16555555164813995, loss=2.4335741996765137
test: epoch 38, loss 3.504058361053467, acc=0.0694444477558136, loss=3.504058361053467
train: epoch 39, loss 2.447554111480713, acc=0.1673888862133026, loss=2.447554111480713
test: epoch 39, loss 3.433029890060425, acc=0.06388889253139496, loss=3.433029890060425
train: epoch 40, loss 2.442044496536255, acc=0.1728888899087906, loss=2.442044496536255
test: epoch 40, loss 3.485214948654175, acc=0.07222222536802292, loss=3.485214948654175
train: epoch 41, loss 2.4398462772369385, acc=0.16822221875190735, loss=2.4398462772369385
test: epoch 41, loss 3.4970128536224365, acc=0.0555555559694767, loss=3.4970128536224365
train: epoch 42, loss 2.4233176708221436, acc=0.16811111569404602, loss=2.4233176708221436
test: epoch 42, loss 3.4629592895507812, acc=0.06111111119389534, loss=3.4629592895507812
train: epoch 43, loss 2.422175168991089, acc=0.17000000178813934, loss=2.422175168991089
test: epoch 43, loss 3.511582612991333, acc=0.06111111119389534, loss=3.511582612991333
train: epoch 44, loss 2.420846462249756, acc=0.16949999332427979, loss=2.420846462249756
test: epoch 44, loss 3.476893424987793, acc=0.05833333358168602, loss=3.476893424987793
train: epoch 45, loss 2.425689458847046, acc=0.16994445025920868, loss=2.425689458847046
test: epoch 45, loss 3.520064353942871, acc=0.05277777835726738, loss=3.520064353942871
train: epoch 46, loss 2.4315412044525146, acc=0.16699999570846558, loss=2.4315412044525146
test: epoch 46, loss 3.266474485397339, acc=0.05833333358168602, loss=3.266474485397339
train: epoch 47, loss 2.417006254196167, acc=0.1675555557012558, loss=2.417006254196167
test: epoch 47, loss 3.268472671508789, acc=0.07222222536802292, loss=3.268472671508789
train: epoch 48, loss 2.436222791671753, acc=0.17238888144493103, loss=2.436222791671753
test: epoch 48, loss 3.3277969360351562, acc=0.06388889253139496, loss=3.3277969360351562
train: epoch 49, loss 2.4211840629577637, acc=0.17027777433395386, loss=2.4211840629577637
test: epoch 49, loss 3.4914467334747314, acc=0.06111111119389534, loss=3.4914467334747314
train: epoch 50, loss 2.4287455081939697, acc=0.16861110925674438, loss=2.4287455081939697
test: epoch 50, loss 3.2711493968963623, acc=0.07222222536802292, loss=3.2711493968963623
train: epoch 51, loss 2.4226489067077637, acc=0.17149999737739563, loss=2.4226489067077637
test: epoch 51, loss 3.2699079513549805, acc=0.0694444477558136, loss=3.2699079513549805
train: epoch 52, loss 2.436291217803955, acc=0.1691666692495346, loss=2.436291217803955
test: epoch 52, loss 3.388690233230591, acc=0.05277777835726738, loss=3.388690233230591
train: epoch 53, loss 2.414581537246704, acc=0.1720000058412552, loss=2.414581537246704
test: epoch 53, loss 3.2553446292877197, acc=0.07222222536802292, loss=3.2553446292877197
train: epoch 54, loss 2.424020528793335, acc=0.16433332860469818, loss=2.424020528793335
test: epoch 54, loss 3.197929620742798, acc=0.07222222536802292, loss=3.197929620742798
train: epoch 55, loss 2.4123623371124268, acc=0.171833336353302, loss=2.4123623371124268
test: epoch 55, loss 3.2623801231384277, acc=0.05277777835726738, loss=3.2623801231384277
train: epoch 56, loss 2.4168741703033447, acc=0.1678333282470703, loss=2.4168741703033447
test: epoch 56, loss 3.303042411804199, acc=0.0694444477558136, loss=3.303042411804199
train: epoch 57, loss 2.438171863555908, acc=0.16838888823986053, loss=2.438171863555908
test: epoch 57, loss 3.2237343788146973, acc=0.05833333358168602, loss=3.2237343788146973
train: epoch 58, loss 2.406320095062256, acc=0.1663888841867447, loss=2.406320095062256
test: epoch 58, loss 3.237445116043091, acc=0.07777778059244156, loss=3.237445116043091
train: epoch 59, loss 2.4060983657836914, acc=0.17149999737739563, loss=2.4060983657836914
test: epoch 59, loss 3.219651460647583, acc=0.07500000298023224, loss=3.219651460647583
train: epoch 60, loss 2.4270553588867188, acc=0.17588889598846436, loss=2.4270553588867188
test: epoch 60, loss 3.247589111328125, acc=0.08055555820465088, loss=3.247589111328125
train: epoch 61, loss 2.4084765911102295, acc=0.1752222180366516, loss=2.4084765911102295
test: epoch 61, loss 3.1777701377868652, acc=0.0833333358168602, loss=3.1777701377868652
train: epoch 62, loss 2.3928110599517822, acc=0.17594444751739502, loss=2.3928110599517822
test: epoch 62, loss 3.2481155395507812, acc=0.07222222536802292, loss=3.2481155395507812
train: epoch 63, loss 2.4037926197052, acc=0.16677777469158173, loss=2.4037926197052
test: epoch 63, loss 3.1773970127105713, acc=0.07500000298023224, loss=3.1773970127105713
train: epoch 64, loss 2.4113454818725586, acc=0.17105555534362793, loss=2.4113454818725586
test: epoch 64, loss 3.150047779083252, acc=0.0694444477558136, loss=3.150047779083252
train: epoch 65, loss 2.4013545513153076, acc=0.16722221672534943, loss=2.4013545513153076
test: epoch 65, loss 3.209517240524292, acc=0.07222222536802292, loss=3.209517240524292
train: epoch 66, loss 2.4047727584838867, acc=0.1758333295583725, loss=2.4047727584838867
test: epoch 66, loss 3.1481683254241943, acc=0.08888889104127884, loss=3.1481683254241943
train: epoch 67, loss 2.4063620567321777, acc=0.17338888347148895, loss=2.4063620567321777
test: epoch 67, loss 3.1520156860351562, acc=0.07777778059244156, loss=3.1520156860351562
train: epoch 68, loss 2.394437551498413, acc=0.17527778446674347, loss=2.394437551498413
test: epoch 68, loss 3.157611131668091, acc=0.07500000298023224, loss=3.157611131668091
train: epoch 69, loss 2.3929355144500732, acc=0.17427778244018555, loss=2.3929355144500732
test: epoch 69, loss 3.2296700477600098, acc=0.05833333358168602, loss=3.2296700477600098
train: epoch 70, loss 2.3849568367004395, acc=0.17527778446674347, loss=2.3849568367004395
test: epoch 70, loss 3.1750855445861816, acc=0.07500000298023224, loss=3.1750855445861816
train: epoch 71, loss 2.3858230113983154, acc=0.17366667091846466, loss=2.3858230113983154
test: epoch 71, loss 3.1670756340026855, acc=0.07222222536802292, loss=3.1670756340026855
train: epoch 72, loss 2.387998580932617, acc=0.17444443702697754, loss=2.387998580932617
test: epoch 72, loss 3.178163766860962, acc=0.07222222536802292, loss=3.178163766860962
train: epoch 73, loss 2.383777379989624, acc=0.1749444454908371, loss=2.383777379989624
test: epoch 73, loss 3.1971137523651123, acc=0.07500000298023224, loss=3.1971137523651123
train: epoch 74, loss 2.3852641582489014, acc=0.1753888875246048, loss=2.3852641582489014
test: epoch 74, loss 3.146901845932007, acc=0.06666667014360428, loss=3.146901845932007
train: epoch 75, loss 2.375638484954834, acc=0.17933332920074463, loss=2.375638484954834
test: epoch 75, loss 3.113753318786621, acc=0.05833333358168602, loss=3.113753318786621
train: epoch 76, loss 2.3954336643218994, acc=0.17383334040641785, loss=2.3954336643218994
test: epoch 76, loss 3.0708694458007812, acc=0.07500000298023224, loss=3.0708694458007812
train: epoch 77, loss 2.376246452331543, acc=0.17733334004878998, loss=2.376246452331543
test: epoch 77, loss 3.214738607406616, acc=0.07500000298023224, loss=3.214738607406616
train: epoch 78, loss 2.3716278076171875, acc=0.17927777767181396, loss=2.3716278076171875
test: epoch 78, loss 3.252322196960449, acc=0.07777778059244156, loss=3.252322196960449
train: epoch 79, loss 2.3545761108398438, acc=0.18138888478279114, loss=2.3545761108398438
test: epoch 79, loss 3.2076878547668457, acc=0.07222222536802292, loss=3.2076878547668457
train: epoch 80, loss 2.3754093647003174, acc=0.17738889157772064, loss=2.3754093647003174
test: epoch 80, loss 3.2194831371307373, acc=0.06388889253139496, loss=3.2194831371307373
train: epoch 81, loss 2.359560966491699, acc=0.185722216963768, loss=2.359560966491699
test: epoch 81, loss 3.258648157119751, acc=0.05833333358168602, loss=3.258648157119751
train: epoch 82, loss 2.360255241394043, acc=0.1832222193479538, loss=2.360255241394043
test: epoch 82, loss 3.205839157104492, acc=0.0694444477558136, loss=3.205839157104492
train: epoch 83, loss 2.3556647300720215, acc=0.17827777564525604, loss=2.3556647300720215
test: epoch 83, loss 3.203240394592285, acc=0.06111111119389534, loss=3.203240394592285
train: epoch 84, loss 2.362499952316284, acc=0.18038888275623322, loss=2.362499952316284
test: epoch 84, loss 3.1909329891204834, acc=0.0555555559694767, loss=3.1909329891204834
train: epoch 85, loss 2.348629951477051, acc=0.18177777528762817, loss=2.348629951477051
test: epoch 85, loss 3.098782539367676, acc=0.07777778059244156, loss=3.098782539367676
train: epoch 86, loss 2.340430736541748, acc=0.18511110544204712, loss=2.340430736541748
test: epoch 86, loss 3.1296231746673584, acc=0.07222222536802292, loss=3.1296231746673584
train: epoch 87, loss 2.342484474182129, acc=0.18211111426353455, loss=2.342484474182129
test: epoch 87, loss 3.208014726638794, acc=0.07500000298023224, loss=3.208014726638794
train: epoch 88, loss 2.333577871322632, acc=0.1836666613817215, loss=2.333577871322632
test: epoch 88, loss 3.092941999435425, acc=0.07777778059244156, loss=3.092941999435425
train: epoch 89, loss 2.3604965209960938, acc=0.18427777290344238, loss=2.3604965209960938
test: epoch 89, loss 3.236271858215332, acc=0.07500000298023224, loss=3.236271858215332
train: epoch 90, loss 2.346503496170044, acc=0.18266665935516357, loss=2.346503496170044
test: epoch 90, loss 3.1478471755981445, acc=0.0833333358168602, loss=3.1478471755981445
train: epoch 91, loss 2.3343751430511475, acc=0.18505555391311646, loss=2.3343751430511475
test: epoch 91, loss 3.2144052982330322, acc=0.06388889253139496, loss=3.2144052982330322
train: epoch 92, loss 2.3356924057006836, acc=0.18433333933353424, loss=2.3356924057006836
test: epoch 92, loss 3.2155449390411377, acc=0.07777778059244156, loss=3.2155449390411377
train: epoch 93, loss 2.3296377658843994, acc=0.1839444488286972, loss=2.3296377658843994
test: epoch 93, loss 3.1974563598632812, acc=0.07222222536802292, loss=3.1974563598632812
train: epoch 94, loss 2.3313093185424805, acc=0.19211110472679138, loss=2.3313093185424805
test: epoch 94, loss 3.151942729949951, acc=0.07777778059244156, loss=3.151942729949951
train: epoch 95, loss 2.3113934993743896, acc=0.1895555555820465, loss=2.3113934993743896
test: epoch 95, loss 3.2057483196258545, acc=0.06111111119389534, loss=3.2057483196258545
train: epoch 96, loss 2.3380625247955322, acc=0.1850000023841858, loss=2.3380625247955322
test: epoch 96, loss 3.1498970985412598, acc=0.05833333358168602, loss=3.1498970985412598
train: epoch 97, loss 2.3191959857940674, acc=0.1908888816833496, loss=2.3191959857940674
test: epoch 97, loss 3.120645523071289, acc=0.07500000298023224, loss=3.120645523071289
train: epoch 98, loss 2.3269801139831543, acc=0.18283332884311676, loss=2.3269801139831543
test: epoch 98, loss 3.178131103515625, acc=0.07777778059244156, loss=3.178131103515625
train: epoch 99, loss 2.327376127243042, acc=0.19083333015441895, loss=2.327376127243042
test: epoch 99, loss 3.1856253147125244, acc=0.08055555820465088, loss=3.1856253147125244
train: epoch 100, loss 2.307473659515381, acc=0.19038888812065125, loss=2.307473659515381
test: epoch 100, loss 3.3059921264648438, acc=0.07222222536802292, loss=3.3059921264648438
train: epoch 101, loss 2.315194606781006, acc=0.19205555319786072, loss=2.315194606781006
test: epoch 101, loss 3.223264694213867, acc=0.07777778059244156, loss=3.223264694213867
train: epoch 102, loss 2.3232791423797607, acc=0.18933333456516266, loss=2.3232791423797607
test: epoch 102, loss 3.161635398864746, acc=0.0694444477558136, loss=3.161635398864746
train: epoch 103, loss 2.3166215419769287, acc=0.19050000607967377, loss=2.3166215419769287
test: epoch 103, loss 3.177386522293091, acc=0.07222222536802292, loss=3.177386522293091
train: epoch 104, loss 2.2974581718444824, acc=0.19155555963516235, loss=2.2974581718444824
test: epoch 104, loss 3.2082927227020264, acc=0.07222222536802292, loss=3.2082927227020264
train: epoch 105, loss 2.3130264282226562, acc=0.19522222876548767, loss=2.3130264282226562
test: epoch 105, loss 3.1539154052734375, acc=0.08055555820465088, loss=3.1539154052734375
train: epoch 106, loss 2.2846672534942627, acc=0.19127777218818665, loss=2.2846672534942627
test: epoch 106, loss 3.218410015106201, acc=0.07222222536802292, loss=3.218410015106201
train: epoch 107, loss 2.3020384311676025, acc=0.1895555555820465, loss=2.3020384311676025
test: epoch 107, loss 3.243516206741333, acc=0.07500000298023224, loss=3.243516206741333
train: epoch 108, loss 2.2920405864715576, acc=0.19349999725818634, loss=2.2920405864715576
test: epoch 108, loss 3.264507532119751, acc=0.06388889253139496, loss=3.264507532119751
train: epoch 109, loss 2.2710204124450684, acc=0.19261111319065094, loss=2.2710204124450684
test: epoch 109, loss 3.162639856338501, acc=0.08055555820465088, loss=3.162639856338501
train: epoch 110, loss 2.2976198196411133, acc=0.19405555725097656, loss=2.2976198196411133
test: epoch 110, loss 3.1720218658447266, acc=0.07777778059244156, loss=3.1720218658447266
train: epoch 111, loss 2.286503314971924, acc=0.19777777791023254, loss=2.286503314971924
test: epoch 111, loss 3.2010223865509033, acc=0.06111111119389534, loss=3.2010223865509033
train: epoch 112, loss 2.3040311336517334, acc=0.19122222065925598, loss=2.3040311336517334
test: epoch 112, loss 3.1513516902923584, acc=0.07777778059244156, loss=3.1513516902923584
train: epoch 113, loss 2.2906157970428467, acc=0.19166666269302368, loss=2.2906157970428467
test: epoch 113, loss 3.1385498046875, acc=0.07500000298023224, loss=3.1385498046875
train: epoch 114, loss 2.279160737991333, acc=0.19988888502120972, loss=2.279160737991333
test: epoch 114, loss 3.171384811401367, acc=0.0833333358168602, loss=3.171384811401367
train: epoch 115, loss 2.2722020149230957, acc=0.19377778470516205, loss=2.2722020149230957
test: epoch 115, loss 3.186699151992798, acc=0.07500000298023224, loss=3.186699151992798
train: epoch 116, loss 2.2890424728393555, acc=0.19705554842948914, loss=2.2890424728393555
test: epoch 116, loss 3.1882641315460205, acc=0.0833333358168602, loss=3.1882641315460205
train: epoch 117, loss 2.2744550704956055, acc=0.20088888704776764, loss=2.2744550704956055
test: epoch 117, loss 3.2797720432281494, acc=0.08055555820465088, loss=3.2797720432281494
train: epoch 118, loss 2.277820348739624, acc=0.1969444453716278, loss=2.277820348739624
test: epoch 118, loss 3.2646138668060303, acc=0.0833333358168602, loss=3.2646138668060303
train: epoch 119, loss 2.2656052112579346, acc=0.1991666704416275, loss=2.2656052112579346
test: epoch 119, loss 3.2153148651123047, acc=0.07777778059244156, loss=3.2153148651123047
train: epoch 120, loss 2.265981912612915, acc=0.19683332741260529, loss=2.265981912612915
test: epoch 120, loss 3.2341411113739014, acc=0.08055555820465088, loss=3.2341411113739014
train: epoch 121, loss 2.264822006225586, acc=0.19949999451637268, loss=2.264822006225586
test: epoch 121, loss 3.275472402572632, acc=0.07222222536802292, loss=3.275472402572632
train: epoch 122, loss 2.268630266189575, acc=0.19866666197776794, loss=2.268630266189575
test: epoch 122, loss 3.179806709289551, acc=0.08055555820465088, loss=3.179806709289551
train: epoch 123, loss 2.2677364349365234, acc=0.19949999451637268, loss=2.2677364349365234
test: epoch 123, loss 3.2072341442108154, acc=0.07777778059244156, loss=3.2072341442108154
train: epoch 124, loss 2.249769687652588, acc=0.20294444262981415, loss=2.249769687652588
test: epoch 124, loss 3.217193603515625, acc=0.0833333358168602, loss=3.217193603515625
train: epoch 125, loss 2.256206750869751, acc=0.20027777552604675, loss=2.256206750869751
test: epoch 125, loss 3.180893659591675, acc=0.08055555820465088, loss=3.180893659591675
train: epoch 126, loss 2.259410858154297, acc=0.20133332908153534, loss=2.259410858154297
test: epoch 126, loss 3.24037766456604, acc=0.0833333358168602, loss=3.24037766456604
train: epoch 127, loss 2.258727788925171, acc=0.20105555653572083, loss=2.258727788925171
test: epoch 127, loss 3.091423273086548, acc=0.0833333358168602, loss=3.091423273086548
train: epoch 128, loss 2.2675962448120117, acc=0.19994445145130157, loss=2.2675962448120117
test: epoch 128, loss 3.1105852127075195, acc=0.0833333358168602, loss=3.1105852127075195
train: epoch 129, loss 2.2478525638580322, acc=0.2018333375453949, loss=2.2478525638580322
test: epoch 129, loss 3.1769585609436035, acc=0.0833333358168602, loss=3.1769585609436035
train: epoch 130, loss 2.261967658996582, acc=0.20399999618530273, loss=2.261967658996582
test: epoch 130, loss 3.2610552310943604, acc=0.05833333358168602, loss=3.2610552310943604
train: epoch 131, loss 2.2548089027404785, acc=0.20200000703334808, loss=2.2548089027404785
test: epoch 131, loss 3.2225756645202637, acc=0.0833333358168602, loss=3.2225756645202637
train: epoch 132, loss 2.2404603958129883, acc=0.20594444870948792, loss=2.2404603958129883
test: epoch 132, loss 3.1761488914489746, acc=0.0833333358168602, loss=3.1761488914489746
train: epoch 133, loss 2.2690584659576416, acc=0.20466665923595428, loss=2.2690584659576416
test: epoch 133, loss 3.1188206672668457, acc=0.0833333358168602, loss=3.1188206672668457
train: epoch 134, loss 2.2517776489257812, acc=0.20311111211776733, loss=2.2517776489257812
test: epoch 134, loss 3.318016290664673, acc=0.07777778059244156, loss=3.318016290664673
train: epoch 135, loss 2.2294325828552246, acc=0.20944444835186005, loss=2.2294325828552246
test: epoch 135, loss 3.220088005065918, acc=0.05833333358168602, loss=3.220088005065918
train: epoch 136, loss 2.2369565963745117, acc=0.203166663646698, loss=2.2369565963745117
test: epoch 136, loss 3.1761345863342285, acc=0.07222222536802292, loss=3.1761345863342285
train: epoch 137, loss 2.2342686653137207, acc=0.20800000429153442, loss=2.2342686653137207
test: epoch 137, loss 3.2392923831939697, acc=0.07500000298023224, loss=3.2392923831939697
train: epoch 138, loss 2.2392749786376953, acc=0.209055557847023, loss=2.2392749786376953
test: epoch 138, loss 3.3696646690368652, acc=0.05833333358168602, loss=3.3696646690368652
train: epoch 139, loss 2.2382216453552246, acc=0.20866666734218597, loss=2.2382216453552246
test: epoch 139, loss 3.2139534950256348, acc=0.0833333358168602, loss=3.2139534950256348
train: epoch 140, loss 2.2354562282562256, acc=0.21016666293144226, loss=2.2354562282562256
test: epoch 140, loss 3.2169787883758545, acc=0.07777778059244156, loss=3.2169787883758545
train: epoch 141, loss 2.2307050228118896, acc=0.20466665923595428, loss=2.2307050228118896
test: epoch 141, loss 3.255629539489746, acc=0.07777778059244156, loss=3.255629539489746
train: epoch 142, loss 2.2379791736602783, acc=0.20372222363948822, loss=2.2379791736602783
test: epoch 142, loss 3.2336888313293457, acc=0.07777778059244156, loss=3.2336888313293457
train: epoch 143, loss 2.2384629249572754, acc=0.20577777922153473, loss=2.2384629249572754
test: epoch 143, loss 3.162262439727783, acc=0.07500000298023224, loss=3.162262439727783
train: epoch 144, loss 2.2346017360687256, acc=0.21494443714618683, loss=2.2346017360687256
test: epoch 144, loss 3.2995171546936035, acc=0.0694444477558136, loss=3.2995171546936035
train: epoch 145, loss 2.2125980854034424, acc=0.2084999978542328, loss=2.2125980854034424
test: epoch 145, loss 3.1975748538970947, acc=0.08055555820465088, loss=3.1975748538970947
train: epoch 146, loss 2.2284202575683594, acc=0.21155555546283722, loss=2.2284202575683594
test: epoch 146, loss 3.205270767211914, acc=0.0833333358168602, loss=3.205270767211914
train: epoch 147, loss 2.2180871963500977, acc=0.21061110496520996, loss=2.2180871963500977
test: epoch 147, loss 3.266812562942505, acc=0.06666667014360428, loss=3.266812562942505
train: epoch 148, loss 2.2309436798095703, acc=0.20827777683734894, loss=2.2309436798095703
test: epoch 148, loss 3.2360541820526123, acc=0.0833333358168602, loss=3.2360541820526123
train: epoch 149, loss 2.2147393226623535, acc=0.20594444870948792, loss=2.2147393226623535
test: epoch 149, loss 3.173163652420044, acc=0.0833333358168602, loss=3.173163652420044
train: epoch 150, loss 2.214663505554199, acc=0.2092222273349762, loss=2.214663505554199
test: epoch 150, loss 3.3288919925689697, acc=0.07500000298023224, loss=3.3288919925689697
