# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=0", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=1673412073, receiver_embed_dim=32, save_run=0, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=1673412073, receiver_embed_dim=32, save_run=False, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.531883478164673, acc=0.1545555591583252, loss=2.531883478164673
test: epoch 1, loss 7.518248558044434, acc=0.06388889253139496, loss=7.518248558044434
train: epoch 2, loss 1.6307945251464844, acc=0.3377777636051178, loss=1.6307945251464844
test: epoch 2, loss 6.806291580200195, acc=0.0833333358168602, loss=6.806291580200195
train: epoch 3, loss 1.3873016834259033, acc=0.4284999966621399, loss=1.3873016834259033
test: epoch 3, loss 6.658620834350586, acc=0.11388888955116272, loss=6.658620834350586
train: epoch 4, loss 1.2176388502120972, acc=0.49122223258018494, loss=1.2176388502120972
test: epoch 4, loss 6.908995628356934, acc=0.10833333432674408, loss=6.908995628356934
train: epoch 5, loss 1.1018470525741577, acc=0.5484444499015808, loss=1.1018470525741577
test: epoch 5, loss 6.219669818878174, acc=0.14444445073604584, loss=6.219669818878174
train: epoch 6, loss 1.0312094688415527, acc=0.5747222304344177, loss=1.0312094688415527
test: epoch 6, loss 6.6941423416137695, acc=0.13611111044883728, loss=6.6941423416137695
train: epoch 7, loss 0.970075249671936, acc=0.6039999723434448, loss=0.970075249671936
test: epoch 7, loss 5.872955322265625, acc=0.14444445073604584, loss=5.872955322265625
train: epoch 8, loss 0.8865438103675842, acc=0.6370000243186951, loss=0.8865438103675842
test: epoch 8, loss 6.5921244621276855, acc=0.13055555522441864, loss=6.5921244621276855
train: epoch 9, loss 0.8551248908042908, acc=0.6552777886390686, loss=0.8551248908042908
test: epoch 9, loss 6.0124335289001465, acc=0.11944444477558136, loss=6.0124335289001465
train: epoch 10, loss 0.8203315734863281, acc=0.6734444499015808, loss=0.8203315734863281
test: epoch 10, loss 5.022721290588379, acc=0.23055554926395416, loss=5.022721290588379
train: epoch 11, loss 0.8075422644615173, acc=0.6737222075462341, loss=0.8075422644615173
test: epoch 11, loss 4.07672119140625, acc=0.1944444477558136, loss=4.07672119140625
train: epoch 12, loss 0.766372561454773, acc=0.6966111063957214, loss=0.766372561454773
test: epoch 12, loss 4.516599178314209, acc=0.20555555820465088, loss=4.516599178314209
train: epoch 13, loss 0.7411786317825317, acc=0.7075555324554443, loss=0.7411786317825317
test: epoch 13, loss 5.682563304901123, acc=0.18611110746860504, loss=5.682563304901123
train: epoch 14, loss 0.7381030321121216, acc=0.7027222514152527, loss=0.7381030321121216
test: epoch 14, loss 4.150761604309082, acc=0.24722221493721008, loss=4.150761604309082
train: epoch 15, loss 0.7028861045837402, acc=0.7248333096504211, loss=0.7028861045837402
test: epoch 15, loss 4.8574323654174805, acc=0.14444445073604584, loss=4.8574323654174805
train: epoch 16, loss 0.6916533708572388, acc=0.734499990940094, loss=0.6916533708572388
test: epoch 16, loss 3.9483377933502197, acc=0.25833332538604736, loss=3.9483377933502197
train: epoch 17, loss 0.6693843007087708, acc=0.7379999756813049, loss=0.6693843007087708
test: epoch 17, loss 4.419415473937988, acc=0.2222222238779068, loss=4.419415473937988
train: epoch 18, loss 0.6665261387825012, acc=0.7436110973358154, loss=0.6665261387825012
test: epoch 18, loss 3.702423095703125, acc=0.2888889014720917, loss=3.702423095703125
train: epoch 19, loss 0.6591929197311401, acc=0.7424444556236267, loss=0.6591929197311401
test: epoch 19, loss 3.4907238483428955, acc=0.2916666567325592, loss=3.4907238483428955
train: epoch 20, loss 0.6439967751502991, acc=0.7491666674613953, loss=0.6439967751502991
test: epoch 20, loss 3.2805848121643066, acc=0.25833332538604736, loss=3.2805848121643066
train: epoch 21, loss 0.6263611912727356, acc=0.7587777972221375, loss=0.6263611912727356
test: epoch 21, loss 3.2062642574310303, acc=0.28333333134651184, loss=3.2062642574310303
train: epoch 22, loss 0.6084551215171814, acc=0.7709444165229797, loss=0.6084551215171814
test: epoch 22, loss 3.7559831142425537, acc=0.2222222238779068, loss=3.7559831142425537
train: epoch 23, loss 0.5938267707824707, acc=0.7745555639266968, loss=0.5938267707824707
test: epoch 23, loss 2.741140127182007, acc=0.3166666626930237, loss=2.741140127182007
train: epoch 24, loss 0.5915257930755615, acc=0.7761666774749756, loss=0.5915257930755615
test: epoch 24, loss 2.92146372795105, acc=0.3638888895511627, loss=2.92146372795105
train: epoch 25, loss 0.5781844258308411, acc=0.7796111106872559, loss=0.5781844258308411
test: epoch 25, loss 2.4059042930603027, acc=0.3333333432674408, loss=2.4059042930603027
train: epoch 26, loss 0.5712612271308899, acc=0.7775555849075317, loss=0.5712612271308899
test: epoch 26, loss 2.5562021732330322, acc=0.3305555582046509, loss=2.5562021732330322
train: epoch 27, loss 0.5411239266395569, acc=0.7901666760444641, loss=0.5411239266395569
test: epoch 27, loss 3.1231143474578857, acc=0.24166665971279144, loss=3.1231143474578857
train: epoch 28, loss 0.5245820879936218, acc=0.7986666560173035, loss=0.5245820879936218
test: epoch 28, loss 2.5036754608154297, acc=0.2916666567325592, loss=2.5036754608154297
train: epoch 29, loss 0.5391472578048706, acc=0.7947777509689331, loss=0.5391472578048706
test: epoch 29, loss 3.0862808227539062, acc=0.30000001192092896, loss=3.0862808227539062
train: epoch 30, loss 0.5360546112060547, acc=0.7976666688919067, loss=0.5360546112060547
test: epoch 30, loss 2.3685107231140137, acc=0.3222222328186035, loss=2.3685107231140137
train: epoch 31, loss 0.5131750702857971, acc=0.8033333420753479, loss=0.5131750702857971
test: epoch 31, loss 2.4233438968658447, acc=0.36944442987442017, loss=2.4233438968658447
train: epoch 32, loss 0.5146095156669617, acc=0.805055558681488, loss=0.5146095156669617
test: epoch 32, loss 2.0057196617126465, acc=0.375, loss=2.0057196617126465
train: epoch 33, loss 0.5096306204795837, acc=0.8086110949516296, loss=0.5096306204795837
test: epoch 33, loss 2.5626566410064697, acc=0.3166666626930237, loss=2.5626566410064697
train: epoch 34, loss 0.5023475289344788, acc=0.8093888759613037, loss=0.5023475289344788
test: epoch 34, loss 2.330042600631714, acc=0.3916666805744171, loss=2.330042600631714
train: epoch 35, loss 0.4848257303237915, acc=0.8184444308280945, loss=0.4848257303237915
test: epoch 35, loss 2.4532454013824463, acc=0.2777777910232544, loss=2.4532454013824463
train: epoch 36, loss 0.4819234609603882, acc=0.820722222328186, loss=0.4819234609603882
test: epoch 36, loss 2.322205066680908, acc=0.29722222685813904, loss=2.322205066680908
train: epoch 37, loss 0.46826356649398804, acc=0.8228333592414856, loss=0.46826356649398804
test: epoch 37, loss 2.321190118789673, acc=0.375, loss=2.321190118789673
train: epoch 38, loss 0.4692660868167877, acc=0.824833333492279, loss=0.4692660868167877
test: epoch 38, loss 1.8688273429870605, acc=0.3611111044883728, loss=1.8688273429870605
train: epoch 39, loss 0.4687119126319885, acc=0.8262777924537659, loss=0.4687119126319885
test: epoch 39, loss 3.011129379272461, acc=0.28333333134651184, loss=3.011129379272461
train: epoch 40, loss 0.46623674035072327, acc=0.8279444575309753, loss=0.46623674035072327
test: epoch 40, loss 2.3609182834625244, acc=0.39722222089767456, loss=2.3609182834625244
train: epoch 41, loss 0.47416365146636963, acc=0.8245000243186951, loss=0.47416365146636963
test: epoch 41, loss 2.9288716316223145, acc=0.23888888955116272, loss=2.9288716316223145
train: epoch 42, loss 0.45277726650238037, acc=0.8303333520889282, loss=0.45277726650238037
test: epoch 42, loss 2.8738789558410645, acc=0.2916666567325592, loss=2.8738789558410645
train: epoch 43, loss 0.4567558467388153, acc=0.8314444422721863, loss=0.4567558467388153
test: epoch 43, loss 2.5689549446105957, acc=0.35555556416511536, loss=2.5689549446105957
train: epoch 44, loss 0.4464455842971802, acc=0.8327222466468811, loss=0.4464455842971802
test: epoch 44, loss 2.05947208404541, acc=0.3777777850627899, loss=2.05947208404541
train: epoch 45, loss 0.46171295642852783, acc=0.8273888826370239, loss=0.46171295642852783
test: epoch 45, loss 2.1031599044799805, acc=0.35277777910232544, loss=2.1031599044799805
train: epoch 46, loss 0.45561710000038147, acc=0.8329444527626038, loss=0.45561710000038147
test: epoch 46, loss 1.6563538312911987, acc=0.44999998807907104, loss=1.6563538312911987
train: epoch 47, loss 0.4548190236091614, acc=0.828000009059906, loss=0.4548190236091614
test: epoch 47, loss 2.4976797103881836, acc=0.30000001192092896, loss=2.4976797103881836
train: epoch 48, loss 0.4414953589439392, acc=0.8385000228881836, loss=0.4414953589439392
test: epoch 48, loss 2.703385829925537, acc=0.2666666805744171, loss=2.703385829925537
train: epoch 49, loss 0.4469579756259918, acc=0.8397777676582336, loss=0.4469579756259918
test: epoch 49, loss 2.179408550262451, acc=0.3638888895511627, loss=2.179408550262451
train: epoch 50, loss 0.4756808578968048, acc=0.8169999718666077, loss=0.4756808578968048
test: epoch 50, loss 3.3859152793884277, acc=0.3222222328186035, loss=3.3859152793884277
train: epoch 51, loss 0.4576883912086487, acc=0.8317221999168396, loss=0.4576883912086487
test: epoch 51, loss 2.2337028980255127, acc=0.39444443583488464, loss=2.2337028980255127
train: epoch 52, loss 0.44824928045272827, acc=0.8287777900695801, loss=0.44824928045272827
test: epoch 52, loss 2.002481698989868, acc=0.4138889014720917, loss=2.002481698989868
train: epoch 53, loss 0.428902804851532, acc=0.8435555696487427, loss=0.428902804851532
test: epoch 53, loss 2.0454373359680176, acc=0.3861111104488373, loss=2.0454373359680176
train: epoch 54, loss 0.4435785412788391, acc=0.8351666927337646, loss=0.4435785412788391
test: epoch 54, loss 2.157790422439575, acc=0.3611111044883728, loss=2.157790422439575
train: epoch 55, loss 0.44610077142715454, acc=0.8357222080230713, loss=0.44610077142715454
test: epoch 55, loss 2.0073230266571045, acc=0.35555556416511536, loss=2.0073230266571045
train: epoch 56, loss 0.4470437467098236, acc=0.8314444422721863, loss=0.4470437467098236
test: epoch 56, loss 1.8916981220245361, acc=0.39444443583488464, loss=1.8916981220245361
train: epoch 57, loss 0.4387248158454895, acc=0.8353888988494873, loss=0.4387248158454895
test: epoch 57, loss 2.082137107849121, acc=0.27222222089767456, loss=2.082137107849121
train: epoch 58, loss 0.44433319568634033, acc=0.8335000276565552, loss=0.44433319568634033
test: epoch 58, loss 2.1309547424316406, acc=0.42222222685813904, loss=2.1309547424316406
train: epoch 59, loss 0.4263879954814911, acc=0.8395000100135803, loss=0.4263879954814911
test: epoch 59, loss 1.7049833536148071, acc=0.42500001192092896, loss=1.7049833536148071
train: epoch 60, loss 0.4559798538684845, acc=0.8295555710792542, loss=0.4559798538684845
test: epoch 60, loss 2.2081220149993896, acc=0.38333332538604736, loss=2.2081220149993896
train: epoch 61, loss 0.44632449746131897, acc=0.8316666483879089, loss=0.44632449746131897
test: epoch 61, loss 1.6576738357543945, acc=0.4611110985279083, loss=1.6576738357543945
train: epoch 62, loss 0.41869956254959106, acc=0.8412222266197205, loss=0.41869956254959106
test: epoch 62, loss 2.4181108474731445, acc=0.32499998807907104, loss=2.4181108474731445
train: epoch 63, loss 0.4113505482673645, acc=0.8475555777549744, loss=0.4113505482673645
test: epoch 63, loss 1.812537670135498, acc=0.3611111044883728, loss=1.812537670135498
train: epoch 64, loss 0.4430815279483795, acc=0.8290555477142334, loss=0.4430815279483795
test: epoch 64, loss 1.6654566526412964, acc=0.4472222328186035, loss=1.6654566526412964
train: epoch 65, loss 0.4077875316143036, acc=0.8446666598320007, loss=0.4077875316143036
test: epoch 65, loss 1.8390798568725586, acc=0.4138889014720917, loss=1.8390798568725586
train: epoch 66, loss 0.42632415890693665, acc=0.8441110849380493, loss=0.42632415890693665
test: epoch 66, loss 2.095247268676758, acc=0.38333332538604736, loss=2.095247268676758
train: epoch 67, loss 0.43708303570747375, acc=0.8355000019073486, loss=0.43708303570747375
test: epoch 67, loss 2.1368343830108643, acc=0.38055557012557983, loss=2.1368343830108643
train: epoch 68, loss 0.42849159240722656, acc=0.8385000228881836, loss=0.42849159240722656
test: epoch 68, loss 1.5697473287582397, acc=0.4333333373069763, loss=1.5697473287582397
train: epoch 69, loss 0.4154919981956482, acc=0.8461111187934875, loss=0.4154919981956482
test: epoch 69, loss 1.7190525531768799, acc=0.43888887763023376, loss=1.7190525531768799
train: epoch 70, loss 0.43446841835975647, acc=0.8339444398880005, loss=0.43446841835975647
test: epoch 70, loss 1.7105475664138794, acc=0.3916666805744171, loss=1.7105475664138794
train: epoch 71, loss 0.39354443550109863, acc=0.8528888821601868, loss=0.39354443550109863
test: epoch 71, loss 1.604857087135315, acc=0.46666666865348816, loss=1.604857087135315
train: epoch 72, loss 0.4316469430923462, acc=0.8405555486679077, loss=0.4316469430923462
test: epoch 72, loss 1.8297466039657593, acc=0.3583333194255829, loss=1.8297466039657593
train: epoch 73, loss 0.4234912693500519, acc=0.8402222394943237, loss=0.4234912693500519
test: epoch 73, loss 2.177415132522583, acc=0.3916666805744171, loss=2.177415132522583
train: epoch 74, loss 0.40818411111831665, acc=0.843833327293396, loss=0.40818411111831665
test: epoch 74, loss 2.4417667388916016, acc=0.3055555522441864, loss=2.4417667388916016
train: epoch 75, loss 0.41281557083129883, acc=0.8437777757644653, loss=0.41281557083129883
test: epoch 75, loss 1.4307441711425781, acc=0.4833333194255829, loss=1.4307441711425781
train: epoch 76, loss 0.42170509696006775, acc=0.8458333611488342, loss=0.42170509696006775
test: epoch 76, loss 2.0761406421661377, acc=0.42500001192092896, loss=2.0761406421661377
train: epoch 77, loss 0.42140427231788635, acc=0.8445555567741394, loss=0.42140427231788635
test: epoch 77, loss 1.709930419921875, acc=0.46666666865348816, loss=1.709930419921875
train: epoch 78, loss 0.4140680730342865, acc=0.843666672706604, loss=0.4140680730342865
test: epoch 78, loss 2.0776305198669434, acc=0.4444444477558136, loss=2.0776305198669434
train: epoch 79, loss 0.4062538743019104, acc=0.8470555543899536, loss=0.4062538743019104
test: epoch 79, loss 2.0560388565063477, acc=0.375, loss=2.0560388565063477
train: epoch 80, loss 0.4298630654811859, acc=0.8385555744171143, loss=0.4298630654811859
test: epoch 80, loss 1.8506481647491455, acc=0.3777777850627899, loss=1.8506481647491455
train: epoch 81, loss 0.4073202311992645, acc=0.8502222299575806, loss=0.4073202311992645
test: epoch 81, loss 2.011652708053589, acc=0.42222222685813904, loss=2.011652708053589
train: epoch 82, loss 0.43604931235313416, acc=0.8377222418785095, loss=0.43604931235313416
test: epoch 82, loss 1.6364041566848755, acc=0.49444442987442017, loss=1.6364041566848755
train: epoch 83, loss 0.3810422420501709, acc=0.8559444546699524, loss=0.3810422420501709
test: epoch 83, loss 1.5016483068466187, acc=0.43611112236976624, loss=1.5016483068466187
train: epoch 84, loss 0.4326854646205902, acc=0.8408889174461365, loss=0.4326854646205902
test: epoch 84, loss 1.6349799633026123, acc=0.48055556416511536, loss=1.6349799633026123
train: epoch 85, loss 0.4074304401874542, acc=0.8496111035346985, loss=0.4074304401874542
test: epoch 85, loss 1.7966536283493042, acc=0.42222222685813904, loss=1.7966536283493042
train: epoch 86, loss 0.4022902548313141, acc=0.8454999923706055, loss=0.4022902548313141
test: epoch 86, loss 1.549699306488037, acc=0.4277777671813965, loss=1.549699306488037
train: epoch 87, loss 0.40459439158439636, acc=0.8489999771118164, loss=0.40459439158439636
test: epoch 87, loss 1.7753640413284302, acc=0.4305555522441864, loss=1.7753640413284302
train: epoch 88, loss 0.40217307209968567, acc=0.8514999747276306, loss=0.40217307209968567
test: epoch 88, loss 1.6006114482879639, acc=0.4055555462837219, loss=1.6006114482879639
train: epoch 89, loss 0.4298408329486847, acc=0.8416110873222351, loss=0.4298408329486847
test: epoch 89, loss 1.9331117868423462, acc=0.4444444477558136, loss=1.9331117868423462
train: epoch 90, loss 0.4094099998474121, acc=0.8470555543899536, loss=0.4094099998474121
test: epoch 90, loss 1.656407356262207, acc=0.46388888359069824, loss=1.656407356262207
train: epoch 91, loss 0.3826199769973755, acc=0.8562777638435364, loss=0.3826199769973755
test: epoch 91, loss 1.4923593997955322, acc=0.46388888359069824, loss=1.4923593997955322
train: epoch 92, loss 0.3812098503112793, acc=0.8560000061988831, loss=0.3812098503112793
test: epoch 92, loss 1.652998447418213, acc=0.4333333373069763, loss=1.652998447418213
train: epoch 93, loss 0.3804284334182739, acc=0.8569999933242798, loss=0.3804284334182739
test: epoch 93, loss 1.3855764865875244, acc=0.46388888359069824, loss=1.3855764865875244
train: epoch 94, loss 0.40428951382637024, acc=0.8493888974189758, loss=0.40428951382637024
test: epoch 94, loss 1.5416582822799683, acc=0.4555555582046509, loss=1.5416582822799683
train: epoch 95, loss 0.3916463851928711, acc=0.8543333411216736, loss=0.3916463851928711
test: epoch 95, loss 1.5733578205108643, acc=0.48055556416511536, loss=1.5733578205108643
train: epoch 96, loss 0.3853646218776703, acc=0.856166660785675, loss=0.3853646218776703
test: epoch 96, loss 1.412308931350708, acc=0.46388888359069824, loss=1.412308931350708
train: epoch 97, loss 0.399152010679245, acc=0.8524444699287415, loss=0.399152010679245
test: epoch 97, loss 1.372597575187683, acc=0.4333333373069763, loss=1.372597575187683
train: epoch 98, loss 0.37650489807128906, acc=0.8591111302375793, loss=0.37650489807128906
test: epoch 98, loss 1.2678204774856567, acc=0.5361111164093018, loss=1.2678204774856567
train: epoch 99, loss 0.42670419812202454, acc=0.8407777547836304, loss=0.42670419812202454
test: epoch 99, loss 1.9351946115493774, acc=0.4444444477558136, loss=1.9351946115493774
train: epoch 100, loss 0.40709689259529114, acc=0.8482778072357178, loss=0.40709689259529114
test: epoch 100, loss 1.2738033533096313, acc=0.5388888716697693, loss=1.2738033533096313
train: epoch 101, loss 0.3957133889198303, acc=0.8537777662277222, loss=0.3957133889198303
test: epoch 101, loss 1.3269038200378418, acc=0.5083333253860474, loss=1.3269038200378418
train: epoch 102, loss 0.3839523494243622, acc=0.856333315372467, loss=0.3839523494243622
test: epoch 102, loss 1.3427833318710327, acc=0.4749999940395355, loss=1.3427833318710327
train: epoch 103, loss 0.35865333676338196, acc=0.8643888831138611, loss=0.35865333676338196
test: epoch 103, loss 1.405695915222168, acc=0.4888888895511627, loss=1.405695915222168
train: epoch 104, loss 0.3779810965061188, acc=0.8578888773918152, loss=0.3779810965061188
test: epoch 104, loss 1.6106696128845215, acc=0.48055556416511536, loss=1.6106696128845215
train: epoch 105, loss 0.3862205743789673, acc=0.8562222123146057, loss=0.3862205743789673
test: epoch 105, loss 1.3415683507919312, acc=0.5027777552604675, loss=1.3415683507919312
train: epoch 106, loss 0.3912108540534973, acc=0.8544999957084656, loss=0.3912108540534973
test: epoch 106, loss 1.426127314567566, acc=0.5111111402511597, loss=1.426127314567566
train: epoch 107, loss 0.3827984929084778, acc=0.855055570602417, loss=0.3827984929084778
test: epoch 107, loss 1.4344608783721924, acc=0.519444465637207, loss=1.4344608783721924
train: epoch 108, loss 0.4068579375743866, acc=0.8479999899864197, loss=0.4068579375743866
test: epoch 108, loss 1.5067793130874634, acc=0.44999998807907104, loss=1.5067793130874634
train: epoch 109, loss 0.3582080602645874, acc=0.8668888807296753, loss=0.3582080602645874
test: epoch 109, loss 1.4971951246261597, acc=0.39722222089767456, loss=1.4971951246261597
train: epoch 110, loss 0.379876971244812, acc=0.8598889112472534, loss=0.379876971244812
test: epoch 110, loss 1.4183324575424194, acc=0.4833333194255829, loss=1.4183324575424194
train: epoch 111, loss 0.3985208570957184, acc=0.8527222275733948, loss=0.3985208570957184
test: epoch 111, loss 1.2708752155303955, acc=0.49444442987442017, loss=1.2708752155303955
train: epoch 112, loss 0.3856198191642761, acc=0.8556110858917236, loss=0.3856198191642761
test: epoch 112, loss 1.7747528553009033, acc=0.40833333134651184, loss=1.7747528553009033
train: epoch 113, loss 0.4016875624656677, acc=0.8480555415153503, loss=0.4016875624656677
test: epoch 113, loss 1.2794482707977295, acc=0.4694444537162781, loss=1.2794482707977295
train: epoch 114, loss 0.3768596053123474, acc=0.8618333339691162, loss=0.3768596053123474
test: epoch 114, loss 1.2803857326507568, acc=0.5277777910232544, loss=1.2803857326507568
train: epoch 115, loss 0.3881918489933014, acc=0.8586111068725586, loss=0.3881918489933014
test: epoch 115, loss 1.0577428340911865, acc=0.5444444417953491, loss=1.0577428340911865
train: epoch 116, loss 0.40068963170051575, acc=0.8486111164093018, loss=0.40068963170051575
test: epoch 116, loss 1.6305861473083496, acc=0.4583333432674408, loss=1.6305861473083496
train: epoch 117, loss 0.3803495466709137, acc=0.8589444160461426, loss=0.3803495466709137
test: epoch 117, loss 1.4541263580322266, acc=0.4888888895511627, loss=1.4541263580322266
train: epoch 118, loss 0.37783193588256836, acc=0.8604999780654907, loss=0.37783193588256836
test: epoch 118, loss 1.4582699537277222, acc=0.5027777552604675, loss=1.4582699537277222
train: epoch 119, loss 0.3726639151573181, acc=0.8592222332954407, loss=0.3726639151573181
test: epoch 119, loss 1.2123973369598389, acc=0.5055555701255798, loss=1.2123973369598389
train: epoch 120, loss 0.3633096516132355, acc=0.8637222051620483, loss=0.3633096516132355
test: epoch 120, loss 1.0525388717651367, acc=0.550000011920929, loss=1.0525388717651367
train: epoch 121, loss 0.3642927408218384, acc=0.8662777543067932, loss=0.3642927408218384
test: epoch 121, loss 1.1594789028167725, acc=0.5416666865348816, loss=1.1594789028167725
train: epoch 122, loss 0.36340928077697754, acc=0.8665000200271606, loss=0.36340928077697754
test: epoch 122, loss 1.2034953832626343, acc=0.5666666626930237, loss=1.2034953832626343
train: epoch 123, loss 0.3673774302005768, acc=0.8596110939979553, loss=0.3673774302005768
test: epoch 123, loss 1.246860384941101, acc=0.519444465637207, loss=1.246860384941101
train: epoch 124, loss 0.3694116175174713, acc=0.8607777953147888, loss=0.3694116175174713
test: epoch 124, loss 1.2338544130325317, acc=0.5611110925674438, loss=1.2338544130325317
train: epoch 125, loss 0.3695301413536072, acc=0.8585000038146973, loss=0.3695301413536072
test: epoch 125, loss 1.0068854093551636, acc=0.6222222447395325, loss=1.0068854093551636
train: epoch 126, loss 0.367547869682312, acc=0.8616111278533936, loss=0.367547869682312
test: epoch 126, loss 1.1470991373062134, acc=0.5249999761581421, loss=1.1470991373062134
train: epoch 127, loss 0.3525882363319397, acc=0.8676111102104187, loss=0.3525882363319397
test: epoch 127, loss 1.3842604160308838, acc=0.5666666626930237, loss=1.3842604160308838
train: epoch 128, loss 0.36688730120658875, acc=0.862666666507721, loss=0.36688730120658875
test: epoch 128, loss 1.3235442638397217, acc=0.5888888835906982, loss=1.3235442638397217
train: epoch 129, loss 0.38431018590927124, acc=0.8569999933242798, loss=0.38431018590927124
test: epoch 129, loss 1.078000783920288, acc=0.5166666507720947, loss=1.078000783920288
train: epoch 130, loss 0.3560830056667328, acc=0.8641666769981384, loss=0.3560830056667328
test: epoch 130, loss 0.8219497799873352, acc=0.6555555462837219, loss=0.8219497799873352
train: epoch 131, loss 0.3743245303630829, acc=0.8602777719497681, loss=0.3743245303630829
test: epoch 131, loss 1.153005838394165, acc=0.5805555582046509, loss=1.153005838394165
train: epoch 132, loss 0.3484889268875122, acc=0.8698889017105103, loss=0.3484889268875122
test: epoch 132, loss 1.4170634746551514, acc=0.5805555582046509, loss=1.4170634746551514
train: epoch 133, loss 0.3703186810016632, acc=0.859499990940094, loss=0.3703186810016632
test: epoch 133, loss 1.336201548576355, acc=0.5277777910232544, loss=1.336201548576355
train: epoch 134, loss 0.35370972752571106, acc=0.867111086845398, loss=0.35370972752571106
test: epoch 134, loss 1.2039626836776733, acc=0.550000011920929, loss=1.2039626836776733
train: epoch 135, loss 0.37648463249206543, acc=0.8583333492279053, loss=0.37648463249206543
test: epoch 135, loss 1.182909369468689, acc=0.5555555820465088, loss=1.182909369468689
train: epoch 136, loss 0.33733034133911133, acc=0.8732222318649292, loss=0.33733034133911133
test: epoch 136, loss 0.955241322517395, acc=0.5944444537162781, loss=0.955241322517395
train: epoch 137, loss 0.357639342546463, acc=0.863611102104187, loss=0.357639342546463
test: epoch 137, loss 1.4493894577026367, acc=0.4833333194255829, loss=1.4493894577026367
train: epoch 138, loss 0.3631524443626404, acc=0.8638888597488403, loss=0.3631524443626404
test: epoch 138, loss 0.9855808019638062, acc=0.6527777910232544, loss=0.9855808019638062
train: epoch 139, loss 0.37743887305259705, acc=0.8561111092567444, loss=0.37743887305259705
test: epoch 139, loss 0.9301844239234924, acc=0.6416666507720947, loss=0.9301844239234924
train: epoch 140, loss 0.36965009570121765, acc=0.8566666841506958, loss=0.36965009570121765
test: epoch 140, loss 0.7188190817832947, acc=0.6166666746139526, loss=0.7188190817832947
train: epoch 141, loss 0.329365074634552, acc=0.8715000152587891, loss=0.329365074634552
test: epoch 141, loss 0.8472980260848999, acc=0.5944444537162781, loss=0.8472980260848999
train: epoch 142, loss 0.36754828691482544, acc=0.859666645526886, loss=0.36754828691482544
test: epoch 142, loss 0.9333025813102722, acc=0.6527777910232544, loss=0.9333025813102722
train: epoch 143, loss 0.34881308674812317, acc=0.8687777519226074, loss=0.34881308674812317
test: epoch 143, loss 0.9545313119888306, acc=0.5972222089767456, loss=0.9545313119888306
train: epoch 144, loss 0.33719372749328613, acc=0.871666669845581, loss=0.33719372749328613
test: epoch 144, loss 0.9852079749107361, acc=0.5388888716697693, loss=0.9852079749107361
train: epoch 145, loss 0.36268678307533264, acc=0.8606666922569275, loss=0.36268678307533264
test: epoch 145, loss 0.8944209814071655, acc=0.6305555701255798, loss=0.8944209814071655
train: epoch 146, loss 0.3592475950717926, acc=0.8598333597183228, loss=0.3592475950717926
test: epoch 146, loss 0.7775313854217529, acc=0.7138888835906982, loss=0.7775313854217529
train: epoch 147, loss 0.33567559719085693, acc=0.8732777833938599, loss=0.33567559719085693
test: epoch 147, loss 1.1664674282073975, acc=0.5333333611488342, loss=1.1664674282073975
train: epoch 148, loss 0.36444956064224243, acc=0.8566111326217651, loss=0.36444956064224243
test: epoch 148, loss 1.2470269203186035, acc=0.5666666626930237, loss=1.2470269203186035
train: epoch 149, loss 0.3505917191505432, acc=0.867111086845398, loss=0.3505917191505432
test: epoch 149, loss 0.7987717986106873, acc=0.675000011920929, loss=0.7987717986106873
train: epoch 150, loss 0.3157203495502472, acc=0.8782222270965576, loss=0.3157203495502472
test: epoch 150, loss 0.9787037372589111, acc=0.6388888955116272, loss=0.9787037372589111
