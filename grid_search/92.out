# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=1", "--one_hot=0", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=1697767744, receiver_embed_dim=64, save_run=0, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=1697767744, receiver_embed_dim=64, save_run=False, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.311836004257202, acc=0.17944444715976715, loss=2.311836004257202
test: epoch 1, loss 6.883077144622803, acc=0.04722222313284874, loss=6.883077144622803
train: epoch 2, loss 1.5581940412521362, acc=0.35455554723739624, loss=1.5581940412521362
test: epoch 2, loss 6.309058666229248, acc=0.10000000149011612, loss=6.309058666229248
train: epoch 3, loss 1.2985483407974243, acc=0.44377776980400085, loss=1.2985483407974243
test: epoch 3, loss 4.9538068771362305, acc=0.13611111044883728, loss=4.9538068771362305
train: epoch 4, loss 1.1197081804275513, acc=0.5291666388511658, loss=1.1197081804275513
test: epoch 4, loss 6.2956695556640625, acc=0.15555556118488312, loss=6.2956695556640625
train: epoch 5, loss 1.014460802078247, acc=0.5787222385406494, loss=1.014460802078247
test: epoch 5, loss 4.589560031890869, acc=0.16388888657093048, loss=4.589560031890869
train: epoch 6, loss 0.9257696866989136, acc=0.6162777543067932, loss=0.9257696866989136
test: epoch 6, loss 5.451751232147217, acc=0.20000000298023224, loss=5.451751232147217
train: epoch 7, loss 0.8531371355056763, acc=0.6489444375038147, loss=0.8531371355056763
test: epoch 7, loss 4.5900959968566895, acc=0.2638888955116272, loss=4.5900959968566895
train: epoch 8, loss 0.7724334001541138, acc=0.6863333582878113, loss=0.7724334001541138
test: epoch 8, loss 4.160843849182129, acc=0.18888889253139496, loss=4.160843849182129
train: epoch 9, loss 0.7436169981956482, acc=0.6952221989631653, loss=0.7436169981956482
test: epoch 9, loss 3.7466647624969482, acc=0.2083333283662796, loss=3.7466647624969482
train: epoch 10, loss 0.7421666979789734, acc=0.698722243309021, loss=0.7421666979789734
test: epoch 10, loss 4.298708915710449, acc=0.2611111104488373, loss=4.298708915710449
train: epoch 11, loss 0.6602793335914612, acc=0.737500011920929, loss=0.6602793335914612
test: epoch 11, loss 3.2981436252593994, acc=0.2638888955116272, loss=3.2981436252593994
train: epoch 12, loss 0.6617465615272522, acc=0.7360000014305115, loss=0.6617465615272522
test: epoch 12, loss 3.081326723098755, acc=0.2888889014720917, loss=3.081326723098755
train: epoch 13, loss 0.6305339336395264, acc=0.7434444427490234, loss=0.6305339336395264
test: epoch 13, loss 4.087915420532227, acc=0.2083333283662796, loss=4.087915420532227
train: epoch 14, loss 0.5999168753623962, acc=0.7610555291175842, loss=0.5999168753623962
test: epoch 14, loss 3.0052788257598877, acc=0.28611111640930176, loss=3.0052788257598877
train: epoch 15, loss 0.5431885719299316, acc=0.788444459438324, loss=0.5431885719299316
test: epoch 15, loss 3.4266743659973145, acc=0.30000001192092896, loss=3.4266743659973145
train: epoch 16, loss 0.5372815132141113, acc=0.7887222170829773, loss=0.5372815132141113
test: epoch 16, loss 2.9168319702148438, acc=0.3333333432674408, loss=2.9168319702148438
train: epoch 17, loss 0.5465822219848633, acc=0.785611093044281, loss=0.5465822219848633
test: epoch 17, loss 3.795745849609375, acc=0.23055554926395416, loss=3.795745849609375
train: epoch 18, loss 0.5294798016548157, acc=0.7910000085830688, loss=0.5294798016548157
test: epoch 18, loss 2.1721198558807373, acc=0.36666667461395264, loss=2.1721198558807373
train: epoch 19, loss 0.4870189130306244, acc=0.8082777857780457, loss=0.4870189130306244
test: epoch 19, loss 3.6523613929748535, acc=0.2916666567325592, loss=3.6523613929748535
train: epoch 20, loss 0.4849274754524231, acc=0.8111666440963745, loss=0.4849274754524231
test: epoch 20, loss 3.3957948684692383, acc=0.23333333432674408, loss=3.3957948684692383
train: epoch 21, loss 0.49581456184387207, acc=0.8066666722297668, loss=0.49581456184387207
test: epoch 21, loss 2.955627918243408, acc=0.3333333432674408, loss=2.955627918243408
train: epoch 22, loss 0.4717878997325897, acc=0.8153333067893982, loss=0.4717878997325897
test: epoch 22, loss 2.6015636920928955, acc=0.3722222149372101, loss=2.6015636920928955
train: epoch 23, loss 0.4078874886035919, acc=0.8450000286102295, loss=0.4078874886035919
test: epoch 23, loss 2.8337557315826416, acc=0.35277777910232544, loss=2.8337557315826416
train: epoch 24, loss 0.4688791334629059, acc=0.819944441318512, loss=0.4688791334629059
test: epoch 24, loss 3.000314474105835, acc=0.3083333373069763, loss=3.000314474105835
train: epoch 25, loss 0.40294209122657776, acc=0.8457777500152588, loss=0.40294209122657776
test: epoch 25, loss 3.1427505016326904, acc=0.28611111640930176, loss=3.1427505016326904
train: epoch 26, loss 0.4475984275341034, acc=0.824222207069397, loss=0.4475984275341034
test: epoch 26, loss 2.8417787551879883, acc=0.24444444477558136, loss=2.8417787551879883
train: epoch 27, loss 0.4098484516143799, acc=0.8403888940811157, loss=0.4098484516143799
test: epoch 27, loss 2.7860031127929688, acc=0.25, loss=2.7860031127929688
train: epoch 28, loss 0.42990022897720337, acc=0.8381666541099548, loss=0.42990022897720337
test: epoch 28, loss 2.362168550491333, acc=0.40833333134651184, loss=2.362168550491333
train: epoch 29, loss 0.37625953555107117, acc=0.8568888902664185, loss=0.37625953555107117
test: epoch 29, loss 3.2746329307556152, acc=0.23888888955116272, loss=3.2746329307556152
train: epoch 30, loss 0.40951505303382874, acc=0.8410000205039978, loss=0.40951505303382874
test: epoch 30, loss 2.438840866088867, acc=0.36666667461395264, loss=2.438840866088867
train: epoch 31, loss 0.3743301033973694, acc=0.8591111302375793, loss=0.3743301033973694
test: epoch 31, loss 3.3796122074127197, acc=0.3027777671813965, loss=3.3796122074127197
train: epoch 32, loss 0.3686288893222809, acc=0.8621666431427002, loss=0.3686288893222809
test: epoch 32, loss 3.062680721282959, acc=0.3222222328186035, loss=3.062680721282959
train: epoch 33, loss 0.3695530295372009, acc=0.8607777953147888, loss=0.3695530295372009
test: epoch 33, loss 1.7963857650756836, acc=0.3722222149372101, loss=1.7963857650756836
train: epoch 34, loss 0.3425581753253937, acc=0.8696110844612122, loss=0.3425581753253937
test: epoch 34, loss 2.6291582584381104, acc=0.3722222149372101, loss=2.6291582584381104
train: epoch 35, loss 0.36439794301986694, acc=0.8648889064788818, loss=0.36439794301986694
test: epoch 35, loss 2.2760207653045654, acc=0.3611111044883728, loss=2.2760207653045654
train: epoch 36, loss 0.34234359860420227, acc=0.8692777752876282, loss=0.34234359860420227
test: epoch 36, loss 2.4586172103881836, acc=0.33888888359069824, loss=2.4586172103881836
train: epoch 37, loss 0.3116321563720703, acc=0.8859444260597229, loss=0.3116321563720703
test: epoch 37, loss 2.724369764328003, acc=0.2888889014720917, loss=2.724369764328003
train: epoch 38, loss 0.3372551500797272, acc=0.8701666593551636, loss=0.3372551500797272
test: epoch 38, loss 2.6620256900787354, acc=0.3222222328186035, loss=2.6620256900787354
train: epoch 39, loss 0.3136787414550781, acc=0.8812777996063232, loss=0.3136787414550781
test: epoch 39, loss 3.1209113597869873, acc=0.32499998807907104, loss=3.1209113597869873
train: epoch 40, loss 0.32346683740615845, acc=0.8847777843475342, loss=0.32346683740615845
test: epoch 40, loss 2.3965234756469727, acc=0.3027777671813965, loss=2.3965234756469727
train: epoch 41, loss 0.2951313853263855, acc=0.8886666893959045, loss=0.2951313853263855
test: epoch 41, loss 2.304034948348999, acc=0.3361110985279083, loss=2.304034948348999
train: epoch 42, loss 0.2948194742202759, acc=0.8911111354827881, loss=0.2948194742202759
test: epoch 42, loss 2.383683681488037, acc=0.36944442987442017, loss=2.383683681488037
train: epoch 43, loss 0.30498430132865906, acc=0.8862777948379517, loss=0.30498430132865906
test: epoch 43, loss 2.9270925521850586, acc=0.35277777910232544, loss=2.9270925521850586
train: epoch 44, loss 0.2831929326057434, acc=0.8921111226081848, loss=0.2831929326057434
test: epoch 44, loss 2.412121057510376, acc=0.3083333373069763, loss=2.412121057510376
train: epoch 45, loss 0.2906062602996826, acc=0.8918333053588867, loss=0.2906062602996826
test: epoch 45, loss 3.1632256507873535, acc=0.3083333373069763, loss=3.1632256507873535
train: epoch 46, loss 0.26735594868659973, acc=0.9014444351196289, loss=0.26735594868659973
test: epoch 46, loss 2.121962785720825, acc=0.36944442987442017, loss=2.121962785720825
train: epoch 47, loss 0.29628849029541016, acc=0.8911666870117188, loss=0.29628849029541016
test: epoch 47, loss 2.4083611965179443, acc=0.3305555582046509, loss=2.4083611965179443
train: epoch 48, loss 0.26151978969573975, acc=0.9051111340522766, loss=0.26151978969573975
test: epoch 48, loss 2.438687324523926, acc=0.36944442987442017, loss=2.438687324523926
train: epoch 49, loss 0.2785557806491852, acc=0.8960000276565552, loss=0.2785557806491852
test: epoch 49, loss 2.740562915802002, acc=0.2638888955116272, loss=2.740562915802002
train: epoch 50, loss 0.29451489448547363, acc=0.890500009059906, loss=0.29451489448547363
test: epoch 50, loss 2.793257713317871, acc=0.31111112236976624, loss=2.793257713317871
train: epoch 51, loss 0.2946198582649231, acc=0.8907777667045593, loss=0.2946198582649231
test: epoch 51, loss 2.3011350631713867, acc=0.3333333432674408, loss=2.3011350631713867
train: epoch 52, loss 0.23190879821777344, acc=0.9151666760444641, loss=0.23190879821777344
test: epoch 52, loss 2.6428751945495605, acc=0.2888889014720917, loss=2.6428751945495605
train: epoch 53, loss 0.2710563838481903, acc=0.899055540561676, loss=0.2710563838481903
test: epoch 53, loss 3.384260416030884, acc=0.34166666865348816, loss=3.384260416030884
train: epoch 54, loss 0.24907176196575165, acc=0.9058333039283752, loss=0.24907176196575165
test: epoch 54, loss 1.9309815168380737, acc=0.3916666805744171, loss=1.9309815168380737
train: epoch 55, loss 0.26828548312187195, acc=0.9006111025810242, loss=0.26828548312187195
test: epoch 55, loss 2.3115837574005127, acc=0.2916666567325592, loss=2.3115837574005127
train: epoch 56, loss 0.2557397484779358, acc=0.9021111130714417, loss=0.2557397484779358
test: epoch 56, loss 2.0816919803619385, acc=0.29722222685813904, loss=2.0816919803619385
train: epoch 57, loss 0.23971745371818542, acc=0.9116111397743225, loss=0.23971745371818542
test: epoch 57, loss 1.8793774843215942, acc=0.4194444417953491, loss=1.8793774843215942
train: epoch 58, loss 0.25340598821640015, acc=0.9084444642066956, loss=0.25340598821640015
test: epoch 58, loss 2.5642852783203125, acc=0.3499999940395355, loss=2.5642852783203125
train: epoch 59, loss 0.2403465062379837, acc=0.9100000262260437, loss=0.2403465062379837
test: epoch 59, loss 3.3107621669769287, acc=0.3083333373069763, loss=3.3107621669769287
train: epoch 60, loss 0.22611205279827118, acc=0.9174444675445557, loss=0.22611205279827118
test: epoch 60, loss 1.5828064680099487, acc=0.39444443583488464, loss=1.5828064680099487
train: epoch 61, loss 0.2522467076778412, acc=0.905055582523346, loss=0.2522467076778412
test: epoch 61, loss 2.4860363006591797, acc=0.3166666626930237, loss=2.4860363006591797
train: epoch 62, loss 0.22318899631500244, acc=0.917722225189209, loss=0.22318899631500244
test: epoch 62, loss 2.259500503540039, acc=0.40833333134651184, loss=2.259500503540039
train: epoch 63, loss 0.25197315216064453, acc=0.9089999794960022, loss=0.25197315216064453
test: epoch 63, loss 2.701479434967041, acc=0.3083333373069763, loss=2.701479434967041
train: epoch 64, loss 0.24106383323669434, acc=0.9112777709960938, loss=0.24106383323669434
test: epoch 64, loss 2.264436960220337, acc=0.24166665971279144, loss=2.264436960220337
train: epoch 65, loss 0.22759541869163513, acc=0.917888879776001, loss=0.22759541869163513
test: epoch 65, loss 2.3805816173553467, acc=0.3638888895511627, loss=2.3805816173553467
train: epoch 66, loss 0.19711123406887054, acc=0.9244999885559082, loss=0.19711123406887054
test: epoch 66, loss 2.2216484546661377, acc=0.3583333194255829, loss=2.2216484546661377
train: epoch 67, loss 0.23375113308429718, acc=0.9117222428321838, loss=0.23375113308429718
test: epoch 67, loss 2.1884169578552246, acc=0.3222222328186035, loss=2.1884169578552246
train: epoch 68, loss 0.22140122950077057, acc=0.9190000295639038, loss=0.22140122950077057
test: epoch 68, loss 2.3179233074188232, acc=0.2888889014720917, loss=2.3179233074188232
train: epoch 69, loss 0.22304020822048187, acc=0.9181666374206543, loss=0.22304020822048187
test: epoch 69, loss 2.415574789047241, acc=0.3027777671813965, loss=2.415574789047241
train: epoch 70, loss 0.2371559590101242, acc=0.9104999899864197, loss=0.2371559590101242
test: epoch 70, loss 2.137784481048584, acc=0.3861111104488373, loss=2.137784481048584
train: epoch 71, loss 0.2305336892604828, acc=0.9154444336891174, loss=0.2305336892604828
test: epoch 71, loss 1.904361367225647, acc=0.4194444417953491, loss=1.904361367225647
train: epoch 72, loss 0.18923887610435486, acc=0.9290555715560913, loss=0.18923887610435486
test: epoch 72, loss 2.4595768451690674, acc=0.2611111104488373, loss=2.4595768451690674
train: epoch 73, loss 0.23402269184589386, acc=0.9131110906600952, loss=0.23402269184589386
test: epoch 73, loss 1.849274754524231, acc=0.3305555582046509, loss=1.849274754524231
train: epoch 74, loss 0.21590258181095123, acc=0.9232777953147888, loss=0.21590258181095123
test: epoch 74, loss 1.760772466659546, acc=0.375, loss=1.760772466659546
train: epoch 75, loss 0.2420552372932434, acc=0.9085555672645569, loss=0.2420552372932434
test: epoch 75, loss 1.880378246307373, acc=0.3499999940395355, loss=1.880378246307373
train: epoch 76, loss 0.19751539826393127, acc=0.925611138343811, loss=0.19751539826393127
test: epoch 76, loss 1.8108772039413452, acc=0.29722222685813904, loss=1.8108772039413452
train: epoch 77, loss 0.2071051150560379, acc=0.9247221946716309, loss=0.2071051150560379
test: epoch 77, loss 2.0527777671813965, acc=0.3194444477558136, loss=2.0527777671813965
train: epoch 78, loss 0.20804668962955475, acc=0.9207777976989746, loss=0.20804668962955475
test: epoch 78, loss 2.9497742652893066, acc=0.32499998807907104, loss=2.9497742652893066
train: epoch 79, loss 0.20752258598804474, acc=0.921999990940094, loss=0.20752258598804474
test: epoch 79, loss 2.0497236251831055, acc=0.3861111104488373, loss=2.0497236251831055
train: epoch 80, loss 0.19036684930324554, acc=0.929277777671814, loss=0.19036684930324554
test: epoch 80, loss 2.239572763442993, acc=0.3222222328186035, loss=2.239572763442993
train: epoch 81, loss 0.18715961277484894, acc=0.9307222366333008, loss=0.18715961277484894
test: epoch 81, loss 2.0571789741516113, acc=0.3916666805744171, loss=2.0571789741516113
train: epoch 82, loss 0.20706531405448914, acc=0.9227222204208374, loss=0.20706531405448914
test: epoch 82, loss 1.677213430404663, acc=0.39722222089767456, loss=1.677213430404663
train: epoch 83, loss 0.19642475247383118, acc=0.9271110892295837, loss=0.19642475247383118
test: epoch 83, loss 2.195251703262329, acc=0.3583333194255829, loss=2.195251703262329
train: epoch 84, loss 0.19250091910362244, acc=0.9317777752876282, loss=0.19250091910362244
test: epoch 84, loss 2.006490468978882, acc=0.4333333373069763, loss=2.006490468978882
train: epoch 85, loss 0.20988520979881287, acc=0.9195555448532104, loss=0.20988520979881287
test: epoch 85, loss 2.952800989151001, acc=0.34166666865348816, loss=2.952800989151001
train: epoch 86, loss 0.1810496598482132, acc=0.9336666464805603, loss=0.1810496598482132
test: epoch 86, loss 2.048903703689575, acc=0.3333333432674408, loss=2.048903703689575
train: epoch 87, loss 0.19619198143482208, acc=0.9276111125946045, loss=0.19619198143482208
test: epoch 87, loss 2.0991716384887695, acc=0.4305555522441864, loss=2.0991716384887695
train: epoch 88, loss 0.18213248252868652, acc=0.9340000152587891, loss=0.18213248252868652
test: epoch 88, loss 2.543905735015869, acc=0.35277777910232544, loss=2.543905735015869
train: epoch 89, loss 0.19174645841121674, acc=0.9273889064788818, loss=0.19174645841121674
test: epoch 89, loss 1.5470833778381348, acc=0.5111111402511597, loss=1.5470833778381348
train: epoch 90, loss 0.190158873796463, acc=0.9285555481910706, loss=0.190158873796463
test: epoch 90, loss 2.459918260574341, acc=0.35277777910232544, loss=2.459918260574341
train: epoch 91, loss 0.1700834333896637, acc=0.9379444718360901, loss=0.1700834333896637
test: epoch 91, loss 2.1706628799438477, acc=0.3722222149372101, loss=2.1706628799438477
train: epoch 92, loss 0.18021923303604126, acc=0.933222234249115, loss=0.18021923303604126
test: epoch 92, loss 2.363684892654419, acc=0.4416666626930237, loss=2.363684892654419
train: epoch 93, loss 0.18412606418132782, acc=0.9318888783454895, loss=0.18412606418132782
test: epoch 93, loss 2.260929584503174, acc=0.3611111044883728, loss=2.260929584503174
train: epoch 94, loss 0.18677547574043274, acc=0.929111123085022, loss=0.18677547574043274
test: epoch 94, loss 2.4952738285064697, acc=0.36944442987442017, loss=2.4952738285064697
train: epoch 95, loss 0.16555744409561157, acc=0.9398888945579529, loss=0.16555744409561157
test: epoch 95, loss 2.2224295139312744, acc=0.3305555582046509, loss=2.2224295139312744
train: epoch 96, loss 0.1595071405172348, acc=0.9403333067893982, loss=0.1595071405172348
test: epoch 96, loss 2.2354562282562256, acc=0.3444444537162781, loss=2.2354562282562256
train: epoch 97, loss 0.17605336010456085, acc=0.9361666440963745, loss=0.17605336010456085
test: epoch 97, loss 3.0188064575195312, acc=0.36666667461395264, loss=3.0188064575195312
train: epoch 98, loss 0.16345642507076263, acc=0.9417222142219543, loss=0.16345642507076263
test: epoch 98, loss 3.207162857055664, acc=0.3499999940395355, loss=3.207162857055664
train: epoch 99, loss 0.1818549633026123, acc=0.9339444637298584, loss=0.1818549633026123
test: epoch 99, loss 2.531148910522461, acc=0.3861111104488373, loss=2.531148910522461
train: epoch 100, loss 0.15285421907901764, acc=0.9428889155387878, loss=0.15285421907901764
test: epoch 100, loss 2.2090299129486084, acc=0.3083333373069763, loss=2.2090299129486084
train: epoch 101, loss 0.18290796875953674, acc=0.9363889098167419, loss=0.18290796875953674
test: epoch 101, loss 2.297410488128662, acc=0.4027777910232544, loss=2.297410488128662
train: epoch 102, loss 0.17254315316677094, acc=0.9384444355964661, loss=0.17254315316677094
test: epoch 102, loss 2.173619270324707, acc=0.35277777910232544, loss=2.173619270324707
train: epoch 103, loss 0.18476983904838562, acc=0.934499979019165, loss=0.18476983904838562
test: epoch 103, loss 1.9732764959335327, acc=0.3472222089767456, loss=1.9732764959335327
train: epoch 104, loss 0.13099470734596252, acc=0.9521666765213013, loss=0.13099470734596252
test: epoch 104, loss 2.40535306930542, acc=0.4166666567325592, loss=2.40535306930542
train: epoch 105, loss 0.17736610770225525, acc=0.937333345413208, loss=0.17736610770225525
test: epoch 105, loss 1.9394416809082031, acc=0.39444443583488464, loss=1.9394416809082031
train: epoch 106, loss 0.1677173227071762, acc=0.937833309173584, loss=0.1677173227071762
test: epoch 106, loss 2.022869825363159, acc=0.43611112236976624, loss=2.022869825363159
train: epoch 107, loss 0.17551632225513458, acc=0.9341111183166504, loss=0.17551632225513458
test: epoch 107, loss 1.9009813070297241, acc=0.3027777671813965, loss=1.9009813070297241
train: epoch 108, loss 0.153746098279953, acc=0.9436666369438171, loss=0.153746098279953
test: epoch 108, loss 2.2092647552490234, acc=0.43611112236976624, loss=2.2092647552490234
train: epoch 109, loss 0.1352333277463913, acc=0.9483888745307922, loss=0.1352333277463913
test: epoch 109, loss 2.989347457885742, acc=0.3583333194255829, loss=2.989347457885742
train: epoch 110, loss 0.16189511120319366, acc=0.9409444332122803, loss=0.16189511120319366
test: epoch 110, loss 2.2929391860961914, acc=0.4333333373069763, loss=2.2929391860961914
train: epoch 111, loss 0.16476260125637054, acc=0.9387778043746948, loss=0.16476260125637054
test: epoch 111, loss 2.417570114135742, acc=0.31388887763023376, loss=2.417570114135742
train: epoch 112, loss 0.14755678176879883, acc=0.9454444646835327, loss=0.14755678176879883
test: epoch 112, loss 2.0885109901428223, acc=0.43888887763023376, loss=2.0885109901428223
train: epoch 113, loss 0.15272945165634155, acc=0.941944420337677, loss=0.15272945165634155
test: epoch 113, loss 2.2006452083587646, acc=0.3916666805744171, loss=2.2006452083587646
train: epoch 114, loss 0.1524239182472229, acc=0.9419999718666077, loss=0.1524239182472229
test: epoch 114, loss 2.274702310562134, acc=0.4000000059604645, loss=2.274702310562134
train: epoch 115, loss 0.16223323345184326, acc=0.9418333172798157, loss=0.16223323345184326
test: epoch 115, loss 2.2013092041015625, acc=0.4055555462837219, loss=2.2013092041015625
train: epoch 116, loss 0.14563243091106415, acc=0.94477778673172, loss=0.14563243091106415
test: epoch 116, loss 2.191887140274048, acc=0.375, loss=2.191887140274048
train: epoch 117, loss 0.14858239889144897, acc=0.9456111192703247, loss=0.14858239889144897
test: epoch 117, loss 2.7749571800231934, acc=0.35555556416511536, loss=2.7749571800231934
train: epoch 118, loss 0.13722240924835205, acc=0.9520555734634399, loss=0.13722240924835205
test: epoch 118, loss 1.4736127853393555, acc=0.4555555582046509, loss=1.4736127853393555
train: epoch 119, loss 0.14661657810211182, acc=0.9457777738571167, loss=0.14661657810211182
test: epoch 119, loss 2.0522654056549072, acc=0.4611110985279083, loss=2.0522654056549072
train: epoch 120, loss 0.15176478028297424, acc=0.9465000033378601, loss=0.15176478028297424
test: epoch 120, loss 2.432070255279541, acc=0.4027777910232544, loss=2.432070255279541
train: epoch 121, loss 0.15007759630680084, acc=0.9467222094535828, loss=0.15007759630680084
test: epoch 121, loss 1.6046844720840454, acc=0.4972222149372101, loss=1.6046844720840454
train: epoch 122, loss 0.13694196939468384, acc=0.9481666684150696, loss=0.13694196939468384
test: epoch 122, loss 2.3926634788513184, acc=0.43888887763023376, loss=2.3926634788513184
train: epoch 123, loss 0.15037016570568085, acc=0.9507222175598145, loss=0.15037016570568085
test: epoch 123, loss 2.3674123287200928, acc=0.29722222685813904, loss=2.3674123287200928
train: epoch 124, loss 0.12805740535259247, acc=0.9524999856948853, loss=0.12805740535259247
test: epoch 124, loss 2.2490394115448, acc=0.375, loss=2.2490394115448
train: epoch 125, loss 0.146131232380867, acc=0.9471111297607422, loss=0.146131232380867
test: epoch 125, loss 1.8995496034622192, acc=0.4583333432674408, loss=1.8995496034622192
train: epoch 126, loss 0.13036789000034332, acc=0.9507222175598145, loss=0.13036789000034332
test: epoch 126, loss 1.7586710453033447, acc=0.4333333373069763, loss=1.7586710453033447
train: epoch 127, loss 0.13121464848518372, acc=0.9507222175598145, loss=0.13121464848518372
test: epoch 127, loss 1.6518255472183228, acc=0.43611112236976624, loss=1.6518255472183228
train: epoch 128, loss 0.14170987904071808, acc=0.9473888874053955, loss=0.14170987904071808
test: epoch 128, loss 1.2879871129989624, acc=0.49444442987442017, loss=1.2879871129989624
train: epoch 129, loss 0.1266566663980484, acc=0.9546111226081848, loss=0.1266566663980484
test: epoch 129, loss 2.4190852642059326, acc=0.36944442987442017, loss=2.4190852642059326
train: epoch 130, loss 0.13758079707622528, acc=0.9490000009536743, loss=0.13758079707622528
test: epoch 130, loss 1.681563377380371, acc=0.47777777910232544, loss=1.681563377380371
train: epoch 131, loss 0.134460911154747, acc=0.9527222514152527, loss=0.134460911154747
test: epoch 131, loss 1.7530710697174072, acc=0.46388888359069824, loss=1.7530710697174072
train: epoch 132, loss 0.11815383285284042, acc=0.9577777981758118, loss=0.11815383285284042
test: epoch 132, loss 1.8094854354858398, acc=0.4305555522441864, loss=1.8094854354858398
train: epoch 133, loss 0.13408716022968292, acc=0.9509444236755371, loss=0.13408716022968292
test: epoch 133, loss 2.034512996673584, acc=0.4055555462837219, loss=2.034512996673584
train: epoch 134, loss 0.1316981166601181, acc=0.9538333415985107, loss=0.1316981166601181
test: epoch 134, loss 2.8436477184295654, acc=0.43611112236976624, loss=2.8436477184295654
train: epoch 135, loss 0.15153159201145172, acc=0.9445555806159973, loss=0.15153159201145172
test: epoch 135, loss 1.3304141759872437, acc=0.5555555820465088, loss=1.3304141759872437
train: epoch 136, loss 0.13169066607952118, acc=0.9503333568572998, loss=0.13169066607952118
test: epoch 136, loss 1.7554242610931396, acc=0.39722222089767456, loss=1.7554242610931396
train: epoch 137, loss 0.12681274116039276, acc=0.9536666870117188, loss=0.12681274116039276
test: epoch 137, loss 1.9538556337356567, acc=0.31388887763023376, loss=1.9538556337356567
train: epoch 138, loss 0.1584853231906891, acc=0.944944441318512, loss=0.1584853231906891
test: epoch 138, loss 1.7944756746292114, acc=0.49166667461395264, loss=1.7944756746292114
train: epoch 139, loss 0.1179424449801445, acc=0.9573333263397217, loss=0.1179424449801445
test: epoch 139, loss 1.783638834953308, acc=0.42500001192092896, loss=1.783638834953308
train: epoch 140, loss 0.14950214326381683, acc=0.9461110830307007, loss=0.14950214326381683
test: epoch 140, loss 2.596370220184326, acc=0.43888887763023376, loss=2.596370220184326
train: epoch 141, loss 0.11380565166473389, acc=0.957277774810791, loss=0.11380565166473389
test: epoch 141, loss 2.163024663925171, acc=0.4416666626930237, loss=2.163024663925171
train: epoch 142, loss 0.13736854493618011, acc=0.9497222304344177, loss=0.13736854493618011
test: epoch 142, loss 1.5494294166564941, acc=0.48055556416511536, loss=1.5494294166564941
train: epoch 143, loss 0.10643638670444489, acc=0.9612777829170227, loss=0.10643638670444489
test: epoch 143, loss 2.1760969161987305, acc=0.43888887763023376, loss=2.1760969161987305
train: epoch 144, loss 0.1412535458803177, acc=0.9482777714729309, loss=0.1412535458803177
test: epoch 144, loss 1.7879492044448853, acc=0.519444465637207, loss=1.7879492044448853
train: epoch 145, loss 0.10504380613565445, acc=0.9612777829170227, loss=0.10504380613565445
test: epoch 145, loss 2.3240668773651123, acc=0.36666667461395264, loss=2.3240668773651123
train: epoch 146, loss 0.11867592483758926, acc=0.9585000276565552, loss=0.11867592483758926
test: epoch 146, loss 1.7148380279541016, acc=0.4333333373069763, loss=1.7148380279541016
train: epoch 147, loss 0.12625692784786224, acc=0.9544444680213928, loss=0.12625692784786224
test: epoch 147, loss 1.630138874053955, acc=0.5277777910232544, loss=1.630138874053955
train: epoch 148, loss 0.11389206349849701, acc=0.9589999914169312, loss=0.11389206349849701
test: epoch 148, loss 1.970953106880188, acc=0.47777777910232544, loss=1.970953106880188
train: epoch 149, loss 0.14854831993579865, acc=0.9483333230018616, loss=0.14854831993579865
test: epoch 149, loss 1.6868555545806885, acc=0.40833333134651184, loss=1.6868555545806885
train: epoch 150, loss 0.11960598081350327, acc=0.9570555686950684, loss=0.11960598081350327
test: epoch 150, loss 2.6310160160064697, acc=0.47777777910232544, loss=2.6310160160064697
