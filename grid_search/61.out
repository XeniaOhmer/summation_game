# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=1", "--temp_decay=0.995", "--one_hot=0", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=872847187, receiver_embed_dim=64, save_run=0, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=872847187, receiver_embed_dim=64, save_run=False, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.8714122772216797, acc=0.09744444489479065, loss=2.8714122772216797
test: epoch 1, loss 3.3882715702056885, acc=0.07500000298023224, loss=3.3882715702056885
train: epoch 2, loss 2.405045509338379, acc=0.1675555557012558, loss=2.405045509338379
test: epoch 2, loss 2.8223843574523926, acc=0.11388888955116272, loss=2.8223843574523926
train: epoch 3, loss 2.1559765338897705, acc=0.20883333683013916, loss=2.1559765338897705
test: epoch 3, loss 2.7443017959594727, acc=0.12222222238779068, loss=2.7443017959594727
train: epoch 4, loss 2.0274808406829834, acc=0.2365555614233017, loss=2.0274808406829834
test: epoch 4, loss 2.4100341796875, acc=0.12777778506278992, loss=2.4100341796875
train: epoch 5, loss 1.9415075778961182, acc=0.25316667556762695, loss=1.9415075778961182
test: epoch 5, loss 2.344329833984375, acc=0.13333334028720856, loss=2.344329833984375
train: epoch 6, loss 1.8735501766204834, acc=0.26750001311302185, loss=1.8735501766204834
test: epoch 6, loss 2.3817524909973145, acc=0.1388888955116272, loss=2.3817524909973145
train: epoch 7, loss 1.816489815711975, acc=0.2876666784286499, loss=1.816489815711975
test: epoch 7, loss 2.5276572704315186, acc=0.13333334028720856, loss=2.5276572704315186
train: epoch 8, loss 1.7766926288604736, acc=0.3033333420753479, loss=1.7766926288604736
test: epoch 8, loss 2.489042043685913, acc=0.15555556118488312, loss=2.489042043685913
train: epoch 9, loss 1.7120202779769897, acc=0.3161666691303253, loss=1.7120202779769897
test: epoch 9, loss 2.3548941612243652, acc=0.14722222089767456, loss=2.3548941612243652
train: epoch 10, loss 1.6903092861175537, acc=0.32811111211776733, loss=1.6903092861175537
test: epoch 10, loss 2.2247066497802734, acc=0.16944444179534912, loss=2.2247066497802734
train: epoch 11, loss 1.6556813716888428, acc=0.3338888883590698, loss=1.6556813716888428
test: epoch 11, loss 2.3393518924713135, acc=0.20000000298023224, loss=2.3393518924713135
train: epoch 12, loss 1.63643217086792, acc=0.33772221207618713, loss=1.63643217086792
test: epoch 12, loss 2.275078773498535, acc=0.17222222685813904, loss=2.275078773498535
train: epoch 13, loss 1.6061824560165405, acc=0.35294443368911743, loss=1.6061824560165405
test: epoch 13, loss 2.5965068340301514, acc=0.1388888955116272, loss=2.5965068340301514
train: epoch 14, loss 1.5735963582992554, acc=0.36322221159935, loss=1.5735963582992554
test: epoch 14, loss 2.4740898609161377, acc=0.17499999701976776, loss=2.4740898609161377
train: epoch 15, loss 1.5515360832214355, acc=0.3728888928890228, loss=1.5515360832214355
test: epoch 15, loss 2.2902472019195557, acc=0.21388888359069824, loss=2.2902472019195557
train: epoch 16, loss 1.5412429571151733, acc=0.37461110949516296, loss=1.5412429571151733
test: epoch 16, loss 2.218592405319214, acc=0.1944444477558136, loss=2.218592405319214
train: epoch 17, loss 1.5238124132156372, acc=0.3756110966205597, loss=1.5238124132156372
test: epoch 17, loss 2.299729347229004, acc=0.20555555820465088, loss=2.299729347229004
train: epoch 18, loss 1.4882594347000122, acc=0.39622223377227783, loss=1.4882594347000122
test: epoch 18, loss 2.0386404991149902, acc=0.21388888359069824, loss=2.0386404991149902
train: epoch 19, loss 1.4658269882202148, acc=0.3971666693687439, loss=1.4658269882202148
test: epoch 19, loss 2.1293575763702393, acc=0.2222222238779068, loss=2.1293575763702393
train: epoch 20, loss 1.4540926218032837, acc=0.40016666054725647, loss=1.4540926218032837
test: epoch 20, loss 2.2880325317382812, acc=0.17777778208255768, loss=2.2880325317382812
train: epoch 21, loss 1.4342656135559082, acc=0.41777777671813965, loss=1.4342656135559082
test: epoch 21, loss 2.2606699466705322, acc=0.17222222685813904, loss=2.2606699466705322
train: epoch 22, loss 1.440418004989624, acc=0.4138889014720917, loss=1.440418004989624
test: epoch 22, loss 2.2565720081329346, acc=0.2083333283662796, loss=2.2565720081329346
train: epoch 23, loss 1.4178872108459473, acc=0.4208333194255829, loss=1.4178872108459473
test: epoch 23, loss 2.174091100692749, acc=0.16388888657093048, loss=2.174091100692749
train: epoch 24, loss 1.3892093896865845, acc=0.4302777647972107, loss=1.3892093896865845
test: epoch 24, loss 2.078096866607666, acc=0.2222222238779068, loss=2.078096866607666
train: epoch 25, loss 1.3858222961425781, acc=0.4252777695655823, loss=1.3858222961425781
test: epoch 25, loss 2.022092342376709, acc=0.21944443881511688, loss=2.022092342376709
train: epoch 26, loss 1.383198857307434, acc=0.4283333420753479, loss=1.383198857307434
test: epoch 26, loss 2.0277252197265625, acc=0.2361111044883728, loss=2.0277252197265625
train: epoch 27, loss 1.3638545274734497, acc=0.4360555410385132, loss=1.3638545274734497
test: epoch 27, loss 2.038607120513916, acc=0.24166665971279144, loss=2.038607120513916
train: epoch 28, loss 1.3567415475845337, acc=0.44172221422195435, loss=1.3567415475845337
test: epoch 28, loss 2.1336417198181152, acc=0.21666666865348816, loss=2.1336417198181152
train: epoch 29, loss 1.3324223756790161, acc=0.44927778840065, loss=1.3324223756790161
test: epoch 29, loss 2.154392957687378, acc=0.21944443881511688, loss=2.154392957687378
train: epoch 30, loss 1.3442236185073853, acc=0.4487222135066986, loss=1.3442236185073853
test: epoch 30, loss 2.039322853088379, acc=0.24166665971279144, loss=2.039322853088379
train: epoch 31, loss 1.3153905868530273, acc=0.45911112427711487, loss=1.3153905868530273
test: epoch 31, loss 2.2306442260742188, acc=0.23333333432674408, loss=2.2306442260742188
train: epoch 32, loss 1.310910940170288, acc=0.45883333683013916, loss=1.310910940170288
test: epoch 32, loss 2.1138949394226074, acc=0.2222222238779068, loss=2.1138949394226074
train: epoch 33, loss 1.300434947013855, acc=0.4655555486679077, loss=1.300434947013855
test: epoch 33, loss 2.226026773452759, acc=0.23055554926395416, loss=2.226026773452759
train: epoch 34, loss 1.2982587814331055, acc=0.4672222137451172, loss=1.2982587814331055
test: epoch 34, loss 2.135939121246338, acc=0.21388888359069824, loss=2.135939121246338
train: epoch 35, loss 1.2904095649719238, acc=0.47661110758781433, loss=1.2904095649719238
test: epoch 35, loss 2.092576503753662, acc=0.20277777314186096, loss=2.092576503753662
train: epoch 36, loss 1.272437572479248, acc=0.47394445538520813, loss=1.272437572479248
test: epoch 36, loss 2.0259921550750732, acc=0.2222222238779068, loss=2.0259921550750732
train: epoch 37, loss 1.2896689176559448, acc=0.47083333134651184, loss=1.2896689176559448
test: epoch 37, loss 1.9666117429733276, acc=0.22499999403953552, loss=1.9666117429733276
train: epoch 38, loss 1.2478370666503906, acc=0.49105554819107056, loss=1.2478370666503906
test: epoch 38, loss 2.166701555252075, acc=0.22499999403953552, loss=2.166701555252075
train: epoch 39, loss 1.2454544305801392, acc=0.4852222204208374, loss=1.2454544305801392
test: epoch 39, loss 2.025052547454834, acc=0.22777777910232544, loss=2.025052547454834
train: epoch 40, loss 1.2405200004577637, acc=0.4860000014305115, loss=1.2405200004577637
test: epoch 40, loss 2.0455076694488525, acc=0.25, loss=2.0455076694488525
train: epoch 41, loss 1.2452664375305176, acc=0.4892222285270691, loss=1.2452664375305176
test: epoch 41, loss 2.0014331340789795, acc=0.2222222238779068, loss=2.0014331340789795
train: epoch 42, loss 1.2443491220474243, acc=0.4911110997200012, loss=1.2443491220474243
test: epoch 42, loss 1.9802080392837524, acc=0.26944443583488464, loss=1.9802080392837524
train: epoch 43, loss 1.2348222732543945, acc=0.49255555868148804, loss=1.2348222732543945
test: epoch 43, loss 2.0275747776031494, acc=0.25833332538604736, loss=2.0275747776031494
train: epoch 44, loss 1.2178752422332764, acc=0.5019999742507935, loss=1.2178752422332764
test: epoch 44, loss 2.149841070175171, acc=0.23333333432674408, loss=2.149841070175171
train: epoch 45, loss 1.2136439085006714, acc=0.5002777576446533, loss=1.2136439085006714
test: epoch 45, loss 2.0707569122314453, acc=0.24722221493721008, loss=2.0707569122314453
train: epoch 46, loss 1.2298861742019653, acc=0.5040555596351624, loss=1.2298861742019653
test: epoch 46, loss 1.8368135690689087, acc=0.23333333432674408, loss=1.8368135690689087
train: epoch 47, loss 1.1972488164901733, acc=0.5095000267028809, loss=1.1972488164901733
test: epoch 47, loss 2.0110318660736084, acc=0.28333333134651184, loss=2.0110318660736084
train: epoch 48, loss 1.1881605386734009, acc=0.5092777609825134, loss=1.1881605386734009
test: epoch 48, loss 1.9603804349899292, acc=0.3055555522441864, loss=1.9603804349899292
train: epoch 49, loss 1.178722620010376, acc=0.5176666378974915, loss=1.178722620010376
test: epoch 49, loss 1.7886966466903687, acc=0.2888889014720917, loss=1.7886966466903687
train: epoch 50, loss 1.1842128038406372, acc=0.5088333487510681, loss=1.1842128038406372
test: epoch 50, loss 1.7802218198776245, acc=0.2944444417953491, loss=1.7802218198776245
train: epoch 51, loss 1.189022421836853, acc=0.5145555734634399, loss=1.189022421836853
test: epoch 51, loss 1.6978307962417603, acc=0.2888889014720917, loss=1.6978307962417603
train: epoch 52, loss 1.1585822105407715, acc=0.5246666669845581, loss=1.1585822105407715
test: epoch 52, loss 1.6658339500427246, acc=0.34166666865348816, loss=1.6658339500427246
train: epoch 53, loss 1.1473780870437622, acc=0.531000018119812, loss=1.1473780870437622
test: epoch 53, loss 1.886419415473938, acc=0.2611111104488373, loss=1.886419415473938
train: epoch 54, loss 1.1557788848876953, acc=0.5290555357933044, loss=1.1557788848876953
test: epoch 54, loss 1.6036207675933838, acc=0.32499998807907104, loss=1.6036207675933838
train: epoch 55, loss 1.1486730575561523, acc=0.5317222476005554, loss=1.1486730575561523
test: epoch 55, loss 1.7102773189544678, acc=0.2611111104488373, loss=1.7102773189544678
train: epoch 56, loss 1.1579349040985107, acc=0.5313888788223267, loss=1.1579349040985107
test: epoch 56, loss 1.6772898435592651, acc=0.3027777671813965, loss=1.6772898435592651
train: epoch 57, loss 1.1547296047210693, acc=0.5308333039283752, loss=1.1547296047210693
test: epoch 57, loss 1.7022751569747925, acc=0.31111112236976624, loss=1.7022751569747925
train: epoch 58, loss 1.1537437438964844, acc=0.5285555720329285, loss=1.1537437438964844
test: epoch 58, loss 1.7738779783248901, acc=0.2750000059604645, loss=1.7738779783248901
train: epoch 59, loss 1.1287134885787964, acc=0.5363888740539551, loss=1.1287134885787964
test: epoch 59, loss 1.7596884965896606, acc=0.24166665971279144, loss=1.7596884965896606
train: epoch 60, loss 1.1268658638000488, acc=0.5431666374206543, loss=1.1268658638000488
test: epoch 60, loss 1.92113196849823, acc=0.28333333134651184, loss=1.92113196849823
train: epoch 61, loss 1.1169615983963013, acc=0.5416111350059509, loss=1.1169615983963013
test: epoch 61, loss 1.649971842765808, acc=0.25555557012557983, loss=1.649971842765808
train: epoch 62, loss 1.1030353307724, acc=0.5460000038146973, loss=1.1030353307724
test: epoch 62, loss 1.6581417322158813, acc=0.3222222328186035, loss=1.6581417322158813
train: epoch 63, loss 1.0836158990859985, acc=0.5528333187103271, loss=1.0836158990859985
test: epoch 63, loss 1.644738793373108, acc=0.3333333432674408, loss=1.644738793373108
train: epoch 64, loss 1.0822559595108032, acc=0.5571110844612122, loss=1.0822559595108032
test: epoch 64, loss 1.6499117612838745, acc=0.3499999940395355, loss=1.6499117612838745
train: epoch 65, loss 1.1003578901290894, acc=0.5479444265365601, loss=1.1003578901290894
test: epoch 65, loss 1.7169079780578613, acc=0.3055555522441864, loss=1.7169079780578613
train: epoch 66, loss 1.0748826265335083, acc=0.5633888840675354, loss=1.0748826265335083
test: epoch 66, loss 1.6158185005187988, acc=0.3222222328186035, loss=1.6158185005187988
train: epoch 67, loss 1.073834776878357, acc=0.5590000152587891, loss=1.073834776878357
test: epoch 67, loss 1.6215858459472656, acc=0.3472222089767456, loss=1.6215858459472656
train: epoch 68, loss 1.0620630979537964, acc=0.5686110854148865, loss=1.0620630979537964
test: epoch 68, loss 1.7000834941864014, acc=0.35277777910232544, loss=1.7000834941864014
train: epoch 69, loss 1.0713237524032593, acc=0.558222234249115, loss=1.0713237524032593
test: epoch 69, loss 1.660797357559204, acc=0.3055555522441864, loss=1.660797357559204
train: epoch 70, loss 1.0682802200317383, acc=0.5652777552604675, loss=1.0682802200317383
test: epoch 70, loss 1.6505314111709595, acc=0.3305555582046509, loss=1.6505314111709595
train: epoch 71, loss 1.0498369932174683, acc=0.5757777690887451, loss=1.0498369932174683
test: epoch 71, loss 1.669655442237854, acc=0.3777777850627899, loss=1.669655442237854
train: epoch 72, loss 1.0508018732070923, acc=0.5774999856948853, loss=1.0508018732070923
test: epoch 72, loss 1.7852028608322144, acc=0.3361110985279083, loss=1.7852028608322144
train: epoch 73, loss 1.0238990783691406, acc=0.5827777981758118, loss=1.0238990783691406
test: epoch 73, loss 1.7666178941726685, acc=0.3638888895511627, loss=1.7666178941726685
train: epoch 74, loss 1.042502760887146, acc=0.5764444470405579, loss=1.042502760887146
test: epoch 74, loss 1.6184731721878052, acc=0.3638888895511627, loss=1.6184731721878052
train: epoch 75, loss 1.0119128227233887, acc=0.585777759552002, loss=1.0119128227233887
test: epoch 75, loss 1.5837721824645996, acc=0.36666667461395264, loss=1.5837721824645996
train: epoch 76, loss 1.015353798866272, acc=0.5841110944747925, loss=1.015353798866272
test: epoch 76, loss 1.742004156112671, acc=0.3499999940395355, loss=1.742004156112671
train: epoch 77, loss 1.0001530647277832, acc=0.5947777628898621, loss=1.0001530647277832
test: epoch 77, loss 1.534639835357666, acc=0.35555556416511536, loss=1.534639835357666
train: epoch 78, loss 0.9941117167472839, acc=0.5976666808128357, loss=0.9941117167472839
test: epoch 78, loss 1.584938883781433, acc=0.36666667461395264, loss=1.584938883781433
train: epoch 79, loss 1.0014469623565674, acc=0.592555582523346, loss=1.0014469623565674
test: epoch 79, loss 1.6622369289398193, acc=0.34166666865348816, loss=1.6622369289398193
train: epoch 80, loss 0.9796038866043091, acc=0.6070555448532104, loss=0.9796038866043091
test: epoch 80, loss 1.6905769109725952, acc=0.32499998807907104, loss=1.6905769109725952
train: epoch 81, loss 0.9766199588775635, acc=0.6065000295639038, loss=0.9766199588775635
test: epoch 81, loss 1.5625536441802979, acc=0.32777777314186096, loss=1.5625536441802979
train: epoch 82, loss 0.9762457609176636, acc=0.6046666502952576, loss=0.9762457609176636
test: epoch 82, loss 1.6030956506729126, acc=0.3444444537162781, loss=1.6030956506729126
train: epoch 83, loss 0.9632996916770935, acc=0.6071110963821411, loss=0.9632996916770935
test: epoch 83, loss 1.7965821027755737, acc=0.34166666865348816, loss=1.7965821027755737
train: epoch 84, loss 0.9623430371284485, acc=0.6087777614593506, loss=0.9623430371284485
test: epoch 84, loss 1.7650831937789917, acc=0.2916666567325592, loss=1.7650831937789917
train: epoch 85, loss 0.9587072134017944, acc=0.609000027179718, loss=0.9587072134017944
test: epoch 85, loss 1.6364868879318237, acc=0.3611111044883728, loss=1.6364868879318237
train: epoch 86, loss 0.9598298668861389, acc=0.609000027179718, loss=0.9598298668861389
test: epoch 86, loss 1.6069937944412231, acc=0.3861111104488373, loss=1.6069937944412231
train: epoch 87, loss 0.9464659094810486, acc=0.6168888807296753, loss=0.9464659094810486
test: epoch 87, loss 1.6473584175109863, acc=0.3722222149372101, loss=1.6473584175109863
train: epoch 88, loss 0.9442217946052551, acc=0.6183888912200928, loss=0.9442217946052551
test: epoch 88, loss 1.6427325010299683, acc=0.34166666865348816, loss=1.6427325010299683
train: epoch 89, loss 0.9332172870635986, acc=0.6233888864517212, loss=0.9332172870635986
test: epoch 89, loss 1.7911003828048706, acc=0.3361110985279083, loss=1.7911003828048706
train: epoch 90, loss 0.939385712146759, acc=0.6169999837875366, loss=0.939385712146759
test: epoch 90, loss 1.6080445051193237, acc=0.39444443583488464, loss=1.6080445051193237
train: epoch 91, loss 0.914293646812439, acc=0.6287222504615784, loss=0.914293646812439
test: epoch 91, loss 1.7458666563034058, acc=0.3638888895511627, loss=1.7458666563034058
train: epoch 92, loss 0.9361779689788818, acc=0.621833324432373, loss=0.9361779689788818
test: epoch 92, loss 1.7110048532485962, acc=0.3361110985279083, loss=1.7110048532485962
train: epoch 93, loss 0.9187584519386292, acc=0.6286110877990723, loss=0.9187584519386292
test: epoch 93, loss 1.6774210929870605, acc=0.34166666865348816, loss=1.6774210929870605
train: epoch 94, loss 0.9162228107452393, acc=0.6298333406448364, loss=0.9162228107452393
test: epoch 94, loss 1.6111488342285156, acc=0.3638888895511627, loss=1.6111488342285156
train: epoch 95, loss 0.9108991026878357, acc=0.6288333535194397, loss=0.9108991026878357
test: epoch 95, loss 1.7364943027496338, acc=0.3583333194255829, loss=1.7364943027496338
train: epoch 96, loss 0.9093177318572998, acc=0.63227778673172, loss=0.9093177318572998
test: epoch 96, loss 1.9173252582550049, acc=0.3361110985279083, loss=1.9173252582550049
train: epoch 97, loss 0.9036505818367004, acc=0.6312222480773926, loss=0.9036505818367004
test: epoch 97, loss 1.7001370191574097, acc=0.36944442987442017, loss=1.7001370191574097
train: epoch 98, loss 0.9027441740036011, acc=0.636555552482605, loss=0.9027441740036011
test: epoch 98, loss 1.7407338619232178, acc=0.3722222149372101, loss=1.7407338619232178
train: epoch 99, loss 0.9104876518249512, acc=0.633222222328186, loss=0.9104876518249512
test: epoch 99, loss 1.876503586769104, acc=0.375, loss=1.876503586769104
train: epoch 100, loss 0.9028271436691284, acc=0.6311666369438171, loss=0.9028271436691284
test: epoch 100, loss 1.836245059967041, acc=0.375, loss=1.836245059967041
train: epoch 101, loss 0.9002824425697327, acc=0.6349444389343262, loss=0.9002824425697327
test: epoch 101, loss 1.4832862615585327, acc=0.3611111044883728, loss=1.4832862615585327
train: epoch 102, loss 0.8768935203552246, acc=0.6441666483879089, loss=0.8768935203552246
test: epoch 102, loss 1.7845306396484375, acc=0.3333333432674408, loss=1.7845306396484375
train: epoch 103, loss 0.8743727803230286, acc=0.6414999961853027, loss=0.8743727803230286
test: epoch 103, loss 1.7679182291030884, acc=0.3305555582046509, loss=1.7679182291030884
train: epoch 104, loss 0.8817986249923706, acc=0.6413888931274414, loss=0.8817986249923706
test: epoch 104, loss 1.8769257068634033, acc=0.3361110985279083, loss=1.8769257068634033
train: epoch 105, loss 0.8786444664001465, acc=0.643833339214325, loss=0.8786444664001465
test: epoch 105, loss 1.7756104469299316, acc=0.3333333432674408, loss=1.7756104469299316
train: epoch 106, loss 0.8663862943649292, acc=0.6498333215713501, loss=0.8663862943649292
test: epoch 106, loss 1.5990259647369385, acc=0.3583333194255829, loss=1.5990259647369385
train: epoch 107, loss 0.8578566908836365, acc=0.6542778015136719, loss=0.8578566908836365
test: epoch 107, loss 1.685613751411438, acc=0.3777777850627899, loss=1.685613751411438
train: epoch 108, loss 0.8655604124069214, acc=0.6475555300712585, loss=0.8655604124069214
test: epoch 108, loss 1.8793100118637085, acc=0.25, loss=1.8793100118637085
train: epoch 109, loss 0.8602281808853149, acc=0.656000018119812, loss=0.8602281808853149
test: epoch 109, loss 1.5501736402511597, acc=0.4027777910232544, loss=1.5501736402511597
train: epoch 110, loss 0.8489832878112793, acc=0.6561111211776733, loss=0.8489832878112793
test: epoch 110, loss 1.6687391996383667, acc=0.32777777314186096, loss=1.6687391996383667
train: epoch 111, loss 0.8581867218017578, acc=0.6505555510520935, loss=0.8581867218017578
test: epoch 111, loss 1.566384196281433, acc=0.3583333194255829, loss=1.566384196281433
train: epoch 112, loss 0.8438844680786133, acc=0.6578333377838135, loss=0.8438844680786133
test: epoch 112, loss 1.626252293586731, acc=0.29722222685813904, loss=1.626252293586731
train: epoch 113, loss 0.8421987891197205, acc=0.6595555543899536, loss=0.8421987891197205
test: epoch 113, loss 1.666927456855774, acc=0.3333333432674408, loss=1.666927456855774
train: epoch 114, loss 0.833993136882782, acc=0.6661666631698608, loss=0.833993136882782
test: epoch 114, loss 1.542229413986206, acc=0.39444443583488464, loss=1.542229413986206
train: epoch 115, loss 0.8367897868156433, acc=0.6630555391311646, loss=0.8367897868156433
test: epoch 115, loss 1.656704068183899, acc=0.38333332538604736, loss=1.656704068183899
train: epoch 116, loss 0.82853102684021, acc=0.6663333177566528, loss=0.82853102684021
test: epoch 116, loss 1.5784847736358643, acc=0.33888888359069824, loss=1.5784847736358643
train: epoch 117, loss 0.8201069831848145, acc=0.6697221994400024, loss=0.8201069831848145
test: epoch 117, loss 1.7144618034362793, acc=0.3166666626930237, loss=1.7144618034362793
train: epoch 118, loss 0.8157442808151245, acc=0.6725555658340454, loss=0.8157442808151245
test: epoch 118, loss 1.760739803314209, acc=0.35555556416511536, loss=1.760739803314209
train: epoch 119, loss 0.8179792761802673, acc=0.6725000143051147, loss=0.8179792761802673
test: epoch 119, loss 1.614770531654358, acc=0.4055555462837219, loss=1.614770531654358
train: epoch 120, loss 0.8063030242919922, acc=0.6759999990463257, loss=0.8063030242919922
test: epoch 120, loss 1.4921319484710693, acc=0.38333332538604736, loss=1.4921319484710693
train: epoch 121, loss 0.8155384659767151, acc=0.6704444289207458, loss=0.8155384659767151
test: epoch 121, loss 1.6357694864273071, acc=0.3638888895511627, loss=1.6357694864273071
train: epoch 122, loss 0.8036224842071533, acc=0.6733888983726501, loss=0.8036224842071533
test: epoch 122, loss 1.6010946035385132, acc=0.4000000059604645, loss=1.6010946035385132
train: epoch 123, loss 0.7955095171928406, acc=0.6754444241523743, loss=0.7955095171928406
test: epoch 123, loss 1.6358553171157837, acc=0.3638888895511627, loss=1.6358553171157837
train: epoch 124, loss 0.7918822765350342, acc=0.6766111254692078, loss=0.7918822765350342
test: epoch 124, loss 1.5643450021743774, acc=0.36666667461395264, loss=1.5643450021743774
train: epoch 125, loss 0.8012924194335938, acc=0.6791666746139526, loss=0.8012924194335938
test: epoch 125, loss 1.678398847579956, acc=0.4000000059604645, loss=1.678398847579956
train: epoch 126, loss 0.8000174164772034, acc=0.675000011920929, loss=0.8000174164772034
test: epoch 126, loss 1.4826860427856445, acc=0.3583333194255829, loss=1.4826860427856445
train: epoch 127, loss 0.7875587940216064, acc=0.6817222237586975, loss=0.7875587940216064
test: epoch 127, loss 1.5188508033752441, acc=0.38333332538604736, loss=1.5188508033752441
train: epoch 128, loss 0.7759596109390259, acc=0.6862221956253052, loss=0.7759596109390259
test: epoch 128, loss 1.5869897603988647, acc=0.4055555462837219, loss=1.5869897603988647
train: epoch 129, loss 0.7725611329078674, acc=0.6892222166061401, loss=0.7725611329078674
test: epoch 129, loss 1.677385687828064, acc=0.32499998807907104, loss=1.677385687828064
train: epoch 130, loss 0.7763804793357849, acc=0.6819444298744202, loss=0.7763804793357849
test: epoch 130, loss 1.5462762117385864, acc=0.33888888359069824, loss=1.5462762117385864
train: epoch 131, loss 0.7739459276199341, acc=0.6883333325386047, loss=0.7739459276199341
test: epoch 131, loss 1.6765055656433105, acc=0.31388887763023376, loss=1.6765055656433105
train: epoch 132, loss 0.7676064968109131, acc=0.6854444742202759, loss=0.7676064968109131
test: epoch 132, loss 1.5655158758163452, acc=0.3499999940395355, loss=1.5655158758163452
train: epoch 133, loss 0.7542988657951355, acc=0.6940000057220459, loss=0.7542988657951355
test: epoch 133, loss 1.6679091453552246, acc=0.38055557012557983, loss=1.6679091453552246
train: epoch 134, loss 0.7714048027992249, acc=0.6860555410385132, loss=0.7714048027992249
test: epoch 134, loss 1.632535457611084, acc=0.3583333194255829, loss=1.632535457611084
train: epoch 135, loss 0.7583478689193726, acc=0.69477778673172, loss=0.7583478689193726
test: epoch 135, loss 1.6444388628005981, acc=0.3861111104488373, loss=1.6444388628005981
train: epoch 136, loss 0.7687032222747803, acc=0.6939444541931152, loss=0.7687032222747803
test: epoch 136, loss 1.5680421590805054, acc=0.36944442987442017, loss=1.5680421590805054
train: epoch 137, loss 0.7534617185592651, acc=0.6945555806159973, loss=0.7534617185592651
test: epoch 137, loss 1.5780619382858276, acc=0.4027777910232544, loss=1.5780619382858276
train: epoch 138, loss 0.7647550106048584, acc=0.6890555620193481, loss=0.7647550106048584
test: epoch 138, loss 1.6712778806686401, acc=0.3611111044883728, loss=1.6712778806686401
train: epoch 139, loss 0.758365273475647, acc=0.6906111240386963, loss=0.758365273475647
test: epoch 139, loss 1.6179643869400024, acc=0.4027777910232544, loss=1.6179643869400024
train: epoch 140, loss 0.7560713291168213, acc=0.6940555572509766, loss=0.7560713291168213
test: epoch 140, loss 1.6307135820388794, acc=0.3638888895511627, loss=1.6307135820388794
train: epoch 141, loss 0.745897650718689, acc=0.6982222199440002, loss=0.745897650718689
test: epoch 141, loss 1.6105598211288452, acc=0.4000000059604645, loss=1.6105598211288452
train: epoch 142, loss 0.7666486501693726, acc=0.6902777552604675, loss=0.7666486501693726
test: epoch 142, loss 1.6779030561447144, acc=0.3083333373069763, loss=1.6779030561447144
train: epoch 143, loss 0.7473564147949219, acc=0.6944444179534912, loss=0.7473564147949219
test: epoch 143, loss 1.5427089929580688, acc=0.4166666567325592, loss=1.5427089929580688
train: epoch 144, loss 0.7419717907905579, acc=0.6998888850212097, loss=0.7419717907905579
test: epoch 144, loss 1.5246716737747192, acc=0.36944442987442017, loss=1.5246716737747192
train: epoch 145, loss 0.7429006695747375, acc=0.6971666812896729, loss=0.7429006695747375
test: epoch 145, loss 1.711745023727417, acc=0.31388887763023376, loss=1.711745023727417
train: epoch 146, loss 0.752120316028595, acc=0.6945555806159973, loss=0.752120316028595
test: epoch 146, loss 1.776745319366455, acc=0.3583333194255829, loss=1.776745319366455
train: epoch 147, loss 0.7449746131896973, acc=0.6973888874053955, loss=0.7449746131896973
test: epoch 147, loss 1.6726711988449097, acc=0.3583333194255829, loss=1.6726711988449097
train: epoch 148, loss 0.7415814399719238, acc=0.6962777972221375, loss=0.7415814399719238
test: epoch 148, loss 1.6957511901855469, acc=0.4027777910232544, loss=1.6957511901855469
train: epoch 149, loss 0.7410547137260437, acc=0.6993333101272583, loss=0.7410547137260437
test: epoch 149, loss 1.5948400497436523, acc=0.4166666567325592, loss=1.5948400497436523
train: epoch 150, loss 0.7211425304412842, acc=0.7068889141082764, loss=0.7211425304412842
test: epoch 150, loss 1.6511344909667969, acc=0.40833333134651184, loss=1.6511344909667969
