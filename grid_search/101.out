# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=1", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=811196392, receiver_embed_dim=64, save_run=0, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=811196392, receiver_embed_dim=64, save_run=False, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.7599503993988037, acc=0.10344444215297699, loss=2.7599503993988037
test: epoch 1, loss 4.9487457275390625, acc=0.08611111342906952, loss=4.9487457275390625
train: epoch 2, loss 1.7184885740280151, acc=0.2687777876853943, loss=1.7184885740280151
test: epoch 2, loss 5.0300612449646, acc=0.14166666567325592, loss=5.0300612449646
train: epoch 3, loss 1.3413329124450684, acc=0.4224444329738617, loss=1.3413329124450684
test: epoch 3, loss 5.657257080078125, acc=0.10555555671453476, loss=5.657257080078125
train: epoch 4, loss 1.00798761844635, acc=0.5767222046852112, loss=1.00798761844635
test: epoch 4, loss 4.81511116027832, acc=0.1527777761220932, loss=4.81511116027832
train: epoch 5, loss 0.8509517312049866, acc=0.6512777805328369, loss=0.8509517312049866
test: epoch 5, loss 4.3846611976623535, acc=0.16944444179534912, loss=4.3846611976623535
train: epoch 6, loss 0.6613807082176208, acc=0.7397778034210205, loss=0.6613807082176208
test: epoch 6, loss 4.808138847351074, acc=0.22499999403953552, loss=4.808138847351074
train: epoch 7, loss 0.5526658296585083, acc=0.7857221961021423, loss=0.5526658296585083
test: epoch 7, loss 3.7929799556732178, acc=0.2611111104488373, loss=3.7929799556732178
train: epoch 8, loss 0.4398241341114044, acc=0.8309444189071655, loss=0.4398241341114044
test: epoch 8, loss 3.665008544921875, acc=0.2750000059604645, loss=3.665008544921875
train: epoch 9, loss 0.3952295780181885, acc=0.8465555310249329, loss=0.3952295780181885
test: epoch 9, loss 2.997095823287964, acc=0.28333333134651184, loss=2.997095823287964
train: epoch 10, loss 0.34981420636177063, acc=0.8622778058052063, loss=0.34981420636177063
test: epoch 10, loss 3.7663562297821045, acc=0.2777777910232544, loss=3.7663562297821045
train: epoch 11, loss 0.32575294375419617, acc=0.8700555562973022, loss=0.32575294375419617
test: epoch 11, loss 3.042473316192627, acc=0.27222222089767456, loss=3.042473316192627
train: epoch 12, loss 0.2927594482898712, acc=0.8840000033378601, loss=0.2927594482898712
test: epoch 12, loss 3.3920207023620605, acc=0.29722222685813904, loss=3.3920207023620605
train: epoch 13, loss 0.268070787191391, acc=0.8941666483879089, loss=0.268070787191391
test: epoch 13, loss 3.080763101577759, acc=0.33888888359069824, loss=3.080763101577759
train: epoch 14, loss 0.2714575529098511, acc=0.8907777667045593, loss=0.2714575529098511
test: epoch 14, loss 2.4696128368377686, acc=0.3638888895511627, loss=2.4696128368377686
train: epoch 15, loss 0.2633568346500397, acc=0.8971111178398132, loss=0.2633568346500397
test: epoch 15, loss 2.610585927963257, acc=0.3305555582046509, loss=2.610585927963257
train: epoch 16, loss 0.2298649102449417, acc=0.9068333506584167, loss=0.2298649102449417
test: epoch 16, loss 2.9288907051086426, acc=0.2944444417953491, loss=2.9288907051086426
train: epoch 17, loss 0.217772975564003, acc=0.9115555286407471, loss=0.217772975564003
test: epoch 17, loss 2.372035026550293, acc=0.3916666805744171, loss=2.372035026550293
train: epoch 18, loss 0.21592052280902863, acc=0.9162222146987915, loss=0.21592052280902863
test: epoch 18, loss 2.050506353378296, acc=0.3777777850627899, loss=2.050506353378296
train: epoch 19, loss 0.20376372337341309, acc=0.9241666793823242, loss=0.20376372337341309
test: epoch 19, loss 1.9938442707061768, acc=0.3777777850627899, loss=1.9938442707061768
train: epoch 20, loss 0.19356109201908112, acc=0.9328333139419556, loss=0.19356109201908112
test: epoch 20, loss 1.8895270824432373, acc=0.44999998807907104, loss=1.8895270824432373
train: epoch 21, loss 0.18333035707473755, acc=0.9390000104904175, loss=0.18333035707473755
test: epoch 21, loss 2.5951409339904785, acc=0.4166666567325592, loss=2.5951409339904785
train: epoch 22, loss 0.16365911066532135, acc=0.9491111040115356, loss=0.16365911066532135
test: epoch 22, loss 1.8032704591751099, acc=0.5361111164093018, loss=1.8032704591751099
train: epoch 23, loss 0.14505714178085327, acc=0.9541110992431641, loss=0.14505714178085327
test: epoch 23, loss 2.0856361389160156, acc=0.4555555582046509, loss=2.0856361389160156
train: epoch 24, loss 0.13076551258563995, acc=0.9581111073493958, loss=0.13076551258563995
test: epoch 24, loss 2.104118824005127, acc=0.4555555582046509, loss=2.104118824005127
train: epoch 25, loss 0.13484640419483185, acc=0.9561111330986023, loss=0.13484640419483185
test: epoch 25, loss 1.5422636270523071, acc=0.550000011920929, loss=1.5422636270523071
train: epoch 26, loss 0.13223107159137726, acc=0.960277795791626, loss=0.13223107159137726
test: epoch 26, loss 2.5521440505981445, acc=0.4555555582046509, loss=2.5521440505981445
train: epoch 27, loss 0.13340415060520172, acc=0.9572222232818604, loss=0.13340415060520172
test: epoch 27, loss 1.8812839984893799, acc=0.4277777671813965, loss=1.8812839984893799
train: epoch 28, loss 0.11812017112970352, acc=0.9634444713592529, loss=0.11812017112970352
test: epoch 28, loss 1.6897183656692505, acc=0.4722222089767456, loss=1.6897183656692505
train: epoch 29, loss 0.12210637331008911, acc=0.9606666564941406, loss=0.12210637331008911
test: epoch 29, loss 2.326716661453247, acc=0.5138888955116272, loss=2.326716661453247
train: epoch 30, loss 0.12217061966657639, acc=0.9624999761581421, loss=0.12217061966657639
test: epoch 30, loss 1.7992357015609741, acc=0.5138888955116272, loss=1.7992357015609741
train: epoch 31, loss 0.10839829593896866, acc=0.9663888812065125, loss=0.10839829593896866
test: epoch 31, loss 1.9542962312698364, acc=0.46666666865348816, loss=1.9542962312698364
train: epoch 32, loss 0.09939125925302505, acc=0.968666672706604, loss=0.09939125925302505
test: epoch 32, loss 2.1250345706939697, acc=0.46388888359069824, loss=2.1250345706939697
train: epoch 33, loss 0.11094801127910614, acc=0.9662777781486511, loss=0.11094801127910614
test: epoch 33, loss 2.193310260772705, acc=0.4861111044883728, loss=2.193310260772705
train: epoch 34, loss 0.09860901534557343, acc=0.9707777500152588, loss=0.09860901534557343
test: epoch 34, loss 1.8353056907653809, acc=0.5138888955116272, loss=1.8353056907653809
train: epoch 35, loss 0.10319172590970993, acc=0.9679444432258606, loss=0.10319172590970993
test: epoch 35, loss 1.6208471059799194, acc=0.4972222149372101, loss=1.6208471059799194
train: epoch 36, loss 0.09743176400661469, acc=0.971833348274231, loss=0.09743176400661469
test: epoch 36, loss 1.9764511585235596, acc=0.5055555701255798, loss=1.9764511585235596
train: epoch 37, loss 0.09393429756164551, acc=0.9711111187934875, loss=0.09393429756164551
test: epoch 37, loss 1.8245729207992554, acc=0.5305555462837219, loss=1.8245729207992554
train: epoch 38, loss 0.09592598676681519, acc=0.9701666831970215, loss=0.09592598676681519
test: epoch 38, loss 2.3508965969085693, acc=0.49444442987442017, loss=2.3508965969085693
train: epoch 39, loss 0.09170792251825333, acc=0.9714999794960022, loss=0.09170792251825333
test: epoch 39, loss 1.8489946126937866, acc=0.5083333253860474, loss=1.8489946126937866
train: epoch 40, loss 0.08253173530101776, acc=0.9757221937179565, loss=0.08253173530101776
test: epoch 40, loss 1.8411580324172974, acc=0.48055556416511536, loss=1.8411580324172974
train: epoch 41, loss 0.08201240003108978, acc=0.9753888845443726, loss=0.08201240003108978
test: epoch 41, loss 2.2215423583984375, acc=0.5, loss=2.2215423583984375
train: epoch 42, loss 0.0871201902627945, acc=0.9748333096504211, loss=0.0871201902627945
test: epoch 42, loss 2.511847734451294, acc=0.5249999761581421, loss=2.511847734451294
train: epoch 43, loss 0.07653911411762238, acc=0.976722240447998, loss=0.07653911411762238
test: epoch 43, loss 2.069587469100952, acc=0.4611110985279083, loss=2.069587469100952
train: epoch 44, loss 0.08910147100687027, acc=0.9747777581214905, loss=0.08910147100687027
test: epoch 44, loss 2.0993099212646484, acc=0.5277777910232544, loss=2.0993099212646484
train: epoch 45, loss 0.08005031198263168, acc=0.97688889503479, loss=0.08005031198263168
test: epoch 45, loss 1.4596279859542847, acc=0.5416666865348816, loss=1.4596279859542847
train: epoch 46, loss 0.07527400553226471, acc=0.975944459438324, loss=0.07527400553226471
test: epoch 46, loss 1.5737838745117188, acc=0.5222222208976746, loss=1.5737838745117188
train: epoch 47, loss 0.086787149310112, acc=0.9734444618225098, loss=0.086787149310112
test: epoch 47, loss 1.5919501781463623, acc=0.5416666865348816, loss=1.5919501781463623
train: epoch 48, loss 0.08166588097810745, acc=0.9751666784286499, loss=0.08166588097810745
test: epoch 48, loss 1.6520699262619019, acc=0.5222222208976746, loss=1.6520699262619019
train: epoch 49, loss 0.06623084843158722, acc=0.9795555472373962, loss=0.06623084843158722
test: epoch 49, loss 2.0230770111083984, acc=0.6027777791023254, loss=2.0230770111083984
train: epoch 50, loss 0.07411199808120728, acc=0.9778888821601868, loss=0.07411199808120728
test: epoch 50, loss 1.5046855211257935, acc=0.574999988079071, loss=1.5046855211257935
train: epoch 51, loss 0.07970733195543289, acc=0.9754999876022339, loss=0.07970733195543289
test: epoch 51, loss 1.4985029697418213, acc=0.6083333492279053, loss=1.4985029697418213
train: epoch 52, loss 0.07494808733463287, acc=0.9777777791023254, loss=0.07494808733463287
test: epoch 52, loss 1.7020195722579956, acc=0.6527777910232544, loss=1.7020195722579956
train: epoch 53, loss 0.0718449056148529, acc=0.9777777791023254, loss=0.0718449056148529
test: epoch 53, loss 1.0815813541412354, acc=0.7111111283302307, loss=1.0815813541412354
train: epoch 54, loss 0.05851173773407936, acc=0.9817222356796265, loss=0.05851173773407936
test: epoch 54, loss 1.5970430374145508, acc=0.6361111402511597, loss=1.5970430374145508
train: epoch 55, loss 0.055405065417289734, acc=0.9834444522857666, loss=0.055405065417289734
test: epoch 55, loss 0.9505355954170227, acc=0.7111111283302307, loss=0.9505355954170227
train: epoch 56, loss 0.06499406695365906, acc=0.9814444184303284, loss=0.06499406695365906
test: epoch 56, loss 1.354278326034546, acc=0.6833333373069763, loss=1.354278326034546
train: epoch 57, loss 0.060510024428367615, acc=0.9826111197471619, loss=0.060510024428367615
test: epoch 57, loss 1.6841027736663818, acc=0.6861110925674438, loss=1.6841027736663818
train: epoch 58, loss 0.07704444974660873, acc=0.9789444208145142, loss=0.07704444974660873
test: epoch 58, loss 1.5624626874923706, acc=0.6666666865348816, loss=1.5624626874923706
train: epoch 59, loss 0.06930994987487793, acc=0.9810555577278137, loss=0.06930994987487793
test: epoch 59, loss 1.0799764394760132, acc=0.7333333492279053, loss=1.0799764394760132
train: epoch 60, loss 0.05507052689790726, acc=0.9832777976989746, loss=0.05507052689790726
test: epoch 60, loss 1.2329096794128418, acc=0.6833333373069763, loss=1.2329096794128418
train: epoch 61, loss 0.062466707080602646, acc=0.9827777743339539, loss=0.062466707080602646
test: epoch 61, loss 0.8914263844490051, acc=0.7972221970558167, loss=0.8914263844490051
train: epoch 62, loss 0.05415404960513115, acc=0.9858333468437195, loss=0.05415404960513115
test: epoch 62, loss 0.6112648248672485, acc=0.7805555462837219, loss=0.6112648248672485
train: epoch 63, loss 0.054095614701509476, acc=0.9842222332954407, loss=0.054095614701509476
test: epoch 63, loss 0.9269556999206543, acc=0.8194444179534912, loss=0.9269556999206543
train: epoch 64, loss 0.058159466832876205, acc=0.9841111302375793, loss=0.058159466832876205
test: epoch 64, loss 0.7651125192642212, acc=0.7722222208976746, loss=0.7651125192642212
train: epoch 65, loss 0.05146658048033714, acc=0.9858333468437195, loss=0.05146658048033714
test: epoch 65, loss 0.7547354698181152, acc=0.7972221970558167, loss=0.7547354698181152
train: epoch 66, loss 0.06329904496669769, acc=0.9822777509689331, loss=0.06329904496669769
test: epoch 66, loss 0.6917113661766052, acc=0.875, loss=0.6917113661766052
train: epoch 67, loss 0.04452631622552872, acc=0.988277792930603, loss=0.04452631622552872
test: epoch 67, loss 0.6598778963088989, acc=0.8833333253860474, loss=0.6598778963088989
train: epoch 68, loss 0.043673478066921234, acc=0.9882222414016724, loss=0.043673478066921234
test: epoch 68, loss 0.4665813148021698, acc=0.9166666865348816, loss=0.4665813148021698
train: epoch 69, loss 0.04613684117794037, acc=0.9867222309112549, loss=0.04613684117794037
test: epoch 69, loss 0.5080686807632446, acc=0.894444465637207, loss=0.5080686807632446
train: epoch 70, loss 0.03893546015024185, acc=0.9889444708824158, loss=0.03893546015024185
test: epoch 70, loss 0.3971917927265167, acc=0.9083333611488342, loss=0.3971917927265167
train: epoch 71, loss 0.04514153674244881, acc=0.9879444241523743, loss=0.04514153674244881
test: epoch 71, loss 0.23667429387569427, acc=0.9638888835906982, loss=0.23667429387569427
train: epoch 72, loss 0.03985733911395073, acc=0.9903333187103271, loss=0.03985733911395073
test: epoch 72, loss 0.13582099974155426, acc=0.9666666388511658, loss=0.13582099974155426
train: epoch 73, loss 0.03274104371666908, acc=0.9911666512489319, loss=0.03274104371666908
test: epoch 73, loss 0.06303755939006805, acc=0.9777777791023254, loss=0.06303755939006805
train: epoch 74, loss 0.03139425814151764, acc=0.991611123085022, loss=0.03139425814151764
test: epoch 74, loss 0.13958962261676788, acc=0.9694444537162781, loss=0.13958962261676788
train: epoch 75, loss 0.031325869262218475, acc=0.9926666617393494, loss=0.031325869262218475
test: epoch 75, loss 0.08820483833551407, acc=0.9750000238418579, loss=0.08820483833551407
train: epoch 76, loss 0.03187387064099312, acc=0.9918888807296753, loss=0.03187387064099312
test: epoch 76, loss 0.0899813324213028, acc=0.9777777791023254, loss=0.0899813324213028
train: epoch 77, loss 0.025702182203531265, acc=0.9944444298744202, loss=0.025702182203531265
test: epoch 77, loss 0.008391202427446842, acc=1.0, loss=0.008391202427446842
