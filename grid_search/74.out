# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=1.5", "--temp_decay=1", "--one_hot=0", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=861104250, receiver_embed_dim=64, save_run=0, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=861104250, receiver_embed_dim=64, save_run=False, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.426448345184326, acc=0.15627777576446533, loss=2.426448345184326
test: epoch 1, loss 4.558320999145508, acc=0.07500000298023224, loss=4.558320999145508
train: epoch 2, loss 1.7008541822433472, acc=0.31211110949516296, loss=1.7008541822433472
test: epoch 2, loss 3.0256457328796387, acc=0.1805555522441864, loss=3.0256457328796387
train: epoch 3, loss 1.4396946430206299, acc=0.40405556559562683, loss=1.4396946430206299
test: epoch 3, loss 2.6931254863739014, acc=0.20555555820465088, loss=2.6931254863739014
train: epoch 4, loss 1.2708194255828857, acc=0.47038888931274414, loss=1.2708194255828857
test: epoch 4, loss 3.0563900470733643, acc=0.18611110746860504, loss=3.0563900470733643
train: epoch 5, loss 1.1779472827911377, acc=0.5192777514457703, loss=1.1779472827911377
test: epoch 5, loss 2.953498125076294, acc=0.2638888955116272, loss=2.953498125076294
train: epoch 6, loss 1.090225338935852, acc=0.5556666851043701, loss=1.090225338935852
test: epoch 6, loss 2.803434371948242, acc=0.28333333134651184, loss=2.803434371948242
train: epoch 7, loss 1.0494879484176636, acc=0.5776110887527466, loss=1.0494879484176636
test: epoch 7, loss 2.4693591594696045, acc=0.2222222238779068, loss=2.4693591594696045
train: epoch 8, loss 0.9666212797164917, acc=0.6115555763244629, loss=0.9666212797164917
test: epoch 8, loss 2.480356454849243, acc=0.2638888955116272, loss=2.480356454849243
train: epoch 9, loss 0.9458199739456177, acc=0.6260555386543274, loss=0.9458199739456177
test: epoch 9, loss 2.593510389328003, acc=0.2750000059604645, loss=2.593510389328003
train: epoch 10, loss 0.9356377720832825, acc=0.6216111183166504, loss=0.9356377720832825
test: epoch 10, loss 2.425931215286255, acc=0.27222222089767456, loss=2.425931215286255
train: epoch 11, loss 0.8457460999488831, acc=0.6575555801391602, loss=0.8457460999488831
test: epoch 11, loss 2.585721969604492, acc=0.25555557012557983, loss=2.585721969604492
train: epoch 12, loss 0.8258015513420105, acc=0.6738888621330261, loss=0.8258015513420105
test: epoch 12, loss 2.2289509773254395, acc=0.3194444477558136, loss=2.2289509773254395
train: epoch 13, loss 0.8035433888435364, acc=0.6879444718360901, loss=0.8035433888435364
test: epoch 13, loss 1.962958812713623, acc=0.36666667461395264, loss=1.962958812713623
train: epoch 14, loss 0.7626804113388062, acc=0.6974999904632568, loss=0.7626804113388062
test: epoch 14, loss 2.2838501930236816, acc=0.29722222685813904, loss=2.2838501930236816
train: epoch 15, loss 0.7141777276992798, acc=0.7180555462837219, loss=0.7141777276992798
test: epoch 15, loss 1.7465159893035889, acc=0.3638888895511627, loss=1.7465159893035889
train: epoch 16, loss 0.6974607110023499, acc=0.7239444255828857, loss=0.6974607110023499
test: epoch 16, loss 1.7755277156829834, acc=0.32777777314186096, loss=1.7755277156829834
train: epoch 17, loss 0.7108480930328369, acc=0.7174999713897705, loss=0.7108480930328369
test: epoch 17, loss 1.7120118141174316, acc=0.33888888359069824, loss=1.7120118141174316
train: epoch 18, loss 0.6724307537078857, acc=0.7317222356796265, loss=0.6724307537078857
test: epoch 18, loss 1.8753740787506104, acc=0.38055557012557983, loss=1.8753740787506104
train: epoch 19, loss 0.6395629048347473, acc=0.7480000257492065, loss=0.6395629048347473
test: epoch 19, loss 2.205517530441284, acc=0.3583333194255829, loss=2.205517530441284
train: epoch 20, loss 0.6335460543632507, acc=0.7448333501815796, loss=0.6335460543632507
test: epoch 20, loss 1.8962786197662354, acc=0.3611111044883728, loss=1.8962786197662354
train: epoch 21, loss 0.5862411856651306, acc=0.7685555815696716, loss=0.5862411856651306
test: epoch 21, loss 3.111544609069824, acc=0.23333333432674408, loss=3.111544609069824
train: epoch 22, loss 0.6083251237869263, acc=0.7547777891159058, loss=0.6083251237869263
test: epoch 22, loss 1.9974501132965088, acc=0.4027777910232544, loss=1.9974501132965088
train: epoch 23, loss 0.5785227417945862, acc=0.7700555324554443, loss=0.5785227417945862
test: epoch 23, loss 2.55336856842041, acc=0.27222222089767456, loss=2.55336856842041
train: epoch 24, loss 0.5629633069038391, acc=0.7759444713592529, loss=0.5629633069038391
test: epoch 24, loss 2.2222087383270264, acc=0.3472222089767456, loss=2.2222087383270264
train: epoch 25, loss 0.5586662292480469, acc=0.7779444456100464, loss=0.5586662292480469
test: epoch 25, loss 2.1553707122802734, acc=0.32777777314186096, loss=2.1553707122802734
train: epoch 26, loss 0.5207902789115906, acc=0.7906110882759094, loss=0.5207902789115906
test: epoch 26, loss 1.832669973373413, acc=0.3027777671813965, loss=1.832669973373413
train: epoch 27, loss 0.5313253998756409, acc=0.788611114025116, loss=0.5313253998756409
test: epoch 27, loss 1.9149775505065918, acc=0.28333333134651184, loss=1.9149775505065918
train: epoch 28, loss 0.5152363777160645, acc=0.7960000038146973, loss=0.5152363777160645
test: epoch 28, loss 1.6907339096069336, acc=0.31111112236976624, loss=1.6907339096069336
train: epoch 29, loss 0.505966067314148, acc=0.7962222099304199, loss=0.505966067314148
test: epoch 29, loss 1.8001482486724854, acc=0.42222222685813904, loss=1.8001482486724854
train: epoch 30, loss 0.4836292564868927, acc=0.8062222003936768, loss=0.4836292564868927
test: epoch 30, loss 1.815101146697998, acc=0.36666667461395264, loss=1.815101146697998
train: epoch 31, loss 0.4831139147281647, acc=0.8096110820770264, loss=0.4831139147281647
test: epoch 31, loss 2.139819622039795, acc=0.42222222685813904, loss=2.139819622039795
train: epoch 32, loss 0.47278034687042236, acc=0.8127777576446533, loss=0.47278034687042236
test: epoch 32, loss 1.5835320949554443, acc=0.5222222208976746, loss=1.5835320949554443
train: epoch 33, loss 0.47828856110572815, acc=0.8107222318649292, loss=0.47828856110572815
test: epoch 33, loss 1.7088749408721924, acc=0.39444443583488464, loss=1.7088749408721924
train: epoch 34, loss 0.43854084610939026, acc=0.824833333492279, loss=0.43854084610939026
test: epoch 34, loss 1.6941070556640625, acc=0.4138889014720917, loss=1.6941070556640625
train: epoch 35, loss 0.44950565695762634, acc=0.8247777819633484, loss=0.44950565695762634
test: epoch 35, loss 1.4445065259933472, acc=0.45277777314186096, loss=1.4445065259933472
train: epoch 36, loss 0.4384957551956177, acc=0.8286111354827881, loss=0.4384957551956177
test: epoch 36, loss 1.695871353149414, acc=0.4000000059604645, loss=1.695871353149414
train: epoch 37, loss 0.4326506555080414, acc=0.8298333287239075, loss=0.4326506555080414
test: epoch 37, loss 1.9839576482772827, acc=0.4027777910232544, loss=1.9839576482772827
train: epoch 38, loss 0.42696040868759155, acc=0.8312777876853943, loss=0.42696040868759155
test: epoch 38, loss 1.6103509664535522, acc=0.42500001192092896, loss=1.6103509664535522
train: epoch 39, loss 0.43272581696510315, acc=0.8303889036178589, loss=0.43272581696510315
test: epoch 39, loss 1.7910994291305542, acc=0.4444444477558136, loss=1.7910994291305542
train: epoch 40, loss 0.4026569426059723, acc=0.8463333249092102, loss=0.4026569426059723
test: epoch 40, loss 1.3969529867172241, acc=0.45277777314186096, loss=1.3969529867172241
train: epoch 41, loss 0.3810693919658661, acc=0.8533889055252075, loss=0.3810693919658661
test: epoch 41, loss 1.4411346912384033, acc=0.4833333194255829, loss=1.4411346912384033
train: epoch 42, loss 0.3951750695705414, acc=0.8463333249092102, loss=0.3951750695705414
test: epoch 42, loss 1.7489005327224731, acc=0.42222222685813904, loss=1.7489005327224731
train: epoch 43, loss 0.3909875750541687, acc=0.8455555438995361, loss=0.3909875750541687
test: epoch 43, loss 1.4669493436813354, acc=0.3722222149372101, loss=1.4669493436813354
train: epoch 44, loss 0.3857027590274811, acc=0.8505555391311646, loss=0.3857027590274811
test: epoch 44, loss 2.1525180339813232, acc=0.32777777314186096, loss=2.1525180339813232
train: epoch 45, loss 0.37063243985176086, acc=0.8575555682182312, loss=0.37063243985176086
test: epoch 45, loss 1.6744046211242676, acc=0.49444442987442017, loss=1.6744046211242676
train: epoch 46, loss 0.3672424554824829, acc=0.859333336353302, loss=0.3672424554824829
test: epoch 46, loss 1.366847038269043, acc=0.5361111164093018, loss=1.366847038269043
train: epoch 47, loss 0.37943828105926514, acc=0.850777804851532, loss=0.37943828105926514
test: epoch 47, loss 1.5080645084381104, acc=0.4305555522441864, loss=1.5080645084381104
train: epoch 48, loss 0.33498987555503845, acc=0.8715000152587891, loss=0.33498987555503845
test: epoch 48, loss 1.8022946119308472, acc=0.4555555582046509, loss=1.8022946119308472
train: epoch 49, loss 0.3677968680858612, acc=0.8560000061988831, loss=0.3677968680858612
test: epoch 49, loss 1.8533741235733032, acc=0.4583333432674408, loss=1.8533741235733032
train: epoch 50, loss 0.37865686416625977, acc=0.8503333330154419, loss=0.37865686416625977
test: epoch 50, loss 1.5341342687606812, acc=0.4333333373069763, loss=1.5341342687606812
train: epoch 51, loss 0.32276836037635803, acc=0.8742222189903259, loss=0.32276836037635803
test: epoch 51, loss 1.4002081155776978, acc=0.4583333432674408, loss=1.4002081155776978
train: epoch 52, loss 0.33969831466674805, acc=0.871222198009491, loss=0.33969831466674805
test: epoch 52, loss 1.4419907331466675, acc=0.4888888895511627, loss=1.4419907331466675
train: epoch 53, loss 0.3241729140281677, acc=0.8731111288070679, loss=0.3241729140281677
test: epoch 53, loss 2.0700318813323975, acc=0.49166667461395264, loss=2.0700318813323975
train: epoch 54, loss 0.3327474594116211, acc=0.8719444274902344, loss=0.3327474594116211
test: epoch 54, loss 1.6960194110870361, acc=0.38333332538604736, loss=1.6960194110870361
train: epoch 55, loss 0.3381589353084564, acc=0.8683333396911621, loss=0.3381589353084564
test: epoch 55, loss 1.7249497175216675, acc=0.49166667461395264, loss=1.7249497175216675
train: epoch 56, loss 0.32391101121902466, acc=0.8748888969421387, loss=0.32391101121902466
test: epoch 56, loss 1.5907070636749268, acc=0.42222222685813904, loss=1.5907070636749268
train: epoch 57, loss 0.31689202785491943, acc=0.8768888711929321, loss=0.31689202785491943
test: epoch 57, loss 1.5466725826263428, acc=0.42222222685813904, loss=1.5466725826263428
train: epoch 58, loss 0.3083183765411377, acc=0.8818333148956299, loss=0.3083183765411377
test: epoch 58, loss 1.4613687992095947, acc=0.49444442987442017, loss=1.4613687992095947
train: epoch 59, loss 0.3344913423061371, acc=0.870722234249115, loss=0.3344913423061371
test: epoch 59, loss 1.5165385007858276, acc=0.4027777910232544, loss=1.5165385007858276
train: epoch 60, loss 0.29429733753204346, acc=0.8886666893959045, loss=0.29429733753204346
test: epoch 60, loss 1.6499260663986206, acc=0.4194444417953491, loss=1.6499260663986206
train: epoch 61, loss 0.2980537414550781, acc=0.8842222094535828, loss=0.2980537414550781
test: epoch 61, loss 1.606481671333313, acc=0.4972222149372101, loss=1.606481671333313
train: epoch 62, loss 0.2815178334712982, acc=0.8930000066757202, loss=0.2815178334712982
test: epoch 62, loss 1.6678276062011719, acc=0.4833333194255829, loss=1.6678276062011719
train: epoch 63, loss 0.289798378944397, acc=0.8918333053588867, loss=0.289798378944397
test: epoch 63, loss 1.7090798616409302, acc=0.4833333194255829, loss=1.7090798616409302
train: epoch 64, loss 0.2831524908542633, acc=0.8939444422721863, loss=0.2831524908542633
test: epoch 64, loss 1.5077606439590454, acc=0.550000011920929, loss=1.5077606439590454
train: epoch 65, loss 0.27083295583724976, acc=0.8989999890327454, loss=0.27083295583724976
test: epoch 65, loss 1.5319929122924805, acc=0.5027777552604675, loss=1.5319929122924805
train: epoch 66, loss 0.2808604836463928, acc=0.8949999809265137, loss=0.2808604836463928
test: epoch 66, loss 1.535577416419983, acc=0.43888887763023376, loss=1.535577416419983
train: epoch 67, loss 0.27243003249168396, acc=0.8974444270133972, loss=0.27243003249168396
test: epoch 67, loss 1.753717064857483, acc=0.5166666507720947, loss=1.753717064857483
train: epoch 68, loss 0.26762470602989197, acc=0.9001666903495789, loss=0.26762470602989197
test: epoch 68, loss 1.623587727546692, acc=0.4833333194255829, loss=1.623587727546692
train: epoch 69, loss 0.2952839136123657, acc=0.8901666402816772, loss=0.2952839136123657
test: epoch 69, loss 1.8832753896713257, acc=0.4888888895511627, loss=1.8832753896713257
train: epoch 70, loss 0.28833529353141785, acc=0.8897777795791626, loss=0.28833529353141785
test: epoch 70, loss 1.359811782836914, acc=0.6166666746139526, loss=1.359811782836914
train: epoch 71, loss 0.25135567784309387, acc=0.9093888998031616, loss=0.25135567784309387
test: epoch 71, loss 1.6779229640960693, acc=0.4972222149372101, loss=1.6779229640960693
train: epoch 72, loss 0.24237971007823944, acc=0.9093888998031616, loss=0.24237971007823944
test: epoch 72, loss 1.4019749164581299, acc=0.48055556416511536, loss=1.4019749164581299
train: epoch 73, loss 0.23261983692646027, acc=0.9130555391311646, loss=0.23261983692646027
test: epoch 73, loss 1.5639058351516724, acc=0.4694444537162781, loss=1.5639058351516724
train: epoch 74, loss 0.2811073660850525, acc=0.8920000195503235, loss=0.2811073660850525
test: epoch 74, loss 1.87832510471344, acc=0.5305555462837219, loss=1.87832510471344
train: epoch 75, loss 0.2338436245918274, acc=0.9110555648803711, loss=0.2338436245918274
test: epoch 75, loss 1.9670823812484741, acc=0.49444442987442017, loss=1.9670823812484741
train: epoch 76, loss 0.26515501737594604, acc=0.9018333554267883, loss=0.26515501737594604
test: epoch 76, loss 1.6148251295089722, acc=0.46388888359069824, loss=1.6148251295089722
train: epoch 77, loss 0.24648010730743408, acc=0.9085555672645569, loss=0.24648010730743408
test: epoch 77, loss 1.3040366172790527, acc=0.5722222328186035, loss=1.3040366172790527
train: epoch 78, loss 0.24001005291938782, acc=0.9112777709960938, loss=0.24001005291938782
test: epoch 78, loss 1.5516225099563599, acc=0.5361111164093018, loss=1.5516225099563599
train: epoch 79, loss 0.21899166703224182, acc=0.9187777638435364, loss=0.21899166703224182
test: epoch 79, loss 1.3059446811676025, acc=0.5583333373069763, loss=1.3059446811676025
train: epoch 80, loss 0.261105477809906, acc=0.9041666388511658, loss=0.261105477809906
test: epoch 80, loss 1.4325544834136963, acc=0.5722222328186035, loss=1.4325544834136963
train: epoch 81, loss 0.23670564591884613, acc=0.9123888611793518, loss=0.23670564591884613
test: epoch 81, loss 1.6502628326416016, acc=0.5027777552604675, loss=1.6502628326416016
train: epoch 82, loss 0.23245887458324432, acc=0.9152222275733948, loss=0.23245887458324432
test: epoch 82, loss 2.0028300285339355, acc=0.5083333253860474, loss=2.0028300285339355
train: epoch 83, loss 0.2394677847623825, acc=0.9135555624961853, loss=0.2394677847623825
test: epoch 83, loss 1.7699124813079834, acc=0.43888887763023376, loss=1.7699124813079834
train: epoch 84, loss 0.2365894764661789, acc=0.9133889079093933, loss=0.2365894764661789
test: epoch 84, loss 1.68201744556427, acc=0.5277777910232544, loss=1.68201744556427
train: epoch 85, loss 0.21594923734664917, acc=0.9206666946411133, loss=0.21594923734664917
test: epoch 85, loss 1.5842466354370117, acc=0.48055556416511536, loss=1.5842466354370117
train: epoch 86, loss 0.23209090530872345, acc=0.9141111373901367, loss=0.23209090530872345
test: epoch 86, loss 1.8150849342346191, acc=0.4833333194255829, loss=1.8150849342346191
train: epoch 87, loss 0.23916062712669373, acc=0.9125555753707886, loss=0.23916062712669373
test: epoch 87, loss 1.6693865060806274, acc=0.4749999940395355, loss=1.6693865060806274
train: epoch 88, loss 0.24379314482212067, acc=0.9127777814865112, loss=0.24379314482212067
test: epoch 88, loss 1.3800524473190308, acc=0.5388888716697693, loss=1.3800524473190308
train: epoch 89, loss 0.2257704734802246, acc=0.917888879776001, loss=0.2257704734802246
test: epoch 89, loss 1.1471459865570068, acc=0.5861111283302307, loss=1.1471459865570068
train: epoch 90, loss 0.2039656788110733, acc=0.9267222285270691, loss=0.2039656788110733
test: epoch 90, loss 1.6538434028625488, acc=0.5249999761581421, loss=1.6538434028625488
train: epoch 91, loss 0.22356662154197693, acc=0.9179444313049316, loss=0.22356662154197693
test: epoch 91, loss 1.8541053533554077, acc=0.5833333134651184, loss=1.8541053533554077
train: epoch 92, loss 0.21756334602832794, acc=0.922166645526886, loss=0.21756334602832794
test: epoch 92, loss 1.5288006067276, acc=0.5527777671813965, loss=1.5288006067276
train: epoch 93, loss 0.2204238474369049, acc=0.9192777872085571, loss=0.2204238474369049
test: epoch 93, loss 1.2296608686447144, acc=0.5916666388511658, loss=1.2296608686447144
train: epoch 94, loss 0.20717543363571167, acc=0.925000011920929, loss=0.20717543363571167
test: epoch 94, loss 1.532418131828308, acc=0.5361111164093018, loss=1.532418131828308
train: epoch 95, loss 0.2072451114654541, acc=0.9221110939979553, loss=0.2072451114654541
test: epoch 95, loss 1.5064412355422974, acc=0.5361111164093018, loss=1.5064412355422974
train: epoch 96, loss 0.2364659458398819, acc=0.9138888716697693, loss=0.2364659458398819
test: epoch 96, loss 1.3990434408187866, acc=0.644444465637207, loss=1.3990434408187866
train: epoch 97, loss 0.20927314460277557, acc=0.9224444627761841, loss=0.20927314460277557
test: epoch 97, loss 1.372079610824585, acc=0.5805555582046509, loss=1.372079610824585
train: epoch 98, loss 0.21834959089756012, acc=0.9195555448532104, loss=0.21834959089756012
test: epoch 98, loss 1.496881127357483, acc=0.5694444179534912, loss=1.496881127357483
train: epoch 99, loss 0.2243143767118454, acc=0.9165555834770203, loss=0.2243143767118454
test: epoch 99, loss 1.5611416101455688, acc=0.4888888895511627, loss=1.5611416101455688
train: epoch 100, loss 0.20228131115436554, acc=0.9254444241523743, loss=0.20228131115436554
test: epoch 100, loss 1.6075304746627808, acc=0.4861111044883728, loss=1.6075304746627808
train: epoch 101, loss 0.19554632902145386, acc=0.9293888807296753, loss=0.19554632902145386
test: epoch 101, loss 1.4212278127670288, acc=0.5888888835906982, loss=1.4212278127670288
train: epoch 102, loss 0.21021582186222076, acc=0.9233888983726501, loss=0.21021582186222076
test: epoch 102, loss 1.2157536745071411, acc=0.6000000238418579, loss=1.2157536745071411
train: epoch 103, loss 0.1981181800365448, acc=0.9268888831138611, loss=0.1981181800365448
test: epoch 103, loss 1.5703436136245728, acc=0.5472221970558167, loss=1.5703436136245728
train: epoch 104, loss 0.1964827924966812, acc=0.9292222261428833, loss=0.1964827924966812
test: epoch 104, loss 1.3004150390625, acc=0.5944444537162781, loss=1.3004150390625
train: epoch 105, loss 0.2532047629356384, acc=0.9094444513320923, loss=0.2532047629356384
test: epoch 105, loss 1.8855794668197632, acc=0.5777778029441833, loss=1.8855794668197632
train: epoch 106, loss 0.19205860793590546, acc=0.9284444451332092, loss=0.19205860793590546
test: epoch 106, loss 1.2997089624404907, acc=0.6222222447395325, loss=1.2997089624404907
train: epoch 107, loss 0.19698785245418549, acc=0.9290555715560913, loss=0.19698785245418549
test: epoch 107, loss 1.293101191520691, acc=0.6305555701255798, loss=1.293101191520691
train: epoch 108, loss 0.2035156637430191, acc=0.9235555529594421, loss=0.2035156637430191
test: epoch 108, loss 1.6722848415374756, acc=0.5861111283302307, loss=1.6722848415374756
train: epoch 109, loss 0.19728581607341766, acc=0.9274444580078125, loss=0.19728581607341766
test: epoch 109, loss 1.5690020322799683, acc=0.5527777671813965, loss=1.5690020322799683
train: epoch 110, loss 0.1756201684474945, acc=0.9339444637298584, loss=0.1756201684474945
test: epoch 110, loss 1.5954636335372925, acc=0.6333333253860474, loss=1.5954636335372925
train: epoch 111, loss 0.19365502893924713, acc=0.9312222003936768, loss=0.19365502893924713
test: epoch 111, loss 1.5033818483352661, acc=0.5083333253860474, loss=1.5033818483352661
train: epoch 112, loss 0.1861279010772705, acc=0.9312222003936768, loss=0.1861279010772705
test: epoch 112, loss 1.2790663242340088, acc=0.6499999761581421, loss=1.2790663242340088
train: epoch 113, loss 0.21591782569885254, acc=0.9206666946411133, loss=0.21591782569885254
test: epoch 113, loss 1.5142693519592285, acc=0.5777778029441833, loss=1.5142693519592285
train: epoch 114, loss 0.19337975978851318, acc=0.9283888936042786, loss=0.19337975978851318
test: epoch 114, loss 1.4098641872406006, acc=0.605555534362793, loss=1.4098641872406006
train: epoch 115, loss 0.24245566129684448, acc=0.913444459438324, loss=0.24245566129684448
test: epoch 115, loss 1.4040933847427368, acc=0.5944444537162781, loss=1.4040933847427368
train: epoch 116, loss 0.21404173970222473, acc=0.921833336353302, loss=0.21404173970222473
test: epoch 116, loss 1.1232240200042725, acc=0.5861111283302307, loss=1.1232240200042725
train: epoch 117, loss 0.20909510552883148, acc=0.9236666560173035, loss=0.20909510552883148
test: epoch 117, loss 1.472510814666748, acc=0.5361111164093018, loss=1.472510814666748
train: epoch 118, loss 0.1704464852809906, acc=0.9370555281639099, loss=0.1704464852809906
test: epoch 118, loss 1.163928508758545, acc=0.6361111402511597, loss=1.163928508758545
train: epoch 119, loss 0.2032800316810608, acc=0.9266666769981384, loss=0.2032800316810608
test: epoch 119, loss 1.4478923082351685, acc=0.5555555820465088, loss=1.4478923082351685
train: epoch 120, loss 0.19495166838169098, acc=0.9268888831138611, loss=0.19495166838169098
test: epoch 120, loss 1.5294071435928345, acc=0.5638889074325562, loss=1.5294071435928345
train: epoch 121, loss 0.19372200965881348, acc=0.9313889145851135, loss=0.19372200965881348
test: epoch 121, loss 1.2347090244293213, acc=0.5972222089767456, loss=1.2347090244293213
train: epoch 122, loss 0.19686754047870636, acc=0.9266111254692078, loss=0.19686754047870636
test: epoch 122, loss 1.8595900535583496, acc=0.5416666865348816, loss=1.8595900535583496
train: epoch 123, loss 0.1781720668077469, acc=0.933722198009491, loss=0.1781720668077469
test: epoch 123, loss 1.5127286911010742, acc=0.574999988079071, loss=1.5127286911010742
train: epoch 124, loss 0.1832364797592163, acc=0.9317777752876282, loss=0.1832364797592163
test: epoch 124, loss 1.5246951580047607, acc=0.5833333134651184, loss=1.5246951580047607
train: epoch 125, loss 0.19382327795028687, acc=0.9286666512489319, loss=0.19382327795028687
test: epoch 125, loss 2.0511960983276367, acc=0.5388888716697693, loss=2.0511960983276367
train: epoch 126, loss 0.18005788326263428, acc=0.9341111183166504, loss=0.18005788326263428
test: epoch 126, loss 2.1645865440368652, acc=0.46388888359069824, loss=2.1645865440368652
train: epoch 127, loss 0.17499704658985138, acc=0.937166690826416, loss=0.17499704658985138
test: epoch 127, loss 1.4604848623275757, acc=0.5249999761581421, loss=1.4604848623275757
train: epoch 128, loss 0.19722771644592285, acc=0.9291666746139526, loss=0.19722771644592285
test: epoch 128, loss 1.404938817024231, acc=0.5305555462837219, loss=1.404938817024231
train: epoch 129, loss 0.1856251060962677, acc=0.9308888912200928, loss=0.1856251060962677
test: epoch 129, loss 1.530038833618164, acc=0.5138888955116272, loss=1.530038833618164
train: epoch 130, loss 0.17549118399620056, acc=0.9367222189903259, loss=0.17549118399620056
test: epoch 130, loss 1.0534344911575317, acc=0.699999988079071, loss=1.0534344911575317
train: epoch 131, loss 0.19391568005084991, acc=0.9294999837875366, loss=0.19391568005084991
test: epoch 131, loss 1.1917273998260498, acc=0.6583333611488342, loss=1.1917273998260498
train: epoch 132, loss 0.20166409015655518, acc=0.925166666507721, loss=0.20166409015655518
test: epoch 132, loss 0.9975964426994324, acc=0.6388888955116272, loss=0.9975964426994324
train: epoch 133, loss 0.1793566346168518, acc=0.9332777857780457, loss=0.1793566346168518
test: epoch 133, loss 1.2825076580047607, acc=0.6361111402511597, loss=1.2825076580047607
train: epoch 134, loss 0.1827930361032486, acc=0.9311666488647461, loss=0.1827930361032486
test: epoch 134, loss 1.9590750932693481, acc=0.4694444537162781, loss=1.9590750932693481
train: epoch 135, loss 0.20011301338672638, acc=0.9256666898727417, loss=0.20011301338672638
test: epoch 135, loss 1.8219242095947266, acc=0.5805555582046509, loss=1.8219242095947266
train: epoch 136, loss 0.1929846704006195, acc=0.9307222366333008, loss=0.1929846704006195
test: epoch 136, loss 1.2580852508544922, acc=0.6166666746139526, loss=1.2580852508544922
train: epoch 137, loss 0.19092108309268951, acc=0.9287777543067932, loss=0.19092108309268951
test: epoch 137, loss 1.3852812051773071, acc=0.5138888955116272, loss=1.3852812051773071
train: epoch 138, loss 0.1717941164970398, acc=0.9347777962684631, loss=0.1717941164970398
test: epoch 138, loss 1.4433653354644775, acc=0.49166667461395264, loss=1.4433653354644775
train: epoch 139, loss 0.16598552465438843, acc=0.9394999742507935, loss=0.16598552465438843
test: epoch 139, loss 1.5113821029663086, acc=0.5583333373069763, loss=1.5113821029663086
train: epoch 140, loss 0.19125372171401978, acc=0.9319999814033508, loss=0.19125372171401978
test: epoch 140, loss 1.1884939670562744, acc=0.6083333492279053, loss=1.1884939670562744
train: epoch 141, loss 0.16881057620048523, acc=0.9396111369132996, loss=0.16881057620048523
test: epoch 141, loss 1.3921711444854736, acc=0.6083333492279053, loss=1.3921711444854736
train: epoch 142, loss 0.16415511071681976, acc=0.9399999976158142, loss=0.16415511071681976
test: epoch 142, loss 1.1462446451187134, acc=0.6277777552604675, loss=1.1462446451187134
train: epoch 143, loss 0.18002131581306458, acc=0.9355555772781372, loss=0.18002131581306458
test: epoch 143, loss 2.1377201080322266, acc=0.5277777910232544, loss=2.1377201080322266
train: epoch 144, loss 0.18675100803375244, acc=0.9306666851043701, loss=0.18675100803375244
test: epoch 144, loss 1.340135931968689, acc=0.5444444417953491, loss=1.340135931968689
train: epoch 145, loss 0.15781565010547638, acc=0.941277801990509, loss=0.15781565010547638
test: epoch 145, loss 1.5116347074508667, acc=0.5833333134651184, loss=1.5116347074508667
train: epoch 146, loss 0.1985122710466385, acc=0.9278888702392578, loss=0.1985122710466385
test: epoch 146, loss 1.5825324058532715, acc=0.6000000238418579, loss=1.5825324058532715
train: epoch 147, loss 0.15923048555850983, acc=0.941944420337677, loss=0.15923048555850983
test: epoch 147, loss 1.524752140045166, acc=0.5638889074325562, loss=1.524752140045166
train: epoch 148, loss 0.17779308557510376, acc=0.933222234249115, loss=0.17779308557510376
test: epoch 148, loss 1.539700984954834, acc=0.5888888835906982, loss=1.539700984954834
train: epoch 149, loss 0.1590309590101242, acc=0.9423333406448364, loss=0.1590309590101242
test: epoch 149, loss 1.645686388015747, acc=0.5777778029441833, loss=1.645686388015747
train: epoch 150, loss 0.19011858105659485, acc=0.9320555329322815, loss=0.19011858105659485
test: epoch 150, loss 1.6670535802841187, acc=0.5527777671813965, loss=1.6670535802841187
