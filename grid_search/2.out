# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=1", "--temp_decay=1", "--one_hot=0", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=485635420, receiver_embed_dim=32, save_run=0, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=485635420, receiver_embed_dim=32, save_run=False, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.9034507274627686, acc=0.09622222185134888, loss=2.9034507274627686
test: epoch 1, loss 4.302044868469238, acc=0.05000000074505806, loss=4.302044868469238
train: epoch 2, loss 2.2877390384674072, acc=0.18199999630451202, loss=2.2877390384674072
test: epoch 2, loss 3.402556896209717, acc=0.11944444477558136, loss=3.402556896209717
train: epoch 3, loss 2.0176467895507812, acc=0.23216666281223297, loss=2.0176467895507812
test: epoch 3, loss 2.459937572479248, acc=0.1805555522441864, loss=2.459937572479248
train: epoch 4, loss 1.886795997619629, acc=0.2671666741371155, loss=1.886795997619629
test: epoch 4, loss 2.6785106658935547, acc=0.1527777761220932, loss=2.6785106658935547
train: epoch 5, loss 1.740992784500122, acc=0.3135555684566498, loss=1.740992784500122
test: epoch 5, loss 2.2934305667877197, acc=0.23055554926395416, loss=2.2934305667877197
train: epoch 6, loss 1.6522566080093384, acc=0.34377777576446533, loss=1.6522566080093384
test: epoch 6, loss 2.2943944931030273, acc=0.1944444477558136, loss=2.2943944931030273
train: epoch 7, loss 1.5799704790115356, acc=0.3617222309112549, loss=1.5799704790115356
test: epoch 7, loss 2.4242630004882812, acc=0.18611110746860504, loss=2.4242630004882812
train: epoch 8, loss 1.5100711584091187, acc=0.390666663646698, loss=1.5100711584091187
test: epoch 8, loss 2.094426155090332, acc=0.20277777314186096, loss=2.094426155090332
train: epoch 9, loss 1.4617536067962646, acc=0.41038888692855835, loss=1.4617536067962646
test: epoch 9, loss 2.0505311489105225, acc=0.2361111044883728, loss=2.0505311489105225
train: epoch 10, loss 1.3966188430786133, acc=0.42927777767181396, loss=1.3966188430786133
test: epoch 10, loss 2.0882937908172607, acc=0.23055554926395416, loss=2.0882937908172607
train: epoch 11, loss 1.3727049827575684, acc=0.44083333015441895, loss=1.3727049827575684
test: epoch 11, loss 1.8030403852462769, acc=0.2527777850627899, loss=1.8030403852462769
train: epoch 12, loss 1.3281689882278442, acc=0.4603888988494873, loss=1.3281689882278442
test: epoch 12, loss 2.0196826457977295, acc=0.2527777850627899, loss=2.0196826457977295
train: epoch 13, loss 1.2747529745101929, acc=0.4754444360733032, loss=1.2747529745101929
test: epoch 13, loss 1.7093513011932373, acc=0.3083333373069763, loss=1.7093513011932373
train: epoch 14, loss 1.2455905675888062, acc=0.49005556106567383, loss=1.2455905675888062
test: epoch 14, loss 1.7760988473892212, acc=0.28333333134651184, loss=1.7760988473892212
train: epoch 15, loss 1.1925817728042603, acc=0.5061666369438171, loss=1.1925817728042603
test: epoch 15, loss 1.7010996341705322, acc=0.31388887763023376, loss=1.7010996341705322
train: epoch 16, loss 1.1808326244354248, acc=0.5200555324554443, loss=1.1808326244354248
test: epoch 16, loss 1.7947676181793213, acc=0.3027777671813965, loss=1.7947676181793213
train: epoch 17, loss 1.1451525688171387, acc=0.5336111187934875, loss=1.1451525688171387
test: epoch 17, loss 1.58718740940094, acc=0.3361110985279083, loss=1.58718740940094
train: epoch 18, loss 1.1136220693588257, acc=0.5437777638435364, loss=1.1136220693588257
test: epoch 18, loss 1.6648085117340088, acc=0.3027777671813965, loss=1.6648085117340088
train: epoch 19, loss 1.093431830406189, acc=0.5476111173629761, loss=1.093431830406189
test: epoch 19, loss 1.7591452598571777, acc=0.30000001192092896, loss=1.7591452598571777
train: epoch 20, loss 1.071596384048462, acc=0.5630000233650208, loss=1.071596384048462
test: epoch 20, loss 1.6790601015090942, acc=0.31388887763023376, loss=1.6790601015090942
train: epoch 21, loss 1.0539970397949219, acc=0.5657222270965576, loss=1.0539970397949219
test: epoch 21, loss 1.6155192852020264, acc=0.35555556416511536, loss=1.6155192852020264
train: epoch 22, loss 1.0201420783996582, acc=0.5776666402816772, loss=1.0201420783996582
test: epoch 22, loss 1.5930676460266113, acc=0.33888888359069824, loss=1.5930676460266113
train: epoch 23, loss 1.0031884908676147, acc=0.5861666798591614, loss=1.0031884908676147
test: epoch 23, loss 1.6525111198425293, acc=0.3499999940395355, loss=1.6525111198425293
train: epoch 24, loss 0.9933080673217773, acc=0.5887222290039062, loss=0.9933080673217773
test: epoch 24, loss 1.9224677085876465, acc=0.3083333373069763, loss=1.9224677085876465
train: epoch 25, loss 0.9784284830093384, acc=0.5970555543899536, loss=0.9784284830093384
test: epoch 25, loss 1.5027039051055908, acc=0.3638888895511627, loss=1.5027039051055908
train: epoch 26, loss 0.9762920141220093, acc=0.6033889055252075, loss=0.9762920141220093
test: epoch 26, loss 1.7055515050888062, acc=0.2888889014720917, loss=1.7055515050888062
train: epoch 27, loss 0.9515001773834229, acc=0.6101111173629761, loss=0.9515001773834229
test: epoch 27, loss 1.6775914430618286, acc=0.35555556416511536, loss=1.6775914430618286
train: epoch 28, loss 0.9271087646484375, acc=0.6221666932106018, loss=0.9271087646484375
test: epoch 28, loss 1.6455363035202026, acc=0.4055555462837219, loss=1.6455363035202026
train: epoch 29, loss 0.9225970506668091, acc=0.6224444508552551, loss=0.9225970506668091
test: epoch 29, loss 1.6949100494384766, acc=0.38055557012557983, loss=1.6949100494384766
train: epoch 30, loss 0.9289340376853943, acc=0.6193888783454895, loss=0.9289340376853943
test: epoch 30, loss 1.7558380365371704, acc=0.32499998807907104, loss=1.7558380365371704
train: epoch 31, loss 0.8911494016647339, acc=0.6402778029441833, loss=0.8911494016647339
test: epoch 31, loss 1.8781627416610718, acc=0.3611111044883728, loss=1.8781627416610718
train: epoch 32, loss 0.9223394393920898, acc=0.6201111078262329, loss=0.9223394393920898
test: epoch 32, loss 1.5247986316680908, acc=0.3777777850627899, loss=1.5247986316680908
train: epoch 33, loss 0.8861628770828247, acc=0.6396111249923706, loss=0.8861628770828247
test: epoch 33, loss 1.5885454416275024, acc=0.32777777314186096, loss=1.5885454416275024
train: epoch 34, loss 0.8871457576751709, acc=0.6392222046852112, loss=0.8871457576751709
test: epoch 34, loss 1.4881490468978882, acc=0.43611112236976624, loss=1.4881490468978882
train: epoch 35, loss 0.8939812779426575, acc=0.6353889107704163, loss=0.8939812779426575
test: epoch 35, loss 1.5344221591949463, acc=0.3499999940395355, loss=1.5344221591949463
train: epoch 36, loss 0.8757164478302002, acc=0.6405555605888367, loss=0.8757164478302002
test: epoch 36, loss 1.400875210762024, acc=0.3583333194255829, loss=1.400875210762024
train: epoch 37, loss 0.8583570718765259, acc=0.6558889150619507, loss=0.8583570718765259
test: epoch 37, loss 1.4143896102905273, acc=0.3722222149372101, loss=1.4143896102905273
train: epoch 38, loss 0.8655442595481873, acc=0.64811110496521, loss=0.8655442595481873
test: epoch 38, loss 1.3787879943847656, acc=0.4694444537162781, loss=1.3787879943847656
train: epoch 39, loss 0.8317091464996338, acc=0.6670555472373962, loss=0.8317091464996338
test: epoch 39, loss 1.6107035875320435, acc=0.3777777850627899, loss=1.6107035875320435
train: epoch 40, loss 0.845104455947876, acc=0.6578333377838135, loss=0.845104455947876
test: epoch 40, loss 1.3719065189361572, acc=0.42222222685813904, loss=1.3719065189361572
train: epoch 41, loss 0.8161495923995972, acc=0.6741666793823242, loss=0.8161495923995972
test: epoch 41, loss 1.3724561929702759, acc=0.4166666567325592, loss=1.3724561929702759
train: epoch 42, loss 0.8037272691726685, acc=0.6736111044883728, loss=0.8037272691726685
test: epoch 42, loss 1.401099681854248, acc=0.4194444417953491, loss=1.401099681854248
train: epoch 43, loss 0.8042906522750854, acc=0.6792222261428833, loss=0.8042906522750854
test: epoch 43, loss 1.7042911052703857, acc=0.3305555582046509, loss=1.7042911052703857
train: epoch 44, loss 0.8086085915565491, acc=0.6768333315849304, loss=0.8086085915565491
test: epoch 44, loss 1.5026469230651855, acc=0.46388888359069824, loss=1.5026469230651855
train: epoch 45, loss 0.8125770688056946, acc=0.6787222027778625, loss=0.8125770688056946
test: epoch 45, loss 1.7304457426071167, acc=0.35277777910232544, loss=1.7304457426071167
train: epoch 46, loss 0.77522873878479, acc=0.6923333406448364, loss=0.77522873878479
test: epoch 46, loss 1.4901069402694702, acc=0.3611111044883728, loss=1.4901069402694702
train: epoch 47, loss 0.7766458988189697, acc=0.6910555362701416, loss=0.7766458988189697
test: epoch 47, loss 1.6955924034118652, acc=0.4333333373069763, loss=1.6955924034118652
train: epoch 48, loss 0.7842603325843811, acc=0.6872222423553467, loss=0.7842603325843811
test: epoch 48, loss 1.5433939695358276, acc=0.43611112236976624, loss=1.5433939695358276
train: epoch 49, loss 0.7729014158248901, acc=0.691777765750885, loss=0.7729014158248901
test: epoch 49, loss 1.6227103471755981, acc=0.3472222089767456, loss=1.6227103471755981
train: epoch 50, loss 0.7357288599014282, acc=0.7091110944747925, loss=0.7357288599014282
test: epoch 50, loss 1.4864317178726196, acc=0.39722222089767456, loss=1.4864317178726196
train: epoch 51, loss 0.7502450942993164, acc=0.7046666741371155, loss=0.7502450942993164
test: epoch 51, loss 1.6988211870193481, acc=0.3499999940395355, loss=1.6988211870193481
train: epoch 52, loss 0.7523378729820251, acc=0.7038888931274414, loss=0.7523378729820251
test: epoch 52, loss 1.4258288145065308, acc=0.3777777850627899, loss=1.4258288145065308
train: epoch 53, loss 0.7271360754966736, acc=0.7122222185134888, loss=0.7271360754966736
test: epoch 53, loss 1.5337759256362915, acc=0.36666667461395264, loss=1.5337759256362915
train: epoch 54, loss 0.717657208442688, acc=0.7181110978126526, loss=0.717657208442688
test: epoch 54, loss 1.422541618347168, acc=0.4305555522441864, loss=1.422541618347168
train: epoch 55, loss 0.7194721102714539, acc=0.7163333296775818, loss=0.7194721102714539
test: epoch 55, loss 1.4789584875106812, acc=0.42222222685813904, loss=1.4789584875106812
train: epoch 56, loss 0.7136391401290894, acc=0.7241666913032532, loss=0.7136391401290894
test: epoch 56, loss 1.650901436805725, acc=0.36944442987442017, loss=1.650901436805725
train: epoch 57, loss 0.7126663327217102, acc=0.721666693687439, loss=0.7126663327217102
test: epoch 57, loss 1.7015421390533447, acc=0.4138889014720917, loss=1.7015421390533447
train: epoch 58, loss 0.6986269354820251, acc=0.7235555648803711, loss=0.6986269354820251
test: epoch 58, loss 1.673763394355774, acc=0.4166666567325592, loss=1.673763394355774
train: epoch 59, loss 0.7018143534660339, acc=0.7233889102935791, loss=0.7018143534660339
test: epoch 59, loss 1.7166647911071777, acc=0.3777777850627899, loss=1.7166647911071777
train: epoch 60, loss 0.7107056379318237, acc=0.7246111035346985, loss=0.7107056379318237
test: epoch 60, loss 1.4725521802902222, acc=0.4305555522441864, loss=1.4725521802902222
train: epoch 61, loss 0.6806233525276184, acc=0.7357777953147888, loss=0.6806233525276184
test: epoch 61, loss 1.6220934391021729, acc=0.3611111044883728, loss=1.6220934391021729
train: epoch 62, loss 0.6745172142982483, acc=0.7340555787086487, loss=0.6745172142982483
test: epoch 62, loss 1.6035349369049072, acc=0.4194444417953491, loss=1.6035349369049072
train: epoch 63, loss 0.6926931738853455, acc=0.7294444441795349, loss=0.6926931738853455
test: epoch 63, loss 1.5640414953231812, acc=0.38055557012557983, loss=1.5640414953231812
train: epoch 64, loss 0.684563159942627, acc=0.7360000014305115, loss=0.684563159942627
test: epoch 64, loss 1.4570930004119873, acc=0.46388888359069824, loss=1.4570930004119873
train: epoch 65, loss 0.6524717807769775, acc=0.7488889098167419, loss=0.6524717807769775
test: epoch 65, loss 1.64750337600708, acc=0.3472222089767456, loss=1.64750337600708
train: epoch 66, loss 0.6817156076431274, acc=0.7329999804496765, loss=0.6817156076431274
test: epoch 66, loss 1.5561643838882446, acc=0.4555555582046509, loss=1.5561643838882446
train: epoch 67, loss 0.64951092004776, acc=0.7441666722297668, loss=0.64951092004776
test: epoch 67, loss 1.67612886428833, acc=0.4000000059604645, loss=1.67612886428833
train: epoch 68, loss 0.6653496623039246, acc=0.7372778058052063, loss=0.6653496623039246
test: epoch 68, loss 1.587250828742981, acc=0.3861111104488373, loss=1.587250828742981
train: epoch 69, loss 0.6542250514030457, acc=0.7446110844612122, loss=0.6542250514030457
test: epoch 69, loss 1.4134340286254883, acc=0.4277777671813965, loss=1.4134340286254883
train: epoch 70, loss 0.623876690864563, acc=0.7556111216545105, loss=0.623876690864563
test: epoch 70, loss 1.67922842502594, acc=0.42500001192092896, loss=1.67922842502594
train: epoch 71, loss 0.6373366713523865, acc=0.7454444169998169, loss=0.6373366713523865
test: epoch 71, loss 1.4361443519592285, acc=0.38055557012557983, loss=1.4361443519592285
train: epoch 72, loss 0.6205721497535706, acc=0.7610555291175842, loss=0.6205721497535706
test: epoch 72, loss 1.7422364950180054, acc=0.36666667461395264, loss=1.7422364950180054
train: epoch 73, loss 0.6341872811317444, acc=0.7542222142219543, loss=0.6341872811317444
test: epoch 73, loss 1.6093347072601318, acc=0.4194444417953491, loss=1.6093347072601318
train: epoch 74, loss 0.6376124024391174, acc=0.7524444460868835, loss=0.6376124024391174
test: epoch 74, loss 1.3993765115737915, acc=0.5249999761581421, loss=1.3993765115737915
train: epoch 75, loss 0.6408544778823853, acc=0.7515000104904175, loss=0.6408544778823853
test: epoch 75, loss 1.5647306442260742, acc=0.42222222685813904, loss=1.5647306442260742
train: epoch 76, loss 0.6167683601379395, acc=0.7587777972221375, loss=0.6167683601379395
test: epoch 76, loss 1.360558032989502, acc=0.4972222149372101, loss=1.360558032989502
train: epoch 77, loss 0.6302927136421204, acc=0.7547777891159058, loss=0.6302927136421204
test: epoch 77, loss 1.5162898302078247, acc=0.4027777910232544, loss=1.5162898302078247
train: epoch 78, loss 0.6252703666687012, acc=0.7548888921737671, loss=0.6252703666687012
test: epoch 78, loss 1.7014145851135254, acc=0.45277777314186096, loss=1.7014145851135254
train: epoch 79, loss 0.6360114216804504, acc=0.749666690826416, loss=0.6360114216804504
test: epoch 79, loss 1.7186211347579956, acc=0.40833333134651184, loss=1.7186211347579956
train: epoch 80, loss 0.6199804544448853, acc=0.7609444260597229, loss=0.6199804544448853
test: epoch 80, loss 1.5332504510879517, acc=0.4277777671813965, loss=1.5332504510879517
train: epoch 81, loss 0.617784321308136, acc=0.7583333253860474, loss=0.617784321308136
test: epoch 81, loss 1.6303359270095825, acc=0.4305555522441864, loss=1.6303359270095825
train: epoch 82, loss 0.6060153245925903, acc=0.7644444704055786, loss=0.6060153245925903
test: epoch 82, loss 1.5732325315475464, acc=0.4333333373069763, loss=1.5732325315475464
train: epoch 83, loss 0.6038499474525452, acc=0.7631666660308838, loss=0.6038499474525452
test: epoch 83, loss 1.4173895120620728, acc=0.45277777314186096, loss=1.4173895120620728
train: epoch 84, loss 0.6125989556312561, acc=0.7633888721466064, loss=0.6125989556312561
test: epoch 84, loss 1.4395465850830078, acc=0.4888888895511627, loss=1.4395465850830078
train: epoch 85, loss 0.6200891137123108, acc=0.7587777972221375, loss=0.6200891137123108
test: epoch 85, loss 1.3815672397613525, acc=0.4611110985279083, loss=1.3815672397613525
train: epoch 86, loss 0.5939855575561523, acc=0.7649999856948853, loss=0.5939855575561523
test: epoch 86, loss 1.599418044090271, acc=0.4833333194255829, loss=1.599418044090271
train: epoch 87, loss 0.5977661609649658, acc=0.7664999961853027, loss=0.5977661609649658
test: epoch 87, loss 1.4756029844284058, acc=0.47777777910232544, loss=1.4756029844284058
train: epoch 88, loss 0.5960202813148499, acc=0.765333354473114, loss=0.5960202813148499
test: epoch 88, loss 1.4811917543411255, acc=0.4694444537162781, loss=1.4811917543411255
train: epoch 89, loss 0.6049674153327942, acc=0.7647222280502319, loss=0.6049674153327942
test: epoch 89, loss 1.4203441143035889, acc=0.4555555582046509, loss=1.4203441143035889
train: epoch 90, loss 0.5733000040054321, acc=0.7762777805328369, loss=0.5733000040054321
test: epoch 90, loss 1.4429012537002563, acc=0.44999998807907104, loss=1.4429012537002563
train: epoch 91, loss 0.5721859335899353, acc=0.7759444713592529, loss=0.5721859335899353
test: epoch 91, loss 1.401998519897461, acc=0.44999998807907104, loss=1.401998519897461
train: epoch 92, loss 0.6053074598312378, acc=0.7646666765213013, loss=0.6053074598312378
test: epoch 92, loss 1.7528432607650757, acc=0.4055555462837219, loss=1.7528432607650757
train: epoch 93, loss 0.5867030024528503, acc=0.7678889036178589, loss=0.5867030024528503
test: epoch 93, loss 1.4986547231674194, acc=0.45277777314186096, loss=1.4986547231674194
train: epoch 94, loss 0.5659700632095337, acc=0.7789444327354431, loss=0.5659700632095337
test: epoch 94, loss 1.473386287689209, acc=0.47777777910232544, loss=1.473386287689209
train: epoch 95, loss 0.5661324262619019, acc=0.7762777805328369, loss=0.5661324262619019
test: epoch 95, loss 1.3861340284347534, acc=0.5722222328186035, loss=1.3861340284347534
train: epoch 96, loss 0.5726448893547058, acc=0.7760000228881836, loss=0.5726448893547058
test: epoch 96, loss 1.6334246397018433, acc=0.49444442987442017, loss=1.6334246397018433
train: epoch 97, loss 0.5577507019042969, acc=0.7807777523994446, loss=0.5577507019042969
test: epoch 97, loss 1.3861128091812134, acc=0.5416666865348816, loss=1.3861128091812134
train: epoch 98, loss 0.5684504508972168, acc=0.7752777934074402, loss=0.5684504508972168
test: epoch 98, loss 1.3139889240264893, acc=0.4972222149372101, loss=1.3139889240264893
train: epoch 99, loss 0.5723989009857178, acc=0.7749444246292114, loss=0.5723989009857178
test: epoch 99, loss 1.2991658449172974, acc=0.5222222208976746, loss=1.2991658449172974
train: epoch 100, loss 0.55057692527771, acc=0.7822222113609314, loss=0.55057692527771
test: epoch 100, loss 1.2857404947280884, acc=0.5805555582046509, loss=1.2857404947280884
train: epoch 101, loss 0.5435860753059387, acc=0.7865555286407471, loss=0.5435860753059387
test: epoch 101, loss 1.5193380117416382, acc=0.49444442987442017, loss=1.5193380117416382
train: epoch 102, loss 0.5553507208824158, acc=0.7813888788223267, loss=0.5553507208824158
test: epoch 102, loss 1.4010417461395264, acc=0.49166667461395264, loss=1.4010417461395264
train: epoch 103, loss 0.5527952909469604, acc=0.781000018119812, loss=0.5527952909469604
test: epoch 103, loss 1.3611445426940918, acc=0.49444442987442017, loss=1.3611445426940918
train: epoch 104, loss 0.538152277469635, acc=0.7876666784286499, loss=0.538152277469635
test: epoch 104, loss 1.478291392326355, acc=0.4583333432674408, loss=1.478291392326355
train: epoch 105, loss 0.552764356136322, acc=0.7851666808128357, loss=0.552764356136322
test: epoch 105, loss 1.5320972204208374, acc=0.49166667461395264, loss=1.5320972204208374
train: epoch 106, loss 0.5480823516845703, acc=0.784333348274231, loss=0.5480823516845703
test: epoch 106, loss 1.3187355995178223, acc=0.4833333194255829, loss=1.3187355995178223
train: epoch 107, loss 0.5232660174369812, acc=0.7909444570541382, loss=0.5232660174369812
test: epoch 107, loss 1.2756741046905518, acc=0.5472221970558167, loss=1.2756741046905518
train: epoch 108, loss 0.54402756690979, acc=0.7857221961021423, loss=0.54402756690979
test: epoch 108, loss 1.3068360090255737, acc=0.5638889074325562, loss=1.3068360090255737
train: epoch 109, loss 0.5391595363616943, acc=0.7876666784286499, loss=0.5391595363616943
test: epoch 109, loss 1.3838579654693604, acc=0.47777777910232544, loss=1.3838579654693604
train: epoch 110, loss 0.5213599801063538, acc=0.7946110963821411, loss=0.5213599801063538
test: epoch 110, loss 1.9591400623321533, acc=0.4416666626930237, loss=1.9591400623321533
train: epoch 111, loss 0.5307116508483887, acc=0.7955555319786072, loss=0.5307116508483887
test: epoch 111, loss 1.513533592224121, acc=0.40833333134651184, loss=1.513533592224121
train: epoch 112, loss 0.5417901873588562, acc=0.7899444699287415, loss=0.5417901873588562
test: epoch 112, loss 1.3351047039031982, acc=0.48055556416511536, loss=1.3351047039031982
train: epoch 113, loss 0.530494749546051, acc=0.7926111221313477, loss=0.530494749546051
test: epoch 113, loss 1.27312171459198, acc=0.48055556416511536, loss=1.27312171459198
train: epoch 114, loss 0.534902036190033, acc=0.7900555729866028, loss=0.534902036190033
test: epoch 114, loss 1.412948727607727, acc=0.5472221970558167, loss=1.412948727607727
train: epoch 115, loss 0.5090354084968567, acc=0.8040000200271606, loss=0.5090354084968567
test: epoch 115, loss 1.1862655878067017, acc=0.49166667461395264, loss=1.1862655878067017
train: epoch 116, loss 0.5358359217643738, acc=0.7910555601119995, loss=0.5358359217643738
test: epoch 116, loss 1.512635350227356, acc=0.46666666865348816, loss=1.512635350227356
train: epoch 117, loss 0.5185706615447998, acc=0.8008888959884644, loss=0.5185706615447998
test: epoch 117, loss 1.487328290939331, acc=0.5666666626930237, loss=1.487328290939331
train: epoch 118, loss 0.518613338470459, acc=0.800944447517395, loss=0.518613338470459
test: epoch 118, loss 1.459702968597412, acc=0.5694444179534912, loss=1.459702968597412
train: epoch 119, loss 0.5259706974029541, acc=0.7951666712760925, loss=0.5259706974029541
test: epoch 119, loss 1.3661882877349854, acc=0.5249999761581421, loss=1.3661882877349854
train: epoch 120, loss 0.5268919467926025, acc=0.7941666841506958, loss=0.5268919467926025
test: epoch 120, loss 1.337591290473938, acc=0.5333333611488342, loss=1.337591290473938
train: epoch 121, loss 0.5124105215072632, acc=0.8014444708824158, loss=0.5124105215072632
test: epoch 121, loss 1.5203711986541748, acc=0.4694444537162781, loss=1.5203711986541748
train: epoch 122, loss 0.49163326621055603, acc=0.8103888630867004, loss=0.49163326621055603
test: epoch 122, loss 1.416326642036438, acc=0.5222222208976746, loss=1.416326642036438
train: epoch 123, loss 0.4987276494503021, acc=0.8055555820465088, loss=0.4987276494503021
test: epoch 123, loss 1.3628212213516235, acc=0.5166666507720947, loss=1.3628212213516235
train: epoch 124, loss 0.5030952095985413, acc=0.8070555329322815, loss=0.5030952095985413
test: epoch 124, loss 1.4389065504074097, acc=0.5361111164093018, loss=1.4389065504074097
train: epoch 125, loss 0.49851474165916443, acc=0.8093888759613037, loss=0.49851474165916443
test: epoch 125, loss 1.2749730348587036, acc=0.5694444179534912, loss=1.2749730348587036
train: epoch 126, loss 0.5040572881698608, acc=0.8022778034210205, loss=0.5040572881698608
test: epoch 126, loss 1.2655526399612427, acc=0.605555534362793, loss=1.2655526399612427
train: epoch 127, loss 0.5210483074188232, acc=0.8017777800559998, loss=0.5210483074188232
test: epoch 127, loss 1.2125461101531982, acc=0.5694444179534912, loss=1.2125461101531982
train: epoch 128, loss 0.47633299231529236, acc=0.8142222166061401, loss=0.47633299231529236
test: epoch 128, loss 1.197385549545288, acc=0.5249999761581421, loss=1.197385549545288
train: epoch 129, loss 0.49620482325553894, acc=0.8069444298744202, loss=0.49620482325553894
test: epoch 129, loss 1.3525900840759277, acc=0.5833333134651184, loss=1.3525900840759277
train: epoch 130, loss 0.5154029726982117, acc=0.8041666746139526, loss=0.5154029726982117
test: epoch 130, loss 1.0828794240951538, acc=0.5638889074325562, loss=1.0828794240951538
train: epoch 131, loss 0.4993076026439667, acc=0.8084999918937683, loss=0.4993076026439667
test: epoch 131, loss 1.3784641027450562, acc=0.5222222208976746, loss=1.3784641027450562
train: epoch 132, loss 0.5174981951713562, acc=0.8002777695655823, loss=0.5174981951713562
test: epoch 132, loss 1.2248159646987915, acc=0.5722222328186035, loss=1.2248159646987915
train: epoch 133, loss 0.4740232229232788, acc=0.8172222375869751, loss=0.4740232229232788
test: epoch 133, loss 1.3900595903396606, acc=0.5305555462837219, loss=1.3900595903396606
train: epoch 134, loss 0.4975550174713135, acc=0.8089444637298584, loss=0.4975550174713135
test: epoch 134, loss 1.2248570919036865, acc=0.5277777910232544, loss=1.2248570919036865
train: epoch 135, loss 0.4853290915489197, acc=0.8128888607025146, loss=0.4853290915489197
test: epoch 135, loss 1.3812164068222046, acc=0.5111111402511597, loss=1.3812164068222046
train: epoch 136, loss 0.492332398891449, acc=0.8125, loss=0.492332398891449
test: epoch 136, loss 1.2963030338287354, acc=0.6194444298744202, loss=1.2963030338287354
train: epoch 137, loss 0.5012087225914001, acc=0.8097777962684631, loss=0.5012087225914001
test: epoch 137, loss 1.3009238243103027, acc=0.5916666388511658, loss=1.3009238243103027
train: epoch 138, loss 0.4539218246936798, acc=0.8256666660308838, loss=0.4539218246936798
test: epoch 138, loss 1.5670627355575562, acc=0.5305555462837219, loss=1.5670627355575562
train: epoch 139, loss 0.48638591170310974, acc=0.8112778067588806, loss=0.48638591170310974
test: epoch 139, loss 1.4008442163467407, acc=0.5388888716697693, loss=1.4008442163467407
train: epoch 140, loss 0.4649094045162201, acc=0.823888897895813, loss=0.4649094045162201
test: epoch 140, loss 1.4754269123077393, acc=0.5472221970558167, loss=1.4754269123077393
train: epoch 141, loss 0.48196136951446533, acc=0.8151111006736755, loss=0.48196136951446533
test: epoch 141, loss 1.2565199136734009, acc=0.5277777910232544, loss=1.2565199136734009
train: epoch 142, loss 0.48537662625312805, acc=0.8138889074325562, loss=0.48537662625312805
test: epoch 142, loss 1.3265306949615479, acc=0.574999988079071, loss=1.3265306949615479
train: epoch 143, loss 0.47655919194221497, acc=0.8153889179229736, loss=0.47655919194221497
test: epoch 143, loss 1.5010510683059692, acc=0.5277777910232544, loss=1.5010510683059692
train: epoch 144, loss 0.4515269100666046, acc=0.8241666555404663, loss=0.4515269100666046
test: epoch 144, loss 1.2036709785461426, acc=0.6083333492279053, loss=1.2036709785461426
train: epoch 145, loss 0.4721809923648834, acc=0.8194444179534912, loss=0.4721809923648834
test: epoch 145, loss 1.3106889724731445, acc=0.574999988079071, loss=1.3106889724731445
train: epoch 146, loss 0.4551933705806732, acc=0.8217777609825134, loss=0.4551933705806732
test: epoch 146, loss 1.158339500427246, acc=0.6111111044883728, loss=1.158339500427246
train: epoch 147, loss 0.455380916595459, acc=0.8246111273765564, loss=0.455380916595459
test: epoch 147, loss 1.3111709356307983, acc=0.5361111164093018, loss=1.3111709356307983
train: epoch 148, loss 0.475307434797287, acc=0.8176110982894897, loss=0.475307434797287
test: epoch 148, loss 1.6094204187393188, acc=0.49444442987442017, loss=1.6094204187393188
train: epoch 149, loss 0.48740464448928833, acc=0.8127777576446533, loss=0.48740464448928833
test: epoch 149, loss 1.227431297302246, acc=0.5833333134651184, loss=1.227431297302246
train: epoch 150, loss 0.4669124484062195, acc=0.8205000162124634, loss=0.4669124484062195
test: epoch 150, loss 1.720737099647522, acc=0.5277777910232544, loss=1.720737099647522
