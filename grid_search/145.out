# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=2.0", "--temp_decay=1", "--one_hot=0", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=906959714, receiver_embed_dim=128, save_run=0, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=906959714, receiver_embed_dim=128, save_run=False, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.380478858947754, acc=0.16716666519641876, loss=2.380478858947754
test: epoch 1, loss 7.155466079711914, acc=0.04722222313284874, loss=7.155466079711914
train: epoch 2, loss 1.8024816513061523, acc=0.28861111402511597, loss=1.8024816513061523
test: epoch 2, loss 7.030871868133545, acc=0.05277777835726738, loss=7.030871868133545
train: epoch 3, loss 1.5985249280929565, acc=0.3458888828754425, loss=1.5985249280929565
test: epoch 3, loss 6.931351661682129, acc=0.06666667014360428, loss=6.931351661682129
train: epoch 4, loss 1.4288274049758911, acc=0.4056110978126526, loss=1.4288274049758911
test: epoch 4, loss 5.681778907775879, acc=0.09166666865348816, loss=5.681778907775879
train: epoch 5, loss 1.312373161315918, acc=0.4565555453300476, loss=1.312373161315918
test: epoch 5, loss 5.457091331481934, acc=0.07222222536802292, loss=5.457091331481934
train: epoch 6, loss 1.2367419004440308, acc=0.49433332681655884, loss=1.2367419004440308
test: epoch 6, loss 5.803102016448975, acc=0.11388888955116272, loss=5.803102016448975
train: epoch 7, loss 1.1346813440322876, acc=0.5368888974189758, loss=1.1346813440322876
test: epoch 7, loss 6.811805725097656, acc=0.0555555559694767, loss=6.811805725097656
train: epoch 8, loss 1.0744171142578125, acc=0.5622222423553467, loss=1.0744171142578125
test: epoch 8, loss 6.399140357971191, acc=0.07500000298023224, loss=6.399140357971191
train: epoch 9, loss 1.0136104822158813, acc=0.5901111364364624, loss=1.0136104822158813
test: epoch 9, loss 4.794306755065918, acc=0.17777778208255768, loss=4.794306755065918
train: epoch 10, loss 0.9472125172615051, acc=0.6186666488647461, loss=0.9472125172615051
test: epoch 10, loss 6.138528347015381, acc=0.07500000298023224, loss=6.138528347015381
train: epoch 11, loss 0.9171093106269836, acc=0.6321666836738586, loss=0.9171093106269836
test: epoch 11, loss 6.359358787536621, acc=0.08888889104127884, loss=6.359358787536621
train: epoch 12, loss 0.8853264451026917, acc=0.6480000019073486, loss=0.8853264451026917
test: epoch 12, loss 6.659339904785156, acc=0.10277777910232544, loss=6.659339904785156
train: epoch 13, loss 0.8372668623924255, acc=0.6664999723434448, loss=0.8372668623924255
test: epoch 13, loss 5.640849590301514, acc=0.11388888955116272, loss=5.640849590301514
train: epoch 14, loss 0.8008601069450378, acc=0.6881666779518127, loss=0.8008601069450378
test: epoch 14, loss 6.417799472808838, acc=0.10277777910232544, loss=6.417799472808838
train: epoch 15, loss 0.7605253458023071, acc=0.6963333487510681, loss=0.7605253458023071
test: epoch 15, loss 6.452902793884277, acc=0.125, loss=6.452902793884277
train: epoch 16, loss 0.7434356808662415, acc=0.7086111307144165, loss=0.7434356808662415
test: epoch 16, loss 5.7585015296936035, acc=0.08611111342906952, loss=5.7585015296936035
train: epoch 17, loss 0.7098814845085144, acc=0.7212222218513489, loss=0.7098814845085144
test: epoch 17, loss 5.803842544555664, acc=0.09166666865348816, loss=5.803842544555664
train: epoch 18, loss 0.693577766418457, acc=0.7304999828338623, loss=0.693577766418457
test: epoch 18, loss 5.739202499389648, acc=0.12777778506278992, loss=5.739202499389648
train: epoch 19, loss 0.6698988080024719, acc=0.7366111278533936, loss=0.6698988080024719
test: epoch 19, loss 6.0016984939575195, acc=0.13611111044883728, loss=6.0016984939575195
train: epoch 20, loss 0.6579387187957764, acc=0.7415000200271606, loss=0.6579387187957764
test: epoch 20, loss 5.510211944580078, acc=0.10000000149011612, loss=5.510211944580078
train: epoch 21, loss 0.6262255311012268, acc=0.754277765750885, loss=0.6262255311012268
test: epoch 21, loss 6.5971198081970215, acc=0.09444444626569748, loss=6.5971198081970215
train: epoch 22, loss 0.6229907870292664, acc=0.7562222480773926, loss=0.6229907870292664
test: epoch 22, loss 6.403414249420166, acc=0.08611111342906952, loss=6.403414249420166
train: epoch 23, loss 0.6139137148857117, acc=0.7638888955116272, loss=0.6139137148857117
test: epoch 23, loss 5.3840460777282715, acc=0.17777778208255768, loss=5.3840460777282715
train: epoch 24, loss 0.5763537287712097, acc=0.7764444351196289, loss=0.5763537287712097
test: epoch 24, loss 5.535511016845703, acc=0.11388888955116272, loss=5.535511016845703
train: epoch 25, loss 0.5673987865447998, acc=0.7806110978126526, loss=0.5673987865447998
test: epoch 25, loss 6.083481788635254, acc=0.10833333432674408, loss=6.083481788635254
train: epoch 26, loss 0.5466277599334717, acc=0.7868333458900452, loss=0.5466277599334717
test: epoch 26, loss 6.386487007141113, acc=0.09166666865348816, loss=6.386487007141113
train: epoch 27, loss 0.5548430681228638, acc=0.7890555262565613, loss=0.5548430681228638
test: epoch 27, loss 5.299430847167969, acc=0.0833333358168602, loss=5.299430847167969
train: epoch 28, loss 0.5508578419685364, acc=0.7918888926506042, loss=0.5508578419685364
test: epoch 28, loss 5.826762676239014, acc=0.1111111119389534, loss=5.826762676239014
train: epoch 29, loss 0.5138649344444275, acc=0.8070555329322815, loss=0.5138649344444275
test: epoch 29, loss 5.8739519119262695, acc=0.09444444626569748, loss=5.8739519119262695
train: epoch 30, loss 0.503889262676239, acc=0.8069444298744202, loss=0.503889262676239
test: epoch 30, loss 5.824197769165039, acc=0.11944444477558136, loss=5.824197769165039
train: epoch 31, loss 0.49443307518959045, acc=0.812666654586792, loss=0.49443307518959045
test: epoch 31, loss 4.405279636383057, acc=0.12777778506278992, loss=4.405279636383057
train: epoch 32, loss 0.4895755350589752, acc=0.812166690826416, loss=0.4895755350589752
test: epoch 32, loss 5.41102933883667, acc=0.09444444626569748, loss=5.41102933883667
train: epoch 33, loss 0.4719885587692261, acc=0.820722222328186, loss=0.4719885587692261
test: epoch 33, loss 6.399563312530518, acc=0.14722222089767456, loss=6.399563312530518
train: epoch 34, loss 0.46464693546295166, acc=0.8228889107704163, loss=0.46464693546295166
test: epoch 34, loss 5.390626907348633, acc=0.15555556118488312, loss=5.390626907348633
train: epoch 35, loss 0.4662420451641083, acc=0.8216111063957214, loss=0.4662420451641083
test: epoch 35, loss 4.96831750869751, acc=0.11944444477558136, loss=4.96831750869751
train: epoch 36, loss 0.46154433488845825, acc=0.824222207069397, loss=0.46154433488845825
test: epoch 36, loss 4.581169128417969, acc=0.13611111044883728, loss=4.581169128417969
train: epoch 37, loss 0.45317691564559937, acc=0.8291666507720947, loss=0.45317691564559937
test: epoch 37, loss 5.267426490783691, acc=0.05833333358168602, loss=5.267426490783691
train: epoch 38, loss 0.41627904772758484, acc=0.8407222032546997, loss=0.41627904772758484
test: epoch 38, loss 5.588632583618164, acc=0.1805555522441864, loss=5.588632583618164
train: epoch 39, loss 0.44469133019447327, acc=0.8320000171661377, loss=0.44469133019447327
test: epoch 39, loss 5.876649379730225, acc=0.16388888657093048, loss=5.876649379730225
train: epoch 40, loss 0.43213528394699097, acc=0.83561110496521, loss=0.43213528394699097
test: epoch 40, loss 5.254408359527588, acc=0.15833333134651184, loss=5.254408359527588
train: epoch 41, loss 0.42846494913101196, acc=0.8391110897064209, loss=0.42846494913101196
test: epoch 41, loss 5.425784587860107, acc=0.13611111044883728, loss=5.425784587860107
train: epoch 42, loss 0.40952733159065247, acc=0.8461666703224182, loss=0.40952733159065247
test: epoch 42, loss 4.576846122741699, acc=0.17777778208255768, loss=4.576846122741699
train: epoch 43, loss 0.41507965326309204, acc=0.8461666703224182, loss=0.41507965326309204
test: epoch 43, loss 4.848394870758057, acc=0.07222222536802292, loss=4.848394870758057
train: epoch 44, loss 0.40365955233573914, acc=0.8500000238418579, loss=0.40365955233573914
test: epoch 44, loss 6.114686489105225, acc=0.0972222238779068, loss=6.114686489105225
train: epoch 45, loss 0.4000944197177887, acc=0.8513888716697693, loss=0.4000944197177887
test: epoch 45, loss 4.452508449554443, acc=0.18888889253139496, loss=4.452508449554443
train: epoch 46, loss 0.3911980092525482, acc=0.8529999852180481, loss=0.3911980092525482
test: epoch 46, loss 5.000862121582031, acc=0.08888889104127884, loss=5.000862121582031
train: epoch 47, loss 0.376969575881958, acc=0.8583889007568359, loss=0.376969575881958
test: epoch 47, loss 5.3048601150512695, acc=0.18333333730697632, loss=5.3048601150512695
train: epoch 48, loss 0.37911665439605713, acc=0.8581110835075378, loss=0.37911665439605713
test: epoch 48, loss 5.353244304656982, acc=0.1111111119389534, loss=5.353244304656982
train: epoch 49, loss 0.37152746319770813, acc=0.863777756690979, loss=0.37152746319770813
test: epoch 49, loss 6.108014106750488, acc=0.14722222089767456, loss=6.108014106750488
train: epoch 50, loss 0.38025394082069397, acc=0.8549444675445557, loss=0.38025394082069397
test: epoch 50, loss 6.385571002960205, acc=0.12777778506278992, loss=6.385571002960205
train: epoch 51, loss 0.37542757391929626, acc=0.8601666688919067, loss=0.37542757391929626
test: epoch 51, loss 6.202359676361084, acc=0.17222222685813904, loss=6.202359676361084
train: epoch 52, loss 0.3726547658443451, acc=0.8585000038146973, loss=0.3726547658443451
test: epoch 52, loss 9.336907386779785, acc=0.09166666865348816, loss=9.336907386779785
train: epoch 53, loss 0.3753979206085205, acc=0.8654999732971191, loss=0.3753979206085205
test: epoch 53, loss 3.3371975421905518, acc=0.16388888657093048, loss=3.3371975421905518
train: epoch 54, loss 0.34582656621932983, acc=0.8696666955947876, loss=0.34582656621932983
test: epoch 54, loss 6.549312591552734, acc=0.06388889253139496, loss=6.549312591552734
train: epoch 55, loss 0.3344419300556183, acc=0.8757777810096741, loss=0.3344419300556183
test: epoch 55, loss 6.1232099533081055, acc=0.1388888955116272, loss=6.1232099533081055
train: epoch 56, loss 0.35860365629196167, acc=0.8682777881622314, loss=0.35860365629196167
test: epoch 56, loss 5.133683204650879, acc=0.13611111044883728, loss=5.133683204650879
train: epoch 57, loss 0.3206682801246643, acc=0.8814444541931152, loss=0.3206682801246643
test: epoch 57, loss 7.266305446624756, acc=0.08055555820465088, loss=7.266305446624756
train: epoch 58, loss 0.3247029185295105, acc=0.8784444332122803, loss=0.3247029185295105
test: epoch 58, loss 6.679155349731445, acc=0.07500000298023224, loss=6.679155349731445
train: epoch 59, loss 0.3559364378452301, acc=0.8705000281333923, loss=0.3559364378452301
test: epoch 59, loss 5.932308197021484, acc=0.07777778059244156, loss=5.932308197021484
train: epoch 60, loss 0.31875914335250854, acc=0.8820000290870667, loss=0.31875914335250854
test: epoch 60, loss 7.982662200927734, acc=0.11388888955116272, loss=7.982662200927734
train: epoch 61, loss 0.31581392884254456, acc=0.8820555806159973, loss=0.31581392884254456
test: epoch 61, loss 4.962701320648193, acc=0.13333334028720856, loss=4.962701320648193
train: epoch 62, loss 0.31826040148735046, acc=0.882444441318512, loss=0.31826040148735046
test: epoch 62, loss 10.540291786193848, acc=0.13333334028720856, loss=10.540291786193848
train: epoch 63, loss 0.31225889921188354, acc=0.8834444284439087, loss=0.31225889921188354
test: epoch 63, loss 4.680486679077148, acc=0.12222222238779068, loss=4.680486679077148
train: epoch 64, loss 0.32887887954711914, acc=0.8764444589614868, loss=0.32887887954711914
test: epoch 64, loss 5.9084882736206055, acc=0.12222222238779068, loss=5.9084882736206055
train: epoch 65, loss 0.3179428279399872, acc=0.8857777714729309, loss=0.3179428279399872
test: epoch 65, loss 5.290555477142334, acc=0.1111111119389534, loss=5.290555477142334
train: epoch 66, loss 0.3021266460418701, acc=0.8878889083862305, loss=0.3021266460418701
test: epoch 66, loss 7.664129257202148, acc=0.10000000149011612, loss=7.664129257202148
train: epoch 67, loss 0.2953837513923645, acc=0.8920000195503235, loss=0.2953837513923645
test: epoch 67, loss 5.342163562774658, acc=0.1111111119389534, loss=5.342163562774658
train: epoch 68, loss 0.30297529697418213, acc=0.8915555477142334, loss=0.30297529697418213
test: epoch 68, loss 5.787814617156982, acc=0.17499999701976776, loss=5.787814617156982
train: epoch 69, loss 0.293917715549469, acc=0.8924444317817688, loss=0.293917715549469
test: epoch 69, loss 5.527645111083984, acc=0.13611111044883728, loss=5.527645111083984
train: epoch 70, loss 0.29625439643859863, acc=0.8888333439826965, loss=0.29625439643859863
test: epoch 70, loss 5.65917444229126, acc=0.15833333134651184, loss=5.65917444229126
train: epoch 71, loss 0.31311988830566406, acc=0.8855000138282776, loss=0.31311988830566406
test: epoch 71, loss 4.898732662200928, acc=0.1805555522441864, loss=4.898732662200928
train: epoch 72, loss 0.2868949770927429, acc=0.8956666588783264, loss=0.2868949770927429
test: epoch 72, loss 4.593204975128174, acc=0.18888889253139496, loss=4.593204975128174
train: epoch 73, loss 0.28612321615219116, acc=0.894611120223999, loss=0.28612321615219116
test: epoch 73, loss 5.867753028869629, acc=0.14166666567325592, loss=5.867753028869629
train: epoch 74, loss 0.2948862612247467, acc=0.8894444704055786, loss=0.2948862612247467
test: epoch 74, loss 4.885250091552734, acc=0.20555555820465088, loss=4.885250091552734
train: epoch 75, loss 0.300907164812088, acc=0.8921666741371155, loss=0.300907164812088
test: epoch 75, loss 4.9390459060668945, acc=0.1666666716337204, loss=4.9390459060668945
train: epoch 76, loss 0.26245662569999695, acc=0.9013333320617676, loss=0.26245662569999695
test: epoch 76, loss 6.271675109863281, acc=0.12777778506278992, loss=6.271675109863281
train: epoch 77, loss 0.28379762172698975, acc=0.8963888883590698, loss=0.28379762172698975
test: epoch 77, loss 6.1693267822265625, acc=0.05000000074505806, loss=6.1693267822265625
train: epoch 78, loss 0.2927637994289398, acc=0.8930000066757202, loss=0.2927637994289398
test: epoch 78, loss 5.6698174476623535, acc=0.12777778506278992, loss=5.6698174476623535
train: epoch 79, loss 0.2655344605445862, acc=0.8997222185134888, loss=0.2655344605445862
test: epoch 79, loss 8.74282455444336, acc=0.09444444626569748, loss=8.74282455444336
train: epoch 80, loss 0.27764007449150085, acc=0.8974999785423279, loss=0.27764007449150085
test: epoch 80, loss 5.817478656768799, acc=0.15555556118488312, loss=5.817478656768799
train: epoch 81, loss 0.29263025522232056, acc=0.8937222361564636, loss=0.29263025522232056
test: epoch 81, loss 6.882415294647217, acc=0.14444445073604584, loss=6.882415294647217
train: epoch 82, loss 0.2593073546886444, acc=0.9053888916969299, loss=0.2593073546886444
test: epoch 82, loss 5.655878067016602, acc=0.15000000596046448, loss=5.655878067016602
train: epoch 83, loss 0.2578834891319275, acc=0.9061111211776733, loss=0.2578834891319275
test: epoch 83, loss 6.94036865234375, acc=0.08888889104127884, loss=6.94036865234375
train: epoch 84, loss 0.2717124819755554, acc=0.9046666622161865, loss=0.2717124819755554
test: epoch 84, loss 7.4672064781188965, acc=0.11666666716337204, loss=7.4672064781188965
train: epoch 85, loss 0.2521827220916748, acc=0.910611093044281, loss=0.2521827220916748
test: epoch 85, loss 8.261094093322754, acc=0.1666666716337204, loss=8.261094093322754
train: epoch 86, loss 0.29029762744903564, acc=0.8959444165229797, loss=0.29029762744903564
test: epoch 86, loss 7.3431572914123535, acc=0.18888889253139496, loss=7.3431572914123535
train: epoch 87, loss 0.2802666127681732, acc=0.9008888602256775, loss=0.2802666127681732
test: epoch 87, loss 6.268925189971924, acc=0.14722222089767456, loss=6.268925189971924
train: epoch 88, loss 0.2546207308769226, acc=0.9062777757644653, loss=0.2546207308769226
test: epoch 88, loss 5.908814430236816, acc=0.10833333432674408, loss=5.908814430236816
train: epoch 89, loss 0.2757250964641571, acc=0.9009444713592529, loss=0.2757250964641571
test: epoch 89, loss 6.805091381072998, acc=0.1111111119389534, loss=6.805091381072998
train: epoch 90, loss 0.2566863000392914, acc=0.9069444537162781, loss=0.2566863000392914
test: epoch 90, loss 4.625409126281738, acc=0.16944444179534912, loss=4.625409126281738
train: epoch 91, loss 0.2642589509487152, acc=0.9021111130714417, loss=0.2642589509487152
test: epoch 91, loss 4.830817699432373, acc=0.15000000596046448, loss=4.830817699432373
train: epoch 92, loss 0.2680305540561676, acc=0.9026666879653931, loss=0.2680305540561676
test: epoch 92, loss 5.394684791564941, acc=0.1805555522441864, loss=5.394684791564941
train: epoch 93, loss 0.25275641679763794, acc=0.907444417476654, loss=0.25275641679763794
test: epoch 93, loss 6.1874213218688965, acc=0.10000000149011612, loss=6.1874213218688965
train: epoch 94, loss 0.23820696771144867, acc=0.9118888974189758, loss=0.23820696771144867
test: epoch 94, loss 7.393926620483398, acc=0.17777778208255768, loss=7.393926620483398
train: epoch 95, loss 0.24747183918952942, acc=0.9096111059188843, loss=0.24747183918952942
test: epoch 95, loss 6.480945110321045, acc=0.17777778208255768, loss=6.480945110321045
train: epoch 96, loss 0.24999350309371948, acc=0.9092777967453003, loss=0.24999350309371948
test: epoch 96, loss 6.9022088050842285, acc=0.13333334028720856, loss=6.9022088050842285
train: epoch 97, loss 0.25023528933525085, acc=0.9131666421890259, loss=0.25023528933525085
test: epoch 97, loss 6.118870735168457, acc=0.15000000596046448, loss=6.118870735168457
train: epoch 98, loss 0.25041133165359497, acc=0.9093888998031616, loss=0.25041133165359497
test: epoch 98, loss 6.276345729827881, acc=0.15000000596046448, loss=6.276345729827881
train: epoch 99, loss 0.24791738390922546, acc=0.9089999794960022, loss=0.24791738390922546
test: epoch 99, loss 9.051676750183105, acc=0.15555556118488312, loss=9.051676750183105
train: epoch 100, loss 0.24867528676986694, acc=0.9115555286407471, loss=0.24867528676986694
test: epoch 100, loss 7.60599946975708, acc=0.08888889104127884, loss=7.60599946975708
train: epoch 101, loss 0.24397319555282593, acc=0.9128333330154419, loss=0.24397319555282593
test: epoch 101, loss 6.042291641235352, acc=0.10000000149011612, loss=6.042291641235352
train: epoch 102, loss 0.234750896692276, acc=0.9139999747276306, loss=0.234750896692276
test: epoch 102, loss 8.737391471862793, acc=0.13611111044883728, loss=8.737391471862793
train: epoch 103, loss 0.2523835599422455, acc=0.9114999771118164, loss=0.2523835599422455
test: epoch 103, loss 6.606128215789795, acc=0.13055555522441864, loss=6.606128215789795
train: epoch 104, loss 0.2580491304397583, acc=0.9053333401679993, loss=0.2580491304397583
test: epoch 104, loss 5.743847846984863, acc=0.19166666269302368, loss=5.743847846984863
train: epoch 105, loss 0.23607590794563293, acc=0.9127777814865112, loss=0.23607590794563293
test: epoch 105, loss 4.407828330993652, acc=0.20000000298023224, loss=4.407828330993652
train: epoch 106, loss 0.23542864620685577, acc=0.9154999852180481, loss=0.23542864620685577
test: epoch 106, loss 5.534106254577637, acc=0.1111111119389534, loss=5.534106254577637
train: epoch 107, loss 0.22706396877765656, acc=0.9203333258628845, loss=0.22706396877765656
test: epoch 107, loss 6.952521800994873, acc=0.13055555522441864, loss=6.952521800994873
train: epoch 108, loss 0.24548009037971497, acc=0.9121111035346985, loss=0.24548009037971497
test: epoch 108, loss 5.870939254760742, acc=0.125, loss=5.870939254760742
train: epoch 109, loss 0.2504034638404846, acc=0.9083889126777649, loss=0.2504034638404846
test: epoch 109, loss 9.162130355834961, acc=0.21944443881511688, loss=9.162130355834961
train: epoch 110, loss 0.2412872165441513, acc=0.913611114025116, loss=0.2412872165441513
test: epoch 110, loss 8.325528144836426, acc=0.1527777761220932, loss=8.325528144836426
train: epoch 111, loss 0.2363838255405426, acc=0.9158333539962769, loss=0.2363838255405426
test: epoch 111, loss 5.71806526184082, acc=0.1388888955116272, loss=5.71806526184082
train: epoch 112, loss 0.2336159199476242, acc=0.9157778024673462, loss=0.2336159199476242
test: epoch 112, loss 8.342829704284668, acc=0.11944444477558136, loss=8.342829704284668
train: epoch 113, loss 0.2331816703081131, acc=0.9194444417953491, loss=0.2331816703081131
test: epoch 113, loss 6.609888553619385, acc=0.17777778208255768, loss=6.609888553619385
train: epoch 114, loss 0.24336828291416168, acc=0.910444438457489, loss=0.24336828291416168
test: epoch 114, loss 6.227358818054199, acc=0.13611111044883728, loss=6.227358818054199
train: epoch 115, loss 0.23710890114307404, acc=0.9144444465637207, loss=0.23710890114307404
test: epoch 115, loss 3.90854811668396, acc=0.21111111342906952, loss=3.90854811668396
train: epoch 116, loss 0.2359912395477295, acc=0.9135000109672546, loss=0.2359912395477295
test: epoch 116, loss 4.542455673217773, acc=0.29722222685813904, loss=4.542455673217773
train: epoch 117, loss 0.21242819726467133, acc=0.9217222332954407, loss=0.21242819726467133
test: epoch 117, loss 6.792818546295166, acc=0.10277777910232544, loss=6.792818546295166
train: epoch 118, loss 0.21073514223098755, acc=0.9237777590751648, loss=0.21073514223098755
test: epoch 118, loss 6.4879045486450195, acc=0.1111111119389534, loss=6.4879045486450195
train: epoch 119, loss 0.22286921739578247, acc=0.9186111092567444, loss=0.22286921739578247
test: epoch 119, loss 9.786073684692383, acc=0.15000000596046448, loss=9.786073684692383
train: epoch 120, loss 0.2232935130596161, acc=0.9194999933242798, loss=0.2232935130596161
test: epoch 120, loss 9.19977855682373, acc=0.0972222238779068, loss=9.19977855682373
train: epoch 121, loss 0.23067574203014374, acc=0.917555570602417, loss=0.23067574203014374
test: epoch 121, loss 10.015487670898438, acc=0.1666666716337204, loss=10.015487670898438
train: epoch 122, loss 0.2228623330593109, acc=0.9219444394111633, loss=0.2228623330593109
test: epoch 122, loss 5.492368698120117, acc=0.20000000298023224, loss=5.492368698120117
train: epoch 123, loss 0.2146943062543869, acc=0.9230555295944214, loss=0.2146943062543869
test: epoch 123, loss 3.367281913757324, acc=0.30000001192092896, loss=3.367281913757324
train: epoch 124, loss 0.21211332082748413, acc=0.9245555400848389, loss=0.21211332082748413
test: epoch 124, loss 7.582735538482666, acc=0.14166666567325592, loss=7.582735538482666
train: epoch 125, loss 0.21515965461730957, acc=0.9242777824401855, loss=0.21515965461730957
test: epoch 125, loss 5.282841682434082, acc=0.1388888955116272, loss=5.282841682434082
train: epoch 126, loss 0.22513674199581146, acc=0.9182778000831604, loss=0.22513674199581146
test: epoch 126, loss 6.20852518081665, acc=0.18611110746860504, loss=6.20852518081665
train: epoch 127, loss 0.22191675007343292, acc=0.9200000166893005, loss=0.22191675007343292
test: epoch 127, loss 8.339309692382812, acc=0.11944444477558136, loss=8.339309692382812
train: epoch 128, loss 0.20981205999851227, acc=0.9250555634498596, loss=0.20981205999851227
test: epoch 128, loss 6.149007797241211, acc=0.13611111044883728, loss=6.149007797241211
train: epoch 129, loss 0.21297751367092133, acc=0.922166645526886, loss=0.21297751367092133
test: epoch 129, loss 4.660141468048096, acc=0.14722222089767456, loss=4.660141468048096
train: epoch 130, loss 0.21546120941638947, acc=0.9213888645172119, loss=0.21546120941638947
test: epoch 130, loss 7.247801780700684, acc=0.19166666269302368, loss=7.247801780700684
train: epoch 131, loss 0.21378493309020996, acc=0.9238333106040955, loss=0.21378493309020996
test: epoch 131, loss 4.320072650909424, acc=0.23888888955116272, loss=4.320072650909424
train: epoch 132, loss 0.2301262617111206, acc=0.9181110858917236, loss=0.2301262617111206
test: epoch 132, loss 6.532415390014648, acc=0.1944444477558136, loss=6.532415390014648
train: epoch 133, loss 0.2135917842388153, acc=0.9227222204208374, loss=0.2135917842388153
test: epoch 133, loss 5.91981840133667, acc=0.12222222238779068, loss=5.91981840133667
train: epoch 134, loss 0.22403328120708466, acc=0.9200000166893005, loss=0.22403328120708466
test: epoch 134, loss 6.194329261779785, acc=0.15555556118488312, loss=6.194329261779785
train: epoch 135, loss 0.2203509509563446, acc=0.9233333468437195, loss=0.2203509509563446
test: epoch 135, loss 4.465503215789795, acc=0.24166665971279144, loss=4.465503215789795
train: epoch 136, loss 0.21525917947292328, acc=0.9225000143051147, loss=0.21525917947292328
test: epoch 136, loss 7.078277111053467, acc=0.09444444626569748, loss=7.078277111053467
train: epoch 137, loss 0.20549115538597107, acc=0.9246110916137695, loss=0.20549115538597107
test: epoch 137, loss 4.201107978820801, acc=0.24722221493721008, loss=4.201107978820801
train: epoch 138, loss 0.20561105012893677, acc=0.9265555739402771, loss=0.20561105012893677
test: epoch 138, loss 8.044905662536621, acc=0.18888889253139496, loss=8.044905662536621
train: epoch 139, loss 0.19139738380908966, acc=0.9307777881622314, loss=0.19139738380908966
test: epoch 139, loss 7.355190753936768, acc=0.1944444477558136, loss=7.355190753936768
train: epoch 140, loss 0.21014147996902466, acc=0.9241666793823242, loss=0.21014147996902466
test: epoch 140, loss 7.494572639465332, acc=0.15000000596046448, loss=7.494572639465332
train: epoch 141, loss 0.21249422430992126, acc=0.9221110939979553, loss=0.21249422430992126
test: epoch 141, loss 7.720071315765381, acc=0.13333334028720856, loss=7.720071315765381
train: epoch 142, loss 0.2098665088415146, acc=0.9271110892295837, loss=0.2098665088415146
test: epoch 142, loss 7.767789363861084, acc=0.19722221791744232, loss=7.767789363861084
train: epoch 143, loss 0.20503561198711395, acc=0.9282777905464172, loss=0.20503561198711395
test: epoch 143, loss 6.479747295379639, acc=0.24722221493721008, loss=6.479747295379639
train: epoch 144, loss 0.2012963443994522, acc=0.9269444346427917, loss=0.2012963443994522
test: epoch 144, loss 8.86337947845459, acc=0.1111111119389534, loss=8.86337947845459
train: epoch 145, loss 0.21728089451789856, acc=0.9229444265365601, loss=0.21728089451789856
test: epoch 145, loss 8.040034294128418, acc=0.1666666716337204, loss=8.040034294128418
train: epoch 146, loss 0.19479770958423615, acc=0.9276666641235352, loss=0.19479770958423615
test: epoch 146, loss 6.96380615234375, acc=0.10555555671453476, loss=6.96380615234375
train: epoch 147, loss 0.2128562182188034, acc=0.9250555634498596, loss=0.2128562182188034
test: epoch 147, loss 8.114250183105469, acc=0.1388888955116272, loss=8.114250183105469
train: epoch 148, loss 0.18850219249725342, acc=0.9327222108840942, loss=0.18850219249725342
test: epoch 148, loss 7.029172897338867, acc=0.2944444417953491, loss=7.029172897338867
train: epoch 149, loss 0.2107900232076645, acc=0.9244999885559082, loss=0.2107900232076645
test: epoch 149, loss 7.772855758666992, acc=0.13333334028720856, loss=7.772855758666992
train: epoch 150, loss 0.19198423624038696, acc=0.9282777905464172, loss=0.19198423624038696
test: epoch 150, loss 5.277708530426025, acc=0.22777777910232544, loss=5.277708530426025
