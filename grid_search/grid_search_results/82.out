# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=false", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=307234086, receiver_embed_dim=64, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.919800281524658, acc=0.09755555540323257, loss=2.919800281524658
test: epoch 1, loss 3.2778632640838623, acc=0.09444444626569748, loss=3.2778632640838623
train: epoch 2, loss 1.8790745735168457, acc=0.28866666555404663, loss=1.8790745735168457
test: epoch 2, loss 3.1135010719299316, acc=0.16388888657093048, loss=3.1135010719299316
train: epoch 3, loss 1.3478636741638184, acc=0.46399998664855957, loss=1.3478636741638184
test: epoch 3, loss 2.4981236457824707, acc=0.20000000298023224, loss=2.4981236457824707
train: epoch 4, loss 1.0657634735107422, acc=0.5689444541931152, loss=1.0657634735107422
test: epoch 4, loss 2.4513001441955566, acc=0.24444444477558136, loss=2.4513001441955566
train: epoch 5, loss 0.9159076809883118, acc=0.6357222199440002, loss=0.9159076809883118
test: epoch 5, loss 2.271566152572632, acc=0.24166665971279144, loss=2.271566152572632
train: epoch 6, loss 0.8155161738395691, acc=0.6727777719497681, loss=0.8155161738395691
test: epoch 6, loss 1.8161548376083374, acc=0.3333333432674408, loss=1.8161548376083374
train: epoch 7, loss 0.7422617077827454, acc=0.7059999704360962, loss=0.7422617077827454
test: epoch 7, loss 1.980774998664856, acc=0.3222222328186035, loss=1.980774998664856
train: epoch 8, loss 0.6633317470550537, acc=0.7361111044883728, loss=0.6633317470550537
test: epoch 8, loss 1.7314215898513794, acc=0.39444443583488464, loss=1.7314215898513794
train: epoch 9, loss 0.6047725677490234, acc=0.75855553150177, loss=0.6047725677490234
test: epoch 9, loss 1.5007175207138062, acc=0.4166666567325592, loss=1.5007175207138062
train: epoch 10, loss 0.5748316645622253, acc=0.7687222361564636, loss=0.5748316645622253
test: epoch 10, loss 1.7058296203613281, acc=0.3888888955116272, loss=1.7058296203613281
train: epoch 11, loss 0.5116990208625793, acc=0.7933889031410217, loss=0.5116990208625793
test: epoch 11, loss 1.743710994720459, acc=0.4027777910232544, loss=1.743710994720459
train: epoch 12, loss 0.5025553107261658, acc=0.7936111092567444, loss=0.5025553107261658
test: epoch 12, loss 1.6834975481033325, acc=0.4166666567325592, loss=1.6834975481033325
train: epoch 13, loss 0.4652084410190582, acc=0.8089444637298584, loss=0.4652084410190582
test: epoch 13, loss 1.7910974025726318, acc=0.3055555522441864, loss=1.7910974025726318
train: epoch 14, loss 0.45415157079696655, acc=0.8132222294807434, loss=0.45415157079696655
test: epoch 14, loss 1.5881266593933105, acc=0.4000000059604645, loss=1.5881266593933105
train: epoch 15, loss 0.42512357234954834, acc=0.8272222280502319, loss=0.42512357234954834
test: epoch 15, loss 1.5941557884216309, acc=0.4305555522441864, loss=1.5941557884216309
train: epoch 16, loss 0.3964199423789978, acc=0.8436111211776733, loss=0.3964199423789978
test: epoch 16, loss 1.5678666830062866, acc=0.519444465637207, loss=1.5678666830062866
train: epoch 17, loss 0.38727906346321106, acc=0.8446111083030701, loss=0.38727906346321106
test: epoch 17, loss 1.452256679534912, acc=0.5, loss=1.452256679534912
train: epoch 18, loss 0.3690800070762634, acc=0.8521111011505127, loss=0.3690800070762634
test: epoch 18, loss 1.324904441833496, acc=0.5361111164093018, loss=1.324904441833496
train: epoch 19, loss 0.34776562452316284, acc=0.8598333597183228, loss=0.34776562452316284
test: epoch 19, loss 1.4036521911621094, acc=0.5277777910232544, loss=1.4036521911621094
train: epoch 20, loss 0.33624377846717834, acc=0.8682777881622314, loss=0.33624377846717834
test: epoch 20, loss 1.3686437606811523, acc=0.5055555701255798, loss=1.3686437606811523
train: epoch 21, loss 0.31987348198890686, acc=0.8717777729034424, loss=0.31987348198890686
test: epoch 21, loss 1.5146090984344482, acc=0.46666666865348816, loss=1.5146090984344482
train: epoch 22, loss 0.3020492494106293, acc=0.886555552482605, loss=0.3020492494106293
test: epoch 22, loss 1.2205312252044678, acc=0.5944444537162781, loss=1.2205312252044678
train: epoch 23, loss 0.29987379908561707, acc=0.8934999704360962, loss=0.29987379908561707
test: epoch 23, loss 1.2747387886047363, acc=0.5, loss=1.2747387886047363
train: epoch 24, loss 0.2895145118236542, acc=0.8994444608688354, loss=0.2895145118236542
test: epoch 24, loss 1.7661452293395996, acc=0.5138888955116272, loss=1.7661452293395996
train: epoch 25, loss 0.26498398184776306, acc=0.9085555672645569, loss=0.26498398184776306
test: epoch 25, loss 1.6540591716766357, acc=0.5, loss=1.6540591716766357
train: epoch 26, loss 0.2599281370639801, acc=0.9087222218513489, loss=0.2599281370639801
test: epoch 26, loss 1.8672524690628052, acc=0.5138888955116272, loss=1.8672524690628052
train: epoch 27, loss 0.25568535923957825, acc=0.9101666808128357, loss=0.25568535923957825
test: epoch 27, loss 1.4955475330352783, acc=0.5166666507720947, loss=1.4955475330352783
train: epoch 28, loss 0.26241448521614075, acc=0.9070000052452087, loss=0.26241448521614075
test: epoch 28, loss 1.3925367593765259, acc=0.5527777671813965, loss=1.3925367593765259
train: epoch 29, loss 0.2367015779018402, acc=0.9171110987663269, loss=0.2367015779018402
test: epoch 29, loss 1.2889564037322998, acc=0.5138888955116272, loss=1.2889564037322998
train: epoch 30, loss 0.2432153970003128, acc=0.9171666502952576, loss=0.2432153970003128
test: epoch 30, loss 1.4877980947494507, acc=0.5555555820465088, loss=1.4877980947494507
train: epoch 31, loss 0.2400052845478058, acc=0.9191666841506958, loss=0.2400052845478058
test: epoch 31, loss 1.6922519207000732, acc=0.5388888716697693, loss=1.6922519207000732
train: epoch 32, loss 0.220799520611763, acc=0.9229999780654907, loss=0.220799520611763
test: epoch 32, loss 1.5206539630889893, acc=0.5444444417953491, loss=1.5206539630889893
train: epoch 33, loss 0.22494451701641083, acc=0.9231666922569275, loss=0.22494451701641083
test: epoch 33, loss 1.2657073736190796, acc=0.5694444179534912, loss=1.2657073736190796
train: epoch 34, loss 0.21431155502796173, acc=0.9266111254692078, loss=0.21431155502796173
test: epoch 34, loss 1.1729371547698975, acc=0.6000000238418579, loss=1.1729371547698975
train: epoch 35, loss 0.20392091572284698, acc=0.930388867855072, loss=0.20392091572284698
test: epoch 35, loss 1.440467357635498, acc=0.550000011920929, loss=1.440467357635498
train: epoch 36, loss 0.19976966083049774, acc=0.929888904094696, loss=0.19976966083049774
test: epoch 36, loss 1.823125958442688, acc=0.5111111402511597, loss=1.823125958442688
train: epoch 37, loss 0.20183762907981873, acc=0.9317222237586975, loss=0.20183762907981873
test: epoch 37, loss 1.5507032871246338, acc=0.5277777910232544, loss=1.5507032871246338
train: epoch 38, loss 0.19502399861812592, acc=0.9303333163261414, loss=0.19502399861812592
test: epoch 38, loss 1.5985157489776611, acc=0.5527777671813965, loss=1.5985157489776611
train: epoch 39, loss 0.19225867092609406, acc=0.9325000047683716, loss=0.19225867092609406
test: epoch 39, loss 1.5146937370300293, acc=0.5361111164093018, loss=1.5146937370300293
train: epoch 40, loss 0.1846444457769394, acc=0.937333345413208, loss=0.1846444457769394
test: epoch 40, loss 1.3463387489318848, acc=0.6333333253860474, loss=1.3463387489318848
train: epoch 41, loss 0.18879635632038116, acc=0.9356111288070679, loss=0.18879635632038116
test: epoch 41, loss 1.8472856283187866, acc=0.5472221970558167, loss=1.8472856283187866
train: epoch 42, loss 0.1916428804397583, acc=0.9347222447395325, loss=0.1916428804397583
test: epoch 42, loss 1.5322123765945435, acc=0.6138888597488403, loss=1.5322123765945435
train: epoch 43, loss 0.16934734582901, acc=0.9434999823570251, loss=0.16934734582901
test: epoch 43, loss 1.3508485555648804, acc=0.6388888955116272, loss=1.3508485555648804
train: epoch 44, loss 0.18900565803050995, acc=0.9359444379806519, loss=0.18900565803050995
test: epoch 44, loss 1.462133765220642, acc=0.605555534362793, loss=1.462133765220642
train: epoch 45, loss 0.17973792552947998, acc=0.9397222399711609, loss=0.17973792552947998
test: epoch 45, loss 1.417779803276062, acc=0.644444465637207, loss=1.417779803276062
train: epoch 46, loss 0.18169192969799042, acc=0.9392777681350708, loss=0.18169192969799042
test: epoch 46, loss 1.4137276411056519, acc=0.6111111044883728, loss=1.4137276411056519
train: epoch 47, loss 0.17145296931266785, acc=0.9427777528762817, loss=0.17145296931266785
test: epoch 47, loss 1.2252044677734375, acc=0.6944444179534912, loss=1.2252044677734375
train: epoch 48, loss 0.17149044573307037, acc=0.9438333511352539, loss=0.17149044573307037
test: epoch 48, loss 0.8122294545173645, acc=0.7055555582046509, loss=0.8122294545173645
train: epoch 49, loss 0.1707034409046173, acc=0.9449999928474426, loss=0.1707034409046173
test: epoch 49, loss 1.0790483951568604, acc=0.7250000238418579, loss=1.0790483951568604
train: epoch 50, loss 0.1735178679227829, acc=0.9410555362701416, loss=0.1735178679227829
test: epoch 50, loss 1.4749016761779785, acc=0.6166666746139526, loss=1.4749016761779785
train: epoch 51, loss 0.16109387576580048, acc=0.9488333463668823, loss=0.16109387576580048
test: epoch 51, loss 1.0993748903274536, acc=0.6944444179534912, loss=1.0993748903274536
train: epoch 52, loss 0.15268516540527344, acc=0.9520000219345093, loss=0.15268516540527344
test: epoch 52, loss 1.2466117143630981, acc=0.6861110925674438, loss=1.2466117143630981
train: epoch 53, loss 0.14394943416118622, acc=0.9545000195503235, loss=0.14394943416118622
test: epoch 53, loss 1.0040768384933472, acc=0.6972222328186035, loss=1.0040768384933472
train: epoch 54, loss 0.15542010962963104, acc=0.9526110887527466, loss=0.15542010962963104
test: epoch 54, loss 1.1345576047897339, acc=0.7083333134651184, loss=1.1345576047897339
train: epoch 55, loss 0.14453600347042084, acc=0.9524999856948853, loss=0.14453600347042084
test: epoch 55, loss 1.2060717344284058, acc=0.6472222208976746, loss=1.2060717344284058
train: epoch 56, loss 0.14137355983257294, acc=0.9524999856948853, loss=0.14137355983257294
test: epoch 56, loss 0.9972039461135864, acc=0.7472222447395325, loss=0.9972039461135864
train: epoch 57, loss 0.1462153047323227, acc=0.9518333077430725, loss=0.1462153047323227
test: epoch 57, loss 1.0463732481002808, acc=0.7416666746139526, loss=1.0463732481002808
train: epoch 58, loss 0.12087520956993103, acc=0.9606666564941406, loss=0.12087520956993103
test: epoch 58, loss 0.9005092978477478, acc=0.730555534362793, loss=0.9005092978477478
train: epoch 59, loss 0.1438596546649933, acc=0.9531111121177673, loss=0.1438596546649933
test: epoch 59, loss 0.9951733946800232, acc=0.7416666746139526, loss=0.9951733946800232
train: epoch 60, loss 0.13491612672805786, acc=0.9566110968589783, loss=0.13491612672805786
test: epoch 60, loss 0.8594201803207397, acc=0.7166666388511658, loss=0.8594201803207397
train: epoch 61, loss 0.1356169581413269, acc=0.9556666612625122, loss=0.1356169581413269
test: epoch 61, loss 0.8369559645652771, acc=0.7222222089767456, loss=0.8369559645652771
train: epoch 62, loss 0.12612836062908173, acc=0.9598333239555359, loss=0.12612836062908173
test: epoch 62, loss 0.9389107823371887, acc=0.7222222089767456, loss=0.9389107823371887
train: epoch 63, loss 0.12465773522853851, acc=0.9601666927337646, loss=0.12465773522853851
test: epoch 63, loss 0.8625397086143494, acc=0.7194444537162781, loss=0.8625397086143494
train: epoch 64, loss 0.12857508659362793, acc=0.9577222466468811, loss=0.12857508659362793
test: epoch 64, loss 0.7957456707954407, acc=0.7527777552604675, loss=0.7957456707954407
train: epoch 65, loss 0.13066257536411285, acc=0.9561111330986023, loss=0.13066257536411285
test: epoch 65, loss 1.0653897523880005, acc=0.6777777671813965, loss=1.0653897523880005
train: epoch 66, loss 0.12793686985969543, acc=0.9577777981758118, loss=0.12793686985969543
test: epoch 66, loss 0.9502111077308655, acc=0.7166666388511658, loss=0.9502111077308655
train: epoch 67, loss 0.1392115354537964, acc=0.9538888931274414, loss=0.1392115354537964
test: epoch 67, loss 0.9151050448417664, acc=0.7111111283302307, loss=0.9151050448417664
train: epoch 68, loss 0.12206893414258957, acc=0.9590555429458618, loss=0.12206893414258957
test: epoch 68, loss 1.012121319770813, acc=0.6833333373069763, loss=1.012121319770813
train: epoch 69, loss 0.11663510650396347, acc=0.9609444737434387, loss=0.11663510650396347
test: epoch 69, loss 0.9215476512908936, acc=0.75, loss=0.9215476512908936
train: epoch 70, loss 0.11748400330543518, acc=0.9610000252723694, loss=0.11748400330543518
test: epoch 70, loss 0.9238399863243103, acc=0.7361111044883728, loss=0.9238399863243103
train: epoch 71, loss 0.11846119165420532, acc=0.9611111283302307, loss=0.11846119165420532
test: epoch 71, loss 0.7864596247673035, acc=0.7805555462837219, loss=0.7864596247673035
train: epoch 72, loss 0.12178454548120499, acc=0.960444450378418, loss=0.12178454548120499
test: epoch 72, loss 0.8683846592903137, acc=0.7277777791023254, loss=0.8683846592903137
train: epoch 73, loss 0.12090711295604706, acc=0.961555540561676, loss=0.12090711295604706
test: epoch 73, loss 0.9221706390380859, acc=0.7333333492279053, loss=0.9221706390380859
train: epoch 74, loss 0.11333733052015305, acc=0.9623333215713501, loss=0.11333733052015305
test: epoch 74, loss 1.0616296529769897, acc=0.7361111044883728, loss=1.0616296529769897
train: epoch 75, loss 0.12547115981578827, acc=0.9599444270133972, loss=0.12547115981578827
test: epoch 75, loss 0.7443737387657166, acc=0.7527777552604675, loss=0.7443737387657166
train: epoch 76, loss 0.11984477937221527, acc=0.9598888754844666, loss=0.11984477937221527
test: epoch 76, loss 0.756594717502594, acc=0.7805555462837219, loss=0.756594717502594
train: epoch 77, loss 0.11718466877937317, acc=0.9636111259460449, loss=0.11718466877937317
test: epoch 77, loss 0.6426730155944824, acc=0.824999988079071, loss=0.6426730155944824
train: epoch 78, loss 0.12067661434412003, acc=0.9629444479942322, loss=0.12067661434412003
test: epoch 78, loss 0.6982065439224243, acc=0.800000011920929, loss=0.6982065439224243
train: epoch 79, loss 0.12419372797012329, acc=0.9595555663108826, loss=0.12419372797012329
test: epoch 79, loss 0.8075429201126099, acc=0.7805555462837219, loss=0.8075429201126099
train: epoch 80, loss 0.10297592729330063, acc=0.9677777886390686, loss=0.10297592729330063
test: epoch 80, loss 0.6518925428390503, acc=0.8194444179534912, loss=0.6518925428390503
train: epoch 81, loss 0.10379073023796082, acc=0.9652222394943237, loss=0.10379073023796082
test: epoch 81, loss 0.7116662263870239, acc=0.8138889074325562, loss=0.7116662263870239
train: epoch 82, loss 0.11075450479984283, acc=0.964555561542511, loss=0.11075450479984283
test: epoch 82, loss 0.581579864025116, acc=0.8138889074325562, loss=0.581579864025116
train: epoch 83, loss 0.1106393039226532, acc=0.9647777676582336, loss=0.1106393039226532
test: epoch 83, loss 0.9210425615310669, acc=0.824999988079071, loss=0.9210425615310669
train: epoch 84, loss 0.12236268818378448, acc=0.9605555534362793, loss=0.12236268818378448
test: epoch 84, loss 0.5865373611450195, acc=0.824999988079071, loss=0.5865373611450195
train: epoch 85, loss 0.08851326256990433, acc=0.9718888998031616, loss=0.08851326256990433
test: epoch 85, loss 0.7609931230545044, acc=0.8277778029441833, loss=0.7609931230545044
train: epoch 86, loss 0.09579316526651382, acc=0.9691110849380493, loss=0.09579316526651382
test: epoch 86, loss 0.6074880361557007, acc=0.8305555582046509, loss=0.6074880361557007
train: epoch 87, loss 0.100335493683815, acc=0.9679999947547913, loss=0.100335493683815
test: epoch 87, loss 0.6632835865020752, acc=0.8222222328186035, loss=0.6632835865020752
train: epoch 88, loss 0.10637831687927246, acc=0.9657222032546997, loss=0.10637831687927246
test: epoch 88, loss 0.4604018032550812, acc=0.824999988079071, loss=0.4604018032550812
train: epoch 89, loss 0.09316577017307281, acc=0.9692777991294861, loss=0.09316577017307281
test: epoch 89, loss 0.6755856275558472, acc=0.8361111283302307, loss=0.6755856275558472
train: epoch 90, loss 0.09877405315637589, acc=0.9690555334091187, loss=0.09877405315637589
test: epoch 90, loss 0.7099142670631409, acc=0.824999988079071, loss=0.7099142670631409
train: epoch 91, loss 0.11023133993148804, acc=0.9637222290039062, loss=0.11023133993148804
test: epoch 91, loss 0.5770882368087769, acc=0.8416666388511658, loss=0.5770882368087769
train: epoch 92, loss 0.09254200011491776, acc=0.9701111316680908, loss=0.09254200011491776
test: epoch 92, loss 0.6299652457237244, acc=0.8416666388511658, loss=0.6299652457237244
train: epoch 93, loss 0.09126534312963486, acc=0.9710555672645569, loss=0.09126534312963486
test: epoch 93, loss 0.5597861409187317, acc=0.8388888835906982, loss=0.5597861409187317
train: epoch 94, loss 0.092176653444767, acc=0.9679999947547913, loss=0.092176653444767
test: epoch 94, loss 0.6767710447311401, acc=0.8388888835906982, loss=0.6767710447311401
train: epoch 95, loss 0.09323237091302872, acc=0.9696666598320007, loss=0.09323237091302872
test: epoch 95, loss 0.6429195404052734, acc=0.8111110925674438, loss=0.6429195404052734
train: epoch 96, loss 0.0940319299697876, acc=0.9690555334091187, loss=0.0940319299697876
test: epoch 96, loss 0.6256420016288757, acc=0.8416666388511658, loss=0.6256420016288757
train: epoch 97, loss 0.10590208321809769, acc=0.9656111001968384, loss=0.10590208321809769
test: epoch 97, loss 0.5806761384010315, acc=0.8416666388511658, loss=0.5806761384010315
train: epoch 98, loss 0.1003408133983612, acc=0.9671666622161865, loss=0.1003408133983612
test: epoch 98, loss 0.6341239213943481, acc=0.8416666388511658, loss=0.6341239213943481
train: epoch 99, loss 0.09774468839168549, acc=0.9700555801391602, loss=0.09774468839168549
test: epoch 99, loss 0.4877503514289856, acc=0.8388888835906982, loss=0.4877503514289856
train: epoch 100, loss 0.10001014918088913, acc=0.9687777757644653, loss=0.10001014918088913
test: epoch 100, loss 0.6360023021697998, acc=0.8388888835906982, loss=0.6360023021697998
train: epoch 101, loss 0.08956977725028992, acc=0.9711666703224182, loss=0.08956977725028992
test: epoch 101, loss 0.5761842727661133, acc=0.8416666388511658, loss=0.5761842727661133
train: epoch 102, loss 0.10570648312568665, acc=0.9669444561004639, loss=0.10570648312568665
test: epoch 102, loss 0.5023840069770813, acc=0.8388888835906982, loss=0.5023840069770813
train: epoch 103, loss 0.09175455570220947, acc=0.9696666598320007, loss=0.09175455570220947
test: epoch 103, loss 0.6445274353027344, acc=0.8305555582046509, loss=0.6445274353027344
train: epoch 104, loss 0.09711660444736481, acc=0.9695555567741394, loss=0.09711660444736481
test: epoch 104, loss 0.6155053377151489, acc=0.8194444179534912, loss=0.6155053377151489
train: epoch 105, loss 0.08991511911153793, acc=0.9711666703224182, loss=0.08991511911153793
test: epoch 105, loss 0.5403428673744202, acc=0.8416666388511658, loss=0.5403428673744202
train: epoch 106, loss 0.10390997678041458, acc=0.9648333191871643, loss=0.10390997678041458
test: epoch 106, loss 0.5399280786514282, acc=0.8416666388511658, loss=0.5399280786514282
train: epoch 107, loss 0.0893135517835617, acc=0.9715555310249329, loss=0.0893135517835617
test: epoch 107, loss 0.621742844581604, acc=0.8416666388511658, loss=0.621742844581604
train: epoch 108, loss 0.09227980673313141, acc=0.9704999923706055, loss=0.09227980673313141
test: epoch 108, loss 0.5779919028282166, acc=0.8416666388511658, loss=0.5779919028282166
train: epoch 109, loss 0.10289295017719269, acc=0.9679999947547913, loss=0.10289295017719269
test: epoch 109, loss 0.5665366053581238, acc=0.8416666388511658, loss=0.5665366053581238
train: epoch 110, loss 0.09660466015338898, acc=0.9700555801391602, loss=0.09660466015338898
test: epoch 110, loss 0.5499935150146484, acc=0.8416666388511658, loss=0.5499935150146484
train: epoch 111, loss 0.09591097384691238, acc=0.9696111083030701, loss=0.09591097384691238
test: epoch 111, loss 0.4299691915512085, acc=0.8500000238418579, loss=0.4299691915512085
train: epoch 112, loss 0.10964979231357574, acc=0.9647777676582336, loss=0.10964979231357574
test: epoch 112, loss 0.5489695072174072, acc=0.8416666388511658, loss=0.5489695072174072
train: epoch 113, loss 0.10433237254619598, acc=0.9666666388511658, loss=0.10433237254619598
test: epoch 113, loss 0.5442926287651062, acc=0.8416666388511658, loss=0.5442926287651062
train: epoch 114, loss 0.10967201739549637, acc=0.9645000100135803, loss=0.10967201739549637
test: epoch 114, loss 0.55292147397995, acc=0.8416666388511658, loss=0.55292147397995
train: epoch 115, loss 0.09715516120195389, acc=0.9668889045715332, loss=0.09715516120195389
test: epoch 115, loss 0.6647147536277771, acc=0.8388888835906982, loss=0.6647147536277771
train: epoch 116, loss 0.09436863660812378, acc=0.9700000286102295, loss=0.09436863660812378
test: epoch 116, loss 0.6286063194274902, acc=0.8416666388511658, loss=0.6286063194274902
train: epoch 117, loss 0.102303147315979, acc=0.9669444561004639, loss=0.102303147315979
test: epoch 117, loss 0.5961262583732605, acc=0.8416666388511658, loss=0.5961262583732605
train: epoch 118, loss 0.1152152568101883, acc=0.9642778038978577, loss=0.1152152568101883
test: epoch 118, loss 0.5293489098548889, acc=0.8416666388511658, loss=0.5293489098548889
train: epoch 119, loss 0.10761038213968277, acc=0.9660555720329285, loss=0.10761038213968277
test: epoch 119, loss 0.6084632873535156, acc=0.8416666388511658, loss=0.6084632873535156
train: epoch 120, loss 0.09999599307775497, acc=0.9686111211776733, loss=0.09999599307775497
test: epoch 120, loss 0.5436718463897705, acc=0.8416666388511658, loss=0.5436718463897705
train: epoch 121, loss 0.10011524707078934, acc=0.9686111211776733, loss=0.10011524707078934
test: epoch 121, loss 0.5305356383323669, acc=0.8416666388511658, loss=0.5305356383323669
train: epoch 122, loss 0.09013792127370834, acc=0.9697222113609314, loss=0.09013792127370834
test: epoch 122, loss 0.5883984565734863, acc=0.8416666388511658, loss=0.5883984565734863
train: epoch 123, loss 0.10539654642343521, acc=0.9640555381774902, loss=0.10539654642343521
test: epoch 123, loss 0.49319785833358765, acc=0.8416666388511658, loss=0.49319785833358765
train: epoch 124, loss 0.1041778028011322, acc=0.9669444561004639, loss=0.1041778028011322
test: epoch 124, loss 0.5832456350326538, acc=0.8388888835906982, loss=0.5832456350326538
train: epoch 125, loss 0.1067083552479744, acc=0.9653888940811157, loss=0.1067083552479744
test: epoch 125, loss 0.5580992102622986, acc=0.8416666388511658, loss=0.5580992102622986
train: epoch 126, loss 0.10243304073810577, acc=0.968666672706604, loss=0.10243304073810577
test: epoch 126, loss 0.5419308543205261, acc=0.8388888835906982, loss=0.5419308543205261
train: epoch 127, loss 0.1280573606491089, acc=0.9623888731002808, loss=0.1280573606491089
test: epoch 127, loss 0.5534798502922058, acc=0.8416666388511658, loss=0.5534798502922058
train: epoch 128, loss 0.10429108142852783, acc=0.9669444561004639, loss=0.10429108142852783
test: epoch 128, loss 0.5510339736938477, acc=0.8416666388511658, loss=0.5510339736938477
train: epoch 129, loss 0.09251873195171356, acc=0.9697222113609314, loss=0.09251873195171356
test: epoch 129, loss 0.44312161207199097, acc=0.8500000238418579, loss=0.44312161207199097
train: epoch 130, loss 0.11124829947948456, acc=0.9638333320617676, loss=0.11124829947948456
test: epoch 130, loss 0.4625866413116455, acc=0.8416666388511658, loss=0.4625866413116455
train: epoch 131, loss 0.10941842943429947, acc=0.9668889045715332, loss=0.10941842943429947
test: epoch 131, loss 0.5340932607650757, acc=0.8388888835906982, loss=0.5340932607650757
train: epoch 132, loss 0.09504576772451401, acc=0.9701111316680908, loss=0.09504576772451401
test: epoch 132, loss 0.5576474070549011, acc=0.8416666388511658, loss=0.5576474070549011
train: epoch 133, loss 0.11103817820549011, acc=0.9642221927642822, loss=0.11103817820549011
test: epoch 133, loss 0.4973900020122528, acc=0.8416666388511658, loss=0.4973900020122528
train: epoch 134, loss 0.10426881164312363, acc=0.967555582523346, loss=0.10426881164312363
test: epoch 134, loss 0.5340661406517029, acc=0.8388888835906982, loss=0.5340661406517029
train: epoch 135, loss 0.11337307840585709, acc=0.9650555849075317, loss=0.11337307840585709
test: epoch 135, loss 0.46416789293289185, acc=0.8416666388511658, loss=0.46416789293289185
train: epoch 136, loss 0.1040051206946373, acc=0.9648333191871643, loss=0.1040051206946373
test: epoch 136, loss 0.5038319230079651, acc=0.8416666388511658, loss=0.5038319230079651
train: epoch 137, loss 0.09321285784244537, acc=0.9687222242355347, loss=0.09321285784244537
test: epoch 137, loss 0.5499804019927979, acc=0.8388888835906982, loss=0.5499804019927979
train: epoch 138, loss 0.09750135987997055, acc=0.9691666960716248, loss=0.09750135987997055
test: epoch 138, loss 0.5262258648872375, acc=0.8416666388511658, loss=0.5262258648872375
train: epoch 139, loss 0.11454488337039948, acc=0.9649444222450256, loss=0.11454488337039948
test: epoch 139, loss 0.5018486380577087, acc=0.8361111283302307, loss=0.5018486380577087
train: epoch 140, loss 0.1095908135175705, acc=0.9670555591583252, loss=0.1095908135175705
test: epoch 140, loss 0.5654001832008362, acc=0.8444444537162781, loss=0.5654001832008362
train: epoch 141, loss 0.1072939857840538, acc=0.9642221927642822, loss=0.1072939857840538
test: epoch 141, loss 0.44456255435943604, acc=0.8416666388511658, loss=0.44456255435943604
train: epoch 142, loss 0.10263395309448242, acc=0.9673333168029785, loss=0.10263395309448242
test: epoch 142, loss 0.5806686282157898, acc=0.8416666388511658, loss=0.5806686282157898
train: epoch 143, loss 0.10820726305246353, acc=0.9670555591583252, loss=0.10820726305246353
test: epoch 143, loss 0.5670962929725647, acc=0.8416666388511658, loss=0.5670962929725647
train: epoch 144, loss 0.09992553293704987, acc=0.968999981880188, loss=0.09992553293704987
test: epoch 144, loss 0.46893125772476196, acc=0.8416666388511658, loss=0.46893125772476196
train: epoch 145, loss 0.1099681705236435, acc=0.964888870716095, loss=0.1099681705236435
test: epoch 145, loss 0.4927463233470917, acc=0.8416666388511658, loss=0.4927463233470917
train: epoch 146, loss 0.10544317960739136, acc=0.9649999737739563, loss=0.10544317960739136
test: epoch 146, loss 0.513197660446167, acc=0.8416666388511658, loss=0.513197660446167
train: epoch 147, loss 0.10690146684646606, acc=0.964555561542511, loss=0.10690146684646606
test: epoch 147, loss 0.49295902252197266, acc=0.8416666388511658, loss=0.49295902252197266
train: epoch 148, loss 0.1039196327328682, acc=0.9663888812065125, loss=0.1039196327328682
test: epoch 148, loss 0.5515573620796204, acc=0.8416666388511658, loss=0.5515573620796204
train: epoch 149, loss 0.10783380270004272, acc=0.9661666750907898, loss=0.10783380270004272
test: epoch 149, loss 0.505314290523529, acc=0.8416666388511658, loss=0.505314290523529
train: epoch 150, loss 0.09907754510641098, acc=0.9688888788223267, loss=0.09907754510641098
test: epoch 150, loss 0.5024184584617615, acc=0.8416666388511658, loss=0.5024184584617615
