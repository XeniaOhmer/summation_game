# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=false", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1723735782, receiver_embed_dim=32, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.0169155597686768, acc=0.07616666704416275, loss=3.0169155597686768
test: epoch 1, loss 4.577313423156738, acc=0.06666667014360428, loss=4.577313423156738
train: epoch 2, loss 2.070106029510498, acc=0.20711110532283783, loss=2.070106029510498
test: epoch 2, loss 4.980371475219727, acc=0.08611111342906952, loss=4.980371475219727
train: epoch 3, loss 1.631119966506958, acc=0.308555543422699, loss=1.631119966506958
test: epoch 3, loss 4.45474100112915, acc=0.19166666269302368, loss=4.45474100112915
train: epoch 4, loss 1.3999091386795044, acc=0.38455554842948914, loss=1.3999091386795044
test: epoch 4, loss 4.053257465362549, acc=0.1666666716337204, loss=4.053257465362549
train: epoch 5, loss 1.2864903211593628, acc=0.42605555057525635, loss=1.2864903211593628
test: epoch 5, loss 4.144750118255615, acc=0.19722221791744232, loss=4.144750118255615
train: epoch 6, loss 1.1878869533538818, acc=0.47672221064567566, loss=1.1878869533538818
test: epoch 6, loss 3.3010454177856445, acc=0.2888889014720917, loss=3.3010454177856445
train: epoch 7, loss 1.1139488220214844, acc=0.5070555806159973, loss=1.1139488220214844
test: epoch 7, loss 3.55037784576416, acc=0.22777777910232544, loss=3.55037784576416
train: epoch 8, loss 1.0664350986480713, acc=0.5357221961021423, loss=1.0664350986480713
test: epoch 8, loss 3.1397252082824707, acc=0.2361111044883728, loss=3.1397252082824707
train: epoch 9, loss 1.0186188220977783, acc=0.5522222518920898, loss=1.0186188220977783
test: epoch 9, loss 2.9475154876708984, acc=0.3305555582046509, loss=2.9475154876708984
train: epoch 10, loss 0.9381740093231201, acc=0.5926111340522766, loss=0.9381740093231201
test: epoch 10, loss 3.436532974243164, acc=0.2777777910232544, loss=3.436532974243164
train: epoch 11, loss 0.9175916910171509, acc=0.6021111011505127, loss=0.9175916910171509
test: epoch 11, loss 3.3547403812408447, acc=0.2083333283662796, loss=3.3547403812408447
train: epoch 12, loss 0.7993029356002808, acc=0.657444417476654, loss=0.7993029356002808
test: epoch 12, loss 3.3790881633758545, acc=0.2750000059604645, loss=3.3790881633758545
train: epoch 13, loss 0.6717120409011841, acc=0.7182222008705139, loss=0.6717120409011841
test: epoch 13, loss 3.0801799297332764, acc=0.3222222328186035, loss=3.0801799297332764
train: epoch 14, loss 0.611374020576477, acc=0.7466111183166504, loss=0.611374020576477
test: epoch 14, loss 3.412929058074951, acc=0.31111112236976624, loss=3.412929058074951
train: epoch 15, loss 0.5718011856079102, acc=0.7556666731834412, loss=0.5718011856079102
test: epoch 15, loss 3.320904016494751, acc=0.32777777314186096, loss=3.320904016494751
train: epoch 16, loss 0.5407357811927795, acc=0.7702222466468811, loss=0.5407357811927795
test: epoch 16, loss 3.390733003616333, acc=0.27222222089767456, loss=3.390733003616333
train: epoch 17, loss 0.4962610900402069, acc=0.7861111164093018, loss=0.4962610900402069
test: epoch 17, loss 3.2212724685668945, acc=0.28333333134651184, loss=3.2212724685668945
train: epoch 18, loss 0.47970783710479736, acc=0.800166666507721, loss=0.47970783710479736
test: epoch 18, loss 2.9331631660461426, acc=0.35277777910232544, loss=2.9331631660461426
train: epoch 19, loss 0.4276919662952423, acc=0.8273888826370239, loss=0.4276919662952423
test: epoch 19, loss 3.451709747314453, acc=0.3166666626930237, loss=3.451709747314453
train: epoch 20, loss 0.4132845103740692, acc=0.8281111121177673, loss=0.4132845103740692
test: epoch 20, loss 3.447204351425171, acc=0.3305555582046509, loss=3.447204351425171
train: epoch 21, loss 0.3390028476715088, acc=0.8575555682182312, loss=0.3390028476715088
test: epoch 21, loss 2.781766414642334, acc=0.3583333194255829, loss=2.781766414642334
train: epoch 22, loss 0.34139320254325867, acc=0.8576666712760925, loss=0.34139320254325867
test: epoch 22, loss 2.766244649887085, acc=0.4027777910232544, loss=2.766244649887085
train: epoch 23, loss 0.3209451735019684, acc=0.8646666407585144, loss=0.3209451735019684
test: epoch 23, loss 2.793321371078491, acc=0.4166666567325592, loss=2.793321371078491
train: epoch 24, loss 0.32198795676231384, acc=0.8666666746139526, loss=0.32198795676231384
test: epoch 24, loss 2.9109647274017334, acc=0.41111111640930176, loss=2.9109647274017334
train: epoch 25, loss 0.2932506203651428, acc=0.8772777915000916, loss=0.2932506203651428
test: epoch 25, loss 2.8669333457946777, acc=0.3861111104488373, loss=2.8669333457946777
train: epoch 26, loss 0.2786864936351776, acc=0.882111132144928, loss=0.2786864936351776
test: epoch 26, loss 2.8718161582946777, acc=0.4305555522441864, loss=2.8718161582946777
train: epoch 27, loss 0.29538053274154663, acc=0.8776111006736755, loss=0.29538053274154663
test: epoch 27, loss 2.613617181777954, acc=0.4722222089767456, loss=2.613617181777954
train: epoch 28, loss 0.2952425479888916, acc=0.8794999718666077, loss=0.2952425479888916
test: epoch 28, loss 2.5204737186431885, acc=0.4583333432674408, loss=2.5204737186431885
train: epoch 29, loss 0.26337099075317383, acc=0.887499988079071, loss=0.26337099075317383
test: epoch 29, loss 2.5148143768310547, acc=0.46388888359069824, loss=2.5148143768310547
train: epoch 30, loss 0.28567907214164734, acc=0.8831666707992554, loss=0.28567907214164734
test: epoch 30, loss 2.3433027267456055, acc=0.45277777314186096, loss=2.3433027267456055
train: epoch 31, loss 0.26122337579727173, acc=0.8908888697624207, loss=0.26122337579727173
test: epoch 31, loss 2.5075700283050537, acc=0.5, loss=2.5075700283050537
train: epoch 32, loss 0.23813927173614502, acc=0.8991666436195374, loss=0.23813927173614502
test: epoch 32, loss 2.0140438079833984, acc=0.5166666507720947, loss=2.0140438079833984
train: epoch 33, loss 0.25343212485313416, acc=0.8950555324554443, loss=0.25343212485313416
test: epoch 33, loss 1.815919041633606, acc=0.5027777552604675, loss=1.815919041633606
train: epoch 34, loss 0.26969271898269653, acc=0.8904444575309753, loss=0.26969271898269653
test: epoch 34, loss 1.7572991847991943, acc=0.519444465637207, loss=1.7572991847991943
train: epoch 35, loss 0.22328035533428192, acc=0.9063888788223267, loss=0.22328035533428192
test: epoch 35, loss 1.6001288890838623, acc=0.5027777552604675, loss=1.6001288890838623
train: epoch 36, loss 0.237041175365448, acc=0.9103888869285583, loss=0.237041175365448
test: epoch 36, loss 1.9841279983520508, acc=0.5444444417953491, loss=1.9841279983520508
train: epoch 37, loss 0.21794071793556213, acc=0.9252222180366516, loss=0.21794071793556213
test: epoch 37, loss 1.8150869607925415, acc=0.574999988079071, loss=1.8150869607925415
train: epoch 38, loss 0.182815819978714, acc=0.9387221932411194, loss=0.182815819978714
test: epoch 38, loss 1.801700234413147, acc=0.6111111044883728, loss=1.801700234413147
train: epoch 39, loss 0.180211141705513, acc=0.9397777915000916, loss=0.180211141705513
test: epoch 39, loss 2.250751495361328, acc=0.5166666507720947, loss=2.250751495361328
train: epoch 40, loss 0.1738140881061554, acc=0.9408888816833496, loss=0.1738140881061554
test: epoch 40, loss 1.4670690298080444, acc=0.6194444298744202, loss=1.4670690298080444
train: epoch 41, loss 0.16783463954925537, acc=0.9419999718666077, loss=0.16783463954925537
test: epoch 41, loss 2.245063066482544, acc=0.4833333194255829, loss=2.245063066482544
train: epoch 42, loss 0.13847163319587708, acc=0.9537777900695801, loss=0.13847163319587708
test: epoch 42, loss 1.4904301166534424, acc=0.5777778029441833, loss=1.4904301166534424
train: epoch 43, loss 0.17340093851089478, acc=0.9426110982894897, loss=0.17340093851089478
test: epoch 43, loss 1.7193031311035156, acc=0.5638889074325562, loss=1.7193031311035156
train: epoch 44, loss 0.15346656739711761, acc=0.9487777948379517, loss=0.15346656739711761
test: epoch 44, loss 1.555513858795166, acc=0.5916666388511658, loss=1.555513858795166
train: epoch 45, loss 0.16280749440193176, acc=0.9445555806159973, loss=0.16280749440193176
test: epoch 45, loss 2.0465662479400635, acc=0.5833333134651184, loss=2.0465662479400635
train: epoch 46, loss 0.1596461832523346, acc=0.9457777738571167, loss=0.1596461832523346
test: epoch 46, loss 2.1837775707244873, acc=0.5166666507720947, loss=2.1837775707244873
train: epoch 47, loss 0.1531238853931427, acc=0.949999988079071, loss=0.1531238853931427
test: epoch 47, loss 1.6157044172286987, acc=0.5722222328186035, loss=1.6157044172286987
train: epoch 48, loss 0.1541363149881363, acc=0.949999988079071, loss=0.1541363149881363
test: epoch 48, loss 1.585259199142456, acc=0.5694444179534912, loss=1.585259199142456
train: epoch 49, loss 0.1511346846818924, acc=0.9467222094535828, loss=0.1511346846818924
test: epoch 49, loss 1.2026593685150146, acc=0.5638889074325562, loss=1.2026593685150146
train: epoch 50, loss 0.1608293205499649, acc=0.9455000162124634, loss=0.1608293205499649
test: epoch 50, loss 2.0513546466827393, acc=0.5555555820465088, loss=2.0513546466827393
train: epoch 51, loss 0.14601613581180573, acc=0.9501110911369324, loss=0.14601613581180573
test: epoch 51, loss 1.7840259075164795, acc=0.574999988079071, loss=1.7840259075164795
train: epoch 52, loss 0.14807038009166718, acc=0.949999988079071, loss=0.14807038009166718
test: epoch 52, loss 1.436700463294983, acc=0.6000000238418579, loss=1.436700463294983
train: epoch 53, loss 0.15870621800422668, acc=0.9484444260597229, loss=0.15870621800422668
test: epoch 53, loss 1.4200607538223267, acc=0.5944444537162781, loss=1.4200607538223267
train: epoch 54, loss 0.14176473021507263, acc=0.9516666531562805, loss=0.14176473021507263
test: epoch 54, loss 1.5716590881347656, acc=0.5805555582046509, loss=1.5716590881347656
train: epoch 55, loss 0.15693402290344238, acc=0.9465555548667908, loss=0.15693402290344238
test: epoch 55, loss 1.7143914699554443, acc=0.5611110925674438, loss=1.7143914699554443
train: epoch 56, loss 0.11489079892635345, acc=0.9603888988494873, loss=0.11489079892635345
test: epoch 56, loss 1.580539345741272, acc=0.5333333611488342, loss=1.580539345741272
train: epoch 57, loss 0.12762826681137085, acc=0.9555555582046509, loss=0.12762826681137085
test: epoch 57, loss 1.9001089334487915, acc=0.5916666388511658, loss=1.9001089334487915
train: epoch 58, loss 0.169033020734787, acc=0.9440000057220459, loss=0.169033020734787
test: epoch 58, loss 1.0985350608825684, acc=0.7027778029441833, loss=1.0985350608825684
train: epoch 59, loss 0.15420810878276825, acc=0.9479444622993469, loss=0.15420810878276825
test: epoch 59, loss 1.3941748142242432, acc=0.6083333492279053, loss=1.3941748142242432
train: epoch 60, loss 0.1293247640132904, acc=0.9555000066757202, loss=0.1293247640132904
test: epoch 60, loss 1.2982957363128662, acc=0.6333333253860474, loss=1.2982957363128662
train: epoch 61, loss 0.138898104429245, acc=0.9526110887527466, loss=0.138898104429245
test: epoch 61, loss 1.3778513669967651, acc=0.6472222208976746, loss=1.3778513669967651
train: epoch 62, loss 0.14001725614070892, acc=0.9538333415985107, loss=0.14001725614070892
test: epoch 62, loss 1.3550689220428467, acc=0.625, loss=1.3550689220428467
train: epoch 63, loss 0.12484177947044373, acc=0.9574999809265137, loss=0.12484177947044373
test: epoch 63, loss 1.1814113855361938, acc=0.6777777671813965, loss=1.1814113855361938
train: epoch 64, loss 0.1380741000175476, acc=0.953499972820282, loss=0.1380741000175476
test: epoch 64, loss 1.201882243156433, acc=0.6333333253860474, loss=1.201882243156433
train: epoch 65, loss 0.13701780140399933, acc=0.9545000195503235, loss=0.13701780140399933
test: epoch 65, loss 1.4906301498413086, acc=0.675000011920929, loss=1.4906301498413086
train: epoch 66, loss 0.12028592824935913, acc=0.9588888883590698, loss=0.12028592824935913
test: epoch 66, loss 1.3665460348129272, acc=0.6888889074325562, loss=1.3665460348129272
train: epoch 67, loss 0.12656962871551514, acc=0.9586111307144165, loss=0.12656962871551514
test: epoch 67, loss 1.2943707704544067, acc=0.6722221970558167, loss=1.2943707704544067
train: epoch 68, loss 0.11823717504739761, acc=0.9611666798591614, loss=0.11823717504739761
test: epoch 68, loss 1.3409392833709717, acc=0.5805555582046509, loss=1.3409392833709717
train: epoch 69, loss 0.13982640206813812, acc=0.9530555605888367, loss=0.13982640206813812
test: epoch 69, loss 1.0674630403518677, acc=0.7027778029441833, loss=1.0674630403518677
train: epoch 70, loss 0.11727891862392426, acc=0.9593889117240906, loss=0.11727891862392426
test: epoch 70, loss 0.9674650430679321, acc=0.7055555582046509, loss=0.9674650430679321
train: epoch 71, loss 0.12044543027877808, acc=0.960277795791626, loss=0.12044543027877808
test: epoch 71, loss 1.1111654043197632, acc=0.7138888835906982, loss=1.1111654043197632
train: epoch 72, loss 0.12197954952716827, acc=0.9593333601951599, loss=0.12197954952716827
test: epoch 72, loss 0.7060564756393433, acc=0.7250000238418579, loss=0.7060564756393433
train: epoch 73, loss 0.12341635674238205, acc=0.9587222337722778, loss=0.12341635674238205
test: epoch 73, loss 0.8699276447296143, acc=0.7444444298744202, loss=0.8699276447296143
train: epoch 74, loss 0.11622877418994904, acc=0.9612777829170227, loss=0.11622877418994904
test: epoch 74, loss 1.2451364994049072, acc=0.6472222208976746, loss=1.2451364994049072
train: epoch 75, loss 0.13125140964984894, acc=0.9556666612625122, loss=0.13125140964984894
test: epoch 75, loss 0.6764929294586182, acc=0.7944444417953491, loss=0.6764929294586182
train: epoch 76, loss 0.13057132065296173, acc=0.9558888673782349, loss=0.13057132065296173
test: epoch 76, loss 1.0114933252334595, acc=0.7250000238418579, loss=1.0114933252334595
train: epoch 77, loss 0.12298306077718735, acc=0.9598333239555359, loss=0.12298306077718735
test: epoch 77, loss 1.0881924629211426, acc=0.7333333492279053, loss=1.0881924629211426
train: epoch 78, loss 0.12498609721660614, acc=0.9574999809265137, loss=0.12498609721660614
test: epoch 78, loss 0.7804187536239624, acc=0.7777777910232544, loss=0.7804187536239624
train: epoch 79, loss 0.11370725184679031, acc=0.96061110496521, loss=0.11370725184679031
test: epoch 79, loss 0.7017839550971985, acc=0.7638888955116272, loss=0.7017839550971985
train: epoch 80, loss 0.1117115244269371, acc=0.9623888731002808, loss=0.1117115244269371
test: epoch 80, loss 0.8728583455085754, acc=0.7749999761581421, loss=0.8728583455085754
train: epoch 81, loss 0.12090720236301422, acc=0.9587777853012085, loss=0.12090720236301422
test: epoch 81, loss 0.8671059608459473, acc=0.7638888955116272, loss=0.8671059608459473
train: epoch 82, loss 0.11336255073547363, acc=0.9634444713592529, loss=0.11336255073547363
test: epoch 82, loss 0.6201541423797607, acc=0.7666666507720947, loss=0.6201541423797607
train: epoch 83, loss 0.13843905925750732, acc=0.9539444446563721, loss=0.13843905925750732
test: epoch 83, loss 0.8111212849617004, acc=0.7138888835906982, loss=0.8111212849617004
train: epoch 84, loss 0.12339378893375397, acc=0.9587777853012085, loss=0.12339378893375397
test: epoch 84, loss 0.9519243240356445, acc=0.7388888597488403, loss=0.9519243240356445
train: epoch 85, loss 0.09220869839191437, acc=0.9682222008705139, loss=0.09220869839191437
test: epoch 85, loss 0.9636099934577942, acc=0.7611111402511597, loss=0.9636099934577942
train: epoch 86, loss 0.10929890722036362, acc=0.9631111025810242, loss=0.10929890722036362
test: epoch 86, loss 0.6267980337142944, acc=0.7805555462837219, loss=0.6267980337142944
train: epoch 87, loss 0.10775484144687653, acc=0.9627777934074402, loss=0.10775484144687653
test: epoch 87, loss 0.8410391211509705, acc=0.7611111402511597, loss=0.8410391211509705
train: epoch 88, loss 0.1151580736041069, acc=0.9624444246292114, loss=0.1151580736041069
test: epoch 88, loss 0.7788223624229431, acc=0.7666666507720947, loss=0.7788223624229431
train: epoch 89, loss 0.10957618057727814, acc=0.9633333086967468, loss=0.10957618057727814
test: epoch 89, loss 0.8845612406730652, acc=0.769444465637207, loss=0.8845612406730652
train: epoch 90, loss 0.1094108372926712, acc=0.9638333320617676, loss=0.1094108372926712
test: epoch 90, loss 0.6605653762817383, acc=0.8055555820465088, loss=0.6605653762817383
train: epoch 91, loss 0.12214618921279907, acc=0.9591110944747925, loss=0.12214618921279907
test: epoch 91, loss 0.7306762933731079, acc=0.7722222208976746, loss=0.7306762933731079
train: epoch 92, loss 0.10337557643651962, acc=0.965666651725769, loss=0.10337557643651962
test: epoch 92, loss 0.6893956065177917, acc=0.8083333373069763, loss=0.6893956065177917
train: epoch 93, loss 0.10745424032211304, acc=0.964722216129303, loss=0.10745424032211304
test: epoch 93, loss 0.8058032989501953, acc=0.7805555462837219, loss=0.8058032989501953
train: epoch 94, loss 0.10467219352722168, acc=0.9639444351196289, loss=0.10467219352722168
test: epoch 94, loss 0.6996654272079468, acc=0.8138889074325562, loss=0.6996654272079468
train: epoch 95, loss 0.11964669823646545, acc=0.960444450378418, loss=0.11964669823646545
test: epoch 95, loss 0.47616612911224365, acc=0.8305555582046509, loss=0.47616612911224365
train: epoch 96, loss 0.10558298975229263, acc=0.964388906955719, loss=0.10558298975229263
test: epoch 96, loss 0.4764736294746399, acc=0.8194444179534912, loss=0.4764736294746399
train: epoch 97, loss 0.10031194984912872, acc=0.9655555486679077, loss=0.10031194984912872
test: epoch 97, loss 0.5166007876396179, acc=0.8611111044883728, loss=0.5166007876396179
train: epoch 98, loss 0.090944305062294, acc=0.9698888659477234, loss=0.090944305062294
test: epoch 98, loss 0.6368157267570496, acc=0.8527777791023254, loss=0.6368157267570496
train: epoch 99, loss 0.10454759001731873, acc=0.9644444584846497, loss=0.10454759001731873
test: epoch 99, loss 0.5377894043922424, acc=0.8694444298744202, loss=0.5377894043922424
train: epoch 100, loss 0.09950485825538635, acc=0.9666110873222351, loss=0.09950485825538635
test: epoch 100, loss 0.5922058820724487, acc=0.8472222089767456, loss=0.5922058820724487
train: epoch 101, loss 0.09892695397138596, acc=0.9663333296775818, loss=0.09892695397138596
test: epoch 101, loss 0.4451582729816437, acc=0.8444444537162781, loss=0.4451582729816437
train: epoch 102, loss 0.09342645853757858, acc=0.968833327293396, loss=0.09342645853757858
test: epoch 102, loss 0.5208115577697754, acc=0.8500000238418579, loss=0.5208115577697754
train: epoch 103, loss 0.09052622318267822, acc=0.968666672706604, loss=0.09052622318267822
test: epoch 103, loss 0.45558303594589233, acc=0.8611111044883728, loss=0.45558303594589233
train: epoch 104, loss 0.10291716456413269, acc=0.9657222032546997, loss=0.10291716456413269
test: epoch 104, loss 0.51276034116745, acc=0.8638888597488403, loss=0.51276034116745
train: epoch 105, loss 0.08621234446763992, acc=0.9712222218513489, loss=0.08621234446763992
test: epoch 105, loss 0.5536002516746521, acc=0.8583333492279053, loss=0.5536002516746521
train: epoch 106, loss 0.09319110214710236, acc=0.9689444303512573, loss=0.09319110214710236
test: epoch 106, loss 0.40562084317207336, acc=0.8666666746139526, loss=0.40562084317207336
train: epoch 107, loss 0.08820246905088425, acc=0.9709444642066956, loss=0.08820246905088425
test: epoch 107, loss 0.37405189871788025, acc=0.8722222447395325, loss=0.37405189871788025
train: epoch 108, loss 0.13204379379749298, acc=0.9605000019073486, loss=0.13204379379749298
test: epoch 108, loss 0.5564070343971252, acc=0.8666666746139526, loss=0.5564070343971252
train: epoch 109, loss 0.09228050708770752, acc=0.9692222476005554, loss=0.09228050708770752
test: epoch 109, loss 0.406448632478714, acc=0.8583333492279053, loss=0.406448632478714
train: epoch 110, loss 0.0905395969748497, acc=0.9717222452163696, loss=0.0905395969748497
test: epoch 110, loss 0.4634578824043274, acc=0.8694444298744202, loss=0.4634578824043274
train: epoch 111, loss 0.08124461024999619, acc=0.9724444150924683, loss=0.08124461024999619
test: epoch 111, loss 0.4472995400428772, acc=0.875, loss=0.4472995400428772
train: epoch 112, loss 0.11803016811609268, acc=0.9635000228881836, loss=0.11803016811609268
test: epoch 112, loss 0.6040427684783936, acc=0.8694444298744202, loss=0.6040427684783936
train: epoch 113, loss 0.09871944040060043, acc=0.9679444432258606, loss=0.09871944040060043
test: epoch 113, loss 0.43958067893981934, acc=0.8611111044883728, loss=0.43958067893981934
train: epoch 114, loss 0.09922417998313904, acc=0.9677222371101379, loss=0.09922417998313904
test: epoch 114, loss 0.5622835755348206, acc=0.8722222447395325, loss=0.5622835755348206
train: epoch 115, loss 0.0973319262266159, acc=0.968833327293396, loss=0.0973319262266159
test: epoch 115, loss 0.43074244260787964, acc=0.8722222447395325, loss=0.43074244260787964
train: epoch 116, loss 0.06608691811561584, acc=0.9762222170829773, loss=0.06608691811561584
test: epoch 116, loss 0.4650467336177826, acc=0.8722222447395325, loss=0.4650467336177826
train: epoch 117, loss 0.09296773374080658, acc=0.967555582523346, loss=0.09296773374080658
test: epoch 117, loss 0.42084288597106934, acc=0.8666666746139526, loss=0.42084288597106934
train: epoch 118, loss 0.07199675589799881, acc=0.9752777814865112, loss=0.07199675589799881
test: epoch 118, loss 0.39553943276405334, acc=0.875, loss=0.39553943276405334
train: epoch 119, loss 0.10052959620952606, acc=0.9662222266197205, loss=0.10052959620952606
test: epoch 119, loss 0.6693722009658813, acc=0.8416666388511658, loss=0.6693722009658813
train: epoch 120, loss 0.09173742681741714, acc=0.9698333144187927, loss=0.09173742681741714
test: epoch 120, loss 0.3580300807952881, acc=0.8666666746139526, loss=0.3580300807952881
train: epoch 121, loss 0.08985728025436401, acc=0.9695555567741394, loss=0.08985728025436401
test: epoch 121, loss 0.3557877540588379, acc=0.8722222447395325, loss=0.3557877540588379
train: epoch 122, loss 0.09647177159786224, acc=0.9682777523994446, loss=0.09647177159786224
test: epoch 122, loss 0.508187472820282, acc=0.8722222447395325, loss=0.508187472820282
train: epoch 123, loss 0.08618640154600143, acc=0.9730555415153503, loss=0.08618640154600143
test: epoch 123, loss 0.48610594868659973, acc=0.8694444298744202, loss=0.48610594868659973
train: epoch 124, loss 0.10321531444787979, acc=0.968999981880188, loss=0.10321531444787979
test: epoch 124, loss 0.48954910039901733, acc=0.8694444298744202, loss=0.48954910039901733
train: epoch 125, loss 0.07704614847898483, acc=0.9729999899864197, loss=0.07704614847898483
test: epoch 125, loss 0.37650036811828613, acc=0.8722222447395325, loss=0.37650036811828613
train: epoch 126, loss 0.08162982016801834, acc=0.9728333353996277, loss=0.08162982016801834
test: epoch 126, loss 0.37289634346961975, acc=0.8722222447395325, loss=0.37289634346961975
train: epoch 127, loss 0.08657804131507874, acc=0.9695000052452087, loss=0.08657804131507874
test: epoch 127, loss 0.4674277603626251, acc=0.8666666746139526, loss=0.4674277603626251
train: epoch 128, loss 0.10203204303979874, acc=0.9673888683319092, loss=0.10203204303979874
test: epoch 128, loss 0.4270414710044861, acc=0.8777777552604675, loss=0.4270414710044861
train: epoch 129, loss 0.10009203851222992, acc=0.9682222008705139, loss=0.10009203851222992
test: epoch 129, loss 0.5100128054618835, acc=0.8694444298744202, loss=0.5100128054618835
train: epoch 130, loss 0.10082004219293594, acc=0.9680555462837219, loss=0.10082004219293594
test: epoch 130, loss 0.5028812289237976, acc=0.875, loss=0.5028812289237976
train: epoch 131, loss 0.08217219263315201, acc=0.971833348274231, loss=0.08217219263315201
test: epoch 131, loss 0.5465605854988098, acc=0.8722222447395325, loss=0.5465605854988098
train: epoch 132, loss 0.07385624945163727, acc=0.9748333096504211, loss=0.07385624945163727
test: epoch 132, loss 0.5413733124732971, acc=0.8722222447395325, loss=0.5413733124732971
train: epoch 133, loss 0.07103001326322556, acc=0.9742222428321838, loss=0.07103001326322556
test: epoch 133, loss 0.39132073521614075, acc=0.8694444298744202, loss=0.39132073521614075
train: epoch 134, loss 0.12933620810508728, acc=0.957444429397583, loss=0.12933620810508728
test: epoch 134, loss 0.4627876281738281, acc=0.8638888597488403, loss=0.4627876281738281
train: epoch 135, loss 0.09296466410160065, acc=0.9692222476005554, loss=0.09296466410160065
test: epoch 135, loss 0.39707881212234497, acc=0.8222222328186035, loss=0.39707881212234497
train: epoch 136, loss 0.08756158500909805, acc=0.9704999923706055, loss=0.08756158500909805
test: epoch 136, loss 0.40782788395881653, acc=0.8722222447395325, loss=0.40782788395881653
train: epoch 137, loss 0.08002656698226929, acc=0.9731666445732117, loss=0.08002656698226929
test: epoch 137, loss 0.3941750228404999, acc=0.875, loss=0.3941750228404999
train: epoch 138, loss 0.113360695540905, acc=0.9633333086967468, loss=0.113360695540905
test: epoch 138, loss 0.43784642219543457, acc=0.8444444537162781, loss=0.43784642219543457
train: epoch 139, loss 0.07952257245779037, acc=0.9725000262260437, loss=0.07952257245779037
test: epoch 139, loss 0.39969027042388916, acc=0.8861111402511597, loss=0.39969027042388916
train: epoch 140, loss 0.1003977581858635, acc=0.9673888683319092, loss=0.1003977581858635
test: epoch 140, loss 0.48339617252349854, acc=0.8833333253860474, loss=0.48339617252349854
train: epoch 141, loss 0.09433186054229736, acc=0.968666672706604, loss=0.09433186054229736
test: epoch 141, loss 0.34321388602256775, acc=0.8833333253860474, loss=0.34321388602256775
train: epoch 142, loss 0.07296505570411682, acc=0.9756110906600952, loss=0.07296505570411682
test: epoch 142, loss 0.5817326307296753, acc=0.875, loss=0.5817326307296753
train: epoch 143, loss 0.07789063453674316, acc=0.9739999771118164, loss=0.07789063453674316
test: epoch 143, loss 0.3230094015598297, acc=0.8805555701255798, loss=0.3230094015598297
train: epoch 144, loss 0.091147281229496, acc=0.9704444408416748, loss=0.091147281229496
test: epoch 144, loss 0.6761910319328308, acc=0.8472222089767456, loss=0.6761910319328308
train: epoch 145, loss 0.12366442382335663, acc=0.9622777700424194, loss=0.12366442382335663
test: epoch 145, loss 0.4218890368938446, acc=0.8833333253860474, loss=0.4218890368938446
train: epoch 146, loss 0.07781561464071274, acc=0.9740555286407471, loss=0.07781561464071274
test: epoch 146, loss 0.4372769296169281, acc=0.8833333253860474, loss=0.4372769296169281
train: epoch 147, loss 0.08035562187433243, acc=0.972611129283905, loss=0.08035562187433243
test: epoch 147, loss 0.42007747292518616, acc=0.8833333253860474, loss=0.42007747292518616
train: epoch 148, loss 0.0658741146326065, acc=0.9766666889190674, loss=0.0658741146326065
test: epoch 148, loss 0.48558294773101807, acc=0.8722222447395325, loss=0.48558294773101807
train: epoch 149, loss 0.087044857442379, acc=0.9726666808128357, loss=0.087044857442379
test: epoch 149, loss 0.35249945521354675, acc=0.8805555701255798, loss=0.35249945521354675
train: epoch 150, loss 0.0932944267988205, acc=0.9691110849380493, loss=0.0932944267988205
test: epoch 150, loss 0.431761234998703, acc=0.8833333253860474, loss=0.431761234998703
