# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=false", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1287969399, receiver_embed_dim=128, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.7475078105926514, acc=0.10361111164093018, loss=2.7475078105926514
test: epoch 1, loss 2.8061938285827637, acc=0.14722222089767456, loss=2.8061938285827637
train: epoch 2, loss 1.6597956418991089, acc=0.3145555555820465, loss=1.6597956418991089
test: epoch 2, loss 1.9885741472244263, acc=0.28333333134651184, loss=1.9885741472244263
train: epoch 3, loss 1.127683162689209, acc=0.5147777795791626, loss=1.127683162689209
test: epoch 3, loss 1.691835880279541, acc=0.3638888895511627, loss=1.691835880279541
train: epoch 4, loss 0.8766185641288757, acc=0.6165000200271606, loss=0.8766185641288757
test: epoch 4, loss 1.4555433988571167, acc=0.5055555701255798, loss=1.4555433988571167
train: epoch 5, loss 0.6920073628425598, acc=0.6889444589614868, loss=0.6920073628425598
test: epoch 5, loss 1.357291340827942, acc=0.4749999940395355, loss=1.357291340827942
train: epoch 6, loss 0.5343028903007507, acc=0.7595000267028809, loss=0.5343028903007507
test: epoch 6, loss 1.1331290006637573, acc=0.5083333253860474, loss=1.1331290006637573
train: epoch 7, loss 0.5115594863891602, acc=0.7721666693687439, loss=0.5115594863891602
test: epoch 7, loss 0.9552078247070312, acc=0.6277777552604675, loss=0.9552078247070312
train: epoch 8, loss 0.46946659684181213, acc=0.8001111149787903, loss=0.46946659684181213
test: epoch 8, loss 0.8957157135009766, acc=0.6416666507720947, loss=0.8957157135009766
train: epoch 9, loss 0.4262794852256775, acc=0.8146666884422302, loss=0.4262794852256775
test: epoch 9, loss 1.3081917762756348, acc=0.5638889074325562, loss=1.3081917762756348
train: epoch 10, loss 0.401828795671463, acc=0.8245000243186951, loss=0.401828795671463
test: epoch 10, loss 1.076401948928833, acc=0.605555534362793, loss=1.076401948928833
train: epoch 11, loss 0.3478449583053589, acc=0.8455555438995361, loss=0.3478449583053589
test: epoch 11, loss 0.8685657382011414, acc=0.6388888955116272, loss=0.8685657382011414
train: epoch 12, loss 0.3552885055541992, acc=0.8424999713897705, loss=0.3552885055541992
test: epoch 12, loss 0.9117217659950256, acc=0.6805555820465088, loss=0.9117217659950256
train: epoch 13, loss 0.3216944932937622, acc=0.8573333621025085, loss=0.3216944932937622
test: epoch 13, loss 0.8044029474258423, acc=0.7138888835906982, loss=0.8044029474258423
train: epoch 14, loss 0.34928464889526367, acc=0.8482221961021423, loss=0.34928464889526367
test: epoch 14, loss 0.7915725111961365, acc=0.730555534362793, loss=0.7915725111961365
train: epoch 15, loss 0.3075884282588959, acc=0.8633888959884644, loss=0.3075884282588959
test: epoch 15, loss 0.7456509470939636, acc=0.7749999761581421, loss=0.7456509470939636
train: epoch 16, loss 0.3059738576412201, acc=0.8612777590751648, loss=0.3059738576412201
test: epoch 16, loss 0.39382490515708923, acc=0.8222222328186035, loss=0.39382490515708923
train: epoch 17, loss 0.32668933272361755, acc=0.8625555634498596, loss=0.32668933272361755
test: epoch 17, loss 0.40074408054351807, acc=0.8388888835906982, loss=0.40074408054351807
train: epoch 18, loss 0.2701917886734009, acc=0.8842777609825134, loss=0.2701917886734009
test: epoch 18, loss 0.37880778312683105, acc=0.8444444537162781, loss=0.37880778312683105
train: epoch 19, loss 0.2773051857948303, acc=0.8817222118377686, loss=0.2773051857948303
test: epoch 19, loss 0.3573867380619049, acc=0.8444444537162781, loss=0.3573867380619049
train: epoch 20, loss 0.27563825249671936, acc=0.8763333559036255, loss=0.27563825249671936
test: epoch 20, loss 0.4283790588378906, acc=0.8361111283302307, loss=0.4283790588378906
train: epoch 21, loss 0.26164954900741577, acc=0.8822222352027893, loss=0.26164954900741577
test: epoch 21, loss 0.5541569590568542, acc=0.7861111164093018, loss=0.5541569590568542
train: epoch 22, loss 0.2479989379644394, acc=0.8860555291175842, loss=0.2479989379644394
test: epoch 22, loss 0.40622103214263916, acc=0.8611111044883728, loss=0.40622103214263916
train: epoch 23, loss 0.2423664927482605, acc=0.8971666693687439, loss=0.2423664927482605
test: epoch 23, loss 0.34603917598724365, acc=0.855555534362793, loss=0.34603917598724365
train: epoch 24, loss 0.254460871219635, acc=0.8936111330986023, loss=0.254460871219635
test: epoch 24, loss 0.3591373860836029, acc=0.8611111044883728, loss=0.3591373860836029
train: epoch 25, loss 0.23836995661258698, acc=0.8887777924537659, loss=0.23836995661258698
test: epoch 25, loss 0.24160292744636536, acc=0.8694444298744202, loss=0.24160292744636536
train: epoch 26, loss 0.2576592266559601, acc=0.8732222318649292, loss=0.2576592266559601
test: epoch 26, loss 0.31547847390174866, acc=0.8638888597488403, loss=0.31547847390174866
train: epoch 27, loss 0.2289545089006424, acc=0.8910555839538574, loss=0.2289545089006424
test: epoch 27, loss 0.48634788393974304, acc=0.8388888835906982, loss=0.48634788393974304
train: epoch 28, loss 0.2871219515800476, acc=0.8738333582878113, loss=0.2871219515800476
test: epoch 28, loss 0.3769098222255707, acc=0.8527777791023254, loss=0.3769098222255707
train: epoch 29, loss 0.27325865626335144, acc=0.8834444284439087, loss=0.27325865626335144
test: epoch 29, loss 0.33336925506591797, acc=0.855555534362793, loss=0.33336925506591797
train: epoch 30, loss 0.26780226826667786, acc=0.8732222318649292, loss=0.26780226826667786
test: epoch 30, loss 0.3521539270877838, acc=0.8388888835906982, loss=0.3521539270877838
train: epoch 31, loss 0.24893595278263092, acc=0.8823333382606506, loss=0.24893595278263092
test: epoch 31, loss 0.44541850686073303, acc=0.8333333134651184, loss=0.44541850686073303
train: epoch 32, loss 0.26955607533454895, acc=0.8845555782318115, loss=0.26955607533454895
test: epoch 32, loss 0.4798709452152252, acc=0.8472222089767456, loss=0.4798709452152252
train: epoch 33, loss 0.277924120426178, acc=0.8774999976158142, loss=0.277924120426178
test: epoch 33, loss 0.42679721117019653, acc=0.8361111283302307, loss=0.42679721117019653
train: epoch 34, loss 0.21999166905879974, acc=0.8889444470405579, loss=0.21999166905879974
test: epoch 34, loss 0.36349913477897644, acc=0.8472222089767456, loss=0.36349913477897644
train: epoch 35, loss 0.27354133129119873, acc=0.875, loss=0.27354133129119873
test: epoch 35, loss 0.32548651099205017, acc=0.8472222089767456, loss=0.32548651099205017
train: epoch 36, loss 0.25126394629478455, acc=0.88227778673172, loss=0.25126394629478455
test: epoch 36, loss 0.40613657236099243, acc=0.8416666388511658, loss=0.40613657236099243
train: epoch 37, loss 0.24964967370033264, acc=0.8738333582878113, loss=0.24964967370033264
test: epoch 37, loss 0.3594531714916229, acc=0.8416666388511658, loss=0.3594531714916229
train: epoch 38, loss 0.21380656957626343, acc=0.8867777585983276, loss=0.21380656957626343
test: epoch 38, loss 0.3441509008407593, acc=0.8416666388511658, loss=0.3441509008407593
train: epoch 39, loss 0.22707195580005646, acc=0.8784999847412109, loss=0.22707195580005646
test: epoch 39, loss 0.3227141201496124, acc=0.8444444537162781, loss=0.3227141201496124
train: epoch 40, loss 0.291532963514328, acc=0.8722222447395325, loss=0.291532963514328
test: epoch 40, loss 0.45289766788482666, acc=0.8444444537162781, loss=0.45289766788482666
train: epoch 41, loss 0.20397619903087616, acc=0.8900555372238159, loss=0.20397619903087616
test: epoch 41, loss 0.4820871353149414, acc=0.8444444537162781, loss=0.4820871353149414
train: epoch 42, loss 0.22453570365905762, acc=0.8886666893959045, loss=0.22453570365905762
test: epoch 42, loss 0.44985267519950867, acc=0.8444444537162781, loss=0.44985267519950867
train: epoch 43, loss 0.26549452543258667, acc=0.8808333277702332, loss=0.26549452543258667
test: epoch 43, loss 0.537054181098938, acc=0.8361111283302307, loss=0.537054181098938
train: epoch 44, loss 0.21862846612930298, acc=0.8870555758476257, loss=0.21862846612930298
test: epoch 44, loss 0.4721910357475281, acc=0.8333333134651184, loss=0.4721910357475281
train: epoch 45, loss 0.23938345909118652, acc=0.8857222199440002, loss=0.23938345909118652
test: epoch 45, loss 0.454098641872406, acc=0.8388888835906982, loss=0.454098641872406
train: epoch 46, loss 0.24134276807308197, acc=0.8857222199440002, loss=0.24134276807308197
test: epoch 46, loss 0.4974411129951477, acc=0.8277778029441833, loss=0.4974411129951477
train: epoch 47, loss 0.24504783749580383, acc=0.8873888850212097, loss=0.24504783749580383
test: epoch 47, loss 0.6199014782905579, acc=0.8305555582046509, loss=0.6199014782905579
train: epoch 48, loss 0.2519916594028473, acc=0.8820555806159973, loss=0.2519916594028473
test: epoch 48, loss 0.46261581778526306, acc=0.8416666388511658, loss=0.46261581778526306
train: epoch 49, loss 0.28420954942703247, acc=0.8560555577278137, loss=0.28420954942703247
test: epoch 49, loss 0.4240460693836212, acc=0.8138889074325562, loss=0.4240460693836212
train: epoch 50, loss 0.2398642599582672, acc=0.8788333535194397, loss=0.2398642599582672
test: epoch 50, loss 0.45116424560546875, acc=0.8416666388511658, loss=0.45116424560546875
train: epoch 51, loss 0.24029441177845, acc=0.8875555396080017, loss=0.24029441177845
test: epoch 51, loss 0.770198404788971, acc=0.800000011920929, loss=0.770198404788971
train: epoch 52, loss 0.24389399588108063, acc=0.8902222514152527, loss=0.24389399588108063
test: epoch 52, loss 0.4582524597644806, acc=0.8416666388511658, loss=0.4582524597644806
train: epoch 53, loss 0.2579491138458252, acc=0.8866111040115356, loss=0.2579491138458252
test: epoch 53, loss 0.5105065703392029, acc=0.8333333134651184, loss=0.5105065703392029
train: epoch 54, loss 0.23379261791706085, acc=0.8921666741371155, loss=0.23379261791706085
test: epoch 54, loss 0.49271249771118164, acc=0.8361111283302307, loss=0.49271249771118164
train: epoch 55, loss 0.25073525309562683, acc=0.8821666836738586, loss=0.25073525309562683
test: epoch 55, loss 0.38749995827674866, acc=0.8444444537162781, loss=0.38749995827674866
train: epoch 56, loss 0.2083635926246643, acc=0.8907777667045593, loss=0.2083635926246643
test: epoch 56, loss 0.5464425683021545, acc=0.8416666388511658, loss=0.5464425683021545
train: epoch 57, loss 0.2656898498535156, acc=0.8756111264228821, loss=0.2656898498535156
test: epoch 57, loss 0.38650497794151306, acc=0.8305555582046509, loss=0.38650497794151306
train: epoch 58, loss 0.23250126838684082, acc=0.8841111063957214, loss=0.23250126838684082
test: epoch 58, loss 0.4203393757343292, acc=0.8444444537162781, loss=0.4203393757343292
train: epoch 59, loss 0.2560005187988281, acc=0.8848888874053955, loss=0.2560005187988281
test: epoch 59, loss 0.38279300928115845, acc=0.8388888835906982, loss=0.38279300928115845
train: epoch 60, loss 0.2079600691795349, acc=0.8946666717529297, loss=0.2079600691795349
test: epoch 60, loss 0.37440064549446106, acc=0.8583333492279053, loss=0.37440064549446106
train: epoch 61, loss 0.2089824080467224, acc=0.8955555558204651, loss=0.2089824080467224
test: epoch 61, loss 0.46054908633232117, acc=0.855555534362793, loss=0.46054908633232117
train: epoch 62, loss 0.17917592823505402, acc=0.9038888812065125, loss=0.17917592823505402
test: epoch 62, loss 0.4216462969779968, acc=0.8638888597488403, loss=0.4216462969779968
train: epoch 63, loss 0.24641536176204681, acc=0.8857777714729309, loss=0.24641536176204681
test: epoch 63, loss 0.3871426284313202, acc=0.8527777791023254, loss=0.3871426284313202
train: epoch 64, loss 0.20807147026062012, acc=0.8919444680213928, loss=0.20807147026062012
test: epoch 64, loss 0.5131491422653198, acc=0.8527777791023254, loss=0.5131491422653198
train: epoch 65, loss 0.21855002641677856, acc=0.8856111168861389, loss=0.21855002641677856
test: epoch 65, loss 0.5869545936584473, acc=0.824999988079071, loss=0.5869545936584473
train: epoch 66, loss 0.24429969489574432, acc=0.8762221932411194, loss=0.24429969489574432
test: epoch 66, loss 0.4814894199371338, acc=0.8500000238418579, loss=0.4814894199371338
train: epoch 67, loss 0.2575778365135193, acc=0.8741666674613953, loss=0.2575778365135193
test: epoch 67, loss 0.4210948646068573, acc=0.8305555582046509, loss=0.4210948646068573
train: epoch 68, loss 0.26296964287757874, acc=0.8730555772781372, loss=0.26296964287757874
test: epoch 68, loss 0.4504294693470001, acc=0.8416666388511658, loss=0.4504294693470001
train: epoch 69, loss 0.30348071455955505, acc=0.8639444708824158, loss=0.30348071455955505
test: epoch 69, loss 0.41107118129730225, acc=0.8305555582046509, loss=0.41107118129730225
train: epoch 70, loss 0.25296035408973694, acc=0.8859444260597229, loss=0.25296035408973694
test: epoch 70, loss 0.40225669741630554, acc=0.8527777791023254, loss=0.40225669741630554
train: epoch 71, loss 0.19412124156951904, acc=0.8952222466468811, loss=0.19412124156951904
test: epoch 71, loss 0.41228586435317993, acc=0.8527777791023254, loss=0.41228586435317993
train: epoch 72, loss 0.22977259755134583, acc=0.887499988079071, loss=0.22977259755134583
test: epoch 72, loss 0.47698527574539185, acc=0.8472222089767456, loss=0.47698527574539185
train: epoch 73, loss 0.24499796330928802, acc=0.8818888664245605, loss=0.24499796330928802
test: epoch 73, loss 0.43171828985214233, acc=0.8444444537162781, loss=0.43171828985214233
train: epoch 74, loss 0.24073940515518188, acc=0.878333330154419, loss=0.24073940515518188
test: epoch 74, loss 0.3309248089790344, acc=0.8527777791023254, loss=0.3309248089790344
train: epoch 75, loss 0.2932249903678894, acc=0.8692222237586975, loss=0.2932249903678894
test: epoch 75, loss 0.37357592582702637, acc=0.8472222089767456, loss=0.37357592582702637
train: epoch 76, loss 0.2779938876628876, acc=0.8671666383743286, loss=0.2779938876628876
test: epoch 76, loss 0.4092296361923218, acc=0.8472222089767456, loss=0.4092296361923218
train: epoch 77, loss 0.2615607678890228, acc=0.8692222237586975, loss=0.2615607678890228
test: epoch 77, loss 0.3992459774017334, acc=0.8500000238418579, loss=0.3992459774017334
train: epoch 78, loss 0.2280404418706894, acc=0.8852777481079102, loss=0.2280404418706894
test: epoch 78, loss 0.2144913375377655, acc=0.8888888955116272, loss=0.2144913375377655
train: epoch 79, loss 0.210817351937294, acc=0.8926110863685608, loss=0.210817351937294
test: epoch 79, loss 0.2154662311077118, acc=0.8888888955116272, loss=0.2154662311077118
train: epoch 80, loss 0.20109103620052338, acc=0.8940555453300476, loss=0.20109103620052338
test: epoch 80, loss 0.24875377118587494, acc=0.8888888955116272, loss=0.24875377118587494
train: epoch 81, loss 0.22555406391620636, acc=0.8926666378974915, loss=0.22555406391620636
test: epoch 81, loss 0.22529645264148712, acc=0.8888888955116272, loss=0.22529645264148712
train: epoch 82, loss 0.22455789148807526, acc=0.8914444446563721, loss=0.22455789148807526
test: epoch 82, loss 0.27202531695365906, acc=0.8805555701255798, loss=0.27202531695365906
train: epoch 83, loss 0.2536555230617523, acc=0.887666642665863, loss=0.2536555230617523
test: epoch 83, loss 0.27151745557785034, acc=0.8888888955116272, loss=0.27151745557785034
train: epoch 84, loss 0.22722801566123962, acc=0.8923333287239075, loss=0.22722801566123962
test: epoch 84, loss 0.2529293894767761, acc=0.8888888955116272, loss=0.2529293894767761
train: epoch 85, loss 0.21455416083335876, acc=0.8906111121177673, loss=0.21455416083335876
test: epoch 85, loss 0.2692524492740631, acc=0.8888888955116272, loss=0.2692524492740631
train: epoch 86, loss 0.20789214968681335, acc=0.8941666483879089, loss=0.20789214968681335
test: epoch 86, loss 0.2587276101112366, acc=0.8916666507720947, loss=0.2587276101112366
train: epoch 87, loss 0.2618005573749542, acc=0.886888861656189, loss=0.2618005573749542
test: epoch 87, loss 0.24535994231700897, acc=0.894444465637207, loss=0.24535994231700897
train: epoch 88, loss 0.18527257442474365, acc=0.9002777934074402, loss=0.18527257442474365
test: epoch 88, loss 0.2524457275867462, acc=0.8805555701255798, loss=0.2524457275867462
train: epoch 89, loss 0.2633116543292999, acc=0.8767222166061401, loss=0.2633116543292999
test: epoch 89, loss 0.28756675124168396, acc=0.8777777552604675, loss=0.28756675124168396
train: epoch 90, loss 0.2608366310596466, acc=0.8786110877990723, loss=0.2608366310596466
test: epoch 90, loss 0.38618138432502747, acc=0.875, loss=0.38618138432502747
train: epoch 91, loss 0.3236129879951477, acc=0.8617222309112549, loss=0.3236129879951477
test: epoch 91, loss 0.34455591440200806, acc=0.855555534362793, loss=0.34455591440200806
train: epoch 92, loss 0.3418550193309784, acc=0.863444447517395, loss=0.3418550193309784
test: epoch 92, loss 0.3331793248653412, acc=0.8638888597488403, loss=0.3331793248653412
train: epoch 93, loss 0.3117268681526184, acc=0.870888888835907, loss=0.3117268681526184
test: epoch 93, loss 0.3327581584453583, acc=0.8638888597488403, loss=0.3327581584453583
train: epoch 94, loss 0.30994847416877747, acc=0.8713889122009277, loss=0.30994847416877747
test: epoch 94, loss 0.30680155754089355, acc=0.8722222447395325, loss=0.30680155754089355
train: epoch 95, loss 0.2781102657318115, acc=0.8737778067588806, loss=0.2781102657318115
test: epoch 95, loss 0.3027798533439636, acc=0.8694444298744202, loss=0.3027798533439636
train: epoch 96, loss 0.35585224628448486, acc=0.8517777919769287, loss=0.35585224628448486
test: epoch 96, loss 0.36554789543151855, acc=0.8388888835906982, loss=0.36554789543151855
train: epoch 97, loss 0.36032789945602417, acc=0.8500555753707886, loss=0.36032789945602417
test: epoch 97, loss 0.31976550817489624, acc=0.8611111044883728, loss=0.31976550817489624
train: epoch 98, loss 0.3332536816596985, acc=0.859000027179718, loss=0.3332536816596985
test: epoch 98, loss 0.32854703068733215, acc=0.8583333492279053, loss=0.32854703068733215
train: epoch 99, loss 0.33111175894737244, acc=0.8588888645172119, loss=0.33111175894737244
test: epoch 99, loss 0.3197939097881317, acc=0.8611111044883728, loss=0.3197939097881317
train: epoch 100, loss 0.39463984966278076, acc=0.8437222242355347, loss=0.39463984966278076
test: epoch 100, loss 0.3630349040031433, acc=0.8472222089767456, loss=0.3630349040031433
train: epoch 101, loss 0.3350936770439148, acc=0.8641666769981384, loss=0.3350936770439148
test: epoch 101, loss 0.27031370997428894, acc=0.8805555701255798, loss=0.27031370997428894
train: epoch 102, loss 0.26985323429107666, acc=0.8807777762413025, loss=0.26985323429107666
test: epoch 102, loss 0.3459615707397461, acc=0.8777777552604675, loss=0.3459615707397461
train: epoch 103, loss 0.3372032940387726, acc=0.8672778010368347, loss=0.3372032940387726
test: epoch 103, loss 0.27096277475357056, acc=0.8777777552604675, loss=0.27096277475357056
train: epoch 104, loss 0.25870299339294434, acc=0.8771111369132996, loss=0.25870299339294434
test: epoch 104, loss 0.2385256290435791, acc=0.8888888955116272, loss=0.2385256290435791
train: epoch 105, loss 0.270038902759552, acc=0.8800555467605591, loss=0.270038902759552
test: epoch 105, loss 0.2678053677082062, acc=0.8833333253860474, loss=0.2678053677082062
train: epoch 106, loss 0.2725818455219269, acc=0.8812222480773926, loss=0.2725818455219269
test: epoch 106, loss 0.2794625461101532, acc=0.8916666507720947, loss=0.2794625461101532
train: epoch 107, loss 0.22653698921203613, acc=0.8874444365501404, loss=0.22653698921203613
test: epoch 107, loss 0.2151278257369995, acc=0.8972222208976746, loss=0.2151278257369995
train: epoch 108, loss 0.2168903946876526, acc=0.8897222280502319, loss=0.2168903946876526
test: epoch 108, loss 0.21498915553092957, acc=0.8972222208976746, loss=0.21498915553092957
train: epoch 109, loss 0.22445711493492126, acc=0.8884444236755371, loss=0.22445711493492126
test: epoch 109, loss 0.2846587896347046, acc=0.8888888955116272, loss=0.2846587896347046
train: epoch 110, loss 0.38919174671173096, acc=0.851111114025116, loss=0.38919174671173096
test: epoch 110, loss 0.299442857503891, acc=0.8694444298744202, loss=0.299442857503891
train: epoch 111, loss 0.302798330783844, acc=0.867388904094696, loss=0.302798330783844
test: epoch 111, loss 0.2978799641132355, acc=0.8694444298744202, loss=0.2978799641132355
train: epoch 112, loss 0.2942839562892914, acc=0.8688333630561829, loss=0.2942839562892914
test: epoch 112, loss 0.2867297828197479, acc=0.8722222447395325, loss=0.2867297828197479
train: epoch 113, loss 0.29018741846084595, acc=0.8665555715560913, loss=0.29018741846084595
test: epoch 113, loss 0.28665438294410706, acc=0.8722222447395325, loss=0.28665438294410706
train: epoch 114, loss 0.31272071599960327, acc=0.8657222390174866, loss=0.31272071599960327
test: epoch 114, loss 0.6977488398551941, acc=0.8111110925674438, loss=0.6977488398551941
train: epoch 115, loss 0.5194997787475586, acc=0.8117777705192566, loss=0.5194997787475586
test: epoch 115, loss 0.44446220993995667, acc=0.8222222328186035, loss=0.44446220993995667
train: epoch 116, loss 0.444703608751297, acc=0.819611132144928, loss=0.444703608751297
test: epoch 116, loss 0.42029547691345215, acc=0.824999988079071, loss=0.42029547691345215
train: epoch 117, loss 0.42279601097106934, acc=0.8185555338859558, loss=0.42279601097106934
test: epoch 117, loss 0.41799435019493103, acc=0.824999988079071, loss=0.41799435019493103
train: epoch 118, loss 0.4220150411128998, acc=0.8177777528762817, loss=0.4220150411128998
test: epoch 118, loss 0.41778895258903503, acc=0.824999988079071, loss=0.41778895258903503
train: epoch 119, loss 0.442200630903244, acc=0.832277774810791, loss=0.442200630903244
test: epoch 119, loss 0.3921586871147156, acc=0.8500000238418579, loss=0.3921586871147156
train: epoch 120, loss 0.35822436213493347, acc=0.8604444265365601, loss=0.35822436213493347
test: epoch 120, loss 0.3214101791381836, acc=0.8638888597488403, loss=0.3214101791381836
train: epoch 121, loss 0.3191593885421753, acc=0.8630555272102356, loss=0.3191593885421753
test: epoch 121, loss 0.31207409501075745, acc=0.8666666746139526, loss=0.31207409501075745
train: epoch 122, loss 0.3404253423213959, acc=0.856333315372467, loss=0.3404253423213959
test: epoch 122, loss 0.4276888072490692, acc=0.8444444537162781, loss=0.4276888072490692
train: epoch 123, loss 0.32194584608078003, acc=0.8621110916137695, loss=0.32194584608078003
test: epoch 123, loss 0.31087997555732727, acc=0.8666666746139526, loss=0.31087997555732727
train: epoch 124, loss 0.3136163353919983, acc=0.8646110892295837, loss=0.3136163353919983
test: epoch 124, loss 0.3104803264141083, acc=0.8666666746139526, loss=0.3104803264141083
train: epoch 125, loss 0.3132683038711548, acc=0.8630555272102356, loss=0.3132683038711548
test: epoch 125, loss 0.3103393316268921, acc=0.8666666746139526, loss=0.3103393316268921
train: epoch 126, loss 0.3131025433540344, acc=0.8605555295944214, loss=0.3131025433540344
test: epoch 126, loss 0.3102673590183258, acc=0.8666666746139526, loss=0.3102673590183258
train: epoch 127, loss 0.31292903423309326, acc=0.8599444627761841, loss=0.31292903423309326
test: epoch 127, loss 0.31023868918418884, acc=0.8666666746139526, loss=0.31023868918418884
train: epoch 128, loss 0.31282925605773926, acc=0.8600000143051147, loss=0.31282925605773926
test: epoch 128, loss 0.3104664385318756, acc=0.8666666746139526, loss=0.3104664385318756
train: epoch 129, loss 0.31393104791641235, acc=0.8594444394111633, loss=0.31393104791641235
test: epoch 129, loss 0.31021538376808167, acc=0.8666666746139526, loss=0.31021538376808167
train: epoch 130, loss 0.31293755769729614, acc=0.8595555424690247, loss=0.31293755769729614
test: epoch 130, loss 0.31018176674842834, acc=0.8666666746139526, loss=0.31018176674842834
train: epoch 131, loss 0.4166043698787689, acc=0.8416666388511658, loss=0.4166043698787689
test: epoch 131, loss 0.633271336555481, acc=0.7666666507720947, loss=0.633271336555481
train: epoch 132, loss 0.5410158634185791, acc=0.7731666564941406, loss=0.5410158634185791
test: epoch 132, loss 0.42509618401527405, acc=0.8083333373069763, loss=0.42509618401527405
train: epoch 133, loss 0.5184386372566223, acc=0.781499981880188, loss=0.5184386372566223
test: epoch 133, loss 0.48813408613204956, acc=0.8027777671813965, loss=0.48813408613204956
train: epoch 134, loss 0.4639502465724945, acc=0.79666668176651, loss=0.4639502465724945
test: epoch 134, loss 0.4491923451423645, acc=0.8055555820465088, loss=0.4491923451423645
train: epoch 135, loss 0.4545433819293976, acc=0.7972221970558167, loss=0.4545433819293976
test: epoch 135, loss 0.44872620701789856, acc=0.8055555820465088, loss=0.44872620701789856
train: epoch 136, loss 0.45397019386291504, acc=0.7972221970558167, loss=0.45397019386291504
test: epoch 136, loss 0.448541522026062, acc=0.8055555820465088, loss=0.448541522026062
train: epoch 137, loss 0.46829652786254883, acc=0.7960000038146973, loss=0.46829652786254883
test: epoch 137, loss 0.46527981758117676, acc=0.8083333373069763, loss=0.46527981758117676
train: epoch 138, loss 0.43371817469596863, acc=0.8058888912200928, loss=0.43371817469596863
test: epoch 138, loss 0.41236913204193115, acc=0.8138889074325562, loss=0.41236913204193115
train: epoch 139, loss 0.4324362874031067, acc=0.8069999814033508, loss=0.4324362874031067
test: epoch 139, loss 0.42928510904312134, acc=0.8138889074325562, loss=0.42928510904312134
train: epoch 140, loss 0.4586472809314728, acc=0.8122777938842773, loss=0.4586472809314728
test: epoch 140, loss 0.3587263524532318, acc=0.8472222089767456, loss=0.3587263524532318
train: epoch 141, loss 0.349408894777298, acc=0.8516111373901367, loss=0.349408894777298
test: epoch 141, loss 0.342581182718277, acc=0.8527777791023254, loss=0.342581182718277
train: epoch 142, loss 0.3448837399482727, acc=0.8527777791023254, loss=0.3448837399482727
test: epoch 142, loss 0.34235960245132446, acc=0.8527777791023254, loss=0.34235960245132446
train: epoch 143, loss 0.4253091812133789, acc=0.8332777619361877, loss=0.4253091812133789
test: epoch 143, loss 0.47528398036956787, acc=0.8111110925674438, loss=0.47528398036956787
train: epoch 144, loss 0.4623493552207947, acc=0.8191111087799072, loss=0.4623493552207947
test: epoch 144, loss 0.42413219809532166, acc=0.8333333134651184, loss=0.42413219809532166
train: epoch 145, loss 0.4675323963165283, acc=0.8163333535194397, loss=0.4675323963165283
test: epoch 145, loss 0.4397597014904022, acc=0.8222222328186035, loss=0.4397597014904022
train: epoch 146, loss 0.4649856686592102, acc=0.8211666941642761, loss=0.4649856686592102
test: epoch 146, loss 0.4222552180290222, acc=0.8305555582046509, loss=0.4222552180290222
train: epoch 147, loss 0.4217666685581207, acc=0.8316666483879089, loss=0.4217666685581207
test: epoch 147, loss 0.4109577238559723, acc=0.8333333134651184, loss=0.4109577238559723
train: epoch 148, loss 0.41890379786491394, acc=0.8328889012336731, loss=0.41890379786491394
test: epoch 148, loss 0.4447614252567291, acc=0.8222222328186035, loss=0.4447614252567291
train: epoch 149, loss 0.4494837820529938, acc=0.8195000290870667, loss=0.4494837820529938
test: epoch 149, loss 0.4435156285762787, acc=0.8194444179534912, loss=0.4435156285762787
train: epoch 150, loss 0.45223960280418396, acc=0.8219444155693054, loss=0.45223960280418396
test: epoch 150, loss 0.43125417828559875, acc=0.8333333134651184, loss=0.43125417828559875
