# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=1", "--temp_decay=1", "--one_hot=true", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1321082753, receiver_embed_dim=128, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.349876880645752, acc=0.05322222039103508, loss=3.349876880645752
test: epoch 1, loss 2.664482593536377, acc=0.10277777910232544, loss=2.664482593536377
train: epoch 2, loss 2.0466513633728027, acc=0.20600000023841858, loss=2.0466513633728027
test: epoch 2, loss 2.056398630142212, acc=0.17777778208255768, loss=2.056398630142212
train: epoch 3, loss 1.6806280612945557, acc=0.3054444491863251, loss=1.6806280612945557
test: epoch 3, loss 1.9784801006317139, acc=0.20000000298023224, loss=1.9784801006317139
train: epoch 4, loss 1.5197211503982544, acc=0.36149999499320984, loss=1.5197211503982544
test: epoch 4, loss 2.0670454502105713, acc=0.20555555820465088, loss=2.0670454502105713
train: epoch 5, loss 1.430891752243042, acc=0.3989444375038147, loss=1.430891752243042
test: epoch 5, loss 1.9924547672271729, acc=0.21111111342906952, loss=1.9924547672271729
train: epoch 6, loss 1.349004864692688, acc=0.4339999854564667, loss=1.349004864692688
test: epoch 6, loss 2.0500566959381104, acc=0.21388888359069824, loss=2.0500566959381104
train: epoch 7, loss 1.2987141609191895, acc=0.45399999618530273, loss=1.2987141609191895
test: epoch 7, loss 1.9135949611663818, acc=0.25555557012557983, loss=1.9135949611663818
train: epoch 8, loss 1.2392282485961914, acc=0.4741111099720001, loss=1.2392282485961914
test: epoch 8, loss 1.956094741821289, acc=0.25, loss=1.956094741821289
train: epoch 9, loss 1.2121928930282593, acc=0.4896666705608368, loss=1.2121928930282593
test: epoch 9, loss 2.0495545864105225, acc=0.24722221493721008, loss=2.0495545864105225
train: epoch 10, loss 1.1757725477218628, acc=0.5068333148956299, loss=1.1757725477218628
test: epoch 10, loss 1.9382399320602417, acc=0.2666666805744171, loss=1.9382399320602417
train: epoch 11, loss 1.1404790878295898, acc=0.5163888931274414, loss=1.1404790878295898
test: epoch 11, loss 1.9614149332046509, acc=0.25833332538604736, loss=1.9614149332046509
train: epoch 12, loss 1.113971471786499, acc=0.5304444432258606, loss=1.113971471786499
test: epoch 12, loss 2.026719331741333, acc=0.2666666805744171, loss=2.026719331741333
train: epoch 13, loss 1.0773588418960571, acc=0.550777792930603, loss=1.0773588418960571
test: epoch 13, loss 2.0180342197418213, acc=0.2666666805744171, loss=2.0180342197418213
train: epoch 14, loss 1.0411150455474854, acc=0.5610555410385132, loss=1.0411150455474854
test: epoch 14, loss 2.079169273376465, acc=0.28333333134651184, loss=2.079169273376465
train: epoch 15, loss 1.0300695896148682, acc=0.566944420337677, loss=1.0300695896148682
test: epoch 15, loss 2.1865062713623047, acc=0.27222222089767456, loss=2.1865062713623047
train: epoch 16, loss 0.9895551800727844, acc=0.5843333601951599, loss=0.9895551800727844
test: epoch 16, loss 2.190244674682617, acc=0.2805555462837219, loss=2.190244674682617
train: epoch 17, loss 0.9815841913223267, acc=0.5849999785423279, loss=0.9815841913223267
test: epoch 17, loss 2.013245105743408, acc=0.2805555462837219, loss=2.013245105743408
train: epoch 18, loss 0.9551352858543396, acc=0.5924999713897705, loss=0.9551352858543396
test: epoch 18, loss 2.2764804363250732, acc=0.2888889014720917, loss=2.2764804363250732
train: epoch 19, loss 0.9600023627281189, acc=0.5944444537162781, loss=0.9600023627281189
test: epoch 19, loss 2.019907236099243, acc=0.2944444417953491, loss=2.019907236099243
train: epoch 20, loss 0.9448359608650208, acc=0.597777783870697, loss=0.9448359608650208
test: epoch 20, loss 2.218135356903076, acc=0.28333333134651184, loss=2.218135356903076
train: epoch 21, loss 0.9321261048316956, acc=0.6000555753707886, loss=0.9321261048316956
test: epoch 21, loss 2.1564457416534424, acc=0.2888889014720917, loss=2.1564457416534424
train: epoch 22, loss 0.9292200803756714, acc=0.6007221937179565, loss=0.9292200803756714
test: epoch 22, loss 2.0698893070220947, acc=0.2888889014720917, loss=2.0698893070220947
train: epoch 23, loss 0.8990558981895447, acc=0.6113888621330261, loss=0.8990558981895447
test: epoch 23, loss 2.3090970516204834, acc=0.29722222685813904, loss=2.3090970516204834
train: epoch 24, loss 0.8969178199768066, acc=0.6113333106040955, loss=0.8969178199768066
test: epoch 24, loss 2.200883626937866, acc=0.29722222685813904, loss=2.200883626937866
train: epoch 25, loss 0.878847599029541, acc=0.6201666593551636, loss=0.878847599029541
test: epoch 25, loss 2.2056875228881836, acc=0.2916666567325592, loss=2.2056875228881836
train: epoch 26, loss 0.8749112486839294, acc=0.617888867855072, loss=0.8749112486839294
test: epoch 26, loss 2.153533935546875, acc=0.3055555522441864, loss=2.153533935546875
train: epoch 27, loss 0.8848134279251099, acc=0.6183333396911621, loss=0.8848134279251099
test: epoch 27, loss 2.3003933429718018, acc=0.3083333373069763, loss=2.3003933429718018
train: epoch 28, loss 0.8760647177696228, acc=0.6199444532394409, loss=0.8760647177696228
test: epoch 28, loss 2.1674933433532715, acc=0.3083333373069763, loss=2.1674933433532715
train: epoch 29, loss 0.868970513343811, acc=0.6216111183166504, loss=0.868970513343811
test: epoch 29, loss 2.146397113800049, acc=0.3083333373069763, loss=2.146397113800049
train: epoch 30, loss 0.8499529957771301, acc=0.628166675567627, loss=0.8499529957771301
test: epoch 30, loss 2.362194061279297, acc=0.31111112236976624, loss=2.362194061279297
train: epoch 31, loss 0.8533177375793457, acc=0.6282777786254883, loss=0.8533177375793457
test: epoch 31, loss 2.3459270000457764, acc=0.3083333373069763, loss=2.3459270000457764
train: epoch 32, loss 0.856193482875824, acc=0.6241666674613953, loss=0.856193482875824
test: epoch 32, loss 2.1788668632507324, acc=0.31111112236976624, loss=2.1788668632507324
train: epoch 33, loss 0.8412135243415833, acc=0.6278889179229736, loss=0.8412135243415833
test: epoch 33, loss 2.1999335289001465, acc=0.31111112236976624, loss=2.1999335289001465
train: epoch 34, loss 0.8437581062316895, acc=0.6301110982894897, loss=0.8437581062316895
test: epoch 34, loss 2.1582419872283936, acc=0.3222222328186035, loss=2.1582419872283936
train: epoch 35, loss 0.8476939797401428, acc=0.6253888607025146, loss=0.8476939797401428
test: epoch 35, loss 2.1282594203948975, acc=0.3166666626930237, loss=2.1282594203948975
train: epoch 36, loss 0.8381548523902893, acc=0.6355555653572083, loss=0.8381548523902893
test: epoch 36, loss 2.1903860569000244, acc=0.31111112236976624, loss=2.1903860569000244
train: epoch 37, loss 0.8320963978767395, acc=0.633055567741394, loss=0.8320963978767395
test: epoch 37, loss 2.0939981937408447, acc=0.3166666626930237, loss=2.0939981937408447
train: epoch 38, loss 0.8254067897796631, acc=0.6370000243186951, loss=0.8254067897796631
test: epoch 38, loss 2.2816195487976074, acc=0.3166666626930237, loss=2.2816195487976074
train: epoch 39, loss 0.8211768269538879, acc=0.6411111354827881, loss=0.8211768269538879
test: epoch 39, loss 2.2191755771636963, acc=0.3194444477558136, loss=2.2191755771636963
train: epoch 40, loss 0.8065597414970398, acc=0.6466110944747925, loss=0.8065597414970398
test: epoch 40, loss 2.39274001121521, acc=0.3222222328186035, loss=2.39274001121521
train: epoch 41, loss 0.8208240270614624, acc=0.6398333311080933, loss=0.8208240270614624
test: epoch 41, loss 2.4084677696228027, acc=0.3222222328186035, loss=2.4084677696228027
train: epoch 42, loss 0.8184388279914856, acc=0.6413888931274414, loss=0.8184388279914856
test: epoch 42, loss 2.2843432426452637, acc=0.3194444477558136, loss=2.2843432426452637
train: epoch 43, loss 0.8185040354728699, acc=0.6424999833106995, loss=0.8185040354728699
test: epoch 43, loss 2.3153088092803955, acc=0.3166666626930237, loss=2.3153088092803955
train: epoch 44, loss 0.8104531168937683, acc=0.6428333520889282, loss=0.8104531168937683
test: epoch 44, loss 2.3588032722473145, acc=0.3222222328186035, loss=2.3588032722473145
train: epoch 45, loss 0.7984605431556702, acc=0.6483333110809326, loss=0.7984605431556702
test: epoch 45, loss 2.6171722412109375, acc=0.3222222328186035, loss=2.6171722412109375
train: epoch 46, loss 0.8033621907234192, acc=0.644777774810791, loss=0.8033621907234192
test: epoch 46, loss 2.2827999591827393, acc=0.3222222328186035, loss=2.2827999591827393
train: epoch 47, loss 0.8003902435302734, acc=0.6493889093399048, loss=0.8003902435302734
test: epoch 47, loss 2.233609437942505, acc=0.32499998807907104, loss=2.233609437942505
train: epoch 48, loss 0.8026688694953918, acc=0.644777774810791, loss=0.8026688694953918
test: epoch 48, loss 2.382983684539795, acc=0.3166666626930237, loss=2.382983684539795
train: epoch 49, loss 0.797146737575531, acc=0.6459444165229797, loss=0.797146737575531
test: epoch 49, loss 2.3041677474975586, acc=0.32499998807907104, loss=2.3041677474975586
train: epoch 50, loss 0.8057489395141602, acc=0.6472777724266052, loss=0.8057489395141602
test: epoch 50, loss 2.38639235496521, acc=0.32499998807907104, loss=2.38639235496521
train: epoch 51, loss 0.7964513897895813, acc=0.6475555300712585, loss=0.7964513897895813
test: epoch 51, loss 2.299459218978882, acc=0.32499998807907104, loss=2.299459218978882
train: epoch 52, loss 0.7902868390083313, acc=0.6496666669845581, loss=0.7902868390083313
test: epoch 52, loss 2.469702959060669, acc=0.3361110985279083, loss=2.469702959060669
train: epoch 53, loss 0.7893111109733582, acc=0.6472222208976746, loss=0.7893111109733582
test: epoch 53, loss 2.502376079559326, acc=0.3305555582046509, loss=2.502376079559326
train: epoch 54, loss 0.7857964038848877, acc=0.652388870716095, loss=0.7857964038848877
test: epoch 54, loss 2.57692813873291, acc=0.3305555582046509, loss=2.57692813873291
train: epoch 55, loss 0.7990558743476868, acc=0.6474999785423279, loss=0.7990558743476868
test: epoch 55, loss 2.2198827266693115, acc=0.3222222328186035, loss=2.2198827266693115
train: epoch 56, loss 0.7895382046699524, acc=0.648888885974884, loss=0.7895382046699524
test: epoch 56, loss 2.2638964653015137, acc=0.3305555582046509, loss=2.2638964653015137
train: epoch 57, loss 0.7835972309112549, acc=0.6531111001968384, loss=0.7835972309112549
test: epoch 57, loss 2.3592922687530518, acc=0.3361110985279083, loss=2.3592922687530518
train: epoch 58, loss 0.7896645069122314, acc=0.6511111259460449, loss=0.7896645069122314
test: epoch 58, loss 2.456364393234253, acc=0.3333333432674408, loss=2.456364393234253
train: epoch 59, loss 0.7810260653495789, acc=0.6510555744171143, loss=0.7810260653495789
test: epoch 59, loss 2.4863152503967285, acc=0.3305555582046509, loss=2.4863152503967285
train: epoch 60, loss 0.7762476801872253, acc=0.6527777910232544, loss=0.7762476801872253
test: epoch 60, loss 2.3648581504821777, acc=0.3305555582046509, loss=2.3648581504821777
train: epoch 61, loss 0.7920082211494446, acc=0.6513333320617676, loss=0.7920082211494446
test: epoch 61, loss 2.48294997215271, acc=0.3305555582046509, loss=2.48294997215271
train: epoch 62, loss 0.784698486328125, acc=0.6506666541099548, loss=0.784698486328125
test: epoch 62, loss 2.3282487392425537, acc=0.3305555582046509, loss=2.3282487392425537
train: epoch 63, loss 0.7801589369773865, acc=0.6564444303512573, loss=0.7801589369773865
test: epoch 63, loss 2.2890729904174805, acc=0.32777777314186096, loss=2.2890729904174805
train: epoch 64, loss 0.7809637188911438, acc=0.6557222008705139, loss=0.7809637188911438
test: epoch 64, loss 2.294060468673706, acc=0.3222222328186035, loss=2.294060468673706
train: epoch 65, loss 0.7760398387908936, acc=0.6526111364364624, loss=0.7760398387908936
test: epoch 65, loss 2.298691987991333, acc=0.3361110985279083, loss=2.298691987991333
train: epoch 66, loss 0.770295262336731, acc=0.6554444432258606, loss=0.770295262336731
test: epoch 66, loss 2.370993137359619, acc=0.3444444537162781, loss=2.370993137359619
train: epoch 67, loss 0.7788308262825012, acc=0.6536111235618591, loss=0.7788308262825012
test: epoch 67, loss 2.343458890914917, acc=0.3361110985279083, loss=2.343458890914917
train: epoch 68, loss 0.7776631712913513, acc=0.6530555486679077, loss=0.7776631712913513
test: epoch 68, loss 2.970710039138794, acc=0.34166666865348816, loss=2.970710039138794
train: epoch 69, loss 0.7811892032623291, acc=0.655055582523346, loss=0.7811892032623291
test: epoch 69, loss 2.409682512283325, acc=0.3444444537162781, loss=2.409682512283325
train: epoch 70, loss 0.7689138054847717, acc=0.6572777628898621, loss=0.7689138054847717
test: epoch 70, loss 2.1743085384368896, acc=0.33888888359069824, loss=2.1743085384368896
train: epoch 71, loss 0.7678943276405334, acc=0.6579444408416748, loss=0.7678943276405334
test: epoch 71, loss 2.5437774658203125, acc=0.3499999940395355, loss=2.5437774658203125
train: epoch 72, loss 0.7580958604812622, acc=0.6618333458900452, loss=0.7580958604812622
test: epoch 72, loss 2.238809823989868, acc=0.34166666865348816, loss=2.238809823989868
train: epoch 73, loss 0.7670985460281372, acc=0.6557777523994446, loss=0.7670985460281372
test: epoch 73, loss 2.348921060562134, acc=0.34166666865348816, loss=2.348921060562134
train: epoch 74, loss 0.7555506229400635, acc=0.6653333306312561, loss=0.7555506229400635
test: epoch 74, loss 2.4507791996002197, acc=0.3444444537162781, loss=2.4507791996002197
train: epoch 75, loss 0.7641614675521851, acc=0.6625000238418579, loss=0.7641614675521851
test: epoch 75, loss 2.695486068725586, acc=0.3444444537162781, loss=2.695486068725586
train: epoch 76, loss 0.7539625763893127, acc=0.6604999899864197, loss=0.7539625763893127
test: epoch 76, loss 2.588874340057373, acc=0.3444444537162781, loss=2.588874340057373
train: epoch 77, loss 0.7689764499664307, acc=0.6551111340522766, loss=0.7689764499664307
test: epoch 77, loss 2.45597243309021, acc=0.3444444537162781, loss=2.45597243309021
train: epoch 78, loss 0.7557147741317749, acc=0.6625000238418579, loss=0.7557147741317749
test: epoch 78, loss 2.4601824283599854, acc=0.3444444537162781, loss=2.4601824283599854
train: epoch 79, loss 0.759631872177124, acc=0.6585000157356262, loss=0.759631872177124
test: epoch 79, loss 2.5764095783233643, acc=0.3444444537162781, loss=2.5764095783233643
train: epoch 80, loss 0.7574126720428467, acc=0.6631110906600952, loss=0.7574126720428467
test: epoch 80, loss 2.355039358139038, acc=0.34166666865348816, loss=2.355039358139038
train: epoch 81, loss 0.7585596442222595, acc=0.6589444279670715, loss=0.7585596442222595
test: epoch 81, loss 2.395263433456421, acc=0.3444444537162781, loss=2.395263433456421
train: epoch 82, loss 0.7622957229614258, acc=0.6608333587646484, loss=0.7622957229614258
test: epoch 82, loss 2.224442958831787, acc=0.3444444537162781, loss=2.224442958831787
train: epoch 83, loss 0.7502440214157104, acc=0.6622777581214905, loss=0.7502440214157104
test: epoch 83, loss 2.341435432434082, acc=0.3444444537162781, loss=2.341435432434082
train: epoch 84, loss 0.7603009939193726, acc=0.6631110906600952, loss=0.7603009939193726
test: epoch 84, loss 2.326568603515625, acc=0.3444444537162781, loss=2.326568603515625
train: epoch 85, loss 0.757839024066925, acc=0.6625000238418579, loss=0.757839024066925
test: epoch 85, loss 2.2037103176116943, acc=0.3472222089767456, loss=2.2037103176116943
train: epoch 86, loss 0.7529200315475464, acc=0.6714444160461426, loss=0.7529200315475464
test: epoch 86, loss 2.5013444423675537, acc=0.3444444537162781, loss=2.5013444423675537
train: epoch 87, loss 0.7461754083633423, acc=0.668833315372467, loss=0.7461754083633423
test: epoch 87, loss 2.361398935317993, acc=0.34166666865348816, loss=2.361398935317993
train: epoch 88, loss 0.7519695162773132, acc=0.663611114025116, loss=0.7519695162773132
test: epoch 88, loss 2.6120047569274902, acc=0.34166666865348816, loss=2.6120047569274902
train: epoch 89, loss 0.7487013936042786, acc=0.6618888974189758, loss=0.7487013936042786
test: epoch 89, loss 2.4497926235198975, acc=0.34166666865348816, loss=2.4497926235198975
train: epoch 90, loss 0.7405548095703125, acc=0.6644999980926514, loss=0.7405548095703125
test: epoch 90, loss 2.4480037689208984, acc=0.33888888359069824, loss=2.4480037689208984
train: epoch 91, loss 0.743110716342926, acc=0.6697777509689331, loss=0.743110716342926
test: epoch 91, loss 2.342728853225708, acc=0.3499999940395355, loss=2.342728853225708
train: epoch 92, loss 0.751370906829834, acc=0.6585555672645569, loss=0.751370906829834
test: epoch 92, loss 2.3401060104370117, acc=0.3444444537162781, loss=2.3401060104370117
train: epoch 93, loss 0.7332409620285034, acc=0.6740555763244629, loss=0.7332409620285034
test: epoch 93, loss 2.2763137817382812, acc=0.3444444537162781, loss=2.2763137817382812
train: epoch 94, loss 0.7501665949821472, acc=0.6646666526794434, loss=0.7501665949821472
test: epoch 94, loss 2.7682034969329834, acc=0.3499999940395355, loss=2.7682034969329834
train: epoch 95, loss 0.732901394367218, acc=0.6694444417953491, loss=0.732901394367218
test: epoch 95, loss 2.285706043243408, acc=0.3499999940395355, loss=2.285706043243408
train: epoch 96, loss 0.7375612854957581, acc=0.6697777509689331, loss=0.7375612854957581
test: epoch 96, loss 2.330803155899048, acc=0.3499999940395355, loss=2.330803155899048
train: epoch 97, loss 0.7370597124099731, acc=0.6657222509384155, loss=0.7370597124099731
test: epoch 97, loss 2.3531436920166016, acc=0.3472222089767456, loss=2.3531436920166016
train: epoch 98, loss 0.7359065413475037, acc=0.6679999828338623, loss=0.7359065413475037
test: epoch 98, loss 2.408850908279419, acc=0.3444444537162781, loss=2.408850908279419
train: epoch 99, loss 0.739606499671936, acc=0.667388916015625, loss=0.739606499671936
test: epoch 99, loss 2.509192943572998, acc=0.3499999940395355, loss=2.509192943572998
train: epoch 100, loss 0.7283267378807068, acc=0.6725000143051147, loss=0.7283267378807068
test: epoch 100, loss 2.1894686222076416, acc=0.3444444537162781, loss=2.1894686222076416
train: epoch 101, loss 0.7370378375053406, acc=0.6674444675445557, loss=0.7370378375053406
test: epoch 101, loss 2.50175142288208, acc=0.3499999940395355, loss=2.50175142288208
train: epoch 102, loss 0.7346823215484619, acc=0.6676111221313477, loss=0.7346823215484619
test: epoch 102, loss 2.5304806232452393, acc=0.35555556416511536, loss=2.5304806232452393
train: epoch 103, loss 0.7264691591262817, acc=0.6713888645172119, loss=0.7264691591262817
test: epoch 103, loss 2.7193448543548584, acc=0.3499999940395355, loss=2.7193448543548584
train: epoch 104, loss 0.7289644479751587, acc=0.6707777976989746, loss=0.7289644479751587
test: epoch 104, loss 2.17032790184021, acc=0.35277777910232544, loss=2.17032790184021
train: epoch 105, loss 0.738934338092804, acc=0.667555570602417, loss=0.738934338092804
test: epoch 105, loss 2.3319590091705322, acc=0.3499999940395355, loss=2.3319590091705322
train: epoch 106, loss 0.7356132864952087, acc=0.6695555448532104, loss=0.7356132864952087
test: epoch 106, loss 2.4487075805664062, acc=0.3583333194255829, loss=2.4487075805664062
train: epoch 107, loss 0.7220261693000793, acc=0.6765000224113464, loss=0.7220261693000793
test: epoch 107, loss 2.304567575454712, acc=0.3499999940395355, loss=2.304567575454712
train: epoch 108, loss 0.739862322807312, acc=0.6683889031410217, loss=0.739862322807312
test: epoch 108, loss 2.4157142639160156, acc=0.3499999940395355, loss=2.4157142639160156
train: epoch 109, loss 0.7320502996444702, acc=0.6722221970558167, loss=0.7320502996444702
test: epoch 109, loss 2.2969424724578857, acc=0.3499999940395355, loss=2.2969424724578857
train: epoch 110, loss 0.732284426689148, acc=0.6718888878822327, loss=0.732284426689148
test: epoch 110, loss 2.4842028617858887, acc=0.3499999940395355, loss=2.4842028617858887
train: epoch 111, loss 0.7249012589454651, acc=0.6720555424690247, loss=0.7249012589454651
test: epoch 111, loss 2.3215231895446777, acc=0.35277777910232544, loss=2.3215231895446777
train: epoch 112, loss 0.7277328968048096, acc=0.6713888645172119, loss=0.7277328968048096
test: epoch 112, loss 2.626955986022949, acc=0.3472222089767456, loss=2.626955986022949
train: epoch 113, loss 0.726858913898468, acc=0.6734444499015808, loss=0.726858913898468
test: epoch 113, loss 2.411189556121826, acc=0.3499999940395355, loss=2.411189556121826
train: epoch 114, loss 0.7367085814476013, acc=0.6690000295639038, loss=0.7367085814476013
test: epoch 114, loss 2.479013681411743, acc=0.35277777910232544, loss=2.479013681411743
train: epoch 115, loss 0.7355128526687622, acc=0.6729999780654907, loss=0.7355128526687622
test: epoch 115, loss 2.292666435241699, acc=0.35277777910232544, loss=2.292666435241699
train: epoch 116, loss 0.7296689748764038, acc=0.6711666584014893, loss=0.7296689748764038
test: epoch 116, loss 2.311718702316284, acc=0.35277777910232544, loss=2.311718702316284
train: epoch 117, loss 0.7338806986808777, acc=0.6678333282470703, loss=0.7338806986808777
test: epoch 117, loss 2.311950922012329, acc=0.35277777910232544, loss=2.311950922012329
train: epoch 118, loss 0.7161555290222168, acc=0.6762222051620483, loss=0.7161555290222168
test: epoch 118, loss 2.229389190673828, acc=0.35277777910232544, loss=2.229389190673828
train: epoch 119, loss 0.709613561630249, acc=0.6765000224113464, loss=0.709613561630249
test: epoch 119, loss 2.3855998516082764, acc=0.3472222089767456, loss=2.3855998516082764
train: epoch 120, loss 0.7197485566139221, acc=0.6779999732971191, loss=0.7197485566139221
test: epoch 120, loss 2.169750213623047, acc=0.35277777910232544, loss=2.169750213623047
train: epoch 121, loss 0.7272923588752747, acc=0.6711111068725586, loss=0.7272923588752747
test: epoch 121, loss 2.5534985065460205, acc=0.3583333194255829, loss=2.5534985065460205
train: epoch 122, loss 0.7224161624908447, acc=0.675000011920929, loss=0.7224161624908447
test: epoch 122, loss 2.3830983638763428, acc=0.35277777910232544, loss=2.3830983638763428
train: epoch 123, loss 0.711790919303894, acc=0.679722249507904, loss=0.711790919303894
test: epoch 123, loss 2.379946708679199, acc=0.35277777910232544, loss=2.379946708679199
train: epoch 124, loss 0.7268339991569519, acc=0.6704999804496765, loss=0.7268339991569519
test: epoch 124, loss 2.35275936126709, acc=0.3499999940395355, loss=2.35275936126709
train: epoch 125, loss 0.7159352898597717, acc=0.6784999966621399, loss=0.7159352898597717
test: epoch 125, loss 2.632758378982544, acc=0.35277777910232544, loss=2.632758378982544
train: epoch 126, loss 0.7188646197319031, acc=0.6736111044883728, loss=0.7188646197319031
test: epoch 126, loss 2.32592511177063, acc=0.35277777910232544, loss=2.32592511177063
train: epoch 127, loss 0.7237294316291809, acc=0.6763333082199097, loss=0.7237294316291809
test: epoch 127, loss 2.5527944564819336, acc=0.35277777910232544, loss=2.5527944564819336
train: epoch 128, loss 0.7164450883865356, acc=0.6791666746139526, loss=0.7164450883865356
test: epoch 128, loss 2.24725341796875, acc=0.3499999940395355, loss=2.24725341796875
train: epoch 129, loss 0.7156637907028198, acc=0.6772778034210205, loss=0.7156637907028198
test: epoch 129, loss 2.5729241371154785, acc=0.35277777910232544, loss=2.5729241371154785
train: epoch 130, loss 0.7205960154533386, acc=0.6753333210945129, loss=0.7205960154533386
test: epoch 130, loss 2.4531807899475098, acc=0.35555556416511536, loss=2.4531807899475098
train: epoch 131, loss 0.7166865468025208, acc=0.6740555763244629, loss=0.7166865468025208
test: epoch 131, loss 2.2660064697265625, acc=0.35277777910232544, loss=2.2660064697265625
train: epoch 132, loss 0.7129525542259216, acc=0.6778333187103271, loss=0.7129525542259216
test: epoch 132, loss 2.4531514644622803, acc=0.3583333194255829, loss=2.4531514644622803
train: epoch 133, loss 0.7183976173400879, acc=0.674833357334137, loss=0.7183976173400879
test: epoch 133, loss 2.6758217811584473, acc=0.35555556416511536, loss=2.6758217811584473
train: epoch 134, loss 0.7146787643432617, acc=0.6753888726234436, loss=0.7146787643432617
test: epoch 134, loss 2.4807827472686768, acc=0.35555556416511536, loss=2.4807827472686768
train: epoch 135, loss 0.7163129448890686, acc=0.6736666560173035, loss=0.7163129448890686
test: epoch 135, loss 2.392561912536621, acc=0.35277777910232544, loss=2.392561912536621
train: epoch 136, loss 0.7064592242240906, acc=0.67894446849823, loss=0.7064592242240906
test: epoch 136, loss 2.7754249572753906, acc=0.35555556416511536, loss=2.7754249572753906
train: epoch 137, loss 0.7090959548950195, acc=0.6793888807296753, loss=0.7090959548950195
test: epoch 137, loss 2.4038455486297607, acc=0.35555556416511536, loss=2.4038455486297607
train: epoch 138, loss 0.7112952470779419, acc=0.675000011920929, loss=0.7112952470779419
test: epoch 138, loss 2.2509217262268066, acc=0.35555556416511536, loss=2.2509217262268066
train: epoch 139, loss 0.7107766270637512, acc=0.6747221946716309, loss=0.7107766270637512
test: epoch 139, loss 2.4700934886932373, acc=0.35555556416511536, loss=2.4700934886932373
train: epoch 140, loss 0.7131279706954956, acc=0.6783888936042786, loss=0.7131279706954956
test: epoch 140, loss 2.4427578449249268, acc=0.35555556416511536, loss=2.4427578449249268
train: epoch 141, loss 0.7136822938919067, acc=0.6775000095367432, loss=0.7136822938919067
test: epoch 141, loss 2.5311546325683594, acc=0.35555556416511536, loss=2.5311546325683594
train: epoch 142, loss 0.7043214440345764, acc=0.6776666641235352, loss=0.7043214440345764
test: epoch 142, loss 2.4367663860321045, acc=0.35277777910232544, loss=2.4367663860321045
train: epoch 143, loss 0.7156227231025696, acc=0.6778333187103271, loss=0.7156227231025696
test: epoch 143, loss 2.488426685333252, acc=0.35555556416511536, loss=2.488426685333252
train: epoch 144, loss 0.7107404470443726, acc=0.6783888936042786, loss=0.7107404470443726
test: epoch 144, loss 2.3592112064361572, acc=0.35555556416511536, loss=2.3592112064361572
train: epoch 145, loss 0.7131692171096802, acc=0.679277777671814, loss=0.7131692171096802
test: epoch 145, loss 2.616584539413452, acc=0.3499999940395355, loss=2.616584539413452
train: epoch 146, loss 0.7208065390586853, acc=0.6779444217681885, loss=0.7208065390586853
test: epoch 146, loss 2.433769464492798, acc=0.35277777910232544, loss=2.433769464492798
train: epoch 147, loss 0.7118970155715942, acc=0.679888904094696, loss=0.7118970155715942
test: epoch 147, loss 2.568270683288574, acc=0.35555556416511536, loss=2.568270683288574
train: epoch 148, loss 0.7124632596969604, acc=0.6786110997200012, loss=0.7124632596969604
test: epoch 148, loss 2.2860569953918457, acc=0.35555556416511536, loss=2.2860569953918457
train: epoch 149, loss 0.7033871412277222, acc=0.6801111102104187, loss=0.7033871412277222
test: epoch 149, loss 2.260082960128784, acc=0.3638888895511627, loss=2.260082960128784
train: epoch 150, loss 0.7038054466247559, acc=0.6807222366333008, loss=0.7038054466247559
test: epoch 150, loss 2.3168845176696777, acc=0.3499999940395355, loss=2.3168845176696777
