# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=true", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=667243277, receiver_embed_dim=32, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.097165107727051, acc=0.06822222471237183, loss=3.097165107727051
test: epoch 1, loss 3.6940736770629883, acc=0.07777778059244156, loss=3.6940736770629883
train: epoch 2, loss 2.2261810302734375, acc=0.17811110615730286, loss=2.2261810302734375
test: epoch 2, loss 3.3010566234588623, acc=0.13611111044883728, loss=3.3010566234588623
train: epoch 3, loss 1.8261831998825073, acc=0.2606111168861389, loss=1.8261831998825073
test: epoch 3, loss 3.300234794616699, acc=0.15555556118488312, loss=3.300234794616699
train: epoch 4, loss 1.6144976615905762, acc=0.3195555508136749, loss=1.6144976615905762
test: epoch 4, loss 2.7223832607269287, acc=0.17777778208255768, loss=2.7223832607269287
train: epoch 5, loss 1.471877098083496, acc=0.36177778244018555, loss=1.471877098083496
test: epoch 5, loss 2.2473795413970947, acc=0.25, loss=2.2473795413970947
train: epoch 6, loss 1.3485801219940186, acc=0.3927222192287445, loss=1.3485801219940186
test: epoch 6, loss 2.3051822185516357, acc=0.24444444477558136, loss=2.3051822185516357
train: epoch 7, loss 1.270789384841919, acc=0.4258333444595337, loss=1.270789384841919
test: epoch 7, loss 1.9050877094268799, acc=0.3027777671813965, loss=1.9050877094268799
train: epoch 8, loss 1.1976728439331055, acc=0.4546111226081848, loss=1.1976728439331055
test: epoch 8, loss 1.9143108129501343, acc=0.2777777910232544, loss=1.9143108129501343
train: epoch 9, loss 1.1210477352142334, acc=0.49300000071525574, loss=1.1210477352142334
test: epoch 9, loss 2.0621519088745117, acc=0.32499998807907104, loss=2.0621519088745117
train: epoch 10, loss 1.0391998291015625, acc=0.5271111130714417, loss=1.0391998291015625
test: epoch 10, loss 2.123520851135254, acc=0.32499998807907104, loss=2.123520851135254
train: epoch 11, loss 0.9988203048706055, acc=0.5569999814033508, loss=0.9988203048706055
test: epoch 11, loss 1.5677554607391357, acc=0.4138889014720917, loss=1.5677554607391357
train: epoch 12, loss 0.8967944979667664, acc=0.5984444618225098, loss=0.8967944979667664
test: epoch 12, loss 1.922491192817688, acc=0.35277777910232544, loss=1.922491192817688
train: epoch 13, loss 0.8149092793464661, acc=0.6474999785423279, loss=0.8149092793464661
test: epoch 13, loss 1.3444695472717285, acc=0.5083333253860474, loss=1.3444695472717285
train: epoch 14, loss 0.7261189222335815, acc=0.6783333420753479, loss=0.7261189222335815
test: epoch 14, loss 1.270808219909668, acc=0.4833333194255829, loss=1.270808219909668
train: epoch 15, loss 0.6954783201217651, acc=0.6981666684150696, loss=0.6954783201217651
test: epoch 15, loss 1.3338539600372314, acc=0.47777777910232544, loss=1.3338539600372314
train: epoch 16, loss 0.5838873386383057, acc=0.7502222061157227, loss=0.5838873386383057
test: epoch 16, loss 1.5876728296279907, acc=0.48055556416511536, loss=1.5876728296279907
train: epoch 17, loss 0.5295425653457642, acc=0.7699999809265137, loss=0.5295425653457642
test: epoch 17, loss 1.1531744003295898, acc=0.5611110925674438, loss=1.1531744003295898
train: epoch 18, loss 0.5071136355400085, acc=0.7778888940811157, loss=0.5071136355400085
test: epoch 18, loss 0.9571901559829712, acc=0.5611110925674438, loss=0.9571901559829712
train: epoch 19, loss 0.4540773630142212, acc=0.7991666793823242, loss=0.4540773630142212
test: epoch 19, loss 1.1772538423538208, acc=0.519444465637207, loss=1.1772538423538208
train: epoch 20, loss 0.4746575653553009, acc=0.7917222380638123, loss=0.4746575653553009
test: epoch 20, loss 1.0493824481964111, acc=0.5444444417953491, loss=1.0493824481964111
train: epoch 21, loss 0.41961097717285156, acc=0.8117777705192566, loss=0.41961097717285156
test: epoch 21, loss 1.1090278625488281, acc=0.5611110925674438, loss=1.1090278625488281
train: epoch 22, loss 0.4416893720626831, acc=0.809166669845581, loss=0.4416893720626831
test: epoch 22, loss 1.268519401550293, acc=0.5722222328186035, loss=1.268519401550293
train: epoch 23, loss 0.4160318970680237, acc=0.8183333277702332, loss=0.4160318970680237
test: epoch 23, loss 1.1370956897735596, acc=0.5972222089767456, loss=1.1370956897735596
train: epoch 24, loss 0.37033891677856445, acc=0.8412777781486511, loss=0.37033891677856445
test: epoch 24, loss 1.4304251670837402, acc=0.5666666626930237, loss=1.4304251670837402
train: epoch 25, loss 0.3646508753299713, acc=0.8430555462837219, loss=0.3646508753299713
test: epoch 25, loss 1.1259088516235352, acc=0.6138888597488403, loss=1.1259088516235352
train: epoch 26, loss 0.32779815793037415, acc=0.852055549621582, loss=0.32779815793037415
test: epoch 26, loss 1.0707470178604126, acc=0.6611111164093018, loss=1.0707470178604126
train: epoch 27, loss 0.3179854154586792, acc=0.8577777743339539, loss=0.3179854154586792
test: epoch 27, loss 1.0111846923828125, acc=0.6361111402511597, loss=1.0111846923828125
train: epoch 28, loss 0.30585551261901855, acc=0.8653333187103271, loss=0.30585551261901855
test: epoch 28, loss 0.9905399084091187, acc=0.6027777791023254, loss=0.9905399084091187
train: epoch 29, loss 0.2974807620048523, acc=0.8701666593551636, loss=0.2974807620048523
test: epoch 29, loss 0.7890448570251465, acc=0.7055555582046509, loss=0.7890448570251465
train: epoch 30, loss 0.29357364773750305, acc=0.8715555667877197, loss=0.29357364773750305
test: epoch 30, loss 1.0044957399368286, acc=0.6083333492279053, loss=1.0044957399368286
train: epoch 31, loss 0.2957380414009094, acc=0.871999979019165, loss=0.2957380414009094
test: epoch 31, loss 1.1306878328323364, acc=0.605555534362793, loss=1.1306878328323364
train: epoch 32, loss 0.30496853590011597, acc=0.8688333630561829, loss=0.30496853590011597
test: epoch 32, loss 0.8755940794944763, acc=0.6777777671813965, loss=0.8755940794944763
train: epoch 33, loss 0.28040361404418945, acc=0.8772222399711609, loss=0.28040361404418945
test: epoch 33, loss 1.0555888414382935, acc=0.6666666865348816, loss=1.0555888414382935
train: epoch 34, loss 0.28403669595718384, acc=0.8783888816833496, loss=0.28403669595718384
test: epoch 34, loss 0.8726625442504883, acc=0.7194444537162781, loss=0.8726625442504883
train: epoch 35, loss 0.26743292808532715, acc=0.883055567741394, loss=0.26743292808532715
test: epoch 35, loss 0.9298936724662781, acc=0.6583333611488342, loss=0.9298936724662781
train: epoch 36, loss 0.2810477912425995, acc=0.8808333277702332, loss=0.2810477912425995
test: epoch 36, loss 0.7222590446472168, acc=0.7055555582046509, loss=0.7222590446472168
train: epoch 37, loss 0.26151952147483826, acc=0.8857222199440002, loss=0.26151952147483826
test: epoch 37, loss 0.9043813347816467, acc=0.7416666746139526, loss=0.9043813347816467
train: epoch 38, loss 0.27058902382850647, acc=0.8850555419921875, loss=0.27058902382850647
test: epoch 38, loss 0.8709050416946411, acc=0.7055555582046509, loss=0.8709050416946411
train: epoch 39, loss 0.28262415528297424, acc=0.8810555338859558, loss=0.28262415528297424
test: epoch 39, loss 0.5235990881919861, acc=0.800000011920929, loss=0.5235990881919861
train: epoch 40, loss 0.24774441123008728, acc=0.890666663646698, loss=0.24774441123008728
test: epoch 40, loss 0.6241255402565002, acc=0.800000011920929, loss=0.6241255402565002
train: epoch 41, loss 0.2616805136203766, acc=0.8881111145019531, loss=0.2616805136203766
test: epoch 41, loss 0.6938667893409729, acc=0.7777777910232544, loss=0.6938667893409729
train: epoch 42, loss 0.2582333981990814, acc=0.8860555291175842, loss=0.2582333981990814
test: epoch 42, loss 0.5951813459396362, acc=0.7888888716697693, loss=0.5951813459396362
train: epoch 43, loss 0.2451903373003006, acc=0.8907222151756287, loss=0.2451903373003006
test: epoch 43, loss 0.6514968872070312, acc=0.7638888955116272, loss=0.6514968872070312
train: epoch 44, loss 0.24221710860729218, acc=0.8920000195503235, loss=0.24221710860729218
test: epoch 44, loss 0.5394864678382874, acc=0.8194444179534912, loss=0.5394864678382874
train: epoch 45, loss 0.2193363606929779, acc=0.899222195148468, loss=0.2193363606929779
test: epoch 45, loss 0.4036957621574402, acc=0.8222222328186035, loss=0.4036957621574402
train: epoch 46, loss 0.23866255581378937, acc=0.8934999704360962, loss=0.23866255581378937
test: epoch 46, loss 0.5332788228988647, acc=0.7944444417953491, loss=0.5332788228988647
train: epoch 47, loss 0.2145308256149292, acc=0.9013333320617676, loss=0.2145308256149292
test: epoch 47, loss 0.4273856282234192, acc=0.8138889074325562, loss=0.4273856282234192
train: epoch 48, loss 0.2398546189069748, acc=0.894444465637207, loss=0.2398546189069748
test: epoch 48, loss 0.45174863934516907, acc=0.8083333373069763, loss=0.45174863934516907
train: epoch 49, loss 0.22765636444091797, acc=0.8970555663108826, loss=0.22765636444091797
test: epoch 49, loss 0.47994059324264526, acc=0.8166666626930237, loss=0.47994059324264526
train: epoch 50, loss 0.21138860285282135, acc=0.9026111364364624, loss=0.21138860285282135
test: epoch 50, loss 0.5912092328071594, acc=0.7888888716697693, loss=0.5912092328071594
train: epoch 51, loss 0.21748189628124237, acc=0.9002777934074402, loss=0.21748189628124237
test: epoch 51, loss 0.4426518976688385, acc=0.8277778029441833, loss=0.4426518976688385
train: epoch 52, loss 0.1844262331724167, acc=0.9092222452163696, loss=0.1844262331724167
test: epoch 52, loss 0.477862149477005, acc=0.8111110925674438, loss=0.477862149477005
train: epoch 53, loss 0.22204963862895966, acc=0.9006666541099548, loss=0.22204963862895966
test: epoch 53, loss 0.546603262424469, acc=0.8194444179534912, loss=0.546603262424469
train: epoch 54, loss 0.21333976089954376, acc=0.9032222032546997, loss=0.21333976089954376
test: epoch 54, loss 0.47165647149086, acc=0.8361111283302307, loss=0.47165647149086
train: epoch 55, loss 0.19772036373615265, acc=0.9072777628898621, loss=0.19772036373615265
test: epoch 55, loss 0.4135490655899048, acc=0.8277778029441833, loss=0.4135490655899048
train: epoch 56, loss 0.2098141610622406, acc=0.9028888940811157, loss=0.2098141610622406
test: epoch 56, loss 0.42401614785194397, acc=0.8138889074325562, loss=0.42401614785194397
train: epoch 57, loss 0.19318236410617828, acc=0.9054444432258606, loss=0.19318236410617828
test: epoch 57, loss 0.5137068033218384, acc=0.8166666626930237, loss=0.5137068033218384
train: epoch 58, loss 0.19877323508262634, acc=0.9071111083030701, loss=0.19877323508262634
test: epoch 58, loss 0.4072973430156708, acc=0.8277778029441833, loss=0.4072973430156708
train: epoch 59, loss 0.20341670513153076, acc=0.9032777547836304, loss=0.20341670513153076
test: epoch 59, loss 0.4818985164165497, acc=0.8222222328186035, loss=0.4818985164165497
train: epoch 60, loss 0.19602662324905396, acc=0.9064444303512573, loss=0.19602662324905396
test: epoch 60, loss 0.4758414924144745, acc=0.8138889074325562, loss=0.4758414924144745
train: epoch 61, loss 0.19896815717220306, acc=0.9066666960716248, loss=0.19896815717220306
test: epoch 61, loss 0.4856611490249634, acc=0.824999988079071, loss=0.4856611490249634
train: epoch 62, loss 0.19131475687026978, acc=0.909166693687439, loss=0.19131475687026978
test: epoch 62, loss 0.5465561151504517, acc=0.8194444179534912, loss=0.5465561151504517
train: epoch 63, loss 0.19709347188472748, acc=0.9077777862548828, loss=0.19709347188472748
test: epoch 63, loss 0.40620332956314087, acc=0.8277778029441833, loss=0.40620332956314087
train: epoch 64, loss 0.19417449831962585, acc=0.9088888764381409, loss=0.19417449831962585
test: epoch 64, loss 0.5744891166687012, acc=0.8027777671813965, loss=0.5744891166687012
train: epoch 65, loss 0.18798118829727173, acc=0.910444438457489, loss=0.18798118829727173
test: epoch 65, loss 0.5231644511222839, acc=0.8222222328186035, loss=0.5231644511222839
train: epoch 66, loss 0.20976188778877258, acc=0.9067222476005554, loss=0.20976188778877258
test: epoch 66, loss 0.44502758979797363, acc=0.8222222328186035, loss=0.44502758979797363
train: epoch 67, loss 0.19338752329349518, acc=0.9103333353996277, loss=0.19338752329349518
test: epoch 67, loss 0.37669238448143005, acc=0.8305555582046509, loss=0.37669238448143005
train: epoch 68, loss 0.17735347151756287, acc=0.9113333225250244, loss=0.17735347151756287
test: epoch 68, loss 0.5162631273269653, acc=0.8083333373069763, loss=0.5162631273269653
train: epoch 69, loss 0.22494326531887054, acc=0.902999997138977, loss=0.22494326531887054
test: epoch 69, loss 0.40175437927246094, acc=0.8277778029441833, loss=0.40175437927246094
train: epoch 70, loss 0.20404812693595886, acc=0.9048888683319092, loss=0.20404812693595886
test: epoch 70, loss 0.5421662926673889, acc=0.8138889074325562, loss=0.5421662926673889
train: epoch 71, loss 0.18538980185985565, acc=0.910444438457489, loss=0.18538980185985565
test: epoch 71, loss 0.44076406955718994, acc=0.8361111283302307, loss=0.44076406955718994
train: epoch 72, loss 0.18495070934295654, acc=0.9114999771118164, loss=0.18495070934295654
test: epoch 72, loss 0.4609285295009613, acc=0.824999988079071, loss=0.4609285295009613
train: epoch 73, loss 0.20385001599788666, acc=0.9082221984863281, loss=0.20385001599788666
test: epoch 73, loss 0.42826682329177856, acc=0.824999988079071, loss=0.42826682329177856
train: epoch 74, loss 0.18904238939285278, acc=0.9116666913032532, loss=0.18904238939285278
test: epoch 74, loss 0.4451107084751129, acc=0.8277778029441833, loss=0.4451107084751129
train: epoch 75, loss 0.19104468822479248, acc=0.9098333120346069, loss=0.19104468822479248
test: epoch 75, loss 0.5233629941940308, acc=0.8305555582046509, loss=0.5233629941940308
train: epoch 76, loss 0.2199946492910385, acc=0.9051666855812073, loss=0.2199946492910385
test: epoch 76, loss 0.4785894751548767, acc=0.8305555582046509, loss=0.4785894751548767
train: epoch 77, loss 0.20774269104003906, acc=0.9094444513320923, loss=0.20774269104003906
test: epoch 77, loss 0.4756496846675873, acc=0.8166666626930237, loss=0.4756496846675873
train: epoch 78, loss 0.18053509294986725, acc=0.9154999852180481, loss=0.18053509294986725
test: epoch 78, loss 0.34820833802223206, acc=0.8305555582046509, loss=0.34820833802223206
train: epoch 79, loss 0.19730812311172485, acc=0.9190000295639038, loss=0.19730812311172485
test: epoch 79, loss 0.5046093463897705, acc=0.8138889074325562, loss=0.5046093463897705
train: epoch 80, loss 0.1677483320236206, acc=0.9344444274902344, loss=0.1677483320236206
test: epoch 80, loss 0.40872669219970703, acc=0.8305555582046509, loss=0.40872669219970703
train: epoch 81, loss 0.18593743443489075, acc=0.9277777671813965, loss=0.18593743443489075
test: epoch 81, loss 0.4549388587474823, acc=0.8305555582046509, loss=0.4549388587474823
train: epoch 82, loss 0.18824008107185364, acc=0.9268888831138611, loss=0.18824008107185364
test: epoch 82, loss 0.6156681776046753, acc=0.8305555582046509, loss=0.6156681776046753
train: epoch 83, loss 0.16324478387832642, acc=0.9426666498184204, loss=0.16324478387832642
test: epoch 83, loss 0.468873530626297, acc=0.824999988079071, loss=0.468873530626297
train: epoch 84, loss 0.16132386028766632, acc=0.9357222318649292, loss=0.16132386028766632
test: epoch 84, loss 0.5505843162536621, acc=0.8305555582046509, loss=0.5505843162536621
train: epoch 85, loss 0.1531415581703186, acc=0.9430000185966492, loss=0.1531415581703186
test: epoch 85, loss 0.5307042002677917, acc=0.8416666388511658, loss=0.5307042002677917
train: epoch 86, loss 0.17828413844108582, acc=0.9361666440963745, loss=0.17828413844108582
test: epoch 86, loss 0.5805083513259888, acc=0.8194444179534912, loss=0.5805083513259888
train: epoch 87, loss 0.17922207713127136, acc=0.9362778067588806, loss=0.17922207713127136
test: epoch 87, loss 0.5069682598114014, acc=0.8222222328186035, loss=0.5069682598114014
train: epoch 88, loss 0.14845752716064453, acc=0.9445555806159973, loss=0.14845752716064453
test: epoch 88, loss 0.5267528891563416, acc=0.8222222328186035, loss=0.5267528891563416
train: epoch 89, loss 0.14912201464176178, acc=0.9427777528762817, loss=0.14912201464176178
test: epoch 89, loss 0.532856822013855, acc=0.824999988079071, loss=0.532856822013855
train: epoch 90, loss 0.1393435150384903, acc=0.9461110830307007, loss=0.1393435150384903
test: epoch 90, loss 0.4885733425617218, acc=0.8333333134651184, loss=0.4885733425617218
train: epoch 91, loss 0.16967366635799408, acc=0.9352222084999084, loss=0.16967366635799408
test: epoch 91, loss 0.48852455615997314, acc=0.8277778029441833, loss=0.48852455615997314
train: epoch 92, loss 0.13089744746685028, acc=0.9499444365501404, loss=0.13089744746685028
test: epoch 92, loss 0.48295649886131287, acc=0.8472222089767456, loss=0.48295649886131287
train: epoch 93, loss 0.15767376124858856, acc=0.9433333277702332, loss=0.15767376124858856
test: epoch 93, loss 0.5335481762886047, acc=0.8083333373069763, loss=0.5335481762886047
train: epoch 94, loss 0.14821000397205353, acc=0.9456111192703247, loss=0.14821000397205353
test: epoch 94, loss 0.5507099628448486, acc=0.8305555582046509, loss=0.5507099628448486
train: epoch 95, loss 0.1753443330526352, acc=0.9375555515289307, loss=0.1753443330526352
test: epoch 95, loss 0.6108575463294983, acc=0.8277778029441833, loss=0.6108575463294983
train: epoch 96, loss 0.14903408288955688, acc=0.9431666731834412, loss=0.14903408288955688
test: epoch 96, loss 0.7417563796043396, acc=0.8138889074325562, loss=0.7417563796043396
train: epoch 97, loss 0.15388911962509155, acc=0.9422222375869751, loss=0.15388911962509155
test: epoch 97, loss 0.4775981605052948, acc=0.824999988079071, loss=0.4775981605052948
train: epoch 98, loss 0.15871025621891022, acc=0.9430555701255798, loss=0.15871025621891022
test: epoch 98, loss 0.5668975710868835, acc=0.8166666626930237, loss=0.5668975710868835
train: epoch 99, loss 0.159923255443573, acc=0.9409444332122803, loss=0.159923255443573
test: epoch 99, loss 0.5311098694801331, acc=0.800000011920929, loss=0.5311098694801331
train: epoch 100, loss 0.14559440314769745, acc=0.9466666579246521, loss=0.14559440314769745
test: epoch 100, loss 0.5203561782836914, acc=0.8194444179534912, loss=0.5203561782836914
train: epoch 101, loss 0.15328814089298248, acc=0.9417222142219543, loss=0.15328814089298248
test: epoch 101, loss 0.4369544982910156, acc=0.8194444179534912, loss=0.4369544982910156
train: epoch 102, loss 0.14382816851139069, acc=0.945555567741394, loss=0.14382816851139069
test: epoch 102, loss 0.5771171450614929, acc=0.8166666626930237, loss=0.5771171450614929
train: epoch 103, loss 0.15320143103599548, acc=0.9439444541931152, loss=0.15320143103599548
test: epoch 103, loss 0.43722930550575256, acc=0.8222222328186035, loss=0.43722930550575256
train: epoch 104, loss 0.14244693517684937, acc=0.9455000162124634, loss=0.14244693517684937
test: epoch 104, loss 0.6613717675209045, acc=0.824999988079071, loss=0.6613717675209045
train: epoch 105, loss 0.1604948341846466, acc=0.9398333430290222, loss=0.1604948341846466
test: epoch 105, loss 0.6936516165733337, acc=0.8027777671813965, loss=0.6936516165733337
train: epoch 106, loss 0.1422988325357437, acc=0.9467777609825134, loss=0.1422988325357437
test: epoch 106, loss 0.4541412591934204, acc=0.8388888835906982, loss=0.4541412591934204
train: epoch 107, loss 0.15373554825782776, acc=0.9444444179534912, loss=0.15373554825782776
test: epoch 107, loss 0.44335460662841797, acc=0.8138889074325562, loss=0.44335460662841797
train: epoch 108, loss 0.15783900022506714, acc=0.9405555725097656, loss=0.15783900022506714
test: epoch 108, loss 0.4678458869457245, acc=0.8305555582046509, loss=0.4678458869457245
train: epoch 109, loss 0.16261067986488342, acc=0.9401666522026062, loss=0.16261067986488342
test: epoch 109, loss 0.47164592146873474, acc=0.8305555582046509, loss=0.47164592146873474
train: epoch 110, loss 0.1508960872888565, acc=0.9436666369438171, loss=0.1508960872888565
test: epoch 110, loss 0.5731949210166931, acc=0.8222222328186035, loss=0.5731949210166931
train: epoch 111, loss 0.1424621343612671, acc=0.945388913154602, loss=0.1424621343612671
test: epoch 111, loss 0.4901244342327118, acc=0.8138889074325562, loss=0.4901244342327118
train: epoch 112, loss 0.1570485681295395, acc=0.9384444355964661, loss=0.1570485681295395
test: epoch 112, loss 0.3923211097717285, acc=0.8361111283302307, loss=0.3923211097717285
train: epoch 113, loss 0.16643661260604858, acc=0.9421111345291138, loss=0.16643661260604858
test: epoch 113, loss 0.3875978887081146, acc=0.8500000238418579, loss=0.3875978887081146
train: epoch 114, loss 0.1477532535791397, acc=0.9469444155693054, loss=0.1477532535791397
test: epoch 114, loss 0.44751909375190735, acc=0.8361111283302307, loss=0.44751909375190735
train: epoch 115, loss 0.1719481199979782, acc=0.9360555410385132, loss=0.1719481199979782
test: epoch 115, loss 0.4476245641708374, acc=0.7888888716697693, loss=0.4476245641708374
train: epoch 116, loss 0.15347564220428467, acc=0.9441111087799072, loss=0.15347564220428467
test: epoch 116, loss 0.46245282888412476, acc=0.8333333134651184, loss=0.46245282888412476
train: epoch 117, loss 0.15847034752368927, acc=0.944944441318512, loss=0.15847034752368927
test: epoch 117, loss 0.4554370045661926, acc=0.8333333134651184, loss=0.4554370045661926
train: epoch 118, loss 0.15268729627132416, acc=0.9461666941642761, loss=0.15268729627132416
test: epoch 118, loss 0.39901047945022583, acc=0.8361111283302307, loss=0.39901047945022583
train: epoch 119, loss 0.14774714410305023, acc=0.94605553150177, loss=0.14774714410305023
test: epoch 119, loss 0.628828763961792, acc=0.824999988079071, loss=0.628828763961792
train: epoch 120, loss 0.15777742862701416, acc=0.9451666474342346, loss=0.15777742862701416
test: epoch 120, loss 0.512487530708313, acc=0.8388888835906982, loss=0.512487530708313
train: epoch 121, loss 0.16129009425640106, acc=0.9438889026641846, loss=0.16129009425640106
test: epoch 121, loss 0.41001978516578674, acc=0.8333333134651184, loss=0.41001978516578674
train: epoch 122, loss 0.15859796106815338, acc=0.9427777528762817, loss=0.15859796106815338
test: epoch 122, loss 0.45531168580055237, acc=0.8333333134651184, loss=0.45531168580055237
train: epoch 123, loss 0.15734243392944336, acc=0.9402777552604675, loss=0.15734243392944336
test: epoch 123, loss 0.3611116409301758, acc=0.8472222089767456, loss=0.3611116409301758
train: epoch 124, loss 0.15954245626926422, acc=0.941444456577301, loss=0.15954245626926422
test: epoch 124, loss 0.4811438024044037, acc=0.8416666388511658, loss=0.4811438024044037
train: epoch 125, loss 0.1465788632631302, acc=0.945388913154602, loss=0.1465788632631302
test: epoch 125, loss 0.4652496874332428, acc=0.8305555582046509, loss=0.4652496874332428
train: epoch 126, loss 0.1646866798400879, acc=0.937166690826416, loss=0.1646866798400879
test: epoch 126, loss 0.4820023477077484, acc=0.8416666388511658, loss=0.4820023477077484
train: epoch 127, loss 0.1424298882484436, acc=0.9441666603088379, loss=0.1424298882484436
test: epoch 127, loss 0.4798240065574646, acc=0.8416666388511658, loss=0.4798240065574646
train: epoch 128, loss 0.1716403216123581, acc=0.9352777600288391, loss=0.1716403216123581
test: epoch 128, loss 0.4533199965953827, acc=0.8388888835906982, loss=0.4533199965953827
train: epoch 129, loss 0.15602856874465942, acc=0.9383888840675354, loss=0.15602856874465942
test: epoch 129, loss 0.4312063455581665, acc=0.8500000238418579, loss=0.4312063455581665
train: epoch 130, loss 0.13991689682006836, acc=0.9463889002799988, loss=0.13991689682006836
test: epoch 130, loss 0.3942685127258301, acc=0.8416666388511658, loss=0.3942685127258301
train: epoch 131, loss 0.14296403527259827, acc=0.9477777481079102, loss=0.14296403527259827
test: epoch 131, loss 0.4498905837535858, acc=0.8361111283302307, loss=0.4498905837535858
train: epoch 132, loss 0.21798324584960938, acc=0.9144999980926514, loss=0.21798324584960938
test: epoch 132, loss 0.5564724802970886, acc=0.7888888716697693, loss=0.5564724802970886
train: epoch 133, loss 0.18514542281627655, acc=0.929888904094696, loss=0.18514542281627655
test: epoch 133, loss 0.3608510494232178, acc=0.8361111283302307, loss=0.3608510494232178
train: epoch 134, loss 0.21585364639759064, acc=0.910444438457489, loss=0.21585364639759064
test: epoch 134, loss 0.5372325778007507, acc=0.8138889074325562, loss=0.5372325778007507
train: epoch 135, loss 0.19249077141284943, acc=0.9099444150924683, loss=0.19249077141284943
test: epoch 135, loss 0.512823224067688, acc=0.8027777671813965, loss=0.512823224067688
train: epoch 136, loss 0.19410263001918793, acc=0.9294999837875366, loss=0.19410263001918793
test: epoch 136, loss 0.48682743310928345, acc=0.8277778029441833, loss=0.48682743310928345
train: epoch 137, loss 0.16540059447288513, acc=0.9358333349227905, loss=0.16540059447288513
test: epoch 137, loss 0.4627741575241089, acc=0.8472222089767456, loss=0.4627741575241089
train: epoch 138, loss 0.17052708566188812, acc=0.9316666722297668, loss=0.17052708566188812
test: epoch 138, loss 0.36751022934913635, acc=0.8527777791023254, loss=0.36751022934913635
train: epoch 139, loss 0.1366332769393921, acc=0.9462777972221375, loss=0.1366332769393921
test: epoch 139, loss 0.42371147871017456, acc=0.855555534362793, loss=0.42371147871017456
train: epoch 140, loss 0.16221566498279572, acc=0.9392777681350708, loss=0.16221566498279572
test: epoch 140, loss 0.5350123047828674, acc=0.8388888835906982, loss=0.5350123047828674
train: epoch 141, loss 0.14688274264335632, acc=0.9398888945579529, loss=0.14688274264335632
test: epoch 141, loss 0.4142580032348633, acc=0.855555534362793, loss=0.4142580032348633
train: epoch 142, loss 0.14424344897270203, acc=0.9470555782318115, loss=0.14424344897270203
test: epoch 142, loss 0.309908390045166, acc=0.855555534362793, loss=0.309908390045166
train: epoch 143, loss 0.1660543829202652, acc=0.9424444437026978, loss=0.1660543829202652
test: epoch 143, loss 0.41278883814811707, acc=0.855555534362793, loss=0.41278883814811707
train: epoch 144, loss 0.13223424553871155, acc=0.949999988079071, loss=0.13223424553871155
test: epoch 144, loss 0.4032213091850281, acc=0.855555534362793, loss=0.4032213091850281
train: epoch 145, loss 0.15735028684139252, acc=0.9441111087799072, loss=0.15735028684139252
test: epoch 145, loss 0.4518623948097229, acc=0.855555534362793, loss=0.4518623948097229
train: epoch 146, loss 0.13626953959465027, acc=0.9476666450500488, loss=0.13626953959465027
test: epoch 146, loss 0.5769438147544861, acc=0.855555534362793, loss=0.5769438147544861
train: epoch 147, loss 0.17411154508590698, acc=0.9418888688087463, loss=0.17411154508590698
test: epoch 147, loss 0.5166290402412415, acc=0.8527777791023254, loss=0.5166290402412415
train: epoch 148, loss 0.12871776521205902, acc=0.9507222175598145, loss=0.12871776521205902
test: epoch 148, loss 0.4349198639392853, acc=0.855555534362793, loss=0.4349198639392853
train: epoch 149, loss 0.138882115483284, acc=0.9497777819633484, loss=0.138882115483284
test: epoch 149, loss 0.4461231231689453, acc=0.855555534362793, loss=0.4461231231689453
train: epoch 150, loss 0.13892975449562073, acc=0.949833333492279, loss=0.13892975449562073
test: epoch 150, loss 0.49413859844207764, acc=0.8527777791023254, loss=0.49413859844207764
