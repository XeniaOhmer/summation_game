# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=1.5", "--temp_decay=1", "--one_hot=false", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1283803967, receiver_embed_dim=128, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.8004767894744873, acc=0.09694444388151169, loss=2.8004767894744873
test: epoch 1, loss 2.8366811275482178, acc=0.09166666865348816, loss=2.8366811275482178
train: epoch 2, loss 1.7309608459472656, acc=0.27561110258102417, loss=1.7309608459472656
test: epoch 2, loss 1.8935333490371704, acc=0.2361111044883728, loss=1.8935333490371704
train: epoch 3, loss 1.3483365774154663, acc=0.4079444408416748, loss=1.3483365774154663
test: epoch 3, loss 1.6874750852584839, acc=0.32499998807907104, loss=1.6874750852584839
train: epoch 4, loss 1.1064561605453491, acc=0.5221111178398132, loss=1.1064561605453491
test: epoch 4, loss 1.3633941411972046, acc=0.4194444417953491, loss=1.3633941411972046
train: epoch 5, loss 0.8103748559951782, acc=0.6485000252723694, loss=0.8103748559951782
test: epoch 5, loss 1.4931907653808594, acc=0.46388888359069824, loss=1.4931907653808594
train: epoch 6, loss 0.6266503930091858, acc=0.7322221994400024, loss=0.6266503930091858
test: epoch 6, loss 1.1109071969985962, acc=0.5138888955116272, loss=1.1109071969985962
train: epoch 7, loss 0.5102686882019043, acc=0.7752777934074402, loss=0.5102686882019043
test: epoch 7, loss 1.1751772165298462, acc=0.5888888835906982, loss=1.1751772165298462
train: epoch 8, loss 0.4542902708053589, acc=0.7923333048820496, loss=0.4542902708053589
test: epoch 8, loss 1.1595885753631592, acc=0.5916666388511658, loss=1.1595885753631592
train: epoch 9, loss 0.4402572810649872, acc=0.8076111078262329, loss=0.4402572810649872
test: epoch 9, loss 1.071123480796814, acc=0.6611111164093018, loss=1.071123480796814
train: epoch 10, loss 0.3897002637386322, acc=0.8296666741371155, loss=0.3897002637386322
test: epoch 10, loss 0.6281673312187195, acc=0.7777777910232544, loss=0.6281673312187195
train: epoch 11, loss 0.35354894399642944, acc=0.8401111364364624, loss=0.35354894399642944
test: epoch 11, loss 0.6488091349601746, acc=0.7333333492279053, loss=0.6488091349601746
train: epoch 12, loss 0.34211304783821106, acc=0.8462222218513489, loss=0.34211304783821106
test: epoch 12, loss 0.6035737991333008, acc=0.7749999761581421, loss=0.6035737991333008
train: epoch 13, loss 0.3391987681388855, acc=0.8416110873222351, loss=0.3391987681388855
test: epoch 13, loss 0.5376051068305969, acc=0.7805555462837219, loss=0.5376051068305969
train: epoch 14, loss 0.31098684668540955, acc=0.8522777557373047, loss=0.31098684668540955
test: epoch 14, loss 0.5271596312522888, acc=0.8027777671813965, loss=0.5271596312522888
train: epoch 15, loss 0.277436763048172, acc=0.8648889064788818, loss=0.277436763048172
test: epoch 15, loss 0.5505728721618652, acc=0.8111110925674438, loss=0.5505728721618652
train: epoch 16, loss 0.296578973531723, acc=0.8599444627761841, loss=0.296578973531723
test: epoch 16, loss 0.3956296443939209, acc=0.824999988079071, loss=0.3956296443939209
train: epoch 17, loss 0.2801133096218109, acc=0.8652222156524658, loss=0.2801133096218109
test: epoch 17, loss 0.3927382230758667, acc=0.8361111283302307, loss=0.3927382230758667
train: epoch 18, loss 0.2707342803478241, acc=0.8698333501815796, loss=0.2707342803478241
test: epoch 18, loss 0.2941514849662781, acc=0.8666666746139526, loss=0.2941514849662781
train: epoch 19, loss 0.2772420644760132, acc=0.8701111078262329, loss=0.2772420644760132
test: epoch 19, loss 0.3757270574569702, acc=0.855555534362793, loss=0.3757270574569702
train: epoch 20, loss 0.2729962170124054, acc=0.8715555667877197, loss=0.2729962170124054
test: epoch 20, loss 0.3912423551082611, acc=0.855555534362793, loss=0.3912423551082611
train: epoch 21, loss 0.26524049043655396, acc=0.8801666498184204, loss=0.26524049043655396
test: epoch 21, loss 0.41521701216697693, acc=0.8472222089767456, loss=0.41521701216697693
train: epoch 22, loss 0.25427255034446716, acc=0.8938888907432556, loss=0.25427255034446716
test: epoch 22, loss 0.43988096714019775, acc=0.855555534362793, loss=0.43988096714019775
train: epoch 23, loss 0.23939761519432068, acc=0.8971111178398132, loss=0.23939761519432068
test: epoch 23, loss 0.4022844731807709, acc=0.8583333492279053, loss=0.4022844731807709
train: epoch 24, loss 0.18873730301856995, acc=0.9156666398048401, loss=0.18873730301856995
test: epoch 24, loss 0.3504886329174042, acc=0.8666666746139526, loss=0.3504886329174042
train: epoch 25, loss 0.20490850508213043, acc=0.9151111245155334, loss=0.20490850508213043
test: epoch 25, loss 0.3242751359939575, acc=0.8638888597488403, loss=0.3242751359939575
train: epoch 26, loss 0.19381912052631378, acc=0.9146111011505127, loss=0.19381912052631378
test: epoch 26, loss 0.4592021703720093, acc=0.8583333492279053, loss=0.4592021703720093
train: epoch 27, loss 0.25823599100112915, acc=0.8973888754844666, loss=0.25823599100112915
test: epoch 27, loss 0.4879285395145416, acc=0.8638888597488403, loss=0.4879285395145416
train: epoch 28, loss 0.17065484821796417, acc=0.9231666922569275, loss=0.17065484821796417
test: epoch 28, loss 0.49025142192840576, acc=0.8611111044883728, loss=0.49025142192840576
train: epoch 29, loss 0.21421879529953003, acc=0.9112222194671631, loss=0.21421879529953003
test: epoch 29, loss 0.44578540325164795, acc=0.8611111044883728, loss=0.44578540325164795
train: epoch 30, loss 0.19722169637680054, acc=0.9139999747276306, loss=0.19722169637680054
test: epoch 30, loss 0.3123159110546112, acc=0.8638888597488403, loss=0.3123159110546112
train: epoch 31, loss 0.16754186153411865, acc=0.9222777485847473, loss=0.16754186153411865
test: epoch 31, loss 0.5486394166946411, acc=0.855555534362793, loss=0.5486394166946411
train: epoch 32, loss 0.2652415335178375, acc=0.8922777771949768, loss=0.2652415335178375
test: epoch 32, loss 0.4073638916015625, acc=0.824999988079071, loss=0.4073638916015625
train: epoch 33, loss 0.20789176225662231, acc=0.9135000109672546, loss=0.20789176225662231
test: epoch 33, loss 0.43635594844818115, acc=0.8638888597488403, loss=0.43635594844818115
train: epoch 34, loss 0.16863685846328735, acc=0.9222221970558167, loss=0.16863685846328735
test: epoch 34, loss 0.42390409111976624, acc=0.8666666746139526, loss=0.42390409111976624
train: epoch 35, loss 0.18265241384506226, acc=0.92166668176651, loss=0.18265241384506226
test: epoch 35, loss 0.7847879528999329, acc=0.8472222089767456, loss=0.7847879528999329
train: epoch 36, loss 0.17733025550842285, acc=0.9201111197471619, loss=0.17733025550842285
test: epoch 36, loss 0.6624306440353394, acc=0.855555534362793, loss=0.6624306440353394
train: epoch 37, loss 0.1798468381166458, acc=0.9219444394111633, loss=0.1798468381166458
test: epoch 37, loss 0.5446084141731262, acc=0.8500000238418579, loss=0.5446084141731262
train: epoch 38, loss 0.1516001969575882, acc=0.9271666407585144, loss=0.1516001969575882
test: epoch 38, loss 0.38874706625938416, acc=0.8500000238418579, loss=0.38874706625938416
train: epoch 39, loss 0.16741269826889038, acc=0.9231111407279968, loss=0.16741269826889038
test: epoch 39, loss 0.49247267842292786, acc=0.8361111283302307, loss=0.49247267842292786
train: epoch 40, loss 0.13533300161361694, acc=0.933388888835907, loss=0.13533300161361694
test: epoch 40, loss 0.4017407298088074, acc=0.8638888597488403, loss=0.4017407298088074
train: epoch 41, loss 0.13184796273708344, acc=0.933555543422699, loss=0.13184796273708344
test: epoch 41, loss 0.4793762266635895, acc=0.8638888597488403, loss=0.4793762266635895
train: epoch 42, loss 0.18674443662166595, acc=0.9208889007568359, loss=0.18674443662166595
test: epoch 42, loss 0.41395342350006104, acc=0.855555534362793, loss=0.41395342350006104
train: epoch 43, loss 0.17485052347183228, acc=0.9258333444595337, loss=0.17485052347183228
test: epoch 43, loss 0.6840140223503113, acc=0.8166666626930237, loss=0.6840140223503113
train: epoch 44, loss 0.20895229279994965, acc=0.9089999794960022, loss=0.20895229279994965
test: epoch 44, loss 0.5816443562507629, acc=0.8583333492279053, loss=0.5816443562507629
train: epoch 45, loss 0.19576634466648102, acc=0.9123333096504211, loss=0.19576634466648102
test: epoch 45, loss 0.46573606133461, acc=0.8583333492279053, loss=0.46573606133461
train: epoch 46, loss 0.22699162364006042, acc=0.9083889126777649, loss=0.22699162364006042
test: epoch 46, loss 0.5686907768249512, acc=0.8527777791023254, loss=0.5686907768249512
train: epoch 47, loss 0.18831899762153625, acc=0.9171666502952576, loss=0.18831899762153625
test: epoch 47, loss 0.4749697148799896, acc=0.8666666746139526, loss=0.4749697148799896
train: epoch 48, loss 0.15515956282615662, acc=0.9258333444595337, loss=0.15515956282615662
test: epoch 48, loss 0.5290839672088623, acc=0.8416666388511658, loss=0.5290839672088623
train: epoch 49, loss 0.20310448110103607, acc=0.9096111059188843, loss=0.20310448110103607
test: epoch 49, loss 0.42454463243484497, acc=0.855555534362793, loss=0.42454463243484497
train: epoch 50, loss 0.16367124021053314, acc=0.9237777590751648, loss=0.16367124021053314
test: epoch 50, loss 0.446832537651062, acc=0.8583333492279053, loss=0.446832537651062
train: epoch 51, loss 0.15739765763282776, acc=0.9265000224113464, loss=0.15739765763282776
test: epoch 51, loss 0.4908851385116577, acc=0.8611111044883728, loss=0.4908851385116577
train: epoch 52, loss 0.1491338014602661, acc=0.9292222261428833, loss=0.1491338014602661
test: epoch 52, loss 0.5513201355934143, acc=0.8694444298744202, loss=0.5513201355934143
train: epoch 53, loss 0.18221226334571838, acc=0.9212222099304199, loss=0.18221226334571838
test: epoch 53, loss 0.5362682938575745, acc=0.8444444537162781, loss=0.5362682938575745
train: epoch 54, loss 0.18687021732330322, acc=0.9088333249092102, loss=0.18687021732330322
test: epoch 54, loss 0.46264684200286865, acc=0.8583333492279053, loss=0.46264684200286865
train: epoch 55, loss 0.16060227155685425, acc=0.9132221937179565, loss=0.16060227155685425
test: epoch 55, loss 0.515970766544342, acc=0.8583333492279053, loss=0.515970766544342
train: epoch 56, loss 0.22235825657844543, acc=0.9018333554267883, loss=0.22235825657844543
test: epoch 56, loss 0.42768594622612, acc=0.8472222089767456, loss=0.42768594622612
train: epoch 57, loss 0.19051752984523773, acc=0.9084444642066956, loss=0.19051752984523773
test: epoch 57, loss 0.5881122946739197, acc=0.8388888835906982, loss=0.5881122946739197
train: epoch 58, loss 0.16329443454742432, acc=0.9099444150924683, loss=0.16329443454742432
test: epoch 58, loss 0.6383651494979858, acc=0.8444444537162781, loss=0.6383651494979858
train: epoch 59, loss 0.17862486839294434, acc=0.9111666679382324, loss=0.17862486839294434
test: epoch 59, loss 0.6951213479042053, acc=0.8166666626930237, loss=0.6951213479042053
train: epoch 60, loss 0.19792793691158295, acc=0.9103888869285583, loss=0.19792793691158295
test: epoch 60, loss 0.5245375633239746, acc=0.8611111044883728, loss=0.5245375633239746
train: epoch 61, loss 0.1453065723180771, acc=0.9204999804496765, loss=0.1453065723180771
test: epoch 61, loss 0.4466632604598999, acc=0.8583333492279053, loss=0.4466632604598999
train: epoch 62, loss 0.17620471119880676, acc=0.9120555520057678, loss=0.17620471119880676
test: epoch 62, loss 0.5921950340270996, acc=0.8500000238418579, loss=0.5921950340270996
train: epoch 63, loss 0.17393368482589722, acc=0.9153888821601868, loss=0.17393368482589722
test: epoch 63, loss 0.41131269931793213, acc=0.8611111044883728, loss=0.41131269931793213
train: epoch 64, loss 0.143276646733284, acc=0.9213333129882812, loss=0.143276646733284
test: epoch 64, loss 0.5113800764083862, acc=0.8638888597488403, loss=0.5113800764083862
train: epoch 65, loss 0.12935085594654083, acc=0.9201666712760925, loss=0.12935085594654083
test: epoch 65, loss 0.32972586154937744, acc=0.8638888597488403, loss=0.32972586154937744
train: epoch 66, loss 0.1734417974948883, acc=0.9171666502952576, loss=0.1734417974948883
test: epoch 66, loss 0.5046924352645874, acc=0.8500000238418579, loss=0.5046924352645874
train: epoch 67, loss 0.17345918715000153, acc=0.9150555729866028, loss=0.17345918715000153
test: epoch 67, loss 0.5430085062980652, acc=0.8611111044883728, loss=0.5430085062980652
train: epoch 68, loss 0.20985230803489685, acc=0.907444417476654, loss=0.20985230803489685
test: epoch 68, loss 0.5292341709136963, acc=0.8444444537162781, loss=0.5292341709136963
train: epoch 69, loss 0.16433341801166534, acc=0.9157778024673462, loss=0.16433341801166534
test: epoch 69, loss 0.5416846871376038, acc=0.8611111044883728, loss=0.5416846871376038
train: epoch 70, loss 0.15094387531280518, acc=0.9208333492279053, loss=0.15094387531280518
test: epoch 70, loss 0.337834894657135, acc=0.8833333253860474, loss=0.337834894657135
train: epoch 71, loss 0.17947609722614288, acc=0.9212777614593506, loss=0.17947609722614288
test: epoch 71, loss 0.3742959499359131, acc=0.8916666507720947, loss=0.3742959499359131
train: epoch 72, loss 0.188416987657547, acc=0.9247778058052063, loss=0.188416987657547
test: epoch 72, loss 0.3462047576904297, acc=0.894444465637207, loss=0.3462047576904297
train: epoch 73, loss 0.12475575506687164, acc=0.9333333373069763, loss=0.12475575506687164
test: epoch 73, loss 0.3736417293548584, acc=0.8972222208976746, loss=0.3736417293548584
train: epoch 74, loss 0.13322784006595612, acc=0.9303333163261414, loss=0.13322784006595612
test: epoch 74, loss 0.39079391956329346, acc=0.8972222208976746, loss=0.39079391956329346
train: epoch 75, loss 0.17171673476696014, acc=0.9266666769981384, loss=0.17171673476696014
test: epoch 75, loss 0.45846816897392273, acc=0.8805555701255798, loss=0.45846816897392273
train: epoch 76, loss 0.17094343900680542, acc=0.9208333492279053, loss=0.17094343900680542
test: epoch 76, loss 0.36568427085876465, acc=0.8861111402511597, loss=0.36568427085876465
train: epoch 77, loss 0.15736231207847595, acc=0.9287777543067932, loss=0.15736231207847595
test: epoch 77, loss 0.4403190016746521, acc=0.8861111402511597, loss=0.4403190016746521
train: epoch 78, loss 0.15059280395507812, acc=0.9286666512489319, loss=0.15059280395507812
test: epoch 78, loss 0.35918888449668884, acc=0.894444465637207, loss=0.35918888449668884
train: epoch 79, loss 0.13350160419940948, acc=0.933722198009491, loss=0.13350160419940948
test: epoch 79, loss 0.36780503392219543, acc=0.8972222208976746, loss=0.36780503392219543
train: epoch 80, loss 0.12882393598556519, acc=0.9365555644035339, loss=0.12882393598556519
test: epoch 80, loss 0.44827598333358765, acc=0.8777777552604675, loss=0.44827598333358765
train: epoch 81, loss 0.14364540576934814, acc=0.9301111102104187, loss=0.14364540576934814
test: epoch 81, loss 0.37790071964263916, acc=0.894444465637207, loss=0.37790071964263916
train: epoch 82, loss 0.15964427590370178, acc=0.9256666898727417, loss=0.15964427590370178
test: epoch 82, loss 0.3298296332359314, acc=0.8805555701255798, loss=0.3298296332359314
train: epoch 83, loss 0.1898368000984192, acc=0.9169999957084656, loss=0.1898368000984192
test: epoch 83, loss 0.38765865564346313, acc=0.8805555701255798, loss=0.38765865564346313
train: epoch 84, loss 0.13505959510803223, acc=0.9315000176429749, loss=0.13505959510803223
test: epoch 84, loss 0.4000204801559448, acc=0.8916666507720947, loss=0.4000204801559448
train: epoch 85, loss 0.12531399726867676, acc=0.9342222213745117, loss=0.12531399726867676
test: epoch 85, loss 0.4286138415336609, acc=0.8916666507720947, loss=0.4286138415336609
train: epoch 86, loss 0.15654407441616058, acc=0.9269444346427917, loss=0.15654407441616058
test: epoch 86, loss 0.319080114364624, acc=0.8888888955116272, loss=0.319080114364624
train: epoch 87, loss 0.1466541886329651, acc=0.9246666431427002, loss=0.1466541886329651
test: epoch 87, loss 0.1610390543937683, acc=0.9194444417953491, loss=0.1610390543937683
train: epoch 88, loss 0.14056462049484253, acc=0.9279444217681885, loss=0.14056462049484253
test: epoch 88, loss 0.19476285576820374, acc=0.9194444417953491, loss=0.19476285576820374
train: epoch 89, loss 0.2852567732334137, acc=0.9056666493415833, loss=0.2852567732334137
test: epoch 89, loss 0.4201318919658661, acc=0.8833333253860474, loss=0.4201318919658661
train: epoch 90, loss 0.1779193878173828, acc=0.9127777814865112, loss=0.1779193878173828
test: epoch 90, loss 0.2743798792362213, acc=0.9027777910232544, loss=0.2743798792362213
train: epoch 91, loss 0.19519010186195374, acc=0.9087777733802795, loss=0.19519010186195374
test: epoch 91, loss 0.2585088014602661, acc=0.9055555462837219, loss=0.2585088014602661
train: epoch 92, loss 0.18875855207443237, acc=0.9157222509384155, loss=0.18875855207443237
test: epoch 92, loss 0.2134169340133667, acc=0.9083333611488342, loss=0.2134169340133667
train: epoch 93, loss 0.16986234486103058, acc=0.9093888998031616, loss=0.16986234486103058
test: epoch 93, loss 0.2514484226703644, acc=0.9111111164093018, loss=0.2514484226703644
train: epoch 94, loss 0.17678262293338776, acc=0.910611093044281, loss=0.17678262293338776
test: epoch 94, loss 0.21917131543159485, acc=0.9111111164093018, loss=0.21917131543159485
train: epoch 95, loss 0.16775542497634888, acc=0.9139444231987, loss=0.16775542497634888
test: epoch 95, loss 0.2355194389820099, acc=0.9111111164093018, loss=0.2355194389820099
train: epoch 96, loss 0.16980934143066406, acc=0.9138333201408386, loss=0.16980934143066406
test: epoch 96, loss 0.243952676653862, acc=0.9111111164093018, loss=0.243952676653862
train: epoch 97, loss 0.21229596436023712, acc=0.9076111316680908, loss=0.21229596436023712
test: epoch 97, loss 0.37043628096580505, acc=0.8972222208976746, loss=0.37043628096580505
train: epoch 98, loss 0.21632952988147736, acc=0.9005555510520935, loss=0.21632952988147736
test: epoch 98, loss 0.22080595791339874, acc=0.9083333611488342, loss=0.22080595791339874
train: epoch 99, loss 0.17579728364944458, acc=0.9084444642066956, loss=0.17579728364944458
test: epoch 99, loss 0.2592664957046509, acc=0.9083333611488342, loss=0.2592664957046509
train: epoch 100, loss 0.16879743337631226, acc=0.9049999713897705, loss=0.16879743337631226
test: epoch 100, loss 0.3621407449245453, acc=0.9027777910232544, loss=0.3621407449245453
train: epoch 101, loss 0.21898923814296722, acc=0.8999444246292114, loss=0.21898923814296722
test: epoch 101, loss 0.3705793619155884, acc=0.8999999761581421, loss=0.3705793619155884
train: epoch 102, loss 0.23878273367881775, acc=0.8999999761581421, loss=0.23878273367881775
test: epoch 102, loss 0.2529416084289551, acc=0.9083333611488342, loss=0.2529416084289551
train: epoch 103, loss 0.1550450176000595, acc=0.9131666421890259, loss=0.1550450176000595
test: epoch 103, loss 0.30110856890678406, acc=0.9138888716697693, loss=0.30110856890678406
train: epoch 104, loss 0.18597902357578278, acc=0.9077222347259521, loss=0.18597902357578278
test: epoch 104, loss 0.21685664355754852, acc=0.9166666865348816, loss=0.21685664355754852
train: epoch 105, loss 0.15534813702106476, acc=0.9136666655540466, loss=0.15534813702106476
test: epoch 105, loss 0.17791549861431122, acc=0.9222221970558167, loss=0.17791549861431122
train: epoch 106, loss 0.14751961827278137, acc=0.9161666631698608, loss=0.14751961827278137
test: epoch 106, loss 0.14089839160442352, acc=0.9305555820465088, loss=0.14089839160442352
train: epoch 107, loss 0.14365562796592712, acc=0.9118888974189758, loss=0.14365562796592712
test: epoch 107, loss 0.14033962786197662, acc=0.9305555820465088, loss=0.14033962786197662
train: epoch 108, loss 0.1379173994064331, acc=0.9116666913032532, loss=0.1379173994064331
test: epoch 108, loss 0.129606693983078, acc=0.9333333373069763, loss=0.129606693983078
train: epoch 109, loss 0.13348788022994995, acc=0.9130555391311646, loss=0.13348788022994995
test: epoch 109, loss 0.3156176209449768, acc=0.9194444417953491, loss=0.3156176209449768
train: epoch 110, loss 0.23689118027687073, acc=0.9093888998031616, loss=0.23689118027687073
test: epoch 110, loss 0.18603397905826569, acc=0.9194444417953491, loss=0.18603397905826569
train: epoch 111, loss 0.1790195107460022, acc=0.9167777895927429, loss=0.1790195107460022
test: epoch 111, loss 0.1650993973016739, acc=0.9222221970558167, loss=0.1650993973016739
train: epoch 112, loss 0.16816657781600952, acc=0.9150000214576721, loss=0.16816657781600952
test: epoch 112, loss 0.16463306546211243, acc=0.9222221970558167, loss=0.16463306546211243
train: epoch 113, loss 0.1807553768157959, acc=0.9141111373901367, loss=0.1807553768157959
test: epoch 113, loss 0.19405420124530792, acc=0.9166666865348816, loss=0.19405420124530792
train: epoch 114, loss 0.25762349367141724, acc=0.8971666693687439, loss=0.25762349367141724
test: epoch 114, loss 0.19618666172027588, acc=0.9111111164093018, loss=0.19618666172027588
train: epoch 115, loss 0.19395579397678375, acc=0.9087222218513489, loss=0.19395579397678375
test: epoch 115, loss 0.18466006219387054, acc=0.9166666865348816, loss=0.18466006219387054
train: epoch 116, loss 0.18532808125019073, acc=0.9087222218513489, loss=0.18532808125019073
test: epoch 116, loss 0.18207618594169617, acc=0.9166666865348816, loss=0.18207618594169617
train: epoch 117, loss 0.18770185112953186, acc=0.9089999794960022, loss=0.18770185112953186
test: epoch 117, loss 0.1827508807182312, acc=0.9166666865348816, loss=0.1827508807182312
train: epoch 118, loss 0.18475544452667236, acc=0.9102222323417664, loss=0.18475544452667236
test: epoch 118, loss 0.18194936215877533, acc=0.9166666865348816, loss=0.18194936215877533
train: epoch 119, loss 0.18455417454242706, acc=0.9083333611488342, loss=0.18455417454242706
test: epoch 119, loss 0.18191058933734894, acc=0.9166666865348816, loss=0.18191058933734894
train: epoch 120, loss 0.18269012868404388, acc=0.9089999794960022, loss=0.18269012868404388
test: epoch 120, loss 0.1624097228050232, acc=0.9222221970558167, loss=0.1624097228050232
train: epoch 121, loss 0.16567525267601013, acc=0.914222240447998, loss=0.16567525267601013
test: epoch 121, loss 0.16022099554538727, acc=0.9222221970558167, loss=0.16022099554538727
train: epoch 122, loss 0.1531413495540619, acc=0.917722225189209, loss=0.1531413495540619
test: epoch 122, loss 0.1454915553331375, acc=0.9277777671813965, loss=0.1454915553331375
train: epoch 123, loss 0.14707668125629425, acc=0.9194444417953491, loss=0.14707668125629425
test: epoch 123, loss 0.1453501433134079, acc=0.9277777671813965, loss=0.1453501433134079
train: epoch 124, loss 0.14687660336494446, acc=0.9194444417953491, loss=0.14687660336494446
test: epoch 124, loss 0.14531385898590088, acc=0.9277777671813965, loss=0.14531385898590088
train: epoch 125, loss 0.1467575877904892, acc=0.9194999933242798, loss=0.1467575877904892
test: epoch 125, loss 0.1452857404947281, acc=0.9277777671813965, loss=0.1452857404947281
train: epoch 126, loss 0.14610755443572998, acc=0.9197777509689331, loss=0.14610755443572998
test: epoch 126, loss 0.13933216035366058, acc=0.9305555820465088, loss=0.13933216035366058
train: epoch 127, loss 0.14069223403930664, acc=0.9222777485847473, loss=0.14069223403930664
test: epoch 127, loss 0.13932554423809052, acc=0.9305555820465088, loss=0.13932554423809052
train: epoch 128, loss 0.1408097743988037, acc=0.9228333234786987, loss=0.1408097743988037
test: epoch 128, loss 0.13931986689567566, acc=0.9305555820465088, loss=0.13931986689567566
train: epoch 129, loss 0.4210887849330902, acc=0.8687222003936768, loss=0.4210887849330902
test: epoch 129, loss 0.36660701036453247, acc=0.8527777791023254, loss=0.36660701036453247
train: epoch 130, loss 0.46856576204299927, acc=0.8263888955116272, loss=0.46856576204299927
test: epoch 130, loss 0.4081285297870636, acc=0.8277778029441833, loss=0.4081285297870636
train: epoch 131, loss 0.4062298536300659, acc=0.8298333287239075, loss=0.4062298536300659
test: epoch 131, loss 0.392721563577652, acc=0.8305555582046509, loss=0.392721563577652
train: epoch 132, loss 0.3953453302383423, acc=0.8295000195503235, loss=0.3953453302383423
test: epoch 132, loss 0.6391777396202087, acc=0.8333333134651184, loss=0.6391777396202087
train: epoch 133, loss 0.36799103021621704, acc=0.8456110954284668, loss=0.36799103021621704
test: epoch 133, loss 0.33201298117637634, acc=0.8583333492279053, loss=0.33201298117637634
train: epoch 134, loss 0.34648460149765015, acc=0.8506666421890259, loss=0.34648460149765015
test: epoch 134, loss 0.3310634195804596, acc=0.8666666746139526, loss=0.3310634195804596
train: epoch 135, loss 0.31053391098976135, acc=0.871055543422699, loss=0.31053391098976135
test: epoch 135, loss 0.2548133134841919, acc=0.8916666507720947, loss=0.2548133134841919
train: epoch 136, loss 0.25453147292137146, acc=0.8846111297607422, loss=0.25453147292137146
test: epoch 136, loss 0.23473210632801056, acc=0.894444465637207, loss=0.23473210632801056
train: epoch 137, loss 0.2305501103401184, acc=0.8901110887527466, loss=0.2305501103401184
test: epoch 137, loss 0.2263123095035553, acc=0.8972222208976746, loss=0.2263123095035553
train: epoch 138, loss 0.24606935679912567, acc=0.8907777667045593, loss=0.24606935679912567
test: epoch 138, loss 0.5630567073822021, acc=0.8583333492279053, loss=0.5630567073822021
train: epoch 139, loss 0.2732318043708801, acc=0.886888861656189, loss=0.2732318043708801
test: epoch 139, loss 0.21556168794631958, acc=0.9027777910232544, loss=0.21556168794631958
train: epoch 140, loss 0.21766231954097748, acc=0.8971666693687439, loss=0.21766231954097748
test: epoch 140, loss 0.21425476670265198, acc=0.9027777910232544, loss=0.21425476670265198
train: epoch 141, loss 0.2231658548116684, acc=0.8949999809265137, loss=0.2231658548116684
test: epoch 141, loss 0.2139476239681244, acc=0.9027777910232544, loss=0.2139476239681244
train: epoch 142, loss 0.3626073896884918, acc=0.8622221946716309, loss=0.3626073896884918
test: epoch 142, loss 0.3426474630832672, acc=0.8666666746139526, loss=0.3426474630832672
train: epoch 143, loss 0.3014163374900818, acc=0.8707777857780457, loss=0.3014163374900818
test: epoch 143, loss 0.2899765372276306, acc=0.8777777552604675, loss=0.2899765372276306
train: epoch 144, loss 0.29193270206451416, acc=0.8707777857780457, loss=0.29193270206451416
test: epoch 144, loss 0.28939002752304077, acc=0.8777777552604675, loss=0.28939002752304077
train: epoch 145, loss 0.38216426968574524, acc=0.8585555553436279, loss=0.38216426968574524
test: epoch 145, loss 0.3000793159008026, acc=0.8666666746139526, loss=0.3000793159008026
train: epoch 146, loss 0.35102322697639465, acc=0.8533889055252075, loss=0.35102322697639465
test: epoch 146, loss 0.3280554711818695, acc=0.8583333492279053, loss=0.3280554711818695
train: epoch 147, loss 0.3216246962547302, acc=0.8556666374206543, loss=0.3216246962547302
test: epoch 147, loss 0.31066182255744934, acc=0.8638888597488403, loss=0.31066182255744934
train: epoch 148, loss 0.31144461035728455, acc=0.8572777509689331, loss=0.31144461035728455
test: epoch 148, loss 0.30517926812171936, acc=0.8666666746139526, loss=0.30517926812171936
train: epoch 149, loss 0.3052968680858612, acc=0.859499990940094, loss=0.3052968680858612
test: epoch 149, loss 0.2956376075744629, acc=0.8694444298744202, loss=0.2956376075744629
train: epoch 150, loss 0.29924437403678894, acc=0.8609444499015808, loss=0.29924437403678894
test: epoch 150, loss 0.2954474091529846, acc=0.8694444298744202, loss=0.2954474091529846
