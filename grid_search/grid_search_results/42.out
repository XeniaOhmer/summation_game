# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=true", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1347855976, receiver_embed_dim=32, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.3635189533233643, acc=0.050833333283662796, loss=3.3635189533233643
test: epoch 1, loss 4.339684963226318, acc=0.06388889253139496, loss=4.339684963226318
train: epoch 2, loss 2.5691964626312256, acc=0.18000000715255737, loss=2.5691964626312256
test: epoch 2, loss 4.612845420837402, acc=0.10833333432674408, loss=4.612845420837402
train: epoch 3, loss 1.7149708271026611, acc=0.35411110520362854, loss=1.7149708271026611
test: epoch 3, loss 4.186275959014893, acc=0.13333334028720856, loss=4.186275959014893
train: epoch 4, loss 1.389696478843689, acc=0.4582222104072571, loss=1.389696478843689
test: epoch 4, loss 3.558929443359375, acc=0.15833333134651184, loss=3.558929443359375
train: epoch 5, loss 1.2100412845611572, acc=0.534333348274231, loss=1.2100412845611572
test: epoch 5, loss 3.829650640487671, acc=0.15833333134651184, loss=3.829650640487671
train: epoch 6, loss 1.0944392681121826, acc=0.5787222385406494, loss=1.0944392681121826
test: epoch 6, loss 3.4454197883605957, acc=0.1666666716337204, loss=3.4454197883605957
train: epoch 7, loss 0.9985835552215576, acc=0.6203888654708862, loss=0.9985835552215576
test: epoch 7, loss 3.345963716506958, acc=0.15833333134651184, loss=3.345963716506958
train: epoch 8, loss 0.9373084306716919, acc=0.6457222104072571, loss=0.9373084306716919
test: epoch 8, loss 3.3104119300842285, acc=0.16944444179534912, loss=3.3104119300842285
train: epoch 9, loss 0.8668398261070251, acc=0.675166666507721, loss=0.8668398261070251
test: epoch 9, loss 3.4265706539154053, acc=0.17777778208255768, loss=3.4265706539154053
train: epoch 10, loss 0.8285590410232544, acc=0.6984444260597229, loss=0.8285590410232544
test: epoch 10, loss 3.3916287422180176, acc=0.1944444477558136, loss=3.3916287422180176
train: epoch 11, loss 0.7744645476341248, acc=0.7208333611488342, loss=0.7744645476341248
test: epoch 11, loss 3.3499181270599365, acc=0.19722221791744232, loss=3.3499181270599365
train: epoch 12, loss 0.7487417459487915, acc=0.7277222275733948, loss=0.7487417459487915
test: epoch 12, loss 3.126863718032837, acc=0.20555555820465088, loss=3.126863718032837
train: epoch 13, loss 0.7030654549598694, acc=0.7455000281333923, loss=0.7030654549598694
test: epoch 13, loss 2.90250563621521, acc=0.23055554926395416, loss=2.90250563621521
train: epoch 14, loss 0.6710526943206787, acc=0.7587222456932068, loss=0.6710526943206787
test: epoch 14, loss 2.7702810764312744, acc=0.25, loss=2.7702810764312744
train: epoch 15, loss 0.6450620889663696, acc=0.7695000171661377, loss=0.6450620889663696
test: epoch 15, loss 2.8827600479125977, acc=0.24444444477558136, loss=2.8827600479125977
train: epoch 16, loss 0.6250050663948059, acc=0.781499981880188, loss=0.6250050663948059
test: epoch 16, loss 2.8558356761932373, acc=0.23888888955116272, loss=2.8558356761932373
train: epoch 17, loss 0.5913780927658081, acc=0.7885000109672546, loss=0.5913780927658081
test: epoch 17, loss 2.6378872394561768, acc=0.2611111104488373, loss=2.6378872394561768
train: epoch 18, loss 0.565858006477356, acc=0.8069444298744202, loss=0.565858006477356
test: epoch 18, loss 2.7159905433654785, acc=0.24444444477558136, loss=2.7159905433654785
train: epoch 19, loss 0.5697358846664429, acc=0.8028888702392578, loss=0.5697358846664429
test: epoch 19, loss 2.724461317062378, acc=0.2611111104488373, loss=2.724461317062378
train: epoch 20, loss 0.5412998199462891, acc=0.812666654586792, loss=0.5412998199462891
test: epoch 20, loss 2.4899802207946777, acc=0.27222222089767456, loss=2.4899802207946777
train: epoch 21, loss 0.5261399149894714, acc=0.816611111164093, loss=0.5261399149894714
test: epoch 21, loss 2.4132606983184814, acc=0.2666666805744171, loss=2.4132606983184814
train: epoch 22, loss 0.509885311126709, acc=0.824999988079071, loss=0.509885311126709
test: epoch 22, loss 2.4232981204986572, acc=0.2638888955116272, loss=2.4232981204986572
train: epoch 23, loss 0.505782961845398, acc=0.8266666531562805, loss=0.505782961845398
test: epoch 23, loss 2.578483819961548, acc=0.24722221493721008, loss=2.578483819961548
train: epoch 24, loss 0.48681017756462097, acc=0.83561110496521, loss=0.48681017756462097
test: epoch 24, loss 2.374474048614502, acc=0.2527777850627899, loss=2.374474048614502
train: epoch 25, loss 0.4618687033653259, acc=0.8387777805328369, loss=0.4618687033653259
test: epoch 25, loss 2.355792999267578, acc=0.30000001192092896, loss=2.355792999267578
train: epoch 26, loss 0.46775898337364197, acc=0.8405555486679077, loss=0.46775898337364197
test: epoch 26, loss 2.4690334796905518, acc=0.28611111640930176, loss=2.4690334796905518
train: epoch 27, loss 0.47344186902046204, acc=0.8370555639266968, loss=0.47344186902046204
test: epoch 27, loss 2.401642322540283, acc=0.2666666805744171, loss=2.401642322540283
train: epoch 28, loss 0.4389677345752716, acc=0.8484444618225098, loss=0.4389677345752716
test: epoch 28, loss 2.2022526264190674, acc=0.2888889014720917, loss=2.2022526264190674
train: epoch 29, loss 0.44097810983657837, acc=0.8524444699287415, loss=0.44097810983657837
test: epoch 29, loss 2.4336109161376953, acc=0.28333333134651184, loss=2.4336109161376953
train: epoch 30, loss 0.43340474367141724, acc=0.8539444208145142, loss=0.43340474367141724
test: epoch 30, loss 2.052229881286621, acc=0.2805555462837219, loss=2.052229881286621
train: epoch 31, loss 0.4271480143070221, acc=0.8581666946411133, loss=0.4271480143070221
test: epoch 31, loss 2.173374891281128, acc=0.26944443583488464, loss=2.173374891281128
train: epoch 32, loss 0.4173153340816498, acc=0.8606666922569275, loss=0.4173153340816498
test: epoch 32, loss 2.3348867893218994, acc=0.24166665971279144, loss=2.3348867893218994
train: epoch 33, loss 0.41008371114730835, acc=0.8641111254692078, loss=0.41008371114730835
test: epoch 33, loss 2.3588438034057617, acc=0.24722221493721008, loss=2.3588438034057617
train: epoch 34, loss 0.4039722681045532, acc=0.8649444580078125, loss=0.4039722681045532
test: epoch 34, loss 2.294370174407959, acc=0.25833332538604736, loss=2.294370174407959
train: epoch 35, loss 0.39529407024383545, acc=0.8677777647972107, loss=0.39529407024383545
test: epoch 35, loss 2.0971901416778564, acc=0.26944443583488464, loss=2.0971901416778564
train: epoch 36, loss 0.39296311140060425, acc=0.8683333396911621, loss=0.39296311140060425
test: epoch 36, loss 2.0683345794677734, acc=0.2777777910232544, loss=2.0683345794677734
train: epoch 37, loss 0.3936520516872406, acc=0.870888888835907, loss=0.3936520516872406
test: epoch 37, loss 2.2718594074249268, acc=0.24444444477558136, loss=2.2718594074249268
train: epoch 38, loss 0.3635552227497101, acc=0.8799444437026978, loss=0.3635552227497101
test: epoch 38, loss 2.237022876739502, acc=0.25, loss=2.237022876739502
train: epoch 39, loss 0.37137970328330994, acc=0.8737778067588806, loss=0.37137970328330994
test: epoch 39, loss 2.1617822647094727, acc=0.2611111104488373, loss=2.1617822647094727
train: epoch 40, loss 0.36808714270591736, acc=0.8795555830001831, loss=0.36808714270591736
test: epoch 40, loss 2.3046395778656006, acc=0.23055554926395416, loss=2.3046395778656006
train: epoch 41, loss 0.36867067217826843, acc=0.8792222142219543, loss=0.36867067217826843
test: epoch 41, loss 1.9342360496520996, acc=0.31388887763023376, loss=1.9342360496520996
train: epoch 42, loss 0.3712046444416046, acc=0.8841666579246521, loss=0.3712046444416046
test: epoch 42, loss 2.144535779953003, acc=0.3027777671813965, loss=2.144535779953003
train: epoch 43, loss 0.3561180830001831, acc=0.8828333616256714, loss=0.3561180830001831
test: epoch 43, loss 2.1859500408172607, acc=0.2944444417953491, loss=2.1859500408172607
train: epoch 44, loss 0.35705772042274475, acc=0.8852221965789795, loss=0.35705772042274475
test: epoch 44, loss 2.1800270080566406, acc=0.2611111104488373, loss=2.1800270080566406
train: epoch 45, loss 0.35241445899009705, acc=0.8866111040115356, loss=0.35241445899009705
test: epoch 45, loss 2.110183000564575, acc=0.2777777910232544, loss=2.110183000564575
train: epoch 46, loss 0.33922216296195984, acc=0.8929444551467896, loss=0.33922216296195984
test: epoch 46, loss 2.045816659927368, acc=0.3166666626930237, loss=2.045816659927368
train: epoch 47, loss 0.34122031927108765, acc=0.8886111378669739, loss=0.34122031927108765
test: epoch 47, loss 2.0887186527252197, acc=0.31388887763023376, loss=2.0887186527252197
train: epoch 48, loss 0.33161136507987976, acc=0.8929444551467896, loss=0.33161136507987976
test: epoch 48, loss 1.8815009593963623, acc=0.30000001192092896, loss=1.8815009593963623
train: epoch 49, loss 0.3382318913936615, acc=0.8929444551467896, loss=0.3382318913936615
test: epoch 49, loss 1.8632324934005737, acc=0.31388887763023376, loss=1.8632324934005737
train: epoch 50, loss 0.3236185610294342, acc=0.893833339214325, loss=0.3236185610294342
test: epoch 50, loss 2.0153491497039795, acc=0.3222222328186035, loss=2.0153491497039795
train: epoch 51, loss 0.3254616856575012, acc=0.8963333368301392, loss=0.3254616856575012
test: epoch 51, loss 1.926023244857788, acc=0.33888888359069824, loss=1.926023244857788
train: epoch 52, loss 0.32268717885017395, acc=0.898722231388092, loss=0.32268717885017395
test: epoch 52, loss 2.0151565074920654, acc=0.32499998807907104, loss=2.0151565074920654
train: epoch 53, loss 0.32446759939193726, acc=0.8939444422721863, loss=0.32446759939193726
test: epoch 53, loss 1.7712775468826294, acc=0.3583333194255829, loss=1.7712775468826294
train: epoch 54, loss 0.3074304163455963, acc=0.9000555276870728, loss=0.3074304163455963
test: epoch 54, loss 1.859188199043274, acc=0.3305555582046509, loss=1.859188199043274
train: epoch 55, loss 0.3256758749485016, acc=0.8985555768013, loss=0.3256758749485016
test: epoch 55, loss 1.84511399269104, acc=0.3305555582046509, loss=1.84511399269104
train: epoch 56, loss 0.30245161056518555, acc=0.9002222418785095, loss=0.30245161056518555
test: epoch 56, loss 1.9519057273864746, acc=0.33888888359069824, loss=1.9519057273864746
train: epoch 57, loss 0.30833882093429565, acc=0.9017778038978577, loss=0.30833882093429565
test: epoch 57, loss 1.8576968908309937, acc=0.3444444537162781, loss=1.8576968908309937
train: epoch 58, loss 0.3064196705818176, acc=0.9008888602256775, loss=0.3064196705818176
test: epoch 58, loss 1.9416148662567139, acc=0.35277777910232544, loss=1.9416148662567139
train: epoch 59, loss 0.3028576970100403, acc=0.9051111340522766, loss=0.3028576970100403
test: epoch 59, loss 1.709350347518921, acc=0.38055557012557983, loss=1.709350347518921
train: epoch 60, loss 0.29063495993614197, acc=0.9067777991294861, loss=0.29063495993614197
test: epoch 60, loss 1.8173819780349731, acc=0.3861111104488373, loss=1.8173819780349731
train: epoch 61, loss 0.29298099875450134, acc=0.9071666598320007, loss=0.29298099875450134
test: epoch 61, loss 1.8534929752349854, acc=0.3638888895511627, loss=1.8534929752349854
train: epoch 62, loss 0.289974182844162, acc=0.9072777628898621, loss=0.289974182844162
test: epoch 62, loss 1.8298699855804443, acc=0.36666667461395264, loss=1.8298699855804443
train: epoch 63, loss 0.2874443829059601, acc=0.910611093044281, loss=0.2874443829059601
test: epoch 63, loss 1.874487042427063, acc=0.33888888359069824, loss=1.874487042427063
train: epoch 64, loss 0.2975771725177765, acc=0.9079999923706055, loss=0.2975771725177765
test: epoch 64, loss 1.8663662672042847, acc=0.3611111044883728, loss=1.8663662672042847
train: epoch 65, loss 0.2877015769481659, acc=0.9068889021873474, loss=0.2877015769481659
test: epoch 65, loss 1.7764722108840942, acc=0.3916666805744171, loss=1.7764722108840942
train: epoch 66, loss 0.27723026275634766, acc=0.9107778072357178, loss=0.27723026275634766
test: epoch 66, loss 1.839952826499939, acc=0.39444443583488464, loss=1.839952826499939
train: epoch 67, loss 0.276675283908844, acc=0.9135555624961853, loss=0.276675283908844
test: epoch 67, loss 1.8347355127334595, acc=0.3861111104488373, loss=1.8347355127334595
train: epoch 68, loss 0.2780837416648865, acc=0.9129999876022339, loss=0.2780837416648865
test: epoch 68, loss 1.8226417303085327, acc=0.3722222149372101, loss=1.8226417303085327
train: epoch 69, loss 0.27652496099472046, acc=0.9114999771118164, loss=0.27652496099472046
test: epoch 69, loss 1.9901102781295776, acc=0.3777777850627899, loss=1.9901102781295776
train: epoch 70, loss 0.2786450982093811, acc=0.9087222218513489, loss=0.2786450982093811
test: epoch 70, loss 1.6644421815872192, acc=0.3638888895511627, loss=1.6644421815872192
train: epoch 71, loss 0.27644065022468567, acc=0.9120000004768372, loss=0.27644065022468567
test: epoch 71, loss 1.7236084938049316, acc=0.4027777910232544, loss=1.7236084938049316
train: epoch 72, loss 0.2652529180049896, acc=0.9146111011505127, loss=0.2652529180049896
test: epoch 72, loss 1.723382830619812, acc=0.4055555462837219, loss=1.723382830619812
train: epoch 73, loss 0.25946465134620667, acc=0.914222240447998, loss=0.25946465134620667
test: epoch 73, loss 1.6572967767715454, acc=0.4333333373069763, loss=1.6572967767715454
train: epoch 74, loss 0.2665015161037445, acc=0.9143333435058594, loss=0.2665015161037445
test: epoch 74, loss 1.7892587184906006, acc=0.3777777850627899, loss=1.7892587184906006
train: epoch 75, loss 0.263312965631485, acc=0.9163333177566528, loss=0.263312965631485
test: epoch 75, loss 1.6933677196502686, acc=0.39722222089767456, loss=1.6933677196502686
train: epoch 76, loss 0.2837485373020172, acc=0.913444459438324, loss=0.2837485373020172
test: epoch 76, loss 1.7022508382797241, acc=0.4166666567325592, loss=1.7022508382797241
train: epoch 77, loss 0.2610676884651184, acc=0.9171110987663269, loss=0.2610676884651184
test: epoch 77, loss 1.707663655281067, acc=0.4194444417953491, loss=1.707663655281067
train: epoch 78, loss 0.278769314289093, acc=0.9160000085830688, loss=0.278769314289093
test: epoch 78, loss 1.7889717817306519, acc=0.375, loss=1.7889717817306519
train: epoch 79, loss 0.25594615936279297, acc=0.9161666631698608, loss=0.25594615936279297
test: epoch 79, loss 1.7027796506881714, acc=0.4138889014720917, loss=1.7027796506881714
train: epoch 80, loss 0.25367435812950134, acc=0.9173333048820496, loss=0.25367435812950134
test: epoch 80, loss 1.6931817531585693, acc=0.41111111640930176, loss=1.6931817531585693
train: epoch 81, loss 0.25553080439567566, acc=0.9169999957084656, loss=0.25553080439567566
test: epoch 81, loss 1.7096455097198486, acc=0.42500001192092896, loss=1.7096455097198486
train: epoch 82, loss 0.2588416337966919, acc=0.9183889031410217, loss=0.2588416337966919
test: epoch 82, loss 1.7530906200408936, acc=0.44999998807907104, loss=1.7530906200408936
train: epoch 83, loss 0.24362985789775848, acc=0.92166668176651, loss=0.24362985789775848
test: epoch 83, loss 1.7071245908737183, acc=0.3888888955116272, loss=1.7071245908737183
train: epoch 84, loss 0.2500755190849304, acc=0.9232222437858582, loss=0.2500755190849304
test: epoch 84, loss 1.6668111085891724, acc=0.4277777671813965, loss=1.6668111085891724
train: epoch 85, loss 0.2475508749485016, acc=0.9242222309112549, loss=0.2475508749485016
test: epoch 85, loss 1.7128862142562866, acc=0.4611110985279083, loss=1.7128862142562866
train: epoch 86, loss 0.23628577589988708, acc=0.9242777824401855, loss=0.23628577589988708
test: epoch 86, loss 1.7930349111557007, acc=0.42222222685813904, loss=1.7930349111557007
train: epoch 87, loss 0.24315382540225983, acc=0.9184444546699524, loss=0.24315382540225983
test: epoch 87, loss 1.6934573650360107, acc=0.3888888955116272, loss=1.6934573650360107
train: epoch 88, loss 0.2409338504076004, acc=0.9232222437858582, loss=0.2409338504076004
test: epoch 88, loss 1.7270146608352661, acc=0.4194444417953491, loss=1.7270146608352661
train: epoch 89, loss 0.24502705037593842, acc=0.9233888983726501, loss=0.24502705037593842
test: epoch 89, loss 1.4491573572158813, acc=0.4583333432674408, loss=1.4491573572158813
train: epoch 90, loss 0.23444268107414246, acc=0.9205555319786072, loss=0.23444268107414246
test: epoch 90, loss 1.660346508026123, acc=0.4305555522441864, loss=1.660346508026123
train: epoch 91, loss 0.23357759416103363, acc=0.9230555295944214, loss=0.23357759416103363
test: epoch 91, loss 1.6411560773849487, acc=0.44999998807907104, loss=1.6411560773849487
train: epoch 92, loss 0.24429088830947876, acc=0.9234444499015808, loss=0.24429088830947876
test: epoch 92, loss 1.6435092687606812, acc=0.4472222328186035, loss=1.6435092687606812
train: epoch 93, loss 0.22544829547405243, acc=0.9284444451332092, loss=0.22544829547405243
test: epoch 93, loss 1.7230947017669678, acc=0.42500001192092896, loss=1.7230947017669678
train: epoch 94, loss 0.2313975840806961, acc=0.9258888959884644, loss=0.2313975840806961
test: epoch 94, loss 1.519970178604126, acc=0.4277777671813965, loss=1.519970178604126
train: epoch 95, loss 0.23088380694389343, acc=0.9242777824401855, loss=0.23088380694389343
test: epoch 95, loss 1.577097773551941, acc=0.47777777910232544, loss=1.577097773551941
train: epoch 96, loss 0.2277945578098297, acc=0.9261666536331177, loss=0.2277945578098297
test: epoch 96, loss 1.5676273107528687, acc=0.4555555582046509, loss=1.5676273107528687
train: epoch 97, loss 0.23675163090229034, acc=0.9259999990463257, loss=0.23675163090229034
test: epoch 97, loss 1.4739996194839478, acc=0.4722222089767456, loss=1.4739996194839478
train: epoch 98, loss 0.2342829406261444, acc=0.9267222285270691, loss=0.2342829406261444
test: epoch 98, loss 1.5427201986312866, acc=0.4833333194255829, loss=1.5427201986312866
train: epoch 99, loss 0.23119112849235535, acc=0.9246666431427002, loss=0.23119112849235535
test: epoch 99, loss 1.545113205909729, acc=0.4833333194255829, loss=1.545113205909729
train: epoch 100, loss 0.22337095439434052, acc=0.9279444217681885, loss=0.22337095439434052
test: epoch 100, loss 1.560238003730774, acc=0.5055555701255798, loss=1.560238003730774
train: epoch 101, loss 0.21917308866977692, acc=0.9323333501815796, loss=0.21917308866977692
test: epoch 101, loss 1.6008083820343018, acc=0.46666666865348816, loss=1.6008083820343018
train: epoch 102, loss 0.23200823366641998, acc=0.9254444241523743, loss=0.23200823366641998
test: epoch 102, loss 1.528816819190979, acc=0.5, loss=1.528816819190979
train: epoch 103, loss 0.21346653997898102, acc=0.933722198009491, loss=0.21346653997898102
test: epoch 103, loss 1.7129286527633667, acc=0.5055555701255798, loss=1.7129286527633667
train: epoch 104, loss 0.23440508544445038, acc=0.9282777905464172, loss=0.23440508544445038
test: epoch 104, loss 1.4285041093826294, acc=0.5333333611488342, loss=1.4285041093826294
train: epoch 105, loss 0.22790060937404633, acc=0.9275000095367432, loss=0.22790060937404633
test: epoch 105, loss 1.674020767211914, acc=0.4694444537162781, loss=1.674020767211914
train: epoch 106, loss 0.22505125403404236, acc=0.9301666617393494, loss=0.22505125403404236
test: epoch 106, loss 1.4745348691940308, acc=0.519444465637207, loss=1.4745348691940308
train: epoch 107, loss 0.21212820708751678, acc=0.9351111054420471, loss=0.21212820708751678
test: epoch 107, loss 1.4125761985778809, acc=0.5083333253860474, loss=1.4125761985778809
train: epoch 108, loss 0.20935122668743134, acc=0.9345555305480957, loss=0.20935122668743134
test: epoch 108, loss 1.5357728004455566, acc=0.5111111402511597, loss=1.5357728004455566
train: epoch 109, loss 0.21242362260818481, acc=0.9334999918937683, loss=0.21242362260818481
test: epoch 109, loss 1.4360002279281616, acc=0.5416666865348816, loss=1.4360002279281616
train: epoch 110, loss 0.20017006993293762, acc=0.937833309173584, loss=0.20017006993293762
test: epoch 110, loss 1.427737832069397, acc=0.550000011920929, loss=1.427737832069397
train: epoch 111, loss 0.2013358473777771, acc=0.9367777705192566, loss=0.2013358473777771
test: epoch 111, loss 1.4039057493209839, acc=0.5138888955116272, loss=1.4039057493209839
train: epoch 112, loss 0.20298266410827637, acc=0.9377777576446533, loss=0.20298266410827637
test: epoch 112, loss 1.5421967506408691, acc=0.5472221970558167, loss=1.5421967506408691
train: epoch 113, loss 0.2064688354730606, acc=0.9362221956253052, loss=0.2064688354730606
test: epoch 113, loss 1.5036791563034058, acc=0.5222222208976746, loss=1.5036791563034058
train: epoch 114, loss 0.21195323765277863, acc=0.9375555515289307, loss=0.21195323765277863
test: epoch 114, loss 1.58747136592865, acc=0.5333333611488342, loss=1.58747136592865
train: epoch 115, loss 0.20270377397537231, acc=0.9382222294807434, loss=0.20270377397537231
test: epoch 115, loss 1.4800208806991577, acc=0.5472221970558167, loss=1.4800208806991577
train: epoch 116, loss 0.1831444799900055, acc=0.9424444437026978, loss=0.1831444799900055
test: epoch 116, loss 1.4520350694656372, acc=0.5083333253860474, loss=1.4520350694656372
train: epoch 117, loss 0.2089294195175171, acc=0.9375, loss=0.2089294195175171
test: epoch 117, loss 1.381300926208496, acc=0.5361111164093018, loss=1.381300926208496
train: epoch 118, loss 0.19982503354549408, acc=0.9357222318649292, loss=0.19982503354549408
test: epoch 118, loss 1.4303412437438965, acc=0.5555555820465088, loss=1.4303412437438965
train: epoch 119, loss 0.20446676015853882, acc=0.9375, loss=0.20446676015853882
test: epoch 119, loss 1.296339511871338, acc=0.5583333373069763, loss=1.296339511871338
train: epoch 120, loss 0.1975683867931366, acc=0.9401111006736755, loss=0.1975683867931366
test: epoch 120, loss 1.3689788579940796, acc=0.5611110925674438, loss=1.3689788579940796
train: epoch 121, loss 0.18536727130413055, acc=0.9441111087799072, loss=0.18536727130413055
test: epoch 121, loss 1.3361690044403076, acc=0.5361111164093018, loss=1.3361690044403076
train: epoch 122, loss 0.18854978680610657, acc=0.9428333044052124, loss=0.18854978680610657
test: epoch 122, loss 1.3902121782302856, acc=0.5416666865348816, loss=1.3902121782302856
train: epoch 123, loss 0.18684980273246765, acc=0.9445555806159973, loss=0.18684980273246765
test: epoch 123, loss 1.4261794090270996, acc=0.5472221970558167, loss=1.4261794090270996
train: epoch 124, loss 0.18824300169944763, acc=0.9448333382606506, loss=0.18824300169944763
test: epoch 124, loss 1.2745152711868286, acc=0.5583333373069763, loss=1.2745152711868286
train: epoch 125, loss 0.20193059742450714, acc=0.9409999847412109, loss=0.20193059742450714
test: epoch 125, loss 1.2277673482894897, acc=0.6000000238418579, loss=1.2277673482894897
train: epoch 126, loss 0.16857406497001648, acc=0.9456111192703247, loss=0.16857406497001648
test: epoch 126, loss 1.2567857503890991, acc=0.5833333134651184, loss=1.2567857503890991
train: epoch 127, loss 0.1833026111125946, acc=0.9431666731834412, loss=0.1833026111125946
test: epoch 127, loss 1.2400070428848267, acc=0.5805555582046509, loss=1.2400070428848267
train: epoch 128, loss 0.1807880401611328, acc=0.9444444179534912, loss=0.1807880401611328
test: epoch 128, loss 1.2597309350967407, acc=0.605555534362793, loss=1.2597309350967407
train: epoch 129, loss 0.17221756279468536, acc=0.9446666836738586, loss=0.17221756279468536
test: epoch 129, loss 1.1931909322738647, acc=0.5805555582046509, loss=1.1931909322738647
train: epoch 130, loss 0.1631765067577362, acc=0.9488333463668823, loss=0.1631765067577362
test: epoch 130, loss 1.1474559307098389, acc=0.6111111044883728, loss=1.1474559307098389
train: epoch 131, loss 0.1784985512495041, acc=0.9459999799728394, loss=0.1784985512495041
test: epoch 131, loss 1.2500921487808228, acc=0.5888888835906982, loss=1.2500921487808228
train: epoch 132, loss 0.17595823109149933, acc=0.9463889002799988, loss=0.17595823109149933
test: epoch 132, loss 1.3130172491073608, acc=0.5666666626930237, loss=1.3130172491073608
train: epoch 133, loss 0.18296052515506744, acc=0.945555567741394, loss=0.18296052515506744
test: epoch 133, loss 1.2482627630233765, acc=0.6194444298744202, loss=1.2482627630233765
train: epoch 134, loss 0.18865038454532623, acc=0.945555567741394, loss=0.18865038454532623
test: epoch 134, loss 1.0470061302185059, acc=0.6527777910232544, loss=1.0470061302185059
train: epoch 135, loss 0.1652015894651413, acc=0.949833333492279, loss=0.1652015894651413
test: epoch 135, loss 1.1282297372817993, acc=0.6583333611488342, loss=1.1282297372817993
train: epoch 136, loss 0.18167200684547424, acc=0.9451666474342346, loss=0.18167200684547424
test: epoch 136, loss 1.0052803754806519, acc=0.6527777910232544, loss=1.0052803754806519
train: epoch 137, loss 0.1639491319656372, acc=0.9496666789054871, loss=0.1639491319656372
test: epoch 137, loss 1.160971760749817, acc=0.6277777552604675, loss=1.160971760749817
train: epoch 138, loss 0.16667446494102478, acc=0.9466111063957214, loss=0.16667446494102478
test: epoch 138, loss 1.1052852869033813, acc=0.6333333253860474, loss=1.1052852869033813
train: epoch 139, loss 0.18457698822021484, acc=0.9455000162124634, loss=0.18457698822021484
test: epoch 139, loss 1.1878535747528076, acc=0.6000000238418579, loss=1.1878535747528076
train: epoch 140, loss 0.1631898730993271, acc=0.9479444622993469, loss=0.1631898730993271
test: epoch 140, loss 1.0644314289093018, acc=0.6138888597488403, loss=1.0644314289093018
train: epoch 141, loss 0.17117616534233093, acc=0.9476110935211182, loss=0.17117616534233093
test: epoch 141, loss 1.072152853012085, acc=0.6499999761581421, loss=1.072152853012085
train: epoch 142, loss 0.17650002241134644, acc=0.9482777714729309, loss=0.17650002241134644
test: epoch 142, loss 1.172135353088379, acc=0.6499999761581421, loss=1.172135353088379
train: epoch 143, loss 0.17352285981178284, acc=0.9462777972221375, loss=0.17352285981178284
test: epoch 143, loss 1.044539451599121, acc=0.6555555462837219, loss=1.044539451599121
train: epoch 144, loss 0.1816691756248474, acc=0.9497222304344177, loss=0.1816691756248474
test: epoch 144, loss 1.124065637588501, acc=0.6277777552604675, loss=1.124065637588501
train: epoch 145, loss 0.1714453250169754, acc=0.94605553150177, loss=0.1714453250169754
test: epoch 145, loss 1.0084084272384644, acc=0.6583333611488342, loss=1.0084084272384644
train: epoch 146, loss 0.1684744507074356, acc=0.9478333592414856, loss=0.1684744507074356
test: epoch 146, loss 1.0756973028182983, acc=0.6388888955116272, loss=1.0756973028182983
train: epoch 147, loss 0.16747362911701202, acc=0.9472222328186035, loss=0.16747362911701202
test: epoch 147, loss 0.9953982830047607, acc=0.6361111402511597, loss=0.9953982830047607
train: epoch 148, loss 0.17147690057754517, acc=0.9481666684150696, loss=0.17147690057754517
test: epoch 148, loss 1.148459553718567, acc=0.6527777910232544, loss=1.148459553718567
train: epoch 149, loss 0.16307273507118225, acc=0.9499444365501404, loss=0.16307273507118225
test: epoch 149, loss 1.0067871809005737, acc=0.6722221970558167, loss=1.0067871809005737
train: epoch 150, loss 0.17824849486351013, acc=0.9453333616256714, loss=0.17824849486351013
test: epoch 150, loss 0.8781107664108276, acc=0.6861110925674438, loss=0.8781107664108276
