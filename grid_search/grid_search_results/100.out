# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=false", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1725203431, receiver_embed_dim=64, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.809591770172119, acc=0.10311111062765121, loss=2.809591770172119
test: epoch 1, loss 4.394479751586914, acc=0.125, loss=4.394479751586914
train: epoch 2, loss 1.734137773513794, acc=0.27638888359069824, loss=1.734137773513794
test: epoch 2, loss 4.341099739074707, acc=0.11666666716337204, loss=4.341099739074707
train: epoch 3, loss 1.2662887573242188, acc=0.4786111116409302, loss=1.2662887573242188
test: epoch 3, loss 3.8296902179718018, acc=0.1805555522441864, loss=3.8296902179718018
train: epoch 4, loss 0.9917547702789307, acc=0.596666693687439, loss=0.9917547702789307
test: epoch 4, loss 3.4274258613586426, acc=0.2083333283662796, loss=3.4274258613586426
train: epoch 5, loss 0.788551390171051, acc=0.683722198009491, loss=0.788551390171051
test: epoch 5, loss 2.801377534866333, acc=0.2888889014720917, loss=2.801377534866333
train: epoch 6, loss 0.6431960463523865, acc=0.7467777729034424, loss=0.6431960463523865
test: epoch 6, loss 3.1635661125183105, acc=0.23055554926395416, loss=3.1635661125183105
train: epoch 7, loss 0.5312477946281433, acc=0.7929444313049316, loss=0.5312477946281433
test: epoch 7, loss 2.8898401260375977, acc=0.29722222685813904, loss=2.8898401260375977
train: epoch 8, loss 0.4611511826515198, acc=0.8214444518089294, loss=0.4611511826515198
test: epoch 8, loss 2.752490758895874, acc=0.3027777671813965, loss=2.752490758895874
train: epoch 9, loss 0.4291614592075348, acc=0.8384444713592529, loss=0.4291614592075348
test: epoch 9, loss 2.373361110687256, acc=0.2805555462837219, loss=2.373361110687256
train: epoch 10, loss 0.3768678605556488, acc=0.8615000247955322, loss=0.3768678605556488
test: epoch 10, loss 2.5899858474731445, acc=0.3305555582046509, loss=2.5899858474731445
train: epoch 11, loss 0.3662707507610321, acc=0.8651111125946045, loss=0.3662707507610321
test: epoch 11, loss 2.6852169036865234, acc=0.3222222328186035, loss=2.6852169036865234
train: epoch 12, loss 0.31990793347358704, acc=0.8871111273765564, loss=0.31990793347358704
test: epoch 12, loss 2.261590003967285, acc=0.2750000059604645, loss=2.261590003967285
train: epoch 13, loss 0.28419211506843567, acc=0.9004444479942322, loss=0.28419211506843567
test: epoch 13, loss 2.5625357627868652, acc=0.3583333194255829, loss=2.5625357627868652
train: epoch 14, loss 0.2744506001472473, acc=0.9053333401679993, loss=0.2744506001472473
test: epoch 14, loss 2.1097571849823, acc=0.35555556416511536, loss=2.1097571849823
train: epoch 15, loss 0.27244365215301514, acc=0.9049444198608398, loss=0.27244365215301514
test: epoch 15, loss 2.148791551589966, acc=0.3611111044883728, loss=2.148791551589966
train: epoch 16, loss 0.2458447962999344, acc=0.9164444208145142, loss=0.2458447962999344
test: epoch 16, loss 2.3413753509521484, acc=0.36944442987442017, loss=2.3413753509521484
train: epoch 17, loss 0.2237195521593094, acc=0.9244999885559082, loss=0.2237195521593094
test: epoch 17, loss 1.9959253072738647, acc=0.4000000059604645, loss=1.9959253072738647
train: epoch 18, loss 0.24172668159008026, acc=0.9176666736602783, loss=0.24172668159008026
test: epoch 18, loss 1.7928264141082764, acc=0.42222222685813904, loss=1.7928264141082764
train: epoch 19, loss 0.20354945957660675, acc=0.9304444193840027, loss=0.20354945957660675
test: epoch 19, loss 2.0055997371673584, acc=0.4277777671813965, loss=2.0055997371673584
train: epoch 20, loss 0.1870170533657074, acc=0.9366111159324646, loss=0.1870170533657074
test: epoch 20, loss 1.886409044265747, acc=0.42500001192092896, loss=1.886409044265747
train: epoch 21, loss 0.218098983168602, acc=0.9240555763244629, loss=0.218098983168602
test: epoch 21, loss 1.8694753646850586, acc=0.4555555582046509, loss=1.8694753646850586
train: epoch 22, loss 0.17740730941295624, acc=0.9391666650772095, loss=0.17740730941295624
test: epoch 22, loss 2.1989939212799072, acc=0.42222222685813904, loss=2.1989939212799072
train: epoch 23, loss 0.18635766208171844, acc=0.9372777938842773, loss=0.18635766208171844
test: epoch 23, loss 1.6128867864608765, acc=0.46388888359069824, loss=1.6128867864608765
train: epoch 24, loss 0.1663227528333664, acc=0.9450555443763733, loss=0.1663227528333664
test: epoch 24, loss 1.9753530025482178, acc=0.4444444477558136, loss=1.9753530025482178
train: epoch 25, loss 0.16803063452243805, acc=0.941444456577301, loss=0.16803063452243805
test: epoch 25, loss 1.9082512855529785, acc=0.4694444537162781, loss=1.9082512855529785
train: epoch 26, loss 0.1560918390750885, acc=0.9471111297607422, loss=0.1560918390750885
test: epoch 26, loss 2.423388957977295, acc=0.4444444477558136, loss=2.423388957977295
train: epoch 27, loss 0.16609567403793335, acc=0.9436666369438171, loss=0.16609567403793335
test: epoch 27, loss 1.8893555402755737, acc=0.4694444537162781, loss=1.8893555402755737
train: epoch 28, loss 0.1456080973148346, acc=0.9507777690887451, loss=0.1456080973148346
test: epoch 28, loss 2.0226950645446777, acc=0.4305555522441864, loss=2.0226950645446777
train: epoch 29, loss 0.1447596251964569, acc=0.9511666893959045, loss=0.1447596251964569
test: epoch 29, loss 2.000429630279541, acc=0.4166666567325592, loss=2.000429630279541
train: epoch 30, loss 0.15727119147777557, acc=0.94605553150177, loss=0.15727119147777557
test: epoch 30, loss 1.6689019203186035, acc=0.4833333194255829, loss=1.6689019203186035
train: epoch 31, loss 0.1608063131570816, acc=0.9461666941642761, loss=0.1608063131570816
test: epoch 31, loss 1.8210158348083496, acc=0.4888888895511627, loss=1.8210158348083496
train: epoch 32, loss 0.14721953868865967, acc=0.9510555267333984, loss=0.14721953868865967
test: epoch 32, loss 1.9843275547027588, acc=0.5138888955116272, loss=1.9843275547027588
train: epoch 33, loss 0.13737456500530243, acc=0.9547777771949768, loss=0.13737456500530243
test: epoch 33, loss 1.8394665718078613, acc=0.4694444537162781, loss=1.8394665718078613
train: epoch 34, loss 0.14868022501468658, acc=0.9502221941947937, loss=0.14868022501468658
test: epoch 34, loss 2.0723252296447754, acc=0.5388888716697693, loss=2.0723252296447754
train: epoch 35, loss 0.14117573201656342, acc=0.9528889060020447, loss=0.14117573201656342
test: epoch 35, loss 2.0336999893188477, acc=0.46388888359069824, loss=2.0336999893188477
train: epoch 36, loss 0.13751059770584106, acc=0.9538888931274414, loss=0.13751059770584106
test: epoch 36, loss 1.9686418771743774, acc=0.5, loss=1.9686418771743774
train: epoch 37, loss 0.12782563269138336, acc=0.957444429397583, loss=0.12782563269138336
test: epoch 37, loss 1.578852891921997, acc=0.5666666626930237, loss=1.578852891921997
train: epoch 38, loss 0.14576709270477295, acc=0.9494444727897644, loss=0.14576709270477295
test: epoch 38, loss 1.9451528787612915, acc=0.5861111283302307, loss=1.9451528787612915
train: epoch 39, loss 0.11677971482276917, acc=0.9608333110809326, loss=0.11677971482276917
test: epoch 39, loss 2.056788921356201, acc=0.4972222149372101, loss=2.056788921356201
train: epoch 40, loss 0.13179782032966614, acc=0.9556666612625122, loss=0.13179782032966614
test: epoch 40, loss 1.9789950847625732, acc=0.5388888716697693, loss=1.9789950847625732
train: epoch 41, loss 0.12673400342464447, acc=0.9573333263397217, loss=0.12673400342464447
test: epoch 41, loss 1.9777330160140991, acc=0.47777777910232544, loss=1.9777330160140991
train: epoch 42, loss 0.1291884332895279, acc=0.9570000171661377, loss=0.1291884332895279
test: epoch 42, loss 1.8223176002502441, acc=0.4972222149372101, loss=1.8223176002502441
train: epoch 43, loss 0.11552872508764267, acc=0.9596666693687439, loss=0.11552872508764267
test: epoch 43, loss 1.7404181957244873, acc=0.5888888835906982, loss=1.7404181957244873
train: epoch 44, loss 0.1348903328180313, acc=0.9557777643203735, loss=0.1348903328180313
test: epoch 44, loss 1.5010815858840942, acc=0.5305555462837219, loss=1.5010815858840942
train: epoch 45, loss 0.11852309107780457, acc=0.9594444632530212, loss=0.11852309107780457
test: epoch 45, loss 1.8958252668380737, acc=0.550000011920929, loss=1.8958252668380737
train: epoch 46, loss 0.11462431401014328, acc=0.9622222185134888, loss=0.11462431401014328
test: epoch 46, loss 1.6547207832336426, acc=0.5583333373069763, loss=1.6547207832336426
train: epoch 47, loss 0.11576966941356659, acc=0.9642778038978577, loss=0.11576966941356659
test: epoch 47, loss 1.8084322214126587, acc=0.5361111164093018, loss=1.8084322214126587
train: epoch 48, loss 0.11767754703760147, acc=0.9611111283302307, loss=0.11767754703760147
test: epoch 48, loss 1.56838858127594, acc=0.5138888955116272, loss=1.56838858127594
train: epoch 49, loss 0.1097378060221672, acc=0.9633333086967468, loss=0.1097378060221672
test: epoch 49, loss 1.64543879032135, acc=0.5361111164093018, loss=1.64543879032135
train: epoch 50, loss 0.10985937714576721, acc=0.9638333320617676, loss=0.10985937714576721
test: epoch 50, loss 1.7452356815338135, acc=0.5555555820465088, loss=1.7452356815338135
train: epoch 51, loss 0.10826121270656586, acc=0.9639999866485596, loss=0.10826121270656586
test: epoch 51, loss 1.5062141418457031, acc=0.6027777791023254, loss=1.5062141418457031
train: epoch 52, loss 0.11668363958597183, acc=0.9647777676582336, loss=0.11668363958597183
test: epoch 52, loss 1.6700985431671143, acc=0.5805555582046509, loss=1.6700985431671143
train: epoch 53, loss 0.10888209193944931, acc=0.9626111388206482, loss=0.10888209193944931
test: epoch 53, loss 1.5406162738800049, acc=0.5638889074325562, loss=1.5406162738800049
train: epoch 54, loss 0.10184001922607422, acc=0.9652222394943237, loss=0.10184001922607422
test: epoch 54, loss 1.502750039100647, acc=0.5916666388511658, loss=1.502750039100647
train: epoch 55, loss 0.09644659608602524, acc=0.9681666493415833, loss=0.09644659608602524
test: epoch 55, loss 1.3217028379440308, acc=0.6333333253860474, loss=1.3217028379440308
train: epoch 56, loss 0.10053602606058121, acc=0.965833306312561, loss=0.10053602606058121
test: epoch 56, loss 1.5972930192947388, acc=0.625, loss=1.5972930192947388
train: epoch 57, loss 0.10174159705638885, acc=0.9670000076293945, loss=0.10174159705638885
test: epoch 57, loss 1.3079020977020264, acc=0.6277777552604675, loss=1.3079020977020264
train: epoch 58, loss 0.11098846793174744, acc=0.9651111364364624, loss=0.11098846793174744
test: epoch 58, loss 1.4209834337234497, acc=0.6277777552604675, loss=1.4209834337234497
train: epoch 59, loss 0.09598664194345474, acc=0.9693333506584167, loss=0.09598664194345474
test: epoch 59, loss 1.3913568258285522, acc=0.6555555462837219, loss=1.3913568258285522
train: epoch 60, loss 0.08416059613227844, acc=0.9732221961021423, loss=0.08416059613227844
test: epoch 60, loss 1.2630424499511719, acc=0.6277777552604675, loss=1.2630424499511719
train: epoch 61, loss 0.09603925049304962, acc=0.9681110978126526, loss=0.09603925049304962
test: epoch 61, loss 1.2450668811798096, acc=0.6583333611488342, loss=1.2450668811798096
train: epoch 62, loss 0.10221350938081741, acc=0.9674999713897705, loss=0.10221350938081741
test: epoch 62, loss 1.2029023170471191, acc=0.6694444417953491, loss=1.2029023170471191
train: epoch 63, loss 0.1011229082942009, acc=0.967555582523346, loss=0.1011229082942009
test: epoch 63, loss 0.9850298762321472, acc=0.7250000238418579, loss=0.9850298762321472
train: epoch 64, loss 0.09051007032394409, acc=0.9710555672645569, loss=0.09051007032394409
test: epoch 64, loss 1.583019495010376, acc=0.6416666507720947, loss=1.583019495010376
train: epoch 65, loss 0.09397569298744202, acc=0.9693889021873474, loss=0.09397569298744202
test: epoch 65, loss 1.3351079225540161, acc=0.6666666865348816, loss=1.3351079225540161
train: epoch 66, loss 0.08966097980737686, acc=0.9719444513320923, loss=0.08966097980737686
test: epoch 66, loss 0.9538024067878723, acc=0.675000011920929, loss=0.9538024067878723
train: epoch 67, loss 0.0841929167509079, acc=0.972944438457489, loss=0.0841929167509079
test: epoch 67, loss 1.115561842918396, acc=0.6666666865348816, loss=1.115561842918396
train: epoch 68, loss 0.09153993427753448, acc=0.9691666960716248, loss=0.09153993427753448
test: epoch 68, loss 1.2858279943466187, acc=0.644444465637207, loss=1.2858279943466187
train: epoch 69, loss 0.08487400412559509, acc=0.9736666679382324, loss=0.08487400412559509
test: epoch 69, loss 0.9728651642799377, acc=0.7361111044883728, loss=0.9728651642799377
train: epoch 70, loss 0.08513594418764114, acc=0.9721666574478149, loss=0.08513594418764114
test: epoch 70, loss 1.0028676986694336, acc=0.7027778029441833, loss=1.0028676986694336
train: epoch 71, loss 0.09348690509796143, acc=0.9700000286102295, loss=0.09348690509796143
test: epoch 71, loss 1.1515223979949951, acc=0.6861110925674438, loss=1.1515223979949951
train: epoch 72, loss 0.08326835185289383, acc=0.9725000262260437, loss=0.08326835185289383
test: epoch 72, loss 1.0703542232513428, acc=0.7666666507720947, loss=1.0703542232513428
train: epoch 73, loss 0.07994749397039413, acc=0.973111093044281, loss=0.07994749397039413
test: epoch 73, loss 0.6005270481109619, acc=0.7749999761581421, loss=0.6005270481109619
train: epoch 74, loss 0.08878298848867416, acc=0.9733333587646484, loss=0.08878298848867416
test: epoch 74, loss 0.7794243097305298, acc=0.7333333492279053, loss=0.7794243097305298
train: epoch 75, loss 0.07113616168498993, acc=0.97688889503479, loss=0.07113616168498993
test: epoch 75, loss 0.8561967015266418, acc=0.7555555701255798, loss=0.8561967015266418
train: epoch 76, loss 0.08920791745185852, acc=0.9713888764381409, loss=0.08920791745185852
test: epoch 76, loss 1.002366304397583, acc=0.7416666746139526, loss=1.002366304397583
train: epoch 77, loss 0.0810871347784996, acc=0.9729999899864197, loss=0.0810871347784996
test: epoch 77, loss 0.7458592653274536, acc=0.7861111164093018, loss=0.7458592653274536
train: epoch 78, loss 0.08874442428350449, acc=0.9709444642066956, loss=0.08874442428350449
test: epoch 78, loss 0.8781255483627319, acc=0.7805555462837219, loss=0.8781255483627319
train: epoch 79, loss 0.07636752724647522, acc=0.9767777919769287, loss=0.07636752724647522
test: epoch 79, loss 0.6849544048309326, acc=0.7833333611488342, loss=0.6849544048309326
train: epoch 80, loss 0.07910734415054321, acc=0.9750000238418579, loss=0.07910734415054321
test: epoch 80, loss 0.931352436542511, acc=0.7722222208976746, loss=0.931352436542511
train: epoch 81, loss 0.06723985075950623, acc=0.9793888926506042, loss=0.06723985075950623
test: epoch 81, loss 0.8423535823822021, acc=0.7722222208976746, loss=0.8423535823822021
train: epoch 82, loss 0.08381131291389465, acc=0.9739444255828857, loss=0.08381131291389465
test: epoch 82, loss 0.629034161567688, acc=0.7638888955116272, loss=0.629034161567688
train: epoch 83, loss 0.07516882568597794, acc=0.9771666526794434, loss=0.07516882568597794
test: epoch 83, loss 0.6545650362968445, acc=0.769444465637207, loss=0.6545650362968445
train: epoch 84, loss 0.08101613819599152, acc=0.9753333330154419, loss=0.08101613819599152
test: epoch 84, loss 0.7894822359085083, acc=0.7805555462837219, loss=0.7894822359085083
train: epoch 85, loss 0.07596831023693085, acc=0.9765555262565613, loss=0.07596831023693085
test: epoch 85, loss 0.8350773453712463, acc=0.7888888716697693, loss=0.8350773453712463
train: epoch 86, loss 0.0706227645277977, acc=0.9777222275733948, loss=0.0706227645277977
test: epoch 86, loss 0.88120037317276, acc=0.800000011920929, loss=0.88120037317276
train: epoch 87, loss 0.06512464582920074, acc=0.9797777533531189, loss=0.06512464582920074
test: epoch 87, loss 0.7178846597671509, acc=0.7777777910232544, loss=0.7178846597671509
train: epoch 88, loss 0.07316363602876663, acc=0.9766111373901367, loss=0.07316363602876663
test: epoch 88, loss 0.6820297837257385, acc=0.800000011920929, loss=0.6820297837257385
train: epoch 89, loss 0.06873154640197754, acc=0.9789999723434448, loss=0.06873154640197754
test: epoch 89, loss 0.4884650409221649, acc=0.8444444537162781, loss=0.4884650409221649
train: epoch 90, loss 0.06936685740947723, acc=0.9780555367469788, loss=0.06936685740947723
test: epoch 90, loss 0.7740837335586548, acc=0.7861111164093018, loss=0.7740837335586548
train: epoch 91, loss 0.07200692594051361, acc=0.975777804851532, loss=0.07200692594051361
test: epoch 91, loss 0.8353676795959473, acc=0.7916666865348816, loss=0.8353676795959473
train: epoch 92, loss 0.07035626471042633, acc=0.9776111245155334, loss=0.07035626471042633
test: epoch 92, loss 0.654631495475769, acc=0.8277778029441833, loss=0.654631495475769
train: epoch 93, loss 0.05700124055147171, acc=0.9818888902664185, loss=0.05700124055147171
test: epoch 93, loss 0.6568573117256165, acc=0.8083333373069763, loss=0.6568573117256165
train: epoch 94, loss 0.0639922097325325, acc=0.9794444441795349, loss=0.0639922097325325
test: epoch 94, loss 0.6604766845703125, acc=0.8222222328186035, loss=0.6604766845703125
train: epoch 95, loss 0.05592671036720276, acc=0.9826111197471619, loss=0.05592671036720276
test: epoch 95, loss 0.5783103704452515, acc=0.824999988079071, loss=0.5783103704452515
train: epoch 96, loss 0.07010591775178909, acc=0.9783889055252075, loss=0.07010591775178909
test: epoch 96, loss 0.4139818847179413, acc=0.8611111044883728, loss=0.4139818847179413
train: epoch 97, loss 0.06993747502565384, acc=0.9774444699287415, loss=0.06993747502565384
test: epoch 97, loss 0.5668444633483887, acc=0.8388888835906982, loss=0.5668444633483887
train: epoch 98, loss 0.06616844236850739, acc=0.9786666631698608, loss=0.06616844236850739
test: epoch 98, loss 0.6204863786697388, acc=0.8194444179534912, loss=0.6204863786697388
train: epoch 99, loss 0.06008967384696007, acc=0.980388879776001, loss=0.06008967384696007
test: epoch 99, loss 0.6932603716850281, acc=0.8194444179534912, loss=0.6932603716850281
train: epoch 100, loss 0.06257200986146927, acc=0.9803333282470703, loss=0.06257200986146927
test: epoch 100, loss 0.5811619162559509, acc=0.8583333492279053, loss=0.5811619162559509
train: epoch 101, loss 0.060859039425849915, acc=0.9799444675445557, loss=0.060859039425849915
test: epoch 101, loss 0.5789633989334106, acc=0.8583333492279053, loss=0.5789633989334106
train: epoch 102, loss 0.05500279739499092, acc=0.9819444417953491, loss=0.05500279739499092
test: epoch 102, loss 0.7041518688201904, acc=0.8388888835906982, loss=0.7041518688201904
train: epoch 103, loss 0.05354864150285721, acc=0.9827777743339539, loss=0.05354864150285721
test: epoch 103, loss 0.475710391998291, acc=0.855555534362793, loss=0.475710391998291
train: epoch 104, loss 0.06545814126729965, acc=0.9819999933242798, loss=0.06545814126729965
test: epoch 104, loss 0.48721152544021606, acc=0.8583333492279053, loss=0.48721152544021606
train: epoch 105, loss 0.05770247429609299, acc=0.9818888902664185, loss=0.05770247429609299
test: epoch 105, loss 0.6374067664146423, acc=0.8611111044883728, loss=0.6374067664146423
train: epoch 106, loss 0.04861080273985863, acc=0.9845555424690247, loss=0.04861080273985863
test: epoch 106, loss 0.4026305377483368, acc=0.8500000238418579, loss=0.4026305377483368
train: epoch 107, loss 0.05859364941716194, acc=0.9817777872085571, loss=0.05859364941716194
test: epoch 107, loss 0.3503396213054657, acc=0.8916666507720947, loss=0.3503396213054657
train: epoch 108, loss 0.05512452498078346, acc=0.9831110835075378, loss=0.05512452498078346
test: epoch 108, loss 0.38598141074180603, acc=0.8999999761581421, loss=0.38598141074180603
train: epoch 109, loss 0.06230241805315018, acc=0.9812777638435364, loss=0.06230241805315018
test: epoch 109, loss 0.36741888523101807, acc=0.9083333611488342, loss=0.36741888523101807
train: epoch 110, loss 0.05804005637764931, acc=0.9825000166893005, loss=0.05804005637764931
test: epoch 110, loss 0.33324387669563293, acc=0.9055555462837219, loss=0.33324387669563293
train: epoch 111, loss 0.04893932491540909, acc=0.984333336353302, loss=0.04893932491540909
test: epoch 111, loss 0.3283921778202057, acc=0.9055555462837219, loss=0.3283921778202057
train: epoch 112, loss 0.04910295456647873, acc=0.9846110939979553, loss=0.04910295456647873
test: epoch 112, loss 0.503070056438446, acc=0.9027777910232544, loss=0.503070056438446
train: epoch 113, loss 0.04384788125753403, acc=0.9858888983726501, loss=0.04384788125753403
test: epoch 113, loss 0.34175893664360046, acc=0.9277777671813965, loss=0.34175893664360046
train: epoch 114, loss 0.058281902223825455, acc=0.9829999804496765, loss=0.058281902223825455
test: epoch 114, loss 0.3034213185310364, acc=0.9277777671813965, loss=0.3034213185310364
train: epoch 115, loss 0.05545778572559357, acc=0.9833333492279053, loss=0.05545778572559357
test: epoch 115, loss 0.3276301324367523, acc=0.9305555820465088, loss=0.3276301324367523
train: epoch 116, loss 0.05508041009306908, acc=0.9847221970558167, loss=0.05508041009306908
test: epoch 116, loss 0.36460232734680176, acc=0.9222221970558167, loss=0.36460232734680176
train: epoch 117, loss 0.042172666639089584, acc=0.9871666431427002, loss=0.042172666639089584
test: epoch 117, loss 0.31084492802619934, acc=0.9305555820465088, loss=0.31084492802619934
train: epoch 118, loss 0.03720713034272194, acc=0.9883333444595337, loss=0.03720713034272194
test: epoch 118, loss 0.32815316319465637, acc=0.9138888716697693, loss=0.32815316319465637
train: epoch 119, loss 0.05508023872971535, acc=0.9845555424690247, loss=0.05508023872971535
test: epoch 119, loss 0.2677772045135498, acc=0.9277777671813965, loss=0.2677772045135498
train: epoch 120, loss 0.042675863951444626, acc=0.9860000014305115, loss=0.042675863951444626
test: epoch 120, loss 0.3375442922115326, acc=0.8916666507720947, loss=0.3375442922115326
train: epoch 121, loss 0.04582331329584122, acc=0.9861666560173035, loss=0.04582331329584122
test: epoch 121, loss 0.519598126411438, acc=0.9083333611488342, loss=0.519598126411438
train: epoch 122, loss 0.04782785847783089, acc=0.9858888983726501, loss=0.04782785847783089
test: epoch 122, loss 0.3798682391643524, acc=0.9277777671813965, loss=0.3798682391643524
train: epoch 123, loss 0.04942534863948822, acc=0.9850555658340454, loss=0.04942534863948822
test: epoch 123, loss 0.33861005306243896, acc=0.9277777671813965, loss=0.33861005306243896
train: epoch 124, loss 0.04527504742145538, acc=0.9847777485847473, loss=0.04527504742145538
test: epoch 124, loss 0.332993745803833, acc=0.9305555820465088, loss=0.332993745803833
train: epoch 125, loss 0.03681162744760513, acc=0.9886666536331177, loss=0.03681162744760513
test: epoch 125, loss 0.22729168832302094, acc=0.9305555820465088, loss=0.22729168832302094
train: epoch 126, loss 0.04402947798371315, acc=0.9849444627761841, loss=0.04402947798371315
test: epoch 126, loss 0.2976277470588684, acc=0.9194444417953491, loss=0.2976277470588684
train: epoch 127, loss 0.04021655395627022, acc=0.9863333106040955, loss=0.04021655395627022
test: epoch 127, loss 0.2541658580303192, acc=0.9305555820465088, loss=0.2541658580303192
train: epoch 128, loss 0.0377977080643177, acc=0.9879444241523743, loss=0.0377977080643177
test: epoch 128, loss 0.32328152656555176, acc=0.9305555820465088, loss=0.32328152656555176
train: epoch 129, loss 0.04292865842580795, acc=0.9857777953147888, loss=0.04292865842580795
test: epoch 129, loss 0.2630904018878937, acc=0.9305555820465088, loss=0.2630904018878937
train: epoch 130, loss 0.03950836881995201, acc=0.988444447517395, loss=0.03950836881995201
test: epoch 130, loss 0.2408965677022934, acc=0.9277777671813965, loss=0.2408965677022934
train: epoch 131, loss 0.038746971637010574, acc=0.9872778058052063, loss=0.038746971637010574
test: epoch 131, loss 0.23417091369628906, acc=0.9277777671813965, loss=0.23417091369628906
train: epoch 132, loss 0.035500556230545044, acc=0.9868333339691162, loss=0.035500556230545044
test: epoch 132, loss 0.24948036670684814, acc=0.9222221970558167, loss=0.24948036670684814
train: epoch 133, loss 0.05083141103386879, acc=0.9853888750076294, loss=0.05083141103386879
test: epoch 133, loss 0.19582656025886536, acc=0.9277777671813965, loss=0.19582656025886536
train: epoch 134, loss 0.04686008766293526, acc=0.9858888983726501, loss=0.04686008766293526
test: epoch 134, loss 0.2513054311275482, acc=0.9305555820465088, loss=0.2513054311275482
train: epoch 135, loss 0.03861208260059357, acc=0.987500011920929, loss=0.03861208260059357
test: epoch 135, loss 0.40499797463417053, acc=0.9277777671813965, loss=0.40499797463417053
train: epoch 136, loss 0.0387362577021122, acc=0.9865000247955322, loss=0.0387362577021122
test: epoch 136, loss 0.3325842618942261, acc=0.9194444417953491, loss=0.3325842618942261
train: epoch 137, loss 0.05815630778670311, acc=0.9828333258628845, loss=0.05815630778670311
test: epoch 137, loss 0.24480748176574707, acc=0.9277777671813965, loss=0.24480748176574707
train: epoch 138, loss 0.04398978129029274, acc=0.9855555295944214, loss=0.04398978129029274
test: epoch 138, loss 0.2118709236383438, acc=0.9305555820465088, loss=0.2118709236383438
train: epoch 139, loss 0.041673026978969574, acc=0.9871666431427002, loss=0.041673026978969574
test: epoch 139, loss 0.2366591989994049, acc=0.9277777671813965, loss=0.2366591989994049
train: epoch 140, loss 0.051914431154727936, acc=0.9861111044883728, loss=0.051914431154727936
test: epoch 140, loss 0.24711497128009796, acc=0.9277777671813965, loss=0.24711497128009796
train: epoch 141, loss 0.03798507899045944, acc=0.9885555505752563, loss=0.03798507899045944
test: epoch 141, loss 0.36193832755088806, acc=0.9305555820465088, loss=0.36193832755088806
train: epoch 142, loss 0.03664609417319298, acc=0.988111138343811, loss=0.03664609417319298
test: epoch 142, loss 0.42247286438941956, acc=0.9111111164093018, loss=0.42247286438941956
train: epoch 143, loss 0.03760360926389694, acc=0.9875555634498596, loss=0.03760360926389694
test: epoch 143, loss 0.3284640908241272, acc=0.9083333611488342, loss=0.3284640908241272
train: epoch 144, loss 0.04484173655509949, acc=0.9856666922569275, loss=0.04484173655509949
test: epoch 144, loss 0.30690616369247437, acc=0.9305555820465088, loss=0.30690616369247437
train: epoch 145, loss 0.02962207980453968, acc=0.9896666407585144, loss=0.02962207980453968
test: epoch 145, loss 0.3726711869239807, acc=0.9305555820465088, loss=0.3726711869239807
train: epoch 146, loss 0.03900937736034393, acc=0.987333357334137, loss=0.03900937736034393
test: epoch 146, loss 0.3374016284942627, acc=0.9305555820465088, loss=0.3374016284942627
train: epoch 147, loss 0.038859207183122635, acc=0.9860000014305115, loss=0.038859207183122635
test: epoch 147, loss 0.2996733784675598, acc=0.9194444417953491, loss=0.2996733784675598
train: epoch 148, loss 0.03718911483883858, acc=0.9875555634498596, loss=0.03718911483883858
test: epoch 148, loss 0.21719428896903992, acc=0.9305555820465088, loss=0.21719428896903992
train: epoch 149, loss 0.044468194246292114, acc=0.9869999885559082, loss=0.044468194246292114
test: epoch 149, loss 0.22381499409675598, acc=0.9305555820465088, loss=0.22381499409675598
train: epoch 150, loss 0.04102370887994766, acc=0.9871666431427002, loss=0.04102370887994766
test: epoch 150, loss 0.15525858104228973, acc=0.9277777671813965, loss=0.15525858104228973
