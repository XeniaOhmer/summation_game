# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=2.0", "--temp_decay=1", "--one_hot=true", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=154166659, receiver_embed_dim=128, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.73439359664917, acc=0.10999999940395355, loss=2.73439359664917
test: epoch 1, loss 4.569082736968994, acc=0.07500000298023224, loss=4.569082736968994
train: epoch 2, loss 1.6000639200210571, acc=0.33544445037841797, loss=1.6000639200210571
test: epoch 2, loss 2.6511590480804443, acc=0.24722221493721008, loss=2.6511590480804443
train: epoch 3, loss 1.0091814994812012, acc=0.5791110992431641, loss=1.0091814994812012
test: epoch 3, loss 2.6121907234191895, acc=0.3027777671813965, loss=2.6121907234191895
train: epoch 4, loss 0.6376069188117981, acc=0.7504444718360901, loss=0.6376069188117981
test: epoch 4, loss 2.0677402019500732, acc=0.40833333134651184, loss=2.0677402019500732
train: epoch 5, loss 0.4205813407897949, acc=0.8367778062820435, loss=0.4205813407897949
test: epoch 5, loss 2.164947509765625, acc=0.42500001192092896, loss=2.164947509765625
train: epoch 6, loss 0.3173612952232361, acc=0.8870555758476257, loss=0.3173612952232361
test: epoch 6, loss 1.671061635017395, acc=0.4027777910232544, loss=1.671061635017395
train: epoch 7, loss 0.2725450098514557, acc=0.9022777676582336, loss=0.2725450098514557
test: epoch 7, loss 1.4379774332046509, acc=0.5388888716697693, loss=1.4379774332046509
train: epoch 8, loss 0.2287706881761551, acc=0.9189444184303284, loss=0.2287706881761551
test: epoch 8, loss 2.0499680042266846, acc=0.4555555582046509, loss=2.0499680042266846
train: epoch 9, loss 0.20443139970302582, acc=0.9292222261428833, loss=0.20443139970302582
test: epoch 9, loss 1.9547688961029053, acc=0.4416666626930237, loss=1.9547688961029053
train: epoch 10, loss 0.21412628889083862, acc=0.9255555272102356, loss=0.21412628889083862
test: epoch 10, loss 1.7932568788528442, acc=0.519444465637207, loss=1.7932568788528442
train: epoch 11, loss 0.15575040876865387, acc=0.9442222118377686, loss=0.15575040876865387
test: epoch 11, loss 1.731128454208374, acc=0.5111111402511597, loss=1.731128454208374
train: epoch 12, loss 0.16765549778938293, acc=0.9394444227218628, loss=0.16765549778938293
test: epoch 12, loss 1.7971110343933105, acc=0.5666666626930237, loss=1.7971110343933105
train: epoch 13, loss 0.15711715817451477, acc=0.9472222328186035, loss=0.15711715817451477
test: epoch 13, loss 1.6093848943710327, acc=0.5444444417953491, loss=1.6093848943710327
train: epoch 14, loss 0.14652593433856964, acc=0.9498888850212097, loss=0.14652593433856964
test: epoch 14, loss 1.373220682144165, acc=0.5944444537162781, loss=1.373220682144165
train: epoch 15, loss 0.1534288227558136, acc=0.9502221941947937, loss=0.1534288227558136
test: epoch 15, loss 1.628061294555664, acc=0.5972222089767456, loss=1.628061294555664
train: epoch 16, loss 0.12421471625566483, acc=0.9576666951179504, loss=0.12421471625566483
test: epoch 16, loss 1.8367785215377808, acc=0.5555555820465088, loss=1.8367785215377808
train: epoch 17, loss 0.11681102961301804, acc=0.9614999890327454, loss=0.11681102961301804
test: epoch 17, loss 2.0652005672454834, acc=0.5388888716697693, loss=2.0652005672454834
train: epoch 18, loss 0.12301827222108841, acc=0.9610555768013, loss=0.12301827222108841
test: epoch 18, loss 1.3848309516906738, acc=0.6833333373069763, loss=1.3848309516906738
train: epoch 19, loss 0.11391562968492508, acc=0.9641110897064209, loss=0.11391562968492508
test: epoch 19, loss 1.1551480293273926, acc=0.6888889074325562, loss=1.1551480293273926
train: epoch 20, loss 0.09998907893896103, acc=0.9685555696487427, loss=0.09998907893896103
test: epoch 20, loss 1.4990495443344116, acc=0.6861110925674438, loss=1.4990495443344116
train: epoch 21, loss 0.11813345551490784, acc=0.9646666646003723, loss=0.11813345551490784
test: epoch 21, loss 1.5060559511184692, acc=0.6333333253860474, loss=1.5060559511184692
train: epoch 22, loss 0.09422296285629272, acc=0.971833348274231, loss=0.09422296285629272
test: epoch 22, loss 1.1973042488098145, acc=0.7222222089767456, loss=1.1973042488098145
train: epoch 23, loss 0.08263399451971054, acc=0.9751666784286499, loss=0.08263399451971054
test: epoch 23, loss 0.9114204049110413, acc=0.7916666865348816, loss=0.9114204049110413
train: epoch 24, loss 0.07449828088283539, acc=0.9767777919769287, loss=0.07449828088283539
test: epoch 24, loss 1.0097628831863403, acc=0.7777777910232544, loss=1.0097628831863403
train: epoch 25, loss 0.07684655487537384, acc=0.9769444465637207, loss=0.07684655487537384
test: epoch 25, loss 1.2193922996520996, acc=0.6777777671813965, loss=1.2193922996520996
train: epoch 26, loss 0.07849210500717163, acc=0.977055549621582, loss=0.07849210500717163
test: epoch 26, loss 0.49257293343544006, acc=0.8583333492279053, loss=0.49257293343544006
train: epoch 27, loss 0.08056468516588211, acc=0.9763333201408386, loss=0.08056468516588211
test: epoch 27, loss 0.6010137796401978, acc=0.855555534362793, loss=0.6010137796401978
train: epoch 28, loss 0.06179046258330345, acc=0.9816666841506958, loss=0.06179046258330345
test: epoch 28, loss 0.4547964334487915, acc=0.8999999761581421, loss=0.4547964334487915
train: epoch 29, loss 0.09147758781909943, acc=0.9752222299575806, loss=0.09147758781909943
test: epoch 29, loss 0.2667475938796997, acc=0.9361110925674438, loss=0.2667475938796997
train: epoch 30, loss 0.06126357242465019, acc=0.981333315372467, loss=0.06126357242465019
test: epoch 30, loss 0.23987935483455658, acc=0.9305555820465088, loss=0.23987935483455658
train: epoch 31, loss 0.05733995512127876, acc=0.984000027179718, loss=0.05733995512127876
test: epoch 31, loss 0.22102802991867065, acc=0.9333333373069763, loss=0.22102802991867065
train: epoch 32, loss 0.055480025708675385, acc=0.9837222099304199, loss=0.055480025708675385
test: epoch 32, loss 0.2559245228767395, acc=0.9527778029441833, loss=0.2559245228767395
train: epoch 33, loss 0.049754828214645386, acc=0.9869999885559082, loss=0.049754828214645386
test: epoch 33, loss 0.14320987462997437, acc=0.9694444537162781, loss=0.14320987462997437
train: epoch 34, loss 0.08919630944728851, acc=0.975777804851532, loss=0.08919630944728851
test: epoch 34, loss 0.11573899537324905, acc=0.9638888835906982, loss=0.11573899537324905
train: epoch 35, loss 0.057743217796087265, acc=0.9837777614593506, loss=0.057743217796087265
test: epoch 35, loss 0.2554306089878082, acc=0.9361110925674438, loss=0.2554306089878082
train: epoch 36, loss 0.04761308804154396, acc=0.9848889112472534, loss=0.04761308804154396
test: epoch 36, loss 0.15713068842887878, acc=0.980555534362793, loss=0.15713068842887878
train: epoch 37, loss 0.0728122815489769, acc=0.9822221994400024, loss=0.0728122815489769
test: epoch 37, loss 0.09614891558885574, acc=0.9722222089767456, loss=0.09614891558885574
train: epoch 38, loss 0.08095003664493561, acc=0.9787222146987915, loss=0.08095003664493561
test: epoch 38, loss 0.13147585093975067, acc=0.9666666388511658, loss=0.13147585093975067
train: epoch 39, loss 0.051045868545770645, acc=0.9853333234786987, loss=0.051045868545770645
test: epoch 39, loss 0.05114438012242317, acc=0.9861111044883728, loss=0.05114438012242317
train: epoch 40, loss 0.03673436492681503, acc=0.9899444580078125, loss=0.03673436492681503
test: epoch 40, loss 0.3274582028388977, acc=0.9444444179534912, loss=0.3274582028388977
train: epoch 41, loss 0.02705291658639908, acc=0.9913889169692993, loss=0.02705291658639908
test: epoch 41, loss 0.04071030765771866, acc=0.9888888597488403, loss=0.04071030765771866
train: epoch 42, loss 0.06238885968923569, acc=0.9824444651603699, loss=0.06238885968923569
test: epoch 42, loss 0.14556021988391876, acc=0.9527778029441833, loss=0.14556021988391876
train: epoch 43, loss 0.0531996488571167, acc=0.9857222437858582, loss=0.0531996488571167
test: epoch 43, loss 0.036166299134492874, acc=0.9888888597488403, loss=0.036166299134492874
train: epoch 44, loss 0.03926670551300049, acc=0.99144446849823, loss=0.03926670551300049
test: epoch 44, loss 0.07599226385354996, acc=0.9777777791023254, loss=0.07599226385354996
train: epoch 45, loss 0.027242150157690048, acc=0.9911666512489319, loss=0.027242150157690048
test: epoch 45, loss 0.038489170372486115, acc=0.9888888597488403, loss=0.038489170372486115
train: epoch 46, loss 0.018551787361502647, acc=0.9934999942779541, loss=0.018551787361502647
test: epoch 46, loss 0.04900786280632019, acc=0.9888888597488403, loss=0.04900786280632019
train: epoch 47, loss 0.03840246796607971, acc=0.9905555844306946, loss=0.03840246796607971
test: epoch 47, loss 0.0253310427069664, acc=0.9888888597488403, loss=0.0253310427069664
train: epoch 48, loss 0.13302357494831085, acc=0.957444429397583, loss=0.13302357494831085
test: epoch 48, loss 0.074737548828125, acc=0.9666666388511658, loss=0.074737548828125
train: epoch 49, loss 0.028269164264202118, acc=0.9913333058357239, loss=0.028269164264202118
test: epoch 49, loss 0.03405465558171272, acc=0.9888888597488403, loss=0.03405465558171272
train: epoch 50, loss 0.022035880014300346, acc=0.9939444661140442, loss=0.022035880014300346
test: epoch 50, loss 0.04649188742041588, acc=0.9888888597488403, loss=0.04649188742041588
train: epoch 51, loss 0.016408054158091545, acc=0.9950000047683716, loss=0.016408054158091545
test: epoch 51, loss 0.03425208851695061, acc=0.9888888597488403, loss=0.03425208851695061
train: epoch 52, loss 0.07730893790721893, acc=0.9828333258628845, loss=0.07730893790721893
test: epoch 52, loss 0.0705585703253746, acc=0.980555534362793, loss=0.0705585703253746
train: epoch 53, loss 0.06567174941301346, acc=0.9827222228050232, loss=0.06567174941301346
test: epoch 53, loss 0.04380013421177864, acc=0.9861111044883728, loss=0.04380013421177864
train: epoch 54, loss 0.023256288841366768, acc=0.9929444193840027, loss=0.023256288841366768
test: epoch 54, loss 0.05480516329407692, acc=0.9861111044883728, loss=0.05480516329407692
train: epoch 55, loss 0.058891914784908295, acc=0.9858888983726501, loss=0.058891914784908295
test: epoch 55, loss 0.05719966068863869, acc=0.9861111044883728, loss=0.05719966068863869
train: epoch 56, loss 0.010951869189739227, acc=0.9959999918937683, loss=0.010951869189739227
test: epoch 56, loss 0.05739538371562958, acc=0.9888888597488403, loss=0.05739538371562958
train: epoch 57, loss 0.026353346183896065, acc=0.9932222366333008, loss=0.026353346183896065
test: epoch 57, loss 0.05043938010931015, acc=0.9888888597488403, loss=0.05043938010931015
train: epoch 58, loss 0.023314477875828743, acc=0.9945555329322815, loss=0.023314477875828743
test: epoch 58, loss 0.032026465982198715, acc=0.9888888597488403, loss=0.032026465982198715
train: epoch 59, loss 0.007694549392908812, acc=0.9967777729034424, loss=0.007694549392908812
test: epoch 59, loss 0.03618606552481651, acc=0.9888888597488403, loss=0.03618606552481651
train: epoch 60, loss 0.0846889540553093, acc=0.9848333597183228, loss=0.0846889540553093
test: epoch 60, loss 0.05288184434175491, acc=0.9861111044883728, loss=0.05288184434175491
train: epoch 61, loss 0.053827740252017975, acc=0.9868333339691162, loss=0.053827740252017975
test: epoch 61, loss 0.04014531522989273, acc=0.9833333492279053, loss=0.04014531522989273
train: epoch 62, loss 0.020734408870339394, acc=0.9932222366333008, loss=0.020734408870339394
test: epoch 62, loss 0.06140786036849022, acc=0.9861111044883728, loss=0.06140786036849022
train: epoch 63, loss 0.022704094648361206, acc=0.9931111335754395, loss=0.022704094648361206
test: epoch 63, loss 0.057360321283340454, acc=0.9833333492279053, loss=0.057360321283340454
train: epoch 64, loss 0.017718739807605743, acc=0.9937777519226074, loss=0.017718739807605743
test: epoch 64, loss 0.0682230144739151, acc=0.9861111044883728, loss=0.0682230144739151
train: epoch 65, loss 0.05973575636744499, acc=0.9850555658340454, loss=0.05973575636744499
test: epoch 65, loss 0.14463789761066437, acc=0.9638888835906982, loss=0.14463789761066437
train: epoch 66, loss 0.05635690689086914, acc=0.9849444627761841, loss=0.05635690689086914
test: epoch 66, loss 0.044535938650369644, acc=0.9888888597488403, loss=0.044535938650369644
train: epoch 67, loss 0.008119838312268257, acc=0.9963889122009277, loss=0.008119838312268257
test: epoch 67, loss 0.056234247982501984, acc=0.9888888597488403, loss=0.056234247982501984
train: epoch 68, loss 0.007330565247684717, acc=0.9967777729034424, loss=0.007330565247684717
test: epoch 68, loss 0.03210034966468811, acc=0.9888888597488403, loss=0.03210034966468811
train: epoch 69, loss 0.006536509841680527, acc=0.9969444274902344, loss=0.006536509841680527
test: epoch 69, loss 0.05200207233428955, acc=0.9888888597488403, loss=0.05200207233428955
train: epoch 70, loss 0.02392987720668316, acc=0.9934999942779541, loss=0.02392987720668316
test: epoch 70, loss 0.4147893488407135, acc=0.9472222328186035, loss=0.4147893488407135
train: epoch 71, loss 0.16579404473304749, acc=0.9348333477973938, loss=0.16579404473304749
test: epoch 71, loss 0.10368062555789948, acc=0.9472222328186035, loss=0.10368062555789948
train: epoch 72, loss 0.09239982068538666, acc=0.9650555849075317, loss=0.09239982068538666
test: epoch 72, loss 0.06321816891431808, acc=0.9750000238418579, loss=0.06321816891431808
train: epoch 73, loss 0.08078644424676895, acc=0.9788888692855835, loss=0.08078644424676895
test: epoch 73, loss 0.1039985716342926, acc=0.9722222089767456, loss=0.1039985716342926
train: epoch 74, loss 0.038197603076696396, acc=0.9876111149787903, loss=0.038197603076696396
test: epoch 74, loss 0.06412997841835022, acc=0.980555534362793, loss=0.06412997841835022
train: epoch 75, loss 0.03485674411058426, acc=0.9895555377006531, loss=0.03485674411058426
test: epoch 75, loss 0.0588826946914196, acc=0.9833333492279053, loss=0.0588826946914196
train: epoch 76, loss 0.0921049565076828, acc=0.9766111373901367, loss=0.0921049565076828
test: epoch 76, loss 0.13727667927742004, acc=0.9722222089767456, loss=0.13727667927742004
train: epoch 77, loss 0.03099539503455162, acc=0.9896666407585144, loss=0.03099539503455162
test: epoch 77, loss 0.0585179328918457, acc=0.9861111044883728, loss=0.0585179328918457
train: epoch 78, loss 0.0429687425494194, acc=0.9899444580078125, loss=0.0429687425494194
test: epoch 78, loss 0.08582380414009094, acc=0.9777777791023254, loss=0.08582380414009094
train: epoch 79, loss 0.04291478544473648, acc=0.9890000224113464, loss=0.04291478544473648
test: epoch 79, loss 0.07482654601335526, acc=0.9833333492279053, loss=0.07482654601335526
train: epoch 80, loss 0.029833223670721054, acc=0.9910555481910706, loss=0.029833223670721054
test: epoch 80, loss 0.07703499495983124, acc=0.9833333492279053, loss=0.07703499495983124
train: epoch 81, loss 0.06128116324543953, acc=0.9855555295944214, loss=0.06128116324543953
test: epoch 81, loss 0.11389470100402832, acc=0.9694444537162781, loss=0.11389470100402832
train: epoch 82, loss 0.07672704756259918, acc=0.9756110906600952, loss=0.07672704756259918
test: epoch 82, loss 0.136112779378891, acc=0.9722222089767456, loss=0.136112779378891
train: epoch 83, loss 0.018790144473314285, acc=0.9936666488647461, loss=0.018790144473314285
test: epoch 83, loss 0.04267248138785362, acc=0.9888888597488403, loss=0.04267248138785362
train: epoch 84, loss 0.006895408965647221, acc=0.9968888759613037, loss=0.006895408965647221
test: epoch 84, loss 0.05536070093512535, acc=0.9888888597488403, loss=0.05536070093512535
train: epoch 85, loss 0.005937147885560989, acc=0.996999979019165, loss=0.005937147885560989
test: epoch 85, loss 0.01775454171001911, acc=0.9916666746139526, loss=0.01775454171001911
