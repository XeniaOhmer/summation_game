# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=1.5", "--temp_decay=0.99", "--one_hot=false", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1202463203, receiver_embed_dim=128, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.7531049251556396, acc=0.1077222228050232, loss=2.7531049251556396
test: epoch 1, loss 3.9433774948120117, acc=0.11388888955116272, loss=3.9433774948120117
train: epoch 2, loss 1.6569478511810303, acc=0.3412777781486511, loss=1.6569478511810303
test: epoch 2, loss 2.5218615531921387, acc=0.21944443881511688, loss=2.5218615531921387
train: epoch 3, loss 1.0961101055145264, acc=0.5581666827201843, loss=1.0961101055145264
test: epoch 3, loss 2.34678053855896, acc=0.2944444417953491, loss=2.34678053855896
train: epoch 4, loss 0.8625806570053101, acc=0.6457777619361877, loss=0.8625806570053101
test: epoch 4, loss 1.7199747562408447, acc=0.38055557012557983, loss=1.7199747562408447
train: epoch 5, loss 0.7305945754051208, acc=0.6959999799728394, loss=0.7305945754051208
test: epoch 5, loss 1.780313491821289, acc=0.36944442987442017, loss=1.780313491821289
train: epoch 6, loss 0.6589519381523132, acc=0.726111114025116, loss=0.6589519381523132
test: epoch 6, loss 1.9567865133285522, acc=0.34166666865348816, loss=1.9567865133285522
train: epoch 7, loss 0.5793867111206055, acc=0.7587222456932068, loss=0.5793867111206055
test: epoch 7, loss 1.8017492294311523, acc=0.38055557012557983, loss=1.8017492294311523
train: epoch 8, loss 0.5361643433570862, acc=0.7751666903495789, loss=0.5361643433570862
test: epoch 8, loss 1.9719699621200562, acc=0.3916666805744171, loss=1.9719699621200562
train: epoch 9, loss 0.48890918493270874, acc=0.7947777509689331, loss=0.48890918493270874
test: epoch 9, loss 1.601064920425415, acc=0.4416666626930237, loss=1.601064920425415
train: epoch 10, loss 0.44582507014274597, acc=0.8161666393280029, loss=0.44582507014274597
test: epoch 10, loss 1.6773970127105713, acc=0.4833333194255829, loss=1.6773970127105713
train: epoch 11, loss 0.41212227940559387, acc=0.8263888955116272, loss=0.41212227940559387
test: epoch 11, loss 1.5625871419906616, acc=0.4749999940395355, loss=1.5625871419906616
train: epoch 12, loss 0.39753925800323486, acc=0.8291110992431641, loss=0.39753925800323486
test: epoch 12, loss 1.2490791082382202, acc=0.5305555462837219, loss=1.2490791082382202
train: epoch 13, loss 0.3838551342487335, acc=0.8372777700424194, loss=0.3838551342487335
test: epoch 13, loss 1.340057611465454, acc=0.4972222149372101, loss=1.340057611465454
train: epoch 14, loss 0.36460572481155396, acc=0.8446111083030701, loss=0.36460572481155396
test: epoch 14, loss 1.5847581624984741, acc=0.4694444537162781, loss=1.5847581624984741
train: epoch 15, loss 0.34402623772621155, acc=0.8516666889190674, loss=0.34402623772621155
test: epoch 15, loss 1.391402006149292, acc=0.5166666507720947, loss=1.391402006149292
train: epoch 16, loss 0.3458422124385834, acc=0.8526111245155334, loss=0.3458422124385834
test: epoch 16, loss 1.4237536191940308, acc=0.5138888955116272, loss=1.4237536191940308
train: epoch 17, loss 0.32516220211982727, acc=0.8600000143051147, loss=0.32516220211982727
test: epoch 17, loss 1.228632926940918, acc=0.5722222328186035, loss=1.228632926940918
train: epoch 18, loss 0.29829519987106323, acc=0.8696110844612122, loss=0.29829519987106323
test: epoch 18, loss 1.3865050077438354, acc=0.5611110925674438, loss=1.3865050077438354
train: epoch 19, loss 0.3023264408111572, acc=0.8696666955947876, loss=0.3023264408111572
test: epoch 19, loss 1.325576901435852, acc=0.5583333373069763, loss=1.325576901435852
train: epoch 20, loss 0.28617143630981445, acc=0.8763333559036255, loss=0.28617143630981445
test: epoch 20, loss 1.1002751588821411, acc=0.6333333253860474, loss=1.1002751588821411
train: epoch 21, loss 0.28960126638412476, acc=0.8762221932411194, loss=0.28960126638412476
test: epoch 21, loss 1.2261418104171753, acc=0.644444465637207, loss=1.2261418104171753
train: epoch 22, loss 0.28064244985580444, acc=0.8796666860580444, loss=0.28064244985580444
test: epoch 22, loss 1.0894191265106201, acc=0.6027777791023254, loss=1.0894191265106201
train: epoch 23, loss 0.2807774543762207, acc=0.8797777891159058, loss=0.2807774543762207
test: epoch 23, loss 1.0433366298675537, acc=0.6222222447395325, loss=1.0433366298675537
train: epoch 24, loss 0.24658404290676117, acc=0.8948333263397217, loss=0.24658404290676117
test: epoch 24, loss 1.0541454553604126, acc=0.6111111044883728, loss=1.0541454553604126
train: epoch 25, loss 0.25561025738716125, acc=0.890666663646698, loss=0.25561025738716125
test: epoch 25, loss 1.198736548423767, acc=0.6083333492279053, loss=1.198736548423767
train: epoch 26, loss 0.2363908737897873, acc=0.8963888883590698, loss=0.2363908737897873
test: epoch 26, loss 0.867348849773407, acc=0.6555555462837219, loss=0.867348849773407
train: epoch 27, loss 0.23542441427707672, acc=0.8971111178398132, loss=0.23542441427707672
test: epoch 27, loss 0.903170645236969, acc=0.6805555820465088, loss=0.903170645236969
train: epoch 28, loss 0.23505200445652008, acc=0.8996666669845581, loss=0.23505200445652008
test: epoch 28, loss 0.9525860548019409, acc=0.6527777910232544, loss=0.9525860548019409
train: epoch 29, loss 0.2285747081041336, acc=0.902388870716095, loss=0.2285747081041336
test: epoch 29, loss 0.973635733127594, acc=0.7083333134651184, loss=0.973635733127594
train: epoch 30, loss 0.21021246910095215, acc=0.9071111083030701, loss=0.21021246910095215
test: epoch 30, loss 1.0016754865646362, acc=0.7222222089767456, loss=1.0016754865646362
train: epoch 31, loss 0.22027435898780823, acc=0.9068333506584167, loss=0.22027435898780823
test: epoch 31, loss 0.644915759563446, acc=0.7722222208976746, loss=0.644915759563446
train: epoch 32, loss 0.21585942804813385, acc=0.9056666493415833, loss=0.21585942804813385
test: epoch 32, loss 0.7361540198326111, acc=0.800000011920929, loss=0.7361540198326111
train: epoch 33, loss 0.19781102240085602, acc=0.9144444465637207, loss=0.19781102240085602
test: epoch 33, loss 0.6121031045913696, acc=0.824999988079071, loss=0.6121031045913696
train: epoch 34, loss 0.18916307389736176, acc=0.9163333177566528, loss=0.18916307389736176
test: epoch 34, loss 0.6248852610588074, acc=0.8166666626930237, loss=0.6248852610588074
train: epoch 35, loss 0.20311293005943298, acc=0.9109444618225098, loss=0.20311293005943298
test: epoch 35, loss 0.39357542991638184, acc=0.8527777791023254, loss=0.39357542991638184
train: epoch 36, loss 0.18353766202926636, acc=0.9210000038146973, loss=0.18353766202926636
test: epoch 36, loss 0.5717048645019531, acc=0.8166666626930237, loss=0.5717048645019531
train: epoch 37, loss 0.1911621391773224, acc=0.9169444441795349, loss=0.1911621391773224
test: epoch 37, loss 0.34033846855163574, acc=0.8611111044883728, loss=0.34033846855163574
train: epoch 38, loss 0.16658854484558105, acc=0.9240555763244629, loss=0.16658854484558105
test: epoch 38, loss 0.5145027041435242, acc=0.8444444537162781, loss=0.5145027041435242
train: epoch 39, loss 0.18628399074077606, acc=0.9191111326217651, loss=0.18628399074077606
test: epoch 39, loss 0.4141215980052948, acc=0.8611111044883728, loss=0.4141215980052948
train: epoch 40, loss 0.17268197238445282, acc=0.9201111197471619, loss=0.17268197238445282
test: epoch 40, loss 0.38548147678375244, acc=0.8611111044883728, loss=0.38548147678375244
train: epoch 41, loss 0.15702351927757263, acc=0.925166666507721, loss=0.15702351927757263
test: epoch 41, loss 0.39466366171836853, acc=0.8527777791023254, loss=0.39466366171836853
train: epoch 42, loss 0.16791196167469025, acc=0.9231111407279968, loss=0.16791196167469025
test: epoch 42, loss 0.3945729732513428, acc=0.8527777791023254, loss=0.3945729732513428
train: epoch 43, loss 0.1792563945055008, acc=0.9176111221313477, loss=0.1792563945055008
test: epoch 43, loss 0.39105936884880066, acc=0.8611111044883728, loss=0.39105936884880066
train: epoch 44, loss 0.15096263587474823, acc=0.924833357334137, loss=0.15096263587474823
test: epoch 44, loss 0.38518625497817993, acc=0.8611111044883728, loss=0.38518625497817993
train: epoch 45, loss 0.1630399376153946, acc=0.924833357334137, loss=0.1630399376153946
test: epoch 45, loss 0.42680659890174866, acc=0.8527777791023254, loss=0.42680659890174866
train: epoch 46, loss 0.17422731220722198, acc=0.9204444289207458, loss=0.17422731220722198
test: epoch 46, loss 0.34941771626472473, acc=0.8500000238418579, loss=0.34941771626472473
train: epoch 47, loss 0.18138600885868073, acc=0.9172777533531189, loss=0.18138600885868073
test: epoch 47, loss 0.35367465019226074, acc=0.855555534362793, loss=0.35367465019226074
train: epoch 48, loss 0.16456346213817596, acc=0.9235000014305115, loss=0.16456346213817596
test: epoch 48, loss 0.32666292786598206, acc=0.8527777791023254, loss=0.32666292786598206
train: epoch 49, loss 0.16395100951194763, acc=0.9235555529594421, loss=0.16395100951194763
test: epoch 49, loss 0.4122488796710968, acc=0.8527777791023254, loss=0.4122488796710968
train: epoch 50, loss 0.1575055718421936, acc=0.9243333339691162, loss=0.1575055718421936
test: epoch 50, loss 0.411093145608902, acc=0.8500000238418579, loss=0.411093145608902
train: epoch 51, loss 0.1676333248615265, acc=0.9242222309112549, loss=0.1676333248615265
test: epoch 51, loss 0.3729439377784729, acc=0.8527777791023254, loss=0.3729439377784729
train: epoch 52, loss 0.15926019847393036, acc=0.9247221946716309, loss=0.15926019847393036
test: epoch 52, loss 0.49609121680259705, acc=0.8472222089767456, loss=0.49609121680259705
train: epoch 53, loss 0.17869088053703308, acc=0.9200000166893005, loss=0.17869088053703308
test: epoch 53, loss 0.3159889578819275, acc=0.8527777791023254, loss=0.3159889578819275
train: epoch 54, loss 0.16853117942810059, acc=0.9209444522857666, loss=0.16853117942810059
test: epoch 54, loss 0.40209388732910156, acc=0.855555534362793, loss=0.40209388732910156
train: epoch 55, loss 0.15559880435466766, acc=0.9239444732666016, loss=0.15559880435466766
test: epoch 55, loss 0.378389835357666, acc=0.855555534362793, loss=0.378389835357666
train: epoch 56, loss 0.14964498579502106, acc=0.925166666507721, loss=0.14964498579502106
test: epoch 56, loss 0.4438421428203583, acc=0.8527777791023254, loss=0.4438421428203583
train: epoch 57, loss 0.1687646359205246, acc=0.9212222099304199, loss=0.1687646359205246
test: epoch 57, loss 0.33750152587890625, acc=0.8527777791023254, loss=0.33750152587890625
train: epoch 58, loss 0.16201883554458618, acc=0.9210555553436279, loss=0.16201883554458618
test: epoch 58, loss 0.3781733214855194, acc=0.8527777791023254, loss=0.3781733214855194
train: epoch 59, loss 0.17435352504253387, acc=0.9199444651603699, loss=0.17435352504253387
test: epoch 59, loss 0.4256259500980377, acc=0.8527777791023254, loss=0.4256259500980377
train: epoch 60, loss 0.16061453521251678, acc=0.9232777953147888, loss=0.16061453521251678
test: epoch 60, loss 0.3941865861415863, acc=0.855555534362793, loss=0.3941865861415863
train: epoch 61, loss 0.16899295151233673, acc=0.9240555763244629, loss=0.16899295151233673
test: epoch 61, loss 0.3678578734397888, acc=0.855555534362793, loss=0.3678578734397888
train: epoch 62, loss 0.1623939722776413, acc=0.9243333339691162, loss=0.1623939722776413
test: epoch 62, loss 0.4159368872642517, acc=0.855555534362793, loss=0.4159368872642517
train: epoch 63, loss 0.15510722994804382, acc=0.925611138343811, loss=0.15510722994804382
test: epoch 63, loss 0.37990015745162964, acc=0.855555534362793, loss=0.37990015745162964
train: epoch 64, loss 0.1691218912601471, acc=0.9245555400848389, loss=0.1691218912601471
test: epoch 64, loss 0.38694509863853455, acc=0.8527777791023254, loss=0.38694509863853455
train: epoch 65, loss 0.16516931354999542, acc=0.9234444499015808, loss=0.16516931354999542
test: epoch 65, loss 0.36568647623062134, acc=0.855555534362793, loss=0.36568647623062134
train: epoch 66, loss 0.17702989280223846, acc=0.917722225189209, loss=0.17702989280223846
test: epoch 66, loss 0.32854020595550537, acc=0.8611111044883728, loss=0.32854020595550537
train: epoch 67, loss 0.17070791125297546, acc=0.9211111068725586, loss=0.17070791125297546
test: epoch 67, loss 0.2950630187988281, acc=0.855555534362793, loss=0.2950630187988281
train: epoch 68, loss 0.15976183116436005, acc=0.9227777719497681, loss=0.15976183116436005
test: epoch 68, loss 0.43820828199386597, acc=0.855555534362793, loss=0.43820828199386597
train: epoch 69, loss 0.15063294768333435, acc=0.9303333163261414, loss=0.15063294768333435
test: epoch 69, loss 0.4999289810657501, acc=0.8527777791023254, loss=0.4999289810657501
train: epoch 70, loss 0.17076486349105835, acc=0.9199444651603699, loss=0.17076486349105835
test: epoch 70, loss 0.30377396941185, acc=0.8611111044883728, loss=0.30377396941185
train: epoch 71, loss 0.18216553330421448, acc=0.9166666865348816, loss=0.18216553330421448
test: epoch 71, loss 0.34856435656547546, acc=0.8583333492279053, loss=0.34856435656547546
train: epoch 72, loss 0.1818636953830719, acc=0.9212777614593506, loss=0.1818636953830719
test: epoch 72, loss 0.3244136571884155, acc=0.8527777791023254, loss=0.3244136571884155
train: epoch 73, loss 0.15494872629642487, acc=0.9263333082199097, loss=0.15494872629642487
test: epoch 73, loss 0.3739364743232727, acc=0.855555534362793, loss=0.3739364743232727
train: epoch 74, loss 0.1600927859544754, acc=0.9249444603919983, loss=0.1600927859544754
test: epoch 74, loss 0.42168623208999634, acc=0.8527777791023254, loss=0.42168623208999634
train: epoch 75, loss 0.15732847154140472, acc=0.9255555272102356, loss=0.15732847154140472
test: epoch 75, loss 0.3410431742668152, acc=0.855555534362793, loss=0.3410431742668152
train: epoch 76, loss 0.17443545162677765, acc=0.9226666688919067, loss=0.17443545162677765
test: epoch 76, loss 0.3843930661678314, acc=0.855555534362793, loss=0.3843930661678314
train: epoch 77, loss 0.1580798625946045, acc=0.925000011920929, loss=0.1580798625946045
test: epoch 77, loss 0.29902610182762146, acc=0.8611111044883728, loss=0.29902610182762146
train: epoch 78, loss 0.16064733266830444, acc=0.9222221970558167, loss=0.16064733266830444
test: epoch 78, loss 0.40097466111183167, acc=0.855555534362793, loss=0.40097466111183167
train: epoch 79, loss 0.1525873988866806, acc=0.9263888597488403, loss=0.1525873988866806
test: epoch 79, loss 0.39132970571517944, acc=0.8527777791023254, loss=0.39132970571517944
train: epoch 80, loss 0.14983290433883667, acc=0.9281666874885559, loss=0.14983290433883667
test: epoch 80, loss 0.31978532671928406, acc=0.8527777791023254, loss=0.31978532671928406
train: epoch 81, loss 0.15849891304969788, acc=0.9253333210945129, loss=0.15849891304969788
test: epoch 81, loss 0.4019594192504883, acc=0.8500000238418579, loss=0.4019594192504883
train: epoch 82, loss 0.1701507270336151, acc=0.9262222051620483, loss=0.1701507270336151
test: epoch 82, loss 0.402788907289505, acc=0.8500000238418579, loss=0.402788907289505
train: epoch 83, loss 0.15860265493392944, acc=0.9287777543067932, loss=0.15860265493392944
test: epoch 83, loss 0.4068087339401245, acc=0.8583333492279053, loss=0.4068087339401245
train: epoch 84, loss 0.17086495459079742, acc=0.918833315372467, loss=0.17086495459079742
test: epoch 84, loss 0.2746790945529938, acc=0.8611111044883728, loss=0.2746790945529938
train: epoch 85, loss 0.15683859586715698, acc=0.9230555295944214, loss=0.15683859586715698
test: epoch 85, loss 0.34286996722221375, acc=0.8611111044883728, loss=0.34286996722221375
train: epoch 86, loss 0.1658266931772232, acc=0.9149444699287415, loss=0.1658266931772232
test: epoch 86, loss 0.4168368875980377, acc=0.8527777791023254, loss=0.4168368875980377
train: epoch 87, loss 0.14932292699813843, acc=0.9286110997200012, loss=0.14932292699813843
test: epoch 87, loss 0.391417920589447, acc=0.8527777791023254, loss=0.391417920589447
train: epoch 88, loss 0.15479989349842072, acc=0.9307222366333008, loss=0.15479989349842072
test: epoch 88, loss 0.34140804409980774, acc=0.8527777791023254, loss=0.34140804409980774
train: epoch 89, loss 0.15464508533477783, acc=0.9276666641235352, loss=0.15464508533477783
test: epoch 89, loss 0.34864702820777893, acc=0.8527777791023254, loss=0.34864702820777893
train: epoch 90, loss 0.1502622812986374, acc=0.9260555505752563, loss=0.1502622812986374
test: epoch 90, loss 0.39588290452957153, acc=0.8527777791023254, loss=0.39588290452957153
train: epoch 91, loss 0.14756134152412415, acc=0.9281666874885559, loss=0.14756134152412415
test: epoch 91, loss 0.38875946402549744, acc=0.8527777791023254, loss=0.38875946402549744
train: epoch 92, loss 0.14850838482379913, acc=0.9300000071525574, loss=0.14850838482379913
test: epoch 92, loss 0.3939921259880066, acc=0.8527777791023254, loss=0.3939921259880066
train: epoch 93, loss 0.14627376198768616, acc=0.9302777647972107, loss=0.14627376198768616
test: epoch 93, loss 0.44542187452316284, acc=0.8527777791023254, loss=0.44542187452316284
train: epoch 94, loss 0.1476084291934967, acc=0.930055558681488, loss=0.1476084291934967
test: epoch 94, loss 0.4028443396091461, acc=0.8527777791023254, loss=0.4028443396091461
train: epoch 95, loss 0.14464685320854187, acc=0.9282777905464172, loss=0.14464685320854187
test: epoch 95, loss 0.404565691947937, acc=0.855555534362793, loss=0.404565691947937
train: epoch 96, loss 0.15329253673553467, acc=0.930388867855072, loss=0.15329253673553467
test: epoch 96, loss 0.4001747965812683, acc=0.8527777791023254, loss=0.4001747965812683
train: epoch 97, loss 0.14347748458385468, acc=0.9300000071525574, loss=0.14347748458385468
test: epoch 97, loss 0.3894752264022827, acc=0.8527777791023254, loss=0.3894752264022827
train: epoch 98, loss 0.13936747610569, acc=0.929611086845398, loss=0.13936747610569
test: epoch 98, loss 0.30743035674095154, acc=0.8527777791023254, loss=0.30743035674095154
train: epoch 99, loss 0.15025576949119568, acc=0.9280555844306946, loss=0.15025576949119568
test: epoch 99, loss 0.46377232670783997, acc=0.8527777791023254, loss=0.46377232670783997
train: epoch 100, loss 0.13837172091007233, acc=0.9336110949516296, loss=0.13837172091007233
test: epoch 100, loss 0.41217041015625, acc=0.8527777791023254, loss=0.41217041015625
train: epoch 101, loss 0.15253645181655884, acc=0.929611086845398, loss=0.15253645181655884
test: epoch 101, loss 0.41285333037376404, acc=0.8472222089767456, loss=0.41285333037376404
train: epoch 102, loss 0.1450444757938385, acc=0.9326666593551636, loss=0.1450444757938385
test: epoch 102, loss 0.42600369453430176, acc=0.8527777791023254, loss=0.42600369453430176
train: epoch 103, loss 0.14760568737983704, acc=0.9269999861717224, loss=0.14760568737983704
test: epoch 103, loss 0.36134931445121765, acc=0.8583333492279053, loss=0.36134931445121765
train: epoch 104, loss 0.15366801619529724, acc=0.9264444708824158, loss=0.15366801619529724
test: epoch 104, loss 0.355813592672348, acc=0.8611111044883728, loss=0.355813592672348
train: epoch 105, loss 0.14547637104988098, acc=0.9278333187103271, loss=0.14547637104988098
test: epoch 105, loss 0.454344242811203, acc=0.8527777791023254, loss=0.454344242811203
train: epoch 106, loss 0.13817280530929565, acc=0.9263888597488403, loss=0.13817280530929565
test: epoch 106, loss 0.42642560601234436, acc=0.855555534362793, loss=0.42642560601234436
train: epoch 107, loss 0.13671573996543884, acc=0.9279444217681885, loss=0.13671573996543884
test: epoch 107, loss 0.33387646079063416, acc=0.8527777791023254, loss=0.33387646079063416
train: epoch 108, loss 0.1370830535888672, acc=0.9262222051620483, loss=0.1370830535888672
test: epoch 108, loss 0.3458079397678375, acc=0.8611111044883728, loss=0.3458079397678375
train: epoch 109, loss 0.138576477766037, acc=0.9284444451332092, loss=0.138576477766037
test: epoch 109, loss 0.43002307415008545, acc=0.8527777791023254, loss=0.43002307415008545
train: epoch 110, loss 0.14620040357112885, acc=0.929722249507904, loss=0.14620040357112885
test: epoch 110, loss 0.37208235263824463, acc=0.8527777791023254, loss=0.37208235263824463
train: epoch 111, loss 0.13573767244815826, acc=0.9247778058052063, loss=0.13573767244815826
test: epoch 111, loss 0.41541197896003723, acc=0.8527777791023254, loss=0.41541197896003723
train: epoch 112, loss 0.14309686422348022, acc=0.9272222518920898, loss=0.14309686422348022
test: epoch 112, loss 0.4076266586780548, acc=0.8527777791023254, loss=0.4076266586780548
train: epoch 113, loss 0.1426587551832199, acc=0.9263888597488403, loss=0.1426587551832199
test: epoch 113, loss 0.4103551208972931, acc=0.8527777791023254, loss=0.4103551208972931
train: epoch 114, loss 0.14999212324619293, acc=0.9263333082199097, loss=0.14999212324619293
test: epoch 114, loss 0.5588610768318176, acc=0.8527777791023254, loss=0.5588610768318176
train: epoch 115, loss 0.14353720843791962, acc=0.9288333058357239, loss=0.14353720843791962
test: epoch 115, loss 0.3876025378704071, acc=0.8527777791023254, loss=0.3876025378704071
train: epoch 116, loss 0.13163214921951294, acc=0.9286666512489319, loss=0.13163214921951294
test: epoch 116, loss 0.4098786413669586, acc=0.8611111044883728, loss=0.4098786413669586
train: epoch 117, loss 0.1651344746351242, acc=0.9276666641235352, loss=0.1651344746351242
test: epoch 117, loss 0.3445653021335602, acc=0.8611111044883728, loss=0.3445653021335602
train: epoch 118, loss 0.13562573492527008, acc=0.929277777671814, loss=0.13562573492527008
test: epoch 118, loss 0.4032958149909973, acc=0.8527777791023254, loss=0.4032958149909973
train: epoch 119, loss 0.1397048681974411, acc=0.9287777543067932, loss=0.1397048681974411
test: epoch 119, loss 0.4517526626586914, acc=0.8500000238418579, loss=0.4517526626586914
train: epoch 120, loss 0.1365218609571457, acc=0.9285555481910706, loss=0.1365218609571457
test: epoch 120, loss 0.3790203332901001, acc=0.8527777791023254, loss=0.3790203332901001
train: epoch 121, loss 0.1400676667690277, acc=0.9326666593551636, loss=0.1400676667690277
test: epoch 121, loss 0.40143513679504395, acc=0.8527777791023254, loss=0.40143513679504395
train: epoch 122, loss 0.13746799528598785, acc=0.9309444427490234, loss=0.13746799528598785
test: epoch 122, loss 0.44118866324424744, acc=0.8472222089767456, loss=0.44118866324424744
train: epoch 123, loss 0.13260281085968018, acc=0.9286666512489319, loss=0.13260281085968018
test: epoch 123, loss 0.434807687997818, acc=0.8527777791023254, loss=0.434807687997818
train: epoch 124, loss 0.12271136045455933, acc=0.9330000281333923, loss=0.12271136045455933
test: epoch 124, loss 0.40138304233551025, acc=0.8527777791023254, loss=0.40138304233551025
train: epoch 125, loss 0.1313672661781311, acc=0.9325555562973022, loss=0.1313672661781311
test: epoch 125, loss 0.41072821617126465, acc=0.8527777791023254, loss=0.41072821617126465
train: epoch 126, loss 0.1366330236196518, acc=0.9319444298744202, loss=0.1366330236196518
test: epoch 126, loss 0.43304312229156494, acc=0.855555534362793, loss=0.43304312229156494
train: epoch 127, loss 0.13812072575092316, acc=0.9334999918937683, loss=0.13812072575092316
test: epoch 127, loss 0.4146169424057007, acc=0.8527777791023254, loss=0.4146169424057007
train: epoch 128, loss 0.12052983790636063, acc=0.9329444169998169, loss=0.12052983790636063
test: epoch 128, loss 0.3490130305290222, acc=0.8611111044883728, loss=0.3490130305290222
train: epoch 129, loss 0.1329939216375351, acc=0.9308333396911621, loss=0.1329939216375351
test: epoch 129, loss 0.33821454644203186, acc=0.8583333492279053, loss=0.33821454644203186
train: epoch 130, loss 0.12793852388858795, acc=0.9302777647972107, loss=0.12793852388858795
test: epoch 130, loss 0.4070182144641876, acc=0.855555534362793, loss=0.4070182144641876
train: epoch 131, loss 0.126181960105896, acc=0.933722198009491, loss=0.126181960105896
test: epoch 131, loss 0.3556215167045593, acc=0.8833333253860474, loss=0.3556215167045593
train: epoch 132, loss 0.11591194570064545, acc=0.9349444508552551, loss=0.11591194570064545
test: epoch 132, loss 0.324908971786499, acc=0.8833333253860474, loss=0.324908971786499
train: epoch 133, loss 0.11701739579439163, acc=0.933388888835907, loss=0.11701739579439163
test: epoch 133, loss 0.30433082580566406, acc=0.8833333253860474, loss=0.30433082580566406
train: epoch 134, loss 0.11473708599805832, acc=0.9340000152587891, loss=0.11473708599805832
test: epoch 134, loss 0.30799347162246704, acc=0.8916666507720947, loss=0.30799347162246704
train: epoch 135, loss 0.12145987898111343, acc=0.9302777647972107, loss=0.12145987898111343
test: epoch 135, loss 0.338377982378006, acc=0.8861111402511597, loss=0.338377982378006
train: epoch 136, loss 0.10694334656000137, acc=0.9361666440963745, loss=0.10694334656000137
test: epoch 136, loss 0.2857600450515747, acc=0.8972222208976746, loss=0.2857600450515747
train: epoch 137, loss 0.10911798477172852, acc=0.9362221956253052, loss=0.10911798477172852
test: epoch 137, loss 0.29888540506362915, acc=0.8916666507720947, loss=0.29888540506362915
train: epoch 138, loss 0.09951997548341751, acc=0.9374444484710693, loss=0.09951997548341751
test: epoch 138, loss 0.21618574857711792, acc=0.9166666865348816, loss=0.21618574857711792
train: epoch 139, loss 0.11021369695663452, acc=0.9384999871253967, loss=0.11021369695663452
test: epoch 139, loss 0.39401525259017944, acc=0.9111111164093018, loss=0.39401525259017944
train: epoch 140, loss 0.12623238563537598, acc=0.9390000104904175, loss=0.12623238563537598
test: epoch 140, loss 0.17310231924057007, acc=0.9166666865348816, loss=0.17310231924057007
train: epoch 141, loss 0.11461885273456573, acc=0.9412222504615784, loss=0.11461885273456573
test: epoch 141, loss 0.1906314194202423, acc=0.9166666865348816, loss=0.1906314194202423
train: epoch 142, loss 0.10745855420827866, acc=0.9412222504615784, loss=0.10745855420827866
test: epoch 142, loss 0.1991494745016098, acc=0.9166666865348816, loss=0.1991494745016098
train: epoch 143, loss 0.10743755847215652, acc=0.9413333535194397, loss=0.10743755847215652
test: epoch 143, loss 0.19434064626693726, acc=0.9166666865348816, loss=0.19434064626693726
train: epoch 144, loss 0.10521659255027771, acc=0.9433333277702332, loss=0.10521659255027771
test: epoch 144, loss 0.20784737169742584, acc=0.9194444417953491, loss=0.20784737169742584
train: epoch 145, loss 0.10132431983947754, acc=0.9438889026641846, loss=0.10132431983947754
test: epoch 145, loss 0.1992720514535904, acc=0.9166666865348816, loss=0.1992720514535904
train: epoch 146, loss 0.11282756179571152, acc=0.941444456577301, loss=0.11282756179571152
test: epoch 146, loss 0.17063653469085693, acc=0.9194444417953491, loss=0.17063653469085693
train: epoch 147, loss 0.09673784673213959, acc=0.9445555806159973, loss=0.09673784673213959
test: epoch 147, loss 0.19284339249134064, acc=0.9194444417953491, loss=0.19284339249134064
train: epoch 148, loss 0.09837274998426437, acc=0.9445555806159973, loss=0.09837274998426437
test: epoch 148, loss 0.2185882180929184, acc=0.9194444417953491, loss=0.2185882180929184
train: epoch 149, loss 0.09913813322782516, acc=0.9434444308280945, loss=0.09913813322782516
test: epoch 149, loss 0.16800865530967712, acc=0.9194444417953491, loss=0.16800865530967712
train: epoch 150, loss 0.10775870829820633, acc=0.9417222142219543, loss=0.10775870829820633
test: epoch 150, loss 0.18683987855911255, acc=0.9194444417953491, loss=0.18683987855911255
