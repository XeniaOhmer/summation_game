# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=1", "--one_hot=true", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=344555419, receiver_embed_dim=32, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.0311131477355957, acc=0.07188888639211655, loss=3.0311131477355957
test: epoch 1, loss 4.1984968185424805, acc=0.0694444477558136, loss=4.1984968185424805
train: epoch 2, loss 2.120572090148926, acc=0.17722222208976746, loss=2.120572090148926
test: epoch 2, loss 3.299030303955078, acc=0.1527777761220932, loss=3.299030303955078
train: epoch 3, loss 1.774329662322998, acc=0.24694444239139557, loss=1.774329662322998
test: epoch 3, loss 2.746211051940918, acc=0.15833333134651184, loss=2.746211051940918
train: epoch 4, loss 1.5360209941864014, acc=0.3113333284854889, loss=1.5360209941864014
test: epoch 4, loss 2.8097028732299805, acc=0.14444445073604584, loss=2.8097028732299805
train: epoch 5, loss 1.3875350952148438, acc=0.3605555593967438, loss=1.3875350952148438
test: epoch 5, loss 2.8134262561798096, acc=0.19722221791744232, loss=2.8134262561798096
train: epoch 6, loss 1.2608823776245117, acc=0.4124999940395355, loss=1.2608823776245117
test: epoch 6, loss 2.4319636821746826, acc=0.24722221493721008, loss=2.4319636821746826
train: epoch 7, loss 1.137319803237915, acc=0.47744444012641907, loss=1.137319803237915
test: epoch 7, loss 2.779728889465332, acc=0.1944444477558136, loss=2.779728889465332
train: epoch 8, loss 1.092594861984253, acc=0.49594444036483765, loss=1.092594861984253
test: epoch 8, loss 3.7018046379089355, acc=0.1805555522441864, loss=3.7018046379089355
train: epoch 9, loss 1.014716386795044, acc=0.5482777953147888, loss=1.014716386795044
test: epoch 9, loss 2.661632776260376, acc=0.23055554926395416, loss=2.661632776260376
train: epoch 10, loss 0.9261302351951599, acc=0.5910555720329285, loss=0.9261302351951599
test: epoch 10, loss 2.172285795211792, acc=0.3166666626930237, loss=2.172285795211792
train: epoch 11, loss 0.9635623693466187, acc=0.585777759552002, loss=0.9635623693466187
test: epoch 11, loss 2.4500739574432373, acc=0.2888889014720917, loss=2.4500739574432373
train: epoch 12, loss 0.8605903387069702, acc=0.6227777600288391, loss=0.8605903387069702
test: epoch 12, loss 2.960869312286377, acc=0.25555557012557983, loss=2.960869312286377
train: epoch 13, loss 0.8179240822792053, acc=0.652388870716095, loss=0.8179240822792053
test: epoch 13, loss 3.114518642425537, acc=0.32499998807907104, loss=3.114518642425537
train: epoch 14, loss 0.8265957832336426, acc=0.64083331823349, loss=0.8265957832336426
test: epoch 14, loss 2.4287967681884766, acc=0.3083333373069763, loss=2.4287967681884766
train: epoch 15, loss 0.7462152242660522, acc=0.6863333582878113, loss=0.7462152242660522
test: epoch 15, loss 2.0877702236175537, acc=0.4416666626930237, loss=2.0877702236175537
train: epoch 16, loss 0.7549844980239868, acc=0.6871111392974854, loss=0.7549844980239868
test: epoch 16, loss 2.859595537185669, acc=0.2611111104488373, loss=2.859595537185669
train: epoch 17, loss 0.6747843623161316, acc=0.7311111092567444, loss=0.6747843623161316
test: epoch 17, loss 2.9343149662017822, acc=0.3333333432674408, loss=2.9343149662017822
train: epoch 18, loss 0.6989436149597168, acc=0.718500018119812, loss=0.6989436149597168
test: epoch 18, loss 2.1295135021209717, acc=0.4472222328186035, loss=2.1295135021209717
train: epoch 19, loss 0.6627617478370667, acc=0.7278888821601868, loss=0.6627617478370667
test: epoch 19, loss 2.2741434574127197, acc=0.4611110985279083, loss=2.2741434574127197
train: epoch 20, loss 0.631813645362854, acc=0.7477777600288391, loss=0.631813645362854
test: epoch 20, loss 2.0659432411193848, acc=0.4472222328186035, loss=2.0659432411193848
train: epoch 21, loss 0.5765795111656189, acc=0.7757777571678162, loss=0.5765795111656189
test: epoch 21, loss 1.8319299221038818, acc=0.45277777314186096, loss=1.8319299221038818
train: epoch 22, loss 0.4972318112850189, acc=0.8115000128746033, loss=0.4972318112850189
test: epoch 22, loss 1.7172411680221558, acc=0.4416666626930237, loss=1.7172411680221558
train: epoch 23, loss 0.5366107225418091, acc=0.792388916015625, loss=0.5366107225418091
test: epoch 23, loss 2.104132890701294, acc=0.4277777671813965, loss=2.104132890701294
train: epoch 24, loss 0.45082005858421326, acc=0.8286666870117188, loss=0.45082005858421326
test: epoch 24, loss 2.219924211502075, acc=0.3583333194255829, loss=2.219924211502075
train: epoch 25, loss 0.40187323093414307, acc=0.8506110906600952, loss=0.40187323093414307
test: epoch 25, loss 2.1880648136138916, acc=0.4277777671813965, loss=2.1880648136138916
train: epoch 26, loss 0.3855276107788086, acc=0.8525555729866028, loss=0.3855276107788086
test: epoch 26, loss 1.9055596590042114, acc=0.4749999940395355, loss=1.9055596590042114
train: epoch 27, loss 0.3597070276737213, acc=0.8637222051620483, loss=0.3597070276737213
test: epoch 27, loss 2.8308780193328857, acc=0.39722222089767456, loss=2.8308780193328857
train: epoch 28, loss 0.3260076642036438, acc=0.8798333406448364, loss=0.3260076642036438
test: epoch 28, loss 2.6404643058776855, acc=0.39722222089767456, loss=2.6404643058776855
train: epoch 29, loss 0.2895003855228424, acc=0.8936111330986023, loss=0.2895003855228424
test: epoch 29, loss 2.1751515865325928, acc=0.4972222149372101, loss=2.1751515865325928
train: epoch 30, loss 0.25167030096054077, acc=0.9079444408416748, loss=0.25167030096054077
test: epoch 30, loss 1.7865653038024902, acc=0.4861111044883728, loss=1.7865653038024902
train: epoch 31, loss 0.24253658950328827, acc=0.9146111011505127, loss=0.24253658950328827
test: epoch 31, loss 1.6139951944351196, acc=0.5222222208976746, loss=1.6139951944351196
train: epoch 32, loss 0.23359140753746033, acc=0.9190000295639038, loss=0.23359140753746033
test: epoch 32, loss 1.56810462474823, acc=0.5472221970558167, loss=1.56810462474823
train: epoch 33, loss 0.20476052165031433, acc=0.9287222027778625, loss=0.20476052165031433
test: epoch 33, loss 2.0728507041931152, acc=0.46388888359069824, loss=2.0728507041931152
train: epoch 34, loss 0.22074168920516968, acc=0.9226111173629761, loss=0.22074168920516968
test: epoch 34, loss 2.0415425300598145, acc=0.5111111402511597, loss=2.0415425300598145
train: epoch 35, loss 0.22092992067337036, acc=0.9228888750076294, loss=0.22092992067337036
test: epoch 35, loss 1.6934587955474854, acc=0.6166666746139526, loss=1.6934587955474854
train: epoch 36, loss 0.24387754499912262, acc=0.9235555529594421, loss=0.24387754499912262
test: epoch 36, loss 1.632209300994873, acc=0.49166667461395264, loss=1.632209300994873
train: epoch 37, loss 0.14186690747737885, acc=0.9520000219345093, loss=0.14186690747737885
test: epoch 37, loss 1.6936635971069336, acc=0.5611110925674438, loss=1.6936635971069336
train: epoch 38, loss 0.16399991512298584, acc=0.9448333382606506, loss=0.16399991512298584
test: epoch 38, loss 1.5302746295928955, acc=0.5722222328186035, loss=1.5302746295928955
train: epoch 39, loss 0.1637735664844513, acc=0.9438333511352539, loss=0.1637735664844513
test: epoch 39, loss 1.579825520515442, acc=0.47777777910232544, loss=1.579825520515442
train: epoch 40, loss 0.14214849472045898, acc=0.9540555477142334, loss=0.14214849472045898
test: epoch 40, loss 2.067004919052124, acc=0.5277777910232544, loss=2.067004919052124
train: epoch 41, loss 0.1824202835559845, acc=0.9416666626930237, loss=0.1824202835559845
test: epoch 41, loss 1.5675088167190552, acc=0.6194444298744202, loss=1.5675088167190552
train: epoch 42, loss 0.12348408252000809, acc=0.9595555663108826, loss=0.12348408252000809
test: epoch 42, loss 1.5045832395553589, acc=0.5777778029441833, loss=1.5045832395553589
train: epoch 43, loss 0.15301766991615295, acc=0.9483888745307922, loss=0.15301766991615295
test: epoch 43, loss 1.6382120847702026, acc=0.5833333134651184, loss=1.6382120847702026
train: epoch 44, loss 0.12704262137413025, acc=0.9593889117240906, loss=0.12704262137413025
test: epoch 44, loss 1.8298081159591675, acc=0.5722222328186035, loss=1.8298081159591675
train: epoch 45, loss 0.14433656632900238, acc=0.953000009059906, loss=0.14433656632900238
test: epoch 45, loss 1.4929583072662354, acc=0.6222222447395325, loss=1.4929583072662354
train: epoch 46, loss 0.1271587759256363, acc=0.957444429397583, loss=0.1271587759256363
test: epoch 46, loss 1.8193634748458862, acc=0.6388888955116272, loss=1.8193634748458862
train: epoch 47, loss 0.12776224315166473, acc=0.9587222337722778, loss=0.12776224315166473
test: epoch 47, loss 2.1673359870910645, acc=0.5555555820465088, loss=2.1673359870910645
train: epoch 48, loss 0.1239280253648758, acc=0.9591666460037231, loss=0.1239280253648758
test: epoch 48, loss 1.778924584388733, acc=0.5444444417953491, loss=1.778924584388733
train: epoch 49, loss 0.1061968058347702, acc=0.9663333296775818, loss=0.1061968058347702
test: epoch 49, loss 1.820761799812317, acc=0.5638889074325562, loss=1.820761799812317
train: epoch 50, loss 0.1090710386633873, acc=0.9661111235618591, loss=0.1090710386633873
test: epoch 50, loss 1.8751102685928345, acc=0.5722222328186035, loss=1.8751102685928345
train: epoch 51, loss 0.11092210561037064, acc=0.9626111388206482, loss=0.11092210561037064
test: epoch 51, loss 1.83436119556427, acc=0.574999988079071, loss=1.83436119556427
train: epoch 52, loss 0.1411236971616745, acc=0.9555555582046509, loss=0.1411236971616745
test: epoch 52, loss 1.557399034500122, acc=0.644444465637207, loss=1.557399034500122
train: epoch 53, loss 0.10504108667373657, acc=0.9677222371101379, loss=0.10504108667373657
test: epoch 53, loss 1.8730663061141968, acc=0.6138888597488403, loss=1.8730663061141968
train: epoch 54, loss 0.09899589419364929, acc=0.968666672706604, loss=0.09899589419364929
test: epoch 54, loss 1.807812213897705, acc=0.5916666388511658, loss=1.807812213897705
train: epoch 55, loss 0.09327128529548645, acc=0.9710000157356262, loss=0.09327128529548645
test: epoch 55, loss 1.2310922145843506, acc=0.7166666388511658, loss=1.2310922145843506
train: epoch 56, loss 0.10515858978033066, acc=0.9672777652740479, loss=0.10515858978033066
test: epoch 56, loss 1.9911366701126099, acc=0.5638889074325562, loss=1.9911366701126099
train: epoch 57, loss 0.09429541230201721, acc=0.9706110954284668, loss=0.09429541230201721
test: epoch 57, loss 1.2073585987091064, acc=0.644444465637207, loss=1.2073585987091064
train: epoch 58, loss 0.09514424949884415, acc=0.9710555672645569, loss=0.09514424949884415
test: epoch 58, loss 1.5749256610870361, acc=0.6944444179534912, loss=1.5749256610870361
train: epoch 59, loss 0.09798992425203323, acc=0.9657222032546997, loss=0.09798992425203323
test: epoch 59, loss 1.6865102052688599, acc=0.6333333253860474, loss=1.6865102052688599
train: epoch 60, loss 0.10062752664089203, acc=0.9713333249092102, loss=0.10062752664089203
test: epoch 60, loss 1.6997853517532349, acc=0.6888889074325562, loss=1.6997853517532349
train: epoch 61, loss 0.07151786983013153, acc=0.9787777662277222, loss=0.07151786983013153
test: epoch 61, loss 1.6871538162231445, acc=0.6388888955116272, loss=1.6871538162231445
train: epoch 62, loss 0.10465224087238312, acc=0.9678333401679993, loss=0.10465224087238312
test: epoch 62, loss 1.6458096504211426, acc=0.6083333492279053, loss=1.6458096504211426
train: epoch 63, loss 0.07688573002815247, acc=0.9766111373901367, loss=0.07688573002815247
test: epoch 63, loss 0.9934409260749817, acc=0.6888889074325562, loss=0.9934409260749817
train: epoch 64, loss 0.0758776143193245, acc=0.9787222146987915, loss=0.0758776143193245
test: epoch 64, loss 1.3044060468673706, acc=0.6916666626930237, loss=1.3044060468673706
train: epoch 65, loss 0.09135111421346664, acc=0.9727222323417664, loss=0.09135111421346664
test: epoch 65, loss 1.3266531229019165, acc=0.699999988079071, loss=1.3266531229019165
train: epoch 66, loss 0.06951314955949783, acc=0.9792777895927429, loss=0.06951314955949783
test: epoch 66, loss 1.2961251735687256, acc=0.6111111044883728, loss=1.2961251735687256
train: epoch 67, loss 0.05297159031033516, acc=0.9830555319786072, loss=0.05297159031033516
test: epoch 67, loss 2.12357497215271, acc=0.7222222089767456, loss=2.12357497215271
train: epoch 68, loss 0.09350189566612244, acc=0.9721111059188843, loss=0.09350189566612244
test: epoch 68, loss 1.2860898971557617, acc=0.6472222208976746, loss=1.2860898971557617
train: epoch 69, loss 0.08672379702329636, acc=0.9748333096504211, loss=0.08672379702329636
test: epoch 69, loss 1.4866065979003906, acc=0.6027777791023254, loss=1.4866065979003906
train: epoch 70, loss 0.06497987359762192, acc=0.9804999828338623, loss=0.06497987359762192
test: epoch 70, loss 0.8828758597373962, acc=0.7611111402511597, loss=0.8828758597373962
train: epoch 71, loss 0.0856846272945404, acc=0.9736666679382324, loss=0.0856846272945404
test: epoch 71, loss 0.8960868120193481, acc=0.7749999761581421, loss=0.8960868120193481
train: epoch 72, loss 0.05095663666725159, acc=0.9848333597183228, loss=0.05095663666725159
test: epoch 72, loss 0.8670629262924194, acc=0.75, loss=0.8670629262924194
train: epoch 73, loss 0.07945013046264648, acc=0.9774444699287415, loss=0.07945013046264648
test: epoch 73, loss 0.8545123934745789, acc=0.7916666865348816, loss=0.8545123934745789
train: epoch 74, loss 0.06555286049842834, acc=0.9798333048820496, loss=0.06555286049842834
test: epoch 74, loss 1.191489338874817, acc=0.769444465637207, loss=1.191489338874817
train: epoch 75, loss 0.078877292573452, acc=0.9773889183998108, loss=0.078877292573452
test: epoch 75, loss 1.195817232131958, acc=0.7749999761581421, loss=1.195817232131958
train: epoch 76, loss 0.049143385142087936, acc=0.9858888983726501, loss=0.049143385142087936
test: epoch 76, loss 1.5663713216781616, acc=0.7194444537162781, loss=1.5663713216781616
train: epoch 77, loss 0.06819898635149002, acc=0.980222225189209, loss=0.06819898635149002
test: epoch 77, loss 0.8089986443519592, acc=0.8305555582046509, loss=0.8089986443519592
train: epoch 78, loss 0.06714513897895813, acc=0.9808889031410217, loss=0.06714513897895813
test: epoch 78, loss 0.8999364376068115, acc=0.7916666865348816, loss=0.8999364376068115
train: epoch 79, loss 0.07122504711151123, acc=0.9796666502952576, loss=0.07122504711151123
test: epoch 79, loss 1.021712064743042, acc=0.8138889074325562, loss=1.021712064743042
train: epoch 80, loss 0.04152507707476616, acc=0.988111138343811, loss=0.04152507707476616
test: epoch 80, loss 1.1774793863296509, acc=0.7666666507720947, loss=1.1774793863296509
train: epoch 81, loss 0.05709853768348694, acc=0.98416668176651, loss=0.05709853768348694
test: epoch 81, loss 1.240215539932251, acc=0.7916666865348816, loss=1.240215539932251
train: epoch 82, loss 0.05705865100026131, acc=0.9828888773918152, loss=0.05705865100026131
test: epoch 82, loss 0.43903014063835144, acc=0.8500000238418579, loss=0.43903014063835144
train: epoch 83, loss 0.08065208792686462, acc=0.9772777557373047, loss=0.08065208792686462
test: epoch 83, loss 0.6470317244529724, acc=0.8999999761581421, loss=0.6470317244529724
train: epoch 84, loss 0.03783221170306206, acc=0.9890555739402771, loss=0.03783221170306206
test: epoch 84, loss 0.6327734589576721, acc=0.875, loss=0.6327734589576721
train: epoch 85, loss 0.048926327377557755, acc=0.9861666560173035, loss=0.048926327377557755
test: epoch 85, loss 0.500313401222229, acc=0.8833333253860474, loss=0.500313401222229
train: epoch 86, loss 0.08391191810369492, acc=0.9799444675445557, loss=0.08391191810369492
test: epoch 86, loss 0.6019721627235413, acc=0.8583333492279053, loss=0.6019721627235413
train: epoch 87, loss 0.03685223311185837, acc=0.9883888959884644, loss=0.03685223311185837
test: epoch 87, loss 0.4066604673862457, acc=0.855555534362793, loss=0.4066604673862457
train: epoch 88, loss 0.06257186084985733, acc=0.9837777614593506, loss=0.06257186084985733
test: epoch 88, loss 0.4448552429676056, acc=0.8999999761581421, loss=0.4448552429676056
train: epoch 89, loss 0.03294302150607109, acc=0.9898333549499512, loss=0.03294302150607109
test: epoch 89, loss 0.9074029326438904, acc=0.8583333492279053, loss=0.9074029326438904
train: epoch 90, loss 0.05206664651632309, acc=0.9863888621330261, loss=0.05206664651632309
test: epoch 90, loss 0.8469216227531433, acc=0.8500000238418579, loss=0.8469216227531433
train: epoch 91, loss 0.056434717029333115, acc=0.9848333597183228, loss=0.056434717029333115
test: epoch 91, loss 0.8340443968772888, acc=0.8583333492279053, loss=0.8340443968772888
train: epoch 92, loss 0.04051099345088005, acc=0.9879999756813049, loss=0.04051099345088005
test: epoch 92, loss 0.30340734124183655, acc=0.9138888716697693, loss=0.30340734124183655
train: epoch 93, loss 0.03562546148896217, acc=0.9888333082199097, loss=0.03562546148896217
test: epoch 93, loss 0.43436169624328613, acc=0.8972222208976746, loss=0.43436169624328613
train: epoch 94, loss 0.04332779720425606, acc=0.9882222414016724, loss=0.04332779720425606
test: epoch 94, loss 0.5888852477073669, acc=0.8861111402511597, loss=0.5888852477073669
train: epoch 95, loss 0.05394791439175606, acc=0.9851666688919067, loss=0.05394791439175606
test: epoch 95, loss 0.680839478969574, acc=0.8388888835906982, loss=0.680839478969574
train: epoch 96, loss 0.03406573459506035, acc=0.9899444580078125, loss=0.03406573459506035
test: epoch 96, loss 0.5415794253349304, acc=0.8916666507720947, loss=0.5415794253349304
train: epoch 97, loss 0.04945095628499985, acc=0.9868888854980469, loss=0.04945095628499985
test: epoch 97, loss 0.5387289524078369, acc=0.855555534362793, loss=0.5387289524078369
train: epoch 98, loss 0.04084064066410065, acc=0.9881666898727417, loss=0.04084064066410065
test: epoch 98, loss 0.4488232731819153, acc=0.8999999761581421, loss=0.4488232731819153
train: epoch 99, loss 0.027158480137586594, acc=0.992388904094696, loss=0.027158480137586594
test: epoch 99, loss 0.926102876663208, acc=0.8388888835906982, loss=0.926102876663208
train: epoch 100, loss 0.03916822373867035, acc=0.9895555377006531, loss=0.03916822373867035
test: epoch 100, loss 0.4257630407810211, acc=0.8916666507720947, loss=0.4257630407810211
train: epoch 101, loss 0.04004047065973282, acc=0.988777756690979, loss=0.04004047065973282
test: epoch 101, loss 0.51285719871521, acc=0.8861111402511597, loss=0.51285719871521
train: epoch 102, loss 0.037159308791160583, acc=0.9904444217681885, loss=0.037159308791160583
test: epoch 102, loss 0.3368499279022217, acc=0.8972222208976746, loss=0.3368499279022217
train: epoch 103, loss 0.03944459557533264, acc=0.9897222518920898, loss=0.03944459557533264
test: epoch 103, loss 0.3562721014022827, acc=0.8916666507720947, loss=0.3562721014022827
train: epoch 104, loss 0.014446425251662731, acc=0.995888888835907, loss=0.014446425251662731
test: epoch 104, loss 0.20819678902626038, acc=0.9277777671813965, loss=0.20819678902626038
train: epoch 105, loss 0.052820879966020584, acc=0.9865555763244629, loss=0.052820879966020584
test: epoch 105, loss 0.3896711766719818, acc=0.9222221970558167, loss=0.3896711766719818
train: epoch 106, loss 0.017878729850053787, acc=0.9945555329322815, loss=0.017878729850053787
test: epoch 106, loss 0.4835340976715088, acc=0.8694444298744202, loss=0.4835340976715088
train: epoch 107, loss 0.0569828636944294, acc=0.9857777953147888, loss=0.0569828636944294
test: epoch 107, loss 0.3214116096496582, acc=0.949999988079071, loss=0.3214116096496582
train: epoch 108, loss 0.02738136798143387, acc=0.9920555353164673, loss=0.02738136798143387
test: epoch 108, loss 0.5035874843597412, acc=0.9083333611488342, loss=0.5035874843597412
train: epoch 109, loss 0.014379359781742096, acc=0.9961666464805603, loss=0.014379359781742096
test: epoch 109, loss 0.2990259826183319, acc=0.9194444417953491, loss=0.2990259826183319
train: epoch 110, loss 0.04408479854464531, acc=0.9891666769981384, loss=0.04408479854464531
test: epoch 110, loss 0.48667994141578674, acc=0.9055555462837219, loss=0.48667994141578674
train: epoch 111, loss 0.03138911724090576, acc=0.99144446849823, loss=0.03138911724090576
test: epoch 111, loss 0.22719943523406982, acc=0.9333333373069763, loss=0.22719943523406982
train: epoch 112, loss 0.01740841381251812, acc=0.9943333268165588, loss=0.01740841381251812
test: epoch 112, loss 0.44934719800949097, acc=0.9194444417953491, loss=0.44934719800949097
train: epoch 113, loss 0.03536533936858177, acc=0.9902777671813965, loss=0.03536533936858177
test: epoch 113, loss 0.29697057604789734, acc=0.9416666626930237, loss=0.29697057604789734
train: epoch 114, loss 0.01108289323747158, acc=0.996666669845581, loss=0.01108289323747158
test: epoch 114, loss 0.44595617055892944, acc=0.9277777671813965, loss=0.44595617055892944
train: epoch 115, loss 0.023887183517217636, acc=0.9937222003936768, loss=0.023887183517217636
test: epoch 115, loss 0.30269744992256165, acc=0.9166666865348816, loss=0.30269744992256165
train: epoch 116, loss 0.06325475871562958, acc=0.9852777719497681, loss=0.06325475871562958
test: epoch 116, loss 0.36351290345191956, acc=0.9138888716697693, loss=0.36351290345191956
train: epoch 117, loss 0.020921118557453156, acc=0.9940555691719055, loss=0.020921118557453156
test: epoch 117, loss 0.48314735293388367, acc=0.9111111164093018, loss=0.48314735293388367
train: epoch 118, loss 0.03580629453063011, acc=0.9915000200271606, loss=0.03580629453063011
test: epoch 118, loss 0.44119513034820557, acc=0.9027777910232544, loss=0.44119513034820557
train: epoch 119, loss 0.0238899365067482, acc=0.9932222366333008, loss=0.0238899365067482
test: epoch 119, loss 0.3665561378002167, acc=0.9166666865348816, loss=0.3665561378002167
train: epoch 120, loss 0.01826607435941696, acc=0.9955000281333923, loss=0.01826607435941696
test: epoch 120, loss 0.49099597334861755, acc=0.8999999761581421, loss=0.49099597334861755
train: epoch 121, loss 0.03101159818470478, acc=0.9931111335754395, loss=0.03101159818470478
test: epoch 121, loss 0.32309967279434204, acc=0.8972222208976746, loss=0.32309967279434204
train: epoch 122, loss 0.023684890940785408, acc=0.9932222366333008, loss=0.023684890940785408
test: epoch 122, loss 0.20810553431510925, acc=0.9527778029441833, loss=0.20810553431510925
train: epoch 123, loss 0.03132021799683571, acc=0.9932222366333008, loss=0.03132021799683571
test: epoch 123, loss 0.40906068682670593, acc=0.9361110925674438, loss=0.40906068682670593
train: epoch 124, loss 0.05853676050901413, acc=0.9866666793823242, loss=0.05853676050901413
test: epoch 124, loss 0.2679477035999298, acc=0.9555555582046509, loss=0.2679477035999298
train: epoch 125, loss 0.010403929278254509, acc=0.996999979019165, loss=0.010403929278254509
test: epoch 125, loss 0.25912773609161377, acc=0.9305555820465088, loss=0.25912773609161377
train: epoch 126, loss 0.027764199301600456, acc=0.9918888807296753, loss=0.027764199301600456
test: epoch 126, loss 0.2779216468334198, acc=0.9277777671813965, loss=0.2779216468334198
train: epoch 127, loss 0.016797810792922974, acc=0.995555579662323, loss=0.016797810792922974
test: epoch 127, loss 0.3238786458969116, acc=0.9194444417953491, loss=0.3238786458969116
train: epoch 128, loss 0.029656801372766495, acc=0.992888867855072, loss=0.029656801372766495
test: epoch 128, loss 0.5661498308181763, acc=0.8666666746139526, loss=0.5661498308181763
train: epoch 129, loss 0.011574800126254559, acc=0.996999979019165, loss=0.011574800126254559
test: epoch 129, loss 0.22597412765026093, acc=0.9361110925674438, loss=0.22597412765026093
train: epoch 130, loss 0.03380197659134865, acc=0.9934444427490234, loss=0.03380197659134865
test: epoch 130, loss 0.6507129669189453, acc=0.8861111402511597, loss=0.6507129669189453
train: epoch 131, loss 0.025603460147976875, acc=0.9939444661140442, loss=0.025603460147976875
test: epoch 131, loss 0.37601199746131897, acc=0.9444444179534912, loss=0.37601199746131897
train: epoch 132, loss 0.035249464213848114, acc=0.9928333163261414, loss=0.035249464213848114
test: epoch 132, loss 0.3079700469970703, acc=0.9527778029441833, loss=0.3079700469970703
train: epoch 133, loss 0.012875190936028957, acc=0.996666669845581, loss=0.012875190936028957
test: epoch 133, loss 0.28238755464553833, acc=0.9444444179534912, loss=0.28238755464553833
train: epoch 134, loss 0.03623441234230995, acc=0.9913889169692993, loss=0.03623441234230995
test: epoch 134, loss 0.2732459604740143, acc=0.9472222328186035, loss=0.2732459604740143
train: epoch 135, loss 0.02223513089120388, acc=0.9950000047683716, loss=0.02223513089120388
test: epoch 135, loss 0.2770776152610779, acc=0.9472222328186035, loss=0.2770776152610779
train: epoch 136, loss 0.01632683351635933, acc=0.995888888835907, loss=0.01632683351635933
test: epoch 136, loss 0.2609509825706482, acc=0.9444444179534912, loss=0.2609509825706482
train: epoch 137, loss 0.029238933697342873, acc=0.9931111335754395, loss=0.029238933697342873
test: epoch 137, loss 0.18724466860294342, acc=0.9472222328186035, loss=0.18724466860294342
train: epoch 138, loss 0.028187084943056107, acc=0.9936110973358154, loss=0.028187084943056107
test: epoch 138, loss 0.23936565220355988, acc=0.9555555582046509, loss=0.23936565220355988
train: epoch 139, loss 0.01575637422502041, acc=0.995722234249115, loss=0.01575637422502041
test: epoch 139, loss 0.31525495648384094, acc=0.9305555820465088, loss=0.31525495648384094
train: epoch 140, loss 0.03527684882283211, acc=0.9918333292007446, loss=0.03527684882283211
test: epoch 140, loss 0.1493445336818695, acc=0.9555555582046509, loss=0.1493445336818695
train: epoch 141, loss 0.0075503201223909855, acc=0.9982777833938599, loss=0.0075503201223909855
test: epoch 141, loss 0.295429527759552, acc=0.9527778029441833, loss=0.295429527759552
train: epoch 142, loss 0.020786674693226814, acc=0.9951666593551636, loss=0.020786674693226814
test: epoch 142, loss 0.1981332153081894, acc=0.9638888835906982, loss=0.1981332153081894
train: epoch 143, loss 0.024175800383090973, acc=0.9939444661140442, loss=0.024175800383090973
test: epoch 143, loss 0.26288801431655884, acc=0.9444444179534912, loss=0.26288801431655884
train: epoch 144, loss 0.0090914536267519, acc=0.9978333115577698, loss=0.0090914536267519
test: epoch 144, loss 0.31020522117614746, acc=0.9444444179534912, loss=0.31020522117614746
train: epoch 145, loss 0.015986265614628792, acc=0.9956666827201843, loss=0.015986265614628792
test: epoch 145, loss 0.22266237437725067, acc=0.9333333373069763, loss=0.22266237437725067
train: epoch 146, loss 0.021794553846120834, acc=0.9956666827201843, loss=0.021794553846120834
test: epoch 146, loss 0.17834028601646423, acc=0.9611111283302307, loss=0.17834028601646423
train: epoch 147, loss 0.04003206640481949, acc=0.9909999966621399, loss=0.04003206640481949
test: epoch 147, loss 0.2555299997329712, acc=0.9472222328186035, loss=0.2555299997329712
train: epoch 148, loss 0.006859465502202511, acc=0.9982222318649292, loss=0.006859465502202511
test: epoch 148, loss 0.28175094723701477, acc=0.9583333134651184, loss=0.28175094723701477
train: epoch 149, loss 0.03162333741784096, acc=0.9927777647972107, loss=0.03162333741784096
test: epoch 149, loss 0.15909022092819214, acc=0.9611111283302307, loss=0.15909022092819214
train: epoch 150, loss 0.016711870208382607, acc=0.9963889122009277, loss=0.016711870208382607
test: epoch 150, loss 0.18951480090618134, acc=0.9611111283302307, loss=0.18951480090618134
