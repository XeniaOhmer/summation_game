# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1.5", "--temp_decay=0.99", "--one_hot=true", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=320466684, receiver_embed_dim=32, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.0878937244415283, acc=0.07444444298744202, loss=3.0878937244415283
test: epoch 1, loss 2.9892144203186035, acc=0.09444444626569748, loss=2.9892144203186035
train: epoch 2, loss 2.1515402793884277, acc=0.19200000166893005, loss=2.1515402793884277
test: epoch 2, loss 3.2651021480560303, acc=0.10555555671453476, loss=3.2651021480560303
train: epoch 3, loss 1.880714774131775, acc=0.25022223591804504, loss=1.880714774131775
test: epoch 3, loss 2.9195828437805176, acc=0.13333334028720856, loss=2.9195828437805176
train: epoch 4, loss 1.7289966344833374, acc=0.2816111147403717, loss=1.7289966344833374
test: epoch 4, loss 2.6573550701141357, acc=0.13611111044883728, loss=2.6573550701141357
train: epoch 5, loss 1.6160670518875122, acc=0.320166677236557, loss=1.6160670518875122
test: epoch 5, loss 2.917499542236328, acc=0.14722222089767456, loss=2.917499542236328
train: epoch 6, loss 1.5131498575210571, acc=0.33977776765823364, loss=1.5131498575210571
test: epoch 6, loss 2.9108548164367676, acc=0.16111111640930176, loss=2.9108548164367676
train: epoch 7, loss 1.4478075504302979, acc=0.35883334279060364, loss=1.4478075504302979
test: epoch 7, loss 2.6843972206115723, acc=0.1527777761220932, loss=2.6843972206115723
train: epoch 8, loss 1.3907779455184937, acc=0.3717222213745117, loss=1.3907779455184937
test: epoch 8, loss 2.5537736415863037, acc=0.17499999701976776, loss=2.5537736415863037
train: epoch 9, loss 1.3432518243789673, acc=0.38877779245376587, loss=1.3432518243789673
test: epoch 9, loss 2.8042593002319336, acc=0.1666666716337204, loss=2.8042593002319336
train: epoch 10, loss 1.2793819904327393, acc=0.4082222282886505, loss=1.2793819904327393
test: epoch 10, loss 2.7441184520721436, acc=0.20000000298023224, loss=2.7441184520721436
train: epoch 11, loss 1.2750393152236938, acc=0.41794443130493164, loss=1.2750393152236938
test: epoch 11, loss 2.545111656188965, acc=0.19722221791744232, loss=2.545111656188965
train: epoch 12, loss 1.2353739738464355, acc=0.4347222149372101, loss=1.2353739738464355
test: epoch 12, loss 2.346613883972168, acc=0.17222222685813904, loss=2.346613883972168
train: epoch 13, loss 1.1985756158828735, acc=0.4573333263397217, loss=1.1985756158828735
test: epoch 13, loss 2.1060171127319336, acc=0.1944444477558136, loss=2.1060171127319336
train: epoch 14, loss 1.1629308462142944, acc=0.4698333442211151, loss=1.1629308462142944
test: epoch 14, loss 1.9583747386932373, acc=0.31388887763023376, loss=1.9583747386932373
train: epoch 15, loss 1.1091724634170532, acc=0.49505555629730225, loss=1.1091724634170532
test: epoch 15, loss 2.0081796646118164, acc=0.28333333134651184, loss=2.0081796646118164
train: epoch 16, loss 1.0533946752548218, acc=0.5239444375038147, loss=1.0533946752548218
test: epoch 16, loss 1.7548962831497192, acc=0.36944442987442017, loss=1.7548962831497192
train: epoch 17, loss 1.0041956901550293, acc=0.5513333082199097, loss=1.0041956901550293
test: epoch 17, loss 1.9765245914459229, acc=0.3055555522441864, loss=1.9765245914459229
train: epoch 18, loss 0.9611696004867554, acc=0.5796666741371155, loss=0.9611696004867554
test: epoch 18, loss 1.7406290769577026, acc=0.3222222328186035, loss=1.7406290769577026
train: epoch 19, loss 0.8690770864486694, acc=0.6328333616256714, loss=0.8690770864486694
test: epoch 19, loss 2.025972604751587, acc=0.31388887763023376, loss=2.025972604751587
train: epoch 20, loss 0.7754978537559509, acc=0.6892777681350708, loss=0.7754978537559509
test: epoch 20, loss 1.617384672164917, acc=0.43888887763023376, loss=1.617384672164917
train: epoch 21, loss 0.6854608654975891, acc=0.731166660785675, loss=0.6854608654975891
test: epoch 21, loss 1.604612946510315, acc=0.4333333373069763, loss=1.604612946510315
train: epoch 22, loss 0.6336207985877991, acc=0.7553889155387878, loss=0.6336207985877991
test: epoch 22, loss 1.6431059837341309, acc=0.3861111104488373, loss=1.6431059837341309
train: epoch 23, loss 0.5882003307342529, acc=0.7723888754844666, loss=0.5882003307342529
test: epoch 23, loss 1.5677204132080078, acc=0.4055555462837219, loss=1.5677204132080078
train: epoch 24, loss 0.5449587106704712, acc=0.7902777791023254, loss=0.5449587106704712
test: epoch 24, loss 1.6486397981643677, acc=0.4472222328186035, loss=1.6486397981643677
train: epoch 25, loss 0.5101993083953857, acc=0.8004444241523743, loss=0.5101993083953857
test: epoch 25, loss 1.532488226890564, acc=0.4305555522441864, loss=1.532488226890564
train: epoch 26, loss 0.4948893189430237, acc=0.8065000176429749, loss=0.4948893189430237
test: epoch 26, loss 1.784483551979065, acc=0.4027777910232544, loss=1.784483551979065
train: epoch 27, loss 0.4916824400424957, acc=0.8063889145851135, loss=0.4916824400424957
test: epoch 27, loss 1.6344879865646362, acc=0.48055556416511536, loss=1.6344879865646362
train: epoch 28, loss 0.46835073828697205, acc=0.8172222375869751, loss=0.46835073828697205
test: epoch 28, loss 1.3711961507797241, acc=0.4972222149372101, loss=1.3711961507797241
train: epoch 29, loss 0.45593705773353577, acc=0.8253889083862305, loss=0.45593705773353577
test: epoch 29, loss 1.4496101140975952, acc=0.4611110985279083, loss=1.4496101140975952
train: epoch 30, loss 0.4314044117927551, acc=0.8342221975326538, loss=0.4314044117927551
test: epoch 30, loss 1.6393375396728516, acc=0.4472222328186035, loss=1.6393375396728516
train: epoch 31, loss 0.4344156086444855, acc=0.8323888778686523, loss=0.4344156086444855
test: epoch 31, loss 1.8976852893829346, acc=0.4722222089767456, loss=1.8976852893829346
train: epoch 32, loss 0.43060535192489624, acc=0.83561110496521, loss=0.43060535192489624
test: epoch 32, loss 1.4895355701446533, acc=0.5222222208976746, loss=1.4895355701446533
train: epoch 33, loss 0.4134235382080078, acc=0.839722216129303, loss=0.4134235382080078
test: epoch 33, loss 1.5737007856369019, acc=0.4833333194255829, loss=1.5737007856369019
train: epoch 34, loss 0.4039672613143921, acc=0.8493333458900452, loss=0.4039672613143921
test: epoch 34, loss 1.5001307725906372, acc=0.4888888895511627, loss=1.5001307725906372
train: epoch 35, loss 0.390324205160141, acc=0.8510555624961853, loss=0.390324205160141
test: epoch 35, loss 1.48416006565094, acc=0.45277777314186096, loss=1.48416006565094
train: epoch 36, loss 0.41027697920799255, acc=0.8475555777549744, loss=0.41027697920799255
test: epoch 36, loss 1.6243418455123901, acc=0.5111111402511597, loss=1.6243418455123901
train: epoch 37, loss 0.3751981258392334, acc=0.8594444394111633, loss=0.3751981258392334
test: epoch 37, loss 1.3855024576187134, acc=0.5583333373069763, loss=1.3855024576187134
train: epoch 38, loss 0.3904806971549988, acc=0.8528888821601868, loss=0.3904806971549988
test: epoch 38, loss 1.589264988899231, acc=0.5138888955116272, loss=1.589264988899231
train: epoch 39, loss 0.38430944085121155, acc=0.8529444336891174, loss=0.38430944085121155
test: epoch 39, loss 1.4971176385879517, acc=0.5083333253860474, loss=1.4971176385879517
train: epoch 40, loss 0.3651544749736786, acc=0.8600555658340454, loss=0.3651544749736786
test: epoch 40, loss 1.3987489938735962, acc=0.5277777910232544, loss=1.3987489938735962
train: epoch 41, loss 0.3650616407394409, acc=0.8617777824401855, loss=0.3650616407394409
test: epoch 41, loss 1.4032424688339233, acc=0.4888888895511627, loss=1.4032424688339233
train: epoch 42, loss 0.3756628632545471, acc=0.8581110835075378, loss=0.3756628632545471
test: epoch 42, loss 1.2492258548736572, acc=0.5388888716697693, loss=1.2492258548736572
train: epoch 43, loss 0.35688138008117676, acc=0.8669999837875366, loss=0.35688138008117676
test: epoch 43, loss 1.3033276796340942, acc=0.5277777910232544, loss=1.3033276796340942
train: epoch 44, loss 0.3672627806663513, acc=0.8641111254692078, loss=0.3672627806663513
test: epoch 44, loss 1.3821840286254883, acc=0.5305555462837219, loss=1.3821840286254883
train: epoch 45, loss 0.33655235171318054, acc=0.8758333325386047, loss=0.33655235171318054
test: epoch 45, loss 1.375514030456543, acc=0.6027777791023254, loss=1.375514030456543
train: epoch 46, loss 0.36472615599632263, acc=0.8638888597488403, loss=0.36472615599632263
test: epoch 46, loss 1.2175517082214355, acc=0.5416666865348816, loss=1.2175517082214355
train: epoch 47, loss 0.3750168979167938, acc=0.8576111197471619, loss=0.3750168979167938
test: epoch 47, loss 1.2486772537231445, acc=0.5583333373069763, loss=1.2486772537231445
train: epoch 48, loss 0.3393249809741974, acc=0.8709999918937683, loss=0.3393249809741974
test: epoch 48, loss 1.2291918992996216, acc=0.5416666865348816, loss=1.2291918992996216
train: epoch 49, loss 0.3646535277366638, acc=0.8616666793823242, loss=0.3646535277366638
test: epoch 49, loss 1.2572920322418213, acc=0.5666666626930237, loss=1.2572920322418213
train: epoch 50, loss 0.3399645984172821, acc=0.8708333373069763, loss=0.3399645984172821
test: epoch 50, loss 1.1359062194824219, acc=0.5777778029441833, loss=1.1359062194824219
train: epoch 51, loss 0.3404330909252167, acc=0.8699444532394409, loss=0.3404330909252167
test: epoch 51, loss 1.1189584732055664, acc=0.5805555582046509, loss=1.1189584732055664
train: epoch 52, loss 0.3515288233757019, acc=0.8663889169692993, loss=0.3515288233757019
test: epoch 52, loss 1.1147475242614746, acc=0.6027777791023254, loss=1.1147475242614746
train: epoch 53, loss 0.3622501492500305, acc=0.8650555610656738, loss=0.3622501492500305
test: epoch 53, loss 1.153173804283142, acc=0.5305555462837219, loss=1.153173804283142
train: epoch 54, loss 0.3556963801383972, acc=0.8668888807296753, loss=0.3556963801383972
test: epoch 54, loss 1.0868443250656128, acc=0.6138888597488403, loss=1.0868443250656128
train: epoch 55, loss 0.327596515417099, acc=0.8774999976158142, loss=0.327596515417099
test: epoch 55, loss 1.0319160223007202, acc=0.5972222089767456, loss=1.0319160223007202
train: epoch 56, loss 0.33777907490730286, acc=0.8731111288070679, loss=0.33777907490730286
test: epoch 56, loss 1.096222996711731, acc=0.5805555582046509, loss=1.096222996711731
train: epoch 57, loss 0.37136971950531006, acc=0.8608888983726501, loss=0.37136971950531006
test: epoch 57, loss 1.2533001899719238, acc=0.6000000238418579, loss=1.2533001899719238
train: epoch 58, loss 0.3422671854496002, acc=0.8755555748939514, loss=0.3422671854496002
test: epoch 58, loss 1.0491050481796265, acc=0.5666666626930237, loss=1.0491050481796265
train: epoch 59, loss 0.33047717809677124, acc=0.8734999895095825, loss=0.33047717809677124
test: epoch 59, loss 1.0839805603027344, acc=0.6361111402511597, loss=1.0839805603027344
train: epoch 60, loss 0.3432079553604126, acc=0.8706666827201843, loss=0.3432079553604126
test: epoch 60, loss 1.1707115173339844, acc=0.5694444179534912, loss=1.1707115173339844
train: epoch 61, loss 0.34007588028907776, acc=0.867388904094696, loss=0.34007588028907776
test: epoch 61, loss 1.1529701948165894, acc=0.6138888597488403, loss=1.1529701948165894
train: epoch 62, loss 0.3371991515159607, acc=0.8761110901832581, loss=0.3371991515159607
test: epoch 62, loss 0.9643324613571167, acc=0.6611111164093018, loss=0.9643324613571167
train: epoch 63, loss 0.3532174527645111, acc=0.8654999732971191, loss=0.3532174527645111
test: epoch 63, loss 1.0160504579544067, acc=0.6027777791023254, loss=1.0160504579544067
train: epoch 64, loss 0.3477521538734436, acc=0.867555558681488, loss=0.3477521538734436
test: epoch 64, loss 1.2303274869918823, acc=0.5722222328186035, loss=1.2303274869918823
train: epoch 65, loss 0.35247886180877686, acc=0.8652222156524658, loss=0.35247886180877686
test: epoch 65, loss 1.1167025566101074, acc=0.5888888835906982, loss=1.1167025566101074
train: epoch 66, loss 0.3274158239364624, acc=0.8750555515289307, loss=0.3274158239364624
test: epoch 66, loss 0.9611184000968933, acc=0.625, loss=0.9611184000968933
train: epoch 67, loss 0.3378942906856537, acc=0.8761666417121887, loss=0.3378942906856537
test: epoch 67, loss 0.8756834268569946, acc=0.6888889074325562, loss=0.8756834268569946
train: epoch 68, loss 0.3330293297767639, acc=0.874666690826416, loss=0.3330293297767639
test: epoch 68, loss 1.1574935913085938, acc=0.6277777552604675, loss=1.1574935913085938
train: epoch 69, loss 0.3686787486076355, acc=0.859000027179718, loss=0.3686787486076355
test: epoch 69, loss 0.9171139597892761, acc=0.6583333611488342, loss=0.9171139597892761
train: epoch 70, loss 0.34252864122390747, acc=0.8697777986526489, loss=0.34252864122390747
test: epoch 70, loss 1.1417994499206543, acc=0.6277777552604675, loss=1.1417994499206543
train: epoch 71, loss 0.3476395308971405, acc=0.8678333163261414, loss=0.3476395308971405
test: epoch 71, loss 0.9198204874992371, acc=0.644444465637207, loss=0.9198204874992371
train: epoch 72, loss 0.32276982069015503, acc=0.8790555596351624, loss=0.32276982069015503
test: epoch 72, loss 0.8571646809577942, acc=0.6666666865348816, loss=0.8571646809577942
train: epoch 73, loss 0.34789320826530457, acc=0.8650000095367432, loss=0.34789320826530457
test: epoch 73, loss 0.9464530348777771, acc=0.6694444417953491, loss=0.9464530348777771
train: epoch 74, loss 0.3423372805118561, acc=0.8708333373069763, loss=0.3423372805118561
test: epoch 74, loss 1.064107894897461, acc=0.6472222208976746, loss=1.064107894897461
train: epoch 75, loss 0.31919363141059875, acc=0.8793888688087463, loss=0.31919363141059875
test: epoch 75, loss 0.9149178862571716, acc=0.6611111164093018, loss=0.9149178862571716
train: epoch 76, loss 0.32552435994148254, acc=0.8777222037315369, loss=0.32552435994148254
test: epoch 76, loss 0.9334579706192017, acc=0.6638888716697693, loss=0.9334579706192017
train: epoch 77, loss 0.32088708877563477, acc=0.8773888945579529, loss=0.32088708877563477
test: epoch 77, loss 0.8811655044555664, acc=0.6777777671813965, loss=0.8811655044555664
train: epoch 78, loss 0.33418816328048706, acc=0.8772777915000916, loss=0.33418816328048706
test: epoch 78, loss 1.068008303642273, acc=0.6833333373069763, loss=1.068008303642273
train: epoch 79, loss 0.31433114409446716, acc=0.879444420337677, loss=0.31433114409446716
test: epoch 79, loss 0.8237603306770325, acc=0.6944444179534912, loss=0.8237603306770325
train: epoch 80, loss 0.30726879835128784, acc=0.8841666579246521, loss=0.30726879835128784
test: epoch 80, loss 1.0066875219345093, acc=0.6833333373069763, loss=1.0066875219345093
train: epoch 81, loss 0.3200213313102722, acc=0.8762221932411194, loss=0.3200213313102722
test: epoch 81, loss 0.9084201455116272, acc=0.6888889074325562, loss=0.9084201455116272
train: epoch 82, loss 0.30414149165153503, acc=0.8795555830001831, loss=0.30414149165153503
test: epoch 82, loss 0.966301679611206, acc=0.6361111402511597, loss=0.966301679611206
train: epoch 83, loss 0.30245649814605713, acc=0.8858333230018616, loss=0.30245649814605713
test: epoch 83, loss 0.9548963904380798, acc=0.6972222328186035, loss=0.9548963904380798
train: epoch 84, loss 0.31502190232276917, acc=0.8823333382606506, loss=0.31502190232276917
test: epoch 84, loss 0.7476301789283752, acc=0.7138888835906982, loss=0.7476301789283752
train: epoch 85, loss 0.29396548867225647, acc=0.8829444646835327, loss=0.29396548867225647
test: epoch 85, loss 0.8254384398460388, acc=0.699999988079071, loss=0.8254384398460388
train: epoch 86, loss 0.30855903029441833, acc=0.8820000290870667, loss=0.30855903029441833
test: epoch 86, loss 0.6401617527008057, acc=0.7361111044883728, loss=0.6401617527008057
train: epoch 87, loss 0.2999842166900635, acc=0.8852777481079102, loss=0.2999842166900635
test: epoch 87, loss 0.8809825778007507, acc=0.7055555582046509, loss=0.8809825778007507
train: epoch 88, loss 0.3075684905052185, acc=0.8849444389343262, loss=0.3075684905052185
test: epoch 88, loss 0.9912391304969788, acc=0.6666666865348816, loss=0.9912391304969788
train: epoch 89, loss 0.2902962267398834, acc=0.8889999985694885, loss=0.2902962267398834
test: epoch 89, loss 0.6866751313209534, acc=0.7194444537162781, loss=0.6866751313209534
train: epoch 90, loss 0.29073184728622437, acc=0.886388897895813, loss=0.29073184728622437
test: epoch 90, loss 0.6614046096801758, acc=0.7166666388511658, loss=0.6614046096801758
train: epoch 91, loss 0.29349955916404724, acc=0.890500009059906, loss=0.29349955916404724
test: epoch 91, loss 0.8929311037063599, acc=0.675000011920929, loss=0.8929311037063599
train: epoch 92, loss 0.28279995918273926, acc=0.8942777514457703, loss=0.28279995918273926
test: epoch 92, loss 0.6855522990226746, acc=0.7472222447395325, loss=0.6855522990226746
train: epoch 93, loss 0.2833121120929718, acc=0.8934999704360962, loss=0.2833121120929718
test: epoch 93, loss 0.7772437334060669, acc=0.6916666626930237, loss=0.7772437334060669
train: epoch 94, loss 0.27595850825309753, acc=0.8964444398880005, loss=0.27595850825309753
test: epoch 94, loss 0.7924414277076721, acc=0.7583333253860474, loss=0.7924414277076721
train: epoch 95, loss 0.2822975814342499, acc=0.8926666378974915, loss=0.2822975814342499
test: epoch 95, loss 0.8213392496109009, acc=0.7333333492279053, loss=0.8213392496109009
train: epoch 96, loss 0.27282777428627014, acc=0.8969444632530212, loss=0.27282777428627014
test: epoch 96, loss 0.7190358638763428, acc=0.6916666626930237, loss=0.7190358638763428
train: epoch 97, loss 0.2836053967475891, acc=0.8911666870117188, loss=0.2836053967475891
test: epoch 97, loss 0.6328908205032349, acc=0.7138888835906982, loss=0.6328908205032349
train: epoch 98, loss 0.2723807692527771, acc=0.8973333239555359, loss=0.2723807692527771
test: epoch 98, loss 0.8251655101776123, acc=0.7416666746139526, loss=0.8251655101776123
train: epoch 99, loss 0.2677995562553406, acc=0.9002777934074402, loss=0.2677995562553406
test: epoch 99, loss 0.7380388975143433, acc=0.7388888597488403, loss=0.7380388975143433
train: epoch 100, loss 0.28072425723075867, acc=0.8950555324554443, loss=0.28072425723075867
test: epoch 100, loss 0.8148797154426575, acc=0.7277777791023254, loss=0.8148797154426575
train: epoch 101, loss 0.2590005695819855, acc=0.9014999866485596, loss=0.2590005695819855
test: epoch 101, loss 0.6332586407661438, acc=0.7416666746139526, loss=0.6332586407661438
train: epoch 102, loss 0.2461683750152588, acc=0.9026111364364624, loss=0.2461683750152588
test: epoch 102, loss 0.7927305698394775, acc=0.730555534362793, loss=0.7927305698394775
train: epoch 103, loss 0.26095670461654663, acc=0.9037222266197205, loss=0.26095670461654663
test: epoch 103, loss 0.672619640827179, acc=0.7583333253860474, loss=0.672619640827179
train: epoch 104, loss 0.2598767876625061, acc=0.903166651725769, loss=0.2598767876625061
test: epoch 104, loss 0.6469256281852722, acc=0.7444444298744202, loss=0.6469256281852722
train: epoch 105, loss 0.2606828212738037, acc=0.9000555276870728, loss=0.2606828212738037
test: epoch 105, loss 0.630092442035675, acc=0.7444444298744202, loss=0.630092442035675
train: epoch 106, loss 0.25109341740608215, acc=0.9054999947547913, loss=0.25109341740608215
test: epoch 106, loss 0.7480853796005249, acc=0.7250000238418579, loss=0.7480853796005249
train: epoch 107, loss 0.25055089592933655, acc=0.9066110849380493, loss=0.25055089592933655
test: epoch 107, loss 0.8625999093055725, acc=0.7388888597488403, loss=0.8625999093055725
train: epoch 108, loss 0.24930956959724426, acc=0.9054999947547913, loss=0.24930956959724426
test: epoch 108, loss 0.8555000424385071, acc=0.6944444179534912, loss=0.8555000424385071
train: epoch 109, loss 0.2501440942287445, acc=0.9052222371101379, loss=0.2501440942287445
test: epoch 109, loss 0.7089449763298035, acc=0.7777777910232544, loss=0.7089449763298035
train: epoch 110, loss 0.24372462928295135, acc=0.9078333377838135, loss=0.24372462928295135
test: epoch 110, loss 0.6844502687454224, acc=0.7722222208976746, loss=0.6844502687454224
train: epoch 111, loss 0.24411965906620026, acc=0.9083333611488342, loss=0.24411965906620026
test: epoch 111, loss 0.6536658406257629, acc=0.7638888955116272, loss=0.6536658406257629
train: epoch 112, loss 0.25542715191841125, acc=0.9061111211776733, loss=0.25542715191841125
test: epoch 112, loss 0.7799988985061646, acc=0.7944444417953491, loss=0.7799988985061646
train: epoch 113, loss 0.24294014275074005, acc=0.9068333506584167, loss=0.24294014275074005
test: epoch 113, loss 0.7882260084152222, acc=0.7638888955116272, loss=0.7882260084152222
train: epoch 114, loss 0.23312599956989288, acc=0.9117222428321838, loss=0.23312599956989288
test: epoch 114, loss 0.7052000164985657, acc=0.7555555701255798, loss=0.7052000164985657
train: epoch 115, loss 0.25152266025543213, acc=0.9043333530426025, loss=0.25152266025543213
test: epoch 115, loss 0.6468726396560669, acc=0.7472222447395325, loss=0.6468726396560669
train: epoch 116, loss 0.2499886453151703, acc=0.906166672706604, loss=0.2499886453151703
test: epoch 116, loss 0.5709760785102844, acc=0.8138889074325562, loss=0.5709760785102844
train: epoch 117, loss 0.22959217429161072, acc=0.9140555262565613, loss=0.22959217429161072
test: epoch 117, loss 0.6457928419113159, acc=0.8083333373069763, loss=0.6457928419113159
train: epoch 118, loss 0.23423895239830017, acc=0.9104999899864197, loss=0.23423895239830017
test: epoch 118, loss 0.641386091709137, acc=0.7250000238418579, loss=0.641386091709137
train: epoch 119, loss 0.23437972366809845, acc=0.910444438457489, loss=0.23437972366809845
test: epoch 119, loss 0.6191555857658386, acc=0.769444465637207, loss=0.6191555857658386
train: epoch 120, loss 0.23694823682308197, acc=0.9096111059188843, loss=0.23694823682308197
test: epoch 120, loss 0.6985728740692139, acc=0.8083333373069763, loss=0.6985728740692139
train: epoch 121, loss 0.2298300862312317, acc=0.9135555624961853, loss=0.2298300862312317
test: epoch 121, loss 0.5561781525611877, acc=0.8055555820465088, loss=0.5561781525611877
train: epoch 122, loss 0.23741745948791504, acc=0.9110555648803711, loss=0.23741745948791504
test: epoch 122, loss 0.6580184698104858, acc=0.7666666507720947, loss=0.6580184698104858
train: epoch 123, loss 0.24595926702022552, acc=0.9082221984863281, loss=0.24595926702022552
test: epoch 123, loss 0.6094070672988892, acc=0.7944444417953491, loss=0.6094070672988892
train: epoch 124, loss 0.23413506150245667, acc=0.9097222089767456, loss=0.23413506150245667
test: epoch 124, loss 0.7186343669891357, acc=0.8111110925674438, loss=0.7186343669891357
train: epoch 125, loss 0.2352634072303772, acc=0.9111111164093018, loss=0.2352634072303772
test: epoch 125, loss 0.594588577747345, acc=0.7749999761581421, loss=0.594588577747345
train: epoch 126, loss 0.22260424494743347, acc=0.9156666398048401, loss=0.22260424494743347
test: epoch 126, loss 0.5668168663978577, acc=0.7749999761581421, loss=0.5668168663978577
train: epoch 127, loss 0.23711621761322021, acc=0.9132221937179565, loss=0.23711621761322021
test: epoch 127, loss 0.5680059790611267, acc=0.7749999761581421, loss=0.5680059790611267
train: epoch 128, loss 0.22721131145954132, acc=0.9094444513320923, loss=0.22721131145954132
test: epoch 128, loss 0.6515498757362366, acc=0.7805555462837219, loss=0.6515498757362366
train: epoch 129, loss 0.2110244482755661, acc=0.9178333282470703, loss=0.2110244482755661
test: epoch 129, loss 0.5758821964263916, acc=0.8194444179534912, loss=0.5758821964263916
train: epoch 130, loss 0.21958832442760468, acc=0.9162777662277222, loss=0.21958832442760468
test: epoch 130, loss 0.7816922664642334, acc=0.7805555462837219, loss=0.7816922664642334
train: epoch 131, loss 0.21224181354045868, acc=0.9197777509689331, loss=0.21224181354045868
test: epoch 131, loss 0.5449373126029968, acc=0.8027777671813965, loss=0.5449373126029968
train: epoch 132, loss 0.23366084694862366, acc=0.9110555648803711, loss=0.23366084694862366
test: epoch 132, loss 0.4787614643573761, acc=0.8166666626930237, loss=0.4787614643573761
train: epoch 133, loss 0.21104538440704346, acc=0.9193888902664185, loss=0.21104538440704346
test: epoch 133, loss 0.5568745732307434, acc=0.8194444179534912, loss=0.5568745732307434
train: epoch 134, loss 0.22164824604988098, acc=0.9200000166893005, loss=0.22164824604988098
test: epoch 134, loss 0.7652509808540344, acc=0.8083333373069763, loss=0.7652509808540344
train: epoch 135, loss 0.22850598394870758, acc=0.9123333096504211, loss=0.22850598394870758
test: epoch 135, loss 0.5563133955001831, acc=0.8194444179534912, loss=0.5563133955001831
train: epoch 136, loss 0.21950532495975494, acc=0.9160555601119995, loss=0.21950532495975494
test: epoch 136, loss 0.5338253378868103, acc=0.8166666626930237, loss=0.5338253378868103
train: epoch 137, loss 0.20181934535503387, acc=0.9254999756813049, loss=0.20181934535503387
test: epoch 137, loss 0.6052700281143188, acc=0.7749999761581421, loss=0.6052700281143188
train: epoch 138, loss 0.21307146549224854, acc=0.9187777638435364, loss=0.21307146549224854
test: epoch 138, loss 0.5669587850570679, acc=0.8194444179534912, loss=0.5669587850570679
train: epoch 139, loss 0.2329864799976349, acc=0.92166668176651, loss=0.2329864799976349
test: epoch 139, loss 0.6187848448753357, acc=0.8166666626930237, loss=0.6187848448753357
train: epoch 140, loss 0.22159667313098907, acc=0.9164999723434448, loss=0.22159667313098907
test: epoch 140, loss 0.531566858291626, acc=0.8166666626930237, loss=0.531566858291626
train: epoch 141, loss 0.2050573080778122, acc=0.9225000143051147, loss=0.2050573080778122
test: epoch 141, loss 0.518147885799408, acc=0.8083333373069763, loss=0.518147885799408
train: epoch 142, loss 0.22043046355247498, acc=0.9152222275733948, loss=0.22043046355247498
test: epoch 142, loss 0.5395922064781189, acc=0.8138889074325562, loss=0.5395922064781189
train: epoch 143, loss 0.2003614902496338, acc=0.9225000143051147, loss=0.2003614902496338
test: epoch 143, loss 0.5749565362930298, acc=0.7805555462837219, loss=0.5749565362930298
train: epoch 144, loss 0.2154766321182251, acc=0.917888879776001, loss=0.2154766321182251
test: epoch 144, loss 0.5673263072967529, acc=0.8027777671813965, loss=0.5673263072967529
train: epoch 145, loss 0.20649054646492004, acc=0.9227222204208374, loss=0.20649054646492004
test: epoch 145, loss 0.5745978355407715, acc=0.8166666626930237, loss=0.5745978355407715
train: epoch 146, loss 0.1841587871313095, acc=0.9251111149787903, loss=0.1841587871313095
test: epoch 146, loss 0.5496280193328857, acc=0.8055555820465088, loss=0.5496280193328857
train: epoch 147, loss 0.2083388715982437, acc=0.9183889031410217, loss=0.2083388715982437
test: epoch 147, loss 0.8218752145767212, acc=0.8138889074325562, loss=0.8218752145767212
train: epoch 148, loss 0.19986572861671448, acc=0.9227222204208374, loss=0.19986572861671448
test: epoch 148, loss 0.641680896282196, acc=0.8138889074325562, loss=0.641680896282196
train: epoch 149, loss 0.19862231612205505, acc=0.9254999756813049, loss=0.19862231612205505
test: epoch 149, loss 0.5920619368553162, acc=0.8138889074325562, loss=0.5920619368553162
train: epoch 150, loss 0.19020815193653107, acc=0.9258888959884644, loss=0.19020815193653107
test: epoch 150, loss 0.6135340332984924, acc=0.8111110925674438, loss=0.6135340332984924
