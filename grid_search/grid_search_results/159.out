# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=2.0", "--temp_decay=0.99", "--one_hot=false", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=518436925, receiver_embed_dim=128, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.7719407081604004, acc=0.1397777795791626, loss=2.7719407081604004
test: epoch 1, loss 2.740217447280884, acc=0.15833333134651184, loss=2.740217447280884
train: epoch 2, loss 1.441536545753479, acc=0.41422221064567566, loss=1.441536545753479
test: epoch 2, loss 2.7000885009765625, acc=0.18333333730697632, loss=2.7000885009765625
train: epoch 3, loss 1.1402517557144165, acc=0.5312222242355347, loss=1.1402517557144165
test: epoch 3, loss 2.4683966636657715, acc=0.21944443881511688, loss=2.4683966636657715
train: epoch 4, loss 0.9628570675849915, acc=0.612500011920929, loss=0.9628570675849915
test: epoch 4, loss 2.2378296852111816, acc=0.22499999403953552, loss=2.2378296852111816
train: epoch 5, loss 0.8501801490783691, acc=0.6600555777549744, loss=0.8501801490783691
test: epoch 5, loss 2.5214297771453857, acc=0.24444444477558136, loss=2.5214297771453857
train: epoch 6, loss 0.7597265839576721, acc=0.7012777924537659, loss=0.7597265839576721
test: epoch 6, loss 2.5092878341674805, acc=0.25555557012557983, loss=2.5092878341674805
train: epoch 7, loss 0.7008332014083862, acc=0.7262222170829773, loss=0.7008332014083862
test: epoch 7, loss 2.141785144805908, acc=0.2777777910232544, loss=2.141785144805908
train: epoch 8, loss 0.6426207423210144, acc=0.7509999871253967, loss=0.6426207423210144
test: epoch 8, loss 2.537174940109253, acc=0.24166665971279144, loss=2.537174940109253
train: epoch 9, loss 0.5982280969619751, acc=0.766777753829956, loss=0.5982280969619751
test: epoch 9, loss 2.1711812019348145, acc=0.25, loss=2.1711812019348145
train: epoch 10, loss 0.5723345875740051, acc=0.7819444537162781, loss=0.5723345875740051
test: epoch 10, loss 2.193981409072876, acc=0.28611111640930176, loss=2.193981409072876
train: epoch 11, loss 0.5482177138328552, acc=0.7924444675445557, loss=0.5482177138328552
test: epoch 11, loss 2.1418864727020264, acc=0.3083333373069763, loss=2.1418864727020264
train: epoch 12, loss 0.5104526877403259, acc=0.8070555329322815, loss=0.5104526877403259
test: epoch 12, loss 2.4250621795654297, acc=0.23888888955116272, loss=2.4250621795654297
train: epoch 13, loss 0.48144689202308655, acc=0.8211110830307007, loss=0.48144689202308655
test: epoch 13, loss 2.2800605297088623, acc=0.2666666805744171, loss=2.2800605297088623
train: epoch 14, loss 0.45897331833839417, acc=0.8286111354827881, loss=0.45897331833839417
test: epoch 14, loss 2.1741225719451904, acc=0.27222222089767456, loss=2.1741225719451904
train: epoch 15, loss 0.4521217942237854, acc=0.8328889012336731, loss=0.4521217942237854
test: epoch 15, loss 2.1797590255737305, acc=0.21666666865348816, loss=2.1797590255737305
train: epoch 16, loss 0.43835145235061646, acc=0.8402777910232544, loss=0.43835145235061646
test: epoch 16, loss 2.3562445640563965, acc=0.3194444477558136, loss=2.3562445640563965
train: epoch 17, loss 0.432079017162323, acc=0.8418889045715332, loss=0.432079017162323
test: epoch 17, loss 2.2685439586639404, acc=0.26944443583488464, loss=2.2685439586639404
train: epoch 18, loss 0.4096897840499878, acc=0.8493333458900452, loss=0.4096897840499878
test: epoch 18, loss 1.9818984270095825, acc=0.34166666865348816, loss=1.9818984270095825
train: epoch 19, loss 0.39135298132896423, acc=0.8560000061988831, loss=0.39135298132896423
test: epoch 19, loss 2.003000259399414, acc=0.375, loss=2.003000259399414
train: epoch 20, loss 0.3626764416694641, acc=0.8661666512489319, loss=0.3626764416694641
test: epoch 20, loss 2.327709674835205, acc=0.3305555582046509, loss=2.327709674835205
train: epoch 21, loss 0.37076395750045776, acc=0.8638888597488403, loss=0.37076395750045776
test: epoch 21, loss 2.1152021884918213, acc=0.30000001192092896, loss=2.1152021884918213
train: epoch 22, loss 0.36061519384384155, acc=0.8704444169998169, loss=0.36061519384384155
test: epoch 22, loss 1.9050685167312622, acc=0.3611111044883728, loss=1.9050685167312622
train: epoch 23, loss 0.33340513706207275, acc=0.8796111345291138, loss=0.33340513706207275
test: epoch 23, loss 1.9407894611358643, acc=0.3333333432674408, loss=1.9407894611358643
train: epoch 24, loss 0.3286210000514984, acc=0.8797777891159058, loss=0.3286210000514984
test: epoch 24, loss 1.7589569091796875, acc=0.43888887763023376, loss=1.7589569091796875
train: epoch 25, loss 0.31844234466552734, acc=0.8838333487510681, loss=0.31844234466552734
test: epoch 25, loss 1.8593825101852417, acc=0.4027777910232544, loss=1.8593825101852417
train: epoch 26, loss 0.29913756251335144, acc=0.8921666741371155, loss=0.29913756251335144
test: epoch 26, loss 1.9746782779693604, acc=0.45277777314186096, loss=1.9746782779693604
train: epoch 27, loss 0.3052999973297119, acc=0.8921666741371155, loss=0.3052999973297119
test: epoch 27, loss 1.774627685546875, acc=0.4277777671813965, loss=1.774627685546875
train: epoch 28, loss 0.2923997938632965, acc=0.8966110944747925, loss=0.2923997938632965
test: epoch 28, loss 1.8654578924179077, acc=0.42222222685813904, loss=1.8654578924179077
train: epoch 29, loss 0.2866227626800537, acc=0.8971666693687439, loss=0.2866227626800537
test: epoch 29, loss 1.8604313135147095, acc=0.4444444477558136, loss=1.8604313135147095
train: epoch 30, loss 0.2673838138580322, acc=0.9065555334091187, loss=0.2673838138580322
test: epoch 30, loss 1.73249089717865, acc=0.41111111640930176, loss=1.73249089717865
train: epoch 31, loss 0.2735302150249481, acc=0.9027222394943237, loss=0.2735302150249481
test: epoch 31, loss 1.8156794309616089, acc=0.4444444477558136, loss=1.8156794309616089
train: epoch 32, loss 0.25919216871261597, acc=0.9081110954284668, loss=0.25919216871261597
test: epoch 32, loss 1.8348450660705566, acc=0.4694444537162781, loss=1.8348450660705566
train: epoch 33, loss 0.24969382584095, acc=0.9091110825538635, loss=0.24969382584095
test: epoch 33, loss 1.8908461332321167, acc=0.49444442987442017, loss=1.8908461332321167
train: epoch 34, loss 0.2506624460220337, acc=0.910277783870697, loss=0.2506624460220337
test: epoch 34, loss 1.6572136878967285, acc=0.4277777671813965, loss=1.6572136878967285
train: epoch 35, loss 0.2555474042892456, acc=0.9126111268997192, loss=0.2555474042892456
test: epoch 35, loss 2.1546337604522705, acc=0.39444443583488464, loss=2.1546337604522705
train: epoch 36, loss 0.2452269047498703, acc=0.9152222275733948, loss=0.2452269047498703
test: epoch 36, loss 1.582543969154358, acc=0.5027777552604675, loss=1.582543969154358
train: epoch 37, loss 0.2330247312784195, acc=0.9181666374206543, loss=0.2330247312784195
test: epoch 37, loss 1.4199765920639038, acc=0.5277777910232544, loss=1.4199765920639038
train: epoch 38, loss 0.22437897324562073, acc=0.9241666793823242, loss=0.22437897324562073
test: epoch 38, loss 1.8628329038619995, acc=0.48055556416511536, loss=1.8628329038619995
train: epoch 39, loss 0.22316467761993408, acc=0.92166668176651, loss=0.22316467761993408
test: epoch 39, loss 1.7388187646865845, acc=0.5083333253860474, loss=1.7388187646865845
train: epoch 40, loss 0.2289256900548935, acc=0.921833336353302, loss=0.2289256900548935
test: epoch 40, loss 1.6790931224822998, acc=0.4694444537162781, loss=1.6790931224822998
train: epoch 41, loss 0.2144499570131302, acc=0.9267777800559998, loss=0.2144499570131302
test: epoch 41, loss 1.8604973554611206, acc=0.5027777552604675, loss=1.8604973554611206
train: epoch 42, loss 0.22784020006656647, acc=0.9252222180366516, loss=0.22784020006656647
test: epoch 42, loss 1.6842148303985596, acc=0.5111111402511597, loss=1.6842148303985596
train: epoch 43, loss 0.2145642638206482, acc=0.9264444708824158, loss=0.2145642638206482
test: epoch 43, loss 1.649578332901001, acc=0.5305555462837219, loss=1.649578332901001
train: epoch 44, loss 0.1999174803495407, acc=0.9330000281333923, loss=0.1999174803495407
test: epoch 44, loss 1.7867205142974854, acc=0.5249999761581421, loss=1.7867205142974854
train: epoch 45, loss 0.20038901269435883, acc=0.9328333139419556, loss=0.20038901269435883
test: epoch 45, loss 1.5030062198638916, acc=0.5833333134651184, loss=1.5030062198638916
train: epoch 46, loss 0.21133162081241608, acc=0.9303333163261414, loss=0.21133162081241608
test: epoch 46, loss 1.462156057357788, acc=0.5222222208976746, loss=1.462156057357788
train: epoch 47, loss 0.20081523060798645, acc=0.9332777857780457, loss=0.20081523060798645
test: epoch 47, loss 1.8423829078674316, acc=0.5666666626930237, loss=1.8423829078674316
train: epoch 48, loss 0.18768705427646637, acc=0.9354444742202759, loss=0.18768705427646637
test: epoch 48, loss 1.4920183420181274, acc=0.5555555820465088, loss=1.4920183420181274
train: epoch 49, loss 0.19703523814678192, acc=0.9350000023841858, loss=0.19703523814678192
test: epoch 49, loss 1.6243879795074463, acc=0.6000000238418579, loss=1.6243879795074463
train: epoch 50, loss 0.19054201245307922, acc=0.9357222318649292, loss=0.19054201245307922
test: epoch 50, loss 1.6952446699142456, acc=0.574999988079071, loss=1.6952446699142456
train: epoch 51, loss 0.1951715499162674, acc=0.9369444251060486, loss=0.1951715499162674
test: epoch 51, loss 1.4342442750930786, acc=0.6138888597488403, loss=1.4342442750930786
train: epoch 52, loss 0.1909673810005188, acc=0.937166690826416, loss=0.1909673810005188
test: epoch 52, loss 1.4423388242721558, acc=0.6027777791023254, loss=1.4423388242721558
train: epoch 53, loss 0.1898038536310196, acc=0.9375555515289307, loss=0.1898038536310196
test: epoch 53, loss 1.520896553993225, acc=0.6194444298744202, loss=1.520896553993225
train: epoch 54, loss 0.18137884140014648, acc=0.9415000081062317, loss=0.18137884140014648
test: epoch 54, loss 1.7876492738723755, acc=0.5666666626930237, loss=1.7876492738723755
train: epoch 55, loss 0.17966163158416748, acc=0.9429444670677185, loss=0.17966163158416748
test: epoch 55, loss 1.5091156959533691, acc=0.605555534362793, loss=1.5091156959533691
train: epoch 56, loss 0.18980368971824646, acc=0.9390555620193481, loss=0.18980368971824646
test: epoch 56, loss 1.3759886026382446, acc=0.605555534362793, loss=1.3759886026382446
train: epoch 57, loss 0.16507239639759064, acc=0.9482777714729309, loss=0.16507239639759064
test: epoch 57, loss 1.5507187843322754, acc=0.6111111044883728, loss=1.5507187843322754
train: epoch 58, loss 0.18289487063884735, acc=0.9406111240386963, loss=0.18289487063884735
test: epoch 58, loss 1.2959811687469482, acc=0.6499999761581421, loss=1.2959811687469482
train: epoch 59, loss 0.1795923411846161, acc=0.9421111345291138, loss=0.1795923411846161
test: epoch 59, loss 1.3436274528503418, acc=0.6472222208976746, loss=1.3436274528503418
train: epoch 60, loss 0.17340613901615143, acc=0.9452221989631653, loss=0.17340613901615143
test: epoch 60, loss 1.2251031398773193, acc=0.6472222208976746, loss=1.2251031398773193
train: epoch 61, loss 0.1741304248571396, acc=0.9444444179534912, loss=0.1741304248571396
test: epoch 61, loss 1.2264468669891357, acc=0.6555555462837219, loss=1.2264468669891357
train: epoch 62, loss 0.17349980771541595, acc=0.9452221989631653, loss=0.17349980771541595
test: epoch 62, loss 1.658732533454895, acc=0.6416666507720947, loss=1.658732533454895
train: epoch 63, loss 0.16301649808883667, acc=0.9466666579246521, loss=0.16301649808883667
test: epoch 63, loss 1.5410733222961426, acc=0.6388888955116272, loss=1.5410733222961426
train: epoch 64, loss 0.1808692067861557, acc=0.9462222456932068, loss=0.1808692067861557
test: epoch 64, loss 1.43363618850708, acc=0.5916666388511658, loss=1.43363618850708
train: epoch 65, loss 0.16001832485198975, acc=0.9502221941947937, loss=0.16001832485198975
test: epoch 65, loss 1.6252429485321045, acc=0.6305555701255798, loss=1.6252429485321045
train: epoch 66, loss 0.1723550260066986, acc=0.9471666812896729, loss=0.1723550260066986
test: epoch 66, loss 1.232017159461975, acc=0.675000011920929, loss=1.232017159461975
train: epoch 67, loss 0.16796614229679108, acc=0.9506111145019531, loss=0.16796614229679108
test: epoch 67, loss 1.311861515045166, acc=0.6472222208976746, loss=1.311861515045166
train: epoch 68, loss 0.16414418816566467, acc=0.949999988079071, loss=0.16414418816566467
test: epoch 68, loss 1.2199105024337769, acc=0.6805555820465088, loss=1.2199105024337769
train: epoch 69, loss 0.16584908962249756, acc=0.9499444365501404, loss=0.16584908962249756
test: epoch 69, loss 1.260146975517273, acc=0.6472222208976746, loss=1.260146975517273
train: epoch 70, loss 0.17252103984355927, acc=0.9519444704055786, loss=0.17252103984355927
test: epoch 70, loss 1.398350715637207, acc=0.6527777910232544, loss=1.398350715637207
train: epoch 71, loss 0.1524951010942459, acc=0.9532777667045593, loss=0.1524951010942459
test: epoch 71, loss 1.1627627611160278, acc=0.6916666626930237, loss=1.1627627611160278
train: epoch 72, loss 0.1559564173221588, acc=0.9525555372238159, loss=0.1559564173221588
test: epoch 72, loss 1.2447115182876587, acc=0.7222222089767456, loss=1.2447115182876587
train: epoch 73, loss 0.15014824271202087, acc=0.9556666612625122, loss=0.15014824271202087
test: epoch 73, loss 1.0862390995025635, acc=0.7111111283302307, loss=1.0862390995025635
train: epoch 74, loss 0.14817138016223907, acc=0.9549999833106995, loss=0.14817138016223907
test: epoch 74, loss 1.2719488143920898, acc=0.7111111283302307, loss=1.2719488143920898
train: epoch 75, loss 0.15307918190956116, acc=0.953000009059906, loss=0.15307918190956116
test: epoch 75, loss 0.9333336353302002, acc=0.7138888835906982, loss=0.9333336353302002
train: epoch 76, loss 0.15342314541339874, acc=0.9526110887527466, loss=0.15342314541339874
test: epoch 76, loss 1.132813572883606, acc=0.7416666746139526, loss=1.132813572883606
train: epoch 77, loss 0.14503632485866547, acc=0.9560555815696716, loss=0.14503632485866547
test: epoch 77, loss 0.9296296834945679, acc=0.7472222447395325, loss=0.9296296834945679
train: epoch 78, loss 0.14553050696849823, acc=0.9575555324554443, loss=0.14553050696849823
test: epoch 78, loss 1.0215671062469482, acc=0.7333333492279053, loss=1.0215671062469482
train: epoch 79, loss 0.1491188108921051, acc=0.9558333158493042, loss=0.1491188108921051
test: epoch 79, loss 1.083668828010559, acc=0.7222222089767456, loss=1.083668828010559
train: epoch 80, loss 0.14437146484851837, acc=0.9580555558204651, loss=0.14437146484851837
test: epoch 80, loss 0.9870542287826538, acc=0.75, loss=0.9870542287826538
train: epoch 81, loss 0.14353163540363312, acc=0.957611083984375, loss=0.14353163540363312
test: epoch 81, loss 0.8359311819076538, acc=0.7444444298744202, loss=0.8359311819076538
train: epoch 82, loss 0.1337287575006485, acc=0.9598333239555359, loss=0.1337287575006485
test: epoch 82, loss 1.04610276222229, acc=0.75, loss=1.04610276222229
train: epoch 83, loss 0.14094895124435425, acc=0.9570555686950684, loss=0.14094895124435425
test: epoch 83, loss 1.065338373184204, acc=0.7361111044883728, loss=1.065338373184204
train: epoch 84, loss 0.13428281247615814, acc=0.9591666460037231, loss=0.13428281247615814
test: epoch 84, loss 0.9150841236114502, acc=0.7638888955116272, loss=0.9150841236114502
train: epoch 85, loss 0.1338214874267578, acc=0.961555540561676, loss=0.1338214874267578
test: epoch 85, loss 0.988152027130127, acc=0.7361111044883728, loss=0.988152027130127
train: epoch 86, loss 0.1414293646812439, acc=0.9596666693687439, loss=0.1414293646812439
test: epoch 86, loss 0.8742614388465881, acc=0.7833333611488342, loss=0.8742614388465881
train: epoch 87, loss 0.13228586316108704, acc=0.9595000147819519, loss=0.13228586316108704
test: epoch 87, loss 0.7636216282844543, acc=0.769444465637207, loss=0.7636216282844543
train: epoch 88, loss 0.14019246399402618, acc=0.9589999914169312, loss=0.14019246399402618
test: epoch 88, loss 0.8803896903991699, acc=0.7722222208976746, loss=0.8803896903991699
train: epoch 89, loss 0.1364583522081375, acc=0.9581111073493958, loss=0.1364583522081375
test: epoch 89, loss 0.8065615296363831, acc=0.7805555462837219, loss=0.8065615296363831
train: epoch 90, loss 0.14186421036720276, acc=0.9579444527626038, loss=0.14186421036720276
test: epoch 90, loss 0.891771137714386, acc=0.769444465637207, loss=0.891771137714386
train: epoch 91, loss 0.13751284778118134, acc=0.9589444398880005, loss=0.13751284778118134
test: epoch 91, loss 0.7791683673858643, acc=0.7583333253860474, loss=0.7791683673858643
train: epoch 92, loss 0.1371728479862213, acc=0.9589444398880005, loss=0.1371728479862213
test: epoch 92, loss 0.8797689080238342, acc=0.7666666507720947, loss=0.8797689080238342
train: epoch 93, loss 0.14201566576957703, acc=0.9563888907432556, loss=0.14201566576957703
test: epoch 93, loss 0.8063129186630249, acc=0.7805555462837219, loss=0.8063129186630249
train: epoch 94, loss 0.13747720420360565, acc=0.9580000042915344, loss=0.13747720420360565
test: epoch 94, loss 0.8052101135253906, acc=0.7583333253860474, loss=0.8052101135253906
train: epoch 95, loss 0.13515828549861908, acc=0.9586666822433472, loss=0.13515828549861908
test: epoch 95, loss 0.7443218231201172, acc=0.7388888597488403, loss=0.7443218231201172
train: epoch 96, loss 0.1454058140516281, acc=0.9566666483879089, loss=0.1454058140516281
test: epoch 96, loss 0.7281084656715393, acc=0.7749999761581421, loss=0.7281084656715393
train: epoch 97, loss 0.13826382160186768, acc=0.957611083984375, loss=0.13826382160186768
test: epoch 97, loss 0.7767084836959839, acc=0.769444465637207, loss=0.7767084836959839
train: epoch 98, loss 0.1397688090801239, acc=0.9548888802528381, loss=0.1397688090801239
test: epoch 98, loss 0.858687162399292, acc=0.7666666507720947, loss=0.858687162399292
train: epoch 99, loss 0.1370885819196701, acc=0.9588333368301392, loss=0.1370885819196701
test: epoch 99, loss 0.732479989528656, acc=0.7722222208976746, loss=0.732479989528656
train: epoch 100, loss 0.14715631306171417, acc=0.9557777643203735, loss=0.14715631306171417
test: epoch 100, loss 0.8781569004058838, acc=0.7444444298744202, loss=0.8781569004058838
train: epoch 101, loss 0.1458708643913269, acc=0.9547777771949768, loss=0.1458708643913269
test: epoch 101, loss 0.9645864367485046, acc=0.7777777910232544, loss=0.9645864367485046
train: epoch 102, loss 0.14750653505325317, acc=0.9543889164924622, loss=0.14750653505325317
test: epoch 102, loss 0.8016856908798218, acc=0.7777777910232544, loss=0.8016856908798218
train: epoch 103, loss 0.13096584379673004, acc=0.9595555663108826, loss=0.13096584379673004
test: epoch 103, loss 0.8255123496055603, acc=0.7722222208976746, loss=0.8255123496055603
train: epoch 104, loss 0.13463354110717773, acc=0.9576666951179504, loss=0.13463354110717773
test: epoch 104, loss 0.8219132423400879, acc=0.7777777910232544, loss=0.8219132423400879
train: epoch 105, loss 0.13744129240512848, acc=0.957277774810791, loss=0.13744129240512848
test: epoch 105, loss 0.7754667401313782, acc=0.7833333611488342, loss=0.7754667401313782
train: epoch 106, loss 0.13366036117076874, acc=0.9578889012336731, loss=0.13366036117076874
test: epoch 106, loss 0.922768235206604, acc=0.7444444298744202, loss=0.922768235206604
train: epoch 107, loss 0.13518401980400085, acc=0.9586111307144165, loss=0.13518401980400085
test: epoch 107, loss 0.7773777842521667, acc=0.7722222208976746, loss=0.7773777842521667
train: epoch 108, loss 0.13598494231700897, acc=0.9601110816001892, loss=0.13598494231700897
test: epoch 108, loss 0.7583238482475281, acc=0.769444465637207, loss=0.7583238482475281
train: epoch 109, loss 0.1340165138244629, acc=0.9597222208976746, loss=0.1340165138244629
test: epoch 109, loss 0.7434374094009399, acc=0.7527777552604675, loss=0.7434374094009399
train: epoch 110, loss 0.12810242176055908, acc=0.9599999785423279, loss=0.12810242176055908
test: epoch 110, loss 0.8582227230072021, acc=0.769444465637207, loss=0.8582227230072021
train: epoch 111, loss 0.13307948410511017, acc=0.9576666951179504, loss=0.13307948410511017
test: epoch 111, loss 0.8630551099777222, acc=0.75, loss=0.8630551099777222
train: epoch 112, loss 0.12461448460817337, acc=0.9618889093399048, loss=0.12461448460817337
test: epoch 112, loss 0.8167707920074463, acc=0.730555534362793, loss=0.8167707920074463
train: epoch 113, loss 0.12835244834423065, acc=0.9616110920906067, loss=0.12835244834423065
test: epoch 113, loss 0.829616904258728, acc=0.769444465637207, loss=0.829616904258728
train: epoch 114, loss 0.12992772459983826, acc=0.960777759552002, loss=0.12992772459983826
test: epoch 114, loss 0.7440010905265808, acc=0.7722222208976746, loss=0.7440010905265808
train: epoch 115, loss 0.1302543431520462, acc=0.9583888649940491, loss=0.1302543431520462
test: epoch 115, loss 0.8589808940887451, acc=0.7638888955116272, loss=0.8589808940887451
train: epoch 116, loss 0.12540091574192047, acc=0.9610000252723694, loss=0.12540091574192047
test: epoch 116, loss 0.6231397390365601, acc=0.7666666507720947, loss=0.6231397390365601
train: epoch 117, loss 0.12473879754543304, acc=0.9629444479942322, loss=0.12473879754543304
test: epoch 117, loss 0.7813337445259094, acc=0.7722222208976746, loss=0.7813337445259094
train: epoch 118, loss 0.11433997750282288, acc=0.9660555720329285, loss=0.11433997750282288
test: epoch 118, loss 0.734233558177948, acc=0.7722222208976746, loss=0.734233558177948
train: epoch 119, loss 0.12783090770244598, acc=0.9614444375038147, loss=0.12783090770244598
test: epoch 119, loss 0.79109126329422, acc=0.7555555701255798, loss=0.79109126329422
train: epoch 120, loss 0.11838896572589874, acc=0.9641666412353516, loss=0.11838896572589874
test: epoch 120, loss 0.7654194235801697, acc=0.7638888955116272, loss=0.7654194235801697
train: epoch 121, loss 0.12249608337879181, acc=0.961388885974884, loss=0.12249608337879181
test: epoch 121, loss 0.8547378778457642, acc=0.7722222208976746, loss=0.8547378778457642
train: epoch 122, loss 0.11874990165233612, acc=0.9634444713592529, loss=0.11874990165233612
test: epoch 122, loss 0.814264714717865, acc=0.7666666507720947, loss=0.814264714717865
train: epoch 123, loss 0.12702804803848267, acc=0.9602222442626953, loss=0.12702804803848267
test: epoch 123, loss 0.6694206595420837, acc=0.7777777910232544, loss=0.6694206595420837
train: epoch 124, loss 0.12341121584177017, acc=0.9608888626098633, loss=0.12341121584177017
test: epoch 124, loss 0.7086026072502136, acc=0.7749999761581421, loss=0.7086026072502136
train: epoch 125, loss 0.11557622253894806, acc=0.9641110897064209, loss=0.11557622253894806
test: epoch 125, loss 0.8346152901649475, acc=0.7666666507720947, loss=0.8346152901649475
train: epoch 126, loss 0.12319068610668182, acc=0.9636111259460449, loss=0.12319068610668182
test: epoch 126, loss 0.6731081008911133, acc=0.7611111402511597, loss=0.6731081008911133
train: epoch 127, loss 0.11202730238437653, acc=0.9632222056388855, loss=0.11202730238437653
test: epoch 127, loss 0.6990372538566589, acc=0.769444465637207, loss=0.6990372538566589
train: epoch 128, loss 0.12183575332164764, acc=0.9622777700424194, loss=0.12183575332164764
test: epoch 128, loss 0.9049118161201477, acc=0.7722222208976746, loss=0.9049118161201477
train: epoch 129, loss 0.1227450743317604, acc=0.961555540561676, loss=0.1227450743317604
test: epoch 129, loss 0.8494380116462708, acc=0.7777777910232544, loss=0.8494380116462708
train: epoch 130, loss 0.12365332990884781, acc=0.9633333086967468, loss=0.12365332990884781
test: epoch 130, loss 0.8361115455627441, acc=0.7611111402511597, loss=0.8361115455627441
train: epoch 131, loss 0.12681803107261658, acc=0.9616110920906067, loss=0.12681803107261658
test: epoch 131, loss 0.883195161819458, acc=0.7638888955116272, loss=0.883195161819458
train: epoch 132, loss 0.12158356606960297, acc=0.9621666669845581, loss=0.12158356606960297
test: epoch 132, loss 0.6679967641830444, acc=0.7805555462837219, loss=0.6679967641830444
train: epoch 133, loss 0.12014343589544296, acc=0.9635555744171143, loss=0.12014343589544296
test: epoch 133, loss 0.8173850178718567, acc=0.7583333253860474, loss=0.8173850178718567
train: epoch 134, loss 0.12001490592956543, acc=0.9642221927642822, loss=0.12001490592956543
test: epoch 134, loss 0.7367376089096069, acc=0.769444465637207, loss=0.7367376089096069
train: epoch 135, loss 0.1192147433757782, acc=0.9624444246292114, loss=0.1192147433757782
test: epoch 135, loss 0.7224650979042053, acc=0.7722222208976746, loss=0.7224650979042053
train: epoch 136, loss 0.1097763329744339, acc=0.9666666388511658, loss=0.1097763329744339
test: epoch 136, loss 0.710468590259552, acc=0.7833333611488342, loss=0.710468590259552
train: epoch 137, loss 0.11674726009368896, acc=0.9633333086967468, loss=0.11674726009368896
test: epoch 137, loss 0.6552375555038452, acc=0.7805555462837219, loss=0.6552375555038452
train: epoch 138, loss 0.12108591943979263, acc=0.9623888731002808, loss=0.12108591943979263
test: epoch 138, loss 0.6722689270973206, acc=0.769444465637207, loss=0.6722689270973206
train: epoch 139, loss 0.11608418077230453, acc=0.965666651725769, loss=0.11608418077230453
test: epoch 139, loss 0.7609180212020874, acc=0.769444465637207, loss=0.7609180212020874
train: epoch 140, loss 0.11297386139631271, acc=0.9660000205039978, loss=0.11297386139631271
test: epoch 140, loss 0.8098439574241638, acc=0.7638888955116272, loss=0.8098439574241638
train: epoch 141, loss 0.11757545173168182, acc=0.9654444456100464, loss=0.11757545173168182
test: epoch 141, loss 0.7309268712997437, acc=0.7805555462837219, loss=0.7309268712997437
train: epoch 142, loss 0.11119922250509262, acc=0.9653888940811157, loss=0.11119922250509262
test: epoch 142, loss 0.8434098362922668, acc=0.7666666507720947, loss=0.8434098362922668
train: epoch 143, loss 0.11605561524629593, acc=0.964555561542511, loss=0.11605561524629593
test: epoch 143, loss 0.9369217157363892, acc=0.7611111402511597, loss=0.9369217157363892
train: epoch 144, loss 0.1112927719950676, acc=0.9664999842643738, loss=0.1112927719950676
test: epoch 144, loss 0.9143853187561035, acc=0.7527777552604675, loss=0.9143853187561035
train: epoch 145, loss 0.11078532040119171, acc=0.9646111130714417, loss=0.11078532040119171
test: epoch 145, loss 0.8157013058662415, acc=0.769444465637207, loss=0.8157013058662415
train: epoch 146, loss 0.11302459985017776, acc=0.965499997138977, loss=0.11302459985017776
test: epoch 146, loss 0.7181732058525085, acc=0.7749999761581421, loss=0.7181732058525085
train: epoch 147, loss 0.1280718445777893, acc=0.9622222185134888, loss=0.1280718445777893
test: epoch 147, loss 0.8161417245864868, acc=0.769444465637207, loss=0.8161417245864868
train: epoch 148, loss 0.10870058834552765, acc=0.9664444327354431, loss=0.10870058834552765
test: epoch 148, loss 0.7989098429679871, acc=0.7749999761581421, loss=0.7989098429679871
train: epoch 149, loss 0.10776139050722122, acc=0.9671111106872559, loss=0.10776139050722122
test: epoch 149, loss 0.7088223099708557, acc=0.7722222208976746, loss=0.7088223099708557
train: epoch 150, loss 0.10227120667695999, acc=0.9687777757644653, loss=0.10227120667695999
test: epoch 150, loss 0.7476028800010681, acc=0.7666666507720947, loss=0.7476028800010681
