# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=1", "--temp_decay=0.995", "--one_hot=true", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1918064402, receiver_embed_dim=128, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.361849784851074, acc=0.05000000074505806, loss=3.361849784851074
test: epoch 1, loss 2.8276619911193848, acc=0.10277777910232544, loss=2.8276619911193848
train: epoch 2, loss 2.212989568710327, acc=0.17505554854869843, loss=2.212989568710327
test: epoch 2, loss 2.3137195110321045, acc=0.1388888955116272, loss=2.3137195110321045
train: epoch 3, loss 1.8572638034820557, acc=0.2585555613040924, loss=1.8572638034820557
test: epoch 3, loss 2.4451332092285156, acc=0.15000000596046448, loss=2.4451332092285156
train: epoch 4, loss 1.6954878568649292, acc=0.308388888835907, loss=1.6954878568649292
test: epoch 4, loss 2.300220012664795, acc=0.16944444179534912, loss=2.300220012664795
train: epoch 5, loss 1.6239027976989746, acc=0.3352222144603729, loss=1.6239027976989746
test: epoch 5, loss 2.2732465267181396, acc=0.1666666716337204, loss=2.2732465267181396
train: epoch 6, loss 1.5622565746307373, acc=0.36116665601730347, loss=1.5622565746307373
test: epoch 6, loss 2.362562656402588, acc=0.1805555522441864, loss=2.362562656402588
train: epoch 7, loss 1.5211457014083862, acc=0.3819444477558136, loss=1.5211457014083862
test: epoch 7, loss 2.2971794605255127, acc=0.1805555522441864, loss=2.2971794605255127
train: epoch 8, loss 1.5075241327285767, acc=0.3880000114440918, loss=1.5075241327285767
test: epoch 8, loss 2.4049394130706787, acc=0.18611110746860504, loss=2.4049394130706787
train: epoch 9, loss 1.464067816734314, acc=0.4026666581630707, loss=1.464067816734314
test: epoch 9, loss 2.395237445831299, acc=0.18888889253139496, loss=2.395237445831299
train: epoch 10, loss 1.4328675270080566, acc=0.4116666615009308, loss=1.4328675270080566
test: epoch 10, loss 2.466331720352173, acc=0.1805555522441864, loss=2.466331720352173
train: epoch 11, loss 1.4234434366226196, acc=0.4167777895927429, loss=1.4234434366226196
test: epoch 11, loss 2.567106008529663, acc=0.18333333730697632, loss=2.567106008529663
train: epoch 12, loss 1.405515193939209, acc=0.42116665840148926, loss=1.405515193939209
test: epoch 12, loss 2.2269647121429443, acc=0.20277777314186096, loss=2.2269647121429443
train: epoch 13, loss 1.3821183443069458, acc=0.4262222349643707, loss=1.3821183443069458
test: epoch 13, loss 2.4031307697296143, acc=0.20277777314186096, loss=2.4031307697296143
train: epoch 14, loss 1.367851972579956, acc=0.4315555691719055, loss=1.367851972579956
test: epoch 14, loss 2.2223501205444336, acc=0.21666666865348816, loss=2.2223501205444336
train: epoch 15, loss 1.348573923110962, acc=0.44200000166893005, loss=1.348573923110962
test: epoch 15, loss 2.512221336364746, acc=0.1944444477558136, loss=2.512221336364746
train: epoch 16, loss 1.3430752754211426, acc=0.4431111216545105, loss=1.3430752754211426
test: epoch 16, loss 2.431838274002075, acc=0.20000000298023224, loss=2.431838274002075
train: epoch 17, loss 1.3273588418960571, acc=0.44733333587646484, loss=1.3273588418960571
test: epoch 17, loss 2.541578531265259, acc=0.21111111342906952, loss=2.541578531265259
train: epoch 18, loss 1.3092763423919678, acc=0.45355555415153503, loss=1.3092763423919678
test: epoch 18, loss 2.426628351211548, acc=0.19166666269302368, loss=2.426628351211548
train: epoch 19, loss 1.3105255365371704, acc=0.4491666555404663, loss=1.3105255365371704
test: epoch 19, loss 2.4593968391418457, acc=0.21666666865348816, loss=2.4593968391418457
train: epoch 20, loss 1.29586923122406, acc=0.4586111009120941, loss=1.29586923122406
test: epoch 20, loss 2.4286677837371826, acc=0.21944443881511688, loss=2.4286677837371826
train: epoch 21, loss 1.296755313873291, acc=0.4623333215713501, loss=1.296755313873291
test: epoch 21, loss 2.358151912689209, acc=0.21111111342906952, loss=2.358151912689209
train: epoch 22, loss 1.298559308052063, acc=0.45722222328186035, loss=1.298559308052063
test: epoch 22, loss 2.421603202819824, acc=0.21666666865348816, loss=2.421603202819824
train: epoch 23, loss 1.2697962522506714, acc=0.4658333361148834, loss=1.2697962522506714
test: epoch 23, loss 2.4104092121124268, acc=0.23055554926395416, loss=2.4104092121124268
train: epoch 24, loss 1.2773494720458984, acc=0.4682222306728363, loss=1.2773494720458984
test: epoch 24, loss 2.444058895111084, acc=0.22777777910232544, loss=2.444058895111084
train: epoch 25, loss 1.270764946937561, acc=0.4697222113609314, loss=1.270764946937561
test: epoch 25, loss 2.724076271057129, acc=0.2222222238779068, loss=2.724076271057129
train: epoch 26, loss 1.2590938806533813, acc=0.47138887643814087, loss=1.2590938806533813
test: epoch 26, loss 2.3302383422851562, acc=0.23333333432674408, loss=2.3302383422851562
train: epoch 27, loss 1.257805347442627, acc=0.47805556654930115, loss=1.257805347442627
test: epoch 27, loss 2.591564416885376, acc=0.2361111044883728, loss=2.591564416885376
train: epoch 28, loss 1.241971731185913, acc=0.48488888144493103, loss=1.241971731185913
test: epoch 28, loss 2.358157157897949, acc=0.2222222238779068, loss=2.358157157897949
train: epoch 29, loss 1.230884313583374, acc=0.4862777888774872, loss=1.230884313583374
test: epoch 29, loss 2.6205217838287354, acc=0.22777777910232544, loss=2.6205217838287354
train: epoch 30, loss 1.2273426055908203, acc=0.492166668176651, loss=1.2273426055908203
test: epoch 30, loss 2.7647387981414795, acc=0.22499999403953552, loss=2.7647387981414795
train: epoch 31, loss 1.2169601917266846, acc=0.4933333396911621, loss=1.2169601917266846
test: epoch 31, loss 2.5200061798095703, acc=0.24722221493721008, loss=2.5200061798095703
train: epoch 32, loss 1.2120234966278076, acc=0.4963333308696747, loss=1.2120234966278076
test: epoch 32, loss 2.492318868637085, acc=0.22777777910232544, loss=2.492318868637085
train: epoch 33, loss 1.1931464672088623, acc=0.5061110854148865, loss=1.1931464672088623
test: epoch 33, loss 2.2474470138549805, acc=0.2361111044883728, loss=2.2474470138549805
train: epoch 34, loss 1.1799737215042114, acc=0.5122222304344177, loss=1.1799737215042114
test: epoch 34, loss 2.241558313369751, acc=0.27222222089767456, loss=2.241558313369751
train: epoch 35, loss 1.1777523756027222, acc=0.5129444599151611, loss=1.1777523756027222
test: epoch 35, loss 2.358975887298584, acc=0.2750000059604645, loss=2.358975887298584
train: epoch 36, loss 1.1653040647506714, acc=0.5162777900695801, loss=1.1653040647506714
test: epoch 36, loss 2.394765853881836, acc=0.2666666805744171, loss=2.394765853881836
train: epoch 37, loss 1.158704400062561, acc=0.5278888940811157, loss=1.158704400062561
test: epoch 37, loss 2.588310718536377, acc=0.26944443583488464, loss=2.588310718536377
train: epoch 38, loss 1.1562113761901855, acc=0.5239999890327454, loss=1.1562113761901855
test: epoch 38, loss 2.3317348957061768, acc=0.2805555462837219, loss=2.3317348957061768
train: epoch 39, loss 1.145498275756836, acc=0.523722231388092, loss=1.145498275756836
test: epoch 39, loss 2.2843122482299805, acc=0.2777777910232544, loss=2.2843122482299805
train: epoch 40, loss 1.1359615325927734, acc=0.5377222299575806, loss=1.1359615325927734
test: epoch 40, loss 2.307462453842163, acc=0.2777777910232544, loss=2.307462453842163
train: epoch 41, loss 1.1382296085357666, acc=0.5302222371101379, loss=1.1382296085357666
test: epoch 41, loss 2.2257416248321533, acc=0.28333333134651184, loss=2.2257416248321533
train: epoch 42, loss 1.1346323490142822, acc=0.5334444642066956, loss=1.1346323490142822
test: epoch 42, loss 2.548971176147461, acc=0.27222222089767456, loss=2.548971176147461
train: epoch 43, loss 1.1213353872299194, acc=0.5378333330154419, loss=1.1213353872299194
test: epoch 43, loss 2.3447751998901367, acc=0.28611111640930176, loss=2.3447751998901367
train: epoch 44, loss 1.109071135520935, acc=0.5460000038146973, loss=1.109071135520935
test: epoch 44, loss 2.2794182300567627, acc=0.3027777671813965, loss=2.2794182300567627
train: epoch 45, loss 1.1087048053741455, acc=0.5397777557373047, loss=1.1087048053741455
test: epoch 45, loss 2.3920304775238037, acc=0.26944443583488464, loss=2.3920304775238037
train: epoch 46, loss 1.1159080266952515, acc=0.5446666479110718, loss=1.1159080266952515
test: epoch 46, loss 2.55497145652771, acc=0.2750000059604645, loss=2.55497145652771
train: epoch 47, loss 1.1096997261047363, acc=0.5426666736602783, loss=1.1096997261047363
test: epoch 47, loss 2.5853049755096436, acc=0.28611111640930176, loss=2.5853049755096436
train: epoch 48, loss 1.0900169610977173, acc=0.5519999861717224, loss=1.0900169610977173
test: epoch 48, loss 2.188581943511963, acc=0.2916666567325592, loss=2.188581943511963
train: epoch 49, loss 1.0868724584579468, acc=0.5462777614593506, loss=1.0868724584579468
test: epoch 49, loss 2.4863033294677734, acc=0.2888889014720917, loss=2.4863033294677734
train: epoch 50, loss 1.085124135017395, acc=0.5492222309112549, loss=1.085124135017395
test: epoch 50, loss 2.2715651988983154, acc=0.2944444417953491, loss=2.2715651988983154
train: epoch 51, loss 1.0767563581466675, acc=0.5475555658340454, loss=1.0767563581466675
test: epoch 51, loss 2.4484639167785645, acc=0.2888889014720917, loss=2.4484639167785645
train: epoch 52, loss 1.076744794845581, acc=0.5487777590751648, loss=1.076744794845581
test: epoch 52, loss 2.4833526611328125, acc=0.31111112236976624, loss=2.4833526611328125
train: epoch 53, loss 1.0953962802886963, acc=0.5471110939979553, loss=1.0953962802886963
test: epoch 53, loss 2.480419397354126, acc=0.28333333134651184, loss=2.480419397354126
train: epoch 54, loss 1.0760802030563354, acc=0.5516666769981384, loss=1.0760802030563354
test: epoch 54, loss 2.325247287750244, acc=0.3055555522441864, loss=2.325247287750244
train: epoch 55, loss 1.06879460811615, acc=0.5523889064788818, loss=1.06879460811615
test: epoch 55, loss 2.355557680130005, acc=0.29722222685813904, loss=2.355557680130005
train: epoch 56, loss 1.0839457511901855, acc=0.5487777590751648, loss=1.0839457511901855
test: epoch 56, loss 2.2413740158081055, acc=0.31388887763023376, loss=2.2413740158081055
train: epoch 57, loss 1.0606681108474731, acc=0.555388867855072, loss=1.0606681108474731
test: epoch 57, loss 2.3036956787109375, acc=0.31388887763023376, loss=2.3036956787109375
train: epoch 58, loss 1.0654230117797852, acc=0.5573889017105103, loss=1.0654230117797852
test: epoch 58, loss 2.471038818359375, acc=0.31388887763023376, loss=2.471038818359375
train: epoch 59, loss 1.076399803161621, acc=0.5503333210945129, loss=1.076399803161621
test: epoch 59, loss 2.6272900104522705, acc=0.31111112236976624, loss=2.6272900104522705
train: epoch 60, loss 1.0577328205108643, acc=0.5559444427490234, loss=1.0577328205108643
test: epoch 60, loss 2.5276355743408203, acc=0.3027777671813965, loss=2.5276355743408203
train: epoch 61, loss 1.054924488067627, acc=0.5587777495384216, loss=1.054924488067627
test: epoch 61, loss 2.2198662757873535, acc=0.3055555522441864, loss=2.2198662757873535
train: epoch 62, loss 1.0575473308563232, acc=0.5565555691719055, loss=1.0575473308563232
test: epoch 62, loss 2.57623028755188, acc=0.3083333373069763, loss=2.57623028755188
train: epoch 63, loss 1.0542716979980469, acc=0.5605000257492065, loss=1.0542716979980469
test: epoch 63, loss 2.2616944313049316, acc=0.3166666626930237, loss=2.2616944313049316
train: epoch 64, loss 1.0592284202575684, acc=0.554611086845398, loss=1.0592284202575684
test: epoch 64, loss 2.2854607105255127, acc=0.3166666626930237, loss=2.2854607105255127
train: epoch 65, loss 1.0428367853164673, acc=0.5633333325386047, loss=1.0428367853164673
test: epoch 65, loss 2.433992624282837, acc=0.31388887763023376, loss=2.433992624282837
train: epoch 66, loss 1.0358572006225586, acc=0.5643333196640015, loss=1.0358572006225586
test: epoch 66, loss 2.65568208694458, acc=0.3055555522441864, loss=2.65568208694458
train: epoch 67, loss 1.0385987758636475, acc=0.5665000081062317, loss=1.0385987758636475
test: epoch 67, loss 2.5699462890625, acc=0.32499998807907104, loss=2.5699462890625
train: epoch 68, loss 1.0364447832107544, acc=0.5722777843475342, loss=1.0364447832107544
test: epoch 68, loss 2.3305678367614746, acc=0.3222222328186035, loss=2.3305678367614746
train: epoch 69, loss 1.0316483974456787, acc=0.5717222094535828, loss=1.0316483974456787
test: epoch 69, loss 2.1572325229644775, acc=0.3194444477558136, loss=2.1572325229644775
train: epoch 70, loss 1.0439679622650146, acc=0.565833330154419, loss=1.0439679622650146
test: epoch 70, loss 2.2342369556427, acc=0.3027777671813965, loss=2.2342369556427
train: epoch 71, loss 1.0412683486938477, acc=0.5691111087799072, loss=1.0412683486938477
test: epoch 71, loss 2.538058280944824, acc=0.2944444417953491, loss=2.538058280944824
train: epoch 72, loss 1.0466243028640747, acc=0.5641666650772095, loss=1.0466243028640747
test: epoch 72, loss 2.1606853008270264, acc=0.3194444477558136, loss=2.1606853008270264
train: epoch 73, loss 1.026761770248413, acc=0.5734999775886536, loss=1.026761770248413
test: epoch 73, loss 2.257216691970825, acc=0.3194444477558136, loss=2.257216691970825
train: epoch 74, loss 1.0379582643508911, acc=0.570388913154602, loss=1.0379582643508911
test: epoch 74, loss 2.2640130519866943, acc=0.32499998807907104, loss=2.2640130519866943
train: epoch 75, loss 1.0310522317886353, acc=0.56977778673172, loss=1.0310522317886353
test: epoch 75, loss 2.3810184001922607, acc=0.3194444477558136, loss=2.3810184001922607
train: epoch 76, loss 1.0282012224197388, acc=0.5727777481079102, loss=1.0282012224197388
test: epoch 76, loss 2.673485040664673, acc=0.31388887763023376, loss=2.673485040664673
train: epoch 77, loss 1.0221457481384277, acc=0.5753333568572998, loss=1.0221457481384277
test: epoch 77, loss 2.338472604751587, acc=0.32499998807907104, loss=2.338472604751587
train: epoch 78, loss 1.0276923179626465, acc=0.573888897895813, loss=1.0276923179626465
test: epoch 78, loss 2.3855507373809814, acc=0.3305555582046509, loss=2.3855507373809814
train: epoch 79, loss 1.020341157913208, acc=0.5699999928474426, loss=1.020341157913208
test: epoch 79, loss 2.4726808071136475, acc=0.3305555582046509, loss=2.4726808071136475
train: epoch 80, loss 1.0198312997817993, acc=0.5765555500984192, loss=1.0198312997817993
test: epoch 80, loss 2.3362016677856445, acc=0.3305555582046509, loss=2.3362016677856445
train: epoch 81, loss 1.0169932842254639, acc=0.5723333358764648, loss=1.0169932842254639
test: epoch 81, loss 2.502561569213867, acc=0.3222222328186035, loss=2.502561569213867
train: epoch 82, loss 1.0107858180999756, acc=0.5771666765213013, loss=1.0107858180999756
test: epoch 82, loss 2.2333428859710693, acc=0.3305555582046509, loss=2.2333428859710693
train: epoch 83, loss 1.0264815092086792, acc=0.5694444179534912, loss=1.0264815092086792
test: epoch 83, loss 2.378736734390259, acc=0.3305555582046509, loss=2.378736734390259
train: epoch 84, loss 1.0150107145309448, acc=0.5753889083862305, loss=1.0150107145309448
test: epoch 84, loss 2.4740798473358154, acc=0.3305555582046509, loss=2.4740798473358154
train: epoch 85, loss 1.0245393514633179, acc=0.5704444646835327, loss=1.0245393514633179
test: epoch 85, loss 2.4322731494903564, acc=0.3305555582046509, loss=2.4322731494903564
train: epoch 86, loss 1.0013242959976196, acc=0.5793889164924622, loss=1.0013242959976196
test: epoch 86, loss 2.3981850147247314, acc=0.32499998807907104, loss=2.3981850147247314
train: epoch 87, loss 1.0130088329315186, acc=0.5744444727897644, loss=1.0130088329315186
test: epoch 87, loss 2.3322060108184814, acc=0.3305555582046509, loss=2.3322060108184814
train: epoch 88, loss 1.0125815868377686, acc=0.5762777924537659, loss=1.0125815868377686
test: epoch 88, loss 2.118762493133545, acc=0.3305555582046509, loss=2.118762493133545
train: epoch 89, loss 1.010062575340271, acc=0.5761666893959045, loss=1.010062575340271
test: epoch 89, loss 2.376410722732544, acc=0.3305555582046509, loss=2.376410722732544
train: epoch 90, loss 1.012985110282898, acc=0.570888876914978, loss=1.012985110282898
test: epoch 90, loss 2.364962100982666, acc=0.3305555582046509, loss=2.364962100982666
train: epoch 91, loss 1.0059261322021484, acc=0.5791110992431641, loss=1.0059261322021484
test: epoch 91, loss 2.2521400451660156, acc=0.3305555582046509, loss=2.2521400451660156
train: epoch 92, loss 1.006862759590149, acc=0.5791666507720947, loss=1.006862759590149
test: epoch 92, loss 2.1690542697906494, acc=0.3361110985279083, loss=2.1690542697906494
train: epoch 93, loss 0.9914737343788147, acc=0.5832222104072571, loss=0.9914737343788147
test: epoch 93, loss 2.1893880367279053, acc=0.3333333432674408, loss=2.1893880367279053
train: epoch 94, loss 1.0075608491897583, acc=0.5817777514457703, loss=1.0075608491897583
test: epoch 94, loss 2.3804287910461426, acc=0.3333333432674408, loss=2.3804287910461426
train: epoch 95, loss 0.9979389309883118, acc=0.5815555453300476, loss=0.9979389309883118
test: epoch 95, loss 2.3432188034057617, acc=0.3333333432674408, loss=2.3432188034057617
train: epoch 96, loss 1.0009914636611938, acc=0.5763888955116272, loss=1.0009914636611938
test: epoch 96, loss 2.2116312980651855, acc=0.3333333432674408, loss=2.2116312980651855
train: epoch 97, loss 1.0055681467056274, acc=0.5763333439826965, loss=1.0055681467056274
test: epoch 97, loss 2.528632879257202, acc=0.32777777314186096, loss=2.528632879257202
train: epoch 98, loss 1.0002102851867676, acc=0.5770555734634399, loss=1.0002102851867676
test: epoch 98, loss 2.3145980834960938, acc=0.33888888359069824, loss=2.3145980834960938
train: epoch 99, loss 1.0057017803192139, acc=0.5767777562141418, loss=1.0057017803192139
test: epoch 99, loss 2.3709683418273926, acc=0.34166666865348816, loss=2.3709683418273926
train: epoch 100, loss 1.005806803703308, acc=0.5812222361564636, loss=1.005806803703308
test: epoch 100, loss 2.384212017059326, acc=0.3444444537162781, loss=2.384212017059326
train: epoch 101, loss 1.0021535158157349, acc=0.578499972820282, loss=1.0021535158157349
test: epoch 101, loss 2.263620138168335, acc=0.3472222089767456, loss=2.263620138168335
train: epoch 102, loss 1.008512258529663, acc=0.5775555372238159, loss=1.008512258529663
test: epoch 102, loss 2.4446237087249756, acc=0.3472222089767456, loss=2.4446237087249756
train: epoch 103, loss 0.9950598478317261, acc=0.5733333230018616, loss=0.9950598478317261
test: epoch 103, loss 2.223691940307617, acc=0.3499999940395355, loss=2.223691940307617
train: epoch 104, loss 0.994560718536377, acc=0.5799444317817688, loss=0.994560718536377
test: epoch 104, loss 2.4785959720611572, acc=0.3472222089767456, loss=2.4785959720611572
train: epoch 105, loss 0.9965357780456543, acc=0.5747222304344177, loss=0.9965357780456543
test: epoch 105, loss 2.185603618621826, acc=0.3472222089767456, loss=2.185603618621826
train: epoch 106, loss 0.9854611754417419, acc=0.5832222104072571, loss=0.9854611754417419
test: epoch 106, loss 2.436779260635376, acc=0.3444444537162781, loss=2.436779260635376
train: epoch 107, loss 0.982032060623169, acc=0.581333339214325, loss=0.982032060623169
test: epoch 107, loss 2.4639337062835693, acc=0.3472222089767456, loss=2.4639337062835693
train: epoch 108, loss 0.9906164407730103, acc=0.5806666612625122, loss=0.9906164407730103
test: epoch 108, loss 2.3835151195526123, acc=0.3472222089767456, loss=2.3835151195526123
train: epoch 109, loss 0.9886569976806641, acc=0.5810555815696716, loss=0.9886569976806641
test: epoch 109, loss 2.3516337871551514, acc=0.34166666865348816, loss=2.3516337871551514
train: epoch 110, loss 0.9935053586959839, acc=0.5786111354827881, loss=0.9935053586959839
test: epoch 110, loss 2.434023141860962, acc=0.3472222089767456, loss=2.434023141860962
train: epoch 111, loss 0.9935596585273743, acc=0.5797777771949768, loss=0.9935596585273743
test: epoch 111, loss 2.4382224082946777, acc=0.3472222089767456, loss=2.4382224082946777
train: epoch 112, loss 0.9872616529464722, acc=0.5811111330986023, loss=0.9872616529464722
test: epoch 112, loss 2.3860225677490234, acc=0.3472222089767456, loss=2.3860225677490234
train: epoch 113, loss 0.9822913408279419, acc=0.5815555453300476, loss=0.9822913408279419
test: epoch 113, loss 2.387214183807373, acc=0.3444444537162781, loss=2.387214183807373
train: epoch 114, loss 0.9843704700469971, acc=0.5827777981758118, loss=0.9843704700469971
test: epoch 114, loss 2.423719882965088, acc=0.3472222089767456, loss=2.423719882965088
train: epoch 115, loss 0.9825831055641174, acc=0.5841666460037231, loss=0.9825831055641174
test: epoch 115, loss 2.421893358230591, acc=0.3472222089767456, loss=2.421893358230591
train: epoch 116, loss 0.9821325540542603, acc=0.5836666822433472, loss=0.9821325540542603
test: epoch 116, loss 2.2212717533111572, acc=0.3472222089767456, loss=2.2212717533111572
train: epoch 117, loss 0.9797446131706238, acc=0.586222231388092, loss=0.9797446131706238
test: epoch 117, loss 2.2131338119506836, acc=0.3472222089767456, loss=2.2131338119506836
train: epoch 118, loss 0.9898960590362549, acc=0.5839444398880005, loss=0.9898960590362549
test: epoch 118, loss 2.2901058197021484, acc=0.3499999940395355, loss=2.2901058197021484
train: epoch 119, loss 0.9616385102272034, acc=0.586555540561676, loss=0.9616385102272034
test: epoch 119, loss 2.3392651081085205, acc=0.3499999940395355, loss=2.3392651081085205
train: epoch 120, loss 0.9736566543579102, acc=0.5845000147819519, loss=0.9736566543579102
test: epoch 120, loss 2.205040216445923, acc=0.3499999940395355, loss=2.205040216445923
train: epoch 121, loss 0.9859688878059387, acc=0.5808333158493042, loss=0.9859688878059387
test: epoch 121, loss 2.1816208362579346, acc=0.3499999940395355, loss=2.1816208362579346
train: epoch 122, loss 0.9760903120040894, acc=0.5820000171661377, loss=0.9760903120040894
test: epoch 122, loss 2.572465658187866, acc=0.3499999940395355, loss=2.572465658187866
train: epoch 123, loss 0.9718109965324402, acc=0.5901111364364624, loss=0.9718109965324402
test: epoch 123, loss 2.1663453578948975, acc=0.3444444537162781, loss=2.1663453578948975
train: epoch 124, loss 0.972653865814209, acc=0.5876666903495789, loss=0.972653865814209
test: epoch 124, loss 2.5083141326904297, acc=0.3499999940395355, loss=2.5083141326904297
train: epoch 125, loss 0.9751706123352051, acc=0.5811111330986023, loss=0.9751706123352051
test: epoch 125, loss 2.3008251190185547, acc=0.3499999940395355, loss=2.3008251190185547
train: epoch 126, loss 0.9806962013244629, acc=0.5808888673782349, loss=0.9806962013244629
test: epoch 126, loss 2.3418824672698975, acc=0.3499999940395355, loss=2.3418824672698975
train: epoch 127, loss 0.9699439406394958, acc=0.5849444270133972, loss=0.9699439406394958
test: epoch 127, loss 2.3260700702667236, acc=0.3499999940395355, loss=2.3260700702667236
train: epoch 128, loss 0.9627140164375305, acc=0.5871666669845581, loss=0.9627140164375305
test: epoch 128, loss 2.1138052940368652, acc=0.3499999940395355, loss=2.1138052940368652
train: epoch 129, loss 0.9828364849090576, acc=0.586722195148468, loss=0.9828364849090576
test: epoch 129, loss 2.261554002761841, acc=0.3499999940395355, loss=2.261554002761841
train: epoch 130, loss 0.9648981094360352, acc=0.5898333191871643, loss=0.9648981094360352
test: epoch 130, loss 2.265907049179077, acc=0.3444444537162781, loss=2.265907049179077
train: epoch 131, loss 0.9713645577430725, acc=0.5858888626098633, loss=0.9713645577430725
test: epoch 131, loss 2.2460036277770996, acc=0.3499999940395355, loss=2.2460036277770996
train: epoch 132, loss 0.9780023097991943, acc=0.5845000147819519, loss=0.9780023097991943
test: epoch 132, loss 2.4277594089508057, acc=0.3499999940395355, loss=2.4277594089508057
train: epoch 133, loss 0.9766486883163452, acc=0.5841666460037231, loss=0.9766486883163452
test: epoch 133, loss 2.42376971244812, acc=0.3499999940395355, loss=2.42376971244812
train: epoch 134, loss 0.9700060486793518, acc=0.5803333520889282, loss=0.9700060486793518
test: epoch 134, loss 2.448801279067993, acc=0.3499999940395355, loss=2.448801279067993
train: epoch 135, loss 0.9635939002037048, acc=0.5889444351196289, loss=0.9635939002037048
test: epoch 135, loss 2.195646286010742, acc=0.3499999940395355, loss=2.195646286010742
train: epoch 136, loss 0.9770072102546692, acc=0.5833888649940491, loss=0.9770072102546692
test: epoch 136, loss 2.1309614181518555, acc=0.3499999940395355, loss=2.1309614181518555
train: epoch 137, loss 0.9619184136390686, acc=0.5847777724266052, loss=0.9619184136390686
test: epoch 137, loss 2.167130708694458, acc=0.3444444537162781, loss=2.167130708694458
train: epoch 138, loss 0.9760950803756714, acc=0.5814999938011169, loss=0.9760950803756714
test: epoch 138, loss 2.107980966567993, acc=0.3472222089767456, loss=2.107980966567993
train: epoch 139, loss 0.9564951658248901, acc=0.5923333168029785, loss=0.9564951658248901
test: epoch 139, loss 2.5841434001922607, acc=0.3444444537162781, loss=2.5841434001922607
train: epoch 140, loss 0.9673299789428711, acc=0.5864444375038147, loss=0.9673299789428711
test: epoch 140, loss 2.4304449558258057, acc=0.3444444537162781, loss=2.4304449558258057
train: epoch 141, loss 0.9680277109146118, acc=0.5839999914169312, loss=0.9680277109146118
test: epoch 141, loss 2.2707176208496094, acc=0.34166666865348816, loss=2.2707176208496094
train: epoch 142, loss 0.9658070802688599, acc=0.5870555639266968, loss=0.9658070802688599
test: epoch 142, loss 2.6118478775024414, acc=0.3499999940395355, loss=2.6118478775024414
train: epoch 143, loss 0.9643694758415222, acc=0.5910555720329285, loss=0.9643694758415222
test: epoch 143, loss 2.3360562324523926, acc=0.3499999940395355, loss=2.3360562324523926
train: epoch 144, loss 0.9762865304946899, acc=0.5863333344459534, loss=0.9762865304946899
test: epoch 144, loss 2.1439895629882812, acc=0.3499999940395355, loss=2.1439895629882812
train: epoch 145, loss 0.9607858657836914, acc=0.5914444327354431, loss=0.9607858657836914
test: epoch 145, loss 2.3292717933654785, acc=0.3499999940395355, loss=2.3292717933654785
train: epoch 146, loss 0.9622848629951477, acc=0.5900555849075317, loss=0.9622848629951477
test: epoch 146, loss 2.299298048019409, acc=0.3499999940395355, loss=2.299298048019409
train: epoch 147, loss 0.9559037089347839, acc=0.5893333554267883, loss=0.9559037089347839
test: epoch 147, loss 2.60866117477417, acc=0.3499999940395355, loss=2.60866117477417
train: epoch 148, loss 0.960006058216095, acc=0.590833306312561, loss=0.960006058216095
test: epoch 148, loss 2.378366231918335, acc=0.3444444537162781, loss=2.378366231918335
train: epoch 149, loss 0.954902172088623, acc=0.5908889174461365, loss=0.954902172088623
test: epoch 149, loss 2.287370204925537, acc=0.3472222089767456, loss=2.287370204925537
train: epoch 150, loss 0.9620534181594849, acc=0.5891110897064209, loss=0.9620534181594849
test: epoch 150, loss 2.311955213546753, acc=0.3499999940395355, loss=2.311955213546753
