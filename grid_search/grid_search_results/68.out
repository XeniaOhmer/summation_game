# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=1", "--temp_decay=0.99", "--one_hot=true", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=70749709, receiver_embed_dim=64, temp_decay=0.99, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.0447134971618652, acc=0.07088889181613922, loss=3.0447134971618652
test: epoch 1, loss 2.5158987045288086, acc=0.13333334028720856, loss=2.5158987045288086
train: epoch 2, loss 2.1306512355804443, acc=0.18511110544204712, loss=2.1306512355804443
test: epoch 2, loss 2.0930850505828857, acc=0.1944444477558136, loss=2.0930850505828857
train: epoch 3, loss 1.7238647937774658, acc=0.2771666646003723, loss=1.7238647937774658
test: epoch 3, loss 1.6959459781646729, acc=0.2777777910232544, loss=1.6959459781646729
train: epoch 4, loss 1.4916870594024658, acc=0.3564999997615814, loss=1.4916870594024658
test: epoch 4, loss 1.626587152481079, acc=0.2805555462837219, loss=1.626587152481079
train: epoch 5, loss 1.2793563604354858, acc=0.43211111426353455, loss=1.2793563604354858
test: epoch 5, loss 1.4018516540527344, acc=0.3361110985279083, loss=1.4018516540527344
train: epoch 6, loss 1.1594141721725464, acc=0.4775555431842804, loss=1.1594141721725464
test: epoch 6, loss 1.2094779014587402, acc=0.4277777671813965, loss=1.2094779014587402
train: epoch 7, loss 1.0411920547485352, acc=0.5404999852180481, loss=1.0411920547485352
test: epoch 7, loss 1.2996445894241333, acc=0.4305555522441864, loss=1.2996445894241333
train: epoch 8, loss 0.9736883640289307, acc=0.5699999928474426, loss=0.9736883640289307
test: epoch 8, loss 1.2702574729919434, acc=0.43611112236976624, loss=1.2702574729919434
train: epoch 9, loss 0.9448939561843872, acc=0.574222207069397, loss=0.9448939561843872
test: epoch 9, loss 1.2697612047195435, acc=0.42500001192092896, loss=1.2697612047195435
train: epoch 10, loss 0.9167160987854004, acc=0.5897777676582336, loss=0.9167160987854004
test: epoch 10, loss 1.4133927822113037, acc=0.4055555462837219, loss=1.4133927822113037
train: epoch 11, loss 0.9109825491905212, acc=0.5993888974189758, loss=0.9109825491905212
test: epoch 11, loss 1.4782541990280151, acc=0.43888887763023376, loss=1.4782541990280151
train: epoch 12, loss 0.873413622379303, acc=0.6098889112472534, loss=0.873413622379303
test: epoch 12, loss 1.1991949081420898, acc=0.4472222328186035, loss=1.1991949081420898
train: epoch 13, loss 0.878461480140686, acc=0.6118888854980469, loss=0.878461480140686
test: epoch 13, loss 1.2932592630386353, acc=0.46388888359069824, loss=1.2932592630386353
train: epoch 14, loss 0.8557953238487244, acc=0.6179999709129333, loss=0.8557953238487244
test: epoch 14, loss 1.1791892051696777, acc=0.4583333432674408, loss=1.1791892051696777
train: epoch 15, loss 0.8561449646949768, acc=0.6219444274902344, loss=0.8561449646949768
test: epoch 15, loss 1.1605253219604492, acc=0.4888888895511627, loss=1.1605253219604492
train: epoch 16, loss 0.8283537030220032, acc=0.6301110982894897, loss=0.8283537030220032
test: epoch 16, loss 1.2689064741134644, acc=0.4583333432674408, loss=1.2689064741134644
train: epoch 17, loss 0.8147966861724854, acc=0.6345000267028809, loss=0.8147966861724854
test: epoch 17, loss 1.1381691694259644, acc=0.49166667461395264, loss=1.1381691694259644
train: epoch 18, loss 0.8194780349731445, acc=0.6338889002799988, loss=0.8194780349731445
test: epoch 18, loss 1.1053398847579956, acc=0.47777777910232544, loss=1.1053398847579956
train: epoch 19, loss 0.8233266472816467, acc=0.6227222084999084, loss=0.8233266472816467
test: epoch 19, loss 1.1743413209915161, acc=0.49166667461395264, loss=1.1743413209915161
train: epoch 20, loss 0.8234850168228149, acc=0.6205000281333923, loss=0.8234850168228149
test: epoch 20, loss 1.1863939762115479, acc=0.49444442987442017, loss=1.1863939762115479
train: epoch 21, loss 0.8217668533325195, acc=0.6282222270965576, loss=0.8217668533325195
test: epoch 21, loss 1.163427472114563, acc=0.49444442987442017, loss=1.163427472114563
train: epoch 22, loss 0.8073786497116089, acc=0.6386666893959045, loss=0.8073786497116089
test: epoch 22, loss 1.0837527513504028, acc=0.49166667461395264, loss=1.0837527513504028
train: epoch 23, loss 0.8110240697860718, acc=0.6371111273765564, loss=0.8110240697860718
test: epoch 23, loss 1.190220832824707, acc=0.4861111044883728, loss=1.190220832824707
train: epoch 24, loss 0.8239477872848511, acc=0.6218888759613037, loss=0.8239477872848511
test: epoch 24, loss 1.1634351015090942, acc=0.49166667461395264, loss=1.1634351015090942
train: epoch 25, loss 0.8074231743812561, acc=0.6331111192703247, loss=0.8074231743812561
test: epoch 25, loss 1.1263858079910278, acc=0.4888888895511627, loss=1.1263858079910278
train: epoch 26, loss 0.8295432925224304, acc=0.6304444670677185, loss=0.8295432925224304
test: epoch 26, loss 1.134544014930725, acc=0.49166667461395264, loss=1.134544014930725
train: epoch 27, loss 0.8278738856315613, acc=0.6248888969421387, loss=0.8278738856315613
test: epoch 27, loss 1.1454336643218994, acc=0.4833333194255829, loss=1.1454336643218994
train: epoch 28, loss 0.8074257373809814, acc=0.6175000071525574, loss=0.8074257373809814
test: epoch 28, loss 1.0628666877746582, acc=0.49444442987442017, loss=1.0628666877746582
train: epoch 29, loss 0.8142668604850769, acc=0.6176666617393494, loss=0.8142668604850769
test: epoch 29, loss 1.1286189556121826, acc=0.4888888895511627, loss=1.1286189556121826
train: epoch 30, loss 0.8201920986175537, acc=0.6200000047683716, loss=0.8201920986175537
test: epoch 30, loss 1.1017768383026123, acc=0.49444442987442017, loss=1.1017768383026123
train: epoch 31, loss 0.8131541013717651, acc=0.6234444379806519, loss=0.8131541013717651
test: epoch 31, loss 1.1939263343811035, acc=0.49444442987442017, loss=1.1939263343811035
train: epoch 32, loss 0.8023903369903564, acc=0.6314444541931152, loss=0.8023903369903564
test: epoch 32, loss 1.1698676347732544, acc=0.49444442987442017, loss=1.1698676347732544
train: epoch 33, loss 0.8109941482543945, acc=0.6266111135482788, loss=0.8109941482543945
test: epoch 33, loss 1.141867995262146, acc=0.49444442987442017, loss=1.141867995262146
train: epoch 34, loss 0.8178643584251404, acc=0.6154999732971191, loss=0.8178643584251404
test: epoch 34, loss 1.1267611980438232, acc=0.4861111044883728, loss=1.1267611980438232
train: epoch 35, loss 0.8321002125740051, acc=0.6162777543067932, loss=0.8321002125740051
test: epoch 35, loss 1.1990504264831543, acc=0.49444442987442017, loss=1.1990504264831543
train: epoch 36, loss 0.8196690678596497, acc=0.6221110820770264, loss=0.8196690678596497
test: epoch 36, loss 1.0262682437896729, acc=0.49444442987442017, loss=1.0262682437896729
train: epoch 37, loss 0.8172679543495178, acc=0.6176666617393494, loss=0.8172679543495178
test: epoch 37, loss 1.0978114604949951, acc=0.49444442987442017, loss=1.0978114604949951
train: epoch 38, loss 0.8111386895179749, acc=0.6263889074325562, loss=0.8111386895179749
test: epoch 38, loss 1.1312289237976074, acc=0.49166667461395264, loss=1.1312289237976074
train: epoch 39, loss 0.791266918182373, acc=0.6339444518089294, loss=0.791266918182373
test: epoch 39, loss 1.2243750095367432, acc=0.4833333194255829, loss=1.2243750095367432
train: epoch 40, loss 0.7838631272315979, acc=0.6267777681350708, loss=0.7838631272315979
test: epoch 40, loss 1.0975215435028076, acc=0.49444442987442017, loss=1.0975215435028076
train: epoch 41, loss 0.7996896505355835, acc=0.628777801990509, loss=0.7996896505355835
test: epoch 41, loss 1.1064915657043457, acc=0.49444442987442017, loss=1.1064915657043457
train: epoch 42, loss 0.7996976375579834, acc=0.6294999718666077, loss=0.7996976375579834
test: epoch 42, loss 1.3085672855377197, acc=0.47777777910232544, loss=1.3085672855377197
train: epoch 43, loss 0.8177948594093323, acc=0.6205000281333923, loss=0.8177948594093323
test: epoch 43, loss 1.257435917854309, acc=0.49444442987442017, loss=1.257435917854309
train: epoch 44, loss 0.7885262370109558, acc=0.6388888955116272, loss=0.7885262370109558
test: epoch 44, loss 1.0923535823822021, acc=0.49166667461395264, loss=1.0923535823822021
train: epoch 45, loss 0.7821417450904846, acc=0.6392777562141418, loss=0.7821417450904846
test: epoch 45, loss 1.158575177192688, acc=0.49166667461395264, loss=1.158575177192688
train: epoch 46, loss 0.7846431136131287, acc=0.636388897895813, loss=0.7846431136131287
test: epoch 46, loss 1.173842191696167, acc=0.49166667461395264, loss=1.173842191696167
train: epoch 47, loss 0.7622218728065491, acc=0.6467221975326538, loss=0.7622218728065491
test: epoch 47, loss 1.3444302082061768, acc=0.49166667461395264, loss=1.3444302082061768
train: epoch 48, loss 0.7856557369232178, acc=0.637666642665863, loss=0.7856557369232178
test: epoch 48, loss 1.1325292587280273, acc=0.4972222149372101, loss=1.1325292587280273
train: epoch 49, loss 0.7449619770050049, acc=0.6553888916969299, loss=0.7449619770050049
test: epoch 49, loss 1.069419026374817, acc=0.5277777910232544, loss=1.069419026374817
train: epoch 50, loss 0.7370715141296387, acc=0.6621666550636292, loss=0.7370715141296387
test: epoch 50, loss 1.1112208366394043, acc=0.5305555462837219, loss=1.1112208366394043
train: epoch 51, loss 0.7466568350791931, acc=0.6581666469573975, loss=0.7466568350791931
test: epoch 51, loss 1.0215001106262207, acc=0.5277777910232544, loss=1.0215001106262207
train: epoch 52, loss 0.7157754302024841, acc=0.6683333516120911, loss=0.7157754302024841
test: epoch 52, loss 1.1039525270462036, acc=0.5222222208976746, loss=1.1039525270462036
train: epoch 53, loss 0.6874889731407166, acc=0.6859444379806519, loss=0.6874889731407166
test: epoch 53, loss 1.1234261989593506, acc=0.5305555462837219, loss=1.1234261989593506
train: epoch 54, loss 0.6746336221694946, acc=0.6944444179534912, loss=0.6746336221694946
test: epoch 54, loss 1.206470012664795, acc=0.5111111402511597, loss=1.206470012664795
train: epoch 55, loss 0.6812612414360046, acc=0.6928889155387878, loss=0.6812612414360046
test: epoch 55, loss 1.1426661014556885, acc=0.5166666507720947, loss=1.1426661014556885
train: epoch 56, loss 0.6690319776535034, acc=0.7024999856948853, loss=0.6690319776535034
test: epoch 56, loss 1.2828236818313599, acc=0.5305555462837219, loss=1.2828236818313599
train: epoch 57, loss 0.6563473343849182, acc=0.7052222490310669, loss=0.6563473343849182
test: epoch 57, loss 1.187806248664856, acc=0.5249999761581421, loss=1.187806248664856
train: epoch 58, loss 0.6609297394752502, acc=0.7047777771949768, loss=0.6609297394752502
test: epoch 58, loss 1.0944374799728394, acc=0.5333333611488342, loss=1.0944374799728394
train: epoch 59, loss 0.6500521302223206, acc=0.7075555324554443, loss=0.6500521302223206
test: epoch 59, loss 1.1487170457839966, acc=0.5333333611488342, loss=1.1487170457839966
train: epoch 60, loss 0.6478342413902283, acc=0.7062777876853943, loss=0.6478342413902283
test: epoch 60, loss 1.1564756631851196, acc=0.5277777910232544, loss=1.1564756631851196
train: epoch 61, loss 0.64899742603302, acc=0.7086111307144165, loss=0.64899742603302
test: epoch 61, loss 1.1824283599853516, acc=0.5277777910232544, loss=1.1824283599853516
train: epoch 62, loss 0.6467880606651306, acc=0.706166684627533, loss=0.6467880606651306
test: epoch 62, loss 1.1500946283340454, acc=0.5305555462837219, loss=1.1500946283340454
train: epoch 63, loss 0.6293362975120544, acc=0.7176111340522766, loss=0.6293362975120544
test: epoch 63, loss 1.215078592300415, acc=0.5333333611488342, loss=1.215078592300415
train: epoch 64, loss 0.6561439633369446, acc=0.7057777643203735, loss=0.6561439633369446
test: epoch 64, loss 1.2360117435455322, acc=0.5222222208976746, loss=1.2360117435455322
train: epoch 65, loss 0.6374018788337708, acc=0.7132222056388855, loss=0.6374018788337708
test: epoch 65, loss 1.067102074623108, acc=0.5305555462837219, loss=1.067102074623108
train: epoch 66, loss 0.6290735602378845, acc=0.7178888916969299, loss=0.6290735602378845
test: epoch 66, loss 1.1431353092193604, acc=0.5333333611488342, loss=1.1431353092193604
train: epoch 67, loss 0.6381451487541199, acc=0.7125555276870728, loss=0.6381451487541199
test: epoch 67, loss 1.1410248279571533, acc=0.5305555462837219, loss=1.1410248279571533
train: epoch 68, loss 0.651180624961853, acc=0.7064999938011169, loss=0.651180624961853
test: epoch 68, loss 1.1133742332458496, acc=0.5277777910232544, loss=1.1133742332458496
train: epoch 69, loss 0.6372259259223938, acc=0.7135000228881836, loss=0.6372259259223938
test: epoch 69, loss 1.1259406805038452, acc=0.5333333611488342, loss=1.1259406805038452
train: epoch 70, loss 0.620017945766449, acc=0.7190555334091187, loss=0.620017945766449
test: epoch 70, loss 1.1827664375305176, acc=0.5333333611488342, loss=1.1827664375305176
train: epoch 71, loss 0.6317918300628662, acc=0.715666651725769, loss=0.6317918300628662
test: epoch 71, loss 1.2645004987716675, acc=0.5305555462837219, loss=1.2645004987716675
train: epoch 72, loss 0.64463871717453, acc=0.7150555849075317, loss=0.64463871717453
test: epoch 72, loss 1.1596819162368774, acc=0.5305555462837219, loss=1.1596819162368774
train: epoch 73, loss 0.6175565719604492, acc=0.7245000004768372, loss=0.6175565719604492
test: epoch 73, loss 1.104594349861145, acc=0.5472221970558167, loss=1.104594349861145
train: epoch 74, loss 0.6292881369590759, acc=0.7202222347259521, loss=0.6292881369590759
test: epoch 74, loss 1.2338509559631348, acc=0.4861111044883728, loss=1.2338509559631348
train: epoch 75, loss 0.6619669795036316, acc=0.7067777514457703, loss=0.6619669795036316
test: epoch 75, loss 1.1159350872039795, acc=0.5333333611488342, loss=1.1159350872039795
train: epoch 76, loss 0.6279744505882263, acc=0.7179999947547913, loss=0.6279744505882263
test: epoch 76, loss 1.1252295970916748, acc=0.5527777671813965, loss=1.1252295970916748
train: epoch 77, loss 0.5987555384635925, acc=0.7306666374206543, loss=0.5987555384635925
test: epoch 77, loss 1.1209444999694824, acc=0.5388888716697693, loss=1.1209444999694824
train: epoch 78, loss 0.6234260201454163, acc=0.7219444513320923, loss=0.6234260201454163
test: epoch 78, loss 1.1887801885604858, acc=0.5388888716697693, loss=1.1887801885604858
train: epoch 79, loss 0.6431576013565063, acc=0.7146111130714417, loss=0.6431576013565063
test: epoch 79, loss 1.0761610269546509, acc=0.5527777671813965, loss=1.0761610269546509
train: epoch 80, loss 0.6271336674690247, acc=0.7191110849380493, loss=0.6271336674690247
test: epoch 80, loss 1.1378540992736816, acc=0.5472221970558167, loss=1.1378540992736816
train: epoch 81, loss 0.6363707780838013, acc=0.7208333611488342, loss=0.6363707780838013
test: epoch 81, loss 1.1704964637756348, acc=0.550000011920929, loss=1.1704964637756348
train: epoch 82, loss 0.6277302503585815, acc=0.7202222347259521, loss=0.6277302503585815
test: epoch 82, loss 1.1156132221221924, acc=0.5555555820465088, loss=1.1156132221221924
train: epoch 83, loss 0.6220616102218628, acc=0.7229999899864197, loss=0.6220616102218628
test: epoch 83, loss 1.0803871154785156, acc=0.550000011920929, loss=1.0803871154785156
train: epoch 84, loss 0.6035335063934326, acc=0.7281110882759094, loss=0.6035335063934326
test: epoch 84, loss 1.1139873266220093, acc=0.5555555820465088, loss=1.1139873266220093
train: epoch 85, loss 0.6181827187538147, acc=0.7254999876022339, loss=0.6181827187538147
test: epoch 85, loss 1.0485860109329224, acc=0.5611110925674438, loss=1.0485860109329224
train: epoch 86, loss 0.6203340291976929, acc=0.7260000109672546, loss=0.6203340291976929
test: epoch 86, loss 1.0541329383850098, acc=0.5555555820465088, loss=1.0541329383850098
train: epoch 87, loss 0.5919560194015503, acc=0.7335555553436279, loss=0.5919560194015503
test: epoch 87, loss 1.2539050579071045, acc=0.5555555820465088, loss=1.2539050579071045
train: epoch 88, loss 0.5849530100822449, acc=0.7354444265365601, loss=0.5849530100822449
test: epoch 88, loss 1.0846164226531982, acc=0.5777778029441833, loss=1.0846164226531982
train: epoch 89, loss 0.5932159423828125, acc=0.7321110963821411, loss=0.5932159423828125
test: epoch 89, loss 1.0591691732406616, acc=0.5722222328186035, loss=1.0591691732406616
train: epoch 90, loss 0.5910497903823853, acc=0.7291111350059509, loss=0.5910497903823853
test: epoch 90, loss 1.0266740322113037, acc=0.5916666388511658, loss=1.0266740322113037
train: epoch 91, loss 0.6054121255874634, acc=0.7291111350059509, loss=0.6054121255874634
test: epoch 91, loss 0.976463258266449, acc=0.5916666388511658, loss=0.976463258266449
train: epoch 92, loss 0.5844101309776306, acc=0.7372778058052063, loss=0.5844101309776306
test: epoch 92, loss 1.143930435180664, acc=0.5555555820465088, loss=1.143930435180664
train: epoch 93, loss 0.5825594067573547, acc=0.734333336353302, loss=0.5825594067573547
test: epoch 93, loss 1.004658579826355, acc=0.5916666388511658, loss=1.004658579826355
train: epoch 94, loss 0.5899618864059448, acc=0.7326666712760925, loss=0.5899618864059448
test: epoch 94, loss 1.0494129657745361, acc=0.5916666388511658, loss=1.0494129657745361
train: epoch 95, loss 0.5802724361419678, acc=0.7363333106040955, loss=0.5802724361419678
test: epoch 95, loss 1.055783987045288, acc=0.5916666388511658, loss=1.055783987045288
train: epoch 96, loss 0.6287892460823059, acc=0.7237777709960938, loss=0.6287892460823059
test: epoch 96, loss 1.0770143270492554, acc=0.5805555582046509, loss=1.0770143270492554
train: epoch 97, loss 0.6285274624824524, acc=0.7219444513320923, loss=0.6285274624824524
test: epoch 97, loss 1.0326793193817139, acc=0.5805555582046509, loss=1.0326793193817139
train: epoch 98, loss 0.6097884178161621, acc=0.7273333072662354, loss=0.6097884178161621
test: epoch 98, loss 1.14994215965271, acc=0.5777778029441833, loss=1.14994215965271
train: epoch 99, loss 0.6060032248497009, acc=0.7285555601119995, loss=0.6060032248497009
test: epoch 99, loss 1.0622681379318237, acc=0.5888888835906982, loss=1.0622681379318237
train: epoch 100, loss 0.6278978586196899, acc=0.7238333225250244, loss=0.6278978586196899
test: epoch 100, loss 1.143668532371521, acc=0.5611110925674438, loss=1.143668532371521
train: epoch 101, loss 0.587746262550354, acc=0.7287222146987915, loss=0.587746262550354
test: epoch 101, loss 1.1092272996902466, acc=0.5916666388511658, loss=1.1092272996902466
train: epoch 102, loss 0.5748072862625122, acc=0.7351111173629761, loss=0.5748072862625122
test: epoch 102, loss 1.0707300901412964, acc=0.5833333134651184, loss=1.0707300901412964
train: epoch 103, loss 0.5578490495681763, acc=0.7432222366333008, loss=0.5578490495681763
test: epoch 103, loss 1.1287527084350586, acc=0.5888888835906982, loss=1.1287527084350586
train: epoch 104, loss 0.582168459892273, acc=0.7390555739402771, loss=0.582168459892273
test: epoch 104, loss 1.0950284004211426, acc=0.5805555582046509, loss=1.0950284004211426
train: epoch 105, loss 0.5717613697052002, acc=0.7394999861717224, loss=0.5717613697052002
test: epoch 105, loss 1.1506348848342896, acc=0.5777778029441833, loss=1.1506348848342896
train: epoch 106, loss 0.5829771757125854, acc=0.7361666560173035, loss=0.5829771757125854
test: epoch 106, loss 1.1122897863388062, acc=0.5888888835906982, loss=1.1122897863388062
train: epoch 107, loss 0.5849447846412659, acc=0.738611102104187, loss=0.5849447846412659
test: epoch 107, loss 1.1350960731506348, acc=0.5805555582046509, loss=1.1350960731506348
train: epoch 108, loss 0.5514851212501526, acc=0.7447222471237183, loss=0.5514851212501526
test: epoch 108, loss 1.1310925483703613, acc=0.5861111283302307, loss=1.1310925483703613
train: epoch 109, loss 0.5732170939445496, acc=0.7375555634498596, loss=0.5732170939445496
test: epoch 109, loss 1.025306224822998, acc=0.5861111283302307, loss=1.025306224822998
train: epoch 110, loss 0.5530983805656433, acc=0.7432222366333008, loss=0.5530983805656433
test: epoch 110, loss 1.1222392320632935, acc=0.5805555582046509, loss=1.1222392320632935
train: epoch 111, loss 0.5936297178268433, acc=0.7432222366333008, loss=0.5936297178268433
test: epoch 111, loss 1.0227864980697632, acc=0.5888888835906982, loss=1.0227864980697632
train: epoch 112, loss 0.5629861950874329, acc=0.7486666440963745, loss=0.5629861950874329
test: epoch 112, loss 1.1893526315689087, acc=0.5861111283302307, loss=1.1893526315689087
train: epoch 113, loss 0.5696273446083069, acc=0.7483888864517212, loss=0.5696273446083069
test: epoch 113, loss 1.142387866973877, acc=0.5861111283302307, loss=1.142387866973877
train: epoch 114, loss 0.5547950267791748, acc=0.7507777810096741, loss=0.5547950267791748
test: epoch 114, loss 1.1876474618911743, acc=0.5861111283302307, loss=1.1876474618911743
train: epoch 115, loss 0.5515321493148804, acc=0.7513889074325562, loss=0.5515321493148804
test: epoch 115, loss 1.0828571319580078, acc=0.5861111283302307, loss=1.0828571319580078
train: epoch 116, loss 0.5524170994758606, acc=0.7528889179229736, loss=0.5524170994758606
test: epoch 116, loss 1.163140058517456, acc=0.5583333373069763, loss=1.163140058517456
train: epoch 117, loss 0.5804212093353271, acc=0.7413333058357239, loss=0.5804212093353271
test: epoch 117, loss 1.2180986404418945, acc=0.5805555582046509, loss=1.2180986404418945
train: epoch 118, loss 0.6166458129882812, acc=0.737666666507721, loss=0.6166458129882812
test: epoch 118, loss 1.142687201499939, acc=0.5916666388511658, loss=1.142687201499939
train: epoch 119, loss 0.6403025388717651, acc=0.7333333492279053, loss=0.6403025388717651
test: epoch 119, loss 1.0185623168945312, acc=0.6027777791023254, loss=1.0185623168945312
train: epoch 120, loss 0.5343512296676636, acc=0.7649444341659546, loss=0.5343512296676636
test: epoch 120, loss 1.1539297103881836, acc=0.5805555582046509, loss=1.1539297103881836
train: epoch 121, loss 0.5962486863136292, acc=0.7500555515289307, loss=0.5962486863136292
test: epoch 121, loss 0.9787923693656921, acc=0.6138888597488403, loss=0.9787923693656921
train: epoch 122, loss 0.5298724174499512, acc=0.7672777771949768, loss=0.5298724174499512
test: epoch 122, loss 0.9931945204734802, acc=0.6166666746139526, loss=0.9931945204734802
train: epoch 123, loss 0.5135137438774109, acc=0.7653889060020447, loss=0.5135137438774109
test: epoch 123, loss 1.1133875846862793, acc=0.6166666746139526, loss=1.1133875846862793
train: epoch 124, loss 0.5678671598434448, acc=0.7597222328186035, loss=0.5678671598434448
test: epoch 124, loss 1.0337499380111694, acc=0.5944444537162781, loss=1.0337499380111694
train: epoch 125, loss 0.5452553629875183, acc=0.7592222094535828, loss=0.5452553629875183
test: epoch 125, loss 1.0749491453170776, acc=0.6083333492279053, loss=1.0749491453170776
train: epoch 126, loss 0.5666757822036743, acc=0.7595000267028809, loss=0.5666757822036743
test: epoch 126, loss 1.1330456733703613, acc=0.605555534362793, loss=1.1330456733703613
train: epoch 127, loss 0.5843955278396606, acc=0.7486110925674438, loss=0.5843955278396606
test: epoch 127, loss 0.9405243396759033, acc=0.6111111044883728, loss=0.9405243396759033
train: epoch 128, loss 0.5443515777587891, acc=0.7618333101272583, loss=0.5443515777587891
test: epoch 128, loss 1.021310806274414, acc=0.6111111044883728, loss=1.021310806274414
train: epoch 129, loss 0.5241432189941406, acc=0.7727222442626953, loss=0.5241432189941406
test: epoch 129, loss 0.9431067109107971, acc=0.605555534362793, loss=0.9431067109107971
train: epoch 130, loss 0.5543127655982971, acc=0.7609444260597229, loss=0.5543127655982971
test: epoch 130, loss 1.083107590675354, acc=0.605555534362793, loss=1.083107590675354
train: epoch 131, loss 0.511527419090271, acc=0.7734444737434387, loss=0.511527419090271
test: epoch 131, loss 1.0301319360733032, acc=0.6194444298744202, loss=1.0301319360733032
train: epoch 132, loss 0.5167360901832581, acc=0.7734444737434387, loss=0.5167360901832581
test: epoch 132, loss 1.1303677558898926, acc=0.6222222447395325, loss=1.1303677558898926
train: epoch 133, loss 0.5156808495521545, acc=0.7735555768013, loss=0.5156808495521545
test: epoch 133, loss 1.0489449501037598, acc=0.6222222447395325, loss=1.0489449501037598
train: epoch 134, loss 0.5018102526664734, acc=0.777055561542511, loss=0.5018102526664734
test: epoch 134, loss 1.0266039371490479, acc=0.6305555701255798, loss=1.0266039371490479
train: epoch 135, loss 0.4890649616718292, acc=0.7823333144187927, loss=0.4890649616718292
test: epoch 135, loss 1.0502434968948364, acc=0.6277777552604675, loss=1.0502434968948364
train: epoch 136, loss 0.48557496070861816, acc=0.7822777628898621, loss=0.48557496070861816
test: epoch 136, loss 0.9301198720932007, acc=0.625, loss=0.9301198720932007
train: epoch 137, loss 0.47140660881996155, acc=0.785444438457489, loss=0.47140660881996155
test: epoch 137, loss 0.9933298230171204, acc=0.6305555701255798, loss=0.9933298230171204
train: epoch 138, loss 0.48315566778182983, acc=0.7827222347259521, loss=0.48315566778182983
test: epoch 138, loss 1.0250704288482666, acc=0.6194444298744202, loss=1.0250704288482666
train: epoch 139, loss 0.48949676752090454, acc=0.7794444561004639, loss=0.48949676752090454
test: epoch 139, loss 0.9909775257110596, acc=0.6472222208976746, loss=0.9909775257110596
train: epoch 140, loss 0.47948044538497925, acc=0.7973889112472534, loss=0.47948044538497925
test: epoch 140, loss 0.9764950275421143, acc=0.6666666865348816, loss=0.9764950275421143
train: epoch 141, loss 0.45003435015678406, acc=0.8190000057220459, loss=0.45003435015678406
test: epoch 141, loss 0.9365482926368713, acc=0.6694444417953491, loss=0.9365482926368713
train: epoch 142, loss 0.40425822138786316, acc=0.8248888850212097, loss=0.40425822138786316
test: epoch 142, loss 1.0158140659332275, acc=0.6722221970558167, loss=1.0158140659332275
train: epoch 143, loss 0.3960740864276886, acc=0.8268333077430725, loss=0.3960740864276886
test: epoch 143, loss 0.9587056636810303, acc=0.6694444417953491, loss=0.9587056636810303
train: epoch 144, loss 0.4052104353904724, acc=0.8271666765213013, loss=0.4052104353904724
test: epoch 144, loss 0.9671365022659302, acc=0.6722221970558167, loss=0.9671365022659302
train: epoch 145, loss 0.4098460078239441, acc=0.8276110887527466, loss=0.4098460078239441
test: epoch 145, loss 0.9597731232643127, acc=0.6722221970558167, loss=0.9597731232643127
train: epoch 146, loss 0.3948739767074585, acc=0.8293889164924622, loss=0.3948739767074585
test: epoch 146, loss 0.9881166219711304, acc=0.6694444417953491, loss=0.9881166219711304
train: epoch 147, loss 0.4867149889469147, acc=0.8025555610656738, loss=0.4867149889469147
test: epoch 147, loss 1.0267690420150757, acc=0.6666666865348816, loss=1.0267690420150757
train: epoch 148, loss 0.4224371016025543, acc=0.8183333277702332, loss=0.4224371016025543
test: epoch 148, loss 0.9036597609519958, acc=0.6694444417953491, loss=0.9036597609519958
train: epoch 149, loss 0.39501264691352844, acc=0.8270000219345093, loss=0.39501264691352844
test: epoch 149, loss 1.0111385583877563, acc=0.6777777671813965, loss=1.0111385583877563
train: epoch 150, loss 0.43815988302230835, acc=0.8186110854148865, loss=0.43815988302230835
test: epoch 150, loss 0.9565112590789795, acc=0.6611111164093018, loss=0.9565112590789795
