# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.99", "--one_hot=true", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=787336155, receiver_embed_dim=64, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.7959349155426025, acc=0.092777781188488, loss=2.7959349155426025
test: epoch 1, loss 3.0743632316589355, acc=0.07500000298023224, loss=3.0743632316589355
train: epoch 2, loss 1.8763302564620972, acc=0.2222222238779068, loss=1.8763302564620972
test: epoch 2, loss 2.516571521759033, acc=0.18333333730697632, loss=2.516571521759033
train: epoch 3, loss 1.523266315460205, acc=0.3086666762828827, loss=1.523266315460205
test: epoch 3, loss 2.8452630043029785, acc=0.21388888359069824, loss=2.8452630043029785
train: epoch 4, loss 1.2701475620269775, acc=0.39750000834465027, loss=1.2701475620269775
test: epoch 4, loss 2.237283945083618, acc=0.2527777850627899, loss=2.237283945083618
train: epoch 5, loss 1.1146931648254395, acc=0.4776666760444641, loss=1.1146931648254395
test: epoch 5, loss 2.588315486907959, acc=0.2777777910232544, loss=2.588315486907959
train: epoch 6, loss 1.0155643224716187, acc=0.5217221975326538, loss=1.0155643224716187
test: epoch 6, loss 2.137159824371338, acc=0.3194444477558136, loss=2.137159824371338
train: epoch 7, loss 0.9325957298278809, acc=0.5642222166061401, loss=0.9325957298278809
test: epoch 7, loss 2.2442753314971924, acc=0.30000001192092896, loss=2.2442753314971924
train: epoch 8, loss 0.835712730884552, acc=0.6242222189903259, loss=0.835712730884552
test: epoch 8, loss 1.8603663444519043, acc=0.3583333194255829, loss=1.8603663444519043
train: epoch 9, loss 0.7734352350234985, acc=0.6534444689750671, loss=0.7734352350234985
test: epoch 9, loss 1.918981671333313, acc=0.3638888895511627, loss=1.918981671333313
train: epoch 10, loss 0.7335575819015503, acc=0.6736111044883728, loss=0.7335575819015503
test: epoch 10, loss 1.5425916910171509, acc=0.39722222089767456, loss=1.5425916910171509
train: epoch 11, loss 0.6888092756271362, acc=0.7023888826370239, loss=0.6888092756271362
test: epoch 11, loss 1.7180925607681274, acc=0.4000000059604645, loss=1.7180925607681274
train: epoch 12, loss 0.6677826642990112, acc=0.7073333263397217, loss=0.6677826642990112
test: epoch 12, loss 1.6530954837799072, acc=0.3888888955116272, loss=1.6530954837799072
train: epoch 13, loss 0.5915701985359192, acc=0.7407777905464172, loss=0.5915701985359192
test: epoch 13, loss 1.630686640739441, acc=0.4444444477558136, loss=1.630686640739441
train: epoch 14, loss 0.6181442737579346, acc=0.7333889007568359, loss=0.6181442737579346
test: epoch 14, loss 1.6557282209396362, acc=0.4166666567325592, loss=1.6557282209396362
train: epoch 15, loss 0.5465636253356934, acc=0.7654444575309753, loss=0.5465636253356934
test: epoch 15, loss 1.7243571281433105, acc=0.4305555522441864, loss=1.7243571281433105
train: epoch 16, loss 0.5001605749130249, acc=0.7872777581214905, loss=0.5001605749130249
test: epoch 16, loss 2.2288260459899902, acc=0.3722222149372101, loss=2.2288260459899902
train: epoch 17, loss 0.458760529756546, acc=0.8063333630561829, loss=0.458760529756546
test: epoch 17, loss 2.037933826446533, acc=0.4472222328186035, loss=2.037933826446533
train: epoch 18, loss 0.41028356552124023, acc=0.8277778029441833, loss=0.41028356552124023
test: epoch 18, loss 1.910309910774231, acc=0.4833333194255829, loss=1.910309910774231
train: epoch 19, loss 0.3850058615207672, acc=0.8330000042915344, loss=0.3850058615207672
test: epoch 19, loss 1.6649301052093506, acc=0.5249999761581421, loss=1.6649301052093506
train: epoch 20, loss 0.3682060241699219, acc=0.8459444642066956, loss=0.3682060241699219
test: epoch 20, loss 1.568772792816162, acc=0.5833333134651184, loss=1.568772792816162
train: epoch 21, loss 0.3363610804080963, acc=0.8556666374206543, loss=0.3363610804080963
test: epoch 21, loss 1.2085800170898438, acc=0.5833333134651184, loss=1.2085800170898438
train: epoch 22, loss 0.3407883048057556, acc=0.8542777895927429, loss=0.3407883048057556
test: epoch 22, loss 0.894112765789032, acc=0.605555534362793, loss=0.894112765789032
train: epoch 23, loss 0.31291574239730835, acc=0.8623889088630676, loss=0.31291574239730835
test: epoch 23, loss 0.9768497943878174, acc=0.6527777910232544, loss=0.9768497943878174
train: epoch 24, loss 0.3148852586746216, acc=0.8601666688919067, loss=0.3148852586746216
test: epoch 24, loss 0.9407582879066467, acc=0.6944444179534912, loss=0.9407582879066467
train: epoch 25, loss 0.3091844916343689, acc=0.8628333210945129, loss=0.3091844916343689
test: epoch 25, loss 0.9237381815910339, acc=0.6833333373069763, loss=0.9237381815910339
train: epoch 26, loss 0.27852389216423035, acc=0.8732777833938599, loss=0.27852389216423035
test: epoch 26, loss 0.9750953316688538, acc=0.6305555701255798, loss=0.9750953316688538
train: epoch 27, loss 0.2771451473236084, acc=0.8738333582878113, loss=0.2771451473236084
test: epoch 27, loss 0.7795359492301941, acc=0.7749999761581421, loss=0.7795359492301941
train: epoch 28, loss 0.2700217366218567, acc=0.8786666393280029, loss=0.2700217366218567
test: epoch 28, loss 0.5936556458473206, acc=0.7444444298744202, loss=0.5936556458473206
train: epoch 29, loss 0.2435741275548935, acc=0.899055540561676, loss=0.2435741275548935
test: epoch 29, loss 0.6071453094482422, acc=0.7083333134651184, loss=0.6071453094482422
train: epoch 30, loss 0.22405469417572021, acc=0.906499981880188, loss=0.22405469417572021
test: epoch 30, loss 0.8073912262916565, acc=0.7666666507720947, loss=0.8073912262916565
train: epoch 31, loss 0.2196737378835678, acc=0.9056110978126526, loss=0.2196737378835678
test: epoch 31, loss 0.6994739174842834, acc=0.7583333253860474, loss=0.6994739174842834
train: epoch 32, loss 0.21705035865306854, acc=0.9062777757644653, loss=0.21705035865306854
test: epoch 32, loss 0.4848939776420593, acc=0.8361111283302307, loss=0.4848939776420593
train: epoch 33, loss 0.19092945754528046, acc=0.9146111011505127, loss=0.19092945754528046
test: epoch 33, loss 0.6699110865592957, acc=0.7944444417953491, loss=0.6699110865592957
train: epoch 34, loss 0.20232054591178894, acc=0.9114999771118164, loss=0.20232054591178894
test: epoch 34, loss 0.4515675902366638, acc=0.8416666388511658, loss=0.4515675902366638
train: epoch 35, loss 0.20142033696174622, acc=0.9146111011505127, loss=0.20142033696174622
test: epoch 35, loss 0.39563852548599243, acc=0.875, loss=0.39563852548599243
train: epoch 36, loss 0.21412873268127441, acc=0.9108889102935791, loss=0.21412873268127441
test: epoch 36, loss 0.37446117401123047, acc=0.8777777552604675, loss=0.37446117401123047
train: epoch 37, loss 0.19213084876537323, acc=0.9153333306312561, loss=0.19213084876537323
test: epoch 37, loss 0.3460865318775177, acc=0.855555534362793, loss=0.3460865318775177
train: epoch 38, loss 0.19533149898052216, acc=0.9109444618225098, loss=0.19533149898052216
test: epoch 38, loss 0.3266867995262146, acc=0.8777777552604675, loss=0.3266867995262146
train: epoch 39, loss 0.17916543781757355, acc=0.9164444208145142, loss=0.17916543781757355
test: epoch 39, loss 0.30535292625427246, acc=0.8777777552604675, loss=0.30535292625427246
train: epoch 40, loss 0.19394604861736298, acc=0.913777768611908, loss=0.19394604861736298
test: epoch 40, loss 0.5839658379554749, acc=0.8472222089767456, loss=0.5839658379554749
train: epoch 41, loss 0.19186224043369293, acc=0.9118888974189758, loss=0.19186224043369293
test: epoch 41, loss 0.3761776387691498, acc=0.8777777552604675, loss=0.3761776387691498
train: epoch 42, loss 0.2084369659423828, acc=0.9089999794960022, loss=0.2084369659423828
test: epoch 42, loss 0.35406190156936646, acc=0.875, loss=0.35406190156936646
train: epoch 43, loss 0.1623544543981552, acc=0.921999990940094, loss=0.1623544543981552
test: epoch 43, loss 0.34657227993011475, acc=0.875, loss=0.34657227993011475
train: epoch 44, loss 0.18898440897464752, acc=0.9155555367469788, loss=0.18898440897464752
test: epoch 44, loss 0.38876521587371826, acc=0.875, loss=0.38876521587371826
train: epoch 45, loss 0.17429345846176147, acc=0.9217222332954407, loss=0.17429345846176147
test: epoch 45, loss 0.4238818883895874, acc=0.8666666746139526, loss=0.4238818883895874
train: epoch 46, loss 0.1653919667005539, acc=0.9268333315849304, loss=0.1653919667005539
test: epoch 46, loss 0.32159438729286194, acc=0.8777777552604675, loss=0.32159438729286194
train: epoch 47, loss 0.18499067425727844, acc=0.9201111197471619, loss=0.18499067425727844
test: epoch 47, loss 0.41157376766204834, acc=0.875, loss=0.41157376766204834
train: epoch 48, loss 0.16132964193820953, acc=0.9265000224113464, loss=0.16132964193820953
test: epoch 48, loss 0.32384517788887024, acc=0.8805555701255798, loss=0.32384517788887024
train: epoch 49, loss 0.16540923714637756, acc=0.9242777824401855, loss=0.16540923714637756
test: epoch 49, loss 0.35733962059020996, acc=0.8777777552604675, loss=0.35733962059020996
train: epoch 50, loss 0.166773721575737, acc=0.9239444732666016, loss=0.166773721575737
test: epoch 50, loss 0.34276890754699707, acc=0.8777777552604675, loss=0.34276890754699707
train: epoch 51, loss 0.22133006155490875, acc=0.9157778024673462, loss=0.22133006155490875
test: epoch 51, loss 0.2569887936115265, acc=0.8805555701255798, loss=0.2569887936115265
train: epoch 52, loss 0.16937145590782166, acc=0.9280555844306946, loss=0.16937145590782166
test: epoch 52, loss 0.3309548795223236, acc=0.8805555701255798, loss=0.3309548795223236
train: epoch 53, loss 0.18088674545288086, acc=0.9258888959884644, loss=0.18088674545288086
test: epoch 53, loss 0.4787220060825348, acc=0.8722222447395325, loss=0.4787220060825348
train: epoch 54, loss 0.15591181814670563, acc=0.9284999966621399, loss=0.15591181814670563
test: epoch 54, loss 0.2726996839046478, acc=0.8833333253860474, loss=0.2726996839046478
train: epoch 55, loss 0.18462778627872467, acc=0.9218888878822327, loss=0.18462778627872467
test: epoch 55, loss 0.29690682888031006, acc=0.8833333253860474, loss=0.29690682888031006
train: epoch 56, loss 0.1485619693994522, acc=0.9306111335754395, loss=0.1485619693994522
test: epoch 56, loss 0.32136270403862, acc=0.8777777552604675, loss=0.32136270403862
train: epoch 57, loss 0.16387620568275452, acc=0.9282777905464172, loss=0.16387620568275452
test: epoch 57, loss 0.36441105604171753, acc=0.8833333253860474, loss=0.36441105604171753
train: epoch 58, loss 0.1505294144153595, acc=0.9287777543067932, loss=0.1505294144153595
test: epoch 58, loss 0.41818705201148987, acc=0.8611111044883728, loss=0.41818705201148987
train: epoch 59, loss 0.1665315181016922, acc=0.9264444708824158, loss=0.1665315181016922
test: epoch 59, loss 0.37198132276535034, acc=0.8777777552604675, loss=0.37198132276535034
train: epoch 60, loss 0.18931157886981964, acc=0.9220555424690247, loss=0.18931157886981964
test: epoch 60, loss 0.26200351119041443, acc=0.8833333253860474, loss=0.26200351119041443
train: epoch 61, loss 0.1920408010482788, acc=0.9196110963821411, loss=0.1920408010482788
test: epoch 61, loss 0.39152613282203674, acc=0.8777777552604675, loss=0.39152613282203674
train: epoch 62, loss 0.19555281102657318, acc=0.918055534362793, loss=0.19555281102657318
test: epoch 62, loss 0.4050203263759613, acc=0.8388888835906982, loss=0.4050203263759613
train: epoch 63, loss 0.18538635969161987, acc=0.9163333177566528, loss=0.18538635969161987
test: epoch 63, loss 0.3350754678249359, acc=0.8638888597488403, loss=0.3350754678249359
train: epoch 64, loss 0.15437541902065277, acc=0.9283888936042786, loss=0.15437541902065277
test: epoch 64, loss 0.4357443153858185, acc=0.8777777552604675, loss=0.4357443153858185
train: epoch 65, loss 0.168535977602005, acc=0.9266666769981384, loss=0.168535977602005
test: epoch 65, loss 0.2918769419193268, acc=0.8777777552604675, loss=0.2918769419193268
train: epoch 66, loss 0.16038325428962708, acc=0.9258888959884644, loss=0.16038325428962708
test: epoch 66, loss 0.3625478744506836, acc=0.875, loss=0.3625478744506836
train: epoch 67, loss 0.2972269654273987, acc=0.8804444670677185, loss=0.2972269654273987
test: epoch 67, loss 0.3924117684364319, acc=0.8444444537162781, loss=0.3924117684364319
train: epoch 68, loss 0.20653237402439117, acc=0.9095555543899536, loss=0.20653237402439117
test: epoch 68, loss 0.3745809495449066, acc=0.8666666746139526, loss=0.3745809495449066
train: epoch 69, loss 0.2020849734544754, acc=0.9200000166893005, loss=0.2020849734544754
test: epoch 69, loss 0.35548046231269836, acc=0.8694444298744202, loss=0.35548046231269836
train: epoch 70, loss 0.1724742352962494, acc=0.9249444603919983, loss=0.1724742352962494
test: epoch 70, loss 0.29189208149909973, acc=0.8833333253860474, loss=0.29189208149909973
train: epoch 71, loss 0.13415348529815674, acc=0.9331666827201843, loss=0.13415348529815674
test: epoch 71, loss 0.2513684332370758, acc=0.8777777552604675, loss=0.2513684332370758
train: epoch 72, loss 0.17731168866157532, acc=0.9235555529594421, loss=0.17731168866157532
test: epoch 72, loss 0.3748999834060669, acc=0.875, loss=0.3748999834060669
train: epoch 73, loss 0.19366885721683502, acc=0.918833315372467, loss=0.19366885721683502
test: epoch 73, loss 0.28401893377304077, acc=0.8861111402511597, loss=0.28401893377304077
train: epoch 74, loss 0.19492307305335999, acc=0.9178333282470703, loss=0.19492307305335999
test: epoch 74, loss 0.35950368642807007, acc=0.875, loss=0.35950368642807007
train: epoch 75, loss 0.14984048902988434, acc=0.9277777671813965, loss=0.14984048902988434
test: epoch 75, loss 0.3181527554988861, acc=0.8833333253860474, loss=0.3181527554988861
train: epoch 76, loss 0.18730266392230988, acc=0.9219444394111633, loss=0.18730266392230988
test: epoch 76, loss 0.37527644634246826, acc=0.8833333253860474, loss=0.37527644634246826
train: epoch 77, loss 0.18701988458633423, acc=0.9206666946411133, loss=0.18701988458633423
test: epoch 77, loss 0.3284473419189453, acc=0.8777777552604675, loss=0.3284473419189453
train: epoch 78, loss 0.1742319017648697, acc=0.9237777590751648, loss=0.1742319017648697
test: epoch 78, loss 0.3944644033908844, acc=0.8722222447395325, loss=0.3944644033908844
train: epoch 79, loss 0.1813315749168396, acc=0.9215555787086487, loss=0.1813315749168396
test: epoch 79, loss 0.4445837438106537, acc=0.8777777552604675, loss=0.4445837438106537
train: epoch 80, loss 0.20666693150997162, acc=0.9150555729866028, loss=0.20666693150997162
test: epoch 80, loss 0.3179941773414612, acc=0.8833333253860474, loss=0.3179941773414612
train: epoch 81, loss 0.16766396164894104, acc=0.9240555763244629, loss=0.16766396164894104
test: epoch 81, loss 0.2815619111061096, acc=0.8805555701255798, loss=0.2815619111061096
train: epoch 82, loss 0.1883344203233719, acc=0.9139444231987, loss=0.1883344203233719
test: epoch 82, loss 0.24950867891311646, acc=0.8805555701255798, loss=0.24950867891311646
train: epoch 83, loss 0.16994772851467133, acc=0.9218888878822327, loss=0.16994772851467133
test: epoch 83, loss 0.2861754894256592, acc=0.8777777552604675, loss=0.2861754894256592
train: epoch 84, loss 0.25762316584587097, acc=0.9035555720329285, loss=0.25762316584587097
test: epoch 84, loss 0.33485332131385803, acc=0.875, loss=0.33485332131385803
train: epoch 85, loss 0.20471008121967316, acc=0.9150555729866028, loss=0.20471008121967316
test: epoch 85, loss 0.2542763352394104, acc=0.8805555701255798, loss=0.2542763352394104
train: epoch 86, loss 0.16269607841968536, acc=0.9217222332954407, loss=0.16269607841968536
test: epoch 86, loss 0.39971616864204407, acc=0.8638888597488403, loss=0.39971616864204407
train: epoch 87, loss 0.21490120887756348, acc=0.9105555415153503, loss=0.21490120887756348
test: epoch 87, loss 0.3631967306137085, acc=0.8666666746139526, loss=0.3631967306137085
train: epoch 88, loss 0.18356801569461823, acc=0.9185000061988831, loss=0.18356801569461823
test: epoch 88, loss 0.2756623327732086, acc=0.8777777552604675, loss=0.2756623327732086
train: epoch 89, loss 0.16531716287136078, acc=0.9238333106040955, loss=0.16531716287136078
test: epoch 89, loss 0.33505094051361084, acc=0.8805555701255798, loss=0.33505094051361084
train: epoch 90, loss 0.1965256780385971, acc=0.9139444231987, loss=0.1965256780385971
test: epoch 90, loss 0.2940097153186798, acc=0.8777777552604675, loss=0.2940097153186798
train: epoch 91, loss 0.18148662149906158, acc=0.9183889031410217, loss=0.18148662149906158
test: epoch 91, loss 0.2750133275985718, acc=0.8777777552604675, loss=0.2750133275985718
train: epoch 92, loss 0.2543483376502991, acc=0.8978333473205566, loss=0.2543483376502991
test: epoch 92, loss 0.4644257128238678, acc=0.855555534362793, loss=0.4644257128238678
train: epoch 93, loss 0.25786328315734863, acc=0.867388904094696, loss=0.25786328315734863
test: epoch 93, loss 0.34982943534851074, acc=0.8333333134651184, loss=0.34982943534851074
train: epoch 94, loss 0.26859888434410095, acc=0.862666666507721, loss=0.26859888434410095
test: epoch 94, loss 0.31223806738853455, acc=0.8500000238418579, loss=0.31223806738853455
train: epoch 95, loss 0.23053255677223206, acc=0.8773888945579529, loss=0.23053255677223206
test: epoch 95, loss 0.325095534324646, acc=0.855555534362793, loss=0.325095534324646
train: epoch 96, loss 0.20755749940872192, acc=0.8963888883590698, loss=0.20755749940872192
test: epoch 96, loss 0.21691124141216278, acc=0.8861111402511597, loss=0.21691124141216278
train: epoch 97, loss 0.18116959929466248, acc=0.9161666631698608, loss=0.18116959929466248
test: epoch 97, loss 0.45289015769958496, acc=0.8361111283302307, loss=0.45289015769958496
train: epoch 98, loss 0.22137020528316498, acc=0.909500002861023, loss=0.22137020528316498
test: epoch 98, loss 0.37501129508018494, acc=0.8777777552604675, loss=0.37501129508018494
train: epoch 99, loss 0.21533671021461487, acc=0.9070000052452087, loss=0.21533671021461487
test: epoch 99, loss 0.21895137429237366, acc=0.8805555701255798, loss=0.21895137429237366
train: epoch 100, loss 0.1795213520526886, acc=0.9153888821601868, loss=0.1795213520526886
test: epoch 100, loss 0.2998654842376709, acc=0.8805555701255798, loss=0.2998654842376709
train: epoch 101, loss 0.2008446604013443, acc=0.8980000019073486, loss=0.2008446604013443
test: epoch 101, loss 0.2066430002450943, acc=0.8805555701255798, loss=0.2066430002450943
train: epoch 102, loss 0.22632576525211334, acc=0.9016666412353516, loss=0.22632576525211334
test: epoch 102, loss 0.3279329240322113, acc=0.8722222447395325, loss=0.3279329240322113
train: epoch 103, loss 0.2382945865392685, acc=0.8991110920906067, loss=0.2382945865392685
test: epoch 103, loss 0.3070574998855591, acc=0.8722222447395325, loss=0.3070574998855591
train: epoch 104, loss 0.21000100672245026, acc=0.903166651725769, loss=0.21000100672245026
test: epoch 104, loss 0.3723427653312683, acc=0.8722222447395325, loss=0.3723427653312683
train: epoch 105, loss 0.21176305413246155, acc=0.9078333377838135, loss=0.21176305413246155
test: epoch 105, loss 0.24249446392059326, acc=0.8833333253860474, loss=0.24249446392059326
train: epoch 106, loss 0.18852201104164124, acc=0.9157222509384155, loss=0.18852201104164124
test: epoch 106, loss 0.2916857898235321, acc=0.8777777552604675, loss=0.2916857898235321
train: epoch 107, loss 0.21863305568695068, acc=0.9043333530426025, loss=0.21863305568695068
test: epoch 107, loss 0.3869076371192932, acc=0.8666666746139526, loss=0.3869076371192932
train: epoch 108, loss 0.24799178540706635, acc=0.8983888626098633, loss=0.24799178540706635
test: epoch 108, loss 0.31913360953330994, acc=0.855555534362793, loss=0.31913360953330994
train: epoch 109, loss 0.23942354321479797, acc=0.8993333578109741, loss=0.23942354321479797
test: epoch 109, loss 0.4039737284183502, acc=0.8666666746139526, loss=0.4039737284183502
train: epoch 110, loss 0.2300502061843872, acc=0.9032222032546997, loss=0.2300502061843872
test: epoch 110, loss 0.27105772495269775, acc=0.8694444298744202, loss=0.27105772495269775
train: epoch 111, loss 0.2471192628145218, acc=0.9002777934074402, loss=0.2471192628145218
test: epoch 111, loss 0.3871991038322449, acc=0.875, loss=0.3871991038322449
train: epoch 112, loss 0.21020391583442688, acc=0.9066110849380493, loss=0.21020391583442688
test: epoch 112, loss 0.441153883934021, acc=0.8666666746139526, loss=0.441153883934021
train: epoch 113, loss 0.25098609924316406, acc=0.8920000195503235, loss=0.25098609924316406
test: epoch 113, loss 0.34273234009742737, acc=0.8722222447395325, loss=0.34273234009742737
train: epoch 114, loss 0.2524259388446808, acc=0.8976110816001892, loss=0.2524259388446808
test: epoch 114, loss 0.35570862889289856, acc=0.8583333492279053, loss=0.35570862889289856
train: epoch 115, loss 0.2554720342159271, acc=0.8940555453300476, loss=0.2554720342159271
test: epoch 115, loss 0.4064992368221283, acc=0.8527777791023254, loss=0.4064992368221283
train: epoch 116, loss 0.2774866223335266, acc=0.8888888955116272, loss=0.2774866223335266
test: epoch 116, loss 0.3741399645805359, acc=0.8666666746139526, loss=0.3741399645805359
train: epoch 117, loss 0.21677693724632263, acc=0.9096666574478149, loss=0.21677693724632263
test: epoch 117, loss 0.2915462553501129, acc=0.8861111402511597, loss=0.2915462553501129
train: epoch 118, loss 0.15889722108840942, acc=0.9200555682182312, loss=0.15889722108840942
test: epoch 118, loss 0.3153020739555359, acc=0.8833333253860474, loss=0.3153020739555359
train: epoch 119, loss 0.20211467146873474, acc=0.9107778072357178, loss=0.20211467146873474
test: epoch 119, loss 0.43416112661361694, acc=0.8694444298744202, loss=0.43416112661361694
train: epoch 120, loss 0.208449587225914, acc=0.8951666951179504, loss=0.208449587225914
test: epoch 120, loss 0.3943383991718292, acc=0.8638888597488403, loss=0.3943383991718292
train: epoch 121, loss 0.24362801015377045, acc=0.8784444332122803, loss=0.24362801015377045
test: epoch 121, loss 0.3404853641986847, acc=0.8527777791023254, loss=0.3404853641986847
train: epoch 122, loss 0.19812193512916565, acc=0.8914444446563721, loss=0.19812193512916565
test: epoch 122, loss 0.41587916016578674, acc=0.8638888597488403, loss=0.41587916016578674
train: epoch 123, loss 0.2382417917251587, acc=0.8941666483879089, loss=0.2382417917251587
test: epoch 123, loss 0.3435124456882477, acc=0.8777777552604675, loss=0.3435124456882477
train: epoch 124, loss 0.2462776154279709, acc=0.9015555381774902, loss=0.2462776154279709
test: epoch 124, loss 0.36155298352241516, acc=0.8777777552604675, loss=0.36155298352241516
train: epoch 125, loss 0.1804841160774231, acc=0.9141666889190674, loss=0.1804841160774231
test: epoch 125, loss 0.2806263864040375, acc=0.8777777552604675, loss=0.2806263864040375
train: epoch 126, loss 0.17189860343933105, acc=0.9160000085830688, loss=0.17189860343933105
test: epoch 126, loss 0.3294357359409332, acc=0.8777777552604675, loss=0.3294357359409332
train: epoch 127, loss 0.19448460638523102, acc=0.9094444513320923, loss=0.19448460638523102
test: epoch 127, loss 0.2607409954071045, acc=0.8805555701255798, loss=0.2607409954071045
train: epoch 128, loss 0.21579347550868988, acc=0.9065555334091187, loss=0.21579347550868988
test: epoch 128, loss 0.36930009722709656, acc=0.8527777791023254, loss=0.36930009722709656
train: epoch 129, loss 0.18787051737308502, acc=0.9124444723129272, loss=0.18787051737308502
test: epoch 129, loss 0.28551891446113586, acc=0.8805555701255798, loss=0.28551891446113586
train: epoch 130, loss 0.19195455312728882, acc=0.9126111268997192, loss=0.19195455312728882
test: epoch 130, loss 0.27986010909080505, acc=0.8805555701255798, loss=0.27986010909080505
train: epoch 131, loss 0.17304199934005737, acc=0.9155555367469788, loss=0.17304199934005737
test: epoch 131, loss 0.2988088130950928, acc=0.8805555701255798, loss=0.2988088130950928
train: epoch 132, loss 0.23712846636772156, acc=0.9047222137451172, loss=0.23712846636772156
test: epoch 132, loss 0.4405033588409424, acc=0.8611111044883728, loss=0.4405033588409424
train: epoch 133, loss 0.24160932004451752, acc=0.8978333473205566, loss=0.24160932004451752
test: epoch 133, loss 0.3732433319091797, acc=0.8638888597488403, loss=0.3732433319091797
train: epoch 134, loss 0.23813103139400482, acc=0.9006111025810242, loss=0.23813103139400482
test: epoch 134, loss 0.3780527710914612, acc=0.855555534362793, loss=0.3780527710914612
train: epoch 135, loss 0.29638683795928955, acc=0.8845000267028809, loss=0.29638683795928955
test: epoch 135, loss 0.4975275695323944, acc=0.8388888835906982, loss=0.4975275695323944
train: epoch 136, loss 0.30094754695892334, acc=0.8829444646835327, loss=0.30094754695892334
test: epoch 136, loss 0.3813970386981964, acc=0.8500000238418579, loss=0.3813970386981964
train: epoch 137, loss 0.2667938470840454, acc=0.8911666870117188, loss=0.2667938470840454
test: epoch 137, loss 0.3663076162338257, acc=0.8611111044883728, loss=0.3663076162338257
train: epoch 138, loss 0.2383114993572235, acc=0.8961111307144165, loss=0.2383114993572235
test: epoch 138, loss 0.3155606985092163, acc=0.8611111044883728, loss=0.3155606985092163
train: epoch 139, loss 0.24422423541545868, acc=0.8961666822433472, loss=0.24422423541545868
test: epoch 139, loss 0.2897106409072876, acc=0.855555534362793, loss=0.2897106409072876
train: epoch 140, loss 0.24960850179195404, acc=0.8919444680213928, loss=0.24960850179195404
test: epoch 140, loss 0.3443681597709656, acc=0.8666666746139526, loss=0.3443681597709656
train: epoch 141, loss 0.19778747856616974, acc=0.9087777733802795, loss=0.19778747856616974
test: epoch 141, loss 0.37637534737586975, acc=0.875, loss=0.37637534737586975
train: epoch 142, loss 0.31599199771881104, acc=0.8786666393280029, loss=0.31599199771881104
test: epoch 142, loss 0.45129600167274475, acc=0.824999988079071, loss=0.45129600167274475
train: epoch 143, loss 0.28980380296707153, acc=0.878166675567627, loss=0.28980380296707153
test: epoch 143, loss 0.41698503494262695, acc=0.8527777791023254, loss=0.41698503494262695
train: epoch 144, loss 0.26928144693374634, acc=0.890500009059906, loss=0.26928144693374634
test: epoch 144, loss 0.41809341311454773, acc=0.8527777791023254, loss=0.41809341311454773
train: epoch 145, loss 0.27076420187950134, acc=0.887666642665863, loss=0.27076420187950134
test: epoch 145, loss 0.4904961585998535, acc=0.8527777791023254, loss=0.4904961585998535
train: epoch 146, loss 0.2834388315677643, acc=0.8854444622993469, loss=0.2834388315677643
test: epoch 146, loss 0.3952597677707672, acc=0.8388888835906982, loss=0.3952597677707672
train: epoch 147, loss 0.26501038670539856, acc=0.8909444212913513, loss=0.26501038670539856
test: epoch 147, loss 0.37952694296836853, acc=0.855555534362793, loss=0.37952694296836853
train: epoch 148, loss 0.2434724122285843, acc=0.8941110968589783, loss=0.2434724122285843
test: epoch 148, loss 0.4008413553237915, acc=0.855555534362793, loss=0.4008413553237915
train: epoch 149, loss 0.2377830296754837, acc=0.8955000042915344, loss=0.2377830296754837
test: epoch 149, loss 0.33795538544654846, acc=0.8638888597488403, loss=0.33795538544654846
train: epoch 150, loss 0.22673329710960388, acc=0.9012222290039062, loss=0.22673329710960388
test: epoch 150, loss 0.3900470435619354, acc=0.855555534362793, loss=0.3900470435619354
