# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=0.99", "--one_hot=false", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=2090320887, receiver_embed_dim=32, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.0334441661834717, acc=0.07983333617448807, loss=3.0334441661834717
test: epoch 1, loss 3.714184284210205, acc=0.10555555671453476, loss=3.714184284210205
train: epoch 2, loss 2.0223288536071777, acc=0.20727777481079102, loss=2.0223288536071777
test: epoch 2, loss 3.7141599655151367, acc=0.1527777761220932, loss=3.7141599655151367
train: epoch 3, loss 1.6446841955184937, acc=0.2990555465221405, loss=1.6446841955184937
test: epoch 3, loss 4.033113479614258, acc=0.12222222238779068, loss=4.033113479614258
train: epoch 4, loss 1.455217719078064, acc=0.3636666536331177, loss=1.455217719078064
test: epoch 4, loss 3.3183281421661377, acc=0.16388888657093048, loss=3.3183281421661377
train: epoch 5, loss 1.3223084211349487, acc=0.4157777726650238, loss=1.3223084211349487
test: epoch 5, loss 3.967761754989624, acc=0.16388888657093048, loss=3.967761754989624
train: epoch 6, loss 1.226157307624817, acc=0.449055552482605, loss=1.226157307624817
test: epoch 6, loss 3.502061128616333, acc=0.18333333730697632, loss=3.502061128616333
train: epoch 7, loss 1.1571310758590698, acc=0.48527777194976807, loss=1.1571310758590698
test: epoch 7, loss 3.4991862773895264, acc=0.18611110746860504, loss=3.4991862773895264
train: epoch 8, loss 1.1057766675949097, acc=0.5015555620193481, loss=1.1057766675949097
test: epoch 8, loss 3.5350773334503174, acc=0.21666666865348816, loss=3.5350773334503174
train: epoch 9, loss 1.0601969957351685, acc=0.5247222185134888, loss=1.0601969957351685
test: epoch 9, loss 3.339341402053833, acc=0.24444444477558136, loss=3.339341402053833
train: epoch 10, loss 1.0293632745742798, acc=0.5343888998031616, loss=1.0293632745742798
test: epoch 10, loss 3.3703930377960205, acc=0.17777778208255768, loss=3.3703930377960205
train: epoch 11, loss 1.0038424730300903, acc=0.5501111149787903, loss=1.0038424730300903
test: epoch 11, loss 2.4803073406219482, acc=0.2611111104488373, loss=2.4803073406219482
train: epoch 12, loss 0.9800130128860474, acc=0.5677222013473511, loss=0.9800130128860474
test: epoch 12, loss 3.2075769901275635, acc=0.20277777314186096, loss=3.2075769901275635
train: epoch 13, loss 0.9317378997802734, acc=0.5886111259460449, loss=0.9317378997802734
test: epoch 13, loss 3.0153539180755615, acc=0.23888888955116272, loss=3.0153539180755615
train: epoch 14, loss 0.9392086863517761, acc=0.5846666693687439, loss=0.9392086863517761
test: epoch 14, loss 2.5228593349456787, acc=0.2750000059604645, loss=2.5228593349456787
train: epoch 15, loss 0.897162139415741, acc=0.6031110882759094, loss=0.897162139415741
test: epoch 15, loss 2.509643316268921, acc=0.2638888955116272, loss=2.509643316268921
train: epoch 16, loss 0.8815960884094238, acc=0.6175000071525574, loss=0.8815960884094238
test: epoch 16, loss 2.686269998550415, acc=0.2222222238779068, loss=2.686269998550415
train: epoch 17, loss 0.8282356262207031, acc=0.648277759552002, loss=0.8282356262207031
test: epoch 17, loss 2.2576351165771484, acc=0.32777777314186096, loss=2.2576351165771484
train: epoch 18, loss 0.7464605569839478, acc=0.6859999895095825, loss=0.7464605569839478
test: epoch 18, loss 2.391810894012451, acc=0.3333333432674408, loss=2.391810894012451
train: epoch 19, loss 0.6932915449142456, acc=0.7114999890327454, loss=0.6932915449142456
test: epoch 19, loss 1.8194743394851685, acc=0.3583333194255829, loss=1.8194743394851685
train: epoch 20, loss 0.6193877458572388, acc=0.7357777953147888, loss=0.6193877458572388
test: epoch 20, loss 1.920701503753662, acc=0.3361110985279083, loss=1.920701503753662
train: epoch 21, loss 0.6031934022903442, acc=0.7491111159324646, loss=0.6031934022903442
test: epoch 21, loss 1.7250722646713257, acc=0.3722222149372101, loss=1.7250722646713257
train: epoch 22, loss 0.5829370617866516, acc=0.7600555419921875, loss=0.5829370617866516
test: epoch 22, loss 1.7427667379379272, acc=0.3611111044883728, loss=1.7427667379379272
train: epoch 23, loss 0.5351443886756897, acc=0.7776666879653931, loss=0.5351443886756897
test: epoch 23, loss 1.750649333000183, acc=0.3638888895511627, loss=1.750649333000183
train: epoch 24, loss 0.48970773816108704, acc=0.8036110997200012, loss=0.48970773816108704
test: epoch 24, loss 1.9277222156524658, acc=0.38055557012557983, loss=1.9277222156524658
train: epoch 25, loss 0.4658452570438385, acc=0.8220555782318115, loss=0.4658452570438385
test: epoch 25, loss 1.8330514430999756, acc=0.39722222089767456, loss=1.8330514430999756
train: epoch 26, loss 0.41008350253105164, acc=0.8382777571678162, loss=0.41008350253105164
test: epoch 26, loss 1.680847406387329, acc=0.43888887763023376, loss=1.680847406387329
train: epoch 27, loss 0.390231728553772, acc=0.8504444360733032, loss=0.390231728553772
test: epoch 27, loss 1.6305677890777588, acc=0.45277777314186096, loss=1.6305677890777588
train: epoch 28, loss 0.3822281062602997, acc=0.851111114025116, loss=0.3822281062602997
test: epoch 28, loss 1.7974472045898438, acc=0.4277777671813965, loss=1.7974472045898438
train: epoch 29, loss 0.3875788450241089, acc=0.8543333411216736, loss=0.3875788450241089
test: epoch 29, loss 1.4831767082214355, acc=0.4694444537162781, loss=1.4831767082214355
train: epoch 30, loss 0.3606153726577759, acc=0.8668888807296753, loss=0.3606153726577759
test: epoch 30, loss 1.6322048902511597, acc=0.49166667461395264, loss=1.6322048902511597
train: epoch 31, loss 0.31869107484817505, acc=0.8843333125114441, loss=0.31869107484817505
test: epoch 31, loss 1.2113428115844727, acc=0.5083333253860474, loss=1.2113428115844727
train: epoch 32, loss 0.3242517411708832, acc=0.8861111402511597, loss=0.3242517411708832
test: epoch 32, loss 1.3034312725067139, acc=0.5333333611488342, loss=1.3034312725067139
train: epoch 33, loss 0.3364003300666809, acc=0.886388897895813, loss=0.3364003300666809
test: epoch 33, loss 1.3710906505584717, acc=0.49166667461395264, loss=1.3710906505584717
train: epoch 34, loss 0.319780170917511, acc=0.8926666378974915, loss=0.319780170917511
test: epoch 34, loss 1.5241408348083496, acc=0.4444444477558136, loss=1.5241408348083496
train: epoch 35, loss 0.2878301441669464, acc=0.9024444222450256, loss=0.2878301441669464
test: epoch 35, loss 1.6172335147857666, acc=0.5027777552604675, loss=1.6172335147857666
train: epoch 36, loss 0.27713367342948914, acc=0.9066110849380493, loss=0.27713367342948914
test: epoch 36, loss 1.535245656967163, acc=0.4333333373069763, loss=1.535245656967163
train: epoch 37, loss 0.26066550612449646, acc=0.9092222452163696, loss=0.26066550612449646
test: epoch 37, loss 1.3249469995498657, acc=0.5222222208976746, loss=1.3249469995498657
train: epoch 38, loss 0.27565255761146545, acc=0.9068333506584167, loss=0.27565255761146545
test: epoch 38, loss 1.396716594696045, acc=0.5111111402511597, loss=1.396716594696045
train: epoch 39, loss 0.2735130488872528, acc=0.9092777967453003, loss=0.2735130488872528
test: epoch 39, loss 1.3207014799118042, acc=0.6000000238418579, loss=1.3207014799118042
train: epoch 40, loss 0.2615756392478943, acc=0.9135000109672546, loss=0.2615756392478943
test: epoch 40, loss 1.545471429824829, acc=0.4555555582046509, loss=1.545471429824829
train: epoch 41, loss 0.2665667235851288, acc=0.9086111187934875, loss=0.2665667235851288
test: epoch 41, loss 1.3379369974136353, acc=0.5027777552604675, loss=1.3379369974136353
train: epoch 42, loss 0.24983766674995422, acc=0.9135555624961853, loss=0.24983766674995422
test: epoch 42, loss 1.2849041223526, acc=0.550000011920929, loss=1.2849041223526
train: epoch 43, loss 0.23442864418029785, acc=0.9207777976989746, loss=0.23442864418029785
test: epoch 43, loss 1.5231026411056519, acc=0.5638889074325562, loss=1.5231026411056519
train: epoch 44, loss 0.24171221256256104, acc=0.918833315372467, loss=0.24171221256256104
test: epoch 44, loss 1.3655674457550049, acc=0.5055555701255798, loss=1.3655674457550049
train: epoch 45, loss 0.24575695395469666, acc=0.9192222356796265, loss=0.24575695395469666
test: epoch 45, loss 1.1337748765945435, acc=0.6222222447395325, loss=1.1337748765945435
train: epoch 46, loss 0.22713537514209747, acc=0.9232777953147888, loss=0.22713537514209747
test: epoch 46, loss 1.4647849798202515, acc=0.5694444179534912, loss=1.4647849798202515
train: epoch 47, loss 0.22201676666736603, acc=0.9258888959884644, loss=0.22201676666736603
test: epoch 47, loss 1.467013955116272, acc=0.5111111402511597, loss=1.467013955116272
train: epoch 48, loss 0.22942529618740082, acc=0.9252777695655823, loss=0.22942529618740082
test: epoch 48, loss 1.413193941116333, acc=0.5583333373069763, loss=1.413193941116333
train: epoch 49, loss 0.23699341714382172, acc=0.9215555787086487, loss=0.23699341714382172
test: epoch 49, loss 1.3751164674758911, acc=0.5305555462837219, loss=1.3751164674758911
train: epoch 50, loss 0.22336269915103912, acc=0.9256666898727417, loss=0.22336269915103912
test: epoch 50, loss 1.446210265159607, acc=0.5305555462837219, loss=1.446210265159607
train: epoch 51, loss 0.2335980236530304, acc=0.922166645526886, loss=0.2335980236530304
test: epoch 51, loss 1.5549513101577759, acc=0.5527777671813965, loss=1.5549513101577759
train: epoch 52, loss 0.22323811054229736, acc=0.9236666560173035, loss=0.22323811054229736
test: epoch 52, loss 1.5133886337280273, acc=0.5472221970558167, loss=1.5133886337280273
train: epoch 53, loss 0.2076900750398636, acc=0.9314444661140442, loss=0.2076900750398636
test: epoch 53, loss 1.5197519063949585, acc=0.5944444537162781, loss=1.5197519063949585
train: epoch 54, loss 0.21132366359233856, acc=0.9282777905464172, loss=0.21132366359233856
test: epoch 54, loss 1.502689003944397, acc=0.5388888716697693, loss=1.502689003944397
train: epoch 55, loss 0.21167461574077606, acc=0.9316111207008362, loss=0.21167461574077606
test: epoch 55, loss 1.423805832862854, acc=0.6083333492279053, loss=1.423805832862854
train: epoch 56, loss 0.22393928468227386, acc=0.9243333339691162, loss=0.22393928468227386
test: epoch 56, loss 1.4260751008987427, acc=0.5944444537162781, loss=1.4260751008987427
train: epoch 57, loss 0.21789701282978058, acc=0.9301666617393494, loss=0.21789701282978058
test: epoch 57, loss 1.8369178771972656, acc=0.5416666865348816, loss=1.8369178771972656
train: epoch 58, loss 0.19768980145454407, acc=0.9334999918937683, loss=0.19768980145454407
test: epoch 58, loss 1.4508898258209229, acc=0.5305555462837219, loss=1.4508898258209229
train: epoch 59, loss 0.21409036219120026, acc=0.9279444217681885, loss=0.21409036219120026
test: epoch 59, loss 1.244164228439331, acc=0.6027777791023254, loss=1.244164228439331
train: epoch 60, loss 0.19527198374271393, acc=0.9322222471237183, loss=0.19527198374271393
test: epoch 60, loss 1.3232113122940063, acc=0.550000011920929, loss=1.3232113122940063
train: epoch 61, loss 0.20794415473937988, acc=0.9316111207008362, loss=0.20794415473937988
test: epoch 61, loss 1.6986616849899292, acc=0.550000011920929, loss=1.6986616849899292
train: epoch 62, loss 0.19988791644573212, acc=0.9359444379806519, loss=0.19988791644573212
test: epoch 62, loss 1.4203057289123535, acc=0.6027777791023254, loss=1.4203057289123535
train: epoch 63, loss 0.20549727976322174, acc=0.9318333268165588, loss=0.20549727976322174
test: epoch 63, loss 1.1836477518081665, acc=0.6222222447395325, loss=1.1836477518081665
train: epoch 64, loss 0.2110835611820221, acc=0.9296666383743286, loss=0.2110835611820221
test: epoch 64, loss 1.31997549533844, acc=0.6194444298744202, loss=1.31997549533844
train: epoch 65, loss 0.20552030205726624, acc=0.9354444742202759, loss=0.20552030205726624
test: epoch 65, loss 1.3728907108306885, acc=0.5694444179534912, loss=1.3728907108306885
train: epoch 66, loss 0.20219087600708008, acc=0.933055579662323, loss=0.20219087600708008
test: epoch 66, loss 1.258014440536499, acc=0.6833333373069763, loss=1.258014440536499
train: epoch 67, loss 0.22088594734668732, acc=0.9261666536331177, loss=0.22088594734668732
test: epoch 67, loss 1.2261079549789429, acc=0.6305555701255798, loss=1.2261079549789429
train: epoch 68, loss 0.19931839406490326, acc=0.9328888654708862, loss=0.19931839406490326
test: epoch 68, loss 1.1020172834396362, acc=0.6333333253860474, loss=1.1020172834396362
train: epoch 69, loss 0.21713531017303467, acc=0.9307222366333008, loss=0.21713531017303467
test: epoch 69, loss 1.0210381746292114, acc=0.6805555820465088, loss=1.0210381746292114
train: epoch 70, loss 0.2188500016927719, acc=0.925777792930603, loss=0.2188500016927719
test: epoch 70, loss 1.0813320875167847, acc=0.6138888597488403, loss=1.0813320875167847
train: epoch 71, loss 0.19954630732536316, acc=0.9347777962684631, loss=0.19954630732536316
test: epoch 71, loss 1.1388624906539917, acc=0.6555555462837219, loss=1.1388624906539917
train: epoch 72, loss 0.22093702852725983, acc=0.9253333210945129, loss=0.22093702852725983
test: epoch 72, loss 0.9474387764930725, acc=0.6833333373069763, loss=0.9474387764930725
train: epoch 73, loss 0.19611889123916626, acc=0.9355555772781372, loss=0.19611889123916626
test: epoch 73, loss 1.0910178422927856, acc=0.6416666507720947, loss=1.0910178422927856
train: epoch 74, loss 0.19632481038570404, acc=0.9351666569709778, loss=0.19632481038570404
test: epoch 74, loss 1.0562955141067505, acc=0.6499999761581421, loss=1.0562955141067505
train: epoch 75, loss 0.21694159507751465, acc=0.9278888702392578, loss=0.21694159507751465
test: epoch 75, loss 1.1528524160385132, acc=0.605555534362793, loss=1.1528524160385132
train: epoch 76, loss 0.19582484662532806, acc=0.9347777962684631, loss=0.19582484662532806
test: epoch 76, loss 0.8366385698318481, acc=0.6694444417953491, loss=0.8366385698318481
train: epoch 77, loss 0.20460675656795502, acc=0.9293888807296753, loss=0.20460675656795502
test: epoch 77, loss 1.445000410079956, acc=0.6333333253860474, loss=1.445000410079956
train: epoch 78, loss 0.2058328092098236, acc=0.9346110820770264, loss=0.2058328092098236
test: epoch 78, loss 1.12737238407135, acc=0.6833333373069763, loss=1.12737238407135
train: epoch 79, loss 0.19683553278446198, acc=0.9331111311912537, loss=0.19683553278446198
test: epoch 79, loss 0.956386148929596, acc=0.6805555820465088, loss=0.956386148929596
train: epoch 80, loss 0.188100665807724, acc=0.9367777705192566, loss=0.188100665807724
test: epoch 80, loss 1.0496238470077515, acc=0.7055555582046509, loss=1.0496238470077515
train: epoch 81, loss 0.1965675801038742, acc=0.9346110820770264, loss=0.1965675801038742
test: epoch 81, loss 0.6921830177307129, acc=0.7527777552604675, loss=0.6921830177307129
train: epoch 82, loss 0.213827982544899, acc=0.9282222390174866, loss=0.213827982544899
test: epoch 82, loss 0.8709678053855896, acc=0.7333333492279053, loss=0.8709678053855896
train: epoch 83, loss 0.22148190438747406, acc=0.9253333210945129, loss=0.22148190438747406
test: epoch 83, loss 0.789381742477417, acc=0.7388888597488403, loss=0.789381742477417
train: epoch 84, loss 0.19874651730060577, acc=0.9327222108840942, loss=0.19874651730060577
test: epoch 84, loss 0.8493744134902954, acc=0.7583333253860474, loss=0.8493744134902954
train: epoch 85, loss 0.19420909881591797, acc=0.9352222084999084, loss=0.19420909881591797
test: epoch 85, loss 0.9601885080337524, acc=0.7222222089767456, loss=0.9601885080337524
train: epoch 86, loss 0.19820010662078857, acc=0.9357777833938599, loss=0.19820010662078857
test: epoch 86, loss 0.775795578956604, acc=0.7638888955116272, loss=0.775795578956604
train: epoch 87, loss 0.20278936624526978, acc=0.9315000176429749, loss=0.20278936624526978
test: epoch 87, loss 0.857068657875061, acc=0.7333333492279053, loss=0.857068657875061
train: epoch 88, loss 0.20249290764331818, acc=0.9341111183166504, loss=0.20249290764331818
test: epoch 88, loss 0.958268404006958, acc=0.7333333492279053, loss=0.958268404006958
train: epoch 89, loss 0.20337051153182983, acc=0.9311110973358154, loss=0.20337051153182983
test: epoch 89, loss 0.8143571615219116, acc=0.7277777791023254, loss=0.8143571615219116
train: epoch 90, loss 0.21254925429821014, acc=0.9272778034210205, loss=0.21254925429821014
test: epoch 90, loss 0.7735223770141602, acc=0.7250000238418579, loss=0.7735223770141602
train: epoch 91, loss 0.20744900405406952, acc=0.9328888654708862, loss=0.20744900405406952
test: epoch 91, loss 0.7147252559661865, acc=0.7638888955116272, loss=0.7147252559661865
train: epoch 92, loss 0.2158200740814209, acc=0.929277777671814, loss=0.2158200740814209
test: epoch 92, loss 0.8867831230163574, acc=0.7083333134651184, loss=0.8867831230163574
train: epoch 93, loss 0.21089327335357666, acc=0.9279999732971191, loss=0.21089327335357666
test: epoch 93, loss 0.8444191813468933, acc=0.7388888597488403, loss=0.8444191813468933
train: epoch 94, loss 0.20910026133060455, acc=0.9304444193840027, loss=0.20910026133060455
test: epoch 94, loss 0.8903677463531494, acc=0.7222222089767456, loss=0.8903677463531494
train: epoch 95, loss 0.20281603932380676, acc=0.9309444427490234, loss=0.20281603932380676
test: epoch 95, loss 0.722827136516571, acc=0.75, loss=0.722827136516571
train: epoch 96, loss 0.20261181890964508, acc=0.9295555353164673, loss=0.20261181890964508
test: epoch 96, loss 0.6124612092971802, acc=0.7277777791023254, loss=0.6124612092971802
train: epoch 97, loss 0.21478845179080963, acc=0.9263333082199097, loss=0.21478845179080963
test: epoch 97, loss 0.7342973947525024, acc=0.7638888955116272, loss=0.7342973947525024
train: epoch 98, loss 0.21419978141784668, acc=0.926111102104187, loss=0.21419978141784668
test: epoch 98, loss 0.5568222403526306, acc=0.7611111402511597, loss=0.5568222403526306
train: epoch 99, loss 0.17494097352027893, acc=0.9387778043746948, loss=0.17494097352027893
test: epoch 99, loss 0.5508309602737427, acc=0.7749999761581421, loss=0.5508309602737427
train: epoch 100, loss 0.19972552359104156, acc=0.9311110973358154, loss=0.19972552359104156
test: epoch 100, loss 0.8267159461975098, acc=0.7722222208976746, loss=0.8267159461975098
train: epoch 101, loss 0.20935632288455963, acc=0.9284444451332092, loss=0.20935632288455963
test: epoch 101, loss 0.5895870327949524, acc=0.7777777910232544, loss=0.5895870327949524
train: epoch 102, loss 0.192365825176239, acc=0.9306111335754395, loss=0.192365825176239
test: epoch 102, loss 0.5248380303382874, acc=0.7666666507720947, loss=0.5248380303382874
train: epoch 103, loss 0.17896398901939392, acc=0.9380555748939514, loss=0.17896398901939392
test: epoch 103, loss 0.5652498602867126, acc=0.7861111164093018, loss=0.5652498602867126
train: epoch 104, loss 0.19291672110557556, acc=0.9327222108840942, loss=0.19291672110557556
test: epoch 104, loss 0.656166672706604, acc=0.7722222208976746, loss=0.656166672706604
train: epoch 105, loss 0.17046265304088593, acc=0.9426110982894897, loss=0.17046265304088593
test: epoch 105, loss 0.5157002806663513, acc=0.800000011920929, loss=0.5157002806663513
train: epoch 106, loss 0.1873442530632019, acc=0.9389444589614868, loss=0.1873442530632019
test: epoch 106, loss 0.6469939351081848, acc=0.8222222328186035, loss=0.6469939351081848
train: epoch 107, loss 0.19851401448249817, acc=0.9320555329322815, loss=0.19851401448249817
test: epoch 107, loss 0.7031188011169434, acc=0.800000011920929, loss=0.7031188011169434
train: epoch 108, loss 0.17968115210533142, acc=0.940666675567627, loss=0.17968115210533142
test: epoch 108, loss 0.6041460037231445, acc=0.7833333611488342, loss=0.6041460037231445
train: epoch 109, loss 0.16607961058616638, acc=0.9433888792991638, loss=0.16607961058616638
test: epoch 109, loss 0.6552118062973022, acc=0.7749999761581421, loss=0.6552118062973022
train: epoch 110, loss 0.18807555735111237, acc=0.9352222084999084, loss=0.18807555735111237
test: epoch 110, loss 0.5597319602966309, acc=0.7916666865348816, loss=0.5597319602966309
train: epoch 111, loss 0.170573428273201, acc=0.9407777786254883, loss=0.170573428273201
test: epoch 111, loss 0.5726398825645447, acc=0.8083333373069763, loss=0.5726398825645447
train: epoch 112, loss 0.15872888267040253, acc=0.944611132144928, loss=0.15872888267040253
test: epoch 112, loss 0.4634472131729126, acc=0.8305555582046509, loss=0.4634472131729126
train: epoch 113, loss 0.17026297748088837, acc=0.9392222166061401, loss=0.17026297748088837
test: epoch 113, loss 0.39575812220573425, acc=0.8305555582046509, loss=0.39575812220573425
train: epoch 114, loss 0.16880741715431213, acc=0.9413889050483704, loss=0.16880741715431213
test: epoch 114, loss 0.5675199627876282, acc=0.8305555582046509, loss=0.5675199627876282
train: epoch 115, loss 0.15282100439071655, acc=0.9473888874053955, loss=0.15282100439071655
test: epoch 115, loss 0.4257481098175049, acc=0.8305555582046509, loss=0.4257481098175049
train: epoch 116, loss 0.15821337699890137, acc=0.945555567741394, loss=0.15821337699890137
test: epoch 116, loss 0.5244898796081543, acc=0.824999988079071, loss=0.5244898796081543
train: epoch 117, loss 0.15606340765953064, acc=0.945888876914978, loss=0.15606340765953064
test: epoch 117, loss 0.5071767568588257, acc=0.8194444179534912, loss=0.5071767568588257
train: epoch 118, loss 0.1546756774187088, acc=0.9470000267028809, loss=0.1546756774187088
test: epoch 118, loss 0.5239841938018799, acc=0.8333333134651184, loss=0.5239841938018799
train: epoch 119, loss 0.13812942802906036, acc=0.9523333311080933, loss=0.13812942802906036
test: epoch 119, loss 0.4421684443950653, acc=0.8333333134651184, loss=0.4421684443950653
train: epoch 120, loss 0.14140638709068298, acc=0.9512777924537659, loss=0.14140638709068298
test: epoch 120, loss 0.40444129705429077, acc=0.8333333134651184, loss=0.40444129705429077
train: epoch 121, loss 0.14902788400650024, acc=0.9491111040115356, loss=0.14902788400650024
test: epoch 121, loss 0.505901038646698, acc=0.800000011920929, loss=0.505901038646698
train: epoch 122, loss 0.14666970074176788, acc=0.9485555291175842, loss=0.14666970074176788
test: epoch 122, loss 0.5894609689712524, acc=0.8277778029441833, loss=0.5894609689712524
train: epoch 123, loss 0.16159114241600037, acc=0.9446666836738586, loss=0.16159114241600037
test: epoch 123, loss 0.5548033714294434, acc=0.8416666388511658, loss=0.5548033714294434
train: epoch 124, loss 0.1449497640132904, acc=0.9507222175598145, loss=0.1449497640132904
test: epoch 124, loss 0.5438383221626282, acc=0.824999988079071, loss=0.5438383221626282
train: epoch 125, loss 0.14804747700691223, acc=0.9505555629730225, loss=0.14804747700691223
test: epoch 125, loss 0.5654996633529663, acc=0.8333333134651184, loss=0.5654996633529663
train: epoch 126, loss 0.12721358239650726, acc=0.9555555582046509, loss=0.12721358239650726
test: epoch 126, loss 0.48638561367988586, acc=0.8277778029441833, loss=0.48638561367988586
train: epoch 127, loss 0.13585743308067322, acc=0.9535555839538574, loss=0.13585743308067322
test: epoch 127, loss 0.39540237188339233, acc=0.8166666626930237, loss=0.39540237188339233
train: epoch 128, loss 0.1437198668718338, acc=0.9513333439826965, loss=0.1437198668718338
test: epoch 128, loss 0.5416274070739746, acc=0.8222222328186035, loss=0.5416274070739746
train: epoch 129, loss 0.14160047471523285, acc=0.9515555500984192, loss=0.14160047471523285
test: epoch 129, loss 0.47993728518486023, acc=0.8500000238418579, loss=0.47993728518486023
train: epoch 130, loss 0.14742441475391388, acc=0.949833333492279, loss=0.14742441475391388
test: epoch 130, loss 0.42409074306488037, acc=0.8416666388511658, loss=0.42409074306488037
train: epoch 131, loss 0.14383845031261444, acc=0.9507222175598145, loss=0.14383845031261444
test: epoch 131, loss 0.47652801871299744, acc=0.8333333134651184, loss=0.47652801871299744
train: epoch 132, loss 0.1480502039194107, acc=0.9510555267333984, loss=0.1480502039194107
test: epoch 132, loss 0.47307446599006653, acc=0.8333333134651184, loss=0.47307446599006653
train: epoch 133, loss 0.13283219933509827, acc=0.9538333415985107, loss=0.13283219933509827
test: epoch 133, loss 0.4774865508079529, acc=0.8333333134651184, loss=0.4774865508079529
train: epoch 134, loss 0.12631261348724365, acc=0.9556666612625122, loss=0.12631261348724365
test: epoch 134, loss 0.4861479103565216, acc=0.8305555582046509, loss=0.4861479103565216
train: epoch 135, loss 0.1426258087158203, acc=0.9520000219345093, loss=0.1426258087158203
test: epoch 135, loss 0.5393891930580139, acc=0.8388888835906982, loss=0.5393891930580139
train: epoch 136, loss 0.1480911523103714, acc=0.9494444727897644, loss=0.1480911523103714
test: epoch 136, loss 0.5361484885215759, acc=0.824999988079071, loss=0.5361484885215759
train: epoch 137, loss 0.1346127837896347, acc=0.9528889060020447, loss=0.1346127837896347
test: epoch 137, loss 0.5467845797538757, acc=0.8333333134651184, loss=0.5467845797538757
train: epoch 138, loss 0.12380149960517883, acc=0.9578889012336731, loss=0.12380149960517883
test: epoch 138, loss 0.470597505569458, acc=0.8333333134651184, loss=0.470597505569458
train: epoch 139, loss 0.12411505728960037, acc=0.9588333368301392, loss=0.12411505728960037
test: epoch 139, loss 0.4791354537010193, acc=0.8277778029441833, loss=0.4791354537010193
train: epoch 140, loss 0.12440462410449982, acc=0.9580555558204651, loss=0.12440462410449982
test: epoch 140, loss 0.5548135638237, acc=0.8277778029441833, loss=0.5548135638237
train: epoch 141, loss 0.11949193477630615, acc=0.9588888883590698, loss=0.11949193477630615
test: epoch 141, loss 0.5393993854522705, acc=0.8333333134651184, loss=0.5393993854522705
train: epoch 142, loss 0.1262073963880539, acc=0.9560555815696716, loss=0.1262073963880539
test: epoch 142, loss 0.5293592810630798, acc=0.8333333134651184, loss=0.5293592810630798
train: epoch 143, loss 0.13441964983940125, acc=0.9535555839538574, loss=0.13441964983940125
test: epoch 143, loss 0.6011167764663696, acc=0.8333333134651184, loss=0.6011167764663696
train: epoch 144, loss 0.12056180834770203, acc=0.9578889012336731, loss=0.12056180834770203
test: epoch 144, loss 0.5042499899864197, acc=0.8416666388511658, loss=0.5042499899864197
train: epoch 145, loss 0.1324838250875473, acc=0.9527222514152527, loss=0.1324838250875473
test: epoch 145, loss 0.44675523042678833, acc=0.8333333134651184, loss=0.44675523042678833
train: epoch 146, loss 0.11969462037086487, acc=0.9570000171661377, loss=0.11969462037086487
test: epoch 146, loss 0.5665345788002014, acc=0.8277778029441833, loss=0.5665345788002014
train: epoch 147, loss 0.12533791363239288, acc=0.9555000066757202, loss=0.12533791363239288
test: epoch 147, loss 0.43397197127342224, acc=0.8305555582046509, loss=0.43397197127342224
train: epoch 148, loss 0.11955559253692627, acc=0.9591666460037231, loss=0.11955559253692627
test: epoch 148, loss 0.5154573917388916, acc=0.8333333134651184, loss=0.5154573917388916
train: epoch 149, loss 0.12546104192733765, acc=0.9578889012336731, loss=0.12546104192733765
test: epoch 149, loss 0.5114557147026062, acc=0.8361111283302307, loss=0.5114557147026062
train: epoch 150, loss 0.1162944808602333, acc=0.9613333344459534, loss=0.1162944808602333
test: epoch 150, loss 0.5235137939453125, acc=0.8277778029441833, loss=0.5235137939453125
