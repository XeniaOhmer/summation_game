# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=false", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=324170950, receiver_embed_dim=64, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.272132396697998, acc=0.06883333623409271, loss=3.272132396697998
test: epoch 1, loss 3.138739824295044, acc=0.09166666865348816, loss=3.138739824295044
train: epoch 2, loss 2.033182144165039, acc=0.2468888908624649, loss=2.033182144165039
test: epoch 2, loss 2.7511613368988037, acc=0.13055555522441864, loss=2.7511613368988037
train: epoch 3, loss 1.5705952644348145, acc=0.3684999942779541, loss=1.5705952644348145
test: epoch 3, loss 2.7194972038269043, acc=0.12777778506278992, loss=2.7194972038269043
train: epoch 4, loss 1.3843878507614136, acc=0.4387222230434418, loss=1.3843878507614136
test: epoch 4, loss 2.541149616241455, acc=0.1666666716337204, loss=2.541149616241455
train: epoch 5, loss 1.2748647928237915, acc=0.4841666519641876, loss=1.2748647928237915
test: epoch 5, loss 2.651127338409424, acc=0.15000000596046448, loss=2.651127338409424
train: epoch 6, loss 1.1854774951934814, acc=0.5220000147819519, loss=1.1854774951934814
test: epoch 6, loss 2.4487533569335938, acc=0.1805555522441864, loss=2.4487533569335938
train: epoch 7, loss 1.1117546558380127, acc=0.5534999966621399, loss=1.1117546558380127
test: epoch 7, loss 2.5816240310668945, acc=0.1944444477558136, loss=2.5816240310668945
train: epoch 8, loss 1.053161382675171, acc=0.5752221941947937, loss=1.053161382675171
test: epoch 8, loss 2.4402053356170654, acc=0.2083333283662796, loss=2.4402053356170654
train: epoch 9, loss 1.0052485466003418, acc=0.5995000004768372, loss=1.0052485466003418
test: epoch 9, loss 2.4207797050476074, acc=0.2222222238779068, loss=2.4207797050476074
train: epoch 10, loss 0.960861325263977, acc=0.6211666464805603, loss=0.960861325263977
test: epoch 10, loss 2.3503856658935547, acc=0.22499999403953552, loss=2.3503856658935547
train: epoch 11, loss 0.9164592623710632, acc=0.6412777900695801, loss=0.9164592623710632
test: epoch 11, loss 2.2967400550842285, acc=0.25833332538604736, loss=2.2967400550842285
train: epoch 12, loss 0.8816730380058289, acc=0.6532777547836304, loss=0.8816730380058289
test: epoch 12, loss 2.21846342086792, acc=0.26944443583488464, loss=2.21846342086792
train: epoch 13, loss 0.8522515892982483, acc=0.663277804851532, loss=0.8522515892982483
test: epoch 13, loss 2.1508123874664307, acc=0.27222222089767456, loss=2.1508123874664307
train: epoch 14, loss 0.8178911805152893, acc=0.683222234249115, loss=0.8178911805152893
test: epoch 14, loss 2.1654655933380127, acc=0.2805555462837219, loss=2.1654655933380127
train: epoch 15, loss 0.7917969226837158, acc=0.6907222270965576, loss=0.7917969226837158
test: epoch 15, loss 2.1043996810913086, acc=0.31111112236976624, loss=2.1043996810913086
train: epoch 16, loss 0.7577563524246216, acc=0.7118333578109741, loss=0.7577563524246216
test: epoch 16, loss 2.0920586585998535, acc=0.29722222685813904, loss=2.0920586585998535
train: epoch 17, loss 0.7428622841835022, acc=0.7123333215713501, loss=0.7428622841835022
test: epoch 17, loss 2.0321590900421143, acc=0.28611111640930176, loss=2.0321590900421143
train: epoch 18, loss 0.724227786064148, acc=0.7237222194671631, loss=0.724227786064148
test: epoch 18, loss 1.921614170074463, acc=0.3083333373069763, loss=1.921614170074463
train: epoch 19, loss 0.6923699378967285, acc=0.7340555787086487, loss=0.6923699378967285
test: epoch 19, loss 1.9802199602127075, acc=0.3166666626930237, loss=1.9802199602127075
train: epoch 20, loss 0.6802342534065247, acc=0.7369999885559082, loss=0.6802342534065247
test: epoch 20, loss 1.966080665588379, acc=0.3194444477558136, loss=1.966080665588379
train: epoch 21, loss 0.6435738801956177, acc=0.75, loss=0.6435738801956177
test: epoch 21, loss 1.970015525817871, acc=0.3499999940395355, loss=1.970015525817871
train: epoch 22, loss 0.6398972272872925, acc=0.7590000033378601, loss=0.6398972272872925
test: epoch 22, loss 1.9001797437667847, acc=0.3305555582046509, loss=1.9001797437667847
train: epoch 23, loss 0.6367812156677246, acc=0.7581666707992554, loss=0.6367812156677246
test: epoch 23, loss 1.803491473197937, acc=0.3472222089767456, loss=1.803491473197937
train: epoch 24, loss 0.6080127954483032, acc=0.7730000019073486, loss=0.6080127954483032
test: epoch 24, loss 1.902238368988037, acc=0.3361110985279083, loss=1.902238368988037
train: epoch 25, loss 0.5950301885604858, acc=0.7779444456100464, loss=0.5950301885604858
test: epoch 25, loss 1.768486738204956, acc=0.38333332538604736, loss=1.768486738204956
train: epoch 26, loss 0.5853665471076965, acc=0.7807222008705139, loss=0.5853665471076965
test: epoch 26, loss 1.818173885345459, acc=0.3861111104488373, loss=1.818173885345459
train: epoch 27, loss 0.5453657507896423, acc=0.788444459438324, loss=0.5453657507896423
test: epoch 27, loss 1.7366255521774292, acc=0.3888888955116272, loss=1.7366255521774292
train: epoch 28, loss 0.5414077639579773, acc=0.7932222485542297, loss=0.5414077639579773
test: epoch 28, loss 1.8226908445358276, acc=0.3888888955116272, loss=1.8226908445358276
train: epoch 29, loss 0.538232147693634, acc=0.7966111302375793, loss=0.538232147693634
test: epoch 29, loss 1.741814374923706, acc=0.39722222089767456, loss=1.741814374923706
train: epoch 30, loss 0.5224260091781616, acc=0.8046666383743286, loss=0.5224260091781616
test: epoch 30, loss 1.7039858102798462, acc=0.40833333134651184, loss=1.7039858102798462
train: epoch 31, loss 0.5158268809318542, acc=0.8084999918937683, loss=0.5158268809318542
test: epoch 31, loss 1.6062856912612915, acc=0.4055555462837219, loss=1.6062856912612915
train: epoch 32, loss 0.5086635947227478, acc=0.8078333139419556, loss=0.5086635947227478
test: epoch 32, loss 1.8335819244384766, acc=0.4194444417953491, loss=1.8335819244384766
train: epoch 33, loss 0.4897766709327698, acc=0.8162222504615784, loss=0.4897766709327698
test: epoch 33, loss 1.6303585767745972, acc=0.4027777910232544, loss=1.6303585767745972
train: epoch 34, loss 0.48868855834007263, acc=0.8157777786254883, loss=0.48868855834007263
test: epoch 34, loss 1.7609143257141113, acc=0.3888888955116272, loss=1.7609143257141113
train: epoch 35, loss 0.46990713477134705, acc=0.8257777690887451, loss=0.46990713477134705
test: epoch 35, loss 1.6837457418441772, acc=0.4027777910232544, loss=1.6837457418441772
train: epoch 36, loss 0.47075843811035156, acc=0.824055552482605, loss=0.47075843811035156
test: epoch 36, loss 1.6483100652694702, acc=0.42500001192092896, loss=1.6483100652694702
train: epoch 37, loss 0.4674254357814789, acc=0.8230555653572083, loss=0.4674254357814789
test: epoch 37, loss 1.6387388706207275, acc=0.4277777671813965, loss=1.6387388706207275
train: epoch 38, loss 0.4507529139518738, acc=0.8330000042915344, loss=0.4507529139518738
test: epoch 38, loss 1.7810797691345215, acc=0.42500001192092896, loss=1.7810797691345215
train: epoch 39, loss 0.4516953229904175, acc=0.8285555839538574, loss=0.4516953229904175
test: epoch 39, loss 1.6510899066925049, acc=0.4194444417953491, loss=1.6510899066925049
train: epoch 40, loss 0.4420701861381531, acc=0.8348888754844666, loss=0.4420701861381531
test: epoch 40, loss 1.6378486156463623, acc=0.4416666626930237, loss=1.6378486156463623
train: epoch 41, loss 0.43703147768974304, acc=0.8386111259460449, loss=0.43703147768974304
test: epoch 41, loss 1.7444485425949097, acc=0.43611112236976624, loss=1.7444485425949097
train: epoch 42, loss 0.42677122354507446, acc=0.8416110873222351, loss=0.42677122354507446
test: epoch 42, loss 1.6743730306625366, acc=0.43611112236976624, loss=1.6743730306625366
train: epoch 43, loss 0.4337006211280823, acc=0.8372777700424194, loss=0.4337006211280823
test: epoch 43, loss 1.8483588695526123, acc=0.41111111640930176, loss=1.8483588695526123
train: epoch 44, loss 0.41514459252357483, acc=0.8437222242355347, loss=0.41514459252357483
test: epoch 44, loss 1.6242599487304688, acc=0.43888887763023376, loss=1.6242599487304688
train: epoch 45, loss 0.4063960313796997, acc=0.846833348274231, loss=0.4063960313796997
test: epoch 45, loss 1.733123540878296, acc=0.4444444477558136, loss=1.733123540878296
train: epoch 46, loss 0.40532276034355164, acc=0.8503888845443726, loss=0.40532276034355164
test: epoch 46, loss 1.5956143140792847, acc=0.45277777314186096, loss=1.5956143140792847
train: epoch 47, loss 0.3975917398929596, acc=0.8538888692855835, loss=0.3975917398929596
test: epoch 47, loss 1.6305079460144043, acc=0.46666666865348816, loss=1.6305079460144043
train: epoch 48, loss 0.39092501997947693, acc=0.8570555448532104, loss=0.39092501997947693
test: epoch 48, loss 1.6093896627426147, acc=0.47777777910232544, loss=1.6093896627426147
train: epoch 49, loss 0.40030789375305176, acc=0.8525555729866028, loss=0.40030789375305176
test: epoch 49, loss 1.5268731117248535, acc=0.4749999940395355, loss=1.5268731117248535
train: epoch 50, loss 0.3806086480617523, acc=0.8618333339691162, loss=0.3806086480617523
test: epoch 50, loss 1.5138046741485596, acc=0.4722222089767456, loss=1.5138046741485596
train: epoch 51, loss 0.37880438566207886, acc=0.8629999756813049, loss=0.37880438566207886
test: epoch 51, loss 1.540175199508667, acc=0.4694444537162781, loss=1.540175199508667
train: epoch 52, loss 0.377700537443161, acc=0.8621110916137695, loss=0.377700537443161
test: epoch 52, loss 1.564860224723816, acc=0.4749999940395355, loss=1.564860224723816
train: epoch 53, loss 0.3787441849708557, acc=0.8597221970558167, loss=0.3787441849708557
test: epoch 53, loss 1.5772478580474854, acc=0.4722222089767456, loss=1.5772478580474854
train: epoch 54, loss 0.37652724981307983, acc=0.862500011920929, loss=0.37652724981307983
test: epoch 54, loss 1.6747466325759888, acc=0.4472222328186035, loss=1.6747466325759888
train: epoch 55, loss 0.36284109950065613, acc=0.8659444451332092, loss=0.36284109950065613
test: epoch 55, loss 1.5663199424743652, acc=0.4861111044883728, loss=1.5663199424743652
train: epoch 56, loss 0.3590877950191498, acc=0.8684999942779541, loss=0.3590877950191498
test: epoch 56, loss 1.4606939554214478, acc=0.5249999761581421, loss=1.4606939554214478
train: epoch 57, loss 0.35141900181770325, acc=0.8702777624130249, loss=0.35141900181770325
test: epoch 57, loss 1.5421377420425415, acc=0.49166667461395264, loss=1.5421377420425415
train: epoch 58, loss 0.3544699251651764, acc=0.8711666464805603, loss=0.3544699251651764
test: epoch 58, loss 1.8325964212417603, acc=0.49444442987442017, loss=1.8325964212417603
train: epoch 59, loss 0.35353338718414307, acc=0.8709999918937683, loss=0.35353338718414307
test: epoch 59, loss 1.7195340394973755, acc=0.4694444537162781, loss=1.7195340394973755
train: epoch 60, loss 0.3606589436531067, acc=0.8676666617393494, loss=0.3606589436531067
test: epoch 60, loss 1.5975896120071411, acc=0.5, loss=1.5975896120071411
train: epoch 61, loss 0.3534635603427887, acc=0.8697222471237183, loss=0.3534635603427887
test: epoch 61, loss 1.6784931421279907, acc=0.4972222149372101, loss=1.6784931421279907
train: epoch 62, loss 0.33373287320137024, acc=0.8771666884422302, loss=0.33373287320137024
test: epoch 62, loss 1.490027904510498, acc=0.519444465637207, loss=1.490027904510498
train: epoch 63, loss 0.3476483225822449, acc=0.8711666464805603, loss=0.3476483225822449
test: epoch 63, loss 1.6100715398788452, acc=0.5361111164093018, loss=1.6100715398788452
train: epoch 64, loss 0.3366815149784088, acc=0.8763889074325562, loss=0.3366815149784088
test: epoch 64, loss 1.6047409772872925, acc=0.4972222149372101, loss=1.6047409772872925
train: epoch 65, loss 0.34498336911201477, acc=0.8727777600288391, loss=0.34498336911201477
test: epoch 65, loss 1.4162694215774536, acc=0.5416666865348816, loss=1.4162694215774536
train: epoch 66, loss 0.33831852674484253, acc=0.8752777576446533, loss=0.33831852674484253
test: epoch 66, loss 1.4593400955200195, acc=0.5444444417953491, loss=1.4593400955200195
train: epoch 67, loss 0.33932504057884216, acc=0.8757777810096741, loss=0.33932504057884216
test: epoch 67, loss 1.6077229976654053, acc=0.5, loss=1.6077229976654053
train: epoch 68, loss 0.3366610109806061, acc=0.8752777576446533, loss=0.3366610109806061
test: epoch 68, loss 1.531838059425354, acc=0.519444465637207, loss=1.531838059425354
train: epoch 69, loss 0.3370571434497833, acc=0.8741666674613953, loss=0.3370571434497833
test: epoch 69, loss 1.5440500974655151, acc=0.5388888716697693, loss=1.5440500974655151
train: epoch 70, loss 0.32593536376953125, acc=0.878000020980835, loss=0.32593536376953125
test: epoch 70, loss 1.5368517637252808, acc=0.5222222208976746, loss=1.5368517637252808
train: epoch 71, loss 0.34035953879356384, acc=0.8759999871253967, loss=0.34035953879356384
test: epoch 71, loss 1.542597770690918, acc=0.5444444417953491, loss=1.542597770690918
train: epoch 72, loss 0.33856239914894104, acc=0.8760555386543274, loss=0.33856239914894104
test: epoch 72, loss 1.5158694982528687, acc=0.574999988079071, loss=1.5158694982528687
train: epoch 73, loss 0.33156102895736694, acc=0.8785555362701416, loss=0.33156102895736694
test: epoch 73, loss 1.550057291984558, acc=0.5583333373069763, loss=1.550057291984558
train: epoch 74, loss 0.3255300521850586, acc=0.8791666626930237, loss=0.3255300521850586
test: epoch 74, loss 1.4189658164978027, acc=0.5611110925674438, loss=1.4189658164978027
train: epoch 75, loss 0.3284841775894165, acc=0.8780555725097656, loss=0.3284841775894165
test: epoch 75, loss 1.3522619009017944, acc=0.5694444179534912, loss=1.3522619009017944
train: epoch 76, loss 0.324668824672699, acc=0.8812777996063232, loss=0.324668824672699
test: epoch 76, loss 1.550626277923584, acc=0.5805555582046509, loss=1.550626277923584
train: epoch 77, loss 0.33514314889907837, acc=0.878166675567627, loss=0.33514314889907837
test: epoch 77, loss 1.3945047855377197, acc=0.5527777671813965, loss=1.3945047855377197
train: epoch 78, loss 0.3225857615470886, acc=0.8792222142219543, loss=0.3225857615470886
test: epoch 78, loss 1.398840308189392, acc=0.5916666388511658, loss=1.398840308189392
train: epoch 79, loss 0.3279651701450348, acc=0.8790000081062317, loss=0.3279651701450348
test: epoch 79, loss 1.3929243087768555, acc=0.5972222089767456, loss=1.3929243087768555
train: epoch 80, loss 0.3159504532814026, acc=0.8836110830307007, loss=0.3159504532814026
test: epoch 80, loss 1.4388929605484009, acc=0.6111111044883728, loss=1.4388929605484009
train: epoch 81, loss 0.31519585847854614, acc=0.8838333487510681, loss=0.31519585847854614
test: epoch 81, loss 1.2699663639068604, acc=0.6277777552604675, loss=1.2699663639068604
train: epoch 82, loss 0.3328026235103607, acc=0.8767222166061401, loss=0.3328026235103607
test: epoch 82, loss 1.358086347579956, acc=0.6083333492279053, loss=1.358086347579956
train: epoch 83, loss 0.32019394636154175, acc=0.8791666626930237, loss=0.32019394636154175
test: epoch 83, loss 1.1437028646469116, acc=0.6166666746139526, loss=1.1437028646469116
train: epoch 84, loss 0.3105228543281555, acc=0.8834999799728394, loss=0.3105228543281555
test: epoch 84, loss 1.2479842901229858, acc=0.6277777552604675, loss=1.2479842901229858
train: epoch 85, loss 0.3173052668571472, acc=0.8870555758476257, loss=0.3173052668571472
test: epoch 85, loss 1.194710612297058, acc=0.6083333492279053, loss=1.194710612297058
train: epoch 86, loss 0.3141571581363678, acc=0.8853889107704163, loss=0.3141571581363678
test: epoch 86, loss 1.3601685762405396, acc=0.6277777552604675, loss=1.3601685762405396
train: epoch 87, loss 0.3142666220664978, acc=0.8852777481079102, loss=0.3142666220664978
test: epoch 87, loss 1.2451460361480713, acc=0.6305555701255798, loss=1.2451460361480713
train: epoch 88, loss 0.31587210297584534, acc=0.8825555443763733, loss=0.31587210297584534
test: epoch 88, loss 1.330176830291748, acc=0.6499999761581421, loss=1.330176830291748
train: epoch 89, loss 0.296835720539093, acc=0.8899444341659546, loss=0.296835720539093
test: epoch 89, loss 1.030981183052063, acc=0.6583333611488342, loss=1.030981183052063
train: epoch 90, loss 0.3059543967247009, acc=0.8883888721466064, loss=0.3059543967247009
test: epoch 90, loss 1.2611825466156006, acc=0.6527777910232544, loss=1.2611825466156006
train: epoch 91, loss 0.29839178919792175, acc=0.8896111249923706, loss=0.29839178919792175
test: epoch 91, loss 1.1632002592086792, acc=0.644444465637207, loss=1.1632002592086792
train: epoch 92, loss 0.2985406219959259, acc=0.8906111121177673, loss=0.2985406219959259
test: epoch 92, loss 1.267453670501709, acc=0.6555555462837219, loss=1.267453670501709
train: epoch 93, loss 0.3147699534893036, acc=0.8843888640403748, loss=0.3147699534893036
test: epoch 93, loss 1.1765996217727661, acc=0.6361111402511597, loss=1.1765996217727661
train: epoch 94, loss 0.301057904958725, acc=0.8883888721466064, loss=0.301057904958725
test: epoch 94, loss 1.1175158023834229, acc=0.6611111164093018, loss=1.1175158023834229
train: epoch 95, loss 0.3018462061882019, acc=0.890666663646698, loss=0.3018462061882019
test: epoch 95, loss 1.2212246656417847, acc=0.6555555462837219, loss=1.2212246656417847
train: epoch 96, loss 0.2949965298175812, acc=0.8914444446563721, loss=0.2949965298175812
test: epoch 96, loss 1.151360273361206, acc=0.6555555462837219, loss=1.151360273361206
train: epoch 97, loss 0.2971283197402954, acc=0.8893333077430725, loss=0.2971283197402954
test: epoch 97, loss 1.1825073957443237, acc=0.6583333611488342, loss=1.1825073957443237
train: epoch 98, loss 0.29542115330696106, acc=0.8901666402816772, loss=0.29542115330696106
test: epoch 98, loss 1.0959110260009766, acc=0.6499999761581421, loss=1.0959110260009766
train: epoch 99, loss 0.29330024123191833, acc=0.8867777585983276, loss=0.29330024123191833
test: epoch 99, loss 1.1020948886871338, acc=0.6416666507720947, loss=1.1020948886871338
train: epoch 100, loss 0.30180132389068604, acc=0.8880000114440918, loss=0.30180132389068604
test: epoch 100, loss 1.3009071350097656, acc=0.6611111164093018, loss=1.3009071350097656
train: epoch 101, loss 0.29286012053489685, acc=0.8901110887527466, loss=0.29286012053489685
test: epoch 101, loss 1.2933193445205688, acc=0.6499999761581421, loss=1.2933193445205688
train: epoch 102, loss 0.2852199077606201, acc=0.890500009059906, loss=0.2852199077606201
test: epoch 102, loss 1.2500100135803223, acc=0.6499999761581421, loss=1.2500100135803223
train: epoch 103, loss 0.30029210448265076, acc=0.8861111402511597, loss=0.30029210448265076
test: epoch 103, loss 1.1666561365127563, acc=0.6499999761581421, loss=1.1666561365127563
train: epoch 104, loss 0.2927189767360687, acc=0.8897777795791626, loss=0.2927189767360687
test: epoch 104, loss 1.179776668548584, acc=0.6666666865348816, loss=1.179776668548584
train: epoch 105, loss 0.2952224612236023, acc=0.8899444341659546, loss=0.2952224612236023
test: epoch 105, loss 1.2099931240081787, acc=0.6499999761581421, loss=1.2099931240081787
train: epoch 106, loss 0.30039358139038086, acc=0.8902222514152527, loss=0.30039358139038086
test: epoch 106, loss 1.084883689880371, acc=0.6583333611488342, loss=1.084883689880371
train: epoch 107, loss 0.28441622853279114, acc=0.8898888826370239, loss=0.28441622853279114
test: epoch 107, loss 1.072580337524414, acc=0.6555555462837219, loss=1.072580337524414
train: epoch 108, loss 0.2907845079898834, acc=0.8884444236755371, loss=0.2907845079898834
test: epoch 108, loss 1.0364505052566528, acc=0.6694444417953491, loss=1.0364505052566528
train: epoch 109, loss 0.29604822397232056, acc=0.8866666555404663, loss=0.29604822397232056
test: epoch 109, loss 0.9500246047973633, acc=0.6694444417953491, loss=0.9500246047973633
train: epoch 110, loss 0.2887183427810669, acc=0.8899444341659546, loss=0.2887183427810669
test: epoch 110, loss 1.1830151081085205, acc=0.6666666865348816, loss=1.1830151081085205
train: epoch 111, loss 0.291106641292572, acc=0.8905555605888367, loss=0.291106641292572
test: epoch 111, loss 1.0165228843688965, acc=0.6666666865348816, loss=1.0165228843688965
train: epoch 112, loss 0.2996349036693573, acc=0.8865000009536743, loss=0.2996349036693573
test: epoch 112, loss 0.9743973016738892, acc=0.6805555820465088, loss=0.9743973016738892
train: epoch 113, loss 0.3092840015888214, acc=0.8836666941642761, loss=0.3092840015888214
test: epoch 113, loss 1.1201529502868652, acc=0.6694444417953491, loss=1.1201529502868652
train: epoch 114, loss 0.28037869930267334, acc=0.8926666378974915, loss=0.28037869930267334
test: epoch 114, loss 1.112424373626709, acc=0.6666666865348816, loss=1.112424373626709
train: epoch 115, loss 0.28882545232772827, acc=0.8882222175598145, loss=0.28882545232772827
test: epoch 115, loss 0.897778332233429, acc=0.6777777671813965, loss=0.897778332233429
train: epoch 116, loss 0.2955404222011566, acc=0.8902778029441833, loss=0.2955404222011566
test: epoch 116, loss 1.0157049894332886, acc=0.6722221970558167, loss=1.0157049894332886
train: epoch 117, loss 0.29415440559387207, acc=0.8900555372238159, loss=0.29415440559387207
test: epoch 117, loss 0.9427833557128906, acc=0.6777777671813965, loss=0.9427833557128906
train: epoch 118, loss 0.28817296028137207, acc=0.8889999985694885, loss=0.28817296028137207
test: epoch 118, loss 0.9691708087921143, acc=0.675000011920929, loss=0.9691708087921143
train: epoch 119, loss 0.2840205430984497, acc=0.8920000195503235, loss=0.2840205430984497
test: epoch 119, loss 1.1294329166412354, acc=0.6833333373069763, loss=1.1294329166412354
train: epoch 120, loss 0.29118165373802185, acc=0.8891666531562805, loss=0.29118165373802185
test: epoch 120, loss 1.0960549116134644, acc=0.6611111164093018, loss=1.0960549116134644
train: epoch 121, loss 0.3041154444217682, acc=0.886888861656189, loss=0.3041154444217682
test: epoch 121, loss 1.063839077949524, acc=0.6833333373069763, loss=1.063839077949524
train: epoch 122, loss 0.29185596108436584, acc=0.8877778053283691, loss=0.29185596108436584
test: epoch 122, loss 1.0919389724731445, acc=0.6888889074325562, loss=1.0919389724731445
train: epoch 123, loss 0.28945785760879517, acc=0.8880000114440918, loss=0.28945785760879517
test: epoch 123, loss 0.9238041639328003, acc=0.6777777671813965, loss=0.9238041639328003
train: epoch 124, loss 0.30101266503334045, acc=0.8871666789054871, loss=0.30101266503334045
test: epoch 124, loss 1.0119290351867676, acc=0.6638888716697693, loss=1.0119290351867676
train: epoch 125, loss 0.2879403233528137, acc=0.8906111121177673, loss=0.2879403233528137
test: epoch 125, loss 1.0535318851470947, acc=0.6805555820465088, loss=1.0535318851470947
train: epoch 126, loss 0.30870920419692993, acc=0.8842222094535828, loss=0.30870920419692993
test: epoch 126, loss 1.0079072713851929, acc=0.675000011920929, loss=1.0079072713851929
train: epoch 127, loss 0.29533660411834717, acc=0.8842777609825134, loss=0.29533660411834717
test: epoch 127, loss 0.9966558218002319, acc=0.6833333373069763, loss=0.9966558218002319
train: epoch 128, loss 0.2928484082221985, acc=0.886222243309021, loss=0.2928484082221985
test: epoch 128, loss 1.0113753080368042, acc=0.675000011920929, loss=1.0113753080368042
train: epoch 129, loss 0.3002317547798157, acc=0.8842777609825134, loss=0.3002317547798157
test: epoch 129, loss 0.9722999930381775, acc=0.6833333373069763, loss=0.9722999930381775
train: epoch 130, loss 0.29835522174835205, acc=0.8872222304344177, loss=0.29835522174835205
test: epoch 130, loss 1.1393439769744873, acc=0.6527777910232544, loss=1.1393439769744873
train: epoch 131, loss 0.31263604760169983, acc=0.8818333148956299, loss=0.31263604760169983
test: epoch 131, loss 0.9388452768325806, acc=0.675000011920929, loss=0.9388452768325806
train: epoch 132, loss 0.2926996648311615, acc=0.8846111297607422, loss=0.2926996648311615
test: epoch 132, loss 1.0824880599975586, acc=0.6722221970558167, loss=1.0824880599975586
train: epoch 133, loss 0.3066413700580597, acc=0.8840555548667908, loss=0.3066413700580597
test: epoch 133, loss 1.0433646440505981, acc=0.6805555820465088, loss=1.0433646440505981
train: epoch 134, loss 0.3009575605392456, acc=0.882111132144928, loss=0.3009575605392456
test: epoch 134, loss 0.937760591506958, acc=0.6944444179534912, loss=0.937760591506958
train: epoch 135, loss 0.28838950395584106, acc=0.8830000162124634, loss=0.28838950395584106
test: epoch 135, loss 1.045825719833374, acc=0.6833333373069763, loss=1.045825719833374
train: epoch 136, loss 0.3069036602973938, acc=0.8811110854148865, loss=0.3069036602973938
test: epoch 136, loss 0.9356127381324768, acc=0.6805555820465088, loss=0.9356127381324768
train: epoch 137, loss 0.2966039478778839, acc=0.8860555291175842, loss=0.2966039478778839
test: epoch 137, loss 0.9974992871284485, acc=0.6833333373069763, loss=0.9974992871284485
train: epoch 138, loss 0.29295700788497925, acc=0.8865000009536743, loss=0.29295700788497925
test: epoch 138, loss 0.9219853281974792, acc=0.675000011920929, loss=0.9219853281974792
train: epoch 139, loss 0.29759660363197327, acc=0.8851666450500488, loss=0.29759660363197327
test: epoch 139, loss 0.9711644649505615, acc=0.6611111164093018, loss=0.9711644649505615
train: epoch 140, loss 0.30367788672447205, acc=0.8838333487510681, loss=0.30367788672447205
test: epoch 140, loss 0.981307327747345, acc=0.6916666626930237, loss=0.981307327747345
train: epoch 141, loss 0.29395774006843567, acc=0.8869444727897644, loss=0.29395774006843567
test: epoch 141, loss 0.961766242980957, acc=0.6666666865348816, loss=0.961766242980957
train: epoch 142, loss 0.28364720940589905, acc=0.887333333492279, loss=0.28364720940589905
test: epoch 142, loss 0.9597722887992859, acc=0.6777777671813965, loss=0.9597722887992859
train: epoch 143, loss 0.2999241352081299, acc=0.8845555782318115, loss=0.2999241352081299
test: epoch 143, loss 0.8616049289703369, acc=0.6861110925674438, loss=0.8616049289703369
train: epoch 144, loss 0.2998887300491333, acc=0.8802222013473511, loss=0.2998887300491333
test: epoch 144, loss 1.101142168045044, acc=0.6833333373069763, loss=1.101142168045044
train: epoch 145, loss 0.2857052683830261, acc=0.8877221941947937, loss=0.2857052683830261
test: epoch 145, loss 1.0581365823745728, acc=0.6805555820465088, loss=1.0581365823745728
train: epoch 146, loss 0.2800440788269043, acc=0.8887222409248352, loss=0.2800440788269043
test: epoch 146, loss 1.1193852424621582, acc=0.6722221970558167, loss=1.1193852424621582
train: epoch 147, loss 0.28711700439453125, acc=0.8892222046852112, loss=0.28711700439453125
test: epoch 147, loss 1.063156247138977, acc=0.675000011920929, loss=1.063156247138977
train: epoch 148, loss 0.3017517626285553, acc=0.8839444518089294, loss=0.3017517626285553
test: epoch 148, loss 1.0957635641098022, acc=0.6888889074325562, loss=1.0957635641098022
train: epoch 149, loss 0.2916288375854492, acc=0.8844444155693054, loss=0.2916288375854492
test: epoch 149, loss 1.0016860961914062, acc=0.675000011920929, loss=1.0016860961914062
train: epoch 150, loss 0.282682865858078, acc=0.8893333077430725, loss=0.282682865858078
test: epoch 150, loss 0.9451582431793213, acc=0.6611111164093018, loss=0.9451582431793213
