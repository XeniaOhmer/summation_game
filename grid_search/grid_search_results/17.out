# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1", "--temp_decay=0.99", "--one_hot=false", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=287281698, receiver_embed_dim=32, temp_decay=0.99, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.1920621395111084, acc=0.06438888609409332, loss=3.1920621395111084
test: epoch 1, loss 2.854688882827759, acc=0.09444444626569748, loss=2.854688882827759
train: epoch 2, loss 2.492433786392212, acc=0.13927777111530304, loss=2.492433786392212
test: epoch 2, loss 2.3905749320983887, acc=0.14722222089767456, loss=2.3905749320983887
train: epoch 3, loss 2.1021060943603516, acc=0.20622222125530243, loss=2.1021060943603516
test: epoch 3, loss 2.3577375411987305, acc=0.17222222685813904, loss=2.3577375411987305
train: epoch 4, loss 1.8634787797927856, acc=0.2602222263813019, loss=1.8634787797927856
test: epoch 4, loss 2.1947906017303467, acc=0.18888889253139496, loss=2.1947906017303467
train: epoch 5, loss 1.6863412857055664, acc=0.3188333213329315, loss=1.6863412857055664
test: epoch 5, loss 2.1319804191589355, acc=0.22777777910232544, loss=2.1319804191589355
train: epoch 6, loss 1.5235371589660645, acc=0.370888888835907, loss=1.5235371589660645
test: epoch 6, loss 1.9904330968856812, acc=0.26944443583488464, loss=1.9904330968856812
train: epoch 7, loss 1.361771821975708, acc=0.42372220754623413, loss=1.361771821975708
test: epoch 7, loss 1.7752553224563599, acc=0.29722222685813904, loss=1.7752553224563599
train: epoch 8, loss 1.2871249914169312, acc=0.4502222239971161, loss=1.2871249914169312
test: epoch 8, loss 1.8276180028915405, acc=0.32499998807907104, loss=1.8276180028915405
train: epoch 9, loss 1.2140260934829712, acc=0.4742777645587921, loss=1.2140260934829712
test: epoch 9, loss 1.9283875226974487, acc=0.32499998807907104, loss=1.9283875226974487
train: epoch 10, loss 1.1583033800125122, acc=0.492000013589859, loss=1.1583033800125122
test: epoch 10, loss 1.590191125869751, acc=0.3444444537162781, loss=1.590191125869751
train: epoch 11, loss 1.1214572191238403, acc=0.504111111164093, loss=1.1214572191238403
test: epoch 11, loss 1.8105008602142334, acc=0.3444444537162781, loss=1.8105008602142334
train: epoch 12, loss 1.0829055309295654, acc=0.5176666378974915, loss=1.0829055309295654
test: epoch 12, loss 1.8316810131072998, acc=0.3611111044883728, loss=1.8316810131072998
train: epoch 13, loss 1.0309277772903442, acc=0.5325000286102295, loss=1.0309277772903442
test: epoch 13, loss 1.6059740781784058, acc=0.38055557012557983, loss=1.6059740781784058
train: epoch 14, loss 1.0292876958847046, acc=0.5325000286102295, loss=1.0292876958847046
test: epoch 14, loss 1.866986632347107, acc=0.3499999940395355, loss=1.866986632347107
train: epoch 15, loss 1.0123785734176636, acc=0.5367777943611145, loss=1.0123785734176636
test: epoch 15, loss 1.7988193035125732, acc=0.36944442987442017, loss=1.7988193035125732
train: epoch 16, loss 0.9973132610321045, acc=0.5406666398048401, loss=0.9973132610321045
test: epoch 16, loss 1.7654609680175781, acc=0.3722222149372101, loss=1.7654609680175781
train: epoch 17, loss 0.9918079972267151, acc=0.5478333234786987, loss=0.9918079972267151
test: epoch 17, loss 1.6591325998306274, acc=0.3499999940395355, loss=1.6591325998306274
train: epoch 18, loss 0.993700385093689, acc=0.5459444522857666, loss=0.993700385093689
test: epoch 18, loss 1.6627485752105713, acc=0.39722222089767456, loss=1.6627485752105713
train: epoch 19, loss 0.9796356558799744, acc=0.5492222309112549, loss=0.9796356558799744
test: epoch 19, loss 1.5146523714065552, acc=0.4138889014720917, loss=1.5146523714065552
train: epoch 20, loss 0.9724584221839905, acc=0.5522222518920898, loss=0.9724584221839905
test: epoch 20, loss 1.4585142135620117, acc=0.40833333134651184, loss=1.4585142135620117
train: epoch 21, loss 0.9488973617553711, acc=0.5610555410385132, loss=0.9488973617553711
test: epoch 21, loss 1.5769283771514893, acc=0.4055555462837219, loss=1.5769283771514893
train: epoch 22, loss 0.9886288642883301, acc=0.5481111407279968, loss=0.9886288642883301
test: epoch 22, loss 1.728458046913147, acc=0.4055555462837219, loss=1.728458046913147
train: epoch 23, loss 0.9614048600196838, acc=0.5635555386543274, loss=0.9614048600196838
test: epoch 23, loss 1.4189258813858032, acc=0.4166666567325592, loss=1.4189258813858032
train: epoch 24, loss 0.9415077567100525, acc=0.577833354473114, loss=0.9415077567100525
test: epoch 24, loss 1.5565111637115479, acc=0.41111111640930176, loss=1.5565111637115479
train: epoch 25, loss 0.9154750108718872, acc=0.5831111073493958, loss=0.9154750108718872
test: epoch 25, loss 1.445534348487854, acc=0.4333333373069763, loss=1.445534348487854
train: epoch 26, loss 0.9125895500183105, acc=0.5830555558204651, loss=0.9125895500183105
test: epoch 26, loss 1.3648704290390015, acc=0.4166666567325592, loss=1.3648704290390015
train: epoch 27, loss 0.9198781847953796, acc=0.5876111388206482, loss=0.9198781847953796
test: epoch 27, loss 1.4593979120254517, acc=0.4138889014720917, loss=1.4593979120254517
train: epoch 28, loss 0.9219611883163452, acc=0.5856666564941406, loss=0.9219611883163452
test: epoch 28, loss 1.4746280908584595, acc=0.41111111640930176, loss=1.4746280908584595
train: epoch 29, loss 0.9461339712142944, acc=0.5752778053283691, loss=0.9461339712142944
test: epoch 29, loss 1.4709744453430176, acc=0.43888887763023376, loss=1.4709744453430176
train: epoch 30, loss 0.9013013243675232, acc=0.5926111340522766, loss=0.9013013243675232
test: epoch 30, loss 1.45242178440094, acc=0.43888887763023376, loss=1.45242178440094
train: epoch 31, loss 0.9113290309906006, acc=0.5952222347259521, loss=0.9113290309906006
test: epoch 31, loss 1.4033164978027344, acc=0.4416666626930237, loss=1.4033164978027344
train: epoch 32, loss 0.8740143775939941, acc=0.612333357334137, loss=0.8740143775939941
test: epoch 32, loss 1.437657356262207, acc=0.4416666626930237, loss=1.437657356262207
train: epoch 33, loss 0.862722635269165, acc=0.6157777905464172, loss=0.862722635269165
test: epoch 33, loss 1.338315725326538, acc=0.43888887763023376, loss=1.338315725326538
train: epoch 34, loss 0.8654667139053345, acc=0.6113888621330261, loss=0.8654667139053345
test: epoch 34, loss 1.3479416370391846, acc=0.4444444477558136, loss=1.3479416370391846
train: epoch 35, loss 0.8708774447441101, acc=0.6181666851043701, loss=0.8708774447441101
test: epoch 35, loss 1.4572484493255615, acc=0.44999998807907104, loss=1.4572484493255615
train: epoch 36, loss 0.861659049987793, acc=0.6172778010368347, loss=0.861659049987793
test: epoch 36, loss 1.56327486038208, acc=0.45277777314186096, loss=1.56327486038208
train: epoch 37, loss 0.8477773666381836, acc=0.6209444403648376, loss=0.8477773666381836
test: epoch 37, loss 1.4303131103515625, acc=0.4416666626930237, loss=1.4303131103515625
train: epoch 38, loss 0.8279854655265808, acc=0.6257777810096741, loss=0.8279854655265808
test: epoch 38, loss 1.440875768661499, acc=0.45277777314186096, loss=1.440875768661499
train: epoch 39, loss 0.8581938743591309, acc=0.6192222237586975, loss=0.8581938743591309
test: epoch 39, loss 1.353826880455017, acc=0.45277777314186096, loss=1.353826880455017
train: epoch 40, loss 0.8432890772819519, acc=0.6231666803359985, loss=0.8432890772819519
test: epoch 40, loss 1.3262803554534912, acc=0.45277777314186096, loss=1.3262803554534912
train: epoch 41, loss 0.837466835975647, acc=0.6268333196640015, loss=0.837466835975647
test: epoch 41, loss 1.3765617609024048, acc=0.4333333373069763, loss=1.3765617609024048
train: epoch 42, loss 0.8388165831565857, acc=0.6261666417121887, loss=0.8388165831565857
test: epoch 42, loss 1.4300888776779175, acc=0.45277777314186096, loss=1.4300888776779175
train: epoch 43, loss 0.8296279907226562, acc=0.6290000081062317, loss=0.8296279907226562
test: epoch 43, loss 1.5280673503875732, acc=0.44999998807907104, loss=1.5280673503875732
train: epoch 44, loss 0.8001556396484375, acc=0.6375555396080017, loss=0.8001556396484375
test: epoch 44, loss 1.5022871494293213, acc=0.44999998807907104, loss=1.5022871494293213
train: epoch 45, loss 0.8155940175056458, acc=0.6345555782318115, loss=0.8155940175056458
test: epoch 45, loss 1.3412646055221558, acc=0.45277777314186096, loss=1.3412646055221558
train: epoch 46, loss 0.8448765873908997, acc=0.6281111240386963, loss=0.8448765873908997
test: epoch 46, loss 1.4061981439590454, acc=0.45277777314186096, loss=1.4061981439590454
train: epoch 47, loss 0.8193264007568359, acc=0.6392222046852112, loss=0.8193264007568359
test: epoch 47, loss 1.3459855318069458, acc=0.4555555582046509, loss=1.3459855318069458
train: epoch 48, loss 0.7993960380554199, acc=0.6494444608688354, loss=0.7993960380554199
test: epoch 48, loss 1.4014815092086792, acc=0.4444444477558136, loss=1.4014815092086792
train: epoch 49, loss 0.768802285194397, acc=0.6596111059188843, loss=0.768802285194397
test: epoch 49, loss 1.3474442958831787, acc=0.45277777314186096, loss=1.3474442958831787
train: epoch 50, loss 0.7743993997573853, acc=0.6578888893127441, loss=0.7743993997573853
test: epoch 50, loss 1.3795416355133057, acc=0.4555555582046509, loss=1.3795416355133057
train: epoch 51, loss 0.7869526147842407, acc=0.6511111259460449, loss=0.7869526147842407
test: epoch 51, loss 1.5196415185928345, acc=0.4583333432674408, loss=1.5196415185928345
train: epoch 52, loss 0.7917724847793579, acc=0.6498888731002808, loss=0.7917724847793579
test: epoch 52, loss 1.4541327953338623, acc=0.4583333432674408, loss=1.4541327953338623
train: epoch 53, loss 0.8218609690666199, acc=0.6302777528762817, loss=0.8218609690666199
test: epoch 53, loss 1.255861759185791, acc=0.4555555582046509, loss=1.255861759185791
train: epoch 54, loss 0.7441872358322144, acc=0.6652222275733948, loss=0.7441872358322144
test: epoch 54, loss 1.3482654094696045, acc=0.45277777314186096, loss=1.3482654094696045
train: epoch 55, loss 0.804344117641449, acc=0.6420555710792542, loss=0.804344117641449
test: epoch 55, loss 1.2567698955535889, acc=0.4555555582046509, loss=1.2567698955535889
train: epoch 56, loss 0.7952209711074829, acc=0.6375555396080017, loss=0.7952209711074829
test: epoch 56, loss 1.2488452196121216, acc=0.4555555582046509, loss=1.2488452196121216
train: epoch 57, loss 0.7657638788223267, acc=0.6558333039283752, loss=0.7657638788223267
test: epoch 57, loss 1.2912954092025757, acc=0.4555555582046509, loss=1.2912954092025757
train: epoch 58, loss 0.7578035593032837, acc=0.6617777943611145, loss=0.7578035593032837
test: epoch 58, loss 1.3589894771575928, acc=0.45277777314186096, loss=1.3589894771575928
train: epoch 59, loss 0.7609130144119263, acc=0.6601666808128357, loss=0.7609130144119263
test: epoch 59, loss 1.2551547288894653, acc=0.4555555582046509, loss=1.2551547288894653
train: epoch 60, loss 0.7711103558540344, acc=0.6552222371101379, loss=0.7711103558540344
test: epoch 60, loss 1.4592719078063965, acc=0.4555555582046509, loss=1.4592719078063965
train: epoch 61, loss 0.7606362700462341, acc=0.651888906955719, loss=0.7606362700462341
test: epoch 61, loss 1.3433068990707397, acc=0.4555555582046509, loss=1.3433068990707397
train: epoch 62, loss 0.7466580867767334, acc=0.6672222018241882, loss=0.7466580867767334
test: epoch 62, loss 1.387407660484314, acc=0.4555555582046509, loss=1.387407660484314
train: epoch 63, loss 0.7751907110214233, acc=0.653333306312561, loss=0.7751907110214233
test: epoch 63, loss 1.5278202295303345, acc=0.4555555582046509, loss=1.5278202295303345
train: epoch 64, loss 0.7657093405723572, acc=0.663277804851532, loss=0.7657093405723572
test: epoch 64, loss 1.4408637285232544, acc=0.4555555582046509, loss=1.4408637285232544
train: epoch 65, loss 0.7615514397621155, acc=0.6588888764381409, loss=0.7615514397621155
test: epoch 65, loss 1.4826058149337769, acc=0.4555555582046509, loss=1.4826058149337769
train: epoch 66, loss 0.7459405660629272, acc=0.6638333201408386, loss=0.7459405660629272
test: epoch 66, loss 1.351507306098938, acc=0.4555555582046509, loss=1.351507306098938
train: epoch 67, loss 0.7359310388565063, acc=0.6722777485847473, loss=0.7359310388565063
test: epoch 67, loss 1.5572906732559204, acc=0.4555555582046509, loss=1.5572906732559204
train: epoch 68, loss 0.7450382709503174, acc=0.6708333492279053, loss=0.7450382709503174
test: epoch 68, loss 1.4502862691879272, acc=0.4555555582046509, loss=1.4502862691879272
train: epoch 69, loss 0.7495518326759338, acc=0.667722225189209, loss=0.7495518326759338
test: epoch 69, loss 1.3479572534561157, acc=0.4555555582046509, loss=1.3479572534561157
train: epoch 70, loss 0.7375645637512207, acc=0.6699444651603699, loss=0.7375645637512207
test: epoch 70, loss 1.5081851482391357, acc=0.4555555582046509, loss=1.5081851482391357
train: epoch 71, loss 0.743028461933136, acc=0.6701111197471619, loss=0.743028461933136
test: epoch 71, loss 1.3330169916152954, acc=0.4555555582046509, loss=1.3330169916152954
train: epoch 72, loss 0.7416860461235046, acc=0.667722225189209, loss=0.7416860461235046
test: epoch 72, loss 1.3012254238128662, acc=0.4555555582046509, loss=1.3012254238128662
train: epoch 73, loss 0.7597772479057312, acc=0.6613888740539551, loss=0.7597772479057312
test: epoch 73, loss 1.4654711484909058, acc=0.4444444477558136, loss=1.4654711484909058
train: epoch 74, loss 0.7511558532714844, acc=0.6668333411216736, loss=0.7511558532714844
test: epoch 74, loss 1.2829782962799072, acc=0.4583333432674408, loss=1.2829782962799072
train: epoch 75, loss 0.7455528974533081, acc=0.6667222380638123, loss=0.7455528974533081
test: epoch 75, loss 1.3391938209533691, acc=0.4555555582046509, loss=1.3391938209533691
train: epoch 76, loss 0.7500430941581726, acc=0.6614444255828857, loss=0.7500430941581726
test: epoch 76, loss 1.3914440870285034, acc=0.4555555582046509, loss=1.3914440870285034
train: epoch 77, loss 0.7229834198951721, acc=0.6773333549499512, loss=0.7229834198951721
test: epoch 77, loss 1.354465126991272, acc=0.4555555582046509, loss=1.354465126991272
train: epoch 78, loss 0.7308449745178223, acc=0.6750555634498596, loss=0.7308449745178223
test: epoch 78, loss 1.424530267715454, acc=0.4555555582046509, loss=1.424530267715454
train: epoch 79, loss 0.725329577922821, acc=0.6758333444595337, loss=0.725329577922821
test: epoch 79, loss 1.4652971029281616, acc=0.4555555582046509, loss=1.4652971029281616
train: epoch 80, loss 0.7351821064949036, acc=0.6726666688919067, loss=0.7351821064949036
test: epoch 80, loss 1.4079524278640747, acc=0.4555555582046509, loss=1.4079524278640747
train: epoch 81, loss 0.7359333038330078, acc=0.675777792930603, loss=0.7359333038330078
test: epoch 81, loss 1.3923404216766357, acc=0.4555555582046509, loss=1.3923404216766357
train: epoch 82, loss 0.766703724861145, acc=0.6642777919769287, loss=0.766703724861145
test: epoch 82, loss 1.3377447128295898, acc=0.4555555582046509, loss=1.3377447128295898
train: epoch 83, loss 0.7150595784187317, acc=0.679888904094696, loss=0.7150595784187317
test: epoch 83, loss 1.4679055213928223, acc=0.45277777314186096, loss=1.4679055213928223
train: epoch 84, loss 0.7442396879196167, acc=0.6699444651603699, loss=0.7442396879196167
test: epoch 84, loss 1.4422017335891724, acc=0.45277777314186096, loss=1.4422017335891724
train: epoch 85, loss 0.7385442852973938, acc=0.6721110939979553, loss=0.7385442852973938
test: epoch 85, loss 1.3400799036026, acc=0.4555555582046509, loss=1.3400799036026
train: epoch 86, loss 0.7331553101539612, acc=0.6732222437858582, loss=0.7331553101539612
test: epoch 86, loss 1.4479024410247803, acc=0.4555555582046509, loss=1.4479024410247803
train: epoch 87, loss 0.749542772769928, acc=0.6664999723434448, loss=0.749542772769928
test: epoch 87, loss 1.3685791492462158, acc=0.4555555582046509, loss=1.3685791492462158
train: epoch 88, loss 0.7314559817314148, acc=0.6734444499015808, loss=0.7314559817314148
test: epoch 88, loss 1.4076014757156372, acc=0.45277777314186096, loss=1.4076014757156372
train: epoch 89, loss 0.7486205697059631, acc=0.6672777533531189, loss=0.7486205697059631
test: epoch 89, loss 1.3948851823806763, acc=0.4555555582046509, loss=1.3948851823806763
train: epoch 90, loss 0.7288746237754822, acc=0.6761666536331177, loss=0.7288746237754822
test: epoch 90, loss 1.3262183666229248, acc=0.4555555582046509, loss=1.3262183666229248
train: epoch 91, loss 0.7318741679191589, acc=0.6741666793823242, loss=0.7318741679191589
test: epoch 91, loss 1.4802851676940918, acc=0.4555555582046509, loss=1.4802851676940918
train: epoch 92, loss 0.7121223211288452, acc=0.6812222003936768, loss=0.7121223211288452
test: epoch 92, loss 1.44698965549469, acc=0.4555555582046509, loss=1.44698965549469
train: epoch 93, loss 0.7388836741447449, acc=0.6721110939979553, loss=0.7388836741447449
test: epoch 93, loss 1.3408071994781494, acc=0.45277777314186096, loss=1.3408071994781494
train: epoch 94, loss 0.7078273296356201, acc=0.6795555353164673, loss=0.7078273296356201
test: epoch 94, loss 1.5192312002182007, acc=0.4555555582046509, loss=1.5192312002182007
train: epoch 95, loss 0.7374778389930725, acc=0.6725000143051147, loss=0.7374778389930725
test: epoch 95, loss 1.420074701309204, acc=0.4555555582046509, loss=1.420074701309204
train: epoch 96, loss 0.7225695252418518, acc=0.6788889169692993, loss=0.7225695252418518
test: epoch 96, loss 1.4347976446151733, acc=0.4555555582046509, loss=1.4347976446151733
train: epoch 97, loss 0.7118735909461975, acc=0.6823889017105103, loss=0.7118735909461975
test: epoch 97, loss 1.526289463043213, acc=0.4555555582046509, loss=1.526289463043213
train: epoch 98, loss 0.7113686800003052, acc=0.6825000047683716, loss=0.7113686800003052
test: epoch 98, loss 1.512353539466858, acc=0.4555555582046509, loss=1.512353539466858
train: epoch 99, loss 0.7331003546714783, acc=0.6740555763244629, loss=0.7331003546714783
test: epoch 99, loss 1.4709011316299438, acc=0.4416666626930237, loss=1.4709011316299438
train: epoch 100, loss 0.7133781909942627, acc=0.6760555505752563, loss=0.7133781909942627
test: epoch 100, loss 1.4193331003189087, acc=0.45277777314186096, loss=1.4193331003189087
train: epoch 101, loss 0.7284439206123352, acc=0.6722221970558167, loss=0.7284439206123352
test: epoch 101, loss 1.3520243167877197, acc=0.4555555582046509, loss=1.3520243167877197
train: epoch 102, loss 0.7111493945121765, acc=0.6812222003936768, loss=0.7111493945121765
test: epoch 102, loss 1.416867971420288, acc=0.44999998807907104, loss=1.416867971420288
train: epoch 103, loss 0.7289406657218933, acc=0.6761666536331177, loss=0.7289406657218933
test: epoch 103, loss 1.3781242370605469, acc=0.4555555582046509, loss=1.3781242370605469
train: epoch 104, loss 0.7057482004165649, acc=0.6822222471237183, loss=0.7057482004165649
test: epoch 104, loss 1.504160761833191, acc=0.4555555582046509, loss=1.504160761833191
train: epoch 105, loss 0.7155389785766602, acc=0.6802777647972107, loss=0.7155389785766602
test: epoch 105, loss 1.5668613910675049, acc=0.4555555582046509, loss=1.5668613910675049
train: epoch 106, loss 0.7530849575996399, acc=0.6685000061988831, loss=0.7530849575996399
test: epoch 106, loss 1.2478692531585693, acc=0.45277777314186096, loss=1.2478692531585693
train: epoch 107, loss 0.7262269854545593, acc=0.6725000143051147, loss=0.7262269854545593
test: epoch 107, loss 1.4035699367523193, acc=0.4444444477558136, loss=1.4035699367523193
train: epoch 108, loss 0.7173224091529846, acc=0.6784999966621399, loss=0.7173224091529846
test: epoch 108, loss 1.333260416984558, acc=0.4555555582046509, loss=1.333260416984558
train: epoch 109, loss 0.7299312949180603, acc=0.6668888926506042, loss=0.7299312949180603
test: epoch 109, loss 1.4977103471755981, acc=0.45277777314186096, loss=1.4977103471755981
train: epoch 110, loss 0.6964353322982788, acc=0.6809999942779541, loss=0.6964353322982788
test: epoch 110, loss 1.4152456521987915, acc=0.44999998807907104, loss=1.4152456521987915
train: epoch 111, loss 0.704856276512146, acc=0.683388888835907, loss=0.704856276512146
test: epoch 111, loss 1.4110121726989746, acc=0.47777777910232544, loss=1.4110121726989746
train: epoch 112, loss 0.7010088562965393, acc=0.6846666932106018, loss=0.7010088562965393
test: epoch 112, loss 1.3320165872573853, acc=0.4861111044883728, loss=1.3320165872573853
train: epoch 113, loss 0.705292284488678, acc=0.6819999814033508, loss=0.705292284488678
test: epoch 113, loss 1.3992140293121338, acc=0.4861111044883728, loss=1.3992140293121338
train: epoch 114, loss 0.7255917191505432, acc=0.6763333082199097, loss=0.7255917191505432
test: epoch 114, loss 1.2276880741119385, acc=0.4861111044883728, loss=1.2276880741119385
train: epoch 115, loss 0.6872702836990356, acc=0.6855000257492065, loss=0.6872702836990356
test: epoch 115, loss 1.3900909423828125, acc=0.4861111044883728, loss=1.3900909423828125
train: epoch 116, loss 0.6924152374267578, acc=0.6866666674613953, loss=0.6924152374267578
test: epoch 116, loss 1.3953351974487305, acc=0.4861111044883728, loss=1.3953351974487305
train: epoch 117, loss 0.7014415860176086, acc=0.6867777705192566, loss=0.7014415860176086
test: epoch 117, loss 1.3540855646133423, acc=0.4861111044883728, loss=1.3540855646133423
train: epoch 118, loss 0.6606736779212952, acc=0.6976110935211182, loss=0.6606736779212952
test: epoch 118, loss 1.3623452186584473, acc=0.4861111044883728, loss=1.3623452186584473
train: epoch 119, loss 0.6899418234825134, acc=0.6875, loss=0.6899418234825134
test: epoch 119, loss 1.3548917770385742, acc=0.4861111044883728, loss=1.3548917770385742
train: epoch 120, loss 0.6997291445732117, acc=0.6850555539131165, loss=0.6997291445732117
test: epoch 120, loss 1.3396998643875122, acc=0.4861111044883728, loss=1.3396998643875122
train: epoch 121, loss 0.6926296949386597, acc=0.6900555491447449, loss=0.6926296949386597
test: epoch 121, loss 1.4429987668991089, acc=0.4833333194255829, loss=1.4429987668991089
train: epoch 122, loss 0.6782926917076111, acc=0.6958333253860474, loss=0.6782926917076111
test: epoch 122, loss 1.3248751163482666, acc=0.4888888895511627, loss=1.3248751163482666
train: epoch 123, loss 0.6671430468559265, acc=0.6994444727897644, loss=0.6671430468559265
test: epoch 123, loss 1.3919792175292969, acc=0.4888888895511627, loss=1.3919792175292969
train: epoch 124, loss 0.6804107427597046, acc=0.6981111168861389, loss=0.6804107427597046
test: epoch 124, loss 1.2520431280136108, acc=0.4888888895511627, loss=1.2520431280136108
train: epoch 125, loss 0.6494717597961426, acc=0.7102222442626953, loss=0.6494717597961426
test: epoch 125, loss 1.4240107536315918, acc=0.4888888895511627, loss=1.4240107536315918
train: epoch 126, loss 0.662432074546814, acc=0.7103888988494873, loss=0.662432074546814
test: epoch 126, loss 1.3165688514709473, acc=0.4888888895511627, loss=1.3165688514709473
train: epoch 127, loss 0.6241078972816467, acc=0.7208889126777649, loss=0.6241078972816467
test: epoch 127, loss 1.2621198892593384, acc=0.4888888895511627, loss=1.2621198892593384
train: epoch 128, loss 0.6119781136512756, acc=0.7262222170829773, loss=0.6119781136512756
test: epoch 128, loss 1.4964834451675415, acc=0.4888888895511627, loss=1.4964834451675415
train: epoch 129, loss 0.6644764542579651, acc=0.7070555686950684, loss=0.6644764542579651
test: epoch 129, loss 1.400092601776123, acc=0.4833333194255829, loss=1.400092601776123
train: epoch 130, loss 0.6155598163604736, acc=0.7208889126777649, loss=0.6155598163604736
test: epoch 130, loss 1.5078481435775757, acc=0.4833333194255829, loss=1.5078481435775757
train: epoch 131, loss 0.6470447778701782, acc=0.7147777676582336, loss=0.6470447778701782
test: epoch 131, loss 1.2897378206253052, acc=0.4888888895511627, loss=1.2897378206253052
train: epoch 132, loss 0.6048983335494995, acc=0.7262222170829773, loss=0.6048983335494995
test: epoch 132, loss 1.4084941148757935, acc=0.4888888895511627, loss=1.4084941148757935
train: epoch 133, loss 0.6023927927017212, acc=0.7281666398048401, loss=0.6023927927017212
test: epoch 133, loss 1.344760537147522, acc=0.4888888895511627, loss=1.344760537147522
train: epoch 134, loss 0.62137770652771, acc=0.7178333401679993, loss=0.62137770652771
test: epoch 134, loss 1.4123774766921997, acc=0.4888888895511627, loss=1.4123774766921997
train: epoch 135, loss 0.6225162148475647, acc=0.7176666855812073, loss=0.6225162148475647
test: epoch 135, loss 1.3312406539916992, acc=0.4861111044883728, loss=1.3312406539916992
train: epoch 136, loss 0.5700752139091492, acc=0.7360000014305115, loss=0.5700752139091492
test: epoch 136, loss 1.4687715768814087, acc=0.4694444537162781, loss=1.4687715768814087
train: epoch 137, loss 0.5869318842887878, acc=0.7317222356796265, loss=0.5869318842887878
test: epoch 137, loss 1.4279463291168213, acc=0.4722222089767456, loss=1.4279463291168213
train: epoch 138, loss 0.580112099647522, acc=0.7334444522857666, loss=0.580112099647522
test: epoch 138, loss 1.2892827987670898, acc=0.4861111044883728, loss=1.2892827987670898
train: epoch 139, loss 0.6095825433731079, acc=0.7251666784286499, loss=0.6095825433731079
test: epoch 139, loss 1.4392591714859009, acc=0.49444442987442017, loss=1.4392591714859009
train: epoch 140, loss 0.5940804481506348, acc=0.7318333387374878, loss=0.5940804481506348
test: epoch 140, loss 1.4717445373535156, acc=0.49444442987442017, loss=1.4717445373535156
train: epoch 141, loss 0.5831637382507324, acc=0.7336666584014893, loss=0.5831637382507324
test: epoch 141, loss 1.466755747795105, acc=0.49444442987442017, loss=1.466755747795105
train: epoch 142, loss 0.5791206359863281, acc=0.7354999780654907, loss=0.5791206359863281
test: epoch 142, loss 1.3297966718673706, acc=0.49444442987442017, loss=1.3297966718673706
train: epoch 143, loss 0.5688480734825134, acc=0.7390555739402771, loss=0.5688480734825134
test: epoch 143, loss 1.4808433055877686, acc=0.4833333194255829, loss=1.4808433055877686
train: epoch 144, loss 0.5781397819519043, acc=0.7388333082199097, loss=0.5781397819519043
test: epoch 144, loss 1.4697405099868774, acc=0.49444442987442017, loss=1.4697405099868774
train: epoch 145, loss 0.6052346229553223, acc=0.72688889503479, loss=0.6052346229553223
test: epoch 145, loss 1.4310272932052612, acc=0.49166667461395264, loss=1.4310272932052612
train: epoch 146, loss 0.5683095455169678, acc=0.738277792930603, loss=0.5683095455169678
test: epoch 146, loss 1.5931332111358643, acc=0.47777777910232544, loss=1.5931332111358643
train: epoch 147, loss 0.6181265711784363, acc=0.7216110825538635, loss=0.6181265711784363
test: epoch 147, loss 1.5059027671813965, acc=0.48055556416511536, loss=1.5059027671813965
train: epoch 148, loss 0.5494231581687927, acc=0.7434444427490234, loss=0.5494231581687927
test: epoch 148, loss 1.4177850484848022, acc=0.49444442987442017, loss=1.4177850484848022
train: epoch 149, loss 0.5659797191619873, acc=0.741777777671814, loss=0.5659797191619873
test: epoch 149, loss 1.3579332828521729, acc=0.49444442987442017, loss=1.3579332828521729
train: epoch 150, loss 0.6447371244430542, acc=0.7174999713897705, loss=0.6447371244430542
test: epoch 150, loss 1.3493378162384033, acc=0.49166667461395264, loss=1.3493378162384033
