# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=true", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1876273971, receiver_embed_dim=128, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.7184853553771973, acc=0.10400000214576721, loss=2.7184853553771973
test: epoch 1, loss 2.9348247051239014, acc=0.11388888955116272, loss=2.9348247051239014
train: epoch 2, loss 1.6271991729736328, acc=0.32899999618530273, loss=1.6271991729736328
test: epoch 2, loss 2.174906015396118, acc=0.3055555522441864, loss=2.174906015396118
train: epoch 3, loss 1.0462974309921265, acc=0.5450555682182312, loss=1.0462974309921265
test: epoch 3, loss 1.6002804040908813, acc=0.40833333134651184, loss=1.6002804040908813
train: epoch 4, loss 0.7758346199989319, acc=0.6733333468437195, loss=0.7758346199989319
test: epoch 4, loss 1.2930881977081299, acc=0.5, loss=1.2930881977081299
train: epoch 5, loss 0.6213934421539307, acc=0.7329999804496765, loss=0.6213934421539307
test: epoch 5, loss 1.3341976404190063, acc=0.5027777552604675, loss=1.3341976404190063
train: epoch 6, loss 0.5055745244026184, acc=0.7818333506584167, loss=0.5055745244026184
test: epoch 6, loss 1.3537579774856567, acc=0.5666666626930237, loss=1.3537579774856567
train: epoch 7, loss 0.4592452347278595, acc=0.8026666641235352, loss=0.4592452347278595
test: epoch 7, loss 1.080362319946289, acc=0.605555534362793, loss=1.080362319946289
train: epoch 8, loss 0.3988356292247772, acc=0.8268888592720032, loss=0.3988356292247772
test: epoch 8, loss 1.107583999633789, acc=0.5972222089767456, loss=1.107583999633789
train: epoch 9, loss 0.3848860561847687, acc=0.8321666717529297, loss=0.3848860561847687
test: epoch 9, loss 1.0963423252105713, acc=0.644444465637207, loss=1.0963423252105713
train: epoch 10, loss 0.38162362575531006, acc=0.8358333110809326, loss=0.38162362575531006
test: epoch 10, loss 1.1117843389511108, acc=0.6027777791023254, loss=1.1117843389511108
train: epoch 11, loss 0.368350088596344, acc=0.8386111259460449, loss=0.368350088596344
test: epoch 11, loss 1.0494328737258911, acc=0.6361111402511597, loss=1.0494328737258911
train: epoch 12, loss 0.3362695276737213, acc=0.8523889183998108, loss=0.3362695276737213
test: epoch 12, loss 0.6706173419952393, acc=0.7416666746139526, loss=0.6706173419952393
train: epoch 13, loss 0.29683831334114075, acc=0.8682222366333008, loss=0.29683831334114075
test: epoch 13, loss 0.7264197468757629, acc=0.7416666746139526, loss=0.7264197468757629
train: epoch 14, loss 0.3096698820590973, acc=0.8635555505752563, loss=0.3096698820590973
test: epoch 14, loss 0.7237004637718201, acc=0.7749999761581421, loss=0.7237004637718201
train: epoch 15, loss 0.2739102244377136, acc=0.8721110820770264, loss=0.2739102244377136
test: epoch 15, loss 0.622456967830658, acc=0.7861111164093018, loss=0.622456967830658
train: epoch 16, loss 0.26650384068489075, acc=0.8776666522026062, loss=0.26650384068489075
test: epoch 16, loss 0.4203503131866455, acc=0.8361111283302307, loss=0.4203503131866455
train: epoch 17, loss 0.2533347010612488, acc=0.8803889155387878, loss=0.2533347010612488
test: epoch 17, loss 0.38146471977233887, acc=0.8500000238418579, loss=0.38146471977233887
train: epoch 18, loss 0.24509456753730774, acc=0.8816666603088379, loss=0.24509456753730774
test: epoch 18, loss 0.48765477538108826, acc=0.8361111283302307, loss=0.48765477538108826
train: epoch 19, loss 0.22889482975006104, acc=0.8851666450500488, loss=0.22889482975006104
test: epoch 19, loss 0.41391944885253906, acc=0.855555534362793, loss=0.41391944885253906
train: epoch 20, loss 0.23209378123283386, acc=0.8894444704055786, loss=0.23209378123283386
test: epoch 20, loss 0.3875707983970642, acc=0.8694444298744202, loss=0.3875707983970642
train: epoch 21, loss 0.2315671741962433, acc=0.8882777690887451, loss=0.2315671741962433
test: epoch 21, loss 0.3309330940246582, acc=0.8694444298744202, loss=0.3309330940246582
train: epoch 22, loss 0.22273367643356323, acc=0.8893333077430725, loss=0.22273367643356323
test: epoch 22, loss 0.41040003299713135, acc=0.8611111044883728, loss=0.41040003299713135
train: epoch 23, loss 0.20627829432487488, acc=0.8922222256660461, loss=0.20627829432487488
test: epoch 23, loss 0.4251062273979187, acc=0.855555534362793, loss=0.4251062273979187
train: epoch 24, loss 0.1926131397485733, acc=0.899222195148468, loss=0.1926131397485733
test: epoch 24, loss 0.35960397124290466, acc=0.8722222447395325, loss=0.35960397124290466
train: epoch 25, loss 0.20149573683738708, acc=0.9011666774749756, loss=0.20149573683738708
test: epoch 25, loss 0.385791540145874, acc=0.8638888597488403, loss=0.385791540145874
train: epoch 26, loss 0.22107228636741638, acc=0.8934444189071655, loss=0.22107228636741638
test: epoch 26, loss 0.37039804458618164, acc=0.8694444298744202, loss=0.37039804458618164
train: epoch 27, loss 0.19717343151569366, acc=0.9016110897064209, loss=0.19717343151569366
test: epoch 27, loss 0.3236306309700012, acc=0.8694444298744202, loss=0.3236306309700012
train: epoch 28, loss 0.23227378726005554, acc=0.8910555839538574, loss=0.23227378726005554
test: epoch 28, loss 0.4036196768283844, acc=0.8611111044883728, loss=0.4036196768283844
train: epoch 29, loss 0.20717833936214447, acc=0.8949999809265137, loss=0.20717833936214447
test: epoch 29, loss 0.40842005610466003, acc=0.8722222447395325, loss=0.40842005610466003
train: epoch 30, loss 0.188297837972641, acc=0.9064444303512573, loss=0.188297837972641
test: epoch 30, loss 0.3075851500034332, acc=0.8694444298744202, loss=0.3075851500034332
train: epoch 31, loss 0.23982404172420502, acc=0.8849444389343262, loss=0.23982404172420502
test: epoch 31, loss 0.32213300466537476, acc=0.8666666746139526, loss=0.32213300466537476
train: epoch 32, loss 0.2751191556453705, acc=0.8741666674613953, loss=0.2751191556453705
test: epoch 32, loss 0.3231234848499298, acc=0.8611111044883728, loss=0.3231234848499298
train: epoch 33, loss 0.22458942234516144, acc=0.886555552482605, loss=0.22458942234516144
test: epoch 33, loss 0.39727991819381714, acc=0.855555534362793, loss=0.39727991819381714
train: epoch 34, loss 0.22606869041919708, acc=0.8934999704360962, loss=0.22606869041919708
test: epoch 34, loss 0.42013269662857056, acc=0.8666666746139526, loss=0.42013269662857056
train: epoch 35, loss 0.210593119263649, acc=0.9012777805328369, loss=0.210593119263649
test: epoch 35, loss 0.4222736060619354, acc=0.8527777791023254, loss=0.4222736060619354
train: epoch 36, loss 0.21885116398334503, acc=0.9057222008705139, loss=0.21885116398334503
test: epoch 36, loss 0.3951599597930908, acc=0.8583333492279053, loss=0.3951599597930908
train: epoch 37, loss 0.1955147087574005, acc=0.9032777547836304, loss=0.1955147087574005
test: epoch 37, loss 0.4061683714389801, acc=0.855555534362793, loss=0.4061683714389801
train: epoch 38, loss 0.1914878636598587, acc=0.9099444150924683, loss=0.1914878636598587
test: epoch 38, loss 0.41718944907188416, acc=0.8611111044883728, loss=0.41718944907188416
train: epoch 39, loss 0.2121698409318924, acc=0.902388870716095, loss=0.2121698409318924
test: epoch 39, loss 0.4270542562007904, acc=0.8527777791023254, loss=0.4270542562007904
train: epoch 40, loss 0.2024613469839096, acc=0.9075000286102295, loss=0.2024613469839096
test: epoch 40, loss 0.41915249824523926, acc=0.8638888597488403, loss=0.41915249824523926
train: epoch 41, loss 0.21063946187496185, acc=0.9085000157356262, loss=0.21063946187496185
test: epoch 41, loss 0.31028780341148376, acc=0.8666666746139526, loss=0.31028780341148376
train: epoch 42, loss 0.17798735201358795, acc=0.9166666865348816, loss=0.17798735201358795
test: epoch 42, loss 0.3608241677284241, acc=0.8861111402511597, loss=0.3608241677284241
train: epoch 43, loss 0.1531197428703308, acc=0.9228333234786987, loss=0.1531197428703308
test: epoch 43, loss 0.3325013816356659, acc=0.8805555701255798, loss=0.3325013816356659
train: epoch 44, loss 0.17081555724143982, acc=0.91438889503479, loss=0.17081555724143982
test: epoch 44, loss 0.32354670763015747, acc=0.8833333253860474, loss=0.32354670763015747
train: epoch 45, loss 0.17268024384975433, acc=0.9116666913032532, loss=0.17268024384975433
test: epoch 45, loss 0.2558133602142334, acc=0.8861111402511597, loss=0.2558133602142334
train: epoch 46, loss 0.1825380027294159, acc=0.9110555648803711, loss=0.1825380027294159
test: epoch 46, loss 0.35707956552505493, acc=0.8833333253860474, loss=0.35707956552505493
train: epoch 47, loss 0.18965376913547516, acc=0.9057222008705139, loss=0.18965376913547516
test: epoch 47, loss 0.2948777973651886, acc=0.875, loss=0.2948777973651886
train: epoch 48, loss 0.17578478157520294, acc=0.9058333039283752, loss=0.17578478157520294
test: epoch 48, loss 0.32112783193588257, acc=0.8833333253860474, loss=0.32112783193588257
train: epoch 49, loss 0.17941130697727203, acc=0.9088888764381409, loss=0.17941130697727203
test: epoch 49, loss 0.3901355266571045, acc=0.8583333492279053, loss=0.3901355266571045
train: epoch 50, loss 0.18371684849262238, acc=0.9055555462837219, loss=0.18371684849262238
test: epoch 50, loss 0.3995698094367981, acc=0.8833333253860474, loss=0.3995698094367981
train: epoch 51, loss 0.15121285617351532, acc=0.9121666550636292, loss=0.15121285617351532
test: epoch 51, loss 0.31489530205726624, acc=0.8833333253860474, loss=0.31489530205726624
train: epoch 52, loss 0.14128351211547852, acc=0.9141666889190674, loss=0.14128351211547852
test: epoch 52, loss 0.3739235997200012, acc=0.8833333253860474, loss=0.3739235997200012
train: epoch 53, loss 0.20094801485538483, acc=0.9008888602256775, loss=0.20094801485538483
test: epoch 53, loss 0.3428499698638916, acc=0.8694444298744202, loss=0.3428499698638916
train: epoch 54, loss 0.1987781673669815, acc=0.9020000100135803, loss=0.1987781673669815
test: epoch 54, loss 0.3145548701286316, acc=0.875, loss=0.3145548701286316
train: epoch 55, loss 0.17950481176376343, acc=0.9025555849075317, loss=0.17950481176376343
test: epoch 55, loss 0.4126831293106079, acc=0.875, loss=0.4126831293106079
train: epoch 56, loss 0.20470041036605835, acc=0.9037222266197205, loss=0.20470041036605835
test: epoch 56, loss 0.3192456364631653, acc=0.8777777552604675, loss=0.3192456364631653
train: epoch 57, loss 0.13215208053588867, acc=0.9194444417953491, loss=0.13215208053588867
test: epoch 57, loss 0.2828352153301239, acc=0.8861111402511597, loss=0.2828352153301239
train: epoch 58, loss 0.20560762286186218, acc=0.9028333425521851, loss=0.20560762286186218
test: epoch 58, loss 0.29841071367263794, acc=0.8805555701255798, loss=0.29841071367263794
train: epoch 59, loss 0.23356783390045166, acc=0.8949999809265137, loss=0.23356783390045166
test: epoch 59, loss 0.3332313299179077, acc=0.8722222447395325, loss=0.3332313299179077
train: epoch 60, loss 0.21398058533668518, acc=0.8983888626098633, loss=0.21398058533668518
test: epoch 60, loss 0.2882740795612335, acc=0.875, loss=0.2882740795612335
train: epoch 61, loss 0.17133034765720367, acc=0.906166672706604, loss=0.17133034765720367
test: epoch 61, loss 0.3668651282787323, acc=0.8777777552604675, loss=0.3668651282787323
train: epoch 62, loss 0.23470088839530945, acc=0.8954444527626038, loss=0.23470088839530945
test: epoch 62, loss 0.46425214409828186, acc=0.8500000238418579, loss=0.46425214409828186
train: epoch 63, loss 0.21980595588684082, acc=0.8956666588783264, loss=0.21980595588684082
test: epoch 63, loss 0.3064729869365692, acc=0.8722222447395325, loss=0.3064729869365692
train: epoch 64, loss 0.21057665348052979, acc=0.9001666903495789, loss=0.21057665348052979
test: epoch 64, loss 0.26728129386901855, acc=0.8805555701255798, loss=0.26728129386901855
train: epoch 65, loss 0.21020755171775818, acc=0.8998333215713501, loss=0.21020755171775818
test: epoch 65, loss 0.36772263050079346, acc=0.875, loss=0.36772263050079346
train: epoch 66, loss 0.16759590804576874, acc=0.9066110849380493, loss=0.16759590804576874
test: epoch 66, loss 0.23791122436523438, acc=0.8833333253860474, loss=0.23791122436523438
train: epoch 67, loss 0.13560672104358673, acc=0.9160555601119995, loss=0.13560672104358673
test: epoch 67, loss 0.27061569690704346, acc=0.8888888955116272, loss=0.27061569690704346
train: epoch 68, loss 0.25717833638191223, acc=0.8976666927337646, loss=0.25717833638191223
test: epoch 68, loss 0.41791942715644836, acc=0.8583333492279053, loss=0.41791942715644836
train: epoch 69, loss 0.17797701060771942, acc=0.9135000109672546, loss=0.17797701060771942
test: epoch 69, loss 0.34917569160461426, acc=0.8805555701255798, loss=0.34917569160461426
train: epoch 70, loss 0.18092751502990723, acc=0.9104999899864197, loss=0.18092751502990723
test: epoch 70, loss 0.3802948594093323, acc=0.8777777552604675, loss=0.3802948594093323
train: epoch 71, loss 0.1802641898393631, acc=0.9064444303512573, loss=0.1802641898393631
test: epoch 71, loss 0.3143867552280426, acc=0.8888888955116272, loss=0.3143867552280426
train: epoch 72, loss 0.18243427574634552, acc=0.9079444408416748, loss=0.18243427574634552
test: epoch 72, loss 0.2567538022994995, acc=0.9027777910232544, loss=0.2567538022994995
train: epoch 73, loss 0.18797671794891357, acc=0.9086111187934875, loss=0.18797671794891357
test: epoch 73, loss 0.20644034445285797, acc=0.9111111164093018, loss=0.20644034445285797
train: epoch 74, loss 0.15590783953666687, acc=0.914222240447998, loss=0.15590783953666687
test: epoch 74, loss 0.21274100244045258, acc=0.9138888716697693, loss=0.21274100244045258
train: epoch 75, loss 0.17222076654434204, acc=0.9117777943611145, loss=0.17222076654434204
test: epoch 75, loss 0.19184939563274384, acc=0.9166666865348816, loss=0.19184939563274384
train: epoch 76, loss 0.13998845219612122, acc=0.9170555472373962, loss=0.13998845219612122
test: epoch 76, loss 0.20667627453804016, acc=0.9166666865348816, loss=0.20667627453804016
train: epoch 77, loss 0.17227323353290558, acc=0.9106666445732117, loss=0.17227323353290558
test: epoch 77, loss 0.2500605881214142, acc=0.8916666507720947, loss=0.2500605881214142
train: epoch 78, loss 0.19343380630016327, acc=0.8991666436195374, loss=0.19343380630016327
test: epoch 78, loss 0.24085775017738342, acc=0.8999999761581421, loss=0.24085775017738342
train: epoch 79, loss 0.24747510254383087, acc=0.8956111073493958, loss=0.24747510254383087
test: epoch 79, loss 0.2170812040567398, acc=0.9055555462837219, loss=0.2170812040567398
train: epoch 80, loss 0.17733119428157806, acc=0.9200000166893005, loss=0.17733119428157806
test: epoch 80, loss 0.21751506626605988, acc=0.9027777910232544, loss=0.21751506626605988
train: epoch 81, loss 0.25914430618286133, acc=0.8966666460037231, loss=0.25914430618286133
test: epoch 81, loss 0.2649381756782532, acc=0.8999999761581421, loss=0.2649381756782532
train: epoch 82, loss 0.1976928412914276, acc=0.9151666760444641, loss=0.1976928412914276
test: epoch 82, loss 0.1800495833158493, acc=0.9083333611488342, loss=0.1800495833158493
train: epoch 83, loss 0.20509465038776398, acc=0.9029444456100464, loss=0.20509465038776398
test: epoch 83, loss 0.27971938252449036, acc=0.894444465637207, loss=0.27971938252449036
train: epoch 84, loss 0.1740507036447525, acc=0.9098333120346069, loss=0.1740507036447525
test: epoch 84, loss 0.18657827377319336, acc=0.9111111164093018, loss=0.18657827377319336
train: epoch 85, loss 0.15002964437007904, acc=0.913277804851532, loss=0.15002964437007904
test: epoch 85, loss 0.22520963847637177, acc=0.9111111164093018, loss=0.22520963847637177
train: epoch 86, loss 0.14200890064239502, acc=0.9118888974189758, loss=0.14200890064239502
test: epoch 86, loss 0.16813963651657104, acc=0.9138888716697693, loss=0.16813963651657104
train: epoch 87, loss 0.16080160439014435, acc=0.9126111268997192, loss=0.16080160439014435
test: epoch 87, loss 0.21070201694965363, acc=0.9027777910232544, loss=0.21070201694965363
train: epoch 88, loss 0.21645882725715637, acc=0.906333327293396, loss=0.21645882725715637
test: epoch 88, loss 0.14881901443004608, acc=0.9222221970558167, loss=0.14881901443004608
train: epoch 89, loss 0.18503828346729279, acc=0.9068889021873474, loss=0.18503828346729279
test: epoch 89, loss 0.1723746806383133, acc=0.9166666865348816, loss=0.1723746806383133
train: epoch 90, loss 0.19050875306129456, acc=0.9049999713897705, loss=0.19050875306129456
test: epoch 90, loss 0.25385111570358276, acc=0.8972222208976746, loss=0.25385111570358276
train: epoch 91, loss 0.2344716191291809, acc=0.9014444351196289, loss=0.2344716191291809
test: epoch 91, loss 0.18297040462493896, acc=0.9111111164093018, loss=0.18297040462493896
train: epoch 92, loss 0.1822829693555832, acc=0.9036111235618591, loss=0.1822829693555832
test: epoch 92, loss 0.1784408539533615, acc=0.9111111164093018, loss=0.1784408539533615
train: epoch 93, loss 0.18016645312309265, acc=0.8972777724266052, loss=0.18016645312309265
test: epoch 93, loss 0.17813009023666382, acc=0.9111111164093018, loss=0.17813009023666382
train: epoch 94, loss 0.17993739247322083, acc=0.898888885974884, loss=0.17993739247322083
test: epoch 94, loss 0.17803576588630676, acc=0.9111111164093018, loss=0.17803576588630676
train: epoch 95, loss 0.2822229564189911, acc=0.8823333382606506, loss=0.2822229564189911
test: epoch 95, loss 0.23628801107406616, acc=0.894444465637207, loss=0.23628801107406616
train: epoch 96, loss 0.24075455963611603, acc=0.8815555572509766, loss=0.24075455963611603
test: epoch 96, loss 0.23174907267093658, acc=0.894444465637207, loss=0.23174907267093658
train: epoch 97, loss 0.22306500375270844, acc=0.8851110935211182, loss=0.22306500375270844
test: epoch 97, loss 0.20351755619049072, acc=0.9027777910232544, loss=0.20351755619049072
train: epoch 98, loss 0.20542334020137787, acc=0.8871666789054871, loss=0.20542334020137787
test: epoch 98, loss 0.20202594995498657, acc=0.9027777910232544, loss=0.20202594995498657
train: epoch 99, loss 0.20493260025978088, acc=0.8872777819633484, loss=0.20493260025978088
test: epoch 99, loss 0.20192155241966248, acc=0.9027777910232544, loss=0.20192155241966248
train: epoch 100, loss 0.27249136567115784, acc=0.8762778043746948, loss=0.27249136567115784
test: epoch 100, loss 0.5105898380279541, acc=0.800000011920929, loss=0.5105898380279541
train: epoch 101, loss 0.35908758640289307, acc=0.8423333168029785, loss=0.35908758640289307
test: epoch 101, loss 0.3136976659297943, acc=0.8611111044883728, loss=0.3136976659297943
train: epoch 102, loss 0.37408846616744995, acc=0.8528888821601868, loss=0.37408846616744995
test: epoch 102, loss 0.28581786155700684, acc=0.8722222447395325, loss=0.28581786155700684
train: epoch 103, loss 0.28091907501220703, acc=0.874666690826416, loss=0.28091907501220703
test: epoch 103, loss 0.3599434792995453, acc=0.855555534362793, loss=0.3599434792995453
train: epoch 104, loss 0.29658377170562744, acc=0.8658888936042786, loss=0.29658377170562744
test: epoch 104, loss 0.23398374021053314, acc=0.8916666507720947, loss=0.23398374021053314
train: epoch 105, loss 0.23385170102119446, acc=0.878166675567627, loss=0.23385170102119446
test: epoch 105, loss 0.23479142785072327, acc=0.8888888955116272, loss=0.23479142785072327
train: epoch 106, loss 0.2349008470773697, acc=0.8770555257797241, loss=0.2349008470773697
test: epoch 106, loss 0.2306952178478241, acc=0.8916666507720947, loss=0.2306952178478241
train: epoch 107, loss 0.23305684328079224, acc=0.8790000081062317, loss=0.23305684328079224
test: epoch 107, loss 0.22608809173107147, acc=0.894444465637207, loss=0.22608809173107147
train: epoch 108, loss 0.22828468680381775, acc=0.8849999904632568, loss=0.22828468680381775
test: epoch 108, loss 0.2196471393108368, acc=0.8972222208976746, loss=0.2196471393108368
train: epoch 109, loss 0.3429507315158844, acc=0.8575000166893005, loss=0.3429507315158844
test: epoch 109, loss 0.30843278765678406, acc=0.8611111044883728, loss=0.30843278765678406
train: epoch 110, loss 0.3112422525882721, acc=0.8494444489479065, loss=0.3112422525882721
test: epoch 110, loss 0.3060634136199951, acc=0.8611111044883728, loss=0.3060634136199951
train: epoch 111, loss 0.3934987187385559, acc=0.8379444479942322, loss=0.3934987187385559
test: epoch 111, loss 0.34779787063598633, acc=0.8527777791023254, loss=0.34779787063598633
train: epoch 112, loss 0.29600754380226135, acc=0.8650555610656738, loss=0.29600754380226135
test: epoch 112, loss 0.2579381465911865, acc=0.8805555701255798, loss=0.2579381465911865
train: epoch 113, loss 0.24775230884552002, acc=0.8768333196640015, loss=0.24775230884552002
test: epoch 113, loss 0.24056413769721985, acc=0.8888888955116272, loss=0.24056413769721985
train: epoch 114, loss 0.31793317198753357, acc=0.8578888773918152, loss=0.31793317198753357
test: epoch 114, loss 0.24301542341709137, acc=0.8888888955116272, loss=0.24301542341709137
train: epoch 115, loss 0.2386418879032135, acc=0.8809444308280945, loss=0.2386418879032135
test: epoch 115, loss 0.23165659606456757, acc=0.8916666507720947, loss=0.23165659606456757
train: epoch 116, loss 0.23293259739875793, acc=0.8783888816833496, loss=0.23293259739875793
test: epoch 116, loss 0.23077988624572754, acc=0.8916666507720947, loss=0.23077988624572754
train: epoch 117, loss 0.24061690270900726, acc=0.8773333430290222, loss=0.24061690270900726
test: epoch 117, loss 0.2325110137462616, acc=0.8916666507720947, loss=0.2325110137462616
train: epoch 118, loss 0.40067729353904724, acc=0.8584444522857666, loss=0.40067729353904724
test: epoch 118, loss 0.2741891145706177, acc=0.8833333253860474, loss=0.2741891145706177
train: epoch 119, loss 0.25261810421943665, acc=0.8841666579246521, loss=0.25261810421943665
test: epoch 119, loss 0.22661758959293365, acc=0.8972222208976746, loss=0.22661758959293365
train: epoch 120, loss 0.22538557648658752, acc=0.8902778029441833, loss=0.22538557648658752
test: epoch 120, loss 0.21052519977092743, acc=0.9027777910232544, loss=0.21052519977092743
train: epoch 121, loss 0.23895800113677979, acc=0.8898333311080933, loss=0.23895800113677979
test: epoch 121, loss 0.20913930237293243, acc=0.9027777910232544, loss=0.20913930237293243
train: epoch 122, loss 0.24346300959587097, acc=0.8817222118377686, loss=0.24346300959587097
test: epoch 122, loss 0.24769940972328186, acc=0.894444465637207, loss=0.24769940972328186
train: epoch 123, loss 0.25371330976486206, acc=0.8851666450500488, loss=0.25371330976486206
test: epoch 123, loss 0.2516612112522125, acc=0.894444465637207, loss=0.2516612112522125
train: epoch 124, loss 0.2542574405670166, acc=0.8768333196640015, loss=0.2542574405670166
test: epoch 124, loss 0.2510201036930084, acc=0.894444465637207, loss=0.2510201036930084
train: epoch 125, loss 0.2536455988883972, acc=0.8767777681350708, loss=0.2536455988883972
test: epoch 125, loss 0.25085389614105225, acc=0.894444465637207, loss=0.25085389614105225
train: epoch 126, loss 0.25348010659217834, acc=0.8767777681350708, loss=0.25348010659217834
test: epoch 126, loss 0.25077545642852783, acc=0.894444465637207, loss=0.25077545642852783
train: epoch 127, loss 0.25320425629615784, acc=0.8771111369132996, loss=0.25320425629615784
test: epoch 127, loss 0.25073739886283875, acc=0.894444465637207, loss=0.25073739886283875
train: epoch 128, loss 0.25320255756378174, acc=0.8771111369132996, loss=0.25320255756378174
test: epoch 128, loss 0.25072330236434937, acc=0.894444465637207, loss=0.25072330236434937
train: epoch 129, loss 0.2530243396759033, acc=0.8772777915000916, loss=0.2530243396759033
test: epoch 129, loss 0.25068536400794983, acc=0.894444465637207, loss=0.25068536400794983
train: epoch 130, loss 0.4323752522468567, acc=0.8478333353996277, loss=0.4323752522468567
test: epoch 130, loss 0.4285135865211487, acc=0.8527777791023254, loss=0.4285135865211487
train: epoch 131, loss 0.35609135031700134, acc=0.8560000061988831, loss=0.35609135031700134
test: epoch 131, loss 0.3217175006866455, acc=0.8694444298744202, loss=0.3217175006866455
train: epoch 132, loss 0.32229986786842346, acc=0.859333336353302, loss=0.32229986786842346
test: epoch 132, loss 0.3159697949886322, acc=0.8694444298744202, loss=0.3159697949886322
train: epoch 133, loss 0.3202255666255951, acc=0.8597221970558167, loss=0.3202255666255951
test: epoch 133, loss 0.3155949115753174, acc=0.8694444298744202, loss=0.3155949115753174
train: epoch 134, loss 0.3444127142429352, acc=0.8584444522857666, loss=0.3444127142429352
test: epoch 134, loss 0.4473983943462372, acc=0.8611111044883728, loss=0.4473983943462372
train: epoch 135, loss 0.35798922181129456, acc=0.863777756690979, loss=0.35798922181129456
test: epoch 135, loss 0.3267742991447449, acc=0.8666666746139526, loss=0.3267742991447449
train: epoch 136, loss 0.3467719852924347, acc=0.8527222275733948, loss=0.3467719852924347
test: epoch 136, loss 0.31997746229171753, acc=0.8722222447395325, loss=0.31997746229171753
train: epoch 137, loss 0.3202666640281677, acc=0.8542777895927429, loss=0.3202666640281677
test: epoch 137, loss 0.31386294960975647, acc=0.8722222447395325, loss=0.31386294960975647
train: epoch 138, loss 0.3176898956298828, acc=0.8547222018241882, loss=0.3176898956298828
test: epoch 138, loss 0.3129956126213074, acc=0.8722222447395325, loss=0.3129956126213074
train: epoch 139, loss 0.3167284429073334, acc=0.8551666736602783, loss=0.3167284429073334
test: epoch 139, loss 0.3054462671279907, acc=0.875, loss=0.3054462671279907
train: epoch 140, loss 0.3047138452529907, acc=0.8579444289207458, loss=0.3047138452529907
test: epoch 140, loss 0.2932543456554413, acc=0.8777777552604675, loss=0.2932543456554413
train: epoch 141, loss 0.4738263785839081, acc=0.828499972820282, loss=0.4738263785839081
test: epoch 141, loss 0.28079578280448914, acc=0.8638888597488403, loss=0.28079578280448914
train: epoch 142, loss 0.2774651348590851, acc=0.8473333120346069, loss=0.2774651348590851
test: epoch 142, loss 0.27192386984825134, acc=0.8638888597488403, loss=0.27192386984825134
train: epoch 143, loss 0.2977457046508789, acc=0.8451666831970215, loss=0.2977457046508789
test: epoch 143, loss 0.29689183831214905, acc=0.8583333492279053, loss=0.29689183831214905
train: epoch 144, loss 0.2973739802837372, acc=0.8472777605056763, loss=0.2973739802837372
test: epoch 144, loss 0.29192036390304565, acc=0.8583333492279053, loss=0.29192036390304565
train: epoch 145, loss 0.29473522305488586, acc=0.8498333096504211, loss=0.29473522305488586
test: epoch 145, loss 0.2903384268283844, acc=0.8583333492279053, loss=0.2903384268283844
train: epoch 146, loss 0.2936196029186249, acc=0.843833327293396, loss=0.2936196029186249
test: epoch 146, loss 0.28966307640075684, acc=0.8583333492279053, loss=0.28966307640075684
train: epoch 147, loss 0.2931438088417053, acc=0.8387777805328369, loss=0.2931438088417053
test: epoch 147, loss 0.289433091878891, acc=0.8583333492279053, loss=0.289433091878891
train: epoch 148, loss 0.43643760681152344, acc=0.808722198009491, loss=0.43643760681152344
test: epoch 148, loss 0.40196338295936584, acc=0.8277778029441833, loss=0.40196338295936584
train: epoch 149, loss 0.392153263092041, acc=0.8116666674613953, loss=0.392153263092041
test: epoch 149, loss 0.37102067470550537, acc=0.8361111283302307, loss=0.37102067470550537
train: epoch 150, loss 0.39419490098953247, acc=0.8182777762413025, loss=0.39419490098953247
test: epoch 150, loss 0.35315805673599243, acc=0.8472222089767456, loss=0.35315805673599243
