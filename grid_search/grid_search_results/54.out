# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=1", "--temp_decay=1", "--one_hot=true", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=2125923428, receiver_embed_dim=64, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.4387521743774414, acc=0.0499444454908371, loss=3.4387521743774414
test: epoch 1, loss 3.2316691875457764, acc=0.07777778059244156, loss=3.2316691875457764
train: epoch 2, loss 2.4044432640075684, acc=0.1663888841867447, loss=2.4044432640075684
test: epoch 2, loss 2.224109411239624, acc=0.14722222089767456, loss=2.224109411239624
train: epoch 3, loss 1.879451870918274, acc=0.2612222135066986, loss=1.879451870918274
test: epoch 3, loss 2.1566178798675537, acc=0.15833333134651184, loss=2.1566178798675537
train: epoch 4, loss 1.7116444110870361, acc=0.3050000071525574, loss=1.7116444110870361
test: epoch 4, loss 2.183480978012085, acc=0.16944444179534912, loss=2.183480978012085
train: epoch 5, loss 1.6187649965286255, acc=0.33266666531562805, loss=1.6187649965286255
test: epoch 5, loss 2.183331251144409, acc=0.17222222685813904, loss=2.183331251144409
train: epoch 6, loss 1.5520272254943848, acc=0.3558333218097687, loss=1.5520272254943848
test: epoch 6, loss 2.1701419353485107, acc=0.17499999701976776, loss=2.1701419353485107
train: epoch 7, loss 1.5046745538711548, acc=0.3768889009952545, loss=1.5046745538711548
test: epoch 7, loss 2.1902823448181152, acc=0.18611110746860504, loss=2.1902823448181152
train: epoch 8, loss 1.4576754570007324, acc=0.3957222104072571, loss=1.4576754570007324
test: epoch 8, loss 2.1428110599517822, acc=0.18611110746860504, loss=2.1428110599517822
train: epoch 9, loss 1.4185620546340942, acc=0.41055554151535034, loss=1.4185620546340942
test: epoch 9, loss 2.176645278930664, acc=0.18888889253139496, loss=2.176645278930664
train: epoch 10, loss 1.387005090713501, acc=0.42238888144493103, loss=1.387005090713501
test: epoch 10, loss 2.171884059906006, acc=0.20000000298023224, loss=2.171884059906006
train: epoch 11, loss 1.3607001304626465, acc=0.43772223591804504, loss=1.3607001304626465
test: epoch 11, loss 2.143012523651123, acc=0.19722221791744232, loss=2.143012523651123
train: epoch 12, loss 1.3308172225952148, acc=0.4441111087799072, loss=1.3308172225952148
test: epoch 12, loss 2.2027697563171387, acc=0.20000000298023224, loss=2.2027697563171387
train: epoch 13, loss 1.3128142356872559, acc=0.45722222328186035, loss=1.3128142356872559
test: epoch 13, loss 2.1761209964752197, acc=0.20277777314186096, loss=2.1761209964752197
train: epoch 14, loss 1.2875158786773682, acc=0.4583333432674408, loss=1.2875158786773682
test: epoch 14, loss 2.253330945968628, acc=0.20555555820465088, loss=2.253330945968628
train: epoch 15, loss 1.2710511684417725, acc=0.4721111059188843, loss=1.2710511684417725
test: epoch 15, loss 2.304356098175049, acc=0.2222222238779068, loss=2.304356098175049
train: epoch 16, loss 1.2516838312149048, acc=0.4803333282470703, loss=1.2516838312149048
test: epoch 16, loss 2.212595224380493, acc=0.2083333283662796, loss=2.212595224380493
train: epoch 17, loss 1.2129710912704468, acc=0.49149999022483826, loss=1.2129710912704468
test: epoch 17, loss 2.1706881523132324, acc=0.23888888955116272, loss=2.1706881523132324
train: epoch 18, loss 1.196069598197937, acc=0.5034999847412109, loss=1.196069598197937
test: epoch 18, loss 2.0238747596740723, acc=0.2638888955116272, loss=2.0238747596740723
train: epoch 19, loss 1.1671944856643677, acc=0.5139999985694885, loss=1.1671944856643677
test: epoch 19, loss 2.085569143295288, acc=0.24166665971279144, loss=2.085569143295288
train: epoch 20, loss 1.1455270051956177, acc=0.5188888907432556, loss=1.1455270051956177
test: epoch 20, loss 2.1660349369049072, acc=0.24444444477558136, loss=2.1660349369049072
train: epoch 21, loss 1.123184323310852, acc=0.5281111001968384, loss=1.123184323310852
test: epoch 21, loss 2.0115854740142822, acc=0.25555557012557983, loss=2.0115854740142822
train: epoch 22, loss 1.1123679876327515, acc=0.5339444279670715, loss=1.1123679876327515
test: epoch 22, loss 2.057335615158081, acc=0.25, loss=2.057335615158081
train: epoch 23, loss 1.0834426879882812, acc=0.539722204208374, loss=1.0834426879882812
test: epoch 23, loss 2.152081251144409, acc=0.2611111104488373, loss=2.152081251144409
train: epoch 24, loss 1.0794883966445923, acc=0.5465555787086487, loss=1.0794883966445923
test: epoch 24, loss 2.0641469955444336, acc=0.25833332538604736, loss=2.0641469955444336
train: epoch 25, loss 1.0555243492126465, acc=0.554111123085022, loss=1.0555243492126465
test: epoch 25, loss 1.9888343811035156, acc=0.2777777910232544, loss=1.9888343811035156
train: epoch 26, loss 1.0536082983016968, acc=0.5607777833938599, loss=1.0536082983016968
test: epoch 26, loss 2.160663366317749, acc=0.28333333134651184, loss=2.160663366317749
train: epoch 27, loss 1.0455868244171143, acc=0.562666654586792, loss=1.0455868244171143
test: epoch 27, loss 1.9794772863388062, acc=0.26944443583488464, loss=1.9794772863388062
train: epoch 28, loss 1.0197415351867676, acc=0.5695555806159973, loss=1.0197415351867676
test: epoch 28, loss 2.0796284675598145, acc=0.2777777910232544, loss=2.0796284675598145
train: epoch 29, loss 1.0186777114868164, acc=0.5733888745307922, loss=1.0186777114868164
test: epoch 29, loss 2.0214457511901855, acc=0.28333333134651184, loss=2.0214457511901855
train: epoch 30, loss 1.0089550018310547, acc=0.5791666507720947, loss=1.0089550018310547
test: epoch 30, loss 2.0299577713012695, acc=0.2944444417953491, loss=2.0299577713012695
train: epoch 31, loss 0.987044095993042, acc=0.5855555534362793, loss=0.987044095993042
test: epoch 31, loss 1.9988644123077393, acc=0.28611111640930176, loss=1.9988644123077393
train: epoch 32, loss 0.9734634757041931, acc=0.5937777757644653, loss=0.9734634757041931
test: epoch 32, loss 1.9608128070831299, acc=0.2944444417953491, loss=1.9608128070831299
train: epoch 33, loss 0.9698491096496582, acc=0.5946111083030701, loss=0.9698491096496582
test: epoch 33, loss 1.9767875671386719, acc=0.28333333134651184, loss=1.9767875671386719
train: epoch 34, loss 0.9647233486175537, acc=0.5931666493415833, loss=0.9647233486175537
test: epoch 34, loss 2.093109607696533, acc=0.2888889014720917, loss=2.093109607696533
train: epoch 35, loss 0.9482763409614563, acc=0.6015555262565613, loss=0.9482763409614563
test: epoch 35, loss 2.041811466217041, acc=0.28333333134651184, loss=2.041811466217041
train: epoch 36, loss 0.9296551942825317, acc=0.6118888854980469, loss=0.9296551942825317
test: epoch 36, loss 2.0119452476501465, acc=0.2888889014720917, loss=2.0119452476501465
train: epoch 37, loss 0.931641161441803, acc=0.6078888773918152, loss=0.931641161441803
test: epoch 37, loss 1.9626234769821167, acc=0.2888889014720917, loss=1.9626234769821167
train: epoch 38, loss 0.9177771806716919, acc=0.6158888936042786, loss=0.9177771806716919
test: epoch 38, loss 1.9597712755203247, acc=0.2805555462837219, loss=1.9597712755203247
train: epoch 39, loss 0.9145517945289612, acc=0.6117777824401855, loss=0.9145517945289612
test: epoch 39, loss 1.9147453308105469, acc=0.2944444417953491, loss=1.9147453308105469
train: epoch 40, loss 0.9020854234695435, acc=0.6156666874885559, loss=0.9020854234695435
test: epoch 40, loss 2.0205774307250977, acc=0.29722222685813904, loss=2.0205774307250977
train: epoch 41, loss 0.8906389474868774, acc=0.6191666722297668, loss=0.8906389474868774
test: epoch 41, loss 2.038973331451416, acc=0.29722222685813904, loss=2.038973331451416
train: epoch 42, loss 0.8864837288856506, acc=0.6218888759613037, loss=0.8864837288856506
test: epoch 42, loss 2.1096155643463135, acc=0.30000001192092896, loss=2.1096155643463135
train: epoch 43, loss 0.8720447421073914, acc=0.6272222399711609, loss=0.8720447421073914
test: epoch 43, loss 2.131662368774414, acc=0.3055555522441864, loss=2.131662368774414
train: epoch 44, loss 0.8639088869094849, acc=0.628333330154419, loss=0.8639088869094849
test: epoch 44, loss 2.0862443447113037, acc=0.3083333373069763, loss=2.0862443447113037
train: epoch 45, loss 0.8721936345100403, acc=0.6309999823570251, loss=0.8721936345100403
test: epoch 45, loss 2.0807390213012695, acc=0.29722222685813904, loss=2.0807390213012695
train: epoch 46, loss 0.8504811525344849, acc=0.6366111040115356, loss=0.8504811525344849
test: epoch 46, loss 2.12699556350708, acc=0.3166666626930237, loss=2.12699556350708
train: epoch 47, loss 0.8695348501205444, acc=0.632111132144928, loss=0.8695348501205444
test: epoch 47, loss 2.0426971912384033, acc=0.3083333373069763, loss=2.0426971912384033
train: epoch 48, loss 0.8602191209793091, acc=0.6343888640403748, loss=0.8602191209793091
test: epoch 48, loss 2.138446092605591, acc=0.31111112236976624, loss=2.138446092605591
train: epoch 49, loss 0.8456142544746399, acc=0.6422222256660461, loss=0.8456142544746399
test: epoch 49, loss 2.2009639739990234, acc=0.31111112236976624, loss=2.2009639739990234
train: epoch 50, loss 0.8470478653907776, acc=0.6372777819633484, loss=0.8470478653907776
test: epoch 50, loss 2.018092632293701, acc=0.31388887763023376, loss=2.018092632293701
train: epoch 51, loss 0.833308219909668, acc=0.6422777771949768, loss=0.833308219909668
test: epoch 51, loss 2.125883102416992, acc=0.3055555522441864, loss=2.125883102416992
train: epoch 52, loss 0.8322052955627441, acc=0.6464999914169312, loss=0.8322052955627441
test: epoch 52, loss 2.130446434020996, acc=0.3166666626930237, loss=2.130446434020996
train: epoch 53, loss 0.8341403007507324, acc=0.643833339214325, loss=0.8341403007507324
test: epoch 53, loss 2.1023318767547607, acc=0.3194444477558136, loss=2.1023318767547607
train: epoch 54, loss 0.827440619468689, acc=0.6430000066757202, loss=0.827440619468689
test: epoch 54, loss 2.0256340503692627, acc=0.31111112236976624, loss=2.0256340503692627
train: epoch 55, loss 0.8110010623931885, acc=0.6542778015136719, loss=0.8110010623931885
test: epoch 55, loss 2.090761423110962, acc=0.32777777314186096, loss=2.090761423110962
train: epoch 56, loss 0.829193651676178, acc=0.6504999995231628, loss=0.829193651676178
test: epoch 56, loss 2.05842661857605, acc=0.32499998807907104, loss=2.05842661857605
train: epoch 57, loss 0.8191341757774353, acc=0.6572777628898621, loss=0.8191341757774353
test: epoch 57, loss 2.0594754219055176, acc=0.3194444477558136, loss=2.0594754219055176
train: epoch 58, loss 0.80899977684021, acc=0.6553333401679993, loss=0.80899977684021
test: epoch 58, loss 2.1670498847961426, acc=0.3194444477558136, loss=2.1670498847961426
train: epoch 59, loss 0.8136110901832581, acc=0.6557222008705139, loss=0.8136110901832581
test: epoch 59, loss 2.308889389038086, acc=0.3222222328186035, loss=2.308889389038086
train: epoch 60, loss 0.8113185167312622, acc=0.6553333401679993, loss=0.8113185167312622
test: epoch 60, loss 2.1341307163238525, acc=0.32777777314186096, loss=2.1341307163238525
train: epoch 61, loss 0.793096125125885, acc=0.6636666655540466, loss=0.793096125125885
test: epoch 61, loss 2.0276174545288086, acc=0.3333333432674408, loss=2.0276174545288086
train: epoch 62, loss 0.7891977429389954, acc=0.6638333201408386, loss=0.7891977429389954
test: epoch 62, loss 2.263303756713867, acc=0.32777777314186096, loss=2.263303756713867
train: epoch 63, loss 0.7868391871452332, acc=0.6664999723434448, loss=0.7868391871452332
test: epoch 63, loss 2.0260024070739746, acc=0.3361110985279083, loss=2.0260024070739746
train: epoch 64, loss 0.7923206686973572, acc=0.6622777581214905, loss=0.7923206686973572
test: epoch 64, loss 2.0564897060394287, acc=0.3305555582046509, loss=2.0564897060394287
train: epoch 65, loss 0.7905427813529968, acc=0.6656666398048401, loss=0.7905427813529968
test: epoch 65, loss 2.1294474601745605, acc=0.33888888359069824, loss=2.1294474601745605
train: epoch 66, loss 0.7858577370643616, acc=0.6727777719497681, loss=0.7858577370643616
test: epoch 66, loss 1.9611924886703491, acc=0.33888888359069824, loss=1.9611924886703491
train: epoch 67, loss 0.7712347507476807, acc=0.6788333058357239, loss=0.7712347507476807
test: epoch 67, loss 1.9895375967025757, acc=0.3361110985279083, loss=1.9895375967025757
train: epoch 68, loss 0.7813116908073425, acc=0.6721110939979553, loss=0.7813116908073425
test: epoch 68, loss 2.03836727142334, acc=0.32499998807907104, loss=2.03836727142334
train: epoch 69, loss 0.7748144268989563, acc=0.6767777800559998, loss=0.7748144268989563
test: epoch 69, loss 2.1335678100585938, acc=0.33888888359069824, loss=2.1335678100585938
train: epoch 70, loss 0.7721728682518005, acc=0.6749444603919983, loss=0.7721728682518005
test: epoch 70, loss 2.2267906665802, acc=0.3333333432674408, loss=2.2267906665802
train: epoch 71, loss 0.7716575264930725, acc=0.6738333106040955, loss=0.7716575264930725
test: epoch 71, loss 2.062018632888794, acc=0.34166666865348816, loss=2.062018632888794
train: epoch 72, loss 0.7749583721160889, acc=0.6747778058052063, loss=0.7749583721160889
test: epoch 72, loss 2.0817818641662598, acc=0.33888888359069824, loss=2.0817818641662598
train: epoch 73, loss 0.7696382999420166, acc=0.675166666507721, loss=0.7696382999420166
test: epoch 73, loss 2.038268804550171, acc=0.32777777314186096, loss=2.038268804550171
train: epoch 74, loss 0.7655249834060669, acc=0.6784444451332092, loss=0.7655249834060669
test: epoch 74, loss 2.238626718521118, acc=0.3361110985279083, loss=2.238626718521118
train: epoch 75, loss 0.7692372798919678, acc=0.6746110916137695, loss=0.7692372798919678
test: epoch 75, loss 2.0114004611968994, acc=0.33888888359069824, loss=2.0114004611968994
train: epoch 76, loss 0.7497214674949646, acc=0.6831666827201843, loss=0.7497214674949646
test: epoch 76, loss 2.047445058822632, acc=0.3361110985279083, loss=2.047445058822632
train: epoch 77, loss 0.7653392553329468, acc=0.6804444193840027, loss=0.7653392553329468
test: epoch 77, loss 2.2566769123077393, acc=0.3361110985279083, loss=2.2566769123077393
train: epoch 78, loss 0.7648151516914368, acc=0.6852222084999084, loss=0.7648151516914368
test: epoch 78, loss 2.050433397293091, acc=0.3333333432674408, loss=2.050433397293091
train: epoch 79, loss 0.7530809640884399, acc=0.6822222471237183, loss=0.7530809640884399
test: epoch 79, loss 1.9617613554000854, acc=0.3499999940395355, loss=1.9617613554000854
train: epoch 80, loss 0.7632773518562317, acc=0.679444432258606, loss=0.7632773518562317
test: epoch 80, loss 2.2947797775268555, acc=0.3361110985279083, loss=2.2947797775268555
train: epoch 81, loss 0.7601393461227417, acc=0.6825555562973022, loss=0.7601393461227417
test: epoch 81, loss 2.0455777645111084, acc=0.34166666865348816, loss=2.0455777645111084
train: epoch 82, loss 0.7508867979049683, acc=0.6827222108840942, loss=0.7508867979049683
test: epoch 82, loss 2.221897840499878, acc=0.34166666865348816, loss=2.221897840499878
train: epoch 83, loss 0.7532686591148376, acc=0.6810555458068848, loss=0.7532686591148376
test: epoch 83, loss 2.013822078704834, acc=0.3361110985279083, loss=2.013822078704834
train: epoch 84, loss 0.7439728379249573, acc=0.6881666779518127, loss=0.7439728379249573
test: epoch 84, loss 2.147688865661621, acc=0.3361110985279083, loss=2.147688865661621
train: epoch 85, loss 0.7432650923728943, acc=0.6859999895095825, loss=0.7432650923728943
test: epoch 85, loss 2.0814208984375, acc=0.3444444537162781, loss=2.0814208984375
train: epoch 86, loss 0.7420685887336731, acc=0.6894444227218628, loss=0.7420685887336731
test: epoch 86, loss 2.2057464122772217, acc=0.3499999940395355, loss=2.2057464122772217
train: epoch 87, loss 0.7483174800872803, acc=0.6847777962684631, loss=0.7483174800872803
test: epoch 87, loss 2.1269168853759766, acc=0.3444444537162781, loss=2.1269168853759766
train: epoch 88, loss 0.7380168437957764, acc=0.6885555386543274, loss=0.7380168437957764
test: epoch 88, loss 2.0558414459228516, acc=0.35277777910232544, loss=2.0558414459228516
train: epoch 89, loss 0.7367616891860962, acc=0.6884999871253967, loss=0.7367616891860962
test: epoch 89, loss 2.0497007369995117, acc=0.3472222089767456, loss=2.0497007369995117
train: epoch 90, loss 0.7383955121040344, acc=0.687833309173584, loss=0.7383955121040344
test: epoch 90, loss 2.1096625328063965, acc=0.35277777910232544, loss=2.1096625328063965
train: epoch 91, loss 0.742582380771637, acc=0.6884444355964661, loss=0.742582380771637
test: epoch 91, loss 1.9263510704040527, acc=0.35277777910232544, loss=1.9263510704040527
train: epoch 92, loss 0.7360637187957764, acc=0.6846110820770264, loss=0.7360637187957764
test: epoch 92, loss 2.3281588554382324, acc=0.3499999940395355, loss=2.3281588554382324
train: epoch 93, loss 0.724205732345581, acc=0.691444456577301, loss=0.724205732345581
test: epoch 93, loss 2.1971898078918457, acc=0.3583333194255829, loss=2.1971898078918457
train: epoch 94, loss 0.7199823260307312, acc=0.6894999742507935, loss=0.7199823260307312
test: epoch 94, loss 2.3035409450531006, acc=0.3499999940395355, loss=2.3035409450531006
train: epoch 95, loss 0.7382737994194031, acc=0.6904444694519043, loss=0.7382737994194031
test: epoch 95, loss 2.398345947265625, acc=0.3499999940395355, loss=2.398345947265625
train: epoch 96, loss 0.7287948727607727, acc=0.6880000233650208, loss=0.7287948727607727
test: epoch 96, loss 2.2360873222351074, acc=0.34166666865348816, loss=2.2360873222351074
train: epoch 97, loss 0.7283317446708679, acc=0.6940555572509766, loss=0.7283317446708679
test: epoch 97, loss 1.9672967195510864, acc=0.3472222089767456, loss=1.9672967195510864
train: epoch 98, loss 0.7281774282455444, acc=0.6905555725097656, loss=0.7281774282455444
test: epoch 98, loss 2.1251282691955566, acc=0.3611111044883728, loss=2.1251282691955566
train: epoch 99, loss 0.7244923114776611, acc=0.6902777552604675, loss=0.7244923114776611
test: epoch 99, loss 2.0050370693206787, acc=0.3583333194255829, loss=2.0050370693206787
train: epoch 100, loss 0.7218593955039978, acc=0.6966111063957214, loss=0.7218593955039978
test: epoch 100, loss 2.4477086067199707, acc=0.3583333194255829, loss=2.4477086067199707
train: epoch 101, loss 0.723584771156311, acc=0.6968333125114441, loss=0.723584771156311
test: epoch 101, loss 2.0246269702911377, acc=0.35555556416511536, loss=2.0246269702911377
train: epoch 102, loss 0.7354166507720947, acc=0.6938333511352539, loss=0.7354166507720947
test: epoch 102, loss 2.054358720779419, acc=0.3499999940395355, loss=2.054358720779419
train: epoch 103, loss 0.727877140045166, acc=0.6930000185966492, loss=0.727877140045166
test: epoch 103, loss 2.145103693008423, acc=0.3611111044883728, loss=2.145103693008423
train: epoch 104, loss 0.72283935546875, acc=0.6959444284439087, loss=0.72283935546875
test: epoch 104, loss 2.2145743370056152, acc=0.35277777910232544, loss=2.2145743370056152
train: epoch 105, loss 0.7245033383369446, acc=0.6937777996063232, loss=0.7245033383369446
test: epoch 105, loss 2.029690980911255, acc=0.36666667461395264, loss=2.029690980911255
train: epoch 106, loss 0.7147242426872253, acc=0.6965555548667908, loss=0.7147242426872253
test: epoch 106, loss 2.0120606422424316, acc=0.35277777910232544, loss=2.0120606422424316
train: epoch 107, loss 0.7228512167930603, acc=0.6981666684150696, loss=0.7228512167930603
test: epoch 107, loss 2.007166862487793, acc=0.3611111044883728, loss=2.007166862487793
train: epoch 108, loss 0.7132769823074341, acc=0.6946666836738586, loss=0.7132769823074341
test: epoch 108, loss 2.258805990219116, acc=0.3638888895511627, loss=2.258805990219116
train: epoch 109, loss 0.7127736210823059, acc=0.694944441318512, loss=0.7127736210823059
test: epoch 109, loss 1.970117449760437, acc=0.35555556416511536, loss=1.970117449760437
train: epoch 110, loss 0.7117829322814941, acc=0.6985555291175842, loss=0.7117829322814941
test: epoch 110, loss 2.193199396133423, acc=0.36944442987442017, loss=2.193199396133423
train: epoch 111, loss 0.7186334729194641, acc=0.7010555267333984, loss=0.7186334729194641
test: epoch 111, loss 2.0894362926483154, acc=0.3722222149372101, loss=2.0894362926483154
train: epoch 112, loss 0.7155425548553467, acc=0.6986666917800903, loss=0.7155425548553467
test: epoch 112, loss 2.1321184635162354, acc=0.36944442987442017, loss=2.1321184635162354
train: epoch 113, loss 0.7167259454727173, acc=0.7003333568572998, loss=0.7167259454727173
test: epoch 113, loss 2.192189931869507, acc=0.35555556416511536, loss=2.192189931869507
train: epoch 114, loss 0.7037456035614014, acc=0.7028889060020447, loss=0.7037456035614014
test: epoch 114, loss 2.185953378677368, acc=0.36944442987442017, loss=2.185953378677368
train: epoch 115, loss 0.7041792869567871, acc=0.7054444551467896, loss=0.7041792869567871
test: epoch 115, loss 2.2049272060394287, acc=0.36944442987442017, loss=2.2049272060394287
train: epoch 116, loss 0.701320469379425, acc=0.7039444446563721, loss=0.701320469379425
test: epoch 116, loss 2.234569787979126, acc=0.3638888895511627, loss=2.234569787979126
train: epoch 117, loss 0.7072747349739075, acc=0.699055552482605, loss=0.7072747349739075
test: epoch 117, loss 2.0527026653289795, acc=0.36666667461395264, loss=2.0527026653289795
train: epoch 118, loss 0.7093509435653687, acc=0.6974999904632568, loss=0.7093509435653687
test: epoch 118, loss 2.3908722400665283, acc=0.3611111044883728, loss=2.3908722400665283
train: epoch 119, loss 0.7144953012466431, acc=0.699999988079071, loss=0.7144953012466431
test: epoch 119, loss 2.3334431648254395, acc=0.36666667461395264, loss=2.3334431648254395
train: epoch 120, loss 0.6961575150489807, acc=0.7046666741371155, loss=0.6961575150489807
test: epoch 120, loss 2.148012399673462, acc=0.375, loss=2.148012399673462
train: epoch 121, loss 0.6965555548667908, acc=0.7035555839538574, loss=0.6965555548667908
test: epoch 121, loss 2.2479538917541504, acc=0.3722222149372101, loss=2.2479538917541504
train: epoch 122, loss 0.7043890953063965, acc=0.7067221999168396, loss=0.7043890953063965
test: epoch 122, loss 2.134958028793335, acc=0.3777777850627899, loss=2.134958028793335
train: epoch 123, loss 0.6917802095413208, acc=0.7062777876853943, loss=0.6917802095413208
test: epoch 123, loss 2.3419651985168457, acc=0.3638888895511627, loss=2.3419651985168457
train: epoch 124, loss 0.6916504502296448, acc=0.7053333520889282, loss=0.6916504502296448
test: epoch 124, loss 2.3712286949157715, acc=0.38055557012557983, loss=2.3712286949157715
train: epoch 125, loss 0.7023268342018127, acc=0.7064999938011169, loss=0.7023268342018127
test: epoch 125, loss 2.2823588848114014, acc=0.38055557012557983, loss=2.2823588848114014
train: epoch 126, loss 0.6952570676803589, acc=0.7086666822433472, loss=0.6952570676803589
test: epoch 126, loss 2.214747905731201, acc=0.3777777850627899, loss=2.214747905731201
train: epoch 127, loss 0.6928253769874573, acc=0.7052222490310669, loss=0.6928253769874573
test: epoch 127, loss 2.1751303672790527, acc=0.375, loss=2.1751303672790527
train: epoch 128, loss 0.6861410737037659, acc=0.7084444165229797, loss=0.6861410737037659
test: epoch 128, loss 2.2855238914489746, acc=0.38055557012557983, loss=2.2855238914489746
train: epoch 129, loss 0.6945685744285583, acc=0.7087222337722778, loss=0.6945685744285583
test: epoch 129, loss 2.2034573554992676, acc=0.3777777850627899, loss=2.2034573554992676
train: epoch 130, loss 0.6937673687934875, acc=0.7059999704360962, loss=0.6937673687934875
test: epoch 130, loss 2.585026502609253, acc=0.3722222149372101, loss=2.585026502609253
train: epoch 131, loss 0.6938623189926147, acc=0.7072222232818604, loss=0.6938623189926147
test: epoch 131, loss 2.221461296081543, acc=0.36944442987442017, loss=2.221461296081543
train: epoch 132, loss 0.6804690957069397, acc=0.7127222418785095, loss=0.6804690957069397
test: epoch 132, loss 2.017233371734619, acc=0.38055557012557983, loss=2.017233371734619
train: epoch 133, loss 0.6871268153190613, acc=0.7055555582046509, loss=0.6871268153190613
test: epoch 133, loss 1.9301897287368774, acc=0.3722222149372101, loss=1.9301897287368774
train: epoch 134, loss 0.6794976592063904, acc=0.711388885974884, loss=0.6794976592063904
test: epoch 134, loss 2.196594715118408, acc=0.375, loss=2.196594715118408
train: epoch 135, loss 0.7027006149291992, acc=0.7048888802528381, loss=0.7027006149291992
test: epoch 135, loss 2.2918143272399902, acc=0.38055557012557983, loss=2.2918143272399902
train: epoch 136, loss 0.6886678338050842, acc=0.7124444246292114, loss=0.6886678338050842
test: epoch 136, loss 2.2220280170440674, acc=0.38055557012557983, loss=2.2220280170440674
train: epoch 137, loss 0.6889398694038391, acc=0.7114444375038147, loss=0.6889398694038391
test: epoch 137, loss 2.105541944503784, acc=0.3777777850627899, loss=2.105541944503784
train: epoch 138, loss 0.6820330023765564, acc=0.7130555510520935, loss=0.6820330023765564
test: epoch 138, loss 2.1878621578216553, acc=0.38333332538604736, loss=2.1878621578216553
train: epoch 139, loss 0.6940527558326721, acc=0.7119444608688354, loss=0.6940527558326721
test: epoch 139, loss 2.165761947631836, acc=0.36666667461395264, loss=2.165761947631836
train: epoch 140, loss 0.6801822781562805, acc=0.7171666622161865, loss=0.6801822781562805
test: epoch 140, loss 2.380542039871216, acc=0.36666667461395264, loss=2.380542039871216
train: epoch 141, loss 0.6823862195014954, acc=0.7136111259460449, loss=0.6823862195014954
test: epoch 141, loss 2.5019490718841553, acc=0.36944442987442017, loss=2.5019490718841553
train: epoch 142, loss 0.6968328356742859, acc=0.7135000228881836, loss=0.6968328356742859
test: epoch 142, loss 2.186450242996216, acc=0.38055557012557983, loss=2.186450242996216
train: epoch 143, loss 0.6850993633270264, acc=0.7152222394943237, loss=0.6850993633270264
test: epoch 143, loss 2.2111897468566895, acc=0.38055557012557983, loss=2.2111897468566895
train: epoch 144, loss 0.6717821359634399, acc=0.7177222371101379, loss=0.6717821359634399
test: epoch 144, loss 2.1365489959716797, acc=0.3861111104488373, loss=2.1365489959716797
train: epoch 145, loss 0.6776570677757263, acc=0.7168889045715332, loss=0.6776570677757263
test: epoch 145, loss 2.002342462539673, acc=0.3888888955116272, loss=2.002342462539673
train: epoch 146, loss 0.6720846891403198, acc=0.7206666469573975, loss=0.6720846891403198
test: epoch 146, loss 2.293262481689453, acc=0.38055557012557983, loss=2.293262481689453
train: epoch 147, loss 0.6661242246627808, acc=0.7195000052452087, loss=0.6661242246627808
test: epoch 147, loss 2.4791202545166016, acc=0.3888888955116272, loss=2.4791202545166016
train: epoch 148, loss 0.6815369725227356, acc=0.7160000205039978, loss=0.6815369725227356
test: epoch 148, loss 2.2273452281951904, acc=0.39444443583488464, loss=2.2273452281951904
train: epoch 149, loss 0.6697254776954651, acc=0.7210555672645569, loss=0.6697254776954651
test: epoch 149, loss 1.9461231231689453, acc=0.4000000059604645, loss=1.9461231231689453
train: epoch 150, loss 0.6668444871902466, acc=0.7213888764381409, loss=0.6668444871902466
test: epoch 150, loss 2.0474038124084473, acc=0.4027777910232544, loss=2.0474038124084473
