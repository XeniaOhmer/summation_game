# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=2.0", "--temp_decay=0.99", "--one_hot=false", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=894249755, receiver_embed_dim=128, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.6917386054992676, acc=0.10966666787862778, loss=2.6917386054992676
test: epoch 1, loss 4.0485358238220215, acc=0.07777778059244156, loss=4.0485358238220215
train: epoch 2, loss 1.637527585029602, acc=0.2875555455684662, loss=1.637527585029602
test: epoch 2, loss 2.8577332496643066, acc=0.1527777761220932, loss=2.8577332496643066
train: epoch 3, loss 1.1032794713974, acc=0.5254444479942322, loss=1.1032794713974
test: epoch 3, loss 2.42207932472229, acc=0.2888889014720917, loss=2.42207932472229
train: epoch 4, loss 0.7896072864532471, acc=0.6664999723434448, loss=0.7896072864532471
test: epoch 4, loss 2.228910446166992, acc=0.39722222089767456, loss=2.228910446166992
train: epoch 5, loss 0.5075459480285645, acc=0.7860000133514404, loss=0.5075459480285645
test: epoch 5, loss 1.8453043699264526, acc=0.4194444417953491, loss=1.8453043699264526
train: epoch 6, loss 0.39943069219589233, acc=0.8281111121177673, loss=0.39943069219589233
test: epoch 6, loss 1.8746521472930908, acc=0.4305555522441864, loss=1.8746521472930908
train: epoch 7, loss 0.35735923051834106, acc=0.8451666831970215, loss=0.35735923051834106
test: epoch 7, loss 1.470368504524231, acc=0.5222222208976746, loss=1.470368504524231
train: epoch 8, loss 0.31733325123786926, acc=0.8665555715560913, loss=0.31733325123786926
test: epoch 8, loss 1.6836694478988647, acc=0.4472222328186035, loss=1.6836694478988647
train: epoch 9, loss 0.2693156898021698, acc=0.8854444622993469, loss=0.2693156898021698
test: epoch 9, loss 1.3377151489257812, acc=0.5416666865348816, loss=1.3377151489257812
train: epoch 10, loss 0.24389342963695526, acc=0.8960000276565552, loss=0.24389342963695526
test: epoch 10, loss 1.2847259044647217, acc=0.6111111044883728, loss=1.2847259044647217
train: epoch 11, loss 0.2534337639808655, acc=0.8936111330986023, loss=0.2534337639808655
test: epoch 11, loss 1.4899922609329224, acc=0.5166666507720947, loss=1.4899922609329224
train: epoch 12, loss 0.24308256804943085, acc=0.8964999914169312, loss=0.24308256804943085
test: epoch 12, loss 1.1914340257644653, acc=0.5666666626930237, loss=1.1914340257644653
train: epoch 13, loss 0.227144256234169, acc=0.903166651725769, loss=0.227144256234169
test: epoch 13, loss 1.0559773445129395, acc=0.6277777552604675, loss=1.0559773445129395
train: epoch 14, loss 0.22450944781303406, acc=0.9021111130714417, loss=0.22450944781303406
test: epoch 14, loss 1.4261687994003296, acc=0.5861111283302307, loss=1.4261687994003296
train: epoch 15, loss 0.20009197294712067, acc=0.9149444699287415, loss=0.20009197294712067
test: epoch 15, loss 0.8865867257118225, acc=0.699999988079071, loss=0.8865867257118225
train: epoch 16, loss 0.19697290658950806, acc=0.9164999723434448, loss=0.19697290658950806
test: epoch 16, loss 0.8968750238418579, acc=0.7166666388511658, loss=0.8968750238418579
train: epoch 17, loss 0.1869908720254898, acc=0.9203888773918152, loss=0.1869908720254898
test: epoch 17, loss 0.8974077105522156, acc=0.6972222328186035, loss=0.8974077105522156
train: epoch 18, loss 0.21836726367473602, acc=0.9117777943611145, loss=0.21836726367473602
test: epoch 18, loss 1.1572798490524292, acc=0.6638888716697693, loss=1.1572798490524292
train: epoch 19, loss 0.20201842486858368, acc=0.9171666502952576, loss=0.20201842486858368
test: epoch 19, loss 0.8985168933868408, acc=0.7444444298744202, loss=0.8985168933868408
train: epoch 20, loss 0.18657998740673065, acc=0.9201666712760925, loss=0.18657998740673065
test: epoch 20, loss 0.7479504942893982, acc=0.7972221970558167, loss=0.7479504942893982
train: epoch 21, loss 0.18180613219738007, acc=0.924833357334137, loss=0.18180613219738007
test: epoch 21, loss 0.8998095989227295, acc=0.7444444298744202, loss=0.8998095989227295
train: epoch 22, loss 0.19219326972961426, acc=0.9217777848243713, loss=0.19219326972961426
test: epoch 22, loss 0.6836355328559875, acc=0.7888888716697693, loss=0.6836355328559875
train: epoch 23, loss 0.15258824825286865, acc=0.9325555562973022, loss=0.15258824825286865
test: epoch 23, loss 0.6457063555717468, acc=0.8305555582046509, loss=0.6457063555717468
train: epoch 24, loss 0.16165004670619965, acc=0.930055558681488, loss=0.16165004670619965
test: epoch 24, loss 0.44925656914711, acc=0.8194444179534912, loss=0.44925656914711
train: epoch 25, loss 0.18989789485931396, acc=0.9169999957084656, loss=0.18989789485931396
test: epoch 25, loss 0.5853883624076843, acc=0.8416666388511658, loss=0.5853883624076843
train: epoch 26, loss 0.16822300851345062, acc=0.930055558681488, loss=0.16822300851345062
test: epoch 26, loss 0.4157014787197113, acc=0.8805555701255798, loss=0.4157014787197113
train: epoch 27, loss 0.13642215728759766, acc=0.9392777681350708, loss=0.13642215728759766
test: epoch 27, loss 0.32972943782806396, acc=0.8833333253860474, loss=0.32972943782806396
train: epoch 28, loss 0.17619723081588745, acc=0.9313333630561829, loss=0.17619723081588745
test: epoch 28, loss 0.5020574927330017, acc=0.8833333253860474, loss=0.5020574927330017
train: epoch 29, loss 0.16765201091766357, acc=0.9265555739402771, loss=0.16765201091766357
test: epoch 29, loss 0.21717135608196259, acc=0.9055555462837219, loss=0.21717135608196259
train: epoch 30, loss 0.1629520058631897, acc=0.9308888912200928, loss=0.1629520058631897
test: epoch 30, loss 0.25142115354537964, acc=0.8666666746139526, loss=0.25142115354537964
train: epoch 31, loss 0.16536207497119904, acc=0.9316666722297668, loss=0.16536207497119904
test: epoch 31, loss 0.28601762652397156, acc=0.9194444417953491, loss=0.28601762652397156
train: epoch 32, loss 0.18582507967948914, acc=0.9268333315849304, loss=0.18582507967948914
test: epoch 32, loss 0.17925019562244415, acc=0.9305555820465088, loss=0.17925019562244415
train: epoch 33, loss 0.15762805938720703, acc=0.930388867855072, loss=0.15762805938720703
test: epoch 33, loss 0.0947999581694603, acc=0.9472222328186035, loss=0.0947999581694603
train: epoch 34, loss 0.1079268828034401, acc=0.9415000081062317, loss=0.1079268828034401
test: epoch 34, loss 0.15263916552066803, acc=0.9361110925674438, loss=0.15263916552066803
train: epoch 35, loss 0.1737097054719925, acc=0.9221110939979553, loss=0.1737097054719925
test: epoch 35, loss 0.1592264026403427, acc=0.9333333373069763, loss=0.1592264026403427
train: epoch 36, loss 0.17822952568531036, acc=0.929722249507904, loss=0.17822952568531036
test: epoch 36, loss 0.14049796760082245, acc=0.9416666626930237, loss=0.14049796760082245
train: epoch 37, loss 0.11379645764827728, acc=0.9455000162124634, loss=0.11379645764827728
test: epoch 37, loss 0.15370486676692963, acc=0.9444444179534912, loss=0.15370486676692963
train: epoch 38, loss 0.12440129369497299, acc=0.9431111216545105, loss=0.12440129369497299
test: epoch 38, loss 0.10237269103527069, acc=0.9472222328186035, loss=0.10237269103527069
train: epoch 39, loss 0.1443895399570465, acc=0.9394444227218628, loss=0.1443895399570465
test: epoch 39, loss 0.19241714477539062, acc=0.9277777671813965, loss=0.19241714477539062
train: epoch 40, loss 0.17726363241672516, acc=0.9310555458068848, loss=0.17726363241672516
test: epoch 40, loss 0.12706969678401947, acc=0.9416666626930237, loss=0.12706969678401947
train: epoch 41, loss 0.12873530387878418, acc=0.941611111164093, loss=0.12873530387878418
test: epoch 41, loss 0.07971512526273727, acc=0.9527778029441833, loss=0.07971512526273727
train: epoch 42, loss 0.11010538041591644, acc=0.9468333125114441, loss=0.11010538041591644
test: epoch 42, loss 0.08862865716218948, acc=0.949999988079071, loss=0.08862865716218948
train: epoch 43, loss 0.13994431495666504, acc=0.941277801990509, loss=0.13994431495666504
test: epoch 43, loss 0.09169058501720428, acc=0.949999988079071, loss=0.09169058501720428
train: epoch 44, loss 0.18584823608398438, acc=0.9292222261428833, loss=0.18584823608398438
test: epoch 44, loss 0.2538124620914459, acc=0.9138888716697693, loss=0.2538124620914459
train: epoch 45, loss 0.12651652097702026, acc=0.941611111164093, loss=0.12651652097702026
test: epoch 45, loss 0.09061925858259201, acc=0.949999988079071, loss=0.09061925858259201
train: epoch 46, loss 0.09000027179718018, acc=0.9502221941947937, loss=0.09000027179718018
test: epoch 46, loss 0.07837482541799545, acc=0.9527778029441833, loss=0.07837482541799545
train: epoch 47, loss 0.13391004502773285, acc=0.9427222013473511, loss=0.13391004502773285
test: epoch 47, loss 0.09587673842906952, acc=0.9472222328186035, loss=0.09587673842906952
train: epoch 48, loss 0.17943163216114044, acc=0.9295555353164673, loss=0.17943163216114044
test: epoch 48, loss 0.2031482756137848, acc=0.9333333373069763, loss=0.2031482756137848
train: epoch 49, loss 0.20008955895900726, acc=0.9203333258628845, loss=0.20008955895900726
test: epoch 49, loss 0.13373614847660065, acc=0.9333333373069763, loss=0.13373614847660065
train: epoch 50, loss 0.1253168135881424, acc=0.9357222318649292, loss=0.1253168135881424
test: epoch 50, loss 0.12143433094024658, acc=0.9361110925674438, loss=0.12143433094024658
train: epoch 51, loss 0.12814365327358246, acc=0.9351111054420471, loss=0.12814365327358246
test: epoch 51, loss 0.13131466507911682, acc=0.9333333373069763, loss=0.13131466507911682
train: epoch 52, loss 0.214565247297287, acc=0.9177777767181396, loss=0.214565247297287
test: epoch 52, loss 0.1412348449230194, acc=0.9305555820465088, loss=0.1412348449230194
train: epoch 53, loss 0.14696037769317627, acc=0.9308888912200928, loss=0.14696037769317627
test: epoch 53, loss 0.10878067463636398, acc=0.9416666626930237, loss=0.10878067463636398
train: epoch 54, loss 0.12024091184139252, acc=0.9375, loss=0.12024091184139252
test: epoch 54, loss 0.11959544569253922, acc=0.9361110925674438, loss=0.11959544569253922
train: epoch 55, loss 0.13338804244995117, acc=0.9328333139419556, loss=0.13338804244995117
test: epoch 55, loss 0.12954269349575043, acc=0.9305555820465088, loss=0.12954269349575043
train: epoch 56, loss 0.2603496313095093, acc=0.8973888754844666, loss=0.2603496313095093
test: epoch 56, loss 0.2634282410144806, acc=0.894444465637207, loss=0.2634282410144806
train: epoch 57, loss 0.18689250946044922, acc=0.9141111373901367, loss=0.18689250946044922
test: epoch 57, loss 0.1172032579779625, acc=0.9361110925674438, loss=0.1172032579779625
train: epoch 58, loss 0.11825552582740784, acc=0.9361110925674438, loss=0.11825552582740784
test: epoch 58, loss 0.11657759547233582, acc=0.9361110925674438, loss=0.11657759547233582
train: epoch 59, loss 0.1730416715145111, acc=0.9239444732666016, loss=0.1730416715145111
test: epoch 59, loss 0.25815340876579285, acc=0.8916666507720947, loss=0.25815340876579285
train: epoch 60, loss 0.1594998985528946, acc=0.9220555424690247, loss=0.1594998985528946
test: epoch 60, loss 0.14810287952423096, acc=0.9222221970558167, loss=0.14810287952423096
train: epoch 61, loss 0.14496788382530212, acc=0.9220555424690247, loss=0.14496788382530212
test: epoch 61, loss 0.14250318706035614, acc=0.9222221970558167, loss=0.14250318706035614
train: epoch 62, loss 0.1497122049331665, acc=0.9211666584014893, loss=0.1497122049331665
test: epoch 62, loss 0.1427181512117386, acc=0.9222221970558167, loss=0.1427181512117386
train: epoch 63, loss 0.14531032741069794, acc=0.9214444160461426, loss=0.14531032741069794
test: epoch 63, loss 0.14152929186820984, acc=0.9222221970558167, loss=0.14152929186820984
train: epoch 64, loss 0.14371809363365173, acc=0.92166668176651, loss=0.14371809363365173
test: epoch 64, loss 0.1413975954055786, acc=0.9222221970558167, loss=0.1413975954055786
train: epoch 65, loss 0.39104461669921875, acc=0.8578888773918152, loss=0.39104461669921875
test: epoch 65, loss 0.26637014746665955, acc=0.8777777552604675, loss=0.26637014746665955
train: epoch 66, loss 0.30700913071632385, acc=0.867111086845398, loss=0.30700913071632385
test: epoch 66, loss 0.2558470368385315, acc=0.8722222447395325, loss=0.2558470368385315
train: epoch 67, loss 0.32135170698165894, acc=0.8547222018241882, loss=0.32135170698165894
test: epoch 67, loss 0.3313843309879303, acc=0.8444444537162781, loss=0.3313843309879303
train: epoch 68, loss 0.2616938352584839, acc=0.8782777786254883, loss=0.2616938352584839
test: epoch 68, loss 0.21521280705928802, acc=0.8916666507720947, loss=0.21521280705928802
train: epoch 69, loss 0.23415371775627136, acc=0.8924444317817688, loss=0.23415371775627136
test: epoch 69, loss 0.27260008454322815, acc=0.894444465637207, loss=0.27260008454322815
train: epoch 70, loss 0.2488974928855896, acc=0.8902222514152527, loss=0.2488974928855896
test: epoch 70, loss 0.220794677734375, acc=0.9027777910232544, loss=0.220794677734375
train: epoch 71, loss 0.1980140656232834, acc=0.9036111235618591, loss=0.1980140656232834
test: epoch 71, loss 0.1900424212217331, acc=0.9027777910232544, loss=0.1900424212217331
train: epoch 72, loss 0.20178572833538055, acc=0.9024444222450256, loss=0.20178572833538055
test: epoch 72, loss 0.20763491094112396, acc=0.8861111402511597, loss=0.20763491094112396
train: epoch 73, loss 0.29889968037605286, acc=0.8584444522857666, loss=0.29889968037605286
test: epoch 73, loss 0.2990516722202301, acc=0.8694444298744202, loss=0.2990516722202301
train: epoch 74, loss 0.24430029094219208, acc=0.8811666369438171, loss=0.24430029094219208
test: epoch 74, loss 0.22099652886390686, acc=0.8888888955116272, loss=0.22099652886390686
train: epoch 75, loss 0.2753934860229492, acc=0.8792222142219543, loss=0.2753934860229492
test: epoch 75, loss 0.31065118312835693, acc=0.8777777552604675, loss=0.31065118312835693
train: epoch 76, loss 0.22914285957813263, acc=0.8921666741371155, loss=0.22914285957813263
test: epoch 76, loss 0.2036602646112442, acc=0.8999999761581421, loss=0.2036602646112442
train: epoch 77, loss 0.20480574667453766, acc=0.9007222056388855, loss=0.20480574667453766
test: epoch 77, loss 0.19293539226055145, acc=0.9027777910232544, loss=0.19293539226055145
train: epoch 78, loss 0.19420863687992096, acc=0.9031111001968384, loss=0.19420863687992096
test: epoch 78, loss 0.1870032399892807, acc=0.9055555462837219, loss=0.1870032399892807
train: epoch 79, loss 0.18854372203350067, acc=0.9055555462837219, loss=0.18854372203350067
test: epoch 79, loss 0.1868835985660553, acc=0.9055555462837219, loss=0.1868835985660553
train: epoch 80, loss 0.2913578152656555, acc=0.8855555653572083, loss=0.2913578152656555
test: epoch 80, loss 0.25303828716278076, acc=0.8861111402511597, loss=0.25303828716278076
train: epoch 81, loss 0.2182922214269638, acc=0.8986666798591614, loss=0.2182922214269638
test: epoch 81, loss 0.1936250925064087, acc=0.9027777910232544, loss=0.1936250925064087
train: epoch 82, loss 0.1967390775680542, acc=0.9026111364364624, loss=0.1967390775680542
test: epoch 82, loss 0.19425329566001892, acc=0.9027777910232544, loss=0.19425329566001892
train: epoch 83, loss 0.19519054889678955, acc=0.9027777910232544, loss=0.19519054889678955
test: epoch 83, loss 0.19291220605373383, acc=0.9027777910232544, loss=0.19291220605373383
train: epoch 84, loss 0.28256678581237793, acc=0.8847777843475342, loss=0.28256678581237793
test: epoch 84, loss 0.24522866308689117, acc=0.8888888955116272, loss=0.24522866308689117
train: epoch 85, loss 0.239206925034523, acc=0.8893888592720032, loss=0.239206925034523
test: epoch 85, loss 0.2252032458782196, acc=0.8916666507720947, loss=0.2252032458782196
train: epoch 86, loss 0.2921111285686493, acc=0.8805000185966492, loss=0.2921111285686493
test: epoch 86, loss 0.2529587149620056, acc=0.8833333253860474, loss=0.2529587149620056
train: epoch 87, loss 0.25848349928855896, acc=0.882888913154602, loss=0.25848349928855896
test: epoch 87, loss 0.2593516409397125, acc=0.8805555701255798, loss=0.2593516409397125
train: epoch 88, loss 0.28338107466697693, acc=0.8731666803359985, loss=0.28338107466697693
test: epoch 88, loss 0.2815766930580139, acc=0.8722222447395325, loss=0.2815766930580139
train: epoch 89, loss 0.34441763162612915, acc=0.856333315372467, loss=0.34441763162612915
test: epoch 89, loss 0.3947973847389221, acc=0.8361111283302307, loss=0.3947973847389221
train: epoch 90, loss 0.3398562967777252, acc=0.8536111116409302, loss=0.3398562967777252
test: epoch 90, loss 0.30166545510292053, acc=0.8611111044883728, loss=0.30166545510292053
train: epoch 91, loss 0.306240051984787, acc=0.8607777953147888, loss=0.306240051984787
test: epoch 91, loss 0.3051786422729492, acc=0.8611111044883728, loss=0.3051786422729492
train: epoch 92, loss 0.31392669677734375, acc=0.859333336353302, loss=0.31392669677734375
test: epoch 92, loss 0.3906887471675873, acc=0.8583333492279053, loss=0.3906887471675873
train: epoch 93, loss 0.29689088463783264, acc=0.8737778067588806, loss=0.29689088463783264
test: epoch 93, loss 0.26354455947875977, acc=0.8805555701255798, loss=0.26354455947875977
train: epoch 94, loss 0.26210081577301025, acc=0.8810555338859558, loss=0.26210081577301025
test: epoch 94, loss 0.24036701023578644, acc=0.8888888955116272, loss=0.24036701023578644
train: epoch 95, loss 0.24310016632080078, acc=0.8870555758476257, loss=0.24310016632080078
test: epoch 95, loss 0.2400316298007965, acc=0.8888888955116272, loss=0.2400316298007965
train: epoch 96, loss 0.24315312504768372, acc=0.8874444365501404, loss=0.24315312504768372
test: epoch 96, loss 0.2399795651435852, acc=0.8888888955116272, loss=0.2399795651435852
train: epoch 97, loss 0.33386293053627014, acc=0.8712777495384216, loss=0.33386293053627014
test: epoch 97, loss 0.38621988892555237, acc=0.8444444537162781, loss=0.38621988892555237
train: epoch 98, loss 0.35874438285827637, acc=0.8516666889190674, loss=0.35874438285827637
test: epoch 98, loss 0.34183698892593384, acc=0.8500000238418579, loss=0.34183698892593384
train: epoch 99, loss 0.35509800910949707, acc=0.8459444642066956, loss=0.35509800910949707
test: epoch 99, loss 0.4701679050922394, acc=0.8305555582046509, loss=0.4701679050922394
train: epoch 100, loss 0.3331888020038605, acc=0.8588333129882812, loss=0.3331888020038605
test: epoch 100, loss 0.23816683888435364, acc=0.8833333253860474, loss=0.23816683888435364
train: epoch 101, loss 0.24237403273582458, acc=0.8765555620193481, loss=0.24237403273582458
test: epoch 101, loss 0.23819610476493835, acc=0.8833333253860474, loss=0.23819610476493835
train: epoch 102, loss 0.24054285883903503, acc=0.8758333325386047, loss=0.24054285883903503
test: epoch 102, loss 0.2380666732788086, acc=0.8833333253860474, loss=0.2380666732788086
train: epoch 103, loss 0.24035891890525818, acc=0.8756666779518127, loss=0.24035891890525818
test: epoch 103, loss 0.23800909519195557, acc=0.8833333253860474, loss=0.23800909519195557
train: epoch 104, loss 0.37278398871421814, acc=0.8467777967453003, loss=0.37278398871421814
test: epoch 104, loss 0.3411572575569153, acc=0.8500000238418579, loss=0.3411572575569153
train: epoch 105, loss 0.34114545583724976, acc=0.851722240447998, loss=0.34114545583724976
test: epoch 105, loss 0.33343130350112915, acc=0.8527777791023254, loss=0.33343130350112915
train: epoch 106, loss 0.35411742329597473, acc=0.8478888869285583, loss=0.35411742329597473
test: epoch 106, loss 0.3818715214729309, acc=0.8333333134651184, loss=0.3818715214729309
train: epoch 107, loss 0.3959081768989563, acc=0.8441666960716248, loss=0.3959081768989563
test: epoch 107, loss 0.2927573323249817, acc=0.8833333253860474, loss=0.2927573323249817
train: epoch 108, loss 0.29891237616539, acc=0.8799999952316284, loss=0.29891237616539
test: epoch 108, loss 0.25148680806159973, acc=0.8888888955116272, loss=0.25148680806159973
train: epoch 109, loss 0.27237045764923096, acc=0.8842777609825134, loss=0.27237045764923096
test: epoch 109, loss 0.3477821946144104, acc=0.875, loss=0.3477821946144104
train: epoch 110, loss 0.2800195515155792, acc=0.882777750492096, loss=0.2800195515155792
test: epoch 110, loss 0.27245447039604187, acc=0.8833333253860474, loss=0.27245447039604187
train: epoch 111, loss 0.2760571539402008, acc=0.8833333253860474, loss=0.2760571539402008
test: epoch 111, loss 0.27207669615745544, acc=0.8833333253860474, loss=0.27207669615745544
train: epoch 112, loss 0.27553635835647583, acc=0.8833333253860474, loss=0.27553635835647583
test: epoch 112, loss 0.27195391058921814, acc=0.8833333253860474, loss=0.27195391058921814
train: epoch 113, loss 0.34233057498931885, acc=0.8640000224113464, loss=0.34233057498931885
test: epoch 113, loss 0.3301168382167816, acc=0.8583333492279053, loss=0.3301168382167816
train: epoch 114, loss 0.28841689229011536, acc=0.8729444742202759, loss=0.28841689229011536
test: epoch 114, loss 0.30967292189598083, acc=0.8638888597488403, loss=0.30967292189598083
train: epoch 115, loss 0.3594399094581604, acc=0.8561111092567444, loss=0.3594399094581604
test: epoch 115, loss 0.2937653362751007, acc=0.8694444298744202, loss=0.2937653362751007
train: epoch 116, loss 0.27255627512931824, acc=0.8813889026641846, loss=0.27255627512931824
test: epoch 116, loss 0.2347983568906784, acc=0.8972222208976746, loss=0.2347983568906784
train: epoch 117, loss 0.23459331691265106, acc=0.8994444608688354, loss=0.23459331691265106
test: epoch 117, loss 0.22759903967380524, acc=0.8999999761581421, loss=0.22759903967380524
train: epoch 118, loss 0.29489514231681824, acc=0.8815555572509766, loss=0.29489514231681824
test: epoch 118, loss 0.4307364821434021, acc=0.8361111283302307, loss=0.4307364821434021
train: epoch 119, loss 0.4798978269100189, acc=0.8078333139419556, loss=0.4798978269100189
test: epoch 119, loss 0.4373549818992615, acc=0.8138889074325562, loss=0.4373549818992615
train: epoch 120, loss 0.44068843126296997, acc=0.8138889074325562, loss=0.44068843126296997
test: epoch 120, loss 0.43460729718208313, acc=0.8138889074325562, loss=0.43460729718208313
train: epoch 121, loss 0.44742509722709656, acc=0.8141666650772095, loss=0.44742509722709656
test: epoch 121, loss 0.43129315972328186, acc=0.8166666626930237, loss=0.43129315972328186
train: epoch 122, loss 0.4305790364742279, acc=0.8177777528762817, loss=0.4305790364742279
test: epoch 122, loss 0.42369481921195984, acc=0.8194444179534912, loss=0.42369481921195984
train: epoch 123, loss 0.522874116897583, acc=0.7919444441795349, loss=0.522874116897583
test: epoch 123, loss 0.4575214385986328, acc=0.8055555820465088, loss=0.4575214385986328
train: epoch 124, loss 0.45180222392082214, acc=0.8075555562973022, loss=0.45180222392082214
test: epoch 124, loss 0.44127410650253296, acc=0.8083333373069763, loss=0.44127410650253296
train: epoch 125, loss 0.44417715072631836, acc=0.8083333373069763, loss=0.44417715072631836
test: epoch 125, loss 0.44037213921546936, acc=0.8083333373069763, loss=0.44037213921546936
train: epoch 126, loss 0.43440747261047363, acc=0.8110555410385132, loss=0.43440747261047363
test: epoch 126, loss 0.4306800067424774, acc=0.8111110925674438, loss=0.4306800067424774
train: epoch 127, loss 0.4337763488292694, acc=0.8111110925674438, loss=0.4337763488292694
test: epoch 127, loss 0.4306386411190033, acc=0.8111110925674438, loss=0.4306386411190033
train: epoch 128, loss 0.43365004658699036, acc=0.8111110925674438, loss=0.43365004658699036
test: epoch 128, loss 0.4305204153060913, acc=0.8111110925674438, loss=0.4305204153060913
train: epoch 129, loss 0.4344436228275299, acc=0.8111666440963745, loss=0.4344436228275299
test: epoch 129, loss 0.43081000447273254, acc=0.8111110925674438, loss=0.43081000447273254
train: epoch 130, loss 0.4351830780506134, acc=0.8108333349227905, loss=0.4351830780506134
test: epoch 130, loss 0.43106791377067566, acc=0.8111110925674438, loss=0.43106791377067566
train: epoch 131, loss 0.42657598853111267, acc=0.8137778043746948, loss=0.42657598853111267
test: epoch 131, loss 0.41632047295570374, acc=0.8138889074325562, loss=0.41632047295570374
train: epoch 132, loss 0.6299114227294922, acc=0.7698888778686523, loss=0.6299114227294922
test: epoch 132, loss 0.5911819338798523, acc=0.75, loss=0.5911819338798523
train: epoch 133, loss 0.5172170996665955, acc=0.7769444584846497, loss=0.5172170996665955
test: epoch 133, loss 0.4871498942375183, acc=0.7833333611488342, loss=0.4871498942375183
train: epoch 134, loss 0.487230122089386, acc=0.7789444327354431, loss=0.487230122089386
test: epoch 134, loss 0.4808902442455292, acc=0.7861111164093018, loss=0.4808902442455292
train: epoch 135, loss 0.48634782433509827, acc=0.7756666541099548, loss=0.48634782433509827
test: epoch 135, loss 0.4839097857475281, acc=0.7805555462837219, loss=0.4839097857475281
train: epoch 136, loss 0.4885592758655548, acc=0.7683888673782349, loss=0.4885592758655548
test: epoch 136, loss 0.4850524961948395, acc=0.7777777910232544, loss=0.4850524961948395
train: epoch 137, loss 0.488547146320343, acc=0.765333354473114, loss=0.488547146320343
test: epoch 137, loss 0.48497188091278076, acc=0.7777777910232544, loss=0.48497188091278076
train: epoch 138, loss 0.569002091884613, acc=0.7722777724266052, loss=0.569002091884613
test: epoch 138, loss 0.4519534707069397, acc=0.8222222328186035, loss=0.4519534707069397
train: epoch 139, loss 0.4140092134475708, acc=0.815666675567627, loss=0.4140092134475708
test: epoch 139, loss 1.808768630027771, acc=0.824999988079071, loss=1.808768630027771
train: epoch 140, loss 0.43674436211586, acc=0.8151111006736755, loss=0.43674436211586
test: epoch 140, loss 0.40331438183784485, acc=0.824999988079071, loss=0.40331438183784485
train: epoch 141, loss 0.4052141308784485, acc=0.8157222270965576, loss=0.4052141308784485
test: epoch 141, loss 0.393462210893631, acc=0.8277778029441833, loss=0.393462210893631
train: epoch 142, loss 0.39766037464141846, acc=0.8178333044052124, loss=0.39766037464141846
test: epoch 142, loss 0.39326146245002747, acc=0.8277778029441833, loss=0.39326146245002747
train: epoch 143, loss 0.4227255582809448, acc=0.8160555362701416, loss=0.4227255582809448
test: epoch 143, loss 0.45746830105781555, acc=0.8027777671813965, loss=0.45746830105781555
train: epoch 144, loss 0.4239897131919861, acc=0.8084444403648376, loss=0.4239897131919861
test: epoch 144, loss 0.39434951543807983, acc=0.8222222328186035, loss=0.39434951543807983
train: epoch 145, loss 0.3976062834262848, acc=0.8127777576446533, loss=0.3976062834262848
test: epoch 145, loss 0.39347925782203674, acc=0.8222222328186035, loss=0.39347925782203674
train: epoch 146, loss 0.3867429196834564, acc=0.816777765750885, loss=0.3867429196834564
test: epoch 146, loss 0.37990978360176086, acc=0.8277778029441833, loss=0.37990978360176086
train: epoch 147, loss 0.38964807987213135, acc=0.8199999928474426, loss=0.38964807987213135
test: epoch 147, loss 0.38391390442848206, acc=0.8277778029441833, loss=0.38391390442848206
train: epoch 148, loss 0.4255504310131073, acc=0.8106111288070679, loss=0.4255504310131073
test: epoch 148, loss 0.39797911047935486, acc=0.8194444179534912, loss=0.39797911047935486
train: epoch 149, loss 0.401838093996048, acc=0.8100000023841858, loss=0.401838093996048
test: epoch 149, loss 0.3968867063522339, acc=0.8194444179534912, loss=0.3968867063522339
train: epoch 150, loss 0.4014166593551636, acc=0.8097777962684631, loss=0.4014166593551636
test: epoch 150, loss 0.39665690064430237, acc=0.8194444179534912, loss=0.39665690064430237
