# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=1", "--one_hot=true", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1797468513, receiver_embed_dim=64, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.716787338256836, acc=0.10877777636051178, loss=2.716787338256836
test: epoch 1, loss 4.187568187713623, acc=0.09166666865348816, loss=4.187568187713623
train: epoch 2, loss 1.965180516242981, acc=0.2173333317041397, loss=1.965180516242981
test: epoch 2, loss 3.5920217037200928, acc=0.11666666716337204, loss=3.5920217037200928
train: epoch 3, loss 1.69331955909729, acc=0.2884444296360016, loss=1.69331955909729
test: epoch 3, loss 2.603928804397583, acc=0.1805555522441864, loss=2.603928804397583
train: epoch 4, loss 1.4871701002120972, acc=0.343833327293396, loss=1.4871701002120972
test: epoch 4, loss 2.0532119274139404, acc=0.21944443881511688, loss=2.0532119274139404
train: epoch 5, loss 1.3293734788894653, acc=0.3935000002384186, loss=1.3293734788894653
test: epoch 5, loss 2.530841827392578, acc=0.21944443881511688, loss=2.530841827392578
train: epoch 6, loss 1.213437795639038, acc=0.44477778673171997, loss=1.213437795639038
test: epoch 6, loss 3.7010416984558105, acc=0.2083333283662796, loss=3.7010416984558105
train: epoch 7, loss 1.1035261154174805, acc=0.5259444713592529, loss=1.1035261154174805
test: epoch 7, loss 3.408970832824707, acc=0.23055554926395416, loss=3.408970832824707
train: epoch 8, loss 0.9072560667991638, acc=0.6156666874885559, loss=0.9072560667991638
test: epoch 8, loss 4.127503871917725, acc=0.2527777850627899, loss=4.127503871917725
train: epoch 9, loss 0.8250577449798584, acc=0.6537777781486511, loss=0.8250577449798584
test: epoch 9, loss 3.744798421859741, acc=0.2527777850627899, loss=3.744798421859741
train: epoch 10, loss 0.7124465703964233, acc=0.6982222199440002, loss=0.7124465703964233
test: epoch 10, loss 3.2176594734191895, acc=0.2888889014720917, loss=3.2176594734191895
train: epoch 11, loss 0.6264272332191467, acc=0.7356666922569275, loss=0.6264272332191467
test: epoch 11, loss 3.157740592956543, acc=0.28611111640930176, loss=3.157740592956543
train: epoch 12, loss 0.5639874339103699, acc=0.7636666893959045, loss=0.5639874339103699
test: epoch 12, loss 2.2510299682617188, acc=0.36944442987442017, loss=2.2510299682617188
train: epoch 13, loss 0.4594079852104187, acc=0.7946110963821411, loss=0.4594079852104187
test: epoch 13, loss 3.3683254718780518, acc=0.2750000059604645, loss=3.3683254718780518
train: epoch 14, loss 0.39381861686706543, acc=0.8218333125114441, loss=0.39381861686706543
test: epoch 14, loss 2.4799063205718994, acc=0.4138889014720917, loss=2.4799063205718994
train: epoch 15, loss 0.3404691815376282, acc=0.8480555415153503, loss=0.3404691815376282
test: epoch 15, loss 2.1780617237091064, acc=0.4333333373069763, loss=2.1780617237091064
train: epoch 16, loss 0.3113844096660614, acc=0.8628888726234436, loss=0.3113844096660614
test: epoch 16, loss 2.1125335693359375, acc=0.4555555582046509, loss=2.1125335693359375
train: epoch 17, loss 0.30481719970703125, acc=0.8695555329322815, loss=0.30481719970703125
test: epoch 17, loss 2.2751505374908447, acc=0.39444443583488464, loss=2.2751505374908447
train: epoch 18, loss 0.25087398290634155, acc=0.890666663646698, loss=0.25087398290634155
test: epoch 18, loss 2.5529940128326416, acc=0.36666667461395264, loss=2.5529940128326416
train: epoch 19, loss 0.25832825899124146, acc=0.8897777795791626, loss=0.25832825899124146
test: epoch 19, loss 2.1434950828552246, acc=0.4055555462837219, loss=2.1434950828552246
train: epoch 20, loss 0.19141793251037598, acc=0.9294999837875366, loss=0.19141793251037598
test: epoch 20, loss 2.226637601852417, acc=0.48055556416511536, loss=2.226637601852417
train: epoch 21, loss 0.17038865387439728, acc=0.9401111006736755, loss=0.17038865387439728
test: epoch 21, loss 2.045762538909912, acc=0.4749999940395355, loss=2.045762538909912
train: epoch 22, loss 0.1480104923248291, acc=0.9513888955116272, loss=0.1480104923248291
test: epoch 22, loss 2.0589096546173096, acc=0.5583333373069763, loss=2.0589096546173096
train: epoch 23, loss 0.15325820446014404, acc=0.9472222328186035, loss=0.15325820446014404
test: epoch 23, loss 1.7824124097824097, acc=0.5888888835906982, loss=1.7824124097824097
train: epoch 24, loss 0.1621994972229004, acc=0.94605553150177, loss=0.1621994972229004
test: epoch 24, loss 1.8852037191390991, acc=0.550000011920929, loss=1.8852037191390991
train: epoch 25, loss 0.10334238409996033, acc=0.9663888812065125, loss=0.10334238409996033
test: epoch 25, loss 2.250946283340454, acc=0.5277777910232544, loss=2.250946283340454
train: epoch 26, loss 0.14324182271957397, acc=0.9528889060020447, loss=0.14324182271957397
test: epoch 26, loss 2.2454473972320557, acc=0.48055556416511536, loss=2.2454473972320557
train: epoch 27, loss 0.11045581102371216, acc=0.9629999995231628, loss=0.11045581102371216
test: epoch 27, loss 1.3672349452972412, acc=0.6333333253860474, loss=1.3672349452972412
train: epoch 28, loss 0.12766516208648682, acc=0.9594444632530212, loss=0.12766516208648682
test: epoch 28, loss 1.8124604225158691, acc=0.5444444417953491, loss=1.8124604225158691
train: epoch 29, loss 0.11616424471139908, acc=0.9618333578109741, loss=0.11616424471139908
test: epoch 29, loss 1.7793984413146973, acc=0.6000000238418579, loss=1.7793984413146973
train: epoch 30, loss 0.13095590472221375, acc=0.9568333625793457, loss=0.13095590472221375
test: epoch 30, loss 1.6683390140533447, acc=0.5027777552604675, loss=1.6683390140533447
train: epoch 31, loss 0.11433641612529755, acc=0.9624999761581421, loss=0.11433641612529755
test: epoch 31, loss 1.8568447828292847, acc=0.519444465637207, loss=1.8568447828292847
train: epoch 32, loss 0.10099021345376968, acc=0.9664999842643738, loss=0.10099021345376968
test: epoch 32, loss 2.2138822078704834, acc=0.5583333373069763, loss=2.2138822078704834
train: epoch 33, loss 0.12259316444396973, acc=0.9598888754844666, loss=0.12259316444396973
test: epoch 33, loss 1.7722513675689697, acc=0.5777778029441833, loss=1.7722513675689697
train: epoch 34, loss 0.08579924702644348, acc=0.9713333249092102, loss=0.08579924702644348
test: epoch 34, loss 1.5183019638061523, acc=0.6166666746139526, loss=1.5183019638061523
train: epoch 35, loss 0.10251985490322113, acc=0.9664999842643738, loss=0.10251985490322113
test: epoch 35, loss 1.8836441040039062, acc=0.6027777791023254, loss=1.8836441040039062
train: epoch 36, loss 0.11878182739019394, acc=0.9622222185134888, loss=0.11878182739019394
test: epoch 36, loss 1.7474886178970337, acc=0.5861111283302307, loss=1.7474886178970337
train: epoch 37, loss 0.09356590360403061, acc=0.9682777523994446, loss=0.09356590360403061
test: epoch 37, loss 1.6425679922103882, acc=0.6388888955116272, loss=1.6425679922103882
train: epoch 38, loss 0.08021124452352524, acc=0.9728888869285583, loss=0.08021124452352524
test: epoch 38, loss 1.5197696685791016, acc=0.5861111283302307, loss=1.5197696685791016
train: epoch 39, loss 0.09740511327981949, acc=0.968833327293396, loss=0.09740511327981949
test: epoch 39, loss 1.6199802160263062, acc=0.625, loss=1.6199802160263062
train: epoch 40, loss 0.10220785439014435, acc=0.9665555357933044, loss=0.10220785439014435
test: epoch 40, loss 1.28288733959198, acc=0.6638888716697693, loss=1.28288733959198
train: epoch 41, loss 0.07558083534240723, acc=0.9748888611793518, loss=0.07558083534240723
test: epoch 41, loss 1.4391313791275024, acc=0.5888888835906982, loss=1.4391313791275024
train: epoch 42, loss 0.07669700682163239, acc=0.9733333587646484, loss=0.07669700682163239
test: epoch 42, loss 2.1472370624542236, acc=0.5277777910232544, loss=2.1472370624542236
train: epoch 43, loss 0.10578043758869171, acc=0.9655555486679077, loss=0.10578043758869171
test: epoch 43, loss 1.59074068069458, acc=0.6000000238418579, loss=1.59074068069458
train: epoch 44, loss 0.07636617869138718, acc=0.9738888740539551, loss=0.07636617869138718
test: epoch 44, loss 1.697817325592041, acc=0.5972222089767456, loss=1.697817325592041
train: epoch 45, loss 0.06865514069795609, acc=0.975777804851532, loss=0.06865514069795609
test: epoch 45, loss 1.2772492170333862, acc=0.675000011920929, loss=1.2772492170333862
train: epoch 46, loss 0.08920657634735107, acc=0.971666693687439, loss=0.08920657634735107
test: epoch 46, loss 1.388332724571228, acc=0.6916666626930237, loss=1.388332724571228
train: epoch 47, loss 0.06575404852628708, acc=0.9763888716697693, loss=0.06575404852628708
test: epoch 47, loss 1.4197187423706055, acc=0.7361111044883728, loss=1.4197187423706055
train: epoch 48, loss 0.08348144590854645, acc=0.972000002861023, loss=0.08348144590854645
test: epoch 48, loss 1.3131805658340454, acc=0.699999988079071, loss=1.3131805658340454
train: epoch 49, loss 0.08664622902870178, acc=0.9708333611488342, loss=0.08664622902870178
test: epoch 49, loss 1.2404388189315796, acc=0.6416666507720947, loss=1.2404388189315796
train: epoch 50, loss 0.06895792484283447, acc=0.9756110906600952, loss=0.06895792484283447
test: epoch 50, loss 1.4421780109405518, acc=0.730555534362793, loss=1.4421780109405518
train: epoch 51, loss 0.07460550963878632, acc=0.9742777943611145, loss=0.07460550963878632
test: epoch 51, loss 1.179290533065796, acc=0.6888889074325562, loss=1.179290533065796
train: epoch 52, loss 0.04804474487900734, acc=0.9825000166893005, loss=0.04804474487900734
test: epoch 52, loss 1.447203278541565, acc=0.730555534362793, loss=1.447203278541565
train: epoch 53, loss 0.08718297630548477, acc=0.9715555310249329, loss=0.08718297630548477
test: epoch 53, loss 1.4879179000854492, acc=0.6916666626930237, loss=1.4879179000854492
train: epoch 54, loss 0.050910189747810364, acc=0.9819444417953491, loss=0.050910189747810364
test: epoch 54, loss 1.2860251665115356, acc=0.7444444298744202, loss=1.2860251665115356
train: epoch 55, loss 0.06860008835792542, acc=0.9765555262565613, loss=0.06860008835792542
test: epoch 55, loss 1.0134599208831787, acc=0.7444444298744202, loss=1.0134599208831787
train: epoch 56, loss 0.06153472885489464, acc=0.9806110858917236, loss=0.06153472885489464
test: epoch 56, loss 1.1610370874404907, acc=0.7916666865348816, loss=1.1610370874404907
train: epoch 57, loss 0.06382345408201218, acc=0.9801666736602783, loss=0.06382345408201218
test: epoch 57, loss 1.1899042129516602, acc=0.800000011920929, loss=1.1899042129516602
train: epoch 58, loss 0.05952094495296478, acc=0.9797222018241882, loss=0.05952094495296478
test: epoch 58, loss 1.5296056270599365, acc=0.7027778029441833, loss=1.5296056270599365
train: epoch 59, loss 0.07933145016431808, acc=0.9756110906600952, loss=0.07933145016431808
test: epoch 59, loss 1.0099047422409058, acc=0.7611111402511597, loss=1.0099047422409058
train: epoch 60, loss 0.04251683130860329, acc=0.9850555658340454, loss=0.04251683130860329
test: epoch 60, loss 1.1117866039276123, acc=0.7666666507720947, loss=1.1117866039276123
train: epoch 61, loss 0.05753108486533165, acc=0.9804999828338623, loss=0.05753108486533165
test: epoch 61, loss 0.9816735982894897, acc=0.7805555462837219, loss=0.9816735982894897
train: epoch 62, loss 0.02848135679960251, acc=0.9886666536331177, loss=0.02848135679960251
test: epoch 62, loss 1.2503987550735474, acc=0.7833333611488342, loss=1.2503987550735474
train: epoch 63, loss 0.06357470154762268, acc=0.9794444441795349, loss=0.06357470154762268
test: epoch 63, loss 1.0237996578216553, acc=0.8222222328186035, loss=1.0237996578216553
train: epoch 64, loss 0.04211483895778656, acc=0.9858888983726501, loss=0.04211483895778656
test: epoch 64, loss 1.0758392810821533, acc=0.8111110925674438, loss=1.0758392810821533
train: epoch 65, loss 0.06647368520498276, acc=0.9789444208145142, loss=0.06647368520498276
test: epoch 65, loss 1.0781794786453247, acc=0.7972221970558167, loss=1.0781794786453247
train: epoch 66, loss 0.044123388826847076, acc=0.984333336353302, loss=0.044123388826847076
test: epoch 66, loss 1.1332550048828125, acc=0.7972221970558167, loss=1.1332550048828125
train: epoch 67, loss 0.036137714982032776, acc=0.9860000014305115, loss=0.036137714982032776
test: epoch 67, loss 1.1444642543792725, acc=0.8166666626930237, loss=1.1444642543792725
train: epoch 68, loss 0.0594603531062603, acc=0.9812777638435364, loss=0.0594603531062603
test: epoch 68, loss 0.9681094884872437, acc=0.7722222208976746, loss=0.9681094884872437
train: epoch 69, loss 0.058084119111299515, acc=0.9812222123146057, loss=0.058084119111299515
test: epoch 69, loss 0.9228983521461487, acc=0.8111110925674438, loss=0.9228983521461487
train: epoch 70, loss 0.04584585875272751, acc=0.9846110939979553, loss=0.04584585875272751
test: epoch 70, loss 0.8308500647544861, acc=0.7916666865348816, loss=0.8308500647544861
train: epoch 71, loss 0.054381344467401505, acc=0.9829444289207458, loss=0.054381344467401505
test: epoch 71, loss 1.0463389158248901, acc=0.8111110925674438, loss=1.0463389158248901
train: epoch 72, loss 0.04333875700831413, acc=0.9858333468437195, loss=0.04333875700831413
test: epoch 72, loss 1.3298113346099854, acc=0.769444465637207, loss=1.3298113346099854
train: epoch 73, loss 0.034532833844423294, acc=0.9872221946716309, loss=0.034532833844423294
test: epoch 73, loss 1.1094419956207275, acc=0.855555534362793, loss=1.1094419956207275
train: epoch 74, loss 0.05922135338187218, acc=0.9826111197471619, loss=0.05922135338187218
test: epoch 74, loss 0.7658030986785889, acc=0.8583333492279053, loss=0.7658030986785889
train: epoch 75, loss 0.05147197097539902, acc=0.9826666712760925, loss=0.05147197097539902
test: epoch 75, loss 0.8792309165000916, acc=0.8416666388511658, loss=0.8792309165000916
train: epoch 76, loss 0.045096125453710556, acc=0.9850000143051147, loss=0.045096125453710556
test: epoch 76, loss 0.7165253758430481, acc=0.8333333134651184, loss=0.7165253758430481
train: epoch 77, loss 0.04777535796165466, acc=0.9842222332954407, loss=0.04777535796165466
test: epoch 77, loss 0.6222074627876282, acc=0.8583333492279053, loss=0.6222074627876282
train: epoch 78, loss 0.04495595023036003, acc=0.9873889088630676, loss=0.04495595023036003
test: epoch 78, loss 0.9290029406547546, acc=0.8500000238418579, loss=0.9290029406547546
train: epoch 79, loss 0.045487869530916214, acc=0.984499990940094, loss=0.045487869530916214
test: epoch 79, loss 0.770689845085144, acc=0.8611111044883728, loss=0.770689845085144
train: epoch 80, loss 0.03978857025504112, acc=0.9878888726234436, loss=0.03978857025504112
test: epoch 80, loss 0.6024540662765503, acc=0.8805555701255798, loss=0.6024540662765503
train: epoch 81, loss 0.040412548929452896, acc=0.9871110916137695, loss=0.040412548929452896
test: epoch 81, loss 0.6414141654968262, acc=0.8999999761581421, loss=0.6414141654968262
train: epoch 82, loss 0.03755100816488266, acc=0.9877222180366516, loss=0.03755100816488266
test: epoch 82, loss 0.881597101688385, acc=0.8666666746139526, loss=0.881597101688385
train: epoch 83, loss 0.04375527426600456, acc=0.9852222204208374, loss=0.04375527426600456
test: epoch 83, loss 0.8581187129020691, acc=0.8722222447395325, loss=0.8581187129020691
train: epoch 84, loss 0.026820214465260506, acc=0.9887222051620483, loss=0.026820214465260506
test: epoch 84, loss 0.6457327008247375, acc=0.8916666507720947, loss=0.6457327008247375
train: epoch 85, loss 0.013697538524866104, acc=0.9927777647972107, loss=0.013697538524866104
test: epoch 85, loss 0.860100507736206, acc=0.8666666746139526, loss=0.860100507736206
train: epoch 86, loss 0.03285523131489754, acc=0.9872778058052063, loss=0.03285523131489754
test: epoch 86, loss 0.5728321075439453, acc=0.8833333253860474, loss=0.5728321075439453
train: epoch 87, loss 0.030528677627444267, acc=0.9877777695655823, loss=0.030528677627444267
test: epoch 87, loss 0.5087798237800598, acc=0.8833333253860474, loss=0.5087798237800598
train: epoch 88, loss 0.04964772239327431, acc=0.9835555553436279, loss=0.04964772239327431
test: epoch 88, loss 0.646842896938324, acc=0.894444465637207, loss=0.646842896938324
train: epoch 89, loss 0.018352089449763298, acc=0.992222249507904, loss=0.018352089449763298
test: epoch 89, loss 0.5427260994911194, acc=0.9083333611488342, loss=0.5427260994911194
train: epoch 90, loss 0.024241555482149124, acc=0.9899444580078125, loss=0.024241555482149124
test: epoch 90, loss 0.6568716168403625, acc=0.9055555462837219, loss=0.6568716168403625
train: epoch 91, loss 0.040145229548215866, acc=0.9867777824401855, loss=0.040145229548215866
test: epoch 91, loss 0.6291273236274719, acc=0.9083333611488342, loss=0.6291273236274719
train: epoch 92, loss 0.03068527579307556, acc=0.9897222518920898, loss=0.03068527579307556
test: epoch 92, loss 0.2797127962112427, acc=0.925000011920929, loss=0.2797127962112427
train: epoch 93, loss 0.02587803825736046, acc=0.9902222156524658, loss=0.02587803825736046
test: epoch 93, loss 0.2882133424282074, acc=0.9222221970558167, loss=0.2882133424282074
train: epoch 94, loss 0.033646032214164734, acc=0.9891111254692078, loss=0.033646032214164734
test: epoch 94, loss 0.5401549339294434, acc=0.9194444417953491, loss=0.5401549339294434
train: epoch 95, loss 0.034017592668533325, acc=0.9879444241523743, loss=0.034017592668533325
test: epoch 95, loss 0.4937393367290497, acc=0.9138888716697693, loss=0.4937393367290497
train: epoch 96, loss 0.014522961340844631, acc=0.9938333630561829, loss=0.014522961340844631
test: epoch 96, loss 0.5429317951202393, acc=0.9222221970558167, loss=0.5429317951202393
train: epoch 97, loss 0.0314084030687809, acc=0.9903333187103271, loss=0.0314084030687809
test: epoch 97, loss 0.5481448173522949, acc=0.9277777671813965, loss=0.5481448173522949
train: epoch 98, loss 0.02797558531165123, acc=0.9907222390174866, loss=0.02797558531165123
test: epoch 98, loss 0.4556046426296234, acc=0.9277777671813965, loss=0.4556046426296234
train: epoch 99, loss 0.03639210760593414, acc=0.9889444708824158, loss=0.03639210760593414
test: epoch 99, loss 0.52814120054245, acc=0.9055555462837219, loss=0.52814120054245
train: epoch 100, loss 0.01483690645545721, acc=0.9919999837875366, loss=0.01483690645545721
test: epoch 100, loss 0.5090980529785156, acc=0.9277777671813965, loss=0.5090980529785156
train: epoch 101, loss 0.016211310401558876, acc=0.9923333525657654, loss=0.016211310401558876
test: epoch 101, loss 0.5520859360694885, acc=0.9305555820465088, loss=0.5520859360694885
train: epoch 102, loss 0.058335136622190475, acc=0.9837777614593506, loss=0.058335136622190475
test: epoch 102, loss 0.39929357171058655, acc=0.9194444417953491, loss=0.39929357171058655
train: epoch 103, loss 0.04917241632938385, acc=0.984499990940094, loss=0.04917241632938385
test: epoch 103, loss 0.47685888409614563, acc=0.9222221970558167, loss=0.47685888409614563
train: epoch 104, loss 0.027170799672603607, acc=0.9906111359596252, loss=0.027170799672603607
test: epoch 104, loss 0.3382989764213562, acc=0.9277777671813965, loss=0.3382989764213562
train: epoch 105, loss 0.02067520096898079, acc=0.99144446849823, loss=0.02067520096898079
test: epoch 105, loss 0.4820392429828644, acc=0.9277777671813965, loss=0.4820392429828644
train: epoch 106, loss 0.018862225115299225, acc=0.9929444193840027, loss=0.018862225115299225
test: epoch 106, loss 0.5227477550506592, acc=0.9083333611488342, loss=0.5227477550506592
train: epoch 107, loss 0.021091511473059654, acc=0.9921666383743286, loss=0.021091511473059654
test: epoch 107, loss 0.5393298864364624, acc=0.9305555820465088, loss=0.5393298864364624
train: epoch 108, loss 0.017584117129445076, acc=0.9928333163261414, loss=0.017584117129445076
test: epoch 108, loss 0.6328153610229492, acc=0.9305555820465088, loss=0.6328153610229492
train: epoch 109, loss 0.03767036646604538, acc=0.9889444708824158, loss=0.03767036646604538
test: epoch 109, loss 0.4744294285774231, acc=0.9305555820465088, loss=0.4744294285774231
train: epoch 110, loss 0.0559861995279789, acc=0.9855555295944214, loss=0.0559861995279789
test: epoch 110, loss 0.43275538086891174, acc=0.9166666865348816, loss=0.43275538086891174
train: epoch 111, loss 0.014787578955292702, acc=0.9929999709129333, loss=0.014787578955292702
test: epoch 111, loss 0.4483386278152466, acc=0.9305555820465088, loss=0.4483386278152466
train: epoch 112, loss 0.01202781405299902, acc=0.9928333163261414, loss=0.01202781405299902
test: epoch 112, loss 0.31549468636512756, acc=0.9305555820465088, loss=0.31549468636512756
train: epoch 113, loss 0.01511985994875431, acc=0.9926111102104187, loss=0.01511985994875431
test: epoch 113, loss 0.4442431330680847, acc=0.9277777671813965, loss=0.4442431330680847
train: epoch 114, loss 0.044057149440050125, acc=0.987500011920929, loss=0.044057149440050125
test: epoch 114, loss 0.2906404733657837, acc=0.9305555820465088, loss=0.2906404733657837
train: epoch 115, loss 0.0351807102560997, acc=0.9877777695655823, loss=0.0351807102560997
test: epoch 115, loss 0.4740639626979828, acc=0.9361110925674438, loss=0.4740639626979828
train: epoch 116, loss 0.008663800545036793, acc=0.9942777752876282, loss=0.008663800545036793
test: epoch 116, loss 0.5339727997779846, acc=0.9305555820465088, loss=0.5339727997779846
train: epoch 117, loss 0.0411016121506691, acc=0.9865000247955322, loss=0.0411016121506691
test: epoch 117, loss 0.3874349892139435, acc=0.9388889074325562, loss=0.3874349892139435
train: epoch 118, loss 0.029269989579916, acc=0.9892777800559998, loss=0.029269989579916
test: epoch 118, loss 0.231897234916687, acc=0.9305555820465088, loss=0.231897234916687
train: epoch 119, loss 0.020176665857434273, acc=0.9906111359596252, loss=0.020176665857434273
test: epoch 119, loss 0.21925732493400574, acc=0.9333333373069763, loss=0.21925732493400574
train: epoch 120, loss 0.0389520600438118, acc=0.9879999756813049, loss=0.0389520600438118
test: epoch 120, loss 0.5870688557624817, acc=0.9194444417953491, loss=0.5870688557624817
train: epoch 121, loss 0.051697179675102234, acc=0.9850555658340454, loss=0.051697179675102234
test: epoch 121, loss 0.23352810740470886, acc=0.9277777671813965, loss=0.23352810740470886
train: epoch 122, loss 0.03697316721081734, acc=0.9864444732666016, loss=0.03697316721081734
test: epoch 122, loss 0.22899776697158813, acc=0.9388889074325562, loss=0.22899776697158813
train: epoch 123, loss 0.02536083571612835, acc=0.9907777905464172, loss=0.02536083571612835
test: epoch 123, loss 0.4413532316684723, acc=0.9277777671813965, loss=0.4413532316684723
train: epoch 124, loss 0.017634926363825798, acc=0.991611123085022, loss=0.017634926363825798
test: epoch 124, loss 0.17455635964870453, acc=0.9361110925674438, loss=0.17455635964870453
train: epoch 125, loss 0.030747005715966225, acc=0.9902777671813965, loss=0.030747005715966225
test: epoch 125, loss 0.2627231776714325, acc=0.9388889074325562, loss=0.2627231776714325
train: epoch 126, loss 0.012293477542698383, acc=0.9934444427490234, loss=0.012293477542698383
test: epoch 126, loss 0.4488329589366913, acc=0.9305555820465088, loss=0.4488329589366913
train: epoch 127, loss 0.008877837099134922, acc=0.9936666488647461, loss=0.008877837099134922
test: epoch 127, loss 0.4372110664844513, acc=0.9361110925674438, loss=0.4372110664844513
train: epoch 128, loss 0.006397418677806854, acc=0.9940000176429749, loss=0.006397418677806854
test: epoch 128, loss 0.5220464468002319, acc=0.9388889074325562, loss=0.5220464468002319
train: epoch 129, loss 0.07115524262189865, acc=0.9794999957084656, loss=0.07115524262189865
test: epoch 129, loss 0.44064828753471375, acc=0.9305555820465088, loss=0.44064828753471375
train: epoch 130, loss 0.03308795019984245, acc=0.9897222518920898, loss=0.03308795019984245
test: epoch 130, loss 0.4169509708881378, acc=0.9333333373069763, loss=0.4169509708881378
train: epoch 131, loss 0.017505459487438202, acc=0.9922778010368347, loss=0.017505459487438202
test: epoch 131, loss 0.4497321844100952, acc=0.9388889074325562, loss=0.4497321844100952
train: epoch 132, loss 0.01301322877407074, acc=0.992888867855072, loss=0.01301322877407074
test: epoch 132, loss 0.3268062174320221, acc=0.9388889074325562, loss=0.3268062174320221
train: epoch 133, loss 0.053401846438646317, acc=0.9868333339691162, loss=0.053401846438646317
test: epoch 133, loss 0.31561315059661865, acc=0.9388889074325562, loss=0.31561315059661865
train: epoch 134, loss 0.014308777637779713, acc=0.9937777519226074, loss=0.014308777637779713
test: epoch 134, loss 0.4670999348163605, acc=0.925000011920929, loss=0.4670999348163605
train: epoch 135, loss 0.016920842230319977, acc=0.9919999837875366, loss=0.016920842230319977
test: epoch 135, loss 0.4731920063495636, acc=0.9388889074325562, loss=0.4731920063495636
train: epoch 136, loss 0.023546278476715088, acc=0.9915555715560913, loss=0.023546278476715088
test: epoch 136, loss 0.3571435809135437, acc=0.9388889074325562, loss=0.3571435809135437
train: epoch 137, loss 0.022222081199288368, acc=0.9899444580078125, loss=0.022222081199288368
test: epoch 137, loss 0.5437708497047424, acc=0.925000011920929, loss=0.5437708497047424
train: epoch 138, loss 0.020801464095711708, acc=0.9909999966621399, loss=0.020801464095711708
test: epoch 138, loss 0.42584264278411865, acc=0.9388889074325562, loss=0.42584264278411865
train: epoch 139, loss 0.013840687461197376, acc=0.9920555353164673, loss=0.013840687461197376
test: epoch 139, loss 0.3447200059890747, acc=0.9388889074325562, loss=0.3447200059890747
train: epoch 140, loss 0.05067753791809082, acc=0.9891111254692078, loss=0.05067753791809082
test: epoch 140, loss 0.40056002140045166, acc=0.9361110925674438, loss=0.40056002140045166
train: epoch 141, loss 0.016777323558926582, acc=0.9920555353164673, loss=0.016777323558926582
test: epoch 141, loss 0.16315141320228577, acc=0.9388889074325562, loss=0.16315141320228577
train: epoch 142, loss 0.012090260162949562, acc=0.9933888912200928, loss=0.012090260162949562
test: epoch 142, loss 0.6065277457237244, acc=0.9333333373069763, loss=0.6065277457237244
train: epoch 143, loss 0.02038583904504776, acc=0.9918888807296753, loss=0.02038583904504776
test: epoch 143, loss 0.46450212597846985, acc=0.9333333373069763, loss=0.46450212597846985
train: epoch 144, loss 0.016308091580867767, acc=0.9915555715560913, loss=0.016308091580867767
test: epoch 144, loss 0.4674658477306366, acc=0.9361110925674438, loss=0.4674658477306366
train: epoch 145, loss 0.0380532443523407, acc=0.9884999990463257, loss=0.0380532443523407
test: epoch 145, loss 0.5069714784622192, acc=0.9361110925674438, loss=0.5069714784622192
train: epoch 146, loss 0.018870562314987183, acc=0.9907222390174866, loss=0.018870562314987183
test: epoch 146, loss 0.7418146729469299, acc=0.9361110925674438, loss=0.7418146729469299
train: epoch 147, loss 0.022511199116706848, acc=0.9908333420753479, loss=0.022511199116706848
test: epoch 147, loss 0.41709625720977783, acc=0.9388889074325562, loss=0.41709625720977783
train: epoch 148, loss 0.007354456931352615, acc=0.9937777519226074, loss=0.007354456931352615
test: epoch 148, loss 0.49277180433273315, acc=0.9388889074325562, loss=0.49277180433273315
train: epoch 149, loss 0.023174839094281197, acc=0.9920555353164673, loss=0.023174839094281197
test: epoch 149, loss 0.44257381558418274, acc=0.9277777671813965, loss=0.44257381558418274
train: epoch 150, loss 0.0262400284409523, acc=0.9903888702392578, loss=0.0262400284409523
test: epoch 150, loss 0.5014923810958862, acc=0.9388889074325562, loss=0.5014923810958862
