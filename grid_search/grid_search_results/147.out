# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=2.0", "--temp_decay=1", "--one_hot=false", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=485178195, receiver_embed_dim=128, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.9942901134490967, acc=0.11072222143411636, loss=2.9942901134490967
test: epoch 1, loss 3.7386224269866943, acc=0.125, loss=3.7386224269866943
train: epoch 2, loss 1.4961159229278564, acc=0.402444452047348, loss=1.4961159229278564
test: epoch 2, loss 3.42002534866333, acc=0.1805555522441864, loss=3.42002534866333
train: epoch 3, loss 1.0702056884765625, acc=0.5652777552604675, loss=1.0702056884765625
test: epoch 3, loss 3.8211617469787598, acc=0.1527777761220932, loss=3.8211617469787598
train: epoch 4, loss 0.8955202698707581, acc=0.6483333110809326, loss=0.8955202698707581
test: epoch 4, loss 3.838545799255371, acc=0.16388888657093048, loss=3.838545799255371
train: epoch 5, loss 0.7569877505302429, acc=0.7077222466468811, loss=0.7569877505302429
test: epoch 5, loss 3.616100549697876, acc=0.20277777314186096, loss=3.616100549697876
train: epoch 6, loss 0.6539267897605896, acc=0.7508333325386047, loss=0.6539267897605896
test: epoch 6, loss 3.896674394607544, acc=0.19166666269302368, loss=3.896674394607544
train: epoch 7, loss 0.5916069746017456, acc=0.7723333239555359, loss=0.5916069746017456
test: epoch 7, loss 3.4073426723480225, acc=0.23055554926395416, loss=3.4073426723480225
train: epoch 8, loss 0.5397329926490784, acc=0.7995555400848389, loss=0.5397329926490784
test: epoch 8, loss 3.1172127723693848, acc=0.24444444477558136, loss=3.1172127723693848
train: epoch 9, loss 0.49847859144210815, acc=0.815500020980835, loss=0.49847859144210815
test: epoch 9, loss 3.013615608215332, acc=0.22499999403953552, loss=3.013615608215332
train: epoch 10, loss 0.4487096667289734, acc=0.8366110920906067, loss=0.4487096667289734
test: epoch 10, loss 3.3177287578582764, acc=0.2083333283662796, loss=3.3177287578582764
train: epoch 11, loss 0.4285989999771118, acc=0.8462222218513489, loss=0.4285989999771118
test: epoch 11, loss 3.2464070320129395, acc=0.22499999403953552, loss=3.2464070320129395
train: epoch 12, loss 0.3931218683719635, acc=0.8568333387374878, loss=0.3931218683719635
test: epoch 12, loss 3.2389626502990723, acc=0.2222222238779068, loss=3.2389626502990723
train: epoch 13, loss 0.3680476248264313, acc=0.8688333630561829, loss=0.3680476248264313
test: epoch 13, loss 2.789834976196289, acc=0.22777777910232544, loss=2.789834976196289
train: epoch 14, loss 0.3509827256202698, acc=0.8776111006736755, loss=0.3509827256202698
test: epoch 14, loss 2.7968437671661377, acc=0.30000001192092896, loss=2.7968437671661377
train: epoch 15, loss 0.3113476634025574, acc=0.8895000219345093, loss=0.3113476634025574
test: epoch 15, loss 2.5878489017486572, acc=0.2666666805744171, loss=2.5878489017486572
train: epoch 16, loss 0.30905404686927795, acc=0.8901110887527466, loss=0.30905404686927795
test: epoch 16, loss 2.9158055782318115, acc=0.3083333373069763, loss=2.9158055782318115
train: epoch 17, loss 0.2734108865261078, acc=0.9053333401679993, loss=0.2734108865261078
test: epoch 17, loss 2.7758889198303223, acc=0.25833332538604736, loss=2.7758889198303223
train: epoch 18, loss 0.2806098163127899, acc=0.9057222008705139, loss=0.2806098163127899
test: epoch 18, loss 2.6146061420440674, acc=0.31111112236976624, loss=2.6146061420440674
train: epoch 19, loss 0.25322309136390686, acc=0.9120000004768372, loss=0.25322309136390686
test: epoch 19, loss 2.727635383605957, acc=0.3055555522441864, loss=2.727635383605957
train: epoch 20, loss 0.241072416305542, acc=0.9193888902664185, loss=0.241072416305542
test: epoch 20, loss 3.2102773189544678, acc=0.23333333432674408, loss=3.2102773189544678
train: epoch 21, loss 0.22361698746681213, acc=0.9222221970558167, loss=0.22361698746681213
test: epoch 21, loss 3.3964030742645264, acc=0.25, loss=3.3964030742645264
train: epoch 22, loss 0.2168527990579605, acc=0.9276666641235352, loss=0.2168527990579605
test: epoch 22, loss 3.6020753383636475, acc=0.27222222089767456, loss=3.6020753383636475
train: epoch 23, loss 0.2018054574728012, acc=0.9312222003936768, loss=0.2018054574728012
test: epoch 23, loss 3.1684679985046387, acc=0.32499998807907104, loss=3.1684679985046387
train: epoch 24, loss 0.19486336410045624, acc=0.9358333349227905, loss=0.19486336410045624
test: epoch 24, loss 2.777597188949585, acc=0.32499998807907104, loss=2.777597188949585
train: epoch 25, loss 0.19677788019180298, acc=0.9347777962684631, loss=0.19677788019180298
test: epoch 25, loss 3.043910026550293, acc=0.3055555522441864, loss=3.043910026550293
train: epoch 26, loss 0.18115095794200897, acc=0.9424999952316284, loss=0.18115095794200897
test: epoch 26, loss 2.92437744140625, acc=0.3361110985279083, loss=2.92437744140625
train: epoch 27, loss 0.17836400866508484, acc=0.945388913154602, loss=0.17836400866508484
test: epoch 27, loss 2.7627933025360107, acc=0.3166666626930237, loss=2.7627933025360107
train: epoch 28, loss 0.1644655168056488, acc=0.9478333592414856, loss=0.1644655168056488
test: epoch 28, loss 2.9640839099884033, acc=0.3305555582046509, loss=2.9640839099884033
train: epoch 29, loss 0.14912620186805725, acc=0.9523888826370239, loss=0.14912620186805725
test: epoch 29, loss 2.52363657951355, acc=0.33888888359069824, loss=2.52363657951355
train: epoch 30, loss 0.15723097324371338, acc=0.9518333077430725, loss=0.15723097324371338
test: epoch 30, loss 3.013655662536621, acc=0.34166666865348816, loss=3.013655662536621
train: epoch 31, loss 0.1384604275226593, acc=0.9578333497047424, loss=0.1384604275226593
test: epoch 31, loss 2.7308125495910645, acc=0.4000000059604645, loss=2.7308125495910645
train: epoch 32, loss 0.13221797347068787, acc=0.9605555534362793, loss=0.13221797347068787
test: epoch 32, loss 2.8300859928131104, acc=0.36666667461395264, loss=2.8300859928131104
train: epoch 33, loss 0.13031159341335297, acc=0.9612777829170227, loss=0.13031159341335297
test: epoch 33, loss 3.14520001411438, acc=0.375, loss=3.14520001411438
train: epoch 34, loss 0.12377740442752838, acc=0.9621111154556274, loss=0.12377740442752838
test: epoch 34, loss 2.9674453735351562, acc=0.2777777910232544, loss=2.9674453735351562
train: epoch 35, loss 0.1172637939453125, acc=0.9647777676582336, loss=0.1172637939453125
test: epoch 35, loss 3.278468608856201, acc=0.32499998807907104, loss=3.278468608856201
train: epoch 36, loss 0.10746932774782181, acc=0.9655555486679077, loss=0.10746932774782181
test: epoch 36, loss 3.202944278717041, acc=0.31388887763023376, loss=3.202944278717041
train: epoch 37, loss 0.10993976145982742, acc=0.9650555849075317, loss=0.10993976145982742
test: epoch 37, loss 3.1171727180480957, acc=0.29722222685813904, loss=3.1171727180480957
train: epoch 38, loss 0.10156390815973282, acc=0.9693333506584167, loss=0.10156390815973282
test: epoch 38, loss 2.832186698913574, acc=0.3861111104488373, loss=2.832186698913574
train: epoch 39, loss 0.08684343099594116, acc=0.9737222194671631, loss=0.08684343099594116
test: epoch 39, loss 3.15883731842041, acc=0.3638888895511627, loss=3.15883731842041
train: epoch 40, loss 0.09901756048202515, acc=0.9698333144187927, loss=0.09901756048202515
test: epoch 40, loss 3.374713182449341, acc=0.33888888359069824, loss=3.374713182449341
train: epoch 41, loss 0.09811993688344955, acc=0.9721666574478149, loss=0.09811993688344955
test: epoch 41, loss 3.742243528366089, acc=0.3722222149372101, loss=3.742243528366089
train: epoch 42, loss 0.08202949166297913, acc=0.9753333330154419, loss=0.08202949166297913
test: epoch 42, loss 3.382443904876709, acc=0.35555556416511536, loss=3.382443904876709
train: epoch 43, loss 0.08337948471307755, acc=0.9750555753707886, loss=0.08337948471307755
test: epoch 43, loss 3.4874424934387207, acc=0.32777777314186096, loss=3.4874424934387207
train: epoch 44, loss 0.07737027108669281, acc=0.9756666421890259, loss=0.07737027108669281
test: epoch 44, loss 3.3587160110473633, acc=0.3361110985279083, loss=3.3587160110473633
train: epoch 45, loss 0.08786464482545853, acc=0.9747777581214905, loss=0.08786464482545853
test: epoch 45, loss 3.2859010696411133, acc=0.40833333134651184, loss=3.2859010696411133
train: epoch 46, loss 0.07109551876783371, acc=0.9769999980926514, loss=0.07109551876783371
test: epoch 46, loss 3.3047235012054443, acc=0.3083333373069763, loss=3.3047235012054443
train: epoch 47, loss 0.07569967210292816, acc=0.9790555834770203, loss=0.07569967210292816
test: epoch 47, loss 3.8954761028289795, acc=0.3305555582046509, loss=3.8954761028289795
train: epoch 48, loss 0.08093781769275665, acc=0.9756666421890259, loss=0.08093781769275665
test: epoch 48, loss 2.9867148399353027, acc=0.4166666567325592, loss=2.9867148399353027
train: epoch 49, loss 0.07067124545574188, acc=0.9789999723434448, loss=0.07067124545574188
test: epoch 49, loss 3.112802505493164, acc=0.39722222089767456, loss=3.112802505493164
train: epoch 50, loss 0.0689845010638237, acc=0.9796110987663269, loss=0.0689845010638237
test: epoch 50, loss 3.065159797668457, acc=0.39722222089767456, loss=3.065159797668457
train: epoch 51, loss 0.07826479524374008, acc=0.9785000085830688, loss=0.07826479524374008
test: epoch 51, loss 3.4240329265594482, acc=0.4000000059604645, loss=3.4240329265594482
train: epoch 52, loss 0.06531013548374176, acc=0.980555534362793, loss=0.06531013548374176
test: epoch 52, loss 3.836867332458496, acc=0.40833333134651184, loss=3.836867332458496
train: epoch 53, loss 0.060939185321331024, acc=0.9818333387374878, loss=0.060939185321331024
test: epoch 53, loss 3.852477550506592, acc=0.4027777910232544, loss=3.852477550506592
train: epoch 54, loss 0.05520378798246384, acc=0.9831666946411133, loss=0.05520378798246384
test: epoch 54, loss 3.3464784622192383, acc=0.40833333134651184, loss=3.3464784622192383
train: epoch 55, loss 0.06436970084905624, acc=0.9816666841506958, loss=0.06436970084905624
test: epoch 55, loss 3.745051383972168, acc=0.39722222089767456, loss=3.745051383972168
train: epoch 56, loss 0.05894949287176132, acc=0.9831666946411133, loss=0.05894949287176132
test: epoch 56, loss 3.576690673828125, acc=0.38055557012557983, loss=3.576690673828125
train: epoch 57, loss 0.057033270597457886, acc=0.9840555787086487, loss=0.057033270597457886
test: epoch 57, loss 3.933539628982544, acc=0.4027777910232544, loss=3.933539628982544
train: epoch 58, loss 0.05765876919031143, acc=0.9842777848243713, loss=0.05765876919031143
test: epoch 58, loss 3.918153762817383, acc=0.40833333134651184, loss=3.918153762817383
train: epoch 59, loss 0.06644562631845474, acc=0.9825000166893005, loss=0.06644562631845474
test: epoch 59, loss 3.44842267036438, acc=0.4305555522441864, loss=3.44842267036438
train: epoch 60, loss 0.04472425952553749, acc=0.9864444732666016, loss=0.04472425952553749
test: epoch 60, loss 3.6417694091796875, acc=0.3916666805744171, loss=3.6417694091796875
train: epoch 61, loss 0.053466811776161194, acc=0.9857222437858582, loss=0.053466811776161194
test: epoch 61, loss 3.549046516418457, acc=0.38333332538604736, loss=3.549046516418457
train: epoch 62, loss 0.055531878024339676, acc=0.9854444265365601, loss=0.055531878024339676
test: epoch 62, loss 3.454939603805542, acc=0.46666666865348816, loss=3.454939603805542
train: epoch 63, loss 0.049682293087244034, acc=0.9858333468437195, loss=0.049682293087244034
test: epoch 63, loss 3.2791261672973633, acc=0.39722222089767456, loss=3.2791261672973633
train: epoch 64, loss 0.047545284032821655, acc=0.9873889088630676, loss=0.047545284032821655
test: epoch 64, loss 3.5203099250793457, acc=0.4194444417953491, loss=3.5203099250793457
train: epoch 65, loss 0.04773588106036186, acc=0.9865000247955322, loss=0.04773588106036186
test: epoch 65, loss 3.1255481243133545, acc=0.46388888359069824, loss=3.1255481243133545
train: epoch 66, loss 0.04083166643977165, acc=0.9879999756813049, loss=0.04083166643977165
test: epoch 66, loss 3.4875528812408447, acc=0.46388888359069824, loss=3.4875528812408447
train: epoch 67, loss 0.04441767558455467, acc=0.9883888959884644, loss=0.04441767558455467
test: epoch 67, loss 3.3286707401275635, acc=0.47777777910232544, loss=3.3286707401275635
train: epoch 68, loss 0.0485152006149292, acc=0.9873889088630676, loss=0.0485152006149292
test: epoch 68, loss 3.6067845821380615, acc=0.49166667461395264, loss=3.6067845821380615
train: epoch 69, loss 0.04400932416319847, acc=0.9876111149787903, loss=0.04400932416319847
test: epoch 69, loss 4.07278299331665, acc=0.45277777314186096, loss=4.07278299331665
train: epoch 70, loss 0.042332980781793594, acc=0.988611102104187, loss=0.042332980781793594
test: epoch 70, loss 3.270419120788574, acc=0.519444465637207, loss=3.270419120788574
train: epoch 71, loss 0.05577867105603218, acc=0.9867777824401855, loss=0.05577867105603218
test: epoch 71, loss 3.5083022117614746, acc=0.4861111044883728, loss=3.5083022117614746
train: epoch 72, loss 0.04692773148417473, acc=0.9879999756813049, loss=0.04692773148417473
test: epoch 72, loss 3.308274984359741, acc=0.46388888359069824, loss=3.308274984359741
train: epoch 73, loss 0.04415883123874664, acc=0.9888888597488403, loss=0.04415883123874664
test: epoch 73, loss 3.1414127349853516, acc=0.47777777910232544, loss=3.1414127349853516
train: epoch 74, loss 0.04579997435212135, acc=0.988111138343811, loss=0.04579997435212135
test: epoch 74, loss 3.5829861164093018, acc=0.4694444537162781, loss=3.5829861164093018
train: epoch 75, loss 0.03736529126763344, acc=0.9904999732971191, loss=0.03736529126763344
test: epoch 75, loss 3.3839192390441895, acc=0.4861111044883728, loss=3.3839192390441895
train: epoch 76, loss 0.04676911607384682, acc=0.9878333210945129, loss=0.04676911607384682
test: epoch 76, loss 3.1520028114318848, acc=0.5222222208976746, loss=3.1520028114318848
train: epoch 77, loss 0.0402098074555397, acc=0.9898889064788818, loss=0.0402098074555397
test: epoch 77, loss 2.8969807624816895, acc=0.519444465637207, loss=2.8969807624816895
train: epoch 78, loss 0.039781179279088974, acc=0.9897222518920898, loss=0.039781179279088974
test: epoch 78, loss 3.2894911766052246, acc=0.4444444477558136, loss=3.2894911766052246
train: epoch 79, loss 0.049531277269124985, acc=0.9887222051620483, loss=0.049531277269124985
test: epoch 79, loss 3.2976982593536377, acc=0.4611110985279083, loss=3.2976982593536377
train: epoch 80, loss 0.0435037836432457, acc=0.9880555272102356, loss=0.0435037836432457
test: epoch 80, loss 2.998586416244507, acc=0.5138888955116272, loss=2.998586416244507
train: epoch 81, loss 0.03395506367087364, acc=0.9909999966621399, loss=0.03395506367087364
test: epoch 81, loss 3.5219998359680176, acc=0.4472222328186035, loss=3.5219998359680176
train: epoch 82, loss 0.03438163176178932, acc=0.9909444451332092, loss=0.03438163176178932
test: epoch 82, loss 2.5214390754699707, acc=0.550000011920929, loss=2.5214390754699707
train: epoch 83, loss 0.03174642473459244, acc=0.9918333292007446, loss=0.03174642473459244
test: epoch 83, loss 3.08978271484375, acc=0.5277777910232544, loss=3.08978271484375
train: epoch 84, loss 0.04098602384328842, acc=0.9886666536331177, loss=0.04098602384328842
test: epoch 84, loss 3.42598557472229, acc=0.5055555701255798, loss=3.42598557472229
train: epoch 85, loss 0.034293293952941895, acc=0.9906666874885559, loss=0.034293293952941895
test: epoch 85, loss 3.644378662109375, acc=0.5555555820465088, loss=3.644378662109375
train: epoch 86, loss 0.04253655672073364, acc=0.9900555610656738, loss=0.04253655672073364
test: epoch 86, loss 2.949597120285034, acc=0.5444444417953491, loss=2.949597120285034
train: epoch 87, loss 0.03791722282767296, acc=0.9911666512489319, loss=0.03791722282767296
test: epoch 87, loss 3.1122031211853027, acc=0.5555555820465088, loss=3.1122031211853027
train: epoch 88, loss 0.037777114659547806, acc=0.9906666874885559, loss=0.037777114659547806
test: epoch 88, loss 3.6115381717681885, acc=0.5333333611488342, loss=3.6115381717681885
train: epoch 89, loss 0.041576217859983444, acc=0.9904999732971191, loss=0.041576217859983444
test: epoch 89, loss 3.4453940391540527, acc=0.43888887763023376, loss=3.4453940391540527
train: epoch 90, loss 0.039715852588415146, acc=0.9895555377006531, loss=0.039715852588415146
test: epoch 90, loss 3.080411195755005, acc=0.519444465637207, loss=3.080411195755005
train: epoch 91, loss 0.03948969766497612, acc=0.9902222156524658, loss=0.03948969766497612
test: epoch 91, loss 3.5129141807556152, acc=0.5583333373069763, loss=3.5129141807556152
train: epoch 92, loss 0.03328564390540123, acc=0.9911110997200012, loss=0.03328564390540123
test: epoch 92, loss 3.023266315460205, acc=0.5, loss=3.023266315460205
train: epoch 93, loss 0.0312502458691597, acc=0.9917222261428833, loss=0.0312502458691597
test: epoch 93, loss 3.8049917221069336, acc=0.5083333253860474, loss=3.8049917221069336
train: epoch 94, loss 0.04057002067565918, acc=0.9901666641235352, loss=0.04057002067565918
test: epoch 94, loss 4.0013556480407715, acc=0.5166666507720947, loss=4.0013556480407715
train: epoch 95, loss 0.033231381326913834, acc=0.9913333058357239, loss=0.033231381326913834
test: epoch 95, loss 3.29750657081604, acc=0.4749999940395355, loss=3.29750657081604
train: epoch 96, loss 0.03820781782269478, acc=0.9903333187103271, loss=0.03820781782269478
test: epoch 96, loss 2.9399166107177734, acc=0.5361111164093018, loss=2.9399166107177734
train: epoch 97, loss 0.031273629516363144, acc=0.992388904094696, loss=0.031273629516363144
test: epoch 97, loss 3.3056230545043945, acc=0.5333333611488342, loss=3.3056230545043945
train: epoch 98, loss 0.0342075377702713, acc=0.9903333187103271, loss=0.0342075377702713
test: epoch 98, loss 3.4922146797180176, acc=0.5333333611488342, loss=3.4922146797180176
train: epoch 99, loss 0.03188521787524223, acc=0.991611123085022, loss=0.03188521787524223
test: epoch 99, loss 3.0077507495880127, acc=0.4861111044883728, loss=3.0077507495880127
train: epoch 100, loss 0.03420228511095047, acc=0.9923333525657654, loss=0.03420228511095047
test: epoch 100, loss 2.713914394378662, acc=0.5527777671813965, loss=2.713914394378662
train: epoch 101, loss 0.037159066647291183, acc=0.992111086845398, loss=0.037159066647291183
test: epoch 101, loss 3.439441680908203, acc=0.5444444417953491, loss=3.439441680908203
train: epoch 102, loss 0.030194684863090515, acc=0.9928333163261414, loss=0.030194684863090515
test: epoch 102, loss 2.7651584148406982, acc=0.605555534362793, loss=2.7651584148406982
train: epoch 103, loss 0.028104687109589577, acc=0.9924444556236267, loss=0.028104687109589577
test: epoch 103, loss 2.5756611824035645, acc=0.5722222328186035, loss=2.5756611824035645
train: epoch 104, loss 0.024582592770457268, acc=0.9933888912200928, loss=0.024582592770457268
test: epoch 104, loss 2.7913782596588135, acc=0.5388888716697693, loss=2.7913782596588135
train: epoch 105, loss 0.03799721598625183, acc=0.9916666746139526, loss=0.03799721598625183
test: epoch 105, loss 2.6317901611328125, acc=0.6138888597488403, loss=2.6317901611328125
train: epoch 106, loss 0.03595544397830963, acc=0.991777777671814, loss=0.03595544397830963
test: epoch 106, loss 3.3573315143585205, acc=0.550000011920929, loss=3.3573315143585205
train: epoch 107, loss 0.03442894294857979, acc=0.9912777543067932, loss=0.03442894294857979
test: epoch 107, loss 3.6702992916107178, acc=0.5694444179534912, loss=3.6702992916107178
train: epoch 108, loss 0.02626732923090458, acc=0.9936666488647461, loss=0.02626732923090458
test: epoch 108, loss 3.223917007446289, acc=0.5694444179534912, loss=3.223917007446289
train: epoch 109, loss 0.027997897937893867, acc=0.9936110973358154, loss=0.027997897937893867
test: epoch 109, loss 3.344782829284668, acc=0.5611110925674438, loss=3.344782829284668
train: epoch 110, loss 0.0321657620370388, acc=0.992111086845398, loss=0.0321657620370388
test: epoch 110, loss 3.405627489089966, acc=0.5722222328186035, loss=3.405627489089966
train: epoch 111, loss 0.02162560075521469, acc=0.9938889145851135, loss=0.02162560075521469
test: epoch 111, loss 3.0756213665008545, acc=0.5333333611488342, loss=3.0756213665008545
train: epoch 112, loss 0.033799853175878525, acc=0.991944432258606, loss=0.033799853175878525
test: epoch 112, loss 3.215158462524414, acc=0.5916666388511658, loss=3.215158462524414
train: epoch 113, loss 0.03394600749015808, acc=0.9911666512489319, loss=0.03394600749015808
test: epoch 113, loss 2.9454972743988037, acc=0.574999988079071, loss=2.9454972743988037
train: epoch 114, loss 0.02503560297191143, acc=0.9937777519226074, loss=0.02503560297191143
test: epoch 114, loss 3.649229049682617, acc=0.5138888955116272, loss=3.649229049682617
train: epoch 115, loss 0.028910601511597633, acc=0.9929444193840027, loss=0.028910601511597633
test: epoch 115, loss 3.0765538215637207, acc=0.5333333611488342, loss=3.0765538215637207
train: epoch 116, loss 0.019242364913225174, acc=0.9942777752876282, loss=0.019242364913225174
test: epoch 116, loss 3.1624867916107178, acc=0.5944444537162781, loss=3.1624867916107178
train: epoch 117, loss 0.027465317398309708, acc=0.9931666851043701, loss=0.027465317398309708
test: epoch 117, loss 2.9838480949401855, acc=0.5666666626930237, loss=2.9838480949401855
train: epoch 118, loss 0.032718759030103683, acc=0.991777777671814, loss=0.032718759030103683
test: epoch 118, loss 3.862759828567505, acc=0.5083333253860474, loss=3.862759828567505
train: epoch 119, loss 0.02615950256586075, acc=0.9934444427490234, loss=0.02615950256586075
test: epoch 119, loss 2.5763981342315674, acc=0.5611110925674438, loss=2.5763981342315674
train: epoch 120, loss 0.02625376731157303, acc=0.9933888912200928, loss=0.02625376731157303
test: epoch 120, loss 3.1235551834106445, acc=0.605555534362793, loss=3.1235551834106445
train: epoch 121, loss 0.031041286885738373, acc=0.992555558681488, loss=0.031041286885738373
test: epoch 121, loss 3.636669397354126, acc=0.5277777910232544, loss=3.636669397354126
train: epoch 122, loss 0.028133763000369072, acc=0.9929444193840027, loss=0.028133763000369072
test: epoch 122, loss 3.2942540645599365, acc=0.6083333492279053, loss=3.2942540645599365
train: epoch 123, loss 0.026666060090065002, acc=0.9934444427490234, loss=0.026666060090065002
test: epoch 123, loss 3.180006265640259, acc=0.5527777671813965, loss=3.180006265640259
train: epoch 124, loss 0.025843989104032516, acc=0.9940000176429749, loss=0.025843989104032516
test: epoch 124, loss 2.993511438369751, acc=0.5583333373069763, loss=2.993511438369751
train: epoch 125, loss 0.027944862842559814, acc=0.9940555691719055, loss=0.027944862842559814
test: epoch 125, loss 2.755988121032715, acc=0.5611110925674438, loss=2.755988121032715
train: epoch 126, loss 0.03233256936073303, acc=0.9930555820465088, loss=0.03233256936073303
test: epoch 126, loss 3.108914375305176, acc=0.5666666626930237, loss=3.108914375305176
train: epoch 127, loss 0.028259096667170525, acc=0.9947222471237183, loss=0.028259096667170525
test: epoch 127, loss 2.6135711669921875, acc=0.5722222328186035, loss=2.6135711669921875
train: epoch 128, loss 0.020210029557347298, acc=0.9948333501815796, loss=0.020210029557347298
test: epoch 128, loss 3.4262800216674805, acc=0.5444444417953491, loss=3.4262800216674805
train: epoch 129, loss 0.021745590493083, acc=0.9951666593551636, loss=0.021745590493083
test: epoch 129, loss 2.4087910652160645, acc=0.6333333253860474, loss=2.4087910652160645
train: epoch 130, loss 0.03384211286902428, acc=0.9931666851043701, loss=0.03384211286902428
test: epoch 130, loss 2.9249167442321777, acc=0.5833333134651184, loss=2.9249167442321777
train: epoch 131, loss 0.023393044248223305, acc=0.9937777519226074, loss=0.023393044248223305
test: epoch 131, loss 3.0222415924072266, acc=0.6194444298744202, loss=3.0222415924072266
train: epoch 132, loss 0.02260371670126915, acc=0.9947777986526489, loss=0.02260371670126915
test: epoch 132, loss 2.6564977169036865, acc=0.5972222089767456, loss=2.6564977169036865
train: epoch 133, loss 0.02854568511247635, acc=0.9943888783454895, loss=0.02854568511247635
test: epoch 133, loss 2.928942918777466, acc=0.574999988079071, loss=2.928942918777466
train: epoch 134, loss 0.031740523874759674, acc=0.9927777647972107, loss=0.031740523874759674
test: epoch 134, loss 2.6006901264190674, acc=0.6333333253860474, loss=2.6006901264190674
train: epoch 135, loss 0.02486649714410305, acc=0.9942222237586975, loss=0.02486649714410305
test: epoch 135, loss 3.2869036197662354, acc=0.5833333134651184, loss=3.2869036197662354
train: epoch 136, loss 0.0251883864402771, acc=0.9944999814033508, loss=0.0251883864402771
test: epoch 136, loss 2.5609147548675537, acc=0.6555555462837219, loss=2.5609147548675537
train: epoch 137, loss 0.023898009210824966, acc=0.9958333373069763, loss=0.023898009210824966
test: epoch 137, loss 2.361966609954834, acc=0.6499999761581421, loss=2.361966609954834
train: epoch 138, loss 0.02781449817121029, acc=0.9941111207008362, loss=0.02781449817121029
test: epoch 138, loss 3.2808594703674316, acc=0.6083333492279053, loss=3.2808594703674316
train: epoch 139, loss 0.025061054155230522, acc=0.9951111078262329, loss=0.025061054155230522
test: epoch 139, loss 2.7119107246398926, acc=0.6583333611488342, loss=2.7119107246398926
train: epoch 140, loss 0.02385307475924492, acc=0.9942222237586975, loss=0.02385307475924492
test: epoch 140, loss 2.3094987869262695, acc=0.6361111402511597, loss=2.3094987869262695
train: epoch 141, loss 0.026249825954437256, acc=0.9932222366333008, loss=0.026249825954437256
test: epoch 141, loss 3.3146960735321045, acc=0.5916666388511658, loss=3.3146960735321045
train: epoch 142, loss 0.020964547991752625, acc=0.9943333268165588, loss=0.020964547991752625
test: epoch 142, loss 3.016256332397461, acc=0.6611111164093018, loss=3.016256332397461
train: epoch 143, loss 0.020243404433131218, acc=0.9959444403648376, loss=0.020243404433131218
test: epoch 143, loss 2.6547691822052, acc=0.6333333253860474, loss=2.6547691822052
train: epoch 144, loss 0.024243848398327827, acc=0.9950555562973022, loss=0.024243848398327827
test: epoch 144, loss 2.7213070392608643, acc=0.6499999761581421, loss=2.7213070392608643
train: epoch 145, loss 0.01865154318511486, acc=0.9957777857780457, loss=0.01865154318511486
test: epoch 145, loss 3.196133852005005, acc=0.6361111402511597, loss=3.196133852005005
train: epoch 146, loss 0.02486618235707283, acc=0.9942222237586975, loss=0.02486618235707283
test: epoch 146, loss 3.6979780197143555, acc=0.6000000238418579, loss=3.6979780197143555
train: epoch 147, loss 0.019760286435484886, acc=0.9956111311912537, loss=0.019760286435484886
test: epoch 147, loss 2.992971897125244, acc=0.6083333492279053, loss=2.992971897125244
train: epoch 148, loss 0.020291287451982498, acc=0.9949444532394409, loss=0.020291287451982498
test: epoch 148, loss 3.061711072921753, acc=0.6333333253860474, loss=3.061711072921753
train: epoch 149, loss 0.02380269207060337, acc=0.9944444298744202, loss=0.02380269207060337
test: epoch 149, loss 2.777515411376953, acc=0.6361111402511597, loss=2.777515411376953
train: epoch 150, loss 0.023089349269866943, acc=0.9948889017105103, loss=0.023089349269866943
test: epoch 150, loss 2.7623424530029297, acc=0.5916666388511658, loss=2.7623424530029297
