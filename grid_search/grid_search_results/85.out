# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=1.5", "--temp_decay=0.99", "--one_hot=true", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1127714804, receiver_embed_dim=64, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.906582832336426, acc=0.09622222185134888, loss=2.906582832336426
test: epoch 1, loss 3.418644905090332, acc=0.10833333432674408, loss=3.418644905090332
train: epoch 2, loss 1.8369187116622925, acc=0.30383333563804626, loss=1.8369187116622925
test: epoch 2, loss 3.8278677463531494, acc=0.12777778506278992, loss=3.8278677463531494
train: epoch 3, loss 1.3639518022537231, acc=0.45249998569488525, loss=1.3639518022537231
test: epoch 3, loss 2.7529213428497314, acc=0.20277777314186096, loss=2.7529213428497314
train: epoch 4, loss 1.1126154661178589, acc=0.5502777695655823, loss=1.1126154661178589
test: epoch 4, loss 2.781503915786743, acc=0.21944443881511688, loss=2.781503915786743
train: epoch 5, loss 0.9809368848800659, acc=0.5983333587646484, loss=0.9809368848800659
test: epoch 5, loss 2.1790339946746826, acc=0.26944443583488464, loss=2.1790339946746826
train: epoch 6, loss 0.863244354724884, acc=0.6515555381774902, loss=0.863244354724884
test: epoch 6, loss 1.7927272319793701, acc=0.39722222089767456, loss=1.7927272319793701
train: epoch 7, loss 0.7608151435852051, acc=0.6935555338859558, loss=0.7608151435852051
test: epoch 7, loss 1.9640508890151978, acc=0.3027777671813965, loss=1.9640508890151978
train: epoch 8, loss 0.7064813375473022, acc=0.7190555334091187, loss=0.7064813375473022
test: epoch 8, loss 2.0858383178710938, acc=0.3222222328186035, loss=2.0858383178710938
train: epoch 9, loss 0.629262387752533, acc=0.7494444251060486, loss=0.629262387752533
test: epoch 9, loss 2.0311367511749268, acc=0.3361110985279083, loss=2.0311367511749268
train: epoch 10, loss 0.5863323211669922, acc=0.7651666402816772, loss=0.5863323211669922
test: epoch 10, loss 1.6989085674285889, acc=0.35277777910232544, loss=1.6989085674285889
train: epoch 11, loss 0.5405504703521729, acc=0.7868333458900452, loss=0.5405504703521729
test: epoch 11, loss 1.7529176473617554, acc=0.4027777910232544, loss=1.7529176473617554
train: epoch 12, loss 0.4941639006137848, acc=0.8045555353164673, loss=0.4941639006137848
test: epoch 12, loss 1.476866364479065, acc=0.4305555522441864, loss=1.476866364479065
train: epoch 13, loss 0.49174633622169495, acc=0.801277756690979, loss=0.49174633622169495
test: epoch 13, loss 1.6203584671020508, acc=0.4166666567325592, loss=1.6203584671020508
train: epoch 14, loss 0.4495818316936493, acc=0.8223888874053955, loss=0.4495818316936493
test: epoch 14, loss 1.7047804594039917, acc=0.42500001192092896, loss=1.7047804594039917
train: epoch 15, loss 0.43581774830818176, acc=0.8259444236755371, loss=0.43581774830818176
test: epoch 15, loss 2.0391533374786377, acc=0.3861111104488373, loss=2.0391533374786377
train: epoch 16, loss 0.4133906066417694, acc=0.8345000147819519, loss=0.4133906066417694
test: epoch 16, loss 1.7856330871582031, acc=0.4694444537162781, loss=1.7856330871582031
train: epoch 17, loss 0.40882498025894165, acc=0.8337222337722778, loss=0.40882498025894165
test: epoch 17, loss 1.5241490602493286, acc=0.43888887763023376, loss=1.5241490602493286
train: epoch 18, loss 0.38837912678718567, acc=0.8392221927642822, loss=0.38837912678718567
test: epoch 18, loss 1.4458636045455933, acc=0.519444465637207, loss=1.4458636045455933
train: epoch 19, loss 0.39351508021354675, acc=0.8421111106872559, loss=0.39351508021354675
test: epoch 19, loss 1.5187398195266724, acc=0.48055556416511536, loss=1.5187398195266724
train: epoch 20, loss 0.36407339572906494, acc=0.8501666784286499, loss=0.36407339572906494
test: epoch 20, loss 1.7922253608703613, acc=0.4472222328186035, loss=1.7922253608703613
train: epoch 21, loss 0.3620598614215851, acc=0.851111114025116, loss=0.3620598614215851
test: epoch 21, loss 1.4037796258926392, acc=0.4472222328186035, loss=1.4037796258926392
train: epoch 22, loss 0.3458194434642792, acc=0.8587777614593506, loss=0.3458194434642792
test: epoch 22, loss 1.974125862121582, acc=0.4027777910232544, loss=1.974125862121582
train: epoch 23, loss 0.3474067747592926, acc=0.8606111407279968, loss=0.3474067747592926
test: epoch 23, loss 1.7808462381362915, acc=0.4166666567325592, loss=1.7808462381362915
train: epoch 24, loss 0.3416881263256073, acc=0.8605555295944214, loss=0.3416881263256073
test: epoch 24, loss 1.7191702127456665, acc=0.49166667461395264, loss=1.7191702127456665
train: epoch 25, loss 0.3184412121772766, acc=0.8679444193840027, loss=0.3184412121772766
test: epoch 25, loss 1.5743547677993774, acc=0.5138888955116272, loss=1.5743547677993774
train: epoch 26, loss 0.31328311562538147, acc=0.8713889122009277, loss=0.31328311562538147
test: epoch 26, loss 1.6437395811080933, acc=0.43888887763023376, loss=1.6437395811080933
train: epoch 27, loss 0.30268359184265137, acc=0.8776666522026062, loss=0.30268359184265137
test: epoch 27, loss 1.4469696283340454, acc=0.519444465637207, loss=1.4469696283340454
train: epoch 28, loss 0.30882060527801514, acc=0.8727777600288391, loss=0.30882060527801514
test: epoch 28, loss 1.4991064071655273, acc=0.5472221970558167, loss=1.4991064071655273
train: epoch 29, loss 0.2883440852165222, acc=0.8796111345291138, loss=0.2883440852165222
test: epoch 29, loss 1.426143765449524, acc=0.4611110985279083, loss=1.426143765449524
train: epoch 30, loss 0.28517672419548035, acc=0.8829444646835327, loss=0.28517672419548035
test: epoch 30, loss 1.2651411294937134, acc=0.5861111283302307, loss=1.2651411294937134
train: epoch 31, loss 0.2891809046268463, acc=0.882444441318512, loss=0.2891809046268463
test: epoch 31, loss 0.9215266108512878, acc=0.644444465637207, loss=0.9215266108512878
train: epoch 32, loss 0.27894142270088196, acc=0.8840555548667908, loss=0.27894142270088196
test: epoch 32, loss 1.1814959049224854, acc=0.625, loss=1.1814959049224854
train: epoch 33, loss 0.28145769238471985, acc=0.8849444389343262, loss=0.28145769238471985
test: epoch 33, loss 1.2371271848678589, acc=0.6138888597488403, loss=1.2371271848678589
train: epoch 34, loss 0.2807210683822632, acc=0.8843333125114441, loss=0.2807210683822632
test: epoch 34, loss 0.7845748066902161, acc=0.7277777791023254, loss=0.7845748066902161
train: epoch 35, loss 0.25777101516723633, acc=0.8918889164924622, loss=0.25777101516723633
test: epoch 35, loss 0.9207178950309753, acc=0.6861110925674438, loss=0.9207178950309753
train: epoch 36, loss 0.27781519293785095, acc=0.8849999904632568, loss=0.27781519293785095
test: epoch 36, loss 0.8597973585128784, acc=0.699999988079071, loss=0.8597973585128784
train: epoch 37, loss 0.25042468309402466, acc=0.8953333497047424, loss=0.25042468309402466
test: epoch 37, loss 0.8771862387657166, acc=0.7166666388511658, loss=0.8771862387657166
train: epoch 38, loss 0.2286521941423416, acc=0.9018333554267883, loss=0.2286521941423416
test: epoch 38, loss 0.9643104076385498, acc=0.6972222328186035, loss=0.9643104076385498
train: epoch 39, loss 0.2503734230995178, acc=0.8971666693687439, loss=0.2503734230995178
test: epoch 39, loss 0.7952723503112793, acc=0.7444444298744202, loss=0.7952723503112793
train: epoch 40, loss 0.24165989458560944, acc=0.8998333215713501, loss=0.24165989458560944
test: epoch 40, loss 0.8337284922599792, acc=0.7361111044883728, loss=0.8337284922599792
train: epoch 41, loss 0.23864887654781342, acc=0.9008333086967468, loss=0.23864887654781342
test: epoch 41, loss 0.8497217297554016, acc=0.7361111044883728, loss=0.8497217297554016
train: epoch 42, loss 0.23846344649791718, acc=0.9017778038978577, loss=0.23846344649791718
test: epoch 42, loss 0.5649002194404602, acc=0.7777777910232544, loss=0.5649002194404602
train: epoch 43, loss 0.22572815418243408, acc=0.906333327293396, loss=0.22572815418243408
test: epoch 43, loss 0.6965305805206299, acc=0.7472222447395325, loss=0.6965305805206299
train: epoch 44, loss 0.2293339967727661, acc=0.9046666622161865, loss=0.2293339967727661
test: epoch 44, loss 0.755837082862854, acc=0.75, loss=0.755837082862854
train: epoch 45, loss 0.2187243402004242, acc=0.9076111316680908, loss=0.2187243402004242
test: epoch 45, loss 0.5615445971488953, acc=0.8027777671813965, loss=0.5615445971488953
train: epoch 46, loss 0.2254311591386795, acc=0.9098333120346069, loss=0.2254311591386795
test: epoch 46, loss 0.6213564872741699, acc=0.769444465637207, loss=0.6213564872741699
train: epoch 47, loss 0.22621434926986694, acc=0.9081666469573975, loss=0.22621434926986694
test: epoch 47, loss 0.6735821962356567, acc=0.7777777910232544, loss=0.6735821962356567
train: epoch 48, loss 0.22669890522956848, acc=0.9060555696487427, loss=0.22669890522956848
test: epoch 48, loss 0.6466299295425415, acc=0.7944444417953491, loss=0.6466299295425415
train: epoch 49, loss 0.22464600205421448, acc=0.9076666831970215, loss=0.22464600205421448
test: epoch 49, loss 0.6694513559341431, acc=0.7388888597488403, loss=0.6694513559341431
train: epoch 50, loss 0.20822273194789886, acc=0.9130555391311646, loss=0.20822273194789886
test: epoch 50, loss 0.731532633304596, acc=0.7861111164093018, loss=0.731532633304596
train: epoch 51, loss 0.20777367055416107, acc=0.9133889079093933, loss=0.20777367055416107
test: epoch 51, loss 0.5725924968719482, acc=0.8111110925674438, loss=0.5725924968719482
train: epoch 52, loss 0.20382653176784515, acc=0.9158889055252075, loss=0.20382653176784515
test: epoch 52, loss 0.584639310836792, acc=0.8138889074325562, loss=0.584639310836792
train: epoch 53, loss 0.1986778825521469, acc=0.9183333516120911, loss=0.1986778825521469
test: epoch 53, loss 0.48056840896606445, acc=0.8416666388511658, loss=0.48056840896606445
train: epoch 54, loss 0.20487242937088013, acc=0.9159444570541382, loss=0.20487242937088013
test: epoch 54, loss 0.5136816501617432, acc=0.8361111283302307, loss=0.5136816501617432
train: epoch 55, loss 0.20062127709388733, acc=0.9176666736602783, loss=0.20062127709388733
test: epoch 55, loss 0.4749252498149872, acc=0.8444444537162781, loss=0.4749252498149872
train: epoch 56, loss 0.19442495703697205, acc=0.9208889007568359, loss=0.19442495703697205
test: epoch 56, loss 0.4539816677570343, acc=0.8333333134651184, loss=0.4539816677570343
train: epoch 57, loss 0.188115194439888, acc=0.9198333621025085, loss=0.188115194439888
test: epoch 57, loss 0.36427974700927734, acc=0.8416666388511658, loss=0.36427974700927734
train: epoch 58, loss 0.1813725084066391, acc=0.9213333129882812, loss=0.1813725084066391
test: epoch 58, loss 0.5034258365631104, acc=0.8361111283302307, loss=0.5034258365631104
train: epoch 59, loss 0.19713494181632996, acc=0.918833315372467, loss=0.19713494181632996
test: epoch 59, loss 0.44051870703697205, acc=0.8444444537162781, loss=0.44051870703697205
train: epoch 60, loss 0.18965642154216766, acc=0.9200555682182312, loss=0.18965642154216766
test: epoch 60, loss 0.7414603233337402, acc=0.8055555820465088, loss=0.7414603233337402
train: epoch 61, loss 0.18528303503990173, acc=0.9197777509689331, loss=0.18528303503990173
test: epoch 61, loss 0.39020147919654846, acc=0.8361111283302307, loss=0.39020147919654846
train: epoch 62, loss 0.18032464385032654, acc=0.9222221970558167, loss=0.18032464385032654
test: epoch 62, loss 0.44719430804252625, acc=0.8444444537162781, loss=0.44719430804252625
train: epoch 63, loss 0.20044632256031036, acc=0.9176111221313477, loss=0.20044632256031036
test: epoch 63, loss 0.4610571563243866, acc=0.8444444537162781, loss=0.4610571563243866
train: epoch 64, loss 0.19709114730358124, acc=0.9198333621025085, loss=0.19709114730358124
test: epoch 64, loss 0.5320619344711304, acc=0.8416666388511658, loss=0.5320619344711304
train: epoch 65, loss 0.18639402091503143, acc=0.9212222099304199, loss=0.18639402091503143
test: epoch 65, loss 0.4741078019142151, acc=0.8416666388511658, loss=0.4741078019142151
train: epoch 66, loss 0.2059118002653122, acc=0.9135000109672546, loss=0.2059118002653122
test: epoch 66, loss 0.5580235719680786, acc=0.824999988079071, loss=0.5580235719680786
train: epoch 67, loss 0.18746988475322723, acc=0.9194999933242798, loss=0.18746988475322723
test: epoch 67, loss 0.44269707798957825, acc=0.8444444537162781, loss=0.44269707798957825
train: epoch 68, loss 0.19060713052749634, acc=0.9179444313049316, loss=0.19060713052749634
test: epoch 68, loss 0.3918206989765167, acc=0.8361111283302307, loss=0.3918206989765167
train: epoch 69, loss 0.18267451226711273, acc=0.9220555424690247, loss=0.18267451226711273
test: epoch 69, loss 0.41361004114151, acc=0.8444444537162781, loss=0.41361004114151
train: epoch 70, loss 0.19847466051578522, acc=0.9183333516120911, loss=0.19847466051578522
test: epoch 70, loss 0.3823291063308716, acc=0.8361111283302307, loss=0.3823291063308716
train: epoch 71, loss 0.19622965157032013, acc=0.917555570602417, loss=0.19622965157032013
test: epoch 71, loss 0.4125095009803772, acc=0.8361111283302307, loss=0.4125095009803772
train: epoch 72, loss 0.19662965834140778, acc=0.9187777638435364, loss=0.19662965834140778
test: epoch 72, loss 0.429361492395401, acc=0.8444444537162781, loss=0.429361492395401
train: epoch 73, loss 0.18212655186653137, acc=0.9201666712760925, loss=0.18212655186653137
test: epoch 73, loss 0.438653826713562, acc=0.8444444537162781, loss=0.438653826713562
train: epoch 74, loss 0.19036662578582764, acc=0.9204999804496765, loss=0.19036662578582764
test: epoch 74, loss 0.5101751685142517, acc=0.8361111283302307, loss=0.5101751685142517
train: epoch 75, loss 0.19553197920322418, acc=0.9190000295639038, loss=0.19553197920322418
test: epoch 75, loss 0.41411304473876953, acc=0.8444444537162781, loss=0.41411304473876953
train: epoch 76, loss 0.18683473765850067, acc=0.9199444651603699, loss=0.18683473765850067
test: epoch 76, loss 0.488588809967041, acc=0.8444444537162781, loss=0.488588809967041
train: epoch 77, loss 0.17691592872142792, acc=0.9206666946411133, loss=0.17691592872142792
test: epoch 77, loss 0.4227599799633026, acc=0.8444444537162781, loss=0.4227599799633026
train: epoch 78, loss 0.1909167617559433, acc=0.920722246170044, loss=0.1909167617559433
test: epoch 78, loss 0.36461785435676575, acc=0.8444444537162781, loss=0.36461785435676575
train: epoch 79, loss 0.18118223547935486, acc=0.9231666922569275, loss=0.18118223547935486
test: epoch 79, loss 0.4680272936820984, acc=0.8444444537162781, loss=0.4680272936820984
train: epoch 80, loss 0.177762970328331, acc=0.9242222309112549, loss=0.177762970328331
test: epoch 80, loss 0.46247538924217224, acc=0.8444444537162781, loss=0.46247538924217224
train: epoch 81, loss 0.17849862575531006, acc=0.9244444370269775, loss=0.17849862575531006
test: epoch 81, loss 0.4504673480987549, acc=0.8444444537162781, loss=0.4504673480987549
train: epoch 82, loss 0.18543381989002228, acc=0.9217222332954407, loss=0.18543381989002228
test: epoch 82, loss 0.44072824716567993, acc=0.8444444537162781, loss=0.44072824716567993
train: epoch 83, loss 0.18441084027290344, acc=0.9223889112472534, loss=0.18441084027290344
test: epoch 83, loss 0.4155885577201843, acc=0.8444444537162781, loss=0.4155885577201843
train: epoch 84, loss 0.1828121393918991, acc=0.9204999804496765, loss=0.1828121393918991
test: epoch 84, loss 0.42692282795906067, acc=0.8416666388511658, loss=0.42692282795906067
train: epoch 85, loss 0.175618514418602, acc=0.9233888983726501, loss=0.175618514418602
test: epoch 85, loss 0.43035775423049927, acc=0.8444444537162781, loss=0.43035775423049927
train: epoch 86, loss 0.18273331224918365, acc=0.9216111302375793, loss=0.18273331224918365
test: epoch 86, loss 0.4094735085964203, acc=0.8444444537162781, loss=0.4094735085964203
train: epoch 87, loss 0.1877553015947342, acc=0.9224444627761841, loss=0.1877553015947342
test: epoch 87, loss 0.44602763652801514, acc=0.8444444537162781, loss=0.44602763652801514
train: epoch 88, loss 0.18915864825248718, acc=0.9205555319786072, loss=0.18915864825248718
test: epoch 88, loss 0.39692485332489014, acc=0.8444444537162781, loss=0.39692485332489014
train: epoch 89, loss 0.18827424943447113, acc=0.9204444289207458, loss=0.18827424943447113
test: epoch 89, loss 0.39495447278022766, acc=0.8388888835906982, loss=0.39495447278022766
train: epoch 90, loss 0.1807345598936081, acc=0.9204999804496765, loss=0.1807345598936081
test: epoch 90, loss 0.4297150671482086, acc=0.8444444537162781, loss=0.4297150671482086
train: epoch 91, loss 0.17406287789344788, acc=0.9266111254692078, loss=0.17406287789344788
test: epoch 91, loss 0.5266150236129761, acc=0.8222222328186035, loss=0.5266150236129761
train: epoch 92, loss 0.17278650403022766, acc=0.9258888959884644, loss=0.17278650403022766
test: epoch 92, loss 0.44329869747161865, acc=0.8444444537162781, loss=0.44329869747161865
train: epoch 93, loss 0.1815832555294037, acc=0.9242777824401855, loss=0.1815832555294037
test: epoch 93, loss 0.521486759185791, acc=0.8111110925674438, loss=0.521486759185791
train: epoch 94, loss 0.17415666580200195, acc=0.9254999756813049, loss=0.17415666580200195
test: epoch 94, loss 0.4196261465549469, acc=0.8444444537162781, loss=0.4196261465549469
train: epoch 95, loss 0.17245720326900482, acc=0.9248889088630676, loss=0.17245720326900482
test: epoch 95, loss 0.44501379132270813, acc=0.8444444537162781, loss=0.44501379132270813
train: epoch 96, loss 0.16281160712242126, acc=0.9280555844306946, loss=0.16281160712242126
test: epoch 96, loss 0.4733211100101471, acc=0.8444444537162781, loss=0.4733211100101471
train: epoch 97, loss 0.1729154735803604, acc=0.9253333210945129, loss=0.1729154735803604
test: epoch 97, loss 0.39453601837158203, acc=0.8416666388511658, loss=0.39453601837158203
train: epoch 98, loss 0.17137080430984497, acc=0.9258333444595337, loss=0.17137080430984497
test: epoch 98, loss 0.4784806966781616, acc=0.8416666388511658, loss=0.4784806966781616
train: epoch 99, loss 0.17036429047584534, acc=0.9285555481910706, loss=0.17036429047584534
test: epoch 99, loss 0.45538678765296936, acc=0.824999988079071, loss=0.45538678765296936
train: epoch 100, loss 0.18376033008098602, acc=0.9232777953147888, loss=0.18376033008098602
test: epoch 100, loss 0.4298272430896759, acc=0.8444444537162781, loss=0.4298272430896759
train: epoch 101, loss 0.16908526420593262, acc=0.9263888597488403, loss=0.16908526420593262
test: epoch 101, loss 0.4753194749355316, acc=0.8444444537162781, loss=0.4753194749355316
train: epoch 102, loss 0.16780968010425568, acc=0.9277222156524658, loss=0.16780968010425568
test: epoch 102, loss 0.4670783281326294, acc=0.8444444537162781, loss=0.4670783281326294
train: epoch 103, loss 0.1700703650712967, acc=0.9263333082199097, loss=0.1700703650712967
test: epoch 103, loss 0.41790658235549927, acc=0.8444444537162781, loss=0.41790658235549927
train: epoch 104, loss 0.16512636840343475, acc=0.9273889064788818, loss=0.16512636840343475
test: epoch 104, loss 0.43199971318244934, acc=0.8444444537162781, loss=0.43199971318244934
train: epoch 105, loss 0.19560277462005615, acc=0.9194444417953491, loss=0.19560277462005615
test: epoch 105, loss 0.4194786250591278, acc=0.8361111283302307, loss=0.4194786250591278
train: epoch 106, loss 0.19886994361877441, acc=0.917388916015625, loss=0.19886994361877441
test: epoch 106, loss 0.46960315108299255, acc=0.8444444537162781, loss=0.46960315108299255
train: epoch 107, loss 0.16435331106185913, acc=0.9266111254692078, loss=0.16435331106185913
test: epoch 107, loss 0.4684985280036926, acc=0.8444444537162781, loss=0.4684985280036926
train: epoch 108, loss 0.16654011607170105, acc=0.9278888702392578, loss=0.16654011607170105
test: epoch 108, loss 0.398659348487854, acc=0.8444444537162781, loss=0.398659348487854
train: epoch 109, loss 0.15903596580028534, acc=0.9294999837875366, loss=0.15903596580028534
test: epoch 109, loss 0.49446967244148254, acc=0.8444444537162781, loss=0.49446967244148254
train: epoch 110, loss 0.16664870083332062, acc=0.9281111359596252, loss=0.16664870083332062
test: epoch 110, loss 0.45304760336875916, acc=0.8444444537162781, loss=0.45304760336875916
train: epoch 111, loss 0.16094870865345, acc=0.930055558681488, loss=0.16094870865345
test: epoch 111, loss 0.4289286732673645, acc=0.8444444537162781, loss=0.4289286732673645
train: epoch 112, loss 0.16045238077640533, acc=0.9294999837875366, loss=0.16045238077640533
test: epoch 112, loss 0.48215609788894653, acc=0.8444444537162781, loss=0.48215609788894653
train: epoch 113, loss 0.16360318660736084, acc=0.9285555481910706, loss=0.16360318660736084
test: epoch 113, loss 0.37590768933296204, acc=0.8444444537162781, loss=0.37590768933296204
train: epoch 114, loss 0.16892553865909576, acc=0.9271666407585144, loss=0.16892553865909576
test: epoch 114, loss 0.3895799517631531, acc=0.8388888835906982, loss=0.3895799517631531
train: epoch 115, loss 0.16804493963718414, acc=0.9279444217681885, loss=0.16804493963718414
test: epoch 115, loss 0.4739782512187958, acc=0.8444444537162781, loss=0.4739782512187958
train: epoch 116, loss 0.15604427456855774, acc=0.9304444193840027, loss=0.15604427456855774
test: epoch 116, loss 0.4545089304447174, acc=0.8444444537162781, loss=0.4545089304447174
train: epoch 117, loss 0.16730822622776031, acc=0.9269999861717224, loss=0.16730822622776031
test: epoch 117, loss 0.4319262206554413, acc=0.8444444537162781, loss=0.4319262206554413
train: epoch 118, loss 0.16269434988498688, acc=0.9283333420753479, loss=0.16269434988498688
test: epoch 118, loss 0.4599330723285675, acc=0.8388888835906982, loss=0.4599330723285675
train: epoch 119, loss 0.1579182744026184, acc=0.9283333420753479, loss=0.1579182744026184
test: epoch 119, loss 0.4351276457309723, acc=0.8444444537162781, loss=0.4351276457309723
train: epoch 120, loss 0.17169487476348877, acc=0.9242222309112549, loss=0.17169487476348877
test: epoch 120, loss 0.5079640746116638, acc=0.8388888835906982, loss=0.5079640746116638
train: epoch 121, loss 0.17731811106204987, acc=0.9252777695655823, loss=0.17731811106204987
test: epoch 121, loss 0.4718218743801117, acc=0.8444444537162781, loss=0.4718218743801117
train: epoch 122, loss 0.1585734337568283, acc=0.9307777881622314, loss=0.1585734337568283
test: epoch 122, loss 0.5027807354927063, acc=0.8444444537162781, loss=0.5027807354927063
train: epoch 123, loss 0.15071097016334534, acc=0.9329444169998169, loss=0.15071097016334534
test: epoch 123, loss 0.45692622661590576, acc=0.8444444537162781, loss=0.45692622661590576
train: epoch 124, loss 0.16914184391498566, acc=0.9259999990463257, loss=0.16914184391498566
test: epoch 124, loss 0.4544261693954468, acc=0.8444444537162781, loss=0.4544261693954468
train: epoch 125, loss 0.16338412463665009, acc=0.9326666593551636, loss=0.16338412463665009
test: epoch 125, loss 0.4924916625022888, acc=0.8444444537162781, loss=0.4924916625022888
train: epoch 126, loss 0.16489219665527344, acc=0.9307777881622314, loss=0.16489219665527344
test: epoch 126, loss 0.4761512875556946, acc=0.8444444537162781, loss=0.4761512875556946
train: epoch 127, loss 0.16104131937026978, acc=0.9293888807296753, loss=0.16104131937026978
test: epoch 127, loss 0.4431966245174408, acc=0.8444444537162781, loss=0.4431966245174408
train: epoch 128, loss 0.15998701751232147, acc=0.9327222108840942, loss=0.15998701751232147
test: epoch 128, loss 0.5176123976707458, acc=0.8416666388511658, loss=0.5176123976707458
train: epoch 129, loss 0.1596667319536209, acc=0.9318888783454895, loss=0.1596667319536209
test: epoch 129, loss 0.38306155800819397, acc=0.8416666388511658, loss=0.38306155800819397
train: epoch 130, loss 0.16595560312271118, acc=0.9274444580078125, loss=0.16595560312271118
test: epoch 130, loss 0.4241366982460022, acc=0.8444444537162781, loss=0.4241366982460022
train: epoch 131, loss 0.16321031749248505, acc=0.9312222003936768, loss=0.16321031749248505
test: epoch 131, loss 0.5382701754570007, acc=0.8388888835906982, loss=0.5382701754570007
train: epoch 132, loss 0.1568547487258911, acc=0.9321110844612122, loss=0.1568547487258911
test: epoch 132, loss 0.48489218950271606, acc=0.8444444537162781, loss=0.48489218950271606
train: epoch 133, loss 0.15928083658218384, acc=0.9301666617393494, loss=0.15928083658218384
test: epoch 133, loss 0.5096225142478943, acc=0.8444444537162781, loss=0.5096225142478943
train: epoch 134, loss 0.16922657191753387, acc=0.9297778010368347, loss=0.16922657191753387
test: epoch 134, loss 0.37356826663017273, acc=0.8444444537162781, loss=0.37356826663017273
train: epoch 135, loss 0.15436385571956635, acc=0.9326111078262329, loss=0.15436385571956635
test: epoch 135, loss 0.4415399730205536, acc=0.8444444537162781, loss=0.4415399730205536
train: epoch 136, loss 0.16550247371196747, acc=0.9287222027778625, loss=0.16550247371196747
test: epoch 136, loss 0.46561750769615173, acc=0.8444444537162781, loss=0.46561750769615173
train: epoch 137, loss 0.15176647901535034, acc=0.9339444637298584, loss=0.15176647901535034
test: epoch 137, loss 0.49438366293907166, acc=0.8444444537162781, loss=0.49438366293907166
train: epoch 138, loss 0.1607479751110077, acc=0.9291666746139526, loss=0.1607479751110077
test: epoch 138, loss 0.448572039604187, acc=0.8444444537162781, loss=0.448572039604187
train: epoch 139, loss 0.15613290667533875, acc=0.9337777495384216, loss=0.15613290667533875
test: epoch 139, loss 0.4311423599720001, acc=0.8444444537162781, loss=0.4311423599720001
train: epoch 140, loss 0.1546051800251007, acc=0.9319999814033508, loss=0.1546051800251007
test: epoch 140, loss 0.4299791753292084, acc=0.8444444537162781, loss=0.4299791753292084
train: epoch 141, loss 0.1571865975856781, acc=0.9321110844612122, loss=0.1571865975856781
test: epoch 141, loss 0.4777766764163971, acc=0.8444444537162781, loss=0.4777766764163971
train: epoch 142, loss 0.15643428266048431, acc=0.9316111207008362, loss=0.15643428266048431
test: epoch 142, loss 0.439848929643631, acc=0.8444444537162781, loss=0.439848929643631
train: epoch 143, loss 0.16140611469745636, acc=0.9319444298744202, loss=0.16140611469745636
test: epoch 143, loss 0.4711902439594269, acc=0.8444444537162781, loss=0.4711902439594269
train: epoch 144, loss 0.15114092826843262, acc=0.9321666955947876, loss=0.15114092826843262
test: epoch 144, loss 0.40671423077583313, acc=0.8444444537162781, loss=0.40671423077583313
train: epoch 145, loss 0.16654545068740845, acc=0.9273889064788818, loss=0.16654545068740845
test: epoch 145, loss 0.5114836692810059, acc=0.8444444537162781, loss=0.5114836692810059
train: epoch 146, loss 0.16855862736701965, acc=0.9263888597488403, loss=0.16855862736701965
test: epoch 146, loss 0.4088537096977234, acc=0.8388888835906982, loss=0.4088537096977234
train: epoch 147, loss 0.15974797308444977, acc=0.9323333501815796, loss=0.15974797308444977
test: epoch 147, loss 0.3634754717350006, acc=0.8416666388511658, loss=0.3634754717350006
train: epoch 148, loss 0.15479274094104767, acc=0.933555543422699, loss=0.15479274094104767
test: epoch 148, loss 0.3278673589229584, acc=0.8444444537162781, loss=0.3278673589229584
train: epoch 149, loss 0.13764692842960358, acc=0.9379444718360901, loss=0.13764692842960358
test: epoch 149, loss 0.5721582770347595, acc=0.8444444537162781, loss=0.5721582770347595
train: epoch 150, loss 0.15953592956066132, acc=0.9316666722297668, loss=0.15953592956066132
test: epoch 150, loss 0.4187864661216736, acc=0.8444444537162781, loss=0.4187864661216736
