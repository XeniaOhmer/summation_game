# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=1", "--temp_decay=0.99", "--one_hot=false", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1826507190, receiver_embed_dim=64, temp_decay=0.99, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.9679458141326904, acc=0.07944444566965103, loss=2.9679458141326904
test: epoch 1, loss 2.409701347351074, acc=0.125, loss=2.409701347351074
train: epoch 2, loss 2.093592643737793, acc=0.17355555295944214, loss=2.093592643737793
test: epoch 2, loss 2.0343949794769287, acc=0.18333333730697632, loss=2.0343949794769287
train: epoch 3, loss 1.8352042436599731, acc=0.23238888382911682, loss=1.8352042436599731
test: epoch 3, loss 1.936698079109192, acc=0.18611110746860504, loss=1.936698079109192
train: epoch 4, loss 1.6512879133224487, acc=0.28172221779823303, loss=1.6512879133224487
test: epoch 4, loss 1.8745039701461792, acc=0.24444444477558136, loss=1.8745039701461792
train: epoch 5, loss 1.5613757371902466, acc=0.31772223114967346, loss=1.5613757371902466
test: epoch 5, loss 1.8625916242599487, acc=0.2361111044883728, loss=1.8625916242599487
train: epoch 6, loss 1.4746229648590088, acc=0.3362777829170227, loss=1.4746229648590088
test: epoch 6, loss 1.8182997703552246, acc=0.2805555462837219, loss=1.8182997703552246
train: epoch 7, loss 1.3666837215423584, acc=0.39605554938316345, loss=1.3666837215423584
test: epoch 7, loss 1.5278666019439697, acc=0.3583333194255829, loss=1.5278666019439697
train: epoch 8, loss 1.2412046194076538, acc=0.4481666684150696, loss=1.2412046194076538
test: epoch 8, loss 1.5993558168411255, acc=0.3638888895511627, loss=1.5993558168411255
train: epoch 9, loss 1.160746693611145, acc=0.49227777123451233, loss=1.160746693611145
test: epoch 9, loss 1.5263105630874634, acc=0.375, loss=1.5263105630874634
train: epoch 10, loss 1.1041511297225952, acc=0.5187777876853943, loss=1.1041511297225952
test: epoch 10, loss 1.5078376531600952, acc=0.39444443583488464, loss=1.5078376531600952
train: epoch 11, loss 1.0475752353668213, acc=0.5369444489479065, loss=1.0475752353668213
test: epoch 11, loss 1.3723680973052979, acc=0.4027777910232544, loss=1.3723680973052979
train: epoch 12, loss 0.9959878325462341, acc=0.5547778010368347, loss=0.9959878325462341
test: epoch 12, loss 1.4210618734359741, acc=0.4333333373069763, loss=1.4210618734359741
train: epoch 13, loss 0.9692919850349426, acc=0.5644999742507935, loss=0.9692919850349426
test: epoch 13, loss 1.3964039087295532, acc=0.4416666626930237, loss=1.3964039087295532
train: epoch 14, loss 0.9915883541107178, acc=0.5657222270965576, loss=0.9915883541107178
test: epoch 14, loss 1.2837562561035156, acc=0.4444444477558136, loss=1.2837562561035156
train: epoch 15, loss 0.9484595656394958, acc=0.5715000033378601, loss=0.9484595656394958
test: epoch 15, loss 1.4665993452072144, acc=0.4333333373069763, loss=1.4665993452072144
train: epoch 16, loss 0.950553834438324, acc=0.5755555629730225, loss=0.950553834438324
test: epoch 16, loss 1.2821242809295654, acc=0.4333333373069763, loss=1.2821242809295654
train: epoch 17, loss 0.9447134733200073, acc=0.5828333497047424, loss=0.9447134733200073
test: epoch 17, loss 1.3551939725875854, acc=0.4444444477558136, loss=1.3551939725875854
train: epoch 18, loss 0.9447517395019531, acc=0.589388906955719, loss=0.9447517395019531
test: epoch 18, loss 1.3721541166305542, acc=0.4444444477558136, loss=1.3721541166305542
train: epoch 19, loss 0.9153794646263123, acc=0.6083333492279053, loss=0.9153794646263123
test: epoch 19, loss 1.402127742767334, acc=0.4444444477558136, loss=1.402127742767334
train: epoch 20, loss 0.9049016833305359, acc=0.6112222075462341, loss=0.9049016833305359
test: epoch 20, loss 1.4343410730361938, acc=0.4444444477558136, loss=1.4343410730361938
train: epoch 21, loss 0.8781015276908875, acc=0.6201666593551636, loss=0.8781015276908875
test: epoch 21, loss 1.4180129766464233, acc=0.4416666626930237, loss=1.4180129766464233
train: epoch 22, loss 0.8841509819030762, acc=0.6183888912200928, loss=0.8841509819030762
test: epoch 22, loss 1.4583218097686768, acc=0.43888887763023376, loss=1.4583218097686768
train: epoch 23, loss 0.894097089767456, acc=0.6132222414016724, loss=0.894097089767456
test: epoch 23, loss 1.4614495038986206, acc=0.4138889014720917, loss=1.4614495038986206
train: epoch 24, loss 0.8725460171699524, acc=0.6193333268165588, loss=0.8725460171699524
test: epoch 24, loss 1.4240614175796509, acc=0.4305555522441864, loss=1.4240614175796509
train: epoch 25, loss 0.8687254786491394, acc=0.6162222027778625, loss=0.8687254786491394
test: epoch 25, loss 1.32756507396698, acc=0.4472222328186035, loss=1.32756507396698
train: epoch 26, loss 0.8584581017494202, acc=0.6246111392974854, loss=0.8584581017494202
test: epoch 26, loss 1.2369143962860107, acc=0.47777777910232544, loss=1.2369143962860107
train: epoch 27, loss 0.8509857654571533, acc=0.6318888664245605, loss=0.8509857654571533
test: epoch 27, loss 1.3290903568267822, acc=0.48055556416511536, loss=1.3290903568267822
train: epoch 28, loss 0.8425460457801819, acc=0.6421666741371155, loss=0.8425460457801819
test: epoch 28, loss 1.3939008712768555, acc=0.4722222089767456, loss=1.3939008712768555
train: epoch 29, loss 0.8198570609092712, acc=0.6396666765213013, loss=0.8198570609092712
test: epoch 29, loss 1.4129447937011719, acc=0.4472222328186035, loss=1.4129447937011719
train: epoch 30, loss 0.8188546299934387, acc=0.6384444236755371, loss=0.8188546299934387
test: epoch 30, loss 1.286754846572876, acc=0.48055556416511536, loss=1.286754846572876
train: epoch 31, loss 0.8182659149169922, acc=0.6409444212913513, loss=0.8182659149169922
test: epoch 31, loss 1.353755235671997, acc=0.48055556416511536, loss=1.353755235671997
train: epoch 32, loss 0.8112127780914307, acc=0.6400555372238159, loss=0.8112127780914307
test: epoch 32, loss 1.2779440879821777, acc=0.4833333194255829, loss=1.2779440879821777
train: epoch 33, loss 0.8241525292396545, acc=0.6359444260597229, loss=0.8241525292396545
test: epoch 33, loss 1.2077009677886963, acc=0.48055556416511536, loss=1.2077009677886963
train: epoch 34, loss 0.8309748768806458, acc=0.6296666860580444, loss=0.8309748768806458
test: epoch 34, loss 1.2834581136703491, acc=0.4833333194255829, loss=1.2834581136703491
train: epoch 35, loss 0.8023802638053894, acc=0.636388897895813, loss=0.8023802638053894
test: epoch 35, loss 1.259247064590454, acc=0.48055556416511536, loss=1.259247064590454
train: epoch 36, loss 0.807068943977356, acc=0.6432777643203735, loss=0.807068943977356
test: epoch 36, loss 1.2928930521011353, acc=0.4888888895511627, loss=1.2928930521011353
train: epoch 37, loss 0.8152722716331482, acc=0.6426666378974915, loss=0.8152722716331482
test: epoch 37, loss 1.3676475286483765, acc=0.4833333194255829, loss=1.3676475286483765
train: epoch 38, loss 0.78713458776474, acc=0.652999997138977, loss=0.78713458776474
test: epoch 38, loss 1.495885968208313, acc=0.4833333194255829, loss=1.495885968208313
train: epoch 39, loss 0.7965929508209229, acc=0.6470000147819519, loss=0.7965929508209229
test: epoch 39, loss 1.3670672178268433, acc=0.48055556416511536, loss=1.3670672178268433
train: epoch 40, loss 0.787241518497467, acc=0.6521666646003723, loss=0.787241518497467
test: epoch 40, loss 1.3384184837341309, acc=0.48055556416511536, loss=1.3384184837341309
train: epoch 41, loss 0.7694423198699951, acc=0.6624444723129272, loss=0.7694423198699951
test: epoch 41, loss 1.3406062126159668, acc=0.4833333194255829, loss=1.3406062126159668
train: epoch 42, loss 0.7693167328834534, acc=0.6652222275733948, loss=0.7693167328834534
test: epoch 42, loss 1.3073111772537231, acc=0.48055556416511536, loss=1.3073111772537231
train: epoch 43, loss 0.8031949996948242, acc=0.6517778038978577, loss=0.8031949996948242
test: epoch 43, loss 1.436949372291565, acc=0.4749999940395355, loss=1.436949372291565
train: epoch 44, loss 0.7505196332931519, acc=0.6629999876022339, loss=0.7505196332931519
test: epoch 44, loss 1.4201595783233643, acc=0.48055556416511536, loss=1.4201595783233643
train: epoch 45, loss 0.7510896921157837, acc=0.6642777919769287, loss=0.7510896921157837
test: epoch 45, loss 1.3806729316711426, acc=0.4749999940395355, loss=1.3806729316711426
train: epoch 46, loss 0.7373830676078796, acc=0.6753333210945129, loss=0.7373830676078796
test: epoch 46, loss 1.2595187425613403, acc=0.48055556416511536, loss=1.2595187425613403
train: epoch 47, loss 0.7201881408691406, acc=0.6817777752876282, loss=0.7201881408691406
test: epoch 47, loss 1.2693864107131958, acc=0.48055556416511536, loss=1.2693864107131958
train: epoch 48, loss 0.7146322727203369, acc=0.6866666674613953, loss=0.7146322727203369
test: epoch 48, loss 1.4614266157150269, acc=0.4749999940395355, loss=1.4614266157150269
train: epoch 49, loss 0.7063321471214294, acc=0.6898888945579529, loss=0.7063321471214294
test: epoch 49, loss 1.3760278224945068, acc=0.4749999940395355, loss=1.3760278224945068
train: epoch 50, loss 0.709206223487854, acc=0.691777765750885, loss=0.709206223487854
test: epoch 50, loss 1.5219862461090088, acc=0.47777777910232544, loss=1.5219862461090088
train: epoch 51, loss 0.6928988099098206, acc=0.6959999799728394, loss=0.6928988099098206
test: epoch 51, loss 1.657449722290039, acc=0.4611110985279083, loss=1.657449722290039
train: epoch 52, loss 0.7008987069129944, acc=0.6940000057220459, loss=0.7008987069129944
test: epoch 52, loss 1.3930244445800781, acc=0.47777777910232544, loss=1.3930244445800781
train: epoch 53, loss 0.7002310752868652, acc=0.6948888897895813, loss=0.7002310752868652
test: epoch 53, loss 1.5518625974655151, acc=0.48055556416511536, loss=1.5518625974655151
train: epoch 54, loss 0.7161734104156494, acc=0.6851111054420471, loss=0.7161734104156494
test: epoch 54, loss 1.5268324613571167, acc=0.47777777910232544, loss=1.5268324613571167
train: epoch 55, loss 0.6962887644767761, acc=0.6947222352027893, loss=0.6962887644767761
test: epoch 55, loss 1.5811775922775269, acc=0.47777777910232544, loss=1.5811775922775269
train: epoch 56, loss 0.7085084915161133, acc=0.6934999823570251, loss=0.7085084915161133
test: epoch 56, loss 1.4855960607528687, acc=0.4694444537162781, loss=1.4855960607528687
train: epoch 57, loss 0.6760003566741943, acc=0.7065555453300476, loss=0.6760003566741943
test: epoch 57, loss 1.6051958799362183, acc=0.4555555582046509, loss=1.6051958799362183
train: epoch 58, loss 0.6743832230567932, acc=0.7087777853012085, loss=0.6743832230567932
test: epoch 58, loss 1.6067054271697998, acc=0.47777777910232544, loss=1.6067054271697998
train: epoch 59, loss 0.6705843806266785, acc=0.7077777981758118, loss=0.6705843806266785
test: epoch 59, loss 1.3906662464141846, acc=0.4861111044883728, loss=1.3906662464141846
train: epoch 60, loss 0.6507816910743713, acc=0.7195000052452087, loss=0.6507816910743713
test: epoch 60, loss 1.3860493898391724, acc=0.5472221970558167, loss=1.3860493898391724
train: epoch 61, loss 0.6317657828330994, acc=0.7219444513320923, loss=0.6317657828330994
test: epoch 61, loss 1.1695696115493774, acc=0.574999988079071, loss=1.1695696115493774
train: epoch 62, loss 0.6325352787971497, acc=0.723111093044281, loss=0.6325352787971497
test: epoch 62, loss 1.2883106470108032, acc=0.5611110925674438, loss=1.2883106470108032
train: epoch 63, loss 0.6115169525146484, acc=0.7203888893127441, loss=0.6115169525146484
test: epoch 63, loss 1.166572093963623, acc=0.5861111283302307, loss=1.166572093963623
train: epoch 64, loss 0.6111360192298889, acc=0.722777783870697, loss=0.6111360192298889
test: epoch 64, loss 1.1135025024414062, acc=0.5722222328186035, loss=1.1135025024414062
train: epoch 65, loss 0.6103368997573853, acc=0.72688889503479, loss=0.6103368997573853
test: epoch 65, loss 1.165062665939331, acc=0.5861111283302307, loss=1.165062665939331
train: epoch 66, loss 0.5982120633125305, acc=0.7318888902664185, loss=0.5982120633125305
test: epoch 66, loss 1.2805474996566772, acc=0.5861111283302307, loss=1.2805474996566772
train: epoch 67, loss 0.5979425311088562, acc=0.7297222018241882, loss=0.5979425311088562
test: epoch 67, loss 1.2994266748428345, acc=0.5805555582046509, loss=1.2994266748428345
train: epoch 68, loss 0.5893517136573792, acc=0.7321666479110718, loss=0.5893517136573792
test: epoch 68, loss 1.0482302904129028, acc=0.6166666746139526, loss=1.0482302904129028
train: epoch 69, loss 0.5955130457878113, acc=0.734333336353302, loss=0.5955130457878113
test: epoch 69, loss 1.0392709970474243, acc=0.6277777552604675, loss=1.0392709970474243
train: epoch 70, loss 0.5739779472351074, acc=0.7415555715560913, loss=0.5739779472351074
test: epoch 70, loss 1.1188567876815796, acc=0.6277777552604675, loss=1.1188567876815796
train: epoch 71, loss 0.5603541731834412, acc=0.7450000047683716, loss=0.5603541731834412
test: epoch 71, loss 1.089719295501709, acc=0.6222222447395325, loss=1.089719295501709
train: epoch 72, loss 0.5989987254142761, acc=0.731333315372467, loss=0.5989987254142761
test: epoch 72, loss 1.0348682403564453, acc=0.625, loss=1.0348682403564453
train: epoch 73, loss 0.573547899723053, acc=0.738611102104187, loss=0.573547899723053
test: epoch 73, loss 1.1127136945724487, acc=0.6138888597488403, loss=1.1127136945724487
train: epoch 74, loss 0.5857114791870117, acc=0.7383888959884644, loss=0.5857114791870117
test: epoch 74, loss 1.242740273475647, acc=0.6194444298744202, loss=1.242740273475647
train: epoch 75, loss 0.5804301500320435, acc=0.7395555377006531, loss=0.5804301500320435
test: epoch 75, loss 1.008354663848877, acc=0.6277777552604675, loss=1.008354663848877
train: epoch 76, loss 0.5437795519828796, acc=0.7511110901832581, loss=0.5437795519828796
test: epoch 76, loss 1.06283438205719, acc=0.6277777552604675, loss=1.06283438205719
train: epoch 77, loss 0.5589543581008911, acc=0.7452777624130249, loss=0.5589543581008911
test: epoch 77, loss 1.0341609716415405, acc=0.6277777552604675, loss=1.0341609716415405
train: epoch 78, loss 0.5729455947875977, acc=0.7419999837875366, loss=0.5729455947875977
test: epoch 78, loss 1.0066616535186768, acc=0.6222222447395325, loss=1.0066616535186768
train: epoch 79, loss 0.551898717880249, acc=0.7476666569709778, loss=0.551898717880249
test: epoch 79, loss 1.0452959537506104, acc=0.6277777552604675, loss=1.0452959537506104
train: epoch 80, loss 0.5606430768966675, acc=0.7461110949516296, loss=0.5606430768966675
test: epoch 80, loss 1.1343992948532104, acc=0.6277777552604675, loss=1.1343992948532104
train: epoch 81, loss 0.5553441643714905, acc=0.7472777962684631, loss=0.5553441643714905
test: epoch 81, loss 1.0134689807891846, acc=0.625, loss=1.0134689807891846
train: epoch 82, loss 0.5898584127426147, acc=0.741611123085022, loss=0.5898584127426147
test: epoch 82, loss 1.0367145538330078, acc=0.625, loss=1.0367145538330078
train: epoch 83, loss 0.5570574402809143, acc=0.7467222213745117, loss=0.5570574402809143
test: epoch 83, loss 1.172480821609497, acc=0.625, loss=1.172480821609497
train: epoch 84, loss 0.5466733574867249, acc=0.7493888735771179, loss=0.5466733574867249
test: epoch 84, loss 1.1408768892288208, acc=0.625, loss=1.1408768892288208
train: epoch 85, loss 0.5359408855438232, acc=0.754277765750885, loss=0.5359408855438232
test: epoch 85, loss 0.988581120967865, acc=0.6305555701255798, loss=0.988581120967865
train: epoch 86, loss 0.5504319667816162, acc=0.7523333430290222, loss=0.5504319667816162
test: epoch 86, loss 1.321481466293335, acc=0.6138888597488403, loss=1.321481466293335
train: epoch 87, loss 0.5440617799758911, acc=0.7517222166061401, loss=0.5440617799758911
test: epoch 87, loss 1.082606554031372, acc=0.6277777552604675, loss=1.082606554031372
train: epoch 88, loss 0.547944962978363, acc=0.7500555515289307, loss=0.547944962978363
test: epoch 88, loss 1.1412532329559326, acc=0.6194444298744202, loss=1.1412532329559326
train: epoch 89, loss 0.5703403949737549, acc=0.7415000200271606, loss=0.5703403949737549
test: epoch 89, loss 1.1485249996185303, acc=0.6222222447395325, loss=1.1485249996185303
train: epoch 90, loss 0.5541019439697266, acc=0.7476666569709778, loss=0.5541019439697266
test: epoch 90, loss 1.0923446416854858, acc=0.6222222447395325, loss=1.0923446416854858
train: epoch 91, loss 0.5513668060302734, acc=0.7461110949516296, loss=0.5513668060302734
test: epoch 91, loss 1.0938467979431152, acc=0.625, loss=1.0938467979431152
train: epoch 92, loss 0.5504963397979736, acc=0.7473333477973938, loss=0.5504963397979736
test: epoch 92, loss 1.1092594861984253, acc=0.625, loss=1.1092594861984253
train: epoch 93, loss 0.5684314966201782, acc=0.7380555272102356, loss=0.5684314966201782
test: epoch 93, loss 1.147733211517334, acc=0.6194444298744202, loss=1.147733211517334
train: epoch 94, loss 0.5548883676528931, acc=0.7480555772781372, loss=0.5548883676528931
test: epoch 94, loss 1.13975989818573, acc=0.6194444298744202, loss=1.13975989818573
train: epoch 95, loss 0.5385134220123291, acc=0.7490555644035339, loss=0.5385134220123291
test: epoch 95, loss 1.1392799615859985, acc=0.6194444298744202, loss=1.1392799615859985
train: epoch 96, loss 0.5444560647010803, acc=0.7503888607025146, loss=0.5444560647010803
test: epoch 96, loss 1.180600643157959, acc=0.6222222447395325, loss=1.180600643157959
train: epoch 97, loss 0.5428228974342346, acc=0.7551666498184204, loss=0.5428228974342346
test: epoch 97, loss 1.1101300716400146, acc=0.6277777552604675, loss=1.1101300716400146
train: epoch 98, loss 0.5207847952842712, acc=0.7608888745307922, loss=0.5207847952842712
test: epoch 98, loss 1.0716187953948975, acc=0.6527777910232544, loss=1.0716187953948975
train: epoch 99, loss 0.5156741738319397, acc=0.7666666507720947, loss=0.5156741738319397
test: epoch 99, loss 0.9267333149909973, acc=0.6527777910232544, loss=0.9267333149909973
train: epoch 100, loss 0.5044634938240051, acc=0.7670555710792542, loss=0.5044634938240051
test: epoch 100, loss 1.1515474319458008, acc=0.6527777910232544, loss=1.1515474319458008
train: epoch 101, loss 0.5391227602958679, acc=0.7638888955116272, loss=0.5391227602958679
test: epoch 101, loss 0.9797938466072083, acc=0.6527777910232544, loss=0.9797938466072083
train: epoch 102, loss 0.5222310423851013, acc=0.7672222256660461, loss=0.5222310423851013
test: epoch 102, loss 0.9839989542961121, acc=0.644444465637207, loss=0.9839989542961121
train: epoch 103, loss 0.5186984539031982, acc=0.7693889141082764, loss=0.5186984539031982
test: epoch 103, loss 1.0259356498718262, acc=0.6527777910232544, loss=1.0259356498718262
train: epoch 104, loss 0.5318933129310608, acc=0.769944429397583, loss=0.5318933129310608
test: epoch 104, loss 1.0374712944030762, acc=0.644444465637207, loss=1.0374712944030762
train: epoch 105, loss 0.5290366411209106, acc=0.7662777900695801, loss=0.5290366411209106
test: epoch 105, loss 1.1934236288070679, acc=0.6361111402511597, loss=1.1934236288070679
train: epoch 106, loss 0.5418288111686707, acc=0.7683888673782349, loss=0.5418288111686707
test: epoch 106, loss 1.0024360418319702, acc=0.6527777910232544, loss=1.0024360418319702
train: epoch 107, loss 0.5072170495986938, acc=0.7722777724266052, loss=0.5072170495986938
test: epoch 107, loss 1.0515165328979492, acc=0.6527777910232544, loss=1.0515165328979492
train: epoch 108, loss 0.4809530973434448, acc=0.7803333401679993, loss=0.4809530973434448
test: epoch 108, loss 1.046518325805664, acc=0.6472222208976746, loss=1.046518325805664
train: epoch 109, loss 0.49504202604293823, acc=0.7788888812065125, loss=0.49504202604293823
test: epoch 109, loss 1.1321791410446167, acc=0.6583333611488342, loss=1.1321791410446167
train: epoch 110, loss 0.5316562056541443, acc=0.7725555300712585, loss=0.5316562056541443
test: epoch 110, loss 1.0411022901535034, acc=0.6472222208976746, loss=1.0411022901535034
train: epoch 111, loss 0.5164511799812317, acc=0.773277759552002, loss=0.5164511799812317
test: epoch 111, loss 1.0741634368896484, acc=0.6555555462837219, loss=1.0741634368896484
train: epoch 112, loss 0.49901261925697327, acc=0.7762777805328369, loss=0.49901261925697327
test: epoch 112, loss 1.026667594909668, acc=0.6555555462837219, loss=1.026667594909668
train: epoch 113, loss 0.548715353012085, acc=0.7648888826370239, loss=0.548715353012085
test: epoch 113, loss 1.0264815092086792, acc=0.6499999761581421, loss=1.0264815092086792
train: epoch 114, loss 0.5094857215881348, acc=0.7731666564941406, loss=0.5094857215881348
test: epoch 114, loss 0.9915337562561035, acc=0.6499999761581421, loss=0.9915337562561035
train: epoch 115, loss 0.5501649379730225, acc=0.7651110887527466, loss=0.5501649379730225
test: epoch 115, loss 0.844104528427124, acc=0.6666666865348816, loss=0.844104528427124
train: epoch 116, loss 0.5181152820587158, acc=0.770111083984375, loss=0.5181152820587158
test: epoch 116, loss 0.9299655556678772, acc=0.675000011920929, loss=0.9299655556678772
train: epoch 117, loss 0.5121097564697266, acc=0.7710000276565552, loss=0.5121097564697266
test: epoch 117, loss 0.999089241027832, acc=0.6722221970558167, loss=0.999089241027832
train: epoch 118, loss 0.5121051669120789, acc=0.7698333263397217, loss=0.5121051669120789
test: epoch 118, loss 0.8867790699005127, acc=0.6777777671813965, loss=0.8867790699005127
train: epoch 119, loss 0.5057180523872375, acc=0.7721111178398132, loss=0.5057180523872375
test: epoch 119, loss 0.9379177689552307, acc=0.6694444417953491, loss=0.9379177689552307
train: epoch 120, loss 0.5044717788696289, acc=0.7748888731002808, loss=0.5044717788696289
test: epoch 120, loss 0.9921633005142212, acc=0.6722221970558167, loss=0.9921633005142212
train: epoch 121, loss 0.5046537518501282, acc=0.77311110496521, loss=0.5046537518501282
test: epoch 121, loss 0.9876176714897156, acc=0.675000011920929, loss=0.9876176714897156
train: epoch 122, loss 0.5017884969711304, acc=0.7764444351196289, loss=0.5017884969711304
test: epoch 122, loss 0.9408883452415466, acc=0.6805555820465088, loss=0.9408883452415466
train: epoch 123, loss 0.5084294080734253, acc=0.7762777805328369, loss=0.5084294080734253
test: epoch 123, loss 0.8100959062576294, acc=0.6888889074325562, loss=0.8100959062576294
train: epoch 124, loss 0.49537304043769836, acc=0.7765555381774902, loss=0.49537304043769836
test: epoch 124, loss 0.9273398518562317, acc=0.6833333373069763, loss=0.9273398518562317
train: epoch 125, loss 0.5355563759803772, acc=0.7683333158493042, loss=0.5355563759803772
test: epoch 125, loss 0.9793501496315002, acc=0.6777777671813965, loss=0.9793501496315002
train: epoch 126, loss 0.5078401565551758, acc=0.7749999761581421, loss=0.5078401565551758
test: epoch 126, loss 0.7862274646759033, acc=0.7083333134651184, loss=0.7862274646759033
train: epoch 127, loss 0.5041320323944092, acc=0.7686111330986023, loss=0.5041320323944092
test: epoch 127, loss 0.7143178582191467, acc=0.7083333134651184, loss=0.7143178582191467
train: epoch 128, loss 0.4914553463459015, acc=0.7723333239555359, loss=0.4914553463459015
test: epoch 128, loss 0.7615202069282532, acc=0.7138888835906982, loss=0.7615202069282532
train: epoch 129, loss 0.47097063064575195, acc=0.7764444351196289, loss=0.47097063064575195
test: epoch 129, loss 0.773292064666748, acc=0.7111111283302307, loss=0.773292064666748
train: epoch 130, loss 0.47201085090637207, acc=0.7752777934074402, loss=0.47201085090637207
test: epoch 130, loss 0.6205991506576538, acc=0.730555534362793, loss=0.6205991506576538
train: epoch 131, loss 0.47406402230262756, acc=0.7717777490615845, loss=0.47406402230262756
test: epoch 131, loss 0.6778376698493958, acc=0.730555534362793, loss=0.6778376698493958
train: epoch 132, loss 0.4503882825374603, acc=0.7768333554267883, loss=0.4503882825374603
test: epoch 132, loss 0.6371035575866699, acc=0.7333333492279053, loss=0.6371035575866699
train: epoch 133, loss 0.452009379863739, acc=0.7756111025810242, loss=0.452009379863739
test: epoch 133, loss 0.6110995411872864, acc=0.7333333492279053, loss=0.6110995411872864
train: epoch 134, loss 0.4693024754524231, acc=0.7739444375038147, loss=0.4693024754524231
test: epoch 134, loss 0.6228854656219482, acc=0.7333333492279053, loss=0.6228854656219482
train: epoch 135, loss 0.4575962424278259, acc=0.7750555276870728, loss=0.4575962424278259
test: epoch 135, loss 0.6377121806144714, acc=0.7333333492279053, loss=0.6377121806144714
train: epoch 136, loss 0.4705272316932678, acc=0.7722222208976746, loss=0.4705272316932678
test: epoch 136, loss 0.6409871578216553, acc=0.7277777791023254, loss=0.6409871578216553
train: epoch 137, loss 0.5301312208175659, acc=0.7566666603088379, loss=0.5301312208175659
test: epoch 137, loss 0.6780745983123779, acc=0.7111111283302307, loss=0.6780745983123779
train: epoch 138, loss 0.5250661373138428, acc=0.7565000057220459, loss=0.5250661373138428
test: epoch 138, loss 0.684790313243866, acc=0.7222222089767456, loss=0.684790313243866
train: epoch 139, loss 0.49960267543792725, acc=0.7611666917800903, loss=0.49960267543792725
test: epoch 139, loss 0.6427980661392212, acc=0.7250000238418579, loss=0.6427980661392212
train: epoch 140, loss 0.4896538555622101, acc=0.7687222361564636, loss=0.4896538555622101
test: epoch 140, loss 0.6593981385231018, acc=0.7250000238418579, loss=0.6593981385231018
train: epoch 141, loss 0.4720706343650818, acc=0.7727222442626953, loss=0.4720706343650818
test: epoch 141, loss 0.6385605931282043, acc=0.7222222089767456, loss=0.6385605931282043
train: epoch 142, loss 0.49088799953460693, acc=0.7743333578109741, loss=0.49088799953460693
test: epoch 142, loss 0.5925665497779846, acc=0.7277777791023254, loss=0.5925665497779846
train: epoch 143, loss 0.45615848898887634, acc=0.7753333449363708, loss=0.45615848898887634
test: epoch 143, loss 0.6074355840682983, acc=0.7333333492279053, loss=0.6074355840682983
train: epoch 144, loss 0.43834632635116577, acc=0.7822222113609314, loss=0.43834632635116577
test: epoch 144, loss 0.6413465738296509, acc=0.7388888597488403, loss=0.6413465738296509
train: epoch 145, loss 0.4090600907802582, acc=0.7928333282470703, loss=0.4090600907802582
test: epoch 145, loss 0.6184935569763184, acc=0.7416666746139526, loss=0.6184935569763184
train: epoch 146, loss 0.39823344349861145, acc=0.7965555787086487, loss=0.39823344349861145
test: epoch 146, loss 0.6086791157722473, acc=0.7416666746139526, loss=0.6086791157722473
train: epoch 147, loss 0.39578977227211, acc=0.7995555400848389, loss=0.39578977227211
test: epoch 147, loss 0.6508210301399231, acc=0.7416666746139526, loss=0.6508210301399231
train: epoch 148, loss 0.45232540369033813, acc=0.7864444255828857, loss=0.45232540369033813
test: epoch 148, loss 0.7161039710044861, acc=0.6916666626930237, loss=0.7161039710044861
train: epoch 149, loss 0.49198219180107117, acc=0.7722222208976746, loss=0.49198219180107117
test: epoch 149, loss 0.6399769186973572, acc=0.7277777791023254, loss=0.6399769186973572
train: epoch 150, loss 0.4492120146751404, acc=0.7868333458900452, loss=0.4492120146751404
test: epoch 150, loss 0.6498882174491882, acc=0.7361111044883728, loss=0.6498882174491882
