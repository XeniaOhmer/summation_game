# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.99", "--one_hot=true", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=2010209565, receiver_embed_dim=64, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.1166014671325684, acc=0.0985555574297905, loss=3.1166014671325684
test: epoch 1, loss 3.4240407943725586, acc=0.11388888955116272, loss=3.4240407943725586
train: epoch 2, loss 1.699182391166687, acc=0.33844444155693054, loss=1.699182391166687
test: epoch 2, loss 3.1884899139404297, acc=0.15833333134651184, loss=3.1884899139404297
train: epoch 3, loss 1.3280057907104492, acc=0.4658888876438141, loss=1.3280057907104492
test: epoch 3, loss 3.2465221881866455, acc=0.15833333134651184, loss=3.2465221881866455
train: epoch 4, loss 1.1342347860336304, acc=0.5535555481910706, loss=1.1342347860336304
test: epoch 4, loss 3.217654228210449, acc=0.19722221791744232, loss=3.217654228210449
train: epoch 5, loss 1.0065369606018066, acc=0.6090555787086487, loss=1.0065369606018066
test: epoch 5, loss 2.8455095291137695, acc=0.21666666865348816, loss=2.8455095291137695
train: epoch 6, loss 0.9156557321548462, acc=0.6483888626098633, loss=0.9156557321548462
test: epoch 6, loss 3.282329797744751, acc=0.18611110746860504, loss=3.282329797744751
train: epoch 7, loss 0.842451810836792, acc=0.6845555305480957, loss=0.842451810836792
test: epoch 7, loss 3.1953275203704834, acc=0.2083333283662796, loss=3.1953275203704834
train: epoch 8, loss 0.7784978151321411, acc=0.7014999985694885, loss=0.7784978151321411
test: epoch 8, loss 3.2375142574310303, acc=0.21111111342906952, loss=3.2375142574310303
train: epoch 9, loss 0.7306603789329529, acc=0.7290555834770203, loss=0.7306603789329529
test: epoch 9, loss 2.7833638191223145, acc=0.20277777314186096, loss=2.7833638191223145
train: epoch 10, loss 0.6882103085517883, acc=0.7475555539131165, loss=0.6882103085517883
test: epoch 10, loss 2.8928627967834473, acc=0.21666666865348816, loss=2.8928627967834473
train: epoch 11, loss 0.6476696729660034, acc=0.7593888640403748, loss=0.6476696729660034
test: epoch 11, loss 2.616755962371826, acc=0.23055554926395416, loss=2.616755962371826
train: epoch 12, loss 0.6273952126502991, acc=0.7649999856948853, loss=0.6273952126502991
test: epoch 12, loss 2.5321261882781982, acc=0.22499999403953552, loss=2.5321261882781982
train: epoch 13, loss 0.6094534993171692, acc=0.7764444351196289, loss=0.6094534993171692
test: epoch 13, loss 2.3704659938812256, acc=0.24722221493721008, loss=2.3704659938812256
train: epoch 14, loss 0.5862424969673157, acc=0.7858333587646484, loss=0.5862424969673157
test: epoch 14, loss 2.2975220680236816, acc=0.25555557012557983, loss=2.2975220680236816
train: epoch 15, loss 0.5537564158439636, acc=0.7973333597183228, loss=0.5537564158439636
test: epoch 15, loss 2.053807258605957, acc=0.29722222685813904, loss=2.053807258605957
train: epoch 16, loss 0.5299072265625, acc=0.8055555820465088, loss=0.5299072265625
test: epoch 16, loss 2.0664687156677246, acc=0.2750000059604645, loss=2.0664687156677246
train: epoch 17, loss 0.5174599289894104, acc=0.8168333172798157, loss=0.5174599289894104
test: epoch 17, loss 1.918279767036438, acc=0.32499998807907104, loss=1.918279767036438
train: epoch 18, loss 0.5019350051879883, acc=0.8141666650772095, loss=0.5019350051879883
test: epoch 18, loss 2.0799953937530518, acc=0.24444444477558136, loss=2.0799953937530518
train: epoch 19, loss 0.5008119940757751, acc=0.8228333592414856, loss=0.5008119940757751
test: epoch 19, loss 1.9776774644851685, acc=0.29722222685813904, loss=1.9776774644851685
train: epoch 20, loss 0.4654047191143036, acc=0.8308333158493042, loss=0.4654047191143036
test: epoch 20, loss 1.9905803203582764, acc=0.33888888359069824, loss=1.9905803203582764
train: epoch 21, loss 0.45675671100616455, acc=0.839555561542511, loss=0.45675671100616455
test: epoch 21, loss 1.9285285472869873, acc=0.32499998807907104, loss=1.9285285472869873
train: epoch 22, loss 0.44711679220199585, acc=0.8422222137451172, loss=0.44711679220199585
test: epoch 22, loss 1.9302846193313599, acc=0.3583333194255829, loss=1.9302846193313599
train: epoch 23, loss 0.44639959931373596, acc=0.8364999890327454, loss=0.44639959931373596
test: epoch 23, loss 1.7913978099822998, acc=0.4000000059604645, loss=1.7913978099822998
train: epoch 24, loss 0.42560383677482605, acc=0.8467222452163696, loss=0.42560383677482605
test: epoch 24, loss 1.7362356185913086, acc=0.3499999940395355, loss=1.7362356185913086
train: epoch 25, loss 0.4170277416706085, acc=0.8527777791023254, loss=0.4170277416706085
test: epoch 25, loss 1.780215859413147, acc=0.3499999940395355, loss=1.780215859413147
train: epoch 26, loss 0.4192003905773163, acc=0.8517777919769287, loss=0.4192003905773163
test: epoch 26, loss 1.6786702871322632, acc=0.38333332538604736, loss=1.6786702871322632
train: epoch 27, loss 0.39942827820777893, acc=0.856333315372467, loss=0.39942827820777893
test: epoch 27, loss 1.6520329713821411, acc=0.4000000059604645, loss=1.6520329713821411
train: epoch 28, loss 0.39992475509643555, acc=0.8577222228050232, loss=0.39992475509643555
test: epoch 28, loss 1.6001583337783813, acc=0.4055555462837219, loss=1.6001583337783813
train: epoch 29, loss 0.3886446952819824, acc=0.8641666769981384, loss=0.3886446952819824
test: epoch 29, loss 1.6675374507904053, acc=0.38333332538604736, loss=1.6675374507904053
train: epoch 30, loss 0.3718217611312866, acc=0.8688889145851135, loss=0.3718217611312866
test: epoch 30, loss 1.744512677192688, acc=0.3638888895511627, loss=1.744512677192688
train: epoch 31, loss 0.3886740207672119, acc=0.8611666560173035, loss=0.3886740207672119
test: epoch 31, loss 1.6569883823394775, acc=0.36666667461395264, loss=1.6569883823394775
train: epoch 32, loss 0.3633231520652771, acc=0.8711110949516296, loss=0.3633231520652771
test: epoch 32, loss 1.522611141204834, acc=0.39444443583488464, loss=1.522611141204834
train: epoch 33, loss 0.35783320665359497, acc=0.8736666440963745, loss=0.35783320665359497
test: epoch 33, loss 1.5466387271881104, acc=0.39444443583488464, loss=1.5466387271881104
train: epoch 34, loss 0.35995155572891235, acc=0.8748888969421387, loss=0.35995155572891235
test: epoch 34, loss 1.6793010234832764, acc=0.375, loss=1.6793010234832764
train: epoch 35, loss 0.3667738139629364, acc=0.8722222447395325, loss=0.3667738139629364
test: epoch 35, loss 1.5469058752059937, acc=0.43888887763023376, loss=1.5469058752059937
train: epoch 36, loss 0.3399930000305176, acc=0.8818888664245605, loss=0.3399930000305176
test: epoch 36, loss 1.4061157703399658, acc=0.46388888359069824, loss=1.4061157703399658
train: epoch 37, loss 0.34126752614974976, acc=0.8811110854148865, loss=0.34126752614974976
test: epoch 37, loss 1.669274091720581, acc=0.4277777671813965, loss=1.669274091720581
train: epoch 38, loss 0.35443007946014404, acc=0.8764444589614868, loss=0.35443007946014404
test: epoch 38, loss 1.4403040409088135, acc=0.46388888359069824, loss=1.4403040409088135
train: epoch 39, loss 0.3258391320705414, acc=0.8831666707992554, loss=0.3258391320705414
test: epoch 39, loss 1.5918874740600586, acc=0.3888888955116272, loss=1.5918874740600586
train: epoch 40, loss 0.3127971589565277, acc=0.8893888592720032, loss=0.3127971589565277
test: epoch 40, loss 1.4267172813415527, acc=0.4611110985279083, loss=1.4267172813415527
train: epoch 41, loss 0.3324320912361145, acc=0.8839444518089294, loss=0.3324320912361145
test: epoch 41, loss 1.57120943069458, acc=0.43611112236976624, loss=1.57120943069458
train: epoch 42, loss 0.31739163398742676, acc=0.8904444575309753, loss=0.31739163398742676
test: epoch 42, loss 1.6570563316345215, acc=0.4749999940395355, loss=1.6570563316345215
train: epoch 43, loss 0.31132441759109497, acc=0.890666663646698, loss=0.31132441759109497
test: epoch 43, loss 1.5266900062561035, acc=0.43888887763023376, loss=1.5266900062561035
train: epoch 44, loss 0.3138875365257263, acc=0.8898888826370239, loss=0.3138875365257263
test: epoch 44, loss 1.4353190660476685, acc=0.5055555701255798, loss=1.4353190660476685
train: epoch 45, loss 0.30902475118637085, acc=0.8892222046852112, loss=0.30902475118637085
test: epoch 45, loss 1.4241218566894531, acc=0.4749999940395355, loss=1.4241218566894531
train: epoch 46, loss 0.32666388154029846, acc=0.8849444389343262, loss=0.32666388154029846
test: epoch 46, loss 1.4753855466842651, acc=0.4694444537162781, loss=1.4753855466842651
train: epoch 47, loss 0.3108992278575897, acc=0.8916666507720947, loss=0.3108992278575897
test: epoch 47, loss 1.504331111907959, acc=0.5027777552604675, loss=1.504331111907959
train: epoch 48, loss 0.2932053208351135, acc=0.8970555663108826, loss=0.2932053208351135
test: epoch 48, loss 1.3243902921676636, acc=0.5472221970558167, loss=1.3243902921676636
train: epoch 49, loss 0.3035433292388916, acc=0.8938888907432556, loss=0.3035433292388916
test: epoch 49, loss 1.2489420175552368, acc=0.5027777552604675, loss=1.2489420175552368
train: epoch 50, loss 0.3068222105503082, acc=0.8875555396080017, loss=0.3068222105503082
test: epoch 50, loss 1.323421835899353, acc=0.519444465637207, loss=1.323421835899353
train: epoch 51, loss 0.2874492406845093, acc=0.8971111178398132, loss=0.2874492406845093
test: epoch 51, loss 1.2419776916503906, acc=0.5083333253860474, loss=1.2419776916503906
train: epoch 52, loss 0.2853773236274719, acc=0.8918333053588867, loss=0.2853773236274719
test: epoch 52, loss 1.244395136833191, acc=0.5277777910232544, loss=1.244395136833191
train: epoch 53, loss 0.2977953851222992, acc=0.8914444446563721, loss=0.2977953851222992
test: epoch 53, loss 1.407615065574646, acc=0.48055556416511536, loss=1.407615065574646
train: epoch 54, loss 0.30142658948898315, acc=0.8916110992431641, loss=0.30142658948898315
test: epoch 54, loss 1.3444914817810059, acc=0.4694444537162781, loss=1.3444914817810059
train: epoch 55, loss 0.2863978147506714, acc=0.8955000042915344, loss=0.2863978147506714
test: epoch 55, loss 1.3521887063980103, acc=0.5111111402511597, loss=1.3521887063980103
train: epoch 56, loss 0.2857414782047272, acc=0.8962222337722778, loss=0.2857414782047272
test: epoch 56, loss 1.1373366117477417, acc=0.5916666388511658, loss=1.1373366117477417
train: epoch 57, loss 0.2923203110694885, acc=0.8971111178398132, loss=0.2923203110694885
test: epoch 57, loss 1.504247784614563, acc=0.4833333194255829, loss=1.504247784614563
train: epoch 58, loss 0.28617072105407715, acc=0.8976666927337646, loss=0.28617072105407715
test: epoch 58, loss 1.2276102304458618, acc=0.5333333611488342, loss=1.2276102304458618
train: epoch 59, loss 0.27699777483940125, acc=0.8966110944747925, loss=0.27699777483940125
test: epoch 59, loss 1.1704217195510864, acc=0.5333333611488342, loss=1.1704217195510864
train: epoch 60, loss 0.30039072036743164, acc=0.8961111307144165, loss=0.30039072036743164
test: epoch 60, loss 1.2291679382324219, acc=0.5277777910232544, loss=1.2291679382324219
train: epoch 61, loss 0.2934803366661072, acc=0.8952777981758118, loss=0.2934803366661072
test: epoch 61, loss 1.270398497581482, acc=0.5527777671813965, loss=1.270398497581482
train: epoch 62, loss 0.27808454632759094, acc=0.8983888626098633, loss=0.27808454632759094
test: epoch 62, loss 1.343428611755371, acc=0.5277777910232544, loss=1.343428611755371
train: epoch 63, loss 0.2764042317867279, acc=0.8964444398880005, loss=0.2764042317867279
test: epoch 63, loss 1.0077828168869019, acc=0.625, loss=1.0077828168869019
train: epoch 64, loss 0.2879326641559601, acc=0.9012222290039062, loss=0.2879326641559601
test: epoch 64, loss 1.1839042901992798, acc=0.5333333611488342, loss=1.1839042901992798
train: epoch 65, loss 0.2845003306865692, acc=0.8991110920906067, loss=0.2845003306865692
test: epoch 65, loss 1.196063756942749, acc=0.5638889074325562, loss=1.196063756942749
train: epoch 66, loss 0.26199617981910706, acc=0.9067777991294861, loss=0.26199617981910706
test: epoch 66, loss 1.1089447736740112, acc=0.5944444537162781, loss=1.1089447736740112
train: epoch 67, loss 0.27917563915252686, acc=0.8981666564941406, loss=0.27917563915252686
test: epoch 67, loss 1.050800085067749, acc=0.5583333373069763, loss=1.050800085067749
train: epoch 68, loss 0.26299506425857544, acc=0.9076111316680908, loss=0.26299506425857544
test: epoch 68, loss 1.1998324394226074, acc=0.5694444179534912, loss=1.1998324394226074
train: epoch 69, loss 0.27248260378837585, acc=0.9039999842643738, loss=0.27248260378837585
test: epoch 69, loss 1.3241873979568481, acc=0.574999988079071, loss=1.3241873979568481
train: epoch 70, loss 0.2620614767074585, acc=0.9038333296775818, loss=0.2620614767074585
test: epoch 70, loss 1.1475396156311035, acc=0.5527777671813965, loss=1.1475396156311035
train: epoch 71, loss 0.26959192752838135, acc=0.906499981880188, loss=0.26959192752838135
test: epoch 71, loss 1.0597877502441406, acc=0.6277777552604675, loss=1.0597877502441406
train: epoch 72, loss 0.2615216076374054, acc=0.9068333506584167, loss=0.2615216076374054
test: epoch 72, loss 1.1902211904525757, acc=0.5916666388511658, loss=1.1902211904525757
train: epoch 73, loss 0.25042861700057983, acc=0.909333348274231, loss=0.25042861700057983
test: epoch 73, loss 1.2581193447113037, acc=0.6222222447395325, loss=1.2581193447113037
train: epoch 74, loss 0.24857410788536072, acc=0.9108333587646484, loss=0.24857410788536072
test: epoch 74, loss 1.1377671957015991, acc=0.6472222208976746, loss=1.1377671957015991
train: epoch 75, loss 0.2572091817855835, acc=0.909166693687439, loss=0.2572091817855835
test: epoch 75, loss 1.190279483795166, acc=0.605555534362793, loss=1.190279483795166
train: epoch 76, loss 0.24800601601600647, acc=0.9114999771118164, loss=0.24800601601600647
test: epoch 76, loss 1.2140719890594482, acc=0.625, loss=1.2140719890594482
train: epoch 77, loss 0.2486935257911682, acc=0.9135555624961853, loss=0.2486935257911682
test: epoch 77, loss 1.0555751323699951, acc=0.6361111402511597, loss=1.0555751323699951
train: epoch 78, loss 0.24396972358226776, acc=0.9153888821601868, loss=0.24396972358226776
test: epoch 78, loss 0.9557828307151794, acc=0.6222222447395325, loss=0.9557828307151794
train: epoch 79, loss 0.2307521402835846, acc=0.9202777743339539, loss=0.2307521402835846
test: epoch 79, loss 1.0498695373535156, acc=0.6527777910232544, loss=1.0498695373535156
train: epoch 80, loss 0.24084964394569397, acc=0.9162777662277222, loss=0.24084964394569397
test: epoch 80, loss 0.9221925735473633, acc=0.6722221970558167, loss=0.9221925735473633
train: epoch 81, loss 0.23445455729961395, acc=0.9185000061988831, loss=0.23445455729961395
test: epoch 81, loss 0.9172810912132263, acc=0.6777777671813965, loss=0.9172810912132263
train: epoch 82, loss 0.21997225284576416, acc=0.924833357334137, loss=0.21997225284576416
test: epoch 82, loss 1.064839243888855, acc=0.644444465637207, loss=1.064839243888855
train: epoch 83, loss 0.23541460931301117, acc=0.9188888669013977, loss=0.23541460931301117
test: epoch 83, loss 1.0154767036437988, acc=0.6916666626930237, loss=1.0154767036437988
train: epoch 84, loss 0.23238228261470795, acc=0.9199444651603699, loss=0.23238228261470795
test: epoch 84, loss 0.9601301550865173, acc=0.6861110925674438, loss=0.9601301550865173
train: epoch 85, loss 0.22952021658420563, acc=0.9234444499015808, loss=0.22952021658420563
test: epoch 85, loss 0.8759592771530151, acc=0.6805555820465088, loss=0.8759592771530151
train: epoch 86, loss 0.2214362472295761, acc=0.9224444627761841, loss=0.2214362472295761
test: epoch 86, loss 0.8690677285194397, acc=0.7083333134651184, loss=0.8690677285194397
train: epoch 87, loss 0.2381884604692459, acc=0.9215555787086487, loss=0.2381884604692459
test: epoch 87, loss 0.8584502339363098, acc=0.7250000238418579, loss=0.8584502339363098
train: epoch 88, loss 0.21483318507671356, acc=0.9235555529594421, loss=0.21483318507671356
test: epoch 88, loss 0.9084705114364624, acc=0.6722221970558167, loss=0.9084705114364624
train: epoch 89, loss 0.23182488977909088, acc=0.9243333339691162, loss=0.23182488977909088
test: epoch 89, loss 1.0760316848754883, acc=0.6861110925674438, loss=1.0760316848754883
train: epoch 90, loss 0.22258582711219788, acc=0.9246666431427002, loss=0.22258582711219788
test: epoch 90, loss 0.8764394521713257, acc=0.6888889074325562, loss=0.8764394521713257
train: epoch 91, loss 0.20718641579151154, acc=0.9283888936042786, loss=0.20718641579151154
test: epoch 91, loss 0.7622494101524353, acc=0.7194444537162781, loss=0.7622494101524353
train: epoch 92, loss 0.21635471284389496, acc=0.9268333315849304, loss=0.21635471284389496
test: epoch 92, loss 0.7776440382003784, acc=0.7250000238418579, loss=0.7776440382003784
train: epoch 93, loss 0.20493414998054504, acc=0.9308333396911621, loss=0.20493414998054504
test: epoch 93, loss 0.7506888508796692, acc=0.7222222089767456, loss=0.7506888508796692
train: epoch 94, loss 0.20384250581264496, acc=0.9287222027778625, loss=0.20384250581264496
test: epoch 94, loss 0.7523412108421326, acc=0.7333333492279053, loss=0.7523412108421326
train: epoch 95, loss 0.2160060852766037, acc=0.9240555763244629, loss=0.2160060852766037
test: epoch 95, loss 0.709500789642334, acc=0.7222222089767456, loss=0.709500789642334
train: epoch 96, loss 0.20665043592453003, acc=0.9278888702392578, loss=0.20665043592453003
test: epoch 96, loss 0.6631993055343628, acc=0.7361111044883728, loss=0.6631993055343628
train: epoch 97, loss 0.2066403478384018, acc=0.9293888807296753, loss=0.2066403478384018
test: epoch 97, loss 0.8059440851211548, acc=0.7166666388511658, loss=0.8059440851211548
train: epoch 98, loss 0.20477573573589325, acc=0.9296666383743286, loss=0.20477573573589325
test: epoch 98, loss 0.7264308929443359, acc=0.75, loss=0.7264308929443359
train: epoch 99, loss 0.20927736163139343, acc=0.9270555377006531, loss=0.20927736163139343
test: epoch 99, loss 0.6494654417037964, acc=0.7638888955116272, loss=0.6494654417037964
train: epoch 100, loss 0.20845071971416473, acc=0.9265555739402771, loss=0.20845071971416473
test: epoch 100, loss 0.8072701692581177, acc=0.7361111044883728, loss=0.8072701692581177
train: epoch 101, loss 0.19589294493198395, acc=0.9319444298744202, loss=0.19589294493198395
test: epoch 101, loss 0.8191289305686951, acc=0.7416666746139526, loss=0.8191289305686951
train: epoch 102, loss 0.18589642643928528, acc=0.9325000047683716, loss=0.18589642643928528
test: epoch 102, loss 0.6154682636260986, acc=0.769444465637207, loss=0.6154682636260986
train: epoch 103, loss 0.19164791703224182, acc=0.9330000281333923, loss=0.19164791703224182
test: epoch 103, loss 0.6817035675048828, acc=0.7666666507720947, loss=0.6817035675048828
train: epoch 104, loss 0.19365307688713074, acc=0.9338333606719971, loss=0.19365307688713074
test: epoch 104, loss 0.7049789428710938, acc=0.75, loss=0.7049789428710938
train: epoch 105, loss 0.19793415069580078, acc=0.9316666722297668, loss=0.19793415069580078
test: epoch 105, loss 0.7644040584564209, acc=0.7527777552604675, loss=0.7644040584564209
train: epoch 106, loss 0.18436922132968903, acc=0.937833309173584, loss=0.18436922132968903
test: epoch 106, loss 0.7326499819755554, acc=0.7388888597488403, loss=0.7326499819755554
train: epoch 107, loss 0.17345228791236877, acc=0.9381666779518127, loss=0.17345228791236877
test: epoch 107, loss 0.6690018773078918, acc=0.769444465637207, loss=0.6690018773078918
train: epoch 108, loss 0.17958573997020721, acc=0.9375555515289307, loss=0.17958573997020721
test: epoch 108, loss 0.7500473260879517, acc=0.7611111402511597, loss=0.7500473260879517
train: epoch 109, loss 0.17350322008132935, acc=0.9383333325386047, loss=0.17350322008132935
test: epoch 109, loss 0.668550431728363, acc=0.7749999761581421, loss=0.668550431728363
train: epoch 110, loss 0.1763455718755722, acc=0.9372222423553467, loss=0.1763455718755722
test: epoch 110, loss 0.6985441446304321, acc=0.7833333611488342, loss=0.6985441446304321
train: epoch 111, loss 0.17090356349945068, acc=0.9402777552604675, loss=0.17090356349945068
test: epoch 111, loss 0.6013230085372925, acc=0.7861111164093018, loss=0.6013230085372925
train: epoch 112, loss 0.1712818294763565, acc=0.9374444484710693, loss=0.1712818294763565
test: epoch 112, loss 0.6497681736946106, acc=0.7888888716697693, loss=0.6497681736946106
train: epoch 113, loss 0.1749623566865921, acc=0.9396111369132996, loss=0.1749623566865921
test: epoch 113, loss 0.6529585123062134, acc=0.7749999761581421, loss=0.6529585123062134
train: epoch 114, loss 0.16411159932613373, acc=0.9404444694519043, loss=0.16411159932613373
test: epoch 114, loss 0.6855859756469727, acc=0.7527777552604675, loss=0.6855859756469727
train: epoch 115, loss 0.16364403069019318, acc=0.9396666884422302, loss=0.16364403069019318
test: epoch 115, loss 0.5502983927726746, acc=0.8138889074325562, loss=0.5502983927726746
train: epoch 116, loss 0.171641543507576, acc=0.941444456577301, loss=0.171641543507576
test: epoch 116, loss 0.6859907507896423, acc=0.7722222208976746, loss=0.6859907507896423
train: epoch 117, loss 0.15666496753692627, acc=0.9455000162124634, loss=0.15666496753692627
test: epoch 117, loss 0.596849262714386, acc=0.7888888716697693, loss=0.596849262714386
train: epoch 118, loss 0.1659332811832428, acc=0.9428333044052124, loss=0.1659332811832428
test: epoch 118, loss 0.513963520526886, acc=0.8138889074325562, loss=0.513963520526886
train: epoch 119, loss 0.16358686983585358, acc=0.9427222013473511, loss=0.16358686983585358
test: epoch 119, loss 0.525429368019104, acc=0.8111110925674438, loss=0.525429368019104
train: epoch 120, loss 0.16108475625514984, acc=0.9423888921737671, loss=0.16108475625514984
test: epoch 120, loss 0.6718772053718567, acc=0.8277778029441833, loss=0.6718772053718567
train: epoch 121, loss 0.154373437166214, acc=0.9421666860580444, loss=0.154373437166214
test: epoch 121, loss 0.589774489402771, acc=0.7861111164093018, loss=0.589774489402771
train: epoch 122, loss 0.15100844204425812, acc=0.9470555782318115, loss=0.15100844204425812
test: epoch 122, loss 0.5669291615486145, acc=0.7666666507720947, loss=0.5669291615486145
train: epoch 123, loss 0.15618152916431427, acc=0.9446666836738586, loss=0.15618152916431427
test: epoch 123, loss 0.6760920882225037, acc=0.8277778029441833, loss=0.6760920882225037
train: epoch 124, loss 0.14809930324554443, acc=0.9468888640403748, loss=0.14809930324554443
test: epoch 124, loss 0.614468514919281, acc=0.8055555820465088, loss=0.614468514919281
train: epoch 125, loss 0.15167266130447388, acc=0.9466111063957214, loss=0.15167266130447388
test: epoch 125, loss 0.5244543552398682, acc=0.8083333373069763, loss=0.5244543552398682
train: epoch 126, loss 0.1572750061750412, acc=0.9465000033378601, loss=0.1572750061750412
test: epoch 126, loss 0.5149495005607605, acc=0.8138889074325562, loss=0.5149495005607605
train: epoch 127, loss 0.15647950768470764, acc=0.9445000290870667, loss=0.15647950768470764
test: epoch 127, loss 0.5736256837844849, acc=0.824999988079071, loss=0.5736256837844849
train: epoch 128, loss 0.15318945050239563, acc=0.9474444389343262, loss=0.15318945050239563
test: epoch 128, loss 0.6663812398910522, acc=0.8138889074325562, loss=0.6663812398910522
train: epoch 129, loss 0.1389589011669159, acc=0.9513888955116272, loss=0.1389589011669159
test: epoch 129, loss 0.5974894165992737, acc=0.8055555820465088, loss=0.5974894165992737
train: epoch 130, loss 0.13906288146972656, acc=0.949999988079071, loss=0.13906288146972656
test: epoch 130, loss 0.6230937838554382, acc=0.8194444179534912, loss=0.6230937838554382
train: epoch 131, loss 0.14177606999874115, acc=0.9505000114440918, loss=0.14177606999874115
test: epoch 131, loss 0.5988236665725708, acc=0.8277778029441833, loss=0.5988236665725708
train: epoch 132, loss 0.14460855722427368, acc=0.9490000009536743, loss=0.14460855722427368
test: epoch 132, loss 0.6287645101547241, acc=0.8388888835906982, loss=0.6287645101547241
train: epoch 133, loss 0.14091558754444122, acc=0.9508333206176758, loss=0.14091558754444122
test: epoch 133, loss 0.6139245629310608, acc=0.824999988079071, loss=0.6139245629310608
train: epoch 134, loss 0.13671553134918213, acc=0.9515555500984192, loss=0.13671553134918213
test: epoch 134, loss 0.5596276521682739, acc=0.8055555820465088, loss=0.5596276521682739
train: epoch 135, loss 0.1334669440984726, acc=0.954277753829956, loss=0.1334669440984726
test: epoch 135, loss 0.5122429132461548, acc=0.8277778029441833, loss=0.5122429132461548
train: epoch 136, loss 0.14045731723308563, acc=0.9508333206176758, loss=0.14045731723308563
test: epoch 136, loss 0.5477646589279175, acc=0.8166666626930237, loss=0.5477646589279175
train: epoch 137, loss 0.14258745312690735, acc=0.9527222514152527, loss=0.14258745312690735
test: epoch 137, loss 0.5217155814170837, acc=0.8277778029441833, loss=0.5217155814170837
train: epoch 138, loss 0.12779578566551208, acc=0.9561111330986023, loss=0.12779578566551208
test: epoch 138, loss 0.5322076082229614, acc=0.8277778029441833, loss=0.5322076082229614
train: epoch 139, loss 0.1313333809375763, acc=0.9526666402816772, loss=0.1313333809375763
test: epoch 139, loss 0.5442884564399719, acc=0.8444444537162781, loss=0.5442884564399719
train: epoch 140, loss 0.1406824290752411, acc=0.9521666765213013, loss=0.1406824290752411
test: epoch 140, loss 0.4885929226875305, acc=0.8305555582046509, loss=0.4885929226875305
train: epoch 141, loss 0.13244733214378357, acc=0.9533888697624207, loss=0.13244733214378357
test: epoch 141, loss 0.5165690183639526, acc=0.8305555582046509, loss=0.5165690183639526
train: epoch 142, loss 0.13627445697784424, acc=0.9536666870117188, loss=0.13627445697784424
test: epoch 142, loss 0.4786587357521057, acc=0.8305555582046509, loss=0.4786587357521057
train: epoch 143, loss 0.12302939593791962, acc=0.9553333520889282, loss=0.12302939593791962
test: epoch 143, loss 0.6214776635169983, acc=0.8305555582046509, loss=0.6214776635169983
train: epoch 144, loss 0.13709180057048798, acc=0.9548888802528381, loss=0.13709180057048798
test: epoch 144, loss 0.5860608816146851, acc=0.8222222328186035, loss=0.5860608816146851
train: epoch 145, loss 0.13223938643932343, acc=0.9550555348396301, loss=0.13223938643932343
test: epoch 145, loss 0.5644609928131104, acc=0.8305555582046509, loss=0.5644609928131104
train: epoch 146, loss 0.11984358727931976, acc=0.957611083984375, loss=0.11984358727931976
test: epoch 146, loss 0.43927401304244995, acc=0.8277778029441833, loss=0.43927401304244995
train: epoch 147, loss 0.1288834661245346, acc=0.9551666378974915, loss=0.1288834661245346
test: epoch 147, loss 0.6478682160377502, acc=0.824999988079071, loss=0.6478682160377502
train: epoch 148, loss 0.1344001293182373, acc=0.9533888697624207, loss=0.1344001293182373
test: epoch 148, loss 0.488479882478714, acc=0.8277778029441833, loss=0.488479882478714
train: epoch 149, loss 0.1229977011680603, acc=0.9561111330986023, loss=0.1229977011680603
test: epoch 149, loss 0.4806354343891144, acc=0.8444444537162781, loss=0.4806354343891144
train: epoch 150, loss 0.12948454916477203, acc=0.9542222023010254, loss=0.12948454916477203
test: epoch 150, loss 0.5285935401916504, acc=0.8305555582046509, loss=0.5285935401916504
