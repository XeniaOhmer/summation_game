# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=0.99", "--one_hot=true", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=285985807, receiver_embed_dim=32, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.3795454502105713, acc=0.05366666615009308, loss=3.3795454502105713
test: epoch 1, loss 3.9764528274536133, acc=0.05000000074505806, loss=3.9764528274536133
train: epoch 2, loss 2.624549150466919, acc=0.1711111068725586, loss=2.624549150466919
test: epoch 2, loss 4.37099552154541, acc=0.0972222238779068, loss=4.37099552154541
train: epoch 3, loss 1.8282806873321533, acc=0.34361112117767334, loss=1.8282806873321533
test: epoch 3, loss 4.479578971862793, acc=0.11666666716337204, loss=4.479578971862793
train: epoch 4, loss 1.4671251773834229, acc=0.4436666667461395, loss=1.4671251773834229
test: epoch 4, loss 4.677499771118164, acc=0.12222222238779068, loss=4.677499771118164
train: epoch 5, loss 1.2535326480865479, acc=0.5187222361564636, loss=1.2535326480865479
test: epoch 5, loss 4.615222930908203, acc=0.14166666567325592, loss=4.615222930908203
train: epoch 6, loss 1.1162129640579224, acc=0.5732222199440002, loss=1.1162129640579224
test: epoch 6, loss 4.415194988250732, acc=0.17222222685813904, loss=4.415194988250732
train: epoch 7, loss 1.0035799741744995, acc=0.6216111183166504, loss=1.0035799741744995
test: epoch 7, loss 4.450441360473633, acc=0.16388888657093048, loss=4.450441360473633
train: epoch 8, loss 0.9395073652267456, acc=0.6488333344459534, loss=0.9395073652267456
test: epoch 8, loss 4.092264175415039, acc=0.19722221791744232, loss=4.092264175415039
train: epoch 9, loss 0.8731724619865417, acc=0.6748889088630676, loss=0.8731724619865417
test: epoch 9, loss 3.8660454750061035, acc=0.19722221791744232, loss=3.8660454750061035
train: epoch 10, loss 0.819727897644043, acc=0.6982222199440002, loss=0.819727897644043
test: epoch 10, loss 3.612846612930298, acc=0.1944444477558136, loss=3.612846612930298
train: epoch 11, loss 0.7898621559143066, acc=0.7109444737434387, loss=0.7898621559143066
test: epoch 11, loss 3.8322396278381348, acc=0.23333333432674408, loss=3.8322396278381348
train: epoch 12, loss 0.7539876699447632, acc=0.7269999980926514, loss=0.7539876699447632
test: epoch 12, loss 3.5683553218841553, acc=0.21666666865348816, loss=3.5683553218841553
train: epoch 13, loss 0.741242527961731, acc=0.7313888669013977, loss=0.741242527961731
test: epoch 13, loss 3.3474745750427246, acc=0.20555555820465088, loss=3.3474745750427246
train: epoch 14, loss 0.7011598944664001, acc=0.7465555667877197, loss=0.7011598944664001
test: epoch 14, loss 3.177844285964966, acc=0.24166665971279144, loss=3.177844285964966
train: epoch 15, loss 0.6912541389465332, acc=0.7512778043746948, loss=0.6912541389465332
test: epoch 15, loss 3.051180362701416, acc=0.24722221493721008, loss=3.051180362701416
train: epoch 16, loss 0.6632933616638184, acc=0.7641666531562805, loss=0.6632933616638184
test: epoch 16, loss 3.083676338195801, acc=0.23333333432674408, loss=3.083676338195801
train: epoch 17, loss 0.6428393125534058, acc=0.7698333263397217, loss=0.6428393125534058
test: epoch 17, loss 2.909088611602783, acc=0.25, loss=2.909088611602783
train: epoch 18, loss 0.6354929804801941, acc=0.7726666927337646, loss=0.6354929804801941
test: epoch 18, loss 2.8535373210906982, acc=0.24722221493721008, loss=2.8535373210906982
train: epoch 19, loss 0.6170392036437988, acc=0.7812777757644653, loss=0.6170392036437988
test: epoch 19, loss 2.7221310138702393, acc=0.2638888955116272, loss=2.7221310138702393
train: epoch 20, loss 0.6063316464424133, acc=0.784500002861023, loss=0.6063316464424133
test: epoch 20, loss 2.51235294342041, acc=0.25833332538604736, loss=2.51235294342041
train: epoch 21, loss 0.5924256443977356, acc=0.7883333563804626, loss=0.5924256443977356
test: epoch 21, loss 2.744288444519043, acc=0.2666666805744171, loss=2.744288444519043
train: epoch 22, loss 0.5886379480361938, acc=0.7944999933242798, loss=0.5886379480361938
test: epoch 22, loss 2.526961088180542, acc=0.2750000059604645, loss=2.526961088180542
train: epoch 23, loss 0.5706031322479248, acc=0.7991666793823242, loss=0.5706031322479248
test: epoch 23, loss 2.5184414386749268, acc=0.26944443583488464, loss=2.5184414386749268
train: epoch 24, loss 0.561035692691803, acc=0.7983888983726501, loss=0.561035692691803
test: epoch 24, loss 2.556889295578003, acc=0.2750000059604645, loss=2.556889295578003
train: epoch 25, loss 0.5407333374023438, acc=0.8066111207008362, loss=0.5407333374023438
test: epoch 25, loss 2.368405818939209, acc=0.3027777671813965, loss=2.368405818939209
train: epoch 26, loss 0.556074321269989, acc=0.8063333630561829, loss=0.556074321269989
test: epoch 26, loss 2.421032190322876, acc=0.3055555522441864, loss=2.421032190322876
train: epoch 27, loss 0.5624369382858276, acc=0.804722249507904, loss=0.5624369382858276
test: epoch 27, loss 2.398430109024048, acc=0.2916666567325592, loss=2.398430109024048
train: epoch 28, loss 0.54175865650177, acc=0.8070555329322815, loss=0.54175865650177
test: epoch 28, loss 2.3367655277252197, acc=0.2916666567325592, loss=2.3367655277252197
train: epoch 29, loss 0.5199127197265625, acc=0.8191666603088379, loss=0.5199127197265625
test: epoch 29, loss 2.289370536804199, acc=0.3222222328186035, loss=2.289370536804199
train: epoch 30, loss 0.5319265127182007, acc=0.812666654586792, loss=0.5319265127182007
test: epoch 30, loss 2.118631601333618, acc=0.34166666865348816, loss=2.118631601333618
train: epoch 31, loss 0.5281456112861633, acc=0.8135555386543274, loss=0.5281456112861633
test: epoch 31, loss 2.133862257003784, acc=0.3055555522441864, loss=2.133862257003784
train: epoch 32, loss 0.5190536975860596, acc=0.819611132144928, loss=0.5190536975860596
test: epoch 32, loss 2.1489462852478027, acc=0.3083333373069763, loss=2.1489462852478027
train: epoch 33, loss 0.5055003762245178, acc=0.8202221989631653, loss=0.5055003762245178
test: epoch 33, loss 2.1543684005737305, acc=0.3222222328186035, loss=2.1543684005737305
train: epoch 34, loss 0.5037237405776978, acc=0.8227777481079102, loss=0.5037237405776978
test: epoch 34, loss 2.1635427474975586, acc=0.3222222328186035, loss=2.1635427474975586
train: epoch 35, loss 0.5080915689468384, acc=0.8186666369438171, loss=0.5080915689468384
test: epoch 35, loss 1.9361495971679688, acc=0.35277777910232544, loss=1.9361495971679688
train: epoch 36, loss 0.49448299407958984, acc=0.824055552482605, loss=0.49448299407958984
test: epoch 36, loss 2.0056369304656982, acc=0.33888888359069824, loss=2.0056369304656982
train: epoch 37, loss 0.4914530813694, acc=0.8267222046852112, loss=0.4914530813694
test: epoch 37, loss 1.8717237710952759, acc=0.3638888895511627, loss=1.8717237710952759
train: epoch 38, loss 0.4886007010936737, acc=0.8302778005599976, loss=0.4886007010936737
test: epoch 38, loss 1.9746148586273193, acc=0.3583333194255829, loss=1.9746148586273193
train: epoch 39, loss 0.4771990478038788, acc=0.8295000195503235, loss=0.4771990478038788
test: epoch 39, loss 2.007816791534424, acc=0.35277777910232544, loss=2.007816791534424
train: epoch 40, loss 0.4794212579727173, acc=0.8308333158493042, loss=0.4794212579727173
test: epoch 40, loss 1.9850844144821167, acc=0.36944442987442017, loss=1.9850844144821167
train: epoch 41, loss 0.48354730010032654, acc=0.8328889012336731, loss=0.48354730010032654
test: epoch 41, loss 1.982693076133728, acc=0.35555556416511536, loss=1.982693076133728
train: epoch 42, loss 0.48087379336357117, acc=0.8272777795791626, loss=0.48087379336357117
test: epoch 42, loss 1.890695571899414, acc=0.3638888895511627, loss=1.890695571899414
train: epoch 43, loss 0.4710237681865692, acc=0.8376666903495789, loss=0.4710237681865692
test: epoch 43, loss 1.8580994606018066, acc=0.3583333194255829, loss=1.8580994606018066
train: epoch 44, loss 0.4671383202075958, acc=0.8361666798591614, loss=0.4671383202075958
test: epoch 44, loss 1.9193741083145142, acc=0.36944442987442017, loss=1.9193741083145142
train: epoch 45, loss 0.4692119061946869, acc=0.8355000019073486, loss=0.4692119061946869
test: epoch 45, loss 1.782423973083496, acc=0.3777777850627899, loss=1.782423973083496
train: epoch 46, loss 0.47182536125183105, acc=0.8371111154556274, loss=0.47182536125183105
test: epoch 46, loss 1.835738182067871, acc=0.3638888895511627, loss=1.835738182067871
train: epoch 47, loss 0.4681894779205322, acc=0.8344444632530212, loss=0.4681894779205322
test: epoch 47, loss 1.9209574460983276, acc=0.36666667461395264, loss=1.9209574460983276
train: epoch 48, loss 0.4550263583660126, acc=0.839722216129303, loss=0.4550263583660126
test: epoch 48, loss 1.7402760982513428, acc=0.4055555462837219, loss=1.7402760982513428
train: epoch 49, loss 0.45976710319519043, acc=0.8369444608688354, loss=0.45976710319519043
test: epoch 49, loss 1.687417984008789, acc=0.40833333134651184, loss=1.687417984008789
train: epoch 50, loss 0.4416864812374115, acc=0.8415555357933044, loss=0.4416864812374115
test: epoch 50, loss 1.811418890953064, acc=0.375, loss=1.811418890953064
train: epoch 51, loss 0.443343847990036, acc=0.8376666903495789, loss=0.443343847990036
test: epoch 51, loss 1.7252564430236816, acc=0.38055557012557983, loss=1.7252564430236816
train: epoch 52, loss 0.4564002454280853, acc=0.8363333344459534, loss=0.4564002454280853
test: epoch 52, loss 1.702493667602539, acc=0.3888888955116272, loss=1.702493667602539
train: epoch 53, loss 0.43585988879203796, acc=0.8384444713592529, loss=0.43585988879203796
test: epoch 53, loss 1.7928721904754639, acc=0.4194444417953491, loss=1.7928721904754639
train: epoch 54, loss 0.4390762150287628, acc=0.8411111235618591, loss=0.4390762150287628
test: epoch 54, loss 1.6877392530441284, acc=0.4194444417953491, loss=1.6877392530441284
train: epoch 55, loss 0.4319775700569153, acc=0.8416110873222351, loss=0.4319775700569153
test: epoch 55, loss 1.6246854066848755, acc=0.42222222685813904, loss=1.6246854066848755
train: epoch 56, loss 0.4397117793560028, acc=0.8407777547836304, loss=0.4397117793560028
test: epoch 56, loss 1.68099844455719, acc=0.40833333134651184, loss=1.68099844455719
train: epoch 57, loss 0.44553273916244507, acc=0.8410555720329285, loss=0.44553273916244507
test: epoch 57, loss 1.6767854690551758, acc=0.4333333373069763, loss=1.6767854690551758
train: epoch 58, loss 0.4400000274181366, acc=0.836555540561676, loss=0.4400000274181366
test: epoch 58, loss 1.6780474185943604, acc=0.42500001192092896, loss=1.6780474185943604
train: epoch 59, loss 0.429142028093338, acc=0.8427222371101379, loss=0.429142028093338
test: epoch 59, loss 1.634214162826538, acc=0.4027777910232544, loss=1.634214162826538
train: epoch 60, loss 0.4347858130931854, acc=0.8387222290039062, loss=0.4347858130931854
test: epoch 60, loss 1.5719205141067505, acc=0.4333333373069763, loss=1.5719205141067505
train: epoch 61, loss 0.4320427477359772, acc=0.8394444584846497, loss=0.4320427477359772
test: epoch 61, loss 1.574873924255371, acc=0.4861111044883728, loss=1.574873924255371
train: epoch 62, loss 0.4143645465373993, acc=0.8454444408416748, loss=0.4143645465373993
test: epoch 62, loss 1.5627224445343018, acc=0.46666666865348816, loss=1.5627224445343018
train: epoch 63, loss 0.4316299557685852, acc=0.8412777781486511, loss=0.4316299557685852
test: epoch 63, loss 1.4152425527572632, acc=0.47777777910232544, loss=1.4152425527572632
train: epoch 64, loss 0.43255433440208435, acc=0.8420000076293945, loss=0.43255433440208435
test: epoch 64, loss 1.4687998294830322, acc=0.4611110985279083, loss=1.4687998294830322
train: epoch 65, loss 0.42525380849838257, acc=0.8447222113609314, loss=0.42525380849838257
test: epoch 65, loss 1.4398694038391113, acc=0.47777777910232544, loss=1.4398694038391113
train: epoch 66, loss 0.42917755246162415, acc=0.8446666598320007, loss=0.42917755246162415
test: epoch 66, loss 1.4511594772338867, acc=0.49166667461395264, loss=1.4511594772338867
train: epoch 67, loss 0.4018080234527588, acc=0.847777783870697, loss=0.4018080234527588
test: epoch 67, loss 1.3829803466796875, acc=0.4861111044883728, loss=1.3829803466796875
train: epoch 68, loss 0.4145382344722748, acc=0.8488888740539551, loss=0.4145382344722748
test: epoch 68, loss 1.4373470544815063, acc=0.4972222149372101, loss=1.4373470544815063
train: epoch 69, loss 0.3946640193462372, acc=0.8489444255828857, loss=0.3946640193462372
test: epoch 69, loss 1.389524221420288, acc=0.5138888955116272, loss=1.389524221420288
train: epoch 70, loss 0.41757825016975403, acc=0.8447777628898621, loss=0.41757825016975403
test: epoch 70, loss 1.392338752746582, acc=0.5083333253860474, loss=1.392338752746582
train: epoch 71, loss 0.41167646646499634, acc=0.8482778072357178, loss=0.41167646646499634
test: epoch 71, loss 1.44171142578125, acc=0.4833333194255829, loss=1.44171142578125
train: epoch 72, loss 0.4098437428474426, acc=0.8466110825538635, loss=0.4098437428474426
test: epoch 72, loss 1.312536358833313, acc=0.5222222208976746, loss=1.312536358833313
train: epoch 73, loss 0.4166713356971741, acc=0.8450555801391602, loss=0.4166713356971741
test: epoch 73, loss 1.3591235876083374, acc=0.5083333253860474, loss=1.3591235876083374
train: epoch 74, loss 0.40435516834259033, acc=0.846666693687439, loss=0.40435516834259033
test: epoch 74, loss 1.2798826694488525, acc=0.5249999761581421, loss=1.2798826694488525
train: epoch 75, loss 0.4012899398803711, acc=0.8493888974189758, loss=0.4012899398803711
test: epoch 75, loss 1.289489984512329, acc=0.519444465637207, loss=1.289489984512329
train: epoch 76, loss 0.39012715220451355, acc=0.8483889102935791, loss=0.39012715220451355
test: epoch 76, loss 1.2393012046813965, acc=0.550000011920929, loss=1.2393012046813965
train: epoch 77, loss 0.370103120803833, acc=0.8550000190734863, loss=0.370103120803833
test: epoch 77, loss 1.3177739381790161, acc=0.5472221970558167, loss=1.3177739381790161
train: epoch 78, loss 0.40051722526550293, acc=0.8483889102935791, loss=0.40051722526550293
test: epoch 78, loss 1.218639612197876, acc=0.5666666626930237, loss=1.218639612197876
train: epoch 79, loss 0.3847138285636902, acc=0.8517777919769287, loss=0.3847138285636902
test: epoch 79, loss 1.2045453786849976, acc=0.574999988079071, loss=1.2045453786849976
train: epoch 80, loss 0.3825494050979614, acc=0.8540555834770203, loss=0.3825494050979614
test: epoch 80, loss 1.2412294149398804, acc=0.5888888835906982, loss=1.2412294149398804
train: epoch 81, loss 0.3927921652793884, acc=0.8542222380638123, loss=0.3927921652793884
test: epoch 81, loss 1.1549391746520996, acc=0.5944444537162781, loss=1.1549391746520996
train: epoch 82, loss 0.3655065894126892, acc=0.8587222099304199, loss=0.3655065894126892
test: epoch 82, loss 1.0535377264022827, acc=0.6000000238418579, loss=1.0535377264022827
train: epoch 83, loss 0.38010773062705994, acc=0.8551666736602783, loss=0.38010773062705994
test: epoch 83, loss 1.1319293975830078, acc=0.605555534362793, loss=1.1319293975830078
train: epoch 84, loss 0.368645042181015, acc=0.8631666898727417, loss=0.368645042181015
test: epoch 84, loss 1.0996298789978027, acc=0.6333333253860474, loss=1.0996298789978027
train: epoch 85, loss 0.3608643412590027, acc=0.8627222180366516, loss=0.3608643412590027
test: epoch 85, loss 1.0749648809432983, acc=0.6361111402511597, loss=1.0749648809432983
train: epoch 86, loss 0.3615396022796631, acc=0.863444447517395, loss=0.3615396022796631
test: epoch 86, loss 1.0953830480575562, acc=0.6138888597488403, loss=1.0953830480575562
train: epoch 87, loss 0.3509830832481384, acc=0.862500011920929, loss=0.3509830832481384
test: epoch 87, loss 0.9468129873275757, acc=0.6333333253860474, loss=0.9468129873275757
train: epoch 88, loss 0.3526866137981415, acc=0.862500011920929, loss=0.3526866137981415
test: epoch 88, loss 1.0770457983016968, acc=0.6499999761581421, loss=1.0770457983016968
train: epoch 89, loss 0.3560355007648468, acc=0.8611666560173035, loss=0.3560355007648468
test: epoch 89, loss 0.9739603996276855, acc=0.644444465637207, loss=0.9739603996276855
train: epoch 90, loss 0.3608161509037018, acc=0.862666666507721, loss=0.3608161509037018
test: epoch 90, loss 0.8677586913108826, acc=0.675000011920929, loss=0.8677586913108826
train: epoch 91, loss 0.3517642319202423, acc=0.8622778058052063, loss=0.3517642319202423
test: epoch 91, loss 0.9177504181861877, acc=0.6499999761581421, loss=0.9177504181861877
train: epoch 92, loss 0.3517760932445526, acc=0.863277792930603, loss=0.3517760932445526
test: epoch 92, loss 1.008536458015442, acc=0.6583333611488342, loss=1.008536458015442
train: epoch 93, loss 0.3487386405467987, acc=0.8651666641235352, loss=0.3487386405467987
test: epoch 93, loss 1.0208518505096436, acc=0.6638888716697693, loss=1.0208518505096436
train: epoch 94, loss 0.33500418066978455, acc=0.8706111311912537, loss=0.33500418066978455
test: epoch 94, loss 0.8961519002914429, acc=0.6722221970558167, loss=0.8961519002914429
train: epoch 95, loss 0.3429555594921112, acc=0.8648889064788818, loss=0.3429555594921112
test: epoch 95, loss 0.9136356711387634, acc=0.6638888716697693, loss=0.9136356711387634
train: epoch 96, loss 0.36289089918136597, acc=0.8628333210945129, loss=0.36289089918136597
test: epoch 96, loss 0.8642645478248596, acc=0.6777777671813965, loss=0.8642645478248596
train: epoch 97, loss 0.33938896656036377, acc=0.8702222108840942, loss=0.33938896656036377
test: epoch 97, loss 0.8579807281494141, acc=0.6861110925674438, loss=0.8579807281494141
train: epoch 98, loss 0.33695337176322937, acc=0.8699444532394409, loss=0.33695337176322937
test: epoch 98, loss 0.8943997025489807, acc=0.6777777671813965, loss=0.8943997025489807
train: epoch 99, loss 0.3355310261249542, acc=0.8709999918937683, loss=0.3355310261249542
test: epoch 99, loss 0.7973626255989075, acc=0.7027778029441833, loss=0.7973626255989075
train: epoch 100, loss 0.34016525745391846, acc=0.8689444661140442, loss=0.34016525745391846
test: epoch 100, loss 0.8614978790283203, acc=0.6944444179534912, loss=0.8614978790283203
train: epoch 101, loss 0.32868149876594543, acc=0.8711666464805603, loss=0.32868149876594543
test: epoch 101, loss 0.8641547560691833, acc=0.6777777671813965, loss=0.8641547560691833
train: epoch 102, loss 0.3212946653366089, acc=0.8736110925674438, loss=0.3212946653366089
test: epoch 102, loss 0.8768879771232605, acc=0.6861110925674438, loss=0.8768879771232605
train: epoch 103, loss 0.3187311589717865, acc=0.8753888607025146, loss=0.3187311589717865
test: epoch 103, loss 0.7997855544090271, acc=0.699999988079071, loss=0.7997855544090271
train: epoch 104, loss 0.3190467953681946, acc=0.8742777705192566, loss=0.3190467953681946
test: epoch 104, loss 0.8082784414291382, acc=0.7083333134651184, loss=0.8082784414291382
train: epoch 105, loss 0.3064962327480316, acc=0.8774999976158142, loss=0.3064962327480316
test: epoch 105, loss 0.8644382357597351, acc=0.7055555582046509, loss=0.8644382357597351
train: epoch 106, loss 0.3152013421058655, acc=0.8744444251060486, loss=0.3152013421058655
test: epoch 106, loss 0.8622631430625916, acc=0.6972222328186035, loss=0.8622631430625916
train: epoch 107, loss 0.30673253536224365, acc=0.8744999766349792, loss=0.30673253536224365
test: epoch 107, loss 0.8410182595252991, acc=0.7111111283302307, loss=0.8410182595252991
train: epoch 108, loss 0.3049432337284088, acc=0.8776666522026062, loss=0.3049432337284088
test: epoch 108, loss 0.9125173091888428, acc=0.7083333134651184, loss=0.9125173091888428
train: epoch 109, loss 0.30556532740592957, acc=0.8793888688087463, loss=0.30556532740592957
test: epoch 109, loss 0.8721453547477722, acc=0.6888889074325562, loss=0.8721453547477722
train: epoch 110, loss 0.2985663115978241, acc=0.8818888664245605, loss=0.2985663115978241
test: epoch 110, loss 0.9076254963874817, acc=0.7138888835906982, loss=0.9076254963874817
train: epoch 111, loss 0.2966628074645996, acc=0.8816666603088379, loss=0.2966628074645996
test: epoch 111, loss 0.8891652822494507, acc=0.7083333134651184, loss=0.8891652822494507
train: epoch 112, loss 0.28816595673561096, acc=0.8838889002799988, loss=0.28816595673561096
test: epoch 112, loss 0.8341923952102661, acc=0.7222222089767456, loss=0.8341923952102661
train: epoch 113, loss 0.2890191078186035, acc=0.8831111192703247, loss=0.2890191078186035
test: epoch 113, loss 0.7492260336875916, acc=0.7250000238418579, loss=0.7492260336875916
train: epoch 114, loss 0.29622089862823486, acc=0.8857777714729309, loss=0.29622089862823486
test: epoch 114, loss 0.6837092638015747, acc=0.7472222447395325, loss=0.6837092638015747
train: epoch 115, loss 0.27361536026000977, acc=0.8858888745307922, loss=0.27361536026000977
test: epoch 115, loss 0.8102045655250549, acc=0.7194444537162781, loss=0.8102045655250549
train: epoch 116, loss 0.2857253849506378, acc=0.8836110830307007, loss=0.2857253849506378
test: epoch 116, loss 0.7880852222442627, acc=0.7166666388511658, loss=0.7880852222442627
train: epoch 117, loss 0.2812977433204651, acc=0.887333333492279, loss=0.2812977433204651
test: epoch 117, loss 0.7151319980621338, acc=0.7416666746139526, loss=0.7151319980621338
train: epoch 118, loss 0.2784372568130493, acc=0.8837222456932068, loss=0.2784372568130493
test: epoch 118, loss 0.7012286186218262, acc=0.7472222447395325, loss=0.7012286186218262
train: epoch 119, loss 0.2741854190826416, acc=0.8847777843475342, loss=0.2741854190826416
test: epoch 119, loss 0.7526583671569824, acc=0.7361111044883728, loss=0.7526583671569824
train: epoch 120, loss 0.27969229221343994, acc=0.8850555419921875, loss=0.27969229221343994
test: epoch 120, loss 0.6945487856864929, acc=0.7444444298744202, loss=0.6945487856864929
train: epoch 121, loss 0.26850372552871704, acc=0.8877221941947937, loss=0.26850372552871704
test: epoch 121, loss 0.695418655872345, acc=0.7444444298744202, loss=0.695418655872345
train: epoch 122, loss 0.26592710614204407, acc=0.8882777690887451, loss=0.26592710614204407
test: epoch 122, loss 0.6621015071868896, acc=0.7444444298744202, loss=0.6621015071868896
train: epoch 123, loss 0.2775008976459503, acc=0.8884444236755371, loss=0.2775008976459503
test: epoch 123, loss 0.6869258880615234, acc=0.7583333253860474, loss=0.6869258880615234
train: epoch 124, loss 0.27485689520835876, acc=0.890500009059906, loss=0.27485689520835876
test: epoch 124, loss 0.6648710370063782, acc=0.7638888955116272, loss=0.6648710370063782
train: epoch 125, loss 0.25724124908447266, acc=0.8930555582046509, loss=0.25724124908447266
test: epoch 125, loss 0.7745972871780396, acc=0.7638888955116272, loss=0.7745972871780396
train: epoch 126, loss 0.2719731330871582, acc=0.8902778029441833, loss=0.2719731330871582
test: epoch 126, loss 0.7672491669654846, acc=0.7555555701255798, loss=0.7672491669654846
train: epoch 127, loss 0.2694303095340729, acc=0.8928889036178589, loss=0.2694303095340729
test: epoch 127, loss 0.6262518167495728, acc=0.7638888955116272, loss=0.6262518167495728
train: epoch 128, loss 0.25976473093032837, acc=0.8963333368301392, loss=0.25976473093032837
test: epoch 128, loss 0.643195629119873, acc=0.7722222208976746, loss=0.643195629119873
train: epoch 129, loss 0.24867519736289978, acc=0.8976110816001892, loss=0.24867519736289978
test: epoch 129, loss 0.6179475784301758, acc=0.7666666507720947, loss=0.6179475784301758
train: epoch 130, loss 0.24655568599700928, acc=0.8956666588783264, loss=0.24655568599700928
test: epoch 130, loss 0.6456500887870789, acc=0.7722222208976746, loss=0.6456500887870789
train: epoch 131, loss 0.2579156458377838, acc=0.8973333239555359, loss=0.2579156458377838
test: epoch 131, loss 0.6022093892097473, acc=0.7777777910232544, loss=0.6022093892097473
train: epoch 132, loss 0.24515323340892792, acc=0.8985000252723694, loss=0.24515323340892792
test: epoch 132, loss 0.6157217621803284, acc=0.7611111402511597, loss=0.6157217621803284
train: epoch 133, loss 0.2515309453010559, acc=0.8974444270133972, loss=0.2515309453010559
test: epoch 133, loss 0.7114811539649963, acc=0.7749999761581421, loss=0.7114811539649963
train: epoch 134, loss 0.25236251950263977, acc=0.8989999890327454, loss=0.25236251950263977
test: epoch 134, loss 0.6684519648551941, acc=0.7749999761581421, loss=0.6684519648551941
train: epoch 135, loss 0.24186615645885468, acc=0.8999999761581421, loss=0.24186615645885468
test: epoch 135, loss 0.6521425843238831, acc=0.7805555462837219, loss=0.6521425843238831
train: epoch 136, loss 0.23949751257896423, acc=0.9004999995231628, loss=0.23949751257896423
test: epoch 136, loss 0.6875858902931213, acc=0.7833333611488342, loss=0.6875858902931213
train: epoch 137, loss 0.2455274760723114, acc=0.8997222185134888, loss=0.2455274760723114
test: epoch 137, loss 0.600297749042511, acc=0.7666666507720947, loss=0.600297749042511
train: epoch 138, loss 0.24487456679344177, acc=0.9009444713592529, loss=0.24487456679344177
test: epoch 138, loss 0.6510553956031799, acc=0.7861111164093018, loss=0.6510553956031799
train: epoch 139, loss 0.2437092363834381, acc=0.89811110496521, loss=0.2437092363834381
test: epoch 139, loss 0.6882268786430359, acc=0.7833333611488342, loss=0.6882268786430359
train: epoch 140, loss 0.24651476740837097, acc=0.8983333110809326, loss=0.24651476740837097
test: epoch 140, loss 0.6182356476783752, acc=0.7833333611488342, loss=0.6182356476783752
train: epoch 141, loss 0.23486290872097015, acc=0.9013333320617676, loss=0.23486290872097015
test: epoch 141, loss 0.5943626761436462, acc=0.7861111164093018, loss=0.5943626761436462
train: epoch 142, loss 0.24465449154376984, acc=0.897777795791626, loss=0.24465449154376984
test: epoch 142, loss 0.6756551861763, acc=0.7833333611488342, loss=0.6756551861763
train: epoch 143, loss 0.23928424715995789, acc=0.9013333320617676, loss=0.23928424715995789
test: epoch 143, loss 0.65864098072052, acc=0.7833333611488342, loss=0.65864098072052
train: epoch 144, loss 0.22702832520008087, acc=0.9024444222450256, loss=0.22702832520008087
test: epoch 144, loss 0.5875648260116577, acc=0.7861111164093018, loss=0.5875648260116577
train: epoch 145, loss 0.22786502540111542, acc=0.9026666879653931, loss=0.22786502540111542
test: epoch 145, loss 0.6682497262954712, acc=0.7805555462837219, loss=0.6682497262954712
train: epoch 146, loss 0.23192386329174042, acc=0.9045000076293945, loss=0.23192386329174042
test: epoch 146, loss 0.6704736351966858, acc=0.7805555462837219, loss=0.6704736351966858
train: epoch 147, loss 0.22987672686576843, acc=0.9027777910232544, loss=0.22987672686576843
test: epoch 147, loss 0.6235766410827637, acc=0.7805555462837219, loss=0.6235766410827637
train: epoch 148, loss 0.24089443683624268, acc=0.902999997138977, loss=0.24089443683624268
test: epoch 148, loss 0.5854566693305969, acc=0.7777777910232544, loss=0.5854566693305969
train: epoch 149, loss 0.22442200779914856, acc=0.9057777523994446, loss=0.22442200779914856
test: epoch 149, loss 0.658963680267334, acc=0.7861111164093018, loss=0.658963680267334
train: epoch 150, loss 0.2181285172700882, acc=0.906166672706604, loss=0.2181285172700882
test: epoch 150, loss 0.6318312287330627, acc=0.7777777910232544, loss=0.6318312287330627
