# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1", "--temp_decay=0.99", "--one_hot=false", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=971204433, receiver_embed_dim=32, temp_decay=0.99, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.296525239944458, acc=0.053833331912755966, loss=3.296525239944458
test: epoch 1, loss 3.0990588665008545, acc=0.08055555820465088, loss=3.0990588665008545
train: epoch 2, loss 2.523557424545288, acc=0.1384444385766983, loss=2.523557424545288
test: epoch 2, loss 2.513535261154175, acc=0.1388888955116272, loss=2.513535261154175
train: epoch 3, loss 2.1411476135253906, acc=0.19955556094646454, loss=2.1411476135253906
test: epoch 3, loss 2.679147958755493, acc=0.13333334028720856, loss=2.679147958755493
train: epoch 4, loss 1.9315584897994995, acc=0.25966668128967285, loss=1.9315584897994995
test: epoch 4, loss 2.6037631034851074, acc=0.1527777761220932, loss=2.6037631034851074
train: epoch 5, loss 1.7631486654281616, acc=0.3092777729034424, loss=1.7631486654281616
test: epoch 5, loss 2.5393500328063965, acc=0.15833333134651184, loss=2.5393500328063965
train: epoch 6, loss 1.5867164134979248, acc=0.3588888943195343, loss=1.5867164134979248
test: epoch 6, loss 2.1739914417266846, acc=0.19166666269302368, loss=2.1739914417266846
train: epoch 7, loss 1.466976523399353, acc=0.38261112570762634, loss=1.466976523399353
test: epoch 7, loss 1.9563124179840088, acc=0.2361111044883728, loss=1.9563124179840088
train: epoch 8, loss 1.3594416379928589, acc=0.4212222099304199, loss=1.3594416379928589
test: epoch 8, loss 1.7306714057922363, acc=0.25555557012557983, loss=1.7306714057922363
train: epoch 9, loss 1.2853667736053467, acc=0.44127777218818665, loss=1.2853667736053467
test: epoch 9, loss 1.7600340843200684, acc=0.2666666805744171, loss=1.7600340843200684
train: epoch 10, loss 1.21732497215271, acc=0.4627777636051178, loss=1.21732497215271
test: epoch 10, loss 1.6704142093658447, acc=0.29722222685813904, loss=1.6704142093658447
train: epoch 11, loss 1.1859462261199951, acc=0.4671666622161865, loss=1.1859462261199951
test: epoch 11, loss 1.6514835357666016, acc=0.26944443583488464, loss=1.6514835357666016
train: epoch 12, loss 1.1607897281646729, acc=0.47688889503479004, loss=1.1607897281646729
test: epoch 12, loss 1.60899019241333, acc=0.28333333134651184, loss=1.60899019241333
train: epoch 13, loss 1.122053623199463, acc=0.4928888976573944, loss=1.122053623199463
test: epoch 13, loss 1.627833604812622, acc=0.28611111640930176, loss=1.627833604812622
train: epoch 14, loss 1.0986775159835815, acc=0.5016111135482788, loss=1.0986775159835815
test: epoch 14, loss 1.719628930091858, acc=0.32499998807907104, loss=1.719628930091858
train: epoch 15, loss 1.0778762102127075, acc=0.5162777900695801, loss=1.0778762102127075
test: epoch 15, loss 1.864166259765625, acc=0.28333333134651184, loss=1.864166259765625
train: epoch 16, loss 1.0371544361114502, acc=0.5306110978126526, loss=1.0371544361114502
test: epoch 16, loss 1.6537716388702393, acc=0.35555556416511536, loss=1.6537716388702393
train: epoch 17, loss 1.0102537870407104, acc=0.5379444360733032, loss=1.0102537870407104
test: epoch 17, loss 1.5718234777450562, acc=0.3444444537162781, loss=1.5718234777450562
train: epoch 18, loss 0.9548781514167786, acc=0.5612221956253052, loss=0.9548781514167786
test: epoch 18, loss 1.5329464673995972, acc=0.3472222089767456, loss=1.5329464673995972
train: epoch 19, loss 0.939389705657959, acc=0.5681666731834412, loss=0.939389705657959
test: epoch 19, loss 1.4665141105651855, acc=0.3583333194255829, loss=1.4665141105651855
train: epoch 20, loss 0.9214826822280884, acc=0.5770000219345093, loss=0.9214826822280884
test: epoch 20, loss 1.3841325044631958, acc=0.38333332538604736, loss=1.3841325044631958
train: epoch 21, loss 0.9042456150054932, acc=0.5926666855812073, loss=0.9042456150054932
test: epoch 21, loss 1.6681691408157349, acc=0.36944442987442017, loss=1.6681691408157349
train: epoch 22, loss 0.882258415222168, acc=0.6026111245155334, loss=0.882258415222168
test: epoch 22, loss 1.4852631092071533, acc=0.38333332538604736, loss=1.4852631092071533
train: epoch 23, loss 0.8614130020141602, acc=0.6160555481910706, loss=0.8614130020141602
test: epoch 23, loss 1.4672305583953857, acc=0.4166666567325592, loss=1.4672305583953857
train: epoch 24, loss 0.8425482511520386, acc=0.6292222142219543, loss=0.8425482511520386
test: epoch 24, loss 1.4505635499954224, acc=0.4194444417953491, loss=1.4505635499954224
train: epoch 25, loss 0.8338520526885986, acc=0.6256666779518127, loss=0.8338520526885986
test: epoch 25, loss 1.3687950372695923, acc=0.42222222685813904, loss=1.3687950372695923
train: epoch 26, loss 0.8124215006828308, acc=0.6386666893959045, loss=0.8124215006828308
test: epoch 26, loss 1.3982077836990356, acc=0.4166666567325592, loss=1.3982077836990356
train: epoch 27, loss 0.7922476530075073, acc=0.6431111097335815, loss=0.7922476530075073
test: epoch 27, loss 1.3589986562728882, acc=0.42222222685813904, loss=1.3589986562728882
train: epoch 28, loss 0.8097891807556152, acc=0.6422777771949768, loss=0.8097891807556152
test: epoch 28, loss 1.4603655338287354, acc=0.4305555522441864, loss=1.4603655338287354
train: epoch 29, loss 0.7922981977462769, acc=0.6463333368301392, loss=0.7922981977462769
test: epoch 29, loss 1.5464234352111816, acc=0.4416666626930237, loss=1.5464234352111816
train: epoch 30, loss 0.7714853882789612, acc=0.6571666598320007, loss=0.7714853882789612
test: epoch 30, loss 1.4642295837402344, acc=0.4305555522441864, loss=1.4642295837402344
train: epoch 31, loss 0.7606381177902222, acc=0.6564444303512573, loss=0.7606381177902222
test: epoch 31, loss 1.4617449045181274, acc=0.4333333373069763, loss=1.4617449045181274
train: epoch 32, loss 0.757274866104126, acc=0.6603888869285583, loss=0.757274866104126
test: epoch 32, loss 1.5560652017593384, acc=0.42222222685813904, loss=1.5560652017593384
train: epoch 33, loss 0.7585874795913696, acc=0.6641111373901367, loss=0.7585874795913696
test: epoch 33, loss 1.4336992502212524, acc=0.4166666567325592, loss=1.4336992502212524
train: epoch 34, loss 0.73847496509552, acc=0.6710555553436279, loss=0.73847496509552
test: epoch 34, loss 1.315645694732666, acc=0.4305555522441864, loss=1.315645694732666
train: epoch 35, loss 0.712985634803772, acc=0.675944447517395, loss=0.712985634803772
test: epoch 35, loss 1.472391963005066, acc=0.4305555522441864, loss=1.472391963005066
train: epoch 36, loss 0.6983597874641418, acc=0.6927777528762817, loss=0.6983597874641418
test: epoch 36, loss 1.5153040885925293, acc=0.43611112236976624, loss=1.5153040885925293
train: epoch 37, loss 0.6708305478096008, acc=0.7093889117240906, loss=0.6708305478096008
test: epoch 37, loss 1.4995521306991577, acc=0.43611112236976624, loss=1.4995521306991577
train: epoch 38, loss 0.6810475587844849, acc=0.7068333625793457, loss=0.6810475587844849
test: epoch 38, loss 1.5462613105773926, acc=0.4194444417953491, loss=1.5462613105773926
train: epoch 39, loss 0.6617404222488403, acc=0.7089444398880005, loss=0.6617404222488403
test: epoch 39, loss 1.4371850490570068, acc=0.4555555582046509, loss=1.4371850490570068
train: epoch 40, loss 0.6482256054878235, acc=0.7183333039283752, loss=0.6482256054878235
test: epoch 40, loss 1.6514723300933838, acc=0.45277777314186096, loss=1.6514723300933838
train: epoch 41, loss 0.6482874751091003, acc=0.7178888916969299, loss=0.6482874751091003
test: epoch 41, loss 1.569350242614746, acc=0.4583333432674408, loss=1.569350242614746
train: epoch 42, loss 0.6427201628684998, acc=0.7207221984863281, loss=0.6427201628684998
test: epoch 42, loss 1.6154650449752808, acc=0.45277777314186096, loss=1.6154650449752808
train: epoch 43, loss 0.6318343281745911, acc=0.7256666421890259, loss=0.6318343281745911
test: epoch 43, loss 1.4801266193389893, acc=0.46388888359069824, loss=1.4801266193389893
train: epoch 44, loss 0.626183807849884, acc=0.7238888740539551, loss=0.626183807849884
test: epoch 44, loss 1.3625259399414062, acc=0.4583333432674408, loss=1.3625259399414062
train: epoch 45, loss 0.6187307834625244, acc=0.7247777581214905, loss=0.6187307834625244
test: epoch 45, loss 1.3100074529647827, acc=0.4694444537162781, loss=1.3100074529647827
train: epoch 46, loss 0.6146862506866455, acc=0.7292777895927429, loss=0.6146862506866455
test: epoch 46, loss 1.6101523637771606, acc=0.46388888359069824, loss=1.6101523637771606
train: epoch 47, loss 0.6229285001754761, acc=0.7320555448532104, loss=0.6229285001754761
test: epoch 47, loss 1.4661779403686523, acc=0.46388888359069824, loss=1.4661779403686523
train: epoch 48, loss 0.6053417325019836, acc=0.7351111173629761, loss=0.6053417325019836
test: epoch 48, loss 1.586119294166565, acc=0.4416666626930237, loss=1.586119294166565
train: epoch 49, loss 0.6102403998374939, acc=0.7338888645172119, loss=0.6102403998374939
test: epoch 49, loss 1.4373646974563599, acc=0.4555555582046509, loss=1.4373646974563599
train: epoch 50, loss 0.6209965348243713, acc=0.7286111116409302, loss=0.6209965348243713
test: epoch 50, loss 1.4500683546066284, acc=0.46388888359069824, loss=1.4500683546066284
train: epoch 51, loss 0.6004377603530884, acc=0.7399444580078125, loss=0.6004377603530884
test: epoch 51, loss 1.5549938678741455, acc=0.4472222328186035, loss=1.5549938678741455
train: epoch 52, loss 0.6211370229721069, acc=0.7310000061988831, loss=0.6211370229721069
test: epoch 52, loss 1.3858351707458496, acc=0.46388888359069824, loss=1.3858351707458496
train: epoch 53, loss 0.6001383662223816, acc=0.7379999756813049, loss=0.6001383662223816
test: epoch 53, loss 1.404616355895996, acc=0.46388888359069824, loss=1.404616355895996
train: epoch 54, loss 0.6016550064086914, acc=0.7397222518920898, loss=0.6016550064086914
test: epoch 54, loss 1.3995273113250732, acc=0.46388888359069824, loss=1.3995273113250732
train: epoch 55, loss 0.591001033782959, acc=0.7424444556236267, loss=0.591001033782959
test: epoch 55, loss 1.4744117259979248, acc=0.43888887763023376, loss=1.4744117259979248
train: epoch 56, loss 0.5958472490310669, acc=0.741611123085022, loss=0.5958472490310669
test: epoch 56, loss 1.4892988204956055, acc=0.46388888359069824, loss=1.4892988204956055
train: epoch 57, loss 0.5956343412399292, acc=0.7437777519226074, loss=0.5956343412399292
test: epoch 57, loss 1.564501166343689, acc=0.43888887763023376, loss=1.564501166343689
train: epoch 58, loss 0.5918992757797241, acc=0.7397778034210205, loss=0.5918992757797241
test: epoch 58, loss 1.493655800819397, acc=0.46388888359069824, loss=1.493655800819397
train: epoch 59, loss 0.583046019077301, acc=0.7434444427490234, loss=0.583046019077301
test: epoch 59, loss 1.6028958559036255, acc=0.4583333432674408, loss=1.6028958559036255
train: epoch 60, loss 0.582676351070404, acc=0.7453333139419556, loss=0.582676351070404
test: epoch 60, loss 1.4750735759735107, acc=0.4472222328186035, loss=1.4750735759735107
train: epoch 61, loss 0.5841996669769287, acc=0.7437777519226074, loss=0.5841996669769287
test: epoch 61, loss 1.4860107898712158, acc=0.46388888359069824, loss=1.4860107898712158
train: epoch 62, loss 0.5752893090248108, acc=0.7506111264228821, loss=0.5752893090248108
test: epoch 62, loss 1.373366117477417, acc=0.4749999940395355, loss=1.373366117477417
train: epoch 63, loss 0.5880119204521179, acc=0.7453888654708862, loss=0.5880119204521179
test: epoch 63, loss 1.5841686725616455, acc=0.46388888359069824, loss=1.5841686725616455
train: epoch 64, loss 0.5746539235115051, acc=0.7510555386543274, loss=0.5746539235115051
test: epoch 64, loss 1.2751938104629517, acc=0.46388888359069824, loss=1.2751938104629517
train: epoch 65, loss 0.5752183794975281, acc=0.7484999895095825, loss=0.5752183794975281
test: epoch 65, loss 1.4006767272949219, acc=0.48055556416511536, loss=1.4006767272949219
train: epoch 66, loss 0.579192578792572, acc=0.7475000023841858, loss=0.579192578792572
test: epoch 66, loss 1.4108220338821411, acc=0.48055556416511536, loss=1.4108220338821411
train: epoch 67, loss 0.5644629001617432, acc=0.7557777762413025, loss=0.5644629001617432
test: epoch 67, loss 1.465616226196289, acc=0.46388888359069824, loss=1.465616226196289
train: epoch 68, loss 0.5796809792518616, acc=0.7515555620193481, loss=0.5796809792518616
test: epoch 68, loss 1.4923652410507202, acc=0.4861111044883728, loss=1.4923652410507202
train: epoch 69, loss 0.582338273525238, acc=0.746666669845581, loss=0.582338273525238
test: epoch 69, loss 1.5572360754013062, acc=0.4888888895511627, loss=1.5572360754013062
train: epoch 70, loss 0.5584941506385803, acc=0.7569444179534912, loss=0.5584941506385803
test: epoch 70, loss 1.5136075019836426, acc=0.46388888359069824, loss=1.5136075019836426
train: epoch 71, loss 0.5695088505744934, acc=0.7513333559036255, loss=0.5695088505744934
test: epoch 71, loss 1.4611148834228516, acc=0.49166667461395264, loss=1.4611148834228516
train: epoch 72, loss 0.5693708062171936, acc=0.7550555467605591, loss=0.5693708062171936
test: epoch 72, loss 1.6116645336151123, acc=0.4861111044883728, loss=1.6116645336151123
train: epoch 73, loss 0.552253246307373, acc=0.7607777714729309, loss=0.552253246307373
test: epoch 73, loss 1.5635783672332764, acc=0.49166667461395264, loss=1.5635783672332764
train: epoch 74, loss 0.5665766000747681, acc=0.7578333616256714, loss=0.5665766000747681
test: epoch 74, loss 1.5611252784729004, acc=0.49166667461395264, loss=1.5611252784729004
train: epoch 75, loss 0.5566554665565491, acc=0.754444420337677, loss=0.5566554665565491
test: epoch 75, loss 1.4552100896835327, acc=0.49166667461395264, loss=1.4552100896835327
train: epoch 76, loss 0.5439212918281555, acc=0.762666642665863, loss=0.5439212918281555
test: epoch 76, loss 1.5529361963272095, acc=0.4888888895511627, loss=1.5529361963272095
train: epoch 77, loss 0.5523052215576172, acc=0.7581111192703247, loss=0.5523052215576172
test: epoch 77, loss 1.5496002435684204, acc=0.49166667461395264, loss=1.5496002435684204
train: epoch 78, loss 0.5483524799346924, acc=0.7602221965789795, loss=0.5483524799346924
test: epoch 78, loss 1.426702618598938, acc=0.49166667461395264, loss=1.426702618598938
train: epoch 79, loss 0.5405832529067993, acc=0.7662222385406494, loss=0.5405832529067993
test: epoch 79, loss 1.4289900064468384, acc=0.49166667461395264, loss=1.4289900064468384
train: epoch 80, loss 0.5422014594078064, acc=0.7617777585983276, loss=0.5422014594078064
test: epoch 80, loss 1.2795031070709229, acc=0.49166667461395264, loss=1.2795031070709229
train: epoch 81, loss 0.5403057336807251, acc=0.7630000114440918, loss=0.5403057336807251
test: epoch 81, loss 1.4296592473983765, acc=0.49166667461395264, loss=1.4296592473983765
train: epoch 82, loss 0.5440953373908997, acc=0.7609444260597229, loss=0.5440953373908997
test: epoch 82, loss 1.6323459148406982, acc=0.49166667461395264, loss=1.6323459148406982
train: epoch 83, loss 0.5530465245246887, acc=0.7575555443763733, loss=0.5530465245246887
test: epoch 83, loss 1.3580427169799805, acc=0.4972222149372101, loss=1.3580427169799805
train: epoch 84, loss 0.5550309419631958, acc=0.7559999823570251, loss=0.5550309419631958
test: epoch 84, loss 1.441230297088623, acc=0.49166667461395264, loss=1.441230297088623
train: epoch 85, loss 0.5487732887268066, acc=0.7602221965789795, loss=0.5487732887268066
test: epoch 85, loss 1.5030399560928345, acc=0.49166667461395264, loss=1.5030399560928345
train: epoch 86, loss 0.5466809272766113, acc=0.7593333125114441, loss=0.5466809272766113
test: epoch 86, loss 1.4806032180786133, acc=0.49166667461395264, loss=1.4806032180786133
train: epoch 87, loss 0.5366184711456299, acc=0.7633888721466064, loss=0.5366184711456299
test: epoch 87, loss 1.4073996543884277, acc=0.49444442987442017, loss=1.4073996543884277
train: epoch 88, loss 0.522651731967926, acc=0.7690555453300476, loss=0.522651731967926
test: epoch 88, loss 1.5558096170425415, acc=0.49166667461395264, loss=1.5558096170425415
train: epoch 89, loss 0.5387094020843506, acc=0.7626110911369324, loss=0.5387094020843506
test: epoch 89, loss 1.4438761472702026, acc=0.4833333194255829, loss=1.4438761472702026
train: epoch 90, loss 0.5421696305274963, acc=0.7631666660308838, loss=0.5421696305274963
test: epoch 90, loss 1.5531654357910156, acc=0.49444442987442017, loss=1.5531654357910156
train: epoch 91, loss 0.5416657328605652, acc=0.7628889083862305, loss=0.5416657328605652
test: epoch 91, loss 1.3708206415176392, acc=0.49166667461395264, loss=1.3708206415176392
train: epoch 92, loss 0.5348106026649475, acc=0.76583331823349, loss=0.5348106026649475
test: epoch 92, loss 1.6391452550888062, acc=0.49166667461395264, loss=1.6391452550888062
train: epoch 93, loss 0.5386740565299988, acc=0.7639444470405579, loss=0.5386740565299988
test: epoch 93, loss 1.4150117635726929, acc=0.49166667461395264, loss=1.4150117635726929
train: epoch 94, loss 0.5271405577659607, acc=0.7678333520889282, loss=0.5271405577659607
test: epoch 94, loss 1.4753557443618774, acc=0.49166667461395264, loss=1.4753557443618774
train: epoch 95, loss 0.5305954813957214, acc=0.7651110887527466, loss=0.5305954813957214
test: epoch 95, loss 1.3867372274398804, acc=0.49166667461395264, loss=1.3867372274398804
train: epoch 96, loss 0.5300048589706421, acc=0.7664999961853027, loss=0.5300048589706421
test: epoch 96, loss 1.494162678718567, acc=0.49166667461395264, loss=1.494162678718567
train: epoch 97, loss 0.5228919386863708, acc=0.7693889141082764, loss=0.5228919386863708
test: epoch 97, loss 1.5776439905166626, acc=0.49166667461395264, loss=1.5776439905166626
train: epoch 98, loss 0.5367633104324341, acc=0.7631111145019531, loss=0.5367633104324341
test: epoch 98, loss 1.500098705291748, acc=0.49166667461395264, loss=1.500098705291748
train: epoch 99, loss 0.5409591197967529, acc=0.7595000267028809, loss=0.5409591197967529
test: epoch 99, loss 1.5537943840026855, acc=0.49166667461395264, loss=1.5537943840026855
train: epoch 100, loss 0.5291852951049805, acc=0.76583331823349, loss=0.5291852951049805
test: epoch 100, loss 1.5082708597183228, acc=0.49166667461395264, loss=1.5082708597183228
train: epoch 101, loss 0.5169066190719604, acc=0.7703889012336731, loss=0.5169066190719604
test: epoch 101, loss 1.5056933164596558, acc=0.49166667461395264, loss=1.5056933164596558
train: epoch 102, loss 0.5316367149353027, acc=0.7671666741371155, loss=0.5316367149353027
test: epoch 102, loss 1.4080464839935303, acc=0.49166667461395264, loss=1.4080464839935303
train: epoch 103, loss 0.5216864943504333, acc=0.7716110944747925, loss=0.5216864943504333
test: epoch 103, loss 1.5728689432144165, acc=0.49166667461395264, loss=1.5728689432144165
train: epoch 104, loss 0.5211344361305237, acc=0.772777795791626, loss=0.5211344361305237
test: epoch 104, loss 1.4359700679779053, acc=0.49166667461395264, loss=1.4359700679779053
train: epoch 105, loss 0.5457797050476074, acc=0.7634999752044678, loss=0.5457797050476074
test: epoch 105, loss 1.4465291500091553, acc=0.49166667461395264, loss=1.4465291500091553
train: epoch 106, loss 0.5259934067726135, acc=0.7666110992431641, loss=0.5259934067726135
test: epoch 106, loss 1.5508097410202026, acc=0.4749999940395355, loss=1.5508097410202026
train: epoch 107, loss 0.5272138118743896, acc=0.7680000066757202, loss=0.5272138118743896
test: epoch 107, loss 1.4408881664276123, acc=0.49166667461395264, loss=1.4408881664276123
train: epoch 108, loss 0.5160467028617859, acc=0.7717777490615845, loss=0.5160467028617859
test: epoch 108, loss 1.6064822673797607, acc=0.49166667461395264, loss=1.6064822673797607
train: epoch 109, loss 0.531611979007721, acc=0.7665555477142334, loss=0.531611979007721
test: epoch 109, loss 1.5768799781799316, acc=0.49166667461395264, loss=1.5768799781799316
train: epoch 110, loss 0.5302520394325256, acc=0.7677222490310669, loss=0.5302520394325256
test: epoch 110, loss 1.50002920627594, acc=0.49166667461395264, loss=1.50002920627594
train: epoch 111, loss 0.5193322896957397, acc=0.7702222466468811, loss=0.5193322896957397
test: epoch 111, loss 1.4001164436340332, acc=0.49166667461395264, loss=1.4001164436340332
train: epoch 112, loss 0.5323522090911865, acc=0.7680555582046509, loss=0.5323522090911865
test: epoch 112, loss 1.5166324377059937, acc=0.49166667461395264, loss=1.5166324377059937
train: epoch 113, loss 0.5167127847671509, acc=0.7734444737434387, loss=0.5167127847671509
test: epoch 113, loss 1.421053409576416, acc=0.49166667461395264, loss=1.421053409576416
train: epoch 114, loss 0.5359171032905579, acc=0.7686111330986023, loss=0.5359171032905579
test: epoch 114, loss 1.59164297580719, acc=0.49166667461395264, loss=1.59164297580719
train: epoch 115, loss 0.5238622426986694, acc=0.7733888626098633, loss=0.5238622426986694
test: epoch 115, loss 1.3929469585418701, acc=0.49166667461395264, loss=1.3929469585418701
train: epoch 116, loss 0.5223149657249451, acc=0.7715555429458618, loss=0.5223149657249451
test: epoch 116, loss 1.4760416746139526, acc=0.49166667461395264, loss=1.4760416746139526
train: epoch 117, loss 0.509941816329956, acc=0.7747222185134888, loss=0.509941816329956
test: epoch 117, loss 1.3941624164581299, acc=0.49166667461395264, loss=1.3941624164581299
train: epoch 118, loss 0.5209254026412964, acc=0.773722231388092, loss=0.5209254026412964
test: epoch 118, loss 1.4325708150863647, acc=0.49166667461395264, loss=1.4325708150863647
train: epoch 119, loss 0.5222631692886353, acc=0.773277759552002, loss=0.5222631692886353
test: epoch 119, loss 1.4998012781143188, acc=0.4972222149372101, loss=1.4998012781143188
train: epoch 120, loss 0.5144652724266052, acc=0.7745555639266968, loss=0.5144652724266052
test: epoch 120, loss 1.5224418640136719, acc=0.49166667461395264, loss=1.5224418640136719
train: epoch 121, loss 0.5264835953712463, acc=0.7693333625793457, loss=0.5264835953712463
test: epoch 121, loss 1.4855871200561523, acc=0.49166667461395264, loss=1.4855871200561523
train: epoch 122, loss 0.530018150806427, acc=0.7678889036178589, loss=0.530018150806427
test: epoch 122, loss 1.547067642211914, acc=0.49166667461395264, loss=1.547067642211914
train: epoch 123, loss 0.5399978756904602, acc=0.7691666483879089, loss=0.5399978756904602
test: epoch 123, loss 1.4166022539138794, acc=0.49166667461395264, loss=1.4166022539138794
train: epoch 124, loss 0.5129635334014893, acc=0.7735000252723694, loss=0.5129635334014893
test: epoch 124, loss 1.5893702507019043, acc=0.49166667461395264, loss=1.5893702507019043
train: epoch 125, loss 0.5096433758735657, acc=0.7766666412353516, loss=0.5096433758735657
test: epoch 125, loss 1.6247520446777344, acc=0.49166667461395264, loss=1.6247520446777344
train: epoch 126, loss 0.5260570645332336, acc=0.7678889036178589, loss=0.5260570645332336
test: epoch 126, loss 1.510269045829773, acc=0.49166667461395264, loss=1.510269045829773
train: epoch 127, loss 0.5040135383605957, acc=0.7764444351196289, loss=0.5040135383605957
test: epoch 127, loss 1.5765489339828491, acc=0.49166667461395264, loss=1.5765489339828491
train: epoch 128, loss 0.5110450387001038, acc=0.7777777910232544, loss=0.5110450387001038
test: epoch 128, loss 1.5981853008270264, acc=0.49166667461395264, loss=1.5981853008270264
train: epoch 129, loss 0.5245419144630432, acc=0.7692777514457703, loss=0.5245419144630432
test: epoch 129, loss 1.6347819566726685, acc=0.49166667461395264, loss=1.6347819566726685
train: epoch 130, loss 0.525495171546936, acc=0.7707777619361877, loss=0.525495171546936
test: epoch 130, loss 1.481593132019043, acc=0.49166667461395264, loss=1.481593132019043
train: epoch 131, loss 0.5141968727111816, acc=0.7751666903495789, loss=0.5141968727111816
test: epoch 131, loss 1.6426817178726196, acc=0.49166667461395264, loss=1.6426817178726196
train: epoch 132, loss 0.529036283493042, acc=0.7674444317817688, loss=0.529036283493042
test: epoch 132, loss 1.5486652851104736, acc=0.49166667461395264, loss=1.5486652851104736
train: epoch 133, loss 0.5129761099815369, acc=0.7747222185134888, loss=0.5129761099815369
test: epoch 133, loss 1.4281158447265625, acc=0.49166667461395264, loss=1.4281158447265625
train: epoch 134, loss 0.5067119002342224, acc=0.7747222185134888, loss=0.5067119002342224
test: epoch 134, loss 1.5242388248443604, acc=0.4861111044883728, loss=1.5242388248443604
train: epoch 135, loss 0.5105844736099243, acc=0.7747222185134888, loss=0.5105844736099243
test: epoch 135, loss 1.553969144821167, acc=0.49166667461395264, loss=1.553969144821167
train: epoch 136, loss 0.5207712054252625, acc=0.7736666798591614, loss=0.5207712054252625
test: epoch 136, loss 1.3586933612823486, acc=0.4861111044883728, loss=1.3586933612823486
train: epoch 137, loss 0.5103737711906433, acc=0.7771111130714417, loss=0.5103737711906433
test: epoch 137, loss 1.624193549156189, acc=0.49166667461395264, loss=1.624193549156189
train: epoch 138, loss 0.5111455321311951, acc=0.7752777934074402, loss=0.5111455321311951
test: epoch 138, loss 1.6542803049087524, acc=0.49166667461395264, loss=1.6542803049087524
train: epoch 139, loss 0.5150042772293091, acc=0.7756666541099548, loss=0.5150042772293091
test: epoch 139, loss 1.5135843753814697, acc=0.5, loss=1.5135843753814697
train: epoch 140, loss 0.5178254842758179, acc=0.7733333110809326, loss=0.5178254842758179
test: epoch 140, loss 1.4525483846664429, acc=0.49166667461395264, loss=1.4525483846664429
train: epoch 141, loss 0.5062465667724609, acc=0.7756111025810242, loss=0.5062465667724609
test: epoch 141, loss 1.3314355611801147, acc=0.48055556416511536, loss=1.3314355611801147
train: epoch 142, loss 0.4951890707015991, acc=0.7773333191871643, loss=0.4951890707015991
test: epoch 142, loss 1.7632372379302979, acc=0.49166667461395264, loss=1.7632372379302979
train: epoch 143, loss 0.5231424570083618, acc=0.7730555534362793, loss=0.5231424570083618
test: epoch 143, loss 1.5212002992630005, acc=0.49166667461395264, loss=1.5212002992630005
train: epoch 144, loss 0.5264701247215271, acc=0.765999972820282, loss=0.5264701247215271
test: epoch 144, loss 1.5792254209518433, acc=0.49166667461395264, loss=1.5792254209518433
train: epoch 145, loss 0.506316602230072, acc=0.7771666646003723, loss=0.506316602230072
test: epoch 145, loss 1.5043566226959229, acc=0.49166667461395264, loss=1.5043566226959229
train: epoch 146, loss 0.5206959247589111, acc=0.7706666588783264, loss=0.5206959247589111
test: epoch 146, loss 1.5036938190460205, acc=0.49166667461395264, loss=1.5036938190460205
train: epoch 147, loss 0.4997115433216095, acc=0.7801111340522766, loss=0.4997115433216095
test: epoch 147, loss 1.4939996004104614, acc=0.49166667461395264, loss=1.4939996004104614
train: epoch 148, loss 0.5119213461875916, acc=0.7743333578109741, loss=0.5119213461875916
test: epoch 148, loss 1.6163225173950195, acc=0.49166667461395264, loss=1.6163225173950195
train: epoch 149, loss 0.5050058960914612, acc=0.7728333473205566, loss=0.5050058960914612
test: epoch 149, loss 1.493941307067871, acc=0.49166667461395264, loss=1.493941307067871
train: epoch 150, loss 0.504729688167572, acc=0.7774999737739563, loss=0.504729688167572
test: epoch 150, loss 1.3966861963272095, acc=0.5027777552604675, loss=1.3966861963272095
