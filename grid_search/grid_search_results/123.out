# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=1", "--temp_decay=0.99", "--one_hot=false", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1801879679, receiver_embed_dim=128, temp_decay=0.99, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.4188482761383057, acc=0.052388887852430344, loss=3.4188482761383057
test: epoch 1, loss 2.913313865661621, acc=0.10277777910232544, loss=2.913313865661621
train: epoch 2, loss 2.0712530612945557, acc=0.21888889372348785, loss=2.0712530612945557
test: epoch 2, loss 1.9816901683807373, acc=0.20000000298023224, loss=1.9816901683807373
train: epoch 3, loss 1.6094778776168823, acc=0.3324444591999054, loss=1.6094778776168823
test: epoch 3, loss 1.9211291074752808, acc=0.2222222238779068, loss=1.9211291074752808
train: epoch 4, loss 1.4451810121536255, acc=0.39649999141693115, loss=1.4451810121536255
test: epoch 4, loss 1.9665322303771973, acc=0.2222222238779068, loss=1.9665322303771973
train: epoch 5, loss 1.3358197212219238, acc=0.4389444589614868, loss=1.3358197212219238
test: epoch 5, loss 1.970137596130371, acc=0.2527777850627899, loss=1.970137596130371
train: epoch 6, loss 1.2697447538375854, acc=0.4599444568157196, loss=1.2697447538375854
test: epoch 6, loss 1.9013711214065552, acc=0.25, loss=1.9013711214065552
train: epoch 7, loss 1.2097009420394897, acc=0.4894999861717224, loss=1.2097009420394897
test: epoch 7, loss 1.9468759298324585, acc=0.22777777910232544, loss=1.9468759298324585
train: epoch 8, loss 1.1545836925506592, acc=0.508222222328186, loss=1.1545836925506592
test: epoch 8, loss 1.885797142982483, acc=0.2611111104488373, loss=1.885797142982483
train: epoch 9, loss 1.1261200904846191, acc=0.515666663646698, loss=1.1261200904846191
test: epoch 9, loss 1.9731130599975586, acc=0.24166665971279144, loss=1.9731130599975586
train: epoch 10, loss 1.0925543308258057, acc=0.5264999866485596, loss=1.0925543308258057
test: epoch 10, loss 1.9462758302688599, acc=0.2527777850627899, loss=1.9462758302688599
train: epoch 11, loss 1.072084903717041, acc=0.5379999876022339, loss=1.072084903717041
test: epoch 11, loss 1.825716495513916, acc=0.2750000059604645, loss=1.825716495513916
train: epoch 12, loss 1.0429491996765137, acc=0.5497778058052063, loss=1.0429491996765137
test: epoch 12, loss 1.8839563131332397, acc=0.25833332538604736, loss=1.8839563131332397
train: epoch 13, loss 1.0216987133026123, acc=0.5501111149787903, loss=1.0216987133026123
test: epoch 13, loss 1.8936456441879272, acc=0.2611111104488373, loss=1.8936456441879272
train: epoch 14, loss 1.0165218114852905, acc=0.5577222108840942, loss=1.0165218114852905
test: epoch 14, loss 1.9052656888961792, acc=0.2638888955116272, loss=1.9052656888961792
train: epoch 15, loss 0.9911396503448486, acc=0.5665000081062317, loss=0.9911396503448486
test: epoch 15, loss 1.900715708732605, acc=0.25555557012557983, loss=1.900715708732605
train: epoch 16, loss 0.9764273166656494, acc=0.5643333196640015, loss=0.9764273166656494
test: epoch 16, loss 1.9496768712997437, acc=0.24722221493721008, loss=1.9496768712997437
train: epoch 17, loss 0.9819133281707764, acc=0.5662222504615784, loss=0.9819133281707764
test: epoch 17, loss 2.0089571475982666, acc=0.2527777850627899, loss=2.0089571475982666
train: epoch 18, loss 0.9660217761993408, acc=0.5668888688087463, loss=0.9660217761993408
test: epoch 18, loss 1.9387909173965454, acc=0.25833332538604736, loss=1.9387909173965454
train: epoch 19, loss 0.9476057291030884, acc=0.5770555734634399, loss=0.9476057291030884
test: epoch 19, loss 2.0069730281829834, acc=0.25555557012557983, loss=2.0069730281829834
train: epoch 20, loss 0.9573053121566772, acc=0.569611132144928, loss=0.9573053121566772
test: epoch 20, loss 2.057621955871582, acc=0.2638888955116272, loss=2.057621955871582
train: epoch 21, loss 0.9461719989776611, acc=0.5758888721466064, loss=0.9461719989776611
test: epoch 21, loss 2.0000014305114746, acc=0.25555557012557983, loss=2.0000014305114746
train: epoch 22, loss 0.9524847269058228, acc=0.5748888850212097, loss=0.9524847269058228
test: epoch 22, loss 2.019942045211792, acc=0.2638888955116272, loss=2.019942045211792
train: epoch 23, loss 0.9392244815826416, acc=0.5806111097335815, loss=0.9392244815826416
test: epoch 23, loss 1.9590959548950195, acc=0.2777777910232544, loss=1.9590959548950195
train: epoch 24, loss 0.9470934867858887, acc=0.5716666579246521, loss=0.9470934867858887
test: epoch 24, loss 1.9288978576660156, acc=0.2916666567325592, loss=1.9288978576660156
train: epoch 25, loss 0.9391151070594788, acc=0.5799999833106995, loss=0.9391151070594788
test: epoch 25, loss 2.0074002742767334, acc=0.2777777910232544, loss=2.0074002742767334
train: epoch 26, loss 0.947006106376648, acc=0.5747222304344177, loss=0.947006106376648
test: epoch 26, loss 2.0188181400299072, acc=0.28611111640930176, loss=2.0188181400299072
train: epoch 27, loss 0.9432513117790222, acc=0.5797777771949768, loss=0.9432513117790222
test: epoch 27, loss 1.990852952003479, acc=0.25833332538604736, loss=1.990852952003479
train: epoch 28, loss 0.929575502872467, acc=0.5794444680213928, loss=0.929575502872467
test: epoch 28, loss 1.870612621307373, acc=0.2611111104488373, loss=1.870612621307373
train: epoch 29, loss 0.932550311088562, acc=0.5799999833106995, loss=0.932550311088562
test: epoch 29, loss 2.0820913314819336, acc=0.2638888955116272, loss=2.0820913314819336
train: epoch 30, loss 0.934132993221283, acc=0.578000009059906, loss=0.934132993221283
test: epoch 30, loss 2.0264015197753906, acc=0.2805555462837219, loss=2.0264015197753906
train: epoch 31, loss 0.9217895865440369, acc=0.5802778005599976, loss=0.9217895865440369
test: epoch 31, loss 2.0651824474334717, acc=0.2750000059604645, loss=2.0651824474334717
train: epoch 32, loss 0.9170730710029602, acc=0.585444450378418, loss=0.9170730710029602
test: epoch 32, loss 2.1135778427124023, acc=0.28333333134651184, loss=2.1135778427124023
train: epoch 33, loss 0.9196853637695312, acc=0.5878888964653015, loss=0.9196853637695312
test: epoch 33, loss 2.044490337371826, acc=0.2750000059604645, loss=2.044490337371826
train: epoch 34, loss 0.9182664752006531, acc=0.5866666436195374, loss=0.9182664752006531
test: epoch 34, loss 2.1942076683044434, acc=0.28611111640930176, loss=2.1942076683044434
train: epoch 35, loss 0.9146978259086609, acc=0.5831111073493958, loss=0.9146978259086609
test: epoch 35, loss 2.2388458251953125, acc=0.26944443583488464, loss=2.2388458251953125
train: epoch 36, loss 0.9047147631645203, acc=0.5892778038978577, loss=0.9047147631645203
test: epoch 36, loss 2.036905527114868, acc=0.26944443583488464, loss=2.036905527114868
train: epoch 37, loss 0.9039309024810791, acc=0.589388906955719, loss=0.9039309024810791
test: epoch 37, loss 2.1650025844573975, acc=0.30000001192092896, loss=2.1650025844573975
train: epoch 38, loss 0.8916940093040466, acc=0.5945555567741394, loss=0.8916940093040466
test: epoch 38, loss 1.9626233577728271, acc=0.30000001192092896, loss=1.9626233577728271
train: epoch 39, loss 0.9042584300041199, acc=0.5904444456100464, loss=0.9042584300041199
test: epoch 39, loss 2.1633663177490234, acc=0.29722222685813904, loss=2.1633663177490234
train: epoch 40, loss 0.8772953152656555, acc=0.5953333377838135, loss=0.8772953152656555
test: epoch 40, loss 2.002711534500122, acc=0.2944444417953491, loss=2.002711534500122
train: epoch 41, loss 0.8800865411758423, acc=0.5978888869285583, loss=0.8800865411758423
test: epoch 41, loss 2.0412275791168213, acc=0.30000001192092896, loss=2.0412275791168213
train: epoch 42, loss 0.8789898157119751, acc=0.6030555367469788, loss=0.8789898157119751
test: epoch 42, loss 2.2229912281036377, acc=0.2916666567325592, loss=2.2229912281036377
train: epoch 43, loss 0.8739766478538513, acc=0.5985000133514404, loss=0.8739766478538513
test: epoch 43, loss 2.112039804458618, acc=0.29722222685813904, loss=2.112039804458618
train: epoch 44, loss 0.8678647875785828, acc=0.6075555682182312, loss=0.8678647875785828
test: epoch 44, loss 2.085357427597046, acc=0.3027777671813965, loss=2.085357427597046
train: epoch 45, loss 0.8680294752120972, acc=0.6071110963821411, loss=0.8680294752120972
test: epoch 45, loss 2.0650429725646973, acc=0.30000001192092896, loss=2.0650429725646973
train: epoch 46, loss 0.8597016334533691, acc=0.6042777895927429, loss=0.8597016334533691
test: epoch 46, loss 2.5191352367401123, acc=0.30000001192092896, loss=2.5191352367401123
train: epoch 47, loss 0.8710319995880127, acc=0.6013888716697693, loss=0.8710319995880127
test: epoch 47, loss 2.131619930267334, acc=0.3083333373069763, loss=2.131619930267334
train: epoch 48, loss 0.8521524667739868, acc=0.6092222332954407, loss=0.8521524667739868
test: epoch 48, loss 2.1870994567871094, acc=0.28611111640930176, loss=2.1870994567871094
train: epoch 49, loss 0.8516198992729187, acc=0.6079444289207458, loss=0.8516198992729187
test: epoch 49, loss 2.2680790424346924, acc=0.2916666567325592, loss=2.2680790424346924
train: epoch 50, loss 0.8457752466201782, acc=0.6079444289207458, loss=0.8457752466201782
test: epoch 50, loss 2.076622486114502, acc=0.2944444417953491, loss=2.076622486114502
train: epoch 51, loss 0.8497326374053955, acc=0.6109444499015808, loss=0.8497326374053955
test: epoch 51, loss 2.324582099914551, acc=0.2944444417953491, loss=2.324582099914551
train: epoch 52, loss 0.868288516998291, acc=0.6065000295639038, loss=0.868288516998291
test: epoch 52, loss 2.225377321243286, acc=0.3083333373069763, loss=2.225377321243286
train: epoch 53, loss 0.8431888222694397, acc=0.6146110892295837, loss=0.8431888222694397
test: epoch 53, loss 2.0880019664764404, acc=0.2805555462837219, loss=2.0880019664764404
train: epoch 54, loss 0.8501733541488647, acc=0.6078333258628845, loss=0.8501733541488647
test: epoch 54, loss 2.3305981159210205, acc=0.2916666567325592, loss=2.3305981159210205
train: epoch 55, loss 0.8578898906707764, acc=0.6066111326217651, loss=0.8578898906707764
test: epoch 55, loss 2.069751739501953, acc=0.3027777671813965, loss=2.069751739501953
train: epoch 56, loss 0.8409466743469238, acc=0.6121110916137695, loss=0.8409466743469238
test: epoch 56, loss 2.292752504348755, acc=0.3083333373069763, loss=2.292752504348755
train: epoch 57, loss 0.8447209000587463, acc=0.6111111044883728, loss=0.8447209000587463
test: epoch 57, loss 2.182335376739502, acc=0.29722222685813904, loss=2.182335376739502
train: epoch 58, loss 0.8451182842254639, acc=0.6113888621330261, loss=0.8451182842254639
test: epoch 58, loss 2.092172622680664, acc=0.2944444417953491, loss=2.092172622680664
train: epoch 59, loss 0.8388676047325134, acc=0.6122221946716309, loss=0.8388676047325134
test: epoch 59, loss 2.107243537902832, acc=0.3055555522441864, loss=2.107243537902832
train: epoch 60, loss 0.8387226462364197, acc=0.6130555272102356, loss=0.8387226462364197
test: epoch 60, loss 2.149785041809082, acc=0.31111112236976624, loss=2.149785041809082
train: epoch 61, loss 0.8285396695137024, acc=0.6133888959884644, loss=0.8285396695137024
test: epoch 61, loss 2.230604887008667, acc=0.3055555522441864, loss=2.230604887008667
train: epoch 62, loss 0.8305560350418091, acc=0.6108333468437195, loss=0.8305560350418091
test: epoch 62, loss 2.248037338256836, acc=0.3083333373069763, loss=2.248037338256836
train: epoch 63, loss 0.8276607990264893, acc=0.6166666746139526, loss=0.8276607990264893
test: epoch 63, loss 2.3965799808502197, acc=0.3055555522441864, loss=2.3965799808502197
train: epoch 64, loss 0.8217707872390747, acc=0.6188889145851135, loss=0.8217707872390747
test: epoch 64, loss 2.5754482746124268, acc=0.31388887763023376, loss=2.5754482746124268
train: epoch 65, loss 0.8406116366386414, acc=0.6128333210945129, loss=0.8406116366386414
test: epoch 65, loss 2.31412410736084, acc=0.3083333373069763, loss=2.31412410736084
train: epoch 66, loss 0.8344137668609619, acc=0.6194444298744202, loss=0.8344137668609619
test: epoch 66, loss 2.2080435752868652, acc=0.3083333373069763, loss=2.2080435752868652
train: epoch 67, loss 0.8267074823379517, acc=0.6188333630561829, loss=0.8267074823379517
test: epoch 67, loss 2.215735912322998, acc=0.31388887763023376, loss=2.215735912322998
train: epoch 68, loss 0.8226196765899658, acc=0.6202222108840942, loss=0.8226196765899658
test: epoch 68, loss 2.16866397857666, acc=0.3166666626930237, loss=2.16866397857666
train: epoch 69, loss 0.8270366191864014, acc=0.6206666827201843, loss=0.8270366191864014
test: epoch 69, loss 2.131418466567993, acc=0.3083333373069763, loss=2.131418466567993
train: epoch 70, loss 0.8133466839790344, acc=0.6234999895095825, loss=0.8133466839790344
test: epoch 70, loss 2.1927096843719482, acc=0.3055555522441864, loss=2.1927096843719482
train: epoch 71, loss 0.82435142993927, acc=0.6192222237586975, loss=0.82435142993927
test: epoch 71, loss 2.1366944313049316, acc=0.2944444417953491, loss=2.1366944313049316
train: epoch 72, loss 0.824413001537323, acc=0.617111086845398, loss=0.824413001537323
test: epoch 72, loss 2.220740556716919, acc=0.3083333373069763, loss=2.220740556716919
train: epoch 73, loss 0.8407280445098877, acc=0.6113333106040955, loss=0.8407280445098877
test: epoch 73, loss 2.470991849899292, acc=0.2805555462837219, loss=2.470991849899292
train: epoch 74, loss 0.8173555731773376, acc=0.6202222108840942, loss=0.8173555731773376
test: epoch 74, loss 2.284590244293213, acc=0.3083333373069763, loss=2.284590244293213
train: epoch 75, loss 0.8241793513298035, acc=0.6146666407585144, loss=0.8241793513298035
test: epoch 75, loss 2.2036995887756348, acc=0.31111112236976624, loss=2.2036995887756348
train: epoch 76, loss 0.8293889164924622, acc=0.6159444451332092, loss=0.8293889164924622
test: epoch 76, loss 2.287864923477173, acc=0.3083333373069763, loss=2.287864923477173
train: epoch 77, loss 0.8216143250465393, acc=0.616611123085022, loss=0.8216143250465393
test: epoch 77, loss 2.1980934143066406, acc=0.29722222685813904, loss=2.1980934143066406
train: epoch 78, loss 0.813940167427063, acc=0.6183888912200928, loss=0.813940167427063
test: epoch 78, loss 2.11415696144104, acc=0.3027777671813965, loss=2.11415696144104
train: epoch 79, loss 0.8142262697219849, acc=0.6201666593551636, loss=0.8142262697219849
test: epoch 79, loss 2.196075916290283, acc=0.2944444417953491, loss=2.196075916290283
train: epoch 80, loss 0.8155732154846191, acc=0.6228888630867004, loss=0.8155732154846191
test: epoch 80, loss 2.276076555252075, acc=0.31111112236976624, loss=2.276076555252075
train: epoch 81, loss 0.8059541583061218, acc=0.6209999918937683, loss=0.8059541583061218
test: epoch 81, loss 2.3168652057647705, acc=0.31111112236976624, loss=2.3168652057647705
train: epoch 82, loss 0.8147100210189819, acc=0.6208333373069763, loss=0.8147100210189819
test: epoch 82, loss 2.2760586738586426, acc=0.2944444417953491, loss=2.2760586738586426
train: epoch 83, loss 0.8121474385261536, acc=0.6198333501815796, loss=0.8121474385261536
test: epoch 83, loss 2.1863906383514404, acc=0.3222222328186035, loss=2.1863906383514404
train: epoch 84, loss 0.8145850300788879, acc=0.6155555844306946, loss=0.8145850300788879
test: epoch 84, loss 2.2540371417999268, acc=0.31111112236976624, loss=2.2540371417999268
train: epoch 85, loss 0.8218677639961243, acc=0.6186666488647461, loss=0.8218677639961243
test: epoch 85, loss 2.2360711097717285, acc=0.3166666626930237, loss=2.2360711097717285
train: epoch 86, loss 0.8010772466659546, acc=0.6257777810096741, loss=0.8010772466659546
test: epoch 86, loss 2.028662919998169, acc=0.3055555522441864, loss=2.028662919998169
train: epoch 87, loss 0.8155398368835449, acc=0.6218888759613037, loss=0.8155398368835449
test: epoch 87, loss 2.198467969894409, acc=0.3166666626930237, loss=2.198467969894409
train: epoch 88, loss 0.8083739876747131, acc=0.6223888993263245, loss=0.8083739876747131
test: epoch 88, loss 2.2342844009399414, acc=0.3083333373069763, loss=2.2342844009399414
train: epoch 89, loss 0.7974633574485779, acc=0.6246111392974854, loss=0.7974633574485779
test: epoch 89, loss 2.3365180492401123, acc=0.30000001192092896, loss=2.3365180492401123
train: epoch 90, loss 0.8184992671012878, acc=0.6194444298744202, loss=0.8184992671012878
test: epoch 90, loss 2.2900872230529785, acc=0.31111112236976624, loss=2.2900872230529785
train: epoch 91, loss 0.8138439059257507, acc=0.6190555691719055, loss=0.8138439059257507
test: epoch 91, loss 2.1410176753997803, acc=0.31388887763023376, loss=2.1410176753997803
train: epoch 92, loss 0.807688295841217, acc=0.6241111159324646, loss=0.807688295841217
test: epoch 92, loss 2.2273342609405518, acc=0.3166666626930237, loss=2.2273342609405518
train: epoch 93, loss 0.8057906031608582, acc=0.6207777857780457, loss=0.8057906031608582
test: epoch 93, loss 2.2801530361175537, acc=0.30000001192092896, loss=2.2801530361175537
train: epoch 94, loss 0.7979146838188171, acc=0.6252777576446533, loss=0.7979146838188171
test: epoch 94, loss 2.4634411334991455, acc=0.2888889014720917, loss=2.4634411334991455
train: epoch 95, loss 0.813602089881897, acc=0.6225000023841858, loss=0.813602089881897
test: epoch 95, loss 2.2507779598236084, acc=0.31388887763023376, loss=2.2507779598236084
train: epoch 96, loss 0.8112162351608276, acc=0.6245555281639099, loss=0.8112162351608276
test: epoch 96, loss 2.1270241737365723, acc=0.30000001192092896, loss=2.1270241737365723
train: epoch 97, loss 0.8008917570114136, acc=0.6278333067893982, loss=0.8008917570114136
test: epoch 97, loss 2.3074090480804443, acc=0.2944444417953491, loss=2.3074090480804443
train: epoch 98, loss 0.8053744435310364, acc=0.621833324432373, loss=0.8053744435310364
test: epoch 98, loss 2.2402703762054443, acc=0.31388887763023376, loss=2.2402703762054443
train: epoch 99, loss 0.8131183385848999, acc=0.6268333196640015, loss=0.8131183385848999
test: epoch 99, loss 2.4101901054382324, acc=0.31388887763023376, loss=2.4101901054382324
train: epoch 100, loss 0.7964272499084473, acc=0.6231666803359985, loss=0.7964272499084473
test: epoch 100, loss 2.457414388656616, acc=0.29722222685813904, loss=2.457414388656616
train: epoch 101, loss 0.8062072992324829, acc=0.624666690826416, loss=0.8062072992324829
test: epoch 101, loss 2.2061076164245605, acc=0.3222222328186035, loss=2.2061076164245605
train: epoch 102, loss 0.7908535599708557, acc=0.6273333430290222, loss=0.7908535599708557
test: epoch 102, loss 2.1786699295043945, acc=0.32499998807907104, loss=2.1786699295043945
train: epoch 103, loss 0.7990128993988037, acc=0.6252222061157227, loss=0.7990128993988037
test: epoch 103, loss 2.282127618789673, acc=0.3194444477558136, loss=2.282127618789673
train: epoch 104, loss 0.7907004952430725, acc=0.6275555491447449, loss=0.7907004952430725
test: epoch 104, loss 2.1596198081970215, acc=0.3083333373069763, loss=2.1596198081970215
train: epoch 105, loss 0.7972865104675293, acc=0.625, loss=0.7972865104675293
test: epoch 105, loss 2.2162363529205322, acc=0.30000001192092896, loss=2.2162363529205322
train: epoch 106, loss 0.8064084053039551, acc=0.6198889017105103, loss=0.8064084053039551
test: epoch 106, loss 2.3669004440307617, acc=0.30000001192092896, loss=2.3669004440307617
train: epoch 107, loss 0.7960187196731567, acc=0.6257777810096741, loss=0.7960187196731567
test: epoch 107, loss 2.1335859298706055, acc=0.3055555522441864, loss=2.1335859298706055
train: epoch 108, loss 0.7946776151657104, acc=0.6282222270965576, loss=0.7946776151657104
test: epoch 108, loss 2.2020769119262695, acc=0.3222222328186035, loss=2.2020769119262695
train: epoch 109, loss 0.7860455513000488, acc=0.6317222118377686, loss=0.7860455513000488
test: epoch 109, loss 2.346492052078247, acc=0.29722222685813904, loss=2.346492052078247
train: epoch 110, loss 0.7933017015457153, acc=0.6305555701255798, loss=0.7933017015457153
test: epoch 110, loss 2.304534673690796, acc=0.31388887763023376, loss=2.304534673690796
train: epoch 111, loss 0.7940369248390198, acc=0.6228333115577698, loss=0.7940369248390198
test: epoch 111, loss 2.1358561515808105, acc=0.3055555522441864, loss=2.1358561515808105
train: epoch 112, loss 0.790014386177063, acc=0.6284999847412109, loss=0.790014386177063
test: epoch 112, loss 2.354815721511841, acc=0.31111112236976624, loss=2.354815721511841
train: epoch 113, loss 0.79097580909729, acc=0.6276666522026062, loss=0.79097580909729
test: epoch 113, loss 2.4573683738708496, acc=0.32499998807907104, loss=2.4573683738708496
train: epoch 114, loss 0.7872571349143982, acc=0.6252777576446533, loss=0.7872571349143982
test: epoch 114, loss 2.178277015686035, acc=0.31388887763023376, loss=2.178277015686035
train: epoch 115, loss 0.7793600559234619, acc=0.6347222328186035, loss=0.7793600559234619
test: epoch 115, loss 2.459566593170166, acc=0.2916666567325592, loss=2.459566593170166
train: epoch 116, loss 0.7839232683181763, acc=0.6315000057220459, loss=0.7839232683181763
test: epoch 116, loss 2.423431396484375, acc=0.30000001192092896, loss=2.423431396484375
train: epoch 117, loss 0.7799854874610901, acc=0.6332777738571167, loss=0.7799854874610901
test: epoch 117, loss 2.333770990371704, acc=0.3194444477558136, loss=2.333770990371704
train: epoch 118, loss 0.7876447439193726, acc=0.6302222013473511, loss=0.7876447439193726
test: epoch 118, loss 2.271688222885132, acc=0.3166666626930237, loss=2.271688222885132
train: epoch 119, loss 0.7829989194869995, acc=0.6341666579246521, loss=0.7829989194869995
test: epoch 119, loss 2.223700761795044, acc=0.31111112236976624, loss=2.223700761795044
train: epoch 120, loss 0.7881899476051331, acc=0.6330000162124634, loss=0.7881899476051331
test: epoch 120, loss 2.1574878692626953, acc=0.3083333373069763, loss=2.1574878692626953
train: epoch 121, loss 0.7850127816200256, acc=0.6297777891159058, loss=0.7850127816200256
test: epoch 121, loss 2.0978193283081055, acc=0.3083333373069763, loss=2.0978193283081055
train: epoch 122, loss 0.7810258269309998, acc=0.6352221965789795, loss=0.7810258269309998
test: epoch 122, loss 2.168447732925415, acc=0.31111112236976624, loss=2.168447732925415
train: epoch 123, loss 0.7871822714805603, acc=0.6342777609825134, loss=0.7871822714805603
test: epoch 123, loss 2.3193471431732178, acc=0.3166666626930237, loss=2.3193471431732178
train: epoch 124, loss 0.7787554860115051, acc=0.6346666812896729, loss=0.7787554860115051
test: epoch 124, loss 2.350754737854004, acc=0.3027777671813965, loss=2.350754737854004
train: epoch 125, loss 0.7844482660293579, acc=0.6316111087799072, loss=0.7844482660293579
test: epoch 125, loss 2.3055365085601807, acc=0.31388887763023376, loss=2.3055365085601807
train: epoch 126, loss 0.7813552618026733, acc=0.6340000033378601, loss=0.7813552618026733
test: epoch 126, loss 2.2545511722564697, acc=0.30000001192092896, loss=2.2545511722564697
train: epoch 127, loss 0.7858334183692932, acc=0.6342777609825134, loss=0.7858334183692932
test: epoch 127, loss 2.260118246078491, acc=0.31388887763023376, loss=2.260118246078491
train: epoch 128, loss 0.7862148880958557, acc=0.633222222328186, loss=0.7862148880958557
test: epoch 128, loss 2.3919074535369873, acc=0.32499998807907104, loss=2.3919074535369873
train: epoch 129, loss 0.7690649628639221, acc=0.6373888850212097, loss=0.7690649628639221
test: epoch 129, loss 2.138162851333618, acc=0.30000001192092896, loss=2.138162851333618
train: epoch 130, loss 0.7765371203422546, acc=0.6390555500984192, loss=0.7765371203422546
test: epoch 130, loss 2.0968401432037354, acc=0.3083333373069763, loss=2.0968401432037354
train: epoch 131, loss 0.7789608240127563, acc=0.6334444284439087, loss=0.7789608240127563
test: epoch 131, loss 2.2095913887023926, acc=0.3055555522441864, loss=2.2095913887023926
train: epoch 132, loss 0.7722066640853882, acc=0.6359444260597229, loss=0.7722066640853882
test: epoch 132, loss 2.0908122062683105, acc=0.31111112236976624, loss=2.0908122062683105
train: epoch 133, loss 0.7699057459831238, acc=0.6397222280502319, loss=0.7699057459831238
test: epoch 133, loss 2.3067164421081543, acc=0.31111112236976624, loss=2.3067164421081543
train: epoch 134, loss 0.7685727477073669, acc=0.6407222151756287, loss=0.7685727477073669
test: epoch 134, loss 2.2379605770111084, acc=0.3222222328186035, loss=2.2379605770111084
train: epoch 135, loss 0.7755995392799377, acc=0.637333333492279, loss=0.7755995392799377
test: epoch 135, loss 2.1674444675445557, acc=0.3222222328186035, loss=2.1674444675445557
train: epoch 136, loss 0.7723408341407776, acc=0.6355000138282776, loss=0.7723408341407776
test: epoch 136, loss 1.996152400970459, acc=0.3222222328186035, loss=1.996152400970459
train: epoch 137, loss 0.7795969247817993, acc=0.6389999985694885, loss=0.7795969247817993
test: epoch 137, loss 2.1193602085113525, acc=0.3194444477558136, loss=2.1193602085113525
train: epoch 138, loss 0.7681543231010437, acc=0.6383333206176758, loss=0.7681543231010437
test: epoch 138, loss 2.306243896484375, acc=0.3194444477558136, loss=2.306243896484375
train: epoch 139, loss 0.7716471552848816, acc=0.6342777609825134, loss=0.7716471552848816
test: epoch 139, loss 2.2477145195007324, acc=0.32777777314186096, loss=2.2477145195007324
train: epoch 140, loss 0.7834219336509705, acc=0.6331666707992554, loss=0.7834219336509705
test: epoch 140, loss 2.051957130432129, acc=0.3222222328186035, loss=2.051957130432129
train: epoch 141, loss 0.758963406085968, acc=0.6439444422721863, loss=0.758963406085968
test: epoch 141, loss 2.377166748046875, acc=0.3166666626930237, loss=2.377166748046875
train: epoch 142, loss 0.7633504867553711, acc=0.6397222280502319, loss=0.7633504867553711
test: epoch 142, loss 2.146001100540161, acc=0.3027777671813965, loss=2.146001100540161
train: epoch 143, loss 0.7721166014671326, acc=0.6346111297607422, loss=0.7721166014671326
test: epoch 143, loss 2.1934056282043457, acc=0.3166666626930237, loss=2.1934056282043457
train: epoch 144, loss 0.7761780023574829, acc=0.6397777795791626, loss=0.7761780023574829
test: epoch 144, loss 2.3349804878234863, acc=0.3333333432674408, loss=2.3349804878234863
train: epoch 145, loss 0.7714699506759644, acc=0.636388897895813, loss=0.7714699506759644
test: epoch 145, loss 2.0742075443267822, acc=0.3222222328186035, loss=2.0742075443267822
train: epoch 146, loss 0.7639079093933105, acc=0.6416110992431641, loss=0.7639079093933105
test: epoch 146, loss 2.2418158054351807, acc=0.31388887763023376, loss=2.2418158054351807
train: epoch 147, loss 0.7651230692863464, acc=0.6360555291175842, loss=0.7651230692863464
test: epoch 147, loss 2.2723443508148193, acc=0.3222222328186035, loss=2.2723443508148193
train: epoch 148, loss 0.7695283889770508, acc=0.6390555500984192, loss=0.7695283889770508
test: epoch 148, loss 2.2619950771331787, acc=0.3166666626930237, loss=2.2619950771331787
train: epoch 149, loss 0.7606859803199768, acc=0.6453333497047424, loss=0.7606859803199768
test: epoch 149, loss 2.2924704551696777, acc=0.3222222328186035, loss=2.2924704551696777
train: epoch 150, loss 0.762047529220581, acc=0.6360555291175842, loss=0.762047529220581
test: epoch 150, loss 2.254364490509033, acc=0.3194444477558136, loss=2.254364490509033
