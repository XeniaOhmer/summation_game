# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=true", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1259712700, receiver_embed_dim=128, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.0670924186706543, acc=0.08633333444595337, loss=3.0670924186706543
test: epoch 1, loss 2.865813970565796, acc=0.11388888955116272, loss=2.865813970565796
train: epoch 2, loss 1.7368144989013672, acc=0.2989444434642792, loss=1.7368144989013672
test: epoch 2, loss 2.55837082862854, acc=0.16944444179534912, loss=2.55837082862854
train: epoch 3, loss 1.3988569974899292, acc=0.41499999165534973, loss=1.3988569974899292
test: epoch 3, loss 2.552111864089966, acc=0.1805555522441864, loss=2.552111864089966
train: epoch 4, loss 1.2310631275177002, acc=0.4937777817249298, loss=1.2310631275177002
test: epoch 4, loss 2.498274087905884, acc=0.21666666865348816, loss=2.498274087905884
train: epoch 5, loss 1.1147361993789673, acc=0.5394999980926514, loss=1.1147361993789673
test: epoch 5, loss 2.3989152908325195, acc=0.2083333283662796, loss=2.3989152908325195
train: epoch 6, loss 1.021498441696167, acc=0.5816666483879089, loss=1.021498441696167
test: epoch 6, loss 2.1008875370025635, acc=0.20277777314186096, loss=2.1008875370025635
train: epoch 7, loss 0.9437708258628845, acc=0.6187777519226074, loss=0.9437708258628845
test: epoch 7, loss 1.9698697328567505, acc=0.2805555462837219, loss=1.9698697328567505
train: epoch 8, loss 0.8801197409629822, acc=0.6461111307144165, loss=0.8801197409629822
test: epoch 8, loss 1.9488106966018677, acc=0.2611111104488373, loss=1.9488106966018677
train: epoch 9, loss 0.8190954327583313, acc=0.6758888959884644, loss=0.8190954327583313
test: epoch 9, loss 2.0481724739074707, acc=0.2805555462837219, loss=2.0481724739074707
train: epoch 10, loss 0.7655070424079895, acc=0.703499972820282, loss=0.7655070424079895
test: epoch 10, loss 1.889431357383728, acc=0.28611111640930176, loss=1.889431357383728
train: epoch 11, loss 0.729654848575592, acc=0.714555561542511, loss=0.729654848575592
test: epoch 11, loss 1.7605020999908447, acc=0.3305555582046509, loss=1.7605020999908447
train: epoch 12, loss 0.6838301420211792, acc=0.7370555400848389, loss=0.6838301420211792
test: epoch 12, loss 1.8046352863311768, acc=0.3083333373069763, loss=1.8046352863311768
train: epoch 13, loss 0.6322442889213562, acc=0.7598888874053955, loss=0.6322442889213562
test: epoch 13, loss 1.8572652339935303, acc=0.2805555462837219, loss=1.8572652339935303
train: epoch 14, loss 0.612429141998291, acc=0.7645000219345093, loss=0.612429141998291
test: epoch 14, loss 2.0363898277282715, acc=0.31111112236976624, loss=2.0363898277282715
train: epoch 15, loss 0.5703617930412292, acc=0.7862222194671631, loss=0.5703617930412292
test: epoch 15, loss 2.018430709838867, acc=0.3305555582046509, loss=2.018430709838867
train: epoch 16, loss 0.539829432964325, acc=0.7976111173629761, loss=0.539829432964325
test: epoch 16, loss 1.9070693254470825, acc=0.3444444537162781, loss=1.9070693254470825
train: epoch 17, loss 0.5120834708213806, acc=0.8066666722297668, loss=0.5120834708213806
test: epoch 17, loss 1.9061920642852783, acc=0.35277777910232544, loss=1.9061920642852783
train: epoch 18, loss 0.4817292094230652, acc=0.8177777528762817, loss=0.4817292094230652
test: epoch 18, loss 1.915681004524231, acc=0.35555556416511536, loss=1.915681004524231
train: epoch 19, loss 0.4471737742424011, acc=0.8291110992431641, loss=0.4471737742424011
test: epoch 19, loss 2.0223731994628906, acc=0.36944442987442017, loss=2.0223731994628906
train: epoch 20, loss 0.43918028473854065, acc=0.8373333215713501, loss=0.43918028473854065
test: epoch 20, loss 1.9925137758255005, acc=0.375, loss=1.9925137758255005
train: epoch 21, loss 0.41091060638427734, acc=0.8487222194671631, loss=0.41091060638427734
test: epoch 21, loss 1.9520491361618042, acc=0.4055555462837219, loss=1.9520491361618042
train: epoch 22, loss 0.3917566239833832, acc=0.8577222228050232, loss=0.3917566239833832
test: epoch 22, loss 1.9614284038543701, acc=0.39722222089767456, loss=1.9614284038543701
train: epoch 23, loss 0.3753332495689392, acc=0.8627777695655823, loss=0.3753332495689392
test: epoch 23, loss 2.0144731998443604, acc=0.42500001192092896, loss=2.0144731998443604
train: epoch 24, loss 0.3727697730064392, acc=0.8646666407585144, loss=0.3727697730064392
test: epoch 24, loss 2.042482852935791, acc=0.4055555462837219, loss=2.042482852935791
train: epoch 25, loss 0.3471176326274872, acc=0.8764444589614868, loss=0.3471176326274872
test: epoch 25, loss 2.0550596714019775, acc=0.43611112236976624, loss=2.0550596714019775
train: epoch 26, loss 0.3423158526420593, acc=0.8751111030578613, loss=0.3423158526420593
test: epoch 26, loss 2.1322596073150635, acc=0.39444443583488464, loss=2.1322596073150635
train: epoch 27, loss 0.31899765133857727, acc=0.8882222175598145, loss=0.31899765133857727
test: epoch 27, loss 2.015491247177124, acc=0.43888887763023376, loss=2.015491247177124
train: epoch 28, loss 0.31946998834609985, acc=0.8880000114440918, loss=0.31946998834609985
test: epoch 28, loss 2.2667226791381836, acc=0.3861111104488373, loss=2.2667226791381836
train: epoch 29, loss 0.31288424134254456, acc=0.890666663646698, loss=0.31288424134254456
test: epoch 29, loss 2.070363998413086, acc=0.39722222089767456, loss=2.070363998413086
train: epoch 30, loss 0.2921597957611084, acc=0.8981666564941406, loss=0.2921597957611084
test: epoch 30, loss 2.1160898208618164, acc=0.39722222089767456, loss=2.1160898208618164
train: epoch 31, loss 0.2890496850013733, acc=0.8996666669845581, loss=0.2890496850013733
test: epoch 31, loss 2.040355920791626, acc=0.4583333432674408, loss=2.040355920791626
train: epoch 32, loss 0.2875434458255768, acc=0.9018333554267883, loss=0.2875434458255768
test: epoch 32, loss 1.7954638004302979, acc=0.5027777552604675, loss=1.7954638004302979
train: epoch 33, loss 0.28195810317993164, acc=0.9016666412353516, loss=0.28195810317993164
test: epoch 33, loss 1.8766511678695679, acc=0.44999998807907104, loss=1.8766511678695679
train: epoch 34, loss 0.2790955603122711, acc=0.9052777886390686, loss=0.2790955603122711
test: epoch 34, loss 2.3164350986480713, acc=0.4472222328186035, loss=2.3164350986480713
train: epoch 35, loss 0.2604818046092987, acc=0.9122777581214905, loss=0.2604818046092987
test: epoch 35, loss 2.2941277027130127, acc=0.4555555582046509, loss=2.2941277027130127
train: epoch 36, loss 0.26433688402175903, acc=0.9076111316680908, loss=0.26433688402175903
test: epoch 36, loss 2.0440895557403564, acc=0.5, loss=2.0440895557403564
train: epoch 37, loss 0.25080350041389465, acc=0.9118333458900452, loss=0.25080350041389465
test: epoch 37, loss 2.209956169128418, acc=0.4833333194255829, loss=2.209956169128418
train: epoch 38, loss 0.2533532381057739, acc=0.9132221937179565, loss=0.2533532381057739
test: epoch 38, loss 2.133589744567871, acc=0.4722222089767456, loss=2.133589744567871
train: epoch 39, loss 0.2504606246948242, acc=0.9131666421890259, loss=0.2504606246948242
test: epoch 39, loss 2.186692237854004, acc=0.4861111044883728, loss=2.186692237854004
train: epoch 40, loss 0.24736452102661133, acc=0.9127222299575806, loss=0.24736452102661133
test: epoch 40, loss 2.2119884490966797, acc=0.4555555582046509, loss=2.2119884490966797
train: epoch 41, loss 0.23909921944141388, acc=0.9173333048820496, loss=0.23909921944141388
test: epoch 41, loss 2.1371376514434814, acc=0.4888888895511627, loss=2.1371376514434814
train: epoch 42, loss 0.2441778928041458, acc=0.9136666655540466, loss=0.2441778928041458
test: epoch 42, loss 1.9838367700576782, acc=0.5, loss=1.9838367700576782
train: epoch 43, loss 0.24141426384449005, acc=0.9163888692855835, loss=0.24141426384449005
test: epoch 43, loss 2.1787078380584717, acc=0.44999998807907104, loss=2.1787078380584717
train: epoch 44, loss 0.24030089378356934, acc=0.9171110987663269, loss=0.24030089378356934
test: epoch 44, loss 2.005763053894043, acc=0.5027777552604675, loss=2.005763053894043
train: epoch 45, loss 0.23966622352600098, acc=0.9144444465637207, loss=0.23966622352600098
test: epoch 45, loss 1.9478185176849365, acc=0.46666666865348816, loss=1.9478185176849365
train: epoch 46, loss 0.22499950230121613, acc=0.9209444522857666, loss=0.22499950230121613
test: epoch 46, loss 1.9505051374435425, acc=0.4861111044883728, loss=1.9505051374435425
train: epoch 47, loss 0.22770336270332336, acc=0.9188888669013977, loss=0.22770336270332336
test: epoch 47, loss 1.8822788000106812, acc=0.5027777552604675, loss=1.8822788000106812
train: epoch 48, loss 0.2177116423845291, acc=0.9219444394111633, loss=0.2177116423845291
test: epoch 48, loss 1.8382158279418945, acc=0.5416666865348816, loss=1.8382158279418945
train: epoch 49, loss 0.21850743889808655, acc=0.9226666688919067, loss=0.21850743889808655
test: epoch 49, loss 1.8450056314468384, acc=0.4861111044883728, loss=1.8450056314468384
train: epoch 50, loss 0.21463647484779358, acc=0.9278333187103271, loss=0.21463647484779358
test: epoch 50, loss 2.136482000350952, acc=0.47777777910232544, loss=2.136482000350952
train: epoch 51, loss 0.22312547266483307, acc=0.9222777485847473, loss=0.22312547266483307
test: epoch 51, loss 2.0051937103271484, acc=0.5083333253860474, loss=2.0051937103271484
train: epoch 52, loss 0.21026496589183807, acc=0.9275000095367432, loss=0.21026496589183807
test: epoch 52, loss 2.1632022857666016, acc=0.5, loss=2.1632022857666016
train: epoch 53, loss 0.22111037373542786, acc=0.9231111407279968, loss=0.22111037373542786
test: epoch 53, loss 2.1615729331970215, acc=0.5, loss=2.1615729331970215
train: epoch 54, loss 0.2195367068052292, acc=0.9235555529594421, loss=0.2195367068052292
test: epoch 54, loss 1.7742092609405518, acc=0.5361111164093018, loss=1.7742092609405518
train: epoch 55, loss 0.19779422879219055, acc=0.9299444556236267, loss=0.19779422879219055
test: epoch 55, loss 2.08616042137146, acc=0.4888888895511627, loss=2.08616042137146
train: epoch 56, loss 0.21337446570396423, acc=0.9246666431427002, loss=0.21337446570396423
test: epoch 56, loss 1.815653920173645, acc=0.5277777910232544, loss=1.815653920173645
train: epoch 57, loss 0.21960872411727905, acc=0.9238888621330261, loss=0.21960872411727905
test: epoch 57, loss 1.7793434858322144, acc=0.5138888955116272, loss=1.7793434858322144
train: epoch 58, loss 0.20590835809707642, acc=0.9283333420753479, loss=0.20590835809707642
test: epoch 58, loss 1.8181825876235962, acc=0.5416666865348816, loss=1.8181825876235962
train: epoch 59, loss 0.21479645371437073, acc=0.9250555634498596, loss=0.21479645371437073
test: epoch 59, loss 2.068126916885376, acc=0.5083333253860474, loss=2.068126916885376
train: epoch 60, loss 0.21285408735275269, acc=0.9246110916137695, loss=0.21285408735275269
test: epoch 60, loss 1.9104090929031372, acc=0.5138888955116272, loss=1.9104090929031372
train: epoch 61, loss 0.20935505628585815, acc=0.9268888831138611, loss=0.20935505628585815
test: epoch 61, loss 1.7026041746139526, acc=0.5111111402511597, loss=1.7026041746139526
train: epoch 62, loss 0.20555903017520905, acc=0.9281111359596252, loss=0.20555903017520905
test: epoch 62, loss 1.733237385749817, acc=0.5305555462837219, loss=1.733237385749817
train: epoch 63, loss 0.2008170336484909, acc=0.9256666898727417, loss=0.2008170336484909
test: epoch 63, loss 1.8108646869659424, acc=0.5305555462837219, loss=1.8108646869659424
train: epoch 64, loss 0.20331528782844543, acc=0.9264444708824158, loss=0.20331528782844543
test: epoch 64, loss 1.9210573434829712, acc=0.5416666865348816, loss=1.9210573434829712
train: epoch 65, loss 0.20423391461372375, acc=0.9269999861717224, loss=0.20423391461372375
test: epoch 65, loss 1.8874198198318481, acc=0.5222222208976746, loss=1.8874198198318481
train: epoch 66, loss 0.20700593292713165, acc=0.9263333082199097, loss=0.20700593292713165
test: epoch 66, loss 1.8328857421875, acc=0.5444444417953491, loss=1.8328857421875
train: epoch 67, loss 0.20703670382499695, acc=0.9245555400848389, loss=0.20703670382499695
test: epoch 67, loss 1.6418427228927612, acc=0.5527777671813965, loss=1.6418427228927612
train: epoch 68, loss 0.2116645872592926, acc=0.9237777590751648, loss=0.2116645872592926
test: epoch 68, loss 1.5054138898849487, acc=0.5638889074325562, loss=1.5054138898849487
train: epoch 69, loss 0.21140390634536743, acc=0.9252222180366516, loss=0.21140390634536743
test: epoch 69, loss 1.6733938455581665, acc=0.5666666626930237, loss=1.6733938455581665
train: epoch 70, loss 0.19918502867221832, acc=0.9258333444595337, loss=0.19918502867221832
test: epoch 70, loss 1.9294030666351318, acc=0.5333333611488342, loss=1.9294030666351318
train: epoch 71, loss 0.20558586716651917, acc=0.9229444265365601, loss=0.20558586716651917
test: epoch 71, loss 1.6334545612335205, acc=0.5805555582046509, loss=1.6334545612335205
train: epoch 72, loss 0.20202428102493286, acc=0.9265000224113464, loss=0.20202428102493286
test: epoch 72, loss 1.724450707435608, acc=0.5583333373069763, loss=1.724450707435608
train: epoch 73, loss 0.19536767899990082, acc=0.9263888597488403, loss=0.19536767899990082
test: epoch 73, loss 1.7145963907241821, acc=0.5361111164093018, loss=1.7145963907241821
train: epoch 74, loss 0.2005046159029007, acc=0.9254444241523743, loss=0.2005046159029007
test: epoch 74, loss 1.6731737852096558, acc=0.5583333373069763, loss=1.6731737852096558
train: epoch 75, loss 0.20645783841609955, acc=0.9242222309112549, loss=0.20645783841609955
test: epoch 75, loss 1.670099139213562, acc=0.5833333134651184, loss=1.670099139213562
train: epoch 76, loss 0.2035568654537201, acc=0.925166666507721, loss=0.2035568654537201
test: epoch 76, loss 1.673203706741333, acc=0.5972222089767456, loss=1.673203706741333
train: epoch 77, loss 0.20013798773288727, acc=0.9255555272102356, loss=0.20013798773288727
test: epoch 77, loss 1.501906394958496, acc=0.5638889074325562, loss=1.501906394958496
train: epoch 78, loss 0.2049621343612671, acc=0.9236666560173035, loss=0.2049621343612671
test: epoch 78, loss 1.5793488025665283, acc=0.6194444298744202, loss=1.5793488025665283
train: epoch 79, loss 0.19929219782352448, acc=0.9264444708824158, loss=0.19929219782352448
test: epoch 79, loss 1.5546119213104248, acc=0.5944444537162781, loss=1.5546119213104248
train: epoch 80, loss 0.20373430848121643, acc=0.9244999885559082, loss=0.20373430848121643
test: epoch 80, loss 1.4241034984588623, acc=0.6166666746139526, loss=1.4241034984588623
train: epoch 81, loss 0.20146240293979645, acc=0.9230555295944214, loss=0.20146240293979645
test: epoch 81, loss 1.3060599565505981, acc=0.6138888597488403, loss=1.3060599565505981
train: epoch 82, loss 0.203567773103714, acc=0.9249444603919983, loss=0.203567773103714
test: epoch 82, loss 1.525763988494873, acc=0.5888888835906982, loss=1.525763988494873
train: epoch 83, loss 0.20298954844474792, acc=0.9244999885559082, loss=0.20298954844474792
test: epoch 83, loss 1.617189884185791, acc=0.5972222089767456, loss=1.617189884185791
train: epoch 84, loss 0.20840221643447876, acc=0.9250555634498596, loss=0.20840221643447876
test: epoch 84, loss 1.7790626287460327, acc=0.574999988079071, loss=1.7790626287460327
train: epoch 85, loss 0.19767840206623077, acc=0.9282222390174866, loss=0.19767840206623077
test: epoch 85, loss 1.5413832664489746, acc=0.6138888597488403, loss=1.5413832664489746
train: epoch 86, loss 0.20195423066616058, acc=0.9249444603919983, loss=0.20195423066616058
test: epoch 86, loss 1.5600513219833374, acc=0.5833333134651184, loss=1.5600513219833374
train: epoch 87, loss 0.2022157460451126, acc=0.9261666536331177, loss=0.2022157460451126
test: epoch 87, loss 1.5212112665176392, acc=0.5805555582046509, loss=1.5212112665176392
train: epoch 88, loss 0.20313453674316406, acc=0.9244444370269775, loss=0.20313453674316406
test: epoch 88, loss 1.6043583154678345, acc=0.5805555582046509, loss=1.6043583154678345
train: epoch 89, loss 0.19811399281024933, acc=0.925944447517395, loss=0.19811399281024933
test: epoch 89, loss 1.5173996686935425, acc=0.5833333134651184, loss=1.5173996686935425
train: epoch 90, loss 0.19990022480487823, acc=0.9243333339691162, loss=0.19990022480487823
test: epoch 90, loss 1.5224063396453857, acc=0.605555534362793, loss=1.5224063396453857
train: epoch 91, loss 0.2018473744392395, acc=0.9254999756813049, loss=0.2018473744392395
test: epoch 91, loss 1.5383421182632446, acc=0.625, loss=1.5383421182632446
train: epoch 92, loss 0.19826732575893402, acc=0.9258888959884644, loss=0.19826732575893402
test: epoch 92, loss 1.3723537921905518, acc=0.5944444537162781, loss=1.3723537921905518
train: epoch 93, loss 0.2071564644575119, acc=0.9228888750076294, loss=0.2071564644575119
test: epoch 93, loss 1.4552885293960571, acc=0.6194444298744202, loss=1.4552885293960571
train: epoch 94, loss 0.21010081470012665, acc=0.9226111173629761, loss=0.21010081470012665
test: epoch 94, loss 1.3949493169784546, acc=0.5916666388511658, loss=1.3949493169784546
train: epoch 95, loss 0.20377938449382782, acc=0.9231666922569275, loss=0.20377938449382782
test: epoch 95, loss 1.5167179107666016, acc=0.6083333492279053, loss=1.5167179107666016
train: epoch 96, loss 0.2085278332233429, acc=0.9211111068725586, loss=0.2085278332233429
test: epoch 96, loss 1.2261393070220947, acc=0.6277777552604675, loss=1.2261393070220947
train: epoch 97, loss 0.21226611733436584, acc=0.9226666688919067, loss=0.21226611733436584
test: epoch 97, loss 1.516948938369751, acc=0.6083333492279053, loss=1.516948938369751
train: epoch 98, loss 0.2057182639837265, acc=0.9243333339691162, loss=0.2057182639837265
test: epoch 98, loss 1.3987606763839722, acc=0.6138888597488403, loss=1.3987606763839722
train: epoch 99, loss 0.20438696444034576, acc=0.9242222309112549, loss=0.20438696444034576
test: epoch 99, loss 1.451768159866333, acc=0.6111111044883728, loss=1.451768159866333
train: epoch 100, loss 0.2082347571849823, acc=0.9235555529594421, loss=0.2082347571849823
test: epoch 100, loss 1.4448089599609375, acc=0.6222222447395325, loss=1.4448089599609375
train: epoch 101, loss 0.19739538431167603, acc=0.9267222285270691, loss=0.19739538431167603
test: epoch 101, loss 1.5297778844833374, acc=0.6111111044883728, loss=1.5297778844833374
train: epoch 102, loss 0.21888437867164612, acc=0.9201111197471619, loss=0.21888437867164612
test: epoch 102, loss 1.3837389945983887, acc=0.6277777552604675, loss=1.3837389945983887
train: epoch 103, loss 0.2050485908985138, acc=0.9242222309112549, loss=0.2050485908985138
test: epoch 103, loss 1.442516803741455, acc=0.625, loss=1.442516803741455
train: epoch 104, loss 0.21832847595214844, acc=0.9179444313049316, loss=0.21832847595214844
test: epoch 104, loss 1.3787554502487183, acc=0.605555534362793, loss=1.3787554502487183
train: epoch 105, loss 0.2076423317193985, acc=0.9226111173629761, loss=0.2076423317193985
test: epoch 105, loss 1.3298897743225098, acc=0.6138888597488403, loss=1.3298897743225098
train: epoch 106, loss 0.21968457102775574, acc=0.9191666841506958, loss=0.21968457102775574
test: epoch 106, loss 1.5767314434051514, acc=0.6194444298744202, loss=1.5767314434051514
train: epoch 107, loss 0.20945508778095245, acc=0.9225000143051147, loss=0.20945508778095245
test: epoch 107, loss 1.3707355260849, acc=0.6361111402511597, loss=1.3707355260849
train: epoch 108, loss 0.21078690886497498, acc=0.9208889007568359, loss=0.21078690886497498
test: epoch 108, loss 1.4227726459503174, acc=0.5944444537162781, loss=1.4227726459503174
train: epoch 109, loss 0.21566374599933624, acc=0.9199444651603699, loss=0.21566374599933624
test: epoch 109, loss 1.5851969718933105, acc=0.605555534362793, loss=1.5851969718933105
train: epoch 110, loss 0.22522738575935364, acc=0.9176111221313477, loss=0.22522738575935364
test: epoch 110, loss 1.298951268196106, acc=0.5888888835906982, loss=1.298951268196106
train: epoch 111, loss 0.21345709264278412, acc=0.9223333597183228, loss=0.21345709264278412
test: epoch 111, loss 1.4394055604934692, acc=0.6222222447395325, loss=1.4394055604934692
train: epoch 112, loss 0.2322188764810562, acc=0.91438889503479, loss=0.2322188764810562
test: epoch 112, loss 1.3639990091323853, acc=0.6083333492279053, loss=1.3639990091323853
train: epoch 113, loss 0.22209513187408447, acc=0.9197221994400024, loss=0.22209513187408447
test: epoch 113, loss 1.3577640056610107, acc=0.6305555701255798, loss=1.3577640056610107
train: epoch 114, loss 0.2169293910264969, acc=0.9197777509689331, loss=0.2169293910264969
test: epoch 114, loss 1.3647727966308594, acc=0.6194444298744202, loss=1.3647727966308594
train: epoch 115, loss 0.2154717743396759, acc=0.9236666560173035, loss=0.2154717743396759
test: epoch 115, loss 1.3800508975982666, acc=0.6194444298744202, loss=1.3800508975982666
train: epoch 116, loss 0.2218065857887268, acc=0.9185555577278137, loss=0.2218065857887268
test: epoch 116, loss 1.3152967691421509, acc=0.6222222447395325, loss=1.3152967691421509
train: epoch 117, loss 0.21872927248477936, acc=0.9199444651603699, loss=0.21872927248477936
test: epoch 117, loss 1.436599612236023, acc=0.6194444298744202, loss=1.436599612236023
train: epoch 118, loss 0.22716024518013, acc=0.9158889055252075, loss=0.22716024518013
test: epoch 118, loss 1.3431220054626465, acc=0.6472222208976746, loss=1.3431220054626465
train: epoch 119, loss 0.2217148244380951, acc=0.917722225189209, loss=0.2217148244380951
test: epoch 119, loss 1.466529369354248, acc=0.6138888597488403, loss=1.466529369354248
train: epoch 120, loss 0.22402256727218628, acc=0.9182778000831604, loss=0.22402256727218628
test: epoch 120, loss 1.4713267087936401, acc=0.6222222447395325, loss=1.4713267087936401
train: epoch 121, loss 0.22468264400959015, acc=0.9162222146987915, loss=0.22468264400959015
test: epoch 121, loss 1.3648097515106201, acc=0.6361111402511597, loss=1.3648097515106201
train: epoch 122, loss 0.22889497876167297, acc=0.9168888926506042, loss=0.22889497876167297
test: epoch 122, loss 1.4087889194488525, acc=0.6222222447395325, loss=1.4087889194488525
train: epoch 123, loss 0.21994546055793762, acc=0.9184444546699524, loss=0.21994546055793762
test: epoch 123, loss 1.3687494993209839, acc=0.625, loss=1.3687494993209839
train: epoch 124, loss 0.2229081094264984, acc=0.917388916015625, loss=0.2229081094264984
test: epoch 124, loss 1.2783076763153076, acc=0.6361111402511597, loss=1.2783076763153076
train: epoch 125, loss 0.2192271649837494, acc=0.917388916015625, loss=0.2192271649837494
test: epoch 125, loss 1.4279338121414185, acc=0.625, loss=1.4279338121414185
train: epoch 126, loss 0.21838992834091187, acc=0.9197777509689331, loss=0.21838992834091187
test: epoch 126, loss 1.2802499532699585, acc=0.6361111402511597, loss=1.2802499532699585
train: epoch 127, loss 0.22426514327526093, acc=0.9158333539962769, loss=0.22426514327526093
test: epoch 127, loss 1.366033673286438, acc=0.6388888955116272, loss=1.366033673286438
train: epoch 128, loss 0.2426978498697281, acc=0.9107778072357178, loss=0.2426978498697281
test: epoch 128, loss 1.2979347705841064, acc=0.6361111402511597, loss=1.2979347705841064
train: epoch 129, loss 0.2291097790002823, acc=0.9175000190734863, loss=0.2291097790002823
test: epoch 129, loss 1.2551759481430054, acc=0.6472222208976746, loss=1.2551759481430054
train: epoch 130, loss 0.23601225018501282, acc=0.9154444336891174, loss=0.23601225018501282
test: epoch 130, loss 1.3488655090332031, acc=0.6361111402511597, loss=1.3488655090332031
train: epoch 131, loss 0.23341581225395203, acc=0.9139999747276306, loss=0.23341581225395203
test: epoch 131, loss 1.4413994550704956, acc=0.6499999761581421, loss=1.4413994550704956
train: epoch 132, loss 0.2321350872516632, acc=0.9125000238418579, loss=0.2321350872516632
test: epoch 132, loss 1.2256518602371216, acc=0.6472222208976746, loss=1.2256518602371216
train: epoch 133, loss 0.24059967696666718, acc=0.910111129283905, loss=0.24059967696666718
test: epoch 133, loss 1.2174346446990967, acc=0.6361111402511597, loss=1.2174346446990967
train: epoch 134, loss 0.23788785934448242, acc=0.9116111397743225, loss=0.23788785934448242
test: epoch 134, loss 1.2963429689407349, acc=0.6305555701255798, loss=1.2963429689407349
train: epoch 135, loss 0.24043843150138855, acc=0.9132221937179565, loss=0.24043843150138855
test: epoch 135, loss 1.259109377861023, acc=0.6416666507720947, loss=1.259109377861023
train: epoch 136, loss 0.2394285649061203, acc=0.9126666784286499, loss=0.2394285649061203
test: epoch 136, loss 1.246693730354309, acc=0.6416666507720947, loss=1.246693730354309
train: epoch 137, loss 0.24804458022117615, acc=0.9117777943611145, loss=0.24804458022117615
test: epoch 137, loss 1.311712622642517, acc=0.6333333253860474, loss=1.311712622642517
train: epoch 138, loss 0.22740934789180756, acc=0.9158333539962769, loss=0.22740934789180756
test: epoch 138, loss 1.323067307472229, acc=0.6138888597488403, loss=1.323067307472229
train: epoch 139, loss 0.24033840000629425, acc=0.910111129283905, loss=0.24033840000629425
test: epoch 139, loss 1.3564987182617188, acc=0.6361111402511597, loss=1.3564987182617188
train: epoch 140, loss 0.24701443314552307, acc=0.9083333611488342, loss=0.24701443314552307
test: epoch 140, loss 1.2136996984481812, acc=0.6361111402511597, loss=1.2136996984481812
train: epoch 141, loss 0.24689604341983795, acc=0.9109444618225098, loss=0.24689604341983795
test: epoch 141, loss 1.1109598875045776, acc=0.6361111402511597, loss=1.1109598875045776
train: epoch 142, loss 0.23516395688056946, acc=0.9138888716697693, loss=0.23516395688056946
test: epoch 142, loss 1.1449470520019531, acc=0.6472222208976746, loss=1.1449470520019531
train: epoch 143, loss 0.2406548708677292, acc=0.9127222299575806, loss=0.2406548708677292
test: epoch 143, loss 1.2162435054779053, acc=0.625, loss=1.2162435054779053
train: epoch 144, loss 0.23787568509578705, acc=0.9138333201408386, loss=0.23787568509578705
test: epoch 144, loss 1.268811583518982, acc=0.6416666507720947, loss=1.268811583518982
train: epoch 145, loss 0.2425975203514099, acc=0.9112222194671631, loss=0.2425975203514099
test: epoch 145, loss 1.2032495737075806, acc=0.6361111402511597, loss=1.2032495737075806
train: epoch 146, loss 0.2369082123041153, acc=0.9122222065925598, loss=0.2369082123041153
test: epoch 146, loss 1.1664475202560425, acc=0.6416666507720947, loss=1.1664475202560425
train: epoch 147, loss 0.2350499927997589, acc=0.9118888974189758, loss=0.2350499927997589
test: epoch 147, loss 1.1737881898880005, acc=0.6194444298744202, loss=1.1737881898880005
train: epoch 148, loss 0.24215354025363922, acc=0.9120000004768372, loss=0.24215354025363922
test: epoch 148, loss 1.1148375272750854, acc=0.6416666507720947, loss=1.1148375272750854
train: epoch 149, loss 0.24553079903125763, acc=0.9112777709960938, loss=0.24553079903125763
test: epoch 149, loss 1.3318443298339844, acc=0.6305555701255798, loss=1.3318443298339844
train: epoch 150, loss 0.23641784489154816, acc=0.9118888974189758, loss=0.23641784489154816
test: epoch 150, loss 1.0874215364456177, acc=0.644444465637207, loss=1.0874215364456177
