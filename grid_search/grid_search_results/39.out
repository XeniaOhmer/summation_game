# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=1", "--one_hot=false", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1738424884, receiver_embed_dim=32, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.3718059062957764, acc=0.052888888865709305, loss=3.3718059062957764
test: epoch 1, loss 4.120177745819092, acc=0.0694444477558136, loss=4.120177745819092
train: epoch 2, loss 2.702131509780884, acc=0.14072221517562866, loss=2.702131509780884
test: epoch 2, loss 4.634953498840332, acc=0.07500000298023224, loss=4.634953498840332
train: epoch 3, loss 2.0033082962036133, acc=0.29527777433395386, loss=2.0033082962036133
test: epoch 3, loss 5.342831134796143, acc=0.08611111342906952, loss=5.342831134796143
train: epoch 4, loss 1.549497127532959, acc=0.41494444012641907, loss=1.549497127532959
test: epoch 4, loss 5.386229038238525, acc=0.10555555671453476, loss=5.386229038238525
train: epoch 5, loss 1.327812671661377, acc=0.4860000014305115, loss=1.327812671661377
test: epoch 5, loss 4.608283996582031, acc=0.15000000596046448, loss=4.608283996582031
train: epoch 6, loss 1.184417486190796, acc=0.5426111221313477, loss=1.184417486190796
test: epoch 6, loss 4.19744873046875, acc=0.16388888657093048, loss=4.19744873046875
train: epoch 7, loss 1.079969048500061, acc=0.5888888835906982, loss=1.079969048500061
test: epoch 7, loss 4.0769572257995605, acc=0.1666666716337204, loss=4.0769572257995605
train: epoch 8, loss 0.9878738522529602, acc=0.6240000128746033, loss=0.9878738522529602
test: epoch 8, loss 3.5819835662841797, acc=0.17499999701976776, loss=3.5819835662841797
train: epoch 9, loss 0.8992266654968262, acc=0.6567777991294861, loss=0.8992266654968262
test: epoch 9, loss 3.7580831050872803, acc=0.14722222089767456, loss=3.7580831050872803
train: epoch 10, loss 0.8324770927429199, acc=0.6860555410385132, loss=0.8324770927429199
test: epoch 10, loss 3.538823127746582, acc=0.17777778208255768, loss=3.538823127746582
train: epoch 11, loss 0.7944017648696899, acc=0.7078889012336731, loss=0.7944017648696899
test: epoch 11, loss 3.242837905883789, acc=0.18611110746860504, loss=3.242837905883789
train: epoch 12, loss 0.7363884449005127, acc=0.730555534362793, loss=0.7363884449005127
test: epoch 12, loss 3.129387855529785, acc=0.21944443881511688, loss=3.129387855529785
train: epoch 13, loss 0.6876222491264343, acc=0.7495555281639099, loss=0.6876222491264343
test: epoch 13, loss 3.2834930419921875, acc=0.21111111342906952, loss=3.2834930419921875
train: epoch 14, loss 0.6538252830505371, acc=0.7643333077430725, loss=0.6538252830505371
test: epoch 14, loss 3.086188554763794, acc=0.21944443881511688, loss=3.086188554763794
train: epoch 15, loss 0.6247185468673706, acc=0.7766666412353516, loss=0.6247185468673706
test: epoch 15, loss 3.125051259994507, acc=0.2222222238779068, loss=3.125051259994507
train: epoch 16, loss 0.5857760906219482, acc=0.7857778072357178, loss=0.5857760906219482
test: epoch 16, loss 3.2240777015686035, acc=0.2222222238779068, loss=3.2240777015686035
train: epoch 17, loss 0.5737494230270386, acc=0.7898333072662354, loss=0.5737494230270386
test: epoch 17, loss 3.2886123657226562, acc=0.22499999403953552, loss=3.2886123657226562
train: epoch 18, loss 0.5409833788871765, acc=0.8072222471237183, loss=0.5409833788871765
test: epoch 18, loss 3.472280740737915, acc=0.23888888955116272, loss=3.472280740737915
train: epoch 19, loss 0.5150326490402222, acc=0.816611111164093, loss=0.5150326490402222
test: epoch 19, loss 3.019075632095337, acc=0.25, loss=3.019075632095337
train: epoch 20, loss 0.49959975481033325, acc=0.8255555629730225, loss=0.49959975481033325
test: epoch 20, loss 3.2727057933807373, acc=0.2222222238779068, loss=3.2727057933807373
train: epoch 21, loss 0.4730609059333801, acc=0.8337222337722778, loss=0.4730609059333801
test: epoch 21, loss 3.2251803874969482, acc=0.21388888359069824, loss=3.2251803874969482
train: epoch 22, loss 0.46405795216560364, acc=0.8393333554267883, loss=0.46405795216560364
test: epoch 22, loss 2.943617820739746, acc=0.21111111342906952, loss=2.943617820739746
train: epoch 23, loss 0.43699580430984497, acc=0.8498888611793518, loss=0.43699580430984497
test: epoch 23, loss 2.9227592945098877, acc=0.23055554926395416, loss=2.9227592945098877
train: epoch 24, loss 0.4352976679801941, acc=0.8508333563804626, loss=0.4352976679801941
test: epoch 24, loss 2.9663331508636475, acc=0.2222222238779068, loss=2.9663331508636475
train: epoch 25, loss 0.41526246070861816, acc=0.8577777743339539, loss=0.41526246070861816
test: epoch 25, loss 3.0167741775512695, acc=0.26944443583488464, loss=3.0167741775512695
train: epoch 26, loss 0.39851754903793335, acc=0.8622221946716309, loss=0.39851754903793335
test: epoch 26, loss 3.2331767082214355, acc=0.26944443583488464, loss=3.2331767082214355
train: epoch 27, loss 0.391092985868454, acc=0.8657777905464172, loss=0.391092985868454
test: epoch 27, loss 2.8218400478363037, acc=0.2638888955116272, loss=2.8218400478363037
train: epoch 28, loss 0.36646199226379395, acc=0.8766111135482788, loss=0.36646199226379395
test: epoch 28, loss 3.079507827758789, acc=0.2888889014720917, loss=3.079507827758789
train: epoch 29, loss 0.3596982955932617, acc=0.8773888945579529, loss=0.3596982955932617
test: epoch 29, loss 2.772681474685669, acc=0.2805555462837219, loss=2.772681474685669
train: epoch 30, loss 0.36619049310684204, acc=0.8786110877990723, loss=0.36619049310684204
test: epoch 30, loss 3.027294635772705, acc=0.2611111104488373, loss=3.027294635772705
train: epoch 31, loss 0.3442889451980591, acc=0.8837222456932068, loss=0.3442889451980591
test: epoch 31, loss 2.6852123737335205, acc=0.2944444417953491, loss=2.6852123737335205
train: epoch 32, loss 0.3278571367263794, acc=0.8887222409248352, loss=0.3278571367263794
test: epoch 32, loss 2.852982759475708, acc=0.28611111640930176, loss=2.852982759475708
train: epoch 33, loss 0.31786802411079407, acc=0.8934999704360962, loss=0.31786802411079407
test: epoch 33, loss 2.394622564315796, acc=0.3305555582046509, loss=2.394622564315796
train: epoch 34, loss 0.30999189615249634, acc=0.8956666588783264, loss=0.30999189615249634
test: epoch 34, loss 2.715801477432251, acc=0.2944444417953491, loss=2.715801477432251
train: epoch 35, loss 0.30388209223747253, acc=0.8989444375038147, loss=0.30388209223747253
test: epoch 35, loss 2.39372181892395, acc=0.3499999940395355, loss=2.39372181892395
train: epoch 36, loss 0.28708431124687195, acc=0.9056110978126526, loss=0.28708431124687195
test: epoch 36, loss 2.8576483726501465, acc=0.2527777850627899, loss=2.8576483726501465
train: epoch 37, loss 0.28675681352615356, acc=0.903333306312561, loss=0.28675681352615356
test: epoch 37, loss 2.4753904342651367, acc=0.2805555462837219, loss=2.4753904342651367
train: epoch 38, loss 0.2864536941051483, acc=0.9049999713897705, loss=0.2864536941051483
test: epoch 38, loss 2.6614737510681152, acc=0.3194444477558136, loss=2.6614737510681152
train: epoch 39, loss 0.2698788344860077, acc=0.9114444255828857, loss=0.2698788344860077
test: epoch 39, loss 2.655768871307373, acc=0.3055555522441864, loss=2.655768871307373
train: epoch 40, loss 0.26874250173568726, acc=0.9079999923706055, loss=0.26874250173568726
test: epoch 40, loss 2.572467803955078, acc=0.28611111640930176, loss=2.572467803955078
train: epoch 41, loss 0.2705742418766022, acc=0.9098888635635376, loss=0.2705742418766022
test: epoch 41, loss 2.4204375743865967, acc=0.3361110985279083, loss=2.4204375743865967
train: epoch 42, loss 0.25958874821662903, acc=0.9128888845443726, loss=0.25958874821662903
test: epoch 42, loss 2.615868091583252, acc=0.2944444417953491, loss=2.615868091583252
train: epoch 43, loss 0.25620904564857483, acc=0.9179999828338623, loss=0.25620904564857483
test: epoch 43, loss 2.677400827407837, acc=0.2805555462837219, loss=2.677400827407837
train: epoch 44, loss 0.24013762176036835, acc=0.9196666479110718, loss=0.24013762176036835
test: epoch 44, loss 2.544816017150879, acc=0.28611111640930176, loss=2.544816017150879
train: epoch 45, loss 0.25285688042640686, acc=0.9192777872085571, loss=0.25285688042640686
test: epoch 45, loss 2.529435396194458, acc=0.3027777671813965, loss=2.529435396194458
train: epoch 46, loss 0.24300114810466766, acc=0.9251111149787903, loss=0.24300114810466766
test: epoch 46, loss 2.580822467803955, acc=0.3083333373069763, loss=2.580822467803955
train: epoch 47, loss 0.2464962601661682, acc=0.9230555295944214, loss=0.2464962601661682
test: epoch 47, loss 2.5442936420440674, acc=0.3055555522441864, loss=2.5442936420440674
train: epoch 48, loss 0.22799652814865112, acc=0.9247221946716309, loss=0.22799652814865112
test: epoch 48, loss 2.5082485675811768, acc=0.3194444477558136, loss=2.5082485675811768
train: epoch 49, loss 0.22016304731369019, acc=0.925000011920929, loss=0.22016304731369019
test: epoch 49, loss 2.792304277420044, acc=0.3194444477558136, loss=2.792304277420044
train: epoch 50, loss 0.2086087316274643, acc=0.9311666488647461, loss=0.2086087316274643
test: epoch 50, loss 2.3403406143188477, acc=0.3361110985279083, loss=2.3403406143188477
train: epoch 51, loss 0.21247397363185883, acc=0.9306111335754395, loss=0.21247397363185883
test: epoch 51, loss 2.731863021850586, acc=0.3222222328186035, loss=2.731863021850586
train: epoch 52, loss 0.2182941436767578, acc=0.9286666512489319, loss=0.2182941436767578
test: epoch 52, loss 2.42386794090271, acc=0.3583333194255829, loss=2.42386794090271
train: epoch 53, loss 0.203410804271698, acc=0.9361110925674438, loss=0.203410804271698
test: epoch 53, loss 2.6579689979553223, acc=0.31111112236976624, loss=2.6579689979553223
train: epoch 54, loss 0.19734223186969757, acc=0.9354444742202759, loss=0.19734223186969757
test: epoch 54, loss 2.446186065673828, acc=0.3361110985279083, loss=2.446186065673828
train: epoch 55, loss 0.19461919367313385, acc=0.9381111264228821, loss=0.19461919367313385
test: epoch 55, loss 2.5981197357177734, acc=0.35277777910232544, loss=2.5981197357177734
train: epoch 56, loss 0.19301706552505493, acc=0.9394444227218628, loss=0.19301706552505493
test: epoch 56, loss 2.6449344158172607, acc=0.33888888359069824, loss=2.6449344158172607
train: epoch 57, loss 0.1879267394542694, acc=0.9418888688087463, loss=0.1879267394542694
test: epoch 57, loss 2.728198528289795, acc=0.32499998807907104, loss=2.728198528289795
train: epoch 58, loss 0.18718010187149048, acc=0.9415555596351624, loss=0.18718010187149048
test: epoch 58, loss 2.4475600719451904, acc=0.3499999940395355, loss=2.4475600719451904
train: epoch 59, loss 0.17935360968112946, acc=0.9430555701255798, loss=0.17935360968112946
test: epoch 59, loss 2.5347278118133545, acc=0.3444444537162781, loss=2.5347278118133545
train: epoch 60, loss 0.17153583467006683, acc=0.9436110854148865, loss=0.17153583467006683
test: epoch 60, loss 2.4674341678619385, acc=0.32777777314186096, loss=2.4674341678619385
train: epoch 61, loss 0.172496035695076, acc=0.9419999718666077, loss=0.172496035695076
test: epoch 61, loss 2.4231510162353516, acc=0.3611111044883728, loss=2.4231510162353516
train: epoch 62, loss 0.174905464053154, acc=0.9457777738571167, loss=0.174905464053154
test: epoch 62, loss 2.5191457271575928, acc=0.3611111044883728, loss=2.5191457271575928
train: epoch 63, loss 0.16351571679115295, acc=0.9491111040115356, loss=0.16351571679115295
test: epoch 63, loss 2.670994758605957, acc=0.34166666865348816, loss=2.670994758605957
train: epoch 64, loss 0.16408167779445648, acc=0.9502221941947937, loss=0.16408167779445648
test: epoch 64, loss 2.5328502655029297, acc=0.36666667461395264, loss=2.5328502655029297
train: epoch 65, loss 0.1565776765346527, acc=0.9508333206176758, loss=0.1565776765346527
test: epoch 65, loss 2.4549059867858887, acc=0.3444444537162781, loss=2.4549059867858887
train: epoch 66, loss 0.15249887108802795, acc=0.9529444575309753, loss=0.15249887108802795
test: epoch 66, loss 2.87384033203125, acc=0.3333333432674408, loss=2.87384033203125
train: epoch 67, loss 0.15602535009384155, acc=0.9521111249923706, loss=0.15602535009384155
test: epoch 67, loss 2.5287656784057617, acc=0.3222222328186035, loss=2.5287656784057617
train: epoch 68, loss 0.15809118747711182, acc=0.9529444575309753, loss=0.15809118747711182
test: epoch 68, loss 2.7925846576690674, acc=0.31111112236976624, loss=2.7925846576690674
train: epoch 69, loss 0.1546708643436432, acc=0.9513888955116272, loss=0.1546708643436432
test: epoch 69, loss 2.364422559738159, acc=0.3499999940395355, loss=2.364422559738159
train: epoch 70, loss 0.1504252851009369, acc=0.9559999704360962, loss=0.1504252851009369
test: epoch 70, loss 2.490246534347534, acc=0.35555556416511536, loss=2.490246534347534
train: epoch 71, loss 0.1492244303226471, acc=0.9537222385406494, loss=0.1492244303226471
test: epoch 71, loss 2.3502261638641357, acc=0.36666667461395264, loss=2.3502261638641357
train: epoch 72, loss 0.1346580982208252, acc=0.9583888649940491, loss=0.1346580982208252
test: epoch 72, loss 2.477522611618042, acc=0.36666667461395264, loss=2.477522611618042
train: epoch 73, loss 0.14243920147418976, acc=0.9556111097335815, loss=0.14243920147418976
test: epoch 73, loss 2.3512823581695557, acc=0.3583333194255829, loss=2.3512823581695557
train: epoch 74, loss 0.12464268505573273, acc=0.960777759552002, loss=0.12464268505573273
test: epoch 74, loss 2.3520114421844482, acc=0.3722222149372101, loss=2.3520114421844482
train: epoch 75, loss 0.13862201571464539, acc=0.9587222337722778, loss=0.13862201571464539
test: epoch 75, loss 2.637697696685791, acc=0.3444444537162781, loss=2.637697696685791
train: epoch 76, loss 0.1331499069929123, acc=0.9601666927337646, loss=0.1331499069929123
test: epoch 76, loss 2.375775098800659, acc=0.3777777850627899, loss=2.375775098800659
train: epoch 77, loss 0.14261530339717865, acc=0.9583333134651184, loss=0.14261530339717865
test: epoch 77, loss 2.436650037765503, acc=0.3916666805744171, loss=2.436650037765503
train: epoch 78, loss 0.13002268970012665, acc=0.9606666564941406, loss=0.13002268970012665
test: epoch 78, loss 2.5549633502960205, acc=0.3611111044883728, loss=2.5549633502960205
train: epoch 79, loss 0.12904876470565796, acc=0.9628333449363708, loss=0.12904876470565796
test: epoch 79, loss 2.4160454273223877, acc=0.3583333194255829, loss=2.4160454273223877
train: epoch 80, loss 0.12869778275489807, acc=0.9631666541099548, loss=0.12869778275489807
test: epoch 80, loss 2.470400094985962, acc=0.3333333432674408, loss=2.470400094985962
train: epoch 81, loss 0.11578056216239929, acc=0.9638333320617676, loss=0.11578056216239929
test: epoch 81, loss 2.47126841545105, acc=0.39722222089767456, loss=2.47126841545105
train: epoch 82, loss 0.12263280153274536, acc=0.9642778038978577, loss=0.12263280153274536
test: epoch 82, loss 2.595355987548828, acc=0.375, loss=2.595355987548828
train: epoch 83, loss 0.11243977397680283, acc=0.9664999842643738, loss=0.11243977397680283
test: epoch 83, loss 2.48223876953125, acc=0.35555556416511536, loss=2.48223876953125
train: epoch 84, loss 0.11628428101539612, acc=0.9650555849075317, loss=0.11628428101539612
test: epoch 84, loss 2.7560653686523438, acc=0.36944442987442017, loss=2.7560653686523438
train: epoch 85, loss 0.11109325289726257, acc=0.9696666598320007, loss=0.11109325289726257
test: epoch 85, loss 2.540977954864502, acc=0.3611111044883728, loss=2.540977954864502
train: epoch 86, loss 0.10944158583879471, acc=0.9673333168029785, loss=0.10944158583879471
test: epoch 86, loss 2.3173491954803467, acc=0.4000000059604645, loss=2.3173491954803467
train: epoch 87, loss 0.11516381800174713, acc=0.9677777886390686, loss=0.11516381800174713
test: epoch 87, loss 2.639521837234497, acc=0.3499999940395355, loss=2.639521837234497
train: epoch 88, loss 0.10596967488527298, acc=0.9677222371101379, loss=0.10596967488527298
test: epoch 88, loss 2.502242088317871, acc=0.33888888359069824, loss=2.502242088317871
train: epoch 89, loss 0.10546287149190903, acc=0.9683333039283752, loss=0.10546287149190903
test: epoch 89, loss 2.527712345123291, acc=0.3861111104488373, loss=2.527712345123291
train: epoch 90, loss 0.11464058607816696, acc=0.9663333296775818, loss=0.11464058607816696
test: epoch 90, loss 2.563093662261963, acc=0.3611111044883728, loss=2.563093662261963
train: epoch 91, loss 0.10362595319747925, acc=0.9698333144187927, loss=0.10362595319747925
test: epoch 91, loss 2.512998580932617, acc=0.3777777850627899, loss=2.512998580932617
train: epoch 92, loss 0.1151740774512291, acc=0.9680555462837219, loss=0.1151740774512291
test: epoch 92, loss 2.36822509765625, acc=0.3861111104488373, loss=2.36822509765625
train: epoch 93, loss 0.10996171087026596, acc=0.9693889021873474, loss=0.10996171087026596
test: epoch 93, loss 2.446856737136841, acc=0.38333332538604736, loss=2.446856737136841
train: epoch 94, loss 0.09736001491546631, acc=0.971666693687439, loss=0.09736001491546631
test: epoch 94, loss 2.460165500640869, acc=0.3444444537162781, loss=2.460165500640869
train: epoch 95, loss 0.09743015468120575, acc=0.9713333249092102, loss=0.09743015468120575
test: epoch 95, loss 2.905268669128418, acc=0.33888888359069824, loss=2.905268669128418
train: epoch 96, loss 0.10043572634458542, acc=0.9705555438995361, loss=0.10043572634458542
test: epoch 96, loss 2.571864366531372, acc=0.34166666865348816, loss=2.571864366531372
train: epoch 97, loss 0.10063044726848602, acc=0.9714444279670715, loss=0.10063044726848602
test: epoch 97, loss 2.5489108562469482, acc=0.3722222149372101, loss=2.5489108562469482
train: epoch 98, loss 0.09368713945150375, acc=0.9739444255828857, loss=0.09368713945150375
test: epoch 98, loss 2.5967600345611572, acc=0.35555556416511536, loss=2.5967600345611572
train: epoch 99, loss 0.09657320380210876, acc=0.9721666574478149, loss=0.09657320380210876
test: epoch 99, loss 2.237305164337158, acc=0.39722222089767456, loss=2.237305164337158
train: epoch 100, loss 0.08514948189258575, acc=0.9743333458900452, loss=0.08514948189258575
test: epoch 100, loss 2.6974921226501465, acc=0.3722222149372101, loss=2.6974921226501465
train: epoch 101, loss 0.09357252717018127, acc=0.9714999794960022, loss=0.09357252717018127
test: epoch 101, loss 2.646498680114746, acc=0.36944442987442017, loss=2.646498680114746
train: epoch 102, loss 0.09212453663349152, acc=0.972611129283905, loss=0.09212453663349152
test: epoch 102, loss 2.7054603099823, acc=0.32777777314186096, loss=2.7054603099823
train: epoch 103, loss 0.08692841231822968, acc=0.9728333353996277, loss=0.08692841231822968
test: epoch 103, loss 2.591517210006714, acc=0.3444444537162781, loss=2.591517210006714
train: epoch 104, loss 0.08350657671689987, acc=0.9738333225250244, loss=0.08350657671689987
test: epoch 104, loss 2.6507768630981445, acc=0.38333332538604736, loss=2.6507768630981445
train: epoch 105, loss 0.0838855728507042, acc=0.976722240447998, loss=0.0838855728507042
test: epoch 105, loss 2.6196746826171875, acc=0.3583333194255829, loss=2.6196746826171875
train: epoch 106, loss 0.09421215951442719, acc=0.9723888635635376, loss=0.09421215951442719
test: epoch 106, loss 2.5147006511688232, acc=0.3777777850627899, loss=2.5147006511688232
train: epoch 107, loss 0.08045561611652374, acc=0.9753888845443726, loss=0.08045561611652374
test: epoch 107, loss 2.744715690612793, acc=0.3305555582046509, loss=2.744715690612793
train: epoch 108, loss 0.08269750326871872, acc=0.9747222065925598, loss=0.08269750326871872
test: epoch 108, loss 2.7380447387695312, acc=0.3499999940395355, loss=2.7380447387695312
train: epoch 109, loss 0.07541028410196304, acc=0.9778888821601868, loss=0.07541028410196304
test: epoch 109, loss 2.6058058738708496, acc=0.3166666626930237, loss=2.6058058738708496
train: epoch 110, loss 0.07531753182411194, acc=0.9778333306312561, loss=0.07531753182411194
test: epoch 110, loss 2.805898666381836, acc=0.3722222149372101, loss=2.805898666381836
train: epoch 111, loss 0.08659184724092484, acc=0.9754999876022339, loss=0.08659184724092484
test: epoch 111, loss 2.9526941776275635, acc=0.38055557012557983, loss=2.9526941776275635
train: epoch 112, loss 0.07834430038928986, acc=0.976722240447998, loss=0.07834430038928986
test: epoch 112, loss 2.378296136856079, acc=0.4277777671813965, loss=2.378296136856079
train: epoch 113, loss 0.07143685966730118, acc=0.9793333411216736, loss=0.07143685966730118
test: epoch 113, loss 2.417652130126953, acc=0.36666667461395264, loss=2.417652130126953
train: epoch 114, loss 0.08136293292045593, acc=0.977222204208374, loss=0.08136293292045593
test: epoch 114, loss 2.4990456104278564, acc=0.3722222149372101, loss=2.4990456104278564
train: epoch 115, loss 0.07220397144556046, acc=0.9802777767181396, loss=0.07220397144556046
test: epoch 115, loss 2.5192275047302246, acc=0.3888888955116272, loss=2.5192275047302246
train: epoch 116, loss 0.08331352472305298, acc=0.9763888716697693, loss=0.08331352472305298
test: epoch 116, loss 2.896416664123535, acc=0.33888888359069824, loss=2.896416664123535
train: epoch 117, loss 0.07700640708208084, acc=0.9799444675445557, loss=0.07700640708208084
test: epoch 117, loss 2.60679030418396, acc=0.39722222089767456, loss=2.60679030418396
train: epoch 118, loss 0.06621979922056198, acc=0.980555534362793, loss=0.06621979922056198
test: epoch 118, loss 2.5057334899902344, acc=0.4055555462837219, loss=2.5057334899902344
train: epoch 119, loss 0.07547591626644135, acc=0.9789444208145142, loss=0.07547591626644135
test: epoch 119, loss 2.5182645320892334, acc=0.3611111044883728, loss=2.5182645320892334
train: epoch 120, loss 0.0751623883843422, acc=0.9793333411216736, loss=0.0751623883843422
test: epoch 120, loss 2.4969234466552734, acc=0.4194444417953491, loss=2.4969234466552734
train: epoch 121, loss 0.08011715114116669, acc=0.9787222146987915, loss=0.08011715114116669
test: epoch 121, loss 2.6818742752075195, acc=0.375, loss=2.6818742752075195
train: epoch 122, loss 0.07864278554916382, acc=0.9780555367469788, loss=0.07864278554916382
test: epoch 122, loss 2.221506357192993, acc=0.3638888895511627, loss=2.221506357192993
train: epoch 123, loss 0.06246418505907059, acc=0.9817222356796265, loss=0.06246418505907059
test: epoch 123, loss 2.521131753921509, acc=0.3888888955116272, loss=2.521131753921509
train: epoch 124, loss 0.06247837468981743, acc=0.9809444546699524, loss=0.06247837468981743
test: epoch 124, loss 2.7520222663879395, acc=0.39444443583488464, loss=2.7520222663879395
train: epoch 125, loss 0.06678402423858643, acc=0.9796110987663269, loss=0.06678402423858643
test: epoch 125, loss 2.726194381713867, acc=0.3722222149372101, loss=2.726194381713867
train: epoch 126, loss 0.06922436505556107, acc=0.9788888692855835, loss=0.06922436505556107
test: epoch 126, loss 2.6577353477478027, acc=0.3499999940395355, loss=2.6577353477478027
train: epoch 127, loss 0.06337770819664001, acc=0.9819444417953491, loss=0.06337770819664001
test: epoch 127, loss 2.7902257442474365, acc=0.3638888895511627, loss=2.7902257442474365
train: epoch 128, loss 0.06419982016086578, acc=0.9813888669013977, loss=0.06419982016086578
test: epoch 128, loss 2.577448606491089, acc=0.38055557012557983, loss=2.577448606491089
train: epoch 129, loss 0.058682627975940704, acc=0.9831110835075378, loss=0.058682627975940704
test: epoch 129, loss 2.724006175994873, acc=0.4138889014720917, loss=2.724006175994873
train: epoch 130, loss 0.060828376561403275, acc=0.9816666841506958, loss=0.060828376561403275
test: epoch 130, loss 2.5987911224365234, acc=0.3722222149372101, loss=2.5987911224365234
train: epoch 131, loss 0.06547221541404724, acc=0.9826111197471619, loss=0.06547221541404724
test: epoch 131, loss 3.1441895961761475, acc=0.3361110985279083, loss=3.1441895961761475
train: epoch 132, loss 0.07280564308166504, acc=0.9796110987663269, loss=0.07280564308166504
test: epoch 132, loss 2.77901554107666, acc=0.43611112236976624, loss=2.77901554107666
train: epoch 133, loss 0.06575676053762436, acc=0.9815000295639038, loss=0.06575676053762436
test: epoch 133, loss 2.3560984134674072, acc=0.39444443583488464, loss=2.3560984134674072
train: epoch 134, loss 0.060495734214782715, acc=0.9821666479110718, loss=0.060495734214782715
test: epoch 134, loss 2.633448839187622, acc=0.3777777850627899, loss=2.633448839187622
train: epoch 135, loss 0.06063247472047806, acc=0.9836111068725586, loss=0.06063247472047806
test: epoch 135, loss 2.8985135555267334, acc=0.3916666805744171, loss=2.8985135555267334
train: epoch 136, loss 0.061118293553590775, acc=0.9823889136314392, loss=0.061118293553590775
test: epoch 136, loss 2.6061313152313232, acc=0.43611112236976624, loss=2.6061313152313232
train: epoch 137, loss 0.06654056906700134, acc=0.9827222228050232, loss=0.06654056906700134
test: epoch 137, loss 2.8955628871917725, acc=0.3888888955116272, loss=2.8955628871917725
train: epoch 138, loss 0.06131554767489433, acc=0.9815555810928345, loss=0.06131554767489433
test: epoch 138, loss 2.6221282482147217, acc=0.3861111104488373, loss=2.6221282482147217
train: epoch 139, loss 0.05324593558907509, acc=0.9846110939979553, loss=0.05324593558907509
test: epoch 139, loss 2.6172993183135986, acc=0.375, loss=2.6172993183135986
train: epoch 140, loss 0.06325817853212357, acc=0.9830555319786072, loss=0.06325817853212357
test: epoch 140, loss 2.8494107723236084, acc=0.4194444417953491, loss=2.8494107723236084
train: epoch 141, loss 0.054883912205696106, acc=0.9845555424690247, loss=0.054883912205696106
test: epoch 141, loss 2.738406181335449, acc=0.39722222089767456, loss=2.738406181335449
train: epoch 142, loss 0.05693988502025604, acc=0.9839444160461426, loss=0.05693988502025604
test: epoch 142, loss 2.4055302143096924, acc=0.4555555582046509, loss=2.4055302143096924
train: epoch 143, loss 0.0552511140704155, acc=0.9852222204208374, loss=0.0552511140704155
test: epoch 143, loss 2.8089535236358643, acc=0.375, loss=2.8089535236358643
train: epoch 144, loss 0.05228210240602493, acc=0.9849444627761841, loss=0.05228210240602493
test: epoch 144, loss 2.9264323711395264, acc=0.4333333373069763, loss=2.9264323711395264
train: epoch 145, loss 0.05800468102097511, acc=0.9848333597183228, loss=0.05800468102097511
test: epoch 145, loss 2.5810561180114746, acc=0.4277777671813965, loss=2.5810561180114746
train: epoch 146, loss 0.05700761079788208, acc=0.9848333597183228, loss=0.05700761079788208
test: epoch 146, loss 2.4191174507141113, acc=0.4333333373069763, loss=2.4191174507141113
train: epoch 147, loss 0.057739097625017166, acc=0.9852222204208374, loss=0.057739097625017166
test: epoch 147, loss 2.486027240753174, acc=0.41111111640930176, loss=2.486027240753174
train: epoch 148, loss 0.057271357625722885, acc=0.9842222332954407, loss=0.057271357625722885
test: epoch 148, loss 2.543063163757324, acc=0.4138889014720917, loss=2.543063163757324
train: epoch 149, loss 0.055346325039863586, acc=0.9852777719497681, loss=0.055346325039863586
test: epoch 149, loss 2.6300435066223145, acc=0.4472222328186035, loss=2.6300435066223145
train: epoch 150, loss 0.05925295501947403, acc=0.9837222099304199, loss=0.05925295501947403
test: epoch 150, loss 3.2816312313079834, acc=0.3888888955116272, loss=3.2816312313079834
