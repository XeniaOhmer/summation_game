# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.99", "--one_hot=false", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=280259761, receiver_embed_dim=64, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.789210319519043, acc=0.09566666930913925, loss=2.789210319519043
test: epoch 1, loss 3.324892520904541, acc=0.12777778506278992, loss=3.324892520904541
train: epoch 2, loss 1.8625519275665283, acc=0.23561111092567444, loss=1.8625519275665283
test: epoch 2, loss 2.8461785316467285, acc=0.18888889253139496, loss=2.8461785316467285
train: epoch 3, loss 1.4747167825698853, acc=0.34288889169692993, loss=1.4747167825698853
test: epoch 3, loss 3.385653495788574, acc=0.17499999701976776, loss=3.385653495788574
train: epoch 4, loss 1.2151235342025757, acc=0.4441666603088379, loss=1.2151235342025757
test: epoch 4, loss 2.2411177158355713, acc=0.3083333373069763, loss=2.2411177158355713
train: epoch 5, loss 1.0964760780334473, acc=0.5048333406448364, loss=1.0964760780334473
test: epoch 5, loss 2.448133707046509, acc=0.3027777671813965, loss=2.448133707046509
train: epoch 6, loss 0.942748486995697, acc=0.5842221975326538, loss=0.942748486995697
test: epoch 6, loss 2.020787239074707, acc=0.3499999940395355, loss=2.020787239074707
train: epoch 7, loss 0.8374786376953125, acc=0.6388888955116272, loss=0.8374786376953125
test: epoch 7, loss 2.2472968101501465, acc=0.3166666626930237, loss=2.2472968101501465
train: epoch 8, loss 0.7443884611129761, acc=0.6807777881622314, loss=0.7443884611129761
test: epoch 8, loss 1.7593424320220947, acc=0.39722222089767456, loss=1.7593424320220947
train: epoch 9, loss 0.6607687473297119, acc=0.7167222499847412, loss=0.6607687473297119
test: epoch 9, loss 2.192558526992798, acc=0.4333333373069763, loss=2.192558526992798
train: epoch 10, loss 0.5890139937400818, acc=0.753000020980835, loss=0.5890139937400818
test: epoch 10, loss 1.5425400733947754, acc=0.43888887763023376, loss=1.5425400733947754
train: epoch 11, loss 0.574336588382721, acc=0.7515000104904175, loss=0.574336588382721
test: epoch 11, loss 1.6871414184570312, acc=0.4138889014720917, loss=1.6871414184570312
train: epoch 12, loss 0.5134589672088623, acc=0.7830555438995361, loss=0.5134589672088623
test: epoch 12, loss 2.0582828521728516, acc=0.4277777671813965, loss=2.0582828521728516
train: epoch 13, loss 0.4458047151565552, acc=0.815833330154419, loss=0.4458047151565552
test: epoch 13, loss 1.5218807458877563, acc=0.5, loss=1.5218807458877563
train: epoch 14, loss 0.4321926236152649, acc=0.816444456577301, loss=0.4321926236152649
test: epoch 14, loss 2.278728723526001, acc=0.4472222328186035, loss=2.278728723526001
train: epoch 15, loss 0.4013306200504303, acc=0.8327777981758118, loss=0.4013306200504303
test: epoch 15, loss 1.576089859008789, acc=0.4833333194255829, loss=1.576089859008789
train: epoch 16, loss 0.3872344493865967, acc=0.8431110978126526, loss=0.3872344493865967
test: epoch 16, loss 1.6595133543014526, acc=0.4888888895511627, loss=1.6595133543014526
train: epoch 17, loss 0.30455097556114197, acc=0.874833345413208, loss=0.30455097556114197
test: epoch 17, loss 1.040231704711914, acc=0.5972222089767456, loss=1.040231704711914
train: epoch 18, loss 0.2653982937335968, acc=0.8932222127914429, loss=0.2653982937335968
test: epoch 18, loss 0.9096106886863708, acc=0.6638888716697693, loss=0.9096106886863708
train: epoch 19, loss 0.236692875623703, acc=0.9014999866485596, loss=0.236692875623703
test: epoch 19, loss 1.7395596504211426, acc=0.6166666746139526, loss=1.7395596504211426
train: epoch 20, loss 0.2345947027206421, acc=0.9029444456100464, loss=0.2345947027206421
test: epoch 20, loss 0.9582442045211792, acc=0.675000011920929, loss=0.9582442045211792
train: epoch 21, loss 0.21213982999324799, acc=0.9106666445732117, loss=0.21213982999324799
test: epoch 21, loss 0.6922893524169922, acc=0.6972222328186035, loss=0.6922893524169922
train: epoch 22, loss 0.20098528265953064, acc=0.9133333563804626, loss=0.20098528265953064
test: epoch 22, loss 0.5385000705718994, acc=0.7916666865348816, loss=0.5385000705718994
train: epoch 23, loss 0.197705939412117, acc=0.9162777662277222, loss=0.197705939412117
test: epoch 23, loss 0.690771758556366, acc=0.75, loss=0.690771758556366
train: epoch 24, loss 0.17619259655475616, acc=0.9233888983726501, loss=0.17619259655475616
test: epoch 24, loss 0.5899668335914612, acc=0.7666666507720947, loss=0.5899668335914612
train: epoch 25, loss 0.19946086406707764, acc=0.9161666631698608, loss=0.19946086406707764
test: epoch 25, loss 0.5264798998832703, acc=0.7611111402511597, loss=0.5264798998832703
train: epoch 26, loss 0.1656947135925293, acc=0.9266666769981384, loss=0.1656947135925293
test: epoch 26, loss 0.4324283301830292, acc=0.8666666746139526, loss=0.4324283301830292
train: epoch 27, loss 0.18547502160072327, acc=0.9218888878822327, loss=0.18547502160072327
test: epoch 27, loss 0.4477444291114807, acc=0.8138889074325562, loss=0.4477444291114807
train: epoch 28, loss 0.1676609069108963, acc=0.925611138343811, loss=0.1676609069108963
test: epoch 28, loss 0.5677284598350525, acc=0.7722222208976746, loss=0.5677284598350525
train: epoch 29, loss 0.14995615184307098, acc=0.9324444532394409, loss=0.14995615184307098
test: epoch 29, loss 0.3676687479019165, acc=0.8277778029441833, loss=0.3676687479019165
train: epoch 30, loss 0.15903715789318085, acc=0.9290000200271606, loss=0.15903715789318085
test: epoch 30, loss 0.5552443861961365, acc=0.8472222089767456, loss=0.5552443861961365
train: epoch 31, loss 0.1657620519399643, acc=0.9290555715560913, loss=0.1657620519399643
test: epoch 31, loss 0.3815224766731262, acc=0.8583333492279053, loss=0.3815224766731262
train: epoch 32, loss 0.13982848823070526, acc=0.9340555667877197, loss=0.13982848823070526
test: epoch 32, loss 0.27886900305747986, acc=0.8805555701255798, loss=0.27886900305747986
train: epoch 33, loss 0.15832844376564026, acc=0.9363333582878113, loss=0.15832844376564026
test: epoch 33, loss 0.3723810911178589, acc=0.8638888597488403, loss=0.3723810911178589
train: epoch 34, loss 0.10618435591459274, acc=0.9585555791854858, loss=0.10618435591459274
test: epoch 34, loss 0.4831669330596924, acc=0.8666666746139526, loss=0.4831669330596924
train: epoch 35, loss 0.11216177046298981, acc=0.9660000205039978, loss=0.11216177046298981
test: epoch 35, loss 0.3208352029323578, acc=0.9055555462837219, loss=0.3208352029323578
train: epoch 36, loss 0.10537537932395935, acc=0.9686111211776733, loss=0.10537537932395935
test: epoch 36, loss 0.3472261428833008, acc=0.9027777910232544, loss=0.3472261428833008
train: epoch 37, loss 0.09449265152215958, acc=0.9692777991294861, loss=0.09449265152215958
test: epoch 37, loss 0.2675866186618805, acc=0.9222221970558167, loss=0.2675866186618805
train: epoch 38, loss 0.10061868280172348, acc=0.971833348274231, loss=0.10061868280172348
test: epoch 38, loss 0.5222484469413757, acc=0.875, loss=0.5222484469413757
train: epoch 39, loss 0.08366071432828903, acc=0.972777783870697, loss=0.08366071432828903
test: epoch 39, loss 0.4168170690536499, acc=0.9083333611488342, loss=0.4168170690536499
train: epoch 40, loss 0.11339201033115387, acc=0.9669444561004639, loss=0.11339201033115387
test: epoch 40, loss 0.33080950379371643, acc=0.9083333611488342, loss=0.33080950379371643
train: epoch 41, loss 0.07858212292194366, acc=0.9780555367469788, loss=0.07858212292194366
test: epoch 41, loss 0.29654461145401, acc=0.8972222208976746, loss=0.29654461145401
train: epoch 42, loss 0.07150503247976303, acc=0.9796110987663269, loss=0.07150503247976303
test: epoch 42, loss 0.3143395483493805, acc=0.9111111164093018, loss=0.3143395483493805
train: epoch 43, loss 0.08313553780317307, acc=0.9750000238418579, loss=0.08313553780317307
test: epoch 43, loss 0.4150030314922333, acc=0.894444465637207, loss=0.4150030314922333
train: epoch 44, loss 0.07571862637996674, acc=0.9775000214576721, loss=0.07571862637996674
test: epoch 44, loss 0.33571410179138184, acc=0.9166666865348816, loss=0.33571410179138184
train: epoch 45, loss 0.10308051109313965, acc=0.9713888764381409, loss=0.10308051109313965
test: epoch 45, loss 0.26326707005500793, acc=0.9111111164093018, loss=0.26326707005500793
train: epoch 46, loss 0.08044420182704926, acc=0.9769444465637207, loss=0.08044420182704926
test: epoch 46, loss 0.3609406352043152, acc=0.9166666865348816, loss=0.3609406352043152
train: epoch 47, loss 0.06346240639686584, acc=0.9808889031410217, loss=0.06346240639686584
test: epoch 47, loss 0.4427141845226288, acc=0.855555534362793, loss=0.4427141845226288
train: epoch 48, loss 0.12314492464065552, acc=0.9646666646003723, loss=0.12314492464065552
test: epoch 48, loss 0.19720341265201569, acc=0.9194444417953491, loss=0.19720341265201569
train: epoch 49, loss 0.07137057185173035, acc=0.9783333539962769, loss=0.07137057185173035
test: epoch 49, loss 0.20017893612384796, acc=0.9222221970558167, loss=0.20017893612384796
train: epoch 50, loss 0.08148591220378876, acc=0.9741666913032532, loss=0.08148591220378876
test: epoch 50, loss 0.30016785860061646, acc=0.9222221970558167, loss=0.30016785860061646
train: epoch 51, loss 0.08916506171226501, acc=0.9762222170829773, loss=0.08916506171226501
test: epoch 51, loss 0.20447975397109985, acc=0.9138888716697693, loss=0.20447975397109985
train: epoch 52, loss 0.11868126690387726, acc=0.9590555429458618, loss=0.11868126690387726
test: epoch 52, loss 0.37261566519737244, acc=0.8916666507720947, loss=0.37261566519737244
train: epoch 53, loss 0.0979524552822113, acc=0.9731666445732117, loss=0.0979524552822113
test: epoch 53, loss 0.32893985509872437, acc=0.9222221970558167, loss=0.32893985509872437
train: epoch 54, loss 0.0793890729546547, acc=0.9778333306312561, loss=0.0793890729546547
test: epoch 54, loss 0.3534011244773865, acc=0.9166666865348816, loss=0.3534011244773865
train: epoch 55, loss 0.0718071460723877, acc=0.9799444675445557, loss=0.0718071460723877
test: epoch 55, loss 0.509696364402771, acc=0.894444465637207, loss=0.509696364402771
train: epoch 56, loss 0.056990642100572586, acc=0.9831666946411133, loss=0.056990642100572586
test: epoch 56, loss 0.48177990317344666, acc=0.9222221970558167, loss=0.48177990317344666
train: epoch 57, loss 0.10078741610050201, acc=0.9711666703224182, loss=0.10078741610050201
test: epoch 57, loss 0.2454443722963333, acc=0.9111111164093018, loss=0.2454443722963333
train: epoch 58, loss 0.09043264389038086, acc=0.9758333563804626, loss=0.09043264389038086
test: epoch 58, loss 0.23383888602256775, acc=0.9194444417953491, loss=0.23383888602256775
train: epoch 59, loss 0.07395359128713608, acc=0.977222204208374, loss=0.07395359128713608
test: epoch 59, loss 0.3487083911895752, acc=0.9222221970558167, loss=0.3487083911895752
train: epoch 60, loss 0.06304360926151276, acc=0.9822221994400024, loss=0.06304360926151276
test: epoch 60, loss 0.321927934885025, acc=0.9222221970558167, loss=0.321927934885025
train: epoch 61, loss 0.07886097580194473, acc=0.9783333539962769, loss=0.07886097580194473
test: epoch 61, loss 0.24005074799060822, acc=0.9166666865348816, loss=0.24005074799060822
train: epoch 62, loss 0.12916788458824158, acc=0.9563888907432556, loss=0.12916788458824158
test: epoch 62, loss 0.24059376120567322, acc=0.9166666865348816, loss=0.24059376120567322
train: epoch 63, loss 0.08017417043447495, acc=0.9772777557373047, loss=0.08017417043447495
test: epoch 63, loss 0.35505083203315735, acc=0.9166666865348816, loss=0.35505083203315735
train: epoch 64, loss 0.05864276736974716, acc=0.9815000295639038, loss=0.05864276736974716
test: epoch 64, loss 0.3009025752544403, acc=0.9194444417953491, loss=0.3009025752544403
train: epoch 65, loss 0.0538276769220829, acc=0.9847221970558167, loss=0.0538276769220829
test: epoch 65, loss 0.21707795560359955, acc=0.9166666865348816, loss=0.21707795560359955
train: epoch 66, loss 0.08467400819063187, acc=0.9748888611793518, loss=0.08467400819063187
test: epoch 66, loss 0.33721068501472473, acc=0.9222221970558167, loss=0.33721068501472473
train: epoch 67, loss 0.1071745902299881, acc=0.9698333144187927, loss=0.1071745902299881
test: epoch 67, loss 0.16178973019123077, acc=0.9083333611488342, loss=0.16178973019123077
train: epoch 68, loss 0.07872869074344635, acc=0.9752222299575806, loss=0.07872869074344635
test: epoch 68, loss 0.24553553760051727, acc=0.9222221970558167, loss=0.24553553760051727
train: epoch 69, loss 0.08149226754903793, acc=0.9766666889190674, loss=0.08149226754903793
test: epoch 69, loss 0.311002641916275, acc=0.9166666865348816, loss=0.311002641916275
train: epoch 70, loss 0.11204268038272858, acc=0.9681666493415833, loss=0.11204268038272858
test: epoch 70, loss 0.27493858337402344, acc=0.9222221970558167, loss=0.27493858337402344
train: epoch 71, loss 0.05610283091664314, acc=0.9823333621025085, loss=0.05610283091664314
test: epoch 71, loss 0.26175495982170105, acc=0.9222221970558167, loss=0.26175495982170105
train: epoch 72, loss 0.10762146860361099, acc=0.9673888683319092, loss=0.10762146860361099
test: epoch 72, loss 0.21189618110656738, acc=0.9194444417953491, loss=0.21189618110656738
train: epoch 73, loss 0.07749324291944504, acc=0.975777804851532, loss=0.07749324291944504
test: epoch 73, loss 0.29444029927253723, acc=0.8999999761581421, loss=0.29444029927253723
train: epoch 74, loss 0.0679614394903183, acc=0.969944417476654, loss=0.0679614394903183
test: epoch 74, loss 0.327430784702301, acc=0.9194444417953491, loss=0.327430784702301
train: epoch 75, loss 0.09619373083114624, acc=0.9677222371101379, loss=0.09619373083114624
test: epoch 75, loss 0.21492820978164673, acc=0.9166666865348816, loss=0.21492820978164673
train: epoch 76, loss 0.13107003271579742, acc=0.9489444494247437, loss=0.13107003271579742
test: epoch 76, loss 0.31321996450424194, acc=0.9083333611488342, loss=0.31321996450424194
train: epoch 77, loss 0.07136086374521255, acc=0.9695000052452087, loss=0.07136086374521255
test: epoch 77, loss 0.3258766233921051, acc=0.9138888716697693, loss=0.3258766233921051
train: epoch 78, loss 0.10832589864730835, acc=0.9636666774749756, loss=0.10832589864730835
test: epoch 78, loss 0.20149560272693634, acc=0.9111111164093018, loss=0.20149560272693634
train: epoch 79, loss 0.08931715041399002, acc=0.9732778072357178, loss=0.08931715041399002
test: epoch 79, loss 0.25622105598449707, acc=0.9138888716697693, loss=0.25622105598449707
train: epoch 80, loss 0.10509102046489716, acc=0.9667778015136719, loss=0.10509102046489716
test: epoch 80, loss 0.14454658329486847, acc=0.9194444417953491, loss=0.14454658329486847
train: epoch 81, loss 0.06976381689310074, acc=0.9665555357933044, loss=0.06976381689310074
test: epoch 81, loss 0.23864313960075378, acc=0.9138888716697693, loss=0.23864313960075378
train: epoch 82, loss 0.0869583934545517, acc=0.9564999938011169, loss=0.0869583934545517
test: epoch 82, loss 0.14400669932365417, acc=0.9277777671813965, loss=0.14400669932365417
train: epoch 83, loss 0.13812074065208435, acc=0.945277750492096, loss=0.13812074065208435
test: epoch 83, loss 0.33650073409080505, acc=0.9111111164093018, loss=0.33650073409080505
train: epoch 84, loss 0.09447704255580902, acc=0.9700000286102295, loss=0.09447704255580902
test: epoch 84, loss 0.21842487156391144, acc=0.9138888716697693, loss=0.21842487156391144
train: epoch 85, loss 0.08485240489244461, acc=0.9700555801391602, loss=0.08485240489244461
test: epoch 85, loss 0.2521269619464874, acc=0.9166666865348816, loss=0.2521269619464874
train: epoch 86, loss 0.08522680401802063, acc=0.9677777886390686, loss=0.08522680401802063
test: epoch 86, loss 0.20904956758022308, acc=0.9166666865348816, loss=0.20904956758022308
train: epoch 87, loss 0.0824371799826622, acc=0.9642778038978577, loss=0.0824371799826622
test: epoch 87, loss 0.29418420791625977, acc=0.9138888716697693, loss=0.29418420791625977
train: epoch 88, loss 0.15128158032894135, acc=0.950166642665863, loss=0.15128158032894135
test: epoch 88, loss 0.316064715385437, acc=0.9194444417953491, loss=0.316064715385437
train: epoch 89, loss 0.07086493074893951, acc=0.9706666469573975, loss=0.07086493074893951
test: epoch 89, loss 0.2660277783870697, acc=0.9222221970558167, loss=0.2660277783870697
train: epoch 90, loss 0.08790530264377594, acc=0.9713888764381409, loss=0.08790530264377594
test: epoch 90, loss 0.3321012258529663, acc=0.9194444417953491, loss=0.3321012258529663
train: epoch 91, loss 0.10149288177490234, acc=0.9690555334091187, loss=0.10149288177490234
test: epoch 91, loss 0.2411627471446991, acc=0.9194444417953491, loss=0.2411627471446991
train: epoch 92, loss 0.06121055409312248, acc=0.9750555753707886, loss=0.06121055409312248
test: epoch 92, loss 0.28815704584121704, acc=0.9222221970558167, loss=0.28815704584121704
train: epoch 93, loss 0.05122014507651329, acc=0.9728333353996277, loss=0.05122014507651329
test: epoch 93, loss 0.12135840952396393, acc=0.9277777671813965, loss=0.12135840952396393
train: epoch 94, loss 0.05797336623072624, acc=0.9714444279670715, loss=0.05797336623072624
test: epoch 94, loss 0.2593851387500763, acc=0.9222221970558167, loss=0.2593851387500763
train: epoch 95, loss 0.19118216633796692, acc=0.9456111192703247, loss=0.19118216633796692
test: epoch 95, loss 0.24010471999645233, acc=0.9111111164093018, loss=0.24010471999645233
train: epoch 96, loss 0.10640829801559448, acc=0.9653333425521851, loss=0.10640829801559448
test: epoch 96, loss 0.15927056968212128, acc=0.9194444417953491, loss=0.15927056968212128
train: epoch 97, loss 0.0682092159986496, acc=0.972944438457489, loss=0.0682092159986496
test: epoch 97, loss 0.25488007068634033, acc=0.9194444417953491, loss=0.25488007068634033
train: epoch 98, loss 0.13493302464485168, acc=0.9562222361564636, loss=0.13493302464485168
test: epoch 98, loss 0.2568275034427643, acc=0.9138888716697693, loss=0.2568275034427643
train: epoch 99, loss 0.0833517462015152, acc=0.9660555720329285, loss=0.0833517462015152
test: epoch 99, loss 0.28024590015411377, acc=0.9166666865348816, loss=0.28024590015411377
train: epoch 100, loss 0.061595700681209564, acc=0.9693889021873474, loss=0.061595700681209564
test: epoch 100, loss 0.22220252454280853, acc=0.9194444417953491, loss=0.22220252454280853
train: epoch 101, loss 0.15494227409362793, acc=0.9482777714729309, loss=0.15494227409362793
test: epoch 101, loss 0.23686929047107697, acc=0.9333333373069763, loss=0.23686929047107697
train: epoch 102, loss 0.08558929711580276, acc=0.9651111364364624, loss=0.08558929711580276
test: epoch 102, loss 0.18953612446784973, acc=0.9361110925674438, loss=0.18953612446784973
train: epoch 103, loss 0.06955141574144363, acc=0.971833348274231, loss=0.06955141574144363
test: epoch 103, loss 0.25961825251579285, acc=0.9222221970558167, loss=0.25961825251579285
train: epoch 104, loss 0.07261648029088974, acc=0.968666672706604, loss=0.07261648029088974
test: epoch 104, loss 0.15040892362594604, acc=0.9361110925674438, loss=0.15040892362594604
train: epoch 105, loss 0.07131433486938477, acc=0.9682222008705139, loss=0.07131433486938477
test: epoch 105, loss 0.2388867735862732, acc=0.9361110925674438, loss=0.2388867735862732
train: epoch 106, loss 0.10275761038064957, acc=0.9661111235618591, loss=0.10275761038064957
test: epoch 106, loss 0.18215827643871307, acc=0.9333333373069763, loss=0.18215827643871307
train: epoch 107, loss 0.06302108615636826, acc=0.9754444360733032, loss=0.06302108615636826
test: epoch 107, loss 0.10964585840702057, acc=0.9361110925674438, loss=0.10964585840702057
train: epoch 108, loss 0.05329952389001846, acc=0.9746666550636292, loss=0.05329952389001846
test: epoch 108, loss 0.11771901696920395, acc=0.9611111283302307, loss=0.11771901696920395
train: epoch 109, loss 0.16214825212955475, acc=0.9246666431427002, loss=0.16214825212955475
test: epoch 109, loss 0.1329885572195053, acc=0.9361110925674438, loss=0.1329885572195053
train: epoch 110, loss 0.15306511521339417, acc=0.9267777800559998, loss=0.15306511521339417
test: epoch 110, loss 0.14324498176574707, acc=0.9388889074325562, loss=0.14324498176574707
train: epoch 111, loss 0.13236480951309204, acc=0.9338333606719971, loss=0.13236480951309204
test: epoch 111, loss 0.6083768010139465, acc=0.8638888597488403, loss=0.6083768010139465
train: epoch 112, loss 0.21290041506290436, acc=0.8995555639266968, loss=0.21290041506290436
test: epoch 112, loss 0.13798470795154572, acc=0.9222221970558167, loss=0.13798470795154572
train: epoch 113, loss 0.13959093391895294, acc=0.914222240447998, loss=0.13959093391895294
test: epoch 113, loss 0.12463752925395966, acc=0.925000011920929, loss=0.12463752925395966
train: epoch 114, loss 0.12664392590522766, acc=0.9162777662277222, loss=0.12664392590522766
test: epoch 114, loss 0.1243172138929367, acc=0.925000011920929, loss=0.1243172138929367
train: epoch 115, loss 0.23457713425159454, acc=0.8921111226081848, loss=0.23457713425159454
test: epoch 115, loss 0.16659772396087646, acc=0.9166666865348816, loss=0.16659772396087646
train: epoch 116, loss 0.17879213392734528, acc=0.9072222113609314, loss=0.17879213392734528
test: epoch 116, loss 0.14153501391410828, acc=0.9222221970558167, loss=0.14153501391410828
train: epoch 117, loss 0.17100834846496582, acc=0.9119444489479065, loss=0.17100834846496582
test: epoch 117, loss 0.2031438946723938, acc=0.9111111164093018, loss=0.2031438946723938
train: epoch 118, loss 0.17110872268676758, acc=0.9064444303512573, loss=0.17110872268676758
test: epoch 118, loss 0.1635735034942627, acc=0.9111111164093018, loss=0.1635735034942627
train: epoch 119, loss 0.15871937572956085, acc=0.9043333530426025, loss=0.15871937572956085
test: epoch 119, loss 0.14652559161186218, acc=0.9166666865348816, loss=0.14652559161186218
train: epoch 120, loss 0.1864878088235855, acc=0.9024999737739563, loss=0.1864878088235855
test: epoch 120, loss 0.17269273102283478, acc=0.9055555462837219, loss=0.17269273102283478
train: epoch 121, loss 0.17815956473350525, acc=0.8970555663108826, loss=0.17815956473350525
test: epoch 121, loss 0.16988882422447205, acc=0.9027777910232544, loss=0.16988882422447205
train: epoch 122, loss 0.16875523328781128, acc=0.8939444422721863, loss=0.16875523328781128
test: epoch 122, loss 0.16556403040885925, acc=0.9055555462837219, loss=0.16556403040885925
train: epoch 123, loss 0.1686176061630249, acc=0.8951666951179504, loss=0.1686176061630249
test: epoch 123, loss 0.16796503961086273, acc=0.9111111164093018, loss=0.16796503961086273
train: epoch 124, loss 0.27206531167030334, acc=0.8611111044883728, loss=0.27206531167030334
test: epoch 124, loss 0.2297465056180954, acc=0.8694444298744202, loss=0.2297465056180954
train: epoch 125, loss 0.23090538382530212, acc=0.8523333072662354, loss=0.23090538382530212
test: epoch 125, loss 0.22894085943698883, acc=0.8694444298744202, loss=0.22894085943698883
train: epoch 126, loss 0.29725635051727295, acc=0.8687222003936768, loss=0.29725635051727295
test: epoch 126, loss 0.23813162744045258, acc=0.8972222208976746, loss=0.23813162744045258
train: epoch 127, loss 0.20286405086517334, acc=0.9012777805328369, loss=0.20286405086517334
test: epoch 127, loss 0.16524028778076172, acc=0.9138888716697693, loss=0.16524028778076172
train: epoch 128, loss 0.16662563383579254, acc=0.9101666808128357, loss=0.16662563383579254
test: epoch 128, loss 0.17444877326488495, acc=0.9027777910232544, loss=0.17444877326488495
train: epoch 129, loss 0.1950702965259552, acc=0.8976110816001892, loss=0.1950702965259552
test: epoch 129, loss 0.17694717645645142, acc=0.9055555462837219, loss=0.17694717645645142
train: epoch 130, loss 0.1936764270067215, acc=0.9001666903495789, loss=0.1936764270067215
test: epoch 130, loss 0.2167115956544876, acc=0.8972222208976746, loss=0.2167115956544876
train: epoch 131, loss 0.17005938291549683, acc=0.906499981880188, loss=0.17005938291549683
test: epoch 131, loss 0.14738424122333527, acc=0.9194444417953491, loss=0.14738424122333527
train: epoch 132, loss 0.1493930220603943, acc=0.9109444618225098, loss=0.1493930220603943
test: epoch 132, loss 0.14669793844223022, acc=0.9194444417953491, loss=0.14669793844223022
train: epoch 133, loss 0.16928966343402863, acc=0.9087222218513489, loss=0.16928966343402863
test: epoch 133, loss 0.3820064961910248, acc=0.8861111402511597, loss=0.3820064961910248
train: epoch 134, loss 0.19229096174240112, acc=0.9054999947547913, loss=0.19229096174240112
test: epoch 134, loss 0.14700382947921753, acc=0.9222221970558167, loss=0.14700382947921753
train: epoch 135, loss 0.14786697924137115, acc=0.9168888926506042, loss=0.14786697924137115
test: epoch 135, loss 0.14645157754421234, acc=0.9222221970558167, loss=0.14645157754421234
train: epoch 136, loss 0.16414397954940796, acc=0.9162222146987915, loss=0.16414397954940796
test: epoch 136, loss 0.1402115374803543, acc=0.925000011920929, loss=0.1402115374803543
train: epoch 137, loss 0.2375376969575882, acc=0.9013888835906982, loss=0.2375376969575882
test: epoch 137, loss 0.24319106340408325, acc=0.9083333611488342, loss=0.24319106340408325
train: epoch 138, loss 0.19159027934074402, acc=0.9119444489479065, loss=0.19159027934074402
test: epoch 138, loss 0.17938511073589325, acc=0.9138888716697693, loss=0.17938511073589325
train: epoch 139, loss 0.18184156715869904, acc=0.914555549621582, loss=0.18184156715869904
test: epoch 139, loss 0.1545615941286087, acc=0.9222221970558167, loss=0.1545615941286087
train: epoch 140, loss 0.1882515549659729, acc=0.9158889055252075, loss=0.1882515549659729
test: epoch 140, loss 0.1573280692100525, acc=0.9194444417953491, loss=0.1573280692100525
train: epoch 141, loss 0.1466985046863556, acc=0.9251111149787903, loss=0.1466985046863556
test: epoch 141, loss 0.13216175138950348, acc=0.9277777671813965, loss=0.13216175138950348
train: epoch 142, loss 0.1326773464679718, acc=0.9278888702392578, loss=0.1326773464679718
test: epoch 142, loss 0.12422177195549011, acc=0.9305555820465088, loss=0.12422177195549011
train: epoch 143, loss 0.13716495037078857, acc=0.9278333187103271, loss=0.13716495037078857
test: epoch 143, loss 0.13600601255893707, acc=0.9277777671813965, loss=0.13600601255893707
train: epoch 144, loss 0.13686616718769073, acc=0.9277777671813965, loss=0.13686616718769073
test: epoch 144, loss 0.1359504908323288, acc=0.9277777671813965, loss=0.1359504908323288
train: epoch 145, loss 0.1384526789188385, acc=0.9274444580078125, loss=0.1384526789188385
test: epoch 145, loss 0.13598360121250153, acc=0.9277777671813965, loss=0.13598360121250153
train: epoch 146, loss 0.13687001168727875, acc=0.9277777671813965, loss=0.13687001168727875
test: epoch 146, loss 0.1359257847070694, acc=0.9277777671813965, loss=0.1359257847070694
train: epoch 147, loss 0.13685014843940735, acc=0.9277777671813965, loss=0.13685014843940735
test: epoch 147, loss 0.1359095573425293, acc=0.9277777671813965, loss=0.1359095573425293
train: epoch 148, loss 0.1367393583059311, acc=0.9277777671813965, loss=0.1367393583059311
test: epoch 148, loss 0.13590314984321594, acc=0.9277777671813965, loss=0.13590314984321594
train: epoch 149, loss 0.13668590784072876, acc=0.9277777671813965, loss=0.13668590784072876
test: epoch 149, loss 0.13589359819889069, acc=0.9277777671813965, loss=0.13589359819889069
train: epoch 150, loss 0.13663560152053833, acc=0.9277777671813965, loss=0.13663560152053833
test: epoch 150, loss 0.135889932513237, acc=0.9277777671813965, loss=0.135889932513237
