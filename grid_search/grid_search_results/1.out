# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1", "--temp_decay=1", "--one_hot=true", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=882554279, receiver_embed_dim=32, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.256443977355957, acc=0.05666666850447655, loss=3.256443977355957
test: epoch 1, loss 2.9461822509765625, acc=0.10833333432674408, loss=2.9461822509765625
train: epoch 2, loss 2.3877999782562256, acc=0.16705556213855743, loss=2.3877999782562256
test: epoch 2, loss 2.868889808654785, acc=0.1388888955116272, loss=2.868889808654785
train: epoch 3, loss 2.099524974822998, acc=0.22194445133209229, loss=2.099524974822998
test: epoch 3, loss 2.506333589553833, acc=0.13055555522441864, loss=2.506333589553833
train: epoch 4, loss 1.8632678985595703, acc=0.2819444537162781, loss=1.8632678985595703
test: epoch 4, loss 2.4669852256774902, acc=0.1805555522441864, loss=2.4669852256774902
train: epoch 5, loss 1.6652657985687256, acc=0.33933332562446594, loss=1.6652657985687256
test: epoch 5, loss 2.102649688720703, acc=0.2361111044883728, loss=2.102649688720703
train: epoch 6, loss 1.5200233459472656, acc=0.38749998807907104, loss=1.5200233459472656
test: epoch 6, loss 1.8374390602111816, acc=0.2611111104488373, loss=1.8374390602111816
train: epoch 7, loss 1.3790678977966309, acc=0.43522220849990845, loss=1.3790678977966309
test: epoch 7, loss 1.7681715488433838, acc=0.26944443583488464, loss=1.7681715488433838
train: epoch 8, loss 1.2690712213516235, acc=0.4651666581630707, loss=1.2690712213516235
test: epoch 8, loss 1.6686867475509644, acc=0.28611111640930176, loss=1.6686867475509644
train: epoch 9, loss 1.19497549533844, acc=0.4951111078262329, loss=1.19497549533844
test: epoch 9, loss 1.7790265083312988, acc=0.2888889014720917, loss=1.7790265083312988
train: epoch 10, loss 1.1374480724334717, acc=0.512666642665863, loss=1.1374480724334717
test: epoch 10, loss 1.6640968322753906, acc=0.28333333134651184, loss=1.6640968322753906
train: epoch 11, loss 1.0879210233688354, acc=0.5266110897064209, loss=1.0879210233688354
test: epoch 11, loss 1.749974250793457, acc=0.3055555522441864, loss=1.749974250793457
train: epoch 12, loss 1.0288070440292358, acc=0.5454444289207458, loss=1.0288070440292358
test: epoch 12, loss 1.629266381263733, acc=0.2916666567325592, loss=1.629266381263733
train: epoch 13, loss 1.0075583457946777, acc=0.5586110949516296, loss=1.0075583457946777
test: epoch 13, loss 1.5376867055892944, acc=0.2805555462837219, loss=1.5376867055892944
train: epoch 14, loss 0.9792405962944031, acc=0.5683333277702332, loss=0.9792405962944031
test: epoch 14, loss 1.4902008771896362, acc=0.3333333432674408, loss=1.4902008771896362
train: epoch 15, loss 0.9455131888389587, acc=0.5815555453300476, loss=0.9455131888389587
test: epoch 15, loss 1.521538496017456, acc=0.3083333373069763, loss=1.521538496017456
train: epoch 16, loss 0.9363561868667603, acc=0.5916666388511658, loss=0.9363561868667603
test: epoch 16, loss 1.5847471952438354, acc=0.3472222089767456, loss=1.5847471952438354
train: epoch 17, loss 0.8992134928703308, acc=0.6092222332954407, loss=0.8992134928703308
test: epoch 17, loss 1.53318452835083, acc=0.3916666805744171, loss=1.53318452835083
train: epoch 18, loss 0.8688830137252808, acc=0.6258333325386047, loss=0.8688830137252808
test: epoch 18, loss 1.3639453649520874, acc=0.4166666567325592, loss=1.3639453649520874
train: epoch 19, loss 0.8483518958091736, acc=0.6382777690887451, loss=0.8483518958091736
test: epoch 19, loss 1.4998308420181274, acc=0.42222222685813904, loss=1.4998308420181274
train: epoch 20, loss 0.8175647258758545, acc=0.6457222104072571, loss=0.8175647258758545
test: epoch 20, loss 1.3401433229446411, acc=0.4472222328186035, loss=1.3401433229446411
train: epoch 21, loss 0.7790942192077637, acc=0.6653888821601868, loss=0.7790942192077637
test: epoch 21, loss 1.3858436346054077, acc=0.38333332538604736, loss=1.3858436346054077
train: epoch 22, loss 0.7393508553504944, acc=0.683555543422699, loss=0.7393508553504944
test: epoch 22, loss 1.445199966430664, acc=0.42500001192092896, loss=1.445199966430664
train: epoch 23, loss 0.7539005279541016, acc=0.6736666560173035, loss=0.7539005279541016
test: epoch 23, loss 1.4040906429290771, acc=0.43888887763023376, loss=1.4040906429290771
train: epoch 24, loss 0.7142698168754578, acc=0.6972777843475342, loss=0.7142698168754578
test: epoch 24, loss 1.4715877771377563, acc=0.4277777671813965, loss=1.4715877771377563
train: epoch 25, loss 0.6875107884407043, acc=0.7073888778686523, loss=0.6875107884407043
test: epoch 25, loss 1.3655180931091309, acc=0.46666666865348816, loss=1.3655180931091309
train: epoch 26, loss 0.6752094030380249, acc=0.7093333601951599, loss=0.6752094030380249
test: epoch 26, loss 1.2473081350326538, acc=0.49444442987442017, loss=1.2473081350326538
train: epoch 27, loss 0.659254252910614, acc=0.7127777934074402, loss=0.659254252910614
test: epoch 27, loss 1.338881254196167, acc=0.46666666865348816, loss=1.338881254196167
train: epoch 28, loss 0.6412966847419739, acc=0.7197222113609314, loss=0.6412966847419739
test: epoch 28, loss 1.253313422203064, acc=0.4972222149372101, loss=1.253313422203064
train: epoch 29, loss 0.6179749369621277, acc=0.7264444231987, loss=0.6179749369621277
test: epoch 29, loss 1.1722908020019531, acc=0.5138888955116272, loss=1.1722908020019531
train: epoch 30, loss 0.6143384575843811, acc=0.7264999747276306, loss=0.6143384575843811
test: epoch 30, loss 1.196425199508667, acc=0.5138888955116272, loss=1.196425199508667
train: epoch 31, loss 0.6042637228965759, acc=0.7343888878822327, loss=0.6042637228965759
test: epoch 31, loss 1.303739070892334, acc=0.5166666507720947, loss=1.303739070892334
train: epoch 32, loss 0.5902040004730225, acc=0.7369444370269775, loss=0.5902040004730225
test: epoch 32, loss 1.3739985227584839, acc=0.4749999940395355, loss=1.3739985227584839
train: epoch 33, loss 0.5743412375450134, acc=0.7441666722297668, loss=0.5743412375450134
test: epoch 33, loss 1.54079270362854, acc=0.4277777671813965, loss=1.54079270362854
train: epoch 34, loss 0.5625945329666138, acc=0.7475555539131165, loss=0.5625945329666138
test: epoch 34, loss 1.2551994323730469, acc=0.49166667461395264, loss=1.2551994323730469
train: epoch 35, loss 0.5514078736305237, acc=0.7532777786254883, loss=0.5514078736305237
test: epoch 35, loss 1.3917025327682495, acc=0.5055555701255798, loss=1.3917025327682495
train: epoch 36, loss 0.5482207536697388, acc=0.7538889050483704, loss=0.5482207536697388
test: epoch 36, loss 1.3239563703536987, acc=0.5277777910232544, loss=1.3239563703536987
train: epoch 37, loss 0.5592411756515503, acc=0.7510555386543274, loss=0.5592411756515503
test: epoch 37, loss 1.3942183256149292, acc=0.5138888955116272, loss=1.3942183256149292
train: epoch 38, loss 0.5356461405754089, acc=0.758055567741394, loss=0.5356461405754089
test: epoch 38, loss 1.3883235454559326, acc=0.5027777552604675, loss=1.3883235454559326
train: epoch 39, loss 0.5286680459976196, acc=0.7612777948379517, loss=0.5286680459976196
test: epoch 39, loss 1.3651976585388184, acc=0.49166667461395264, loss=1.3651976585388184
train: epoch 40, loss 0.5162280201911926, acc=0.7663888931274414, loss=0.5162280201911926
test: epoch 40, loss 1.4793498516082764, acc=0.5055555701255798, loss=1.4793498516082764
train: epoch 41, loss 0.5285632610321045, acc=0.761888861656189, loss=0.5285632610321045
test: epoch 41, loss 1.2933285236358643, acc=0.5027777552604675, loss=1.2933285236358643
train: epoch 42, loss 0.5140595436096191, acc=0.769444465637207, loss=0.5140595436096191
test: epoch 42, loss 1.3543477058410645, acc=0.5138888955116272, loss=1.3543477058410645
train: epoch 43, loss 0.5113694071769714, acc=0.7703889012336731, loss=0.5113694071769714
test: epoch 43, loss 1.3783096075057983, acc=0.5027777552604675, loss=1.3783096075057983
train: epoch 44, loss 0.5024513006210327, acc=0.7748333215713501, loss=0.5024513006210327
test: epoch 44, loss 1.3406978845596313, acc=0.519444465637207, loss=1.3406978845596313
train: epoch 45, loss 0.4980134963989258, acc=0.7744444608688354, loss=0.4980134963989258
test: epoch 45, loss 1.4651676416397095, acc=0.5, loss=1.4651676416397095
train: epoch 46, loss 0.48505643010139465, acc=0.7781111001968384, loss=0.48505643010139465
test: epoch 46, loss 1.484084963798523, acc=0.5138888955116272, loss=1.484084963798523
train: epoch 47, loss 0.48049482703208923, acc=0.781166672706604, loss=0.48049482703208923
test: epoch 47, loss 1.2545270919799805, acc=0.5249999761581421, loss=1.2545270919799805
train: epoch 48, loss 0.48909109830856323, acc=0.7798888683319092, loss=0.48909109830856323
test: epoch 48, loss 1.2677781581878662, acc=0.5361111164093018, loss=1.2677781581878662
train: epoch 49, loss 0.4704142212867737, acc=0.7808333039283752, loss=0.4704142212867737
test: epoch 49, loss 1.2044345140457153, acc=0.5583333373069763, loss=1.2044345140457153
train: epoch 50, loss 0.47312361001968384, acc=0.7828888893127441, loss=0.47312361001968384
test: epoch 50, loss 1.5339101552963257, acc=0.5333333611488342, loss=1.5339101552963257
train: epoch 51, loss 0.48833921551704407, acc=0.7786666750907898, loss=0.48833921551704407
test: epoch 51, loss 1.5487031936645508, acc=0.5222222208976746, loss=1.5487031936645508
train: epoch 52, loss 0.45571932196617126, acc=0.7917222380638123, loss=0.45571932196617126
test: epoch 52, loss 1.4180394411087036, acc=0.49444442987442017, loss=1.4180394411087036
train: epoch 53, loss 0.4693593382835388, acc=0.785611093044281, loss=0.4693593382835388
test: epoch 53, loss 1.4299468994140625, acc=0.5361111164093018, loss=1.4299468994140625
train: epoch 54, loss 0.46074604988098145, acc=0.7901666760444641, loss=0.46074604988098145
test: epoch 54, loss 1.4434843063354492, acc=0.5083333253860474, loss=1.4434843063354492
train: epoch 55, loss 0.47972002625465393, acc=0.7835000157356262, loss=0.47972002625465393
test: epoch 55, loss 1.1932015419006348, acc=0.5666666626930237, loss=1.1932015419006348
train: epoch 56, loss 0.44224783778190613, acc=0.7947221994400024, loss=0.44224783778190613
test: epoch 56, loss 1.240800380706787, acc=0.5305555462837219, loss=1.240800380706787
train: epoch 57, loss 0.44202089309692383, acc=0.7954999804496765, loss=0.44202089309692383
test: epoch 57, loss 1.2099950313568115, acc=0.5861111283302307, loss=1.2099950313568115
train: epoch 58, loss 0.4717579185962677, acc=0.788444459438324, loss=0.4717579185962677
test: epoch 58, loss 1.411205530166626, acc=0.5388888716697693, loss=1.411205530166626
train: epoch 59, loss 0.45224472880363464, acc=0.7897777557373047, loss=0.45224472880363464
test: epoch 59, loss 1.497820258140564, acc=0.5, loss=1.497820258140564
train: epoch 60, loss 0.44936782121658325, acc=0.7943888902664185, loss=0.44936782121658325
test: epoch 60, loss 1.3408541679382324, acc=0.5416666865348816, loss=1.3408541679382324
train: epoch 61, loss 0.44533294439315796, acc=0.7952222228050232, loss=0.44533294439315796
test: epoch 61, loss 1.1522716283798218, acc=0.5611110925674438, loss=1.1522716283798218
train: epoch 62, loss 0.4573209285736084, acc=0.7954999804496765, loss=0.4573209285736084
test: epoch 62, loss 1.217518925666809, acc=0.5527777671813965, loss=1.217518925666809
train: epoch 63, loss 0.4373506009578705, acc=0.8077222108840942, loss=0.4373506009578705
test: epoch 63, loss 1.4450076818466187, acc=0.5305555462837219, loss=1.4450076818466187
train: epoch 64, loss 0.43581071496009827, acc=0.8111110925674438, loss=0.43581071496009827
test: epoch 64, loss 1.0110028982162476, acc=0.5416666865348816, loss=1.0110028982162476
train: epoch 65, loss 0.43409737944602966, acc=0.812166690826416, loss=0.43409737944602966
test: epoch 65, loss 1.4541863203048706, acc=0.5222222208976746, loss=1.4541863203048706
train: epoch 66, loss 0.42657408118247986, acc=0.8130000233650208, loss=0.42657408118247986
test: epoch 66, loss 1.4612454175949097, acc=0.5277777910232544, loss=1.4612454175949097
train: epoch 67, loss 0.4434215724468231, acc=0.8103888630867004, loss=0.4434215724468231
test: epoch 67, loss 1.3391486406326294, acc=0.5527777671813965, loss=1.3391486406326294
train: epoch 68, loss 0.41516557335853577, acc=0.8183888792991638, loss=0.41516557335853577
test: epoch 68, loss 1.3016185760498047, acc=0.5833333134651184, loss=1.3016185760498047
train: epoch 69, loss 0.4194948375225067, acc=0.8171111345291138, loss=0.4194948375225067
test: epoch 69, loss 1.126893401145935, acc=0.5777778029441833, loss=1.126893401145935
train: epoch 70, loss 0.43301627039909363, acc=0.8134999871253967, loss=0.43301627039909363
test: epoch 70, loss 1.5064667463302612, acc=0.5694444179534912, loss=1.5064667463302612
train: epoch 71, loss 0.444816917181015, acc=0.8107777833938599, loss=0.444816917181015
test: epoch 71, loss 1.3218655586242676, acc=0.5638889074325562, loss=1.3218655586242676
train: epoch 72, loss 0.411894291639328, acc=0.820277750492096, loss=0.411894291639328
test: epoch 72, loss 1.280292272567749, acc=0.5638889074325562, loss=1.280292272567749
train: epoch 73, loss 0.4182230830192566, acc=0.820888876914978, loss=0.4182230830192566
test: epoch 73, loss 1.2244198322296143, acc=0.5555555820465088, loss=1.2244198322296143
train: epoch 74, loss 0.4095698297023773, acc=0.8173333406448364, loss=0.4095698297023773
test: epoch 74, loss 1.2640060186386108, acc=0.4972222149372101, loss=1.2640060186386108
train: epoch 75, loss 0.4075106084346771, acc=0.8212222456932068, loss=0.4075106084346771
test: epoch 75, loss 1.1229194402694702, acc=0.5305555462837219, loss=1.1229194402694702
train: epoch 76, loss 0.41310203075408936, acc=0.8189444541931152, loss=0.41310203075408936
test: epoch 76, loss 0.9808700084686279, acc=0.574999988079071, loss=0.9808700084686279
train: epoch 77, loss 0.4172367453575134, acc=0.8180000185966492, loss=0.4172367453575134
test: epoch 77, loss 1.4216067790985107, acc=0.5694444179534912, loss=1.4216067790985107
train: epoch 78, loss 0.4112285077571869, acc=0.8171111345291138, loss=0.4112285077571869
test: epoch 78, loss 1.7285512685775757, acc=0.5444444417953491, loss=1.7285512685775757
train: epoch 79, loss 0.405330628156662, acc=0.8209999799728394, loss=0.405330628156662
test: epoch 79, loss 1.1957098245620728, acc=0.5888888835906982, loss=1.1957098245620728
train: epoch 80, loss 0.4086964726448059, acc=0.8206111192703247, loss=0.4086964726448059
test: epoch 80, loss 1.1971282958984375, acc=0.5166666507720947, loss=1.1971282958984375
train: epoch 81, loss 0.40272244811058044, acc=0.8224999904632568, loss=0.40272244811058044
test: epoch 81, loss 1.2722254991531372, acc=0.5833333134651184, loss=1.2722254991531372
train: epoch 82, loss 0.4094611704349518, acc=0.820722222328186, loss=0.4094611704349518
test: epoch 82, loss 1.3571170568466187, acc=0.5666666626930237, loss=1.3571170568466187
train: epoch 83, loss 0.3934984803199768, acc=0.8234444260597229, loss=0.3934984803199768
test: epoch 83, loss 1.33341646194458, acc=0.550000011920929, loss=1.33341646194458
train: epoch 84, loss 0.41386786103248596, acc=0.8202221989631653, loss=0.41386786103248596
test: epoch 84, loss 1.1283013820648193, acc=0.6138888597488403, loss=1.1283013820648193
train: epoch 85, loss 0.39098384976387024, acc=0.824388861656189, loss=0.39098384976387024
test: epoch 85, loss 1.3869833946228027, acc=0.6083333492279053, loss=1.3869833946228027
train: epoch 86, loss 0.40040600299835205, acc=0.8218888640403748, loss=0.40040600299835205
test: epoch 86, loss 1.292076826095581, acc=0.5611110925674438, loss=1.292076826095581
train: epoch 87, loss 0.41388168931007385, acc=0.8179444670677185, loss=0.41388168931007385
test: epoch 87, loss 1.2718526124954224, acc=0.5555555820465088, loss=1.2718526124954224
train: epoch 88, loss 0.39903104305267334, acc=0.8222222328186035, loss=0.39903104305267334
test: epoch 88, loss 1.140262246131897, acc=0.5944444537162781, loss=1.140262246131897
train: epoch 89, loss 0.39067980647087097, acc=0.8267222046852112, loss=0.39067980647087097
test: epoch 89, loss 1.084978461265564, acc=0.6111111044883728, loss=1.084978461265564
train: epoch 90, loss 0.4021700322628021, acc=0.824055552482605, loss=0.4021700322628021
test: epoch 90, loss 1.3591868877410889, acc=0.5555555820465088, loss=1.3591868877410889
train: epoch 91, loss 0.39411044120788574, acc=0.8266666531562805, loss=0.39411044120788574
test: epoch 91, loss 1.100961685180664, acc=0.6083333492279053, loss=1.100961685180664
train: epoch 92, loss 0.40174204111099243, acc=0.8238333463668823, loss=0.40174204111099243
test: epoch 92, loss 1.1810946464538574, acc=0.5638889074325562, loss=1.1810946464538574
train: epoch 93, loss 0.389837384223938, acc=0.824222207069397, loss=0.389837384223938
test: epoch 93, loss 1.0937939882278442, acc=0.5944444537162781, loss=1.0937939882278442
train: epoch 94, loss 0.3877079486846924, acc=0.8252778053283691, loss=0.3877079486846924
test: epoch 94, loss 1.3177868127822876, acc=0.5777778029441833, loss=1.3177868127822876
train: epoch 95, loss 0.4151649475097656, acc=0.8176666498184204, loss=0.4151649475097656
test: epoch 95, loss 1.3586112260818481, acc=0.5694444179534912, loss=1.3586112260818481
train: epoch 96, loss 0.3827914893627167, acc=0.8297777771949768, loss=0.3827914893627167
test: epoch 96, loss 1.1597124338150024, acc=0.5611110925674438, loss=1.1597124338150024
train: epoch 97, loss 0.3860362470149994, acc=0.827833354473114, loss=0.3860362470149994
test: epoch 97, loss 1.1712082624435425, acc=0.5861111283302307, loss=1.1712082624435425
train: epoch 98, loss 0.3923111855983734, acc=0.8253333568572998, loss=0.3923111855983734
test: epoch 98, loss 1.4070706367492676, acc=0.5472221970558167, loss=1.4070706367492676
train: epoch 99, loss 0.38405412435531616, acc=0.828499972820282, loss=0.38405412435531616
test: epoch 99, loss 1.1897438764572144, acc=0.6083333492279053, loss=1.1897438764572144
train: epoch 100, loss 0.38398200273513794, acc=0.8286666870117188, loss=0.38398200273513794
test: epoch 100, loss 1.3509521484375, acc=0.6111111044883728, loss=1.3509521484375
train: epoch 101, loss 0.38429397344589233, acc=0.8294444680213928, loss=0.38429397344589233
test: epoch 101, loss 1.303564429283142, acc=0.5694444179534912, loss=1.303564429283142
train: epoch 102, loss 0.37654662132263184, acc=0.8308888673782349, loss=0.37654662132263184
test: epoch 102, loss 1.0331908464431763, acc=0.6027777791023254, loss=1.0331908464431763
train: epoch 103, loss 0.3798498511314392, acc=0.82833331823349, loss=0.3798498511314392
test: epoch 103, loss 1.3135676383972168, acc=0.5638889074325562, loss=1.3135676383972168
train: epoch 104, loss 0.395540326833725, acc=0.8271666765213013, loss=0.395540326833725
test: epoch 104, loss 1.2474802732467651, acc=0.5972222089767456, loss=1.2474802732467651
train: epoch 105, loss 0.3803952634334564, acc=0.829277753829956, loss=0.3803952634334564
test: epoch 105, loss 1.2986280918121338, acc=0.5694444179534912, loss=1.2986280918121338
train: epoch 106, loss 0.3824057877063751, acc=0.8266111016273499, loss=0.3824057877063751
test: epoch 106, loss 1.0636662244796753, acc=0.5861111283302307, loss=1.0636662244796753
train: epoch 107, loss 0.37707605957984924, acc=0.8307222127914429, loss=0.37707605957984924
test: epoch 107, loss 1.018682837486267, acc=0.6000000238418579, loss=1.018682837486267
train: epoch 108, loss 0.38069555163383484, acc=0.8299444317817688, loss=0.38069555163383484
test: epoch 108, loss 1.1674184799194336, acc=0.5694444179534912, loss=1.1674184799194336
train: epoch 109, loss 0.38496363162994385, acc=0.8284444212913513, loss=0.38496363162994385
test: epoch 109, loss 1.0232733488082886, acc=0.5888888835906982, loss=1.0232733488082886
train: epoch 110, loss 0.39366087317466736, acc=0.8271111249923706, loss=0.39366087317466736
test: epoch 110, loss 1.0687721967697144, acc=0.5944444537162781, loss=1.0687721967697144
train: epoch 111, loss 0.3703041076660156, acc=0.8333333134651184, loss=0.3703041076660156
test: epoch 111, loss 1.3689963817596436, acc=0.5555555820465088, loss=1.3689963817596436
train: epoch 112, loss 0.3878188133239746, acc=0.8266666531562805, loss=0.3878188133239746
test: epoch 112, loss 1.080838918685913, acc=0.6138888597488403, loss=1.080838918685913
train: epoch 113, loss 0.37165918946266174, acc=0.8335555791854858, loss=0.37165918946266174
test: epoch 113, loss 1.3161929845809937, acc=0.5694444179534912, loss=1.3161929845809937
train: epoch 114, loss 0.37561509013175964, acc=0.8318333625793457, loss=0.37561509013175964
test: epoch 114, loss 1.1799489259719849, acc=0.6111111044883728, loss=1.1799489259719849
train: epoch 115, loss 0.38011786341667175, acc=0.8302222490310669, loss=0.38011786341667175
test: epoch 115, loss 1.4127119779586792, acc=0.5444444417953491, loss=1.4127119779586792
train: epoch 116, loss 0.3777865469455719, acc=0.8293333053588867, loss=0.3777865469455719
test: epoch 116, loss 1.2985926866531372, acc=0.6000000238418579, loss=1.2985926866531372
train: epoch 117, loss 0.38403889536857605, acc=0.8286666870117188, loss=0.38403889536857605
test: epoch 117, loss 1.1100046634674072, acc=0.5944444537162781, loss=1.1100046634674072
train: epoch 118, loss 0.373328298330307, acc=0.8297222256660461, loss=0.373328298330307
test: epoch 118, loss 1.279123306274414, acc=0.5611110925674438, loss=1.279123306274414
train: epoch 119, loss 0.3764282763004303, acc=0.832111120223999, loss=0.3764282763004303
test: epoch 119, loss 1.1230158805847168, acc=0.5777778029441833, loss=1.1230158805847168
train: epoch 120, loss 0.37286093831062317, acc=0.8314999938011169, loss=0.37286093831062317
test: epoch 120, loss 1.2003607749938965, acc=0.574999988079071, loss=1.2003607749938965
train: epoch 121, loss 0.37017789483070374, acc=0.8335555791854858, loss=0.37017789483070374
test: epoch 121, loss 1.1088650226593018, acc=0.6027777791023254, loss=1.1088650226593018
train: epoch 122, loss 0.3950783610343933, acc=0.824055552482605, loss=0.3950783610343933
test: epoch 122, loss 1.1874057054519653, acc=0.605555534362793, loss=1.1874057054519653
train: epoch 123, loss 0.36738380789756775, acc=0.8323333263397217, loss=0.36738380789756775
test: epoch 123, loss 1.173195242881775, acc=0.5972222089767456, loss=1.173195242881775
train: epoch 124, loss 0.3708459436893463, acc=0.831333339214325, loss=0.3708459436893463
test: epoch 124, loss 1.0712518692016602, acc=0.6194444298744202, loss=1.0712518692016602
train: epoch 125, loss 0.3749026954174042, acc=0.8322222232818604, loss=0.3749026954174042
test: epoch 125, loss 1.1142395734786987, acc=0.625, loss=1.1142395734786987
train: epoch 126, loss 0.37989139556884766, acc=0.8299444317817688, loss=0.37989139556884766
test: epoch 126, loss 1.0347869396209717, acc=0.6138888597488403, loss=1.0347869396209717
train: epoch 127, loss 0.36387839913368225, acc=0.8353888988494873, loss=0.36387839913368225
test: epoch 127, loss 1.1112003326416016, acc=0.6138888597488403, loss=1.1112003326416016
train: epoch 128, loss 0.3668389618396759, acc=0.8355555534362793, loss=0.3668389618396759
test: epoch 128, loss 1.1217234134674072, acc=0.6166666746139526, loss=1.1217234134674072
train: epoch 129, loss 0.375554621219635, acc=0.8328889012336731, loss=0.375554621219635
test: epoch 129, loss 1.3604085445404053, acc=0.550000011920929, loss=1.3604085445404053
train: epoch 130, loss 0.3608908951282501, acc=0.8368333578109741, loss=0.3608908951282501
test: epoch 130, loss 1.074044942855835, acc=0.5555555820465088, loss=1.074044942855835
train: epoch 131, loss 0.37907540798187256, acc=0.8314999938011169, loss=0.37907540798187256
test: epoch 131, loss 1.2526241540908813, acc=0.5888888835906982, loss=1.2526241540908813
train: epoch 132, loss 0.3611685633659363, acc=0.8398333191871643, loss=0.3611685633659363
test: epoch 132, loss 1.2035187482833862, acc=0.6000000238418579, loss=1.2035187482833862
train: epoch 133, loss 0.35749420523643494, acc=0.8388333320617676, loss=0.35749420523643494
test: epoch 133, loss 1.3191026449203491, acc=0.550000011920929, loss=1.3191026449203491
train: epoch 134, loss 0.3537665903568268, acc=0.8402222394943237, loss=0.3537665903568268
test: epoch 134, loss 1.3738716840744019, acc=0.5972222089767456, loss=1.3738716840744019
train: epoch 135, loss 0.3584902584552765, acc=0.8368333578109741, loss=0.3584902584552765
test: epoch 135, loss 1.0871258974075317, acc=0.6000000238418579, loss=1.0871258974075317
train: epoch 136, loss 0.36022016406059265, acc=0.8377777934074402, loss=0.36022016406059265
test: epoch 136, loss 1.2551027536392212, acc=0.5944444537162781, loss=1.2551027536392212
train: epoch 137, loss 0.3598639667034149, acc=0.8377777934074402, loss=0.3598639667034149
test: epoch 137, loss 1.1160318851470947, acc=0.5916666388511658, loss=1.1160318851470947
train: epoch 138, loss 0.35851427912712097, acc=0.8369444608688354, loss=0.35851427912712097
test: epoch 138, loss 1.233715295791626, acc=0.605555534362793, loss=1.233715295791626
train: epoch 139, loss 0.36040136218070984, acc=0.8374444246292114, loss=0.36040136218070984
test: epoch 139, loss 1.1203876733779907, acc=0.5472221970558167, loss=1.1203876733779907
train: epoch 140, loss 0.348087340593338, acc=0.8414444327354431, loss=0.348087340593338
test: epoch 140, loss 1.4137403964996338, acc=0.5694444179534912, loss=1.4137403964996338
train: epoch 141, loss 0.3473370373249054, acc=0.8431666493415833, loss=0.3473370373249054
test: epoch 141, loss 1.0361746549606323, acc=0.5694444179534912, loss=1.0361746549606323
train: epoch 142, loss 0.3644651472568512, acc=0.8369444608688354, loss=0.3644651472568512
test: epoch 142, loss 1.1878031492233276, acc=0.6083333492279053, loss=1.1878031492233276
train: epoch 143, loss 0.3645583987236023, acc=0.8370000123977661, loss=0.3645583987236023
test: epoch 143, loss 1.2690812349319458, acc=0.6083333492279053, loss=1.2690812349319458
train: epoch 144, loss 0.3489241600036621, acc=0.8402222394943237, loss=0.3489241600036621
test: epoch 144, loss 1.3215270042419434, acc=0.5666666626930237, loss=1.3215270042419434
train: epoch 145, loss 0.36395275592803955, acc=0.8383888602256775, loss=0.36395275592803955
test: epoch 145, loss 1.1893244981765747, acc=0.5805555582046509, loss=1.1893244981765747
train: epoch 146, loss 0.35116156935691833, acc=0.839888870716095, loss=0.35116156935691833
test: epoch 146, loss 1.2148609161376953, acc=0.5861111283302307, loss=1.2148609161376953
train: epoch 147, loss 0.36473339796066284, acc=0.8360000252723694, loss=0.36473339796066284
test: epoch 147, loss 0.9842333793640137, acc=0.605555534362793, loss=0.9842333793640137
train: epoch 148, loss 0.33802878856658936, acc=0.8411111235618591, loss=0.33802878856658936
test: epoch 148, loss 1.087307333946228, acc=0.6166666746139526, loss=1.087307333946228
train: epoch 149, loss 0.361724853515625, acc=0.8358333110809326, loss=0.361724853515625
test: epoch 149, loss 1.2292137145996094, acc=0.5861111283302307, loss=1.2292137145996094
train: epoch 150, loss 0.35268616676330566, acc=0.8406111001968384, loss=0.35268616676330566
test: epoch 150, loss 1.4554417133331299, acc=0.5694444179534912, loss=1.4554417133331299
