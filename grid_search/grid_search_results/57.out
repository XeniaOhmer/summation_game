# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=1", "--temp_decay=1", "--one_hot=false", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=2013858873, receiver_embed_dim=64, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.429508686065674, acc=0.053388889878988266, loss=3.429508686065674
test: epoch 1, loss 3.0978639125823975, acc=0.08611111342906952, loss=3.0978639125823975
train: epoch 2, loss 2.4317238330841064, acc=0.14588889479637146, loss=2.4317238330841064
test: epoch 2, loss 2.396836996078491, acc=0.13611111044883728, loss=2.396836996078491
train: epoch 3, loss 1.9478590488433838, acc=0.2442222237586975, loss=1.9478590488433838
test: epoch 3, loss 2.3021035194396973, acc=0.14722222089767456, loss=2.3021035194396973
train: epoch 4, loss 1.7760590314865112, acc=0.28822222352027893, loss=1.7760590314865112
test: epoch 4, loss 2.2453150749206543, acc=0.16944444179534912, loss=2.2453150749206543
train: epoch 5, loss 1.6785778999328613, acc=0.32644444704055786, loss=1.6785778999328613
test: epoch 5, loss 2.2374916076660156, acc=0.1666666716337204, loss=2.2374916076660156
train: epoch 6, loss 1.6066011190414429, acc=0.34788888692855835, loss=1.6066011190414429
test: epoch 6, loss 2.1842660903930664, acc=0.16944444179534912, loss=2.1842660903930664
train: epoch 7, loss 1.5407634973526, acc=0.36577779054641724, loss=1.5407634973526
test: epoch 7, loss 2.1250967979431152, acc=0.20555555820465088, loss=2.1250967979431152
train: epoch 8, loss 1.4748152494430542, acc=0.39266666769981384, loss=1.4748152494430542
test: epoch 8, loss 2.036750555038452, acc=0.21666666865348816, loss=2.036750555038452
train: epoch 9, loss 1.4354666471481323, acc=0.4066111147403717, loss=1.4354666471481323
test: epoch 9, loss 2.1290297508239746, acc=0.2222222238779068, loss=2.1290297508239746
train: epoch 10, loss 1.3729393482208252, acc=0.425555557012558, loss=1.3729393482208252
test: epoch 10, loss 2.0651965141296387, acc=0.21666666865348816, loss=2.0651965141296387
train: epoch 11, loss 1.3494387865066528, acc=0.44449999928474426, loss=1.3494387865066528
test: epoch 11, loss 1.9737695455551147, acc=0.23055554926395416, loss=1.9737695455551147
train: epoch 12, loss 1.2996773719787598, acc=0.46433332562446594, loss=1.2996773719787598
test: epoch 12, loss 2.0186829566955566, acc=0.22499999403953552, loss=2.0186829566955566
train: epoch 13, loss 1.2745779752731323, acc=0.4708888828754425, loss=1.2745779752731323
test: epoch 13, loss 2.005448579788208, acc=0.23055554926395416, loss=2.005448579788208
train: epoch 14, loss 1.2507795095443726, acc=0.4788888990879059, loss=1.2507795095443726
test: epoch 14, loss 1.9081817865371704, acc=0.25555557012557983, loss=1.9081817865371704
train: epoch 15, loss 1.2194013595581055, acc=0.49566665291786194, loss=1.2194013595581055
test: epoch 15, loss 1.9680542945861816, acc=0.25, loss=1.9680542945861816
train: epoch 16, loss 1.201640248298645, acc=0.5040000081062317, loss=1.201640248298645
test: epoch 16, loss 1.9199740886688232, acc=0.25, loss=1.9199740886688232
train: epoch 17, loss 1.1759569644927979, acc=0.5127778053283691, loss=1.1759569644927979
test: epoch 17, loss 1.9350782632827759, acc=0.2611111104488373, loss=1.9350782632827759
train: epoch 18, loss 1.147160530090332, acc=0.5276666879653931, loss=1.147160530090332
test: epoch 18, loss 1.9240690469741821, acc=0.2611111104488373, loss=1.9240690469741821
train: epoch 19, loss 1.1327823400497437, acc=0.5296111106872559, loss=1.1327823400497437
test: epoch 19, loss 1.9027090072631836, acc=0.27222222089767456, loss=1.9027090072631836
train: epoch 20, loss 1.1102852821350098, acc=0.5407222509384155, loss=1.1102852821350098
test: epoch 20, loss 1.8393341302871704, acc=0.2611111104488373, loss=1.8393341302871704
train: epoch 21, loss 1.0885058641433716, acc=0.5488888621330261, loss=1.0885058641433716
test: epoch 21, loss 1.9133528470993042, acc=0.27222222089767456, loss=1.9133528470993042
train: epoch 22, loss 1.0678143501281738, acc=0.5568333268165588, loss=1.0678143501281738
test: epoch 22, loss 1.9076796770095825, acc=0.2750000059604645, loss=1.9076796770095825
train: epoch 23, loss 1.052197813987732, acc=0.570111095905304, loss=1.052197813987732
test: epoch 23, loss 1.9139856100082397, acc=0.2777777910232544, loss=1.9139856100082397
train: epoch 24, loss 1.026829719543457, acc=0.5784444212913513, loss=1.026829719543457
test: epoch 24, loss 1.8257640600204468, acc=0.2916666567325592, loss=1.8257640600204468
train: epoch 25, loss 1.0185052156448364, acc=0.5815555453300476, loss=1.0185052156448364
test: epoch 25, loss 1.8942126035690308, acc=0.2805555462837219, loss=1.8942126035690308
train: epoch 26, loss 0.9987126588821411, acc=0.5880555510520935, loss=0.9987126588821411
test: epoch 26, loss 1.8550620079040527, acc=0.28611111640930176, loss=1.8550620079040527
train: epoch 27, loss 0.9767723083496094, acc=0.5962777733802795, loss=0.9767723083496094
test: epoch 27, loss 1.8936060667037964, acc=0.28611111640930176, loss=1.8936060667037964
train: epoch 28, loss 0.9772912859916687, acc=0.5947777628898621, loss=0.9772912859916687
test: epoch 28, loss 1.8975523710250854, acc=0.28611111640930176, loss=1.8975523710250854
train: epoch 29, loss 0.9391787648200989, acc=0.6117777824401855, loss=0.9391787648200989
test: epoch 29, loss 1.8459516763687134, acc=0.2916666567325592, loss=1.8459516763687134
train: epoch 30, loss 0.9488316178321838, acc=0.6073889136314392, loss=0.9488316178321838
test: epoch 30, loss 2.027324914932251, acc=0.2888889014720917, loss=2.027324914932251
train: epoch 31, loss 0.935854971408844, acc=0.6106111407279968, loss=0.935854971408844
test: epoch 31, loss 2.0054876804351807, acc=0.3055555522441864, loss=2.0054876804351807
train: epoch 32, loss 0.9330307841300964, acc=0.6163889169692993, loss=0.9330307841300964
test: epoch 32, loss 1.8820374011993408, acc=0.2805555462837219, loss=1.8820374011993408
train: epoch 33, loss 0.9169182777404785, acc=0.6211666464805603, loss=0.9169182777404785
test: epoch 33, loss 1.9503272771835327, acc=0.2916666567325592, loss=1.9503272771835327
train: epoch 34, loss 0.8905118107795715, acc=0.6295555830001831, loss=0.8905118107795715
test: epoch 34, loss 2.04848313331604, acc=0.30000001192092896, loss=2.04848313331604
train: epoch 35, loss 0.9006966352462769, acc=0.6242222189903259, loss=0.9006966352462769
test: epoch 35, loss 1.850447654724121, acc=0.2944444417953491, loss=1.850447654724121
train: epoch 36, loss 0.8825570940971375, acc=0.6288889050483704, loss=0.8825570940971375
test: epoch 36, loss 2.0858569145202637, acc=0.30000001192092896, loss=2.0858569145202637
train: epoch 37, loss 0.8772456645965576, acc=0.6385555267333984, loss=0.8772456645965576
test: epoch 37, loss 2.0762176513671875, acc=0.2916666567325592, loss=2.0762176513671875
train: epoch 38, loss 0.8662803173065186, acc=0.6366111040115356, loss=0.8662803173065186
test: epoch 38, loss 1.8350434303283691, acc=0.31388887763023376, loss=1.8350434303283691
train: epoch 39, loss 0.8559823036193848, acc=0.6426110863685608, loss=0.8559823036193848
test: epoch 39, loss 2.1373634338378906, acc=0.29722222685813904, loss=2.1373634338378906
train: epoch 40, loss 0.8464351296424866, acc=0.6411666870117188, loss=0.8464351296424866
test: epoch 40, loss 2.017932415008545, acc=0.3055555522441864, loss=2.017932415008545
train: epoch 41, loss 0.8518615365028381, acc=0.6461666822433472, loss=0.8518615365028381
test: epoch 41, loss 1.8886234760284424, acc=0.31111112236976624, loss=1.8886234760284424
train: epoch 42, loss 0.8290934562683105, acc=0.6465555429458618, loss=0.8290934562683105
test: epoch 42, loss 1.9838465452194214, acc=0.3083333373069763, loss=1.9838465452194214
train: epoch 43, loss 0.8364682793617249, acc=0.6464999914169312, loss=0.8364682793617249
test: epoch 43, loss 1.9885971546173096, acc=0.3083333373069763, loss=1.9885971546173096
train: epoch 44, loss 0.8341103196144104, acc=0.6499444246292114, loss=0.8341103196144104
test: epoch 44, loss 1.9552656412124634, acc=0.3027777671813965, loss=1.9552656412124634
train: epoch 45, loss 0.8167957067489624, acc=0.6512777805328369, loss=0.8167957067489624
test: epoch 45, loss 1.9478474855422974, acc=0.3055555522441864, loss=1.9478474855422974
train: epoch 46, loss 0.8094562888145447, acc=0.656333327293396, loss=0.8094562888145447
test: epoch 46, loss 2.0106539726257324, acc=0.29722222685813904, loss=2.0106539726257324
train: epoch 47, loss 0.7979820370674133, acc=0.6589444279670715, loss=0.7979820370674133
test: epoch 47, loss 2.0260214805603027, acc=0.29722222685813904, loss=2.0260214805603027
train: epoch 48, loss 0.8039062023162842, acc=0.6593888998031616, loss=0.8039062023162842
test: epoch 48, loss 2.1017637252807617, acc=0.3083333373069763, loss=2.1017637252807617
train: epoch 49, loss 0.8076233267784119, acc=0.6623333096504211, loss=0.8076233267784119
test: epoch 49, loss 2.2191853523254395, acc=0.3305555582046509, loss=2.2191853523254395
train: epoch 50, loss 0.8072289824485779, acc=0.6580555438995361, loss=0.8072289824485779
test: epoch 50, loss 2.0012080669403076, acc=0.3305555582046509, loss=2.0012080669403076
train: epoch 51, loss 0.8070265054702759, acc=0.6545555591583252, loss=0.8070265054702759
test: epoch 51, loss 1.9220712184906006, acc=0.3361110985279083, loss=1.9220712184906006
train: epoch 52, loss 0.7806239724159241, acc=0.6666111350059509, loss=0.7806239724159241
test: epoch 52, loss 1.9301435947418213, acc=0.3333333432674408, loss=1.9301435947418213
train: epoch 53, loss 0.7909507155418396, acc=0.6654999852180481, loss=0.7909507155418396
test: epoch 53, loss 1.9883314371109009, acc=0.34166666865348816, loss=1.9883314371109009
train: epoch 54, loss 0.7841575145721436, acc=0.6627222299575806, loss=0.7841575145721436
test: epoch 54, loss 2.0594241619110107, acc=0.3472222089767456, loss=2.0594241619110107
train: epoch 55, loss 0.7740060091018677, acc=0.667388916015625, loss=0.7740060091018677
test: epoch 55, loss 2.1149721145629883, acc=0.3305555582046509, loss=2.1149721145629883
train: epoch 56, loss 0.7729290723800659, acc=0.6697221994400024, loss=0.7729290723800659
test: epoch 56, loss 2.0252935886383057, acc=0.35277777910232544, loss=2.0252935886383057
train: epoch 57, loss 0.7807838320732117, acc=0.664222240447998, loss=0.7807838320732117
test: epoch 57, loss 2.077768564224243, acc=0.34166666865348816, loss=2.077768564224243
train: epoch 58, loss 0.7721511721611023, acc=0.6696110963821411, loss=0.7721511721611023
test: epoch 58, loss 2.0916428565979004, acc=0.3472222089767456, loss=2.0916428565979004
train: epoch 59, loss 0.7600976228713989, acc=0.6748889088630676, loss=0.7600976228713989
test: epoch 59, loss 2.0400941371917725, acc=0.33888888359069824, loss=2.0400941371917725
train: epoch 60, loss 0.7649663090705872, acc=0.6696110963821411, loss=0.7649663090705872
test: epoch 60, loss 2.2082018852233887, acc=0.3194444477558136, loss=2.2082018852233887
train: epoch 61, loss 0.763644814491272, acc=0.6747221946716309, loss=0.763644814491272
test: epoch 61, loss 2.0146329402923584, acc=0.3333333432674408, loss=2.0146329402923584
train: epoch 62, loss 0.7516217231750488, acc=0.6801111102104187, loss=0.7516217231750488
test: epoch 62, loss 1.9554328918457031, acc=0.3472222089767456, loss=1.9554328918457031
train: epoch 63, loss 0.7534357905387878, acc=0.6752222180366516, loss=0.7534357905387878
test: epoch 63, loss 1.9337599277496338, acc=0.3361110985279083, loss=1.9337599277496338
train: epoch 64, loss 0.7511122226715088, acc=0.6766111254692078, loss=0.7511122226715088
test: epoch 64, loss 2.1203956604003906, acc=0.3222222328186035, loss=2.1203956604003906
train: epoch 65, loss 0.7534331679344177, acc=0.6779999732971191, loss=0.7534331679344177
test: epoch 65, loss 2.0131444931030273, acc=0.33888888359069824, loss=2.0131444931030273
train: epoch 66, loss 0.7516805529594421, acc=0.6767222285270691, loss=0.7516805529594421
test: epoch 66, loss 2.0355522632598877, acc=0.3611111044883728, loss=2.0355522632598877
train: epoch 67, loss 0.7597064971923828, acc=0.6765000224113464, loss=0.7597064971923828
test: epoch 67, loss 2.1847949028015137, acc=0.33888888359069824, loss=2.1847949028015137
train: epoch 68, loss 0.7324971556663513, acc=0.6807777881622314, loss=0.7324971556663513
test: epoch 68, loss 2.128693103790283, acc=0.3611111044883728, loss=2.128693103790283
train: epoch 69, loss 0.7357490658760071, acc=0.6827222108840942, loss=0.7357490658760071
test: epoch 69, loss 2.0026309490203857, acc=0.3499999940395355, loss=2.0026309490203857
train: epoch 70, loss 0.7429788708686829, acc=0.6821666955947876, loss=0.7429788708686829
test: epoch 70, loss 1.9790310859680176, acc=0.36944442987442017, loss=1.9790310859680176
train: epoch 71, loss 0.7398712635040283, acc=0.6857222318649292, loss=0.7398712635040283
test: epoch 71, loss 1.9933658838272095, acc=0.3333333432674408, loss=1.9933658838272095
train: epoch 72, loss 0.7373250722885132, acc=0.6861110925674438, loss=0.7373250722885132
test: epoch 72, loss 2.1352109909057617, acc=0.33888888359069824, loss=2.1352109909057617
train: epoch 73, loss 0.7295510768890381, acc=0.6876111030578613, loss=0.7295510768890381
test: epoch 73, loss 1.9915692806243896, acc=0.35555556416511536, loss=1.9915692806243896
train: epoch 74, loss 0.73963463306427, acc=0.6826666593551636, loss=0.73963463306427
test: epoch 74, loss 2.0166518688201904, acc=0.3472222089767456, loss=2.0166518688201904
train: epoch 75, loss 0.7319289445877075, acc=0.6828888654708862, loss=0.7319289445877075
test: epoch 75, loss 2.2023282051086426, acc=0.3499999940395355, loss=2.2023282051086426
train: epoch 76, loss 0.7230532765388489, acc=0.6920555830001831, loss=0.7230532765388489
test: epoch 76, loss 2.026900053024292, acc=0.3722222149372101, loss=2.026900053024292
train: epoch 77, loss 0.7191417813301086, acc=0.691277801990509, loss=0.7191417813301086
test: epoch 77, loss 2.035132646560669, acc=0.3638888895511627, loss=2.035132646560669
train: epoch 78, loss 0.7238787412643433, acc=0.691777765750885, loss=0.7238787412643433
test: epoch 78, loss 2.087934970855713, acc=0.36666667461395264, loss=2.087934970855713
train: epoch 79, loss 0.7260408401489258, acc=0.6882222294807434, loss=0.7260408401489258
test: epoch 79, loss 1.9520807266235352, acc=0.35555556416511536, loss=1.9520807266235352
train: epoch 80, loss 0.7221799492835999, acc=0.694944441318512, loss=0.7221799492835999
test: epoch 80, loss 2.083045721054077, acc=0.3444444537162781, loss=2.083045721054077
train: epoch 81, loss 0.7123532295227051, acc=0.6957777738571167, loss=0.7123532295227051
test: epoch 81, loss 2.261467456817627, acc=0.3722222149372101, loss=2.261467456817627
train: epoch 82, loss 0.712426483631134, acc=0.6972222328186035, loss=0.712426483631134
test: epoch 82, loss 2.098351001739502, acc=0.36666667461395264, loss=2.098351001739502
train: epoch 83, loss 0.7153563499450684, acc=0.6916666626930237, loss=0.7153563499450684
test: epoch 83, loss 2.190415620803833, acc=0.35555556416511536, loss=2.190415620803833
train: epoch 84, loss 0.7130894660949707, acc=0.6949999928474426, loss=0.7130894660949707
test: epoch 84, loss 1.938140869140625, acc=0.3722222149372101, loss=1.938140869140625
train: epoch 85, loss 0.714552640914917, acc=0.6895555257797241, loss=0.714552640914917
test: epoch 85, loss 2.0671465396881104, acc=0.3638888895511627, loss=2.0671465396881104
train: epoch 86, loss 0.7188154458999634, acc=0.6937222480773926, loss=0.7188154458999634
test: epoch 86, loss 2.137460947036743, acc=0.3722222149372101, loss=2.137460947036743
train: epoch 87, loss 0.7057610750198364, acc=0.7002778053283691, loss=0.7057610750198364
test: epoch 87, loss 2.2547614574432373, acc=0.375, loss=2.2547614574432373
train: epoch 88, loss 0.7037400007247925, acc=0.6969444155693054, loss=0.7037400007247925
test: epoch 88, loss 2.1329009532928467, acc=0.36944442987442017, loss=2.1329009532928467
train: epoch 89, loss 0.7075260877609253, acc=0.6996111273765564, loss=0.7075260877609253
test: epoch 89, loss 2.08660888671875, acc=0.3722222149372101, loss=2.08660888671875
train: epoch 90, loss 0.7100536823272705, acc=0.6952221989631653, loss=0.7100536823272705
test: epoch 90, loss 2.289827585220337, acc=0.3583333194255829, loss=2.289827585220337
train: epoch 91, loss 0.7117547988891602, acc=0.69605553150177, loss=0.7117547988891602
test: epoch 91, loss 2.3681435585021973, acc=0.3638888895511627, loss=2.3681435585021973
train: epoch 92, loss 0.7063660621643066, acc=0.6973333358764648, loss=0.7063660621643066
test: epoch 92, loss 2.1366004943847656, acc=0.3638888895511627, loss=2.1366004943847656
train: epoch 93, loss 0.6979475617408752, acc=0.6989444494247437, loss=0.6979475617408752
test: epoch 93, loss 2.3736379146575928, acc=0.38055557012557983, loss=2.3736379146575928
train: epoch 94, loss 0.7012847065925598, acc=0.6972222328186035, loss=0.7012847065925598
test: epoch 94, loss 2.1169421672821045, acc=0.36666667461395264, loss=2.1169421672821045
train: epoch 95, loss 0.7011908888816833, acc=0.6969444155693054, loss=0.7011908888816833
test: epoch 95, loss 2.0946004390716553, acc=0.3777777850627899, loss=2.0946004390716553
train: epoch 96, loss 0.6947001218795776, acc=0.6990000009536743, loss=0.6947001218795776
test: epoch 96, loss 2.2070677280426025, acc=0.38055557012557983, loss=2.2070677280426025
train: epoch 97, loss 0.6978709101676941, acc=0.7006666660308838, loss=0.6978709101676941
test: epoch 97, loss 2.243109941482544, acc=0.375, loss=2.243109941482544
train: epoch 98, loss 0.7032734751701355, acc=0.7011111378669739, loss=0.7032734751701355
test: epoch 98, loss 2.2162728309631348, acc=0.38055557012557983, loss=2.2162728309631348
train: epoch 99, loss 0.7006728649139404, acc=0.7017222046852112, loss=0.7006728649139404
test: epoch 99, loss 2.1318671703338623, acc=0.375, loss=2.1318671703338623
train: epoch 100, loss 0.6944719552993774, acc=0.7036111354827881, loss=0.6944719552993774
test: epoch 100, loss 2.275144577026367, acc=0.3611111044883728, loss=2.275144577026367
train: epoch 101, loss 0.6851664185523987, acc=0.7068333625793457, loss=0.6851664185523987
test: epoch 101, loss 2.1684234142303467, acc=0.3583333194255829, loss=2.1684234142303467
train: epoch 102, loss 0.6841669082641602, acc=0.7058333158493042, loss=0.6841669082641602
test: epoch 102, loss 2.224104166030884, acc=0.3888888955116272, loss=2.224104166030884
train: epoch 103, loss 0.6873695254325867, acc=0.7078889012336731, loss=0.6873695254325867
test: epoch 103, loss 2.081953763961792, acc=0.3777777850627899, loss=2.081953763961792
train: epoch 104, loss 0.699422299861908, acc=0.7042222023010254, loss=0.699422299861908
test: epoch 104, loss 2.1413791179656982, acc=0.3777777850627899, loss=2.1413791179656982
train: epoch 105, loss 0.6904628872871399, acc=0.70333331823349, loss=0.6904628872871399
test: epoch 105, loss 1.9875843524932861, acc=0.38333332538604736, loss=1.9875843524932861
train: epoch 106, loss 0.6868816614151001, acc=0.7072222232818604, loss=0.6868816614151001
test: epoch 106, loss 2.0446228981018066, acc=0.38055557012557983, loss=2.0446228981018066
train: epoch 107, loss 0.6816520690917969, acc=0.7132777571678162, loss=0.6816520690917969
test: epoch 107, loss 2.298304557800293, acc=0.3888888955116272, loss=2.298304557800293
train: epoch 108, loss 0.6737222671508789, acc=0.7138333320617676, loss=0.6737222671508789
test: epoch 108, loss 2.0429322719573975, acc=0.38333332538604736, loss=2.0429322719573975
train: epoch 109, loss 0.6727966070175171, acc=0.7146666646003723, loss=0.6727966070175171
test: epoch 109, loss 2.392646074295044, acc=0.38055557012557983, loss=2.392646074295044
train: epoch 110, loss 0.6740201711654663, acc=0.7120000123977661, loss=0.6740201711654663
test: epoch 110, loss 2.2018887996673584, acc=0.3861111104488373, loss=2.2018887996673584
train: epoch 111, loss 0.6812435388565063, acc=0.7121666669845581, loss=0.6812435388565063
test: epoch 111, loss 2.351318836212158, acc=0.39444443583488464, loss=2.351318836212158
train: epoch 112, loss 0.6772893667221069, acc=0.7137222290039062, loss=0.6772893667221069
test: epoch 112, loss 2.02919602394104, acc=0.3916666805744171, loss=2.02919602394104
train: epoch 113, loss 0.6637735366821289, acc=0.7151666879653931, loss=0.6637735366821289
test: epoch 113, loss 2.2308990955352783, acc=0.38055557012557983, loss=2.2308990955352783
train: epoch 114, loss 0.6704205274581909, acc=0.7142221927642822, loss=0.6704205274581909
test: epoch 114, loss 2.1836435794830322, acc=0.3777777850627899, loss=2.1836435794830322
train: epoch 115, loss 0.6656303405761719, acc=0.7137777805328369, loss=0.6656303405761719
test: epoch 115, loss 2.003777503967285, acc=0.36944442987442017, loss=2.003777503967285
train: epoch 116, loss 0.6666896343231201, acc=0.7145000100135803, loss=0.6666896343231201
test: epoch 116, loss 2.0038697719573975, acc=0.3777777850627899, loss=2.0038697719573975
train: epoch 117, loss 0.66343092918396, acc=0.7131111025810242, loss=0.66343092918396
test: epoch 117, loss 2.1285648345947266, acc=0.3888888955116272, loss=2.1285648345947266
train: epoch 118, loss 0.6648749709129333, acc=0.7201666831970215, loss=0.6648749709129333
test: epoch 118, loss 2.125192642211914, acc=0.38333332538604736, loss=2.125192642211914
train: epoch 119, loss 0.6555779576301575, acc=0.7192222476005554, loss=0.6555779576301575
test: epoch 119, loss 2.3532137870788574, acc=0.3861111104488373, loss=2.3532137870788574
train: epoch 120, loss 0.6658614873886108, acc=0.7149999737739563, loss=0.6658614873886108
test: epoch 120, loss 2.309858798980713, acc=0.38055557012557983, loss=2.309858798980713
train: epoch 121, loss 0.6477265954017639, acc=0.7212222218513489, loss=0.6477265954017639
test: epoch 121, loss 2.0396788120269775, acc=0.38333332538604736, loss=2.0396788120269775
train: epoch 122, loss 0.6651580929756165, acc=0.7197777628898621, loss=0.6651580929756165
test: epoch 122, loss 2.3860979080200195, acc=0.3888888955116272, loss=2.3860979080200195
train: epoch 123, loss 0.6666834950447083, acc=0.717555582523346, loss=0.6666834950447083
test: epoch 123, loss 2.117363452911377, acc=0.375, loss=2.117363452911377
train: epoch 124, loss 0.6571940779685974, acc=0.718833327293396, loss=0.6571940779685974
test: epoch 124, loss 2.286405086517334, acc=0.3861111104488373, loss=2.286405086517334
train: epoch 125, loss 0.662968635559082, acc=0.717555582523346, loss=0.662968635559082
test: epoch 125, loss 2.1767873764038086, acc=0.4055555462837219, loss=2.1767873764038086
train: epoch 126, loss 0.6566813588142395, acc=0.7198333144187927, loss=0.6566813588142395
test: epoch 126, loss 2.127202033996582, acc=0.3861111104488373, loss=2.127202033996582
train: epoch 127, loss 0.6564465165138245, acc=0.718666672706604, loss=0.6564465165138245
test: epoch 127, loss 2.0349040031433105, acc=0.39722222089767456, loss=2.0349040031433105
train: epoch 128, loss 0.6466364860534668, acc=0.7210000157356262, loss=0.6466364860534668
test: epoch 128, loss 2.226773262023926, acc=0.4027777910232544, loss=2.226773262023926
train: epoch 129, loss 0.6673250794410706, acc=0.7163888812065125, loss=0.6673250794410706
test: epoch 129, loss 2.181621789932251, acc=0.3638888895511627, loss=2.181621789932251
train: epoch 130, loss 0.6498235464096069, acc=0.7221666574478149, loss=0.6498235464096069
test: epoch 130, loss 2.3641958236694336, acc=0.3777777850627899, loss=2.3641958236694336
train: epoch 131, loss 0.6508915424346924, acc=0.7198333144187927, loss=0.6508915424346924
test: epoch 131, loss 2.0552613735198975, acc=0.41111111640930176, loss=2.0552613735198975
train: epoch 132, loss 0.6498012542724609, acc=0.7201666831970215, loss=0.6498012542724609
test: epoch 132, loss 2.128901958465576, acc=0.3888888955116272, loss=2.128901958465576
train: epoch 133, loss 0.6610328555107117, acc=0.7200000286102295, loss=0.6610328555107117
test: epoch 133, loss 2.675501585006714, acc=0.39444443583488464, loss=2.675501585006714
train: epoch 134, loss 0.6399275660514832, acc=0.725777804851532, loss=0.6399275660514832
test: epoch 134, loss 2.199465036392212, acc=0.3888888955116272, loss=2.199465036392212
train: epoch 135, loss 0.6535724997520447, acc=0.7232221961021423, loss=0.6535724997520447
test: epoch 135, loss 2.2060768604278564, acc=0.3861111104488373, loss=2.2060768604278564
train: epoch 136, loss 0.6498278975486755, acc=0.7214999794960022, loss=0.6498278975486755
test: epoch 136, loss 2.1192777156829834, acc=0.3916666805744171, loss=2.1192777156829834
train: epoch 137, loss 0.6467317342758179, acc=0.7191110849380493, loss=0.6467317342758179
test: epoch 137, loss 2.1741297245025635, acc=0.40833333134651184, loss=2.1741297245025635
train: epoch 138, loss 0.6539278626441956, acc=0.7183333039283752, loss=0.6539278626441956
test: epoch 138, loss 2.0656118392944336, acc=0.39722222089767456, loss=2.0656118392944336
train: epoch 139, loss 0.6494967937469482, acc=0.7221111059188843, loss=0.6494967937469482
test: epoch 139, loss 1.9666212797164917, acc=0.4138889014720917, loss=1.9666212797164917
train: epoch 140, loss 0.6496211290359497, acc=0.7192777991294861, loss=0.6496211290359497
test: epoch 140, loss 2.2116072177886963, acc=0.39444443583488464, loss=2.2116072177886963
train: epoch 141, loss 0.6435133218765259, acc=0.7240555286407471, loss=0.6435133218765259
test: epoch 141, loss 2.125854253768921, acc=0.39444443583488464, loss=2.125854253768921
train: epoch 142, loss 0.6483792066574097, acc=0.7249444723129272, loss=0.6483792066574097
test: epoch 142, loss 2.2235701084136963, acc=0.38333332538604736, loss=2.2235701084136963
train: epoch 143, loss 0.6454969644546509, acc=0.7228888869285583, loss=0.6454969644546509
test: epoch 143, loss 2.2371108531951904, acc=0.4027777910232544, loss=2.2371108531951904
train: epoch 144, loss 0.6387887001037598, acc=0.7260555624961853, loss=0.6387887001037598
test: epoch 144, loss 2.334374189376831, acc=0.3861111104488373, loss=2.334374189376831
train: epoch 145, loss 0.6436412334442139, acc=0.7239999771118164, loss=0.6436412334442139
test: epoch 145, loss 2.0696356296539307, acc=0.4055555462837219, loss=2.0696356296539307
train: epoch 146, loss 0.6476984024047852, acc=0.7198333144187927, loss=0.6476984024047852
test: epoch 146, loss 2.371035575866699, acc=0.4000000059604645, loss=2.371035575866699
train: epoch 147, loss 0.6492643356323242, acc=0.7235555648803711, loss=0.6492643356323242
test: epoch 147, loss 2.197352647781372, acc=0.3888888955116272, loss=2.197352647781372
train: epoch 148, loss 0.6321671605110168, acc=0.726722240447998, loss=0.6321671605110168
test: epoch 148, loss 2.1544127464294434, acc=0.4000000059604645, loss=2.1544127464294434
train: epoch 149, loss 0.6366370916366577, acc=0.7273333072662354, loss=0.6366370916366577
test: epoch 149, loss 2.6426100730895996, acc=0.4027777910232544, loss=2.6426100730895996
train: epoch 150, loss 0.6357582211494446, acc=0.7256110906600952, loss=0.6357582211494446
test: epoch 150, loss 2.396523952484131, acc=0.4138889014720917, loss=2.396523952484131
