# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=true", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=2050982184, receiver_embed_dim=32, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.9718971252441406, acc=0.07577777653932571, loss=2.9718971252441406
test: epoch 1, loss 4.424844741821289, acc=0.0694444477558136, loss=4.424844741821289
train: epoch 2, loss 2.056335926055908, acc=0.20366667211055756, loss=2.056335926055908
test: epoch 2, loss 3.1094653606414795, acc=0.1527777761220932, loss=3.1094653606414795
train: epoch 3, loss 1.6880468130111694, acc=0.28033334016799927, loss=1.6880468130111694
test: epoch 3, loss 2.549575090408325, acc=0.20000000298023224, loss=2.549575090408325
train: epoch 4, loss 1.4507962465286255, acc=0.3443889021873474, loss=1.4507962465286255
test: epoch 4, loss 2.6706600189208984, acc=0.1944444477558136, loss=2.6706600189208984
train: epoch 5, loss 1.3220824003219604, acc=0.39044445753097534, loss=1.3220824003219604
test: epoch 5, loss 3.1134183406829834, acc=0.18611110746860504, loss=3.1134183406829834
train: epoch 6, loss 1.2101737260818481, acc=0.4360555410385132, loss=1.2101737260818481
test: epoch 6, loss 2.6327247619628906, acc=0.25833332538604736, loss=2.6327247619628906
train: epoch 7, loss 1.1313087940216064, acc=0.48311111330986023, loss=1.1313087940216064
test: epoch 7, loss 2.788536787033081, acc=0.22499999403953552, loss=2.788536787033081
train: epoch 8, loss 1.066780924797058, acc=0.5317777991294861, loss=1.066780924797058
test: epoch 8, loss 2.6523892879486084, acc=0.25555557012557983, loss=2.6523892879486084
train: epoch 9, loss 0.9976292848587036, acc=0.5603888630867004, loss=0.9976292848587036
test: epoch 9, loss 3.0033349990844727, acc=0.25, loss=3.0033349990844727
train: epoch 10, loss 0.9975754022598267, acc=0.5563889145851135, loss=0.9975754022598267
test: epoch 10, loss 3.2980165481567383, acc=0.21944443881511688, loss=3.2980165481567383
train: epoch 11, loss 0.9081377983093262, acc=0.6017777919769287, loss=0.9081377983093262
test: epoch 11, loss 3.0639455318450928, acc=0.2666666805744171, loss=3.0639455318450928
train: epoch 12, loss 0.8737186193466187, acc=0.632111132144928, loss=0.8737186193466187
test: epoch 12, loss 3.099087953567505, acc=0.2888889014720917, loss=3.099087953567505
train: epoch 13, loss 0.8852589726448059, acc=0.6162777543067932, loss=0.8852589726448059
test: epoch 13, loss 3.5253806114196777, acc=0.24722221493721008, loss=3.5253806114196777
train: epoch 14, loss 0.8053839206695557, acc=0.6532222032546997, loss=0.8053839206695557
test: epoch 14, loss 3.3214380741119385, acc=0.21944443881511688, loss=3.3214380741119385
train: epoch 15, loss 0.7488246560096741, acc=0.6822777986526489, loss=0.7488246560096741
test: epoch 15, loss 3.2922756671905518, acc=0.25833332538604736, loss=3.2922756671905518
train: epoch 16, loss 0.6856162548065186, acc=0.7068333625793457, loss=0.6856162548065186
test: epoch 16, loss 3.104731321334839, acc=0.2750000059604645, loss=3.104731321334839
train: epoch 17, loss 0.6359031796455383, acc=0.7385555505752563, loss=0.6359031796455383
test: epoch 17, loss 3.190310478210449, acc=0.3055555522441864, loss=3.190310478210449
train: epoch 18, loss 0.5397316217422485, acc=0.781333327293396, loss=0.5397316217422485
test: epoch 18, loss 3.7791707515716553, acc=0.25833332538604736, loss=3.7791707515716553
train: epoch 19, loss 0.5110927224159241, acc=0.7888333201408386, loss=0.5110927224159241
test: epoch 19, loss 3.6033313274383545, acc=0.3055555522441864, loss=3.6033313274383545
train: epoch 20, loss 0.4409361779689789, acc=0.8203333616256714, loss=0.4409361779689789
test: epoch 20, loss 3.163546562194824, acc=0.3083333373069763, loss=3.163546562194824
train: epoch 21, loss 0.43133261799812317, acc=0.8282222151756287, loss=0.43133261799812317
test: epoch 21, loss 2.927006483078003, acc=0.3166666626930237, loss=2.927006483078003
train: epoch 22, loss 0.3834899961948395, acc=0.8432777523994446, loss=0.3834899961948395
test: epoch 22, loss 2.800185441970825, acc=0.39444443583488464, loss=2.800185441970825
train: epoch 23, loss 0.3497586250305176, acc=0.8532778024673462, loss=0.3497586250305176
test: epoch 23, loss 2.6259610652923584, acc=0.38055557012557983, loss=2.6259610652923584
train: epoch 24, loss 0.32621124386787415, acc=0.867222249507904, loss=0.32621124386787415
test: epoch 24, loss 2.073117256164551, acc=0.4861111044883728, loss=2.073117256164551
train: epoch 25, loss 0.3495895266532898, acc=0.8592222332954407, loss=0.3495895266532898
test: epoch 25, loss 1.9919826984405518, acc=0.46666666865348816, loss=1.9919826984405518
train: epoch 26, loss 0.3299201428890228, acc=0.8620555400848389, loss=0.3299201428890228
test: epoch 26, loss 1.8665339946746826, acc=0.4416666626930237, loss=1.8665339946746826
train: epoch 27, loss 0.28995534777641296, acc=0.8764444589614868, loss=0.28995534777641296
test: epoch 27, loss 2.1728897094726562, acc=0.4833333194255829, loss=2.1728897094726562
train: epoch 28, loss 0.312042772769928, acc=0.8692222237586975, loss=0.312042772769928
test: epoch 28, loss 1.7793205976486206, acc=0.5416666865348816, loss=1.7793205976486206
train: epoch 29, loss 0.27669185400009155, acc=0.8807777762413025, loss=0.27669185400009155
test: epoch 29, loss 2.0797605514526367, acc=0.4972222149372101, loss=2.0797605514526367
train: epoch 30, loss 0.2887997329235077, acc=0.8793888688087463, loss=0.2887997329235077
test: epoch 30, loss 1.845524787902832, acc=0.5305555462837219, loss=1.845524787902832
train: epoch 31, loss 0.2679383158683777, acc=0.8852777481079102, loss=0.2679383158683777
test: epoch 31, loss 1.5576423406600952, acc=0.5333333611488342, loss=1.5576423406600952
train: epoch 32, loss 0.2498711347579956, acc=0.8911666870117188, loss=0.2498711347579956
test: epoch 32, loss 1.9268734455108643, acc=0.4972222149372101, loss=1.9268734455108643
train: epoch 33, loss 0.2690279483795166, acc=0.8855555653572083, loss=0.2690279483795166
test: epoch 33, loss 1.7826104164123535, acc=0.5416666865348816, loss=1.7826104164123535
train: epoch 34, loss 0.25278258323669434, acc=0.8909444212913513, loss=0.25278258323669434
test: epoch 34, loss 1.4501522779464722, acc=0.5944444537162781, loss=1.4501522779464722
train: epoch 35, loss 0.26701414585113525, acc=0.8871666789054871, loss=0.26701414585113525
test: epoch 35, loss 1.8123104572296143, acc=0.5333333611488342, loss=1.8123104572296143
train: epoch 36, loss 0.23446369171142578, acc=0.8958333134651184, loss=0.23446369171142578
test: epoch 36, loss 1.4840110540390015, acc=0.5222222208976746, loss=1.4840110540390015
train: epoch 37, loss 0.23418284952640533, acc=0.8962222337722778, loss=0.23418284952640533
test: epoch 37, loss 1.7008649110794067, acc=0.5416666865348816, loss=1.7008649110794067
train: epoch 38, loss 0.23576323688030243, acc=0.8968333601951599, loss=0.23576323688030243
test: epoch 38, loss 1.2879445552825928, acc=0.5805555582046509, loss=1.2879445552825928
train: epoch 39, loss 0.22781668603420258, acc=0.899055540561676, loss=0.22781668603420258
test: epoch 39, loss 1.3761054277420044, acc=0.6277777552604675, loss=1.3761054277420044
train: epoch 40, loss 0.2222411036491394, acc=0.9041110873222351, loss=0.2222411036491394
test: epoch 40, loss 1.2290185689926147, acc=0.6138888597488403, loss=1.2290185689926147
train: epoch 41, loss 0.2186577320098877, acc=0.9003333449363708, loss=0.2186577320098877
test: epoch 41, loss 1.2711788415908813, acc=0.5527777671813965, loss=1.2711788415908813
train: epoch 42, loss 0.2193092405796051, acc=0.906333327293396, loss=0.2193092405796051
test: epoch 42, loss 1.4302797317504883, acc=0.574999988079071, loss=1.4302797317504883
train: epoch 43, loss 0.21903982758522034, acc=0.9024444222450256, loss=0.21903982758522034
test: epoch 43, loss 1.5396018028259277, acc=0.5666666626930237, loss=1.5396018028259277
train: epoch 44, loss 0.20271137356758118, acc=0.909333348274231, loss=0.20271137356758118
test: epoch 44, loss 1.4532020092010498, acc=0.5916666388511658, loss=1.4532020092010498
train: epoch 45, loss 0.2019638866186142, acc=0.9104999899864197, loss=0.2019638866186142
test: epoch 45, loss 1.5386946201324463, acc=0.6166666746139526, loss=1.5386946201324463
train: epoch 46, loss 0.21420890092849731, acc=0.9062777757644653, loss=0.21420890092849731
test: epoch 46, loss 1.6831098794937134, acc=0.5722222328186035, loss=1.6831098794937134
train: epoch 47, loss 0.20904961228370667, acc=0.9072777628898621, loss=0.20904961228370667
test: epoch 47, loss 0.9962434768676758, acc=0.6111111044883728, loss=0.9962434768676758
train: epoch 48, loss 0.1880684494972229, acc=0.9153888821601868, loss=0.1880684494972229
test: epoch 48, loss 1.0144636631011963, acc=0.6638888716697693, loss=1.0144636631011963
train: epoch 49, loss 0.215521439909935, acc=0.9066110849380493, loss=0.215521439909935
test: epoch 49, loss 1.1354327201843262, acc=0.6611111164093018, loss=1.1354327201843262
train: epoch 50, loss 0.1882690042257309, acc=0.9153333306312561, loss=0.1882690042257309
test: epoch 50, loss 0.853123128414154, acc=0.7666666507720947, loss=0.853123128414154
train: epoch 51, loss 0.19453787803649902, acc=0.9131110906600952, loss=0.19453787803649902
test: epoch 51, loss 0.8697802424430847, acc=0.7027778029441833, loss=0.8697802424430847
train: epoch 52, loss 0.18968570232391357, acc=0.9150000214576721, loss=0.18968570232391357
test: epoch 52, loss 0.8273025751113892, acc=0.7277777791023254, loss=0.8273025751113892
train: epoch 53, loss 0.18761618435382843, acc=0.9187222123146057, loss=0.18761618435382843
test: epoch 53, loss 0.8210448622703552, acc=0.6722221970558167, loss=0.8210448622703552
train: epoch 54, loss 0.19333641231060028, acc=0.913277804851532, loss=0.19333641231060028
test: epoch 54, loss 0.66118985414505, acc=0.7444444298744202, loss=0.66118985414505
train: epoch 55, loss 0.19041550159454346, acc=0.9153333306312561, loss=0.19041550159454346
test: epoch 55, loss 1.2351950407028198, acc=0.6694444417953491, loss=1.2351950407028198
train: epoch 56, loss 0.19364896416664124, acc=0.913611114025116, loss=0.19364896416664124
test: epoch 56, loss 0.81978440284729, acc=0.7527777552604675, loss=0.81978440284729
train: epoch 57, loss 0.17877966165542603, acc=0.9190000295639038, loss=0.17877966165542603
test: epoch 57, loss 0.8422425985336304, acc=0.6944444179534912, loss=0.8422425985336304
train: epoch 58, loss 0.19467563927173615, acc=0.9160555601119995, loss=0.19467563927173615
test: epoch 58, loss 0.88482666015625, acc=0.7527777552604675, loss=0.88482666015625
train: epoch 59, loss 0.1870202124118805, acc=0.9152777791023254, loss=0.1870202124118805
test: epoch 59, loss 0.8440881967544556, acc=0.7611111402511597, loss=0.8440881967544556
train: epoch 60, loss 0.1769687682390213, acc=0.9196666479110718, loss=0.1769687682390213
test: epoch 60, loss 0.6678184866905212, acc=0.7833333611488342, loss=0.6678184866905212
train: epoch 61, loss 0.1613040715456009, acc=0.929722249507904, loss=0.1613040715456009
test: epoch 61, loss 0.8869995474815369, acc=0.7638888955116272, loss=0.8869995474815369
train: epoch 62, loss 0.1618034392595291, acc=0.9380000233650208, loss=0.1618034392595291
test: epoch 62, loss 0.712981104850769, acc=0.7277777791023254, loss=0.712981104850769
train: epoch 63, loss 0.12782785296440125, acc=0.9545000195503235, loss=0.12782785296440125
test: epoch 63, loss 0.7991141676902771, acc=0.7583333253860474, loss=0.7991141676902771
train: epoch 64, loss 0.15168684720993042, acc=0.9514999985694885, loss=0.15168684720993042
test: epoch 64, loss 0.7713716626167297, acc=0.7250000238418579, loss=0.7713716626167297
train: epoch 65, loss 0.1305556744337082, acc=0.957444429397583, loss=0.1305556744337082
test: epoch 65, loss 0.7437734007835388, acc=0.7861111164093018, loss=0.7437734007835388
train: epoch 66, loss 0.1166963055729866, acc=0.9616666436195374, loss=0.1166963055729866
test: epoch 66, loss 0.6573340892791748, acc=0.8138889074325562, loss=0.6573340892791748
train: epoch 67, loss 0.12953931093215942, acc=0.957611083984375, loss=0.12953931093215942
test: epoch 67, loss 0.7833177447319031, acc=0.8055555820465088, loss=0.7833177447319031
train: epoch 68, loss 0.13400320708751678, acc=0.953000009059906, loss=0.13400320708751678
test: epoch 68, loss 0.7605815529823303, acc=0.7861111164093018, loss=0.7605815529823303
train: epoch 69, loss 0.1387123167514801, acc=0.9557222127914429, loss=0.1387123167514801
test: epoch 69, loss 0.6175768971443176, acc=0.8083333373069763, loss=0.6175768971443176
train: epoch 70, loss 0.10937453806400299, acc=0.965499997138977, loss=0.10937453806400299
test: epoch 70, loss 0.8434594869613647, acc=0.7444444298744202, loss=0.8434594869613647
train: epoch 71, loss 0.11085312068462372, acc=0.9643333554267883, loss=0.11085312068462372
test: epoch 71, loss 0.6956208348274231, acc=0.800000011920929, loss=0.6956208348274231
train: epoch 72, loss 0.1276366412639618, acc=0.9581111073493958, loss=0.1276366412639618
test: epoch 72, loss 0.8302158117294312, acc=0.769444465637207, loss=0.8302158117294312
train: epoch 73, loss 0.09988457709550858, acc=0.9674444198608398, loss=0.09988457709550858
test: epoch 73, loss 0.7361409664154053, acc=0.7972221970558167, loss=0.7361409664154053
train: epoch 74, loss 0.1228136345744133, acc=0.9610555768013, loss=0.1228136345744133
test: epoch 74, loss 0.8776286840438843, acc=0.7444444298744202, loss=0.8776286840438843
train: epoch 75, loss 0.1241324320435524, acc=0.9614999890327454, loss=0.1241324320435524
test: epoch 75, loss 0.7719882726669312, acc=0.7722222208976746, loss=0.7719882726669312
train: epoch 76, loss 0.1085306778550148, acc=0.9648333191871643, loss=0.1085306778550148
test: epoch 76, loss 0.6720867156982422, acc=0.7916666865348816, loss=0.6720867156982422
train: epoch 77, loss 0.1051701009273529, acc=0.9659444689750671, loss=0.1051701009273529
test: epoch 77, loss 0.7895436882972717, acc=0.769444465637207, loss=0.7895436882972717
train: epoch 78, loss 0.10452868044376373, acc=0.9667778015136719, loss=0.10452868044376373
test: epoch 78, loss 0.7060430645942688, acc=0.8083333373069763, loss=0.7060430645942688
train: epoch 79, loss 0.13200914859771729, acc=0.9562777876853943, loss=0.13200914859771729
test: epoch 79, loss 0.7130922079086304, acc=0.7777777910232544, loss=0.7130922079086304
train: epoch 80, loss 0.10645512491464615, acc=0.964722216129303, loss=0.10645512491464615
test: epoch 80, loss 0.753351092338562, acc=0.769444465637207, loss=0.753351092338562
train: epoch 81, loss 0.10485200583934784, acc=0.9681666493415833, loss=0.10485200583934784
test: epoch 81, loss 0.6014119386672974, acc=0.800000011920929, loss=0.6014119386672974
train: epoch 82, loss 0.0915294662117958, acc=0.9701111316680908, loss=0.0915294662117958
test: epoch 82, loss 0.8004329204559326, acc=0.7944444417953491, loss=0.8004329204559326
train: epoch 83, loss 0.1121211126446724, acc=0.9641110897064209, loss=0.1121211126446724
test: epoch 83, loss 0.689903199672699, acc=0.8083333373069763, loss=0.689903199672699
train: epoch 84, loss 0.12271518260240555, acc=0.9607222080230713, loss=0.12271518260240555
test: epoch 84, loss 0.604189395904541, acc=0.8222222328186035, loss=0.604189395904541
train: epoch 85, loss 0.10066205263137817, acc=0.9687777757644653, loss=0.10066205263137817
test: epoch 85, loss 1.1812394857406616, acc=0.7527777552604675, loss=1.1812394857406616
train: epoch 86, loss 0.12201273441314697, acc=0.9608333110809326, loss=0.12201273441314697
test: epoch 86, loss 0.7646969556808472, acc=0.8222222328186035, loss=0.7646969556808472
train: epoch 87, loss 0.10755801200866699, acc=0.9668333530426025, loss=0.10755801200866699
test: epoch 87, loss 0.8159797191619873, acc=0.8055555820465088, loss=0.8159797191619873
train: epoch 88, loss 0.12362474948167801, acc=0.9595555663108826, loss=0.12362474948167801
test: epoch 88, loss 0.5657716393470764, acc=0.800000011920929, loss=0.5657716393470764
train: epoch 89, loss 0.10689011961221695, acc=0.9649444222450256, loss=0.10689011961221695
test: epoch 89, loss 0.6246905326843262, acc=0.8138889074325562, loss=0.6246905326843262
train: epoch 90, loss 0.08496085554361343, acc=0.9725000262260437, loss=0.08496085554361343
test: epoch 90, loss 0.5872878432273865, acc=0.8166666626930237, loss=0.5872878432273865
train: epoch 91, loss 0.10171420127153397, acc=0.9681666493415833, loss=0.10171420127153397
test: epoch 91, loss 0.5851098895072937, acc=0.8222222328186035, loss=0.5851098895072937
train: epoch 92, loss 0.09997379034757614, acc=0.9687777757644653, loss=0.09997379034757614
test: epoch 92, loss 0.5734714865684509, acc=0.8277778029441833, loss=0.5734714865684509
train: epoch 93, loss 0.10876783728599548, acc=0.965666651725769, loss=0.10876783728599548
test: epoch 93, loss 0.5503754019737244, acc=0.824999988079071, loss=0.5503754019737244
train: epoch 94, loss 0.0800665095448494, acc=0.9746666550636292, loss=0.0800665095448494
test: epoch 94, loss 0.7845332026481628, acc=0.7805555462837219, loss=0.7845332026481628
train: epoch 95, loss 0.10953276604413986, acc=0.9674999713897705, loss=0.10953276604413986
test: epoch 95, loss 0.47061192989349365, acc=0.8472222089767456, loss=0.47061192989349365
train: epoch 96, loss 0.10312335193157196, acc=0.9668333530426025, loss=0.10312335193157196
test: epoch 96, loss 0.5873468518257141, acc=0.8361111283302307, loss=0.5873468518257141
train: epoch 97, loss 0.10397841036319733, acc=0.9683889150619507, loss=0.10397841036319733
test: epoch 97, loss 0.6459490656852722, acc=0.824999988079071, loss=0.6459490656852722
train: epoch 98, loss 0.09927743673324585, acc=0.9702222347259521, loss=0.09927743673324585
test: epoch 98, loss 0.6725756525993347, acc=0.8361111283302307, loss=0.6725756525993347
train: epoch 99, loss 0.09079953283071518, acc=0.9722777605056763, loss=0.09079953283071518
test: epoch 99, loss 0.7340517640113831, acc=0.7972221970558167, loss=0.7340517640113831
train: epoch 100, loss 0.0869300588965416, acc=0.9730555415153503, loss=0.0869300588965416
test: epoch 100, loss 0.6884535551071167, acc=0.8138889074325562, loss=0.6884535551071167
train: epoch 101, loss 0.07871939986944199, acc=0.9743333458900452, loss=0.07871939986944199
test: epoch 101, loss 0.6106213331222534, acc=0.8500000238418579, loss=0.6106213331222534
train: epoch 102, loss 0.10828076303005219, acc=0.9659444689750671, loss=0.10828076303005219
test: epoch 102, loss 0.6745537519454956, acc=0.8305555582046509, loss=0.6745537519454956
train: epoch 103, loss 0.09272554516792297, acc=0.9697222113609314, loss=0.09272554516792297
test: epoch 103, loss 0.6317141056060791, acc=0.8333333134651184, loss=0.6317141056060791
train: epoch 104, loss 0.09839995950460434, acc=0.9689444303512573, loss=0.09839995950460434
test: epoch 104, loss 0.584581196308136, acc=0.8361111283302307, loss=0.584581196308136
train: epoch 105, loss 0.1483406126499176, acc=0.9562777876853943, loss=0.1483406126499176
test: epoch 105, loss 0.49189040064811707, acc=0.8388888835906982, loss=0.49189040064811707
train: epoch 106, loss 0.07994750142097473, acc=0.9741666913032532, loss=0.07994750142097473
test: epoch 106, loss 0.5198420882225037, acc=0.8388888835906982, loss=0.5198420882225037
train: epoch 107, loss 0.10695772618055344, acc=0.9683333039283752, loss=0.10695772618055344
test: epoch 107, loss 0.628542959690094, acc=0.8500000238418579, loss=0.628542959690094
train: epoch 108, loss 0.08953823149204254, acc=0.9720555543899536, loss=0.08953823149204254
test: epoch 108, loss 0.5603044629096985, acc=0.8527777791023254, loss=0.5603044629096985
train: epoch 109, loss 0.10397858917713165, acc=0.9693333506584167, loss=0.10397858917713165
test: epoch 109, loss 0.6232544779777527, acc=0.8416666388511658, loss=0.6232544779777527
train: epoch 110, loss 0.0939050167798996, acc=0.9704444408416748, loss=0.0939050167798996
test: epoch 110, loss 0.5581815838813782, acc=0.855555534362793, loss=0.5581815838813782
train: epoch 111, loss 0.10583211481571198, acc=0.9667778015136719, loss=0.10583211481571198
test: epoch 111, loss 0.5650103688240051, acc=0.8500000238418579, loss=0.5650103688240051
train: epoch 112, loss 0.08213712275028229, acc=0.9753333330154419, loss=0.08213712275028229
test: epoch 112, loss 0.6032145619392395, acc=0.8500000238418579, loss=0.6032145619392395
train: epoch 113, loss 0.07815909385681152, acc=0.9753888845443726, loss=0.07815909385681152
test: epoch 113, loss 0.5457648038864136, acc=0.8305555582046509, loss=0.5457648038864136
train: epoch 114, loss 0.13161303102970123, acc=0.9659444689750671, loss=0.13161303102970123
test: epoch 114, loss 0.5943397283554077, acc=0.8500000238418579, loss=0.5943397283554077
train: epoch 115, loss 0.10013195127248764, acc=0.9691110849380493, loss=0.10013195127248764
test: epoch 115, loss 0.5092620253562927, acc=0.8527777791023254, loss=0.5092620253562927
train: epoch 116, loss 0.0837055891752243, acc=0.9743333458900452, loss=0.0837055891752243
test: epoch 116, loss 0.6438720226287842, acc=0.8444444537162781, loss=0.6438720226287842
train: epoch 117, loss 0.08514010161161423, acc=0.9729999899864197, loss=0.08514010161161423
test: epoch 117, loss 0.6370262503623962, acc=0.8444444537162781, loss=0.6370262503623962
train: epoch 118, loss 0.09568401426076889, acc=0.9720555543899536, loss=0.09568401426076889
test: epoch 118, loss 0.676795244216919, acc=0.8527777791023254, loss=0.676795244216919
train: epoch 119, loss 0.10038840770721436, acc=0.9725000262260437, loss=0.10038840770721436
test: epoch 119, loss 0.5388320684432983, acc=0.8527777791023254, loss=0.5388320684432983
train: epoch 120, loss 0.09248482435941696, acc=0.9723333120346069, loss=0.09248482435941696
test: epoch 120, loss 0.609525203704834, acc=0.8527777791023254, loss=0.609525203704834
train: epoch 121, loss 0.09525031596422195, acc=0.9711111187934875, loss=0.09525031596422195
test: epoch 121, loss 0.509783148765564, acc=0.8416666388511658, loss=0.509783148765564
train: epoch 122, loss 0.08818657696247101, acc=0.9736666679382324, loss=0.08818657696247101
test: epoch 122, loss 0.5606025457382202, acc=0.855555534362793, loss=0.5606025457382202
train: epoch 123, loss 0.08217819780111313, acc=0.9749444723129272, loss=0.08217819780111313
test: epoch 123, loss 0.5332930684089661, acc=0.8583333492279053, loss=0.5332930684089661
train: epoch 124, loss 0.09020145982503891, acc=0.9739444255828857, loss=0.09020145982503891
test: epoch 124, loss 0.5173303484916687, acc=0.855555534362793, loss=0.5173303484916687
train: epoch 125, loss 0.09508330374956131, acc=0.9725000262260437, loss=0.09508330374956131
test: epoch 125, loss 0.507745623588562, acc=0.8611111044883728, loss=0.507745623588562
train: epoch 126, loss 0.08910439908504486, acc=0.9749444723129272, loss=0.08910439908504486
test: epoch 126, loss 0.6173834800720215, acc=0.8388888835906982, loss=0.6173834800720215
train: epoch 127, loss 0.09237420558929443, acc=0.9744444489479065, loss=0.09237420558929443
test: epoch 127, loss 0.6052035689353943, acc=0.855555534362793, loss=0.6052035689353943
train: epoch 128, loss 0.08935771137475967, acc=0.972611129283905, loss=0.08935771137475967
test: epoch 128, loss 0.5329740643501282, acc=0.8444444537162781, loss=0.5329740643501282
train: epoch 129, loss 0.12171024084091187, acc=0.9658889174461365, loss=0.12171024084091187
test: epoch 129, loss 0.49581828713417053, acc=0.8472222089767456, loss=0.49581828713417053
train: epoch 130, loss 0.11564212292432785, acc=0.9659444689750671, loss=0.11564212292432785
test: epoch 130, loss 0.6086779236793518, acc=0.8527777791023254, loss=0.6086779236793518
train: epoch 131, loss 0.08752945810556412, acc=0.9735555648803711, loss=0.08752945810556412
test: epoch 131, loss 0.5185257196426392, acc=0.855555534362793, loss=0.5185257196426392
train: epoch 132, loss 0.08774516731500626, acc=0.9732778072357178, loss=0.08774516731500626
test: epoch 132, loss 0.5048741698265076, acc=0.8527777791023254, loss=0.5048741698265076
train: epoch 133, loss 0.07840333878993988, acc=0.9767777919769287, loss=0.07840333878993988
test: epoch 133, loss 0.44957610964775085, acc=0.8888888955116272, loss=0.44957610964775085
train: epoch 134, loss 0.08809463679790497, acc=0.9740555286407471, loss=0.08809463679790497
test: epoch 134, loss 0.6005511283874512, acc=0.8527777791023254, loss=0.6005511283874512
train: epoch 135, loss 0.08307400345802307, acc=0.9753888845443726, loss=0.08307400345802307
test: epoch 135, loss 0.40983983874320984, acc=0.9027777910232544, loss=0.40983983874320984
train: epoch 136, loss 0.0722605437040329, acc=0.9796110987663269, loss=0.0722605437040329
test: epoch 136, loss 0.382602334022522, acc=0.9138888716697693, loss=0.382602334022522
train: epoch 137, loss 0.07973141968250275, acc=0.9783889055252075, loss=0.07973141968250275
test: epoch 137, loss 0.330433189868927, acc=0.9083333611488342, loss=0.330433189868927
train: epoch 138, loss 0.06503656506538391, acc=0.981333315372467, loss=0.06503656506538391
test: epoch 138, loss 0.18058408796787262, acc=0.925000011920929, loss=0.18058408796787262
train: epoch 139, loss 0.07926995307207108, acc=0.9763888716697693, loss=0.07926995307207108
test: epoch 139, loss 0.3743714392185211, acc=0.9027777910232544, loss=0.3743714392185211
train: epoch 140, loss 0.05398428812623024, acc=0.9835555553436279, loss=0.05398428812623024
test: epoch 140, loss 0.20094753801822662, acc=0.9194444417953491, loss=0.20094753801822662
train: epoch 141, loss 0.0636255294084549, acc=0.9821110963821411, loss=0.0636255294084549
test: epoch 141, loss 0.31543752551078796, acc=0.9222221970558167, loss=0.31543752551078796
train: epoch 142, loss 0.07414628565311432, acc=0.9795555472373962, loss=0.07414628565311432
test: epoch 142, loss 0.2480960488319397, acc=0.9111111164093018, loss=0.2480960488319397
train: epoch 143, loss 0.08800385892391205, acc=0.9754999876022339, loss=0.08800385892391205
test: epoch 143, loss 0.2780773341655731, acc=0.9111111164093018, loss=0.2780773341655731
train: epoch 144, loss 0.05493521690368652, acc=0.9846110939979553, loss=0.05493521690368652
test: epoch 144, loss 0.2181551605463028, acc=0.9138888716697693, loss=0.2181551605463028
train: epoch 145, loss 0.04544861614704132, acc=0.98416668176651, loss=0.04544861614704132
test: epoch 145, loss 0.18766041100025177, acc=0.9222221970558167, loss=0.18766041100025177
train: epoch 146, loss 0.09296954423189163, acc=0.975944459438324, loss=0.09296954423189163
test: epoch 146, loss 0.2986578643321991, acc=0.9111111164093018, loss=0.2986578643321991
train: epoch 147, loss 0.06885349750518799, acc=0.9797777533531189, loss=0.06885349750518799
test: epoch 147, loss 0.34482279419898987, acc=0.9111111164093018, loss=0.34482279419898987
train: epoch 148, loss 0.074940986931324, acc=0.9796666502952576, loss=0.074940986931324
test: epoch 148, loss 0.3012145161628723, acc=0.9222221970558167, loss=0.3012145161628723
train: epoch 149, loss 0.07075952738523483, acc=0.9802777767181396, loss=0.07075952738523483
test: epoch 149, loss 0.3702319860458374, acc=0.9222221970558167, loss=0.3702319860458374
train: epoch 150, loss 0.055264897644519806, acc=0.9836111068725586, loss=0.055264897644519806
test: epoch 150, loss 0.8030017614364624, acc=0.8444444537162781, loss=0.8030017614364624
