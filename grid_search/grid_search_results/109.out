# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=1", "--temp_decay=1", "--one_hot=true", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=606593626, receiver_embed_dim=128, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.9831695556640625, acc=0.08477777987718582, loss=2.9831695556640625
test: epoch 1, loss 2.585242509841919, acc=0.1111111119389534, loss=2.585242509841919
train: epoch 2, loss 1.8266328573226929, acc=0.2833888828754425, loss=1.8266328573226929
test: epoch 2, loss 1.9690325260162354, acc=0.24166665971279144, loss=1.9690325260162354
train: epoch 3, loss 1.3694820404052734, acc=0.4226111173629761, loss=1.3694820404052734
test: epoch 3, loss 1.6461507081985474, acc=0.3333333432674408, loss=1.6461507081985474
train: epoch 4, loss 1.1767704486846924, acc=0.49183332920074463, loss=1.1767704486846924
test: epoch 4, loss 1.5379540920257568, acc=0.34166666865348816, loss=1.5379540920257568
train: epoch 5, loss 1.0490515232086182, acc=0.539222240447998, loss=1.0490515232086182
test: epoch 5, loss 1.4734009504318237, acc=0.36666667461395264, loss=1.4734009504318237
train: epoch 6, loss 0.9498637318611145, acc=0.5774999856948853, loss=0.9498637318611145
test: epoch 6, loss 1.7806249856948853, acc=0.3472222089767456, loss=1.7806249856948853
train: epoch 7, loss 0.8836495876312256, acc=0.6092777848243713, loss=0.8836495876312256
test: epoch 7, loss 1.4823276996612549, acc=0.3777777850627899, loss=1.4823276996612549
train: epoch 8, loss 0.8136190176010132, acc=0.6453889012336731, loss=0.8136190176010132
test: epoch 8, loss 1.6385709047317505, acc=0.39444443583488464, loss=1.6385709047317505
train: epoch 9, loss 0.7708137035369873, acc=0.6633889079093933, loss=0.7708137035369873
test: epoch 9, loss 1.5824693441390991, acc=0.4277777671813965, loss=1.5824693441390991
train: epoch 10, loss 0.7245172262191772, acc=0.6869444251060486, loss=0.7245172262191772
test: epoch 10, loss 1.45611572265625, acc=0.4194444417953491, loss=1.45611572265625
train: epoch 11, loss 0.6930588483810425, acc=0.6974444389343262, loss=0.6930588483810425
test: epoch 11, loss 1.585932970046997, acc=0.42500001192092896, loss=1.585932970046997
train: epoch 12, loss 0.6846559047698975, acc=0.7036666870117188, loss=0.6846559047698975
test: epoch 12, loss 1.7147644758224487, acc=0.4027777910232544, loss=1.7147644758224487
train: epoch 13, loss 0.678341805934906, acc=0.7005555629730225, loss=0.678341805934906
test: epoch 13, loss 1.6589897871017456, acc=0.42222222685813904, loss=1.6589897871017456
train: epoch 14, loss 0.6568900346755981, acc=0.711388885974884, loss=0.6568900346755981
test: epoch 14, loss 1.5395318269729614, acc=0.4194444417953491, loss=1.5395318269729614
train: epoch 15, loss 0.6344788670539856, acc=0.7211666703224182, loss=0.6344788670539856
test: epoch 15, loss 1.5160601139068604, acc=0.42500001192092896, loss=1.5160601139068604
train: epoch 16, loss 0.6169577836990356, acc=0.7284444570541382, loss=0.6169577836990356
test: epoch 16, loss 1.5573832988739014, acc=0.44999998807907104, loss=1.5573832988739014
train: epoch 17, loss 0.6240167617797852, acc=0.7233889102935791, loss=0.6240167617797852
test: epoch 17, loss 1.4770514965057373, acc=0.43611112236976624, loss=1.4770514965057373
train: epoch 18, loss 0.5979954600334167, acc=0.7336111068725586, loss=0.5979954600334167
test: epoch 18, loss 1.7601184844970703, acc=0.4416666626930237, loss=1.7601184844970703
train: epoch 19, loss 0.5954906940460205, acc=0.7376111149787903, loss=0.5954906940460205
test: epoch 19, loss 1.5529773235321045, acc=0.45277777314186096, loss=1.5529773235321045
train: epoch 20, loss 0.5872933268547058, acc=0.7378888726234436, loss=0.5872933268547058
test: epoch 20, loss 1.608108401298523, acc=0.43888887763023376, loss=1.608108401298523
train: epoch 21, loss 0.5910825133323669, acc=0.7360000014305115, loss=0.5910825133323669
test: epoch 21, loss 1.5278276205062866, acc=0.45277777314186096, loss=1.5278276205062866
train: epoch 22, loss 0.5950661897659302, acc=0.7376111149787903, loss=0.5950661897659302
test: epoch 22, loss 1.479928970336914, acc=0.46388888359069824, loss=1.479928970336914
train: epoch 23, loss 0.5842039585113525, acc=0.7403333187103271, loss=0.5842039585113525
test: epoch 23, loss 1.5717936754226685, acc=0.44999998807907104, loss=1.5717936754226685
train: epoch 24, loss 0.5708407759666443, acc=0.7471110820770264, loss=0.5708407759666443
test: epoch 24, loss 1.557837963104248, acc=0.4583333432674408, loss=1.557837963104248
train: epoch 25, loss 0.5553587079048157, acc=0.749666690826416, loss=0.5553587079048157
test: epoch 25, loss 1.4516782760620117, acc=0.46388888359069824, loss=1.4516782760620117
train: epoch 26, loss 0.5511420369148254, acc=0.7453888654708862, loss=0.5511420369148254
test: epoch 26, loss 1.593302845954895, acc=0.4555555582046509, loss=1.593302845954895
train: epoch 27, loss 0.5771411657333374, acc=0.7434444427490234, loss=0.5771411657333374
test: epoch 27, loss 1.569305658340454, acc=0.4583333432674408, loss=1.569305658340454
train: epoch 28, loss 0.5562822818756104, acc=0.7523333430290222, loss=0.5562822818756104
test: epoch 28, loss 1.7601726055145264, acc=0.4277777671813965, loss=1.7601726055145264
train: epoch 29, loss 0.5683974623680115, acc=0.7478888630867004, loss=0.5683974623680115
test: epoch 29, loss 1.6394107341766357, acc=0.4472222328186035, loss=1.6394107341766357
train: epoch 30, loss 0.5357564687728882, acc=0.7543333172798157, loss=0.5357564687728882
test: epoch 30, loss 1.7657274007797241, acc=0.4555555582046509, loss=1.7657274007797241
train: epoch 31, loss 0.5438967347145081, acc=0.7554444670677185, loss=0.5438967347145081
test: epoch 31, loss 1.5770925283432007, acc=0.45277777314186096, loss=1.5770925283432007
train: epoch 32, loss 0.5433530211448669, acc=0.7536110877990723, loss=0.5433530211448669
test: epoch 32, loss 1.7071452140808105, acc=0.4472222328186035, loss=1.7071452140808105
train: epoch 33, loss 0.5450864434242249, acc=0.7568333148956299, loss=0.5450864434242249
test: epoch 33, loss 1.7039011716842651, acc=0.4444444477558136, loss=1.7039011716842651
train: epoch 34, loss 0.545856237411499, acc=0.7513333559036255, loss=0.545856237411499
test: epoch 34, loss 1.6755852699279785, acc=0.4611110985279083, loss=1.6755852699279785
train: epoch 35, loss 0.5323483347892761, acc=0.757888913154602, loss=0.5323483347892761
test: epoch 35, loss 1.4918618202209473, acc=0.4583333432674408, loss=1.4918618202209473
train: epoch 36, loss 0.5362152457237244, acc=0.7581111192703247, loss=0.5362152457237244
test: epoch 36, loss 1.6185648441314697, acc=0.43611112236976624, loss=1.6185648441314697
train: epoch 37, loss 0.526259183883667, acc=0.7624444365501404, loss=0.526259183883667
test: epoch 37, loss 1.6115566492080688, acc=0.4611110985279083, loss=1.6115566492080688
train: epoch 38, loss 0.5334523320198059, acc=0.7562222480773926, loss=0.5334523320198059
test: epoch 38, loss 1.4959218502044678, acc=0.4333333373069763, loss=1.4959218502044678
train: epoch 39, loss 0.5222258567810059, acc=0.7626110911369324, loss=0.5222258567810059
test: epoch 39, loss 1.532273530960083, acc=0.4722222089767456, loss=1.532273530960083
train: epoch 40, loss 0.5125957727432251, acc=0.7683888673782349, loss=0.5125957727432251
test: epoch 40, loss 1.573837161064148, acc=0.4611110985279083, loss=1.573837161064148
train: epoch 41, loss 0.5111219882965088, acc=0.7649444341659546, loss=0.5111219882965088
test: epoch 41, loss 1.7036669254302979, acc=0.43888887763023376, loss=1.7036669254302979
train: epoch 42, loss 0.49923884868621826, acc=0.7723333239555359, loss=0.49923884868621826
test: epoch 42, loss 1.561592936515808, acc=0.4833333194255829, loss=1.561592936515808
train: epoch 43, loss 0.5047658681869507, acc=0.7715555429458618, loss=0.5047658681869507
test: epoch 43, loss 1.5289192199707031, acc=0.46388888359069824, loss=1.5289192199707031
train: epoch 44, loss 0.5043096542358398, acc=0.7720000147819519, loss=0.5043096542358398
test: epoch 44, loss 1.705047369003296, acc=0.4472222328186035, loss=1.705047369003296
train: epoch 45, loss 0.5033735632896423, acc=0.7722777724266052, loss=0.5033735632896423
test: epoch 45, loss 1.5446243286132812, acc=0.4749999940395355, loss=1.5446243286132812
train: epoch 46, loss 0.5016090869903564, acc=0.769944429397583, loss=0.5016090869903564
test: epoch 46, loss 1.569463849067688, acc=0.4555555582046509, loss=1.569463849067688
train: epoch 47, loss 0.5082935094833374, acc=0.7682777643203735, loss=0.5082935094833374
test: epoch 47, loss 1.575048565864563, acc=0.47777777910232544, loss=1.575048565864563
train: epoch 48, loss 0.5060318112373352, acc=0.7675555348396301, loss=0.5060318112373352
test: epoch 48, loss 1.680757999420166, acc=0.4694444537162781, loss=1.680757999420166
train: epoch 49, loss 0.49867507815361023, acc=0.7746111154556274, loss=0.49867507815361023
test: epoch 49, loss 1.5564056634902954, acc=0.46388888359069824, loss=1.5564056634902954
train: epoch 50, loss 0.49938565492630005, acc=0.7693889141082764, loss=0.49938565492630005
test: epoch 50, loss 1.6987125873565674, acc=0.4694444537162781, loss=1.6987125873565674
train: epoch 51, loss 0.49944353103637695, acc=0.7751666903495789, loss=0.49944353103637695
test: epoch 51, loss 1.461980938911438, acc=0.47777777910232544, loss=1.461980938911438
train: epoch 52, loss 0.4890759587287903, acc=0.7762777805328369, loss=0.4890759587287903
test: epoch 52, loss 1.6837894916534424, acc=0.4749999940395355, loss=1.6837894916534424
train: epoch 53, loss 0.4843829870223999, acc=0.7770000100135803, loss=0.4843829870223999
test: epoch 53, loss 1.79423189163208, acc=0.4694444537162781, loss=1.79423189163208
train: epoch 54, loss 0.476958304643631, acc=0.7804444432258606, loss=0.476958304643631
test: epoch 54, loss 1.6237823963165283, acc=0.44999998807907104, loss=1.6237823963165283
train: epoch 55, loss 0.4838145673274994, acc=0.7726666927337646, loss=0.4838145673274994
test: epoch 55, loss 1.7236909866333008, acc=0.47777777910232544, loss=1.7236909866333008
train: epoch 56, loss 0.48825329542160034, acc=0.7784444689750671, loss=0.48825329542160034
test: epoch 56, loss 1.5701643228530884, acc=0.47777777910232544, loss=1.5701643228530884
train: epoch 57, loss 0.48659223318099976, acc=0.7792778015136719, loss=0.48659223318099976
test: epoch 57, loss 1.694667935371399, acc=0.46388888359069824, loss=1.694667935371399
train: epoch 58, loss 0.4725242555141449, acc=0.7850555777549744, loss=0.4725242555141449
test: epoch 58, loss 1.5662554502487183, acc=0.47777777910232544, loss=1.5662554502487183
train: epoch 59, loss 0.47235310077667236, acc=0.7820000052452087, loss=0.47235310077667236
test: epoch 59, loss 1.6918666362762451, acc=0.4833333194255829, loss=1.6918666362762451
train: epoch 60, loss 0.4637478291988373, acc=0.7860555648803711, loss=0.4637478291988373
test: epoch 60, loss 1.5726746320724487, acc=0.4833333194255829, loss=1.5726746320724487
train: epoch 61, loss 0.4701235294342041, acc=0.7811111211776733, loss=0.4701235294342041
test: epoch 61, loss 1.599584698677063, acc=0.4749999940395355, loss=1.599584698677063
train: epoch 62, loss 0.4729197025299072, acc=0.7822777628898621, loss=0.4729197025299072
test: epoch 62, loss 1.697731852531433, acc=0.4694444537162781, loss=1.697731852531433
train: epoch 63, loss 0.4656432867050171, acc=0.7868333458900452, loss=0.4656432867050171
test: epoch 63, loss 1.6474460363388062, acc=0.4749999940395355, loss=1.6474460363388062
train: epoch 64, loss 0.4668009579181671, acc=0.781499981880188, loss=0.4668009579181671
test: epoch 64, loss 1.66303551197052, acc=0.4749999940395355, loss=1.66303551197052
train: epoch 65, loss 0.45125240087509155, acc=0.7904999852180481, loss=0.45125240087509155
test: epoch 65, loss 1.7491306066513062, acc=0.48055556416511536, loss=1.7491306066513062
train: epoch 66, loss 0.46192795038223267, acc=0.7846111059188843, loss=0.46192795038223267
test: epoch 66, loss 1.5589096546173096, acc=0.48055556416511536, loss=1.5589096546173096
train: epoch 67, loss 0.45213356614112854, acc=0.789555549621582, loss=0.45213356614112854
test: epoch 67, loss 1.6679582595825195, acc=0.4833333194255829, loss=1.6679582595825195
train: epoch 68, loss 0.44265681505203247, acc=0.7931666374206543, loss=0.44265681505203247
test: epoch 68, loss 1.6055183410644531, acc=0.47777777910232544, loss=1.6055183410644531
train: epoch 69, loss 0.4539927840232849, acc=0.7881666421890259, loss=0.4539927840232849
test: epoch 69, loss 1.683421015739441, acc=0.47777777910232544, loss=1.683421015739441
train: epoch 70, loss 0.45311012864112854, acc=0.7892777919769287, loss=0.45311012864112854
test: epoch 70, loss 1.6419302225112915, acc=0.48055556416511536, loss=1.6419302225112915
train: epoch 71, loss 0.47318965196609497, acc=0.7825555801391602, loss=0.47318965196609497
test: epoch 71, loss 1.9783234596252441, acc=0.4444444477558136, loss=1.9783234596252441
train: epoch 72, loss 0.45122748613357544, acc=0.7921110987663269, loss=0.45122748613357544
test: epoch 72, loss 1.584019660949707, acc=0.46666666865348816, loss=1.584019660949707
train: epoch 73, loss 0.44623875617980957, acc=0.7935000061988831, loss=0.44623875617980957
test: epoch 73, loss 1.4954183101654053, acc=0.4833333194255829, loss=1.4954183101654053
train: epoch 74, loss 0.43964946269989014, acc=0.7914444208145142, loss=0.43964946269989014
test: epoch 74, loss 1.693501353263855, acc=0.4749999940395355, loss=1.693501353263855
train: epoch 75, loss 0.44132182002067566, acc=0.7954999804496765, loss=0.44132182002067566
test: epoch 75, loss 1.7469075918197632, acc=0.4888888895511627, loss=1.7469075918197632
train: epoch 76, loss 0.4463823139667511, acc=0.7931666374206543, loss=0.4463823139667511
test: epoch 76, loss 1.7029027938842773, acc=0.4833333194255829, loss=1.7029027938842773
train: epoch 77, loss 0.4418827295303345, acc=0.7950000166893005, loss=0.4418827295303345
test: epoch 77, loss 1.586949348449707, acc=0.4861111044883728, loss=1.586949348449707
train: epoch 78, loss 0.4497929513454437, acc=0.7923333048820496, loss=0.4497929513454437
test: epoch 78, loss 1.8576140403747559, acc=0.4833333194255829, loss=1.8576140403747559
train: epoch 79, loss 0.4275818169116974, acc=0.7975555658340454, loss=0.4275818169116974
test: epoch 79, loss 1.800391674041748, acc=0.5055555701255798, loss=1.800391674041748
train: epoch 80, loss 0.42249488830566406, acc=0.800611138343811, loss=0.42249488830566406
test: epoch 80, loss 1.6281204223632812, acc=0.49444442987442017, loss=1.6281204223632812
train: epoch 81, loss 0.4365970194339752, acc=0.7971110939979553, loss=0.4365970194339752
test: epoch 81, loss 1.6310142278671265, acc=0.5, loss=1.6310142278671265
train: epoch 82, loss 0.4359661936759949, acc=0.7974444627761841, loss=0.4359661936759949
test: epoch 82, loss 1.8098050355911255, acc=0.48055556416511536, loss=1.8098050355911255
train: epoch 83, loss 0.4210790991783142, acc=0.8004444241523743, loss=0.4210790991783142
test: epoch 83, loss 1.6204676628112793, acc=0.5027777552604675, loss=1.6204676628112793
train: epoch 84, loss 0.4254467189311981, acc=0.796833336353302, loss=0.4254467189311981
test: epoch 84, loss 1.48856782913208, acc=0.4861111044883728, loss=1.48856782913208
train: epoch 85, loss 0.4196120798587799, acc=0.8068888783454895, loss=0.4196120798587799
test: epoch 85, loss 1.5914459228515625, acc=0.5083333253860474, loss=1.5914459228515625
train: epoch 86, loss 0.41108211874961853, acc=0.8073889017105103, loss=0.41108211874961853
test: epoch 86, loss 1.811946153640747, acc=0.5111111402511597, loss=1.811946153640747
train: epoch 87, loss 0.40212467312812805, acc=0.8159444332122803, loss=0.40212467312812805
test: epoch 87, loss 1.6635563373565674, acc=0.5361111164093018, loss=1.6635563373565674
train: epoch 88, loss 0.37995216250419617, acc=0.8302222490310669, loss=0.37995216250419617
test: epoch 88, loss 1.7818121910095215, acc=0.5361111164093018, loss=1.7818121910095215
train: epoch 89, loss 0.3746050298213959, acc=0.8357222080230713, loss=0.3746050298213959
test: epoch 89, loss 1.556208610534668, acc=0.5444444417953491, loss=1.556208610534668
train: epoch 90, loss 0.36969509720802307, acc=0.835277795791626, loss=0.36969509720802307
test: epoch 90, loss 1.6731878519058228, acc=0.5416666865348816, loss=1.6731878519058228
train: epoch 91, loss 0.3655667006969452, acc=0.835444450378418, loss=0.3655667006969452
test: epoch 91, loss 1.6899902820587158, acc=0.5444444417953491, loss=1.6899902820587158
train: epoch 92, loss 0.3574058711528778, acc=0.8389999866485596, loss=0.3574058711528778
test: epoch 92, loss 1.7661421298980713, acc=0.5361111164093018, loss=1.7661421298980713
train: epoch 93, loss 0.3623106777667999, acc=0.8391110897064209, loss=0.3623106777667999
test: epoch 93, loss 1.596942663192749, acc=0.5361111164093018, loss=1.596942663192749
train: epoch 94, loss 0.3600233495235443, acc=0.8424999713897705, loss=0.3600233495235443
test: epoch 94, loss 1.786032795906067, acc=0.5333333611488342, loss=1.786032795906067
train: epoch 95, loss 0.336788535118103, acc=0.8450555801391602, loss=0.336788535118103
test: epoch 95, loss 1.8336195945739746, acc=0.5361111164093018, loss=1.8336195945739746
train: epoch 96, loss 0.3459698557853699, acc=0.842555582523346, loss=0.3459698557853699
test: epoch 96, loss 1.5773206949234009, acc=0.5361111164093018, loss=1.5773206949234009
train: epoch 97, loss 0.33676061034202576, acc=0.8460555672645569, loss=0.33676061034202576
test: epoch 97, loss 1.832320213317871, acc=0.519444465637207, loss=1.832320213317871
train: epoch 98, loss 0.3506915271282196, acc=0.8390555381774902, loss=0.3506915271282196
test: epoch 98, loss 1.7497162818908691, acc=0.5388888716697693, loss=1.7497162818908691
train: epoch 99, loss 0.3456213176250458, acc=0.8456666469573975, loss=0.3456213176250458
test: epoch 99, loss 1.6163452863693237, acc=0.5388888716697693, loss=1.6163452863693237
train: epoch 100, loss 0.34058377146720886, acc=0.8457221984863281, loss=0.34058377146720886
test: epoch 100, loss 1.8499972820281982, acc=0.5416666865348816, loss=1.8499972820281982
train: epoch 101, loss 0.3302207291126251, acc=0.8470555543899536, loss=0.3302207291126251
test: epoch 101, loss 1.6401574611663818, acc=0.5388888716697693, loss=1.6401574611663818
train: epoch 102, loss 0.33417844772338867, acc=0.8482778072357178, loss=0.33417844772338867
test: epoch 102, loss 1.589393138885498, acc=0.5444444417953491, loss=1.589393138885498
train: epoch 103, loss 0.3270284831523895, acc=0.8545555472373962, loss=0.3270284831523895
test: epoch 103, loss 1.6948858499526978, acc=0.574999988079071, loss=1.6948858499526978
train: epoch 104, loss 0.3101760745048523, acc=0.8572777509689331, loss=0.3101760745048523
test: epoch 104, loss 1.5556451082229614, acc=0.5944444537162781, loss=1.5556451082229614
train: epoch 105, loss 0.2938605546951294, acc=0.862666666507721, loss=0.2938605546951294
test: epoch 105, loss 1.610694408416748, acc=0.6000000238418579, loss=1.610694408416748
train: epoch 106, loss 0.28989553451538086, acc=0.8630555272102356, loss=0.28989553451538086
test: epoch 106, loss 1.3882369995117188, acc=0.6027777791023254, loss=1.3882369995117188
train: epoch 107, loss 0.2881929576396942, acc=0.8611111044883728, loss=0.2881929576396942
test: epoch 107, loss 1.633634328842163, acc=0.6027777791023254, loss=1.633634328842163
train: epoch 108, loss 0.29156604409217834, acc=0.8608888983726501, loss=0.29156604409217834
test: epoch 108, loss 1.4558219909667969, acc=0.6027777791023254, loss=1.4558219909667969
train: epoch 109, loss 0.28486955165863037, acc=0.8646110892295837, loss=0.28486955165863037
test: epoch 109, loss 1.550778865814209, acc=0.6027777791023254, loss=1.550778865814209
train: epoch 110, loss 0.29323479533195496, acc=0.8613888621330261, loss=0.29323479533195496
test: epoch 110, loss 1.4676557779312134, acc=0.6027777791023254, loss=1.4676557779312134
train: epoch 111, loss 0.286405086517334, acc=0.8647222518920898, loss=0.286405086517334
test: epoch 111, loss 1.5097767114639282, acc=0.6027777791023254, loss=1.5097767114639282
train: epoch 112, loss 0.27592042088508606, acc=0.8658333420753479, loss=0.27592042088508606
test: epoch 112, loss 1.6013177633285522, acc=0.6000000238418579, loss=1.6013177633285522
train: epoch 113, loss 0.28508129715919495, acc=0.8642777800559998, loss=0.28508129715919495
test: epoch 113, loss 1.579388976097107, acc=0.6000000238418579, loss=1.579388976097107
train: epoch 114, loss 0.29325050115585327, acc=0.8650555610656738, loss=0.29325050115585327
test: epoch 114, loss 1.5160646438598633, acc=0.6000000238418579, loss=1.5160646438598633
train: epoch 115, loss 0.27952033281326294, acc=0.8648333549499512, loss=0.27952033281326294
test: epoch 115, loss 1.5038752555847168, acc=0.605555534362793, loss=1.5038752555847168
train: epoch 116, loss 0.2701115906238556, acc=0.86772221326828, loss=0.2701115906238556
test: epoch 116, loss 1.5301066637039185, acc=0.6111111044883728, loss=1.5301066637039185
train: epoch 117, loss 0.28894734382629395, acc=0.8676111102104187, loss=0.28894734382629395
test: epoch 117, loss 1.5543572902679443, acc=0.6111111044883728, loss=1.5543572902679443
train: epoch 118, loss 0.27715060114860535, acc=0.8682777881622314, loss=0.27715060114860535
test: epoch 118, loss 1.496376633644104, acc=0.6111111044883728, loss=1.496376633644104
train: epoch 119, loss 0.28350314497947693, acc=0.8660555481910706, loss=0.28350314497947693
test: epoch 119, loss 1.4498493671417236, acc=0.6138888597488403, loss=1.4498493671417236
train: epoch 120, loss 0.2808080315589905, acc=0.8711110949516296, loss=0.2808080315589905
test: epoch 120, loss 1.4986622333526611, acc=0.6111111044883728, loss=1.4986622333526611
train: epoch 121, loss 0.27468591928482056, acc=0.8648333549499512, loss=0.27468591928482056
test: epoch 121, loss 1.4312198162078857, acc=0.6138888597488403, loss=1.4312198162078857
train: epoch 122, loss 0.2728143036365509, acc=0.8673333525657654, loss=0.2728143036365509
test: epoch 122, loss 1.4347058534622192, acc=0.6138888597488403, loss=1.4347058534622192
train: epoch 123, loss 0.2961519956588745, acc=0.8631666898727417, loss=0.2961519956588745
test: epoch 123, loss 1.57249915599823, acc=0.6138888597488403, loss=1.57249915599823
train: epoch 124, loss 0.27818888425827026, acc=0.8650000095367432, loss=0.27818888425827026
test: epoch 124, loss 1.3872102499008179, acc=0.6138888597488403, loss=1.3872102499008179
train: epoch 125, loss 0.281232088804245, acc=0.8725555539131165, loss=0.281232088804245
test: epoch 125, loss 1.532365322113037, acc=0.6138888597488403, loss=1.532365322113037
train: epoch 126, loss 0.2815879285335541, acc=0.8718888759613037, loss=0.2815879285335541
test: epoch 126, loss 1.6184353828430176, acc=0.6138888597488403, loss=1.6184353828430176
train: epoch 127, loss 0.27106574177742004, acc=0.874833345413208, loss=0.27106574177742004
test: epoch 127, loss 1.6349406242370605, acc=0.6138888597488403, loss=1.6349406242370605
train: epoch 128, loss 0.28105291724205017, acc=0.8717222213745117, loss=0.28105291724205017
test: epoch 128, loss 1.3870832920074463, acc=0.6361111402511597, loss=1.3870832920074463
train: epoch 129, loss 0.2645889222621918, acc=0.871666669845581, loss=0.2645889222621918
test: epoch 129, loss 1.6660200357437134, acc=0.6194444298744202, loss=1.6660200357437134
train: epoch 130, loss 0.2745381295681, acc=0.8676666617393494, loss=0.2745381295681
test: epoch 130, loss 1.3624267578125, acc=0.644444465637207, loss=1.3624267578125
train: epoch 131, loss 0.2741566598415375, acc=0.871833324432373, loss=0.2741566598415375
test: epoch 131, loss 1.2738595008850098, acc=0.6499999761581421, loss=1.2738595008850098
train: epoch 132, loss 0.2675691843032837, acc=0.8705000281333923, loss=0.2675691843032837
test: epoch 132, loss 1.352555751800537, acc=0.6499999761581421, loss=1.352555751800537
train: epoch 133, loss 0.26430439949035645, acc=0.8719444274902344, loss=0.26430439949035645
test: epoch 133, loss 1.3846533298492432, acc=0.6499999761581421, loss=1.3846533298492432
train: epoch 134, loss 0.2592534124851227, acc=0.8747777938842773, loss=0.2592534124851227
test: epoch 134, loss 1.2907614707946777, acc=0.6499999761581421, loss=1.2907614707946777
train: epoch 135, loss 0.2672061026096344, acc=0.8702777624130249, loss=0.2672061026096344
test: epoch 135, loss 1.3113491535186768, acc=0.6499999761581421, loss=1.3113491535186768
train: epoch 136, loss 0.2607188820838928, acc=0.871833324432373, loss=0.2607188820838928
test: epoch 136, loss 1.3203785419464111, acc=0.6499999761581421, loss=1.3203785419464111
train: epoch 137, loss 0.2581067383289337, acc=0.8734999895095825, loss=0.2581067383289337
test: epoch 137, loss 1.3114486932754517, acc=0.6472222208976746, loss=1.3114486932754517
train: epoch 138, loss 0.27438291907310486, acc=0.8679444193840027, loss=0.27438291907310486
test: epoch 138, loss 1.285186767578125, acc=0.6472222208976746, loss=1.285186767578125
train: epoch 139, loss 0.259307861328125, acc=0.8696666955947876, loss=0.259307861328125
test: epoch 139, loss 1.255098819732666, acc=0.6499999761581421, loss=1.255098819732666
train: epoch 140, loss 0.2640113830566406, acc=0.8713333606719971, loss=0.2640113830566406
test: epoch 140, loss 1.440219521522522, acc=0.6527777910232544, loss=1.440219521522522
train: epoch 141, loss 0.26482728123664856, acc=0.8700000047683716, loss=0.26482728123664856
test: epoch 141, loss 1.2314567565917969, acc=0.644444465637207, loss=1.2314567565917969
train: epoch 142, loss 0.27137503027915955, acc=0.8690000176429749, loss=0.27137503027915955
test: epoch 142, loss 1.17841374874115, acc=0.6472222208976746, loss=1.17841374874115
train: epoch 143, loss 0.25524765253067017, acc=0.8728333115577698, loss=0.25524765253067017
test: epoch 143, loss 1.2148823738098145, acc=0.6472222208976746, loss=1.2148823738098145
train: epoch 144, loss 0.25166943669319153, acc=0.8730555772781372, loss=0.25166943669319153
test: epoch 144, loss 1.370219111442566, acc=0.6583333611488342, loss=1.370219111442566
train: epoch 145, loss 0.25042471289634705, acc=0.8747777938842773, loss=0.25042471289634705
test: epoch 145, loss 1.4953258037567139, acc=0.675000011920929, loss=1.4953258037567139
train: epoch 146, loss 0.2494824230670929, acc=0.8750555515289307, loss=0.2494824230670929
test: epoch 146, loss 1.1861108541488647, acc=0.6916666626930237, loss=1.1861108541488647
train: epoch 147, loss 0.25448402762413025, acc=0.8718888759613037, loss=0.25448402762413025
test: epoch 147, loss 1.1404531002044678, acc=0.699999988079071, loss=1.1404531002044678
train: epoch 148, loss 0.2418682873249054, acc=0.8778333067893982, loss=0.2418682873249054
test: epoch 148, loss 1.204252004623413, acc=0.6722221970558167, loss=1.204252004623413
train: epoch 149, loss 0.26783502101898193, acc=0.8715000152587891, loss=0.26783502101898193
test: epoch 149, loss 1.0393965244293213, acc=0.7083333134651184, loss=1.0393965244293213
train: epoch 150, loss 0.2419184297323227, acc=0.8770555257797241, loss=0.2419184297323227
test: epoch 150, loss 1.0793589353561401, acc=0.7083333134651184, loss=1.0793589353561401
