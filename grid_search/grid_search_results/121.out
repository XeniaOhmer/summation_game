# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=1", "--temp_decay=0.99", "--one_hot=true", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=358799399, receiver_embed_dim=128, temp_decay=0.99, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.9358279705047607, acc=0.09955555200576782, loss=2.9358279705047607
test: epoch 1, loss 2.3575191497802734, acc=0.17222222685813904, loss=2.3575191497802734
train: epoch 2, loss 1.7454067468643188, acc=0.2947777807712555, loss=1.7454067468643188
test: epoch 2, loss 2.058335065841675, acc=0.2361111044883728, loss=2.058335065841675
train: epoch 3, loss 1.425485372543335, acc=0.3967222273349762, loss=1.425485372543335
test: epoch 3, loss 1.7279980182647705, acc=0.3166666626930237, loss=1.7279980182647705
train: epoch 4, loss 1.2304927110671997, acc=0.4651666581630707, loss=1.2304927110671997
test: epoch 4, loss 1.692747712135315, acc=0.32499998807907104, loss=1.692747712135315
train: epoch 5, loss 1.1113475561141968, acc=0.5098888874053955, loss=1.1113475561141968
test: epoch 5, loss 1.6415107250213623, acc=0.3611111044883728, loss=1.6415107250213623
train: epoch 6, loss 1.0167276859283447, acc=0.5567222237586975, loss=1.0167276859283447
test: epoch 6, loss 1.8259996175765991, acc=0.3777777850627899, loss=1.8259996175765991
train: epoch 7, loss 0.9379523992538452, acc=0.5806111097335815, loss=0.9379523992538452
test: epoch 7, loss 1.47186279296875, acc=0.3916666805744171, loss=1.47186279296875
train: epoch 8, loss 0.888536274433136, acc=0.5981666445732117, loss=0.888536274433136
test: epoch 8, loss 1.4546966552734375, acc=0.375, loss=1.4546966552734375
train: epoch 9, loss 0.850744366645813, acc=0.6168888807296753, loss=0.850744366645813
test: epoch 9, loss 1.496010184288025, acc=0.4027777910232544, loss=1.496010184288025
train: epoch 10, loss 0.8112742304801941, acc=0.6349999904632568, loss=0.8112742304801941
test: epoch 10, loss 1.6394344568252563, acc=0.41111111640930176, loss=1.6394344568252563
train: epoch 11, loss 0.7925136089324951, acc=0.6386111378669739, loss=0.7925136089324951
test: epoch 11, loss 1.6307395696640015, acc=0.38333332538604736, loss=1.6307395696640015
train: epoch 12, loss 0.7909589409828186, acc=0.6445000171661377, loss=0.7909589409828186
test: epoch 12, loss 1.5400241613388062, acc=0.4138889014720917, loss=1.5400241613388062
train: epoch 13, loss 0.7778460383415222, acc=0.6436111330986023, loss=0.7778460383415222
test: epoch 13, loss 1.6595954895019531, acc=0.41111111640930176, loss=1.6595954895019531
train: epoch 14, loss 0.772558331489563, acc=0.6466110944747925, loss=0.772558331489563
test: epoch 14, loss 1.5582526922225952, acc=0.4277777671813965, loss=1.5582526922225952
train: epoch 15, loss 0.7662968635559082, acc=0.644611120223999, loss=0.7662968635559082
test: epoch 15, loss 1.7904690504074097, acc=0.42222222685813904, loss=1.7904690504074097
train: epoch 16, loss 0.7366942167282104, acc=0.6577222347259521, loss=0.7366942167282104
test: epoch 16, loss 1.5168243646621704, acc=0.4416666626930237, loss=1.5168243646621704
train: epoch 17, loss 0.7340720891952515, acc=0.6593888998031616, loss=0.7340720891952515
test: epoch 17, loss 1.4881229400634766, acc=0.4472222328186035, loss=1.4881229400634766
train: epoch 18, loss 0.7203230857849121, acc=0.6679444313049316, loss=0.7203230857849121
test: epoch 18, loss 1.5764421224594116, acc=0.4166666567325592, loss=1.5764421224594116
train: epoch 19, loss 0.7339157462120056, acc=0.6629999876022339, loss=0.7339157462120056
test: epoch 19, loss 1.3616936206817627, acc=0.4472222328186035, loss=1.3616936206817627
train: epoch 20, loss 0.709919273853302, acc=0.6787222027778625, loss=0.709919273853302
test: epoch 20, loss 1.496044635772705, acc=0.4444444477558136, loss=1.496044635772705
train: epoch 21, loss 0.7083326578140259, acc=0.6807222366333008, loss=0.7083326578140259
test: epoch 21, loss 1.4981708526611328, acc=0.4444444477558136, loss=1.4981708526611328
train: epoch 22, loss 0.695391833782196, acc=0.6854444742202759, loss=0.695391833782196
test: epoch 22, loss 1.603313684463501, acc=0.4277777671813965, loss=1.603313684463501
train: epoch 23, loss 0.7132706046104431, acc=0.679722249507904, loss=0.7132706046104431
test: epoch 23, loss 1.5415173768997192, acc=0.4416666626930237, loss=1.5415173768997192
train: epoch 24, loss 0.6990379095077515, acc=0.6844444274902344, loss=0.6990379095077515
test: epoch 24, loss 1.567710041999817, acc=0.4333333373069763, loss=1.567710041999817
train: epoch 25, loss 0.7192078828811646, acc=0.6803333163261414, loss=0.7192078828811646
test: epoch 25, loss 1.463619351387024, acc=0.4444444477558136, loss=1.463619351387024
train: epoch 26, loss 0.6978179812431335, acc=0.6863333582878113, loss=0.6978179812431335
test: epoch 26, loss 1.4630707502365112, acc=0.4444444477558136, loss=1.4630707502365112
train: epoch 27, loss 0.7233802676200867, acc=0.6751111149787903, loss=0.7233802676200867
test: epoch 27, loss 1.4089349508285522, acc=0.43611112236976624, loss=1.4089349508285522
train: epoch 28, loss 0.7187731266021729, acc=0.6752222180366516, loss=0.7187731266021729
test: epoch 28, loss 1.537017822265625, acc=0.4333333373069763, loss=1.537017822265625
train: epoch 29, loss 0.712990403175354, acc=0.6832777857780457, loss=0.712990403175354
test: epoch 29, loss 1.4274966716766357, acc=0.4444444477558136, loss=1.4274966716766357
train: epoch 30, loss 0.709464967250824, acc=0.6808333396911621, loss=0.709464967250824
test: epoch 30, loss 1.4152405261993408, acc=0.43888887763023376, loss=1.4152405261993408
train: epoch 31, loss 0.7086284756660461, acc=0.6769444346427917, loss=0.7086284756660461
test: epoch 31, loss 1.410833716392517, acc=0.4444444477558136, loss=1.410833716392517
train: epoch 32, loss 0.7155486345291138, acc=0.6790555715560913, loss=0.7155486345291138
test: epoch 32, loss 1.4965342283248901, acc=0.4416666626930237, loss=1.4965342283248901
train: epoch 33, loss 0.713019609451294, acc=0.675777792930603, loss=0.713019609451294
test: epoch 33, loss 1.4545059204101562, acc=0.4444444477558136, loss=1.4545059204101562
train: epoch 34, loss 0.7019398212432861, acc=0.6811666488647461, loss=0.7019398212432861
test: epoch 34, loss 1.4386379718780518, acc=0.4555555582046509, loss=1.4386379718780518
train: epoch 35, loss 0.6658817529678345, acc=0.6946666836738586, loss=0.6658817529678345
test: epoch 35, loss 1.4412227869033813, acc=0.46666666865348816, loss=1.4412227869033813
train: epoch 36, loss 0.6840341687202454, acc=0.6885555386543274, loss=0.6840341687202454
test: epoch 36, loss 1.4306668043136597, acc=0.4611110985279083, loss=1.4306668043136597
train: epoch 37, loss 0.6696690320968628, acc=0.6936110854148865, loss=0.6696690320968628
test: epoch 37, loss 1.5432946681976318, acc=0.4611110985279083, loss=1.5432946681976318
train: epoch 38, loss 0.6820881366729736, acc=0.6910555362701416, loss=0.6820881366729736
test: epoch 38, loss 1.4264252185821533, acc=0.4555555582046509, loss=1.4264252185821533
train: epoch 39, loss 0.6657990217208862, acc=0.6977777481079102, loss=0.6657990217208862
test: epoch 39, loss 1.3543436527252197, acc=0.4555555582046509, loss=1.3543436527252197
train: epoch 40, loss 0.6720454096794128, acc=0.6978333592414856, loss=0.6720454096794128
test: epoch 40, loss 1.425549864768982, acc=0.4555555582046509, loss=1.425549864768982
train: epoch 41, loss 0.6658484935760498, acc=0.6974999904632568, loss=0.6658484935760498
test: epoch 41, loss 1.3749388456344604, acc=0.4611110985279083, loss=1.3749388456344604
train: epoch 42, loss 0.6882902979850769, acc=0.6889444589614868, loss=0.6882902979850769
test: epoch 42, loss 1.3022295236587524, acc=0.46666666865348816, loss=1.3022295236587524
train: epoch 43, loss 0.6700761318206787, acc=0.6942222118377686, loss=0.6700761318206787
test: epoch 43, loss 1.3981338739395142, acc=0.4611110985279083, loss=1.3981338739395142
train: epoch 44, loss 0.6550007462501526, acc=0.7023888826370239, loss=0.6550007462501526
test: epoch 44, loss 1.3850642442703247, acc=0.4611110985279083, loss=1.3850642442703247
train: epoch 45, loss 0.6592660546302795, acc=0.7005555629730225, loss=0.6592660546302795
test: epoch 45, loss 1.4978187084197998, acc=0.4611110985279083, loss=1.4978187084197998
train: epoch 46, loss 0.6388963460922241, acc=0.7078333497047424, loss=0.6388963460922241
test: epoch 46, loss 1.4761749505996704, acc=0.4611110985279083, loss=1.4761749505996704
train: epoch 47, loss 0.6334259510040283, acc=0.7128888964653015, loss=0.6334259510040283
test: epoch 47, loss 1.5196340084075928, acc=0.4611110985279083, loss=1.5196340084075928
train: epoch 48, loss 0.6408246755599976, acc=0.7051666378974915, loss=0.6408246755599976
test: epoch 48, loss 1.544150948524475, acc=0.4611110985279083, loss=1.544150948524475
train: epoch 49, loss 0.6625530123710632, acc=0.6987777948379517, loss=0.6625530123710632
test: epoch 49, loss 1.4816327095031738, acc=0.4611110985279083, loss=1.4816327095031738
train: epoch 50, loss 0.641723096370697, acc=0.707277774810791, loss=0.641723096370697
test: epoch 50, loss 1.5409038066864014, acc=0.4611110985279083, loss=1.5409038066864014
train: epoch 51, loss 0.6466673016548157, acc=0.7034444212913513, loss=0.6466673016548157
test: epoch 51, loss 1.5202138423919678, acc=0.4611110985279083, loss=1.5202138423919678
train: epoch 52, loss 0.6210435628890991, acc=0.7111111283302307, loss=0.6210435628890991
test: epoch 52, loss 1.4820611476898193, acc=0.4611110985279083, loss=1.4820611476898193
train: epoch 53, loss 0.6279029846191406, acc=0.7088333368301392, loss=0.6279029846191406
test: epoch 53, loss 1.5751081705093384, acc=0.4611110985279083, loss=1.5751081705093384
train: epoch 54, loss 0.6154998540878296, acc=0.7135000228881836, loss=0.6154998540878296
test: epoch 54, loss 1.491960048675537, acc=0.4611110985279083, loss=1.491960048675537
train: epoch 55, loss 0.6253687143325806, acc=0.7105555534362793, loss=0.6253687143325806
test: epoch 55, loss 1.5883287191390991, acc=0.4611110985279083, loss=1.5883287191390991
train: epoch 56, loss 0.6181495785713196, acc=0.7150555849075317, loss=0.6181495785713196
test: epoch 56, loss 1.4264276027679443, acc=0.4611110985279083, loss=1.4264276027679443
train: epoch 57, loss 0.6363804936408997, acc=0.7090555429458618, loss=0.6363804936408997
test: epoch 57, loss 1.355660319328308, acc=0.4611110985279083, loss=1.355660319328308
train: epoch 58, loss 0.62903892993927, acc=0.7132222056388855, loss=0.62903892993927
test: epoch 58, loss 1.4446889162063599, acc=0.4611110985279083, loss=1.4446889162063599
train: epoch 59, loss 0.6376827955245972, acc=0.7105555534362793, loss=0.6376827955245972
test: epoch 59, loss 1.6186144351959229, acc=0.44999998807907104, loss=1.6186144351959229
train: epoch 60, loss 0.600157618522644, acc=0.7232778072357178, loss=0.600157618522644
test: epoch 60, loss 1.5097784996032715, acc=0.4611110985279083, loss=1.5097784996032715
train: epoch 61, loss 0.6021727919578552, acc=0.7214999794960022, loss=0.6021727919578552
test: epoch 61, loss 1.531843900680542, acc=0.4611110985279083, loss=1.531843900680542
train: epoch 62, loss 0.6208743453025818, acc=0.7177222371101379, loss=0.6208743453025818
test: epoch 62, loss 1.4314724206924438, acc=0.4611110985279083, loss=1.4314724206924438
train: epoch 63, loss 0.6093717813491821, acc=0.7186111211776733, loss=0.6093717813491821
test: epoch 63, loss 1.5595757961273193, acc=0.4611110985279083, loss=1.5595757961273193
train: epoch 64, loss 0.6173369884490967, acc=0.7193333506584167, loss=0.6173369884490967
test: epoch 64, loss 1.4704704284667969, acc=0.4611110985279083, loss=1.4704704284667969
train: epoch 65, loss 0.5955976247787476, acc=0.722000002861023, loss=0.5955976247787476
test: epoch 65, loss 1.5752336978912354, acc=0.4611110985279083, loss=1.5752336978912354
train: epoch 66, loss 0.6057624220848083, acc=0.7193889021873474, loss=0.6057624220848083
test: epoch 66, loss 1.5302263498306274, acc=0.4611110985279083, loss=1.5302263498306274
train: epoch 67, loss 0.6132975816726685, acc=0.7120555639266968, loss=0.6132975816726685
test: epoch 67, loss 1.5778400897979736, acc=0.4611110985279083, loss=1.5778400897979736
train: epoch 68, loss 0.6171915531158447, acc=0.7147777676582336, loss=0.6171915531158447
test: epoch 68, loss 1.4370112419128418, acc=0.4611110985279083, loss=1.4370112419128418
train: epoch 69, loss 0.6046827435493469, acc=0.7196666598320007, loss=0.6046827435493469
test: epoch 69, loss 1.515262246131897, acc=0.45277777314186096, loss=1.515262246131897
train: epoch 70, loss 0.5958670973777771, acc=0.7266111373901367, loss=0.5958670973777771
test: epoch 70, loss 1.6762149333953857, acc=0.4611110985279083, loss=1.6762149333953857
train: epoch 71, loss 0.5979139804840088, acc=0.7197777628898621, loss=0.5979139804840088
test: epoch 71, loss 1.546260118484497, acc=0.4611110985279083, loss=1.546260118484497
train: epoch 72, loss 0.6003066897392273, acc=0.7222777605056763, loss=0.6003066897392273
test: epoch 72, loss 1.4604190587997437, acc=0.46666666865348816, loss=1.4604190587997437
train: epoch 73, loss 0.5872038006782532, acc=0.723111093044281, loss=0.5872038006782532
test: epoch 73, loss 1.5094325542449951, acc=0.46666666865348816, loss=1.5094325542449951
train: epoch 74, loss 0.5751491785049438, acc=0.7278888821601868, loss=0.5751491785049438
test: epoch 74, loss 1.476564884185791, acc=0.48055556416511536, loss=1.476564884185791
train: epoch 75, loss 0.5904459357261658, acc=0.7264999747276306, loss=0.5904459357261658
test: epoch 75, loss 1.5761076211929321, acc=0.47777777910232544, loss=1.5761076211929321
train: epoch 76, loss 0.575899600982666, acc=0.7319999933242798, loss=0.575899600982666
test: epoch 76, loss 1.5325236320495605, acc=0.4861111044883728, loss=1.5325236320495605
train: epoch 77, loss 0.570412278175354, acc=0.7328888773918152, loss=0.570412278175354
test: epoch 77, loss 1.423418402671814, acc=0.49166667461395264, loss=1.423418402671814
train: epoch 78, loss 0.5632495880126953, acc=0.7344444394111633, loss=0.5632495880126953
test: epoch 78, loss 1.4301992654800415, acc=0.4722222089767456, loss=1.4301992654800415
train: epoch 79, loss 0.5802682638168335, acc=0.7247222065925598, loss=0.5802682638168335
test: epoch 79, loss 1.4346517324447632, acc=0.49444442987442017, loss=1.4346517324447632
train: epoch 80, loss 0.5767197608947754, acc=0.7281110882759094, loss=0.5767197608947754
test: epoch 80, loss 1.4403975009918213, acc=0.49444442987442017, loss=1.4403975009918213
train: epoch 81, loss 0.5578424334526062, acc=0.7338888645172119, loss=0.5578424334526062
test: epoch 81, loss 1.4864672422409058, acc=0.49444442987442017, loss=1.4864672422409058
train: epoch 82, loss 0.5576205849647522, acc=0.7378888726234436, loss=0.5576205849647522
test: epoch 82, loss 1.40248441696167, acc=0.4972222149372101, loss=1.40248441696167
train: epoch 83, loss 0.5510038733482361, acc=0.7352222204208374, loss=0.5510038733482361
test: epoch 83, loss 1.3889238834381104, acc=0.4972222149372101, loss=1.3889238834381104
train: epoch 84, loss 0.5475473999977112, acc=0.7408333420753479, loss=0.5475473999977112
test: epoch 84, loss 1.375654935836792, acc=0.5222222208976746, loss=1.375654935836792
train: epoch 85, loss 0.5393950343132019, acc=0.7432777881622314, loss=0.5393950343132019
test: epoch 85, loss 1.3387664556503296, acc=0.5222222208976746, loss=1.3387664556503296
train: epoch 86, loss 0.5420770049095154, acc=0.7408888936042786, loss=0.5420770049095154
test: epoch 86, loss 1.4459577798843384, acc=0.5222222208976746, loss=1.4459577798843384
train: epoch 87, loss 0.5553451180458069, acc=0.7337777614593506, loss=0.5553451180458069
test: epoch 87, loss 1.4204585552215576, acc=0.5222222208976746, loss=1.4204585552215576
train: epoch 88, loss 0.53944993019104, acc=0.7398333549499512, loss=0.53944993019104
test: epoch 88, loss 1.3522995710372925, acc=0.5222222208976746, loss=1.3522995710372925
train: epoch 89, loss 0.5330302119255066, acc=0.7410555481910706, loss=0.5330302119255066
test: epoch 89, loss 1.4465527534484863, acc=0.5222222208976746, loss=1.4465527534484863
train: epoch 90, loss 0.5291178226470947, acc=0.7441666722297668, loss=0.5291178226470947
test: epoch 90, loss 1.47780442237854, acc=0.5222222208976746, loss=1.47780442237854
train: epoch 91, loss 0.5275834202766418, acc=0.7450555562973022, loss=0.5275834202766418
test: epoch 91, loss 1.3678596019744873, acc=0.5222222208976746, loss=1.3678596019744873
train: epoch 92, loss 0.5508717894554138, acc=0.7418333292007446, loss=0.5508717894554138
test: epoch 92, loss 1.3799474239349365, acc=0.5027777552604675, loss=1.3799474239349365
train: epoch 93, loss 0.529915452003479, acc=0.7454444169998169, loss=0.529915452003479
test: epoch 93, loss 1.4146437644958496, acc=0.5222222208976746, loss=1.4146437644958496
train: epoch 94, loss 0.5135673880577087, acc=0.7489444613456726, loss=0.5135673880577087
test: epoch 94, loss 1.5348281860351562, acc=0.519444465637207, loss=1.5348281860351562
train: epoch 95, loss 0.5385653376579285, acc=0.7437777519226074, loss=0.5385653376579285
test: epoch 95, loss 1.3672764301300049, acc=0.5249999761581421, loss=1.3672764301300049
train: epoch 96, loss 0.5151628255844116, acc=0.7523333430290222, loss=0.5151628255844116
test: epoch 96, loss 1.3746570348739624, acc=0.5305555462837219, loss=1.3746570348739624
train: epoch 97, loss 0.510776698589325, acc=0.754444420337677, loss=0.510776698589325
test: epoch 97, loss 1.375524640083313, acc=0.5416666865348816, loss=1.375524640083313
train: epoch 98, loss 0.4955812394618988, acc=0.7630000114440918, loss=0.4955812394618988
test: epoch 98, loss 1.3584762811660767, acc=0.5638889074325562, loss=1.3584762811660767
train: epoch 99, loss 0.49119821190834045, acc=0.7672222256660461, loss=0.49119821190834045
test: epoch 99, loss 1.1884645223617554, acc=0.5611110925674438, loss=1.1884645223617554
train: epoch 100, loss 0.47309446334838867, acc=0.7708333134651184, loss=0.47309446334838867
test: epoch 100, loss 1.2960131168365479, acc=0.5638889074325562, loss=1.2960131168365479
train: epoch 101, loss 0.47964808344841003, acc=0.7707222104072571, loss=0.47964808344841003
test: epoch 101, loss 1.1811060905456543, acc=0.5611110925674438, loss=1.1811060905456543
train: epoch 102, loss 0.47683653235435486, acc=0.7708888649940491, loss=0.47683653235435486
test: epoch 102, loss 1.308760404586792, acc=0.5638889074325562, loss=1.308760404586792
train: epoch 103, loss 0.48445674777030945, acc=0.7652222514152527, loss=0.48445674777030945
test: epoch 103, loss 1.2426663637161255, acc=0.5638889074325562, loss=1.2426663637161255
train: epoch 104, loss 0.46765413880348206, acc=0.7721111178398132, loss=0.46765413880348206
test: epoch 104, loss 1.2627791166305542, acc=0.5638889074325562, loss=1.2627791166305542
train: epoch 105, loss 0.4731399416923523, acc=0.7723333239555359, loss=0.4731399416923523
test: epoch 105, loss 1.1908577680587769, acc=0.5638889074325562, loss=1.1908577680587769
train: epoch 106, loss 0.46169379353523254, acc=0.7716666460037231, loss=0.46169379353523254
test: epoch 106, loss 1.2219476699829102, acc=0.5638889074325562, loss=1.2219476699829102
train: epoch 107, loss 0.4759390950202942, acc=0.7701666951179504, loss=0.4759390950202942
test: epoch 107, loss 1.1158586740493774, acc=0.5666666626930237, loss=1.1158586740493774
train: epoch 108, loss 0.4679017961025238, acc=0.7706666588783264, loss=0.4679017961025238
test: epoch 108, loss 1.3267996311187744, acc=0.5638889074325562, loss=1.3267996311187744
train: epoch 109, loss 0.4664326310157776, acc=0.7718333601951599, loss=0.4664326310157776
test: epoch 109, loss 1.2974052429199219, acc=0.5638889074325562, loss=1.2974052429199219
train: epoch 110, loss 0.4455113410949707, acc=0.7777222394943237, loss=0.4455113410949707
test: epoch 110, loss 1.13938570022583, acc=0.5861111283302307, loss=1.13938570022583
train: epoch 111, loss 0.46481606364250183, acc=0.7721666693687439, loss=0.46481606364250183
test: epoch 111, loss 1.170743465423584, acc=0.5916666388511658, loss=1.170743465423584
train: epoch 112, loss 0.47486263513565063, acc=0.7680000066757202, loss=0.47486263513565063
test: epoch 112, loss 1.198498010635376, acc=0.5916666388511658, loss=1.198498010635376
train: epoch 113, loss 0.46342554688453674, acc=0.7728888988494873, loss=0.46342554688453674
test: epoch 113, loss 1.062280297279358, acc=0.5916666388511658, loss=1.062280297279358
train: epoch 114, loss 0.45149004459381104, acc=0.7737777829170227, loss=0.45149004459381104
test: epoch 114, loss 1.1094993352890015, acc=0.5916666388511658, loss=1.1094993352890015
train: epoch 115, loss 0.44246289134025574, acc=0.7774999737739563, loss=0.44246289134025574
test: epoch 115, loss 1.1495329141616821, acc=0.5916666388511658, loss=1.1495329141616821
train: epoch 116, loss 0.442806214094162, acc=0.7736666798591614, loss=0.442806214094162
test: epoch 116, loss 1.1707384586334229, acc=0.605555534362793, loss=1.1707384586334229
train: epoch 117, loss 0.42568671703338623, acc=0.7807222008705139, loss=0.42568671703338623
test: epoch 117, loss 1.0982246398925781, acc=0.6194444298744202, loss=1.0982246398925781
train: epoch 118, loss 0.44803088903427124, acc=0.7760555744171143, loss=0.44803088903427124
test: epoch 118, loss 0.7674201130867004, acc=0.6555555462837219, loss=0.7674201130867004
train: epoch 119, loss 0.4385448396205902, acc=0.7743889093399048, loss=0.4385448396205902
test: epoch 119, loss 0.8873226046562195, acc=0.6555555462837219, loss=0.8873226046562195
train: epoch 120, loss 0.4271285831928253, acc=0.7839444279670715, loss=0.4271285831928253
test: epoch 120, loss 0.8311415910720825, acc=0.6666666865348816, loss=0.8311415910720825
train: epoch 121, loss 0.42606303095817566, acc=0.7798333168029785, loss=0.42606303095817566
test: epoch 121, loss 0.8565570712089539, acc=0.6666666865348816, loss=0.8565570712089539
train: epoch 122, loss 0.41856709122657776, acc=0.7806666493415833, loss=0.41856709122657776
test: epoch 122, loss 0.8060633540153503, acc=0.6666666865348816, loss=0.8060633540153503
train: epoch 123, loss 0.4301302134990692, acc=0.7724444270133972, loss=0.4301302134990692
test: epoch 123, loss 0.8377565145492554, acc=0.6666666865348816, loss=0.8377565145492554
train: epoch 124, loss 0.4105749726295471, acc=0.7799444198608398, loss=0.4105749726295471
test: epoch 124, loss 0.8160896301269531, acc=0.6666666865348816, loss=0.8160896301269531
train: epoch 125, loss 0.4220161736011505, acc=0.7760000228881836, loss=0.4220161736011505
test: epoch 125, loss 0.8683264255523682, acc=0.6666666865348816, loss=0.8683264255523682
train: epoch 126, loss 0.4219467043876648, acc=0.7791666388511658, loss=0.4219467043876648
test: epoch 126, loss 0.8913794755935669, acc=0.6666666865348816, loss=0.8913794755935669
train: epoch 127, loss 0.409183144569397, acc=0.7791110873222351, loss=0.409183144569397
test: epoch 127, loss 0.7864682078361511, acc=0.6666666865348816, loss=0.7864682078361511
train: epoch 128, loss 0.4165067970752716, acc=0.7822777628898621, loss=0.4165067970752716
test: epoch 128, loss 0.8570025563240051, acc=0.6722221970558167, loss=0.8570025563240051
train: epoch 129, loss 0.41269370913505554, acc=0.7816110849380493, loss=0.41269370913505554
test: epoch 129, loss 0.8621986508369446, acc=0.6666666865348816, loss=0.8621986508369446
train: epoch 130, loss 0.42062464356422424, acc=0.7801666855812073, loss=0.42062464356422424
test: epoch 130, loss 0.8207370638847351, acc=0.6666666865348816, loss=0.8207370638847351
train: epoch 131, loss 0.41328227519989014, acc=0.7808333039283752, loss=0.41328227519989014
test: epoch 131, loss 0.9469592571258545, acc=0.6666666865348816, loss=0.9469592571258545
train: epoch 132, loss 0.40650931000709534, acc=0.782444417476654, loss=0.40650931000709534
test: epoch 132, loss 0.9018498659133911, acc=0.6666666865348816, loss=0.9018498659133911
train: epoch 133, loss 0.4005180299282074, acc=0.7877777814865112, loss=0.4005180299282074
test: epoch 133, loss 0.9597189426422119, acc=0.6666666865348816, loss=0.9597189426422119
train: epoch 134, loss 0.4171653091907501, acc=0.7818333506584167, loss=0.4171653091907501
test: epoch 134, loss 0.9034435153007507, acc=0.6611111164093018, loss=0.9034435153007507
train: epoch 135, loss 0.43906325101852417, acc=0.7889444231987, loss=0.43906325101852417
test: epoch 135, loss 0.8681504130363464, acc=0.6583333611488342, loss=0.8681504130363464
train: epoch 136, loss 0.45151618123054504, acc=0.7850555777549744, loss=0.45151618123054504
test: epoch 136, loss 0.908949077129364, acc=0.6777777671813965, loss=0.908949077129364
train: epoch 137, loss 0.43012478947639465, acc=0.7903888821601868, loss=0.43012478947639465
test: epoch 137, loss 0.9031983613967896, acc=0.675000011920929, loss=0.9031983613967896
train: epoch 138, loss 0.43038123846054077, acc=0.789222240447998, loss=0.43038123846054077
test: epoch 138, loss 0.8340518474578857, acc=0.6805555820465088, loss=0.8340518474578857
train: epoch 139, loss 0.3997270464897156, acc=0.7964444160461426, loss=0.3997270464897156
test: epoch 139, loss 0.7253541946411133, acc=0.6888889074325562, loss=0.7253541946411133
train: epoch 140, loss 0.4064713418483734, acc=0.7946110963821411, loss=0.4064713418483734
test: epoch 140, loss 0.7588743567466736, acc=0.6972222328186035, loss=0.7588743567466736
train: epoch 141, loss 0.4159334599971771, acc=0.7916111350059509, loss=0.4159334599971771
test: epoch 141, loss 0.6943356394767761, acc=0.6944444179534912, loss=0.6943356394767761
train: epoch 142, loss 0.41586124897003174, acc=0.7942222356796265, loss=0.41586124897003174
test: epoch 142, loss 0.8171538710594177, acc=0.6916666626930237, loss=0.8171538710594177
train: epoch 143, loss 0.4281250238418579, acc=0.788444459438324, loss=0.4281250238418579
test: epoch 143, loss 0.8658539056777954, acc=0.6916666626930237, loss=0.8658539056777954
train: epoch 144, loss 0.41390833258628845, acc=0.7908333539962769, loss=0.41390833258628845
test: epoch 144, loss 0.8258050084114075, acc=0.6916666626930237, loss=0.8258050084114075
train: epoch 145, loss 0.42125973105430603, acc=0.7868333458900452, loss=0.42125973105430603
test: epoch 145, loss 0.7726449966430664, acc=0.6916666626930237, loss=0.7726449966430664
train: epoch 146, loss 0.4210703670978546, acc=0.7876111268997192, loss=0.4210703670978546
test: epoch 146, loss 0.6984845995903015, acc=0.6888889074325562, loss=0.6984845995903015
train: epoch 147, loss 0.432284414768219, acc=0.7818333506584167, loss=0.432284414768219
test: epoch 147, loss 0.774036705493927, acc=0.6944444179534912, loss=0.774036705493927
train: epoch 148, loss 0.42548513412475586, acc=0.7867222428321838, loss=0.42548513412475586
test: epoch 148, loss 0.7914531230926514, acc=0.6944444179534912, loss=0.7914531230926514
train: epoch 149, loss 0.41571375727653503, acc=0.7875000238418579, loss=0.41571375727653503
test: epoch 149, loss 0.814174234867096, acc=0.699999988079071, loss=0.814174234867096
train: epoch 150, loss 0.4252488613128662, acc=0.7829444408416748, loss=0.4252488613128662
test: epoch 150, loss 0.6426385641098022, acc=0.7027778029441833, loss=0.6426385641098022
