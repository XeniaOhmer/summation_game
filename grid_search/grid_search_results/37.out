# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=1", "--one_hot=true", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1943921157, receiver_embed_dim=32, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.049192428588867, acc=0.08811111003160477, loss=3.049192428588867
test: epoch 1, loss 4.399982452392578, acc=0.08888889104127884, loss=4.399982452392578
train: epoch 2, loss 1.940891981124878, acc=0.2785555422306061, loss=1.940891981124878
test: epoch 2, loss 5.024267196655273, acc=0.10833333432674408, loss=5.024267196655273
train: epoch 3, loss 1.4622297286987305, acc=0.42294445633888245, loss=1.4622297286987305
test: epoch 3, loss 4.920246601104736, acc=0.13055555522441864, loss=4.920246601104736
train: epoch 4, loss 1.232373595237732, acc=0.5006666779518127, loss=1.232373595237732
test: epoch 4, loss 6.269512176513672, acc=0.12777778506278992, loss=6.269512176513672
train: epoch 5, loss 1.0908464193344116, acc=0.5533888936042786, loss=1.0908464193344116
test: epoch 5, loss 4.123192310333252, acc=0.17499999701976776, loss=4.123192310333252
train: epoch 6, loss 0.9297690391540527, acc=0.636555552482605, loss=0.9297690391540527
test: epoch 6, loss 4.044788837432861, acc=0.21944443881511688, loss=4.044788837432861
train: epoch 7, loss 0.7934461832046509, acc=0.6902777552604675, loss=0.7934461832046509
test: epoch 7, loss 4.261866092681885, acc=0.2361111044883728, loss=4.261866092681885
train: epoch 8, loss 0.6872705221176147, acc=0.7370555400848389, loss=0.6872705221176147
test: epoch 8, loss 3.722062349319458, acc=0.18888889253139496, loss=3.722062349319458
train: epoch 9, loss 0.6059886813163757, acc=0.7723888754844666, loss=0.6059886813163757
test: epoch 9, loss 3.5403623580932617, acc=0.24722221493721008, loss=3.5403623580932617
train: epoch 10, loss 0.5500729084014893, acc=0.7954444289207458, loss=0.5500729084014893
test: epoch 10, loss 3.4276111125946045, acc=0.2527777850627899, loss=3.4276111125946045
train: epoch 11, loss 0.5011799931526184, acc=0.8136666417121887, loss=0.5011799931526184
test: epoch 11, loss 3.587778091430664, acc=0.23055554926395416, loss=3.587778091430664
train: epoch 12, loss 0.4452854096889496, acc=0.8366110920906067, loss=0.4452854096889496
test: epoch 12, loss 3.8671369552612305, acc=0.2527777850627899, loss=3.8671369552612305
train: epoch 13, loss 0.41069433093070984, acc=0.8513888716697693, loss=0.41069433093070984
test: epoch 13, loss 3.625880241394043, acc=0.2527777850627899, loss=3.625880241394043
train: epoch 14, loss 0.40913331508636475, acc=0.852222204208374, loss=0.40913331508636475
test: epoch 14, loss 3.713541030883789, acc=0.21666666865348816, loss=3.713541030883789
train: epoch 15, loss 0.3715617060661316, acc=0.8650555610656738, loss=0.3715617060661316
test: epoch 15, loss 3.5208253860473633, acc=0.22499999403953552, loss=3.5208253860473633
train: epoch 16, loss 0.35106801986694336, acc=0.8738889098167419, loss=0.35106801986694336
test: epoch 16, loss 3.7214038372039795, acc=0.22777777910232544, loss=3.7214038372039795
train: epoch 17, loss 0.33659446239471436, acc=0.8830000162124634, loss=0.33659446239471436
test: epoch 17, loss 4.126614570617676, acc=0.20277777314186096, loss=4.126614570617676
train: epoch 18, loss 0.3243426978588104, acc=0.8848333358764648, loss=0.3243426978588104
test: epoch 18, loss 4.13418436050415, acc=0.22499999403953552, loss=4.13418436050415
train: epoch 19, loss 0.3019178509712219, acc=0.8954444527626038, loss=0.3019178509712219
test: epoch 19, loss 3.859943151473999, acc=0.24166665971279144, loss=3.859943151473999
train: epoch 20, loss 0.28190863132476807, acc=0.9032222032546997, loss=0.28190863132476807
test: epoch 20, loss 3.656802177429199, acc=0.2944444417953491, loss=3.656802177429199
train: epoch 21, loss 0.265153706073761, acc=0.9079444408416748, loss=0.265153706073761
test: epoch 21, loss 3.0717320442199707, acc=0.3222222328186035, loss=3.0717320442199707
train: epoch 22, loss 0.2547401487827301, acc=0.9144999980926514, loss=0.2547401487827301
test: epoch 22, loss 2.7375893592834473, acc=0.3444444537162781, loss=2.7375893592834473
train: epoch 23, loss 0.24463459849357605, acc=0.9157222509384155, loss=0.24463459849357605
test: epoch 23, loss 3.507127046585083, acc=0.25, loss=3.507127046585083
train: epoch 24, loss 0.23242025077342987, acc=0.9239444732666016, loss=0.23242025077342987
test: epoch 24, loss 3.330012321472168, acc=0.28333333134651184, loss=3.330012321472168
train: epoch 25, loss 0.2395814210176468, acc=0.9198889136314392, loss=0.2395814210176468
test: epoch 25, loss 2.791346549987793, acc=0.31388887763023376, loss=2.791346549987793
train: epoch 26, loss 0.20271281898021698, acc=0.9333333373069763, loss=0.20271281898021698
test: epoch 26, loss 3.204094409942627, acc=0.2944444417953491, loss=3.204094409942627
train: epoch 27, loss 0.20220401883125305, acc=0.9308333396911621, loss=0.20220401883125305
test: epoch 27, loss 3.7133970260620117, acc=0.2666666805744171, loss=3.7133970260620117
train: epoch 28, loss 0.20752540230751038, acc=0.9319999814033508, loss=0.20752540230751038
test: epoch 28, loss 3.5774753093719482, acc=0.2888889014720917, loss=3.5774753093719482
train: epoch 29, loss 0.21568959951400757, acc=0.9321666955947876, loss=0.21568959951400757
test: epoch 29, loss 2.8485634326934814, acc=0.3027777671813965, loss=2.8485634326934814
train: epoch 30, loss 0.1912766546010971, acc=0.9363889098167419, loss=0.1912766546010971
test: epoch 30, loss 2.6316092014312744, acc=0.3472222089767456, loss=2.6316092014312744
train: epoch 31, loss 0.17890042066574097, acc=0.9405555725097656, loss=0.17890042066574097
test: epoch 31, loss 2.6445188522338867, acc=0.3194444477558136, loss=2.6445188522338867
train: epoch 32, loss 0.1682933270931244, acc=0.9459999799728394, loss=0.1682933270931244
test: epoch 32, loss 2.7242729663848877, acc=0.3083333373069763, loss=2.7242729663848877
train: epoch 33, loss 0.17488887906074524, acc=0.9418888688087463, loss=0.17488887906074524
test: epoch 33, loss 2.676846742630005, acc=0.32777777314186096, loss=2.676846742630005
train: epoch 34, loss 0.16625873744487762, acc=0.9452221989631653, loss=0.16625873744487762
test: epoch 34, loss 2.6879236698150635, acc=0.3638888895511627, loss=2.6879236698150635
train: epoch 35, loss 0.1652897298336029, acc=0.9465555548667908, loss=0.1652897298336029
test: epoch 35, loss 3.0101828575134277, acc=0.30000001192092896, loss=3.0101828575134277
train: epoch 36, loss 0.15784379839897156, acc=0.9480000138282776, loss=0.15784379839897156
test: epoch 36, loss 1.9138323068618774, acc=0.4027777910232544, loss=1.9138323068618774
train: epoch 37, loss 0.14041563868522644, acc=0.95333331823349, loss=0.14041563868522644
test: epoch 37, loss 2.4028854370117188, acc=0.4027777910232544, loss=2.4028854370117188
train: epoch 38, loss 0.14808149635791779, acc=0.9526666402816772, loss=0.14808149635791779
test: epoch 38, loss 2.8217034339904785, acc=0.4138889014720917, loss=2.8217034339904785
train: epoch 39, loss 0.14703494310379028, acc=0.9511666893959045, loss=0.14703494310379028
test: epoch 39, loss 2.621983528137207, acc=0.40833333134651184, loss=2.621983528137207
train: epoch 40, loss 0.13646678626537323, acc=0.9556111097335815, loss=0.13646678626537323
test: epoch 40, loss 2.7414684295654297, acc=0.3305555582046509, loss=2.7414684295654297
train: epoch 41, loss 0.13773277401924133, acc=0.9558333158493042, loss=0.13773277401924133
test: epoch 41, loss 2.7722761631011963, acc=0.3583333194255829, loss=2.7722761631011963
train: epoch 42, loss 0.1321818232536316, acc=0.9557777643203735, loss=0.1321818232536316
test: epoch 42, loss 2.797626495361328, acc=0.38055557012557983, loss=2.797626495361328
train: epoch 43, loss 0.13965868949890137, acc=0.9556666612625122, loss=0.13965868949890137
test: epoch 43, loss 3.051496744155884, acc=0.3722222149372101, loss=3.051496744155884
train: epoch 44, loss 0.13682913780212402, acc=0.9550555348396301, loss=0.13682913780212402
test: epoch 44, loss 2.367950439453125, acc=0.4138889014720917, loss=2.367950439453125
train: epoch 45, loss 0.11124347150325775, acc=0.9654444456100464, loss=0.11124347150325775
test: epoch 45, loss 2.944690465927124, acc=0.3222222328186035, loss=2.944690465927124
train: epoch 46, loss 0.13061988353729248, acc=0.9591110944747925, loss=0.13061988353729248
test: epoch 46, loss 2.3691093921661377, acc=0.3361110985279083, loss=2.3691093921661377
train: epoch 47, loss 0.11551973968744278, acc=0.9616666436195374, loss=0.11551973968744278
test: epoch 47, loss 2.765817403793335, acc=0.32777777314186096, loss=2.765817403793335
train: epoch 48, loss 0.11168774962425232, acc=0.9649999737739563, loss=0.11168774962425232
test: epoch 48, loss 3.3024332523345947, acc=0.3222222328186035, loss=3.3024332523345947
train: epoch 49, loss 0.10459389537572861, acc=0.9665555357933044, loss=0.10459389537572861
test: epoch 49, loss 2.9609925746917725, acc=0.3583333194255829, loss=2.9609925746917725
train: epoch 50, loss 0.12620167434215546, acc=0.9589444398880005, loss=0.12620167434215546
test: epoch 50, loss 2.5818305015563965, acc=0.3916666805744171, loss=2.5818305015563965
train: epoch 51, loss 0.10178039222955704, acc=0.965833306312561, loss=0.10178039222955704
test: epoch 51, loss 2.975855827331543, acc=0.3472222089767456, loss=2.975855827331543
train: epoch 52, loss 0.09752998501062393, acc=0.9681666493415833, loss=0.09752998501062393
test: epoch 52, loss 3.2982993125915527, acc=0.3888888955116272, loss=3.2982993125915527
train: epoch 53, loss 0.11136386543512344, acc=0.9640555381774902, loss=0.11136386543512344
test: epoch 53, loss 2.5280020236968994, acc=0.39444443583488464, loss=2.5280020236968994
train: epoch 54, loss 0.10079443454742432, acc=0.9679444432258606, loss=0.10079443454742432
test: epoch 54, loss 2.5589566230773926, acc=0.3722222149372101, loss=2.5589566230773926
train: epoch 55, loss 0.10398881137371063, acc=0.9673333168029785, loss=0.10398881137371063
test: epoch 55, loss 2.787043333053589, acc=0.4055555462837219, loss=2.787043333053589
train: epoch 56, loss 0.09995065629482269, acc=0.9668889045715332, loss=0.09995065629482269
test: epoch 56, loss 2.574577808380127, acc=0.43888887763023376, loss=2.574577808380127
train: epoch 57, loss 0.10108942538499832, acc=0.9660555720329285, loss=0.10108942538499832
test: epoch 57, loss 2.8808951377868652, acc=0.42500001192092896, loss=2.8808951377868652
train: epoch 58, loss 0.09375084191560745, acc=0.9696666598320007, loss=0.09375084191560745
test: epoch 58, loss 2.2742652893066406, acc=0.46666666865348816, loss=2.2742652893066406
train: epoch 59, loss 0.0976305827498436, acc=0.9693333506584167, loss=0.0976305827498436
test: epoch 59, loss 2.696033000946045, acc=0.41111111640930176, loss=2.696033000946045
train: epoch 60, loss 0.10382314771413803, acc=0.9672777652740479, loss=0.10382314771413803
test: epoch 60, loss 2.906506061553955, acc=0.3305555582046509, loss=2.906506061553955
train: epoch 61, loss 0.09867004305124283, acc=0.9679444432258606, loss=0.09867004305124283
test: epoch 61, loss 3.2058093547821045, acc=0.3444444537162781, loss=3.2058093547821045
train: epoch 62, loss 0.08345858752727509, acc=0.9724444150924683, loss=0.08345858752727509
test: epoch 62, loss 2.9217092990875244, acc=0.4166666567325592, loss=2.9217092990875244
train: epoch 63, loss 0.0901070162653923, acc=0.9717777967453003, loss=0.0901070162653923
test: epoch 63, loss 3.179128885269165, acc=0.42500001192092896, loss=3.179128885269165
train: epoch 64, loss 0.08495326340198517, acc=0.972777783870697, loss=0.08495326340198517
test: epoch 64, loss 2.7519876956939697, acc=0.42500001192092896, loss=2.7519876956939697
train: epoch 65, loss 0.08975672721862793, acc=0.9709444642066956, loss=0.08975672721862793
test: epoch 65, loss 2.1597540378570557, acc=0.38055557012557983, loss=2.1597540378570557
train: epoch 66, loss 0.07946903258562088, acc=0.9758889079093933, loss=0.07946903258562088
test: epoch 66, loss 3.2611701488494873, acc=0.4027777910232544, loss=3.2611701488494873
train: epoch 67, loss 0.08728224784135818, acc=0.9736111164093018, loss=0.08728224784135818
test: epoch 67, loss 2.4369893074035645, acc=0.4555555582046509, loss=2.4369893074035645
train: epoch 68, loss 0.07669409364461899, acc=0.976111114025116, loss=0.07669409364461899
test: epoch 68, loss 2.429872751235962, acc=0.4000000059604645, loss=2.429872751235962
train: epoch 69, loss 0.08222924172878265, acc=0.975777804851532, loss=0.08222924172878265
test: epoch 69, loss 3.1789286136627197, acc=0.31111112236976624, loss=3.1789286136627197
train: epoch 70, loss 0.0882086530327797, acc=0.9741111397743225, loss=0.0882086530327797
test: epoch 70, loss 2.5497682094573975, acc=0.39444443583488464, loss=2.5497682094573975
train: epoch 71, loss 0.07287740707397461, acc=0.9787222146987915, loss=0.07287740707397461
test: epoch 71, loss 2.4959170818328857, acc=0.40833333134651184, loss=2.4959170818328857
train: epoch 72, loss 0.07953561097383499, acc=0.9756110906600952, loss=0.07953561097383499
test: epoch 72, loss 3.0335023403167725, acc=0.36944442987442017, loss=3.0335023403167725
train: epoch 73, loss 0.07913026213645935, acc=0.9757221937179565, loss=0.07913026213645935
test: epoch 73, loss 3.3766977787017822, acc=0.3777777850627899, loss=3.3766977787017822
train: epoch 74, loss 0.07709456980228424, acc=0.9762222170829773, loss=0.07709456980228424
test: epoch 74, loss 2.7854392528533936, acc=0.41111111640930176, loss=2.7854392528533936
train: epoch 75, loss 0.0768759697675705, acc=0.9763333201408386, loss=0.0768759697675705
test: epoch 75, loss 2.6655828952789307, acc=0.39444443583488464, loss=2.6655828952789307
train: epoch 76, loss 0.07176525145769119, acc=0.9783333539962769, loss=0.07176525145769119
test: epoch 76, loss 2.8558411598205566, acc=0.4333333373069763, loss=2.8558411598205566
train: epoch 77, loss 0.06448698043823242, acc=0.979888916015625, loss=0.06448698043823242
test: epoch 77, loss 4.101555824279785, acc=0.3444444537162781, loss=4.101555824279785
train: epoch 78, loss 0.08168599754571915, acc=0.9747222065925598, loss=0.08168599754571915
test: epoch 78, loss 3.316797971725464, acc=0.3888888955116272, loss=3.316797971725464
train: epoch 79, loss 0.061347637325525284, acc=0.9812222123146057, loss=0.061347637325525284
test: epoch 79, loss 3.283860445022583, acc=0.38333332538604736, loss=3.283860445022583
train: epoch 80, loss 0.06739414483308792, acc=0.9781666398048401, loss=0.06739414483308792
test: epoch 80, loss 2.8794426918029785, acc=0.3638888895511627, loss=2.8794426918029785
train: epoch 81, loss 0.07132408022880554, acc=0.980555534362793, loss=0.07132408022880554
test: epoch 81, loss 2.791149139404297, acc=0.4138889014720917, loss=2.791149139404297
train: epoch 82, loss 0.05617141351103783, acc=0.9822777509689331, loss=0.05617141351103783
test: epoch 82, loss 2.9236531257629395, acc=0.40833333134651184, loss=2.9236531257629395
train: epoch 83, loss 0.0685371682047844, acc=0.9804444313049316, loss=0.0685371682047844
test: epoch 83, loss 2.5255138874053955, acc=0.45277777314186096, loss=2.5255138874053955
train: epoch 84, loss 0.07001809775829315, acc=0.9794999957084656, loss=0.07001809775829315
test: epoch 84, loss 3.218644380569458, acc=0.43888887763023376, loss=3.218644380569458
train: epoch 85, loss 0.06124122440814972, acc=0.9823333621025085, loss=0.06124122440814972
test: epoch 85, loss 2.808931827545166, acc=0.47777777910232544, loss=2.808931827545166
train: epoch 86, loss 0.07149766385555267, acc=0.9794999957084656, loss=0.07149766385555267
test: epoch 86, loss 2.193154811859131, acc=0.3777777850627899, loss=2.193154811859131
train: epoch 87, loss 0.07594379037618637, acc=0.9773333072662354, loss=0.07594379037618637
test: epoch 87, loss 2.647585391998291, acc=0.38055557012557983, loss=2.647585391998291
train: epoch 88, loss 0.06665224581956863, acc=0.9791666865348816, loss=0.06665224581956863
test: epoch 88, loss 2.848004102706909, acc=0.49166667461395264, loss=2.848004102706909
train: epoch 89, loss 0.04671106114983559, acc=0.9867777824401855, loss=0.04671106114983559
test: epoch 89, loss 2.410987377166748, acc=0.4472222328186035, loss=2.410987377166748
train: epoch 90, loss 0.05707443132996559, acc=0.9819444417953491, loss=0.05707443132996559
test: epoch 90, loss 3.1705915927886963, acc=0.4277777671813965, loss=3.1705915927886963
train: epoch 91, loss 0.07240914553403854, acc=0.9782778024673462, loss=0.07240914553403854
test: epoch 91, loss 2.6910393238067627, acc=0.4416666626930237, loss=2.6910393238067627
train: epoch 92, loss 0.06845911592245102, acc=0.9803333282470703, loss=0.06845911592245102
test: epoch 92, loss 3.1233718395233154, acc=0.3611111044883728, loss=3.1233718395233154
train: epoch 93, loss 0.04992750287055969, acc=0.9854999780654907, loss=0.04992750287055969
test: epoch 93, loss 2.6518986225128174, acc=0.4472222328186035, loss=2.6518986225128174
train: epoch 94, loss 0.05226471647620201, acc=0.984333336353302, loss=0.05226471647620201
test: epoch 94, loss 2.7469851970672607, acc=0.3916666805744171, loss=2.7469851970672607
train: epoch 95, loss 0.059986162930727005, acc=0.9825000166893005, loss=0.059986162930727005
test: epoch 95, loss 2.912461042404175, acc=0.42500001192092896, loss=2.912461042404175
train: epoch 96, loss 0.054794661700725555, acc=0.9840555787086487, loss=0.054794661700725555
test: epoch 96, loss 2.897554636001587, acc=0.4472222328186035, loss=2.897554636001587
train: epoch 97, loss 0.05889702960848808, acc=0.9826666712760925, loss=0.05889702960848808
test: epoch 97, loss 3.3353896141052246, acc=0.4611110985279083, loss=3.3353896141052246
train: epoch 98, loss 0.05508905649185181, acc=0.984000027179718, loss=0.05508905649185181
test: epoch 98, loss 2.2865774631500244, acc=0.43888887763023376, loss=2.2865774631500244
train: epoch 99, loss 0.051325250416994095, acc=0.9854444265365601, loss=0.051325250416994095
test: epoch 99, loss 3.6581082344055176, acc=0.4138889014720917, loss=3.6581082344055176
train: epoch 100, loss 0.055555034428834915, acc=0.9828333258628845, loss=0.055555034428834915
test: epoch 100, loss 3.1949756145477295, acc=0.36944442987442017, loss=3.1949756145477295
train: epoch 101, loss 0.06078299507498741, acc=0.981166660785675, loss=0.06078299507498741
test: epoch 101, loss 3.0707573890686035, acc=0.42222222685813904, loss=3.0707573890686035
train: epoch 102, loss 0.055087391287088394, acc=0.9833333492279053, loss=0.055087391287088394
test: epoch 102, loss 3.1217265129089355, acc=0.43611112236976624, loss=3.1217265129089355
train: epoch 103, loss 0.058070115745067596, acc=0.9839444160461426, loss=0.058070115745067596
test: epoch 103, loss 2.7143683433532715, acc=0.45277777314186096, loss=2.7143683433532715
train: epoch 104, loss 0.04613799974322319, acc=0.9867777824401855, loss=0.04613799974322319
test: epoch 104, loss 3.001269578933716, acc=0.45277777314186096, loss=3.001269578933716
train: epoch 105, loss 0.05816510319709778, acc=0.9822221994400024, loss=0.05816510319709778
test: epoch 105, loss 3.86653208732605, acc=0.4305555522441864, loss=3.86653208732605
train: epoch 106, loss 0.05915742367506027, acc=0.9812222123146057, loss=0.05915742367506027
test: epoch 106, loss 3.262479066848755, acc=0.4472222328186035, loss=3.262479066848755
train: epoch 107, loss 0.0447203703224659, acc=0.987666666507721, loss=0.0447203703224659
test: epoch 107, loss 3.0117573738098145, acc=0.4416666626930237, loss=3.0117573738098145
train: epoch 108, loss 0.04742085188627243, acc=0.9863333106040955, loss=0.04742085188627243
test: epoch 108, loss 3.262880563735962, acc=0.4749999940395355, loss=3.262880563735962
train: epoch 109, loss 0.06201774999499321, acc=0.9818333387374878, loss=0.06201774999499321
test: epoch 109, loss 2.7201454639434814, acc=0.5027777552604675, loss=2.7201454639434814
train: epoch 110, loss 0.046178240329027176, acc=0.9871110916137695, loss=0.046178240329027176
test: epoch 110, loss 3.23687744140625, acc=0.4444444477558136, loss=3.23687744140625
train: epoch 111, loss 0.0499316081404686, acc=0.9846110939979553, loss=0.0499316081404686
test: epoch 111, loss 3.0605320930480957, acc=0.4583333432674408, loss=3.0605320930480957
train: epoch 112, loss 0.05920230597257614, acc=0.9836111068725586, loss=0.05920230597257614
test: epoch 112, loss 2.559731960296631, acc=0.5305555462837219, loss=2.559731960296631
train: epoch 113, loss 0.03959410637617111, acc=0.988444447517395, loss=0.03959410637617111
test: epoch 113, loss 3.054273843765259, acc=0.39722222089767456, loss=3.054273843765259
train: epoch 114, loss 0.05567999929189682, acc=0.9831666946411133, loss=0.05567999929189682
test: epoch 114, loss 2.9114739894866943, acc=0.4472222328186035, loss=2.9114739894866943
train: epoch 115, loss 0.04048631712794304, acc=0.9877777695655823, loss=0.04048631712794304
test: epoch 115, loss 2.899420976638794, acc=0.4583333432674408, loss=2.899420976638794
train: epoch 116, loss 0.0493728443980217, acc=0.9846110939979553, loss=0.0493728443980217
test: epoch 116, loss 3.5902316570281982, acc=0.4166666567325592, loss=3.5902316570281982
train: epoch 117, loss 0.046174321323633194, acc=0.9869999885559082, loss=0.046174321323633194
test: epoch 117, loss 2.5681190490722656, acc=0.5111111402511597, loss=2.5681190490722656
train: epoch 118, loss 0.03819090500473976, acc=0.9894444346427917, loss=0.03819090500473976
test: epoch 118, loss 2.734795093536377, acc=0.4861111044883728, loss=2.734795093536377
train: epoch 119, loss 0.05530572310090065, acc=0.984499990940094, loss=0.05530572310090065
test: epoch 119, loss 2.5697720050811768, acc=0.4138889014720917, loss=2.5697720050811768
train: epoch 120, loss 0.04944601282477379, acc=0.9854444265365601, loss=0.04944601282477379
test: epoch 120, loss 2.2775397300720215, acc=0.4722222089767456, loss=2.2775397300720215
train: epoch 121, loss 0.04231402650475502, acc=0.9870555400848389, loss=0.04231402650475502
test: epoch 121, loss 2.2093398571014404, acc=0.46666666865348816, loss=2.2093398571014404
train: epoch 122, loss 0.04389498010277748, acc=0.9871666431427002, loss=0.04389498010277748
test: epoch 122, loss 2.6662707328796387, acc=0.46388888359069824, loss=2.6662707328796387
train: epoch 123, loss 0.047352466732263565, acc=0.9865000247955322, loss=0.047352466732263565
test: epoch 123, loss 2.981654644012451, acc=0.3777777850627899, loss=2.981654644012451
train: epoch 124, loss 0.051321014761924744, acc=0.9858333468437195, loss=0.051321014761924744
test: epoch 124, loss 2.931915044784546, acc=0.46666666865348816, loss=2.931915044784546
train: epoch 125, loss 0.04735776036977768, acc=0.9872778058052063, loss=0.04735776036977768
test: epoch 125, loss 2.1233067512512207, acc=0.4694444537162781, loss=2.1233067512512207
train: epoch 126, loss 0.049800481647253036, acc=0.9859444499015808, loss=0.049800481647253036
test: epoch 126, loss 2.849199056625366, acc=0.4166666567325592, loss=2.849199056625366
train: epoch 127, loss 0.04417194798588753, acc=0.9861111044883728, loss=0.04417194798588753
test: epoch 127, loss 3.0718398094177246, acc=0.46666666865348816, loss=3.0718398094177246
train: epoch 128, loss 0.0520479790866375, acc=0.9848889112472534, loss=0.0520479790866375
test: epoch 128, loss 3.8316762447357178, acc=0.46388888359069824, loss=3.8316762447357178
train: epoch 129, loss 0.04566790908575058, acc=0.9866666793823242, loss=0.04566790908575058
test: epoch 129, loss 3.2031242847442627, acc=0.4444444477558136, loss=3.2031242847442627
train: epoch 130, loss 0.03689039126038551, acc=0.988277792930603, loss=0.03689039126038551
test: epoch 130, loss 2.7917189598083496, acc=0.4333333373069763, loss=2.7917189598083496
train: epoch 131, loss 0.04393327981233597, acc=0.9867777824401855, loss=0.04393327981233597
test: epoch 131, loss 2.63173246383667, acc=0.46388888359069824, loss=2.63173246383667
train: epoch 132, loss 0.048398979008197784, acc=0.9852777719497681, loss=0.048398979008197784
test: epoch 132, loss 2.5910422801971436, acc=0.4749999940395355, loss=2.5910422801971436
train: epoch 133, loss 0.03956379368901253, acc=0.9878333210945129, loss=0.03956379368901253
test: epoch 133, loss 3.0655338764190674, acc=0.4888888895511627, loss=3.0655338764190674
train: epoch 134, loss 0.03749941289424896, acc=0.988277792930603, loss=0.03749941289424896
test: epoch 134, loss 2.7133376598358154, acc=0.4194444417953491, loss=2.7133376598358154
train: epoch 135, loss 0.030926493927836418, acc=0.9909444451332092, loss=0.030926493927836418
test: epoch 135, loss 3.6896414756774902, acc=0.39444443583488464, loss=3.6896414756774902
train: epoch 136, loss 0.05263708904385567, acc=0.9857777953147888, loss=0.05263708904385567
test: epoch 136, loss 2.247601270675659, acc=0.4972222149372101, loss=2.247601270675659
train: epoch 137, loss 0.04386110603809357, acc=0.9872778058052063, loss=0.04386110603809357
test: epoch 137, loss 2.443894624710083, acc=0.5083333253860474, loss=2.443894624710083
train: epoch 138, loss 0.035348232835531235, acc=0.9897222518920898, loss=0.035348232835531235
test: epoch 138, loss 3.15017032623291, acc=0.46666666865348816, loss=3.15017032623291
train: epoch 139, loss 0.04308450222015381, acc=0.9871110916137695, loss=0.04308450222015381
test: epoch 139, loss 2.8897671699523926, acc=0.4472222328186035, loss=2.8897671699523926
train: epoch 140, loss 0.03845573589205742, acc=0.9884999990463257, loss=0.03845573589205742
test: epoch 140, loss 2.833400249481201, acc=0.43888887763023376, loss=2.833400249481201
train: epoch 141, loss 0.04083198681473732, acc=0.988777756690979, loss=0.04083198681473732
test: epoch 141, loss 2.748605728149414, acc=0.5361111164093018, loss=2.748605728149414
train: epoch 142, loss 0.052286166697740555, acc=0.9859444499015808, loss=0.052286166697740555
test: epoch 142, loss 2.5207748413085938, acc=0.5166666507720947, loss=2.5207748413085938
train: epoch 143, loss 0.03353027254343033, acc=0.9904999732971191, loss=0.03353027254343033
test: epoch 143, loss 2.4870657920837402, acc=0.48055556416511536, loss=2.4870657920837402
train: epoch 144, loss 0.037516120821237564, acc=0.9885555505752563, loss=0.037516120821237564
test: epoch 144, loss 2.6116580963134766, acc=0.4888888895511627, loss=2.6116580963134766
train: epoch 145, loss 0.03536844253540039, acc=0.9901111125946045, loss=0.03536844253540039
test: epoch 145, loss 2.289412260055542, acc=0.4972222149372101, loss=2.289412260055542
train: epoch 146, loss 0.03800232335925102, acc=0.988611102104187, loss=0.03800232335925102
test: epoch 146, loss 3.2851383686065674, acc=0.5, loss=3.2851383686065674
train: epoch 147, loss 0.04254544526338577, acc=0.9878888726234436, loss=0.04254544526338577
test: epoch 147, loss 3.2083449363708496, acc=0.4305555522441864, loss=3.2083449363708496
train: epoch 148, loss 0.03658796101808548, acc=0.9894999861717224, loss=0.03658796101808548
test: epoch 148, loss 2.970160722732544, acc=0.45277777314186096, loss=2.970160722732544
train: epoch 149, loss 0.041317861527204514, acc=0.9873889088630676, loss=0.041317861527204514
test: epoch 149, loss 2.3073575496673584, acc=0.5361111164093018, loss=2.3073575496673584
train: epoch 150, loss 0.04473867267370224, acc=0.9878888726234436, loss=0.04473867267370224
test: epoch 150, loss 2.7184858322143555, acc=0.5388888716697693, loss=2.7184858322143555
