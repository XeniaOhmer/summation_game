# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.99", "--one_hot=false", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1029657279, receiver_embed_dim=64, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.2289018630981445, acc=0.07088889181613922, loss=3.2289018630981445
test: epoch 1, loss 4.469344139099121, acc=0.08611111342906952, loss=4.469344139099121
train: epoch 2, loss 2.0128118991851807, acc=0.29827776551246643, loss=2.0128118991851807
test: epoch 2, loss 4.0821309089660645, acc=0.1388888955116272, loss=4.0821309089660645
train: epoch 3, loss 1.3288156986236572, acc=0.4801666736602783, loss=1.3288156986236572
test: epoch 3, loss 3.5103726387023926, acc=0.16111111640930176, loss=3.5103726387023926
train: epoch 4, loss 1.0973918437957764, acc=0.5711110830307007, loss=1.0973918437957764
test: epoch 4, loss 3.591226577758789, acc=0.17777778208255768, loss=3.591226577758789
train: epoch 5, loss 0.9515915513038635, acc=0.6352777481079102, loss=0.9515915513038635
test: epoch 5, loss 3.2729291915893555, acc=0.20277777314186096, loss=3.2729291915893555
train: epoch 6, loss 0.8381070494651794, acc=0.6867222189903259, loss=0.8381070494651794
test: epoch 6, loss 3.1473076343536377, acc=0.2222222238779068, loss=3.1473076343536377
train: epoch 7, loss 0.7670926451683044, acc=0.7178333401679993, loss=0.7670926451683044
test: epoch 7, loss 3.0486786365509033, acc=0.21388888359069824, loss=3.0486786365509033
train: epoch 8, loss 0.700587272644043, acc=0.7379444241523743, loss=0.700587272644043
test: epoch 8, loss 2.907640218734741, acc=0.21666666865348816, loss=2.907640218734741
train: epoch 9, loss 0.6335626244544983, acc=0.7661666870117188, loss=0.6335626244544983
test: epoch 9, loss 2.817141056060791, acc=0.23055554926395416, loss=2.817141056060791
train: epoch 10, loss 0.6053178310394287, acc=0.7755555510520935, loss=0.6053178310394287
test: epoch 10, loss 2.66938853263855, acc=0.23055554926395416, loss=2.66938853263855
train: epoch 11, loss 0.5785346627235413, acc=0.7905555367469788, loss=0.5785346627235413
test: epoch 11, loss 2.6567745208740234, acc=0.23888888955116272, loss=2.6567745208740234
train: epoch 12, loss 0.552351713180542, acc=0.8048333525657654, loss=0.552351713180542
test: epoch 12, loss 2.442279815673828, acc=0.2888889014720917, loss=2.442279815673828
train: epoch 13, loss 0.5294268131256104, acc=0.8110555410385132, loss=0.5294268131256104
test: epoch 13, loss 2.4833505153656006, acc=0.24444444477558136, loss=2.4833505153656006
train: epoch 14, loss 0.5031185746192932, acc=0.8165555596351624, loss=0.5031185746192932
test: epoch 14, loss 2.189148426055908, acc=0.30000001192092896, loss=2.189148426055908
train: epoch 15, loss 0.47533753514289856, acc=0.831944465637207, loss=0.47533753514289856
test: epoch 15, loss 2.227846384048462, acc=0.2916666567325592, loss=2.227846384048462
train: epoch 16, loss 0.45746728777885437, acc=0.8383333086967468, loss=0.45746728777885437
test: epoch 16, loss 2.082258462905884, acc=0.32777777314186096, loss=2.082258462905884
train: epoch 17, loss 0.452340692281723, acc=0.8420000076293945, loss=0.452340692281723
test: epoch 17, loss 2.1468100547790527, acc=0.32777777314186096, loss=2.1468100547790527
train: epoch 18, loss 0.4478108286857605, acc=0.8395000100135803, loss=0.4478108286857605
test: epoch 18, loss 2.2130396366119385, acc=0.3083333373069763, loss=2.2130396366119385
train: epoch 19, loss 0.43542927503585815, acc=0.8455555438995361, loss=0.43542927503585815
test: epoch 19, loss 2.1410489082336426, acc=0.35277777910232544, loss=2.1410489082336426
train: epoch 20, loss 0.41028067469596863, acc=0.8534444570541382, loss=0.41028067469596863
test: epoch 20, loss 1.888869285583496, acc=0.3583333194255829, loss=1.888869285583496
train: epoch 21, loss 0.3921169936656952, acc=0.8646666407585144, loss=0.3921169936656952
test: epoch 21, loss 1.9537239074707031, acc=0.3499999940395355, loss=1.9537239074707031
train: epoch 22, loss 0.39845120906829834, acc=0.8601111173629761, loss=0.39845120906829834
test: epoch 22, loss 1.8167827129364014, acc=0.38055557012557983, loss=1.8167827129364014
train: epoch 23, loss 0.38607802987098694, acc=0.8662222027778625, loss=0.38607802987098694
test: epoch 23, loss 1.7758463621139526, acc=0.39444443583488464, loss=1.7758463621139526
train: epoch 24, loss 0.3713369369506836, acc=0.8665000200271606, loss=0.3713369369506836
test: epoch 24, loss 1.8943151235580444, acc=0.36944442987442017, loss=1.8943151235580444
train: epoch 25, loss 0.35746315121650696, acc=0.8759444355964661, loss=0.35746315121650696
test: epoch 25, loss 1.8368730545043945, acc=0.38333332538604736, loss=1.8368730545043945
train: epoch 26, loss 0.36583638191223145, acc=0.8765555620193481, loss=0.36583638191223145
test: epoch 26, loss 1.9679415225982666, acc=0.3499999940395355, loss=1.9679415225982666
train: epoch 27, loss 0.3490680754184723, acc=0.878166675567627, loss=0.3490680754184723
test: epoch 27, loss 1.80894136428833, acc=0.375, loss=1.80894136428833
train: epoch 28, loss 0.3518671989440918, acc=0.8818888664245605, loss=0.3518671989440918
test: epoch 28, loss 1.8243064880371094, acc=0.36944442987442017, loss=1.8243064880371094
train: epoch 29, loss 0.35650795698165894, acc=0.8801110982894897, loss=0.35650795698165894
test: epoch 29, loss 1.8172879219055176, acc=0.3888888955116272, loss=1.8172879219055176
train: epoch 30, loss 0.3386828601360321, acc=0.8845000267028809, loss=0.3386828601360321
test: epoch 30, loss 1.6151255369186401, acc=0.43888887763023376, loss=1.6151255369186401
train: epoch 31, loss 0.3384203016757965, acc=0.8829444646835327, loss=0.3384203016757965
test: epoch 31, loss 1.6279598474502563, acc=0.43611112236976624, loss=1.6279598474502563
train: epoch 32, loss 0.34760352969169617, acc=0.8848888874053955, loss=0.34760352969169617
test: epoch 32, loss 1.7749760150909424, acc=0.4027777910232544, loss=1.7749760150909424
train: epoch 33, loss 0.3292014002799988, acc=0.8900555372238159, loss=0.3292014002799988
test: epoch 33, loss 1.8433732986450195, acc=0.3722222149372101, loss=1.8433732986450195
train: epoch 34, loss 0.31240299344062805, acc=0.8910555839538574, loss=0.31240299344062805
test: epoch 34, loss 1.6610623598098755, acc=0.42500001192092896, loss=1.6610623598098755
train: epoch 35, loss 0.31553661823272705, acc=0.8942777514457703, loss=0.31553661823272705
test: epoch 35, loss 1.7344639301300049, acc=0.36944442987442017, loss=1.7344639301300049
train: epoch 36, loss 0.32233405113220215, acc=0.8931666612625122, loss=0.32233405113220215
test: epoch 36, loss 1.6912245750427246, acc=0.42222222685813904, loss=1.6912245750427246
train: epoch 37, loss 0.2986159324645996, acc=0.8987777829170227, loss=0.2986159324645996
test: epoch 37, loss 1.4153010845184326, acc=0.4472222328186035, loss=1.4153010845184326
train: epoch 38, loss 0.29263436794281006, acc=0.9051111340522766, loss=0.29263436794281006
test: epoch 38, loss 1.5614317655563354, acc=0.4833333194255829, loss=1.5614317655563354
train: epoch 39, loss 0.295987993478775, acc=0.9037222266197205, loss=0.295987993478775
test: epoch 39, loss 1.7629257440567017, acc=0.44999998807907104, loss=1.7629257440567017
train: epoch 40, loss 0.2834588587284088, acc=0.9070000052452087, loss=0.2834588587284088
test: epoch 40, loss 1.6920000314712524, acc=0.41111111640930176, loss=1.6920000314712524
train: epoch 41, loss 0.2872805595397949, acc=0.9040555357933044, loss=0.2872805595397949
test: epoch 41, loss 1.7709754705429077, acc=0.3916666805744171, loss=1.7709754705429077
train: epoch 42, loss 0.28184834122657776, acc=0.9055555462837219, loss=0.28184834122657776
test: epoch 42, loss 1.6197890043258667, acc=0.46666666865348816, loss=1.6197890043258667
train: epoch 43, loss 0.2845781445503235, acc=0.9017778038978577, loss=0.2845781445503235
test: epoch 43, loss 1.7410061359405518, acc=0.4305555522441864, loss=1.7410061359405518
train: epoch 44, loss 0.28026083111763, acc=0.9068333506584167, loss=0.28026083111763
test: epoch 44, loss 1.6564586162567139, acc=0.4888888895511627, loss=1.6564586162567139
train: epoch 45, loss 0.26989734172821045, acc=0.9091110825538635, loss=0.26989734172821045
test: epoch 45, loss 1.4598177671432495, acc=0.4722222089767456, loss=1.4598177671432495
train: epoch 46, loss 0.2805509865283966, acc=0.9098888635635376, loss=0.2805509865283966
test: epoch 46, loss 1.4777352809906006, acc=0.4611110985279083, loss=1.4777352809906006
train: epoch 47, loss 0.2742636203765869, acc=0.9095555543899536, loss=0.2742636203765869
test: epoch 47, loss 1.468849778175354, acc=0.4722222089767456, loss=1.468849778175354
train: epoch 48, loss 0.2721504867076874, acc=0.9076111316680908, loss=0.2721504867076874
test: epoch 48, loss 1.443723201751709, acc=0.4611110985279083, loss=1.443723201751709
train: epoch 49, loss 0.2894512712955475, acc=0.9032222032546997, loss=0.2894512712955475
test: epoch 49, loss 1.4477574825286865, acc=0.49444442987442017, loss=1.4477574825286865
train: epoch 50, loss 0.2655554711818695, acc=0.9084444642066956, loss=0.2655554711818695
test: epoch 50, loss 1.2922590970993042, acc=0.4888888895511627, loss=1.2922590970993042
train: epoch 51, loss 0.26574650406837463, acc=0.9109444618225098, loss=0.26574650406837463
test: epoch 51, loss 1.4474254846572876, acc=0.4722222089767456, loss=1.4474254846572876
train: epoch 52, loss 0.2672181725502014, acc=0.9108333587646484, loss=0.2672181725502014
test: epoch 52, loss 1.4398192167282104, acc=0.5138888955116272, loss=1.4398192167282104
train: epoch 53, loss 0.273876428604126, acc=0.9075000286102295, loss=0.273876428604126
test: epoch 53, loss 1.4434702396392822, acc=0.47777777910232544, loss=1.4434702396392822
train: epoch 54, loss 0.2668423056602478, acc=0.9097777605056763, loss=0.2668423056602478
test: epoch 54, loss 1.3051178455352783, acc=0.5, loss=1.3051178455352783
train: epoch 55, loss 0.25550350546836853, acc=0.9158889055252075, loss=0.25550350546836853
test: epoch 55, loss 1.2393361330032349, acc=0.5249999761581421, loss=1.2393361330032349
train: epoch 56, loss 0.2650318145751953, acc=0.9120000004768372, loss=0.2650318145751953
test: epoch 56, loss 1.3130943775177002, acc=0.5, loss=1.3130943775177002
train: epoch 57, loss 0.26395323872566223, acc=0.9083889126777649, loss=0.26395323872566223
test: epoch 57, loss 1.2522926330566406, acc=0.5138888955116272, loss=1.2522926330566406
train: epoch 58, loss 0.26863184571266174, acc=0.9084444642066956, loss=0.26863184571266174
test: epoch 58, loss 1.3320199251174927, acc=0.5055555701255798, loss=1.3320199251174927
train: epoch 59, loss 0.2485891729593277, acc=0.9162777662277222, loss=0.2485891729593277
test: epoch 59, loss 1.1401370763778687, acc=0.5333333611488342, loss=1.1401370763778687
train: epoch 60, loss 0.25065600872039795, acc=0.9122777581214905, loss=0.25065600872039795
test: epoch 60, loss 1.2625318765640259, acc=0.5305555462837219, loss=1.2625318765640259
train: epoch 61, loss 0.25778868794441223, acc=0.9136666655540466, loss=0.25778868794441223
test: epoch 61, loss 1.258083701133728, acc=0.5222222208976746, loss=1.258083701133728
train: epoch 62, loss 0.2570366859436035, acc=0.9108889102935791, loss=0.2570366859436035
test: epoch 62, loss 1.3779536485671997, acc=0.5277777910232544, loss=1.3779536485671997
train: epoch 63, loss 0.24410860240459442, acc=0.9141111373901367, loss=0.24410860240459442
test: epoch 63, loss 1.1788362264633179, acc=0.5666666626930237, loss=1.1788362264633179
train: epoch 64, loss 0.24724997580051422, acc=0.9166111350059509, loss=0.24724997580051422
test: epoch 64, loss 1.2682381868362427, acc=0.5361111164093018, loss=1.2682381868362427
train: epoch 65, loss 0.2495325356721878, acc=0.9133333563804626, loss=0.2495325356721878
test: epoch 65, loss 1.1557180881500244, acc=0.5694444179534912, loss=1.1557180881500244
train: epoch 66, loss 0.26003989577293396, acc=0.9112222194671631, loss=0.26003989577293396
test: epoch 66, loss 1.1664377450942993, acc=0.5944444537162781, loss=1.1664377450942993
train: epoch 67, loss 0.245433509349823, acc=0.9171666502952576, loss=0.245433509349823
test: epoch 67, loss 1.2573573589324951, acc=0.5777778029441833, loss=1.2573573589324951
train: epoch 68, loss 0.2510850429534912, acc=0.9168888926506042, loss=0.2510850429534912
test: epoch 68, loss 1.0760831832885742, acc=0.5777778029441833, loss=1.0760831832885742
train: epoch 69, loss 0.2505939304828644, acc=0.9153333306312561, loss=0.2505939304828644
test: epoch 69, loss 1.1638151407241821, acc=0.5888888835906982, loss=1.1638151407241821
train: epoch 70, loss 0.2415679395198822, acc=0.9161111116409302, loss=0.2415679395198822
test: epoch 70, loss 1.312650442123413, acc=0.5694444179534912, loss=1.312650442123413
train: epoch 71, loss 0.25465327501296997, acc=0.9121666550636292, loss=0.25465327501296997
test: epoch 71, loss 1.177917718887329, acc=0.5916666388511658, loss=1.177917718887329
train: epoch 72, loss 0.2527030408382416, acc=0.9115555286407471, loss=0.2527030408382416
test: epoch 72, loss 1.1293431520462036, acc=0.5944444537162781, loss=1.1293431520462036
train: epoch 73, loss 0.23974065482616425, acc=0.9176111221313477, loss=0.23974065482616425
test: epoch 73, loss 1.1770967245101929, acc=0.6111111044883728, loss=1.1770967245101929
train: epoch 74, loss 0.23390477895736694, acc=0.9203333258628845, loss=0.23390477895736694
test: epoch 74, loss 1.038074016571045, acc=0.5638889074325562, loss=1.038074016571045
train: epoch 75, loss 0.24222368001937866, acc=0.9160000085830688, loss=0.24222368001937866
test: epoch 75, loss 1.1137577295303345, acc=0.6000000238418579, loss=1.1137577295303345
train: epoch 76, loss 0.24255704879760742, acc=0.9120000004768372, loss=0.24255704879760742
test: epoch 76, loss 1.0473215579986572, acc=0.6277777552604675, loss=1.0473215579986572
train: epoch 77, loss 0.24054470658302307, acc=0.9148889183998108, loss=0.24054470658302307
test: epoch 77, loss 0.9544041156768799, acc=0.6194444298744202, loss=0.9544041156768799
train: epoch 78, loss 0.24785900115966797, acc=0.9141111373901367, loss=0.24785900115966797
test: epoch 78, loss 1.1530004739761353, acc=0.6027777791023254, loss=1.1530004739761353
train: epoch 79, loss 0.22204835712909698, acc=0.9208333492279053, loss=0.22204835712909698
test: epoch 79, loss 0.9810199737548828, acc=0.6222222447395325, loss=0.9810199737548828
train: epoch 80, loss 0.23323538899421692, acc=0.9169999957084656, loss=0.23323538899421692
test: epoch 80, loss 1.1196966171264648, acc=0.6000000238418579, loss=1.1196966171264648
train: epoch 81, loss 0.23690000176429749, acc=0.9157778024673462, loss=0.23690000176429749
test: epoch 81, loss 0.861945390701294, acc=0.6666666865348816, loss=0.861945390701294
train: epoch 82, loss 0.23142048716545105, acc=0.9196110963821411, loss=0.23142048716545105
test: epoch 82, loss 1.0076380968093872, acc=0.6416666507720947, loss=1.0076380968093872
train: epoch 83, loss 0.22923173010349274, acc=0.9211666584014893, loss=0.22923173010349274
test: epoch 83, loss 0.9115873575210571, acc=0.6833333373069763, loss=0.9115873575210571
train: epoch 84, loss 0.22231771051883698, acc=0.921500027179718, loss=0.22231771051883698
test: epoch 84, loss 0.8044106364250183, acc=0.6611111164093018, loss=0.8044106364250183
train: epoch 85, loss 0.2358890175819397, acc=0.9179444313049316, loss=0.2358890175819397
test: epoch 85, loss 0.9546136260032654, acc=0.6333333253860474, loss=0.9546136260032654
train: epoch 86, loss 0.23491041362285614, acc=0.9195555448532104, loss=0.23491041362285614
test: epoch 86, loss 0.9254370927810669, acc=0.699999988079071, loss=0.9254370927810669
train: epoch 87, loss 0.21866752207279205, acc=0.9201111197471619, loss=0.21866752207279205
test: epoch 87, loss 0.8683112263679504, acc=0.6666666865348816, loss=0.8683112263679504
train: epoch 88, loss 0.2299032360315323, acc=0.9201666712760925, loss=0.2299032360315323
test: epoch 88, loss 0.8654066324234009, acc=0.6527777910232544, loss=0.8654066324234009
train: epoch 89, loss 0.2327645868062973, acc=0.918055534362793, loss=0.2327645868062973
test: epoch 89, loss 0.7935230135917664, acc=0.6888889074325562, loss=0.7935230135917664
train: epoch 90, loss 0.23207220435142517, acc=0.9160000085830688, loss=0.23207220435142517
test: epoch 90, loss 0.9069529175758362, acc=0.6833333373069763, loss=0.9069529175758362
train: epoch 91, loss 0.2206401228904724, acc=0.9227777719497681, loss=0.2206401228904724
test: epoch 91, loss 0.8896642327308655, acc=0.6833333373069763, loss=0.8896642327308655
train: epoch 92, loss 0.2199070304632187, acc=0.9194999933242798, loss=0.2199070304632187
test: epoch 92, loss 0.7698186635971069, acc=0.699999988079071, loss=0.7698186635971069
train: epoch 93, loss 0.22805729508399963, acc=0.9216111302375793, loss=0.22805729508399963
test: epoch 93, loss 0.7353911399841309, acc=0.730555534362793, loss=0.7353911399841309
train: epoch 94, loss 0.232330784201622, acc=0.918055534362793, loss=0.232330784201622
test: epoch 94, loss 0.7905042767524719, acc=0.699999988079071, loss=0.7905042767524719
train: epoch 95, loss 0.21690785884857178, acc=0.9225555658340454, loss=0.21690785884857178
test: epoch 95, loss 0.8667658567428589, acc=0.7083333134651184, loss=0.8667658567428589
train: epoch 96, loss 0.22206318378448486, acc=0.9210000038146973, loss=0.22206318378448486
test: epoch 96, loss 0.7460591197013855, acc=0.730555534362793, loss=0.7460591197013855
train: epoch 97, loss 0.2159598022699356, acc=0.9206110835075378, loss=0.2159598022699356
test: epoch 97, loss 0.7015760540962219, acc=0.7416666746139526, loss=0.7015760540962219
train: epoch 98, loss 0.21528683602809906, acc=0.9208889007568359, loss=0.21528683602809906
test: epoch 98, loss 0.7338218092918396, acc=0.7611111402511597, loss=0.7338218092918396
train: epoch 99, loss 0.22811515629291534, acc=0.9175000190734863, loss=0.22811515629291534
test: epoch 99, loss 0.6922261118888855, acc=0.7138888835906982, loss=0.6922261118888855
train: epoch 100, loss 0.21904049813747406, acc=0.9220555424690247, loss=0.21904049813747406
test: epoch 100, loss 0.6121054887771606, acc=0.7611111402511597, loss=0.6121054887771606
train: epoch 101, loss 0.20985785126686096, acc=0.9214444160461426, loss=0.20985785126686096
test: epoch 101, loss 0.605173647403717, acc=0.7611111402511597, loss=0.605173647403717
train: epoch 102, loss 0.2250720113515854, acc=0.9246110916137695, loss=0.2250720113515854
test: epoch 102, loss 0.687512218952179, acc=0.7638888955116272, loss=0.687512218952179
train: epoch 103, loss 0.2106393426656723, acc=0.9208889007568359, loss=0.2106393426656723
test: epoch 103, loss 0.6529887318611145, acc=0.7583333253860474, loss=0.6529887318611145
train: epoch 104, loss 0.2195834070444107, acc=0.9226111173629761, loss=0.2195834070444107
test: epoch 104, loss 0.6388318538665771, acc=0.7666666507720947, loss=0.6388318538665771
train: epoch 105, loss 0.19739271700382233, acc=0.9287222027778625, loss=0.19739271700382233
test: epoch 105, loss 0.6432466506958008, acc=0.7805555462837219, loss=0.6432466506958008
train: epoch 106, loss 0.20153972506523132, acc=0.9244999885559082, loss=0.20153972506523132
test: epoch 106, loss 0.6599661111831665, acc=0.7611111402511597, loss=0.6599661111831665
train: epoch 107, loss 0.1898680478334427, acc=0.9300000071525574, loss=0.1898680478334427
test: epoch 107, loss 0.6196098327636719, acc=0.7805555462837219, loss=0.6196098327636719
train: epoch 108, loss 0.19497142732143402, acc=0.9274444580078125, loss=0.19497142732143402
test: epoch 108, loss 0.6553525328636169, acc=0.730555534362793, loss=0.6553525328636169
train: epoch 109, loss 0.2052110880613327, acc=0.9278888702392578, loss=0.2052110880613327
test: epoch 109, loss 0.6316632628440857, acc=0.7638888955116272, loss=0.6316632628440857
train: epoch 110, loss 0.18497367203235626, acc=0.9316111207008362, loss=0.18497367203235626
test: epoch 110, loss 0.7696611285209656, acc=0.7638888955116272, loss=0.7696611285209656
train: epoch 111, loss 0.18557634949684143, acc=0.9323333501815796, loss=0.18557634949684143
test: epoch 111, loss 0.7055012583732605, acc=0.7833333611488342, loss=0.7055012583732605
train: epoch 112, loss 0.18698281049728394, acc=0.933388888835907, loss=0.18698281049728394
test: epoch 112, loss 0.6500762104988098, acc=0.7944444417953491, loss=0.6500762104988098
train: epoch 113, loss 0.18035350739955902, acc=0.9350555539131165, loss=0.18035350739955902
test: epoch 113, loss 0.644476056098938, acc=0.7861111164093018, loss=0.644476056098938
train: epoch 114, loss 0.19033995270729065, acc=0.9328888654708862, loss=0.19033995270729065
test: epoch 114, loss 0.5925029516220093, acc=0.7944444417953491, loss=0.5925029516220093
train: epoch 115, loss 0.16867217421531677, acc=0.9374444484710693, loss=0.16867217421531677
test: epoch 115, loss 0.6238763332366943, acc=0.7749999761581421, loss=0.6238763332366943
train: epoch 116, loss 0.1781277358531952, acc=0.9337777495384216, loss=0.1781277358531952
test: epoch 116, loss 0.6806937456130981, acc=0.800000011920929, loss=0.6806937456130981
train: epoch 117, loss 0.16940538585186005, acc=0.9385555386543274, loss=0.16940538585186005
test: epoch 117, loss 0.678054928779602, acc=0.8055555820465088, loss=0.678054928779602
train: epoch 118, loss 0.17532524466514587, acc=0.9346110820770264, loss=0.17532524466514587
test: epoch 118, loss 0.6132275462150574, acc=0.800000011920929, loss=0.6132275462150574
train: epoch 119, loss 0.16827082633972168, acc=0.9373888969421387, loss=0.16827082633972168
test: epoch 119, loss 0.706497848033905, acc=0.7916666865348816, loss=0.706497848033905
train: epoch 120, loss 0.17060497403144836, acc=0.9372222423553467, loss=0.17060497403144836
test: epoch 120, loss 0.626755952835083, acc=0.8361111283302307, loss=0.626755952835083
train: epoch 121, loss 0.16275165975093842, acc=0.9391666650772095, loss=0.16275165975093842
test: epoch 121, loss 0.5523280501365662, acc=0.8111110925674438, loss=0.5523280501365662
train: epoch 122, loss 0.17148736119270325, acc=0.9350000023841858, loss=0.17148736119270325
test: epoch 122, loss 0.5792847871780396, acc=0.8083333373069763, loss=0.5792847871780396
train: epoch 123, loss 0.16667260229587555, acc=0.9390555620193481, loss=0.16667260229587555
test: epoch 123, loss 0.5492528676986694, acc=0.7888888716697693, loss=0.5492528676986694
train: epoch 124, loss 0.167718768119812, acc=0.9352777600288391, loss=0.167718768119812
test: epoch 124, loss 0.563759982585907, acc=0.8083333373069763, loss=0.563759982585907
train: epoch 125, loss 0.1611785739660263, acc=0.9380000233650208, loss=0.1611785739660263
test: epoch 125, loss 0.5436388850212097, acc=0.8333333134651184, loss=0.5436388850212097
train: epoch 126, loss 0.17703695595264435, acc=0.9383333325386047, loss=0.17703695595264435
test: epoch 126, loss 0.4886898994445801, acc=0.8388888835906982, loss=0.4886898994445801
train: epoch 127, loss 0.15984828770160675, acc=0.9384444355964661, loss=0.15984828770160675
test: epoch 127, loss 0.48636841773986816, acc=0.8388888835906982, loss=0.48636841773986816
train: epoch 128, loss 0.15158839523792267, acc=0.9393888711929321, loss=0.15158839523792267
test: epoch 128, loss 0.5143068432807922, acc=0.8388888835906982, loss=0.5143068432807922
train: epoch 129, loss 0.15525290369987488, acc=0.9402222037315369, loss=0.15525290369987488
test: epoch 129, loss 0.49501675367355347, acc=0.8388888835906982, loss=0.49501675367355347
train: epoch 130, loss 0.14413221180438995, acc=0.9423333406448364, loss=0.14413221180438995
test: epoch 130, loss 0.4844198524951935, acc=0.8388888835906982, loss=0.4844198524951935
train: epoch 131, loss 0.15436778962612152, acc=0.941444456577301, loss=0.15436778962612152
test: epoch 131, loss 0.48615774512290955, acc=0.8361111283302307, loss=0.48615774512290955
train: epoch 132, loss 0.14720652997493744, acc=0.9432777762413025, loss=0.14720652997493744
test: epoch 132, loss 0.5961930751800537, acc=0.8416666388511658, loss=0.5961930751800537
train: epoch 133, loss 0.1518281102180481, acc=0.9376111030578613, loss=0.1518281102180481
test: epoch 133, loss 0.5094574689865112, acc=0.8444444537162781, loss=0.5094574689865112
train: epoch 134, loss 0.14921726286411285, acc=0.9422222375869751, loss=0.14921726286411285
test: epoch 134, loss 0.4444893002510071, acc=0.8416666388511658, loss=0.4444893002510071
train: epoch 135, loss 0.14473524689674377, acc=0.9407777786254883, loss=0.14473524689674377
test: epoch 135, loss 0.5037921667098999, acc=0.8472222089767456, loss=0.5037921667098999
train: epoch 136, loss 0.14580723643302917, acc=0.9443333148956299, loss=0.14580723643302917
test: epoch 136, loss 0.4833793640136719, acc=0.8527777791023254, loss=0.4833793640136719
train: epoch 137, loss 0.1404784768819809, acc=0.94477778673172, loss=0.1404784768819809
test: epoch 137, loss 0.51140296459198, acc=0.8527777791023254, loss=0.51140296459198
train: epoch 138, loss 0.1465236246585846, acc=0.9439444541931152, loss=0.1465236246585846
test: epoch 138, loss 0.5021817088127136, acc=0.8500000238418579, loss=0.5021817088127136
train: epoch 139, loss 0.14275388419628143, acc=0.9442777633666992, loss=0.14275388419628143
test: epoch 139, loss 0.5057591795921326, acc=0.8527777791023254, loss=0.5057591795921326
train: epoch 140, loss 0.1555832028388977, acc=0.9422222375869751, loss=0.1555832028388977
test: epoch 140, loss 0.4334515929222107, acc=0.8444444537162781, loss=0.4334515929222107
train: epoch 141, loss 0.13709881901741028, acc=0.9455000162124634, loss=0.13709881901741028
test: epoch 141, loss 0.4819466173648834, acc=0.8527777791023254, loss=0.4819466173648834
train: epoch 142, loss 0.1336187869310379, acc=0.9470555782318115, loss=0.1336187869310379
test: epoch 142, loss 0.4380147457122803, acc=0.8527777791023254, loss=0.4380147457122803
train: epoch 143, loss 0.1361522525548935, acc=0.9463889002799988, loss=0.1361522525548935
test: epoch 143, loss 0.4835880696773529, acc=0.8527777791023254, loss=0.4835880696773529
train: epoch 144, loss 0.14289818704128265, acc=0.9438333511352539, loss=0.14289818704128265
test: epoch 144, loss 0.43334388732910156, acc=0.8527777791023254, loss=0.43334388732910156
train: epoch 145, loss 0.1273963451385498, acc=0.9477221965789795, loss=0.1273963451385498
test: epoch 145, loss 0.5057880282402039, acc=0.8527777791023254, loss=0.5057880282402039
train: epoch 146, loss 0.12986713647842407, acc=0.9462777972221375, loss=0.12986713647842407
test: epoch 146, loss 0.44232192635536194, acc=0.8527777791023254, loss=0.44232192635536194
train: epoch 147, loss 0.13159431517124176, acc=0.949055552482605, loss=0.13159431517124176
test: epoch 147, loss 0.5313154458999634, acc=0.8527777791023254, loss=0.5313154458999634
train: epoch 148, loss 0.12936559319496155, acc=0.9461666941642761, loss=0.12936559319496155
test: epoch 148, loss 0.4473726153373718, acc=0.8527777791023254, loss=0.4473726153373718
train: epoch 149, loss 0.13063333928585052, acc=0.9477221965789795, loss=0.13063333928585052
test: epoch 149, loss 0.4485320746898651, acc=0.8500000238418579, loss=0.4485320746898651
train: epoch 150, loss 0.12856128811836243, acc=0.9471666812896729, loss=0.12856128811836243
test: epoch 150, loss 0.44413095712661743, acc=0.8527777791023254, loss=0.44413095712661743
