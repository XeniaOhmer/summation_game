# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=1.5", "--temp_decay=1", "--one_hot=true", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1312628190, receiver_embed_dim=128, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.76530122756958, acc=0.09644444286823273, loss=2.76530122756958
test: epoch 1, loss 2.633833408355713, acc=0.15000000596046448, loss=2.633833408355713
train: epoch 2, loss 1.7866486310958862, acc=0.2492777705192566, loss=1.7866486310958862
test: epoch 2, loss 2.2241523265838623, acc=0.23333333432674408, loss=2.2241523265838623
train: epoch 3, loss 1.3936097621917725, acc=0.37594443559646606, loss=1.3936097621917725
test: epoch 3, loss 2.1923158168792725, acc=0.2666666805744171, loss=2.1923158168792725
train: epoch 4, loss 1.0705219507217407, acc=0.5331110954284668, loss=1.0705219507217407
test: epoch 4, loss 1.7191067934036255, acc=0.41111111640930176, loss=1.7191067934036255
train: epoch 5, loss 0.8853427171707153, acc=0.6138888597488403, loss=0.8853427171707153
test: epoch 5, loss 1.4217909574508667, acc=0.4583333432674408, loss=1.4217909574508667
train: epoch 6, loss 0.7192973494529724, acc=0.6951666474342346, loss=0.7192973494529724
test: epoch 6, loss 1.6883940696716309, acc=0.4277777671813965, loss=1.6883940696716309
train: epoch 7, loss 0.6687130928039551, acc=0.711722195148468, loss=0.6687130928039551
test: epoch 7, loss 1.4172836542129517, acc=0.4722222089767456, loss=1.4172836542129517
train: epoch 8, loss 0.5780510902404785, acc=0.7549444437026978, loss=0.5780510902404785
test: epoch 8, loss 1.410919189453125, acc=0.5416666865348816, loss=1.410919189453125
train: epoch 9, loss 0.499571830034256, acc=0.7902777791023254, loss=0.499571830034256
test: epoch 9, loss 0.941211998462677, acc=0.6277777552604675, loss=0.941211998462677
train: epoch 10, loss 0.43672701716423035, acc=0.8132222294807434, loss=0.43672701716423035
test: epoch 10, loss 0.8516594767570496, acc=0.6638888716697693, loss=0.8516594767570496
train: epoch 11, loss 0.398344486951828, acc=0.8379444479942322, loss=0.398344486951828
test: epoch 11, loss 0.959571361541748, acc=0.6333333253860474, loss=0.959571361541748
train: epoch 12, loss 0.31419119238853455, acc=0.8759999871253967, loss=0.31419119238853455
test: epoch 12, loss 0.941472053527832, acc=0.6722221970558167, loss=0.941472053527832
train: epoch 13, loss 0.2901771068572998, acc=0.88355553150177, loss=0.2901771068572998
test: epoch 13, loss 0.9535024166107178, acc=0.6694444417953491, loss=0.9535024166107178
train: epoch 14, loss 0.27802836894989014, acc=0.890333354473114, loss=0.27802836894989014
test: epoch 14, loss 0.8891462683677673, acc=0.7361111044883728, loss=0.8891462683677673
train: epoch 15, loss 0.25968870520591736, acc=0.8957777619361877, loss=0.25968870520591736
test: epoch 15, loss 1.104495644569397, acc=0.7333333492279053, loss=1.104495644569397
train: epoch 16, loss 0.2592589259147644, acc=0.8972222208976746, loss=0.2592589259147644
test: epoch 16, loss 0.539563000202179, acc=0.800000011920929, loss=0.539563000202179
train: epoch 17, loss 0.26365694403648376, acc=0.8946666717529297, loss=0.26365694403648376
test: epoch 17, loss 0.5937270522117615, acc=0.7805555462837219, loss=0.5937270522117615
train: epoch 18, loss 0.2306361198425293, acc=0.9052222371101379, loss=0.2306361198425293
test: epoch 18, loss 0.689314603805542, acc=0.7861111164093018, loss=0.689314603805542
train: epoch 19, loss 0.22250866889953613, acc=0.9170555472373962, loss=0.22250866889953613
test: epoch 19, loss 0.6223740577697754, acc=0.8055555820465088, loss=0.6223740577697754
train: epoch 20, loss 0.19612720608711243, acc=0.9308888912200928, loss=0.19612720608711243
test: epoch 20, loss 0.5687028765678406, acc=0.8277778029441833, loss=0.5687028765678406
train: epoch 21, loss 0.2103072553873062, acc=0.9270555377006531, loss=0.2103072553873062
test: epoch 21, loss 0.687075138092041, acc=0.8055555820465088, loss=0.687075138092041
train: epoch 22, loss 0.1659279465675354, acc=0.9448333382606506, loss=0.1659279465675354
test: epoch 22, loss 0.7565903067588806, acc=0.8083333373069763, loss=0.7565903067588806
train: epoch 23, loss 0.16994917392730713, acc=0.9433888792991638, loss=0.16994917392730713
test: epoch 23, loss 0.6972561478614807, acc=0.7916666865348816, loss=0.6972561478614807
train: epoch 24, loss 0.15740135312080383, acc=0.9461666941642761, loss=0.15740135312080383
test: epoch 24, loss 0.6891168355941772, acc=0.8305555582046509, loss=0.6891168355941772
train: epoch 25, loss 0.15648233890533447, acc=0.949222207069397, loss=0.15648233890533447
test: epoch 25, loss 0.7599000334739685, acc=0.8027777671813965, loss=0.7599000334739685
train: epoch 26, loss 0.1619078367948532, acc=0.9477777481079102, loss=0.1619078367948532
test: epoch 26, loss 0.5837293863296509, acc=0.8277778029441833, loss=0.5837293863296509
train: epoch 27, loss 0.1519881784915924, acc=0.9484444260597229, loss=0.1519881784915924
test: epoch 27, loss 0.6925386190414429, acc=0.8333333134651184, loss=0.6925386190414429
train: epoch 28, loss 0.1562310755252838, acc=0.9509444236755371, loss=0.1562310755252838
test: epoch 28, loss 0.7721424102783203, acc=0.8305555582046509, loss=0.7721424102783203
train: epoch 29, loss 0.15521399676799774, acc=0.9497222304344177, loss=0.15521399676799774
test: epoch 29, loss 0.6334131956100464, acc=0.8138889074325562, loss=0.6334131956100464
train: epoch 30, loss 0.14052832126617432, acc=0.9538333415985107, loss=0.14052832126617432
test: epoch 30, loss 0.8028907179832458, acc=0.8194444179534912, loss=0.8028907179832458
train: epoch 31, loss 0.14747516810894012, acc=0.953000009059906, loss=0.14747516810894012
test: epoch 31, loss 0.7790893912315369, acc=0.8111110925674438, loss=0.7790893912315369
train: epoch 32, loss 0.15154831111431122, acc=0.953000009059906, loss=0.15154831111431122
test: epoch 32, loss 0.7238118052482605, acc=0.8194444179534912, loss=0.7238118052482605
train: epoch 33, loss 0.11407086253166199, acc=0.9636666774749756, loss=0.11407086253166199
test: epoch 33, loss 0.8196790814399719, acc=0.8388888835906982, loss=0.8196790814399719
train: epoch 34, loss 0.13915430009365082, acc=0.9592777490615845, loss=0.13915430009365082
test: epoch 34, loss 0.60225510597229, acc=0.8277778029441833, loss=0.60225510597229
train: epoch 35, loss 0.11042406409978867, acc=0.9654444456100464, loss=0.11042406409978867
test: epoch 35, loss 0.6794595122337341, acc=0.8361111283302307, loss=0.6794595122337341
train: epoch 36, loss 0.1273881047964096, acc=0.9600555300712585, loss=0.1273881047964096
test: epoch 36, loss 0.6322510242462158, acc=0.800000011920929, loss=0.6322510242462158
train: epoch 37, loss 0.1055053249001503, acc=0.9661111235618591, loss=0.1055053249001503
test: epoch 37, loss 0.6716258525848389, acc=0.8416666388511658, loss=0.6716258525848389
train: epoch 38, loss 0.14803776144981384, acc=0.9550555348396301, loss=0.14803776144981384
test: epoch 38, loss 0.5273834466934204, acc=0.8444444537162781, loss=0.5273834466934204
train: epoch 39, loss 0.08506029099225998, acc=0.9710000157356262, loss=0.08506029099225998
test: epoch 39, loss 0.7098727226257324, acc=0.8416666388511658, loss=0.7098727226257324
train: epoch 40, loss 0.09114140272140503, acc=0.9721111059188843, loss=0.09114140272140503
test: epoch 40, loss 0.6739356517791748, acc=0.8416666388511658, loss=0.6739356517791748
train: epoch 41, loss 0.10307102650403976, acc=0.9676666855812073, loss=0.10307102650403976
test: epoch 41, loss 0.6204561591148376, acc=0.8472222089767456, loss=0.6204561591148376
train: epoch 42, loss 0.1254122257232666, acc=0.9624444246292114, loss=0.1254122257232666
test: epoch 42, loss 0.6243215799331665, acc=0.8388888835906982, loss=0.6243215799331665
train: epoch 43, loss 0.12325236946344376, acc=0.9631666541099548, loss=0.12325236946344376
test: epoch 43, loss 0.6338900923728943, acc=0.8444444537162781, loss=0.6338900923728943
train: epoch 44, loss 0.0969807356595993, acc=0.9677777886390686, loss=0.0969807356595993
test: epoch 44, loss 0.9865407347679138, acc=0.8305555582046509, loss=0.9865407347679138
train: epoch 45, loss 0.10398048907518387, acc=0.9668889045715332, loss=0.10398048907518387
test: epoch 45, loss 0.7391179800033569, acc=0.8055555820465088, loss=0.7391179800033569
train: epoch 46, loss 0.13225066661834717, acc=0.9557222127914429, loss=0.13225066661834717
test: epoch 46, loss 0.7056277394294739, acc=0.855555534362793, loss=0.7056277394294739
train: epoch 47, loss 0.08752495795488358, acc=0.9740555286407471, loss=0.08752495795488358
test: epoch 47, loss 0.6082946062088013, acc=0.855555534362793, loss=0.6082946062088013
train: epoch 48, loss 0.07621226459741592, acc=0.9755555391311646, loss=0.07621226459741592
test: epoch 48, loss 0.8027172684669495, acc=0.8583333492279053, loss=0.8027172684669495
train: epoch 49, loss 0.09795140475034714, acc=0.9704444408416748, loss=0.09795140475034714
test: epoch 49, loss 0.5895431041717529, acc=0.8527777791023254, loss=0.5895431041717529
train: epoch 50, loss 0.10196920484304428, acc=0.9711111187934875, loss=0.10196920484304428
test: epoch 50, loss 0.5776934623718262, acc=0.8500000238418579, loss=0.5776934623718262
train: epoch 51, loss 0.08429174870252609, acc=0.972611129283905, loss=0.08429174870252609
test: epoch 51, loss 0.6740005016326904, acc=0.8416666388511658, loss=0.6740005016326904
train: epoch 52, loss 0.10346585512161255, acc=0.9676111340522766, loss=0.10346585512161255
test: epoch 52, loss 0.620170533657074, acc=0.8500000238418579, loss=0.620170533657074
train: epoch 53, loss 0.06069307401776314, acc=0.9790555834770203, loss=0.06069307401776314
test: epoch 53, loss 0.628797173500061, acc=0.8583333492279053, loss=0.628797173500061
train: epoch 54, loss 0.10838298499584198, acc=0.9707221984863281, loss=0.10838298499584198
test: epoch 54, loss 0.6841330528259277, acc=0.8305555582046509, loss=0.6841330528259277
train: epoch 55, loss 0.07832136750221252, acc=0.975777804851532, loss=0.07832136750221252
test: epoch 55, loss 0.7181183099746704, acc=0.8583333492279053, loss=0.7181183099746704
train: epoch 56, loss 0.10266005247831345, acc=0.9700000286102295, loss=0.10266005247831345
test: epoch 56, loss 0.6940228939056396, acc=0.8527777791023254, loss=0.6940228939056396
train: epoch 57, loss 0.1622077226638794, acc=0.9393888711929321, loss=0.1622077226638794
test: epoch 57, loss 0.5490925312042236, acc=0.8305555582046509, loss=0.5490925312042236
train: epoch 58, loss 0.1058211550116539, acc=0.9633333086967468, loss=0.1058211550116539
test: epoch 58, loss 0.677203357219696, acc=0.8805555701255798, loss=0.677203357219696
train: epoch 59, loss 0.05614759027957916, acc=0.984000027179718, loss=0.05614759027957916
test: epoch 59, loss 0.5699231028556824, acc=0.8861111402511597, loss=0.5699231028556824
train: epoch 60, loss 0.03784872591495514, acc=0.9877777695655823, loss=0.03784872591495514
test: epoch 60, loss 0.6369190216064453, acc=0.8888888955116272, loss=0.6369190216064453
train: epoch 61, loss 0.08788876980543137, acc=0.9778333306312561, loss=0.08788876980543137
test: epoch 61, loss 0.38272354006767273, acc=0.8888888955116272, loss=0.38272354006767273
train: epoch 62, loss 0.05328088998794556, acc=0.9841111302375793, loss=0.05328088998794556
test: epoch 62, loss 0.3969566524028778, acc=0.9166666865348816, loss=0.3969566524028778
train: epoch 63, loss 0.0513153038918972, acc=0.9853888750076294, loss=0.0513153038918972
test: epoch 63, loss 0.30644965171813965, acc=0.9166666865348816, loss=0.30644965171813965
train: epoch 64, loss 0.07254311442375183, acc=0.9826666712760925, loss=0.07254311442375183
test: epoch 64, loss 0.4598020017147064, acc=0.9027777910232544, loss=0.4598020017147064
train: epoch 65, loss 0.056682977825403214, acc=0.9827777743339539, loss=0.056682977825403214
test: epoch 65, loss 0.4335639178752899, acc=0.9111111164093018, loss=0.4335639178752899
train: epoch 66, loss 0.09283322840929031, acc=0.9754444360733032, loss=0.09283322840929031
test: epoch 66, loss 0.4454345405101776, acc=0.9055555462837219, loss=0.4454345405101776
train: epoch 67, loss 0.051656320691108704, acc=0.984499990940094, loss=0.051656320691108704
test: epoch 67, loss 0.3398233652114868, acc=0.9138888716697693, loss=0.3398233652114868
train: epoch 68, loss 0.035203833132982254, acc=0.9891666769981384, loss=0.035203833132982254
test: epoch 68, loss 0.3489190638065338, acc=0.9138888716697693, loss=0.3489190638065338
train: epoch 69, loss 0.04985019564628601, acc=0.9857777953147888, loss=0.04985019564628601
test: epoch 69, loss 0.5130693912506104, acc=0.9166666865348816, loss=0.5130693912506104
train: epoch 70, loss 0.027443911880254745, acc=0.9911110997200012, loss=0.027443911880254745
test: epoch 70, loss 0.3349058926105499, acc=0.9166666865348816, loss=0.3349058926105499
train: epoch 71, loss 0.016780121251940727, acc=0.9933888912200928, loss=0.016780121251940727
test: epoch 71, loss 0.4503253698348999, acc=0.9166666865348816, loss=0.4503253698348999
train: epoch 72, loss 0.1409798264503479, acc=0.964388906955719, loss=0.1409798264503479
test: epoch 72, loss 0.4736204445362091, acc=0.9138888716697693, loss=0.4736204445362091
train: epoch 73, loss 0.057654969394207, acc=0.9852777719497681, loss=0.057654969394207
test: epoch 73, loss 0.356907457113266, acc=0.9027777910232544, loss=0.356907457113266
train: epoch 74, loss 0.049746718257665634, acc=0.9858333468437195, loss=0.049746718257665634
test: epoch 74, loss 0.47917965054512024, acc=0.9111111164093018, loss=0.47917965054512024
train: epoch 75, loss 0.04592834785580635, acc=0.9874444603919983, loss=0.04592834785580635
test: epoch 75, loss 0.6841643452644348, acc=0.8916666507720947, loss=0.6841643452644348
train: epoch 76, loss 0.05868261307477951, acc=0.981333315372467, loss=0.05868261307477951
test: epoch 76, loss 0.47023648023605347, acc=0.9111111164093018, loss=0.47023648023605347
train: epoch 77, loss 0.039011500775814056, acc=0.988111138343811, loss=0.039011500775814056
test: epoch 77, loss 0.349605530500412, acc=0.9194444417953491, loss=0.349605530500412
train: epoch 78, loss 0.07164832204580307, acc=0.9794999957084656, loss=0.07164832204580307
test: epoch 78, loss 0.4085194170475006, acc=0.9138888716697693, loss=0.4085194170475006
train: epoch 79, loss 0.07761777192354202, acc=0.9840555787086487, loss=0.07761777192354202
test: epoch 79, loss 0.9092320799827576, acc=0.9111111164093018, loss=0.9092320799827576
train: epoch 80, loss 0.07140493392944336, acc=0.9812777638435364, loss=0.07140493392944336
test: epoch 80, loss 0.5902484059333801, acc=0.9111111164093018, loss=0.5902484059333801
train: epoch 81, loss 0.03818437457084656, acc=0.9870555400848389, loss=0.03818437457084656
test: epoch 81, loss 0.8422108888626099, acc=0.9111111164093018, loss=0.8422108888626099
train: epoch 82, loss 0.0685979574918747, acc=0.9823333621025085, loss=0.0685979574918747
test: epoch 82, loss 0.4421007037162781, acc=0.9111111164093018, loss=0.4421007037162781
train: epoch 83, loss 0.060530904680490494, acc=0.9842222332954407, loss=0.060530904680490494
test: epoch 83, loss 0.4888232946395874, acc=0.9055555462837219, loss=0.4888232946395874
train: epoch 84, loss 0.08908163011074066, acc=0.968666672706604, loss=0.08908163011074066
test: epoch 84, loss 0.43778669834136963, acc=0.9138888716697693, loss=0.43778669834136963
train: epoch 85, loss 0.06916036456823349, acc=0.97688889503479, loss=0.06916036456823349
test: epoch 85, loss 0.3231082856655121, acc=0.9222221970558167, loss=0.3231082856655121
train: epoch 86, loss 0.06381213665008545, acc=0.9763333201408386, loss=0.06381213665008545
test: epoch 86, loss 0.3018229305744171, acc=0.9388889074325562, loss=0.3018229305744171
train: epoch 87, loss 0.11816342920064926, acc=0.964888870716095, loss=0.11816342920064926
test: epoch 87, loss 0.45807477831840515, acc=0.9027777910232544, loss=0.45807477831840515
train: epoch 88, loss 0.04706166312098503, acc=0.9752777814865112, loss=0.04706166312098503
test: epoch 88, loss 0.48036283254623413, acc=0.9138888716697693, loss=0.48036283254623413
train: epoch 89, loss 0.03711264580488205, acc=0.9773889183998108, loss=0.03711264580488205
test: epoch 89, loss 0.32693371176719666, acc=0.9277777671813965, loss=0.32693371176719666
train: epoch 90, loss 0.0617072694003582, acc=0.9740555286407471, loss=0.0617072694003582
test: epoch 90, loss 0.4371196925640106, acc=0.9222221970558167, loss=0.4371196925640106
train: epoch 91, loss 0.053660351783037186, acc=0.9738888740539551, loss=0.053660351783037186
test: epoch 91, loss 0.22559823095798492, acc=0.9388889074325562, loss=0.22559823095798492
train: epoch 92, loss 0.08046212047338486, acc=0.9749444723129272, loss=0.08046212047338486
test: epoch 92, loss 0.28472286462783813, acc=0.925000011920929, loss=0.28472286462783813
train: epoch 93, loss 0.07274188101291656, acc=0.9693333506584167, loss=0.07274188101291656
test: epoch 93, loss 0.2650972306728363, acc=0.9277777671813965, loss=0.2650972306728363
train: epoch 94, loss 0.09612412750720978, acc=0.9673333168029785, loss=0.09612412750720978
test: epoch 94, loss 0.41353628039360046, acc=0.925000011920929, loss=0.41353628039360046
train: epoch 95, loss 0.07631591707468033, acc=0.9633333086967468, loss=0.07631591707468033
test: epoch 95, loss 0.2786603271961212, acc=0.9305555820465088, loss=0.2786603271961212
train: epoch 96, loss 0.09931188821792603, acc=0.9652777910232544, loss=0.09931188821792603
test: epoch 96, loss 0.2916410267353058, acc=0.9333333373069763, loss=0.2916410267353058
train: epoch 97, loss 0.061831384897232056, acc=0.9701666831970215, loss=0.061831384897232056
test: epoch 97, loss 0.42483606934547424, acc=0.894444465637207, loss=0.42483606934547424
train: epoch 98, loss 0.16724060475826263, acc=0.9427222013473511, loss=0.16724060475826263
test: epoch 98, loss 0.34123122692108154, acc=0.925000011920929, loss=0.34123122692108154
train: epoch 99, loss 0.11752519011497498, acc=0.9553889036178589, loss=0.11752519011497498
test: epoch 99, loss 0.2992301881313324, acc=0.8999999761581421, loss=0.2992301881313324
train: epoch 100, loss 0.12508952617645264, acc=0.9516111016273499, loss=0.12508952617645264
test: epoch 100, loss 0.30814066529273987, acc=0.9138888716697693, loss=0.30814066529273987
train: epoch 101, loss 0.11392085999250412, acc=0.9533888697624207, loss=0.11392085999250412
test: epoch 101, loss 0.3379785418510437, acc=0.8861111402511597, loss=0.3379785418510437
train: epoch 102, loss 0.09435930103063583, acc=0.957111120223999, loss=0.09435930103063583
test: epoch 102, loss 0.5219382643699646, acc=0.8916666507720947, loss=0.5219382643699646
train: epoch 103, loss 0.0849197581410408, acc=0.9652222394943237, loss=0.0849197581410408
test: epoch 103, loss 0.29200479388237, acc=0.9222221970558167, loss=0.29200479388237
train: epoch 104, loss 0.08098679035902023, acc=0.9578333497047424, loss=0.08098679035902023
test: epoch 104, loss 0.2478483021259308, acc=0.9222221970558167, loss=0.2478483021259308
train: epoch 105, loss 0.1434444785118103, acc=0.9513333439826965, loss=0.1434444785118103
test: epoch 105, loss 0.5202855467796326, acc=0.8833333253860474, loss=0.5202855467796326
train: epoch 106, loss 0.10756596177816391, acc=0.9532222151756287, loss=0.10756596177816391
test: epoch 106, loss 0.35702750086784363, acc=0.8833333253860474, loss=0.35702750086784363
train: epoch 107, loss 0.10440608114004135, acc=0.9568333625793457, loss=0.10440608114004135
test: epoch 107, loss 0.723665714263916, acc=0.8833333253860474, loss=0.723665714263916
train: epoch 108, loss 0.12843117117881775, acc=0.9526110887527466, loss=0.12843117117881775
test: epoch 108, loss 0.3639511168003082, acc=0.9194444417953491, loss=0.3639511168003082
train: epoch 109, loss 0.09059619903564453, acc=0.9585555791854858, loss=0.09059619903564453
test: epoch 109, loss 0.31205856800079346, acc=0.9222221970558167, loss=0.31205856800079346
train: epoch 110, loss 0.10287534445524216, acc=0.9583333134651184, loss=0.10287534445524216
test: epoch 110, loss 0.12346616387367249, acc=0.9611111283302307, loss=0.12346616387367249
train: epoch 111, loss 0.09126098453998566, acc=0.9601110816001892, loss=0.09126098453998566
test: epoch 111, loss 0.08746922016143799, acc=0.9638888835906982, loss=0.08746922016143799
train: epoch 112, loss 0.07788757979869843, acc=0.9664444327354431, loss=0.07788757979869843
test: epoch 112, loss 0.10675349831581116, acc=0.9638888835906982, loss=0.10675349831581116
train: epoch 113, loss 0.0706147775053978, acc=0.964722216129303, loss=0.0706147775053978
test: epoch 113, loss 0.11497891694307327, acc=0.9638888835906982, loss=0.11497891694307327
train: epoch 114, loss 0.10485842823982239, acc=0.9621111154556274, loss=0.10485842823982239
test: epoch 114, loss 0.13777554035186768, acc=0.9527778029441833, loss=0.13777554035186768
train: epoch 115, loss 0.10759831219911575, acc=0.9541110992431641, loss=0.10759831219911575
test: epoch 115, loss 0.1360444575548172, acc=0.9527778029441833, loss=0.1360444575548172
train: epoch 116, loss 0.1084839329123497, acc=0.9534444212913513, loss=0.1084839329123497
test: epoch 116, loss 0.13246068358421326, acc=0.9527778029441833, loss=0.13246068358421326
train: epoch 117, loss 0.10359878838062286, acc=0.9546666741371155, loss=0.10359878838062286
test: epoch 117, loss 0.13482894003391266, acc=0.9555555582046509, loss=0.13482894003391266
train: epoch 118, loss 0.15544328093528748, acc=0.9535555839538574, loss=0.15544328093528748
test: epoch 118, loss 0.13929802179336548, acc=0.9555555582046509, loss=0.13929802179336548
train: epoch 119, loss 0.12026605010032654, acc=0.9543889164924622, loss=0.12026605010032654
test: epoch 119, loss 0.20144763588905334, acc=0.9138888716697693, loss=0.20144763588905334
train: epoch 120, loss 0.08491409569978714, acc=0.9564444422721863, loss=0.08491409569978714
test: epoch 120, loss 0.19049611687660217, acc=0.925000011920929, loss=0.19049611687660217
train: epoch 121, loss 0.08542368561029434, acc=0.9634444713592529, loss=0.08542368561029434
test: epoch 121, loss 0.23046572506427765, acc=0.9305555820465088, loss=0.23046572506427765
train: epoch 122, loss 0.07825564593076706, acc=0.964388906955719, loss=0.07825564593076706
test: epoch 122, loss 0.23786981403827667, acc=0.9305555820465088, loss=0.23786981403827667
train: epoch 123, loss 0.06819000095129013, acc=0.9671666622161865, loss=0.06819000095129013
test: epoch 123, loss 0.2825409471988678, acc=0.9305555820465088, loss=0.2825409471988678
train: epoch 124, loss 0.07100636512041092, acc=0.9712222218513489, loss=0.07100636512041092
test: epoch 124, loss 0.2919122576713562, acc=0.9361110925674438, loss=0.2919122576713562
train: epoch 125, loss 0.08900109678506851, acc=0.9666666388511658, loss=0.08900109678506851
test: epoch 125, loss 0.09635189920663834, acc=0.9638888835906982, loss=0.09635189920663834
train: epoch 126, loss 0.08041305840015411, acc=0.9650555849075317, loss=0.08041305840015411
test: epoch 126, loss 0.09772365540266037, acc=0.9666666388511658, loss=0.09772365540266037
train: epoch 127, loss 0.07126350700855255, acc=0.9696666598320007, loss=0.07126350700855255
test: epoch 127, loss 0.10854640603065491, acc=0.9694444537162781, loss=0.10854640603065491
train: epoch 128, loss 0.07863633334636688, acc=0.9672222137451172, loss=0.07863633334636688
test: epoch 128, loss 0.0910516306757927, acc=0.9638888835906982, loss=0.0910516306757927
train: epoch 129, loss 0.08201030641794205, acc=0.961722195148468, loss=0.08201030641794205
test: epoch 129, loss 0.1053895354270935, acc=0.9638888835906982, loss=0.1053895354270935
train: epoch 130, loss 0.07653854787349701, acc=0.9624444246292114, loss=0.07653854787349701
test: epoch 130, loss 0.10898716747760773, acc=0.9638888835906982, loss=0.10898716747760773
train: epoch 131, loss 0.07288357615470886, acc=0.9651666879653931, loss=0.07288357615470886
test: epoch 131, loss 0.08845272660255432, acc=0.9694444537162781, loss=0.08845272660255432
train: epoch 132, loss 0.09405913203954697, acc=0.9614999890327454, loss=0.09405913203954697
test: epoch 132, loss 0.13347503542900085, acc=0.9527778029441833, loss=0.13347503542900085
train: epoch 133, loss 0.0719013586640358, acc=0.9671111106872559, loss=0.0719013586640358
test: epoch 133, loss 0.09228161722421646, acc=0.9694444537162781, loss=0.09228161722421646
train: epoch 134, loss 0.06023237109184265, acc=0.9678888916969299, loss=0.06023237109184265
test: epoch 134, loss 0.9665804505348206, acc=0.9638888835906982, loss=0.9665804505348206
train: epoch 135, loss 0.1962447613477707, acc=0.9507777690887451, loss=0.1962447613477707
test: epoch 135, loss 0.13559414446353912, acc=0.9527778029441833, loss=0.13559414446353912
train: epoch 136, loss 0.09494368731975555, acc=0.9599444270133972, loss=0.09494368731975555
test: epoch 136, loss 0.09735967963933945, acc=0.9583333134651184, loss=0.09735967963933945
train: epoch 137, loss 0.12190605700016022, acc=0.9536111354827881, loss=0.12190605700016022
test: epoch 137, loss 0.11928971856832504, acc=0.9527778029441833, loss=0.11928971856832504
train: epoch 138, loss 0.1300298422574997, acc=0.9540555477142334, loss=0.1300298422574997
test: epoch 138, loss 0.12442510575056076, acc=0.9555555582046509, loss=0.12442510575056076
train: epoch 139, loss 0.10123210400342941, acc=0.961722195148468, loss=0.10123210400342941
test: epoch 139, loss 0.11746877431869507, acc=0.9638888835906982, loss=0.11746877431869507
train: epoch 140, loss 0.08385802060365677, acc=0.9616110920906067, loss=0.08385802060365677
test: epoch 140, loss 0.12339936941862106, acc=0.9638888835906982, loss=0.12339936941862106
train: epoch 141, loss 0.0848083347082138, acc=0.9622222185134888, loss=0.0848083347082138
test: epoch 141, loss 0.11122506856918335, acc=0.9638888835906982, loss=0.11122506856918335
train: epoch 142, loss 0.0846935361623764, acc=0.9614444375038147, loss=0.0846935361623764
test: epoch 142, loss 0.11284320056438446, acc=0.9638888835906982, loss=0.11284320056438446
train: epoch 143, loss 0.13450977206230164, acc=0.9587222337722778, loss=0.13450977206230164
test: epoch 143, loss 0.13023900985717773, acc=0.9555555582046509, loss=0.13023900985717773
train: epoch 144, loss 0.11474175751209259, acc=0.9610555768013, loss=0.11474175751209259
test: epoch 144, loss 0.11712063103914261, acc=0.9611111283302307, loss=0.11712063103914261
train: epoch 145, loss 0.09185390919446945, acc=0.9618333578109741, loss=0.09185390919446945
test: epoch 145, loss 0.10895361751317978, acc=0.9611111283302307, loss=0.10895361751317978
train: epoch 146, loss 0.11821992695331573, acc=0.9590555429458618, loss=0.11821992695331573
test: epoch 146, loss 0.1330701857805252, acc=0.9555555582046509, loss=0.1330701857805252
train: epoch 147, loss 0.12320985645055771, acc=0.9570555686950684, loss=0.12320985645055771
test: epoch 147, loss 0.1739037185907364, acc=0.9583333134651184, loss=0.1739037185907364
train: epoch 148, loss 0.13585661351680756, acc=0.960277795791626, loss=0.13585661351680756
test: epoch 148, loss 0.11581464856863022, acc=0.9611111283302307, loss=0.11581464856863022
train: epoch 149, loss 0.11700019985437393, acc=0.9608888626098633, loss=0.11700019985437393
test: epoch 149, loss 0.1937832534313202, acc=0.9416666626930237, loss=0.1937832534313202
train: epoch 150, loss 0.16241341829299927, acc=0.9425555467605591, loss=0.16241341829299927
test: epoch 150, loss 0.1742386817932129, acc=0.9444444179534912, loss=0.1742386817932129
