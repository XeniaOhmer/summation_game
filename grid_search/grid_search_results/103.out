# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.99", "--one_hot=true", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1374649960, receiver_embed_dim=64, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.8288142681121826, acc=0.10433333367109299, loss=2.8288142681121826
test: epoch 1, loss 4.893737316131592, acc=0.1111111119389534, loss=4.893737316131592
train: epoch 2, loss 1.7590041160583496, acc=0.2668333351612091, loss=1.7590041160583496
test: epoch 2, loss 3.980242967605591, acc=0.16111111640930176, loss=3.980242967605591
train: epoch 3, loss 1.344461441040039, acc=0.4416666626930237, loss=1.344461441040039
test: epoch 3, loss 4.955010890960693, acc=0.1111111119389534, loss=4.955010890960693
train: epoch 4, loss 1.0273321866989136, acc=0.5857222080230713, loss=1.0273321866989136
test: epoch 4, loss 5.00674295425415, acc=0.20555555820465088, loss=5.00674295425415
train: epoch 5, loss 0.8176347017288208, acc=0.6755555272102356, loss=0.8176347017288208
test: epoch 5, loss 4.245687484741211, acc=0.2083333283662796, loss=4.245687484741211
train: epoch 6, loss 0.7003013491630554, acc=0.7192222476005554, loss=0.7003013491630554
test: epoch 6, loss 3.7451741695404053, acc=0.21666666865348816, loss=3.7451741695404053
train: epoch 7, loss 0.6147769093513489, acc=0.7567222118377686, loss=0.6147769093513489
test: epoch 7, loss 3.0163609981536865, acc=0.24722221493721008, loss=3.0163609981536865
train: epoch 8, loss 0.5241769552230835, acc=0.7951666712760925, loss=0.5241769552230835
test: epoch 8, loss 2.5261411666870117, acc=0.35555556416511536, loss=2.5261411666870117
train: epoch 9, loss 0.5066090822219849, acc=0.8065555691719055, loss=0.5066090822219849
test: epoch 9, loss 2.918124198913574, acc=0.32499998807907104, loss=2.918124198913574
train: epoch 10, loss 0.4422147572040558, acc=0.8337222337722778, loss=0.4422147572040558
test: epoch 10, loss 2.766225814819336, acc=0.3055555522441864, loss=2.766225814819336
train: epoch 11, loss 0.4029186964035034, acc=0.8534444570541382, loss=0.4029186964035034
test: epoch 11, loss 2.6413185596466064, acc=0.3444444537162781, loss=2.6413185596466064
train: epoch 12, loss 0.3428225815296173, acc=0.8743888735771179, loss=0.3428225815296173
test: epoch 12, loss 2.119163990020752, acc=0.38055557012557983, loss=2.119163990020752
train: epoch 13, loss 0.35161688923835754, acc=0.8780555725097656, loss=0.35161688923835754
test: epoch 13, loss 1.8912086486816406, acc=0.3888888955116272, loss=1.8912086486816406
train: epoch 14, loss 0.30076247453689575, acc=0.8969444632530212, loss=0.30076247453689575
test: epoch 14, loss 1.9880160093307495, acc=0.3583333194255829, loss=1.9880160093307495
train: epoch 15, loss 0.2894364297389984, acc=0.8977222442626953, loss=0.2894364297389984
test: epoch 15, loss 1.9142318964004517, acc=0.4138889014720917, loss=1.9142318964004517
train: epoch 16, loss 0.28299859166145325, acc=0.899055540561676, loss=0.28299859166145325
test: epoch 16, loss 2.0449233055114746, acc=0.4138889014720917, loss=2.0449233055114746
train: epoch 17, loss 0.25740155577659607, acc=0.910277783870697, loss=0.25740155577659607
test: epoch 17, loss 1.8236982822418213, acc=0.4055555462837219, loss=1.8236982822418213
train: epoch 18, loss 0.24801234900951385, acc=0.913777768611908, loss=0.24801234900951385
test: epoch 18, loss 1.7398755550384521, acc=0.49444442987442017, loss=1.7398755550384521
train: epoch 19, loss 0.23666682839393616, acc=0.9203888773918152, loss=0.23666682839393616
test: epoch 19, loss 2.415083408355713, acc=0.42500001192092896, loss=2.415083408355713
train: epoch 20, loss 0.2254713475704193, acc=0.925611138343811, loss=0.2254713475704193
test: epoch 20, loss 1.8119418621063232, acc=0.4722222089767456, loss=1.8119418621063232
train: epoch 21, loss 0.19819673895835876, acc=0.9362778067588806, loss=0.19819673895835876
test: epoch 21, loss 1.9988044500350952, acc=0.47777777910232544, loss=1.9988044500350952
train: epoch 22, loss 0.20659662783145905, acc=0.9325000047683716, loss=0.20659662783145905
test: epoch 22, loss 2.0311777591705322, acc=0.4694444537162781, loss=2.0311777591705322
train: epoch 23, loss 0.18861614167690277, acc=0.9383333325386047, loss=0.18861614167690277
test: epoch 23, loss 1.8527852296829224, acc=0.5222222208976746, loss=1.8527852296829224
train: epoch 24, loss 0.18391430377960205, acc=0.9382222294807434, loss=0.18391430377960205
test: epoch 24, loss 1.7113996744155884, acc=0.4833333194255829, loss=1.7113996744155884
train: epoch 25, loss 0.17866744101047516, acc=0.9430555701255798, loss=0.17866744101047516
test: epoch 25, loss 1.7210944890975952, acc=0.5666666626930237, loss=1.7210944890975952
train: epoch 26, loss 0.16172732412815094, acc=0.9502778053283691, loss=0.16172732412815094
test: epoch 26, loss 2.0030555725097656, acc=0.4277777671813965, loss=2.0030555725097656
train: epoch 27, loss 0.157642662525177, acc=0.9517222046852112, loss=0.157642662525177
test: epoch 27, loss 1.995924949645996, acc=0.5222222208976746, loss=1.995924949645996
train: epoch 28, loss 0.16997402906417847, acc=0.9469444155693054, loss=0.16997402906417847
test: epoch 28, loss 1.7889351844787598, acc=0.5138888955116272, loss=1.7889351844787598
train: epoch 29, loss 0.15521296858787537, acc=0.9516666531562805, loss=0.15521296858787537
test: epoch 29, loss 1.7849533557891846, acc=0.5, loss=1.7849533557891846
train: epoch 30, loss 0.14707453548908234, acc=0.9524444341659546, loss=0.14707453548908234
test: epoch 30, loss 1.5591647624969482, acc=0.5333333611488342, loss=1.5591647624969482
train: epoch 31, loss 0.15742525458335876, acc=0.9500555396080017, loss=0.15742525458335876
test: epoch 31, loss 2.0990922451019287, acc=0.5472221970558167, loss=2.0990922451019287
train: epoch 32, loss 0.1529989093542099, acc=0.9538333415985107, loss=0.1529989093542099
test: epoch 32, loss 1.5432789325714111, acc=0.6083333492279053, loss=1.5432789325714111
train: epoch 33, loss 0.14002948999404907, acc=0.9580000042915344, loss=0.14002948999404907
test: epoch 33, loss 1.4527385234832764, acc=0.5583333373069763, loss=1.4527385234832764
train: epoch 34, loss 0.13233329355716705, acc=0.9593889117240906, loss=0.13233329355716705
test: epoch 34, loss 1.5602312088012695, acc=0.5861111283302307, loss=1.5602312088012695
train: epoch 35, loss 0.1362590342760086, acc=0.9591110944747925, loss=0.1362590342760086
test: epoch 35, loss 1.4886515140533447, acc=0.5777778029441833, loss=1.4886515140533447
train: epoch 36, loss 0.12730735540390015, acc=0.9618333578109741, loss=0.12730735540390015
test: epoch 36, loss 1.6953887939453125, acc=0.5833333134651184, loss=1.6953887939453125
train: epoch 37, loss 0.12102652341127396, acc=0.9616666436195374, loss=0.12102652341127396
test: epoch 37, loss 1.6226898431777954, acc=0.5888888835906982, loss=1.6226898431777954
train: epoch 38, loss 0.12086322903633118, acc=0.9645000100135803, loss=0.12086322903633118
test: epoch 38, loss 1.2651901245117188, acc=0.6194444298744202, loss=1.2651901245117188
train: epoch 39, loss 0.1326371282339096, acc=0.9595000147819519, loss=0.1326371282339096
test: epoch 39, loss 1.2286896705627441, acc=0.6305555701255798, loss=1.2286896705627441
train: epoch 40, loss 0.12346047908067703, acc=0.9642778038978577, loss=0.12346047908067703
test: epoch 40, loss 1.4149836301803589, acc=0.6333333253860474, loss=1.4149836301803589
train: epoch 41, loss 0.11549239605665207, acc=0.9650555849075317, loss=0.11549239605665207
test: epoch 41, loss 1.720110297203064, acc=0.6277777552604675, loss=1.720110297203064
train: epoch 42, loss 0.11334768682718277, acc=0.964555561542511, loss=0.11334768682718277
test: epoch 42, loss 1.4081165790557861, acc=0.6499999761581421, loss=1.4081165790557861
train: epoch 43, loss 0.12327311933040619, acc=0.9622222185134888, loss=0.12327311933040619
test: epoch 43, loss 1.2109568119049072, acc=0.6805555820465088, loss=1.2109568119049072
train: epoch 44, loss 0.1117144227027893, acc=0.9681110978126526, loss=0.1117144227027893
test: epoch 44, loss 1.9183706045150757, acc=0.644444465637207, loss=1.9183706045150757
train: epoch 45, loss 0.11065299063920975, acc=0.9643333554267883, loss=0.11065299063920975
test: epoch 45, loss 0.992043673992157, acc=0.730555534362793, loss=0.992043673992157
train: epoch 46, loss 0.11096556484699249, acc=0.965666651725769, loss=0.11096556484699249
test: epoch 46, loss 0.9091927409172058, acc=0.6694444417953491, loss=0.9091927409172058
train: epoch 47, loss 0.09477050602436066, acc=0.9704444408416748, loss=0.09477050602436066
test: epoch 47, loss 1.0034297704696655, acc=0.7250000238418579, loss=1.0034297704696655
train: epoch 48, loss 0.11723335832357407, acc=0.9653888940811157, loss=0.11723335832357407
test: epoch 48, loss 0.7235291600227356, acc=0.7833333611488342, loss=0.7235291600227356
train: epoch 49, loss 0.0969732254743576, acc=0.9705555438995361, loss=0.0969732254743576
test: epoch 49, loss 0.7415186166763306, acc=0.730555534362793, loss=0.7415186166763306
train: epoch 50, loss 0.11455290764570236, acc=0.9662777781486511, loss=0.11455290764570236
test: epoch 50, loss 0.6334277987480164, acc=0.7972221970558167, loss=0.6334277987480164
train: epoch 51, loss 0.09674110263586044, acc=0.9723333120346069, loss=0.09674110263586044
test: epoch 51, loss 0.7056944966316223, acc=0.8416666388511658, loss=0.7056944966316223
train: epoch 52, loss 0.09799519926309586, acc=0.9711666703224182, loss=0.09799519926309586
test: epoch 52, loss 0.46072056889533997, acc=0.8527777791023254, loss=0.46072056889533997
train: epoch 53, loss 0.0952189713716507, acc=0.9703888893127441, loss=0.0952189713716507
test: epoch 53, loss 0.6969073414802551, acc=0.8138889074325562, loss=0.6969073414802551
train: epoch 54, loss 0.09395435452461243, acc=0.9726666808128357, loss=0.09395435452461243
test: epoch 54, loss 0.5613170862197876, acc=0.875, loss=0.5613170862197876
train: epoch 55, loss 0.09024260193109512, acc=0.9739444255828857, loss=0.09024260193109512
test: epoch 55, loss 0.5741629004478455, acc=0.8666666746139526, loss=0.5741629004478455
train: epoch 56, loss 0.08604356646537781, acc=0.9758333563804626, loss=0.08604356646537781
test: epoch 56, loss 0.5761920809745789, acc=0.8611111044883728, loss=0.5761920809745789
train: epoch 57, loss 0.07990073412656784, acc=0.977055549621582, loss=0.07990073412656784
test: epoch 57, loss 0.3872782588005066, acc=0.8916666507720947, loss=0.3872782588005066
train: epoch 58, loss 0.08748520165681839, acc=0.9751666784286499, loss=0.08748520165681839
test: epoch 58, loss 0.3539385497570038, acc=0.9166666865348816, loss=0.3539385497570038
train: epoch 59, loss 0.07529694586992264, acc=0.9779444336891174, loss=0.07529694586992264
test: epoch 59, loss 0.31927290558815, acc=0.925000011920929, loss=0.31927290558815
train: epoch 60, loss 0.0772133320569992, acc=0.9765555262565613, loss=0.0772133320569992
test: epoch 60, loss 0.3447357416152954, acc=0.925000011920929, loss=0.3447357416152954
train: epoch 61, loss 0.07553510367870331, acc=0.9791666865348816, loss=0.07553510367870331
test: epoch 61, loss 0.26050353050231934, acc=0.925000011920929, loss=0.26050353050231934
train: epoch 62, loss 0.07361244410276413, acc=0.9801666736602783, loss=0.07361244410276413
test: epoch 62, loss 0.3890436887741089, acc=0.9222221970558167, loss=0.3890436887741089
train: epoch 63, loss 0.0720762237906456, acc=0.9807222485542297, loss=0.0720762237906456
test: epoch 63, loss 0.28246235847473145, acc=0.9277777671813965, loss=0.28246235847473145
train: epoch 64, loss 0.073265939950943, acc=0.9780555367469788, loss=0.073265939950943
test: epoch 64, loss 0.24333886802196503, acc=0.9222221970558167, loss=0.24333886802196503
train: epoch 65, loss 0.06940686702728271, acc=0.9815555810928345, loss=0.06940686702728271
test: epoch 65, loss 0.2704962491989136, acc=0.9277777671813965, loss=0.2704962491989136
train: epoch 66, loss 0.06773653626441956, acc=0.9803333282470703, loss=0.06773653626441956
test: epoch 66, loss 0.3423500657081604, acc=0.9277777671813965, loss=0.3423500657081604
train: epoch 67, loss 0.06004071980714798, acc=0.9838888645172119, loss=0.06004071980714798
test: epoch 67, loss 0.3099668323993683, acc=0.9305555820465088, loss=0.3099668323993683
train: epoch 68, loss 0.0639784187078476, acc=0.9810000061988831, loss=0.0639784187078476
test: epoch 68, loss 0.328097403049469, acc=0.925000011920929, loss=0.328097403049469
train: epoch 69, loss 0.07046005129814148, acc=0.9806666374206543, loss=0.07046005129814148
test: epoch 69, loss 0.4003053605556488, acc=0.9333333373069763, loss=0.4003053605556488
train: epoch 70, loss 0.05817412957549095, acc=0.9831110835075378, loss=0.05817412957549095
test: epoch 70, loss 0.1410081833600998, acc=0.9333333373069763, loss=0.1410081833600998
train: epoch 71, loss 0.049061890691518784, acc=0.9860555529594421, loss=0.049061890691518784
test: epoch 71, loss 0.2911282479763031, acc=0.9222221970558167, loss=0.2911282479763031
train: epoch 72, loss 0.08226990699768066, acc=0.9776111245155334, loss=0.08226990699768066
test: epoch 72, loss 0.3065219819545746, acc=0.9194444417953491, loss=0.3065219819545746
train: epoch 73, loss 0.055451683700084686, acc=0.9834444522857666, loss=0.055451683700084686
test: epoch 73, loss 0.29125434160232544, acc=0.9305555820465088, loss=0.29125434160232544
train: epoch 74, loss 0.056399207562208176, acc=0.9828333258628845, loss=0.056399207562208176
test: epoch 74, loss 0.2175874561071396, acc=0.9305555820465088, loss=0.2175874561071396
train: epoch 75, loss 0.05701577290892601, acc=0.9833333492279053, loss=0.05701577290892601
test: epoch 75, loss 0.297484427690506, acc=0.9277777671813965, loss=0.297484427690506
train: epoch 76, loss 0.05734264478087425, acc=0.984499990940094, loss=0.05734264478087425
test: epoch 76, loss 0.28399619460105896, acc=0.925000011920929, loss=0.28399619460105896
train: epoch 77, loss 0.06192447617650032, acc=0.9816111326217651, loss=0.06192447617650032
test: epoch 77, loss 0.2993888556957245, acc=0.9277777671813965, loss=0.2993888556957245
train: epoch 78, loss 0.05963912233710289, acc=0.9820555448532104, loss=0.05963912233710289
test: epoch 78, loss 0.26758044958114624, acc=0.9305555820465088, loss=0.26758044958114624
train: epoch 79, loss 0.0598430410027504, acc=0.9836111068725586, loss=0.0598430410027504
test: epoch 79, loss 0.1845300942659378, acc=0.9333333373069763, loss=0.1845300942659378
train: epoch 80, loss 0.056294962763786316, acc=0.984000027179718, loss=0.056294962763786316
test: epoch 80, loss 0.27512869238853455, acc=0.9305555820465088, loss=0.27512869238853455
train: epoch 81, loss 0.05627690628170967, acc=0.9831110835075378, loss=0.05627690628170967
test: epoch 81, loss 0.2872297465801239, acc=0.9333333373069763, loss=0.2872297465801239
train: epoch 82, loss 0.06578769534826279, acc=0.9815000295639038, loss=0.06578769534826279
test: epoch 82, loss 0.26345503330230713, acc=0.9305555820465088, loss=0.26345503330230713
train: epoch 83, loss 0.055826444178819656, acc=0.9832777976989746, loss=0.055826444178819656
test: epoch 83, loss 0.20553623139858246, acc=0.9333333373069763, loss=0.20553623139858246
train: epoch 84, loss 0.062317222356796265, acc=0.9812222123146057, loss=0.062317222356796265
test: epoch 84, loss 0.23110316693782806, acc=0.9333333373069763, loss=0.23110316693782806
train: epoch 85, loss 0.059858664870262146, acc=0.9818888902664185, loss=0.059858664870262146
test: epoch 85, loss 0.19039484858512878, acc=0.9333333373069763, loss=0.19039484858512878
train: epoch 86, loss 0.0747857466340065, acc=0.9776111245155334, loss=0.0747857466340065
test: epoch 86, loss 0.1958540678024292, acc=0.9305555820465088, loss=0.1958540678024292
train: epoch 87, loss 0.06697715073823929, acc=0.9795555472373962, loss=0.06697715073823929
test: epoch 87, loss 0.24241967499256134, acc=0.9333333373069763, loss=0.24241967499256134
train: epoch 88, loss 0.05863478407263756, acc=0.9828333258628845, loss=0.05863478407263756
test: epoch 88, loss 0.24672779440879822, acc=0.9333333373069763, loss=0.24672779440879822
train: epoch 89, loss 0.06372639536857605, acc=0.9817777872085571, loss=0.06372639536857605
test: epoch 89, loss 0.21991132199764252, acc=0.9305555820465088, loss=0.21991132199764252
train: epoch 90, loss 0.05724886432290077, acc=0.9838888645172119, loss=0.05724886432290077
test: epoch 90, loss 0.23535530269145966, acc=0.9333333373069763, loss=0.23535530269145966
train: epoch 91, loss 0.05734482780098915, acc=0.9826111197471619, loss=0.05734482780098915
test: epoch 91, loss 0.18190352618694305, acc=0.9333333373069763, loss=0.18190352618694305
train: epoch 92, loss 0.06974253058433533, acc=0.980055570602417, loss=0.06974253058433533
test: epoch 92, loss 0.2202264815568924, acc=0.9333333373069763, loss=0.2202264815568924
train: epoch 93, loss 0.04934388026595116, acc=0.9839444160461426, loss=0.04934388026595116
test: epoch 93, loss 0.2817109525203705, acc=0.9333333373069763, loss=0.2817109525203705
train: epoch 94, loss 0.056175392121076584, acc=0.9827222228050232, loss=0.056175392121076584
test: epoch 94, loss 0.19554507732391357, acc=0.9305555820465088, loss=0.19554507732391357
train: epoch 95, loss 0.07356441766023636, acc=0.97688889503479, loss=0.07356441766023636
test: epoch 95, loss 0.21211306750774384, acc=0.9333333373069763, loss=0.21211306750774384
train: epoch 96, loss 0.05508928745985031, acc=0.984000027179718, loss=0.05508928745985031
test: epoch 96, loss 0.22651052474975586, acc=0.9333333373069763, loss=0.22651052474975586
train: epoch 97, loss 0.06052705645561218, acc=0.9815000295639038, loss=0.06052705645561218
test: epoch 97, loss 0.2289106696844101, acc=0.9333333373069763, loss=0.2289106696844101
train: epoch 98, loss 0.06904227286577225, acc=0.9782778024673462, loss=0.06904227286577225
test: epoch 98, loss 0.20725862681865692, acc=0.9333333373069763, loss=0.20725862681865692
train: epoch 99, loss 0.06291615962982178, acc=0.9804444313049316, loss=0.06291615962982178
test: epoch 99, loss 0.2348261922597885, acc=0.9333333373069763, loss=0.2348261922597885
train: epoch 100, loss 0.06353981047868729, acc=0.9800000190734863, loss=0.06353981047868729
test: epoch 100, loss 0.15477381646633148, acc=0.9333333373069763, loss=0.15477381646633148
train: epoch 101, loss 0.06477423012256622, acc=0.9792777895927429, loss=0.06477423012256622
test: epoch 101, loss 0.25092434883117676, acc=0.9305555820465088, loss=0.25092434883117676
train: epoch 102, loss 0.09817400574684143, acc=0.9687222242355347, loss=0.09817400574684143
test: epoch 102, loss 0.19221921265125275, acc=0.9305555820465088, loss=0.19221921265125275
train: epoch 103, loss 0.06051992252469063, acc=0.9819444417953491, loss=0.06051992252469063
test: epoch 103, loss 0.2515242397785187, acc=0.9305555820465088, loss=0.2515242397785187
train: epoch 104, loss 0.06200352683663368, acc=0.980222225189209, loss=0.06200352683663368
test: epoch 104, loss 0.17522679269313812, acc=0.9333333373069763, loss=0.17522679269313812
train: epoch 105, loss 0.053371306508779526, acc=0.9843888878822327, loss=0.053371306508779526
test: epoch 105, loss 0.15351149439811707, acc=0.9333333373069763, loss=0.15351149439811707
train: epoch 106, loss 0.061761923134326935, acc=0.9813888669013977, loss=0.061761923134326935
test: epoch 106, loss 0.2201254963874817, acc=0.9333333373069763, loss=0.2201254963874817
train: epoch 107, loss 0.0631222352385521, acc=0.9808889031410217, loss=0.0631222352385521
test: epoch 107, loss 0.18154530227184296, acc=0.9333333373069763, loss=0.18154530227184296
train: epoch 108, loss 0.04938153177499771, acc=0.9837777614593506, loss=0.04938153177499771
test: epoch 108, loss 0.16850192844867706, acc=0.9333333373069763, loss=0.16850192844867706
train: epoch 109, loss 0.06797268986701965, acc=0.9801111221313477, loss=0.06797268986701965
test: epoch 109, loss 0.19357839226722717, acc=0.9333333373069763, loss=0.19357839226722717
train: epoch 110, loss 0.056933868676424026, acc=0.9838333129882812, loss=0.056933868676424026
test: epoch 110, loss 0.2521958351135254, acc=0.9305555820465088, loss=0.2521958351135254
train: epoch 111, loss 0.06365474313497543, acc=0.9801111221313477, loss=0.06365474313497543
test: epoch 111, loss 0.17870913445949554, acc=0.9333333373069763, loss=0.17870913445949554
train: epoch 112, loss 0.07424961775541306, acc=0.9777777791023254, loss=0.07424961775541306
test: epoch 112, loss 0.23158302903175354, acc=0.9305555820465088, loss=0.23158302903175354
train: epoch 113, loss 0.0466170459985733, acc=0.9849444627761841, loss=0.0466170459985733
test: epoch 113, loss 0.1635214388370514, acc=0.9333333373069763, loss=0.1635214388370514
train: epoch 114, loss 0.053703758865594864, acc=0.9834444522857666, loss=0.053703758865594864
test: epoch 114, loss 0.224395751953125, acc=0.9333333373069763, loss=0.224395751953125
train: epoch 115, loss 0.06572549045085907, acc=0.9795555472373962, loss=0.06572549045085907
test: epoch 115, loss 0.20214103162288666, acc=0.9333333373069763, loss=0.20214103162288666
train: epoch 116, loss 0.055732131004333496, acc=0.9842222332954407, loss=0.055732131004333496
test: epoch 116, loss 0.2291393280029297, acc=0.9361110925674438, loss=0.2291393280029297
train: epoch 117, loss 0.0599091500043869, acc=0.9814444184303284, loss=0.0599091500043869
test: epoch 117, loss 0.20301023125648499, acc=0.9333333373069763, loss=0.20301023125648499
train: epoch 118, loss 0.05441771075129509, acc=0.9834444522857666, loss=0.05441771075129509
test: epoch 118, loss 0.20368283987045288, acc=0.9361110925674438, loss=0.20368283987045288
train: epoch 119, loss 0.0560128279030323, acc=0.9830555319786072, loss=0.0560128279030323
test: epoch 119, loss 0.21169082820415497, acc=0.9361110925674438, loss=0.21169082820415497
train: epoch 120, loss 0.060179635882377625, acc=0.9808889031410217, loss=0.060179635882377625
test: epoch 120, loss 0.18084441125392914, acc=0.9361110925674438, loss=0.18084441125392914
train: epoch 121, loss 0.052962590008974075, acc=0.9838888645172119, loss=0.052962590008974075
test: epoch 121, loss 0.21872836351394653, acc=0.9361110925674438, loss=0.21872836351394653
train: epoch 122, loss 0.05324523523449898, acc=0.9835000038146973, loss=0.05324523523449898
test: epoch 122, loss 0.19987723231315613, acc=0.9333333373069763, loss=0.19987723231315613
train: epoch 123, loss 0.056349579244852066, acc=0.9817222356796265, loss=0.056349579244852066
test: epoch 123, loss 0.16760151088237762, acc=0.9361110925674438, loss=0.16760151088237762
train: epoch 124, loss 0.04788752645254135, acc=0.9857222437858582, loss=0.04788752645254135
test: epoch 124, loss 0.21679861843585968, acc=0.9361110925674438, loss=0.21679861843585968
train: epoch 125, loss 0.0563875176012516, acc=0.9826111197471619, loss=0.0563875176012516
test: epoch 125, loss 0.14311864972114563, acc=0.9361110925674438, loss=0.14311864972114563
train: epoch 126, loss 0.056935057044029236, acc=0.9829999804496765, loss=0.056935057044029236
test: epoch 126, loss 0.18731196224689484, acc=0.9361110925674438, loss=0.18731196224689484
train: epoch 127, loss 0.06381788104772568, acc=0.9766666889190674, loss=0.06381788104772568
test: epoch 127, loss 0.19492626190185547, acc=0.9361110925674438, loss=0.19492626190185547
train: epoch 128, loss 0.056039657443761826, acc=0.9836111068725586, loss=0.056039657443761826
test: epoch 128, loss 0.18212853372097015, acc=0.9361110925674438, loss=0.18212853372097015
train: epoch 129, loss 0.05743776261806488, acc=0.9836111068725586, loss=0.05743776261806488
test: epoch 129, loss 0.20088382065296173, acc=0.9361110925674438, loss=0.20088382065296173
train: epoch 130, loss 0.05007769167423248, acc=0.9840555787086487, loss=0.05007769167423248
test: epoch 130, loss 0.2414892464876175, acc=0.9333333373069763, loss=0.2414892464876175
train: epoch 131, loss 0.049392834305763245, acc=0.9848333597183228, loss=0.049392834305763245
test: epoch 131, loss 0.1894921064376831, acc=0.9361110925674438, loss=0.1894921064376831
train: epoch 132, loss 0.0480160154402256, acc=0.9854999780654907, loss=0.0480160154402256
test: epoch 132, loss 0.23190563917160034, acc=0.9361110925674438, loss=0.23190563917160034
train: epoch 133, loss 0.05374181270599365, acc=0.9836111068725586, loss=0.05374181270599365
test: epoch 133, loss 0.17467094957828522, acc=0.9361110925674438, loss=0.17467094957828522
train: epoch 134, loss 0.05411599949002266, acc=0.9836666584014893, loss=0.05411599949002266
test: epoch 134, loss 0.1888064742088318, acc=0.9333333373069763, loss=0.1888064742088318
train: epoch 135, loss 0.059248246252536774, acc=0.9820555448532104, loss=0.059248246252536774
test: epoch 135, loss 0.20227941870689392, acc=0.9361110925674438, loss=0.20227941870689392
train: epoch 136, loss 0.039151277393102646, acc=0.9877777695655823, loss=0.039151277393102646
test: epoch 136, loss 0.2517452836036682, acc=0.9361110925674438, loss=0.2517452836036682
train: epoch 137, loss 0.04943203926086426, acc=0.984666645526886, loss=0.04943203926086426
test: epoch 137, loss 0.16551025211811066, acc=0.9361110925674438, loss=0.16551025211811066
train: epoch 138, loss 0.059866417199373245, acc=0.9815000295639038, loss=0.059866417199373245
test: epoch 138, loss 0.1959669142961502, acc=0.9361110925674438, loss=0.1959669142961502
train: epoch 139, loss 0.07891550660133362, acc=0.9783889055252075, loss=0.07891550660133362
test: epoch 139, loss 0.19013583660125732, acc=0.9333333373069763, loss=0.19013583660125732
train: epoch 140, loss 0.0523078478872776, acc=0.9849444627761841, loss=0.0523078478872776
test: epoch 140, loss 0.19503864645957947, acc=0.9361110925674438, loss=0.19503864645957947
train: epoch 141, loss 0.04908927530050278, acc=0.9854999780654907, loss=0.04908927530050278
test: epoch 141, loss 0.1617535650730133, acc=0.9361110925674438, loss=0.1617535650730133
train: epoch 142, loss 0.05427519977092743, acc=0.9850000143051147, loss=0.05427519977092743
test: epoch 142, loss 0.2237531542778015, acc=0.9333333373069763, loss=0.2237531542778015
train: epoch 143, loss 0.05077101290225983, acc=0.9861666560173035, loss=0.05077101290225983
test: epoch 143, loss 0.21099065244197845, acc=0.9361110925674438, loss=0.21099065244197845
train: epoch 144, loss 0.04616793245077133, acc=0.9863333106040955, loss=0.04616793245077133
test: epoch 144, loss 0.20559269189834595, acc=0.9361110925674438, loss=0.20559269189834595
train: epoch 145, loss 0.04229327663779259, acc=0.9869999885559082, loss=0.04229327663779259
test: epoch 145, loss 0.1731162965297699, acc=0.9361110925674438, loss=0.1731162965297699
train: epoch 146, loss 0.05258776620030403, acc=0.9852777719497681, loss=0.05258776620030403
test: epoch 146, loss 0.23834773898124695, acc=0.9361110925674438, loss=0.23834773898124695
train: epoch 147, loss 0.039138711988925934, acc=0.988277792930603, loss=0.039138711988925934
test: epoch 147, loss 0.17037072777748108, acc=0.9333333373069763, loss=0.17037072777748108
train: epoch 148, loss 0.05146127939224243, acc=0.9838888645172119, loss=0.05146127939224243
test: epoch 148, loss 0.15196429193019867, acc=0.9361110925674438, loss=0.15196429193019867
train: epoch 149, loss 0.03918548673391342, acc=0.9883333444595337, loss=0.03918548673391342
test: epoch 149, loss 0.21354283392429352, acc=0.9361110925674438, loss=0.21354283392429352
train: epoch 150, loss 0.05244453251361847, acc=0.9860555529594421, loss=0.05244453251361847
test: epoch 150, loss 0.17806708812713623, acc=0.9361110925674438, loss=0.17806708812713623
