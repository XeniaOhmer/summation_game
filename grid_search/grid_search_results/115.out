# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=1", "--temp_decay=0.995", "--one_hot=true", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1696440741, receiver_embed_dim=128, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.963789463043213, acc=0.08922222256660461, loss=2.963789463043213
test: epoch 1, loss 2.3023085594177246, acc=0.16944444179534912, loss=2.3023085594177246
train: epoch 2, loss 1.7459067106246948, acc=0.30250000953674316, loss=1.7459067106246948
test: epoch 2, loss 1.7738444805145264, acc=0.24722221493721008, loss=1.7738444805145264
train: epoch 3, loss 1.3237062692642212, acc=0.4313333332538605, loss=1.3237062692642212
test: epoch 3, loss 1.6853797435760498, acc=0.28611111640930176, loss=1.6853797435760498
train: epoch 4, loss 1.1269214153289795, acc=0.496277779340744, loss=1.1269214153289795
test: epoch 4, loss 1.729525089263916, acc=0.2944444417953491, loss=1.729525089263916
train: epoch 5, loss 1.0498113632202148, acc=0.5309444665908813, loss=1.0498113632202148
test: epoch 5, loss 1.6655161380767822, acc=0.3055555522441864, loss=1.6655161380767822
train: epoch 6, loss 0.9813066720962524, acc=0.5575000047683716, loss=0.9813066720962524
test: epoch 6, loss 1.881813406944275, acc=0.31111112236976624, loss=1.881813406944275
train: epoch 7, loss 0.9437238574028015, acc=0.565833330154419, loss=0.9437238574028015
test: epoch 7, loss 1.962579369544983, acc=0.3055555522441864, loss=1.962579369544983
train: epoch 8, loss 0.9030582308769226, acc=0.5741666555404663, loss=0.9030582308769226
test: epoch 8, loss 1.9285489320755005, acc=0.3194444477558136, loss=1.9285489320755005
train: epoch 9, loss 0.8830263614654541, acc=0.5856666564941406, loss=0.8830263614654541
test: epoch 9, loss 1.9218814373016357, acc=0.32777777314186096, loss=1.9218814373016357
train: epoch 10, loss 0.8862535357475281, acc=0.5838888883590698, loss=0.8862535357475281
test: epoch 10, loss 1.9855972528457642, acc=0.3222222328186035, loss=1.9855972528457642
train: epoch 11, loss 0.8691098690032959, acc=0.5841110944747925, loss=0.8691098690032959
test: epoch 11, loss 1.9322439432144165, acc=0.3361110985279083, loss=1.9322439432144165
train: epoch 12, loss 0.8512091040611267, acc=0.5928333401679993, loss=0.8512091040611267
test: epoch 12, loss 1.781159520149231, acc=0.35277777910232544, loss=1.781159520149231
train: epoch 13, loss 0.8494608998298645, acc=0.6019444465637207, loss=0.8494608998298645
test: epoch 13, loss 1.7456763982772827, acc=0.35555556416511536, loss=1.7456763982772827
train: epoch 14, loss 0.8361743688583374, acc=0.6101111173629761, loss=0.8361743688583374
test: epoch 14, loss 1.8879671096801758, acc=0.3472222089767456, loss=1.8879671096801758
train: epoch 15, loss 0.8460263013839722, acc=0.6114444732666016, loss=0.8460263013839722
test: epoch 15, loss 1.731356143951416, acc=0.36666667461395264, loss=1.731356143951416
train: epoch 16, loss 0.8333303928375244, acc=0.6122778058052063, loss=0.8333303928375244
test: epoch 16, loss 1.8730952739715576, acc=0.36944442987442017, loss=1.8730952739715576
train: epoch 17, loss 0.8131316304206848, acc=0.6181111335754395, loss=0.8131316304206848
test: epoch 17, loss 1.8505288362503052, acc=0.36666667461395264, loss=1.8505288362503052
train: epoch 18, loss 0.8179126381874084, acc=0.6176111102104187, loss=0.8179126381874084
test: epoch 18, loss 1.7671890258789062, acc=0.36944442987442017, loss=1.7671890258789062
train: epoch 19, loss 0.8149263262748718, acc=0.617222249507904, loss=0.8149263262748718
test: epoch 19, loss 1.808469295501709, acc=0.3722222149372101, loss=1.808469295501709
train: epoch 20, loss 0.8032456636428833, acc=0.6256666779518127, loss=0.8032456636428833
test: epoch 20, loss 1.8542914390563965, acc=0.3861111104488373, loss=1.8542914390563965
train: epoch 21, loss 0.8000812530517578, acc=0.6202222108840942, loss=0.8000812530517578
test: epoch 21, loss 1.731235146522522, acc=0.3722222149372101, loss=1.731235146522522
train: epoch 22, loss 0.7928405404090881, acc=0.6268888711929321, loss=0.7928405404090881
test: epoch 22, loss 1.762510061264038, acc=0.39444443583488464, loss=1.762510061264038
train: epoch 23, loss 0.7877566814422607, acc=0.6286666393280029, loss=0.7877566814422607
test: epoch 23, loss 1.7694668769836426, acc=0.38333332538604736, loss=1.7694668769836426
train: epoch 24, loss 0.7927044034004211, acc=0.6228333115577698, loss=0.7927044034004211
test: epoch 24, loss 1.6968801021575928, acc=0.39722222089767456, loss=1.6968801021575928
train: epoch 25, loss 0.7810657024383545, acc=0.63227778673172, loss=0.7810657024383545
test: epoch 25, loss 1.72866690158844, acc=0.4027777910232544, loss=1.72866690158844
train: epoch 26, loss 0.782513439655304, acc=0.6357222199440002, loss=0.782513439655304
test: epoch 26, loss 1.756698489189148, acc=0.3888888955116272, loss=1.756698489189148
train: epoch 27, loss 0.7616390585899353, acc=0.6388888955116272, loss=0.7616390585899353
test: epoch 27, loss 1.6116011142730713, acc=0.4027777910232544, loss=1.6116011142730713
train: epoch 28, loss 0.7784045338630676, acc=0.6276666522026062, loss=0.7784045338630676
test: epoch 28, loss 1.6535682678222656, acc=0.4027777910232544, loss=1.6535682678222656
train: epoch 29, loss 0.7771482467651367, acc=0.6318888664245605, loss=0.7771482467651367
test: epoch 29, loss 1.7207659482955933, acc=0.4000000059604645, loss=1.7207659482955933
train: epoch 30, loss 0.7532236576080322, acc=0.6448333263397217, loss=0.7532236576080322
test: epoch 30, loss 1.9535739421844482, acc=0.4000000059604645, loss=1.9535739421844482
train: epoch 31, loss 0.7427959442138672, acc=0.6504999995231628, loss=0.7427959442138672
test: epoch 31, loss 1.74463951587677, acc=0.4000000059604645, loss=1.74463951587677
train: epoch 32, loss 0.7377927899360657, acc=0.6577777862548828, loss=0.7377927899360657
test: epoch 32, loss 1.5624260902404785, acc=0.4027777910232544, loss=1.5624260902404785
train: epoch 33, loss 0.7540184259414673, acc=0.647777795791626, loss=0.7540184259414673
test: epoch 33, loss 1.6996612548828125, acc=0.41111111640930176, loss=1.6996612548828125
train: epoch 34, loss 0.7501114010810852, acc=0.6499444246292114, loss=0.7501114010810852
test: epoch 34, loss 1.6254055500030518, acc=0.4027777910232544, loss=1.6254055500030518
train: epoch 35, loss 0.7375136613845825, acc=0.6543333530426025, loss=0.7375136613845825
test: epoch 35, loss 1.6051952838897705, acc=0.4138889014720917, loss=1.6051952838897705
train: epoch 36, loss 0.739115297794342, acc=0.6517778038978577, loss=0.739115297794342
test: epoch 36, loss 1.7854459285736084, acc=0.42500001192092896, loss=1.7854459285736084
train: epoch 37, loss 0.736650824546814, acc=0.6588333249092102, loss=0.736650824546814
test: epoch 37, loss 1.705756664276123, acc=0.4166666567325592, loss=1.705756664276123
train: epoch 38, loss 0.7317878603935242, acc=0.6562777757644653, loss=0.7317878603935242
test: epoch 38, loss 1.686179280281067, acc=0.42222222685813904, loss=1.686179280281067
train: epoch 39, loss 0.7175703048706055, acc=0.6626111268997192, loss=0.7175703048706055
test: epoch 39, loss 1.6925508975982666, acc=0.4277777671813965, loss=1.6925508975982666
train: epoch 40, loss 0.7405244708061218, acc=0.6566110849380493, loss=0.7405244708061218
test: epoch 40, loss 1.769816279411316, acc=0.42222222685813904, loss=1.769816279411316
train: epoch 41, loss 0.7278232574462891, acc=0.6591110825538635, loss=0.7278232574462891
test: epoch 41, loss 1.5664056539535522, acc=0.42222222685813904, loss=1.5664056539535522
train: epoch 42, loss 0.7331058979034424, acc=0.6573888659477234, loss=0.7331058979034424
test: epoch 42, loss 1.7418887615203857, acc=0.41111111640930176, loss=1.7418887615203857
train: epoch 43, loss 0.7451621294021606, acc=0.6491110920906067, loss=0.7451621294021606
test: epoch 43, loss 1.5989634990692139, acc=0.41111111640930176, loss=1.5989634990692139
train: epoch 44, loss 0.7177241444587708, acc=0.6602222323417664, loss=0.7177241444587708
test: epoch 44, loss 1.6811615228652954, acc=0.4166666567325592, loss=1.6811615228652954
train: epoch 45, loss 0.7488259077072144, acc=0.6513333320617676, loss=0.7488259077072144
test: epoch 45, loss 1.6527315378189087, acc=0.4194444417953491, loss=1.6527315378189087
train: epoch 46, loss 0.7133052945137024, acc=0.6639999747276306, loss=0.7133052945137024
test: epoch 46, loss 1.6929833889007568, acc=0.42222222685813904, loss=1.6929833889007568
train: epoch 47, loss 0.7262394428253174, acc=0.6561111211776733, loss=0.7262394428253174
test: epoch 47, loss 1.5902167558670044, acc=0.4333333373069763, loss=1.5902167558670044
train: epoch 48, loss 0.7272703647613525, acc=0.6581110954284668, loss=0.7272703647613525
test: epoch 48, loss 1.5673394203186035, acc=0.4333333373069763, loss=1.5673394203186035
train: epoch 49, loss 0.7111449837684631, acc=0.6612777709960938, loss=0.7111449837684631
test: epoch 49, loss 1.6650421619415283, acc=0.43611112236976624, loss=1.6650421619415283
train: epoch 50, loss 0.7153968214988708, acc=0.6648889183998108, loss=0.7153968214988708
test: epoch 50, loss 1.6557873487472534, acc=0.4333333373069763, loss=1.6557873487472534
train: epoch 51, loss 0.7263156175613403, acc=0.6572777628898621, loss=0.7263156175613403
test: epoch 51, loss 1.5158799886703491, acc=0.4333333373069763, loss=1.5158799886703491
train: epoch 52, loss 0.7167773246765137, acc=0.660444438457489, loss=0.7167773246765137
test: epoch 52, loss 1.6829605102539062, acc=0.43888887763023376, loss=1.6829605102539062
train: epoch 53, loss 0.7161198258399963, acc=0.6607221961021423, loss=0.7161198258399963
test: epoch 53, loss 1.6076771020889282, acc=0.4333333373069763, loss=1.6076771020889282
train: epoch 54, loss 0.7223541736602783, acc=0.6572222113609314, loss=0.7223541736602783
test: epoch 54, loss 1.601544737815857, acc=0.43888887763023376, loss=1.601544737815857
train: epoch 55, loss 0.7030265927314758, acc=0.6656666398048401, loss=0.7030265927314758
test: epoch 55, loss 1.824825406074524, acc=0.4333333373069763, loss=1.824825406074524
train: epoch 56, loss 0.7159398794174194, acc=0.6632221937179565, loss=0.7159398794174194
test: epoch 56, loss 1.4686508178710938, acc=0.43611112236976624, loss=1.4686508178710938
train: epoch 57, loss 0.7203909754753113, acc=0.663611114025116, loss=0.7203909754753113
test: epoch 57, loss 1.5973787307739258, acc=0.4333333373069763, loss=1.5973787307739258
train: epoch 58, loss 0.7169083952903748, acc=0.659333348274231, loss=0.7169083952903748
test: epoch 58, loss 1.710421085357666, acc=0.4305555522441864, loss=1.710421085357666
train: epoch 59, loss 0.7131210565567017, acc=0.6616666913032532, loss=0.7131210565567017
test: epoch 59, loss 1.645451545715332, acc=0.43611112236976624, loss=1.645451545715332
train: epoch 60, loss 0.7181682586669922, acc=0.6627777814865112, loss=0.7181682586669922
test: epoch 60, loss 1.7164623737335205, acc=0.4333333373069763, loss=1.7164623737335205
train: epoch 61, loss 0.7117223143577576, acc=0.6534444689750671, loss=0.7117223143577576
test: epoch 61, loss 1.6440562009811401, acc=0.43888887763023376, loss=1.6440562009811401
train: epoch 62, loss 0.7073650360107422, acc=0.6613333225250244, loss=0.7073650360107422
test: epoch 62, loss 1.5715620517730713, acc=0.4333333373069763, loss=1.5715620517730713
train: epoch 63, loss 0.6985007524490356, acc=0.6652222275733948, loss=0.6985007524490356
test: epoch 63, loss 1.7430247068405151, acc=0.4333333373069763, loss=1.7430247068405151
train: epoch 64, loss 0.6897587180137634, acc=0.667722225189209, loss=0.6897587180137634
test: epoch 64, loss 1.6032427549362183, acc=0.4333333373069763, loss=1.6032427549362183
train: epoch 65, loss 0.7157061696052551, acc=0.6623333096504211, loss=0.7157061696052551
test: epoch 65, loss 1.5367624759674072, acc=0.4333333373069763, loss=1.5367624759674072
train: epoch 66, loss 0.710247278213501, acc=0.6609444618225098, loss=0.710247278213501
test: epoch 66, loss 1.596435785293579, acc=0.43611112236976624, loss=1.596435785293579
train: epoch 67, loss 0.7038925886154175, acc=0.6674444675445557, loss=0.7038925886154175
test: epoch 67, loss 1.7074344158172607, acc=0.4333333373069763, loss=1.7074344158172607
train: epoch 68, loss 0.6999568343162537, acc=0.6679999828338623, loss=0.6999568343162537
test: epoch 68, loss 1.6517058610916138, acc=0.4333333373069763, loss=1.6517058610916138
train: epoch 69, loss 0.7247377038002014, acc=0.6603333353996277, loss=0.7247377038002014
test: epoch 69, loss 1.689579963684082, acc=0.4333333373069763, loss=1.689579963684082
train: epoch 70, loss 0.6815526485443115, acc=0.6704999804496765, loss=0.6815526485443115
test: epoch 70, loss 1.6425625085830688, acc=0.4333333373069763, loss=1.6425625085830688
train: epoch 71, loss 0.6840655207633972, acc=0.6747221946716309, loss=0.6840655207633972
test: epoch 71, loss 1.7361799478530884, acc=0.4333333373069763, loss=1.7361799478530884
train: epoch 72, loss 0.7047914266586304, acc=0.6618333458900452, loss=0.7047914266586304
test: epoch 72, loss 1.6793091297149658, acc=0.4333333373069763, loss=1.6793091297149658
train: epoch 73, loss 0.6717832088470459, acc=0.6732777953147888, loss=0.6717832088470459
test: epoch 73, loss 1.7544294595718384, acc=0.4333333373069763, loss=1.7544294595718384
train: epoch 74, loss 0.6931508183479309, acc=0.6710000038146973, loss=0.6931508183479309
test: epoch 74, loss 1.613899827003479, acc=0.4305555522441864, loss=1.613899827003479
train: epoch 75, loss 0.6815567016601562, acc=0.6736666560173035, loss=0.6815567016601562
test: epoch 75, loss 1.6833209991455078, acc=0.4305555522441864, loss=1.6833209991455078
train: epoch 76, loss 0.6796611547470093, acc=0.6745555400848389, loss=0.6796611547470093
test: epoch 76, loss 1.729135513305664, acc=0.4333333373069763, loss=1.729135513305664
train: epoch 77, loss 0.6643238663673401, acc=0.679444432258606, loss=0.6643238663673401
test: epoch 77, loss 1.5682651996612549, acc=0.4333333373069763, loss=1.5682651996612549
train: epoch 78, loss 0.6727704405784607, acc=0.675944447517395, loss=0.6727704405784607
test: epoch 78, loss 1.902581810951233, acc=0.4333333373069763, loss=1.902581810951233
train: epoch 79, loss 0.6834697723388672, acc=0.6722221970558167, loss=0.6834697723388672
test: epoch 79, loss 1.6390130519866943, acc=0.4305555522441864, loss=1.6390130519866943
train: epoch 80, loss 0.6848604083061218, acc=0.6737222075462341, loss=0.6848604083061218
test: epoch 80, loss 1.6989775896072388, acc=0.4305555522441864, loss=1.6989775896072388
train: epoch 81, loss 0.6777527928352356, acc=0.676277756690979, loss=0.6777527928352356
test: epoch 81, loss 1.7233214378356934, acc=0.4138889014720917, loss=1.7233214378356934
train: epoch 82, loss 0.6801806688308716, acc=0.6753888726234436, loss=0.6801806688308716
test: epoch 82, loss 1.6795681715011597, acc=0.4305555522441864, loss=1.6795681715011597
train: epoch 83, loss 0.6912780404090881, acc=0.6697221994400024, loss=0.6912780404090881
test: epoch 83, loss 1.6269243955612183, acc=0.43611112236976624, loss=1.6269243955612183
train: epoch 84, loss 0.6784409284591675, acc=0.6709444522857666, loss=0.6784409284591675
test: epoch 84, loss 1.6946591138839722, acc=0.4277777671813965, loss=1.6946591138839722
train: epoch 85, loss 0.6629472374916077, acc=0.6822222471237183, loss=0.6629472374916077
test: epoch 85, loss 1.6518199443817139, acc=0.43888887763023376, loss=1.6518199443817139
train: epoch 86, loss 0.6715498566627502, acc=0.6782222390174866, loss=0.6715498566627502
test: epoch 86, loss 1.5990427732467651, acc=0.45277777314186096, loss=1.5990427732467651
train: epoch 87, loss 0.6480404734611511, acc=0.6865000128746033, loss=0.6480404734611511
test: epoch 87, loss 1.8152742385864258, acc=0.44999998807907104, loss=1.8152742385864258
train: epoch 88, loss 0.6473925113677979, acc=0.691777765750885, loss=0.6473925113677979
test: epoch 88, loss 1.642080545425415, acc=0.45277777314186096, loss=1.642080545425415
train: epoch 89, loss 0.6307262182235718, acc=0.6945000290870667, loss=0.6307262182235718
test: epoch 89, loss 1.6502314805984497, acc=0.4833333194255829, loss=1.6502314805984497
train: epoch 90, loss 0.6319116950035095, acc=0.6956666707992554, loss=0.6319116950035095
test: epoch 90, loss 1.4903889894485474, acc=0.4888888895511627, loss=1.4903889894485474
train: epoch 91, loss 0.6236792206764221, acc=0.6958333253860474, loss=0.6236792206764221
test: epoch 91, loss 1.5316771268844604, acc=0.5, loss=1.5316771268844604
train: epoch 92, loss 0.6296421885490417, acc=0.695111095905304, loss=0.6296421885490417
test: epoch 92, loss 1.5406392812728882, acc=0.4972222149372101, loss=1.5406392812728882
train: epoch 93, loss 0.6323426961898804, acc=0.6981666684150696, loss=0.6323426961898804
test: epoch 93, loss 1.4437761306762695, acc=0.5055555701255798, loss=1.4437761306762695
train: epoch 94, loss 0.6195788979530334, acc=0.7008333206176758, loss=0.6195788979530334
test: epoch 94, loss 1.4693444967269897, acc=0.5166666507720947, loss=1.4693444967269897
train: epoch 95, loss 0.609631359577179, acc=0.7035555839538574, loss=0.609631359577179
test: epoch 95, loss 1.4545055627822876, acc=0.5277777910232544, loss=1.4545055627822876
train: epoch 96, loss 0.6207295060157776, acc=0.7012222409248352, loss=0.6207295060157776
test: epoch 96, loss 1.3821462392807007, acc=0.5388888716697693, loss=1.3821462392807007
train: epoch 97, loss 0.5977781414985657, acc=0.7086111307144165, loss=0.5977781414985657
test: epoch 97, loss 1.3540914058685303, acc=0.5361111164093018, loss=1.3540914058685303
train: epoch 98, loss 0.5737798810005188, acc=0.7133333086967468, loss=0.5737798810005188
test: epoch 98, loss 1.3221262693405151, acc=0.5416666865348816, loss=1.3221262693405151
train: epoch 99, loss 0.6094753742218018, acc=0.7091110944747925, loss=0.6094753742218018
test: epoch 99, loss 1.2465180158615112, acc=0.5444444417953491, loss=1.2465180158615112
train: epoch 100, loss 0.5760873556137085, acc=0.7178333401679993, loss=0.5760873556137085
test: epoch 100, loss 1.2890503406524658, acc=0.5472221970558167, loss=1.2890503406524658
train: epoch 101, loss 0.5671352744102478, acc=0.7181110978126526, loss=0.5671352744102478
test: epoch 101, loss 1.356286644935608, acc=0.550000011920929, loss=1.356286644935608
train: epoch 102, loss 0.5554671883583069, acc=0.7232221961021423, loss=0.5554671883583069
test: epoch 102, loss 1.4173393249511719, acc=0.550000011920929, loss=1.4173393249511719
train: epoch 103, loss 0.5482879281044006, acc=0.725944459438324, loss=0.5482879281044006
test: epoch 103, loss 1.3723411560058594, acc=0.5527777671813965, loss=1.3723411560058594
train: epoch 104, loss 0.5503883957862854, acc=0.7272777557373047, loss=0.5503883957862854
test: epoch 104, loss 1.227123737335205, acc=0.5388888716697693, loss=1.227123737335205
train: epoch 105, loss 0.563071072101593, acc=0.7257221937179565, loss=0.563071072101593
test: epoch 105, loss 1.366150975227356, acc=0.5555555820465088, loss=1.366150975227356
train: epoch 106, loss 0.5597357153892517, acc=0.7285555601119995, loss=0.5597357153892517
test: epoch 106, loss 1.366583228111267, acc=0.5583333373069763, loss=1.366583228111267
train: epoch 107, loss 0.5550136566162109, acc=0.7313888669013977, loss=0.5550136566162109
test: epoch 107, loss 1.2941884994506836, acc=0.5666666626930237, loss=1.2941884994506836
train: epoch 108, loss 0.5423028469085693, acc=0.7369999885559082, loss=0.5423028469085693
test: epoch 108, loss 1.2612602710723877, acc=0.5833333134651184, loss=1.2612602710723877
train: epoch 109, loss 0.520310640335083, acc=0.7473333477973938, loss=0.520310640335083
test: epoch 109, loss 1.2918494939804077, acc=0.5916666388511658, loss=1.2918494939804077
train: epoch 110, loss 0.5367212891578674, acc=0.7459999918937683, loss=0.5367212891578674
test: epoch 110, loss 1.1183655261993408, acc=0.6000000238418579, loss=1.1183655261993408
train: epoch 111, loss 0.5381366610527039, acc=0.7382222414016724, loss=0.5381366610527039
test: epoch 111, loss 1.1922425031661987, acc=0.6000000238418579, loss=1.1922425031661987
train: epoch 112, loss 0.5038638710975647, acc=0.7525555491447449, loss=0.5038638710975647
test: epoch 112, loss 1.2219840288162231, acc=0.5972222089767456, loss=1.2219840288162231
train: epoch 113, loss 0.5120136141777039, acc=0.7526111006736755, loss=0.5120136141777039
test: epoch 113, loss 1.042716145515442, acc=0.6027777791023254, loss=1.042716145515442
train: epoch 114, loss 0.5080764889717102, acc=0.7558333277702332, loss=0.5080764889717102
test: epoch 114, loss 0.9998762011528015, acc=0.6166666746139526, loss=0.9998762011528015
train: epoch 115, loss 0.49607256054878235, acc=0.7595000267028809, loss=0.49607256054878235
test: epoch 115, loss 1.0598502159118652, acc=0.6222222447395325, loss=1.0598502159118652
train: epoch 116, loss 0.48338180780410767, acc=0.7711111307144165, loss=0.48338180780410767
test: epoch 116, loss 0.9520897269248962, acc=0.6388888955116272, loss=0.9520897269248962
train: epoch 117, loss 0.47097834944725037, acc=0.7706666588783264, loss=0.47097834944725037
test: epoch 117, loss 0.9882974624633789, acc=0.6388888955116272, loss=0.9882974624633789
train: epoch 118, loss 0.46324941515922546, acc=0.773722231388092, loss=0.46324941515922546
test: epoch 118, loss 0.9992680549621582, acc=0.6416666507720947, loss=0.9992680549621582
train: epoch 119, loss 0.44569432735443115, acc=0.7782777547836304, loss=0.44569432735443115
test: epoch 119, loss 1.011968731880188, acc=0.6416666507720947, loss=1.011968731880188
train: epoch 120, loss 0.4379776418209076, acc=0.7788888812065125, loss=0.4379776418209076
test: epoch 120, loss 1.0646257400512695, acc=0.644444465637207, loss=1.0646257400512695
train: epoch 121, loss 0.45279720425605774, acc=0.7760555744171143, loss=0.45279720425605774
test: epoch 121, loss 0.9424830079078674, acc=0.644444465637207, loss=0.9424830079078674
train: epoch 122, loss 0.4403371810913086, acc=0.7782777547836304, loss=0.4403371810913086
test: epoch 122, loss 1.018399715423584, acc=0.644444465637207, loss=1.018399715423584
train: epoch 123, loss 0.445199191570282, acc=0.7761666774749756, loss=0.445199191570282
test: epoch 123, loss 0.9554043412208557, acc=0.644444465637207, loss=0.9554043412208557
train: epoch 124, loss 0.44155898690223694, acc=0.7817222476005554, loss=0.44155898690223694
test: epoch 124, loss 1.0171840190887451, acc=0.644444465637207, loss=1.0171840190887451
train: epoch 125, loss 0.4552654027938843, acc=0.7787777781486511, loss=0.4552654027938843
test: epoch 125, loss 0.956484854221344, acc=0.6499999761581421, loss=0.956484854221344
train: epoch 126, loss 0.4536462128162384, acc=0.7741666436195374, loss=0.4536462128162384
test: epoch 126, loss 1.0043416023254395, acc=0.6499999761581421, loss=1.0043416023254395
train: epoch 127, loss 0.42720675468444824, acc=0.7849444150924683, loss=0.42720675468444824
test: epoch 127, loss 0.9811984896659851, acc=0.6638888716697693, loss=0.9811984896659851
train: epoch 128, loss 0.4262201488018036, acc=0.7905555367469788, loss=0.4262201488018036
test: epoch 128, loss 0.855034589767456, acc=0.6722221970558167, loss=0.855034589767456
train: epoch 129, loss 0.4090974032878876, acc=0.7944444417953491, loss=0.4090974032878876
test: epoch 129, loss 1.0318819284439087, acc=0.6722221970558167, loss=1.0318819284439087
train: epoch 130, loss 0.42066261172294617, acc=0.7935555577278137, loss=0.42066261172294617
test: epoch 130, loss 0.9679902791976929, acc=0.6722221970558167, loss=0.9679902791976929
train: epoch 131, loss 0.4087843894958496, acc=0.7943888902664185, loss=0.4087843894958496
test: epoch 131, loss 0.9778584837913513, acc=0.6722221970558167, loss=0.9778584837913513
train: epoch 132, loss 0.4033501148223877, acc=0.7960555553436279, loss=0.4033501148223877
test: epoch 132, loss 1.0508226156234741, acc=0.6722221970558167, loss=1.0508226156234741
train: epoch 133, loss 0.40396928787231445, acc=0.7952222228050232, loss=0.40396928787231445
test: epoch 133, loss 0.8855106830596924, acc=0.675000011920929, loss=0.8855106830596924
train: epoch 134, loss 0.4012184143066406, acc=0.7983888983726501, loss=0.4012184143066406
test: epoch 134, loss 1.0122382640838623, acc=0.6722221970558167, loss=1.0122382640838623
train: epoch 135, loss 0.4179514944553375, acc=0.7932778000831604, loss=0.4179514944553375
test: epoch 135, loss 0.813690185546875, acc=0.6694444417953491, loss=0.813690185546875
train: epoch 136, loss 0.41427192091941833, acc=0.7920555472373962, loss=0.41427192091941833
test: epoch 136, loss 0.9909418821334839, acc=0.6694444417953491, loss=0.9909418821334839
train: epoch 137, loss 0.4452019929885864, acc=0.7899444699287415, loss=0.4452019929885864
test: epoch 137, loss 0.872603714466095, acc=0.6694444417953491, loss=0.872603714466095
train: epoch 138, loss 0.4069872498512268, acc=0.7951111197471619, loss=0.4069872498512268
test: epoch 138, loss 0.9076948761940002, acc=0.6722221970558167, loss=0.9076948761940002
train: epoch 139, loss 0.4018406867980957, acc=0.7950000166893005, loss=0.4018406867980957
test: epoch 139, loss 1.0120701789855957, acc=0.6722221970558167, loss=1.0120701789855957
train: epoch 140, loss 0.40695545077323914, acc=0.795722246170044, loss=0.40695545077323914
test: epoch 140, loss 0.9516535401344299, acc=0.6722221970558167, loss=0.9516535401344299
train: epoch 141, loss 0.3994300961494446, acc=0.796500027179718, loss=0.3994300961494446
test: epoch 141, loss 0.9802609086036682, acc=0.6694444417953491, loss=0.9802609086036682
train: epoch 142, loss 0.39937829971313477, acc=0.7965555787086487, loss=0.39937829971313477
test: epoch 142, loss 0.8856776356697083, acc=0.6722221970558167, loss=0.8856776356697083
train: epoch 143, loss 0.39552584290504456, acc=0.7962222099304199, loss=0.39552584290504456
test: epoch 143, loss 0.8919011354446411, acc=0.6722221970558167, loss=0.8919011354446411
train: epoch 144, loss 0.4031071662902832, acc=0.7965555787086487, loss=0.4031071662902832
test: epoch 144, loss 0.9265314936637878, acc=0.6722221970558167, loss=0.9265314936637878
train: epoch 145, loss 0.41447797417640686, acc=0.7940555810928345, loss=0.41447797417640686
test: epoch 145, loss 0.9135406613349915, acc=0.6666666865348816, loss=0.9135406613349915
train: epoch 146, loss 0.42996764183044434, acc=0.7920555472373962, loss=0.42996764183044434
test: epoch 146, loss 0.9374780058860779, acc=0.6666666865348816, loss=0.9374780058860779
train: epoch 147, loss 0.43024155497550964, acc=0.7942222356796265, loss=0.43024155497550964
test: epoch 147, loss 0.9661412835121155, acc=0.6694444417953491, loss=0.9661412835121155
train: epoch 148, loss 0.4200088679790497, acc=0.7933333516120911, loss=0.4200088679790497
test: epoch 148, loss 0.9156232476234436, acc=0.675000011920929, loss=0.9156232476234436
train: epoch 149, loss 0.4074436128139496, acc=0.7983888983726501, loss=0.4074436128139496
test: epoch 149, loss 0.9375483393669128, acc=0.6694444417953491, loss=0.9375483393669128
train: epoch 150, loss 0.40636613965034485, acc=0.7973889112472534, loss=0.40636613965034485
test: epoch 150, loss 0.9223555326461792, acc=0.6694444417953491, loss=0.9223555326461792
