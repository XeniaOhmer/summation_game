# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=0.99", "--one_hot=true", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=508396762, receiver_embed_dim=32, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.028762102127075, acc=0.07422222197055817, loss=3.028762102127075
test: epoch 1, loss 4.136484622955322, acc=0.08611111342906952, loss=4.136484622955322
train: epoch 2, loss 2.11797833442688, acc=0.1982777714729309, loss=2.11797833442688
test: epoch 2, loss 4.269053936004639, acc=0.09444444626569748, loss=4.269053936004639
train: epoch 3, loss 1.7550511360168457, acc=0.27399998903274536, loss=1.7550511360168457
test: epoch 3, loss 3.190178155899048, acc=0.20000000298023224, loss=3.190178155899048
train: epoch 4, loss 1.5326497554779053, acc=0.33222222328186035, loss=1.5326497554779053
test: epoch 4, loss 3.7496495246887207, acc=0.17222222685813904, loss=3.7496495246887207
train: epoch 5, loss 1.3819420337677002, acc=0.38555556535720825, loss=1.3819420337677002
test: epoch 5, loss 2.790895700454712, acc=0.22777777910232544, loss=2.790895700454712
train: epoch 6, loss 1.29340398311615, acc=0.4122222363948822, loss=1.29340398311615
test: epoch 6, loss 2.8606879711151123, acc=0.21111111342906952, loss=2.8606879711151123
train: epoch 7, loss 1.1906626224517822, acc=0.46149998903274536, loss=1.1906626224517822
test: epoch 7, loss 2.9419524669647217, acc=0.23055554926395416, loss=2.9419524669647217
train: epoch 8, loss 1.1415027379989624, acc=0.48622220754623413, loss=1.1415027379989624
test: epoch 8, loss 2.651583433151245, acc=0.2638888955116272, loss=2.651583433151245
train: epoch 9, loss 1.0223186016082764, acc=0.5521666407585144, loss=1.0223186016082764
test: epoch 9, loss 3.076803207397461, acc=0.28611111640930176, loss=3.076803207397461
train: epoch 10, loss 1.0134735107421875, acc=0.5530555844306946, loss=1.0134735107421875
test: epoch 10, loss 3.0294137001037598, acc=0.24166665971279144, loss=3.0294137001037598
train: epoch 11, loss 0.9007493853569031, acc=0.6081666946411133, loss=0.9007493853569031
test: epoch 11, loss 3.1349759101867676, acc=0.21944443881511688, loss=3.1349759101867676
train: epoch 12, loss 0.8791363835334778, acc=0.6119999885559082, loss=0.8791363835334778
test: epoch 12, loss 2.8021130561828613, acc=0.2750000059604645, loss=2.8021130561828613
train: epoch 13, loss 0.8116561770439148, acc=0.6478888988494873, loss=0.8116561770439148
test: epoch 13, loss 2.6379151344299316, acc=0.31388887763023376, loss=2.6379151344299316
train: epoch 14, loss 0.7335619926452637, acc=0.6821110844612122, loss=0.7335619926452637
test: epoch 14, loss 2.5820095539093018, acc=0.3472222089767456, loss=2.5820095539093018
train: epoch 15, loss 0.7213080525398254, acc=0.6821110844612122, loss=0.7213080525398254
test: epoch 15, loss 2.381185293197632, acc=0.4000000059604645, loss=2.381185293197632
train: epoch 16, loss 0.6558088660240173, acc=0.7138333320617676, loss=0.6558088660240173
test: epoch 16, loss 2.302377462387085, acc=0.3638888895511627, loss=2.302377462387085
train: epoch 17, loss 0.6110084652900696, acc=0.7317222356796265, loss=0.6110084652900696
test: epoch 17, loss 2.093405246734619, acc=0.4027777910232544, loss=2.093405246734619
train: epoch 18, loss 0.595145583152771, acc=0.7418888807296753, loss=0.595145583152771
test: epoch 18, loss 2.3602490425109863, acc=0.35277777910232544, loss=2.3602490425109863
train: epoch 19, loss 0.5730092525482178, acc=0.7521111369132996, loss=0.5730092525482178
test: epoch 19, loss 1.8232195377349854, acc=0.3888888955116272, loss=1.8232195377349854
train: epoch 20, loss 0.5642762184143066, acc=0.7581111192703247, loss=0.5642762184143066
test: epoch 20, loss 1.8976479768753052, acc=0.39722222089767456, loss=1.8976479768753052
train: epoch 21, loss 0.5546741485595703, acc=0.7606666684150696, loss=0.5546741485595703
test: epoch 21, loss 2.2026588916778564, acc=0.3722222149372101, loss=2.2026588916778564
train: epoch 22, loss 0.48775801062583923, acc=0.7878333330154419, loss=0.48775801062583923
test: epoch 22, loss 1.8380495309829712, acc=0.4055555462837219, loss=1.8380495309829712
train: epoch 23, loss 0.48833200335502625, acc=0.7908333539962769, loss=0.48833200335502625
test: epoch 23, loss 1.768876314163208, acc=0.4416666626930237, loss=1.768876314163208
train: epoch 24, loss 0.47963422536849976, acc=0.7932222485542297, loss=0.47963422536849976
test: epoch 24, loss 1.8794831037521362, acc=0.4166666567325592, loss=1.8794831037521362
train: epoch 25, loss 0.4166311025619507, acc=0.816777765750885, loss=0.4166311025619507
test: epoch 25, loss 1.6797279119491577, acc=0.5027777552604675, loss=1.6797279119491577
train: epoch 26, loss 0.42024877667427063, acc=0.816611111164093, loss=0.42024877667427063
test: epoch 26, loss 1.3893251419067383, acc=0.5333333611488342, loss=1.3893251419067383
train: epoch 27, loss 0.4219234585762024, acc=0.8138889074325562, loss=0.4219234585762024
test: epoch 27, loss 1.9856998920440674, acc=0.39722222089767456, loss=1.9856998920440674
train: epoch 28, loss 0.408711701631546, acc=0.8217222094535828, loss=0.408711701631546
test: epoch 28, loss 1.3681364059448242, acc=0.5388888716697693, loss=1.3681364059448242
train: epoch 29, loss 0.40241310000419617, acc=0.8239444494247437, loss=0.40241310000419617
test: epoch 29, loss 1.3386497497558594, acc=0.5583333373069763, loss=1.3386497497558594
train: epoch 30, loss 0.40356504917144775, acc=0.824999988079071, loss=0.40356504917144775
test: epoch 30, loss 1.7429187297821045, acc=0.46666666865348816, loss=1.7429187297821045
train: epoch 31, loss 0.4086398184299469, acc=0.823722243309021, loss=0.4086398184299469
test: epoch 31, loss 1.4106162786483765, acc=0.5833333134651184, loss=1.4106162786483765
train: epoch 32, loss 0.38794466853141785, acc=0.8277778029441833, loss=0.38794466853141785
test: epoch 32, loss 1.3802955150604248, acc=0.4694444537162781, loss=1.3802955150604248
train: epoch 33, loss 0.3792150914669037, acc=0.8316110968589783, loss=0.3792150914669037
test: epoch 33, loss 1.2183434963226318, acc=0.5277777910232544, loss=1.2183434963226318
train: epoch 34, loss 0.3639048933982849, acc=0.8387222290039062, loss=0.3639048933982849
test: epoch 34, loss 1.327501654624939, acc=0.5361111164093018, loss=1.327501654624939
train: epoch 35, loss 0.3643307387828827, acc=0.840833306312561, loss=0.3643307387828827
test: epoch 35, loss 1.4004356861114502, acc=0.5805555582046509, loss=1.4004356861114502
train: epoch 36, loss 0.347922682762146, acc=0.8468888998031616, loss=0.347922682762146
test: epoch 36, loss 1.0458766222000122, acc=0.6388888955116272, loss=1.0458766222000122
train: epoch 37, loss 0.3603792190551758, acc=0.8463888764381409, loss=0.3603792190551758
test: epoch 37, loss 0.9371545910835266, acc=0.644444465637207, loss=0.9371545910835266
train: epoch 38, loss 0.3175322115421295, acc=0.8588888645172119, loss=0.3175322115421295
test: epoch 38, loss 1.1125303506851196, acc=0.6611111164093018, loss=1.1125303506851196
train: epoch 39, loss 0.3269353210926056, acc=0.8581666946411133, loss=0.3269353210926056
test: epoch 39, loss 1.0469694137573242, acc=0.6861110925674438, loss=1.0469694137573242
train: epoch 40, loss 0.3340773582458496, acc=0.852222204208374, loss=0.3340773582458496
test: epoch 40, loss 1.1125717163085938, acc=0.625, loss=1.1125717163085938
train: epoch 41, loss 0.3180282711982727, acc=0.8603333234786987, loss=0.3180282711982727
test: epoch 41, loss 1.015342354774475, acc=0.7138888835906982, loss=1.015342354774475
train: epoch 42, loss 0.30913016200065613, acc=0.8615000247955322, loss=0.30913016200065613
test: epoch 42, loss 0.6927102208137512, acc=0.7027778029441833, loss=0.6927102208137512
train: epoch 43, loss 0.32831481099128723, acc=0.8558889031410217, loss=0.32831481099128723
test: epoch 43, loss 0.8824602365493774, acc=0.7222222089767456, loss=0.8824602365493774
train: epoch 44, loss 0.2909053862094879, acc=0.867388904094696, loss=0.2909053862094879
test: epoch 44, loss 0.6357653737068176, acc=0.7555555701255798, loss=0.6357653737068176
train: epoch 45, loss 0.30418291687965393, acc=0.8653333187103271, loss=0.30418291687965393
test: epoch 45, loss 0.8199676871299744, acc=0.6916666626930237, loss=0.8199676871299744
train: epoch 46, loss 0.2923888564109802, acc=0.8687222003936768, loss=0.2923888564109802
test: epoch 46, loss 0.5160006880760193, acc=0.7805555462837219, loss=0.5160006880760193
train: epoch 47, loss 0.26509132981300354, acc=0.887333333492279, loss=0.26509132981300354
test: epoch 47, loss 0.6570228934288025, acc=0.7222222089767456, loss=0.6570228934288025
train: epoch 48, loss 0.23274782299995422, acc=0.9024999737739563, loss=0.23274782299995422
test: epoch 48, loss 0.68010413646698, acc=0.7888888716697693, loss=0.68010413646698
train: epoch 49, loss 0.22642874717712402, acc=0.9054444432258606, loss=0.22642874717712402
test: epoch 49, loss 0.5447015166282654, acc=0.7777777910232544, loss=0.5447015166282654
train: epoch 50, loss 0.19218288362026215, acc=0.9171110987663269, loss=0.19218288362026215
test: epoch 50, loss 0.6125884652137756, acc=0.8027777671813965, loss=0.6125884652137756
train: epoch 51, loss 0.20669673383235931, acc=0.9112777709960938, loss=0.20669673383235931
test: epoch 51, loss 0.5699391961097717, acc=0.769444465637207, loss=0.5699391961097717
train: epoch 52, loss 0.21365584433078766, acc=0.9092222452163696, loss=0.21365584433078766
test: epoch 52, loss 0.5205708146095276, acc=0.8166666626930237, loss=0.5205708146095276
train: epoch 53, loss 0.20887689292430878, acc=0.9105555415153503, loss=0.20887689292430878
test: epoch 53, loss 0.5619945526123047, acc=0.7972221970558167, loss=0.5619945526123047
train: epoch 54, loss 0.19295723736286163, acc=0.9156666398048401, loss=0.19295723736286163
test: epoch 54, loss 0.6996302008628845, acc=0.7972221970558167, loss=0.6996302008628845
train: epoch 55, loss 0.19270245730876923, acc=0.9158889055252075, loss=0.19270245730876923
test: epoch 55, loss 0.4383576512336731, acc=0.8194444179534912, loss=0.4383576512336731
train: epoch 56, loss 0.19018934667110443, acc=0.9164999723434448, loss=0.19018934667110443
test: epoch 56, loss 0.7000897526741028, acc=0.7861111164093018, loss=0.7000897526741028
train: epoch 57, loss 0.21057184040546417, acc=0.9103888869285583, loss=0.21057184040546417
test: epoch 57, loss 0.6692127585411072, acc=0.8027777671813965, loss=0.6692127585411072
train: epoch 58, loss 0.19029942154884338, acc=0.9161111116409302, loss=0.19029942154884338
test: epoch 58, loss 0.6195411086082458, acc=0.8083333373069763, loss=0.6195411086082458
train: epoch 59, loss 0.20267845690250397, acc=0.9143333435058594, loss=0.20267845690250397
test: epoch 59, loss 0.5341870188713074, acc=0.7916666865348816, loss=0.5341870188713074
train: epoch 60, loss 0.19562478363513947, acc=0.9144999980926514, loss=0.19562478363513947
test: epoch 60, loss 0.5446268916130066, acc=0.8027777671813965, loss=0.5446268916130066
train: epoch 61, loss 0.19604289531707764, acc=0.9122222065925598, loss=0.19604289531707764
test: epoch 61, loss 0.561346173286438, acc=0.8166666626930237, loss=0.561346173286438
train: epoch 62, loss 0.19245527684688568, acc=0.9165555834770203, loss=0.19245527684688568
test: epoch 62, loss 0.5205674767494202, acc=0.8083333373069763, loss=0.5205674767494202
train: epoch 63, loss 0.19311396777629852, acc=0.9133333563804626, loss=0.19311396777629852
test: epoch 63, loss 0.5231746435165405, acc=0.8111110925674438, loss=0.5231746435165405
train: epoch 64, loss 0.19005338847637177, acc=0.9121666550636292, loss=0.19005338847637177
test: epoch 64, loss 0.39729490876197815, acc=0.8111110925674438, loss=0.39729490876197815
train: epoch 65, loss 0.19118435680866241, acc=0.9133333563804626, loss=0.19118435680866241
test: epoch 65, loss 0.425072580575943, acc=0.8138889074325562, loss=0.425072580575943
train: epoch 66, loss 0.22185152769088745, acc=0.9034444689750671, loss=0.22185152769088745
test: epoch 66, loss 0.4096183776855469, acc=0.8083333373069763, loss=0.4096183776855469
train: epoch 67, loss 0.20731431245803833, acc=0.9088888764381409, loss=0.20731431245803833
test: epoch 67, loss 0.5029305219650269, acc=0.8194444179534912, loss=0.5029305219650269
train: epoch 68, loss 0.19932162761688232, acc=0.9116666913032532, loss=0.19932162761688232
test: epoch 68, loss 0.40433913469314575, acc=0.8222222328186035, loss=0.40433913469314575
train: epoch 69, loss 0.18255382776260376, acc=0.9170555472373962, loss=0.18255382776260376
test: epoch 69, loss 0.5165276527404785, acc=0.8166666626930237, loss=0.5165276527404785
train: epoch 70, loss 0.20750518143177032, acc=0.9103333353996277, loss=0.20750518143177032
test: epoch 70, loss 0.5798416137695312, acc=0.8055555820465088, loss=0.5798416137695312
train: epoch 71, loss 0.19110645353794098, acc=0.9119444489479065, loss=0.19110645353794098
test: epoch 71, loss 0.5198464393615723, acc=0.8222222328186035, loss=0.5198464393615723
train: epoch 72, loss 0.20955176651477814, acc=0.9108333587646484, loss=0.20955176651477814
test: epoch 72, loss 0.5217568278312683, acc=0.7944444417953491, loss=0.5217568278312683
train: epoch 73, loss 0.18673014640808105, acc=0.9184444546699524, loss=0.18673014640808105
test: epoch 73, loss 0.542789101600647, acc=0.8166666626930237, loss=0.542789101600647
train: epoch 74, loss 0.19253568351268768, acc=0.9148333072662354, loss=0.19253568351268768
test: epoch 74, loss 0.4380634129047394, acc=0.855555534362793, loss=0.4380634129047394
train: epoch 75, loss 0.20205390453338623, acc=0.9127222299575806, loss=0.20205390453338623
test: epoch 75, loss 0.32628509402275085, acc=0.8638888597488403, loss=0.32628509402275085
train: epoch 76, loss 0.1942916214466095, acc=0.9136666655540466, loss=0.1942916214466095
test: epoch 76, loss 0.4389941990375519, acc=0.8500000238418579, loss=0.4389941990375519
train: epoch 77, loss 0.20535704493522644, acc=0.9097777605056763, loss=0.20535704493522644
test: epoch 77, loss 0.3672349452972412, acc=0.8527777791023254, loss=0.3672349452972412
train: epoch 78, loss 0.17334745824337006, acc=0.9208889007568359, loss=0.17334745824337006
test: epoch 78, loss 0.30350184440612793, acc=0.875, loss=0.30350184440612793
train: epoch 79, loss 0.17540737986564636, acc=0.9185555577278137, loss=0.17540737986564636
test: epoch 79, loss 0.3302045166492462, acc=0.8333333134651184, loss=0.3302045166492462
train: epoch 80, loss 0.19983544945716858, acc=0.9124444723129272, loss=0.19983544945716858
test: epoch 80, loss 0.28112658858299255, acc=0.8666666746139526, loss=0.28112658858299255
train: epoch 81, loss 0.19734826683998108, acc=0.9116666913032532, loss=0.19734826683998108
test: epoch 81, loss 0.30574101209640503, acc=0.8638888597488403, loss=0.30574101209640503
train: epoch 82, loss 0.2215348780155182, acc=0.9010000228881836, loss=0.2215348780155182
test: epoch 82, loss 0.31874367594718933, acc=0.8611111044883728, loss=0.31874367594718933
train: epoch 83, loss 0.17457528412342072, acc=0.918833315372467, loss=0.17457528412342072
test: epoch 83, loss 0.38459423184394836, acc=0.8611111044883728, loss=0.38459423184394836
train: epoch 84, loss 0.1966671645641327, acc=0.9133333563804626, loss=0.1966671645641327
test: epoch 84, loss 0.2961682677268982, acc=0.8638888597488403, loss=0.2961682677268982
train: epoch 85, loss 0.21461108326911926, acc=0.9045000076293945, loss=0.21461108326911926
test: epoch 85, loss 0.2632327675819397, acc=0.8694444298744202, loss=0.2632327675819397
train: epoch 86, loss 0.19348637759685516, acc=0.9108889102935791, loss=0.19348637759685516
test: epoch 86, loss 0.31276634335517883, acc=0.8666666746139526, loss=0.31276634335517883
train: epoch 87, loss 0.20103810727596283, acc=0.9086111187934875, loss=0.20103810727596283
test: epoch 87, loss 0.31908613443374634, acc=0.8666666746139526, loss=0.31908613443374634
train: epoch 88, loss 0.18854697048664093, acc=0.9142777919769287, loss=0.18854697048664093
test: epoch 88, loss 0.3886505365371704, acc=0.8638888597488403, loss=0.3886505365371704
train: epoch 89, loss 0.19602395594120026, acc=0.9053888916969299, loss=0.19602395594120026
test: epoch 89, loss 0.2568814754486084, acc=0.8666666746139526, loss=0.2568814754486084
train: epoch 90, loss 0.1872342824935913, acc=0.9044444561004639, loss=0.1872342824935913
test: epoch 90, loss 0.2699149549007416, acc=0.8638888597488403, loss=0.2699149549007416
train: epoch 91, loss 0.2096925526857376, acc=0.9007777571678162, loss=0.2096925526857376
test: epoch 91, loss 0.34498700499534607, acc=0.8611111044883728, loss=0.34498700499534607
train: epoch 92, loss 0.2080075442790985, acc=0.9077777862548828, loss=0.2080075442790985
test: epoch 92, loss 0.30202916264533997, acc=0.8638888597488403, loss=0.30202916264533997
train: epoch 93, loss 0.2157324254512787, acc=0.9005555510520935, loss=0.2157324254512787
test: epoch 93, loss 0.2367195039987564, acc=0.8666666746139526, loss=0.2367195039987564
train: epoch 94, loss 0.2044830173254013, acc=0.8963333368301392, loss=0.2044830173254013
test: epoch 94, loss 0.29691463708877563, acc=0.8666666746139526, loss=0.29691463708877563
train: epoch 95, loss 0.18978235125541687, acc=0.9051666855812073, loss=0.18978235125541687
test: epoch 95, loss 0.28351402282714844, acc=0.8666666746139526, loss=0.28351402282714844
train: epoch 96, loss 0.2029964178800583, acc=0.8986666798591614, loss=0.2029964178800583
test: epoch 96, loss 0.26942864060401917, acc=0.8722222447395325, loss=0.26942864060401917
train: epoch 97, loss 0.19221921265125275, acc=0.898888885974884, loss=0.19221921265125275
test: epoch 97, loss 0.22333967685699463, acc=0.875, loss=0.22333967685699463
train: epoch 98, loss 0.21697932481765747, acc=0.8996111154556274, loss=0.21697932481765747
test: epoch 98, loss 0.24995185434818268, acc=0.875, loss=0.24995185434818268
train: epoch 99, loss 0.18784579634666443, acc=0.9016110897064209, loss=0.18784579634666443
test: epoch 99, loss 0.2795799672603607, acc=0.875, loss=0.2795799672603607
train: epoch 100, loss 0.17363572120666504, acc=0.903166651725769, loss=0.17363572120666504
test: epoch 100, loss 0.2408829629421234, acc=0.8666666746139526, loss=0.2408829629421234
train: epoch 101, loss 0.20745669305324554, acc=0.8957777619361877, loss=0.20745669305324554
test: epoch 101, loss 0.20394368469715118, acc=0.8722222447395325, loss=0.20394368469715118
train: epoch 102, loss 0.21001198887825012, acc=0.8940555453300476, loss=0.21001198887825012
test: epoch 102, loss 0.3044166564941406, acc=0.8694444298744202, loss=0.3044166564941406
train: epoch 103, loss 0.19739659130573273, acc=0.8970000147819519, loss=0.19739659130573273
test: epoch 103, loss 0.25071123242378235, acc=0.8722222447395325, loss=0.25071123242378235
train: epoch 104, loss 0.2074219435453415, acc=0.894944429397583, loss=0.2074219435453415
test: epoch 104, loss 0.23545393347740173, acc=0.875, loss=0.23545393347740173
train: epoch 105, loss 0.1708093285560608, acc=0.903333306312561, loss=0.1708093285560608
test: epoch 105, loss 0.2418472319841385, acc=0.875, loss=0.2418472319841385
train: epoch 106, loss 0.24161089956760406, acc=0.8782777786254883, loss=0.24161089956760406
test: epoch 106, loss 0.24996724724769592, acc=0.8694444298744202, loss=0.24996724724769592
train: epoch 107, loss 0.19401726126670837, acc=0.8978888988494873, loss=0.19401726126670837
test: epoch 107, loss 0.2340061217546463, acc=0.8722222447395325, loss=0.2340061217546463
train: epoch 108, loss 0.1907198280096054, acc=0.898277759552002, loss=0.1907198280096054
test: epoch 108, loss 0.32659345865249634, acc=0.8694444298744202, loss=0.32659345865249634
train: epoch 109, loss 0.19800592958927155, acc=0.8966666460037231, loss=0.19800592958927155
test: epoch 109, loss 0.43545371294021606, acc=0.8583333492279053, loss=0.43545371294021606
train: epoch 110, loss 0.1818525195121765, acc=0.9027777910232544, loss=0.1818525195121765
test: epoch 110, loss 0.2865753769874573, acc=0.8666666746139526, loss=0.2865753769874573
train: epoch 111, loss 0.19194553792476654, acc=0.8991666436195374, loss=0.19194553792476654
test: epoch 111, loss 0.2478703409433365, acc=0.875, loss=0.2478703409433365
train: epoch 112, loss 0.20645339787006378, acc=0.8939444422721863, loss=0.20645339787006378
test: epoch 112, loss 0.24488747119903564, acc=0.875, loss=0.24488747119903564
train: epoch 113, loss 0.217309832572937, acc=0.8827221989631653, loss=0.217309832572937
test: epoch 113, loss 0.24504831433296204, acc=0.8583333492279053, loss=0.24504831433296204
train: epoch 114, loss 0.23573322594165802, acc=0.8764444589614868, loss=0.23573322594165802
test: epoch 114, loss 0.4192652106285095, acc=0.8416666388511658, loss=0.4192652106285095
train: epoch 115, loss 0.20745807886123657, acc=0.8846111297607422, loss=0.20745807886123657
test: epoch 115, loss 0.27746760845184326, acc=0.8611111044883728, loss=0.27746760845184326
train: epoch 116, loss 0.20949898660182953, acc=0.8854444622993469, loss=0.20949898660182953
test: epoch 116, loss 0.2508426606655121, acc=0.8583333492279053, loss=0.2508426606655121
train: epoch 117, loss 0.22826620936393738, acc=0.8804444670677185, loss=0.22826620936393738
test: epoch 117, loss 0.2730328440666199, acc=0.855555534362793, loss=0.2730328440666199
train: epoch 118, loss 0.22045476734638214, acc=0.8820555806159973, loss=0.22045476734638214
test: epoch 118, loss 0.2569628953933716, acc=0.8583333492279053, loss=0.2569628953933716
train: epoch 119, loss 0.23949569463729858, acc=0.8737778067588806, loss=0.23949569463729858
test: epoch 119, loss 0.3047582507133484, acc=0.8500000238418579, loss=0.3047582507133484
train: epoch 120, loss 0.25122785568237305, acc=0.8702777624130249, loss=0.25122785568237305
test: epoch 120, loss 0.3077744245529175, acc=0.8500000238418579, loss=0.3077744245529175
train: epoch 121, loss 0.27292564511299133, acc=0.8623889088630676, loss=0.27292564511299133
test: epoch 121, loss 0.29076382517814636, acc=0.8416666388511658, loss=0.29076382517814636
train: epoch 122, loss 0.2868732511997223, acc=0.8592777848243713, loss=0.2868732511997223
test: epoch 122, loss 0.3842194676399231, acc=0.8222222328186035, loss=0.3842194676399231
train: epoch 123, loss 0.24277378618717194, acc=0.8696110844612122, loss=0.24277378618717194
test: epoch 123, loss 0.23411567509174347, acc=0.8611111044883728, loss=0.23411567509174347
train: epoch 124, loss 0.2103031724691391, acc=0.883388876914978, loss=0.2103031724691391
test: epoch 124, loss 0.2510615587234497, acc=0.8611111044883728, loss=0.2510615587234497
train: epoch 125, loss 0.21712327003479004, acc=0.8830000162124634, loss=0.21712327003479004
test: epoch 125, loss 0.3001018762588501, acc=0.8583333492279053, loss=0.3001018762588501
train: epoch 126, loss 0.204172745347023, acc=0.8846111297607422, loss=0.204172745347023
test: epoch 126, loss 0.33179038763046265, acc=0.8500000238418579, loss=0.33179038763046265
train: epoch 127, loss 0.22121009230613708, acc=0.8817222118377686, loss=0.22121009230613708
test: epoch 127, loss 0.28030556440353394, acc=0.8611111044883728, loss=0.28030556440353394
train: epoch 128, loss 0.2012852430343628, acc=0.8848333358764648, loss=0.2012852430343628
test: epoch 128, loss 0.27017027139663696, acc=0.8611111044883728, loss=0.27017027139663696
train: epoch 129, loss 0.22079318761825562, acc=0.8806666731834412, loss=0.22079318761825562
test: epoch 129, loss 0.2842172086238861, acc=0.8583333492279053, loss=0.2842172086238861
train: epoch 130, loss 0.20730741322040558, acc=0.8842777609825134, loss=0.20730741322040558
test: epoch 130, loss 0.28309696912765503, acc=0.8611111044883728, loss=0.28309696912765503
train: epoch 131, loss 0.22802746295928955, acc=0.878777801990509, loss=0.22802746295928955
test: epoch 131, loss 0.37175700068473816, acc=0.8222222328186035, loss=0.37175700068473816
train: epoch 132, loss 0.2703019082546234, acc=0.8687222003936768, loss=0.2703019082546234
test: epoch 132, loss 0.30334851145744324, acc=0.8527777791023254, loss=0.30334851145744324
train: epoch 133, loss 0.25522539019584656, acc=0.8718888759613037, loss=0.25522539019584656
test: epoch 133, loss 0.30922478437423706, acc=0.855555534362793, loss=0.30922478437423706
train: epoch 134, loss 0.23048724234104156, acc=0.8736666440963745, loss=0.23048724234104156
test: epoch 134, loss 0.33480748534202576, acc=0.8527777791023254, loss=0.33480748534202576
train: epoch 135, loss 0.22133038938045502, acc=0.8771111369132996, loss=0.22133038938045502
test: epoch 135, loss 0.29679277539253235, acc=0.8527777791023254, loss=0.29679277539253235
train: epoch 136, loss 0.2744527757167816, acc=0.8642222285270691, loss=0.2744527757167816
test: epoch 136, loss 0.2473834604024887, acc=0.8500000238418579, loss=0.2473834604024887
train: epoch 137, loss 0.23461724817752838, acc=0.8744999766349792, loss=0.23461724817752838
test: epoch 137, loss 0.4312174618244171, acc=0.8527777791023254, loss=0.4312174618244171
train: epoch 138, loss 0.22715458273887634, acc=0.8761110901832581, loss=0.22715458273887634
test: epoch 138, loss 0.27231907844543457, acc=0.855555534362793, loss=0.27231907844543457
train: epoch 139, loss 0.21061599254608154, acc=0.8803333044052124, loss=0.21061599254608154
test: epoch 139, loss 0.32573986053466797, acc=0.855555534362793, loss=0.32573986053466797
train: epoch 140, loss 0.24257656931877136, acc=0.8686110973358154, loss=0.24257656931877136
test: epoch 140, loss 0.27954474091529846, acc=0.8527777791023254, loss=0.27954474091529846
train: epoch 141, loss 0.24070049822330475, acc=0.8725000023841858, loss=0.24070049822330475
test: epoch 141, loss 0.29052022099494934, acc=0.855555534362793, loss=0.29052022099494934
train: epoch 142, loss 0.2101549208164215, acc=0.8796111345291138, loss=0.2101549208164215
test: epoch 142, loss 0.29097795486450195, acc=0.855555534362793, loss=0.29097795486450195
train: epoch 143, loss 0.23368540406227112, acc=0.8767222166061401, loss=0.23368540406227112
test: epoch 143, loss 0.2572856843471527, acc=0.855555534362793, loss=0.2572856843471527
train: epoch 144, loss 0.223510280251503, acc=0.8755000233650208, loss=0.223510280251503
test: epoch 144, loss 0.26697924733161926, acc=0.8527777791023254, loss=0.26697924733161926
train: epoch 145, loss 0.2355060577392578, acc=0.871666669845581, loss=0.2355060577392578
test: epoch 145, loss 0.30026283860206604, acc=0.8444444537162781, loss=0.30026283860206604
train: epoch 146, loss 0.23633946478366852, acc=0.871999979019165, loss=0.23633946478366852
test: epoch 146, loss 0.31716054677963257, acc=0.8500000238418579, loss=0.31716054677963257
train: epoch 147, loss 0.2540298402309418, acc=0.867111086845398, loss=0.2540298402309418
test: epoch 147, loss 0.3211970031261444, acc=0.8527777791023254, loss=0.3211970031261444
train: epoch 148, loss 0.22286410629749298, acc=0.8748888969421387, loss=0.22286410629749298
test: epoch 148, loss 0.3238285779953003, acc=0.8416666388511658, loss=0.3238285779953003
train: epoch 149, loss 0.265106737613678, acc=0.8690000176429749, loss=0.265106737613678
test: epoch 149, loss 0.27522554993629456, acc=0.8666666746139526, loss=0.27522554993629456
train: epoch 150, loss 0.18818987905979156, acc=0.8932222127914429, loss=0.18818987905979156
test: epoch 150, loss 0.22944258153438568, acc=0.8694444298744202, loss=0.22944258153438568
