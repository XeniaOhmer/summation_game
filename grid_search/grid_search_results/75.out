# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=1.5", "--temp_decay=1", "--one_hot=false", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=656331063, receiver_embed_dim=64, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.297013998031616, acc=0.0667777806520462, loss=3.297013998031616
test: epoch 1, loss 3.2362000942230225, acc=0.09444444626569748, loss=3.2362000942230225
train: epoch 2, loss 1.9949053525924683, acc=0.26777777075767517, loss=1.9949053525924683
test: epoch 2, loss 2.882838726043701, acc=0.13055555522441864, loss=2.882838726043701
train: epoch 3, loss 1.5500737428665161, acc=0.3739444315433502, loss=1.5500737428665161
test: epoch 3, loss 2.5503761768341064, acc=0.16944444179534912, loss=2.5503761768341064
train: epoch 4, loss 1.366430401802063, acc=0.4444444477558136, loss=1.366430401802063
test: epoch 4, loss 2.620049238204956, acc=0.18888889253139496, loss=2.620049238204956
train: epoch 5, loss 1.2433695793151855, acc=0.49772220849990845, loss=1.2433695793151855
test: epoch 5, loss 2.5589752197265625, acc=0.1944444477558136, loss=2.5589752197265625
train: epoch 6, loss 1.1554439067840576, acc=0.5302222371101379, loss=1.1554439067840576
test: epoch 6, loss 2.5494608879089355, acc=0.2083333283662796, loss=2.5494608879089355
train: epoch 7, loss 1.0767054557800293, acc=0.5690000057220459, loss=1.0767054557800293
test: epoch 7, loss 2.6289889812469482, acc=0.19722221791744232, loss=2.6289889812469482
train: epoch 8, loss 1.0149245262145996, acc=0.5986111164093018, loss=1.0149245262145996
test: epoch 8, loss 2.357454538345337, acc=0.23055554926395416, loss=2.357454538345337
train: epoch 9, loss 0.9587480425834656, acc=0.6227222084999084, loss=0.9587480425834656
test: epoch 9, loss 2.3912205696105957, acc=0.2361111044883728, loss=2.3912205696105957
train: epoch 10, loss 0.9069893956184387, acc=0.6435555815696716, loss=0.9069893956184387
test: epoch 10, loss 2.129509925842285, acc=0.2777777910232544, loss=2.129509925842285
train: epoch 11, loss 0.8565217852592468, acc=0.66438889503479, loss=0.8565217852592468
test: epoch 11, loss 2.1069869995117188, acc=0.28611111640930176, loss=2.1069869995117188
train: epoch 12, loss 0.8019963502883911, acc=0.6846666932106018, loss=0.8019963502883911
test: epoch 12, loss 2.0792715549468994, acc=0.2666666805744171, loss=2.0792715549468994
train: epoch 13, loss 0.773079514503479, acc=0.6981666684150696, loss=0.773079514503479
test: epoch 13, loss 2.1544430255889893, acc=0.2666666805744171, loss=2.1544430255889893
train: epoch 14, loss 0.7286696434020996, acc=0.7183889150619507, loss=0.7286696434020996
test: epoch 14, loss 1.829921007156372, acc=0.28333333134651184, loss=1.829921007156372
train: epoch 15, loss 0.6954872608184814, acc=0.7379444241523743, loss=0.6954872608184814
test: epoch 15, loss 2.026747941970825, acc=0.2944444417953491, loss=2.026747941970825
train: epoch 16, loss 0.6626115441322327, acc=0.7485555410385132, loss=0.6626115441322327
test: epoch 16, loss 1.8911980390548706, acc=0.3055555522441864, loss=1.8911980390548706
train: epoch 17, loss 0.6248549222946167, acc=0.7671111226081848, loss=0.6248549222946167
test: epoch 17, loss 1.9857983589172363, acc=0.2944444417953491, loss=1.9857983589172363
train: epoch 18, loss 0.6121542453765869, acc=0.7714999914169312, loss=0.6121542453765869
test: epoch 18, loss 1.8730013370513916, acc=0.3305555582046509, loss=1.8730013370513916
train: epoch 19, loss 0.5780194997787476, acc=0.7836666703224182, loss=0.5780194997787476
test: epoch 19, loss 1.9138944149017334, acc=0.3333333432674408, loss=1.9138944149017334
train: epoch 20, loss 0.5574692487716675, acc=0.7891111373901367, loss=0.5574692487716675
test: epoch 20, loss 1.9694610834121704, acc=0.3027777671813965, loss=1.9694610834121704
train: epoch 21, loss 0.5275493264198303, acc=0.800944447517395, loss=0.5275493264198303
test: epoch 21, loss 1.9258670806884766, acc=0.3333333432674408, loss=1.9258670806884766
train: epoch 22, loss 0.5097982883453369, acc=0.8092777729034424, loss=0.5097982883453369
test: epoch 22, loss 1.745398998260498, acc=0.3361110985279083, loss=1.745398998260498
train: epoch 23, loss 0.49969032406806946, acc=0.8145555257797241, loss=0.49969032406806946
test: epoch 23, loss 1.873724102973938, acc=0.36944442987442017, loss=1.873724102973938
train: epoch 24, loss 0.4733986556529999, acc=0.8209444284439087, loss=0.4733986556529999
test: epoch 24, loss 1.852981448173523, acc=0.3083333373069763, loss=1.852981448173523
train: epoch 25, loss 0.4515284597873688, acc=0.8298888802528381, loss=0.4515284597873688
test: epoch 25, loss 1.8679994344711304, acc=0.35555556416511536, loss=1.8679994344711304
train: epoch 26, loss 0.4422966539859772, acc=0.8349999785423279, loss=0.4422966539859772
test: epoch 26, loss 1.9067822694778442, acc=0.3499999940395355, loss=1.9067822694778442
train: epoch 27, loss 0.43004462122917175, acc=0.8414444327354431, loss=0.43004462122917175
test: epoch 27, loss 1.7927595376968384, acc=0.38055557012557983, loss=1.7927595376968384
train: epoch 28, loss 0.4150950014591217, acc=0.8497222065925598, loss=0.4150950014591217
test: epoch 28, loss 1.8229109048843384, acc=0.375, loss=1.8229109048843384
train: epoch 29, loss 0.4050564467906952, acc=0.8500555753707886, loss=0.4050564467906952
test: epoch 29, loss 1.8618344068527222, acc=0.3777777850627899, loss=1.8618344068527222
train: epoch 30, loss 0.3945583403110504, acc=0.8523889183998108, loss=0.3945583403110504
test: epoch 30, loss 1.9220707416534424, acc=0.3722222149372101, loss=1.9220707416534424
train: epoch 31, loss 0.38123637437820435, acc=0.8585000038146973, loss=0.38123637437820435
test: epoch 31, loss 1.7084968090057373, acc=0.39444443583488464, loss=1.7084968090057373
train: epoch 32, loss 0.3688339591026306, acc=0.8647222518920898, loss=0.3688339591026306
test: epoch 32, loss 1.7164819240570068, acc=0.43611112236976624, loss=1.7164819240570068
train: epoch 33, loss 0.3484794497489929, acc=0.8691666722297668, loss=0.3484794497489929
test: epoch 33, loss 2.0619466304779053, acc=0.3583333194255829, loss=2.0619466304779053
train: epoch 34, loss 0.3623698353767395, acc=0.8706666827201843, loss=0.3623698353767395
test: epoch 34, loss 1.811881184577942, acc=0.4166666567325592, loss=1.811881184577942
train: epoch 35, loss 0.3299820125102997, acc=0.8766666650772095, loss=0.3299820125102997
test: epoch 35, loss 1.9412795305252075, acc=0.4277777671813965, loss=1.9412795305252075
train: epoch 36, loss 0.32646238803863525, acc=0.8807777762413025, loss=0.32646238803863525
test: epoch 36, loss 1.8496501445770264, acc=0.4444444477558136, loss=1.8496501445770264
train: epoch 37, loss 0.3204609155654907, acc=0.8825555443763733, loss=0.3204609155654907
test: epoch 37, loss 1.8316881656646729, acc=0.39444443583488464, loss=1.8316881656646729
train: epoch 38, loss 0.31281578540802, acc=0.8846666812896729, loss=0.31281578540802
test: epoch 38, loss 1.8477885723114014, acc=0.42500001192092896, loss=1.8477885723114014
train: epoch 39, loss 0.3022044003009796, acc=0.8871666789054871, loss=0.3022044003009796
test: epoch 39, loss 2.112553596496582, acc=0.42500001192092896, loss=2.112553596496582
train: epoch 40, loss 0.30334603786468506, acc=0.8880000114440918, loss=0.30334603786468506
test: epoch 40, loss 1.8148281574249268, acc=0.44999998807907104, loss=1.8148281574249268
train: epoch 41, loss 0.292743444442749, acc=0.8901110887527466, loss=0.292743444442749
test: epoch 41, loss 1.9878109693527222, acc=0.41111111640930176, loss=1.9878109693527222
train: epoch 42, loss 0.28853142261505127, acc=0.895111083984375, loss=0.28853142261505127
test: epoch 42, loss 1.892761468887329, acc=0.4861111044883728, loss=1.892761468887329
train: epoch 43, loss 0.2881622612476349, acc=0.8958333134651184, loss=0.2881622612476349
test: epoch 43, loss 2.0138661861419678, acc=0.4027777910232544, loss=2.0138661861419678
train: epoch 44, loss 0.2777300477027893, acc=0.8995000123977661, loss=0.2777300477027893
test: epoch 44, loss 1.836692214012146, acc=0.45277777314186096, loss=1.836692214012146
train: epoch 45, loss 0.2767176926136017, acc=0.9012777805328369, loss=0.2767176926136017
test: epoch 45, loss 2.3598690032958984, acc=0.42500001192092896, loss=2.3598690032958984
train: epoch 46, loss 0.2834298014640808, acc=0.8977222442626953, loss=0.2834298014640808
test: epoch 46, loss 1.8201433420181274, acc=0.47777777910232544, loss=1.8201433420181274
train: epoch 47, loss 0.266965389251709, acc=0.9001111388206482, loss=0.266965389251709
test: epoch 47, loss 2.1517233848571777, acc=0.45277777314186096, loss=2.1517233848571777
train: epoch 48, loss 0.26663294434547424, acc=0.9001111388206482, loss=0.26663294434547424
test: epoch 48, loss 2.025062322616577, acc=0.44999998807907104, loss=2.025062322616577
train: epoch 49, loss 0.26658695936203003, acc=0.9044444561004639, loss=0.26658695936203003
test: epoch 49, loss 1.9500502347946167, acc=0.42222222685813904, loss=1.9500502347946167
train: epoch 50, loss 0.25909745693206787, acc=0.9046111106872559, loss=0.25909745693206787
test: epoch 50, loss 1.8999460935592651, acc=0.48055556416511536, loss=1.8999460935592651
train: epoch 51, loss 0.24601280689239502, acc=0.9089999794960022, loss=0.24601280689239502
test: epoch 51, loss 2.1382386684417725, acc=0.4555555582046509, loss=2.1382386684417725
train: epoch 52, loss 0.2452889084815979, acc=0.9088888764381409, loss=0.2452889084815979
test: epoch 52, loss 2.0742344856262207, acc=0.43611112236976624, loss=2.0742344856262207
train: epoch 53, loss 0.24387043714523315, acc=0.9084444642066956, loss=0.24387043714523315
test: epoch 53, loss 2.1326427459716797, acc=0.4194444417953491, loss=2.1326427459716797
train: epoch 54, loss 0.2361975461244583, acc=0.9113888740539551, loss=0.2361975461244583
test: epoch 54, loss 1.9044179916381836, acc=0.4722222089767456, loss=1.9044179916381836
train: epoch 55, loss 0.24617013335227966, acc=0.9096111059188843, loss=0.24617013335227966
test: epoch 55, loss 2.0102827548980713, acc=0.48055556416511536, loss=2.0102827548980713
train: epoch 56, loss 0.23123028874397278, acc=0.9120555520057678, loss=0.23123028874397278
test: epoch 56, loss 1.9585727453231812, acc=0.4749999940395355, loss=1.9585727453231812
train: epoch 57, loss 0.23406292498111725, acc=0.9144999980926514, loss=0.23406292498111725
test: epoch 57, loss 2.2530593872070312, acc=0.5083333253860474, loss=2.2530593872070312
train: epoch 58, loss 0.23144564032554626, acc=0.9143333435058594, loss=0.23144564032554626
test: epoch 58, loss 1.9197113513946533, acc=0.47777777910232544, loss=1.9197113513946533
train: epoch 59, loss 0.22937427461147308, acc=0.9147777557373047, loss=0.22937427461147308
test: epoch 59, loss 1.9587619304656982, acc=0.46388888359069824, loss=1.9587619304656982
train: epoch 60, loss 0.22709058225154877, acc=0.9174444675445557, loss=0.22709058225154877
test: epoch 60, loss 1.9475256204605103, acc=0.5027777552604675, loss=1.9475256204605103
train: epoch 61, loss 0.21915853023529053, acc=0.9193333387374878, loss=0.21915853023529053
test: epoch 61, loss 2.1630842685699463, acc=0.4472222328186035, loss=2.1630842685699463
train: epoch 62, loss 0.21097128093242645, acc=0.9209444522857666, loss=0.21097128093242645
test: epoch 62, loss 2.0715019702911377, acc=0.4583333432674408, loss=2.0715019702911377
train: epoch 63, loss 0.21985451877117157, acc=0.9185000061988831, loss=0.21985451877117157
test: epoch 63, loss 2.123077869415283, acc=0.4833333194255829, loss=2.123077869415283
train: epoch 64, loss 0.20838287472724915, acc=0.9224444627761841, loss=0.20838287472724915
test: epoch 64, loss 2.167733669281006, acc=0.4861111044883728, loss=2.167733669281006
train: epoch 65, loss 0.20441369712352753, acc=0.9238333106040955, loss=0.20441369712352753
test: epoch 65, loss 1.9020352363586426, acc=0.5111111402511597, loss=1.9020352363586426
train: epoch 66, loss 0.2103799432516098, acc=0.922166645526886, loss=0.2103799432516098
test: epoch 66, loss 2.0711867809295654, acc=0.48055556416511536, loss=2.0711867809295654
train: epoch 67, loss 0.1987939327955246, acc=0.9243333339691162, loss=0.1987939327955246
test: epoch 67, loss 1.7874195575714111, acc=0.5, loss=1.7874195575714111
train: epoch 68, loss 0.20754876732826233, acc=0.9229999780654907, loss=0.20754876732826233
test: epoch 68, loss 2.322418689727783, acc=0.4694444537162781, loss=2.322418689727783
train: epoch 69, loss 0.20299428701400757, acc=0.9237222075462341, loss=0.20299428701400757
test: epoch 69, loss 2.0187056064605713, acc=0.5055555701255798, loss=2.0187056064605713
train: epoch 70, loss 0.19269168376922607, acc=0.9266666769981384, loss=0.19269168376922607
test: epoch 70, loss 1.9211305379867554, acc=0.5083333253860474, loss=1.9211305379867554
train: epoch 71, loss 0.18655070662498474, acc=0.9288889169692993, loss=0.18655070662498474
test: epoch 71, loss 1.9160957336425781, acc=0.5, loss=1.9160957336425781
train: epoch 72, loss 0.19258622825145721, acc=0.9286110997200012, loss=0.19258622825145721
test: epoch 72, loss 2.2523257732391357, acc=0.4722222089767456, loss=2.2523257732391357
train: epoch 73, loss 0.18800176680088043, acc=0.9282222390174866, loss=0.18800176680088043
test: epoch 73, loss 2.1147074699401855, acc=0.5055555701255798, loss=2.1147074699401855
train: epoch 74, loss 0.19024470448493958, acc=0.9291666746139526, loss=0.19024470448493958
test: epoch 74, loss 1.7490874528884888, acc=0.5138888955116272, loss=1.7490874528884888
train: epoch 75, loss 0.18615511059761047, acc=0.9309444427490234, loss=0.18615511059761047
test: epoch 75, loss 2.296581745147705, acc=0.5138888955116272, loss=2.296581745147705
train: epoch 76, loss 0.1814793348312378, acc=0.9355000257492065, loss=0.1814793348312378
test: epoch 76, loss 1.8753703832626343, acc=0.5333333611488342, loss=1.8753703832626343
train: epoch 77, loss 0.18028244376182556, acc=0.933222234249115, loss=0.18028244376182556
test: epoch 77, loss 2.053370714187622, acc=0.5083333253860474, loss=2.053370714187622
train: epoch 78, loss 0.18223503232002258, acc=0.933722198009491, loss=0.18223503232002258
test: epoch 78, loss 2.3774466514587402, acc=0.5055555701255798, loss=2.3774466514587402
train: epoch 79, loss 0.18161322176456451, acc=0.9329444169998169, loss=0.18161322176456451
test: epoch 79, loss 2.092482089996338, acc=0.4833333194255829, loss=2.092482089996338
train: epoch 80, loss 0.17632263898849487, acc=0.9352777600288391, loss=0.17632263898849487
test: epoch 80, loss 2.1662418842315674, acc=0.5027777552604675, loss=2.1662418842315674
train: epoch 81, loss 0.17558811604976654, acc=0.9346110820770264, loss=0.17558811604976654
test: epoch 81, loss 1.888291835784912, acc=0.5166666507720947, loss=1.888291835784912
train: epoch 82, loss 0.1835087537765503, acc=0.9325555562973022, loss=0.1835087537765503
test: epoch 82, loss 2.0382611751556396, acc=0.5138888955116272, loss=2.0382611751556396
train: epoch 83, loss 0.17771324515342712, acc=0.933222234249115, loss=0.17771324515342712
test: epoch 83, loss 2.196225643157959, acc=0.5222222208976746, loss=2.196225643157959
train: epoch 84, loss 0.16963054239749908, acc=0.9361666440963745, loss=0.16963054239749908
test: epoch 84, loss 1.7992724180221558, acc=0.5277777910232544, loss=1.7992724180221558
train: epoch 85, loss 0.16157576441764832, acc=0.9391666650772095, loss=0.16157576441764832
test: epoch 85, loss 2.1401889324188232, acc=0.5249999761581421, loss=2.1401889324188232
train: epoch 86, loss 0.16760791838169098, acc=0.9360555410385132, loss=0.16760791838169098
test: epoch 86, loss 1.8941588401794434, acc=0.5722222328186035, loss=1.8941588401794434
train: epoch 87, loss 0.1712862253189087, acc=0.9374444484710693, loss=0.1712862253189087
test: epoch 87, loss 1.8982781171798706, acc=0.5055555701255798, loss=1.8982781171798706
train: epoch 88, loss 0.16958120465278625, acc=0.9373888969421387, loss=0.16958120465278625
test: epoch 88, loss 1.8695344924926758, acc=0.5361111164093018, loss=1.8695344924926758
train: epoch 89, loss 0.17014414072036743, acc=0.9364444613456726, loss=0.17014414072036743
test: epoch 89, loss 1.8295719623565674, acc=0.5555555820465088, loss=1.8295719623565674
train: epoch 90, loss 0.16706879436969757, acc=0.9382777810096741, loss=0.16706879436969757
test: epoch 90, loss 1.8681515455245972, acc=0.5305555462837219, loss=1.8681515455245972
train: epoch 91, loss 0.1627180427312851, acc=0.9390555620193481, loss=0.1627180427312851
test: epoch 91, loss 1.8907650709152222, acc=0.5666666626930237, loss=1.8907650709152222
train: epoch 92, loss 0.16675788164138794, acc=0.9380000233650208, loss=0.16675788164138794
test: epoch 92, loss 2.003732442855835, acc=0.5388888716697693, loss=2.003732442855835
train: epoch 93, loss 0.16233450174331665, acc=0.937166690826416, loss=0.16233450174331665
test: epoch 93, loss 1.9900254011154175, acc=0.5666666626930237, loss=1.9900254011154175
train: epoch 94, loss 0.1594618558883667, acc=0.9390555620193481, loss=0.1594618558883667
test: epoch 94, loss 2.0742268562316895, acc=0.5055555701255798, loss=2.0742268562316895
train: epoch 95, loss 0.15969061851501465, acc=0.9394444227218628, loss=0.15969061851501465
test: epoch 95, loss 2.2094552516937256, acc=0.5055555701255798, loss=2.2094552516937256
train: epoch 96, loss 0.16345295310020447, acc=0.9394444227218628, loss=0.16345295310020447
test: epoch 96, loss 1.9308686256408691, acc=0.5333333611488342, loss=1.9308686256408691
train: epoch 97, loss 0.1597089171409607, acc=0.941444456577301, loss=0.1597089171409607
test: epoch 97, loss 2.0881271362304688, acc=0.5444444417953491, loss=2.0881271362304688
train: epoch 98, loss 0.16191597282886505, acc=0.9406111240386963, loss=0.16191597282886505
test: epoch 98, loss 1.983260989189148, acc=0.5388888716697693, loss=1.983260989189148
train: epoch 99, loss 0.15167836844921112, acc=0.9422777891159058, loss=0.15167836844921112
test: epoch 99, loss 1.9384732246398926, acc=0.574999988079071, loss=1.9384732246398926
train: epoch 100, loss 0.14433464407920837, acc=0.9432222247123718, loss=0.14433464407920837
test: epoch 100, loss 1.9505105018615723, acc=0.5472221970558167, loss=1.9505105018615723
train: epoch 101, loss 0.15615397691726685, acc=0.9406111240386963, loss=0.15615397691726685
test: epoch 101, loss 2.0643632411956787, acc=0.5472221970558167, loss=2.0643632411956787
train: epoch 102, loss 0.14809836447238922, acc=0.9468888640403748, loss=0.14809836447238922
test: epoch 102, loss 2.089182138442993, acc=0.5694444179534912, loss=2.089182138442993
train: epoch 103, loss 0.1518632173538208, acc=0.9441666603088379, loss=0.1518632173538208
test: epoch 103, loss 1.9073072671890259, acc=0.5444444417953491, loss=1.9073072671890259
train: epoch 104, loss 0.1483636051416397, acc=0.9427777528762817, loss=0.1483636051416397
test: epoch 104, loss 2.074436902999878, acc=0.5777778029441833, loss=2.074436902999878
train: epoch 105, loss 0.15118171274662018, acc=0.9431111216545105, loss=0.15118171274662018
test: epoch 105, loss 1.9784654378890991, acc=0.5583333373069763, loss=1.9784654378890991
train: epoch 106, loss 0.13946300745010376, acc=0.9449999928474426, loss=0.13946300745010376
test: epoch 106, loss 2.2152388095855713, acc=0.5472221970558167, loss=2.2152388095855713
train: epoch 107, loss 0.15266063809394836, acc=0.9425555467605591, loss=0.15266063809394836
test: epoch 107, loss 2.0463249683380127, acc=0.5777778029441833, loss=2.0463249683380127
train: epoch 108, loss 0.15246394276618958, acc=0.9424999952316284, loss=0.15246394276618958
test: epoch 108, loss 1.9017870426177979, acc=0.5527777671813965, loss=1.9017870426177979
train: epoch 109, loss 0.1475355476140976, acc=0.9443888664245605, loss=0.1475355476140976
test: epoch 109, loss 2.23885440826416, acc=0.5527777671813965, loss=2.23885440826416
train: epoch 110, loss 0.1417360156774521, acc=0.9467222094535828, loss=0.1417360156774521
test: epoch 110, loss 1.9202646017074585, acc=0.5916666388511658, loss=1.9202646017074585
train: epoch 111, loss 0.14139333367347717, acc=0.9468333125114441, loss=0.14139333367347717
test: epoch 111, loss 2.1913504600524902, acc=0.5083333253860474, loss=2.1913504600524902
train: epoch 112, loss 0.14199940860271454, acc=0.94605553150177, loss=0.14199940860271454
test: epoch 112, loss 1.8453986644744873, acc=0.5638889074325562, loss=1.8453986644744873
train: epoch 113, loss 0.1395542472600937, acc=0.9438333511352539, loss=0.1395542472600937
test: epoch 113, loss 1.789733648300171, acc=0.5666666626930237, loss=1.789733648300171
train: epoch 114, loss 0.13742025196552277, acc=0.9463333487510681, loss=0.13742025196552277
test: epoch 114, loss 1.8406057357788086, acc=0.5888888835906982, loss=1.8406057357788086
train: epoch 115, loss 0.15379734337329865, acc=0.9433333277702332, loss=0.15379734337329865
test: epoch 115, loss 2.078732967376709, acc=0.5638889074325562, loss=2.078732967376709
train: epoch 116, loss 0.14095686376094818, acc=0.9441111087799072, loss=0.14095686376094818
test: epoch 116, loss 1.8922582864761353, acc=0.5666666626930237, loss=1.8922582864761353
train: epoch 117, loss 0.14254134893417358, acc=0.9472222328186035, loss=0.14254134893417358
test: epoch 117, loss 1.8169634342193604, acc=0.5916666388511658, loss=1.8169634342193604
train: epoch 118, loss 0.14322254061698914, acc=0.9466666579246521, loss=0.14322254061698914
test: epoch 118, loss 2.093013286590576, acc=0.5583333373069763, loss=2.093013286590576
train: epoch 119, loss 0.14125679433345795, acc=0.9462222456932068, loss=0.14125679433345795
test: epoch 119, loss 1.9227685928344727, acc=0.5972222089767456, loss=1.9227685928344727
train: epoch 120, loss 0.1310468316078186, acc=0.9473888874053955, loss=0.1310468316078186
test: epoch 120, loss 1.9233843088150024, acc=0.5722222328186035, loss=1.9233843088150024
train: epoch 121, loss 0.14149025082588196, acc=0.945888876914978, loss=0.14149025082588196
test: epoch 121, loss 1.9357880353927612, acc=0.5472221970558167, loss=1.9357880353927612
train: epoch 122, loss 0.13581377267837524, acc=0.9470000267028809, loss=0.13581377267837524
test: epoch 122, loss 1.9677051305770874, acc=0.5805555582046509, loss=1.9677051305770874
train: epoch 123, loss 0.13012561202049255, acc=0.9504444599151611, loss=0.13012561202049255
test: epoch 123, loss 1.8163949251174927, acc=0.6388888955116272, loss=1.8163949251174927
train: epoch 124, loss 0.13651175796985626, acc=0.9478333592414856, loss=0.13651175796985626
test: epoch 124, loss 1.8897743225097656, acc=0.5861111283302307, loss=1.8897743225097656
train: epoch 125, loss 0.12783128023147583, acc=0.9502221941947937, loss=0.12783128023147583
test: epoch 125, loss 1.8045661449432373, acc=0.6222222447395325, loss=1.8045661449432373
train: epoch 126, loss 0.13822327554225922, acc=0.9461110830307007, loss=0.13822327554225922
test: epoch 126, loss 1.900465726852417, acc=0.5833333134651184, loss=1.900465726852417
train: epoch 127, loss 0.13528956472873688, acc=0.9468333125114441, loss=0.13528956472873688
test: epoch 127, loss 2.081528902053833, acc=0.5861111283302307, loss=2.081528902053833
train: epoch 128, loss 0.13428279757499695, acc=0.948722243309021, loss=0.13428279757499695
test: epoch 128, loss 2.0874173641204834, acc=0.605555534362793, loss=2.0874173641204834
train: epoch 129, loss 0.1303863525390625, acc=0.9496666789054871, loss=0.1303863525390625
test: epoch 129, loss 1.9285482168197632, acc=0.6000000238418579, loss=1.9285482168197632
train: epoch 130, loss 0.13560456037521362, acc=0.9474999904632568, loss=0.13560456037521362
test: epoch 130, loss 2.0585741996765137, acc=0.5861111283302307, loss=2.0585741996765137
train: epoch 131, loss 0.13389219343662262, acc=0.9509999752044678, loss=0.13389219343662262
test: epoch 131, loss 2.038098096847534, acc=0.5916666388511658, loss=2.038098096847534
train: epoch 132, loss 0.1337180882692337, acc=0.9492777585983276, loss=0.1337180882692337
test: epoch 132, loss 2.130169630050659, acc=0.6000000238418579, loss=2.130169630050659
train: epoch 133, loss 0.1310453563928604, acc=0.9497777819633484, loss=0.1310453563928604
test: epoch 133, loss 1.8908147811889648, acc=0.5805555582046509, loss=1.8908147811889648
train: epoch 134, loss 0.12506426870822906, acc=0.9504444599151611, loss=0.12506426870822906
test: epoch 134, loss 1.7888463735580444, acc=0.6166666746139526, loss=1.7888463735580444
train: epoch 135, loss 0.1303960084915161, acc=0.9496666789054871, loss=0.1303960084915161
test: epoch 135, loss 1.635522484779358, acc=0.6277777552604675, loss=1.635522484779358
train: epoch 136, loss 0.13018523156642914, acc=0.9515555500984192, loss=0.13018523156642914
test: epoch 136, loss 1.8294041156768799, acc=0.6138888597488403, loss=1.8294041156768799
train: epoch 137, loss 0.13112269341945648, acc=0.9512777924537659, loss=0.13112269341945648
test: epoch 137, loss 2.3009138107299805, acc=0.5861111283302307, loss=2.3009138107299805
train: epoch 138, loss 0.13261458277702332, acc=0.9508888721466064, loss=0.13261458277702332
test: epoch 138, loss 1.6418440341949463, acc=0.6361111402511597, loss=1.6418440341949463
train: epoch 139, loss 0.12281611561775208, acc=0.9523888826370239, loss=0.12281611561775208
test: epoch 139, loss 1.7030450105667114, acc=0.6166666746139526, loss=1.7030450105667114
train: epoch 140, loss 0.1320507675409317, acc=0.9508333206176758, loss=0.1320507675409317
test: epoch 140, loss 1.9203613996505737, acc=0.6111111044883728, loss=1.9203613996505737
train: epoch 141, loss 0.1241239383816719, acc=0.9518888592720032, loss=0.1241239383816719
test: epoch 141, loss 1.864197850227356, acc=0.6000000238418579, loss=1.864197850227356
train: epoch 142, loss 0.14059855043888092, acc=0.9496666789054871, loss=0.14059855043888092
test: epoch 142, loss 1.8873698711395264, acc=0.6000000238418579, loss=1.8873698711395264
train: epoch 143, loss 0.12297827005386353, acc=0.9516111016273499, loss=0.12297827005386353
test: epoch 143, loss 1.8313815593719482, acc=0.6333333253860474, loss=1.8313815593719482
train: epoch 144, loss 0.12306396663188934, acc=0.9524999856948853, loss=0.12306396663188934
test: epoch 144, loss 1.8953993320465088, acc=0.6111111044883728, loss=1.8953993320465088
train: epoch 145, loss 0.13814812898635864, acc=0.9505000114440918, loss=0.13814812898635864
test: epoch 145, loss 1.8861427307128906, acc=0.6277777552604675, loss=1.8861427307128906
train: epoch 146, loss 0.12218032777309418, acc=0.9535555839538574, loss=0.12218032777309418
test: epoch 146, loss 1.803279995918274, acc=0.6361111402511597, loss=1.803279995918274
train: epoch 147, loss 0.13152801990509033, acc=0.9513888955116272, loss=0.13152801990509033
test: epoch 147, loss 1.7896744012832642, acc=0.6166666746139526, loss=1.7896744012832642
train: epoch 148, loss 0.12453348189592361, acc=0.9526110887527466, loss=0.12453348189592361
test: epoch 148, loss 1.900872826576233, acc=0.605555534362793, loss=1.900872826576233
train: epoch 149, loss 0.122604139149189, acc=0.9523888826370239, loss=0.122604139149189
test: epoch 149, loss 1.686301350593567, acc=0.6083333492279053, loss=1.686301350593567
train: epoch 150, loss 0.12394905835390091, acc=0.9518333077430725, loss=0.12394905835390091
test: epoch 150, loss 1.6639046669006348, acc=0.5972222089767456, loss=1.6639046669006348
