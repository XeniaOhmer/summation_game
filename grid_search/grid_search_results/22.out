# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1.5", "--temp_decay=1", "--one_hot=false", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=304664894, receiver_embed_dim=32, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.0697989463806152, acc=0.07855555415153503, loss=3.0697989463806152
test: epoch 1, loss 3.3866472244262695, acc=0.11388888955116272, loss=3.3866472244262695
train: epoch 2, loss 2.065643072128296, acc=0.21227778494358063, loss=2.065643072128296
test: epoch 2, loss 3.20723557472229, acc=0.1388888955116272, loss=3.20723557472229
train: epoch 3, loss 1.7673795223236084, acc=0.27977776527404785, loss=1.7673795223236084
test: epoch 3, loss 2.9988715648651123, acc=0.13611111044883728, loss=2.9988715648651123
train: epoch 4, loss 1.6124902963638306, acc=0.3131110966205597, loss=1.6124902963638306
test: epoch 4, loss 3.3867242336273193, acc=0.18888889253139496, loss=3.3867242336273193
train: epoch 5, loss 1.4871405363082886, acc=0.3445555567741394, loss=1.4871405363082886
test: epoch 5, loss 2.943397045135498, acc=0.17777778208255768, loss=2.943397045135498
train: epoch 6, loss 1.3999894857406616, acc=0.3677777647972107, loss=1.3999894857406616
test: epoch 6, loss 3.3539252281188965, acc=0.17777778208255768, loss=3.3539252281188965
train: epoch 7, loss 1.3297970294952393, acc=0.3961666524410248, loss=1.3297970294952393
test: epoch 7, loss 3.0284547805786133, acc=0.17777778208255768, loss=3.0284547805786133
train: epoch 8, loss 1.2676405906677246, acc=0.4233333468437195, loss=1.2676405906677246
test: epoch 8, loss 2.950162172317505, acc=0.18333333730697632, loss=2.950162172317505
train: epoch 9, loss 1.2365570068359375, acc=0.44538888335227966, loss=1.2365570068359375
test: epoch 9, loss 2.7446563243865967, acc=0.21944443881511688, loss=2.7446563243865967
train: epoch 10, loss 1.1465895175933838, acc=0.49900001287460327, loss=1.1465895175933838
test: epoch 10, loss 3.2379796504974365, acc=0.20000000298023224, loss=3.2379796504974365
train: epoch 11, loss 1.0527162551879883, acc=0.5470555424690247, loss=1.0527162551879883
test: epoch 11, loss 2.7725796699523926, acc=0.23888888955116272, loss=2.7725796699523926
train: epoch 12, loss 0.957495391368866, acc=0.6143888831138611, loss=0.957495391368866
test: epoch 12, loss 2.7019076347351074, acc=0.23055554926395416, loss=2.7019076347351074
train: epoch 13, loss 0.7923652529716492, acc=0.6874444484710693, loss=0.7923652529716492
test: epoch 13, loss 2.3091351985931396, acc=0.2944444417953491, loss=2.3091351985931396
train: epoch 14, loss 0.6896995902061462, acc=0.7328888773918152, loss=0.6896995902061462
test: epoch 14, loss 2.611201286315918, acc=0.27222222089767456, loss=2.611201286315918
train: epoch 15, loss 0.6351943016052246, acc=0.746666669845581, loss=0.6351943016052246
test: epoch 15, loss 2.4597227573394775, acc=0.3194444477558136, loss=2.4597227573394775
train: epoch 16, loss 0.5852400064468384, acc=0.7680555582046509, loss=0.5852400064468384
test: epoch 16, loss 2.134963274002075, acc=0.34166666865348816, loss=2.134963274002075
train: epoch 17, loss 0.5483016967773438, acc=0.781166672706604, loss=0.5483016967773438
test: epoch 17, loss 2.0170373916625977, acc=0.3361110985279083, loss=2.0170373916625977
train: epoch 18, loss 0.5345168113708496, acc=0.7857778072357178, loss=0.5345168113708496
test: epoch 18, loss 2.0002005100250244, acc=0.3499999940395355, loss=2.0002005100250244
train: epoch 19, loss 0.4959377646446228, acc=0.804277777671814, loss=0.4959377646446228
test: epoch 19, loss 1.8034498691558838, acc=0.34166666865348816, loss=1.8034498691558838
train: epoch 20, loss 0.4755346179008484, acc=0.8136110901832581, loss=0.4755346179008484
test: epoch 20, loss 1.8691056966781616, acc=0.3777777850627899, loss=1.8691056966781616
train: epoch 21, loss 0.45651739835739136, acc=0.8252221941947937, loss=0.45651739835739136
test: epoch 21, loss 2.0524940490722656, acc=0.35555556416511536, loss=2.0524940490722656
train: epoch 22, loss 0.4337090849876404, acc=0.8305000066757202, loss=0.4337090849876404
test: epoch 22, loss 1.806934118270874, acc=0.3888888955116272, loss=1.806934118270874
train: epoch 23, loss 0.4132740795612335, acc=0.8364999890327454, loss=0.4132740795612335
test: epoch 23, loss 1.7079603672027588, acc=0.39444443583488464, loss=1.7079603672027588
train: epoch 24, loss 0.37999460101127625, acc=0.8483333587646484, loss=0.37999460101127625
test: epoch 24, loss 1.632477879524231, acc=0.3888888955116272, loss=1.632477879524231
train: epoch 25, loss 0.38005128502845764, acc=0.8442222476005554, loss=0.38005128502845764
test: epoch 25, loss 1.7163573503494263, acc=0.4027777910232544, loss=1.7163573503494263
train: epoch 26, loss 0.36898183822631836, acc=0.852222204208374, loss=0.36898183822631836
test: epoch 26, loss 1.5433149337768555, acc=0.4888888895511627, loss=1.5433149337768555
train: epoch 27, loss 0.34549590945243835, acc=0.8579999804496765, loss=0.34549590945243835
test: epoch 27, loss 1.7383257150650024, acc=0.48055556416511536, loss=1.7383257150650024
train: epoch 28, loss 0.32937225699424744, acc=0.8689444661140442, loss=0.32937225699424744
test: epoch 28, loss 1.3755302429199219, acc=0.4749999940395355, loss=1.3755302429199219
train: epoch 29, loss 0.322502076625824, acc=0.8679444193840027, loss=0.322502076625824
test: epoch 29, loss 1.3592841625213623, acc=0.5, loss=1.3592841625213623
train: epoch 30, loss 0.30662551522254944, acc=0.8772222399711609, loss=0.30662551522254944
test: epoch 30, loss 1.336195945739746, acc=0.519444465637207, loss=1.336195945739746
train: epoch 31, loss 0.2988587021827698, acc=0.8848333358764648, loss=0.2988587021827698
test: epoch 31, loss 1.3344929218292236, acc=0.47777777910232544, loss=1.3344929218292236
train: epoch 32, loss 0.2950240671634674, acc=0.8879444599151611, loss=0.2950240671634674
test: epoch 32, loss 1.3692864179611206, acc=0.5555555820465088, loss=1.3692864179611206
train: epoch 33, loss 0.2836915850639343, acc=0.8964444398880005, loss=0.2836915850639343
test: epoch 33, loss 1.3342609405517578, acc=0.5055555701255798, loss=1.3342609405517578
train: epoch 34, loss 0.25673118233680725, acc=0.9068333506584167, loss=0.25673118233680725
test: epoch 34, loss 1.3397380113601685, acc=0.5222222208976746, loss=1.3397380113601685
train: epoch 35, loss 0.2651173770427704, acc=0.9075000286102295, loss=0.2651173770427704
test: epoch 35, loss 1.303989291191101, acc=0.5777778029441833, loss=1.303989291191101
train: epoch 36, loss 0.22861911356449127, acc=0.9218888878822327, loss=0.22861911356449127
test: epoch 36, loss 1.4952448606491089, acc=0.5527777671813965, loss=1.4952448606491089
train: epoch 37, loss 0.22455960512161255, acc=0.921999990940094, loss=0.22455960512161255
test: epoch 37, loss 1.6724692583084106, acc=0.49166667461395264, loss=1.6724692583084106
train: epoch 38, loss 0.24008382856845856, acc=0.9169999957084656, loss=0.24008382856845856
test: epoch 38, loss 2.0159389972686768, acc=0.4861111044883728, loss=2.0159389972686768
train: epoch 39, loss 0.19765467941761017, acc=0.9338333606719971, loss=0.19765467941761017
test: epoch 39, loss 1.4115629196166992, acc=0.5333333611488342, loss=1.4115629196166992
train: epoch 40, loss 0.21113720536231995, acc=0.9271110892295837, loss=0.21113720536231995
test: epoch 40, loss 1.5184121131896973, acc=0.5638889074325562, loss=1.5184121131896973
train: epoch 41, loss 0.19839560985565186, acc=0.9332777857780457, loss=0.19839560985565186
test: epoch 41, loss 1.5530558824539185, acc=0.5249999761581421, loss=1.5530558824539185
train: epoch 42, loss 0.19851407408714294, acc=0.9314444661140442, loss=0.19851407408714294
test: epoch 42, loss 1.694825291633606, acc=0.5138888955116272, loss=1.694825291633606
train: epoch 43, loss 0.18634124100208282, acc=0.9361666440963745, loss=0.18634124100208282
test: epoch 43, loss 1.4821720123291016, acc=0.5305555462837219, loss=1.4821720123291016
train: epoch 44, loss 0.17040042579174042, acc=0.940666675567627, loss=0.17040042579174042
test: epoch 44, loss 1.1447317600250244, acc=0.5583333373069763, loss=1.1447317600250244
train: epoch 45, loss 0.18213914334774017, acc=0.937833309173584, loss=0.18213914334774017
test: epoch 45, loss 1.8094899654388428, acc=0.5111111402511597, loss=1.8094899654388428
train: epoch 46, loss 0.18552742898464203, acc=0.9362778067588806, loss=0.18552742898464203
test: epoch 46, loss 1.3517913818359375, acc=0.5611110925674438, loss=1.3517913818359375
train: epoch 47, loss 0.15778839588165283, acc=0.9461666941642761, loss=0.15778839588165283
test: epoch 47, loss 1.6926754713058472, acc=0.5277777910232544, loss=1.6926754713058472
train: epoch 48, loss 0.16091646254062653, acc=0.9455000162124634, loss=0.16091646254062653
test: epoch 48, loss 1.5349814891815186, acc=0.5416666865348816, loss=1.5349814891815186
train: epoch 49, loss 0.1695273220539093, acc=0.9427222013473511, loss=0.1695273220539093
test: epoch 49, loss 1.7885199785232544, acc=0.5166666507720947, loss=1.7885199785232544
train: epoch 50, loss 0.1538291722536087, acc=0.945888876914978, loss=0.1538291722536087
test: epoch 50, loss 1.7341922521591187, acc=0.5611110925674438, loss=1.7341922521591187
train: epoch 51, loss 0.1577981561422348, acc=0.9478333592414856, loss=0.1577981561422348
test: epoch 51, loss 1.2344284057617188, acc=0.5777778029441833, loss=1.2344284057617188
train: epoch 52, loss 0.14885224401950836, acc=0.9502221941947937, loss=0.14885224401950836
test: epoch 52, loss 1.6027886867523193, acc=0.4749999940395355, loss=1.6027886867523193
train: epoch 53, loss 0.14506395161151886, acc=0.9513333439826965, loss=0.14506395161151886
test: epoch 53, loss 1.6583588123321533, acc=0.4888888895511627, loss=1.6583588123321533
train: epoch 54, loss 0.1465330570936203, acc=0.9506666660308838, loss=0.1465330570936203
test: epoch 54, loss 1.426337718963623, acc=0.5638889074325562, loss=1.426337718963623
train: epoch 55, loss 0.1525907665491104, acc=0.9487777948379517, loss=0.1525907665491104
test: epoch 55, loss 1.3395248651504517, acc=0.6083333492279053, loss=1.3395248651504517
train: epoch 56, loss 0.13868649303913116, acc=0.9522777795791626, loss=0.13868649303913116
test: epoch 56, loss 1.6507980823516846, acc=0.5472221970558167, loss=1.6507980823516846
train: epoch 57, loss 0.1333453208208084, acc=0.9551110863685608, loss=0.1333453208208084
test: epoch 57, loss 1.575739860534668, acc=0.49166667461395264, loss=1.575739860534668
train: epoch 58, loss 0.1272655576467514, acc=0.9563888907432556, loss=0.1272655576467514
test: epoch 58, loss 1.6553575992584229, acc=0.5361111164093018, loss=1.6553575992584229
train: epoch 59, loss 0.12792301177978516, acc=0.9562222361564636, loss=0.12792301177978516
test: epoch 59, loss 1.5244191884994507, acc=0.4888888895511627, loss=1.5244191884994507
train: epoch 60, loss 0.13066282868385315, acc=0.9548333287239075, loss=0.13066282868385315
test: epoch 60, loss 1.7025607824325562, acc=0.5638889074325562, loss=1.7025607824325562
train: epoch 61, loss 0.13155588507652283, acc=0.9551110863685608, loss=0.13155588507652283
test: epoch 61, loss 1.6243035793304443, acc=0.5055555701255798, loss=1.6243035793304443
train: epoch 62, loss 0.12154076993465424, acc=0.9603333473205566, loss=0.12154076993465424
test: epoch 62, loss 1.3811184167861938, acc=0.5611110925674438, loss=1.3811184167861938
train: epoch 63, loss 0.1173025518655777, acc=0.960777759552002, loss=0.1173025518655777
test: epoch 63, loss 1.1922460794448853, acc=0.6388888955116272, loss=1.1922460794448853
train: epoch 64, loss 0.11520306020975113, acc=0.9634444713592529, loss=0.11520306020975113
test: epoch 64, loss 1.6127374172210693, acc=0.5805555582046509, loss=1.6127374172210693
train: epoch 65, loss 0.1131049394607544, acc=0.9614444375038147, loss=0.1131049394607544
test: epoch 65, loss 1.606012225151062, acc=0.5444444417953491, loss=1.606012225151062
train: epoch 66, loss 0.11876944452524185, acc=0.96061110496521, loss=0.11876944452524185
test: epoch 66, loss 1.1953898668289185, acc=0.605555534362793, loss=1.1953898668289185
train: epoch 67, loss 0.09756156802177429, acc=0.9666110873222351, loss=0.09756156802177429
test: epoch 67, loss 1.705944538116455, acc=0.5555555820465088, loss=1.705944538116455
train: epoch 68, loss 0.11213012784719467, acc=0.9620000123977661, loss=0.11213012784719467
test: epoch 68, loss 1.8623393774032593, acc=0.574999988079071, loss=1.8623393774032593
train: epoch 69, loss 0.10112264007329941, acc=0.9651111364364624, loss=0.10112264007329941
test: epoch 69, loss 1.6150661706924438, acc=0.5916666388511658, loss=1.6150661706924438
train: epoch 70, loss 0.11337826400995255, acc=0.9616666436195374, loss=0.11337826400995255
test: epoch 70, loss 1.4978176355361938, acc=0.5638889074325562, loss=1.4978176355361938
train: epoch 71, loss 0.09543502330780029, acc=0.9651111364364624, loss=0.09543502330780029
test: epoch 71, loss 1.9286160469055176, acc=0.5, loss=1.9286160469055176
train: epoch 72, loss 0.09657647460699081, acc=0.9666110873222351, loss=0.09657647460699081
test: epoch 72, loss 1.7221388816833496, acc=0.550000011920929, loss=1.7221388816833496
train: epoch 73, loss 0.10127691179513931, acc=0.964555561542511, loss=0.10127691179513931
test: epoch 73, loss 1.8002839088439941, acc=0.5833333134651184, loss=1.8002839088439941
train: epoch 74, loss 0.10331655293703079, acc=0.9646111130714417, loss=0.10331655293703079
test: epoch 74, loss 1.6838196516036987, acc=0.5972222089767456, loss=1.6838196516036987
train: epoch 75, loss 0.09746403992176056, acc=0.9671111106872559, loss=0.09746403992176056
test: epoch 75, loss 1.156760811805725, acc=0.6388888955116272, loss=1.156760811805725
train: epoch 76, loss 0.11049020290374756, acc=0.9628333449363708, loss=0.11049020290374756
test: epoch 76, loss 1.2430225610733032, acc=0.5972222089767456, loss=1.2430225610733032
train: epoch 77, loss 0.10103952139616013, acc=0.9651666879653931, loss=0.10103952139616013
test: epoch 77, loss 1.5887963771820068, acc=0.5972222089767456, loss=1.5887963771820068
train: epoch 78, loss 0.09143131971359253, acc=0.9682777523994446, loss=0.09143131971359253
test: epoch 78, loss 1.158926248550415, acc=0.7222222089767456, loss=1.158926248550415
train: epoch 79, loss 0.07989884167909622, acc=0.971666693687439, loss=0.07989884167909622
test: epoch 79, loss 1.4743595123291016, acc=0.6083333492279053, loss=1.4743595123291016
train: epoch 80, loss 0.09555134177207947, acc=0.9688888788223267, loss=0.09555134177207947
test: epoch 80, loss 1.3801188468933105, acc=0.605555534362793, loss=1.3801188468933105
train: epoch 81, loss 0.0981268510222435, acc=0.9691110849380493, loss=0.0981268510222435
test: epoch 81, loss 1.4134747982025146, acc=0.5972222089767456, loss=1.4134747982025146
train: epoch 82, loss 0.0981389656662941, acc=0.968833327293396, loss=0.0981389656662941
test: epoch 82, loss 1.742234468460083, acc=0.605555534362793, loss=1.742234468460083
train: epoch 83, loss 0.0803239718079567, acc=0.9747222065925598, loss=0.0803239718079567
test: epoch 83, loss 1.477023720741272, acc=0.5944444537162781, loss=1.477023720741272
train: epoch 84, loss 0.08195750415325165, acc=0.9737222194671631, loss=0.08195750415325165
test: epoch 84, loss 1.5999666452407837, acc=0.625, loss=1.5999666452407837
train: epoch 85, loss 0.08479299396276474, acc=0.971833348274231, loss=0.08479299396276474
test: epoch 85, loss 1.5514111518859863, acc=0.5361111164093018, loss=1.5514111518859863
train: epoch 86, loss 0.09161273390054703, acc=0.9697777628898621, loss=0.09161273390054703
test: epoch 86, loss 1.4393609762191772, acc=0.519444465637207, loss=1.4393609762191772
train: epoch 87, loss 0.08642995357513428, acc=0.9734444618225098, loss=0.08642995357513428
test: epoch 87, loss 1.4879523515701294, acc=0.644444465637207, loss=1.4879523515701294
train: epoch 88, loss 0.07700272649526596, acc=0.9764444231987, loss=0.07700272649526596
test: epoch 88, loss 1.3811110258102417, acc=0.6138888597488403, loss=1.3811110258102417
train: epoch 89, loss 0.07034718245267868, acc=0.9781110882759094, loss=0.07034718245267868
test: epoch 89, loss 1.5876203775405884, acc=0.6166666746139526, loss=1.5876203775405884
train: epoch 90, loss 0.09234487265348434, acc=0.9701666831970215, loss=0.09234487265348434
test: epoch 90, loss 1.2456492185592651, acc=0.6694444417953491, loss=1.2456492185592651
train: epoch 91, loss 0.06656000763177872, acc=0.9801666736602783, loss=0.06656000763177872
test: epoch 91, loss 1.2386434078216553, acc=0.6305555701255798, loss=1.2386434078216553
train: epoch 92, loss 0.06936535984277725, acc=0.9790555834770203, loss=0.06936535984277725
test: epoch 92, loss 1.4826090335845947, acc=0.5916666388511658, loss=1.4826090335845947
train: epoch 93, loss 0.07796616107225418, acc=0.9753333330154419, loss=0.07796616107225418
test: epoch 93, loss 1.3549126386642456, acc=0.6166666746139526, loss=1.3549126386642456
train: epoch 94, loss 0.07548162341117859, acc=0.9756666421890259, loss=0.07548162341117859
test: epoch 94, loss 1.4196990728378296, acc=0.5944444537162781, loss=1.4196990728378296
train: epoch 95, loss 0.0835411474108696, acc=0.9733333587646484, loss=0.0835411474108696
test: epoch 95, loss 1.1709951162338257, acc=0.6416666507720947, loss=1.1709951162338257
train: epoch 96, loss 0.07776220142841339, acc=0.9760000109672546, loss=0.07776220142841339
test: epoch 96, loss 1.2510331869125366, acc=0.6305555701255798, loss=1.2510331869125366
train: epoch 97, loss 0.06895913928747177, acc=0.9781666398048401, loss=0.06895913928747177
test: epoch 97, loss 1.0569218397140503, acc=0.6722221970558167, loss=1.0569218397140503
train: epoch 98, loss 0.07136722654104233, acc=0.9769444465637207, loss=0.07136722654104233
test: epoch 98, loss 1.5533125400543213, acc=0.6555555462837219, loss=1.5533125400543213
train: epoch 99, loss 0.07443182915449142, acc=0.9768333435058594, loss=0.07443182915449142
test: epoch 99, loss 1.8584115505218506, acc=0.5666666626930237, loss=1.8584115505218506
train: epoch 100, loss 0.06620626896619797, acc=0.9786666631698608, loss=0.06620626896619797
test: epoch 100, loss 1.2975884675979614, acc=0.6694444417953491, loss=1.2975884675979614
train: epoch 101, loss 0.0665791779756546, acc=0.9795555472373962, loss=0.0665791779756546
test: epoch 101, loss 1.1752809286117554, acc=0.6138888597488403, loss=1.1752809286117554
train: epoch 102, loss 0.07006893306970596, acc=0.9781110882759094, loss=0.07006893306970596
test: epoch 102, loss 1.566443920135498, acc=0.6499999761581421, loss=1.566443920135498
train: epoch 103, loss 0.06803087890148163, acc=0.9794999957084656, loss=0.06803087890148163
test: epoch 103, loss 1.4407374858856201, acc=0.6361111402511597, loss=1.4407374858856201
train: epoch 104, loss 0.06341828405857086, acc=0.9814444184303284, loss=0.06341828405857086
test: epoch 104, loss 1.3358209133148193, acc=0.7083333134651184, loss=1.3358209133148193
train: epoch 105, loss 0.0688532367348671, acc=0.9786666631698608, loss=0.0688532367348671
test: epoch 105, loss 1.590976357460022, acc=0.6694444417953491, loss=1.590976357460022
train: epoch 106, loss 0.08977993577718735, acc=0.9733889102935791, loss=0.08977993577718735
test: epoch 106, loss 1.4314097166061401, acc=0.6194444298744202, loss=1.4314097166061401
train: epoch 107, loss 0.06603877246379852, acc=0.9786666631698608, loss=0.06603877246379852
test: epoch 107, loss 1.2870466709136963, acc=0.6083333492279053, loss=1.2870466709136963
train: epoch 108, loss 0.06074284762144089, acc=0.9818333387374878, loss=0.06074284762144089
test: epoch 108, loss 1.4805731773376465, acc=0.5555555820465088, loss=1.4805731773376465
train: epoch 109, loss 0.06087639182806015, acc=0.9808889031410217, loss=0.06087639182806015
test: epoch 109, loss 1.4585695266723633, acc=0.5861111283302307, loss=1.4585695266723633
train: epoch 110, loss 0.07675409317016602, acc=0.9754999876022339, loss=0.07675409317016602
test: epoch 110, loss 1.4212383031845093, acc=0.6805555820465088, loss=1.4212383031845093
train: epoch 111, loss 0.06051183119416237, acc=0.9801666736602783, loss=0.06051183119416237
test: epoch 111, loss 1.3796722888946533, acc=0.6416666507720947, loss=1.3796722888946533
train: epoch 112, loss 0.06371188163757324, acc=0.9806110858917236, loss=0.06371188163757324
test: epoch 112, loss 1.3848737478256226, acc=0.6361111402511597, loss=1.3848737478256226
train: epoch 113, loss 0.06119479238986969, acc=0.9798333048820496, loss=0.06119479238986969
test: epoch 113, loss 1.0613844394683838, acc=0.6972222328186035, loss=1.0613844394683838
train: epoch 114, loss 0.05671705678105354, acc=0.9820555448532104, loss=0.05671705678105354
test: epoch 114, loss 1.3627699613571167, acc=0.6277777552604675, loss=1.3627699613571167
train: epoch 115, loss 0.0691123902797699, acc=0.9782222509384155, loss=0.0691123902797699
test: epoch 115, loss 0.9801257848739624, acc=0.7027778029441833, loss=0.9801257848739624
train: epoch 116, loss 0.0604403018951416, acc=0.9815000295639038, loss=0.0604403018951416
test: epoch 116, loss 1.2843503952026367, acc=0.7361111044883728, loss=1.2843503952026367
train: epoch 117, loss 0.06349990516901016, acc=0.9797777533531189, loss=0.06349990516901016
test: epoch 117, loss 1.2502690553665161, acc=0.6916666626930237, loss=1.2502690553665161
train: epoch 118, loss 0.06298194825649261, acc=0.9804999828338623, loss=0.06298194825649261
test: epoch 118, loss 1.1969642639160156, acc=0.6277777552604675, loss=1.1969642639160156
train: epoch 119, loss 0.06217794120311737, acc=0.9808333516120911, loss=0.06217794120311737
test: epoch 119, loss 1.4075754880905151, acc=0.6694444417953491, loss=1.4075754880905151
train: epoch 120, loss 0.05110456794500351, acc=0.984333336353302, loss=0.05110456794500351
test: epoch 120, loss 1.26621413230896, acc=0.6527777910232544, loss=1.26621413230896
train: epoch 121, loss 0.061356235295534134, acc=0.9813888669013977, loss=0.061356235295534134
test: epoch 121, loss 1.7918150424957275, acc=0.644444465637207, loss=1.7918150424957275
train: epoch 122, loss 0.06724728643894196, acc=0.9786666631698608, loss=0.06724728643894196
test: epoch 122, loss 1.4732234477996826, acc=0.625, loss=1.4732234477996826
train: epoch 123, loss 0.0544649139046669, acc=0.9823889136314392, loss=0.0544649139046669
test: epoch 123, loss 1.0194836854934692, acc=0.6583333611488342, loss=1.0194836854934692
train: epoch 124, loss 0.0641552209854126, acc=0.9806110858917236, loss=0.0641552209854126
test: epoch 124, loss 1.9156949520111084, acc=0.6305555701255798, loss=1.9156949520111084
train: epoch 125, loss 0.0556676872074604, acc=0.9829444289207458, loss=0.0556676872074604
test: epoch 125, loss 1.2481261491775513, acc=0.6583333611488342, loss=1.2481261491775513
train: epoch 126, loss 0.05547241121530533, acc=0.9829999804496765, loss=0.05547241121530533
test: epoch 126, loss 1.2677955627441406, acc=0.6583333611488342, loss=1.2677955627441406
train: epoch 127, loss 0.06810138374567032, acc=0.9794999957084656, loss=0.06810138374567032
test: epoch 127, loss 1.3876094818115234, acc=0.6583333611488342, loss=1.3876094818115234
train: epoch 128, loss 0.06282351911067963, acc=0.9801111221313477, loss=0.06282351911067963
test: epoch 128, loss 1.2081350088119507, acc=0.6694444417953491, loss=1.2081350088119507
train: epoch 129, loss 0.052166085690259933, acc=0.9836666584014893, loss=0.052166085690259933
test: epoch 129, loss 1.4444851875305176, acc=0.6361111402511597, loss=1.4444851875305176
train: epoch 130, loss 0.04837837070226669, acc=0.984499990940094, loss=0.04837837070226669
test: epoch 130, loss 1.5948225259780884, acc=0.6000000238418579, loss=1.5948225259780884
train: epoch 131, loss 0.05464128032326698, acc=0.9831666946411133, loss=0.05464128032326698
test: epoch 131, loss 1.620690107345581, acc=0.6472222208976746, loss=1.620690107345581
train: epoch 132, loss 0.05085024982690811, acc=0.9837222099304199, loss=0.05085024982690811
test: epoch 132, loss 1.421316385269165, acc=0.6833333373069763, loss=1.421316385269165
train: epoch 133, loss 0.05222329869866371, acc=0.9827777743339539, loss=0.05222329869866371
test: epoch 133, loss 1.4727705717086792, acc=0.6333333253860474, loss=1.4727705717086792
train: epoch 134, loss 0.05764110013842583, acc=0.9824444651603699, loss=0.05764110013842583
test: epoch 134, loss 1.0994338989257812, acc=0.7222222089767456, loss=1.0994338989257812
train: epoch 135, loss 0.05598638206720352, acc=0.9826111197471619, loss=0.05598638206720352
test: epoch 135, loss 1.0516294240951538, acc=0.6944444179534912, loss=1.0516294240951538
train: epoch 136, loss 0.05625717714428902, acc=0.9822221994400024, loss=0.05625717714428902
test: epoch 136, loss 1.2080707550048828, acc=0.699999988079071, loss=1.2080707550048828
train: epoch 137, loss 0.052881114184856415, acc=0.9841111302375793, loss=0.052881114184856415
test: epoch 137, loss 1.2540203332901, acc=0.6611111164093018, loss=1.2540203332901
train: epoch 138, loss 0.056808263063430786, acc=0.9818888902664185, loss=0.056808263063430786
test: epoch 138, loss 1.3061999082565308, acc=0.6777777671813965, loss=1.3061999082565308
train: epoch 139, loss 0.05056484416127205, acc=0.9842222332954407, loss=0.05056484416127205
test: epoch 139, loss 0.9404821991920471, acc=0.6888889074325562, loss=0.9404821991920471
train: epoch 140, loss 0.04657552018761635, acc=0.9851111173629761, loss=0.04657552018761635
test: epoch 140, loss 1.1055408716201782, acc=0.6833333373069763, loss=1.1055408716201782
train: epoch 141, loss 0.05496849864721298, acc=0.9827777743339539, loss=0.05496849864721298
test: epoch 141, loss 1.203367829322815, acc=0.7055555582046509, loss=1.203367829322815
train: epoch 142, loss 0.054233208298683167, acc=0.9836666584014893, loss=0.054233208298683167
test: epoch 142, loss 1.460536003112793, acc=0.6916666626930237, loss=1.460536003112793
train: epoch 143, loss 0.049284033477306366, acc=0.9838888645172119, loss=0.049284033477306366
test: epoch 143, loss 1.2320075035095215, acc=0.7222222089767456, loss=1.2320075035095215
train: epoch 144, loss 0.042392611503601074, acc=0.9865555763244629, loss=0.042392611503601074
test: epoch 144, loss 1.0537135601043701, acc=0.7250000238418579, loss=1.0537135601043701
train: epoch 145, loss 0.05300487205386162, acc=0.9840555787086487, loss=0.05300487205386162
test: epoch 145, loss 1.214404821395874, acc=0.7027778029441833, loss=1.214404821395874
train: epoch 146, loss 0.0478689931333065, acc=0.9854444265365601, loss=0.0478689931333065
test: epoch 146, loss 1.4708679914474487, acc=0.6888889074325562, loss=1.4708679914474487
train: epoch 147, loss 0.043070487678050995, acc=0.9872778058052063, loss=0.043070487678050995
test: epoch 147, loss 1.2859293222427368, acc=0.675000011920929, loss=1.2859293222427368
train: epoch 148, loss 0.052065860480070114, acc=0.984333336353302, loss=0.052065860480070114
test: epoch 148, loss 1.1571519374847412, acc=0.7111111283302307, loss=1.1571519374847412
train: epoch 149, loss 0.03951606899499893, acc=0.9874444603919983, loss=0.03951606899499893
test: epoch 149, loss 1.1106549501419067, acc=0.7055555582046509, loss=1.1106549501419067
train: epoch 150, loss 0.051299892365932465, acc=0.9840555787086487, loss=0.051299892365932465
test: epoch 150, loss 1.0911248922348022, acc=0.6499999761581421, loss=1.0911248922348022
