# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=1", "--temp_decay=0.99", "--one_hot=true", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1122410793, receiver_embed_dim=64, temp_decay=0.99, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.4589664936065674, acc=0.047333333641290665, loss=3.4589664936065674
test: epoch 1, loss 3.6338162422180176, acc=0.04444444552063942, loss=3.6338162422180176
train: epoch 2, loss 2.9241771697998047, acc=0.09894444793462753, loss=2.9241771697998047
test: epoch 2, loss 2.762587785720825, acc=0.12222222238779068, loss=2.762587785720825
train: epoch 3, loss 2.148716688156128, acc=0.21199999749660492, loss=2.148716688156128
test: epoch 3, loss 2.350006341934204, acc=0.14166666567325592, loss=2.350006341934204
train: epoch 4, loss 1.9008238315582275, acc=0.26499998569488525, loss=1.9008238315582275
test: epoch 4, loss 2.2978434562683105, acc=0.14722222089767456, loss=2.2978434562683105
train: epoch 5, loss 1.7656883001327515, acc=0.2937222123146057, loss=1.7656883001327515
test: epoch 5, loss 2.1851112842559814, acc=0.17499999701976776, loss=2.1851112842559814
train: epoch 6, loss 1.6741881370544434, acc=0.32527777552604675, loss=1.6741881370544434
test: epoch 6, loss 2.102229118347168, acc=0.1944444477558136, loss=2.102229118347168
train: epoch 7, loss 1.6022897958755493, acc=0.3534444570541382, loss=1.6022897958755493
test: epoch 7, loss 2.0157651901245117, acc=0.20000000298023224, loss=2.0157651901245117
train: epoch 8, loss 1.5157684087753296, acc=0.375, loss=1.5157684087753296
test: epoch 8, loss 2.0481162071228027, acc=0.19166666269302368, loss=2.0481162071228027
train: epoch 9, loss 1.4790318012237549, acc=0.3911111056804657, loss=1.4790318012237549
test: epoch 9, loss 2.040686845779419, acc=0.20277777314186096, loss=2.040686845779419
train: epoch 10, loss 1.4500436782836914, acc=0.39605554938316345, loss=1.4500436782836914
test: epoch 10, loss 2.0906150341033936, acc=0.20277777314186096, loss=2.0906150341033936
train: epoch 11, loss 1.4178173542022705, acc=0.4103333353996277, loss=1.4178173542022705
test: epoch 11, loss 1.9683383703231812, acc=0.22499999403953552, loss=1.9683383703231812
train: epoch 12, loss 1.3745627403259277, acc=0.4338333308696747, loss=1.3745627403259277
test: epoch 12, loss 1.869964361190796, acc=0.24722221493721008, loss=1.869964361190796
train: epoch 13, loss 1.3435659408569336, acc=0.4403333365917206, loss=1.3435659408569336
test: epoch 13, loss 1.8473563194274902, acc=0.24722221493721008, loss=1.8473563194274902
train: epoch 14, loss 1.306243658065796, acc=0.45233333110809326, loss=1.306243658065796
test: epoch 14, loss 1.8119938373565674, acc=0.2638888955116272, loss=1.8119938373565674
train: epoch 15, loss 1.2625160217285156, acc=0.4726666808128357, loss=1.2625160217285156
test: epoch 15, loss 1.6981408596038818, acc=0.2777777910232544, loss=1.6981408596038818
train: epoch 16, loss 1.2343508005142212, acc=0.48605555295944214, loss=1.2343508005142212
test: epoch 16, loss 1.7384597063064575, acc=0.27222222089767456, loss=1.7384597063064575
train: epoch 17, loss 1.207977294921875, acc=0.496111124753952, loss=1.207977294921875
test: epoch 17, loss 1.7267855405807495, acc=0.28333333134651184, loss=1.7267855405807495
train: epoch 18, loss 1.1822596788406372, acc=0.5106666684150696, loss=1.1822596788406372
test: epoch 18, loss 1.7472869157791138, acc=0.28333333134651184, loss=1.7472869157791138
train: epoch 19, loss 1.1593854427337646, acc=0.5163888931274414, loss=1.1593854427337646
test: epoch 19, loss 1.734903335571289, acc=0.2805555462837219, loss=1.734903335571289
train: epoch 20, loss 1.144648790359497, acc=0.5243333578109741, loss=1.144648790359497
test: epoch 20, loss 1.718436598777771, acc=0.28611111640930176, loss=1.718436598777771
train: epoch 21, loss 1.1237024068832397, acc=0.5308333039283752, loss=1.1237024068832397
test: epoch 21, loss 1.679884910583496, acc=0.2805555462837219, loss=1.679884910583496
train: epoch 22, loss 1.1097795963287354, acc=0.5358333587646484, loss=1.1097795963287354
test: epoch 22, loss 1.7028298377990723, acc=0.28333333134651184, loss=1.7028298377990723
train: epoch 23, loss 1.1046873331069946, acc=0.5391666889190674, loss=1.1046873331069946
test: epoch 23, loss 1.700433373451233, acc=0.28333333134651184, loss=1.700433373451233
train: epoch 24, loss 1.0601930618286133, acc=0.5513333082199097, loss=1.0601930618286133
test: epoch 24, loss 1.682157039642334, acc=0.28333333134651184, loss=1.682157039642334
train: epoch 25, loss 1.0569815635681152, acc=0.5617777705192566, loss=1.0569815635681152
test: epoch 25, loss 1.6830037832260132, acc=0.28611111640930176, loss=1.6830037832260132
train: epoch 26, loss 1.0505316257476807, acc=0.5618333220481873, loss=1.0505316257476807
test: epoch 26, loss 1.650090217590332, acc=0.2888889014720917, loss=1.650090217590332
train: epoch 27, loss 1.0360994338989258, acc=0.5675555467605591, loss=1.0360994338989258
test: epoch 27, loss 1.6835734844207764, acc=0.2916666567325592, loss=1.6835734844207764
train: epoch 28, loss 1.0117943286895752, acc=0.5793889164924622, loss=1.0117943286895752
test: epoch 28, loss 1.6786750555038452, acc=0.2944444417953491, loss=1.6786750555038452
train: epoch 29, loss 1.0033562183380127, acc=0.5718333125114441, loss=1.0033562183380127
test: epoch 29, loss 1.6229808330535889, acc=0.30000001192092896, loss=1.6229808330535889
train: epoch 30, loss 0.9932849407196045, acc=0.5820000171661377, loss=0.9932849407196045
test: epoch 30, loss 1.7415046691894531, acc=0.30000001192092896, loss=1.7415046691894531
train: epoch 31, loss 0.979308009147644, acc=0.5834444165229797, loss=0.979308009147644
test: epoch 31, loss 1.6426239013671875, acc=0.3027777671813965, loss=1.6426239013671875
train: epoch 32, loss 0.96551114320755, acc=0.5893333554267883, loss=0.96551114320755
test: epoch 32, loss 1.5545576810836792, acc=0.31388887763023376, loss=1.5545576810836792
train: epoch 33, loss 0.9472103714942932, acc=0.5955555438995361, loss=0.9472103714942932
test: epoch 33, loss 1.6009647846221924, acc=0.31111112236976624, loss=1.6009647846221924
train: epoch 34, loss 0.9294158220291138, acc=0.5956110954284668, loss=0.9294158220291138
test: epoch 34, loss 1.637486457824707, acc=0.3055555522441864, loss=1.637486457824707
train: epoch 35, loss 0.9293229579925537, acc=0.6010555624961853, loss=0.9293229579925537
test: epoch 35, loss 1.6639615297317505, acc=0.3166666626930237, loss=1.6639615297317505
train: epoch 36, loss 0.9205394983291626, acc=0.5978333353996277, loss=0.9205394983291626
test: epoch 36, loss 1.5638445615768433, acc=0.3166666626930237, loss=1.5638445615768433
train: epoch 37, loss 0.8942576050758362, acc=0.6056110858917236, loss=0.8942576050758362
test: epoch 37, loss 1.5947858095169067, acc=0.3194444477558136, loss=1.5947858095169067
train: epoch 38, loss 0.8959572911262512, acc=0.6028888821601868, loss=0.8959572911262512
test: epoch 38, loss 1.6643636226654053, acc=0.31388887763023376, loss=1.6643636226654053
train: epoch 39, loss 0.8877654075622559, acc=0.6066111326217651, loss=0.8877654075622559
test: epoch 39, loss 1.6409976482391357, acc=0.3222222328186035, loss=1.6409976482391357
train: epoch 40, loss 0.8828480839729309, acc=0.6138888597488403, loss=0.8828480839729309
test: epoch 40, loss 1.5865132808685303, acc=0.32777777314186096, loss=1.5865132808685303
train: epoch 41, loss 0.8655586242675781, acc=0.6133888959884644, loss=0.8655586242675781
test: epoch 41, loss 1.6225403547286987, acc=0.32777777314186096, loss=1.6225403547286987
train: epoch 42, loss 0.8538942933082581, acc=0.6161110997200012, loss=0.8538942933082581
test: epoch 42, loss 1.6755905151367188, acc=0.32777777314186096, loss=1.6755905151367188
train: epoch 43, loss 0.857390820980072, acc=0.6201111078262329, loss=0.857390820980072
test: epoch 43, loss 1.57683265209198, acc=0.3194444477558136, loss=1.57683265209198
train: epoch 44, loss 0.8395736217498779, acc=0.6276666522026062, loss=0.8395736217498779
test: epoch 44, loss 1.7071589231491089, acc=0.3194444477558136, loss=1.7071589231491089
train: epoch 45, loss 0.8442489504814148, acc=0.6241666674613953, loss=0.8442489504814148
test: epoch 45, loss 1.6831283569335938, acc=0.3194444477558136, loss=1.6831283569335938
train: epoch 46, loss 0.8399280309677124, acc=0.6237778067588806, loss=0.8399280309677124
test: epoch 46, loss 1.5971639156341553, acc=0.3333333432674408, loss=1.5971639156341553
train: epoch 47, loss 0.8213518261909485, acc=0.6293333172798157, loss=0.8213518261909485
test: epoch 47, loss 1.7063117027282715, acc=0.3333333432674408, loss=1.7063117027282715
train: epoch 48, loss 0.8307055234909058, acc=0.6312222480773926, loss=0.8307055234909058
test: epoch 48, loss 1.6333853006362915, acc=0.32777777314186096, loss=1.6333853006362915
train: epoch 49, loss 0.8237501978874207, acc=0.629111111164093, loss=0.8237501978874207
test: epoch 49, loss 1.735985517501831, acc=0.32499998807907104, loss=1.735985517501831
train: epoch 50, loss 0.8040423393249512, acc=0.6371666789054871, loss=0.8040423393249512
test: epoch 50, loss 1.6569057703018188, acc=0.3305555582046509, loss=1.6569057703018188
train: epoch 51, loss 0.8111613392829895, acc=0.6308333277702332, loss=0.8111613392829895
test: epoch 51, loss 1.6005662679672241, acc=0.3333333432674408, loss=1.6005662679672241
train: epoch 52, loss 0.8142998218536377, acc=0.637666642665863, loss=0.8142998218536377
test: epoch 52, loss 1.7160547971725464, acc=0.3194444477558136, loss=1.7160547971725464
train: epoch 53, loss 0.7994160652160645, acc=0.6398888826370239, loss=0.7994160652160645
test: epoch 53, loss 1.7087119817733765, acc=0.32777777314186096, loss=1.7087119817733765
train: epoch 54, loss 0.7935119271278381, acc=0.6437777876853943, loss=0.7935119271278381
test: epoch 54, loss 1.7715907096862793, acc=0.34166666865348816, loss=1.7715907096862793
train: epoch 55, loss 0.7843308448791504, acc=0.6421666741371155, loss=0.7843308448791504
test: epoch 55, loss 1.6380096673965454, acc=0.34166666865348816, loss=1.6380096673965454
train: epoch 56, loss 0.7920246124267578, acc=0.6430555582046509, loss=0.7920246124267578
test: epoch 56, loss 1.6530966758728027, acc=0.3444444537162781, loss=1.6530966758728027
train: epoch 57, loss 0.7823569774627686, acc=0.6463888883590698, loss=0.7823569774627686
test: epoch 57, loss 1.73737633228302, acc=0.33888888359069824, loss=1.73737633228302
train: epoch 58, loss 0.7831405997276306, acc=0.6472777724266052, loss=0.7831405997276306
test: epoch 58, loss 1.7045499086380005, acc=0.3361110985279083, loss=1.7045499086380005
train: epoch 59, loss 0.7903770804405212, acc=0.6406111121177673, loss=0.7903770804405212
test: epoch 59, loss 1.7541266679763794, acc=0.3361110985279083, loss=1.7541266679763794
train: epoch 60, loss 0.7760747075080872, acc=0.6420555710792542, loss=0.7760747075080872
test: epoch 60, loss 1.6441588401794434, acc=0.34166666865348816, loss=1.6441588401794434
train: epoch 61, loss 0.7696627974510193, acc=0.648277759552002, loss=0.7696627974510193
test: epoch 61, loss 1.7190033197402954, acc=0.3472222089767456, loss=1.7190033197402954
train: epoch 62, loss 0.769782304763794, acc=0.6504999995231628, loss=0.769782304763794
test: epoch 62, loss 1.687619686126709, acc=0.3472222089767456, loss=1.687619686126709
train: epoch 63, loss 0.7734131813049316, acc=0.6468889117240906, loss=0.7734131813049316
test: epoch 63, loss 1.7837550640106201, acc=0.34166666865348816, loss=1.7837550640106201
train: epoch 64, loss 0.7671025395393372, acc=0.6458888649940491, loss=0.7671025395393372
test: epoch 64, loss 1.6872261762619019, acc=0.3499999940395355, loss=1.6872261762619019
train: epoch 65, loss 0.7649660110473633, acc=0.6456111073493958, loss=0.7649660110473633
test: epoch 65, loss 1.6668715476989746, acc=0.3444444537162781, loss=1.6668715476989746
train: epoch 66, loss 0.7549267411231995, acc=0.6523333191871643, loss=0.7549267411231995
test: epoch 66, loss 1.8571540117263794, acc=0.3472222089767456, loss=1.8571540117263794
train: epoch 67, loss 0.7581550478935242, acc=0.6508333086967468, loss=0.7581550478935242
test: epoch 67, loss 1.8005993366241455, acc=0.3583333194255829, loss=1.8005993366241455
train: epoch 68, loss 0.7578428983688354, acc=0.6507777571678162, loss=0.7578428983688354
test: epoch 68, loss 1.8250774145126343, acc=0.3499999940395355, loss=1.8250774145126343
train: epoch 69, loss 0.7555823922157288, acc=0.6551111340522766, loss=0.7555823922157288
test: epoch 69, loss 1.6735084056854248, acc=0.3444444537162781, loss=1.6735084056854248
train: epoch 70, loss 0.7583436369895935, acc=0.6578888893127441, loss=0.7583436369895935
test: epoch 70, loss 1.7932597398757935, acc=0.3444444537162781, loss=1.7932597398757935
train: epoch 71, loss 0.747933030128479, acc=0.6556666493415833, loss=0.747933030128479
test: epoch 71, loss 1.7998281717300415, acc=0.3472222089767456, loss=1.7998281717300415
train: epoch 72, loss 0.7460705637931824, acc=0.6555555462837219, loss=0.7460705637931824
test: epoch 72, loss 1.7075474262237549, acc=0.35277777910232544, loss=1.7075474262237549
train: epoch 73, loss 0.7460711002349854, acc=0.6597777605056763, loss=0.7460711002349854
test: epoch 73, loss 1.750209927558899, acc=0.3499999940395355, loss=1.750209927558899
train: epoch 74, loss 0.7485799789428711, acc=0.6571666598320007, loss=0.7485799789428711
test: epoch 74, loss 1.8202910423278809, acc=0.35277777910232544, loss=1.8202910423278809
train: epoch 75, loss 0.741376519203186, acc=0.6592222452163696, loss=0.741376519203186
test: epoch 75, loss 1.7313525676727295, acc=0.35555556416511536, loss=1.7313525676727295
train: epoch 76, loss 0.7410067915916443, acc=0.6577777862548828, loss=0.7410067915916443
test: epoch 76, loss 1.7004252672195435, acc=0.35555556416511536, loss=1.7004252672195435
train: epoch 77, loss 0.7379139065742493, acc=0.6585000157356262, loss=0.7379139065742493
test: epoch 77, loss 1.7277253866195679, acc=0.35277777910232544, loss=1.7277253866195679
train: epoch 78, loss 0.731573760509491, acc=0.6610555648803711, loss=0.731573760509491
test: epoch 78, loss 1.8121219873428345, acc=0.35555556416511536, loss=1.8121219873428345
train: epoch 79, loss 0.734373152256012, acc=0.6611111164093018, loss=0.734373152256012
test: epoch 79, loss 1.7084788084030151, acc=0.35277777910232544, loss=1.7084788084030151
train: epoch 80, loss 0.7314977645874023, acc=0.6598888635635376, loss=0.7314977645874023
test: epoch 80, loss 1.744674563407898, acc=0.3499999940395355, loss=1.744674563407898
train: epoch 81, loss 0.7265000343322754, acc=0.6618333458900452, loss=0.7265000343322754
test: epoch 81, loss 1.7843375205993652, acc=0.35277777910232544, loss=1.7843375205993652
train: epoch 82, loss 0.7316886186599731, acc=0.6595555543899536, loss=0.7316886186599731
test: epoch 82, loss 1.8474657535552979, acc=0.3499999940395355, loss=1.8474657535552979
train: epoch 83, loss 0.7270590662956238, acc=0.66438889503479, loss=0.7270590662956238
test: epoch 83, loss 1.702479600906372, acc=0.35555556416511536, loss=1.702479600906372
train: epoch 84, loss 0.7146521210670471, acc=0.6605555415153503, loss=0.7146521210670471
test: epoch 84, loss 1.7681467533111572, acc=0.35555556416511536, loss=1.7681467533111572
train: epoch 85, loss 0.7192994356155396, acc=0.6626666784286499, loss=0.7192994356155396
test: epoch 85, loss 1.7452627420425415, acc=0.35555556416511536, loss=1.7452627420425415
train: epoch 86, loss 0.7210829257965088, acc=0.6630555391311646, loss=0.7210829257965088
test: epoch 86, loss 1.7578625679016113, acc=0.3638888895511627, loss=1.7578625679016113
train: epoch 87, loss 0.7243925333023071, acc=0.6637222170829773, loss=0.7243925333023071
test: epoch 87, loss 1.5974851846694946, acc=0.3611111044883728, loss=1.5974851846694946
train: epoch 88, loss 0.7056179046630859, acc=0.6690000295639038, loss=0.7056179046630859
test: epoch 88, loss 1.8724288940429688, acc=0.3638888895511627, loss=1.8724288940429688
train: epoch 89, loss 0.716196596622467, acc=0.6669999957084656, loss=0.716196596622467
test: epoch 89, loss 1.7966220378875732, acc=0.36944442987442017, loss=1.7966220378875732
train: epoch 90, loss 0.7249288558959961, acc=0.6636666655540466, loss=0.7249288558959961
test: epoch 90, loss 1.791590929031372, acc=0.3638888895511627, loss=1.791590929031372
train: epoch 91, loss 0.6996908783912659, acc=0.6715555787086487, loss=0.6996908783912659
test: epoch 91, loss 1.7384291887283325, acc=0.3638888895511627, loss=1.7384291887283325
train: epoch 92, loss 0.7115365862846375, acc=0.6661111116409302, loss=0.7115365862846375
test: epoch 92, loss 1.7840996980667114, acc=0.36666667461395264, loss=1.7840996980667114
train: epoch 93, loss 0.7075867056846619, acc=0.6706666946411133, loss=0.7075867056846619
test: epoch 93, loss 1.7980257272720337, acc=0.3611111044883728, loss=1.7980257272720337
train: epoch 94, loss 0.7133040428161621, acc=0.6679999828338623, loss=0.7133040428161621
test: epoch 94, loss 1.7523753643035889, acc=0.3611111044883728, loss=1.7523753643035889
train: epoch 95, loss 0.7089262008666992, acc=0.6723889112472534, loss=0.7089262008666992
test: epoch 95, loss 1.7201347351074219, acc=0.3611111044883728, loss=1.7201347351074219
train: epoch 96, loss 0.7048248648643494, acc=0.6669999957084656, loss=0.7048248648643494
test: epoch 96, loss 1.7600088119506836, acc=0.36666667461395264, loss=1.7600088119506836
train: epoch 97, loss 0.7071511149406433, acc=0.6651666760444641, loss=0.7071511149406433
test: epoch 97, loss 1.7538994550704956, acc=0.3611111044883728, loss=1.7538994550704956
train: epoch 98, loss 0.6998440623283386, acc=0.6710555553436279, loss=0.6998440623283386
test: epoch 98, loss 1.6892168521881104, acc=0.375, loss=1.6892168521881104
train: epoch 99, loss 0.7035604119300842, acc=0.6707777976989746, loss=0.7035604119300842
test: epoch 99, loss 1.749670147895813, acc=0.3722222149372101, loss=1.749670147895813
train: epoch 100, loss 0.7059825658798218, acc=0.6690555810928345, loss=0.7059825658798218
test: epoch 100, loss 1.8059918880462646, acc=0.36666667461395264, loss=1.8059918880462646
train: epoch 101, loss 0.7003194093704224, acc=0.671500027179718, loss=0.7003194093704224
test: epoch 101, loss 1.701585054397583, acc=0.3722222149372101, loss=1.701585054397583
train: epoch 102, loss 0.6911506652832031, acc=0.6721110939979553, loss=0.6911506652832031
test: epoch 102, loss 1.7714757919311523, acc=0.3722222149372101, loss=1.7714757919311523
train: epoch 103, loss 0.6961545348167419, acc=0.670722246170044, loss=0.6961545348167419
test: epoch 103, loss 1.7398505210876465, acc=0.36944442987442017, loss=1.7398505210876465
train: epoch 104, loss 0.6947475671768188, acc=0.6746666431427002, loss=0.6947475671768188
test: epoch 104, loss 1.716889500617981, acc=0.3722222149372101, loss=1.716889500617981
train: epoch 105, loss 0.6950667500495911, acc=0.6697221994400024, loss=0.6950667500495911
test: epoch 105, loss 1.8541531562805176, acc=0.3722222149372101, loss=1.8541531562805176
train: epoch 106, loss 0.700472354888916, acc=0.6658889055252075, loss=0.700472354888916
test: epoch 106, loss 1.7466638088226318, acc=0.3777777850627899, loss=1.7466638088226318
train: epoch 107, loss 0.6898078918457031, acc=0.6740000247955322, loss=0.6898078918457031
test: epoch 107, loss 1.7326899766921997, acc=0.3777777850627899, loss=1.7326899766921997
train: epoch 108, loss 0.6908366680145264, acc=0.670722246170044, loss=0.6908366680145264
test: epoch 108, loss 1.7866718769073486, acc=0.375, loss=1.7866718769073486
train: epoch 109, loss 0.6950262784957886, acc=0.6701111197471619, loss=0.6950262784957886
test: epoch 109, loss 1.8248029947280884, acc=0.3777777850627899, loss=1.8248029947280884
train: epoch 110, loss 0.6886811852455139, acc=0.675944447517395, loss=0.6886811852455139
test: epoch 110, loss 1.8768653869628906, acc=0.375, loss=1.8768653869628906
train: epoch 111, loss 0.6915121078491211, acc=0.6717777848243713, loss=0.6915121078491211
test: epoch 111, loss 1.7730801105499268, acc=0.3722222149372101, loss=1.7730801105499268
train: epoch 112, loss 0.6869261860847473, acc=0.6747778058052063, loss=0.6869261860847473
test: epoch 112, loss 1.8263821601867676, acc=0.3722222149372101, loss=1.8263821601867676
train: epoch 113, loss 0.6858742237091064, acc=0.675166666507721, loss=0.6858742237091064
test: epoch 113, loss 1.7760698795318604, acc=0.375, loss=1.7760698795318604
train: epoch 114, loss 0.6846941709518433, acc=0.6781111359596252, loss=0.6846941709518433
test: epoch 114, loss 1.8489291667938232, acc=0.36944442987442017, loss=1.8489291667938232
train: epoch 115, loss 0.69270259141922, acc=0.6665555834770203, loss=0.69270259141922
test: epoch 115, loss 1.8845988512039185, acc=0.375, loss=1.8845988512039185
train: epoch 116, loss 0.6926995515823364, acc=0.6703333258628845, loss=0.6926995515823364
test: epoch 116, loss 1.8257782459259033, acc=0.3722222149372101, loss=1.8257782459259033
train: epoch 117, loss 0.6915456056594849, acc=0.6731111407279968, loss=0.6915456056594849
test: epoch 117, loss 1.7800630331039429, acc=0.36944442987442017, loss=1.7800630331039429
train: epoch 118, loss 0.6842090487480164, acc=0.6755555272102356, loss=0.6842090487480164
test: epoch 118, loss 1.807547688484192, acc=0.375, loss=1.807547688484192
train: epoch 119, loss 0.690958559513092, acc=0.6732777953147888, loss=0.690958559513092
test: epoch 119, loss 1.935369610786438, acc=0.375, loss=1.935369610786438
train: epoch 120, loss 0.6905471682548523, acc=0.6718888878822327, loss=0.6905471682548523
test: epoch 120, loss 1.8262207508087158, acc=0.36666667461395264, loss=1.8262207508087158
train: epoch 121, loss 0.6827443838119507, acc=0.6779999732971191, loss=0.6827443838119507
test: epoch 121, loss 1.8730452060699463, acc=0.375, loss=1.8730452060699463
train: epoch 122, loss 0.6866930723190308, acc=0.674833357334137, loss=0.6866930723190308
test: epoch 122, loss 1.9256612062454224, acc=0.38055557012557983, loss=1.9256612062454224
train: epoch 123, loss 0.687057614326477, acc=0.6741111278533936, loss=0.687057614326477
test: epoch 123, loss 1.8530751466751099, acc=0.38055557012557983, loss=1.8530751466751099
train: epoch 124, loss 0.6764534711837769, acc=0.6771110892295837, loss=0.6764534711837769
test: epoch 124, loss 1.686843752861023, acc=0.375, loss=1.686843752861023
train: epoch 125, loss 0.686311662197113, acc=0.6742777824401855, loss=0.686311662197113
test: epoch 125, loss 1.8560272455215454, acc=0.3777777850627899, loss=1.8560272455215454
train: epoch 126, loss 0.6816433668136597, acc=0.6737222075462341, loss=0.6816433668136597
test: epoch 126, loss 1.8649420738220215, acc=0.3722222149372101, loss=1.8649420738220215
train: epoch 127, loss 0.6726173162460327, acc=0.6826666593551636, loss=0.6726173162460327
test: epoch 127, loss 1.790037751197815, acc=0.375, loss=1.790037751197815
train: epoch 128, loss 0.6798250079154968, acc=0.6757222414016724, loss=0.6798250079154968
test: epoch 128, loss 1.9573554992675781, acc=0.3722222149372101, loss=1.9573554992675781
train: epoch 129, loss 0.6784628033638, acc=0.6815555691719055, loss=0.6784628033638
test: epoch 129, loss 1.7259504795074463, acc=0.3722222149372101, loss=1.7259504795074463
train: epoch 130, loss 0.6828119158744812, acc=0.6770555377006531, loss=0.6828119158744812
test: epoch 130, loss 1.8496792316436768, acc=0.36944442987442017, loss=1.8496792316436768
train: epoch 131, loss 0.6759756207466125, acc=0.6804999709129333, loss=0.6759756207466125
test: epoch 131, loss 1.7178581953048706, acc=0.3722222149372101, loss=1.7178581953048706
train: epoch 132, loss 0.6730788946151733, acc=0.6817222237586975, loss=0.6730788946151733
test: epoch 132, loss 1.8495639562606812, acc=0.38055557012557983, loss=1.8495639562606812
train: epoch 133, loss 0.6702311038970947, acc=0.6825000047683716, loss=0.6702311038970947
test: epoch 133, loss 1.8131314516067505, acc=0.36666667461395264, loss=1.8131314516067505
train: epoch 134, loss 0.6794967651367188, acc=0.6802777647972107, loss=0.6794967651367188
test: epoch 134, loss 1.7988922595977783, acc=0.3722222149372101, loss=1.7988922595977783
train: epoch 135, loss 0.6780797243118286, acc=0.6812222003936768, loss=0.6780797243118286
test: epoch 135, loss 1.7793902158737183, acc=0.3722222149372101, loss=1.7793902158737183
train: epoch 136, loss 0.6574897766113281, acc=0.6866666674613953, loss=0.6574897766113281
test: epoch 136, loss 1.9015452861785889, acc=0.3722222149372101, loss=1.9015452861785889
train: epoch 137, loss 0.667384147644043, acc=0.6869444251060486, loss=0.667384147644043
test: epoch 137, loss 1.841644048690796, acc=0.36666667461395264, loss=1.841644048690796
train: epoch 138, loss 0.666217029094696, acc=0.6840000152587891, loss=0.666217029094696
test: epoch 138, loss 1.8612689971923828, acc=0.36944442987442017, loss=1.8612689971923828
train: epoch 139, loss 0.6719608306884766, acc=0.6844444274902344, loss=0.6719608306884766
test: epoch 139, loss 1.8163056373596191, acc=0.36944442987442017, loss=1.8163056373596191
train: epoch 140, loss 0.6760599613189697, acc=0.6847222447395325, loss=0.6760599613189697
test: epoch 140, loss 1.8493527173995972, acc=0.3722222149372101, loss=1.8493527173995972
train: epoch 141, loss 0.671805202960968, acc=0.6853333115577698, loss=0.671805202960968
test: epoch 141, loss 1.9266725778579712, acc=0.3722222149372101, loss=1.9266725778579712
train: epoch 142, loss 0.6662988066673279, acc=0.6878888607025146, loss=0.6662988066673279
test: epoch 142, loss 1.7597501277923584, acc=0.3722222149372101, loss=1.7597501277923584
train: epoch 143, loss 0.6796553730964661, acc=0.6852222084999084, loss=0.6796553730964661
test: epoch 143, loss 1.9729384183883667, acc=0.36666667461395264, loss=1.9729384183883667
train: epoch 144, loss 0.6729788780212402, acc=0.6838333606719971, loss=0.6729788780212402
test: epoch 144, loss 1.7941676378250122, acc=0.3638888895511627, loss=1.7941676378250122
train: epoch 145, loss 0.6613329648971558, acc=0.687833309173584, loss=0.6613329648971558
test: epoch 145, loss 1.8963044881820679, acc=0.3722222149372101, loss=1.8963044881820679
train: epoch 146, loss 0.6705969572067261, acc=0.6897222399711609, loss=0.6705969572067261
test: epoch 146, loss 1.9349579811096191, acc=0.36944442987442017, loss=1.9349579811096191
train: epoch 147, loss 0.6648401021957397, acc=0.6877222061157227, loss=0.6648401021957397
test: epoch 147, loss 1.8519856929779053, acc=0.3777777850627899, loss=1.8519856929779053
train: epoch 148, loss 0.676834762096405, acc=0.687833309173584, loss=0.676834762096405
test: epoch 148, loss 1.6973565816879272, acc=0.3722222149372101, loss=1.6973565816879272
train: epoch 149, loss 0.6726704239845276, acc=0.6846110820770264, loss=0.6726704239845276
test: epoch 149, loss 1.7957404851913452, acc=0.3722222149372101, loss=1.7957404851913452
train: epoch 150, loss 0.6635898947715759, acc=0.6880555748939514, loss=0.6635898947715759
test: epoch 150, loss 1.8157190084457397, acc=0.3777777850627899, loss=1.8157190084457397
