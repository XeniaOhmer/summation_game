# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=1", "--temp_decay=1", "--one_hot=false", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1799103108, receiver_embed_dim=64, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.1893436908721924, acc=0.0658888891339302, loss=3.1893436908721924
test: epoch 1, loss 2.845285177230835, acc=0.10000000149011612, loss=2.845285177230835
train: epoch 2, loss 2.4575700759887695, acc=0.14483332633972168, loss=2.4575700759887695
test: epoch 2, loss 2.4636926651000977, acc=0.12777778506278992, loss=2.4636926651000977
train: epoch 3, loss 1.8282657861709595, acc=0.2764444351196289, loss=1.8282657861709595
test: epoch 3, loss 1.6696484088897705, acc=0.2916666567325592, loss=1.6696484088897705
train: epoch 4, loss 1.3709642887115479, acc=0.4079444408416748, loss=1.3709642887115479
test: epoch 4, loss 1.5097256898880005, acc=0.3472222089767456, loss=1.5097256898880005
train: epoch 5, loss 1.1694308519363403, acc=0.46844443678855896, loss=1.1694308519363403
test: epoch 5, loss 1.417169451713562, acc=0.3472222089767456, loss=1.417169451713562
train: epoch 6, loss 1.0476356744766235, acc=0.5262222290039062, loss=1.0476356744766235
test: epoch 6, loss 1.477347493171692, acc=0.3583333194255829, loss=1.477347493171692
train: epoch 7, loss 0.9510017037391663, acc=0.5603333115577698, loss=0.9510017037391663
test: epoch 7, loss 1.5195326805114746, acc=0.4138889014720917, loss=1.5195326805114746
train: epoch 8, loss 0.9062960147857666, acc=0.5848333239555359, loss=0.9062960147857666
test: epoch 8, loss 1.4045583009719849, acc=0.40833333134651184, loss=1.4045583009719849
train: epoch 9, loss 0.8911951780319214, acc=0.5893333554267883, loss=0.8911951780319214
test: epoch 9, loss 1.4884772300720215, acc=0.4416666626930237, loss=1.4884772300720215
train: epoch 10, loss 0.8487071394920349, acc=0.6014444231987, loss=0.8487071394920349
test: epoch 10, loss 1.4387335777282715, acc=0.38333332538604736, loss=1.4387335777282715
train: epoch 11, loss 0.8238878846168518, acc=0.6150555610656738, loss=0.8238878846168518
test: epoch 11, loss 1.4081785678863525, acc=0.46666666865348816, loss=1.4081785678863525
train: epoch 12, loss 0.8019917011260986, acc=0.624833345413208, loss=0.8019917011260986
test: epoch 12, loss 1.3924773931503296, acc=0.4416666626930237, loss=1.3924773931503296
train: epoch 13, loss 0.7941413521766663, acc=0.6200555562973022, loss=0.7941413521766663
test: epoch 13, loss 1.2860596179962158, acc=0.4722222089767456, loss=1.2860596179962158
train: epoch 14, loss 0.7692456841468811, acc=0.6271111369132996, loss=0.7692456841468811
test: epoch 14, loss 1.5892701148986816, acc=0.47777777910232544, loss=1.5892701148986816
train: epoch 15, loss 0.7807789444923401, acc=0.6265555620193481, loss=0.7807789444923401
test: epoch 15, loss 1.3118475675582886, acc=0.4611110985279083, loss=1.3118475675582886
train: epoch 16, loss 0.7566549181938171, acc=0.6321666836738586, loss=0.7566549181938171
test: epoch 16, loss 1.4590189456939697, acc=0.44999998807907104, loss=1.4590189456939697
train: epoch 17, loss 0.7456448674201965, acc=0.6390555500984192, loss=0.7456448674201965
test: epoch 17, loss 1.3653326034545898, acc=0.4722222089767456, loss=1.3653326034545898
train: epoch 18, loss 0.7455963492393494, acc=0.640666663646698, loss=0.7455963492393494
test: epoch 18, loss 1.4076814651489258, acc=0.48055556416511536, loss=1.4076814651489258
train: epoch 19, loss 0.7214124798774719, acc=0.6435555815696716, loss=0.7214124798774719
test: epoch 19, loss 1.3238762617111206, acc=0.4972222149372101, loss=1.3238762617111206
train: epoch 20, loss 0.709434449672699, acc=0.6534444689750671, loss=0.709434449672699
test: epoch 20, loss 1.564758539199829, acc=0.4333333373069763, loss=1.564758539199829
train: epoch 21, loss 0.7052347660064697, acc=0.652222216129303, loss=0.7052347660064697
test: epoch 21, loss 1.3886226415634155, acc=0.47777777910232544, loss=1.3886226415634155
train: epoch 22, loss 0.7136157155036926, acc=0.6513333320617676, loss=0.7136157155036926
test: epoch 22, loss 1.5355242490768433, acc=0.48055556416511536, loss=1.5355242490768433
train: epoch 23, loss 0.7004663944244385, acc=0.6536666750907898, loss=0.7004663944244385
test: epoch 23, loss 1.346677541732788, acc=0.47777777910232544, loss=1.346677541732788
train: epoch 24, loss 0.6865770220756531, acc=0.6643333435058594, loss=0.6865770220756531
test: epoch 24, loss 1.3015683889389038, acc=0.4833333194255829, loss=1.3015683889389038
train: epoch 25, loss 0.6976178884506226, acc=0.6533889174461365, loss=0.6976178884506226
test: epoch 25, loss 1.4676003456115723, acc=0.4749999940395355, loss=1.4676003456115723
train: epoch 26, loss 0.6977013349533081, acc=0.6613333225250244, loss=0.6977013349533081
test: epoch 26, loss 1.4099570512771606, acc=0.48055556416511536, loss=1.4099570512771606
train: epoch 27, loss 0.6801597476005554, acc=0.6661111116409302, loss=0.6801597476005554
test: epoch 27, loss 1.5681674480438232, acc=0.4749999940395355, loss=1.5681674480438232
train: epoch 28, loss 0.6787353157997131, acc=0.6691111326217651, loss=0.6787353157997131
test: epoch 28, loss 1.426409125328064, acc=0.4888888895511627, loss=1.426409125328064
train: epoch 29, loss 0.6737406253814697, acc=0.6725555658340454, loss=0.6737406253814697
test: epoch 29, loss 1.3501309156417847, acc=0.4861111044883728, loss=1.3501309156417847
train: epoch 30, loss 0.6769081354141235, acc=0.6750555634498596, loss=0.6769081354141235
test: epoch 30, loss 1.4553992748260498, acc=0.4611110985279083, loss=1.4553992748260498
train: epoch 31, loss 0.6682659983634949, acc=0.6738888621330261, loss=0.6682659983634949
test: epoch 31, loss 1.4358022212982178, acc=0.49166667461395264, loss=1.4358022212982178
train: epoch 32, loss 0.6424707174301147, acc=0.6818888783454895, loss=0.6424707174301147
test: epoch 32, loss 1.4485435485839844, acc=0.4749999940395355, loss=1.4485435485839844
train: epoch 33, loss 0.6552544832229614, acc=0.6784999966621399, loss=0.6552544832229614
test: epoch 33, loss 1.6267386674880981, acc=0.4888888895511627, loss=1.6267386674880981
train: epoch 34, loss 0.6746633052825928, acc=0.6724444627761841, loss=0.6746633052825928
test: epoch 34, loss 1.3928000926971436, acc=0.4972222149372101, loss=1.3928000926971436
train: epoch 35, loss 0.6532694697380066, acc=0.6765000224113464, loss=0.6532694697380066
test: epoch 35, loss 1.5172512531280518, acc=0.4722222089767456, loss=1.5172512531280518
train: epoch 36, loss 0.6685713529586792, acc=0.6754999756813049, loss=0.6685713529586792
test: epoch 36, loss 1.4392602443695068, acc=0.4972222149372101, loss=1.4392602443695068
train: epoch 37, loss 0.6311802268028259, acc=0.6842777729034424, loss=0.6311802268028259
test: epoch 37, loss 1.6636344194412231, acc=0.4888888895511627, loss=1.6636344194412231
train: epoch 38, loss 0.626358687877655, acc=0.691777765750885, loss=0.626358687877655
test: epoch 38, loss 1.4576735496520996, acc=0.4861111044883728, loss=1.4576735496520996
train: epoch 39, loss 0.6177773475646973, acc=0.6902777552604675, loss=0.6177773475646973
test: epoch 39, loss 1.5643064975738525, acc=0.4694444537162781, loss=1.5643064975738525
train: epoch 40, loss 0.6373452544212341, acc=0.6834444403648376, loss=0.6373452544212341
test: epoch 40, loss 1.457037329673767, acc=0.49166667461395264, loss=1.457037329673767
train: epoch 41, loss 0.626905083656311, acc=0.6921666860580444, loss=0.626905083656311
test: epoch 41, loss 1.4670991897583008, acc=0.48055556416511536, loss=1.4670991897583008
train: epoch 42, loss 0.6503984332084656, acc=0.6855000257492065, loss=0.6503984332084656
test: epoch 42, loss 1.528027057647705, acc=0.4972222149372101, loss=1.528027057647705
train: epoch 43, loss 0.6210596561431885, acc=0.6924444437026978, loss=0.6210596561431885
test: epoch 43, loss 1.4945675134658813, acc=0.49444442987442017, loss=1.4945675134658813
train: epoch 44, loss 0.6427481770515442, acc=0.6840555667877197, loss=0.6427481770515442
test: epoch 44, loss 1.4195818901062012, acc=0.49444442987442017, loss=1.4195818901062012
train: epoch 45, loss 0.6270623803138733, acc=0.6910555362701416, loss=0.6270623803138733
test: epoch 45, loss 1.4948805570602417, acc=0.49444442987442017, loss=1.4948805570602417
train: epoch 46, loss 0.6419117450714111, acc=0.6803333163261414, loss=0.6419117450714111
test: epoch 46, loss 1.2794699668884277, acc=0.49166667461395264, loss=1.2794699668884277
train: epoch 47, loss 0.6185258030891418, acc=0.6889444589614868, loss=0.6185258030891418
test: epoch 47, loss 1.3948538303375244, acc=0.4972222149372101, loss=1.3948538303375244
train: epoch 48, loss 0.5970962643623352, acc=0.6959444284439087, loss=0.5970962643623352
test: epoch 48, loss 1.5212795734405518, acc=0.4972222149372101, loss=1.5212795734405518
train: epoch 49, loss 0.6016422510147095, acc=0.6915555596351624, loss=0.6016422510147095
test: epoch 49, loss 1.4543440341949463, acc=0.4861111044883728, loss=1.4543440341949463
train: epoch 50, loss 0.5866163372993469, acc=0.7012777924537659, loss=0.5866163372993469
test: epoch 50, loss 1.6363290548324585, acc=0.4888888895511627, loss=1.6363290548324585
train: epoch 51, loss 0.6039506196975708, acc=0.694944441318512, loss=0.6039506196975708
test: epoch 51, loss 1.3402067422866821, acc=0.49444442987442017, loss=1.3402067422866821
train: epoch 52, loss 0.5939754843711853, acc=0.7031111121177673, loss=0.5939754843711853
test: epoch 52, loss 1.4685524702072144, acc=0.4972222149372101, loss=1.4685524702072144
train: epoch 53, loss 0.5944222211837769, acc=0.7046666741371155, loss=0.5944222211837769
test: epoch 53, loss 1.7243071794509888, acc=0.4722222089767456, loss=1.7243071794509888
train: epoch 54, loss 0.6126896142959595, acc=0.6962777972221375, loss=0.6126896142959595
test: epoch 54, loss 1.4038788080215454, acc=0.49166667461395264, loss=1.4038788080215454
train: epoch 55, loss 0.5790248513221741, acc=0.7124444246292114, loss=0.5790248513221741
test: epoch 55, loss 1.3583284616470337, acc=0.49444442987442017, loss=1.3583284616470337
train: epoch 56, loss 0.60828697681427, acc=0.7012222409248352, loss=0.60828697681427
test: epoch 56, loss 1.5961700677871704, acc=0.4861111044883728, loss=1.5961700677871704
train: epoch 57, loss 0.5995726585388184, acc=0.7017777562141418, loss=0.5995726585388184
test: epoch 57, loss 1.6197277307510376, acc=0.49444442987442017, loss=1.6197277307510376
train: epoch 58, loss 0.5819058418273926, acc=0.7092777490615845, loss=0.5819058418273926
test: epoch 58, loss 1.5286293029785156, acc=0.4972222149372101, loss=1.5286293029785156
train: epoch 59, loss 0.5951583385467529, acc=0.7083888649940491, loss=0.5951583385467529
test: epoch 59, loss 1.4015469551086426, acc=0.4972222149372101, loss=1.4015469551086426
train: epoch 60, loss 0.5790966749191284, acc=0.7140555381774902, loss=0.5790966749191284
test: epoch 60, loss 1.5060665607452393, acc=0.4861111044883728, loss=1.5060665607452393
train: epoch 61, loss 0.5636175274848938, acc=0.7170000076293945, loss=0.5636175274848938
test: epoch 61, loss 1.3950444459915161, acc=0.49444442987442017, loss=1.3950444459915161
train: epoch 62, loss 0.5856959819793701, acc=0.7056666612625122, loss=0.5856959819793701
test: epoch 62, loss 1.5086054801940918, acc=0.49166667461395264, loss=1.5086054801940918
train: epoch 63, loss 0.5803364515304565, acc=0.7090555429458618, loss=0.5803364515304565
test: epoch 63, loss 1.480374813079834, acc=0.49444442987442017, loss=1.480374813079834
train: epoch 64, loss 0.5851951837539673, acc=0.7098888754844666, loss=0.5851951837539673
test: epoch 64, loss 1.3840159177780151, acc=0.4972222149372101, loss=1.3840159177780151
train: epoch 65, loss 0.5803625583648682, acc=0.7145000100135803, loss=0.5803625583648682
test: epoch 65, loss 1.3907629251480103, acc=0.4972222149372101, loss=1.3907629251480103
train: epoch 66, loss 0.601390540599823, acc=0.7024999856948853, loss=0.601390540599823
test: epoch 66, loss 1.6000803709030151, acc=0.4861111044883728, loss=1.6000803709030151
train: epoch 67, loss 0.5635954737663269, acc=0.717555582523346, loss=0.5635954737663269
test: epoch 67, loss 1.5256210565567017, acc=0.4888888895511627, loss=1.5256210565567017
train: epoch 68, loss 0.5837197303771973, acc=0.7078333497047424, loss=0.5837197303771973
test: epoch 68, loss 1.5567667484283447, acc=0.49444442987442017, loss=1.5567667484283447
train: epoch 69, loss 0.5831460952758789, acc=0.7135555744171143, loss=0.5831460952758789
test: epoch 69, loss 1.3862528800964355, acc=0.4972222149372101, loss=1.3862528800964355
train: epoch 70, loss 0.5849249958992004, acc=0.7074999809265137, loss=0.5849249958992004
test: epoch 70, loss 1.3875031471252441, acc=0.5, loss=1.3875031471252441
train: epoch 71, loss 0.5847126245498657, acc=0.704277753829956, loss=0.5847126245498657
test: epoch 71, loss 1.4023478031158447, acc=0.5, loss=1.4023478031158447
train: epoch 72, loss 0.5583338737487793, acc=0.7170000076293945, loss=0.5583338737487793
test: epoch 72, loss 1.4581871032714844, acc=0.4972222149372101, loss=1.4581871032714844
train: epoch 73, loss 0.5482017993927002, acc=0.7196666598320007, loss=0.5482017993927002
test: epoch 73, loss 1.499820351600647, acc=0.46666666865348816, loss=1.499820351600647
train: epoch 74, loss 0.5521741509437561, acc=0.722777783870697, loss=0.5521741509437561
test: epoch 74, loss 1.546390175819397, acc=0.5, loss=1.546390175819397
train: epoch 75, loss 0.5423344373703003, acc=0.7244444489479065, loss=0.5423344373703003
test: epoch 75, loss 1.6275079250335693, acc=0.4694444537162781, loss=1.6275079250335693
train: epoch 76, loss 0.5523537993431091, acc=0.7213333249092102, loss=0.5523537993431091
test: epoch 76, loss 1.3954282999038696, acc=0.49444442987442017, loss=1.3954282999038696
train: epoch 77, loss 0.5375537872314453, acc=0.7276111245155334, loss=0.5375537872314453
test: epoch 77, loss 1.7075799703598022, acc=0.5055555701255798, loss=1.7075799703598022
train: epoch 78, loss 0.5358113050460815, acc=0.7260000109672546, loss=0.5358113050460815
test: epoch 78, loss 1.6221436262130737, acc=0.5055555701255798, loss=1.6221436262130737
train: epoch 79, loss 0.5478838682174683, acc=0.722777783870697, loss=0.5478838682174683
test: epoch 79, loss 1.5739927291870117, acc=0.5055555701255798, loss=1.5739927291870117
train: epoch 80, loss 0.5283337235450745, acc=0.7289999723434448, loss=0.5283337235450745
test: epoch 80, loss 1.5913915634155273, acc=0.4972222149372101, loss=1.5913915634155273
train: epoch 81, loss 0.6366291642189026, acc=0.6988333463668823, loss=0.6366291642189026
test: epoch 81, loss 1.4436564445495605, acc=0.5, loss=1.4436564445495605
train: epoch 82, loss 0.5374915599822998, acc=0.7261666655540466, loss=0.5374915599822998
test: epoch 82, loss 1.5175913572311401, acc=0.5027777552604675, loss=1.5175913572311401
train: epoch 83, loss 0.541455090045929, acc=0.7212222218513489, loss=0.541455090045929
test: epoch 83, loss 1.6207512617111206, acc=0.5027777552604675, loss=1.6207512617111206
train: epoch 84, loss 0.5726684331893921, acc=0.7149444222450256, loss=0.5726684331893921
test: epoch 84, loss 1.6119307279586792, acc=0.5, loss=1.6119307279586792
train: epoch 85, loss 0.5518428087234497, acc=0.7216110825538635, loss=0.5518428087234497
test: epoch 85, loss 1.6103692054748535, acc=0.4722222089767456, loss=1.6103692054748535
train: epoch 86, loss 0.548470139503479, acc=0.7336666584014893, loss=0.548470139503479
test: epoch 86, loss 1.4122850894927979, acc=0.5, loss=1.4122850894927979
train: epoch 87, loss 0.5371546149253845, acc=0.7335555553436279, loss=0.5371546149253845
test: epoch 87, loss 1.4798591136932373, acc=0.5027777552604675, loss=1.4798591136932373
train: epoch 88, loss 0.5501523017883301, acc=0.7224444150924683, loss=0.5501523017883301
test: epoch 88, loss 1.5401241779327393, acc=0.5055555701255798, loss=1.5401241779327393
train: epoch 89, loss 0.5649267435073853, acc=0.7182222008705139, loss=0.5649267435073853
test: epoch 89, loss 1.4832156896591187, acc=0.5027777552604675, loss=1.4832156896591187
train: epoch 90, loss 0.521919310092926, acc=0.7313888669013977, loss=0.521919310092926
test: epoch 90, loss 1.4586883783340454, acc=0.5055555701255798, loss=1.4586883783340454
train: epoch 91, loss 0.5337964296340942, acc=0.7306110858917236, loss=0.5337964296340942
test: epoch 91, loss 1.6549811363220215, acc=0.4833333194255829, loss=1.6549811363220215
train: epoch 92, loss 0.5161944031715393, acc=0.73416668176651, loss=0.5161944031715393
test: epoch 92, loss 1.608476161956787, acc=0.5, loss=1.608476161956787
train: epoch 93, loss 0.5552321672439575, acc=0.7241111397743225, loss=0.5552321672439575
test: epoch 93, loss 1.6777408123016357, acc=0.49444442987442017, loss=1.6777408123016357
train: epoch 94, loss 0.534552812576294, acc=0.7248888611793518, loss=0.534552812576294
test: epoch 94, loss 1.4330238103866577, acc=0.5055555701255798, loss=1.4330238103866577
train: epoch 95, loss 0.5245285034179688, acc=0.7296666502952576, loss=0.5245285034179688
test: epoch 95, loss 1.607429027557373, acc=0.5166666507720947, loss=1.607429027557373
train: epoch 96, loss 0.5504664182662964, acc=0.7226666808128357, loss=0.5504664182662964
test: epoch 96, loss 1.4156054258346558, acc=0.5083333253860474, loss=1.4156054258346558
train: epoch 97, loss 0.5125439167022705, acc=0.7410555481910706, loss=0.5125439167022705
test: epoch 97, loss 1.4922893047332764, acc=0.5472221970558167, loss=1.4922893047332764
train: epoch 98, loss 0.50975501537323, acc=0.742888867855072, loss=0.50975501537323
test: epoch 98, loss 1.350960373878479, acc=0.5555555820465088, loss=1.350960373878479
train: epoch 99, loss 0.4710228443145752, acc=0.7483333349227905, loss=0.4710228443145752
test: epoch 99, loss 1.3211034536361694, acc=0.5472221970558167, loss=1.3211034536361694
train: epoch 100, loss 0.4811883866786957, acc=0.7478333115577698, loss=0.4811883866786957
test: epoch 100, loss 1.3741353750228882, acc=0.5611110925674438, loss=1.3741353750228882
train: epoch 101, loss 0.4751165211200714, acc=0.7504444718360901, loss=0.4751165211200714
test: epoch 101, loss 1.4081376791000366, acc=0.5527777671813965, loss=1.4081376791000366
train: epoch 102, loss 0.4903602600097656, acc=0.7466111183166504, loss=0.4903602600097656
test: epoch 102, loss 1.4615049362182617, acc=0.5583333373069763, loss=1.4615049362182617
train: epoch 103, loss 0.49101722240448, acc=0.7464444637298584, loss=0.49101722240448
test: epoch 103, loss 1.4755927324295044, acc=0.5611110925674438, loss=1.4755927324295044
train: epoch 104, loss 0.46587154269218445, acc=0.7527777552604675, loss=0.46587154269218445
test: epoch 104, loss 1.3912758827209473, acc=0.5666666626930237, loss=1.3912758827209473
train: epoch 105, loss 0.48330533504486084, acc=0.7496111392974854, loss=0.48330533504486084
test: epoch 105, loss 1.5039066076278687, acc=0.5583333373069763, loss=1.5039066076278687
train: epoch 106, loss 0.479019433259964, acc=0.7482222318649292, loss=0.479019433259964
test: epoch 106, loss 1.4152272939682007, acc=0.5805555582046509, loss=1.4152272939682007
train: epoch 107, loss 0.49670812487602234, acc=0.746222198009491, loss=0.49670812487602234
test: epoch 107, loss 1.3110980987548828, acc=0.5944444537162781, loss=1.3110980987548828
train: epoch 108, loss 0.48646506667137146, acc=0.7486110925674438, loss=0.48646506667137146
test: epoch 108, loss 1.2851130962371826, acc=0.6000000238418579, loss=1.2851130962371826
train: epoch 109, loss 0.4814351201057434, acc=0.7505000233650208, loss=0.4814351201057434
test: epoch 109, loss 1.273162603378296, acc=0.6000000238418579, loss=1.273162603378296
train: epoch 110, loss 0.4512498676776886, acc=0.7565000057220459, loss=0.4512498676776886
test: epoch 110, loss 1.2221369743347168, acc=0.6027777791023254, loss=1.2221369743347168
train: epoch 111, loss 0.46070975065231323, acc=0.7553333044052124, loss=0.46070975065231323
test: epoch 111, loss 1.229048490524292, acc=0.6000000238418579, loss=1.229048490524292
train: epoch 112, loss 0.469603568315506, acc=0.7536110877990723, loss=0.469603568315506
test: epoch 112, loss 1.1881017684936523, acc=0.6027777791023254, loss=1.1881017684936523
train: epoch 113, loss 0.4730253517627716, acc=0.7542222142219543, loss=0.4730253517627716
test: epoch 113, loss 1.1584144830703735, acc=0.6027777791023254, loss=1.1584144830703735
train: epoch 114, loss 0.47230765223503113, acc=0.754277765750885, loss=0.47230765223503113
test: epoch 114, loss 1.196592092514038, acc=0.605555534362793, loss=1.196592092514038
train: epoch 115, loss 0.4760216474533081, acc=0.7512221932411194, loss=0.4760216474533081
test: epoch 115, loss 1.006973147392273, acc=0.6305555701255798, loss=1.006973147392273
train: epoch 116, loss 0.4649796485900879, acc=0.757111132144928, loss=0.4649796485900879
test: epoch 116, loss 1.1511567831039429, acc=0.6333333253860474, loss=1.1511567831039429
train: epoch 117, loss 0.47755950689315796, acc=0.7554444670677185, loss=0.47755950689315796
test: epoch 117, loss 1.0067241191864014, acc=0.6361111402511597, loss=1.0067241191864014
train: epoch 118, loss 0.4634702503681183, acc=0.7581666707992554, loss=0.4634702503681183
test: epoch 118, loss 1.112584114074707, acc=0.6361111402511597, loss=1.112584114074707
train: epoch 119, loss 0.4518769681453705, acc=0.7592222094535828, loss=0.4518769681453705
test: epoch 119, loss 1.1138436794281006, acc=0.6361111402511597, loss=1.1138436794281006
train: epoch 120, loss 0.46233129501342773, acc=0.758388876914978, loss=0.46233129501342773
test: epoch 120, loss 1.1022608280181885, acc=0.6333333253860474, loss=1.1022608280181885
train: epoch 121, loss 0.4417891204357147, acc=0.758055567741394, loss=0.4417891204357147
test: epoch 121, loss 1.014390230178833, acc=0.6361111402511597, loss=1.014390230178833
train: epoch 122, loss 0.47240251302719116, acc=0.7601666450500488, loss=0.47240251302719116
test: epoch 122, loss 1.1295100450515747, acc=0.6388888955116272, loss=1.1295100450515747
train: epoch 123, loss 0.4658829867839813, acc=0.7564444541931152, loss=0.4658829867839813
test: epoch 123, loss 1.180113673210144, acc=0.6361111402511597, loss=1.180113673210144
train: epoch 124, loss 0.47153469920158386, acc=0.7567222118377686, loss=0.47153469920158386
test: epoch 124, loss 1.024722933769226, acc=0.6333333253860474, loss=1.024722933769226
train: epoch 125, loss 0.4748901128768921, acc=0.7561110854148865, loss=0.4748901128768921
test: epoch 125, loss 1.0384271144866943, acc=0.6388888955116272, loss=1.0384271144866943
train: epoch 126, loss 0.4598439037799835, acc=0.7627221941947937, loss=0.4598439037799835
test: epoch 126, loss 1.0938820838928223, acc=0.6388888955116272, loss=1.0938820838928223
train: epoch 127, loss 0.4796541631221771, acc=0.7608888745307922, loss=0.4796541631221771
test: epoch 127, loss 0.9571040868759155, acc=0.6333333253860474, loss=0.9571040868759155
train: epoch 128, loss 0.4509313404560089, acc=0.7661111354827881, loss=0.4509313404560089
test: epoch 128, loss 0.9550605416297913, acc=0.644444465637207, loss=0.9550605416297913
train: epoch 129, loss 0.46754398941993713, acc=0.7630000114440918, loss=0.46754398941993713
test: epoch 129, loss 0.9270719885826111, acc=0.6388888955116272, loss=0.9270719885826111
train: epoch 130, loss 0.43855786323547363, acc=0.7682222127914429, loss=0.43855786323547363
test: epoch 130, loss 1.0290254354476929, acc=0.644444465637207, loss=1.0290254354476929
train: epoch 131, loss 0.4342610239982605, acc=0.7746111154556274, loss=0.4342610239982605
test: epoch 131, loss 1.0799278020858765, acc=0.644444465637207, loss=1.0799278020858765
train: epoch 132, loss 0.4311874508857727, acc=0.7761666774749756, loss=0.4311874508857727
test: epoch 132, loss 1.1528677940368652, acc=0.644444465637207, loss=1.1528677940368652
train: epoch 133, loss 0.40391644835472107, acc=0.7846666574478149, loss=0.40391644835472107
test: epoch 133, loss 1.193538784980774, acc=0.6472222208976746, loss=1.193538784980774
train: epoch 134, loss 0.4027527868747711, acc=0.7836666703224182, loss=0.4027527868747711
test: epoch 134, loss 1.1436723470687866, acc=0.6527777910232544, loss=1.1436723470687866
train: epoch 135, loss 0.4079369008541107, acc=0.7835555672645569, loss=0.4079369008541107
test: epoch 135, loss 0.9028691053390503, acc=0.675000011920929, loss=0.9028691053390503
train: epoch 136, loss 0.42750006914138794, acc=0.7773333191871643, loss=0.42750006914138794
test: epoch 136, loss 0.9609711766242981, acc=0.675000011920929, loss=0.9609711766242981
train: epoch 137, loss 0.412597119808197, acc=0.7840555310249329, loss=0.412597119808197
test: epoch 137, loss 0.9764511585235596, acc=0.6638888716697693, loss=0.9764511585235596
train: epoch 138, loss 0.3961479365825653, acc=0.7881110906600952, loss=0.3961479365825653
test: epoch 138, loss 0.8645569682121277, acc=0.6916666626930237, loss=0.8645569682121277
train: epoch 139, loss 0.40189918875694275, acc=0.7864999771118164, loss=0.40189918875694275
test: epoch 139, loss 0.6646748185157776, acc=0.7166666388511658, loss=0.6646748185157776
train: epoch 140, loss 0.4120596647262573, acc=0.7806110978126526, loss=0.4120596647262573
test: epoch 140, loss 0.7032983899116516, acc=0.7138888835906982, loss=0.7032983899116516
train: epoch 141, loss 0.3923575282096863, acc=0.788277804851532, loss=0.3923575282096863
test: epoch 141, loss 0.7279208302497864, acc=0.7166666388511658, loss=0.7279208302497864
train: epoch 142, loss 0.38595545291900635, acc=0.7879999876022339, loss=0.38595545291900635
test: epoch 142, loss 0.7367793917655945, acc=0.7166666388511658, loss=0.7367793917655945
train: epoch 143, loss 0.40874534845352173, acc=0.7945555448532104, loss=0.40874534845352173
test: epoch 143, loss 0.7760764360427856, acc=0.7138888835906982, loss=0.7760764360427856
train: epoch 144, loss 0.403630793094635, acc=0.7889999747276306, loss=0.403630793094635
test: epoch 144, loss 0.7683066725730896, acc=0.7138888835906982, loss=0.7683066725730896
train: epoch 145, loss 0.4308648705482483, acc=0.7736111283302307, loss=0.4308648705482483
test: epoch 145, loss 0.769454300403595, acc=0.699999988079071, loss=0.769454300403595
train: epoch 146, loss 0.4095752537250519, acc=0.7763333320617676, loss=0.4095752537250519
test: epoch 146, loss 0.6847226619720459, acc=0.7055555582046509, loss=0.6847226619720459
train: epoch 147, loss 0.4025622010231018, acc=0.7778333425521851, loss=0.4025622010231018
test: epoch 147, loss 0.7891257405281067, acc=0.7083333134651184, loss=0.7891257405281067
train: epoch 148, loss 0.40441930294036865, acc=0.7805555462837219, loss=0.40441930294036865
test: epoch 148, loss 0.721065104007721, acc=0.7055555582046509, loss=0.721065104007721
train: epoch 149, loss 0.438231885433197, acc=0.7832777500152588, loss=0.438231885433197
test: epoch 149, loss 0.7647027373313904, acc=0.7138888835906982, loss=0.7647027373313904
train: epoch 150, loss 0.4012625515460968, acc=0.7916666865348816, loss=0.4012625515460968
test: epoch 150, loss 0.6739789247512817, acc=0.7138888835906982, loss=0.6739789247512817
