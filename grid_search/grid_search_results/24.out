# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=true", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1562175526, receiver_embed_dim=32, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.3980042934417725, acc=0.04888888821005821, loss=3.3980042934417725
test: epoch 1, loss 4.10398530960083, acc=0.04722222313284874, loss=4.10398530960083
train: epoch 2, loss 2.818023681640625, acc=0.11433333158493042, loss=2.818023681640625
test: epoch 2, loss 4.032115936279297, acc=0.0833333358168602, loss=4.032115936279297
train: epoch 3, loss 2.2738540172576904, acc=0.22377777099609375, loss=2.2738540172576904
test: epoch 3, loss 3.6158342361450195, acc=0.1111111119389534, loss=3.6158342361450195
train: epoch 4, loss 1.8769258260726929, acc=0.32205554842948914, loss=1.8769258260726929
test: epoch 4, loss 3.230626106262207, acc=0.12222222238779068, loss=3.230626106262207
train: epoch 5, loss 1.6498913764953613, acc=0.3777777850627899, loss=1.6498913764953613
test: epoch 5, loss 3.1636593341827393, acc=0.14166666567325592, loss=3.1636593341827393
train: epoch 6, loss 1.5159560441970825, acc=0.41361111402511597, loss=1.5159560441970825
test: epoch 6, loss 2.879533052444458, acc=0.15000000596046448, loss=2.879533052444458
train: epoch 7, loss 1.4104100465774536, acc=0.448888897895813, loss=1.4104100465774536
test: epoch 7, loss 2.808673858642578, acc=0.15000000596046448, loss=2.808673858642578
train: epoch 8, loss 1.3328152894973755, acc=0.48088890314102173, loss=1.3328152894973755
test: epoch 8, loss 2.852740526199341, acc=0.16388888657093048, loss=2.852740526199341
train: epoch 9, loss 1.2799769639968872, acc=0.5006111264228821, loss=1.2799769639968872
test: epoch 9, loss 2.8448235988616943, acc=0.16388888657093048, loss=2.8448235988616943
train: epoch 10, loss 1.2202787399291992, acc=0.5251666903495789, loss=1.2202787399291992
test: epoch 10, loss 2.7268412113189697, acc=0.1805555522441864, loss=2.7268412113189697
train: epoch 11, loss 1.1706565618515015, acc=0.5479444265365601, loss=1.1706565618515015
test: epoch 11, loss 2.498969554901123, acc=0.18611110746860504, loss=2.498969554901123
train: epoch 12, loss 1.1285516023635864, acc=0.5686666369438171, loss=1.1285516023635864
test: epoch 12, loss 2.5082805156707764, acc=0.1944444477558136, loss=2.5082805156707764
train: epoch 13, loss 1.0896934270858765, acc=0.5839999914169312, loss=1.0896934270858765
test: epoch 13, loss 2.542840003967285, acc=0.19722221791744232, loss=2.542840003967285
train: epoch 14, loss 1.0499926805496216, acc=0.5975000262260437, loss=1.0499926805496216
test: epoch 14, loss 2.6255900859832764, acc=0.20000000298023224, loss=2.6255900859832764
train: epoch 15, loss 1.0194586515426636, acc=0.6145555377006531, loss=1.0194586515426636
test: epoch 15, loss 2.634143829345703, acc=0.21388888359069824, loss=2.634143829345703
train: epoch 16, loss 0.996070921421051, acc=0.6231111288070679, loss=0.996070921421051
test: epoch 16, loss 2.5553460121154785, acc=0.20555555820465088, loss=2.5553460121154785
train: epoch 17, loss 0.9598356485366821, acc=0.6413888931274414, loss=0.9598356485366821
test: epoch 17, loss 2.3832333087921143, acc=0.23888888955116272, loss=2.3832333087921143
train: epoch 18, loss 0.9313299655914307, acc=0.6476666927337646, loss=0.9313299655914307
test: epoch 18, loss 2.4933717250823975, acc=0.23055554926395416, loss=2.4933717250823975
train: epoch 19, loss 0.9126405119895935, acc=0.6516110897064209, loss=0.9126405119895935
test: epoch 19, loss 2.3057408332824707, acc=0.24722221493721008, loss=2.3057408332824707
train: epoch 20, loss 0.8954265713691711, acc=0.6633333563804626, loss=0.8954265713691711
test: epoch 20, loss 2.393854856491089, acc=0.2527777850627899, loss=2.393854856491089
train: epoch 21, loss 0.8623702526092529, acc=0.6752777695655823, loss=0.8623702526092529
test: epoch 21, loss 2.2359535694122314, acc=0.2527777850627899, loss=2.2359535694122314
train: epoch 22, loss 0.8385218381881714, acc=0.6859444379806519, loss=0.8385218381881714
test: epoch 22, loss 2.1966798305511475, acc=0.2527777850627899, loss=2.1966798305511475
train: epoch 23, loss 0.8249170184135437, acc=0.6898888945579529, loss=0.8249170184135437
test: epoch 23, loss 2.2029733657836914, acc=0.2888889014720917, loss=2.2029733657836914
train: epoch 24, loss 0.8114176392555237, acc=0.6949999928474426, loss=0.8114176392555237
test: epoch 24, loss 2.219836473464966, acc=0.2750000059604645, loss=2.219836473464966
train: epoch 25, loss 0.8048271536827087, acc=0.6969444155693054, loss=0.8048271536827087
test: epoch 25, loss 2.2063982486724854, acc=0.2750000059604645, loss=2.2063982486724854
train: epoch 26, loss 0.7876029014587402, acc=0.706166684627533, loss=0.7876029014587402
test: epoch 26, loss 2.1086182594299316, acc=0.28333333134651184, loss=2.1086182594299316
train: epoch 27, loss 0.7816978693008423, acc=0.7092221975326538, loss=0.7816978693008423
test: epoch 27, loss 2.018435478210449, acc=0.3027777671813965, loss=2.018435478210449
train: epoch 28, loss 0.7519500255584717, acc=0.7185555696487427, loss=0.7519500255584717
test: epoch 28, loss 1.9693145751953125, acc=0.2888889014720917, loss=1.9693145751953125
train: epoch 29, loss 0.7472005486488342, acc=0.7196666598320007, loss=0.7472005486488342
test: epoch 29, loss 1.9796864986419678, acc=0.2750000059604645, loss=1.9796864986419678
train: epoch 30, loss 0.7320104241371155, acc=0.7262222170829773, loss=0.7320104241371155
test: epoch 30, loss 1.8990288972854614, acc=0.2944444417953491, loss=1.8990288972854614
train: epoch 31, loss 0.7083631753921509, acc=0.7346110939979553, loss=0.7083631753921509
test: epoch 31, loss 2.003066062927246, acc=0.31388887763023376, loss=2.003066062927246
train: epoch 32, loss 0.7005056738853455, acc=0.741944432258606, loss=0.7005056738853455
test: epoch 32, loss 1.9548689126968384, acc=0.3055555522441864, loss=1.9548689126968384
train: epoch 33, loss 0.6891825795173645, acc=0.7412777543067932, loss=0.6891825795173645
test: epoch 33, loss 1.9514720439910889, acc=0.31388887763023376, loss=1.9514720439910889
train: epoch 34, loss 0.6758168935775757, acc=0.7497222423553467, loss=0.6758168935775757
test: epoch 34, loss 1.9638184309005737, acc=0.31388887763023376, loss=1.9638184309005737
train: epoch 35, loss 0.6675320267677307, acc=0.746055543422699, loss=0.6675320267677307
test: epoch 35, loss 1.8848758935928345, acc=0.32777777314186096, loss=1.8848758935928345
train: epoch 36, loss 0.6684067845344543, acc=0.7497222423553467, loss=0.6684067845344543
test: epoch 36, loss 1.8625478744506836, acc=0.3333333432674408, loss=1.8625478744506836
train: epoch 37, loss 0.6446457505226135, acc=0.7602777481079102, loss=0.6446457505226135
test: epoch 37, loss 1.9056644439697266, acc=0.33888888359069824, loss=1.9056644439697266
train: epoch 38, loss 0.6367404460906982, acc=0.7632222175598145, loss=0.6367404460906982
test: epoch 38, loss 1.8907490968704224, acc=0.32777777314186096, loss=1.8907490968704224
train: epoch 39, loss 0.6430625915527344, acc=0.7622222304344177, loss=0.6430625915527344
test: epoch 39, loss 1.8782812356948853, acc=0.3444444537162781, loss=1.8782812356948853
train: epoch 40, loss 0.6227949261665344, acc=0.7715555429458618, loss=0.6227949261665344
test: epoch 40, loss 1.9468106031417847, acc=0.3333333432674408, loss=1.9468106031417847
train: epoch 41, loss 0.6153339147567749, acc=0.7707777619361877, loss=0.6153339147567749
test: epoch 41, loss 1.9421546459197998, acc=0.3444444537162781, loss=1.9421546459197998
train: epoch 42, loss 0.5975226759910583, acc=0.7775555849075317, loss=0.5975226759910583
test: epoch 42, loss 1.887614369392395, acc=0.35277777910232544, loss=1.887614369392395
train: epoch 43, loss 0.5951691269874573, acc=0.7802222371101379, loss=0.5951691269874573
test: epoch 43, loss 1.7586054801940918, acc=0.3499999940395355, loss=1.7586054801940918
train: epoch 44, loss 0.5869114398956299, acc=0.7795000076293945, loss=0.5869114398956299
test: epoch 44, loss 1.7314832210540771, acc=0.3722222149372101, loss=1.7314832210540771
train: epoch 45, loss 0.5965070128440857, acc=0.7808889150619507, loss=0.5965070128440857
test: epoch 45, loss 1.8620344400405884, acc=0.36944442987442017, loss=1.8620344400405884
train: epoch 46, loss 0.5746515989303589, acc=0.7856666445732117, loss=0.5746515989303589
test: epoch 46, loss 1.892317533493042, acc=0.3638888895511627, loss=1.892317533493042
train: epoch 47, loss 0.5629165172576904, acc=0.7909444570541382, loss=0.5629165172576904
test: epoch 47, loss 1.8382309675216675, acc=0.3499999940395355, loss=1.8382309675216675
train: epoch 48, loss 0.5720840692520142, acc=0.7856666445732117, loss=0.5720840692520142
test: epoch 48, loss 1.8093693256378174, acc=0.35555556416511536, loss=1.8093693256378174
train: epoch 49, loss 0.5625112056732178, acc=0.7871666550636292, loss=0.5625112056732178
test: epoch 49, loss 1.7557005882263184, acc=0.3861111104488373, loss=1.7557005882263184
train: epoch 50, loss 0.5566203594207764, acc=0.7922777533531189, loss=0.5566203594207764
test: epoch 50, loss 1.775984764099121, acc=0.4000000059604645, loss=1.775984764099121
train: epoch 51, loss 0.5544000267982483, acc=0.7962777614593506, loss=0.5544000267982483
test: epoch 51, loss 1.8695050477981567, acc=0.36944442987442017, loss=1.8695050477981567
train: epoch 52, loss 0.5411110520362854, acc=0.793666660785675, loss=0.5411110520362854
test: epoch 52, loss 1.730684757232666, acc=0.39722222089767456, loss=1.730684757232666
train: epoch 53, loss 0.5393317937850952, acc=0.7987222075462341, loss=0.5393317937850952
test: epoch 53, loss 1.8233749866485596, acc=0.3777777850627899, loss=1.8233749866485596
train: epoch 54, loss 0.5289886593818665, acc=0.800166666507721, loss=0.5289886593818665
test: epoch 54, loss 1.7965296506881714, acc=0.375, loss=1.7965296506881714
train: epoch 55, loss 0.5351252555847168, acc=0.8029444217681885, loss=0.5351252555847168
test: epoch 55, loss 1.8300564289093018, acc=0.39722222089767456, loss=1.8300564289093018
train: epoch 56, loss 0.5179591774940491, acc=0.8037777543067932, loss=0.5179591774940491
test: epoch 56, loss 1.6711006164550781, acc=0.3777777850627899, loss=1.6711006164550781
train: epoch 57, loss 0.5167316198348999, acc=0.8079444169998169, loss=0.5167316198348999
test: epoch 57, loss 1.7698599100112915, acc=0.4055555462837219, loss=1.7698599100112915
train: epoch 58, loss 0.5139256119728088, acc=0.8064444661140442, loss=0.5139256119728088
test: epoch 58, loss 1.7434498071670532, acc=0.41111111640930176, loss=1.7434498071670532
train: epoch 59, loss 0.4955594539642334, acc=0.8104444742202759, loss=0.4955594539642334
test: epoch 59, loss 1.7706844806671143, acc=0.4277777671813965, loss=1.7706844806671143
train: epoch 60, loss 0.5091808438301086, acc=0.8093888759613037, loss=0.5091808438301086
test: epoch 60, loss 1.8060506582260132, acc=0.40833333134651184, loss=1.8060506582260132
train: epoch 61, loss 0.5090430974960327, acc=0.8065000176429749, loss=0.5090430974960327
test: epoch 61, loss 1.7749627828598022, acc=0.42500001192092896, loss=1.7749627828598022
train: epoch 62, loss 0.4852333068847656, acc=0.8117222189903259, loss=0.4852333068847656
test: epoch 62, loss 1.7370632886886597, acc=0.4333333373069763, loss=1.7370632886886597
train: epoch 63, loss 0.49415743350982666, acc=0.8169999718666077, loss=0.49415743350982666
test: epoch 63, loss 1.726015567779541, acc=0.39444443583488464, loss=1.726015567779541
train: epoch 64, loss 0.490657776594162, acc=0.8090000152587891, loss=0.490657776594162
test: epoch 64, loss 1.6370887756347656, acc=0.42500001192092896, loss=1.6370887756347656
train: epoch 65, loss 0.5000891089439392, acc=0.8130555748939514, loss=0.5000891089439392
test: epoch 65, loss 1.6821331977844238, acc=0.43611112236976624, loss=1.6821331977844238
train: epoch 66, loss 0.4882040321826935, acc=0.815500020980835, loss=0.4882040321826935
test: epoch 66, loss 1.7580363750457764, acc=0.42500001192092896, loss=1.7580363750457764
train: epoch 67, loss 0.48721081018447876, acc=0.8151666522026062, loss=0.48721081018447876
test: epoch 67, loss 1.711236834526062, acc=0.4194444417953491, loss=1.711236834526062
train: epoch 68, loss 0.49039191007614136, acc=0.8147777915000916, loss=0.49039191007614136
test: epoch 68, loss 1.691812515258789, acc=0.4305555522441864, loss=1.691812515258789
train: epoch 69, loss 0.481862872838974, acc=0.8185555338859558, loss=0.481862872838974
test: epoch 69, loss 1.6350840330123901, acc=0.4333333373069763, loss=1.6350840330123901
train: epoch 70, loss 0.47622647881507874, acc=0.8231111168861389, loss=0.47622647881507874
test: epoch 70, loss 1.5431715250015259, acc=0.43888887763023376, loss=1.5431715250015259
train: epoch 71, loss 0.4772845208644867, acc=0.816611111164093, loss=0.4772845208644867
test: epoch 71, loss 1.6166011095046997, acc=0.4444444477558136, loss=1.6166011095046997
train: epoch 72, loss 0.45709678530693054, acc=0.8231666684150696, loss=0.45709678530693054
test: epoch 72, loss 1.7258636951446533, acc=0.4583333432674408, loss=1.7258636951446533
train: epoch 73, loss 0.46502822637557983, acc=0.8216666579246521, loss=0.46502822637557983
test: epoch 73, loss 1.5552785396575928, acc=0.43611112236976624, loss=1.5552785396575928
train: epoch 74, loss 0.46076351404190063, acc=0.8221666812896729, loss=0.46076351404190063
test: epoch 74, loss 1.7138302326202393, acc=0.43888887763023376, loss=1.7138302326202393
train: epoch 75, loss 0.4732626676559448, acc=0.8209999799728394, loss=0.4732626676559448
test: epoch 75, loss 1.5947344303131104, acc=0.46388888359069824, loss=1.5947344303131104
train: epoch 76, loss 0.46024075150489807, acc=0.8247222304344177, loss=0.46024075150489807
test: epoch 76, loss 1.6780012845993042, acc=0.4472222328186035, loss=1.6780012845993042
train: epoch 77, loss 0.46310392022132874, acc=0.8222777843475342, loss=0.46310392022132874
test: epoch 77, loss 1.4818356037139893, acc=0.5027777552604675, loss=1.4818356037139893
train: epoch 78, loss 0.4559263288974762, acc=0.8252778053283691, loss=0.4559263288974762
test: epoch 78, loss 1.4900323152542114, acc=0.4722222089767456, loss=1.4900323152542114
train: epoch 79, loss 0.4535908102989197, acc=0.8257222175598145, loss=0.4535908102989197
test: epoch 79, loss 1.507533073425293, acc=0.47777777910232544, loss=1.507533073425293
train: epoch 80, loss 0.4442862272262573, acc=0.8289444446563721, loss=0.4442862272262573
test: epoch 80, loss 1.5748895406723022, acc=0.46666666865348816, loss=1.5748895406723022
train: epoch 81, loss 0.450035035610199, acc=0.8236111402511597, loss=0.450035035610199
test: epoch 81, loss 1.4525797367095947, acc=0.4861111044883728, loss=1.4525797367095947
train: epoch 82, loss 0.46676409244537354, acc=0.8238333463668823, loss=0.46676409244537354
test: epoch 82, loss 1.4991222620010376, acc=0.5, loss=1.4991222620010376
train: epoch 83, loss 0.4421491026878357, acc=0.8299999833106995, loss=0.4421491026878357
test: epoch 83, loss 1.4694797992706299, acc=0.49444442987442017, loss=1.4694797992706299
train: epoch 84, loss 0.4393521845340729, acc=0.8291666507720947, loss=0.4393521845340729
test: epoch 84, loss 1.4993045330047607, acc=0.4972222149372101, loss=1.4993045330047607
train: epoch 85, loss 0.4457116723060608, acc=0.8271666765213013, loss=0.4457116723060608
test: epoch 85, loss 1.3762080669403076, acc=0.5111111402511597, loss=1.3762080669403076
train: epoch 86, loss 0.4381791949272156, acc=0.8321666717529297, loss=0.4381791949272156
test: epoch 86, loss 1.4436696767807007, acc=0.5055555701255798, loss=1.4436696767807007
train: epoch 87, loss 0.4683389663696289, acc=0.8273888826370239, loss=0.4683389663696289
test: epoch 87, loss 1.40746009349823, acc=0.4861111044883728, loss=1.40746009349823
train: epoch 88, loss 0.4326536953449249, acc=0.8316666483879089, loss=0.4326536953449249
test: epoch 88, loss 1.4046790599822998, acc=0.5277777910232544, loss=1.4046790599822998
train: epoch 89, loss 0.43063098192214966, acc=0.8301666378974915, loss=0.43063098192214966
test: epoch 89, loss 1.4333101511001587, acc=0.519444465637207, loss=1.4333101511001587
train: epoch 90, loss 0.44158297777175903, acc=0.8338888883590698, loss=0.44158297777175903
test: epoch 90, loss 1.4014469385147095, acc=0.5222222208976746, loss=1.4014469385147095
train: epoch 91, loss 0.426705002784729, acc=0.8320000171661377, loss=0.426705002784729
test: epoch 91, loss 1.4799025058746338, acc=0.5249999761581421, loss=1.4799025058746338
train: epoch 92, loss 0.4192045032978058, acc=0.8374444246292114, loss=0.4192045032978058
test: epoch 92, loss 1.4889904260635376, acc=0.4972222149372101, loss=1.4889904260635376
train: epoch 93, loss 0.44202643632888794, acc=0.8246111273765564, loss=0.44202643632888794
test: epoch 93, loss 1.3505223989486694, acc=0.5333333611488342, loss=1.3505223989486694
train: epoch 94, loss 0.42577260732650757, acc=0.8355555534362793, loss=0.42577260732650757
test: epoch 94, loss 1.3125032186508179, acc=0.5527777671813965, loss=1.3125032186508179
train: epoch 95, loss 0.4287080466747284, acc=0.8328333497047424, loss=0.4287080466747284
test: epoch 95, loss 1.3784849643707275, acc=0.550000011920929, loss=1.3784849643707275
train: epoch 96, loss 0.42066434025764465, acc=0.8330000042915344, loss=0.42066434025764465
test: epoch 96, loss 1.2500486373901367, acc=0.5472221970558167, loss=1.2500486373901367
train: epoch 97, loss 0.4390854239463806, acc=0.8313888907432556, loss=0.4390854239463806
test: epoch 97, loss 1.265151858329773, acc=0.5388888716697693, loss=1.265151858329773
train: epoch 98, loss 0.45457926392555237, acc=0.8312222361564636, loss=0.45457926392555237
test: epoch 98, loss 1.2229849100112915, acc=0.5305555462837219, loss=1.2229849100112915
train: epoch 99, loss 0.4540409445762634, acc=0.8277778029441833, loss=0.4540409445762634
test: epoch 99, loss 1.3287948369979858, acc=0.5416666865348816, loss=1.3287948369979858
train: epoch 100, loss 0.4212062954902649, acc=0.8357222080230713, loss=0.4212062954902649
test: epoch 100, loss 1.2781246900558472, acc=0.5388888716697693, loss=1.2781246900558472
train: epoch 101, loss 0.4317343831062317, acc=0.8312777876853943, loss=0.4317343831062317
test: epoch 101, loss 1.253394603729248, acc=0.5305555462837219, loss=1.253394603729248
train: epoch 102, loss 0.4279455244541168, acc=0.8343333601951599, loss=0.4279455244541168
test: epoch 102, loss 1.2752679586410522, acc=0.5416666865348816, loss=1.2752679586410522
train: epoch 103, loss 0.4257080852985382, acc=0.8297777771949768, loss=0.4257080852985382
test: epoch 103, loss 1.1637005805969238, acc=0.5444444417953491, loss=1.1637005805969238
train: epoch 104, loss 0.41891685128211975, acc=0.836222231388092, loss=0.41891685128211975
test: epoch 104, loss 1.232994794845581, acc=0.5611110925674438, loss=1.232994794845581
train: epoch 105, loss 0.41771626472473145, acc=0.8378333449363708, loss=0.41771626472473145
test: epoch 105, loss 1.2554640769958496, acc=0.5583333373069763, loss=1.2554640769958496
train: epoch 106, loss 0.40759626030921936, acc=0.8360000252723694, loss=0.40759626030921936
test: epoch 106, loss 1.2019926309585571, acc=0.5666666626930237, loss=1.2019926309585571
train: epoch 107, loss 0.44066938757896423, acc=0.8352222442626953, loss=0.44066938757896423
test: epoch 107, loss 1.3394887447357178, acc=0.5611110925674438, loss=1.3394887447357178
train: epoch 108, loss 0.42527198791503906, acc=0.8338888883590698, loss=0.42527198791503906
test: epoch 108, loss 1.2785353660583496, acc=0.5694444179534912, loss=1.2785353660583496
train: epoch 109, loss 0.411521315574646, acc=0.8378333449363708, loss=0.411521315574646
test: epoch 109, loss 1.1721946001052856, acc=0.5638889074325562, loss=1.1721946001052856
train: epoch 110, loss 0.44201910495758057, acc=0.8338333368301392, loss=0.44201910495758057
test: epoch 110, loss 1.3798390626907349, acc=0.5472221970558167, loss=1.3798390626907349
train: epoch 111, loss 0.4085637927055359, acc=0.8364999890327454, loss=0.4085637927055359
test: epoch 111, loss 1.3081656694412231, acc=0.5472221970558167, loss=1.3081656694412231
train: epoch 112, loss 0.42945438623428345, acc=0.8357222080230713, loss=0.42945438623428345
test: epoch 112, loss 1.2532947063446045, acc=0.5777778029441833, loss=1.2532947063446045
train: epoch 113, loss 0.4175921082496643, acc=0.8372777700424194, loss=0.4175921082496643
test: epoch 113, loss 1.258874773979187, acc=0.5583333373069763, loss=1.258874773979187
train: epoch 114, loss 0.41487202048301697, acc=0.836388885974884, loss=0.41487202048301697
test: epoch 114, loss 1.3743886947631836, acc=0.5638889074325562, loss=1.3743886947631836
train: epoch 115, loss 0.41089290380477905, acc=0.8335000276565552, loss=0.41089290380477905
test: epoch 115, loss 1.2440710067749023, acc=0.5611110925674438, loss=1.2440710067749023
train: epoch 116, loss 0.4053369462490082, acc=0.8376666903495789, loss=0.4053369462490082
test: epoch 116, loss 1.2011371850967407, acc=0.5722222328186035, loss=1.2011371850967407
train: epoch 117, loss 0.4044595956802368, acc=0.8382222056388855, loss=0.4044595956802368
test: epoch 117, loss 1.1412553787231445, acc=0.5972222089767456, loss=1.1412553787231445
train: epoch 118, loss 0.40346604585647583, acc=0.8366110920906067, loss=0.40346604585647583
test: epoch 118, loss 1.2034966945648193, acc=0.5805555582046509, loss=1.2034966945648193
train: epoch 119, loss 0.41020211577415466, acc=0.8374444246292114, loss=0.41020211577415466
test: epoch 119, loss 1.2421690225601196, acc=0.5555555820465088, loss=1.2421690225601196
train: epoch 120, loss 0.4061136245727539, acc=0.8357222080230713, loss=0.4061136245727539
test: epoch 120, loss 1.2782448530197144, acc=0.5888888835906982, loss=1.2782448530197144
train: epoch 121, loss 0.4125889241695404, acc=0.8318889141082764, loss=0.4125889241695404
test: epoch 121, loss 1.34211003780365, acc=0.5861111283302307, loss=1.34211003780365
train: epoch 122, loss 0.4031173586845398, acc=0.8333888649940491, loss=0.4031173586845398
test: epoch 122, loss 1.2814687490463257, acc=0.5722222328186035, loss=1.2814687490463257
train: epoch 123, loss 0.4042383134365082, acc=0.8346111178398132, loss=0.4042383134365082
test: epoch 123, loss 1.193267822265625, acc=0.5888888835906982, loss=1.193267822265625
train: epoch 124, loss 0.39900365471839905, acc=0.8351666927337646, loss=0.39900365471839905
test: epoch 124, loss 1.1030522584915161, acc=0.6027777791023254, loss=1.1030522584915161
train: epoch 125, loss 0.41994214057922363, acc=0.8372222185134888, loss=0.41994214057922363
test: epoch 125, loss 1.0802383422851562, acc=0.6000000238418579, loss=1.0802383422851562
train: epoch 126, loss 0.39831414818763733, acc=0.8377777934074402, loss=0.39831414818763733
test: epoch 126, loss 1.1353094577789307, acc=0.5916666388511658, loss=1.1353094577789307
train: epoch 127, loss 0.3972049355506897, acc=0.8372222185134888, loss=0.3972049355506897
test: epoch 127, loss 1.185526728630066, acc=0.5916666388511658, loss=1.185526728630066
train: epoch 128, loss 0.38544759154319763, acc=0.8397777676582336, loss=0.38544759154319763
test: epoch 128, loss 1.1050711870193481, acc=0.605555534362793, loss=1.1050711870193481
train: epoch 129, loss 0.39965933561325073, acc=0.8377777934074402, loss=0.39965933561325073
test: epoch 129, loss 1.0685443878173828, acc=0.6027777791023254, loss=1.0685443878173828
train: epoch 130, loss 0.3941713869571686, acc=0.8376666903495789, loss=0.3941713869571686
test: epoch 130, loss 1.0759685039520264, acc=0.605555534362793, loss=1.0759685039520264
train: epoch 131, loss 0.39661985635757446, acc=0.8381666541099548, loss=0.39661985635757446
test: epoch 131, loss 1.0899500846862793, acc=0.6111111044883728, loss=1.0899500846862793
train: epoch 132, loss 0.38739487528800964, acc=0.8390555381774902, loss=0.38739487528800964
test: epoch 132, loss 1.068727731704712, acc=0.6083333492279053, loss=1.068727731704712
train: epoch 133, loss 0.4162895679473877, acc=0.8329444527626038, loss=0.4162895679473877
test: epoch 133, loss 1.1217896938323975, acc=0.6111111044883728, loss=1.1217896938323975
train: epoch 134, loss 0.39642444252967834, acc=0.8374999761581421, loss=0.39642444252967834
test: epoch 134, loss 1.1185357570648193, acc=0.6222222447395325, loss=1.1185357570648193
train: epoch 135, loss 0.38863736391067505, acc=0.8403333425521851, loss=0.38863736391067505
test: epoch 135, loss 1.086499810218811, acc=0.6138888597488403, loss=1.086499810218811
train: epoch 136, loss 0.39979562163352966, acc=0.8371666669845581, loss=0.39979562163352966
test: epoch 136, loss 1.0588860511779785, acc=0.625, loss=1.0588860511779785
train: epoch 137, loss 0.3867091238498688, acc=0.8381111025810242, loss=0.3867091238498688
test: epoch 137, loss 1.0417888164520264, acc=0.6166666746139526, loss=1.0417888164520264
train: epoch 138, loss 0.412693053483963, acc=0.8351110816001892, loss=0.412693053483963
test: epoch 138, loss 0.9881999492645264, acc=0.6305555701255798, loss=0.9881999492645264
train: epoch 139, loss 0.38932403922080994, acc=0.8372777700424194, loss=0.38932403922080994
test: epoch 139, loss 0.9597744941711426, acc=0.6194444298744202, loss=0.9597744941711426
train: epoch 140, loss 0.39596790075302124, acc=0.8401111364364624, loss=0.39596790075302124
test: epoch 140, loss 1.0199631452560425, acc=0.6138888597488403, loss=1.0199631452560425
train: epoch 141, loss 0.38568389415740967, acc=0.8391110897064209, loss=0.38568389415740967
test: epoch 141, loss 0.9200583696365356, acc=0.6277777552604675, loss=0.9200583696365356
train: epoch 142, loss 0.394252747297287, acc=0.8339444398880005, loss=0.394252747297287
test: epoch 142, loss 0.9723392128944397, acc=0.6305555701255798, loss=0.9723392128944397
train: epoch 143, loss 0.4049912989139557, acc=0.8341666460037231, loss=0.4049912989139557
test: epoch 143, loss 1.023421287536621, acc=0.6416666507720947, loss=1.023421287536621
train: epoch 144, loss 0.3819419741630554, acc=0.839555561542511, loss=0.3819419741630554
test: epoch 144, loss 1.0938094854354858, acc=0.6388888955116272, loss=1.0938094854354858
train: epoch 145, loss 0.38435256481170654, acc=0.8387222290039062, loss=0.38435256481170654
test: epoch 145, loss 1.0566167831420898, acc=0.6361111402511597, loss=1.0566167831420898
train: epoch 146, loss 0.3794555068016052, acc=0.8413888812065125, loss=0.3794555068016052
test: epoch 146, loss 1.0178544521331787, acc=0.6416666507720947, loss=1.0178544521331787
train: epoch 147, loss 0.38015568256378174, acc=0.8399999737739563, loss=0.38015568256378174
test: epoch 147, loss 0.9188051223754883, acc=0.644444465637207, loss=0.9188051223754883
train: epoch 148, loss 0.38118818402290344, acc=0.8371111154556274, loss=0.38118818402290344
test: epoch 148, loss 0.9503129124641418, acc=0.6388888955116272, loss=0.9503129124641418
train: epoch 149, loss 0.37662622332572937, acc=0.8394444584846497, loss=0.37662622332572937
test: epoch 149, loss 1.0285582542419434, acc=0.644444465637207, loss=1.0285582542419434
train: epoch 150, loss 0.3813736140727997, acc=0.8396111130714417, loss=0.3813736140727997
test: epoch 150, loss 0.9520200490951538, acc=0.6499999761581421, loss=0.9520200490951538
