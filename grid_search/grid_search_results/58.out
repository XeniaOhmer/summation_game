# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=1", "--temp_decay=1", "--one_hot=false", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=479937983, receiver_embed_dim=64, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.0998756885528564, acc=0.07355555891990662, loss=3.0998756885528564
test: epoch 1, loss 2.703117609024048, acc=0.10000000149011612, loss=2.703117609024048
train: epoch 2, loss 2.1940534114837646, acc=0.1962222158908844, loss=2.1940534114837646
test: epoch 2, loss 2.481890916824341, acc=0.15555556118488312, loss=2.481890916824341
train: epoch 3, loss 1.743554949760437, acc=0.3117222189903259, loss=1.743554949760437
test: epoch 3, loss 2.1585967540740967, acc=0.20555555820465088, loss=2.1585967540740967
train: epoch 4, loss 1.4241317510604858, acc=0.4119444489479065, loss=1.4241317510604858
test: epoch 4, loss 1.8772855997085571, acc=0.24444444477558136, loss=1.8772855997085571
train: epoch 5, loss 1.235944151878357, acc=0.47644445300102234, loss=1.235944151878357
test: epoch 5, loss 1.821580410003662, acc=0.2944444417953491, loss=1.821580410003662
train: epoch 6, loss 1.1491732597351074, acc=0.5138333439826965, loss=1.1491732597351074
test: epoch 6, loss 1.813970685005188, acc=0.2750000059604645, loss=1.813970685005188
train: epoch 7, loss 1.0525048971176147, acc=0.5480555295944214, loss=1.0525048971176147
test: epoch 7, loss 1.8001899719238281, acc=0.28333333134651184, loss=1.8001899719238281
train: epoch 8, loss 0.9667526483535767, acc=0.5756666660308838, loss=0.9667526483535767
test: epoch 8, loss 1.8684651851654053, acc=0.2805555462837219, loss=1.8684651851654053
train: epoch 9, loss 0.9050001502037048, acc=0.5926666855812073, loss=0.9050001502037048
test: epoch 9, loss 1.7108656167984009, acc=0.3027777671813965, loss=1.7108656167984009
train: epoch 10, loss 0.8821606040000916, acc=0.6053333282470703, loss=0.8821606040000916
test: epoch 10, loss 1.7676106691360474, acc=0.3333333432674408, loss=1.7676106691360474
train: epoch 11, loss 0.862383246421814, acc=0.6127222180366516, loss=0.862383246421814
test: epoch 11, loss 1.7188303470611572, acc=0.36666667461395264, loss=1.7188303470611572
train: epoch 12, loss 0.8139007091522217, acc=0.628777801990509, loss=0.8139007091522217
test: epoch 12, loss 1.6343764066696167, acc=0.35555556416511536, loss=1.6343764066696167
train: epoch 13, loss 0.7670047283172607, acc=0.6433333158493042, loss=0.7670047283172607
test: epoch 13, loss 1.7669447660446167, acc=0.3472222089767456, loss=1.7669447660446167
train: epoch 14, loss 0.7630622982978821, acc=0.64811110496521, loss=0.7630622982978821
test: epoch 14, loss 1.8330397605895996, acc=0.36944442987442017, loss=1.8330397605895996
train: epoch 15, loss 0.7431843280792236, acc=0.6559444665908813, loss=0.7431843280792236
test: epoch 15, loss 1.9493017196655273, acc=0.3638888895511627, loss=1.9493017196655273
train: epoch 16, loss 0.7172442078590393, acc=0.6671666502952576, loss=0.7172442078590393
test: epoch 16, loss 1.707066535949707, acc=0.4000000059604645, loss=1.707066535949707
train: epoch 17, loss 0.7138444781303406, acc=0.6701666712760925, loss=0.7138444781303406
test: epoch 17, loss 1.9326962232589722, acc=0.39722222089767456, loss=1.9326962232589722
train: epoch 18, loss 0.6857374906539917, acc=0.6836666464805603, loss=0.6857374906539917
test: epoch 18, loss 1.7035661935806274, acc=0.4000000059604645, loss=1.7035661935806274
train: epoch 19, loss 0.6650592684745789, acc=0.6938333511352539, loss=0.6650592684745789
test: epoch 19, loss 1.82279634475708, acc=0.3638888895511627, loss=1.82279634475708
train: epoch 20, loss 0.6461104154586792, acc=0.7008888721466064, loss=0.6461104154586792
test: epoch 20, loss 1.66292405128479, acc=0.4027777910232544, loss=1.66292405128479
train: epoch 21, loss 0.6623761057853699, acc=0.6909999847412109, loss=0.6623761057853699
test: epoch 21, loss 1.9304674863815308, acc=0.39722222089767456, loss=1.9304674863815308
train: epoch 22, loss 0.6261667609214783, acc=0.7065555453300476, loss=0.6261667609214783
test: epoch 22, loss 1.7455699443817139, acc=0.40833333134651184, loss=1.7455699443817139
train: epoch 23, loss 0.6051812171936035, acc=0.7185555696487427, loss=0.6051812171936035
test: epoch 23, loss 1.8149160146713257, acc=0.4027777910232544, loss=1.8149160146713257
train: epoch 24, loss 0.5934218764305115, acc=0.7326111197471619, loss=0.5934218764305115
test: epoch 24, loss 1.780712604522705, acc=0.43611112236976624, loss=1.780712604522705
train: epoch 25, loss 0.5726708769798279, acc=0.746833324432373, loss=0.5726708769798279
test: epoch 25, loss 1.618106484413147, acc=0.43888887763023376, loss=1.618106484413147
train: epoch 26, loss 0.5515584945678711, acc=0.753944456577301, loss=0.5515584945678711
test: epoch 26, loss 1.4500871896743774, acc=0.4305555522441864, loss=1.4500871896743774
train: epoch 27, loss 0.5299352407455444, acc=0.7647777795791626, loss=0.5299352407455444
test: epoch 27, loss 1.9120501279830933, acc=0.43611112236976624, loss=1.9120501279830933
train: epoch 28, loss 0.5403725504875183, acc=0.758055567741394, loss=0.5403725504875183
test: epoch 28, loss 1.7703945636749268, acc=0.43611112236976624, loss=1.7703945636749268
train: epoch 29, loss 0.5240915417671204, acc=0.7690555453300476, loss=0.5240915417671204
test: epoch 29, loss 1.778944492340088, acc=0.43888887763023376, loss=1.778944492340088
train: epoch 30, loss 0.5136392116546631, acc=0.7762777805328369, loss=0.5136392116546631
test: epoch 30, loss 1.7406394481658936, acc=0.4194444417953491, loss=1.7406394481658936
train: epoch 31, loss 0.5144737362861633, acc=0.7706666588783264, loss=0.5144737362861633
test: epoch 31, loss 1.4904422760009766, acc=0.42222222685813904, loss=1.4904422760009766
train: epoch 32, loss 0.503638744354248, acc=0.7788888812065125, loss=0.503638744354248
test: epoch 32, loss 1.7355067729949951, acc=0.4333333373069763, loss=1.7355067729949951
train: epoch 33, loss 0.4767099916934967, acc=0.788611114025116, loss=0.4767099916934967
test: epoch 33, loss 1.650173306465149, acc=0.4472222328186035, loss=1.650173306465149
train: epoch 34, loss 0.48010310530662537, acc=0.7830555438995361, loss=0.48010310530662537
test: epoch 34, loss 1.6643924713134766, acc=0.4444444477558136, loss=1.6643924713134766
train: epoch 35, loss 0.4726852476596832, acc=0.7857221961021423, loss=0.4726852476596832
test: epoch 35, loss 1.702009677886963, acc=0.4416666626930237, loss=1.702009677886963
train: epoch 36, loss 0.4816014766693115, acc=0.7841110825538635, loss=0.4816014766693115
test: epoch 36, loss 1.7049025297164917, acc=0.46666666865348816, loss=1.7049025297164917
train: epoch 37, loss 0.4688445031642914, acc=0.7849444150924683, loss=0.4688445031642914
test: epoch 37, loss 1.7254055738449097, acc=0.4611110985279083, loss=1.7254055738449097
train: epoch 38, loss 0.4744904637336731, acc=0.7883333563804626, loss=0.4744904637336731
test: epoch 38, loss 1.5780107975006104, acc=0.46666666865348816, loss=1.5780107975006104
train: epoch 39, loss 0.4693145155906677, acc=0.7899444699287415, loss=0.4693145155906677
test: epoch 39, loss 1.534360408782959, acc=0.49444442987442017, loss=1.534360408782959
train: epoch 40, loss 0.47337812185287476, acc=0.789222240447998, loss=0.47337812185287476
test: epoch 40, loss 1.767383337020874, acc=0.46666666865348816, loss=1.767383337020874
train: epoch 41, loss 0.45473620295524597, acc=0.7926666736602783, loss=0.45473620295524597
test: epoch 41, loss 1.6388652324676514, acc=0.4861111044883728, loss=1.6388652324676514
train: epoch 42, loss 0.4531531035900116, acc=0.7907778024673462, loss=0.4531531035900116
test: epoch 42, loss 1.6230331659317017, acc=0.47777777910232544, loss=1.6230331659317017
train: epoch 43, loss 0.44599032402038574, acc=0.7963888645172119, loss=0.44599032402038574
test: epoch 43, loss 1.833261489868164, acc=0.4444444477558136, loss=1.833261489868164
train: epoch 44, loss 0.44332194328308105, acc=0.7990000247955322, loss=0.44332194328308105
test: epoch 44, loss 1.7281709909439087, acc=0.4749999940395355, loss=1.7281709909439087
train: epoch 45, loss 0.44257014989852905, acc=0.7992222309112549, loss=0.44257014989852905
test: epoch 45, loss 1.5703474283218384, acc=0.519444465637207, loss=1.5703474283218384
train: epoch 46, loss 0.44306713342666626, acc=0.8006666898727417, loss=0.44306713342666626
test: epoch 46, loss 1.6885205507278442, acc=0.519444465637207, loss=1.6885205507278442
train: epoch 47, loss 0.44486698508262634, acc=0.7994444370269775, loss=0.44486698508262634
test: epoch 47, loss 1.4380844831466675, acc=0.4888888895511627, loss=1.4380844831466675
train: epoch 48, loss 0.432504266500473, acc=0.8026111125946045, loss=0.432504266500473
test: epoch 48, loss 1.6510555744171143, acc=0.5222222208976746, loss=1.6510555744171143
train: epoch 49, loss 0.42759275436401367, acc=0.8029444217681885, loss=0.42759275436401367
test: epoch 49, loss 1.532184362411499, acc=0.5166666507720947, loss=1.532184362411499
train: epoch 50, loss 0.43329599499702454, acc=0.8026666641235352, loss=0.43329599499702454
test: epoch 50, loss 1.7216166257858276, acc=0.5027777552604675, loss=1.7216166257858276
train: epoch 51, loss 0.43849390745162964, acc=0.8016111254692078, loss=0.43849390745162964
test: epoch 51, loss 1.5621446371078491, acc=0.5222222208976746, loss=1.5621446371078491
train: epoch 52, loss 0.43194225430488586, acc=0.8035555481910706, loss=0.43194225430488586
test: epoch 52, loss 1.3853976726531982, acc=0.4972222149372101, loss=1.3853976726531982
train: epoch 53, loss 0.42256513237953186, acc=0.8043333292007446, loss=0.42256513237953186
test: epoch 53, loss 1.622636318206787, acc=0.5166666507720947, loss=1.622636318206787
train: epoch 54, loss 0.414367139339447, acc=0.8086666464805603, loss=0.414367139339447
test: epoch 54, loss 1.4401458501815796, acc=0.5111111402511597, loss=1.4401458501815796
train: epoch 55, loss 0.41971829533576965, acc=0.8072777986526489, loss=0.41971829533576965
test: epoch 55, loss 1.6801414489746094, acc=0.519444465637207, loss=1.6801414489746094
train: epoch 56, loss 0.4203394949436188, acc=0.808555543422699, loss=0.4203394949436188
test: epoch 56, loss 1.4902628660202026, acc=0.5249999761581421, loss=1.4902628660202026
train: epoch 57, loss 0.4129364788532257, acc=0.8113889098167419, loss=0.4129364788532257
test: epoch 57, loss 1.4774936437606812, acc=0.5277777910232544, loss=1.4774936437606812
train: epoch 58, loss 0.42053884267807007, acc=0.8068888783454895, loss=0.42053884267807007
test: epoch 58, loss 1.2746384143829346, acc=0.5277777910232544, loss=1.2746384143829346
train: epoch 59, loss 0.41308513283729553, acc=0.8113333582878113, loss=0.41308513283729553
test: epoch 59, loss 1.446300983428955, acc=0.5138888955116272, loss=1.446300983428955
train: epoch 60, loss 0.40696480870246887, acc=0.8122777938842773, loss=0.40696480870246887
test: epoch 60, loss 1.6239285469055176, acc=0.5249999761581421, loss=1.6239285469055176
train: epoch 61, loss 0.40925973653793335, acc=0.8109444379806519, loss=0.40925973653793335
test: epoch 61, loss 1.5552423000335693, acc=0.5, loss=1.5552423000335693
train: epoch 62, loss 0.4071691930294037, acc=0.8118333220481873, loss=0.4071691930294037
test: epoch 62, loss 1.5813031196594238, acc=0.5111111402511597, loss=1.5813031196594238
train: epoch 63, loss 0.40535759925842285, acc=0.8156111240386963, loss=0.40535759925842285
test: epoch 63, loss 1.4114400148391724, acc=0.5277777910232544, loss=1.4114400148391724
train: epoch 64, loss 0.40348801016807556, acc=0.8110555410385132, loss=0.40348801016807556
test: epoch 64, loss 1.4505729675292969, acc=0.5249999761581421, loss=1.4505729675292969
train: epoch 65, loss 0.39297565817832947, acc=0.8174999952316284, loss=0.39297565817832947
test: epoch 65, loss 1.4405287504196167, acc=0.5333333611488342, loss=1.4405287504196167
train: epoch 66, loss 0.4031752943992615, acc=0.8145555257797241, loss=0.4031752943992615
test: epoch 66, loss 1.5633291006088257, acc=0.5138888955116272, loss=1.5633291006088257
train: epoch 67, loss 0.4170754849910736, acc=0.8067777752876282, loss=0.4170754849910736
test: epoch 67, loss 1.4574778079986572, acc=0.5222222208976746, loss=1.4574778079986572
train: epoch 68, loss 0.4080026149749756, acc=0.8131111264228821, loss=0.4080026149749756
test: epoch 68, loss 1.4152145385742188, acc=0.5277777910232544, loss=1.4152145385742188
train: epoch 69, loss 0.40323540568351746, acc=0.8109999895095825, loss=0.40323540568351746
test: epoch 69, loss 1.363708734512329, acc=0.5472221970558167, loss=1.363708734512329
train: epoch 70, loss 0.38607385754585266, acc=0.8187222480773926, loss=0.38607385754585266
test: epoch 70, loss 1.4985911846160889, acc=0.5444444417953491, loss=1.4985911846160889
train: epoch 71, loss 0.4048006534576416, acc=0.8133888840675354, loss=0.4048006534576416
test: epoch 71, loss 1.4469149112701416, acc=0.5444444417953491, loss=1.4469149112701416
train: epoch 72, loss 0.3874346911907196, acc=0.8172222375869751, loss=0.3874346911907196
test: epoch 72, loss 1.6408271789550781, acc=0.5361111164093018, loss=1.6408271789550781
train: epoch 73, loss 0.39695653319358826, acc=0.8161666393280029, loss=0.39695653319358826
test: epoch 73, loss 1.5859973430633545, acc=0.5472221970558167, loss=1.5859973430633545
train: epoch 74, loss 0.3868485391139984, acc=0.8214444518089294, loss=0.3868485391139984
test: epoch 74, loss 1.4980838298797607, acc=0.5472221970558167, loss=1.4980838298797607
train: epoch 75, loss 0.3823992908000946, acc=0.8224444389343262, loss=0.3823992908000946
test: epoch 75, loss 1.808720588684082, acc=0.5166666507720947, loss=1.808720588684082
train: epoch 76, loss 0.3864312469959259, acc=0.8212222456932068, loss=0.3864312469959259
test: epoch 76, loss 1.3868157863616943, acc=0.5472221970558167, loss=1.3868157863616943
train: epoch 77, loss 0.3887319266796112, acc=0.8195555806159973, loss=0.3887319266796112
test: epoch 77, loss 1.413923978805542, acc=0.5444444417953491, loss=1.413923978805542
train: epoch 78, loss 0.3795359432697296, acc=0.8232222199440002, loss=0.3795359432697296
test: epoch 78, loss 1.6058237552642822, acc=0.5444444417953491, loss=1.6058237552642822
train: epoch 79, loss 0.39314255118370056, acc=0.816777765750885, loss=0.39314255118370056
test: epoch 79, loss 1.4495022296905518, acc=0.5444444417953491, loss=1.4495022296905518
train: epoch 80, loss 0.3874424695968628, acc=0.8203333616256714, loss=0.3874424695968628
test: epoch 80, loss 1.4917019605636597, acc=0.5444444417953491, loss=1.4917019605636597
train: epoch 81, loss 0.3781965374946594, acc=0.8223333358764648, loss=0.3781965374946594
test: epoch 81, loss 1.6023318767547607, acc=0.5444444417953491, loss=1.6023318767547607
train: epoch 82, loss 0.3906075656414032, acc=0.8199999928474426, loss=0.3906075656414032
test: epoch 82, loss 1.4137892723083496, acc=0.550000011920929, loss=1.4137892723083496
train: epoch 83, loss 0.38162195682525635, acc=0.8230000138282776, loss=0.38162195682525635
test: epoch 83, loss 1.3569039106369019, acc=0.5444444417953491, loss=1.3569039106369019
train: epoch 84, loss 0.38432276248931885, acc=0.8195555806159973, loss=0.38432276248931885
test: epoch 84, loss 1.5550825595855713, acc=0.5222222208976746, loss=1.5550825595855713
train: epoch 85, loss 0.3565131723880768, acc=0.8323333263397217, loss=0.3565131723880768
test: epoch 85, loss 1.5080921649932861, acc=0.5472221970558167, loss=1.5080921649932861
train: epoch 86, loss 0.38418877124786377, acc=0.8232222199440002, loss=0.38418877124786377
test: epoch 86, loss 1.3511756658554077, acc=0.5472221970558167, loss=1.3511756658554077
train: epoch 87, loss 0.3761584162712097, acc=0.8233888745307922, loss=0.3761584162712097
test: epoch 87, loss 1.4452875852584839, acc=0.5472221970558167, loss=1.4452875852584839
train: epoch 88, loss 0.37763962149620056, acc=0.8231666684150696, loss=0.37763962149620056
test: epoch 88, loss 1.608763337135315, acc=0.5444444417953491, loss=1.608763337135315
train: epoch 89, loss 0.3595505654811859, acc=0.8296666741371155, loss=0.3595505654811859
test: epoch 89, loss 1.5169882774353027, acc=0.5444444417953491, loss=1.5169882774353027
train: epoch 90, loss 0.39042556285858154, acc=0.8191666603088379, loss=0.39042556285858154
test: epoch 90, loss 1.3529185056686401, acc=0.574999988079071, loss=1.3529185056686401
train: epoch 91, loss 0.3789539635181427, acc=0.824222207069397, loss=0.3789539635181427
test: epoch 91, loss 1.3627631664276123, acc=0.5694444179534912, loss=1.3627631664276123
train: epoch 92, loss 0.3563755452632904, acc=0.8313888907432556, loss=0.3563755452632904
test: epoch 92, loss 1.4134764671325684, acc=0.5444444417953491, loss=1.4134764671325684
train: epoch 93, loss 0.3697498142719269, acc=0.8259999752044678, loss=0.3697498142719269
test: epoch 93, loss 1.4257317781448364, acc=0.574999988079071, loss=1.4257317781448364
train: epoch 94, loss 0.3662554621696472, acc=0.8270000219345093, loss=0.3662554621696472
test: epoch 94, loss 1.462164044380188, acc=0.550000011920929, loss=1.462164044380188
train: epoch 95, loss 0.37238195538520813, acc=0.8245000243186951, loss=0.37238195538520813
test: epoch 95, loss 1.267922282218933, acc=0.5472221970558167, loss=1.267922282218933
train: epoch 96, loss 0.3736063838005066, acc=0.8232222199440002, loss=0.3736063838005066
test: epoch 96, loss 1.4477722644805908, acc=0.5722222328186035, loss=1.4477722644805908
train: epoch 97, loss 0.3611033856868744, acc=0.8293333053588867, loss=0.3611033856868744
test: epoch 97, loss 1.4410775899887085, acc=0.5777778029441833, loss=1.4410775899887085
train: epoch 98, loss 0.3812958598136902, acc=0.8240000009536743, loss=0.3812958598136902
test: epoch 98, loss 1.3173637390136719, acc=0.5805555582046509, loss=1.3173637390136719
train: epoch 99, loss 0.3617962598800659, acc=0.8305000066757202, loss=0.3617962598800659
test: epoch 99, loss 1.3570497035980225, acc=0.574999988079071, loss=1.3570497035980225
train: epoch 100, loss 0.36735138297080994, acc=0.824388861656189, loss=0.36735138297080994
test: epoch 100, loss 1.2600806951522827, acc=0.5777778029441833, loss=1.2600806951522827
train: epoch 101, loss 0.35180655121803284, acc=0.8305000066757202, loss=0.35180655121803284
test: epoch 101, loss 1.5742251873016357, acc=0.574999988079071, loss=1.5742251873016357
train: epoch 102, loss 0.3552708625793457, acc=0.831944465637207, loss=0.3552708625793457
test: epoch 102, loss 1.4934449195861816, acc=0.5777778029441833, loss=1.4934449195861816
train: epoch 103, loss 0.3501587212085724, acc=0.8372777700424194, loss=0.3501587212085724
test: epoch 103, loss 1.3717068433761597, acc=0.5777778029441833, loss=1.3717068433761597
train: epoch 104, loss 0.34892135858535767, acc=0.8499444723129272, loss=0.34892135858535767
test: epoch 104, loss 1.3087674379348755, acc=0.5777778029441833, loss=1.3087674379348755
train: epoch 105, loss 0.3425283432006836, acc=0.8575555682182312, loss=0.3425283432006836
test: epoch 105, loss 1.451025366783142, acc=0.5777778029441833, loss=1.451025366783142
train: epoch 106, loss 0.32367587089538574, acc=0.8652222156524658, loss=0.32367587089538574
test: epoch 106, loss 1.313039779663086, acc=0.574999988079071, loss=1.313039779663086
train: epoch 107, loss 0.3398596942424774, acc=0.8577222228050232, loss=0.3398596942424774
test: epoch 107, loss 1.2945021390914917, acc=0.5777778029441833, loss=1.2945021390914917
train: epoch 108, loss 0.3041432797908783, acc=0.8712777495384216, loss=0.3041432797908783
test: epoch 108, loss 1.3944714069366455, acc=0.5777778029441833, loss=1.3944714069366455
train: epoch 109, loss 0.3115435540676117, acc=0.8686666488647461, loss=0.3115435540676117
test: epoch 109, loss 1.307410478591919, acc=0.5777778029441833, loss=1.307410478591919
train: epoch 110, loss 0.3133370578289032, acc=0.8665555715560913, loss=0.3133370578289032
test: epoch 110, loss 1.4456617832183838, acc=0.5805555582046509, loss=1.4456617832183838
train: epoch 111, loss 0.30590271949768066, acc=0.86772221326828, loss=0.30590271949768066
test: epoch 111, loss 1.4154397249221802, acc=0.5777778029441833, loss=1.4154397249221802
train: epoch 112, loss 0.30152463912963867, acc=0.8700555562973022, loss=0.30152463912963867
test: epoch 112, loss 1.5408356189727783, acc=0.5777778029441833, loss=1.5408356189727783
train: epoch 113, loss 0.306143581867218, acc=0.8694999814033508, loss=0.306143581867218
test: epoch 113, loss 1.450343132019043, acc=0.5805555582046509, loss=1.450343132019043
train: epoch 114, loss 0.2955278158187866, acc=0.8738889098167419, loss=0.2955278158187866
test: epoch 114, loss 1.3635292053222656, acc=0.5861111283302307, loss=1.3635292053222656
train: epoch 115, loss 0.3214823603630066, acc=0.867388904094696, loss=0.3214823603630066
test: epoch 115, loss 1.4314680099487305, acc=0.5861111283302307, loss=1.4314680099487305
train: epoch 116, loss 0.3073391616344452, acc=0.8669999837875366, loss=0.3073391616344452
test: epoch 116, loss 1.2919800281524658, acc=0.5861111283302307, loss=1.2919800281524658
train: epoch 117, loss 0.28901591897010803, acc=0.8758333325386047, loss=0.28901591897010803
test: epoch 117, loss 1.4523102045059204, acc=0.5861111283302307, loss=1.4523102045059204
train: epoch 118, loss 0.30087241530418396, acc=0.8731111288070679, loss=0.30087241530418396
test: epoch 118, loss 1.3816910982131958, acc=0.5861111283302307, loss=1.3816910982131958
train: epoch 119, loss 0.3286207318305969, acc=0.8633333444595337, loss=0.3286207318305969
test: epoch 119, loss 1.3676893711090088, acc=0.5861111283302307, loss=1.3676893711090088
train: epoch 120, loss 0.30884507298469543, acc=0.8662222027778625, loss=0.30884507298469543
test: epoch 120, loss 1.4888477325439453, acc=0.5777778029441833, loss=1.4888477325439453
train: epoch 121, loss 0.28727853298187256, acc=0.8721666932106018, loss=0.28727853298187256
test: epoch 121, loss 1.3837215900421143, acc=0.5861111283302307, loss=1.3837215900421143
train: epoch 122, loss 0.28603246808052063, acc=0.8734444379806519, loss=0.28603246808052063
test: epoch 122, loss 1.21534264087677, acc=0.5861111283302307, loss=1.21534264087677
train: epoch 123, loss 0.28812745213508606, acc=0.8732222318649292, loss=0.28812745213508606
test: epoch 123, loss 1.351388692855835, acc=0.5777778029441833, loss=1.351388692855835
train: epoch 124, loss 0.28972771763801575, acc=0.8759999871253967, loss=0.28972771763801575
test: epoch 124, loss 1.4891753196716309, acc=0.5861111283302307, loss=1.4891753196716309
train: epoch 125, loss 0.30352458357810974, acc=0.8701666593551636, loss=0.30352458357810974
test: epoch 125, loss 1.391128659248352, acc=0.5861111283302307, loss=1.391128659248352
train: epoch 126, loss 0.2858913540840149, acc=0.8728888630867004, loss=0.2858913540840149
test: epoch 126, loss 1.4082865715026855, acc=0.5833333134651184, loss=1.4082865715026855
train: epoch 127, loss 0.2920950949192047, acc=0.8756666779518127, loss=0.2920950949192047
test: epoch 127, loss 1.4809983968734741, acc=0.5861111283302307, loss=1.4809983968734741
train: epoch 128, loss 0.28834259510040283, acc=0.874833345413208, loss=0.28834259510040283
test: epoch 128, loss 1.4140384197235107, acc=0.5833333134651184, loss=1.4140384197235107
train: epoch 129, loss 0.292877197265625, acc=0.8762778043746948, loss=0.292877197265625
test: epoch 129, loss 1.5032840967178345, acc=0.5861111283302307, loss=1.5032840967178345
train: epoch 130, loss 0.2924780249595642, acc=0.8772222399711609, loss=0.2924780249595642
test: epoch 130, loss 1.469480037689209, acc=0.5861111283302307, loss=1.469480037689209
train: epoch 131, loss 0.28116080164909363, acc=0.8765555620193481, loss=0.28116080164909363
test: epoch 131, loss 1.4750844240188599, acc=0.5861111283302307, loss=1.4750844240188599
train: epoch 132, loss 0.28013327717781067, acc=0.8733333349227905, loss=0.28013327717781067
test: epoch 132, loss 1.5777579545974731, acc=0.5861111283302307, loss=1.5777579545974731
train: epoch 133, loss 0.28085389733314514, acc=0.8797777891159058, loss=0.28085389733314514
test: epoch 133, loss 1.465551733970642, acc=0.5833333134651184, loss=1.465551733970642
train: epoch 134, loss 0.2768544852733612, acc=0.8780555725097656, loss=0.2768544852733612
test: epoch 134, loss 1.490185260772705, acc=0.5861111283302307, loss=1.490185260772705
train: epoch 135, loss 0.2923316955566406, acc=0.8757777810096741, loss=0.2923316955566406
test: epoch 135, loss 1.3680920600891113, acc=0.5861111283302307, loss=1.3680920600891113
train: epoch 136, loss 0.27711209654808044, acc=0.8788333535194397, loss=0.27711209654808044
test: epoch 136, loss 1.4211572408676147, acc=0.5861111283302307, loss=1.4211572408676147
train: epoch 137, loss 0.2915480136871338, acc=0.8741111159324646, loss=0.2915480136871338
test: epoch 137, loss 1.4455000162124634, acc=0.5861111283302307, loss=1.4455000162124634
train: epoch 138, loss 0.27005162835121155, acc=0.8811666369438171, loss=0.27005162835121155
test: epoch 138, loss 1.420647382736206, acc=0.5861111283302307, loss=1.420647382736206
train: epoch 139, loss 0.27152717113494873, acc=0.8799444437026978, loss=0.27152717113494873
test: epoch 139, loss 1.217158317565918, acc=0.5833333134651184, loss=1.217158317565918
train: epoch 140, loss 0.2813435196876526, acc=0.8766666650772095, loss=0.2813435196876526
test: epoch 140, loss 1.4482975006103516, acc=0.5861111283302307, loss=1.4482975006103516
train: epoch 141, loss 0.2851811349391937, acc=0.8753888607025146, loss=0.2851811349391937
test: epoch 141, loss 1.2516167163848877, acc=0.5861111283302307, loss=1.2516167163848877
train: epoch 142, loss 0.29231324791908264, acc=0.8764444589614868, loss=0.29231324791908264
test: epoch 142, loss 1.3446189165115356, acc=0.5833333134651184, loss=1.3446189165115356
train: epoch 143, loss 0.28852787613868713, acc=0.8763889074325562, loss=0.28852787613868713
test: epoch 143, loss 1.275397539138794, acc=0.5861111283302307, loss=1.275397539138794
train: epoch 144, loss 0.2710970938205719, acc=0.8815000057220459, loss=0.2710970938205719
test: epoch 144, loss 1.344874620437622, acc=0.5833333134651184, loss=1.344874620437622
train: epoch 145, loss 0.2768835127353668, acc=0.8771111369132996, loss=0.2768835127353668
test: epoch 145, loss 1.4690566062927246, acc=0.5833333134651184, loss=1.4690566062927246
train: epoch 146, loss 0.30431458353996277, acc=0.8728333115577698, loss=0.30431458353996277
test: epoch 146, loss 1.4939258098602295, acc=0.5833333134651184, loss=1.4939258098602295
train: epoch 147, loss 0.263094961643219, acc=0.8848888874053955, loss=0.263094961643219
test: epoch 147, loss 1.4172823429107666, acc=0.5861111283302307, loss=1.4172823429107666
train: epoch 148, loss 0.26447510719299316, acc=0.8863333463668823, loss=0.26447510719299316
test: epoch 148, loss 1.43095064163208, acc=0.5805555582046509, loss=1.43095064163208
train: epoch 149, loss 0.28589126467704773, acc=0.8783888816833496, loss=0.28589126467704773
test: epoch 149, loss 1.4424870014190674, acc=0.5861111283302307, loss=1.4424870014190674
train: epoch 150, loss 0.2734726369380951, acc=0.8796666860580444, loss=0.2734726369380951
test: epoch 150, loss 1.4277057647705078, acc=0.5861111283302307, loss=1.4277057647705078
