# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1.5", "--temp_decay=1", "--one_hot=true", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1136906779, receiver_embed_dim=32, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.403669595718384, acc=0.05155555531382561, loss=3.403669595718384
test: epoch 1, loss 3.6341910362243652, acc=0.06111111119389534, loss=3.6341910362243652
train: epoch 2, loss 2.4876303672790527, acc=0.18711110949516296, loss=2.4876303672790527
test: epoch 2, loss 2.7236440181732178, acc=0.125, loss=2.7236440181732178
train: epoch 3, loss 1.7914365530014038, acc=0.31538888812065125, loss=1.7914365530014038
test: epoch 3, loss 2.5908350944519043, acc=0.13611111044883728, loss=2.5908350944519043
train: epoch 4, loss 1.5989009141921997, acc=0.37388888001441956, loss=1.5989009141921997
test: epoch 4, loss 2.6301867961883545, acc=0.125, loss=2.6301867961883545
train: epoch 5, loss 1.4624439477920532, acc=0.42161110043525696, loss=1.4624439477920532
test: epoch 5, loss 2.5932886600494385, acc=0.14444445073604584, loss=2.5932886600494385
train: epoch 6, loss 1.3529256582260132, acc=0.4625000059604645, loss=1.3529256582260132
test: epoch 6, loss 2.7030014991760254, acc=0.16111111640930176, loss=2.7030014991760254
train: epoch 7, loss 1.2851577997207642, acc=0.496055543422699, loss=1.2851577997207642
test: epoch 7, loss 2.6296913623809814, acc=0.17777778208255768, loss=2.6296913623809814
train: epoch 8, loss 1.2214635610580444, acc=0.5173888802528381, loss=1.2214635610580444
test: epoch 8, loss 2.6365256309509277, acc=0.17777778208255768, loss=2.6365256309509277
train: epoch 9, loss 1.1563297510147095, acc=0.546999990940094, loss=1.1563297510147095
test: epoch 9, loss 2.6679604053497314, acc=0.18611110746860504, loss=2.6679604053497314
train: epoch 10, loss 1.1232205629348755, acc=0.562333345413208, loss=1.1232205629348755
test: epoch 10, loss 2.692319631576538, acc=0.19722221791744232, loss=2.692319631576538
train: epoch 11, loss 1.0627779960632324, acc=0.5882222056388855, loss=1.0627779960632324
test: epoch 11, loss 2.6435511112213135, acc=0.19722221791744232, loss=2.6435511112213135
train: epoch 12, loss 1.0268700122833252, acc=0.6046110987663269, loss=1.0268700122833252
test: epoch 12, loss 2.6004717350006104, acc=0.18888889253139496, loss=2.6004717350006104
train: epoch 13, loss 0.9883798360824585, acc=0.620555579662323, loss=0.9883798360824585
test: epoch 13, loss 2.540370464324951, acc=0.21111111342906952, loss=2.540370464324951
train: epoch 14, loss 0.9528142213821411, acc=0.6309999823570251, loss=0.9528142213821411
test: epoch 14, loss 2.5172111988067627, acc=0.2222222238779068, loss=2.5172111988067627
train: epoch 15, loss 0.9245511293411255, acc=0.6443333625793457, loss=0.9245511293411255
test: epoch 15, loss 2.5854525566101074, acc=0.20277777314186096, loss=2.5854525566101074
train: epoch 16, loss 0.9053825736045837, acc=0.6567222476005554, loss=0.9053825736045837
test: epoch 16, loss 2.379723072052002, acc=0.2083333283662796, loss=2.379723072052002
train: epoch 17, loss 0.8626289367675781, acc=0.6698889136314392, loss=0.8626289367675781
test: epoch 17, loss 2.3021862506866455, acc=0.2527777850627899, loss=2.3021862506866455
train: epoch 18, loss 0.8305151462554932, acc=0.6899444460868835, loss=0.8305151462554932
test: epoch 18, loss 2.1610138416290283, acc=0.2611111104488373, loss=2.1610138416290283
train: epoch 19, loss 0.8146055340766907, acc=0.6909999847412109, loss=0.8146055340766907
test: epoch 19, loss 2.2342357635498047, acc=0.26944443583488464, loss=2.2342357635498047
train: epoch 20, loss 0.7908853888511658, acc=0.7070555686950684, loss=0.7908853888511658
test: epoch 20, loss 2.1843020915985107, acc=0.28611111640930176, loss=2.1843020915985107
train: epoch 21, loss 0.7671989798545837, acc=0.7108888626098633, loss=0.7671989798545837
test: epoch 21, loss 2.1195285320281982, acc=0.2611111104488373, loss=2.1195285320281982
train: epoch 22, loss 0.7483732104301453, acc=0.7222222089767456, loss=0.7483732104301453
test: epoch 22, loss 2.187854290008545, acc=0.29722222685813904, loss=2.187854290008545
train: epoch 23, loss 0.7403632402420044, acc=0.7301111221313477, loss=0.7403632402420044
test: epoch 23, loss 1.967109203338623, acc=0.3222222328186035, loss=1.967109203338623
train: epoch 24, loss 0.7115832567214966, acc=0.7378888726234436, loss=0.7115832567214966
test: epoch 24, loss 1.971726417541504, acc=0.29722222685813904, loss=1.971726417541504
train: epoch 25, loss 0.6963369846343994, acc=0.7435555458068848, loss=0.6963369846343994
test: epoch 25, loss 1.9651448726654053, acc=0.3222222328186035, loss=1.9651448726654053
train: epoch 26, loss 0.6786646246910095, acc=0.7493888735771179, loss=0.6786646246910095
test: epoch 26, loss 2.0036823749542236, acc=0.3333333432674408, loss=2.0036823749542236
train: epoch 27, loss 0.664929211139679, acc=0.7589444518089294, loss=0.664929211139679
test: epoch 27, loss 1.886813759803772, acc=0.32499998807907104, loss=1.886813759803772
train: epoch 28, loss 0.6541566848754883, acc=0.7649999856948853, loss=0.6541566848754883
test: epoch 28, loss 1.93752121925354, acc=0.3333333432674408, loss=1.93752121925354
train: epoch 29, loss 0.6381896734237671, acc=0.7680555582046509, loss=0.6381896734237671
test: epoch 29, loss 1.9712406396865845, acc=0.30000001192092896, loss=1.9712406396865845
train: epoch 30, loss 0.6260246634483337, acc=0.772777795791626, loss=0.6260246634483337
test: epoch 30, loss 1.8671537637710571, acc=0.3194444477558136, loss=1.8671537637710571
train: epoch 31, loss 0.6076697111129761, acc=0.782444417476654, loss=0.6076697111129761
test: epoch 31, loss 1.8718199729919434, acc=0.3444444537162781, loss=1.8718199729919434
train: epoch 32, loss 0.587074875831604, acc=0.7879999876022339, loss=0.587074875831604
test: epoch 32, loss 2.015352487564087, acc=0.3083333373069763, loss=2.015352487564087
train: epoch 33, loss 0.5811281204223633, acc=0.7924444675445557, loss=0.5811281204223633
test: epoch 33, loss 1.9072462320327759, acc=0.31388887763023376, loss=1.9072462320327759
train: epoch 34, loss 0.5626658201217651, acc=0.7972777485847473, loss=0.5626658201217651
test: epoch 34, loss 1.8276256322860718, acc=0.3194444477558136, loss=1.8276256322860718
train: epoch 35, loss 0.549281656742096, acc=0.8038889169692993, loss=0.549281656742096
test: epoch 35, loss 1.817746877670288, acc=0.34166666865348816, loss=1.817746877670288
train: epoch 36, loss 0.5321730971336365, acc=0.8073333501815796, loss=0.5321730971336365
test: epoch 36, loss 1.723397135734558, acc=0.3055555522441864, loss=1.723397135734558
train: epoch 37, loss 0.5435838103294373, acc=0.8041666746139526, loss=0.5435838103294373
test: epoch 37, loss 1.7103620767593384, acc=0.35277777910232544, loss=1.7103620767593384
train: epoch 38, loss 0.5170981884002686, acc=0.8155555725097656, loss=0.5170981884002686
test: epoch 38, loss 1.7415215969085693, acc=0.32499998807907104, loss=1.7415215969085693
train: epoch 39, loss 0.5021902322769165, acc=0.8191111087799072, loss=0.5021902322769165
test: epoch 39, loss 1.7265355587005615, acc=0.33888888359069824, loss=1.7265355587005615
train: epoch 40, loss 0.49595510959625244, acc=0.8239444494247437, loss=0.49595510959625244
test: epoch 40, loss 1.8511161804199219, acc=0.3444444537162781, loss=1.8511161804199219
train: epoch 41, loss 0.5045181512832642, acc=0.8212777972221375, loss=0.5045181512832642
test: epoch 41, loss 1.726231575012207, acc=0.3305555582046509, loss=1.726231575012207
train: epoch 42, loss 0.4760403633117676, acc=0.8331111073493958, loss=0.4760403633117676
test: epoch 42, loss 1.819677472114563, acc=0.3333333432674408, loss=1.819677472114563
train: epoch 43, loss 0.4725397229194641, acc=0.82833331823349, loss=0.4725397229194641
test: epoch 43, loss 1.8277133703231812, acc=0.34166666865348816, loss=1.8277133703231812
train: epoch 44, loss 0.45456796884536743, acc=0.8383333086967468, loss=0.45456796884536743
test: epoch 44, loss 1.723755121231079, acc=0.36666667461395264, loss=1.723755121231079
train: epoch 45, loss 0.4577585756778717, acc=0.8378888964653015, loss=0.4577585756778717
test: epoch 45, loss 1.7838897705078125, acc=0.3472222089767456, loss=1.7838897705078125
train: epoch 46, loss 0.4379284977912903, acc=0.8463333249092102, loss=0.4379284977912903
test: epoch 46, loss 1.810776948928833, acc=0.3638888895511627, loss=1.810776948928833
train: epoch 47, loss 0.4199255108833313, acc=0.8532222509384155, loss=0.4199255108833313
test: epoch 47, loss 1.773639440536499, acc=0.3305555582046509, loss=1.773639440536499
train: epoch 48, loss 0.4190591275691986, acc=0.8492222428321838, loss=0.4190591275691986
test: epoch 48, loss 1.7523432970046997, acc=0.3638888895511627, loss=1.7523432970046997
train: epoch 49, loss 0.4173433482646942, acc=0.8533333539962769, loss=0.4173433482646942
test: epoch 49, loss 1.7264667749404907, acc=0.3472222089767456, loss=1.7264667749404907
train: epoch 50, loss 0.4103342592716217, acc=0.8574444651603699, loss=0.4103342592716217
test: epoch 50, loss 1.6608953475952148, acc=0.38333332538604736, loss=1.6608953475952148
train: epoch 51, loss 0.4029664695262909, acc=0.8601666688919067, loss=0.4029664695262909
test: epoch 51, loss 1.6185181140899658, acc=0.3861111104488373, loss=1.6185181140899658
train: epoch 52, loss 0.3940134048461914, acc=0.8663889169692993, loss=0.3940134048461914
test: epoch 52, loss 1.879921555519104, acc=0.35555556416511536, loss=1.879921555519104
train: epoch 53, loss 0.3868396580219269, acc=0.8684999942779541, loss=0.3868396580219269
test: epoch 53, loss 1.5449849367141724, acc=0.40833333134651184, loss=1.5449849367141724
train: epoch 54, loss 0.3780062198638916, acc=0.8677777647972107, loss=0.3780062198638916
test: epoch 54, loss 1.6167484521865845, acc=0.4138889014720917, loss=1.6167484521865845
train: epoch 55, loss 0.37440675497055054, acc=0.8684999942779541, loss=0.37440675497055054
test: epoch 55, loss 1.6956653594970703, acc=0.38333332538604736, loss=1.6956653594970703
train: epoch 56, loss 0.3622833788394928, acc=0.8725000023841858, loss=0.3622833788394928
test: epoch 56, loss 1.601323127746582, acc=0.4000000059604645, loss=1.601323127746582
train: epoch 57, loss 0.35228052735328674, acc=0.8777777552604675, loss=0.35228052735328674
test: epoch 57, loss 1.6526274681091309, acc=0.4027777910232544, loss=1.6526274681091309
train: epoch 58, loss 0.3487568497657776, acc=0.8773888945579529, loss=0.3487568497657776
test: epoch 58, loss 1.5221296548843384, acc=0.3888888955116272, loss=1.5221296548843384
train: epoch 59, loss 0.3490256071090698, acc=0.8819444179534912, loss=0.3490256071090698
test: epoch 59, loss 1.5003043413162231, acc=0.4000000059604645, loss=1.5003043413162231
train: epoch 60, loss 0.3318348526954651, acc=0.8853889107704163, loss=0.3318348526954651
test: epoch 60, loss 1.589788556098938, acc=0.4000000059604645, loss=1.589788556098938
train: epoch 61, loss 0.34569430351257324, acc=0.8786110877990723, loss=0.34569430351257324
test: epoch 61, loss 1.5971088409423828, acc=0.4305555522441864, loss=1.5971088409423828
train: epoch 62, loss 0.33062833547592163, acc=0.8833333253860474, loss=0.33062833547592163
test: epoch 62, loss 1.7273458242416382, acc=0.3777777850627899, loss=1.7273458242416382
train: epoch 63, loss 0.33340269327163696, acc=0.8838889002799988, loss=0.33340269327163696
test: epoch 63, loss 1.7869455814361572, acc=0.39444443583488464, loss=1.7869455814361572
train: epoch 64, loss 0.3140426576137543, acc=0.8913888931274414, loss=0.3140426576137543
test: epoch 64, loss 1.4963607788085938, acc=0.4416666626930237, loss=1.4963607788085938
train: epoch 65, loss 0.32563281059265137, acc=0.8878333568572998, loss=0.32563281059265137
test: epoch 65, loss 1.6748085021972656, acc=0.3777777850627899, loss=1.6748085021972656
train: epoch 66, loss 0.31447264552116394, acc=0.8924444317817688, loss=0.31447264552116394
test: epoch 66, loss 1.75252366065979, acc=0.3916666805744171, loss=1.75252366065979
train: epoch 67, loss 0.2987980842590332, acc=0.8961111307144165, loss=0.2987980842590332
test: epoch 67, loss 1.659168004989624, acc=0.4416666626930237, loss=1.659168004989624
train: epoch 68, loss 0.2972673773765564, acc=0.897944450378418, loss=0.2972673773765564
test: epoch 68, loss 1.7013882398605347, acc=0.4416666626930237, loss=1.7013882398605347
train: epoch 69, loss 0.2899169325828552, acc=0.8996111154556274, loss=0.2899169325828552
test: epoch 69, loss 1.6126354932785034, acc=0.4277777671813965, loss=1.6126354932785034
train: epoch 70, loss 0.29341810941696167, acc=0.9036666750907898, loss=0.29341810941696167
test: epoch 70, loss 1.6583645343780518, acc=0.4555555582046509, loss=1.6583645343780518
train: epoch 71, loss 0.2828724980354309, acc=0.9052777886390686, loss=0.2828724980354309
test: epoch 71, loss 1.6088200807571411, acc=0.42500001192092896, loss=1.6088200807571411
train: epoch 72, loss 0.27857425808906555, acc=0.9043889045715332, loss=0.27857425808906555
test: epoch 72, loss 1.6858495473861694, acc=0.4333333373069763, loss=1.6858495473861694
train: epoch 73, loss 0.2809212803840637, acc=0.9032222032546997, loss=0.2809212803840637
test: epoch 73, loss 1.6944024562835693, acc=0.4444444477558136, loss=1.6944024562835693
train: epoch 74, loss 0.261955201625824, acc=0.9113888740539551, loss=0.261955201625824
test: epoch 74, loss 1.6021150350570679, acc=0.46388888359069824, loss=1.6021150350570679
train: epoch 75, loss 0.2606293559074402, acc=0.910277783870697, loss=0.2606293559074402
test: epoch 75, loss 1.5831117630004883, acc=0.44999998807907104, loss=1.5831117630004883
train: epoch 76, loss 0.2566488981246948, acc=0.9117777943611145, loss=0.2566488981246948
test: epoch 76, loss 1.6734243631362915, acc=0.4583333432674408, loss=1.6734243631362915
train: epoch 77, loss 0.2541615962982178, acc=0.9121666550636292, loss=0.2541615962982178
test: epoch 77, loss 1.6686187982559204, acc=0.4749999940395355, loss=1.6686187982559204
train: epoch 78, loss 0.2511850893497467, acc=0.913611114025116, loss=0.2511850893497467
test: epoch 78, loss 1.5535807609558105, acc=0.45277777314186096, loss=1.5535807609558105
train: epoch 79, loss 0.2509482502937317, acc=0.9168333411216736, loss=0.2509482502937317
test: epoch 79, loss 1.6433864831924438, acc=0.4138889014720917, loss=1.6433864831924438
train: epoch 80, loss 0.24338337779045105, acc=0.9190555810928345, loss=0.24338337779045105
test: epoch 80, loss 1.6819196939468384, acc=0.4333333373069763, loss=1.6819196939468384
train: epoch 81, loss 0.2356911301612854, acc=0.9211666584014893, loss=0.2356911301612854
test: epoch 81, loss 1.443658709526062, acc=0.4749999940395355, loss=1.443658709526062
train: epoch 82, loss 0.2351764589548111, acc=0.9235000014305115, loss=0.2351764589548111
test: epoch 82, loss 1.8406633138656616, acc=0.4055555462837219, loss=1.8406633138656616
train: epoch 83, loss 0.23526175320148468, acc=0.9228333234786987, loss=0.23526175320148468
test: epoch 83, loss 1.6562467813491821, acc=0.4694444537162781, loss=1.6562467813491821
train: epoch 84, loss 0.22883820533752441, acc=0.9248889088630676, loss=0.22883820533752441
test: epoch 84, loss 1.6856756210327148, acc=0.4555555582046509, loss=1.6856756210327148
train: epoch 85, loss 0.22224865853786469, acc=0.9271666407585144, loss=0.22224865853786469
test: epoch 85, loss 1.5621333122253418, acc=0.4583333432674408, loss=1.5621333122253418
train: epoch 86, loss 0.2072281688451767, acc=0.9299444556236267, loss=0.2072281688451767
test: epoch 86, loss 1.7484301328659058, acc=0.46388888359069824, loss=1.7484301328659058
train: epoch 87, loss 0.22024783492088318, acc=0.9281666874885559, loss=0.22024783492088318
test: epoch 87, loss 1.681938886642456, acc=0.46388888359069824, loss=1.681938886642456
train: epoch 88, loss 0.21070903539657593, acc=0.9328888654708862, loss=0.21070903539657593
test: epoch 88, loss 1.8164253234863281, acc=0.4555555582046509, loss=1.8164253234863281
train: epoch 89, loss 0.20203152298927307, acc=0.934166669845581, loss=0.20203152298927307
test: epoch 89, loss 1.8853193521499634, acc=0.43611112236976624, loss=1.8853193521499634
train: epoch 90, loss 0.198795884847641, acc=0.9350000023841858, loss=0.198795884847641
test: epoch 90, loss 1.8041826486587524, acc=0.4472222328186035, loss=1.8041826486587524
train: epoch 91, loss 0.19906839728355408, acc=0.9355555772781372, loss=0.19906839728355408
test: epoch 91, loss 1.8678057193756104, acc=0.4694444537162781, loss=1.8678057193756104
train: epoch 92, loss 0.184884175658226, acc=0.9415555596351624, loss=0.184884175658226
test: epoch 92, loss 1.657466173171997, acc=0.47777777910232544, loss=1.657466173171997
train: epoch 93, loss 0.17929191887378693, acc=0.9393333196640015, loss=0.17929191887378693
test: epoch 93, loss 1.8524553775787354, acc=0.43888887763023376, loss=1.8524553775787354
train: epoch 94, loss 0.1789863556623459, acc=0.9420555830001831, loss=0.1789863556623459
test: epoch 94, loss 2.0983996391296387, acc=0.4583333432674408, loss=2.0983996391296387
train: epoch 95, loss 0.17799314856529236, acc=0.940666675567627, loss=0.17799314856529236
test: epoch 95, loss 1.7386839389801025, acc=0.4694444537162781, loss=1.7386839389801025
train: epoch 96, loss 0.1733109951019287, acc=0.9445555806159973, loss=0.1733109951019287
test: epoch 96, loss 1.9455010890960693, acc=0.46388888359069824, loss=1.9455010890960693
train: epoch 97, loss 0.16389481723308563, acc=0.9482222199440002, loss=0.16389481723308563
test: epoch 97, loss 1.8248237371444702, acc=0.4555555582046509, loss=1.8248237371444702
train: epoch 98, loss 0.1640186756849289, acc=0.9464444518089294, loss=0.1640186756849289
test: epoch 98, loss 1.9739259481430054, acc=0.43888887763023376, loss=1.9739259481430054
train: epoch 99, loss 0.1703558713197708, acc=0.9443333148956299, loss=0.1703558713197708
test: epoch 99, loss 1.8231028318405151, acc=0.4694444537162781, loss=1.8231028318405151
train: epoch 100, loss 0.16172170639038086, acc=0.9470000267028809, loss=0.16172170639038086
test: epoch 100, loss 1.9843785762786865, acc=0.4749999940395355, loss=1.9843785762786865
train: epoch 101, loss 0.16362638771533966, acc=0.9476666450500488, loss=0.16362638771533966
test: epoch 101, loss 1.9001400470733643, acc=0.4555555582046509, loss=1.9001400470733643
train: epoch 102, loss 0.15480303764343262, acc=0.9518333077430725, loss=0.15480303764343262
test: epoch 102, loss 1.88356614112854, acc=0.46388888359069824, loss=1.88356614112854
train: epoch 103, loss 0.15682773292064667, acc=0.9498888850212097, loss=0.15682773292064667
test: epoch 103, loss 1.9971246719360352, acc=0.4583333432674408, loss=1.9971246719360352
train: epoch 104, loss 0.15218982100486755, acc=0.9521666765213013, loss=0.15218982100486755
test: epoch 104, loss 1.9404902458190918, acc=0.519444465637207, loss=1.9404902458190918
train: epoch 105, loss 0.1452072411775589, acc=0.9541666507720947, loss=0.1452072411775589
test: epoch 105, loss 1.8058509826660156, acc=0.4833333194255829, loss=1.8058509826660156
train: epoch 106, loss 0.1382984220981598, acc=0.9548888802528381, loss=0.1382984220981598
test: epoch 106, loss 1.8174289464950562, acc=0.4861111044883728, loss=1.8174289464950562
train: epoch 107, loss 0.1568586528301239, acc=0.9531111121177673, loss=0.1568586528301239
test: epoch 107, loss 1.8248525857925415, acc=0.5249999761581421, loss=1.8248525857925415
train: epoch 108, loss 0.13472796976566315, acc=0.9577777981758118, loss=0.13472796976566315
test: epoch 108, loss 1.7204575538635254, acc=0.5277777910232544, loss=1.7204575538635254
train: epoch 109, loss 0.1480068564414978, acc=0.9558333158493042, loss=0.1480068564414978
test: epoch 109, loss 1.7344516515731812, acc=0.4694444537162781, loss=1.7344516515731812
train: epoch 110, loss 0.1372440904378891, acc=0.9581111073493958, loss=0.1372440904378891
test: epoch 110, loss 1.8430901765823364, acc=0.5416666865348816, loss=1.8430901765823364
train: epoch 111, loss 0.13847948610782623, acc=0.9557222127914429, loss=0.13847948610782623
test: epoch 111, loss 1.7389593124389648, acc=0.5, loss=1.7389593124389648
train: epoch 112, loss 0.13506852090358734, acc=0.9589444398880005, loss=0.13506852090358734
test: epoch 112, loss 2.0382518768310547, acc=0.5083333253860474, loss=2.0382518768310547
train: epoch 113, loss 0.130618616938591, acc=0.9584444165229797, loss=0.130618616938591
test: epoch 113, loss 1.8577333688735962, acc=0.5027777552604675, loss=1.8577333688735962
train: epoch 114, loss 0.12361811846494675, acc=0.9605000019073486, loss=0.12361811846494675
test: epoch 114, loss 2.157853364944458, acc=0.4861111044883728, loss=2.157853364944458
train: epoch 115, loss 0.12286166101694107, acc=0.9611666798591614, loss=0.12286166101694107
test: epoch 115, loss 2.2027487754821777, acc=0.4722222089767456, loss=2.2027487754821777
train: epoch 116, loss 0.12078863382339478, acc=0.9608888626098633, loss=0.12078863382339478
test: epoch 116, loss 2.0196890830993652, acc=0.4861111044883728, loss=2.0196890830993652
train: epoch 117, loss 0.1198132187128067, acc=0.9624444246292114, loss=0.1198132187128067
test: epoch 117, loss 1.9015048742294312, acc=0.49166667461395264, loss=1.9015048742294312
train: epoch 118, loss 0.11988295614719391, acc=0.9635000228881836, loss=0.11988295614719391
test: epoch 118, loss 2.1654727458953857, acc=0.4861111044883728, loss=2.1654727458953857
train: epoch 119, loss 0.1184639036655426, acc=0.9620555639266968, loss=0.1184639036655426
test: epoch 119, loss 1.9351577758789062, acc=0.49444442987442017, loss=1.9351577758789062
train: epoch 120, loss 0.12185391038656235, acc=0.9641666412353516, loss=0.12185391038656235
test: epoch 120, loss 1.9269611835479736, acc=0.4833333194255829, loss=1.9269611835479736
train: epoch 121, loss 0.11462268233299255, acc=0.9640555381774902, loss=0.11462268233299255
test: epoch 121, loss 1.9928321838378906, acc=0.47777777910232544, loss=1.9928321838378906
train: epoch 122, loss 0.1150006577372551, acc=0.9648333191871643, loss=0.1150006577372551
test: epoch 122, loss 1.7265830039978027, acc=0.519444465637207, loss=1.7265830039978027
train: epoch 123, loss 0.10713241249322891, acc=0.9633333086967468, loss=0.10713241249322891
test: epoch 123, loss 2.209383964538574, acc=0.5083333253860474, loss=2.209383964538574
train: epoch 124, loss 0.11185820400714874, acc=0.9655555486679077, loss=0.11185820400714874
test: epoch 124, loss 2.1465375423431396, acc=0.5055555701255798, loss=2.1465375423431396
train: epoch 125, loss 0.0995461642742157, acc=0.9695000052452087, loss=0.0995461642742157
test: epoch 125, loss 1.9858357906341553, acc=0.5249999761581421, loss=1.9858357906341553
train: epoch 126, loss 0.10767602920532227, acc=0.9665555357933044, loss=0.10767602920532227
test: epoch 126, loss 2.110140800476074, acc=0.5111111402511597, loss=2.110140800476074
train: epoch 127, loss 0.10761001706123352, acc=0.9663888812065125, loss=0.10761001706123352
test: epoch 127, loss 1.803221344947815, acc=0.5111111402511597, loss=1.803221344947815
train: epoch 128, loss 0.1021440178155899, acc=0.9676666855812073, loss=0.1021440178155899
test: epoch 128, loss 1.9366201162338257, acc=0.5222222208976746, loss=1.9366201162338257
train: epoch 129, loss 0.1091047152876854, acc=0.9680555462837219, loss=0.1091047152876854
test: epoch 129, loss 1.8821723461151123, acc=0.5222222208976746, loss=1.8821723461151123
train: epoch 130, loss 0.11115456372499466, acc=0.9652222394943237, loss=0.11115456372499466
test: epoch 130, loss 2.09591007232666, acc=0.5083333253860474, loss=2.09591007232666
train: epoch 131, loss 0.09346605092287064, acc=0.9710000157356262, loss=0.09346605092287064
test: epoch 131, loss 1.9837332963943481, acc=0.5249999761581421, loss=1.9837332963943481
train: epoch 132, loss 0.10172036290168762, acc=0.9680555462837219, loss=0.10172036290168762
test: epoch 132, loss 2.054934024810791, acc=0.4833333194255829, loss=2.054934024810791
train: epoch 133, loss 0.09111851453781128, acc=0.9714999794960022, loss=0.09111851453781128
test: epoch 133, loss 1.7915822267532349, acc=0.5277777910232544, loss=1.7915822267532349
train: epoch 134, loss 0.1017913743853569, acc=0.9686111211776733, loss=0.1017913743853569
test: epoch 134, loss 1.9495205879211426, acc=0.5388888716697693, loss=1.9495205879211426
train: epoch 135, loss 0.09848784655332565, acc=0.9696111083030701, loss=0.09848784655332565
test: epoch 135, loss 2.134063959121704, acc=0.5222222208976746, loss=2.134063959121704
train: epoch 136, loss 0.10330405831336975, acc=0.9701111316680908, loss=0.10330405831336975
test: epoch 136, loss 1.8779819011688232, acc=0.519444465637207, loss=1.8779819011688232
train: epoch 137, loss 0.08846533298492432, acc=0.9713333249092102, loss=0.08846533298492432
test: epoch 137, loss 2.297781467437744, acc=0.5111111402511597, loss=2.297781467437744
train: epoch 138, loss 0.09105981886386871, acc=0.9713888764381409, loss=0.09105981886386871
test: epoch 138, loss 1.9900764226913452, acc=0.5138888955116272, loss=1.9900764226913452
train: epoch 139, loss 0.09174162894487381, acc=0.9721111059188843, loss=0.09174162894487381
test: epoch 139, loss 1.9647881984710693, acc=0.5472221970558167, loss=1.9647881984710693
train: epoch 140, loss 0.08817467093467712, acc=0.9731666445732117, loss=0.08817467093467712
test: epoch 140, loss 2.2100276947021484, acc=0.519444465637207, loss=2.2100276947021484
train: epoch 141, loss 0.09495923668146133, acc=0.9711111187934875, loss=0.09495923668146133
test: epoch 141, loss 2.0473713874816895, acc=0.4972222149372101, loss=2.0473713874816895
train: epoch 142, loss 0.08597443252801895, acc=0.9722777605056763, loss=0.08597443252801895
test: epoch 142, loss 1.7971317768096924, acc=0.5527777671813965, loss=1.7971317768096924
train: epoch 143, loss 0.08393138647079468, acc=0.9748888611793518, loss=0.08393138647079468
test: epoch 143, loss 2.191673517227173, acc=0.5416666865348816, loss=2.191673517227173
train: epoch 144, loss 0.08317830413579941, acc=0.9739999771118164, loss=0.08317830413579941
test: epoch 144, loss 1.9984984397888184, acc=0.5305555462837219, loss=1.9984984397888184
train: epoch 145, loss 0.08492343872785568, acc=0.9729999899864197, loss=0.08492343872785568
test: epoch 145, loss 2.0294151306152344, acc=0.550000011920929, loss=2.0294151306152344
train: epoch 146, loss 0.08908456563949585, acc=0.9726666808128357, loss=0.08908456563949585
test: epoch 146, loss 1.9553378820419312, acc=0.5333333611488342, loss=1.9553378820419312
train: epoch 147, loss 0.0829550102353096, acc=0.9734444618225098, loss=0.0829550102353096
test: epoch 147, loss 2.068697929382324, acc=0.5249999761581421, loss=2.068697929382324
train: epoch 148, loss 0.08426827192306519, acc=0.9739999771118164, loss=0.08426827192306519
test: epoch 148, loss 2.0778799057006836, acc=0.5361111164093018, loss=2.0778799057006836
train: epoch 149, loss 0.0866965502500534, acc=0.9733333587646484, loss=0.0866965502500534
test: epoch 149, loss 2.1455323696136475, acc=0.5472221970558167, loss=2.1455323696136475
train: epoch 150, loss 0.08209086209535599, acc=0.9745000004768372, loss=0.08209086209535599
test: epoch 150, loss 2.0181102752685547, acc=0.5583333373069763, loss=2.0181102752685547
