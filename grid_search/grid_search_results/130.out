# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=1.5", "--temp_decay=1", "--one_hot=false", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=42448528, receiver_embed_dim=128, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.7639734745025635, acc=0.11388888955116272, loss=2.7639734745025635
test: epoch 1, loss 3.210029125213623, acc=0.1527777761220932, loss=3.210029125213623
train: epoch 2, loss 1.5125696659088135, acc=0.3884444534778595, loss=1.5125696659088135
test: epoch 2, loss 2.5795438289642334, acc=0.22499999403953552, loss=2.5795438289642334
train: epoch 3, loss 1.0791131258010864, acc=0.5494444370269775, loss=1.0791131258010864
test: epoch 3, loss 2.1191980838775635, acc=0.25833332538604736, loss=2.1191980838775635
train: epoch 4, loss 0.8611184358596802, acc=0.6440555453300476, loss=0.8611184358596802
test: epoch 4, loss 2.0072154998779297, acc=0.3444444537162781, loss=2.0072154998779297
train: epoch 5, loss 0.7136864066123962, acc=0.7020555734634399, loss=0.7136864066123962
test: epoch 5, loss 2.19950270652771, acc=0.28611111640930176, loss=2.19950270652771
train: epoch 6, loss 0.604680597782135, acc=0.7481111288070679, loss=0.604680597782135
test: epoch 6, loss 2.1007518768310547, acc=0.3888888955116272, loss=2.1007518768310547
train: epoch 7, loss 0.524806797504425, acc=0.7837777733802795, loss=0.524806797504425
test: epoch 7, loss 2.3480184078216553, acc=0.36944442987442017, loss=2.3480184078216553
train: epoch 8, loss 0.47492551803588867, acc=0.8080000281333923, loss=0.47492551803588867
test: epoch 8, loss 1.9121148586273193, acc=0.42222222685813904, loss=1.9121148586273193
train: epoch 9, loss 0.41855305433273315, acc=0.8292222023010254, loss=0.41855305433273315
test: epoch 9, loss 1.7317044734954834, acc=0.39444443583488464, loss=1.7317044734954834
train: epoch 10, loss 0.37868553400039673, acc=0.8450000286102295, loss=0.37868553400039673
test: epoch 10, loss 1.5446953773498535, acc=0.5277777910232544, loss=1.5446953773498535
train: epoch 11, loss 0.3351709842681885, acc=0.863277792930603, loss=0.3351709842681885
test: epoch 11, loss 2.0390448570251465, acc=0.4138889014720917, loss=2.0390448570251465
train: epoch 12, loss 0.32852447032928467, acc=0.863777756690979, loss=0.32852447032928467
test: epoch 12, loss 2.199180841445923, acc=0.43888887763023376, loss=2.199180841445923
train: epoch 13, loss 0.2963513731956482, acc=0.8841666579246521, loss=0.2963513731956482
test: epoch 13, loss 1.8441376686096191, acc=0.36944442987442017, loss=1.8441376686096191
train: epoch 14, loss 0.2868679463863373, acc=0.8926666378974915, loss=0.2868679463863373
test: epoch 14, loss 1.7853525876998901, acc=0.48055556416511536, loss=1.7853525876998901
train: epoch 15, loss 0.24867916107177734, acc=0.9094444513320923, loss=0.24867916107177734
test: epoch 15, loss 1.9510492086410522, acc=0.4749999940395355, loss=1.9510492086410522
train: epoch 16, loss 0.22332720458507538, acc=0.921500027179718, loss=0.22332720458507538
test: epoch 16, loss 1.554754376411438, acc=0.5666666626930237, loss=1.554754376411438
train: epoch 17, loss 0.21034705638885498, acc=0.9254444241523743, loss=0.21034705638885498
test: epoch 17, loss 1.523923397064209, acc=0.5249999761581421, loss=1.523923397064209
train: epoch 18, loss 0.19464153051376343, acc=0.9312777519226074, loss=0.19464153051376343
test: epoch 18, loss 1.6503925323486328, acc=0.550000011920929, loss=1.6503925323486328
train: epoch 19, loss 0.1815381944179535, acc=0.9366111159324646, loss=0.1815381944179535
test: epoch 19, loss 2.4001963138580322, acc=0.46666666865348816, loss=2.4001963138580322
train: epoch 20, loss 0.16405035555362701, acc=0.9413889050483704, loss=0.16405035555362701
test: epoch 20, loss 1.843453049659729, acc=0.5305555462837219, loss=1.843453049659729
train: epoch 21, loss 0.167581707239151, acc=0.9424999952316284, loss=0.167581707239151
test: epoch 21, loss 1.7441987991333008, acc=0.6027777791023254, loss=1.7441987991333008
train: epoch 22, loss 0.17178204655647278, acc=0.9382777810096741, loss=0.17178204655647278
test: epoch 22, loss 1.326563835144043, acc=0.605555534362793, loss=1.326563835144043
train: epoch 23, loss 0.1504223346710205, acc=0.9443888664245605, loss=0.1504223346710205
test: epoch 23, loss 1.5418195724487305, acc=0.574999988079071, loss=1.5418195724487305
train: epoch 24, loss 0.14865364134311676, acc=0.9468333125114441, loss=0.14865364134311676
test: epoch 24, loss 1.6629024744033813, acc=0.5722222328186035, loss=1.6629024744033813
train: epoch 25, loss 0.1387041211128235, acc=0.9495000243186951, loss=0.1387041211128235
test: epoch 25, loss 1.3774497509002686, acc=0.6472222208976746, loss=1.3774497509002686
train: epoch 26, loss 0.13604822754859924, acc=0.9512777924537659, loss=0.13604822754859924
test: epoch 26, loss 1.601828694343567, acc=0.5916666388511658, loss=1.601828694343567
train: epoch 27, loss 0.13055390119552612, acc=0.9514444470405579, loss=0.13055390119552612
test: epoch 27, loss 1.4634374380111694, acc=0.644444465637207, loss=1.4634374380111694
train: epoch 28, loss 0.12723630666732788, acc=0.9555555582046509, loss=0.12723630666732788
test: epoch 28, loss 1.3667197227478027, acc=0.6722221970558167, loss=1.3667197227478027
train: epoch 29, loss 0.12757690250873566, acc=0.9574999809265137, loss=0.12757690250873566
test: epoch 29, loss 1.374645471572876, acc=0.625, loss=1.374645471572876
train: epoch 30, loss 0.11762869358062744, acc=0.9605000019073486, loss=0.11762869358062744
test: epoch 30, loss 1.1129114627838135, acc=0.7027778029441833, loss=1.1129114627838135
train: epoch 31, loss 0.09943106025457382, acc=0.9662777781486511, loss=0.09943106025457382
test: epoch 31, loss 1.2147762775421143, acc=0.6694444417953491, loss=1.2147762775421143
train: epoch 32, loss 0.10294026881456375, acc=0.9653888940811157, loss=0.10294026881456375
test: epoch 32, loss 1.262231469154358, acc=0.6666666865348816, loss=1.262231469154358
train: epoch 33, loss 0.11012108623981476, acc=0.9638333320617676, loss=0.11012108623981476
test: epoch 33, loss 1.078608751296997, acc=0.7472222447395325, loss=1.078608751296997
train: epoch 34, loss 0.09940473735332489, acc=0.9671666622161865, loss=0.09940473735332489
test: epoch 34, loss 0.8669647574424744, acc=0.769444465637207, loss=0.8669647574424744
train: epoch 35, loss 0.088337741792202, acc=0.9702222347259521, loss=0.088337741792202
test: epoch 35, loss 1.0613261461257935, acc=0.6694444417953491, loss=1.0613261461257935
train: epoch 36, loss 0.09019305557012558, acc=0.9685555696487427, loss=0.09019305557012558
test: epoch 36, loss 0.9601136445999146, acc=0.7583333253860474, loss=0.9601136445999146
train: epoch 37, loss 0.07914257049560547, acc=0.9733889102935791, loss=0.07914257049560547
test: epoch 37, loss 1.1333717107772827, acc=0.7611111402511597, loss=1.1333717107772827
train: epoch 38, loss 0.10404545813798904, acc=0.9650555849075317, loss=0.10404545813798904
test: epoch 38, loss 1.2636501789093018, acc=0.6944444179534912, loss=1.2636501789093018
train: epoch 39, loss 0.08483985811471939, acc=0.9714999794960022, loss=0.08483985811471939
test: epoch 39, loss 0.8239836096763611, acc=0.7888888716697693, loss=0.8239836096763611
train: epoch 40, loss 0.0792158991098404, acc=0.9721111059188843, loss=0.0792158991098404
test: epoch 40, loss 0.8465040326118469, acc=0.8111110925674438, loss=0.8465040326118469
train: epoch 41, loss 0.06963641941547394, acc=0.9763333201408386, loss=0.06963641941547394
test: epoch 41, loss 0.9568033814430237, acc=0.8194444179534912, loss=0.9568033814430237
train: epoch 42, loss 0.0811278223991394, acc=0.9739999771118164, loss=0.0811278223991394
test: epoch 42, loss 0.9725515842437744, acc=0.8138889074325562, loss=0.9725515842437744
train: epoch 43, loss 0.0736832320690155, acc=0.9748888611793518, loss=0.0736832320690155
test: epoch 43, loss 0.6322216987609863, acc=0.8194444179534912, loss=0.6322216987609863
train: epoch 44, loss 0.07333093881607056, acc=0.9753888845443726, loss=0.07333093881607056
test: epoch 44, loss 0.6534265279769897, acc=0.8166666626930237, loss=0.6534265279769897
train: epoch 45, loss 0.06702646613121033, acc=0.9769999980926514, loss=0.06702646613121033
test: epoch 45, loss 1.0007649660110474, acc=0.8194444179534912, loss=1.0007649660110474
train: epoch 46, loss 0.0721183568239212, acc=0.9755555391311646, loss=0.0721183568239212
test: epoch 46, loss 0.7265158891677856, acc=0.8583333492279053, loss=0.7265158891677856
train: epoch 47, loss 0.06825203448534012, acc=0.976277768611908, loss=0.06825203448534012
test: epoch 47, loss 0.7378422617912292, acc=0.8472222089767456, loss=0.7378422617912292
train: epoch 48, loss 0.05987374857068062, acc=0.9778888821601868, loss=0.05987374857068062
test: epoch 48, loss 0.6678587794303894, acc=0.8527777791023254, loss=0.6678587794303894
train: epoch 49, loss 0.06482194364070892, acc=0.9774444699287415, loss=0.06482194364070892
test: epoch 49, loss 0.750050961971283, acc=0.8305555582046509, loss=0.750050961971283
train: epoch 50, loss 0.06927772611379623, acc=0.9771666526794434, loss=0.06927772611379623
test: epoch 50, loss 0.5000418424606323, acc=0.8388888835906982, loss=0.5000418424606323
train: epoch 51, loss 0.045721832662820816, acc=0.9835555553436279, loss=0.045721832662820816
test: epoch 51, loss 0.7005301117897034, acc=0.8805555701255798, loss=0.7005301117897034
train: epoch 52, loss 0.059409912675619125, acc=0.9801111221313477, loss=0.059409912675619125
test: epoch 52, loss 0.45917558670043945, acc=0.8805555701255798, loss=0.45917558670043945
train: epoch 53, loss 0.059177372604608536, acc=0.9803333282470703, loss=0.059177372604608536
test: epoch 53, loss 0.5092806816101074, acc=0.9111111164093018, loss=0.5092806816101074
train: epoch 54, loss 0.04827144369482994, acc=0.9827222228050232, loss=0.04827144369482994
test: epoch 54, loss 0.4663846492767334, acc=0.8999999761581421, loss=0.4663846492767334
train: epoch 55, loss 0.060089077800512314, acc=0.9802777767181396, loss=0.060089077800512314
test: epoch 55, loss 0.30328598618507385, acc=0.9166666865348816, loss=0.30328598618507385
train: epoch 56, loss 0.04554130509495735, acc=0.9831110835075378, loss=0.04554130509495735
test: epoch 56, loss 0.4412427842617035, acc=0.9083333611488342, loss=0.4412427842617035
train: epoch 57, loss 0.0446065254509449, acc=0.9836111068725586, loss=0.0446065254509449
test: epoch 57, loss 0.37758079171180725, acc=0.925000011920929, loss=0.37758079171180725
train: epoch 58, loss 0.04624171927571297, acc=0.9826111197471619, loss=0.04624171927571297
test: epoch 58, loss 0.2630152106285095, acc=0.9277777671813965, loss=0.2630152106285095
train: epoch 59, loss 0.0526701919734478, acc=0.9804999828338623, loss=0.0526701919734478
test: epoch 59, loss 0.2634289264678955, acc=0.9194444417953491, loss=0.2634289264678955
train: epoch 60, loss 0.050137702375650406, acc=0.9823889136314392, loss=0.050137702375650406
test: epoch 60, loss 0.23929007351398468, acc=0.9222221970558167, loss=0.23929007351398468
train: epoch 61, loss 0.050163209438323975, acc=0.9829444289207458, loss=0.050163209438323975
test: epoch 61, loss 0.44186994433403015, acc=0.9138888716697693, loss=0.44186994433403015
train: epoch 62, loss 0.05156436562538147, acc=0.9821666479110718, loss=0.05156436562538147
test: epoch 62, loss 0.3300648629665375, acc=0.925000011920929, loss=0.3300648629665375
train: epoch 63, loss 0.04844481498003006, acc=0.9819444417953491, loss=0.04844481498003006
test: epoch 63, loss 0.2085566222667694, acc=0.925000011920929, loss=0.2085566222667694
train: epoch 64, loss 0.03850995749235153, acc=0.9838333129882812, loss=0.03850995749235153
test: epoch 64, loss 0.32025086879730225, acc=0.9277777671813965, loss=0.32025086879730225
train: epoch 65, loss 0.04358860105276108, acc=0.9848333597183228, loss=0.04358860105276108
test: epoch 65, loss 0.37619832158088684, acc=0.9166666865348816, loss=0.37619832158088684
train: epoch 66, loss 0.04760696738958359, acc=0.9829444289207458, loss=0.04760696738958359
test: epoch 66, loss 0.35388484597206116, acc=0.9277777671813965, loss=0.35388484597206116
train: epoch 67, loss 0.050046153366565704, acc=0.9826666712760925, loss=0.050046153366565704
test: epoch 67, loss 0.4973304569721222, acc=0.9027777910232544, loss=0.4973304569721222
train: epoch 68, loss 0.0506216362118721, acc=0.9823333621025085, loss=0.0506216362118721
test: epoch 68, loss 0.29285380244255066, acc=0.9277777671813965, loss=0.29285380244255066
train: epoch 69, loss 0.04403263330459595, acc=0.9845555424690247, loss=0.04403263330459595
test: epoch 69, loss 0.3708515763282776, acc=0.9277777671813965, loss=0.3708515763282776
train: epoch 70, loss 0.04454667866230011, acc=0.9840555787086487, loss=0.04454667866230011
test: epoch 70, loss 0.3275947570800781, acc=0.9277777671813965, loss=0.3275947570800781
train: epoch 71, loss 0.04218757525086403, acc=0.9842777848243713, loss=0.04218757525086403
test: epoch 71, loss 0.22217856347560883, acc=0.9277777671813965, loss=0.22217856347560883
train: epoch 72, loss 0.04039774835109711, acc=0.984000027179718, loss=0.04039774835109711
test: epoch 72, loss 0.3063967525959015, acc=0.9277777671813965, loss=0.3063967525959015
train: epoch 73, loss 0.0550885871052742, acc=0.9822221994400024, loss=0.0550885871052742
test: epoch 73, loss 0.3288578689098358, acc=0.9222221970558167, loss=0.3288578689098358
train: epoch 74, loss 0.039183761924505234, acc=0.9852777719497681, loss=0.039183761924505234
test: epoch 74, loss 0.42940962314605713, acc=0.9222221970558167, loss=0.42940962314605713
train: epoch 75, loss 0.03800596296787262, acc=0.9850000143051147, loss=0.03800596296787262
test: epoch 75, loss 0.3502510190010071, acc=0.925000011920929, loss=0.3502510190010071
train: epoch 76, loss 0.044585902243852615, acc=0.9846110939979553, loss=0.044585902243852615
test: epoch 76, loss 0.2798022925853729, acc=0.9194444417953491, loss=0.2798022925853729
train: epoch 77, loss 0.03982625529170036, acc=0.9838333129882812, loss=0.03982625529170036
test: epoch 77, loss 0.3311854600906372, acc=0.9194444417953491, loss=0.3311854600906372
train: epoch 78, loss 0.03963813558220863, acc=0.984666645526886, loss=0.03963813558220863
test: epoch 78, loss 0.28951817750930786, acc=0.9222221970558167, loss=0.28951817750930786
train: epoch 79, loss 0.03720877319574356, acc=0.9852222204208374, loss=0.03720877319574356
test: epoch 79, loss 0.32408905029296875, acc=0.925000011920929, loss=0.32408905029296875
train: epoch 80, loss 0.043118733912706375, acc=0.984333336353302, loss=0.043118733912706375
test: epoch 80, loss 0.4364263713359833, acc=0.9138888716697693, loss=0.4364263713359833
train: epoch 81, loss 0.03774868696928024, acc=0.9854444265365601, loss=0.03774868696928024
test: epoch 81, loss 0.31822943687438965, acc=0.925000011920929, loss=0.31822943687438965
train: epoch 82, loss 0.03820447996258736, acc=0.9853888750076294, loss=0.03820447996258736
test: epoch 82, loss 0.41376686096191406, acc=0.9277777671813965, loss=0.41376686096191406
train: epoch 83, loss 0.041639555245637894, acc=0.9847777485847473, loss=0.041639555245637894
test: epoch 83, loss 0.2857683598995209, acc=0.9305555820465088, loss=0.2857683598995209
train: epoch 84, loss 0.054849449545145035, acc=0.9807778000831604, loss=0.054849449545145035
test: epoch 84, loss 0.21257084608078003, acc=0.9305555820465088, loss=0.21257084608078003
train: epoch 85, loss 0.0357416570186615, acc=0.9857222437858582, loss=0.0357416570186615
test: epoch 85, loss 0.23709064722061157, acc=0.9472222328186035, loss=0.23709064722061157
train: epoch 86, loss 0.04943699389696121, acc=0.9843888878822327, loss=0.04943699389696121
test: epoch 86, loss 0.2359810769557953, acc=0.9472222328186035, loss=0.2359810769557953
train: epoch 87, loss 0.03764590993523598, acc=0.9859444499015808, loss=0.03764590993523598
test: epoch 87, loss 0.1984032839536667, acc=0.9472222328186035, loss=0.1984032839536667
train: epoch 88, loss 0.031201496720314026, acc=0.9867222309112549, loss=0.031201496720314026
test: epoch 88, loss 0.2410537302494049, acc=0.9472222328186035, loss=0.2410537302494049
train: epoch 89, loss 0.040363676846027374, acc=0.9861111044883728, loss=0.040363676846027374
test: epoch 89, loss 0.2608841359615326, acc=0.9472222328186035, loss=0.2608841359615326
train: epoch 90, loss 0.030110768973827362, acc=0.9877777695655823, loss=0.030110768973827362
test: epoch 90, loss 0.24725215137004852, acc=0.9472222328186035, loss=0.24725215137004852
train: epoch 91, loss 0.039837323129177094, acc=0.9840555787086487, loss=0.039837323129177094
test: epoch 91, loss 0.36995062232017517, acc=0.949999988079071, loss=0.36995062232017517
train: epoch 92, loss 0.030629266053438187, acc=0.9869999885559082, loss=0.030629266053438187
test: epoch 92, loss 0.2091272622346878, acc=0.949999988079071, loss=0.2091272622346878
train: epoch 93, loss 0.030136756598949432, acc=0.9871110916137695, loss=0.030136756598949432
test: epoch 93, loss 0.31802764534950256, acc=0.9527778029441833, loss=0.31802764534950256
train: epoch 94, loss 0.028741104528307915, acc=0.9873889088630676, loss=0.028741104528307915
test: epoch 94, loss 0.2673121988773346, acc=0.9527778029441833, loss=0.2673121988773346
train: epoch 95, loss 0.03427838534116745, acc=0.9863888621330261, loss=0.03427838534116745
test: epoch 95, loss 0.19796541333198547, acc=0.9527778029441833, loss=0.19796541333198547
train: epoch 96, loss 0.034194763749837875, acc=0.9870555400848389, loss=0.034194763749837875
test: epoch 96, loss 0.21553760766983032, acc=0.949999988079071, loss=0.21553760766983032
train: epoch 97, loss 0.053527940064668655, acc=0.9835555553436279, loss=0.053527940064668655
test: epoch 97, loss 0.23855379223823547, acc=0.949999988079071, loss=0.23855379223823547
train: epoch 98, loss 0.029018642380833626, acc=0.987333357334137, loss=0.029018642380833626
test: epoch 98, loss 0.1865355670452118, acc=0.9527778029441833, loss=0.1865355670452118
train: epoch 99, loss 0.0312938317656517, acc=0.9871110916137695, loss=0.0312938317656517
test: epoch 99, loss 0.18507513403892517, acc=0.9527778029441833, loss=0.18507513403892517
train: epoch 100, loss 0.030257081612944603, acc=0.9874444603919983, loss=0.030257081612944603
test: epoch 100, loss 0.24882063269615173, acc=0.9527778029441833, loss=0.24882063269615173
train: epoch 101, loss 0.03483729064464569, acc=0.9862777590751648, loss=0.03483729064464569
test: epoch 101, loss 0.16623806953430176, acc=0.9527778029441833, loss=0.16623806953430176
train: epoch 102, loss 0.02949504740536213, acc=0.9877222180366516, loss=0.02949504740536213
test: epoch 102, loss 0.25805121660232544, acc=0.9527778029441833, loss=0.25805121660232544
train: epoch 103, loss 0.024874484166502953, acc=0.9884999990463257, loss=0.024874484166502953
test: epoch 103, loss 0.22791554033756256, acc=0.9527778029441833, loss=0.22791554033756256
train: epoch 104, loss 0.03172558173537254, acc=0.9866111278533936, loss=0.03172558173537254
test: epoch 104, loss 0.24441327154636383, acc=0.9527778029441833, loss=0.24441327154636383
train: epoch 105, loss 0.0301410760730505, acc=0.9878333210945129, loss=0.0301410760730505
test: epoch 105, loss 0.2161991447210312, acc=0.9527778029441833, loss=0.2161991447210312
train: epoch 106, loss 0.026727784425020218, acc=0.9877777695655823, loss=0.026727784425020218
test: epoch 106, loss 0.25284355878829956, acc=0.9527778029441833, loss=0.25284355878829956
train: epoch 107, loss 0.03825868293642998, acc=0.9868333339691162, loss=0.03825868293642998
test: epoch 107, loss 0.14349645376205444, acc=0.9527778029441833, loss=0.14349645376205444
train: epoch 108, loss 0.031147189438343048, acc=0.9872778058052063, loss=0.031147189438343048
test: epoch 108, loss 0.2489442229270935, acc=0.9527778029441833, loss=0.2489442229270935
train: epoch 109, loss 0.02474895492196083, acc=0.988444447517395, loss=0.02474895492196083
test: epoch 109, loss 0.22623075544834137, acc=0.9527778029441833, loss=0.22623075544834137
train: epoch 110, loss 0.03475268557667732, acc=0.9863888621330261, loss=0.03475268557667732
test: epoch 110, loss 0.2693297863006592, acc=0.9527778029441833, loss=0.2693297863006592
train: epoch 111, loss 0.03254171460866928, acc=0.9869999885559082, loss=0.03254171460866928
test: epoch 111, loss 0.24790005385875702, acc=0.9527778029441833, loss=0.24790005385875702
train: epoch 112, loss 0.046676136553287506, acc=0.9846110939979553, loss=0.046676136553287506
test: epoch 112, loss 0.1647980511188507, acc=0.9527778029441833, loss=0.1647980511188507
train: epoch 113, loss 0.037949204444885254, acc=0.9868888854980469, loss=0.037949204444885254
test: epoch 113, loss 0.2069770246744156, acc=0.9527778029441833, loss=0.2069770246744156
train: epoch 114, loss 0.028793010860681534, acc=0.987666666507721, loss=0.028793010860681534
test: epoch 114, loss 0.24002063274383545, acc=0.9527778029441833, loss=0.24002063274383545
train: epoch 115, loss 0.029160959646105766, acc=0.987500011920929, loss=0.029160959646105766
test: epoch 115, loss 0.23058487474918365, acc=0.9527778029441833, loss=0.23058487474918365
train: epoch 116, loss 0.027393877506256104, acc=0.9878333210945129, loss=0.027393877506256104
test: epoch 116, loss 0.19704832136631012, acc=0.9527778029441833, loss=0.19704832136631012
train: epoch 117, loss 0.031017398461699486, acc=0.9868333339691162, loss=0.031017398461699486
test: epoch 117, loss 0.2242778241634369, acc=0.9527778029441833, loss=0.2242778241634369
train: epoch 118, loss 0.025592252612113953, acc=0.988111138343811, loss=0.025592252612113953
test: epoch 118, loss 0.3593808710575104, acc=0.9527778029441833, loss=0.3593808710575104
train: epoch 119, loss 0.04180561751127243, acc=0.9861666560173035, loss=0.04180561751127243
test: epoch 119, loss 0.2752854824066162, acc=0.9527778029441833, loss=0.2752854824066162
train: epoch 120, loss 0.028670944273471832, acc=0.9879444241523743, loss=0.028670944273471832
test: epoch 120, loss 0.200836181640625, acc=0.9527778029441833, loss=0.200836181640625
train: epoch 121, loss 0.03570494055747986, acc=0.9861111044883728, loss=0.03570494055747986
test: epoch 121, loss 0.22748778760433197, acc=0.949999988079071, loss=0.22748778760433197
train: epoch 122, loss 0.03651699423789978, acc=0.9852777719497681, loss=0.03651699423789978
test: epoch 122, loss 0.18035613000392914, acc=0.949999988079071, loss=0.18035613000392914
train: epoch 123, loss 0.035167865455150604, acc=0.9868888854980469, loss=0.035167865455150604
test: epoch 123, loss 0.1081039234995842, acc=0.949999988079071, loss=0.1081039234995842
train: epoch 124, loss 0.04155281186103821, acc=0.9851111173629761, loss=0.04155281186103821
test: epoch 124, loss 0.17372794449329376, acc=0.949999988079071, loss=0.17372794449329376
train: epoch 125, loss 0.02981877699494362, acc=0.9870555400848389, loss=0.02981877699494362
test: epoch 125, loss 0.1614074558019638, acc=0.9527778029441833, loss=0.1614074558019638
train: epoch 126, loss 0.04319401830434799, acc=0.9862222075462341, loss=0.04319401830434799
test: epoch 126, loss 0.1875828504562378, acc=0.9527778029441833, loss=0.1875828504562378
train: epoch 127, loss 0.02679969184100628, acc=0.9883888959884644, loss=0.02679969184100628
test: epoch 127, loss 0.2078363299369812, acc=0.9527778029441833, loss=0.2078363299369812
train: epoch 128, loss 0.030043577775359154, acc=0.9879999756813049, loss=0.030043577775359154
test: epoch 128, loss 0.14140337705612183, acc=0.9527778029441833, loss=0.14140337705612183
train: epoch 129, loss 0.03054591454565525, acc=0.9871110916137695, loss=0.03054591454565525
test: epoch 129, loss 0.03417990729212761, acc=0.9861111044883728, loss=0.03417990729212761
train: epoch 130, loss 0.022893639281392097, acc=0.988777756690979, loss=0.022893639281392097
test: epoch 130, loss 0.02223997935652733, acc=0.9888888597488403, loss=0.02223997935652733
train: epoch 131, loss 0.02513945661485195, acc=0.9883888959884644, loss=0.02513945661485195
test: epoch 131, loss 0.21068623661994934, acc=0.9750000238418579, loss=0.21068623661994934
train: epoch 132, loss 0.028024962171912193, acc=0.988277792930603, loss=0.028024962171912193
test: epoch 132, loss 0.02221381664276123, acc=0.9888888597488403, loss=0.02221381664276123
train: epoch 133, loss 0.025704268366098404, acc=0.988444447517395, loss=0.025704268366098404
test: epoch 133, loss 0.022309552878141403, acc=0.9888888597488403, loss=0.022309552878141403
train: epoch 134, loss 0.02394126169383526, acc=0.9886666536331177, loss=0.02394126169383526
test: epoch 134, loss 0.022169923409819603, acc=0.9888888597488403, loss=0.022169923409819603
train: epoch 135, loss 0.024077340960502625, acc=0.988611102104187, loss=0.024077340960502625
test: epoch 135, loss 0.022166619077324867, acc=0.9888888597488403, loss=0.022166619077324867
train: epoch 136, loss 0.03531309589743614, acc=0.9877222180366516, loss=0.03531309589743614
test: epoch 136, loss 0.022185714915394783, acc=0.9888888597488403, loss=0.022185714915394783
train: epoch 137, loss 0.02891729027032852, acc=0.9879999756813049, loss=0.02891729027032852
test: epoch 137, loss 0.022171558812260628, acc=0.9888888597488403, loss=0.022171558812260628
train: epoch 138, loss 0.02259916067123413, acc=0.9888333082199097, loss=0.02259916067123413
test: epoch 138, loss 0.02216746099293232, acc=0.9888888597488403, loss=0.02216746099293232
train: epoch 139, loss 0.03194444254040718, acc=0.9877777695655823, loss=0.03194444254040718
test: epoch 139, loss 0.022168807685375214, acc=0.9888888597488403, loss=0.022168807685375214
train: epoch 140, loss 0.022309260442852974, acc=0.9888333082199097, loss=0.022309260442852974
test: epoch 140, loss 0.02216435968875885, acc=0.9888888597488403, loss=0.02216435968875885
train: epoch 141, loss 0.02223622240126133, acc=0.9888888597488403, loss=0.02223622240126133
test: epoch 141, loss 0.02216348610818386, acc=0.9888888597488403, loss=0.02216348610818386
train: epoch 142, loss 0.028451401740312576, acc=0.9886666536331177, loss=0.028451401740312576
test: epoch 142, loss 0.02216324396431446, acc=0.9888888597488403, loss=0.02216324396431446
train: epoch 143, loss 0.024768393486738205, acc=0.988611102104187, loss=0.024768393486738205
test: epoch 143, loss 0.022164031863212585, acc=0.9888888597488403, loss=0.022164031863212585
train: epoch 144, loss 0.024853603914380074, acc=0.9887222051620483, loss=0.024853603914380074
test: epoch 144, loss 0.02216307818889618, acc=0.9888888597488403, loss=0.02216307818889618
train: epoch 145, loss 0.022731643170118332, acc=0.988777756690979, loss=0.022731643170118332
test: epoch 145, loss 0.02216314524412155, acc=0.9888888597488403, loss=0.02216314524412155
train: epoch 146, loss 0.030537933111190796, acc=0.988444447517395, loss=0.030537933111190796
test: epoch 146, loss 0.022163087502121925, acc=0.9888888597488403, loss=0.022163087502121925
train: epoch 147, loss 0.023218754678964615, acc=0.9887222051620483, loss=0.023218754678964615
test: epoch 147, loss 0.022163134068250656, acc=0.9888888597488403, loss=0.022163134068250656
train: epoch 148, loss 0.03511517122387886, acc=0.9875555634498596, loss=0.03511517122387886
test: epoch 148, loss 0.02217053435742855, acc=0.9888888597488403, loss=0.02217053435742855
train: epoch 149, loss 0.023653196170926094, acc=0.988777756690979, loss=0.023653196170926094
test: epoch 149, loss 0.02216843143105507, acc=0.9888888597488403, loss=0.02216843143105507
train: epoch 150, loss 0.023821307346224785, acc=0.988611102104187, loss=0.023821307346224785
test: epoch 150, loss 0.022166581824421883, acc=0.9888888597488403, loss=0.022166581824421883
