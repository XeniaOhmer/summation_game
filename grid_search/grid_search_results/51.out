# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=0.99", "--one_hot=false", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1097162521, receiver_embed_dim=32, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.380035638809204, acc=0.04938888922333717, loss=3.380035638809204
test: epoch 1, loss 4.240089416503906, acc=0.04444444552063942, loss=4.240089416503906
train: epoch 2, loss 2.607720375061035, acc=0.17972221970558167, loss=2.607720375061035
test: epoch 2, loss 4.6055755615234375, acc=0.07500000298023224, loss=4.6055755615234375
train: epoch 3, loss 1.7612900733947754, acc=0.355222225189209, loss=1.7612900733947754
test: epoch 3, loss 3.9034221172332764, acc=0.1388888955116272, loss=3.9034221172332764
train: epoch 4, loss 1.4390668869018555, acc=0.4456111192703247, loss=1.4390668869018555
test: epoch 4, loss 3.6876256465911865, acc=0.12777778506278992, loss=3.6876256465911865
train: epoch 5, loss 1.2795145511627197, acc=0.4965555667877197, loss=1.2795145511627197
test: epoch 5, loss 3.629843235015869, acc=0.15000000596046448, loss=3.629843235015869
train: epoch 6, loss 1.1685523986816406, acc=0.545722246170044, loss=1.1685523986816406
test: epoch 6, loss 3.5992813110351562, acc=0.15555556118488312, loss=3.5992813110351562
train: epoch 7, loss 1.0800811052322388, acc=0.5804444551467896, loss=1.0800811052322388
test: epoch 7, loss 3.5916988849639893, acc=0.1527777761220932, loss=3.5916988849639893
train: epoch 8, loss 1.0113905668258667, acc=0.6124444603919983, loss=1.0113905668258667
test: epoch 8, loss 3.3689067363739014, acc=0.19166666269302368, loss=3.3689067363739014
train: epoch 9, loss 0.9627849459648132, acc=0.628944456577301, loss=0.9627849459648132
test: epoch 9, loss 3.3488528728485107, acc=0.17222222685813904, loss=3.3488528728485107
train: epoch 10, loss 0.9066190719604492, acc=0.6542778015136719, loss=0.9066190719604492
test: epoch 10, loss 3.1983087062835693, acc=0.19722221791744232, loss=3.1983087062835693
train: epoch 11, loss 0.8640265464782715, acc=0.6750555634498596, loss=0.8640265464782715
test: epoch 11, loss 3.2421977519989014, acc=0.21111111342906952, loss=3.2421977519989014
train: epoch 12, loss 0.841694712638855, acc=0.6834999918937683, loss=0.841694712638855
test: epoch 12, loss 3.4776651859283447, acc=0.18888889253139496, loss=3.4776651859283447
train: epoch 13, loss 0.8007940649986267, acc=0.7041110992431641, loss=0.8007940649986267
test: epoch 13, loss 3.209326982498169, acc=0.22499999403953552, loss=3.209326982498169
train: epoch 14, loss 0.779628574848175, acc=0.7039999961853027, loss=0.779628574848175
test: epoch 14, loss 3.184605598449707, acc=0.24722221493721008, loss=3.184605598449707
train: epoch 15, loss 0.7413713335990906, acc=0.7315555810928345, loss=0.7413713335990906
test: epoch 15, loss 3.139411449432373, acc=0.23055554926395416, loss=3.139411449432373
train: epoch 16, loss 0.7359308004379272, acc=0.7316666841506958, loss=0.7359308004379272
test: epoch 16, loss 2.9655206203460693, acc=0.2361111044883728, loss=2.9655206203460693
train: epoch 17, loss 0.7126162052154541, acc=0.7402777671813965, loss=0.7126162052154541
test: epoch 17, loss 2.921231508255005, acc=0.26944443583488464, loss=2.921231508255005
train: epoch 18, loss 0.6847177743911743, acc=0.754277765750885, loss=0.6847177743911743
test: epoch 18, loss 2.6694984436035156, acc=0.26944443583488464, loss=2.6694984436035156
train: epoch 19, loss 0.6716528534889221, acc=0.7581111192703247, loss=0.6716528534889221
test: epoch 19, loss 2.7577085494995117, acc=0.2750000059604645, loss=2.7577085494995117
train: epoch 20, loss 0.6600714921951294, acc=0.7604444622993469, loss=0.6600714921951294
test: epoch 20, loss 2.5070488452911377, acc=0.2888889014720917, loss=2.5070488452911377
train: epoch 21, loss 0.6373921036720276, acc=0.7710000276565552, loss=0.6373921036720276
test: epoch 21, loss 2.6174111366271973, acc=0.2638888955116272, loss=2.6174111366271973
train: epoch 22, loss 0.6326226592063904, acc=0.7745555639266968, loss=0.6326226592063904
test: epoch 22, loss 2.632582902908325, acc=0.2611111104488373, loss=2.632582902908325
train: epoch 23, loss 0.6129866242408752, acc=0.7829444408416748, loss=0.6129866242408752
test: epoch 23, loss 2.4132206439971924, acc=0.24166665971279144, loss=2.4132206439971924
train: epoch 24, loss 0.6097323298454285, acc=0.7788888812065125, loss=0.6097323298454285
test: epoch 24, loss 2.654181718826294, acc=0.2916666567325592, loss=2.654181718826294
train: epoch 25, loss 0.6047266125679016, acc=0.7882221937179565, loss=0.6047266125679016
test: epoch 25, loss 2.4974708557128906, acc=0.28611111640930176, loss=2.4974708557128906
train: epoch 26, loss 0.5947185754776001, acc=0.7915555834770203, loss=0.5947185754776001
test: epoch 26, loss 2.3115363121032715, acc=0.2750000059604645, loss=2.3115363121032715
train: epoch 27, loss 0.5812388062477112, acc=0.7975000143051147, loss=0.5812388062477112
test: epoch 27, loss 2.265491247177124, acc=0.29722222685813904, loss=2.265491247177124
train: epoch 28, loss 0.5640212297439575, acc=0.8001111149787903, loss=0.5640212297439575
test: epoch 28, loss 2.1906933784484863, acc=0.30000001192092896, loss=2.1906933784484863
train: epoch 29, loss 0.5636913180351257, acc=0.8029444217681885, loss=0.5636913180351257
test: epoch 29, loss 1.9081133604049683, acc=0.32499998807907104, loss=1.9081133604049683
train: epoch 30, loss 0.5601040720939636, acc=0.8043888807296753, loss=0.5601040720939636
test: epoch 30, loss 2.031489133834839, acc=0.2777777910232544, loss=2.031489133834839
train: epoch 31, loss 0.5482633709907532, acc=0.8050000071525574, loss=0.5482633709907532
test: epoch 31, loss 2.030668258666992, acc=0.3305555582046509, loss=2.030668258666992
train: epoch 32, loss 0.5371730327606201, acc=0.808555543422699, loss=0.5371730327606201
test: epoch 32, loss 1.9572645425796509, acc=0.3444444537162781, loss=1.9572645425796509
train: epoch 33, loss 0.5553067326545715, acc=0.8047778010368347, loss=0.5553067326545715
test: epoch 33, loss 1.914736270904541, acc=0.3194444477558136, loss=1.914736270904541
train: epoch 34, loss 0.5407922863960266, acc=0.808388888835907, loss=0.5407922863960266
test: epoch 34, loss 1.9529527425765991, acc=0.3722222149372101, loss=1.9529527425765991
train: epoch 35, loss 0.5344592928886414, acc=0.8146111369132996, loss=0.5344592928886414
test: epoch 35, loss 1.895400047302246, acc=0.30000001192092896, loss=1.895400047302246
train: epoch 36, loss 0.5198370814323425, acc=0.8158888816833496, loss=0.5198370814323425
test: epoch 36, loss 1.9001251459121704, acc=0.3638888895511627, loss=1.9001251459121704
train: epoch 37, loss 0.541106104850769, acc=0.8153889179229736, loss=0.541106104850769
test: epoch 37, loss 1.846961498260498, acc=0.3083333373069763, loss=1.846961498260498
train: epoch 38, loss 0.5257512927055359, acc=0.8153333067893982, loss=0.5257512927055359
test: epoch 38, loss 1.8217194080352783, acc=0.3444444537162781, loss=1.8217194080352783
train: epoch 39, loss 0.520626962184906, acc=0.8168888688087463, loss=0.520626962184906
test: epoch 39, loss 1.7086490392684937, acc=0.3722222149372101, loss=1.7086490392684937
train: epoch 40, loss 0.5138016939163208, acc=0.820722222328186, loss=0.5138016939163208
test: epoch 40, loss 1.7937452793121338, acc=0.375, loss=1.7937452793121338
train: epoch 41, loss 0.5087223052978516, acc=0.8212222456932068, loss=0.5087223052978516
test: epoch 41, loss 1.7280336618423462, acc=0.3861111104488373, loss=1.7280336618423462
train: epoch 42, loss 0.509488046169281, acc=0.8192222118377686, loss=0.509488046169281
test: epoch 42, loss 1.7297049760818481, acc=0.3777777850627899, loss=1.7297049760818481
train: epoch 43, loss 0.5203688740730286, acc=0.815833330154419, loss=0.5203688740730286
test: epoch 43, loss 1.7310919761657715, acc=0.375, loss=1.7310919761657715
train: epoch 44, loss 0.5131829380989075, acc=0.8191111087799072, loss=0.5131829380989075
test: epoch 44, loss 1.7341814041137695, acc=0.3722222149372101, loss=1.7341814041137695
train: epoch 45, loss 0.5043216943740845, acc=0.8220555782318115, loss=0.5043216943740845
test: epoch 45, loss 1.7956651449203491, acc=0.3499999940395355, loss=1.7956651449203491
train: epoch 46, loss 0.5142615437507629, acc=0.8208333253860474, loss=0.5142615437507629
test: epoch 46, loss 1.6682943105697632, acc=0.38333332538604736, loss=1.6682943105697632
train: epoch 47, loss 0.49814650416374207, acc=0.8254444599151611, loss=0.49814650416374207
test: epoch 47, loss 1.7606076002120972, acc=0.38055557012557983, loss=1.7606076002120972
train: epoch 48, loss 0.4995900094509125, acc=0.8231111168861389, loss=0.4995900094509125
test: epoch 48, loss 1.6289364099502563, acc=0.39444443583488464, loss=1.6289364099502563
train: epoch 49, loss 0.5004129409790039, acc=0.8222777843475342, loss=0.5004129409790039
test: epoch 49, loss 1.7605221271514893, acc=0.3444444537162781, loss=1.7605221271514893
train: epoch 50, loss 0.4938599467277527, acc=0.8223333358764648, loss=0.4938599467277527
test: epoch 50, loss 1.542763352394104, acc=0.3888888955116272, loss=1.542763352394104
train: epoch 51, loss 0.5017480254173279, acc=0.8222777843475342, loss=0.5017480254173279
test: epoch 51, loss 1.5428348779678345, acc=0.3888888955116272, loss=1.5428348779678345
train: epoch 52, loss 0.4835328161716461, acc=0.8271666765213013, loss=0.4835328161716461
test: epoch 52, loss 1.596215844154358, acc=0.38333332538604736, loss=1.596215844154358
train: epoch 53, loss 0.4879521131515503, acc=0.8258333206176758, loss=0.4879521131515503
test: epoch 53, loss 1.5273007154464722, acc=0.4305555522441864, loss=1.5273007154464722
train: epoch 54, loss 0.4841715693473816, acc=0.8258888721466064, loss=0.4841715693473816
test: epoch 54, loss 1.5607610940933228, acc=0.3888888955116272, loss=1.5607610940933228
train: epoch 55, loss 0.4830016791820526, acc=0.8286666870117188, loss=0.4830016791820526
test: epoch 55, loss 1.5793921947479248, acc=0.4138889014720917, loss=1.5793921947479248
train: epoch 56, loss 0.4919375777244568, acc=0.8277222514152527, loss=0.4919375777244568
test: epoch 56, loss 1.4777783155441284, acc=0.4472222328186035, loss=1.4777783155441284
train: epoch 57, loss 0.47516167163848877, acc=0.8306111097335815, loss=0.47516167163848877
test: epoch 57, loss 1.535274624824524, acc=0.4444444477558136, loss=1.535274624824524
train: epoch 58, loss 0.4849676489830017, acc=0.8283888697624207, loss=0.4849676489830017
test: epoch 58, loss 1.4347642660140991, acc=0.43888887763023376, loss=1.4347642660140991
train: epoch 59, loss 0.4751298725605011, acc=0.8274444341659546, loss=0.4751298725605011
test: epoch 59, loss 1.4813423156738281, acc=0.4305555522441864, loss=1.4813423156738281
train: epoch 60, loss 0.4844958484172821, acc=0.8305555582046509, loss=0.4844958484172821
test: epoch 60, loss 1.4573134183883667, acc=0.4194444417953491, loss=1.4573134183883667
train: epoch 61, loss 0.4939081072807312, acc=0.8256666660308838, loss=0.4939081072807312
test: epoch 61, loss 1.4003782272338867, acc=0.4416666626930237, loss=1.4003782272338867
train: epoch 62, loss 0.4852040410041809, acc=0.8295555710792542, loss=0.4852040410041809
test: epoch 62, loss 1.3512364625930786, acc=0.4722222089767456, loss=1.3512364625930786
train: epoch 63, loss 0.4794323146343231, acc=0.8316110968589783, loss=0.4794323146343231
test: epoch 63, loss 1.4320553541183472, acc=0.4694444537162781, loss=1.4320553541183472
train: epoch 64, loss 0.48957881331443787, acc=0.828166663646698, loss=0.48957881331443787
test: epoch 64, loss 1.379783272743225, acc=0.4444444477558136, loss=1.379783272743225
train: epoch 65, loss 0.4652501344680786, acc=0.8300555348396301, loss=0.4652501344680786
test: epoch 65, loss 1.3539671897888184, acc=0.4694444537162781, loss=1.3539671897888184
train: epoch 66, loss 0.5017108917236328, acc=0.8277222514152527, loss=0.5017108917236328
test: epoch 66, loss 1.4257545471191406, acc=0.4749999940395355, loss=1.4257545471191406
train: epoch 67, loss 0.4733513295650482, acc=0.832611083984375, loss=0.4733513295650482
test: epoch 67, loss 1.2948652505874634, acc=0.4861111044883728, loss=1.2948652505874634
train: epoch 68, loss 0.45220810174942017, acc=0.8388888835906982, loss=0.45220810174942017
test: epoch 68, loss 1.3453556299209595, acc=0.48055556416511536, loss=1.3453556299209595
train: epoch 69, loss 0.46646103262901306, acc=0.8337222337722778, loss=0.46646103262901306
test: epoch 69, loss 1.362579345703125, acc=0.4833333194255829, loss=1.362579345703125
train: epoch 70, loss 0.47010666131973267, acc=0.8332222104072571, loss=0.47010666131973267
test: epoch 70, loss 1.4080564975738525, acc=0.4833333194255829, loss=1.4080564975738525
train: epoch 71, loss 0.453770250082016, acc=0.8382222056388855, loss=0.453770250082016
test: epoch 71, loss 1.3615385293960571, acc=0.4888888895511627, loss=1.3615385293960571
train: epoch 72, loss 0.45383912324905396, acc=0.836388885974884, loss=0.45383912324905396
test: epoch 72, loss 1.2715163230895996, acc=0.4861111044883728, loss=1.2715163230895996
train: epoch 73, loss 0.45345714688301086, acc=0.8378333449363708, loss=0.45345714688301086
test: epoch 73, loss 1.3497552871704102, acc=0.4722222089767456, loss=1.3497552871704102
train: epoch 74, loss 0.4422459006309509, acc=0.8392778038978577, loss=0.4422459006309509
test: epoch 74, loss 1.2595632076263428, acc=0.48055556416511536, loss=1.2595632076263428
train: epoch 75, loss 0.44501280784606934, acc=0.8388333320617676, loss=0.44501280784606934
test: epoch 75, loss 1.2816108465194702, acc=0.5, loss=1.2816108465194702
train: epoch 76, loss 0.4541904032230377, acc=0.8345555663108826, loss=0.4541904032230377
test: epoch 76, loss 1.256149172782898, acc=0.5111111402511597, loss=1.256149172782898
train: epoch 77, loss 0.4267764389514923, acc=0.8417778015136719, loss=0.4267764389514923
test: epoch 77, loss 1.2119791507720947, acc=0.5416666865348816, loss=1.2119791507720947
train: epoch 78, loss 0.4447512924671173, acc=0.8380555510520935, loss=0.4447512924671173
test: epoch 78, loss 1.1799602508544922, acc=0.5361111164093018, loss=1.1799602508544922
train: epoch 79, loss 0.4379078149795532, acc=0.8422222137451172, loss=0.4379078149795532
test: epoch 79, loss 1.3083829879760742, acc=0.5416666865348816, loss=1.3083829879760742
train: epoch 80, loss 0.4295022487640381, acc=0.8418333530426025, loss=0.4295022487640381
test: epoch 80, loss 1.2890498638153076, acc=0.5083333253860474, loss=1.2890498638153076
train: epoch 81, loss 0.43194952607154846, acc=0.8427222371101379, loss=0.43194952607154846
test: epoch 81, loss 1.216546893119812, acc=0.5666666626930237, loss=1.216546893119812
train: epoch 82, loss 0.4341525733470917, acc=0.8428888916969299, loss=0.4341525733470917
test: epoch 82, loss 1.1459983587265015, acc=0.5666666626930237, loss=1.1459983587265015
train: epoch 83, loss 0.4334702789783478, acc=0.8442222476005554, loss=0.4334702789783478
test: epoch 83, loss 1.1644357442855835, acc=0.5583333373069763, loss=1.1644357442855835
train: epoch 84, loss 0.42719563841819763, acc=0.8427777886390686, loss=0.42719563841819763
test: epoch 84, loss 1.1047550439834595, acc=0.5444444417953491, loss=1.1047550439834595
train: epoch 85, loss 0.4212197959423065, acc=0.8439444303512573, loss=0.4212197959423065
test: epoch 85, loss 1.1692031621932983, acc=0.550000011920929, loss=1.1692031621932983
train: epoch 86, loss 0.4187679886817932, acc=0.8464444279670715, loss=0.4187679886817932
test: epoch 86, loss 1.1468000411987305, acc=0.5527777671813965, loss=1.1468000411987305
train: epoch 87, loss 0.4176793396472931, acc=0.8456110954284668, loss=0.4176793396472931
test: epoch 87, loss 1.0831551551818848, acc=0.5527777671813965, loss=1.0831551551818848
train: epoch 88, loss 0.42523667216300964, acc=0.8454999923706055, loss=0.42523667216300964
test: epoch 88, loss 1.0915532112121582, acc=0.5944444537162781, loss=1.0915532112121582
train: epoch 89, loss 0.4120752513408661, acc=0.8510555624961853, loss=0.4120752513408661
test: epoch 89, loss 1.0484634637832642, acc=0.5722222328186035, loss=1.0484634637832642
train: epoch 90, loss 0.4159359335899353, acc=0.8458889126777649, loss=0.4159359335899353
test: epoch 90, loss 1.0639727115631104, acc=0.6194444298744202, loss=1.0639727115631104
train: epoch 91, loss 0.40882956981658936, acc=0.8487222194671631, loss=0.40882956981658936
test: epoch 91, loss 1.076709508895874, acc=0.6083333492279053, loss=1.076709508895874
train: epoch 92, loss 0.401552677154541, acc=0.8554444313049316, loss=0.401552677154541
test: epoch 92, loss 1.0735208988189697, acc=0.6000000238418579, loss=1.0735208988189697
train: epoch 93, loss 0.39153042435646057, acc=0.8578888773918152, loss=0.39153042435646057
test: epoch 93, loss 0.8882570266723633, acc=0.6499999761581421, loss=0.8882570266723633
train: epoch 94, loss 0.40947118401527405, acc=0.8531666398048401, loss=0.40947118401527405
test: epoch 94, loss 0.9074240922927856, acc=0.6527777910232544, loss=0.9074240922927856
train: epoch 95, loss 0.404909610748291, acc=0.8547777533531189, loss=0.404909610748291
test: epoch 95, loss 1.0184930562973022, acc=0.6305555701255798, loss=1.0184930562973022
train: epoch 96, loss 0.3938765823841095, acc=0.8565000295639038, loss=0.3938765823841095
test: epoch 96, loss 0.9570201635360718, acc=0.6638888716697693, loss=0.9570201635360718
train: epoch 97, loss 0.38929101824760437, acc=0.8546110987663269, loss=0.38929101824760437
test: epoch 97, loss 0.9302015900611877, acc=0.6555555462837219, loss=0.9302015900611877
train: epoch 98, loss 0.3852480351924896, acc=0.8615000247955322, loss=0.3852480351924896
test: epoch 98, loss 0.8486289381980896, acc=0.675000011920929, loss=0.8486289381980896
train: epoch 99, loss 0.38370129466056824, acc=0.862666666507721, loss=0.38370129466056824
test: epoch 99, loss 0.8922088146209717, acc=0.6555555462837219, loss=0.8922088146209717
train: epoch 100, loss 0.38883697986602783, acc=0.8591111302375793, loss=0.38883697986602783
test: epoch 100, loss 0.8486104607582092, acc=0.6888889074325562, loss=0.8486104607582092
train: epoch 101, loss 0.37899360060691833, acc=0.8661110997200012, loss=0.37899360060691833
test: epoch 101, loss 0.9007134437561035, acc=0.6777777671813965, loss=0.9007134437561035
train: epoch 102, loss 0.36238470673561096, acc=0.8663889169692993, loss=0.36238470673561096
test: epoch 102, loss 0.8622749447822571, acc=0.6861110925674438, loss=0.8622749447822571
train: epoch 103, loss 0.3809584975242615, acc=0.8659444451332092, loss=0.3809584975242615
test: epoch 103, loss 0.8262202739715576, acc=0.6833333373069763, loss=0.8262202739715576
train: epoch 104, loss 0.36989569664001465, acc=0.8686110973358154, loss=0.36989569664001465
test: epoch 104, loss 0.8407986164093018, acc=0.7027778029441833, loss=0.8407986164093018
train: epoch 105, loss 0.34410208463668823, acc=0.8748888969421387, loss=0.34410208463668823
test: epoch 105, loss 0.762062668800354, acc=0.7138888835906982, loss=0.762062668800354
train: epoch 106, loss 0.33913418650627136, acc=0.8749444484710693, loss=0.33913418650627136
test: epoch 106, loss 0.7958952188491821, acc=0.6888889074325562, loss=0.7958952188491821
train: epoch 107, loss 0.34525594115257263, acc=0.8762221932411194, loss=0.34525594115257263
test: epoch 107, loss 0.8178443908691406, acc=0.6666666865348816, loss=0.8178443908691406
train: epoch 108, loss 0.3534499406814575, acc=0.8715555667877197, loss=0.3534499406814575
test: epoch 108, loss 0.7223192453384399, acc=0.6916666626930237, loss=0.7223192453384399
train: epoch 109, loss 0.33148419857025146, acc=0.8813333511352539, loss=0.33148419857025146
test: epoch 109, loss 0.8370082378387451, acc=0.7027778029441833, loss=0.8370082378387451
train: epoch 110, loss 0.3231297731399536, acc=0.8815555572509766, loss=0.3231297731399536
test: epoch 110, loss 0.7644031047821045, acc=0.699999988079071, loss=0.7644031047821045
train: epoch 111, loss 0.32322144508361816, acc=0.8816111087799072, loss=0.32322144508361816
test: epoch 111, loss 0.7451260089874268, acc=0.7055555582046509, loss=0.7451260089874268
train: epoch 112, loss 0.33621978759765625, acc=0.8848888874053955, loss=0.33621978759765625
test: epoch 112, loss 0.7974263429641724, acc=0.7194444537162781, loss=0.7974263429641724
train: epoch 113, loss 0.3208295702934265, acc=0.8841666579246521, loss=0.3208295702934265
test: epoch 113, loss 0.7533703446388245, acc=0.7138888835906982, loss=0.7533703446388245
train: epoch 114, loss 0.3115490972995758, acc=0.8856666684150696, loss=0.3115490972995758
test: epoch 114, loss 0.8233876824378967, acc=0.7250000238418579, loss=0.8233876824378967
train: epoch 115, loss 0.33251720666885376, acc=0.8818888664245605, loss=0.33251720666885376
test: epoch 115, loss 0.7023526430130005, acc=0.7361111044883728, loss=0.7023526430130005
train: epoch 116, loss 0.29436808824539185, acc=0.8894444704055786, loss=0.29436808824539185
test: epoch 116, loss 0.6795599460601807, acc=0.7472222447395325, loss=0.6795599460601807
train: epoch 117, loss 0.3051885664463043, acc=0.8899999856948853, loss=0.3051885664463043
test: epoch 117, loss 0.6973590850830078, acc=0.75, loss=0.6973590850830078
train: epoch 118, loss 0.30269721150398254, acc=0.8891666531562805, loss=0.30269721150398254
test: epoch 118, loss 0.6681339144706726, acc=0.7444444298744202, loss=0.6681339144706726
train: epoch 119, loss 0.3206541836261749, acc=0.8900555372238159, loss=0.3206541836261749
test: epoch 119, loss 0.7303501963615417, acc=0.7333333492279053, loss=0.7303501963615417
train: epoch 120, loss 0.3001323342323303, acc=0.8904444575309753, loss=0.3001323342323303
test: epoch 120, loss 0.6765168309211731, acc=0.7638888955116272, loss=0.6765168309211731
train: epoch 121, loss 0.28246867656707764, acc=0.894444465637207, loss=0.28246867656707764
test: epoch 121, loss 0.6940574049949646, acc=0.7555555701255798, loss=0.6940574049949646
train: epoch 122, loss 0.2790983319282532, acc=0.899055540561676, loss=0.2790983319282532
test: epoch 122, loss 0.6756086945533752, acc=0.7666666507720947, loss=0.6756086945533752
train: epoch 123, loss 0.294223815202713, acc=0.8943889141082764, loss=0.294223815202713
test: epoch 123, loss 0.6932180523872375, acc=0.7611111402511597, loss=0.6932180523872375
train: epoch 124, loss 0.27727454900741577, acc=0.8957777619361877, loss=0.27727454900741577
test: epoch 124, loss 0.6359421014785767, acc=0.7666666507720947, loss=0.6359421014785767
train: epoch 125, loss 0.2754600942134857, acc=0.898277759552002, loss=0.2754600942134857
test: epoch 125, loss 0.668455958366394, acc=0.7722222208976746, loss=0.668455958366394
train: epoch 126, loss 0.2802008390426636, acc=0.8995555639266968, loss=0.2802008390426636
test: epoch 126, loss 0.6446362137794495, acc=0.769444465637207, loss=0.6446362137794495
train: epoch 127, loss 0.27161723375320435, acc=0.9008888602256775, loss=0.27161723375320435
test: epoch 127, loss 0.6680247187614441, acc=0.7583333253860474, loss=0.6680247187614441
train: epoch 128, loss 0.2786625623703003, acc=0.8995555639266968, loss=0.2786625623703003
test: epoch 128, loss 0.638090193271637, acc=0.7722222208976746, loss=0.638090193271637
train: epoch 129, loss 0.2677239775657654, acc=0.8989444375038147, loss=0.2677239775657654
test: epoch 129, loss 0.6913208961486816, acc=0.7666666507720947, loss=0.6913208961486816
train: epoch 130, loss 0.26166394352912903, acc=0.9026111364364624, loss=0.26166394352912903
test: epoch 130, loss 0.6527446508407593, acc=0.7722222208976746, loss=0.6527446508407593
train: epoch 131, loss 0.2692877948284149, acc=0.898722231388092, loss=0.2692877948284149
test: epoch 131, loss 0.6785466074943542, acc=0.769444465637207, loss=0.6785466074943542
train: epoch 132, loss 0.2621334195137024, acc=0.9036666750907898, loss=0.2621334195137024
test: epoch 132, loss 0.6565326452255249, acc=0.7749999761581421, loss=0.6565326452255249
train: epoch 133, loss 0.26741713285446167, acc=0.9054444432258606, loss=0.26741713285446167
test: epoch 133, loss 0.7078258395195007, acc=0.7611111402511597, loss=0.7078258395195007
train: epoch 134, loss 0.25938329100608826, acc=0.9029444456100464, loss=0.25938329100608826
test: epoch 134, loss 0.6172531247138977, acc=0.7749999761581421, loss=0.6172531247138977
train: epoch 135, loss 0.2497788518667221, acc=0.9049999713897705, loss=0.2497788518667221
test: epoch 135, loss 0.6281071901321411, acc=0.7666666507720947, loss=0.6281071901321411
train: epoch 136, loss 0.2501947283744812, acc=0.906000018119812, loss=0.2501947283744812
test: epoch 136, loss 0.6991167664527893, acc=0.7777777910232544, loss=0.6991167664527893
train: epoch 137, loss 0.2518084645271301, acc=0.9078888893127441, loss=0.2518084645271301
test: epoch 137, loss 0.6679865121841431, acc=0.7583333253860474, loss=0.6679865121841431
train: epoch 138, loss 0.24937477707862854, acc=0.9079444408416748, loss=0.24937477707862854
test: epoch 138, loss 0.6665675044059753, acc=0.7777777910232544, loss=0.6665675044059753
train: epoch 139, loss 0.251800537109375, acc=0.9054999947547913, loss=0.251800537109375
test: epoch 139, loss 0.6861927509307861, acc=0.7777777910232544, loss=0.6861927509307861
train: epoch 140, loss 0.24844598770141602, acc=0.9091110825538635, loss=0.24844598770141602
test: epoch 140, loss 0.7323780059814453, acc=0.7638888955116272, loss=0.7323780059814453
train: epoch 141, loss 0.23489263653755188, acc=0.9116666913032532, loss=0.23489263653755188
test: epoch 141, loss 0.6548065543174744, acc=0.7777777910232544, loss=0.6548065543174744
train: epoch 142, loss 0.23885734379291534, acc=0.9122777581214905, loss=0.23885734379291534
test: epoch 142, loss 0.6685859560966492, acc=0.769444465637207, loss=0.6685859560966492
train: epoch 143, loss 0.23905552923679352, acc=0.9117777943611145, loss=0.23905552923679352
test: epoch 143, loss 0.6632404327392578, acc=0.7666666507720947, loss=0.6632404327392578
train: epoch 144, loss 0.22845673561096191, acc=0.913277804851532, loss=0.22845673561096191
test: epoch 144, loss 0.6550468802452087, acc=0.7805555462837219, loss=0.6550468802452087
train: epoch 145, loss 0.2474571317434311, acc=0.9088333249092102, loss=0.2474571317434311
test: epoch 145, loss 0.5800769329071045, acc=0.7722222208976746, loss=0.5800769329071045
train: epoch 146, loss 0.22052504122257233, acc=0.9163888692855835, loss=0.22052504122257233
test: epoch 146, loss 0.6382369995117188, acc=0.7861111164093018, loss=0.6382369995117188
train: epoch 147, loss 0.2339746206998825, acc=0.9131666421890259, loss=0.2339746206998825
test: epoch 147, loss 0.6306169033050537, acc=0.7833333611488342, loss=0.6306169033050537
train: epoch 148, loss 0.22387082874774933, acc=0.914222240447998, loss=0.22387082874774933
test: epoch 148, loss 0.5819931030273438, acc=0.7916666865348816, loss=0.5819931030273438
train: epoch 149, loss 0.22998164594173431, acc=0.9136666655540466, loss=0.22998164594173431
test: epoch 149, loss 0.702634871006012, acc=0.7805555462837219, loss=0.702634871006012
train: epoch 150, loss 0.2326587289571762, acc=0.9110555648803711, loss=0.2326587289571762
test: epoch 150, loss 0.6652701497077942, acc=0.7833333611488342, loss=0.6652701497077942
