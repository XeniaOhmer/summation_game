# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1", "--temp_decay=0.99", "--one_hot=true", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1795747440, receiver_embed_dim=32, temp_decay=0.99, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.1964316368103027, acc=0.06127777695655823, loss=3.1964316368103027
test: epoch 1, loss 2.6169450283050537, acc=0.13055555522441864, loss=2.6169450283050537
train: epoch 2, loss 2.3009445667266846, acc=0.1535000056028366, loss=2.3009445667266846
test: epoch 2, loss 2.404714345932007, acc=0.14444445073604584, loss=2.404714345932007
train: epoch 3, loss 1.9891822338104248, acc=0.21311111748218536, loss=1.9891822338104248
test: epoch 3, loss 2.066133499145508, acc=0.18611110746860504, loss=2.066133499145508
train: epoch 4, loss 1.7905032634735107, acc=0.24922221899032593, loss=1.7905032634735107
test: epoch 4, loss 2.0624613761901855, acc=0.21666666865348816, loss=2.0624613761901855
train: epoch 5, loss 1.6810539960861206, acc=0.2839444577693939, loss=1.6810539960861206
test: epoch 5, loss 1.9702476263046265, acc=0.24722221493721008, loss=1.9702476263046265
train: epoch 6, loss 1.5901861190795898, acc=0.3117777705192566, loss=1.5901861190795898
test: epoch 6, loss 1.990038275718689, acc=0.25555557012557983, loss=1.990038275718689
train: epoch 7, loss 1.514194130897522, acc=0.34238889813423157, loss=1.514194130897522
test: epoch 7, loss 1.9117860794067383, acc=0.2666666805744171, loss=1.9117860794067383
train: epoch 8, loss 1.4600462913513184, acc=0.3653889000415802, loss=1.4600462913513184
test: epoch 8, loss 2.2115299701690674, acc=0.23333333432674408, loss=2.2115299701690674
train: epoch 9, loss 1.4199175834655762, acc=0.3838889002799988, loss=1.4199175834655762
test: epoch 9, loss 1.8097273111343384, acc=0.2750000059604645, loss=1.8097273111343384
train: epoch 10, loss 1.3129472732543945, acc=0.4212222099304199, loss=1.3129472732543945
test: epoch 10, loss 1.7748324871063232, acc=0.3194444477558136, loss=1.7748324871063232
train: epoch 11, loss 1.261781930923462, acc=0.4401666522026062, loss=1.261781930923462
test: epoch 11, loss 1.5250364542007446, acc=0.3472222089767456, loss=1.5250364542007446
train: epoch 12, loss 1.1742979288101196, acc=0.47655555605888367, loss=1.1742979288101196
test: epoch 12, loss 1.4988471269607544, acc=0.4000000059604645, loss=1.4988471269607544
train: epoch 13, loss 1.1097666025161743, acc=0.5059444308280945, loss=1.1097666025161743
test: epoch 13, loss 1.4269752502441406, acc=0.39722222089767456, loss=1.4269752502441406
train: epoch 14, loss 1.0471699237823486, acc=0.5328888893127441, loss=1.0471699237823486
test: epoch 14, loss 1.4318747520446777, acc=0.4000000059604645, loss=1.4318747520446777
train: epoch 15, loss 0.9982566833496094, acc=0.5613889098167419, loss=0.9982566833496094
test: epoch 15, loss 1.3451789617538452, acc=0.4444444477558136, loss=1.3451789617538452
train: epoch 16, loss 0.9802252650260925, acc=0.5717777609825134, loss=0.9802252650260925
test: epoch 16, loss 1.2839643955230713, acc=0.46666666865348816, loss=1.2839643955230713
train: epoch 17, loss 0.8774866461753845, acc=0.6280555725097656, loss=0.8774866461753845
test: epoch 17, loss 1.2708133459091187, acc=0.49166667461395264, loss=1.2708133459091187
train: epoch 18, loss 0.841659665107727, acc=0.6363333463668823, loss=0.841659665107727
test: epoch 18, loss 1.3793491125106812, acc=0.4472222328186035, loss=1.3793491125106812
train: epoch 19, loss 0.8265634775161743, acc=0.6399444341659546, loss=0.8265634775161743
test: epoch 19, loss 1.2383108139038086, acc=0.5444444417953491, loss=1.2383108139038086
train: epoch 20, loss 0.7828399538993835, acc=0.6549444198608398, loss=0.7828399538993835
test: epoch 20, loss 1.339002013206482, acc=0.49444442987442017, loss=1.339002013206482
train: epoch 21, loss 0.7786675691604614, acc=0.6614444255828857, loss=0.7786675691604614
test: epoch 21, loss 1.1875171661376953, acc=0.5277777910232544, loss=1.1875171661376953
train: epoch 22, loss 0.7437747120857239, acc=0.6714444160461426, loss=0.7437747120857239
test: epoch 22, loss 1.1123464107513428, acc=0.5361111164093018, loss=1.1123464107513428
train: epoch 23, loss 0.7442265748977661, acc=0.6765555739402771, loss=0.7442265748977661
test: epoch 23, loss 1.333723545074463, acc=0.519444465637207, loss=1.333723545074463
train: epoch 24, loss 0.7391753196716309, acc=0.6786666512489319, loss=0.7391753196716309
test: epoch 24, loss 1.0693480968475342, acc=0.550000011920929, loss=1.0693480968475342
train: epoch 25, loss 0.6977924704551697, acc=0.6899444460868835, loss=0.6977924704551697
test: epoch 25, loss 1.2327126264572144, acc=0.5527777671813965, loss=1.2327126264572144
train: epoch 26, loss 0.7045416235923767, acc=0.6831111311912537, loss=0.7045416235923767
test: epoch 26, loss 1.0501203536987305, acc=0.5611110925674438, loss=1.0501203536987305
train: epoch 27, loss 0.6946236491203308, acc=0.6882222294807434, loss=0.6946236491203308
test: epoch 27, loss 0.9991657137870789, acc=0.5555555820465088, loss=0.9991657137870789
train: epoch 28, loss 0.6789896488189697, acc=0.6945000290870667, loss=0.6789896488189697
test: epoch 28, loss 1.052079200744629, acc=0.5472221970558167, loss=1.052079200744629
train: epoch 29, loss 0.6883372068405151, acc=0.6927777528762817, loss=0.6883372068405151
test: epoch 29, loss 1.0657967329025269, acc=0.5416666865348816, loss=1.0657967329025269
train: epoch 30, loss 0.6791996359825134, acc=0.699222207069397, loss=0.6791996359825134
test: epoch 30, loss 0.924758791923523, acc=0.5861111283302307, loss=0.924758791923523
train: epoch 31, loss 0.654061496257782, acc=0.7055555582046509, loss=0.654061496257782
test: epoch 31, loss 1.1082663536071777, acc=0.5361111164093018, loss=1.1082663536071777
train: epoch 32, loss 0.6577427983283997, acc=0.6981666684150696, loss=0.6577427983283997
test: epoch 32, loss 1.1053253412246704, acc=0.5805555582046509, loss=1.1053253412246704
train: epoch 33, loss 0.6624919772148132, acc=0.7005000114440918, loss=0.6624919772148132
test: epoch 33, loss 0.9156702756881714, acc=0.5777778029441833, loss=0.9156702756881714
train: epoch 34, loss 0.6505192518234253, acc=0.7113333344459534, loss=0.6505192518234253
test: epoch 34, loss 1.1792012453079224, acc=0.550000011920929, loss=1.1792012453079224
train: epoch 35, loss 0.6501134037971497, acc=0.7090555429458618, loss=0.6501134037971497
test: epoch 35, loss 1.080778956413269, acc=0.5333333611488342, loss=1.080778956413269
train: epoch 36, loss 0.6345948576927185, acc=0.7206666469573975, loss=0.6345948576927185
test: epoch 36, loss 0.9163811802864075, acc=0.5861111283302307, loss=0.9163811802864075
train: epoch 37, loss 0.6121288537979126, acc=0.7312222123146057, loss=0.6121288537979126
test: epoch 37, loss 0.9044989943504333, acc=0.5972222089767456, loss=0.9044989943504333
train: epoch 38, loss 0.5606759786605835, acc=0.7522222399711609, loss=0.5606759786605835
test: epoch 38, loss 1.1383945941925049, acc=0.5805555582046509, loss=1.1383945941925049
train: epoch 39, loss 0.5845979452133179, acc=0.7465000152587891, loss=0.5845979452133179
test: epoch 39, loss 1.109755039215088, acc=0.5638889074325562, loss=1.109755039215088
train: epoch 40, loss 0.589417576789856, acc=0.74144446849823, loss=0.589417576789856
test: epoch 40, loss 1.0358672142028809, acc=0.5888888835906982, loss=1.0358672142028809
train: epoch 41, loss 0.5707858204841614, acc=0.7502777576446533, loss=0.5707858204841614
test: epoch 41, loss 0.9560763835906982, acc=0.5916666388511658, loss=0.9560763835906982
train: epoch 42, loss 0.5618195533752441, acc=0.7555555701255798, loss=0.5618195533752441
test: epoch 42, loss 1.2300302982330322, acc=0.5944444537162781, loss=1.2300302982330322
train: epoch 43, loss 0.5639238953590393, acc=0.7494999766349792, loss=0.5639238953590393
test: epoch 43, loss 1.2080029249191284, acc=0.5833333134651184, loss=1.2080029249191284
train: epoch 44, loss 0.5808825492858887, acc=0.7459444403648376, loss=0.5808825492858887
test: epoch 44, loss 1.129676342010498, acc=0.5722222328186035, loss=1.129676342010498
train: epoch 45, loss 0.5647834539413452, acc=0.7536110877990723, loss=0.5647834539413452
test: epoch 45, loss 1.0089386701583862, acc=0.5833333134651184, loss=1.0089386701583862
train: epoch 46, loss 0.5477885603904724, acc=0.7565000057220459, loss=0.5477885603904724
test: epoch 46, loss 1.083308458328247, acc=0.5916666388511658, loss=1.083308458328247
train: epoch 47, loss 0.5536692142486572, acc=0.7568333148956299, loss=0.5536692142486572
test: epoch 47, loss 0.9022557735443115, acc=0.5972222089767456, loss=0.9022557735443115
train: epoch 48, loss 0.5382353663444519, acc=0.7638888955116272, loss=0.5382353663444519
test: epoch 48, loss 0.941748321056366, acc=0.5972222089767456, loss=0.941748321056366
train: epoch 49, loss 0.5537943840026855, acc=0.7606666684150696, loss=0.5537943840026855
test: epoch 49, loss 1.0649895668029785, acc=0.574999988079071, loss=1.0649895668029785
train: epoch 50, loss 0.5400063991546631, acc=0.7634999752044678, loss=0.5400063991546631
test: epoch 50, loss 1.105360984802246, acc=0.5944444537162781, loss=1.105360984802246
train: epoch 51, loss 0.5423994064331055, acc=0.7683888673782349, loss=0.5423994064331055
test: epoch 51, loss 1.0734158754348755, acc=0.6000000238418579, loss=1.0734158754348755
train: epoch 52, loss 0.5264632701873779, acc=0.7663888931274414, loss=0.5264632701873779
test: epoch 52, loss 1.2347073554992676, acc=0.5611110925674438, loss=1.2347073554992676
train: epoch 53, loss 0.5538641810417175, acc=0.7595000267028809, loss=0.5538641810417175
test: epoch 53, loss 1.0739686489105225, acc=0.5777778029441833, loss=1.0739686489105225
train: epoch 54, loss 0.5374311208724976, acc=0.7642222046852112, loss=0.5374311208724976
test: epoch 54, loss 1.006380558013916, acc=0.5972222089767456, loss=1.006380558013916
train: epoch 55, loss 0.539315402507782, acc=0.7650555372238159, loss=0.539315402507782
test: epoch 55, loss 0.9996122717857361, acc=0.5944444537162781, loss=0.9996122717857361
train: epoch 56, loss 0.5214271545410156, acc=0.774055540561676, loss=0.5214271545410156
test: epoch 56, loss 1.0626816749572754, acc=0.5638889074325562, loss=1.0626816749572754
train: epoch 57, loss 0.5312833189964294, acc=0.769444465637207, loss=0.5312833189964294
test: epoch 57, loss 1.0083621740341187, acc=0.5972222089767456, loss=1.0083621740341187
train: epoch 58, loss 0.5260467529296875, acc=0.7698333263397217, loss=0.5260467529296875
test: epoch 58, loss 1.0242817401885986, acc=0.5972222089767456, loss=1.0242817401885986
train: epoch 59, loss 0.5181516408920288, acc=0.7721666693687439, loss=0.5181516408920288
test: epoch 59, loss 1.0215790271759033, acc=0.5972222089767456, loss=1.0215790271759033
train: epoch 60, loss 0.5152528285980225, acc=0.7746111154556274, loss=0.5152528285980225
test: epoch 60, loss 1.1737414598464966, acc=0.5944444537162781, loss=1.1737414598464966
train: epoch 61, loss 0.5309204459190369, acc=0.7753333449363708, loss=0.5309204459190369
test: epoch 61, loss 1.1095374822616577, acc=0.6000000238418579, loss=1.1095374822616577
train: epoch 62, loss 0.5119293928146362, acc=0.781333327293396, loss=0.5119293928146362
test: epoch 62, loss 1.061601161956787, acc=0.5833333134651184, loss=1.061601161956787
train: epoch 63, loss 0.512825071811676, acc=0.7798888683319092, loss=0.512825071811676
test: epoch 63, loss 1.099212646484375, acc=0.5916666388511658, loss=1.099212646484375
train: epoch 64, loss 0.511106550693512, acc=0.7776666879653931, loss=0.511106550693512
test: epoch 64, loss 1.095393180847168, acc=0.6000000238418579, loss=1.095393180847168
train: epoch 65, loss 0.5118831396102905, acc=0.7845555543899536, loss=0.5118831396102905
test: epoch 65, loss 1.1497461795806885, acc=0.5944444537162781, loss=1.1497461795806885
train: epoch 66, loss 0.5196262001991272, acc=0.777222216129303, loss=0.5196262001991272
test: epoch 66, loss 1.0442959070205688, acc=0.5944444537162781, loss=1.0442959070205688
train: epoch 67, loss 0.5227975249290466, acc=0.7731666564941406, loss=0.5227975249290466
test: epoch 67, loss 1.0811160802841187, acc=0.5944444537162781, loss=1.0811160802841187
train: epoch 68, loss 0.48765236139297485, acc=0.7838888764381409, loss=0.48765236139297485
test: epoch 68, loss 0.936322033405304, acc=0.5833333134651184, loss=0.936322033405304
train: epoch 69, loss 0.49577242136001587, acc=0.7885555624961853, loss=0.49577242136001587
test: epoch 69, loss 1.256658673286438, acc=0.5861111283302307, loss=1.256658673286438
train: epoch 70, loss 0.5054203867912292, acc=0.7801111340522766, loss=0.5054203867912292
test: epoch 70, loss 1.1754807233810425, acc=0.5916666388511658, loss=1.1754807233810425
train: epoch 71, loss 0.49932119250297546, acc=0.7822222113609314, loss=0.49932119250297546
test: epoch 71, loss 1.2507600784301758, acc=0.5805555582046509, loss=1.2507600784301758
train: epoch 72, loss 0.5048962831497192, acc=0.789555549621582, loss=0.5048962831497192
test: epoch 72, loss 1.0910016298294067, acc=0.5972222089767456, loss=1.0910016298294067
train: epoch 73, loss 0.4956485331058502, acc=0.7880555391311646, loss=0.4956485331058502
test: epoch 73, loss 1.013553500175476, acc=0.5972222089767456, loss=1.013553500175476
train: epoch 74, loss 0.510707437992096, acc=0.7796111106872559, loss=0.510707437992096
test: epoch 74, loss 1.0695430040359497, acc=0.5861111283302307, loss=1.0695430040359497
train: epoch 75, loss 0.4945700466632843, acc=0.7900555729866028, loss=0.4945700466632843
test: epoch 75, loss 1.129481554031372, acc=0.574999988079071, loss=1.129481554031372
train: epoch 76, loss 0.4888724684715271, acc=0.7943333387374878, loss=0.4888724684715271
test: epoch 76, loss 1.0930081605911255, acc=0.5833333134651184, loss=1.0930081605911255
train: epoch 77, loss 0.5072969794273376, acc=0.7827222347259521, loss=0.5072969794273376
test: epoch 77, loss 1.0711909532546997, acc=0.5916666388511658, loss=1.0711909532546997
train: epoch 78, loss 0.5160473585128784, acc=0.7817222476005554, loss=0.5160473585128784
test: epoch 78, loss 1.0154237747192383, acc=0.5972222089767456, loss=1.0154237747192383
train: epoch 79, loss 0.47631046175956726, acc=0.7941111326217651, loss=0.47631046175956726
test: epoch 79, loss 1.2197309732437134, acc=0.5916666388511658, loss=1.2197309732437134
train: epoch 80, loss 0.49471157789230347, acc=0.7886666655540466, loss=0.49471157789230347
test: epoch 80, loss 1.2098337411880493, acc=0.5638889074325562, loss=1.2098337411880493
train: epoch 81, loss 0.4869457483291626, acc=0.7880555391311646, loss=0.4869457483291626
test: epoch 81, loss 1.2187060117721558, acc=0.5888888835906982, loss=1.2187060117721558
train: epoch 82, loss 0.4829625189304352, acc=0.784333348274231, loss=0.4829625189304352
test: epoch 82, loss 1.0254510641098022, acc=0.5916666388511658, loss=1.0254510641098022
train: epoch 83, loss 0.5003412961959839, acc=0.7827222347259521, loss=0.5003412961959839
test: epoch 83, loss 1.1755895614624023, acc=0.5944444537162781, loss=1.1755895614624023
train: epoch 84, loss 0.4819484055042267, acc=0.7865555286407471, loss=0.4819484055042267
test: epoch 84, loss 1.2009779214859009, acc=0.5861111283302307, loss=1.2009779214859009
train: epoch 85, loss 0.49930259585380554, acc=0.7821666598320007, loss=0.49930259585380554
test: epoch 85, loss 1.0487546920776367, acc=0.5972222089767456, loss=1.0487546920776367
train: epoch 86, loss 0.4633833169937134, acc=0.800166666507721, loss=0.4633833169937134
test: epoch 86, loss 1.2731516361236572, acc=0.5888888835906982, loss=1.2731516361236572
train: epoch 87, loss 0.4893365204334259, acc=0.7908333539962769, loss=0.4893365204334259
test: epoch 87, loss 1.110114574432373, acc=0.5861111283302307, loss=1.110114574432373
train: epoch 88, loss 0.4883904755115509, acc=0.7912777662277222, loss=0.4883904755115509
test: epoch 88, loss 1.1715158224105835, acc=0.5972222089767456, loss=1.1715158224105835
train: epoch 89, loss 0.4764035940170288, acc=0.7941666841506958, loss=0.4764035940170288
test: epoch 89, loss 1.2405253648757935, acc=0.5888888835906982, loss=1.2405253648757935
train: epoch 90, loss 0.48497274518013, acc=0.7980555295944214, loss=0.48497274518013
test: epoch 90, loss 1.2479246854782104, acc=0.5916666388511658, loss=1.2479246854782104
train: epoch 91, loss 0.4712250232696533, acc=0.7990555763244629, loss=0.4712250232696533
test: epoch 91, loss 1.168959617614746, acc=0.5888888835906982, loss=1.168959617614746
train: epoch 92, loss 0.4758138954639435, acc=0.8023889064788818, loss=0.4758138954639435
test: epoch 92, loss 1.1800808906555176, acc=0.5888888835906982, loss=1.1800808906555176
train: epoch 93, loss 0.4696465730667114, acc=0.8069999814033508, loss=0.4696465730667114
test: epoch 93, loss 1.228111982345581, acc=0.5916666388511658, loss=1.228111982345581
train: epoch 94, loss 0.4586639702320099, acc=0.8081111311912537, loss=0.4586639702320099
test: epoch 94, loss 1.0699604749679565, acc=0.5916666388511658, loss=1.0699604749679565
train: epoch 95, loss 0.44671958684921265, acc=0.8146666884422302, loss=0.44671958684921265
test: epoch 95, loss 1.1524970531463623, acc=0.5972222089767456, loss=1.1524970531463623
train: epoch 96, loss 0.4298039674758911, acc=0.8234999775886536, loss=0.4298039674758911
test: epoch 96, loss 1.1511876583099365, acc=0.5944444537162781, loss=1.1511876583099365
train: epoch 97, loss 0.4316563010215759, acc=0.8186110854148865, loss=0.4316563010215759
test: epoch 97, loss 1.1693503856658936, acc=0.5916666388511658, loss=1.1693503856658936
train: epoch 98, loss 0.4565563201904297, acc=0.808222234249115, loss=0.4565563201904297
test: epoch 98, loss 1.2030612230300903, acc=0.5666666626930237, loss=1.2030612230300903
train: epoch 99, loss 0.42843103408813477, acc=0.824055552482605, loss=0.42843103408813477
test: epoch 99, loss 1.3734347820281982, acc=0.5833333134651184, loss=1.3734347820281982
train: epoch 100, loss 0.42214977741241455, acc=0.8236111402511597, loss=0.42214977741241455
test: epoch 100, loss 1.1468279361724854, acc=0.5916666388511658, loss=1.1468279361724854
train: epoch 101, loss 0.44756925106048584, acc=0.8122777938842773, loss=0.44756925106048584
test: epoch 101, loss 1.0667815208435059, acc=0.5888888835906982, loss=1.0667815208435059
train: epoch 102, loss 0.4178014397621155, acc=0.8264999985694885, loss=0.4178014397621155
test: epoch 102, loss 1.1633402109146118, acc=0.5944444537162781, loss=1.1633402109146118
train: epoch 103, loss 0.44108808040618896, acc=0.8211110830307007, loss=0.44108808040618896
test: epoch 103, loss 1.0841277837753296, acc=0.5916666388511658, loss=1.0841277837753296
train: epoch 104, loss 0.452864408493042, acc=0.8143333196640015, loss=0.452864408493042
test: epoch 104, loss 1.3505115509033203, acc=0.5666666626930237, loss=1.3505115509033203
train: epoch 105, loss 0.4247111678123474, acc=0.8241666555404663, loss=0.4247111678123474
test: epoch 105, loss 1.2662293910980225, acc=0.5527777671813965, loss=1.2662293910980225
train: epoch 106, loss 0.4318004548549652, acc=0.8221666812896729, loss=0.4318004548549652
test: epoch 106, loss 1.0842519998550415, acc=0.5944444537162781, loss=1.0842519998550415
train: epoch 107, loss 0.4313584268093109, acc=0.8202221989631653, loss=0.4313584268093109
test: epoch 107, loss 1.1475911140441895, acc=0.574999988079071, loss=1.1475911140441895
train: epoch 108, loss 0.43360769748687744, acc=0.8178333044052124, loss=0.43360769748687744
test: epoch 108, loss 1.2503046989440918, acc=0.5944444537162781, loss=1.2503046989440918
train: epoch 109, loss 0.42337480187416077, acc=0.8262222409248352, loss=0.42337480187416077
test: epoch 109, loss 1.2181262969970703, acc=0.5972222089767456, loss=1.2181262969970703
train: epoch 110, loss 0.43334683775901794, acc=0.8256666660308838, loss=0.43334683775901794
test: epoch 110, loss 1.190211534500122, acc=0.5888888835906982, loss=1.190211534500122
train: epoch 111, loss 0.4355100691318512, acc=0.8226110935211182, loss=0.4355100691318512
test: epoch 111, loss 1.2869442701339722, acc=0.5722222328186035, loss=1.2869442701339722
train: epoch 112, loss 0.42894306778907776, acc=0.8231111168861389, loss=0.42894306778907776
test: epoch 112, loss 1.0373393297195435, acc=0.5805555582046509, loss=1.0373393297195435
train: epoch 113, loss 0.4193480610847473, acc=0.8266111016273499, loss=0.4193480610847473
test: epoch 113, loss 1.1999305486679077, acc=0.5916666388511658, loss=1.1999305486679077
train: epoch 114, loss 0.4323706328868866, acc=0.824055552482605, loss=0.4323706328868866
test: epoch 114, loss 1.1210708618164062, acc=0.5694444179534912, loss=1.1210708618164062
train: epoch 115, loss 0.42294859886169434, acc=0.8217777609825134, loss=0.42294859886169434
test: epoch 115, loss 1.2393800020217896, acc=0.5944444537162781, loss=1.2393800020217896
train: epoch 116, loss 0.4161553382873535, acc=0.8263333439826965, loss=0.4161553382873535
test: epoch 116, loss 1.3341976404190063, acc=0.5888888835906982, loss=1.3341976404190063
train: epoch 117, loss 0.40558090806007385, acc=0.8293333053588867, loss=0.40558090806007385
test: epoch 117, loss 1.3183823823928833, acc=0.5916666388511658, loss=1.3183823823928833
train: epoch 118, loss 0.3848610818386078, acc=0.8375555276870728, loss=0.3848610818386078
test: epoch 118, loss 1.2146024703979492, acc=0.5972222089767456, loss=1.2146024703979492
train: epoch 119, loss 0.40745478868484497, acc=0.8342777490615845, loss=0.40745478868484497
test: epoch 119, loss 1.2605870962142944, acc=0.574999988079071, loss=1.2605870962142944
train: epoch 120, loss 0.42564865946769714, acc=0.8268333077430725, loss=0.42564865946769714
test: epoch 120, loss 1.3136178255081177, acc=0.5972222089767456, loss=1.3136178255081177
train: epoch 121, loss 0.4266362190246582, acc=0.8270000219345093, loss=0.4266362190246582
test: epoch 121, loss 1.207227110862732, acc=0.5944444537162781, loss=1.207227110862732
train: epoch 122, loss 0.389410138130188, acc=0.8371111154556274, loss=0.389410138130188
test: epoch 122, loss 1.2943198680877686, acc=0.5972222089767456, loss=1.2943198680877686
train: epoch 123, loss 0.41125521063804626, acc=0.8306666612625122, loss=0.41125521063804626
test: epoch 123, loss 1.2494821548461914, acc=0.5888888835906982, loss=1.2494821548461914
train: epoch 124, loss 0.41990041732788086, acc=0.8282222151756287, loss=0.41990041732788086
test: epoch 124, loss 1.116181492805481, acc=0.5944444537162781, loss=1.116181492805481
train: epoch 125, loss 0.4036372900009155, acc=0.8287222385406494, loss=0.4036372900009155
test: epoch 125, loss 1.3373770713806152, acc=0.5888888835906982, loss=1.3373770713806152
train: epoch 126, loss 0.42057526111602783, acc=0.8277222514152527, loss=0.42057526111602783
test: epoch 126, loss 1.1162256002426147, acc=0.5944444537162781, loss=1.1162256002426147
train: epoch 127, loss 0.39657309651374817, acc=0.836555540561676, loss=0.39657309651374817
test: epoch 127, loss 1.2730512619018555, acc=0.5944444537162781, loss=1.2730512619018555
train: epoch 128, loss 0.40321266651153564, acc=0.832611083984375, loss=0.40321266651153564
test: epoch 128, loss 1.2708648443222046, acc=0.5944444537162781, loss=1.2708648443222046
train: epoch 129, loss 0.41902127861976624, acc=0.8301110863685608, loss=0.41902127861976624
test: epoch 129, loss 1.0984668731689453, acc=0.5888888835906982, loss=1.0984668731689453
train: epoch 130, loss 0.40812593698501587, acc=0.8317221999168396, loss=0.40812593698501587
test: epoch 130, loss 1.1503113508224487, acc=0.5972222089767456, loss=1.1503113508224487
train: epoch 131, loss 0.4181433618068695, acc=0.8316666483879089, loss=0.4181433618068695
test: epoch 131, loss 1.2483104467391968, acc=0.5972222089767456, loss=1.2483104467391968
train: epoch 132, loss 0.38633882999420166, acc=0.8396666646003723, loss=0.38633882999420166
test: epoch 132, loss 1.375340223312378, acc=0.5944444537162781, loss=1.375340223312378
train: epoch 133, loss 0.4134925901889801, acc=0.8346666693687439, loss=0.4134925901889801
test: epoch 133, loss 1.0971269607543945, acc=0.5916666388511658, loss=1.0971269607543945
train: epoch 134, loss 0.4273677170276642, acc=0.8244444727897644, loss=0.4273677170276642
test: epoch 134, loss 1.2172303199768066, acc=0.5972222089767456, loss=1.2172303199768066
train: epoch 135, loss 0.38954102993011475, acc=0.8373333215713501, loss=0.38954102993011475
test: epoch 135, loss 1.2468774318695068, acc=0.5833333134651184, loss=1.2468774318695068
train: epoch 136, loss 0.4179956912994385, acc=0.8307222127914429, loss=0.4179956912994385
test: epoch 136, loss 1.2330783605575562, acc=0.6000000238418579, loss=1.2330783605575562
train: epoch 137, loss 0.37902942299842834, acc=0.8415555357933044, loss=0.37902942299842834
test: epoch 137, loss 1.1716206073760986, acc=0.625, loss=1.1716206073760986
train: epoch 138, loss 0.4062086045742035, acc=0.8307777643203735, loss=0.4062086045742035
test: epoch 138, loss 1.205880045890808, acc=0.6277777552604675, loss=1.205880045890808
train: epoch 139, loss 0.3877500891685486, acc=0.8404444456100464, loss=0.3877500891685486
test: epoch 139, loss 1.142845869064331, acc=0.6083333492279053, loss=1.142845869064331
train: epoch 140, loss 0.3853779435157776, acc=0.8389999866485596, loss=0.3853779435157776
test: epoch 140, loss 1.3172839879989624, acc=0.5944444537162781, loss=1.3172839879989624
train: epoch 141, loss 0.3867075741291046, acc=0.8369444608688354, loss=0.3867075741291046
test: epoch 141, loss 1.194433569908142, acc=0.5916666388511658, loss=1.194433569908142
train: epoch 142, loss 0.3904256522655487, acc=0.8389999866485596, loss=0.3904256522655487
test: epoch 142, loss 1.25674569606781, acc=0.5944444537162781, loss=1.25674569606781
train: epoch 143, loss 0.37097591161727905, acc=0.8429444432258606, loss=0.37097591161727905
test: epoch 143, loss 1.1717883348464966, acc=0.6277777552604675, loss=1.1717883348464966
train: epoch 144, loss 0.41012898087501526, acc=0.8327777981758118, loss=0.41012898087501526
test: epoch 144, loss 1.214188814163208, acc=0.6194444298744202, loss=1.214188814163208
train: epoch 145, loss 0.404414564371109, acc=0.8345000147819519, loss=0.404414564371109
test: epoch 145, loss 1.1642082929611206, acc=0.6194444298744202, loss=1.1642082929611206
train: epoch 146, loss 0.38816678524017334, acc=0.8376666903495789, loss=0.38816678524017334
test: epoch 146, loss 1.1165376901626587, acc=0.6305555701255798, loss=1.1165376901626587
train: epoch 147, loss 0.4156538248062134, acc=0.824999988079071, loss=0.4156538248062134
test: epoch 147, loss 1.1605207920074463, acc=0.6111111044883728, loss=1.1605207920074463
train: epoch 148, loss 0.37520548701286316, acc=0.8429999947547913, loss=0.37520548701286316
test: epoch 148, loss 1.2265031337738037, acc=0.5972222089767456, loss=1.2265031337738037
train: epoch 149, loss 0.36988502740859985, acc=0.8453333377838135, loss=0.36988502740859985
test: epoch 149, loss 1.2247816324234009, acc=0.5805555582046509, loss=1.2247816324234009
train: epoch 150, loss 0.38955649733543396, acc=0.8385000228881836, loss=0.38955649733543396
test: epoch 150, loss 1.130679726600647, acc=0.625, loss=1.130679726600647
