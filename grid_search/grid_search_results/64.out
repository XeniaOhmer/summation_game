# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=1", "--temp_decay=0.995", "--one_hot=false", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1704629480, receiver_embed_dim=64, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.1417438983917236, acc=0.07005555927753448, loss=3.1417438983917236
test: epoch 1, loss 2.7995238304138184, acc=0.09444444626569748, loss=2.7995238304138184
train: epoch 2, loss 2.155571699142456, acc=0.2152777761220932, loss=2.155571699142456
test: epoch 2, loss 2.2818801403045654, acc=0.21666666865348816, loss=2.2818801403045654
train: epoch 3, loss 1.6962391138076782, acc=0.328722208738327, loss=1.6962391138076782
test: epoch 3, loss 1.9418463706970215, acc=0.23333333432674408, loss=1.9418463706970215
train: epoch 4, loss 1.4478442668914795, acc=0.4021666646003723, loss=1.4478442668914795
test: epoch 4, loss 1.8006389141082764, acc=0.25833332538604736, loss=1.8006389141082764
train: epoch 5, loss 1.2650357484817505, acc=0.46272221207618713, loss=1.2650357484817505
test: epoch 5, loss 1.7998837232589722, acc=0.2944444417953491, loss=1.7998837232589722
train: epoch 6, loss 1.147013783454895, acc=0.5063889026641846, loss=1.147013783454895
test: epoch 6, loss 1.7657301425933838, acc=0.30000001192092896, loss=1.7657301425933838
train: epoch 7, loss 1.086484432220459, acc=0.528333306312561, loss=1.086484432220459
test: epoch 7, loss 1.6122468709945679, acc=0.3333333432674408, loss=1.6122468709945679
train: epoch 8, loss 1.019283652305603, acc=0.5616111159324646, loss=1.019283652305603
test: epoch 8, loss 1.6372298002243042, acc=0.3194444477558136, loss=1.6372298002243042
train: epoch 9, loss 0.9580843448638916, acc=0.5907777547836304, loss=0.9580843448638916
test: epoch 9, loss 1.484254002571106, acc=0.3638888895511627, loss=1.484254002571106
train: epoch 10, loss 0.8807713389396667, acc=0.6238333582878113, loss=0.8807713389396667
test: epoch 10, loss 1.6183512210845947, acc=0.3888888955116272, loss=1.6183512210845947
train: epoch 11, loss 0.840293288230896, acc=0.6311110854148865, loss=0.840293288230896
test: epoch 11, loss 1.507990837097168, acc=0.39444443583488464, loss=1.507990837097168
train: epoch 12, loss 0.801947832107544, acc=0.6489444375038147, loss=0.801947832107544
test: epoch 12, loss 1.6021136045455933, acc=0.38333332538604736, loss=1.6021136045455933
train: epoch 13, loss 0.774980902671814, acc=0.6620555520057678, loss=0.774980902671814
test: epoch 13, loss 1.5693118572235107, acc=0.39722222089767456, loss=1.5693118572235107
train: epoch 14, loss 0.7530772089958191, acc=0.6713888645172119, loss=0.7530772089958191
test: epoch 14, loss 1.6982572078704834, acc=0.38333332538604736, loss=1.6982572078704834
train: epoch 15, loss 0.7386592626571655, acc=0.6779999732971191, loss=0.7386592626571655
test: epoch 15, loss 1.5930407047271729, acc=0.3916666805744171, loss=1.5930407047271729
train: epoch 16, loss 0.7274600863456726, acc=0.683388888835907, loss=0.7274600863456726
test: epoch 16, loss 1.544105052947998, acc=0.4000000059604645, loss=1.544105052947998
train: epoch 17, loss 0.7150835990905762, acc=0.6911666393280029, loss=0.7150835990905762
test: epoch 17, loss 1.6829752922058105, acc=0.3888888955116272, loss=1.6829752922058105
train: epoch 18, loss 0.7068527936935425, acc=0.6965555548667908, loss=0.7068527936935425
test: epoch 18, loss 1.5725998878479004, acc=0.3777777850627899, loss=1.5725998878479004
train: epoch 19, loss 0.6993616223335266, acc=0.6940555572509766, loss=0.6993616223335266
test: epoch 19, loss 1.6950976848602295, acc=0.3777777850627899, loss=1.6950976848602295
train: epoch 20, loss 0.690994381904602, acc=0.6997777819633484, loss=0.690994381904602
test: epoch 20, loss 1.7704987525939941, acc=0.42222222685813904, loss=1.7704987525939941
train: epoch 21, loss 0.6836925745010376, acc=0.7031111121177673, loss=0.6836925745010376
test: epoch 21, loss 1.8148669004440308, acc=0.4000000059604645, loss=1.8148669004440308
train: epoch 22, loss 0.6919823884963989, acc=0.6973888874053955, loss=0.6919823884963989
test: epoch 22, loss 1.8145867586135864, acc=0.3777777850627899, loss=1.8145867586135864
train: epoch 23, loss 0.6610463857650757, acc=0.7145000100135803, loss=0.6610463857650757
test: epoch 23, loss 1.8020387887954712, acc=0.3777777850627899, loss=1.8020387887954712
train: epoch 24, loss 0.6648803949356079, acc=0.7088333368301392, loss=0.6648803949356079
test: epoch 24, loss 1.713986873626709, acc=0.4027777910232544, loss=1.713986873626709
train: epoch 25, loss 0.6782822012901306, acc=0.7064444422721863, loss=0.6782822012901306
test: epoch 25, loss 1.6085938215255737, acc=0.41111111640930176, loss=1.6085938215255737
train: epoch 26, loss 0.6590820550918579, acc=0.7134444713592529, loss=0.6590820550918579
test: epoch 26, loss 1.792784333229065, acc=0.4138889014720917, loss=1.792784333229065
train: epoch 27, loss 0.6547076106071472, acc=0.7191110849380493, loss=0.6547076106071472
test: epoch 27, loss 1.6941689252853394, acc=0.3916666805744171, loss=1.6941689252853394
train: epoch 28, loss 0.6615605354309082, acc=0.7123888731002808, loss=0.6615605354309082
test: epoch 28, loss 1.5943173170089722, acc=0.4055555462837219, loss=1.5943173170089722
train: epoch 29, loss 0.6527411341667175, acc=0.7192222476005554, loss=0.6527411341667175
test: epoch 29, loss 1.603421926498413, acc=0.4305555522441864, loss=1.603421926498413
train: epoch 30, loss 0.6498328447341919, acc=0.7197222113609314, loss=0.6498328447341919
test: epoch 30, loss 1.7469204664230347, acc=0.4166666567325592, loss=1.7469204664230347
train: epoch 31, loss 0.6520630717277527, acc=0.7197222113609314, loss=0.6520630717277527
test: epoch 31, loss 1.72750723361969, acc=0.4055555462837219, loss=1.72750723361969
train: epoch 32, loss 0.6620451807975769, acc=0.7133333086967468, loss=0.6620451807975769
test: epoch 32, loss 1.7322700023651123, acc=0.43611112236976624, loss=1.7322700023651123
train: epoch 33, loss 0.6482483744621277, acc=0.7177777886390686, loss=0.6482483744621277
test: epoch 33, loss 1.5880886316299438, acc=0.4166666567325592, loss=1.5880886316299438
train: epoch 34, loss 0.6535376906394958, acc=0.7147777676582336, loss=0.6535376906394958
test: epoch 34, loss 1.6767748594284058, acc=0.4277777671813965, loss=1.6767748594284058
train: epoch 35, loss 0.6428889632225037, acc=0.7162777781486511, loss=0.6428889632225037
test: epoch 35, loss 1.696802020072937, acc=0.42500001192092896, loss=1.696802020072937
train: epoch 36, loss 0.6552272439002991, acc=0.7138888835906982, loss=0.6552272439002991
test: epoch 36, loss 1.574372410774231, acc=0.4277777671813965, loss=1.574372410774231
train: epoch 37, loss 0.6395642161369324, acc=0.7204444408416748, loss=0.6395642161369324
test: epoch 37, loss 1.5188959836959839, acc=0.4444444477558136, loss=1.5188959836959839
train: epoch 38, loss 0.6365945339202881, acc=0.7233889102935791, loss=0.6365945339202881
test: epoch 38, loss 1.578528881072998, acc=0.4416666626930237, loss=1.578528881072998
train: epoch 39, loss 0.6500078439712524, acc=0.7162777781486511, loss=0.6500078439712524
test: epoch 39, loss 1.4967008829116821, acc=0.4277777671813965, loss=1.4967008829116821
train: epoch 40, loss 0.6335997581481934, acc=0.7214999794960022, loss=0.6335997581481934
test: epoch 40, loss 1.5205724239349365, acc=0.4444444477558136, loss=1.5205724239349365
train: epoch 41, loss 0.6421042084693909, acc=0.7238888740539551, loss=0.6421042084693909
test: epoch 41, loss 1.491995930671692, acc=0.4611110985279083, loss=1.491995930671692
train: epoch 42, loss 0.6382110118865967, acc=0.7204999923706055, loss=0.6382110118865967
test: epoch 42, loss 1.5280559062957764, acc=0.43888887763023376, loss=1.5280559062957764
train: epoch 43, loss 0.6391609311103821, acc=0.7181110978126526, loss=0.6391609311103821
test: epoch 43, loss 1.371286392211914, acc=0.46666666865348816, loss=1.371286392211914
train: epoch 44, loss 0.6384064555168152, acc=0.7201666831970215, loss=0.6384064555168152
test: epoch 44, loss 1.4534369707107544, acc=0.4444444477558136, loss=1.4534369707107544
train: epoch 45, loss 0.6166994571685791, acc=0.7254999876022339, loss=0.6166994571685791
test: epoch 45, loss 1.7337514162063599, acc=0.4277777671813965, loss=1.7337514162063599
train: epoch 46, loss 0.6406067609786987, acc=0.7228333353996277, loss=0.6406067609786987
test: epoch 46, loss 1.4381163120269775, acc=0.4555555582046509, loss=1.4381163120269775
train: epoch 47, loss 0.6370514035224915, acc=0.7218888998031616, loss=0.6370514035224915
test: epoch 47, loss 1.380294680595398, acc=0.4611110985279083, loss=1.380294680595398
train: epoch 48, loss 0.6236333250999451, acc=0.7275000214576721, loss=0.6236333250999451
test: epoch 48, loss 1.3770406246185303, acc=0.46388888359069824, loss=1.3770406246185303
train: epoch 49, loss 0.6330280303955078, acc=0.7236666679382324, loss=0.6330280303955078
test: epoch 49, loss 1.530190348625183, acc=0.4333333373069763, loss=1.530190348625183
train: epoch 50, loss 0.6278051733970642, acc=0.723111093044281, loss=0.6278051733970642
test: epoch 50, loss 1.5293368101119995, acc=0.4555555582046509, loss=1.5293368101119995
train: epoch 51, loss 0.6345515847206116, acc=0.7221666574478149, loss=0.6345515847206116
test: epoch 51, loss 1.4458494186401367, acc=0.46388888359069824, loss=1.4458494186401367
train: epoch 52, loss 0.634017288684845, acc=0.7248333096504211, loss=0.634017288684845
test: epoch 52, loss 1.4277045726776123, acc=0.4611110985279083, loss=1.4277045726776123
train: epoch 53, loss 0.6469834446907043, acc=0.7194444537162781, loss=0.6469834446907043
test: epoch 53, loss 1.4963167905807495, acc=0.46388888359069824, loss=1.4963167905807495
train: epoch 54, loss 0.6349127888679504, acc=0.7168889045715332, loss=0.6349127888679504
test: epoch 54, loss 1.388939619064331, acc=0.46388888359069824, loss=1.388939619064331
train: epoch 55, loss 0.6355370283126831, acc=0.7192777991294861, loss=0.6355370283126831
test: epoch 55, loss 1.4732468128204346, acc=0.4611110985279083, loss=1.4732468128204346
train: epoch 56, loss 0.6302062273025513, acc=0.72688889503479, loss=0.6302062273025513
test: epoch 56, loss 1.4587246179580688, acc=0.4583333432674408, loss=1.4587246179580688
train: epoch 57, loss 0.6408627033233643, acc=0.7213888764381409, loss=0.6408627033233643
test: epoch 57, loss 1.3772374391555786, acc=0.4611110985279083, loss=1.3772374391555786
train: epoch 58, loss 0.6585710644721985, acc=0.7152222394943237, loss=0.6585710644721985
test: epoch 58, loss 1.4391956329345703, acc=0.4583333432674408, loss=1.4391956329345703
train: epoch 59, loss 0.6321445107460022, acc=0.7239999771118164, loss=0.6321445107460022
test: epoch 59, loss 1.44564688205719, acc=0.4583333432674408, loss=1.44564688205719
train: epoch 60, loss 0.6347990036010742, acc=0.7244444489479065, loss=0.6347990036010742
test: epoch 60, loss 1.4455400705337524, acc=0.44999998807907104, loss=1.4455400705337524
train: epoch 61, loss 0.6261171102523804, acc=0.7256110906600952, loss=0.6261171102523804
test: epoch 61, loss 1.334850549697876, acc=0.46388888359069824, loss=1.334850549697876
train: epoch 62, loss 0.6400753259658813, acc=0.7170555591583252, loss=0.6400753259658813
test: epoch 62, loss 1.4047428369522095, acc=0.45277777314186096, loss=1.4047428369522095
train: epoch 63, loss 0.6182969808578491, acc=0.7285555601119995, loss=0.6182969808578491
test: epoch 63, loss 1.5833868980407715, acc=0.4611110985279083, loss=1.5833868980407715
train: epoch 64, loss 0.6379214525222778, acc=0.7239999771118164, loss=0.6379214525222778
test: epoch 64, loss 1.4455280303955078, acc=0.4472222328186035, loss=1.4455280303955078
train: epoch 65, loss 0.6269842386245728, acc=0.7256110906600952, loss=0.6269842386245728
test: epoch 65, loss 1.5353388786315918, acc=0.45277777314186096, loss=1.5353388786315918
train: epoch 66, loss 0.6198620796203613, acc=0.7282222509384155, loss=0.6198620796203613
test: epoch 66, loss 1.3503437042236328, acc=0.4583333432674408, loss=1.3503437042236328
train: epoch 67, loss 0.6235765218734741, acc=0.7252777814865112, loss=0.6235765218734741
test: epoch 67, loss 1.5078895092010498, acc=0.46388888359069824, loss=1.5078895092010498
train: epoch 68, loss 0.6197344064712524, acc=0.7279999852180481, loss=0.6197344064712524
test: epoch 68, loss 1.5051051378250122, acc=0.4583333432674408, loss=1.5051051378250122
train: epoch 69, loss 0.6327449679374695, acc=0.7233333587646484, loss=0.6327449679374695
test: epoch 69, loss 1.4179056882858276, acc=0.4583333432674408, loss=1.4179056882858276
train: epoch 70, loss 0.6100636720657349, acc=0.7328333258628845, loss=0.6100636720657349
test: epoch 70, loss 1.4512507915496826, acc=0.46388888359069824, loss=1.4512507915496826
train: epoch 71, loss 0.6147536039352417, acc=0.7325000166893005, loss=0.6147536039352417
test: epoch 71, loss 1.4753904342651367, acc=0.44999998807907104, loss=1.4753904342651367
train: epoch 72, loss 0.6245275139808655, acc=0.727222204208374, loss=0.6245275139808655
test: epoch 72, loss 1.308821678161621, acc=0.4583333432674408, loss=1.308821678161621
train: epoch 73, loss 0.6278730034828186, acc=0.7283889055252075, loss=0.6278730034828186
test: epoch 73, loss 1.506253719329834, acc=0.4611110985279083, loss=1.506253719329834
train: epoch 74, loss 0.6110323071479797, acc=0.7322777509689331, loss=0.6110323071479797
test: epoch 74, loss 1.3973203897476196, acc=0.4555555582046509, loss=1.3973203897476196
train: epoch 75, loss 0.6248540282249451, acc=0.7275000214576721, loss=0.6248540282249451
test: epoch 75, loss 1.3912433385849, acc=0.4694444537162781, loss=1.3912433385849
train: epoch 76, loss 0.6121046543121338, acc=0.731333315372467, loss=0.6121046543121338
test: epoch 76, loss 1.4409390687942505, acc=0.46666666865348816, loss=1.4409390687942505
train: epoch 77, loss 0.6149418950080872, acc=0.7313888669013977, loss=0.6149418950080872
test: epoch 77, loss 1.4536798000335693, acc=0.4583333432674408, loss=1.4536798000335693
train: epoch 78, loss 0.6310293674468994, acc=0.7247222065925598, loss=0.6310293674468994
test: epoch 78, loss 1.5485613346099854, acc=0.4444444477558136, loss=1.5485613346099854
train: epoch 79, loss 0.612922728061676, acc=0.7333889007568359, loss=0.612922728061676
test: epoch 79, loss 1.3903782367706299, acc=0.46666666865348816, loss=1.3903782367706299
train: epoch 80, loss 0.6131232976913452, acc=0.7330555319786072, loss=0.6131232976913452
test: epoch 80, loss 1.3937361240386963, acc=0.4583333432674408, loss=1.3937361240386963
train: epoch 81, loss 0.6230244636535645, acc=0.7278888821601868, loss=0.6230244636535645
test: epoch 81, loss 1.3458874225616455, acc=0.4583333432674408, loss=1.3458874225616455
train: epoch 82, loss 0.6225281357765198, acc=0.7248333096504211, loss=0.6225281357765198
test: epoch 82, loss 1.3877596855163574, acc=0.46666666865348816, loss=1.3877596855163574
train: epoch 83, loss 0.6189454793930054, acc=0.7252222299575806, loss=0.6189454793930054
test: epoch 83, loss 1.29859459400177, acc=0.44999998807907104, loss=1.29859459400177
train: epoch 84, loss 0.6097277402877808, acc=0.7304999828338623, loss=0.6097277402877808
test: epoch 84, loss 1.523449420928955, acc=0.4583333432674408, loss=1.523449420928955
train: epoch 85, loss 0.6129900813102722, acc=0.7337222099304199, loss=0.6129900813102722
test: epoch 85, loss 1.413513422012329, acc=0.46388888359069824, loss=1.413513422012329
train: epoch 86, loss 0.5982099771499634, acc=0.7378333210945129, loss=0.5982099771499634
test: epoch 86, loss 1.3262443542480469, acc=0.46388888359069824, loss=1.3262443542480469
train: epoch 87, loss 0.6005271673202515, acc=0.7368333339691162, loss=0.6005271673202515
test: epoch 87, loss 1.4684696197509766, acc=0.46388888359069824, loss=1.4684696197509766
train: epoch 88, loss 0.6063193678855896, acc=0.7335555553436279, loss=0.6063193678855896
test: epoch 88, loss 1.5263477563858032, acc=0.4611110985279083, loss=1.5263477563858032
train: epoch 89, loss 0.6003292202949524, acc=0.7365555763244629, loss=0.6003292202949524
test: epoch 89, loss 1.4826449155807495, acc=0.46666666865348816, loss=1.4826449155807495
train: epoch 90, loss 0.6061077117919922, acc=0.7390555739402771, loss=0.6061077117919922
test: epoch 90, loss 1.4455770254135132, acc=0.46388888359069824, loss=1.4455770254135132
train: epoch 91, loss 0.607779324054718, acc=0.7360555529594421, loss=0.607779324054718
test: epoch 91, loss 1.3449856042861938, acc=0.46388888359069824, loss=1.3449856042861938
train: epoch 92, loss 0.6015416383743286, acc=0.7361111044883728, loss=0.6015416383743286
test: epoch 92, loss 1.3742961883544922, acc=0.4611110985279083, loss=1.3742961883544922
train: epoch 93, loss 0.597762405872345, acc=0.7371666431427002, loss=0.597762405872345
test: epoch 93, loss 1.3602975606918335, acc=0.46666666865348816, loss=1.3602975606918335
train: epoch 94, loss 0.6038612723350525, acc=0.7407777905464172, loss=0.6038612723350525
test: epoch 94, loss 1.4541555643081665, acc=0.46388888359069824, loss=1.4541555643081665
train: epoch 95, loss 0.6114171147346497, acc=0.731166660785675, loss=0.6114171147346497
test: epoch 95, loss 1.4510319232940674, acc=0.45277777314186096, loss=1.4510319232940674
train: epoch 96, loss 0.6042993068695068, acc=0.7350555658340454, loss=0.6042993068695068
test: epoch 96, loss 1.482619047164917, acc=0.4611110985279083, loss=1.482619047164917
train: epoch 97, loss 0.6016953587532043, acc=0.7358333468437195, loss=0.6016953587532043
test: epoch 97, loss 1.4316160678863525, acc=0.4611110985279083, loss=1.4316160678863525
train: epoch 98, loss 0.5959052443504333, acc=0.7379999756813049, loss=0.5959052443504333
test: epoch 98, loss 1.501051902770996, acc=0.4583333432674408, loss=1.501051902770996
train: epoch 99, loss 0.585813581943512, acc=0.7426111102104187, loss=0.585813581943512
test: epoch 99, loss 1.4810658693313599, acc=0.45277777314186096, loss=1.4810658693313599
train: epoch 100, loss 0.585885763168335, acc=0.7431666851043701, loss=0.585885763168335
test: epoch 100, loss 1.4209320545196533, acc=0.4583333432674408, loss=1.4209320545196533
train: epoch 101, loss 0.5882447957992554, acc=0.7435555458068848, loss=0.5882447957992554
test: epoch 101, loss 1.4404460191726685, acc=0.46666666865348816, loss=1.4404460191726685
train: epoch 102, loss 0.5964933633804321, acc=0.7336111068725586, loss=0.5964933633804321
test: epoch 102, loss 1.4310011863708496, acc=0.4694444537162781, loss=1.4310011863708496
train: epoch 103, loss 0.5847854614257812, acc=0.7455000281333923, loss=0.5847854614257812
test: epoch 103, loss 1.5812897682189941, acc=0.4555555582046509, loss=1.5812897682189941
train: epoch 104, loss 0.5804020166397095, acc=0.7434444427490234, loss=0.5804020166397095
test: epoch 104, loss 1.4980700016021729, acc=0.4611110985279083, loss=1.4980700016021729
train: epoch 105, loss 0.5874177813529968, acc=0.7387222051620483, loss=0.5874177813529968
test: epoch 105, loss 1.5239607095718384, acc=0.46388888359069824, loss=1.5239607095718384
train: epoch 106, loss 0.5868026614189148, acc=0.7420555353164673, loss=0.5868026614189148
test: epoch 106, loss 1.458064317703247, acc=0.46388888359069824, loss=1.458064317703247
train: epoch 107, loss 0.5745896100997925, acc=0.7492222189903259, loss=0.5745896100997925
test: epoch 107, loss 1.5212020874023438, acc=0.45277777314186096, loss=1.5212020874023438
train: epoch 108, loss 0.5726774334907532, acc=0.7473888993263245, loss=0.5726774334907532
test: epoch 108, loss 1.5342563390731812, acc=0.46666666865348816, loss=1.5342563390731812
train: epoch 109, loss 0.5749918818473816, acc=0.7486110925674438, loss=0.5749918818473816
test: epoch 109, loss 1.3808350563049316, acc=0.46388888359069824, loss=1.3808350563049316
train: epoch 110, loss 0.602137565612793, acc=0.7394999861717224, loss=0.602137565612793
test: epoch 110, loss 1.591971516609192, acc=0.4416666626930237, loss=1.591971516609192
train: epoch 111, loss 0.5818256139755249, acc=0.7437222003936768, loss=0.5818256139755249
test: epoch 111, loss 1.4494266510009766, acc=0.4694444537162781, loss=1.4494266510009766
train: epoch 112, loss 0.5985773205757141, acc=0.7356666922569275, loss=0.5985773205757141
test: epoch 112, loss 1.474658727645874, acc=0.4611110985279083, loss=1.474658727645874
train: epoch 113, loss 0.5815756916999817, acc=0.7419999837875366, loss=0.5815756916999817
test: epoch 113, loss 1.42827570438385, acc=0.44999998807907104, loss=1.42827570438385
train: epoch 114, loss 0.5597740411758423, acc=0.7538889050483704, loss=0.5597740411758423
test: epoch 114, loss 1.4154354333877563, acc=0.4722222089767456, loss=1.4154354333877563
train: epoch 115, loss 0.5727737545967102, acc=0.745888888835907, loss=0.5727737545967102
test: epoch 115, loss 1.4901760816574097, acc=0.4722222089767456, loss=1.4901760816574097
train: epoch 116, loss 0.573073148727417, acc=0.7483333349227905, loss=0.573073148727417
test: epoch 116, loss 1.5190476179122925, acc=0.4583333432674408, loss=1.5190476179122925
train: epoch 117, loss 0.5942016243934631, acc=0.7413889169692993, loss=0.5942016243934631
test: epoch 117, loss 1.518478274345398, acc=0.46388888359069824, loss=1.518478274345398
train: epoch 118, loss 0.5773181915283203, acc=0.7453333139419556, loss=0.5773181915283203
test: epoch 118, loss 1.5269114971160889, acc=0.46666666865348816, loss=1.5269114971160889
train: epoch 119, loss 0.580801248550415, acc=0.7450555562973022, loss=0.580801248550415
test: epoch 119, loss 1.4181389808654785, acc=0.4749999940395355, loss=1.4181389808654785
train: epoch 120, loss 0.5741650462150574, acc=0.7473888993263245, loss=0.5741650462150574
test: epoch 120, loss 1.2845268249511719, acc=0.4833333194255829, loss=1.2845268249511719
train: epoch 121, loss 0.5670924782752991, acc=0.7478333115577698, loss=0.5670924782752991
test: epoch 121, loss 1.4214614629745483, acc=0.4749999940395355, loss=1.4214614629745483
train: epoch 122, loss 0.5597561001777649, acc=0.753166675567627, loss=0.5597561001777649
test: epoch 122, loss 1.3860965967178345, acc=0.4861111044883728, loss=1.3860965967178345
train: epoch 123, loss 0.5707335472106934, acc=0.7507777810096741, loss=0.5707335472106934
test: epoch 123, loss 1.4160343408584595, acc=0.4555555582046509, loss=1.4160343408584595
train: epoch 124, loss 0.5573875308036804, acc=0.7548333406448364, loss=0.5573875308036804
test: epoch 124, loss 1.5029367208480835, acc=0.4749999940395355, loss=1.5029367208480835
train: epoch 125, loss 0.5654478669166565, acc=0.7522777915000916, loss=0.5654478669166565
test: epoch 125, loss 1.3047593832015991, acc=0.49166667461395264, loss=1.3047593832015991
train: epoch 126, loss 0.5773507356643677, acc=0.7438333630561829, loss=0.5773507356643677
test: epoch 126, loss 1.3957622051239014, acc=0.49444442987442017, loss=1.3957622051239014
train: epoch 127, loss 0.5668224096298218, acc=0.7502222061157227, loss=0.5668224096298218
test: epoch 127, loss 1.5212507247924805, acc=0.4972222149372101, loss=1.5212507247924805
train: epoch 128, loss 0.5638529062271118, acc=0.7485555410385132, loss=0.5638529062271118
test: epoch 128, loss 1.4107710123062134, acc=0.4972222149372101, loss=1.4107710123062134
train: epoch 129, loss 0.5523587465286255, acc=0.7553333044052124, loss=0.5523587465286255
test: epoch 129, loss 1.4818073511123657, acc=0.4972222149372101, loss=1.4818073511123657
train: epoch 130, loss 0.5615904927253723, acc=0.7512221932411194, loss=0.5615904927253723
test: epoch 130, loss 1.375643253326416, acc=0.4888888895511627, loss=1.375643253326416
train: epoch 131, loss 0.5687506794929504, acc=0.7488333582878113, loss=0.5687506794929504
test: epoch 131, loss 1.3829635381698608, acc=0.5, loss=1.3829635381698608
train: epoch 132, loss 0.5737171769142151, acc=0.7486666440963745, loss=0.5737171769142151
test: epoch 132, loss 1.4047458171844482, acc=0.5, loss=1.4047458171844482
train: epoch 133, loss 0.5480126738548279, acc=0.7569444179534912, loss=0.5480126738548279
test: epoch 133, loss 1.5732239484786987, acc=0.5027777552604675, loss=1.5732239484786987
train: epoch 134, loss 0.5658521056175232, acc=0.7481666803359985, loss=0.5658521056175232
test: epoch 134, loss 1.453204870223999, acc=0.4861111044883728, loss=1.453204870223999
train: epoch 135, loss 0.564572811126709, acc=0.7512778043746948, loss=0.564572811126709
test: epoch 135, loss 1.3714734315872192, acc=0.4888888895511627, loss=1.3714734315872192
train: epoch 136, loss 0.5568780303001404, acc=0.7532777786254883, loss=0.5568780303001404
test: epoch 136, loss 1.5315598249435425, acc=0.4861111044883728, loss=1.5315598249435425
train: epoch 137, loss 0.5457317233085632, acc=0.7582777738571167, loss=0.5457317233085632
test: epoch 137, loss 1.3574596643447876, acc=0.5027777552604675, loss=1.3574596643447876
train: epoch 138, loss 0.5503392219543457, acc=0.7561666369438171, loss=0.5503392219543457
test: epoch 138, loss 1.44199800491333, acc=0.4972222149372101, loss=1.44199800491333
train: epoch 139, loss 0.5394055247306824, acc=0.7607222199440002, loss=0.5394055247306824
test: epoch 139, loss 1.3245681524276733, acc=0.5027777552604675, loss=1.3245681524276733
train: epoch 140, loss 0.5534052848815918, acc=0.7574999928474426, loss=0.5534052848815918
test: epoch 140, loss 1.473508596420288, acc=0.4861111044883728, loss=1.473508596420288
train: epoch 141, loss 0.5527424216270447, acc=0.7556111216545105, loss=0.5527424216270447
test: epoch 141, loss 1.5058826208114624, acc=0.4972222149372101, loss=1.5058826208114624
train: epoch 142, loss 0.5671586394309998, acc=0.7497222423553467, loss=0.5671586394309998
test: epoch 142, loss 1.283431887626648, acc=0.4972222149372101, loss=1.283431887626648
train: epoch 143, loss 0.5499044060707092, acc=0.7588333487510681, loss=0.5499044060707092
test: epoch 143, loss 1.4060757160186768, acc=0.5027777552604675, loss=1.4060757160186768
train: epoch 144, loss 0.5465578436851501, acc=0.7563333511352539, loss=0.5465578436851501
test: epoch 144, loss 1.3519082069396973, acc=0.5027777552604675, loss=1.3519082069396973
train: epoch 145, loss 0.5478167533874512, acc=0.7574999928474426, loss=0.5478167533874512
test: epoch 145, loss 1.3124574422836304, acc=0.49166667461395264, loss=1.3124574422836304
train: epoch 146, loss 0.5548445582389832, acc=0.7546666860580444, loss=0.5548445582389832
test: epoch 146, loss 1.4429829120635986, acc=0.4972222149372101, loss=1.4429829120635986
train: epoch 147, loss 0.549857497215271, acc=0.7527222037315369, loss=0.549857497215271
test: epoch 147, loss 1.4463274478912354, acc=0.5, loss=1.4463274478912354
train: epoch 148, loss 0.5422350168228149, acc=0.7604444622993469, loss=0.5422350168228149
test: epoch 148, loss 1.3618996143341064, acc=0.5027777552604675, loss=1.3618996143341064
train: epoch 149, loss 0.5327861309051514, acc=0.7639999985694885, loss=0.5327861309051514
test: epoch 149, loss 1.2650222778320312, acc=0.5333333611488342, loss=1.2650222778320312
train: epoch 150, loss 0.5367910861968994, acc=0.7642777562141418, loss=0.5367910861968994
test: epoch 150, loss 1.3357768058776855, acc=0.5388888716697693, loss=1.3357768058776855
