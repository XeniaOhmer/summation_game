# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=true", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=288489024, receiver_embed_dim=32, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.062688112258911, acc=0.07855555415153503, loss=3.062688112258911
test: epoch 1, loss 3.12878155708313, acc=0.10000000149011612, loss=3.12878155708313
train: epoch 2, loss 2.024418592453003, acc=0.21377778053283691, loss=2.024418592453003
test: epoch 2, loss 3.124504327774048, acc=0.1388888955116272, loss=3.124504327774048
train: epoch 3, loss 1.7313942909240723, acc=0.2915555536746979, loss=1.7313942909240723
test: epoch 3, loss 3.1777403354644775, acc=0.14444445073604584, loss=3.1777403354644775
train: epoch 4, loss 1.49154794216156, acc=0.3762222230434418, loss=1.49154794216156
test: epoch 4, loss 2.859243392944336, acc=0.14722222089767456, loss=2.859243392944336
train: epoch 5, loss 1.232732892036438, acc=0.4812777638435364, loss=1.232732892036438
test: epoch 5, loss 2.6423099040985107, acc=0.21388888359069824, loss=2.6423099040985107
train: epoch 6, loss 1.055194616317749, acc=0.5558333396911621, loss=1.055194616317749
test: epoch 6, loss 2.6978747844696045, acc=0.22499999403953552, loss=2.6978747844696045
train: epoch 7, loss 0.9279149174690247, acc=0.6157777905464172, loss=0.9279149174690247
test: epoch 7, loss 2.5116140842437744, acc=0.24722221493721008, loss=2.5116140842437744
train: epoch 8, loss 0.8251234889030457, acc=0.6675000190734863, loss=0.8251234889030457
test: epoch 8, loss 2.5201339721679688, acc=0.21111111342906952, loss=2.5201339721679688
train: epoch 9, loss 0.7830694913864136, acc=0.6773889064788818, loss=0.7830694913864136
test: epoch 9, loss 2.5981204509735107, acc=0.24722221493721008, loss=2.5981204509735107
train: epoch 10, loss 0.7250715494155884, acc=0.7066666483879089, loss=0.7250715494155884
test: epoch 10, loss 2.2058539390563965, acc=0.2888889014720917, loss=2.2058539390563965
train: epoch 11, loss 0.6793329119682312, acc=0.7301111221313477, loss=0.6793329119682312
test: epoch 11, loss 2.176053285598755, acc=0.28333333134651184, loss=2.176053285598755
train: epoch 12, loss 0.6482835412025452, acc=0.7364444732666016, loss=0.6482835412025452
test: epoch 12, loss 2.506978988647461, acc=0.31111112236976624, loss=2.506978988647461
train: epoch 13, loss 0.6227876543998718, acc=0.7486110925674438, loss=0.6227876543998718
test: epoch 13, loss 2.1594817638397217, acc=0.25833332538604736, loss=2.1594817638397217
train: epoch 14, loss 0.5923914909362793, acc=0.7650555372238159, loss=0.5923914909362793
test: epoch 14, loss 1.9493558406829834, acc=0.32499998807907104, loss=1.9493558406829834
train: epoch 15, loss 0.5925279855728149, acc=0.7605555653572083, loss=0.5925279855728149
test: epoch 15, loss 1.9194414615631104, acc=0.36666667461395264, loss=1.9194414615631104
train: epoch 16, loss 0.5326317548751831, acc=0.7806666493415833, loss=0.5326317548751831
test: epoch 16, loss 1.9189101457595825, acc=0.33888888359069824, loss=1.9189101457595825
train: epoch 17, loss 0.5263979434967041, acc=0.7839444279670715, loss=0.5263979434967041
test: epoch 17, loss 1.8642293214797974, acc=0.33888888359069824, loss=1.8642293214797974
train: epoch 18, loss 0.5216909646987915, acc=0.7907778024673462, loss=0.5216909646987915
test: epoch 18, loss 1.825074315071106, acc=0.4000000059604645, loss=1.825074315071106
train: epoch 19, loss 0.49237626791000366, acc=0.7972221970558167, loss=0.49237626791000366
test: epoch 19, loss 1.5959076881408691, acc=0.41111111640930176, loss=1.5959076881408691
train: epoch 20, loss 0.48945555090904236, acc=0.800000011920929, loss=0.48945555090904236
test: epoch 20, loss 1.7469717264175415, acc=0.3722222149372101, loss=1.7469717264175415
train: epoch 21, loss 0.47627386450767517, acc=0.8028888702392578, loss=0.47627386450767517
test: epoch 21, loss 1.8985623121261597, acc=0.40833333134651184, loss=1.8985623121261597
train: epoch 22, loss 0.4605266749858856, acc=0.8132777810096741, loss=0.4605266749858856
test: epoch 22, loss 1.6627076864242554, acc=0.38333332538604736, loss=1.6627076864242554
train: epoch 23, loss 0.4630882740020752, acc=0.808555543422699, loss=0.4630882740020752
test: epoch 23, loss 1.9662554264068604, acc=0.38055557012557983, loss=1.9662554264068604
train: epoch 24, loss 0.4420919418334961, acc=0.8183888792991638, loss=0.4420919418334961
test: epoch 24, loss 1.9106553792953491, acc=0.3638888895511627, loss=1.9106553792953491
train: epoch 25, loss 0.43845587968826294, acc=0.816944420337677, loss=0.43845587968826294
test: epoch 25, loss 1.7372586727142334, acc=0.39444443583488464, loss=1.7372586727142334
train: epoch 26, loss 0.431299090385437, acc=0.8174444437026978, loss=0.431299090385437
test: epoch 26, loss 1.8606605529785156, acc=0.3222222328186035, loss=1.8606605529785156
train: epoch 27, loss 0.42513808608055115, acc=0.823888897895813, loss=0.42513808608055115
test: epoch 27, loss 1.7979838848114014, acc=0.4055555462837219, loss=1.7979838848114014
train: epoch 28, loss 0.4219337999820709, acc=0.8255555629730225, loss=0.4219337999820709
test: epoch 28, loss 1.4027055501937866, acc=0.43888887763023376, loss=1.4027055501937866
train: epoch 29, loss 0.4023973047733307, acc=0.8286666870117188, loss=0.4023973047733307
test: epoch 29, loss 1.5202763080596924, acc=0.4055555462837219, loss=1.5202763080596924
train: epoch 30, loss 0.3893911838531494, acc=0.8392221927642822, loss=0.3893911838531494
test: epoch 30, loss 1.6686042547225952, acc=0.4055555462837219, loss=1.6686042547225952
train: epoch 31, loss 0.4009297788143158, acc=0.8343333601951599, loss=0.4009297788143158
test: epoch 31, loss 1.8439935445785522, acc=0.4305555522441864, loss=1.8439935445785522
train: epoch 32, loss 0.39935576915740967, acc=0.8328889012336731, loss=0.39935576915740967
test: epoch 32, loss 1.5420831441879272, acc=0.44999998807907104, loss=1.5420831441879272
train: epoch 33, loss 0.3921482563018799, acc=0.8369444608688354, loss=0.3921482563018799
test: epoch 33, loss 1.5492796897888184, acc=0.4194444417953491, loss=1.5492796897888184
train: epoch 34, loss 0.3862399756908417, acc=0.8395000100135803, loss=0.3862399756908417
test: epoch 34, loss 1.6210049390792847, acc=0.4416666626930237, loss=1.6210049390792847
train: epoch 35, loss 0.38505837321281433, acc=0.8396111130714417, loss=0.38505837321281433
test: epoch 35, loss 1.6711995601654053, acc=0.4138889014720917, loss=1.6711995601654053
train: epoch 36, loss 0.37388190627098083, acc=0.8407777547836304, loss=0.37388190627098083
test: epoch 36, loss 1.4361138343811035, acc=0.4444444477558136, loss=1.4361138343811035
train: epoch 37, loss 0.36653780937194824, acc=0.8451666831970215, loss=0.36653780937194824
test: epoch 37, loss 1.8637114763259888, acc=0.4416666626930237, loss=1.8637114763259888
train: epoch 38, loss 0.3664543330669403, acc=0.8467222452163696, loss=0.3664543330669403
test: epoch 38, loss 1.6100016832351685, acc=0.43611112236976624, loss=1.6100016832351685
train: epoch 39, loss 0.34619730710983276, acc=0.8526666760444641, loss=0.34619730710983276
test: epoch 39, loss 1.7066460847854614, acc=0.5111111402511597, loss=1.7066460847854614
train: epoch 40, loss 0.3618769943714142, acc=0.848111093044281, loss=0.3618769943714142
test: epoch 40, loss 1.855346441268921, acc=0.3722222149372101, loss=1.855346441268921
train: epoch 41, loss 0.3548809885978699, acc=0.8514999747276306, loss=0.3548809885978699
test: epoch 41, loss 1.8254218101501465, acc=0.4194444417953491, loss=1.8254218101501465
train: epoch 42, loss 0.3445616066455841, acc=0.8601111173629761, loss=0.3445616066455841
test: epoch 42, loss 1.624924898147583, acc=0.5249999761581421, loss=1.624924898147583
train: epoch 43, loss 0.3407253324985504, acc=0.8597221970558167, loss=0.3407253324985504
test: epoch 43, loss 1.31071937084198, acc=0.5166666507720947, loss=1.31071937084198
train: epoch 44, loss 0.3316437005996704, acc=0.8613888621330261, loss=0.3316437005996704
test: epoch 44, loss 1.5752519369125366, acc=0.49166667461395264, loss=1.5752519369125366
train: epoch 45, loss 0.3319092094898224, acc=0.8622221946716309, loss=0.3319092094898224
test: epoch 45, loss 1.4385915994644165, acc=0.5055555701255798, loss=1.4385915994644165
train: epoch 46, loss 0.3384952247142792, acc=0.8585000038146973, loss=0.3384952247142792
test: epoch 46, loss 1.3958791494369507, acc=0.5166666507720947, loss=1.3958791494369507
train: epoch 47, loss 0.3260253369808197, acc=0.8608333468437195, loss=0.3260253369808197
test: epoch 47, loss 1.5368744134902954, acc=0.5527777671813965, loss=1.5368744134902954
train: epoch 48, loss 0.31247180700302124, acc=0.8700555562973022, loss=0.31247180700302124
test: epoch 48, loss 1.4862031936645508, acc=0.49444442987442017, loss=1.4862031936645508
train: epoch 49, loss 0.32771679759025574, acc=0.8642222285270691, loss=0.32771679759025574
test: epoch 49, loss 1.4265910387039185, acc=0.5249999761581421, loss=1.4265910387039185
train: epoch 50, loss 0.3146319091320038, acc=0.866777777671814, loss=0.3146319091320038
test: epoch 50, loss 1.4933900833129883, acc=0.4861111044883728, loss=1.4933900833129883
train: epoch 51, loss 0.31103748083114624, acc=0.8715555667877197, loss=0.31103748083114624
test: epoch 51, loss 1.4972337484359741, acc=0.519444465637207, loss=1.4972337484359741
train: epoch 52, loss 0.3274989724159241, acc=0.8644999861717224, loss=0.3274989724159241
test: epoch 52, loss 1.3852750062942505, acc=0.5083333253860474, loss=1.3852750062942505
train: epoch 53, loss 0.30672839283943176, acc=0.8711110949516296, loss=0.30672839283943176
test: epoch 53, loss 1.5094150304794312, acc=0.4972222149372101, loss=1.5094150304794312
train: epoch 54, loss 0.3119228184223175, acc=0.867888867855072, loss=0.3119228184223175
test: epoch 54, loss 1.2291268110275269, acc=0.5472221970558167, loss=1.2291268110275269
train: epoch 55, loss 0.3135947585105896, acc=0.8724444508552551, loss=0.3135947585105896
test: epoch 55, loss 1.4913876056671143, acc=0.4694444537162781, loss=1.4913876056671143
train: epoch 56, loss 0.30724573135375977, acc=0.8737778067588806, loss=0.30724573135375977
test: epoch 56, loss 1.4094542264938354, acc=0.49166667461395264, loss=1.4094542264938354
train: epoch 57, loss 0.3077510595321655, acc=0.870555579662323, loss=0.3077510595321655
test: epoch 57, loss 1.238569736480713, acc=0.5138888955116272, loss=1.238569736480713
train: epoch 58, loss 0.2962273061275482, acc=0.8772222399711609, loss=0.2962273061275482
test: epoch 58, loss 1.2088772058486938, acc=0.49444442987442017, loss=1.2088772058486938
train: epoch 59, loss 0.3099772036075592, acc=0.8701111078262329, loss=0.3099772036075592
test: epoch 59, loss 1.516571283340454, acc=0.4722222089767456, loss=1.516571283340454
train: epoch 60, loss 0.30806177854537964, acc=0.8721110820770264, loss=0.30806177854537964
test: epoch 60, loss 1.3604941368103027, acc=0.5361111164093018, loss=1.3604941368103027
train: epoch 61, loss 0.2779819369316101, acc=0.8842222094535828, loss=0.2779819369316101
test: epoch 61, loss 1.335044264793396, acc=0.5222222208976746, loss=1.335044264793396
train: epoch 62, loss 0.30367013812065125, acc=0.875166654586792, loss=0.30367013812065125
test: epoch 62, loss 1.4408499002456665, acc=0.43611112236976624, loss=1.4408499002456665
train: epoch 63, loss 0.29663312435150146, acc=0.875166654586792, loss=0.29663312435150146
test: epoch 63, loss 1.3211227655410767, acc=0.5611110925674438, loss=1.3211227655410767
train: epoch 64, loss 0.2971441149711609, acc=0.8759999871253967, loss=0.2971441149711609
test: epoch 64, loss 1.2750343084335327, acc=0.5333333611488342, loss=1.2750343084335327
train: epoch 65, loss 0.3008861839771271, acc=0.8759999871253967, loss=0.3008861839771271
test: epoch 65, loss 1.6574604511260986, acc=0.42500001192092896, loss=1.6574604511260986
train: epoch 66, loss 0.2964666485786438, acc=0.8782222270965576, loss=0.2964666485786438
test: epoch 66, loss 1.4224752187728882, acc=0.5722222328186035, loss=1.4224752187728882
train: epoch 67, loss 0.27951279282569885, acc=0.8826666474342346, loss=0.27951279282569885
test: epoch 67, loss 1.1807761192321777, acc=0.5111111402511597, loss=1.1807761192321777
train: epoch 68, loss 0.2901495397090912, acc=0.8780555725097656, loss=0.2901495397090912
test: epoch 68, loss 1.2555131912231445, acc=0.5055555701255798, loss=1.2555131912231445
train: epoch 69, loss 0.287905752658844, acc=0.8790555596351624, loss=0.287905752658844
test: epoch 69, loss 1.431022047996521, acc=0.5333333611488342, loss=1.431022047996521
train: epoch 70, loss 0.2896227538585663, acc=0.8783888816833496, loss=0.2896227538585663
test: epoch 70, loss 1.3476150035858154, acc=0.519444465637207, loss=1.3476150035858154
train: epoch 71, loss 0.2873838245868683, acc=0.8803889155387878, loss=0.2873838245868683
test: epoch 71, loss 1.4037412405014038, acc=0.5055555701255798, loss=1.4037412405014038
train: epoch 72, loss 0.2902282476425171, acc=0.8806111216545105, loss=0.2902282476425171
test: epoch 72, loss 1.4196245670318604, acc=0.574999988079071, loss=1.4196245670318604
train: epoch 73, loss 0.2777138948440552, acc=0.8821666836738586, loss=0.2777138948440552
test: epoch 73, loss 1.4527406692504883, acc=0.5, loss=1.4527406692504883
train: epoch 74, loss 0.28250932693481445, acc=0.878333330154419, loss=0.28250932693481445
test: epoch 74, loss 1.2372218370437622, acc=0.4972222149372101, loss=1.2372218370437622
train: epoch 75, loss 0.28006765246391296, acc=0.8819444179534912, loss=0.28006765246391296
test: epoch 75, loss 1.3204550743103027, acc=0.5416666865348816, loss=1.3204550743103027
train: epoch 76, loss 0.3038925528526306, acc=0.8741666674613953, loss=0.3038925528526306
test: epoch 76, loss 1.513240098953247, acc=0.5, loss=1.513240098953247
train: epoch 77, loss 0.2804512679576874, acc=0.8818333148956299, loss=0.2804512679576874
test: epoch 77, loss 1.1619311571121216, acc=0.5277777910232544, loss=1.1619311571121216
train: epoch 78, loss 0.2882959544658661, acc=0.8787222504615784, loss=0.2882959544658661
test: epoch 78, loss 1.2325187921524048, acc=0.519444465637207, loss=1.2325187921524048
train: epoch 79, loss 0.2815439999103546, acc=0.8818888664245605, loss=0.2815439999103546
test: epoch 79, loss 1.1981565952301025, acc=0.5638889074325562, loss=1.1981565952301025
train: epoch 80, loss 0.28325656056404114, acc=0.8803333044052124, loss=0.28325656056404114
test: epoch 80, loss 1.3134753704071045, acc=0.5472221970558167, loss=1.3134753704071045
train: epoch 81, loss 0.2966516315937042, acc=0.8762221932411194, loss=0.2966516315937042
test: epoch 81, loss 1.2793715000152588, acc=0.5333333611488342, loss=1.2793715000152588
train: epoch 82, loss 0.28065457940101624, acc=0.8832777738571167, loss=0.28065457940101624
test: epoch 82, loss 1.2142397165298462, acc=0.5333333611488342, loss=1.2142397165298462
train: epoch 83, loss 0.3005686402320862, acc=0.8731666803359985, loss=0.3005686402320862
test: epoch 83, loss 1.1889501810073853, acc=0.5861111283302307, loss=1.1889501810073853
train: epoch 84, loss 0.2781219184398651, acc=0.8815000057220459, loss=0.2781219184398651
test: epoch 84, loss 1.0865263938903809, acc=0.5833333134651184, loss=1.0865263938903809
train: epoch 85, loss 0.27743154764175415, acc=0.8825555443763733, loss=0.27743154764175415
test: epoch 85, loss 1.1321979761123657, acc=0.5027777552604675, loss=1.1321979761123657
train: epoch 86, loss 0.2780381739139557, acc=0.8817777633666992, loss=0.2780381739139557
test: epoch 86, loss 0.9069596529006958, acc=0.5833333134651184, loss=0.9069596529006958
train: epoch 87, loss 0.2784753739833832, acc=0.8807222247123718, loss=0.2784753739833832
test: epoch 87, loss 0.897463321685791, acc=0.6027777791023254, loss=0.897463321685791
train: epoch 88, loss 0.2780790627002716, acc=0.8831111192703247, loss=0.2780790627002716
test: epoch 88, loss 1.0950300693511963, acc=0.574999988079071, loss=1.0950300693511963
train: epoch 89, loss 0.2647865116596222, acc=0.887499988079071, loss=0.2647865116596222
test: epoch 89, loss 1.151233196258545, acc=0.5916666388511658, loss=1.151233196258545
train: epoch 90, loss 0.27158576250076294, acc=0.8847777843475342, loss=0.27158576250076294
test: epoch 90, loss 0.9368040561676025, acc=0.5916666388511658, loss=0.9368040561676025
train: epoch 91, loss 0.27579906582832336, acc=0.88355553150177, loss=0.27579906582832336
test: epoch 91, loss 1.1366450786590576, acc=0.6166666746139526, loss=1.1366450786590576
train: epoch 92, loss 0.2814720571041107, acc=0.8811110854148865, loss=0.2814720571041107
test: epoch 92, loss 1.4146617650985718, acc=0.5527777671813965, loss=1.4146617650985718
train: epoch 93, loss 0.26426586508750916, acc=0.8878889083862305, loss=0.26426586508750916
test: epoch 93, loss 0.9068869948387146, acc=0.625, loss=0.9068869948387146
train: epoch 94, loss 0.26516255736351013, acc=0.886555552482605, loss=0.26516255736351013
test: epoch 94, loss 1.1005507707595825, acc=0.5944444537162781, loss=1.1005507707595825
train: epoch 95, loss 0.2646405100822449, acc=0.8870555758476257, loss=0.2646405100822449
test: epoch 95, loss 1.277126669883728, acc=0.6083333492279053, loss=1.277126669883728
train: epoch 96, loss 0.26653116941452026, acc=0.8871111273765564, loss=0.26653116941452026
test: epoch 96, loss 1.1532859802246094, acc=0.6222222447395325, loss=1.1532859802246094
train: epoch 97, loss 0.2733035385608673, acc=0.8853889107704163, loss=0.2733035385608673
test: epoch 97, loss 1.1926779747009277, acc=0.5722222328186035, loss=1.1926779747009277
train: epoch 98, loss 0.2625632584095001, acc=0.8902778029441833, loss=0.2625632584095001
test: epoch 98, loss 0.9343249201774597, acc=0.6361111402511597, loss=0.9343249201774597
train: epoch 99, loss 0.2715330123901367, acc=0.8877778053283691, loss=0.2715330123901367
test: epoch 99, loss 1.2691776752471924, acc=0.6000000238418579, loss=1.2691776752471924
train: epoch 100, loss 0.2750699818134308, acc=0.8867777585983276, loss=0.2750699818134308
test: epoch 100, loss 0.9680594801902771, acc=0.6499999761581421, loss=0.9680594801902771
train: epoch 101, loss 0.2691050171852112, acc=0.8856666684150696, loss=0.2691050171852112
test: epoch 101, loss 1.2375712394714355, acc=0.5972222089767456, loss=1.2375712394714355
train: epoch 102, loss 0.26576581597328186, acc=0.8889444470405579, loss=0.26576581597328186
test: epoch 102, loss 0.9077461361885071, acc=0.6916666626930237, loss=0.9077461361885071
train: epoch 103, loss 0.25946590304374695, acc=0.8886111378669739, loss=0.25946590304374695
test: epoch 103, loss 0.9140231609344482, acc=0.675000011920929, loss=0.9140231609344482
train: epoch 104, loss 0.26359283924102783, acc=0.8922777771949768, loss=0.26359283924102783
test: epoch 104, loss 0.9087901711463928, acc=0.699999988079071, loss=0.9087901711463928
train: epoch 105, loss 0.26132234930992126, acc=0.8877221941947937, loss=0.26132234930992126
test: epoch 105, loss 0.9419155716896057, acc=0.6000000238418579, loss=0.9419155716896057
train: epoch 106, loss 0.2638450562953949, acc=0.8891111016273499, loss=0.2638450562953949
test: epoch 106, loss 0.8606787919998169, acc=0.7083333134651184, loss=0.8606787919998169
train: epoch 107, loss 0.26003962755203247, acc=0.890666663646698, loss=0.26003962755203247
test: epoch 107, loss 0.8338622450828552, acc=0.6666666865348816, loss=0.8338622450828552
train: epoch 108, loss 0.26188862323760986, acc=0.8905555605888367, loss=0.26188862323760986
test: epoch 108, loss 0.9980137348175049, acc=0.6694444417953491, loss=0.9980137348175049
train: epoch 109, loss 0.28207606077194214, acc=0.8825555443763733, loss=0.28207606077194214
test: epoch 109, loss 0.8504186272621155, acc=0.6833333373069763, loss=0.8504186272621155
train: epoch 110, loss 0.26167431473731995, acc=0.8892777562141418, loss=0.26167431473731995
test: epoch 110, loss 1.0033398866653442, acc=0.6527777910232544, loss=1.0033398866653442
train: epoch 111, loss 0.25724929571151733, acc=0.8915555477142334, loss=0.25724929571151733
test: epoch 111, loss 0.9952130913734436, acc=0.7027778029441833, loss=0.9952130913734436
train: epoch 112, loss 0.264395534992218, acc=0.8895000219345093, loss=0.264395534992218
test: epoch 112, loss 0.7936479449272156, acc=0.699999988079071, loss=0.7936479449272156
train: epoch 113, loss 0.2538052201271057, acc=0.8923888802528381, loss=0.2538052201271057
test: epoch 113, loss 1.0284512042999268, acc=0.6305555701255798, loss=1.0284512042999268
train: epoch 114, loss 0.2584252655506134, acc=0.890500009059906, loss=0.2584252655506134
test: epoch 114, loss 0.7050809860229492, acc=0.75, loss=0.7050809860229492
train: epoch 115, loss 0.25696831941604614, acc=0.8929444551467896, loss=0.25696831941604614
test: epoch 115, loss 0.9221462607383728, acc=0.7250000238418579, loss=0.9221462607383728
train: epoch 116, loss 0.2730282247066498, acc=0.8871666789054871, loss=0.2730282247066498
test: epoch 116, loss 0.8317728638648987, acc=0.7250000238418579, loss=0.8317728638648987
train: epoch 117, loss 0.2607395648956299, acc=0.8896111249923706, loss=0.2607395648956299
test: epoch 117, loss 0.9140104651451111, acc=0.7111111283302307, loss=0.9140104651451111
train: epoch 118, loss 0.2546805143356323, acc=0.8927222490310669, loss=0.2546805143356323
test: epoch 118, loss 0.8508755564689636, acc=0.730555534362793, loss=0.8508755564689636
train: epoch 119, loss 0.2575397193431854, acc=0.8953889012336731, loss=0.2575397193431854
test: epoch 119, loss 0.7868961691856384, acc=0.730555534362793, loss=0.7868961691856384
train: epoch 120, loss 0.2654159963130951, acc=0.8906111121177673, loss=0.2654159963130951
test: epoch 120, loss 0.7842031121253967, acc=0.7555555701255798, loss=0.7842031121253967
train: epoch 121, loss 0.26005247235298157, acc=0.890333354473114, loss=0.26005247235298157
test: epoch 121, loss 0.8259682655334473, acc=0.7222222089767456, loss=0.8259682655334473
train: epoch 122, loss 0.24584950506687164, acc=0.8937777876853943, loss=0.24584950506687164
test: epoch 122, loss 0.8698174357414246, acc=0.7388888597488403, loss=0.8698174357414246
train: epoch 123, loss 0.2621658146381378, acc=0.8898888826370239, loss=0.2621658146381378
test: epoch 123, loss 0.7025961875915527, acc=0.7722222208976746, loss=0.7025961875915527
train: epoch 124, loss 0.262553870677948, acc=0.8885555267333984, loss=0.262553870677948
test: epoch 124, loss 0.5269339680671692, acc=0.7749999761581421, loss=0.5269339680671692
train: epoch 125, loss 0.26401346921920776, acc=0.8890555500984192, loss=0.26401346921920776
test: epoch 125, loss 0.7965944409370422, acc=0.75, loss=0.7965944409370422
train: epoch 126, loss 0.2593861520290375, acc=0.8902778029441833, loss=0.2593861520290375
test: epoch 126, loss 0.8329117894172668, acc=0.7527777552604675, loss=0.8329117894172668
train: epoch 127, loss 0.247769296169281, acc=0.8968889117240906, loss=0.247769296169281
test: epoch 127, loss 0.8287868499755859, acc=0.7472222447395325, loss=0.8287868499755859
train: epoch 128, loss 0.2665090262889862, acc=0.8899444341659546, loss=0.2665090262889862
test: epoch 128, loss 0.6209225058555603, acc=0.7777777910232544, loss=0.6209225058555603
train: epoch 129, loss 0.2524312138557434, acc=0.8934444189071655, loss=0.2524312138557434
test: epoch 129, loss 0.7851384878158569, acc=0.7277777791023254, loss=0.7851384878158569
train: epoch 130, loss 0.2586151957511902, acc=0.8911111354827881, loss=0.2586151957511902
test: epoch 130, loss 0.5836731195449829, acc=0.7833333611488342, loss=0.5836731195449829
train: epoch 131, loss 0.2552749216556549, acc=0.8908888697624207, loss=0.2552749216556549
test: epoch 131, loss 0.6677795648574829, acc=0.7805555462837219, loss=0.6677795648574829
train: epoch 132, loss 0.2529175579547882, acc=0.8927778005599976, loss=0.2529175579547882
test: epoch 132, loss 0.6346967220306396, acc=0.7805555462837219, loss=0.6346967220306396
train: epoch 133, loss 0.24952666461467743, acc=0.8912777900695801, loss=0.24952666461467743
test: epoch 133, loss 0.636721670627594, acc=0.7833333611488342, loss=0.636721670627594
train: epoch 134, loss 0.26732805371284485, acc=0.8846666812896729, loss=0.26732805371284485
test: epoch 134, loss 0.5027043223381042, acc=0.7777777910232544, loss=0.5027043223381042
train: epoch 135, loss 0.24674150347709656, acc=0.8933888673782349, loss=0.24674150347709656
test: epoch 135, loss 0.48717156052589417, acc=0.7805555462837219, loss=0.48717156052589417
train: epoch 136, loss 0.25097528100013733, acc=0.8923333287239075, loss=0.25097528100013733
test: epoch 136, loss 0.6395483613014221, acc=0.7861111164093018, loss=0.6395483613014221
train: epoch 137, loss 0.2455167919397354, acc=0.8934999704360962, loss=0.2455167919397354
test: epoch 137, loss 0.5822353363037109, acc=0.7805555462837219, loss=0.5822353363037109
train: epoch 138, loss 0.23811839520931244, acc=0.8970000147819519, loss=0.23811839520931244
test: epoch 138, loss 0.751899003982544, acc=0.7444444298744202, loss=0.751899003982544
train: epoch 139, loss 0.26672038435935974, acc=0.8905555605888367, loss=0.26672038435935974
test: epoch 139, loss 0.528215765953064, acc=0.7833333611488342, loss=0.528215765953064
train: epoch 140, loss 0.2516322731971741, acc=0.8932222127914429, loss=0.2516322731971741
test: epoch 140, loss 0.5851802825927734, acc=0.8138889074325562, loss=0.5851802825927734
train: epoch 141, loss 0.23357604444026947, acc=0.8997777700424194, loss=0.23357604444026947
test: epoch 141, loss 0.5906213521957397, acc=0.8194444179534912, loss=0.5906213521957397
train: epoch 142, loss 0.25329622626304626, acc=0.8913333415985107, loss=0.25329622626304626
test: epoch 142, loss 0.5031976699829102, acc=0.8055555820465088, loss=0.5031976699829102
train: epoch 143, loss 0.24054448306560516, acc=0.894777774810791, loss=0.24054448306560516
test: epoch 143, loss 0.5947248935699463, acc=0.8138889074325562, loss=0.5947248935699463
train: epoch 144, loss 0.2322445511817932, acc=0.8981666564941406, loss=0.2322445511817932
test: epoch 144, loss 0.5095497369766235, acc=0.8166666626930237, loss=0.5095497369766235
train: epoch 145, loss 0.23402999341487885, acc=0.8993333578109741, loss=0.23402999341487885
test: epoch 145, loss 0.5006720423698425, acc=0.8305555582046509, loss=0.5006720423698425
train: epoch 146, loss 0.23656462132930756, acc=0.8995000123977661, loss=0.23656462132930756
test: epoch 146, loss 0.43745872378349304, acc=0.8222222328186035, loss=0.43745872378349304
train: epoch 147, loss 0.236037939786911, acc=0.8970000147819519, loss=0.236037939786911
test: epoch 147, loss 0.47926971316337585, acc=0.8083333373069763, loss=0.47926971316337585
train: epoch 148, loss 0.23379413783550262, acc=0.898888885974884, loss=0.23379413783550262
test: epoch 148, loss 0.5392979979515076, acc=0.800000011920929, loss=0.5392979979515076
train: epoch 149, loss 0.24221546947956085, acc=0.8927778005599976, loss=0.24221546947956085
test: epoch 149, loss 0.5846270322799683, acc=0.824999988079071, loss=0.5846270322799683
train: epoch 150, loss 0.22987398505210876, acc=0.8963333368301392, loss=0.22987398505210876
test: epoch 150, loss 0.4953327178955078, acc=0.8222222328186035, loss=0.4953327178955078
