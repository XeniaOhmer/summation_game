# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=false", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1764767724, receiver_embed_dim=32, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.3860106468200684, acc=0.052444443106651306, loss=3.3860106468200684
test: epoch 1, loss 3.781572103500366, acc=0.06666667014360428, loss=3.781572103500366
train: epoch 2, loss 2.400639533996582, acc=0.21977777779102325, loss=2.400639533996582
test: epoch 2, loss 3.4659640789031982, acc=0.11666666716337204, loss=3.4659640789031982
train: epoch 3, loss 1.5818889141082764, acc=0.3917222321033478, loss=1.5818889141082764
test: epoch 3, loss 3.3192315101623535, acc=0.13333334028720856, loss=3.3192315101623535
train: epoch 4, loss 1.3236339092254639, acc=0.47922220826148987, loss=1.3236339092254639
test: epoch 4, loss 3.3115668296813965, acc=0.15000000596046448, loss=3.3115668296813965
train: epoch 5, loss 1.1743370294570923, acc=0.5446110963821411, loss=1.1743370294570923
test: epoch 5, loss 3.257199287414551, acc=0.18611110746860504, loss=3.257199287414551
train: epoch 6, loss 1.0670344829559326, acc=0.5932222008705139, loss=1.0670344829559326
test: epoch 6, loss 3.2849173545837402, acc=0.18611110746860504, loss=3.2849173545837402
train: epoch 7, loss 0.9818283319473267, acc=0.6262778043746948, loss=0.9818283319473267
test: epoch 7, loss 3.098134994506836, acc=0.21111111342906952, loss=3.098134994506836
train: epoch 8, loss 0.9187227487564087, acc=0.6516110897064209, loss=0.9187227487564087
test: epoch 8, loss 3.1062698364257812, acc=0.21388888359069824, loss=3.1062698364257812
train: epoch 9, loss 0.8466960787773132, acc=0.6852777600288391, loss=0.8466960787773132
test: epoch 9, loss 3.1526858806610107, acc=0.20555555820465088, loss=3.1526858806610107
train: epoch 10, loss 0.7877206206321716, acc=0.6997777819633484, loss=0.7877206206321716
test: epoch 10, loss 3.096019983291626, acc=0.21666666865348816, loss=3.096019983291626
train: epoch 11, loss 0.753200113773346, acc=0.7191110849380493, loss=0.753200113773346
test: epoch 11, loss 3.033862352371216, acc=0.2222222238779068, loss=3.033862352371216
train: epoch 12, loss 0.7100943326950073, acc=0.7363888621330261, loss=0.7100943326950073
test: epoch 12, loss 2.8357901573181152, acc=0.24166665971279144, loss=2.8357901573181152
train: epoch 13, loss 0.6913177967071533, acc=0.746055543422699, loss=0.6913177967071533
test: epoch 13, loss 2.8988847732543945, acc=0.24444444477558136, loss=2.8988847732543945
train: epoch 14, loss 0.6560583114624023, acc=0.7636111378669739, loss=0.6560583114624023
test: epoch 14, loss 2.6403398513793945, acc=0.2611111104488373, loss=2.6403398513793945
train: epoch 15, loss 0.6184569597244263, acc=0.7766666412353516, loss=0.6184569597244263
test: epoch 15, loss 2.6639790534973145, acc=0.21666666865348816, loss=2.6639790534973145
train: epoch 16, loss 0.5945137143135071, acc=0.7870555520057678, loss=0.5945137143135071
test: epoch 16, loss 2.712416172027588, acc=0.24722221493721008, loss=2.712416172027588
train: epoch 17, loss 0.5649417042732239, acc=0.7974444627761841, loss=0.5649417042732239
test: epoch 17, loss 2.5357742309570312, acc=0.2805555462837219, loss=2.5357742309570312
train: epoch 18, loss 0.5406304597854614, acc=0.8087777495384216, loss=0.5406304597854614
test: epoch 18, loss 2.5692667961120605, acc=0.27222222089767456, loss=2.5692667961120605
train: epoch 19, loss 0.5283812284469604, acc=0.8150555491447449, loss=0.5283812284469604
test: epoch 19, loss 2.3082666397094727, acc=0.31111112236976624, loss=2.3082666397094727
train: epoch 20, loss 0.5063573718070984, acc=0.820888876914978, loss=0.5063573718070984
test: epoch 20, loss 2.497326612472534, acc=0.3055555522441864, loss=2.497326612472534
train: epoch 21, loss 0.48509782552719116, acc=0.8282222151756287, loss=0.48509782552719116
test: epoch 21, loss 2.4512622356414795, acc=0.2944444417953491, loss=2.4512622356414795
train: epoch 22, loss 0.46607357263565063, acc=0.8358333110809326, loss=0.46607357263565063
test: epoch 22, loss 2.3569605350494385, acc=0.3194444477558136, loss=2.3569605350494385
train: epoch 23, loss 0.4525073766708374, acc=0.8451666831970215, loss=0.4525073766708374
test: epoch 23, loss 2.2034168243408203, acc=0.3083333373069763, loss=2.2034168243408203
train: epoch 24, loss 0.44068846106529236, acc=0.8487777709960938, loss=0.44068846106529236
test: epoch 24, loss 2.166813611984253, acc=0.3055555522441864, loss=2.166813611984253
train: epoch 25, loss 0.4200350046157837, acc=0.8570555448532104, loss=0.4200350046157837
test: epoch 25, loss 2.0116007328033447, acc=0.33888888359069824, loss=2.0116007328033447
train: epoch 26, loss 0.41349586844444275, acc=0.8544999957084656, loss=0.41349586844444275
test: epoch 26, loss 2.139198064804077, acc=0.3083333373069763, loss=2.139198064804077
train: epoch 27, loss 0.40112394094467163, acc=0.8666666746139526, loss=0.40112394094467163
test: epoch 27, loss 2.3500545024871826, acc=0.3083333373069763, loss=2.3500545024871826
train: epoch 28, loss 0.3868630826473236, acc=0.8723333477973938, loss=0.3868630826473236
test: epoch 28, loss 2.346262216567993, acc=0.28611111640930176, loss=2.346262216567993
train: epoch 29, loss 0.3839341700077057, acc=0.8698889017105103, loss=0.3839341700077057
test: epoch 29, loss 2.210982084274292, acc=0.3222222328186035, loss=2.210982084274292
train: epoch 30, loss 0.38236430287361145, acc=0.8702777624130249, loss=0.38236430287361145
test: epoch 30, loss 2.003077745437622, acc=0.3499999940395355, loss=2.003077745437622
train: epoch 31, loss 0.36067816615104675, acc=0.8813333511352539, loss=0.36067816615104675
test: epoch 31, loss 2.0286874771118164, acc=0.31111112236976624, loss=2.0286874771118164
train: epoch 32, loss 0.3521505892276764, acc=0.883388876914978, loss=0.3521505892276764
test: epoch 32, loss 1.938918113708496, acc=0.375, loss=1.938918113708496
train: epoch 33, loss 0.3471721112728119, acc=0.8829444646835327, loss=0.3471721112728119
test: epoch 33, loss 2.0412650108337402, acc=0.3361110985279083, loss=2.0412650108337402
train: epoch 34, loss 0.3373403549194336, acc=0.8876110911369324, loss=0.3373403549194336
test: epoch 34, loss 1.955867886543274, acc=0.3361110985279083, loss=1.955867886543274
train: epoch 35, loss 0.3285689651966095, acc=0.8892777562141418, loss=0.3285689651966095
test: epoch 35, loss 1.9185937643051147, acc=0.3638888895511627, loss=1.9185937643051147
train: epoch 36, loss 0.32905465364456177, acc=0.8909444212913513, loss=0.32905465364456177
test: epoch 36, loss 2.1328787803649902, acc=0.35277777910232544, loss=2.1328787803649902
train: epoch 37, loss 0.3209318518638611, acc=0.8955555558204651, loss=0.3209318518638611
test: epoch 37, loss 1.9249186515808105, acc=0.39444443583488464, loss=1.9249186515808105
train: epoch 38, loss 0.31903597712516785, acc=0.8931666612625122, loss=0.31903597712516785
test: epoch 38, loss 1.8556681871414185, acc=0.4027777910232544, loss=1.8556681871414185
train: epoch 39, loss 0.3107340931892395, acc=0.894611120223999, loss=0.3107340931892395
test: epoch 39, loss 1.8289967775344849, acc=0.35277777910232544, loss=1.8289967775344849
train: epoch 40, loss 0.30251163244247437, acc=0.8970000147819519, loss=0.30251163244247437
test: epoch 40, loss 1.9059596061706543, acc=0.39722222089767456, loss=1.9059596061706543
train: epoch 41, loss 0.30849820375442505, acc=0.894444465637207, loss=0.30849820375442505
test: epoch 41, loss 1.7499115467071533, acc=0.3888888955116272, loss=1.7499115467071533
train: epoch 42, loss 0.29136916995048523, acc=0.9031111001968384, loss=0.29136916995048523
test: epoch 42, loss 1.9327315092086792, acc=0.35277777910232544, loss=1.9327315092086792
train: epoch 43, loss 0.30223819613456726, acc=0.9001666903495789, loss=0.30223819613456726
test: epoch 43, loss 1.8890098333358765, acc=0.3777777850627899, loss=1.8890098333358765
train: epoch 44, loss 0.28196221590042114, acc=0.9056666493415833, loss=0.28196221590042114
test: epoch 44, loss 1.7022234201431274, acc=0.42222222685813904, loss=1.7022234201431274
train: epoch 45, loss 0.29465019702911377, acc=0.9037777781486511, loss=0.29465019702911377
test: epoch 45, loss 1.6587049961090088, acc=0.4416666626930237, loss=1.6587049961090088
train: epoch 46, loss 0.28124475479125977, acc=0.9081666469573975, loss=0.28124475479125977
test: epoch 46, loss 1.72823965549469, acc=0.4055555462837219, loss=1.72823965549469
train: epoch 47, loss 0.27843382954597473, acc=0.9069444537162781, loss=0.27843382954597473
test: epoch 47, loss 1.7247918844223022, acc=0.4000000059604645, loss=1.7247918844223022
train: epoch 48, loss 0.26545190811157227, acc=0.9076666831970215, loss=0.26545190811157227
test: epoch 48, loss 1.5041565895080566, acc=0.4611110985279083, loss=1.5041565895080566
train: epoch 49, loss 0.26215338706970215, acc=0.9119444489479065, loss=0.26215338706970215
test: epoch 49, loss 1.5842323303222656, acc=0.4444444477558136, loss=1.5842323303222656
train: epoch 50, loss 0.2714693248271942, acc=0.910277783870697, loss=0.2714693248271942
test: epoch 50, loss 1.6634026765823364, acc=0.3777777850627899, loss=1.6634026765823364
train: epoch 51, loss 0.25250765681266785, acc=0.9130555391311646, loss=0.25250765681266785
test: epoch 51, loss 1.5338891744613647, acc=0.4555555582046509, loss=1.5338891744613647
train: epoch 52, loss 0.2617111802101135, acc=0.9157778024673462, loss=0.2617111802101135
test: epoch 52, loss 1.5562896728515625, acc=0.46388888359069824, loss=1.5562896728515625
train: epoch 53, loss 0.2724530100822449, acc=0.9130555391311646, loss=0.2724530100822449
test: epoch 53, loss 1.5843174457550049, acc=0.40833333134651184, loss=1.5843174457550049
train: epoch 54, loss 0.25920218229293823, acc=0.9138888716697693, loss=0.25920218229293823
test: epoch 54, loss 1.4634172916412354, acc=0.3888888955116272, loss=1.4634172916412354
train: epoch 55, loss 0.26667270064353943, acc=0.9127777814865112, loss=0.26667270064353943
test: epoch 55, loss 1.5984243154525757, acc=0.39722222089767456, loss=1.5984243154525757
train: epoch 56, loss 0.25507694482803345, acc=0.9152777791023254, loss=0.25507694482803345
test: epoch 56, loss 1.5971262454986572, acc=0.4305555522441864, loss=1.5971262454986572
train: epoch 57, loss 0.2451312094926834, acc=0.918055534362793, loss=0.2451312094926834
test: epoch 57, loss 1.5432217121124268, acc=0.4444444477558136, loss=1.5432217121124268
train: epoch 58, loss 0.2413501888513565, acc=0.9188888669013977, loss=0.2413501888513565
test: epoch 58, loss 1.3310306072235107, acc=0.47777777910232544, loss=1.3310306072235107
train: epoch 59, loss 0.2440929263830185, acc=0.9211111068725586, loss=0.2440929263830185
test: epoch 59, loss 1.3794569969177246, acc=0.4722222089767456, loss=1.3794569969177246
train: epoch 60, loss 0.23594796657562256, acc=0.9217222332954407, loss=0.23594796657562256
test: epoch 60, loss 1.5445656776428223, acc=0.48055556416511536, loss=1.5445656776428223
train: epoch 61, loss 0.22742770612239838, acc=0.9241111278533936, loss=0.22742770612239838
test: epoch 61, loss 1.4494351148605347, acc=0.4749999940395355, loss=1.4494351148605347
train: epoch 62, loss 0.22757235169410706, acc=0.9212222099304199, loss=0.22757235169410706
test: epoch 62, loss 1.4300991296768188, acc=0.4861111044883728, loss=1.4300991296768188
train: epoch 63, loss 0.2289862185716629, acc=0.9232222437858582, loss=0.2289862185716629
test: epoch 63, loss 1.3573795557022095, acc=0.49444442987442017, loss=1.3573795557022095
train: epoch 64, loss 0.22779963910579681, acc=0.9269444346427917, loss=0.22779963910579681
test: epoch 64, loss 1.4723775386810303, acc=0.47777777910232544, loss=1.4723775386810303
train: epoch 65, loss 0.2272685319185257, acc=0.9212777614593506, loss=0.2272685319185257
test: epoch 65, loss 1.438256859779358, acc=0.48055556416511536, loss=1.438256859779358
train: epoch 66, loss 0.22469067573547363, acc=0.9258888959884644, loss=0.22469067573547363
test: epoch 66, loss 1.5202363729476929, acc=0.44999998807907104, loss=1.5202363729476929
train: epoch 67, loss 0.21377864480018616, acc=0.9287777543067932, loss=0.21377864480018616
test: epoch 67, loss 1.2705901861190796, acc=0.49444442987442017, loss=1.2705901861190796
train: epoch 68, loss 0.219406858086586, acc=0.9268888831138611, loss=0.219406858086586
test: epoch 68, loss 1.2860865592956543, acc=0.5083333253860474, loss=1.2860865592956543
train: epoch 69, loss 0.2140558809041977, acc=0.9282222390174866, loss=0.2140558809041977
test: epoch 69, loss 1.3951820135116577, acc=0.49444442987442017, loss=1.3951820135116577
train: epoch 70, loss 0.20775827765464783, acc=0.9301111102104187, loss=0.20775827765464783
test: epoch 70, loss 1.2807079553604126, acc=0.5277777910232544, loss=1.2807079553604126
train: epoch 71, loss 0.21572443842887878, acc=0.926277756690979, loss=0.21572443842887878
test: epoch 71, loss 1.3866615295410156, acc=0.5138888955116272, loss=1.3866615295410156
train: epoch 72, loss 0.20873311161994934, acc=0.9310555458068848, loss=0.20873311161994934
test: epoch 72, loss 1.3050163984298706, acc=0.4972222149372101, loss=1.3050163984298706
train: epoch 73, loss 0.2011454850435257, acc=0.9334999918937683, loss=0.2011454850435257
test: epoch 73, loss 1.305967926979065, acc=0.519444465637207, loss=1.305967926979065
train: epoch 74, loss 0.1982404738664627, acc=0.9336110949516296, loss=0.1982404738664627
test: epoch 74, loss 1.4204251766204834, acc=0.47777777910232544, loss=1.4204251766204834
train: epoch 75, loss 0.21047216653823853, acc=0.9312222003936768, loss=0.21047216653823853
test: epoch 75, loss 1.2518031597137451, acc=0.5083333253860474, loss=1.2518031597137451
train: epoch 76, loss 0.2032252848148346, acc=0.9351666569709778, loss=0.2032252848148346
test: epoch 76, loss 1.2982046604156494, acc=0.5361111164093018, loss=1.2982046604156494
train: epoch 77, loss 0.19647572934627533, acc=0.933388888835907, loss=0.19647572934627533
test: epoch 77, loss 1.264016032218933, acc=0.519444465637207, loss=1.264016032218933
train: epoch 78, loss 0.20403137803077698, acc=0.9342222213745117, loss=0.20403137803077698
test: epoch 78, loss 1.2613970041275024, acc=0.4833333194255829, loss=1.2613970041275024
train: epoch 79, loss 0.18174012005329132, acc=0.9408888816833496, loss=0.18174012005329132
test: epoch 79, loss 1.3489044904708862, acc=0.5166666507720947, loss=1.3489044904708862
train: epoch 80, loss 0.19632935523986816, acc=0.9374444484710693, loss=0.19632935523986816
test: epoch 80, loss 1.3018372058868408, acc=0.5388888716697693, loss=1.3018372058868408
train: epoch 81, loss 0.20265965163707733, acc=0.9367777705192566, loss=0.20265965163707733
test: epoch 81, loss 1.2649070024490356, acc=0.5416666865348816, loss=1.2649070024490356
train: epoch 82, loss 0.18901212513446808, acc=0.9367777705192566, loss=0.18901212513446808
test: epoch 82, loss 1.2615641355514526, acc=0.5416666865348816, loss=1.2615641355514526
train: epoch 83, loss 0.19728058576583862, acc=0.9366666674613953, loss=0.19728058576583862
test: epoch 83, loss 1.3176124095916748, acc=0.5583333373069763, loss=1.3176124095916748
train: epoch 84, loss 0.19858339428901672, acc=0.9333333373069763, loss=0.19858339428901672
test: epoch 84, loss 1.1812185049057007, acc=0.5333333611488342, loss=1.1812185049057007
train: epoch 85, loss 0.1822473555803299, acc=0.9372222423553467, loss=0.1822473555803299
test: epoch 85, loss 1.275612473487854, acc=0.5361111164093018, loss=1.275612473487854
train: epoch 86, loss 0.18560779094696045, acc=0.9376111030578613, loss=0.18560779094696045
test: epoch 86, loss 1.1952046155929565, acc=0.5249999761581421, loss=1.1952046155929565
train: epoch 87, loss 0.18534409999847412, acc=0.9398888945579529, loss=0.18534409999847412
test: epoch 87, loss 1.3519229888916016, acc=0.5166666507720947, loss=1.3519229888916016
train: epoch 88, loss 0.18577931821346283, acc=0.9383333325386047, loss=0.18577931821346283
test: epoch 88, loss 1.2389254570007324, acc=0.5527777671813965, loss=1.2389254570007324
train: epoch 89, loss 0.17446067929267883, acc=0.9430000185966492, loss=0.17446067929267883
test: epoch 89, loss 1.275625467300415, acc=0.5416666865348816, loss=1.275625467300415
train: epoch 90, loss 0.1768794059753418, acc=0.9417222142219543, loss=0.1768794059753418
test: epoch 90, loss 1.0676289796829224, acc=0.5722222328186035, loss=1.0676289796829224
train: epoch 91, loss 0.16684050858020782, acc=0.9440000057220459, loss=0.16684050858020782
test: epoch 91, loss 1.380102515220642, acc=0.49444442987442017, loss=1.380102515220642
train: epoch 92, loss 0.17443111538887024, acc=0.9432222247123718, loss=0.17443111538887024
test: epoch 92, loss 1.3005763292312622, acc=0.5666666626930237, loss=1.3005763292312622
train: epoch 93, loss 0.18121729791164398, acc=0.9411110877990723, loss=0.18121729791164398
test: epoch 93, loss 1.2313505411148071, acc=0.5833333134651184, loss=1.2313505411148071
train: epoch 94, loss 0.17514590919017792, acc=0.9436110854148865, loss=0.17514590919017792
test: epoch 94, loss 1.2765859365463257, acc=0.550000011920929, loss=1.2765859365463257
train: epoch 95, loss 0.17022520303726196, acc=0.9424999952316284, loss=0.17022520303726196
test: epoch 95, loss 1.3066256046295166, acc=0.5611110925674438, loss=1.3066256046295166
train: epoch 96, loss 0.16078032553195953, acc=0.9491111040115356, loss=0.16078032553195953
test: epoch 96, loss 1.134334921836853, acc=0.5527777671813965, loss=1.134334921836853
train: epoch 97, loss 0.17903444170951843, acc=0.9422222375869751, loss=0.17903444170951843
test: epoch 97, loss 1.220290184020996, acc=0.5833333134651184, loss=1.220290184020996
train: epoch 98, loss 0.1573091745376587, acc=0.9467222094535828, loss=0.1573091745376587
test: epoch 98, loss 1.279405117034912, acc=0.5861111283302307, loss=1.279405117034912
train: epoch 99, loss 0.16682325303554535, acc=0.9443888664245605, loss=0.16682325303554535
test: epoch 99, loss 1.1570693254470825, acc=0.5833333134651184, loss=1.1570693254470825
train: epoch 100, loss 0.16110853850841522, acc=0.9475555419921875, loss=0.16110853850841522
test: epoch 100, loss 1.2681654691696167, acc=0.5833333134651184, loss=1.2681654691696167
train: epoch 101, loss 0.17253677546977997, acc=0.940666675567627, loss=0.17253677546977997
test: epoch 101, loss 1.1747506856918335, acc=0.5944444537162781, loss=1.1747506856918335
train: epoch 102, loss 0.1579807996749878, acc=0.9478889107704163, loss=0.1579807996749878
test: epoch 102, loss 1.1843847036361694, acc=0.6166666746139526, loss=1.1843847036361694
train: epoch 103, loss 0.16149261593818665, acc=0.9488333463668823, loss=0.16149261593818665
test: epoch 103, loss 1.2485976219177246, acc=0.5944444537162781, loss=1.2485976219177246
train: epoch 104, loss 0.16708427667617798, acc=0.9462777972221375, loss=0.16708427667617798
test: epoch 104, loss 1.032956600189209, acc=0.5888888835906982, loss=1.032956600189209
train: epoch 105, loss 0.1694803088903427, acc=0.9462777972221375, loss=0.1694803088903427
test: epoch 105, loss 1.2425320148468018, acc=0.5638889074325562, loss=1.2425320148468018
train: epoch 106, loss 0.16103523969650269, acc=0.9470000267028809, loss=0.16103523969650269
test: epoch 106, loss 1.2673869132995605, acc=0.5861111283302307, loss=1.2673869132995605
train: epoch 107, loss 0.16507568955421448, acc=0.9477777481079102, loss=0.16507568955421448
test: epoch 107, loss 1.1406922340393066, acc=0.6000000238418579, loss=1.1406922340393066
train: epoch 108, loss 0.15433882176876068, acc=0.949833333492279, loss=0.15433882176876068
test: epoch 108, loss 1.188439130783081, acc=0.6194444298744202, loss=1.188439130783081
train: epoch 109, loss 0.1571567952632904, acc=0.9483333230018616, loss=0.1571567952632904
test: epoch 109, loss 1.2951136827468872, acc=0.5888888835906982, loss=1.2951136827468872
train: epoch 110, loss 0.155989870429039, acc=0.9483888745307922, loss=0.155989870429039
test: epoch 110, loss 1.1344982385635376, acc=0.6111111044883728, loss=1.1344982385635376
train: epoch 111, loss 0.1494075357913971, acc=0.9486666917800903, loss=0.1494075357913971
test: epoch 111, loss 1.1941395998001099, acc=0.605555534362793, loss=1.1941395998001099
train: epoch 112, loss 0.14719921350479126, acc=0.9482222199440002, loss=0.14719921350479126
test: epoch 112, loss 1.230150818824768, acc=0.6222222447395325, loss=1.230150818824768
train: epoch 113, loss 0.15006162226200104, acc=0.9498888850212097, loss=0.15006162226200104
test: epoch 113, loss 1.1501595973968506, acc=0.6166666746139526, loss=1.1501595973968506
train: epoch 114, loss 0.1601136028766632, acc=0.9483888745307922, loss=0.1601136028766632
test: epoch 114, loss 1.1587814092636108, acc=0.6083333492279053, loss=1.1587814092636108
train: epoch 115, loss 0.14859172701835632, acc=0.9499444365501404, loss=0.14859172701835632
test: epoch 115, loss 1.1237502098083496, acc=0.6138888597488403, loss=1.1237502098083496
train: epoch 116, loss 0.15137270092964172, acc=0.9495555758476257, loss=0.15137270092964172
test: epoch 116, loss 1.0986191034317017, acc=0.6416666507720947, loss=1.0986191034317017
train: epoch 117, loss 0.1614098846912384, acc=0.9484999775886536, loss=0.1614098846912384
test: epoch 117, loss 1.1264265775680542, acc=0.6111111044883728, loss=1.1264265775680542
train: epoch 118, loss 0.15571630001068115, acc=0.9513888955116272, loss=0.15571630001068115
test: epoch 118, loss 1.2046661376953125, acc=0.6305555701255798, loss=1.2046661376953125
train: epoch 119, loss 0.1483541578054428, acc=0.9507777690887451, loss=0.1483541578054428
test: epoch 119, loss 1.1568683385849, acc=0.5972222089767456, loss=1.1568683385849
train: epoch 120, loss 0.15240180492401123, acc=0.9508888721466064, loss=0.15240180492401123
test: epoch 120, loss 1.0521283149719238, acc=0.6472222208976746, loss=1.0521283149719238
train: epoch 121, loss 0.15359118580818176, acc=0.9495555758476257, loss=0.15359118580818176
test: epoch 121, loss 1.1077378988265991, acc=0.6388888955116272, loss=1.1077378988265991
train: epoch 122, loss 0.15192869305610657, acc=0.9495555758476257, loss=0.15192869305610657
test: epoch 122, loss 1.0077205896377563, acc=0.6583333611488342, loss=1.0077205896377563
train: epoch 123, loss 0.1466512829065323, acc=0.9517222046852112, loss=0.1466512829065323
test: epoch 123, loss 1.1902915239334106, acc=0.625, loss=1.1902915239334106
train: epoch 124, loss 0.143661230802536, acc=0.9520555734634399, loss=0.143661230802536
test: epoch 124, loss 1.0643349885940552, acc=0.6416666507720947, loss=1.0643349885940552
train: epoch 125, loss 0.1562531441450119, acc=0.9503333568572998, loss=0.1562531441450119
test: epoch 125, loss 0.961711049079895, acc=0.6777777671813965, loss=0.961711049079895
train: epoch 126, loss 0.14286234974861145, acc=0.953166663646698, loss=0.14286234974861145
test: epoch 126, loss 1.075150966644287, acc=0.6333333253860474, loss=1.075150966644287
train: epoch 127, loss 0.14994210004806519, acc=0.9496111273765564, loss=0.14994210004806519
test: epoch 127, loss 1.1068626642227173, acc=0.6611111164093018, loss=1.1068626642227173
train: epoch 128, loss 0.14418692886829376, acc=0.9521111249923706, loss=0.14418692886829376
test: epoch 128, loss 1.061509609222412, acc=0.6611111164093018, loss=1.061509609222412
train: epoch 129, loss 0.15559959411621094, acc=0.9487777948379517, loss=0.15559959411621094
test: epoch 129, loss 1.0132018327713013, acc=0.6416666507720947, loss=1.0132018327713013
train: epoch 130, loss 0.14325271546840668, acc=0.9520555734634399, loss=0.14325271546840668
test: epoch 130, loss 0.9665960669517517, acc=0.6972222328186035, loss=0.9665960669517517
train: epoch 131, loss 0.16072125732898712, acc=0.9467777609825134, loss=0.16072125732898712
test: epoch 131, loss 1.0489578247070312, acc=0.6611111164093018, loss=1.0489578247070312
train: epoch 132, loss 0.14742963016033173, acc=0.953000009059906, loss=0.14742963016033173
test: epoch 132, loss 0.9648059606552124, acc=0.6916666626930237, loss=0.9648059606552124
train: epoch 133, loss 0.15031272172927856, acc=0.9503333568572998, loss=0.15031272172927856
test: epoch 133, loss 0.9681810140609741, acc=0.6499999761581421, loss=0.9681810140609741
train: epoch 134, loss 0.15250156819820404, acc=0.948722243309021, loss=0.15250156819820404
test: epoch 134, loss 1.026471495628357, acc=0.6305555701255798, loss=1.026471495628357
train: epoch 135, loss 0.14588315784931183, acc=0.9507777690887451, loss=0.14588315784931183
test: epoch 135, loss 0.9517922401428223, acc=0.6777777671813965, loss=0.9517922401428223
train: epoch 136, loss 0.15067985653877258, acc=0.9503333568572998, loss=0.15067985653877258
test: epoch 136, loss 1.1148536205291748, acc=0.6694444417953491, loss=1.1148536205291748
train: epoch 137, loss 0.13415102660655975, acc=0.9522777795791626, loss=0.13415102660655975
test: epoch 137, loss 1.1226636171340942, acc=0.644444465637207, loss=1.1226636171340942
train: epoch 138, loss 0.1474362015724182, acc=0.9500555396080017, loss=0.1474362015724182
test: epoch 138, loss 1.02993643283844, acc=0.6722221970558167, loss=1.02993643283844
train: epoch 139, loss 0.14640197157859802, acc=0.949999988079071, loss=0.14640197157859802
test: epoch 139, loss 1.1433393955230713, acc=0.6611111164093018, loss=1.1433393955230713
train: epoch 140, loss 0.1481768637895584, acc=0.950166642665863, loss=0.1481768637895584
test: epoch 140, loss 0.9982162117958069, acc=0.699999988079071, loss=0.9982162117958069
train: epoch 141, loss 0.16586370766162872, acc=0.9487777948379517, loss=0.16586370766162872
test: epoch 141, loss 0.9613966345787048, acc=0.6888889074325562, loss=0.9613966345787048
train: epoch 142, loss 0.1462724357843399, acc=0.9513333439826965, loss=0.1462724357843399
test: epoch 142, loss 1.0539602041244507, acc=0.6694444417953491, loss=1.0539602041244507
train: epoch 143, loss 0.13575227558612823, acc=0.9532222151756287, loss=0.13575227558612823
test: epoch 143, loss 0.9028688669204712, acc=0.7166666388511658, loss=0.9028688669204712
train: epoch 144, loss 0.1368427276611328, acc=0.9518333077430725, loss=0.1368427276611328
test: epoch 144, loss 0.9985373616218567, acc=0.7055555582046509, loss=0.9985373616218567
train: epoch 145, loss 0.1422247737646103, acc=0.9497777819633484, loss=0.1422247737646103
test: epoch 145, loss 0.9515581727027893, acc=0.730555534362793, loss=0.9515581727027893
train: epoch 146, loss 0.1503024697303772, acc=0.9495000243186951, loss=0.1503024697303772
test: epoch 146, loss 0.9118860960006714, acc=0.6805555820465088, loss=0.9118860960006714
train: epoch 147, loss 0.14229406416416168, acc=0.950166642665863, loss=0.14229406416416168
test: epoch 147, loss 0.922835111618042, acc=0.7333333492279053, loss=0.922835111618042
train: epoch 148, loss 0.1455763578414917, acc=0.9502221941947937, loss=0.1455763578414917
test: epoch 148, loss 0.8557210564613342, acc=0.6972222328186035, loss=0.8557210564613342
train: epoch 149, loss 0.1458003968000412, acc=0.9517777562141418, loss=0.1458003968000412
test: epoch 149, loss 0.7949268221855164, acc=0.730555534362793, loss=0.7949268221855164
train: epoch 150, loss 0.1445131152868271, acc=0.9503889083862305, loss=0.1445131152868271
test: epoch 150, loss 0.7738070487976074, acc=0.6972222328186035, loss=0.7738070487976074
