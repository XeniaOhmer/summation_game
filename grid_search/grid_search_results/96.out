# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=true", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1338813217, receiver_embed_dim=64, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.2290425300598145, acc=0.07111111283302307, loss=3.2290425300598145
test: epoch 1, loss 4.531957626342773, acc=0.07222222536802292, loss=4.531957626342773
train: epoch 2, loss 1.966404914855957, acc=0.30238887667655945, loss=1.966404914855957
test: epoch 2, loss 3.377187490463257, acc=0.14722222089767456, loss=3.377187490463257
train: epoch 3, loss 1.351456642150879, acc=0.4706111252307892, loss=1.351456642150879
test: epoch 3, loss 2.8851711750030518, acc=0.17222222685813904, loss=2.8851711750030518
train: epoch 4, loss 1.1144517660140991, acc=0.5601666569709778, loss=1.1144517660140991
test: epoch 4, loss 3.0300097465515137, acc=0.20277777314186096, loss=3.0300097465515137
train: epoch 5, loss 0.9698035717010498, acc=0.624833345413208, loss=0.9698035717010498
test: epoch 5, loss 3.1764774322509766, acc=0.2083333283662796, loss=3.1764774322509766
train: epoch 6, loss 0.8697881102561951, acc=0.6700000166893005, loss=0.8697881102561951
test: epoch 6, loss 3.187398672103882, acc=0.21111111342906952, loss=3.187398672103882
train: epoch 7, loss 0.7909142971038818, acc=0.6930000185966492, loss=0.7909142971038818
test: epoch 7, loss 3.046980619430542, acc=0.23888888955116272, loss=3.046980619430542
train: epoch 8, loss 0.7137095332145691, acc=0.7321666479110718, loss=0.7137095332145691
test: epoch 8, loss 3.1083245277404785, acc=0.22777777910232544, loss=3.1083245277404785
train: epoch 9, loss 0.6744071245193481, acc=0.7479444742202759, loss=0.6744071245193481
test: epoch 9, loss 3.2950475215911865, acc=0.2222222238779068, loss=3.2950475215911865
train: epoch 10, loss 0.6381994485855103, acc=0.7595555782318115, loss=0.6381994485855103
test: epoch 10, loss 2.966517925262451, acc=0.24722221493721008, loss=2.966517925262451
train: epoch 11, loss 0.5827504396438599, acc=0.7860000133514404, loss=0.5827504396438599
test: epoch 11, loss 2.960958242416382, acc=0.2222222238779068, loss=2.960958242416382
train: epoch 12, loss 0.5555121898651123, acc=0.7989444732666016, loss=0.5555121898651123
test: epoch 12, loss 2.7192623615264893, acc=0.26944443583488464, loss=2.7192623615264893
train: epoch 13, loss 0.5172524452209473, acc=0.8132222294807434, loss=0.5172524452209473
test: epoch 13, loss 2.737927198410034, acc=0.2666666805744171, loss=2.737927198410034
train: epoch 14, loss 0.49382755160331726, acc=0.8216666579246521, loss=0.49382755160331726
test: epoch 14, loss 2.7308387756347656, acc=0.2611111104488373, loss=2.7308387756347656
train: epoch 15, loss 0.4613054692745209, acc=0.8352222442626953, loss=0.4613054692745209
test: epoch 15, loss 2.5512161254882812, acc=0.2666666805744171, loss=2.5512161254882812
train: epoch 16, loss 0.4604925811290741, acc=0.836555540561676, loss=0.4604925811290741
test: epoch 16, loss 2.6721365451812744, acc=0.28333333134651184, loss=2.6721365451812744
train: epoch 17, loss 0.4313565790653229, acc=0.8482221961021423, loss=0.4313565790653229
test: epoch 17, loss 2.3096401691436768, acc=0.31111112236976624, loss=2.3096401691436768
train: epoch 18, loss 0.3980260491371155, acc=0.863777756690979, loss=0.3980260491371155
test: epoch 18, loss 2.377744197845459, acc=0.30000001192092896, loss=2.377744197845459
train: epoch 19, loss 0.40247824788093567, acc=0.8581666946411133, loss=0.40247824788093567
test: epoch 19, loss 2.3699734210968018, acc=0.27222222089767456, loss=2.3699734210968018
train: epoch 20, loss 0.37809279561042786, acc=0.867388904094696, loss=0.37809279561042786
test: epoch 20, loss 2.430356502532959, acc=0.2916666567325592, loss=2.430356502532959
train: epoch 21, loss 0.36118465662002563, acc=0.8737221956253052, loss=0.36118465662002563
test: epoch 21, loss 2.332772970199585, acc=0.3083333373069763, loss=2.332772970199585
train: epoch 22, loss 0.3403033912181854, acc=0.8839444518089294, loss=0.3403033912181854
test: epoch 22, loss 2.43984055519104, acc=0.31111112236976624, loss=2.43984055519104
train: epoch 23, loss 0.3356480598449707, acc=0.8839444518089294, loss=0.3356480598449707
test: epoch 23, loss 2.4708573818206787, acc=0.3027777671813965, loss=2.4708573818206787
train: epoch 24, loss 0.3306816816329956, acc=0.8861111402511597, loss=0.3306816816329956
test: epoch 24, loss 2.2110283374786377, acc=0.3444444537162781, loss=2.2110283374786377
train: epoch 25, loss 0.3183012902736664, acc=0.8900555372238159, loss=0.3183012902736664
test: epoch 25, loss 2.125562906265259, acc=0.35555556416511536, loss=2.125562906265259
train: epoch 26, loss 0.30531787872314453, acc=0.8945000171661377, loss=0.30531787872314453
test: epoch 26, loss 2.1855714321136475, acc=0.34166666865348816, loss=2.1855714321136475
train: epoch 27, loss 0.2905201315879822, acc=0.899055540561676, loss=0.2905201315879822
test: epoch 27, loss 2.119013786315918, acc=0.3638888895511627, loss=2.119013786315918
train: epoch 28, loss 0.2916863262653351, acc=0.9001666903495789, loss=0.2916863262653351
test: epoch 28, loss 2.1610124111175537, acc=0.3583333194255829, loss=2.1610124111175537
train: epoch 29, loss 0.29655590653419495, acc=0.9026111364364624, loss=0.29655590653419495
test: epoch 29, loss 2.0452568531036377, acc=0.32777777314186096, loss=2.0452568531036377
train: epoch 30, loss 0.26160895824432373, acc=0.9138333201408386, loss=0.26160895824432373
test: epoch 30, loss 2.0707266330718994, acc=0.36944442987442017, loss=2.0707266330718994
train: epoch 31, loss 0.26140931248664856, acc=0.9088333249092102, loss=0.26140931248664856
test: epoch 31, loss 2.0198795795440674, acc=0.35555556416511536, loss=2.0198795795440674
train: epoch 32, loss 0.2673574984073639, acc=0.9138888716697693, loss=0.2673574984073639
test: epoch 32, loss 2.1214470863342285, acc=0.375, loss=2.1214470863342285
train: epoch 33, loss 0.24957498908042908, acc=0.9154444336891174, loss=0.24957498908042908
test: epoch 33, loss 1.983317255973816, acc=0.38333332538604736, loss=1.983317255973816
train: epoch 34, loss 0.23337575793266296, acc=0.9232777953147888, loss=0.23337575793266296
test: epoch 34, loss 2.0877232551574707, acc=0.39444443583488464, loss=2.0877232551574707
train: epoch 35, loss 0.23913875222206116, acc=0.9205555319786072, loss=0.23913875222206116
test: epoch 35, loss 2.0294699668884277, acc=0.3722222149372101, loss=2.0294699668884277
train: epoch 36, loss 0.24541252851486206, acc=0.9193333387374878, loss=0.24541252851486206
test: epoch 36, loss 1.8906073570251465, acc=0.4000000059604645, loss=1.8906073570251465
train: epoch 37, loss 0.224861741065979, acc=0.9236111044883728, loss=0.224861741065979
test: epoch 37, loss 1.9662660360336304, acc=0.4055555462837219, loss=1.9662660360336304
train: epoch 38, loss 0.22096388041973114, acc=0.9270555377006531, loss=0.22096388041973114
test: epoch 38, loss 1.872747540473938, acc=0.38055557012557983, loss=1.872747540473938
train: epoch 39, loss 0.22818021476268768, acc=0.9271110892295837, loss=0.22818021476268768
test: epoch 39, loss 1.8611304759979248, acc=0.4277777671813965, loss=1.8611304759979248
train: epoch 40, loss 0.20296087861061096, acc=0.933722198009491, loss=0.20296087861061096
test: epoch 40, loss 2.252239465713501, acc=0.36666667461395264, loss=2.252239465713501
train: epoch 41, loss 0.21284034848213196, acc=0.9328888654708862, loss=0.21284034848213196
test: epoch 41, loss 1.9962433576583862, acc=0.3888888955116272, loss=1.9962433576583862
train: epoch 42, loss 0.19819115102291107, acc=0.9325000047683716, loss=0.19819115102291107
test: epoch 42, loss 2.091583728790283, acc=0.4000000059604645, loss=2.091583728790283
train: epoch 43, loss 0.20260782539844513, acc=0.9351111054420471, loss=0.20260782539844513
test: epoch 43, loss 2.070843458175659, acc=0.42222222685813904, loss=2.070843458175659
train: epoch 44, loss 0.19234785437583923, acc=0.9397222399711609, loss=0.19234785437583923
test: epoch 44, loss 2.244957208633423, acc=0.3722222149372101, loss=2.244957208633423
train: epoch 45, loss 0.18349015712738037, acc=0.9424999952316284, loss=0.18349015712738037
test: epoch 45, loss 2.2699215412139893, acc=0.4000000059604645, loss=2.2699215412139893
train: epoch 46, loss 0.18603715300559998, acc=0.9411666393280029, loss=0.18603715300559998
test: epoch 46, loss 1.9187588691711426, acc=0.4277777671813965, loss=1.9187588691711426
train: epoch 47, loss 0.17721624672412872, acc=0.944611132144928, loss=0.17721624672412872
test: epoch 47, loss 1.897790551185608, acc=0.43888887763023376, loss=1.897790551185608
train: epoch 48, loss 0.1875399798154831, acc=0.941944420337677, loss=0.1875399798154831
test: epoch 48, loss 2.0232977867126465, acc=0.43888887763023376, loss=2.0232977867126465
train: epoch 49, loss 0.18872712552547455, acc=0.9416666626930237, loss=0.18872712552547455
test: epoch 49, loss 2.089661121368408, acc=0.3888888955116272, loss=2.089661121368408
train: epoch 50, loss 0.17576323449611664, acc=0.9434444308280945, loss=0.17576323449611664
test: epoch 50, loss 1.9426690340042114, acc=0.4583333432674408, loss=1.9426690340042114
train: epoch 51, loss 0.17210832238197327, acc=0.9452221989631653, loss=0.17210832238197327
test: epoch 51, loss 2.1385185718536377, acc=0.4194444417953491, loss=2.1385185718536377
train: epoch 52, loss 0.16226087510585785, acc=0.9500555396080017, loss=0.16226087510585785
test: epoch 52, loss 2.1828689575195312, acc=0.42500001192092896, loss=2.1828689575195312
train: epoch 53, loss 0.1760576218366623, acc=0.944944441318512, loss=0.1760576218366623
test: epoch 53, loss 1.8269258737564087, acc=0.44999998807907104, loss=1.8269258737564087
train: epoch 54, loss 0.1718090921640396, acc=0.949055552482605, loss=0.1718090921640396
test: epoch 54, loss 2.0296688079833984, acc=0.3861111104488373, loss=2.0296688079833984
train: epoch 55, loss 0.16381749510765076, acc=0.9489444494247437, loss=0.16381749510765076
test: epoch 55, loss 1.8126347064971924, acc=0.4277777671813965, loss=1.8126347064971924
train: epoch 56, loss 0.16235283017158508, acc=0.9483888745307922, loss=0.16235283017158508
test: epoch 56, loss 2.214967966079712, acc=0.4444444477558136, loss=2.214967966079712
train: epoch 57, loss 0.1526026427745819, acc=0.9506666660308838, loss=0.1526026427745819
test: epoch 57, loss 1.9477653503417969, acc=0.42500001192092896, loss=1.9477653503417969
train: epoch 58, loss 0.1522853672504425, acc=0.9537777900695801, loss=0.1522853672504425
test: epoch 58, loss 2.0578739643096924, acc=0.46388888359069824, loss=2.0578739643096924
train: epoch 59, loss 0.15673092007637024, acc=0.952833354473114, loss=0.15673092007637024
test: epoch 59, loss 1.941575050354004, acc=0.4583333432674408, loss=1.941575050354004
train: epoch 60, loss 0.14966242015361786, acc=0.9537777900695801, loss=0.14966242015361786
test: epoch 60, loss 1.944496750831604, acc=0.46388888359069824, loss=1.944496750831604
train: epoch 61, loss 0.14780206978321075, acc=0.9545000195503235, loss=0.14780206978321075
test: epoch 61, loss 1.8795766830444336, acc=0.48055556416511536, loss=1.8795766830444336
train: epoch 62, loss 0.14027351140975952, acc=0.956166684627533, loss=0.14027351140975952
test: epoch 62, loss 1.8396118879318237, acc=0.4861111044883728, loss=1.8396118879318237
train: epoch 63, loss 0.15875548124313354, acc=0.9528889060020447, loss=0.15875548124313354
test: epoch 63, loss 1.9677499532699585, acc=0.49444442987442017, loss=1.9677499532699585
train: epoch 64, loss 0.15124841034412384, acc=0.9528889060020447, loss=0.15124841034412384
test: epoch 64, loss 1.8444377183914185, acc=0.49444442987442017, loss=1.8444377183914185
train: epoch 65, loss 0.13898567855358124, acc=0.9555555582046509, loss=0.13898567855358124
test: epoch 65, loss 1.9841035604476929, acc=0.4694444537162781, loss=1.9841035604476929
train: epoch 66, loss 0.1510942429304123, acc=0.9543333053588867, loss=0.1510942429304123
test: epoch 66, loss 1.8977502584457397, acc=0.4749999940395355, loss=1.8977502584457397
train: epoch 67, loss 0.13587190210819244, acc=0.9562222361564636, loss=0.13587190210819244
test: epoch 67, loss 1.908538818359375, acc=0.48055556416511536, loss=1.908538818359375
train: epoch 68, loss 0.14058516919612885, acc=0.9562222361564636, loss=0.14058516919612885
test: epoch 68, loss 2.062194347381592, acc=0.49166667461395264, loss=2.062194347381592
train: epoch 69, loss 0.14406424760818481, acc=0.9547777771949768, loss=0.14406424760818481
test: epoch 69, loss 1.8057339191436768, acc=0.4833333194255829, loss=1.8057339191436768
train: epoch 70, loss 0.1414012759923935, acc=0.9571666717529297, loss=0.1414012759923935
test: epoch 70, loss 2.036395311355591, acc=0.4277777671813965, loss=2.036395311355591
train: epoch 71, loss 0.13536213338375092, acc=0.9588333368301392, loss=0.13536213338375092
test: epoch 71, loss 1.8856208324432373, acc=0.4694444537162781, loss=1.8856208324432373
train: epoch 72, loss 0.1383252590894699, acc=0.9578889012336731, loss=0.1383252590894699
test: epoch 72, loss 2.0439460277557373, acc=0.4749999940395355, loss=2.0439460277557373
train: epoch 73, loss 0.14741820096969604, acc=0.9558333158493042, loss=0.14741820096969604
test: epoch 73, loss 1.862728238105774, acc=0.49166667461395264, loss=1.862728238105774
train: epoch 74, loss 0.13075487315654755, acc=0.9596111178398132, loss=0.13075487315654755
test: epoch 74, loss 1.6882015466690063, acc=0.5138888955116272, loss=1.6882015466690063
train: epoch 75, loss 0.13626746833324432, acc=0.9572222232818604, loss=0.13626746833324432
test: epoch 75, loss 2.0357606410980225, acc=0.47777777910232544, loss=2.0357606410980225
train: epoch 76, loss 0.12589707970619202, acc=0.9619444608688354, loss=0.12589707970619202
test: epoch 76, loss 2.0470356941223145, acc=0.4722222089767456, loss=2.0470356941223145
train: epoch 77, loss 0.13855713605880737, acc=0.9587777853012085, loss=0.13855713605880737
test: epoch 77, loss 1.8638532161712646, acc=0.48055556416511536, loss=1.8638532161712646
train: epoch 78, loss 0.1375540941953659, acc=0.9574999809265137, loss=0.1375540941953659
test: epoch 78, loss 1.9215097427368164, acc=0.5249999761581421, loss=1.9215097427368164
train: epoch 79, loss 0.1332554668188095, acc=0.9610555768013, loss=0.1332554668188095
test: epoch 79, loss 1.7003602981567383, acc=0.49166667461395264, loss=1.7003602981567383
train: epoch 80, loss 0.1347064971923828, acc=0.9581111073493958, loss=0.1347064971923828
test: epoch 80, loss 1.7602773904800415, acc=0.5027777552604675, loss=1.7602773904800415
train: epoch 81, loss 0.12922559678554535, acc=0.9583333134651184, loss=0.12922559678554535
test: epoch 81, loss 1.9633209705352783, acc=0.48055556416511536, loss=1.9633209705352783
train: epoch 82, loss 0.1349446326494217, acc=0.9595555663108826, loss=0.1349446326494217
test: epoch 82, loss 1.957859992980957, acc=0.47777777910232544, loss=1.957859992980957
train: epoch 83, loss 0.12685756385326385, acc=0.9586111307144165, loss=0.12685756385326385
test: epoch 83, loss 1.8014919757843018, acc=0.5027777552604675, loss=1.8014919757843018
train: epoch 84, loss 0.12462592869997025, acc=0.9601110816001892, loss=0.12462592869997025
test: epoch 84, loss 1.756691813468933, acc=0.5027777552604675, loss=1.756691813468933
train: epoch 85, loss 0.1376839578151703, acc=0.9581666588783264, loss=0.1376839578151703
test: epoch 85, loss 2.0436384677886963, acc=0.5333333611488342, loss=2.0436384677886963
train: epoch 86, loss 0.12268327176570892, acc=0.9605000019073486, loss=0.12268327176570892
test: epoch 86, loss 2.0485386848449707, acc=0.5388888716697693, loss=2.0485386848449707
train: epoch 87, loss 0.1330110877752304, acc=0.9603888988494873, loss=0.1330110877752304
test: epoch 87, loss 1.8386787176132202, acc=0.5527777671813965, loss=1.8386787176132202
train: epoch 88, loss 0.12849874794483185, acc=0.9603888988494873, loss=0.12849874794483185
test: epoch 88, loss 1.798503041267395, acc=0.5472221970558167, loss=1.798503041267395
train: epoch 89, loss 0.12601953744888306, acc=0.9613333344459534, loss=0.12601953744888306
test: epoch 89, loss 1.7754498720169067, acc=0.5249999761581421, loss=1.7754498720169067
train: epoch 90, loss 0.12667842209339142, acc=0.961388885974884, loss=0.12667842209339142
test: epoch 90, loss 1.895752191543579, acc=0.5722222328186035, loss=1.895752191543579
train: epoch 91, loss 0.1233634203672409, acc=0.961722195148468, loss=0.1233634203672409
test: epoch 91, loss 1.702262043952942, acc=0.5888888835906982, loss=1.702262043952942
train: epoch 92, loss 0.12621240317821503, acc=0.9638333320617676, loss=0.12621240317821503
test: epoch 92, loss 1.7781487703323364, acc=0.5305555462837219, loss=1.7781487703323364
train: epoch 93, loss 0.12328394502401352, acc=0.9609444737434387, loss=0.12328394502401352
test: epoch 93, loss 1.737465500831604, acc=0.5666666626930237, loss=1.737465500831604
train: epoch 94, loss 0.1249343752861023, acc=0.9611111283302307, loss=0.1249343752861023
test: epoch 94, loss 1.5229675769805908, acc=0.5861111283302307, loss=1.5229675769805908
train: epoch 95, loss 0.12891846895217896, acc=0.9622777700424194, loss=0.12891846895217896
test: epoch 95, loss 1.7004464864730835, acc=0.5333333611488342, loss=1.7004464864730835
train: epoch 96, loss 0.12443315237760544, acc=0.9618333578109741, loss=0.12443315237760544
test: epoch 96, loss 1.6052404642105103, acc=0.5944444537162781, loss=1.6052404642105103
train: epoch 97, loss 0.1198556199669838, acc=0.961722195148468, loss=0.1198556199669838
test: epoch 97, loss 1.6606652736663818, acc=0.5888888835906982, loss=1.6606652736663818
train: epoch 98, loss 0.1329500675201416, acc=0.9608888626098633, loss=0.1329500675201416
test: epoch 98, loss 1.6379272937774658, acc=0.5861111283302307, loss=1.6379272937774658
train: epoch 99, loss 0.12310631573200226, acc=0.961222231388092, loss=0.12310631573200226
test: epoch 99, loss 1.463537573814392, acc=0.6222222447395325, loss=1.463537573814392
train: epoch 100, loss 0.12115620076656342, acc=0.9613333344459534, loss=0.12115620076656342
test: epoch 100, loss 1.6327217817306519, acc=0.5888888835906982, loss=1.6327217817306519
train: epoch 101, loss 0.1350870430469513, acc=0.9583888649940491, loss=0.1350870430469513
test: epoch 101, loss 1.4953163862228394, acc=0.6138888597488403, loss=1.4953163862228394
train: epoch 102, loss 0.1111520454287529, acc=0.9632222056388855, loss=0.1111520454287529
test: epoch 102, loss 1.7810510396957397, acc=0.5833333134651184, loss=1.7810510396957397
train: epoch 103, loss 0.12631529569625854, acc=0.9618889093399048, loss=0.12631529569625854
test: epoch 103, loss 1.642341136932373, acc=0.6027777791023254, loss=1.642341136932373
train: epoch 104, loss 0.12366538494825363, acc=0.9618889093399048, loss=0.12366538494825363
test: epoch 104, loss 1.4811064004898071, acc=0.6333333253860474, loss=1.4811064004898071
train: epoch 105, loss 0.12281941622495651, acc=0.9601666927337646, loss=0.12281941622495651
test: epoch 105, loss 1.5439419746398926, acc=0.6388888955116272, loss=1.5439419746398926
train: epoch 106, loss 0.11825980246067047, acc=0.9619444608688354, loss=0.11825980246067047
test: epoch 106, loss 1.590457558631897, acc=0.625, loss=1.590457558631897
train: epoch 107, loss 0.13070963323116302, acc=0.9586666822433472, loss=0.13070963323116302
test: epoch 107, loss 1.3157697916030884, acc=0.644444465637207, loss=1.3157697916030884
train: epoch 108, loss 0.12795594334602356, acc=0.9603888988494873, loss=0.12795594334602356
test: epoch 108, loss 1.4873360395431519, acc=0.6222222447395325, loss=1.4873360395431519
train: epoch 109, loss 0.13216793537139893, acc=0.961555540561676, loss=0.13216793537139893
test: epoch 109, loss 1.2355430126190186, acc=0.6972222328186035, loss=1.2355430126190186
train: epoch 110, loss 0.11593402177095413, acc=0.9642778038978577, loss=0.11593402177095413
test: epoch 110, loss 1.4415825605392456, acc=0.6694444417953491, loss=1.4415825605392456
train: epoch 111, loss 0.12174168229103088, acc=0.9622777700424194, loss=0.12174168229103088
test: epoch 111, loss 1.4365589618682861, acc=0.6333333253860474, loss=1.4365589618682861
train: epoch 112, loss 0.12186266481876373, acc=0.9632777571678162, loss=0.12186266481876373
test: epoch 112, loss 1.2913386821746826, acc=0.675000011920929, loss=1.2913386821746826
train: epoch 113, loss 0.12449023127555847, acc=0.9619444608688354, loss=0.12449023127555847
test: epoch 113, loss 1.289640188217163, acc=0.6555555462837219, loss=1.289640188217163
train: epoch 114, loss 0.11379630118608475, acc=0.9642221927642822, loss=0.11379630118608475
test: epoch 114, loss 1.4255096912384033, acc=0.6361111402511597, loss=1.4255096912384033
train: epoch 115, loss 0.12725205719470978, acc=0.9608888626098633, loss=0.12725205719470978
test: epoch 115, loss 1.1802246570587158, acc=0.7027778029441833, loss=1.1802246570587158
train: epoch 116, loss 0.11841781437397003, acc=0.964388906955719, loss=0.11841781437397003
test: epoch 116, loss 1.3575692176818848, acc=0.7111111283302307, loss=1.3575692176818848
train: epoch 117, loss 0.12985098361968994, acc=0.9608333110809326, loss=0.12985098361968994
test: epoch 117, loss 1.199197769165039, acc=0.6944444179534912, loss=1.199197769165039
train: epoch 118, loss 0.12427093833684921, acc=0.9608888626098633, loss=0.12427093833684921
test: epoch 118, loss 1.2228553295135498, acc=0.7166666388511658, loss=1.2228553295135498
train: epoch 119, loss 0.12448081374168396, acc=0.9611111283302307, loss=0.12448081374168396
test: epoch 119, loss 1.089683175086975, acc=0.7027778029441833, loss=1.089683175086975
train: epoch 120, loss 0.12159550189971924, acc=0.960277795791626, loss=0.12159550189971924
test: epoch 120, loss 1.1854609251022339, acc=0.675000011920929, loss=1.1854609251022339
train: epoch 121, loss 0.137269526720047, acc=0.960277795791626, loss=0.137269526720047
test: epoch 121, loss 1.1613821983337402, acc=0.7111111283302307, loss=1.1613821983337402
train: epoch 122, loss 0.11478574573993683, acc=0.9641110897064209, loss=0.11478574573993683
test: epoch 122, loss 1.0661431550979614, acc=0.7111111283302307, loss=1.0661431550979614
train: epoch 123, loss 0.133859783411026, acc=0.960777759552002, loss=0.133859783411026
test: epoch 123, loss 1.2867357730865479, acc=0.6944444179534912, loss=1.2867357730865479
train: epoch 124, loss 0.13082827627658844, acc=0.9583888649940491, loss=0.13082827627658844
test: epoch 124, loss 1.0471007823944092, acc=0.7166666388511658, loss=1.0471007823944092
train: epoch 125, loss 0.126750186085701, acc=0.960277795791626, loss=0.126750186085701
test: epoch 125, loss 1.0935642719268799, acc=0.7277777791023254, loss=1.0935642719268799
train: epoch 126, loss 0.12460067123174667, acc=0.9637222290039062, loss=0.12460067123174667
test: epoch 126, loss 1.2225691080093384, acc=0.699999988079071, loss=1.2225691080093384
train: epoch 127, loss 0.11909254640340805, acc=0.9642221927642822, loss=0.11909254640340805
test: epoch 127, loss 1.0720293521881104, acc=0.7222222089767456, loss=1.0720293521881104
train: epoch 128, loss 0.12528550624847412, acc=0.9626666903495789, loss=0.12528550624847412
test: epoch 128, loss 1.2533605098724365, acc=0.7138888835906982, loss=1.2533605098724365
train: epoch 129, loss 0.11426512151956558, acc=0.964555561542511, loss=0.11426512151956558
test: epoch 129, loss 1.1156471967697144, acc=0.7277777791023254, loss=1.1156471967697144
train: epoch 130, loss 0.12382107973098755, acc=0.9610000252723694, loss=0.12382107973098755
test: epoch 130, loss 1.149458885192871, acc=0.7333333492279053, loss=1.149458885192871
train: epoch 131, loss 0.12435606867074966, acc=0.961388885974884, loss=0.12435606867074966
test: epoch 131, loss 0.8376150727272034, acc=0.7527777552604675, loss=0.8376150727272034
train: epoch 132, loss 0.12274453043937683, acc=0.964388906955719, loss=0.12274453043937683
test: epoch 132, loss 1.1277837753295898, acc=0.7388888597488403, loss=1.1277837753295898
train: epoch 133, loss 0.11624686419963837, acc=0.9642221927642822, loss=0.11624686419963837
test: epoch 133, loss 0.906189501285553, acc=0.7611111402511597, loss=0.906189501285553
train: epoch 134, loss 0.12477819621562958, acc=0.9622222185134888, loss=0.12477819621562958
test: epoch 134, loss 0.9619799256324768, acc=0.7611111402511597, loss=0.9619799256324768
train: epoch 135, loss 0.11490054428577423, acc=0.964555561542511, loss=0.11490054428577423
test: epoch 135, loss 0.961766242980957, acc=0.7749999761581421, loss=0.961766242980957
train: epoch 136, loss 0.11434982717037201, acc=0.9629444479942322, loss=0.11434982717037201
test: epoch 136, loss 0.8371631503105164, acc=0.7749999761581421, loss=0.8371631503105164
train: epoch 137, loss 0.13180889189243317, acc=0.9586111307144165, loss=0.13180889189243317
test: epoch 137, loss 0.8133904337882996, acc=0.7555555701255798, loss=0.8133904337882996
train: epoch 138, loss 0.12203305959701538, acc=0.9608333110809326, loss=0.12203305959701538
test: epoch 138, loss 0.8358566761016846, acc=0.7472222447395325, loss=0.8358566761016846
train: epoch 139, loss 0.12011976540088654, acc=0.9620555639266968, loss=0.12011976540088654
test: epoch 139, loss 0.8974066972732544, acc=0.7777777910232544, loss=0.8974066972732544
train: epoch 140, loss 0.1124165952205658, acc=0.9637222290039062, loss=0.1124165952205658
test: epoch 140, loss 0.8697038888931274, acc=0.7638888955116272, loss=0.8697038888931274
train: epoch 141, loss 0.12060472369194031, acc=0.9627777934074402, loss=0.12060472369194031
test: epoch 141, loss 0.7689515352249146, acc=0.7555555701255798, loss=0.7689515352249146
train: epoch 142, loss 0.12175371497869492, acc=0.9613333344459534, loss=0.12175371497869492
test: epoch 142, loss 0.791392982006073, acc=0.7749999761581421, loss=0.791392982006073
train: epoch 143, loss 0.11704958975315094, acc=0.9632222056388855, loss=0.11704958975315094
test: epoch 143, loss 0.7899852395057678, acc=0.7805555462837219, loss=0.7899852395057678
train: epoch 144, loss 0.11679210513830185, acc=0.9636666774749756, loss=0.11679210513830185
test: epoch 144, loss 0.7979273796081543, acc=0.7861111164093018, loss=0.7979273796081543
train: epoch 145, loss 0.12047333270311356, acc=0.9634444713592529, loss=0.12047333270311356
test: epoch 145, loss 0.8653995990753174, acc=0.7833333611488342, loss=0.8653995990753174
train: epoch 146, loss 0.11237538605928421, acc=0.9665555357933044, loss=0.11237538605928421
test: epoch 146, loss 0.8666025400161743, acc=0.7916666865348816, loss=0.8666025400161743
train: epoch 147, loss 0.12086289376020432, acc=0.9622222185134888, loss=0.12086289376020432
test: epoch 147, loss 0.7781962156295776, acc=0.8055555820465088, loss=0.7781962156295776
train: epoch 148, loss 0.1199801042675972, acc=0.9636111259460449, loss=0.1199801042675972
test: epoch 148, loss 0.9914796948432922, acc=0.7611111402511597, loss=0.9914796948432922
train: epoch 149, loss 0.11309146136045456, acc=0.9638888835906982, loss=0.11309146136045456
test: epoch 149, loss 0.6924719214439392, acc=0.8027777671813965, loss=0.6924719214439392
train: epoch 150, loss 0.11255249381065369, acc=0.9627222418785095, loss=0.11255249381065369
test: epoch 150, loss 0.8941340446472168, acc=0.7722222208976746, loss=0.8941340446472168
