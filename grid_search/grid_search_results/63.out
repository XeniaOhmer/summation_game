# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=1", "--temp_decay=0.995", "--one_hot=false", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1508805381, receiver_embed_dim=64, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.451331853866577, acc=0.04777777940034866, loss=3.451331853866577
test: epoch 1, loss 3.403872489929199, acc=0.0555555559694767, loss=3.403872489929199
train: epoch 2, loss 2.5390305519104004, acc=0.14661110937595367, loss=2.5390305519104004
test: epoch 2, loss 2.3037092685699463, acc=0.14166666567325592, loss=2.3037092685699463
train: epoch 3, loss 1.8889657258987427, acc=0.25911110639572144, loss=1.8889657258987427
test: epoch 3, loss 2.1715855598449707, acc=0.16388888657093048, loss=2.1715855598449707
train: epoch 4, loss 1.7073060274124146, acc=0.31216666102409363, loss=1.7073060274124146
test: epoch 4, loss 2.0552337169647217, acc=0.17777778208255768, loss=2.0552337169647217
train: epoch 5, loss 1.5665700435638428, acc=0.35677778720855713, loss=1.5665700435638428
test: epoch 5, loss 2.1071486473083496, acc=0.17777778208255768, loss=2.1071486473083496
train: epoch 6, loss 1.4953503608703613, acc=0.38083332777023315, loss=1.4953503608703613
test: epoch 6, loss 1.9950611591339111, acc=0.19166666269302368, loss=1.9950611591339111
train: epoch 7, loss 1.4229272603988647, acc=0.4111666679382324, loss=1.4229272603988647
test: epoch 7, loss 2.0296285152435303, acc=0.19722221791744232, loss=2.0296285152435303
train: epoch 8, loss 1.3715951442718506, acc=0.42577776312828064, loss=1.3715951442718506
test: epoch 8, loss 2.0186188220977783, acc=0.19722221791744232, loss=2.0186188220977783
train: epoch 9, loss 1.3270418643951416, acc=0.44661110639572144, loss=1.3270418643951416
test: epoch 9, loss 2.007002830505371, acc=0.21111111342906952, loss=2.007002830505371
train: epoch 10, loss 1.2941571474075317, acc=0.46044445037841797, loss=1.2941571474075317
test: epoch 10, loss 2.0829851627349854, acc=0.21944443881511688, loss=2.0829851627349854
train: epoch 11, loss 1.2740217447280884, acc=0.4658888876438141, loss=1.2740217447280884
test: epoch 11, loss 2.0905513763427734, acc=0.19722221791744232, loss=2.0905513763427734
train: epoch 12, loss 1.2454707622528076, acc=0.47661110758781433, loss=1.2454707622528076
test: epoch 12, loss 2.059382915496826, acc=0.21944443881511688, loss=2.059382915496826
train: epoch 13, loss 1.2203643321990967, acc=0.4792777895927429, loss=1.2203643321990967
test: epoch 13, loss 2.0713789463043213, acc=0.2222222238779068, loss=2.0713789463043213
train: epoch 14, loss 1.1926828622817993, acc=0.4846111238002777, loss=1.1926828622817993
test: epoch 14, loss 2.0505075454711914, acc=0.23055554926395416, loss=2.0505075454711914
train: epoch 15, loss 1.1807653903961182, acc=0.4950000047683716, loss=1.1807653903961182
test: epoch 15, loss 2.085310697555542, acc=0.2361111044883728, loss=2.085310697555542
train: epoch 16, loss 1.175299882888794, acc=0.4948333203792572, loss=1.175299882888794
test: epoch 16, loss 1.95937180519104, acc=0.22499999403953552, loss=1.95937180519104
train: epoch 17, loss 1.171722650527954, acc=0.4981110990047455, loss=1.171722650527954
test: epoch 17, loss 2.0883312225341797, acc=0.21666666865348816, loss=2.0883312225341797
train: epoch 18, loss 1.1465797424316406, acc=0.5019444227218628, loss=1.1465797424316406
test: epoch 18, loss 2.043833017349243, acc=0.23333333432674408, loss=2.043833017349243
train: epoch 19, loss 1.1308282613754272, acc=0.5073333382606506, loss=1.1308282613754272
test: epoch 19, loss 2.0229828357696533, acc=0.23055554926395416, loss=2.0229828357696533
train: epoch 20, loss 1.1177958250045776, acc=0.5117777585983276, loss=1.1177958250045776
test: epoch 20, loss 2.078226089477539, acc=0.24444444477558136, loss=2.078226089477539
train: epoch 21, loss 1.124251127243042, acc=0.5097777843475342, loss=1.124251127243042
test: epoch 21, loss 1.9309651851654053, acc=0.24722221493721008, loss=1.9309651851654053
train: epoch 22, loss 1.1135590076446533, acc=0.5146666765213013, loss=1.1135590076446533
test: epoch 22, loss 2.054983139038086, acc=0.25, loss=2.054983139038086
train: epoch 23, loss 1.106626033782959, acc=0.5143333077430725, loss=1.106626033782959
test: epoch 23, loss 2.074742317199707, acc=0.2527777850627899, loss=2.074742317199707
train: epoch 24, loss 1.0901509523391724, acc=0.5228333473205566, loss=1.0901509523391724
test: epoch 24, loss 2.101349353790283, acc=0.25555557012557983, loss=2.101349353790283
train: epoch 25, loss 1.0919548273086548, acc=0.5205000042915344, loss=1.0919548273086548
test: epoch 25, loss 2.051802396774292, acc=0.25833332538604736, loss=2.051802396774292
train: epoch 26, loss 1.071491003036499, acc=0.5295555591583252, loss=1.071491003036499
test: epoch 26, loss 2.0858709812164307, acc=0.2666666805744171, loss=2.0858709812164307
train: epoch 27, loss 1.0723384618759155, acc=0.5269444584846497, loss=1.0723384618759155
test: epoch 27, loss 2.04484486579895, acc=0.26944443583488464, loss=2.04484486579895
train: epoch 28, loss 1.067130208015442, acc=0.5336111187934875, loss=1.067130208015442
test: epoch 28, loss 2.103285551071167, acc=0.2638888955116272, loss=2.103285551071167
train: epoch 29, loss 1.0509988069534302, acc=0.5380555391311646, loss=1.0509988069534302
test: epoch 29, loss 2.1146562099456787, acc=0.2638888955116272, loss=2.1146562099456787
train: epoch 30, loss 1.0556037425994873, acc=0.5368888974189758, loss=1.0556037425994873
test: epoch 30, loss 2.0803139209747314, acc=0.2638888955116272, loss=2.0803139209747314
train: epoch 31, loss 1.0455446243286133, acc=0.5426666736602783, loss=1.0455446243286133
test: epoch 31, loss 2.164785385131836, acc=0.25555557012557983, loss=2.164785385131836
train: epoch 32, loss 1.0352505445480347, acc=0.5379999876022339, loss=1.0352505445480347
test: epoch 32, loss 2.1667680740356445, acc=0.2638888955116272, loss=2.1667680740356445
train: epoch 33, loss 1.0408347845077515, acc=0.5413333177566528, loss=1.0408347845077515
test: epoch 33, loss 2.0706369876861572, acc=0.2638888955116272, loss=2.0706369876861572
train: epoch 34, loss 1.0241491794586182, acc=0.5473889112472534, loss=1.0241491794586182
test: epoch 34, loss 2.1171579360961914, acc=0.2611111104488373, loss=2.1171579360961914
train: epoch 35, loss 1.020658016204834, acc=0.5484444499015808, loss=1.020658016204834
test: epoch 35, loss 2.005800485610962, acc=0.2750000059604645, loss=2.005800485610962
train: epoch 36, loss 1.0264984369277954, acc=0.5471110939979553, loss=1.0264984369277954
test: epoch 36, loss 2.141805410385132, acc=0.2750000059604645, loss=2.141805410385132
train: epoch 37, loss 1.0181405544281006, acc=0.5541666746139526, loss=1.0181405544281006
test: epoch 37, loss 2.144867420196533, acc=0.26944443583488464, loss=2.144867420196533
train: epoch 38, loss 1.0045795440673828, acc=0.5565000176429749, loss=1.0045795440673828
test: epoch 38, loss 2.0124831199645996, acc=0.28611111640930176, loss=2.0124831199645996
train: epoch 39, loss 1.007765531539917, acc=0.5496110916137695, loss=1.007765531539917
test: epoch 39, loss 2.151186227798462, acc=0.28333333134651184, loss=2.151186227798462
train: epoch 40, loss 1.0006648302078247, acc=0.5581111311912537, loss=1.0006648302078247
test: epoch 40, loss 2.1162736415863037, acc=0.2777777910232544, loss=2.1162736415863037
train: epoch 41, loss 1.0094949007034302, acc=0.5571110844612122, loss=1.0094949007034302
test: epoch 41, loss 2.031238555908203, acc=0.2805555462837219, loss=2.031238555908203
train: epoch 42, loss 1.0091280937194824, acc=0.555055558681488, loss=1.0091280937194824
test: epoch 42, loss 2.16374135017395, acc=0.2777777910232544, loss=2.16374135017395
train: epoch 43, loss 1.0003973245620728, acc=0.5610555410385132, loss=1.0003973245620728
test: epoch 43, loss 2.078258752822876, acc=0.27222222089767456, loss=2.078258752822876
train: epoch 44, loss 1.0041190385818481, acc=0.5579444169998169, loss=1.0041190385818481
test: epoch 44, loss 2.1142349243164062, acc=0.2916666567325592, loss=2.1142349243164062
train: epoch 45, loss 1.001976728439331, acc=0.5572222471237183, loss=1.001976728439331
test: epoch 45, loss 1.9765100479125977, acc=0.2805555462837219, loss=1.9765100479125977
train: epoch 46, loss 1.0003445148468018, acc=0.5573333501815796, loss=1.0003445148468018
test: epoch 46, loss 2.0068135261535645, acc=0.2944444417953491, loss=2.0068135261535645
train: epoch 47, loss 0.9873493909835815, acc=0.5591111183166504, loss=0.9873493909835815
test: epoch 47, loss 2.019784688949585, acc=0.28611111640930176, loss=2.019784688949585
train: epoch 48, loss 0.989723801612854, acc=0.5655555725097656, loss=0.989723801612854
test: epoch 48, loss 2.0319910049438477, acc=0.29722222685813904, loss=2.0319910049438477
train: epoch 49, loss 0.9882615208625793, acc=0.5673888921737671, loss=0.9882615208625793
test: epoch 49, loss 2.075937271118164, acc=0.29722222685813904, loss=2.075937271118164
train: epoch 50, loss 0.979108989238739, acc=0.5635555386543274, loss=0.979108989238739
test: epoch 50, loss 2.0908701419830322, acc=0.3027777671813965, loss=2.0908701419830322
train: epoch 51, loss 0.9823316931724548, acc=0.5647222399711609, loss=0.9823316931724548
test: epoch 51, loss 1.9334686994552612, acc=0.3027777671813965, loss=1.9334686994552612
train: epoch 52, loss 0.9895315766334534, acc=0.5631111264228821, loss=0.9895315766334534
test: epoch 52, loss 2.004859685897827, acc=0.2944444417953491, loss=2.004859685897827
train: epoch 53, loss 0.987160861492157, acc=0.562833309173584, loss=0.987160861492157
test: epoch 53, loss 2.1149466037750244, acc=0.3055555522441864, loss=2.1149466037750244
train: epoch 54, loss 0.9827967882156372, acc=0.5662222504615784, loss=0.9827967882156372
test: epoch 54, loss 1.9936561584472656, acc=0.3055555522441864, loss=1.9936561584472656
train: epoch 55, loss 0.9709063172340393, acc=0.5713889002799988, loss=0.9709063172340393
test: epoch 55, loss 2.0213334560394287, acc=0.31111112236976624, loss=2.0213334560394287
train: epoch 56, loss 0.9803280830383301, acc=0.5692222118377686, loss=0.9803280830383301
test: epoch 56, loss 2.0790085792541504, acc=0.3055555522441864, loss=2.0790085792541504
train: epoch 57, loss 0.9797354936599731, acc=0.5688333511352539, loss=0.9797354936599731
test: epoch 57, loss 1.9730496406555176, acc=0.3027777671813965, loss=1.9730496406555176
train: epoch 58, loss 0.9836430549621582, acc=0.5660555362701416, loss=0.9836430549621582
test: epoch 58, loss 1.9934124946594238, acc=0.31111112236976624, loss=1.9934124946594238
train: epoch 59, loss 0.9704338312149048, acc=0.5681111216545105, loss=0.9704338312149048
test: epoch 59, loss 1.9993808269500732, acc=0.3083333373069763, loss=1.9993808269500732
train: epoch 60, loss 0.9700750112533569, acc=0.5702221989631653, loss=0.9700750112533569
test: epoch 60, loss 2.1417057514190674, acc=0.31111112236976624, loss=2.1417057514190674
train: epoch 61, loss 0.9576042294502258, acc=0.5680000185966492, loss=0.9576042294502258
test: epoch 61, loss 1.9280402660369873, acc=0.31111112236976624, loss=1.9280402660369873
train: epoch 62, loss 0.9550256729125977, acc=0.5693888664245605, loss=0.9550256729125977
test: epoch 62, loss 2.0157017707824707, acc=0.31111112236976624, loss=2.0157017707824707
train: epoch 63, loss 0.9582895636558533, acc=0.5758333206176758, loss=0.9582895636558533
test: epoch 63, loss 1.9885966777801514, acc=0.3083333373069763, loss=1.9885966777801514
train: epoch 64, loss 0.9636305570602417, acc=0.5713333487510681, loss=0.9636305570602417
test: epoch 64, loss 2.0347254276275635, acc=0.3166666626930237, loss=2.0347254276275635
train: epoch 65, loss 0.9493070244789124, acc=0.5751110911369324, loss=0.9493070244789124
test: epoch 65, loss 2.019115924835205, acc=0.31111112236976624, loss=2.019115924835205
train: epoch 66, loss 0.9445797801017761, acc=0.5766111016273499, loss=0.9445797801017761
test: epoch 66, loss 2.2695751190185547, acc=0.28611111640930176, loss=2.2695751190185547
train: epoch 67, loss 0.9540970325469971, acc=0.5772222280502319, loss=0.9540970325469971
test: epoch 67, loss 1.9385974407196045, acc=0.3083333373069763, loss=1.9385974407196045
train: epoch 68, loss 0.9494632482528687, acc=0.574833333492279, loss=0.9494632482528687
test: epoch 68, loss 1.9811601638793945, acc=0.31388887763023376, loss=1.9811601638793945
train: epoch 69, loss 0.9476081132888794, acc=0.5772777795791626, loss=0.9476081132888794
test: epoch 69, loss 2.252088785171509, acc=0.3166666626930237, loss=2.252088785171509
train: epoch 70, loss 0.9467606544494629, acc=0.5720555782318115, loss=0.9467606544494629
test: epoch 70, loss 1.9793486595153809, acc=0.3166666626930237, loss=1.9793486595153809
train: epoch 71, loss 0.9485305547714233, acc=0.5756666660308838, loss=0.9485305547714233
test: epoch 71, loss 2.0760552883148193, acc=0.3166666626930237, loss=2.0760552883148193
train: epoch 72, loss 0.9390977621078491, acc=0.5809444189071655, loss=0.9390977621078491
test: epoch 72, loss 2.054978132247925, acc=0.3222222328186035, loss=2.054978132247925
train: epoch 73, loss 0.9412074685096741, acc=0.5823333263397217, loss=0.9412074685096741
test: epoch 73, loss 1.9441399574279785, acc=0.3166666626930237, loss=1.9441399574279785
train: epoch 74, loss 0.9349014163017273, acc=0.5833333134651184, loss=0.9349014163017273
test: epoch 74, loss 2.0410730838775635, acc=0.3194444477558136, loss=2.0410730838775635
train: epoch 75, loss 0.9335981011390686, acc=0.5824999809265137, loss=0.9335981011390686
test: epoch 75, loss 1.9275532960891724, acc=0.3194444477558136, loss=1.9275532960891724
train: epoch 76, loss 0.9405685663223267, acc=0.5807777643203735, loss=0.9405685663223267
test: epoch 76, loss 2.057939291000366, acc=0.31388887763023376, loss=2.057939291000366
train: epoch 77, loss 0.936798632144928, acc=0.5820555686950684, loss=0.936798632144928
test: epoch 77, loss 2.100519895553589, acc=0.3083333373069763, loss=2.100519895553589
train: epoch 78, loss 0.9303947687149048, acc=0.5833333134651184, loss=0.9303947687149048
test: epoch 78, loss 2.1046152114868164, acc=0.3166666626930237, loss=2.1046152114868164
train: epoch 79, loss 0.9346016645431519, acc=0.5800555348396301, loss=0.9346016645431519
test: epoch 79, loss 1.975870132446289, acc=0.3166666626930237, loss=1.975870132446289
train: epoch 80, loss 0.9296078681945801, acc=0.5826666951179504, loss=0.9296078681945801
test: epoch 80, loss 1.938796877861023, acc=0.3166666626930237, loss=1.938796877861023
train: epoch 81, loss 0.9234551191329956, acc=0.586722195148468, loss=0.9234551191329956
test: epoch 81, loss 2.239680767059326, acc=0.32499998807907104, loss=2.239680767059326
train: epoch 82, loss 0.9374029040336609, acc=0.5841110944747925, loss=0.9374029040336609
test: epoch 82, loss 2.1145553588867188, acc=0.3194444477558136, loss=2.1145553588867188
train: epoch 83, loss 0.916317880153656, acc=0.5892221927642822, loss=0.916317880153656
test: epoch 83, loss 2.243518352508545, acc=0.3194444477558136, loss=2.243518352508545
train: epoch 84, loss 0.9322859048843384, acc=0.5828333497047424, loss=0.9322859048843384
test: epoch 84, loss 2.0239033699035645, acc=0.3222222328186035, loss=2.0239033699035645
train: epoch 85, loss 0.9120259284973145, acc=0.592555582523346, loss=0.9120259284973145
test: epoch 85, loss 2.1944737434387207, acc=0.32777777314186096, loss=2.1944737434387207
train: epoch 86, loss 0.9208486080169678, acc=0.5880555510520935, loss=0.9208486080169678
test: epoch 86, loss 2.2110865116119385, acc=0.3194444477558136, loss=2.2110865116119385
train: epoch 87, loss 0.9229472279548645, acc=0.5897777676582336, loss=0.9229472279548645
test: epoch 87, loss 2.1651198863983154, acc=0.32499998807907104, loss=2.1651198863983154
train: epoch 88, loss 0.9111335873603821, acc=0.5923888683319092, loss=0.9111335873603821
test: epoch 88, loss 2.183448076248169, acc=0.32777777314186096, loss=2.183448076248169
train: epoch 89, loss 0.920512855052948, acc=0.5879444479942322, loss=0.920512855052948
test: epoch 89, loss 1.9566431045532227, acc=0.32499998807907104, loss=1.9566431045532227
train: epoch 90, loss 0.9124945998191833, acc=0.5896666646003723, loss=0.9124945998191833
test: epoch 90, loss 1.9556978940963745, acc=0.3222222328186035, loss=1.9556978940963745
train: epoch 91, loss 0.9171973466873169, acc=0.5930555462837219, loss=0.9171973466873169
test: epoch 91, loss 2.0535483360290527, acc=0.32777777314186096, loss=2.0535483360290527
train: epoch 92, loss 0.9151675701141357, acc=0.5926666855812073, loss=0.9151675701141357
test: epoch 92, loss 2.021826982498169, acc=0.3222222328186035, loss=2.021826982498169
train: epoch 93, loss 0.9205348491668701, acc=0.5913333296775818, loss=0.9205348491668701
test: epoch 93, loss 2.0036962032318115, acc=0.3166666626930237, loss=2.0036962032318115
train: epoch 94, loss 0.9108197689056396, acc=0.5924999713897705, loss=0.9108197689056396
test: epoch 94, loss 1.998084545135498, acc=0.32499998807907104, loss=1.998084545135498
train: epoch 95, loss 0.9163188934326172, acc=0.593833327293396, loss=0.9163188934326172
test: epoch 95, loss 2.155996322631836, acc=0.32499998807907104, loss=2.155996322631836
train: epoch 96, loss 0.9048587679862976, acc=0.5951666831970215, loss=0.9048587679862976
test: epoch 96, loss 2.0017595291137695, acc=0.3305555582046509, loss=2.0017595291137695
train: epoch 97, loss 0.9123087525367737, acc=0.5909444689750671, loss=0.9123087525367737
test: epoch 97, loss 2.1501035690307617, acc=0.3194444477558136, loss=2.1501035690307617
train: epoch 98, loss 0.906089186668396, acc=0.5923888683319092, loss=0.906089186668396
test: epoch 98, loss 2.2756433486938477, acc=0.3361110985279083, loss=2.2756433486938477
train: epoch 99, loss 0.8990342020988464, acc=0.5958889126777649, loss=0.8990342020988464
test: epoch 99, loss 2.1326260566711426, acc=0.3472222089767456, loss=2.1326260566711426
train: epoch 100, loss 0.9086180329322815, acc=0.5960000157356262, loss=0.9086180329322815
test: epoch 100, loss 2.0277631282806396, acc=0.3305555582046509, loss=2.0277631282806396
train: epoch 101, loss 0.9176158905029297, acc=0.5914999842643738, loss=0.9176158905029297
test: epoch 101, loss 2.061878204345703, acc=0.3166666626930237, loss=2.061878204345703
train: epoch 102, loss 0.9176409244537354, acc=0.5921666622161865, loss=0.9176409244537354
test: epoch 102, loss 2.14630126953125, acc=0.33888888359069824, loss=2.14630126953125
train: epoch 103, loss 0.8994027376174927, acc=0.5974444150924683, loss=0.8994027376174927
test: epoch 103, loss 2.2393813133239746, acc=0.34166666865348816, loss=2.2393813133239746
train: epoch 104, loss 0.9025160074234009, acc=0.5955555438995361, loss=0.9025160074234009
test: epoch 104, loss 1.9358690977096558, acc=0.3361110985279083, loss=1.9358690977096558
train: epoch 105, loss 0.8998962640762329, acc=0.5987777709960938, loss=0.8998962640762329
test: epoch 105, loss 2.033477544784546, acc=0.32499998807907104, loss=2.033477544784546
train: epoch 106, loss 0.909828245639801, acc=0.5987222194671631, loss=0.909828245639801
test: epoch 106, loss 2.2021303176879883, acc=0.3361110985279083, loss=2.2021303176879883
train: epoch 107, loss 0.8995561599731445, acc=0.5968888998031616, loss=0.8995561599731445
test: epoch 107, loss 2.235382556915283, acc=0.3472222089767456, loss=2.235382556915283
train: epoch 108, loss 0.9032194018363953, acc=0.5972222089767456, loss=0.9032194018363953
test: epoch 108, loss 2.0727508068084717, acc=0.33888888359069824, loss=2.0727508068084717
train: epoch 109, loss 0.903324544429779, acc=0.5985555648803711, loss=0.903324544429779
test: epoch 109, loss 2.107077121734619, acc=0.3444444537162781, loss=2.107077121734619
train: epoch 110, loss 0.9056152105331421, acc=0.5971666574478149, loss=0.9056152105331421
test: epoch 110, loss 1.847658634185791, acc=0.3499999940395355, loss=1.847658634185791
train: epoch 111, loss 0.903552234172821, acc=0.593999981880188, loss=0.903552234172821
test: epoch 111, loss 2.049150228500366, acc=0.33888888359069824, loss=2.049150228500366
train: epoch 112, loss 0.8933518528938293, acc=0.6004999876022339, loss=0.8933518528938293
test: epoch 112, loss 2.0859124660491943, acc=0.3472222089767456, loss=2.0859124660491943
train: epoch 113, loss 0.903986930847168, acc=0.5991111397743225, loss=0.903986930847168
test: epoch 113, loss 2.1815896034240723, acc=0.3472222089767456, loss=2.1815896034240723
train: epoch 114, loss 0.9006044268608093, acc=0.5993333458900452, loss=0.9006044268608093
test: epoch 114, loss 1.9404722452163696, acc=0.3166666626930237, loss=1.9404722452163696
train: epoch 115, loss 0.9002234935760498, acc=0.6000000238418579, loss=0.9002234935760498
test: epoch 115, loss 2.1344621181488037, acc=0.3333333432674408, loss=2.1344621181488037
train: epoch 116, loss 0.8867868781089783, acc=0.6054999828338623, loss=0.8867868781089783
test: epoch 116, loss 2.1595468521118164, acc=0.34166666865348816, loss=2.1595468521118164
train: epoch 117, loss 0.8974775671958923, acc=0.6011666655540466, loss=0.8974775671958923
test: epoch 117, loss 2.0790719985961914, acc=0.3361110985279083, loss=2.0790719985961914
train: epoch 118, loss 0.8978462815284729, acc=0.6010000109672546, loss=0.8978462815284729
test: epoch 118, loss 2.1913647651672363, acc=0.34166666865348816, loss=2.1913647651672363
train: epoch 119, loss 0.9045978784561157, acc=0.5981666445732117, loss=0.9045978784561157
test: epoch 119, loss 2.1632080078125, acc=0.33888888359069824, loss=2.1632080078125
train: epoch 120, loss 0.8860623240470886, acc=0.6006666421890259, loss=0.8860623240470886
test: epoch 120, loss 2.1347508430480957, acc=0.34166666865348816, loss=2.1347508430480957
train: epoch 121, loss 0.8954159617424011, acc=0.6037777662277222, loss=0.8954159617424011
test: epoch 121, loss 2.105154037475586, acc=0.3472222089767456, loss=2.105154037475586
train: epoch 122, loss 0.895919144153595, acc=0.6023333072662354, loss=0.895919144153595
test: epoch 122, loss 2.092571496963501, acc=0.3361110985279083, loss=2.092571496963501
train: epoch 123, loss 0.8846524953842163, acc=0.6018333435058594, loss=0.8846524953842163
test: epoch 123, loss 2.0636465549468994, acc=0.34166666865348816, loss=2.0636465549468994
train: epoch 124, loss 0.8953458666801453, acc=0.6016111373901367, loss=0.8953458666801453
test: epoch 124, loss 2.2169580459594727, acc=0.33888888359069824, loss=2.2169580459594727
train: epoch 125, loss 0.897054135799408, acc=0.5998333096504211, loss=0.897054135799408
test: epoch 125, loss 1.984435796737671, acc=0.3472222089767456, loss=1.984435796737671
train: epoch 126, loss 0.9013820886611938, acc=0.601277768611908, loss=0.9013820886611938
test: epoch 126, loss 2.0068392753601074, acc=0.34166666865348816, loss=2.0068392753601074
train: epoch 127, loss 0.8890947699546814, acc=0.6046110987663269, loss=0.8890947699546814
test: epoch 127, loss 2.1625163555145264, acc=0.3444444537162781, loss=2.1625163555145264
train: epoch 128, loss 0.8888006210327148, acc=0.6028888821601868, loss=0.8888006210327148
test: epoch 128, loss 2.2549045085906982, acc=0.33888888359069824, loss=2.2549045085906982
train: epoch 129, loss 0.8908823728561401, acc=0.601111114025116, loss=0.8908823728561401
test: epoch 129, loss 1.8766437768936157, acc=0.3472222089767456, loss=1.8766437768936157
train: epoch 130, loss 0.891156017780304, acc=0.6034444570541382, loss=0.891156017780304
test: epoch 130, loss 2.066926956176758, acc=0.3444444537162781, loss=2.066926956176758
train: epoch 131, loss 0.891822099685669, acc=0.601111114025116, loss=0.891822099685669
test: epoch 131, loss 2.0311903953552246, acc=0.33888888359069824, loss=2.0311903953552246
train: epoch 132, loss 0.8946636319160461, acc=0.6023889183998108, loss=0.8946636319160461
test: epoch 132, loss 2.2218849658966064, acc=0.33888888359069824, loss=2.2218849658966064
train: epoch 133, loss 0.8819963932037354, acc=0.6029444336891174, loss=0.8819963932037354
test: epoch 133, loss 2.199737310409546, acc=0.34166666865348816, loss=2.199737310409546
train: epoch 134, loss 0.892827570438385, acc=0.6038333177566528, loss=0.892827570438385
test: epoch 134, loss 2.0680606365203857, acc=0.3361110985279083, loss=2.0680606365203857
train: epoch 135, loss 0.8913073539733887, acc=0.5990555286407471, loss=0.8913073539733887
test: epoch 135, loss 2.1147987842559814, acc=0.35277777910232544, loss=2.1147987842559814
train: epoch 136, loss 0.8758984804153442, acc=0.6056666374206543, loss=0.8758984804153442
test: epoch 136, loss 2.1118550300598145, acc=0.34166666865348816, loss=2.1118550300598145
train: epoch 137, loss 0.8830419778823853, acc=0.6052777767181396, loss=0.8830419778823853
test: epoch 137, loss 2.117518663406372, acc=0.35277777910232544, loss=2.117518663406372
train: epoch 138, loss 0.8913737535476685, acc=0.5995555520057678, loss=0.8913737535476685
test: epoch 138, loss 2.054023504257202, acc=0.34166666865348816, loss=2.054023504257202
train: epoch 139, loss 0.8940235376358032, acc=0.6016111373901367, loss=0.8940235376358032
test: epoch 139, loss 2.1067111492156982, acc=0.3444444537162781, loss=2.1067111492156982
train: epoch 140, loss 0.888843297958374, acc=0.6036666631698608, loss=0.888843297958374
test: epoch 140, loss 2.112751007080078, acc=0.35277777910232544, loss=2.112751007080078
train: epoch 141, loss 0.8827587366104126, acc=0.6037777662277222, loss=0.8827587366104126
test: epoch 141, loss 1.9059733152389526, acc=0.3444444537162781, loss=1.9059733152389526
train: epoch 142, loss 0.8701367974281311, acc=0.6080555319786072, loss=0.8701367974281311
test: epoch 142, loss 2.062561511993408, acc=0.3444444537162781, loss=2.062561511993408
train: epoch 143, loss 0.8672505617141724, acc=0.6087222099304199, loss=0.8672505617141724
test: epoch 143, loss 2.3300247192382812, acc=0.3499999940395355, loss=2.3300247192382812
train: epoch 144, loss 0.883882462978363, acc=0.6069999933242798, loss=0.883882462978363
test: epoch 144, loss 2.234071969985962, acc=0.3444444537162781, loss=2.234071969985962
train: epoch 145, loss 0.8884403705596924, acc=0.6018333435058594, loss=0.8884403705596924
test: epoch 145, loss 2.354813575744629, acc=0.3444444537162781, loss=2.354813575744629
train: epoch 146, loss 0.8732430934906006, acc=0.6084444522857666, loss=0.8732430934906006
test: epoch 146, loss 2.130692720413208, acc=0.3444444537162781, loss=2.130692720413208
train: epoch 147, loss 0.8721314072608948, acc=0.6039999723434448, loss=0.8721314072608948
test: epoch 147, loss 2.1007065773010254, acc=0.34166666865348816, loss=2.1007065773010254
train: epoch 148, loss 0.8801771402359009, acc=0.6044444441795349, loss=0.8801771402359009
test: epoch 148, loss 1.976772427558899, acc=0.3444444537162781, loss=1.976772427558899
train: epoch 149, loss 0.8852566480636597, acc=0.6033889055252075, loss=0.8852566480636597
test: epoch 149, loss 2.1182339191436768, acc=0.3472222089767456, loss=2.1182339191436768
train: epoch 150, loss 0.8604480624198914, acc=0.6107222437858582, loss=0.8604480624198914
test: epoch 150, loss 2.007349967956543, acc=0.3444444537162781, loss=2.007349967956543
