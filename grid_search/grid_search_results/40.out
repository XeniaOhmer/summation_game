# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=1", "--one_hot=false", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1001362127, receiver_embed_dim=32, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.0546188354492188, acc=0.0777222216129303, loss=3.0546188354492188
test: epoch 1, loss 3.8083741664886475, acc=0.09166666865348816, loss=3.8083741664886475
train: epoch 2, loss 1.968027114868164, acc=0.2266666740179062, loss=1.968027114868164
test: epoch 2, loss 4.0019211769104, acc=0.13611111044883728, loss=4.0019211769104
train: epoch 3, loss 1.643216848373413, acc=0.31877776980400085, loss=1.643216848373413
test: epoch 3, loss 4.21268367767334, acc=0.11944444477558136, loss=4.21268367767334
train: epoch 4, loss 1.4588727951049805, acc=0.3806111216545105, loss=1.4588727951049805
test: epoch 4, loss 3.8624789714813232, acc=0.16388888657093048, loss=3.8624789714813232
train: epoch 5, loss 1.2668848037719727, acc=0.47361111640930176, loss=1.2668848037719727
test: epoch 5, loss 4.250857353210449, acc=0.16944444179534912, loss=4.250857353210449
train: epoch 6, loss 1.0139131546020508, acc=0.5748888850212097, loss=1.0139131546020508
test: epoch 6, loss 3.834944009780884, acc=0.1805555522441864, loss=3.834944009780884
train: epoch 7, loss 0.8899129033088684, acc=0.6195555329322815, loss=0.8899129033088684
test: epoch 7, loss 3.63094425201416, acc=0.1666666716337204, loss=3.63094425201416
train: epoch 8, loss 0.7833495140075684, acc=0.6769444346427917, loss=0.7833495140075684
test: epoch 8, loss 3.3599138259887695, acc=0.23333333432674408, loss=3.3599138259887695
train: epoch 9, loss 0.6787883043289185, acc=0.7277777791023254, loss=0.6787883043289185
test: epoch 9, loss 3.9449715614318848, acc=0.21666666865348816, loss=3.9449715614318848
train: epoch 10, loss 0.632479190826416, acc=0.746055543422699, loss=0.632479190826416
test: epoch 10, loss 3.803342819213867, acc=0.22499999403953552, loss=3.803342819213867
train: epoch 11, loss 0.5693243145942688, acc=0.7726666927337646, loss=0.5693243145942688
test: epoch 11, loss 3.1152138710021973, acc=0.24166665971279144, loss=3.1152138710021973
train: epoch 12, loss 0.5259816646575928, acc=0.7986666560173035, loss=0.5259816646575928
test: epoch 12, loss 4.055980205535889, acc=0.20555555820465088, loss=4.055980205535889
train: epoch 13, loss 0.5043927431106567, acc=0.805055558681488, loss=0.5043927431106567
test: epoch 13, loss 3.307917594909668, acc=0.2666666805744171, loss=3.307917594909668
train: epoch 14, loss 0.46339088678359985, acc=0.8255000114440918, loss=0.46339088678359985
test: epoch 14, loss 3.1555392742156982, acc=0.31111112236976624, loss=3.1555392742156982
train: epoch 15, loss 0.41021016240119934, acc=0.846833348274231, loss=0.41021016240119934
test: epoch 15, loss 3.245135545730591, acc=0.2777777910232544, loss=3.245135545730591
train: epoch 16, loss 0.39310014247894287, acc=0.8544999957084656, loss=0.39310014247894287
test: epoch 16, loss 3.2492141723632812, acc=0.3083333373069763, loss=3.2492141723632812
train: epoch 17, loss 0.36406001448631287, acc=0.8683333396911621, loss=0.36406001448631287
test: epoch 17, loss 3.4129137992858887, acc=0.24444444477558136, loss=3.4129137992858887
train: epoch 18, loss 0.34605100750923157, acc=0.8744999766349792, loss=0.34605100750923157
test: epoch 18, loss 2.446470260620117, acc=0.3611111044883728, loss=2.446470260620117
train: epoch 19, loss 0.31793102622032166, acc=0.887666642665863, loss=0.31793102622032166
test: epoch 19, loss 3.082355499267578, acc=0.2916666567325592, loss=3.082355499267578
train: epoch 20, loss 0.32141757011413574, acc=0.8881111145019531, loss=0.32141757011413574
test: epoch 20, loss 2.684835433959961, acc=0.31388887763023376, loss=2.684835433959961
train: epoch 21, loss 0.2749220132827759, acc=0.9053888916969299, loss=0.2749220132827759
test: epoch 21, loss 2.3639919757843018, acc=0.3444444537162781, loss=2.3639919757843018
train: epoch 22, loss 0.27217045426368713, acc=0.9114999771118164, loss=0.27217045426368713
test: epoch 22, loss 2.903350830078125, acc=0.3499999940395355, loss=2.903350830078125
train: epoch 23, loss 0.23869949579238892, acc=0.9201666712760925, loss=0.23869949579238892
test: epoch 23, loss 2.558150053024292, acc=0.38333332538604736, loss=2.558150053024292
train: epoch 24, loss 0.2378031313419342, acc=0.922166645526886, loss=0.2378031313419342
test: epoch 24, loss 2.0682532787323, acc=0.4055555462837219, loss=2.0682532787323
train: epoch 25, loss 0.24536412954330444, acc=0.9162777662277222, loss=0.24536412954330444
test: epoch 25, loss 3.1765496730804443, acc=0.31388887763023376, loss=3.1765496730804443
train: epoch 26, loss 0.20985230803489685, acc=0.93022221326828, loss=0.20985230803489685
test: epoch 26, loss 2.7596476078033447, acc=0.35555556416511536, loss=2.7596476078033447
train: epoch 27, loss 0.20158618688583374, acc=0.9349444508552551, loss=0.20158618688583374
test: epoch 27, loss 2.314028024673462, acc=0.39722222089767456, loss=2.314028024673462
train: epoch 28, loss 0.19724106788635254, acc=0.9329444169998169, loss=0.19724106788635254
test: epoch 28, loss 2.499155282974243, acc=0.3444444537162781, loss=2.499155282974243
train: epoch 29, loss 0.18818052113056183, acc=0.9399444460868835, loss=0.18818052113056183
test: epoch 29, loss 2.9216911792755127, acc=0.35555556416511536, loss=2.9216911792755127
train: epoch 30, loss 0.18727664649486542, acc=0.9379444718360901, loss=0.18727664649486542
test: epoch 30, loss 2.825169563293457, acc=0.3888888955116272, loss=2.825169563293457
train: epoch 31, loss 0.1758098304271698, acc=0.9421111345291138, loss=0.1758098304271698
test: epoch 31, loss 2.2592201232910156, acc=0.4055555462837219, loss=2.2592201232910156
train: epoch 32, loss 0.180812805891037, acc=0.9403333067893982, loss=0.180812805891037
test: epoch 32, loss 2.293856143951416, acc=0.42500001192092896, loss=2.293856143951416
train: epoch 33, loss 0.16288529336452484, acc=0.945555567741394, loss=0.16288529336452484
test: epoch 33, loss 2.332803249359131, acc=0.4305555522441864, loss=2.332803249359131
train: epoch 34, loss 0.16840752959251404, acc=0.9445555806159973, loss=0.16840752959251404
test: epoch 34, loss 2.1612625122070312, acc=0.4444444477558136, loss=2.1612625122070312
train: epoch 35, loss 0.157497376203537, acc=0.9479444622993469, loss=0.157497376203537
test: epoch 35, loss 2.4085845947265625, acc=0.3472222089767456, loss=2.4085845947265625
train: epoch 36, loss 0.15731777250766754, acc=0.9482222199440002, loss=0.15731777250766754
test: epoch 36, loss 2.275254726409912, acc=0.3583333194255829, loss=2.275254726409912
train: epoch 37, loss 0.15173184871673584, acc=0.9496666789054871, loss=0.15173184871673584
test: epoch 37, loss 1.8265732526779175, acc=0.4138889014720917, loss=1.8265732526779175
train: epoch 38, loss 0.15203827619552612, acc=0.949833333492279, loss=0.15203827619552612
test: epoch 38, loss 1.9080203771591187, acc=0.4472222328186035, loss=1.9080203771591187
train: epoch 39, loss 0.14190542697906494, acc=0.9532222151756287, loss=0.14190542697906494
test: epoch 39, loss 1.9719018936157227, acc=0.4694444537162781, loss=1.9719018936157227
train: epoch 40, loss 0.13221564888954163, acc=0.9568333625793457, loss=0.13221564888954163
test: epoch 40, loss 1.9893505573272705, acc=0.46666666865348816, loss=1.9893505573272705
train: epoch 41, loss 0.13251067698001862, acc=0.9556666612625122, loss=0.13251067698001862
test: epoch 41, loss 2.6070659160614014, acc=0.36666667461395264, loss=2.6070659160614014
train: epoch 42, loss 0.12505388259887695, acc=0.9577222466468811, loss=0.12505388259887695
test: epoch 42, loss 2.2910690307617188, acc=0.4333333373069763, loss=2.2910690307617188
train: epoch 43, loss 0.13148434460163116, acc=0.9574999809265137, loss=0.13148434460163116
test: epoch 43, loss 1.9147542715072632, acc=0.4888888895511627, loss=1.9147542715072632
train: epoch 44, loss 0.12105708569288254, acc=0.9600555300712585, loss=0.12105708569288254
test: epoch 44, loss 2.0191996097564697, acc=0.4749999940395355, loss=2.0191996097564697
train: epoch 45, loss 0.13406850397586823, acc=0.9558888673782349, loss=0.13406850397586823
test: epoch 45, loss 1.6311619281768799, acc=0.49444442987442017, loss=1.6311619281768799
train: epoch 46, loss 0.11790485680103302, acc=0.9626111388206482, loss=0.11790485680103302
test: epoch 46, loss 2.0408990383148193, acc=0.375, loss=2.0408990383148193
train: epoch 47, loss 0.11577470600605011, acc=0.9628888964653015, loss=0.11577470600605011
test: epoch 47, loss 1.6823513507843018, acc=0.46666666865348816, loss=1.6823513507843018
train: epoch 48, loss 0.1045236811041832, acc=0.9650555849075317, loss=0.1045236811041832
test: epoch 48, loss 1.7887539863586426, acc=0.49444442987442017, loss=1.7887539863586426
train: epoch 49, loss 0.12165924906730652, acc=0.9588888883590698, loss=0.12165924906730652
test: epoch 49, loss 1.8582948446273804, acc=0.4722222089767456, loss=1.8582948446273804
train: epoch 50, loss 0.10065998136997223, acc=0.9651111364364624, loss=0.10065998136997223
test: epoch 50, loss 1.8277180194854736, acc=0.4472222328186035, loss=1.8277180194854736
train: epoch 51, loss 0.1157926395535469, acc=0.9621666669845581, loss=0.1157926395535469
test: epoch 51, loss 2.094573974609375, acc=0.4194444417953491, loss=2.094573974609375
train: epoch 52, loss 0.10386045277118683, acc=0.964388906955719, loss=0.10386045277118683
test: epoch 52, loss 2.2059950828552246, acc=0.4444444477558136, loss=2.2059950828552246
train: epoch 53, loss 0.10986687988042831, acc=0.9635555744171143, loss=0.10986687988042831
test: epoch 53, loss 2.118995428085327, acc=0.3777777850627899, loss=2.118995428085327
train: epoch 54, loss 0.10962172597646713, acc=0.9637777805328369, loss=0.10962172597646713
test: epoch 54, loss 2.462373971939087, acc=0.42500001192092896, loss=2.462373971939087
train: epoch 55, loss 0.10529842227697372, acc=0.9669444561004639, loss=0.10529842227697372
test: epoch 55, loss 1.885356068611145, acc=0.5277777910232544, loss=1.885356068611145
train: epoch 56, loss 0.10493495315313339, acc=0.9657777547836304, loss=0.10493495315313339
test: epoch 56, loss 1.8600901365280151, acc=0.4749999940395355, loss=1.8600901365280151
train: epoch 57, loss 0.09465938061475754, acc=0.9687777757644653, loss=0.09465938061475754
test: epoch 57, loss 2.121406078338623, acc=0.375, loss=2.121406078338623
train: epoch 58, loss 0.11202703416347504, acc=0.9630555510520935, loss=0.11202703416347504
test: epoch 58, loss 1.7480167150497437, acc=0.5, loss=1.7480167150497437
train: epoch 59, loss 0.08792582154273987, acc=0.9690555334091187, loss=0.08792582154273987
test: epoch 59, loss 1.885245680809021, acc=0.4861111044883728, loss=1.885245680809021
train: epoch 60, loss 0.09803269058465958, acc=0.9691666960716248, loss=0.09803269058465958
test: epoch 60, loss 2.28643536567688, acc=0.42222222685813904, loss=2.28643536567688
train: epoch 61, loss 0.08998849242925644, acc=0.9717222452163696, loss=0.08998849242925644
test: epoch 61, loss 2.245954751968384, acc=0.4888888895511627, loss=2.245954751968384
train: epoch 62, loss 0.08997616171836853, acc=0.9703333377838135, loss=0.08997616171836853
test: epoch 62, loss 1.5448371171951294, acc=0.49444442987442017, loss=1.5448371171951294
train: epoch 63, loss 0.09700807929039001, acc=0.9693333506584167, loss=0.09700807929039001
test: epoch 63, loss 1.9180634021759033, acc=0.5249999761581421, loss=1.9180634021759033
train: epoch 64, loss 0.07169687747955322, acc=0.9783333539962769, loss=0.07169687747955322
test: epoch 64, loss 1.714919090270996, acc=0.4833333194255829, loss=1.714919090270996
train: epoch 65, loss 0.100688636302948, acc=0.9667222499847412, loss=0.100688636302948
test: epoch 65, loss 2.498641014099121, acc=0.4444444477558136, loss=2.498641014099121
train: epoch 66, loss 0.09048594534397125, acc=0.9697777628898621, loss=0.09048594534397125
test: epoch 66, loss 1.8991807699203491, acc=0.5, loss=1.8991807699203491
train: epoch 67, loss 0.08660843223333359, acc=0.9729999899864197, loss=0.08660843223333359
test: epoch 67, loss 1.6414388418197632, acc=0.550000011920929, loss=1.6414388418197632
train: epoch 68, loss 0.07674478739500046, acc=0.9751666784286499, loss=0.07674478739500046
test: epoch 68, loss 1.8834195137023926, acc=0.4833333194255829, loss=1.8834195137023926
train: epoch 69, loss 0.0833158865571022, acc=0.972944438457489, loss=0.0833158865571022
test: epoch 69, loss 2.1616122722625732, acc=0.4166666567325592, loss=2.1616122722625732
train: epoch 70, loss 0.07697511464357376, acc=0.9750000238418579, loss=0.07697511464357376
test: epoch 70, loss 1.808056354522705, acc=0.4583333432674408, loss=1.808056354522705
train: epoch 71, loss 0.08134439587593079, acc=0.972777783870697, loss=0.08134439587593079
test: epoch 71, loss 1.797455072402954, acc=0.48055556416511536, loss=1.797455072402954
train: epoch 72, loss 0.07461251318454742, acc=0.9753333330154419, loss=0.07461251318454742
test: epoch 72, loss 2.3348541259765625, acc=0.44999998807907104, loss=2.3348541259765625
train: epoch 73, loss 0.07519292831420898, acc=0.9755555391311646, loss=0.07519292831420898
test: epoch 73, loss 2.237988233566284, acc=0.4166666567325592, loss=2.237988233566284
train: epoch 74, loss 0.06916014105081558, acc=0.9787222146987915, loss=0.06916014105081558
test: epoch 74, loss 2.639312744140625, acc=0.4027777910232544, loss=2.639312744140625
train: epoch 75, loss 0.07665503025054932, acc=0.9753888845443726, loss=0.07665503025054932
test: epoch 75, loss 2.2342565059661865, acc=0.4888888895511627, loss=2.2342565059661865
train: epoch 76, loss 0.0629076436161995, acc=0.9788333177566528, loss=0.0629076436161995
test: epoch 76, loss 1.7550534009933472, acc=0.47777777910232544, loss=1.7550534009933472
train: epoch 77, loss 0.08022502064704895, acc=0.9752222299575806, loss=0.08022502064704895
test: epoch 77, loss 2.1544344425201416, acc=0.4027777910232544, loss=2.1544344425201416
train: epoch 78, loss 0.07292963564395905, acc=0.9779444336891174, loss=0.07292963564395905
test: epoch 78, loss 1.9191925525665283, acc=0.4972222149372101, loss=1.9191925525665283
train: epoch 79, loss 0.07803039252758026, acc=0.9751111268997192, loss=0.07803039252758026
test: epoch 79, loss 1.9639055728912354, acc=0.4722222089767456, loss=1.9639055728912354
train: epoch 80, loss 0.07409220188856125, acc=0.9750000238418579, loss=0.07409220188856125
test: epoch 80, loss 1.8523000478744507, acc=0.4472222328186035, loss=1.8523000478744507
train: epoch 81, loss 0.06664836406707764, acc=0.9783333539962769, loss=0.06664836406707764
test: epoch 81, loss 1.8590108156204224, acc=0.5249999761581421, loss=1.8590108156204224
train: epoch 82, loss 0.060511812567710876, acc=0.9808333516120911, loss=0.060511812567710876
test: epoch 82, loss 1.9355143308639526, acc=0.5, loss=1.9355143308639526
train: epoch 83, loss 0.08059472590684891, acc=0.9747777581214905, loss=0.08059472590684891
test: epoch 83, loss 1.8168820142745972, acc=0.48055556416511536, loss=1.8168820142745972
train: epoch 84, loss 0.06612329185009003, acc=0.9792222380638123, loss=0.06612329185009003
test: epoch 84, loss 1.9053750038146973, acc=0.4555555582046509, loss=1.9053750038146973
train: epoch 85, loss 0.0759020522236824, acc=0.9779444336891174, loss=0.0759020522236824
test: epoch 85, loss 1.9359216690063477, acc=0.4749999940395355, loss=1.9359216690063477
train: epoch 86, loss 0.055046942085027695, acc=0.9826666712760925, loss=0.055046942085027695
test: epoch 86, loss 1.9879541397094727, acc=0.5055555701255798, loss=1.9879541397094727
train: epoch 87, loss 0.057520244270563126, acc=0.9820555448532104, loss=0.057520244270563126
test: epoch 87, loss 2.045968770980835, acc=0.5249999761581421, loss=2.045968770980835
train: epoch 88, loss 0.07845286279916763, acc=0.9745555520057678, loss=0.07845286279916763
test: epoch 88, loss 1.8534027338027954, acc=0.47777777910232544, loss=1.8534027338027954
train: epoch 89, loss 0.07643581181764603, acc=0.9755555391311646, loss=0.07643581181764603
test: epoch 89, loss 2.137601852416992, acc=0.5222222208976746, loss=2.137601852416992
train: epoch 90, loss 0.05672252178192139, acc=0.9821666479110718, loss=0.05672252178192139
test: epoch 90, loss 2.018230438232422, acc=0.4972222149372101, loss=2.018230438232422
train: epoch 91, loss 0.06666106730699539, acc=0.9792222380638123, loss=0.06666106730699539
test: epoch 91, loss 1.8988081216812134, acc=0.519444465637207, loss=1.8988081216812134
train: epoch 92, loss 0.05919868126511574, acc=0.9822221994400024, loss=0.05919868126511574
test: epoch 92, loss 2.080296277999878, acc=0.5083333253860474, loss=2.080296277999878
train: epoch 93, loss 0.06531579047441483, acc=0.980388879776001, loss=0.06531579047441483
test: epoch 93, loss 1.961728572845459, acc=0.4888888895511627, loss=1.961728572845459
train: epoch 94, loss 0.07652882486581802, acc=0.9769999980926514, loss=0.07652882486581802
test: epoch 94, loss 2.0535147190093994, acc=0.48055556416511536, loss=2.0535147190093994
train: epoch 95, loss 0.059209007769823074, acc=0.981166660785675, loss=0.059209007769823074
test: epoch 95, loss 2.1106135845184326, acc=0.5416666865348816, loss=2.1106135845184326
train: epoch 96, loss 0.05415879935026169, acc=0.9826666712760925, loss=0.05415879935026169
test: epoch 96, loss 2.120852470397949, acc=0.5249999761581421, loss=2.120852470397949
train: epoch 97, loss 0.05613034591078758, acc=0.9824444651603699, loss=0.05613034591078758
test: epoch 97, loss 2.2850828170776367, acc=0.5083333253860474, loss=2.2850828170776367
train: epoch 98, loss 0.05232548341155052, acc=0.9835000038146973, loss=0.05232548341155052
test: epoch 98, loss 1.952125072479248, acc=0.5249999761581421, loss=1.952125072479248
train: epoch 99, loss 0.06160435453057289, acc=0.9806666374206543, loss=0.06160435453057289
test: epoch 99, loss 2.0091850757598877, acc=0.5249999761581421, loss=2.0091850757598877
train: epoch 100, loss 0.053563062101602554, acc=0.9833333492279053, loss=0.053563062101602554
test: epoch 100, loss 2.110395669937134, acc=0.4972222149372101, loss=2.110395669937134
train: epoch 101, loss 0.05108978971838951, acc=0.98416668176651, loss=0.05108978971838951
test: epoch 101, loss 2.000018835067749, acc=0.5305555462837219, loss=2.000018835067749
train: epoch 102, loss 0.0693565234541893, acc=0.9801666736602783, loss=0.0693565234541893
test: epoch 102, loss 1.7803404331207275, acc=0.5444444417953491, loss=1.7803404331207275
train: epoch 103, loss 0.048597302287817, acc=0.984333336353302, loss=0.048597302287817
test: epoch 103, loss 2.168225049972534, acc=0.5805555582046509, loss=2.168225049972534
train: epoch 104, loss 0.05751486122608185, acc=0.9826111197471619, loss=0.05751486122608185
test: epoch 104, loss 2.409395456314087, acc=0.48055556416511536, loss=2.409395456314087
train: epoch 105, loss 0.06247009336948395, acc=0.9809444546699524, loss=0.06247009336948395
test: epoch 105, loss 2.025496482849121, acc=0.46666666865348816, loss=2.025496482849121
train: epoch 106, loss 0.048839084804058075, acc=0.9847777485847473, loss=0.048839084804058075
test: epoch 106, loss 2.297562837600708, acc=0.48055556416511536, loss=2.297562837600708
train: epoch 107, loss 0.0517253503203392, acc=0.9838888645172119, loss=0.0517253503203392
test: epoch 107, loss 2.375962972640991, acc=0.4611110985279083, loss=2.375962972640991
train: epoch 108, loss 0.042813900858163834, acc=0.9856666922569275, loss=0.042813900858163834
test: epoch 108, loss 2.301922082901001, acc=0.5249999761581421, loss=2.301922082901001
train: epoch 109, loss 0.06453549116849899, acc=0.9795555472373962, loss=0.06453549116849899
test: epoch 109, loss 2.2298195362091064, acc=0.5333333611488342, loss=2.2298195362091064
train: epoch 110, loss 0.051570188254117966, acc=0.9841111302375793, loss=0.051570188254117966
test: epoch 110, loss 1.9233193397521973, acc=0.5027777552604675, loss=1.9233193397521973
train: epoch 111, loss 0.047689903527498245, acc=0.9856666922569275, loss=0.047689903527498245
test: epoch 111, loss 2.086963653564453, acc=0.5333333611488342, loss=2.086963653564453
train: epoch 112, loss 0.05099157989025116, acc=0.9846110939979553, loss=0.05099157989025116
test: epoch 112, loss 2.4823126792907715, acc=0.4416666626930237, loss=2.4823126792907715
train: epoch 113, loss 0.055433277040719986, acc=0.9836111068725586, loss=0.055433277040719986
test: epoch 113, loss 2.7849843502044678, acc=0.4277777671813965, loss=2.7849843502044678
train: epoch 114, loss 0.04118707776069641, acc=0.9869444370269775, loss=0.04118707776069641
test: epoch 114, loss 2.047008752822876, acc=0.5388888716697693, loss=2.047008752822876
train: epoch 115, loss 0.05544983223080635, acc=0.9827777743339539, loss=0.05544983223080635
test: epoch 115, loss 1.854512095451355, acc=0.49166667461395264, loss=1.854512095451355
train: epoch 116, loss 0.03461293503642082, acc=0.9892777800559998, loss=0.03461293503642082
test: epoch 116, loss 1.674753189086914, acc=0.5333333611488342, loss=1.674753189086914
train: epoch 117, loss 0.036577172577381134, acc=0.9879444241523743, loss=0.036577172577381134
test: epoch 117, loss 2.3075807094573975, acc=0.5416666865348816, loss=2.3075807094573975
train: epoch 118, loss 0.0633268803358078, acc=0.9814444184303284, loss=0.0633268803358078
test: epoch 118, loss 2.072533130645752, acc=0.4694444537162781, loss=2.072533130645752
train: epoch 119, loss 0.05102581903338432, acc=0.9839444160461426, loss=0.05102581903338432
test: epoch 119, loss 1.7699263095855713, acc=0.5472221970558167, loss=1.7699263095855713
train: epoch 120, loss 0.042453497648239136, acc=0.9870555400848389, loss=0.042453497648239136
test: epoch 120, loss 2.2657883167266846, acc=0.5, loss=2.2657883167266846
train: epoch 121, loss 0.045595698058605194, acc=0.9862777590751648, loss=0.045595698058605194
test: epoch 121, loss 3.4560065269470215, acc=0.4194444417953491, loss=3.4560065269470215
train: epoch 122, loss 0.05110356956720352, acc=0.9842222332954407, loss=0.05110356956720352
test: epoch 122, loss 1.906033992767334, acc=0.5444444417953491, loss=1.906033992767334
train: epoch 123, loss 0.0483483150601387, acc=0.9857222437858582, loss=0.0483483150601387
test: epoch 123, loss 1.7018707990646362, acc=0.5638889074325562, loss=1.7018707990646362
train: epoch 124, loss 0.047731902450323105, acc=0.9852777719497681, loss=0.047731902450323105
test: epoch 124, loss 2.733128786087036, acc=0.4722222089767456, loss=2.733128786087036
train: epoch 125, loss 0.033271051943302155, acc=0.9899444580078125, loss=0.033271051943302155
test: epoch 125, loss 2.4369583129882812, acc=0.4972222149372101, loss=2.4369583129882812
train: epoch 126, loss 0.04892215132713318, acc=0.9852777719497681, loss=0.04892215132713318
test: epoch 126, loss 1.6366688013076782, acc=0.5416666865348816, loss=1.6366688013076782
train: epoch 127, loss 0.03672659769654274, acc=0.9885555505752563, loss=0.03672659769654274
test: epoch 127, loss 1.8918708562850952, acc=0.48055556416511536, loss=1.8918708562850952
train: epoch 128, loss 0.039285123348236084, acc=0.9885555505752563, loss=0.039285123348236084
test: epoch 128, loss 2.141425371170044, acc=0.4749999940395355, loss=2.141425371170044
train: epoch 129, loss 0.04674140736460686, acc=0.9866111278533936, loss=0.04674140736460686
test: epoch 129, loss 1.9365953207015991, acc=0.49444442987442017, loss=1.9365953207015991
train: epoch 130, loss 0.04416098818182945, acc=0.988111138343811, loss=0.04416098818182945
test: epoch 130, loss 2.602313995361328, acc=0.4722222089767456, loss=2.602313995361328
train: epoch 131, loss 0.04530642554163933, acc=0.9868888854980469, loss=0.04530642554163933
test: epoch 131, loss 1.7676156759262085, acc=0.574999988079071, loss=1.7676156759262085
train: epoch 132, loss 0.04103470593690872, acc=0.988111138343811, loss=0.04103470593690872
test: epoch 132, loss 2.518566131591797, acc=0.5166666507720947, loss=2.518566131591797
train: epoch 133, loss 0.04541090875864029, acc=0.9868333339691162, loss=0.04541090875864029
test: epoch 133, loss 1.8789069652557373, acc=0.5166666507720947, loss=1.8789069652557373
train: epoch 134, loss 0.037539880722761154, acc=0.9897222518920898, loss=0.037539880722761154
test: epoch 134, loss 1.7543575763702393, acc=0.5444444417953491, loss=1.7543575763702393
train: epoch 135, loss 0.04310876503586769, acc=0.9868888854980469, loss=0.04310876503586769
test: epoch 135, loss 2.000335931777954, acc=0.5388888716697693, loss=2.000335931777954
train: epoch 136, loss 0.046854227781295776, acc=0.9861111044883728, loss=0.046854227781295776
test: epoch 136, loss 2.4135212898254395, acc=0.4694444537162781, loss=2.4135212898254395
train: epoch 137, loss 0.037341613322496414, acc=0.9889444708824158, loss=0.037341613322496414
test: epoch 137, loss 2.813950538635254, acc=0.4861111044883728, loss=2.813950538635254
train: epoch 138, loss 0.035322126001119614, acc=0.988777756690979, loss=0.035322126001119614
test: epoch 138, loss 2.237879753112793, acc=0.519444465637207, loss=2.237879753112793
train: epoch 139, loss 0.03840015083551407, acc=0.987666666507721, loss=0.03840015083551407
test: epoch 139, loss 2.083674430847168, acc=0.4583333432674408, loss=2.083674430847168
train: epoch 140, loss 0.03795221075415611, acc=0.9893333315849304, loss=0.03795221075415611
test: epoch 140, loss 2.2759172916412354, acc=0.5166666507720947, loss=2.2759172916412354
train: epoch 141, loss 0.046290911734104156, acc=0.9868888854980469, loss=0.046290911734104156
test: epoch 141, loss 1.9333566427230835, acc=0.5555555820465088, loss=1.9333566427230835
train: epoch 142, loss 0.039921145886182785, acc=0.9883333444595337, loss=0.039921145886182785
test: epoch 142, loss 2.251608371734619, acc=0.5416666865348816, loss=2.251608371734619
train: epoch 143, loss 0.0327780544757843, acc=0.9910555481910706, loss=0.0327780544757843
test: epoch 143, loss 2.9753408432006836, acc=0.5027777552604675, loss=2.9753408432006836
train: epoch 144, loss 0.03806593269109726, acc=0.9888333082199097, loss=0.03806593269109726
test: epoch 144, loss 2.254474639892578, acc=0.48055556416511536, loss=2.254474639892578
train: epoch 145, loss 0.039462242275476456, acc=0.9881666898727417, loss=0.039462242275476456
test: epoch 145, loss 1.9327515363693237, acc=0.5583333373069763, loss=1.9327515363693237
train: epoch 146, loss 0.040759146213531494, acc=0.9870555400848389, loss=0.040759146213531494
test: epoch 146, loss 2.6191976070404053, acc=0.4472222328186035, loss=2.6191976070404053
train: epoch 147, loss 0.04079250618815422, acc=0.9885555505752563, loss=0.04079250618815422
test: epoch 147, loss 2.2278685569763184, acc=0.4694444537162781, loss=2.2278685569763184
train: epoch 148, loss 0.031457845121622086, acc=0.9915000200271606, loss=0.031457845121622086
test: epoch 148, loss 1.4587346315383911, acc=0.5472221970558167, loss=1.4587346315383911
train: epoch 149, loss 0.041681163012981415, acc=0.9874444603919983, loss=0.041681163012981415
test: epoch 149, loss 1.5623905658721924, acc=0.5805555582046509, loss=1.5623905658721924
train: epoch 150, loss 0.04091515764594078, acc=0.9879444241523743, loss=0.04091515764594078
test: epoch 150, loss 1.6348704099655151, acc=0.5055555701255798, loss=1.6348704099655151
