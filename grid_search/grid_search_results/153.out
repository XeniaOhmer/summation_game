# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=false", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=754322728, receiver_embed_dim=128, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.7584540843963623, acc=0.13544444739818573, loss=2.7584540843963623
test: epoch 1, loss 2.633270740509033, acc=0.16388888657093048, loss=2.633270740509033
train: epoch 2, loss 1.438933253288269, acc=0.406333327293396, loss=1.438933253288269
test: epoch 2, loss 2.526052951812744, acc=0.16388888657093048, loss=2.526052951812744
train: epoch 3, loss 1.1340950727462769, acc=0.535111129283905, loss=1.1340950727462769
test: epoch 3, loss 2.5508368015289307, acc=0.16388888657093048, loss=2.5508368015289307
train: epoch 4, loss 0.9692443609237671, acc=0.6083333492279053, loss=0.9692443609237671
test: epoch 4, loss 2.602935791015625, acc=0.21666666865348816, loss=2.602935791015625
train: epoch 5, loss 0.865604817867279, acc=0.6514999866485596, loss=0.865604817867279
test: epoch 5, loss 2.238947868347168, acc=0.21111111342906952, loss=2.238947868347168
train: epoch 6, loss 0.7699860334396362, acc=0.699833333492279, loss=0.7699860334396362
test: epoch 6, loss 2.4151337146759033, acc=0.21111111342906952, loss=2.4151337146759033
train: epoch 7, loss 0.7129210233688354, acc=0.727222204208374, loss=0.7129210233688354
test: epoch 7, loss 2.246852397918701, acc=0.25, loss=2.246852397918701
train: epoch 8, loss 0.6455784440040588, acc=0.7521666884422302, loss=0.6455784440040588
test: epoch 8, loss 2.459768056869507, acc=0.25555557012557983, loss=2.459768056869507
train: epoch 9, loss 0.5986888408660889, acc=0.773722231388092, loss=0.5986888408660889
test: epoch 9, loss 2.3739516735076904, acc=0.21666666865348816, loss=2.3739516735076904
train: epoch 10, loss 0.5565671324729919, acc=0.7898333072662354, loss=0.5565671324729919
test: epoch 10, loss 2.3655951023101807, acc=0.27222222089767456, loss=2.3655951023101807
train: epoch 11, loss 0.5170742273330688, acc=0.8034444451332092, loss=0.5170742273330688
test: epoch 11, loss 2.455414295196533, acc=0.2222222238779068, loss=2.455414295196533
train: epoch 12, loss 0.4884791076183319, acc=0.8178333044052124, loss=0.4884791076183319
test: epoch 12, loss 2.3044631481170654, acc=0.30000001192092896, loss=2.3044631481170654
train: epoch 13, loss 0.4601910412311554, acc=0.8267222046852112, loss=0.4601910412311554
test: epoch 13, loss 2.3177802562713623, acc=0.2750000059604645, loss=2.3177802562713623
train: epoch 14, loss 0.43676742911338806, acc=0.8416666388511658, loss=0.43676742911338806
test: epoch 14, loss 2.4045820236206055, acc=0.3222222328186035, loss=2.4045820236206055
train: epoch 15, loss 0.39873191714286804, acc=0.8525000214576721, loss=0.39873191714286804
test: epoch 15, loss 2.2794923782348633, acc=0.3083333373069763, loss=2.2794923782348633
train: epoch 16, loss 0.3842698037624359, acc=0.8618888854980469, loss=0.3842698037624359
test: epoch 16, loss 2.1229302883148193, acc=0.2944444417953491, loss=2.1229302883148193
train: epoch 17, loss 0.3675805330276489, acc=0.8657777905464172, loss=0.3675805330276489
test: epoch 17, loss 2.1707565784454346, acc=0.2888889014720917, loss=2.1707565784454346
train: epoch 18, loss 0.3401476740837097, acc=0.8782222270965576, loss=0.3401476740837097
test: epoch 18, loss 2.284433603286743, acc=0.3166666626930237, loss=2.284433603286743
train: epoch 19, loss 0.3201580345630646, acc=0.8867777585983276, loss=0.3201580345630646
test: epoch 19, loss 2.809601306915283, acc=0.29722222685813904, loss=2.809601306915283
train: epoch 20, loss 0.3065280318260193, acc=0.8925555348396301, loss=0.3065280318260193
test: epoch 20, loss 2.26900053024292, acc=0.31111112236976624, loss=2.26900053024292
train: epoch 21, loss 0.2818163335323334, acc=0.9030555486679077, loss=0.2818163335323334
test: epoch 21, loss 2.391972303390503, acc=0.32499998807907104, loss=2.391972303390503
train: epoch 22, loss 0.2663276195526123, acc=0.9099444150924683, loss=0.2663276195526123
test: epoch 22, loss 2.4656805992126465, acc=0.4194444417953491, loss=2.4656805992126465
train: epoch 23, loss 0.26110735535621643, acc=0.9120555520057678, loss=0.26110735535621643
test: epoch 23, loss 2.4387478828430176, acc=0.3444444537162781, loss=2.4387478828430176
train: epoch 24, loss 0.25425681471824646, acc=0.9110555648803711, loss=0.25425681471824646
test: epoch 24, loss 2.5278422832489014, acc=0.35277777910232544, loss=2.5278422832489014
train: epoch 25, loss 0.2218703329563141, acc=0.9268333315849304, loss=0.2218703329563141
test: epoch 25, loss 2.3440632820129395, acc=0.3888888955116272, loss=2.3440632820129395
train: epoch 26, loss 0.2104586660861969, acc=0.9296666383743286, loss=0.2104586660861969
test: epoch 26, loss 2.699115514755249, acc=0.35555556416511536, loss=2.699115514755249
train: epoch 27, loss 0.21209879219532013, acc=0.9269444346427917, loss=0.21209879219532013
test: epoch 27, loss 2.625516891479492, acc=0.3916666805744171, loss=2.625516891479492
train: epoch 28, loss 0.1954462081193924, acc=0.9334444403648376, loss=0.1954462081193924
test: epoch 28, loss 2.482194185256958, acc=0.3888888955116272, loss=2.482194185256958
train: epoch 29, loss 0.1978699415922165, acc=0.9328888654708862, loss=0.1978699415922165
test: epoch 29, loss 2.6119234561920166, acc=0.38055557012557983, loss=2.6119234561920166
train: epoch 30, loss 0.16778399050235748, acc=0.9432222247123718, loss=0.16778399050235748
test: epoch 30, loss 2.4898762702941895, acc=0.29722222685813904, loss=2.4898762702941895
train: epoch 31, loss 0.16721341013908386, acc=0.9456666707992554, loss=0.16721341013908386
test: epoch 31, loss 2.0297038555145264, acc=0.4194444417953491, loss=2.0297038555145264
train: epoch 32, loss 0.157553032040596, acc=0.9491666555404663, loss=0.157553032040596
test: epoch 32, loss 2.4045896530151367, acc=0.4333333373069763, loss=2.4045896530151367
train: epoch 33, loss 0.14282329380512238, acc=0.9533888697624207, loss=0.14282329380512238
test: epoch 33, loss 2.561422348022461, acc=0.39722222089767456, loss=2.561422348022461
train: epoch 34, loss 0.13480612635612488, acc=0.954277753829956, loss=0.13480612635612488
test: epoch 34, loss 2.0424678325653076, acc=0.4583333432674408, loss=2.0424678325653076
train: epoch 35, loss 0.12713778018951416, acc=0.9591666460037231, loss=0.12713778018951416
test: epoch 35, loss 2.6408674716949463, acc=0.4055555462837219, loss=2.6408674716949463
train: epoch 36, loss 0.1265300214290619, acc=0.9623333215713501, loss=0.1265300214290619
test: epoch 36, loss 2.2359728813171387, acc=0.48055556416511536, loss=2.2359728813171387
train: epoch 37, loss 0.1302318125963211, acc=0.9597777724266052, loss=0.1302318125963211
test: epoch 37, loss 2.6864097118377686, acc=0.4444444477558136, loss=2.6864097118377686
train: epoch 38, loss 0.12072601169347763, acc=0.9652222394943237, loss=0.12072601169347763
test: epoch 38, loss 2.2432503700256348, acc=0.43888887763023376, loss=2.2432503700256348
train: epoch 39, loss 0.11129636317491531, acc=0.9671666622161865, loss=0.11129636317491531
test: epoch 39, loss 2.345125913619995, acc=0.5166666507720947, loss=2.345125913619995
train: epoch 40, loss 0.11817274987697601, acc=0.9658889174461365, loss=0.11817274987697601
test: epoch 40, loss 2.131457567214966, acc=0.4888888895511627, loss=2.131457567214966
train: epoch 41, loss 0.10295647382736206, acc=0.9687222242355347, loss=0.10295647382736206
test: epoch 41, loss 2.338005542755127, acc=0.4972222149372101, loss=2.338005542755127
train: epoch 42, loss 0.10259345173835754, acc=0.9697222113609314, loss=0.10259345173835754
test: epoch 42, loss 2.4388580322265625, acc=0.4611110985279083, loss=2.4388580322265625
train: epoch 43, loss 0.09664615243673325, acc=0.9712222218513489, loss=0.09664615243673325
test: epoch 43, loss 2.344614028930664, acc=0.4611110985279083, loss=2.344614028930664
train: epoch 44, loss 0.1020769327878952, acc=0.9695000052452087, loss=0.1020769327878952
test: epoch 44, loss 2.572266101837158, acc=0.4972222149372101, loss=2.572266101837158
train: epoch 45, loss 0.09602812677621841, acc=0.9723333120346069, loss=0.09602812677621841
test: epoch 45, loss 2.386547565460205, acc=0.4888888895511627, loss=2.386547565460205
train: epoch 46, loss 0.09063975512981415, acc=0.9741111397743225, loss=0.09063975512981415
test: epoch 46, loss 2.639953374862671, acc=0.5027777552604675, loss=2.639953374862671
train: epoch 47, loss 0.08810596913099289, acc=0.9735555648803711, loss=0.08810596913099289
test: epoch 47, loss 2.6969711780548096, acc=0.4888888895511627, loss=2.6969711780548096
train: epoch 48, loss 0.09592044353485107, acc=0.9721666574478149, loss=0.09592044353485107
test: epoch 48, loss 1.9033663272857666, acc=0.5638889074325562, loss=1.9033663272857666
train: epoch 49, loss 0.0884089320898056, acc=0.9765555262565613, loss=0.0884089320898056
test: epoch 49, loss 2.444664478302002, acc=0.5083333253860474, loss=2.444664478302002
train: epoch 50, loss 0.08847777545452118, acc=0.9742777943611145, loss=0.08847777545452118
test: epoch 50, loss 2.2389612197875977, acc=0.5138888955116272, loss=2.2389612197875977
train: epoch 51, loss 0.0808698907494545, acc=0.9764999747276306, loss=0.0808698907494545
test: epoch 51, loss 2.4472713470458984, acc=0.5166666507720947, loss=2.4472713470458984
train: epoch 52, loss 0.08233745396137238, acc=0.9771666526794434, loss=0.08233745396137238
test: epoch 52, loss 2.4920008182525635, acc=0.5333333611488342, loss=2.4920008182525635
train: epoch 53, loss 0.08802032470703125, acc=0.9748888611793518, loss=0.08802032470703125
test: epoch 53, loss 2.614082098007202, acc=0.5111111402511597, loss=2.614082098007202
train: epoch 54, loss 0.07963160425424576, acc=0.9777222275733948, loss=0.07963160425424576
test: epoch 54, loss 1.754577398300171, acc=0.6000000238418579, loss=1.754577398300171
train: epoch 55, loss 0.08359377831220627, acc=0.976277768611908, loss=0.08359377831220627
test: epoch 55, loss 2.4633166790008545, acc=0.49444442987442017, loss=2.4633166790008545
train: epoch 56, loss 0.06844829022884369, acc=0.9801666736602783, loss=0.06844829022884369
test: epoch 56, loss 2.0904428958892822, acc=0.5666666626930237, loss=2.0904428958892822
train: epoch 57, loss 0.08014187216758728, acc=0.9788333177566528, loss=0.08014187216758728
test: epoch 57, loss 2.065016746520996, acc=0.5472221970558167, loss=2.065016746520996
train: epoch 58, loss 0.09139891713857651, acc=0.9741666913032532, loss=0.09139891713857651
test: epoch 58, loss 2.0466597080230713, acc=0.550000011920929, loss=2.0466597080230713
train: epoch 59, loss 0.0728505402803421, acc=0.9789999723434448, loss=0.0728505402803421
test: epoch 59, loss 2.3953945636749268, acc=0.5555555820465088, loss=2.3953945636749268
train: epoch 60, loss 0.06749985367059708, acc=0.9814444184303284, loss=0.06749985367059708
test: epoch 60, loss 2.0512540340423584, acc=0.5722222328186035, loss=2.0512540340423584
train: epoch 61, loss 0.07074157893657684, acc=0.9799444675445557, loss=0.07074157893657684
test: epoch 61, loss 1.8618066310882568, acc=0.6027777791023254, loss=1.8618066310882568
train: epoch 62, loss 0.0732070803642273, acc=0.9796110987663269, loss=0.0732070803642273
test: epoch 62, loss 1.765378475189209, acc=0.6138888597488403, loss=1.765378475189209
train: epoch 63, loss 0.07133501768112183, acc=0.9809444546699524, loss=0.07133501768112183
test: epoch 63, loss 1.796825885772705, acc=0.5944444537162781, loss=1.796825885772705
train: epoch 64, loss 0.06881127506494522, acc=0.9804999828338623, loss=0.06881127506494522
test: epoch 64, loss 1.638075828552246, acc=0.6388888955116272, loss=1.638075828552246
train: epoch 65, loss 0.0654882937669754, acc=0.9808889031410217, loss=0.0654882937669754
test: epoch 65, loss 1.6249929666519165, acc=0.6499999761581421, loss=1.6249929666519165
train: epoch 66, loss 0.07544946670532227, acc=0.979888916015625, loss=0.07544946670532227
test: epoch 66, loss 1.8059601783752441, acc=0.644444465637207, loss=1.8059601783752441
train: epoch 67, loss 0.0740814134478569, acc=0.9794444441795349, loss=0.0740814134478569
test: epoch 67, loss 1.9413881301879883, acc=0.6222222447395325, loss=1.9413881301879883
train: epoch 68, loss 0.06601429730653763, acc=0.981333315372467, loss=0.06601429730653763
test: epoch 68, loss 2.3107235431671143, acc=0.5833333134651184, loss=2.3107235431671143
train: epoch 69, loss 0.06947015225887299, acc=0.9802777767181396, loss=0.06947015225887299
test: epoch 69, loss 1.898655891418457, acc=0.625, loss=1.898655891418457
train: epoch 70, loss 0.0691736713051796, acc=0.9820555448532104, loss=0.0691736713051796
test: epoch 70, loss 2.149806022644043, acc=0.5916666388511658, loss=2.149806022644043
train: epoch 71, loss 0.07196826487779617, acc=0.9814444184303284, loss=0.07196826487779617
test: epoch 71, loss 1.7807105779647827, acc=0.6722221970558167, loss=1.7807105779647827
train: epoch 72, loss 0.06447779387235641, acc=0.9818888902664185, loss=0.06447779387235641
test: epoch 72, loss 1.8294888734817505, acc=0.6222222447395325, loss=1.8294888734817505
train: epoch 73, loss 0.06723982840776443, acc=0.9807222485542297, loss=0.06723982840776443
test: epoch 73, loss 1.7088721990585327, acc=0.6361111402511597, loss=1.7088721990585327
train: epoch 74, loss 0.0657588541507721, acc=0.9816666841506958, loss=0.0657588541507721
test: epoch 74, loss 1.9857177734375, acc=0.6361111402511597, loss=1.9857177734375
train: epoch 75, loss 0.06405650079250336, acc=0.9820555448532104, loss=0.06405650079250336
test: epoch 75, loss 1.8467034101486206, acc=0.6805555820465088, loss=1.8467034101486206
train: epoch 76, loss 0.07272584736347198, acc=0.9806666374206543, loss=0.07272584736347198
test: epoch 76, loss 1.417234182357788, acc=0.644444465637207, loss=1.417234182357788
train: epoch 77, loss 0.06107635423541069, acc=0.9830555319786072, loss=0.06107635423541069
test: epoch 77, loss 1.3865290880203247, acc=0.6777777671813965, loss=1.3865290880203247
train: epoch 78, loss 0.07142338901758194, acc=0.9804999828338623, loss=0.07142338901758194
test: epoch 78, loss 1.6703435182571411, acc=0.6333333253860474, loss=1.6703435182571411
train: epoch 79, loss 0.055478863418102264, acc=0.9850000143051147, loss=0.055478863418102264
test: epoch 79, loss 1.1677119731903076, acc=0.6722221970558167, loss=1.1677119731903076
train: epoch 80, loss 0.06979135423898697, acc=0.9822221994400024, loss=0.06979135423898697
test: epoch 80, loss 1.5487782955169678, acc=0.644444465637207, loss=1.5487782955169678
train: epoch 81, loss 0.06500247865915298, acc=0.981333315372467, loss=0.06500247865915298
test: epoch 81, loss 1.6453588008880615, acc=0.6611111164093018, loss=1.6453588008880615
train: epoch 82, loss 0.07375319302082062, acc=0.9799444675445557, loss=0.07375319302082062
test: epoch 82, loss 1.5356183052062988, acc=0.6555555462837219, loss=1.5356183052062988
train: epoch 83, loss 0.057573240250349045, acc=0.9838333129882812, loss=0.057573240250349045
test: epoch 83, loss 1.3968716859817505, acc=0.7166666388511658, loss=1.3968716859817505
train: epoch 84, loss 0.05895709618926048, acc=0.9831110835075378, loss=0.05895709618926048
test: epoch 84, loss 1.1619235277175903, acc=0.7472222447395325, loss=1.1619235277175903
train: epoch 85, loss 0.0666353777050972, acc=0.9812777638435364, loss=0.0666353777050972
test: epoch 85, loss 1.3364425897598267, acc=0.6638888716697693, loss=1.3364425897598267
train: epoch 86, loss 0.07271958142518997, acc=0.9815000295639038, loss=0.07271958142518997
test: epoch 86, loss 1.5228259563446045, acc=0.6583333611488342, loss=1.5228259563446045
train: epoch 87, loss 0.06060843914747238, acc=0.9841111302375793, loss=0.06060843914747238
test: epoch 87, loss 1.8284016847610474, acc=0.6722221970558167, loss=1.8284016847610474
train: epoch 88, loss 0.06445948034524918, acc=0.9831110835075378, loss=0.06445948034524918
test: epoch 88, loss 1.3169199228286743, acc=0.6694444417953491, loss=1.3169199228286743
train: epoch 89, loss 0.06169198453426361, acc=0.9826666712760925, loss=0.06169198453426361
test: epoch 89, loss 1.201924204826355, acc=0.7333333492279053, loss=1.201924204826355
train: epoch 90, loss 0.06604625284671783, acc=0.9828333258628845, loss=0.06604625284671783
test: epoch 90, loss 1.403641700744629, acc=0.7055555582046509, loss=1.403641700744629
train: epoch 91, loss 0.05852590128779411, acc=0.9835000038146973, loss=0.05852590128779411
test: epoch 91, loss 1.4422597885131836, acc=0.6638888716697693, loss=1.4422597885131836
train: epoch 92, loss 0.06052073463797569, acc=0.9823333621025085, loss=0.06052073463797569
test: epoch 92, loss 1.3288637399673462, acc=0.7277777791023254, loss=1.3288637399673462
train: epoch 93, loss 0.05971849709749222, acc=0.9834444522857666, loss=0.05971849709749222
test: epoch 93, loss 1.3469703197479248, acc=0.7111111283302307, loss=1.3469703197479248
train: epoch 94, loss 0.05194268748164177, acc=0.9855555295944214, loss=0.05194268748164177
test: epoch 94, loss 1.2318284511566162, acc=0.7166666388511658, loss=1.2318284511566162
train: epoch 95, loss 0.06178433448076248, acc=0.9824444651603699, loss=0.06178433448076248
test: epoch 95, loss 1.0849732160568237, acc=0.75, loss=1.0849732160568237
train: epoch 96, loss 0.06767245382070541, acc=0.9828333258628845, loss=0.06767245382070541
test: epoch 96, loss 1.1502890586853027, acc=0.7611111402511597, loss=1.1502890586853027
train: epoch 97, loss 0.05238351970911026, acc=0.9857222437858582, loss=0.05238351970911026
test: epoch 97, loss 1.3548132181167603, acc=0.7333333492279053, loss=1.3548132181167603
train: epoch 98, loss 0.07181958109140396, acc=0.9817777872085571, loss=0.07181958109140396
test: epoch 98, loss 0.7709940671920776, acc=0.7861111164093018, loss=0.7709940671920776
train: epoch 99, loss 0.06041478365659714, acc=0.9842777848243713, loss=0.06041478365659714
test: epoch 99, loss 0.8946987986564636, acc=0.7638888955116272, loss=0.8946987986564636
train: epoch 100, loss 0.058041732758283615, acc=0.9851111173629761, loss=0.058041732758283615
test: epoch 100, loss 1.066593050956726, acc=0.7611111402511597, loss=1.066593050956726
train: epoch 101, loss 0.05834368243813515, acc=0.9828888773918152, loss=0.05834368243813515
test: epoch 101, loss 1.15632963180542, acc=0.7361111044883728, loss=1.15632963180542
train: epoch 102, loss 0.051931507885456085, acc=0.9855555295944214, loss=0.051931507885456085
test: epoch 102, loss 1.1352442502975464, acc=0.7611111402511597, loss=1.1352442502975464
train: epoch 103, loss 0.050754107534885406, acc=0.9866666793823242, loss=0.050754107534885406
test: epoch 103, loss 1.0748924016952515, acc=0.7722222208976746, loss=1.0748924016952515
train: epoch 104, loss 0.05817391723394394, acc=0.9842222332954407, loss=0.05817391723394394
test: epoch 104, loss 0.9809367060661316, acc=0.7888888716697693, loss=0.9809367060661316
train: epoch 105, loss 0.06080131605267525, acc=0.9824444651603699, loss=0.06080131605267525
test: epoch 105, loss 1.2052444219589233, acc=0.7722222208976746, loss=1.2052444219589233
train: epoch 106, loss 0.04748213663697243, acc=0.987333357334137, loss=0.04748213663697243
test: epoch 106, loss 0.7429549694061279, acc=0.8194444179534912, loss=0.7429549694061279
train: epoch 107, loss 0.054249342530965805, acc=0.9856666922569275, loss=0.054249342530965805
test: epoch 107, loss 0.6414011716842651, acc=0.8277778029441833, loss=0.6414011716842651
train: epoch 108, loss 0.04482416436076164, acc=0.987333357334137, loss=0.04482416436076164
test: epoch 108, loss 0.9538118243217468, acc=0.800000011920929, loss=0.9538118243217468
train: epoch 109, loss 0.05785207450389862, acc=0.9846110939979553, loss=0.05785207450389862
test: epoch 109, loss 0.808781623840332, acc=0.8055555820465088, loss=0.808781623840332
train: epoch 110, loss 0.0589430145919323, acc=0.9853888750076294, loss=0.0589430145919323
test: epoch 110, loss 0.7793965935707092, acc=0.7666666507720947, loss=0.7793965935707092
train: epoch 111, loss 0.05565348267555237, acc=0.9845555424690247, loss=0.05565348267555237
test: epoch 111, loss 0.6325710415840149, acc=0.7972221970558167, loss=0.6325710415840149
train: epoch 112, loss 0.059100523591041565, acc=0.98416668176651, loss=0.059100523591041565
test: epoch 112, loss 0.7139989137649536, acc=0.8138889074325562, loss=0.7139989137649536
train: epoch 113, loss 0.046787843108177185, acc=0.9878888726234436, loss=0.046787843108177185
test: epoch 113, loss 0.8215471506118774, acc=0.8277778029441833, loss=0.8215471506118774
train: epoch 114, loss 0.04501306265592575, acc=0.9871666431427002, loss=0.04501306265592575
test: epoch 114, loss 0.9001929759979248, acc=0.8527777791023254, loss=0.9001929759979248
train: epoch 115, loss 0.05280331149697304, acc=0.9850555658340454, loss=0.05280331149697304
test: epoch 115, loss 0.6356601715087891, acc=0.8166666626930237, loss=0.6356601715087891
train: epoch 116, loss 0.04869749769568443, acc=0.9866666793823242, loss=0.04869749769568443
test: epoch 116, loss 0.54682457447052, acc=0.8527777791023254, loss=0.54682457447052
train: epoch 117, loss 0.05668685957789421, acc=0.9852222204208374, loss=0.05668685957789421
test: epoch 117, loss 0.5578117370605469, acc=0.824999988079071, loss=0.5578117370605469
train: epoch 118, loss 0.04576295614242554, acc=0.9868888854980469, loss=0.04576295614242554
test: epoch 118, loss 0.6258223056793213, acc=0.8333333134651184, loss=0.6258223056793213
train: epoch 119, loss 0.04801265522837639, acc=0.9875555634498596, loss=0.04801265522837639
test: epoch 119, loss 0.8496531248092651, acc=0.8111110925674438, loss=0.8496531248092651
train: epoch 120, loss 0.04214729368686676, acc=0.9883888959884644, loss=0.04214729368686676
test: epoch 120, loss 0.8384771943092346, acc=0.8416666388511658, loss=0.8384771943092346
train: epoch 121, loss 0.051491402089595795, acc=0.9865000247955322, loss=0.051491402089595795
test: epoch 121, loss 0.6474230885505676, acc=0.8111110925674438, loss=0.6474230885505676
train: epoch 122, loss 0.04570763558149338, acc=0.9862777590751648, loss=0.04570763558149338
test: epoch 122, loss 0.5941645503044128, acc=0.8611111044883728, loss=0.5941645503044128
train: epoch 123, loss 0.04298597574234009, acc=0.9883888959884644, loss=0.04298597574234009
test: epoch 123, loss 0.9732671976089478, acc=0.8111110925674438, loss=0.9732671976089478
train: epoch 124, loss 0.04501054063439369, acc=0.9869444370269775, loss=0.04501054063439369
test: epoch 124, loss 0.5433748364448547, acc=0.8416666388511658, loss=0.5433748364448547
train: epoch 125, loss 0.053362004458904266, acc=0.9851666688919067, loss=0.053362004458904266
test: epoch 125, loss 0.5289939045906067, acc=0.8611111044883728, loss=0.5289939045906067
train: epoch 126, loss 0.04943082109093666, acc=0.9867222309112549, loss=0.04943082109093666
test: epoch 126, loss 0.8431189656257629, acc=0.8277778029441833, loss=0.8431189656257629
train: epoch 127, loss 0.049245771020650864, acc=0.9854444265365601, loss=0.049245771020650864
test: epoch 127, loss 0.5785247087478638, acc=0.8111110925674438, loss=0.5785247087478638
train: epoch 128, loss 0.04967392235994339, acc=0.9861111044883728, loss=0.04967392235994339
test: epoch 128, loss 0.5081189870834351, acc=0.8527777791023254, loss=0.5081189870834351
train: epoch 129, loss 0.044082675129175186, acc=0.9871666431427002, loss=0.044082675129175186
test: epoch 129, loss 0.4720434546470642, acc=0.8472222089767456, loss=0.4720434546470642
train: epoch 130, loss 0.04440769925713539, acc=0.9873889088630676, loss=0.04440769925713539
test: epoch 130, loss 0.6138377785682678, acc=0.8500000238418579, loss=0.6138377785682678
train: epoch 131, loss 0.043893374502658844, acc=0.9877777695655823, loss=0.043893374502658844
test: epoch 131, loss 0.4939883053302765, acc=0.8277778029441833, loss=0.4939883053302765
train: epoch 132, loss 0.04487626254558563, acc=0.9867777824401855, loss=0.04487626254558563
test: epoch 132, loss 0.49211159348487854, acc=0.8444444537162781, loss=0.49211159348487854
train: epoch 133, loss 0.0475199855864048, acc=0.9849444627761841, loss=0.0475199855864048
test: epoch 133, loss 0.5791246891021729, acc=0.855555534362793, loss=0.5791246891021729
train: epoch 134, loss 0.04629382863640785, acc=0.9877777695655823, loss=0.04629382863640785
test: epoch 134, loss 0.734320342540741, acc=0.8333333134651184, loss=0.734320342540741
train: epoch 135, loss 0.03980877622961998, acc=0.9881666898727417, loss=0.03980877622961998
test: epoch 135, loss 0.6872657537460327, acc=0.8388888835906982, loss=0.6872657537460327
train: epoch 136, loss 0.04559961333870888, acc=0.9879444241523743, loss=0.04559961333870888
test: epoch 136, loss 0.7151846885681152, acc=0.824999988079071, loss=0.7151846885681152
train: epoch 137, loss 0.05274999141693115, acc=0.9847777485847473, loss=0.05274999141693115
test: epoch 137, loss 0.6504143476486206, acc=0.8472222089767456, loss=0.6504143476486206
train: epoch 138, loss 0.045737747102975845, acc=0.9869444370269775, loss=0.045737747102975845
test: epoch 138, loss 0.5057780146598816, acc=0.8666666746139526, loss=0.5057780146598816
train: epoch 139, loss 0.04515847563743591, acc=0.9864444732666016, loss=0.04515847563743591
test: epoch 139, loss 0.5169762372970581, acc=0.8805555701255798, loss=0.5169762372970581
train: epoch 140, loss 0.04556664451956749, acc=0.9879999756813049, loss=0.04556664451956749
test: epoch 140, loss 0.4489019811153412, acc=0.8333333134651184, loss=0.4489019811153412
train: epoch 141, loss 0.055051159113645554, acc=0.9862222075462341, loss=0.055051159113645554
test: epoch 141, loss 0.4388353228569031, acc=0.8472222089767456, loss=0.4388353228569031
train: epoch 142, loss 0.0434754379093647, acc=0.9869444370269775, loss=0.0434754379093647
test: epoch 142, loss 0.39253300428390503, acc=0.8611111044883728, loss=0.39253300428390503
train: epoch 143, loss 0.041323646903038025, acc=0.9877222180366516, loss=0.041323646903038025
test: epoch 143, loss 0.439898818731308, acc=0.855555534362793, loss=0.439898818731308
train: epoch 144, loss 0.05296412855386734, acc=0.9865555763244629, loss=0.05296412855386734
test: epoch 144, loss 0.7058742046356201, acc=0.8500000238418579, loss=0.7058742046356201
train: epoch 145, loss 0.04068617522716522, acc=0.9878888726234436, loss=0.04068617522716522
test: epoch 145, loss 0.43561995029449463, acc=0.855555534362793, loss=0.43561995029449463
train: epoch 146, loss 0.042548660188913345, acc=0.9869999885559082, loss=0.042548660188913345
test: epoch 146, loss 0.43593156337738037, acc=0.8527777791023254, loss=0.43593156337738037
train: epoch 147, loss 0.04419592767953873, acc=0.9869444370269775, loss=0.04419592767953873
test: epoch 147, loss 0.40876081585884094, acc=0.8611111044883728, loss=0.40876081585884094
train: epoch 148, loss 0.04937911033630371, acc=0.9850555658340454, loss=0.04937911033630371
test: epoch 148, loss 0.6480470895767212, acc=0.8361111283302307, loss=0.6480470895767212
train: epoch 149, loss 0.04444959759712219, acc=0.9883888959884644, loss=0.04444959759712219
test: epoch 149, loss 0.535642683506012, acc=0.8805555701255798, loss=0.535642683506012
train: epoch 150, loss 0.044227782636880875, acc=0.9878333210945129, loss=0.044227782636880875
test: epoch 150, loss 0.5092563033103943, acc=0.855555534362793, loss=0.5092563033103943
