# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1.5", "--temp_decay=1", "--one_hot=true", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=620986595, receiver_embed_dim=32, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.992122173309326, acc=0.09005555510520935, loss=2.992122173309326
test: epoch 1, loss 2.787320375442505, acc=0.0972222238779068, loss=2.787320375442505
train: epoch 2, loss 2.02594256401062, acc=0.20661111176013947, loss=2.02594256401062
test: epoch 2, loss 2.7849948406219482, acc=0.1527777761220932, loss=2.7849948406219482
train: epoch 3, loss 1.6903990507125854, acc=0.2767222225666046, loss=1.6903990507125854
test: epoch 3, loss 2.241244316101074, acc=0.22777777910232544, loss=2.241244316101074
train: epoch 4, loss 1.5043144226074219, acc=0.3458888828754425, loss=1.5043144226074219
test: epoch 4, loss 2.3632969856262207, acc=0.25833332538604736, loss=2.3632969856262207
train: epoch 5, loss 1.2982947826385498, acc=0.45233333110809326, loss=1.2982947826385498
test: epoch 5, loss 2.127254009246826, acc=0.25833332538604736, loss=2.127254009246826
train: epoch 6, loss 1.078866720199585, acc=0.5244444608688354, loss=1.078866720199585
test: epoch 6, loss 2.2718088626861572, acc=0.2888889014720917, loss=2.2718088626861572
train: epoch 7, loss 0.9483994841575623, acc=0.582111120223999, loss=0.9483994841575623
test: epoch 7, loss 1.8411149978637695, acc=0.3055555522441864, loss=1.8411149978637695
train: epoch 8, loss 0.8770966529846191, acc=0.6197777986526489, loss=0.8770966529846191
test: epoch 8, loss 1.593597412109375, acc=0.38333332538604736, loss=1.593597412109375
train: epoch 9, loss 0.810432493686676, acc=0.651888906955719, loss=0.810432493686676
test: epoch 9, loss 2.0001163482666016, acc=0.3861111104488373, loss=2.0001163482666016
train: epoch 10, loss 0.7425247430801392, acc=0.6775000095367432, loss=0.7425247430801392
test: epoch 10, loss 1.62847900390625, acc=0.375, loss=1.62847900390625
train: epoch 11, loss 0.7491084337234497, acc=0.6804444193840027, loss=0.7491084337234497
test: epoch 11, loss 1.6754157543182373, acc=0.4055555462837219, loss=1.6754157543182373
train: epoch 12, loss 0.6708241701126099, acc=0.7093889117240906, loss=0.6708241701126099
test: epoch 12, loss 1.7340826988220215, acc=0.4416666626930237, loss=1.7340826988220215
train: epoch 13, loss 0.6714814305305481, acc=0.707611083984375, loss=0.6714814305305481
test: epoch 13, loss 2.0128347873687744, acc=0.3472222089767456, loss=2.0128347873687744
train: epoch 14, loss 0.6192706823348999, acc=0.7331110835075378, loss=0.6192706823348999
test: epoch 14, loss 1.6019991636276245, acc=0.39444443583488464, loss=1.6019991636276245
train: epoch 15, loss 0.6065273880958557, acc=0.7404444217681885, loss=0.6065273880958557
test: epoch 15, loss 1.4613310098648071, acc=0.4583333432674408, loss=1.4613310098648071
train: epoch 16, loss 0.5542433261871338, acc=0.762333333492279, loss=0.5542433261871338
test: epoch 16, loss 1.679954171180725, acc=0.42222222685813904, loss=1.679954171180725
train: epoch 17, loss 0.5378254652023315, acc=0.7673333287239075, loss=0.5378254652023315
test: epoch 17, loss 1.8746707439422607, acc=0.43888887763023376, loss=1.8746707439422607
train: epoch 18, loss 0.5400052666664124, acc=0.7683888673782349, loss=0.5400052666664124
test: epoch 18, loss 1.6324795484542847, acc=0.45277777314186096, loss=1.6324795484542847
train: epoch 19, loss 0.5068883299827576, acc=0.7811111211776733, loss=0.5068883299827576
test: epoch 19, loss 1.625641107559204, acc=0.4972222149372101, loss=1.625641107559204
train: epoch 20, loss 0.46819940209388733, acc=0.7942222356796265, loss=0.46819940209388733
test: epoch 20, loss 1.316245436668396, acc=0.4611110985279083, loss=1.316245436668396
train: epoch 21, loss 0.4733111560344696, acc=0.7928333282470703, loss=0.4733111560344696
test: epoch 21, loss 1.6368502378463745, acc=0.5055555701255798, loss=1.6368502378463745
train: epoch 22, loss 0.47024667263031006, acc=0.7944999933242798, loss=0.47024667263031006
test: epoch 22, loss 1.5726996660232544, acc=0.5083333253860474, loss=1.5726996660232544
train: epoch 23, loss 0.4672450125217438, acc=0.7970555424690247, loss=0.4672450125217438
test: epoch 23, loss 1.247610092163086, acc=0.5277777910232544, loss=1.247610092163086
train: epoch 24, loss 0.4514768719673157, acc=0.8028333187103271, loss=0.4514768719673157
test: epoch 24, loss 1.7056671380996704, acc=0.47777777910232544, loss=1.7056671380996704
train: epoch 25, loss 0.4490867257118225, acc=0.8049444556236267, loss=0.4490867257118225
test: epoch 25, loss 1.3548576831817627, acc=0.5083333253860474, loss=1.3548576831817627
train: epoch 26, loss 0.44449010491371155, acc=0.80522221326828, loss=0.44449010491371155
test: epoch 26, loss 1.4166467189788818, acc=0.48055556416511536, loss=1.4166467189788818
train: epoch 27, loss 0.4338630437850952, acc=0.8102777600288391, loss=0.4338630437850952
test: epoch 27, loss 1.5895512104034424, acc=0.5111111402511597, loss=1.5895512104034424
train: epoch 28, loss 0.4324363172054291, acc=0.8107777833938599, loss=0.4324363172054291
test: epoch 28, loss 1.6339237689971924, acc=0.49166667461395264, loss=1.6339237689971924
train: epoch 29, loss 0.43658387660980225, acc=0.8115555644035339, loss=0.43658387660980225
test: epoch 29, loss 1.5548487901687622, acc=0.5138888955116272, loss=1.5548487901687622
train: epoch 30, loss 0.4176754951477051, acc=0.8187777996063232, loss=0.4176754951477051
test: epoch 30, loss 1.7487578392028809, acc=0.5027777552604675, loss=1.7487578392028809
train: epoch 31, loss 0.4118936061859131, acc=0.8213889002799988, loss=0.4118936061859131
test: epoch 31, loss 1.1794497966766357, acc=0.5611110925674438, loss=1.1794497966766357
train: epoch 32, loss 0.41892990469932556, acc=0.8199999928474426, loss=0.41892990469932556
test: epoch 32, loss 1.729872703552246, acc=0.4611110985279083, loss=1.729872703552246
train: epoch 33, loss 0.42170608043670654, acc=0.8157222270965576, loss=0.42170608043670654
test: epoch 33, loss 1.3606728315353394, acc=0.5333333611488342, loss=1.3606728315353394
train: epoch 34, loss 0.40191856026649475, acc=0.8261666893959045, loss=0.40191856026649475
test: epoch 34, loss 1.2953084707260132, acc=0.550000011920929, loss=1.2953084707260132
train: epoch 35, loss 0.4153329133987427, acc=0.8176666498184204, loss=0.4153329133987427
test: epoch 35, loss 1.3459852933883667, acc=0.5388888716697693, loss=1.3459852933883667
train: epoch 36, loss 0.39178648591041565, acc=0.8281111121177673, loss=0.39178648591041565
test: epoch 36, loss 1.4074161052703857, acc=0.550000011920929, loss=1.4074161052703857
train: epoch 37, loss 0.4112076163291931, acc=0.8218333125114441, loss=0.4112076163291931
test: epoch 37, loss 1.3377904891967773, acc=0.5055555701255798, loss=1.3377904891967773
train: epoch 38, loss 0.3868671655654907, acc=0.8298333287239075, loss=0.3868671655654907
test: epoch 38, loss 1.1945387125015259, acc=0.5555555820465088, loss=1.1945387125015259
train: epoch 39, loss 0.34413862228393555, acc=0.8514999747276306, loss=0.34413862228393555
test: epoch 39, loss 1.3361341953277588, acc=0.5944444537162781, loss=1.3361341953277588
train: epoch 40, loss 0.2971576750278473, acc=0.8660555481910706, loss=0.2971576750278473
test: epoch 40, loss 1.4914003610610962, acc=0.5805555582046509, loss=1.4914003610610962
train: epoch 41, loss 0.3068279027938843, acc=0.862666666507721, loss=0.3068279027938843
test: epoch 41, loss 1.3418854475021362, acc=0.5416666865348816, loss=1.3418854475021362
train: epoch 42, loss 0.3060680627822876, acc=0.8598889112472534, loss=0.3060680627822876
test: epoch 42, loss 1.2501274347305298, acc=0.6222222447395325, loss=1.2501274347305298
train: epoch 43, loss 0.30110904574394226, acc=0.8621666431427002, loss=0.30110904574394226
test: epoch 43, loss 1.0767052173614502, acc=0.6111111044883728, loss=1.0767052173614502
train: epoch 44, loss 0.2890172004699707, acc=0.8657222390174866, loss=0.2890172004699707
test: epoch 44, loss 1.3133162260055542, acc=0.5944444537162781, loss=1.3133162260055542
train: epoch 45, loss 0.2877676486968994, acc=0.8661110997200012, loss=0.2877676486968994
test: epoch 45, loss 1.3276809453964233, acc=0.6111111044883728, loss=1.3276809453964233
train: epoch 46, loss 0.2831740081310272, acc=0.8691666722297668, loss=0.2831740081310272
test: epoch 46, loss 1.3882863521575928, acc=0.5805555582046509, loss=1.3882863521575928
train: epoch 47, loss 0.2785230875015259, acc=0.8687777519226074, loss=0.2785230875015259
test: epoch 47, loss 1.2979909181594849, acc=0.6305555701255798, loss=1.2979909181594849
train: epoch 48, loss 0.2777028977870941, acc=0.8686110973358154, loss=0.2777028977870941
test: epoch 48, loss 1.0654792785644531, acc=0.644444465637207, loss=1.0654792785644531
train: epoch 49, loss 0.284869521856308, acc=0.8669999837875366, loss=0.284869521856308
test: epoch 49, loss 1.3851256370544434, acc=0.6361111402511597, loss=1.3851256370544434
train: epoch 50, loss 0.28006985783576965, acc=0.8720555305480957, loss=0.28006985783576965
test: epoch 50, loss 1.139159083366394, acc=0.6638888716697693, loss=1.139159083366394
train: epoch 51, loss 0.2532159090042114, acc=0.8768333196640015, loss=0.2532159090042114
test: epoch 51, loss 1.2187831401824951, acc=0.644444465637207, loss=1.2187831401824951
train: epoch 52, loss 0.2683701515197754, acc=0.8736110925674438, loss=0.2683701515197754
test: epoch 52, loss 1.164686918258667, acc=0.6666666865348816, loss=1.164686918258667
train: epoch 53, loss 0.2695385813713074, acc=0.8729444742202759, loss=0.2695385813713074
test: epoch 53, loss 0.9381439685821533, acc=0.6888889074325562, loss=0.9381439685821533
train: epoch 54, loss 0.27580899000167847, acc=0.8700000047683716, loss=0.27580899000167847
test: epoch 54, loss 1.0612601041793823, acc=0.6916666626930237, loss=1.0612601041793823
train: epoch 55, loss 0.2748134136199951, acc=0.8700555562973022, loss=0.2748134136199951
test: epoch 55, loss 1.0424082279205322, acc=0.6611111164093018, loss=1.0424082279205322
train: epoch 56, loss 0.24130810797214508, acc=0.8802777528762817, loss=0.24130810797214508
test: epoch 56, loss 0.8714313507080078, acc=0.6944444179534912, loss=0.8714313507080078
train: epoch 57, loss 0.2672887146472931, acc=0.8743333220481873, loss=0.2672887146472931
test: epoch 57, loss 0.8589585423469543, acc=0.675000011920929, loss=0.8589585423469543
train: epoch 58, loss 0.2649855315685272, acc=0.8778333067893982, loss=0.2649855315685272
test: epoch 58, loss 0.7774342894554138, acc=0.7083333134651184, loss=0.7774342894554138
train: epoch 59, loss 0.2587924599647522, acc=0.8756111264228821, loss=0.2587924599647522
test: epoch 59, loss 1.1819064617156982, acc=0.6555555462837219, loss=1.1819064617156982
train: epoch 60, loss 0.2572295367717743, acc=0.8781111240386963, loss=0.2572295367717743
test: epoch 60, loss 0.7365301251411438, acc=0.7222222089767456, loss=0.7365301251411438
train: epoch 61, loss 0.24596360325813293, acc=0.8812777996063232, loss=0.24596360325813293
test: epoch 61, loss 1.3791000843048096, acc=0.6472222208976746, loss=1.3791000843048096
train: epoch 62, loss 0.25690555572509766, acc=0.878000020980835, loss=0.25690555572509766
test: epoch 62, loss 0.9498230814933777, acc=0.699999988079071, loss=0.9498230814933777
train: epoch 63, loss 0.24354536831378937, acc=0.8801110982894897, loss=0.24354536831378937
test: epoch 63, loss 1.2378051280975342, acc=0.6694444417953491, loss=1.2378051280975342
train: epoch 64, loss 0.23737309873104095, acc=0.8856111168861389, loss=0.23737309873104095
test: epoch 64, loss 1.104371428489685, acc=0.6833333373069763, loss=1.104371428489685
train: epoch 65, loss 0.24014456570148468, acc=0.8853333592414856, loss=0.24014456570148468
test: epoch 65, loss 1.1210278272628784, acc=0.6722221970558167, loss=1.1210278272628784
train: epoch 66, loss 0.24744276702404022, acc=0.8812777996063232, loss=0.24744276702404022
test: epoch 66, loss 0.9509974122047424, acc=0.7027778029441833, loss=0.9509974122047424
train: epoch 67, loss 0.2491312026977539, acc=0.8820555806159973, loss=0.2491312026977539
test: epoch 67, loss 0.8423396944999695, acc=0.7027778029441833, loss=0.8423396944999695
train: epoch 68, loss 0.23488843441009521, acc=0.8844444155693054, loss=0.23488843441009521
test: epoch 68, loss 0.9689306020736694, acc=0.7166666388511658, loss=0.9689306020736694
train: epoch 69, loss 0.24666808545589447, acc=0.8837777972221375, loss=0.24666808545589447
test: epoch 69, loss 0.8788231015205383, acc=0.7416666746139526, loss=0.8788231015205383
train: epoch 70, loss 0.2352696657180786, acc=0.8878889083862305, loss=0.2352696657180786
test: epoch 70, loss 0.9691458344459534, acc=0.7277777791023254, loss=0.9691458344459534
train: epoch 71, loss 0.2512356638908386, acc=0.8828333616256714, loss=0.2512356638908386
test: epoch 71, loss 0.9048834443092346, acc=0.7333333492279053, loss=0.9048834443092346
train: epoch 72, loss 0.24134255945682526, acc=0.8834999799728394, loss=0.24134255945682526
test: epoch 72, loss 0.7107204794883728, acc=0.730555534362793, loss=0.7107204794883728
train: epoch 73, loss 0.23808790743350983, acc=0.8841666579246521, loss=0.23808790743350983
test: epoch 73, loss 0.7594542503356934, acc=0.7361111044883728, loss=0.7594542503356934
train: epoch 74, loss 0.2523801028728485, acc=0.8837222456932068, loss=0.2523801028728485
test: epoch 74, loss 0.9199355244636536, acc=0.7027778029441833, loss=0.9199355244636536
train: epoch 75, loss 0.2169882208108902, acc=0.8927778005599976, loss=0.2169882208108902
test: epoch 75, loss 0.9054629802703857, acc=0.7472222447395325, loss=0.9054629802703857
train: epoch 76, loss 0.24214111268520355, acc=0.8841111063957214, loss=0.24214111268520355
test: epoch 76, loss 0.740009605884552, acc=0.7472222447395325, loss=0.740009605884552
train: epoch 77, loss 0.22493623197078705, acc=0.8901666402816772, loss=0.22493623197078705
test: epoch 77, loss 0.8637043833732605, acc=0.7444444298744202, loss=0.8637043833732605
train: epoch 78, loss 0.23155972361564636, acc=0.8898333311080933, loss=0.23155972361564636
test: epoch 78, loss 0.7712526321411133, acc=0.7361111044883728, loss=0.7712526321411133
train: epoch 79, loss 0.2323116809129715, acc=0.8895000219345093, loss=0.2323116809129715
test: epoch 79, loss 0.6247388124465942, acc=0.7749999761581421, loss=0.6247388124465942
train: epoch 80, loss 0.22890406847000122, acc=0.8916666507720947, loss=0.22890406847000122
test: epoch 80, loss 0.6666992902755737, acc=0.7666666507720947, loss=0.6666992902755737
train: epoch 81, loss 0.23339492082595825, acc=0.8857222199440002, loss=0.23339492082595825
test: epoch 81, loss 0.7787409424781799, acc=0.7722222208976746, loss=0.7787409424781799
train: epoch 82, loss 0.21999192237854004, acc=0.8921111226081848, loss=0.21999192237854004
test: epoch 82, loss 0.5878668427467346, acc=0.7666666507720947, loss=0.5878668427467346
train: epoch 83, loss 0.2306470423936844, acc=0.8886666893959045, loss=0.2306470423936844
test: epoch 83, loss 0.7333488464355469, acc=0.7611111402511597, loss=0.7333488464355469
train: epoch 84, loss 0.22034934163093567, acc=0.8916666507720947, loss=0.22034934163093567
test: epoch 84, loss 0.6396622061729431, acc=0.7611111402511597, loss=0.6396622061729431
train: epoch 85, loss 0.21748048067092896, acc=0.8926666378974915, loss=0.21748048067092896
test: epoch 85, loss 0.8729466199874878, acc=0.7444444298744202, loss=0.8729466199874878
train: epoch 86, loss 0.23001828789710999, acc=0.8905555605888367, loss=0.23001828789710999
test: epoch 86, loss 0.7180469036102295, acc=0.7527777552604675, loss=0.7180469036102295
train: epoch 87, loss 0.22896189987659454, acc=0.8897777795791626, loss=0.22896189987659454
test: epoch 87, loss 0.7786474823951721, acc=0.7416666746139526, loss=0.7786474823951721
train: epoch 88, loss 0.21357694268226624, acc=0.8938888907432556, loss=0.21357694268226624
test: epoch 88, loss 0.6596705317497253, acc=0.7416666746139526, loss=0.6596705317497253
train: epoch 89, loss 0.2224070131778717, acc=0.890666663646698, loss=0.2224070131778717
test: epoch 89, loss 0.998077929019928, acc=0.7277777791023254, loss=0.998077929019928
train: epoch 90, loss 0.21394550800323486, acc=0.8950555324554443, loss=0.21394550800323486
test: epoch 90, loss 0.7684508562088013, acc=0.7583333253860474, loss=0.7684508562088013
train: epoch 91, loss 0.20914803445339203, acc=0.8955000042915344, loss=0.20914803445339203
test: epoch 91, loss 0.560314416885376, acc=0.7722222208976746, loss=0.560314416885376
train: epoch 92, loss 0.21641777455806732, acc=0.8923888802528381, loss=0.21641777455806732
test: epoch 92, loss 0.9235129952430725, acc=0.730555534362793, loss=0.9235129952430725
train: epoch 93, loss 0.21070201694965363, acc=0.894611120223999, loss=0.21070201694965363
test: epoch 93, loss 0.6523904204368591, acc=0.7638888955116272, loss=0.6523904204368591
train: epoch 94, loss 0.2200738936662674, acc=0.8925555348396301, loss=0.2200738936662674
test: epoch 94, loss 0.6500515341758728, acc=0.7611111402511597, loss=0.6500515341758728
train: epoch 95, loss 0.2156996726989746, acc=0.891777753829956, loss=0.2156996726989746
test: epoch 95, loss 0.673704981803894, acc=0.7472222447395325, loss=0.673704981803894
train: epoch 96, loss 0.19863352179527283, acc=0.8974999785423279, loss=0.19863352179527283
test: epoch 96, loss 0.7786667943000793, acc=0.7638888955116272, loss=0.7786667943000793
train: epoch 97, loss 0.20859399437904358, acc=0.8992778062820435, loss=0.20859399437904358
test: epoch 97, loss 0.6455994844436646, acc=0.7666666507720947, loss=0.6455994844436646
train: epoch 98, loss 0.18253189325332642, acc=0.9205555319786072, loss=0.18253189325332642
test: epoch 98, loss 0.7284018993377686, acc=0.7555555701255798, loss=0.7284018993377686
train: epoch 99, loss 0.17971572279930115, acc=0.9222777485847473, loss=0.17971572279930115
test: epoch 99, loss 0.6782777905464172, acc=0.7749999761581421, loss=0.6782777905464172
train: epoch 100, loss 0.17527155578136444, acc=0.9247221946716309, loss=0.17527155578136444
test: epoch 100, loss 0.6867005228996277, acc=0.7583333253860474, loss=0.6867005228996277
train: epoch 101, loss 0.1650785207748413, acc=0.9258333444595337, loss=0.1650785207748413
test: epoch 101, loss 0.7423447966575623, acc=0.7722222208976746, loss=0.7423447966575623
train: epoch 102, loss 0.15233764052391052, acc=0.9290000200271606, loss=0.15233764052391052
test: epoch 102, loss 0.8318446278572083, acc=0.769444465637207, loss=0.8318446278572083
train: epoch 103, loss 0.17266225814819336, acc=0.9205555319786072, loss=0.17266225814819336
test: epoch 103, loss 0.7569047808647156, acc=0.769444465637207, loss=0.7569047808647156
train: epoch 104, loss 0.14078402519226074, acc=0.9304444193840027, loss=0.14078402519226074
test: epoch 104, loss 0.6039496064186096, acc=0.7833333611488342, loss=0.6039496064186096
train: epoch 105, loss 0.15229175984859467, acc=0.9319444298744202, loss=0.15229175984859467
test: epoch 105, loss 0.8406168818473816, acc=0.7416666746139526, loss=0.8406168818473816
train: epoch 106, loss 0.1612299084663391, acc=0.9273889064788818, loss=0.1612299084663391
test: epoch 106, loss 0.8651654720306396, acc=0.7444444298744202, loss=0.8651654720306396
train: epoch 107, loss 0.1481308937072754, acc=0.9310555458068848, loss=0.1481308937072754
test: epoch 107, loss 0.8272369503974915, acc=0.7833333611488342, loss=0.8272369503974915
train: epoch 108, loss 0.15116029977798462, acc=0.9302777647972107, loss=0.15116029977798462
test: epoch 108, loss 0.7070120573043823, acc=0.800000011920929, loss=0.7070120573043823
train: epoch 109, loss 0.13765257596969604, acc=0.9352777600288391, loss=0.13765257596969604
test: epoch 109, loss 0.680442750453949, acc=0.8138889074325562, loss=0.680442750453949
train: epoch 110, loss 0.15739615261554718, acc=0.9299444556236267, loss=0.15739615261554718
test: epoch 110, loss 0.5962163209915161, acc=0.8166666626930237, loss=0.5962163209915161
train: epoch 111, loss 0.14576885104179382, acc=0.933222234249115, loss=0.14576885104179382
test: epoch 111, loss 0.7532120943069458, acc=0.8027777671813965, loss=0.7532120943069458
train: epoch 112, loss 0.13971389830112457, acc=0.9333333373069763, loss=0.13971389830112457
test: epoch 112, loss 0.5901878476142883, acc=0.8083333373069763, loss=0.5901878476142883
train: epoch 113, loss 0.14703094959259033, acc=0.9323333501815796, loss=0.14703094959259033
test: epoch 113, loss 0.7680754661560059, acc=0.7861111164093018, loss=0.7680754661560059
train: epoch 114, loss 0.12655964493751526, acc=0.9363889098167419, loss=0.12655964493751526
test: epoch 114, loss 0.5608959197998047, acc=0.8138889074325562, loss=0.5608959197998047
train: epoch 115, loss 0.13027672469615936, acc=0.9367222189903259, loss=0.13027672469615936
test: epoch 115, loss 0.7839246988296509, acc=0.8083333373069763, loss=0.7839246988296509
train: epoch 116, loss 0.13764767348766327, acc=0.9351111054420471, loss=0.13764767348766327
test: epoch 116, loss 0.5334277749061584, acc=0.8305555582046509, loss=0.5334277749061584
train: epoch 117, loss 0.13180118799209595, acc=0.9377777576446533, loss=0.13180118799209595
test: epoch 117, loss 0.7283507585525513, acc=0.8138889074325562, loss=0.7283507585525513
train: epoch 118, loss 0.1425076425075531, acc=0.9356666803359985, loss=0.1425076425075531
test: epoch 118, loss 0.6357169151306152, acc=0.8138889074325562, loss=0.6357169151306152
train: epoch 119, loss 0.13456758856773376, acc=0.9362778067588806, loss=0.13456758856773376
test: epoch 119, loss 0.6183193922042847, acc=0.8333333134651184, loss=0.6183193922042847
train: epoch 120, loss 0.1291981041431427, acc=0.9365555644035339, loss=0.1291981041431427
test: epoch 120, loss 0.7300300002098083, acc=0.8138889074325562, loss=0.7300300002098083
train: epoch 121, loss 0.15501490235328674, acc=0.9315000176429749, loss=0.15501490235328674
test: epoch 121, loss 0.7150408029556274, acc=0.8277778029441833, loss=0.7150408029556274
train: epoch 122, loss 0.14025714993476868, acc=0.9365000128746033, loss=0.14025714993476868
test: epoch 122, loss 0.5729036331176758, acc=0.8111110925674438, loss=0.5729036331176758
train: epoch 123, loss 0.12026292085647583, acc=0.9415000081062317, loss=0.12026292085647583
test: epoch 123, loss 0.6886835694313049, acc=0.8138889074325562, loss=0.6886835694313049
train: epoch 124, loss 0.12678280472755432, acc=0.9390000104904175, loss=0.12678280472755432
test: epoch 124, loss 0.6109926104545593, acc=0.8138889074325562, loss=0.6109926104545593
train: epoch 125, loss 0.13510136306285858, acc=0.9344444274902344, loss=0.13510136306285858
test: epoch 125, loss 0.5032657384872437, acc=0.8277778029441833, loss=0.5032657384872437
train: epoch 126, loss 0.1284070461988449, acc=0.9367222189903259, loss=0.1284070461988449
test: epoch 126, loss 0.7906929850578308, acc=0.8166666626930237, loss=0.7906929850578308
train: epoch 127, loss 0.12459421157836914, acc=0.9391666650772095, loss=0.12459421157836914
test: epoch 127, loss 0.4942382872104645, acc=0.8333333134651184, loss=0.4942382872104645
train: epoch 128, loss 0.11964070051908493, acc=0.9408888816833496, loss=0.11964070051908493
test: epoch 128, loss 0.8136730790138245, acc=0.8194444179534912, loss=0.8136730790138245
train: epoch 129, loss 0.12383504956960678, acc=0.9397777915000916, loss=0.12383504956960678
test: epoch 129, loss 0.6931954622268677, acc=0.8138889074325562, loss=0.6931954622268677
train: epoch 130, loss 0.13923901319503784, acc=0.9347777962684631, loss=0.13923901319503784
test: epoch 130, loss 0.579663097858429, acc=0.8305555582046509, loss=0.579663097858429
train: epoch 131, loss 0.12390629947185516, acc=0.9391111135482788, loss=0.12390629947185516
test: epoch 131, loss 0.7267730236053467, acc=0.8305555582046509, loss=0.7267730236053467
train: epoch 132, loss 0.1411798894405365, acc=0.9355555772781372, loss=0.1411798894405365
test: epoch 132, loss 0.6336016058921814, acc=0.8055555820465088, loss=0.6336016058921814
train: epoch 133, loss 0.11757936328649521, acc=0.9423333406448364, loss=0.11757936328649521
test: epoch 133, loss 0.5041162967681885, acc=0.8333333134651184, loss=0.5041162967681885
train: epoch 134, loss 0.16045944392681122, acc=0.9315555691719055, loss=0.16045944392681122
test: epoch 134, loss 0.47350987792015076, acc=0.8361111283302307, loss=0.47350987792015076
train: epoch 135, loss 0.11190014332532883, acc=0.9418333172798157, loss=0.11190014332532883
test: epoch 135, loss 0.669035792350769, acc=0.8222222328186035, loss=0.669035792350769
train: epoch 136, loss 0.10892046988010406, acc=0.9454444646835327, loss=0.10892046988010406
test: epoch 136, loss 0.5994136929512024, acc=0.8277778029441833, loss=0.5994136929512024
train: epoch 137, loss 0.11100408434867859, acc=0.9427777528762817, loss=0.11100408434867859
test: epoch 137, loss 0.8191660642623901, acc=0.8055555820465088, loss=0.8191660642623901
train: epoch 138, loss 0.14478255808353424, acc=0.9333333373069763, loss=0.14478255808353424
test: epoch 138, loss 0.5388473868370056, acc=0.8305555582046509, loss=0.5388473868370056
train: epoch 139, loss 0.12066075950860977, acc=0.941611111164093, loss=0.12066075950860977
test: epoch 139, loss 0.6097240447998047, acc=0.8444444537162781, loss=0.6097240447998047
train: epoch 140, loss 0.11647062748670578, acc=0.9423888921737671, loss=0.11647062748670578
test: epoch 140, loss 0.5649657249450684, acc=0.8444444537162781, loss=0.5649657249450684
train: epoch 141, loss 0.11434328556060791, acc=0.9421111345291138, loss=0.11434328556060791
test: epoch 141, loss 0.5559156537055969, acc=0.8416666388511658, loss=0.5559156537055969
train: epoch 142, loss 0.11640587449073792, acc=0.9426666498184204, loss=0.11640587449073792
test: epoch 142, loss 0.60491544008255, acc=0.8388888835906982, loss=0.60491544008255
train: epoch 143, loss 0.12043002247810364, acc=0.9421111345291138, loss=0.12043002247810364
test: epoch 143, loss 0.6881775856018066, acc=0.8333333134651184, loss=0.6881775856018066
train: epoch 144, loss 0.10272478312253952, acc=0.9459999799728394, loss=0.10272478312253952
test: epoch 144, loss 0.5550370812416077, acc=0.8416666388511658, loss=0.5550370812416077
train: epoch 145, loss 0.11540760099887848, acc=0.9424444437026978, loss=0.11540760099887848
test: epoch 145, loss 0.6204450130462646, acc=0.8388888835906982, loss=0.6204450130462646
train: epoch 146, loss 0.11538821458816528, acc=0.9429444670677185, loss=0.11538821458816528
test: epoch 146, loss 0.6268563866615295, acc=0.8361111283302307, loss=0.6268563866615295
train: epoch 147, loss 0.12972202897071838, acc=0.937333345413208, loss=0.12972202897071838
test: epoch 147, loss 0.5291098952293396, acc=0.8138889074325562, loss=0.5291098952293396
train: epoch 148, loss 0.14008992910385132, acc=0.9305555820465088, loss=0.14008992910385132
test: epoch 148, loss 0.6399088501930237, acc=0.8222222328186035, loss=0.6399088501930237
train: epoch 149, loss 0.1030936911702156, acc=0.9450555443763733, loss=0.1030936911702156
test: epoch 149, loss 0.5831155180931091, acc=0.8166666626930237, loss=0.5831155180931091
train: epoch 150, loss 0.13532991707324982, acc=0.9388333559036255, loss=0.13532991707324982
test: epoch 150, loss 0.6859268546104431, acc=0.8222222328186035, loss=0.6859268546104431
