# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=false", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=53005774, receiver_embed_dim=128, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.0161473751068115, acc=0.09316666424274445, loss=3.0161473751068115
test: epoch 1, loss 2.7820940017700195, acc=0.11388888955116272, loss=2.7820940017700195
train: epoch 2, loss 1.7761824131011963, acc=0.28522223234176636, loss=1.7761824131011963
test: epoch 2, loss 2.443751096725464, acc=0.16388888657093048, loss=2.443751096725464
train: epoch 3, loss 1.4276319742202759, acc=0.40627777576446533, loss=1.4276319742202759
test: epoch 3, loss 2.4426302909851074, acc=0.18888889253139496, loss=2.4426302909851074
train: epoch 4, loss 1.2429044246673584, acc=0.4894999861717224, loss=1.2429044246673584
test: epoch 4, loss 2.4578075408935547, acc=0.19722221791744232, loss=2.4578075408935547
train: epoch 5, loss 1.1032021045684814, acc=0.5456110835075378, loss=1.1032021045684814
test: epoch 5, loss 2.3232712745666504, acc=0.24722221493721008, loss=2.3232712745666504
train: epoch 6, loss 1.0046018362045288, acc=0.5886111259460449, loss=1.0046018362045288
test: epoch 6, loss 2.225302219390869, acc=0.24722221493721008, loss=2.225302219390869
train: epoch 7, loss 0.9305059909820557, acc=0.6200555562973022, loss=0.9305059909820557
test: epoch 7, loss 2.2728800773620605, acc=0.24166665971279144, loss=2.2728800773620605
train: epoch 8, loss 0.8608914017677307, acc=0.6530555486679077, loss=0.8608914017677307
test: epoch 8, loss 2.002164363861084, acc=0.28611111640930176, loss=2.002164363861084
train: epoch 9, loss 0.8091115951538086, acc=0.6741666793823242, loss=0.8091115951538086
test: epoch 9, loss 2.072012186050415, acc=0.3083333373069763, loss=2.072012186050415
train: epoch 10, loss 0.7569447755813599, acc=0.6923333406448364, loss=0.7569447755813599
test: epoch 10, loss 2.011652708053589, acc=0.2777777910232544, loss=2.011652708053589
train: epoch 11, loss 0.7188301086425781, acc=0.710777759552002, loss=0.7188301086425781
test: epoch 11, loss 2.0838639736175537, acc=0.31388887763023376, loss=2.0838639736175537
train: epoch 12, loss 0.6929576396942139, acc=0.7213888764381409, loss=0.6929576396942139
test: epoch 12, loss 2.0865936279296875, acc=0.3222222328186035, loss=2.0865936279296875
train: epoch 13, loss 0.6550764441490173, acc=0.7402222156524658, loss=0.6550764441490173
test: epoch 13, loss 1.9026862382888794, acc=0.3611111044883728, loss=1.9026862382888794
train: epoch 14, loss 0.6371537446975708, acc=0.7488889098167419, loss=0.6371537446975708
test: epoch 14, loss 2.035637378692627, acc=0.3083333373069763, loss=2.035637378692627
train: epoch 15, loss 0.6050876975059509, acc=0.7590555548667908, loss=0.6050876975059509
test: epoch 15, loss 2.095689296722412, acc=0.3333333432674408, loss=2.095689296722412
train: epoch 16, loss 0.580680251121521, acc=0.7649444341659546, loss=0.580680251121521
test: epoch 16, loss 1.9318156242370605, acc=0.3722222149372101, loss=1.9318156242370605
train: epoch 17, loss 0.5624658465385437, acc=0.7760555744171143, loss=0.5624658465385437
test: epoch 17, loss 2.0065882205963135, acc=0.36666667461395264, loss=2.0065882205963135
train: epoch 18, loss 0.5270965099334717, acc=0.7903888821601868, loss=0.5270965099334717
test: epoch 18, loss 2.052342176437378, acc=0.375, loss=2.052342176437378
train: epoch 19, loss 0.5304237604141235, acc=0.7919999957084656, loss=0.5304237604141235
test: epoch 19, loss 2.1379735469818115, acc=0.3472222089767456, loss=2.1379735469818115
train: epoch 20, loss 0.4932599663734436, acc=0.8059444427490234, loss=0.4932599663734436
test: epoch 20, loss 1.8932621479034424, acc=0.3916666805744171, loss=1.8932621479034424
train: epoch 21, loss 0.4950164258480072, acc=0.8082777857780457, loss=0.4950164258480072
test: epoch 21, loss 2.18752384185791, acc=0.36944442987442017, loss=2.18752384185791
train: epoch 22, loss 0.4762246608734131, acc=0.8149999976158142, loss=0.4762246608734131
test: epoch 22, loss 1.9993047714233398, acc=0.375, loss=1.9993047714233398
train: epoch 23, loss 0.4518408179283142, acc=0.8208333253860474, loss=0.4518408179283142
test: epoch 23, loss 2.1974968910217285, acc=0.39444443583488464, loss=2.1974968910217285
train: epoch 24, loss 0.4577535390853882, acc=0.8249444365501404, loss=0.4577535390853882
test: epoch 24, loss 1.9366534948349, acc=0.43888887763023376, loss=1.9366534948349
train: epoch 25, loss 0.4326246976852417, acc=0.8313888907432556, loss=0.4326246976852417
test: epoch 25, loss 2.3379106521606445, acc=0.4027777910232544, loss=2.3379106521606445
train: epoch 26, loss 0.421745628118515, acc=0.8349444270133972, loss=0.421745628118515
test: epoch 26, loss 1.8246796131134033, acc=0.4277777671813965, loss=1.8246796131134033
train: epoch 27, loss 0.41042226552963257, acc=0.8378333449363708, loss=0.41042226552963257
test: epoch 27, loss 1.9887542724609375, acc=0.4055555462837219, loss=1.9887542724609375
train: epoch 28, loss 0.3939288258552551, acc=0.8459444642066956, loss=0.3939288258552551
test: epoch 28, loss 2.0117692947387695, acc=0.4194444417953491, loss=2.0117692947387695
train: epoch 29, loss 0.3947460949420929, acc=0.8479999899864197, loss=0.3947460949420929
test: epoch 29, loss 2.310737371444702, acc=0.3916666805744171, loss=2.310737371444702
train: epoch 30, loss 0.38568806648254395, acc=0.8526666760444641, loss=0.38568806648254395
test: epoch 30, loss 2.1267969608306885, acc=0.3777777850627899, loss=2.1267969608306885
train: epoch 31, loss 0.37961670756340027, acc=0.8535000085830688, loss=0.37961670756340027
test: epoch 31, loss 2.082685708999634, acc=0.3722222149372101, loss=2.082685708999634
train: epoch 32, loss 0.38971754908561707, acc=0.851722240447998, loss=0.38971754908561707
test: epoch 32, loss 2.012251615524292, acc=0.4194444417953491, loss=2.012251615524292
train: epoch 33, loss 0.36714255809783936, acc=0.8541666865348816, loss=0.36714255809783936
test: epoch 33, loss 2.0498483180999756, acc=0.43888887763023376, loss=2.0498483180999756
train: epoch 34, loss 0.36290258169174194, acc=0.858222246170044, loss=0.36290258169174194
test: epoch 34, loss 1.9924525022506714, acc=0.42222222685813904, loss=1.9924525022506714
train: epoch 35, loss 0.36265829205513, acc=0.8620555400848389, loss=0.36265829205513
test: epoch 35, loss 2.016752243041992, acc=0.43888887763023376, loss=2.016752243041992
train: epoch 36, loss 0.34841006994247437, acc=0.8627222180366516, loss=0.34841006994247437
test: epoch 36, loss 2.058145761489868, acc=0.4472222328186035, loss=2.058145761489868
train: epoch 37, loss 0.36701101064682007, acc=0.8602777719497681, loss=0.36701101064682007
test: epoch 37, loss 2.2432515621185303, acc=0.4277777671813965, loss=2.2432515621185303
train: epoch 38, loss 0.35116004943847656, acc=0.8640000224113464, loss=0.35116004943847656
test: epoch 38, loss 1.9420119524002075, acc=0.4472222328186035, loss=1.9420119524002075
train: epoch 39, loss 0.33805370330810547, acc=0.8707777857780457, loss=0.33805370330810547
test: epoch 39, loss 2.0419561862945557, acc=0.4583333432674408, loss=2.0419561862945557
train: epoch 40, loss 0.33871814608573914, acc=0.8730555772781372, loss=0.33871814608573914
test: epoch 40, loss 2.183321952819824, acc=0.4277777671813965, loss=2.183321952819824
train: epoch 41, loss 0.3320651054382324, acc=0.8773333430290222, loss=0.3320651054382324
test: epoch 41, loss 1.8638542890548706, acc=0.4305555522441864, loss=1.8638542890548706
train: epoch 42, loss 0.32788482308387756, acc=0.8731666803359985, loss=0.32788482308387756
test: epoch 42, loss 2.120753526687622, acc=0.4722222089767456, loss=2.120753526687622
train: epoch 43, loss 0.3111940622329712, acc=0.88355553150177, loss=0.3111940622329712
test: epoch 43, loss 2.16357159614563, acc=0.4472222328186035, loss=2.16357159614563
train: epoch 44, loss 0.3197362422943115, acc=0.8784999847412109, loss=0.3197362422943115
test: epoch 44, loss 2.26591420173645, acc=0.4749999940395355, loss=2.26591420173645
train: epoch 45, loss 0.3077235817909241, acc=0.8848888874053955, loss=0.3077235817909241
test: epoch 45, loss 1.9533288478851318, acc=0.47777777910232544, loss=1.9533288478851318
train: epoch 46, loss 0.29124265909194946, acc=0.8895000219345093, loss=0.29124265909194946
test: epoch 46, loss 2.3710713386535645, acc=0.44999998807907104, loss=2.3710713386535645
train: epoch 47, loss 0.29706981778144836, acc=0.8905555605888367, loss=0.29706981778144836
test: epoch 47, loss 2.03419828414917, acc=0.4972222149372101, loss=2.03419828414917
train: epoch 48, loss 0.29404258728027344, acc=0.8934444189071655, loss=0.29404258728027344
test: epoch 48, loss 2.350445508956909, acc=0.43611112236976624, loss=2.350445508956909
train: epoch 49, loss 0.28862982988357544, acc=0.8939999938011169, loss=0.28862982988357544
test: epoch 49, loss 2.210803508758545, acc=0.4749999940395355, loss=2.210803508758545
train: epoch 50, loss 0.2757328152656555, acc=0.8970000147819519, loss=0.2757328152656555
test: epoch 50, loss 2.390996217727661, acc=0.4416666626930237, loss=2.390996217727661
train: epoch 51, loss 0.28068777918815613, acc=0.8965555429458618, loss=0.28068777918815613
test: epoch 51, loss 2.6291472911834717, acc=0.4749999940395355, loss=2.6291472911834717
train: epoch 52, loss 0.28104403614997864, acc=0.8947222232818604, loss=0.28104403614997864
test: epoch 52, loss 2.1433181762695312, acc=0.4694444537162781, loss=2.1433181762695312
train: epoch 53, loss 0.27274370193481445, acc=0.898722231388092, loss=0.27274370193481445
test: epoch 53, loss 2.3092288970947266, acc=0.4861111044883728, loss=2.3092288970947266
train: epoch 54, loss 0.2621351480484009, acc=0.8992778062820435, loss=0.2621351480484009
test: epoch 54, loss 2.1944375038146973, acc=0.4861111044883728, loss=2.1944375038146973
train: epoch 55, loss 0.2691563069820404, acc=0.897777795791626, loss=0.2691563069820404
test: epoch 55, loss 2.1221089363098145, acc=0.49444442987442017, loss=2.1221089363098145
train: epoch 56, loss 0.2790645658969879, acc=0.8955000042915344, loss=0.2790645658969879
test: epoch 56, loss 2.154742479324341, acc=0.4749999940395355, loss=2.154742479324341
train: epoch 57, loss 0.2572481632232666, acc=0.8998333215713501, loss=0.2572481632232666
test: epoch 57, loss 2.367985248565674, acc=0.46666666865348816, loss=2.367985248565674
train: epoch 58, loss 0.2651602029800415, acc=0.9010000228881836, loss=0.2651602029800415
test: epoch 58, loss 2.0955235958099365, acc=0.4861111044883728, loss=2.0955235958099365
train: epoch 59, loss 0.27888256311416626, acc=0.8961666822433472, loss=0.27888256311416626
test: epoch 59, loss 2.0190558433532715, acc=0.5055555701255798, loss=2.0190558433532715
train: epoch 60, loss 0.2591751217842102, acc=0.9021111130714417, loss=0.2591751217842102
test: epoch 60, loss 2.3496267795562744, acc=0.4833333194255829, loss=2.3496267795562744
train: epoch 61, loss 0.2635509967803955, acc=0.9001111388206482, loss=0.2635509967803955
test: epoch 61, loss 2.421785831451416, acc=0.5166666507720947, loss=2.421785831451416
train: epoch 62, loss 0.27028927206993103, acc=0.9018333554267883, loss=0.27028927206993103
test: epoch 62, loss 1.9374746084213257, acc=0.5111111402511597, loss=1.9374746084213257
train: epoch 63, loss 0.25469017028808594, acc=0.903333306312561, loss=0.25469017028808594
test: epoch 63, loss 2.2023537158966064, acc=0.5138888955116272, loss=2.2023537158966064
train: epoch 64, loss 0.2757045328617096, acc=0.8994444608688354, loss=0.2757045328617096
test: epoch 64, loss 2.339625120162964, acc=0.48055556416511536, loss=2.339625120162964
train: epoch 65, loss 0.26116231083869934, acc=0.9020000100135803, loss=0.26116231083869934
test: epoch 65, loss 2.2514712810516357, acc=0.5166666507720947, loss=2.2514712810516357
train: epoch 66, loss 0.26148664951324463, acc=0.9031111001968384, loss=0.26148664951324463
test: epoch 66, loss 2.0126845836639404, acc=0.5361111164093018, loss=2.0126845836639404
train: epoch 67, loss 0.2659248113632202, acc=0.8995000123977661, loss=0.2659248113632202
test: epoch 67, loss 2.101081132888794, acc=0.519444465637207, loss=2.101081132888794
train: epoch 68, loss 0.26235103607177734, acc=0.8995555639266968, loss=0.26235103607177734
test: epoch 68, loss 1.9183838367462158, acc=0.5277777910232544, loss=1.9183838367462158
train: epoch 69, loss 0.26384642720222473, acc=0.9002777934074402, loss=0.26384642720222473
test: epoch 69, loss 1.951987385749817, acc=0.5055555701255798, loss=1.951987385749817
train: epoch 70, loss 0.257546603679657, acc=0.8986666798591614, loss=0.257546603679657
test: epoch 70, loss 2.105041265487671, acc=0.5249999761581421, loss=2.105041265487671
train: epoch 71, loss 0.26333099603652954, acc=0.899222195148468, loss=0.26333099603652954
test: epoch 71, loss 1.8735891580581665, acc=0.519444465637207, loss=1.8735891580581665
train: epoch 72, loss 0.26648810505867004, acc=0.8973888754844666, loss=0.26648810505867004
test: epoch 72, loss 2.068829298019409, acc=0.5305555462837219, loss=2.068829298019409
train: epoch 73, loss 0.2703678607940674, acc=0.8996111154556274, loss=0.2703678607940674
test: epoch 73, loss 1.9162789583206177, acc=0.5166666507720947, loss=1.9162789583206177
train: epoch 74, loss 0.2724330723285675, acc=0.9003888964653015, loss=0.2724330723285675
test: epoch 74, loss 1.860162377357483, acc=0.5138888955116272, loss=1.860162377357483
train: epoch 75, loss 0.2613091468811035, acc=0.8999999761581421, loss=0.2613091468811035
test: epoch 75, loss 2.1219446659088135, acc=0.5333333611488342, loss=2.1219446659088135
train: epoch 76, loss 0.2667297422885895, acc=0.9002777934074402, loss=0.2667297422885895
test: epoch 76, loss 2.054365396499634, acc=0.5277777910232544, loss=2.054365396499634
train: epoch 77, loss 0.2685800790786743, acc=0.901888906955719, loss=0.2685800790786743
test: epoch 77, loss 2.0830843448638916, acc=0.5333333611488342, loss=2.0830843448638916
train: epoch 78, loss 0.2582738399505615, acc=0.9008888602256775, loss=0.2582738399505615
test: epoch 78, loss 1.9615014791488647, acc=0.5333333611488342, loss=1.9615014791488647
train: epoch 79, loss 0.26902103424072266, acc=0.8986111283302307, loss=0.26902103424072266
test: epoch 79, loss 1.9734755754470825, acc=0.5277777910232544, loss=1.9734755754470825
train: epoch 80, loss 0.26314669847488403, acc=0.9000555276870728, loss=0.26314669847488403
test: epoch 80, loss 2.083512306213379, acc=0.519444465637207, loss=2.083512306213379
train: epoch 81, loss 0.25989794731140137, acc=0.9019444584846497, loss=0.25989794731140137
test: epoch 81, loss 2.1350996494293213, acc=0.5472221970558167, loss=2.1350996494293213
train: epoch 82, loss 0.26842018961906433, acc=0.8981666564941406, loss=0.26842018961906433
test: epoch 82, loss 2.1905434131622314, acc=0.5277777910232544, loss=2.1905434131622314
train: epoch 83, loss 0.2656475305557251, acc=0.8994444608688354, loss=0.2656475305557251
test: epoch 83, loss 1.741273045539856, acc=0.5222222208976746, loss=1.741273045539856
train: epoch 84, loss 0.26195278763771057, acc=0.89811110496521, loss=0.26195278763771057
test: epoch 84, loss 1.9981542825698853, acc=0.5166666507720947, loss=1.9981542825698853
train: epoch 85, loss 0.2589339315891266, acc=0.9012777805328369, loss=0.2589339315891266
test: epoch 85, loss 2.169069766998291, acc=0.5138888955116272, loss=2.169069766998291
train: epoch 86, loss 0.27040034532546997, acc=0.898888885974884, loss=0.27040034532546997
test: epoch 86, loss 1.9604012966156006, acc=0.5, loss=1.9604012966156006
train: epoch 87, loss 0.2702856659889221, acc=0.8977222442626953, loss=0.2702856659889221
test: epoch 87, loss 1.8621633052825928, acc=0.5166666507720947, loss=1.8621633052825928
train: epoch 88, loss 0.26609721779823303, acc=0.899222195148468, loss=0.26609721779823303
test: epoch 88, loss 1.8522783517837524, acc=0.5416666865348816, loss=1.8522783517837524
train: epoch 89, loss 0.27119454741477966, acc=0.8978333473205566, loss=0.27119454741477966
test: epoch 89, loss 1.7104041576385498, acc=0.5361111164093018, loss=1.7104041576385498
train: epoch 90, loss 0.25743916630744934, acc=0.9034444689750671, loss=0.25743916630744934
test: epoch 90, loss 1.8165884017944336, acc=0.5527777671813965, loss=1.8165884017944336
train: epoch 91, loss 0.2712654769420624, acc=0.8956111073493958, loss=0.2712654769420624
test: epoch 91, loss 1.7937002182006836, acc=0.5444444417953491, loss=1.7937002182006836
train: epoch 92, loss 0.263385146856308, acc=0.8981666564941406, loss=0.263385146856308
test: epoch 92, loss 1.7981749773025513, acc=0.5444444417953491, loss=1.7981749773025513
train: epoch 93, loss 0.2651287615299225, acc=0.8981666564941406, loss=0.2651287615299225
test: epoch 93, loss 1.8425862789154053, acc=0.5333333611488342, loss=1.8425862789154053
train: epoch 94, loss 0.2794865369796753, acc=0.893833339214325, loss=0.2794865369796753
test: epoch 94, loss 1.7881990671157837, acc=0.5305555462837219, loss=1.7881990671157837
train: epoch 95, loss 0.26864463090896606, acc=0.89811110496521, loss=0.26864463090896606
test: epoch 95, loss 1.818237543106079, acc=0.5472221970558167, loss=1.818237543106079
train: epoch 96, loss 0.27373936772346497, acc=0.8958888649940491, loss=0.27373936772346497
test: epoch 96, loss 1.7821208238601685, acc=0.5583333373069763, loss=1.7821208238601685
train: epoch 97, loss 0.266694575548172, acc=0.9006666541099548, loss=0.266694575548172
test: epoch 97, loss 1.7793859243392944, acc=0.5527777671813965, loss=1.7793859243392944
train: epoch 98, loss 0.27289196848869324, acc=0.8939444422721863, loss=0.27289196848869324
test: epoch 98, loss 1.8891117572784424, acc=0.5555555820465088, loss=1.8891117572784424
train: epoch 99, loss 0.27221980690956116, acc=0.8961111307144165, loss=0.27221980690956116
test: epoch 99, loss 1.7902100086212158, acc=0.550000011920929, loss=1.7902100086212158
train: epoch 100, loss 0.27789151668548584, acc=0.8974444270133972, loss=0.27789151668548584
test: epoch 100, loss 1.7753876447677612, acc=0.5611110925674438, loss=1.7753876447677612
train: epoch 101, loss 0.2779495418071747, acc=0.8948333263397217, loss=0.2779495418071747
test: epoch 101, loss 1.5171443223953247, acc=0.5638889074325562, loss=1.5171443223953247
train: epoch 102, loss 0.27257394790649414, acc=0.8981666564941406, loss=0.27257394790649414
test: epoch 102, loss 1.7172261476516724, acc=0.5666666626930237, loss=1.7172261476516724
train: epoch 103, loss 0.2767142951488495, acc=0.895111083984375, loss=0.2767142951488495
test: epoch 103, loss 1.7462867498397827, acc=0.5583333373069763, loss=1.7462867498397827
train: epoch 104, loss 0.27982330322265625, acc=0.8914999961853027, loss=0.27982330322265625
test: epoch 104, loss 1.578932762145996, acc=0.5361111164093018, loss=1.578932762145996
train: epoch 105, loss 0.2761918008327484, acc=0.8945555686950684, loss=0.2761918008327484
test: epoch 105, loss 1.7432034015655518, acc=0.5583333373069763, loss=1.7432034015655518
train: epoch 106, loss 0.281985342502594, acc=0.8942777514457703, loss=0.281985342502594
test: epoch 106, loss 1.6039971113204956, acc=0.5527777671813965, loss=1.6039971113204956
train: epoch 107, loss 0.27485349774360657, acc=0.8963333368301392, loss=0.27485349774360657
test: epoch 107, loss 1.675462245941162, acc=0.5611110925674438, loss=1.675462245941162
train: epoch 108, loss 0.2820979356765747, acc=0.8932222127914429, loss=0.2820979356765747
test: epoch 108, loss 1.799330472946167, acc=0.5555555820465088, loss=1.799330472946167
train: epoch 109, loss 0.2858113646507263, acc=0.8927222490310669, loss=0.2858113646507263
test: epoch 109, loss 1.831093430519104, acc=0.5694444179534912, loss=1.831093430519104
train: epoch 110, loss 0.2814352512359619, acc=0.8924444317817688, loss=0.2814352512359619
test: epoch 110, loss 1.7059087753295898, acc=0.5611110925674438, loss=1.7059087753295898
train: epoch 111, loss 0.28766095638275146, acc=0.8912777900695801, loss=0.28766095638275146
test: epoch 111, loss 1.5588669776916504, acc=0.5638889074325562, loss=1.5588669776916504
train: epoch 112, loss 0.27598240971565247, acc=0.8958888649940491, loss=0.27598240971565247
test: epoch 112, loss 1.7024359703063965, acc=0.5666666626930237, loss=1.7024359703063965
train: epoch 113, loss 0.278359055519104, acc=0.8964999914169312, loss=0.278359055519104
test: epoch 113, loss 1.630444049835205, acc=0.5611110925674438, loss=1.630444049835205
train: epoch 114, loss 0.2771080434322357, acc=0.894944429397583, loss=0.2771080434322357
test: epoch 114, loss 1.5820869207382202, acc=0.5666666626930237, loss=1.5820869207382202
train: epoch 115, loss 0.28858721256256104, acc=0.8906111121177673, loss=0.28858721256256104
test: epoch 115, loss 1.8246538639068604, acc=0.5722222328186035, loss=1.8246538639068604
train: epoch 116, loss 0.28965049982070923, acc=0.890666663646698, loss=0.28965049982070923
test: epoch 116, loss 1.5899730920791626, acc=0.5694444179534912, loss=1.5899730920791626
train: epoch 117, loss 0.28747260570526123, acc=0.8907222151756287, loss=0.28747260570526123
test: epoch 117, loss 1.6857199668884277, acc=0.5472221970558167, loss=1.6857199668884277
train: epoch 118, loss 0.28559964895248413, acc=0.8894444704055786, loss=0.28559964895248413
test: epoch 118, loss 1.5300084352493286, acc=0.5694444179534912, loss=1.5300084352493286
train: epoch 119, loss 0.28665831685066223, acc=0.8887222409248352, loss=0.28665831685066223
test: epoch 119, loss 1.5777455568313599, acc=0.5638889074325562, loss=1.5777455568313599
train: epoch 120, loss 0.2935506999492645, acc=0.8886666893959045, loss=0.2935506999492645
test: epoch 120, loss 1.50115966796875, acc=0.5722222328186035, loss=1.50115966796875
train: epoch 121, loss 0.29388079047203064, acc=0.886888861656189, loss=0.29388079047203064
test: epoch 121, loss 1.643829345703125, acc=0.5638889074325562, loss=1.643829345703125
train: epoch 122, loss 0.296766459941864, acc=0.8852221965789795, loss=0.296766459941864
test: epoch 122, loss 1.6824066638946533, acc=0.5611110925674438, loss=1.6824066638946533
train: epoch 123, loss 0.29577550292015076, acc=0.8886111378669739, loss=0.29577550292015076
test: epoch 123, loss 1.5689078569412231, acc=0.5444444417953491, loss=1.5689078569412231
train: epoch 124, loss 0.30085697770118713, acc=0.8863333463668823, loss=0.30085697770118713
test: epoch 124, loss 1.578212857246399, acc=0.5694444179534912, loss=1.578212857246399
train: epoch 125, loss 0.29662683606147766, acc=0.8851666450500488, loss=0.29662683606147766
test: epoch 125, loss 1.6842683553695679, acc=0.5361111164093018, loss=1.6842683553695679
train: epoch 126, loss 0.2949939966201782, acc=0.8881111145019531, loss=0.2949939966201782
test: epoch 126, loss 1.8469449281692505, acc=0.5555555820465088, loss=1.8469449281692505
train: epoch 127, loss 0.30104705691337585, acc=0.8846666812896729, loss=0.30104705691337585
test: epoch 127, loss 1.402890682220459, acc=0.5583333373069763, loss=1.402890682220459
train: epoch 128, loss 0.2969883382320404, acc=0.8849999904632568, loss=0.2969883382320404
test: epoch 128, loss 1.4938563108444214, acc=0.5583333373069763, loss=1.4938563108444214
train: epoch 129, loss 0.3045233488082886, acc=0.8829444646835327, loss=0.3045233488082886
test: epoch 129, loss 1.6084293127059937, acc=0.5694444179534912, loss=1.6084293127059937
train: epoch 130, loss 0.3026517629623413, acc=0.883388876914978, loss=0.3026517629623413
test: epoch 130, loss 1.6789823770523071, acc=0.5694444179534912, loss=1.6789823770523071
train: epoch 131, loss 0.2990795969963074, acc=0.8853333592414856, loss=0.2990795969963074
test: epoch 131, loss 1.6080658435821533, acc=0.5638889074325562, loss=1.6080658435821533
train: epoch 132, loss 0.30130326747894287, acc=0.8820000290870667, loss=0.30130326747894287
test: epoch 132, loss 1.5520051717758179, acc=0.5694444179534912, loss=1.5520051717758179
train: epoch 133, loss 0.30942028760910034, acc=0.88227778673172, loss=0.30942028760910034
test: epoch 133, loss 1.368408203125, acc=0.5638889074325562, loss=1.368408203125
train: epoch 134, loss 0.30321818590164185, acc=0.8847222328186035, loss=0.30321818590164185
test: epoch 134, loss 1.5497260093688965, acc=0.5666666626930237, loss=1.5497260093688965
train: epoch 135, loss 0.30338719487190247, acc=0.8842777609825134, loss=0.30338719487190247
test: epoch 135, loss 1.6116580963134766, acc=0.5722222328186035, loss=1.6116580963134766
train: epoch 136, loss 0.3074003756046295, acc=0.8813333511352539, loss=0.3074003756046295
test: epoch 136, loss 1.4234426021575928, acc=0.5694444179534912, loss=1.4234426021575928
train: epoch 137, loss 0.31574544310569763, acc=0.8808888792991638, loss=0.31574544310569763
test: epoch 137, loss 1.4131377935409546, acc=0.5638889074325562, loss=1.4131377935409546
train: epoch 138, loss 0.3082523047924042, acc=0.8846111297607422, loss=0.3082523047924042
test: epoch 138, loss 1.4785031080245972, acc=0.5638889074325562, loss=1.4785031080245972
train: epoch 139, loss 0.3169497549533844, acc=0.8787222504615784, loss=0.3169497549533844
test: epoch 139, loss 1.5035966634750366, acc=0.5694444179534912, loss=1.5035966634750366
train: epoch 140, loss 0.3117014169692993, acc=0.879277765750885, loss=0.3117014169692993
test: epoch 140, loss 1.3700358867645264, acc=0.5722222328186035, loss=1.3700358867645264
train: epoch 141, loss 0.30215567350387573, acc=0.8824999928474426, loss=0.30215567350387573
test: epoch 141, loss 1.4454954862594604, acc=0.5583333373069763, loss=1.4454954862594604
train: epoch 142, loss 0.31469956040382385, acc=0.8784444332122803, loss=0.31469956040382385
test: epoch 142, loss 1.5698978900909424, acc=0.574999988079071, loss=1.5698978900909424
train: epoch 143, loss 0.3056963086128235, acc=0.8813889026641846, loss=0.3056963086128235
test: epoch 143, loss 1.5226305723190308, acc=0.5722222328186035, loss=1.5226305723190308
train: epoch 144, loss 0.31418079137802124, acc=0.8814444541931152, loss=0.31418079137802124
test: epoch 144, loss 1.5671970844268799, acc=0.5527777671813965, loss=1.5671970844268799
train: epoch 145, loss 0.2992804944515228, acc=0.883055567741394, loss=0.2992804944515228
test: epoch 145, loss 1.4821258783340454, acc=0.5722222328186035, loss=1.4821258783340454
train: epoch 146, loss 0.308076411485672, acc=0.8831666707992554, loss=0.308076411485672
test: epoch 146, loss 1.6010125875473022, acc=0.5722222328186035, loss=1.6010125875473022
train: epoch 147, loss 0.31065788865089417, acc=0.8803333044052124, loss=0.31065788865089417
test: epoch 147, loss 1.4826445579528809, acc=0.574999988079071, loss=1.4826445579528809
train: epoch 148, loss 0.29776448011398315, acc=0.8878333568572998, loss=0.29776448011398315
test: epoch 148, loss 1.5201811790466309, acc=0.574999988079071, loss=1.5201811790466309
train: epoch 149, loss 0.3118249475955963, acc=0.8818888664245605, loss=0.3118249475955963
test: epoch 149, loss 1.2703660726547241, acc=0.5722222328186035, loss=1.2703660726547241
train: epoch 150, loss 0.3097755014896393, acc=0.8854444622993469, loss=0.3097755014896393
test: epoch 150, loss 1.5724188089370728, acc=0.5694444179534912, loss=1.5724188089370728
