# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=2.0", "--temp_decay=1", "--one_hot=false", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1332035866, receiver_embed_dim=128, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.6556930541992188, acc=0.12238889187574387, loss=2.6556930541992188
test: epoch 1, loss 5.061646938323975, acc=0.06111111119389534, loss=5.061646938323975
train: epoch 2, loss 1.6137245893478394, acc=0.3207777738571167, loss=1.6137245893478394
test: epoch 2, loss 2.898885726928711, acc=0.18333333730697632, loss=2.898885726928711
train: epoch 3, loss 1.218427062034607, acc=0.4720555543899536, loss=1.218427062034607
test: epoch 3, loss 2.942985773086548, acc=0.24166665971279144, loss=2.942985773086548
train: epoch 4, loss 0.8811630606651306, acc=0.6208333373069763, loss=0.8811630606651306
test: epoch 4, loss 2.0767581462860107, acc=0.35555556416511536, loss=2.0767581462860107
train: epoch 5, loss 0.6514571905136108, acc=0.7174999713897705, loss=0.6514571905136108
test: epoch 5, loss 1.997158408164978, acc=0.35277777910232544, loss=1.997158408164978
train: epoch 6, loss 0.4554484784603119, acc=0.8067777752876282, loss=0.4554484784603119
test: epoch 6, loss 1.7128574848175049, acc=0.48055556416511536, loss=1.7128574848175049
train: epoch 7, loss 0.38083651661872864, acc=0.8426111340522766, loss=0.38083651661872864
test: epoch 7, loss 1.2147867679595947, acc=0.5138888955116272, loss=1.2147867679595947
train: epoch 8, loss 0.28405776619911194, acc=0.8760555386543274, loss=0.28405776619911194
test: epoch 8, loss 1.6707963943481445, acc=0.5555555820465088, loss=1.6707963943481445
train: epoch 9, loss 0.27238836884498596, acc=0.8834999799728394, loss=0.27238836884498596
test: epoch 9, loss 1.560545563697815, acc=0.4749999940395355, loss=1.560545563697815
train: epoch 10, loss 0.24773308634757996, acc=0.8915555477142334, loss=0.24773308634757996
test: epoch 10, loss 1.375754952430725, acc=0.4861111044883728, loss=1.375754952430725
train: epoch 11, loss 0.23405545949935913, acc=0.8968889117240906, loss=0.23405545949935913
test: epoch 11, loss 1.510664463043213, acc=0.4833333194255829, loss=1.510664463043213
train: epoch 12, loss 0.21593403816223145, acc=0.9047222137451172, loss=0.21593403816223145
test: epoch 12, loss 1.3860076665878296, acc=0.5388888716697693, loss=1.3860076665878296
train: epoch 13, loss 0.22088538110256195, acc=0.8998888731002808, loss=0.22088538110256195
test: epoch 13, loss 1.7808506488800049, acc=0.5777778029441833, loss=1.7808506488800049
train: epoch 14, loss 0.19947217404842377, acc=0.9087222218513489, loss=0.19947217404842377
test: epoch 14, loss 1.239410638809204, acc=0.6194444298744202, loss=1.239410638809204
train: epoch 15, loss 0.1915646493434906, acc=0.9140555262565613, loss=0.1915646493434906
test: epoch 15, loss 1.2962015867233276, acc=0.6305555701255798, loss=1.2962015867233276
train: epoch 16, loss 0.20814383029937744, acc=0.906333327293396, loss=0.20814383029937744
test: epoch 16, loss 1.438105583190918, acc=0.6277777552604675, loss=1.438105583190918
train: epoch 17, loss 0.1599384993314743, acc=0.925000011920929, loss=0.1599384993314743
test: epoch 17, loss 1.685903787612915, acc=0.5611110925674438, loss=1.685903787612915
train: epoch 18, loss 0.1758265644311905, acc=0.9198889136314392, loss=0.1758265644311905
test: epoch 18, loss 1.5804619789123535, acc=0.6194444298744202, loss=1.5804619789123535
train: epoch 19, loss 0.1868765503168106, acc=0.9233333468437195, loss=0.1868765503168106
test: epoch 19, loss 0.7113311886787415, acc=0.7027778029441833, loss=0.7113311886787415
train: epoch 20, loss 0.15288130939006805, acc=0.9304999709129333, loss=0.15288130939006805
test: epoch 20, loss 1.0653592348098755, acc=0.699999988079071, loss=1.0653592348098755
train: epoch 21, loss 0.1752452403306961, acc=0.9245555400848389, loss=0.1752452403306961
test: epoch 21, loss 0.8713943958282471, acc=0.6916666626930237, loss=0.8713943958282471
train: epoch 22, loss 0.17078085243701935, acc=0.921833336353302, loss=0.17078085243701935
test: epoch 22, loss 1.0394270420074463, acc=0.6944444179534912, loss=1.0394270420074463
train: epoch 23, loss 0.14929501712322235, acc=0.9293888807296753, loss=0.14929501712322235
test: epoch 23, loss 1.091456413269043, acc=0.7222222089767456, loss=1.091456413269043
train: epoch 24, loss 0.14874328672885895, acc=0.9255555272102356, loss=0.14874328672885895
test: epoch 24, loss 0.47017714381217957, acc=0.7777777910232544, loss=0.47017714381217957
train: epoch 25, loss 0.18890757858753204, acc=0.914722204208374, loss=0.18890757858753204
test: epoch 25, loss 0.5679420828819275, acc=0.8083333373069763, loss=0.5679420828819275
train: epoch 26, loss 0.14493988454341888, acc=0.917722225189209, loss=0.14493988454341888
test: epoch 26, loss 0.6900842785835266, acc=0.7666666507720947, loss=0.6900842785835266
train: epoch 27, loss 0.16860538721084595, acc=0.9235555529594421, loss=0.16860538721084595
test: epoch 27, loss 0.7711809277534485, acc=0.8388888835906982, loss=0.7711809277534485
train: epoch 28, loss 0.13301022350788116, acc=0.9307777881622314, loss=0.13301022350788116
test: epoch 28, loss 0.5162250995635986, acc=0.8222222328186035, loss=0.5162250995635986
train: epoch 29, loss 0.16272127628326416, acc=0.9123333096504211, loss=0.16272127628326416
test: epoch 29, loss 0.769949197769165, acc=0.8027777671813965, loss=0.769949197769165
train: epoch 30, loss 0.1250375211238861, acc=0.934333324432373, loss=0.1250375211238861
test: epoch 30, loss 0.29114457964897156, acc=0.8833333253860474, loss=0.29114457964897156
train: epoch 31, loss 0.1571425199508667, acc=0.9266666769981384, loss=0.1571425199508667
test: epoch 31, loss 0.5853282809257507, acc=0.8277778029441833, loss=0.5853282809257507
train: epoch 32, loss 0.11591099202632904, acc=0.9391111135482788, loss=0.11591099202632904
test: epoch 32, loss 0.2979997396469116, acc=0.9083333611488342, loss=0.2979997396469116
train: epoch 33, loss 0.14839425683021545, acc=0.9273333549499512, loss=0.14839425683021545
test: epoch 33, loss 0.33271002769470215, acc=0.8694444298744202, loss=0.33271002769470215
train: epoch 34, loss 0.11675076931715012, acc=0.9357222318649292, loss=0.11675076931715012
test: epoch 34, loss 0.3474544286727905, acc=0.8916666507720947, loss=0.3474544286727905
train: epoch 35, loss 0.17013424634933472, acc=0.9163333177566528, loss=0.17013424634933472
test: epoch 35, loss 0.3448891341686249, acc=0.8888888955116272, loss=0.3448891341686249
train: epoch 36, loss 0.15371251106262207, acc=0.9213888645172119, loss=0.15371251106262207
test: epoch 36, loss 0.12793917953968048, acc=0.9361110925674438, loss=0.12793917953968048
train: epoch 37, loss 0.16069072484970093, acc=0.9131666421890259, loss=0.16069072484970093
test: epoch 37, loss 0.3456646203994751, acc=0.8888888955116272, loss=0.3456646203994751
train: epoch 38, loss 0.15048633515834808, acc=0.9278333187103271, loss=0.15048633515834808
test: epoch 38, loss 0.09990628808736801, acc=0.9416666626930237, loss=0.09990628808736801
train: epoch 39, loss 0.10773523896932602, acc=0.9407222270965576, loss=0.10773523896932602
test: epoch 39, loss 0.10029096156358719, acc=0.9416666626930237, loss=0.10029096156358719
train: epoch 40, loss 0.18435335159301758, acc=0.9259999990463257, loss=0.18435335159301758
test: epoch 40, loss 0.23493504524230957, acc=0.9333333373069763, loss=0.23493504524230957
train: epoch 41, loss 0.10015483945608139, acc=0.949055552482605, loss=0.10015483945608139
test: epoch 41, loss 0.23586787283420563, acc=0.9305555820465088, loss=0.23586787283420563
train: epoch 42, loss 0.1644032597541809, acc=0.9268888831138611, loss=0.1644032597541809
test: epoch 42, loss 0.24830947816371918, acc=0.9305555820465088, loss=0.24830947816371918
train: epoch 43, loss 0.16081900894641876, acc=0.9293333292007446, loss=0.16081900894641876
test: epoch 43, loss 0.13884437084197998, acc=0.9111111164093018, loss=0.13884437084197998
train: epoch 44, loss 0.16039003431797028, acc=0.929111123085022, loss=0.16039003431797028
test: epoch 44, loss 0.30062001943588257, acc=0.855555534362793, loss=0.30062001943588257
train: epoch 45, loss 0.14968645572662354, acc=0.9299444556236267, loss=0.14968645572662354
test: epoch 45, loss 0.10273859649896622, acc=0.9444444179534912, loss=0.10273859649896622
train: epoch 46, loss 0.0922127291560173, acc=0.9431111216545105, loss=0.0922127291560173
test: epoch 46, loss 0.0861670970916748, acc=0.9472222328186035, loss=0.0861670970916748
train: epoch 47, loss 0.13386785984039307, acc=0.9363333582878113, loss=0.13386785984039307
test: epoch 47, loss 0.10230565816164017, acc=0.9444444179534912, loss=0.10230565816164017
train: epoch 48, loss 0.08855948597192764, acc=0.9442222118377686, loss=0.08855948597192764
test: epoch 48, loss 0.08694811910390854, acc=0.9472222328186035, loss=0.08694811910390854
train: epoch 49, loss 0.16372647881507874, acc=0.9295555353164673, loss=0.16372647881507874
test: epoch 49, loss 0.13015931844711304, acc=0.9361110925674438, loss=0.13015931844711304
train: epoch 50, loss 0.1181875467300415, acc=0.9390000104904175, loss=0.1181875467300415
test: epoch 50, loss 0.08580178022384644, acc=0.9472222328186035, loss=0.08580178022384644
train: epoch 51, loss 0.11674616485834122, acc=0.9384999871253967, loss=0.11674616485834122
test: epoch 51, loss 0.12234016507863998, acc=0.9416666626930237, loss=0.12234016507863998
train: epoch 52, loss 0.0889582559466362, acc=0.9440555572509766, loss=0.0889582559466362
test: epoch 52, loss 0.08580273389816284, acc=0.9472222328186035, loss=0.08580273389816284
train: epoch 53, loss 0.1265515387058258, acc=0.933055579662323, loss=0.1265515387058258
test: epoch 53, loss 0.13056378066539764, acc=0.9388889074325562, loss=0.13056378066539764
train: epoch 54, loss 0.13774965703487396, acc=0.9282222390174866, loss=0.13774965703487396
test: epoch 54, loss 0.13221782445907593, acc=0.9166666865348816, loss=0.13221782445907593
train: epoch 55, loss 0.15979108214378357, acc=0.924833357334137, loss=0.15979108214378357
test: epoch 55, loss 0.10215865820646286, acc=0.9388889074325562, loss=0.10215865820646286
train: epoch 56, loss 0.1257956326007843, acc=0.9326666593551636, loss=0.1257956326007843
test: epoch 56, loss 0.2713909149169922, acc=0.9055555462837219, loss=0.2713909149169922
train: epoch 57, loss 0.13436651229858398, acc=0.9314444661140442, loss=0.13436651229858398
test: epoch 57, loss 0.0990573912858963, acc=0.9388889074325562, loss=0.0990573912858963
train: epoch 58, loss 0.10286412388086319, acc=0.9361110925674438, loss=0.10286412388086319
test: epoch 58, loss 0.14118921756744385, acc=0.9361110925674438, loss=0.14118921756744385
train: epoch 59, loss 0.17843656241893768, acc=0.9212222099304199, loss=0.17843656241893768
test: epoch 59, loss 0.09923369437456131, acc=0.9388889074325562, loss=0.09923369437456131
train: epoch 60, loss 0.10634950548410416, acc=0.9355000257492065, loss=0.10634950548410416
test: epoch 60, loss 0.09887124598026276, acc=0.9388889074325562, loss=0.09887124598026276
train: epoch 61, loss 0.1172197014093399, acc=0.9331111311912537, loss=0.1172197014093399
test: epoch 61, loss 0.1309770792722702, acc=0.9305555820465088, loss=0.1309770792722702
train: epoch 62, loss 0.17309200763702393, acc=0.9181110858917236, loss=0.17309200763702393
test: epoch 62, loss 0.15887555480003357, acc=0.9222221970558167, loss=0.15887555480003357
train: epoch 63, loss 0.161897674202919, acc=0.9217777848243713, loss=0.161897674202919
test: epoch 63, loss 0.14039413630962372, acc=0.9277777671813965, loss=0.14039413630962372
train: epoch 64, loss 0.15639491379261017, acc=0.9233333468437195, loss=0.15639491379261017
test: epoch 64, loss 0.14825931191444397, acc=0.925000011920929, loss=0.14825931191444397
train: epoch 65, loss 0.18919737637043, acc=0.9212777614593506, loss=0.18919737637043
test: epoch 65, loss 0.13275852799415588, acc=0.9305555820465088, loss=0.13275852799415588
train: epoch 66, loss 0.13050751388072968, acc=0.929111123085022, loss=0.13050751388072968
test: epoch 66, loss 0.12191362679004669, acc=0.9333333373069763, loss=0.12191362679004669
train: epoch 67, loss 0.122795470058918, acc=0.9304999709129333, loss=0.122795470058918
test: epoch 67, loss 0.12162531167268753, acc=0.9333333373069763, loss=0.12162531167268753
train: epoch 68, loss 0.2102290540933609, acc=0.9057222008705139, loss=0.2102290540933609
test: epoch 68, loss 0.15106083452701569, acc=0.9166666865348816, loss=0.15106083452701569
train: epoch 69, loss 0.14526426792144775, acc=0.9181666374206543, loss=0.14526426792144775
test: epoch 69, loss 0.1379346400499344, acc=0.9222221970558167, loss=0.1379346400499344
train: epoch 70, loss 0.1390824019908905, acc=0.9190555810928345, loss=0.1390824019908905
test: epoch 70, loss 0.13783404231071472, acc=0.9222221970558167, loss=0.13783404231071472
train: epoch 71, loss 0.18622137606143951, acc=0.9126666784286499, loss=0.18622137606143951
test: epoch 71, loss 0.5386778116226196, acc=0.8611111044883728, loss=0.5386778116226196
train: epoch 72, loss 0.2066139578819275, acc=0.9048333168029785, loss=0.2066139578819275
test: epoch 72, loss 0.17583729326725006, acc=0.9111111164093018, loss=0.17583729326725006
train: epoch 73, loss 0.17958460748195648, acc=0.9105555415153503, loss=0.17958460748195648
test: epoch 73, loss 0.17574039101600647, acc=0.9111111164093018, loss=0.17574039101600647
train: epoch 74, loss 0.1782560795545578, acc=0.9110000133514404, loss=0.1782560795545578
test: epoch 74, loss 0.17570404708385468, acc=0.9111111164093018, loss=0.17570404708385468
train: epoch 75, loss 0.22841936349868774, acc=0.9052222371101379, loss=0.22841936349868774
test: epoch 75, loss 0.18138733506202698, acc=0.9138888716697693, loss=0.18138733506202698
train: epoch 76, loss 0.2000182569026947, acc=0.9157778024673462, loss=0.2000182569026947
test: epoch 76, loss 0.14454001188278198, acc=0.925000011920929, loss=0.14454001188278198
train: epoch 77, loss 0.14946134388446808, acc=0.9248889088630676, loss=0.14946134388446808
test: epoch 77, loss 0.13490431010723114, acc=0.9277777671813965, loss=0.13490431010723114
train: epoch 78, loss 0.20202802121639252, acc=0.9125555753707886, loss=0.20202802121639252
test: epoch 78, loss 0.19093216955661774, acc=0.9194444417953491, loss=0.19093216955661774
train: epoch 79, loss 0.15226896107196808, acc=0.9241666793823242, loss=0.15226896107196808
test: epoch 79, loss 0.11556439101696014, acc=0.9333333373069763, loss=0.11556439101696014
train: epoch 80, loss 0.10761811584234238, acc=0.9359444379806519, loss=0.10761811584234238
test: epoch 80, loss 0.10637002438306808, acc=0.9361110925674438, loss=0.10637002438306808
train: epoch 81, loss 0.10683706402778625, acc=0.9361110925674438, loss=0.10683706402778625
test: epoch 81, loss 0.10633508861064911, acc=0.9361110925674438, loss=0.10633508861064911
train: epoch 82, loss 0.10822085291147232, acc=0.9359999895095825, loss=0.10822085291147232
test: epoch 82, loss 0.10636251419782639, acc=0.9361110925674438, loss=0.10636251419782639
train: epoch 83, loss 0.15567301213741302, acc=0.9277777671813965, loss=0.15567301213741302
test: epoch 83, loss 0.13193495571613312, acc=0.9277777671813965, loss=0.13193495571613312
train: epoch 84, loss 0.13314898312091827, acc=0.9277222156524658, loss=0.13314898312091827
test: epoch 84, loss 0.1315845251083374, acc=0.9277777671813965, loss=0.1315845251083374
train: epoch 85, loss 0.1324998140335083, acc=0.9277777671813965, loss=0.1324998140335083
test: epoch 85, loss 0.13154762983322144, acc=0.9277777671813965, loss=0.13154762983322144
train: epoch 86, loss 0.13238462805747986, acc=0.9277777671813965, loss=0.13238462805747986
test: epoch 86, loss 0.13152863085269928, acc=0.9277777671813965, loss=0.13152863085269928
train: epoch 87, loss 0.18015341460704803, acc=0.9196110963821411, loss=0.18015341460704803
test: epoch 87, loss 0.16177833080291748, acc=0.9194444417953491, loss=0.16177833080291748
train: epoch 88, loss 0.1893584132194519, acc=0.9136666655540466, loss=0.1893584132194519
test: epoch 88, loss 0.20491036772727966, acc=0.9166666865348816, loss=0.20491036772727966
train: epoch 89, loss 0.18640044331550598, acc=0.9181666374206543, loss=0.18640044331550598
test: epoch 89, loss 0.15039385855197906, acc=0.925000011920929, loss=0.15039385855197906
train: epoch 90, loss 0.13755574822425842, acc=0.9275000095367432, loss=0.13755574822425842
test: epoch 90, loss 0.1326000839471817, acc=0.9277777671813965, loss=0.1326000839471817
train: epoch 91, loss 0.13367053866386414, acc=0.9277777671813965, loss=0.13367053866386414
test: epoch 91, loss 0.1325271725654602, acc=0.9277777671813965, loss=0.1325271725654602
train: epoch 92, loss 0.17587827146053314, acc=0.9176111221313477, loss=0.17587827146053314
test: epoch 92, loss 0.32433372735977173, acc=0.8916666507720947, loss=0.32433372735977173
train: epoch 93, loss 0.25610944628715515, acc=0.8993889093399048, loss=0.25610944628715515
test: epoch 93, loss 0.1659708321094513, acc=0.9166666865348816, loss=0.1659708321094513
train: epoch 94, loss 0.167002871632576, acc=0.9164999723434448, loss=0.167002871632576
test: epoch 94, loss 0.16372427344322205, acc=0.9166666865348816, loss=0.16372427344322205
train: epoch 95, loss 0.22682422399520874, acc=0.9052222371101379, loss=0.22682422399520874
test: epoch 95, loss 0.18698927760124207, acc=0.9111111164093018, loss=0.18698927760124207
train: epoch 96, loss 0.18443270027637482, acc=0.9169999957084656, loss=0.18443270027637482
test: epoch 96, loss 0.14141274988651276, acc=0.925000011920929, loss=0.14141274988651276
train: epoch 97, loss 0.14633144438266754, acc=0.9246110916137695, loss=0.14633144438266754
test: epoch 97, loss 0.14114457368850708, acc=0.925000011920929, loss=0.14114457368850708
train: epoch 98, loss 0.1437724083662033, acc=0.9248889088630676, loss=0.1437724083662033
test: epoch 98, loss 0.14106735587120056, acc=0.925000011920929, loss=0.14106735587120056
train: epoch 99, loss 0.14645229279994965, acc=0.9242777824401855, loss=0.14645229279994965
test: epoch 99, loss 0.15047165751457214, acc=0.9222221970558167, loss=0.15047165751457214
train: epoch 100, loss 0.14249293506145477, acc=0.9248889088630676, loss=0.14249293506145477
test: epoch 100, loss 0.1409243941307068, acc=0.925000011920929, loss=0.1409243941307068
train: epoch 101, loss 0.17637395858764648, acc=0.9198333621025085, loss=0.17637395858764648
test: epoch 101, loss 0.2498750537633896, acc=0.9055555462837219, loss=0.2498750537633896
train: epoch 102, loss 0.24578018486499786, acc=0.9017221927642822, loss=0.24578018486499786
test: epoch 102, loss 0.22631920874118805, acc=0.9055555462837219, loss=0.22631920874118805
train: epoch 103, loss 0.21872399747371674, acc=0.9053333401679993, loss=0.21872399747371674
test: epoch 103, loss 0.20163355767726898, acc=0.9083333611488342, loss=0.20163355767726898
train: epoch 104, loss 0.19286195933818817, acc=0.9117222428321838, loss=0.19286195933818817
test: epoch 104, loss 0.17124898731708527, acc=0.9166666865348816, loss=0.17124898731708527
train: epoch 105, loss 0.1835290938615799, acc=0.9152222275733948, loss=0.1835290938615799
test: epoch 105, loss 0.18538695573806763, acc=0.9083333611488342, loss=0.18538695573806763
train: epoch 106, loss 0.21711888909339905, acc=0.9112777709960938, loss=0.21711888909339905
test: epoch 106, loss 0.16473467648029327, acc=0.9194444417953491, loss=0.16473467648029327
train: epoch 107, loss 0.16494905948638916, acc=0.9194444417953491, loss=0.16494905948638916
test: epoch 107, loss 0.16291245818138123, acc=0.9194444417953491, loss=0.16291245818138123
train: epoch 108, loss 0.16430909931659698, acc=0.9194444417953491, loss=0.16430909931659698
test: epoch 108, loss 0.16276830434799194, acc=0.9194444417953491, loss=0.16276830434799194
train: epoch 109, loss 0.1668730229139328, acc=0.9192777872085571, loss=0.1668730229139328
test: epoch 109, loss 0.16274705529212952, acc=0.9194444417953491, loss=0.16274705529212952
train: epoch 110, loss 0.17567172646522522, acc=0.9171110987663269, loss=0.17567172646522522
test: epoch 110, loss 0.17332187294960022, acc=0.9166666865348816, loss=0.17332187294960022
train: epoch 111, loss 0.17476598918437958, acc=0.9166666865348816, loss=0.17476598918437958
test: epoch 111, loss 0.17328131198883057, acc=0.9166666865348816, loss=0.17328131198883057
train: epoch 112, loss 0.17390978336334229, acc=0.9168888926506042, loss=0.17390978336334229
test: epoch 112, loss 0.16332626342773438, acc=0.9194444417953491, loss=0.16332626342773438
train: epoch 113, loss 0.2858521640300751, acc=0.8976666927337646, loss=0.2858521640300751
test: epoch 113, loss 0.232707679271698, acc=0.8972222208976746, loss=0.232707679271698
train: epoch 114, loss 0.22842393815517426, acc=0.8998888731002808, loss=0.22842393815517426
test: epoch 114, loss 0.22426436841487885, acc=0.8999999761581421, loss=0.22426436841487885
train: epoch 115, loss 0.2416100800037384, acc=0.9018333554267883, loss=0.2416100800037384
test: epoch 115, loss 0.25849971175193787, acc=0.8972222208976746, loss=0.25849971175193787
train: epoch 116, loss 0.25978565216064453, acc=0.8961666822433472, loss=0.25978565216064453
test: epoch 116, loss 0.27541399002075195, acc=0.894444465637207, loss=0.27541399002075195
train: epoch 117, loss 0.23153533041477203, acc=0.9013888835906982, loss=0.23153533041477203
test: epoch 117, loss 0.2554723918437958, acc=0.9027777910232544, loss=0.2554723918437958
train: epoch 118, loss 0.22338542342185974, acc=0.9051666855812073, loss=0.22338542342185974
test: epoch 118, loss 0.21603426337242126, acc=0.9055555462837219, loss=0.21603426337242126
train: epoch 119, loss 0.21605722606182098, acc=0.9034444689750671, loss=0.21605722606182098
test: epoch 119, loss 0.19061928987503052, acc=0.9111111164093018, loss=0.19061928987503052
train: epoch 120, loss 0.20646651089191437, acc=0.9098333120346069, loss=0.20646651089191437
test: epoch 120, loss 0.17140477895736694, acc=0.9166666865348816, loss=0.17140477895736694
train: epoch 121, loss 0.16866789758205414, acc=0.9188888669013977, loss=0.16866789758205414
test: epoch 121, loss 0.1646074503660202, acc=0.9194444417953491, loss=0.1646074503660202
train: epoch 122, loss 0.16528865694999695, acc=0.9200555682182312, loss=0.16528865694999695
test: epoch 122, loss 0.15617787837982178, acc=0.9222221970558167, loss=0.15617787837982178
train: epoch 123, loss 0.15089473128318787, acc=0.924833357334137, loss=0.15089473128318787
test: epoch 123, loss 0.14911946654319763, acc=0.925000011920929, loss=0.14911946654319763
train: epoch 124, loss 0.2705710530281067, acc=0.9008333086967468, loss=0.2705710530281067
test: epoch 124, loss 0.24150459468364716, acc=0.8972222208976746, loss=0.24150459468364716
train: epoch 125, loss 0.24405674636363983, acc=0.8952777981758118, loss=0.24405674636363983
test: epoch 125, loss 0.23228564858436584, acc=0.8999999761581421, loss=0.23228564858436584
train: epoch 126, loss 0.22845110297203064, acc=0.9014999866485596, loss=0.22845110297203064
test: epoch 126, loss 0.21038922667503357, acc=0.9055555462837219, loss=0.21038922667503357
train: epoch 127, loss 0.19887736439704895, acc=0.9098333120346069, loss=0.19887736439704895
test: epoch 127, loss 0.18580394983291626, acc=0.9138888716697693, loss=0.18580394983291626
train: epoch 128, loss 0.186412051320076, acc=0.9138888716697693, loss=0.186412051320076
test: epoch 128, loss 0.18482740223407745, acc=0.9138888716697693, loss=0.18482740223407745
train: epoch 129, loss 0.18623247742652893, acc=0.9138888716697693, loss=0.18623247742652893
test: epoch 129, loss 0.18479958176612854, acc=0.9138888716697693, loss=0.18479958176612854
train: epoch 130, loss 0.1814945936203003, acc=0.9156666398048401, loss=0.1814945936203003
test: epoch 130, loss 0.17380794882774353, acc=0.9166666865348816, loss=0.17380794882774353
train: epoch 131, loss 0.17493091523647308, acc=0.9166666865348816, loss=0.17493091523647308
test: epoch 131, loss 0.1737639605998993, acc=0.9166666865348816, loss=0.1737639605998993
train: epoch 132, loss 0.17483434081077576, acc=0.9166666865348816, loss=0.17483434081077576
test: epoch 132, loss 0.17374952137470245, acc=0.9166666865348816, loss=0.17374952137470245
train: epoch 133, loss 0.24067002534866333, acc=0.9041666388511658, loss=0.24067002534866333
test: epoch 133, loss 0.24392814934253693, acc=0.8861111402511597, loss=0.24392814934253693
train: epoch 134, loss 0.21768124401569366, acc=0.9030555486679077, loss=0.21768124401569366
test: epoch 134, loss 0.2092018872499466, acc=0.9083333611488342, loss=0.2092018872499466
train: epoch 135, loss 0.21444235742092133, acc=0.9068333506584167, loss=0.21444235742092133
test: epoch 135, loss 0.20723599195480347, acc=0.9083333611488342, loss=0.20723599195480347
train: epoch 136, loss 0.19698655605316162, acc=0.9110555648803711, loss=0.19698655605316162
test: epoch 136, loss 0.1946997195482254, acc=0.9111111164093018, loss=0.1946997195482254
train: epoch 137, loss 0.2972848415374756, acc=0.8872222304344177, loss=0.2972848415374756
test: epoch 137, loss 0.30307966470718384, acc=0.8694444298744202, loss=0.30307966470718384
train: epoch 138, loss 0.2612908184528351, acc=0.8911111354827881, loss=0.2612908184528351
test: epoch 138, loss 0.24620270729064941, acc=0.894444465637207, loss=0.24620270729064941
train: epoch 139, loss 0.2579800486564636, acc=0.8914999961853027, loss=0.2579800486564636
test: epoch 139, loss 0.24848826229572296, acc=0.8916666507720947, loss=0.24848826229572296
train: epoch 140, loss 0.2859688401222229, acc=0.882888913154602, loss=0.2859688401222229
test: epoch 140, loss 0.2640016973018646, acc=0.8833333253860474, loss=0.2640016973018646
train: epoch 141, loss 0.2581970989704132, acc=0.8910555839538574, loss=0.2581970989704132
test: epoch 141, loss 0.23526357114315033, acc=0.894444465637207, loss=0.23526357114315033
train: epoch 142, loss 0.2533784806728363, acc=0.8928333520889282, loss=0.2533784806728363
test: epoch 142, loss 0.2390245646238327, acc=0.894444465637207, loss=0.2390245646238327
train: epoch 143, loss 0.23919914662837982, acc=0.894444465637207, loss=0.23919914662837982
test: epoch 143, loss 0.23603689670562744, acc=0.894444465637207, loss=0.23603689670562744
train: epoch 144, loss 0.23890258371829987, acc=0.8951666951179504, loss=0.23890258371829987
test: epoch 144, loss 0.21998731791973114, acc=0.8999999761581421, loss=0.21998731791973114
train: epoch 145, loss 0.22723162174224854, acc=0.9007222056388855, loss=0.22723162174224854
test: epoch 145, loss 0.1945466846227646, acc=0.9111111164093018, loss=0.1945466846227646
train: epoch 146, loss 0.22932356595993042, acc=0.9076111316680908, loss=0.22932356595993042
test: epoch 146, loss 0.30483728647232056, acc=0.8972222208976746, loss=0.30483728647232056
train: epoch 147, loss 0.22143878042697906, acc=0.9042778015136719, loss=0.22143878042697906
test: epoch 147, loss 0.2117629051208496, acc=0.9055555462837219, loss=0.2117629051208496
train: epoch 148, loss 0.2125217169523239, acc=0.9051666855812073, loss=0.2125217169523239
test: epoch 148, loss 0.2080412656068802, acc=0.9055555462837219, loss=0.2080412656068802
train: epoch 149, loss 0.21014803647994995, acc=0.9055555462837219, loss=0.21014803647994995
test: epoch 149, loss 0.20789341628551483, acc=0.9055555462837219, loss=0.20789341628551483
train: epoch 150, loss 0.21003808081150055, acc=0.9055555462837219, loss=0.21003808081150055
test: epoch 150, loss 0.20785404741764069, acc=0.9055555462837219, loss=0.20785404741764069
