# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.99", "--one_hot=false", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=616215188, receiver_embed_dim=64, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.8679299354553223, acc=0.100611113011837, loss=2.8679299354553223
test: epoch 1, loss 3.782850503921509, acc=0.09166666865348816, loss=3.782850503921509
train: epoch 2, loss 1.76016104221344, acc=0.3005000054836273, loss=1.76016104221344
test: epoch 2, loss 5.726726055145264, acc=0.09166666865348816, loss=5.726726055145264
train: epoch 3, loss 1.1844958066940308, acc=0.5075555443763733, loss=1.1844958066940308
test: epoch 3, loss 4.678508758544922, acc=0.11388888955116272, loss=4.678508758544922
train: epoch 4, loss 0.8961349129676819, acc=0.6439999938011169, loss=0.8961349129676819
test: epoch 4, loss 3.29178786277771, acc=0.23888888955116272, loss=3.29178786277771
train: epoch 5, loss 0.6905534267425537, acc=0.7328333258628845, loss=0.6905534267425537
test: epoch 5, loss 2.82661509513855, acc=0.22499999403953552, loss=2.82661509513855
train: epoch 6, loss 0.5723418593406677, acc=0.7841110825538635, loss=0.5723418593406677
test: epoch 6, loss 2.739076614379883, acc=0.26944443583488464, loss=2.739076614379883
train: epoch 7, loss 0.48876622319221497, acc=0.8182222247123718, loss=0.48876622319221497
test: epoch 7, loss 2.7538435459136963, acc=0.3194444477558136, loss=2.7538435459136963
train: epoch 8, loss 0.4209960401058197, acc=0.8453333377838135, loss=0.4209960401058197
test: epoch 8, loss 1.826792597770691, acc=0.41111111640930176, loss=1.826792597770691
train: epoch 9, loss 0.3856496512889862, acc=0.8610555529594421, loss=0.3856496512889862
test: epoch 9, loss 2.148857355117798, acc=0.3638888895511627, loss=2.148857355117798
train: epoch 10, loss 0.3462720811367035, acc=0.8819444179534912, loss=0.3462720811367035
test: epoch 10, loss 2.3327035903930664, acc=0.3777777850627899, loss=2.3327035903930664
train: epoch 11, loss 0.3291228413581848, acc=0.8872777819633484, loss=0.3291228413581848
test: epoch 11, loss 1.9618537425994873, acc=0.4027777910232544, loss=1.9618537425994873
train: epoch 12, loss 0.3068901002407074, acc=0.8909444212913513, loss=0.3068901002407074
test: epoch 12, loss 1.9944919347763062, acc=0.3777777850627899, loss=1.9944919347763062
train: epoch 13, loss 0.2782008647918701, acc=0.9029444456100464, loss=0.2782008647918701
test: epoch 13, loss 1.806396484375, acc=0.40833333134651184, loss=1.806396484375
train: epoch 14, loss 0.2755107879638672, acc=0.9046666622161865, loss=0.2755107879638672
test: epoch 14, loss 1.8703142404556274, acc=0.4000000059604645, loss=1.8703142404556274
train: epoch 15, loss 0.25694751739501953, acc=0.9109444618225098, loss=0.25694751739501953
test: epoch 15, loss 1.8362468481063843, acc=0.35555556416511536, loss=1.8362468481063843
train: epoch 16, loss 0.23724138736724854, acc=0.9201666712760925, loss=0.23724138736724854
test: epoch 16, loss 1.9708466529846191, acc=0.3861111104488373, loss=1.9708466529846191
train: epoch 17, loss 0.24788109958171844, acc=0.9163888692855835, loss=0.24788109958171844
test: epoch 17, loss 2.0193238258361816, acc=0.4000000059604645, loss=2.0193238258361816
train: epoch 18, loss 0.2363855540752411, acc=0.9203888773918152, loss=0.2363855540752411
test: epoch 18, loss 1.906556248664856, acc=0.39722222089767456, loss=1.906556248664856
train: epoch 19, loss 0.21387425065040588, acc=0.9261666536331177, loss=0.21387425065040588
test: epoch 19, loss 1.685302734375, acc=0.44999998807907104, loss=1.685302734375
train: epoch 20, loss 0.22419235110282898, acc=0.9244444370269775, loss=0.22419235110282898
test: epoch 20, loss 2.133984088897705, acc=0.45277777314186096, loss=2.133984088897705
train: epoch 21, loss 0.19848641753196716, acc=0.9328888654708862, loss=0.19848641753196716
test: epoch 21, loss 1.920899510383606, acc=0.4055555462837219, loss=1.920899510383606
train: epoch 22, loss 0.2066066712141037, acc=0.9316666722297668, loss=0.2066066712141037
test: epoch 22, loss 1.9686124324798584, acc=0.42500001192092896, loss=1.9686124324798584
train: epoch 23, loss 0.18184655904769897, acc=0.9384999871253967, loss=0.18184655904769897
test: epoch 23, loss 1.7349783182144165, acc=0.4333333373069763, loss=1.7349783182144165
train: epoch 24, loss 0.19679704308509827, acc=0.9334999918937683, loss=0.19679704308509827
test: epoch 24, loss 1.5689876079559326, acc=0.4583333432674408, loss=1.5689876079559326
train: epoch 25, loss 0.18103863298892975, acc=0.9401111006736755, loss=0.18103863298892975
test: epoch 25, loss 1.7872161865234375, acc=0.4416666626930237, loss=1.7872161865234375
train: epoch 26, loss 0.17702819406986237, acc=0.9387778043746948, loss=0.17702819406986237
test: epoch 26, loss 1.7994178533554077, acc=0.4888888895511627, loss=1.7994178533554077
train: epoch 27, loss 0.1720358431339264, acc=0.9427222013473511, loss=0.1720358431339264
test: epoch 27, loss 1.7924385070800781, acc=0.44999998807907104, loss=1.7924385070800781
train: epoch 28, loss 0.17426927387714386, acc=0.9428333044052124, loss=0.17426927387714386
test: epoch 28, loss 1.614937663078308, acc=0.5111111402511597, loss=1.614937663078308
train: epoch 29, loss 0.1596141904592514, acc=0.9461110830307007, loss=0.1596141904592514
test: epoch 29, loss 1.3725323677062988, acc=0.45277777314186096, loss=1.3725323677062988
train: epoch 30, loss 0.1561242640018463, acc=0.9493333101272583, loss=0.1561242640018463
test: epoch 30, loss 1.6276289224624634, acc=0.4972222149372101, loss=1.6276289224624634
train: epoch 31, loss 0.15290319919586182, acc=0.9491666555404663, loss=0.15290319919586182
test: epoch 31, loss 1.8759111166000366, acc=0.4583333432674408, loss=1.8759111166000366
train: epoch 32, loss 0.15047809481620789, acc=0.9505000114440918, loss=0.15047809481620789
test: epoch 32, loss 1.3703422546386719, acc=0.5083333253860474, loss=1.3703422546386719
train: epoch 33, loss 0.1328311264514923, acc=0.9571666717529297, loss=0.1328311264514923
test: epoch 33, loss 1.921624779701233, acc=0.49444442987442017, loss=1.921624779701233
train: epoch 34, loss 0.1532875895500183, acc=0.9496111273765564, loss=0.1532875895500183
test: epoch 34, loss 1.5145888328552246, acc=0.5388888716697693, loss=1.5145888328552246
train: epoch 35, loss 0.1434219479560852, acc=0.9525555372238159, loss=0.1434219479560852
test: epoch 35, loss 1.5982292890548706, acc=0.550000011920929, loss=1.5982292890548706
train: epoch 36, loss 0.13023269176483154, acc=0.9586111307144165, loss=0.13023269176483154
test: epoch 36, loss 2.1001832485198975, acc=0.4749999940395355, loss=2.1001832485198975
train: epoch 37, loss 0.140290305018425, acc=0.9554444551467896, loss=0.140290305018425
test: epoch 37, loss 1.1749467849731445, acc=0.5777778029441833, loss=1.1749467849731445
train: epoch 38, loss 0.128086119890213, acc=0.9583888649940491, loss=0.128086119890213
test: epoch 38, loss 1.5804983377456665, acc=0.5277777910232544, loss=1.5804983377456665
train: epoch 39, loss 0.1246391013264656, acc=0.9594444632530212, loss=0.1246391013264656
test: epoch 39, loss 1.8206360340118408, acc=0.5805555582046509, loss=1.8206360340118408
train: epoch 40, loss 0.132045716047287, acc=0.9578333497047424, loss=0.132045716047287
test: epoch 40, loss 2.063127279281616, acc=0.49166667461395264, loss=2.063127279281616
train: epoch 41, loss 0.13204927742481232, acc=0.9593889117240906, loss=0.13204927742481232
test: epoch 41, loss 1.3273341655731201, acc=0.5972222089767456, loss=1.3273341655731201
train: epoch 42, loss 0.14271733164787292, acc=0.9551666378974915, loss=0.14271733164787292
test: epoch 42, loss 1.1312888860702515, acc=0.6166666746139526, loss=1.1312888860702515
train: epoch 43, loss 0.11102639883756638, acc=0.9639444351196289, loss=0.11102639883756638
test: epoch 43, loss 1.4049066305160522, acc=0.5777778029441833, loss=1.4049066305160522
train: epoch 44, loss 0.12279321253299713, acc=0.9619444608688354, loss=0.12279321253299713
test: epoch 44, loss 1.2100334167480469, acc=0.6194444298744202, loss=1.2100334167480469
train: epoch 45, loss 0.12215974181890488, acc=0.9618889093399048, loss=0.12215974181890488
test: epoch 45, loss 1.4065625667572021, acc=0.574999988079071, loss=1.4065625667572021
train: epoch 46, loss 0.12474431842565536, acc=0.9602222442626953, loss=0.12474431842565536
test: epoch 46, loss 0.9788914322853088, acc=0.675000011920929, loss=0.9788914322853088
train: epoch 47, loss 0.1160367950797081, acc=0.9647777676582336, loss=0.1160367950797081
test: epoch 47, loss 0.9741609692573547, acc=0.7166666388511658, loss=0.9741609692573547
train: epoch 48, loss 0.10574446618556976, acc=0.9649444222450256, loss=0.10574446618556976
test: epoch 48, loss 1.0148723125457764, acc=0.6305555701255798, loss=1.0148723125457764
train: epoch 49, loss 0.12153182923793793, acc=0.9618889093399048, loss=0.12153182923793793
test: epoch 49, loss 0.9420669078826904, acc=0.699999988079071, loss=0.9420669078826904
train: epoch 50, loss 0.10284321755170822, acc=0.9670000076293945, loss=0.10284321755170822
test: epoch 50, loss 0.6214392781257629, acc=0.8138889074325562, loss=0.6214392781257629
train: epoch 51, loss 0.10712464153766632, acc=0.967555582523346, loss=0.10712464153766632
test: epoch 51, loss 0.7331749796867371, acc=0.75, loss=0.7331749796867371
train: epoch 52, loss 0.10955341905355453, acc=0.964888870716095, loss=0.10955341905355453
test: epoch 52, loss 0.8462631702423096, acc=0.7916666865348816, loss=0.8462631702423096
train: epoch 53, loss 0.09529773145914078, acc=0.968666672706604, loss=0.09529773145914078
test: epoch 53, loss 0.7153018712997437, acc=0.7722222208976746, loss=0.7153018712997437
train: epoch 54, loss 0.1050921306014061, acc=0.9668889045715332, loss=0.1050921306014061
test: epoch 54, loss 0.44650688767433167, acc=0.855555534362793, loss=0.44650688767433167
train: epoch 55, loss 0.0965033620595932, acc=0.9712222218513489, loss=0.0965033620595932
test: epoch 55, loss 0.6324893832206726, acc=0.8194444179534912, loss=0.6324893832206726
train: epoch 56, loss 0.09776891767978668, acc=0.9698888659477234, loss=0.09776891767978668
test: epoch 56, loss 0.41395115852355957, acc=0.8722222447395325, loss=0.41395115852355957
train: epoch 57, loss 0.09930342435836792, acc=0.9702777862548828, loss=0.09930342435836792
test: epoch 57, loss 0.4269952178001404, acc=0.8694444298744202, loss=0.4269952178001404
train: epoch 58, loss 0.09635705500841141, acc=0.9700000286102295, loss=0.09635705500841141
test: epoch 58, loss 0.30269694328308105, acc=0.8694444298744202, loss=0.30269694328308105
train: epoch 59, loss 0.08952756226062775, acc=0.9722222089767456, loss=0.08952756226062775
test: epoch 59, loss 0.37842756509780884, acc=0.8833333253860474, loss=0.37842756509780884
train: epoch 60, loss 0.0798707827925682, acc=0.9739999771118164, loss=0.0798707827925682
test: epoch 60, loss 0.3169032335281372, acc=0.8833333253860474, loss=0.3169032335281372
train: epoch 61, loss 0.08238301426172256, acc=0.9737777709960938, loss=0.08238301426172256
test: epoch 61, loss 0.3266213536262512, acc=0.9027777910232544, loss=0.3266213536262512
train: epoch 62, loss 0.09646739810705185, acc=0.9705555438995361, loss=0.09646739810705185
test: epoch 62, loss 0.43011781573295593, acc=0.8722222447395325, loss=0.43011781573295593
train: epoch 63, loss 0.07085184752941132, acc=0.9757221937179565, loss=0.07085184752941132
test: epoch 63, loss 0.47030577063560486, acc=0.875, loss=0.47030577063560486
train: epoch 64, loss 0.08776360005140305, acc=0.9747777581214905, loss=0.08776360005140305
test: epoch 64, loss 0.2592967748641968, acc=0.9222221970558167, loss=0.2592967748641968
train: epoch 65, loss 0.08169104903936386, acc=0.9745000004768372, loss=0.08169104903936386
test: epoch 65, loss 0.35210365056991577, acc=0.9111111164093018, loss=0.35210365056991577
train: epoch 66, loss 0.06486456096172333, acc=0.9794999957084656, loss=0.06486456096172333
test: epoch 66, loss 0.2890104055404663, acc=0.9138888716697693, loss=0.2890104055404663
train: epoch 67, loss 0.07035323232412338, acc=0.9785000085830688, loss=0.07035323232412338
test: epoch 67, loss 0.15666846930980682, acc=0.9416666626930237, loss=0.15666846930980682
train: epoch 68, loss 0.05998549982905388, acc=0.981333315372467, loss=0.05998549982905388
test: epoch 68, loss 0.17758779227733612, acc=0.9444444179534912, loss=0.17758779227733612
train: epoch 69, loss 0.06195643171668053, acc=0.981166660785675, loss=0.06195643171668053
test: epoch 69, loss 0.23977169394493103, acc=0.9444444179534912, loss=0.23977169394493103
train: epoch 70, loss 0.06711583584547043, acc=0.980555534362793, loss=0.06711583584547043
test: epoch 70, loss 0.21669799089431763, acc=0.9444444179534912, loss=0.21669799089431763
train: epoch 71, loss 0.06250590831041336, acc=0.9818888902664185, loss=0.06250590831041336
test: epoch 71, loss 0.0865885466337204, acc=0.9694444537162781, loss=0.0865885466337204
train: epoch 72, loss 0.05406905338168144, acc=0.9829999804496765, loss=0.05406905338168144
test: epoch 72, loss 0.07439432293176651, acc=0.9833333492279053, loss=0.07439432293176651
train: epoch 73, loss 0.06285794824361801, acc=0.9832777976989746, loss=0.06285794824361801
test: epoch 73, loss 0.04961550608277321, acc=0.9861111044883728, loss=0.04961550608277321
train: epoch 74, loss 0.04374336451292038, acc=0.987666666507721, loss=0.04374336451292038
test: epoch 74, loss 0.0549054853618145, acc=0.980555534362793, loss=0.0549054853618145
train: epoch 75, loss 0.03556762635707855, acc=0.9884999990463257, loss=0.03556762635707855
test: epoch 75, loss 0.06483802199363708, acc=0.9833333492279053, loss=0.06483802199363708
train: epoch 76, loss 0.04833371937274933, acc=0.9866111278533936, loss=0.04833371937274933
test: epoch 76, loss 0.03807239234447479, acc=0.9861111044883728, loss=0.03807239234447479
train: epoch 77, loss 0.04831869155168533, acc=0.9860000014305115, loss=0.04831869155168533
test: epoch 77, loss 0.03556695207953453, acc=0.9861111044883728, loss=0.03556695207953453
train: epoch 78, loss 0.03683066740632057, acc=0.9894444346427917, loss=0.03683066740632057
test: epoch 78, loss 0.04868169501423836, acc=0.9861111044883728, loss=0.04868169501423836
train: epoch 79, loss 0.028955884277820587, acc=0.9905555844306946, loss=0.028955884277820587
test: epoch 79, loss 0.0502544641494751, acc=0.9861111044883728, loss=0.0502544641494751
train: epoch 80, loss 0.03512490168213844, acc=0.9892777800559998, loss=0.03512490168213844
test: epoch 80, loss 0.055155616253614426, acc=0.9861111044883728, loss=0.055155616253614426
train: epoch 81, loss 0.0437280535697937, acc=0.9878888726234436, loss=0.0437280535697937
test: epoch 81, loss 0.03423452749848366, acc=0.9861111044883728, loss=0.03423452749848366
train: epoch 82, loss 0.03882819786667824, acc=0.9878888726234436, loss=0.03882819786667824
test: epoch 82, loss 0.043623536825180054, acc=0.9861111044883728, loss=0.043623536825180054
train: epoch 83, loss 0.03646618500351906, acc=0.988611102104187, loss=0.03646618500351906
test: epoch 83, loss 0.07315827906131744, acc=0.9833333492279053, loss=0.07315827906131744
train: epoch 84, loss 0.04494694247841835, acc=0.9874444603919983, loss=0.04494694247841835
test: epoch 84, loss 0.044398508965969086, acc=0.9861111044883728, loss=0.044398508965969086
train: epoch 85, loss 0.02995089627802372, acc=0.9903888702392578, loss=0.02995089627802372
test: epoch 85, loss 0.03146521747112274, acc=0.9888888597488403, loss=0.03146521747112274
train: epoch 86, loss 0.04152984172105789, acc=0.9871666431427002, loss=0.04152984172105789
test: epoch 86, loss 0.03943173587322235, acc=0.9861111044883728, loss=0.03943173587322235
train: epoch 87, loss 0.034143660217523575, acc=0.9877777695655823, loss=0.034143660217523575
test: epoch 87, loss 0.054141514003276825, acc=0.9861111044883728, loss=0.054141514003276825
train: epoch 88, loss 0.0304193627089262, acc=0.9906111359596252, loss=0.0304193627089262
test: epoch 88, loss 0.03175068646669388, acc=0.9861111044883728, loss=0.03175068646669388
train: epoch 89, loss 0.044199008494615555, acc=0.9869999885559082, loss=0.044199008494615555
test: epoch 89, loss 0.04113771393895149, acc=0.9861111044883728, loss=0.04113771393895149
train: epoch 90, loss 0.02638346515595913, acc=0.99144446849823, loss=0.02638346515595913
test: epoch 90, loss 0.038527119904756546, acc=0.9888888597488403, loss=0.038527119904756546
train: epoch 91, loss 0.046101164072752, acc=0.9870555400848389, loss=0.046101164072752
test: epoch 91, loss 0.0371665395796299, acc=0.9861111044883728, loss=0.0371665395796299
train: epoch 92, loss 0.037721093744039536, acc=0.9897222518920898, loss=0.037721093744039536
test: epoch 92, loss 0.04276381805539131, acc=0.9861111044883728, loss=0.04276381805539131
train: epoch 93, loss 0.028464743867516518, acc=0.9905555844306946, loss=0.028464743867516518
test: epoch 93, loss 0.04589592665433884, acc=0.9861111044883728, loss=0.04589592665433884
train: epoch 94, loss 0.04300510510802269, acc=0.9851111173629761, loss=0.04300510510802269
test: epoch 94, loss 0.024463970214128494, acc=0.9888888597488403, loss=0.024463970214128494
train: epoch 95, loss 0.030395383015275, acc=0.9905555844306946, loss=0.030395383015275
test: epoch 95, loss 0.03887522593140602, acc=0.9861111044883728, loss=0.03887522593140602
train: epoch 96, loss 0.03022865392267704, acc=0.9905555844306946, loss=0.03022865392267704
test: epoch 96, loss 0.03004930168390274, acc=0.9861111044883728, loss=0.03004930168390274
train: epoch 97, loss 0.030497698113322258, acc=0.9883333444595337, loss=0.030497698113322258
test: epoch 97, loss 0.03242102265357971, acc=0.9861111044883728, loss=0.03242102265357971
train: epoch 98, loss 0.04068686440587044, acc=0.9859444499015808, loss=0.04068686440587044
test: epoch 98, loss 0.021556878462433815, acc=0.9888888597488403, loss=0.021556878462433815
train: epoch 99, loss 0.036787115037441254, acc=0.9871110916137695, loss=0.036787115037441254
test: epoch 99, loss 0.07050684094429016, acc=0.9861111044883728, loss=0.07050684094429016
train: epoch 100, loss 0.041298069059848785, acc=0.9868333339691162, loss=0.041298069059848785
test: epoch 100, loss 0.028548596426844597, acc=0.9861111044883728, loss=0.028548596426844597
train: epoch 101, loss 0.028598209843039513, acc=0.9903888702392578, loss=0.028598209843039513
test: epoch 101, loss 0.03974444791674614, acc=0.9861111044883728, loss=0.03974444791674614
train: epoch 102, loss 0.022963110357522964, acc=0.991611123085022, loss=0.022963110357522964
test: epoch 102, loss 0.034409310668706894, acc=0.9861111044883728, loss=0.034409310668706894
train: epoch 103, loss 0.025873476639389992, acc=0.9899444580078125, loss=0.025873476639389992
test: epoch 103, loss 0.0409088060259819, acc=0.9861111044883728, loss=0.0409088060259819
train: epoch 104, loss 0.020240843296051025, acc=0.9908888936042786, loss=0.020240843296051025
test: epoch 104, loss 0.0568406917154789, acc=0.9861111044883728, loss=0.0568406917154789
train: epoch 105, loss 0.03787646442651749, acc=0.9890555739402771, loss=0.03787646442651749
test: epoch 105, loss 0.08613043278455734, acc=0.9833333492279053, loss=0.08613043278455734
train: epoch 106, loss 0.02286784164607525, acc=0.991944432258606, loss=0.02286784164607525
test: epoch 106, loss 0.04009127616882324, acc=0.9861111044883728, loss=0.04009127616882324
train: epoch 107, loss 0.03735136613249779, acc=0.9893888831138611, loss=0.03735136613249779
test: epoch 107, loss 0.03900254890322685, acc=0.9861111044883728, loss=0.03900254890322685
train: epoch 108, loss 0.03155535086989403, acc=0.9904999732971191, loss=0.03155535086989403
test: epoch 108, loss 0.03021254390478134, acc=0.9861111044883728, loss=0.03021254390478134
train: epoch 109, loss 0.027569839730858803, acc=0.9909999966621399, loss=0.027569839730858803
test: epoch 109, loss 0.03908918425440788, acc=0.9861111044883728, loss=0.03908918425440788
train: epoch 110, loss 0.026910144835710526, acc=0.9918888807296753, loss=0.026910144835710526
test: epoch 110, loss 0.03886430338025093, acc=0.9861111044883728, loss=0.03886430338025093
train: epoch 111, loss 0.02933403290808201, acc=0.9915555715560913, loss=0.02933403290808201
test: epoch 111, loss 0.02759949490427971, acc=0.9861111044883728, loss=0.02759949490427971
train: epoch 112, loss 0.032141461968421936, acc=0.9906111359596252, loss=0.032141461968421936
test: epoch 112, loss 0.027139315381646156, acc=0.980555534362793, loss=0.027139315381646156
train: epoch 113, loss 0.033919502049684525, acc=0.9892777800559998, loss=0.033919502049684525
test: epoch 113, loss 0.02769889310002327, acc=0.9888888597488403, loss=0.02769889310002327
train: epoch 114, loss 0.03716122359037399, acc=0.9868333339691162, loss=0.03716122359037399
test: epoch 114, loss 0.08392636477947235, acc=0.9861111044883728, loss=0.08392636477947235
train: epoch 115, loss 0.035673581063747406, acc=0.9884999990463257, loss=0.035673581063747406
test: epoch 115, loss 0.025721916928887367, acc=0.9861111044883728, loss=0.025721916928887367
train: epoch 116, loss 0.02171921543776989, acc=0.992222249507904, loss=0.02171921543776989
test: epoch 116, loss 0.028813214972615242, acc=0.9861111044883728, loss=0.028813214972615242
train: epoch 117, loss 0.018886152654886246, acc=0.9930555820465088, loss=0.018886152654886246
test: epoch 117, loss 0.030841846019029617, acc=0.9861111044883728, loss=0.030841846019029617
train: epoch 118, loss 0.026661964133381844, acc=0.9917222261428833, loss=0.026661964133381844
test: epoch 118, loss 0.10496646165847778, acc=0.9833333492279053, loss=0.10496646165847778
train: epoch 119, loss 0.02898014709353447, acc=0.9913333058357239, loss=0.02898014709353447
test: epoch 119, loss 0.035271063446998596, acc=0.9861111044883728, loss=0.035271063446998596
train: epoch 120, loss 0.033510904759168625, acc=0.9907222390174866, loss=0.033510904759168625
test: epoch 120, loss 0.045900795608758926, acc=0.9833333492279053, loss=0.045900795608758926
train: epoch 121, loss 0.030556820333003998, acc=0.9909444451332092, loss=0.030556820333003998
test: epoch 121, loss 0.057239703834056854, acc=0.980555534362793, loss=0.057239703834056854
train: epoch 122, loss 0.035443034023046494, acc=0.988111138343811, loss=0.035443034023046494
test: epoch 122, loss 0.05271236598491669, acc=0.9833333492279053, loss=0.05271236598491669
train: epoch 123, loss 0.035326629877090454, acc=0.9855555295944214, loss=0.035326629877090454
test: epoch 123, loss 0.03650153428316116, acc=0.9861111044883728, loss=0.03650153428316116
train: epoch 124, loss 0.0166889987885952, acc=0.9918333292007446, loss=0.0166889987885952
test: epoch 124, loss 0.029664773494005203, acc=0.9861111044883728, loss=0.029664773494005203
train: epoch 125, loss 0.015790337696671486, acc=0.9903333187103271, loss=0.015790337696671486
test: epoch 125, loss 0.03590662032365799, acc=0.9861111044883728, loss=0.03590662032365799
train: epoch 126, loss 0.017431369051337242, acc=0.9907777905464172, loss=0.017431369051337242
test: epoch 126, loss 0.0249553844332695, acc=0.9861111044883728, loss=0.0249553844332695
train: epoch 127, loss 0.02845795452594757, acc=0.9893333315849304, loss=0.02845795452594757
test: epoch 127, loss 0.021183302626013756, acc=0.9861111044883728, loss=0.021183302626013756
train: epoch 128, loss 0.03549962118268013, acc=0.9890000224113464, loss=0.03549962118268013
test: epoch 128, loss 0.03199680894613266, acc=0.9861111044883728, loss=0.03199680894613266
train: epoch 129, loss 0.03415361046791077, acc=0.9900000095367432, loss=0.03415361046791077
test: epoch 129, loss 0.03053262084722519, acc=0.9888888597488403, loss=0.03053262084722519
train: epoch 130, loss 0.02816851995885372, acc=0.9920555353164673, loss=0.02816851995885372
test: epoch 130, loss 0.03433544933795929, acc=0.980555534362793, loss=0.03433544933795929
train: epoch 131, loss 0.03694714605808258, acc=0.9894999861717224, loss=0.03694714605808258
test: epoch 131, loss 0.04357355087995529, acc=0.9861111044883728, loss=0.04357355087995529
train: epoch 132, loss 0.021138861775398254, acc=0.991611123085022, loss=0.021138861775398254
test: epoch 132, loss 0.022167343646287918, acc=0.9861111044883728, loss=0.022167343646287918
train: epoch 133, loss 0.02229108102619648, acc=0.992555558681488, loss=0.02229108102619648
test: epoch 133, loss 0.027032531797885895, acc=0.9861111044883728, loss=0.027032531797885895
train: epoch 134, loss 0.028289610520005226, acc=0.9902222156524658, loss=0.028289610520005226
test: epoch 134, loss 0.037951547652482986, acc=0.9861111044883728, loss=0.037951547652482986
train: epoch 135, loss 0.027106599882245064, acc=0.9917222261428833, loss=0.027106599882245064
test: epoch 135, loss 0.07012264430522919, acc=0.9833333492279053, loss=0.07012264430522919
train: epoch 136, loss 0.018909279257059097, acc=0.9926666617393494, loss=0.018909279257059097
test: epoch 136, loss 0.04125654324889183, acc=0.9861111044883728, loss=0.04125654324889183
train: epoch 137, loss 0.01696912944316864, acc=0.99272221326828, loss=0.01696912944316864
test: epoch 137, loss 0.029640717431902885, acc=0.9861111044883728, loss=0.029640717431902885
train: epoch 138, loss 0.031050128862261772, acc=0.9886666536331177, loss=0.031050128862261772
test: epoch 138, loss 0.03432605788111687, acc=0.9861111044883728, loss=0.03432605788111687
train: epoch 139, loss 0.02244693413376808, acc=0.9894444346427917, loss=0.02244693413376808
test: epoch 139, loss 0.026121726259589195, acc=0.9861111044883728, loss=0.026121726259589195
train: epoch 140, loss 0.026156237348914146, acc=0.9891666769981384, loss=0.026156237348914146
test: epoch 140, loss 0.030367303639650345, acc=0.9861111044883728, loss=0.030367303639650345
train: epoch 141, loss 0.028561780229210854, acc=0.9877777695655823, loss=0.028561780229210854
test: epoch 141, loss 0.021394940093159676, acc=0.9861111044883728, loss=0.021394940093159676
train: epoch 142, loss 0.017132790759205818, acc=0.9906111359596252, loss=0.017132790759205818
test: epoch 142, loss 0.037689805030822754, acc=0.9861111044883728, loss=0.037689805030822754
train: epoch 143, loss 0.029046837240457535, acc=0.9889444708824158, loss=0.029046837240457535
test: epoch 143, loss 0.03145204111933708, acc=0.9861111044883728, loss=0.03145204111933708
train: epoch 144, loss 0.030311575159430504, acc=0.9873889088630676, loss=0.030311575159430504
test: epoch 144, loss 0.04175912216305733, acc=0.9833333492279053, loss=0.04175912216305733
train: epoch 145, loss 0.028371134772896767, acc=0.9877777695655823, loss=0.028371134772896767
test: epoch 145, loss 0.03926825150847435, acc=0.9861111044883728, loss=0.03926825150847435
train: epoch 146, loss 0.024425731971859932, acc=0.9886666536331177, loss=0.024425731971859932
test: epoch 146, loss 0.03333422914147377, acc=0.9861111044883728, loss=0.03333422914147377
train: epoch 147, loss 0.02069200947880745, acc=0.9905555844306946, loss=0.02069200947880745
test: epoch 147, loss 0.030973073095083237, acc=0.9861111044883728, loss=0.030973073095083237
train: epoch 148, loss 0.016168637201189995, acc=0.9902222156524658, loss=0.016168637201189995
test: epoch 148, loss 0.03852803632616997, acc=0.9861111044883728, loss=0.03852803632616997
train: epoch 149, loss 0.025723740458488464, acc=0.9886666536331177, loss=0.025723740458488464
test: epoch 149, loss 0.03740788251161575, acc=0.9861111044883728, loss=0.03740788251161575
train: epoch 150, loss 0.03739755600690842, acc=0.9878333210945129, loss=0.03739755600690842
test: epoch 150, loss 0.04083927720785141, acc=0.9861111044883728, loss=0.04083927720785141
