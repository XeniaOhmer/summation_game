# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=2.0", "--temp_decay=1", "--one_hot=true", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=283455162, receiver_embed_dim=128, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.667537212371826, acc=0.15177777409553528, loss=2.667537212371826
test: epoch 1, loss 2.5170722007751465, acc=0.13611111044883728, loss=2.5170722007751465
train: epoch 2, loss 1.3875322341918945, acc=0.4194999933242798, loss=1.3875322341918945
test: epoch 2, loss 2.6232380867004395, acc=0.15555556118488312, loss=2.6232380867004395
train: epoch 3, loss 1.1190232038497925, acc=0.542388916015625, loss=1.1190232038497925
test: epoch 3, loss 2.7181341648101807, acc=0.19722221791744232, loss=2.7181341648101807
train: epoch 4, loss 0.967341423034668, acc=0.6094444394111633, loss=0.967341423034668
test: epoch 4, loss 2.487490653991699, acc=0.19722221791744232, loss=2.487490653991699
train: epoch 5, loss 0.8454110026359558, acc=0.6654999852180481, loss=0.8454110026359558
test: epoch 5, loss 2.527966260910034, acc=0.21666666865348816, loss=2.527966260910034
train: epoch 6, loss 0.7551580667495728, acc=0.7054444551467896, loss=0.7551580667495728
test: epoch 6, loss 2.3963003158569336, acc=0.23888888955116272, loss=2.3963003158569336
train: epoch 7, loss 0.6743665337562561, acc=0.7431666851043701, loss=0.6743665337562561
test: epoch 7, loss 2.526278495788574, acc=0.2083333283662796, loss=2.526278495788574
train: epoch 8, loss 0.6302452683448792, acc=0.7625555396080017, loss=0.6302452683448792
test: epoch 8, loss 2.849982738494873, acc=0.24166665971279144, loss=2.849982738494873
train: epoch 9, loss 0.5811203718185425, acc=0.7823333144187927, loss=0.5811203718185425
test: epoch 9, loss 2.5345206260681152, acc=0.24166665971279144, loss=2.5345206260681152
train: epoch 10, loss 0.5380266904830933, acc=0.7979444265365601, loss=0.5380266904830933
test: epoch 10, loss 2.6032497882843018, acc=0.2750000059604645, loss=2.6032497882843018
train: epoch 11, loss 0.500636875629425, acc=0.8144999742507935, loss=0.500636875629425
test: epoch 11, loss 2.885207414627075, acc=0.21111111342906952, loss=2.885207414627075
train: epoch 12, loss 0.4723624587059021, acc=0.8277222514152527, loss=0.4723624587059021
test: epoch 12, loss 2.493760824203491, acc=0.2805555462837219, loss=2.493760824203491
train: epoch 13, loss 0.43809616565704346, acc=0.8403888940811157, loss=0.43809616565704346
test: epoch 13, loss 2.9267077445983887, acc=0.23333333432674408, loss=2.9267077445983887
train: epoch 14, loss 0.4211353361606598, acc=0.8473333120346069, loss=0.4211353361606598
test: epoch 14, loss 2.6241862773895264, acc=0.25833332538604736, loss=2.6241862773895264
train: epoch 15, loss 0.3787177801132202, acc=0.8637222051620483, loss=0.3787177801132202
test: epoch 15, loss 2.6079463958740234, acc=0.2666666805744171, loss=2.6079463958740234
train: epoch 16, loss 0.3723051846027374, acc=0.867111086845398, loss=0.3723051846027374
test: epoch 16, loss 2.6508209705352783, acc=0.24722221493721008, loss=2.6508209705352783
train: epoch 17, loss 0.34519729018211365, acc=0.8768888711929321, loss=0.34519729018211365
test: epoch 17, loss 2.5925490856170654, acc=0.23888888955116272, loss=2.5925490856170654
train: epoch 18, loss 0.34266236424446106, acc=0.8728888630867004, loss=0.34266236424446106
test: epoch 18, loss 3.005678415298462, acc=0.2888889014720917, loss=3.005678415298462
train: epoch 19, loss 0.31536367535591125, acc=0.8874444365501404, loss=0.31536367535591125
test: epoch 19, loss 3.107342004776001, acc=0.2750000059604645, loss=3.107342004776001
train: epoch 20, loss 0.30006977915763855, acc=0.8928889036178589, loss=0.30006977915763855
test: epoch 20, loss 2.5094993114471436, acc=0.24444444477558136, loss=2.5094993114471436
train: epoch 21, loss 0.28601154685020447, acc=0.8964444398880005, loss=0.28601154685020447
test: epoch 21, loss 2.662216901779175, acc=0.26944443583488464, loss=2.662216901779175
train: epoch 22, loss 0.27782827615737915, acc=0.9009444713592529, loss=0.27782827615737915
test: epoch 22, loss 2.8111038208007812, acc=0.29722222685813904, loss=2.8111038208007812
train: epoch 23, loss 0.2628139555454254, acc=0.9070555567741394, loss=0.2628139555454254
test: epoch 23, loss 2.6096839904785156, acc=0.2666666805744171, loss=2.6096839904785156
train: epoch 24, loss 0.25139379501342773, acc=0.9105555415153503, loss=0.25139379501342773
test: epoch 24, loss 2.369288921356201, acc=0.31388887763023376, loss=2.369288921356201
train: epoch 25, loss 0.2533811330795288, acc=0.9109444618225098, loss=0.2533811330795288
test: epoch 25, loss 2.448167324066162, acc=0.2916666567325592, loss=2.448167324066162
train: epoch 26, loss 0.23587879538536072, acc=0.9144444465637207, loss=0.23587879538536072
test: epoch 26, loss 2.90592622756958, acc=0.3027777671813965, loss=2.90592622756958
train: epoch 27, loss 0.22210407257080078, acc=0.9204999804496765, loss=0.22210407257080078
test: epoch 27, loss 2.407968044281006, acc=0.2611111104488373, loss=2.407968044281006
train: epoch 28, loss 0.20904159545898438, acc=0.9265555739402771, loss=0.20904159545898438
test: epoch 28, loss 3.077765703201294, acc=0.3083333373069763, loss=3.077765703201294
train: epoch 29, loss 0.2112945318222046, acc=0.9275000095367432, loss=0.2112945318222046
test: epoch 29, loss 2.7368319034576416, acc=0.2638888955116272, loss=2.7368319034576416
train: epoch 30, loss 0.20801708102226257, acc=0.9278888702392578, loss=0.20801708102226257
test: epoch 30, loss 2.7045910358428955, acc=0.3083333373069763, loss=2.7045910358428955
train: epoch 31, loss 0.18918195366859436, acc=0.9368333220481873, loss=0.18918195366859436
test: epoch 31, loss 2.781378984451294, acc=0.3083333373069763, loss=2.781378984451294
train: epoch 32, loss 0.17862015962600708, acc=0.9366111159324646, loss=0.17862015962600708
test: epoch 32, loss 3.466850519180298, acc=0.24444444477558136, loss=3.466850519180298
train: epoch 33, loss 0.18271656334400177, acc=0.9366666674613953, loss=0.18271656334400177
test: epoch 33, loss 2.731884241104126, acc=0.25555557012557983, loss=2.731884241104126
train: epoch 34, loss 0.16296568512916565, acc=0.9446666836738586, loss=0.16296568512916565
test: epoch 34, loss 2.7053561210632324, acc=0.3222222328186035, loss=2.7053561210632324
train: epoch 35, loss 0.1634630262851715, acc=0.94605553150177, loss=0.1634630262851715
test: epoch 35, loss 2.548090934753418, acc=0.2944444417953491, loss=2.548090934753418
train: epoch 36, loss 0.16370436549186707, acc=0.945388913154602, loss=0.16370436549186707
test: epoch 36, loss 2.7385447025299072, acc=0.3305555582046509, loss=2.7385447025299072
train: epoch 37, loss 0.15920540690422058, acc=0.9471666812896729, loss=0.15920540690422058
test: epoch 37, loss 2.719973564147949, acc=0.2916666567325592, loss=2.719973564147949
train: epoch 38, loss 0.14221909642219543, acc=0.9503889083862305, loss=0.14221909642219543
test: epoch 38, loss 2.6559102535247803, acc=0.3333333432674408, loss=2.6559102535247803
train: epoch 39, loss 0.15462863445281982, acc=0.948722243309021, loss=0.15462863445281982
test: epoch 39, loss 3.1394200325012207, acc=0.3222222328186035, loss=3.1394200325012207
train: epoch 40, loss 0.12431547045707703, acc=0.9553889036178589, loss=0.12431547045707703
test: epoch 40, loss 3.0572638511657715, acc=0.2944444417953491, loss=3.0572638511657715
train: epoch 41, loss 0.13073989748954773, acc=0.9549999833106995, loss=0.13073989748954773
test: epoch 41, loss 2.9675002098083496, acc=0.2944444417953491, loss=2.9675002098083496
train: epoch 42, loss 0.1353127360343933, acc=0.9556111097335815, loss=0.1353127360343933
test: epoch 42, loss 3.2906901836395264, acc=0.3027777671813965, loss=3.2906901836395264
train: epoch 43, loss 0.130181223154068, acc=0.9545555710792542, loss=0.130181223154068
test: epoch 43, loss 3.4323182106018066, acc=0.32777777314186096, loss=3.4323182106018066
train: epoch 44, loss 0.1174108013510704, acc=0.9602222442626953, loss=0.1174108013510704
test: epoch 44, loss 2.97065806388855, acc=0.38333332538604736, loss=2.97065806388855
train: epoch 45, loss 0.11943080276250839, acc=0.9598888754844666, loss=0.11943080276250839
test: epoch 45, loss 2.7039570808410645, acc=0.36944442987442017, loss=2.7039570808410645
train: epoch 46, loss 0.10102620720863342, acc=0.9642221927642822, loss=0.10102620720863342
test: epoch 46, loss 2.7794880867004395, acc=0.3472222089767456, loss=2.7794880867004395
train: epoch 47, loss 0.11700207740068436, acc=0.9614444375038147, loss=0.11700207740068436
test: epoch 47, loss 2.871967315673828, acc=0.3916666805744171, loss=2.871967315673828
train: epoch 48, loss 0.10892423242330551, acc=0.9639999866485596, loss=0.10892423242330551
test: epoch 48, loss 3.093438148498535, acc=0.36944442987442017, loss=3.093438148498535
train: epoch 49, loss 0.09786435961723328, acc=0.9673333168029785, loss=0.09786435961723328
test: epoch 49, loss 3.2153713703155518, acc=0.33888888359069824, loss=3.2153713703155518
train: epoch 50, loss 0.09939990192651749, acc=0.9665555357933044, loss=0.09939990192651749
test: epoch 50, loss 4.032674789428711, acc=0.3027777671813965, loss=4.032674789428711
train: epoch 51, loss 0.10044758021831512, acc=0.9669444561004639, loss=0.10044758021831512
test: epoch 51, loss 3.085817813873291, acc=0.38055557012557983, loss=3.085817813873291
train: epoch 52, loss 0.09273016452789307, acc=0.9668333530426025, loss=0.09273016452789307
test: epoch 52, loss 3.442082405090332, acc=0.3083333373069763, loss=3.442082405090332
train: epoch 53, loss 0.09173031896352768, acc=0.9687222242355347, loss=0.09173031896352768
test: epoch 53, loss 2.8148000240325928, acc=0.3916666805744171, loss=2.8148000240325928
train: epoch 54, loss 0.0860929936170578, acc=0.9704444408416748, loss=0.0860929936170578
test: epoch 54, loss 3.488550901412964, acc=0.38333332538604736, loss=3.488550901412964
train: epoch 55, loss 0.0915096178650856, acc=0.9701111316680908, loss=0.0915096178650856
test: epoch 55, loss 3.010209321975708, acc=0.36666667461395264, loss=3.010209321975708
train: epoch 56, loss 0.08278481662273407, acc=0.971833348274231, loss=0.08278481662273407
test: epoch 56, loss 4.055493354797363, acc=0.3861111104488373, loss=4.055493354797363
train: epoch 57, loss 0.07954628765583038, acc=0.9731666445732117, loss=0.07954628765583038
test: epoch 57, loss 2.507805109024048, acc=0.43611112236976624, loss=2.507805109024048
train: epoch 58, loss 0.0800338163971901, acc=0.9737222194671631, loss=0.0800338163971901
test: epoch 58, loss 3.778212547302246, acc=0.35277777910232544, loss=3.778212547302246
train: epoch 59, loss 0.08200541883707047, acc=0.9733889102935791, loss=0.08200541883707047
test: epoch 59, loss 3.8387928009033203, acc=0.33888888359069824, loss=3.8387928009033203
train: epoch 60, loss 0.06986316293478012, acc=0.9763333201408386, loss=0.06986316293478012
test: epoch 60, loss 3.894587516784668, acc=0.3499999940395355, loss=3.894587516784668
train: epoch 61, loss 0.08453933149576187, acc=0.9729999899864197, loss=0.08453933149576187
test: epoch 61, loss 3.386204719543457, acc=0.3861111104488373, loss=3.386204719543457
train: epoch 62, loss 0.07485605776309967, acc=0.9745000004768372, loss=0.07485605776309967
test: epoch 62, loss 3.147435188293457, acc=0.45277777314186096, loss=3.147435188293457
train: epoch 63, loss 0.08188256621360779, acc=0.9739444255828857, loss=0.08188256621360779
test: epoch 63, loss 2.983365297317505, acc=0.4166666567325592, loss=2.983365297317505
train: epoch 64, loss 0.06573828309774399, acc=0.9782778024673462, loss=0.06573828309774399
test: epoch 64, loss 3.3994691371917725, acc=0.38333332538604736, loss=3.3994691371917725
train: epoch 65, loss 0.07458576560020447, acc=0.9778333306312561, loss=0.07458576560020447
test: epoch 65, loss 3.4316389560699463, acc=0.4055555462837219, loss=3.4316389560699463
train: epoch 66, loss 0.07196014374494553, acc=0.976111114025116, loss=0.07196014374494553
test: epoch 66, loss 3.5008645057678223, acc=0.3861111104488373, loss=3.5008645057678223
train: epoch 67, loss 0.06618447601795197, acc=0.9794444441795349, loss=0.06618447601795197
test: epoch 67, loss 2.7274889945983887, acc=0.39444443583488464, loss=2.7274889945983887
train: epoch 68, loss 0.05217081308364868, acc=0.9836111068725586, loss=0.05217081308364868
test: epoch 68, loss 2.913912773132324, acc=0.43888887763023376, loss=2.913912773132324
train: epoch 69, loss 0.05620357021689415, acc=0.981166660785675, loss=0.05620357021689415
test: epoch 69, loss 3.1614491939544678, acc=0.39722222089767456, loss=3.1614491939544678
train: epoch 70, loss 0.060110609978437424, acc=0.9826666712760925, loss=0.060110609978437424
test: epoch 70, loss 3.053544759750366, acc=0.4472222328186035, loss=3.053544759750366
train: epoch 71, loss 0.07158573716878891, acc=0.9777777791023254, loss=0.07158573716878891
test: epoch 71, loss 3.2196099758148193, acc=0.43611112236976624, loss=3.2196099758148193
train: epoch 72, loss 0.05562346801161766, acc=0.9837777614593506, loss=0.05562346801161766
test: epoch 72, loss 3.2696268558502197, acc=0.44999998807907104, loss=3.2696268558502197
train: epoch 73, loss 0.054822392761707306, acc=0.9837777614593506, loss=0.054822392761707306
test: epoch 73, loss 3.688323497772217, acc=0.4611110985279083, loss=3.688323497772217
train: epoch 74, loss 0.056973181664943695, acc=0.9820555448532104, loss=0.056973181664943695
test: epoch 74, loss 3.8913304805755615, acc=0.36666667461395264, loss=3.8913304805755615
train: epoch 75, loss 0.05629536509513855, acc=0.9827777743339539, loss=0.05629536509513855
test: epoch 75, loss 3.8702094554901123, acc=0.4166666567325592, loss=3.8702094554901123
train: epoch 76, loss 0.05480523407459259, acc=0.9837777614593506, loss=0.05480523407459259
test: epoch 76, loss 2.993088960647583, acc=0.39444443583488464, loss=2.993088960647583
train: epoch 77, loss 0.051715198904275894, acc=0.9833889007568359, loss=0.051715198904275894
test: epoch 77, loss 3.1008918285369873, acc=0.46388888359069824, loss=3.1008918285369873
train: epoch 78, loss 0.056565262377262115, acc=0.9842222332954407, loss=0.056565262377262115
test: epoch 78, loss 3.452399492263794, acc=0.4722222089767456, loss=3.452399492263794
train: epoch 79, loss 0.05503787100315094, acc=0.9846110939979553, loss=0.05503787100315094
test: epoch 79, loss 3.97762131690979, acc=0.3611111044883728, loss=3.97762131690979
train: epoch 80, loss 0.049576010555028915, acc=0.9849444627761841, loss=0.049576010555028915
test: epoch 80, loss 3.2097561359405518, acc=0.4694444537162781, loss=3.2097561359405518
train: epoch 81, loss 0.04730198159813881, acc=0.9850555658340454, loss=0.04730198159813881
test: epoch 81, loss 3.5820679664611816, acc=0.42222222685813904, loss=3.5820679664611816
train: epoch 82, loss 0.04950343444943428, acc=0.9851666688919067, loss=0.04950343444943428
test: epoch 82, loss 3.4884021282196045, acc=0.4583333432674408, loss=3.4884021282196045
train: epoch 83, loss 0.05314360186457634, acc=0.9849444627761841, loss=0.05314360186457634
test: epoch 83, loss 4.5060601234436035, acc=0.46666666865348816, loss=4.5060601234436035
train: epoch 84, loss 0.0448814295232296, acc=0.9859444499015808, loss=0.0448814295232296
test: epoch 84, loss 3.0688788890838623, acc=0.4749999940395355, loss=3.0688788890838623
train: epoch 85, loss 0.05034102499485016, acc=0.9856111407279968, loss=0.05034102499485016
test: epoch 85, loss 3.237367868423462, acc=0.5027777552604675, loss=3.237367868423462
train: epoch 86, loss 0.05339103564620018, acc=0.9853333234786987, loss=0.05339103564620018
test: epoch 86, loss 3.253798484802246, acc=0.4972222149372101, loss=3.253798484802246
train: epoch 87, loss 0.049864742904901505, acc=0.9852222204208374, loss=0.049864742904901505
test: epoch 87, loss 3.516101598739624, acc=0.47777777910232544, loss=3.516101598739624
train: epoch 88, loss 0.044088996946811676, acc=0.9863333106040955, loss=0.044088996946811676
test: epoch 88, loss 3.3390238285064697, acc=0.49444442987442017, loss=3.3390238285064697
train: epoch 89, loss 0.050492580980062485, acc=0.9856111407279968, loss=0.050492580980062485
test: epoch 89, loss 3.7713124752044678, acc=0.46666666865348816, loss=3.7713124752044678
train: epoch 90, loss 0.04110949859023094, acc=0.9878333210945129, loss=0.04110949859023094
test: epoch 90, loss 3.4761557579040527, acc=0.4833333194255829, loss=3.4761557579040527
train: epoch 91, loss 0.04714081063866615, acc=0.9874444603919983, loss=0.04714081063866615
test: epoch 91, loss 3.2521860599517822, acc=0.5, loss=3.2521860599517822
train: epoch 92, loss 0.046715039759874344, acc=0.9874444603919983, loss=0.046715039759874344
test: epoch 92, loss 4.103866100311279, acc=0.42500001192092896, loss=4.103866100311279
train: epoch 93, loss 0.04840081185102463, acc=0.9856666922569275, loss=0.04840081185102463
test: epoch 93, loss 2.9575588703155518, acc=0.4972222149372101, loss=2.9575588703155518
train: epoch 94, loss 0.04066958650946617, acc=0.9875555634498596, loss=0.04066958650946617
test: epoch 94, loss 3.6409316062927246, acc=0.5305555462837219, loss=3.6409316062927246
train: epoch 95, loss 0.03868420422077179, acc=0.987666666507721, loss=0.03868420422077179
test: epoch 95, loss 3.319780111312866, acc=0.5249999761581421, loss=3.319780111312866
train: epoch 96, loss 0.03944797441363335, acc=0.9880555272102356, loss=0.03944797441363335
test: epoch 96, loss 3.127089262008667, acc=0.47777777910232544, loss=3.127089262008667
train: epoch 97, loss 0.045447420328855515, acc=0.987333357334137, loss=0.045447420328855515
test: epoch 97, loss 4.1293721199035645, acc=0.46666666865348816, loss=4.1293721199035645
train: epoch 98, loss 0.039016179740428925, acc=0.9884999990463257, loss=0.039016179740428925
test: epoch 98, loss 3.4458112716674805, acc=0.49444442987442017, loss=3.4458112716674805
train: epoch 99, loss 0.03987810015678406, acc=0.9884999990463257, loss=0.03987810015678406
test: epoch 99, loss 2.653068780899048, acc=0.605555534362793, loss=2.653068780899048
train: epoch 100, loss 0.03710543364286423, acc=0.9890000224113464, loss=0.03710543364286423
test: epoch 100, loss 3.59633731842041, acc=0.47777777910232544, loss=3.59633731842041
train: epoch 101, loss 0.04177418723702431, acc=0.987500011920929, loss=0.04177418723702431
test: epoch 101, loss 3.396536350250244, acc=0.5222222208976746, loss=3.396536350250244
train: epoch 102, loss 0.04371506720781326, acc=0.9869444370269775, loss=0.04371506720781326
test: epoch 102, loss 3.9388158321380615, acc=0.4861111044883728, loss=3.9388158321380615
train: epoch 103, loss 0.036124199628829956, acc=0.9904444217681885, loss=0.036124199628829956
test: epoch 103, loss 3.320493698120117, acc=0.5222222208976746, loss=3.320493698120117
train: epoch 104, loss 0.03256860002875328, acc=0.9901111125946045, loss=0.03256860002875328
test: epoch 104, loss 2.62250018119812, acc=0.5916666388511658, loss=2.62250018119812
train: epoch 105, loss 0.04438721388578415, acc=0.9881666898727417, loss=0.04438721388578415
test: epoch 105, loss 2.8792777061462402, acc=0.49166667461395264, loss=2.8792777061462402
train: epoch 106, loss 0.03671183064579964, acc=0.9897778034210205, loss=0.03671183064579964
test: epoch 106, loss 3.030520439147949, acc=0.5472221970558167, loss=3.030520439147949
train: epoch 107, loss 0.03090672940015793, acc=0.9911110997200012, loss=0.03090672940015793
test: epoch 107, loss 2.510807991027832, acc=0.5694444179534912, loss=2.510807991027832
train: epoch 108, loss 0.0328935869038105, acc=0.9898333549499512, loss=0.0328935869038105
test: epoch 108, loss 2.8938443660736084, acc=0.5416666865348816, loss=2.8938443660736084
train: epoch 109, loss 0.03862946107983589, acc=0.9892222285270691, loss=0.03862946107983589
test: epoch 109, loss 2.931389093399048, acc=0.5527777671813965, loss=2.931389093399048
train: epoch 110, loss 0.03512253984808922, acc=0.9894444346427917, loss=0.03512253984808922
test: epoch 110, loss 3.2614150047302246, acc=0.5166666507720947, loss=3.2614150047302246
train: epoch 111, loss 0.03338705003261566, acc=0.9903888702392578, loss=0.03338705003261566
test: epoch 111, loss 3.2569901943206787, acc=0.5361111164093018, loss=3.2569901943206787
train: epoch 112, loss 0.030004292726516724, acc=0.9909444451332092, loss=0.030004292726516724
test: epoch 112, loss 3.2340142726898193, acc=0.5555555820465088, loss=3.2340142726898193
train: epoch 113, loss 0.03475801646709442, acc=0.9890555739402771, loss=0.03475801646709442
test: epoch 113, loss 2.9568231105804443, acc=0.5333333611488342, loss=2.9568231105804443
train: epoch 114, loss 0.03461912274360657, acc=0.9896110892295837, loss=0.03461912274360657
test: epoch 114, loss 2.5920896530151367, acc=0.5555555820465088, loss=2.5920896530151367
train: epoch 115, loss 0.033109523355960846, acc=0.9898333549499512, loss=0.033109523355960846
test: epoch 115, loss 3.3149607181549072, acc=0.5416666865348816, loss=3.3149607181549072
train: epoch 116, loss 0.04097076505422592, acc=0.9898889064788818, loss=0.04097076505422592
test: epoch 116, loss 3.402230978012085, acc=0.49444442987442017, loss=3.402230978012085
train: epoch 117, loss 0.030407385900616646, acc=0.9912777543067932, loss=0.030407385900616646
test: epoch 117, loss 2.9589695930480957, acc=0.5305555462837219, loss=2.9589695930480957
train: epoch 118, loss 0.03742899000644684, acc=0.9891666769981384, loss=0.03742899000644684
test: epoch 118, loss 2.915935754776001, acc=0.5805555582046509, loss=2.915935754776001
train: epoch 119, loss 0.033737488090991974, acc=0.9907222390174866, loss=0.033737488090991974
test: epoch 119, loss 2.714660406112671, acc=0.5694444179534912, loss=2.714660406112671
train: epoch 120, loss 0.03102194145321846, acc=0.99144446849823, loss=0.03102194145321846
test: epoch 120, loss 2.6556098461151123, acc=0.5638889074325562, loss=2.6556098461151123
train: epoch 121, loss 0.029020903632044792, acc=0.9926666617393494, loss=0.029020903632044792
test: epoch 121, loss 3.545985698699951, acc=0.5305555462837219, loss=3.545985698699951
train: epoch 122, loss 0.023913146927952766, acc=0.9939444661140442, loss=0.023913146927952766
test: epoch 122, loss 2.8146936893463135, acc=0.5833333134651184, loss=2.8146936893463135
train: epoch 123, loss 0.02730829082429409, acc=0.9929444193840027, loss=0.02730829082429409
test: epoch 123, loss 3.0157315731048584, acc=0.5805555582046509, loss=3.0157315731048584
train: epoch 124, loss 0.02841654047369957, acc=0.9928333163261414, loss=0.02841654047369957
test: epoch 124, loss 3.0746355056762695, acc=0.519444465637207, loss=3.0746355056762695
train: epoch 125, loss 0.027110004797577858, acc=0.9935555458068848, loss=0.027110004797577858
test: epoch 125, loss 3.793217420578003, acc=0.5222222208976746, loss=3.793217420578003
train: epoch 126, loss 0.030004393309354782, acc=0.9920555353164673, loss=0.030004393309354782
test: epoch 126, loss 3.086214303970337, acc=0.5361111164093018, loss=3.086214303970337
train: epoch 127, loss 0.031328234821558, acc=0.9922778010368347, loss=0.031328234821558
test: epoch 127, loss 3.2272489070892334, acc=0.5388888716697693, loss=3.2272489070892334
train: epoch 128, loss 0.027497543022036552, acc=0.9929999709129333, loss=0.027497543022036552
test: epoch 128, loss 3.7421188354492188, acc=0.5972222089767456, loss=3.7421188354492188
train: epoch 129, loss 0.029441149905323982, acc=0.9928333163261414, loss=0.029441149905323982
test: epoch 129, loss 3.4871890544891357, acc=0.6166666746139526, loss=3.4871890544891357
train: epoch 130, loss 0.03058505430817604, acc=0.99272221326828, loss=0.03058505430817604
test: epoch 130, loss 2.890756607055664, acc=0.5555555820465088, loss=2.890756607055664
train: epoch 131, loss 0.02623026631772518, acc=0.9929999709129333, loss=0.02623026631772518
test: epoch 131, loss 2.187620162963867, acc=0.6138888597488403, loss=2.187620162963867
train: epoch 132, loss 0.021822510287165642, acc=0.9934444427490234, loss=0.021822510287165642
test: epoch 132, loss 3.1064884662628174, acc=0.5722222328186035, loss=3.1064884662628174
train: epoch 133, loss 0.028879541903734207, acc=0.992555558681488, loss=0.028879541903734207
test: epoch 133, loss 2.521554708480835, acc=0.5944444537162781, loss=2.521554708480835
train: epoch 134, loss 0.01924292929470539, acc=0.9943333268165588, loss=0.01924292929470539
test: epoch 134, loss 3.104326009750366, acc=0.5833333134651184, loss=3.104326009750366
train: epoch 135, loss 0.016667822375893593, acc=0.9955000281333923, loss=0.016667822375893593
test: epoch 135, loss 2.3848142623901367, acc=0.5777778029441833, loss=2.3848142623901367
train: epoch 136, loss 0.027930552139878273, acc=0.992888867855072, loss=0.027930552139878273
test: epoch 136, loss 4.13900089263916, acc=0.5472221970558167, loss=4.13900089263916
train: epoch 137, loss 0.02627084031701088, acc=0.9929444193840027, loss=0.02627084031701088
test: epoch 137, loss 2.6250343322753906, acc=0.6000000238418579, loss=2.6250343322753906
train: epoch 138, loss 0.026856496930122375, acc=0.9926666617393494, loss=0.026856496930122375
test: epoch 138, loss 3.385822296142578, acc=0.6194444298744202, loss=3.385822296142578
train: epoch 139, loss 0.020462874323129654, acc=0.9947777986526489, loss=0.020462874323129654
test: epoch 139, loss 2.5826797485351562, acc=0.6166666746139526, loss=2.5826797485351562
train: epoch 140, loss 0.02437022142112255, acc=0.9934999942779541, loss=0.02437022142112255
test: epoch 140, loss 3.535850763320923, acc=0.5583333373069763, loss=3.535850763320923
train: epoch 141, loss 0.025457527488470078, acc=0.9933333396911621, loss=0.025457527488470078
test: epoch 141, loss 3.4745047092437744, acc=0.6111111044883728, loss=3.4745047092437744
train: epoch 142, loss 0.02833550237119198, acc=0.9926666617393494, loss=0.02833550237119198
test: epoch 142, loss 3.052015542984009, acc=0.574999988079071, loss=3.052015542984009
train: epoch 143, loss 0.028835181146860123, acc=0.9920555353164673, loss=0.028835181146860123
test: epoch 143, loss 3.665419578552246, acc=0.5583333373069763, loss=3.665419578552246
train: epoch 144, loss 0.024423308670520782, acc=0.9947222471237183, loss=0.024423308670520782
test: epoch 144, loss 2.4074599742889404, acc=0.605555534362793, loss=2.4074599742889404
train: epoch 145, loss 0.025045223534107208, acc=0.9938889145851135, loss=0.025045223534107208
test: epoch 145, loss 2.8192145824432373, acc=0.625, loss=2.8192145824432373
train: epoch 146, loss 0.015377482399344444, acc=0.996222198009491, loss=0.015377482399344444
test: epoch 146, loss 3.749285936355591, acc=0.5555555820465088, loss=3.749285936355591
train: epoch 147, loss 0.03283899649977684, acc=0.9919999837875366, loss=0.03283899649977684
test: epoch 147, loss 2.817607879638672, acc=0.5722222328186035, loss=2.817607879638672
train: epoch 148, loss 0.028454789891839027, acc=0.9932777881622314, loss=0.028454789891839027
test: epoch 148, loss 3.5419704914093018, acc=0.5249999761581421, loss=3.5419704914093018
train: epoch 149, loss 0.016683822497725487, acc=0.9955000281333923, loss=0.016683822497725487
test: epoch 149, loss 2.0619053840637207, acc=0.5972222089767456, loss=2.0619053840637207
train: epoch 150, loss 0.016686230897903442, acc=0.9961666464805603, loss=0.016686230897903442
test: epoch 150, loss 2.8486151695251465, acc=0.6083333492279053, loss=2.8486151695251465
