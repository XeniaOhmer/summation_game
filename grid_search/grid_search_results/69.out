# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=1", "--temp_decay=0.99", "--one_hot=false", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=710455338, receiver_embed_dim=64, temp_decay=0.99, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.429781198501587, acc=0.04622222110629082, loss=3.429781198501587
test: epoch 1, loss 3.623603343963623, acc=0.05833333358168602, loss=3.623603343963623
train: epoch 2, loss 2.8089399337768555, acc=0.11622222512960434, loss=2.8089399337768555
test: epoch 2, loss 2.7225325107574463, acc=0.11388888955116272, loss=2.7225325107574463
train: epoch 3, loss 2.095609188079834, acc=0.21938888728618622, loss=2.095609188079834
test: epoch 3, loss 2.4736602306365967, acc=0.13055555522441864, loss=2.4736602306365967
train: epoch 4, loss 1.8654453754425049, acc=0.2731666564941406, loss=1.8654453754425049
test: epoch 4, loss 2.4313900470733643, acc=0.1527777761220932, loss=2.4313900470733643
train: epoch 5, loss 1.7364813089370728, acc=0.30799999833106995, loss=1.7364813089370728
test: epoch 5, loss 2.300776958465576, acc=0.15555556118488312, loss=2.300776958465576
train: epoch 6, loss 1.6740556955337524, acc=0.3179444372653961, loss=1.6740556955337524
test: epoch 6, loss 2.298706293106079, acc=0.16388888657093048, loss=2.298706293106079
train: epoch 7, loss 1.6213804483413696, acc=0.34150001406669617, loss=1.6213804483413696
test: epoch 7, loss 2.3275346755981445, acc=0.16388888657093048, loss=2.3275346755981445
train: epoch 8, loss 1.5816175937652588, acc=0.3544444441795349, loss=1.5816175937652588
test: epoch 8, loss 2.26902174949646, acc=0.17777778208255768, loss=2.26902174949646
train: epoch 9, loss 1.5261918306350708, acc=0.371444433927536, loss=1.5261918306350708
test: epoch 9, loss 2.2229583263397217, acc=0.18611110746860504, loss=2.2229583263397217
train: epoch 10, loss 1.4937100410461426, acc=0.3821111023426056, loss=1.4937100410461426
test: epoch 10, loss 2.2659895420074463, acc=0.1805555522441864, loss=2.2659895420074463
train: epoch 11, loss 1.4620918035507202, acc=0.40316668152809143, loss=1.4620918035507202
test: epoch 11, loss 2.1946513652801514, acc=0.19166666269302368, loss=2.1946513652801514
train: epoch 12, loss 1.4419951438903809, acc=0.40299999713897705, loss=1.4419951438903809
test: epoch 12, loss 2.2812492847442627, acc=0.19166666269302368, loss=2.2812492847442627
train: epoch 13, loss 1.4205936193466187, acc=0.4107222259044647, loss=1.4205936193466187
test: epoch 13, loss 2.2018821239471436, acc=0.21111111342906952, loss=2.2018821239471436
train: epoch 14, loss 1.389204978942871, acc=0.41938889026641846, loss=1.389204978942871
test: epoch 14, loss 2.1819329261779785, acc=0.20000000298023224, loss=2.1819329261779785
train: epoch 15, loss 1.3766449689865112, acc=0.4263888895511627, loss=1.3766449689865112
test: epoch 15, loss 2.2273592948913574, acc=0.21111111342906952, loss=2.2273592948913574
train: epoch 16, loss 1.3481171131134033, acc=0.4398888945579529, loss=1.3481171131134033
test: epoch 16, loss 2.109703540802002, acc=0.21944443881511688, loss=2.109703540802002
train: epoch 17, loss 1.3246294260025024, acc=0.4418888986110687, loss=1.3246294260025024
test: epoch 17, loss 2.114010810852051, acc=0.21111111342906952, loss=2.114010810852051
train: epoch 18, loss 1.312107801437378, acc=0.4468333423137665, loss=1.312107801437378
test: epoch 18, loss 2.1023895740509033, acc=0.2222222238779068, loss=2.1023895740509033
train: epoch 19, loss 1.3067796230316162, acc=0.4469444453716278, loss=1.3067796230316162
test: epoch 19, loss 2.1414549350738525, acc=0.21666666865348816, loss=2.1414549350738525
train: epoch 20, loss 1.286673665046692, acc=0.45311111211776733, loss=1.286673665046692
test: epoch 20, loss 2.0865628719329834, acc=0.21944443881511688, loss=2.0865628719329834
train: epoch 21, loss 1.2741442918777466, acc=0.4540555477142334, loss=1.2741442918777466
test: epoch 21, loss 2.097273588180542, acc=0.23333333432674408, loss=2.097273588180542
train: epoch 22, loss 1.267059564590454, acc=0.4584999978542328, loss=1.267059564590454
test: epoch 22, loss 2.084752082824707, acc=0.23055554926395416, loss=2.084752082824707
train: epoch 23, loss 1.2587863206863403, acc=0.4582222104072571, loss=1.2587863206863403
test: epoch 23, loss 2.2260372638702393, acc=0.22777777910232544, loss=2.2260372638702393
train: epoch 24, loss 1.251404047012329, acc=0.4628888964653015, loss=1.251404047012329
test: epoch 24, loss 2.0778608322143555, acc=0.24166665971279144, loss=2.0778608322143555
train: epoch 25, loss 1.252628207206726, acc=0.46194443106651306, loss=1.252628207206726
test: epoch 25, loss 2.0593156814575195, acc=0.22777777910232544, loss=2.0593156814575195
train: epoch 26, loss 1.2521334886550903, acc=0.46833333373069763, loss=1.2521334886550903
test: epoch 26, loss 2.022176504135132, acc=0.23333333432674408, loss=2.022176504135132
train: epoch 27, loss 1.2286779880523682, acc=0.4722222089767456, loss=1.2286779880523682
test: epoch 27, loss 2.041717290878296, acc=0.23888888955116272, loss=2.041717290878296
train: epoch 28, loss 1.229518175125122, acc=0.4720555543899536, loss=1.229518175125122
test: epoch 28, loss 2.0872550010681152, acc=0.22777777910232544, loss=2.0872550010681152
train: epoch 29, loss 1.237953543663025, acc=0.4645000100135803, loss=1.237953543663025
test: epoch 29, loss 2.1026194095611572, acc=0.23333333432674408, loss=2.1026194095611572
train: epoch 30, loss 1.2126106023788452, acc=0.47688889503479004, loss=1.2126106023788452
test: epoch 30, loss 2.1408777236938477, acc=0.2361111044883728, loss=2.1408777236938477
train: epoch 31, loss 1.2167541980743408, acc=0.47477778792381287, loss=1.2167541980743408
test: epoch 31, loss 2.206923723220825, acc=0.23333333432674408, loss=2.206923723220825
train: epoch 32, loss 1.192217230796814, acc=0.4818333387374878, loss=1.192217230796814
test: epoch 32, loss 2.069666862487793, acc=0.2527777850627899, loss=2.069666862487793
train: epoch 33, loss 1.196582555770874, acc=0.48444443941116333, loss=1.196582555770874
test: epoch 33, loss 2.050729990005493, acc=0.24166665971279144, loss=2.050729990005493
train: epoch 34, loss 1.2032337188720703, acc=0.4813888967037201, loss=1.2032337188720703
test: epoch 34, loss 2.0562751293182373, acc=0.24722221493721008, loss=2.0562751293182373
train: epoch 35, loss 1.1840417385101318, acc=0.49044445157051086, loss=1.1840417385101318
test: epoch 35, loss 2.1046085357666016, acc=0.2611111104488373, loss=2.1046085357666016
train: epoch 36, loss 1.1715028285980225, acc=0.49388888478279114, loss=1.1715028285980225
test: epoch 36, loss 2.0109784603118896, acc=0.2527777850627899, loss=2.0109784603118896
train: epoch 37, loss 1.1623910665512085, acc=0.5007777810096741, loss=1.1623910665512085
test: epoch 37, loss 2.0737953186035156, acc=0.2527777850627899, loss=2.0737953186035156
train: epoch 38, loss 1.1603604555130005, acc=0.5021666884422302, loss=1.1603604555130005
test: epoch 38, loss 2.2277238368988037, acc=0.25, loss=2.2277238368988037
train: epoch 39, loss 1.1502528190612793, acc=0.50727778673172, loss=1.1502528190612793
test: epoch 39, loss 2.082533121109009, acc=0.2638888955116272, loss=2.082533121109009
train: epoch 40, loss 1.1509283781051636, acc=0.5036666393280029, loss=1.1509283781051636
test: epoch 40, loss 2.169731616973877, acc=0.24722221493721008, loss=2.169731616973877
train: epoch 41, loss 1.1283533573150635, acc=0.5142777562141418, loss=1.1283533573150635
test: epoch 41, loss 2.0971429347991943, acc=0.25833332538604736, loss=2.0971429347991943
train: epoch 42, loss 1.1212124824523926, acc=0.5164999961853027, loss=1.1212124824523926
test: epoch 42, loss 1.9663466215133667, acc=0.2611111104488373, loss=1.9663466215133667
train: epoch 43, loss 1.129027009010315, acc=0.5159444212913513, loss=1.129027009010315
test: epoch 43, loss 2.0217509269714355, acc=0.2611111104488373, loss=2.0217509269714355
train: epoch 44, loss 1.1117887496948242, acc=0.5212222337722778, loss=1.1117887496948242
test: epoch 44, loss 2.0509746074676514, acc=0.28333333134651184, loss=2.0509746074676514
train: epoch 45, loss 1.0885719060897827, acc=0.528333306312561, loss=1.0885719060897827
test: epoch 45, loss 2.0762405395507812, acc=0.26944443583488464, loss=2.0762405395507812
train: epoch 46, loss 1.0971901416778564, acc=0.5289999842643738, loss=1.0971901416778564
test: epoch 46, loss 2.0400748252868652, acc=0.2805555462837219, loss=2.0400748252868652
train: epoch 47, loss 1.0947048664093018, acc=0.5323888659477234, loss=1.0947048664093018
test: epoch 47, loss 2.224757671356201, acc=0.2750000059604645, loss=2.224757671356201
train: epoch 48, loss 1.071217656135559, acc=0.5413333177566528, loss=1.071217656135559
test: epoch 48, loss 2.1519699096679688, acc=0.2888889014720917, loss=2.1519699096679688
train: epoch 49, loss 1.0670084953308105, acc=0.5434444546699524, loss=1.0670084953308105
test: epoch 49, loss 2.2338364124298096, acc=0.2611111104488373, loss=2.2338364124298096
train: epoch 50, loss 1.0592652559280396, acc=0.542888879776001, loss=1.0592652559280396
test: epoch 50, loss 2.0064666271209717, acc=0.2944444417953491, loss=2.0064666271209717
train: epoch 51, loss 1.0422165393829346, acc=0.5485000014305115, loss=1.0422165393829346
test: epoch 51, loss 2.039931297302246, acc=0.2888889014720917, loss=2.039931297302246
train: epoch 52, loss 1.047382116317749, acc=0.5448889136314392, loss=1.047382116317749
test: epoch 52, loss 2.2456958293914795, acc=0.2944444417953491, loss=2.2456958293914795
train: epoch 53, loss 1.0488075017929077, acc=0.5480555295944214, loss=1.0488075017929077
test: epoch 53, loss 2.051346778869629, acc=0.29722222685813904, loss=2.051346778869629
train: epoch 54, loss 1.0286080837249756, acc=0.5554999709129333, loss=1.0286080837249756
test: epoch 54, loss 2.1330299377441406, acc=0.30000001192092896, loss=2.1330299377441406
train: epoch 55, loss 1.0301039218902588, acc=0.5536110997200012, loss=1.0301039218902588
test: epoch 55, loss 2.0244457721710205, acc=0.30000001192092896, loss=2.0244457721710205
train: epoch 56, loss 1.0184835195541382, acc=0.5588333606719971, loss=1.0184835195541382
test: epoch 56, loss 2.115736961364746, acc=0.2888889014720917, loss=2.115736961364746
train: epoch 57, loss 1.0277178287506104, acc=0.5541666746139526, loss=1.0277178287506104
test: epoch 57, loss 2.0288467407226562, acc=0.29722222685813904, loss=2.0288467407226562
train: epoch 58, loss 1.0143295526504517, acc=0.5628888607025146, loss=1.0143295526504517
test: epoch 58, loss 2.0016794204711914, acc=0.3083333373069763, loss=2.0016794204711914
train: epoch 59, loss 1.011896014213562, acc=0.5590555667877197, loss=1.011896014213562
test: epoch 59, loss 2.2204596996307373, acc=0.31111112236976624, loss=2.2204596996307373
train: epoch 60, loss 0.9987196922302246, acc=0.5634444355964661, loss=0.9987196922302246
test: epoch 60, loss 2.3488221168518066, acc=0.3027777671813965, loss=2.3488221168518066
train: epoch 61, loss 0.9949535131454468, acc=0.5680000185966492, loss=0.9949535131454468
test: epoch 61, loss 2.175807237625122, acc=0.3222222328186035, loss=2.175807237625122
train: epoch 62, loss 1.0052032470703125, acc=0.5622777938842773, loss=1.0052032470703125
test: epoch 62, loss 2.0221076011657715, acc=0.31111112236976624, loss=2.0221076011657715
train: epoch 63, loss 0.9815244674682617, acc=0.5728333592414856, loss=0.9815244674682617
test: epoch 63, loss 2.236800193786621, acc=0.32777777314186096, loss=2.236800193786621
train: epoch 64, loss 0.9922928810119629, acc=0.5713333487510681, loss=0.9922928810119629
test: epoch 64, loss 2.098329782485962, acc=0.32499998807907104, loss=2.098329782485962
train: epoch 65, loss 0.980014979839325, acc=0.5749444365501404, loss=0.980014979839325
test: epoch 65, loss 2.109459161758423, acc=0.31111112236976624, loss=2.109459161758423
train: epoch 66, loss 0.9672749638557434, acc=0.5773333311080933, loss=0.9672749638557434
test: epoch 66, loss 2.113403797149658, acc=0.31388887763023376, loss=2.113403797149658
train: epoch 67, loss 0.9565192461013794, acc=0.581333339214325, loss=0.9565192461013794
test: epoch 67, loss 2.2634406089782715, acc=0.31388887763023376, loss=2.2634406089782715
train: epoch 68, loss 0.9606537818908691, acc=0.5846111178398132, loss=0.9606537818908691
test: epoch 68, loss 1.9362539052963257, acc=0.3194444477558136, loss=1.9362539052963257
train: epoch 69, loss 0.9619394540786743, acc=0.5822222232818604, loss=0.9619394540786743
test: epoch 69, loss 2.105715274810791, acc=0.32499998807907104, loss=2.105715274810791
train: epoch 70, loss 0.9537133574485779, acc=0.5840555429458618, loss=0.9537133574485779
test: epoch 70, loss 1.9702593088150024, acc=0.3194444477558136, loss=1.9702593088150024
train: epoch 71, loss 0.9435994029045105, acc=0.5915555357933044, loss=0.9435994029045105
test: epoch 71, loss 2.12955641746521, acc=0.3222222328186035, loss=2.12955641746521
train: epoch 72, loss 0.9559736251831055, acc=0.5807777643203735, loss=0.9559736251831055
test: epoch 72, loss 1.999800682067871, acc=0.32777777314186096, loss=1.999800682067871
train: epoch 73, loss 0.9482905864715576, acc=0.586555540561676, loss=0.9482905864715576
test: epoch 73, loss 2.129831075668335, acc=0.32777777314186096, loss=2.129831075668335
train: epoch 74, loss 0.9391926527023315, acc=0.5912222266197205, loss=0.9391926527023315
test: epoch 74, loss 1.9753365516662598, acc=0.33888888359069824, loss=1.9753365516662598
train: epoch 75, loss 0.93832927942276, acc=0.5899444222450256, loss=0.93832927942276
test: epoch 75, loss 2.012627124786377, acc=0.34166666865348816, loss=2.012627124786377
train: epoch 76, loss 0.933463454246521, acc=0.5929999947547913, loss=0.933463454246521
test: epoch 76, loss 2.300682544708252, acc=0.3444444537162781, loss=2.300682544708252
train: epoch 77, loss 0.9253890514373779, acc=0.5929999947547913, loss=0.9253890514373779
test: epoch 77, loss 2.2347328662872314, acc=0.32499998807907104, loss=2.2347328662872314
train: epoch 78, loss 0.9250426888465881, acc=0.5956666469573975, loss=0.9250426888465881
test: epoch 78, loss 2.0403895378112793, acc=0.33888888359069824, loss=2.0403895378112793
train: epoch 79, loss 0.9172664880752563, acc=0.6013888716697693, loss=0.9172664880752563
test: epoch 79, loss 2.0990869998931885, acc=0.33888888359069824, loss=2.0990869998931885
train: epoch 80, loss 0.921113133430481, acc=0.5988333225250244, loss=0.921113133430481
test: epoch 80, loss 2.049561023712158, acc=0.33888888359069824, loss=2.049561023712158
train: epoch 81, loss 0.9147212505340576, acc=0.6010555624961853, loss=0.9147212505340576
test: epoch 81, loss 2.1719536781311035, acc=0.34166666865348816, loss=2.1719536781311035
train: epoch 82, loss 0.9176533222198486, acc=0.6019999980926514, loss=0.9176533222198486
test: epoch 82, loss 1.9359105825424194, acc=0.3472222089767456, loss=1.9359105825424194
train: epoch 83, loss 0.9141192436218262, acc=0.5996111035346985, loss=0.9141192436218262
test: epoch 83, loss 1.934855580329895, acc=0.3472222089767456, loss=1.934855580329895
train: epoch 84, loss 0.907335102558136, acc=0.5987777709960938, loss=0.907335102558136
test: epoch 84, loss 2.091022491455078, acc=0.3444444537162781, loss=2.091022491455078
train: epoch 85, loss 0.8985055685043335, acc=0.6047222018241882, loss=0.8985055685043335
test: epoch 85, loss 2.0800158977508545, acc=0.34166666865348816, loss=2.0800158977508545
train: epoch 86, loss 0.9072760343551636, acc=0.6029999852180481, loss=0.9072760343551636
test: epoch 86, loss 2.1842546463012695, acc=0.33888888359069824, loss=2.1842546463012695
train: epoch 87, loss 0.8961670398712158, acc=0.6071666479110718, loss=0.8961670398712158
test: epoch 87, loss 2.0487864017486572, acc=0.3472222089767456, loss=2.0487864017486572
train: epoch 88, loss 0.9028531908988953, acc=0.5997777581214905, loss=0.9028531908988953
test: epoch 88, loss 2.12583327293396, acc=0.3611111044883728, loss=2.12583327293396
train: epoch 89, loss 0.8962984681129456, acc=0.6062777638435364, loss=0.8962984681129456
test: epoch 89, loss 2.0253970623016357, acc=0.3611111044883728, loss=2.0253970623016357
train: epoch 90, loss 0.8913623690605164, acc=0.605222225189209, loss=0.8913623690605164
test: epoch 90, loss 2.1131348609924316, acc=0.3583333194255829, loss=2.1131348609924316
train: epoch 91, loss 0.9026634097099304, acc=0.6060555577278137, loss=0.9026634097099304
test: epoch 91, loss 2.182939291000366, acc=0.3611111044883728, loss=2.182939291000366
train: epoch 92, loss 0.8934794068336487, acc=0.6066666841506958, loss=0.8934794068336487
test: epoch 92, loss 1.922160029411316, acc=0.3583333194255829, loss=1.922160029411316
train: epoch 93, loss 0.8865553140640259, acc=0.6078888773918152, loss=0.8865553140640259
test: epoch 93, loss 2.129220724105835, acc=0.3611111044883728, loss=2.129220724105835
train: epoch 94, loss 0.8960095047950745, acc=0.6028888821601868, loss=0.8960095047950745
test: epoch 94, loss 2.2827107906341553, acc=0.35277777910232544, loss=2.2827107906341553
train: epoch 95, loss 0.8865705132484436, acc=0.6104999780654907, loss=0.8865705132484436
test: epoch 95, loss 1.9570358991622925, acc=0.35555556416511536, loss=1.9570358991622925
train: epoch 96, loss 0.8972926735877991, acc=0.6067777872085571, loss=0.8972926735877991
test: epoch 96, loss 2.1179072856903076, acc=0.3611111044883728, loss=2.1179072856903076
train: epoch 97, loss 0.8905212879180908, acc=0.6099444627761841, loss=0.8905212879180908
test: epoch 97, loss 1.8512909412384033, acc=0.3583333194255829, loss=1.8512909412384033
train: epoch 98, loss 0.8833578824996948, acc=0.6081666946411133, loss=0.8833578824996948
test: epoch 98, loss 2.035169839859009, acc=0.3638888895511627, loss=2.035169839859009
train: epoch 99, loss 0.8844502568244934, acc=0.6079999804496765, loss=0.8844502568244934
test: epoch 99, loss 2.1213133335113525, acc=0.36666667461395264, loss=2.1213133335113525
train: epoch 100, loss 0.8923763632774353, acc=0.609666645526886, loss=0.8923763632774353
test: epoch 100, loss 2.038182020187378, acc=0.3638888895511627, loss=2.038182020187378
train: epoch 101, loss 0.8894367814064026, acc=0.6079999804496765, loss=0.8894367814064026
test: epoch 101, loss 2.1240620613098145, acc=0.3638888895511627, loss=2.1240620613098145
train: epoch 102, loss 0.8803821802139282, acc=0.6104999780654907, loss=0.8803821802139282
test: epoch 102, loss 2.013364315032959, acc=0.3583333194255829, loss=2.013364315032959
train: epoch 103, loss 0.8825360536575317, acc=0.6090555787086487, loss=0.8825360536575317
test: epoch 103, loss 2.198829412460327, acc=0.3611111044883728, loss=2.198829412460327
train: epoch 104, loss 0.8771148920059204, acc=0.613111138343811, loss=0.8771148920059204
test: epoch 104, loss 2.1326358318328857, acc=0.36666667461395264, loss=2.1326358318328857
train: epoch 105, loss 0.8756018877029419, acc=0.6133333444595337, loss=0.8756018877029419
test: epoch 105, loss 2.1698975563049316, acc=0.3638888895511627, loss=2.1698975563049316
train: epoch 106, loss 0.876399040222168, acc=0.6123889088630676, loss=0.876399040222168
test: epoch 106, loss 2.018829107284546, acc=0.3583333194255829, loss=2.018829107284546
train: epoch 107, loss 0.8726574778556824, acc=0.6152222156524658, loss=0.8726574778556824
test: epoch 107, loss 2.382704496383667, acc=0.3611111044883728, loss=2.382704496383667
train: epoch 108, loss 0.8695272207260132, acc=0.6151666641235352, loss=0.8695272207260132
test: epoch 108, loss 2.2491917610168457, acc=0.3638888895511627, loss=2.2491917610168457
train: epoch 109, loss 0.8730431199073792, acc=0.6165000200271606, loss=0.8730431199073792
test: epoch 109, loss 2.213977813720703, acc=0.3638888895511627, loss=2.213977813720703
train: epoch 110, loss 0.864548921585083, acc=0.6181666851043701, loss=0.864548921585083
test: epoch 110, loss 2.2624564170837402, acc=0.35555556416511536, loss=2.2624564170837402
train: epoch 111, loss 0.8792266249656677, acc=0.6077222228050232, loss=0.8792266249656677
test: epoch 111, loss 2.0517096519470215, acc=0.36944442987442017, loss=2.0517096519470215
train: epoch 112, loss 0.8714121580123901, acc=0.612666666507721, loss=0.8714121580123901
test: epoch 112, loss 2.162160873413086, acc=0.3722222149372101, loss=2.162160873413086
train: epoch 113, loss 0.8726604580879211, acc=0.6115000247955322, loss=0.8726604580879211
test: epoch 113, loss 2.066537618637085, acc=0.36666667461395264, loss=2.066537618637085
train: epoch 114, loss 0.8728644847869873, acc=0.6137222051620483, loss=0.8728644847869873
test: epoch 114, loss 2.087879180908203, acc=0.36944442987442017, loss=2.087879180908203
train: epoch 115, loss 0.8672637939453125, acc=0.6147222518920898, loss=0.8672637939453125
test: epoch 115, loss 2.005919933319092, acc=0.3722222149372101, loss=2.005919933319092
train: epoch 116, loss 0.867874801158905, acc=0.6135555505752563, loss=0.867874801158905
test: epoch 116, loss 2.309190034866333, acc=0.36944442987442017, loss=2.309190034866333
train: epoch 117, loss 0.8763157725334167, acc=0.6107777953147888, loss=0.8763157725334167
test: epoch 117, loss 2.1175832748413086, acc=0.3638888895511627, loss=2.1175832748413086
train: epoch 118, loss 0.8607186675071716, acc=0.6200000047683716, loss=0.8607186675071716
test: epoch 118, loss 2.1826257705688477, acc=0.3638888895511627, loss=2.1826257705688477
train: epoch 119, loss 0.8536070585250854, acc=0.6214444637298584, loss=0.8536070585250854
test: epoch 119, loss 2.181147575378418, acc=0.3722222149372101, loss=2.181147575378418
train: epoch 120, loss 0.8469362854957581, acc=0.6221110820770264, loss=0.8469362854957581
test: epoch 120, loss 2.1392710208892822, acc=0.36944442987442017, loss=2.1392710208892822
train: epoch 121, loss 0.8682106733322144, acc=0.616777777671814, loss=0.8682106733322144
test: epoch 121, loss 2.138885498046875, acc=0.3722222149372101, loss=2.138885498046875
train: epoch 122, loss 0.8696829676628113, acc=0.6153333187103271, loss=0.8696829676628113
test: epoch 122, loss 2.1091361045837402, acc=0.375, loss=2.1091361045837402
train: epoch 123, loss 0.8604388236999512, acc=0.6155555844306946, loss=0.8604388236999512
test: epoch 123, loss 2.26043963432312, acc=0.375, loss=2.26043963432312
train: epoch 124, loss 0.8475101590156555, acc=0.6209999918937683, loss=0.8475101590156555
test: epoch 124, loss 2.0493357181549072, acc=0.375, loss=2.0493357181549072
train: epoch 125, loss 0.8554295897483826, acc=0.6196666955947876, loss=0.8554295897483826
test: epoch 125, loss 2.033745050430298, acc=0.3777777850627899, loss=2.033745050430298
train: epoch 126, loss 0.8570712804794312, acc=0.6200000047683716, loss=0.8570712804794312
test: epoch 126, loss 2.0308923721313477, acc=0.38333332538604736, loss=2.0308923721313477
train: epoch 127, loss 0.8502494096755981, acc=0.6247222423553467, loss=0.8502494096755981
test: epoch 127, loss 1.896658182144165, acc=0.375, loss=1.896658182144165
train: epoch 128, loss 0.8497855067253113, acc=0.6262221932411194, loss=0.8497855067253113
test: epoch 128, loss 1.9731636047363281, acc=0.38333332538604736, loss=1.9731636047363281
train: epoch 129, loss 0.8504364490509033, acc=0.6240000128746033, loss=0.8504364490509033
test: epoch 129, loss 2.2612555027008057, acc=0.3861111104488373, loss=2.2612555027008057
train: epoch 130, loss 0.8598241209983826, acc=0.6238889098167419, loss=0.8598241209983826
test: epoch 130, loss 2.253805160522461, acc=0.3861111104488373, loss=2.253805160522461
train: epoch 131, loss 0.8591364622116089, acc=0.6202222108840942, loss=0.8591364622116089
test: epoch 131, loss 2.207096576690674, acc=0.3861111104488373, loss=2.207096576690674
train: epoch 132, loss 0.850105881690979, acc=0.6225555539131165, loss=0.850105881690979
test: epoch 132, loss 2.356144666671753, acc=0.3888888955116272, loss=2.356144666671753
train: epoch 133, loss 0.8476185202598572, acc=0.6239444613456726, loss=0.8476185202598572
test: epoch 133, loss 2.31911563873291, acc=0.3888888955116272, loss=2.31911563873291
train: epoch 134, loss 0.8580747842788696, acc=0.621999979019165, loss=0.8580747842788696
test: epoch 134, loss 2.0512356758117676, acc=0.3861111104488373, loss=2.0512356758117676
train: epoch 135, loss 0.8436899185180664, acc=0.6274999976158142, loss=0.8436899185180664
test: epoch 135, loss 2.052025079727173, acc=0.3888888955116272, loss=2.052025079727173
train: epoch 136, loss 0.8494568467140198, acc=0.621222198009491, loss=0.8494568467140198
test: epoch 136, loss 2.1145501136779785, acc=0.3861111104488373, loss=2.1145501136779785
train: epoch 137, loss 0.846676766872406, acc=0.6286110877990723, loss=0.846676766872406
test: epoch 137, loss 2.014819383621216, acc=0.3888888955116272, loss=2.014819383621216
train: epoch 138, loss 0.8379523158073425, acc=0.6276666522026062, loss=0.8379523158073425
test: epoch 138, loss 2.203720808029175, acc=0.3888888955116272, loss=2.203720808029175
train: epoch 139, loss 0.8468084931373596, acc=0.6305000185966492, loss=0.8468084931373596
test: epoch 139, loss 2.040184497833252, acc=0.3916666805744171, loss=2.040184497833252
train: epoch 140, loss 0.8352875113487244, acc=0.6286666393280029, loss=0.8352875113487244
test: epoch 140, loss 1.9495526552200317, acc=0.39444443583488464, loss=1.9495526552200317
train: epoch 141, loss 0.8466035723686218, acc=0.6255000233650208, loss=0.8466035723686218
test: epoch 141, loss 2.03057599067688, acc=0.39722222089767456, loss=2.03057599067688
train: epoch 142, loss 0.8294180035591125, acc=0.6330000162124634, loss=0.8294180035591125
test: epoch 142, loss 1.9586412906646729, acc=0.39722222089767456, loss=1.9586412906646729
train: epoch 143, loss 0.8355400562286377, acc=0.6274444460868835, loss=0.8355400562286377
test: epoch 143, loss 2.2640178203582764, acc=0.39444443583488464, loss=2.2640178203582764
train: epoch 144, loss 0.8340719938278198, acc=0.6314444541931152, loss=0.8340719938278198
test: epoch 144, loss 2.332517147064209, acc=0.39722222089767456, loss=2.332517147064209
train: epoch 145, loss 0.83831387758255, acc=0.6317222118377686, loss=0.83831387758255
test: epoch 145, loss 1.9672062397003174, acc=0.38333332538604736, loss=1.9672062397003174
train: epoch 146, loss 0.8315587639808655, acc=0.6355555653572083, loss=0.8315587639808655
test: epoch 146, loss 2.12037992477417, acc=0.39444443583488464, loss=2.12037992477417
train: epoch 147, loss 0.8196200728416443, acc=0.6359999775886536, loss=0.8196200728416443
test: epoch 147, loss 1.9783556461334229, acc=0.3888888955116272, loss=1.9783556461334229
train: epoch 148, loss 0.8272040486335754, acc=0.6316111087799072, loss=0.8272040486335754
test: epoch 148, loss 1.97698974609375, acc=0.39722222089767456, loss=1.97698974609375
train: epoch 149, loss 0.8269302845001221, acc=0.6337222456932068, loss=0.8269302845001221
test: epoch 149, loss 2.0389676094055176, acc=0.39444443583488464, loss=2.0389676094055176
train: epoch 150, loss 0.8242210149765015, acc=0.6343333125114441, loss=0.8242210149765015
test: epoch 150, loss 2.183349609375, acc=0.39722222089767456, loss=2.183349609375
