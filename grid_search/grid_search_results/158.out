# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=2.0", "--temp_decay=0.99", "--one_hot=true", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1304239697, receiver_embed_dim=128, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.7388412952423096, acc=0.10577777773141861, loss=2.7388412952423096
test: epoch 1, loss 4.388946533203125, acc=0.07777778059244156, loss=4.388946533203125
train: epoch 2, loss 1.7528139352798462, acc=0.2669999897480011, loss=1.7528139352798462
test: epoch 2, loss 3.1799113750457764, acc=0.1944444477558136, loss=3.1799113750457764
train: epoch 3, loss 1.373854398727417, acc=0.38966667652130127, loss=1.373854398727417
test: epoch 3, loss 2.9613606929779053, acc=0.23055554926395416, loss=2.9613606929779053
train: epoch 4, loss 1.0285416841506958, acc=0.5513888597488403, loss=1.0285416841506958
test: epoch 4, loss 3.4533772468566895, acc=0.23888888955116272, loss=3.4533772468566895
train: epoch 5, loss 0.7468674778938293, acc=0.6809444427490234, loss=0.7468674778938293
test: epoch 5, loss 2.202176570892334, acc=0.39722222089767456, loss=2.202176570892334
train: epoch 6, loss 0.4790041744709015, acc=0.800611138343811, loss=0.4790041744709015
test: epoch 6, loss 1.970099925994873, acc=0.4611110985279083, loss=1.970099925994873
train: epoch 7, loss 0.3807957172393799, acc=0.8427222371101379, loss=0.3807957172393799
test: epoch 7, loss 1.7145118713378906, acc=0.4277777671813965, loss=1.7145118713378906
train: epoch 8, loss 0.324311226606369, acc=0.866777777671814, loss=0.324311226606369
test: epoch 8, loss 1.476692795753479, acc=0.5722222328186035, loss=1.476692795753479
train: epoch 9, loss 0.2832579016685486, acc=0.8820555806159973, loss=0.2832579016685486
test: epoch 9, loss 1.7366223335266113, acc=0.5138888955116272, loss=1.7366223335266113
train: epoch 10, loss 0.25777754187583923, acc=0.8920000195503235, loss=0.25777754187583923
test: epoch 10, loss 1.361615538597107, acc=0.6194444298744202, loss=1.361615538597107
train: epoch 11, loss 0.23987682163715363, acc=0.8986666798591614, loss=0.23987682163715363
test: epoch 11, loss 1.3710495233535767, acc=0.5694444179534912, loss=1.3710495233535767
train: epoch 12, loss 0.2387205958366394, acc=0.9037777781486511, loss=0.2387205958366394
test: epoch 12, loss 1.35775887966156, acc=0.605555534362793, loss=1.35775887966156
train: epoch 13, loss 0.20529282093048096, acc=0.9152777791023254, loss=0.20529282093048096
test: epoch 13, loss 1.1908187866210938, acc=0.5694444179534912, loss=1.1908187866210938
train: epoch 14, loss 0.22830422222614288, acc=0.9071666598320007, loss=0.22830422222614288
test: epoch 14, loss 1.0086915493011475, acc=0.7083333134651184, loss=1.0086915493011475
train: epoch 15, loss 0.1913866549730301, acc=0.9219444394111633, loss=0.1913866549730301
test: epoch 15, loss 1.1518423557281494, acc=0.6111111044883728, loss=1.1518423557281494
train: epoch 16, loss 0.20620396733283997, acc=0.917722225189209, loss=0.20620396733283997
test: epoch 16, loss 1.0763258934020996, acc=0.699999988079071, loss=1.0763258934020996
train: epoch 17, loss 0.20000843703746796, acc=0.9206666946411133, loss=0.20000843703746796
test: epoch 17, loss 0.679354727268219, acc=0.7666666507720947, loss=0.679354727268219
train: epoch 18, loss 0.176209956407547, acc=0.9278888702392578, loss=0.176209956407547
test: epoch 18, loss 0.7072155475616455, acc=0.7583333253860474, loss=0.7072155475616455
train: epoch 19, loss 0.17030437290668488, acc=0.9312222003936768, loss=0.17030437290668488
test: epoch 19, loss 0.5542975068092346, acc=0.8055555820465088, loss=0.5542975068092346
train: epoch 20, loss 0.16090698540210724, acc=0.9352777600288391, loss=0.16090698540210724
test: epoch 20, loss 0.46505776047706604, acc=0.855555534362793, loss=0.46505776047706604
train: epoch 21, loss 0.16633571684360504, acc=0.9346110820770264, loss=0.16633571684360504
test: epoch 21, loss 0.4390544891357422, acc=0.824999988079071, loss=0.4390544891357422
train: epoch 22, loss 0.1594647765159607, acc=0.9357222318649292, loss=0.1594647765159607
test: epoch 22, loss 0.3454422950744629, acc=0.8888888955116272, loss=0.3454422950744629
train: epoch 23, loss 0.15013127028942108, acc=0.9386666417121887, loss=0.15013127028942108
test: epoch 23, loss 0.24635829031467438, acc=0.925000011920929, loss=0.24635829031467438
train: epoch 24, loss 0.1550607681274414, acc=0.9375555515289307, loss=0.1550607681274414
test: epoch 24, loss 0.2352111041545868, acc=0.8999999761581421, loss=0.2352111041545868
train: epoch 25, loss 0.15867269039154053, acc=0.9372222423553467, loss=0.15867269039154053
test: epoch 25, loss 0.22214184701442719, acc=0.925000011920929, loss=0.22214184701442719
train: epoch 26, loss 0.16625438630580902, acc=0.9321666955947876, loss=0.16625438630580902
test: epoch 26, loss 0.18838265538215637, acc=0.9166666865348816, loss=0.18838265538215637
train: epoch 27, loss 0.14210805296897888, acc=0.9411110877990723, loss=0.14210805296897888
test: epoch 27, loss 0.1798933893442154, acc=0.9305555820465088, loss=0.1798933893442154
train: epoch 28, loss 0.13775278627872467, acc=0.9428333044052124, loss=0.13775278627872467
test: epoch 28, loss 0.17856436967849731, acc=0.9388889074325562, loss=0.17856436967849731
train: epoch 29, loss 0.11102422326803207, acc=0.9498888850212097, loss=0.11102422326803207
test: epoch 29, loss 0.20194438099861145, acc=0.9361110925674438, loss=0.20194438099861145
train: epoch 30, loss 0.15193870663642883, acc=0.9398333430290222, loss=0.15193870663642883
test: epoch 30, loss 0.22363592684268951, acc=0.9305555820465088, loss=0.22363592684268951
train: epoch 31, loss 0.09635026007890701, acc=0.9539444446563721, loss=0.09635026007890701
test: epoch 31, loss 0.11711905151605606, acc=0.9527778029441833, loss=0.11711905151605606
train: epoch 32, loss 0.11140528321266174, acc=0.9506666660308838, loss=0.11140528321266174
test: epoch 32, loss 0.0668993666768074, acc=0.9611111283302307, loss=0.0668993666768074
train: epoch 33, loss 0.10715927183628082, acc=0.9524999856948853, loss=0.10715927183628082
test: epoch 33, loss 0.3935943841934204, acc=0.9027777910232544, loss=0.3935943841934204
train: epoch 34, loss 0.17358306050300598, acc=0.9361666440963745, loss=0.17358306050300598
test: epoch 34, loss 0.16376902163028717, acc=0.9138888716697693, loss=0.16376902163028717
train: epoch 35, loss 0.13442839682102203, acc=0.9445555806159973, loss=0.13442839682102203
test: epoch 35, loss 0.16797684133052826, acc=0.9361110925674438, loss=0.16797684133052826
train: epoch 36, loss 0.1340046375989914, acc=0.940833330154419, loss=0.1340046375989914
test: epoch 36, loss 0.09627878665924072, acc=0.949999988079071, loss=0.09627878665924072
train: epoch 37, loss 0.1275033801794052, acc=0.9448333382606506, loss=0.1275033801794052
test: epoch 37, loss 0.09134756028652191, acc=0.9527778029441833, loss=0.09134756028652191
train: epoch 38, loss 0.13526977598667145, acc=0.9448333382606506, loss=0.13526977598667145
test: epoch 38, loss 0.23041941225528717, acc=0.9166666865348816, loss=0.23041941225528717
train: epoch 39, loss 0.14806927740573883, acc=0.9426666498184204, loss=0.14806927740573883
test: epoch 39, loss 0.11129055172204971, acc=0.9472222328186035, loss=0.11129055172204971
train: epoch 40, loss 0.11745002120733261, acc=0.9415000081062317, loss=0.11745002120733261
test: epoch 40, loss 0.09956047683954239, acc=0.9472222328186035, loss=0.09956047683954239
train: epoch 41, loss 0.16757218539714813, acc=0.9266111254692078, loss=0.16757218539714813
test: epoch 41, loss 0.1302589476108551, acc=0.9388889074325562, loss=0.1302589476108551
train: epoch 42, loss 0.160411536693573, acc=0.93022221326828, loss=0.160411536693573
test: epoch 42, loss 0.19052578508853912, acc=0.925000011920929, loss=0.19052578508853912
train: epoch 43, loss 0.21168936789035797, acc=0.9179999828338623, loss=0.21168936789035797
test: epoch 43, loss 0.14174391329288483, acc=0.9361110925674438, loss=0.14174391329288483
train: epoch 44, loss 0.13582518696784973, acc=0.9426666498184204, loss=0.13582518696784973
test: epoch 44, loss 0.09988865256309509, acc=0.9472222328186035, loss=0.09988865256309509
train: epoch 45, loss 0.09881123155355453, acc=0.9406111240386963, loss=0.09881123155355453
test: epoch 45, loss 0.09713393449783325, acc=0.9472222328186035, loss=0.09713393449783325
train: epoch 46, loss 0.10339466482400894, acc=0.9386110901832581, loss=0.10339466482400894
test: epoch 46, loss 0.09720658510923386, acc=0.9472222328186035, loss=0.09720658510923386
train: epoch 47, loss 0.2201508730649948, acc=0.9139444231987, loss=0.2201508730649948
test: epoch 47, loss 0.10792447626590729, acc=0.9472222328186035, loss=0.10792447626590729
train: epoch 48, loss 0.19380423426628113, acc=0.926111102104187, loss=0.19380423426628113
test: epoch 48, loss 0.15142938494682312, acc=0.9333333373069763, loss=0.15142938494682312
train: epoch 49, loss 0.15237188339233398, acc=0.929444432258606, loss=0.15237188339233398
test: epoch 49, loss 0.12200364470481873, acc=0.9416666626930237, loss=0.12200364470481873
train: epoch 50, loss 0.16174080967903137, acc=0.9291666746139526, loss=0.16174080967903137
test: epoch 50, loss 0.11921103298664093, acc=0.9416666626930237, loss=0.11921103298664093
train: epoch 51, loss 0.11472947895526886, acc=0.9398333430290222, loss=0.11472947895526886
test: epoch 51, loss 0.12407147139310837, acc=0.9416666626930237, loss=0.12407147139310837
train: epoch 52, loss 0.1499265879392624, acc=0.9313889145851135, loss=0.1499265879392624
test: epoch 52, loss 0.10628202557563782, acc=0.9472222328186035, loss=0.10628202557563782
train: epoch 53, loss 0.11856545507907867, acc=0.9437777996063232, loss=0.11856545507907867
test: epoch 53, loss 0.10163524746894836, acc=0.9472222328186035, loss=0.10163524746894836
train: epoch 54, loss 0.134257972240448, acc=0.9421111345291138, loss=0.134257972240448
test: epoch 54, loss 0.12611635029315948, acc=0.9444444179534912, loss=0.12611635029315948
train: epoch 55, loss 0.17938677966594696, acc=0.9287222027778625, loss=0.17938677966594696
test: epoch 55, loss 0.09718866646289825, acc=0.9472222328186035, loss=0.09718866646289825
train: epoch 56, loss 0.1389244943857193, acc=0.934499979019165, loss=0.1389244943857193
test: epoch 56, loss 0.11824366450309753, acc=0.9416666626930237, loss=0.11824366450309753
train: epoch 57, loss 0.11659693717956543, acc=0.9356111288070679, loss=0.11659693717956543
test: epoch 57, loss 0.10272479057312012, acc=0.9472222328186035, loss=0.10272479057312012
train: epoch 58, loss 0.17520944774150848, acc=0.9212777614593506, loss=0.17520944774150848
test: epoch 58, loss 0.11858700960874557, acc=0.9388889074325562, loss=0.11858700960874557
train: epoch 59, loss 0.13081026077270508, acc=0.9313333630561829, loss=0.13081026077270508
test: epoch 59, loss 0.11840204894542694, acc=0.9388889074325562, loss=0.11840204894542694
train: epoch 60, loss 0.12248831987380981, acc=0.9315555691719055, loss=0.12248831987380981
test: epoch 60, loss 0.1964035928249359, acc=0.9277777671813965, loss=0.1964035928249359
train: epoch 61, loss 0.17782779037952423, acc=0.925000011920929, loss=0.17782779037952423
test: epoch 61, loss 0.13144096732139587, acc=0.9388889074325562, loss=0.13144096732139587
train: epoch 62, loss 0.13307715952396393, acc=0.9312777519226074, loss=0.13307715952396393
test: epoch 62, loss 0.1311749666929245, acc=0.9388889074325562, loss=0.1311749666929245
train: epoch 63, loss 0.20469442009925842, acc=0.9185555577278137, loss=0.20469442009925842
test: epoch 63, loss 0.24212846159934998, acc=0.9138888716697693, loss=0.24212846159934998
train: epoch 64, loss 0.2193215787410736, acc=0.9206110835075378, loss=0.2193215787410736
test: epoch 64, loss 0.182608500123024, acc=0.925000011920929, loss=0.182608500123024
train: epoch 65, loss 0.19432677328586578, acc=0.9213333129882812, loss=0.19432677328586578
test: epoch 65, loss 0.342204213142395, acc=0.9055555462837219, loss=0.342204213142395
train: epoch 66, loss 0.18421876430511475, acc=0.926277756690979, loss=0.18421876430511475
test: epoch 66, loss 0.12388456612825394, acc=0.9416666626930237, loss=0.12388456612825394
train: epoch 67, loss 0.11791841685771942, acc=0.9364444613456726, loss=0.11791841685771942
test: epoch 67, loss 0.11332418769598007, acc=0.9444444179534912, loss=0.11332418769598007
train: epoch 68, loss 0.11402363330125809, acc=0.9360555410385132, loss=0.11402363330125809
test: epoch 68, loss 0.11325062066316605, acc=0.9444444179534912, loss=0.11325062066316605
train: epoch 69, loss 0.113880954682827, acc=0.9361110925674438, loss=0.113880954682827
test: epoch 69, loss 0.11323041468858719, acc=0.9444444179534912, loss=0.11323041468858719
train: epoch 70, loss 0.11384130269289017, acc=0.9365555644035339, loss=0.11384130269289017
test: epoch 70, loss 0.1132160946726799, acc=0.9444444179534912, loss=0.1132160946726799
train: epoch 71, loss 0.22996586561203003, acc=0.9126666784286499, loss=0.22996586561203003
test: epoch 71, loss 0.4130083918571472, acc=0.8527777791023254, loss=0.4130083918571472
train: epoch 72, loss 0.20916147530078888, acc=0.9073888659477234, loss=0.20916147530078888
test: epoch 72, loss 0.15728330612182617, acc=0.9305555820465088, loss=0.15728330612182617
train: epoch 73, loss 0.24428747594356537, acc=0.9041666388511658, loss=0.24428747594356537
test: epoch 73, loss 0.26913100481033325, acc=0.894444465637207, loss=0.26913100481033325
train: epoch 74, loss 0.2057468146085739, acc=0.9158889055252075, loss=0.2057468146085739
test: epoch 74, loss 0.16172222793102264, acc=0.9305555820465088, loss=0.16172222793102264
train: epoch 75, loss 0.20029430091381073, acc=0.9197777509689331, loss=0.20029430091381073
test: epoch 75, loss 0.2834424376487732, acc=0.8972222208976746, loss=0.2834424376487732
train: epoch 76, loss 0.2629770040512085, acc=0.9077777862548828, loss=0.2629770040512085
test: epoch 76, loss 0.20508389174938202, acc=0.9222221970558167, loss=0.20508389174938202
train: epoch 77, loss 0.19511549174785614, acc=0.9164444208145142, loss=0.19511549174785614
test: epoch 77, loss 0.180588960647583, acc=0.9222221970558167, loss=0.180588960647583
train: epoch 78, loss 0.18007385730743408, acc=0.9159444570541382, loss=0.18007385730743408
test: epoch 78, loss 0.1710512638092041, acc=0.925000011920929, loss=0.1710512638092041
train: epoch 79, loss 0.1736924648284912, acc=0.92166668176651, loss=0.1736924648284912
test: epoch 79, loss 0.17089711129665375, acc=0.925000011920929, loss=0.17089711129665375
train: epoch 80, loss 0.1734892725944519, acc=0.9176666736602783, loss=0.1734892725944519
test: epoch 80, loss 0.1707763969898224, acc=0.925000011920929, loss=0.1707763969898224
train: epoch 81, loss 0.17313718795776367, acc=0.918833315372467, loss=0.17313718795776367
test: epoch 81, loss 0.17075681686401367, acc=0.925000011920929, loss=0.17075681686401367
train: epoch 82, loss 0.395392507314682, acc=0.8577777743339539, loss=0.395392507314682
test: epoch 82, loss 0.3538825213909149, acc=0.8444444537162781, loss=0.3538825213909149
train: epoch 83, loss 0.3143197000026703, acc=0.8700555562973022, loss=0.3143197000026703
test: epoch 83, loss 0.2560441493988037, acc=0.8861111402511597, loss=0.2560441493988037
train: epoch 84, loss 0.23780640959739685, acc=0.9038333296775818, loss=0.23780640959739685
test: epoch 84, loss 0.23180784285068512, acc=0.9194444417953491, loss=0.23180784285068512
train: epoch 85, loss 0.23431025445461273, acc=0.9078333377838135, loss=0.23431025445461273
test: epoch 85, loss 0.18640844523906708, acc=0.9194444417953491, loss=0.18640844523906708
train: epoch 86, loss 0.1965656727552414, acc=0.917555570602417, loss=0.1965656727552414
test: epoch 86, loss 0.1790650486946106, acc=0.9222221970558167, loss=0.1790650486946106
train: epoch 87, loss 0.19422556459903717, acc=0.9193333387374878, loss=0.19422556459903717
test: epoch 87, loss 0.17670607566833496, acc=0.9222221970558167, loss=0.17670607566833496
train: epoch 88, loss 0.17724470794200897, acc=0.9222221970558167, loss=0.17724470794200897
test: epoch 88, loss 0.17459264397621155, acc=0.9222221970558167, loss=0.17459264397621155
train: epoch 89, loss 0.22328266501426697, acc=0.9152777791023254, loss=0.22328266501426697
test: epoch 89, loss 0.2117162048816681, acc=0.9166666865348816, loss=0.2117162048816681
train: epoch 90, loss 0.20327630639076233, acc=0.9161666631698608, loss=0.20327630639076233
test: epoch 90, loss 0.19984717667102814, acc=0.9166666865348816, loss=0.19984717667102814
train: epoch 91, loss 0.19192147254943848, acc=0.9194999933242798, loss=0.19192147254943848
test: epoch 91, loss 0.17931310832500458, acc=0.9222221970558167, loss=0.17931310832500458
train: epoch 92, loss 0.1812599003314972, acc=0.9218888878822327, loss=0.1812599003314972
test: epoch 92, loss 0.17906388640403748, acc=0.9222221970558167, loss=0.17906388640403748
train: epoch 93, loss 0.44264650344848633, acc=0.851722240447998, loss=0.44264650344848633
test: epoch 93, loss 0.3783341348171234, acc=0.8472222089767456, loss=0.3783341348171234
train: epoch 94, loss 0.3079555034637451, acc=0.8739444613456726, loss=0.3079555034637451
test: epoch 94, loss 0.27056652307510376, acc=0.8833333253860474, loss=0.27056652307510376
train: epoch 95, loss 0.287676602602005, acc=0.8828333616256714, loss=0.287676602602005
test: epoch 95, loss 0.22761425375938416, acc=0.9055555462837219, loss=0.22761425375938416
train: epoch 96, loss 0.24083459377288818, acc=0.8943333625793457, loss=0.24083459377288818
test: epoch 96, loss 0.49319231510162354, acc=0.8777777552604675, loss=0.49319231510162354
train: epoch 97, loss 0.28112682700157166, acc=0.878166675567627, loss=0.28112682700157166
test: epoch 97, loss 0.2478482872247696, acc=0.8805555701255798, loss=0.2478482872247696
train: epoch 98, loss 0.2489403486251831, acc=0.8809999823570251, loss=0.2489403486251831
test: epoch 98, loss 0.24156172573566437, acc=0.8833333253860474, loss=0.24156172573566437
train: epoch 99, loss 0.24003690481185913, acc=0.8854444622993469, loss=0.24003690481185913
test: epoch 99, loss 0.23623616993427277, acc=0.8861111402511597, loss=0.23623616993427277
train: epoch 100, loss 0.233319953083992, acc=0.8875555396080017, loss=0.233319953083992
test: epoch 100, loss 0.22668780386447906, acc=0.8888888955116272, loss=0.22668780386447906
train: epoch 101, loss 0.22722959518432617, acc=0.890500009059906, loss=0.22722959518432617
test: epoch 101, loss 0.22446760535240173, acc=0.8916666507720947, loss=0.22446760535240173
train: epoch 102, loss 0.24872490763664246, acc=0.8888888955116272, loss=0.24872490763664246
test: epoch 102, loss 0.40741583704948425, acc=0.8527777791023254, loss=0.40741583704948425
train: epoch 103, loss 0.3919520378112793, acc=0.8483889102935791, loss=0.3919520378112793
test: epoch 103, loss 0.3538922071456909, acc=0.8472222089767456, loss=0.3538922071456909
train: epoch 104, loss 0.29923883080482483, acc=0.8651111125946045, loss=0.29923883080482483
test: epoch 104, loss 0.27342161536216736, acc=0.8777777552604675, loss=0.27342161536216736
train: epoch 105, loss 0.332749605178833, acc=0.8640000224113464, loss=0.332749605178833
test: epoch 105, loss 0.48306623101234436, acc=0.8361111283302307, loss=0.48306623101234436
train: epoch 106, loss 0.4230708181858063, acc=0.8448888659477234, loss=0.4230708181858063
test: epoch 106, loss 0.3298031687736511, acc=0.8666666746139526, loss=0.3298031687736511
train: epoch 107, loss 0.3966578543186188, acc=0.8531110882759094, loss=0.3966578543186188
test: epoch 107, loss 0.298278272151947, acc=0.8805555701255798, loss=0.298278272151947
train: epoch 108, loss 0.2880714237689972, acc=0.8784444332122803, loss=0.2880714237689972
test: epoch 108, loss 0.2798585593700409, acc=0.8833333253860474, loss=0.2798585593700409
train: epoch 109, loss 0.2826453447341919, acc=0.8823888897895813, loss=0.2826453447341919
test: epoch 109, loss 0.2793668210506439, acc=0.8833333253860474, loss=0.2793668210506439
train: epoch 110, loss 0.28225037455558777, acc=0.8799444437026978, loss=0.28225037455558777
test: epoch 110, loss 0.2791953384876251, acc=0.8833333253860474, loss=0.2791953384876251
train: epoch 111, loss 0.2829711437225342, acc=0.8788333535194397, loss=0.2829711437225342
test: epoch 111, loss 0.2755679190158844, acc=0.8861111402511597, loss=0.2755679190158844
train: epoch 112, loss 0.2580156624317169, acc=0.8927222490310669, loss=0.2580156624317169
test: epoch 112, loss 0.2519584894180298, acc=0.8999999761581421, loss=0.2519584894180298
train: epoch 113, loss 0.39309975504875183, acc=0.8686666488647461, loss=0.39309975504875183
test: epoch 113, loss 0.3145189881324768, acc=0.8805555701255798, loss=0.3145189881324768
train: epoch 114, loss 0.2711315453052521, acc=0.8911666870117188, loss=0.2711315453052521
test: epoch 114, loss 0.26094141602516174, acc=0.8972222208976746, loss=0.26094141602516174
train: epoch 115, loss 0.22229968011379242, acc=0.9041110873222351, loss=0.22229968011379242
test: epoch 115, loss 0.2143961638212204, acc=0.9055555462837219, loss=0.2143961638212204
train: epoch 116, loss 0.2165178507566452, acc=0.8975555300712585, loss=0.2165178507566452
test: epoch 116, loss 0.2140558511018753, acc=0.9055555462837219, loss=0.2140558511018753
train: epoch 117, loss 0.2163034826517105, acc=0.9002777934074402, loss=0.2163034826517105
test: epoch 117, loss 0.2140047699213028, acc=0.9055555462837219, loss=0.2140047699213028
train: epoch 118, loss 0.3803722858428955, acc=0.863444447517395, loss=0.3803722858428955
test: epoch 118, loss 0.37432175874710083, acc=0.8500000238418579, loss=0.37432175874710083
train: epoch 119, loss 0.31158021092414856, acc=0.8709444403648376, loss=0.31158021092414856
test: epoch 119, loss 0.2691788971424103, acc=0.8999999761581421, loss=0.2691788971424103
train: epoch 120, loss 0.2317320704460144, acc=0.9003888964653015, loss=0.2317320704460144
test: epoch 120, loss 0.22719059884548187, acc=0.8999999761581421, loss=0.22719059884548187
train: epoch 121, loss 0.2864810526371002, acc=0.8824999928474426, loss=0.2864810526371002
test: epoch 121, loss 0.27693256735801697, acc=0.8833333253860474, loss=0.27693256735801697
train: epoch 122, loss 0.2779233455657959, acc=0.8802222013473511, loss=0.2779233455657959
test: epoch 122, loss 0.273371160030365, acc=0.8833333253860474, loss=0.273371160030365
train: epoch 123, loss 0.2760581076145172, acc=0.8828333616256714, loss=0.2760581076145172
test: epoch 123, loss 0.2731814682483673, acc=0.8833333253860474, loss=0.2731814682483673
train: epoch 124, loss 0.3520435690879822, acc=0.8813889026641846, loss=0.3520435690879822
test: epoch 124, loss 0.2676463723182678, acc=0.8972222208976746, loss=0.2676463723182678
train: epoch 125, loss 0.26517918705940247, acc=0.8929444551467896, loss=0.26517918705940247
test: epoch 125, loss 0.2601962685585022, acc=0.8999999761581421, loss=0.2601962685585022
train: epoch 126, loss 0.2554584741592407, acc=0.9026666879653931, loss=0.2554584741592407
test: epoch 126, loss 0.24795395135879517, acc=0.9027777910232544, loss=0.24795395135879517
train: epoch 127, loss 0.23057833313941956, acc=0.9051666855812073, loss=0.23057833313941956
test: epoch 127, loss 0.2159409075975418, acc=0.9111111164093018, loss=0.2159409075975418
train: epoch 128, loss 0.21909886598587036, acc=0.902999997138977, loss=0.21909886598587036
test: epoch 128, loss 0.21560998260974884, acc=0.9111111164093018, loss=0.21560998260974884
train: epoch 129, loss 0.21931511163711548, acc=0.9037222266197205, loss=0.21931511163711548
test: epoch 129, loss 0.2155081331729889, acc=0.9111111164093018, loss=0.2155081331729889
train: epoch 130, loss 0.21819546818733215, acc=0.9036111235618591, loss=0.21819546818733215
test: epoch 130, loss 0.2159418761730194, acc=0.9111111164093018, loss=0.2159418761730194
train: epoch 131, loss 0.2181861251592636, acc=0.902999997138977, loss=0.2181861251592636
test: epoch 131, loss 0.21542693674564362, acc=0.9111111164093018, loss=0.21542693674564362
train: epoch 132, loss 0.21882294118404388, acc=0.9025555849075317, loss=0.21882294118404388
test: epoch 132, loss 0.21545207500457764, acc=0.9111111164093018, loss=0.21545207500457764
train: epoch 133, loss 0.2154417335987091, acc=0.9037777781486511, loss=0.2154417335987091
test: epoch 133, loss 0.20478999614715576, acc=0.9138888716697693, loss=0.20478999614715576
train: epoch 134, loss 0.20719479024410248, acc=0.9056110978126526, loss=0.20719479024410248
test: epoch 134, loss 0.20452740788459778, acc=0.9138888716697693, loss=0.20452740788459778
train: epoch 135, loss 0.20701582729816437, acc=0.9055555462837219, loss=0.20701582729816437
test: epoch 135, loss 0.2045169472694397, acc=0.9138888716697693, loss=0.2045169472694397
train: epoch 136, loss 0.2070336490869522, acc=0.910444438457489, loss=0.2070336490869522
test: epoch 136, loss 0.2044878900051117, acc=0.9138888716697693, loss=0.2044878900051117
train: epoch 137, loss 0.20682711899280548, acc=0.9079444408416748, loss=0.20682711899280548
test: epoch 137, loss 0.20448125898838043, acc=0.9138888716697693, loss=0.20448125898838043
train: epoch 138, loss 0.20675136148929596, acc=0.9068889021873474, loss=0.20675136148929596
test: epoch 138, loss 0.2044733166694641, acc=0.9138888716697693, loss=0.2044733166694641
train: epoch 139, loss 0.20674923062324524, acc=0.9059444665908813, loss=0.20674923062324524
test: epoch 139, loss 0.20446616411209106, acc=0.9138888716697693, loss=0.20446616411209106
train: epoch 140, loss 0.20680634677410126, acc=0.906000018119812, loss=0.20680634677410126
test: epoch 140, loss 0.20447590947151184, acc=0.9138888716697693, loss=0.20447590947151184
train: epoch 141, loss 0.20132623612880707, acc=0.9098888635635376, loss=0.20132623612880707
test: epoch 141, loss 0.19475287199020386, acc=0.9166666865348816, loss=0.19475287199020386
train: epoch 142, loss 0.19683784246444702, acc=0.9083333611488342, loss=0.19683784246444702
test: epoch 142, loss 0.19468723237514496, acc=0.9166666865348816, loss=0.19468723237514496
train: epoch 143, loss 0.19681839644908905, acc=0.9113888740539551, loss=0.19681839644908905
test: epoch 143, loss 0.1947067677974701, acc=0.9166666865348816, loss=0.1947067677974701
train: epoch 144, loss 0.1973554939031601, acc=0.9110555648803711, loss=0.1973554939031601
test: epoch 144, loss 0.19466829299926758, acc=0.9166666865348816, loss=0.19466829299926758
train: epoch 145, loss 0.1980816125869751, acc=0.9102222323417664, loss=0.1980816125869751
test: epoch 145, loss 0.6677746176719666, acc=0.8999999761581421, loss=0.6677746176719666
train: epoch 146, loss 0.20273004472255707, acc=0.9160000085830688, loss=0.20273004472255707
test: epoch 146, loss 0.19466054439544678, acc=0.9166666865348816, loss=0.19466054439544678
train: epoch 147, loss 0.19655025005340576, acc=0.9165555834770203, loss=0.19655025005340576
test: epoch 147, loss 0.19465123116970062, acc=0.9166666865348816, loss=0.19465123116970062
train: epoch 148, loss 0.5984872579574585, acc=0.8431110978126526, loss=0.5984872579574585
test: epoch 148, loss 0.5602648258209229, acc=0.8055555820465088, loss=0.5602648258209229
train: epoch 149, loss 0.460692435503006, acc=0.8259999752044678, loss=0.460692435503006
test: epoch 149, loss 0.3942319452762604, acc=0.8388888835906982, loss=0.3942319452762604
train: epoch 150, loss 0.3850768208503723, acc=0.8413888812065125, loss=0.3850768208503723
test: epoch 150, loss 0.36066877841949463, acc=0.8500000238418579, loss=0.36066877841949463
