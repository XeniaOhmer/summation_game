# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=1", "--temp_decay=0.995", "--one_hot=false", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=925343643, receiver_embed_dim=128, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.9496562480926514, acc=0.07411111146211624, loss=2.9496562480926514
test: epoch 1, loss 2.4701740741729736, acc=0.13333334028720856, loss=2.4701740741729736
train: epoch 2, loss 2.1250760555267334, acc=0.1756666600704193, loss=2.1250760555267334
test: epoch 2, loss 2.009845495223999, acc=0.2083333283662796, loss=2.009845495223999
train: epoch 3, loss 1.7818713188171387, acc=0.2575555443763733, loss=1.7818713188171387
test: epoch 3, loss 1.8047394752502441, acc=0.2611111104488373, loss=1.8047394752502441
train: epoch 4, loss 1.628981590270996, acc=0.27944445610046387, loss=1.628981590270996
test: epoch 4, loss 1.838531255722046, acc=0.23888888955116272, loss=1.838531255722046
train: epoch 5, loss 1.5221126079559326, acc=0.3165000081062317, loss=1.5221126079559326
test: epoch 5, loss 1.7502186298370361, acc=0.26944443583488464, loss=1.7502186298370361
train: epoch 6, loss 1.4740557670593262, acc=0.32722222805023193, loss=1.4740557670593262
test: epoch 6, loss 2.0345523357391357, acc=0.26944443583488464, loss=2.0345523357391357
train: epoch 7, loss 1.4478085041046143, acc=0.3377777636051178, loss=1.4478085041046143
test: epoch 7, loss 1.70718252658844, acc=0.2611111104488373, loss=1.70718252658844
train: epoch 8, loss 1.3781962394714355, acc=0.3535555601119995, loss=1.3781962394714355
test: epoch 8, loss 1.7188917398452759, acc=0.26944443583488464, loss=1.7188917398452759
train: epoch 9, loss 1.3683122396469116, acc=0.35216665267944336, loss=1.3683122396469116
test: epoch 9, loss 1.775459885597229, acc=0.2777777910232544, loss=1.775459885597229
train: epoch 10, loss 1.3084524869918823, acc=0.3774999976158142, loss=1.3084524869918823
test: epoch 10, loss 1.8340396881103516, acc=0.2805555462837219, loss=1.8340396881103516
train: epoch 11, loss 1.2951221466064453, acc=0.38877779245376587, loss=1.2951221466064453
test: epoch 11, loss 1.8455075025558472, acc=0.2777777910232544, loss=1.8455075025558472
train: epoch 12, loss 1.2909414768218994, acc=0.40016666054725647, loss=1.2909414768218994
test: epoch 12, loss 1.7405378818511963, acc=0.2777777910232544, loss=1.7405378818511963
train: epoch 13, loss 1.239737629890442, acc=0.4151666760444641, loss=1.239737629890442
test: epoch 13, loss 1.8681752681732178, acc=0.30000001192092896, loss=1.8681752681732178
train: epoch 14, loss 1.2453689575195312, acc=0.40755555033683777, loss=1.2453689575195312
test: epoch 14, loss 1.8762263059616089, acc=0.2944444417953491, loss=1.8762263059616089
train: epoch 15, loss 1.2263637781143188, acc=0.41616666316986084, loss=1.2263637781143188
test: epoch 15, loss 1.791879653930664, acc=0.30000001192092896, loss=1.791879653930664
train: epoch 16, loss 1.2104092836380005, acc=0.42161110043525696, loss=1.2104092836380005
test: epoch 16, loss 1.9381102323532104, acc=0.30000001192092896, loss=1.9381102323532104
train: epoch 17, loss 1.2390620708465576, acc=0.4107777774333954, loss=1.2390620708465576
test: epoch 17, loss 1.8079540729522705, acc=0.29722222685813904, loss=1.8079540729522705
train: epoch 18, loss 1.1924279928207397, acc=0.42133334279060364, loss=1.1924279928207397
test: epoch 18, loss 1.7936222553253174, acc=0.30000001192092896, loss=1.7936222553253174
train: epoch 19, loss 1.199514627456665, acc=0.43433332443237305, loss=1.199514627456665
test: epoch 19, loss 1.8650848865509033, acc=0.30000001192092896, loss=1.8650848865509033
train: epoch 20, loss 1.1704353094100952, acc=0.4400555491447449, loss=1.1704353094100952
test: epoch 20, loss 1.7000294923782349, acc=0.30000001192092896, loss=1.7000294923782349
train: epoch 21, loss 1.1814416646957397, acc=0.44350001215934753, loss=1.1814416646957397
test: epoch 21, loss 1.8136647939682007, acc=0.3166666626930237, loss=1.8136647939682007
train: epoch 22, loss 1.141282320022583, acc=0.47566667199134827, loss=1.141282320022583
test: epoch 22, loss 1.887601375579834, acc=0.3222222328186035, loss=1.887601375579834
train: epoch 23, loss 1.0989985466003418, acc=0.4811111092567444, loss=1.0989985466003418
test: epoch 23, loss 1.8894877433776855, acc=0.3222222328186035, loss=1.8894877433776855
train: epoch 24, loss 1.1429499387741089, acc=0.4645000100135803, loss=1.1429499387741089
test: epoch 24, loss 1.9015191793441772, acc=0.3166666626930237, loss=1.9015191793441772
train: epoch 25, loss 1.0808968544006348, acc=0.4863888919353485, loss=1.0808968544006348
test: epoch 25, loss 1.859191656112671, acc=0.3194444477558136, loss=1.859191656112671
train: epoch 26, loss 1.081217885017395, acc=0.484499990940094, loss=1.081217885017395
test: epoch 26, loss 1.9101521968841553, acc=0.31111112236976624, loss=1.9101521968841553
train: epoch 27, loss 1.090187907218933, acc=0.49900001287460327, loss=1.090187907218933
test: epoch 27, loss 1.96142578125, acc=0.32777777314186096, loss=1.96142578125
train: epoch 28, loss 1.124531865119934, acc=0.4901111125946045, loss=1.124531865119934
test: epoch 28, loss 1.9509799480438232, acc=0.32777777314186096, loss=1.9509799480438232
train: epoch 29, loss 1.0436500310897827, acc=0.5024999976158142, loss=1.0436500310897827
test: epoch 29, loss 2.0311553478240967, acc=0.3305555582046509, loss=2.0311553478240967
train: epoch 30, loss 1.0354626178741455, acc=0.5024444460868835, loss=1.0354626178741455
test: epoch 30, loss 1.7757651805877686, acc=0.3305555582046509, loss=1.7757651805877686
train: epoch 31, loss 1.0491764545440674, acc=0.5040000081062317, loss=1.0491764545440674
test: epoch 31, loss 1.8887284994125366, acc=0.3361110985279083, loss=1.8887284994125366
train: epoch 32, loss 1.0631946325302124, acc=0.5024999976158142, loss=1.0631946325302124
test: epoch 32, loss 1.603462815284729, acc=0.3638888895511627, loss=1.603462815284729
train: epoch 33, loss 1.0058008432388306, acc=0.5233333110809326, loss=1.0058008432388306
test: epoch 33, loss 1.8364404439926147, acc=0.36666667461395264, loss=1.8364404439926147
train: epoch 34, loss 0.9768799543380737, acc=0.5569999814033508, loss=0.9768799543380737
test: epoch 34, loss 1.7567542791366577, acc=0.39444443583488464, loss=1.7567542791366577
train: epoch 35, loss 0.8850510120391846, acc=0.5770000219345093, loss=0.8850510120391846
test: epoch 35, loss 1.8703263998031616, acc=0.4000000059604645, loss=1.8703263998031616
train: epoch 36, loss 0.9133445024490356, acc=0.5715555548667908, loss=0.9133445024490356
test: epoch 36, loss 1.7042568922042847, acc=0.39444443583488464, loss=1.7042568922042847
train: epoch 37, loss 0.9209955930709839, acc=0.5672777891159058, loss=0.9209955930709839
test: epoch 37, loss 1.6774705648422241, acc=0.39722222089767456, loss=1.6774705648422241
train: epoch 38, loss 0.8870843052864075, acc=0.5736111402511597, loss=0.8870843052864075
test: epoch 38, loss 1.65367591381073, acc=0.4000000059604645, loss=1.65367591381073
train: epoch 39, loss 0.8964868783950806, acc=0.5769444704055786, loss=0.8964868783950806
test: epoch 39, loss 1.7510663270950317, acc=0.4027777910232544, loss=1.7510663270950317
train: epoch 40, loss 0.8745104074478149, acc=0.5822222232818604, loss=0.8745104074478149
test: epoch 40, loss 1.7884628772735596, acc=0.4027777910232544, loss=1.7884628772735596
train: epoch 41, loss 0.8926756978034973, acc=0.5768333077430725, loss=0.8926756978034973
test: epoch 41, loss 1.66785728931427, acc=0.4027777910232544, loss=1.66785728931427
train: epoch 42, loss 0.906471312046051, acc=0.57105553150177, loss=0.906471312046051
test: epoch 42, loss 1.6365593671798706, acc=0.39722222089767456, loss=1.6365593671798706
train: epoch 43, loss 0.9122164249420166, acc=0.5727777481079102, loss=0.9122164249420166
test: epoch 43, loss 1.676561713218689, acc=0.375, loss=1.676561713218689
train: epoch 44, loss 0.9143213033676147, acc=0.574999988079071, loss=0.9143213033676147
test: epoch 44, loss 1.8954482078552246, acc=0.3583333194255829, loss=1.8954482078552246
train: epoch 45, loss 1.0041197538375854, acc=0.5609444379806519, loss=1.0041197538375854
test: epoch 45, loss 1.4524482488632202, acc=0.4305555522441864, loss=1.4524482488632202
train: epoch 46, loss 0.838093101978302, acc=0.5886666774749756, loss=0.838093101978302
test: epoch 46, loss 1.439988374710083, acc=0.4305555522441864, loss=1.439988374710083
train: epoch 47, loss 0.8479249477386475, acc=0.5918889045715332, loss=0.8479249477386475
test: epoch 47, loss 1.4997584819793701, acc=0.4305555522441864, loss=1.4997584819793701
train: epoch 48, loss 0.8140649199485779, acc=0.6111666560173035, loss=0.8140649199485779
test: epoch 48, loss 1.5245968103408813, acc=0.4583333432674408, loss=1.5245968103408813
train: epoch 49, loss 0.8160644173622131, acc=0.6175000071525574, loss=0.8160644173622131
test: epoch 49, loss 1.3897165060043335, acc=0.4833333194255829, loss=1.3897165060043335
train: epoch 50, loss 0.7985787987709045, acc=0.6090555787086487, loss=0.7985787987709045
test: epoch 50, loss 1.3220202922821045, acc=0.5, loss=1.3220202922821045
train: epoch 51, loss 0.7741029262542725, acc=0.6180555820465088, loss=0.7741029262542725
test: epoch 51, loss 1.2234987020492554, acc=0.5138888955116272, loss=1.2234987020492554
train: epoch 52, loss 0.8587159514427185, acc=0.6097221970558167, loss=0.8587159514427185
test: epoch 52, loss 1.2307641506195068, acc=0.5083333253860474, loss=1.2307641506195068
train: epoch 53, loss 0.8119392991065979, acc=0.6177777647972107, loss=0.8119392991065979
test: epoch 53, loss 1.216017246246338, acc=0.5083333253860474, loss=1.216017246246338
train: epoch 54, loss 0.8063251376152039, acc=0.6165555715560913, loss=0.8063251376152039
test: epoch 54, loss 1.2391963005065918, acc=0.5083333253860474, loss=1.2391963005065918
train: epoch 55, loss 0.8370781540870667, acc=0.6148333549499512, loss=0.8370781540870667
test: epoch 55, loss 1.314913034439087, acc=0.5138888955116272, loss=1.314913034439087
train: epoch 56, loss 0.8318561315536499, acc=0.616611123085022, loss=0.8318561315536499
test: epoch 56, loss 1.0427967309951782, acc=0.5444444417953491, loss=1.0427967309951782
train: epoch 57, loss 0.7754665613174438, acc=0.633055567741394, loss=0.7754665613174438
test: epoch 57, loss 1.1037379503250122, acc=0.5444444417953491, loss=1.1037379503250122
train: epoch 58, loss 0.7800650000572205, acc=0.6328333616256714, loss=0.7800650000572205
test: epoch 58, loss 1.138469934463501, acc=0.5472221970558167, loss=1.138469934463501
train: epoch 59, loss 0.7592567205429077, acc=0.6390555500984192, loss=0.7592567205429077
test: epoch 59, loss 1.1188256740570068, acc=0.550000011920929, loss=1.1188256740570068
train: epoch 60, loss 0.7808950543403625, acc=0.6364444494247437, loss=0.7808950543403625
test: epoch 60, loss 1.0596517324447632, acc=0.550000011920929, loss=1.0596517324447632
train: epoch 61, loss 0.7718466520309448, acc=0.6342222094535828, loss=0.7718466520309448
test: epoch 61, loss 1.0966194868087769, acc=0.5472221970558167, loss=1.0966194868087769
train: epoch 62, loss 0.7472837567329407, acc=0.640500009059906, loss=0.7472837567329407
test: epoch 62, loss 1.0960502624511719, acc=0.5472221970558167, loss=1.0960502624511719
train: epoch 63, loss 0.7506791949272156, acc=0.6399999856948853, loss=0.7506791949272156
test: epoch 63, loss 1.110387921333313, acc=0.550000011920929, loss=1.110387921333313
train: epoch 64, loss 0.7787851691246033, acc=0.6379444599151611, loss=0.7787851691246033
test: epoch 64, loss 1.0414091348648071, acc=0.550000011920929, loss=1.0414091348648071
train: epoch 65, loss 0.7960430979728699, acc=0.6333333253860474, loss=0.7960430979728699
test: epoch 65, loss 1.1422957181930542, acc=0.5416666865348816, loss=1.1422957181930542
train: epoch 66, loss 0.8118195533752441, acc=0.6325555443763733, loss=0.8118195533752441
test: epoch 66, loss 1.1434648036956787, acc=0.5444444417953491, loss=1.1434648036956787
train: epoch 67, loss 0.781547486782074, acc=0.6316666603088379, loss=0.781547486782074
test: epoch 67, loss 1.2217203378677368, acc=0.5416666865348816, loss=1.2217203378677368
train: epoch 68, loss 0.7647910714149475, acc=0.632611095905304, loss=0.7647910714149475
test: epoch 68, loss 1.1151870489120483, acc=0.5388888716697693, loss=1.1151870489120483
train: epoch 69, loss 0.7762126922607422, acc=0.6333333253860474, loss=0.7762126922607422
test: epoch 69, loss 1.1147788763046265, acc=0.5361111164093018, loss=1.1147788763046265
train: epoch 70, loss 0.8126540184020996, acc=0.628166675567627, loss=0.8126540184020996
test: epoch 70, loss 1.0923980474472046, acc=0.5416666865348816, loss=1.0923980474472046
train: epoch 71, loss 0.7628276348114014, acc=0.6362777948379517, loss=0.7628276348114014
test: epoch 71, loss 1.0630484819412231, acc=0.5277777910232544, loss=1.0630484819412231
train: epoch 72, loss 0.7520405650138855, acc=0.6363333463668823, loss=0.7520405650138855
test: epoch 72, loss 1.089499592781067, acc=0.5416666865348816, loss=1.089499592781067
train: epoch 73, loss 0.7941697835922241, acc=0.6346666812896729, loss=0.7941697835922241
test: epoch 73, loss 1.1504210233688354, acc=0.5444444417953491, loss=1.1504210233688354
train: epoch 74, loss 0.8557817935943604, acc=0.6086111068725586, loss=0.8557817935943604
test: epoch 74, loss 1.0218385457992554, acc=0.5388888716697693, loss=1.0218385457992554
train: epoch 75, loss 0.7989765405654907, acc=0.613277792930603, loss=0.7989765405654907
test: epoch 75, loss 1.0073444843292236, acc=0.5555555820465088, loss=1.0073444843292236
train: epoch 76, loss 0.8136366009712219, acc=0.6151666641235352, loss=0.8136366009712219
test: epoch 76, loss 0.9601094126701355, acc=0.5805555582046509, loss=0.9601094126701355
train: epoch 77, loss 0.8025587797164917, acc=0.6232777833938599, loss=0.8025587797164917
test: epoch 77, loss 0.958250105381012, acc=0.5555555820465088, loss=0.958250105381012
train: epoch 78, loss 0.7745859026908875, acc=0.621055543422699, loss=0.7745859026908875
test: epoch 78, loss 0.8629071116447449, acc=0.5805555582046509, loss=0.8629071116447449
train: epoch 79, loss 0.7935223579406738, acc=0.6187777519226074, loss=0.7935223579406738
test: epoch 79, loss 0.8756759762763977, acc=0.5972222089767456, loss=0.8756759762763977
train: epoch 80, loss 0.804650604724884, acc=0.6258888840675354, loss=0.804650604724884
test: epoch 80, loss 0.8642623424530029, acc=0.5916666388511658, loss=0.8642623424530029
train: epoch 81, loss 0.7922909259796143, acc=0.6279444694519043, loss=0.7922909259796143
test: epoch 81, loss 0.8723729848861694, acc=0.6000000238418579, loss=0.8723729848861694
train: epoch 82, loss 0.7723514437675476, acc=0.6336666941642761, loss=0.7723514437675476
test: epoch 82, loss 0.8583759069442749, acc=0.6000000238418579, loss=0.8583759069442749
train: epoch 83, loss 0.782863438129425, acc=0.636722207069397, loss=0.782863438129425
test: epoch 83, loss 0.8735641837120056, acc=0.6000000238418579, loss=0.8735641837120056
train: epoch 84, loss 0.7297269701957703, acc=0.636555552482605, loss=0.7297269701957703
test: epoch 84, loss 0.8121626377105713, acc=0.6083333492279053, loss=0.8121626377105713
train: epoch 85, loss 0.733542799949646, acc=0.6392222046852112, loss=0.733542799949646
test: epoch 85, loss 0.8326401114463806, acc=0.6111111044883728, loss=0.8326401114463806
train: epoch 86, loss 0.7184325456619263, acc=0.6380555629730225, loss=0.7184325456619263
test: epoch 86, loss 0.8068658709526062, acc=0.6222222447395325, loss=0.8068658709526062
train: epoch 87, loss 0.7424194812774658, acc=0.6380000114440918, loss=0.7424194812774658
test: epoch 87, loss 0.7733373045921326, acc=0.625, loss=0.7733373045921326
train: epoch 88, loss 0.8164557814598083, acc=0.6275555491447449, loss=0.8164557814598083
test: epoch 88, loss 0.8317684531211853, acc=0.625, loss=0.8317684531211853
train: epoch 89, loss 0.818906843662262, acc=0.6361666917800903, loss=0.818906843662262
test: epoch 89, loss 0.874190092086792, acc=0.6083333492279053, loss=0.874190092086792
train: epoch 90, loss 0.7880581617355347, acc=0.6403889060020447, loss=0.7880581617355347
test: epoch 90, loss 0.8709235787391663, acc=0.6138888597488403, loss=0.8709235787391663
train: epoch 91, loss 0.7821027636528015, acc=0.6396111249923706, loss=0.7821027636528015
test: epoch 91, loss 0.804122269153595, acc=0.6138888597488403, loss=0.804122269153595
train: epoch 92, loss 0.7759156823158264, acc=0.6426666378974915, loss=0.7759156823158264
test: epoch 92, loss 0.8514674305915833, acc=0.6138888597488403, loss=0.8514674305915833
train: epoch 93, loss 0.849410355091095, acc=0.6253888607025146, loss=0.849410355091095
test: epoch 93, loss 0.9831907749176025, acc=0.574999988079071, loss=0.9831907749176025
train: epoch 94, loss 0.8891675472259521, acc=0.6075000166893005, loss=0.8891675472259521
test: epoch 94, loss 0.9442777037620544, acc=0.5888888835906982, loss=0.9442777037620544
train: epoch 95, loss 0.8999069929122925, acc=0.6183333396911621, loss=0.8999069929122925
test: epoch 95, loss 0.9545373320579529, acc=0.5916666388511658, loss=0.9545373320579529
train: epoch 96, loss 0.8621551394462585, acc=0.6200555562973022, loss=0.8621551394462585
test: epoch 96, loss 0.9120144248008728, acc=0.5888888835906982, loss=0.9120144248008728
train: epoch 97, loss 0.8357089757919312, acc=0.6215000152587891, loss=0.8357089757919312
test: epoch 97, loss 0.876687228679657, acc=0.5944444537162781, loss=0.876687228679657
train: epoch 98, loss 0.8460295796394348, acc=0.6192777752876282, loss=0.8460295796394348
test: epoch 98, loss 0.9091768264770508, acc=0.5888888835906982, loss=0.9091768264770508
train: epoch 99, loss 0.8396351933479309, acc=0.620888888835907, loss=0.8396351933479309
test: epoch 99, loss 0.9052980542182922, acc=0.6000000238418579, loss=0.9052980542182922
train: epoch 100, loss 0.796826958656311, acc=0.6269999742507935, loss=0.796826958656311
test: epoch 100, loss 0.8373733162879944, acc=0.6083333492279053, loss=0.8373733162879944
train: epoch 101, loss 0.7954468727111816, acc=0.6299444437026978, loss=0.7954468727111816
test: epoch 101, loss 0.8365453481674194, acc=0.6222222447395325, loss=0.8365453481674194
train: epoch 102, loss 0.8178069591522217, acc=0.6271111369132996, loss=0.8178069591522217
test: epoch 102, loss 0.8130369782447815, acc=0.6194444298744202, loss=0.8130369782447815
train: epoch 103, loss 0.8647776246070862, acc=0.6194999814033508, loss=0.8647776246070862
test: epoch 103, loss 0.828961193561554, acc=0.6138888597488403, loss=0.828961193561554
train: epoch 104, loss 0.8360291123390198, acc=0.6207777857780457, loss=0.8360291123390198
test: epoch 104, loss 0.8687645792961121, acc=0.6111111044883728, loss=0.8687645792961121
train: epoch 105, loss 0.8286293148994446, acc=0.620722234249115, loss=0.8286293148994446
test: epoch 105, loss 0.8403486609458923, acc=0.6111111044883728, loss=0.8403486609458923
train: epoch 106, loss 0.8348526954650879, acc=0.6179444193840027, loss=0.8348526954650879
test: epoch 106, loss 0.9187300205230713, acc=0.6083333492279053, loss=0.9187300205230713
train: epoch 107, loss 0.8103655576705933, acc=0.6286666393280029, loss=0.8103655576705933
test: epoch 107, loss 0.8290840983390808, acc=0.6222222447395325, loss=0.8290840983390808
train: epoch 108, loss 0.8040612936019897, acc=0.6303889155387878, loss=0.8040612936019897
test: epoch 108, loss 0.8609556555747986, acc=0.6166666746139526, loss=0.8609556555747986
train: epoch 109, loss 0.8803401589393616, acc=0.6208333373069763, loss=0.8803401589393616
test: epoch 109, loss 0.8937006592750549, acc=0.6138888597488403, loss=0.8937006592750549
train: epoch 110, loss 0.8469201326370239, acc=0.6236110925674438, loss=0.8469201326370239
test: epoch 110, loss 0.8535587191581726, acc=0.6166666746139526, loss=0.8535587191581726
train: epoch 111, loss 0.8348397612571716, acc=0.6261110901832581, loss=0.8348397612571716
test: epoch 111, loss 0.8630386590957642, acc=0.6166666746139526, loss=0.8630386590957642
train: epoch 112, loss 0.8327252268791199, acc=0.6263889074325562, loss=0.8327252268791199
test: epoch 112, loss 0.8670768737792969, acc=0.6166666746139526, loss=0.8670768737792969
train: epoch 113, loss 0.901538074016571, acc=0.6186666488647461, loss=0.901538074016571
test: epoch 113, loss 0.9253675937652588, acc=0.6138888597488403, loss=0.9253675937652588
train: epoch 114, loss 0.8683435320854187, acc=0.6267222166061401, loss=0.8683435320854187
test: epoch 114, loss 0.8957427144050598, acc=0.6222222447395325, loss=0.8957427144050598
train: epoch 115, loss 0.8438353538513184, acc=0.6338889002799988, loss=0.8438353538513184
test: epoch 115, loss 0.8637507557868958, acc=0.625, loss=0.8637507557868958
train: epoch 116, loss 0.8501840829849243, acc=0.632888913154602, loss=0.8501840829849243
test: epoch 116, loss 0.8806788921356201, acc=0.6194444298744202, loss=0.8806788921356201
train: epoch 117, loss 0.8599353432655334, acc=0.628000020980835, loss=0.8599353432655334
test: epoch 117, loss 0.9427290558815002, acc=0.6138888597488403, loss=0.9427290558815002
train: epoch 118, loss 0.8854906558990479, acc=0.6258333325386047, loss=0.8854906558990479
test: epoch 118, loss 0.9152130484580994, acc=0.6166666746139526, loss=0.9152130484580994
train: epoch 119, loss 0.9027349352836609, acc=0.621055543422699, loss=0.9027349352836609
test: epoch 119, loss 0.9227781891822815, acc=0.6111111044883728, loss=0.9227781891822815
train: epoch 120, loss 0.9197343587875366, acc=0.6220555305480957, loss=0.9197343587875366
test: epoch 120, loss 0.9018012285232544, acc=0.6166666746139526, loss=0.9018012285232544
train: epoch 121, loss 0.8841575980186462, acc=0.6201111078262329, loss=0.8841575980186462
test: epoch 121, loss 0.9447160959243774, acc=0.6111111044883728, loss=0.9447160959243774
train: epoch 122, loss 0.8204154372215271, acc=0.6298888921737671, loss=0.8204154372215271
test: epoch 122, loss 0.8002045750617981, acc=0.6333333253860474, loss=0.8002045750617981
train: epoch 123, loss 0.8064268231391907, acc=0.632777750492096, loss=0.8064268231391907
test: epoch 123, loss 0.8169667720794678, acc=0.6277777552604675, loss=0.8169667720794678
train: epoch 124, loss 0.8005425930023193, acc=0.6330000162124634, loss=0.8005425930023193
test: epoch 124, loss 0.7954145669937134, acc=0.6333333253860474, loss=0.7954145669937134
train: epoch 125, loss 0.7998209595680237, acc=0.6332777738571167, loss=0.7998209595680237
test: epoch 125, loss 0.8003632426261902, acc=0.6333333253860474, loss=0.8003632426261902
train: epoch 126, loss 0.8049230575561523, acc=0.6314444541931152, loss=0.8049230575561523
test: epoch 126, loss 1.036439061164856, acc=0.6277777552604675, loss=1.036439061164856
train: epoch 127, loss 0.9298352599143982, acc=0.6125555634498596, loss=0.9298352599143982
test: epoch 127, loss 0.855955183506012, acc=0.6222222447395325, loss=0.855955183506012
train: epoch 128, loss 0.8512686491012573, acc=0.6184444427490234, loss=0.8512686491012573
test: epoch 128, loss 0.8845123648643494, acc=0.6083333492279053, loss=0.8845123648643494
train: epoch 129, loss 0.8522545099258423, acc=0.613277792930603, loss=0.8522545099258423
test: epoch 129, loss 0.795497477054596, acc=0.6277777552604675, loss=0.795497477054596
train: epoch 130, loss 0.8128910064697266, acc=0.6227777600288391, loss=0.8128910064697266
test: epoch 130, loss 0.8044636249542236, acc=0.625, loss=0.8044636249542236
train: epoch 131, loss 0.8097440004348755, acc=0.6212777495384216, loss=0.8097440004348755
test: epoch 131, loss 0.8008755445480347, acc=0.6277777552604675, loss=0.8008755445480347
train: epoch 132, loss 0.8028530478477478, acc=0.6205000281333923, loss=0.8028530478477478
test: epoch 132, loss 0.7971688508987427, acc=0.6277777552604675, loss=0.7971688508987427
train: epoch 133, loss 0.7951252460479736, acc=0.6216111183166504, loss=0.7951252460479736
test: epoch 133, loss 0.7881814241409302, acc=0.6305555701255798, loss=0.7881814241409302
train: epoch 134, loss 0.7920973896980286, acc=0.6228333115577698, loss=0.7920973896980286
test: epoch 134, loss 0.7881174087524414, acc=0.6305555701255798, loss=0.7881174087524414
train: epoch 135, loss 0.8117808103561401, acc=0.6239444613456726, loss=0.8117808103561401
test: epoch 135, loss 0.7989856600761414, acc=0.6333333253860474, loss=0.7989856600761414
train: epoch 136, loss 0.8505635857582092, acc=0.6225000023841858, loss=0.8505635857582092
test: epoch 136, loss 0.8136175274848938, acc=0.625, loss=0.8136175274848938
train: epoch 137, loss 0.8304071426391602, acc=0.6223888993263245, loss=0.8304071426391602
test: epoch 137, loss 0.8207756280899048, acc=0.6277777552604675, loss=0.8207756280899048
train: epoch 138, loss 0.8243891000747681, acc=0.6248888969421387, loss=0.8243891000747681
test: epoch 138, loss 0.8197610974311829, acc=0.6277777552604675, loss=0.8197610974311829
train: epoch 139, loss 0.8265295028686523, acc=0.6241666674613953, loss=0.8265295028686523
test: epoch 139, loss 0.7997472286224365, acc=0.6305555701255798, loss=0.7997472286224365
train: epoch 140, loss 0.8219718337059021, acc=0.6252777576446533, loss=0.8219718337059021
test: epoch 140, loss 0.8488925099372864, acc=0.625, loss=0.8488925099372864
train: epoch 141, loss 0.8126068115234375, acc=0.6343333125114441, loss=0.8126068115234375
test: epoch 141, loss 0.7650919556617737, acc=0.6472222208976746, loss=0.7650919556617737
train: epoch 142, loss 0.7762113809585571, acc=0.6426110863685608, loss=0.7762113809585571
test: epoch 142, loss 0.7680433392524719, acc=0.6416666507720947, loss=0.7680433392524719
train: epoch 143, loss 0.8045411705970764, acc=0.6355000138282776, loss=0.8045411705970764
test: epoch 143, loss 0.8430727124214172, acc=0.625, loss=0.8430727124214172
train: epoch 144, loss 0.8382765054702759, acc=0.6267777681350708, loss=0.8382765054702759
test: epoch 144, loss 0.8286537528038025, acc=0.6277777552604675, loss=0.8286537528038025
train: epoch 145, loss 0.8245721459388733, acc=0.6320555806159973, loss=0.8245721459388733
test: epoch 145, loss 0.8020575642585754, acc=0.6361111402511597, loss=0.8020575642585754
train: epoch 146, loss 0.8366094827651978, acc=0.6312222480773926, loss=0.8366094827651978
test: epoch 146, loss 0.8015087842941284, acc=0.6361111402511597, loss=0.8015087842941284
train: epoch 147, loss 0.8026119470596313, acc=0.6361111402511597, loss=0.8026119470596313
test: epoch 147, loss 0.799091100692749, acc=0.6361111402511597, loss=0.799091100692749
train: epoch 148, loss 0.8016976118087769, acc=0.6361111402511597, loss=0.8016976118087769
test: epoch 148, loss 0.7988326549530029, acc=0.6361111402511597, loss=0.7988326549530029
train: epoch 149, loss 0.8014518022537231, acc=0.6361111402511597, loss=0.8014518022537231
test: epoch 149, loss 0.798740804195404, acc=0.6361111402511597, loss=0.798740804195404
train: epoch 150, loss 0.8015031814575195, acc=0.6361666917800903, loss=0.8015031814575195
test: epoch 150, loss 0.7987041473388672, acc=0.6361111402511597, loss=0.7987041473388672
