# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=true", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=649701764, receiver_embed_dim=64, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.2984201908111572, acc=0.060499999672174454, loss=3.2984201908111572
test: epoch 1, loss 3.518446922302246, acc=0.07222222536802292, loss=3.518446922302246
train: epoch 2, loss 1.9909058809280396, acc=0.2608333230018616, loss=1.9909058809280396
test: epoch 2, loss 2.5691890716552734, acc=0.1388888955116272, loss=2.5691890716552734
train: epoch 3, loss 1.583927035331726, acc=0.36738887429237366, loss=1.583927035331726
test: epoch 3, loss 2.4384872913360596, acc=0.1805555522441864, loss=2.4384872913360596
train: epoch 4, loss 1.403462529182434, acc=0.4305555522441864, loss=1.403462529182434
test: epoch 4, loss 2.410175323486328, acc=0.17777778208255768, loss=2.410175323486328
train: epoch 5, loss 1.2807420492172241, acc=0.4859444499015808, loss=1.2807420492172241
test: epoch 5, loss 2.484769344329834, acc=0.20555555820465088, loss=2.484769344329834
train: epoch 6, loss 1.1975598335266113, acc=0.52311110496521, loss=1.1975598335266113
test: epoch 6, loss 2.196732759475708, acc=0.22499999403953552, loss=2.196732759475708
train: epoch 7, loss 1.1134973764419556, acc=0.5577222108840942, loss=1.1134973764419556
test: epoch 7, loss 2.3662197589874268, acc=0.21944443881511688, loss=2.3662197589874268
train: epoch 8, loss 1.0490230321884155, acc=0.586388885974884, loss=1.0490230321884155
test: epoch 8, loss 2.3526391983032227, acc=0.2361111044883728, loss=2.3526391983032227
train: epoch 9, loss 0.9952129125595093, acc=0.6049444675445557, loss=0.9952129125595093
test: epoch 9, loss 2.2017080783843994, acc=0.25555557012557983, loss=2.2017080783843994
train: epoch 10, loss 0.9545447826385498, acc=0.6291666626930237, loss=0.9545447826385498
test: epoch 10, loss 2.116762638092041, acc=0.2666666805744171, loss=2.116762638092041
train: epoch 11, loss 0.9075655341148376, acc=0.6491666436195374, loss=0.9075655341148376
test: epoch 11, loss 2.165407419204712, acc=0.2638888955116272, loss=2.165407419204712
train: epoch 12, loss 0.8653101921081543, acc=0.6635000109672546, loss=0.8653101921081543
test: epoch 12, loss 2.151505947113037, acc=0.22777777910232544, loss=2.151505947113037
train: epoch 13, loss 0.8346480131149292, acc=0.6767222285270691, loss=0.8346480131149292
test: epoch 13, loss 2.048251152038574, acc=0.2611111104488373, loss=2.048251152038574
train: epoch 14, loss 0.7970507144927979, acc=0.6921111345291138, loss=0.7970507144927979
test: epoch 14, loss 2.135793447494507, acc=0.2916666567325592, loss=2.135793447494507
train: epoch 15, loss 0.7768308520317078, acc=0.7077222466468811, loss=0.7768308520317078
test: epoch 15, loss 2.1114134788513184, acc=0.2805555462837219, loss=2.1114134788513184
train: epoch 16, loss 0.7504233121871948, acc=0.7116666436195374, loss=0.7504233121871948
test: epoch 16, loss 1.943793773651123, acc=0.2916666567325592, loss=1.943793773651123
train: epoch 17, loss 0.7075039744377136, acc=0.7271666526794434, loss=0.7075039744377136
test: epoch 17, loss 1.9273957014083862, acc=0.3083333373069763, loss=1.9273957014083862
train: epoch 18, loss 0.6913411021232605, acc=0.7362222075462341, loss=0.6913411021232605
test: epoch 18, loss 1.8519721031188965, acc=0.3333333432674408, loss=1.8519721031188965
train: epoch 19, loss 0.6682148575782776, acc=0.7498888969421387, loss=0.6682148575782776
test: epoch 19, loss 2.004984140396118, acc=0.30000001192092896, loss=2.004984140396118
train: epoch 20, loss 0.6557135581970215, acc=0.7517777681350708, loss=0.6557135581970215
test: epoch 20, loss 1.8214035034179688, acc=0.3361110985279083, loss=1.8214035034179688
train: epoch 21, loss 0.6570223569869995, acc=0.7532777786254883, loss=0.6570223569869995
test: epoch 21, loss 2.0403122901916504, acc=0.2888889014720917, loss=2.0403122901916504
train: epoch 22, loss 0.6106201410293579, acc=0.7692777514457703, loss=0.6106201410293579
test: epoch 22, loss 1.903020977973938, acc=0.3361110985279083, loss=1.903020977973938
train: epoch 23, loss 0.5904160737991333, acc=0.7763333320617676, loss=0.5904160737991333
test: epoch 23, loss 1.8977644443511963, acc=0.3638888895511627, loss=1.8977644443511963
train: epoch 24, loss 0.5820790529251099, acc=0.7781111001968384, loss=0.5820790529251099
test: epoch 24, loss 1.936476707458496, acc=0.31111112236976624, loss=1.936476707458496
train: epoch 25, loss 0.5681705474853516, acc=0.7863333225250244, loss=0.5681705474853516
test: epoch 25, loss 1.9276667833328247, acc=0.36666667461395264, loss=1.9276667833328247
train: epoch 26, loss 0.5513981580734253, acc=0.7940000295639038, loss=0.5513981580734253
test: epoch 26, loss 1.7722870111465454, acc=0.3861111104488373, loss=1.7722870111465454
train: epoch 27, loss 0.5206403732299805, acc=0.8056111335754395, loss=0.5206403732299805
test: epoch 27, loss 1.8885552883148193, acc=0.38055557012557983, loss=1.8885552883148193
train: epoch 28, loss 0.5270084738731384, acc=0.8036666512489319, loss=0.5270084738731384
test: epoch 28, loss 1.8997714519500732, acc=0.35555556416511536, loss=1.8997714519500732
train: epoch 29, loss 0.5134461522102356, acc=0.8105555772781372, loss=0.5134461522102356
test: epoch 29, loss 1.8481284379959106, acc=0.3888888955116272, loss=1.8481284379959106
train: epoch 30, loss 0.5003454089164734, acc=0.8148333430290222, loss=0.5003454089164734
test: epoch 30, loss 1.7620136737823486, acc=0.3916666805744171, loss=1.7620136737823486
train: epoch 31, loss 0.4814029335975647, acc=0.8228333592414856, loss=0.4814029335975647
test: epoch 31, loss 1.7388516664505005, acc=0.4000000059604645, loss=1.7388516664505005
train: epoch 32, loss 0.46019452810287476, acc=0.8305555582046509, loss=0.46019452810287476
test: epoch 32, loss 1.6969692707061768, acc=0.4166666567325592, loss=1.6969692707061768
train: epoch 33, loss 0.46236440539360046, acc=0.8307222127914429, loss=0.46236440539360046
test: epoch 33, loss 1.6748064756393433, acc=0.39722222089767456, loss=1.6748064756393433
train: epoch 34, loss 0.4471750557422638, acc=0.8357222080230713, loss=0.4471750557422638
test: epoch 34, loss 1.5619208812713623, acc=0.41111111640930176, loss=1.5619208812713623
train: epoch 35, loss 0.4421139657497406, acc=0.835777759552002, loss=0.4421139657497406
test: epoch 35, loss 1.7141571044921875, acc=0.4166666567325592, loss=1.7141571044921875
train: epoch 36, loss 0.43343961238861084, acc=0.8416110873222351, loss=0.43343961238861084
test: epoch 36, loss 1.7004340887069702, acc=0.43611112236976624, loss=1.7004340887069702
train: epoch 37, loss 0.41479283571243286, acc=0.8485000133514404, loss=0.41479283571243286
test: epoch 37, loss 1.6580560207366943, acc=0.41111111640930176, loss=1.6580560207366943
train: epoch 38, loss 0.4149244427680969, acc=0.8497222065925598, loss=0.4149244427680969
test: epoch 38, loss 1.6193143129348755, acc=0.4583333432674408, loss=1.6193143129348755
train: epoch 39, loss 0.39128348231315613, acc=0.8544999957084656, loss=0.39128348231315613
test: epoch 39, loss 1.642922282218933, acc=0.4472222328186035, loss=1.642922282218933
train: epoch 40, loss 0.39625564217567444, acc=0.8567777872085571, loss=0.39625564217567444
test: epoch 40, loss 1.5749152898788452, acc=0.4611110985279083, loss=1.5749152898788452
train: epoch 41, loss 0.38524413108825684, acc=0.8607222437858582, loss=0.38524413108825684
test: epoch 41, loss 1.4072877168655396, acc=0.46388888359069824, loss=1.4072877168655396
train: epoch 42, loss 0.37385594844818115, acc=0.8610555529594421, loss=0.37385594844818115
test: epoch 42, loss 1.5631741285324097, acc=0.4611110985279083, loss=1.5631741285324097
train: epoch 43, loss 0.3768281936645508, acc=0.8647778034210205, loss=0.3768281936645508
test: epoch 43, loss 1.721733808517456, acc=0.4555555582046509, loss=1.721733808517456
train: epoch 44, loss 0.3732767701148987, acc=0.8649444580078125, loss=0.3732767701148987
test: epoch 44, loss 1.4171936511993408, acc=0.5111111402511597, loss=1.4171936511993408
train: epoch 45, loss 0.35822179913520813, acc=0.8687777519226074, loss=0.35822179913520813
test: epoch 45, loss 1.307992935180664, acc=0.4833333194255829, loss=1.307992935180664
train: epoch 46, loss 0.34651511907577515, acc=0.8749444484710693, loss=0.34651511907577515
test: epoch 46, loss 1.5687191486358643, acc=0.49444442987442017, loss=1.5687191486358643
train: epoch 47, loss 0.35986608266830444, acc=0.8697222471237183, loss=0.35986608266830444
test: epoch 47, loss 1.314982295036316, acc=0.5111111402511597, loss=1.314982295036316
train: epoch 48, loss 0.3504614233970642, acc=0.8735555410385132, loss=0.3504614233970642
test: epoch 48, loss 1.4149130582809448, acc=0.4749999940395355, loss=1.4149130582809448
train: epoch 49, loss 0.33427900075912476, acc=0.879111111164093, loss=0.33427900075912476
test: epoch 49, loss 1.3920730352401733, acc=0.5166666507720947, loss=1.3920730352401733
train: epoch 50, loss 0.3343607783317566, acc=0.8762778043746948, loss=0.3343607783317566
test: epoch 50, loss 1.3172820806503296, acc=0.5249999761581421, loss=1.3172820806503296
train: epoch 51, loss 0.32800784707069397, acc=0.8786110877990723, loss=0.32800784707069397
test: epoch 51, loss 1.347969651222229, acc=0.5361111164093018, loss=1.347969651222229
train: epoch 52, loss 0.3335101008415222, acc=0.8787222504615784, loss=0.3335101008415222
test: epoch 52, loss 1.446893334388733, acc=0.4972222149372101, loss=1.446893334388733
train: epoch 53, loss 0.31627601385116577, acc=0.8830000162124634, loss=0.31627601385116577
test: epoch 53, loss 1.3606878519058228, acc=0.5166666507720947, loss=1.3606878519058228
train: epoch 54, loss 0.32059773802757263, acc=0.8794999718666077, loss=0.32059773802757263
test: epoch 54, loss 1.3963539600372314, acc=0.5249999761581421, loss=1.3963539600372314
train: epoch 55, loss 0.3129478096961975, acc=0.8860555291175842, loss=0.3129478096961975
test: epoch 55, loss 1.3373152017593384, acc=0.5333333611488342, loss=1.3373152017593384
train: epoch 56, loss 0.30735132098197937, acc=0.8864444494247437, loss=0.30735132098197937
test: epoch 56, loss 1.4546139240264893, acc=0.5222222208976746, loss=1.4546139240264893
train: epoch 57, loss 0.3112296164035797, acc=0.887499988079071, loss=0.3112296164035797
test: epoch 57, loss 1.2802414894104004, acc=0.5444444417953491, loss=1.2802414894104004
train: epoch 58, loss 0.3058328330516815, acc=0.8887222409248352, loss=0.3058328330516815
test: epoch 58, loss 1.2449804544448853, acc=0.5472221970558167, loss=1.2449804544448853
train: epoch 59, loss 0.29596376419067383, acc=0.8911111354827881, loss=0.29596376419067383
test: epoch 59, loss 1.2622840404510498, acc=0.5527777671813965, loss=1.2622840404510498
train: epoch 60, loss 0.2904745638370514, acc=0.8907222151756287, loss=0.2904745638370514
test: epoch 60, loss 1.2771797180175781, acc=0.5611110925674438, loss=1.2771797180175781
train: epoch 61, loss 0.29651519656181335, acc=0.8932777643203735, loss=0.29651519656181335
test: epoch 61, loss 1.22027587890625, acc=0.5611110925674438, loss=1.22027587890625
train: epoch 62, loss 0.2935073971748352, acc=0.8930555582046509, loss=0.2935073971748352
test: epoch 62, loss 1.3727859258651733, acc=0.5416666865348816, loss=1.3727859258651733
train: epoch 63, loss 0.294668972492218, acc=0.893666684627533, loss=0.294668972492218
test: epoch 63, loss 1.176325798034668, acc=0.5611110925674438, loss=1.176325798034668
train: epoch 64, loss 0.28627681732177734, acc=0.895111083984375, loss=0.28627681732177734
test: epoch 64, loss 1.3040509223937988, acc=0.5111111402511597, loss=1.3040509223937988
train: epoch 65, loss 0.2821429669857025, acc=0.8983888626098633, loss=0.2821429669857025
test: epoch 65, loss 1.3227438926696777, acc=0.5333333611488342, loss=1.3227438926696777
train: epoch 66, loss 0.27073898911476135, acc=0.9021666646003723, loss=0.27073898911476135
test: epoch 66, loss 1.1910197734832764, acc=0.574999988079071, loss=1.1910197734832764
train: epoch 67, loss 0.27947667241096497, acc=0.8994444608688354, loss=0.27947667241096497
test: epoch 67, loss 1.2850791215896606, acc=0.574999988079071, loss=1.2850791215896606
train: epoch 68, loss 0.27075493335723877, acc=0.8997222185134888, loss=0.27075493335723877
test: epoch 68, loss 1.402136206626892, acc=0.5277777910232544, loss=1.402136206626892
train: epoch 69, loss 0.265322208404541, acc=0.9001666903495789, loss=0.265322208404541
test: epoch 69, loss 1.3268299102783203, acc=0.5666666626930237, loss=1.3268299102783203
train: epoch 70, loss 0.2759781777858734, acc=0.8984444737434387, loss=0.2759781777858734
test: epoch 70, loss 1.2819863557815552, acc=0.5111111402511597, loss=1.2819863557815552
train: epoch 71, loss 0.280076801776886, acc=0.8967221975326538, loss=0.280076801776886
test: epoch 71, loss 1.1971124410629272, acc=0.5722222328186035, loss=1.1971124410629272
train: epoch 72, loss 0.2690165340900421, acc=0.8985555768013, loss=0.2690165340900421
test: epoch 72, loss 1.287473201751709, acc=0.5638889074325562, loss=1.287473201751709
train: epoch 73, loss 0.2560647130012512, acc=0.9062222242355347, loss=0.2560647130012512
test: epoch 73, loss 1.1678661108016968, acc=0.574999988079071, loss=1.1678661108016968
train: epoch 74, loss 0.26699402928352356, acc=0.9001111388206482, loss=0.26699402928352356
test: epoch 74, loss 1.2786904573440552, acc=0.5666666626930237, loss=1.2786904573440552
train: epoch 75, loss 0.26669859886169434, acc=0.8993889093399048, loss=0.26669859886169434
test: epoch 75, loss 1.2529871463775635, acc=0.574999988079071, loss=1.2529871463775635
train: epoch 76, loss 0.26230552792549133, acc=0.9025555849075317, loss=0.26230552792549133
test: epoch 76, loss 1.2001639604568481, acc=0.5861111283302307, loss=1.2001639604568481
train: epoch 77, loss 0.26196736097335815, acc=0.902999997138977, loss=0.26196736097335815
test: epoch 77, loss 1.1256622076034546, acc=0.5666666626930237, loss=1.1256622076034546
train: epoch 78, loss 0.27632731199264526, acc=0.9002222418785095, loss=0.27632731199264526
test: epoch 78, loss 1.0345258712768555, acc=0.5833333134651184, loss=1.0345258712768555
train: epoch 79, loss 0.26148366928100586, acc=0.898722231388092, loss=0.26148366928100586
test: epoch 79, loss 1.061988353729248, acc=0.6000000238418579, loss=1.061988353729248
train: epoch 80, loss 0.25507181882858276, acc=0.9039999842643738, loss=0.25507181882858276
test: epoch 80, loss 1.1526342630386353, acc=0.6166666746139526, loss=1.1526342630386353
train: epoch 81, loss 0.2521173059940338, acc=0.9066110849380493, loss=0.2521173059940338
test: epoch 81, loss 1.2474315166473389, acc=0.5777778029441833, loss=1.2474315166473389
train: epoch 82, loss 0.261891633272171, acc=0.9031111001968384, loss=0.261891633272171
test: epoch 82, loss 1.2220962047576904, acc=0.5888888835906982, loss=1.2220962047576904
train: epoch 83, loss 0.2610684335231781, acc=0.9057222008705139, loss=0.2610684335231781
test: epoch 83, loss 1.3173238039016724, acc=0.5666666626930237, loss=1.3173238039016724
train: epoch 84, loss 0.26413482427597046, acc=0.9037222266197205, loss=0.26413482427597046
test: epoch 84, loss 1.139160394668579, acc=0.6194444298744202, loss=1.139160394668579
train: epoch 85, loss 0.2466539442539215, acc=0.9066666960716248, loss=0.2466539442539215
test: epoch 85, loss 0.9763977527618408, acc=0.6277777552604675, loss=0.9763977527618408
train: epoch 86, loss 0.24850976467132568, acc=0.9083889126777649, loss=0.24850976467132568
test: epoch 86, loss 1.0887436866760254, acc=0.625, loss=1.0887436866760254
train: epoch 87, loss 0.2706039547920227, acc=0.9008888602256775, loss=0.2706039547920227
test: epoch 87, loss 1.0681769847869873, acc=0.6555555462837219, loss=1.0681769847869873
train: epoch 88, loss 0.2591285705566406, acc=0.9034444689750671, loss=0.2591285705566406
test: epoch 88, loss 1.0825495719909668, acc=0.574999988079071, loss=1.0825495719909668
train: epoch 89, loss 0.246917724609375, acc=0.9097222089767456, loss=0.246917724609375
test: epoch 89, loss 1.0110582113265991, acc=0.6194444298744202, loss=1.0110582113265991
train: epoch 90, loss 0.25457605719566345, acc=0.9076666831970215, loss=0.25457605719566345
test: epoch 90, loss 0.9284581542015076, acc=0.6583333611488342, loss=0.9284581542015076
train: epoch 91, loss 0.24630525708198547, acc=0.9078333377838135, loss=0.24630525708198547
test: epoch 91, loss 1.039321780204773, acc=0.6305555701255798, loss=1.039321780204773
train: epoch 92, loss 0.25420746207237244, acc=0.9098888635635376, loss=0.25420746207237244
test: epoch 92, loss 1.0257385969161987, acc=0.6305555701255798, loss=1.0257385969161987
train: epoch 93, loss 0.25788384675979614, acc=0.910111129283905, loss=0.25788384675979614
test: epoch 93, loss 1.0577491521835327, acc=0.6333333253860474, loss=1.0577491521835327
train: epoch 94, loss 0.24675887823104858, acc=0.910444438457489, loss=0.24675887823104858
test: epoch 94, loss 1.032807469367981, acc=0.6499999761581421, loss=1.032807469367981
train: epoch 95, loss 0.2532958388328552, acc=0.9098888635635376, loss=0.2532958388328552
test: epoch 95, loss 0.9746478796005249, acc=0.6583333611488342, loss=0.9746478796005249
train: epoch 96, loss 0.25555017590522766, acc=0.906499981880188, loss=0.25555017590522766
test: epoch 96, loss 0.8654082417488098, acc=0.6722221970558167, loss=0.8654082417488098
train: epoch 97, loss 0.2440752387046814, acc=0.9108333587646484, loss=0.2440752387046814
test: epoch 97, loss 1.0276858806610107, acc=0.6611111164093018, loss=1.0276858806610107
train: epoch 98, loss 0.24289420247077942, acc=0.9113333225250244, loss=0.24289420247077942
test: epoch 98, loss 0.9703447222709656, acc=0.6833333373069763, loss=0.9703447222709656
train: epoch 99, loss 0.23717571794986725, acc=0.910611093044281, loss=0.23717571794986725
test: epoch 99, loss 1.0349425077438354, acc=0.6722221970558167, loss=1.0349425077438354
train: epoch 100, loss 0.23966754972934723, acc=0.9107778072357178, loss=0.23966754972934723
test: epoch 100, loss 1.0072718858718872, acc=0.6777777671813965, loss=1.0072718858718872
train: epoch 101, loss 0.2510472238063812, acc=0.9065555334091187, loss=0.2510472238063812
test: epoch 101, loss 0.8953206539154053, acc=0.6583333611488342, loss=0.8953206539154053
train: epoch 102, loss 0.23449739813804626, acc=0.9136666655540466, loss=0.23449739813804626
test: epoch 102, loss 0.8707047700881958, acc=0.6944444179534912, loss=0.8707047700881958
train: epoch 103, loss 0.24679018557071686, acc=0.9107778072357178, loss=0.24679018557071686
test: epoch 103, loss 0.9356799125671387, acc=0.6972222328186035, loss=0.9356799125671387
train: epoch 104, loss 0.2475515455007553, acc=0.9106666445732117, loss=0.2475515455007553
test: epoch 104, loss 0.7943415641784668, acc=0.7111111283302307, loss=0.7943415641784668
train: epoch 105, loss 0.23800767958164215, acc=0.9128333330154419, loss=0.23800767958164215
test: epoch 105, loss 0.9084208607673645, acc=0.6916666626930237, loss=0.9084208607673645
train: epoch 106, loss 0.26212677359580994, acc=0.906499981880188, loss=0.26212677359580994
test: epoch 106, loss 0.8221702575683594, acc=0.6861110925674438, loss=0.8221702575683594
train: epoch 107, loss 0.24160577356815338, acc=0.9108889102935791, loss=0.24160577356815338
test: epoch 107, loss 0.8508804440498352, acc=0.6972222328186035, loss=0.8508804440498352
train: epoch 108, loss 0.23977740108966827, acc=0.9163888692855835, loss=0.23977740108966827
test: epoch 108, loss 0.9439412951469421, acc=0.6916666626930237, loss=0.9439412951469421
train: epoch 109, loss 0.23575590550899506, acc=0.9150000214576721, loss=0.23575590550899506
test: epoch 109, loss 0.7884326577186584, acc=0.7055555582046509, loss=0.7884326577186584
train: epoch 110, loss 0.2338896542787552, acc=0.9126666784286499, loss=0.2338896542787552
test: epoch 110, loss 0.7633499503135681, acc=0.7277777791023254, loss=0.7633499503135681
train: epoch 111, loss 0.23484133183956146, acc=0.9105555415153503, loss=0.23484133183956146
test: epoch 111, loss 0.7825562357902527, acc=0.7361111044883728, loss=0.7825562357902527
train: epoch 112, loss 0.23257671296596527, acc=0.9119444489479065, loss=0.23257671296596527
test: epoch 112, loss 0.7638940215110779, acc=0.7222222089767456, loss=0.7638940215110779
train: epoch 113, loss 0.23489497601985931, acc=0.9111666679382324, loss=0.23489497601985931
test: epoch 113, loss 0.8132083415985107, acc=0.7361111044883728, loss=0.8132083415985107
train: epoch 114, loss 0.2360135167837143, acc=0.9112777709960938, loss=0.2360135167837143
test: epoch 114, loss 0.7646801471710205, acc=0.7333333492279053, loss=0.7646801471710205
train: epoch 115, loss 0.23241889476776123, acc=0.9114999771118164, loss=0.23241889476776123
test: epoch 115, loss 0.7706119418144226, acc=0.7416666746139526, loss=0.7706119418144226
train: epoch 116, loss 0.24334216117858887, acc=0.9092777967453003, loss=0.24334216117858887
test: epoch 116, loss 0.6857201457023621, acc=0.7583333253860474, loss=0.6857201457023621
train: epoch 117, loss 0.24101540446281433, acc=0.9082221984863281, loss=0.24101540446281433
test: epoch 117, loss 0.7739855051040649, acc=0.7222222089767456, loss=0.7739855051040649
train: epoch 118, loss 0.23474997282028198, acc=0.9079999923706055, loss=0.23474997282028198
test: epoch 118, loss 0.7441886067390442, acc=0.7611111402511597, loss=0.7441886067390442
train: epoch 119, loss 0.22689542174339294, acc=0.909500002861023, loss=0.22689542174339294
test: epoch 119, loss 0.7585316896438599, acc=0.7527777552604675, loss=0.7585316896438599
train: epoch 120, loss 0.23520463705062866, acc=0.9090555310249329, loss=0.23520463705062866
test: epoch 120, loss 0.689440906047821, acc=0.7611111402511597, loss=0.689440906047821
train: epoch 121, loss 0.24010024964809418, acc=0.907444417476654, loss=0.24010024964809418
test: epoch 121, loss 0.7629832029342651, acc=0.7583333253860474, loss=0.7629832029342651
train: epoch 122, loss 0.23427236080169678, acc=0.9078333377838135, loss=0.23427236080169678
test: epoch 122, loss 0.6976495981216431, acc=0.7666666507720947, loss=0.6976495981216431
train: epoch 123, loss 0.23002256453037262, acc=0.9087222218513489, loss=0.23002256453037262
test: epoch 123, loss 0.72674560546875, acc=0.75, loss=0.72674560546875
train: epoch 124, loss 0.23142360150814056, acc=0.9072222113609314, loss=0.23142360150814056
test: epoch 124, loss 0.7605752348899841, acc=0.7194444537162781, loss=0.7605752348899841
train: epoch 125, loss 0.23531143367290497, acc=0.9071111083030701, loss=0.23531143367290497
test: epoch 125, loss 0.7650782465934753, acc=0.7472222447395325, loss=0.7650782465934753
train: epoch 126, loss 0.22627072036266327, acc=0.9079999923706055, loss=0.22627072036266327
test: epoch 126, loss 0.7096680998802185, acc=0.7555555701255798, loss=0.7096680998802185
train: epoch 127, loss 0.23592033982276917, acc=0.9056110978126526, loss=0.23592033982276917
test: epoch 127, loss 0.7361118197441101, acc=0.7388888597488403, loss=0.7361118197441101
train: epoch 128, loss 0.23421528935432434, acc=0.9087222218513489, loss=0.23421528935432434
test: epoch 128, loss 0.8157979249954224, acc=0.7277777791023254, loss=0.8157979249954224
train: epoch 129, loss 0.23244298994541168, acc=0.9047777652740479, loss=0.23244298994541168
test: epoch 129, loss 0.7885627746582031, acc=0.769444465637207, loss=0.7885627746582031
train: epoch 130, loss 0.24247774481773376, acc=0.9047777652740479, loss=0.24247774481773376
test: epoch 130, loss 0.7009626626968384, acc=0.7611111402511597, loss=0.7009626626968384
train: epoch 131, loss 0.2350827306509018, acc=0.906000018119812, loss=0.2350827306509018
test: epoch 131, loss 0.7983178496360779, acc=0.7583333253860474, loss=0.7983178496360779
train: epoch 132, loss 0.23975442349910736, acc=0.9042222499847412, loss=0.23975442349910736
test: epoch 132, loss 0.7063208222389221, acc=0.7555555701255798, loss=0.7063208222389221
train: epoch 133, loss 0.22999201714992523, acc=0.9079444408416748, loss=0.22999201714992523
test: epoch 133, loss 0.7479446530342102, acc=0.7611111402511597, loss=0.7479446530342102
train: epoch 134, loss 0.2392062395811081, acc=0.906000018119812, loss=0.2392062395811081
test: epoch 134, loss 0.720040500164032, acc=0.7444444298744202, loss=0.720040500164032
train: epoch 135, loss 0.24438118934631348, acc=0.9038333296775818, loss=0.24438118934631348
test: epoch 135, loss 0.7814034819602966, acc=0.7555555701255798, loss=0.7814034819602966
train: epoch 136, loss 0.2324078381061554, acc=0.9071111083030701, loss=0.2324078381061554
test: epoch 136, loss 0.8398152589797974, acc=0.7527777552604675, loss=0.8398152589797974
train: epoch 137, loss 0.2411898523569107, acc=0.903166651725769, loss=0.2411898523569107
test: epoch 137, loss 0.6917352080345154, acc=0.75, loss=0.6917352080345154
train: epoch 138, loss 0.24710476398468018, acc=0.9017221927642822, loss=0.24710476398468018
test: epoch 138, loss 0.6656870245933533, acc=0.7638888955116272, loss=0.6656870245933533
train: epoch 139, loss 0.2306729257106781, acc=0.9088888764381409, loss=0.2306729257106781
test: epoch 139, loss 0.6999892592430115, acc=0.7611111402511597, loss=0.6999892592430115
train: epoch 140, loss 0.24009574949741364, acc=0.9032777547836304, loss=0.24009574949741364
test: epoch 140, loss 0.7581198811531067, acc=0.7638888955116272, loss=0.7581198811531067
train: epoch 141, loss 0.23701412975788116, acc=0.906166672706604, loss=0.23701412975788116
test: epoch 141, loss 0.6998996734619141, acc=0.7611111402511597, loss=0.6998996734619141
train: epoch 142, loss 0.2389015257358551, acc=0.9023333191871643, loss=0.2389015257358551
test: epoch 142, loss 0.7661094069480896, acc=0.7527777552604675, loss=0.7661094069480896
train: epoch 143, loss 0.2380245327949524, acc=0.9016110897064209, loss=0.2380245327949524
test: epoch 143, loss 0.7995819449424744, acc=0.7527777552604675, loss=0.7995819449424744
train: epoch 144, loss 0.23349349200725555, acc=0.9048333168029785, loss=0.23349349200725555
test: epoch 144, loss 0.7220150828361511, acc=0.7555555701255798, loss=0.7220150828361511
train: epoch 145, loss 0.23762273788452148, acc=0.9060555696487427, loss=0.23762273788452148
test: epoch 145, loss 0.6984999775886536, acc=0.7777777910232544, loss=0.6984999775886536
train: epoch 146, loss 0.24278298020362854, acc=0.9034444689750671, loss=0.24278298020362854
test: epoch 146, loss 0.7455454468727112, acc=0.7666666507720947, loss=0.7455454468727112
train: epoch 147, loss 0.2325311303138733, acc=0.906166672706604, loss=0.2325311303138733
test: epoch 147, loss 0.6813461184501648, acc=0.7527777552604675, loss=0.6813461184501648
train: epoch 148, loss 0.2275015264749527, acc=0.9086666703224182, loss=0.2275015264749527
test: epoch 148, loss 0.6778363585472107, acc=0.7638888955116272, loss=0.6778363585472107
train: epoch 149, loss 0.22739434242248535, acc=0.9047777652740479, loss=0.22739434242248535
test: epoch 149, loss 0.686201274394989, acc=0.7666666507720947, loss=0.686201274394989
train: epoch 150, loss 0.2361534833908081, acc=0.9054444432258606, loss=0.2361534833908081
test: epoch 150, loss 0.7519448399543762, acc=0.7555555701255798, loss=0.7519448399543762
