# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=false", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=2072980594, receiver_embed_dim=64, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.2163376808166504, acc=0.07161111384630203, loss=3.2163376808166504
test: epoch 1, loss 3.8993310928344727, acc=0.08055555820465088, loss=3.8993310928344727
train: epoch 2, loss 1.880674958229065, acc=0.31761109828948975, loss=1.880674958229065
test: epoch 2, loss 3.315369129180908, acc=0.13333334028720856, loss=3.315369129180908
train: epoch 3, loss 1.3643375635147095, acc=0.45988887548446655, loss=1.3643375635147095
test: epoch 3, loss 3.25956654548645, acc=0.15000000596046448, loss=3.25956654548645
train: epoch 4, loss 1.1568455696105957, acc=0.5376111268997192, loss=1.1568455696105957
test: epoch 4, loss 3.151423454284668, acc=0.17222222685813904, loss=3.151423454284668
train: epoch 5, loss 1.0108377933502197, acc=0.5983889102935791, loss=1.0108377933502197
test: epoch 5, loss 3.243274688720703, acc=0.21944443881511688, loss=3.243274688720703
train: epoch 6, loss 0.9293065667152405, acc=0.6386666893959045, loss=0.9293065667152405
test: epoch 6, loss 2.9274027347564697, acc=0.24166665971279144, loss=2.9274027347564697
train: epoch 7, loss 0.850344181060791, acc=0.674833357334137, loss=0.850344181060791
test: epoch 7, loss 2.78251051902771, acc=0.22777777910232544, loss=2.78251051902771
train: epoch 8, loss 0.7739819288253784, acc=0.7062777876853943, loss=0.7739819288253784
test: epoch 8, loss 2.5500340461730957, acc=0.21388888359069824, loss=2.5500340461730957
train: epoch 9, loss 0.7296739816665649, acc=0.7254999876022339, loss=0.7296739816665649
test: epoch 9, loss 2.669762134552002, acc=0.2666666805744171, loss=2.669762134552002
train: epoch 10, loss 0.6725815534591675, acc=0.7485555410385132, loss=0.6725815534591675
test: epoch 10, loss 2.6911842823028564, acc=0.2805555462837219, loss=2.6911842823028564
train: epoch 11, loss 0.6427022814750671, acc=0.757777750492096, loss=0.6427022814750671
test: epoch 11, loss 2.652824878692627, acc=0.2944444417953491, loss=2.652824878692627
train: epoch 12, loss 0.595338761806488, acc=0.7794444561004639, loss=0.595338761806488
test: epoch 12, loss 2.261194944381714, acc=0.3027777671813965, loss=2.261194944381714
train: epoch 13, loss 0.5624285936355591, acc=0.7913888692855835, loss=0.5624285936355591
test: epoch 13, loss 2.581528425216675, acc=0.3222222328186035, loss=2.581528425216675
train: epoch 14, loss 0.5453318953514099, acc=0.7979444265365601, loss=0.5453318953514099
test: epoch 14, loss 2.534627914428711, acc=0.3305555582046509, loss=2.534627914428711
train: epoch 15, loss 0.5149737596511841, acc=0.8119999766349792, loss=0.5149737596511841
test: epoch 15, loss 2.343416452407837, acc=0.2750000059604645, loss=2.343416452407837
train: epoch 16, loss 0.49954697489738464, acc=0.8221666812896729, loss=0.49954697489738464
test: epoch 16, loss 2.2035019397735596, acc=0.2888889014720917, loss=2.2035019397735596
train: epoch 17, loss 0.4653153419494629, acc=0.8331666588783264, loss=0.4653153419494629
test: epoch 17, loss 2.2752773761749268, acc=0.2805555462837219, loss=2.2752773761749268
train: epoch 18, loss 0.4557088613510132, acc=0.8332777619361877, loss=0.4557088613510132
test: epoch 18, loss 2.1505534648895264, acc=0.3305555582046509, loss=2.1505534648895264
train: epoch 19, loss 0.42642176151275635, acc=0.8463333249092102, loss=0.42642176151275635
test: epoch 19, loss 2.090996265411377, acc=0.3222222328186035, loss=2.090996265411377
train: epoch 20, loss 0.40654364228248596, acc=0.8563888669013977, loss=0.40654364228248596
test: epoch 20, loss 2.2203996181488037, acc=0.28611111640930176, loss=2.2203996181488037
train: epoch 21, loss 0.4003719389438629, acc=0.855388879776001, loss=0.4003719389438629
test: epoch 21, loss 2.0926196575164795, acc=0.3444444537162781, loss=2.0926196575164795
train: epoch 22, loss 0.38214734196662903, acc=0.8619999885559082, loss=0.38214734196662903
test: epoch 22, loss 2.16418194770813, acc=0.3222222328186035, loss=2.16418194770813
train: epoch 23, loss 0.3786093294620514, acc=0.867222249507904, loss=0.3786093294620514
test: epoch 23, loss 2.002708673477173, acc=0.34166666865348816, loss=2.002708673477173
train: epoch 24, loss 0.36748313903808594, acc=0.8694999814033508, loss=0.36748313903808594
test: epoch 24, loss 2.0415408611297607, acc=0.36666667461395264, loss=2.0415408611297607
train: epoch 25, loss 0.3460759222507477, acc=0.8755000233650208, loss=0.3460759222507477
test: epoch 25, loss 1.8431739807128906, acc=0.3777777850627899, loss=1.8431739807128906
train: epoch 26, loss 0.3353099226951599, acc=0.8830000162124634, loss=0.3353099226951599
test: epoch 26, loss 2.052284002304077, acc=0.3888888955116272, loss=2.052284002304077
train: epoch 27, loss 0.31808164715766907, acc=0.887666642665863, loss=0.31808164715766907
test: epoch 27, loss 2.0241591930389404, acc=0.3499999940395355, loss=2.0241591930389404
train: epoch 28, loss 0.31842556595802307, acc=0.8914999961853027, loss=0.31842556595802307
test: epoch 28, loss 1.7747167348861694, acc=0.3888888955116272, loss=1.7747167348861694
train: epoch 29, loss 0.31111741065979004, acc=0.8926110863685608, loss=0.31111741065979004
test: epoch 29, loss 1.9759113788604736, acc=0.3777777850627899, loss=1.9759113788604736
train: epoch 30, loss 0.302795946598053, acc=0.8930555582046509, loss=0.302795946598053
test: epoch 30, loss 1.9195098876953125, acc=0.39722222089767456, loss=1.9195098876953125
train: epoch 31, loss 0.28804948925971985, acc=0.8985555768013, loss=0.28804948925971985
test: epoch 31, loss 1.994268536567688, acc=0.3861111104488373, loss=1.994268536567688
train: epoch 32, loss 0.28799447417259216, acc=0.9006666541099548, loss=0.28799447417259216
test: epoch 32, loss 2.0064501762390137, acc=0.4166666567325592, loss=2.0064501762390137
train: epoch 33, loss 0.28231313824653625, acc=0.9013333320617676, loss=0.28231313824653625
test: epoch 33, loss 2.0020856857299805, acc=0.39722222089767456, loss=2.0020856857299805
train: epoch 34, loss 0.2656739354133606, acc=0.9068889021873474, loss=0.2656739354133606
test: epoch 34, loss 1.9791303873062134, acc=0.4000000059604645, loss=1.9791303873062134
train: epoch 35, loss 0.2724151909351349, acc=0.9079999923706055, loss=0.2724151909351349
test: epoch 35, loss 1.8460696935653687, acc=0.42222222685813904, loss=1.8460696935653687
train: epoch 36, loss 0.25774991512298584, acc=0.9114999771118164, loss=0.25774991512298584
test: epoch 36, loss 1.96075439453125, acc=0.42222222685813904, loss=1.96075439453125
train: epoch 37, loss 0.25064510107040405, acc=0.9156666398048401, loss=0.25064510107040405
test: epoch 37, loss 1.7545478343963623, acc=0.41111111640930176, loss=1.7545478343963623
train: epoch 38, loss 0.24758493900299072, acc=0.9148889183998108, loss=0.24758493900299072
test: epoch 38, loss 1.8527978658676147, acc=0.4305555522441864, loss=1.8527978658676147
train: epoch 39, loss 0.24635927379131317, acc=0.9174444675445557, loss=0.24635927379131317
test: epoch 39, loss 2.1133480072021484, acc=0.4194444417953491, loss=2.1133480072021484
train: epoch 40, loss 0.2427457720041275, acc=0.9181110858917236, loss=0.2427457720041275
test: epoch 40, loss 1.752738118171692, acc=0.46388888359069824, loss=1.752738118171692
train: epoch 41, loss 0.23182383179664612, acc=0.9202777743339539, loss=0.23182383179664612
test: epoch 41, loss 1.9319665431976318, acc=0.4583333432674408, loss=1.9319665431976318
train: epoch 42, loss 0.22398723661899567, acc=0.9225555658340454, loss=0.22398723661899567
test: epoch 42, loss 1.8752048015594482, acc=0.42500001192092896, loss=1.8752048015594482
train: epoch 43, loss 0.22770163416862488, acc=0.9229444265365601, loss=0.22770163416862488
test: epoch 43, loss 1.8243768215179443, acc=0.44999998807907104, loss=1.8243768215179443
train: epoch 44, loss 0.2107388973236084, acc=0.9293333292007446, loss=0.2107388973236084
test: epoch 44, loss 1.8747062683105469, acc=0.4277777671813965, loss=1.8747062683105469
train: epoch 45, loss 0.2220594882965088, acc=0.9268888831138611, loss=0.2220594882965088
test: epoch 45, loss 1.852900743484497, acc=0.4611110985279083, loss=1.852900743484497
train: epoch 46, loss 0.20909413695335388, acc=0.9265000224113464, loss=0.20909413695335388
test: epoch 46, loss 1.8624006509780884, acc=0.44999998807907104, loss=1.8624006509780884
train: epoch 47, loss 0.2231922149658203, acc=0.9233333468437195, loss=0.2231922149658203
test: epoch 47, loss 1.9212144613265991, acc=0.4611110985279083, loss=1.9212144613265991
train: epoch 48, loss 0.21396991610527039, acc=0.9263333082199097, loss=0.21396991610527039
test: epoch 48, loss 1.901727318763733, acc=0.43888887763023376, loss=1.901727318763733
train: epoch 49, loss 0.1966230571269989, acc=0.9307777881622314, loss=0.1966230571269989
test: epoch 49, loss 2.024717092514038, acc=0.4472222328186035, loss=2.024717092514038
train: epoch 50, loss 0.19739829003810883, acc=0.929611086845398, loss=0.19739829003810883
test: epoch 50, loss 1.9665350914001465, acc=0.4277777671813965, loss=1.9665350914001465
train: epoch 51, loss 0.18900112807750702, acc=0.9329444169998169, loss=0.18900112807750702
test: epoch 51, loss 1.997136116027832, acc=0.45277777314186096, loss=1.997136116027832
train: epoch 52, loss 0.19418515264987946, acc=0.9315000176429749, loss=0.19418515264987946
test: epoch 52, loss 1.7291709184646606, acc=0.49166667461395264, loss=1.7291709184646606
train: epoch 53, loss 0.20293880999088287, acc=0.930055558681488, loss=0.20293880999088287
test: epoch 53, loss 2.196692943572998, acc=0.43888887763023376, loss=2.196692943572998
train: epoch 54, loss 0.1862749457359314, acc=0.9316111207008362, loss=0.1862749457359314
test: epoch 54, loss 1.7234588861465454, acc=0.46388888359069824, loss=1.7234588861465454
train: epoch 55, loss 0.18417467176914215, acc=0.933388888835907, loss=0.18417467176914215
test: epoch 55, loss 1.861880898475647, acc=0.4416666626930237, loss=1.861880898475647
train: epoch 56, loss 0.1832742840051651, acc=0.9336110949516296, loss=0.1832742840051651
test: epoch 56, loss 1.9744943380355835, acc=0.43611112236976624, loss=1.9744943380355835
train: epoch 57, loss 0.1850532740354538, acc=0.9353888630867004, loss=0.1850532740354538
test: epoch 57, loss 1.8924508094787598, acc=0.5055555701255798, loss=1.8924508094787598
train: epoch 58, loss 0.1733049601316452, acc=0.9361110925674438, loss=0.1733049601316452
test: epoch 58, loss 1.792832851409912, acc=0.47777777910232544, loss=1.792832851409912
train: epoch 59, loss 0.178007572889328, acc=0.9357222318649292, loss=0.178007572889328
test: epoch 59, loss 1.8226971626281738, acc=0.5, loss=1.8226971626281738
train: epoch 60, loss 0.1728607714176178, acc=0.9388889074325562, loss=0.1728607714176178
test: epoch 60, loss 1.8120626211166382, acc=0.48055556416511536, loss=1.8120626211166382
train: epoch 61, loss 0.17305800318717957, acc=0.9394999742507935, loss=0.17305800318717957
test: epoch 61, loss 1.9863903522491455, acc=0.49444442987442017, loss=1.9863903522491455
train: epoch 62, loss 0.17177504301071167, acc=0.9388889074325562, loss=0.17177504301071167
test: epoch 62, loss 1.7584278583526611, acc=0.4694444537162781, loss=1.7584278583526611
train: epoch 63, loss 0.1595325618982315, acc=0.9427222013473511, loss=0.1595325618982315
test: epoch 63, loss 1.6766020059585571, acc=0.519444465637207, loss=1.6766020059585571
train: epoch 64, loss 0.15915019810199738, acc=0.9438333511352539, loss=0.15915019810199738
test: epoch 64, loss 1.8694387674331665, acc=0.4861111044883728, loss=1.8694387674331665
train: epoch 65, loss 0.18056011199951172, acc=0.9382777810096741, loss=0.18056011199951172
test: epoch 65, loss 1.989197850227356, acc=0.45277777314186096, loss=1.989197850227356
train: epoch 66, loss 0.1569795459508896, acc=0.9418333172798157, loss=0.1569795459508896
test: epoch 66, loss 1.9442329406738281, acc=0.4972222149372101, loss=1.9442329406738281
train: epoch 67, loss 0.16914525628089905, acc=0.9401111006736755, loss=0.16914525628089905
test: epoch 67, loss 1.7912757396697998, acc=0.5305555462837219, loss=1.7912757396697998
train: epoch 68, loss 0.15969285368919373, acc=0.9422222375869751, loss=0.15969285368919373
test: epoch 68, loss 1.662691593170166, acc=0.519444465637207, loss=1.662691593170166
train: epoch 69, loss 0.15715225040912628, acc=0.9432222247123718, loss=0.15715225040912628
test: epoch 69, loss 2.088087797164917, acc=0.4972222149372101, loss=2.088087797164917
train: epoch 70, loss 0.16427165269851685, acc=0.9420555830001831, loss=0.16427165269851685
test: epoch 70, loss 1.6818581819534302, acc=0.4833333194255829, loss=1.6818581819534302
train: epoch 71, loss 0.15504774451255798, acc=0.9440000057220459, loss=0.15504774451255798
test: epoch 71, loss 1.7951463460922241, acc=0.49166667461395264, loss=1.7951463460922241
train: epoch 72, loss 0.1546327769756317, acc=0.9463333487510681, loss=0.1546327769756317
test: epoch 72, loss 1.601448893547058, acc=0.49166667461395264, loss=1.601448893547058
train: epoch 73, loss 0.15724869072437286, acc=0.9441666603088379, loss=0.15724869072437286
test: epoch 73, loss 1.6852251291275024, acc=0.5166666507720947, loss=1.6852251291275024
train: epoch 74, loss 0.14664767682552338, acc=0.9480000138282776, loss=0.14664767682552338
test: epoch 74, loss 2.0403456687927246, acc=0.5111111402511597, loss=2.0403456687927246
train: epoch 75, loss 0.16140665113925934, acc=0.944944441318512, loss=0.16140665113925934
test: epoch 75, loss 1.6085968017578125, acc=0.5388888716697693, loss=1.6085968017578125
train: epoch 76, loss 0.15304280817508698, acc=0.9444444179534912, loss=0.15304280817508698
test: epoch 76, loss 1.7094154357910156, acc=0.5166666507720947, loss=1.7094154357910156
train: epoch 77, loss 0.14895138144493103, acc=0.9459444284439087, loss=0.14895138144493103
test: epoch 77, loss 1.728588581085205, acc=0.5416666865348816, loss=1.728588581085205
train: epoch 78, loss 0.15359722077846527, acc=0.945888876914978, loss=0.15359722077846527
test: epoch 78, loss 1.896653652191162, acc=0.4722222089767456, loss=1.896653652191162
train: epoch 79, loss 0.15340809524059296, acc=0.9473333358764648, loss=0.15340809524059296
test: epoch 79, loss 1.748651385307312, acc=0.519444465637207, loss=1.748651385307312
train: epoch 80, loss 0.14113867282867432, acc=0.9492777585983276, loss=0.14113867282867432
test: epoch 80, loss 1.6049091815948486, acc=0.5527777671813965, loss=1.6049091815948486
train: epoch 81, loss 0.14148445427417755, acc=0.9511666893959045, loss=0.14148445427417755
test: epoch 81, loss 1.6994909048080444, acc=0.5416666865348816, loss=1.6994909048080444
train: epoch 82, loss 0.14334508776664734, acc=0.9484999775886536, loss=0.14334508776664734
test: epoch 82, loss 1.6207764148712158, acc=0.5638889074325562, loss=1.6207764148712158
train: epoch 83, loss 0.138471782207489, acc=0.9486666917800903, loss=0.138471782207489
test: epoch 83, loss 1.6097246408462524, acc=0.5472221970558167, loss=1.6097246408462524
train: epoch 84, loss 0.13565979897975922, acc=0.9507777690887451, loss=0.13565979897975922
test: epoch 84, loss 1.864377498626709, acc=0.5277777910232544, loss=1.864377498626709
train: epoch 85, loss 0.14470764994621277, acc=0.9510555267333984, loss=0.14470764994621277
test: epoch 85, loss 1.6972848176956177, acc=0.5583333373069763, loss=1.6972848176956177
train: epoch 86, loss 0.13586948812007904, acc=0.9505000114440918, loss=0.13586948812007904
test: epoch 86, loss 1.481925129890442, acc=0.5805555582046509, loss=1.481925129890442
train: epoch 87, loss 0.1362622082233429, acc=0.9508333206176758, loss=0.1362622082233429
test: epoch 87, loss 1.4897695779800415, acc=0.5944444537162781, loss=1.4897695779800415
train: epoch 88, loss 0.1414605677127838, acc=0.9501110911369324, loss=0.1414605677127838
test: epoch 88, loss 1.6355292797088623, acc=0.5472221970558167, loss=1.6355292797088623
train: epoch 89, loss 0.15048252046108246, acc=0.9490000009536743, loss=0.15048252046108246
test: epoch 89, loss 1.4716506004333496, acc=0.5944444537162781, loss=1.4716506004333496
train: epoch 90, loss 0.138925701379776, acc=0.9504444599151611, loss=0.138925701379776
test: epoch 90, loss 1.4350104331970215, acc=0.605555534362793, loss=1.4350104331970215
train: epoch 91, loss 0.132956400513649, acc=0.9521111249923706, loss=0.132956400513649
test: epoch 91, loss 1.5502543449401855, acc=0.550000011920929, loss=1.5502543449401855
train: epoch 92, loss 0.1544034779071808, acc=0.9478333592414856, loss=0.1544034779071808
test: epoch 92, loss 1.4378126859664917, acc=0.5888888835906982, loss=1.4378126859664917
train: epoch 93, loss 0.14229558408260345, acc=0.9509444236755371, loss=0.14229558408260345
test: epoch 93, loss 1.401137351989746, acc=0.6416666507720947, loss=1.401137351989746
train: epoch 94, loss 0.12722225487232208, acc=0.9527778029441833, loss=0.12722225487232208
test: epoch 94, loss 1.5352534055709839, acc=0.5694444179534912, loss=1.5352534055709839
train: epoch 95, loss 0.13543231785297394, acc=0.9516111016273499, loss=0.13543231785297394
test: epoch 95, loss 1.4819568395614624, acc=0.5944444537162781, loss=1.4819568395614624
train: epoch 96, loss 0.1404147446155548, acc=0.9509444236755371, loss=0.1404147446155548
test: epoch 96, loss 1.5286471843719482, acc=0.5833333134651184, loss=1.5286471843719482
train: epoch 97, loss 0.13867872953414917, acc=0.9490000009536743, loss=0.13867872953414917
test: epoch 97, loss 1.3760167360305786, acc=0.6138888597488403, loss=1.3760167360305786
train: epoch 98, loss 0.14267833530902863, acc=0.9490000009536743, loss=0.14267833530902863
test: epoch 98, loss 1.3906538486480713, acc=0.6499999761581421, loss=1.3906538486480713
train: epoch 99, loss 0.13589338958263397, acc=0.9521111249923706, loss=0.13589338958263397
test: epoch 99, loss 1.5332330465316772, acc=0.6222222447395325, loss=1.5332330465316772
train: epoch 100, loss 0.1236518919467926, acc=0.9553333520889282, loss=0.1236518919467926
test: epoch 100, loss 1.2627356052398682, acc=0.6305555701255798, loss=1.2627356052398682
train: epoch 101, loss 0.1365034282207489, acc=0.9512222409248352, loss=0.1365034282207489
test: epoch 101, loss 1.397025465965271, acc=0.6194444298744202, loss=1.397025465965271
train: epoch 102, loss 0.14009323716163635, acc=0.9518333077430725, loss=0.14009323716163635
test: epoch 102, loss 1.1864371299743652, acc=0.6527777910232544, loss=1.1864371299743652
train: epoch 103, loss 0.13520295917987823, acc=0.9519444704055786, loss=0.13520295917987823
test: epoch 103, loss 1.3361895084381104, acc=0.6277777552604675, loss=1.3361895084381104
train: epoch 104, loss 0.13764309883117676, acc=0.9508333206176758, loss=0.13764309883117676
test: epoch 104, loss 1.3762142658233643, acc=0.6277777552604675, loss=1.3762142658233643
train: epoch 105, loss 0.1479042023420334, acc=0.9503333568572998, loss=0.1479042023420334
test: epoch 105, loss 1.3056490421295166, acc=0.6333333253860474, loss=1.3056490421295166
train: epoch 106, loss 0.13961204886436462, acc=0.9496666789054871, loss=0.13961204886436462
test: epoch 106, loss 1.3169593811035156, acc=0.6388888955116272, loss=1.3169593811035156
train: epoch 107, loss 0.12683358788490295, acc=0.954277753829956, loss=0.12683358788490295
test: epoch 107, loss 1.261303186416626, acc=0.6666666865348816, loss=1.261303186416626
train: epoch 108, loss 0.12533511221408844, acc=0.9552778005599976, loss=0.12533511221408844
test: epoch 108, loss 1.1950448751449585, acc=0.6861110925674438, loss=1.1950448751449585
train: epoch 109, loss 0.13838554918766022, acc=0.9524999856948853, loss=0.13838554918766022
test: epoch 109, loss 1.3994793891906738, acc=0.6194444298744202, loss=1.3994793891906738
train: epoch 110, loss 0.12681081891059875, acc=0.9552222490310669, loss=0.12681081891059875
test: epoch 110, loss 1.3567094802856445, acc=0.6555555462837219, loss=1.3567094802856445
train: epoch 111, loss 0.13906998932361603, acc=0.9504444599151611, loss=0.13906998932361603
test: epoch 111, loss 1.2617768049240112, acc=0.6833333373069763, loss=1.2617768049240112
train: epoch 112, loss 0.1334439367055893, acc=0.9548888802528381, loss=0.1334439367055893
test: epoch 112, loss 1.162667989730835, acc=0.6527777910232544, loss=1.162667989730835
train: epoch 113, loss 0.12232267111539841, acc=0.9559444189071655, loss=0.12232267111539841
test: epoch 113, loss 1.2421965599060059, acc=0.6638888716697693, loss=1.2421965599060059
train: epoch 114, loss 0.12610946595668793, acc=0.9549444317817688, loss=0.12610946595668793
test: epoch 114, loss 1.166210412979126, acc=0.675000011920929, loss=1.166210412979126
train: epoch 115, loss 0.1374518871307373, acc=0.9545000195503235, loss=0.1374518871307373
test: epoch 115, loss 1.2297903299331665, acc=0.6555555462837219, loss=1.2297903299331665
train: epoch 116, loss 0.12847766280174255, acc=0.9538333415985107, loss=0.12847766280174255
test: epoch 116, loss 1.2263338565826416, acc=0.6916666626930237, loss=1.2263338565826416
train: epoch 117, loss 0.13297469913959503, acc=0.9540555477142334, loss=0.13297469913959503
test: epoch 117, loss 1.2574656009674072, acc=0.6611111164093018, loss=1.2574656009674072
train: epoch 118, loss 0.12540295720100403, acc=0.9562222361564636, loss=0.12540295720100403
test: epoch 118, loss 1.3980852365493774, acc=0.6722221970558167, loss=1.3980852365493774
train: epoch 119, loss 0.1284317970275879, acc=0.9554444551467896, loss=0.1284317970275879
test: epoch 119, loss 1.2264595031738281, acc=0.6888889074325562, loss=1.2264595031738281
train: epoch 120, loss 0.12887616455554962, acc=0.9552778005599976, loss=0.12887616455554962
test: epoch 120, loss 1.2299933433532715, acc=0.699999988079071, loss=1.2299933433532715
train: epoch 121, loss 0.13742731511592865, acc=0.9517222046852112, loss=0.13742731511592865
test: epoch 121, loss 1.2060168981552124, acc=0.699999988079071, loss=1.2060168981552124
train: epoch 122, loss 0.13615405559539795, acc=0.9515555500984192, loss=0.13615405559539795
test: epoch 122, loss 1.2229673862457275, acc=0.6861110925674438, loss=1.2229673862457275
train: epoch 123, loss 0.12286920845508575, acc=0.9547777771949768, loss=0.12286920845508575
test: epoch 123, loss 1.17466139793396, acc=0.699999988079071, loss=1.17466139793396
train: epoch 124, loss 0.13083624839782715, acc=0.9546111226081848, loss=0.13083624839782715
test: epoch 124, loss 1.1155585050582886, acc=0.7027778029441833, loss=1.1155585050582886
train: epoch 125, loss 0.13156139850616455, acc=0.9536666870117188, loss=0.13156139850616455
test: epoch 125, loss 1.248221516609192, acc=0.6944444179534912, loss=1.248221516609192
train: epoch 126, loss 0.1333763748407364, acc=0.9562222361564636, loss=0.1333763748407364
test: epoch 126, loss 1.2561089992523193, acc=0.7111111283302307, loss=1.2561089992523193
train: epoch 127, loss 0.12582936882972717, acc=0.9582777619361877, loss=0.12582936882972717
test: epoch 127, loss 1.0963339805603027, acc=0.7361111044883728, loss=1.0963339805603027
train: epoch 128, loss 0.12804053723812103, acc=0.9556666612625122, loss=0.12804053723812103
test: epoch 128, loss 1.3056640625, acc=0.6666666865348816, loss=1.3056640625
train: epoch 129, loss 0.13064436614513397, acc=0.9543333053588867, loss=0.13064436614513397
test: epoch 129, loss 1.0635243654251099, acc=0.7055555582046509, loss=1.0635243654251099
train: epoch 130, loss 0.12106945365667343, acc=0.956944465637207, loss=0.12106945365667343
test: epoch 130, loss 1.0425159931182861, acc=0.7166666388511658, loss=1.0425159931182861
train: epoch 131, loss 0.13128013908863068, acc=0.9543333053588867, loss=0.13128013908863068
test: epoch 131, loss 1.147515892982483, acc=0.7083333134651184, loss=1.147515892982483
train: epoch 132, loss 0.13426873087882996, acc=0.9556111097335815, loss=0.13426873087882996
test: epoch 132, loss 1.051578164100647, acc=0.7194444537162781, loss=1.051578164100647
train: epoch 133, loss 0.12697350978851318, acc=0.9553889036178589, loss=0.12697350978851318
test: epoch 133, loss 1.009921669960022, acc=0.730555534362793, loss=1.009921669960022
train: epoch 134, loss 0.14888624846935272, acc=0.9546666741371155, loss=0.14888624846935272
test: epoch 134, loss 1.096022367477417, acc=0.7083333134651184, loss=1.096022367477417
train: epoch 135, loss 0.1367361843585968, acc=0.9547222256660461, loss=0.1367361843585968
test: epoch 135, loss 1.0203009843826294, acc=0.730555534362793, loss=1.0203009843826294
train: epoch 136, loss 0.12080083042383194, acc=0.9568889141082764, loss=0.12080083042383194
test: epoch 136, loss 0.965961754322052, acc=0.7222222089767456, loss=0.965961754322052
train: epoch 137, loss 0.1258627027273178, acc=0.9549999833106995, loss=0.1258627027273178
test: epoch 137, loss 1.0539029836654663, acc=0.730555534362793, loss=1.0539029836654663
train: epoch 138, loss 0.13065634667873383, acc=0.9553333520889282, loss=0.13065634667873383
test: epoch 138, loss 1.0257412195205688, acc=0.7666666507720947, loss=1.0257412195205688
train: epoch 139, loss 0.13939198851585388, acc=0.9578333497047424, loss=0.13939198851585388
test: epoch 139, loss 0.990788996219635, acc=0.7444444298744202, loss=0.990788996219635
train: epoch 140, loss 0.12295573204755783, acc=0.9587777853012085, loss=0.12295573204755783
test: epoch 140, loss 0.8974913358688354, acc=0.769444465637207, loss=0.8974913358688354
train: epoch 141, loss 0.11835065484046936, acc=0.9616110920906067, loss=0.11835065484046936
test: epoch 141, loss 0.8434376120567322, acc=0.769444465637207, loss=0.8434376120567322
train: epoch 142, loss 0.11090631783008575, acc=0.9624444246292114, loss=0.11090631783008575
test: epoch 142, loss 0.8552961945533752, acc=0.7777777910232544, loss=0.8552961945533752
train: epoch 143, loss 0.1254231184720993, acc=0.9608888626098633, loss=0.1254231184720993
test: epoch 143, loss 0.8914045691490173, acc=0.769444465637207, loss=0.8914045691490173
train: epoch 144, loss 0.12602727115154266, acc=0.9593889117240906, loss=0.12602727115154266
test: epoch 144, loss 0.9327382445335388, acc=0.7555555701255798, loss=0.9327382445335388
train: epoch 145, loss 0.12591373920440674, acc=0.961722195148468, loss=0.12591373920440674
test: epoch 145, loss 0.9312657713890076, acc=0.7611111402511597, loss=0.9312657713890076
train: epoch 146, loss 0.11709233373403549, acc=0.9633888602256775, loss=0.11709233373403549
test: epoch 146, loss 0.8717359900474548, acc=0.7777777910232544, loss=0.8717359900474548
train: epoch 147, loss 0.12153170257806778, acc=0.9610555768013, loss=0.12153170257806778
test: epoch 147, loss 0.8398131728172302, acc=0.7611111402511597, loss=0.8398131728172302
train: epoch 148, loss 0.11055877059698105, acc=0.9638888835906982, loss=0.11055877059698105
test: epoch 148, loss 0.9636478424072266, acc=0.7861111164093018, loss=0.9636478424072266
train: epoch 149, loss 0.12122876197099686, acc=0.9614444375038147, loss=0.12122876197099686
test: epoch 149, loss 0.8613156080245972, acc=0.7638888955116272, loss=0.8613156080245972
train: epoch 150, loss 0.1228342279791832, acc=0.9605555534362793, loss=0.1228342279791832
test: epoch 150, loss 0.8596150279045105, acc=0.7888888716697693, loss=0.8596150279045105
