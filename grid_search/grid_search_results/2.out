# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1", "--temp_decay=1", "--one_hot=true", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1695912578, receiver_embed_dim=32, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.1574456691741943, acc=0.06661111116409302, loss=3.1574456691741943
test: epoch 1, loss 2.8760998249053955, acc=0.0972222238779068, loss=2.8760998249053955
train: epoch 2, loss 2.352653741836548, acc=0.16033333539962769, loss=2.352653741836548
test: epoch 2, loss 2.4277851581573486, acc=0.12222222238779068, loss=2.4277851581573486
train: epoch 3, loss 1.971794605255127, acc=0.228444442152977, loss=1.971794605255127
test: epoch 3, loss 2.0899674892425537, acc=0.21666666865348816, loss=2.0899674892425537
train: epoch 4, loss 1.768178105354309, acc=0.2863888740539551, loss=1.768178105354309
test: epoch 4, loss 1.9312385320663452, acc=0.22499999403953552, loss=1.9312385320663452
train: epoch 5, loss 1.616378903388977, acc=0.3337777853012085, loss=1.616378903388977
test: epoch 5, loss 1.9435248374938965, acc=0.24722221493721008, loss=1.9435248374938965
train: epoch 6, loss 1.503623366355896, acc=0.36694443225860596, loss=1.503623366355896
test: epoch 6, loss 1.9026126861572266, acc=0.2777777910232544, loss=1.9026126861572266
train: epoch 7, loss 1.3697675466537476, acc=0.41366666555404663, loss=1.3697675466537476
test: epoch 7, loss 1.9266140460968018, acc=0.2777777910232544, loss=1.9266140460968018
train: epoch 8, loss 1.3113012313842773, acc=0.43772223591804504, loss=1.3113012313842773
test: epoch 8, loss 2.210933208465576, acc=0.2750000059604645, loss=2.210933208465576
train: epoch 9, loss 1.2319782972335815, acc=0.46783334016799927, loss=1.2319782972335815
test: epoch 9, loss 2.0780279636383057, acc=0.2777777910232544, loss=2.0780279636383057
train: epoch 10, loss 1.1506373882293701, acc=0.4992777705192566, loss=1.1506373882293701
test: epoch 10, loss 2.1572282314300537, acc=0.3027777671813965, loss=2.1572282314300537
train: epoch 11, loss 1.1142683029174805, acc=0.5152778029441833, loss=1.1142683029174805
test: epoch 11, loss 1.9925121068954468, acc=0.3333333432674408, loss=1.9925121068954468
train: epoch 12, loss 1.0549060106277466, acc=0.5415555834770203, loss=1.0549060106277466
test: epoch 12, loss 1.9305884838104248, acc=0.3777777850627899, loss=1.9305884838104248
train: epoch 13, loss 1.0291684865951538, acc=0.5604444742202759, loss=1.0291684865951538
test: epoch 13, loss 1.714647650718689, acc=0.3638888895511627, loss=1.714647650718689
train: epoch 14, loss 0.9460909366607666, acc=0.5860000252723694, loss=0.9460909366607666
test: epoch 14, loss 1.662511944770813, acc=0.4000000059604645, loss=1.662511944770813
train: epoch 15, loss 0.9169715046882629, acc=0.598111093044281, loss=0.9169715046882629
test: epoch 15, loss 1.549739956855774, acc=0.4027777910232544, loss=1.549739956855774
train: epoch 16, loss 0.8539296388626099, acc=0.6234444379806519, loss=0.8539296388626099
test: epoch 16, loss 1.95668625831604, acc=0.3888888955116272, loss=1.95668625831604
train: epoch 17, loss 0.8497328758239746, acc=0.6307222247123718, loss=0.8497328758239746
test: epoch 17, loss 1.7596104145050049, acc=0.4000000059604645, loss=1.7596104145050049
train: epoch 18, loss 0.8544228672981262, acc=0.6244444251060486, loss=0.8544228672981262
test: epoch 18, loss 1.5575368404388428, acc=0.4166666567325592, loss=1.5575368404388428
train: epoch 19, loss 0.8241544961929321, acc=0.6434444189071655, loss=0.8241544961929321
test: epoch 19, loss 1.5594582557678223, acc=0.4305555522441864, loss=1.5594582557678223
train: epoch 20, loss 0.809481143951416, acc=0.6497777700424194, loss=0.809481143951416
test: epoch 20, loss 1.5402730703353882, acc=0.44999998807907104, loss=1.5402730703353882
train: epoch 21, loss 0.778782069683075, acc=0.6746666431427002, loss=0.778782069683075
test: epoch 21, loss 1.6600687503814697, acc=0.4194444417953491, loss=1.6600687503814697
train: epoch 22, loss 0.7475383281707764, acc=0.6817777752876282, loss=0.7475383281707764
test: epoch 22, loss 1.6309025287628174, acc=0.43888887763023376, loss=1.6309025287628174
train: epoch 23, loss 0.7452499270439148, acc=0.6806111335754395, loss=0.7452499270439148
test: epoch 23, loss 1.6821492910385132, acc=0.4305555522441864, loss=1.6821492910385132
train: epoch 24, loss 0.7178511023521423, acc=0.691277801990509, loss=0.7178511023521423
test: epoch 24, loss 1.735024333000183, acc=0.4416666626930237, loss=1.735024333000183
train: epoch 25, loss 0.7229525446891785, acc=0.6892777681350708, loss=0.7229525446891785
test: epoch 25, loss 1.7438687086105347, acc=0.4138889014720917, loss=1.7438687086105347
train: epoch 26, loss 0.6859927773475647, acc=0.7038333415985107, loss=0.6859927773475647
test: epoch 26, loss 1.787227749824524, acc=0.4333333373069763, loss=1.787227749824524
train: epoch 27, loss 0.6866299510002136, acc=0.7063888907432556, loss=0.6866299510002136
test: epoch 27, loss 1.6510342359542847, acc=0.4194444417953491, loss=1.6510342359542847
train: epoch 28, loss 0.6884450316429138, acc=0.7031111121177673, loss=0.6884450316429138
test: epoch 28, loss 1.6053354740142822, acc=0.42222222685813904, loss=1.6053354740142822
train: epoch 29, loss 0.6689013242721558, acc=0.7118889093399048, loss=0.6689013242721558
test: epoch 29, loss 1.4823514223098755, acc=0.4472222328186035, loss=1.4823514223098755
train: epoch 30, loss 0.6581383347511292, acc=0.7191110849380493, loss=0.6581383347511292
test: epoch 30, loss 1.4974614381790161, acc=0.4472222328186035, loss=1.4974614381790161
train: epoch 31, loss 0.6812952756881714, acc=0.7077222466468811, loss=0.6812952756881714
test: epoch 31, loss 1.6209522485733032, acc=0.4194444417953491, loss=1.6209522485733032
train: epoch 32, loss 0.6692453622817993, acc=0.7137222290039062, loss=0.6692453622817993
test: epoch 32, loss 1.3549481630325317, acc=0.4888888895511627, loss=1.3549481630325317
train: epoch 33, loss 0.6382344365119934, acc=0.7240555286407471, loss=0.6382344365119934
test: epoch 33, loss 1.3301090002059937, acc=0.4583333432674408, loss=1.3301090002059937
train: epoch 34, loss 0.6375361084938049, acc=0.7237222194671631, loss=0.6375361084938049
test: epoch 34, loss 1.7134311199188232, acc=0.4555555582046509, loss=1.7134311199188232
train: epoch 35, loss 0.644442081451416, acc=0.7229999899864197, loss=0.644442081451416
test: epoch 35, loss 1.2932847738265991, acc=0.49444442987442017, loss=1.2932847738265991
train: epoch 36, loss 0.6509515643119812, acc=0.7231666445732117, loss=0.6509515643119812
test: epoch 36, loss 1.354386568069458, acc=0.4722222089767456, loss=1.354386568069458
train: epoch 37, loss 0.6213831901550293, acc=0.7293333411216736, loss=0.6213831901550293
test: epoch 37, loss 1.4994043111801147, acc=0.4972222149372101, loss=1.4994043111801147
train: epoch 38, loss 0.6355923414230347, acc=0.7245555520057678, loss=0.6355923414230347
test: epoch 38, loss 1.5165789127349854, acc=0.4833333194255829, loss=1.5165789127349854
train: epoch 39, loss 0.6182217001914978, acc=0.730055570602417, loss=0.6182217001914978
test: epoch 39, loss 1.6873056888580322, acc=0.4611110985279083, loss=1.6873056888580322
train: epoch 40, loss 0.6220963001251221, acc=0.730388879776001, loss=0.6220963001251221
test: epoch 40, loss 1.4829654693603516, acc=0.4555555582046509, loss=1.4829654693603516
train: epoch 41, loss 0.6230570673942566, acc=0.7320555448532104, loss=0.6230570673942566
test: epoch 41, loss 1.394019603729248, acc=0.4833333194255829, loss=1.394019603729248
train: epoch 42, loss 0.6124538779258728, acc=0.7301666736602783, loss=0.6124538779258728
test: epoch 42, loss 1.4017561674118042, acc=0.5027777552604675, loss=1.4017561674118042
train: epoch 43, loss 0.6038841009140015, acc=0.7369999885559082, loss=0.6038841009140015
test: epoch 43, loss 1.5442091226577759, acc=0.48055556416511536, loss=1.5442091226577759
train: epoch 44, loss 0.6077157258987427, acc=0.7351111173629761, loss=0.6077157258987427
test: epoch 44, loss 1.4829915761947632, acc=0.4833333194255829, loss=1.4829915761947632
train: epoch 45, loss 0.6036830544471741, acc=0.7373889088630676, loss=0.6036830544471741
test: epoch 45, loss 1.497811198234558, acc=0.5138888955116272, loss=1.497811198234558
train: epoch 46, loss 0.6011119484901428, acc=0.738611102104187, loss=0.6011119484901428
test: epoch 46, loss 1.519590973854065, acc=0.5027777552604675, loss=1.519590973854065
train: epoch 47, loss 0.582877516746521, acc=0.7423333525657654, loss=0.582877516746521
test: epoch 47, loss 1.4015157222747803, acc=0.4749999940395355, loss=1.4015157222747803
train: epoch 48, loss 0.6106389164924622, acc=0.734000027179718, loss=0.6106389164924622
test: epoch 48, loss 1.3556939363479614, acc=0.49166667461395264, loss=1.3556939363479614
train: epoch 49, loss 0.5915069580078125, acc=0.7417222261428833, loss=0.5915069580078125
test: epoch 49, loss 1.415065050125122, acc=0.5, loss=1.415065050125122
train: epoch 50, loss 0.5949657559394836, acc=0.7396666407585144, loss=0.5949657559394836
test: epoch 50, loss 1.5150622129440308, acc=0.4833333194255829, loss=1.5150622129440308
train: epoch 51, loss 0.6157277822494507, acc=0.7342777848243713, loss=0.6157277822494507
test: epoch 51, loss 1.4435079097747803, acc=0.5083333253860474, loss=1.4435079097747803
train: epoch 52, loss 0.5903842449188232, acc=0.7415000200271606, loss=0.5903842449188232
test: epoch 52, loss 1.3644322156906128, acc=0.5055555701255798, loss=1.3644322156906128
train: epoch 53, loss 0.5704792737960815, acc=0.7486666440963745, loss=0.5704792737960815
test: epoch 53, loss 1.4959510564804077, acc=0.519444465637207, loss=1.4959510564804077
train: epoch 54, loss 0.606183648109436, acc=0.7410555481910706, loss=0.606183648109436
test: epoch 54, loss 1.4068493843078613, acc=0.5055555701255798, loss=1.4068493843078613
train: epoch 55, loss 0.5856772065162659, acc=0.742388904094696, loss=0.5856772065162659
test: epoch 55, loss 1.4174071550369263, acc=0.5138888955116272, loss=1.4174071550369263
train: epoch 56, loss 0.585363507270813, acc=0.7438333630561829, loss=0.585363507270813
test: epoch 56, loss 1.2853062152862549, acc=0.5027777552604675, loss=1.2853062152862549
train: epoch 57, loss 0.5703871846199036, acc=0.7476111054420471, loss=0.5703871846199036
test: epoch 57, loss 1.4225406646728516, acc=0.5277777910232544, loss=1.4225406646728516
train: epoch 58, loss 0.5763939023017883, acc=0.7447777986526489, loss=0.5763939023017883
test: epoch 58, loss 1.4422892332077026, acc=0.5, loss=1.4422892332077026
train: epoch 59, loss 0.5883773565292358, acc=0.7424444556236267, loss=0.5883773565292358
test: epoch 59, loss 1.4616726636886597, acc=0.5027777552604675, loss=1.4616726636886597
train: epoch 60, loss 0.5620774030685425, acc=0.7513333559036255, loss=0.5620774030685425
test: epoch 60, loss 1.6340000629425049, acc=0.49444442987442017, loss=1.6340000629425049
train: epoch 61, loss 0.5677637457847595, acc=0.7478333115577698, loss=0.5677637457847595
test: epoch 61, loss 1.3266794681549072, acc=0.5, loss=1.3266794681549072
train: epoch 62, loss 0.5599532723426819, acc=0.7493333220481873, loss=0.5599532723426819
test: epoch 62, loss 1.3339852094650269, acc=0.5388888716697693, loss=1.3339852094650269
train: epoch 63, loss 0.5641040802001953, acc=0.7479444742202759, loss=0.5641040802001953
test: epoch 63, loss 1.4557902812957764, acc=0.4972222149372101, loss=1.4557902812957764
train: epoch 64, loss 0.5557215809822083, acc=0.7573888897895813, loss=0.5557215809822083
test: epoch 64, loss 1.4019436836242676, acc=0.5361111164093018, loss=1.4019436836242676
train: epoch 65, loss 0.5124320983886719, acc=0.7779444456100464, loss=0.5124320983886719
test: epoch 65, loss 1.3943867683410645, acc=0.550000011920929, loss=1.3943867683410645
train: epoch 66, loss 0.5096337795257568, acc=0.7797222137451172, loss=0.5096337795257568
test: epoch 66, loss 1.2541098594665527, acc=0.5388888716697693, loss=1.2541098594665527
train: epoch 67, loss 0.48025742173194885, acc=0.7847222089767456, loss=0.48025742173194885
test: epoch 67, loss 1.3764184713363647, acc=0.5555555820465088, loss=1.3764184713363647
train: epoch 68, loss 0.47607216238975525, acc=0.793666660785675, loss=0.47607216238975525
test: epoch 68, loss 1.3006170988082886, acc=0.550000011920929, loss=1.3006170988082886
train: epoch 69, loss 0.4565128982067108, acc=0.8042222261428833, loss=0.4565128982067108
test: epoch 69, loss 1.4856446981430054, acc=0.5138888955116272, loss=1.4856446981430054
train: epoch 70, loss 0.4278050363063812, acc=0.8165555596351624, loss=0.4278050363063812
test: epoch 70, loss 1.4224607944488525, acc=0.5472221970558167, loss=1.4224607944488525
train: epoch 71, loss 0.4099985361099243, acc=0.8239444494247437, loss=0.4099985361099243
test: epoch 71, loss 1.3844469785690308, acc=0.550000011920929, loss=1.3844469785690308
train: epoch 72, loss 0.42432862520217896, acc=0.816611111164093, loss=0.42432862520217896
test: epoch 72, loss 1.236464500427246, acc=0.550000011920929, loss=1.236464500427246
train: epoch 73, loss 0.39873063564300537, acc=0.8236111402511597, loss=0.39873063564300537
test: epoch 73, loss 1.4578427076339722, acc=0.5444444417953491, loss=1.4578427076339722
train: epoch 74, loss 0.44266045093536377, acc=0.8125, loss=0.44266045093536377
test: epoch 74, loss 1.2502223253250122, acc=0.5444444417953491, loss=1.2502223253250122
train: epoch 75, loss 0.4059533476829529, acc=0.8233888745307922, loss=0.4059533476829529
test: epoch 75, loss 1.376486897468567, acc=0.5388888716697693, loss=1.376486897468567
train: epoch 76, loss 0.3963788151741028, acc=0.8246666789054871, loss=0.3963788151741028
test: epoch 76, loss 1.484298586845398, acc=0.5444444417953491, loss=1.484298586845398
train: epoch 77, loss 0.4149981439113617, acc=0.8183888792991638, loss=0.4149981439113617
test: epoch 77, loss 1.4898664951324463, acc=0.5555555820465088, loss=1.4898664951324463
train: epoch 78, loss 0.39929434657096863, acc=0.8219444155693054, loss=0.39929434657096863
test: epoch 78, loss 1.5224294662475586, acc=0.550000011920929, loss=1.5224294662475586
train: epoch 79, loss 0.4085352122783661, acc=0.8209444284439087, loss=0.4085352122783661
test: epoch 79, loss 1.4540215730667114, acc=0.550000011920929, loss=1.4540215730667114
train: epoch 80, loss 0.4040909707546234, acc=0.8220555782318115, loss=0.4040909707546234
test: epoch 80, loss 1.5322357416152954, acc=0.550000011920929, loss=1.5322357416152954
train: epoch 81, loss 0.40827688574790955, acc=0.8202221989631653, loss=0.40827688574790955
test: epoch 81, loss 1.608132243156433, acc=0.550000011920929, loss=1.608132243156433
train: epoch 82, loss 0.3956965506076813, acc=0.8252221941947937, loss=0.3956965506076813
test: epoch 82, loss 1.5125794410705566, acc=0.550000011920929, loss=1.5125794410705566
train: epoch 83, loss 0.390857070684433, acc=0.8248888850212097, loss=0.390857070684433
test: epoch 83, loss 1.4675419330596924, acc=0.550000011920929, loss=1.4675419330596924
train: epoch 84, loss 0.396281898021698, acc=0.8251110911369324, loss=0.396281898021698
test: epoch 84, loss 1.7090691328048706, acc=0.5416666865348816, loss=1.7090691328048706
train: epoch 85, loss 0.396531879901886, acc=0.823888897895813, loss=0.396531879901886
test: epoch 85, loss 1.4022365808486938, acc=0.5472221970558167, loss=1.4022365808486938
train: epoch 86, loss 0.39125460386276245, acc=0.8257222175598145, loss=0.39125460386276245
test: epoch 86, loss 1.430251121520996, acc=0.550000011920929, loss=1.430251121520996
train: epoch 87, loss 0.39079344272613525, acc=0.8274999856948853, loss=0.39079344272613525
test: epoch 87, loss 1.4350758790969849, acc=0.550000011920929, loss=1.4350758790969849
train: epoch 88, loss 0.36941346526145935, acc=0.8327222466468811, loss=0.36941346526145935
test: epoch 88, loss 1.4725260734558105, acc=0.5361111164093018, loss=1.4725260734558105
train: epoch 89, loss 0.39457210898399353, acc=0.824833333492279, loss=0.39457210898399353
test: epoch 89, loss 1.4380106925964355, acc=0.5472221970558167, loss=1.4380106925964355
train: epoch 90, loss 0.37320876121520996, acc=0.8334444165229797, loss=0.37320876121520996
test: epoch 90, loss 1.557888150215149, acc=0.5472221970558167, loss=1.557888150215149
train: epoch 91, loss 0.40146806836128235, acc=0.8224999904632568, loss=0.40146806836128235
test: epoch 91, loss 1.2397950887680054, acc=0.5472221970558167, loss=1.2397950887680054
train: epoch 92, loss 0.40192651748657227, acc=0.8234444260597229, loss=0.40192651748657227
test: epoch 92, loss 1.4726667404174805, acc=0.5444444417953491, loss=1.4726667404174805
train: epoch 93, loss 0.3914855420589447, acc=0.8262777924537659, loss=0.3914855420589447
test: epoch 93, loss 1.3837268352508545, acc=0.550000011920929, loss=1.3837268352508545
train: epoch 94, loss 0.3786173462867737, acc=0.8286666870117188, loss=0.3786173462867737
test: epoch 94, loss 1.4186267852783203, acc=0.5527777671813965, loss=1.4186267852783203
train: epoch 95, loss 0.3666272461414337, acc=0.8321666717529297, loss=0.3666272461414337
test: epoch 95, loss 1.7026625871658325, acc=0.550000011920929, loss=1.7026625871658325
train: epoch 96, loss 0.37448850274086, acc=0.8330000042915344, loss=0.37448850274086
test: epoch 96, loss 1.5684047937393188, acc=0.5416666865348816, loss=1.5684047937393188
train: epoch 97, loss 0.3864152133464813, acc=0.8290555477142334, loss=0.3864152133464813
test: epoch 97, loss 1.6520708799362183, acc=0.5388888716697693, loss=1.6520708799362183
train: epoch 98, loss 0.3741554915904999, acc=0.8342777490615845, loss=0.3741554915904999
test: epoch 98, loss 1.5310102701187134, acc=0.5444444417953491, loss=1.5310102701187134
train: epoch 99, loss 0.39928507804870605, acc=0.8258333206176758, loss=0.39928507804870605
test: epoch 99, loss 1.5023598670959473, acc=0.5472221970558167, loss=1.5023598670959473
train: epoch 100, loss 0.4027525782585144, acc=0.8246111273765564, loss=0.4027525782585144
test: epoch 100, loss 1.4812870025634766, acc=0.550000011920929, loss=1.4812870025634766
train: epoch 101, loss 0.3859958052635193, acc=0.8303333520889282, loss=0.3859958052635193
test: epoch 101, loss 1.374735951423645, acc=0.550000011920929, loss=1.374735951423645
train: epoch 102, loss 0.3970353603363037, acc=0.8261666893959045, loss=0.3970353603363037
test: epoch 102, loss 1.395392656326294, acc=0.5472221970558167, loss=1.395392656326294
train: epoch 103, loss 0.3688696622848511, acc=0.8334444165229797, loss=0.3688696622848511
test: epoch 103, loss 1.5865075588226318, acc=0.5388888716697693, loss=1.5865075588226318
train: epoch 104, loss 0.38494548201560974, acc=0.8301110863685608, loss=0.38494548201560974
test: epoch 104, loss 1.5632617473602295, acc=0.5472221970558167, loss=1.5632617473602295
train: epoch 105, loss 0.38250622153282166, acc=0.8312222361564636, loss=0.38250622153282166
test: epoch 105, loss 1.43673574924469, acc=0.5472221970558167, loss=1.43673574924469
train: epoch 106, loss 0.4229777753353119, acc=0.8163889050483704, loss=0.4229777753353119
test: epoch 106, loss 1.5003767013549805, acc=0.550000011920929, loss=1.5003767013549805
train: epoch 107, loss 0.380741149187088, acc=0.8314444422721863, loss=0.380741149187088
test: epoch 107, loss 1.531287670135498, acc=0.5138888955116272, loss=1.531287670135498
train: epoch 108, loss 0.34900903701782227, acc=0.8403333425521851, loss=0.34900903701782227
test: epoch 108, loss 1.6210570335388184, acc=0.550000011920929, loss=1.6210570335388184
train: epoch 109, loss 0.3659510016441345, acc=0.8338333368301392, loss=0.3659510016441345
test: epoch 109, loss 1.4903361797332764, acc=0.550000011920929, loss=1.4903361797332764
train: epoch 110, loss 0.38112470507621765, acc=0.8297777771949768, loss=0.38112470507621765
test: epoch 110, loss 1.6093199253082275, acc=0.5694444179534912, loss=1.6093199253082275
train: epoch 111, loss 0.38277530670166016, acc=0.8296666741371155, loss=0.38277530670166016
test: epoch 111, loss 1.475068211555481, acc=0.5583333373069763, loss=1.475068211555481
train: epoch 112, loss 0.3726113438606262, acc=0.8335000276565552, loss=0.3726113438606262
test: epoch 112, loss 1.502444863319397, acc=0.5805555582046509, loss=1.502444863319397
train: epoch 113, loss 0.37306374311447144, acc=0.8338888883590698, loss=0.37306374311447144
test: epoch 113, loss 1.4551920890808105, acc=0.5472221970558167, loss=1.4551920890808105
train: epoch 114, loss 0.3574885427951813, acc=0.8364999890327454, loss=0.3574885427951813
test: epoch 114, loss 1.3452632427215576, acc=0.574999988079071, loss=1.3452632427215576
train: epoch 115, loss 0.3621613085269928, acc=0.835444450378418, loss=0.3621613085269928
test: epoch 115, loss 1.558017373085022, acc=0.5444444417953491, loss=1.558017373085022
train: epoch 116, loss 0.37246111035346985, acc=0.8327222466468811, loss=0.37246111035346985
test: epoch 116, loss 1.560083031654358, acc=0.5555555820465088, loss=1.560083031654358
train: epoch 117, loss 0.3538970649242401, acc=0.8386666774749756, loss=0.3538970649242401
test: epoch 117, loss 1.3386253118515015, acc=0.574999988079071, loss=1.3386253118515015
train: epoch 118, loss 0.35355162620544434, acc=0.8380555510520935, loss=0.35355162620544434
test: epoch 118, loss 1.2980211973190308, acc=0.5777778029441833, loss=1.2980211973190308
train: epoch 119, loss 0.3684230446815491, acc=0.8323888778686523, loss=0.3684230446815491
test: epoch 119, loss 1.3711360692977905, acc=0.5833333134651184, loss=1.3711360692977905
train: epoch 120, loss 0.34994930028915405, acc=0.8403333425521851, loss=0.34994930028915405
test: epoch 120, loss 1.3520053625106812, acc=0.5833333134651184, loss=1.3520053625106812
train: epoch 121, loss 0.363314688205719, acc=0.835444450378418, loss=0.363314688205719
test: epoch 121, loss 1.3865365982055664, acc=0.5861111283302307, loss=1.3865365982055664
train: epoch 122, loss 0.34741663932800293, acc=0.8414999842643738, loss=0.34741663932800293
test: epoch 122, loss 1.4411529302597046, acc=0.5833333134651184, loss=1.4411529302597046
train: epoch 123, loss 0.3812892436981201, acc=0.831333339214325, loss=0.3812892436981201
test: epoch 123, loss 1.316227912902832, acc=0.5777778029441833, loss=1.316227912902832
train: epoch 124, loss 0.3623781204223633, acc=0.8343889117240906, loss=0.3623781204223633
test: epoch 124, loss 1.4097797870635986, acc=0.5861111283302307, loss=1.4097797870635986
train: epoch 125, loss 0.33856201171875, acc=0.8431666493415833, loss=0.33856201171875
test: epoch 125, loss 1.232329249382019, acc=0.5916666388511658, loss=1.232329249382019
train: epoch 126, loss 0.37153443694114685, acc=0.835777759552002, loss=0.37153443694114685
test: epoch 126, loss 1.4652994871139526, acc=0.5916666388511658, loss=1.4652994871139526
train: epoch 127, loss 0.35913974046707153, acc=0.8379444479942322, loss=0.35913974046707153
test: epoch 127, loss 1.4116512537002563, acc=0.5694444179534912, loss=1.4116512537002563
train: epoch 128, loss 0.35877886414527893, acc=0.8385000228881836, loss=0.35877886414527893
test: epoch 128, loss 1.2525182962417603, acc=0.5916666388511658, loss=1.2525182962417603
train: epoch 129, loss 0.3476110100746155, acc=0.8410000205039978, loss=0.3476110100746155
test: epoch 129, loss 1.1455485820770264, acc=0.5888888835906982, loss=1.1455485820770264
train: epoch 130, loss 0.3602801561355591, acc=0.8359444737434387, loss=0.3602801561355591
test: epoch 130, loss 1.5191730260849, acc=0.574999988079071, loss=1.5191730260849
train: epoch 131, loss 0.34721362590789795, acc=0.8423333168029785, loss=0.34721362590789795
test: epoch 131, loss 1.348689317703247, acc=0.6083333492279053, loss=1.348689317703247
train: epoch 132, loss 0.3499450087547302, acc=0.8420555591583252, loss=0.3499450087547302
test: epoch 132, loss 1.331792950630188, acc=0.5972222089767456, loss=1.331792950630188
train: epoch 133, loss 0.35973942279815674, acc=0.8368333578109741, loss=0.35973942279815674
test: epoch 133, loss 1.279934048652649, acc=0.6000000238418579, loss=1.279934048652649
train: epoch 134, loss 0.35042625665664673, acc=0.8391666412353516, loss=0.35042625665664673
test: epoch 134, loss 1.1631574630737305, acc=0.6222222447395325, loss=1.1631574630737305
train: epoch 135, loss 0.3319450616836548, acc=0.8447222113609314, loss=0.3319450616836548
test: epoch 135, loss 1.2601544857025146, acc=0.6222222447395325, loss=1.2601544857025146
train: epoch 136, loss 0.35807281732559204, acc=0.8401111364364624, loss=0.35807281732559204
test: epoch 136, loss 1.2125228643417358, acc=0.6194444298744202, loss=1.2125228643417358
train: epoch 137, loss 0.33463504910469055, acc=0.8446666598320007, loss=0.33463504910469055
test: epoch 137, loss 1.2707289457321167, acc=0.6361111402511597, loss=1.2707289457321167
train: epoch 138, loss 0.3539578914642334, acc=0.8376111388206482, loss=0.3539578914642334
test: epoch 138, loss 1.2065829038619995, acc=0.6416666507720947, loss=1.2065829038619995
train: epoch 139, loss 0.317597895860672, acc=0.8498888611793518, loss=0.317597895860672
test: epoch 139, loss 1.3082971572875977, acc=0.644444465637207, loss=1.3082971572875977
train: epoch 140, loss 0.36210137605667114, acc=0.8342777490615845, loss=0.36210137605667114
test: epoch 140, loss 1.1569900512695312, acc=0.6499999761581421, loss=1.1569900512695312
train: epoch 141, loss 0.32894420623779297, acc=0.8446666598320007, loss=0.32894420623779297
test: epoch 141, loss 1.2919918298721313, acc=0.6499999761581421, loss=1.2919918298721313
train: epoch 142, loss 0.3149661421775818, acc=0.8495555520057678, loss=0.3149661421775818
test: epoch 142, loss 1.2898012399673462, acc=0.6472222208976746, loss=1.2898012399673462
train: epoch 143, loss 0.33228355646133423, acc=0.8450555801391602, loss=0.33228355646133423
test: epoch 143, loss 1.1169432401657104, acc=0.6583333611488342, loss=1.1169432401657104
train: epoch 144, loss 0.3129568099975586, acc=0.8515555262565613, loss=0.3129568099975586
test: epoch 144, loss 1.1932613849639893, acc=0.6638888716697693, loss=1.1932613849639893
train: epoch 145, loss 0.3197661340236664, acc=0.850777804851532, loss=0.3197661340236664
test: epoch 145, loss 1.1494982242584229, acc=0.6583333611488342, loss=1.1494982242584229
train: epoch 146, loss 0.31709024310112, acc=0.8519444465637207, loss=0.31709024310112
test: epoch 146, loss 1.1810407638549805, acc=0.6638888716697693, loss=1.1810407638549805
train: epoch 147, loss 0.31762242317199707, acc=0.8493888974189758, loss=0.31762242317199707
test: epoch 147, loss 1.096170425415039, acc=0.6638888716697693, loss=1.096170425415039
train: epoch 148, loss 0.30915993452072144, acc=0.851111114025116, loss=0.30915993452072144
test: epoch 148, loss 1.0434484481811523, acc=0.6638888716697693, loss=1.0434484481811523
train: epoch 149, loss 0.3903612494468689, acc=0.8307222127914429, loss=0.3903612494468689
test: epoch 149, loss 1.0546913146972656, acc=0.6611111164093018, loss=1.0546913146972656
train: epoch 150, loss 0.3086535930633545, acc=0.8525000214576721, loss=0.3086535930633545
test: epoch 150, loss 1.2835867404937744, acc=0.6638888716697693, loss=1.2835867404937744
