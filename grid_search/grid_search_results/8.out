# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=32", "--temperature=1", "--temp_decay=0.995", "--one_hot=true", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1571549593, receiver_embed_dim=32, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.168867349624634, acc=0.058888889849185944, loss=3.168867349624634
test: epoch 1, loss 2.7328097820281982, acc=0.10000000149011612, loss=2.7328097820281982
train: epoch 2, loss 2.291329860687256, acc=0.16005556285381317, loss=2.291329860687256
test: epoch 2, loss 2.316244125366211, acc=0.20277777314186096, loss=2.316244125366211
train: epoch 3, loss 1.9108703136444092, acc=0.2417222261428833, loss=1.9108703136444092
test: epoch 3, loss 2.265104293823242, acc=0.1944444477558136, loss=2.265104293823242
train: epoch 4, loss 1.6757972240447998, acc=0.3141111135482788, loss=1.6757972240447998
test: epoch 4, loss 2.032579183578491, acc=0.2666666805744171, loss=2.032579183578491
train: epoch 5, loss 1.4702444076538086, acc=0.378888875246048, loss=1.4702444076538086
test: epoch 5, loss 1.8016608953475952, acc=0.30000001192092896, loss=1.8016608953475952
train: epoch 6, loss 1.2744218111038208, acc=0.4410000145435333, loss=1.2744218111038208
test: epoch 6, loss 1.5379654169082642, acc=0.33888888359069824, loss=1.5379654169082642
train: epoch 7, loss 1.1443915367126465, acc=0.4883333444595337, loss=1.1443915367126465
test: epoch 7, loss 1.4087988138198853, acc=0.3722222149372101, loss=1.4087988138198853
train: epoch 8, loss 1.0351083278656006, acc=0.5335555672645569, loss=1.0351083278656006
test: epoch 8, loss 1.3962353467941284, acc=0.40833333134651184, loss=1.3962353467941284
train: epoch 9, loss 0.9507997035980225, acc=0.5667222142219543, loss=0.9507997035980225
test: epoch 9, loss 1.3593071699142456, acc=0.39722222089767456, loss=1.3593071699142456
train: epoch 10, loss 0.8927992582321167, acc=0.589555561542511, loss=0.8927992582321167
test: epoch 10, loss 1.2605857849121094, acc=0.4055555462837219, loss=1.2605857849121094
train: epoch 11, loss 0.8593592047691345, acc=0.6057222485542297, loss=0.8593592047691345
test: epoch 11, loss 1.3687924146652222, acc=0.4166666567325592, loss=1.3687924146652222
train: epoch 12, loss 0.8244039416313171, acc=0.6197222471237183, loss=0.8244039416313171
test: epoch 12, loss 1.40092933177948, acc=0.4166666567325592, loss=1.40092933177948
train: epoch 13, loss 0.8028804063796997, acc=0.6283888816833496, loss=0.8028804063796997
test: epoch 13, loss 1.5033223628997803, acc=0.39722222089767456, loss=1.5033223628997803
train: epoch 14, loss 0.7632529139518738, acc=0.6449999809265137, loss=0.7632529139518738
test: epoch 14, loss 1.6056362390518188, acc=0.4000000059604645, loss=1.6056362390518188
train: epoch 15, loss 0.7496892809867859, acc=0.6498333215713501, loss=0.7496892809867859
test: epoch 15, loss 1.30111563205719, acc=0.4194444417953491, loss=1.30111563205719
train: epoch 16, loss 0.7472246885299683, acc=0.6511666774749756, loss=0.7472246885299683
test: epoch 16, loss 1.3982313871383667, acc=0.43888887763023376, loss=1.3982313871383667
train: epoch 17, loss 0.7309807538986206, acc=0.6603333353996277, loss=0.7309807538986206
test: epoch 17, loss 1.5120595693588257, acc=0.42222222685813904, loss=1.5120595693588257
train: epoch 18, loss 0.7210763692855835, acc=0.6668333411216736, loss=0.7210763692855835
test: epoch 18, loss 1.5364125967025757, acc=0.39444443583488464, loss=1.5364125967025757
train: epoch 19, loss 0.7333259582519531, acc=0.6627777814865112, loss=0.7333259582519531
test: epoch 19, loss 1.5895891189575195, acc=0.4277777671813965, loss=1.5895891189575195
train: epoch 20, loss 0.7034360766410828, acc=0.6763333082199097, loss=0.7034360766410828
test: epoch 20, loss 1.4677327871322632, acc=0.4277777671813965, loss=1.4677327871322632
train: epoch 21, loss 0.6997884511947632, acc=0.6782222390174866, loss=0.6997884511947632
test: epoch 21, loss 1.7183126211166382, acc=0.42222222685813904, loss=1.7183126211166382
train: epoch 22, loss 0.6835864782333374, acc=0.683722198009491, loss=0.6835864782333374
test: epoch 22, loss 1.5155304670333862, acc=0.4333333373069763, loss=1.5155304670333862
train: epoch 23, loss 0.6849780082702637, acc=0.6813889145851135, loss=0.6849780082702637
test: epoch 23, loss 1.7704092264175415, acc=0.41111111640930176, loss=1.7704092264175415
train: epoch 24, loss 0.6747403740882874, acc=0.6836666464805603, loss=0.6747403740882874
test: epoch 24, loss 1.5010383129119873, acc=0.4166666567325592, loss=1.5010383129119873
train: epoch 25, loss 0.6595221161842346, acc=0.6919999718666077, loss=0.6595221161842346
test: epoch 25, loss 1.600105881690979, acc=0.4305555522441864, loss=1.600105881690979
train: epoch 26, loss 0.6647993326187134, acc=0.691444456577301, loss=0.6647993326187134
test: epoch 26, loss 1.4513673782348633, acc=0.4416666626930237, loss=1.4513673782348633
train: epoch 27, loss 0.6767196655273438, acc=0.6893333196640015, loss=0.6767196655273438
test: epoch 27, loss 1.4292707443237305, acc=0.45277777314186096, loss=1.4292707443237305
train: epoch 28, loss 0.6739757061004639, acc=0.6867222189903259, loss=0.6739757061004639
test: epoch 28, loss 1.520396113395691, acc=0.4333333373069763, loss=1.520396113395691
train: epoch 29, loss 0.6674147248268127, acc=0.6894999742507935, loss=0.6674147248268127
test: epoch 29, loss 1.4631376266479492, acc=0.4333333373069763, loss=1.4631376266479492
train: epoch 30, loss 0.6664917469024658, acc=0.6915555596351624, loss=0.6664917469024658
test: epoch 30, loss 1.3495113849639893, acc=0.4444444477558136, loss=1.3495113849639893
train: epoch 31, loss 0.6736125349998474, acc=0.6897222399711609, loss=0.6736125349998474
test: epoch 31, loss 1.3527311086654663, acc=0.46388888359069824, loss=1.3527311086654663
train: epoch 32, loss 0.6581361889839172, acc=0.6948888897895813, loss=0.6581361889839172
test: epoch 32, loss 1.2523937225341797, acc=0.4694444537162781, loss=1.2523937225341797
train: epoch 33, loss 0.6442650556564331, acc=0.7032222151756287, loss=0.6442650556564331
test: epoch 33, loss 1.3776094913482666, acc=0.45277777314186096, loss=1.3776094913482666
train: epoch 34, loss 0.6584524512290955, acc=0.6981666684150696, loss=0.6584524512290955
test: epoch 34, loss 1.4171512126922607, acc=0.4416666626930237, loss=1.4171512126922607
train: epoch 35, loss 0.6518961787223816, acc=0.6965000033378601, loss=0.6518961787223816
test: epoch 35, loss 1.3913908004760742, acc=0.46666666865348816, loss=1.3913908004760742
train: epoch 36, loss 0.6661495566368103, acc=0.6972777843475342, loss=0.6661495566368103
test: epoch 36, loss 1.4046810865402222, acc=0.4694444537162781, loss=1.4046810865402222
train: epoch 37, loss 0.6595997214317322, acc=0.6943333148956299, loss=0.6595997214317322
test: epoch 37, loss 1.4783451557159424, acc=0.4749999940395355, loss=1.4783451557159424
train: epoch 38, loss 0.655717134475708, acc=0.6976666450500488, loss=0.655717134475708
test: epoch 38, loss 1.444225788116455, acc=0.46666666865348816, loss=1.444225788116455
train: epoch 39, loss 0.6551474332809448, acc=0.6977777481079102, loss=0.6551474332809448
test: epoch 39, loss 1.302251935005188, acc=0.4694444537162781, loss=1.302251935005188
train: epoch 40, loss 0.6734181046485901, acc=0.6882777810096741, loss=0.6734181046485901
test: epoch 40, loss 1.274001955986023, acc=0.4722222089767456, loss=1.274001955986023
train: epoch 41, loss 0.6371248960494995, acc=0.7053333520889282, loss=0.6371248960494995
test: epoch 41, loss 1.5619124174118042, acc=0.46388888359069824, loss=1.5619124174118042
train: epoch 42, loss 0.639409601688385, acc=0.7084444165229797, loss=0.639409601688385
test: epoch 42, loss 1.3146671056747437, acc=0.47777777910232544, loss=1.3146671056747437
train: epoch 43, loss 0.6426820755004883, acc=0.7037777900695801, loss=0.6426820755004883
test: epoch 43, loss 1.2505651712417603, acc=0.46666666865348816, loss=1.2505651712417603
train: epoch 44, loss 0.626349925994873, acc=0.7091666460037231, loss=0.626349925994873
test: epoch 44, loss 1.4127193689346313, acc=0.4694444537162781, loss=1.4127193689346313
train: epoch 45, loss 0.6506180167198181, acc=0.699388861656189, loss=0.6506180167198181
test: epoch 45, loss 1.4353268146514893, acc=0.4722222089767456, loss=1.4353268146514893
train: epoch 46, loss 0.6393008828163147, acc=0.7056111097335815, loss=0.6393008828163147
test: epoch 46, loss 1.2992714643478394, acc=0.4583333432674408, loss=1.2992714643478394
train: epoch 47, loss 0.6449885964393616, acc=0.7026666402816772, loss=0.6449885964393616
test: epoch 47, loss 1.3507529497146606, acc=0.46666666865348816, loss=1.3507529497146606
train: epoch 48, loss 0.6496737003326416, acc=0.7011111378669739, loss=0.6496737003326416
test: epoch 48, loss 1.4403793811798096, acc=0.46388888359069824, loss=1.4403793811798096
train: epoch 49, loss 0.6406148672103882, acc=0.7038888931274414, loss=0.6406148672103882
test: epoch 49, loss 1.3414326906204224, acc=0.4694444537162781, loss=1.3414326906204224
train: epoch 50, loss 0.6452615857124329, acc=0.7007777690887451, loss=0.6452615857124329
test: epoch 50, loss 1.364235281944275, acc=0.4694444537162781, loss=1.364235281944275
train: epoch 51, loss 0.6404405832290649, acc=0.7056666612625122, loss=0.6404405832290649
test: epoch 51, loss 1.3446526527404785, acc=0.4722222089767456, loss=1.3446526527404785
train: epoch 52, loss 0.6483878493309021, acc=0.7060555815696716, loss=0.6483878493309021
test: epoch 52, loss 1.4055694341659546, acc=0.4694444537162781, loss=1.4055694341659546
train: epoch 53, loss 0.631083607673645, acc=0.7091666460037231, loss=0.631083607673645
test: epoch 53, loss 1.2176448106765747, acc=0.46666666865348816, loss=1.2176448106765747
train: epoch 54, loss 0.64314204454422, acc=0.706166684627533, loss=0.64314204454422
test: epoch 54, loss 1.304295539855957, acc=0.44999998807907104, loss=1.304295539855957
train: epoch 55, loss 0.6207240223884583, acc=0.711722195148468, loss=0.6207240223884583
test: epoch 55, loss 1.3505321741104126, acc=0.4694444537162781, loss=1.3505321741104126
train: epoch 56, loss 0.6695200800895691, acc=0.6973888874053955, loss=0.6695200800895691
test: epoch 56, loss 1.3219594955444336, acc=0.4722222089767456, loss=1.3219594955444336
train: epoch 57, loss 0.6320727467536926, acc=0.710277795791626, loss=0.6320727467536926
test: epoch 57, loss 1.3638111352920532, acc=0.4611110985279083, loss=1.3638111352920532
train: epoch 58, loss 0.6468531489372253, acc=0.7022777795791626, loss=0.6468531489372253
test: epoch 58, loss 1.4991458654403687, acc=0.45277777314186096, loss=1.4991458654403687
train: epoch 59, loss 0.6201940774917603, acc=0.715499997138977, loss=0.6201940774917603
test: epoch 59, loss 1.4583443403244019, acc=0.4611110985279083, loss=1.4583443403244019
train: epoch 60, loss 0.647668182849884, acc=0.7053889036178589, loss=0.647668182849884
test: epoch 60, loss 1.3509575128555298, acc=0.4555555582046509, loss=1.3509575128555298
train: epoch 61, loss 0.630165159702301, acc=0.7112777829170227, loss=0.630165159702301
test: epoch 61, loss 1.4142042398452759, acc=0.47777777910232544, loss=1.4142042398452759
train: epoch 62, loss 0.6323927640914917, acc=0.7094444632530212, loss=0.6323927640914917
test: epoch 62, loss 1.3782832622528076, acc=0.46666666865348816, loss=1.3782832622528076
train: epoch 63, loss 0.625092625617981, acc=0.7100555300712585, loss=0.625092625617981
test: epoch 63, loss 1.319313883781433, acc=0.46666666865348816, loss=1.319313883781433
train: epoch 64, loss 0.6327114701271057, acc=0.7110555768013, loss=0.6327114701271057
test: epoch 64, loss 1.3598365783691406, acc=0.4694444537162781, loss=1.3598365783691406
train: epoch 65, loss 0.6411725282669067, acc=0.7097222208976746, loss=0.6411725282669067
test: epoch 65, loss 1.2702782154083252, acc=0.46666666865348816, loss=1.2702782154083252
train: epoch 66, loss 0.616277813911438, acc=0.7160000205039978, loss=0.616277813911438
test: epoch 66, loss 1.3278748989105225, acc=0.4694444537162781, loss=1.3278748989105225
train: epoch 67, loss 0.6365888714790344, acc=0.7110555768013, loss=0.6365888714790344
test: epoch 67, loss 1.2620819807052612, acc=0.46666666865348816, loss=1.2620819807052612
train: epoch 68, loss 0.6336364150047302, acc=0.7122777700424194, loss=0.6336364150047302
test: epoch 68, loss 1.3253568410873413, acc=0.4722222089767456, loss=1.3253568410873413
train: epoch 69, loss 0.6169565916061401, acc=0.7222777605056763, loss=0.6169565916061401
test: epoch 69, loss 1.451169490814209, acc=0.4722222089767456, loss=1.451169490814209
train: epoch 70, loss 0.6090243458747864, acc=0.7306666374206543, loss=0.6090243458747864
test: epoch 70, loss 1.2867783308029175, acc=0.4722222089767456, loss=1.2867783308029175
train: epoch 71, loss 0.5797776579856873, acc=0.7409999966621399, loss=0.5797776579856873
test: epoch 71, loss 1.35149085521698, acc=0.4722222089767456, loss=1.35149085521698
train: epoch 72, loss 0.5711877942085266, acc=0.7434444427490234, loss=0.5711877942085266
test: epoch 72, loss 1.365512490272522, acc=0.4722222089767456, loss=1.365512490272522
train: epoch 73, loss 0.5472526550292969, acc=0.7523333430290222, loss=0.5472526550292969
test: epoch 73, loss 1.3510392904281616, acc=0.4722222089767456, loss=1.3510392904281616
train: epoch 74, loss 0.5652351975440979, acc=0.7446666955947876, loss=0.5652351975440979
test: epoch 74, loss 1.4140762090682983, acc=0.4722222089767456, loss=1.4140762090682983
train: epoch 75, loss 0.5744317173957825, acc=0.7431111335754395, loss=0.5744317173957825
test: epoch 75, loss 1.2862935066223145, acc=0.4722222089767456, loss=1.2862935066223145
train: epoch 76, loss 0.5528183579444885, acc=0.7493888735771179, loss=0.5528183579444885
test: epoch 76, loss 1.3669503927230835, acc=0.4722222089767456, loss=1.3669503927230835
train: epoch 77, loss 0.5616355538368225, acc=0.7494444251060486, loss=0.5616355538368225
test: epoch 77, loss 1.5348975658416748, acc=0.4722222089767456, loss=1.5348975658416748
train: epoch 78, loss 0.5721321702003479, acc=0.7429999709129333, loss=0.5721321702003479
test: epoch 78, loss 1.3966059684753418, acc=0.4722222089767456, loss=1.3966059684753418
train: epoch 79, loss 0.5601567029953003, acc=0.7521666884422302, loss=0.5601567029953003
test: epoch 79, loss 1.3372218608856201, acc=0.4611110985279083, loss=1.3372218608856201
train: epoch 80, loss 0.5646602511405945, acc=0.7441111207008362, loss=0.5646602511405945
test: epoch 80, loss 1.3285553455352783, acc=0.4722222089767456, loss=1.3285553455352783
train: epoch 81, loss 0.5563054084777832, acc=0.7481666803359985, loss=0.5563054084777832
test: epoch 81, loss 1.5234543085098267, acc=0.4694444537162781, loss=1.5234543085098267
train: epoch 82, loss 0.5393450260162354, acc=0.7561666369438171, loss=0.5393450260162354
test: epoch 82, loss 1.5340373516082764, acc=0.4722222089767456, loss=1.5340373516082764
train: epoch 83, loss 0.5509019494056702, acc=0.7509444355964661, loss=0.5509019494056702
test: epoch 83, loss 1.2723758220672607, acc=0.46388888359069824, loss=1.2723758220672607
train: epoch 84, loss 0.5603972673416138, acc=0.7476666569709778, loss=0.5603972673416138
test: epoch 84, loss 1.398007869720459, acc=0.4694444537162781, loss=1.398007869720459
train: epoch 85, loss 0.5443477630615234, acc=0.7496111392974854, loss=0.5443477630615234
test: epoch 85, loss 1.3746119737625122, acc=0.4722222089767456, loss=1.3746119737625122
train: epoch 86, loss 0.5462632775306702, acc=0.7484444379806519, loss=0.5462632775306702
test: epoch 86, loss 1.373122215270996, acc=0.4694444537162781, loss=1.373122215270996
train: epoch 87, loss 0.5570817589759827, acc=0.7498888969421387, loss=0.5570817589759827
test: epoch 87, loss 1.4838796854019165, acc=0.4722222089767456, loss=1.4838796854019165
train: epoch 88, loss 0.531833827495575, acc=0.7567222118377686, loss=0.531833827495575
test: epoch 88, loss 1.4841517210006714, acc=0.4722222089767456, loss=1.4841517210006714
train: epoch 89, loss 0.5417317152023315, acc=0.7558888792991638, loss=0.5417317152023315
test: epoch 89, loss 1.4736121892929077, acc=0.4722222089767456, loss=1.4736121892929077
train: epoch 90, loss 0.5492488741874695, acc=0.7535555362701416, loss=0.5492488741874695
test: epoch 90, loss 1.4409371614456177, acc=0.4722222089767456, loss=1.4409371614456177
train: epoch 91, loss 0.529291570186615, acc=0.75727778673172, loss=0.529291570186615
test: epoch 91, loss 1.4470995664596558, acc=0.4722222089767456, loss=1.4470995664596558
train: epoch 92, loss 0.5405362248420715, acc=0.7543333172798157, loss=0.5405362248420715
test: epoch 92, loss 1.4357848167419434, acc=0.46666666865348816, loss=1.4357848167419434
train: epoch 93, loss 0.5424202680587769, acc=0.7541666626930237, loss=0.5424202680587769
test: epoch 93, loss 1.5533678531646729, acc=0.4722222089767456, loss=1.5533678531646729
train: epoch 94, loss 0.5346880555152893, acc=0.758055567741394, loss=0.5346880555152893
test: epoch 94, loss 1.3101204633712769, acc=0.4694444537162781, loss=1.3101204633712769
train: epoch 95, loss 0.5242373943328857, acc=0.7608888745307922, loss=0.5242373943328857
test: epoch 95, loss 1.4999324083328247, acc=0.4722222089767456, loss=1.4999324083328247
train: epoch 96, loss 0.532767117023468, acc=0.7582777738571167, loss=0.532767117023468
test: epoch 96, loss 1.6129792928695679, acc=0.4694444537162781, loss=1.6129792928695679
train: epoch 97, loss 0.5394148826599121, acc=0.7549444437026978, loss=0.5394148826599121
test: epoch 97, loss 1.5745679140090942, acc=0.4722222089767456, loss=1.5745679140090942
train: epoch 98, loss 0.5551536083221436, acc=0.7517222166061401, loss=0.5551536083221436
test: epoch 98, loss 1.5281518697738647, acc=0.46388888359069824, loss=1.5281518697738647
train: epoch 99, loss 0.5076614022254944, acc=0.7682777643203735, loss=0.5076614022254944
test: epoch 99, loss 1.6034585237503052, acc=0.4722222089767456, loss=1.6034585237503052
train: epoch 100, loss 0.5215553641319275, acc=0.7614444494247437, loss=0.5215553641319275
test: epoch 100, loss 1.3675663471221924, acc=0.4722222089767456, loss=1.3675663471221924
train: epoch 101, loss 0.5394794344902039, acc=0.7563333511352539, loss=0.5394794344902039
test: epoch 101, loss 1.4837541580200195, acc=0.4694444537162781, loss=1.4837541580200195
train: epoch 102, loss 0.5395647883415222, acc=0.7567777633666992, loss=0.5395647883415222
test: epoch 102, loss 1.484889268875122, acc=0.4694444537162781, loss=1.484889268875122
train: epoch 103, loss 0.5250194668769836, acc=0.7587777972221375, loss=0.5250194668769836
test: epoch 103, loss 1.5588079690933228, acc=0.4722222089767456, loss=1.5588079690933228
train: epoch 104, loss 0.5344652533531189, acc=0.7607222199440002, loss=0.5344652533531189
test: epoch 104, loss 1.3580060005187988, acc=0.4583333432674408, loss=1.3580060005187988
train: epoch 105, loss 0.530182957649231, acc=0.75855553150177, loss=0.530182957649231
test: epoch 105, loss 1.5512032508850098, acc=0.4722222089767456, loss=1.5512032508850098
train: epoch 106, loss 0.51724773645401, acc=0.7637777924537659, loss=0.51724773645401
test: epoch 106, loss 1.4026685953140259, acc=0.4694444537162781, loss=1.4026685953140259
train: epoch 107, loss 0.5195854902267456, acc=0.7636111378669739, loss=0.5195854902267456
test: epoch 107, loss 1.4685680866241455, acc=0.4694444537162781, loss=1.4685680866241455
train: epoch 108, loss 0.5163541436195374, acc=0.7645555734634399, loss=0.5163541436195374
test: epoch 108, loss 1.5379738807678223, acc=0.4611110985279083, loss=1.5379738807678223
train: epoch 109, loss 0.5336612462997437, acc=0.7617777585983276, loss=0.5336612462997437
test: epoch 109, loss 1.4027444124221802, acc=0.4722222089767456, loss=1.4027444124221802
train: epoch 110, loss 0.5294559597969055, acc=0.7616111040115356, loss=0.5294559597969055
test: epoch 110, loss 1.4208440780639648, acc=0.4694444537162781, loss=1.4208440780639648
train: epoch 111, loss 0.515616774559021, acc=0.7658888697624207, loss=0.515616774559021
test: epoch 111, loss 1.4473626613616943, acc=0.4611110985279083, loss=1.4473626613616943
train: epoch 112, loss 0.5169264674186707, acc=0.7636666893959045, loss=0.5169264674186707
test: epoch 112, loss 1.448691487312317, acc=0.4694444537162781, loss=1.448691487312317
train: epoch 113, loss 0.5091392397880554, acc=0.7672777771949768, loss=0.5091392397880554
test: epoch 113, loss 1.620930552482605, acc=0.4722222089767456, loss=1.620930552482605
train: epoch 114, loss 0.5894747376441956, acc=0.7388888597488403, loss=0.5894747376441956
test: epoch 114, loss 1.359764575958252, acc=0.4333333373069763, loss=1.359764575958252
train: epoch 115, loss 0.5610814690589905, acc=0.7433888912200928, loss=0.5610814690589905
test: epoch 115, loss 1.498518943786621, acc=0.46666666865348816, loss=1.498518943786621
train: epoch 116, loss 0.5005893707275391, acc=0.7674999833106995, loss=0.5005893707275391
test: epoch 116, loss 1.573403239250183, acc=0.4749999940395355, loss=1.573403239250183
train: epoch 117, loss 0.5044649839401245, acc=0.7684444189071655, loss=0.5044649839401245
test: epoch 117, loss 1.5143307447433472, acc=0.4722222089767456, loss=1.5143307447433472
train: epoch 118, loss 0.512065589427948, acc=0.765500009059906, loss=0.512065589427948
test: epoch 118, loss 1.4187296628952026, acc=0.4722222089767456, loss=1.4187296628952026
train: epoch 119, loss 0.5189025402069092, acc=0.7636111378669739, loss=0.5189025402069092
test: epoch 119, loss 1.4611310958862305, acc=0.4694444537162781, loss=1.4611310958862305
train: epoch 120, loss 0.48458391427993774, acc=0.772777795791626, loss=0.48458391427993774
test: epoch 120, loss 1.6635271310806274, acc=0.4694444537162781, loss=1.6635271310806274
train: epoch 121, loss 0.4950423836708069, acc=0.7719444632530212, loss=0.4950423836708069
test: epoch 121, loss 1.4733704328536987, acc=0.4722222089767456, loss=1.4733704328536987
train: epoch 122, loss 0.5077584981918335, acc=0.768666684627533, loss=0.5077584981918335
test: epoch 122, loss 1.585511326789856, acc=0.4694444537162781, loss=1.585511326789856
train: epoch 123, loss 0.5259653329849243, acc=0.7604444622993469, loss=0.5259653329849243
test: epoch 123, loss 1.5940117835998535, acc=0.4583333432674408, loss=1.5940117835998535
train: epoch 124, loss 0.495845764875412, acc=0.7682777643203735, loss=0.495845764875412
test: epoch 124, loss 1.6096062660217285, acc=0.4722222089767456, loss=1.6096062660217285
train: epoch 125, loss 0.4879467189311981, acc=0.7754999995231628, loss=0.4879467189311981
test: epoch 125, loss 1.6651397943496704, acc=0.4722222089767456, loss=1.6651397943496704
train: epoch 126, loss 0.5044984817504883, acc=0.7712777853012085, loss=0.5044984817504883
test: epoch 126, loss 1.5686644315719604, acc=0.4583333432674408, loss=1.5686644315719604
train: epoch 127, loss 0.49491164088249207, acc=0.7716110944747925, loss=0.49491164088249207
test: epoch 127, loss 1.6365846395492554, acc=0.4722222089767456, loss=1.6365846395492554
train: epoch 128, loss 0.5093108415603638, acc=0.7672777771949768, loss=0.5093108415603638
test: epoch 128, loss 1.4497393369674683, acc=0.4722222089767456, loss=1.4497393369674683
train: epoch 129, loss 0.5094678997993469, acc=0.7682777643203735, loss=0.5094678997993469
test: epoch 129, loss 1.444177269935608, acc=0.4694444537162781, loss=1.444177269935608
train: epoch 130, loss 0.48501017689704895, acc=0.7743333578109741, loss=0.48501017689704895
test: epoch 130, loss 1.532046914100647, acc=0.4722222089767456, loss=1.532046914100647
train: epoch 131, loss 0.5275786519050598, acc=0.762499988079071, loss=0.5275786519050598
test: epoch 131, loss 1.5328257083892822, acc=0.4694444537162781, loss=1.5328257083892822
train: epoch 132, loss 0.4912382662296295, acc=0.772777795791626, loss=0.4912382662296295
test: epoch 132, loss 1.6333492994308472, acc=0.4722222089767456, loss=1.6333492994308472
train: epoch 133, loss 0.4840056598186493, acc=0.7725555300712585, loss=0.4840056598186493
test: epoch 133, loss 1.6147651672363281, acc=0.4694444537162781, loss=1.6147651672363281
train: epoch 134, loss 0.5121551752090454, acc=0.7653889060020447, loss=0.5121551752090454
test: epoch 134, loss 1.6143335103988647, acc=0.46388888359069824, loss=1.6143335103988647
train: epoch 135, loss 0.505990743637085, acc=0.7647222280502319, loss=0.505990743637085
test: epoch 135, loss 1.4912011623382568, acc=0.4722222089767456, loss=1.4912011623382568
train: epoch 136, loss 0.4969518780708313, acc=0.7720555663108826, loss=0.4969518780708313
test: epoch 136, loss 1.458777904510498, acc=0.4749999940395355, loss=1.458777904510498
train: epoch 137, loss 0.48971158266067505, acc=0.7731666564941406, loss=0.48971158266067505
test: epoch 137, loss 1.6071245670318604, acc=0.47777777910232544, loss=1.6071245670318604
train: epoch 138, loss 0.49048498272895813, acc=0.7712777853012085, loss=0.49048498272895813
test: epoch 138, loss 1.5497645139694214, acc=0.4611110985279083, loss=1.5497645139694214
train: epoch 139, loss 0.5250079035758972, acc=0.7663333415985107, loss=0.5250079035758972
test: epoch 139, loss 1.5122321844100952, acc=0.4722222089767456, loss=1.5122321844100952
train: epoch 140, loss 0.4869706332683563, acc=0.7791110873222351, loss=0.4869706332683563
test: epoch 140, loss 1.4107431173324585, acc=0.48055556416511536, loss=1.4107431173324585
train: epoch 141, loss 0.48391807079315186, acc=0.7789999842643738, loss=0.48391807079315186
test: epoch 141, loss 1.4078644514083862, acc=0.4722222089767456, loss=1.4078644514083862
train: epoch 142, loss 0.4807244539260864, acc=0.7785000205039978, loss=0.4807244539260864
test: epoch 142, loss 1.5544865131378174, acc=0.4749999940395355, loss=1.5544865131378174
train: epoch 143, loss 0.521490752696991, acc=0.7609444260597229, loss=0.521490752696991
test: epoch 143, loss 1.4319803714752197, acc=0.48055556416511536, loss=1.4319803714752197
train: epoch 144, loss 0.5395210981369019, acc=0.7540000081062317, loss=0.5395210981369019
test: epoch 144, loss 1.3567792177200317, acc=0.48055556416511536, loss=1.3567792177200317
train: epoch 145, loss 0.49501925706863403, acc=0.7668889164924622, loss=0.49501925706863403
test: epoch 145, loss 1.5815458297729492, acc=0.4694444537162781, loss=1.5815458297729492
train: epoch 146, loss 0.4942122995853424, acc=0.7699999809265137, loss=0.4942122995853424
test: epoch 146, loss 1.5568037033081055, acc=0.48055556416511536, loss=1.5568037033081055
train: epoch 147, loss 0.5056260824203491, acc=0.7646666765213013, loss=0.5056260824203491
test: epoch 147, loss 1.410257339477539, acc=0.48055556416511536, loss=1.410257339477539
train: epoch 148, loss 0.49160340428352356, acc=0.7672222256660461, loss=0.49160340428352356
test: epoch 148, loss 1.3506484031677246, acc=0.5027777552604675, loss=1.3506484031677246
train: epoch 149, loss 0.47569170594215393, acc=0.7737777829170227, loss=0.47569170594215393
test: epoch 149, loss 1.5517240762710571, acc=0.49444442987442017, loss=1.5517240762710571
train: epoch 150, loss 0.4883548319339752, acc=0.7698333263397217, loss=0.4883548319339752
test: epoch 150, loss 1.3943623304367065, acc=0.5083333253860474, loss=1.3943623304367065
