# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=1", "--one_hot=false", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1782917841, receiver_embed_dim=64, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.2237327098846436, acc=0.07188888639211655, loss=3.2237327098846436
test: epoch 1, loss 4.868708610534668, acc=0.06388889253139496, loss=4.868708610534668
train: epoch 2, loss 2.0104782581329346, acc=0.29649999737739563, loss=2.0104782581329346
test: epoch 2, loss 3.675837516784668, acc=0.13055555522441864, loss=3.675837516784668
train: epoch 3, loss 1.402330994606018, acc=0.45233333110809326, loss=1.402330994606018
test: epoch 3, loss 3.48354172706604, acc=0.14444445073604584, loss=3.48354172706604
train: epoch 4, loss 1.1820610761642456, acc=0.5347222089767456, loss=1.1820610761642456
test: epoch 4, loss 3.684084177017212, acc=0.16111111640930176, loss=3.684084177017212
train: epoch 5, loss 1.041374921798706, acc=0.5903333425521851, loss=1.041374921798706
test: epoch 5, loss 3.5718512535095215, acc=0.16944444179534912, loss=3.5718512535095215
train: epoch 6, loss 0.9446648955345154, acc=0.6322222352027893, loss=0.9446648955345154
test: epoch 6, loss 3.6390233039855957, acc=0.17499999701976776, loss=3.6390233039855957
train: epoch 7, loss 0.8642928600311279, acc=0.668666660785675, loss=0.8642928600311279
test: epoch 7, loss 3.712264060974121, acc=0.1666666716337204, loss=3.712264060974121
train: epoch 8, loss 0.7917182445526123, acc=0.698888897895813, loss=0.7917182445526123
test: epoch 8, loss 3.4428651332855225, acc=0.1944444477558136, loss=3.4428651332855225
train: epoch 9, loss 0.7269390225410461, acc=0.7250000238418579, loss=0.7269390225410461
test: epoch 9, loss 3.2528481483459473, acc=0.20555555820465088, loss=3.2528481483459473
train: epoch 10, loss 0.6772520542144775, acc=0.7484999895095825, loss=0.6772520542144775
test: epoch 10, loss 3.227215051651001, acc=0.22499999403953552, loss=3.227215051651001
train: epoch 11, loss 0.626029372215271, acc=0.7717777490615845, loss=0.626029372215271
test: epoch 11, loss 3.068896532058716, acc=0.21388888359069824, loss=3.068896532058716
train: epoch 12, loss 0.6067646741867065, acc=0.778166651725769, loss=0.6067646741867065
test: epoch 12, loss 2.904893398284912, acc=0.22777777910232544, loss=2.904893398284912
train: epoch 13, loss 0.5611127018928528, acc=0.7956110835075378, loss=0.5611127018928528
test: epoch 13, loss 2.885188102722168, acc=0.2083333283662796, loss=2.885188102722168
train: epoch 14, loss 0.5314445495605469, acc=0.8045555353164673, loss=0.5314445495605469
test: epoch 14, loss 2.7702648639678955, acc=0.22499999403953552, loss=2.7702648639678955
train: epoch 15, loss 0.49280381202697754, acc=0.823722243309021, loss=0.49280381202697754
test: epoch 15, loss 2.7479379177093506, acc=0.27222222089767456, loss=2.7479379177093506
train: epoch 16, loss 0.4593760669231415, acc=0.8313888907432556, loss=0.4593760669231415
test: epoch 16, loss 2.8241641521453857, acc=0.2638888955116272, loss=2.8241641521453857
train: epoch 17, loss 0.4501619040966034, acc=0.8417222499847412, loss=0.4501619040966034
test: epoch 17, loss 3.2721610069274902, acc=0.24166665971279144, loss=3.2721610069274902
train: epoch 18, loss 0.41969895362854004, acc=0.8526666760444641, loss=0.41969895362854004
test: epoch 18, loss 2.986532211303711, acc=0.24722221493721008, loss=2.986532211303711
train: epoch 19, loss 0.403623104095459, acc=0.8604444265365601, loss=0.403623104095459
test: epoch 19, loss 2.520922899246216, acc=0.3055555522441864, loss=2.520922899246216
train: epoch 20, loss 0.38439351320266724, acc=0.8652222156524658, loss=0.38439351320266724
test: epoch 20, loss 2.6456730365753174, acc=0.31388887763023376, loss=2.6456730365753174
train: epoch 21, loss 0.3596145808696747, acc=0.8736110925674438, loss=0.3596145808696747
test: epoch 21, loss 2.7174670696258545, acc=0.3222222328186035, loss=2.7174670696258545
train: epoch 22, loss 0.34479621052742004, acc=0.8805555701255798, loss=0.34479621052742004
test: epoch 22, loss 2.547675371170044, acc=0.28611111640930176, loss=2.547675371170044
train: epoch 23, loss 0.34037601947784424, acc=0.8849999904632568, loss=0.34037601947784424
test: epoch 23, loss 2.5849356651306152, acc=0.25, loss=2.5849356651306152
train: epoch 24, loss 0.3248271048069, acc=0.8894444704055786, loss=0.3248271048069
test: epoch 24, loss 2.479177474975586, acc=0.32499998807907104, loss=2.479177474975586
train: epoch 25, loss 0.31383705139160156, acc=0.8917222023010254, loss=0.31383705139160156
test: epoch 25, loss 2.682410478591919, acc=0.28333333134651184, loss=2.682410478591919
train: epoch 26, loss 0.28989070653915405, acc=0.9004999995231628, loss=0.28989070653915405
test: epoch 26, loss 2.3539233207702637, acc=0.31388887763023376, loss=2.3539233207702637
train: epoch 27, loss 0.28150704503059387, acc=0.9052222371101379, loss=0.28150704503059387
test: epoch 27, loss 2.6460793018341064, acc=0.3166666626930237, loss=2.6460793018341064
train: epoch 28, loss 0.2645246088504791, acc=0.9117222428321838, loss=0.2645246088504791
test: epoch 28, loss 2.3656909465789795, acc=0.3055555522441864, loss=2.3656909465789795
train: epoch 29, loss 0.2649281919002533, acc=0.9135000109672546, loss=0.2649281919002533
test: epoch 29, loss 2.5001003742218018, acc=0.3055555522441864, loss=2.5001003742218018
train: epoch 30, loss 0.25419971346855164, acc=0.9171110987663269, loss=0.25419971346855164
test: epoch 30, loss 2.2232718467712402, acc=0.30000001192092896, loss=2.2232718467712402
train: epoch 31, loss 0.25172463059425354, acc=0.9192222356796265, loss=0.25172463059425354
test: epoch 31, loss 2.417245388031006, acc=0.3166666626930237, loss=2.417245388031006
train: epoch 32, loss 0.24297529458999634, acc=0.9174444675445557, loss=0.24297529458999634
test: epoch 32, loss 2.584453821182251, acc=0.3305555582046509, loss=2.584453821182251
train: epoch 33, loss 0.2281506359577179, acc=0.9231111407279968, loss=0.2281506359577179
test: epoch 33, loss 2.402437686920166, acc=0.32777777314186096, loss=2.402437686920166
train: epoch 34, loss 0.22060739994049072, acc=0.9268888831138611, loss=0.22060739994049072
test: epoch 34, loss 2.443488597869873, acc=0.3861111104488373, loss=2.443488597869873
train: epoch 35, loss 0.21745935082435608, acc=0.9298333525657654, loss=0.21745935082435608
test: epoch 35, loss 2.2667152881622314, acc=0.3333333432674408, loss=2.2667152881622314
train: epoch 36, loss 0.2123379111289978, acc=0.9307222366333008, loss=0.2123379111289978
test: epoch 36, loss 2.520535707473755, acc=0.3305555582046509, loss=2.520535707473755
train: epoch 37, loss 0.2047004997730255, acc=0.9342222213745117, loss=0.2047004997730255
test: epoch 37, loss 2.5116405487060547, acc=0.3166666626930237, loss=2.5116405487060547
train: epoch 38, loss 0.20019416511058807, acc=0.9346666932106018, loss=0.20019416511058807
test: epoch 38, loss 2.359170913696289, acc=0.3083333373069763, loss=2.359170913696289
train: epoch 39, loss 0.18478453159332275, acc=0.9411110877990723, loss=0.18478453159332275
test: epoch 39, loss 2.2392566204071045, acc=0.39722222089767456, loss=2.2392566204071045
train: epoch 40, loss 0.18586355447769165, acc=0.9384444355964661, loss=0.18586355447769165
test: epoch 40, loss 2.368143320083618, acc=0.33888888359069824, loss=2.368143320083618
train: epoch 41, loss 0.1674412339925766, acc=0.9449999928474426, loss=0.1674412339925766
test: epoch 41, loss 2.055237293243408, acc=0.3722222149372101, loss=2.055237293243408
train: epoch 42, loss 0.17451395094394684, acc=0.944611132144928, loss=0.17451395094394684
test: epoch 42, loss 2.275749444961548, acc=0.36666667461395264, loss=2.275749444961548
train: epoch 43, loss 0.16462410986423492, acc=0.9473888874053955, loss=0.16462410986423492
test: epoch 43, loss 2.1107378005981445, acc=0.38055557012557983, loss=2.1107378005981445
train: epoch 44, loss 0.16615429520606995, acc=0.9461666941642761, loss=0.16615429520606995
test: epoch 44, loss 2.281872510910034, acc=0.4000000059604645, loss=2.281872510910034
train: epoch 45, loss 0.1696545034646988, acc=0.9467222094535828, loss=0.1696545034646988
test: epoch 45, loss 2.489271879196167, acc=0.3361110985279083, loss=2.489271879196167
train: epoch 46, loss 0.1632971465587616, acc=0.9492777585983276, loss=0.1632971465587616
test: epoch 46, loss 2.4453399181365967, acc=0.3777777850627899, loss=2.4453399181365967
train: epoch 47, loss 0.1488114893436432, acc=0.9549999833106995, loss=0.1488114893436432
test: epoch 47, loss 2.4692442417144775, acc=0.36944442987442017, loss=2.4692442417144775
train: epoch 48, loss 0.15313094854354858, acc=0.949833333492279, loss=0.15313094854354858
test: epoch 48, loss 2.468414306640625, acc=0.3444444537162781, loss=2.468414306640625
train: epoch 49, loss 0.15266153216362, acc=0.9539999961853027, loss=0.15266153216362
test: epoch 49, loss 2.2118377685546875, acc=0.4027777910232544, loss=2.2118377685546875
train: epoch 50, loss 0.14247216284275055, acc=0.9544444680213928, loss=0.14247216284275055
test: epoch 50, loss 2.284698486328125, acc=0.40833333134651184, loss=2.284698486328125
train: epoch 51, loss 0.13592873513698578, acc=0.9579444527626038, loss=0.13592873513698578
test: epoch 51, loss 2.5563080310821533, acc=0.35277777910232544, loss=2.5563080310821533
train: epoch 52, loss 0.1299743503332138, acc=0.9564999938011169, loss=0.1299743503332138
test: epoch 52, loss 2.324129343032837, acc=0.35555556416511536, loss=2.324129343032837
train: epoch 53, loss 0.1373506337404251, acc=0.9568889141082764, loss=0.1373506337404251
test: epoch 53, loss 2.545358657836914, acc=0.42222222685813904, loss=2.545358657836914
train: epoch 54, loss 0.1288854479789734, acc=0.9598333239555359, loss=0.1288854479789734
test: epoch 54, loss 2.234004497528076, acc=0.42222222685813904, loss=2.234004497528076
train: epoch 55, loss 0.11950521171092987, acc=0.9618889093399048, loss=0.11950521171092987
test: epoch 55, loss 2.311328411102295, acc=0.39722222089767456, loss=2.311328411102295
train: epoch 56, loss 0.12557737529277802, acc=0.961388885974884, loss=0.12557737529277802
test: epoch 56, loss 2.5205893516540527, acc=0.3472222089767456, loss=2.5205893516540527
train: epoch 57, loss 0.12451574951410294, acc=0.9638333320617676, loss=0.12451574951410294
test: epoch 57, loss 2.434361219406128, acc=0.4055555462837219, loss=2.434361219406128
train: epoch 58, loss 0.1185409277677536, acc=0.9618333578109741, loss=0.1185409277677536
test: epoch 58, loss 2.540097951889038, acc=0.35555556416511536, loss=2.540097951889038
train: epoch 59, loss 0.11638030409812927, acc=0.9665555357933044, loss=0.11638030409812927
test: epoch 59, loss 2.565507411956787, acc=0.4194444417953491, loss=2.565507411956787
train: epoch 60, loss 0.11394864320755005, acc=0.9632777571678162, loss=0.11394864320755005
test: epoch 60, loss 2.449352741241455, acc=0.4027777910232544, loss=2.449352741241455
train: epoch 61, loss 0.10728061944246292, acc=0.9684444665908813, loss=0.10728061944246292
test: epoch 61, loss 2.505730152130127, acc=0.38333332538604736, loss=2.505730152130127
train: epoch 62, loss 0.10562717914581299, acc=0.9700555801391602, loss=0.10562717914581299
test: epoch 62, loss 2.678558349609375, acc=0.3499999940395355, loss=2.678558349609375
train: epoch 63, loss 0.11564594507217407, acc=0.9651666879653931, loss=0.11564594507217407
test: epoch 63, loss 2.4743645191192627, acc=0.3861111104488373, loss=2.4743645191192627
train: epoch 64, loss 0.1133015900850296, acc=0.9672222137451172, loss=0.1133015900850296
test: epoch 64, loss 2.1459639072418213, acc=0.3888888955116272, loss=2.1459639072418213
train: epoch 65, loss 0.10685816407203674, acc=0.9667778015136719, loss=0.10685816407203674
test: epoch 65, loss 2.5555717945098877, acc=0.42222222685813904, loss=2.5555717945098877
train: epoch 66, loss 0.10171549022197723, acc=0.9704999923706055, loss=0.10171549022197723
test: epoch 66, loss 2.4155240058898926, acc=0.4138889014720917, loss=2.4155240058898926
train: epoch 67, loss 0.09950003027915955, acc=0.968999981880188, loss=0.09950003027915955
test: epoch 67, loss 2.3846466541290283, acc=0.4277777671813965, loss=2.3846466541290283
train: epoch 68, loss 0.10480116307735443, acc=0.9695000052452087, loss=0.10480116307735443
test: epoch 68, loss 2.410048723220825, acc=0.43611112236976624, loss=2.410048723220825
train: epoch 69, loss 0.0931529626250267, acc=0.9716110825538635, loss=0.0931529626250267
test: epoch 69, loss 2.136282205581665, acc=0.4444444477558136, loss=2.136282205581665
train: epoch 70, loss 0.10311384499073029, acc=0.9692222476005554, loss=0.10311384499073029
test: epoch 70, loss 2.7476987838745117, acc=0.4333333373069763, loss=2.7476987838745117
train: epoch 71, loss 0.09437162429094315, acc=0.9722222089767456, loss=0.09437162429094315
test: epoch 71, loss 2.4934446811676025, acc=0.4055555462837219, loss=2.4934446811676025
train: epoch 72, loss 0.08503378182649612, acc=0.9750555753707886, loss=0.08503378182649612
test: epoch 72, loss 2.43462872505188, acc=0.4277777671813965, loss=2.43462872505188
train: epoch 73, loss 0.08534171432256699, acc=0.9723333120346069, loss=0.08534171432256699
test: epoch 73, loss 2.4998691082000732, acc=0.41111111640930176, loss=2.4998691082000732
train: epoch 74, loss 0.08894208073616028, acc=0.972944438457489, loss=0.08894208073616028
test: epoch 74, loss 2.424908399581909, acc=0.4444444477558136, loss=2.424908399581909
train: epoch 75, loss 0.08600294589996338, acc=0.9733333587646484, loss=0.08600294589996338
test: epoch 75, loss 2.738931655883789, acc=0.46388888359069824, loss=2.738931655883789
train: epoch 76, loss 0.08437485247850418, acc=0.9752222299575806, loss=0.08437485247850418
test: epoch 76, loss 2.7582509517669678, acc=0.4305555522441864, loss=2.7582509517669678
train: epoch 77, loss 0.0822615921497345, acc=0.9751666784286499, loss=0.0822615921497345
test: epoch 77, loss 2.8895726203918457, acc=0.39722222089767456, loss=2.8895726203918457
train: epoch 78, loss 0.07930835336446762, acc=0.9760555624961853, loss=0.07930835336446762
test: epoch 78, loss 2.620753765106201, acc=0.4333333373069763, loss=2.620753765106201
train: epoch 79, loss 0.08194012939929962, acc=0.9761666655540466, loss=0.08194012939929962
test: epoch 79, loss 2.551619529724121, acc=0.45277777314186096, loss=2.551619529724121
train: epoch 80, loss 0.0833970382809639, acc=0.9745555520057678, loss=0.0833970382809639
test: epoch 80, loss 2.451475143432617, acc=0.4333333373069763, loss=2.451475143432617
train: epoch 81, loss 0.08407120406627655, acc=0.9753888845443726, loss=0.08407120406627655
test: epoch 81, loss 2.478654623031616, acc=0.4833333194255829, loss=2.478654623031616
train: epoch 82, loss 0.08179740607738495, acc=0.9764444231987, loss=0.08179740607738495
test: epoch 82, loss 2.4696855545043945, acc=0.4305555522441864, loss=2.4696855545043945
train: epoch 83, loss 0.0698862075805664, acc=0.9766666889190674, loss=0.0698862075805664
test: epoch 83, loss 2.774061918258667, acc=0.4305555522441864, loss=2.774061918258667
train: epoch 84, loss 0.07666163146495819, acc=0.9776666760444641, loss=0.07666163146495819
test: epoch 84, loss 2.519407033920288, acc=0.46666666865348816, loss=2.519407033920288
train: epoch 85, loss 0.07989505678415298, acc=0.9773889183998108, loss=0.07989505678415298
test: epoch 85, loss 2.69450306892395, acc=0.49166667461395264, loss=2.69450306892395
train: epoch 86, loss 0.07793852686882019, acc=0.9773333072662354, loss=0.07793852686882019
test: epoch 86, loss 2.6668055057525635, acc=0.4555555582046509, loss=2.6668055057525635
train: epoch 87, loss 0.06460468471050262, acc=0.9808889031410217, loss=0.06460468471050262
test: epoch 87, loss 2.721181631088257, acc=0.4611110985279083, loss=2.721181631088257
train: epoch 88, loss 0.06594011187553406, acc=0.9815000295639038, loss=0.06594011187553406
test: epoch 88, loss 2.538647413253784, acc=0.4444444477558136, loss=2.538647413253784
train: epoch 89, loss 0.06351124495267868, acc=0.9810555577278137, loss=0.06351124495267868
test: epoch 89, loss 2.5059852600097656, acc=0.4861111044883728, loss=2.5059852600097656
train: epoch 90, loss 0.06553924828767776, acc=0.9808333516120911, loss=0.06553924828767776
test: epoch 90, loss 2.5720651149749756, acc=0.4000000059604645, loss=2.5720651149749756
train: epoch 91, loss 0.06961841881275177, acc=0.979888916015625, loss=0.06961841881275177
test: epoch 91, loss 2.5985474586486816, acc=0.5, loss=2.5985474586486816
train: epoch 92, loss 0.06566119194030762, acc=0.9806110858917236, loss=0.06566119194030762
test: epoch 92, loss 2.6504297256469727, acc=0.4166666567325592, loss=2.6504297256469727
train: epoch 93, loss 0.06855563074350357, acc=0.9813888669013977, loss=0.06855563074350357
test: epoch 93, loss 2.473090648651123, acc=0.3916666805744171, loss=2.473090648651123
train: epoch 94, loss 0.060354676097631454, acc=0.9813888669013977, loss=0.060354676097631454
test: epoch 94, loss 2.9060661792755127, acc=0.43888887763023376, loss=2.9060661792755127
train: epoch 95, loss 0.057792142033576965, acc=0.9838888645172119, loss=0.057792142033576965
test: epoch 95, loss 2.4830374717712402, acc=0.49444442987442017, loss=2.4830374717712402
train: epoch 96, loss 0.06042385846376419, acc=0.9821666479110718, loss=0.06042385846376419
test: epoch 96, loss 2.8274290561676025, acc=0.45277777314186096, loss=2.8274290561676025
train: epoch 97, loss 0.06331321597099304, acc=0.9811111092567444, loss=0.06331321597099304
test: epoch 97, loss 2.771655321121216, acc=0.39444443583488464, loss=2.771655321121216
train: epoch 98, loss 0.0528358519077301, acc=0.9837222099304199, loss=0.0528358519077301
test: epoch 98, loss 2.7030019760131836, acc=0.5027777552604675, loss=2.7030019760131836
train: epoch 99, loss 0.06322407722473145, acc=0.9819999933242798, loss=0.06322407722473145
test: epoch 99, loss 2.6483242511749268, acc=0.4833333194255829, loss=2.6483242511749268
train: epoch 100, loss 0.06299903988838196, acc=0.9810555577278137, loss=0.06299903988838196
test: epoch 100, loss 2.548557996749878, acc=0.5055555701255798, loss=2.548557996749878
train: epoch 101, loss 0.06018386408686638, acc=0.9828333258628845, loss=0.06018386408686638
test: epoch 101, loss 2.4903433322906494, acc=0.4888888895511627, loss=2.4903433322906494
train: epoch 102, loss 0.05332372710108757, acc=0.984499990940094, loss=0.05332372710108757
test: epoch 102, loss 2.6348400115966797, acc=0.4583333432674408, loss=2.6348400115966797
train: epoch 103, loss 0.0634598582983017, acc=0.9819444417953491, loss=0.0634598582983017
test: epoch 103, loss 2.777611255645752, acc=0.4694444537162781, loss=2.777611255645752
train: epoch 104, loss 0.05933200195431709, acc=0.9838888645172119, loss=0.05933200195431709
test: epoch 104, loss 2.878260612487793, acc=0.519444465637207, loss=2.878260612487793
train: epoch 105, loss 0.048851288855075836, acc=0.9860555529594421, loss=0.048851288855075836
test: epoch 105, loss 2.486863613128662, acc=0.5055555701255798, loss=2.486863613128662
train: epoch 106, loss 0.05246495455503464, acc=0.9848889112472534, loss=0.05246495455503464
test: epoch 106, loss 2.6248857975006104, acc=0.4861111044883728, loss=2.6248857975006104
train: epoch 107, loss 0.05395125970244408, acc=0.9848889112472534, loss=0.05395125970244408
test: epoch 107, loss 2.5990970134735107, acc=0.44999998807907104, loss=2.5990970134735107
train: epoch 108, loss 0.05107065662741661, acc=0.984666645526886, loss=0.05107065662741661
test: epoch 108, loss 2.7223410606384277, acc=0.4305555522441864, loss=2.7223410606384277
train: epoch 109, loss 0.060320448130369186, acc=0.9835000038146973, loss=0.060320448130369186
test: epoch 109, loss 2.8383045196533203, acc=0.4861111044883728, loss=2.8383045196533203
train: epoch 110, loss 0.05208029970526695, acc=0.9854444265365601, loss=0.05208029970526695
test: epoch 110, loss 2.5252573490142822, acc=0.4861111044883728, loss=2.5252573490142822
train: epoch 111, loss 0.047984909266233444, acc=0.9857777953147888, loss=0.047984909266233444
test: epoch 111, loss 2.602426290512085, acc=0.5305555462837219, loss=2.602426290512085
train: epoch 112, loss 0.057553742080926895, acc=0.984333336353302, loss=0.057553742080926895
test: epoch 112, loss 2.5872602462768555, acc=0.4833333194255829, loss=2.5872602462768555
train: epoch 113, loss 0.05156826600432396, acc=0.9858888983726501, loss=0.05156826600432396
test: epoch 113, loss 2.7117011547088623, acc=0.5, loss=2.7117011547088623
train: epoch 114, loss 0.04615882411599159, acc=0.9862777590751648, loss=0.04615882411599159
test: epoch 114, loss 2.6245248317718506, acc=0.5111111402511597, loss=2.6245248317718506
train: epoch 115, loss 0.04940993711352348, acc=0.9857777953147888, loss=0.04940993711352348
test: epoch 115, loss 2.8467941284179688, acc=0.4888888895511627, loss=2.8467941284179688
train: epoch 116, loss 0.05387099087238312, acc=0.9840555787086487, loss=0.05387099087238312
test: epoch 116, loss 2.6053099632263184, acc=0.49166667461395264, loss=2.6053099632263184
train: epoch 117, loss 0.05473097413778305, acc=0.9854999780654907, loss=0.05473097413778305
test: epoch 117, loss 2.512343645095825, acc=0.4888888895511627, loss=2.512343645095825
train: epoch 118, loss 0.052995335310697556, acc=0.9862222075462341, loss=0.052995335310697556
test: epoch 118, loss 2.221449851989746, acc=0.519444465637207, loss=2.221449851989746
train: epoch 119, loss 0.04565535858273506, acc=0.9869444370269775, loss=0.04565535858273506
test: epoch 119, loss 2.5911872386932373, acc=0.4722222089767456, loss=2.5911872386932373
train: epoch 120, loss 0.0436907634139061, acc=0.9866111278533936, loss=0.0436907634139061
test: epoch 120, loss 2.612793207168579, acc=0.5055555701255798, loss=2.612793207168579
train: epoch 121, loss 0.045840416103601456, acc=0.9858888983726501, loss=0.045840416103601456
test: epoch 121, loss 2.756300687789917, acc=0.49166667461395264, loss=2.756300687789917
train: epoch 122, loss 0.04454454779624939, acc=0.987500011920929, loss=0.04454454779624939
test: epoch 122, loss 2.3725814819335938, acc=0.5277777910232544, loss=2.3725814819335938
train: epoch 123, loss 0.047650232911109924, acc=0.9860555529594421, loss=0.047650232911109924
test: epoch 123, loss 3.2162117958068848, acc=0.4694444537162781, loss=3.2162117958068848
train: epoch 124, loss 0.045384228229522705, acc=0.9868888854980469, loss=0.045384228229522705
test: epoch 124, loss 2.9057180881500244, acc=0.5083333253860474, loss=2.9057180881500244
train: epoch 125, loss 0.04461770877242088, acc=0.987333357334137, loss=0.04461770877242088
test: epoch 125, loss 2.669193983078003, acc=0.5277777910232544, loss=2.669193983078003
train: epoch 126, loss 0.041636284440755844, acc=0.9878888726234436, loss=0.041636284440755844
test: epoch 126, loss 2.6317360401153564, acc=0.519444465637207, loss=2.6317360401153564
train: epoch 127, loss 0.04906105250120163, acc=0.9868888854980469, loss=0.04906105250120163
test: epoch 127, loss 2.7242774963378906, acc=0.49166667461395264, loss=2.7242774963378906
train: epoch 128, loss 0.045418642461299896, acc=0.9878333210945129, loss=0.045418642461299896
test: epoch 128, loss 2.8398518562316895, acc=0.5305555462837219, loss=2.8398518562316895
train: epoch 129, loss 0.042540885508060455, acc=0.988111138343811, loss=0.042540885508060455
test: epoch 129, loss 2.2275125980377197, acc=0.5583333373069763, loss=2.2275125980377197
train: epoch 130, loss 0.04511291906237602, acc=0.9874444603919983, loss=0.04511291906237602
test: epoch 130, loss 2.7035069465637207, acc=0.5638889074325562, loss=2.7035069465637207
train: epoch 131, loss 0.047037120908498764, acc=0.9864444732666016, loss=0.047037120908498764
test: epoch 131, loss 3.1162872314453125, acc=0.4555555582046509, loss=3.1162872314453125
train: epoch 132, loss 0.043995875865221024, acc=0.988277792930603, loss=0.043995875865221024
test: epoch 132, loss 2.7583484649658203, acc=0.5277777910232544, loss=2.7583484649658203
train: epoch 133, loss 0.04182811826467514, acc=0.988111138343811, loss=0.04182811826467514
test: epoch 133, loss 3.0798757076263428, acc=0.4555555582046509, loss=3.0798757076263428
train: epoch 134, loss 0.04456578940153122, acc=0.9883888959884644, loss=0.04456578940153122
test: epoch 134, loss 2.619044065475464, acc=0.5472221970558167, loss=2.619044065475464
train: epoch 135, loss 0.03992559388279915, acc=0.9891666769981384, loss=0.03992559388279915
test: epoch 135, loss 2.7205162048339844, acc=0.5444444417953491, loss=2.7205162048339844
train: epoch 136, loss 0.050228510051965714, acc=0.9850555658340454, loss=0.050228510051965714
test: epoch 136, loss 2.599710702896118, acc=0.5111111402511597, loss=2.599710702896118
train: epoch 137, loss 0.03477005288004875, acc=0.9901111125946045, loss=0.03477005288004875
test: epoch 137, loss 2.5536584854125977, acc=0.5444444417953491, loss=2.5536584854125977
train: epoch 138, loss 0.04200836271047592, acc=0.988611102104187, loss=0.04200836271047592
test: epoch 138, loss 2.782221555709839, acc=0.5277777910232544, loss=2.782221555709839
train: epoch 139, loss 0.042995013296604156, acc=0.9898333549499512, loss=0.042995013296604156
test: epoch 139, loss 2.606046438217163, acc=0.5583333373069763, loss=2.606046438217163
train: epoch 140, loss 0.041678473353385925, acc=0.9891111254692078, loss=0.041678473353385925
test: epoch 140, loss 2.785689115524292, acc=0.5055555701255798, loss=2.785689115524292
train: epoch 141, loss 0.03916051983833313, acc=0.9895555377006531, loss=0.03916051983833313
test: epoch 141, loss 2.77364182472229, acc=0.5388888716697693, loss=2.77364182472229
train: epoch 142, loss 0.03370821848511696, acc=0.9901111125946045, loss=0.03370821848511696
test: epoch 142, loss 2.7523674964904785, acc=0.5527777671813965, loss=2.7523674964904785
train: epoch 143, loss 0.04518364369869232, acc=0.9873889088630676, loss=0.04518364369869232
test: epoch 143, loss 3.225389242172241, acc=0.519444465637207, loss=3.225389242172241
train: epoch 144, loss 0.039919447153806686, acc=0.9900000095367432, loss=0.039919447153806686
test: epoch 144, loss 2.883870840072632, acc=0.5472221970558167, loss=2.883870840072632
train: epoch 145, loss 0.03631819412112236, acc=0.9904444217681885, loss=0.03631819412112236
test: epoch 145, loss 3.1156749725341797, acc=0.4861111044883728, loss=3.1156749725341797
train: epoch 146, loss 0.04902942478656769, acc=0.987666666507721, loss=0.04902942478656769
test: epoch 146, loss 2.8016414642333984, acc=0.5083333253860474, loss=2.8016414642333984
train: epoch 147, loss 0.03761344403028488, acc=0.9894444346427917, loss=0.03761344403028488
test: epoch 147, loss 2.9392168521881104, acc=0.5222222208976746, loss=2.9392168521881104
train: epoch 148, loss 0.04370615631341934, acc=0.9877777695655823, loss=0.04370615631341934
test: epoch 148, loss 2.6829352378845215, acc=0.5305555462837219, loss=2.6829352378845215
train: epoch 149, loss 0.04772825539112091, acc=0.9877777695655823, loss=0.04772825539112091
test: epoch 149, loss 2.5900027751922607, acc=0.5083333253860474, loss=2.5900027751922607
train: epoch 150, loss 0.03611632436513901, acc=0.9898333549499512, loss=0.03611632436513901
test: epoch 150, loss 2.946972370147705, acc=0.5111111402511597, loss=2.946972370147705
