# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=1.5", "--temp_decay=0.99", "--one_hot=false", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=192633050, receiver_embed_dim=64, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.8968777656555176, acc=0.09399999678134918, loss=2.8968777656555176
test: epoch 1, loss 2.9887654781341553, acc=0.1111111119389534, loss=2.9887654781341553
train: epoch 2, loss 1.906491994857788, acc=0.26261112093925476, loss=1.906491994857788
test: epoch 2, loss 3.2055892944335938, acc=0.13333334028720856, loss=3.2055892944335938
train: epoch 3, loss 1.3771718740463257, acc=0.4497777819633484, loss=1.3771718740463257
test: epoch 3, loss 3.000541925430298, acc=0.18611110746860504, loss=3.000541925430298
train: epoch 4, loss 1.1016770601272583, acc=0.5541666746139526, loss=1.1016770601272583
test: epoch 4, loss 2.4342029094696045, acc=0.23055554926395416, loss=2.4342029094696045
train: epoch 5, loss 0.9161580801010132, acc=0.6241666674613953, loss=0.9161580801010132
test: epoch 5, loss 2.2893829345703125, acc=0.2750000059604645, loss=2.2893829345703125
train: epoch 6, loss 0.8248624801635742, acc=0.6635555624961853, loss=0.8248624801635742
test: epoch 6, loss 2.001955509185791, acc=0.2777777910232544, loss=2.001955509185791
train: epoch 7, loss 0.7440003156661987, acc=0.6969444155693054, loss=0.7440003156661987
test: epoch 7, loss 2.1651527881622314, acc=0.30000001192092896, loss=2.1651527881622314
train: epoch 8, loss 0.7024945616722107, acc=0.7147777676582336, loss=0.7024945616722107
test: epoch 8, loss 1.987362027168274, acc=0.38055557012557983, loss=1.987362027168274
train: epoch 9, loss 0.652266800403595, acc=0.7322221994400024, loss=0.652266800403595
test: epoch 9, loss 1.968117356300354, acc=0.3638888895511627, loss=1.968117356300354
train: epoch 10, loss 0.6126976013183594, acc=0.7489444613456726, loss=0.6126976013183594
test: epoch 10, loss 1.8636112213134766, acc=0.3777777850627899, loss=1.8636112213134766
train: epoch 11, loss 0.5729356408119202, acc=0.768666684627533, loss=0.5729356408119202
test: epoch 11, loss 2.0537571907043457, acc=0.3222222328186035, loss=2.0537571907043457
train: epoch 12, loss 0.5803653597831726, acc=0.7631666660308838, loss=0.5803653597831726
test: epoch 12, loss 1.7135257720947266, acc=0.375, loss=1.7135257720947266
train: epoch 13, loss 0.5122860074043274, acc=0.7922222018241882, loss=0.5122860074043274
test: epoch 13, loss 1.8438643217086792, acc=0.3888888955116272, loss=1.8438643217086792
train: epoch 14, loss 0.5123079419136047, acc=0.7918333411216736, loss=0.5123079419136047
test: epoch 14, loss 1.9969003200531006, acc=0.3611111044883728, loss=1.9969003200531006
train: epoch 15, loss 0.4777251183986664, acc=0.8058333396911621, loss=0.4777251183986664
test: epoch 15, loss 2.0172111988067627, acc=0.3333333432674408, loss=2.0172111988067627
train: epoch 16, loss 0.4691876173019409, acc=0.8111666440963745, loss=0.4691876173019409
test: epoch 16, loss 1.6608548164367676, acc=0.43888887763023376, loss=1.6608548164367676
train: epoch 17, loss 0.45149967074394226, acc=0.816611111164093, loss=0.45149967074394226
test: epoch 17, loss 1.4863015413284302, acc=0.43888887763023376, loss=1.4863015413284302
train: epoch 18, loss 0.44906380772590637, acc=0.8172222375869751, loss=0.44906380772590637
test: epoch 18, loss 1.8956013917922974, acc=0.3916666805744171, loss=1.8956013917922974
train: epoch 19, loss 0.416931688785553, acc=0.828166663646698, loss=0.416931688785553
test: epoch 19, loss 1.7556942701339722, acc=0.3861111104488373, loss=1.7556942701339722
train: epoch 20, loss 0.41010782122612, acc=0.8323333263397217, loss=0.41010782122612
test: epoch 20, loss 1.5211470127105713, acc=0.4194444417953491, loss=1.5211470127105713
train: epoch 21, loss 0.410376638174057, acc=0.8296111226081848, loss=0.410376638174057
test: epoch 21, loss 1.7824549674987793, acc=0.43888887763023376, loss=1.7824549674987793
train: epoch 22, loss 0.38123396039009094, acc=0.8399999737739563, loss=0.38123396039009094
test: epoch 22, loss 1.6944361925125122, acc=0.45277777314186096, loss=1.6944361925125122
train: epoch 23, loss 0.38293683528900146, acc=0.840666651725769, loss=0.38293683528900146
test: epoch 23, loss 1.7615784406661987, acc=0.4333333373069763, loss=1.7615784406661987
train: epoch 24, loss 0.3860679566860199, acc=0.8401666879653931, loss=0.3860679566860199
test: epoch 24, loss 1.8952680826187134, acc=0.4277777671813965, loss=1.8952680826187134
train: epoch 25, loss 0.3527011275291443, acc=0.851111114025116, loss=0.3527011275291443
test: epoch 25, loss 1.5751582384109497, acc=0.48055556416511536, loss=1.5751582384109497
train: epoch 26, loss 0.3693709671497345, acc=0.8474444150924683, loss=0.3693709671497345
test: epoch 26, loss 1.9012597799301147, acc=0.4722222089767456, loss=1.9012597799301147
train: epoch 27, loss 0.356096476316452, acc=0.8495555520057678, loss=0.356096476316452
test: epoch 27, loss 1.5299420356750488, acc=0.46666666865348816, loss=1.5299420356750488
train: epoch 28, loss 0.34782370924949646, acc=0.8503333330154419, loss=0.34782370924949646
test: epoch 28, loss 1.8654741048812866, acc=0.4416666626930237, loss=1.8654741048812866
train: epoch 29, loss 0.34285783767700195, acc=0.8568333387374878, loss=0.34285783767700195
test: epoch 29, loss 1.5822547674179077, acc=0.5027777552604675, loss=1.5822547674179077
train: epoch 30, loss 0.34147560596466064, acc=0.8542777895927429, loss=0.34147560596466064
test: epoch 30, loss 1.6610013246536255, acc=0.4833333194255829, loss=1.6610013246536255
train: epoch 31, loss 0.3288094103336334, acc=0.8589444160461426, loss=0.3288094103336334
test: epoch 31, loss 1.6616759300231934, acc=0.5333333611488342, loss=1.6616759300231934
train: epoch 32, loss 0.32413116097450256, acc=0.863777756690979, loss=0.32413116097450256
test: epoch 32, loss 1.3643336296081543, acc=0.5027777552604675, loss=1.3643336296081543
train: epoch 33, loss 0.33296865224838257, acc=0.8577222228050232, loss=0.33296865224838257
test: epoch 33, loss 1.7129689455032349, acc=0.4888888895511627, loss=1.7129689455032349
train: epoch 34, loss 0.31354814767837524, acc=0.8651111125946045, loss=0.31354814767837524
test: epoch 34, loss 1.370804786682129, acc=0.5027777552604675, loss=1.370804786682129
train: epoch 35, loss 0.32844462990760803, acc=0.859499990940094, loss=0.32844462990760803
test: epoch 35, loss 1.607643723487854, acc=0.550000011920929, loss=1.607643723487854
train: epoch 36, loss 0.3039803206920624, acc=0.8654444217681885, loss=0.3039803206920624
test: epoch 36, loss 1.6085232496261597, acc=0.5638889074325562, loss=1.6085232496261597
train: epoch 37, loss 0.29927125573158264, acc=0.8690555691719055, loss=0.29927125573158264
test: epoch 37, loss 1.4661298990249634, acc=0.5611110925674438, loss=1.4661298990249634
train: epoch 38, loss 0.30076518654823303, acc=0.8703888654708862, loss=0.30076518654823303
test: epoch 38, loss 0.9734366536140442, acc=0.574999988079071, loss=0.9734366536140442
train: epoch 39, loss 0.29691943526268005, acc=0.8716111183166504, loss=0.29691943526268005
test: epoch 39, loss 1.2007179260253906, acc=0.6499999761581421, loss=1.2007179260253906
train: epoch 40, loss 0.2995099425315857, acc=0.8732222318649292, loss=0.2995099425315857
test: epoch 40, loss 1.2779629230499268, acc=0.5972222089767456, loss=1.2779629230499268
train: epoch 41, loss 0.2940947413444519, acc=0.8717777729034424, loss=0.2940947413444519
test: epoch 41, loss 0.9365743398666382, acc=0.6694444417953491, loss=0.9365743398666382
train: epoch 42, loss 0.29272982478141785, acc=0.8729444742202759, loss=0.29272982478141785
test: epoch 42, loss 0.8865789175033569, acc=0.699999988079071, loss=0.8865789175033569
train: epoch 43, loss 0.26929011940956116, acc=0.8809999823570251, loss=0.26929011940956116
test: epoch 43, loss 0.8930457234382629, acc=0.6805555820465088, loss=0.8930457234382629
train: epoch 44, loss 0.2813856303691864, acc=0.8762221932411194, loss=0.2813856303691864
test: epoch 44, loss 0.7864441275596619, acc=0.6888889074325562, loss=0.7864441275596619
train: epoch 45, loss 0.2746771275997162, acc=0.8796666860580444, loss=0.2746771275997162
test: epoch 45, loss 0.946446418762207, acc=0.7055555582046509, loss=0.946446418762207
train: epoch 46, loss 0.26328203082084656, acc=0.8807222247123718, loss=0.26328203082084656
test: epoch 46, loss 0.7734668254852295, acc=0.7027778029441833, loss=0.7734668254852295
train: epoch 47, loss 0.27447858452796936, acc=0.8798333406448364, loss=0.27447858452796936
test: epoch 47, loss 0.7029017210006714, acc=0.7611111402511597, loss=0.7029017210006714
train: epoch 48, loss 0.2605283260345459, acc=0.8815000057220459, loss=0.2605283260345459
test: epoch 48, loss 0.7144817113876343, acc=0.7472222447395325, loss=0.7144817113876343
train: epoch 49, loss 0.26506567001342773, acc=0.8828333616256714, loss=0.26506567001342773
test: epoch 49, loss 0.6071897149085999, acc=0.7472222447395325, loss=0.6071897149085999
train: epoch 50, loss 0.259233295917511, acc=0.88227778673172, loss=0.259233295917511
test: epoch 50, loss 0.7449063062667847, acc=0.7472222447395325, loss=0.7449063062667847
train: epoch 51, loss 0.2666827440261841, acc=0.8786666393280029, loss=0.2666827440261841
test: epoch 51, loss 0.7201034426689148, acc=0.7472222447395325, loss=0.7201034426689148
train: epoch 52, loss 0.2506811022758484, acc=0.887333333492279, loss=0.2506811022758484
test: epoch 52, loss 0.7282456755638123, acc=0.7472222447395325, loss=0.7282456755638123
train: epoch 53, loss 0.25751712918281555, acc=0.8811666369438171, loss=0.25751712918281555
test: epoch 53, loss 0.6799417734146118, acc=0.7361111044883728, loss=0.6799417734146118
train: epoch 54, loss 0.2463952749967575, acc=0.8849999904632568, loss=0.2463952749967575
test: epoch 54, loss 0.7862510681152344, acc=0.7527777552604675, loss=0.7862510681152344
train: epoch 55, loss 0.2661793529987335, acc=0.8792222142219543, loss=0.2661793529987335
test: epoch 55, loss 0.7490890622138977, acc=0.7527777552604675, loss=0.7490890622138977
train: epoch 56, loss 0.24180004000663757, acc=0.8859444260597229, loss=0.24180004000663757
test: epoch 56, loss 0.7812883257865906, acc=0.7555555701255798, loss=0.7812883257865906
train: epoch 57, loss 0.24454925954341888, acc=0.8871111273765564, loss=0.24454925954341888
test: epoch 57, loss 0.7815984487533569, acc=0.7555555701255798, loss=0.7815984487533569
train: epoch 58, loss 0.24702204763889313, acc=0.8861111402511597, loss=0.24702204763889313
test: epoch 58, loss 0.5945229530334473, acc=0.7583333253860474, loss=0.5945229530334473
train: epoch 59, loss 0.24472783505916595, acc=0.8857777714729309, loss=0.24472783505916595
test: epoch 59, loss 0.7274805903434753, acc=0.7388888597488403, loss=0.7274805903434753
train: epoch 60, loss 0.26173657178878784, acc=0.8786666393280029, loss=0.26173657178878784
test: epoch 60, loss 0.6385785937309265, acc=0.7583333253860474, loss=0.6385785937309265
train: epoch 61, loss 0.24178627133369446, acc=0.8877221941947937, loss=0.24178627133369446
test: epoch 61, loss 0.6765700578689575, acc=0.7527777552604675, loss=0.6765700578689575
train: epoch 62, loss 0.24149516224861145, acc=0.8890555500984192, loss=0.24149516224861145
test: epoch 62, loss 0.6436394453048706, acc=0.7444444298744202, loss=0.6436394453048706
train: epoch 63, loss 0.24758020043373108, acc=0.8859444260597229, loss=0.24758020043373108
test: epoch 63, loss 0.5611606240272522, acc=0.7472222447395325, loss=0.5611606240272522
train: epoch 64, loss 0.23734548687934875, acc=0.890666663646698, loss=0.23734548687934875
test: epoch 64, loss 0.6137087345123291, acc=0.7444444298744202, loss=0.6137087345123291
train: epoch 65, loss 0.22158075869083405, acc=0.8975555300712585, loss=0.22158075869083405
test: epoch 65, loss 0.6643471717834473, acc=0.7555555701255798, loss=0.6643471717834473
train: epoch 66, loss 0.22805312275886536, acc=0.894611120223999, loss=0.22805312275886536
test: epoch 66, loss 0.7388904094696045, acc=0.7583333253860474, loss=0.7388904094696045
train: epoch 67, loss 0.23470763862133026, acc=0.894944429397583, loss=0.23470763862133026
test: epoch 67, loss 0.6362707614898682, acc=0.7722222208976746, loss=0.6362707614898682
train: epoch 68, loss 0.2195540964603424, acc=0.8987777829170227, loss=0.2195540964603424
test: epoch 68, loss 0.6110302805900574, acc=0.769444465637207, loss=0.6110302805900574
train: epoch 69, loss 0.22471196949481964, acc=0.8966666460037231, loss=0.22471196949481964
test: epoch 69, loss 0.6629930138587952, acc=0.769444465637207, loss=0.6629930138587952
train: epoch 70, loss 0.21595139801502228, acc=0.9023333191871643, loss=0.21595139801502228
test: epoch 70, loss 0.633325457572937, acc=0.7722222208976746, loss=0.633325457572937
train: epoch 71, loss 0.22304481267929077, acc=0.8984444737434387, loss=0.22304481267929077
test: epoch 71, loss 0.6562367081642151, acc=0.7666666507720947, loss=0.6562367081642151
train: epoch 72, loss 0.21948814392089844, acc=0.9003333449363708, loss=0.21948814392089844
test: epoch 72, loss 0.5997826457023621, acc=0.7777777910232544, loss=0.5997826457023621
train: epoch 73, loss 0.22467780113220215, acc=0.8989444375038147, loss=0.22467780113220215
test: epoch 73, loss 0.5381950736045837, acc=0.7888888716697693, loss=0.5381950736045837
train: epoch 74, loss 0.22747471928596497, acc=0.8970000147819519, loss=0.22747471928596497
test: epoch 74, loss 0.4804356098175049, acc=0.7805555462837219, loss=0.4804356098175049
train: epoch 75, loss 0.21411287784576416, acc=0.9029444456100464, loss=0.21411287784576416
test: epoch 75, loss 0.6473135948181152, acc=0.7749999761581421, loss=0.6473135948181152
train: epoch 76, loss 0.2241707295179367, acc=0.8984444737434387, loss=0.2241707295179367
test: epoch 76, loss 0.6193081140518188, acc=0.7777777910232544, loss=0.6193081140518188
train: epoch 77, loss 0.22006407380104065, acc=0.8962222337722778, loss=0.22006407380104065
test: epoch 77, loss 0.5976704359054565, acc=0.7777777910232544, loss=0.5976704359054565
train: epoch 78, loss 0.21438845992088318, acc=0.9017778038978577, loss=0.21438845992088318
test: epoch 78, loss 0.6635488271713257, acc=0.7583333253860474, loss=0.6635488271713257
train: epoch 79, loss 0.21897795796394348, acc=0.89811110496521, loss=0.21897795796394348
test: epoch 79, loss 0.5915348529815674, acc=0.7638888955116272, loss=0.5915348529815674
train: epoch 80, loss 0.20444175601005554, acc=0.9081110954284668, loss=0.20444175601005554
test: epoch 80, loss 0.5416185855865479, acc=0.800000011920929, loss=0.5416185855865479
train: epoch 81, loss 0.20952251553535461, acc=0.9065555334091187, loss=0.20952251553535461
test: epoch 81, loss 0.5816043019294739, acc=0.7972221970558167, loss=0.5816043019294739
train: epoch 82, loss 0.1999068409204483, acc=0.9054444432258606, loss=0.1999068409204483
test: epoch 82, loss 0.5448124408721924, acc=0.8138889074325562, loss=0.5448124408721924
train: epoch 83, loss 0.19489698112010956, acc=0.9102222323417664, loss=0.19489698112010956
test: epoch 83, loss 0.558287501335144, acc=0.8083333373069763, loss=0.558287501335144
train: epoch 84, loss 0.1903163641691208, acc=0.909333348274231, loss=0.1903163641691208
test: epoch 84, loss 0.545582115650177, acc=0.8027777671813965, loss=0.545582115650177
train: epoch 85, loss 0.19265668094158173, acc=0.9107778072357178, loss=0.19265668094158173
test: epoch 85, loss 0.5553863644599915, acc=0.8027777671813965, loss=0.5553863644599915
train: epoch 86, loss 0.19079560041427612, acc=0.9089444279670715, loss=0.19079560041427612
test: epoch 86, loss 0.47628530859947205, acc=0.8111110925674438, loss=0.47628530859947205
train: epoch 87, loss 0.18525829911231995, acc=0.9151666760444641, loss=0.18525829911231995
test: epoch 87, loss 0.5462823510169983, acc=0.8027777671813965, loss=0.5462823510169983
train: epoch 88, loss 0.18705227971076965, acc=0.9124444723129272, loss=0.18705227971076965
test: epoch 88, loss 0.556594967842102, acc=0.8055555820465088, loss=0.556594967842102
train: epoch 89, loss 0.19241714477539062, acc=0.9101666808128357, loss=0.19241714477539062
test: epoch 89, loss 0.5431028008460999, acc=0.8055555820465088, loss=0.5431028008460999
train: epoch 90, loss 0.18544453382492065, acc=0.9125555753707886, loss=0.18544453382492065
test: epoch 90, loss 0.5644452571868896, acc=0.8055555820465088, loss=0.5644452571868896
train: epoch 91, loss 0.19677887856960297, acc=0.9054999947547913, loss=0.19677887856960297
test: epoch 91, loss 0.5508353114128113, acc=0.800000011920929, loss=0.5508353114128113
train: epoch 92, loss 0.18151551485061646, acc=0.9098888635635376, loss=0.18151551485061646
test: epoch 92, loss 0.5543496012687683, acc=0.8055555820465088, loss=0.5543496012687683
train: epoch 93, loss 0.19479255378246307, acc=0.9085555672645569, loss=0.19479255378246307
test: epoch 93, loss 0.4806576371192932, acc=0.8055555820465088, loss=0.4806576371192932
train: epoch 94, loss 0.18651756644248962, acc=0.9122777581214905, loss=0.18651756644248962
test: epoch 94, loss 0.5000519156455994, acc=0.8027777671813965, loss=0.5000519156455994
train: epoch 95, loss 0.1904711276292801, acc=0.9141111373901367, loss=0.1904711276292801
test: epoch 95, loss 0.45971477031707764, acc=0.8055555820465088, loss=0.45971477031707764
train: epoch 96, loss 0.1951107680797577, acc=0.9096111059188843, loss=0.1951107680797577
test: epoch 96, loss 0.5208765864372253, acc=0.8083333373069763, loss=0.5208765864372253
train: epoch 97, loss 0.1723199039697647, acc=0.9167777895927429, loss=0.1723199039697647
test: epoch 97, loss 0.4757443964481354, acc=0.8055555820465088, loss=0.4757443964481354
train: epoch 98, loss 0.1873008906841278, acc=0.9116111397743225, loss=0.1873008906841278
test: epoch 98, loss 0.5052740573883057, acc=0.8055555820465088, loss=0.5052740573883057
train: epoch 99, loss 0.20457765460014343, acc=0.9046111106872559, loss=0.20457765460014343
test: epoch 99, loss 0.5386399030685425, acc=0.800000011920929, loss=0.5386399030685425
train: epoch 100, loss 0.1914653331041336, acc=0.914555549621582, loss=0.1914653331041336
test: epoch 100, loss 0.3693056106567383, acc=0.8055555820465088, loss=0.3693056106567383
train: epoch 101, loss 0.18310941755771637, acc=0.9123333096504211, loss=0.18310941755771637
test: epoch 101, loss 0.5996891856193542, acc=0.8055555820465088, loss=0.5996891856193542
train: epoch 102, loss 0.1719726026058197, acc=0.9183333516120911, loss=0.1719726026058197
test: epoch 102, loss 0.4876024127006531, acc=0.7888888716697693, loss=0.4876024127006531
train: epoch 103, loss 0.18343684077262878, acc=0.9150555729866028, loss=0.18343684077262878
test: epoch 103, loss 0.5279150605201721, acc=0.8055555820465088, loss=0.5279150605201721
train: epoch 104, loss 0.19337429106235504, acc=0.9120000004768372, loss=0.19337429106235504
test: epoch 104, loss 0.5137863159179688, acc=0.8027777671813965, loss=0.5137863159179688
train: epoch 105, loss 0.1743188500404358, acc=0.917722225189209, loss=0.1743188500404358
test: epoch 105, loss 0.5627932548522949, acc=0.8055555820465088, loss=0.5627932548522949
train: epoch 106, loss 0.17774732410907745, acc=0.9160555601119995, loss=0.17774732410907745
test: epoch 106, loss 0.6318578124046326, acc=0.7916666865348816, loss=0.6318578124046326
train: epoch 107, loss 0.1803310364484787, acc=0.9158333539962769, loss=0.1803310364484787
test: epoch 107, loss 0.570774257183075, acc=0.8027777671813965, loss=0.570774257183075
train: epoch 108, loss 0.17466990649700165, acc=0.9175000190734863, loss=0.17466990649700165
test: epoch 108, loss 0.5156325697898865, acc=0.8055555820465088, loss=0.5156325697898865
train: epoch 109, loss 0.17715267837047577, acc=0.9174444675445557, loss=0.17715267837047577
test: epoch 109, loss 0.5525560975074768, acc=0.8083333373069763, loss=0.5525560975074768
train: epoch 110, loss 0.18615156412124634, acc=0.9153333306312561, loss=0.18615156412124634
test: epoch 110, loss 0.5206015706062317, acc=0.8055555820465088, loss=0.5206015706062317
train: epoch 111, loss 0.17376476526260376, acc=0.9211666584014893, loss=0.17376476526260376
test: epoch 111, loss 0.5462583303451538, acc=0.8083333373069763, loss=0.5462583303451538
train: epoch 112, loss 0.16872555017471313, acc=0.9196110963821411, loss=0.16872555017471313
test: epoch 112, loss 0.5820783376693726, acc=0.8083333373069763, loss=0.5820783376693726
train: epoch 113, loss 0.1914452761411667, acc=0.9139999747276306, loss=0.1914452761411667
test: epoch 113, loss 0.48470085859298706, acc=0.8027777671813965, loss=0.48470085859298706
train: epoch 114, loss 0.1604209542274475, acc=0.9217777848243713, loss=0.1604209542274475
test: epoch 114, loss 0.519163966178894, acc=0.8055555820465088, loss=0.519163966178894
train: epoch 115, loss 0.171176478266716, acc=0.9206110835075378, loss=0.171176478266716
test: epoch 115, loss 0.5194587111473083, acc=0.8083333373069763, loss=0.5194587111473083
train: epoch 116, loss 0.17914149165153503, acc=0.917388916015625, loss=0.17914149165153503
test: epoch 116, loss 0.522821307182312, acc=0.8083333373069763, loss=0.522821307182312
train: epoch 117, loss 0.16299116611480713, acc=0.9233333468437195, loss=0.16299116611480713
test: epoch 117, loss 0.5589569807052612, acc=0.8083333373069763, loss=0.5589569807052612
train: epoch 118, loss 0.17937064170837402, acc=0.9171110987663269, loss=0.17937064170837402
test: epoch 118, loss 0.4352523982524872, acc=0.8083333373069763, loss=0.4352523982524872
train: epoch 119, loss 0.1804789900779724, acc=0.9190555810928345, loss=0.1804789900779724
test: epoch 119, loss 0.5756100416183472, acc=0.8055555820465088, loss=0.5756100416183472
train: epoch 120, loss 0.1750340610742569, acc=0.914555549621582, loss=0.1750340610742569
test: epoch 120, loss 0.5515773296356201, acc=0.8083333373069763, loss=0.5515773296356201
train: epoch 121, loss 0.1756492257118225, acc=0.9200555682182312, loss=0.1756492257118225
test: epoch 121, loss 0.5962868928909302, acc=0.8083333373069763, loss=0.5962868928909302
train: epoch 122, loss 0.1547042280435562, acc=0.9238333106040955, loss=0.1547042280435562
test: epoch 122, loss 0.6030009388923645, acc=0.8083333373069763, loss=0.6030009388923645
train: epoch 123, loss 0.16889840364456177, acc=0.9163888692855835, loss=0.16889840364456177
test: epoch 123, loss 0.5386000871658325, acc=0.8166666626930237, loss=0.5386000871658325
train: epoch 124, loss 0.16788944602012634, acc=0.9211111068725586, loss=0.16788944602012634
test: epoch 124, loss 0.540709376335144, acc=0.8138889074325562, loss=0.540709376335144
train: epoch 125, loss 0.15923289954662323, acc=0.9230555295944214, loss=0.15923289954662323
test: epoch 125, loss 0.5549858808517456, acc=0.8138889074325562, loss=0.5549858808517456
train: epoch 126, loss 0.1631225198507309, acc=0.9199444651603699, loss=0.1631225198507309
test: epoch 126, loss 0.5047157406806946, acc=0.8083333373069763, loss=0.5047157406806946
train: epoch 127, loss 0.1727856993675232, acc=0.9204444289207458, loss=0.1727856993675232
test: epoch 127, loss 0.5412206053733826, acc=0.8055555820465088, loss=0.5412206053733826
train: epoch 128, loss 0.1762237250804901, acc=0.9198333621025085, loss=0.1762237250804901
test: epoch 128, loss 0.5012788772583008, acc=0.8138889074325562, loss=0.5012788772583008
train: epoch 129, loss 0.18029312789440155, acc=0.917722225189209, loss=0.18029312789440155
test: epoch 129, loss 0.6306344866752625, acc=0.8138889074325562, loss=0.6306344866752625
train: epoch 130, loss 0.18469677865505219, acc=0.9204999804496765, loss=0.18469677865505219
test: epoch 130, loss 0.5778437256813049, acc=0.8027777671813965, loss=0.5778437256813049
train: epoch 131, loss 0.1779530644416809, acc=0.9190000295639038, loss=0.1779530644416809
test: epoch 131, loss 0.5551543235778809, acc=0.8027777671813965, loss=0.5551543235778809
train: epoch 132, loss 0.1915982961654663, acc=0.9118888974189758, loss=0.1915982961654663
test: epoch 132, loss 0.5526646971702576, acc=0.8027777671813965, loss=0.5526646971702576
train: epoch 133, loss 0.20434772968292236, acc=0.9078333377838135, loss=0.20434772968292236
test: epoch 133, loss 0.5114030838012695, acc=0.8027777671813965, loss=0.5114030838012695
train: epoch 134, loss 0.17534378170967102, acc=0.9166111350059509, loss=0.17534378170967102
test: epoch 134, loss 0.5480534434318542, acc=0.8027777671813965, loss=0.5480534434318542
train: epoch 135, loss 0.17943163216114044, acc=0.9151111245155334, loss=0.17943163216114044
test: epoch 135, loss 0.5492997765541077, acc=0.8027777671813965, loss=0.5492997765541077
train: epoch 136, loss 0.16976062953472137, acc=0.9219444394111633, loss=0.16976062953472137
test: epoch 136, loss 0.5293915867805481, acc=0.8027777671813965, loss=0.5293915867805481
train: epoch 137, loss 0.17422421276569366, acc=0.9204999804496765, loss=0.17422421276569366
test: epoch 137, loss 0.5433455109596252, acc=0.8027777671813965, loss=0.5433455109596252
train: epoch 138, loss 0.1701568365097046, acc=0.9222777485847473, loss=0.1701568365097046
test: epoch 138, loss 0.6084697246551514, acc=0.8055555820465088, loss=0.6084697246551514
train: epoch 139, loss 0.16641563177108765, acc=0.9218888878822327, loss=0.16641563177108765
test: epoch 139, loss 0.4744494557380676, acc=0.8083333373069763, loss=0.4744494557380676
train: epoch 140, loss 0.17544789612293243, acc=0.9183889031410217, loss=0.17544789612293243
test: epoch 140, loss 0.5845513939857483, acc=0.8083333373069763, loss=0.5845513939857483
train: epoch 141, loss 0.15895003080368042, acc=0.9255555272102356, loss=0.15895003080368042
test: epoch 141, loss 0.5298001170158386, acc=0.8166666626930237, loss=0.5298001170158386
train: epoch 142, loss 0.15803037583827972, acc=0.9231666922569275, loss=0.15803037583827972
test: epoch 142, loss 0.5728772878646851, acc=0.8055555820465088, loss=0.5728772878646851
train: epoch 143, loss 0.15822841227054596, acc=0.9235000014305115, loss=0.15822841227054596
test: epoch 143, loss 0.45771324634552, acc=0.8083333373069763, loss=0.45771324634552
train: epoch 144, loss 0.17379698157310486, acc=0.918833315372467, loss=0.17379698157310486
test: epoch 144, loss 0.583376944065094, acc=0.8083333373069763, loss=0.583376944065094
train: epoch 145, loss 0.16302573680877686, acc=0.9226111173629761, loss=0.16302573680877686
test: epoch 145, loss 0.5268588662147522, acc=0.8083333373069763, loss=0.5268588662147522
train: epoch 146, loss 0.16405579447746277, acc=0.9233333468437195, loss=0.16405579447746277
test: epoch 146, loss 0.5239754915237427, acc=0.8083333373069763, loss=0.5239754915237427
train: epoch 147, loss 0.15451475977897644, acc=0.9261666536331177, loss=0.15451475977897644
test: epoch 147, loss 0.559945285320282, acc=0.8083333373069763, loss=0.559945285320282
train: epoch 148, loss 0.15591062605381012, acc=0.9253888726234436, loss=0.15591062605381012
test: epoch 148, loss 0.6120564341545105, acc=0.8222222328186035, loss=0.6120564341545105
train: epoch 149, loss 0.1620102971792221, acc=0.9242777824401855, loss=0.1620102971792221
test: epoch 149, loss 0.5224013924598694, acc=0.8083333373069763, loss=0.5224013924598694
train: epoch 150, loss 0.17126083374023438, acc=0.9228888750076294, loss=0.17126083374023438
test: epoch 150, loss 0.5645518898963928, acc=0.8083333373069763, loss=0.5645518898963928
