# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=true", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=906196100, receiver_embed_dim=64, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.8065388202667236, acc=0.08711110800504684, loss=2.8065388202667236
test: epoch 1, loss 3.3417739868164062, acc=0.09444444626569748, loss=3.3417739868164062
train: epoch 2, loss 1.8310668468475342, acc=0.2238333374261856, loss=1.8310668468475342
test: epoch 2, loss 3.257267951965332, acc=0.1527777761220932, loss=3.257267951965332
train: epoch 3, loss 1.4620386362075806, acc=0.3209444582462311, loss=1.4620386362075806
test: epoch 3, loss 2.526456832885742, acc=0.18333333730697632, loss=2.526456832885742
train: epoch 4, loss 1.266184687614441, acc=0.39977777004241943, loss=1.266184687614441
test: epoch 4, loss 2.274369239807129, acc=0.31111112236976624, loss=2.274369239807129
train: epoch 5, loss 1.1087868213653564, acc=0.47716665267944336, loss=1.1087868213653564
test: epoch 5, loss 2.8563945293426514, acc=0.2777777910232544, loss=2.8563945293426514
train: epoch 6, loss 0.9084517359733582, acc=0.5788333415985107, loss=0.9084517359733582
test: epoch 6, loss 1.8004754781723022, acc=0.38055557012557983, loss=1.8004754781723022
train: epoch 7, loss 0.8257668018341064, acc=0.636388897895813, loss=0.8257668018341064
test: epoch 7, loss 1.9252333641052246, acc=0.3861111104488373, loss=1.9252333641052246
train: epoch 8, loss 0.746789813041687, acc=0.6625000238418579, loss=0.746789813041687
test: epoch 8, loss 2.5465075969696045, acc=0.3222222328186035, loss=2.5465075969696045
train: epoch 9, loss 0.6879380941390991, acc=0.6934444308280945, loss=0.6879380941390991
test: epoch 9, loss 1.9670417308807373, acc=0.4138889014720917, loss=1.9670417308807373
train: epoch 10, loss 0.6100702285766602, acc=0.7273889183998108, loss=0.6100702285766602
test: epoch 10, loss 1.69492769241333, acc=0.42500001192092896, loss=1.69492769241333
train: epoch 11, loss 0.5459160804748535, acc=0.7590555548667908, loss=0.5459160804748535
test: epoch 11, loss 1.7168971300125122, acc=0.44999998807907104, loss=1.7168971300125122
train: epoch 12, loss 0.5055243372917175, acc=0.7744444608688354, loss=0.5055243372917175
test: epoch 12, loss 1.6913057565689087, acc=0.4861111044883728, loss=1.6913057565689087
train: epoch 13, loss 0.4153067469596863, acc=0.8184444308280945, loss=0.4153067469596863
test: epoch 13, loss 1.7244503498077393, acc=0.4694444537162781, loss=1.7244503498077393
train: epoch 14, loss 0.36795470118522644, acc=0.8424444198608398, loss=0.36795470118522644
test: epoch 14, loss 1.7277852296829224, acc=0.4888888895511627, loss=1.7277852296829224
train: epoch 15, loss 0.36094218492507935, acc=0.8457777500152588, loss=0.36094218492507935
test: epoch 15, loss 1.4393293857574463, acc=0.4888888895511627, loss=1.4393293857574463
train: epoch 16, loss 0.27112263441085815, acc=0.8693333268165588, loss=0.27112263441085815
test: epoch 16, loss 1.9693292379379272, acc=0.5055555701255798, loss=1.9693292379379272
train: epoch 17, loss 0.2506922483444214, acc=0.8772777915000916, loss=0.2506922483444214
test: epoch 17, loss 1.3873182535171509, acc=0.6222222447395325, loss=1.3873182535171509
train: epoch 18, loss 0.24336731433868408, acc=0.8918333053588867, loss=0.24336731433868408
test: epoch 18, loss 1.2994974851608276, acc=0.5972222089767456, loss=1.2994974851608276
train: epoch 19, loss 0.20494981110095978, acc=0.9033889174461365, loss=0.20494981110095978
test: epoch 19, loss 1.2640219926834106, acc=0.5666666626930237, loss=1.2640219926834106
train: epoch 20, loss 0.22070302069187164, acc=0.8955555558204651, loss=0.22070302069187164
test: epoch 20, loss 1.360997200012207, acc=0.6527777910232544, loss=1.360997200012207
train: epoch 21, loss 0.18685239553451538, acc=0.9102222323417664, loss=0.18685239553451538
test: epoch 21, loss 0.9552226066589355, acc=0.6666666865348816, loss=0.9552226066589355
train: epoch 22, loss 0.18954946100711823, acc=0.910444438457489, loss=0.18954946100711823
test: epoch 22, loss 1.0394248962402344, acc=0.730555534362793, loss=1.0394248962402344
train: epoch 23, loss 0.18855737149715424, acc=0.9098333120346069, loss=0.18855737149715424
test: epoch 23, loss 0.9065016508102417, acc=0.6722221970558167, loss=0.9065016508102417
train: epoch 24, loss 0.15583913028240204, acc=0.9198333621025085, loss=0.15583913028240204
test: epoch 24, loss 0.9146264791488647, acc=0.6555555462837219, loss=0.9146264791488647
train: epoch 25, loss 0.18126794695854187, acc=0.9118888974189758, loss=0.18126794695854187
test: epoch 25, loss 1.0092616081237793, acc=0.75, loss=1.0092616081237793
train: epoch 26, loss 0.15795879065990448, acc=0.917388916015625, loss=0.15795879065990448
test: epoch 26, loss 0.6850587129592896, acc=0.7666666507720947, loss=0.6850587129592896
train: epoch 27, loss 0.16785748302936554, acc=0.9133889079093933, loss=0.16785748302936554
test: epoch 27, loss 0.6700405478477478, acc=0.7527777552604675, loss=0.6700405478477478
train: epoch 28, loss 0.14111290872097015, acc=0.9218888878822327, loss=0.14111290872097015
test: epoch 28, loss 0.6233943104743958, acc=0.8027777671813965, loss=0.6233943104743958
train: epoch 29, loss 0.1468268483877182, acc=0.9212222099304199, loss=0.1468268483877182
test: epoch 29, loss 0.42705705761909485, acc=0.8305555582046509, loss=0.42705705761909485
train: epoch 30, loss 0.14230018854141235, acc=0.9287222027778625, loss=0.14230018854141235
test: epoch 30, loss 0.5107360482215881, acc=0.8194444179534912, loss=0.5107360482215881
train: epoch 31, loss 0.149932861328125, acc=0.924833357334137, loss=0.149932861328125
test: epoch 31, loss 0.3614858388900757, acc=0.8888888955116272, loss=0.3614858388900757
train: epoch 32, loss 0.14154569804668427, acc=0.9268333315849304, loss=0.14154569804668427
test: epoch 32, loss 0.31934452056884766, acc=0.8666666746139526, loss=0.31934452056884766
train: epoch 33, loss 0.1352807581424713, acc=0.9258888959884644, loss=0.1352807581424713
test: epoch 33, loss 0.3565067946910858, acc=0.9111111164093018, loss=0.3565067946910858
train: epoch 34, loss 0.11836831271648407, acc=0.9312222003936768, loss=0.11836831271648407
test: epoch 34, loss 0.2802966833114624, acc=0.8916666507720947, loss=0.2802966833114624
train: epoch 35, loss 0.12061929702758789, acc=0.933222234249115, loss=0.12061929702758789
test: epoch 35, loss 0.19350336492061615, acc=0.9138888716697693, loss=0.19350336492061615
train: epoch 36, loss 0.12036804109811783, acc=0.9390000104904175, loss=0.12036804109811783
test: epoch 36, loss 0.12965689599514008, acc=0.9416666626930237, loss=0.12965689599514008
train: epoch 37, loss 0.12979447841644287, acc=0.9394444227218628, loss=0.12979447841644287
test: epoch 37, loss 0.2450861930847168, acc=0.9194444417953491, loss=0.2450861930847168
train: epoch 38, loss 0.11751046031713486, acc=0.9394999742507935, loss=0.11751046031713486
test: epoch 38, loss 0.27004143595695496, acc=0.9027777910232544, loss=0.27004143595695496
train: epoch 39, loss 0.1345987617969513, acc=0.9372777938842773, loss=0.1345987617969513
test: epoch 39, loss 0.11314799636602402, acc=0.9416666626930237, loss=0.11314799636602402
train: epoch 40, loss 0.11194132268428802, acc=0.9447222352027893, loss=0.11194132268428802
test: epoch 40, loss 0.2504231035709381, acc=0.9166666865348816, loss=0.2504231035709381
train: epoch 41, loss 0.12031713873147964, acc=0.9406111240386963, loss=0.12031713873147964
test: epoch 41, loss 0.08648569136857986, acc=0.9472222328186035, loss=0.08648569136857986
train: epoch 42, loss 0.11848992109298706, acc=0.9438333511352539, loss=0.11848992109298706
test: epoch 42, loss 0.10619814693927765, acc=0.9472222328186035, loss=0.10619814693927765
train: epoch 43, loss 0.10476645082235336, acc=0.9469444155693054, loss=0.10476645082235336
test: epoch 43, loss 0.09507742524147034, acc=0.949999988079071, loss=0.09507742524147034
train: epoch 44, loss 0.12675994634628296, acc=0.9407777786254883, loss=0.12675994634628296
test: epoch 44, loss 0.1230861246585846, acc=0.9416666626930237, loss=0.1230861246585846
train: epoch 45, loss 0.10226483643054962, acc=0.9463889002799988, loss=0.10226483643054962
test: epoch 45, loss 0.07488159090280533, acc=0.9527778029441833, loss=0.07488159090280533
train: epoch 46, loss 0.12003233283758163, acc=0.9433888792991638, loss=0.12003233283758163
test: epoch 46, loss 0.18242444097995758, acc=0.9333333373069763, loss=0.18242444097995758
train: epoch 47, loss 0.10013213753700256, acc=0.9477221965789795, loss=0.10013213753700256
test: epoch 47, loss 0.08198489248752594, acc=0.949999988079071, loss=0.08198489248752594
train: epoch 48, loss 0.12596403062343597, acc=0.940500020980835, loss=0.12596403062343597
test: epoch 48, loss 0.07533174753189087, acc=0.9527778029441833, loss=0.07533174753189087
train: epoch 49, loss 0.12661153078079224, acc=0.9409444332122803, loss=0.12661153078079224
test: epoch 49, loss 0.32618799805641174, acc=0.8972222208976746, loss=0.32618799805641174
train: epoch 50, loss 0.15884847939014435, acc=0.9261666536331177, loss=0.15884847939014435
test: epoch 50, loss 0.10856650769710541, acc=0.9388889074325562, loss=0.10856650769710541
train: epoch 51, loss 0.13529855012893677, acc=0.9227777719497681, loss=0.13529855012893677
test: epoch 51, loss 0.34050947427749634, acc=0.894444465637207, loss=0.34050947427749634
train: epoch 52, loss 0.13608267903327942, acc=0.9331111311912537, loss=0.13608267903327942
test: epoch 52, loss 0.10031257569789886, acc=0.9444444179534912, loss=0.10031257569789886
train: epoch 53, loss 0.12731404602527618, acc=0.9375, loss=0.12731404602527618
test: epoch 53, loss 0.10217784345149994, acc=0.9388889074325562, loss=0.10217784345149994
train: epoch 54, loss 0.09959256649017334, acc=0.9356111288070679, loss=0.09959256649017334
test: epoch 54, loss 0.09605153650045395, acc=0.9388889074325562, loss=0.09605153650045395
train: epoch 55, loss 0.17121656239032745, acc=0.9144444465637207, loss=0.17121656239032745
test: epoch 55, loss 0.15271952748298645, acc=0.9333333373069763, loss=0.15271952748298645
train: epoch 56, loss 0.14814341068267822, acc=0.9248889088630676, loss=0.14814341068267822
test: epoch 56, loss 0.11046723276376724, acc=0.9388889074325562, loss=0.11046723276376724
train: epoch 57, loss 0.11889573931694031, acc=0.9277222156524658, loss=0.11889573931694031
test: epoch 57, loss 0.10646159201860428, acc=0.9361110925674438, loss=0.10646159201860428
train: epoch 58, loss 0.14780476689338684, acc=0.925944447517395, loss=0.14780476689338684
test: epoch 58, loss 0.11877541244029999, acc=0.9361110925674438, loss=0.11877541244029999
train: epoch 59, loss 0.1450536996126175, acc=0.9303333163261414, loss=0.1450536996126175
test: epoch 59, loss 0.16494795680046082, acc=0.9305555820465088, loss=0.16494795680046082
train: epoch 60, loss 0.12615640461444855, acc=0.929444432258606, loss=0.12615640461444855
test: epoch 60, loss 0.1206601932644844, acc=0.9361110925674438, loss=0.1206601932644844
train: epoch 61, loss 0.16744472086429596, acc=0.9203333258628845, loss=0.16744472086429596
test: epoch 61, loss 0.1038159728050232, acc=0.9388889074325562, loss=0.1038159728050232
train: epoch 62, loss 0.10170760750770569, acc=0.9389444589614868, loss=0.10170760750770569
test: epoch 62, loss 0.09898389130830765, acc=0.9388889074325562, loss=0.09898389130830765
train: epoch 63, loss 0.15899789333343506, acc=0.9233333468437195, loss=0.15899789333343506
test: epoch 63, loss 0.09606628865003586, acc=0.9388889074325562, loss=0.09606628865003586
train: epoch 64, loss 0.195630744099617, acc=0.9028888940811157, loss=0.195630744099617
test: epoch 64, loss 0.17066459357738495, acc=0.9027777910232544, loss=0.17066459357738495
train: epoch 65, loss 0.1728391945362091, acc=0.901888906955719, loss=0.1728391945362091
test: epoch 65, loss 0.16067691147327423, acc=0.9055555462837219, loss=0.16067691147327423
train: epoch 66, loss 0.16258005797863007, acc=0.9052777886390686, loss=0.16258005797863007
test: epoch 66, loss 0.16609381139278412, acc=0.9055555462837219, loss=0.16609381139278412
train: epoch 67, loss 0.22897543013095856, acc=0.9041110873222351, loss=0.22897543013095856
test: epoch 67, loss 0.1652608960866928, acc=0.9277777671813965, loss=0.1652608960866928
train: epoch 68, loss 0.1022132858633995, acc=0.933388888835907, loss=0.1022132858633995
test: epoch 68, loss 0.09566354751586914, acc=0.9388889074325562, loss=0.09566354751586914
train: epoch 69, loss 0.19397929310798645, acc=0.9005555510520935, loss=0.19397929310798645
test: epoch 69, loss 0.28752103447914124, acc=0.9027777910232544, loss=0.28752103447914124
train: epoch 70, loss 0.12471724301576614, acc=0.921999990940094, loss=0.12471724301576614
test: epoch 70, loss 0.09595037996768951, acc=0.9388889074325562, loss=0.09595037996768951
train: epoch 71, loss 0.13393759727478027, acc=0.9241666793823242, loss=0.13393759727478027
test: epoch 71, loss 0.10694470256567001, acc=0.9361110925674438, loss=0.10694470256567001
train: epoch 72, loss 0.19401533901691437, acc=0.9088333249092102, loss=0.19401533901691437
test: epoch 72, loss 0.12278425693511963, acc=0.9305555820465088, loss=0.12278425693511963
train: epoch 73, loss 0.12978777289390564, acc=0.9222221970558167, loss=0.12978777289390564
test: epoch 73, loss 0.1231255978345871, acc=0.9305555820465088, loss=0.1231255978345871
train: epoch 74, loss 0.1250244379043579, acc=0.9223333597183228, loss=0.1250244379043579
test: epoch 74, loss 0.11988779902458191, acc=0.9305555820465088, loss=0.11988779902458191
train: epoch 75, loss 0.16981159150600433, acc=0.9093888998031616, loss=0.16981159150600433
test: epoch 75, loss 0.12508463859558105, acc=0.9277777671813965, loss=0.12508463859558105
train: epoch 76, loss 0.15826226770877838, acc=0.9120000004768372, loss=0.15826226770877838
test: epoch 76, loss 0.18788714706897736, acc=0.9083333611488342, loss=0.18788714706897736
train: epoch 77, loss 0.1955150067806244, acc=0.9123888611793518, loss=0.1955150067806244
test: epoch 77, loss 0.1154889315366745, acc=0.9361110925674438, loss=0.1154889315366745
train: epoch 78, loss 0.11144063621759415, acc=0.9377777576446533, loss=0.11144063621759415
test: epoch 78, loss 0.10718250274658203, acc=0.9388889074325562, loss=0.10718250274658203
train: epoch 79, loss 0.13471771776676178, acc=0.9340000152587891, loss=0.13471771776676178
test: epoch 79, loss 0.4142667353153229, acc=0.8416666388511658, loss=0.4142667353153229
train: epoch 80, loss 0.23594635725021362, acc=0.8929444551467896, loss=0.23594635725021362
test: epoch 80, loss 0.17455607652664185, acc=0.9166666865348816, loss=0.17455607652664185
train: epoch 81, loss 0.15853062272071838, acc=0.9252777695655823, loss=0.15853062272071838
test: epoch 81, loss 0.14584791660308838, acc=0.9277777671813965, loss=0.14584791660308838
train: epoch 82, loss 0.18163931369781494, acc=0.9225000143051147, loss=0.18163931369781494
test: epoch 82, loss 0.1699138730764389, acc=0.9194444417953491, loss=0.1699138730764389
train: epoch 83, loss 0.18253734707832336, acc=0.9040555357933044, loss=0.18253734707832336
test: epoch 83, loss 0.16541898250579834, acc=0.8999999761581421, loss=0.16541898250579834
train: epoch 84, loss 0.17089593410491943, acc=0.8961111307144165, loss=0.17089593410491943
test: epoch 84, loss 0.13351546227931976, acc=0.9277777671813965, loss=0.13351546227931976
train: epoch 85, loss 0.17199833691120148, acc=0.9192777872085571, loss=0.17199833691120148
test: epoch 85, loss 0.17703001201152802, acc=0.9083333611488342, loss=0.17703001201152802
train: epoch 86, loss 0.14980141818523407, acc=0.9089444279670715, loss=0.14980141818523407
test: epoch 86, loss 0.4262700080871582, acc=0.8999999761581421, loss=0.4262700080871582
train: epoch 87, loss 0.22490589320659637, acc=0.8898888826370239, loss=0.22490589320659637
test: epoch 87, loss 0.19842715561389923, acc=0.8972222208976746, loss=0.19842715561389923
train: epoch 88, loss 0.26284074783325195, acc=0.8847222328186035, loss=0.26284074783325195
test: epoch 88, loss 0.1880040168762207, acc=0.9055555462837219, loss=0.1880040168762207
train: epoch 89, loss 0.18640227615833282, acc=0.901888906955719, loss=0.18640227615833282
test: epoch 89, loss 0.18224169313907623, acc=0.9055555462837219, loss=0.18224169313907623
train: epoch 90, loss 0.24475623667240143, acc=0.887499988079071, loss=0.24475623667240143
test: epoch 90, loss 0.24515856802463531, acc=0.8972222208976746, loss=0.24515856802463531
train: epoch 91, loss 0.1605939269065857, acc=0.9171666502952576, loss=0.1605939269065857
test: epoch 91, loss 0.14803951978683472, acc=0.9111111164093018, loss=0.14803951978683472
train: epoch 92, loss 0.21200531721115112, acc=0.9023333191871643, loss=0.21200531721115112
test: epoch 92, loss 0.1744072437286377, acc=0.9138888716697693, loss=0.1744072437286377
train: epoch 93, loss 0.15612615644931793, acc=0.9146666526794434, loss=0.15612615644931793
test: epoch 93, loss 0.14587269723415375, acc=0.9166666865348816, loss=0.14587269723415375
train: epoch 94, loss 0.22186081111431122, acc=0.8958888649940491, loss=0.22186081111431122
test: epoch 94, loss 0.1846323013305664, acc=0.9194444417953491, loss=0.1846323013305664
train: epoch 95, loss 0.17283746600151062, acc=0.9130555391311646, loss=0.17283746600151062
test: epoch 95, loss 0.14061959087848663, acc=0.925000011920929, loss=0.14061959087848663
train: epoch 96, loss 0.1311606615781784, acc=0.9208333492279053, loss=0.1311606615781784
test: epoch 96, loss 0.1286749392747879, acc=0.925000011920929, loss=0.1286749392747879
train: epoch 97, loss 0.15947838127613068, acc=0.9124444723129272, loss=0.15947838127613068
test: epoch 97, loss 0.29523661732673645, acc=0.8916666507720947, loss=0.29523661732673645
train: epoch 98, loss 0.2845056354999542, acc=0.8691111207008362, loss=0.2845056354999542
test: epoch 98, loss 0.2248656004667282, acc=0.8888888955116272, loss=0.2248656004667282
train: epoch 99, loss 0.24137818813323975, acc=0.8717222213745117, loss=0.24137818813323975
test: epoch 99, loss 0.49229559302330017, acc=0.8222222328186035, loss=0.49229559302330017
train: epoch 100, loss 0.2700023353099823, acc=0.8633333444595337, loss=0.2700023353099823
test: epoch 100, loss 0.21239112317562103, acc=0.8916666507720947, loss=0.21239112317562103
train: epoch 101, loss 0.21138833463191986, acc=0.8770555257797241, loss=0.21138833463191986
test: epoch 101, loss 0.20200146734714508, acc=0.894444465637207, loss=0.20200146734714508
train: epoch 102, loss 0.2907690405845642, acc=0.8653888702392578, loss=0.2907690405845642
test: epoch 102, loss 0.24090521037578583, acc=0.8833333253860474, loss=0.24090521037578583
train: epoch 103, loss 0.23850813508033752, acc=0.8703888654708862, loss=0.23850813508033752
test: epoch 103, loss 0.24961046874523163, acc=0.8805555701255798, loss=0.24961046874523163
train: epoch 104, loss 0.24393761157989502, acc=0.8758333325386047, loss=0.24393761157989502
test: epoch 104, loss 0.18219128251075745, acc=0.8999999761581421, loss=0.18219128251075745
train: epoch 105, loss 0.2288454920053482, acc=0.8703888654708862, loss=0.2288454920053482
test: epoch 105, loss 0.24528992176055908, acc=0.8694444298744202, loss=0.24528992176055908
train: epoch 106, loss 0.23041008412837982, acc=0.8604999780654907, loss=0.23041008412837982
test: epoch 106, loss 0.21660877764225006, acc=0.8805555701255798, loss=0.21660877764225006
train: epoch 107, loss 0.24873626232147217, acc=0.8711110949516296, loss=0.24873626232147217
test: epoch 107, loss 0.19288253784179688, acc=0.8972222208976746, loss=0.19288253784179688
train: epoch 108, loss 0.1968224197626114, acc=0.8802222013473511, loss=0.1968224197626114
test: epoch 108, loss 0.1932085156440735, acc=0.8972222208976746, loss=0.1932085156440735
train: epoch 109, loss 0.24589073657989502, acc=0.8882222175598145, loss=0.24589073657989502
test: epoch 109, loss 0.20356705784797668, acc=0.8972222208976746, loss=0.20356705784797668
train: epoch 110, loss 0.1955869495868683, acc=0.8965555429458618, loss=0.1955869495868683
test: epoch 110, loss 0.19273848831653595, acc=0.8972222208976746, loss=0.19273848831653595
train: epoch 111, loss 0.1902586668729782, acc=0.8902778029441833, loss=0.1902586668729782
test: epoch 111, loss 0.18322080373764038, acc=0.9027777910232544, loss=0.18322080373764038
train: epoch 112, loss 0.1846666783094406, acc=0.8953333497047424, loss=0.1846666783094406
test: epoch 112, loss 0.18299531936645508, acc=0.9027777910232544, loss=0.18299531936645508
train: epoch 113, loss 0.18457363545894623, acc=0.8948888778686523, loss=0.18457363545894623
test: epoch 113, loss 0.1829497516155243, acc=0.9027777910232544, loss=0.1829497516155243
train: epoch 114, loss 0.27901172637939453, acc=0.8702222108840942, loss=0.27901172637939453
test: epoch 114, loss 0.3579809367656708, acc=0.8388888835906982, loss=0.3579809367656708
train: epoch 115, loss 0.37565499544143677, acc=0.8401111364364624, loss=0.37565499544143677
test: epoch 115, loss 0.3214678168296814, acc=0.8611111044883728, loss=0.3214678168296814
train: epoch 116, loss 0.2394597828388214, acc=0.8836666941642761, loss=0.2394597828388214
test: epoch 116, loss 0.23723162710666656, acc=0.894444465637207, loss=0.23723162710666656
train: epoch 117, loss 0.17853714525699615, acc=0.8999444246292114, loss=0.17853714525699615
test: epoch 117, loss 0.1704036295413971, acc=0.9083333611488342, loss=0.1704036295413971
train: epoch 118, loss 0.23206022381782532, acc=0.8799999952316284, loss=0.23206022381782532
test: epoch 118, loss 0.24515195190906525, acc=0.8694444298744202, loss=0.24515195190906525
train: epoch 119, loss 0.2986132800579071, acc=0.8642222285270691, loss=0.2986132800579071
test: epoch 119, loss 0.2290782928466797, acc=0.894444465637207, loss=0.2290782928466797
train: epoch 120, loss 0.2118121236562729, acc=0.8918889164924622, loss=0.2118121236562729
test: epoch 120, loss 0.20268851518630981, acc=0.8999999761581421, loss=0.20268851518630981
train: epoch 121, loss 0.19877742230892181, acc=0.8932777643203735, loss=0.19877742230892181
test: epoch 121, loss 0.19314970076084137, acc=0.9027777910232544, loss=0.19314970076084137
train: epoch 122, loss 0.2217712551355362, acc=0.8966666460037231, loss=0.2217712551355362
test: epoch 122, loss 0.17101657390594482, acc=0.9166666865348816, loss=0.17101657390594482
train: epoch 123, loss 0.2054745852947235, acc=0.9027777910232544, loss=0.2054745852947235
test: epoch 123, loss 0.19926667213439941, acc=0.8999999761581421, loss=0.19926667213439941
train: epoch 124, loss 0.19394707679748535, acc=0.8948333263397217, loss=0.19394707679748535
test: epoch 124, loss 0.18951569497585297, acc=0.9027777910232544, loss=0.18951569497585297
train: epoch 125, loss 0.2437947392463684, acc=0.8843888640403748, loss=0.2437947392463684
test: epoch 125, loss 0.23905625939369202, acc=0.8916666507720947, loss=0.23905625939369202
train: epoch 126, loss 0.20056843757629395, acc=0.8932222127914429, loss=0.20056843757629395
test: epoch 126, loss 0.17568852007389069, acc=0.9055555462837219, loss=0.17568852007389069
train: epoch 127, loss 0.17699415981769562, acc=0.8974444270133972, loss=0.17699415981769562
test: epoch 127, loss 0.17527776956558228, acc=0.9055555462837219, loss=0.17527776956558228
train: epoch 128, loss 0.1766853630542755, acc=0.8967777490615845, loss=0.1766853630542755
test: epoch 128, loss 0.17517147958278656, acc=0.9055555462837219, loss=0.17517147958278656
train: epoch 129, loss 0.17654265463352203, acc=0.8967777490615845, loss=0.17654265463352203
test: epoch 129, loss 0.17512965202331543, acc=0.9055555462837219, loss=0.17512965202331543
train: epoch 130, loss 0.17644885182380676, acc=0.8963333368301392, loss=0.17644885182380676
test: epoch 130, loss 0.17514438927173615, acc=0.9055555462837219, loss=0.17514438927173615
train: epoch 131, loss 0.17642435431480408, acc=0.8972777724266052, loss=0.17642435431480408
test: epoch 131, loss 0.1750916838645935, acc=0.9055555462837219, loss=0.1750916838645935
train: epoch 132, loss 0.17629387974739075, acc=0.8972222208976746, loss=0.17629387974739075
test: epoch 132, loss 0.17507363855838776, acc=0.9055555462837219, loss=0.17507363855838776
train: epoch 133, loss 0.17634229362010956, acc=0.8966110944747925, loss=0.17634229362010956
test: epoch 133, loss 0.17507007718086243, acc=0.9055555462837219, loss=0.17507007718086243
train: epoch 134, loss 0.32737502455711365, acc=0.8607222437858582, loss=0.32737502455711365
test: epoch 134, loss 0.3654775619506836, acc=0.855555534362793, loss=0.3654775619506836
train: epoch 135, loss 0.284844309091568, acc=0.8816666603088379, loss=0.284844309091568
test: epoch 135, loss 0.2201642245054245, acc=0.8999999761581421, loss=0.2201642245054245
train: epoch 136, loss 0.20247963070869446, acc=0.9082221984863281, loss=0.20247963070869446
test: epoch 136, loss 0.17943066358566284, acc=0.9138888716697693, loss=0.17943066358566284
train: epoch 137, loss 0.179335817694664, acc=0.9138888716697693, loss=0.179335817694664
test: epoch 137, loss 0.17781990766525269, acc=0.9138888716697693, loss=0.17781990766525269
train: epoch 138, loss 0.17893318831920624, acc=0.9138888716697693, loss=0.17893318831920624
test: epoch 138, loss 0.17763683199882507, acc=0.9138888716697693, loss=0.17763683199882507
train: epoch 139, loss 0.1788252741098404, acc=0.9138888716697693, loss=0.1788252741098404
test: epoch 139, loss 0.17755268514156342, acc=0.9138888716697693, loss=0.17755268514156342
train: epoch 140, loss 0.17882220447063446, acc=0.9138888716697693, loss=0.17882220447063446
test: epoch 140, loss 0.17749671638011932, acc=0.9138888716697693, loss=0.17749671638011932
train: epoch 141, loss 0.26131922006607056, acc=0.8957222104072571, loss=0.26131922006607056
test: epoch 141, loss 0.37159639596939087, acc=0.8611111044883728, loss=0.37159639596939087
train: epoch 142, loss 0.3506287932395935, acc=0.8464444279670715, loss=0.3506287932395935
test: epoch 142, loss 0.27632924914360046, acc=0.8777777552604675, loss=0.27632924914360046
train: epoch 143, loss 0.2461225986480713, acc=0.8796111345291138, loss=0.2461225986480713
test: epoch 143, loss 0.22842103242874146, acc=0.8916666507720947, loss=0.22842103242874146
train: epoch 144, loss 0.22038836777210236, acc=0.8833333253860474, loss=0.22038836777210236
test: epoch 144, loss 0.19899563491344452, acc=0.8972222208976746, loss=0.19899563491344452
train: epoch 145, loss 0.2533349096775055, acc=0.8726111054420471, loss=0.2533349096775055
test: epoch 145, loss 0.18445511162281036, acc=0.9027777910232544, loss=0.18445511162281036
train: epoch 146, loss 0.18460218608379364, acc=0.8886111378669739, loss=0.18460218608379364
test: epoch 146, loss 0.1824895292520523, acc=0.9027777910232544, loss=0.1824895292520523
train: epoch 147, loss 0.18380390107631683, acc=0.8886111378669739, loss=0.18380390107631683
test: epoch 147, loss 0.18227459490299225, acc=0.9027777910232544, loss=0.18227459490299225
train: epoch 148, loss 0.18351443111896515, acc=0.8863333463668823, loss=0.18351443111896515
test: epoch 148, loss 0.18218576908111572, acc=0.9027777910232544, loss=0.18218576908111572
train: epoch 149, loss 0.2820267379283905, acc=0.866944432258606, loss=0.2820267379283905
test: epoch 149, loss 0.7348052263259888, acc=0.7055555582046509, loss=0.7348052263259888
train: epoch 150, loss 0.43489012122154236, acc=0.8038889169692993, loss=0.43489012122154236
test: epoch 150, loss 0.3373434841632843, acc=0.8361111283302307, loss=0.3373434841632843
