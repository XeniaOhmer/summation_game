# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=128", "--temperature=2.0", "--temp_decay=0.99", "--one_hot=false", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1715073676, receiver_embed_dim=128, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.699772596359253, acc=0.11994444578886032, loss=2.699772596359253
test: epoch 1, loss 4.185057163238525, acc=0.1111111119389534, loss=4.185057163238525
train: epoch 2, loss 1.325614333152771, acc=0.4571666717529297, loss=1.325614333152771
test: epoch 2, loss 2.371342182159424, acc=0.24444444477558136, loss=2.371342182159424
train: epoch 3, loss 0.8040850758552551, acc=0.6769999861717224, loss=0.8040850758552551
test: epoch 3, loss 3.0805671215057373, acc=0.2361111044883728, loss=3.0805671215057373
train: epoch 4, loss 0.6088347434997559, acc=0.7566111087799072, loss=0.6088347434997559
test: epoch 4, loss 2.521888017654419, acc=0.2805555462837219, loss=2.521888017654419
train: epoch 5, loss 0.4907284080982208, acc=0.8078888654708862, loss=0.4907284080982208
test: epoch 5, loss 2.7813751697540283, acc=0.3027777671813965, loss=2.7813751697540283
train: epoch 6, loss 0.39725029468536377, acc=0.843500018119812, loss=0.39725029468536377
test: epoch 6, loss 2.535569429397583, acc=0.3333333432674408, loss=2.535569429397583
train: epoch 7, loss 0.37227490544319153, acc=0.8547777533531189, loss=0.37227490544319153
test: epoch 7, loss 2.3998336791992188, acc=0.34166666865348816, loss=2.3998336791992188
train: epoch 8, loss 0.33155250549316406, acc=0.8682777881622314, loss=0.33155250549316406
test: epoch 8, loss 2.475607395172119, acc=0.3333333432674408, loss=2.475607395172119
train: epoch 9, loss 0.2801743149757385, acc=0.8930555582046509, loss=0.2801743149757385
test: epoch 9, loss 2.192819356918335, acc=0.42222222685813904, loss=2.192819356918335
train: epoch 10, loss 0.2613030672073364, acc=0.9017778038978577, loss=0.2613030672073364
test: epoch 10, loss 3.0376248359680176, acc=0.31388887763023376, loss=3.0376248359680176
train: epoch 11, loss 0.2677522599697113, acc=0.9069444537162781, loss=0.2677522599697113
test: epoch 11, loss 2.3067426681518555, acc=0.33888888359069824, loss=2.3067426681518555
train: epoch 12, loss 0.2053462564945221, acc=0.9296666383743286, loss=0.2053462564945221
test: epoch 12, loss 2.4850528240203857, acc=0.4333333373069763, loss=2.4850528240203857
train: epoch 13, loss 0.19852186739444733, acc=0.9312222003936768, loss=0.19852186739444733
test: epoch 13, loss 2.6653032302856445, acc=0.4416666626930237, loss=2.6653032302856445
train: epoch 14, loss 0.21196764707565308, acc=0.9233333468437195, loss=0.21196764707565308
test: epoch 14, loss 2.138556957244873, acc=0.43611112236976624, loss=2.138556957244873
train: epoch 15, loss 0.17433913052082062, acc=0.9423333406448364, loss=0.17433913052082062
test: epoch 15, loss 2.3759002685546875, acc=0.49166667461395264, loss=2.3759002685546875
train: epoch 16, loss 0.1555730253458023, acc=0.9481111168861389, loss=0.1555730253458023
test: epoch 16, loss 2.4422295093536377, acc=0.4333333373069763, loss=2.4422295093536377
train: epoch 17, loss 0.1444733738899231, acc=0.949833333492279, loss=0.1444733738899231
test: epoch 17, loss 2.186995267868042, acc=0.4611110985279083, loss=2.186995267868042
train: epoch 18, loss 0.15426333248615265, acc=0.949222207069397, loss=0.15426333248615265
test: epoch 18, loss 2.1774954795837402, acc=0.46388888359069824, loss=2.1774954795837402
train: epoch 19, loss 0.1542195975780487, acc=0.9500555396080017, loss=0.1542195975780487
test: epoch 19, loss 1.9073272943496704, acc=0.5111111402511597, loss=1.9073272943496704
train: epoch 20, loss 0.13050079345703125, acc=0.9567777514457703, loss=0.13050079345703125
test: epoch 20, loss 1.4581760168075562, acc=0.5388888716697693, loss=1.4581760168075562
train: epoch 21, loss 0.14097876846790314, acc=0.9532777667045593, loss=0.14097876846790314
test: epoch 21, loss 2.0575320720672607, acc=0.5111111402511597, loss=2.0575320720672607
train: epoch 22, loss 0.12382381409406662, acc=0.9609444737434387, loss=0.12382381409406662
test: epoch 22, loss 1.7272688150405884, acc=0.5111111402511597, loss=1.7272688150405884
train: epoch 23, loss 0.13721425831317902, acc=0.9556111097335815, loss=0.13721425831317902
test: epoch 23, loss 1.7063850164413452, acc=0.5805555582046509, loss=1.7063850164413452
train: epoch 24, loss 0.14090006053447723, acc=0.9545000195503235, loss=0.14090006053447723
test: epoch 24, loss 1.7063899040222168, acc=0.5722222328186035, loss=1.7063899040222168
train: epoch 25, loss 0.11505280435085297, acc=0.9611666798591614, loss=0.11505280435085297
test: epoch 25, loss 1.8129628896713257, acc=0.5527777671813965, loss=1.8129628896713257
train: epoch 26, loss 0.11452832818031311, acc=0.9619444608688354, loss=0.11452832818031311
test: epoch 26, loss 1.7114386558532715, acc=0.6083333492279053, loss=1.7114386558532715
train: epoch 27, loss 0.10958417505025864, acc=0.9641666412353516, loss=0.10958417505025864
test: epoch 27, loss 1.0463707447052002, acc=0.6222222447395325, loss=1.0463707447052002
train: epoch 28, loss 0.11883557587862015, acc=0.9622777700424194, loss=0.11883557587862015
test: epoch 28, loss 1.603758454322815, acc=0.6083333492279053, loss=1.603758454322815
train: epoch 29, loss 0.1163579598069191, acc=0.9638333320617676, loss=0.1163579598069191
test: epoch 29, loss 1.1248074769973755, acc=0.6111111044883728, loss=1.1248074769973755
train: epoch 30, loss 0.10614939779043198, acc=0.9655555486679077, loss=0.10614939779043198
test: epoch 30, loss 1.088031530380249, acc=0.6333333253860474, loss=1.088031530380249
train: epoch 31, loss 0.11090078949928284, acc=0.9642778038978577, loss=0.11090078949928284
test: epoch 31, loss 1.2407569885253906, acc=0.6222222447395325, loss=1.2407569885253906
train: epoch 32, loss 0.09945061802864075, acc=0.9687777757644653, loss=0.09945061802864075
test: epoch 32, loss 1.358253002166748, acc=0.6277777552604675, loss=1.358253002166748
train: epoch 33, loss 0.10858521610498428, acc=0.9646666646003723, loss=0.10858521610498428
test: epoch 33, loss 1.350264549255371, acc=0.6527777910232544, loss=1.350264549255371
train: epoch 34, loss 0.10986823588609695, acc=0.9646666646003723, loss=0.10986823588609695
test: epoch 34, loss 0.9827001094818115, acc=0.6833333373069763, loss=0.9827001094818115
train: epoch 35, loss 0.09987519681453705, acc=0.9691666960716248, loss=0.09987519681453705
test: epoch 35, loss 0.8773002028465271, acc=0.7388888597488403, loss=0.8773002028465271
train: epoch 36, loss 0.08800546079874039, acc=0.9722222089767456, loss=0.08800546079874039
test: epoch 36, loss 0.7272476553916931, acc=0.7666666507720947, loss=0.7272476553916931
train: epoch 37, loss 0.07981857657432556, acc=0.9751666784286499, loss=0.07981857657432556
test: epoch 37, loss 0.679343581199646, acc=0.8166666626930237, loss=0.679343581199646
train: epoch 38, loss 0.09198027104139328, acc=0.9711666703224182, loss=0.09198027104139328
test: epoch 38, loss 0.5753206610679626, acc=0.8388888835906982, loss=0.5753206610679626
train: epoch 39, loss 0.079892098903656, acc=0.9752777814865112, loss=0.079892098903656
test: epoch 39, loss 0.29192671179771423, acc=0.9138888716697693, loss=0.29192671179771423
train: epoch 40, loss 0.0812854990363121, acc=0.9749444723129272, loss=0.0812854990363121
test: epoch 40, loss 0.30703359842300415, acc=0.8805555701255798, loss=0.30703359842300415
train: epoch 41, loss 0.0693957731127739, acc=0.9772777557373047, loss=0.0693957731127739
test: epoch 41, loss 0.4581385850906372, acc=0.8888888955116272, loss=0.4581385850906372
train: epoch 42, loss 0.07246357202529907, acc=0.9757221937179565, loss=0.07246357202529907
test: epoch 42, loss 0.33980876207351685, acc=0.9055555462837219, loss=0.33980876207351685
train: epoch 43, loss 0.06505752354860306, acc=0.9795555472373962, loss=0.06505752354860306
test: epoch 43, loss 0.33123695850372314, acc=0.9222221970558167, loss=0.33123695850372314
train: epoch 44, loss 0.0646645575761795, acc=0.9797222018241882, loss=0.0646645575761795
test: epoch 44, loss 0.30802878737449646, acc=0.925000011920929, loss=0.30802878737449646
train: epoch 45, loss 0.06195519119501114, acc=0.9809444546699524, loss=0.06195519119501114
test: epoch 45, loss 0.2586608827114105, acc=0.9361110925674438, loss=0.2586608827114105
train: epoch 46, loss 0.051605481654405594, acc=0.9855555295944214, loss=0.051605481654405594
test: epoch 46, loss 0.30699384212493896, acc=0.9305555820465088, loss=0.30699384212493896
train: epoch 47, loss 0.06143634393811226, acc=0.983222246170044, loss=0.06143634393811226
test: epoch 47, loss 0.26189273595809937, acc=0.9416666626930237, loss=0.26189273595809937
train: epoch 48, loss 0.05235373601317406, acc=0.9847777485847473, loss=0.05235373601317406
test: epoch 48, loss 0.19709070026874542, acc=0.9444444179534912, loss=0.19709070026874542
train: epoch 49, loss 0.056624382734298706, acc=0.9826666712760925, loss=0.056624382734298706
test: epoch 49, loss 0.1980326771736145, acc=0.9444444179534912, loss=0.1980326771736145
train: epoch 50, loss 0.04723963886499405, acc=0.9860555529594421, loss=0.04723963886499405
test: epoch 50, loss 0.18581059575080872, acc=0.9444444179534912, loss=0.18581059575080872
train: epoch 51, loss 0.053394682705402374, acc=0.9837777614593506, loss=0.053394682705402374
test: epoch 51, loss 0.16922549903392792, acc=0.9416666626930237, loss=0.16922549903392792
train: epoch 52, loss 0.05832931026816368, acc=0.9824444651603699, loss=0.05832931026816368
test: epoch 52, loss 0.22610317170619965, acc=0.9444444179534912, loss=0.22610317170619965
train: epoch 53, loss 0.04485728591680527, acc=0.9856666922569275, loss=0.04485728591680527
test: epoch 53, loss 0.1564352661371231, acc=0.9444444179534912, loss=0.1564352661371231
train: epoch 54, loss 0.04889530688524246, acc=0.9845555424690247, loss=0.04889530688524246
test: epoch 54, loss 0.13479410111904144, acc=0.9555555582046509, loss=0.13479410111904144
train: epoch 55, loss 0.056176405400037766, acc=0.9840555787086487, loss=0.056176405400037766
test: epoch 55, loss 0.20351193845272064, acc=0.9388889074325562, loss=0.20351193845272064
train: epoch 56, loss 0.04129326716065407, acc=0.9865000247955322, loss=0.04129326716065407
test: epoch 56, loss 0.16979195177555084, acc=0.9444444179534912, loss=0.16979195177555084
train: epoch 57, loss 0.04648593068122864, acc=0.984666645526886, loss=0.04648593068122864
test: epoch 57, loss 0.1221201941370964, acc=0.9555555582046509, loss=0.1221201941370964
train: epoch 58, loss 0.041310492902994156, acc=0.9852777719497681, loss=0.041310492902994156
test: epoch 58, loss 0.17169611155986786, acc=0.9444444179534912, loss=0.17169611155986786
train: epoch 59, loss 0.04844735562801361, acc=0.9858888983726501, loss=0.04844735562801361
test: epoch 59, loss 0.2210545539855957, acc=0.9444444179534912, loss=0.2210545539855957
train: epoch 60, loss 0.04722194746136665, acc=0.9852777719497681, loss=0.04722194746136665
test: epoch 60, loss 0.14987483620643616, acc=0.9444444179534912, loss=0.14987483620643616
train: epoch 61, loss 0.05425553768873215, acc=0.9848333597183228, loss=0.05425553768873215
test: epoch 61, loss 0.20745526254177094, acc=0.9444444179534912, loss=0.20745526254177094
train: epoch 62, loss 0.04939325526356697, acc=0.9853888750076294, loss=0.04939325526356697
test: epoch 62, loss 0.17529872059822083, acc=0.9555555582046509, loss=0.17529872059822083
train: epoch 63, loss 0.05368414893746376, acc=0.9826666712760925, loss=0.05368414893746376
test: epoch 63, loss 0.18839776515960693, acc=0.9444444179534912, loss=0.18839776515960693
train: epoch 64, loss 0.046453144401311874, acc=0.9863888621330261, loss=0.046453144401311874
test: epoch 64, loss 0.18309848010540009, acc=0.9444444179534912, loss=0.18309848010540009
train: epoch 65, loss 0.03995370492339134, acc=0.9856111407279968, loss=0.03995370492339134
test: epoch 65, loss 0.19546912610530853, acc=0.9444444179534912, loss=0.19546912610530853
train: epoch 66, loss 0.047459594905376434, acc=0.9853888750076294, loss=0.047459594905376434
test: epoch 66, loss 0.165013387799263, acc=0.9444444179534912, loss=0.165013387799263
train: epoch 67, loss 0.0495404452085495, acc=0.984000027179718, loss=0.0495404452085495
test: epoch 67, loss 0.16302433609962463, acc=0.9444444179534912, loss=0.16302433609962463
train: epoch 68, loss 0.03452201187610626, acc=0.9869444370269775, loss=0.03452201187610626
test: epoch 68, loss 0.19486179947853088, acc=0.9555555582046509, loss=0.19486179947853088
train: epoch 69, loss 0.05074376240372658, acc=0.9835000038146973, loss=0.05074376240372658
test: epoch 69, loss 0.17561103403568268, acc=0.9388889074325562, loss=0.17561103403568268
train: epoch 70, loss 0.0510447695851326, acc=0.9845555424690247, loss=0.0510447695851326
test: epoch 70, loss 0.1290576308965683, acc=0.9444444179534912, loss=0.1290576308965683
train: epoch 71, loss 0.042460840195417404, acc=0.9863888621330261, loss=0.042460840195417404
test: epoch 71, loss 0.18273688852787018, acc=0.9416666626930237, loss=0.18273688852787018
train: epoch 72, loss 0.051639460027217865, acc=0.9841111302375793, loss=0.051639460027217865
test: epoch 72, loss 0.1368265002965927, acc=0.9555555582046509, loss=0.1368265002965927
train: epoch 73, loss 0.04205404967069626, acc=0.9858333468437195, loss=0.04205404967069626
test: epoch 73, loss 0.17242297530174255, acc=0.9444444179534912, loss=0.17242297530174255
train: epoch 74, loss 0.037994638085365295, acc=0.9863333106040955, loss=0.037994638085365295
test: epoch 74, loss 0.17388413846492767, acc=0.9555555582046509, loss=0.17388413846492767
train: epoch 75, loss 0.04168780893087387, acc=0.9849444627761841, loss=0.04168780893087387
test: epoch 75, loss 0.1233043298125267, acc=0.9444444179534912, loss=0.1233043298125267
train: epoch 76, loss 0.05917257070541382, acc=0.9842777848243713, loss=0.05917257070541382
test: epoch 76, loss 0.1980745643377304, acc=0.9444444179534912, loss=0.1980745643377304
train: epoch 77, loss 0.04752689227461815, acc=0.9827777743339539, loss=0.04752689227461815
test: epoch 77, loss 0.16559268534183502, acc=0.9444444179534912, loss=0.16559268534183502
train: epoch 78, loss 0.05672366917133331, acc=0.9833889007568359, loss=0.05672366917133331
test: epoch 78, loss 0.15983903408050537, acc=0.9416666626930237, loss=0.15983903408050537
train: epoch 79, loss 0.04441303387284279, acc=0.9867777824401855, loss=0.04441303387284279
test: epoch 79, loss 0.17509599030017853, acc=0.9444444179534912, loss=0.17509599030017853
train: epoch 80, loss 0.04407304525375366, acc=0.9850555658340454, loss=0.04407304525375366
test: epoch 80, loss 0.14418570697307587, acc=0.9444444179534912, loss=0.14418570697307587
train: epoch 81, loss 0.05023737624287605, acc=0.9857222437858582, loss=0.05023737624287605
test: epoch 81, loss 0.15585826337337494, acc=0.9444444179534912, loss=0.15585826337337494
train: epoch 82, loss 0.04378392547369003, acc=0.9857777953147888, loss=0.04378392547369003
test: epoch 82, loss 0.09264438599348068, acc=0.9555555582046509, loss=0.09264438599348068
train: epoch 83, loss 0.04057067260146141, acc=0.9874444603919983, loss=0.04057067260146141
test: epoch 83, loss 0.202880859375, acc=0.9416666626930237, loss=0.202880859375
train: epoch 84, loss 0.04702078923583031, acc=0.984333336353302, loss=0.04702078923583031
test: epoch 84, loss 0.12405499815940857, acc=0.9444444179534912, loss=0.12405499815940857
train: epoch 85, loss 0.047823309898376465, acc=0.9865000247955322, loss=0.047823309898376465
test: epoch 85, loss 0.14438094198703766, acc=0.9444444179534912, loss=0.14438094198703766
train: epoch 86, loss 0.04886246845126152, acc=0.984000027179718, loss=0.04886246845126152
test: epoch 86, loss 0.18803757429122925, acc=0.949999988079071, loss=0.18803757429122925
train: epoch 87, loss 0.04257311671972275, acc=0.9860555529594421, loss=0.04257311671972275
test: epoch 87, loss 0.16113896667957306, acc=0.9444444179534912, loss=0.16113896667957306
train: epoch 88, loss 0.04299351945519447, acc=0.9852222204208374, loss=0.04299351945519447
test: epoch 88, loss 0.11502722650766373, acc=0.9444444179534912, loss=0.11502722650766373
train: epoch 89, loss 0.03511258587241173, acc=0.9879444241523743, loss=0.03511258587241173
test: epoch 89, loss 0.1518905907869339, acc=0.9444444179534912, loss=0.1518905907869339
train: epoch 90, loss 0.05147771164774895, acc=0.9838333129882812, loss=0.05147771164774895
test: epoch 90, loss 0.11684688925743103, acc=0.9444444179534912, loss=0.11684688925743103
train: epoch 91, loss 0.05107797682285309, acc=0.9845555424690247, loss=0.05107797682285309
test: epoch 91, loss 0.15128175914287567, acc=0.9444444179534912, loss=0.15128175914287567
train: epoch 92, loss 0.03962794318795204, acc=0.9854999780654907, loss=0.03962794318795204
test: epoch 92, loss 0.15412048995494843, acc=0.9444444179534912, loss=0.15412048995494843
train: epoch 93, loss 0.04257143661379814, acc=0.984499990940094, loss=0.04257143661379814
test: epoch 93, loss 0.152056023478508, acc=0.9388889074325562, loss=0.152056023478508
train: epoch 94, loss 0.04815618321299553, acc=0.9829999804496765, loss=0.04815618321299553
test: epoch 94, loss 0.14715832471847534, acc=0.9416666626930237, loss=0.14715832471847534
train: epoch 95, loss 0.04951689764857292, acc=0.9833333492279053, loss=0.04951689764857292
test: epoch 95, loss 0.14247000217437744, acc=0.9444444179534912, loss=0.14247000217437744
train: epoch 96, loss 0.0606306828558445, acc=0.9839444160461426, loss=0.0606306828558445
test: epoch 96, loss 0.1163940355181694, acc=0.9444444179534912, loss=0.1163940355181694
train: epoch 97, loss 0.07000903785228729, acc=0.9804444313049316, loss=0.07000903785228729
test: epoch 97, loss 0.14623527228832245, acc=0.9416666626930237, loss=0.14623527228832245
train: epoch 98, loss 0.05521242693066597, acc=0.9818888902664185, loss=0.05521242693066597
test: epoch 98, loss 0.12311475723981857, acc=0.9583333134651184, loss=0.12311475723981857
train: epoch 99, loss 0.045086588710546494, acc=0.9830555319786072, loss=0.045086588710546494
test: epoch 99, loss 0.13557347655296326, acc=0.9472222328186035, loss=0.13557347655296326
train: epoch 100, loss 0.05838095396757126, acc=0.9810555577278137, loss=0.05838095396757126
test: epoch 100, loss 0.20236600935459137, acc=0.9472222328186035, loss=0.20236600935459137
train: epoch 101, loss 0.059724438935518265, acc=0.979888916015625, loss=0.059724438935518265
test: epoch 101, loss 0.10619836300611496, acc=0.9555555582046509, loss=0.10619836300611496
train: epoch 102, loss 0.053266048431396484, acc=0.9803333282470703, loss=0.053266048431396484
test: epoch 102, loss 0.13528499007225037, acc=0.9444444179534912, loss=0.13528499007225037
train: epoch 103, loss 0.06903110444545746, acc=0.9787777662277222, loss=0.06903110444545746
test: epoch 103, loss 0.18104593455791473, acc=0.9555555582046509, loss=0.18104593455791473
train: epoch 104, loss 0.04902558773756027, acc=0.9823889136314392, loss=0.04902558773756027
test: epoch 104, loss 0.13911372423171997, acc=0.9361110925674438, loss=0.13911372423171997
train: epoch 105, loss 0.06882356852293015, acc=0.9778333306312561, loss=0.06882356852293015
test: epoch 105, loss 0.13451437652111053, acc=0.9527778029441833, loss=0.13451437652111053
train: epoch 106, loss 0.051287516951560974, acc=0.9810555577278137, loss=0.051287516951560974
test: epoch 106, loss 0.1627749651670456, acc=0.9555555582046509, loss=0.1627749651670456
train: epoch 107, loss 0.04732191190123558, acc=0.9806110858917236, loss=0.04732191190123558
test: epoch 107, loss 0.13614071905612946, acc=0.9527778029441833, loss=0.13614071905612946
train: epoch 108, loss 0.047211021184921265, acc=0.9828888773918152, loss=0.047211021184921265
test: epoch 108, loss 0.17106451094150543, acc=0.949999988079071, loss=0.17106451094150543
train: epoch 109, loss 0.04780665785074234, acc=0.9831110835075378, loss=0.04780665785074234
test: epoch 109, loss 0.20601442456245422, acc=0.9472222328186035, loss=0.20601442456245422
train: epoch 110, loss 0.05358846113085747, acc=0.9812222123146057, loss=0.05358846113085747
test: epoch 110, loss 0.17099373042583466, acc=0.9472222328186035, loss=0.17099373042583466
train: epoch 111, loss 0.03462331369519234, acc=0.9860000014305115, loss=0.03462331369519234
test: epoch 111, loss 0.12944447994232178, acc=0.9472222328186035, loss=0.12944447994232178
train: epoch 112, loss 0.038432713598012924, acc=0.9848889112472534, loss=0.038432713598012924
test: epoch 112, loss 0.13818132877349854, acc=0.9583333134651184, loss=0.13818132877349854
train: epoch 113, loss 0.03633760288357735, acc=0.9858333468437195, loss=0.03633760288357735
test: epoch 113, loss 0.14295560121536255, acc=0.9444444179534912, loss=0.14295560121536255
train: epoch 114, loss 0.05205130577087402, acc=0.9842777848243713, loss=0.05205130577087402
test: epoch 114, loss 0.15732499957084656, acc=0.9444444179534912, loss=0.15732499957084656
train: epoch 115, loss 0.04346013814210892, acc=0.9841111302375793, loss=0.04346013814210892
test: epoch 115, loss 0.15723535418510437, acc=0.9444444179534912, loss=0.15723535418510437
train: epoch 116, loss 0.05317194387316704, acc=0.9821666479110718, loss=0.05317194387316704
test: epoch 116, loss 0.14323443174362183, acc=0.9444444179534912, loss=0.14323443174362183
train: epoch 117, loss 0.07377689331769943, acc=0.9806110858917236, loss=0.07377689331769943
test: epoch 117, loss 0.1813075691461563, acc=0.9388889074325562, loss=0.1813075691461563
train: epoch 118, loss 0.06377268582582474, acc=0.9815555810928345, loss=0.06377268582582474
test: epoch 118, loss 0.1474934071302414, acc=0.9416666626930237, loss=0.1474934071302414
train: epoch 119, loss 0.041904252022504807, acc=0.9854999780654907, loss=0.041904252022504807
test: epoch 119, loss 0.16309043765068054, acc=0.9444444179534912, loss=0.16309043765068054
train: epoch 120, loss 0.041643522679805756, acc=0.9852222204208374, loss=0.041643522679805756
test: epoch 120, loss 0.1470538228750229, acc=0.9416666626930237, loss=0.1470538228750229
train: epoch 121, loss 0.04630312696099281, acc=0.9842222332954407, loss=0.04630312696099281
test: epoch 121, loss 0.18241389095783234, acc=0.9527778029441833, loss=0.18241389095783234
train: epoch 122, loss 0.04387974366545677, acc=0.9855555295944214, loss=0.04387974366545677
test: epoch 122, loss 0.1802854835987091, acc=0.9416666626930237, loss=0.1802854835987091
train: epoch 123, loss 0.0445297472178936, acc=0.9850000143051147, loss=0.0445297472178936
test: epoch 123, loss 0.18523015081882477, acc=0.9444444179534912, loss=0.18523015081882477
train: epoch 124, loss 0.0443902388215065, acc=0.9840555787086487, loss=0.0443902388215065
test: epoch 124, loss 0.08949698507785797, acc=0.9444444179534912, loss=0.08949698507785797
train: epoch 125, loss 0.042582567781209946, acc=0.9835555553436279, loss=0.042582567781209946
test: epoch 125, loss 0.15158693492412567, acc=0.9444444179534912, loss=0.15158693492412567
train: epoch 126, loss 0.055701326578855515, acc=0.9831666946411133, loss=0.055701326578855515
test: epoch 126, loss 0.1165805235505104, acc=0.9472222328186035, loss=0.1165805235505104
train: epoch 127, loss 0.06101546809077263, acc=0.9817222356796265, loss=0.06101546809077263
test: epoch 127, loss 0.16452011466026306, acc=0.9444444179534912, loss=0.16452011466026306
train: epoch 128, loss 0.05280967801809311, acc=0.9818888902664185, loss=0.05280967801809311
test: epoch 128, loss 0.20577970147132874, acc=0.9444444179534912, loss=0.20577970147132874
train: epoch 129, loss 0.04390572011470795, acc=0.9852777719497681, loss=0.04390572011470795
test: epoch 129, loss 0.2263786345720291, acc=0.9416666626930237, loss=0.2263786345720291
train: epoch 130, loss 0.059016890823841095, acc=0.9817777872085571, loss=0.059016890823841095
test: epoch 130, loss 0.1539091169834137, acc=0.9472222328186035, loss=0.1539091169834137
train: epoch 131, loss 0.06036275997757912, acc=0.976111114025116, loss=0.06036275997757912
test: epoch 131, loss 0.20392046868801117, acc=0.9361110925674438, loss=0.20392046868801117
train: epoch 132, loss 0.08023274689912796, acc=0.9737777709960938, loss=0.08023274689912796
test: epoch 132, loss 0.20619109272956848, acc=0.9361110925674438, loss=0.20619109272956848
train: epoch 133, loss 0.059642426669597626, acc=0.9763333201408386, loss=0.059642426669597626
test: epoch 133, loss 0.18048888444900513, acc=0.9333333373069763, loss=0.18048888444900513
train: epoch 134, loss 0.05958549305796623, acc=0.9782778024673462, loss=0.05958549305796623
test: epoch 134, loss 0.16845519840717316, acc=0.9333333373069763, loss=0.16845519840717316
train: epoch 135, loss 0.06503090262413025, acc=0.9775555729866028, loss=0.06503090262413025
test: epoch 135, loss 0.15668831765651703, acc=0.9361110925674438, loss=0.15668831765651703
train: epoch 136, loss 0.06701328605413437, acc=0.9791111350059509, loss=0.06701328605413437
test: epoch 136, loss 0.2600599229335785, acc=0.9333333373069763, loss=0.2600599229335785
train: epoch 137, loss 0.05727561563253403, acc=0.9793888926506042, loss=0.05727561563253403
test: epoch 137, loss 0.2162814438343048, acc=0.9361110925674438, loss=0.2162814438343048
train: epoch 138, loss 0.0916614681482315, acc=0.9717777967453003, loss=0.0916614681482315
test: epoch 138, loss 0.23805004358291626, acc=0.9305555820465088, loss=0.23805004358291626
train: epoch 139, loss 0.08295392990112305, acc=0.9712777733802795, loss=0.08295392990112305
test: epoch 139, loss 0.22075451910495758, acc=0.9277777671813965, loss=0.22075451910495758
train: epoch 140, loss 0.08323721587657928, acc=0.9704444408416748, loss=0.08323721587657928
test: epoch 140, loss 0.3207547664642334, acc=0.925000011920929, loss=0.3207547664642334
train: epoch 141, loss 0.08595689386129379, acc=0.9712222218513489, loss=0.08595689386129379
test: epoch 141, loss 0.24184003472328186, acc=0.9305555820465088, loss=0.24184003472328186
train: epoch 142, loss 0.10108394175767899, acc=0.9696111083030701, loss=0.10108394175767899
test: epoch 142, loss 0.2135481983423233, acc=0.9333333373069763, loss=0.2135481983423233
train: epoch 143, loss 0.07376915216445923, acc=0.9738888740539551, loss=0.07376915216445923
test: epoch 143, loss 0.2318011075258255, acc=0.9305555820465088, loss=0.2318011075258255
train: epoch 144, loss 0.07496247440576553, acc=0.9734444618225098, loss=0.07496247440576553
test: epoch 144, loss 0.22159796953201294, acc=0.9333333373069763, loss=0.22159796953201294
train: epoch 145, loss 0.08393163233995438, acc=0.972000002861023, loss=0.08393163233995438
test: epoch 145, loss 0.18475547432899475, acc=0.9388889074325562, loss=0.18475547432899475
train: epoch 146, loss 0.062027595937252045, acc=0.977222204208374, loss=0.062027595937252045
test: epoch 146, loss 0.1459551900625229, acc=0.949999988079071, loss=0.1459551900625229
train: epoch 147, loss 0.10126182436943054, acc=0.9693889021873474, loss=0.10126182436943054
test: epoch 147, loss 0.2318543791770935, acc=0.925000011920929, loss=0.2318543791770935
train: epoch 148, loss 0.10318039357662201, acc=0.9696111083030701, loss=0.10318039357662201
test: epoch 148, loss 0.8209289908409119, acc=0.9277777671813965, loss=0.8209289908409119
train: epoch 149, loss 0.08674398809671402, acc=0.9735000133514404, loss=0.08674398809671402
test: epoch 149, loss 0.1767028272151947, acc=0.9361110925674438, loss=0.1767028272151947
train: epoch 150, loss 0.07909555733203888, acc=0.9742222428321838, loss=0.07909555733203888
test: epoch 150, loss 0.17249272763729095, acc=0.9388889074325562, loss=0.17249272763729095
