# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=100", "--receiver_embed_dim=64", "--temperature=1", "--temp_decay=0.995", "--one_hot=true", "--n_layers=4"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=4, n_summands=2, n_symbols=100, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=940121247, receiver_embed_dim=64, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.1301348209381104, acc=0.07072222232818604, loss=3.1301348209381104
test: epoch 1, loss 2.756492853164673, acc=0.10555555671453476, loss=2.756492853164673
train: epoch 2, loss 2.121549129486084, acc=0.2034444510936737, loss=2.121549129486084
test: epoch 2, loss 1.8033027648925781, acc=0.2805555462837219, loss=1.8033027648925781
train: epoch 3, loss 1.5738606452941895, acc=0.32572221755981445, loss=1.5738606452941895
test: epoch 3, loss 1.705170750617981, acc=0.2944444417953491, loss=1.705170750617981
train: epoch 4, loss 1.375135064125061, acc=0.3946666717529297, loss=1.375135064125061
test: epoch 4, loss 1.5046380758285522, acc=0.32777777314186096, loss=1.5046380758285522
train: epoch 5, loss 1.2283340692520142, acc=0.44522222876548767, loss=1.2283340692520142
test: epoch 5, loss 1.3641360998153687, acc=0.3638888895511627, loss=1.3641360998153687
train: epoch 6, loss 1.1617231369018555, acc=0.4672222137451172, loss=1.1617231369018555
test: epoch 6, loss 1.4575475454330444, acc=0.3916666805744171, loss=1.4575475454330444
train: epoch 7, loss 1.1136218309402466, acc=0.4889444410800934, loss=1.1136218309402466
test: epoch 7, loss 1.2956476211547852, acc=0.41111111640930176, loss=1.2956476211547852
train: epoch 8, loss 1.0506765842437744, acc=0.5026666522026062, loss=1.0506765842437744
test: epoch 8, loss 1.4241379499435425, acc=0.40833333134651184, loss=1.4241379499435425
train: epoch 9, loss 1.0555672645568848, acc=0.5054444670677185, loss=1.0555672645568848
test: epoch 9, loss 1.4191839694976807, acc=0.3888888955116272, loss=1.4191839694976807
train: epoch 10, loss 1.034105896949768, acc=0.5106666684150696, loss=1.034105896949768
test: epoch 10, loss 1.4270033836364746, acc=0.4000000059604645, loss=1.4270033836364746
train: epoch 11, loss 1.007448434829712, acc=0.5285555720329285, loss=1.007448434829712
test: epoch 11, loss 1.449275016784668, acc=0.4027777910232544, loss=1.449275016784668
train: epoch 12, loss 1.0141260623931885, acc=0.5262222290039062, loss=1.0141260623931885
test: epoch 12, loss 1.38985276222229, acc=0.40833333134651184, loss=1.38985276222229
train: epoch 13, loss 1.0233612060546875, acc=0.5208888649940491, loss=1.0233612060546875
test: epoch 13, loss 1.3562729358673096, acc=0.4027777910232544, loss=1.3562729358673096
train: epoch 14, loss 1.0071423053741455, acc=0.5302222371101379, loss=1.0071423053741455
test: epoch 14, loss 1.4873567819595337, acc=0.4055555462837219, loss=1.4873567819595337
train: epoch 15, loss 1.0048060417175293, acc=0.5295555591583252, loss=1.0048060417175293
test: epoch 15, loss 1.3299468755722046, acc=0.4166666567325592, loss=1.3299468755722046
train: epoch 16, loss 0.9691455960273743, acc=0.542888879776001, loss=0.9691455960273743
test: epoch 16, loss 1.3119831085205078, acc=0.4166666567325592, loss=1.3119831085205078
train: epoch 17, loss 0.985702633857727, acc=0.543666660785675, loss=0.985702633857727
test: epoch 17, loss 1.4313048124313354, acc=0.42222222685813904, loss=1.4313048124313354
train: epoch 18, loss 0.9778713583946228, acc=0.538444459438324, loss=0.9778713583946228
test: epoch 18, loss 1.3952834606170654, acc=0.4194444417953491, loss=1.3952834606170654
train: epoch 19, loss 0.956834614276886, acc=0.5575000047683716, loss=0.956834614276886
test: epoch 19, loss 1.4491119384765625, acc=0.4055555462837219, loss=1.4491119384765625
train: epoch 20, loss 0.9758244752883911, acc=0.550944447517395, loss=0.9758244752883911
test: epoch 20, loss 1.3352723121643066, acc=0.4194444417953491, loss=1.3352723121643066
train: epoch 21, loss 0.9566867351531982, acc=0.5565555691719055, loss=0.9566867351531982
test: epoch 21, loss 1.4814038276672363, acc=0.4138889014720917, loss=1.4814038276672363
train: epoch 22, loss 0.9644522070884705, acc=0.5551111102104187, loss=0.9644522070884705
test: epoch 22, loss 1.3440603017807007, acc=0.42222222685813904, loss=1.3440603017807007
train: epoch 23, loss 0.9571698307991028, acc=0.5575555562973022, loss=0.9571698307991028
test: epoch 23, loss 1.2932490110397339, acc=0.4194444417953491, loss=1.2932490110397339
train: epoch 24, loss 0.9411709904670715, acc=0.5596666932106018, loss=0.9411709904670715
test: epoch 24, loss 1.4006731510162354, acc=0.4138889014720917, loss=1.4006731510162354
train: epoch 25, loss 0.9426136612892151, acc=0.5630000233650208, loss=0.9426136612892151
test: epoch 25, loss 1.46310293674469, acc=0.4166666567325592, loss=1.46310293674469
train: epoch 26, loss 0.9425341486930847, acc=0.5659999847412109, loss=0.9425341486930847
test: epoch 26, loss 1.4601958990097046, acc=0.4055555462837219, loss=1.4601958990097046
train: epoch 27, loss 0.9341839551925659, acc=0.5706111192703247, loss=0.9341839551925659
test: epoch 27, loss 1.4174503087997437, acc=0.4277777671813965, loss=1.4174503087997437
train: epoch 28, loss 0.950316309928894, acc=0.5642777681350708, loss=0.950316309928894
test: epoch 28, loss 1.3517282009124756, acc=0.4277777671813965, loss=1.3517282009124756
train: epoch 29, loss 0.9397439956665039, acc=0.5672777891159058, loss=0.9397439956665039
test: epoch 29, loss 1.2825360298156738, acc=0.4277777671813965, loss=1.2825360298156738
train: epoch 30, loss 0.9388996958732605, acc=0.5692777633666992, loss=0.9388996958732605
test: epoch 30, loss 1.3453887701034546, acc=0.4277777671813965, loss=1.3453887701034546
train: epoch 31, loss 0.919072151184082, acc=0.5712777972221375, loss=0.919072151184082
test: epoch 31, loss 1.3056106567382812, acc=0.4277777671813965, loss=1.3056106567382812
train: epoch 32, loss 0.9345577359199524, acc=0.5734999775886536, loss=0.9345577359199524
test: epoch 32, loss 1.411831021308899, acc=0.4277777671813965, loss=1.411831021308899
train: epoch 33, loss 0.9302957057952881, acc=0.5719444155693054, loss=0.9302957057952881
test: epoch 33, loss 1.3637168407440186, acc=0.42500001192092896, loss=1.3637168407440186
train: epoch 34, loss 0.9304216504096985, acc=0.56977778673172, loss=0.9304216504096985
test: epoch 34, loss 1.41982901096344, acc=0.4277777671813965, loss=1.41982901096344
train: epoch 35, loss 0.9427551031112671, acc=0.5709999799728394, loss=0.9427551031112671
test: epoch 35, loss 1.3511210680007935, acc=0.42500001192092896, loss=1.3511210680007935
train: epoch 36, loss 0.9293993711471558, acc=0.5726110935211182, loss=0.9293993711471558
test: epoch 36, loss 1.265236735343933, acc=0.42222222685813904, loss=1.265236735343933
train: epoch 37, loss 0.9432157278060913, acc=0.5699999928474426, loss=0.9432157278060913
test: epoch 37, loss 1.337515950202942, acc=0.4194444417953491, loss=1.337515950202942
train: epoch 38, loss 0.9261557459831238, acc=0.5781111121177673, loss=0.9261557459831238
test: epoch 38, loss 1.4326614141464233, acc=0.42222222685813904, loss=1.4326614141464233
train: epoch 39, loss 0.902842104434967, acc=0.5843889117240906, loss=0.902842104434967
test: epoch 39, loss 1.4550747871398926, acc=0.4277777671813965, loss=1.4550747871398926
train: epoch 40, loss 0.9093790054321289, acc=0.5812777876853943, loss=0.9093790054321289
test: epoch 40, loss 1.3856711387634277, acc=0.4277777671813965, loss=1.3856711387634277
train: epoch 41, loss 0.9200877547264099, acc=0.5821666717529297, loss=0.9200877547264099
test: epoch 41, loss 1.3855631351470947, acc=0.4333333373069763, loss=1.3855631351470947
train: epoch 42, loss 0.9018215537071228, acc=0.5871666669845581, loss=0.9018215537071228
test: epoch 42, loss 1.3469023704528809, acc=0.4333333373069763, loss=1.3469023704528809
train: epoch 43, loss 0.8868364095687866, acc=0.592555582523346, loss=0.8868364095687866
test: epoch 43, loss 1.3948017358779907, acc=0.4194444417953491, loss=1.3948017358779907
train: epoch 44, loss 0.907855212688446, acc=0.5837777853012085, loss=0.907855212688446
test: epoch 44, loss 1.3923786878585815, acc=0.4333333373069763, loss=1.3923786878585815
train: epoch 45, loss 0.9467592835426331, acc=0.5638889074325562, loss=0.9467592835426331
test: epoch 45, loss 1.2807903289794922, acc=0.43611112236976624, loss=1.2807903289794922
train: epoch 46, loss 0.9121617674827576, acc=0.5613889098167419, loss=0.9121617674827576
test: epoch 46, loss 1.2574585676193237, acc=0.42500001192092896, loss=1.2574585676193237
train: epoch 47, loss 0.9207925200462341, acc=0.562833309173584, loss=0.9207925200462341
test: epoch 47, loss 1.2405524253845215, acc=0.4444444477558136, loss=1.2405524253845215
train: epoch 48, loss 0.8951015472412109, acc=0.5817777514457703, loss=0.8951015472412109
test: epoch 48, loss 1.2974776029586792, acc=0.4444444477558136, loss=1.2974776029586792
train: epoch 49, loss 0.8953557014465332, acc=0.5879999995231628, loss=0.8953557014465332
test: epoch 49, loss 1.271567940711975, acc=0.4611110985279083, loss=1.271567940711975
train: epoch 50, loss 0.8845697045326233, acc=0.5924444198608398, loss=0.8845697045326233
test: epoch 50, loss 1.2312521934509277, acc=0.4555555582046509, loss=1.2312521934509277
train: epoch 51, loss 0.8738278150558472, acc=0.6015555262565613, loss=0.8738278150558472
test: epoch 51, loss 1.3158429861068726, acc=0.4138889014720917, loss=1.3158429861068726
train: epoch 52, loss 0.8811414241790771, acc=0.5948888659477234, loss=0.8811414241790771
test: epoch 52, loss 1.3523006439208984, acc=0.4555555582046509, loss=1.3523006439208984
train: epoch 53, loss 0.8682080507278442, acc=0.6023333072662354, loss=0.8682080507278442
test: epoch 53, loss 1.3282289505004883, acc=0.4611110985279083, loss=1.3282289505004883
train: epoch 54, loss 0.8405875563621521, acc=0.6166666746139526, loss=0.8405875563621521
test: epoch 54, loss 1.257488489151001, acc=0.4694444537162781, loss=1.257488489151001
train: epoch 55, loss 0.8029550909996033, acc=0.624833345413208, loss=0.8029550909996033
test: epoch 55, loss 1.420408010482788, acc=0.4611110985279083, loss=1.420408010482788
train: epoch 56, loss 0.83261638879776, acc=0.6116111278533936, loss=0.83261638879776
test: epoch 56, loss 1.2684757709503174, acc=0.4611110985279083, loss=1.2684757709503174
train: epoch 57, loss 0.7892374396324158, acc=0.6262221932411194, loss=0.7892374396324158
test: epoch 57, loss 1.2228773832321167, acc=0.4555555582046509, loss=1.2228773832321167
train: epoch 58, loss 0.7959674596786499, acc=0.624666690826416, loss=0.7959674596786499
test: epoch 58, loss 1.2891185283660889, acc=0.4611110985279083, loss=1.2891185283660889
train: epoch 59, loss 0.8219277858734131, acc=0.6129999756813049, loss=0.8219277858734131
test: epoch 59, loss 1.3708769083023071, acc=0.4611110985279083, loss=1.3708769083023071
train: epoch 60, loss 0.8136895298957825, acc=0.616611123085022, loss=0.8136895298957825
test: epoch 60, loss 1.3710230588912964, acc=0.4611110985279083, loss=1.3710230588912964
train: epoch 61, loss 0.81330406665802, acc=0.6187777519226074, loss=0.81330406665802
test: epoch 61, loss 1.4185494184494019, acc=0.4555555582046509, loss=1.4185494184494019
train: epoch 62, loss 0.7687244415283203, acc=0.6298333406448364, loss=0.7687244415283203
test: epoch 62, loss 1.4583011865615845, acc=0.4583333432674408, loss=1.4583011865615845
train: epoch 63, loss 0.7992541790008545, acc=0.6236110925674438, loss=0.7992541790008545
test: epoch 63, loss 1.4193317890167236, acc=0.46388888359069824, loss=1.4193317890167236
train: epoch 64, loss 0.7653855085372925, acc=0.6317222118377686, loss=0.7653855085372925
test: epoch 64, loss 1.3733350038528442, acc=0.46388888359069824, loss=1.3733350038528442
train: epoch 65, loss 0.7615607380867004, acc=0.6303333044052124, loss=0.7615607380867004
test: epoch 65, loss 1.3568072319030762, acc=0.4583333432674408, loss=1.3568072319030762
train: epoch 66, loss 0.7480142712593079, acc=0.637333333492279, loss=0.7480142712593079
test: epoch 66, loss 1.4184620380401611, acc=0.4583333432674408, loss=1.4184620380401611
train: epoch 67, loss 0.7883268594741821, acc=0.6267777681350708, loss=0.7883268594741821
test: epoch 67, loss 1.3244203329086304, acc=0.4611110985279083, loss=1.3244203329086304
train: epoch 68, loss 0.7845904231071472, acc=0.6274444460868835, loss=0.7845904231071472
test: epoch 68, loss 1.290175199508667, acc=0.46388888359069824, loss=1.290175199508667
train: epoch 69, loss 0.8026771545410156, acc=0.6114444732666016, loss=0.8026771545410156
test: epoch 69, loss 1.3414746522903442, acc=0.44999998807907104, loss=1.3414746522903442
train: epoch 70, loss 0.7621063590049744, acc=0.6303333044052124, loss=0.7621063590049744
test: epoch 70, loss 1.2958850860595703, acc=0.46388888359069824, loss=1.2958850860595703
train: epoch 71, loss 0.7536998987197876, acc=0.6333333253860474, loss=0.7536998987197876
test: epoch 71, loss 1.320021390914917, acc=0.4611110985279083, loss=1.320021390914917
train: epoch 72, loss 0.7858051657676697, acc=0.6226666569709778, loss=0.7858051657676697
test: epoch 72, loss 1.4170606136322021, acc=0.44999998807907104, loss=1.4170606136322021
train: epoch 73, loss 0.7590274214744568, acc=0.6300555467605591, loss=0.7590274214744568
test: epoch 73, loss 1.429758071899414, acc=0.45277777314186096, loss=1.429758071899414
train: epoch 74, loss 0.7647925615310669, acc=0.6315000057220459, loss=0.7647925615310669
test: epoch 74, loss 1.4078030586242676, acc=0.46388888359069824, loss=1.4078030586242676
train: epoch 75, loss 0.7355150580406189, acc=0.6399444341659546, loss=0.7355150580406189
test: epoch 75, loss 1.3217664957046509, acc=0.4583333432674408, loss=1.3217664957046509
train: epoch 76, loss 0.7792758345603943, acc=0.6272777915000916, loss=0.7792758345603943
test: epoch 76, loss 1.4330203533172607, acc=0.4583333432674408, loss=1.4330203533172607
train: epoch 77, loss 0.759797215461731, acc=0.6298333406448364, loss=0.759797215461731
test: epoch 77, loss 1.395467758178711, acc=0.4555555582046509, loss=1.395467758178711
train: epoch 78, loss 0.7392333149909973, acc=0.6424444317817688, loss=0.7392333149909973
test: epoch 78, loss 1.324942946434021, acc=0.4194444417953491, loss=1.324942946434021
train: epoch 79, loss 0.7368174195289612, acc=0.6461111307144165, loss=0.7368174195289612
test: epoch 79, loss 1.4552158117294312, acc=0.4444444477558136, loss=1.4552158117294312
train: epoch 80, loss 0.7488868832588196, acc=0.6357777714729309, loss=0.7488868832588196
test: epoch 80, loss 1.431636929512024, acc=0.4555555582046509, loss=1.431636929512024
train: epoch 81, loss 0.7555944919586182, acc=0.6365000009536743, loss=0.7555944919586182
test: epoch 81, loss 1.438245177268982, acc=0.4611110985279083, loss=1.438245177268982
train: epoch 82, loss 0.7353560328483582, acc=0.6413888931274414, loss=0.7353560328483582
test: epoch 82, loss 1.3929548263549805, acc=0.4555555582046509, loss=1.3929548263549805
train: epoch 83, loss 0.7389174103736877, acc=0.6387222409248352, loss=0.7389174103736877
test: epoch 83, loss 1.340429663658142, acc=0.4611110985279083, loss=1.340429663658142
train: epoch 84, loss 0.7334834337234497, acc=0.6432777643203735, loss=0.7334834337234497
test: epoch 84, loss 1.4731208086013794, acc=0.42500001192092896, loss=1.4731208086013794
train: epoch 85, loss 0.7385761141777039, acc=0.6395000219345093, loss=0.7385761141777039
test: epoch 85, loss 1.3992602825164795, acc=0.4583333432674408, loss=1.3992602825164795
train: epoch 86, loss 0.7430925369262695, acc=0.6426666378974915, loss=0.7430925369262695
test: epoch 86, loss 1.4852535724639893, acc=0.45277777314186096, loss=1.4852535724639893
train: epoch 87, loss 0.7039155960083008, acc=0.6434999704360962, loss=0.7039155960083008
test: epoch 87, loss 1.382980227470398, acc=0.4555555582046509, loss=1.382980227470398
train: epoch 88, loss 0.7799464464187622, acc=0.6374444365501404, loss=0.7799464464187622
test: epoch 88, loss 1.4458831548690796, acc=0.4611110985279083, loss=1.4458831548690796
train: epoch 89, loss 0.7438700199127197, acc=0.6431111097335815, loss=0.7438700199127197
test: epoch 89, loss 1.379888653755188, acc=0.45277777314186096, loss=1.379888653755188
train: epoch 90, loss 0.7213970422744751, acc=0.6473333239555359, loss=0.7213970422744751
test: epoch 90, loss 1.4323469400405884, acc=0.44999998807907104, loss=1.4323469400405884
train: epoch 91, loss 0.7493517398834229, acc=0.637333333492279, loss=0.7493517398834229
test: epoch 91, loss 1.5190188884735107, acc=0.4583333432674408, loss=1.5190188884735107
train: epoch 92, loss 0.7386380434036255, acc=0.6453889012336731, loss=0.7386380434036255
test: epoch 92, loss 1.4550144672393799, acc=0.40833333134651184, loss=1.4550144672393799
train: epoch 93, loss 0.7073346972465515, acc=0.6535000205039978, loss=0.7073346972465515
test: epoch 93, loss 1.423195481300354, acc=0.45277777314186096, loss=1.423195481300354
train: epoch 94, loss 0.728821337223053, acc=0.6397222280502319, loss=0.728821337223053
test: epoch 94, loss 1.355234980583191, acc=0.4611110985279083, loss=1.355234980583191
train: epoch 95, loss 0.7210977077484131, acc=0.6445000171661377, loss=0.7210977077484131
test: epoch 95, loss 1.390822410583496, acc=0.4749999940395355, loss=1.390822410583496
train: epoch 96, loss 0.6686214208602905, acc=0.6611666679382324, loss=0.6686214208602905
test: epoch 96, loss 1.3617194890975952, acc=0.5055555701255798, loss=1.3617194890975952
train: epoch 97, loss 0.6904811263084412, acc=0.6528333425521851, loss=0.6904811263084412
test: epoch 97, loss 1.345394253730774, acc=0.5027777552604675, loss=1.345394253730774
train: epoch 98, loss 0.6581032276153564, acc=0.6689444184303284, loss=0.6581032276153564
test: epoch 98, loss 1.197218656539917, acc=0.5222222208976746, loss=1.197218656539917
train: epoch 99, loss 0.6502901315689087, acc=0.6739444732666016, loss=0.6502901315689087
test: epoch 99, loss 1.1522506475448608, acc=0.5305555462837219, loss=1.1522506475448608
train: epoch 100, loss 0.7425387501716614, acc=0.6493889093399048, loss=0.7425387501716614
test: epoch 100, loss 1.2828865051269531, acc=0.5166666507720947, loss=1.2828865051269531
train: epoch 101, loss 0.656785249710083, acc=0.6736666560173035, loss=0.656785249710083
test: epoch 101, loss 1.1012905836105347, acc=0.5444444417953491, loss=1.1012905836105347
train: epoch 102, loss 0.6418663263320923, acc=0.671999990940094, loss=0.6418663263320923
test: epoch 102, loss 1.1185578107833862, acc=0.5138888955116272, loss=1.1185578107833862
train: epoch 103, loss 0.6327996253967285, acc=0.6776111125946045, loss=0.6327996253967285
test: epoch 103, loss 1.1669905185699463, acc=0.5249999761581421, loss=1.1669905185699463
train: epoch 104, loss 0.7196753025054932, acc=0.6629999876022339, loss=0.7196753025054932
test: epoch 104, loss 1.0966917276382446, acc=0.5361111164093018, loss=1.0966917276382446
train: epoch 105, loss 0.6638295650482178, acc=0.6747778058052063, loss=0.6638295650482178
test: epoch 105, loss 1.1642746925354004, acc=0.5222222208976746, loss=1.1642746925354004
train: epoch 106, loss 0.6360568404197693, acc=0.6800000071525574, loss=0.6360568404197693
test: epoch 106, loss 1.1887978315353394, acc=0.5361111164093018, loss=1.1887978315353394
train: epoch 107, loss 0.6366733908653259, acc=0.6821110844612122, loss=0.6366733908653259
test: epoch 107, loss 1.1319291591644287, acc=0.519444465637207, loss=1.1319291591644287
train: epoch 108, loss 0.6261981725692749, acc=0.6865000128746033, loss=0.6261981725692749
test: epoch 108, loss 1.4758167266845703, acc=0.5277777910232544, loss=1.4758167266845703
train: epoch 109, loss 0.6095190644264221, acc=0.6917222142219543, loss=0.6095190644264221
test: epoch 109, loss 1.1958787441253662, acc=0.49444442987442017, loss=1.1958787441253662
train: epoch 110, loss 0.6218581199645996, acc=0.6888333559036255, loss=0.6218581199645996
test: epoch 110, loss 1.156463623046875, acc=0.5388888716697693, loss=1.156463623046875
train: epoch 111, loss 0.6121014952659607, acc=0.691444456577301, loss=0.6121014952659607
test: epoch 111, loss 1.2145419120788574, acc=0.5388888716697693, loss=1.2145419120788574
train: epoch 112, loss 0.6327304244041443, acc=0.6907222270965576, loss=0.6327304244041443
test: epoch 112, loss 1.2554851770401, acc=0.5388888716697693, loss=1.2554851770401
train: epoch 113, loss 0.6704567074775696, acc=0.6762222051620483, loss=0.6704567074775696
test: epoch 113, loss 1.04740571975708, acc=0.5333333611488342, loss=1.04740571975708
train: epoch 114, loss 0.6279825568199158, acc=0.6844444274902344, loss=0.6279825568199158
test: epoch 114, loss 1.1763811111450195, acc=0.5416666865348816, loss=1.1763811111450195
train: epoch 115, loss 0.5980761051177979, acc=0.6945000290870667, loss=0.5980761051177979
test: epoch 115, loss 1.174228310585022, acc=0.5777778029441833, loss=1.174228310585022
train: epoch 116, loss 0.5765421986579895, acc=0.7004444599151611, loss=0.5765421986579895
test: epoch 116, loss 0.9690687656402588, acc=0.6111111044883728, loss=0.9690687656402588
train: epoch 117, loss 0.6265596747398376, acc=0.6874444484710693, loss=0.6265596747398376
test: epoch 117, loss 0.9147208333015442, acc=0.6027777791023254, loss=0.9147208333015442
train: epoch 118, loss 0.5863463878631592, acc=0.695722222328186, loss=0.5863463878631592
test: epoch 118, loss 0.8798728585243225, acc=0.6138888597488403, loss=0.8798728585243225
train: epoch 119, loss 0.588950514793396, acc=0.695388913154602, loss=0.588950514793396
test: epoch 119, loss 0.8858565092086792, acc=0.6111111044883728, loss=0.8858565092086792
train: epoch 120, loss 0.5578185319900513, acc=0.7007222175598145, loss=0.5578185319900513
test: epoch 120, loss 0.8815781474113464, acc=0.6138888597488403, loss=0.8815781474113464
train: epoch 121, loss 0.5903968214988708, acc=0.6966666579246521, loss=0.5903968214988708
test: epoch 121, loss 0.9583966135978699, acc=0.6083333492279053, loss=0.9583966135978699
train: epoch 122, loss 0.5672942399978638, acc=0.7003333568572998, loss=0.5672942399978638
test: epoch 122, loss 0.9937707781791687, acc=0.6111111044883728, loss=0.9937707781791687
train: epoch 123, loss 0.5566025972366333, acc=0.7012222409248352, loss=0.5566025972366333
test: epoch 123, loss 0.9462199211120605, acc=0.6138888597488403, loss=0.9462199211120605
train: epoch 124, loss 0.5709151029586792, acc=0.6965555548667908, loss=0.5709151029586792
test: epoch 124, loss 0.8997002840042114, acc=0.6111111044883728, loss=0.8997002840042114
train: epoch 125, loss 0.5573393702507019, acc=0.6982777714729309, loss=0.5573393702507019
test: epoch 125, loss 0.9123436212539673, acc=0.6083333492279053, loss=0.9123436212539673
train: epoch 126, loss 0.5626790523529053, acc=0.7035555839538574, loss=0.5626790523529053
test: epoch 126, loss 0.9505836963653564, acc=0.6138888597488403, loss=0.9505836963653564
train: epoch 127, loss 0.5720236897468567, acc=0.7012777924537659, loss=0.5720236897468567
test: epoch 127, loss 0.919457197189331, acc=0.6083333492279053, loss=0.919457197189331
train: epoch 128, loss 0.6074040532112122, acc=0.6969444155693054, loss=0.6074040532112122
test: epoch 128, loss 0.9530466794967651, acc=0.6138888597488403, loss=0.9530466794967651
train: epoch 129, loss 0.5507752895355225, acc=0.7009444236755371, loss=0.5507752895355225
test: epoch 129, loss 0.9618289470672607, acc=0.6138888597488403, loss=0.9618289470672607
train: epoch 130, loss 0.56480473279953, acc=0.7035555839538574, loss=0.56480473279953
test: epoch 130, loss 0.8481552600860596, acc=0.6138888597488403, loss=0.8481552600860596
train: epoch 131, loss 0.54633629322052, acc=0.7027778029441833, loss=0.54633629322052
test: epoch 131, loss 0.9952713847160339, acc=0.605555534362793, loss=0.9952713847160339
train: epoch 132, loss 0.5667447447776794, acc=0.7018333077430725, loss=0.5667447447776794
test: epoch 132, loss 0.943706214427948, acc=0.6138888597488403, loss=0.943706214427948
train: epoch 133, loss 0.5399170517921448, acc=0.7065555453300476, loss=0.5399170517921448
test: epoch 133, loss 0.9317812919616699, acc=0.5944444537162781, loss=0.9317812919616699
train: epoch 134, loss 0.6449382305145264, acc=0.6824444532394409, loss=0.6449382305145264
test: epoch 134, loss 0.9605664014816284, acc=0.5888888835906982, loss=0.9605664014816284
train: epoch 135, loss 0.6520240306854248, acc=0.6656666398048401, loss=0.6520240306854248
test: epoch 135, loss 0.8507039546966553, acc=0.6111111044883728, loss=0.8507039546966553
train: epoch 136, loss 0.643160879611969, acc=0.6676666736602783, loss=0.643160879611969
test: epoch 136, loss 0.8857252597808838, acc=0.6111111044883728, loss=0.8857252597808838
train: epoch 137, loss 0.6186444163322449, acc=0.6738333106040955, loss=0.6186444163322449
test: epoch 137, loss 0.9302000403404236, acc=0.6083333492279053, loss=0.9302000403404236
train: epoch 138, loss 0.620001494884491, acc=0.6770555377006531, loss=0.620001494884491
test: epoch 138, loss 0.8668055534362793, acc=0.6083333492279053, loss=0.8668055534362793
train: epoch 139, loss 0.6943740844726562, acc=0.6586111187934875, loss=0.6943740844726562
test: epoch 139, loss 0.9085192680358887, acc=0.6305555701255798, loss=0.9085192680358887
train: epoch 140, loss 0.6490513682365417, acc=0.6713888645172119, loss=0.6490513682365417
test: epoch 140, loss 0.7609127759933472, acc=0.6416666507720947, loss=0.7609127759933472
train: epoch 141, loss 0.6209056973457336, acc=0.6736666560173035, loss=0.6209056973457336
test: epoch 141, loss 0.7601473927497864, acc=0.6472222208976746, loss=0.7601473927497864
train: epoch 142, loss 0.5939156413078308, acc=0.679444432258606, loss=0.5939156413078308
test: epoch 142, loss 0.7410671710968018, acc=0.6472222208976746, loss=0.7410671710968018
train: epoch 143, loss 0.8471497297286987, acc=0.6102777719497681, loss=0.8471497297286987
test: epoch 143, loss 0.995993971824646, acc=0.5861111283302307, loss=0.995993971824646
train: epoch 144, loss 0.7616291046142578, acc=0.6353889107704163, loss=0.7616291046142578
test: epoch 144, loss 0.8900672197341919, acc=0.625, loss=0.8900672197341919
train: epoch 145, loss 0.6832877397537231, acc=0.6545000076293945, loss=0.6832877397537231
test: epoch 145, loss 0.8452626466751099, acc=0.6222222447395325, loss=0.8452626466751099
train: epoch 146, loss 0.6897384524345398, acc=0.6506111025810242, loss=0.6897384524345398
test: epoch 146, loss 0.8176451325416565, acc=0.6166666746139526, loss=0.8176451325416565
train: epoch 147, loss 0.6816372275352478, acc=0.6472777724266052, loss=0.6816372275352478
test: epoch 147, loss 0.8141447305679321, acc=0.6222222447395325, loss=0.8141447305679321
train: epoch 148, loss 0.6846346259117126, acc=0.6514444351196289, loss=0.6846346259117126
test: epoch 148, loss 0.7990897297859192, acc=0.6222222447395325, loss=0.7990897297859192
train: epoch 149, loss 0.6475751996040344, acc=0.6580555438995361, loss=0.6475751996040344
test: epoch 149, loss 0.81159508228302, acc=0.6222222447395325, loss=0.81159508228302
train: epoch 150, loss 0.6520388126373291, acc=0.6552777886390686, loss=0.6520388126373291
test: epoch 150, loss 0.7564845085144043, acc=0.6222222447395325, loss=0.7564845085144043
