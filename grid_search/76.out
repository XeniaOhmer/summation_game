# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=1.5", "--temp_decay=1", "--one_hot=1", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=1178537621, receiver_embed_dim=64, save_run=0, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1178537621, receiver_embed_dim=64, save_run=False, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.2993662357330322, acc=0.06572221964597702, loss=3.2993662357330322
test: epoch 1, loss 4.032589435577393, acc=0.08055555820465088, loss=4.032589435577393
train: epoch 2, loss 2.1914050579071045, acc=0.2492777705192566, loss=2.1914050579071045
test: epoch 2, loss 3.8562405109405518, acc=0.10555555671453476, loss=3.8562405109405518
train: epoch 3, loss 1.6291720867156982, acc=0.38377776741981506, loss=1.6291720867156982
test: epoch 3, loss 3.0259628295898438, acc=0.1527777761220932, loss=3.0259628295898438
train: epoch 4, loss 1.3821698427200317, acc=0.457111120223999, loss=1.3821698427200317
test: epoch 4, loss 2.6568610668182373, acc=0.15833333134651184, loss=2.6568610668182373
train: epoch 5, loss 1.2129188776016235, acc=0.5230000019073486, loss=1.2129188776016235
test: epoch 5, loss 2.7219791412353516, acc=0.1944444477558136, loss=2.7219791412353516
train: epoch 6, loss 1.1036243438720703, acc=0.5670555830001831, loss=1.1036243438720703
test: epoch 6, loss 2.5259814262390137, acc=0.2361111044883728, loss=2.5259814262390137
train: epoch 7, loss 1.013540267944336, acc=0.6044999957084656, loss=1.013540267944336
test: epoch 7, loss 2.6929080486297607, acc=0.20277777314186096, loss=2.6929080486297607
train: epoch 8, loss 0.940588116645813, acc=0.6339444518089294, loss=0.940588116645813
test: epoch 8, loss 2.650116443634033, acc=0.21944443881511688, loss=2.650116443634033
train: epoch 9, loss 0.8784570693969727, acc=0.6670555472373962, loss=0.8784570693969727
test: epoch 9, loss 2.549090623855591, acc=0.25833332538604736, loss=2.549090623855591
train: epoch 10, loss 0.8280531764030457, acc=0.6873888969421387, loss=0.8280531764030457
test: epoch 10, loss 2.2940595149993896, acc=0.24722221493721008, loss=2.2940595149993896
train: epoch 11, loss 0.7782112956047058, acc=0.7088333368301392, loss=0.7782112956047058
test: epoch 11, loss 2.255434274673462, acc=0.2750000059604645, loss=2.255434274673462
train: epoch 12, loss 0.7113717794418335, acc=0.7301111221313477, loss=0.7113717794418335
test: epoch 12, loss 2.3449413776397705, acc=0.2805555462837219, loss=2.3449413776397705
train: epoch 13, loss 0.6769903898239136, acc=0.7484999895095825, loss=0.6769903898239136
test: epoch 13, loss 2.360097885131836, acc=0.2916666567325592, loss=2.360097885131836
train: epoch 14, loss 0.6560826301574707, acc=0.7633333206176758, loss=0.6560826301574707
test: epoch 14, loss 2.2422871589660645, acc=0.3166666626930237, loss=2.2422871589660645
train: epoch 15, loss 0.6047728061676025, acc=0.7760555744171143, loss=0.6047728061676025
test: epoch 15, loss 2.1040139198303223, acc=0.3055555522441864, loss=2.1040139198303223
train: epoch 16, loss 0.5863199830055237, acc=0.7878888845443726, loss=0.5863199830055237
test: epoch 16, loss 2.0729010105133057, acc=0.3499999940395355, loss=2.0729010105133057
train: epoch 17, loss 0.5500516295433044, acc=0.7954999804496765, loss=0.5500516295433044
test: epoch 17, loss 2.0441277027130127, acc=0.3472222089767456, loss=2.0441277027130127
train: epoch 18, loss 0.5424388647079468, acc=0.8048333525657654, loss=0.5424388647079468
test: epoch 18, loss 1.9455478191375732, acc=0.34166666865348816, loss=1.9455478191375732
train: epoch 19, loss 0.49763602018356323, acc=0.8173888921737671, loss=0.49763602018356323
test: epoch 19, loss 1.959838628768921, acc=0.3222222328186035, loss=1.959838628768921
train: epoch 20, loss 0.483106404542923, acc=0.8238333463668823, loss=0.483106404542923
test: epoch 20, loss 1.8522312641143799, acc=0.3333333432674408, loss=1.8522312641143799
train: epoch 21, loss 0.47464439272880554, acc=0.8307222127914429, loss=0.47464439272880554
test: epoch 21, loss 1.8651137351989746, acc=0.3444444537162781, loss=1.8651137351989746
train: epoch 22, loss 0.44474878907203674, acc=0.8389444351196289, loss=0.44474878907203674
test: epoch 22, loss 1.8079661130905151, acc=0.36666667461395264, loss=1.8079661130905151
train: epoch 23, loss 0.43495792150497437, acc=0.8475000262260437, loss=0.43495792150497437
test: epoch 23, loss 1.899134874343872, acc=0.3361110985279083, loss=1.899134874343872
train: epoch 24, loss 0.41591310501098633, acc=0.8490555286407471, loss=0.41591310501098633
test: epoch 24, loss 1.8835690021514893, acc=0.3638888895511627, loss=1.8835690021514893
train: epoch 25, loss 0.39415937662124634, acc=0.856166660785675, loss=0.39415937662124634
test: epoch 25, loss 1.712554693222046, acc=0.36666667461395264, loss=1.712554693222046
train: epoch 26, loss 0.38243618607521057, acc=0.8622221946716309, loss=0.38243618607521057
test: epoch 26, loss 1.690221905708313, acc=0.4194444417953491, loss=1.690221905708313
train: epoch 27, loss 0.37256988883018494, acc=0.8691666722297668, loss=0.37256988883018494
test: epoch 27, loss 1.844225287437439, acc=0.4055555462837219, loss=1.844225287437439
train: epoch 28, loss 0.3643076717853546, acc=0.870722234249115, loss=0.3643076717853546
test: epoch 28, loss 1.7145699262619019, acc=0.38333332538604736, loss=1.7145699262619019
train: epoch 29, loss 0.3611011207103729, acc=0.8717777729034424, loss=0.3611011207103729
test: epoch 29, loss 1.7675836086273193, acc=0.4055555462837219, loss=1.7675836086273193
train: epoch 30, loss 0.3407946228981018, acc=0.8811110854148865, loss=0.3407946228981018
test: epoch 30, loss 1.6050615310668945, acc=0.41111111640930176, loss=1.6050615310668945
train: epoch 31, loss 0.33923661708831787, acc=0.8828333616256714, loss=0.33923661708831787
test: epoch 31, loss 1.6555169820785522, acc=0.4416666626930237, loss=1.6555169820785522
train: epoch 32, loss 0.32597243785858154, acc=0.8884999752044678, loss=0.32597243785858154
test: epoch 32, loss 1.6239776611328125, acc=0.4166666567325592, loss=1.6239776611328125
train: epoch 33, loss 0.29946276545524597, acc=0.8952222466468811, loss=0.29946276545524597
test: epoch 33, loss 1.7140153646469116, acc=0.43611112236976624, loss=1.7140153646469116
train: epoch 34, loss 0.29507577419281006, acc=0.8955000042915344, loss=0.29507577419281006
test: epoch 34, loss 1.5757558345794678, acc=0.43888887763023376, loss=1.5757558345794678
train: epoch 35, loss 0.28244930505752563, acc=0.8976666927337646, loss=0.28244930505752563
test: epoch 35, loss 1.623547077178955, acc=0.43888887763023376, loss=1.623547077178955
train: epoch 36, loss 0.2811991274356842, acc=0.899055540561676, loss=0.2811991274356842
test: epoch 36, loss 1.6570570468902588, acc=0.42222222685813904, loss=1.6570570468902588
train: epoch 37, loss 0.2818059027194977, acc=0.9029444456100464, loss=0.2818059027194977
test: epoch 37, loss 1.7019920349121094, acc=0.42222222685813904, loss=1.7019920349121094
train: epoch 38, loss 0.28403815627098083, acc=0.9017221927642822, loss=0.28403815627098083
test: epoch 38, loss 1.5071146488189697, acc=0.42500001192092896, loss=1.5071146488189697
train: epoch 39, loss 0.26885131001472473, acc=0.9065555334091187, loss=0.26885131001472473
test: epoch 39, loss 1.6450365781784058, acc=0.4194444417953491, loss=1.6450365781784058
train: epoch 40, loss 0.254540354013443, acc=0.9132221937179565, loss=0.254540354013443
test: epoch 40, loss 1.6303614377975464, acc=0.4583333432674408, loss=1.6303614377975464
train: epoch 41, loss 0.2570324242115021, acc=0.9119444489479065, loss=0.2570324242115021
test: epoch 41, loss 1.696260929107666, acc=0.4333333373069763, loss=1.696260929107666
train: epoch 42, loss 0.23441864550113678, acc=0.9196110963821411, loss=0.23441864550113678
test: epoch 42, loss 1.7733843326568604, acc=0.4305555522441864, loss=1.7733843326568604
train: epoch 43, loss 0.2480730563402176, acc=0.914222240447998, loss=0.2480730563402176
test: epoch 43, loss 1.6410549879074097, acc=0.4305555522441864, loss=1.6410549879074097
train: epoch 44, loss 0.24210980534553528, acc=0.9151111245155334, loss=0.24210980534553528
test: epoch 44, loss 1.6097960472106934, acc=0.42500001192092896, loss=1.6097960472106934
train: epoch 45, loss 0.2306925654411316, acc=0.9196666479110718, loss=0.2306925654411316
test: epoch 45, loss 1.758927822113037, acc=0.40833333134651184, loss=1.758927822113037
train: epoch 46, loss 0.2194451540708542, acc=0.9229444265365601, loss=0.2194451540708542
test: epoch 46, loss 1.8659095764160156, acc=0.4277777671813965, loss=1.8659095764160156
train: epoch 47, loss 0.23242421448230743, acc=0.9209444522857666, loss=0.23242421448230743
test: epoch 47, loss 1.8986573219299316, acc=0.4416666626930237, loss=1.8986573219299316
train: epoch 48, loss 0.21864762902259827, acc=0.925611138343811, loss=0.21864762902259827
test: epoch 48, loss 1.5337460041046143, acc=0.48055556416511536, loss=1.5337460041046143
train: epoch 49, loss 0.20631015300750732, acc=0.9277777671813965, loss=0.20631015300750732
test: epoch 49, loss 1.6831082105636597, acc=0.4722222089767456, loss=1.6831082105636597
train: epoch 50, loss 0.21395142376422882, acc=0.9303333163261414, loss=0.21395142376422882
test: epoch 50, loss 1.7074737548828125, acc=0.4722222089767456, loss=1.7074737548828125
train: epoch 51, loss 0.20953142642974854, acc=0.9301111102104187, loss=0.20953142642974854
test: epoch 51, loss 1.553753137588501, acc=0.4972222149372101, loss=1.553753137588501
train: epoch 52, loss 0.19470226764678955, acc=0.9350555539131165, loss=0.19470226764678955
test: epoch 52, loss 1.9107216596603394, acc=0.4138889014720917, loss=1.9107216596603394
train: epoch 53, loss 0.20231956243515015, acc=0.9355000257492065, loss=0.20231956243515015
test: epoch 53, loss 1.7470476627349854, acc=0.44999998807907104, loss=1.7470476627349854
train: epoch 54, loss 0.19342666864395142, acc=0.9364444613456726, loss=0.19342666864395142
test: epoch 54, loss 1.7170380353927612, acc=0.42222222685813904, loss=1.7170380353927612
train: epoch 55, loss 0.1875556856393814, acc=0.9371111392974854, loss=0.1875556856393814
test: epoch 55, loss 1.7988779544830322, acc=0.44999998807907104, loss=1.7988779544830322
train: epoch 56, loss 0.20359797775745392, acc=0.9329444169998169, loss=0.20359797775745392
test: epoch 56, loss 1.6932648420333862, acc=0.46388888359069824, loss=1.6932648420333862
train: epoch 57, loss 0.18046055734157562, acc=0.9394999742507935, loss=0.18046055734157562
test: epoch 57, loss 1.5860328674316406, acc=0.519444465637207, loss=1.5860328674316406
train: epoch 58, loss 0.17471370100975037, acc=0.9423333406448364, loss=0.17471370100975037
test: epoch 58, loss 1.7584724426269531, acc=0.4694444537162781, loss=1.7584724426269531
train: epoch 59, loss 0.1946551501750946, acc=0.9365555644035339, loss=0.1946551501750946
test: epoch 59, loss 1.747694492340088, acc=0.49444442987442017, loss=1.747694492340088
train: epoch 60, loss 0.1694251149892807, acc=0.941777765750885, loss=0.1694251149892807
test: epoch 60, loss 1.8352388143539429, acc=0.4722222089767456, loss=1.8352388143539429
train: epoch 61, loss 0.16484542191028595, acc=0.9477777481079102, loss=0.16484542191028595
test: epoch 61, loss 1.6591391563415527, acc=0.5055555701255798, loss=1.6591391563415527
train: epoch 62, loss 0.1581207513809204, acc=0.9488333463668823, loss=0.1581207513809204
test: epoch 62, loss 1.8690260648727417, acc=0.4611110985279083, loss=1.8690260648727417
train: epoch 63, loss 0.1650390774011612, acc=0.944611132144928, loss=0.1650390774011612
test: epoch 63, loss 1.6673624515533447, acc=0.4749999940395355, loss=1.6673624515533447
train: epoch 64, loss 0.15698646008968353, acc=0.948722243309021, loss=0.15698646008968353
test: epoch 64, loss 1.6483154296875, acc=0.5027777552604675, loss=1.6483154296875
train: epoch 65, loss 0.14737483859062195, acc=0.9518333077430725, loss=0.14737483859062195
test: epoch 65, loss 1.7108783721923828, acc=0.5111111402511597, loss=1.7108783721923828
train: epoch 66, loss 0.1603078991174698, acc=0.9481111168861389, loss=0.1603078991174698
test: epoch 66, loss 1.7476986646652222, acc=0.5333333611488342, loss=1.7476986646652222
train: epoch 67, loss 0.16464214026927948, acc=0.9463333487510681, loss=0.16464214026927948
test: epoch 67, loss 1.6923859119415283, acc=0.5083333253860474, loss=1.6923859119415283
train: epoch 68, loss 0.14536665380001068, acc=0.9508333206176758, loss=0.14536665380001068
test: epoch 68, loss 2.1505227088928223, acc=0.49166667461395264, loss=2.1505227088928223
train: epoch 69, loss 0.14709462225437164, acc=0.9512222409248352, loss=0.14709462225437164
test: epoch 69, loss 1.6769999265670776, acc=0.550000011920929, loss=1.6769999265670776
train: epoch 70, loss 0.1507793813943863, acc=0.9511111378669739, loss=0.1507793813943863
test: epoch 70, loss 1.5992807149887085, acc=0.4888888895511627, loss=1.5992807149887085
train: epoch 71, loss 0.13996060192584991, acc=0.9566666483879089, loss=0.13996060192584991
test: epoch 71, loss 1.6372772455215454, acc=0.5305555462837219, loss=1.6372772455215454
train: epoch 72, loss 0.1396012306213379, acc=0.9552222490310669, loss=0.1396012306213379
test: epoch 72, loss 1.6655441522598267, acc=0.5111111402511597, loss=1.6655441522598267
train: epoch 73, loss 0.13485613465309143, acc=0.9551666378974915, loss=0.13485613465309143
test: epoch 73, loss 1.6604340076446533, acc=0.5472221970558167, loss=1.6604340076446533
train: epoch 74, loss 0.1397227644920349, acc=0.9566666483879089, loss=0.1397227644920349
test: epoch 74, loss 1.429964542388916, acc=0.6000000238418579, loss=1.429964542388916
train: epoch 75, loss 0.13969798386096954, acc=0.9562222361564636, loss=0.13969798386096954
test: epoch 75, loss 1.6245249509811401, acc=0.5249999761581421, loss=1.6245249509811401
train: epoch 76, loss 0.13715821504592896, acc=0.9578889012336731, loss=0.13715821504592896
test: epoch 76, loss 2.0055277347564697, acc=0.4833333194255829, loss=2.0055277347564697
train: epoch 77, loss 0.1316264271736145, acc=0.9591666460037231, loss=0.1316264271736145
test: epoch 77, loss 1.6469626426696777, acc=0.5805555582046509, loss=1.6469626426696777
train: epoch 78, loss 0.13584142923355103, acc=0.9580555558204651, loss=0.13584142923355103
test: epoch 78, loss 1.6467866897583008, acc=0.5555555820465088, loss=1.6467866897583008
train: epoch 79, loss 0.11908575892448425, acc=0.9629999995231628, loss=0.11908575892448425
test: epoch 79, loss 1.7524349689483643, acc=0.5472221970558167, loss=1.7524349689483643
train: epoch 80, loss 0.1336994171142578, acc=0.9572222232818604, loss=0.1336994171142578
test: epoch 80, loss 1.7150033712387085, acc=0.5583333373069763, loss=1.7150033712387085
train: epoch 81, loss 0.12632884085178375, acc=0.9590555429458618, loss=0.12632884085178375
test: epoch 81, loss 1.7592148780822754, acc=0.5583333373069763, loss=1.7592148780822754
train: epoch 82, loss 0.1229478195309639, acc=0.9606666564941406, loss=0.1229478195309639
test: epoch 82, loss 1.6683573722839355, acc=0.5694444179534912, loss=1.6683573722839355
train: epoch 83, loss 0.11956681311130524, acc=0.9611666798591614, loss=0.11956681311130524
test: epoch 83, loss 1.6751919984817505, acc=0.5555555820465088, loss=1.6751919984817505
train: epoch 84, loss 0.11775586009025574, acc=0.9638888835906982, loss=0.11775586009025574
test: epoch 84, loss 1.540607213973999, acc=0.5805555582046509, loss=1.540607213973999
train: epoch 85, loss 0.11685445159673691, acc=0.9626666903495789, loss=0.11685445159673691
test: epoch 85, loss 1.7507195472717285, acc=0.5944444537162781, loss=1.7507195472717285
train: epoch 86, loss 0.12407010048627853, acc=0.9601666927337646, loss=0.12407010048627853
test: epoch 86, loss 1.4897973537445068, acc=0.6000000238418579, loss=1.4897973537445068
train: epoch 87, loss 0.11798010766506195, acc=0.9635000228881836, loss=0.11798010766506195
test: epoch 87, loss 1.68691885471344, acc=0.6166666746139526, loss=1.68691885471344
train: epoch 88, loss 0.10997460037469864, acc=0.9646666646003723, loss=0.10997460037469864
test: epoch 88, loss 1.4780510663986206, acc=0.6194444298744202, loss=1.4780510663986206
train: epoch 89, loss 0.1155698299407959, acc=0.9639999866485596, loss=0.1155698299407959
test: epoch 89, loss 1.571364164352417, acc=0.6083333492279053, loss=1.571364164352417
train: epoch 90, loss 0.12171214073896408, acc=0.9628888964653015, loss=0.12171214073896408
test: epoch 90, loss 1.5508754253387451, acc=0.6194444298744202, loss=1.5508754253387451
train: epoch 91, loss 0.105019710958004, acc=0.9661666750907898, loss=0.105019710958004
test: epoch 91, loss 1.6405202150344849, acc=0.6194444298744202, loss=1.6405202150344849
train: epoch 92, loss 0.10596147179603577, acc=0.9633888602256775, loss=0.10596147179603577
test: epoch 92, loss 1.4552534818649292, acc=0.6166666746139526, loss=1.4552534818649292
train: epoch 93, loss 0.10847576707601547, acc=0.9657777547836304, loss=0.10847576707601547
test: epoch 93, loss 1.4000163078308105, acc=0.6333333253860474, loss=1.4000163078308105
train: epoch 94, loss 0.10609293729066849, acc=0.9646111130714417, loss=0.10609293729066849
test: epoch 94, loss 1.4796634912490845, acc=0.6361111402511597, loss=1.4796634912490845
train: epoch 95, loss 0.10969138145446777, acc=0.9636111259460449, loss=0.10969138145446777
test: epoch 95, loss 1.5639872550964355, acc=0.6194444298744202, loss=1.5639872550964355
train: epoch 96, loss 0.0988883227109909, acc=0.9679444432258606, loss=0.0988883227109909
test: epoch 96, loss 1.4368963241577148, acc=0.6499999761581421, loss=1.4368963241577148
train: epoch 97, loss 0.11569848656654358, acc=0.9630555510520935, loss=0.11569848656654358
test: epoch 97, loss 1.4144794940948486, acc=0.6555555462837219, loss=1.4144794940948486
train: epoch 98, loss 0.10874656587839127, acc=0.9653333425521851, loss=0.10874656587839127
test: epoch 98, loss 1.4975541830062866, acc=0.6499999761581421, loss=1.4975541830062866
train: epoch 99, loss 0.1043495237827301, acc=0.9655555486679077, loss=0.1043495237827301
test: epoch 99, loss 1.5543526411056519, acc=0.6583333611488342, loss=1.5543526411056519
train: epoch 100, loss 0.10643931478261948, acc=0.9681666493415833, loss=0.10643931478261948
test: epoch 100, loss 1.572176456451416, acc=0.625, loss=1.572176456451416
train: epoch 101, loss 0.10388370603322983, acc=0.9663888812065125, loss=0.10388370603322983
test: epoch 101, loss 1.3416602611541748, acc=0.6694444417953491, loss=1.3416602611541748
train: epoch 102, loss 0.09653040766716003, acc=0.9692222476005554, loss=0.09653040766716003
test: epoch 102, loss 1.4663676023483276, acc=0.6361111402511597, loss=1.4663676023483276
train: epoch 103, loss 0.09844271838665009, acc=0.9703888893127441, loss=0.09844271838665009
test: epoch 103, loss 1.3653253316879272, acc=0.625, loss=1.3653253316879272
train: epoch 104, loss 0.09138135612010956, acc=0.9708333611488342, loss=0.09138135612010956
test: epoch 104, loss 1.3479081392288208, acc=0.6666666865348816, loss=1.3479081392288208
train: epoch 105, loss 0.1049794852733612, acc=0.968999981880188, loss=0.1049794852733612
test: epoch 105, loss 1.5368618965148926, acc=0.6638888716697693, loss=1.5368618965148926
train: epoch 106, loss 0.09417860954999924, acc=0.971666693687439, loss=0.09417860954999924
test: epoch 106, loss 1.4749469757080078, acc=0.6833333373069763, loss=1.4749469757080078
train: epoch 107, loss 0.09950181841850281, acc=0.9700000286102295, loss=0.09950181841850281
test: epoch 107, loss 1.4028688669204712, acc=0.6805555820465088, loss=1.4028688669204712
train: epoch 108, loss 0.10308028757572174, acc=0.9673888683319092, loss=0.10308028757572174
test: epoch 108, loss 1.454445481300354, acc=0.6277777552604675, loss=1.454445481300354
train: epoch 109, loss 0.11229375749826431, acc=0.9681110978126526, loss=0.11229375749826431
test: epoch 109, loss 1.5602707862854004, acc=0.6583333611488342, loss=1.5602707862854004
train: epoch 110, loss 0.0918961614370346, acc=0.9714999794960022, loss=0.0918961614370346
test: epoch 110, loss 1.3962255716323853, acc=0.6472222208976746, loss=1.3962255716323853
train: epoch 111, loss 0.09096528589725494, acc=0.9722777605056763, loss=0.09096528589725494
test: epoch 111, loss 1.3754923343658447, acc=0.7166666388511658, loss=1.3754923343658447
train: epoch 112, loss 0.09299679100513458, acc=0.972000002861023, loss=0.09299679100513458
test: epoch 112, loss 1.5527275800704956, acc=0.6805555820465088, loss=1.5527275800704956
train: epoch 113, loss 0.09169451892375946, acc=0.9703333377838135, loss=0.09169451892375946
test: epoch 113, loss 1.378175139427185, acc=0.6611111164093018, loss=1.378175139427185
train: epoch 114, loss 0.09071820229291916, acc=0.971833348274231, loss=0.09071820229291916
test: epoch 114, loss 1.2459863424301147, acc=0.699999988079071, loss=1.2459863424301147
train: epoch 115, loss 0.0835016518831253, acc=0.9732778072357178, loss=0.0835016518831253
test: epoch 115, loss 1.4579975605010986, acc=0.699999988079071, loss=1.4579975605010986
train: epoch 116, loss 0.0835857167840004, acc=0.9735555648803711, loss=0.0835857167840004
test: epoch 116, loss 1.5633151531219482, acc=0.6361111402511597, loss=1.5633151531219482
train: epoch 117, loss 0.07713399082422256, acc=0.9754444360733032, loss=0.07713399082422256
test: epoch 117, loss 1.3865044116973877, acc=0.699999988079071, loss=1.3865044116973877
train: epoch 118, loss 0.08951635658740997, acc=0.9735555648803711, loss=0.08951635658740997
test: epoch 118, loss 1.3654205799102783, acc=0.6777777671813965, loss=1.3654205799102783
train: epoch 119, loss 0.08073893189430237, acc=0.9737777709960938, loss=0.08073893189430237
test: epoch 119, loss 1.1573710441589355, acc=0.7027778029441833, loss=1.1573710441589355
train: epoch 120, loss 0.087156742811203, acc=0.9735555648803711, loss=0.087156742811203
test: epoch 120, loss 1.387407660484314, acc=0.699999988079071, loss=1.387407660484314
train: epoch 121, loss 0.0686526745557785, acc=0.9781110882759094, loss=0.0686526745557785
test: epoch 121, loss 1.285380244255066, acc=0.7250000238418579, loss=1.285380244255066
train: epoch 122, loss 0.07693427801132202, acc=0.9761666655540466, loss=0.07693427801132202
test: epoch 122, loss 1.3748011589050293, acc=0.7194444537162781, loss=1.3748011589050293
train: epoch 123, loss 0.07913278788328171, acc=0.9769444465637207, loss=0.07913278788328171
test: epoch 123, loss 1.266245722770691, acc=0.699999988079071, loss=1.266245722770691
train: epoch 124, loss 0.08279688656330109, acc=0.9751111268997192, loss=0.08279688656330109
test: epoch 124, loss 1.2627248764038086, acc=0.7111111283302307, loss=1.2627248764038086
train: epoch 125, loss 0.07608811557292938, acc=0.9777222275733948, loss=0.07608811557292938
test: epoch 125, loss 1.2487273216247559, acc=0.7138888835906982, loss=1.2487273216247559
train: epoch 126, loss 0.07623090595006943, acc=0.976277768611908, loss=0.07623090595006943
test: epoch 126, loss 1.3561981916427612, acc=0.7027778029441833, loss=1.3561981916427612
train: epoch 127, loss 0.07398828119039536, acc=0.9767777919769287, loss=0.07398828119039536
test: epoch 127, loss 1.283638596534729, acc=0.7194444537162781, loss=1.283638596534729
train: epoch 128, loss 0.06603686511516571, acc=0.977055549621582, loss=0.06603686511516571
test: epoch 128, loss 1.2607228755950928, acc=0.7166666388511658, loss=1.2607228755950928
train: epoch 129, loss 0.08401437103748322, acc=0.9746111035346985, loss=0.08401437103748322
test: epoch 129, loss 1.2398649454116821, acc=0.7333333492279053, loss=1.2398649454116821
train: epoch 130, loss 0.07045357674360275, acc=0.9771666526794434, loss=0.07045357674360275
test: epoch 130, loss 1.2775217294692993, acc=0.6888889074325562, loss=1.2775217294692993
train: epoch 131, loss 0.08519849926233292, acc=0.9753888845443726, loss=0.08519849926233292
test: epoch 131, loss 1.3397196531295776, acc=0.6972222328186035, loss=1.3397196531295776
train: epoch 132, loss 0.07431181520223618, acc=0.9775000214576721, loss=0.07431181520223618
test: epoch 132, loss 1.34251868724823, acc=0.7194444537162781, loss=1.34251868724823
train: epoch 133, loss 0.07228077203035355, acc=0.9779444336891174, loss=0.07228077203035355
test: epoch 133, loss 1.2760080099105835, acc=0.7333333492279053, loss=1.2760080099105835
train: epoch 134, loss 0.06365250796079636, acc=0.980555534362793, loss=0.06365250796079636
test: epoch 134, loss 1.3668010234832764, acc=0.7555555701255798, loss=1.3668010234832764
train: epoch 135, loss 0.06740522384643555, acc=0.9794999957084656, loss=0.06740522384643555
test: epoch 135, loss 1.2797446250915527, acc=0.7388888597488403, loss=1.2797446250915527
train: epoch 136, loss 0.06824186444282532, acc=0.9787222146987915, loss=0.06824186444282532
test: epoch 136, loss 1.231807827949524, acc=0.7472222447395325, loss=1.231807827949524
train: epoch 137, loss 0.0616162046790123, acc=0.9809444546699524, loss=0.0616162046790123
test: epoch 137, loss 1.20612633228302, acc=0.7194444537162781, loss=1.20612633228302
train: epoch 138, loss 0.06865280866622925, acc=0.9808889031410217, loss=0.06865280866622925
test: epoch 138, loss 1.3396965265274048, acc=0.7166666388511658, loss=1.3396965265274048
train: epoch 139, loss 0.060764484107494354, acc=0.9810555577278137, loss=0.060764484107494354
test: epoch 139, loss 1.2390687465667725, acc=0.7444444298744202, loss=1.2390687465667725
train: epoch 140, loss 0.06537794321775436, acc=0.981166660785675, loss=0.06537794321775436
test: epoch 140, loss 1.2377793788909912, acc=0.7361111044883728, loss=1.2377793788909912
train: epoch 141, loss 0.06753691285848618, acc=0.9804444313049316, loss=0.06753691285848618
test: epoch 141, loss 1.3934930562973022, acc=0.730555534362793, loss=1.3934930562973022
train: epoch 142, loss 0.06540961563587189, acc=0.9804444313049316, loss=0.06540961563587189
test: epoch 142, loss 1.1120152473449707, acc=0.7083333134651184, loss=1.1120152473449707
train: epoch 143, loss 0.06117931753396988, acc=0.9820555448532104, loss=0.06117931753396988
test: epoch 143, loss 1.4304616451263428, acc=0.7250000238418579, loss=1.4304616451263428
train: epoch 144, loss 0.053596898913383484, acc=0.9833333492279053, loss=0.053596898913383484
test: epoch 144, loss 1.230203628540039, acc=0.7416666746139526, loss=1.230203628540039
train: epoch 145, loss 0.06541590392589569, acc=0.9828333258628845, loss=0.06541590392589569
test: epoch 145, loss 1.6257081031799316, acc=0.75, loss=1.6257081031799316
train: epoch 146, loss 0.06794876605272293, acc=0.9793333411216736, loss=0.06794876605272293
test: epoch 146, loss 1.1321462392807007, acc=0.7527777552604675, loss=1.1321462392807007
train: epoch 147, loss 0.06579479575157166, acc=0.9820555448532104, loss=0.06579479575157166
test: epoch 147, loss 1.140345811843872, acc=0.7388888597488403, loss=1.140345811843872
train: epoch 148, loss 0.05622169002890587, acc=0.9830555319786072, loss=0.05622169002890587
test: epoch 148, loss 1.0082658529281616, acc=0.7527777552604675, loss=1.0082658529281616
train: epoch 149, loss 0.0567217618227005, acc=0.9835555553436279, loss=0.0567217618227005
test: epoch 149, loss 1.063374638557434, acc=0.7555555701255798, loss=1.063374638557434
train: epoch 150, loss 0.055104028433561325, acc=0.984333336353302, loss=0.055104028433561325
test: epoch 150, loss 1.0106778144836426, acc=0.7583333253860474, loss=1.0106778144836426
