# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=1.5", "--temp_decay=0.99", "--one_hot=1", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=59865040, receiver_embed_dim=32, save_run=0, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=59865040, receiver_embed_dim=32, save_run=False, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.4061172008514404, acc=0.05577777698636055, loss=3.4061172008514404
test: epoch 1, loss 4.002359867095947, acc=0.03611111268401146, loss=4.002359867095947
train: epoch 2, loss 2.667484760284424, acc=0.1548333317041397, loss=2.667484760284424
test: epoch 2, loss 3.4111239910125732, acc=0.08888889104127884, loss=3.4111239910125732
train: epoch 3, loss 1.9893313646316528, acc=0.26738888025283813, loss=1.9893313646316528
test: epoch 3, loss 3.246938943862915, acc=0.10833333432674408, loss=3.246938943862915
train: epoch 4, loss 1.6839836835861206, acc=0.347944438457489, loss=1.6839836835861206
test: epoch 4, loss 2.8666129112243652, acc=0.13611111044883728, loss=2.8666129112243652
train: epoch 5, loss 1.5316781997680664, acc=0.39327776432037354, loss=1.5316781997680664
test: epoch 5, loss 2.78641676902771, acc=0.14722222089767456, loss=2.78641676902771
train: epoch 6, loss 1.4312915802001953, acc=0.4273333251476288, loss=1.4312915802001953
test: epoch 6, loss 2.657299518585205, acc=0.17222222685813904, loss=2.657299518585205
train: epoch 7, loss 1.3558632135391235, acc=0.47216665744781494, loss=1.3558632135391235
test: epoch 7, loss 2.652456283569336, acc=0.14444445073604584, loss=2.652456283569336
train: epoch 8, loss 1.2859277725219727, acc=0.49044445157051086, loss=1.2859277725219727
test: epoch 8, loss 2.5017199516296387, acc=0.17222222685813904, loss=2.5017199516296387
train: epoch 9, loss 1.2303351163864136, acc=0.5123888850212097, loss=1.2303351163864136
test: epoch 9, loss 2.581136465072632, acc=0.18611110746860504, loss=2.581136465072632
train: epoch 10, loss 1.1744306087493896, acc=0.5398889183998108, loss=1.1744306087493896
test: epoch 10, loss 2.493528366088867, acc=0.18611110746860504, loss=2.493528366088867
train: epoch 11, loss 1.1384971141815186, acc=0.5579444169998169, loss=1.1384971141815186
test: epoch 11, loss 2.306255578994751, acc=0.21388888359069824, loss=2.306255578994751
train: epoch 12, loss 1.1005111932754517, acc=0.5765555500984192, loss=1.1005111932754517
test: epoch 12, loss 2.242624521255493, acc=0.20000000298023224, loss=2.242624521255493
train: epoch 13, loss 1.0745471715927124, acc=0.5877222418785095, loss=1.0745471715927124
test: epoch 13, loss 2.2358779907226562, acc=0.21111111342906952, loss=2.2358779907226562
train: epoch 14, loss 1.0403881072998047, acc=0.5958889126777649, loss=1.0403881072998047
test: epoch 14, loss 2.162803888320923, acc=0.22499999403953552, loss=2.162803888320923
train: epoch 15, loss 1.0085082054138184, acc=0.6027222275733948, loss=1.0085082054138184
test: epoch 15, loss 2.1218173503875732, acc=0.2361111044883728, loss=2.1218173503875732
train: epoch 16, loss 0.9889004230499268, acc=0.6184999942779541, loss=0.9889004230499268
test: epoch 16, loss 2.291177272796631, acc=0.24166665971279144, loss=2.291177272796631
train: epoch 17, loss 0.9590888023376465, acc=0.6286110877990723, loss=0.9590888023376465
test: epoch 17, loss 2.1961164474487305, acc=0.2527777850627899, loss=2.1961164474487305
train: epoch 18, loss 0.9361924529075623, acc=0.6387222409248352, loss=0.9361924529075623
test: epoch 18, loss 2.1414313316345215, acc=0.24722221493721008, loss=2.1414313316345215
train: epoch 19, loss 0.9264456033706665, acc=0.6383888721466064, loss=0.9264456033706665
test: epoch 19, loss 2.082439661026001, acc=0.25833332538604736, loss=2.082439661026001
train: epoch 20, loss 0.906105101108551, acc=0.6475555300712585, loss=0.906105101108551
test: epoch 20, loss 2.033076763153076, acc=0.27222222089767456, loss=2.033076763153076
train: epoch 21, loss 0.9046319723129272, acc=0.6456111073493958, loss=0.9046319723129272
test: epoch 21, loss 1.9244977235794067, acc=0.2666666805744171, loss=1.9244977235794067
train: epoch 22, loss 0.8732233047485352, acc=0.6588333249092102, loss=0.8732233047485352
test: epoch 22, loss 1.954630970954895, acc=0.28333333134651184, loss=1.954630970954895
train: epoch 23, loss 0.8714503049850464, acc=0.6613888740539551, loss=0.8714503049850464
test: epoch 23, loss 1.9445924758911133, acc=0.31388887763023376, loss=1.9445924758911133
train: epoch 24, loss 0.8329843878746033, acc=0.6809444427490234, loss=0.8329843878746033
test: epoch 24, loss 1.8086507320404053, acc=0.3444444537162781, loss=1.8086507320404053
train: epoch 25, loss 0.8349912166595459, acc=0.6768888831138611, loss=0.8349912166595459
test: epoch 25, loss 1.8424092531204224, acc=0.2944444417953491, loss=1.8424092531204224
train: epoch 26, loss 0.8335381150245667, acc=0.679277777671814, loss=0.8335381150245667
test: epoch 26, loss 1.9332205057144165, acc=0.28333333134651184, loss=1.9332205057144165
train: epoch 27, loss 0.8179112076759338, acc=0.6855000257492065, loss=0.8179112076759338
test: epoch 27, loss 1.7675920724868774, acc=0.34166666865348816, loss=1.7675920724868774
train: epoch 28, loss 0.7912334203720093, acc=0.6937222480773926, loss=0.7912334203720093
test: epoch 28, loss 1.7182692289352417, acc=0.32777777314186096, loss=1.7182692289352417
train: epoch 29, loss 0.7900649905204773, acc=0.6950555443763733, loss=0.7900649905204773
test: epoch 29, loss 1.6852576732635498, acc=0.3361110985279083, loss=1.6852576732635498
train: epoch 30, loss 0.7843734622001648, acc=0.695888876914978, loss=0.7843734622001648
test: epoch 30, loss 1.6635990142822266, acc=0.38055557012557983, loss=1.6635990142822266
train: epoch 31, loss 0.7705665230751038, acc=0.7013888955116272, loss=0.7705665230751038
test: epoch 31, loss 1.6542413234710693, acc=0.3777777850627899, loss=1.6542413234710693
train: epoch 32, loss 0.7491684556007385, acc=0.7083888649940491, loss=0.7491684556007385
test: epoch 32, loss 1.5179405212402344, acc=0.3916666805744171, loss=1.5179405212402344
train: epoch 33, loss 0.7466011047363281, acc=0.7112777829170227, loss=0.7466011047363281
test: epoch 33, loss 1.5397541522979736, acc=0.41111111640930176, loss=1.5397541522979736
train: epoch 34, loss 0.7394030690193176, acc=0.7166110873222351, loss=0.7394030690193176
test: epoch 34, loss 1.5678328275680542, acc=0.4000000059604645, loss=1.5678328275680542
train: epoch 35, loss 0.7212357521057129, acc=0.717555582523346, loss=0.7212357521057129
test: epoch 35, loss 1.4911020994186401, acc=0.3861111104488373, loss=1.4911020994186401
train: epoch 36, loss 0.6978132128715515, acc=0.7250555753707886, loss=0.6978132128715515
test: epoch 36, loss 1.460989236831665, acc=0.42222222685813904, loss=1.460989236831665
train: epoch 37, loss 0.6910082697868347, acc=0.7356666922569275, loss=0.6910082697868347
test: epoch 37, loss 1.417797565460205, acc=0.44999998807907104, loss=1.417797565460205
train: epoch 38, loss 0.6936925649642944, acc=0.7295555472373962, loss=0.6936925649642944
test: epoch 38, loss 1.4626294374465942, acc=0.4000000059604645, loss=1.4626294374465942
train: epoch 39, loss 0.6872539520263672, acc=0.7338888645172119, loss=0.6872539520263672
test: epoch 39, loss 1.438683271408081, acc=0.4027777910232544, loss=1.438683271408081
train: epoch 40, loss 0.6696013808250427, acc=0.737666666507721, loss=0.6696013808250427
test: epoch 40, loss 1.4002130031585693, acc=0.44999998807907104, loss=1.4002130031585693
train: epoch 41, loss 0.677210807800293, acc=0.7363333106040955, loss=0.677210807800293
test: epoch 41, loss 1.3896701335906982, acc=0.43611112236976624, loss=1.3896701335906982
train: epoch 42, loss 0.6645665168762207, acc=0.7396666407585144, loss=0.6645665168762207
test: epoch 42, loss 1.396127700805664, acc=0.4166666567325592, loss=1.396127700805664
train: epoch 43, loss 0.6411691904067993, acc=0.7469444274902344, loss=0.6411691904067993
test: epoch 43, loss 1.3535152673721313, acc=0.4277777671813965, loss=1.3535152673721313
train: epoch 44, loss 0.6418222188949585, acc=0.7529444694519043, loss=0.6418222188949585
test: epoch 44, loss 1.3410148620605469, acc=0.44999998807907104, loss=1.3410148620605469
train: epoch 45, loss 0.6363467574119568, acc=0.7495555281639099, loss=0.6363467574119568
test: epoch 45, loss 1.3161306381225586, acc=0.4333333373069763, loss=1.3161306381225586
train: epoch 46, loss 0.6213439702987671, acc=0.7548333406448364, loss=0.6213439702987671
test: epoch 46, loss 1.274436116218567, acc=0.47777777910232544, loss=1.274436116218567
train: epoch 47, loss 0.6139436364173889, acc=0.7561666369438171, loss=0.6139436364173889
test: epoch 47, loss 1.2967097759246826, acc=0.4861111044883728, loss=1.2967097759246826
train: epoch 48, loss 0.6137965321540833, acc=0.7600555419921875, loss=0.6137965321540833
test: epoch 48, loss 1.2437896728515625, acc=0.4833333194255829, loss=1.2437896728515625
train: epoch 49, loss 0.5976208448410034, acc=0.7636666893959045, loss=0.5976208448410034
test: epoch 49, loss 1.331437349319458, acc=0.4722222089767456, loss=1.331437349319458
train: epoch 50, loss 0.6012566089630127, acc=0.765333354473114, loss=0.6012566089630127
test: epoch 50, loss 1.1784073114395142, acc=0.5055555701255798, loss=1.1784073114395142
train: epoch 51, loss 0.5918919444084167, acc=0.7641666531562805, loss=0.5918919444084167
test: epoch 51, loss 1.2581048011779785, acc=0.5111111402511597, loss=1.2581048011779785
train: epoch 52, loss 0.5776212215423584, acc=0.7667222023010254, loss=0.5776212215423584
test: epoch 52, loss 1.2973026037216187, acc=0.5055555701255798, loss=1.2973026037216187
train: epoch 53, loss 0.5830879211425781, acc=0.7660555839538574, loss=0.5830879211425781
test: epoch 53, loss 1.1704734563827515, acc=0.5222222208976746, loss=1.1704734563827515
train: epoch 54, loss 0.5721320509910583, acc=0.7645555734634399, loss=0.5721320509910583
test: epoch 54, loss 1.1831003427505493, acc=0.5166666507720947, loss=1.1831003427505493
train: epoch 55, loss 0.5737183690071106, acc=0.7664999961853027, loss=0.5737183690071106
test: epoch 55, loss 1.2163150310516357, acc=0.5027777552604675, loss=1.2163150310516357
train: epoch 56, loss 0.5558853149414062, acc=0.7764444351196289, loss=0.5558853149414062
test: epoch 56, loss 1.1258995532989502, acc=0.5138888955116272, loss=1.1258995532989502
train: epoch 57, loss 0.5611132979393005, acc=0.7748333215713501, loss=0.5611132979393005
test: epoch 57, loss 1.19708251953125, acc=0.550000011920929, loss=1.19708251953125
train: epoch 58, loss 0.5538519620895386, acc=0.7739444375038147, loss=0.5538519620895386
test: epoch 58, loss 1.1361180543899536, acc=0.5611110925674438, loss=1.1361180543899536
train: epoch 59, loss 0.5540847778320312, acc=0.7759444713592529, loss=0.5540847778320312
test: epoch 59, loss 1.1728147268295288, acc=0.5416666865348816, loss=1.1728147268295288
train: epoch 60, loss 0.5507394671440125, acc=0.778166651725769, loss=0.5507394671440125
test: epoch 60, loss 1.1339764595031738, acc=0.5416666865348816, loss=1.1339764595031738
train: epoch 61, loss 0.5356160998344421, acc=0.7834444642066956, loss=0.5356160998344421
test: epoch 61, loss 1.09360933303833, acc=0.5861111283302307, loss=1.09360933303833
train: epoch 62, loss 0.5372435450553894, acc=0.781499981880188, loss=0.5372435450553894
test: epoch 62, loss 1.0807832479476929, acc=0.5694444179534912, loss=1.0807832479476929
train: epoch 63, loss 0.52718585729599, acc=0.7850000262260437, loss=0.52718585729599
test: epoch 63, loss 1.019417643547058, acc=0.5972222089767456, loss=1.019417643547058
train: epoch 64, loss 0.5224853157997131, acc=0.788777768611908, loss=0.5224853157997131
test: epoch 64, loss 1.0816220045089722, acc=0.5944444537162781, loss=1.0816220045089722
train: epoch 65, loss 0.5189321041107178, acc=0.7859444618225098, loss=0.5189321041107178
test: epoch 65, loss 0.9830833077430725, acc=0.5888888835906982, loss=0.9830833077430725
train: epoch 66, loss 0.5186231136322021, acc=0.7850555777549744, loss=0.5186231136322021
test: epoch 66, loss 0.9651289582252502, acc=0.6000000238418579, loss=0.9651289582252502
train: epoch 67, loss 0.5040521025657654, acc=0.7922777533531189, loss=0.5040521025657654
test: epoch 67, loss 0.9659433364868164, acc=0.6138888597488403, loss=0.9659433364868164
train: epoch 68, loss 0.5080519914627075, acc=0.7916666865348816, loss=0.5080519914627075
test: epoch 68, loss 1.0297236442565918, acc=0.5888888835906982, loss=1.0297236442565918
train: epoch 69, loss 0.5007648468017578, acc=0.7932778000831604, loss=0.5007648468017578
test: epoch 69, loss 0.9954642653465271, acc=0.605555534362793, loss=0.9954642653465271
train: epoch 70, loss 0.4987839162349701, acc=0.7944999933242798, loss=0.4987839162349701
test: epoch 70, loss 0.9469059705734253, acc=0.6083333492279053, loss=0.9469059705734253
train: epoch 71, loss 0.48381713032722473, acc=0.7973333597183228, loss=0.48381713032722473
test: epoch 71, loss 0.9743562936782837, acc=0.625, loss=0.9743562936782837
train: epoch 72, loss 0.4906749129295349, acc=0.7994999885559082, loss=0.4906749129295349
test: epoch 72, loss 0.8489722013473511, acc=0.6277777552604675, loss=0.8489722013473511
train: epoch 73, loss 0.4821513593196869, acc=0.7978888750076294, loss=0.4821513593196869
test: epoch 73, loss 0.9398128986358643, acc=0.6305555701255798, loss=0.9398128986358643
train: epoch 74, loss 0.4786278009414673, acc=0.8003333210945129, loss=0.4786278009414673
test: epoch 74, loss 0.8939414620399475, acc=0.6305555701255798, loss=0.8939414620399475
train: epoch 75, loss 0.4703890085220337, acc=0.8007222414016724, loss=0.4703890085220337
test: epoch 75, loss 0.9121476411819458, acc=0.6499999761581421, loss=0.9121476411819458
train: epoch 76, loss 0.4784335792064667, acc=0.8016666769981384, loss=0.4784335792064667
test: epoch 76, loss 0.882964015007019, acc=0.6416666507720947, loss=0.882964015007019
train: epoch 77, loss 0.45914170145988464, acc=0.8017777800559998, loss=0.45914170145988464
test: epoch 77, loss 0.9407552480697632, acc=0.6472222208976746, loss=0.9407552480697632
train: epoch 78, loss 0.46836352348327637, acc=0.8067777752876282, loss=0.46836352348327637
test: epoch 78, loss 0.8550254106521606, acc=0.6583333611488342, loss=0.8550254106521606
train: epoch 79, loss 0.4555884301662445, acc=0.8080000281333923, loss=0.4555884301662445
test: epoch 79, loss 0.867313802242279, acc=0.6666666865348816, loss=0.867313802242279
train: epoch 80, loss 0.4462185502052307, acc=0.805388867855072, loss=0.4462185502052307
test: epoch 80, loss 0.8239008784294128, acc=0.675000011920929, loss=0.8239008784294128
train: epoch 81, loss 0.4492119252681732, acc=0.8090555667877197, loss=0.4492119252681732
test: epoch 81, loss 0.8160430192947388, acc=0.6722221970558167, loss=0.8160430192947388
train: epoch 82, loss 0.447322279214859, acc=0.8109999895095825, loss=0.447322279214859
test: epoch 82, loss 0.7601089477539062, acc=0.6638888716697693, loss=0.7601089477539062
train: epoch 83, loss 0.4375511705875397, acc=0.8111110925674438, loss=0.4375511705875397
test: epoch 83, loss 0.8437883257865906, acc=0.6611111164093018, loss=0.8437883257865906
train: epoch 84, loss 0.43076568841934204, acc=0.8147222399711609, loss=0.43076568841934204
test: epoch 84, loss 0.8570229411125183, acc=0.6833333373069763, loss=0.8570229411125183
train: epoch 85, loss 0.4129268229007721, acc=0.8137221932411194, loss=0.4129268229007721
test: epoch 85, loss 0.8022890686988831, acc=0.675000011920929, loss=0.8022890686988831
train: epoch 86, loss 0.4206071197986603, acc=0.8180000185966492, loss=0.4206071197986603
test: epoch 86, loss 0.8387627601623535, acc=0.6944444179534912, loss=0.8387627601623535
train: epoch 87, loss 0.4278012812137604, acc=0.8176110982894897, loss=0.4278012812137604
test: epoch 87, loss 0.7674348950386047, acc=0.6972222328186035, loss=0.7674348950386047
train: epoch 88, loss 0.4173111617565155, acc=0.8177777528762817, loss=0.4173111617565155
test: epoch 88, loss 0.7914589047431946, acc=0.699999988079071, loss=0.7914589047431946
train: epoch 89, loss 0.41504329442977905, acc=0.8207777738571167, loss=0.41504329442977905
test: epoch 89, loss 0.804546058177948, acc=0.6888889074325562, loss=0.804546058177948
train: epoch 90, loss 0.4129784107208252, acc=0.8209999799728394, loss=0.4129784107208252
test: epoch 90, loss 0.7873386144638062, acc=0.6888889074325562, loss=0.7873386144638062
train: epoch 91, loss 0.40937647223472595, acc=0.8217777609825134, loss=0.40937647223472595
test: epoch 91, loss 0.7981454133987427, acc=0.6888889074325562, loss=0.7981454133987427
train: epoch 92, loss 0.404695600271225, acc=0.8214444518089294, loss=0.404695600271225
test: epoch 92, loss 0.752516508102417, acc=0.6916666626930237, loss=0.752516508102417
train: epoch 93, loss 0.39687806367874146, acc=0.824388861656189, loss=0.39687806367874146
test: epoch 93, loss 0.7909780144691467, acc=0.699999988079071, loss=0.7909780144691467
train: epoch 94, loss 0.3874262273311615, acc=0.825166642665863, loss=0.3874262273311615
test: epoch 94, loss 0.8193366527557373, acc=0.6972222328186035, loss=0.8193366527557373
train: epoch 95, loss 0.40510162711143494, acc=0.8224999904632568, loss=0.40510162711143494
test: epoch 95, loss 0.7330234050750732, acc=0.699999988079071, loss=0.7330234050750732
train: epoch 96, loss 0.3988155126571655, acc=0.8261666893959045, loss=0.3988155126571655
test: epoch 96, loss 0.7985486388206482, acc=0.699999988079071, loss=0.7985486388206482
train: epoch 97, loss 0.3956414759159088, acc=0.8247222304344177, loss=0.3956414759159088
test: epoch 97, loss 0.7577823400497437, acc=0.6972222328186035, loss=0.7577823400497437
train: epoch 98, loss 0.39192643761634827, acc=0.8257777690887451, loss=0.39192643761634827
test: epoch 98, loss 0.7535449862480164, acc=0.6916666626930237, loss=0.7535449862480164
train: epoch 99, loss 0.3780413866043091, acc=0.8291666507720947, loss=0.3780413866043091
test: epoch 99, loss 0.7830349802970886, acc=0.6972222328186035, loss=0.7830349802970886
train: epoch 100, loss 0.3842380940914154, acc=0.8277778029441833, loss=0.3842380940914154
test: epoch 100, loss 0.8135747313499451, acc=0.6944444179534912, loss=0.8135747313499451
train: epoch 101, loss 0.3825139105319977, acc=0.8280555605888367, loss=0.3825139105319977
test: epoch 101, loss 0.7611235976219177, acc=0.6944444179534912, loss=0.7611235976219177
train: epoch 102, loss 0.38717493414878845, acc=0.8273888826370239, loss=0.38717493414878845
test: epoch 102, loss 0.7506759762763977, acc=0.6972222328186035, loss=0.7506759762763977
train: epoch 103, loss 0.37690481543540955, acc=0.8320000171661377, loss=0.37690481543540955
test: epoch 103, loss 0.7602091431617737, acc=0.6972222328186035, loss=0.7602091431617737
train: epoch 104, loss 0.37697818875312805, acc=0.8287222385406494, loss=0.37697818875312805
test: epoch 104, loss 0.7777097821235657, acc=0.6888889074325562, loss=0.7777097821235657
train: epoch 105, loss 0.38149458169937134, acc=0.8291666507720947, loss=0.38149458169937134
test: epoch 105, loss 0.8508936762809753, acc=0.699999988079071, loss=0.8508936762809753
train: epoch 106, loss 0.376512348651886, acc=0.8287222385406494, loss=0.376512348651886
test: epoch 106, loss 0.7692683339118958, acc=0.6944444179534912, loss=0.7692683339118958
train: epoch 107, loss 0.37594836950302124, acc=0.8315555453300476, loss=0.37594836950302124
test: epoch 107, loss 0.7473056316375732, acc=0.7055555582046509, loss=0.7473056316375732
train: epoch 108, loss 0.38399964570999146, acc=0.8289444446563721, loss=0.38399964570999146
test: epoch 108, loss 0.7424870133399963, acc=0.7055555582046509, loss=0.7424870133399963
train: epoch 109, loss 0.3778761029243469, acc=0.8309444189071655, loss=0.3778761029243469
test: epoch 109, loss 0.7811316847801208, acc=0.7027778029441833, loss=0.7811316847801208
train: epoch 110, loss 0.3670012056827545, acc=0.8346666693687439, loss=0.3670012056827545
test: epoch 110, loss 0.8046440482139587, acc=0.7055555582046509, loss=0.8046440482139587
train: epoch 111, loss 0.37159252166748047, acc=0.8313888907432556, loss=0.37159252166748047
test: epoch 111, loss 0.8305761814117432, acc=0.7055555582046509, loss=0.8305761814117432
train: epoch 112, loss 0.3767184913158417, acc=0.8316110968589783, loss=0.3767184913158417
test: epoch 112, loss 0.7448739409446716, acc=0.699999988079071, loss=0.7448739409446716
train: epoch 113, loss 0.3796473443508148, acc=0.8342777490615845, loss=0.3796473443508148
test: epoch 113, loss 0.7715773582458496, acc=0.6972222328186035, loss=0.7715773582458496
train: epoch 114, loss 0.37188443541526794, acc=0.8369444608688354, loss=0.37188443541526794
test: epoch 114, loss 0.8215206861495972, acc=0.7027778029441833, loss=0.8215206861495972
train: epoch 115, loss 0.37465739250183105, acc=0.8322222232818604, loss=0.37465739250183105
test: epoch 115, loss 0.7713883519172668, acc=0.699999988079071, loss=0.7713883519172668
train: epoch 116, loss 0.36303478479385376, acc=0.8349444270133972, loss=0.36303478479385376
test: epoch 116, loss 0.777805745601654, acc=0.7027778029441833, loss=0.777805745601654
train: epoch 117, loss 0.3633774220943451, acc=0.8376111388206482, loss=0.3633774220943451
test: epoch 117, loss 0.8504814505577087, acc=0.6944444179534912, loss=0.8504814505577087
train: epoch 118, loss 0.37201687693595886, acc=0.8328333497047424, loss=0.37201687693595886
test: epoch 118, loss 0.7427146434783936, acc=0.7083333134651184, loss=0.7427146434783936
train: epoch 119, loss 0.3686867356300354, acc=0.8366110920906067, loss=0.3686867356300354
test: epoch 119, loss 0.875592052936554, acc=0.699999988079071, loss=0.875592052936554
train: epoch 120, loss 0.3627755045890808, acc=0.8361111283302307, loss=0.3627755045890808
test: epoch 120, loss 0.8149539828300476, acc=0.7027778029441833, loss=0.8149539828300476
train: epoch 121, loss 0.35483017563819885, acc=0.8373888731002808, loss=0.35483017563819885
test: epoch 121, loss 0.7495164275169373, acc=0.699999988079071, loss=0.7495164275169373
train: epoch 122, loss 0.36304375529289246, acc=0.8380555510520935, loss=0.36304375529289246
test: epoch 122, loss 0.8020669221878052, acc=0.699999988079071, loss=0.8020669221878052
train: epoch 123, loss 0.370764821767807, acc=0.8375555276870728, loss=0.370764821767807
test: epoch 123, loss 0.809749960899353, acc=0.699999988079071, loss=0.809749960899353
train: epoch 124, loss 0.3652525544166565, acc=0.8382777571678162, loss=0.3652525544166565
test: epoch 124, loss 0.7730059623718262, acc=0.699999988079071, loss=0.7730059623718262
train: epoch 125, loss 0.36555901169776917, acc=0.8371666669845581, loss=0.36555901169776917
test: epoch 125, loss 0.8109620809555054, acc=0.7055555582046509, loss=0.8109620809555054
train: epoch 126, loss 0.359201580286026, acc=0.8386111259460449, loss=0.359201580286026
test: epoch 126, loss 0.8055848479270935, acc=0.7083333134651184, loss=0.8055848479270935
train: epoch 127, loss 0.3514241576194763, acc=0.8407777547836304, loss=0.3514241576194763
test: epoch 127, loss 0.7406525015830994, acc=0.7055555582046509, loss=0.7406525015830994
train: epoch 128, loss 0.3504248559474945, acc=0.8400555849075317, loss=0.3504248559474945
test: epoch 128, loss 0.813265323638916, acc=0.7055555582046509, loss=0.813265323638916
train: epoch 129, loss 0.3513944745063782, acc=0.8411111235618591, loss=0.3513944745063782
test: epoch 129, loss 0.8138778209686279, acc=0.7027778029441833, loss=0.8138778209686279
train: epoch 130, loss 0.3566755950450897, acc=0.839388906955719, loss=0.3566755950450897
test: epoch 130, loss 0.7550317049026489, acc=0.7083333134651184, loss=0.7550317049026489
train: epoch 131, loss 0.35181984305381775, acc=0.8427222371101379, loss=0.35181984305381775
test: epoch 131, loss 0.7863510251045227, acc=0.7166666388511658, loss=0.7863510251045227
train: epoch 132, loss 0.3572683036327362, acc=0.8376666903495789, loss=0.3572683036327362
test: epoch 132, loss 0.7494451999664307, acc=0.7111111283302307, loss=0.7494451999664307
train: epoch 133, loss 0.35772091150283813, acc=0.8413333296775818, loss=0.35772091150283813
test: epoch 133, loss 0.7372159361839294, acc=0.7194444537162781, loss=0.7372159361839294
train: epoch 134, loss 0.34988418221473694, acc=0.8390555381774902, loss=0.34988418221473694
test: epoch 134, loss 0.7411497235298157, acc=0.7083333134651184, loss=0.7411497235298157
train: epoch 135, loss 0.35148701071739197, acc=0.8418889045715332, loss=0.35148701071739197
test: epoch 135, loss 0.7153357863426208, acc=0.7194444537162781, loss=0.7153357863426208
train: epoch 136, loss 0.3484904170036316, acc=0.8405555486679077, loss=0.3484904170036316
test: epoch 136, loss 0.7850782871246338, acc=0.7055555582046509, loss=0.7850782871246338
train: epoch 137, loss 0.3524933457374573, acc=0.8413888812065125, loss=0.3524933457374573
test: epoch 137, loss 0.8507462739944458, acc=0.7083333134651184, loss=0.8507462739944458
train: epoch 138, loss 0.3457365036010742, acc=0.8424444198608398, loss=0.3457365036010742
test: epoch 138, loss 0.7755286693572998, acc=0.7166666388511658, loss=0.7755286693572998
train: epoch 139, loss 0.35667797923088074, acc=0.8421111106872559, loss=0.35667797923088074
test: epoch 139, loss 0.761212170124054, acc=0.7138888835906982, loss=0.761212170124054
train: epoch 140, loss 0.3565540015697479, acc=0.8429444432258606, loss=0.3565540015697479
test: epoch 140, loss 0.7817725539207458, acc=0.7111111283302307, loss=0.7817725539207458
train: epoch 141, loss 0.3464980721473694, acc=0.8436111211776733, loss=0.3464980721473694
test: epoch 141, loss 0.8286000490188599, acc=0.7138888835906982, loss=0.8286000490188599
train: epoch 142, loss 0.3371133506298065, acc=0.8458889126777649, loss=0.3371133506298065
test: epoch 142, loss 0.8367493748664856, acc=0.7138888835906982, loss=0.8367493748664856
train: epoch 143, loss 0.34481826424598694, acc=0.846833348274231, loss=0.34481826424598694
test: epoch 143, loss 0.8071445226669312, acc=0.7055555582046509, loss=0.8071445226669312
train: epoch 144, loss 0.3542720079421997, acc=0.8409444689750671, loss=0.3542720079421997
test: epoch 144, loss 0.8115857839584351, acc=0.7138888835906982, loss=0.8115857839584351
train: epoch 145, loss 0.3465987741947174, acc=0.8448888659477234, loss=0.3465987741947174
test: epoch 145, loss 0.8416959047317505, acc=0.7111111283302307, loss=0.8416959047317505
train: epoch 146, loss 0.33953917026519775, acc=0.8452222347259521, loss=0.33953917026519775
test: epoch 146, loss 0.8243789076805115, acc=0.7138888835906982, loss=0.8243789076805115
train: epoch 147, loss 0.34297192096710205, acc=0.8426666855812073, loss=0.34297192096710205
test: epoch 147, loss 0.7995731234550476, acc=0.7027778029441833, loss=0.7995731234550476
train: epoch 148, loss 0.34547266364097595, acc=0.8383888602256775, loss=0.34547266364097595
test: epoch 148, loss 0.7865172624588013, acc=0.7138888835906982, loss=0.7865172624588013
train: epoch 149, loss 0.35500726103782654, acc=0.8403888940811157, loss=0.35500726103782654
test: epoch 149, loss 0.775679349899292, acc=0.7166666388511658, loss=0.775679349899292
train: epoch 150, loss 0.3410417139530182, acc=0.8458889126777649, loss=0.3410417139530182
test: epoch 150, loss 0.7526651620864868, acc=0.7138888835906982, loss=0.7526651620864868
