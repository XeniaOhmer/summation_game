# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=1", "--temp_decay=0.995", "--one_hot=0", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=1235188158, receiver_embed_dim=128, save_run=0, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=1235188158, receiver_embed_dim=128, save_run=False, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.696463108062744, acc=0.11272222548723221, loss=2.696463108062744
test: epoch 1, loss 2.7188303470611572, acc=0.12222222238779068, loss=2.7188303470611572
train: epoch 2, loss 1.98047935962677, acc=0.22699999809265137, loss=1.98047935962677
test: epoch 2, loss 2.382345199584961, acc=0.20277777314186096, loss=2.382345199584961
train: epoch 3, loss 1.673708200454712, acc=0.30933332443237305, loss=1.673708200454712
test: epoch 3, loss 2.7874062061309814, acc=0.125, loss=2.7874062061309814
train: epoch 4, loss 1.50823974609375, acc=0.37033334374427795, loss=1.50823974609375
test: epoch 4, loss 2.0558605194091797, acc=0.24722221493721008, loss=2.0558605194091797
train: epoch 5, loss 1.389841079711914, acc=0.41366666555404663, loss=1.389841079711914
test: epoch 5, loss 2.1341984272003174, acc=0.23888888955116272, loss=2.1341984272003174
train: epoch 6, loss 1.310874104499817, acc=0.4472222328186035, loss=1.310874104499817
test: epoch 6, loss 1.8630832433700562, acc=0.29722222685813904, loss=1.8630832433700562
train: epoch 7, loss 1.2153843641281128, acc=0.48533332347869873, loss=1.2153843641281128
test: epoch 7, loss 1.6242384910583496, acc=0.28611111640930176, loss=1.6242384910583496
train: epoch 8, loss 1.172062873840332, acc=0.5013889074325562, loss=1.172062873840332
test: epoch 8, loss 1.6780555248260498, acc=0.3083333373069763, loss=1.6780555248260498
train: epoch 9, loss 1.1213459968566895, acc=0.52311110496521, loss=1.1213459968566895
test: epoch 9, loss 1.6244378089904785, acc=0.29722222685813904, loss=1.6244378089904785
train: epoch 10, loss 1.0946248769760132, acc=0.5391666889190674, loss=1.0946248769760132
test: epoch 10, loss 1.3720864057540894, acc=0.3888888955116272, loss=1.3720864057540894
train: epoch 11, loss 1.0311264991760254, acc=0.5660555362701416, loss=1.0311264991760254
test: epoch 11, loss 1.3188540935516357, acc=0.41111111640930176, loss=1.3188540935516357
train: epoch 12, loss 0.9876949787139893, acc=0.5899444222450256, loss=0.9876949787139893
test: epoch 12, loss 1.6842739582061768, acc=0.31388887763023376, loss=1.6842739582061768
train: epoch 13, loss 0.9864070415496826, acc=0.5881666541099548, loss=0.9864070415496826
test: epoch 13, loss 1.538130521774292, acc=0.33888888359069824, loss=1.538130521774292
train: epoch 14, loss 0.9510625004768372, acc=0.6008889079093933, loss=0.9510625004768372
test: epoch 14, loss 1.4084187746047974, acc=0.39722222089767456, loss=1.4084187746047974
train: epoch 15, loss 0.8992736339569092, acc=0.6263889074325562, loss=0.8992736339569092
test: epoch 15, loss 1.5253289937973022, acc=0.3499999940395355, loss=1.5253289937973022
train: epoch 16, loss 0.8958307504653931, acc=0.6277222037315369, loss=0.8958307504653931
test: epoch 16, loss 1.675820231437683, acc=0.44999998807907104, loss=1.675820231437683
train: epoch 17, loss 0.8899179100990295, acc=0.6280555725097656, loss=0.8899179100990295
test: epoch 17, loss 1.359601378440857, acc=0.4333333373069763, loss=1.359601378440857
train: epoch 18, loss 0.8554787039756775, acc=0.6456666588783264, loss=0.8554787039756775
test: epoch 18, loss 1.447007656097412, acc=0.3861111104488373, loss=1.447007656097412
train: epoch 19, loss 0.8622358441352844, acc=0.6457777619361877, loss=0.8622358441352844
test: epoch 19, loss 1.44169282913208, acc=0.36944442987442017, loss=1.44169282913208
train: epoch 20, loss 0.8396770358085632, acc=0.6511666774749756, loss=0.8396770358085632
test: epoch 20, loss 1.380820631980896, acc=0.4027777910232544, loss=1.380820631980896
train: epoch 21, loss 0.829030454158783, acc=0.6514999866485596, loss=0.829030454158783
test: epoch 21, loss 1.5521697998046875, acc=0.3777777850627899, loss=1.5521697998046875
train: epoch 22, loss 0.8308563828468323, acc=0.6556110978126526, loss=0.8308563828468323
test: epoch 22, loss 1.624212384223938, acc=0.375, loss=1.624212384223938
train: epoch 23, loss 0.8024823665618896, acc=0.6722777485847473, loss=0.8024823665618896
test: epoch 23, loss 1.296218752861023, acc=0.4972222149372101, loss=1.296218752861023
train: epoch 24, loss 0.7938184142112732, acc=0.6692222356796265, loss=0.7938184142112732
test: epoch 24, loss 1.4332281351089478, acc=0.4416666626930237, loss=1.4332281351089478
train: epoch 25, loss 0.789398193359375, acc=0.6790000200271606, loss=0.789398193359375
test: epoch 25, loss 1.533555507659912, acc=0.4722222089767456, loss=1.533555507659912
train: epoch 26, loss 0.8056946396827698, acc=0.6747221946716309, loss=0.8056946396827698
test: epoch 26, loss 1.5040582418441772, acc=0.41111111640930176, loss=1.5040582418441772
train: epoch 27, loss 0.7683162093162537, acc=0.6853888630867004, loss=0.7683162093162537
test: epoch 27, loss 1.3122962713241577, acc=0.3777777850627899, loss=1.3122962713241577
train: epoch 28, loss 0.7742533683776855, acc=0.679611086845398, loss=0.7742533683776855
test: epoch 28, loss 1.4699751138687134, acc=0.3916666805744171, loss=1.4699751138687134
train: epoch 29, loss 0.7429770827293396, acc=0.6963889002799988, loss=0.7429770827293396
test: epoch 29, loss 1.4030876159667969, acc=0.40833333134651184, loss=1.4030876159667969
train: epoch 30, loss 0.7768635749816895, acc=0.6812777519226074, loss=0.7768635749816895
test: epoch 30, loss 1.2755961418151855, acc=0.4833333194255829, loss=1.2755961418151855
train: epoch 31, loss 0.7158204913139343, acc=0.7146666646003723, loss=0.7158204913139343
test: epoch 31, loss 1.3667405843734741, acc=0.43888887763023376, loss=1.3667405843734741
train: epoch 32, loss 0.7726302146911621, acc=0.6834999918937683, loss=0.7726302146911621
test: epoch 32, loss 1.3000177145004272, acc=0.4694444537162781, loss=1.3000177145004272
train: epoch 33, loss 0.7412225604057312, acc=0.6980555653572083, loss=0.7412225604057312
test: epoch 33, loss 1.4144901037216187, acc=0.4194444417953491, loss=1.4144901037216187
train: epoch 34, loss 0.7310082316398621, acc=0.7076666951179504, loss=0.7310082316398621
test: epoch 34, loss 1.3795700073242188, acc=0.4722222089767456, loss=1.3795700073242188
train: epoch 35, loss 0.7265768647193909, acc=0.7022222280502319, loss=0.7265768647193909
test: epoch 35, loss 1.2372283935546875, acc=0.4611110985279083, loss=1.2372283935546875
train: epoch 36, loss 0.708755373954773, acc=0.7127777934074402, loss=0.708755373954773
test: epoch 36, loss 1.3276180028915405, acc=0.4888888895511627, loss=1.3276180028915405
train: epoch 37, loss 0.7110099196434021, acc=0.7054444551467896, loss=0.7110099196434021
test: epoch 37, loss 1.4749274253845215, acc=0.4138889014720917, loss=1.4749274253845215
train: epoch 38, loss 0.7304640412330627, acc=0.7022777795791626, loss=0.7304640412330627
test: epoch 38, loss 1.250343918800354, acc=0.5222222208976746, loss=1.250343918800354
train: epoch 39, loss 0.6964223980903625, acc=0.7146111130714417, loss=0.6964223980903625
test: epoch 39, loss 1.3416001796722412, acc=0.43888887763023376, loss=1.3416001796722412
train: epoch 40, loss 0.706398606300354, acc=0.7088333368301392, loss=0.706398606300354
test: epoch 40, loss 1.2846858501434326, acc=0.47777777910232544, loss=1.2846858501434326
train: epoch 41, loss 0.7217800617218018, acc=0.7037777900695801, loss=0.7217800617218018
test: epoch 41, loss 1.225968837738037, acc=0.4861111044883728, loss=1.225968837738037
train: epoch 42, loss 0.6741518378257751, acc=0.7203333377838135, loss=0.6741518378257751
test: epoch 42, loss 1.2984586954116821, acc=0.47777777910232544, loss=1.2984586954116821
train: epoch 43, loss 0.7094458937644958, acc=0.7083333134651184, loss=0.7094458937644958
test: epoch 43, loss 1.4534715414047241, acc=0.4972222149372101, loss=1.4534715414047241
train: epoch 44, loss 0.730972170829773, acc=0.7029444575309753, loss=0.730972170829773
test: epoch 44, loss 1.4494423866271973, acc=0.42500001192092896, loss=1.4494423866271973
train: epoch 45, loss 0.7036360502243042, acc=0.7089999914169312, loss=0.7036360502243042
test: epoch 45, loss 1.2195348739624023, acc=0.550000011920929, loss=1.2195348739624023
train: epoch 46, loss 0.6842062473297119, acc=0.7174999713897705, loss=0.6842062473297119
test: epoch 46, loss 1.2584154605865479, acc=0.4583333432674408, loss=1.2584154605865479
train: epoch 47, loss 0.7042139172554016, acc=0.7094444632530212, loss=0.7042139172554016
test: epoch 47, loss 1.2180346250534058, acc=0.5, loss=1.2180346250534058
train: epoch 48, loss 0.6851087212562561, acc=0.7164444327354431, loss=0.6851087212562561
test: epoch 48, loss 1.5367172956466675, acc=0.3611111044883728, loss=1.5367172956466675
train: epoch 49, loss 0.6904449462890625, acc=0.7127222418785095, loss=0.6904449462890625
test: epoch 49, loss 1.1746565103530884, acc=0.5027777552604675, loss=1.1746565103530884
train: epoch 50, loss 0.677401602268219, acc=0.7216110825538635, loss=0.677401602268219
test: epoch 50, loss 1.1423386335372925, acc=0.5416666865348816, loss=1.1423386335372925
train: epoch 51, loss 0.7002352476119995, acc=0.7110555768013, loss=0.7002352476119995
test: epoch 51, loss 1.2062195539474487, acc=0.4749999940395355, loss=1.2062195539474487
train: epoch 52, loss 0.686949610710144, acc=0.7160000205039978, loss=0.686949610710144
test: epoch 52, loss 1.358001947402954, acc=0.39444443583488464, loss=1.358001947402954
train: epoch 53, loss 0.6836709380149841, acc=0.7198333144187927, loss=0.6836709380149841
test: epoch 53, loss 1.3460693359375, acc=0.44999998807907104, loss=1.3460693359375
train: epoch 54, loss 0.7340046763420105, acc=0.6980555653572083, loss=0.7340046763420105
test: epoch 54, loss 1.3020882606506348, acc=0.4722222089767456, loss=1.3020882606506348
train: epoch 55, loss 0.6698379516601562, acc=0.7250555753707886, loss=0.6698379516601562
test: epoch 55, loss 1.4375606775283813, acc=0.43888887763023376, loss=1.4375606775283813
train: epoch 56, loss 0.6582955121994019, acc=0.7348333597183228, loss=0.6582955121994019
test: epoch 56, loss 1.2931311130523682, acc=0.4555555582046509, loss=1.2931311130523682
train: epoch 57, loss 0.7074128985404968, acc=0.7102222442626953, loss=0.7074128985404968
test: epoch 57, loss 1.2366604804992676, acc=0.5055555701255798, loss=1.2366604804992676
train: epoch 58, loss 0.6928935647010803, acc=0.7110555768013, loss=0.6928935647010803
test: epoch 58, loss 1.240437388420105, acc=0.519444465637207, loss=1.240437388420105
train: epoch 59, loss 0.6462672352790833, acc=0.7306110858917236, loss=0.6462672352790833
test: epoch 59, loss 1.2677347660064697, acc=0.4694444537162781, loss=1.2677347660064697
train: epoch 60, loss 0.7328521609306335, acc=0.6970000267028809, loss=0.7328521609306335
test: epoch 60, loss 1.138426423072815, acc=0.4694444537162781, loss=1.138426423072815
train: epoch 61, loss 0.6596053838729858, acc=0.723111093044281, loss=0.6596053838729858
test: epoch 61, loss 1.2209322452545166, acc=0.4694444537162781, loss=1.2209322452545166
train: epoch 62, loss 0.6749966144561768, acc=0.7154444456100464, loss=0.6749966144561768
test: epoch 62, loss 1.132735252380371, acc=0.5, loss=1.132735252380371
train: epoch 63, loss 0.6656726598739624, acc=0.7207777500152588, loss=0.6656726598739624
test: epoch 63, loss 1.2876991033554077, acc=0.5027777552604675, loss=1.2876991033554077
train: epoch 64, loss 0.6745651960372925, acc=0.711222231388092, loss=0.6745651960372925
test: epoch 64, loss 1.318556785583496, acc=0.4333333373069763, loss=1.318556785583496
train: epoch 65, loss 0.6741304397583008, acc=0.7096111178398132, loss=0.6741304397583008
test: epoch 65, loss 1.0906445980072021, acc=0.4416666626930237, loss=1.0906445980072021
train: epoch 66, loss 0.7098940014839172, acc=0.6963333487510681, loss=0.7098940014839172
test: epoch 66, loss 1.0727003812789917, acc=0.4861111044883728, loss=1.0727003812789917
train: epoch 67, loss 0.7283517122268677, acc=0.684333324432373, loss=0.7283517122268677
test: epoch 67, loss 1.233305811882019, acc=0.43611112236976624, loss=1.233305811882019
train: epoch 68, loss 0.6646788120269775, acc=0.7070000171661377, loss=0.6646788120269775
test: epoch 68, loss 1.21561861038208, acc=0.48055556416511536, loss=1.21561861038208
train: epoch 69, loss 0.6472407579421997, acc=0.7235000133514404, loss=0.6472407579421997
test: epoch 69, loss 1.2807193994522095, acc=0.5611110925674438, loss=1.2807193994522095
train: epoch 70, loss 0.6762210726737976, acc=0.7150555849075317, loss=0.6762210726737976
test: epoch 70, loss 1.144822359085083, acc=0.5111111402511597, loss=1.144822359085083
train: epoch 71, loss 0.6463195085525513, acc=0.7228333353996277, loss=0.6463195085525513
test: epoch 71, loss 1.0627092123031616, acc=0.5861111283302307, loss=1.0627092123031616
train: epoch 72, loss 0.6775527596473694, acc=0.7201111316680908, loss=0.6775527596473694
test: epoch 72, loss 1.3448100090026855, acc=0.4277777671813965, loss=1.3448100090026855
train: epoch 73, loss 0.6502912044525146, acc=0.7317222356796265, loss=0.6502912044525146
test: epoch 73, loss 1.2721178531646729, acc=0.519444465637207, loss=1.2721178531646729
train: epoch 74, loss 0.6337485313415527, acc=0.7373889088630676, loss=0.6337485313415527
test: epoch 74, loss 1.2500783205032349, acc=0.519444465637207, loss=1.2500783205032349
train: epoch 75, loss 0.652746319770813, acc=0.7233889102935791, loss=0.652746319770813
test: epoch 75, loss 1.2581921815872192, acc=0.5166666507720947, loss=1.2581921815872192
train: epoch 76, loss 0.6521535515785217, acc=0.7237222194671631, loss=0.6521535515785217
test: epoch 76, loss 1.231564998626709, acc=0.4444444477558136, loss=1.231564998626709
train: epoch 77, loss 0.644225537776947, acc=0.7263333201408386, loss=0.644225537776947
test: epoch 77, loss 1.1584233045578003, acc=0.5222222208976746, loss=1.1584233045578003
train: epoch 78, loss 0.6583462357521057, acc=0.7228888869285583, loss=0.6583462357521057
test: epoch 78, loss 1.2287245988845825, acc=0.5138888955116272, loss=1.2287245988845825
train: epoch 79, loss 0.5984792113304138, acc=0.7480555772781372, loss=0.5984792113304138
test: epoch 79, loss 1.1346408128738403, acc=0.5083333253860474, loss=1.1346408128738403
train: epoch 80, loss 0.633853554725647, acc=0.7284444570541382, loss=0.633853554725647
test: epoch 80, loss 1.0326576232910156, acc=0.5555555820465088, loss=1.0326576232910156
train: epoch 81, loss 0.6505387425422668, acc=0.722944438457489, loss=0.6505387425422668
test: epoch 81, loss 1.1380603313446045, acc=0.5083333253860474, loss=1.1380603313446045
train: epoch 82, loss 0.6217199563980103, acc=0.7349444627761841, loss=0.6217199563980103
test: epoch 82, loss 1.2113462686538696, acc=0.5111111402511597, loss=1.2113462686538696
train: epoch 83, loss 0.6695702075958252, acc=0.7210555672645569, loss=0.6695702075958252
test: epoch 83, loss 1.2279497385025024, acc=0.5222222208976746, loss=1.2279497385025024
train: epoch 84, loss 0.6846067309379578, acc=0.7101666927337646, loss=0.6846067309379578
test: epoch 84, loss 1.0596340894699097, acc=0.5111111402511597, loss=1.0596340894699097
train: epoch 85, loss 0.6073359847068787, acc=0.7394444346427917, loss=0.6073359847068787
test: epoch 85, loss 1.2445546388626099, acc=0.5361111164093018, loss=1.2445546388626099
train: epoch 86, loss 0.6384981870651245, acc=0.7328888773918152, loss=0.6384981870651245
test: epoch 86, loss 1.1255232095718384, acc=0.5416666865348816, loss=1.1255232095718384
train: epoch 87, loss 0.6262453198432922, acc=0.7370555400848389, loss=0.6262453198432922
test: epoch 87, loss 1.1927661895751953, acc=0.5305555462837219, loss=1.1927661895751953
train: epoch 88, loss 0.6294435262680054, acc=0.7373889088630676, loss=0.6294435262680054
test: epoch 88, loss 1.3266342878341675, acc=0.5249999761581421, loss=1.3266342878341675
train: epoch 89, loss 0.606697678565979, acc=0.7472777962684631, loss=0.606697678565979
test: epoch 89, loss 1.1850990056991577, acc=0.5249999761581421, loss=1.1850990056991577
train: epoch 90, loss 0.6178128719329834, acc=0.7416666746139526, loss=0.6178128719329834
test: epoch 90, loss 1.4566549062728882, acc=0.4694444537162781, loss=1.4566549062728882
train: epoch 91, loss 0.6102195382118225, acc=0.741611123085022, loss=0.6102195382118225
test: epoch 91, loss 1.2936840057373047, acc=0.49444442987442017, loss=1.2936840057373047
train: epoch 92, loss 0.6423544883728027, acc=0.7377222180366516, loss=0.6423544883728027
test: epoch 92, loss 1.101518154144287, acc=0.5638889074325562, loss=1.101518154144287
train: epoch 93, loss 0.6163727045059204, acc=0.7455000281333923, loss=0.6163727045059204
test: epoch 93, loss 1.242228388786316, acc=0.519444465637207, loss=1.242228388786316
train: epoch 94, loss 0.5993140935897827, acc=0.7469444274902344, loss=0.5993140935897827
test: epoch 94, loss 1.2280120849609375, acc=0.5166666507720947, loss=1.2280120849609375
train: epoch 95, loss 0.6219398975372314, acc=0.7367777824401855, loss=0.6219398975372314
test: epoch 95, loss 1.2982133626937866, acc=0.5083333253860474, loss=1.2982133626937866
train: epoch 96, loss 0.6200029850006104, acc=0.7406111359596252, loss=0.6200029850006104
test: epoch 96, loss 1.0895886421203613, acc=0.5861111283302307, loss=1.0895886421203613
train: epoch 97, loss 0.5971959233283997, acc=0.7491111159324646, loss=0.5971959233283997
test: epoch 97, loss 1.1108474731445312, acc=0.5444444417953491, loss=1.1108474731445312
train: epoch 98, loss 0.5947992205619812, acc=0.7444999814033508, loss=0.5947992205619812
test: epoch 98, loss 1.4288614988327026, acc=0.49166667461395264, loss=1.4288614988327026
train: epoch 99, loss 0.6210212111473083, acc=0.7356666922569275, loss=0.6210212111473083
test: epoch 99, loss 1.1430264711380005, acc=0.5555555820465088, loss=1.1430264711380005
train: epoch 100, loss 0.608844518661499, acc=0.7424444556236267, loss=0.608844518661499
test: epoch 100, loss 1.2747877836227417, acc=0.5388888716697693, loss=1.2747877836227417
train: epoch 101, loss 0.6315282583236694, acc=0.7349444627761841, loss=0.6315282583236694
test: epoch 101, loss 1.1872599124908447, acc=0.5083333253860474, loss=1.1872599124908447
train: epoch 102, loss 0.6180137991905212, acc=0.7422778010368347, loss=0.6180137991905212
test: epoch 102, loss 1.2232966423034668, acc=0.5472221970558167, loss=1.2232966423034668
train: epoch 103, loss 0.5851092338562012, acc=0.7571666836738586, loss=0.5851092338562012
test: epoch 103, loss 1.2577193975448608, acc=0.5472221970558167, loss=1.2577193975448608
train: epoch 104, loss 0.6552662253379822, acc=0.7252222299575806, loss=0.6552662253379822
test: epoch 104, loss 1.1669381856918335, acc=0.5111111402511597, loss=1.1669381856918335
train: epoch 105, loss 0.5987796187400818, acc=0.7477222084999084, loss=0.5987796187400818
test: epoch 105, loss 1.129029393196106, acc=0.5583333373069763, loss=1.129029393196106
train: epoch 106, loss 0.6206823587417603, acc=0.7396666407585144, loss=0.6206823587417603
test: epoch 106, loss 1.0866446495056152, acc=0.5583333373069763, loss=1.0866446495056152
train: epoch 107, loss 0.6079086065292358, acc=0.7420555353164673, loss=0.6079086065292358
test: epoch 107, loss 1.0743056535720825, acc=0.5888888835906982, loss=1.0743056535720825
train: epoch 108, loss 0.6068835258483887, acc=0.7418333292007446, loss=0.6068835258483887
test: epoch 108, loss 1.2336658239364624, acc=0.519444465637207, loss=1.2336658239364624
train: epoch 109, loss 0.6230015158653259, acc=0.7386666536331177, loss=0.6230015158653259
test: epoch 109, loss 1.138771414756775, acc=0.519444465637207, loss=1.138771414756775
train: epoch 110, loss 0.6436217427253723, acc=0.7282222509384155, loss=0.6436217427253723
test: epoch 110, loss 1.1895358562469482, acc=0.5249999761581421, loss=1.1895358562469482
train: epoch 111, loss 0.5853014588356018, acc=0.7527222037315369, loss=0.5853014588356018
test: epoch 111, loss 1.2325875759124756, acc=0.5611110925674438, loss=1.2325875759124756
train: epoch 112, loss 0.5716275572776794, acc=0.7551110982894897, loss=0.5716275572776794
test: epoch 112, loss 1.0339034795761108, acc=0.5638889074325562, loss=1.0339034795761108
train: epoch 113, loss 0.6251279711723328, acc=0.7379444241523743, loss=0.6251279711723328
test: epoch 113, loss 1.2103271484375, acc=0.5611110925674438, loss=1.2103271484375
train: epoch 114, loss 0.6684474349021912, acc=0.7108333110809326, loss=0.6684474349021912
test: epoch 114, loss 1.1910239458084106, acc=0.5472221970558167, loss=1.1910239458084106
train: epoch 115, loss 0.6140304803848267, acc=0.7283889055252075, loss=0.6140304803848267
test: epoch 115, loss 1.1882041692733765, acc=0.5611110925674438, loss=1.1882041692733765
train: epoch 116, loss 0.6409497261047363, acc=0.7280555367469788, loss=0.6409497261047363
test: epoch 116, loss 1.4205248355865479, acc=0.5416666865348816, loss=1.4205248355865479
train: epoch 117, loss 0.6702466607093811, acc=0.7212222218513489, loss=0.6702466607093811
test: epoch 117, loss 1.1639986038208008, acc=0.5388888716697693, loss=1.1639986038208008
train: epoch 118, loss 0.6478769183158875, acc=0.7233889102935791, loss=0.6478769183158875
test: epoch 118, loss 1.250216007232666, acc=0.5055555701255798, loss=1.250216007232666
train: epoch 119, loss 0.6923767328262329, acc=0.7092777490615845, loss=0.6923767328262329
test: epoch 119, loss 1.0744235515594482, acc=0.5027777552604675, loss=1.0744235515594482
train: epoch 120, loss 0.6299756169319153, acc=0.7314444184303284, loss=0.6299756169319153
test: epoch 120, loss 1.1112881898880005, acc=0.5972222089767456, loss=1.1112881898880005
train: epoch 121, loss 0.6509171724319458, acc=0.7209444642066956, loss=0.6509171724319458
test: epoch 121, loss 1.1487056016921997, acc=0.5722222328186035, loss=1.1487056016921997
train: epoch 122, loss 0.7012310028076172, acc=0.7127222418785095, loss=0.7012310028076172
test: epoch 122, loss 0.9766577482223511, acc=0.5944444537162781, loss=0.9766577482223511
train: epoch 123, loss 0.5982446670532227, acc=0.7434444427490234, loss=0.5982446670532227
test: epoch 123, loss 0.9854114055633545, acc=0.6083333492279053, loss=0.9854114055633545
train: epoch 124, loss 0.6386618614196777, acc=0.7308889031410217, loss=0.6386618614196777
test: epoch 124, loss 1.0615575313568115, acc=0.6083333492279053, loss=1.0615575313568115
train: epoch 125, loss 0.5782477259635925, acc=0.7556111216545105, loss=0.5782477259635925
test: epoch 125, loss 1.1240347623825073, acc=0.5666666626930237, loss=1.1240347623825073
train: epoch 126, loss 0.65621018409729, acc=0.7335000038146973, loss=0.65621018409729
test: epoch 126, loss 1.1997454166412354, acc=0.5416666865348816, loss=1.1997454166412354
train: epoch 127, loss 0.664125919342041, acc=0.7211111187934875, loss=0.664125919342041
test: epoch 127, loss 1.0709747076034546, acc=0.5666666626930237, loss=1.0709747076034546
train: epoch 128, loss 0.5988421440124512, acc=0.7485555410385132, loss=0.5988421440124512
test: epoch 128, loss 1.3188045024871826, acc=0.5222222208976746, loss=1.3188045024871826
train: epoch 129, loss 0.6259036660194397, acc=0.7306666374206543, loss=0.6259036660194397
test: epoch 129, loss 1.071711540222168, acc=0.6083333492279053, loss=1.071711540222168
train: epoch 130, loss 0.6076574921607971, acc=0.7318333387374878, loss=0.6076574921607971
test: epoch 130, loss 1.012160301208496, acc=0.5888888835906982, loss=1.012160301208496
train: epoch 131, loss 0.5490589141845703, acc=0.754277765750885, loss=0.5490589141845703
test: epoch 131, loss 0.9971684813499451, acc=0.5805555582046509, loss=0.9971684813499451
train: epoch 132, loss 0.571765661239624, acc=0.7496111392974854, loss=0.571765661239624
test: epoch 132, loss 1.1234456300735474, acc=0.6083333492279053, loss=1.1234456300735474
train: epoch 133, loss 0.6090717911720276, acc=0.738444447517395, loss=0.6090717911720276
test: epoch 133, loss 0.9793530106544495, acc=0.605555534362793, loss=0.9793530106544495
train: epoch 134, loss 0.5835478901863098, acc=0.7448333501815796, loss=0.5835478901863098
test: epoch 134, loss 1.1335830688476562, acc=0.6027777791023254, loss=1.1335830688476562
train: epoch 135, loss 0.7052321434020996, acc=0.7163888812065125, loss=0.7052321434020996
test: epoch 135, loss 1.1074910163879395, acc=0.6027777791023254, loss=1.1074910163879395
train: epoch 136, loss 0.5807688236236572, acc=0.7576666474342346, loss=0.5807688236236572
test: epoch 136, loss 0.9694125652313232, acc=0.6166666746139526, loss=0.9694125652313232
train: epoch 137, loss 0.5928460359573364, acc=0.7497222423553467, loss=0.5928460359573364
test: epoch 137, loss 0.9274005889892578, acc=0.6027777791023254, loss=0.9274005889892578
train: epoch 138, loss 0.5682453513145447, acc=0.7540555596351624, loss=0.5682453513145447
test: epoch 138, loss 0.9956983923912048, acc=0.5916666388511658, loss=0.9956983923912048
train: epoch 139, loss 0.6622239947319031, acc=0.718500018119812, loss=0.6622239947319031
test: epoch 139, loss 0.9682205319404602, acc=0.6083333492279053, loss=0.9682205319404602
train: epoch 140, loss 0.5628631114959717, acc=0.7595000267028809, loss=0.5628631114959717
test: epoch 140, loss 0.9962283968925476, acc=0.6083333492279053, loss=0.9962283968925476
train: epoch 141, loss 0.5736308693885803, acc=0.7570555806159973, loss=0.5736308693885803
test: epoch 141, loss 1.0620465278625488, acc=0.574999988079071, loss=1.0620465278625488
train: epoch 142, loss 0.628015398979187, acc=0.730222225189209, loss=0.628015398979187
test: epoch 142, loss 1.0449209213256836, acc=0.550000011920929, loss=1.0449209213256836
train: epoch 143, loss 0.6189960837364197, acc=0.7358888983726501, loss=0.6189960837364197
test: epoch 143, loss 1.1496514081954956, acc=0.5555555820465088, loss=1.1496514081954956
train: epoch 144, loss 0.6183751225471497, acc=0.7368888854980469, loss=0.6183751225471497
test: epoch 144, loss 1.1964551210403442, acc=0.5249999761581421, loss=1.1964551210403442
train: epoch 145, loss 0.6232228875160217, acc=0.7367777824401855, loss=0.6232228875160217
test: epoch 145, loss 1.0811203718185425, acc=0.5527777671813965, loss=1.0811203718185425
train: epoch 146, loss 0.5913938283920288, acc=0.7503888607025146, loss=0.5913938283920288
test: epoch 146, loss 1.226645588874817, acc=0.5444444417953491, loss=1.226645588874817
train: epoch 147, loss 0.6052410006523132, acc=0.746222198009491, loss=0.6052410006523132
test: epoch 147, loss 1.0513659715652466, acc=0.5694444179534912, loss=1.0513659715652466
train: epoch 148, loss 0.5527083277702332, acc=0.7654444575309753, loss=0.5527083277702332
test: epoch 148, loss 1.0723402500152588, acc=0.6027777791023254, loss=1.0723402500152588
train: epoch 149, loss 0.5837990045547485, acc=0.7575555443763733, loss=0.5837990045547485
test: epoch 149, loss 1.0688552856445312, acc=0.605555534362793, loss=1.0688552856445312
train: epoch 150, loss 0.5666277408599854, acc=0.7631111145019531, loss=0.5666277408599854
test: epoch 150, loss 1.095662236213684, acc=0.6000000238418579, loss=1.095662236213684
