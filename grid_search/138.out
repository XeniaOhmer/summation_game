# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=1.5", "--temp_decay=0.99", "--one_hot=0", "--n_layers=1"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=349458822, receiver_embed_dim=128, save_run=0, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=349458822, receiver_embed_dim=128, save_run=False, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.035501480102539, acc=0.09188888967037201, loss=3.035501480102539
test: epoch 1, loss 4.438161373138428, acc=0.05000000074505806, loss=4.438161373138428
train: epoch 2, loss 2.619586944580078, acc=0.14444445073604584, loss=2.619586944580078
test: epoch 2, loss 5.204692363739014, acc=0.05277777835726738, loss=5.204692363739014
train: epoch 3, loss 2.5078582763671875, acc=0.1613333374261856, loss=2.5078582763671875
test: epoch 3, loss 5.781844139099121, acc=0.05000000074505806, loss=5.781844139099121
train: epoch 4, loss 2.444497585296631, acc=0.1704999953508377, loss=2.444497585296631
test: epoch 4, loss 6.045186519622803, acc=0.0416666679084301, loss=6.045186519622803
train: epoch 5, loss 2.395909309387207, acc=0.17588889598846436, loss=2.395909309387207
test: epoch 5, loss 6.033117294311523, acc=0.04722222313284874, loss=6.033117294311523
train: epoch 6, loss 2.364499568939209, acc=0.18516667187213898, loss=2.364499568939209
test: epoch 6, loss 6.005154132843018, acc=0.04722222313284874, loss=6.005154132843018
train: epoch 7, loss 2.3282439708709717, acc=0.1917777806520462, loss=2.3282439708709717
test: epoch 7, loss 6.117038249969482, acc=0.0416666679084301, loss=6.117038249969482
train: epoch 8, loss 2.319395065307617, acc=0.18905556201934814, loss=2.319395065307617
test: epoch 8, loss 5.994408130645752, acc=0.04444444552063942, loss=5.994408130645752
train: epoch 9, loss 2.2962114810943604, acc=0.19527778029441833, loss=2.2962114810943604
test: epoch 9, loss 6.075131893157959, acc=0.0416666679084301, loss=6.075131893157959
train: epoch 10, loss 2.286146402359009, acc=0.19683332741260529, loss=2.286146402359009
test: epoch 10, loss 5.906601905822754, acc=0.04722222313284874, loss=5.906601905822754
train: epoch 11, loss 2.2739131450653076, acc=0.20216666162014008, loss=2.2739131450653076
test: epoch 11, loss 6.021509170532227, acc=0.04444444552063942, loss=6.021509170532227
train: epoch 12, loss 2.25272536277771, acc=0.20822222530841827, loss=2.25272536277771
test: epoch 12, loss 6.03289270401001, acc=0.0416666679084301, loss=6.03289270401001
train: epoch 13, loss 2.261366128921509, acc=0.20772221684455872, loss=2.261366128921509
test: epoch 13, loss 6.2788496017456055, acc=0.03611111268401146, loss=6.2788496017456055
train: epoch 14, loss 2.2396152019500732, acc=0.21077777445316315, loss=2.2396152019500732
test: epoch 14, loss 6.3221516609191895, acc=0.03888889029622078, loss=6.3221516609191895
train: epoch 15, loss 2.2403903007507324, acc=0.20838889479637146, loss=2.2403903007507324
test: epoch 15, loss 6.125177383422852, acc=0.03888889029622078, loss=6.125177383422852
train: epoch 16, loss 2.2394847869873047, acc=0.20900000631809235, loss=2.2394847869873047
test: epoch 16, loss 5.887039661407471, acc=0.03888889029622078, loss=5.887039661407471
train: epoch 17, loss 2.2182013988494873, acc=0.21400000154972076, loss=2.2182013988494873
test: epoch 17, loss 5.999781131744385, acc=0.0416666679084301, loss=5.999781131744385
train: epoch 18, loss 2.209526538848877, acc=0.21222221851348877, loss=2.209526538848877
test: epoch 18, loss 6.188747406005859, acc=0.0416666679084301, loss=6.188747406005859
train: epoch 19, loss 2.222315549850464, acc=0.2141111046075821, loss=2.222315549850464
test: epoch 19, loss 5.903712272644043, acc=0.04444444552063942, loss=5.903712272644043
train: epoch 20, loss 2.2205138206481934, acc=0.21133333444595337, loss=2.2205138206481934
test: epoch 20, loss 6.029134750366211, acc=0.03333333507180214, loss=6.029134750366211
train: epoch 21, loss 2.2183167934417725, acc=0.21327777206897736, loss=2.2183167934417725
test: epoch 21, loss 5.896890640258789, acc=0.05000000074505806, loss=5.896890640258789
train: epoch 22, loss 2.2260220050811768, acc=0.21666666865348816, loss=2.2260220050811768
test: epoch 22, loss 5.647103309631348, acc=0.03055555559694767, loss=5.647103309631348
train: epoch 23, loss 2.210954189300537, acc=0.216888889670372, loss=2.210954189300537
test: epoch 23, loss 5.472044467926025, acc=0.03888889029622078, loss=5.472044467926025
train: epoch 24, loss 2.2134106159210205, acc=0.2154444456100464, loss=2.2134106159210205
test: epoch 24, loss 5.48672342300415, acc=0.04722222313284874, loss=5.48672342300415
train: epoch 25, loss 2.2030842304229736, acc=0.2170555591583252, loss=2.2030842304229736
test: epoch 25, loss 5.559935092926025, acc=0.03888889029622078, loss=5.559935092926025
train: epoch 26, loss 2.2124547958374023, acc=0.2167777717113495, loss=2.2124547958374023
test: epoch 26, loss 5.24397611618042, acc=0.03888889029622078, loss=5.24397611618042
train: epoch 27, loss 2.2132601737976074, acc=0.21977777779102325, loss=2.2132601737976074
test: epoch 27, loss 5.24368143081665, acc=0.0416666679084301, loss=5.24368143081665
train: epoch 28, loss 2.2159290313720703, acc=0.21344444155693054, loss=2.2159290313720703
test: epoch 28, loss 5.040139675140381, acc=0.0416666679084301, loss=5.040139675140381
train: epoch 29, loss 2.229409694671631, acc=0.21722222864627838, loss=2.229409694671631
test: epoch 29, loss 5.28508186340332, acc=0.04722222313284874, loss=5.28508186340332
train: epoch 30, loss 2.2189996242523193, acc=0.21622222661972046, loss=2.2189996242523193
test: epoch 30, loss 5.025564193725586, acc=0.0416666679084301, loss=5.025564193725586
train: epoch 31, loss 2.2170369625091553, acc=0.21583333611488342, loss=2.2170369625091553
test: epoch 31, loss 4.817842960357666, acc=0.03888889029622078, loss=4.817842960357666
train: epoch 32, loss 2.2228314876556396, acc=0.21250000596046448, loss=2.2228314876556396
test: epoch 32, loss 4.883587837219238, acc=0.04444444552063942, loss=4.883587837219238
train: epoch 33, loss 2.2253918647766113, acc=0.21222221851348877, loss=2.2253918647766113
test: epoch 33, loss 4.923836708068848, acc=0.04444444552063942, loss=4.923836708068848
train: epoch 34, loss 2.214033603668213, acc=0.21155555546283722, loss=2.214033603668213
test: epoch 34, loss 4.9379730224609375, acc=0.04722222313284874, loss=4.9379730224609375
train: epoch 35, loss 2.2377922534942627, acc=0.21355555951595306, loss=2.2377922534942627
test: epoch 35, loss 4.871011734008789, acc=0.04444444552063942, loss=4.871011734008789
train: epoch 36, loss 2.229987621307373, acc=0.21627777814865112, loss=2.229987621307373
test: epoch 36, loss 4.488823413848877, acc=0.04722222313284874, loss=4.488823413848877
train: epoch 37, loss 2.242691993713379, acc=0.21272222697734833, loss=2.242691993713379
test: epoch 37, loss 4.674346446990967, acc=0.04444444552063942, loss=4.674346446990967
train: epoch 38, loss 2.2524421215057373, acc=0.21005555987358093, loss=2.2524421215057373
test: epoch 38, loss 4.517843246459961, acc=0.04444444552063942, loss=4.517843246459961
train: epoch 39, loss 2.255613088607788, acc=0.2150000035762787, loss=2.255613088607788
test: epoch 39, loss 4.418954372406006, acc=0.04722222313284874, loss=4.418954372406006
train: epoch 40, loss 2.2589166164398193, acc=0.2093888819217682, loss=2.2589166164398193
test: epoch 40, loss 4.380723476409912, acc=0.06666667014360428, loss=4.380723476409912
train: epoch 41, loss 2.2560229301452637, acc=0.2123333364725113, loss=2.2560229301452637
test: epoch 41, loss 4.373550891876221, acc=0.05833333358168602, loss=4.373550891876221
train: epoch 42, loss 2.25757098197937, acc=0.20888888835906982, loss=2.25757098197937
test: epoch 42, loss 4.409755706787109, acc=0.04444444552063942, loss=4.409755706787109
train: epoch 43, loss 2.268535852432251, acc=0.20600000023841858, loss=2.268535852432251
test: epoch 43, loss 4.425849437713623, acc=0.03888889029622078, loss=4.425849437713623
train: epoch 44, loss 2.2793872356414795, acc=0.20544444024562836, loss=2.2793872356414795
test: epoch 44, loss 4.339602947235107, acc=0.04722222313284874, loss=4.339602947235107
train: epoch 45, loss 2.284717082977295, acc=0.2043333351612091, loss=2.284717082977295
test: epoch 45, loss 4.203068256378174, acc=0.04444444552063942, loss=4.203068256378174
train: epoch 46, loss 2.2863669395446777, acc=0.20033332705497742, loss=2.2863669395446777
test: epoch 46, loss 4.0622029304504395, acc=0.05833333358168602, loss=4.0622029304504395
train: epoch 47, loss 2.3070054054260254, acc=0.1940000057220459, loss=2.3070054054260254
test: epoch 47, loss 3.9510626792907715, acc=0.03888889029622078, loss=3.9510626792907715
train: epoch 48, loss 2.3005454540252686, acc=0.19966666400432587, loss=2.3005454540252686
test: epoch 48, loss 3.810211181640625, acc=0.0416666679084301, loss=3.810211181640625
train: epoch 49, loss 2.2961933612823486, acc=0.19905555248260498, loss=2.2961933612823486
test: epoch 49, loss 3.9490323066711426, acc=0.06666667014360428, loss=3.9490323066711426
train: epoch 50, loss 2.3005568981170654, acc=0.19750000536441803, loss=2.3005568981170654
test: epoch 50, loss 3.977717876434326, acc=0.05000000074505806, loss=3.977717876434326
train: epoch 51, loss 2.305907964706421, acc=0.19777777791023254, loss=2.305907964706421
test: epoch 51, loss 3.9449844360351562, acc=0.0555555559694767, loss=3.9449844360351562
train: epoch 52, loss 2.3063933849334717, acc=0.19966666400432587, loss=2.3063933849334717
test: epoch 52, loss 3.758206844329834, acc=0.07222222536802292, loss=3.758206844329834
train: epoch 53, loss 2.298980712890625, acc=0.19316667318344116, loss=2.298980712890625
test: epoch 53, loss 3.848940849304199, acc=0.05277777835726738, loss=3.848940849304199
train: epoch 54, loss 2.3218836784362793, acc=0.19772222638130188, loss=2.3218836784362793
test: epoch 54, loss 3.7324562072753906, acc=0.06666667014360428, loss=3.7324562072753906
train: epoch 55, loss 2.317598819732666, acc=0.19727778434753418, loss=2.317598819732666
test: epoch 55, loss 3.7942817211151123, acc=0.0555555559694767, loss=3.7942817211151123
train: epoch 56, loss 2.3280675411224365, acc=0.18888889253139496, loss=2.3280675411224365
test: epoch 56, loss 3.7488160133361816, acc=0.04444444552063942, loss=3.7488160133361816
train: epoch 57, loss 2.333881139755249, acc=0.19494444131851196, loss=2.333881139755249
test: epoch 57, loss 3.792926788330078, acc=0.05277777835726738, loss=3.792926788330078
train: epoch 58, loss 2.3297183513641357, acc=0.19116666913032532, loss=2.3297183513641357
test: epoch 58, loss 3.668274402618408, acc=0.0555555559694767, loss=3.668274402618408
train: epoch 59, loss 2.3329050540924072, acc=0.18472221493721008, loss=2.3329050540924072
test: epoch 59, loss 3.8229198455810547, acc=0.05833333358168602, loss=3.8229198455810547
train: epoch 60, loss 2.3412845134735107, acc=0.1845555603504181, loss=2.3412845134735107
test: epoch 60, loss 3.8474175930023193, acc=0.03611111268401146, loss=3.8474175930023193
train: epoch 61, loss 2.349175453186035, acc=0.18755555152893066, loss=2.349175453186035
test: epoch 61, loss 3.640841484069824, acc=0.06388889253139496, loss=3.640841484069824
train: epoch 62, loss 2.3600597381591797, acc=0.1863333284854889, loss=2.3600597381591797
test: epoch 62, loss 3.5170552730560303, acc=0.05000000074505806, loss=3.5170552730560303
train: epoch 63, loss 2.358494997024536, acc=0.17911110818386078, loss=2.358494997024536
test: epoch 63, loss 3.4921205043792725, acc=0.05000000074505806, loss=3.4921205043792725
train: epoch 64, loss 2.3723952770233154, acc=0.17783333361148834, loss=2.3723952770233154
test: epoch 64, loss 3.468125581741333, acc=0.06111111119389534, loss=3.468125581741333
train: epoch 65, loss 2.3619577884674072, acc=0.181444451212883, loss=2.3619577884674072
test: epoch 65, loss 3.413003921508789, acc=0.06111111119389534, loss=3.413003921508789
train: epoch 66, loss 2.3790528774261475, acc=0.17694444954395294, loss=2.3790528774261475
test: epoch 66, loss 3.4232938289642334, acc=0.07222222536802292, loss=3.4232938289642334
train: epoch 67, loss 2.3666818141937256, acc=0.17677778005599976, loss=2.3666818141937256
test: epoch 67, loss 3.4335134029388428, acc=0.05000000074505806, loss=3.4335134029388428
train: epoch 68, loss 2.3782620429992676, acc=0.17861111462116241, loss=2.3782620429992676
test: epoch 68, loss 3.4780430793762207, acc=0.05833333358168602, loss=3.4780430793762207
train: epoch 69, loss 2.368396759033203, acc=0.17588889598846436, loss=2.368396759033203
test: epoch 69, loss 3.357760429382324, acc=0.07500000298023224, loss=3.357760429382324
train: epoch 70, loss 2.4028730392456055, acc=0.17116667330265045, loss=2.4028730392456055
test: epoch 70, loss 3.4648597240448, acc=0.05277777835726738, loss=3.4648597240448
train: epoch 71, loss 2.391174554824829, acc=0.1731666624546051, loss=2.391174554824829
test: epoch 71, loss 3.3951406478881836, acc=0.07500000298023224, loss=3.3951406478881836
train: epoch 72, loss 2.3757174015045166, acc=0.17327778041362762, loss=2.3757174015045166
test: epoch 72, loss 3.5363221168518066, acc=0.05277777835726738, loss=3.5363221168518066
train: epoch 73, loss 2.3855011463165283, acc=0.17177778482437134, loss=2.3855011463165283
test: epoch 73, loss 3.36376953125, acc=0.0694444477558136, loss=3.36376953125
train: epoch 74, loss 2.373918056488037, acc=0.1715555489063263, loss=2.373918056488037
test: epoch 74, loss 3.442429304122925, acc=0.0555555559694767, loss=3.442429304122925
train: epoch 75, loss 2.37060284614563, acc=0.17472222447395325, loss=2.37060284614563
test: epoch 75, loss 3.3447647094726562, acc=0.0555555559694767, loss=3.3447647094726562
train: epoch 76, loss 2.382974147796631, acc=0.17649999260902405, loss=2.382974147796631
test: epoch 76, loss 3.3552961349487305, acc=0.04722222313284874, loss=3.3552961349487305
train: epoch 77, loss 2.3764569759368896, acc=0.1742222160100937, loss=2.3764569759368896
test: epoch 77, loss 3.490147590637207, acc=0.05000000074505806, loss=3.490147590637207
train: epoch 78, loss 2.3818342685699463, acc=0.17622222006320953, loss=2.3818342685699463
test: epoch 78, loss 3.417433738708496, acc=0.06388889253139496, loss=3.417433738708496
train: epoch 79, loss 2.393537998199463, acc=0.1756666600704193, loss=2.393537998199463
test: epoch 79, loss 3.3344130516052246, acc=0.07222222536802292, loss=3.3344130516052246
train: epoch 80, loss 2.3719701766967773, acc=0.17466667294502258, loss=2.3719701766967773
test: epoch 80, loss 3.3040432929992676, acc=0.07500000298023224, loss=3.3040432929992676
train: epoch 81, loss 2.354459762573242, acc=0.1783333271741867, loss=2.354459762573242
test: epoch 81, loss 3.367271661758423, acc=0.05277777835726738, loss=3.367271661758423
train: epoch 82, loss 2.352112293243408, acc=0.17505554854869843, loss=2.352112293243408
test: epoch 82, loss 3.2787673473358154, acc=0.08055555820465088, loss=3.2787673473358154
train: epoch 83, loss 2.359492301940918, acc=0.17855554819107056, loss=2.359492301940918
test: epoch 83, loss 3.240170478820801, acc=0.08888889104127884, loss=3.240170478820801
train: epoch 84, loss 2.35475754737854, acc=0.17483332753181458, loss=2.35475754737854
test: epoch 84, loss 3.247114896774292, acc=0.06388889253139496, loss=3.247114896774292
train: epoch 85, loss 2.356959104537964, acc=0.18094444274902344, loss=2.356959104537964
test: epoch 85, loss 3.3573215007781982, acc=0.0694444477558136, loss=3.3573215007781982
train: epoch 86, loss 2.3647074699401855, acc=0.1738888919353485, loss=2.3647074699401855
test: epoch 86, loss 3.266126871109009, acc=0.06111111119389534, loss=3.266126871109009
train: epoch 87, loss 2.357006549835205, acc=0.1753888875246048, loss=2.357006549835205
test: epoch 87, loss 3.345444917678833, acc=0.0555555559694767, loss=3.345444917678833
train: epoch 88, loss 2.3660905361175537, acc=0.17488889396190643, loss=2.3660905361175537
test: epoch 88, loss 3.3748204708099365, acc=0.05000000074505806, loss=3.3748204708099365
train: epoch 89, loss 2.343345880508423, acc=0.17483332753181458, loss=2.343345880508423
test: epoch 89, loss 3.4067389965057373, acc=0.06111111119389534, loss=3.4067389965057373
train: epoch 90, loss 2.354485034942627, acc=0.17749999463558197, loss=2.354485034942627
test: epoch 90, loss 3.267857551574707, acc=0.06666667014360428, loss=3.267857551574707
train: epoch 91, loss 2.341508626937866, acc=0.179666668176651, loss=2.341508626937866
test: epoch 91, loss 3.3879127502441406, acc=0.05000000074505806, loss=3.3879127502441406
train: epoch 92, loss 2.3357439041137695, acc=0.18272222578525543, loss=2.3357439041137695
test: epoch 92, loss 3.326435089111328, acc=0.06666667014360428, loss=3.326435089111328
train: epoch 93, loss 2.3491251468658447, acc=0.1793888956308365, loss=2.3491251468658447
test: epoch 93, loss 3.2700231075286865, acc=0.06388889253139496, loss=3.2700231075286865
train: epoch 94, loss 2.3299763202667236, acc=0.17666666209697723, loss=2.3299763202667236
test: epoch 94, loss 3.294802665710449, acc=0.0694444477558136, loss=3.294802665710449
train: epoch 95, loss 2.337750196456909, acc=0.17916665971279144, loss=2.337750196456909
test: epoch 95, loss 3.273698568344116, acc=0.06111111119389534, loss=3.273698568344116
train: epoch 96, loss 2.3607053756713867, acc=0.18227778375148773, loss=2.3607053756713867
test: epoch 96, loss 3.237422466278076, acc=0.05277777835726738, loss=3.237422466278076
train: epoch 97, loss 2.33498477935791, acc=0.17588889598846436, loss=2.33498477935791
test: epoch 97, loss 3.2482991218566895, acc=0.0555555559694767, loss=3.2482991218566895
train: epoch 98, loss 2.339125871658325, acc=0.1789444386959076, loss=2.339125871658325
test: epoch 98, loss 3.294461727142334, acc=0.06111111119389534, loss=3.294461727142334
train: epoch 99, loss 2.3516955375671387, acc=0.1787777841091156, loss=2.3516955375671387
test: epoch 99, loss 3.2667243480682373, acc=0.05833333358168602, loss=3.2667243480682373
train: epoch 100, loss 2.3294098377227783, acc=0.18333333730697632, loss=2.3294098377227783
test: epoch 100, loss 3.1604819297790527, acc=0.0694444477558136, loss=3.1604819297790527
train: epoch 101, loss 2.3507766723632812, acc=0.17516666650772095, loss=2.3507766723632812
test: epoch 101, loss 3.312842607498169, acc=0.06666667014360428, loss=3.312842607498169
train: epoch 102, loss 2.3313419818878174, acc=0.18427777290344238, loss=2.3313419818878174
test: epoch 102, loss 3.3105344772338867, acc=0.06111111119389534, loss=3.3105344772338867
train: epoch 103, loss 2.325066089630127, acc=0.18377777934074402, loss=2.325066089630127
test: epoch 103, loss 3.207862377166748, acc=0.0555555559694767, loss=3.207862377166748
train: epoch 104, loss 2.329275608062744, acc=0.18299999833106995, loss=2.329275608062744
test: epoch 104, loss 3.1778957843780518, acc=0.08055555820465088, loss=3.1778957843780518
train: epoch 105, loss 2.331620931625366, acc=0.1817222237586975, loss=2.331620931625366
test: epoch 105, loss 3.22463059425354, acc=0.07500000298023224, loss=3.22463059425354
train: epoch 106, loss 2.3255465030670166, acc=0.18294444680213928, loss=2.3255465030670166
test: epoch 106, loss 3.2526748180389404, acc=0.07222222536802292, loss=3.2526748180389404
train: epoch 107, loss 2.330873727798462, acc=0.18227778375148773, loss=2.330873727798462
test: epoch 107, loss 3.220325231552124, acc=0.06666667014360428, loss=3.220325231552124
train: epoch 108, loss 2.328826904296875, acc=0.18477778136730194, loss=2.328826904296875
test: epoch 108, loss 3.1868226528167725, acc=0.05000000074505806, loss=3.1868226528167725
train: epoch 109, loss 2.3133127689361572, acc=0.18238888680934906, loss=2.3133127689361572
test: epoch 109, loss 3.245681047439575, acc=0.05000000074505806, loss=3.245681047439575
train: epoch 110, loss 2.319662570953369, acc=0.18238888680934906, loss=2.319662570953369
test: epoch 110, loss 3.2074077129364014, acc=0.06388889253139496, loss=3.2074077129364014
train: epoch 111, loss 2.3035082817077637, acc=0.18177777528762817, loss=2.3035082817077637
test: epoch 111, loss 3.206810474395752, acc=0.07222222536802292, loss=3.206810474395752
train: epoch 112, loss 2.3119025230407715, acc=0.18211111426353455, loss=2.3119025230407715
test: epoch 112, loss 3.138857126235962, acc=0.07222222536802292, loss=3.138857126235962
train: epoch 113, loss 2.295539140701294, acc=0.18622222542762756, loss=2.295539140701294
test: epoch 113, loss 3.2906863689422607, acc=0.07500000298023224, loss=3.2906863689422607
train: epoch 114, loss 2.305638313293457, acc=0.18316666781902313, loss=2.305638313293457
test: epoch 114, loss 3.190486431121826, acc=0.06388889253139496, loss=3.190486431121826
train: epoch 115, loss 2.3104779720306396, acc=0.18772222101688385, loss=2.3104779720306396
test: epoch 115, loss 3.213467836380005, acc=0.06388889253139496, loss=3.213467836380005
train: epoch 116, loss 2.3013381958007812, acc=0.1839444488286972, loss=2.3013381958007812
test: epoch 116, loss 3.261927604675293, acc=0.07777778059244156, loss=3.261927604675293
train: epoch 117, loss 2.2990174293518066, acc=0.18950000405311584, loss=2.2990174293518066
test: epoch 117, loss 3.2470414638519287, acc=0.05833333358168602, loss=3.2470414638519287
train: epoch 118, loss 2.3035879135131836, acc=0.18488888442516327, loss=2.3035879135131836
test: epoch 118, loss 3.3333659172058105, acc=0.05833333358168602, loss=3.3333659172058105
train: epoch 119, loss 2.303246021270752, acc=0.18744444847106934, loss=2.303246021270752
test: epoch 119, loss 3.2742984294891357, acc=0.07777778059244156, loss=3.2742984294891357
train: epoch 120, loss 2.3061447143554688, acc=0.1854444444179535, loss=2.3061447143554688
test: epoch 120, loss 3.189654588699341, acc=0.08611111342906952, loss=3.189654588699341
train: epoch 121, loss 2.2916412353515625, acc=0.18977777659893036, loss=2.2916412353515625
test: epoch 121, loss 3.0638508796691895, acc=0.08055555820465088, loss=3.0638508796691895
train: epoch 122, loss 2.3078150749206543, acc=0.18238888680934906, loss=2.3078150749206543
test: epoch 122, loss 3.179628610610962, acc=0.06666667014360428, loss=3.179628610610962
train: epoch 123, loss 2.3086729049682617, acc=0.18505555391311646, loss=2.3086729049682617
test: epoch 123, loss 3.284402847290039, acc=0.0694444477558136, loss=3.284402847290039
train: epoch 124, loss 2.294996976852417, acc=0.19227777421474457, loss=2.294996976852417
test: epoch 124, loss 3.1762661933898926, acc=0.06388889253139496, loss=3.1762661933898926
train: epoch 125, loss 2.286539316177368, acc=0.18827778100967407, loss=2.286539316177368
test: epoch 125, loss 3.226365327835083, acc=0.05833333358168602, loss=3.226365327835083
train: epoch 126, loss 2.290313959121704, acc=0.1904444396495819, loss=2.290313959121704
test: epoch 126, loss 3.2719991207122803, acc=0.06666667014360428, loss=3.2719991207122803
train: epoch 127, loss 2.2891221046447754, acc=0.1886666715145111, loss=2.2891221046447754
test: epoch 127, loss 3.157315492630005, acc=0.05833333358168602, loss=3.157315492630005
train: epoch 128, loss 2.288221836090088, acc=0.1860000044107437, loss=2.288221836090088
test: epoch 128, loss 3.319908380508423, acc=0.05000000074505806, loss=3.319908380508423
train: epoch 129, loss 2.288484811782837, acc=0.18738888204097748, loss=2.288484811782837
test: epoch 129, loss 3.0773675441741943, acc=0.0833333358168602, loss=3.0773675441741943
train: epoch 130, loss 2.2924771308898926, acc=0.19455555081367493, loss=2.2924771308898926
test: epoch 130, loss 3.1502368450164795, acc=0.04722222313284874, loss=3.1502368450164795
train: epoch 131, loss 2.292781352996826, acc=0.18905556201934814, loss=2.292781352996826
test: epoch 131, loss 3.181633472442627, acc=0.07222222536802292, loss=3.181633472442627
train: epoch 132, loss 2.292429208755493, acc=0.19072222709655762, loss=2.292429208755493
test: epoch 132, loss 3.1598587036132812, acc=0.07222222536802292, loss=3.1598587036132812
train: epoch 133, loss 2.26513671875, acc=0.19072222709655762, loss=2.26513671875
test: epoch 133, loss 3.1562914848327637, acc=0.05277777835726738, loss=3.1562914848327637
train: epoch 134, loss 2.289095878601074, acc=0.1951666623353958, loss=2.289095878601074
test: epoch 134, loss 3.216169595718384, acc=0.0694444477558136, loss=3.216169595718384
train: epoch 135, loss 2.278195858001709, acc=0.19216667115688324, loss=2.278195858001709
test: epoch 135, loss 3.2042412757873535, acc=0.0694444477558136, loss=3.2042412757873535
train: epoch 136, loss 2.271512508392334, acc=0.19583334028720856, loss=2.271512508392334
test: epoch 136, loss 3.246066093444824, acc=0.05833333358168602, loss=3.246066093444824
train: epoch 137, loss 2.2515809535980225, acc=0.19388888776302338, loss=2.2515809535980225
test: epoch 137, loss 3.3690876960754395, acc=0.05833333358168602, loss=3.3690876960754395
train: epoch 138, loss 2.2604570388793945, acc=0.19333332777023315, loss=2.2604570388793945
test: epoch 138, loss 3.2229812145233154, acc=0.07222222536802292, loss=3.2229812145233154
train: epoch 139, loss 2.2756447792053223, acc=0.19211110472679138, loss=2.2756447792053223
test: epoch 139, loss 3.147550582885742, acc=0.07777778059244156, loss=3.147550582885742
train: epoch 140, loss 2.2756824493408203, acc=0.19405555725097656, loss=2.2756824493408203
test: epoch 140, loss 3.1283180713653564, acc=0.07222222536802292, loss=3.1283180713653564
train: epoch 141, loss 2.275125503540039, acc=0.19683332741260529, loss=2.275125503540039
test: epoch 141, loss 3.182345390319824, acc=0.07500000298023224, loss=3.182345390319824
train: epoch 142, loss 2.2553937435150146, acc=0.19466666877269745, loss=2.2553937435150146
test: epoch 142, loss 3.159691333770752, acc=0.08055555820465088, loss=3.159691333770752
train: epoch 143, loss 2.267983913421631, acc=0.1991666704416275, loss=2.267983913421631
test: epoch 143, loss 3.2180304527282715, acc=0.07222222536802292, loss=3.2180304527282715
train: epoch 144, loss 2.2795321941375732, acc=0.19077777862548828, loss=2.2795321941375732
test: epoch 144, loss 3.1831254959106445, acc=0.0694444477558136, loss=3.1831254959106445
train: epoch 145, loss 2.260334014892578, acc=0.19411110877990723, loss=2.260334014892578
test: epoch 145, loss 3.1669793128967285, acc=0.05000000074505806, loss=3.1669793128967285
train: epoch 146, loss 2.280752420425415, acc=0.1960555613040924, loss=2.280752420425415
test: epoch 146, loss 3.208083391189575, acc=0.07222222536802292, loss=3.208083391189575
train: epoch 147, loss 2.249514579772949, acc=0.19544444978237152, loss=2.249514579772949
test: epoch 147, loss 3.265338659286499, acc=0.0694444477558136, loss=3.265338659286499
train: epoch 148, loss 2.264085531234741, acc=0.2000555545091629, loss=2.264085531234741
test: epoch 148, loss 3.292720317840576, acc=0.06666667014360428, loss=3.292720317840576
train: epoch 149, loss 2.249361276626587, acc=0.19677777588367462, loss=2.249361276626587
test: epoch 149, loss 3.2087416648864746, acc=0.07222222536802292, loss=3.2087416648864746
train: epoch 150, loss 2.2762610912323, acc=0.19550000131130219, loss=2.2762610912323
test: epoch 150, loss 3.2153642177581787, acc=0.07500000298023224, loss=3.2153642177581787
