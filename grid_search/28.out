# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=1", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=2112520222, receiver_embed_dim=32, save_run=0, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=2112520222, receiver_embed_dim=32, save_run=False, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.4139957427978516, acc=0.0486111119389534, loss=3.4139957427978516
test: epoch 1, loss 4.196805953979492, acc=0.04444444552063942, loss=4.196805953979492
train: epoch 2, loss 2.4811487197875977, acc=0.18272222578525543, loss=2.4811487197875977
test: epoch 2, loss 3.5374772548675537, acc=0.0972222238779068, loss=3.5374772548675537
train: epoch 3, loss 1.8085908889770508, acc=0.30694442987442017, loss=1.8085908889770508
test: epoch 3, loss 3.1447219848632812, acc=0.10555555671453476, loss=3.1447219848632812
train: epoch 4, loss 1.6055610179901123, acc=0.3705555498600006, loss=1.6055610179901123
test: epoch 4, loss 2.984631061553955, acc=0.12222222238779068, loss=2.984631061553955
train: epoch 5, loss 1.4741984605789185, acc=0.4174444377422333, loss=1.4741984605789185
test: epoch 5, loss 2.6251277923583984, acc=0.16944444179534912, loss=2.6251277923583984
train: epoch 6, loss 1.363321304321289, acc=0.46133333444595337, loss=1.363321304321289
test: epoch 6, loss 2.888037919998169, acc=0.1666666716337204, loss=2.888037919998169
train: epoch 7, loss 1.287208080291748, acc=0.4941111207008362, loss=1.287208080291748
test: epoch 7, loss 2.586168050765991, acc=0.20555555820465088, loss=2.586168050765991
train: epoch 8, loss 1.2257790565490723, acc=0.5247222185134888, loss=1.2257790565490723
test: epoch 8, loss 2.537538766860962, acc=0.19166666269302368, loss=2.537538766860962
train: epoch 9, loss 1.1641666889190674, acc=0.5450000166893005, loss=1.1641666889190674
test: epoch 9, loss 2.646040678024292, acc=0.17777778208255768, loss=2.646040678024292
train: epoch 10, loss 1.1023820638656616, acc=0.5734999775886536, loss=1.1023820638656616
test: epoch 10, loss 2.569382905960083, acc=0.20555555820465088, loss=2.569382905960083
train: epoch 11, loss 1.0550315380096436, acc=0.5946111083030701, loss=1.0550315380096436
test: epoch 11, loss 2.5235843658447266, acc=0.21944443881511688, loss=2.5235843658447266
train: epoch 12, loss 1.0234854221343994, acc=0.605222225189209, loss=1.0234854221343994
test: epoch 12, loss 2.582369327545166, acc=0.21388888359069824, loss=2.582369327545166
train: epoch 13, loss 0.9683574438095093, acc=0.6314444541931152, loss=0.9683574438095093
test: epoch 13, loss 2.40602970123291, acc=0.23055554926395416, loss=2.40602970123291
train: epoch 14, loss 0.9394364356994629, acc=0.6434444189071655, loss=0.9394364356994629
test: epoch 14, loss 2.276200294494629, acc=0.25, loss=2.276200294494629
train: epoch 15, loss 0.9017771482467651, acc=0.6587777733802795, loss=0.9017771482467651
test: epoch 15, loss 2.3332271575927734, acc=0.26944443583488464, loss=2.3332271575927734
train: epoch 16, loss 0.8693291544914246, acc=0.6712222099304199, loss=0.8693291544914246
test: epoch 16, loss 2.1710731983184814, acc=0.2527777850627899, loss=2.1710731983184814
train: epoch 17, loss 0.8545684218406677, acc=0.6850000023841858, loss=0.8545684218406677
test: epoch 17, loss 2.21635365486145, acc=0.2944444417953491, loss=2.21635365486145
train: epoch 18, loss 0.8267735838890076, acc=0.6927222013473511, loss=0.8267735838890076
test: epoch 18, loss 2.1370952129364014, acc=0.28333333134651184, loss=2.1370952129364014
train: epoch 19, loss 0.8066243529319763, acc=0.7051666378974915, loss=0.8066243529319763
test: epoch 19, loss 1.990124225616455, acc=0.3027777671813965, loss=1.990124225616455
train: epoch 20, loss 0.7773986458778381, acc=0.7118889093399048, loss=0.7773986458778381
test: epoch 20, loss 2.0600180625915527, acc=0.3166666626930237, loss=2.0600180625915527
train: epoch 21, loss 0.7363288998603821, acc=0.7300000190734863, loss=0.7363288998603821
test: epoch 21, loss 1.806230902671814, acc=0.375, loss=1.806230902671814
train: epoch 22, loss 0.7384369373321533, acc=0.7286111116409302, loss=0.7384369373321533
test: epoch 22, loss 1.9445414543151855, acc=0.32499998807907104, loss=1.9445414543151855
train: epoch 23, loss 0.7163907289505005, acc=0.7377222180366516, loss=0.7163907289505005
test: epoch 23, loss 1.8412657976150513, acc=0.3222222328186035, loss=1.8412657976150513
train: epoch 24, loss 0.6984540820121765, acc=0.7441111207008362, loss=0.6984540820121765
test: epoch 24, loss 1.670967698097229, acc=0.3611111044883728, loss=1.670967698097229
train: epoch 25, loss 0.6787517666816711, acc=0.7505000233650208, loss=0.6787517666816711
test: epoch 25, loss 1.6508293151855469, acc=0.3777777850627899, loss=1.6508293151855469
train: epoch 26, loss 0.6689323782920837, acc=0.7551666498184204, loss=0.6689323782920837
test: epoch 26, loss 1.6346871852874756, acc=0.35555556416511536, loss=1.6346871852874756
train: epoch 27, loss 0.6444163918495178, acc=0.7639999985694885, loss=0.6444163918495178
test: epoch 27, loss 1.7097278833389282, acc=0.3611111044883728, loss=1.7097278833389282
train: epoch 28, loss 0.6370550394058228, acc=0.7728333473205566, loss=0.6370550394058228
test: epoch 28, loss 1.6350619792938232, acc=0.3583333194255829, loss=1.6350619792938232
train: epoch 29, loss 0.6137995719909668, acc=0.7808889150619507, loss=0.6137995719909668
test: epoch 29, loss 1.536839485168457, acc=0.4055555462837219, loss=1.536839485168457
train: epoch 30, loss 0.612510085105896, acc=0.7778333425521851, loss=0.612510085105896
test: epoch 30, loss 1.4963016510009766, acc=0.40833333134651184, loss=1.4963016510009766
train: epoch 31, loss 0.5953083038330078, acc=0.789555549621582, loss=0.5953083038330078
test: epoch 31, loss 1.5672987699508667, acc=0.3916666805744171, loss=1.5672987699508667
train: epoch 32, loss 0.5833626985549927, acc=0.7912222146987915, loss=0.5833626985549927
test: epoch 32, loss 1.5651919841766357, acc=0.3916666805744171, loss=1.5651919841766357
train: epoch 33, loss 0.5693498253822327, acc=0.7942222356796265, loss=0.5693498253822327
test: epoch 33, loss 1.4234592914581299, acc=0.4138889014720917, loss=1.4234592914581299
train: epoch 34, loss 0.5445343852043152, acc=0.8063333630561829, loss=0.5445343852043152
test: epoch 34, loss 1.4262357950210571, acc=0.4305555522441864, loss=1.4262357950210571
train: epoch 35, loss 0.535959780216217, acc=0.8133333325386047, loss=0.535959780216217
test: epoch 35, loss 1.4404528141021729, acc=0.4027777910232544, loss=1.4404528141021729
train: epoch 36, loss 0.5170955657958984, acc=0.8133333325386047, loss=0.5170955657958984
test: epoch 36, loss 1.4822014570236206, acc=0.4333333373069763, loss=1.4822014570236206
train: epoch 37, loss 0.5247085690498352, acc=0.8137221932411194, loss=0.5247085690498352
test: epoch 37, loss 1.4567844867706299, acc=0.43611112236976624, loss=1.4567844867706299
train: epoch 38, loss 0.5029922127723694, acc=0.8194444179534912, loss=0.5029922127723694
test: epoch 38, loss 1.252439022064209, acc=0.46666666865348816, loss=1.252439022064209
train: epoch 39, loss 0.50710129737854, acc=0.8194444179534912, loss=0.50710129737854
test: epoch 39, loss 1.3378735780715942, acc=0.46388888359069824, loss=1.3378735780715942
train: epoch 40, loss 0.49480101466178894, acc=0.8250555396080017, loss=0.49480101466178894
test: epoch 40, loss 1.2823642492294312, acc=0.46666666865348816, loss=1.2823642492294312
train: epoch 41, loss 0.47950857877731323, acc=0.8272777795791626, loss=0.47950857877731323
test: epoch 41, loss 1.3289395570755005, acc=0.45277777314186096, loss=1.3289395570755005
train: epoch 42, loss 0.4586566090583801, acc=0.8351666927337646, loss=0.4586566090583801
test: epoch 42, loss 1.2993074655532837, acc=0.46388888359069824, loss=1.2993074655532837
train: epoch 43, loss 0.45835164189338684, acc=0.8364444375038147, loss=0.45835164189338684
test: epoch 43, loss 1.3380005359649658, acc=0.4555555582046509, loss=1.3380005359649658
train: epoch 44, loss 0.44698724150657654, acc=0.8403888940811157, loss=0.44698724150657654
test: epoch 44, loss 1.309345006942749, acc=0.4472222328186035, loss=1.309345006942749
train: epoch 45, loss 0.4508463144302368, acc=0.8412777781486511, loss=0.4508463144302368
test: epoch 45, loss 1.4109519720077515, acc=0.4694444537162781, loss=1.4109519720077515
train: epoch 46, loss 0.4362334609031677, acc=0.8460555672645569, loss=0.4362334609031677
test: epoch 46, loss 1.3577429056167603, acc=0.4749999940395355, loss=1.3577429056167603
train: epoch 47, loss 0.41655975580215454, acc=0.8491666913032532, loss=0.41655975580215454
test: epoch 47, loss 1.299220085144043, acc=0.4833333194255829, loss=1.299220085144043
train: epoch 48, loss 0.41404563188552856, acc=0.8525555729866028, loss=0.41404563188552856
test: epoch 48, loss 1.2484103441238403, acc=0.4472222328186035, loss=1.2484103441238403
train: epoch 49, loss 0.40667611360549927, acc=0.8567777872085571, loss=0.40667611360549927
test: epoch 49, loss 1.2158364057540894, acc=0.5083333253860474, loss=1.2158364057540894
train: epoch 50, loss 0.40239304304122925, acc=0.8566111326217651, loss=0.40239304304122925
test: epoch 50, loss 1.2160327434539795, acc=0.4833333194255829, loss=1.2160327434539795
train: epoch 51, loss 0.39326855540275574, acc=0.856333315372467, loss=0.39326855540275574
test: epoch 51, loss 1.2766574621200562, acc=0.5027777552604675, loss=1.2766574621200562
train: epoch 52, loss 0.38724663853645325, acc=0.863444447517395, loss=0.38724663853645325
test: epoch 52, loss 1.231099247932434, acc=0.4749999940395355, loss=1.231099247932434
train: epoch 53, loss 0.3743757903575897, acc=0.863277792930603, loss=0.3743757903575897
test: epoch 53, loss 1.1907411813735962, acc=0.5388888716697693, loss=1.1907411813735962
train: epoch 54, loss 0.3745352625846863, acc=0.8673333525657654, loss=0.3745352625846863
test: epoch 54, loss 1.2465786933898926, acc=0.5027777552604675, loss=1.2465786933898926
train: epoch 55, loss 0.36414214968681335, acc=0.8682777881622314, loss=0.36414214968681335
test: epoch 55, loss 1.2328236103057861, acc=0.5222222208976746, loss=1.2328236103057861
train: epoch 56, loss 0.36524108052253723, acc=0.867888867855072, loss=0.36524108052253723
test: epoch 56, loss 1.2553945779800415, acc=0.48055556416511536, loss=1.2553945779800415
train: epoch 57, loss 0.35010161995887756, acc=0.8752222061157227, loss=0.35010161995887756
test: epoch 57, loss 1.092060923576355, acc=0.5361111164093018, loss=1.092060923576355
train: epoch 58, loss 0.35224077105522156, acc=0.8765000104904175, loss=0.35224077105522156
test: epoch 58, loss 1.298612117767334, acc=0.5055555701255798, loss=1.298612117767334
train: epoch 59, loss 0.34049293398857117, acc=0.8769444227218628, loss=0.34049293398857117
test: epoch 59, loss 1.201772689819336, acc=0.5416666865348816, loss=1.201772689819336
train: epoch 60, loss 0.32766661047935486, acc=0.8806111216545105, loss=0.32766661047935486
test: epoch 60, loss 1.2553887367248535, acc=0.5472221970558167, loss=1.2553887367248535
train: epoch 61, loss 0.33203622698783875, acc=0.8804444670677185, loss=0.33203622698783875
test: epoch 61, loss 1.219783067703247, acc=0.5249999761581421, loss=1.219783067703247
train: epoch 62, loss 0.3276134729385376, acc=0.8822222352027893, loss=0.3276134729385376
test: epoch 62, loss 1.2249478101730347, acc=0.5444444417953491, loss=1.2249478101730347
train: epoch 63, loss 0.3344747722148895, acc=0.8813889026641846, loss=0.3344747722148895
test: epoch 63, loss 1.2026915550231934, acc=0.5305555462837219, loss=1.2026915550231934
train: epoch 64, loss 0.31810733675956726, acc=0.8875555396080017, loss=0.31810733675956726
test: epoch 64, loss 1.195175290107727, acc=0.5361111164093018, loss=1.195175290107727
train: epoch 65, loss 0.3226867616176605, acc=0.8845000267028809, loss=0.3226867616176605
test: epoch 65, loss 1.1455949544906616, acc=0.5416666865348816, loss=1.1455949544906616
train: epoch 66, loss 0.3066880404949188, acc=0.8913888931274414, loss=0.3066880404949188
test: epoch 66, loss 1.327855110168457, acc=0.5222222208976746, loss=1.327855110168457
train: epoch 67, loss 0.31207913160324097, acc=0.8885555267333984, loss=0.31207913160324097
test: epoch 67, loss 1.1574729681015015, acc=0.5416666865348816, loss=1.1574729681015015
train: epoch 68, loss 0.31156373023986816, acc=0.8885555267333984, loss=0.31156373023986816
test: epoch 68, loss 1.155174732208252, acc=0.5777778029441833, loss=1.155174732208252
train: epoch 69, loss 0.2985571026802063, acc=0.8920555710792542, loss=0.2985571026802063
test: epoch 69, loss 1.183934211730957, acc=0.5833333134651184, loss=1.183934211730957
train: epoch 70, loss 0.287450909614563, acc=0.894611120223999, loss=0.287450909614563
test: epoch 70, loss 1.1937944889068604, acc=0.5583333373069763, loss=1.1937944889068604
train: epoch 71, loss 0.2956177592277527, acc=0.8923888802528381, loss=0.2956177592277527
test: epoch 71, loss 1.1331425905227661, acc=0.5722222328186035, loss=1.1331425905227661
train: epoch 72, loss 0.2860218584537506, acc=0.8952777981758118, loss=0.2860218584537506
test: epoch 72, loss 1.1672863960266113, acc=0.5638889074325562, loss=1.1672863960266113
train: epoch 73, loss 0.29350435733795166, acc=0.8922222256660461, loss=0.29350435733795166
test: epoch 73, loss 1.1780270338058472, acc=0.574999988079071, loss=1.1780270338058472
train: epoch 74, loss 0.2846278250217438, acc=0.8963333368301392, loss=0.2846278250217438
test: epoch 74, loss 1.097334861755371, acc=0.5916666388511658, loss=1.097334861755371
train: epoch 75, loss 0.2891344130039215, acc=0.8965555429458618, loss=0.2891344130039215
test: epoch 75, loss 1.185744047164917, acc=0.605555534362793, loss=1.185744047164917
train: epoch 76, loss 0.2834155261516571, acc=0.8971666693687439, loss=0.2834155261516571
test: epoch 76, loss 1.2253562211990356, acc=0.5805555582046509, loss=1.2253562211990356
train: epoch 77, loss 0.2767244577407837, acc=0.8971666693687439, loss=0.2767244577407837
test: epoch 77, loss 1.182007074356079, acc=0.5777778029441833, loss=1.182007074356079
train: epoch 78, loss 0.28752022981643677, acc=0.894611120223999, loss=0.28752022981643677
test: epoch 78, loss 1.295497179031372, acc=0.5472221970558167, loss=1.295497179031372
train: epoch 79, loss 0.28692740201950073, acc=0.8980555534362793, loss=0.28692740201950073
test: epoch 79, loss 1.052756428718567, acc=0.5972222089767456, loss=1.052756428718567
train: epoch 80, loss 0.2605401575565338, acc=0.9007777571678162, loss=0.2605401575565338
test: epoch 80, loss 0.9652822017669678, acc=0.6027777791023254, loss=0.9652822017669678
train: epoch 81, loss 0.27517008781433105, acc=0.8989999890327454, loss=0.27517008781433105
test: epoch 81, loss 1.2387398481369019, acc=0.5666666626930237, loss=1.2387398481369019
train: epoch 82, loss 0.2751917243003845, acc=0.8974999785423279, loss=0.2751917243003845
test: epoch 82, loss 1.125502347946167, acc=0.5972222089767456, loss=1.125502347946167
train: epoch 83, loss 0.2554769217967987, acc=0.9051111340522766, loss=0.2554769217967987
test: epoch 83, loss 1.0139787197113037, acc=0.6083333492279053, loss=1.0139787197113037
train: epoch 84, loss 0.27389001846313477, acc=0.9002777934074402, loss=0.27389001846313477
test: epoch 84, loss 0.9863057732582092, acc=0.6111111044883728, loss=0.9863057732582092
train: epoch 85, loss 0.2456112802028656, acc=0.9076111316680908, loss=0.2456112802028656
test: epoch 85, loss 1.0475220680236816, acc=0.625, loss=1.0475220680236816
train: epoch 86, loss 0.27042922377586365, acc=0.8995000123977661, loss=0.27042922377586365
test: epoch 86, loss 1.1575093269348145, acc=0.6194444298744202, loss=1.1575093269348145
train: epoch 87, loss 0.26204946637153625, acc=0.9037777781486511, loss=0.26204946637153625
test: epoch 87, loss 1.069508671760559, acc=0.6305555701255798, loss=1.069508671760559
train: epoch 88, loss 0.25307634472846985, acc=0.9049444198608398, loss=0.25307634472846985
test: epoch 88, loss 0.9893958568572998, acc=0.6388888955116272, loss=0.9893958568572998
train: epoch 89, loss 0.2609579563140869, acc=0.9045555591583252, loss=0.2609579563140869
test: epoch 89, loss 0.9462835192680359, acc=0.644444465637207, loss=0.9462835192680359
train: epoch 90, loss 0.25609737634658813, acc=0.9063888788223267, loss=0.25609737634658813
test: epoch 90, loss 0.9784898161888123, acc=0.6361111402511597, loss=0.9784898161888123
train: epoch 91, loss 0.2471066117286682, acc=0.9067222476005554, loss=0.2471066117286682
test: epoch 91, loss 1.0244618654251099, acc=0.6388888955116272, loss=1.0244618654251099
train: epoch 92, loss 0.25762903690338135, acc=0.9039444327354431, loss=0.25762903690338135
test: epoch 92, loss 0.9291162490844727, acc=0.6638888716697693, loss=0.9291162490844727
train: epoch 93, loss 0.2529152035713196, acc=0.9067777991294861, loss=0.2529152035713196
test: epoch 93, loss 1.0089669227600098, acc=0.6583333611488342, loss=1.0089669227600098
train: epoch 94, loss 0.24440541863441467, acc=0.9087222218513489, loss=0.24440541863441467
test: epoch 94, loss 0.89699786901474, acc=0.625, loss=0.89699786901474
train: epoch 95, loss 0.25259727239608765, acc=0.9056666493415833, loss=0.25259727239608765
test: epoch 95, loss 0.8868057727813721, acc=0.6916666626930237, loss=0.8868057727813721
train: epoch 96, loss 0.2527625262737274, acc=0.9068333506584167, loss=0.2527625262737274
test: epoch 96, loss 0.8939650058746338, acc=0.7027778029441833, loss=0.8939650058746338
train: epoch 97, loss 0.2510192394256592, acc=0.9068889021873474, loss=0.2510192394256592
test: epoch 97, loss 0.9521772265434265, acc=0.6833333373069763, loss=0.9521772265434265
train: epoch 98, loss 0.2506512999534607, acc=0.9098888635635376, loss=0.2506512999534607
test: epoch 98, loss 0.9448447823524475, acc=0.6833333373069763, loss=0.9448447823524475
train: epoch 99, loss 0.24105989933013916, acc=0.9090555310249329, loss=0.24105989933013916
test: epoch 99, loss 1.0459305047988892, acc=0.6777777671813965, loss=1.0459305047988892
train: epoch 100, loss 0.2361980378627777, acc=0.9107778072357178, loss=0.2361980378627777
test: epoch 100, loss 0.8236541748046875, acc=0.7111111283302307, loss=0.8236541748046875
train: epoch 101, loss 0.2435208261013031, acc=0.9100000262260437, loss=0.2435208261013031
test: epoch 101, loss 0.8839313983917236, acc=0.6694444417953491, loss=0.8839313983917236
train: epoch 102, loss 0.24110756814479828, acc=0.9117777943611145, loss=0.24110756814479828
test: epoch 102, loss 0.88539057970047, acc=0.6833333373069763, loss=0.88539057970047
train: epoch 103, loss 0.24274283647537231, acc=0.9111666679382324, loss=0.24274283647537231
test: epoch 103, loss 0.8499885201454163, acc=0.6888889074325562, loss=0.8499885201454163
train: epoch 104, loss 0.2457619160413742, acc=0.9101666808128357, loss=0.2457619160413742
test: epoch 104, loss 0.8260638117790222, acc=0.6944444179534912, loss=0.8260638117790222
train: epoch 105, loss 0.24701079726219177, acc=0.9115555286407471, loss=0.24701079726219177
test: epoch 105, loss 0.8445500135421753, acc=0.699999988079071, loss=0.8445500135421753
train: epoch 106, loss 0.24107344448566437, acc=0.9096666574478149, loss=0.24107344448566437
test: epoch 106, loss 0.8336080312728882, acc=0.6833333373069763, loss=0.8336080312728882
train: epoch 107, loss 0.22504694759845734, acc=0.9147777557373047, loss=0.22504694759845734
test: epoch 107, loss 0.8872517347335815, acc=0.7083333134651184, loss=0.8872517347335815
train: epoch 108, loss 0.23395033180713654, acc=0.9128888845443726, loss=0.23395033180713654
test: epoch 108, loss 0.8229261636734009, acc=0.7138888835906982, loss=0.8229261636734009
train: epoch 109, loss 0.24140049517154694, acc=0.9115555286407471, loss=0.24140049517154694
test: epoch 109, loss 0.7808805108070374, acc=0.7194444537162781, loss=0.7808805108070374
train: epoch 110, loss 0.22745846211910248, acc=0.9148333072662354, loss=0.22745846211910248
test: epoch 110, loss 0.8352722525596619, acc=0.7166666388511658, loss=0.8352722525596619
train: epoch 111, loss 0.2366112470626831, acc=0.9114999771118164, loss=0.2366112470626831
test: epoch 111, loss 0.7479646801948547, acc=0.7222222089767456, loss=0.7479646801948547
train: epoch 112, loss 0.23566557466983795, acc=0.9135000109672546, loss=0.23566557466983795
test: epoch 112, loss 0.8179784417152405, acc=0.7222222089767456, loss=0.8179784417152405
train: epoch 113, loss 0.23426486551761627, acc=0.9142777919769287, loss=0.23426486551761627
test: epoch 113, loss 0.7066463828086853, acc=0.7333333492279053, loss=0.7066463828086853
train: epoch 114, loss 0.2267063707113266, acc=0.914722204208374, loss=0.2267063707113266
test: epoch 114, loss 0.6919217109680176, acc=0.7333333492279053, loss=0.6919217109680176
train: epoch 115, loss 0.2275414764881134, acc=0.9162777662277222, loss=0.2275414764881134
test: epoch 115, loss 0.7924354076385498, acc=0.7555555701255798, loss=0.7924354076385498
train: epoch 116, loss 0.2274169772863388, acc=0.9154999852180481, loss=0.2274169772863388
test: epoch 116, loss 0.7609553337097168, acc=0.7555555701255798, loss=0.7609553337097168
train: epoch 117, loss 0.22878025472164154, acc=0.917888879776001, loss=0.22878025472164154
test: epoch 117, loss 0.7392162680625916, acc=0.75, loss=0.7392162680625916
train: epoch 118, loss 0.23332542181015015, acc=0.9157778024673462, loss=0.23332542181015015
test: epoch 118, loss 0.6954861283302307, acc=0.7583333253860474, loss=0.6954861283302307
train: epoch 119, loss 0.21766918897628784, acc=0.9197221994400024, loss=0.21766918897628784
test: epoch 119, loss 0.7230324149131775, acc=0.7333333492279053, loss=0.7230324149131775
train: epoch 120, loss 0.2249256819486618, acc=0.9192777872085571, loss=0.2249256819486618
test: epoch 120, loss 0.6102204918861389, acc=0.7611111402511597, loss=0.6102204918861389
train: epoch 121, loss 0.21551164984703064, acc=0.9184444546699524, loss=0.21551164984703064
test: epoch 121, loss 0.6080715656280518, acc=0.7666666507720947, loss=0.6080715656280518
train: epoch 122, loss 0.21737737953662872, acc=0.9193333387374878, loss=0.21737737953662872
test: epoch 122, loss 0.7072921395301819, acc=0.7722222208976746, loss=0.7072921395301819
train: epoch 123, loss 0.21628274023532867, acc=0.9208889007568359, loss=0.21628274023532867
test: epoch 123, loss 0.6461449861526489, acc=0.7666666507720947, loss=0.6461449861526489
train: epoch 124, loss 0.2113773226737976, acc=0.9222777485847473, loss=0.2113773226737976
test: epoch 124, loss 0.7363424897193909, acc=0.7666666507720947, loss=0.7363424897193909
train: epoch 125, loss 0.2103157639503479, acc=0.9213333129882812, loss=0.2103157639503479
test: epoch 125, loss 0.6966655254364014, acc=0.7722222208976746, loss=0.6966655254364014
train: epoch 126, loss 0.22611074149608612, acc=0.918666660785675, loss=0.22611074149608612
test: epoch 126, loss 0.6512690186500549, acc=0.7722222208976746, loss=0.6512690186500549
train: epoch 127, loss 0.21822863817214966, acc=0.9201666712760925, loss=0.21822863817214966
test: epoch 127, loss 0.6255238056182861, acc=0.7611111402511597, loss=0.6255238056182861
train: epoch 128, loss 0.2061288207769394, acc=0.9225000143051147, loss=0.2061288207769394
test: epoch 128, loss 0.6677526235580444, acc=0.7555555701255798, loss=0.6677526235580444
train: epoch 129, loss 0.2128571718931198, acc=0.9209444522857666, loss=0.2128571718931198
test: epoch 129, loss 0.5964005589485168, acc=0.7805555462837219, loss=0.5964005589485168
train: epoch 130, loss 0.2079598754644394, acc=0.921833336353302, loss=0.2079598754644394
test: epoch 130, loss 0.6270670294761658, acc=0.7888888716697693, loss=0.6270670294761658
train: epoch 131, loss 0.2154187262058258, acc=0.9204999804496765, loss=0.2154187262058258
test: epoch 131, loss 0.6665455102920532, acc=0.7805555462837219, loss=0.6665455102920532
train: epoch 132, loss 0.21548138558864594, acc=0.9211111068725586, loss=0.21548138558864594
test: epoch 132, loss 0.7265405058860779, acc=0.7861111164093018, loss=0.7265405058860779
train: epoch 133, loss 0.21188059449195862, acc=0.9198333621025085, loss=0.21188059449195862
test: epoch 133, loss 0.650468111038208, acc=0.7722222208976746, loss=0.650468111038208
train: epoch 134, loss 0.20551177859306335, acc=0.9211666584014893, loss=0.20551177859306335
test: epoch 134, loss 0.748863935470581, acc=0.7722222208976746, loss=0.748863935470581
train: epoch 135, loss 0.22116556763648987, acc=0.9187777638435364, loss=0.22116556763648987
test: epoch 135, loss 0.6177825331687927, acc=0.7944444417953491, loss=0.6177825331687927
train: epoch 136, loss 0.2154291868209839, acc=0.918666660785675, loss=0.2154291868209839
test: epoch 136, loss 0.5874240398406982, acc=0.7805555462837219, loss=0.5874240398406982
train: epoch 137, loss 0.21161937713623047, acc=0.9211666584014893, loss=0.21161937713623047
test: epoch 137, loss 0.6077537536621094, acc=0.7888888716697693, loss=0.6077537536621094
train: epoch 138, loss 0.21426013112068176, acc=0.9193333387374878, loss=0.21426013112068176
test: epoch 138, loss 0.5821839570999146, acc=0.7888888716697693, loss=0.5821839570999146
train: epoch 139, loss 0.20655909180641174, acc=0.9219444394111633, loss=0.20655909180641174
test: epoch 139, loss 0.5760266780853271, acc=0.7861111164093018, loss=0.5760266780853271
train: epoch 140, loss 0.22185975313186646, acc=0.9198333621025085, loss=0.22185975313186646
test: epoch 140, loss 0.6674588918685913, acc=0.7944444417953491, loss=0.6674588918685913
train: epoch 141, loss 0.20197223126888275, acc=0.9213888645172119, loss=0.20197223126888275
test: epoch 141, loss 0.6236971616744995, acc=0.7888888716697693, loss=0.6236971616744995
train: epoch 142, loss 0.2113783359527588, acc=0.9227777719497681, loss=0.2113783359527588
test: epoch 142, loss 0.6123349666595459, acc=0.800000011920929, loss=0.6123349666595459
train: epoch 143, loss 0.21480345726013184, acc=0.9211111068725586, loss=0.21480345726013184
test: epoch 143, loss 0.6207733750343323, acc=0.7888888716697693, loss=0.6207733750343323
train: epoch 144, loss 0.19276215136051178, acc=0.9247778058052063, loss=0.19276215136051178
test: epoch 144, loss 0.6549816131591797, acc=0.7944444417953491, loss=0.6549816131591797
train: epoch 145, loss 0.21427369117736816, acc=0.9199444651603699, loss=0.21427369117736816
test: epoch 145, loss 0.6161119341850281, acc=0.7749999761581421, loss=0.6161119341850281
train: epoch 146, loss 0.19580277800559998, acc=0.925944447517395, loss=0.19580277800559998
test: epoch 146, loss 0.5700476765632629, acc=0.7972221970558167, loss=0.5700476765632629
train: epoch 147, loss 0.19857363402843475, acc=0.925000011920929, loss=0.19857363402843475
test: epoch 147, loss 0.5772882103919983, acc=0.800000011920929, loss=0.5772882103919983
train: epoch 148, loss 0.20272187888622284, acc=0.9217222332954407, loss=0.20272187888622284
test: epoch 148, loss 0.5378829836845398, acc=0.800000011920929, loss=0.5378829836845398
train: epoch 149, loss 0.20847053825855255, acc=0.925777792930603, loss=0.20847053825855255
test: epoch 149, loss 0.623636782169342, acc=0.7916666865348816, loss=0.623636782169342
train: epoch 150, loss 0.1970667988061905, acc=0.9258888959884644, loss=0.1970667988061905
test: epoch 150, loss 0.5838454365730286, acc=0.7888888716697693, loss=0.5838454365730286
