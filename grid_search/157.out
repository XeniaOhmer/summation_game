# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=2.0", "--temp_decay=0.99", "--one_hot=0", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=2092576099, receiver_embed_dim=128, save_run=0, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=2092576099, receiver_embed_dim=128, save_run=False, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.347651243209839, acc=0.16861110925674438, loss=2.347651243209839
test: epoch 1, loss 6.077949047088623, acc=0.05833333358168602, loss=6.077949047088623
train: epoch 2, loss 1.776118278503418, acc=0.29350000619888306, loss=1.776118278503418
test: epoch 2, loss 6.008230209350586, acc=0.07500000298023224, loss=6.008230209350586
train: epoch 3, loss 1.5842996835708618, acc=0.3457777798175812, loss=1.5842996835708618
test: epoch 3, loss 6.5711188316345215, acc=0.06111111119389534, loss=6.5711188316345215
train: epoch 4, loss 1.4623183012008667, acc=0.3949444591999054, loss=1.4623183012008667
test: epoch 4, loss 4.953426837921143, acc=0.09444444626569748, loss=4.953426837921143
train: epoch 5, loss 1.3805421590805054, acc=0.43744444847106934, loss=1.3805421590805054
test: epoch 5, loss 5.048341274261475, acc=0.0972222238779068, loss=5.048341274261475
train: epoch 6, loss 1.2908843755722046, acc=0.46833333373069763, loss=1.2908843755722046
test: epoch 6, loss 5.3155927658081055, acc=0.12777778506278992, loss=5.3155927658081055
train: epoch 7, loss 1.2191383838653564, acc=0.4974444508552551, loss=1.2191383838653564
test: epoch 7, loss 4.813950538635254, acc=0.06111111119389534, loss=4.813950538635254
train: epoch 8, loss 1.1714726686477661, acc=0.5236111283302307, loss=1.1714726686477661
test: epoch 8, loss 3.9810750484466553, acc=0.12777778506278992, loss=3.9810750484466553
train: epoch 9, loss 1.146491527557373, acc=0.5378333330154419, loss=1.146491527557373
test: epoch 9, loss 4.433969497680664, acc=0.05833333358168602, loss=4.433969497680664
train: epoch 10, loss 1.081776738166809, acc=0.5646111369132996, loss=1.081776738166809
test: epoch 10, loss 4.856018543243408, acc=0.1111111119389534, loss=4.856018543243408
train: epoch 11, loss 1.045845627784729, acc=0.5842221975326538, loss=1.045845627784729
test: epoch 11, loss 4.175188064575195, acc=0.14444445073604584, loss=4.175188064575195
train: epoch 12, loss 1.0160558223724365, acc=0.5982221961021423, loss=1.0160558223724365
test: epoch 12, loss 4.275748252868652, acc=0.11388888955116272, loss=4.275748252868652
train: epoch 13, loss 0.9749456644058228, acc=0.6102222204208374, loss=0.9749456644058228
test: epoch 13, loss 4.201228141784668, acc=0.10000000149011612, loss=4.201228141784668
train: epoch 14, loss 0.9574238061904907, acc=0.6192222237586975, loss=0.9574238061904907
test: epoch 14, loss 4.497835159301758, acc=0.125, loss=4.497835159301758
train: epoch 15, loss 0.9248607754707336, acc=0.6318888664245605, loss=0.9248607754707336
test: epoch 15, loss 4.655457496643066, acc=0.12777778506278992, loss=4.655457496643066
train: epoch 16, loss 0.9414578676223755, acc=0.6244999766349792, loss=0.9414578676223755
test: epoch 16, loss 3.9833130836486816, acc=0.0972222238779068, loss=3.9833130836486816
train: epoch 17, loss 0.9140872359275818, acc=0.6424999833106995, loss=0.9140872359275818
test: epoch 17, loss 4.738376140594482, acc=0.10555555671453476, loss=4.738376140594482
train: epoch 18, loss 0.8840488195419312, acc=0.6527777910232544, loss=0.8840488195419312
test: epoch 18, loss 3.6096673011779785, acc=0.0972222238779068, loss=3.6096673011779785
train: epoch 19, loss 0.8665440678596497, acc=0.6595555543899536, loss=0.8665440678596497
test: epoch 19, loss 4.088412284851074, acc=0.12777778506278992, loss=4.088412284851074
train: epoch 20, loss 0.8536604046821594, acc=0.6702777743339539, loss=0.8536604046821594
test: epoch 20, loss 3.926272392272949, acc=0.0972222238779068, loss=3.926272392272949
train: epoch 21, loss 0.8457227349281311, acc=0.6738333106040955, loss=0.8457227349281311
test: epoch 21, loss 3.9903347492218018, acc=0.12222222238779068, loss=3.9903347492218018
train: epoch 22, loss 0.820566713809967, acc=0.6823889017105103, loss=0.820566713809967
test: epoch 22, loss 3.995939254760742, acc=0.08611111342906952, loss=3.995939254760742
train: epoch 23, loss 0.84440016746521, acc=0.67166668176651, loss=0.84440016746521
test: epoch 23, loss 3.054616928100586, acc=0.16111111640930176, loss=3.054616928100586
train: epoch 24, loss 0.8166950345039368, acc=0.6822777986526489, loss=0.8166950345039368
test: epoch 24, loss 3.143361806869507, acc=0.18333333730697632, loss=3.143361806869507
train: epoch 25, loss 0.8055964112281799, acc=0.6888333559036255, loss=0.8055964112281799
test: epoch 25, loss 3.135186195373535, acc=0.20000000298023224, loss=3.135186195373535
train: epoch 26, loss 0.8043045401573181, acc=0.6909999847412109, loss=0.8043045401573181
test: epoch 26, loss 3.2081246376037598, acc=0.12777778506278992, loss=3.2081246376037598
train: epoch 27, loss 0.8000696301460266, acc=0.6929444670677185, loss=0.8000696301460266
test: epoch 27, loss 2.604156494140625, acc=0.17222222685813904, loss=2.604156494140625
train: epoch 28, loss 0.775442361831665, acc=0.6999444365501404, loss=0.775442361831665
test: epoch 28, loss 2.9408557415008545, acc=0.21666666865348816, loss=2.9408557415008545
train: epoch 29, loss 0.7954596281051636, acc=0.6987777948379517, loss=0.7954596281051636
test: epoch 29, loss 3.4489946365356445, acc=0.1388888955116272, loss=3.4489946365356445
train: epoch 30, loss 0.7717333436012268, acc=0.7055555582046509, loss=0.7717333436012268
test: epoch 30, loss 3.1521053314208984, acc=0.19166666269302368, loss=3.1521053314208984
train: epoch 31, loss 0.7837526798248291, acc=0.6965000033378601, loss=0.7837526798248291
test: epoch 31, loss 2.9774363040924072, acc=0.23333333432674408, loss=2.9774363040924072
train: epoch 32, loss 0.7714313864707947, acc=0.7017777562141418, loss=0.7714313864707947
test: epoch 32, loss 3.0771546363830566, acc=0.1944444477558136, loss=3.0771546363830566
train: epoch 33, loss 0.7761364579200745, acc=0.7013888955116272, loss=0.7761364579200745
test: epoch 33, loss 3.787668228149414, acc=0.1527777761220932, loss=3.787668228149414
train: epoch 34, loss 0.7844054102897644, acc=0.7007222175598145, loss=0.7844054102897644
test: epoch 34, loss 2.6115610599517822, acc=0.21111111342906952, loss=2.6115610599517822
train: epoch 35, loss 0.7720264196395874, acc=0.7092221975326538, loss=0.7720264196395874
test: epoch 35, loss 2.3635787963867188, acc=0.23888888955116272, loss=2.3635787963867188
train: epoch 36, loss 0.7743920683860779, acc=0.7082222104072571, loss=0.7743920683860779
test: epoch 36, loss 2.8955206871032715, acc=0.20277777314186096, loss=2.8955206871032715
train: epoch 37, loss 0.7671465277671814, acc=0.7050555348396301, loss=0.7671465277671814
test: epoch 37, loss 2.7917540073394775, acc=0.17222222685813904, loss=2.7917540073394775
train: epoch 38, loss 0.7773571014404297, acc=0.7008333206176758, loss=0.7773571014404297
test: epoch 38, loss 2.420191764831543, acc=0.17499999701976776, loss=2.420191764831543
train: epoch 39, loss 0.7529722452163696, acc=0.7160000205039978, loss=0.7529722452163696
test: epoch 39, loss 2.8189713954925537, acc=0.14444445073604584, loss=2.8189713954925537
train: epoch 40, loss 0.7465470433235168, acc=0.7079444527626038, loss=0.7465470433235168
test: epoch 40, loss 2.5038228034973145, acc=0.21111111342906952, loss=2.5038228034973145
train: epoch 41, loss 0.7690649628639221, acc=0.7043889164924622, loss=0.7690649628639221
test: epoch 41, loss 3.566936731338501, acc=0.15000000596046448, loss=3.566936731338501
train: epoch 42, loss 0.7726401686668396, acc=0.7051666378974915, loss=0.7726401686668396
test: epoch 42, loss 2.972949981689453, acc=0.14444445073604584, loss=2.972949981689453
train: epoch 43, loss 0.7518885731697083, acc=0.7108888626098633, loss=0.7518885731697083
test: epoch 43, loss 2.450211763381958, acc=0.1527777761220932, loss=2.450211763381958
train: epoch 44, loss 0.7466861009597778, acc=0.7136666774749756, loss=0.7466861009597778
test: epoch 44, loss 2.9274258613586426, acc=0.19166666269302368, loss=2.9274258613586426
train: epoch 45, loss 0.7573727369308472, acc=0.7055555582046509, loss=0.7573727369308472
test: epoch 45, loss 2.4008400440216064, acc=0.21944443881511688, loss=2.4008400440216064
train: epoch 46, loss 0.7466692328453064, acc=0.7120000123977661, loss=0.7466692328453064
test: epoch 46, loss 2.153275489807129, acc=0.2611111104488373, loss=2.153275489807129
train: epoch 47, loss 0.7345201969146729, acc=0.7191666960716248, loss=0.7345201969146729
test: epoch 47, loss 2.038168430328369, acc=0.16944444179534912, loss=2.038168430328369
train: epoch 48, loss 0.7365232110023499, acc=0.7123333215713501, loss=0.7365232110023499
test: epoch 48, loss 2.7883565425872803, acc=0.25, loss=2.7883565425872803
train: epoch 49, loss 0.7361775040626526, acc=0.714555561542511, loss=0.7361775040626526
test: epoch 49, loss 2.024512767791748, acc=0.25555557012557983, loss=2.024512767791748
train: epoch 50, loss 0.7108349800109863, acc=0.7252222299575806, loss=0.7108349800109863
test: epoch 50, loss 2.36586856842041, acc=0.1944444477558136, loss=2.36586856842041
train: epoch 51, loss 0.7389200925827026, acc=0.7156111001968384, loss=0.7389200925827026
test: epoch 51, loss 1.938056468963623, acc=0.3083333373069763, loss=1.938056468963623
train: epoch 52, loss 0.7349839806556702, acc=0.7191110849380493, loss=0.7349839806556702
test: epoch 52, loss 2.3235044479370117, acc=0.23055554926395416, loss=2.3235044479370117
train: epoch 53, loss 0.7371625304222107, acc=0.7153888940811157, loss=0.7371625304222107
test: epoch 53, loss 2.1448781490325928, acc=0.3194444477558136, loss=2.1448781490325928
train: epoch 54, loss 0.7457560896873474, acc=0.7095555663108826, loss=0.7457560896873474
test: epoch 54, loss 2.2452917098999023, acc=0.18888889253139496, loss=2.2452917098999023
train: epoch 55, loss 0.7460628151893616, acc=0.7093333601951599, loss=0.7460628151893616
test: epoch 55, loss 2.009347915649414, acc=0.25, loss=2.009347915649414
train: epoch 56, loss 0.7773644328117371, acc=0.7020555734634399, loss=0.7773644328117371
test: epoch 56, loss 1.907365322113037, acc=0.32777777314186096, loss=1.907365322113037
train: epoch 57, loss 0.7289641499519348, acc=0.7105000019073486, loss=0.7289641499519348
test: epoch 57, loss 2.1679370403289795, acc=0.3361110985279083, loss=2.1679370403289795
train: epoch 58, loss 0.7386243939399719, acc=0.7164999842643738, loss=0.7386243939399719
test: epoch 58, loss 2.8823981285095215, acc=0.21944443881511688, loss=2.8823981285095215
train: epoch 59, loss 0.7536020874977112, acc=0.7096666693687439, loss=0.7536020874977112
test: epoch 59, loss 2.1332340240478516, acc=0.26944443583488464, loss=2.1332340240478516
train: epoch 60, loss 0.7692180871963501, acc=0.6994444727897644, loss=0.7692180871963501
test: epoch 60, loss 1.8516736030578613, acc=0.24444444477558136, loss=1.8516736030578613
train: epoch 61, loss 0.752463161945343, acc=0.7064444422721863, loss=0.752463161945343
test: epoch 61, loss 2.360889196395874, acc=0.2944444417953491, loss=2.360889196395874
train: epoch 62, loss 0.7530841827392578, acc=0.7077222466468811, loss=0.7530841827392578
test: epoch 62, loss 2.604179620742798, acc=0.2638888955116272, loss=2.604179620742798
train: epoch 63, loss 0.7313491106033325, acc=0.7111666798591614, loss=0.7313491106033325
test: epoch 63, loss 1.8466919660568237, acc=0.2805555462837219, loss=1.8466919660568237
train: epoch 64, loss 0.7331337928771973, acc=0.7103888988494873, loss=0.7331337928771973
test: epoch 64, loss 2.136319398880005, acc=0.23333333432674408, loss=2.136319398880005
train: epoch 65, loss 0.7263990044593811, acc=0.7143333554267883, loss=0.7263990044593811
test: epoch 65, loss 2.0587058067321777, acc=0.19722221791744232, loss=2.0587058067321777
train: epoch 66, loss 0.7486052513122559, acc=0.7046666741371155, loss=0.7486052513122559
test: epoch 66, loss 1.8145626783370972, acc=0.31388887763023376, loss=1.8145626783370972
train: epoch 67, loss 0.7292805910110474, acc=0.7152777910232544, loss=0.7292805910110474
test: epoch 67, loss 2.1013851165771484, acc=0.3055555522441864, loss=2.1013851165771484
train: epoch 68, loss 0.7145699262619019, acc=0.7181666493415833, loss=0.7145699262619019
test: epoch 68, loss 2.0590145587921143, acc=0.3916666805744171, loss=2.0590145587921143
train: epoch 69, loss 0.7587373852729797, acc=0.6997222304344177, loss=0.7587373852729797
test: epoch 69, loss 1.8424391746520996, acc=0.32499998807907104, loss=1.8424391746520996
train: epoch 70, loss 0.7221570611000061, acc=0.7146111130714417, loss=0.7221570611000061
test: epoch 70, loss 1.8721812963485718, acc=0.3166666626930237, loss=1.8721812963485718
train: epoch 71, loss 0.7224818468093872, acc=0.710777759552002, loss=0.7224818468093872
test: epoch 71, loss 2.2189934253692627, acc=0.2361111044883728, loss=2.2189934253692627
train: epoch 72, loss 0.734153151512146, acc=0.711722195148468, loss=0.734153151512146
test: epoch 72, loss 2.0390465259552, acc=0.31388887763023376, loss=2.0390465259552
train: epoch 73, loss 0.7349710464477539, acc=0.7067777514457703, loss=0.7349710464477539
test: epoch 73, loss 1.5437395572662354, acc=0.41111111640930176, loss=1.5437395572662354
train: epoch 74, loss 0.7249193787574768, acc=0.711222231388092, loss=0.7249193787574768
test: epoch 74, loss 1.7419732809066772, acc=0.3722222149372101, loss=1.7419732809066772
train: epoch 75, loss 0.7277393341064453, acc=0.710444450378418, loss=0.7277393341064453
test: epoch 75, loss 2.1696624755859375, acc=0.28611111640930176, loss=2.1696624755859375
train: epoch 76, loss 0.7418099045753479, acc=0.7026110887527466, loss=0.7418099045753479
test: epoch 76, loss 2.234048843383789, acc=0.25555557012557983, loss=2.234048843383789
train: epoch 77, loss 0.7159385085105896, acc=0.7129999995231628, loss=0.7159385085105896
test: epoch 77, loss 2.0784318447113037, acc=0.3166666626930237, loss=2.0784318447113037
train: epoch 78, loss 0.7259922027587891, acc=0.7095000147819519, loss=0.7259922027587891
test: epoch 78, loss 1.7382296323776245, acc=0.3305555582046509, loss=1.7382296323776245
train: epoch 79, loss 0.714616060256958, acc=0.7150555849075317, loss=0.714616060256958
test: epoch 79, loss 1.7122657299041748, acc=0.3722222149372101, loss=1.7122657299041748
train: epoch 80, loss 0.7304165959358215, acc=0.7062222361564636, loss=0.7304165959358215
test: epoch 80, loss 1.6811391115188599, acc=0.3194444477558136, loss=1.6811391115188599
train: epoch 81, loss 0.7428897619247437, acc=0.7057222127914429, loss=0.7428897619247437
test: epoch 81, loss 1.483933687210083, acc=0.42500001192092896, loss=1.483933687210083
train: epoch 82, loss 0.7389947772026062, acc=0.7062777876853943, loss=0.7389947772026062
test: epoch 82, loss 1.8592685461044312, acc=0.39444443583488464, loss=1.8592685461044312
train: epoch 83, loss 0.7244988679885864, acc=0.7096666693687439, loss=0.7244988679885864
test: epoch 83, loss 2.1075236797332764, acc=0.29722222685813904, loss=2.1075236797332764
train: epoch 84, loss 0.7371425032615662, acc=0.7050555348396301, loss=0.7371425032615662
test: epoch 84, loss 1.4748711585998535, acc=0.42222222685813904, loss=1.4748711585998535
train: epoch 85, loss 0.7275742292404175, acc=0.7045000195503235, loss=0.7275742292404175
test: epoch 85, loss 1.8701019287109375, acc=0.3638888895511627, loss=1.8701019287109375
train: epoch 86, loss 0.7392516732215881, acc=0.7053889036178589, loss=0.7392516732215881
test: epoch 86, loss 1.7158833742141724, acc=0.32499998807907104, loss=1.7158833742141724
train: epoch 87, loss 0.7505194544792175, acc=0.7006111145019531, loss=0.7505194544792175
test: epoch 87, loss 1.6749542951583862, acc=0.39444443583488464, loss=1.6749542951583862
train: epoch 88, loss 0.7493771910667419, acc=0.6986111402511597, loss=0.7493771910667419
test: epoch 88, loss 1.4437607526779175, acc=0.4138889014720917, loss=1.4437607526779175
train: epoch 89, loss 0.7183710336685181, acc=0.7142221927642822, loss=0.7183710336685181
test: epoch 89, loss 1.334609031677246, acc=0.40833333134651184, loss=1.334609031677246
train: epoch 90, loss 0.7196997404098511, acc=0.7076666951179504, loss=0.7196997404098511
test: epoch 90, loss 1.6953654289245605, acc=0.3861111104488373, loss=1.6953654289245605
train: epoch 91, loss 0.7296253442764282, acc=0.7036666870117188, loss=0.7296253442764282
test: epoch 91, loss 1.4004019498825073, acc=0.39444443583488464, loss=1.4004019498825073
train: epoch 92, loss 0.7335744500160217, acc=0.7030555605888367, loss=0.7335744500160217
test: epoch 92, loss 1.421449065208435, acc=0.40833333134651184, loss=1.421449065208435
train: epoch 93, loss 0.7383129596710205, acc=0.7036666870117188, loss=0.7383129596710205
test: epoch 93, loss 1.4590885639190674, acc=0.43611112236976624, loss=1.4590885639190674
train: epoch 94, loss 0.7167865037918091, acc=0.7160000205039978, loss=0.7167865037918091
test: epoch 94, loss 1.6052212715148926, acc=0.3861111104488373, loss=1.6052212715148926
train: epoch 95, loss 0.7507890462875366, acc=0.69605553150177, loss=0.7507890462875366
test: epoch 95, loss 1.5117672681808472, acc=0.4027777910232544, loss=1.5117672681808472
train: epoch 96, loss 0.7446191310882568, acc=0.699999988079071, loss=0.7446191310882568
test: epoch 96, loss 1.3598483800888062, acc=0.5055555701255798, loss=1.3598483800888062
train: epoch 97, loss 0.7475319504737854, acc=0.7007222175598145, loss=0.7475319504737854
test: epoch 97, loss 1.866241693496704, acc=0.3444444537162781, loss=1.866241693496704
train: epoch 98, loss 0.7304099798202515, acc=0.7019444704055786, loss=0.7304099798202515
test: epoch 98, loss 1.3751381635665894, acc=0.4277777671813965, loss=1.3751381635665894
train: epoch 99, loss 0.7396757006645203, acc=0.6967777609825134, loss=0.7396757006645203
test: epoch 99, loss 1.3552542924880981, acc=0.3583333194255829, loss=1.3552542924880981
train: epoch 100, loss 0.7325993776321411, acc=0.7066110968589783, loss=0.7325993776321411
test: epoch 100, loss 1.4351609945297241, acc=0.3888888955116272, loss=1.4351609945297241
train: epoch 101, loss 0.7377155423164368, acc=0.7014444470405579, loss=0.7377155423164368
test: epoch 101, loss 1.34230375289917, acc=0.4055555462837219, loss=1.34230375289917
train: epoch 102, loss 0.7299710512161255, acc=0.7109444737434387, loss=0.7299710512161255
test: epoch 102, loss 1.1512757539749146, acc=0.4833333194255829, loss=1.1512757539749146
train: epoch 103, loss 0.7069979310035706, acc=0.7141110897064209, loss=0.7069979310035706
test: epoch 103, loss 1.3036407232284546, acc=0.5611110925674438, loss=1.3036407232284546
train: epoch 104, loss 0.7218998670578003, acc=0.7136111259460449, loss=0.7218998670578003
test: epoch 104, loss 1.332476258277893, acc=0.4555555582046509, loss=1.332476258277893
train: epoch 105, loss 0.7016427516937256, acc=0.7211111187934875, loss=0.7016427516937256
test: epoch 105, loss 1.5854418277740479, acc=0.4472222328186035, loss=1.5854418277740479
train: epoch 106, loss 0.6957218050956726, acc=0.7221111059188843, loss=0.6957218050956726
test: epoch 106, loss 1.3194873332977295, acc=0.49166667461395264, loss=1.3194873332977295
train: epoch 107, loss 0.7078543901443481, acc=0.7187777757644653, loss=0.7078543901443481
test: epoch 107, loss 1.405339002609253, acc=0.4305555522441864, loss=1.405339002609253
train: epoch 108, loss 0.6958107948303223, acc=0.717555582523346, loss=0.6958107948303223
test: epoch 108, loss 1.3767623901367188, acc=0.42222222685813904, loss=1.3767623901367188
train: epoch 109, loss 0.6832738518714905, acc=0.7265555262565613, loss=0.6832738518714905
test: epoch 109, loss 1.2577065229415894, acc=0.4416666626930237, loss=1.2577065229415894
train: epoch 110, loss 0.6902917623519897, acc=0.7269444465637207, loss=0.6902917623519897
test: epoch 110, loss 1.6503031253814697, acc=0.3333333432674408, loss=1.6503031253814697
train: epoch 111, loss 0.6737585663795471, acc=0.7258889079093933, loss=0.6737585663795471
test: epoch 111, loss 1.6309984922409058, acc=0.38055557012557983, loss=1.6309984922409058
train: epoch 112, loss 0.671621561050415, acc=0.7295555472373962, loss=0.671621561050415
test: epoch 112, loss 1.3782851696014404, acc=0.42222222685813904, loss=1.3782851696014404
train: epoch 113, loss 0.6682391166687012, acc=0.7263888716697693, loss=0.6682391166687012
test: epoch 113, loss 1.1485041379928589, acc=0.4972222149372101, loss=1.1485041379928589
train: epoch 114, loss 0.6534678339958191, acc=0.7370555400848389, loss=0.6534678339958191
test: epoch 114, loss 1.2455235719680786, acc=0.519444465637207, loss=1.2455235719680786
train: epoch 115, loss 0.6561874747276306, acc=0.7356666922569275, loss=0.6561874747276306
test: epoch 115, loss 1.2897793054580688, acc=0.4694444537162781, loss=1.2897793054580688
train: epoch 116, loss 0.6586265563964844, acc=0.7358888983726501, loss=0.6586265563964844
test: epoch 116, loss 1.3588716983795166, acc=0.4305555522441864, loss=1.3588716983795166
train: epoch 117, loss 0.6509600281715393, acc=0.7387222051620483, loss=0.6509600281715393
test: epoch 117, loss 1.3496204614639282, acc=0.4833333194255829, loss=1.3496204614639282
train: epoch 118, loss 0.6500694751739502, acc=0.7402777671813965, loss=0.6500694751739502
test: epoch 118, loss 1.2046568393707275, acc=0.4722222089767456, loss=1.2046568393707275
train: epoch 119, loss 0.6492348909378052, acc=0.7418888807296753, loss=0.6492348909378052
test: epoch 119, loss 1.4376684427261353, acc=0.45277777314186096, loss=1.4376684427261353
train: epoch 120, loss 0.6544442176818848, acc=0.7377777695655823, loss=0.6544442176818848
test: epoch 120, loss 1.2584465742111206, acc=0.4444444477558136, loss=1.2584465742111206
train: epoch 121, loss 0.6319905519485474, acc=0.7480555772781372, loss=0.6319905519485474
test: epoch 121, loss 1.162203073501587, acc=0.5, loss=1.162203073501587
train: epoch 122, loss 0.6244856715202332, acc=0.7508333325386047, loss=0.6244856715202332
test: epoch 122, loss 1.0326716899871826, acc=0.5472221970558167, loss=1.0326716899871826
train: epoch 123, loss 0.6310880780220032, acc=0.7472777962684631, loss=0.6310880780220032
test: epoch 123, loss 1.2683449983596802, acc=0.49166667461395264, loss=1.2683449983596802
train: epoch 124, loss 0.6312053203582764, acc=0.7497222423553467, loss=0.6312053203582764
test: epoch 124, loss 1.372430682182312, acc=0.4194444417953491, loss=1.372430682182312
train: epoch 125, loss 0.632049024105072, acc=0.745555579662323, loss=0.632049024105072
test: epoch 125, loss 1.2874208688735962, acc=0.5, loss=1.2874208688735962
train: epoch 126, loss 0.6240084767341614, acc=0.7508333325386047, loss=0.6240084767341614
test: epoch 126, loss 1.1004557609558105, acc=0.5527777671813965, loss=1.1004557609558105
train: epoch 127, loss 0.6021793484687805, acc=0.757444441318512, loss=0.6021793484687805
test: epoch 127, loss 1.2002602815628052, acc=0.5166666507720947, loss=1.2002602815628052
train: epoch 128, loss 0.6094691157341003, acc=0.7521666884422302, loss=0.6094691157341003
test: epoch 128, loss 1.3110307455062866, acc=0.550000011920929, loss=1.3110307455062866
train: epoch 129, loss 0.6158409714698792, acc=0.7525555491447449, loss=0.6158409714698792
test: epoch 129, loss 1.09322988986969, acc=0.5, loss=1.09322988986969
train: epoch 130, loss 0.6389918923377991, acc=0.7473333477973938, loss=0.6389918923377991
test: epoch 130, loss 1.4775654077529907, acc=0.40833333134651184, loss=1.4775654077529907
train: epoch 131, loss 0.5950924754142761, acc=0.7616666555404663, loss=0.5950924754142761
test: epoch 131, loss 1.3660900592803955, acc=0.46388888359069824, loss=1.3660900592803955
train: epoch 132, loss 0.6042749285697937, acc=0.7548333406448364, loss=0.6042749285697937
test: epoch 132, loss 1.165330410003662, acc=0.4861111044883728, loss=1.165330410003662
train: epoch 133, loss 0.5939515233039856, acc=0.7603889107704163, loss=0.5939515233039856
test: epoch 133, loss 1.4170171022415161, acc=0.5249999761581421, loss=1.4170171022415161
train: epoch 134, loss 0.5972674489021301, acc=0.7602777481079102, loss=0.5972674489021301
test: epoch 134, loss 1.2060602903366089, acc=0.5694444179534912, loss=1.2060602903366089
train: epoch 135, loss 0.5926182270050049, acc=0.7597222328186035, loss=0.5926182270050049
test: epoch 135, loss 0.9853805899620056, acc=0.5222222208976746, loss=0.9853805899620056
train: epoch 136, loss 0.6082100868225098, acc=0.7568888664245605, loss=0.6082100868225098
test: epoch 136, loss 1.1881771087646484, acc=0.46666666865348816, loss=1.1881771087646484
train: epoch 137, loss 0.5839654803276062, acc=0.7644444704055786, loss=0.5839654803276062
test: epoch 137, loss 1.4401187896728516, acc=0.4694444537162781, loss=1.4401187896728516
train: epoch 138, loss 0.5820765495300293, acc=0.769611120223999, loss=0.5820765495300293
test: epoch 138, loss 1.1910960674285889, acc=0.5722222328186035, loss=1.1910960674285889
train: epoch 139, loss 0.5714458227157593, acc=0.768833339214325, loss=0.5714458227157593
test: epoch 139, loss 1.1954365968704224, acc=0.5, loss=1.1954365968704224
train: epoch 140, loss 0.579395055770874, acc=0.7690555453300476, loss=0.579395055770874
test: epoch 140, loss 1.5068330764770508, acc=0.5222222208976746, loss=1.5068330764770508
train: epoch 141, loss 0.5754920840263367, acc=0.7642777562141418, loss=0.5754920840263367
test: epoch 141, loss 1.3785655498504639, acc=0.5416666865348816, loss=1.3785655498504639
train: epoch 142, loss 0.5759275555610657, acc=0.7695000171661377, loss=0.5759275555610657
test: epoch 142, loss 1.235382080078125, acc=0.5111111402511597, loss=1.235382080078125
train: epoch 143, loss 0.5731319189071655, acc=0.7737777829170227, loss=0.5731319189071655
test: epoch 143, loss 1.1771777868270874, acc=0.5166666507720947, loss=1.1771777868270874
train: epoch 144, loss 0.5643879175186157, acc=0.7821666598320007, loss=0.5643879175186157
test: epoch 144, loss 1.110365390777588, acc=0.5277777910232544, loss=1.110365390777588
train: epoch 145, loss 0.5613264441490173, acc=0.7783889174461365, loss=0.5613264441490173
test: epoch 145, loss 1.2864307165145874, acc=0.4722222089767456, loss=1.2864307165145874
train: epoch 146, loss 0.5623661875724792, acc=0.7752222418785095, loss=0.5623661875724792
test: epoch 146, loss 1.0043656826019287, acc=0.5583333373069763, loss=1.0043656826019287
train: epoch 147, loss 0.5624882578849792, acc=0.7771111130714417, loss=0.5624882578849792
test: epoch 147, loss 1.1125361919403076, acc=0.4722222089767456, loss=1.1125361919403076
train: epoch 148, loss 0.5745219588279724, acc=0.7711666822433472, loss=0.5745219588279724
test: epoch 148, loss 0.9916480183601379, acc=0.5361111164093018, loss=0.9916480183601379
train: epoch 149, loss 0.5534042119979858, acc=0.7795555591583252, loss=0.5534042119979858
test: epoch 149, loss 1.194854974746704, acc=0.5111111402511597, loss=1.194854974746704
train: epoch 150, loss 0.5510849952697754, acc=0.7862222194671631, loss=0.5510849952697754
test: epoch 150, loss 0.9434545040130615, acc=0.5916666388511658, loss=0.9434545040130615
