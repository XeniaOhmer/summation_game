# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=0", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=2097971787, receiver_embed_dim=64, save_run=0, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=2097971787, receiver_embed_dim=64, save_run=False, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.330764055252075, acc=0.18094444274902344, loss=2.330764055252075
test: epoch 1, loss 7.254245281219482, acc=0.07777778059244156, loss=7.254245281219482
train: epoch 2, loss 1.561964988708496, acc=0.3503333330154419, loss=1.561964988708496
test: epoch 2, loss 5.768856525421143, acc=0.10555555671453476, loss=5.768856525421143
train: epoch 3, loss 1.3126006126403809, acc=0.4449999928474426, loss=1.3126006126403809
test: epoch 3, loss 5.988266468048096, acc=0.10277777910232544, loss=5.988266468048096
train: epoch 4, loss 1.1445201635360718, acc=0.5215555429458618, loss=1.1445201635360718
test: epoch 4, loss 5.161413669586182, acc=0.11388888955116272, loss=5.161413669586182
train: epoch 5, loss 1.0278244018554688, acc=0.5720000267028809, loss=1.0278244018554688
test: epoch 5, loss 4.184021949768066, acc=0.20277777314186096, loss=4.184021949768066
train: epoch 6, loss 0.9223349094390869, acc=0.6230000257492065, loss=0.9223349094390869
test: epoch 6, loss 3.952758312225342, acc=0.14166666567325592, loss=3.952758312225342
train: epoch 7, loss 0.8349629640579224, acc=0.655055582523346, loss=0.8349629640579224
test: epoch 7, loss 4.128623962402344, acc=0.23055554926395416, loss=4.128623962402344
train: epoch 8, loss 0.8245872259140015, acc=0.6652222275733948, loss=0.8245872259140015
test: epoch 8, loss 3.1807827949523926, acc=0.2888889014720917, loss=3.1807827949523926
train: epoch 9, loss 0.7334125638008118, acc=0.7031111121177673, loss=0.7334125638008118
test: epoch 9, loss 3.2636406421661377, acc=0.2666666805744171, loss=3.2636406421661377
train: epoch 10, loss 0.7055785655975342, acc=0.7196111083030701, loss=0.7055785655975342
test: epoch 10, loss 3.7481510639190674, acc=0.2527777850627899, loss=3.7481510639190674
train: epoch 11, loss 0.6738506555557251, acc=0.7336666584014893, loss=0.6738506555557251
test: epoch 11, loss 4.081972122192383, acc=0.20000000298023224, loss=4.081972122192383
train: epoch 12, loss 0.6399798393249512, acc=0.7456666827201843, loss=0.6399798393249512
test: epoch 12, loss 2.643237590789795, acc=0.36944442987442017, loss=2.643237590789795
train: epoch 13, loss 0.6557614207267761, acc=0.738777756690979, loss=0.6557614207267761
test: epoch 13, loss 2.5178024768829346, acc=0.2666666805744171, loss=2.5178024768829346
train: epoch 14, loss 0.5852442979812622, acc=0.7707777619361877, loss=0.5852442979812622
test: epoch 14, loss 4.397144317626953, acc=0.2777777910232544, loss=4.397144317626953
train: epoch 15, loss 0.6161345839500427, acc=0.7587222456932068, loss=0.6161345839500427
test: epoch 15, loss 3.534301280975342, acc=0.2638888955116272, loss=3.534301280975342
train: epoch 16, loss 0.5548814535140991, acc=0.7823888659477234, loss=0.5548814535140991
test: epoch 16, loss 2.917423963546753, acc=0.2888889014720917, loss=2.917423963546753
train: epoch 17, loss 0.5128443837165833, acc=0.796833336353302, loss=0.5128443837165833
test: epoch 17, loss 2.892486572265625, acc=0.2805555462837219, loss=2.892486572265625
train: epoch 18, loss 0.5708353519439697, acc=0.7754444479942322, loss=0.5708353519439697
test: epoch 18, loss 2.6329691410064697, acc=0.38055557012557983, loss=2.6329691410064697
train: epoch 19, loss 0.5279921889305115, acc=0.7990555763244629, loss=0.5279921889305115
test: epoch 19, loss 2.421800374984741, acc=0.36944442987442017, loss=2.421800374984741
train: epoch 20, loss 0.4960693120956421, acc=0.808722198009491, loss=0.4960693120956421
test: epoch 20, loss 2.621335506439209, acc=0.375, loss=2.621335506439209
train: epoch 21, loss 0.5051950216293335, acc=0.8031666874885559, loss=0.5051950216293335
test: epoch 21, loss 3.056391716003418, acc=0.30000001192092896, loss=3.056391716003418
train: epoch 22, loss 0.4790351986885071, acc=0.8168888688087463, loss=0.4790351986885071
test: epoch 22, loss 2.5680859088897705, acc=0.3305555582046509, loss=2.5680859088897705
train: epoch 23, loss 0.45845621824264526, acc=0.8239444494247437, loss=0.45845621824264526
test: epoch 23, loss 1.7444308996200562, acc=0.42500001192092896, loss=1.7444308996200562
train: epoch 24, loss 0.45909833908081055, acc=0.8238333463668823, loss=0.45909833908081055
test: epoch 24, loss 2.2500972747802734, acc=0.24166665971279144, loss=2.2500972747802734
train: epoch 25, loss 0.4493943452835083, acc=0.8261666893959045, loss=0.4493943452835083
test: epoch 25, loss 2.0931508541107178, acc=0.39444443583488464, loss=2.0931508541107178
train: epoch 26, loss 0.4671382009983063, acc=0.8198888897895813, loss=0.4671382009983063
test: epoch 26, loss 2.618698835372925, acc=0.31111112236976624, loss=2.618698835372925
train: epoch 27, loss 0.4347483813762665, acc=0.8301110863685608, loss=0.4347483813762665
test: epoch 27, loss 2.0241806507110596, acc=0.32499998807907104, loss=2.0241806507110596
train: epoch 28, loss 0.442084938287735, acc=0.8277222514152527, loss=0.442084938287735
test: epoch 28, loss 3.034075975418091, acc=0.28611111640930176, loss=3.034075975418091
train: epoch 29, loss 0.45290035009384155, acc=0.8214444518089294, loss=0.45290035009384155
test: epoch 29, loss 2.2644379138946533, acc=0.38055557012557983, loss=2.2644379138946533
train: epoch 30, loss 0.4282289445400238, acc=0.8377222418785095, loss=0.4282289445400238
test: epoch 30, loss 2.753864049911499, acc=0.3055555522441864, loss=2.753864049911499
train: epoch 31, loss 0.4482322037220001, acc=0.828166663646698, loss=0.4482322037220001
test: epoch 31, loss 4.148521900177002, acc=0.32777777314186096, loss=4.148521900177002
train: epoch 32, loss 0.41698241233825684, acc=0.8417778015136719, loss=0.41698241233825684
test: epoch 32, loss 2.3861677646636963, acc=0.3083333373069763, loss=2.3861677646636963
train: epoch 33, loss 0.4408215284347534, acc=0.8316110968589783, loss=0.4408215284347534
test: epoch 33, loss 2.364506244659424, acc=0.3499999940395355, loss=2.364506244659424
train: epoch 34, loss 0.4069879949092865, acc=0.8433333039283752, loss=0.4069879949092865
test: epoch 34, loss 2.2602527141571045, acc=0.35277777910232544, loss=2.2602527141571045
train: epoch 35, loss 0.4295528829097748, acc=0.836222231388092, loss=0.4295528829097748
test: epoch 35, loss 2.166872978210449, acc=0.3638888895511627, loss=2.166872978210449
train: epoch 36, loss 0.4074118137359619, acc=0.8461111187934875, loss=0.4074118137359619
test: epoch 36, loss 1.7210123538970947, acc=0.4305555522441864, loss=1.7210123538970947
train: epoch 37, loss 0.41092708706855774, acc=0.8416110873222351, loss=0.41092708706855774
test: epoch 37, loss 2.006403684616089, acc=0.3777777850627899, loss=2.006403684616089
train: epoch 38, loss 0.4307232201099396, acc=0.8349444270133972, loss=0.4307232201099396
test: epoch 38, loss 2.3740408420562744, acc=0.4000000059604645, loss=2.3740408420562744
train: epoch 39, loss 0.4249720871448517, acc=0.8353333473205566, loss=0.4249720871448517
test: epoch 39, loss 2.351297378540039, acc=0.2638888955116272, loss=2.351297378540039
train: epoch 40, loss 0.41233929991722107, acc=0.8415555357933044, loss=0.41233929991722107
test: epoch 40, loss 1.931876301765442, acc=0.31111112236976624, loss=1.931876301765442
train: epoch 41, loss 0.4051339626312256, acc=0.8423888683319092, loss=0.4051339626312256
test: epoch 41, loss 1.7757455110549927, acc=0.46388888359069824, loss=1.7757455110549927
train: epoch 42, loss 0.43971842527389526, acc=0.8297777771949768, loss=0.43971842527389526
test: epoch 42, loss 1.9262498617172241, acc=0.42222222685813904, loss=1.9262498617172241
train: epoch 43, loss 0.3914550244808197, acc=0.8512222170829773, loss=0.3914550244808197
test: epoch 43, loss 1.8348277807235718, acc=0.43888887763023376, loss=1.8348277807235718
train: epoch 44, loss 0.4201298654079437, acc=0.839388906955719, loss=0.4201298654079437
test: epoch 44, loss 3.0692861080169678, acc=0.3861111104488373, loss=3.0692861080169678
train: epoch 45, loss 0.4092916250228882, acc=0.8402222394943237, loss=0.4092916250228882
test: epoch 45, loss 2.2020766735076904, acc=0.4472222328186035, loss=2.2020766735076904
train: epoch 46, loss 0.4113631844520569, acc=0.8430555462837219, loss=0.4113631844520569
test: epoch 46, loss 1.4276009798049927, acc=0.4138889014720917, loss=1.4276009798049927
train: epoch 47, loss 0.3879260718822479, acc=0.8493333458900452, loss=0.3879260718822479
test: epoch 47, loss 1.960554599761963, acc=0.38055557012557983, loss=1.960554599761963
train: epoch 48, loss 0.4109402000904083, acc=0.839388906955719, loss=0.4109402000904083
test: epoch 48, loss 1.694252371788025, acc=0.3194444477558136, loss=1.694252371788025
train: epoch 49, loss 0.4059867858886719, acc=0.8416666388511658, loss=0.4059867858886719
test: epoch 49, loss 1.9194406270980835, acc=0.39444443583488464, loss=1.9194406270980835
train: epoch 50, loss 0.39835402369499207, acc=0.8484444618225098, loss=0.39835402369499207
test: epoch 50, loss 1.968203067779541, acc=0.4444444477558136, loss=1.968203067779541
train: epoch 51, loss 0.37361595034599304, acc=0.8544444441795349, loss=0.37361595034599304
test: epoch 51, loss 2.243926763534546, acc=0.35277777910232544, loss=2.243926763534546
train: epoch 52, loss 0.3609970510005951, acc=0.8621110916137695, loss=0.3609970510005951
test: epoch 52, loss 2.0424106121063232, acc=0.3361110985279083, loss=2.0424106121063232
train: epoch 53, loss 0.38987424969673157, acc=0.8498333096504211, loss=0.38987424969673157
test: epoch 53, loss 1.799869179725647, acc=0.36666667461395264, loss=1.799869179725647
train: epoch 54, loss 0.4076095223426819, acc=0.8445555567741394, loss=0.4076095223426819
test: epoch 54, loss 1.798821210861206, acc=0.38055557012557983, loss=1.798821210861206
train: epoch 55, loss 0.3760388195514679, acc=0.850777804851532, loss=0.3760388195514679
test: epoch 55, loss 2.1882779598236084, acc=0.33888888359069824, loss=2.1882779598236084
train: epoch 56, loss 0.34313079714775085, acc=0.870888888835907, loss=0.34313079714775085
test: epoch 56, loss 2.086595058441162, acc=0.49166667461395264, loss=2.086595058441162
train: epoch 57, loss 0.37611833214759827, acc=0.8554999828338623, loss=0.37611833214759827
test: epoch 57, loss 2.0288333892822266, acc=0.35555556416511536, loss=2.0288333892822266
train: epoch 58, loss 0.3561800420284271, acc=0.8648889064788818, loss=0.3561800420284271
test: epoch 58, loss 1.6884711980819702, acc=0.4722222089767456, loss=1.6884711980819702
train: epoch 59, loss 0.36689865589141846, acc=0.8606111407279968, loss=0.36689865589141846
test: epoch 59, loss 1.2334023714065552, acc=0.5083333253860474, loss=1.2334023714065552
train: epoch 60, loss 0.34202125668525696, acc=0.8681666851043701, loss=0.34202125668525696
test: epoch 60, loss 1.7132073640823364, acc=0.4194444417953491, loss=1.7132073640823364
train: epoch 61, loss 0.3701677918434143, acc=0.8612222075462341, loss=0.3701677918434143
test: epoch 61, loss 1.4335455894470215, acc=0.44999998807907104, loss=1.4335455894470215
train: epoch 62, loss 0.35446029901504517, acc=0.8630555272102356, loss=0.35446029901504517
test: epoch 62, loss 1.4240986108779907, acc=0.4722222089767456, loss=1.4240986108779907
train: epoch 63, loss 0.3294588327407837, acc=0.875333309173584, loss=0.3294588327407837
test: epoch 63, loss 1.8818172216415405, acc=0.41111111640930176, loss=1.8818172216415405
train: epoch 64, loss 0.36524441838264465, acc=0.8603888750076294, loss=0.36524441838264465
test: epoch 64, loss 1.6277016401290894, acc=0.4555555582046509, loss=1.6277016401290894
train: epoch 65, loss 0.35724136233329773, acc=0.8619999885559082, loss=0.35724136233329773
test: epoch 65, loss 1.1685311794281006, acc=0.5833333134651184, loss=1.1685311794281006
train: epoch 66, loss 0.3341972827911377, acc=0.8733333349227905, loss=0.3341972827911377
test: epoch 66, loss 1.17972993850708, acc=0.5277777910232544, loss=1.17972993850708
train: epoch 67, loss 0.3324246108531952, acc=0.8731666803359985, loss=0.3324246108531952
test: epoch 67, loss 1.9595184326171875, acc=0.4611110985279083, loss=1.9595184326171875
train: epoch 68, loss 0.33711352944374084, acc=0.8723888993263245, loss=0.33711352944374084
test: epoch 68, loss 1.1530295610427856, acc=0.5388888716697693, loss=1.1530295610427856
train: epoch 69, loss 0.32662805914878845, acc=0.8765000104904175, loss=0.32662805914878845
test: epoch 69, loss 1.3687862157821655, acc=0.44999998807907104, loss=1.3687862157821655
train: epoch 70, loss 0.31261056661605835, acc=0.8827221989631653, loss=0.31261056661605835
test: epoch 70, loss 1.6032869815826416, acc=0.4833333194255829, loss=1.6032869815826416
train: epoch 71, loss 0.3464685082435608, acc=0.863777756690979, loss=0.3464685082435608
test: epoch 71, loss 1.9168058633804321, acc=0.4583333432674408, loss=1.9168058633804321
train: epoch 72, loss 0.3224731981754303, acc=0.878777801990509, loss=0.3224731981754303
test: epoch 72, loss 1.4710307121276855, acc=0.47777777910232544, loss=1.4710307121276855
train: epoch 73, loss 0.32551705837249756, acc=0.8736666440963745, loss=0.32551705837249756
test: epoch 73, loss 1.4731849431991577, acc=0.5444444417953491, loss=1.4731849431991577
train: epoch 74, loss 0.32815447449684143, acc=0.8746111392974854, loss=0.32815447449684143
test: epoch 74, loss 1.4271372556686401, acc=0.5277777910232544, loss=1.4271372556686401
train: epoch 75, loss 0.31859612464904785, acc=0.8759444355964661, loss=0.31859612464904785
test: epoch 75, loss 1.405295968055725, acc=0.5166666507720947, loss=1.405295968055725
train: epoch 76, loss 0.31062939763069153, acc=0.8830000162124634, loss=0.31062939763069153
test: epoch 76, loss 1.2714500427246094, acc=0.5388888716697693, loss=1.2714500427246094
train: epoch 77, loss 0.3238831162452698, acc=0.8758888840675354, loss=0.3238831162452698
test: epoch 77, loss 1.4593614339828491, acc=0.5, loss=1.4593614339828491
train: epoch 78, loss 0.3109990060329437, acc=0.8849444389343262, loss=0.3109990060329437
test: epoch 78, loss 1.1588395833969116, acc=0.6111111044883728, loss=1.1588395833969116
train: epoch 79, loss 0.3196103870868683, acc=0.8757777810096741, loss=0.3196103870868683
test: epoch 79, loss 1.2240474224090576, acc=0.550000011920929, loss=1.2240474224090576
train: epoch 80, loss 0.3095853328704834, acc=0.8793333172798157, loss=0.3095853328704834
test: epoch 80, loss 1.3350950479507446, acc=0.5222222208976746, loss=1.3350950479507446
train: epoch 81, loss 0.3061770796775818, acc=0.8823888897895813, loss=0.3061770796775818
test: epoch 81, loss 1.2985968589782715, acc=0.4833333194255829, loss=1.2985968589782715
train: epoch 82, loss 0.32257962226867676, acc=0.8812777996063232, loss=0.32257962226867676
test: epoch 82, loss 1.588287353515625, acc=0.47777777910232544, loss=1.588287353515625
train: epoch 83, loss 0.2982109785079956, acc=0.8856111168861389, loss=0.2982109785079956
test: epoch 83, loss 1.1982215642929077, acc=0.5944444537162781, loss=1.1982215642929077
train: epoch 84, loss 0.3263225555419922, acc=0.8752777576446533, loss=0.3263225555419922
test: epoch 84, loss 1.7412394285202026, acc=0.5083333253860474, loss=1.7412394285202026
train: epoch 85, loss 0.3231109082698822, acc=0.8782222270965576, loss=0.3231109082698822
test: epoch 85, loss 1.313871145248413, acc=0.5388888716697693, loss=1.313871145248413
train: epoch 86, loss 0.2836848795413971, acc=0.8927778005599976, loss=0.2836848795413971
test: epoch 86, loss 1.070338249206543, acc=0.6222222447395325, loss=1.070338249206543
train: epoch 87, loss 0.2899461090564728, acc=0.8897222280502319, loss=0.2899461090564728
test: epoch 87, loss 1.6633905172348022, acc=0.5527777671813965, loss=1.6633905172348022
train: epoch 88, loss 0.31674396991729736, acc=0.8793333172798157, loss=0.31674396991729736
test: epoch 88, loss 1.3386943340301514, acc=0.5861111283302307, loss=1.3386943340301514
train: epoch 89, loss 0.3129376173019409, acc=0.8805000185966492, loss=0.3129376173019409
test: epoch 89, loss 1.3662630319595337, acc=0.519444465637207, loss=1.3662630319595337
train: epoch 90, loss 0.2698669731616974, acc=0.9003888964653015, loss=0.2698669731616974
test: epoch 90, loss 1.5680420398712158, acc=0.4833333194255829, loss=1.5680420398712158
train: epoch 91, loss 0.29736313223838806, acc=0.8886111378669739, loss=0.29736313223838806
test: epoch 91, loss 1.135079264640808, acc=0.5861111283302307, loss=1.135079264640808
train: epoch 92, loss 0.310835063457489, acc=0.8824999928474426, loss=0.310835063457489
test: epoch 92, loss 1.5178558826446533, acc=0.46388888359069824, loss=1.5178558826446533
train: epoch 93, loss 0.28974649310112, acc=0.8892777562141418, loss=0.28974649310112
test: epoch 93, loss 1.3398756980895996, acc=0.5416666865348816, loss=1.3398756980895996
train: epoch 94, loss 0.2831107974052429, acc=0.8934444189071655, loss=0.2831107974052429
test: epoch 94, loss 1.2763482332229614, acc=0.5805555582046509, loss=1.2763482332229614
train: epoch 95, loss 0.28097522258758545, acc=0.8916666507720947, loss=0.28097522258758545
test: epoch 95, loss 1.4833730459213257, acc=0.46666666865348816, loss=1.4833730459213257
train: epoch 96, loss 0.29204481840133667, acc=0.8860555291175842, loss=0.29204481840133667
test: epoch 96, loss 0.9697582721710205, acc=0.6027777791023254, loss=0.9697582721710205
train: epoch 97, loss 0.2871412932872772, acc=0.8910555839538574, loss=0.2871412932872772
test: epoch 97, loss 1.088510513305664, acc=0.6305555701255798, loss=1.088510513305664
train: epoch 98, loss 0.3135128617286682, acc=0.8783888816833496, loss=0.3135128617286682
test: epoch 98, loss 1.1802302598953247, acc=0.5888888835906982, loss=1.1802302598953247
train: epoch 99, loss 0.28731006383895874, acc=0.8897222280502319, loss=0.28731006383895874
test: epoch 99, loss 1.2788522243499756, acc=0.5416666865348816, loss=1.2788522243499756
train: epoch 100, loss 0.27414998412132263, acc=0.8961666822433472, loss=0.27414998412132263
test: epoch 100, loss 1.3387339115142822, acc=0.5833333134651184, loss=1.3387339115142822
train: epoch 101, loss 0.2825186252593994, acc=0.8920555710792542, loss=0.2825186252593994
test: epoch 101, loss 1.11190664768219, acc=0.5527777671813965, loss=1.11190664768219
train: epoch 102, loss 0.275359183549881, acc=0.8934999704360962, loss=0.275359183549881
test: epoch 102, loss 1.2004451751708984, acc=0.5583333373069763, loss=1.2004451751708984
train: epoch 103, loss 0.30200234055519104, acc=0.8861666917800903, loss=0.30200234055519104
test: epoch 103, loss 1.0868903398513794, acc=0.6166666746139526, loss=1.0868903398513794
train: epoch 104, loss 0.28199541568756104, acc=0.8916666507720947, loss=0.28199541568756104
test: epoch 104, loss 1.1417475938796997, acc=0.550000011920929, loss=1.1417475938796997
train: epoch 105, loss 0.2817992568016052, acc=0.8939444422721863, loss=0.2817992568016052
test: epoch 105, loss 1.2927823066711426, acc=0.5, loss=1.2927823066711426
train: epoch 106, loss 0.2634347677230835, acc=0.9006111025810242, loss=0.2634347677230835
test: epoch 106, loss 1.4702311754226685, acc=0.5583333373069763, loss=1.4702311754226685
train: epoch 107, loss 0.2945438325405121, acc=0.8867777585983276, loss=0.2945438325405121
test: epoch 107, loss 1.31783926486969, acc=0.625, loss=1.31783926486969
train: epoch 108, loss 0.28121253848075867, acc=0.8923888802528381, loss=0.28121253848075867
test: epoch 108, loss 1.5078468322753906, acc=0.6000000238418579, loss=1.5078468322753906
train: epoch 109, loss 0.267704039812088, acc=0.9001666903495789, loss=0.267704039812088
test: epoch 109, loss 0.9358341693878174, acc=0.6222222447395325, loss=0.9358341693878174
train: epoch 110, loss 0.27788594365119934, acc=0.8943333625793457, loss=0.27788594365119934
test: epoch 110, loss 1.0648859739303589, acc=0.6111111044883728, loss=1.0648859739303589
train: epoch 111, loss 0.25719866156578064, acc=0.9044444561004639, loss=0.25719866156578064
test: epoch 111, loss 0.9334589838981628, acc=0.6333333253860474, loss=0.9334589838981628
train: epoch 112, loss 0.26461493968963623, acc=0.8995000123977661, loss=0.26461493968963623
test: epoch 112, loss 1.0075489282608032, acc=0.6027777791023254, loss=1.0075489282608032
train: epoch 113, loss 0.2651533782482147, acc=0.901888906955719, loss=0.2651533782482147
test: epoch 113, loss 1.0744071006774902, acc=0.5805555582046509, loss=1.0744071006774902
train: epoch 114, loss 0.286692351102829, acc=0.8926666378974915, loss=0.286692351102829
test: epoch 114, loss 0.9786329865455627, acc=0.5555555820465088, loss=0.9786329865455627
train: epoch 115, loss 0.27098211646080017, acc=0.8978888988494873, loss=0.27098211646080017
test: epoch 115, loss 1.0531703233718872, acc=0.6694444417953491, loss=1.0531703233718872
train: epoch 116, loss 0.25961852073669434, acc=0.9021666646003723, loss=0.25961852073669434
test: epoch 116, loss 0.8708196878433228, acc=0.644444465637207, loss=0.8708196878433228
train: epoch 117, loss 0.2850450873374939, acc=0.8918889164924622, loss=0.2850450873374939
test: epoch 117, loss 0.9367203116416931, acc=0.6694444417953491, loss=0.9367203116416931
train: epoch 118, loss 0.2592679262161255, acc=0.9004444479942322, loss=0.2592679262161255
test: epoch 118, loss 0.8672077059745789, acc=0.6555555462837219, loss=0.8672077059745789
train: epoch 119, loss 0.29909268021583557, acc=0.8880555629730225, loss=0.29909268021583557
test: epoch 119, loss 1.3447192907333374, acc=0.5527777671813965, loss=1.3447192907333374
train: epoch 120, loss 0.24766811728477478, acc=0.9072222113609314, loss=0.24766811728477478
test: epoch 120, loss 1.258381724357605, acc=0.5944444537162781, loss=1.258381724357605
train: epoch 121, loss 0.28021863102912903, acc=0.8928333520889282, loss=0.28021863102912903
test: epoch 121, loss 0.9142686724662781, acc=0.644444465637207, loss=0.9142686724662781
train: epoch 122, loss 0.2647354006767273, acc=0.9015555381774902, loss=0.2647354006767273
test: epoch 122, loss 1.2418195009231567, acc=0.5361111164093018, loss=1.2418195009231567
train: epoch 123, loss 0.276204377412796, acc=0.8959444165229797, loss=0.276204377412796
test: epoch 123, loss 0.8806124329566956, acc=0.6138888597488403, loss=0.8806124329566956
train: epoch 124, loss 0.27007123827934265, acc=0.8980000019073486, loss=0.27007123827934265
test: epoch 124, loss 1.221635103225708, acc=0.5805555582046509, loss=1.221635103225708
train: epoch 125, loss 0.24203605949878693, acc=0.9077777862548828, loss=0.24203605949878693
test: epoch 125, loss 1.1098878383636475, acc=0.6472222208976746, loss=1.1098878383636475
train: epoch 126, loss 0.29357171058654785, acc=0.8911666870117188, loss=0.29357171058654785
test: epoch 126, loss 1.0852017402648926, acc=0.6583333611488342, loss=1.0852017402648926
train: epoch 127, loss 0.24171850085258484, acc=0.9113888740539551, loss=0.24171850085258484
test: epoch 127, loss 0.9364829659461975, acc=0.6916666626930237, loss=0.9364829659461975
train: epoch 128, loss 0.27214863896369934, acc=0.8985000252723694, loss=0.27214863896369934
test: epoch 128, loss 1.104751467704773, acc=0.6499999761581421, loss=1.104751467704773
train: epoch 129, loss 0.2584613561630249, acc=0.9019444584846497, loss=0.2584613561630249
test: epoch 129, loss 0.7429646253585815, acc=0.7055555582046509, loss=0.7429646253585815
train: epoch 130, loss 0.25220248103141785, acc=0.9042222499847412, loss=0.25220248103141785
test: epoch 130, loss 1.029382586479187, acc=0.6833333373069763, loss=1.029382586479187
train: epoch 131, loss 0.2676258981227875, acc=0.9002222418785095, loss=0.2676258981227875
test: epoch 131, loss 0.8821930289268494, acc=0.6527777910232544, loss=0.8821930289268494
train: epoch 132, loss 0.26032039523124695, acc=0.9033889174461365, loss=0.26032039523124695
test: epoch 132, loss 0.7183094024658203, acc=0.7361111044883728, loss=0.7183094024658203
train: epoch 133, loss 0.30475935339927673, acc=0.8843888640403748, loss=0.30475935339927673
test: epoch 133, loss 1.121061086654663, acc=0.6361111402511597, loss=1.121061086654663
train: epoch 134, loss 0.2567369043827057, acc=0.9014444351196289, loss=0.2567369043827057
test: epoch 134, loss 1.041668176651001, acc=0.6222222447395325, loss=1.041668176651001
train: epoch 135, loss 0.28596335649490356, acc=0.8950555324554443, loss=0.28596335649490356
test: epoch 135, loss 0.9001016020774841, acc=0.6777777671813965, loss=0.9001016020774841
train: epoch 136, loss 0.24276942014694214, acc=0.9105555415153503, loss=0.24276942014694214
test: epoch 136, loss 0.7270902395248413, acc=0.7250000238418579, loss=0.7270902395248413
train: epoch 137, loss 0.2848173975944519, acc=0.8933888673782349, loss=0.2848173975944519
test: epoch 137, loss 0.9569054841995239, acc=0.6638888716697693, loss=0.9569054841995239
train: epoch 138, loss 0.280957967042923, acc=0.8946666717529297, loss=0.280957967042923
test: epoch 138, loss 0.792227029800415, acc=0.625, loss=0.792227029800415
train: epoch 139, loss 0.25384819507598877, acc=0.905055582523346, loss=0.25384819507598877
test: epoch 139, loss 0.8710954785346985, acc=0.6861110925674438, loss=0.8710954785346985
train: epoch 140, loss 0.2693467140197754, acc=0.8987777829170227, loss=0.2693467140197754
test: epoch 140, loss 0.8861696124076843, acc=0.7361111044883728, loss=0.8861696124076843
train: epoch 141, loss 0.2733844220638275, acc=0.9004999995231628, loss=0.2733844220638275
test: epoch 141, loss 0.8157633543014526, acc=0.6972222328186035, loss=0.8157633543014526
train: epoch 142, loss 0.28225651383399963, acc=0.8961666822433472, loss=0.28225651383399963
test: epoch 142, loss 0.7581886649131775, acc=0.6638888716697693, loss=0.7581886649131775
train: epoch 143, loss 0.25340381264686584, acc=0.9051666855812073, loss=0.25340381264686584
test: epoch 143, loss 0.9297454953193665, acc=0.6916666626930237, loss=0.9297454953193665
train: epoch 144, loss 0.2510499954223633, acc=0.9068889021873474, loss=0.2510499954223633
test: epoch 144, loss 1.0139191150665283, acc=0.6944444179534912, loss=1.0139191150665283
train: epoch 145, loss 0.28983673453330994, acc=0.89083331823349, loss=0.28983673453330994
test: epoch 145, loss 0.6427973508834839, acc=0.7194444537162781, loss=0.6427973508834839
train: epoch 146, loss 0.2343713492155075, acc=0.9105555415153503, loss=0.2343713492155075
test: epoch 146, loss 0.7739896178245544, acc=0.7138888835906982, loss=0.7739896178245544
train: epoch 147, loss 0.2921960651874542, acc=0.8901110887527466, loss=0.2921960651874542
test: epoch 147, loss 0.7576894164085388, acc=0.6916666626930237, loss=0.7576894164085388
train: epoch 148, loss 0.28847190737724304, acc=0.89083331823349, loss=0.28847190737724304
test: epoch 148, loss 0.7277635335922241, acc=0.7055555582046509, loss=0.7277635335922241
train: epoch 149, loss 0.24968703091144562, acc=0.9051111340522766, loss=0.24968703091144562
test: epoch 149, loss 0.7759085297584534, acc=0.6805555820465088, loss=0.7759085297584534
train: epoch 150, loss 0.2556588351726532, acc=0.9042222499847412, loss=0.2556588351726532
test: epoch 150, loss 0.882848858833313, acc=0.6777777671813965, loss=0.882848858833313
