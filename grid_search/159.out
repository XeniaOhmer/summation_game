# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=2.0", "--temp_decay=0.99", "--one_hot=1", "--n_layers=1"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=1938445203, receiver_embed_dim=128, save_run=0, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1938445203, receiver_embed_dim=128, save_run=False, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.5110630989074707, acc=0.05044444277882576, loss=3.5110630989074707
test: epoch 1, loss 3.316120147705078, acc=0.05833333358168602, loss=3.316120147705078
train: epoch 2, loss 3.3959474563598633, acc=0.055666666477918625, loss=3.3959474563598633
test: epoch 2, loss 3.805276870727539, acc=0.0694444477558136, loss=3.805276870727539
train: epoch 3, loss 2.8685083389282227, acc=0.12488888949155807, loss=2.8685083389282227
test: epoch 3, loss 6.95219612121582, acc=0.04722222313284874, loss=6.95219612121582
train: epoch 4, loss 2.468554735183716, acc=0.18050000071525574, loss=2.468554735183716
test: epoch 4, loss 7.678492546081543, acc=0.06111111119389534, loss=7.678492546081543
train: epoch 5, loss 2.2791757583618164, acc=0.21388888359069824, loss=2.2791757583618164
test: epoch 5, loss 7.8815178871154785, acc=0.06388889253139496, loss=7.8815178871154785
train: epoch 6, loss 2.1629674434661865, acc=0.234333336353302, loss=2.1629674434661865
test: epoch 6, loss 7.9571709632873535, acc=0.0555555559694767, loss=7.9571709632873535
train: epoch 7, loss 2.078749179840088, acc=0.25538888573646545, loss=2.078749179840088
test: epoch 7, loss 7.631309986114502, acc=0.05000000074505806, loss=7.631309986114502
train: epoch 8, loss 2.009064197540283, acc=0.2718888819217682, loss=2.009064197540283
test: epoch 8, loss 7.613982677459717, acc=0.07222222536802292, loss=7.613982677459717
train: epoch 9, loss 1.962654709815979, acc=0.2883888781070709, loss=1.962654709815979
test: epoch 9, loss 7.828262805938721, acc=0.07222222536802292, loss=7.828262805938721
train: epoch 10, loss 1.9166926145553589, acc=0.31111112236976624, loss=1.9166926145553589
test: epoch 10, loss 7.631314754486084, acc=0.0694444477558136, loss=7.631314754486084
train: epoch 11, loss 1.879109263420105, acc=0.3138333261013031, loss=1.879109263420105
test: epoch 11, loss 7.626476764678955, acc=0.07777778059244156, loss=7.626476764678955
train: epoch 12, loss 1.8723411560058594, acc=0.31877776980400085, loss=1.8723411560058594
test: epoch 12, loss 7.746796607971191, acc=0.08055555820465088, loss=7.746796607971191
train: epoch 13, loss 1.8150867223739624, acc=0.3333333432674408, loss=1.8150867223739624
test: epoch 13, loss 7.776689052581787, acc=0.09166666865348816, loss=7.776689052581787
train: epoch 14, loss 1.796558141708374, acc=0.3427777886390686, loss=1.796558141708374
test: epoch 14, loss 7.818755626678467, acc=0.09166666865348816, loss=7.818755626678467
train: epoch 15, loss 1.765155553817749, acc=0.34683331847190857, loss=1.765155553817749
test: epoch 15, loss 7.601817607879639, acc=0.09444444626569748, loss=7.601817607879639
train: epoch 16, loss 1.7578003406524658, acc=0.3636666536331177, loss=1.7578003406524658
test: epoch 16, loss 7.434974670410156, acc=0.08611111342906952, loss=7.434974670410156
train: epoch 17, loss 1.7494876384735107, acc=0.363055557012558, loss=1.7494876384735107
test: epoch 17, loss 7.253422260284424, acc=0.0972222238779068, loss=7.253422260284424
train: epoch 18, loss 1.7151623964309692, acc=0.3761666715145111, loss=1.7151623964309692
test: epoch 18, loss 7.091595649719238, acc=0.10555555671453476, loss=7.091595649719238
train: epoch 19, loss 1.7086540460586548, acc=0.38111111521720886, loss=1.7086540460586548
test: epoch 19, loss 6.669868469238281, acc=0.1111111119389534, loss=6.669868469238281
train: epoch 20, loss 1.6937981843948364, acc=0.38938888907432556, loss=1.6937981843948364
test: epoch 20, loss 6.5048136711120605, acc=0.1111111119389534, loss=6.5048136711120605
train: epoch 21, loss 1.6968262195587158, acc=0.3883333206176758, loss=1.6968262195587158
test: epoch 21, loss 5.910274505615234, acc=0.12222222238779068, loss=5.910274505615234
train: epoch 22, loss 1.6615910530090332, acc=0.4048333466053009, loss=1.6615910530090332
test: epoch 22, loss 5.48090934753418, acc=0.12222222238779068, loss=5.48090934753418
train: epoch 23, loss 1.6384352445602417, acc=0.40477776527404785, loss=1.6384352445602417
test: epoch 23, loss 5.309898853302002, acc=0.13611111044883728, loss=5.309898853302002
train: epoch 24, loss 1.6229884624481201, acc=0.41055554151535034, loss=1.6229884624481201
test: epoch 24, loss 4.884478569030762, acc=0.14166666567325592, loss=4.884478569030762
train: epoch 25, loss 1.620912790298462, acc=0.4180000126361847, loss=1.620912790298462
test: epoch 25, loss 4.596710205078125, acc=0.13611111044883728, loss=4.596710205078125
train: epoch 26, loss 1.6093335151672363, acc=0.4156111180782318, loss=1.6093335151672363
test: epoch 26, loss 4.48488712310791, acc=0.125, loss=4.48488712310791
train: epoch 27, loss 1.592156171798706, acc=0.4314444363117218, loss=1.592156171798706
test: epoch 27, loss 4.457350730895996, acc=0.13055555522441864, loss=4.457350730895996
train: epoch 28, loss 1.5936949253082275, acc=0.433388888835907, loss=1.5936949253082275
test: epoch 28, loss 4.218472003936768, acc=0.15833333134651184, loss=4.218472003936768
train: epoch 29, loss 1.5644668340682983, acc=0.44749999046325684, loss=1.5644668340682983
test: epoch 29, loss 4.206812858581543, acc=0.16388888657093048, loss=4.206812858581543
train: epoch 30, loss 1.5486172437667847, acc=0.4398888945579529, loss=1.5486172437667847
test: epoch 30, loss 4.170926094055176, acc=0.15833333134651184, loss=4.170926094055176
train: epoch 31, loss 1.5593092441558838, acc=0.45605555176734924, loss=1.5593092441558838
test: epoch 31, loss 4.056109428405762, acc=0.16388888657093048, loss=4.056109428405762
train: epoch 32, loss 1.546140432357788, acc=0.46299999952316284, loss=1.546140432357788
test: epoch 32, loss 3.7984979152679443, acc=0.16388888657093048, loss=3.7984979152679443
train: epoch 33, loss 1.5174058675765991, acc=0.46211111545562744, loss=1.5174058675765991
test: epoch 33, loss 3.612828254699707, acc=0.16944444179534912, loss=3.612828254699707
train: epoch 34, loss 1.5112417936325073, acc=0.4729999899864197, loss=1.5112417936325073
test: epoch 34, loss 3.519688606262207, acc=0.17499999701976776, loss=3.519688606262207
train: epoch 35, loss 1.5218887329101562, acc=0.47788888216018677, loss=1.5218887329101562
test: epoch 35, loss 3.3885905742645264, acc=0.17777778208255768, loss=3.3885905742645264
train: epoch 36, loss 1.4815162420272827, acc=0.4869999885559082, loss=1.4815162420272827
test: epoch 36, loss 3.385673999786377, acc=0.18333333730697632, loss=3.385673999786377
train: epoch 37, loss 1.4854553937911987, acc=0.4903889000415802, loss=1.4854553937911987
test: epoch 37, loss 3.2151288986206055, acc=0.18888889253139496, loss=3.2151288986206055
train: epoch 38, loss 1.484245777130127, acc=0.49549999833106995, loss=1.484245777130127
test: epoch 38, loss 3.048116683959961, acc=0.19722221791744232, loss=3.048116683959961
train: epoch 39, loss 1.4440866708755493, acc=0.503944456577301, loss=1.4440866708755493
test: epoch 39, loss 2.943998336791992, acc=0.2083333283662796, loss=2.943998336791992
train: epoch 40, loss 1.4471275806427002, acc=0.5116111040115356, loss=1.4471275806427002
test: epoch 40, loss 2.9478116035461426, acc=0.20555555820465088, loss=2.9478116035461426
train: epoch 41, loss 1.42881441116333, acc=0.5175555348396301, loss=1.42881441116333
test: epoch 41, loss 2.809556007385254, acc=0.20555555820465088, loss=2.809556007385254
train: epoch 42, loss 1.4180206060409546, acc=0.5216666460037231, loss=1.4180206060409546
test: epoch 42, loss 2.7785937786102295, acc=0.22499999403953552, loss=2.7785937786102295
train: epoch 43, loss 1.4027469158172607, acc=0.5263333320617676, loss=1.4027469158172607
test: epoch 43, loss 2.8223330974578857, acc=0.20555555820465088, loss=2.8223330974578857
train: epoch 44, loss 1.4050530195236206, acc=0.5408889055252075, loss=1.4050530195236206
test: epoch 44, loss 2.770524501800537, acc=0.23055554926395416, loss=2.770524501800537
train: epoch 45, loss 1.3745479583740234, acc=0.5481111407279968, loss=1.3745479583740234
test: epoch 45, loss 2.657045602798462, acc=0.21388888359069824, loss=2.657045602798462
train: epoch 46, loss 1.3760673999786377, acc=0.5555555820465088, loss=1.3760673999786377
test: epoch 46, loss 2.6131157875061035, acc=0.22499999403953552, loss=2.6131157875061035
train: epoch 47, loss 1.3809075355529785, acc=0.5588333606719971, loss=1.3809075355529785
test: epoch 47, loss 2.5476088523864746, acc=0.24166665971279144, loss=2.5476088523864746
train: epoch 48, loss 1.3514509201049805, acc=0.566277801990509, loss=1.3514509201049805
test: epoch 48, loss 2.516857862472534, acc=0.23333333432674408, loss=2.516857862472534
train: epoch 49, loss 1.334003210067749, acc=0.5762222409248352, loss=1.334003210067749
test: epoch 49, loss 2.4587559700012207, acc=0.22777777910232544, loss=2.4587559700012207
train: epoch 50, loss 1.3276711702346802, acc=0.5816666483879089, loss=1.3276711702346802
test: epoch 50, loss 2.4138998985290527, acc=0.24166665971279144, loss=2.4138998985290527
train: epoch 51, loss 1.298483967781067, acc=0.5917778015136719, loss=1.298483967781067
test: epoch 51, loss 2.346544027328491, acc=0.2361111044883728, loss=2.346544027328491
train: epoch 52, loss 1.2893606424331665, acc=0.5950000286102295, loss=1.2893606424331665
test: epoch 52, loss 2.2921993732452393, acc=0.2638888955116272, loss=2.2921993732452393
train: epoch 53, loss 1.274667501449585, acc=0.6001111268997192, loss=1.274667501449585
test: epoch 53, loss 2.2729849815368652, acc=0.2750000059604645, loss=2.2729849815368652
train: epoch 54, loss 1.2626700401306152, acc=0.608222246170044, loss=1.2626700401306152
test: epoch 54, loss 2.2683587074279785, acc=0.25555557012557983, loss=2.2683587074279785
train: epoch 55, loss 1.2544560432434082, acc=0.6148333549499512, loss=1.2544560432434082
test: epoch 55, loss 2.243238687515259, acc=0.25833332538604736, loss=2.243238687515259
train: epoch 56, loss 1.2322601079940796, acc=0.6207777857780457, loss=1.2322601079940796
test: epoch 56, loss 2.157933235168457, acc=0.2777777910232544, loss=2.157933235168457
train: epoch 57, loss 1.2158079147338867, acc=0.6246111392974854, loss=1.2158079147338867
test: epoch 57, loss 2.200859308242798, acc=0.26944443583488464, loss=2.200859308242798
train: epoch 58, loss 1.2062312364578247, acc=0.633388876914978, loss=1.2062312364578247
test: epoch 58, loss 2.0421125888824463, acc=0.2750000059604645, loss=2.0421125888824463
train: epoch 59, loss 1.193393588066101, acc=0.6480555534362793, loss=1.193393588066101
test: epoch 59, loss 2.1261885166168213, acc=0.27222222089767456, loss=2.1261885166168213
train: epoch 60, loss 1.147371530532837, acc=0.6554444432258606, loss=1.147371530532837
test: epoch 60, loss 2.0984714031219482, acc=0.2611111104488373, loss=2.0984714031219482
train: epoch 61, loss 1.1736230850219727, acc=0.6552222371101379, loss=1.1736230850219727
test: epoch 61, loss 2.0514965057373047, acc=0.2916666567325592, loss=2.0514965057373047
train: epoch 62, loss 1.1293779611587524, acc=0.6691111326217651, loss=1.1293779611587524
test: epoch 62, loss 2.007874011993408, acc=0.2916666567325592, loss=2.007874011993408
train: epoch 63, loss 1.1513705253601074, acc=0.6661111116409302, loss=1.1513705253601074
test: epoch 63, loss 2.0049045085906982, acc=0.2805555462837219, loss=2.0049045085906982
train: epoch 64, loss 1.1095260381698608, acc=0.6746110916137695, loss=1.1095260381698608
test: epoch 64, loss 1.9888075590133667, acc=0.3083333373069763, loss=1.9888075590133667
train: epoch 65, loss 1.1221365928649902, acc=0.6846666932106018, loss=1.1221365928649902
test: epoch 65, loss 1.9083852767944336, acc=0.2944444417953491, loss=1.9083852767944336
train: epoch 66, loss 1.120227336883545, acc=0.6875, loss=1.120227336883545
test: epoch 66, loss 1.972856879234314, acc=0.2916666567325592, loss=1.972856879234314
train: epoch 67, loss 1.0986636877059937, acc=0.6902777552604675, loss=1.0986636877059937
test: epoch 67, loss 1.918853759765625, acc=0.2944444417953491, loss=1.918853759765625
train: epoch 68, loss 1.1277402639389038, acc=0.6893888711929321, loss=1.1277402639389038
test: epoch 68, loss 1.8894606828689575, acc=0.3055555522441864, loss=1.8894606828689575
train: epoch 69, loss 1.061525821685791, acc=0.6967222094535828, loss=1.061525821685791
test: epoch 69, loss 1.851424217224121, acc=0.3027777671813965, loss=1.851424217224121
train: epoch 70, loss 1.0723432302474976, acc=0.6968888640403748, loss=1.0723432302474976
test: epoch 70, loss 1.8466944694519043, acc=0.31388887763023376, loss=1.8466944694519043
train: epoch 71, loss 1.0686297416687012, acc=0.7065555453300476, loss=1.0686297416687012
test: epoch 71, loss 1.8475967645645142, acc=0.31111112236976624, loss=1.8475967645645142
train: epoch 72, loss 1.041498064994812, acc=0.7145000100135803, loss=1.041498064994812
test: epoch 72, loss 1.8478446006774902, acc=0.3222222328186035, loss=1.8478446006774902
train: epoch 73, loss 1.0380529165267944, acc=0.7187222242355347, loss=1.0380529165267944
test: epoch 73, loss 1.837988018989563, acc=0.3194444477558136, loss=1.837988018989563
train: epoch 74, loss 1.0180381536483765, acc=0.714555561542511, loss=1.0180381536483765
test: epoch 74, loss 1.8210880756378174, acc=0.3222222328186035, loss=1.8210880756378174
train: epoch 75, loss 1.0128614902496338, acc=0.7214999794960022, loss=1.0128614902496338
test: epoch 75, loss 1.7688734531402588, acc=0.32499998807907104, loss=1.7688734531402588
train: epoch 76, loss 1.0301623344421387, acc=0.7212777733802795, loss=1.0301623344421387
test: epoch 76, loss 1.7649821043014526, acc=0.33888888359069824, loss=1.7649821043014526
train: epoch 77, loss 1.0035083293914795, acc=0.7253888845443726, loss=1.0035083293914795
test: epoch 77, loss 1.7654812335968018, acc=0.3305555582046509, loss=1.7654812335968018
train: epoch 78, loss 1.0339866876602173, acc=0.7236111164093018, loss=1.0339866876602173
test: epoch 78, loss 1.772626280784607, acc=0.34166666865348816, loss=1.772626280784607
train: epoch 79, loss 0.9732056856155396, acc=0.7350000143051147, loss=0.9732056856155396
test: epoch 79, loss 1.7043665647506714, acc=0.3472222089767456, loss=1.7043665647506714
train: epoch 80, loss 0.9718601107597351, acc=0.7352777719497681, loss=0.9718601107597351
test: epoch 80, loss 1.7116750478744507, acc=0.3444444537162781, loss=1.7116750478744507
train: epoch 81, loss 0.9783394932746887, acc=0.7339444160461426, loss=0.9783394932746887
test: epoch 81, loss 1.704373836517334, acc=0.33888888359069824, loss=1.704373836517334
train: epoch 82, loss 0.9764431715011597, acc=0.7374444603919983, loss=0.9764431715011597
test: epoch 82, loss 1.675836205482483, acc=0.33888888359069824, loss=1.675836205482483
train: epoch 83, loss 0.9560486078262329, acc=0.7389444708824158, loss=0.9560486078262329
test: epoch 83, loss 1.6418706178665161, acc=0.3472222089767456, loss=1.6418706178665161
train: epoch 84, loss 0.9633841514587402, acc=0.7412222027778625, loss=0.9633841514587402
test: epoch 84, loss 1.6322591304779053, acc=0.3499999940395355, loss=1.6322591304779053
train: epoch 85, loss 0.9555636048316956, acc=0.7459999918937683, loss=0.9555636048316956
test: epoch 85, loss 1.5879546403884888, acc=0.3583333194255829, loss=1.5879546403884888
train: epoch 86, loss 0.9552252292633057, acc=0.7438889145851135, loss=0.9552252292633057
test: epoch 86, loss 1.6001161336898804, acc=0.36666667461395264, loss=1.6001161336898804
train: epoch 87, loss 0.9506417512893677, acc=0.74144446849823, loss=0.9506417512893677
test: epoch 87, loss 1.5477027893066406, acc=0.36944442987442017, loss=1.5477027893066406
train: epoch 88, loss 0.9568248391151428, acc=0.7459444403648376, loss=0.9568248391151428
test: epoch 88, loss 1.5532190799713135, acc=0.36666667461395264, loss=1.5532190799713135
train: epoch 89, loss 0.9518803358078003, acc=0.7457777857780457, loss=0.9518803358078003
test: epoch 89, loss 1.5478808879852295, acc=0.36944442987442017, loss=1.5478808879852295
train: epoch 90, loss 0.9353086352348328, acc=0.7491666674613953, loss=0.9353086352348328
test: epoch 90, loss 1.526529312133789, acc=0.39444443583488464, loss=1.526529312133789
train: epoch 91, loss 0.9386502504348755, acc=0.7486110925674438, loss=0.9386502504348755
test: epoch 91, loss 1.5025711059570312, acc=0.38333332538604736, loss=1.5025711059570312
train: epoch 92, loss 0.9392196536064148, acc=0.7475000023841858, loss=0.9392196536064148
test: epoch 92, loss 1.530274510383606, acc=0.3777777850627899, loss=1.530274510383606
train: epoch 93, loss 0.9173731803894043, acc=0.7532777786254883, loss=0.9173731803894043
test: epoch 93, loss 1.4852176904678345, acc=0.3916666805744171, loss=1.4852176904678345
train: epoch 94, loss 0.9092205166816711, acc=0.7553333044052124, loss=0.9092205166816711
test: epoch 94, loss 1.4609858989715576, acc=0.39444443583488464, loss=1.4609858989715576
train: epoch 95, loss 0.9183489680290222, acc=0.753166675567627, loss=0.9183489680290222
test: epoch 95, loss 1.464952826499939, acc=0.3916666805744171, loss=1.464952826499939
train: epoch 96, loss 0.9246514439582825, acc=0.7518888711929321, loss=0.9246514439582825
test: epoch 96, loss 1.436348557472229, acc=0.39444443583488464, loss=1.436348557472229
train: epoch 97, loss 0.934260904788971, acc=0.7508888840675354, loss=0.934260904788971
test: epoch 97, loss 1.4366838932037354, acc=0.39722222089767456, loss=1.4366838932037354
train: epoch 98, loss 0.902321994304657, acc=0.7527222037315369, loss=0.902321994304657
test: epoch 98, loss 1.4237605333328247, acc=0.4055555462837219, loss=1.4237605333328247
train: epoch 99, loss 0.9211380481719971, acc=0.7511666417121887, loss=0.9211380481719971
test: epoch 99, loss 1.413596510887146, acc=0.4138889014720917, loss=1.413596510887146
train: epoch 100, loss 0.8832495808601379, acc=0.7560555338859558, loss=0.8832495808601379
test: epoch 100, loss 1.375686526298523, acc=0.4194444417953491, loss=1.375686526298523
train: epoch 101, loss 0.8882836699485779, acc=0.7600555419921875, loss=0.8882836699485779
test: epoch 101, loss 1.4090934991836548, acc=0.39444443583488464, loss=1.4090934991836548
train: epoch 102, loss 0.8948851823806763, acc=0.7603333592414856, loss=0.8948851823806763
test: epoch 102, loss 1.3924943208694458, acc=0.41111111640930176, loss=1.3924943208694458
train: epoch 103, loss 0.8933499455451965, acc=0.7622222304344177, loss=0.8933499455451965
test: epoch 103, loss 1.3631341457366943, acc=0.41111111640930176, loss=1.3631341457366943
train: epoch 104, loss 0.8857503533363342, acc=0.7620000243186951, loss=0.8857503533363342
test: epoch 104, loss 1.3849178552627563, acc=0.4138889014720917, loss=1.3849178552627563
train: epoch 105, loss 0.8541607856750488, acc=0.7723888754844666, loss=0.8541607856750488
test: epoch 105, loss 1.3563412427902222, acc=0.42500001192092896, loss=1.3563412427902222
train: epoch 106, loss 0.8456364274024963, acc=0.7730000019073486, loss=0.8456364274024963
test: epoch 106, loss 1.3757230043411255, acc=0.42500001192092896, loss=1.3757230043411255
train: epoch 107, loss 0.8589473366737366, acc=0.7720000147819519, loss=0.8589473366737366
test: epoch 107, loss 1.377118706703186, acc=0.43611112236976624, loss=1.377118706703186
train: epoch 108, loss 0.8627493977546692, acc=0.7745000123977661, loss=0.8627493977546692
test: epoch 108, loss 1.364585518836975, acc=0.4444444477558136, loss=1.364585518836975
train: epoch 109, loss 0.836420476436615, acc=0.7708888649940491, loss=0.836420476436615
test: epoch 109, loss 1.334120512008667, acc=0.43888887763023376, loss=1.334120512008667
train: epoch 110, loss 0.823804497718811, acc=0.777222216129303, loss=0.823804497718811
test: epoch 110, loss 1.3095948696136475, acc=0.45277777314186096, loss=1.3095948696136475
train: epoch 111, loss 0.8169330358505249, acc=0.7823333144187927, loss=0.8169330358505249
test: epoch 111, loss 1.3054877519607544, acc=0.43888887763023376, loss=1.3054877519607544
train: epoch 112, loss 0.786956787109375, acc=0.7871111035346985, loss=0.786956787109375
test: epoch 112, loss 1.3188797235488892, acc=0.4472222328186035, loss=1.3188797235488892
train: epoch 113, loss 0.7901327013969421, acc=0.7919999957084656, loss=0.7901327013969421
test: epoch 113, loss 1.3423359394073486, acc=0.4444444477558136, loss=1.3423359394073486
train: epoch 114, loss 0.7860786318778992, acc=0.7902222275733948, loss=0.7860786318778992
test: epoch 114, loss 1.3344361782073975, acc=0.43611112236976624, loss=1.3344361782073975
train: epoch 115, loss 0.7801570892333984, acc=0.7901666760444641, loss=0.7801570892333984
test: epoch 115, loss 1.3290014266967773, acc=0.43611112236976624, loss=1.3290014266967773
train: epoch 116, loss 0.7817280888557434, acc=0.7913333177566528, loss=0.7817280888557434
test: epoch 116, loss 1.2714208364486694, acc=0.4444444477558136, loss=1.2714208364486694
train: epoch 117, loss 0.7613949179649353, acc=0.7921110987663269, loss=0.7613949179649353
test: epoch 117, loss 1.3138262033462524, acc=0.43888887763023376, loss=1.3138262033462524
train: epoch 118, loss 0.7804781794548035, acc=0.7979444265365601, loss=0.7804781794548035
test: epoch 118, loss 1.2864582538604736, acc=0.44999998807907104, loss=1.2864582538604736
train: epoch 119, loss 0.7544845938682556, acc=0.8018333315849304, loss=0.7544845938682556
test: epoch 119, loss 1.3025213479995728, acc=0.4472222328186035, loss=1.3025213479995728
train: epoch 120, loss 0.7535592317581177, acc=0.8052777647972107, loss=0.7535592317581177
test: epoch 120, loss 1.291099190711975, acc=0.4583333432674408, loss=1.291099190711975
train: epoch 121, loss 0.7282127737998962, acc=0.8065555691719055, loss=0.7282127737998962
test: epoch 121, loss 1.2741334438323975, acc=0.46666666865348816, loss=1.2741334438323975
train: epoch 122, loss 0.7161871194839478, acc=0.8115000128746033, loss=0.7161871194839478
test: epoch 122, loss 1.2688274383544922, acc=0.46388888359069824, loss=1.2688274383544922
train: epoch 123, loss 0.7417449951171875, acc=0.8054999709129333, loss=0.7417449951171875
test: epoch 123, loss 1.2790201902389526, acc=0.46388888359069824, loss=1.2790201902389526
train: epoch 124, loss 0.7081753015518188, acc=0.8086666464805603, loss=0.7081753015518188
test: epoch 124, loss 1.2604701519012451, acc=0.45277777314186096, loss=1.2604701519012451
train: epoch 125, loss 0.7045435309410095, acc=0.8153889179229736, loss=0.7045435309410095
test: epoch 125, loss 1.279613733291626, acc=0.4583333432674408, loss=1.279613733291626
train: epoch 126, loss 0.719957172870636, acc=0.8148888945579529, loss=0.719957172870636
test: epoch 126, loss 1.2463099956512451, acc=0.4694444537162781, loss=1.2463099956512451
train: epoch 127, loss 0.706375777721405, acc=0.812666654586792, loss=0.706375777721405
test: epoch 127, loss 1.2611593008041382, acc=0.4694444537162781, loss=1.2611593008041382
train: epoch 128, loss 0.701169490814209, acc=0.812333345413208, loss=0.701169490814209
test: epoch 128, loss 1.2713578939437866, acc=0.4611110985279083, loss=1.2713578939437866
train: epoch 129, loss 0.7156514525413513, acc=0.8176110982894897, loss=0.7156514525413513
test: epoch 129, loss 1.2495790719985962, acc=0.4722222089767456, loss=1.2495790719985962
train: epoch 130, loss 0.6984149813652039, acc=0.8155555725097656, loss=0.6984149813652039
test: epoch 130, loss 1.2588216066360474, acc=0.4694444537162781, loss=1.2588216066360474
train: epoch 131, loss 0.6992347240447998, acc=0.8195555806159973, loss=0.6992347240447998
test: epoch 131, loss 1.2482497692108154, acc=0.4611110985279083, loss=1.2482497692108154
train: epoch 132, loss 0.6773809790611267, acc=0.8223888874053955, loss=0.6773809790611267
test: epoch 132, loss 1.2496917247772217, acc=0.4611110985279083, loss=1.2496917247772217
train: epoch 133, loss 0.6489017009735107, acc=0.8268888592720032, loss=0.6489017009735107
test: epoch 133, loss 1.2368005514144897, acc=0.46388888359069824, loss=1.2368005514144897
train: epoch 134, loss 0.6678152084350586, acc=0.8243333101272583, loss=0.6678152084350586
test: epoch 134, loss 1.2372410297393799, acc=0.47777777910232544, loss=1.2372410297393799
train: epoch 135, loss 0.6365838050842285, acc=0.828499972820282, loss=0.6365838050842285
test: epoch 135, loss 1.2429862022399902, acc=0.46666666865348816, loss=1.2429862022399902
train: epoch 136, loss 0.6344892978668213, acc=0.8329444527626038, loss=0.6344892978668213
test: epoch 136, loss 1.228378415107727, acc=0.4861111044883728, loss=1.228378415107727
train: epoch 137, loss 0.626617968082428, acc=0.8335555791854858, loss=0.626617968082428
test: epoch 137, loss 1.2324626445770264, acc=0.4694444537162781, loss=1.2324626445770264
train: epoch 138, loss 0.6254856586456299, acc=0.8335555791854858, loss=0.6254856586456299
test: epoch 138, loss 1.1841665506362915, acc=0.48055556416511536, loss=1.1841665506362915
train: epoch 139, loss 0.6262907385826111, acc=0.8331666588783264, loss=0.6262907385826111
test: epoch 139, loss 1.1917834281921387, acc=0.4888888895511627, loss=1.1917834281921387
train: epoch 140, loss 0.6066877841949463, acc=0.8373888731002808, loss=0.6066877841949463
test: epoch 140, loss 1.1959978342056274, acc=0.4833333194255829, loss=1.1959978342056274
train: epoch 141, loss 0.607348620891571, acc=0.8372777700424194, loss=0.607348620891571
test: epoch 141, loss 1.1959304809570312, acc=0.5, loss=1.1959304809570312
train: epoch 142, loss 0.6358610987663269, acc=0.8361111283302307, loss=0.6358610987663269
test: epoch 142, loss 1.1974124908447266, acc=0.4888888895511627, loss=1.1974124908447266
train: epoch 143, loss 0.6015046238899231, acc=0.8414999842643738, loss=0.6015046238899231
test: epoch 143, loss 1.2252131700515747, acc=0.5, loss=1.2252131700515747
train: epoch 144, loss 0.6260476112365723, acc=0.8387777805328369, loss=0.6260476112365723
test: epoch 144, loss 1.2331888675689697, acc=0.47777777910232544, loss=1.2331888675689697
train: epoch 145, loss 0.5986545085906982, acc=0.8446111083030701, loss=0.5986545085906982
test: epoch 145, loss 1.2153981924057007, acc=0.4888888895511627, loss=1.2153981924057007
train: epoch 146, loss 0.5943067073822021, acc=0.843500018119812, loss=0.5943067073822021
test: epoch 146, loss 1.1763397455215454, acc=0.49444442987442017, loss=1.1763397455215454
train: epoch 147, loss 0.589719831943512, acc=0.8467222452163696, loss=0.589719831943512
test: epoch 147, loss 1.1987950801849365, acc=0.49166667461395264, loss=1.1987950801849365
train: epoch 148, loss 0.5910948514938354, acc=0.8455555438995361, loss=0.5910948514938354
test: epoch 148, loss 1.1840465068817139, acc=0.49166667461395264, loss=1.1840465068817139
train: epoch 149, loss 0.587414562702179, acc=0.8456666469573975, loss=0.587414562702179
test: epoch 149, loss 1.1920605897903442, acc=0.5027777552604675, loss=1.1920605897903442
train: epoch 150, loss 0.5877009034156799, acc=0.8487222194671631, loss=0.5877009034156799
test: epoch 150, loss 1.1982485055923462, acc=0.48055556416511536, loss=1.1982485055923462
