# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=1", "--one_hot=1", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=1153958890, receiver_embed_dim=32, save_run=0, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1153958890, receiver_embed_dim=32, save_run=False, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.985947370529175, acc=0.09316666424274445, loss=2.985947370529175
test: epoch 1, loss 4.946120262145996, acc=0.07500000298023224, loss=4.946120262145996
train: epoch 2, loss 1.9610947370529175, acc=0.23777778446674347, loss=1.9610947370529175
test: epoch 2, loss 4.496335983276367, acc=0.13611111044883728, loss=4.496335983276367
train: epoch 3, loss 1.597339391708374, acc=0.328166663646698, loss=1.597339391708374
test: epoch 3, loss 4.219054222106934, acc=0.17222222685813904, loss=4.219054222106934
train: epoch 4, loss 1.352337121963501, acc=0.4237777888774872, loss=1.352337121963501
test: epoch 4, loss 5.337584018707275, acc=0.1388888955116272, loss=5.337584018707275
train: epoch 5, loss 1.0711809396743774, acc=0.5502222180366516, loss=1.0711809396743774
test: epoch 5, loss 5.637639999389648, acc=0.15000000596046448, loss=5.637639999389648
train: epoch 6, loss 0.8734745979309082, acc=0.6398333311080933, loss=0.8734745979309082
test: epoch 6, loss 4.488249778747559, acc=0.15000000596046448, loss=4.488249778747559
train: epoch 7, loss 0.7379182577133179, acc=0.6972222328186035, loss=0.7379182577133179
test: epoch 7, loss 5.238437175750732, acc=0.2361111044883728, loss=5.238437175750732
train: epoch 8, loss 0.6387835741043091, acc=0.7488889098167419, loss=0.6387835741043091
test: epoch 8, loss 5.181029796600342, acc=0.24166665971279144, loss=5.181029796600342
train: epoch 9, loss 0.5637869238853455, acc=0.7795555591583252, loss=0.5637869238853455
test: epoch 9, loss 4.633528232574463, acc=0.18888889253139496, loss=4.633528232574463
train: epoch 10, loss 0.4985348880290985, acc=0.8161110877990723, loss=0.4985348880290985
test: epoch 10, loss 5.678095817565918, acc=0.25555557012557983, loss=5.678095817565918
train: epoch 11, loss 0.4315800666809082, acc=0.8452222347259521, loss=0.4315800666809082
test: epoch 11, loss 4.6843180656433105, acc=0.24722221493721008, loss=4.6843180656433105
train: epoch 12, loss 0.3833777606487274, acc=0.8676111102104187, loss=0.3833777606487274
test: epoch 12, loss 6.5879106521606445, acc=0.19722221791744232, loss=6.5879106521606445
train: epoch 13, loss 0.3387141525745392, acc=0.8813333511352539, loss=0.3387141525745392
test: epoch 13, loss 5.501936912536621, acc=0.25555557012557983, loss=5.501936912536621
train: epoch 14, loss 0.2956777513027191, acc=0.902055561542511, loss=0.2956777513027191
test: epoch 14, loss 4.990050792694092, acc=0.22777777910232544, loss=4.990050792694092
train: epoch 15, loss 0.2764721214771271, acc=0.9079999923706055, loss=0.2764721214771271
test: epoch 15, loss 4.914510726928711, acc=0.2888889014720917, loss=4.914510726928711
train: epoch 16, loss 0.24236221611499786, acc=0.9188888669013977, loss=0.24236221611499786
test: epoch 16, loss 4.055602550506592, acc=0.2888889014720917, loss=4.055602550506592
train: epoch 17, loss 0.23751422762870789, acc=0.9236111044883728, loss=0.23751422762870789
test: epoch 17, loss 3.8263652324676514, acc=0.3027777671813965, loss=3.8263652324676514
train: epoch 18, loss 0.21815125644207, acc=0.9290555715560913, loss=0.21815125644207
test: epoch 18, loss 4.113179683685303, acc=0.2916666567325592, loss=4.113179683685303
train: epoch 19, loss 0.20909450948238373, acc=0.9334444403648376, loss=0.20909450948238373
test: epoch 19, loss 3.8239705562591553, acc=0.3055555522441864, loss=3.8239705562591553
train: epoch 20, loss 0.19232186675071716, acc=0.9367222189903259, loss=0.19232186675071716
test: epoch 20, loss 3.773604393005371, acc=0.2916666567325592, loss=3.773604393005371
train: epoch 21, loss 0.18413659930229187, acc=0.9434444308280945, loss=0.18413659930229187
test: epoch 21, loss 3.8590197563171387, acc=0.31111112236976624, loss=3.8590197563171387
train: epoch 22, loss 0.17933069169521332, acc=0.9438889026641846, loss=0.17933069169521332
test: epoch 22, loss 2.787174940109253, acc=0.43888887763023376, loss=2.787174940109253
train: epoch 23, loss 0.17515726387500763, acc=0.9447222352027893, loss=0.17515726387500763
test: epoch 23, loss 4.59023380279541, acc=0.28611111640930176, loss=4.59023380279541
train: epoch 24, loss 0.17022651433944702, acc=0.9482222199440002, loss=0.17022651433944702
test: epoch 24, loss 3.2767701148986816, acc=0.3722222149372101, loss=3.2767701148986816
train: epoch 25, loss 0.15450718998908997, acc=0.9507222175598145, loss=0.15450718998908997
test: epoch 25, loss 3.197575569152832, acc=0.39444443583488464, loss=3.197575569152832
train: epoch 26, loss 0.14870958030223846, acc=0.9535555839538574, loss=0.14870958030223846
test: epoch 26, loss 3.2277920246124268, acc=0.33888888359069824, loss=3.2277920246124268
train: epoch 27, loss 0.1469118297100067, acc=0.9530555605888367, loss=0.1469118297100067
test: epoch 27, loss 2.6193981170654297, acc=0.4000000059604645, loss=2.6193981170654297
train: epoch 28, loss 0.13595689833164215, acc=0.9573888778686523, loss=0.13595689833164215
test: epoch 28, loss 3.0756964683532715, acc=0.2750000059604645, loss=3.0756964683532715
train: epoch 29, loss 0.1272491216659546, acc=0.9608333110809326, loss=0.1272491216659546
test: epoch 29, loss 3.176176071166992, acc=0.36666667461395264, loss=3.176176071166992
train: epoch 30, loss 0.13967782258987427, acc=0.9581666588783264, loss=0.13967782258987427
test: epoch 30, loss 2.7908623218536377, acc=0.4194444417953491, loss=2.7908623218536377
train: epoch 31, loss 0.12879042327404022, acc=0.9608333110809326, loss=0.12879042327404022
test: epoch 31, loss 2.8312788009643555, acc=0.32777777314186096, loss=2.8312788009643555
train: epoch 32, loss 0.10283812880516052, acc=0.968833327293396, loss=0.10283812880516052
test: epoch 32, loss 3.01241397857666, acc=0.4166666567325592, loss=3.01241397857666
train: epoch 33, loss 0.12095747888088226, acc=0.9647777676582336, loss=0.12095747888088226
test: epoch 33, loss 4.021213054656982, acc=0.3333333432674408, loss=4.021213054656982
train: epoch 34, loss 0.11792731285095215, acc=0.9653888940811157, loss=0.11792731285095215
test: epoch 34, loss 2.293827772140503, acc=0.4861111044883728, loss=2.293827772140503
train: epoch 35, loss 0.1213165670633316, acc=0.9667222499847412, loss=0.1213165670633316
test: epoch 35, loss 3.105367660522461, acc=0.3777777850627899, loss=3.105367660522461
train: epoch 36, loss 0.12429974973201752, acc=0.964555561542511, loss=0.12429974973201752
test: epoch 36, loss 2.8933968544006348, acc=0.4472222328186035, loss=2.8933968544006348
train: epoch 37, loss 0.0957530289888382, acc=0.9731666445732117, loss=0.0957530289888382
test: epoch 37, loss 2.626332998275757, acc=0.4194444417953491, loss=2.626332998275757
train: epoch 38, loss 0.09808024764060974, acc=0.9702777862548828, loss=0.09808024764060974
test: epoch 38, loss 2.7807235717773438, acc=0.38055557012557983, loss=2.7807235717773438
train: epoch 39, loss 0.10614467412233353, acc=0.9683333039283752, loss=0.10614467412233353
test: epoch 39, loss 2.6051385402679443, acc=0.35555556416511536, loss=2.6051385402679443
train: epoch 40, loss 0.10020261257886887, acc=0.9703888893127441, loss=0.10020261257886887
test: epoch 40, loss 3.226153612136841, acc=0.3722222149372101, loss=3.226153612136841
train: epoch 41, loss 0.097137451171875, acc=0.9698888659477234, loss=0.097137451171875
test: epoch 41, loss 2.071845531463623, acc=0.5027777552604675, loss=2.071845531463623
train: epoch 42, loss 0.08250400424003601, acc=0.9756666421890259, loss=0.08250400424003601
test: epoch 42, loss 2.138576030731201, acc=0.4972222149372101, loss=2.138576030731201
train: epoch 43, loss 0.08504065871238708, acc=0.9753333330154419, loss=0.08504065871238708
test: epoch 43, loss 2.7237093448638916, acc=0.38333332538604736, loss=2.7237093448638916
train: epoch 44, loss 0.07931205630302429, acc=0.9764444231987, loss=0.07931205630302429
test: epoch 44, loss 2.4007315635681152, acc=0.4027777910232544, loss=2.4007315635681152
train: epoch 45, loss 0.09836584329605103, acc=0.972611129283905, loss=0.09836584329605103
test: epoch 45, loss 1.8531012535095215, acc=0.5138888955116272, loss=1.8531012535095215
train: epoch 46, loss 0.07366400957107544, acc=0.976722240447998, loss=0.07366400957107544
test: epoch 46, loss 2.8133983612060547, acc=0.4472222328186035, loss=2.8133983612060547
train: epoch 47, loss 0.08172990381717682, acc=0.9768333435058594, loss=0.08172990381717682
test: epoch 47, loss 2.8160831928253174, acc=0.5222222208976746, loss=2.8160831928253174
train: epoch 48, loss 0.07451290637254715, acc=0.9783333539962769, loss=0.07451290637254715
test: epoch 48, loss 2.6617279052734375, acc=0.4555555582046509, loss=2.6617279052734375
train: epoch 49, loss 0.0765383243560791, acc=0.9767777919769287, loss=0.0765383243560791
test: epoch 49, loss 2.7306721210479736, acc=0.4277777671813965, loss=2.7306721210479736
train: epoch 50, loss 0.07305706292390823, acc=0.9787777662277222, loss=0.07305706292390823
test: epoch 50, loss 2.632110595703125, acc=0.49166667461395264, loss=2.632110595703125
train: epoch 51, loss 0.07465953379869461, acc=0.9789444208145142, loss=0.07465953379869461
test: epoch 51, loss 2.0478289127349854, acc=0.47777777910232544, loss=2.0478289127349854
train: epoch 52, loss 0.07189588993787766, acc=0.9785000085830688, loss=0.07189588993787766
test: epoch 52, loss 2.3745622634887695, acc=0.3777777850627899, loss=2.3745622634887695
train: epoch 53, loss 0.06699829548597336, acc=0.980388879776001, loss=0.06699829548597336
test: epoch 53, loss 2.967890739440918, acc=0.4000000059604645, loss=2.967890739440918
train: epoch 54, loss 0.07212958484888077, acc=0.9792222380638123, loss=0.07212958484888077
test: epoch 54, loss 2.25846529006958, acc=0.5027777552604675, loss=2.25846529006958
train: epoch 55, loss 0.06764714419841766, acc=0.979888916015625, loss=0.06764714419841766
test: epoch 55, loss 2.3892810344696045, acc=0.3777777850627899, loss=2.3892810344696045
train: epoch 56, loss 0.06875194609165192, acc=0.9810555577278137, loss=0.06875194609165192
test: epoch 56, loss 2.5019514560699463, acc=0.43888887763023376, loss=2.5019514560699463
train: epoch 57, loss 0.05466384068131447, acc=0.9842222332954407, loss=0.05466384068131447
test: epoch 57, loss 2.319509506225586, acc=0.4749999940395355, loss=2.319509506225586
train: epoch 58, loss 0.05941629037261009, acc=0.9839444160461426, loss=0.05941629037261009
test: epoch 58, loss 2.5702133178710938, acc=0.4749999940395355, loss=2.5702133178710938
train: epoch 59, loss 0.07302316278219223, acc=0.9797777533531189, loss=0.07302316278219223
test: epoch 59, loss 3.134168863296509, acc=0.4416666626930237, loss=3.134168863296509
train: epoch 60, loss 0.059471335262060165, acc=0.984000027179718, loss=0.059471335262060165
test: epoch 60, loss 2.1670854091644287, acc=0.5083333253860474, loss=2.1670854091644287
train: epoch 61, loss 0.05849849805235863, acc=0.9825000166893005, loss=0.05849849805235863
test: epoch 61, loss 2.31062388420105, acc=0.5249999761581421, loss=2.31062388420105
train: epoch 62, loss 0.05493095517158508, acc=0.9858888983726501, loss=0.05493095517158508
test: epoch 62, loss 2.6547069549560547, acc=0.4749999940395355, loss=2.6547069549560547
train: epoch 63, loss 0.06603343039751053, acc=0.9807778000831604, loss=0.06603343039751053
test: epoch 63, loss 3.281911611557007, acc=0.49444442987442017, loss=3.281911611557007
train: epoch 64, loss 0.04977035149931908, acc=0.9854444265365601, loss=0.04977035149931908
test: epoch 64, loss 2.130903959274292, acc=0.4749999940395355, loss=2.130903959274292
train: epoch 65, loss 0.05767398327589035, acc=0.9836111068725586, loss=0.05767398327589035
test: epoch 65, loss 2.998312473297119, acc=0.4888888895511627, loss=2.998312473297119
train: epoch 66, loss 0.060286372900009155, acc=0.9836666584014893, loss=0.060286372900009155
test: epoch 66, loss 2.212076187133789, acc=0.5111111402511597, loss=2.212076187133789
train: epoch 67, loss 0.051544565707445145, acc=0.9863333106040955, loss=0.051544565707445145
test: epoch 67, loss 2.2902402877807617, acc=0.5222222208976746, loss=2.2902402877807617
train: epoch 68, loss 0.04391917958855629, acc=0.9868888854980469, loss=0.04391917958855629
test: epoch 68, loss 1.8232561349868774, acc=0.519444465637207, loss=1.8232561349868774
train: epoch 69, loss 0.05063698813319206, acc=0.9857222437858582, loss=0.05063698813319206
test: epoch 69, loss 2.2831954956054688, acc=0.46666666865348816, loss=2.2831954956054688
train: epoch 70, loss 0.05013510212302208, acc=0.9865000247955322, loss=0.05013510212302208
test: epoch 70, loss 2.040983200073242, acc=0.4583333432674408, loss=2.040983200073242
train: epoch 71, loss 0.047951724380254745, acc=0.9856666922569275, loss=0.047951724380254745
test: epoch 71, loss 2.3153789043426514, acc=0.46388888359069824, loss=2.3153789043426514
train: epoch 72, loss 0.04363853484392166, acc=0.987333357334137, loss=0.04363853484392166
test: epoch 72, loss 2.55855131149292, acc=0.46666666865348816, loss=2.55855131149292
train: epoch 73, loss 0.05322512239217758, acc=0.984666645526886, loss=0.05322512239217758
test: epoch 73, loss 2.4943156242370605, acc=0.5138888955116272, loss=2.4943156242370605
train: epoch 74, loss 0.0402667373418808, acc=0.9877222180366516, loss=0.0402667373418808
test: epoch 74, loss 2.2144315242767334, acc=0.4000000059604645, loss=2.2144315242767334
train: epoch 75, loss 0.04248829185962677, acc=0.9872221946716309, loss=0.04248829185962677
test: epoch 75, loss 2.0292227268218994, acc=0.46666666865348816, loss=2.0292227268218994
train: epoch 76, loss 0.05548162758350372, acc=0.9838888645172119, loss=0.05548162758350372
test: epoch 76, loss 2.712327003479004, acc=0.3472222089767456, loss=2.712327003479004
train: epoch 77, loss 0.036869678646326065, acc=0.9908888936042786, loss=0.036869678646326065
test: epoch 77, loss 2.148942470550537, acc=0.550000011920929, loss=2.148942470550537
train: epoch 78, loss 0.03737311437726021, acc=0.9898889064788818, loss=0.03737311437726021
test: epoch 78, loss 2.7220442295074463, acc=0.46666666865348816, loss=2.7220442295074463
train: epoch 79, loss 0.037540074437856674, acc=0.988277792930603, loss=0.037540074437856674
test: epoch 79, loss 2.860386610031128, acc=0.4694444537162781, loss=2.860386610031128
train: epoch 80, loss 0.044256821274757385, acc=0.9877777695655823, loss=0.044256821274757385
test: epoch 80, loss 2.15763258934021, acc=0.49444442987442017, loss=2.15763258934021
train: epoch 81, loss 0.03386204317212105, acc=0.9889444708824158, loss=0.03386204317212105
test: epoch 81, loss 2.2537992000579834, acc=0.4583333432674408, loss=2.2537992000579834
train: epoch 82, loss 0.0558500736951828, acc=0.9856111407279968, loss=0.0558500736951828
test: epoch 82, loss 2.093005418777466, acc=0.49444442987442017, loss=2.093005418777466
train: epoch 83, loss 0.04757639020681381, acc=0.9866111278533936, loss=0.04757639020681381
test: epoch 83, loss 2.40216064453125, acc=0.4861111044883728, loss=2.40216064453125
train: epoch 84, loss 0.03628482669591904, acc=0.9906111359596252, loss=0.03628482669591904
test: epoch 84, loss 2.3253438472747803, acc=0.4694444537162781, loss=2.3253438472747803
train: epoch 85, loss 0.043251361697912216, acc=0.9872221946716309, loss=0.043251361697912216
test: epoch 85, loss 1.6908830404281616, acc=0.5222222208976746, loss=1.6908830404281616
train: epoch 86, loss 0.04244397580623627, acc=0.9878888726234436, loss=0.04244397580623627
test: epoch 86, loss 2.0297646522521973, acc=0.4055555462837219, loss=2.0297646522521973
train: epoch 87, loss 0.044270195066928864, acc=0.9891666769981384, loss=0.044270195066928864
test: epoch 87, loss 2.208364486694336, acc=0.43888887763023376, loss=2.208364486694336
train: epoch 88, loss 0.031838931143283844, acc=0.9909444451332092, loss=0.031838931143283844
test: epoch 88, loss 1.4232683181762695, acc=0.4611110985279083, loss=1.4232683181762695
train: epoch 89, loss 0.04011758044362068, acc=0.987500011920929, loss=0.04011758044362068
test: epoch 89, loss 2.58548903465271, acc=0.5083333253860474, loss=2.58548903465271
train: epoch 90, loss 0.027624335139989853, acc=0.9925000071525574, loss=0.027624335139989853
test: epoch 90, loss 1.902073860168457, acc=0.5166666507720947, loss=1.902073860168457
train: epoch 91, loss 0.034362927079200745, acc=0.9909444451332092, loss=0.034362927079200745
test: epoch 91, loss 2.018845319747925, acc=0.5444444417953491, loss=2.018845319747925
train: epoch 92, loss 0.037718549370765686, acc=0.988777756690979, loss=0.037718549370765686
test: epoch 92, loss 3.2901558876037598, acc=0.4694444537162781, loss=3.2901558876037598
train: epoch 93, loss 0.032149914652109146, acc=0.9913333058357239, loss=0.032149914652109146
test: epoch 93, loss 2.214524030685425, acc=0.46666666865348816, loss=2.214524030685425
train: epoch 94, loss 0.029507365077733994, acc=0.9915000200271606, loss=0.029507365077733994
test: epoch 94, loss 1.9999291896820068, acc=0.5138888955116272, loss=1.9999291896820068
train: epoch 95, loss 0.037585508078336716, acc=0.9894444346427917, loss=0.037585508078336716
test: epoch 95, loss 2.254502296447754, acc=0.5166666507720947, loss=2.254502296447754
train: epoch 96, loss 0.040597423911094666, acc=0.988777756690979, loss=0.040597423911094666
test: epoch 96, loss 2.206470489501953, acc=0.4416666626930237, loss=2.206470489501953
train: epoch 97, loss 0.04269320145249367, acc=0.9886666536331177, loss=0.04269320145249367
test: epoch 97, loss 2.6964221000671387, acc=0.4722222089767456, loss=2.6964221000671387
train: epoch 98, loss 0.02694806642830372, acc=0.9923333525657654, loss=0.02694806642830372
test: epoch 98, loss 2.069326877593994, acc=0.49444442987442017, loss=2.069326877593994
train: epoch 99, loss 0.027130745351314545, acc=0.9924444556236267, loss=0.027130745351314545
test: epoch 99, loss 2.0740163326263428, acc=0.4888888895511627, loss=2.0740163326263428
train: epoch 100, loss 0.03175084665417671, acc=0.9909444451332092, loss=0.03175084665417671
test: epoch 100, loss 1.756667137145996, acc=0.550000011920929, loss=1.756667137145996
train: epoch 101, loss 0.03135015070438385, acc=0.9917222261428833, loss=0.03135015070438385
test: epoch 101, loss 2.128833770751953, acc=0.48055556416511536, loss=2.128833770751953
train: epoch 102, loss 0.02769528143107891, acc=0.99272221326828, loss=0.02769528143107891
test: epoch 102, loss 2.032522678375244, acc=0.43888887763023376, loss=2.032522678375244
train: epoch 103, loss 0.037199344485998154, acc=0.9904444217681885, loss=0.037199344485998154
test: epoch 103, loss 2.451977252960205, acc=0.45277777314186096, loss=2.451977252960205
train: epoch 104, loss 0.03453991562128067, acc=0.9906666874885559, loss=0.03453991562128067
test: epoch 104, loss 1.6431281566619873, acc=0.519444465637207, loss=1.6431281566619873
train: epoch 105, loss 0.02788318693637848, acc=0.9918333292007446, loss=0.02788318693637848
test: epoch 105, loss 1.9091967344284058, acc=0.4194444417953491, loss=1.9091967344284058
train: epoch 106, loss 0.034395795315504074, acc=0.9896666407585144, loss=0.034395795315504074
test: epoch 106, loss 1.5458693504333496, acc=0.5916666388511658, loss=1.5458693504333496
train: epoch 107, loss 0.03537098318338394, acc=0.9906111359596252, loss=0.03537098318338394
test: epoch 107, loss 2.1703362464904785, acc=0.4444444477558136, loss=2.1703362464904785
train: epoch 108, loss 0.022394400089979172, acc=0.9938889145851135, loss=0.022394400089979172
test: epoch 108, loss 2.357954740524292, acc=0.4694444537162781, loss=2.357954740524292
train: epoch 109, loss 0.030266255140304565, acc=0.9917222261428833, loss=0.030266255140304565
test: epoch 109, loss 2.6881067752838135, acc=0.4416666626930237, loss=2.6881067752838135
train: epoch 110, loss 0.03064762055873871, acc=0.9922778010368347, loss=0.03064762055873871
test: epoch 110, loss 2.60227370262146, acc=0.519444465637207, loss=2.60227370262146
train: epoch 111, loss 0.03330836445093155, acc=0.9903333187103271, loss=0.03330836445093155
test: epoch 111, loss 2.6825716495513916, acc=0.48055556416511536, loss=2.6825716495513916
train: epoch 112, loss 0.027827128767967224, acc=0.992888867855072, loss=0.027827128767967224
test: epoch 112, loss 2.771730661392212, acc=0.519444465637207, loss=2.771730661392212
train: epoch 113, loss 0.03136460483074188, acc=0.9913333058357239, loss=0.03136460483074188
test: epoch 113, loss 2.0350663661956787, acc=0.5027777552604675, loss=2.0350663661956787
train: epoch 114, loss 0.028750432655215263, acc=0.9932777881622314, loss=0.028750432655215263
test: epoch 114, loss 1.5659760236740112, acc=0.5166666507720947, loss=1.5659760236740112
train: epoch 115, loss 0.02792777493596077, acc=0.992388904094696, loss=0.02792777493596077
test: epoch 115, loss 1.8807512521743774, acc=0.4694444537162781, loss=1.8807512521743774
train: epoch 116, loss 0.027619443833827972, acc=0.9921666383743286, loss=0.027619443833827972
test: epoch 116, loss 1.6044073104858398, acc=0.5388888716697693, loss=1.6044073104858398
train: epoch 117, loss 0.02901121787726879, acc=0.9919999837875366, loss=0.02901121787726879
test: epoch 117, loss 1.3889307975769043, acc=0.5888888835906982, loss=1.3889307975769043
train: epoch 118, loss 0.028952818363904953, acc=0.9919999837875366, loss=0.028952818363904953
test: epoch 118, loss 1.250308632850647, acc=0.6416666507720947, loss=1.250308632850647
train: epoch 119, loss 0.025917991995811462, acc=0.9922778010368347, loss=0.025917991995811462
test: epoch 119, loss 2.0376029014587402, acc=0.49166667461395264, loss=2.0376029014587402
train: epoch 120, loss 0.02137724496424198, acc=0.9944444298744202, loss=0.02137724496424198
test: epoch 120, loss 2.227534770965576, acc=0.574999988079071, loss=2.227534770965576
train: epoch 121, loss 0.02381434664130211, acc=0.9922778010368347, loss=0.02381434664130211
test: epoch 121, loss 2.033972978591919, acc=0.5166666507720947, loss=2.033972978591919
train: epoch 122, loss 0.025981876999139786, acc=0.9915555715560913, loss=0.025981876999139786
test: epoch 122, loss 1.5466657876968384, acc=0.5916666388511658, loss=1.5466657876968384
train: epoch 123, loss 0.020527809858322144, acc=0.9944999814033508, loss=0.020527809858322144
test: epoch 123, loss 1.9974942207336426, acc=0.5444444417953491, loss=1.9974942207336426
train: epoch 124, loss 0.022471414878964424, acc=0.9938889145851135, loss=0.022471414878964424
test: epoch 124, loss 1.5260989665985107, acc=0.6111111044883728, loss=1.5260989665985107
train: epoch 125, loss 0.02518223412334919, acc=0.9929999709129333, loss=0.02518223412334919
test: epoch 125, loss 2.4473183155059814, acc=0.5611110925674438, loss=2.4473183155059814
train: epoch 126, loss 0.02067856676876545, acc=0.9940555691719055, loss=0.02067856676876545
test: epoch 126, loss 1.9348649978637695, acc=0.5277777910232544, loss=1.9348649978637695
train: epoch 127, loss 0.02546742372214794, acc=0.9936666488647461, loss=0.02546742372214794
test: epoch 127, loss 1.8963115215301514, acc=0.5444444417953491, loss=1.8963115215301514
train: epoch 128, loss 0.029415175318717957, acc=0.9932777881622314, loss=0.029415175318717957
test: epoch 128, loss 1.48894202709198, acc=0.5722222328186035, loss=1.48894202709198
train: epoch 129, loss 0.02320992387831211, acc=0.9933333396911621, loss=0.02320992387831211
test: epoch 129, loss 2.238877058029175, acc=0.5416666865348816, loss=2.238877058029175
train: epoch 130, loss 0.021774183958768845, acc=0.9941666722297668, loss=0.021774183958768845
test: epoch 130, loss 1.773957371711731, acc=0.605555534362793, loss=1.773957371711731
train: epoch 131, loss 0.028905222192406654, acc=0.992222249507904, loss=0.028905222192406654
test: epoch 131, loss 1.7227224111557007, acc=0.4749999940395355, loss=1.7227224111557007
train: epoch 132, loss 0.024347353726625443, acc=0.9935555458068848, loss=0.024347353726625443
test: epoch 132, loss 1.9923475980758667, acc=0.5583333373069763, loss=1.9923475980758667
train: epoch 133, loss 0.02330799214541912, acc=0.9933333396911621, loss=0.02330799214541912
test: epoch 133, loss 1.399079442024231, acc=0.6083333492279053, loss=1.399079442024231
train: epoch 134, loss 0.019035987555980682, acc=0.9951666593551636, loss=0.019035987555980682
test: epoch 134, loss 1.6534943580627441, acc=0.5277777910232544, loss=1.6534943580627441
train: epoch 135, loss 0.01979249343276024, acc=0.995888888835907, loss=0.01979249343276024
test: epoch 135, loss 1.275566816329956, acc=0.6277777552604675, loss=1.275566816329956
train: epoch 136, loss 0.029513927176594734, acc=0.9920555353164673, loss=0.029513927176594734
test: epoch 136, loss 2.2170345783233643, acc=0.574999988079071, loss=2.2170345783233643
train: epoch 137, loss 0.027743512764573097, acc=0.991944432258606, loss=0.027743512764573097
test: epoch 137, loss 1.571955680847168, acc=0.6027777791023254, loss=1.571955680847168
train: epoch 138, loss 0.016200056299567223, acc=0.9953888654708862, loss=0.016200056299567223
test: epoch 138, loss 1.934590220451355, acc=0.5611110925674438, loss=1.934590220451355
train: epoch 139, loss 0.026042712852358818, acc=0.9930555820465088, loss=0.026042712852358818
test: epoch 139, loss 1.4526755809783936, acc=0.6166666746139526, loss=1.4526755809783936
train: epoch 140, loss 0.021932102739810944, acc=0.9937222003936768, loss=0.021932102739810944
test: epoch 140, loss 1.3782258033752441, acc=0.6027777791023254, loss=1.3782258033752441
train: epoch 141, loss 0.02435106225311756, acc=0.9926666617393494, loss=0.02435106225311756
test: epoch 141, loss 1.8213169574737549, acc=0.5388888716697693, loss=1.8213169574737549
train: epoch 142, loss 0.0177724901586771, acc=0.995555579662323, loss=0.0177724901586771
test: epoch 142, loss 1.7200067043304443, acc=0.6111111044883728, loss=1.7200067043304443
train: epoch 143, loss 0.021405713632702827, acc=0.9948889017105103, loss=0.021405713632702827
test: epoch 143, loss 1.652379035949707, acc=0.6583333611488342, loss=1.652379035949707
train: epoch 144, loss 0.017697907984256744, acc=0.9948889017105103, loss=0.017697907984256744
test: epoch 144, loss 1.405003547668457, acc=0.625, loss=1.405003547668457
train: epoch 145, loss 0.011439511552453041, acc=0.9965000152587891, loss=0.011439511552453041
test: epoch 145, loss 1.4401758909225464, acc=0.6111111044883728, loss=1.4401758909225464
train: epoch 146, loss 0.0301729254424572, acc=0.9918888807296753, loss=0.0301729254424572
test: epoch 146, loss 1.63361656665802, acc=0.6722221970558167, loss=1.63361656665802
train: epoch 147, loss 0.02043108455836773, acc=0.9945555329322815, loss=0.02043108455836773
test: epoch 147, loss 1.494744896888733, acc=0.6111111044883728, loss=1.494744896888733
train: epoch 148, loss 0.02688666805624962, acc=0.99272221326828, loss=0.02688666805624962
test: epoch 148, loss 1.570615291595459, acc=0.644444465637207, loss=1.570615291595459
train: epoch 149, loss 0.01525135152041912, acc=0.996222198009491, loss=0.01525135152041912
test: epoch 149, loss 1.0711688995361328, acc=0.6611111164093018, loss=1.0711688995361328
train: epoch 150, loss 0.016892310231924057, acc=0.9954444169998169, loss=0.016892310231924057
test: epoch 150, loss 1.1308647394180298, acc=0.699999988079071, loss=1.1308647394180298
