# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=1.5", "--temp_decay=0.99", "--one_hot=1", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=113786446, receiver_embed_dim=128, save_run=0, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=113786446, receiver_embed_dim=128, save_run=False, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.7623534202575684, acc=0.11455555260181427, loss=2.7623534202575684
test: epoch 1, loss 3.0892727375030518, acc=0.11666666716337204, loss=3.0892727375030518
train: epoch 2, loss 1.4838223457336426, acc=0.4148888885974884, loss=1.4838223457336426
test: epoch 2, loss 2.1194567680358887, acc=0.2638888955116272, loss=2.1194567680358887
train: epoch 3, loss 1.0334548950195312, acc=0.5802778005599976, loss=1.0334548950195312
test: epoch 3, loss 1.8412425518035889, acc=0.30000001192092896, loss=1.8412425518035889
train: epoch 4, loss 0.8122681975364685, acc=0.6720555424690247, loss=0.8122681975364685
test: epoch 4, loss 1.653874397277832, acc=0.36666667461395264, loss=1.653874397277832
train: epoch 5, loss 0.6711185574531555, acc=0.7252777814865112, loss=0.6711185574531555
test: epoch 5, loss 2.0049872398376465, acc=0.3777777850627899, loss=2.0049872398376465
train: epoch 6, loss 0.5968718528747559, acc=0.7553333044052124, loss=0.5968718528747559
test: epoch 6, loss 1.8220927715301514, acc=0.39444443583488464, loss=1.8220927715301514
train: epoch 7, loss 0.5157315731048584, acc=0.7943333387374878, loss=0.5157315731048584
test: epoch 7, loss 1.753918170928955, acc=0.3722222149372101, loss=1.753918170928955
train: epoch 8, loss 0.4708181619644165, acc=0.8118888735771179, loss=0.4708181619644165
test: epoch 8, loss 1.4334371089935303, acc=0.5083333253860474, loss=1.4334371089935303
train: epoch 9, loss 0.4126904308795929, acc=0.8371111154556274, loss=0.4126904308795929
test: epoch 9, loss 1.9417299032211304, acc=0.4166666567325592, loss=1.9417299032211304
train: epoch 10, loss 0.38737761974334717, acc=0.8442777991294861, loss=0.38737761974334717
test: epoch 10, loss 1.7621145248413086, acc=0.41111111640930176, loss=1.7621145248413086
train: epoch 11, loss 0.36186978220939636, acc=0.855388879776001, loss=0.36186978220939636
test: epoch 11, loss 1.4700419902801514, acc=0.5055555701255798, loss=1.4700419902801514
train: epoch 12, loss 0.3544023931026459, acc=0.8556110858917236, loss=0.3544023931026459
test: epoch 12, loss 1.431882619857788, acc=0.39722222089767456, loss=1.431882619857788
train: epoch 13, loss 0.32644161581993103, acc=0.8663889169692993, loss=0.32644161581993103
test: epoch 13, loss 1.611930251121521, acc=0.4305555522441864, loss=1.611930251121521
train: epoch 14, loss 0.3228500485420227, acc=0.8658333420753479, loss=0.3228500485420227
test: epoch 14, loss 1.5100328922271729, acc=0.5111111402511597, loss=1.5100328922271729
train: epoch 15, loss 0.28643184900283813, acc=0.8808333277702332, loss=0.28643184900283813
test: epoch 15, loss 1.4597463607788086, acc=0.4861111044883728, loss=1.4597463607788086
train: epoch 16, loss 0.2796190679073334, acc=0.8862777948379517, loss=0.2796190679073334
test: epoch 16, loss 1.1894197463989258, acc=0.5861111283302307, loss=1.1894197463989258
train: epoch 17, loss 0.2758038341999054, acc=0.8868333101272583, loss=0.2758038341999054
test: epoch 17, loss 1.2046244144439697, acc=0.5694444179534912, loss=1.2046244144439697
train: epoch 18, loss 0.2564619779586792, acc=0.8973333239555359, loss=0.2564619779586792
test: epoch 18, loss 1.0591217279434204, acc=0.5916666388511658, loss=1.0591217279434204
train: epoch 19, loss 0.2514876425266266, acc=0.9020000100135803, loss=0.2514876425266266
test: epoch 19, loss 1.225420594215393, acc=0.574999988079071, loss=1.225420594215393
train: epoch 20, loss 0.23960264027118683, acc=0.906166672706604, loss=0.23960264027118683
test: epoch 20, loss 1.136633038520813, acc=0.6277777552604675, loss=1.136633038520813
train: epoch 21, loss 0.23194460570812225, acc=0.9084444642066956, loss=0.23194460570812225
test: epoch 21, loss 1.1840976476669312, acc=0.6333333253860474, loss=1.1840976476669312
train: epoch 22, loss 0.21731428802013397, acc=0.9148333072662354, loss=0.21731428802013397
test: epoch 22, loss 1.1589218378067017, acc=0.6916666626930237, loss=1.1589218378067017
train: epoch 23, loss 0.22918029129505157, acc=0.9092222452163696, loss=0.22918029129505157
test: epoch 23, loss 0.8865739107131958, acc=0.699999988079071, loss=0.8865739107131958
train: epoch 24, loss 0.20761500298976898, acc=0.9188888669013977, loss=0.20761500298976898
test: epoch 24, loss 0.9576115608215332, acc=0.6861110925674438, loss=0.9576115608215332
train: epoch 25, loss 0.2012449949979782, acc=0.9211666584014893, loss=0.2012449949979782
test: epoch 25, loss 0.7904642820358276, acc=0.7583333253860474, loss=0.7904642820358276
train: epoch 26, loss 0.20392651855945587, acc=0.9190000295639038, loss=0.20392651855945587
test: epoch 26, loss 0.7728353142738342, acc=0.7250000238418579, loss=0.7728353142738342
train: epoch 27, loss 0.20209220051765442, acc=0.9191666841506958, loss=0.20209220051765442
test: epoch 27, loss 0.8519051671028137, acc=0.675000011920929, loss=0.8519051671028137
train: epoch 28, loss 0.18472686409950256, acc=0.926277756690979, loss=0.18472686409950256
test: epoch 28, loss 0.9784396886825562, acc=0.7361111044883728, loss=0.9784396886825562
train: epoch 29, loss 0.18151280283927917, acc=0.926277756690979, loss=0.18151280283927917
test: epoch 29, loss 0.5812037587165833, acc=0.7916666865348816, loss=0.5812037587165833
train: epoch 30, loss 0.171913743019104, acc=0.929611086845398, loss=0.171913743019104
test: epoch 30, loss 0.5654233694076538, acc=0.8500000238418579, loss=0.5654233694076538
train: epoch 31, loss 0.18529658019542694, acc=0.9255555272102356, loss=0.18529658019542694
test: epoch 31, loss 0.5404049754142761, acc=0.8194444179534912, loss=0.5404049754142761
train: epoch 32, loss 0.169776052236557, acc=0.9293333292007446, loss=0.169776052236557
test: epoch 32, loss 0.46514174342155457, acc=0.8444444537162781, loss=0.46514174342155457
train: epoch 33, loss 0.16419275104999542, acc=0.9326666593551636, loss=0.16419275104999542
test: epoch 33, loss 0.31020596623420715, acc=0.8694444298744202, loss=0.31020596623420715
train: epoch 34, loss 0.15569700300693512, acc=0.9348888993263245, loss=0.15569700300693512
test: epoch 34, loss 0.34007465839385986, acc=0.8666666746139526, loss=0.34007465839385986
train: epoch 35, loss 0.1571885198354721, acc=0.9340555667877197, loss=0.1571885198354721
test: epoch 35, loss 0.3317507207393646, acc=0.8722222447395325, loss=0.3317507207393646
train: epoch 36, loss 0.16137398779392242, acc=0.934166669845581, loss=0.16137398779392242
test: epoch 36, loss 0.36478760838508606, acc=0.8611111044883728, loss=0.36478760838508606
train: epoch 37, loss 0.13425546884536743, acc=0.9403333067893982, loss=0.13425546884536743
test: epoch 37, loss 0.3895508646965027, acc=0.8722222447395325, loss=0.3895508646965027
train: epoch 38, loss 0.146991565823555, acc=0.9387778043746948, loss=0.146991565823555
test: epoch 38, loss 0.33969563245773315, acc=0.8777777552604675, loss=0.33969563245773315
train: epoch 39, loss 0.1469908207654953, acc=0.944611132144928, loss=0.1469908207654953
test: epoch 39, loss 0.2959848940372467, acc=0.8805555701255798, loss=0.2959848940372467
train: epoch 40, loss 0.1464502364397049, acc=0.9387221932411194, loss=0.1464502364397049
test: epoch 40, loss 0.3408346176147461, acc=0.875, loss=0.3408346176147461
train: epoch 41, loss 0.1405932456254959, acc=0.9404444694519043, loss=0.1405932456254959
test: epoch 41, loss 0.30016353726387024, acc=0.8777777552604675, loss=0.30016353726387024
train: epoch 42, loss 0.14796605706214905, acc=0.9367222189903259, loss=0.14796605706214905
test: epoch 42, loss 0.37630051374435425, acc=0.8777777552604675, loss=0.37630051374435425
train: epoch 43, loss 0.13484026491641998, acc=0.9397222399711609, loss=0.13484026491641998
test: epoch 43, loss 0.2513514757156372, acc=0.8861111402511597, loss=0.2513514757156372
train: epoch 44, loss 0.1273912787437439, acc=0.9410555362701416, loss=0.1273912787437439
test: epoch 44, loss 0.25765445828437805, acc=0.9138888716697693, loss=0.25765445828437805
train: epoch 45, loss 0.13301190733909607, acc=0.9416666626930237, loss=0.13301190733909607
test: epoch 45, loss 0.2576086223125458, acc=0.9138888716697693, loss=0.2576086223125458
train: epoch 46, loss 0.12618887424468994, acc=0.9440555572509766, loss=0.12618887424468994
test: epoch 46, loss 0.23126617074012756, acc=0.9138888716697693, loss=0.23126617074012756
train: epoch 47, loss 0.13282085955142975, acc=0.9440000057220459, loss=0.13282085955142975
test: epoch 47, loss 0.2347613424062729, acc=0.9138888716697693, loss=0.2347613424062729
train: epoch 48, loss 0.11409426480531693, acc=0.949055552482605, loss=0.11409426480531693
test: epoch 48, loss 0.2360309511423111, acc=0.9111111164093018, loss=0.2360309511423111
train: epoch 49, loss 0.12063894420862198, acc=0.9471666812896729, loss=0.12063894420862198
test: epoch 49, loss 0.207488551735878, acc=0.9138888716697693, loss=0.207488551735878
train: epoch 50, loss 0.1321515291929245, acc=0.9450555443763733, loss=0.1321515291929245
test: epoch 50, loss 0.2046201378107071, acc=0.9138888716697693, loss=0.2046201378107071
train: epoch 51, loss 0.1315537989139557, acc=0.9397777915000916, loss=0.1315537989139557
test: epoch 51, loss 0.24448774755001068, acc=0.9138888716697693, loss=0.24448774755001068
train: epoch 52, loss 0.10961122065782547, acc=0.9479444622993469, loss=0.10961122065782547
test: epoch 52, loss 0.24589289724826813, acc=0.9138888716697693, loss=0.24589289724826813
train: epoch 53, loss 0.1147548258304596, acc=0.9465000033378601, loss=0.1147548258304596
test: epoch 53, loss 0.2635827958583832, acc=0.9138888716697693, loss=0.2635827958583832
train: epoch 54, loss 0.11318442225456238, acc=0.9473333358764648, loss=0.11318442225456238
test: epoch 54, loss 0.1994072049856186, acc=0.9138888716697693, loss=0.1994072049856186
train: epoch 55, loss 0.12552395462989807, acc=0.9442222118377686, loss=0.12552395462989807
test: epoch 55, loss 0.21093407273292542, acc=0.9138888716697693, loss=0.21093407273292542
train: epoch 56, loss 0.11430440098047256, acc=0.945555567741394, loss=0.11430440098047256
test: epoch 56, loss 0.1969147026538849, acc=0.9138888716697693, loss=0.1969147026538849
train: epoch 57, loss 0.12434497475624084, acc=0.9421666860580444, loss=0.12434497475624084
test: epoch 57, loss 0.20079472661018372, acc=0.9111111164093018, loss=0.20079472661018372
train: epoch 58, loss 0.11479829251766205, acc=0.9470000267028809, loss=0.11479829251766205
test: epoch 58, loss 0.2298092395067215, acc=0.9138888716697693, loss=0.2298092395067215
train: epoch 59, loss 0.12368252873420715, acc=0.9438889026641846, loss=0.12368252873420715
test: epoch 59, loss 0.18809428811073303, acc=0.9138888716697693, loss=0.18809428811073303
train: epoch 60, loss 0.12220077216625214, acc=0.9428333044052124, loss=0.12220077216625214
test: epoch 60, loss 0.2481633722782135, acc=0.9138888716697693, loss=0.2481633722782135
train: epoch 61, loss 0.11643099784851074, acc=0.9456666707992554, loss=0.11643099784851074
test: epoch 61, loss 0.25786909461021423, acc=0.9083333611488342, loss=0.25786909461021423
train: epoch 62, loss 0.12014644593000412, acc=0.9471666812896729, loss=0.12014644593000412
test: epoch 62, loss 0.21682286262512207, acc=0.9138888716697693, loss=0.21682286262512207
train: epoch 63, loss 0.11272280663251877, acc=0.9467777609825134, loss=0.11272280663251877
test: epoch 63, loss 0.2787618637084961, acc=0.9138888716697693, loss=0.2787618637084961
train: epoch 64, loss 0.12241871654987335, acc=0.9433888792991638, loss=0.12241871654987335
test: epoch 64, loss 0.18988709151744843, acc=0.9111111164093018, loss=0.18988709151744843
train: epoch 65, loss 0.13089816272258759, acc=0.9384999871253967, loss=0.13089816272258759
test: epoch 65, loss 0.21213731169700623, acc=0.9194444417953491, loss=0.21213731169700623
train: epoch 66, loss 0.12162240594625473, acc=0.9440000057220459, loss=0.12162240594625473
test: epoch 66, loss 0.21146737039089203, acc=0.9138888716697693, loss=0.21146737039089203
train: epoch 67, loss 0.11355172097682953, acc=0.9474999904632568, loss=0.11355172097682953
test: epoch 67, loss 0.2201918512582779, acc=0.9194444417953491, loss=0.2201918512582779
train: epoch 68, loss 0.12115254998207092, acc=0.9413333535194397, loss=0.12115254998207092
test: epoch 68, loss 0.27107200026512146, acc=0.9111111164093018, loss=0.27107200026512146
train: epoch 69, loss 0.12819157540798187, acc=0.9431666731834412, loss=0.12819157540798187
test: epoch 69, loss 0.18407508730888367, acc=0.9138888716697693, loss=0.18407508730888367
train: epoch 70, loss 0.12335777282714844, acc=0.94477778673172, loss=0.12335777282714844
test: epoch 70, loss 0.17412853240966797, acc=0.9166666865348816, loss=0.17412853240966797
train: epoch 71, loss 0.11352042853832245, acc=0.9465000033378601, loss=0.11352042853832245
test: epoch 71, loss 0.21055731177330017, acc=0.9194444417953491, loss=0.21055731177330017
train: epoch 72, loss 0.1353156417608261, acc=0.9410555362701416, loss=0.1353156417608261
test: epoch 72, loss 0.1983667016029358, acc=0.9111111164093018, loss=0.1983667016029358
train: epoch 73, loss 0.12191098183393478, acc=0.9426666498184204, loss=0.12191098183393478
test: epoch 73, loss 0.22215059399604797, acc=0.9138888716697693, loss=0.22215059399604797
train: epoch 74, loss 0.11252833902835846, acc=0.9458333253860474, loss=0.11252833902835846
test: epoch 74, loss 0.18972787261009216, acc=0.9138888716697693, loss=0.18972787261009216
train: epoch 75, loss 0.11778482049703598, acc=0.9465000033378601, loss=0.11778482049703598
test: epoch 75, loss 0.24338163435459137, acc=0.9138888716697693, loss=0.24338163435459137
train: epoch 76, loss 0.12938618659973145, acc=0.9419999718666077, loss=0.12938618659973145
test: epoch 76, loss 0.28109049797058105, acc=0.9055555462837219, loss=0.28109049797058105
train: epoch 77, loss 0.11360716819763184, acc=0.9445000290870667, loss=0.11360716819763184
test: epoch 77, loss 0.1638593226671219, acc=0.9111111164093018, loss=0.1638593226671219
train: epoch 78, loss 0.11246883869171143, acc=0.9461666941642761, loss=0.11246883869171143
test: epoch 78, loss 0.22084736824035645, acc=0.9111111164093018, loss=0.22084736824035645
train: epoch 79, loss 0.11795389652252197, acc=0.9461110830307007, loss=0.11795389652252197
test: epoch 79, loss 0.1614164113998413, acc=0.9083333611488342, loss=0.1614164113998413
train: epoch 80, loss 0.16757406294345856, acc=0.9340555667877197, loss=0.16757406294345856
test: epoch 80, loss 0.24945111572742462, acc=0.9055555462837219, loss=0.24945111572742462
train: epoch 81, loss 0.11293165385723114, acc=0.9481111168861389, loss=0.11293165385723114
test: epoch 81, loss 0.19909170269966125, acc=0.9138888716697693, loss=0.19909170269966125
train: epoch 82, loss 0.10930641740560532, acc=0.9476666450500488, loss=0.10930641740560532
test: epoch 82, loss 0.24473689496517181, acc=0.9138888716697693, loss=0.24473689496517181
train: epoch 83, loss 0.10816700011491776, acc=0.9506666660308838, loss=0.10816700011491776
test: epoch 83, loss 0.2029304802417755, acc=0.9138888716697693, loss=0.2029304802417755
train: epoch 84, loss 0.10100360214710236, acc=0.9513888955116272, loss=0.10100360214710236
test: epoch 84, loss 0.23864904046058655, acc=0.9138888716697693, loss=0.23864904046058655
train: epoch 85, loss 0.11534808576107025, acc=0.9476110935211182, loss=0.11534808576107025
test: epoch 85, loss 0.22537632286548615, acc=0.9138888716697693, loss=0.22537632286548615
train: epoch 86, loss 0.10634277760982513, acc=0.949055552482605, loss=0.10634277760982513
test: epoch 86, loss 0.2349964678287506, acc=0.9194444417953491, loss=0.2349964678287506
train: epoch 87, loss 0.1045335903763771, acc=0.9509444236755371, loss=0.1045335903763771
test: epoch 87, loss 0.25466015934944153, acc=0.9138888716697693, loss=0.25466015934944153
train: epoch 88, loss 0.10378459841012955, acc=0.9497777819633484, loss=0.10378459841012955
test: epoch 88, loss 0.21062012016773224, acc=0.9138888716697693, loss=0.21062012016773224
train: epoch 89, loss 0.10205397754907608, acc=0.9513333439826965, loss=0.10205397754907608
test: epoch 89, loss 0.2376483976840973, acc=0.9138888716697693, loss=0.2376483976840973
train: epoch 90, loss 0.10102985054254532, acc=0.9505000114440918, loss=0.10102985054254532
test: epoch 90, loss 0.22632406651973724, acc=0.9138888716697693, loss=0.22632406651973724
train: epoch 91, loss 0.0983092188835144, acc=0.9531111121177673, loss=0.0983092188835144
test: epoch 91, loss 0.19879154860973358, acc=0.9138888716697693, loss=0.19879154860973358
train: epoch 92, loss 0.11627395451068878, acc=0.9501110911369324, loss=0.11627395451068878
test: epoch 92, loss 0.20315726101398468, acc=0.9138888716697693, loss=0.20315726101398468
train: epoch 93, loss 0.09751494228839874, acc=0.9518888592720032, loss=0.09751494228839874
test: epoch 93, loss 0.2198771834373474, acc=0.9138888716697693, loss=0.2198771834373474
train: epoch 94, loss 0.09634245187044144, acc=0.9533888697624207, loss=0.09634245187044144
test: epoch 94, loss 0.24720296263694763, acc=0.9138888716697693, loss=0.24720296263694763
train: epoch 95, loss 0.11860921233892441, acc=0.9471666812896729, loss=0.11860921233892441
test: epoch 95, loss 0.23143921792507172, acc=0.9138888716697693, loss=0.23143921792507172
train: epoch 96, loss 0.10565666109323502, acc=0.9515555500984192, loss=0.10565666109323502
test: epoch 96, loss 0.2183396965265274, acc=0.9111111164093018, loss=0.2183396965265274
train: epoch 97, loss 0.09142667800188065, acc=0.9543889164924622, loss=0.09142667800188065
test: epoch 97, loss 0.22001506388187408, acc=0.9138888716697693, loss=0.22001506388187408
train: epoch 98, loss 0.1066744402050972, acc=0.9506111145019531, loss=0.1066744402050972
test: epoch 98, loss 0.21379679441452026, acc=0.9138888716697693, loss=0.21379679441452026
train: epoch 99, loss 0.09967638552188873, acc=0.9512777924537659, loss=0.09967638552188873
test: epoch 99, loss 0.22274437546730042, acc=0.9138888716697693, loss=0.22274437546730042
train: epoch 100, loss 0.10521481186151505, acc=0.9486111402511597, loss=0.10521481186151505
test: epoch 100, loss 0.20439797639846802, acc=0.9138888716697693, loss=0.20439797639846802
train: epoch 101, loss 0.09922288358211517, acc=0.9528889060020447, loss=0.09922288358211517
test: epoch 101, loss 0.2069617062807083, acc=0.9138888716697693, loss=0.2069617062807083
train: epoch 102, loss 0.10938198864459991, acc=0.9506666660308838, loss=0.10938198864459991
test: epoch 102, loss 0.20285969972610474, acc=0.9138888716697693, loss=0.20285969972610474
train: epoch 103, loss 0.10361000150442123, acc=0.9521666765213013, loss=0.10361000150442123
test: epoch 103, loss 0.2586395740509033, acc=0.9111111164093018, loss=0.2586395740509033
train: epoch 104, loss 0.11399567872285843, acc=0.949222207069397, loss=0.11399567872285843
test: epoch 104, loss 0.2530168890953064, acc=0.9111111164093018, loss=0.2530168890953064
train: epoch 105, loss 0.12010182440280914, acc=0.9480000138282776, loss=0.12010182440280914
test: epoch 105, loss 0.2886659502983093, acc=0.9083333611488342, loss=0.2886659502983093
train: epoch 106, loss 0.12128002941608429, acc=0.9466666579246521, loss=0.12128002941608429
test: epoch 106, loss 0.2305392473936081, acc=0.9083333611488342, loss=0.2305392473936081
train: epoch 107, loss 0.1132054328918457, acc=0.9489444494247437, loss=0.1132054328918457
test: epoch 107, loss 0.2122139185667038, acc=0.9083333611488342, loss=0.2122139185667038
train: epoch 108, loss 0.11452700197696686, acc=0.9488333463668823, loss=0.11452700197696686
test: epoch 108, loss 0.29821205139160156, acc=0.9111111164093018, loss=0.29821205139160156
train: epoch 109, loss 0.10228176414966583, acc=0.9511111378669739, loss=0.10228176414966583
test: epoch 109, loss 0.23084768652915955, acc=0.9111111164093018, loss=0.23084768652915955
train: epoch 110, loss 0.15906651318073273, acc=0.9402222037315369, loss=0.15906651318073273
test: epoch 110, loss 0.32131314277648926, acc=0.8972222208976746, loss=0.32131314277648926
train: epoch 111, loss 0.1522507518529892, acc=0.9338889122009277, loss=0.1522507518529892
test: epoch 111, loss 0.3056721091270447, acc=0.894444465637207, loss=0.3056721091270447
train: epoch 112, loss 0.13178032636642456, acc=0.9394444227218628, loss=0.13178032636642456
test: epoch 112, loss 0.312599241733551, acc=0.9027777910232544, loss=0.312599241733551
train: epoch 113, loss 0.12561431527137756, acc=0.9412222504615784, loss=0.12561431527137756
test: epoch 113, loss 0.27855199575424194, acc=0.9027777910232544, loss=0.27855199575424194
train: epoch 114, loss 0.11721154302358627, acc=0.9436666369438171, loss=0.11721154302358627
test: epoch 114, loss 0.2572600245475769, acc=0.9083333611488342, loss=0.2572600245475769
train: epoch 115, loss 0.12950241565704346, acc=0.941444456577301, loss=0.12950241565704346
test: epoch 115, loss 0.2689281105995178, acc=0.9027777910232544, loss=0.2689281105995178
train: epoch 116, loss 0.12321930378675461, acc=0.9431111216545105, loss=0.12321930378675461
test: epoch 116, loss 0.27201688289642334, acc=0.9027777910232544, loss=0.27201688289642334
train: epoch 117, loss 0.1343637853860855, acc=0.940833330154419, loss=0.1343637853860855
test: epoch 117, loss 0.28649070858955383, acc=0.9055555462837219, loss=0.28649070858955383
train: epoch 118, loss 0.1207728460431099, acc=0.9458333253860474, loss=0.1207728460431099
test: epoch 118, loss 0.24911528825759888, acc=0.9055555462837219, loss=0.24911528825759888
train: epoch 119, loss 0.1176406592130661, acc=0.9477221965789795, loss=0.1176406592130661
test: epoch 119, loss 0.24656927585601807, acc=0.9083333611488342, loss=0.24656927585601807
train: epoch 120, loss 0.10887018591165543, acc=0.9495000243186951, loss=0.10887018591165543
test: epoch 120, loss 0.22156266868114471, acc=0.9083333611488342, loss=0.22156266868114471
train: epoch 121, loss 0.11133784055709839, acc=0.9494444727897644, loss=0.11133784055709839
test: epoch 121, loss 0.26482367515563965, acc=0.9083333611488342, loss=0.26482367515563965
train: epoch 122, loss 0.10980047285556793, acc=0.9481666684150696, loss=0.10980047285556793
test: epoch 122, loss 0.2906879484653473, acc=0.9083333611488342, loss=0.2906879484653473
train: epoch 123, loss 0.15078604221343994, acc=0.9433888792991638, loss=0.15078604221343994
test: epoch 123, loss 0.30204471945762634, acc=0.9027777910232544, loss=0.30204471945762634
train: epoch 124, loss 0.11999198794364929, acc=0.9456111192703247, loss=0.11999198794364929
test: epoch 124, loss 0.34392252564430237, acc=0.9055555462837219, loss=0.34392252564430237
train: epoch 125, loss 0.1128796711564064, acc=0.9473333358764648, loss=0.1128796711564064
test: epoch 125, loss 0.2715807557106018, acc=0.9055555462837219, loss=0.2715807557106018
train: epoch 126, loss 0.11092232912778854, acc=0.9481666684150696, loss=0.11092232912778854
test: epoch 126, loss 0.3173697590827942, acc=0.9055555462837219, loss=0.3173697590827942
train: epoch 127, loss 0.11625368148088455, acc=0.9463333487510681, loss=0.11625368148088455
test: epoch 127, loss 0.30469441413879395, acc=0.9055555462837219, loss=0.30469441413879395
train: epoch 128, loss 0.1248093917965889, acc=0.9457777738571167, loss=0.1248093917965889
test: epoch 128, loss 0.33916109800338745, acc=0.9027777910232544, loss=0.33916109800338745
train: epoch 129, loss 0.13227809965610504, acc=0.9435555338859558, loss=0.13227809965610504
test: epoch 129, loss 0.2820916473865509, acc=0.9027777910232544, loss=0.2820916473865509
train: epoch 130, loss 0.16600391268730164, acc=0.9362221956253052, loss=0.16600391268730164
test: epoch 130, loss 0.2614619731903076, acc=0.8999999761581421, loss=0.2614619731903076
train: epoch 131, loss 0.13598065078258514, acc=0.945111095905304, loss=0.13598065078258514
test: epoch 131, loss 0.26305726170539856, acc=0.9055555462837219, loss=0.26305726170539856
train: epoch 132, loss 0.13111402094364166, acc=0.9465555548667908, loss=0.13111402094364166
test: epoch 132, loss 0.2878422737121582, acc=0.9055555462837219, loss=0.2878422737121582
train: epoch 133, loss 0.12244633585214615, acc=0.9466666579246521, loss=0.12244633585214615
test: epoch 133, loss 0.29233619570732117, acc=0.9055555462837219, loss=0.29233619570732117
train: epoch 134, loss 0.11878392845392227, acc=0.9476110935211182, loss=0.11878392845392227
test: epoch 134, loss 0.29505568742752075, acc=0.9055555462837219, loss=0.29505568742752075
train: epoch 135, loss 0.11085254698991776, acc=0.9497222304344177, loss=0.11085254698991776
test: epoch 135, loss 0.2980833053588867, acc=0.9083333611488342, loss=0.2980833053588867
train: epoch 136, loss 0.12842413783073425, acc=0.9461110830307007, loss=0.12842413783073425
test: epoch 136, loss 0.2623082995414734, acc=0.9083333611488342, loss=0.2623082995414734
train: epoch 137, loss 0.12187490612268448, acc=0.9490000009536743, loss=0.12187490612268448
test: epoch 137, loss 0.27793824672698975, acc=0.9083333611488342, loss=0.27793824672698975
train: epoch 138, loss 0.11140211671590805, acc=0.949999988079071, loss=0.11140211671590805
test: epoch 138, loss 0.25887608528137207, acc=0.9111111164093018, loss=0.25887608528137207
train: epoch 139, loss 0.10671884566545486, acc=0.9516666531562805, loss=0.10671884566545486
test: epoch 139, loss 0.293692022562027, acc=0.9111111164093018, loss=0.293692022562027
train: epoch 140, loss 0.10814535617828369, acc=0.9523333311080933, loss=0.10814535617828369
test: epoch 140, loss 0.23488524556159973, acc=0.9138888716697693, loss=0.23488524556159973
train: epoch 141, loss 0.0988638624548912, acc=0.9538333415985107, loss=0.0988638624548912
test: epoch 141, loss 0.21742857992649078, acc=0.9166666865348816, loss=0.21742857992649078
train: epoch 142, loss 0.09461107850074768, acc=0.9553889036178589, loss=0.09461107850074768
test: epoch 142, loss 0.21399222314357758, acc=0.9166666865348816, loss=0.21399222314357758
train: epoch 143, loss 0.09794814139604568, acc=0.9551110863685608, loss=0.09794814139604568
test: epoch 143, loss 0.20376968383789062, acc=0.9166666865348816, loss=0.20376968383789062
train: epoch 144, loss 0.08959891647100449, acc=0.9563888907432556, loss=0.08959891647100449
test: epoch 144, loss 0.21584929525852203, acc=0.9111111164093018, loss=0.21584929525852203
train: epoch 145, loss 0.08872555941343307, acc=0.9562777876853943, loss=0.08872555941343307
test: epoch 145, loss 0.27024194598197937, acc=0.9166666865348816, loss=0.27024194598197937
train: epoch 146, loss 0.09019684791564941, acc=0.9568333625793457, loss=0.09019684791564941
test: epoch 146, loss 0.23842473328113556, acc=0.9166666865348816, loss=0.23842473328113556
train: epoch 147, loss 0.09587901830673218, acc=0.9563888907432556, loss=0.09587901830673218
test: epoch 147, loss 0.24833671748638153, acc=0.9194444417953491, loss=0.24833671748638153
train: epoch 148, loss 0.16680553555488586, acc=0.9381666779518127, loss=0.16680553555488586
test: epoch 148, loss 0.2530522346496582, acc=0.9111111164093018, loss=0.2530522346496582
train: epoch 149, loss 0.12392836064100266, acc=0.9494444727897644, loss=0.12392836064100266
test: epoch 149, loss 0.25693392753601074, acc=0.9166666865348816, loss=0.25693392753601074
train: epoch 150, loss 0.11156037449836731, acc=0.9508888721466064, loss=0.11156037449836731
test: epoch 150, loss 0.22139765322208405, acc=0.9222221970558167, loss=0.22139765322208405
