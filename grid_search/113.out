# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=1", "--temp_decay=1", "--one_hot=1", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=141502358, receiver_embed_dim=128, save_run=0, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=141502358, receiver_embed_dim=128, save_run=False, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.0064239501953125, acc=0.08138889074325562, loss=3.0064239501953125
test: epoch 1, loss 2.928312301635742, acc=0.09444444626569748, loss=2.928312301635742
train: epoch 2, loss 1.9506489038467407, acc=0.26277777552604675, loss=1.9506489038467407
test: epoch 2, loss 2.0112385749816895, acc=0.23333333432674408, loss=2.0112385749816895
train: epoch 3, loss 1.4678372144699097, acc=0.39927777647972107, loss=1.4678372144699097
test: epoch 3, loss 1.6425431966781616, acc=0.3055555522441864, loss=1.6425431966781616
train: epoch 4, loss 1.2489646673202515, acc=0.47111111879348755, loss=1.2489646673202515
test: epoch 4, loss 1.6767648458480835, acc=0.3305555582046509, loss=1.6767648458480835
train: epoch 5, loss 1.0965291261672974, acc=0.5321111083030701, loss=1.0965291261672974
test: epoch 5, loss 1.6686596870422363, acc=0.3055555522441864, loss=1.6686596870422363
train: epoch 6, loss 0.9888995289802551, acc=0.5768888592720032, loss=0.9888995289802551
test: epoch 6, loss 1.6276469230651855, acc=0.35555556416511536, loss=1.6276469230651855
train: epoch 7, loss 0.8889853358268738, acc=0.6152222156524658, loss=0.8889853358268738
test: epoch 7, loss 1.5542677640914917, acc=0.3888888955116272, loss=1.5542677640914917
train: epoch 8, loss 0.8169981241226196, acc=0.6382222175598145, loss=0.8169981241226196
test: epoch 8, loss 1.5021264553070068, acc=0.38055557012557983, loss=1.5021264553070068
train: epoch 9, loss 0.7679171562194824, acc=0.667388916015625, loss=0.7679171562194824
test: epoch 9, loss 1.6042336225509644, acc=0.43888887763023376, loss=1.6042336225509644
train: epoch 10, loss 0.7229986190795898, acc=0.67894446849823, loss=0.7229986190795898
test: epoch 10, loss 1.5287660360336304, acc=0.4472222328186035, loss=1.5287660360336304
train: epoch 11, loss 0.6828168630599976, acc=0.7070555686950684, loss=0.6828168630599976
test: epoch 11, loss 1.382458209991455, acc=0.43611112236976624, loss=1.382458209991455
train: epoch 12, loss 0.6083267331123352, acc=0.738777756690979, loss=0.6083267331123352
test: epoch 12, loss 1.5874207019805908, acc=0.5111111402511597, loss=1.5874207019805908
train: epoch 13, loss 0.592186450958252, acc=0.7466111183166504, loss=0.592186450958252
test: epoch 13, loss 1.45050048828125, acc=0.48055556416511536, loss=1.45050048828125
train: epoch 14, loss 0.5732648372650146, acc=0.753333330154419, loss=0.5732648372650146
test: epoch 14, loss 1.3631154298782349, acc=0.5, loss=1.3631154298782349
train: epoch 15, loss 0.5598519444465637, acc=0.7566111087799072, loss=0.5598519444465637
test: epoch 15, loss 1.273417592048645, acc=0.5333333611488342, loss=1.273417592048645
train: epoch 16, loss 0.532563328742981, acc=0.7648888826370239, loss=0.532563328742981
test: epoch 16, loss 1.1717126369476318, acc=0.5111111402511597, loss=1.1717126369476318
train: epoch 17, loss 0.5129912495613098, acc=0.7691666483879089, loss=0.5129912495613098
test: epoch 17, loss 1.141629695892334, acc=0.5805555582046509, loss=1.141629695892334
train: epoch 18, loss 0.5017669200897217, acc=0.773888885974884, loss=0.5017669200897217
test: epoch 18, loss 1.4099715948104858, acc=0.5277777910232544, loss=1.4099715948104858
train: epoch 19, loss 0.4906274676322937, acc=0.7823333144187927, loss=0.4906274676322937
test: epoch 19, loss 1.2672277688980103, acc=0.5138888955116272, loss=1.2672277688980103
train: epoch 20, loss 0.4962487816810608, acc=0.7783889174461365, loss=0.4962487816810608
test: epoch 20, loss 1.2472290992736816, acc=0.5611110925674438, loss=1.2472290992736816
train: epoch 21, loss 0.4780964255332947, acc=0.7889999747276306, loss=0.4780964255332947
test: epoch 21, loss 1.0926895141601562, acc=0.5916666388511658, loss=1.0926895141601562
train: epoch 22, loss 0.4784128665924072, acc=0.7839999794960022, loss=0.4784128665924072
test: epoch 22, loss 1.2251238822937012, acc=0.5777778029441833, loss=1.2251238822937012
train: epoch 23, loss 0.4560262858867645, acc=0.8004444241523743, loss=0.4560262858867645
test: epoch 23, loss 1.1041884422302246, acc=0.5916666388511658, loss=1.1041884422302246
train: epoch 24, loss 0.45571357011795044, acc=0.7986666560173035, loss=0.45571357011795044
test: epoch 24, loss 1.2497426271438599, acc=0.5944444537162781, loss=1.2497426271438599
train: epoch 25, loss 0.4461999237537384, acc=0.8023889064788818, loss=0.4461999237537384
test: epoch 25, loss 1.1578549146652222, acc=0.5861111283302307, loss=1.1578549146652222
train: epoch 26, loss 0.44541412591934204, acc=0.805055558681488, loss=0.44541412591934204
test: epoch 26, loss 1.2917726039886475, acc=0.5972222089767456, loss=1.2917726039886475
train: epoch 27, loss 0.42012372612953186, acc=0.8187777996063232, loss=0.42012372612953186
test: epoch 27, loss 1.300912618637085, acc=0.5972222089767456, loss=1.300912618637085
train: epoch 28, loss 0.4225771427154541, acc=0.8148888945579529, loss=0.4225771427154541
test: epoch 28, loss 1.281264305114746, acc=0.6027777791023254, loss=1.281264305114746
train: epoch 29, loss 0.41572558879852295, acc=0.8148888945579529, loss=0.41572558879852295
test: epoch 29, loss 1.1296586990356445, acc=0.6027777791023254, loss=1.1296586990356445
train: epoch 30, loss 0.41721129417419434, acc=0.8153889179229736, loss=0.41721129417419434
test: epoch 30, loss 1.4032381772994995, acc=0.5916666388511658, loss=1.4032381772994995
train: epoch 31, loss 0.3943875730037689, acc=0.8258888721466064, loss=0.3943875730037689
test: epoch 31, loss 1.2017227411270142, acc=0.6027777791023254, loss=1.2017227411270142
train: epoch 32, loss 0.4056161344051361, acc=0.8194444179534912, loss=0.4056161344051361
test: epoch 32, loss 1.3256022930145264, acc=0.6027777791023254, loss=1.3256022930145264
train: epoch 33, loss 0.4142600893974304, acc=0.8143333196640015, loss=0.4142600893974304
test: epoch 33, loss 1.1333365440368652, acc=0.6027777791023254, loss=1.1333365440368652
train: epoch 34, loss 0.4061856269836426, acc=0.8213333487510681, loss=0.4061856269836426
test: epoch 34, loss 1.321668028831482, acc=0.6027777791023254, loss=1.321668028831482
train: epoch 35, loss 0.38581332564353943, acc=0.8312222361564636, loss=0.38581332564353943
test: epoch 35, loss 1.2735322713851929, acc=0.6027777791023254, loss=1.2735322713851929
train: epoch 36, loss 0.39524129033088684, acc=0.8205000162124634, loss=0.39524129033088684
test: epoch 36, loss 1.1145684719085693, acc=0.6027777791023254, loss=1.1145684719085693
train: epoch 37, loss 0.3954571783542633, acc=0.8252221941947937, loss=0.3954571783542633
test: epoch 37, loss 1.197017788887024, acc=0.5944444537162781, loss=1.197017788887024
train: epoch 38, loss 0.40344589948654175, acc=0.8217222094535828, loss=0.40344589948654175
test: epoch 38, loss 1.2009488344192505, acc=0.6027777791023254, loss=1.2009488344192505
train: epoch 39, loss 0.3862764537334442, acc=0.8257222175598145, loss=0.3862764537334442
test: epoch 39, loss 1.188103199005127, acc=0.5944444537162781, loss=1.188103199005127
train: epoch 40, loss 0.3816976249217987, acc=0.8246666789054871, loss=0.3816976249217987
test: epoch 40, loss 1.1617543697357178, acc=0.6027777791023254, loss=1.1617543697357178
train: epoch 41, loss 0.3993283808231354, acc=0.8237777948379517, loss=0.3993283808231354
test: epoch 41, loss 1.2842097282409668, acc=0.6027777791023254, loss=1.2842097282409668
train: epoch 42, loss 0.37410372495651245, acc=0.8314999938011169, loss=0.37410372495651245
test: epoch 42, loss 1.0495790243148804, acc=0.6027777791023254, loss=1.0495790243148804
train: epoch 43, loss 0.3667214810848236, acc=0.8358333110809326, loss=0.3667214810848236
test: epoch 43, loss 1.2128700017929077, acc=0.5944444537162781, loss=1.2128700017929077
train: epoch 44, loss 0.36953043937683105, acc=0.8416110873222351, loss=0.36953043937683105
test: epoch 44, loss 1.5042330026626587, acc=0.6000000238418579, loss=1.5042330026626587
train: epoch 45, loss 0.3849974274635315, acc=0.8313888907432556, loss=0.3849974274635315
test: epoch 45, loss 1.2901313304901123, acc=0.5972222089767456, loss=1.2901313304901123
train: epoch 46, loss 0.3758483827114105, acc=0.8289999961853027, loss=0.3758483827114105
test: epoch 46, loss 1.3336769342422485, acc=0.6027777791023254, loss=1.3336769342422485
train: epoch 47, loss 0.35545700788497925, acc=0.8391666412353516, loss=0.35545700788497925
test: epoch 47, loss 1.2807581424713135, acc=0.6000000238418579, loss=1.2807581424713135
train: epoch 48, loss 0.3703339993953705, acc=0.8349999785423279, loss=0.3703339993953705
test: epoch 48, loss 1.2000683546066284, acc=0.6027777791023254, loss=1.2000683546066284
train: epoch 49, loss 0.3533087372779846, acc=0.8441110849380493, loss=0.3533087372779846
test: epoch 49, loss 1.206977367401123, acc=0.6027777791023254, loss=1.206977367401123
train: epoch 50, loss 0.34421247243881226, acc=0.8410000205039978, loss=0.34421247243881226
test: epoch 50, loss 1.3365345001220703, acc=0.6027777791023254, loss=1.3365345001220703
train: epoch 51, loss 0.3540084660053253, acc=0.8423333168029785, loss=0.3540084660053253
test: epoch 51, loss 1.3645905256271362, acc=0.625, loss=1.3645905256271362
train: epoch 52, loss 0.3550248444080353, acc=0.842555582523346, loss=0.3550248444080353
test: epoch 52, loss 1.3247917890548706, acc=0.6027777791023254, loss=1.3247917890548706
train: epoch 53, loss 0.346760094165802, acc=0.8416666388511658, loss=0.346760094165802
test: epoch 53, loss 1.4291738271713257, acc=0.6027777791023254, loss=1.4291738271713257
train: epoch 54, loss 0.3545423150062561, acc=0.8411111235618591, loss=0.3545423150062561
test: epoch 54, loss 1.2130769491195679, acc=0.6027777791023254, loss=1.2130769491195679
train: epoch 55, loss 0.34594085812568665, acc=0.8446666598320007, loss=0.34594085812568665
test: epoch 55, loss 1.183005928993225, acc=0.625, loss=1.183005928993225
train: epoch 56, loss 0.33652642369270325, acc=0.8478333353996277, loss=0.33652642369270325
test: epoch 56, loss 1.151934266090393, acc=0.6333333253860474, loss=1.151934266090393
train: epoch 57, loss 0.3426719903945923, acc=0.8460555672645569, loss=0.3426719903945923
test: epoch 57, loss 1.2478266954421997, acc=0.625, loss=1.2478266954421997
train: epoch 58, loss 0.3302627205848694, acc=0.8460000157356262, loss=0.3302627205848694
test: epoch 58, loss 1.3108164072036743, acc=0.6222222447395325, loss=1.3108164072036743
train: epoch 59, loss 0.3240317404270172, acc=0.8515555262565613, loss=0.3240317404270172
test: epoch 59, loss 1.2593289613723755, acc=0.6333333253860474, loss=1.2593289613723755
train: epoch 60, loss 0.3369426131248474, acc=0.8500000238418579, loss=0.3369426131248474
test: epoch 60, loss 1.2847020626068115, acc=0.6388888955116272, loss=1.2847020626068115
train: epoch 61, loss 0.32724207639694214, acc=0.8498888611793518, loss=0.32724207639694214
test: epoch 61, loss 1.098037838935852, acc=0.6305555701255798, loss=1.098037838935852
train: epoch 62, loss 0.33669376373291016, acc=0.8473333120346069, loss=0.33669376373291016
test: epoch 62, loss 1.130244255065918, acc=0.6333333253860474, loss=1.130244255065918
train: epoch 63, loss 0.33106622099876404, acc=0.8461666703224182, loss=0.33106622099876404
test: epoch 63, loss 1.2877883911132812, acc=0.6333333253860474, loss=1.2877883911132812
train: epoch 64, loss 0.3253139853477478, acc=0.850944459438324, loss=0.3253139853477478
test: epoch 64, loss 1.171608567237854, acc=0.6333333253860474, loss=1.171608567237854
train: epoch 65, loss 0.33472511172294617, acc=0.847611129283905, loss=0.33472511172294617
test: epoch 65, loss 1.1772230863571167, acc=0.6333333253860474, loss=1.1772230863571167
train: epoch 66, loss 0.3154524564743042, acc=0.8529999852180481, loss=0.3154524564743042
test: epoch 66, loss 1.3029534816741943, acc=0.6333333253860474, loss=1.3029534816741943
train: epoch 67, loss 0.3337317407131195, acc=0.8481666445732117, loss=0.3337317407131195
test: epoch 67, loss 1.2448018789291382, acc=0.6333333253860474, loss=1.2448018789291382
train: epoch 68, loss 0.3300337493419647, acc=0.8463333249092102, loss=0.3300337493419647
test: epoch 68, loss 1.3572800159454346, acc=0.6333333253860474, loss=1.3572800159454346
train: epoch 69, loss 0.3152299225330353, acc=0.8543888926506042, loss=0.3152299225330353
test: epoch 69, loss 1.2460472583770752, acc=0.6333333253860474, loss=1.2460472583770752
train: epoch 70, loss 0.31209421157836914, acc=0.8547222018241882, loss=0.31209421157836914
test: epoch 70, loss 1.2084449529647827, acc=0.625, loss=1.2084449529647827
train: epoch 71, loss 0.31886693835258484, acc=0.8517777919769287, loss=0.31886693835258484
test: epoch 71, loss 1.2338767051696777, acc=0.6333333253860474, loss=1.2338767051696777
train: epoch 72, loss 0.3092952370643616, acc=0.8559444546699524, loss=0.3092952370643616
test: epoch 72, loss 1.280492901802063, acc=0.6277777552604675, loss=1.280492901802063
train: epoch 73, loss 0.3128005266189575, acc=0.8546110987663269, loss=0.3128005266189575
test: epoch 73, loss 1.2695406675338745, acc=0.6333333253860474, loss=1.2695406675338745
train: epoch 74, loss 0.3113681674003601, acc=0.8542777895927429, loss=0.3113681674003601
test: epoch 74, loss 1.3292111158370972, acc=0.6333333253860474, loss=1.3292111158370972
train: epoch 75, loss 0.303710013628006, acc=0.8583333492279053, loss=0.303710013628006
test: epoch 75, loss 1.2925302982330322, acc=0.6305555701255798, loss=1.2925302982330322
train: epoch 76, loss 0.31217795610427856, acc=0.8563888669013977, loss=0.31217795610427856
test: epoch 76, loss 1.1742620468139648, acc=0.6333333253860474, loss=1.1742620468139648
train: epoch 77, loss 0.2987387776374817, acc=0.8615555763244629, loss=0.2987387776374817
test: epoch 77, loss 1.2873218059539795, acc=0.6305555701255798, loss=1.2873218059539795
train: epoch 78, loss 0.3016537129878998, acc=0.8636666536331177, loss=0.3016537129878998
test: epoch 78, loss 1.278459072113037, acc=0.6361111402511597, loss=1.278459072113037
train: epoch 79, loss 0.31673097610473633, acc=0.8565000295639038, loss=0.31673097610473633
test: epoch 79, loss 1.3185579776763916, acc=0.6388888955116272, loss=1.3185579776763916
train: epoch 80, loss 0.29110416769981384, acc=0.863111138343811, loss=0.29110416769981384
test: epoch 80, loss 1.3678184747695923, acc=0.6361111402511597, loss=1.3678184747695923
train: epoch 81, loss 0.2927228808403015, acc=0.863611102104187, loss=0.2927228808403015
test: epoch 81, loss 1.2598828077316284, acc=0.6333333253860474, loss=1.2598828077316284
train: epoch 82, loss 0.288015216588974, acc=0.866944432258606, loss=0.288015216588974
test: epoch 82, loss 1.2638194561004639, acc=0.6416666507720947, loss=1.2638194561004639
train: epoch 83, loss 0.29174673557281494, acc=0.8640000224113464, loss=0.29174673557281494
test: epoch 83, loss 1.052457571029663, acc=0.6472222208976746, loss=1.052457571029663
train: epoch 84, loss 0.2723630368709564, acc=0.8711110949516296, loss=0.2723630368709564
test: epoch 84, loss 1.3267250061035156, acc=0.6472222208976746, loss=1.3267250061035156
train: epoch 85, loss 0.28072845935821533, acc=0.867222249507904, loss=0.28072845935821533
test: epoch 85, loss 1.2388136386871338, acc=0.6472222208976746, loss=1.2388136386871338
train: epoch 86, loss 0.27591612935066223, acc=0.8721110820770264, loss=0.27591612935066223
test: epoch 86, loss 1.2321996688842773, acc=0.6472222208976746, loss=1.2321996688842773
train: epoch 87, loss 0.26572296023368835, acc=0.8746111392974854, loss=0.26572296023368835
test: epoch 87, loss 1.3595998287200928, acc=0.6472222208976746, loss=1.3595998287200928
train: epoch 88, loss 0.2686578929424286, acc=0.8711110949516296, loss=0.2686578929424286
test: epoch 88, loss 1.3769111633300781, acc=0.6472222208976746, loss=1.3769111633300781
train: epoch 89, loss 0.26608845591545105, acc=0.8711110949516296, loss=0.26608845591545105
test: epoch 89, loss 1.351721167564392, acc=0.6472222208976746, loss=1.351721167564392
train: epoch 90, loss 0.2630729377269745, acc=0.8727777600288391, loss=0.2630729377269745
test: epoch 90, loss 1.2809782028198242, acc=0.6472222208976746, loss=1.2809782028198242
train: epoch 91, loss 0.26888853311538696, acc=0.8737778067588806, loss=0.26888853311538696
test: epoch 91, loss 1.1168153285980225, acc=0.6499999761581421, loss=1.1168153285980225
train: epoch 92, loss 0.26691970229148865, acc=0.875, loss=0.26691970229148865
test: epoch 92, loss 1.3120677471160889, acc=0.644444465637207, loss=1.3120677471160889
train: epoch 93, loss 0.2662471532821655, acc=0.871833324432373, loss=0.2662471532821655
test: epoch 93, loss 1.42852783203125, acc=0.6472222208976746, loss=1.42852783203125
train: epoch 94, loss 0.2752797305583954, acc=0.8691666722297668, loss=0.2752797305583954
test: epoch 94, loss 1.3326890468597412, acc=0.6527777910232544, loss=1.3326890468597412
train: epoch 95, loss 0.25065451860427856, acc=0.8769999742507935, loss=0.25065451860427856
test: epoch 95, loss 1.2469414472579956, acc=0.6527777910232544, loss=1.2469414472579956
train: epoch 96, loss 0.25654974579811096, acc=0.8738333582878113, loss=0.25654974579811096
test: epoch 96, loss 1.312599778175354, acc=0.6555555462837219, loss=1.312599778175354
train: epoch 97, loss 0.25242969393730164, acc=0.8739444613456726, loss=0.25242969393730164
test: epoch 97, loss 1.3017075061798096, acc=0.6555555462837219, loss=1.3017075061798096
train: epoch 98, loss 0.2498985081911087, acc=0.8771666884422302, loss=0.2498985081911087
test: epoch 98, loss 1.3329051733016968, acc=0.6638888716697693, loss=1.3329051733016968
train: epoch 99, loss 0.25980016589164734, acc=0.8736110925674438, loss=0.25980016589164734
test: epoch 99, loss 1.1995103359222412, acc=0.6694444417953491, loss=1.1995103359222412
train: epoch 100, loss 0.2537309229373932, acc=0.8767222166061401, loss=0.2537309229373932
test: epoch 100, loss 1.3662962913513184, acc=0.6611111164093018, loss=1.3662962913513184
train: epoch 101, loss 0.25989285111427307, acc=0.8766666650772095, loss=0.25989285111427307
test: epoch 101, loss 1.2936753034591675, acc=0.6611111164093018, loss=1.2936753034591675
train: epoch 102, loss 0.25235918164253235, acc=0.8812777996063232, loss=0.25235918164253235
test: epoch 102, loss 1.2364859580993652, acc=0.6694444417953491, loss=1.2364859580993652
train: epoch 103, loss 0.24169860780239105, acc=0.8807777762413025, loss=0.24169860780239105
test: epoch 103, loss 1.3275444507598877, acc=0.675000011920929, loss=1.3275444507598877
train: epoch 104, loss 0.25055885314941406, acc=0.8797222375869751, loss=0.25055885314941406
test: epoch 104, loss 1.2310634851455688, acc=0.675000011920929, loss=1.2310634851455688
train: epoch 105, loss 0.24225173890590668, acc=0.8834999799728394, loss=0.24225173890590668
test: epoch 105, loss 1.3493200540542603, acc=0.6722221970558167, loss=1.3493200540542603
train: epoch 106, loss 0.24433723092079163, acc=0.8783888816833496, loss=0.24433723092079163
test: epoch 106, loss 1.2636536359786987, acc=0.6666666865348816, loss=1.2636536359786987
train: epoch 107, loss 0.2572081387042999, acc=0.870555579662323, loss=0.2572081387042999
test: epoch 107, loss 1.3045872449874878, acc=0.675000011920929, loss=1.3045872449874878
train: epoch 108, loss 0.2510944604873657, acc=0.8752777576446533, loss=0.2510944604873657
test: epoch 108, loss 1.1560155153274536, acc=0.6944444179534912, loss=1.1560155153274536
train: epoch 109, loss 0.24334129691123962, acc=0.8780555725097656, loss=0.24334129691123962
test: epoch 109, loss 1.1611580848693848, acc=0.6916666626930237, loss=1.1611580848693848
train: epoch 110, loss 0.2392149120569229, acc=0.8774444460868835, loss=0.2392149120569229
test: epoch 110, loss 1.18834388256073, acc=0.6944444179534912, loss=1.18834388256073
train: epoch 111, loss 0.23139198124408722, acc=0.8761110901832581, loss=0.23139198124408722
test: epoch 111, loss 1.2624019384384155, acc=0.6944444179534912, loss=1.2624019384384155
train: epoch 112, loss 0.235590398311615, acc=0.8801666498184204, loss=0.235590398311615
test: epoch 112, loss 1.296141266822815, acc=0.6944444179534912, loss=1.296141266822815
train: epoch 113, loss 0.23816420137882233, acc=0.8777777552604675, loss=0.23816420137882233
test: epoch 113, loss 1.065771460533142, acc=0.6944444179534912, loss=1.065771460533142
train: epoch 114, loss 0.22394226491451263, acc=0.8844444155693054, loss=0.22394226491451263
test: epoch 114, loss 1.2546851634979248, acc=0.6944444179534912, loss=1.2546851634979248
train: epoch 115, loss 0.2374102771282196, acc=0.8799444437026978, loss=0.2374102771282196
test: epoch 115, loss 1.1551471948623657, acc=0.6944444179534912, loss=1.1551471948623657
train: epoch 116, loss 0.23257458209991455, acc=0.8813889026641846, loss=0.23257458209991455
test: epoch 116, loss 1.0263142585754395, acc=0.6916666626930237, loss=1.0263142585754395
train: epoch 117, loss 0.24065019190311432, acc=0.8820000290870667, loss=0.24065019190311432
test: epoch 117, loss 1.2343395948410034, acc=0.6916666626930237, loss=1.2343395948410034
train: epoch 118, loss 0.2316756397485733, acc=0.8841666579246521, loss=0.2316756397485733
test: epoch 118, loss 1.2971423864364624, acc=0.6916666626930237, loss=1.2971423864364624
train: epoch 119, loss 0.24654360115528107, acc=0.882777750492096, loss=0.24654360115528107
test: epoch 119, loss 1.1248247623443604, acc=0.6944444179534912, loss=1.1248247623443604
train: epoch 120, loss 0.23878821730613708, acc=0.8846666812896729, loss=0.23878821730613708
test: epoch 120, loss 1.1795709133148193, acc=0.6916666626930237, loss=1.1795709133148193
train: epoch 121, loss 0.231109619140625, acc=0.8845555782318115, loss=0.231109619140625
test: epoch 121, loss 1.278148889541626, acc=0.6944444179534912, loss=1.278148889541626
train: epoch 122, loss 0.22858664393424988, acc=0.886388897895813, loss=0.22858664393424988
test: epoch 122, loss 1.1504615545272827, acc=0.6944444179534912, loss=1.1504615545272827
train: epoch 123, loss 0.23302817344665527, acc=0.8866111040115356, loss=0.23302817344665527
test: epoch 123, loss 1.1057795286178589, acc=0.6888889074325562, loss=1.1057795286178589
train: epoch 124, loss 0.23558543622493744, acc=0.8849444389343262, loss=0.23558543622493744
test: epoch 124, loss 1.2569453716278076, acc=0.6944444179534912, loss=1.2569453716278076
train: epoch 125, loss 0.22606772184371948, acc=0.8858888745307922, loss=0.22606772184371948
test: epoch 125, loss 1.3204842805862427, acc=0.6944444179534912, loss=1.3204842805862427
train: epoch 126, loss 0.21833233535289764, acc=0.8885555267333984, loss=0.21833233535289764
test: epoch 126, loss 1.149574875831604, acc=0.6944444179534912, loss=1.149574875831604
train: epoch 127, loss 0.23323805630207062, acc=0.8874444365501404, loss=0.23323805630207062
test: epoch 127, loss 1.1642422676086426, acc=0.6972222328186035, loss=1.1642422676086426
train: epoch 128, loss 0.21389071643352509, acc=0.8882222175598145, loss=0.21389071643352509
test: epoch 128, loss 1.1981263160705566, acc=0.699999988079071, loss=1.1981263160705566
train: epoch 129, loss 0.2308443933725357, acc=0.8861666917800903, loss=0.2308443933725357
test: epoch 129, loss 1.2378134727478027, acc=0.7027778029441833, loss=1.2378134727478027
train: epoch 130, loss 0.22244183719158173, acc=0.8851666450500488, loss=0.22244183719158173
test: epoch 130, loss 0.9708861112594604, acc=0.699999988079071, loss=0.9708861112594604
train: epoch 131, loss 0.218634694814682, acc=0.8863333463668823, loss=0.218634694814682
test: epoch 131, loss 1.0472368001937866, acc=0.7083333134651184, loss=1.0472368001937866
train: epoch 132, loss 0.22425530850887299, acc=0.8884999752044678, loss=0.22425530850887299
test: epoch 132, loss 0.9711084365844727, acc=0.6944444179534912, loss=0.9711084365844727
train: epoch 133, loss 0.22673869132995605, acc=0.8858888745307922, loss=0.22673869132995605
test: epoch 133, loss 1.1342583894729614, acc=0.7277777791023254, loss=1.1342583894729614
train: epoch 134, loss 0.21151801943778992, acc=0.8834444284439087, loss=0.21151801943778992
test: epoch 134, loss 1.0835673809051514, acc=0.7277777791023254, loss=1.0835673809051514
train: epoch 135, loss 0.22567903995513916, acc=0.8837777972221375, loss=0.22567903995513916
test: epoch 135, loss 1.1961766481399536, acc=0.7250000238418579, loss=1.1961766481399536
train: epoch 136, loss 0.22159065306186676, acc=0.8838889002799988, loss=0.22159065306186676
test: epoch 136, loss 1.1424213647842407, acc=0.7333333492279053, loss=1.1424213647842407
train: epoch 137, loss 0.24042773246765137, acc=0.8799444437026978, loss=0.24042773246765137
test: epoch 137, loss 1.0367435216903687, acc=0.7388888597488403, loss=1.0367435216903687
train: epoch 138, loss 0.2150765210390091, acc=0.8865000009536743, loss=0.2150765210390091
test: epoch 138, loss 0.9603063464164734, acc=0.730555534362793, loss=0.9603063464164734
train: epoch 139, loss 0.22027038037776947, acc=0.8808888792991638, loss=0.22027038037776947
test: epoch 139, loss 0.8605397939682007, acc=0.7277777791023254, loss=0.8605397939682007
train: epoch 140, loss 0.21205921471118927, acc=0.8858333230018616, loss=0.21205921471118927
test: epoch 140, loss 1.3234634399414062, acc=0.7333333492279053, loss=1.3234634399414062
train: epoch 141, loss 0.21177087724208832, acc=0.88355553150177, loss=0.21177087724208832
test: epoch 141, loss 1.070814609527588, acc=0.7361111044883728, loss=1.070814609527588
train: epoch 142, loss 0.21392704546451569, acc=0.8843888640403748, loss=0.21392704546451569
test: epoch 142, loss 0.9569934606552124, acc=0.7388888597488403, loss=0.9569934606552124
train: epoch 143, loss 0.22292187809944153, acc=0.8817777633666992, loss=0.22292187809944153
test: epoch 143, loss 1.0323220491409302, acc=0.7444444298744202, loss=1.0323220491409302
train: epoch 144, loss 0.21633696556091309, acc=0.8846666812896729, loss=0.21633696556091309
test: epoch 144, loss 0.8661847710609436, acc=0.7444444298744202, loss=0.8661847710609436
train: epoch 145, loss 0.2105950564146042, acc=0.8871666789054871, loss=0.2105950564146042
test: epoch 145, loss 0.8639317750930786, acc=0.7472222447395325, loss=0.8639317750930786
train: epoch 146, loss 0.2123543918132782, acc=0.8895000219345093, loss=0.2123543918132782
test: epoch 146, loss 0.8767645955085754, acc=0.769444465637207, loss=0.8767645955085754
train: epoch 147, loss 0.2041339874267578, acc=0.8926666378974915, loss=0.2041339874267578
test: epoch 147, loss 0.7500151991844177, acc=0.769444465637207, loss=0.7500151991844177
train: epoch 148, loss 0.200394868850708, acc=0.8932777643203735, loss=0.200394868850708
test: epoch 148, loss 0.625938355922699, acc=0.7972221970558167, loss=0.625938355922699
train: epoch 149, loss 0.1929641216993332, acc=0.8922777771949768, loss=0.1929641216993332
test: epoch 149, loss 0.7179322242736816, acc=0.8055555820465088, loss=0.7179322242736816
train: epoch 150, loss 0.20252956449985504, acc=0.8932222127914429, loss=0.20252956449985504
test: epoch 150, loss 0.6861532330513, acc=0.800000011920929, loss=0.6861532330513
