# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=1.5", "--temp_decay=0.99", "--one_hot=1", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=410498240, receiver_embed_dim=128, save_run=0, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=410498240, receiver_embed_dim=128, save_run=False, temp_decay=0.99, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.1032896041870117, acc=0.08433333039283752, loss=3.1032896041870117
test: epoch 1, loss 3.0921735763549805, acc=0.10277777910232544, loss=3.0921735763549805
train: epoch 2, loss 1.7380859851837158, acc=0.32027778029441833, loss=1.7380859851837158
test: epoch 2, loss 2.7580058574676514, acc=0.17222222685813904, loss=2.7580058574676514
train: epoch 3, loss 1.328089714050293, acc=0.456722229719162, loss=1.328089714050293
test: epoch 3, loss 2.5002095699310303, acc=0.2222222238779068, loss=2.5002095699310303
train: epoch 4, loss 1.1485190391540527, acc=0.5367222428321838, loss=1.1485190391540527
test: epoch 4, loss 2.2145836353302, acc=0.23333333432674408, loss=2.2145836353302
train: epoch 5, loss 1.014744520187378, acc=0.5899999737739563, loss=1.014744520187378
test: epoch 5, loss 2.0603272914886475, acc=0.25, loss=2.0603272914886475
train: epoch 6, loss 0.9164018034934998, acc=0.6389444470405579, loss=0.9164018034934998
test: epoch 6, loss 2.192209243774414, acc=0.2611111104488373, loss=2.192209243774414
train: epoch 7, loss 0.8347614407539368, acc=0.6698889136314392, loss=0.8347614407539368
test: epoch 7, loss 2.05385684967041, acc=0.2944444417953491, loss=2.05385684967041
train: epoch 8, loss 0.7646539211273193, acc=0.6995555758476257, loss=0.7646539211273193
test: epoch 8, loss 1.6963496208190918, acc=0.3499999940395355, loss=1.6963496208190918
train: epoch 9, loss 0.7254403829574585, acc=0.7212222218513489, loss=0.7254403829574585
test: epoch 9, loss 1.9670257568359375, acc=0.3055555522441864, loss=1.9670257568359375
train: epoch 10, loss 0.675751805305481, acc=0.7363333106040955, loss=0.675751805305481
test: epoch 10, loss 1.7235805988311768, acc=0.31388887763023376, loss=1.7235805988311768
train: epoch 11, loss 0.6226118803024292, acc=0.7618333101272583, loss=0.6226118803024292
test: epoch 11, loss 1.7650806903839111, acc=0.3722222149372101, loss=1.7650806903839111
train: epoch 12, loss 0.6070507764816284, acc=0.7627221941947937, loss=0.6070507764816284
test: epoch 12, loss 1.5256375074386597, acc=0.38055557012557983, loss=1.5256375074386597
train: epoch 13, loss 0.5615805387496948, acc=0.7848333120346069, loss=0.5615805387496948
test: epoch 13, loss 1.6437039375305176, acc=0.38055557012557983, loss=1.6437039375305176
train: epoch 14, loss 0.5451666712760925, acc=0.7911111116409302, loss=0.5451666712760925
test: epoch 14, loss 1.7010962963104248, acc=0.38333332538604736, loss=1.7010962963104248
train: epoch 15, loss 0.524376630783081, acc=0.804444432258606, loss=0.524376630783081
test: epoch 15, loss 1.6889137029647827, acc=0.3888888955116272, loss=1.6889137029647827
train: epoch 16, loss 0.4987967610359192, acc=0.8113333582878113, loss=0.4987967610359192
test: epoch 16, loss 1.9168108701705933, acc=0.39722222089767456, loss=1.9168108701705933
train: epoch 17, loss 0.48969823122024536, acc=0.8131111264228821, loss=0.48969823122024536
test: epoch 17, loss 1.6402591466903687, acc=0.4194444417953491, loss=1.6402591466903687
train: epoch 18, loss 0.4615662395954132, acc=0.8241666555404663, loss=0.4615662395954132
test: epoch 18, loss 1.538605809211731, acc=0.42222222685813904, loss=1.538605809211731
train: epoch 19, loss 0.4509877562522888, acc=0.8270555734634399, loss=0.4509877562522888
test: epoch 19, loss 1.5303210020065308, acc=0.45277777314186096, loss=1.5303210020065308
train: epoch 20, loss 0.431654155254364, acc=0.8372222185134888, loss=0.431654155254364
test: epoch 20, loss 1.760903000831604, acc=0.4000000059604645, loss=1.760903000831604
train: epoch 21, loss 0.41650503873825073, acc=0.8414999842643738, loss=0.41650503873825073
test: epoch 21, loss 1.7521196603775024, acc=0.42222222685813904, loss=1.7521196603775024
train: epoch 22, loss 0.4083995223045349, acc=0.847000002861023, loss=0.4083995223045349
test: epoch 22, loss 1.5601938962936401, acc=0.4833333194255829, loss=1.5601938962936401
train: epoch 23, loss 0.38898539543151855, acc=0.8523333072662354, loss=0.38898539543151855
test: epoch 23, loss 1.6820353269577026, acc=0.44999998807907104, loss=1.6820353269577026
train: epoch 24, loss 0.3878616392612457, acc=0.854888916015625, loss=0.3878616392612457
test: epoch 24, loss 1.5730606317520142, acc=0.45277777314186096, loss=1.5730606317520142
train: epoch 25, loss 0.3717031180858612, acc=0.859333336353302, loss=0.3717031180858612
test: epoch 25, loss 1.5801074504852295, acc=0.4749999940395355, loss=1.5801074504852295
train: epoch 26, loss 0.3734646141529083, acc=0.8588333129882812, loss=0.3734646141529083
test: epoch 26, loss 1.578670620918274, acc=0.49444442987442017, loss=1.578670620918274
train: epoch 27, loss 0.35703611373901367, acc=0.8646110892295837, loss=0.35703611373901367
test: epoch 27, loss 1.6006660461425781, acc=0.5083333253860474, loss=1.6006660461425781
train: epoch 28, loss 0.36258217692375183, acc=0.8652222156524658, loss=0.36258217692375183
test: epoch 28, loss 1.3999841213226318, acc=0.5027777552604675, loss=1.3999841213226318
train: epoch 29, loss 0.34169167280197144, acc=0.8696110844612122, loss=0.34169167280197144
test: epoch 29, loss 1.43441641330719, acc=0.5166666507720947, loss=1.43441641330719
train: epoch 30, loss 0.3461611270904541, acc=0.8697222471237183, loss=0.3461611270904541
test: epoch 30, loss 1.4089049100875854, acc=0.5166666507720947, loss=1.4089049100875854
train: epoch 31, loss 0.32407140731811523, acc=0.8763889074325562, loss=0.32407140731811523
test: epoch 31, loss 1.4150052070617676, acc=0.5333333611488342, loss=1.4150052070617676
train: epoch 32, loss 0.3201155364513397, acc=0.8831111192703247, loss=0.3201155364513397
test: epoch 32, loss 1.5850504636764526, acc=0.5222222208976746, loss=1.5850504636764526
train: epoch 33, loss 0.33194470405578613, acc=0.8770555257797241, loss=0.33194470405578613
test: epoch 33, loss 1.3963490724563599, acc=0.5444444417953491, loss=1.3963490724563599
train: epoch 34, loss 0.3077966570854187, acc=0.8845000267028809, loss=0.3077966570854187
test: epoch 34, loss 1.2520713806152344, acc=0.5972222089767456, loss=1.2520713806152344
train: epoch 35, loss 0.3018304407596588, acc=0.8866666555404663, loss=0.3018304407596588
test: epoch 35, loss 1.357448697090149, acc=0.550000011920929, loss=1.357448697090149
train: epoch 36, loss 0.2950504422187805, acc=0.8901110887527466, loss=0.2950504422187805
test: epoch 36, loss 1.081246256828308, acc=0.6083333492279053, loss=1.081246256828308
train: epoch 37, loss 0.2955375611782074, acc=0.8888888955116272, loss=0.2955375611782074
test: epoch 37, loss 1.331382155418396, acc=0.5638889074325562, loss=1.331382155418396
train: epoch 38, loss 0.3015991151332855, acc=0.8889444470405579, loss=0.3015991151332855
test: epoch 38, loss 1.2393722534179688, acc=0.6111111044883728, loss=1.2393722534179688
train: epoch 39, loss 0.3009880483150482, acc=0.8890555500984192, loss=0.3009880483150482
test: epoch 39, loss 1.0703643560409546, acc=0.6277777552604675, loss=1.0703643560409546
train: epoch 40, loss 0.2799251973628998, acc=0.8945555686950684, loss=0.2799251973628998
test: epoch 40, loss 1.2860419750213623, acc=0.6194444298744202, loss=1.2860419750213623
train: epoch 41, loss 0.27872633934020996, acc=0.8937222361564636, loss=0.27872633934020996
test: epoch 41, loss 1.0866429805755615, acc=0.6611111164093018, loss=1.0866429805755615
train: epoch 42, loss 0.2859559655189514, acc=0.8956111073493958, loss=0.2859559655189514
test: epoch 42, loss 0.9432437419891357, acc=0.6527777910232544, loss=0.9432437419891357
train: epoch 43, loss 0.27808913588523865, acc=0.8963888883590698, loss=0.27808913588523865
test: epoch 43, loss 0.8918619751930237, acc=0.6944444179534912, loss=0.8918619751930237
train: epoch 44, loss 0.2659202814102173, acc=0.898888885974884, loss=0.2659202814102173
test: epoch 44, loss 1.1351302862167358, acc=0.6583333611488342, loss=1.1351302862167358
train: epoch 45, loss 0.27112290263175964, acc=0.8976666927337646, loss=0.27112290263175964
test: epoch 45, loss 1.0327019691467285, acc=0.6833333373069763, loss=1.0327019691467285
train: epoch 46, loss 0.25674766302108765, acc=0.9001666903495789, loss=0.25674766302108765
test: epoch 46, loss 0.9544711112976074, acc=0.7027778029441833, loss=0.9544711112976074
train: epoch 47, loss 0.26783475279808044, acc=0.8973888754844666, loss=0.26783475279808044
test: epoch 47, loss 1.0717058181762695, acc=0.6833333373069763, loss=1.0717058181762695
train: epoch 48, loss 0.2681800127029419, acc=0.8980555534362793, loss=0.2681800127029419
test: epoch 48, loss 1.0797038078308105, acc=0.7027778029441833, loss=1.0797038078308105
train: epoch 49, loss 0.2585565745830536, acc=0.9008888602256775, loss=0.2585565745830536
test: epoch 49, loss 0.9030761122703552, acc=0.7138888835906982, loss=0.9030761122703552
train: epoch 50, loss 0.2601432204246521, acc=0.9020000100135803, loss=0.2601432204246521
test: epoch 50, loss 0.96132892370224, acc=0.7250000238418579, loss=0.96132892370224
train: epoch 51, loss 0.24263036251068115, acc=0.9051666855812073, loss=0.24263036251068115
test: epoch 51, loss 0.953031599521637, acc=0.7277777791023254, loss=0.953031599521637
train: epoch 52, loss 0.2513750493526459, acc=0.9041110873222351, loss=0.2513750493526459
test: epoch 52, loss 0.8436093926429749, acc=0.6944444179534912, loss=0.8436093926429749
train: epoch 53, loss 0.24796535074710846, acc=0.9047777652740479, loss=0.24796535074710846
test: epoch 53, loss 0.946664035320282, acc=0.7222222089767456, loss=0.946664035320282
train: epoch 54, loss 0.2530989944934845, acc=0.9047222137451172, loss=0.2530989944934845
test: epoch 54, loss 0.8511422276496887, acc=0.7583333253860474, loss=0.8511422276496887
train: epoch 55, loss 0.24474233388900757, acc=0.9057777523994446, loss=0.24474233388900757
test: epoch 55, loss 0.8077223896980286, acc=0.730555534362793, loss=0.8077223896980286
train: epoch 56, loss 0.24431224167346954, acc=0.9058889150619507, loss=0.24431224167346954
test: epoch 56, loss 0.9194537997245789, acc=0.7472222447395325, loss=0.9194537997245789
train: epoch 57, loss 0.23614326119422913, acc=0.9083333611488342, loss=0.23614326119422913
test: epoch 57, loss 0.8844916820526123, acc=0.7722222208976746, loss=0.8844916820526123
train: epoch 58, loss 0.24426907300949097, acc=0.9067222476005554, loss=0.24426907300949097
test: epoch 58, loss 0.6480291485786438, acc=0.7722222208976746, loss=0.6480291485786438
train: epoch 59, loss 0.24205434322357178, acc=0.9073888659477234, loss=0.24205434322357178
test: epoch 59, loss 0.9545667171478271, acc=0.7722222208976746, loss=0.9545667171478271
train: epoch 60, loss 0.23532834649085999, acc=0.910611093044281, loss=0.23532834649085999
test: epoch 60, loss 0.6884616613388062, acc=0.7638888955116272, loss=0.6884616613388062
train: epoch 61, loss 0.23557278513908386, acc=0.9084444642066956, loss=0.23557278513908386
test: epoch 61, loss 0.6936486959457397, acc=0.7888888716697693, loss=0.6936486959457397
train: epoch 62, loss 0.23833546042442322, acc=0.9091110825538635, loss=0.23833546042442322
test: epoch 62, loss 0.5777652263641357, acc=0.7805555462837219, loss=0.5777652263641357
train: epoch 63, loss 0.22529222071170807, acc=0.9108889102935791, loss=0.22529222071170807
test: epoch 63, loss 0.6857974529266357, acc=0.7916666865348816, loss=0.6857974529266357
train: epoch 64, loss 0.23479846119880676, acc=0.9068333506584167, loss=0.23479846119880676
test: epoch 64, loss 0.6972869038581848, acc=0.7916666865348816, loss=0.6972869038581848
train: epoch 65, loss 0.2192820906639099, acc=0.9131666421890259, loss=0.2192820906639099
test: epoch 65, loss 0.5692457556724548, acc=0.7861111164093018, loss=0.5692457556724548
train: epoch 66, loss 0.23139667510986328, acc=0.9099444150924683, loss=0.23139667510986328
test: epoch 66, loss 0.649899423122406, acc=0.7916666865348816, loss=0.649899423122406
train: epoch 67, loss 0.22521954774856567, acc=0.9105555415153503, loss=0.22521954774856567
test: epoch 67, loss 0.7072944641113281, acc=0.8027777671813965, loss=0.7072944641113281
train: epoch 68, loss 0.22091872990131378, acc=0.9108333587646484, loss=0.22091872990131378
test: epoch 68, loss 0.7418538331985474, acc=0.7972221970558167, loss=0.7418538331985474
train: epoch 69, loss 0.22533264756202698, acc=0.9119444489479065, loss=0.22533264756202698
test: epoch 69, loss 0.6480013132095337, acc=0.7972221970558167, loss=0.6480013132095337
train: epoch 70, loss 0.21905860304832458, acc=0.9116111397743225, loss=0.21905860304832458
test: epoch 70, loss 0.6630961894989014, acc=0.800000011920929, loss=0.6630961894989014
train: epoch 71, loss 0.21533526480197906, acc=0.9148889183998108, loss=0.21533526480197906
test: epoch 71, loss 0.5707371234893799, acc=0.7944444417953491, loss=0.5707371234893799
train: epoch 72, loss 0.2255079448223114, acc=0.9091110825538635, loss=0.2255079448223114
test: epoch 72, loss 0.6175114512443542, acc=0.800000011920929, loss=0.6175114512443542
train: epoch 73, loss 0.21268372237682343, acc=0.914722204208374, loss=0.21268372237682343
test: epoch 73, loss 0.5319541096687317, acc=0.800000011920929, loss=0.5319541096687317
train: epoch 74, loss 0.2190295308828354, acc=0.9103888869285583, loss=0.2190295308828354
test: epoch 74, loss 0.5492560863494873, acc=0.8027777671813965, loss=0.5492560863494873
train: epoch 75, loss 0.21171851456165314, acc=0.9173333048820496, loss=0.21171851456165314
test: epoch 75, loss 0.6483975052833557, acc=0.8027777671813965, loss=0.6483975052833557
train: epoch 76, loss 0.21442179381847382, acc=0.9126666784286499, loss=0.21442179381847382
test: epoch 76, loss 0.6558666825294495, acc=0.8027777671813965, loss=0.6558666825294495
train: epoch 77, loss 0.21775351464748383, acc=0.91438889503479, loss=0.21775351464748383
test: epoch 77, loss 0.585885226726532, acc=0.7888888716697693, loss=0.585885226726532
train: epoch 78, loss 0.2130519151687622, acc=0.9144444465637207, loss=0.2130519151687622
test: epoch 78, loss 0.5954388380050659, acc=0.800000011920929, loss=0.5954388380050659
train: epoch 79, loss 0.2134091854095459, acc=0.9108889102935791, loss=0.2134091854095459
test: epoch 79, loss 0.5994952917098999, acc=0.8027777671813965, loss=0.5994952917098999
train: epoch 80, loss 0.20431216061115265, acc=0.9141111373901367, loss=0.20431216061115265
test: epoch 80, loss 0.552765965461731, acc=0.8027777671813965, loss=0.552765965461731
train: epoch 81, loss 0.2051399201154709, acc=0.9182222485542297, loss=0.2051399201154709
test: epoch 81, loss 0.6277631521224976, acc=0.8027777671813965, loss=0.6277631521224976
train: epoch 82, loss 0.2046983540058136, acc=0.918833315372467, loss=0.2046983540058136
test: epoch 82, loss 0.6824864745140076, acc=0.8027777671813965, loss=0.6824864745140076
train: epoch 83, loss 0.20807217061519623, acc=0.9164444208145142, loss=0.20807217061519623
test: epoch 83, loss 0.5004082918167114, acc=0.8027777671813965, loss=0.5004082918167114
train: epoch 84, loss 0.21221429109573364, acc=0.9166666865348816, loss=0.21221429109573364
test: epoch 84, loss 0.628455638885498, acc=0.800000011920929, loss=0.628455638885498
train: epoch 85, loss 0.20272241532802582, acc=0.9161666631698608, loss=0.20272241532802582
test: epoch 85, loss 0.6548683047294617, acc=0.8027777671813965, loss=0.6548683047294617
train: epoch 86, loss 0.2043936401605606, acc=0.9170555472373962, loss=0.2043936401605606
test: epoch 86, loss 0.5910481214523315, acc=0.8027777671813965, loss=0.5910481214523315
train: epoch 87, loss 0.20499226450920105, acc=0.9178333282470703, loss=0.20499226450920105
test: epoch 87, loss 0.7189098000526428, acc=0.8027777671813965, loss=0.7189098000526428
train: epoch 88, loss 0.20067162811756134, acc=0.9182222485542297, loss=0.20067162811756134
test: epoch 88, loss 0.5832125544548035, acc=0.8055555820465088, loss=0.5832125544548035
train: epoch 89, loss 0.20334844291210175, acc=0.9176666736602783, loss=0.20334844291210175
test: epoch 89, loss 0.6647431254386902, acc=0.8055555820465088, loss=0.6647431254386902
train: epoch 90, loss 0.20043791830539703, acc=0.9200000166893005, loss=0.20043791830539703
test: epoch 90, loss 0.62151038646698, acc=0.7944444417953491, loss=0.62151038646698
train: epoch 91, loss 0.20358559489250183, acc=0.9168888926506042, loss=0.20358559489250183
test: epoch 91, loss 0.5673909187316895, acc=0.8055555820465088, loss=0.5673909187316895
train: epoch 92, loss 0.1960495114326477, acc=0.9183889031410217, loss=0.1960495114326477
test: epoch 92, loss 0.5204176902770996, acc=0.8055555820465088, loss=0.5204176902770996
train: epoch 93, loss 0.20107756555080414, acc=0.9183889031410217, loss=0.20107756555080414
test: epoch 93, loss 0.5956735014915466, acc=0.8055555820465088, loss=0.5956735014915466
train: epoch 94, loss 0.19651289284229279, acc=0.9196110963821411, loss=0.19651289284229279
test: epoch 94, loss 0.5824502110481262, acc=0.8055555820465088, loss=0.5824502110481262
train: epoch 95, loss 0.2004133015871048, acc=0.9174444675445557, loss=0.2004133015871048
test: epoch 95, loss 0.691017746925354, acc=0.8055555820465088, loss=0.691017746925354
train: epoch 96, loss 0.20043568313121796, acc=0.9167777895927429, loss=0.20043568313121796
test: epoch 96, loss 0.5548869967460632, acc=0.8055555820465088, loss=0.5548869967460632
train: epoch 97, loss 0.19258281588554382, acc=0.9229444265365601, loss=0.19258281588554382
test: epoch 97, loss 0.61030113697052, acc=0.8055555820465088, loss=0.61030113697052
train: epoch 98, loss 0.19952653348445892, acc=0.9224444627761841, loss=0.19952653348445892
test: epoch 98, loss 0.5609533190727234, acc=0.8055555820465088, loss=0.5609533190727234
train: epoch 99, loss 0.19729286432266235, acc=0.9179444313049316, loss=0.19729286432266235
test: epoch 99, loss 0.5680429339408875, acc=0.8055555820465088, loss=0.5680429339408875
train: epoch 100, loss 0.1982351541519165, acc=0.9191666841506958, loss=0.1982351541519165
test: epoch 100, loss 0.5656570792198181, acc=0.8027777671813965, loss=0.5656570792198181
train: epoch 101, loss 0.19151845574378967, acc=0.9221110939979553, loss=0.19151845574378967
test: epoch 101, loss 0.7583522796630859, acc=0.8027777671813965, loss=0.7583522796630859
train: epoch 102, loss 0.19153273105621338, acc=0.9210000038146973, loss=0.19153273105621338
test: epoch 102, loss 0.6087387204170227, acc=0.8055555820465088, loss=0.6087387204170227
train: epoch 103, loss 0.19514960050582886, acc=0.9194999933242798, loss=0.19514960050582886
test: epoch 103, loss 0.5389171242713928, acc=0.8055555820465088, loss=0.5389171242713928
train: epoch 104, loss 0.19457300007343292, acc=0.9201666712760925, loss=0.19457300007343292
test: epoch 104, loss 0.6585500240325928, acc=0.8111110925674438, loss=0.6585500240325928
train: epoch 105, loss 0.19372570514678955, acc=0.9205555319786072, loss=0.19372570514678955
test: epoch 105, loss 0.5753417611122131, acc=0.8055555820465088, loss=0.5753417611122131
train: epoch 106, loss 0.19482508301734924, acc=0.9207777976989746, loss=0.19482508301734924
test: epoch 106, loss 0.6513704061508179, acc=0.8055555820465088, loss=0.6513704061508179
train: epoch 107, loss 0.19831612706184387, acc=0.9199444651603699, loss=0.19831612706184387
test: epoch 107, loss 0.5894757509231567, acc=0.8083333373069763, loss=0.5894757509231567
train: epoch 108, loss 0.1986219584941864, acc=0.9188888669013977, loss=0.1986219584941864
test: epoch 108, loss 0.6393155455589294, acc=0.8055555820465088, loss=0.6393155455589294
train: epoch 109, loss 0.1947811096906662, acc=0.921500027179718, loss=0.1947811096906662
test: epoch 109, loss 0.6887280344963074, acc=0.8055555820465088, loss=0.6887280344963074
train: epoch 110, loss 0.19287331402301788, acc=0.9227777719497681, loss=0.19287331402301788
test: epoch 110, loss 0.5559897422790527, acc=0.8055555820465088, loss=0.5559897422790527
train: epoch 111, loss 0.18558235466480255, acc=0.9227777719497681, loss=0.18558235466480255
test: epoch 111, loss 0.6502811312675476, acc=0.800000011920929, loss=0.6502811312675476
train: epoch 112, loss 0.19173967838287354, acc=0.9203888773918152, loss=0.19173967838287354
test: epoch 112, loss 0.6208833456039429, acc=0.8055555820465088, loss=0.6208833456039429
train: epoch 113, loss 0.17924682796001434, acc=0.9268333315849304, loss=0.17924682796001434
test: epoch 113, loss 0.7278822064399719, acc=0.8055555820465088, loss=0.7278822064399719
train: epoch 114, loss 0.19599410891532898, acc=0.9217222332954407, loss=0.19599410891532898
test: epoch 114, loss 0.6060213446617126, acc=0.8027777671813965, loss=0.6060213446617126
train: epoch 115, loss 0.19262032210826874, acc=0.9219444394111633, loss=0.19262032210826874
test: epoch 115, loss 0.5668048858642578, acc=0.8055555820465088, loss=0.5668048858642578
train: epoch 116, loss 0.19268982112407684, acc=0.9205555319786072, loss=0.19268982112407684
test: epoch 116, loss 0.6662514209747314, acc=0.8055555820465088, loss=0.6662514209747314
train: epoch 117, loss 0.1902349591255188, acc=0.9225555658340454, loss=0.1902349591255188
test: epoch 117, loss 0.6224348545074463, acc=0.8055555820465088, loss=0.6224348545074463
train: epoch 118, loss 0.18907040357589722, acc=0.9228333234786987, loss=0.18907040357589722
test: epoch 118, loss 0.5664441585540771, acc=0.8083333373069763, loss=0.5664441585540771
train: epoch 119, loss 0.1874227225780487, acc=0.920722246170044, loss=0.1874227225780487
test: epoch 119, loss 0.6706799268722534, acc=0.8083333373069763, loss=0.6706799268722534
train: epoch 120, loss 0.18602338433265686, acc=0.924833357334137, loss=0.18602338433265686
test: epoch 120, loss 0.6401706337928772, acc=0.8083333373069763, loss=0.6401706337928772
train: epoch 121, loss 0.18782976269721985, acc=0.9226666688919067, loss=0.18782976269721985
test: epoch 121, loss 0.6152578592300415, acc=0.8027777671813965, loss=0.6152578592300415
train: epoch 122, loss 0.18772056698799133, acc=0.925611138343811, loss=0.18772056698799133
test: epoch 122, loss 0.701924204826355, acc=0.8027777671813965, loss=0.701924204826355
train: epoch 123, loss 0.1925736665725708, acc=0.921500027179718, loss=0.1925736665725708
test: epoch 123, loss 0.5640653371810913, acc=0.8083333373069763, loss=0.5640653371810913
train: epoch 124, loss 0.1816435158252716, acc=0.9260555505752563, loss=0.1816435158252716
test: epoch 124, loss 0.5919342041015625, acc=0.8083333373069763, loss=0.5919342041015625
train: epoch 125, loss 0.19271181523799896, acc=0.9226666688919067, loss=0.19271181523799896
test: epoch 125, loss 0.6034725904464722, acc=0.8055555820465088, loss=0.6034725904464722
train: epoch 126, loss 0.18271873891353607, acc=0.9256666898727417, loss=0.18271873891353607
test: epoch 126, loss 0.6600704193115234, acc=0.8083333373069763, loss=0.6600704193115234
train: epoch 127, loss 0.18389366567134857, acc=0.926111102104187, loss=0.18389366567134857
test: epoch 127, loss 0.6547704339027405, acc=0.8083333373069763, loss=0.6547704339027405
train: epoch 128, loss 0.18684488534927368, acc=0.9244444370269775, loss=0.18684488534927368
test: epoch 128, loss 0.6605268716812134, acc=0.8083333373069763, loss=0.6605268716812134
train: epoch 129, loss 0.18064744770526886, acc=0.9263333082199097, loss=0.18064744770526886
test: epoch 129, loss 0.5483286380767822, acc=0.8055555820465088, loss=0.5483286380767822
train: epoch 130, loss 0.1801992952823639, acc=0.9258333444595337, loss=0.1801992952823639
test: epoch 130, loss 0.5845907330513, acc=0.8083333373069763, loss=0.5845907330513
train: epoch 131, loss 0.18294988572597504, acc=0.9256666898727417, loss=0.18294988572597504
test: epoch 131, loss 0.592647135257721, acc=0.8083333373069763, loss=0.592647135257721
train: epoch 132, loss 0.1829441338777542, acc=0.926277756690979, loss=0.1829441338777542
test: epoch 132, loss 0.6523702144622803, acc=0.8083333373069763, loss=0.6523702144622803
train: epoch 133, loss 0.18647585809230804, acc=0.9245555400848389, loss=0.18647585809230804
test: epoch 133, loss 0.6974117159843445, acc=0.8083333373069763, loss=0.6974117159843445
train: epoch 134, loss 0.18130247294902802, acc=0.9256666898727417, loss=0.18130247294902802
test: epoch 134, loss 0.5679093599319458, acc=0.8138889074325562, loss=0.5679093599319458
train: epoch 135, loss 0.18772566318511963, acc=0.9242777824401855, loss=0.18772566318511963
test: epoch 135, loss 0.6376158595085144, acc=0.8055555820465088, loss=0.6376158595085144
train: epoch 136, loss 0.18300090730190277, acc=0.9253333210945129, loss=0.18300090730190277
test: epoch 136, loss 0.5555136203765869, acc=0.8138889074325562, loss=0.5555136203765869
train: epoch 137, loss 0.18026910722255707, acc=0.9282222390174866, loss=0.18026910722255707
test: epoch 137, loss 0.5887362957000732, acc=0.8055555820465088, loss=0.5887362957000732
train: epoch 138, loss 0.18468908965587616, acc=0.9252777695655823, loss=0.18468908965587616
test: epoch 138, loss 0.6635417342185974, acc=0.8055555820465088, loss=0.6635417342185974
train: epoch 139, loss 0.1874198466539383, acc=0.9227222204208374, loss=0.1874198466539383
test: epoch 139, loss 0.5799406170845032, acc=0.8083333373069763, loss=0.5799406170845032
train: epoch 140, loss 0.18528971076011658, acc=0.9236666560173035, loss=0.18528971076011658
test: epoch 140, loss 0.5520817637443542, acc=0.8083333373069763, loss=0.5520817637443542
train: epoch 141, loss 0.18653839826583862, acc=0.9253888726234436, loss=0.18653839826583862
test: epoch 141, loss 0.5901448130607605, acc=0.8083333373069763, loss=0.5901448130607605
train: epoch 142, loss 0.1763618141412735, acc=0.9271666407585144, loss=0.1763618141412735
test: epoch 142, loss 0.6386817693710327, acc=0.8083333373069763, loss=0.6386817693710327
train: epoch 143, loss 0.1801951676607132, acc=0.925000011920929, loss=0.1801951676607132
test: epoch 143, loss 0.5836539268493652, acc=0.8083333373069763, loss=0.5836539268493652
train: epoch 144, loss 0.18035989999771118, acc=0.9269444346427917, loss=0.18035989999771118
test: epoch 144, loss 0.7567766904830933, acc=0.8055555820465088, loss=0.7567766904830933
train: epoch 145, loss 0.18080998957157135, acc=0.9265555739402771, loss=0.18080998957157135
test: epoch 145, loss 0.6335676312446594, acc=0.8083333373069763, loss=0.6335676312446594
train: epoch 146, loss 0.18188871443271637, acc=0.9263333082199097, loss=0.18188871443271637
test: epoch 146, loss 0.6510225534439087, acc=0.8138889074325562, loss=0.6510225534439087
train: epoch 147, loss 0.18205595016479492, acc=0.9254444241523743, loss=0.18205595016479492
test: epoch 147, loss 0.5969394445419312, acc=0.8083333373069763, loss=0.5969394445419312
train: epoch 148, loss 0.18139277398586273, acc=0.9244444370269775, loss=0.18139277398586273
test: epoch 148, loss 0.6157669425010681, acc=0.8055555820465088, loss=0.6157669425010681
train: epoch 149, loss 0.18195746839046478, acc=0.9265000224113464, loss=0.18195746839046478
test: epoch 149, loss 0.642055094242096, acc=0.8166666626930237, loss=0.642055094242096
train: epoch 150, loss 0.17984332144260406, acc=0.925611138343811, loss=0.17984332144260406
test: epoch 150, loss 0.5861625075340271, acc=0.8083333373069763, loss=0.5861625075340271
