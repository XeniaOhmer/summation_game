# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=2.0", "--temp_decay=1", "--one_hot=0", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=1566247325, receiver_embed_dim=128, save_run=0, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=1566247325, receiver_embed_dim=128, save_run=False, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.2255876064300537, acc=0.18727777898311615, loss=2.2255876064300537
test: epoch 1, loss 7.187597751617432, acc=0.04722222313284874, loss=7.187597751617432
train: epoch 2, loss 1.4790840148925781, acc=0.37511110305786133, loss=1.4790840148925781
test: epoch 2, loss 4.8904218673706055, acc=0.17499999701976776, loss=4.8904218673706055
train: epoch 3, loss 1.2026684284210205, acc=0.4852222204208374, loss=1.2026684284210205
test: epoch 3, loss 4.230627536773682, acc=0.16944444179534912, loss=4.230627536773682
train: epoch 4, loss 0.9941900968551636, acc=0.5759444236755371, loss=0.9941900968551636
test: epoch 4, loss 4.6205735206604, acc=0.13333334028720856, loss=4.6205735206604
train: epoch 5, loss 0.8970673084259033, acc=0.6236666440963745, loss=0.8970673084259033
test: epoch 5, loss 3.4538209438323975, acc=0.21666666865348816, loss=3.4538209438323975
train: epoch 6, loss 0.8213590383529663, acc=0.6604999899864197, loss=0.8213590383529663
test: epoch 6, loss 4.937023162841797, acc=0.2222222238779068, loss=4.937023162841797
train: epoch 7, loss 0.739337146282196, acc=0.6930555701255798, loss=0.739337146282196
test: epoch 7, loss 4.334195137023926, acc=0.21944443881511688, loss=4.334195137023926
train: epoch 8, loss 0.7074346542358398, acc=0.7124999761581421, loss=0.7074346542358398
test: epoch 8, loss 3.8309035301208496, acc=0.2361111044883728, loss=3.8309035301208496
train: epoch 9, loss 0.6370890140533447, acc=0.742111086845398, loss=0.6370890140533447
test: epoch 9, loss 3.2984392642974854, acc=0.24166665971279144, loss=3.2984392642974854
train: epoch 10, loss 0.6310613751411438, acc=0.7421666383743286, loss=0.6310613751411438
test: epoch 10, loss 2.643164873123169, acc=0.25, loss=2.643164873123169
train: epoch 11, loss 0.6027848124504089, acc=0.7562222480773926, loss=0.6027848124504089
test: epoch 11, loss 3.1813769340515137, acc=0.2611111104488373, loss=3.1813769340515137
train: epoch 12, loss 0.5646257400512695, acc=0.777222216129303, loss=0.5646257400512695
test: epoch 12, loss 3.2254321575164795, acc=0.24722221493721008, loss=3.2254321575164795
train: epoch 13, loss 0.5224130749702454, acc=0.7953333258628845, loss=0.5224130749702454
test: epoch 13, loss 2.7536144256591797, acc=0.3222222328186035, loss=2.7536144256591797
train: epoch 14, loss 0.5376076102256775, acc=0.7878888845443726, loss=0.5376076102256775
test: epoch 14, loss 3.5740859508514404, acc=0.18611110746860504, loss=3.5740859508514404
train: epoch 15, loss 0.49533554911613464, acc=0.8050000071525574, loss=0.49533554911613464
test: epoch 15, loss 2.275832414627075, acc=0.32499998807907104, loss=2.275832414627075
train: epoch 16, loss 0.4658726751804352, acc=0.812166690826416, loss=0.4658726751804352
test: epoch 16, loss 2.8228659629821777, acc=0.27222222089767456, loss=2.8228659629821777
train: epoch 17, loss 0.4596982002258301, acc=0.8159999847412109, loss=0.4596982002258301
test: epoch 17, loss 2.2072246074676514, acc=0.41111111640930176, loss=2.2072246074676514
train: epoch 18, loss 0.4261725842952728, acc=0.8332777619361877, loss=0.4261725842952728
test: epoch 18, loss 3.011563301086426, acc=0.2888889014720917, loss=3.011563301086426
train: epoch 19, loss 0.43722042441368103, acc=0.8255000114440918, loss=0.43722042441368103
test: epoch 19, loss 2.3068714141845703, acc=0.35277777910232544, loss=2.3068714141845703
train: epoch 20, loss 0.4240354299545288, acc=0.8309444189071655, loss=0.4240354299545288
test: epoch 20, loss 2.484076499938965, acc=0.2666666805744171, loss=2.484076499938965
train: epoch 21, loss 0.427640438079834, acc=0.8314999938011169, loss=0.427640438079834
test: epoch 21, loss 3.5185434818267822, acc=0.24444444477558136, loss=3.5185434818267822
train: epoch 22, loss 0.3892582952976227, acc=0.8495555520057678, loss=0.3892582952976227
test: epoch 22, loss 3.6245980262756348, acc=0.23888888955116272, loss=3.6245980262756348
train: epoch 23, loss 0.39349210262298584, acc=0.8461666703224182, loss=0.39349210262298584
test: epoch 23, loss 3.1814541816711426, acc=0.30000001192092896, loss=3.1814541816711426
train: epoch 24, loss 0.4041280448436737, acc=0.8363333344459534, loss=0.4041280448436737
test: epoch 24, loss 2.0954229831695557, acc=0.4055555462837219, loss=2.0954229831695557
train: epoch 25, loss 0.3730457127094269, acc=0.8543333411216736, loss=0.3730457127094269
test: epoch 25, loss 2.889902114868164, acc=0.29722222685813904, loss=2.889902114868164
train: epoch 26, loss 0.3376496136188507, acc=0.8699444532394409, loss=0.3376496136188507
test: epoch 26, loss 3.3865513801574707, acc=0.2527777850627899, loss=3.3865513801574707
train: epoch 27, loss 0.38860607147216797, acc=0.8489999771118164, loss=0.38860607147216797
test: epoch 27, loss 2.5653774738311768, acc=0.2888889014720917, loss=2.5653774738311768
train: epoch 28, loss 0.3495021462440491, acc=0.863444447517395, loss=0.3495021462440491
test: epoch 28, loss 1.9458649158477783, acc=0.3638888895511627, loss=1.9458649158477783
train: epoch 29, loss 0.34918686747550964, acc=0.8622221946716309, loss=0.34918686747550964
test: epoch 29, loss 2.2683892250061035, acc=0.3361110985279083, loss=2.2683892250061035
train: epoch 30, loss 0.33058786392211914, acc=0.8750555515289307, loss=0.33058786392211914
test: epoch 30, loss 2.287476062774658, acc=0.24166665971279144, loss=2.287476062774658
train: epoch 31, loss 0.33124929666519165, acc=0.8703888654708862, loss=0.33124929666519165
test: epoch 31, loss 2.789196729660034, acc=0.2805555462837219, loss=2.789196729660034
train: epoch 32, loss 0.3341763913631439, acc=0.8671666383743286, loss=0.3341763913631439
test: epoch 32, loss 1.8796658515930176, acc=0.39722222089767456, loss=1.8796658515930176
train: epoch 33, loss 0.3225484788417816, acc=0.8740555644035339, loss=0.3225484788417816
test: epoch 33, loss 2.374650478363037, acc=0.41111111640930176, loss=2.374650478363037
train: epoch 34, loss 0.32894307374954224, acc=0.8713333606719971, loss=0.32894307374954224
test: epoch 34, loss 2.1569671630859375, acc=0.2805555462837219, loss=2.1569671630859375
train: epoch 35, loss 0.3179394602775574, acc=0.8780555725097656, loss=0.3179394602775574
test: epoch 35, loss 2.45194411277771, acc=0.25833332538604736, loss=2.45194411277771
train: epoch 36, loss 0.339348167181015, acc=0.867111086845398, loss=0.339348167181015
test: epoch 36, loss 2.101254940032959, acc=0.3083333373069763, loss=2.101254940032959
train: epoch 37, loss 0.30992820858955383, acc=0.8769999742507935, loss=0.30992820858955383
test: epoch 37, loss 2.4462332725524902, acc=0.2611111104488373, loss=2.4462332725524902
train: epoch 38, loss 0.29524853825569153, acc=0.8872777819633484, loss=0.29524853825569153
test: epoch 38, loss 2.501105785369873, acc=0.38055557012557983, loss=2.501105785369873
train: epoch 39, loss 0.2865050137042999, acc=0.8897222280502319, loss=0.2865050137042999
test: epoch 39, loss 1.8982027769088745, acc=0.3722222149372101, loss=1.8982027769088745
train: epoch 40, loss 0.29798781871795654, acc=0.8885555267333984, loss=0.29798781871795654
test: epoch 40, loss 1.7336775064468384, acc=0.4055555462837219, loss=1.7336775064468384
train: epoch 41, loss 0.28391388058662415, acc=0.8918889164924622, loss=0.28391388058662415
test: epoch 41, loss 1.7862040996551514, acc=0.3777777850627899, loss=1.7862040996551514
train: epoch 42, loss 0.2790704667568207, acc=0.8923333287239075, loss=0.2790704667568207
test: epoch 42, loss 2.950981616973877, acc=0.2805555462837219, loss=2.950981616973877
train: epoch 43, loss 0.28786665201187134, acc=0.8881111145019531, loss=0.28786665201187134
test: epoch 43, loss 2.243877649307251, acc=0.30000001192092896, loss=2.243877649307251
train: epoch 44, loss 0.24898208677768707, acc=0.9056110978126526, loss=0.24898208677768707
test: epoch 44, loss 2.3140194416046143, acc=0.36666667461395264, loss=2.3140194416046143
train: epoch 45, loss 0.2727455198764801, acc=0.8962777853012085, loss=0.2727455198764801
test: epoch 45, loss 3.1316609382629395, acc=0.22777777910232544, loss=3.1316609382629395
train: epoch 46, loss 0.2734237015247345, acc=0.8945555686950684, loss=0.2734237015247345
test: epoch 46, loss 2.1992437839508057, acc=0.42500001192092896, loss=2.1992437839508057
train: epoch 47, loss 0.28048259019851685, acc=0.8927222490310669, loss=0.28048259019851685
test: epoch 47, loss 2.399966239929199, acc=0.3722222149372101, loss=2.399966239929199
train: epoch 48, loss 0.23132218420505524, acc=0.9117222428321838, loss=0.23132218420505524
test: epoch 48, loss 2.728893756866455, acc=0.2750000059604645, loss=2.728893756866455
train: epoch 49, loss 0.27407440543174744, acc=0.8933888673782349, loss=0.27407440543174744
test: epoch 49, loss 1.8172452449798584, acc=0.2888889014720917, loss=1.8172452449798584
train: epoch 50, loss 0.24329711496829987, acc=0.9049444198608398, loss=0.24329711496829987
test: epoch 50, loss 2.647243022918701, acc=0.31388887763023376, loss=2.647243022918701
train: epoch 51, loss 0.25646352767944336, acc=0.9029444456100464, loss=0.25646352767944336
test: epoch 51, loss 1.8820090293884277, acc=0.39722222089767456, loss=1.8820090293884277
train: epoch 52, loss 0.24686366319656372, acc=0.9048888683319092, loss=0.24686366319656372
test: epoch 52, loss 2.7254130840301514, acc=0.41111111640930176, loss=2.7254130840301514
train: epoch 53, loss 0.23945070803165436, acc=0.9083889126777649, loss=0.23945070803165436
test: epoch 53, loss 1.9658241271972656, acc=0.4055555462837219, loss=1.9658241271972656
train: epoch 54, loss 0.2546725571155548, acc=0.902222216129303, loss=0.2546725571155548
test: epoch 54, loss 2.576803684234619, acc=0.32499998807907104, loss=2.576803684234619
train: epoch 55, loss 0.2228451818227768, acc=0.9157222509384155, loss=0.2228451818227768
test: epoch 55, loss 1.8326650857925415, acc=0.4277777671813965, loss=1.8326650857925415
train: epoch 56, loss 0.22091548144817352, acc=0.9151666760444641, loss=0.22091548144817352
test: epoch 56, loss 2.223865509033203, acc=0.3361110985279083, loss=2.223865509033203
train: epoch 57, loss 0.23759552836418152, acc=0.9104999899864197, loss=0.23759552836418152
test: epoch 57, loss 1.6714481115341187, acc=0.42222222685813904, loss=1.6714481115341187
train: epoch 58, loss 0.2407214194536209, acc=0.9089444279670715, loss=0.2407214194536209
test: epoch 58, loss 2.2223222255706787, acc=0.35555556416511536, loss=2.2223222255706787
train: epoch 59, loss 0.21785129606723785, acc=0.9164444208145142, loss=0.21785129606723785
test: epoch 59, loss 1.8827661275863647, acc=0.4444444477558136, loss=1.8827661275863647
train: epoch 60, loss 0.2222471833229065, acc=0.9153888821601868, loss=0.2222471833229065
test: epoch 60, loss 1.617305040359497, acc=0.4416666626930237, loss=1.617305040359497
train: epoch 61, loss 0.18176762759685516, acc=0.9329444169998169, loss=0.18176762759685516
test: epoch 61, loss 1.9505811929702759, acc=0.3194444477558136, loss=1.9505811929702759
train: epoch 62, loss 0.23660126328468323, acc=0.909166693687439, loss=0.23660126328468323
test: epoch 62, loss 2.0266668796539307, acc=0.4472222328186035, loss=2.0266668796539307
train: epoch 63, loss 0.26734423637390137, acc=0.9034444689750671, loss=0.26734423637390137
test: epoch 63, loss 1.6452338695526123, acc=0.44999998807907104, loss=1.6452338695526123
train: epoch 64, loss 0.20474286377429962, acc=0.9240555763244629, loss=0.20474286377429962
test: epoch 64, loss 2.293933629989624, acc=0.3194444477558136, loss=2.293933629989624
train: epoch 65, loss 0.1976896971464157, acc=0.925611138343811, loss=0.1976896971464157
test: epoch 65, loss 2.852735757827759, acc=0.2666666805744171, loss=2.852735757827759
train: epoch 66, loss 0.20896804332733154, acc=0.9227222204208374, loss=0.20896804332733154
test: epoch 66, loss 2.5724380016326904, acc=0.3777777850627899, loss=2.5724380016326904
train: epoch 67, loss 0.17009329795837402, acc=0.9353333115577698, loss=0.17009329795837402
test: epoch 67, loss 2.1884264945983887, acc=0.40833333134651184, loss=2.1884264945983887
train: epoch 68, loss 0.22092042863368988, acc=0.9193888902664185, loss=0.22092042863368988
test: epoch 68, loss 1.9128613471984863, acc=0.42222222685813904, loss=1.9128613471984863
train: epoch 69, loss 0.1927330642938614, acc=0.9291666746139526, loss=0.1927330642938614
test: epoch 69, loss 2.279956340789795, acc=0.39722222089767456, loss=2.279956340789795
train: epoch 70, loss 0.20554105937480927, acc=0.9203333258628845, loss=0.20554105937480927
test: epoch 70, loss 2.240889310836792, acc=0.39444443583488464, loss=2.240889310836792
train: epoch 71, loss 0.19136106967926025, acc=0.9276666641235352, loss=0.19136106967926025
test: epoch 71, loss 1.4205464124679565, acc=0.4583333432674408, loss=1.4205464124679565
train: epoch 72, loss 0.18081244826316833, acc=0.9316666722297668, loss=0.18081244826316833
test: epoch 72, loss 2.133523464202881, acc=0.4555555582046509, loss=2.133523464202881
train: epoch 73, loss 0.1962611973285675, acc=0.929611086845398, loss=0.1962611973285675
test: epoch 73, loss 2.157655954360962, acc=0.3083333373069763, loss=2.157655954360962
train: epoch 74, loss 0.1846379041671753, acc=0.934499979019165, loss=0.1846379041671753
test: epoch 74, loss 2.5044689178466797, acc=0.3472222089767456, loss=2.5044689178466797
train: epoch 75, loss 0.21757404506206512, acc=0.9187222123146057, loss=0.21757404506206512
test: epoch 75, loss 1.7611545324325562, acc=0.4416666626930237, loss=1.7611545324325562
train: epoch 76, loss 0.18523214757442474, acc=0.9288333058357239, loss=0.18523214757442474
test: epoch 76, loss 1.450115442276001, acc=0.5, loss=1.450115442276001
train: epoch 77, loss 0.15956111252307892, acc=0.9418888688087463, loss=0.15956111252307892
test: epoch 77, loss 1.3800201416015625, acc=0.4333333373069763, loss=1.3800201416015625
train: epoch 78, loss 0.172883540391922, acc=0.9346110820770264, loss=0.172883540391922
test: epoch 78, loss 1.5510867834091187, acc=0.42222222685813904, loss=1.5510867834091187
train: epoch 79, loss 0.17762775719165802, acc=0.9336110949516296, loss=0.17762775719165802
test: epoch 79, loss 1.653419017791748, acc=0.41111111640930176, loss=1.653419017791748
train: epoch 80, loss 0.1815008819103241, acc=0.933722198009491, loss=0.1815008819103241
test: epoch 80, loss 1.4452235698699951, acc=0.4444444477558136, loss=1.4452235698699951
train: epoch 81, loss 0.16994638741016388, acc=0.9371111392974854, loss=0.16994638741016388
test: epoch 81, loss 1.6788429021835327, acc=0.3916666805744171, loss=1.6788429021835327
train: epoch 82, loss 0.18232017755508423, acc=0.9334444403648376, loss=0.18232017755508423
test: epoch 82, loss 2.450176954269409, acc=0.31388887763023376, loss=2.450176954269409
train: epoch 83, loss 0.21725884079933167, acc=0.9252777695655823, loss=0.21725884079933167
test: epoch 83, loss 1.5657330751419067, acc=0.3888888955116272, loss=1.5657330751419067
train: epoch 84, loss 0.15176989138126373, acc=0.9447222352027893, loss=0.15176989138126373
test: epoch 84, loss 2.084035873413086, acc=0.3499999940395355, loss=2.084035873413086
train: epoch 85, loss 0.16011656820774078, acc=0.9386666417121887, loss=0.16011656820774078
test: epoch 85, loss 2.011939525604248, acc=0.3361110985279083, loss=2.011939525604248
train: epoch 86, loss 0.18970318138599396, acc=0.9288889169692993, loss=0.18970318138599396
test: epoch 86, loss 1.5610566139221191, acc=0.3777777850627899, loss=1.5610566139221191
train: epoch 87, loss 0.14508841931819916, acc=0.9481111168861389, loss=0.14508841931819916
test: epoch 87, loss 1.8158788681030273, acc=0.3611111044883728, loss=1.8158788681030273
train: epoch 88, loss 0.16301558911800385, acc=0.9393888711929321, loss=0.16301558911800385
test: epoch 88, loss 1.3177177906036377, acc=0.4833333194255829, loss=1.3177177906036377
train: epoch 89, loss 0.1498948186635971, acc=0.9445555806159973, loss=0.1498948186635971
test: epoch 89, loss 1.8608819246292114, acc=0.3361110985279083, loss=1.8608819246292114
train: epoch 90, loss 0.17276990413665771, acc=0.9358888864517212, loss=0.17276990413665771
test: epoch 90, loss 2.217973232269287, acc=0.38333332538604736, loss=2.217973232269287
train: epoch 91, loss 0.17338146269321442, acc=0.9340000152587891, loss=0.17338146269321442
test: epoch 91, loss 1.592348575592041, acc=0.4166666567325592, loss=1.592348575592041
train: epoch 92, loss 0.14908793568611145, acc=0.9450555443763733, loss=0.14908793568611145
test: epoch 92, loss 1.2638622522354126, acc=0.519444465637207, loss=1.2638622522354126
train: epoch 93, loss 0.15077988803386688, acc=0.9440000057220459, loss=0.15077988803386688
test: epoch 93, loss 1.3914594650268555, acc=0.46666666865348816, loss=1.3914594650268555
train: epoch 94, loss 0.16215546429157257, acc=0.9401111006736755, loss=0.16215546429157257
test: epoch 94, loss 1.3129761219024658, acc=0.5222222208976746, loss=1.3129761219024658
train: epoch 95, loss 0.15792426466941833, acc=0.9413333535194397, loss=0.15792426466941833
test: epoch 95, loss 1.6133172512054443, acc=0.45277777314186096, loss=1.6133172512054443
train: epoch 96, loss 0.1447029709815979, acc=0.9459444284439087, loss=0.1447029709815979
test: epoch 96, loss 1.5723093748092651, acc=0.4694444537162781, loss=1.5723093748092651
train: epoch 97, loss 0.16292613744735718, acc=0.9399444460868835, loss=0.16292613744735718
test: epoch 97, loss 1.6971089839935303, acc=0.5666666626930237, loss=1.6971089839935303
train: epoch 98, loss 0.13474176824092865, acc=0.9497777819633484, loss=0.13474176824092865
test: epoch 98, loss 1.6192432641983032, acc=0.4027777910232544, loss=1.6192432641983032
train: epoch 99, loss 0.1953463852405548, acc=0.925777792930603, loss=0.1953463852405548
test: epoch 99, loss 1.5019975900650024, acc=0.4444444477558136, loss=1.5019975900650024
train: epoch 100, loss 0.1349412053823471, acc=0.9512222409248352, loss=0.1349412053823471
test: epoch 100, loss 1.5953888893127441, acc=0.4611110985279083, loss=1.5953888893127441
train: epoch 101, loss 0.14293153584003448, acc=0.9470555782318115, loss=0.14293153584003448
test: epoch 101, loss 1.4123623371124268, acc=0.45277777314186096, loss=1.4123623371124268
train: epoch 102, loss 0.15704815089702606, acc=0.9402777552604675, loss=0.15704815089702606
test: epoch 102, loss 1.6807177066802979, acc=0.4833333194255829, loss=1.6807177066802979
train: epoch 103, loss 0.16361337900161743, acc=0.9430000185966492, loss=0.16361337900161743
test: epoch 103, loss 1.3850643634796143, acc=0.4749999940395355, loss=1.3850643634796143
train: epoch 104, loss 0.13456203043460846, acc=0.9483333230018616, loss=0.13456203043460846
test: epoch 104, loss 1.8233630657196045, acc=0.4722222089767456, loss=1.8233630657196045
train: epoch 105, loss 0.15661939978599548, acc=0.9435555338859558, loss=0.15661939978599548
test: epoch 105, loss 1.8435896635055542, acc=0.41111111640930176, loss=1.8435896635055542
train: epoch 106, loss 0.10533206164836884, acc=0.9611111283302307, loss=0.10533206164836884
test: epoch 106, loss 1.607845425605774, acc=0.39722222089767456, loss=1.607845425605774
train: epoch 107, loss 0.13571156561374664, acc=0.949388861656189, loss=0.13571156561374664
test: epoch 107, loss 1.776249885559082, acc=0.49444442987442017, loss=1.776249885559082
train: epoch 108, loss 0.14668244123458862, acc=0.9477221965789795, loss=0.14668244123458862
test: epoch 108, loss 2.9662868976593018, acc=0.34166666865348816, loss=2.9662868976593018
train: epoch 109, loss 0.13997305929660797, acc=0.9487777948379517, loss=0.13997305929660797
test: epoch 109, loss 1.8196027278900146, acc=0.4333333373069763, loss=1.8196027278900146
train: epoch 110, loss 0.1298896223306656, acc=0.9519444704055786, loss=0.1298896223306656
test: epoch 110, loss 1.4167447090148926, acc=0.5361111164093018, loss=1.4167447090148926
train: epoch 111, loss 0.1436886191368103, acc=0.9513333439826965, loss=0.1436886191368103
test: epoch 111, loss 2.1726741790771484, acc=0.41111111640930176, loss=2.1726741790771484
train: epoch 112, loss 0.16123776137828827, acc=0.9433333277702332, loss=0.16123776137828827
test: epoch 112, loss 1.4653924703598022, acc=0.5444444417953491, loss=1.4653924703598022
train: epoch 113, loss 0.13194304704666138, acc=0.9520555734634399, loss=0.13194304704666138
test: epoch 113, loss 1.7993876934051514, acc=0.4472222328186035, loss=1.7993876934051514
train: epoch 114, loss 0.11950936168432236, acc=0.9564444422721863, loss=0.11950936168432236
test: epoch 114, loss 1.4797977209091187, acc=0.4833333194255829, loss=1.4797977209091187
train: epoch 115, loss 0.12056761980056763, acc=0.9566666483879089, loss=0.12056761980056763
test: epoch 115, loss 2.1437201499938965, acc=0.4305555522441864, loss=2.1437201499938965
train: epoch 116, loss 0.13941635191440582, acc=0.949999988079071, loss=0.13941635191440582
test: epoch 116, loss 1.5429301261901855, acc=0.5638889074325562, loss=1.5429301261901855
train: epoch 117, loss 0.11804751306772232, acc=0.9555555582046509, loss=0.11804751306772232
test: epoch 117, loss 2.3948137760162354, acc=0.45277777314186096, loss=2.3948137760162354
train: epoch 118, loss 0.14402265846729279, acc=0.9481111168861389, loss=0.14402265846729279
test: epoch 118, loss 1.580458641052246, acc=0.5277777910232544, loss=1.580458641052246
train: epoch 119, loss 0.13001517951488495, acc=0.9524444341659546, loss=0.13001517951488495
test: epoch 119, loss 1.7994768619537354, acc=0.5111111402511597, loss=1.7994768619537354
train: epoch 120, loss 0.1176433116197586, acc=0.957277774810791, loss=0.1176433116197586
test: epoch 120, loss 2.0034713745117188, acc=0.4555555582046509, loss=2.0034713745117188
train: epoch 121, loss 0.13097693026065826, acc=0.9515555500984192, loss=0.13097693026065826
test: epoch 121, loss 1.7348213195800781, acc=0.4888888895511627, loss=1.7348213195800781
train: epoch 122, loss 0.11483430117368698, acc=0.9589444398880005, loss=0.11483430117368698
test: epoch 122, loss 1.9292349815368652, acc=0.46666666865348816, loss=1.9292349815368652
train: epoch 123, loss 0.13332517445087433, acc=0.9533888697624207, loss=0.13332517445087433
test: epoch 123, loss 1.2840884923934937, acc=0.4138889014720917, loss=1.2840884923934937
train: epoch 124, loss 0.10837533324956894, acc=0.9609444737434387, loss=0.10837533324956894
test: epoch 124, loss 2.325040817260742, acc=0.4333333373069763, loss=2.325040817260742
train: epoch 125, loss 0.11270847916603088, acc=0.9583888649940491, loss=0.11270847916603088
test: epoch 125, loss 1.3764795064926147, acc=0.5444444417953491, loss=1.3764795064926147
train: epoch 126, loss 0.13226504623889923, acc=0.9532222151756287, loss=0.13226504623889923
test: epoch 126, loss 1.7156789302825928, acc=0.42222222685813904, loss=1.7156789302825928
train: epoch 127, loss 0.11896684765815735, acc=0.9578889012336731, loss=0.11896684765815735
test: epoch 127, loss 1.13418447971344, acc=0.5305555462837219, loss=1.13418447971344
train: epoch 128, loss 0.09915750473737717, acc=0.9633888602256775, loss=0.09915750473737717
test: epoch 128, loss 1.8825609683990479, acc=0.36944442987442017, loss=1.8825609683990479
train: epoch 129, loss 0.14153793454170227, acc=0.9478889107704163, loss=0.14153793454170227
test: epoch 129, loss 1.5263428688049316, acc=0.5249999761581421, loss=1.5263428688049316
train: epoch 130, loss 0.1147908866405487, acc=0.9567221999168396, loss=0.1147908866405487
test: epoch 130, loss 1.3363746404647827, acc=0.4861111044883728, loss=1.3363746404647827
train: epoch 131, loss 0.11411631107330322, acc=0.9596111178398132, loss=0.11411631107330322
test: epoch 131, loss 1.1696503162384033, acc=0.6027777791023254, loss=1.1696503162384033
train: epoch 132, loss 0.12431278824806213, acc=0.9541110992431641, loss=0.12431278824806213
test: epoch 132, loss 1.8987621068954468, acc=0.5, loss=1.8987621068954468
train: epoch 133, loss 0.10325170308351517, acc=0.96061110496521, loss=0.10325170308351517
test: epoch 133, loss 1.901130199432373, acc=0.4583333432674408, loss=1.901130199432373
train: epoch 134, loss 0.10935233533382416, acc=0.9603888988494873, loss=0.10935233533382416
test: epoch 134, loss 1.8088140487670898, acc=0.46666666865348816, loss=1.8088140487670898
train: epoch 135, loss 0.11596831679344177, acc=0.9568333625793457, loss=0.11596831679344177
test: epoch 135, loss 1.7286862134933472, acc=0.42500001192092896, loss=1.7286862134933472
train: epoch 136, loss 0.16333702206611633, acc=0.9434999823570251, loss=0.16333702206611633
test: epoch 136, loss 1.6561495065689087, acc=0.43888887763023376, loss=1.6561495065689087
train: epoch 137, loss 0.09432809054851532, acc=0.9668333530426025, loss=0.09432809054851532
test: epoch 137, loss 1.815279483795166, acc=0.4416666626930237, loss=1.815279483795166
train: epoch 138, loss 0.10702723264694214, acc=0.961222231388092, loss=0.10702723264694214
test: epoch 138, loss 1.5000951290130615, acc=0.49166667461395264, loss=1.5000951290130615
train: epoch 139, loss 0.09548243880271912, acc=0.9636666774749756, loss=0.09548243880271912
test: epoch 139, loss 1.2782487869262695, acc=0.5027777552604675, loss=1.2782487869262695
train: epoch 140, loss 0.1315923035144806, acc=0.953000009059906, loss=0.1315923035144806
test: epoch 140, loss 1.1655000448226929, acc=0.5944444537162781, loss=1.1655000448226929
train: epoch 141, loss 0.10604497045278549, acc=0.9637222290039062, loss=0.10604497045278549
test: epoch 141, loss 1.759198546409607, acc=0.4833333194255829, loss=1.759198546409607
train: epoch 142, loss 0.10768186300992966, acc=0.9623888731002808, loss=0.10768186300992966
test: epoch 142, loss 1.5544688701629639, acc=0.48055556416511536, loss=1.5544688701629639
train: epoch 143, loss 0.1082054078578949, acc=0.9592777490615845, loss=0.1082054078578949
test: epoch 143, loss 1.7322888374328613, acc=0.40833333134651184, loss=1.7322888374328613
train: epoch 144, loss 0.0982373058795929, acc=0.9650555849075317, loss=0.0982373058795929
test: epoch 144, loss 1.6344106197357178, acc=0.4833333194255829, loss=1.6344106197357178
train: epoch 145, loss 0.11113550513982773, acc=0.9600555300712585, loss=0.11113550513982773
test: epoch 145, loss 1.3326243162155151, acc=0.5138888955116272, loss=1.3326243162155151
train: epoch 146, loss 0.12484066933393478, acc=0.9558333158493042, loss=0.12484066933393478
test: epoch 146, loss 1.595029354095459, acc=0.5249999761581421, loss=1.595029354095459
train: epoch 147, loss 0.12503975629806519, acc=0.9552222490310669, loss=0.12503975629806519
test: epoch 147, loss 1.3122743368148804, acc=0.5555555820465088, loss=1.3122743368148804
train: epoch 148, loss 0.09113811701536179, acc=0.9657777547836304, loss=0.09113811701536179
test: epoch 148, loss 1.2586617469787598, acc=0.5222222208976746, loss=1.2586617469787598
train: epoch 149, loss 0.10577420145273209, acc=0.9611666798591614, loss=0.10577420145273209
test: epoch 149, loss 2.2827277183532715, acc=0.42500001192092896, loss=2.2827277183532715
train: epoch 150, loss 0.12356573343276978, acc=0.9566666483879089, loss=0.12356573343276978
test: epoch 150, loss 1.8193559646606445, acc=0.5305555462837219, loss=1.8193559646606445
