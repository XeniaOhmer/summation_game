# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=1.5", "--temp_decay=1", "--one_hot=1", "--n_layers=1"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=1179262379, receiver_embed_dim=32, save_run=0, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1179262379, receiver_embed_dim=32, save_run=False, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.5627450942993164, acc=0.05000000074505806, loss=3.5627450942993164
test: epoch 1, loss 3.5487282276153564, acc=0.0416666679084301, loss=3.5487282276153564
train: epoch 2, loss 3.4713010787963867, acc=0.05044444277882576, loss=3.4713010787963867
test: epoch 2, loss 3.180560827255249, acc=0.07500000298023224, loss=3.180560827255249
train: epoch 3, loss 3.3695881366729736, acc=0.056166667491197586, loss=3.3695881366729736
test: epoch 3, loss 3.262939214706421, acc=0.06666667014360428, loss=3.262939214706421
train: epoch 4, loss 3.040426731109619, acc=0.10038889199495316, loss=3.040426731109619
test: epoch 4, loss 4.6989569664001465, acc=0.04722222313284874, loss=4.6989569664001465
train: epoch 5, loss 2.7513885498046875, acc=0.1322222203016281, loss=2.7513885498046875
test: epoch 5, loss 5.128968238830566, acc=0.06666667014360428, loss=5.128968238830566
train: epoch 6, loss 2.5923261642456055, acc=0.1557222157716751, loss=2.5923261642456055
test: epoch 6, loss 5.324391841888428, acc=0.07222222536802292, loss=5.324391841888428
train: epoch 7, loss 2.4917683601379395, acc=0.17122222483158112, loss=2.4917683601379395
test: epoch 7, loss 5.202676773071289, acc=0.06666667014360428, loss=5.202676773071289
train: epoch 8, loss 2.414781093597412, acc=0.19055555760860443, loss=2.414781093597412
test: epoch 8, loss 5.305302619934082, acc=0.07500000298023224, loss=5.305302619934082
train: epoch 9, loss 2.3587703704833984, acc=0.1993333399295807, loss=2.3587703704833984
test: epoch 9, loss 5.24834680557251, acc=0.07500000298023224, loss=5.24834680557251
train: epoch 10, loss 2.3050150871276855, acc=0.2121666669845581, loss=2.3050150871276855
test: epoch 10, loss 5.170151233673096, acc=0.07222222536802292, loss=5.170151233673096
train: epoch 11, loss 2.2578952312469482, acc=0.22211110591888428, loss=2.2578952312469482
test: epoch 11, loss 5.238311767578125, acc=0.07500000298023224, loss=5.238311767578125
train: epoch 12, loss 2.219359874725342, acc=0.22877778112888336, loss=2.219359874725342
test: epoch 12, loss 5.41128396987915, acc=0.07500000298023224, loss=5.41128396987915
train: epoch 13, loss 2.1862905025482178, acc=0.23916666209697723, loss=2.1862905025482178
test: epoch 13, loss 5.3217034339904785, acc=0.07777778059244156, loss=5.3217034339904785
train: epoch 14, loss 2.1564886569976807, acc=0.23938888311386108, loss=2.1564886569976807
test: epoch 14, loss 5.3152008056640625, acc=0.07222222536802292, loss=5.3152008056640625
train: epoch 15, loss 2.1219797134399414, acc=0.25538888573646545, loss=2.1219797134399414
test: epoch 15, loss 5.258526802062988, acc=0.07777778059244156, loss=5.258526802062988
train: epoch 16, loss 2.0988094806671143, acc=0.26516667008399963, loss=2.0988094806671143
test: epoch 16, loss 5.135286331176758, acc=0.0694444477558136, loss=5.135286331176758
train: epoch 17, loss 2.0713088512420654, acc=0.26911109685897827, loss=2.0713088512420654
test: epoch 17, loss 5.164917945861816, acc=0.07777778059244156, loss=5.164917945861816
train: epoch 18, loss 2.0511903762817383, acc=0.28033334016799927, loss=2.0511903762817383
test: epoch 18, loss 4.967947006225586, acc=0.08055555820465088, loss=4.967947006225586
train: epoch 19, loss 2.0258710384368896, acc=0.2841666638851166, loss=2.0258710384368896
test: epoch 19, loss 4.9552083015441895, acc=0.07222222536802292, loss=4.9552083015441895
train: epoch 20, loss 2.0016233921051025, acc=0.2913333475589752, loss=2.0016233921051025
test: epoch 20, loss 4.850628852844238, acc=0.08055555820465088, loss=4.850628852844238
train: epoch 21, loss 1.9659994840621948, acc=0.30149999260902405, loss=1.9659994840621948
test: epoch 21, loss 4.803650379180908, acc=0.08055555820465088, loss=4.803650379180908
train: epoch 22, loss 1.9468038082122803, acc=0.30372223258018494, loss=1.9468038082122803
test: epoch 22, loss 4.701262474060059, acc=0.08611111342906952, loss=4.701262474060059
train: epoch 23, loss 1.9244829416275024, acc=0.316222220659256, loss=1.9244829416275024
test: epoch 23, loss 4.567389488220215, acc=0.07222222536802292, loss=4.567389488220215
train: epoch 24, loss 1.901180386543274, acc=0.32038888335227966, loss=1.901180386543274
test: epoch 24, loss 4.3891472816467285, acc=0.07500000298023224, loss=4.3891472816467285
train: epoch 25, loss 1.8666967153549194, acc=0.3278888761997223, loss=1.8666967153549194
test: epoch 25, loss 4.268303394317627, acc=0.08611111342906952, loss=4.268303394317627
train: epoch 26, loss 1.8491681814193726, acc=0.33399999141693115, loss=1.8491681814193726
test: epoch 26, loss 4.173550605773926, acc=0.08611111342906952, loss=4.173550605773926
train: epoch 27, loss 1.8377124071121216, acc=0.3442777693271637, loss=1.8377124071121216
test: epoch 27, loss 4.020003795623779, acc=0.08888889104127884, loss=4.020003795623779
train: epoch 28, loss 1.8083709478378296, acc=0.3495555520057678, loss=1.8083709478378296
test: epoch 28, loss 3.943560838699341, acc=0.09166666865348816, loss=3.943560838699341
train: epoch 29, loss 1.7766107320785522, acc=0.3583333194255829, loss=1.7766107320785522
test: epoch 29, loss 3.882763147354126, acc=0.10555555671453476, loss=3.882763147354126
train: epoch 30, loss 1.7549537420272827, acc=0.3637222349643707, loss=1.7549537420272827
test: epoch 30, loss 3.805250883102417, acc=0.10555555671453476, loss=3.805250883102417
train: epoch 31, loss 1.7447073459625244, acc=0.3623333275318146, loss=1.7447073459625244
test: epoch 31, loss 3.5430984497070312, acc=0.10555555671453476, loss=3.5430984497070312
train: epoch 32, loss 1.7249107360839844, acc=0.38055557012557983, loss=1.7249107360839844
test: epoch 32, loss 3.5809407234191895, acc=0.1111111119389534, loss=3.5809407234191895
train: epoch 33, loss 1.6978225708007812, acc=0.3850555419921875, loss=1.6978225708007812
test: epoch 33, loss 3.3840115070343018, acc=0.11388888955116272, loss=3.3840115070343018
train: epoch 34, loss 1.682971477508545, acc=0.38850000500679016, loss=1.682971477508545
test: epoch 34, loss 3.4205310344696045, acc=0.11666666716337204, loss=3.4205310344696045
train: epoch 35, loss 1.6547304391860962, acc=0.39933332800865173, loss=1.6547304391860962
test: epoch 35, loss 3.3257155418395996, acc=0.12777778506278992, loss=3.3257155418395996
train: epoch 36, loss 1.6374856233596802, acc=0.4074999988079071, loss=1.6374856233596802
test: epoch 36, loss 3.2750465869903564, acc=0.13333334028720856, loss=3.2750465869903564
train: epoch 37, loss 1.6120686531066895, acc=0.4148888885974884, loss=1.6120686531066895
test: epoch 37, loss 3.2257590293884277, acc=0.14722222089767456, loss=3.2257590293884277
train: epoch 38, loss 1.5974066257476807, acc=0.42327776551246643, loss=1.5974066257476807
test: epoch 38, loss 3.188838005065918, acc=0.12777778506278992, loss=3.188838005065918
train: epoch 39, loss 1.5729693174362183, acc=0.4360555410385132, loss=1.5729693174362183
test: epoch 39, loss 3.0801732540130615, acc=0.14444445073604584, loss=3.0801732540130615
train: epoch 40, loss 1.5625888109207153, acc=0.4382777810096741, loss=1.5625888109207153
test: epoch 40, loss 3.0934183597564697, acc=0.16388888657093048, loss=3.0934183597564697
train: epoch 41, loss 1.5501636266708374, acc=0.44788888096809387, loss=1.5501636266708374
test: epoch 41, loss 3.058382987976074, acc=0.15555556118488312, loss=3.058382987976074
train: epoch 42, loss 1.5268850326538086, acc=0.44850000739097595, loss=1.5268850326538086
test: epoch 42, loss 3.0368869304656982, acc=0.1527777761220932, loss=3.0368869304656982
train: epoch 43, loss 1.4897184371948242, acc=0.46316665410995483, loss=1.4897184371948242
test: epoch 43, loss 3.0462329387664795, acc=0.15833333134651184, loss=3.0462329387664795
train: epoch 44, loss 1.4778305292129517, acc=0.46905556321144104, loss=1.4778305292129517
test: epoch 44, loss 2.9524149894714355, acc=0.16944444179534912, loss=2.9524149894714355
train: epoch 45, loss 1.4692637920379639, acc=0.4728333353996277, loss=1.4692637920379639
test: epoch 45, loss 2.9874629974365234, acc=0.16944444179534912, loss=2.9874629974365234
train: epoch 46, loss 1.4562221765518188, acc=0.4856666624546051, loss=1.4562221765518188
test: epoch 46, loss 3.0086617469787598, acc=0.17499999701976776, loss=3.0086617469787598
train: epoch 47, loss 1.4167231321334839, acc=0.4911666810512543, loss=1.4167231321334839
test: epoch 47, loss 2.9676554203033447, acc=0.17777778208255768, loss=2.9676554203033447
train: epoch 48, loss 1.4084752798080444, acc=0.5015000104904175, loss=1.4084752798080444
test: epoch 48, loss 2.964167356491089, acc=0.17222222685813904, loss=2.964167356491089
train: epoch 49, loss 1.3822150230407715, acc=0.5092777609825134, loss=1.3822150230407715
test: epoch 49, loss 2.90018630027771, acc=0.19166666269302368, loss=2.90018630027771
train: epoch 50, loss 1.3617165088653564, acc=0.5247777700424194, loss=1.3617165088653564
test: epoch 50, loss 2.8794970512390137, acc=0.18333333730697632, loss=2.8794970512390137
train: epoch 51, loss 1.3289703130722046, acc=0.5316666960716248, loss=1.3289703130722046
test: epoch 51, loss 2.8012053966522217, acc=0.1805555522441864, loss=2.8012053966522217
train: epoch 52, loss 1.3202823400497437, acc=0.5341110825538635, loss=1.3202823400497437
test: epoch 52, loss 2.84578013420105, acc=0.17222222685813904, loss=2.84578013420105
train: epoch 53, loss 1.3068863153457642, acc=0.5443333387374878, loss=1.3068863153457642
test: epoch 53, loss 2.7947206497192383, acc=0.1805555522441864, loss=2.7947206497192383
train: epoch 54, loss 1.2857955694198608, acc=0.5553333163261414, loss=1.2857955694198608
test: epoch 54, loss 2.8694024085998535, acc=0.18611110746860504, loss=2.8694024085998535
train: epoch 55, loss 1.2478996515274048, acc=0.5674999952316284, loss=1.2478996515274048
test: epoch 55, loss 2.7739298343658447, acc=0.19166666269302368, loss=2.7739298343658447
train: epoch 56, loss 1.2468963861465454, acc=0.5757777690887451, loss=1.2468963861465454
test: epoch 56, loss 2.7680885791778564, acc=0.21666666865348816, loss=2.7680885791778564
train: epoch 57, loss 1.2077767848968506, acc=0.5876666903495789, loss=1.2077767848968506
test: epoch 57, loss 2.7358145713806152, acc=0.21666666865348816, loss=2.7358145713806152
train: epoch 58, loss 1.194845199584961, acc=0.5958889126777649, loss=1.194845199584961
test: epoch 58, loss 2.6812942028045654, acc=0.2222222238779068, loss=2.6812942028045654
train: epoch 59, loss 1.1728706359863281, acc=0.6056666374206543, loss=1.1728706359863281
test: epoch 59, loss 2.589489698410034, acc=0.23333333432674408, loss=2.589489698410034
train: epoch 60, loss 1.1421732902526855, acc=0.6209999918937683, loss=1.1421732902526855
test: epoch 60, loss 2.6284449100494385, acc=0.23333333432674408, loss=2.6284449100494385
train: epoch 61, loss 1.1089298725128174, acc=0.629111111164093, loss=1.1089298725128174
test: epoch 61, loss 2.5466277599334717, acc=0.2611111104488373, loss=2.5466277599334717
train: epoch 62, loss 1.1021876335144043, acc=0.6381666660308838, loss=1.1021876335144043
test: epoch 62, loss 2.528618574142456, acc=0.25, loss=2.528618574142456
train: epoch 63, loss 1.073610544204712, acc=0.6480555534362793, loss=1.073610544204712
test: epoch 63, loss 2.5141103267669678, acc=0.25555557012557983, loss=2.5141103267669678
train: epoch 64, loss 1.0465155839920044, acc=0.663444459438324, loss=1.0465155839920044
test: epoch 64, loss 2.512830972671509, acc=0.2750000059604645, loss=2.512830972671509
train: epoch 65, loss 1.0301258563995361, acc=0.6662222146987915, loss=1.0301258563995361
test: epoch 65, loss 2.5269172191619873, acc=0.26944443583488464, loss=2.5269172191619873
train: epoch 66, loss 1.0170116424560547, acc=0.6733888983726501, loss=1.0170116424560547
test: epoch 66, loss 2.530289888381958, acc=0.27222222089767456, loss=2.530289888381958
train: epoch 67, loss 0.9791871309280396, acc=0.6867222189903259, loss=0.9791871309280396
test: epoch 67, loss 2.4642245769500732, acc=0.2805555462837219, loss=2.4642245769500732
train: epoch 68, loss 0.9536268711090088, acc=0.6977221965789795, loss=0.9536268711090088
test: epoch 68, loss 2.4150259494781494, acc=0.28611111640930176, loss=2.4150259494781494
train: epoch 69, loss 0.9343224167823792, acc=0.7068889141082764, loss=0.9343224167823792
test: epoch 69, loss 2.4308407306671143, acc=0.28333333134651184, loss=2.4308407306671143
train: epoch 70, loss 0.9073377251625061, acc=0.715499997138977, loss=0.9073377251625061
test: epoch 70, loss 2.3162600994110107, acc=0.28611111640930176, loss=2.3162600994110107
train: epoch 71, loss 0.9014894962310791, acc=0.7166666388511658, loss=0.9014894962310791
test: epoch 71, loss 2.3683042526245117, acc=0.3027777671813965, loss=2.3683042526245117
train: epoch 72, loss 0.867864727973938, acc=0.7312222123146057, loss=0.867864727973938
test: epoch 72, loss 2.3566675186157227, acc=0.29722222685813904, loss=2.3566675186157227
train: epoch 73, loss 0.8503859639167786, acc=0.7421666383743286, loss=0.8503859639167786
test: epoch 73, loss 2.2967543601989746, acc=0.3055555522441864, loss=2.2967543601989746
train: epoch 74, loss 0.8245540857315063, acc=0.7542222142219543, loss=0.8245540857315063
test: epoch 74, loss 2.3485312461853027, acc=0.3083333373069763, loss=2.3485312461853027
train: epoch 75, loss 0.7967857122421265, acc=0.7633888721466064, loss=0.7967857122421265
test: epoch 75, loss 2.3160736560821533, acc=0.3027777671813965, loss=2.3160736560821533
train: epoch 76, loss 0.8043807744979858, acc=0.7680555582046509, loss=0.8043807744979858
test: epoch 76, loss 2.284670114517212, acc=0.3083333373069763, loss=2.284670114517212
train: epoch 77, loss 0.7667149305343628, acc=0.7747777700424194, loss=0.7667149305343628
test: epoch 77, loss 2.2968196868896484, acc=0.31388887763023376, loss=2.2968196868896484
train: epoch 78, loss 0.7501256465911865, acc=0.7847777605056763, loss=0.7501256465911865
test: epoch 78, loss 2.282773494720459, acc=0.31388887763023376, loss=2.282773494720459
train: epoch 79, loss 0.7287934422492981, acc=0.7941111326217651, loss=0.7287934422492981
test: epoch 79, loss 2.1717164516448975, acc=0.32499998807907104, loss=2.1717164516448975
train: epoch 80, loss 0.7023924589157104, acc=0.8033333420753479, loss=0.7023924589157104
test: epoch 80, loss 2.167043447494507, acc=0.3222222328186035, loss=2.167043447494507
train: epoch 81, loss 0.6815853118896484, acc=0.8057777881622314, loss=0.6815853118896484
test: epoch 81, loss 2.150275707244873, acc=0.3083333373069763, loss=2.150275707244873
train: epoch 82, loss 0.6820251941680908, acc=0.8115000128746033, loss=0.6820251941680908
test: epoch 82, loss 2.115888833999634, acc=0.3305555582046509, loss=2.115888833999634
train: epoch 83, loss 0.6580533981323242, acc=0.8172222375869751, loss=0.6580533981323242
test: epoch 83, loss 2.139627456665039, acc=0.32777777314186096, loss=2.139627456665039
train: epoch 84, loss 0.6288076043128967, acc=0.828499972820282, loss=0.6288076043128967
test: epoch 84, loss 2.0975375175476074, acc=0.3361110985279083, loss=2.0975375175476074
train: epoch 85, loss 0.6228184700012207, acc=0.8287222385406494, loss=0.6228184700012207
test: epoch 85, loss 2.056776762008667, acc=0.34166666865348816, loss=2.056776762008667
train: epoch 86, loss 0.5942844152450562, acc=0.8388333320617676, loss=0.5942844152450562
test: epoch 86, loss 2.0714337825775146, acc=0.3361110985279083, loss=2.0714337825775146
train: epoch 87, loss 0.5741722583770752, acc=0.842555582523346, loss=0.5741722583770752
test: epoch 87, loss 2.0103065967559814, acc=0.3444444537162781, loss=2.0103065967559814
train: epoch 88, loss 0.5532131195068359, acc=0.8481666445732117, loss=0.5532131195068359
test: epoch 88, loss 2.0174436569213867, acc=0.3472222089767456, loss=2.0174436569213867
train: epoch 89, loss 0.5492806434631348, acc=0.8521111011505127, loss=0.5492806434631348
test: epoch 89, loss 2.0020134449005127, acc=0.3361110985279083, loss=2.0020134449005127
train: epoch 90, loss 0.5302141904830933, acc=0.8607777953147888, loss=0.5302141904830933
test: epoch 90, loss 1.994509220123291, acc=0.35277777910232544, loss=1.994509220123291
train: epoch 91, loss 0.5281148552894592, acc=0.866944432258606, loss=0.5281148552894592
test: epoch 91, loss 2.0167181491851807, acc=0.3472222089767456, loss=2.0167181491851807
train: epoch 92, loss 0.49168887734413147, acc=0.8742222189903259, loss=0.49168887734413147
test: epoch 92, loss 1.948701024055481, acc=0.33888888359069824, loss=1.948701024055481
train: epoch 93, loss 0.4942934513092041, acc=0.8731666803359985, loss=0.4942934513092041
test: epoch 93, loss 1.9479097127914429, acc=0.36944442987442017, loss=1.9479097127914429
train: epoch 94, loss 0.4813929498195648, acc=0.8774999976158142, loss=0.4813929498195648
test: epoch 94, loss 1.94612717628479, acc=0.35555556416511536, loss=1.94612717628479
train: epoch 95, loss 0.46940383315086365, acc=0.8845555782318115, loss=0.46940383315086365
test: epoch 95, loss 1.9353828430175781, acc=0.3611111044883728, loss=1.9353828430175781
train: epoch 96, loss 0.4665282964706421, acc=0.8856666684150696, loss=0.4665282964706421
test: epoch 96, loss 2.0201070308685303, acc=0.3499999940395355, loss=2.0201070308685303
train: epoch 97, loss 0.4416508376598358, acc=0.8914444446563721, loss=0.4416508376598358
test: epoch 97, loss 1.9893878698349, acc=0.3499999940395355, loss=1.9893878698349
train: epoch 98, loss 0.4454856812953949, acc=0.8923888802528381, loss=0.4454856812953949
test: epoch 98, loss 1.9584541320800781, acc=0.36666667461395264, loss=1.9584541320800781
train: epoch 99, loss 0.4181171655654907, acc=0.8993333578109741, loss=0.4181171655654907
test: epoch 99, loss 1.994360089302063, acc=0.3611111044883728, loss=1.994360089302063
train: epoch 100, loss 0.40391722321510315, acc=0.9040555357933044, loss=0.40391722321510315
test: epoch 100, loss 1.9293259382247925, acc=0.36666667461395264, loss=1.9293259382247925
train: epoch 101, loss 0.3973386883735657, acc=0.9057222008705139, loss=0.3973386883735657
test: epoch 101, loss 1.8530335426330566, acc=0.3888888955116272, loss=1.8530335426330566
train: epoch 102, loss 0.38550955057144165, acc=0.9109444618225098, loss=0.38550955057144165
test: epoch 102, loss 1.8848439455032349, acc=0.38055557012557983, loss=1.8848439455032349
train: epoch 103, loss 0.3914506435394287, acc=0.9122222065925598, loss=0.3914506435394287
test: epoch 103, loss 1.8381749391555786, acc=0.36944442987442017, loss=1.8381749391555786
train: epoch 104, loss 0.37151333689689636, acc=0.914722204208374, loss=0.37151333689689636
test: epoch 104, loss 1.8202931880950928, acc=0.375, loss=1.8202931880950928
train: epoch 105, loss 0.3513573706150055, acc=0.9163888692855835, loss=0.3513573706150055
test: epoch 105, loss 1.8259742259979248, acc=0.36944442987442017, loss=1.8259742259979248
train: epoch 106, loss 0.3595832586288452, acc=0.9169444441795349, loss=0.3595832586288452
test: epoch 106, loss 1.8318030834197998, acc=0.36944442987442017, loss=1.8318030834197998
train: epoch 107, loss 0.3437861204147339, acc=0.9204999804496765, loss=0.3437861204147339
test: epoch 107, loss 1.8361831903457642, acc=0.38055557012557983, loss=1.8361831903457642
train: epoch 108, loss 0.341067373752594, acc=0.9223889112472534, loss=0.341067373752594
test: epoch 108, loss 1.8430652618408203, acc=0.36666667461395264, loss=1.8430652618408203
train: epoch 109, loss 0.3190692365169525, acc=0.9293888807296753, loss=0.3190692365169525
test: epoch 109, loss 1.7744063138961792, acc=0.38333332538604736, loss=1.7744063138961792
train: epoch 110, loss 0.31128937005996704, acc=0.9277777671813965, loss=0.31128937005996704
test: epoch 110, loss 1.8290252685546875, acc=0.375, loss=1.8290252685546875
train: epoch 111, loss 0.3235260248184204, acc=0.9302777647972107, loss=0.3235260248184204
test: epoch 111, loss 1.8452669382095337, acc=0.3722222149372101, loss=1.8452669382095337
train: epoch 112, loss 0.3126848638057709, acc=0.9312222003936768, loss=0.3126848638057709
test: epoch 112, loss 1.8243510723114014, acc=0.39444443583488464, loss=1.8243510723114014
train: epoch 113, loss 0.30657264590263367, acc=0.9360555410385132, loss=0.30657264590263367
test: epoch 113, loss 1.7593337297439575, acc=0.36944442987442017, loss=1.7593337297439575
train: epoch 114, loss 0.29129040241241455, acc=0.9318888783454895, loss=0.29129040241241455
test: epoch 114, loss 1.7848308086395264, acc=0.38333332538604736, loss=1.7848308086395264
train: epoch 115, loss 0.282786101102829, acc=0.9365000128746033, loss=0.282786101102829
test: epoch 115, loss 1.7956682443618774, acc=0.3722222149372101, loss=1.7956682443618774
train: epoch 116, loss 0.27737104892730713, acc=0.9380000233650208, loss=0.27737104892730713
test: epoch 116, loss 1.776278018951416, acc=0.3777777850627899, loss=1.776278018951416
train: epoch 117, loss 0.26737353205680847, acc=0.9409444332122803, loss=0.26737353205680847
test: epoch 117, loss 1.7995129823684692, acc=0.3777777850627899, loss=1.7995129823684692
train: epoch 118, loss 0.2599985897541046, acc=0.9422777891159058, loss=0.2599985897541046
test: epoch 118, loss 1.7766330242156982, acc=0.38333332538604736, loss=1.7766330242156982
train: epoch 119, loss 0.2581881582736969, acc=0.9421111345291138, loss=0.2581881582736969
test: epoch 119, loss 1.7697771787643433, acc=0.38333332538604736, loss=1.7697771787643433
train: epoch 120, loss 0.25757449865341187, acc=0.9444444179534912, loss=0.25757449865341187
test: epoch 120, loss 1.8167369365692139, acc=0.3861111104488373, loss=1.8167369365692139
train: epoch 121, loss 0.24557344615459442, acc=0.9461666941642761, loss=0.24557344615459442
test: epoch 121, loss 1.7755286693572998, acc=0.38333332538604736, loss=1.7755286693572998
train: epoch 122, loss 0.23576973378658295, acc=0.948888897895813, loss=0.23576973378658295
test: epoch 122, loss 1.74351167678833, acc=0.3777777850627899, loss=1.74351167678833
train: epoch 123, loss 0.23494145274162292, acc=0.9485555291175842, loss=0.23494145274162292
test: epoch 123, loss 1.7312954664230347, acc=0.3916666805744171, loss=1.7312954664230347
train: epoch 124, loss 0.23479194939136505, acc=0.9500555396080017, loss=0.23479194939136505
test: epoch 124, loss 1.7598952054977417, acc=0.4000000059604645, loss=1.7598952054977417
train: epoch 125, loss 0.21958214044570923, acc=0.9521111249923706, loss=0.21958214044570923
test: epoch 125, loss 1.7051775455474854, acc=0.4000000059604645, loss=1.7051775455474854
train: epoch 126, loss 0.2340121567249298, acc=0.9484999775886536, loss=0.2340121567249298
test: epoch 126, loss 1.667008876800537, acc=0.4000000059604645, loss=1.667008876800537
train: epoch 127, loss 0.2292999029159546, acc=0.9536666870117188, loss=0.2292999029159546
test: epoch 127, loss 1.7085936069488525, acc=0.39722222089767456, loss=1.7085936069488525
train: epoch 128, loss 0.22605079412460327, acc=0.953000009059906, loss=0.22605079412460327
test: epoch 128, loss 1.6724294424057007, acc=0.40833333134651184, loss=1.6724294424057007
train: epoch 129, loss 0.20219597220420837, acc=0.9570000171661377, loss=0.20219597220420837
test: epoch 129, loss 1.674201488494873, acc=0.4000000059604645, loss=1.674201488494873
train: epoch 130, loss 0.20086081326007843, acc=0.957611083984375, loss=0.20086081326007843
test: epoch 130, loss 1.6781049966812134, acc=0.41111111640930176, loss=1.6781049966812134
train: epoch 131, loss 0.19888867437839508, acc=0.9589444398880005, loss=0.19888867437839508
test: epoch 131, loss 1.6758049726486206, acc=0.4166666567325592, loss=1.6758049726486206
train: epoch 132, loss 0.1969001740217209, acc=0.9581111073493958, loss=0.1969001740217209
test: epoch 132, loss 1.6340960264205933, acc=0.42500001192092896, loss=1.6340960264205933
train: epoch 133, loss 0.19886134564876556, acc=0.956944465637207, loss=0.19886134564876556
test: epoch 133, loss 1.694312572479248, acc=0.4055555462837219, loss=1.694312572479248
train: epoch 134, loss 0.20199385285377502, acc=0.957277774810791, loss=0.20199385285377502
test: epoch 134, loss 1.6355373859405518, acc=0.4138889014720917, loss=1.6355373859405518
train: epoch 135, loss 0.19364798069000244, acc=0.9616666436195374, loss=0.19364798069000244
test: epoch 135, loss 1.6383345127105713, acc=0.39722222089767456, loss=1.6383345127105713
train: epoch 136, loss 0.18266284465789795, acc=0.961222231388092, loss=0.18266284465789795
test: epoch 136, loss 1.667860984802246, acc=0.4027777910232544, loss=1.667860984802246
train: epoch 137, loss 0.18061527609825134, acc=0.9632777571678162, loss=0.18061527609825134
test: epoch 137, loss 1.6491963863372803, acc=0.42500001192092896, loss=1.6491963863372803
train: epoch 138, loss 0.18425624072551727, acc=0.9626666903495789, loss=0.18425624072551727
test: epoch 138, loss 1.707666039466858, acc=0.39722222089767456, loss=1.707666039466858
train: epoch 139, loss 0.17884749174118042, acc=0.9639444351196289, loss=0.17884749174118042
test: epoch 139, loss 1.6411617994308472, acc=0.4055555462837219, loss=1.6411617994308472
train: epoch 140, loss 0.17569756507873535, acc=0.9636666774749756, loss=0.17569756507873535
test: epoch 140, loss 1.6455895900726318, acc=0.41111111640930176, loss=1.6455895900726318
train: epoch 141, loss 0.17799900472164154, acc=0.9627777934074402, loss=0.17799900472164154
test: epoch 141, loss 1.639265775680542, acc=0.4055555462837219, loss=1.639265775680542
train: epoch 142, loss 0.16570861637592316, acc=0.9644444584846497, loss=0.16570861637592316
test: epoch 142, loss 1.6451650857925415, acc=0.4055555462837219, loss=1.6451650857925415
train: epoch 143, loss 0.15837788581848145, acc=0.9663333296775818, loss=0.15837788581848145
test: epoch 143, loss 1.5922044515609741, acc=0.41111111640930176, loss=1.5922044515609741
train: epoch 144, loss 0.16840532422065735, acc=0.9652777910232544, loss=0.16840532422065735
test: epoch 144, loss 1.5931141376495361, acc=0.40833333134651184, loss=1.5931141376495361
train: epoch 145, loss 0.15820452570915222, acc=0.9666666388511658, loss=0.15820452570915222
test: epoch 145, loss 1.6250770092010498, acc=0.41111111640930176, loss=1.6250770092010498
train: epoch 146, loss 0.18368491530418396, acc=0.9652222394943237, loss=0.18368491530418396
test: epoch 146, loss 1.5819742679595947, acc=0.4138889014720917, loss=1.5819742679595947
train: epoch 147, loss 0.15895968675613403, acc=0.9646111130714417, loss=0.15895968675613403
test: epoch 147, loss 1.5793118476867676, acc=0.4166666567325592, loss=1.5793118476867676
train: epoch 148, loss 0.15605774521827698, acc=0.9674999713897705, loss=0.15605774521827698
test: epoch 148, loss 1.6098856925964355, acc=0.4166666567325592, loss=1.6098856925964355
train: epoch 149, loss 0.14750225841999054, acc=0.9691666960716248, loss=0.14750225841999054
test: epoch 149, loss 1.622137188911438, acc=0.4000000059604645, loss=1.622137188911438
train: epoch 150, loss 0.14992091059684753, acc=0.967555582523346, loss=0.14992091059684753
test: epoch 150, loss 1.5581177473068237, acc=0.42222222685813904, loss=1.5581177473068237
