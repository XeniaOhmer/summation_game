# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=1", "--temp_decay=0.995", "--one_hot=1", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=1823212963, receiver_embed_dim=64, save_run=0, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1823212963, receiver_embed_dim=64, save_run=False, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.4313621520996094, acc=0.048277776688337326, loss=3.4313621520996094
test: epoch 1, loss 3.893131971359253, acc=0.04722222313284874, loss=3.893131971359253
train: epoch 2, loss 2.9170408248901367, acc=0.10094444453716278, loss=2.9170408248901367
test: epoch 2, loss 2.9268088340759277, acc=0.08888889104127884, loss=2.9268088340759277
train: epoch 3, loss 2.232725143432617, acc=0.21355555951595306, loss=2.232725143432617
test: epoch 3, loss 2.5168991088867188, acc=0.12777778506278992, loss=2.5168991088867188
train: epoch 4, loss 1.9127858877182007, acc=0.2777777910232544, loss=1.9127858877182007
test: epoch 4, loss 2.4153993129730225, acc=0.1388888955116272, loss=2.4153993129730225
train: epoch 5, loss 1.75715172290802, acc=0.3191111087799072, loss=1.75715172290802
test: epoch 5, loss 2.4687745571136475, acc=0.1527777761220932, loss=2.4687745571136475
train: epoch 6, loss 1.661857008934021, acc=0.3543333411216736, loss=1.661857008934021
test: epoch 6, loss 2.2746195793151855, acc=0.16111111640930176, loss=2.2746195793151855
train: epoch 7, loss 1.5731916427612305, acc=0.37511110305786133, loss=1.5731916427612305
test: epoch 7, loss 2.2233643531799316, acc=0.20000000298023224, loss=2.2233643531799316
train: epoch 8, loss 1.5015199184417725, acc=0.39766666293144226, loss=1.5015199184417725
test: epoch 8, loss 2.264683723449707, acc=0.17777778208255768, loss=2.264683723449707
train: epoch 9, loss 1.4512219429016113, acc=0.4160555601119995, loss=1.4512219429016113
test: epoch 9, loss 2.257072925567627, acc=0.18333333730697632, loss=2.257072925567627
train: epoch 10, loss 1.4026755094528198, acc=0.4361666738986969, loss=1.4026755094528198
test: epoch 10, loss 2.1506481170654297, acc=0.19166666269302368, loss=2.1506481170654297
train: epoch 11, loss 1.3540228605270386, acc=0.45483332872390747, loss=1.3540228605270386
test: epoch 11, loss 2.218672513961792, acc=0.2083333283662796, loss=2.218672513961792
train: epoch 12, loss 1.3376903533935547, acc=0.45694443583488464, loss=1.3376903533935547
test: epoch 12, loss 2.137725830078125, acc=0.23333333432674408, loss=2.137725830078125
train: epoch 13, loss 1.3001682758331299, acc=0.47316667437553406, loss=1.3001682758331299
test: epoch 13, loss 2.0539233684539795, acc=0.20277777314186096, loss=2.0539233684539795
train: epoch 14, loss 1.2674976587295532, acc=0.4834444522857666, loss=1.2674976587295532
test: epoch 14, loss 2.0903561115264893, acc=0.2527777850627899, loss=2.0903561115264893
train: epoch 15, loss 1.2306454181671143, acc=0.49738889932632446, loss=1.2306454181671143
test: epoch 15, loss 1.911619782447815, acc=0.25833332538604736, loss=1.911619782447815
train: epoch 16, loss 1.1919430494308472, acc=0.5084444284439087, loss=1.1919430494308472
test: epoch 16, loss 1.8548377752304077, acc=0.2666666805744171, loss=1.8548377752304077
train: epoch 17, loss 1.181405782699585, acc=0.5223888754844666, loss=1.181405782699585
test: epoch 17, loss 1.8191713094711304, acc=0.2888889014720917, loss=1.8191713094711304
train: epoch 18, loss 1.1496974229812622, acc=0.5375555753707886, loss=1.1496974229812622
test: epoch 18, loss 1.8569973707199097, acc=0.28333333134651184, loss=1.8569973707199097
train: epoch 19, loss 1.121808409690857, acc=0.5405555367469788, loss=1.121808409690857
test: epoch 19, loss 1.9548085927963257, acc=0.27222222089767456, loss=1.9548085927963257
train: epoch 20, loss 1.0968873500823975, acc=0.5496666431427002, loss=1.0968873500823975
test: epoch 20, loss 1.7500367164611816, acc=0.28333333134651184, loss=1.7500367164611816
train: epoch 21, loss 1.0750857591629028, acc=0.5522778034210205, loss=1.0750857591629028
test: epoch 21, loss 1.8050992488861084, acc=0.2944444417953491, loss=1.8050992488861084
train: epoch 22, loss 1.0499978065490723, acc=0.5677777528762817, loss=1.0499978065490723
test: epoch 22, loss 1.8559465408325195, acc=0.28333333134651184, loss=1.8559465408325195
train: epoch 23, loss 1.0394304990768433, acc=0.5758333206176758, loss=1.0394304990768433
test: epoch 23, loss 1.7911626100540161, acc=0.2750000059604645, loss=1.7911626100540161
train: epoch 24, loss 1.0167481899261475, acc=0.5806666612625122, loss=1.0167481899261475
test: epoch 24, loss 1.8208178281784058, acc=0.2944444417953491, loss=1.8208178281784058
train: epoch 25, loss 0.9992250800132751, acc=0.5836666822433472, loss=0.9992250800132751
test: epoch 25, loss 1.75946044921875, acc=0.31388887763023376, loss=1.75946044921875
train: epoch 26, loss 0.9883259534835815, acc=0.5919444561004639, loss=0.9883259534835815
test: epoch 26, loss 1.8077287673950195, acc=0.32499998807907104, loss=1.8077287673950195
train: epoch 27, loss 0.9956949353218079, acc=0.5943889021873474, loss=0.9956949353218079
test: epoch 27, loss 1.7525838613510132, acc=0.3472222089767456, loss=1.7525838613510132
train: epoch 28, loss 0.9668814539909363, acc=0.6050000190734863, loss=0.9668814539909363
test: epoch 28, loss 1.76282799243927, acc=0.35277777910232544, loss=1.76282799243927
train: epoch 29, loss 0.9423816204071045, acc=0.6108888983726501, loss=0.9423816204071045
test: epoch 29, loss 1.775240421295166, acc=0.33888888359069824, loss=1.775240421295166
train: epoch 30, loss 0.9306579828262329, acc=0.6163333058357239, loss=0.9306579828262329
test: epoch 30, loss 1.6984202861785889, acc=0.32777777314186096, loss=1.6984202861785889
train: epoch 31, loss 0.9303944706916809, acc=0.6241666674613953, loss=0.9303944706916809
test: epoch 31, loss 1.7140907049179077, acc=0.3499999940395355, loss=1.7140907049179077
train: epoch 32, loss 0.901267409324646, acc=0.6334444284439087, loss=0.901267409324646
test: epoch 32, loss 1.572359561920166, acc=0.33888888359069824, loss=1.572359561920166
train: epoch 33, loss 0.8962802290916443, acc=0.6416110992431641, loss=0.8962802290916443
test: epoch 33, loss 1.6237190961837769, acc=0.36666667461395264, loss=1.6237190961837769
train: epoch 34, loss 0.8656546473503113, acc=0.6510000228881836, loss=0.8656546473503113
test: epoch 34, loss 1.7602348327636719, acc=0.3583333194255829, loss=1.7602348327636719
train: epoch 35, loss 0.851648211479187, acc=0.6569444537162781, loss=0.851648211479187
test: epoch 35, loss 1.6077522039413452, acc=0.3583333194255829, loss=1.6077522039413452
train: epoch 36, loss 0.841037929058075, acc=0.6570555567741394, loss=0.841037929058075
test: epoch 36, loss 1.5599874258041382, acc=0.38055557012557983, loss=1.5599874258041382
train: epoch 37, loss 0.8340378403663635, acc=0.6699444651603699, loss=0.8340378403663635
test: epoch 37, loss 1.5048452615737915, acc=0.3888888955116272, loss=1.5048452615737915
train: epoch 38, loss 0.8064241409301758, acc=0.6804999709129333, loss=0.8064241409301758
test: epoch 38, loss 1.662328839302063, acc=0.35277777910232544, loss=1.662328839302063
train: epoch 39, loss 0.8127577304840088, acc=0.6819444298744202, loss=0.8127577304840088
test: epoch 39, loss 1.665497899055481, acc=0.3722222149372101, loss=1.665497899055481
train: epoch 40, loss 0.7916522026062012, acc=0.6855555772781372, loss=0.7916522026062012
test: epoch 40, loss 1.6098957061767578, acc=0.39444443583488464, loss=1.6098957061767578
train: epoch 41, loss 0.7819885611534119, acc=0.6862778067588806, loss=0.7819885611534119
test: epoch 41, loss 1.4892998933792114, acc=0.36666667461395264, loss=1.4892998933792114
train: epoch 42, loss 0.7649621367454529, acc=0.6880000233650208, loss=0.7649621367454529
test: epoch 42, loss 1.6471391916275024, acc=0.4027777910232544, loss=1.6471391916275024
train: epoch 43, loss 0.7533762454986572, acc=0.6966111063957214, loss=0.7533762454986572
test: epoch 43, loss 1.5709279775619507, acc=0.375, loss=1.5709279775619507
train: epoch 44, loss 0.7514517903327942, acc=0.6981111168861389, loss=0.7514517903327942
test: epoch 44, loss 1.5070627927780151, acc=0.3722222149372101, loss=1.5070627927780151
train: epoch 45, loss 0.7448729872703552, acc=0.7003333568572998, loss=0.7448729872703552
test: epoch 45, loss 1.5272388458251953, acc=0.3861111104488373, loss=1.5272388458251953
train: epoch 46, loss 0.7334968447685242, acc=0.7036666870117188, loss=0.7334968447685242
test: epoch 46, loss 1.5672414302825928, acc=0.39722222089767456, loss=1.5672414302825928
train: epoch 47, loss 0.7316954731941223, acc=0.7045555710792542, loss=0.7316954731941223
test: epoch 47, loss 1.5304679870605469, acc=0.4000000059604645, loss=1.5304679870605469
train: epoch 48, loss 0.7202655673027039, acc=0.7052778005599976, loss=0.7202655673027039
test: epoch 48, loss 1.5437076091766357, acc=0.40833333134651184, loss=1.5437076091766357
train: epoch 49, loss 0.7142720818519592, acc=0.7062777876853943, loss=0.7142720818519592
test: epoch 49, loss 1.5830763578414917, acc=0.38055557012557983, loss=1.5830763578414917
train: epoch 50, loss 0.7024057507514954, acc=0.7068889141082764, loss=0.7024057507514954
test: epoch 50, loss 1.6280664205551147, acc=0.3888888955116272, loss=1.6280664205551147
train: epoch 51, loss 0.7113126516342163, acc=0.7066110968589783, loss=0.7113126516342163
test: epoch 51, loss 1.5234711170196533, acc=0.3888888955116272, loss=1.5234711170196533
train: epoch 52, loss 0.7213696837425232, acc=0.7108888626098633, loss=0.7213696837425232
test: epoch 52, loss 1.591931700706482, acc=0.38333332538604736, loss=1.591931700706482
train: epoch 53, loss 0.7049166560173035, acc=0.7095555663108826, loss=0.7049166560173035
test: epoch 53, loss 1.5689209699630737, acc=0.39444443583488464, loss=1.5689209699630737
train: epoch 54, loss 0.6895599365234375, acc=0.7166110873222351, loss=0.6895599365234375
test: epoch 54, loss 1.6187739372253418, acc=0.4027777910232544, loss=1.6187739372253418
train: epoch 55, loss 0.6913576722145081, acc=0.7138888835906982, loss=0.6913576722145081
test: epoch 55, loss 1.6257141828536987, acc=0.3888888955116272, loss=1.6257141828536987
train: epoch 56, loss 0.6942734718322754, acc=0.7079444527626038, loss=0.6942734718322754
test: epoch 56, loss 1.5475674867630005, acc=0.39722222089767456, loss=1.5475674867630005
train: epoch 57, loss 0.6834904551506042, acc=0.7194444537162781, loss=0.6834904551506042
test: epoch 57, loss 1.5437039136886597, acc=0.4027777910232544, loss=1.5437039136886597
train: epoch 58, loss 0.6832730770111084, acc=0.7186111211776733, loss=0.6832730770111084
test: epoch 58, loss 1.6407924890518188, acc=0.40833333134651184, loss=1.6407924890518188
train: epoch 59, loss 0.6860641837120056, acc=0.7151111364364624, loss=0.6860641837120056
test: epoch 59, loss 1.524045467376709, acc=0.4166666567325592, loss=1.524045467376709
train: epoch 60, loss 0.6791549921035767, acc=0.7204444408416748, loss=0.6791549921035767
test: epoch 60, loss 1.5990519523620605, acc=0.4138889014720917, loss=1.5990519523620605
train: epoch 61, loss 0.6740521788597107, acc=0.7202222347259521, loss=0.6740521788597107
test: epoch 61, loss 1.4576389789581299, acc=0.41111111640930176, loss=1.4576389789581299
train: epoch 62, loss 0.6705219149589539, acc=0.718999981880188, loss=0.6705219149589539
test: epoch 62, loss 1.616050362586975, acc=0.4166666567325592, loss=1.616050362586975
train: epoch 63, loss 0.665545642375946, acc=0.7182222008705139, loss=0.665545642375946
test: epoch 63, loss 1.7285633087158203, acc=0.42222222685813904, loss=1.7285633087158203
train: epoch 64, loss 0.6735035181045532, acc=0.7248333096504211, loss=0.6735035181045532
test: epoch 64, loss 1.5419058799743652, acc=0.4305555522441864, loss=1.5419058799743652
train: epoch 65, loss 0.6692089438438416, acc=0.7173888683319092, loss=0.6692089438438416
test: epoch 65, loss 1.4807108640670776, acc=0.4277777671813965, loss=1.4807108640670776
train: epoch 66, loss 0.6494444608688354, acc=0.72688889503479, loss=0.6494444608688354
test: epoch 66, loss 1.4467161893844604, acc=0.4416666626930237, loss=1.4467161893844604
train: epoch 67, loss 0.6539248824119568, acc=0.7250000238418579, loss=0.6539248824119568
test: epoch 67, loss 1.5849230289459229, acc=0.4333333373069763, loss=1.5849230289459229
train: epoch 68, loss 0.6466047763824463, acc=0.725777804851532, loss=0.6466047763824463
test: epoch 68, loss 1.4658571481704712, acc=0.4444444477558136, loss=1.4658571481704712
train: epoch 69, loss 0.6470329165458679, acc=0.7289999723434448, loss=0.6470329165458679
test: epoch 69, loss 1.503770112991333, acc=0.4472222328186035, loss=1.503770112991333
train: epoch 70, loss 0.6447544693946838, acc=0.7307222485542297, loss=0.6447544693946838
test: epoch 70, loss 1.454920768737793, acc=0.45277777314186096, loss=1.454920768737793
train: epoch 71, loss 0.6523656249046326, acc=0.7276666760444641, loss=0.6523656249046326
test: epoch 71, loss 1.3331207036972046, acc=0.45277777314186096, loss=1.3331207036972046
train: epoch 72, loss 0.6352776885032654, acc=0.7357777953147888, loss=0.6352776885032654
test: epoch 72, loss 1.5458412170410156, acc=0.4583333432674408, loss=1.5458412170410156
train: epoch 73, loss 0.629619836807251, acc=0.7326111197471619, loss=0.629619836807251
test: epoch 73, loss 1.4593015909194946, acc=0.46666666865348816, loss=1.4593015909194946
train: epoch 74, loss 0.6434821486473083, acc=0.7277777791023254, loss=0.6434821486473083
test: epoch 74, loss 1.4429482221603394, acc=0.44999998807907104, loss=1.4429482221603394
train: epoch 75, loss 0.6408175826072693, acc=0.730555534362793, loss=0.6408175826072693
test: epoch 75, loss 1.4229578971862793, acc=0.4583333432674408, loss=1.4229578971862793
train: epoch 76, loss 0.6429005265235901, acc=0.731166660785675, loss=0.6429005265235901
test: epoch 76, loss 1.527168869972229, acc=0.4722222089767456, loss=1.527168869972229
train: epoch 77, loss 0.6392022967338562, acc=0.7337222099304199, loss=0.6392022967338562
test: epoch 77, loss 1.3640124797821045, acc=0.4555555582046509, loss=1.3640124797821045
train: epoch 78, loss 0.6253842711448669, acc=0.7308889031410217, loss=0.6253842711448669
test: epoch 78, loss 1.4390451908111572, acc=0.4583333432674408, loss=1.4390451908111572
train: epoch 79, loss 0.6193640232086182, acc=0.7354444265365601, loss=0.6193640232086182
test: epoch 79, loss 1.4630510807037354, acc=0.46388888359069824, loss=1.4630510807037354
train: epoch 80, loss 0.6204925775527954, acc=0.7357222437858582, loss=0.6204925775527954
test: epoch 80, loss 1.3957467079162598, acc=0.48055556416511536, loss=1.3957467079162598
train: epoch 81, loss 0.6161159873008728, acc=0.7341111302375793, loss=0.6161159873008728
test: epoch 81, loss 1.512050747871399, acc=0.4583333432674408, loss=1.512050747871399
train: epoch 82, loss 0.6192100048065186, acc=0.7367222309112549, loss=0.6192100048065186
test: epoch 82, loss 1.577276349067688, acc=0.4583333432674408, loss=1.577276349067688
train: epoch 83, loss 0.6168642044067383, acc=0.7367777824401855, loss=0.6168642044067383
test: epoch 83, loss 1.4541854858398438, acc=0.4722222089767456, loss=1.4541854858398438
train: epoch 84, loss 0.6275362968444824, acc=0.734499990940094, loss=0.6275362968444824
test: epoch 84, loss 1.526073694229126, acc=0.4694444537162781, loss=1.526073694229126
train: epoch 85, loss 0.6204211711883545, acc=0.7345555424690247, loss=0.6204211711883545
test: epoch 85, loss 1.5500270128250122, acc=0.45277777314186096, loss=1.5500270128250122
train: epoch 86, loss 0.6113299131393433, acc=0.738444447517395, loss=0.6113299131393433
test: epoch 86, loss 1.4109784364700317, acc=0.4611110985279083, loss=1.4109784364700317
train: epoch 87, loss 0.6109879612922668, acc=0.7398889064788818, loss=0.6109879612922668
test: epoch 87, loss 1.5553301572799683, acc=0.4694444537162781, loss=1.5553301572799683
train: epoch 88, loss 0.6071721911430359, acc=0.7378333210945129, loss=0.6071721911430359
test: epoch 88, loss 1.4505761861801147, acc=0.46388888359069824, loss=1.4505761861801147
train: epoch 89, loss 0.6050724387168884, acc=0.7438889145851135, loss=0.6050724387168884
test: epoch 89, loss 1.4521712064743042, acc=0.46666666865348816, loss=1.4521712064743042
train: epoch 90, loss 0.6116516590118408, acc=0.7423333525657654, loss=0.6116516590118408
test: epoch 90, loss 1.3823071718215942, acc=0.4722222089767456, loss=1.3823071718215942
train: epoch 91, loss 0.5949336290359497, acc=0.7443888783454895, loss=0.5949336290359497
test: epoch 91, loss 1.3755589723587036, acc=0.47777777910232544, loss=1.3755589723587036
train: epoch 92, loss 0.5921855568885803, acc=0.7441666722297668, loss=0.5921855568885803
test: epoch 92, loss 1.3530237674713135, acc=0.4833333194255829, loss=1.3530237674713135
train: epoch 93, loss 0.5919812917709351, acc=0.7451111078262329, loss=0.5919812917709351
test: epoch 93, loss 1.5167384147644043, acc=0.46388888359069824, loss=1.5167384147644043
train: epoch 94, loss 0.5881202816963196, acc=0.7471666932106018, loss=0.5881202816963196
test: epoch 94, loss 1.4596186876296997, acc=0.4749999940395355, loss=1.4596186876296997
train: epoch 95, loss 0.5848768949508667, acc=0.7423333525657654, loss=0.5848768949508667
test: epoch 95, loss 1.780787706375122, acc=0.4861111044883728, loss=1.780787706375122
train: epoch 96, loss 0.588119387626648, acc=0.7453888654708862, loss=0.588119387626648
test: epoch 96, loss 1.479427456855774, acc=0.4833333194255829, loss=1.479427456855774
train: epoch 97, loss 0.5803712010383606, acc=0.745722234249115, loss=0.5803712010383606
test: epoch 97, loss 1.5366876125335693, acc=0.4833333194255829, loss=1.5366876125335693
train: epoch 98, loss 0.5860404968261719, acc=0.7416666746139526, loss=0.5860404968261719
test: epoch 98, loss 1.4441114664077759, acc=0.48055556416511536, loss=1.4441114664077759
train: epoch 99, loss 0.5872032046318054, acc=0.7453888654708862, loss=0.5872032046318054
test: epoch 99, loss 1.4223670959472656, acc=0.47777777910232544, loss=1.4223670959472656
train: epoch 100, loss 0.5824294686317444, acc=0.7461110949516296, loss=0.5824294686317444
test: epoch 100, loss 1.5670979022979736, acc=0.4722222089767456, loss=1.5670979022979736
train: epoch 101, loss 0.5808390974998474, acc=0.7459999918937683, loss=0.5808390974998474
test: epoch 101, loss 1.3898884057998657, acc=0.4833333194255829, loss=1.3898884057998657
train: epoch 102, loss 0.5709756016731262, acc=0.7517777681350708, loss=0.5709756016731262
test: epoch 102, loss 1.5188299417495728, acc=0.4722222089767456, loss=1.5188299417495728
train: epoch 103, loss 0.5791823267936707, acc=0.7493888735771179, loss=0.5791823267936707
test: epoch 103, loss 1.557004690170288, acc=0.4861111044883728, loss=1.557004690170288
train: epoch 104, loss 0.568962574005127, acc=0.7524999976158142, loss=0.568962574005127
test: epoch 104, loss 1.3765980005264282, acc=0.4888888895511627, loss=1.3765980005264282
train: epoch 105, loss 0.5719555616378784, acc=0.7506111264228821, loss=0.5719555616378784
test: epoch 105, loss 1.4868557453155518, acc=0.48055556416511536, loss=1.4868557453155518
train: epoch 106, loss 0.5771563649177551, acc=0.7472222447395325, loss=0.5771563649177551
test: epoch 106, loss 1.5767985582351685, acc=0.4888888895511627, loss=1.5767985582351685
train: epoch 107, loss 0.5762810707092285, acc=0.7488333582878113, loss=0.5762810707092285
test: epoch 107, loss 1.4189190864562988, acc=0.49166667461395264, loss=1.4189190864562988
train: epoch 108, loss 0.5717513561248779, acc=0.7536110877990723, loss=0.5717513561248779
test: epoch 108, loss 1.4646817445755005, acc=0.4833333194255829, loss=1.4646817445755005
train: epoch 109, loss 0.5700142979621887, acc=0.7541666626930237, loss=0.5700142979621887
test: epoch 109, loss 1.5113612413406372, acc=0.4722222089767456, loss=1.5113612413406372
train: epoch 110, loss 0.5597190260887146, acc=0.7536110877990723, loss=0.5597190260887146
test: epoch 110, loss 1.56735098361969, acc=0.4722222089767456, loss=1.56735098361969
train: epoch 111, loss 0.5719459056854248, acc=0.749833345413208, loss=0.5719459056854248
test: epoch 111, loss 1.4276691675186157, acc=0.4861111044883728, loss=1.4276691675186157
train: epoch 112, loss 0.5725942254066467, acc=0.7518333196640015, loss=0.5725942254066467
test: epoch 112, loss 1.4644265174865723, acc=0.48055556416511536, loss=1.4644265174865723
train: epoch 113, loss 0.5824235677719116, acc=0.7484444379806519, loss=0.5824235677719116
test: epoch 113, loss 1.4311115741729736, acc=0.4694444537162781, loss=1.4311115741729736
train: epoch 114, loss 0.570613443851471, acc=0.7523333430290222, loss=0.570613443851471
test: epoch 114, loss 1.4050875902175903, acc=0.47777777910232544, loss=1.4050875902175903
train: epoch 115, loss 0.5682554841041565, acc=0.7516666650772095, loss=0.5682554841041565
test: epoch 115, loss 1.4444072246551514, acc=0.48055556416511536, loss=1.4444072246551514
train: epoch 116, loss 0.5691912174224854, acc=0.7537222504615784, loss=0.5691912174224854
test: epoch 116, loss 1.5259305238723755, acc=0.4861111044883728, loss=1.5259305238723755
train: epoch 117, loss 0.5665212869644165, acc=0.753000020980835, loss=0.5665212869644165
test: epoch 117, loss 1.6594727039337158, acc=0.4888888895511627, loss=1.6594727039337158
train: epoch 118, loss 0.5658026933670044, acc=0.7522777915000916, loss=0.5658026933670044
test: epoch 118, loss 1.5271100997924805, acc=0.48055556416511536, loss=1.5271100997924805
train: epoch 119, loss 0.5575258135795593, acc=0.7553333044052124, loss=0.5575258135795593
test: epoch 119, loss 1.449270486831665, acc=0.48055556416511536, loss=1.449270486831665
train: epoch 120, loss 0.5727040767669678, acc=0.7528889179229736, loss=0.5727040767669678
test: epoch 120, loss 1.4850813150405884, acc=0.4888888895511627, loss=1.4850813150405884
train: epoch 121, loss 0.5601397752761841, acc=0.7587777972221375, loss=0.5601397752761841
test: epoch 121, loss 1.5373566150665283, acc=0.4888888895511627, loss=1.5373566150665283
train: epoch 122, loss 0.5721749067306519, acc=0.7517777681350708, loss=0.5721749067306519
test: epoch 122, loss 1.4210683107376099, acc=0.48055556416511536, loss=1.4210683107376099
train: epoch 123, loss 0.571604311466217, acc=0.7517222166061401, loss=0.571604311466217
test: epoch 123, loss 1.3909767866134644, acc=0.49166667461395264, loss=1.3909767866134644
train: epoch 124, loss 0.562027096748352, acc=0.7558333277702332, loss=0.562027096748352
test: epoch 124, loss 1.4809175729751587, acc=0.49166667461395264, loss=1.4809175729751587
train: epoch 125, loss 0.5531325340270996, acc=0.7577221989631653, loss=0.5531325340270996
test: epoch 125, loss 1.4861091375350952, acc=0.4749999940395355, loss=1.4861091375350952
train: epoch 126, loss 0.5575944185256958, acc=0.7561666369438171, loss=0.5575944185256958
test: epoch 126, loss 1.473446011543274, acc=0.4833333194255829, loss=1.473446011543274
train: epoch 127, loss 0.5542056560516357, acc=0.757888913154602, loss=0.5542056560516357
test: epoch 127, loss 1.4600328207015991, acc=0.49166667461395264, loss=1.4600328207015991
train: epoch 128, loss 0.5656039714813232, acc=0.7569444179534912, loss=0.5656039714813232
test: epoch 128, loss 1.7006117105484009, acc=0.49444442987442017, loss=1.7006117105484009
train: epoch 129, loss 0.5595260262489319, acc=0.758055567741394, loss=0.5595260262489319
test: epoch 129, loss 1.5561922788619995, acc=0.4888888895511627, loss=1.5561922788619995
train: epoch 130, loss 0.5632944107055664, acc=0.7552222013473511, loss=0.5632944107055664
test: epoch 130, loss 1.5766208171844482, acc=0.4888888895511627, loss=1.5766208171844482
train: epoch 131, loss 0.5569049715995789, acc=0.7576666474342346, loss=0.5569049715995789
test: epoch 131, loss 1.4301249980926514, acc=0.5, loss=1.4301249980926514
train: epoch 132, loss 0.551418662071228, acc=0.7568888664245605, loss=0.551418662071228
test: epoch 132, loss 1.4185441732406616, acc=0.4861111044883728, loss=1.4185441732406616
train: epoch 133, loss 0.5425715446472168, acc=0.7588333487510681, loss=0.5425715446472168
test: epoch 133, loss 1.5765371322631836, acc=0.49166667461395264, loss=1.5765371322631836
train: epoch 134, loss 0.5531432628631592, acc=0.7584444284439087, loss=0.5531432628631592
test: epoch 134, loss 1.3866782188415527, acc=0.4888888895511627, loss=1.3866782188415527
train: epoch 135, loss 0.5482137799263, acc=0.7597777843475342, loss=0.5482137799263
test: epoch 135, loss 1.3543543815612793, acc=0.49166667461395264, loss=1.3543543815612793
train: epoch 136, loss 0.5553308129310608, acc=0.7562222480773926, loss=0.5553308129310608
test: epoch 136, loss 1.569340705871582, acc=0.4888888895511627, loss=1.569340705871582
train: epoch 137, loss 0.543691098690033, acc=0.7625555396080017, loss=0.543691098690033
test: epoch 137, loss 1.5512417554855347, acc=0.49444442987442017, loss=1.5512417554855347
train: epoch 138, loss 0.5591834187507629, acc=0.7573888897895813, loss=0.5591834187507629
test: epoch 138, loss 1.4141639471054077, acc=0.5, loss=1.4141639471054077
train: epoch 139, loss 0.544776201248169, acc=0.7646111249923706, loss=0.544776201248169
test: epoch 139, loss 1.5577545166015625, acc=0.5027777552604675, loss=1.5577545166015625
train: epoch 140, loss 0.545536994934082, acc=0.7630000114440918, loss=0.545536994934082
test: epoch 140, loss 1.55841064453125, acc=0.5, loss=1.55841064453125
train: epoch 141, loss 0.544895589351654, acc=0.7603889107704163, loss=0.544895589351654
test: epoch 141, loss 1.5370714664459229, acc=0.49444442987442017, loss=1.5370714664459229
train: epoch 142, loss 0.5379990339279175, acc=0.7644444704055786, loss=0.5379990339279175
test: epoch 142, loss 1.4337908029556274, acc=0.49444442987442017, loss=1.4337908029556274
train: epoch 143, loss 0.5415730476379395, acc=0.7682222127914429, loss=0.5415730476379395
test: epoch 143, loss 1.6206434965133667, acc=0.5083333253860474, loss=1.6206434965133667
train: epoch 144, loss 0.5359990000724792, acc=0.7667222023010254, loss=0.5359990000724792
test: epoch 144, loss 1.4103533029556274, acc=0.4972222149372101, loss=1.4103533029556274
train: epoch 145, loss 0.54522305727005, acc=0.7651666402816772, loss=0.54522305727005
test: epoch 145, loss 1.713810920715332, acc=0.5083333253860474, loss=1.713810920715332
train: epoch 146, loss 0.5379042625427246, acc=0.7650555372238159, loss=0.5379042625427246
test: epoch 146, loss 1.4909796714782715, acc=0.5083333253860474, loss=1.4909796714782715
train: epoch 147, loss 0.535113513469696, acc=0.7651666402816772, loss=0.535113513469696
test: epoch 147, loss 1.544705867767334, acc=0.4972222149372101, loss=1.544705867767334
train: epoch 148, loss 0.5415375828742981, acc=0.7621666789054871, loss=0.5415375828742981
test: epoch 148, loss 1.5683948993682861, acc=0.5083333253860474, loss=1.5683948993682861
train: epoch 149, loss 0.5361001491546631, acc=0.7670555710792542, loss=0.5361001491546631
test: epoch 149, loss 1.4583927392959595, acc=0.5111111402511597, loss=1.4583927392959595
train: epoch 150, loss 0.542330801486969, acc=0.7632222175598145, loss=0.542330801486969
test: epoch 150, loss 1.5317329168319702, acc=0.5055555701255798, loss=1.5317329168319702
