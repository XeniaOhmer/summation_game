# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=1.5", "--temp_decay=1", "--one_hot=0", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=1134819161, receiver_embed_dim=64, save_run=0, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=1134819161, receiver_embed_dim=64, save_run=False, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.6372616291046143, acc=0.13294444978237152, loss=2.6372616291046143
test: epoch 1, loss 4.833032131195068, acc=0.06666667014360428, loss=4.833032131195068
train: epoch 2, loss 2.060126781463623, acc=0.22772222757339478, loss=2.060126781463623
test: epoch 2, loss 4.353747844696045, acc=0.07777778059244156, loss=4.353747844696045
train: epoch 3, loss 1.8562371730804443, acc=0.2854999899864197, loss=1.8562371730804443
test: epoch 3, loss 4.786957740783691, acc=0.0694444477558136, loss=4.786957740783691
train: epoch 4, loss 1.700289011001587, acc=0.3277222216129303, loss=1.700289011001587
test: epoch 4, loss 3.926401138305664, acc=0.10833333432674408, loss=3.926401138305664
train: epoch 5, loss 1.6179735660552979, acc=0.358777791261673, loss=1.6179735660552979
test: epoch 5, loss 3.9601657390594482, acc=0.14722222089767456, loss=3.9601657390594482
train: epoch 6, loss 1.5336898565292358, acc=0.3919999897480011, loss=1.5336898565292358
test: epoch 6, loss 4.003166675567627, acc=0.11388888955116272, loss=4.003166675567627
train: epoch 7, loss 1.4481805562973022, acc=0.4206666648387909, loss=1.4481805562973022
test: epoch 7, loss 4.134398460388184, acc=0.11944444477558136, loss=4.134398460388184
train: epoch 8, loss 1.3858271837234497, acc=0.44699999690055847, loss=1.3858271837234497
test: epoch 8, loss 4.321829795837402, acc=0.12777778506278992, loss=4.321829795837402
train: epoch 9, loss 1.3415871858596802, acc=0.46816667914390564, loss=1.3415871858596802
test: epoch 9, loss 3.759347915649414, acc=0.10555555671453476, loss=3.759347915649414
train: epoch 10, loss 1.2904313802719116, acc=0.48533332347869873, loss=1.2904313802719116
test: epoch 10, loss 4.018740653991699, acc=0.08611111342906952, loss=4.018740653991699
train: epoch 11, loss 1.2291736602783203, acc=0.5164999961853027, loss=1.2291736602783203
test: epoch 11, loss 3.69533634185791, acc=0.12777778506278992, loss=3.69533634185791
train: epoch 12, loss 1.2226228713989258, acc=0.518833339214325, loss=1.2226228713989258
test: epoch 12, loss 3.7592475414276123, acc=0.13611111044883728, loss=3.7592475414276123
train: epoch 13, loss 1.166522741317749, acc=0.5371666550636292, loss=1.166522741317749
test: epoch 13, loss 4.232872486114502, acc=0.10277777910232544, loss=4.232872486114502
train: epoch 14, loss 1.1280226707458496, acc=0.5582777857780457, loss=1.1280226707458496
test: epoch 14, loss 3.505814790725708, acc=0.14166666567325592, loss=3.505814790725708
train: epoch 15, loss 1.1069698333740234, acc=0.5698333382606506, loss=1.1069698333740234
test: epoch 15, loss 3.790102481842041, acc=0.14166666567325592, loss=3.790102481842041
train: epoch 16, loss 1.0846734046936035, acc=0.5765555500984192, loss=1.0846734046936035
test: epoch 16, loss 3.862032413482666, acc=0.1527777761220932, loss=3.862032413482666
train: epoch 17, loss 1.053391933441162, acc=0.589555561542511, loss=1.053391933441162
test: epoch 17, loss 3.6630706787109375, acc=0.11388888955116272, loss=3.6630706787109375
train: epoch 18, loss 1.0379161834716797, acc=0.6001666784286499, loss=1.0379161834716797
test: epoch 18, loss 4.225739479064941, acc=0.13055555522441864, loss=4.225739479064941
train: epoch 19, loss 1.0065864324569702, acc=0.609000027179718, loss=1.0065864324569702
test: epoch 19, loss 3.771918535232544, acc=0.17222222685813904, loss=3.771918535232544
train: epoch 20, loss 0.9927408695220947, acc=0.6176111102104187, loss=0.9927408695220947
test: epoch 20, loss 3.7479140758514404, acc=0.12777778506278992, loss=3.7479140758514404
train: epoch 21, loss 1.0173648595809937, acc=0.6127777695655823, loss=1.0173648595809937
test: epoch 21, loss 3.54732608795166, acc=0.15833333134651184, loss=3.54732608795166
train: epoch 22, loss 0.9743055105209351, acc=0.6247222423553467, loss=0.9743055105209351
test: epoch 22, loss 3.136908769607544, acc=0.1527777761220932, loss=3.136908769607544
train: epoch 23, loss 0.9642998576164246, acc=0.632111132144928, loss=0.9642998576164246
test: epoch 23, loss 3.5385844707489014, acc=0.17777778208255768, loss=3.5385844707489014
train: epoch 24, loss 0.9282647371292114, acc=0.6474444270133972, loss=0.9282647371292114
test: epoch 24, loss 3.304718017578125, acc=0.16388888657093048, loss=3.304718017578125
train: epoch 25, loss 0.9368287324905396, acc=0.644444465637207, loss=0.9368287324905396
test: epoch 25, loss 3.175135612487793, acc=0.18888889253139496, loss=3.175135612487793
train: epoch 26, loss 0.9078122973442078, acc=0.653333306312561, loss=0.9078122973442078
test: epoch 26, loss 2.8574559688568115, acc=0.21111111342906952, loss=2.8574559688568115
train: epoch 27, loss 0.8906814455986023, acc=0.6584444642066956, loss=0.8906814455986023
test: epoch 27, loss 3.3378589153289795, acc=0.18333333730697632, loss=3.3378589153289795
train: epoch 28, loss 0.8758050203323364, acc=0.6621666550636292, loss=0.8758050203323364
test: epoch 28, loss 3.1132826805114746, acc=0.17222222685813904, loss=3.1132826805114746
train: epoch 29, loss 0.8515715003013611, acc=0.6747778058052063, loss=0.8515715003013611
test: epoch 29, loss 3.9267897605895996, acc=0.2083333283662796, loss=3.9267897605895996
train: epoch 30, loss 0.8507375121116638, acc=0.6792222261428833, loss=0.8507375121116638
test: epoch 30, loss 2.909524917602539, acc=0.18333333730697632, loss=2.909524917602539
train: epoch 31, loss 0.837792158126831, acc=0.6766666769981384, loss=0.837792158126831
test: epoch 31, loss 3.4124274253845215, acc=0.125, loss=3.4124274253845215
train: epoch 32, loss 0.8312478065490723, acc=0.6842777729034424, loss=0.8312478065490723
test: epoch 32, loss 3.3346428871154785, acc=0.16944444179534912, loss=3.3346428871154785
train: epoch 33, loss 0.8305829167366028, acc=0.6857777833938599, loss=0.8305829167366028
test: epoch 33, loss 3.4900615215301514, acc=0.16388888657093048, loss=3.4900615215301514
train: epoch 34, loss 0.8265093564987183, acc=0.6872777938842773, loss=0.8265093564987183
test: epoch 34, loss 3.019230842590332, acc=0.17499999701976776, loss=3.019230842590332
train: epoch 35, loss 0.8153771758079529, acc=0.691777765750885, loss=0.8153771758079529
test: epoch 35, loss 2.825937032699585, acc=0.17222222685813904, loss=2.825937032699585
train: epoch 36, loss 0.795059859752655, acc=0.695722222328186, loss=0.795059859752655
test: epoch 36, loss 3.264286994934082, acc=0.1805555522441864, loss=3.264286994934082
train: epoch 37, loss 0.7986636161804199, acc=0.6968888640403748, loss=0.7986636161804199
test: epoch 37, loss 3.1800670623779297, acc=0.17777778208255768, loss=3.1800670623779297
train: epoch 38, loss 0.7791182994842529, acc=0.7049444317817688, loss=0.7791182994842529
test: epoch 38, loss 2.911210298538208, acc=0.22777777910232544, loss=2.911210298538208
train: epoch 39, loss 0.7754987478256226, acc=0.7083333134651184, loss=0.7754987478256226
test: epoch 39, loss 3.322929859161377, acc=0.14722222089767456, loss=3.322929859161377
train: epoch 40, loss 0.7606105208396912, acc=0.7106666564941406, loss=0.7606105208396912
test: epoch 40, loss 2.400857925415039, acc=0.17222222685813904, loss=2.400857925415039
train: epoch 41, loss 0.7461235523223877, acc=0.7211666703224182, loss=0.7461235523223877
test: epoch 41, loss 2.712050676345825, acc=0.2083333283662796, loss=2.712050676345825
train: epoch 42, loss 0.7504631280899048, acc=0.7141110897064209, loss=0.7504631280899048
test: epoch 42, loss 2.645686388015747, acc=0.17777778208255768, loss=2.645686388015747
train: epoch 43, loss 0.7514173984527588, acc=0.7142221927642822, loss=0.7514173984527588
test: epoch 43, loss 2.5443530082702637, acc=0.21666666865348816, loss=2.5443530082702637
train: epoch 44, loss 0.732125461101532, acc=0.7228333353996277, loss=0.732125461101532
test: epoch 44, loss 2.427981376647949, acc=0.23055554926395416, loss=2.427981376647949
train: epoch 45, loss 0.7265944480895996, acc=0.7249444723129272, loss=0.7265944480895996
test: epoch 45, loss 2.8269853591918945, acc=0.15555556118488312, loss=2.8269853591918945
train: epoch 46, loss 0.7312910556793213, acc=0.7241666913032532, loss=0.7312910556793213
test: epoch 46, loss 2.332754135131836, acc=0.19722221791744232, loss=2.332754135131836
train: epoch 47, loss 0.6979460120201111, acc=0.7350000143051147, loss=0.6979460120201111
test: epoch 47, loss 2.617750883102417, acc=0.20277777314186096, loss=2.617750883102417
train: epoch 48, loss 0.699203372001648, acc=0.7396666407585144, loss=0.699203372001648
test: epoch 48, loss 2.767549991607666, acc=0.19722221791744232, loss=2.767549991607666
train: epoch 49, loss 0.6837201714515686, acc=0.7401111125946045, loss=0.6837201714515686
test: epoch 49, loss 2.5152721405029297, acc=0.16388888657093048, loss=2.5152721405029297
train: epoch 50, loss 0.6932491660118103, acc=0.7422778010368347, loss=0.6932491660118103
test: epoch 50, loss 2.7435965538024902, acc=0.23055554926395416, loss=2.7435965538024902
train: epoch 51, loss 0.6721163392066956, acc=0.7491666674613953, loss=0.6721163392066956
test: epoch 51, loss 2.6513588428497314, acc=0.21111111342906952, loss=2.6513588428497314
train: epoch 52, loss 0.6655994057655334, acc=0.7480000257492065, loss=0.6655994057655334
test: epoch 52, loss 3.234640598297119, acc=0.125, loss=3.234640598297119
train: epoch 53, loss 0.6598337888717651, acc=0.7551666498184204, loss=0.6598337888717651
test: epoch 53, loss 3.189497232437134, acc=0.12777778506278992, loss=3.189497232437134
train: epoch 54, loss 0.6549428701400757, acc=0.7553889155387878, loss=0.6549428701400757
test: epoch 54, loss 2.7853775024414062, acc=0.20000000298023224, loss=2.7853775024414062
train: epoch 55, loss 0.6331883668899536, acc=0.7567222118377686, loss=0.6331883668899536
test: epoch 55, loss 2.89202618598938, acc=0.17499999701976776, loss=2.89202618598938
train: epoch 56, loss 0.6288735270500183, acc=0.7661111354827881, loss=0.6288735270500183
test: epoch 56, loss 3.0705642700195312, acc=0.18888889253139496, loss=3.0705642700195312
train: epoch 57, loss 0.6410611867904663, acc=0.7556111216545105, loss=0.6410611867904663
test: epoch 57, loss 2.5310933589935303, acc=0.21388888359069824, loss=2.5310933589935303
train: epoch 58, loss 0.6236300468444824, acc=0.7619444727897644, loss=0.6236300468444824
test: epoch 58, loss 2.4737722873687744, acc=0.24166665971279144, loss=2.4737722873687744
train: epoch 59, loss 0.6340319514274597, acc=0.7608333230018616, loss=0.6340319514274597
test: epoch 59, loss 2.7097091674804688, acc=0.1944444477558136, loss=2.7097091674804688
train: epoch 60, loss 0.5946349501609802, acc=0.7797777652740479, loss=0.5946349501609802
test: epoch 60, loss 2.9263834953308105, acc=0.1527777761220932, loss=2.9263834953308105
train: epoch 61, loss 0.6192581057548523, acc=0.7684444189071655, loss=0.6192581057548523
test: epoch 61, loss 2.4537696838378906, acc=0.21944443881511688, loss=2.4537696838378906
train: epoch 62, loss 0.6005519032478333, acc=0.7761111259460449, loss=0.6005519032478333
test: epoch 62, loss 3.0041022300720215, acc=0.21666666865348816, loss=3.0041022300720215
train: epoch 63, loss 0.601116955280304, acc=0.7795555591583252, loss=0.601116955280304
test: epoch 63, loss 2.7972195148468018, acc=0.21944443881511688, loss=2.7972195148468018
train: epoch 64, loss 0.5957748889923096, acc=0.7772777676582336, loss=0.5957748889923096
test: epoch 64, loss 2.5854203701019287, acc=0.23333333432674408, loss=2.5854203701019287
train: epoch 65, loss 0.5668686628341675, acc=0.7922222018241882, loss=0.5668686628341675
test: epoch 65, loss 2.1904137134552, acc=0.18611110746860504, loss=2.1904137134552
train: epoch 66, loss 0.5836758017539978, acc=0.784166693687439, loss=0.5836758017539978
test: epoch 66, loss 2.8136227130889893, acc=0.14722222089767456, loss=2.8136227130889893
train: epoch 67, loss 0.5536170601844788, acc=0.7893333435058594, loss=0.5536170601844788
test: epoch 67, loss 2.6787703037261963, acc=0.20277777314186096, loss=2.6787703037261963
train: epoch 68, loss 0.570285439491272, acc=0.788777768611908, loss=0.570285439491272
test: epoch 68, loss 3.5876810550689697, acc=0.15833333134651184, loss=3.5876810550689697
train: epoch 69, loss 0.5916881561279297, acc=0.7815555334091187, loss=0.5916881561279297
test: epoch 69, loss 3.124504327774048, acc=0.15555556118488312, loss=3.124504327774048
train: epoch 70, loss 0.5711803436279297, acc=0.7914444208145142, loss=0.5711803436279297
test: epoch 70, loss 2.9597630500793457, acc=0.2222222238779068, loss=2.9597630500793457
train: epoch 71, loss 0.5461249947547913, acc=0.7911111116409302, loss=0.5461249947547913
test: epoch 71, loss 2.8547110557556152, acc=0.22499999403953552, loss=2.8547110557556152
train: epoch 72, loss 0.5350485444068909, acc=0.8002222180366516, loss=0.5350485444068909
test: epoch 72, loss 2.4339163303375244, acc=0.1666666716337204, loss=2.4339163303375244
train: epoch 73, loss 0.5506851077079773, acc=0.7937777638435364, loss=0.5506851077079773
test: epoch 73, loss 2.195889711380005, acc=0.3027777671813965, loss=2.195889711380005
train: epoch 74, loss 0.5586335062980652, acc=0.7953888773918152, loss=0.5586335062980652
test: epoch 74, loss 2.3300368785858154, acc=0.2638888955116272, loss=2.3300368785858154
train: epoch 75, loss 0.5441344380378723, acc=0.7976666688919067, loss=0.5441344380378723
test: epoch 75, loss 3.396571159362793, acc=0.10555555671453476, loss=3.396571159362793
train: epoch 76, loss 0.5022492408752441, acc=0.8132222294807434, loss=0.5022492408752441
test: epoch 76, loss 2.7516026496887207, acc=0.15555556118488312, loss=2.7516026496887207
train: epoch 77, loss 0.516751766204834, acc=0.8051111102104187, loss=0.516751766204834
test: epoch 77, loss 2.713869333267212, acc=0.19166666269302368, loss=2.713869333267212
train: epoch 78, loss 0.5273399353027344, acc=0.8060555458068848, loss=0.5273399353027344
test: epoch 78, loss 2.576915979385376, acc=0.2361111044883728, loss=2.576915979385376
train: epoch 79, loss 0.5203349590301514, acc=0.8028888702392578, loss=0.5203349590301514
test: epoch 79, loss 2.9874119758605957, acc=0.14722222089767456, loss=2.9874119758605957
train: epoch 80, loss 0.4852333962917328, acc=0.8181666731834412, loss=0.4852333962917328
test: epoch 80, loss 2.215939998626709, acc=0.2666666805744171, loss=2.215939998626709
train: epoch 81, loss 0.5236055254936218, acc=0.8088889122009277, loss=0.5236055254936218
test: epoch 81, loss 2.6143531799316406, acc=0.22499999403953552, loss=2.6143531799316406
train: epoch 82, loss 0.5043204426765442, acc=0.8125555515289307, loss=0.5043204426765442
test: epoch 82, loss 2.259615182876587, acc=0.2888889014720917, loss=2.259615182876587
train: epoch 83, loss 0.5001031160354614, acc=0.8177777528762817, loss=0.5001031160354614
test: epoch 83, loss 1.8421845436096191, acc=0.3194444477558136, loss=1.8421845436096191
train: epoch 84, loss 0.5084039568901062, acc=0.8097222447395325, loss=0.5084039568901062
test: epoch 84, loss 2.5212173461914062, acc=0.16944444179534912, loss=2.5212173461914062
train: epoch 85, loss 0.48392537236213684, acc=0.8229444622993469, loss=0.48392537236213684
test: epoch 85, loss 2.1653521060943604, acc=0.2750000059604645, loss=2.1653521060943604
train: epoch 86, loss 0.4942605495452881, acc=0.8193333148956299, loss=0.4942605495452881
test: epoch 86, loss 2.445309638977051, acc=0.2222222238779068, loss=2.445309638977051
train: epoch 87, loss 0.49901390075683594, acc=0.8193888664245605, loss=0.49901390075683594
test: epoch 87, loss 2.5795652866363525, acc=0.15000000596046448, loss=2.5795652866363525
train: epoch 88, loss 0.49079328775405884, acc=0.8230555653572083, loss=0.49079328775405884
test: epoch 88, loss 2.831721305847168, acc=0.17222222685813904, loss=2.831721305847168
train: epoch 89, loss 0.49197670817375183, acc=0.8176110982894897, loss=0.49197670817375183
test: epoch 89, loss 2.5332143306732178, acc=0.23055554926395416, loss=2.5332143306732178
train: epoch 90, loss 0.4809671640396118, acc=0.8175555467605591, loss=0.4809671640396118
test: epoch 90, loss 2.5326900482177734, acc=0.3055555522441864, loss=2.5326900482177734
train: epoch 91, loss 0.47624143958091736, acc=0.8220555782318115, loss=0.47624143958091736
test: epoch 91, loss 2.804145097732544, acc=0.20000000298023224, loss=2.804145097732544
train: epoch 92, loss 0.4948909878730774, acc=0.8161110877990723, loss=0.4948909878730774
test: epoch 92, loss 3.1754231452941895, acc=0.1527777761220932, loss=3.1754231452941895
train: epoch 93, loss 0.4824170470237732, acc=0.819611132144928, loss=0.4824170470237732
test: epoch 93, loss 2.6309337615966797, acc=0.2888889014720917, loss=2.6309337615966797
train: epoch 94, loss 0.45670315623283386, acc=0.8284444212913513, loss=0.45670315623283386
test: epoch 94, loss 2.6251657009124756, acc=0.2888889014720917, loss=2.6251657009124756
train: epoch 95, loss 0.4450686275959015, acc=0.8366110920906067, loss=0.4450686275959015
test: epoch 95, loss 2.755383014678955, acc=0.2361111044883728, loss=2.755383014678955
train: epoch 96, loss 0.45576563477516174, acc=0.8322222232818604, loss=0.45576563477516174
test: epoch 96, loss 2.153921365737915, acc=0.2750000059604645, loss=2.153921365737915
train: epoch 97, loss 0.47210896015167236, acc=0.8246666789054871, loss=0.47210896015167236
test: epoch 97, loss 2.9136688709259033, acc=0.14722222089767456, loss=2.9136688709259033
train: epoch 98, loss 0.44678956270217896, acc=0.8351110816001892, loss=0.44678956270217896
test: epoch 98, loss 2.4501798152923584, acc=0.25833332538604736, loss=2.4501798152923584
train: epoch 99, loss 0.44747111201286316, acc=0.8335000276565552, loss=0.44747111201286316
test: epoch 99, loss 2.7717714309692383, acc=0.24166665971279144, loss=2.7717714309692383
train: epoch 100, loss 0.4418697655200958, acc=0.8351666927337646, loss=0.4418697655200958
test: epoch 100, loss 3.3009963035583496, acc=0.1944444477558136, loss=3.3009963035583496
train: epoch 101, loss 0.43152379989624023, acc=0.835777759552002, loss=0.43152379989624023
test: epoch 101, loss 3.148383617401123, acc=0.2666666805744171, loss=3.148383617401123
train: epoch 102, loss 0.4226842522621155, acc=0.8439444303512573, loss=0.4226842522621155
test: epoch 102, loss 2.3107187747955322, acc=0.2777777910232544, loss=2.3107187747955322
train: epoch 103, loss 0.42569205164909363, acc=0.839888870716095, loss=0.42569205164909363
test: epoch 103, loss 3.1938884258270264, acc=0.20277777314186096, loss=3.1938884258270264
train: epoch 104, loss 0.4381650984287262, acc=0.8375555276870728, loss=0.4381650984287262
test: epoch 104, loss 2.602670669555664, acc=0.18611110746860504, loss=2.602670669555664
train: epoch 105, loss 0.4397563636302948, acc=0.8374999761581421, loss=0.4397563636302948
test: epoch 105, loss 2.7623403072357178, acc=0.3083333373069763, loss=2.7623403072357178
train: epoch 106, loss 0.4248400628566742, acc=0.8421111106872559, loss=0.4248400628566742
test: epoch 106, loss 2.0770251750946045, acc=0.3361110985279083, loss=2.0770251750946045
train: epoch 107, loss 0.4191420078277588, acc=0.8428333401679993, loss=0.4191420078277588
test: epoch 107, loss 3.5066821575164795, acc=0.14722222089767456, loss=3.5066821575164795
train: epoch 108, loss 0.42580050230026245, acc=0.8412222266197205, loss=0.42580050230026245
test: epoch 108, loss 2.8162760734558105, acc=0.24166665971279144, loss=2.8162760734558105
train: epoch 109, loss 0.435639351606369, acc=0.8360000252723694, loss=0.435639351606369
test: epoch 109, loss 2.2844622135162354, acc=0.2805555462837219, loss=2.2844622135162354
train: epoch 110, loss 0.4511365294456482, acc=0.8337222337722778, loss=0.4511365294456482
test: epoch 110, loss 3.0448508262634277, acc=0.17777778208255768, loss=3.0448508262634277
train: epoch 111, loss 0.43015193939208984, acc=0.844944417476654, loss=0.43015193939208984
test: epoch 111, loss 2.7928571701049805, acc=0.17777778208255768, loss=2.7928571701049805
train: epoch 112, loss 0.4118967652320862, acc=0.8468888998031616, loss=0.4118967652320862
test: epoch 112, loss 2.4325551986694336, acc=0.28333333134651184, loss=2.4325551986694336
train: epoch 113, loss 0.42647820711135864, acc=0.8442222476005554, loss=0.42647820711135864
test: epoch 113, loss 2.975433349609375, acc=0.20555555820465088, loss=2.975433349609375
train: epoch 114, loss 0.4138941466808319, acc=0.8467777967453003, loss=0.4138941466808319
test: epoch 114, loss 2.290428876876831, acc=0.28611111640930176, loss=2.290428876876831
train: epoch 115, loss 0.41662144660949707, acc=0.8431666493415833, loss=0.41662144660949707
test: epoch 115, loss 2.703364372253418, acc=0.2361111044883728, loss=2.703364372253418
train: epoch 116, loss 0.40966346859931946, acc=0.8471111059188843, loss=0.40966346859931946
test: epoch 116, loss 2.435655117034912, acc=0.3333333432674408, loss=2.435655117034912
train: epoch 117, loss 0.3986590802669525, acc=0.8541111350059509, loss=0.3986590802669525
test: epoch 117, loss 2.717700958251953, acc=0.20555555820465088, loss=2.717700958251953
train: epoch 118, loss 0.40359145402908325, acc=0.8484444618225098, loss=0.40359145402908325
test: epoch 118, loss 2.889991283416748, acc=0.2222222238779068, loss=2.889991283416748
train: epoch 119, loss 0.4240102469921112, acc=0.8448888659477234, loss=0.4240102469921112
test: epoch 119, loss 2.402743339538574, acc=0.23055554926395416, loss=2.402743339538574
train: epoch 120, loss 0.43221062421798706, acc=0.8438888788223267, loss=0.43221062421798706
test: epoch 120, loss 3.384143829345703, acc=0.21111111342906952, loss=3.384143829345703
train: epoch 121, loss 0.4096251428127289, acc=0.8487222194671631, loss=0.4096251428127289
test: epoch 121, loss 2.9343760013580322, acc=0.1944444477558136, loss=2.9343760013580322
train: epoch 122, loss 0.41426029801368713, acc=0.8482778072357178, loss=0.41426029801368713
test: epoch 122, loss 2.9324398040771484, acc=0.22499999403953552, loss=2.9324398040771484
train: epoch 123, loss 0.41537708044052124, acc=0.847611129283905, loss=0.41537708044052124
test: epoch 123, loss 3.132225513458252, acc=0.24722221493721008, loss=3.132225513458252
train: epoch 124, loss 0.37981653213500977, acc=0.8606111407279968, loss=0.37981653213500977
test: epoch 124, loss 2.0704190731048584, acc=0.28611111640930176, loss=2.0704190731048584
train: epoch 125, loss 0.40538355708122253, acc=0.8508889079093933, loss=0.40538355708122253
test: epoch 125, loss 2.890383243560791, acc=0.20000000298023224, loss=2.890383243560791
train: epoch 126, loss 0.41152751445770264, acc=0.8457777500152588, loss=0.41152751445770264
test: epoch 126, loss 2.4325079917907715, acc=0.3166666626930237, loss=2.4325079917907715
train: epoch 127, loss 0.3975581228733063, acc=0.8488333225250244, loss=0.3975581228733063
test: epoch 127, loss 3.7143962383270264, acc=0.1805555522441864, loss=3.7143962383270264
train: epoch 128, loss 0.38567206263542175, acc=0.8557222485542297, loss=0.38567206263542175
test: epoch 128, loss 2.2166244983673096, acc=0.3027777671813965, loss=2.2166244983673096
train: epoch 129, loss 0.4080182909965515, acc=0.8479999899864197, loss=0.4080182909965515
test: epoch 129, loss 2.3603696823120117, acc=0.3194444477558136, loss=2.3603696823120117
train: epoch 130, loss 0.3908537030220032, acc=0.8565000295639038, loss=0.3908537030220032
test: epoch 130, loss 2.109182357788086, acc=0.2777777910232544, loss=2.109182357788086
train: epoch 131, loss 0.3759330213069916, acc=0.8561111092567444, loss=0.3759330213069916
test: epoch 131, loss 1.8978620767593384, acc=0.2916666567325592, loss=1.8978620767593384
train: epoch 132, loss 0.3722989857196808, acc=0.8586111068725586, loss=0.3722989857196808
test: epoch 132, loss 2.677565813064575, acc=0.2611111104488373, loss=2.677565813064575
train: epoch 133, loss 0.3684007227420807, acc=0.859000027179718, loss=0.3684007227420807
test: epoch 133, loss 2.1584689617156982, acc=0.3361110985279083, loss=2.1584689617156982
train: epoch 134, loss 0.3706527352333069, acc=0.862333357334137, loss=0.3706527352333069
test: epoch 134, loss 2.989633321762085, acc=0.25, loss=2.989633321762085
train: epoch 135, loss 0.385486900806427, acc=0.8559444546699524, loss=0.385486900806427
test: epoch 135, loss 3.1668894290924072, acc=0.23333333432674408, loss=3.1668894290924072
train: epoch 136, loss 0.40003517270088196, acc=0.8529444336891174, loss=0.40003517270088196
test: epoch 136, loss 2.953648567199707, acc=0.23055554926395416, loss=2.953648567199707
train: epoch 137, loss 0.377386212348938, acc=0.8602222204208374, loss=0.377386212348938
test: epoch 137, loss 3.0847296714782715, acc=0.18333333730697632, loss=3.0847296714782715
train: epoch 138, loss 0.37894120812416077, acc=0.8572221994400024, loss=0.37894120812416077
test: epoch 138, loss 2.5519213676452637, acc=0.32499998807907104, loss=2.5519213676452637
train: epoch 139, loss 0.35903051495552063, acc=0.8644444346427917, loss=0.35903051495552063
test: epoch 139, loss 2.948028564453125, acc=0.2611111104488373, loss=2.948028564453125
train: epoch 140, loss 0.3952333629131317, acc=0.8528333306312561, loss=0.3952333629131317
test: epoch 140, loss 2.5654003620147705, acc=0.3055555522441864, loss=2.5654003620147705
train: epoch 141, loss 0.38696637749671936, acc=0.8588333129882812, loss=0.38696637749671936
test: epoch 141, loss 3.563185691833496, acc=0.21388888359069824, loss=3.563185691833496
train: epoch 142, loss 0.3749392628669739, acc=0.859499990940094, loss=0.3749392628669739
test: epoch 142, loss 2.1121349334716797, acc=0.21944443881511688, loss=2.1121349334716797
train: epoch 143, loss 0.36870816349983215, acc=0.8585555553436279, loss=0.36870816349983215
test: epoch 143, loss 2.8041563034057617, acc=0.21111111342906952, loss=2.8041563034057617
train: epoch 144, loss 0.37961864471435547, acc=0.8540555834770203, loss=0.37961864471435547
test: epoch 144, loss 2.1646368503570557, acc=0.35277777910232544, loss=2.1646368503570557
train: epoch 145, loss 0.35592734813690186, acc=0.8648333549499512, loss=0.35592734813690186
test: epoch 145, loss 2.589909076690674, acc=0.16944444179534912, loss=2.589909076690674
train: epoch 146, loss 0.3666438162326813, acc=0.8610000014305115, loss=0.3666438162326813
test: epoch 146, loss 2.6431374549865723, acc=0.2222222238779068, loss=2.6431374549865723
train: epoch 147, loss 0.3706090450286865, acc=0.8615555763244629, loss=0.3706090450286865
test: epoch 147, loss 2.644536018371582, acc=0.3083333373069763, loss=2.644536018371582
train: epoch 148, loss 0.3889211118221283, acc=0.8588333129882812, loss=0.3889211118221283
test: epoch 148, loss 2.939326286315918, acc=0.2638888955116272, loss=2.939326286315918
train: epoch 149, loss 0.36644065380096436, acc=0.8633333444595337, loss=0.36644065380096436
test: epoch 149, loss 2.67242169380188, acc=0.31111112236976624, loss=2.67242169380188
train: epoch 150, loss 0.34681275486946106, acc=0.8694444298744202, loss=0.34681275486946106
test: epoch 150, loss 2.695455551147461, acc=0.24722221493721008, loss=2.695455551147461
