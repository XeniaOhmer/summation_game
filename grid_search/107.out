# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=0.99", "--one_hot=1", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=735216120, receiver_embed_dim=64, save_run=0, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=735216120, receiver_embed_dim=64, save_run=False, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.805137872695923, acc=0.10255555808544159, loss=2.805137872695923
test: epoch 1, loss 4.819820404052734, acc=0.0972222238779068, loss=4.819820404052734
train: epoch 2, loss 1.6773656606674194, acc=0.2918333411216736, loss=1.6773656606674194
test: epoch 2, loss 4.627121925354004, acc=0.14444445073604584, loss=4.627121925354004
train: epoch 3, loss 1.2302124500274658, acc=0.4775555431842804, loss=1.2302124500274658
test: epoch 3, loss 5.945444107055664, acc=0.10000000149011612, loss=5.945444107055664
train: epoch 4, loss 0.887789785861969, acc=0.6428889036178589, loss=0.887789785861969
test: epoch 4, loss 4.5209269523620605, acc=0.17222222685813904, loss=4.5209269523620605
train: epoch 5, loss 0.6969276070594788, acc=0.7260555624961853, loss=0.6969276070594788
test: epoch 5, loss 4.043952465057373, acc=0.23333333432674408, loss=4.043952465057373
train: epoch 6, loss 0.5711804628372192, acc=0.7719444632530212, loss=0.5711804628372192
test: epoch 6, loss 3.646329879760742, acc=0.18888889253139496, loss=3.646329879760742
train: epoch 7, loss 0.5088375210762024, acc=0.80522221326828, loss=0.5088375210762024
test: epoch 7, loss 3.964108943939209, acc=0.20555555820465088, loss=3.964108943939209
train: epoch 8, loss 0.4520786702632904, acc=0.8249444365501404, loss=0.4520786702632904
test: epoch 8, loss 3.4253880977630615, acc=0.27222222089767456, loss=3.4253880977630615
train: epoch 9, loss 0.41843003034591675, acc=0.8429444432258606, loss=0.41843003034591675
test: epoch 9, loss 3.6135342121124268, acc=0.2944444417953491, loss=3.6135342121124268
train: epoch 10, loss 0.35798072814941406, acc=0.8653888702392578, loss=0.35798072814941406
test: epoch 10, loss 3.185453414916992, acc=0.3305555582046509, loss=3.185453414916992
train: epoch 11, loss 0.35227277874946594, acc=0.875166654586792, loss=0.35227277874946594
test: epoch 11, loss 3.124539375305176, acc=0.3083333373069763, loss=3.124539375305176
train: epoch 12, loss 0.3103487491607666, acc=0.8907222151756287, loss=0.3103487491607666
test: epoch 12, loss 2.9053103923797607, acc=0.3333333432674408, loss=2.9053103923797607
train: epoch 13, loss 0.28657764196395874, acc=0.9011666774749756, loss=0.28657764196395874
test: epoch 13, loss 2.379549503326416, acc=0.38333332538604736, loss=2.379549503326416
train: epoch 14, loss 0.2689019739627838, acc=0.9092777967453003, loss=0.2689019739627838
test: epoch 14, loss 2.8381099700927734, acc=0.3361110985279083, loss=2.8381099700927734
train: epoch 15, loss 0.2626388669013977, acc=0.9123888611793518, loss=0.2626388669013977
test: epoch 15, loss 2.074610710144043, acc=0.4694444537162781, loss=2.074610710144043
train: epoch 16, loss 0.23056462407112122, acc=0.925000011920929, loss=0.23056462407112122
test: epoch 16, loss 2.5969090461730957, acc=0.33888888359069824, loss=2.5969090461730957
train: epoch 17, loss 0.22064872086048126, acc=0.9287222027778625, loss=0.22064872086048126
test: epoch 17, loss 1.9840210676193237, acc=0.42222222685813904, loss=1.9840210676193237
train: epoch 18, loss 0.21300601959228516, acc=0.9309999942779541, loss=0.21300601959228516
test: epoch 18, loss 2.1940388679504395, acc=0.4277777671813965, loss=2.1940388679504395
train: epoch 19, loss 0.2091604620218277, acc=0.9331666827201843, loss=0.2091604620218277
test: epoch 19, loss 2.207209587097168, acc=0.45277777314186096, loss=2.207209587097168
train: epoch 20, loss 0.20417676866054535, acc=0.9375555515289307, loss=0.20417676866054535
test: epoch 20, loss 2.0821173191070557, acc=0.3916666805744171, loss=2.0821173191070557
train: epoch 21, loss 0.1862417459487915, acc=0.9403333067893982, loss=0.1862417459487915
test: epoch 21, loss 1.938720464706421, acc=0.43888887763023376, loss=1.938720464706421
train: epoch 22, loss 0.19923199713230133, acc=0.9358888864517212, loss=0.19923199713230133
test: epoch 22, loss 1.8226500749588013, acc=0.5111111402511597, loss=1.8226500749588013
train: epoch 23, loss 0.17933811247348785, acc=0.9429444670677185, loss=0.17933811247348785
test: epoch 23, loss 1.8291548490524292, acc=0.42222222685813904, loss=1.8291548490524292
train: epoch 24, loss 0.1794673353433609, acc=0.9430555701255798, loss=0.1794673353433609
test: epoch 24, loss 2.2687830924987793, acc=0.47777777910232544, loss=2.2687830924987793
train: epoch 25, loss 0.18157793581485748, acc=0.9427777528762817, loss=0.18157793581485748
test: epoch 25, loss 2.548635482788086, acc=0.38333332538604736, loss=2.548635482788086
train: epoch 26, loss 0.16376470029354095, acc=0.948722243309021, loss=0.16376470029354095
test: epoch 26, loss 2.115302324295044, acc=0.39722222089767456, loss=2.115302324295044
train: epoch 27, loss 0.1581612378358841, acc=0.9507222175598145, loss=0.1581612378358841
test: epoch 27, loss 1.8311221599578857, acc=0.43611112236976624, loss=1.8311221599578857
train: epoch 28, loss 0.1534208059310913, acc=0.9501110911369324, loss=0.1534208059310913
test: epoch 28, loss 2.169469118118286, acc=0.45277777314186096, loss=2.169469118118286
train: epoch 29, loss 0.15023191273212433, acc=0.9527778029441833, loss=0.15023191273212433
test: epoch 29, loss 1.9056651592254639, acc=0.4694444537162781, loss=1.9056651592254639
train: epoch 30, loss 0.16025875508785248, acc=0.9489444494247437, loss=0.16025875508785248
test: epoch 30, loss 2.046694755554199, acc=0.5416666865348816, loss=2.046694755554199
train: epoch 31, loss 0.14854569733142853, acc=0.953499972820282, loss=0.14854569733142853
test: epoch 31, loss 1.4875973463058472, acc=0.5388888716697693, loss=1.4875973463058472
train: epoch 32, loss 0.14376460015773773, acc=0.9538333415985107, loss=0.14376460015773773
test: epoch 32, loss 2.1474826335906982, acc=0.4972222149372101, loss=2.1474826335906982
train: epoch 33, loss 0.15992622077465057, acc=0.9501110911369324, loss=0.15992622077465057
test: epoch 33, loss 1.798226237297058, acc=0.5166666507720947, loss=1.798226237297058
train: epoch 34, loss 0.13622845709323883, acc=0.9587777853012085, loss=0.13622845709323883
test: epoch 34, loss 1.8100528717041016, acc=0.5638889074325562, loss=1.8100528717041016
train: epoch 35, loss 0.14349456131458282, acc=0.9577222466468811, loss=0.14349456131458282
test: epoch 35, loss 1.7593828439712524, acc=0.5, loss=1.7593828439712524
train: epoch 36, loss 0.13444262742996216, acc=0.9591110944747925, loss=0.13444262742996216
test: epoch 36, loss 1.5482051372528076, acc=0.5916666388511658, loss=1.5482051372528076
train: epoch 37, loss 0.13438858091831207, acc=0.9592777490615845, loss=0.13438858091831207
test: epoch 37, loss 2.0954272747039795, acc=0.49166667461395264, loss=2.0954272747039795
train: epoch 38, loss 0.1431482434272766, acc=0.9554444551467896, loss=0.1431482434272766
test: epoch 38, loss 1.3729145526885986, acc=0.5583333373069763, loss=1.3729145526885986
train: epoch 39, loss 0.13453130424022675, acc=0.9583333134651184, loss=0.13453130424022675
test: epoch 39, loss 1.514190673828125, acc=0.6222222447395325, loss=1.514190673828125
train: epoch 40, loss 0.1266394704580307, acc=0.9631111025810242, loss=0.1266394704580307
test: epoch 40, loss 1.1997803449630737, acc=0.6555555462837219, loss=1.1997803449630737
train: epoch 41, loss 0.11833877861499786, acc=0.9616666436195374, loss=0.11833877861499786
test: epoch 41, loss 1.4708354473114014, acc=0.5527777671813965, loss=1.4708354473114014
train: epoch 42, loss 0.14219698309898376, acc=0.9564444422721863, loss=0.14219698309898376
test: epoch 42, loss 1.539370059967041, acc=0.6111111044883728, loss=1.539370059967041
train: epoch 43, loss 0.12029761075973511, acc=0.9626111388206482, loss=0.12029761075973511
test: epoch 43, loss 1.3898756504058838, acc=0.5583333373069763, loss=1.3898756504058838
train: epoch 44, loss 0.12560223042964935, acc=0.9624999761581421, loss=0.12560223042964935
test: epoch 44, loss 1.1507275104522705, acc=0.6694444417953491, loss=1.1507275104522705
train: epoch 45, loss 0.1288379728794098, acc=0.961555540561676, loss=0.1288379728794098
test: epoch 45, loss 1.222448468208313, acc=0.6472222208976746, loss=1.222448468208313
train: epoch 46, loss 0.12224621325731277, acc=0.9637777805328369, loss=0.12224621325731277
test: epoch 46, loss 0.9956421256065369, acc=0.6916666626930237, loss=0.9956421256065369
train: epoch 47, loss 0.11375140398740768, acc=0.9649999737739563, loss=0.11375140398740768
test: epoch 47, loss 1.5186480283737183, acc=0.6138888597488403, loss=1.5186480283737183
train: epoch 48, loss 0.12055220454931259, acc=0.9640555381774902, loss=0.12055220454931259
test: epoch 48, loss 1.405611515045166, acc=0.7111111283302307, loss=1.405611515045166
train: epoch 49, loss 0.1155594065785408, acc=0.9638333320617676, loss=0.1155594065785408
test: epoch 49, loss 1.5166802406311035, acc=0.6499999761581421, loss=1.5166802406311035
train: epoch 50, loss 0.11979226768016815, acc=0.9632777571678162, loss=0.11979226768016815
test: epoch 50, loss 1.1150277853012085, acc=0.6416666507720947, loss=1.1150277853012085
train: epoch 51, loss 0.11053334921598434, acc=0.9668333530426025, loss=0.11053334921598434
test: epoch 51, loss 1.0801481008529663, acc=0.699999988079071, loss=1.0801481008529663
train: epoch 52, loss 0.12341165542602539, acc=0.9635555744171143, loss=0.12341165542602539
test: epoch 52, loss 1.12537682056427, acc=0.7166666388511658, loss=1.12537682056427
train: epoch 53, loss 0.1117686927318573, acc=0.9667778015136719, loss=0.1117686927318573
test: epoch 53, loss 0.7815864086151123, acc=0.7416666746139526, loss=0.7815864086151123
train: epoch 54, loss 0.10598607361316681, acc=0.9678888916969299, loss=0.10598607361316681
test: epoch 54, loss 1.0858768224716187, acc=0.675000011920929, loss=1.0858768224716187
train: epoch 55, loss 0.12016984820365906, acc=0.9646111130714417, loss=0.12016984820365906
test: epoch 55, loss 0.8584365844726562, acc=0.7777777910232544, loss=0.8584365844726562
train: epoch 56, loss 0.11770917475223541, acc=0.9666666388511658, loss=0.11770917475223541
test: epoch 56, loss 0.7998433709144592, acc=0.7972221970558167, loss=0.7998433709144592
train: epoch 57, loss 0.11484808474779129, acc=0.9662777781486511, loss=0.11484808474779129
test: epoch 57, loss 0.7508506178855896, acc=0.7805555462837219, loss=0.7508506178855896
train: epoch 58, loss 0.1017465814948082, acc=0.9703888893127441, loss=0.1017465814948082
test: epoch 58, loss 0.5535029768943787, acc=0.8583333492279053, loss=0.5535029768943787
train: epoch 59, loss 0.09388915449380875, acc=0.9735000133514404, loss=0.09388915449380875
test: epoch 59, loss 1.0411721467971802, acc=0.7055555582046509, loss=1.0411721467971802
train: epoch 60, loss 0.09341175854206085, acc=0.9710000157356262, loss=0.09341175854206085
test: epoch 60, loss 0.5533584952354431, acc=0.8527777791023254, loss=0.5533584952354431
train: epoch 61, loss 0.10226086527109146, acc=0.9702222347259521, loss=0.10226086527109146
test: epoch 61, loss 0.5402933955192566, acc=0.8444444537162781, loss=0.5402933955192566
train: epoch 62, loss 0.09795316308736801, acc=0.9724444150924683, loss=0.09795316308736801
test: epoch 62, loss 0.3277900218963623, acc=0.8722222447395325, loss=0.3277900218963623
train: epoch 63, loss 0.08952942490577698, acc=0.9744444489479065, loss=0.08952942490577698
test: epoch 63, loss 0.46542537212371826, acc=0.8722222447395325, loss=0.46542537212371826
train: epoch 64, loss 0.08400202542543411, acc=0.976111114025116, loss=0.08400202542543411
test: epoch 64, loss 0.4040840268135071, acc=0.894444465637207, loss=0.4040840268135071
train: epoch 65, loss 0.08698666840791702, acc=0.9746666550636292, loss=0.08698666840791702
test: epoch 65, loss 0.3189705014228821, acc=0.9277777671813965, loss=0.3189705014228821
train: epoch 66, loss 0.0758504644036293, acc=0.9777777791023254, loss=0.0758504644036293
test: epoch 66, loss 0.48416659235954285, acc=0.8722222447395325, loss=0.48416659235954285
train: epoch 67, loss 0.06989817321300507, acc=0.980388879776001, loss=0.06989817321300507
test: epoch 67, loss 0.4485015273094177, acc=0.9027777910232544, loss=0.4485015273094177
train: epoch 68, loss 0.07460672408342361, acc=0.9788333177566528, loss=0.07460672408342361
test: epoch 68, loss 0.3003910183906555, acc=0.925000011920929, loss=0.3003910183906555
train: epoch 69, loss 0.07923544198274612, acc=0.9781110882759094, loss=0.07923544198274612
test: epoch 69, loss 0.20659013092517853, acc=0.9527778029441833, loss=0.20659013092517853
train: epoch 70, loss 0.059130363166332245, acc=0.984000027179718, loss=0.059130363166332245
test: epoch 70, loss 0.2309146523475647, acc=0.949999988079071, loss=0.2309146523475647
train: epoch 71, loss 0.051710061728954315, acc=0.9861666560173035, loss=0.051710061728954315
test: epoch 71, loss 0.21396461129188538, acc=0.949999988079071, loss=0.21396461129188538
train: epoch 72, loss 0.05512126535177231, acc=0.9849444627761841, loss=0.05512126535177231
test: epoch 72, loss 0.16603022813796997, acc=0.9583333134651184, loss=0.16603022813796997
train: epoch 73, loss 0.06424619257450104, acc=0.9825000166893005, loss=0.06424619257450104
test: epoch 73, loss 0.21892136335372925, acc=0.949999988079071, loss=0.21892136335372925
train: epoch 74, loss 0.06306470185518265, acc=0.9835000038146973, loss=0.06306470185518265
test: epoch 74, loss 0.14996549487113953, acc=0.9527778029441833, loss=0.14996549487113953
train: epoch 75, loss 0.05565290153026581, acc=0.98416668176651, loss=0.05565290153026581
test: epoch 75, loss 0.19427579641342163, acc=0.9472222328186035, loss=0.19427579641342163
train: epoch 76, loss 0.04310308396816254, acc=0.9877222180366516, loss=0.04310308396816254
test: epoch 76, loss 0.21850864589214325, acc=0.9527778029441833, loss=0.21850864589214325
train: epoch 77, loss 0.04758647084236145, acc=0.9863333106040955, loss=0.04758647084236145
test: epoch 77, loss 0.13461527228355408, acc=0.9527778029441833, loss=0.13461527228355408
train: epoch 78, loss 0.0557192862033844, acc=0.984499990940094, loss=0.0557192862033844
test: epoch 78, loss 0.21504846215248108, acc=0.9527778029441833, loss=0.21504846215248108
train: epoch 79, loss 0.04321013018488884, acc=0.9879999756813049, loss=0.04321013018488884
test: epoch 79, loss 0.2321862131357193, acc=0.949999988079071, loss=0.2321862131357193
train: epoch 80, loss 0.04575933888554573, acc=0.987666666507721, loss=0.04575933888554573
test: epoch 80, loss 0.17548513412475586, acc=0.949999988079071, loss=0.17548513412475586
train: epoch 81, loss 0.04849301278591156, acc=0.9867222309112549, loss=0.04849301278591156
test: epoch 81, loss 0.1600789576768875, acc=0.9555555582046509, loss=0.1600789576768875
train: epoch 82, loss 0.04486208036541939, acc=0.9888888597488403, loss=0.04486208036541939
test: epoch 82, loss 0.15253719687461853, acc=0.9333333373069763, loss=0.15253719687461853
train: epoch 83, loss 0.04682120308279991, acc=0.9867222309112549, loss=0.04682120308279991
test: epoch 83, loss 0.15807601809501648, acc=0.9555555582046509, loss=0.15807601809501648
train: epoch 84, loss 0.043261945247650146, acc=0.9878888726234436, loss=0.043261945247650146
test: epoch 84, loss 0.1276479959487915, acc=0.9555555582046509, loss=0.1276479959487915
train: epoch 85, loss 0.04156304895877838, acc=0.9884999990463257, loss=0.04156304895877838
test: epoch 85, loss 0.1335688829421997, acc=0.9555555582046509, loss=0.1335688829421997
train: epoch 86, loss 0.04264882579445839, acc=0.988611102104187, loss=0.04264882579445839
test: epoch 86, loss 0.15885001420974731, acc=0.9527778029441833, loss=0.15885001420974731
train: epoch 87, loss 0.05502115562558174, acc=0.9855555295944214, loss=0.05502115562558174
test: epoch 87, loss 0.11884430795907974, acc=0.9555555582046509, loss=0.11884430795907974
train: epoch 88, loss 0.0408485122025013, acc=0.9895555377006531, loss=0.0408485122025013
test: epoch 88, loss 0.15852689743041992, acc=0.9555555582046509, loss=0.15852689743041992
train: epoch 89, loss 0.04498955234885216, acc=0.9902222156524658, loss=0.04498955234885216
test: epoch 89, loss 0.11933629214763641, acc=0.9527778029441833, loss=0.11933629214763641
train: epoch 90, loss 0.04236453399062157, acc=0.9890555739402771, loss=0.04236453399062157
test: epoch 90, loss 0.15881112217903137, acc=0.9555555582046509, loss=0.15881112217903137
train: epoch 91, loss 0.03715323656797409, acc=0.9882222414016724, loss=0.03715323656797409
test: epoch 91, loss 0.20191101729869843, acc=0.9527778029441833, loss=0.20191101729869843
train: epoch 92, loss 0.04924434423446655, acc=0.9867222309112549, loss=0.04924434423446655
test: epoch 92, loss 0.14984115958213806, acc=0.9555555582046509, loss=0.14984115958213806
train: epoch 93, loss 0.053429391235113144, acc=0.9853333234786987, loss=0.053429391235113144
test: epoch 93, loss 0.1495225727558136, acc=0.9527778029441833, loss=0.1495225727558136
train: epoch 94, loss 0.04301343485713005, acc=0.987666666507721, loss=0.04301343485713005
test: epoch 94, loss 0.07623907178640366, acc=0.9555555582046509, loss=0.07623907178640366
train: epoch 95, loss 0.04564766213297844, acc=0.9877777695655823, loss=0.04564766213297844
test: epoch 95, loss 0.18497395515441895, acc=0.9555555582046509, loss=0.18497395515441895
train: epoch 96, loss 0.04517627879977226, acc=0.9879444241523743, loss=0.04517627879977226
test: epoch 96, loss 0.13362029194831848, acc=0.9555555582046509, loss=0.13362029194831848
train: epoch 97, loss 0.04554685205221176, acc=0.9882222414016724, loss=0.04554685205221176
test: epoch 97, loss 0.1080005019903183, acc=0.9555555582046509, loss=0.1080005019903183
train: epoch 98, loss 0.04588752239942551, acc=0.9867222309112549, loss=0.04588752239942551
test: epoch 98, loss 0.16070044040679932, acc=0.9555555582046509, loss=0.16070044040679932
train: epoch 99, loss 0.049351658672094345, acc=0.9878888726234436, loss=0.049351658672094345
test: epoch 99, loss 0.14610713720321655, acc=0.9583333134651184, loss=0.14610713720321655
train: epoch 100, loss 0.04795529693365097, acc=0.9877777695655823, loss=0.04795529693365097
test: epoch 100, loss 0.12269751727581024, acc=0.9555555582046509, loss=0.12269751727581024
train: epoch 101, loss 0.050175029784440994, acc=0.9852777719497681, loss=0.050175029784440994
test: epoch 101, loss 0.1393982321023941, acc=0.9555555582046509, loss=0.1393982321023941
train: epoch 102, loss 0.04095957800745964, acc=0.9879444241523743, loss=0.04095957800745964
test: epoch 102, loss 0.14029718935489655, acc=0.9555555582046509, loss=0.14029718935489655
train: epoch 103, loss 0.03424307703971863, acc=0.9902777671813965, loss=0.03424307703971863
test: epoch 103, loss 0.182099848985672, acc=0.9527778029441833, loss=0.182099848985672
train: epoch 104, loss 0.03418537229299545, acc=0.9904999732971191, loss=0.03418537229299545
test: epoch 104, loss 0.09285617619752884, acc=0.9555555582046509, loss=0.09285617619752884
train: epoch 105, loss 0.04041637107729912, acc=0.9890555739402771, loss=0.04041637107729912
test: epoch 105, loss 0.11825284361839294, acc=0.9555555582046509, loss=0.11825284361839294
train: epoch 106, loss 0.043771080672740936, acc=0.9877777695655823, loss=0.043771080672740936
test: epoch 106, loss 0.17816802859306335, acc=0.9527778029441833, loss=0.17816802859306335
train: epoch 107, loss 0.05148732662200928, acc=0.9862777590751648, loss=0.05148732662200928
test: epoch 107, loss 0.14314891397953033, acc=0.9611111283302307, loss=0.14314891397953033
train: epoch 108, loss 0.042557913810014725, acc=0.9883333444595337, loss=0.042557913810014725
test: epoch 108, loss 0.14670906960964203, acc=0.9555555582046509, loss=0.14670906960964203
train: epoch 109, loss 0.03557274118065834, acc=0.9894444346427917, loss=0.03557274118065834
test: epoch 109, loss 0.1517418771982193, acc=0.9555555582046509, loss=0.1517418771982193
train: epoch 110, loss 0.03691690042614937, acc=0.988611102104187, loss=0.03691690042614937
test: epoch 110, loss 0.12871500849723816, acc=0.9555555582046509, loss=0.12871500849723816
train: epoch 111, loss 0.03493616729974747, acc=0.9910555481910706, loss=0.03493616729974747
test: epoch 111, loss 0.15863150358200073, acc=0.9555555582046509, loss=0.15863150358200073
train: epoch 112, loss 0.025145789608359337, acc=0.9929444193840027, loss=0.025145789608359337
test: epoch 112, loss 0.15129134058952332, acc=0.9555555582046509, loss=0.15129134058952332
train: epoch 113, loss 0.03549417853355408, acc=0.9906666874885559, loss=0.03549417853355408
test: epoch 113, loss 0.1513410210609436, acc=0.9555555582046509, loss=0.1513410210609436
train: epoch 114, loss 0.035955674946308136, acc=0.9908888936042786, loss=0.035955674946308136
test: epoch 114, loss 0.21288266777992249, acc=0.9527778029441833, loss=0.21288266777992249
train: epoch 115, loss 0.04273952171206474, acc=0.9899444580078125, loss=0.04273952171206474
test: epoch 115, loss 0.14231549203395844, acc=0.9555555582046509, loss=0.14231549203395844
train: epoch 116, loss 0.039294615387916565, acc=0.9896666407585144, loss=0.039294615387916565
test: epoch 116, loss 0.13800428807735443, acc=0.949999988079071, loss=0.13800428807735443
train: epoch 117, loss 0.04452723264694214, acc=0.9891111254692078, loss=0.04452723264694214
test: epoch 117, loss 0.14475202560424805, acc=0.9555555582046509, loss=0.14475202560424805
train: epoch 118, loss 0.031026272103190422, acc=0.9909444451332092, loss=0.031026272103190422
test: epoch 118, loss 0.15459053218364716, acc=0.9555555582046509, loss=0.15459053218364716
train: epoch 119, loss 0.03505069017410278, acc=0.9888333082199097, loss=0.03505069017410278
test: epoch 119, loss 0.12300969660282135, acc=0.9555555582046509, loss=0.12300969660282135
train: epoch 120, loss 0.034765783697366714, acc=0.9904999732971191, loss=0.034765783697366714
test: epoch 120, loss 0.15282385051250458, acc=0.9555555582046509, loss=0.15282385051250458
train: epoch 121, loss 0.04881399869918823, acc=0.988277792930603, loss=0.04881399869918823
test: epoch 121, loss 0.1362324357032776, acc=0.9555555582046509, loss=0.1362324357032776
train: epoch 122, loss 0.0284085962921381, acc=0.9918333292007446, loss=0.0284085962921381
test: epoch 122, loss 0.12491576373577118, acc=0.9555555582046509, loss=0.12491576373577118
train: epoch 123, loss 0.0443306565284729, acc=0.9856111407279968, loss=0.0443306565284729
test: epoch 123, loss 0.14232926070690155, acc=0.9555555582046509, loss=0.14232926070690155
train: epoch 124, loss 0.04212561994791031, acc=0.9893888831138611, loss=0.04212561994791031
test: epoch 124, loss 0.13222970068454742, acc=0.9555555582046509, loss=0.13222970068454742
train: epoch 125, loss 0.03570675477385521, acc=0.9907777905464172, loss=0.03570675477385521
test: epoch 125, loss 0.1439245194196701, acc=0.9555555582046509, loss=0.1439245194196701
train: epoch 126, loss 0.03364153951406479, acc=0.9897222518920898, loss=0.03364153951406479
test: epoch 126, loss 0.15338459610939026, acc=0.9555555582046509, loss=0.15338459610939026
train: epoch 127, loss 0.03261401504278183, acc=0.9897778034210205, loss=0.03261401504278183
test: epoch 127, loss 0.12525777518749237, acc=0.9555555582046509, loss=0.12525777518749237
train: epoch 128, loss 0.038205649703741074, acc=0.9904444217681885, loss=0.038205649703741074
test: epoch 128, loss 0.1510777622461319, acc=0.9555555582046509, loss=0.1510777622461319
train: epoch 129, loss 0.029345881193876266, acc=0.991944432258606, loss=0.029345881193876266
test: epoch 129, loss 0.1751360446214676, acc=0.9555555582046509, loss=0.1751360446214676
train: epoch 130, loss 0.03800366446375847, acc=0.9901111125946045, loss=0.03800366446375847
test: epoch 130, loss 0.14628255367279053, acc=0.9527778029441833, loss=0.14628255367279053
train: epoch 131, loss 0.038192737847566605, acc=0.988777756690979, loss=0.038192737847566605
test: epoch 131, loss 0.14443404972553253, acc=0.9555555582046509, loss=0.14443404972553253
train: epoch 132, loss 0.03704886883497238, acc=0.9887222051620483, loss=0.03704886883497238
test: epoch 132, loss 0.2041008025407791, acc=0.9555555582046509, loss=0.2041008025407791
train: epoch 133, loss 0.037648119032382965, acc=0.9867222309112549, loss=0.037648119032382965
test: epoch 133, loss 0.14037634432315826, acc=0.9555555582046509, loss=0.14037634432315826
train: epoch 134, loss 0.03346217796206474, acc=0.9912222027778625, loss=0.03346217796206474
test: epoch 134, loss 0.1578790545463562, acc=0.9555555582046509, loss=0.1578790545463562
train: epoch 135, loss 0.038163382560014725, acc=0.99144446849823, loss=0.038163382560014725
test: epoch 135, loss 0.14503417909145355, acc=0.9555555582046509, loss=0.14503417909145355
train: epoch 136, loss 0.04089583829045296, acc=0.9884999990463257, loss=0.04089583829045296
test: epoch 136, loss 0.13926826417446136, acc=0.9555555582046509, loss=0.13926826417446136
train: epoch 137, loss 0.02909369394183159, acc=0.9921666383743286, loss=0.02909369394183159
test: epoch 137, loss 0.15166211128234863, acc=0.9555555582046509, loss=0.15166211128234863
train: epoch 138, loss 0.03522830829024315, acc=0.9901666641235352, loss=0.03522830829024315
test: epoch 138, loss 0.12688830494880676, acc=0.9555555582046509, loss=0.12688830494880676
train: epoch 139, loss 0.03215840458869934, acc=0.992222249507904, loss=0.03215840458869934
test: epoch 139, loss 0.19278675317764282, acc=0.9555555582046509, loss=0.19278675317764282
train: epoch 140, loss 0.03333252668380737, acc=0.9910555481910706, loss=0.03333252668380737
test: epoch 140, loss 0.162324458360672, acc=0.9555555582046509, loss=0.162324458360672
train: epoch 141, loss 0.022088730707764626, acc=0.9943333268165588, loss=0.022088730707764626
test: epoch 141, loss 0.14179933071136475, acc=0.9555555582046509, loss=0.14179933071136475
train: epoch 142, loss 0.03271382302045822, acc=0.9918888807296753, loss=0.03271382302045822
test: epoch 142, loss 0.14022338390350342, acc=0.9555555582046509, loss=0.14022338390350342
train: epoch 143, loss 0.049963999539613724, acc=0.9891666769981384, loss=0.049963999539613724
test: epoch 143, loss 0.13926438987255096, acc=0.9555555582046509, loss=0.13926438987255096
train: epoch 144, loss 0.032540351152420044, acc=0.9923333525657654, loss=0.032540351152420044
test: epoch 144, loss 0.1605849713087082, acc=0.9555555582046509, loss=0.1605849713087082
train: epoch 145, loss 0.027385065332055092, acc=0.9926666617393494, loss=0.027385065332055092
test: epoch 145, loss 0.12442095577716827, acc=0.9555555582046509, loss=0.12442095577716827
train: epoch 146, loss 0.03282236307859421, acc=0.9911666512489319, loss=0.03282236307859421
test: epoch 146, loss 0.13042427599430084, acc=0.9555555582046509, loss=0.13042427599430084
train: epoch 147, loss 0.03190876543521881, acc=0.9912222027778625, loss=0.03190876543521881
test: epoch 147, loss 0.10519707947969437, acc=0.9555555582046509, loss=0.10519707947969437
train: epoch 148, loss 0.06144828349351883, acc=0.9852222204208374, loss=0.06144828349351883
test: epoch 148, loss 0.12793901562690735, acc=0.9527778029441833, loss=0.12793901562690735
train: epoch 149, loss 0.04037823528051376, acc=0.9905555844306946, loss=0.04037823528051376
test: epoch 149, loss 0.1504247635602951, acc=0.9527778029441833, loss=0.1504247635602951
train: epoch 150, loss 0.043489307165145874, acc=0.9881666898727417, loss=0.043489307165145874
test: epoch 150, loss 0.1304580122232437, acc=0.9527778029441833, loss=0.1304580122232437
