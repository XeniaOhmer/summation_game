# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=1.5", "--temp_decay=1", "--one_hot=0", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=450554541, receiver_embed_dim=32, save_run=0, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=450554541, receiver_embed_dim=32, save_run=False, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.8125083446502686, acc=0.11188888549804688, loss=2.8125083446502686
test: epoch 1, loss 5.463913440704346, acc=0.0555555559694767, loss=5.463913440704346
train: epoch 2, loss 2.239112138748169, acc=0.2040555626153946, loss=2.239112138748169
test: epoch 2, loss 5.053704738616943, acc=0.0555555559694767, loss=5.053704738616943
train: epoch 3, loss 2.015052318572998, acc=0.2466111183166504, loss=2.015052318572998
test: epoch 3, loss 5.477326393127441, acc=0.05277777835726738, loss=5.477326393127441
train: epoch 4, loss 1.8775311708450317, acc=0.2831111252307892, loss=1.8775311708450317
test: epoch 4, loss 4.975470542907715, acc=0.07777778059244156, loss=4.975470542907715
train: epoch 5, loss 1.7767703533172607, acc=0.3163333237171173, loss=1.7767703533172607
test: epoch 5, loss 4.923465251922607, acc=0.06666667014360428, loss=4.923465251922607
train: epoch 6, loss 1.6981077194213867, acc=0.3406111001968384, loss=1.6981077194213867
test: epoch 6, loss 5.048202991485596, acc=0.07500000298023224, loss=5.048202991485596
train: epoch 7, loss 1.627132773399353, acc=0.3648333251476288, loss=1.627132773399353
test: epoch 7, loss 4.992189884185791, acc=0.05833333358168602, loss=4.992189884185791
train: epoch 8, loss 1.5456397533416748, acc=0.3884444534778595, loss=1.5456397533416748
test: epoch 8, loss 5.158344268798828, acc=0.09444444626569748, loss=5.158344268798828
train: epoch 9, loss 1.5042039155960083, acc=0.40799999237060547, loss=1.5042039155960083
test: epoch 9, loss 5.000117301940918, acc=0.08611111342906952, loss=5.000117301940918
train: epoch 10, loss 1.4679596424102783, acc=0.4216666519641876, loss=1.4679596424102783
test: epoch 10, loss 4.557806015014648, acc=0.1111111119389534, loss=4.557806015014648
train: epoch 11, loss 1.419756531715393, acc=0.44244444370269775, loss=1.419756531715393
test: epoch 11, loss 5.0819525718688965, acc=0.13333334028720856, loss=5.0819525718688965
train: epoch 12, loss 1.3728545904159546, acc=0.4596666693687439, loss=1.3728545904159546
test: epoch 12, loss 4.912158966064453, acc=0.12777778506278992, loss=4.912158966064453
train: epoch 13, loss 1.3426878452301025, acc=0.47244444489479065, loss=1.3426878452301025
test: epoch 13, loss 4.458941459655762, acc=0.13333334028720856, loss=4.458941459655762
train: epoch 14, loss 1.2996727228164673, acc=0.4887222349643707, loss=1.2996727228164673
test: epoch 14, loss 4.579035758972168, acc=0.10833333432674408, loss=4.579035758972168
train: epoch 15, loss 1.2735955715179443, acc=0.49916666746139526, loss=1.2735955715179443
test: epoch 15, loss 5.035991191864014, acc=0.12777778506278992, loss=5.035991191864014
train: epoch 16, loss 1.2525608539581299, acc=0.5097222328186035, loss=1.2525608539581299
test: epoch 16, loss 4.49794864654541, acc=0.13333334028720856, loss=4.49794864654541
train: epoch 17, loss 1.223978877067566, acc=0.5225555300712585, loss=1.223978877067566
test: epoch 17, loss 4.871774196624756, acc=0.10833333432674408, loss=4.871774196624756
train: epoch 18, loss 1.2235803604125977, acc=0.5253333449363708, loss=1.2235803604125977
test: epoch 18, loss 4.039217472076416, acc=0.11666666716337204, loss=4.039217472076416
train: epoch 19, loss 1.1704943180084229, acc=0.54666668176651, loss=1.1704943180084229
test: epoch 19, loss 4.6544671058654785, acc=0.13333334028720856, loss=4.6544671058654785
train: epoch 20, loss 1.1578309535980225, acc=0.5518888831138611, loss=1.1578309535980225
test: epoch 20, loss 5.574692249298096, acc=0.10555555671453476, loss=5.574692249298096
train: epoch 21, loss 1.1313711404800415, acc=0.5686666369438171, loss=1.1313711404800415
test: epoch 21, loss 4.808349609375, acc=0.11388888955116272, loss=4.808349609375
train: epoch 22, loss 1.1127214431762695, acc=0.5709444284439087, loss=1.1127214431762695
test: epoch 22, loss 4.589456558227539, acc=0.17499999701976776, loss=4.589456558227539
train: epoch 23, loss 1.0986709594726562, acc=0.5771111249923706, loss=1.0986709594726562
test: epoch 23, loss 4.750865936279297, acc=0.13611111044883728, loss=4.750865936279297
train: epoch 24, loss 1.084014654159546, acc=0.5903888940811157, loss=1.084014654159546
test: epoch 24, loss 4.380737781524658, acc=0.16111111640930176, loss=4.380737781524658
train: epoch 25, loss 1.0576938390731812, acc=0.5958333611488342, loss=1.0576938390731812
test: epoch 25, loss 4.4765424728393555, acc=0.14444445073604584, loss=4.4765424728393555
train: epoch 26, loss 1.0591503381729126, acc=0.5916666388511658, loss=1.0591503381729126
test: epoch 26, loss 4.211942195892334, acc=0.13333334028720856, loss=4.211942195892334
train: epoch 27, loss 1.0377966165542603, acc=0.6100555658340454, loss=1.0377966165542603
test: epoch 27, loss 4.294110298156738, acc=0.14722222089767456, loss=4.294110298156738
train: epoch 28, loss 1.0065104961395264, acc=0.61644446849823, loss=1.0065104961395264
test: epoch 28, loss 3.9387378692626953, acc=0.15000000596046448, loss=3.9387378692626953
train: epoch 29, loss 1.0074294805526733, acc=0.6231666803359985, loss=1.0074294805526733
test: epoch 29, loss 4.129543304443359, acc=0.12222222238779068, loss=4.129543304443359
train: epoch 30, loss 0.9883261322975159, acc=0.6272222399711609, loss=0.9883261322975159
test: epoch 30, loss 4.0601582527160645, acc=0.14722222089767456, loss=4.0601582527160645
train: epoch 31, loss 0.9816780090332031, acc=0.6255000233650208, loss=0.9816780090332031
test: epoch 31, loss 4.977949619293213, acc=0.13055555522441864, loss=4.977949619293213
train: epoch 32, loss 0.9637564420700073, acc=0.6351110935211182, loss=0.9637564420700073
test: epoch 32, loss 4.329501152038574, acc=0.12777778506278992, loss=4.329501152038574
train: epoch 33, loss 0.9608025550842285, acc=0.640666663646698, loss=0.9608025550842285
test: epoch 33, loss 3.947235584259033, acc=0.19166666269302368, loss=3.947235584259033
train: epoch 34, loss 0.9582200050354004, acc=0.6353333592414856, loss=0.9582200050354004
test: epoch 34, loss 4.050790786743164, acc=0.14166666567325592, loss=4.050790786743164
train: epoch 35, loss 0.9304717779159546, acc=0.6507777571678162, loss=0.9304717779159546
test: epoch 35, loss 4.330015659332275, acc=0.12777778506278992, loss=4.330015659332275
train: epoch 36, loss 0.9304144978523254, acc=0.6513333320617676, loss=0.9304144978523254
test: epoch 36, loss 5.353659152984619, acc=0.11666666716337204, loss=5.353659152984619
train: epoch 37, loss 0.9153746962547302, acc=0.6504444479942322, loss=0.9153746962547302
test: epoch 37, loss 4.458874702453613, acc=0.16388888657093048, loss=4.458874702453613
train: epoch 38, loss 0.9168007373809814, acc=0.6600555777549744, loss=0.9168007373809814
test: epoch 38, loss 4.309518814086914, acc=0.17222222685813904, loss=4.309518814086914
train: epoch 39, loss 0.8819687962532043, acc=0.6727777719497681, loss=0.8819687962532043
test: epoch 39, loss 3.4911367893218994, acc=0.12777778506278992, loss=3.4911367893218994
train: epoch 40, loss 0.898589015007019, acc=0.6667222380638123, loss=0.898589015007019
test: epoch 40, loss 4.377610683441162, acc=0.12222222238779068, loss=4.377610683441162
train: epoch 41, loss 0.8698326349258423, acc=0.6663888692855835, loss=0.8698326349258423
test: epoch 41, loss 4.0454254150390625, acc=0.13055555522441864, loss=4.0454254150390625
train: epoch 42, loss 0.872410237789154, acc=0.676111102104187, loss=0.872410237789154
test: epoch 42, loss 4.137984752655029, acc=0.12222222238779068, loss=4.137984752655029
train: epoch 43, loss 0.8592681288719177, acc=0.6850000023841858, loss=0.8592681288719177
test: epoch 43, loss 4.133893013000488, acc=0.16388888657093048, loss=4.133893013000488
train: epoch 44, loss 0.8374670743942261, acc=0.6873888969421387, loss=0.8374670743942261
test: epoch 44, loss 3.9644510746002197, acc=0.1388888955116272, loss=3.9644510746002197
train: epoch 45, loss 0.8275378942489624, acc=0.6945555806159973, loss=0.8275378942489624
test: epoch 45, loss 4.558485507965088, acc=0.15555556118488312, loss=4.558485507965088
train: epoch 46, loss 0.8425285816192627, acc=0.69477778673172, loss=0.8425285816192627
test: epoch 46, loss 4.7834272384643555, acc=0.14166666567325592, loss=4.7834272384643555
train: epoch 47, loss 0.8130312561988831, acc=0.6982777714729309, loss=0.8130312561988831
test: epoch 47, loss 3.7034056186676025, acc=0.1666666716337204, loss=3.7034056186676025
train: epoch 48, loss 0.8248457312583923, acc=0.694944441318512, loss=0.8248457312583923
test: epoch 48, loss 3.8148200511932373, acc=0.1527777761220932, loss=3.8148200511932373
train: epoch 49, loss 0.8006880879402161, acc=0.7037222385406494, loss=0.8006880879402161
test: epoch 49, loss 3.8264079093933105, acc=0.15555556118488312, loss=3.8264079093933105
train: epoch 50, loss 0.7974850535392761, acc=0.7060555815696716, loss=0.7974850535392761
test: epoch 50, loss 4.245283603668213, acc=0.1805555522441864, loss=4.245283603668213
train: epoch 51, loss 0.810968279838562, acc=0.7089444398880005, loss=0.810968279838562
test: epoch 51, loss 3.7491493225097656, acc=0.18611110746860504, loss=3.7491493225097656
train: epoch 52, loss 0.7828654050827026, acc=0.7139999866485596, loss=0.7828654050827026
test: epoch 52, loss 3.7996039390563965, acc=0.10555555671453476, loss=3.7996039390563965
train: epoch 53, loss 0.7916284799575806, acc=0.7099444270133972, loss=0.7916284799575806
test: epoch 53, loss 4.073836326599121, acc=0.11388888955116272, loss=4.073836326599121
train: epoch 54, loss 0.7649770975112915, acc=0.7173333168029785, loss=0.7649770975112915
test: epoch 54, loss 5.230401039123535, acc=0.15000000596046448, loss=5.230401039123535
train: epoch 55, loss 0.7626542448997498, acc=0.7211666703224182, loss=0.7626542448997498
test: epoch 55, loss 3.5081262588500977, acc=0.1666666716337204, loss=3.5081262588500977
train: epoch 56, loss 0.755394697189331, acc=0.7241111397743225, loss=0.755394697189331
test: epoch 56, loss 4.1694488525390625, acc=0.17222222685813904, loss=4.1694488525390625
train: epoch 57, loss 0.7651192545890808, acc=0.7213888764381409, loss=0.7651192545890808
test: epoch 57, loss 5.10243558883667, acc=0.16388888657093048, loss=5.10243558883667
train: epoch 58, loss 0.7564036846160889, acc=0.7192777991294861, loss=0.7564036846160889
test: epoch 58, loss 3.6810507774353027, acc=0.16944444179534912, loss=3.6810507774353027
train: epoch 59, loss 0.7605626583099365, acc=0.7254999876022339, loss=0.7605626583099365
test: epoch 59, loss 3.8775126934051514, acc=0.18333333730697632, loss=3.8775126934051514
train: epoch 60, loss 0.7602278590202332, acc=0.7245000004768372, loss=0.7602278590202332
test: epoch 60, loss 3.762120246887207, acc=0.14444445073604584, loss=3.762120246887207
train: epoch 61, loss 0.7513960599899292, acc=0.7282778024673462, loss=0.7513960599899292
test: epoch 61, loss 3.711808443069458, acc=0.17222222685813904, loss=3.711808443069458
train: epoch 62, loss 0.7341822385787964, acc=0.7342222332954407, loss=0.7341822385787964
test: epoch 62, loss 3.7321341037750244, acc=0.14722222089767456, loss=3.7321341037750244
train: epoch 63, loss 0.7228721976280212, acc=0.7352222204208374, loss=0.7228721976280212
test: epoch 63, loss 4.0048322677612305, acc=0.15833333134651184, loss=4.0048322677612305
train: epoch 64, loss 0.7293004989624023, acc=0.7337222099304199, loss=0.7293004989624023
test: epoch 64, loss 3.6494226455688477, acc=0.16944444179534912, loss=3.6494226455688477
train: epoch 65, loss 0.7258180379867554, acc=0.7382222414016724, loss=0.7258180379867554
test: epoch 65, loss 3.447800397872925, acc=0.15833333134651184, loss=3.447800397872925
train: epoch 66, loss 0.6962092518806458, acc=0.7453888654708862, loss=0.6962092518806458
test: epoch 66, loss 3.653022050857544, acc=0.17499999701976776, loss=3.653022050857544
train: epoch 67, loss 0.6989856362342834, acc=0.7406111359596252, loss=0.6989856362342834
test: epoch 67, loss 5.120400905609131, acc=0.1944444477558136, loss=5.120400905609131
train: epoch 68, loss 0.7044954299926758, acc=0.7478888630867004, loss=0.7044954299926758
test: epoch 68, loss 4.557130813598633, acc=0.17222222685813904, loss=4.557130813598633
train: epoch 69, loss 0.6900143027305603, acc=0.7519444227218628, loss=0.6900143027305603
test: epoch 69, loss 3.3882365226745605, acc=0.16388888657093048, loss=3.3882365226745605
train: epoch 70, loss 0.6850576996803284, acc=0.7450555562973022, loss=0.6850576996803284
test: epoch 70, loss 4.153674125671387, acc=0.17499999701976776, loss=4.153674125671387
train: epoch 71, loss 0.6882756352424622, acc=0.7518888711929321, loss=0.6882756352424622
test: epoch 71, loss 4.869182109832764, acc=0.21388888359069824, loss=4.869182109832764
train: epoch 72, loss 0.6921602487564087, acc=0.7439444661140442, loss=0.6921602487564087
test: epoch 72, loss 3.598461627960205, acc=0.13611111044883728, loss=3.598461627960205
train: epoch 73, loss 0.6782446503639221, acc=0.7522777915000916, loss=0.6782446503639221
test: epoch 73, loss 4.329620361328125, acc=0.18611110746860504, loss=4.329620361328125
train: epoch 74, loss 0.654532790184021, acc=0.7602221965789795, loss=0.654532790184021
test: epoch 74, loss 3.2220778465270996, acc=0.2805555462837219, loss=3.2220778465270996
train: epoch 75, loss 0.665040910243988, acc=0.7615000009536743, loss=0.665040910243988
test: epoch 75, loss 3.6891262531280518, acc=0.21944443881511688, loss=3.6891262531280518
train: epoch 76, loss 0.697094738483429, acc=0.7451666593551636, loss=0.697094738483429
test: epoch 76, loss 3.85091233253479, acc=0.17499999701976776, loss=3.85091233253479
train: epoch 77, loss 0.6663845777511597, acc=0.7567777633666992, loss=0.6663845777511597
test: epoch 77, loss 3.2411017417907715, acc=0.2222222238779068, loss=3.2411017417907715
train: epoch 78, loss 0.665462076663971, acc=0.7591666579246521, loss=0.665462076663971
test: epoch 78, loss 3.3962185382843018, acc=0.15555556118488312, loss=3.3962185382843018
train: epoch 79, loss 0.6500234603881836, acc=0.7666110992431641, loss=0.6500234603881836
test: epoch 79, loss 4.294780731201172, acc=0.15000000596046448, loss=4.294780731201172
train: epoch 80, loss 0.6504634618759155, acc=0.7593333125114441, loss=0.6504634618759155
test: epoch 80, loss 2.891784429550171, acc=0.23333333432674408, loss=2.891784429550171
train: epoch 81, loss 0.6572167277336121, acc=0.7641111016273499, loss=0.6572167277336121
test: epoch 81, loss 3.131978750228882, acc=0.18888889253139496, loss=3.131978750228882
train: epoch 82, loss 0.6577112674713135, acc=0.7621666789054871, loss=0.6577112674713135
test: epoch 82, loss 3.577221393585205, acc=0.20277777314186096, loss=3.577221393585205
train: epoch 83, loss 0.6283859610557556, acc=0.7689444422721863, loss=0.6283859610557556
test: epoch 83, loss 3.7282803058624268, acc=0.18611110746860504, loss=3.7282803058624268
train: epoch 84, loss 0.6487084031105042, acc=0.7643888592720032, loss=0.6487084031105042
test: epoch 84, loss 3.7816901206970215, acc=0.17777778208255768, loss=3.7816901206970215
train: epoch 85, loss 0.6273099780082703, acc=0.7692221999168396, loss=0.6273099780082703
test: epoch 85, loss 3.680337905883789, acc=0.18611110746860504, loss=3.680337905883789
train: epoch 86, loss 0.6098018884658813, acc=0.7757777571678162, loss=0.6098018884658813
test: epoch 86, loss 4.527166366577148, acc=0.14444445073604584, loss=4.527166366577148
train: epoch 87, loss 0.6236293911933899, acc=0.7712222337722778, loss=0.6236293911933899
test: epoch 87, loss 3.655880928039551, acc=0.2222222238779068, loss=3.655880928039551
train: epoch 88, loss 0.6024352312088013, acc=0.7792778015136719, loss=0.6024352312088013
test: epoch 88, loss 3.5494799613952637, acc=0.1944444477558136, loss=3.5494799613952637
train: epoch 89, loss 0.6082459688186646, acc=0.7804444432258606, loss=0.6082459688186646
test: epoch 89, loss 3.2371623516082764, acc=0.21388888359069824, loss=3.2371623516082764
train: epoch 90, loss 0.6392112970352173, acc=0.7720000147819519, loss=0.6392112970352173
test: epoch 90, loss 4.4207282066345215, acc=0.14444445073604584, loss=4.4207282066345215
train: epoch 91, loss 0.6187126040458679, acc=0.7770000100135803, loss=0.6187126040458679
test: epoch 91, loss 3.982318878173828, acc=0.19166666269302368, loss=3.982318878173828
train: epoch 92, loss 0.5919162034988403, acc=0.7833889126777649, loss=0.5919162034988403
test: epoch 92, loss 3.6325266361236572, acc=0.18333333730697632, loss=3.6325266361236572
train: epoch 93, loss 0.5978002548217773, acc=0.7866111397743225, loss=0.5978002548217773
test: epoch 93, loss 4.157684803009033, acc=0.18611110746860504, loss=4.157684803009033
train: epoch 94, loss 0.5851196050643921, acc=0.7921110987663269, loss=0.5851196050643921
test: epoch 94, loss 3.753101110458374, acc=0.1805555522441864, loss=3.753101110458374
train: epoch 95, loss 0.6055827736854553, acc=0.7850555777549744, loss=0.6055827736854553
test: epoch 95, loss 3.315931558609009, acc=0.21666666865348816, loss=3.315931558609009
train: epoch 96, loss 0.5781198740005493, acc=0.7881110906600952, loss=0.5781198740005493
test: epoch 96, loss 3.7985363006591797, acc=0.22499999403953552, loss=3.7985363006591797
train: epoch 97, loss 0.5823273658752441, acc=0.7919444441795349, loss=0.5823273658752441
test: epoch 97, loss 3.3836963176727295, acc=0.1944444477558136, loss=3.3836963176727295
train: epoch 98, loss 0.5713356733322144, acc=0.7926666736602783, loss=0.5713356733322144
test: epoch 98, loss 4.148765563964844, acc=0.2083333283662796, loss=4.148765563964844
train: epoch 99, loss 0.5667895674705505, acc=0.7946110963821411, loss=0.5667895674705505
test: epoch 99, loss 3.451509952545166, acc=0.18333333730697632, loss=3.451509952545166
train: epoch 100, loss 0.5912490487098694, acc=0.7869444489479065, loss=0.5912490487098694
test: epoch 100, loss 3.466447591781616, acc=0.19722221791744232, loss=3.466447591781616
train: epoch 101, loss 0.5597017407417297, acc=0.7977777719497681, loss=0.5597017407417297
test: epoch 101, loss 3.8827593326568604, acc=0.19722221791744232, loss=3.8827593326568604
train: epoch 102, loss 0.5705543756484985, acc=0.7953333258628845, loss=0.5705543756484985
test: epoch 102, loss 3.7123336791992188, acc=0.14444445073604584, loss=3.7123336791992188
train: epoch 103, loss 0.5690369009971619, acc=0.7953888773918152, loss=0.5690369009971619
test: epoch 103, loss 4.221476078033447, acc=0.1666666716337204, loss=4.221476078033447
train: epoch 104, loss 0.5573149919509888, acc=0.804888904094696, loss=0.5573149919509888
test: epoch 104, loss 2.925549268722534, acc=0.23888888955116272, loss=2.925549268722534
train: epoch 105, loss 0.5635377168655396, acc=0.7976666688919067, loss=0.5635377168655396
test: epoch 105, loss 3.4868972301483154, acc=0.24722221493721008, loss=3.4868972301483154
train: epoch 106, loss 0.5586786270141602, acc=0.8004444241523743, loss=0.5586786270141602
test: epoch 106, loss 3.576019048690796, acc=0.1944444477558136, loss=3.576019048690796
train: epoch 107, loss 0.5494898557662964, acc=0.8061110973358154, loss=0.5494898557662964
test: epoch 107, loss 3.606365442276001, acc=0.1666666716337204, loss=3.606365442276001
train: epoch 108, loss 0.5434541702270508, acc=0.8046666383743286, loss=0.5434541702270508
test: epoch 108, loss 2.7752280235290527, acc=0.25555557012557983, loss=2.7752280235290527
train: epoch 109, loss 0.5340036749839783, acc=0.8095555305480957, loss=0.5340036749839783
test: epoch 109, loss 4.188324451446533, acc=0.22499999403953552, loss=4.188324451446533
train: epoch 110, loss 0.5305513143539429, acc=0.812666654586792, loss=0.5305513143539429
test: epoch 110, loss 3.339341402053833, acc=0.1944444477558136, loss=3.339341402053833
train: epoch 111, loss 0.5290066599845886, acc=0.8103888630867004, loss=0.5290066599845886
test: epoch 111, loss 2.929910659790039, acc=0.27222222089767456, loss=2.929910659790039
train: epoch 112, loss 0.5189312696456909, acc=0.816277801990509, loss=0.5189312696456909
test: epoch 112, loss 3.4726948738098145, acc=0.20555555820465088, loss=3.4726948738098145
train: epoch 113, loss 0.5327709317207336, acc=0.8112221956253052, loss=0.5327709317207336
test: epoch 113, loss 3.6961822509765625, acc=0.21944443881511688, loss=3.6961822509765625
train: epoch 114, loss 0.5141472220420837, acc=0.8165000081062317, loss=0.5141472220420837
test: epoch 114, loss 3.3368043899536133, acc=0.2805555462837219, loss=3.3368043899536133
train: epoch 115, loss 0.5346006155014038, acc=0.8096110820770264, loss=0.5346006155014038
test: epoch 115, loss 3.4852259159088135, acc=0.18611110746860504, loss=3.4852259159088135
train: epoch 116, loss 0.5139835476875305, acc=0.8191111087799072, loss=0.5139835476875305
test: epoch 116, loss 3.6437385082244873, acc=0.20277777314186096, loss=3.6437385082244873
train: epoch 117, loss 0.5128377079963684, acc=0.8134444355964661, loss=0.5128377079963684
test: epoch 117, loss 3.416261911392212, acc=0.22777777910232544, loss=3.416261911392212
train: epoch 118, loss 0.5180376768112183, acc=0.8189444541931152, loss=0.5180376768112183
test: epoch 118, loss 3.2081892490386963, acc=0.25, loss=3.2081892490386963
train: epoch 119, loss 0.5083205103874207, acc=0.8195000290870667, loss=0.5083205103874207
test: epoch 119, loss 3.8651089668273926, acc=0.21666666865348816, loss=3.8651089668273926
train: epoch 120, loss 0.5196711421012878, acc=0.81977778673172, loss=0.5196711421012878
test: epoch 120, loss 3.19482159614563, acc=0.24166665971279144, loss=3.19482159614563
train: epoch 121, loss 0.505296528339386, acc=0.8221666812896729, loss=0.505296528339386
test: epoch 121, loss 3.718705892562866, acc=0.15555556118488312, loss=3.718705892562866
train: epoch 122, loss 0.531337320804596, acc=0.8107222318649292, loss=0.531337320804596
test: epoch 122, loss 3.1586685180664062, acc=0.23888888955116272, loss=3.1586685180664062
train: epoch 123, loss 0.49375733733177185, acc=0.8256111145019531, loss=0.49375733733177185
test: epoch 123, loss 2.9901649951934814, acc=0.18888889253139496, loss=2.9901649951934814
train: epoch 124, loss 0.49214187264442444, acc=0.8260555267333984, loss=0.49214187264442444
test: epoch 124, loss 3.321155548095703, acc=0.22499999403953552, loss=3.321155548095703
train: epoch 125, loss 0.48385393619537354, acc=0.8260555267333984, loss=0.48385393619537354
test: epoch 125, loss 2.9277656078338623, acc=0.27222222089767456, loss=2.9277656078338623
train: epoch 126, loss 0.4996979832649231, acc=0.8257222175598145, loss=0.4996979832649231
test: epoch 126, loss 3.77292799949646, acc=0.16111111640930176, loss=3.77292799949646
train: epoch 127, loss 0.49759626388549805, acc=0.8237777948379517, loss=0.49759626388549805
test: epoch 127, loss 3.1026771068573, acc=0.1666666716337204, loss=3.1026771068573
train: epoch 128, loss 0.48517951369285583, acc=0.8270555734634399, loss=0.48517951369285583
test: epoch 128, loss 3.524268388748169, acc=0.24444444477558136, loss=3.524268388748169
train: epoch 129, loss 0.5023537874221802, acc=0.8259999752044678, loss=0.5023537874221802
test: epoch 129, loss 3.0066325664520264, acc=0.19166666269302368, loss=3.0066325664520264
train: epoch 130, loss 0.48989805579185486, acc=0.8275555372238159, loss=0.48989805579185486
test: epoch 130, loss 2.8330600261688232, acc=0.21666666865348816, loss=2.8330600261688232
train: epoch 131, loss 0.4797291159629822, acc=0.8318889141082764, loss=0.4797291159629822
test: epoch 131, loss 3.0958878993988037, acc=0.23333333432674408, loss=3.0958878993988037
train: epoch 132, loss 0.4793532192707062, acc=0.8295000195503235, loss=0.4793532192707062
test: epoch 132, loss 3.598858118057251, acc=0.14722222089767456, loss=3.598858118057251
train: epoch 133, loss 0.49396219849586487, acc=0.8259444236755371, loss=0.49396219849586487
test: epoch 133, loss 2.806217670440674, acc=0.2222222238779068, loss=2.806217670440674
train: epoch 134, loss 0.46101075410842896, acc=0.8314444422721863, loss=0.46101075410842896
test: epoch 134, loss 2.438619375228882, acc=0.23888888955116272, loss=2.438619375228882
train: epoch 135, loss 0.46664878726005554, acc=0.8364999890327454, loss=0.46664878726005554
test: epoch 135, loss 3.007486343383789, acc=0.2527777850627899, loss=3.007486343383789
train: epoch 136, loss 0.4885065257549286, acc=0.8315555453300476, loss=0.4885065257549286
test: epoch 136, loss 3.336000680923462, acc=0.19722221791744232, loss=3.336000680923462
train: epoch 137, loss 0.4558095335960388, acc=0.8385000228881836, loss=0.4558095335960388
test: epoch 137, loss 3.2373392581939697, acc=0.22777777910232544, loss=3.2373392581939697
train: epoch 138, loss 0.4734792709350586, acc=0.8349999785423279, loss=0.4734792709350586
test: epoch 138, loss 2.769954204559326, acc=0.20000000298023224, loss=2.769954204559326
train: epoch 139, loss 0.45778000354766846, acc=0.836555540561676, loss=0.45778000354766846
test: epoch 139, loss 2.767773151397705, acc=0.23055554926395416, loss=2.767773151397705
train: epoch 140, loss 0.4665515124797821, acc=0.8355555534362793, loss=0.4665515124797821
test: epoch 140, loss 3.278276205062866, acc=0.2083333283662796, loss=3.278276205062866
train: epoch 141, loss 0.49137529730796814, acc=0.8327222466468811, loss=0.49137529730796814
test: epoch 141, loss 3.50872802734375, acc=0.18611110746860504, loss=3.50872802734375
train: epoch 142, loss 0.45904505252838135, acc=0.8358333110809326, loss=0.45904505252838135
test: epoch 142, loss 3.438495397567749, acc=0.2222222238779068, loss=3.438495397567749
train: epoch 143, loss 0.4722291827201843, acc=0.8331666588783264, loss=0.4722291827201843
test: epoch 143, loss 2.763179302215576, acc=0.24166665971279144, loss=2.763179302215576
train: epoch 144, loss 0.45348256826400757, acc=0.8396111130714417, loss=0.45348256826400757
test: epoch 144, loss 2.7977941036224365, acc=0.2527777850627899, loss=2.7977941036224365
train: epoch 145, loss 0.4581657648086548, acc=0.8378333449363708, loss=0.4581657648086548
test: epoch 145, loss 2.6839075088500977, acc=0.2222222238779068, loss=2.6839075088500977
train: epoch 146, loss 0.46234023571014404, acc=0.8375555276870728, loss=0.46234023571014404
test: epoch 146, loss 3.2055349349975586, acc=0.14722222089767456, loss=3.2055349349975586
train: epoch 147, loss 0.4577098488807678, acc=0.8371666669845581, loss=0.4577098488807678
test: epoch 147, loss 3.7377991676330566, acc=0.1527777761220932, loss=3.7377991676330566
train: epoch 148, loss 0.4597890079021454, acc=0.8372777700424194, loss=0.4597890079021454
test: epoch 148, loss 4.477471828460693, acc=0.25555557012557983, loss=4.477471828460693
train: epoch 149, loss 0.43649986386299133, acc=0.8445555567741394, loss=0.43649986386299133
test: epoch 149, loss 3.2509372234344482, acc=0.2611111104488373, loss=3.2509372234344482
train: epoch 150, loss 0.427967369556427, acc=0.8462222218513489, loss=0.427967369556427
test: epoch 150, loss 2.4846861362457275, acc=0.28611111640930176, loss=2.4846861362457275
