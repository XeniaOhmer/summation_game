# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=1", "--temp_decay=0.99", "--one_hot=0", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=1473690490, receiver_embed_dim=64, save_run=0, temp_decay=0.99, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=1473690490, receiver_embed_dim=64, save_run=False, temp_decay=0.99, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.876696825027466, acc=0.09516666829586029, loss=2.876696825027466
test: epoch 1, loss 3.5373241901397705, acc=0.06666667014360428, loss=3.5373241901397705
train: epoch 2, loss 2.394394636154175, acc=0.1657777726650238, loss=2.394394636154175
test: epoch 2, loss 2.933260917663574, acc=0.10555555671453476, loss=2.933260917663574
train: epoch 3, loss 2.1503758430480957, acc=0.2081666737794876, loss=2.1503758430480957
test: epoch 3, loss 2.6803998947143555, acc=0.125, loss=2.6803998947143555
train: epoch 4, loss 2.017575979232788, acc=0.24211111664772034, loss=2.017575979232788
test: epoch 4, loss 2.5283448696136475, acc=0.12222222238779068, loss=2.5283448696136475
train: epoch 5, loss 1.9429486989974976, acc=0.2535000145435333, loss=1.9429486989974976
test: epoch 5, loss 2.402225971221924, acc=0.13055555522441864, loss=2.402225971221924
train: epoch 6, loss 1.857792854309082, acc=0.2720000147819519, loss=1.857792854309082
test: epoch 6, loss 2.4606685638427734, acc=0.14444445073604584, loss=2.4606685638427734
train: epoch 7, loss 1.802549123764038, acc=0.2894444465637207, loss=1.802549123764038
test: epoch 7, loss 2.3583719730377197, acc=0.17777778208255768, loss=2.3583719730377197
train: epoch 8, loss 1.7622052431106567, acc=0.3070000112056732, loss=1.7622052431106567
test: epoch 8, loss 2.3866124153137207, acc=0.1527777761220932, loss=2.3866124153137207
train: epoch 9, loss 1.7116667032241821, acc=0.3158888816833496, loss=1.7116667032241821
test: epoch 9, loss 2.326137065887451, acc=0.14722222089767456, loss=2.326137065887451
train: epoch 10, loss 1.6824893951416016, acc=0.32855555415153503, loss=1.6824893951416016
test: epoch 10, loss 2.3148069381713867, acc=0.15000000596046448, loss=2.3148069381713867
train: epoch 11, loss 1.6529313325881958, acc=0.34111112356185913, loss=1.6529313325881958
test: epoch 11, loss 2.2476718425750732, acc=0.17499999701976776, loss=2.2476718425750732
train: epoch 12, loss 1.6198256015777588, acc=0.34744444489479065, loss=1.6198256015777588
test: epoch 12, loss 2.133281707763672, acc=0.18888889253139496, loss=2.133281707763672
train: epoch 13, loss 1.5995091199874878, acc=0.34983333945274353, loss=1.5995091199874878
test: epoch 13, loss 2.1790997982025146, acc=0.17222222685813904, loss=2.1790997982025146
train: epoch 14, loss 1.5841397047042847, acc=0.35850000381469727, loss=1.5841397047042847
test: epoch 14, loss 2.155384063720703, acc=0.17499999701976776, loss=2.155384063720703
train: epoch 15, loss 1.5764951705932617, acc=0.35938888788223267, loss=1.5764951705932617
test: epoch 15, loss 2.258453130722046, acc=0.18611110746860504, loss=2.258453130722046
train: epoch 16, loss 1.529951810836792, acc=0.3795555531978607, loss=1.529951810836792
test: epoch 16, loss 2.082979679107666, acc=0.17222222685813904, loss=2.082979679107666
train: epoch 17, loss 1.5295875072479248, acc=0.3817777633666992, loss=1.5295875072479248
test: epoch 17, loss 2.1407253742218018, acc=0.17777778208255768, loss=2.1407253742218018
train: epoch 18, loss 1.5057706832885742, acc=0.3876666724681854, loss=1.5057706832885742
test: epoch 18, loss 2.176767349243164, acc=0.18888889253139496, loss=2.176767349243164
train: epoch 19, loss 1.4972059726715088, acc=0.3927222192287445, loss=1.4972059726715088
test: epoch 19, loss 2.185065507888794, acc=0.19166666269302368, loss=2.185065507888794
train: epoch 20, loss 1.4805408716201782, acc=0.386388897895813, loss=1.4805408716201782
test: epoch 20, loss 2.0735862255096436, acc=0.18333333730697632, loss=2.0735862255096436
train: epoch 21, loss 1.4790252447128296, acc=0.3978888988494873, loss=1.4790252447128296
test: epoch 21, loss 1.9795749187469482, acc=0.21111111342906952, loss=1.9795749187469482
train: epoch 22, loss 1.4467376470565796, acc=0.41127777099609375, loss=1.4467376470565796
test: epoch 22, loss 1.9793647527694702, acc=0.20555555820465088, loss=1.9793647527694702
train: epoch 23, loss 1.451446294784546, acc=0.39883333444595337, loss=1.451446294784546
test: epoch 23, loss 2.1954100131988525, acc=0.20277777314186096, loss=2.1954100131988525
train: epoch 24, loss 1.4444377422332764, acc=0.4048333466053009, loss=1.4444377422332764
test: epoch 24, loss 1.9629825353622437, acc=0.23055554926395416, loss=1.9629825353622437
train: epoch 25, loss 1.4278298616409302, acc=0.41600000858306885, loss=1.4278298616409302
test: epoch 25, loss 2.139690637588501, acc=0.21388888359069824, loss=2.139690637588501
train: epoch 26, loss 1.4196566343307495, acc=0.4162222146987915, loss=1.4196566343307495
test: epoch 26, loss 1.8483680486679077, acc=0.21666666865348816, loss=1.8483680486679077
train: epoch 27, loss 1.4273691177368164, acc=0.41894444823265076, loss=1.4273691177368164
test: epoch 27, loss 1.9738414287567139, acc=0.1944444477558136, loss=1.9738414287567139
train: epoch 28, loss 1.4116610288619995, acc=0.42311111092567444, loss=1.4116610288619995
test: epoch 28, loss 1.878265142440796, acc=0.29722222685813904, loss=1.878265142440796
train: epoch 29, loss 1.3881009817123413, acc=0.42872223258018494, loss=1.3881009817123413
test: epoch 29, loss 1.939993977546692, acc=0.2361111044883728, loss=1.939993977546692
train: epoch 30, loss 1.393595576286316, acc=0.4228888750076294, loss=1.393595576286316
test: epoch 30, loss 1.7660160064697266, acc=0.2916666567325592, loss=1.7660160064697266
train: epoch 31, loss 1.3688666820526123, acc=0.4456111192703247, loss=1.3688666820526123
test: epoch 31, loss 1.753116250038147, acc=0.26944443583488464, loss=1.753116250038147
train: epoch 32, loss 1.3400589227676392, acc=0.44583332538604736, loss=1.3400589227676392
test: epoch 32, loss 1.7540435791015625, acc=0.3055555522441864, loss=1.7540435791015625
train: epoch 33, loss 1.3540347814559937, acc=0.44527778029441833, loss=1.3540347814559937
test: epoch 33, loss 1.7918428182601929, acc=0.28611111640930176, loss=1.7918428182601929
train: epoch 34, loss 1.3259342908859253, acc=0.4543333351612091, loss=1.3259342908859253
test: epoch 34, loss 1.6543670892715454, acc=0.2527777850627899, loss=1.6543670892715454
train: epoch 35, loss 1.338024377822876, acc=0.44733333587646484, loss=1.338024377822876
test: epoch 35, loss 1.7301557064056396, acc=0.26944443583488464, loss=1.7301557064056396
train: epoch 36, loss 1.2952522039413452, acc=0.4666111171245575, loss=1.2952522039413452
test: epoch 36, loss 1.804566502571106, acc=0.2750000059604645, loss=1.804566502571106
train: epoch 37, loss 1.3309497833251953, acc=0.4624444544315338, loss=1.3309497833251953
test: epoch 37, loss 1.7648595571517944, acc=0.2611111104488373, loss=1.7648595571517944
train: epoch 38, loss 1.2984561920166016, acc=0.46655556559562683, loss=1.2984561920166016
test: epoch 38, loss 1.8652739524841309, acc=0.24444444477558136, loss=1.8652739524841309
train: epoch 39, loss 1.2610825300216675, acc=0.48249998688697815, loss=1.2610825300216675
test: epoch 39, loss 1.6350270509719849, acc=0.3166666626930237, loss=1.6350270509719849
train: epoch 40, loss 1.2517766952514648, acc=0.48694443702697754, loss=1.2517766952514648
test: epoch 40, loss 1.7357746362686157, acc=0.2638888955116272, loss=1.7357746362686157
train: epoch 41, loss 1.236595869064331, acc=0.4915555417537689, loss=1.236595869064331
test: epoch 41, loss 1.7531360387802124, acc=0.28611111640930176, loss=1.7531360387802124
train: epoch 42, loss 1.2366164922714233, acc=0.49327778816223145, loss=1.2366164922714233
test: epoch 42, loss 1.6643812656402588, acc=0.2638888955116272, loss=1.6643812656402588
train: epoch 43, loss 1.2243088483810425, acc=0.49961110949516296, loss=1.2243088483810425
test: epoch 43, loss 1.7692774534225464, acc=0.2916666567325592, loss=1.7692774534225464
train: epoch 44, loss 1.204491376876831, acc=0.5026111006736755, loss=1.204491376876831
test: epoch 44, loss 1.7245486974716187, acc=0.2777777910232544, loss=1.7245486974716187
train: epoch 45, loss 1.2069815397262573, acc=0.5053333044052124, loss=1.2069815397262573
test: epoch 45, loss 1.7791060209274292, acc=0.2750000059604645, loss=1.7791060209274292
train: epoch 46, loss 1.1845966577529907, acc=0.5195555686950684, loss=1.1845966577529907
test: epoch 46, loss 1.7635421752929688, acc=0.30000001192092896, loss=1.7635421752929688
train: epoch 47, loss 1.1647868156433105, acc=0.5221666693687439, loss=1.1647868156433105
test: epoch 47, loss 1.7066681385040283, acc=0.3027777671813965, loss=1.7066681385040283
train: epoch 48, loss 1.1650789976119995, acc=0.5153889060020447, loss=1.1650789976119995
test: epoch 48, loss 1.7371876239776611, acc=0.31111112236976624, loss=1.7371876239776611
train: epoch 49, loss 1.1498371362686157, acc=0.5232222080230713, loss=1.1498371362686157
test: epoch 49, loss 1.7394644021987915, acc=0.24722221493721008, loss=1.7394644021987915
train: epoch 50, loss 1.1423907279968262, acc=0.5277222394943237, loss=1.1423907279968262
test: epoch 50, loss 1.7848607301712036, acc=0.2750000059604645, loss=1.7848607301712036
train: epoch 51, loss 1.121523141860962, acc=0.5432778000831604, loss=1.121523141860962
test: epoch 51, loss 1.6345984935760498, acc=0.3222222328186035, loss=1.6345984935760498
train: epoch 52, loss 1.122166633605957, acc=0.5393333435058594, loss=1.122166633605957
test: epoch 52, loss 1.7124476432800293, acc=0.28333333134651184, loss=1.7124476432800293
train: epoch 53, loss 1.1224356889724731, acc=0.5394444465637207, loss=1.1224356889724731
test: epoch 53, loss 1.656785488128662, acc=0.32777777314186096, loss=1.656785488128662
train: epoch 54, loss 1.0987069606781006, acc=0.5512222051620483, loss=1.0987069606781006
test: epoch 54, loss 1.7594832181930542, acc=0.28611111640930176, loss=1.7594832181930542
train: epoch 55, loss 1.0925019979476929, acc=0.5488333106040955, loss=1.0925019979476929
test: epoch 55, loss 1.5869042873382568, acc=0.3166666626930237, loss=1.5869042873382568
train: epoch 56, loss 1.0918855667114258, acc=0.5527777671813965, loss=1.0918855667114258
test: epoch 56, loss 1.5315895080566406, acc=0.32777777314186096, loss=1.5315895080566406
train: epoch 57, loss 1.0858683586120605, acc=0.5576666593551636, loss=1.0858683586120605
test: epoch 57, loss 1.6146050691604614, acc=0.3166666626930237, loss=1.6146050691604614
train: epoch 58, loss 1.0635597705841064, acc=0.5672777891159058, loss=1.0635597705841064
test: epoch 58, loss 1.6706695556640625, acc=0.2888889014720917, loss=1.6706695556640625
train: epoch 59, loss 1.0580822229385376, acc=0.5632777810096741, loss=1.0580822229385376
test: epoch 59, loss 1.5863398313522339, acc=0.25555557012557983, loss=1.5863398313522339
train: epoch 60, loss 1.0631037950515747, acc=0.5613333582878113, loss=1.0631037950515747
test: epoch 60, loss 1.5668233633041382, acc=0.24166665971279144, loss=1.5668233633041382
train: epoch 61, loss 1.0506397485733032, acc=0.5765555500984192, loss=1.0506397485733032
test: epoch 61, loss 1.619067907333374, acc=0.38333332538604736, loss=1.619067907333374
train: epoch 62, loss 1.0408908128738403, acc=0.5737777948379517, loss=1.0408908128738403
test: epoch 62, loss 1.558669090270996, acc=0.2777777910232544, loss=1.558669090270996
train: epoch 63, loss 1.0429983139038086, acc=0.5733333230018616, loss=1.0429983139038086
test: epoch 63, loss 1.5587304830551147, acc=0.3166666626930237, loss=1.5587304830551147
train: epoch 64, loss 1.0351896286010742, acc=0.5766111016273499, loss=1.0351896286010742
test: epoch 64, loss 1.6168477535247803, acc=0.3583333194255829, loss=1.6168477535247803
train: epoch 65, loss 1.0362221002578735, acc=0.5758888721466064, loss=1.0362221002578735
test: epoch 65, loss 1.5563184022903442, acc=0.3638888895511627, loss=1.5563184022903442
train: epoch 66, loss 1.016556978225708, acc=0.5862777829170227, loss=1.016556978225708
test: epoch 66, loss 1.7447950839996338, acc=0.2777777910232544, loss=1.7447950839996338
train: epoch 67, loss 1.0011980533599854, acc=0.5870000123977661, loss=1.0011980533599854
test: epoch 67, loss 1.6896806955337524, acc=0.31388887763023376, loss=1.6896806955337524
train: epoch 68, loss 1.0133839845657349, acc=0.5860555768013, loss=1.0133839845657349
test: epoch 68, loss 1.7689260244369507, acc=0.23055554926395416, loss=1.7689260244369507
train: epoch 69, loss 0.993075430393219, acc=0.593500018119812, loss=0.993075430393219
test: epoch 69, loss 1.6463501453399658, acc=0.31111112236976624, loss=1.6463501453399658
train: epoch 70, loss 0.9841583371162415, acc=0.5955555438995361, loss=0.9841583371162415
test: epoch 70, loss 1.548100471496582, acc=0.38333332538604736, loss=1.548100471496582
train: epoch 71, loss 0.9832708835601807, acc=0.6011666655540466, loss=0.9832708835601807
test: epoch 71, loss 1.7020938396453857, acc=0.3083333373069763, loss=1.7020938396453857
train: epoch 72, loss 0.9808706641197205, acc=0.6003333330154419, loss=0.9808706641197205
test: epoch 72, loss 1.5364129543304443, acc=0.31111112236976624, loss=1.5364129543304443
train: epoch 73, loss 0.963483989238739, acc=0.6090555787086487, loss=0.963483989238739
test: epoch 73, loss 1.5713335275650024, acc=0.39444443583488464, loss=1.5713335275650024
train: epoch 74, loss 0.9761773347854614, acc=0.6038333177566528, loss=0.9761773347854614
test: epoch 74, loss 1.554266095161438, acc=0.3611111044883728, loss=1.554266095161438
train: epoch 75, loss 0.9714481234550476, acc=0.5996111035346985, loss=0.9714481234550476
test: epoch 75, loss 1.6262890100479126, acc=0.3638888895511627, loss=1.6262890100479126
train: epoch 76, loss 0.9578444361686707, acc=0.6100000143051147, loss=0.9578444361686707
test: epoch 76, loss 1.5763039588928223, acc=0.3333333432674408, loss=1.5763039588928223
train: epoch 77, loss 0.9402676224708557, acc=0.6186666488647461, loss=0.9402676224708557
test: epoch 77, loss 1.5545812845230103, acc=0.3472222089767456, loss=1.5545812845230103
train: epoch 78, loss 0.9423532485961914, acc=0.617555558681488, loss=0.9423532485961914
test: epoch 78, loss 1.6339302062988281, acc=0.3222222328186035, loss=1.6339302062988281
train: epoch 79, loss 0.9371181726455688, acc=0.6190000176429749, loss=0.9371181726455688
test: epoch 79, loss 1.6416258811950684, acc=0.34166666865348816, loss=1.6416258811950684
train: epoch 80, loss 0.9349707961082458, acc=0.6184999942779541, loss=0.9349707961082458
test: epoch 80, loss 1.4603006839752197, acc=0.3888888955116272, loss=1.4603006839752197
train: epoch 81, loss 0.9439923167228699, acc=0.6194444298744202, loss=0.9439923167228699
test: epoch 81, loss 1.660871982574463, acc=0.3194444477558136, loss=1.660871982574463
train: epoch 82, loss 0.9293501377105713, acc=0.6190000176429749, loss=0.9293501377105713
test: epoch 82, loss 1.5541104078292847, acc=0.35555556416511536, loss=1.5541104078292847
train: epoch 83, loss 0.9231082201004028, acc=0.6271111369132996, loss=0.9231082201004028
test: epoch 83, loss 1.6100752353668213, acc=0.3444444537162781, loss=1.6100752353668213
train: epoch 84, loss 0.9204976558685303, acc=0.6313889026641846, loss=0.9204976558685303
test: epoch 84, loss 1.601354718208313, acc=0.3916666805744171, loss=1.601354718208313
train: epoch 85, loss 0.9191789627075195, acc=0.6271666884422302, loss=0.9191789627075195
test: epoch 85, loss 1.5147548913955688, acc=0.39722222089767456, loss=1.5147548913955688
train: epoch 86, loss 0.9097439646720886, acc=0.6344444155693054, loss=0.9097439646720886
test: epoch 86, loss 1.6553758382797241, acc=0.2611111104488373, loss=1.6553758382797241
train: epoch 87, loss 0.9022234082221985, acc=0.6383333206176758, loss=0.9022234082221985
test: epoch 87, loss 1.4299062490463257, acc=0.39722222089767456, loss=1.4299062490463257
train: epoch 88, loss 0.8951725363731384, acc=0.6382222175598145, loss=0.8951725363731384
test: epoch 88, loss 1.5511854887008667, acc=0.3638888895511627, loss=1.5511854887008667
train: epoch 89, loss 0.8941895365715027, acc=0.6359999775886536, loss=0.8941895365715027
test: epoch 89, loss 1.652663230895996, acc=0.3166666626930237, loss=1.652663230895996
train: epoch 90, loss 0.9027623534202576, acc=0.6377778053283691, loss=0.9027623534202576
test: epoch 90, loss 1.5963610410690308, acc=0.39722222089767456, loss=1.5963610410690308
train: epoch 91, loss 0.8926718831062317, acc=0.6389444470405579, loss=0.8926718831062317
test: epoch 91, loss 1.6400166749954224, acc=0.36944442987442017, loss=1.6400166749954224
train: epoch 92, loss 0.8746113777160645, acc=0.6478888988494873, loss=0.8746113777160645
test: epoch 92, loss 1.8829573392868042, acc=0.28333333134651184, loss=1.8829573392868042
train: epoch 93, loss 0.8813852071762085, acc=0.6443333625793457, loss=0.8813852071762085
test: epoch 93, loss 1.5222687721252441, acc=0.34166666865348816, loss=1.5222687721252441
train: epoch 94, loss 0.8719674348831177, acc=0.6462777853012085, loss=0.8719674348831177
test: epoch 94, loss 1.672684907913208, acc=0.36666667461395264, loss=1.672684907913208
train: epoch 95, loss 0.8649339079856873, acc=0.6525555849075317, loss=0.8649339079856873
test: epoch 95, loss 1.5742195844650269, acc=0.39444443583488464, loss=1.5742195844650269
train: epoch 96, loss 0.8706521391868591, acc=0.6532222032546997, loss=0.8706521391868591
test: epoch 96, loss 1.6512495279312134, acc=0.33888888359069824, loss=1.6512495279312134
train: epoch 97, loss 0.8623006939888, acc=0.6523333191871643, loss=0.8623006939888
test: epoch 97, loss 1.479763150215149, acc=0.33888888359069824, loss=1.479763150215149
train: epoch 98, loss 0.8547415137290955, acc=0.6576666831970215, loss=0.8547415137290955
test: epoch 98, loss 1.762704849243164, acc=0.3583333194255829, loss=1.762704849243164
train: epoch 99, loss 0.8592934012413025, acc=0.6582221984863281, loss=0.8592934012413025
test: epoch 99, loss 1.7562100887298584, acc=0.32499998807907104, loss=1.7562100887298584
train: epoch 100, loss 0.8496565222740173, acc=0.6588333249092102, loss=0.8496565222740173
test: epoch 100, loss 1.5316029787063599, acc=0.38055557012557983, loss=1.5316029787063599
train: epoch 101, loss 0.8328040838241577, acc=0.6648333072662354, loss=0.8328040838241577
test: epoch 101, loss 1.576850414276123, acc=0.3777777850627899, loss=1.576850414276123
train: epoch 102, loss 0.8506399989128113, acc=0.6558889150619507, loss=0.8506399989128113
test: epoch 102, loss 1.6211439371109009, acc=0.3638888895511627, loss=1.6211439371109009
train: epoch 103, loss 0.8351224064826965, acc=0.6629999876022339, loss=0.8351224064826965
test: epoch 103, loss 1.6807034015655518, acc=0.36666667461395264, loss=1.6807034015655518
train: epoch 104, loss 0.8441157937049866, acc=0.6603888869285583, loss=0.8441157937049866
test: epoch 104, loss 1.555930495262146, acc=0.38333332538604736, loss=1.555930495262146
train: epoch 105, loss 0.8291375637054443, acc=0.6665555834770203, loss=0.8291375637054443
test: epoch 105, loss 1.7301812171936035, acc=0.3472222089767456, loss=1.7301812171936035
train: epoch 106, loss 0.8316909670829773, acc=0.6641111373901367, loss=0.8316909670829773
test: epoch 106, loss 1.54693603515625, acc=0.375, loss=1.54693603515625
train: epoch 107, loss 0.8207951188087463, acc=0.6684444546699524, loss=0.8207951188087463
test: epoch 107, loss 1.4032444953918457, acc=0.36666667461395264, loss=1.4032444953918457
train: epoch 108, loss 0.8128007650375366, acc=0.675000011920929, loss=0.8128007650375366
test: epoch 108, loss 1.4941960573196411, acc=0.3222222328186035, loss=1.4941960573196411
train: epoch 109, loss 0.8158323168754578, acc=0.6731111407279968, loss=0.8158323168754578
test: epoch 109, loss 1.5740079879760742, acc=0.36666667461395264, loss=1.5740079879760742
train: epoch 110, loss 0.816686749458313, acc=0.6706110835075378, loss=0.816686749458313
test: epoch 110, loss 1.5560266971588135, acc=0.36666667461395264, loss=1.5560266971588135
train: epoch 111, loss 0.8049931526184082, acc=0.6740000247955322, loss=0.8049931526184082
test: epoch 111, loss 1.5858858823776245, acc=0.40833333134651184, loss=1.5858858823776245
train: epoch 112, loss 0.8102251887321472, acc=0.675777792930603, loss=0.8102251887321472
test: epoch 112, loss 1.4571235179901123, acc=0.35555556416511536, loss=1.4571235179901123
train: epoch 113, loss 0.8084714412689209, acc=0.679277777671814, loss=0.8084714412689209
test: epoch 113, loss 1.5134741067886353, acc=0.36666667461395264, loss=1.5134741067886353
train: epoch 114, loss 0.7967873811721802, acc=0.6783888936042786, loss=0.7967873811721802
test: epoch 114, loss 1.6066818237304688, acc=0.36944442987442017, loss=1.6066818237304688
train: epoch 115, loss 0.7966877222061157, acc=0.6826666593551636, loss=0.7966877222061157
test: epoch 115, loss 1.6067335605621338, acc=0.36666667461395264, loss=1.6067335605621338
train: epoch 116, loss 0.7931168079376221, acc=0.6801111102104187, loss=0.7931168079376221
test: epoch 116, loss 1.4999630451202393, acc=0.40833333134651184, loss=1.4999630451202393
train: epoch 117, loss 0.7894495725631714, acc=0.6834444403648376, loss=0.7894495725631714
test: epoch 117, loss 1.6282647848129272, acc=0.35277777910232544, loss=1.6282647848129272
train: epoch 118, loss 0.8012850880622864, acc=0.6811666488647461, loss=0.8012850880622864
test: epoch 118, loss 1.554632306098938, acc=0.3166666626930237, loss=1.554632306098938
train: epoch 119, loss 0.7828134894371033, acc=0.6865000128746033, loss=0.7828134894371033
test: epoch 119, loss 1.5327304601669312, acc=0.3638888895511627, loss=1.5327304601669312
train: epoch 120, loss 0.7819228172302246, acc=0.687166690826416, loss=0.7819228172302246
test: epoch 120, loss 1.5034499168395996, acc=0.43611112236976624, loss=1.5034499168395996
train: epoch 121, loss 0.7925340533256531, acc=0.6828888654708862, loss=0.7925340533256531
test: epoch 121, loss 1.4786356687545776, acc=0.4194444417953491, loss=1.4786356687545776
train: epoch 122, loss 0.7886495590209961, acc=0.6816666722297668, loss=0.7886495590209961
test: epoch 122, loss 1.661300539970398, acc=0.3888888955116272, loss=1.661300539970398
train: epoch 123, loss 0.7755025029182434, acc=0.6919999718666077, loss=0.7755025029182434
test: epoch 123, loss 1.560901403427124, acc=0.39722222089767456, loss=1.560901403427124
train: epoch 124, loss 0.7664151191711426, acc=0.695555567741394, loss=0.7664151191711426
test: epoch 124, loss 1.598206639289856, acc=0.375, loss=1.598206639289856
train: epoch 125, loss 0.7675551176071167, acc=0.6915000081062317, loss=0.7675551176071167
test: epoch 125, loss 1.698554515838623, acc=0.32777777314186096, loss=1.698554515838623
train: epoch 126, loss 0.7673819065093994, acc=0.691777765750885, loss=0.7673819065093994
test: epoch 126, loss 1.6054311990737915, acc=0.36944442987442017, loss=1.6054311990737915
train: epoch 127, loss 0.764862060546875, acc=0.6913889050483704, loss=0.764862060546875
test: epoch 127, loss 1.576080322265625, acc=0.3777777850627899, loss=1.576080322265625
train: epoch 128, loss 0.759152889251709, acc=0.6954444646835327, loss=0.759152889251709
test: epoch 128, loss 1.6689122915267944, acc=0.3611111044883728, loss=1.6689122915267944
train: epoch 129, loss 0.7615780234336853, acc=0.695277750492096, loss=0.7615780234336853
test: epoch 129, loss 1.6592859029769897, acc=0.3611111044883728, loss=1.6592859029769897
train: epoch 130, loss 0.7765049934387207, acc=0.6917222142219543, loss=0.7765049934387207
test: epoch 130, loss 1.5611612796783447, acc=0.3444444537162781, loss=1.5611612796783447
train: epoch 131, loss 0.7673494219779968, acc=0.6918888688087463, loss=0.7673494219779968
test: epoch 131, loss 1.4926432371139526, acc=0.39722222089767456, loss=1.4926432371139526
train: epoch 132, loss 0.7544532418251038, acc=0.7035555839538574, loss=0.7544532418251038
test: epoch 132, loss 1.6273345947265625, acc=0.3777777850627899, loss=1.6273345947265625
train: epoch 133, loss 0.7582585215568542, acc=0.6961110830307007, loss=0.7582585215568542
test: epoch 133, loss 1.40080988407135, acc=0.4027777910232544, loss=1.40080988407135
train: epoch 134, loss 0.7475124001502991, acc=0.7013888955116272, loss=0.7475124001502991
test: epoch 134, loss 1.6837615966796875, acc=0.39722222089767456, loss=1.6837615966796875
train: epoch 135, loss 0.7519729137420654, acc=0.6987777948379517, loss=0.7519729137420654
test: epoch 135, loss 1.5942579507827759, acc=0.375, loss=1.5942579507827759
train: epoch 136, loss 0.7580304145812988, acc=0.6991111040115356, loss=0.7580304145812988
test: epoch 136, loss 1.4301851987838745, acc=0.3305555582046509, loss=1.4301851987838745
train: epoch 137, loss 0.745864987373352, acc=0.699222207069397, loss=0.745864987373352
test: epoch 137, loss 1.6446585655212402, acc=0.3472222089767456, loss=1.6446585655212402
train: epoch 138, loss 0.7426127791404724, acc=0.7023888826370239, loss=0.7426127791404724
test: epoch 138, loss 1.4923828840255737, acc=0.39722222089767456, loss=1.4923828840255737
train: epoch 139, loss 0.7337355613708496, acc=0.7042222023010254, loss=0.7337355613708496
test: epoch 139, loss 1.8864821195602417, acc=0.2888889014720917, loss=1.8864821195602417
train: epoch 140, loss 0.7614292502403259, acc=0.6963333487510681, loss=0.7614292502403259
test: epoch 140, loss 1.5482240915298462, acc=0.36944442987442017, loss=1.5482240915298462
train: epoch 141, loss 0.7408500909805298, acc=0.7047777771949768, loss=0.7408500909805298
test: epoch 141, loss 1.7701632976531982, acc=0.32777777314186096, loss=1.7701632976531982
train: epoch 142, loss 0.7325130105018616, acc=0.7064444422721863, loss=0.7325130105018616
test: epoch 142, loss 1.4145607948303223, acc=0.4305555522441864, loss=1.4145607948303223
train: epoch 143, loss 0.7299931645393372, acc=0.7094444632530212, loss=0.7299931645393372
test: epoch 143, loss 1.4895210266113281, acc=0.39444443583488464, loss=1.4895210266113281
train: epoch 144, loss 0.7314088344573975, acc=0.7055555582046509, loss=0.7314088344573975
test: epoch 144, loss 1.5435857772827148, acc=0.34166666865348816, loss=1.5435857772827148
train: epoch 145, loss 0.742111086845398, acc=0.7068889141082764, loss=0.742111086845398
test: epoch 145, loss 1.5994212627410889, acc=0.4027777910232544, loss=1.5994212627410889
train: epoch 146, loss 0.7399170994758606, acc=0.7055555582046509, loss=0.7399170994758606
test: epoch 146, loss 1.7474677562713623, acc=0.33888888359069824, loss=1.7474677562713623
train: epoch 147, loss 0.7272425293922424, acc=0.711555540561676, loss=0.7272425293922424
test: epoch 147, loss 1.518072247505188, acc=0.2888889014720917, loss=1.518072247505188
train: epoch 148, loss 0.7263346314430237, acc=0.706944465637207, loss=0.7263346314430237
test: epoch 148, loss 1.7045749425888062, acc=0.3472222089767456, loss=1.7045749425888062
train: epoch 149, loss 0.7147919535636902, acc=0.7166110873222351, loss=0.7147919535636902
test: epoch 149, loss 1.6359918117523193, acc=0.41111111640930176, loss=1.6359918117523193
train: epoch 150, loss 0.7145933508872986, acc=0.7141110897064209, loss=0.7145933508872986
test: epoch 150, loss 1.5579493045806885, acc=0.3916666805744171, loss=1.5579493045806885
