# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=0.99", "--one_hot=1", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=1856856999, receiver_embed_dim=32, save_run=0, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1856856999, receiver_embed_dim=32, save_run=False, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.983522653579712, acc=0.10538888722658157, loss=2.983522653579712
test: epoch 1, loss 5.205227375030518, acc=0.09166666865348816, loss=5.205227375030518
train: epoch 2, loss 1.7786204814910889, acc=0.3237222135066986, loss=1.7786204814910889
test: epoch 2, loss 5.615677833557129, acc=0.09444444626569748, loss=5.615677833557129
train: epoch 3, loss 1.3521944284439087, acc=0.46194443106651306, loss=1.3521944284439087
test: epoch 3, loss 5.494266033172607, acc=0.125, loss=5.494266033172607
train: epoch 4, loss 1.1240947246551514, acc=0.551277756690979, loss=1.1240947246551514
test: epoch 4, loss 5.674875736236572, acc=0.13333334028720856, loss=5.674875736236572
train: epoch 5, loss 0.9866710305213928, acc=0.6003333330154419, loss=0.9866710305213928
test: epoch 5, loss 4.934780120849609, acc=0.1666666716337204, loss=4.934780120849609
train: epoch 6, loss 0.8602524399757385, acc=0.6583889126777649, loss=0.8602524399757385
test: epoch 6, loss 4.429812908172607, acc=0.15555556118488312, loss=4.429812908172607
train: epoch 7, loss 0.7708454132080078, acc=0.7055555582046509, loss=0.7708454132080078
test: epoch 7, loss 4.522068500518799, acc=0.21944443881511688, loss=4.522068500518799
train: epoch 8, loss 0.6869750618934631, acc=0.7429999709129333, loss=0.6869750618934631
test: epoch 8, loss 4.133117198944092, acc=0.21666666865348816, loss=4.133117198944092
train: epoch 9, loss 0.619796097278595, acc=0.7647222280502319, loss=0.619796097278595
test: epoch 9, loss 4.838646411895752, acc=0.18611110746860504, loss=4.838646411895752
train: epoch 10, loss 0.5734525322914124, acc=0.7817777991294861, loss=0.5734525322914124
test: epoch 10, loss 4.721893310546875, acc=0.2222222238779068, loss=4.721893310546875
train: epoch 11, loss 0.528577983379364, acc=0.8003888726234436, loss=0.528577983379364
test: epoch 11, loss 3.583574056625366, acc=0.27222222089767456, loss=3.583574056625366
train: epoch 12, loss 0.5035203695297241, acc=0.8152777552604675, loss=0.5035203695297241
test: epoch 12, loss 3.7936484813690186, acc=0.21944443881511688, loss=3.7936484813690186
train: epoch 13, loss 0.4642343819141388, acc=0.8310555815696716, loss=0.4642343819141388
test: epoch 13, loss 3.0539021492004395, acc=0.2916666567325592, loss=3.0539021492004395
train: epoch 14, loss 0.45484212040901184, acc=0.835277795791626, loss=0.45484212040901184
test: epoch 14, loss 3.3196609020233154, acc=0.2666666805744171, loss=3.3196609020233154
train: epoch 15, loss 0.43981191515922546, acc=0.843833327293396, loss=0.43981191515922546
test: epoch 15, loss 3.0646791458129883, acc=0.24722221493721008, loss=3.0646791458129883
train: epoch 16, loss 0.4265364408493042, acc=0.8454999923706055, loss=0.4265364408493042
test: epoch 16, loss 2.6514930725097656, acc=0.2888889014720917, loss=2.6514930725097656
train: epoch 17, loss 0.4042944610118866, acc=0.8523333072662354, loss=0.4042944610118866
test: epoch 17, loss 3.2656514644622803, acc=0.3083333373069763, loss=3.2656514644622803
train: epoch 18, loss 0.4011850655078888, acc=0.8621666431427002, loss=0.4011850655078888
test: epoch 18, loss 2.5286436080932617, acc=0.3027777671813965, loss=2.5286436080932617
train: epoch 19, loss 0.3814278542995453, acc=0.8650555610656738, loss=0.3814278542995453
test: epoch 19, loss 2.760817766189575, acc=0.2805555462837219, loss=2.760817766189575
train: epoch 20, loss 0.3752671778202057, acc=0.8703333139419556, loss=0.3752671778202057
test: epoch 20, loss 2.3461782932281494, acc=0.36944442987442017, loss=2.3461782932281494
train: epoch 21, loss 0.3652505576610565, acc=0.8707777857780457, loss=0.3652505576610565
test: epoch 21, loss 2.5604586601257324, acc=0.3361110985279083, loss=2.5604586601257324
train: epoch 22, loss 0.35465922951698303, acc=0.8801666498184204, loss=0.35465922951698303
test: epoch 22, loss 2.1170928478240967, acc=0.39722222089767456, loss=2.1170928478240967
train: epoch 23, loss 0.332955926656723, acc=0.8837222456932068, loss=0.332955926656723
test: epoch 23, loss 2.4132354259490967, acc=0.38055557012557983, loss=2.4132354259490967
train: epoch 24, loss 0.325340211391449, acc=0.890333354473114, loss=0.325340211391449
test: epoch 24, loss 1.9817081689834595, acc=0.4416666626930237, loss=1.9817081689834595
train: epoch 25, loss 0.3167845904827118, acc=0.8935555815696716, loss=0.3167845904827118
test: epoch 25, loss 2.288900375366211, acc=0.39722222089767456, loss=2.288900375366211
train: epoch 26, loss 0.31921815872192383, acc=0.890999972820282, loss=0.31921815872192383
test: epoch 26, loss 2.031392812728882, acc=0.4444444477558136, loss=2.031392812728882
train: epoch 27, loss 0.312339186668396, acc=0.8987777829170227, loss=0.312339186668396
test: epoch 27, loss 1.837709903717041, acc=0.36944442987442017, loss=1.837709903717041
train: epoch 28, loss 0.29069140553474426, acc=0.9045000076293945, loss=0.29069140553474426
test: epoch 28, loss 1.8850165605545044, acc=0.40833333134651184, loss=1.8850165605545044
train: epoch 29, loss 0.28668347001075745, acc=0.9041666388511658, loss=0.28668347001075745
test: epoch 29, loss 1.9872901439666748, acc=0.45277777314186096, loss=1.9872901439666748
train: epoch 30, loss 0.28575825691223145, acc=0.9023333191871643, loss=0.28575825691223145
test: epoch 30, loss 1.8911328315734863, acc=0.3916666805744171, loss=1.8911328315734863
train: epoch 31, loss 0.2724435031414032, acc=0.9112222194671631, loss=0.2724435031414032
test: epoch 31, loss 1.8638678789138794, acc=0.4583333432674408, loss=1.8638678789138794
train: epoch 32, loss 0.26409539580345154, acc=0.9123333096504211, loss=0.26409539580345154
test: epoch 32, loss 1.7668896913528442, acc=0.4416666626930237, loss=1.7668896913528442
train: epoch 33, loss 0.2522630989551544, acc=0.9176666736602783, loss=0.2522630989551544
test: epoch 33, loss 1.7054955959320068, acc=0.5166666507720947, loss=1.7054955959320068
train: epoch 34, loss 0.26600971817970276, acc=0.9155555367469788, loss=0.26600971817970276
test: epoch 34, loss 1.6994253396987915, acc=0.4305555522441864, loss=1.6994253396987915
train: epoch 35, loss 0.2603885531425476, acc=0.9148889183998108, loss=0.2603885531425476
test: epoch 35, loss 1.6323609352111816, acc=0.4472222328186035, loss=1.6323609352111816
train: epoch 36, loss 0.25577810406684875, acc=0.9168333411216736, loss=0.25577810406684875
test: epoch 36, loss 1.7942240238189697, acc=0.41111111640930176, loss=1.7942240238189697
train: epoch 37, loss 0.23754547536373138, acc=0.9225000143051147, loss=0.23754547536373138
test: epoch 37, loss 1.6055952310562134, acc=0.4444444477558136, loss=1.6055952310562134
train: epoch 38, loss 0.24865950644016266, acc=0.918055534362793, loss=0.24865950644016266
test: epoch 38, loss 1.5983422994613647, acc=0.36666667461395264, loss=1.5983422994613647
train: epoch 39, loss 0.23679275810718536, acc=0.9233333468437195, loss=0.23679275810718536
test: epoch 39, loss 1.679853916168213, acc=0.4472222328186035, loss=1.679853916168213
train: epoch 40, loss 0.24464677274227142, acc=0.9188888669013977, loss=0.24464677274227142
test: epoch 40, loss 1.560821533203125, acc=0.5222222208976746, loss=1.560821533203125
train: epoch 41, loss 0.24004119634628296, acc=0.9206666946411133, loss=0.24004119634628296
test: epoch 41, loss 1.8296129703521729, acc=0.4416666626930237, loss=1.8296129703521729
train: epoch 42, loss 0.2430872619152069, acc=0.9230555295944214, loss=0.2430872619152069
test: epoch 42, loss 1.6689180135726929, acc=0.4555555582046509, loss=1.6689180135726929
train: epoch 43, loss 0.2321993112564087, acc=0.9237222075462341, loss=0.2321993112564087
test: epoch 43, loss 1.8016388416290283, acc=0.5, loss=1.8016388416290283
train: epoch 44, loss 0.2178623378276825, acc=0.9296666383743286, loss=0.2178623378276825
test: epoch 44, loss 1.6234012842178345, acc=0.4749999940395355, loss=1.6234012842178345
train: epoch 45, loss 0.21816661953926086, acc=0.9311666488647461, loss=0.21816661953926086
test: epoch 45, loss 1.4977617263793945, acc=0.4749999940395355, loss=1.4977617263793945
train: epoch 46, loss 0.2310689389705658, acc=0.9261666536331177, loss=0.2310689389705658
test: epoch 46, loss 1.7939656972885132, acc=0.4555555582046509, loss=1.7939656972885132
train: epoch 47, loss 0.23183366656303406, acc=0.9282777905464172, loss=0.23183366656303406
test: epoch 47, loss 1.6926944255828857, acc=0.4194444417953491, loss=1.6926944255828857
train: epoch 48, loss 0.2248723804950714, acc=0.9286666512489319, loss=0.2248723804950714
test: epoch 48, loss 1.558882474899292, acc=0.5166666507720947, loss=1.558882474899292
train: epoch 49, loss 0.22108332812786102, acc=0.9316666722297668, loss=0.22108332812786102
test: epoch 49, loss 1.8472541570663452, acc=0.4416666626930237, loss=1.8472541570663452
train: epoch 50, loss 0.23535476624965668, acc=0.9267222285270691, loss=0.23535476624965668
test: epoch 50, loss 1.600642442703247, acc=0.4749999940395355, loss=1.600642442703247
train: epoch 51, loss 0.20770904421806335, acc=0.9334444403648376, loss=0.20770904421806335
test: epoch 51, loss 1.5559333562850952, acc=0.49444442987442017, loss=1.5559333562850952
train: epoch 52, loss 0.20014087855815887, acc=0.9388889074325562, loss=0.20014087855815887
test: epoch 52, loss 1.5014398097991943, acc=0.5555555820465088, loss=1.5014398097991943
train: epoch 53, loss 0.2207932323217392, acc=0.9315555691719055, loss=0.2207932323217392
test: epoch 53, loss 1.4781773090362549, acc=0.5388888716697693, loss=1.4781773090362549
train: epoch 54, loss 0.22451336681842804, acc=0.9284444451332092, loss=0.22451336681842804
test: epoch 54, loss 1.6467801332473755, acc=0.4694444537162781, loss=1.6467801332473755
train: epoch 55, loss 0.2062349170446396, acc=0.9358888864517212, loss=0.2062349170446396
test: epoch 55, loss 1.6278713941574097, acc=0.5055555701255798, loss=1.6278713941574097
train: epoch 56, loss 0.20496365427970886, acc=0.933222234249115, loss=0.20496365427970886
test: epoch 56, loss 1.4306014776229858, acc=0.5166666507720947, loss=1.4306014776229858
train: epoch 57, loss 0.1984623670578003, acc=0.937166690826416, loss=0.1984623670578003
test: epoch 57, loss 1.3754491806030273, acc=0.519444465637207, loss=1.3754491806030273
train: epoch 58, loss 0.2061438262462616, acc=0.9367222189903259, loss=0.2061438262462616
test: epoch 58, loss 1.2989282608032227, acc=0.5666666626930237, loss=1.2989282608032227
train: epoch 59, loss 0.2117157280445099, acc=0.9337777495384216, loss=0.2117157280445099
test: epoch 59, loss 1.1246498823165894, acc=0.5972222089767456, loss=1.1246498823165894
train: epoch 60, loss 0.20529110729694366, acc=0.9352777600288391, loss=0.20529110729694366
test: epoch 60, loss 1.2973471879959106, acc=0.5666666626930237, loss=1.2973471879959106
train: epoch 61, loss 0.21230560541152954, acc=0.9338333606719971, loss=0.21230560541152954
test: epoch 61, loss 1.311697244644165, acc=0.6027777791023254, loss=1.311697244644165
train: epoch 62, loss 0.1983078420162201, acc=0.9371111392974854, loss=0.1983078420162201
test: epoch 62, loss 1.1225697994232178, acc=0.625, loss=1.1225697994232178
train: epoch 63, loss 0.20136849582195282, acc=0.9336110949516296, loss=0.20136849582195282
test: epoch 63, loss 0.8929529786109924, acc=0.6694444417953491, loss=0.8929529786109924
train: epoch 64, loss 0.18391728401184082, acc=0.9411666393280029, loss=0.18391728401184082
test: epoch 64, loss 1.4075809717178345, acc=0.605555534362793, loss=1.4075809717178345
train: epoch 65, loss 0.19197213649749756, acc=0.9394444227218628, loss=0.19197213649749756
test: epoch 65, loss 1.0934556722640991, acc=0.6611111164093018, loss=1.0934556722640991
train: epoch 66, loss 0.18023978173732758, acc=0.945388913154602, loss=0.18023978173732758
test: epoch 66, loss 0.9518735408782959, acc=0.6222222447395325, loss=0.9518735408782959
train: epoch 67, loss 0.19042259454727173, acc=0.9387778043746948, loss=0.19042259454727173
test: epoch 67, loss 0.7727034091949463, acc=0.7055555582046509, loss=0.7727034091949463
train: epoch 68, loss 0.19535405933856964, acc=0.9383888840675354, loss=0.19535405933856964
test: epoch 68, loss 0.8517419099807739, acc=0.6972222328186035, loss=0.8517419099807739
train: epoch 69, loss 0.18048235774040222, acc=0.9417222142219543, loss=0.18048235774040222
test: epoch 69, loss 1.0354279279708862, acc=0.7111111283302307, loss=1.0354279279708862
train: epoch 70, loss 0.18694838881492615, acc=0.9402777552604675, loss=0.18694838881492615
test: epoch 70, loss 1.059979796409607, acc=0.6499999761581421, loss=1.059979796409607
train: epoch 71, loss 0.18883928656578064, acc=0.9396666884422302, loss=0.18883928656578064
test: epoch 71, loss 0.7173268795013428, acc=0.7277777791023254, loss=0.7173268795013428
train: epoch 72, loss 0.17217406630516052, acc=0.9467777609825134, loss=0.17217406630516052
test: epoch 72, loss 0.7567611932754517, acc=0.7416666746139526, loss=0.7567611932754517
train: epoch 73, loss 0.18778635561466217, acc=0.9394999742507935, loss=0.18778635561466217
test: epoch 73, loss 0.809312105178833, acc=0.7138888835906982, loss=0.809312105178833
train: epoch 74, loss 0.1819765418767929, acc=0.9423888921737671, loss=0.1819765418767929
test: epoch 74, loss 0.8795107007026672, acc=0.7749999761581421, loss=0.8795107007026672
train: epoch 75, loss 0.17884673178195953, acc=0.9449999928474426, loss=0.17884673178195953
test: epoch 75, loss 0.78902268409729, acc=0.730555534362793, loss=0.78902268409729
train: epoch 76, loss 0.16564325988292694, acc=0.9484444260597229, loss=0.16564325988292694
test: epoch 76, loss 0.5381418466567993, acc=0.7472222447395325, loss=0.5381418466567993
train: epoch 77, loss 0.17125922441482544, acc=0.9469444155693054, loss=0.17125922441482544
test: epoch 77, loss 0.7783660888671875, acc=0.7333333492279053, loss=0.7783660888671875
train: epoch 78, loss 0.18083323538303375, acc=0.9429444670677185, loss=0.18083323538303375
test: epoch 78, loss 0.7034595012664795, acc=0.75, loss=0.7034595012664795
train: epoch 79, loss 0.16878743469715118, acc=0.9461666941642761, loss=0.16878743469715118
test: epoch 79, loss 0.5783703327178955, acc=0.7888888716697693, loss=0.5783703327178955
train: epoch 80, loss 0.17169561982154846, acc=0.9459444284439087, loss=0.17169561982154846
test: epoch 80, loss 0.6450155973434448, acc=0.7944444417953491, loss=0.6450155973434448
train: epoch 81, loss 0.15352250635623932, acc=0.95333331823349, loss=0.15352250635623932
test: epoch 81, loss 0.4782526195049286, acc=0.824999988079071, loss=0.4782526195049286
train: epoch 82, loss 0.16274915635585785, acc=0.9493333101272583, loss=0.16274915635585785
test: epoch 82, loss 0.4740796387195587, acc=0.8388888835906982, loss=0.4740796387195587
train: epoch 83, loss 0.17158843576908112, acc=0.9462222456932068, loss=0.17158843576908112
test: epoch 83, loss 0.5117062926292419, acc=0.8472222089767456, loss=0.5117062926292419
train: epoch 84, loss 0.155201256275177, acc=0.9516666531562805, loss=0.155201256275177
test: epoch 84, loss 0.36553242802619934, acc=0.8527777791023254, loss=0.36553242802619934
train: epoch 85, loss 0.17104989290237427, acc=0.9463889002799988, loss=0.17104989290237427
test: epoch 85, loss 0.37420329451560974, acc=0.8472222089767456, loss=0.37420329451560974
train: epoch 86, loss 0.1463051736354828, acc=0.9541666507720947, loss=0.1463051736354828
test: epoch 86, loss 0.3291371464729309, acc=0.8444444537162781, loss=0.3291371464729309
train: epoch 87, loss 0.14425799250602722, acc=0.9547777771949768, loss=0.14425799250602722
test: epoch 87, loss 0.49119889736175537, acc=0.8194444179534912, loss=0.49119889736175537
train: epoch 88, loss 0.14382274448871613, acc=0.9558888673782349, loss=0.14382274448871613
test: epoch 88, loss 0.5315435528755188, acc=0.8611111044883728, loss=0.5315435528755188
train: epoch 89, loss 0.1346629559993744, acc=0.9588333368301392, loss=0.1346629559993744
test: epoch 89, loss 0.365280419588089, acc=0.875, loss=0.365280419588089
train: epoch 90, loss 0.13724952936172485, acc=0.9574999809265137, loss=0.13724952936172485
test: epoch 90, loss 0.35157060623168945, acc=0.8694444298744202, loss=0.35157060623168945
train: epoch 91, loss 0.15507091581821442, acc=0.9525555372238159, loss=0.15507091581821442
test: epoch 91, loss 0.45142650604248047, acc=0.8638888597488403, loss=0.45142650604248047
train: epoch 92, loss 0.13731025159358978, acc=0.9567221999168396, loss=0.13731025159358978
test: epoch 92, loss 0.3187679052352905, acc=0.8861111402511597, loss=0.3187679052352905
train: epoch 93, loss 0.13228817284107208, acc=0.9585000276565552, loss=0.13228817284107208
test: epoch 93, loss 0.3219105899333954, acc=0.8888888955116272, loss=0.3219105899333954
train: epoch 94, loss 0.1364724040031433, acc=0.9547777771949768, loss=0.1364724040031433
test: epoch 94, loss 0.4222949147224426, acc=0.8805555701255798, loss=0.4222949147224426
train: epoch 95, loss 0.1293415129184723, acc=0.9590555429458618, loss=0.1293415129184723
test: epoch 95, loss 0.3391364514827728, acc=0.8805555701255798, loss=0.3391364514827728
train: epoch 96, loss 0.137037992477417, acc=0.9577222466468811, loss=0.137037992477417
test: epoch 96, loss 0.3112868368625641, acc=0.8777777552604675, loss=0.3112868368625641
train: epoch 97, loss 0.12612676620483398, acc=0.9608888626098633, loss=0.12612676620483398
test: epoch 97, loss 0.2915922999382019, acc=0.8888888955116272, loss=0.2915922999382019
train: epoch 98, loss 0.13019676506519318, acc=0.9588888883590698, loss=0.13019676506519318
test: epoch 98, loss 0.3170732259750366, acc=0.8861111402511597, loss=0.3170732259750366
train: epoch 99, loss 0.12276273220777512, acc=0.9599999785423279, loss=0.12276273220777512
test: epoch 99, loss 0.35465681552886963, acc=0.8861111402511597, loss=0.35465681552886963
train: epoch 100, loss 0.11022095382213593, acc=0.9649999737739563, loss=0.11022095382213593
test: epoch 100, loss 0.3718929886817932, acc=0.8777777552604675, loss=0.3718929886817932
train: epoch 101, loss 0.10990164428949356, acc=0.964888870716095, loss=0.10990164428949356
test: epoch 101, loss 0.3343571126461029, acc=0.8916666507720947, loss=0.3343571126461029
train: epoch 102, loss 0.11486399173736572, acc=0.9608333110809326, loss=0.11486399173736572
test: epoch 102, loss 0.23746202886104584, acc=0.894444465637207, loss=0.23746202886104584
train: epoch 103, loss 0.1030898168683052, acc=0.9662222266197205, loss=0.1030898168683052
test: epoch 103, loss 0.2716745436191559, acc=0.8916666507720947, loss=0.2716745436191559
train: epoch 104, loss 0.11245806515216827, acc=0.9643333554267883, loss=0.11245806515216827
test: epoch 104, loss 0.2777368724346161, acc=0.894444465637207, loss=0.2777368724346161
train: epoch 105, loss 0.10638711601495743, acc=0.965666651725769, loss=0.10638711601495743
test: epoch 105, loss 0.2535955309867859, acc=0.9083333611488342, loss=0.2535955309867859
train: epoch 106, loss 0.115468330681324, acc=0.9624999761581421, loss=0.115468330681324
test: epoch 106, loss 0.28242799639701843, acc=0.8999999761581421, loss=0.28242799639701843
train: epoch 107, loss 0.1284642517566681, acc=0.9549999833106995, loss=0.1284642517566681
test: epoch 107, loss 0.2919822037220001, acc=0.894444465637207, loss=0.2919822037220001
train: epoch 108, loss 0.10340005159378052, acc=0.9667222499847412, loss=0.10340005159378052
test: epoch 108, loss 0.2856157720088959, acc=0.9055555462837219, loss=0.2856157720088959
train: epoch 109, loss 0.09196552634239197, acc=0.9712777733802795, loss=0.09196552634239197
test: epoch 109, loss 0.2924078702926636, acc=0.9027777910232544, loss=0.2924078702926636
train: epoch 110, loss 0.10519342869520187, acc=0.9661666750907898, loss=0.10519342869520187
test: epoch 110, loss 0.24319428205490112, acc=0.9138888716697693, loss=0.24319428205490112
train: epoch 111, loss 0.10236292332410812, acc=0.9666110873222351, loss=0.10236292332410812
test: epoch 111, loss 0.37617823481559753, acc=0.8972222208976746, loss=0.37617823481559753
train: epoch 112, loss 0.09532107412815094, acc=0.9682222008705139, loss=0.09532107412815094
test: epoch 112, loss 0.21835386753082275, acc=0.8916666507720947, loss=0.21835386753082275
train: epoch 113, loss 0.08883368223905563, acc=0.9726666808128357, loss=0.08883368223905563
test: epoch 113, loss 0.2566801905632019, acc=0.8916666507720947, loss=0.2566801905632019
train: epoch 114, loss 0.09968791157007217, acc=0.9676666855812073, loss=0.09968791157007217
test: epoch 114, loss 0.2361469268798828, acc=0.9277777671813965, loss=0.2361469268798828
train: epoch 115, loss 0.10404184460639954, acc=0.9684444665908813, loss=0.10404184460639954
test: epoch 115, loss 0.24025139212608337, acc=0.9194444417953491, loss=0.24025139212608337
train: epoch 116, loss 0.08095773309469223, acc=0.9736111164093018, loss=0.08095773309469223
test: epoch 116, loss 0.2289169430732727, acc=0.9222221970558167, loss=0.2289169430732727
train: epoch 117, loss 0.09281232208013535, acc=0.9710555672645569, loss=0.09281232208013535
test: epoch 117, loss 0.2970863878726959, acc=0.9166666865348816, loss=0.2970863878726959
train: epoch 118, loss 0.08529896289110184, acc=0.9732778072357178, loss=0.08529896289110184
test: epoch 118, loss 0.1773650050163269, acc=0.8999999761581421, loss=0.1773650050163269
train: epoch 119, loss 0.0981176570057869, acc=0.9660000205039978, loss=0.0981176570057869
test: epoch 119, loss 0.22332531213760376, acc=0.9277777671813965, loss=0.22332531213760376
train: epoch 120, loss 0.10258019715547562, acc=0.9678888916969299, loss=0.10258019715547562
test: epoch 120, loss 0.22254279255867004, acc=0.9194444417953491, loss=0.22254279255867004
train: epoch 121, loss 0.07917942851781845, acc=0.9758889079093933, loss=0.07917942851781845
test: epoch 121, loss 0.2246934324502945, acc=0.925000011920929, loss=0.2246934324502945
train: epoch 122, loss 0.07969370484352112, acc=0.9752777814865112, loss=0.07969370484352112
test: epoch 122, loss 0.32110342383384705, acc=0.894444465637207, loss=0.32110342383384705
train: epoch 123, loss 0.09465957432985306, acc=0.969944417476654, loss=0.09465957432985306
test: epoch 123, loss 0.23108695447444916, acc=0.925000011920929, loss=0.23108695447444916
train: epoch 124, loss 0.08499960601329803, acc=0.972777783870697, loss=0.08499960601329803
test: epoch 124, loss 0.20166008174419403, acc=0.925000011920929, loss=0.20166008174419403
train: epoch 125, loss 0.07757294923067093, acc=0.9757221937179565, loss=0.07757294923067093
test: epoch 125, loss 0.2520252764225006, acc=0.925000011920929, loss=0.2520252764225006
train: epoch 126, loss 0.0784703940153122, acc=0.9745000004768372, loss=0.0784703940153122
test: epoch 126, loss 0.2920375466346741, acc=0.925000011920929, loss=0.2920375466346741
train: epoch 127, loss 0.0809648409485817, acc=0.9743888974189758, loss=0.0809648409485817
test: epoch 127, loss 0.3169260621070862, acc=0.9138888716697693, loss=0.3169260621070862
train: epoch 128, loss 0.0839909017086029, acc=0.9714999794960022, loss=0.0839909017086029
test: epoch 128, loss 0.17923188209533691, acc=0.925000011920929, loss=0.17923188209533691
train: epoch 129, loss 0.07535117119550705, acc=0.9749444723129272, loss=0.07535117119550705
test: epoch 129, loss 0.1937517374753952, acc=0.925000011920929, loss=0.1937517374753952
train: epoch 130, loss 0.07681690901517868, acc=0.9746111035346985, loss=0.07681690901517868
test: epoch 130, loss 0.23276713490486145, acc=0.9277777671813965, loss=0.23276713490486145
train: epoch 131, loss 0.07743389159440994, acc=0.9743333458900452, loss=0.07743389159440994
test: epoch 131, loss 0.2520112693309784, acc=0.925000011920929, loss=0.2520112693309784
train: epoch 132, loss 0.0720982775092125, acc=0.9779444336891174, loss=0.0720982775092125
test: epoch 132, loss 0.22407443821430206, acc=0.925000011920929, loss=0.22407443821430206
train: epoch 133, loss 0.07985835522413254, acc=0.9719444513320923, loss=0.07985835522413254
test: epoch 133, loss 0.23823431134223938, acc=0.925000011920929, loss=0.23823431134223938
train: epoch 134, loss 0.07210321724414825, acc=0.9777777791023254, loss=0.07210321724414825
test: epoch 134, loss 0.22325173020362854, acc=0.9194444417953491, loss=0.22325173020362854
train: epoch 135, loss 0.06844008713960648, acc=0.9775000214576721, loss=0.06844008713960648
test: epoch 135, loss 0.19158311188220978, acc=0.925000011920929, loss=0.19158311188220978
train: epoch 136, loss 0.06871572136878967, acc=0.9780555367469788, loss=0.06871572136878967
test: epoch 136, loss 0.23351599276065826, acc=0.925000011920929, loss=0.23351599276065826
train: epoch 137, loss 0.07685831934213638, acc=0.9764444231987, loss=0.07685831934213638
test: epoch 137, loss 0.20951490104198456, acc=0.925000011920929, loss=0.20951490104198456
train: epoch 138, loss 0.06767812371253967, acc=0.9772777557373047, loss=0.06767812371253967
test: epoch 138, loss 0.2298918515443802, acc=0.925000011920929, loss=0.2298918515443802
train: epoch 139, loss 0.07361233979463577, acc=0.976722240447998, loss=0.07361233979463577
test: epoch 139, loss 0.23627175390720367, acc=0.925000011920929, loss=0.23627175390720367
train: epoch 140, loss 0.06835409253835678, acc=0.9771111011505127, loss=0.06835409253835678
test: epoch 140, loss 0.25411176681518555, acc=0.9166666865348816, loss=0.25411176681518555
train: epoch 141, loss 0.07487962394952774, acc=0.976722240447998, loss=0.07487962394952774
test: epoch 141, loss 0.23104993999004364, acc=0.925000011920929, loss=0.23104993999004364
train: epoch 142, loss 0.06957590579986572, acc=0.9758333563804626, loss=0.06957590579986572
test: epoch 142, loss 0.2651946246623993, acc=0.925000011920929, loss=0.2651946246623993
train: epoch 143, loss 0.06271889805793762, acc=0.9798333048820496, loss=0.06271889805793762
test: epoch 143, loss 0.2069820910692215, acc=0.925000011920929, loss=0.2069820910692215
train: epoch 144, loss 0.06822136044502258, acc=0.9773889183998108, loss=0.06822136044502258
test: epoch 144, loss 0.20315687358379364, acc=0.925000011920929, loss=0.20315687358379364
train: epoch 145, loss 0.07071058452129364, acc=0.9784444570541382, loss=0.07071058452129364
test: epoch 145, loss 0.19887065887451172, acc=0.925000011920929, loss=0.19887065887451172
train: epoch 146, loss 0.06366654485464096, acc=0.9782778024673462, loss=0.06366654485464096
test: epoch 146, loss 0.24719297885894775, acc=0.925000011920929, loss=0.24719297885894775
train: epoch 147, loss 0.0721774771809578, acc=0.9775555729866028, loss=0.0721774771809578
test: epoch 147, loss 0.22708207368850708, acc=0.925000011920929, loss=0.22708207368850708
train: epoch 148, loss 0.06397414207458496, acc=0.9806110858917236, loss=0.06397414207458496
test: epoch 148, loss 0.2915216386318207, acc=0.9166666865348816, loss=0.2915216386318207
train: epoch 149, loss 0.07215941697359085, acc=0.9764444231987, loss=0.07215941697359085
test: epoch 149, loss 0.2662312388420105, acc=0.9222221970558167, loss=0.2662312388420105
train: epoch 150, loss 0.06104190647602081, acc=0.9791111350059509, loss=0.06104190647602081
test: epoch 150, loss 0.24177008867263794, acc=0.925000011920929, loss=0.24177008867263794
