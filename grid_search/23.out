# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=1.5", "--temp_decay=1", "--one_hot=1", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=169802802, receiver_embed_dim=32, save_run=0, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=169802802, receiver_embed_dim=32, save_run=False, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.1302261352539062, acc=0.0698888897895813, loss=3.1302261352539062
test: epoch 1, loss 3.3862364292144775, acc=0.0972222238779068, loss=3.3862364292144775
train: epoch 2, loss 2.191378355026245, acc=0.1926666647195816, loss=2.191378355026245
test: epoch 2, loss 3.71743106842041, acc=0.11666666716337204, loss=3.71743106842041
train: epoch 3, loss 1.8595393896102905, acc=0.25555557012557983, loss=1.8595393896102905
test: epoch 3, loss 3.0310444831848145, acc=0.1388888955116272, loss=3.0310444831848145
train: epoch 4, loss 1.6769015789031982, acc=0.30683332681655884, loss=1.6769015789031982
test: epoch 4, loss 3.457200765609741, acc=0.12777778506278992, loss=3.457200765609741
train: epoch 5, loss 1.5496058464050293, acc=0.34005555510520935, loss=1.5496058464050293
test: epoch 5, loss 3.227463960647583, acc=0.17499999701976776, loss=3.227463960647583
train: epoch 6, loss 1.4246172904968262, acc=0.3773333430290222, loss=1.4246172904968262
test: epoch 6, loss 3.1359663009643555, acc=0.15555556118488312, loss=3.1359663009643555
train: epoch 7, loss 1.3387352228164673, acc=0.40888887643814087, loss=1.3387352228164673
test: epoch 7, loss 2.7241525650024414, acc=0.24166665971279144, loss=2.7241525650024414
train: epoch 8, loss 1.2571625709533691, acc=0.4499444365501404, loss=1.2571625709533691
test: epoch 8, loss 3.1540677547454834, acc=0.15833333134651184, loss=3.1540677547454834
train: epoch 9, loss 1.1660029888153076, acc=0.5064444541931152, loss=1.1660029888153076
test: epoch 9, loss 3.110271692276001, acc=0.2611111104488373, loss=3.110271692276001
train: epoch 10, loss 0.9599353671073914, acc=0.605222225189209, loss=0.9599353671073914
test: epoch 10, loss 2.5230371952056885, acc=0.2750000059604645, loss=2.5230371952056885
train: epoch 11, loss 0.82073974609375, acc=0.6583889126777649, loss=0.82073974609375
test: epoch 11, loss 2.5660784244537354, acc=0.2638888955116272, loss=2.5660784244537354
train: epoch 12, loss 0.7331934571266174, acc=0.6967777609825134, loss=0.7331934571266174
test: epoch 12, loss 2.819119691848755, acc=0.23055554926395416, loss=2.819119691848755
train: epoch 13, loss 0.6662445068359375, acc=0.7218888998031616, loss=0.6662445068359375
test: epoch 13, loss 2.5453555583953857, acc=0.2777777910232544, loss=2.5453555583953857
train: epoch 14, loss 0.6351748108863831, acc=0.734499990940094, loss=0.6351748108863831
test: epoch 14, loss 2.178396701812744, acc=0.2944444417953491, loss=2.178396701812744
train: epoch 15, loss 0.5898022055625916, acc=0.7534444332122803, loss=0.5898022055625916
test: epoch 15, loss 2.5906982421875, acc=0.2944444417953491, loss=2.5906982421875
train: epoch 16, loss 0.5541703701019287, acc=0.7650555372238159, loss=0.5541703701019287
test: epoch 16, loss 2.1305155754089355, acc=0.2916666567325592, loss=2.1305155754089355
train: epoch 17, loss 0.5509623885154724, acc=0.7735555768013, loss=0.5509623885154724
test: epoch 17, loss 2.1264452934265137, acc=0.35277777910232544, loss=2.1264452934265137
train: epoch 18, loss 0.5191879272460938, acc=0.7848333120346069, loss=0.5191879272460938
test: epoch 18, loss 2.2673916816711426, acc=0.3444444537162781, loss=2.2673916816711426
train: epoch 19, loss 0.5156622529029846, acc=0.7940000295639038, loss=0.5156622529029846
test: epoch 19, loss 1.9262332916259766, acc=0.32777777314186096, loss=1.9262332916259766
train: epoch 20, loss 0.46668457984924316, acc=0.8157222270965576, loss=0.46668457984924316
test: epoch 20, loss 2.40993595123291, acc=0.32499998807907104, loss=2.40993595123291
train: epoch 21, loss 0.4485768675804138, acc=0.8201666474342346, loss=0.4485768675804138
test: epoch 21, loss 1.9995445013046265, acc=0.39444443583488464, loss=1.9995445013046265
train: epoch 22, loss 0.4214370548725128, acc=0.8247777819633484, loss=0.4214370548725128
test: epoch 22, loss 2.450096607208252, acc=0.34166666865348816, loss=2.450096607208252
train: epoch 23, loss 0.38943377137184143, acc=0.8391666412353516, loss=0.38943377137184143
test: epoch 23, loss 2.1400041580200195, acc=0.3888888955116272, loss=2.1400041580200195
train: epoch 24, loss 0.39241430163383484, acc=0.8374999761581421, loss=0.39241430163383484
test: epoch 24, loss 1.8253332376480103, acc=0.4027777910232544, loss=1.8253332376480103
train: epoch 25, loss 0.3796374499797821, acc=0.8432777523994446, loss=0.3796374499797821
test: epoch 25, loss 1.8171782493591309, acc=0.4000000059604645, loss=1.8171782493591309
train: epoch 26, loss 0.356520414352417, acc=0.8521666526794434, loss=0.356520414352417
test: epoch 26, loss 1.7927756309509277, acc=0.3916666805744171, loss=1.7927756309509277
train: epoch 27, loss 0.34216514229774475, acc=0.8554444313049316, loss=0.34216514229774475
test: epoch 27, loss 1.7972065210342407, acc=0.41111111640930176, loss=1.7972065210342407
train: epoch 28, loss 0.3278682231903076, acc=0.8614444732666016, loss=0.3278682231903076
test: epoch 28, loss 1.6527894735336304, acc=0.43611112236976624, loss=1.6527894735336304
train: epoch 29, loss 0.3248431384563446, acc=0.8617222309112549, loss=0.3248431384563446
test: epoch 29, loss 2.227815866470337, acc=0.4000000059604645, loss=2.227815866470337
train: epoch 30, loss 0.3295651972293854, acc=0.8626111149787903, loss=0.3295651972293854
test: epoch 30, loss 1.5828474760055542, acc=0.43611112236976624, loss=1.5828474760055542
train: epoch 31, loss 0.3192942142486572, acc=0.867111086845398, loss=0.3192942142486572
test: epoch 31, loss 1.7462105751037598, acc=0.40833333134651184, loss=1.7462105751037598
train: epoch 32, loss 0.2984902560710907, acc=0.8726111054420471, loss=0.2984902560710907
test: epoch 32, loss 1.5876127481460571, acc=0.3916666805744171, loss=1.5876127481460571
train: epoch 33, loss 0.28927406668663025, acc=0.8766666650772095, loss=0.28927406668663025
test: epoch 33, loss 1.668555736541748, acc=0.46388888359069824, loss=1.668555736541748
train: epoch 34, loss 0.29671576619148254, acc=0.8741111159324646, loss=0.29671576619148254
test: epoch 34, loss 1.6378405094146729, acc=0.4000000059604645, loss=1.6378405094146729
train: epoch 35, loss 0.28549155592918396, acc=0.8777777552604675, loss=0.28549155592918396
test: epoch 35, loss 1.6834837198257446, acc=0.46666666865348816, loss=1.6834837198257446
train: epoch 36, loss 0.2886408567428589, acc=0.8774444460868835, loss=0.2886408567428589
test: epoch 36, loss 1.5741645097732544, acc=0.46666666865348816, loss=1.5741645097732544
train: epoch 37, loss 0.26772165298461914, acc=0.882777750492096, loss=0.26772165298461914
test: epoch 37, loss 1.8021368980407715, acc=0.46388888359069824, loss=1.8021368980407715
train: epoch 38, loss 0.284988671541214, acc=0.878777801990509, loss=0.284988671541214
test: epoch 38, loss 1.7318499088287354, acc=0.4583333432674408, loss=1.7318499088287354
train: epoch 39, loss 0.2652379870414734, acc=0.8850555419921875, loss=0.2652379870414734
test: epoch 39, loss 1.7055574655532837, acc=0.43888887763023376, loss=1.7055574655532837
train: epoch 40, loss 0.26177728176116943, acc=0.8868333101272583, loss=0.26177728176116943
test: epoch 40, loss 2.275388240814209, acc=0.40833333134651184, loss=2.275388240814209
train: epoch 41, loss 0.2691291868686676, acc=0.886888861656189, loss=0.2691291868686676
test: epoch 41, loss 1.7682695388793945, acc=0.46388888359069824, loss=1.7682695388793945
train: epoch 42, loss 0.22999177873134613, acc=0.897777795791626, loss=0.22999177873134613
test: epoch 42, loss 1.7341176271438599, acc=0.4611110985279083, loss=1.7341176271438599
train: epoch 43, loss 0.2487199455499649, acc=0.8914444446563721, loss=0.2487199455499649
test: epoch 43, loss 1.9004753828048706, acc=0.4749999940395355, loss=1.9004753828048706
train: epoch 44, loss 0.24332217872142792, acc=0.8897222280502319, loss=0.24332217872142792
test: epoch 44, loss 1.841033935546875, acc=0.38333332538604736, loss=1.841033935546875
train: epoch 45, loss 0.22789567708969116, acc=0.897777795791626, loss=0.22789567708969116
test: epoch 45, loss 1.5997740030288696, acc=0.4888888895511627, loss=1.5997740030288696
train: epoch 46, loss 0.24308207631111145, acc=0.8919444680213928, loss=0.24308207631111145
test: epoch 46, loss 1.7713121175765991, acc=0.46666666865348816, loss=1.7713121175765991
train: epoch 47, loss 0.23415468633174896, acc=0.8991110920906067, loss=0.23415468633174896
test: epoch 47, loss 1.8792213201522827, acc=0.47777777910232544, loss=1.8792213201522827
train: epoch 48, loss 0.2331085205078125, acc=0.8943889141082764, loss=0.2331085205078125
test: epoch 48, loss 1.7142751216888428, acc=0.5472221970558167, loss=1.7142751216888428
train: epoch 49, loss 0.22199560701847076, acc=0.9012222290039062, loss=0.22199560701847076
test: epoch 49, loss 1.7527971267700195, acc=0.5027777552604675, loss=1.7527971267700195
train: epoch 50, loss 0.22868382930755615, acc=0.8991110920906067, loss=0.22868382930755615
test: epoch 50, loss 1.4614081382751465, acc=0.5333333611488342, loss=1.4614081382751465
train: epoch 51, loss 0.21512697637081146, acc=0.9023333191871643, loss=0.21512697637081146
test: epoch 51, loss 1.6420844793319702, acc=0.5666666626930237, loss=1.6420844793319702
train: epoch 52, loss 0.2128589153289795, acc=0.9051666855812073, loss=0.2128589153289795
test: epoch 52, loss 1.8775492906570435, acc=0.4472222328186035, loss=1.8775492906570435
train: epoch 53, loss 0.2173173427581787, acc=0.9048888683319092, loss=0.2173173427581787
test: epoch 53, loss 1.3856086730957031, acc=0.5527777671813965, loss=1.3856086730957031
train: epoch 54, loss 0.2089051753282547, acc=0.9067222476005554, loss=0.2089051753282547
test: epoch 54, loss 1.9364241361618042, acc=0.4027777910232544, loss=1.9364241361618042
train: epoch 55, loss 0.2066386640071869, acc=0.9049999713897705, loss=0.2066386640071869
test: epoch 55, loss 1.573848009109497, acc=0.48055556416511536, loss=1.573848009109497
train: epoch 56, loss 0.2082902193069458, acc=0.9082777500152588, loss=0.2082902193069458
test: epoch 56, loss 1.549760103225708, acc=0.5111111402511597, loss=1.549760103225708
train: epoch 57, loss 0.194454625248909, acc=0.9125000238418579, loss=0.194454625248909
test: epoch 57, loss 1.5151764154434204, acc=0.5138888955116272, loss=1.5151764154434204
train: epoch 58, loss 0.21579411625862122, acc=0.906166672706604, loss=0.21579411625862122
test: epoch 58, loss 1.63983154296875, acc=0.4833333194255829, loss=1.63983154296875
train: epoch 59, loss 0.1911909580230713, acc=0.9108889102935791, loss=0.1911909580230713
test: epoch 59, loss 2.0145297050476074, acc=0.44999998807907104, loss=2.0145297050476074
train: epoch 60, loss 0.1941472738981247, acc=0.9118888974189758, loss=0.1941472738981247
test: epoch 60, loss 1.4149904251098633, acc=0.5305555462837219, loss=1.4149904251098633
train: epoch 61, loss 0.20631329715251923, acc=0.9076666831970215, loss=0.20631329715251923
test: epoch 61, loss 1.777105450630188, acc=0.4861111044883728, loss=1.777105450630188
train: epoch 62, loss 0.2002907246351242, acc=0.9115555286407471, loss=0.2002907246351242
test: epoch 62, loss 1.357114553451538, acc=0.550000011920929, loss=1.357114553451538
train: epoch 63, loss 0.19225753843784332, acc=0.9127222299575806, loss=0.19225753843784332
test: epoch 63, loss 1.7558456659317017, acc=0.5305555462837219, loss=1.7558456659317017
train: epoch 64, loss 0.18439657986164093, acc=0.9164999723434448, loss=0.18439657986164093
test: epoch 64, loss 1.725180745124817, acc=0.47777777910232544, loss=1.725180745124817
train: epoch 65, loss 0.17633087933063507, acc=0.9178333282470703, loss=0.17633087933063507
test: epoch 65, loss 1.677791714668274, acc=0.49166667461395264, loss=1.677791714668274
train: epoch 66, loss 0.18957273662090302, acc=0.9135000109672546, loss=0.18957273662090302
test: epoch 66, loss 1.7270985841751099, acc=0.46666666865348816, loss=1.7270985841751099
train: epoch 67, loss 0.17677471041679382, acc=0.9190555810928345, loss=0.17677471041679382
test: epoch 67, loss 1.0738524198532104, acc=0.5555555820465088, loss=1.0738524198532104
train: epoch 68, loss 0.17996825277805328, acc=0.917555570602417, loss=0.17996825277805328
test: epoch 68, loss 1.805233120918274, acc=0.5277777910232544, loss=1.805233120918274
train: epoch 69, loss 0.1827203780412674, acc=0.9159444570541382, loss=0.1827203780412674
test: epoch 69, loss 1.9189687967300415, acc=0.550000011920929, loss=1.9189687967300415
train: epoch 70, loss 0.17854546010494232, acc=0.917722225189209, loss=0.17854546010494232
test: epoch 70, loss 1.794114589691162, acc=0.4861111044883728, loss=1.794114589691162
train: epoch 71, loss 0.17337271571159363, acc=0.9215555787086487, loss=0.17337271571159363
test: epoch 71, loss 1.521370530128479, acc=0.5222222208976746, loss=1.521370530128479
train: epoch 72, loss 0.16677019000053406, acc=0.9224444627761841, loss=0.16677019000053406
test: epoch 72, loss 1.519906997680664, acc=0.5472221970558167, loss=1.519906997680664
train: epoch 73, loss 0.1748863309621811, acc=0.9187222123146057, loss=0.1748863309621811
test: epoch 73, loss 1.6627658605575562, acc=0.5138888955116272, loss=1.6627658605575562
train: epoch 74, loss 0.16580171883106232, acc=0.9213333129882812, loss=0.16580171883106232
test: epoch 74, loss 1.6114299297332764, acc=0.5416666865348816, loss=1.6114299297332764
train: epoch 75, loss 0.16288262605667114, acc=0.9233333468437195, loss=0.16288262605667114
test: epoch 75, loss 1.4556711912155151, acc=0.5444444417953491, loss=1.4556711912155151
train: epoch 76, loss 0.15706364810466766, acc=0.9256666898727417, loss=0.15706364810466766
test: epoch 76, loss 1.606441617012024, acc=0.49166667461395264, loss=1.606441617012024
train: epoch 77, loss 0.1600700467824936, acc=0.9268888831138611, loss=0.1600700467824936
test: epoch 77, loss 1.4612300395965576, acc=0.5416666865348816, loss=1.4612300395965576
train: epoch 78, loss 0.14952847361564636, acc=0.9278888702392578, loss=0.14952847361564636
test: epoch 78, loss 1.634268879890442, acc=0.550000011920929, loss=1.634268879890442
train: epoch 79, loss 0.17217297852039337, acc=0.9220555424690247, loss=0.17217297852039337
test: epoch 79, loss 1.3012733459472656, acc=0.5083333253860474, loss=1.3012733459472656
train: epoch 80, loss 0.1460282802581787, acc=0.9300000071525574, loss=0.1460282802581787
test: epoch 80, loss 1.3587688207626343, acc=0.5861111283302307, loss=1.3587688207626343
train: epoch 81, loss 0.15762893855571747, acc=0.9273333549499512, loss=0.15762893855571747
test: epoch 81, loss 1.5068660974502563, acc=0.5249999761581421, loss=1.5068660974502563
train: epoch 82, loss 0.15298409759998322, acc=0.9284444451332092, loss=0.15298409759998322
test: epoch 82, loss 1.3208991289138794, acc=0.5166666507720947, loss=1.3208991289138794
train: epoch 83, loss 0.1503586620092392, acc=0.9269444346427917, loss=0.1503586620092392
test: epoch 83, loss 1.562259316444397, acc=0.46388888359069824, loss=1.562259316444397
train: epoch 84, loss 0.1489286571741104, acc=0.9305555820465088, loss=0.1489286571741104
test: epoch 84, loss 1.1508774757385254, acc=0.5861111283302307, loss=1.1508774757385254
train: epoch 85, loss 0.15723586082458496, acc=0.9276666641235352, loss=0.15723586082458496
test: epoch 85, loss 1.4263811111450195, acc=0.5222222208976746, loss=1.4263811111450195
train: epoch 86, loss 0.15219388902187347, acc=0.9293333292007446, loss=0.15219388902187347
test: epoch 86, loss 1.4613103866577148, acc=0.5777778029441833, loss=1.4613103866577148
train: epoch 87, loss 0.14625585079193115, acc=0.9305555820465088, loss=0.14625585079193115
test: epoch 87, loss 1.7477439641952515, acc=0.550000011920929, loss=1.7477439641952515
train: epoch 88, loss 0.14129719138145447, acc=0.9319999814033508, loss=0.14129719138145447
test: epoch 88, loss 1.1225078105926514, acc=0.5333333611488342, loss=1.1225078105926514
train: epoch 89, loss 0.14534328877925873, acc=0.9305555820465088, loss=0.14534328877925873
test: epoch 89, loss 1.2447450160980225, acc=0.5916666388511658, loss=1.2447450160980225
train: epoch 90, loss 0.15846844017505646, acc=0.9296666383743286, loss=0.15846844017505646
test: epoch 90, loss 1.4863207340240479, acc=0.5527777671813965, loss=1.4863207340240479
train: epoch 91, loss 0.1426178216934204, acc=0.9316111207008362, loss=0.1426178216934204
test: epoch 91, loss 1.329858422279358, acc=0.5888888835906982, loss=1.329858422279358
train: epoch 92, loss 0.1429940164089203, acc=0.9320555329322815, loss=0.1429940164089203
test: epoch 92, loss 1.3162201642990112, acc=0.5416666865348816, loss=1.3162201642990112
train: epoch 93, loss 0.13334640860557556, acc=0.9356111288070679, loss=0.13334640860557556
test: epoch 93, loss 1.2758479118347168, acc=0.6583333611488342, loss=1.2758479118347168
train: epoch 94, loss 0.139883354306221, acc=0.9326111078262329, loss=0.139883354306221
test: epoch 94, loss 1.6024329662322998, acc=0.5555555820465088, loss=1.6024329662322998
train: epoch 95, loss 0.13479125499725342, acc=0.9327222108840942, loss=0.13479125499725342
test: epoch 95, loss 1.3428493738174438, acc=0.5777778029441833, loss=1.3428493738174438
train: epoch 96, loss 0.14371666312217712, acc=0.9329444169998169, loss=0.14371666312217712
test: epoch 96, loss 1.3002643585205078, acc=0.605555534362793, loss=1.3002643585205078
train: epoch 97, loss 0.14351370930671692, acc=0.9328888654708862, loss=0.14351370930671692
test: epoch 97, loss 1.1853525638580322, acc=0.5916666388511658, loss=1.1853525638580322
train: epoch 98, loss 0.12673576176166534, acc=0.9368333220481873, loss=0.12673576176166534
test: epoch 98, loss 1.34574294090271, acc=0.574999988079071, loss=1.34574294090271
train: epoch 99, loss 0.1371728479862213, acc=0.9324444532394409, loss=0.1371728479862213
test: epoch 99, loss 1.2364397048950195, acc=0.5722222328186035, loss=1.2364397048950195
train: epoch 100, loss 0.12969659268856049, acc=0.9365555644035339, loss=0.12969659268856049
test: epoch 100, loss 1.3304879665374756, acc=0.6111111044883728, loss=1.3304879665374756
train: epoch 101, loss 0.14501738548278809, acc=0.9308888912200928, loss=0.14501738548278809
test: epoch 101, loss 1.3341381549835205, acc=0.6138888597488403, loss=1.3341381549835205
train: epoch 102, loss 0.13392524421215057, acc=0.9349444508552551, loss=0.13392524421215057
test: epoch 102, loss 1.5508314371109009, acc=0.5222222208976746, loss=1.5508314371109009
train: epoch 103, loss 0.12556242942810059, acc=0.9384444355964661, loss=0.12556242942810059
test: epoch 103, loss 1.4134947061538696, acc=0.6111111044883728, loss=1.4134947061538696
train: epoch 104, loss 0.1305951178073883, acc=0.9351111054420471, loss=0.1305951178073883
test: epoch 104, loss 1.5498013496398926, acc=0.5944444537162781, loss=1.5498013496398926
train: epoch 105, loss 0.12426131963729858, acc=0.9388333559036255, loss=0.12426131963729858
test: epoch 105, loss 1.2694646120071411, acc=0.6416666507720947, loss=1.2694646120071411
train: epoch 106, loss 0.12952186167240143, acc=0.9381111264228821, loss=0.12952186167240143
test: epoch 106, loss 1.2964730262756348, acc=0.6111111044883728, loss=1.2964730262756348
train: epoch 107, loss 0.1273638755083084, acc=0.9368888735771179, loss=0.1273638755083084
test: epoch 107, loss 1.189994215965271, acc=0.6222222447395325, loss=1.189994215965271
train: epoch 108, loss 0.13346827030181885, acc=0.9336110949516296, loss=0.13346827030181885
test: epoch 108, loss 0.9211880564689636, acc=0.6416666507720947, loss=0.9211880564689636
train: epoch 109, loss 0.13381968438625336, acc=0.9366666674613953, loss=0.13381968438625336
test: epoch 109, loss 1.2892578840255737, acc=0.6527777910232544, loss=1.2892578840255737
train: epoch 110, loss 0.13114146888256073, acc=0.9367777705192566, loss=0.13114146888256073
test: epoch 110, loss 1.1406595706939697, acc=0.6111111044883728, loss=1.1406595706939697
train: epoch 111, loss 0.12453535199165344, acc=0.9383888840675354, loss=0.12453535199165344
test: epoch 111, loss 0.901799738407135, acc=0.625, loss=0.901799738407135
train: epoch 112, loss 0.12923750281333923, acc=0.9379444718360901, loss=0.12923750281333923
test: epoch 112, loss 1.1649723052978516, acc=0.6333333253860474, loss=1.1649723052978516
train: epoch 113, loss 0.10923692584037781, acc=0.9426666498184204, loss=0.10923692584037781
test: epoch 113, loss 0.984100341796875, acc=0.6944444179534912, loss=0.984100341796875
train: epoch 114, loss 0.12239979952573776, acc=0.9392777681350708, loss=0.12239979952573776
test: epoch 114, loss 1.0682339668273926, acc=0.6583333611488342, loss=1.0682339668273926
train: epoch 115, loss 0.1328485757112503, acc=0.9360555410385132, loss=0.1328485757112503
test: epoch 115, loss 0.8989646434783936, acc=0.6611111164093018, loss=0.8989646434783936
train: epoch 116, loss 0.11836996674537659, acc=0.9372777938842773, loss=0.11836996674537659
test: epoch 116, loss 1.3209446668624878, acc=0.6722221970558167, loss=1.3209446668624878
train: epoch 117, loss 0.11691528558731079, acc=0.9403889179229736, loss=0.11691528558731079
test: epoch 117, loss 1.3679815530776978, acc=0.6722221970558167, loss=1.3679815530776978
train: epoch 118, loss 0.11578796058893204, acc=0.941777765750885, loss=0.11578796058893204
test: epoch 118, loss 1.2871373891830444, acc=0.6777777671813965, loss=1.2871373891830444
train: epoch 119, loss 0.11762171238660812, acc=0.9402777552604675, loss=0.11762171238660812
test: epoch 119, loss 0.9856318235397339, acc=0.699999988079071, loss=0.9856318235397339
train: epoch 120, loss 0.1195431798696518, acc=0.940666675567627, loss=0.1195431798696518
test: epoch 120, loss 0.7706999778747559, acc=0.6833333373069763, loss=0.7706999778747559
train: epoch 121, loss 0.10975267738103867, acc=0.9445555806159973, loss=0.10975267738103867
test: epoch 121, loss 1.0490643978118896, acc=0.6416666507720947, loss=1.0490643978118896
train: epoch 122, loss 0.12448853254318237, acc=0.9402777552604675, loss=0.12448853254318237
test: epoch 122, loss 1.1688798666000366, acc=0.5944444537162781, loss=1.1688798666000366
train: epoch 123, loss 0.11601193994283676, acc=0.9418888688087463, loss=0.11601193994283676
test: epoch 123, loss 1.5043820142745972, acc=0.6499999761581421, loss=1.5043820142745972
train: epoch 124, loss 0.12817317247390747, acc=0.9384999871253967, loss=0.12817317247390747
test: epoch 124, loss 1.0808618068695068, acc=0.7055555582046509, loss=1.0808618068695068
train: epoch 125, loss 0.11565545946359634, acc=0.9421111345291138, loss=0.11565545946359634
test: epoch 125, loss 1.3248132467269897, acc=0.6194444298744202, loss=1.3248132467269897
train: epoch 126, loss 0.11117739975452423, acc=0.9432222247123718, loss=0.11117739975452423
test: epoch 126, loss 1.1642332077026367, acc=0.6638888716697693, loss=1.1642332077026367
train: epoch 127, loss 0.11486217379570007, acc=0.9430000185966492, loss=0.11486217379570007
test: epoch 127, loss 1.0127897262573242, acc=0.6638888716697693, loss=1.0127897262573242
train: epoch 128, loss 0.12109524011611938, acc=0.9396666884422302, loss=0.12109524011611938
test: epoch 128, loss 1.4150017499923706, acc=0.6805555820465088, loss=1.4150017499923706
train: epoch 129, loss 0.11291904002428055, acc=0.9431111216545105, loss=0.11291904002428055
test: epoch 129, loss 1.2244399785995483, acc=0.6944444179534912, loss=1.2244399785995483
train: epoch 130, loss 0.11565615236759186, acc=0.9427222013473511, loss=0.11565615236759186
test: epoch 130, loss 1.4435691833496094, acc=0.6777777671813965, loss=1.4435691833496094
train: epoch 131, loss 0.11061908304691315, acc=0.9430555701255798, loss=0.11061908304691315
test: epoch 131, loss 1.0366225242614746, acc=0.6916666626930237, loss=1.0366225242614746
train: epoch 132, loss 0.10845035314559937, acc=0.94477778673172, loss=0.10845035314559937
test: epoch 132, loss 0.7986020445823669, acc=0.7361111044883728, loss=0.7986020445823669
train: epoch 133, loss 0.1026415303349495, acc=0.9456111192703247, loss=0.1026415303349495
test: epoch 133, loss 1.0606940984725952, acc=0.7166666388511658, loss=1.0606940984725952
train: epoch 134, loss 0.1175837442278862, acc=0.9426110982894897, loss=0.1175837442278862
test: epoch 134, loss 1.0770984888076782, acc=0.7055555582046509, loss=1.0770984888076782
train: epoch 135, loss 0.11189573258161545, acc=0.9421111345291138, loss=0.11189573258161545
test: epoch 135, loss 0.6425707936286926, acc=0.7805555462837219, loss=0.6425707936286926
train: epoch 136, loss 0.11179107427597046, acc=0.9418333172798157, loss=0.11179107427597046
test: epoch 136, loss 1.138275384902954, acc=0.6472222208976746, loss=1.138275384902954
train: epoch 137, loss 0.10012533515691757, acc=0.9448333382606506, loss=0.10012533515691757
test: epoch 137, loss 0.9330390095710754, acc=0.7444444298744202, loss=0.9330390095710754
train: epoch 138, loss 0.11175987124443054, acc=0.9437222480773926, loss=0.11175987124443054
test: epoch 138, loss 0.6551400423049927, acc=0.7555555701255798, loss=0.6551400423049927
train: epoch 139, loss 0.10038677603006363, acc=0.9474444389343262, loss=0.10038677603006363
test: epoch 139, loss 1.013229489326477, acc=0.6583333611488342, loss=1.013229489326477
train: epoch 140, loss 0.10091482847929001, acc=0.9477221965789795, loss=0.10091482847929001
test: epoch 140, loss 0.9101592302322388, acc=0.7083333134651184, loss=0.9101592302322388
train: epoch 141, loss 0.1124550998210907, acc=0.9437222480773926, loss=0.1124550998210907
test: epoch 141, loss 1.0610917806625366, acc=0.7027778029441833, loss=1.0610917806625366
train: epoch 142, loss 0.0981968343257904, acc=0.9477777481079102, loss=0.0981968343257904
test: epoch 142, loss 0.8704756498336792, acc=0.7749999761581421, loss=0.8704756498336792
train: epoch 143, loss 0.1182192862033844, acc=0.9432777762413025, loss=0.1182192862033844
test: epoch 143, loss 1.1517480611801147, acc=0.769444465637207, loss=1.1517480611801147
train: epoch 144, loss 0.10954611003398895, acc=0.9456111192703247, loss=0.10954611003398895
test: epoch 144, loss 0.8133390545845032, acc=0.7666666507720947, loss=0.8133390545845032
train: epoch 145, loss 0.10339092463254929, acc=0.945722222328186, loss=0.10339092463254929
test: epoch 145, loss 0.8249877095222473, acc=0.7611111402511597, loss=0.8249877095222473
train: epoch 146, loss 0.1016581580042839, acc=0.9471666812896729, loss=0.1016581580042839
test: epoch 146, loss 0.7087257504463196, acc=0.7583333253860474, loss=0.7087257504463196
train: epoch 147, loss 0.09246163070201874, acc=0.948888897895813, loss=0.09246163070201874
test: epoch 147, loss 0.857577383518219, acc=0.7638888955116272, loss=0.857577383518219
train: epoch 148, loss 0.10495220124721527, acc=0.945555567741394, loss=0.10495220124721527
test: epoch 148, loss 0.7501940727233887, acc=0.7944444417953491, loss=0.7501940727233887
train: epoch 149, loss 0.11151503026485443, acc=0.94477778673172, loss=0.11151503026485443
test: epoch 149, loss 0.37693876028060913, acc=0.8444444537162781, loss=0.37693876028060913
train: epoch 150, loss 0.09665330499410629, acc=0.9486111402511597, loss=0.09665330499410629
test: epoch 150, loss 0.7917487621307373, acc=0.7777777910232544, loss=0.7917487621307373
