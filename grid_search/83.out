# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=1", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=790449929, receiver_embed_dim=64, save_run=0, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=790449929, receiver_embed_dim=64, save_run=False, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.9159274101257324, acc=0.09416666626930237, loss=2.9159274101257324
test: epoch 1, loss 3.661954879760742, acc=0.1111111119389534, loss=3.661954879760742
train: epoch 2, loss 1.8307050466537476, acc=0.2802777886390686, loss=1.8307050466537476
test: epoch 2, loss 3.849614143371582, acc=0.1527777761220932, loss=3.849614143371582
train: epoch 3, loss 1.3260928392410278, acc=0.4652777910232544, loss=1.3260928392410278
test: epoch 3, loss 3.1199450492858887, acc=0.19166666269302368, loss=3.1199450492858887
train: epoch 4, loss 1.0588250160217285, acc=0.5751110911369324, loss=1.0588250160217285
test: epoch 4, loss 2.6331655979156494, acc=0.2083333283662796, loss=2.6331655979156494
train: epoch 5, loss 0.8811649680137634, acc=0.6461111307144165, loss=0.8811649680137634
test: epoch 5, loss 2.475553035736084, acc=0.29722222685813904, loss=2.475553035736084
train: epoch 6, loss 0.7509345412254333, acc=0.7011111378669739, loss=0.7509345412254333
test: epoch 6, loss 2.5214104652404785, acc=0.3333333432674408, loss=2.5214104652404785
train: epoch 7, loss 0.6789535284042358, acc=0.7307222485542297, loss=0.6789535284042358
test: epoch 7, loss 2.145862340927124, acc=0.29722222685813904, loss=2.145862340927124
train: epoch 8, loss 0.6232495903968811, acc=0.7510555386543274, loss=0.6232495903968811
test: epoch 8, loss 2.957735538482666, acc=0.26944443583488464, loss=2.957735538482666
train: epoch 9, loss 0.573370635509491, acc=0.7654444575309753, loss=0.573370635509491
test: epoch 9, loss 2.3208911418914795, acc=0.31111112236976624, loss=2.3208911418914795
train: epoch 10, loss 0.527897834777832, acc=0.7835555672645569, loss=0.527897834777832
test: epoch 10, loss 1.9975115060806274, acc=0.4055555462837219, loss=1.9975115060806274
train: epoch 11, loss 0.5055868029594421, acc=0.7910555601119995, loss=0.5055868029594421
test: epoch 11, loss 1.7138545513153076, acc=0.4055555462837219, loss=1.7138545513153076
train: epoch 12, loss 0.4730043113231659, acc=0.8093888759613037, loss=0.4730043113231659
test: epoch 12, loss 1.5479001998901367, acc=0.4277777671813965, loss=1.5479001998901367
train: epoch 13, loss 0.436234712600708, acc=0.8217777609825134, loss=0.436234712600708
test: epoch 13, loss 1.7314645051956177, acc=0.38055557012557983, loss=1.7314645051956177
train: epoch 14, loss 0.4486960172653198, acc=0.8165555596351624, loss=0.4486960172653198
test: epoch 14, loss 1.8548601865768433, acc=0.40833333134651184, loss=1.8548601865768433
train: epoch 15, loss 0.4241410791873932, acc=0.8267222046852112, loss=0.4241410791873932
test: epoch 15, loss 1.4961142539978027, acc=0.4444444477558136, loss=1.4961142539978027
train: epoch 16, loss 0.40342190861701965, acc=0.8368333578109741, loss=0.40342190861701965
test: epoch 16, loss 1.619224190711975, acc=0.4722222089767456, loss=1.619224190711975
train: epoch 17, loss 0.3731406033039093, acc=0.8463888764381409, loss=0.3731406033039093
test: epoch 17, loss 1.8479764461517334, acc=0.4305555522441864, loss=1.8479764461517334
train: epoch 18, loss 0.3459226191043854, acc=0.8583333492279053, loss=0.3459226191043854
test: epoch 18, loss 1.48026704788208, acc=0.5027777552604675, loss=1.48026704788208
train: epoch 19, loss 0.3321525752544403, acc=0.8661666512489319, loss=0.3321525752544403
test: epoch 19, loss 1.633949875831604, acc=0.38333332538604736, loss=1.633949875831604
train: epoch 20, loss 0.31819435954093933, acc=0.8698889017105103, loss=0.31819435954093933
test: epoch 20, loss 1.776394009590149, acc=0.43888887763023376, loss=1.776394009590149
train: epoch 21, loss 0.3184957206249237, acc=0.8697222471237183, loss=0.3184957206249237
test: epoch 21, loss 1.5337331295013428, acc=0.48055556416511536, loss=1.5337331295013428
train: epoch 22, loss 0.2971840500831604, acc=0.8778889179229736, loss=0.2971840500831604
test: epoch 22, loss 1.417741298675537, acc=0.5333333611488342, loss=1.417741298675537
train: epoch 23, loss 0.26909902691841125, acc=0.8907222151756287, loss=0.26909902691841125
test: epoch 23, loss 1.835323691368103, acc=0.5222222208976746, loss=1.835323691368103
train: epoch 24, loss 0.28148776292800903, acc=0.8899444341659546, loss=0.28148776292800903
test: epoch 24, loss 1.351965069770813, acc=0.49444442987442017, loss=1.351965069770813
train: epoch 25, loss 0.26294392347335815, acc=0.8950555324554443, loss=0.26294392347335815
test: epoch 25, loss 1.566389560699463, acc=0.46388888359069824, loss=1.566389560699463
train: epoch 26, loss 0.2490459382534027, acc=0.9024999737739563, loss=0.2490459382534027
test: epoch 26, loss 1.3198546171188354, acc=0.5833333134651184, loss=1.3198546171188354
train: epoch 27, loss 0.24638421833515167, acc=0.9092777967453003, loss=0.24638421833515167
test: epoch 27, loss 1.5183733701705933, acc=0.4972222149372101, loss=1.5183733701705933
train: epoch 28, loss 0.21413195133209229, acc=0.921999990940094, loss=0.21413195133209229
test: epoch 28, loss 1.5876221656799316, acc=0.5583333373069763, loss=1.5876221656799316
train: epoch 29, loss 0.21216337382793427, acc=0.9268333315849304, loss=0.21216337382793427
test: epoch 29, loss 1.7959952354431152, acc=0.4888888895511627, loss=1.7959952354431152
train: epoch 30, loss 0.20626689493656158, acc=0.93022221326828, loss=0.20626689493656158
test: epoch 30, loss 1.4284915924072266, acc=0.5638889074325562, loss=1.4284915924072266
train: epoch 31, loss 0.17050780355930328, acc=0.9438889026641846, loss=0.17050780355930328
test: epoch 31, loss 1.5300885438919067, acc=0.5972222089767456, loss=1.5300885438919067
train: epoch 32, loss 0.18903674185276031, acc=0.9368888735771179, loss=0.18903674185276031
test: epoch 32, loss 1.4064587354660034, acc=0.5722222328186035, loss=1.4064587354660034
train: epoch 33, loss 0.16001659631729126, acc=0.9474444389343262, loss=0.16001659631729126
test: epoch 33, loss 1.2561728954315186, acc=0.6416666507720947, loss=1.2561728954315186
train: epoch 34, loss 0.1608593910932541, acc=0.9477777481079102, loss=0.1608593910932541
test: epoch 34, loss 1.4669796228408813, acc=0.6222222447395325, loss=1.4669796228408813
train: epoch 35, loss 0.16076865792274475, acc=0.949833333492279, loss=0.16076865792274475
test: epoch 35, loss 1.1232764720916748, acc=0.6361111402511597, loss=1.1232764720916748
train: epoch 36, loss 0.15590707957744598, acc=0.9496111273765564, loss=0.15590707957744598
test: epoch 36, loss 1.1682087182998657, acc=0.6333333253860474, loss=1.1682087182998657
train: epoch 37, loss 0.15315045416355133, acc=0.9511111378669739, loss=0.15315045416355133
test: epoch 37, loss 0.9028525948524475, acc=0.7666666507720947, loss=0.9028525948524475
train: epoch 38, loss 0.1390102356672287, acc=0.9537777900695801, loss=0.1390102356672287
test: epoch 38, loss 1.303609013557434, acc=0.6138888597488403, loss=1.303609013557434
train: epoch 39, loss 0.14306427538394928, acc=0.9537777900695801, loss=0.14306427538394928
test: epoch 39, loss 1.1900663375854492, acc=0.6583333611488342, loss=1.1900663375854492
train: epoch 40, loss 0.14525315165519714, acc=0.9541110992431641, loss=0.14525315165519714
test: epoch 40, loss 0.9916076064109802, acc=0.6972222328186035, loss=0.9916076064109802
train: epoch 41, loss 0.1333373785018921, acc=0.9553889036178589, loss=0.1333373785018921
test: epoch 41, loss 1.1129817962646484, acc=0.6527777910232544, loss=1.1129817962646484
train: epoch 42, loss 0.13585951924324036, acc=0.9554444551467896, loss=0.13585951924324036
test: epoch 42, loss 0.9184579253196716, acc=0.7250000238418579, loss=0.9184579253196716
train: epoch 43, loss 0.12878258526325226, acc=0.9598333239555359, loss=0.12878258526325226
test: epoch 43, loss 0.83625727891922, acc=0.7194444537162781, loss=0.83625727891922
train: epoch 44, loss 0.1310373991727829, acc=0.957444429397583, loss=0.1310373991727829
test: epoch 44, loss 0.6595917344093323, acc=0.7555555701255798, loss=0.6595917344093323
train: epoch 45, loss 0.1225396916270256, acc=0.9597777724266052, loss=0.1225396916270256
test: epoch 45, loss 0.8402111530303955, acc=0.7416666746139526, loss=0.8402111530303955
train: epoch 46, loss 0.11337804049253464, acc=0.9639444351196289, loss=0.11337804049253464
test: epoch 46, loss 0.6958590149879456, acc=0.7861111164093018, loss=0.6958590149879456
train: epoch 47, loss 0.10895619541406631, acc=0.9649444222450256, loss=0.10895619541406631
test: epoch 47, loss 1.0042425394058228, acc=0.7388888597488403, loss=1.0042425394058228
train: epoch 48, loss 0.12657015025615692, acc=0.9601666927337646, loss=0.12657015025615692
test: epoch 48, loss 0.6503987908363342, acc=0.7722222208976746, loss=0.6503987908363342
train: epoch 49, loss 0.1195417195558548, acc=0.9625555276870728, loss=0.1195417195558548
test: epoch 49, loss 0.6027500629425049, acc=0.8166666626930237, loss=0.6027500629425049
train: epoch 50, loss 0.10634409636259079, acc=0.9651111364364624, loss=0.10634409636259079
test: epoch 50, loss 0.6543454527854919, acc=0.7833333611488342, loss=0.6543454527854919
train: epoch 51, loss 0.10249198228120804, acc=0.9668333530426025, loss=0.10249198228120804
test: epoch 51, loss 0.7953522801399231, acc=0.7527777552604675, loss=0.7953522801399231
train: epoch 52, loss 0.09781759232282639, acc=0.9677777886390686, loss=0.09781759232282639
test: epoch 52, loss 0.6990343332290649, acc=0.8222222328186035, loss=0.6990343332290649
train: epoch 53, loss 0.10709290951490402, acc=0.9662777781486511, loss=0.10709290951490402
test: epoch 53, loss 0.537377119064331, acc=0.8194444179534912, loss=0.537377119064331
train: epoch 54, loss 0.099739208817482, acc=0.9673888683319092, loss=0.099739208817482
test: epoch 54, loss 0.43729308247566223, acc=0.824999988079071, loss=0.43729308247566223
train: epoch 55, loss 0.09548109769821167, acc=0.9686111211776733, loss=0.09548109769821167
test: epoch 55, loss 0.6009284853935242, acc=0.8111110925674438, loss=0.6009284853935242
train: epoch 56, loss 0.09613161534070969, acc=0.9691110849380493, loss=0.09613161534070969
test: epoch 56, loss 0.5595798492431641, acc=0.8416666388511658, loss=0.5595798492431641
train: epoch 57, loss 0.1115616112947464, acc=0.964388906955719, loss=0.1115616112947464
test: epoch 57, loss 0.5458810925483704, acc=0.8416666388511658, loss=0.5458810925483704
train: epoch 58, loss 0.07563896477222443, acc=0.9758333563804626, loss=0.07563896477222443
test: epoch 58, loss 0.6394920349121094, acc=0.8222222328186035, loss=0.6394920349121094
train: epoch 59, loss 0.0779619887471199, acc=0.9762222170829773, loss=0.0779619887471199
test: epoch 59, loss 0.5492664575576782, acc=0.8694444298744202, loss=0.5492664575576782
train: epoch 60, loss 0.07886240631341934, acc=0.976111114025116, loss=0.07886240631341934
test: epoch 60, loss 0.4190623164176941, acc=0.9138888716697693, loss=0.4190623164176941
train: epoch 61, loss 0.086043581366539, acc=0.9728888869285583, loss=0.086043581366539
test: epoch 61, loss 0.3720315396785736, acc=0.8888888955116272, loss=0.3720315396785736
train: epoch 62, loss 0.08744215965270996, acc=0.9723333120346069, loss=0.08744215965270996
test: epoch 62, loss 0.32799118757247925, acc=0.9166666865348816, loss=0.32799118757247925
train: epoch 63, loss 0.07281883805990219, acc=0.9790555834770203, loss=0.07281883805990219
test: epoch 63, loss 0.4714374244213104, acc=0.9166666865348816, loss=0.4714374244213104
train: epoch 64, loss 0.06923564523458481, acc=0.9788333177566528, loss=0.06923564523458481
test: epoch 64, loss 0.3465650975704193, acc=0.9222221970558167, loss=0.3465650975704193
train: epoch 65, loss 0.07292135804891586, acc=0.9775555729866028, loss=0.07292135804891586
test: epoch 65, loss 0.2781381905078888, acc=0.925000011920929, loss=0.2781381905078888
train: epoch 66, loss 0.07120751589536667, acc=0.9796666502952576, loss=0.07120751589536667
test: epoch 66, loss 0.33395829796791077, acc=0.925000011920929, loss=0.33395829796791077
train: epoch 67, loss 0.053356800228357315, acc=0.984333336353302, loss=0.053356800228357315
test: epoch 67, loss 0.4227018654346466, acc=0.925000011920929, loss=0.4227018654346466
train: epoch 68, loss 0.06784331053495407, acc=0.9794999957084656, loss=0.06784331053495407
test: epoch 68, loss 0.21637077629566193, acc=0.9333333373069763, loss=0.21637077629566193
train: epoch 69, loss 0.07976739853620529, acc=0.9765555262565613, loss=0.07976739853620529
test: epoch 69, loss 0.27242299914360046, acc=0.9305555820465088, loss=0.27242299914360046
train: epoch 70, loss 0.04744342342019081, acc=0.9848889112472534, loss=0.04744342342019081
test: epoch 70, loss 0.19030655920505524, acc=0.9305555820465088, loss=0.19030655920505524
train: epoch 71, loss 0.06775779277086258, acc=0.9797222018241882, loss=0.06775779277086258
test: epoch 71, loss 0.13489621877670288, acc=0.9361110925674438, loss=0.13489621877670288
train: epoch 72, loss 0.05342483893036842, acc=0.9833889007568359, loss=0.05342483893036842
test: epoch 72, loss 0.2840666174888611, acc=0.9333333373069763, loss=0.2840666174888611
train: epoch 73, loss 0.05421904847025871, acc=0.9833889007568359, loss=0.05421904847025871
test: epoch 73, loss 0.2633950412273407, acc=0.9333333373069763, loss=0.2633950412273407
train: epoch 74, loss 0.05495017394423485, acc=0.9842222332954407, loss=0.05495017394423485
test: epoch 74, loss 0.22141033411026, acc=0.9333333373069763, loss=0.22141033411026
train: epoch 75, loss 0.047232337296009064, acc=0.9869999885559082, loss=0.047232337296009064
test: epoch 75, loss 0.2561712861061096, acc=0.9333333373069763, loss=0.2561712861061096
train: epoch 76, loss 0.07342613488435745, acc=0.9806110858917236, loss=0.07342613488435745
test: epoch 76, loss 0.1992364227771759, acc=0.9333333373069763, loss=0.1992364227771759
train: epoch 77, loss 0.05288909003138542, acc=0.9826666712760925, loss=0.05288909003138542
test: epoch 77, loss 0.15193623304367065, acc=0.9333333373069763, loss=0.15193623304367065
train: epoch 78, loss 0.049459006637334824, acc=0.9847777485847473, loss=0.049459006637334824
test: epoch 78, loss 0.23564517498016357, acc=0.9333333373069763, loss=0.23564517498016357
train: epoch 79, loss 0.049551866948604584, acc=0.9849444627761841, loss=0.049551866948604584
test: epoch 79, loss 0.30254268646240234, acc=0.9333333373069763, loss=0.30254268646240234
train: epoch 80, loss 0.04876863211393356, acc=0.9846110939979553, loss=0.04876863211393356
test: epoch 80, loss 0.297595351934433, acc=0.9333333373069763, loss=0.297595351934433
train: epoch 81, loss 0.057336900383234024, acc=0.9837222099304199, loss=0.057336900383234024
test: epoch 81, loss 0.2750915586948395, acc=0.9277777671813965, loss=0.2750915586948395
train: epoch 82, loss 0.053378988057374954, acc=0.9843888878822327, loss=0.053378988057374954
test: epoch 82, loss 0.27827760577201843, acc=0.9333333373069763, loss=0.27827760577201843
train: epoch 83, loss 0.04945650324225426, acc=0.984499990940094, loss=0.04945650324225426
test: epoch 83, loss 0.13006740808486938, acc=0.9333333373069763, loss=0.13006740808486938
train: epoch 84, loss 0.05663413181900978, acc=0.9827777743339539, loss=0.05663413181900978
test: epoch 84, loss 0.15216198563575745, acc=0.9333333373069763, loss=0.15216198563575745
train: epoch 85, loss 0.05647227168083191, acc=0.9837222099304199, loss=0.05647227168083191
test: epoch 85, loss 0.23955519497394562, acc=0.9333333373069763, loss=0.23955519497394562
train: epoch 86, loss 0.04950439929962158, acc=0.9847777485847473, loss=0.04950439929962158
test: epoch 86, loss 0.25289878249168396, acc=0.9333333373069763, loss=0.25289878249168396
train: epoch 87, loss 0.05582472309470177, acc=0.9839444160461426, loss=0.05582472309470177
test: epoch 87, loss 0.233931764960289, acc=0.9333333373069763, loss=0.233931764960289
train: epoch 88, loss 0.04670142009854317, acc=0.9850555658340454, loss=0.04670142009854317
test: epoch 88, loss 0.2511645555496216, acc=0.9333333373069763, loss=0.2511645555496216
train: epoch 89, loss 0.044961538165807724, acc=0.9856111407279968, loss=0.044961538165807724
test: epoch 89, loss 0.24112820625305176, acc=0.9333333373069763, loss=0.24112820625305176
train: epoch 90, loss 0.048066336661577225, acc=0.9854444265365601, loss=0.048066336661577225
test: epoch 90, loss 0.25221312046051025, acc=0.9333333373069763, loss=0.25221312046051025
train: epoch 91, loss 0.05401115119457245, acc=0.9845555424690247, loss=0.05401115119457245
test: epoch 91, loss 0.23939402401447296, acc=0.9305555820465088, loss=0.23939402401447296
train: epoch 92, loss 0.04801607131958008, acc=0.9860000014305115, loss=0.04801607131958008
test: epoch 92, loss 0.16319239139556885, acc=0.9388889074325562, loss=0.16319239139556885
train: epoch 93, loss 0.04610127955675125, acc=0.9863888621330261, loss=0.04610127955675125
test: epoch 93, loss 0.2022622525691986, acc=0.9333333373069763, loss=0.2022622525691986
train: epoch 94, loss 0.043513793498277664, acc=0.9865555763244629, loss=0.043513793498277664
test: epoch 94, loss 0.3477608561515808, acc=0.925000011920929, loss=0.3477608561515808
train: epoch 95, loss 0.05177415534853935, acc=0.9847777485847473, loss=0.05177415534853935
test: epoch 95, loss 0.2129141092300415, acc=0.9333333373069763, loss=0.2129141092300415
train: epoch 96, loss 0.05134715139865875, acc=0.9850555658340454, loss=0.05134715139865875
test: epoch 96, loss 0.24743928015232086, acc=0.9333333373069763, loss=0.24743928015232086
train: epoch 97, loss 0.04828817397356033, acc=0.9857777953147888, loss=0.04828817397356033
test: epoch 97, loss 0.23751585185527802, acc=0.9305555820465088, loss=0.23751585185527802
train: epoch 98, loss 0.05424017831683159, acc=0.9845555424690247, loss=0.05424017831683159
test: epoch 98, loss 0.19675031304359436, acc=0.9333333373069763, loss=0.19675031304359436
train: epoch 99, loss 0.04515014961361885, acc=0.9852777719497681, loss=0.04515014961361885
test: epoch 99, loss 0.3260585069656372, acc=0.9388889074325562, loss=0.3260585069656372
train: epoch 100, loss 0.046929024159908295, acc=0.9853333234786987, loss=0.046929024159908295
test: epoch 100, loss 0.23847931623458862, acc=0.9333333373069763, loss=0.23847931623458862
train: epoch 101, loss 0.047311052680015564, acc=0.9848889112472534, loss=0.047311052680015564
test: epoch 101, loss 0.1593724936246872, acc=0.9333333373069763, loss=0.1593724936246872
train: epoch 102, loss 0.03725811466574669, acc=0.987333357334137, loss=0.03725811466574669
test: epoch 102, loss 0.2125367522239685, acc=0.9333333373069763, loss=0.2125367522239685
train: epoch 103, loss 0.0534588061273098, acc=0.9824444651603699, loss=0.0534588061273098
test: epoch 103, loss 0.14081287384033203, acc=0.9333333373069763, loss=0.14081287384033203
train: epoch 104, loss 0.04839353263378143, acc=0.9857222437858582, loss=0.04839353263378143
test: epoch 104, loss 0.228282630443573, acc=0.9333333373069763, loss=0.228282630443573
train: epoch 105, loss 0.050822291523218155, acc=0.9852222204208374, loss=0.050822291523218155
test: epoch 105, loss 0.24951918423175812, acc=0.9305555820465088, loss=0.24951918423175812
train: epoch 106, loss 0.045668236911296844, acc=0.9863888621330261, loss=0.045668236911296844
test: epoch 106, loss 0.2027321308851242, acc=0.9333333373069763, loss=0.2027321308851242
train: epoch 107, loss 0.053233802318573, acc=0.9842222332954407, loss=0.053233802318573
test: epoch 107, loss 0.1537964791059494, acc=0.9333333373069763, loss=0.1537964791059494
train: epoch 108, loss 0.04392128065228462, acc=0.9867222309112549, loss=0.04392128065228462
test: epoch 108, loss 0.20227758586406708, acc=0.9333333373069763, loss=0.20227758586406708
train: epoch 109, loss 0.04911556467413902, acc=0.9858333468437195, loss=0.04911556467413902
test: epoch 109, loss 0.1984359323978424, acc=0.925000011920929, loss=0.1984359323978424
train: epoch 110, loss 0.04513707384467125, acc=0.9865000247955322, loss=0.04513707384467125
test: epoch 110, loss 0.3055454194545746, acc=0.9305555820465088, loss=0.3055454194545746
train: epoch 111, loss 0.04339531064033508, acc=0.9866111278533936, loss=0.04339531064033508
test: epoch 111, loss 0.24258917570114136, acc=0.9333333373069763, loss=0.24258917570114136
train: epoch 112, loss 0.049418993294239044, acc=0.9863333106040955, loss=0.049418993294239044
test: epoch 112, loss 0.2744566798210144, acc=0.9333333373069763, loss=0.2744566798210144
train: epoch 113, loss 0.04728206247091293, acc=0.9851666688919067, loss=0.04728206247091293
test: epoch 113, loss 0.2268965244293213, acc=0.9305555820465088, loss=0.2268965244293213
train: epoch 114, loss 0.04693956673145294, acc=0.9866111278533936, loss=0.04693956673145294
test: epoch 114, loss 0.19808995723724365, acc=0.9333333373069763, loss=0.19808995723724365
train: epoch 115, loss 0.036281660199165344, acc=0.988111138343811, loss=0.036281660199165344
test: epoch 115, loss 0.19419321417808533, acc=0.9333333373069763, loss=0.19419321417808533
train: epoch 116, loss 0.049789950251579285, acc=0.9850000143051147, loss=0.049789950251579285
test: epoch 116, loss 0.19131113588809967, acc=0.9333333373069763, loss=0.19131113588809967
train: epoch 117, loss 0.0427725724875927, acc=0.987333357334137, loss=0.0427725724875927
test: epoch 117, loss 0.18485093116760254, acc=0.9333333373069763, loss=0.18485093116760254
train: epoch 118, loss 0.059814974665641785, acc=0.9818333387374878, loss=0.059814974665641785
test: epoch 118, loss 0.20672495663166046, acc=0.9333333373069763, loss=0.20672495663166046
train: epoch 119, loss 0.05129995569586754, acc=0.9835000038146973, loss=0.05129995569586754
test: epoch 119, loss 0.24146616458892822, acc=0.9333333373069763, loss=0.24146616458892822
train: epoch 120, loss 0.0488913394510746, acc=0.9832777976989746, loss=0.0488913394510746
test: epoch 120, loss 0.1857893466949463, acc=0.9333333373069763, loss=0.1857893466949463
train: epoch 121, loss 0.03769804164767265, acc=0.9878333210945129, loss=0.03769804164767265
test: epoch 121, loss 0.23839205503463745, acc=0.9333333373069763, loss=0.23839205503463745
train: epoch 122, loss 0.046748969703912735, acc=0.9856666922569275, loss=0.046748969703912735
test: epoch 122, loss 0.20695871114730835, acc=0.9333333373069763, loss=0.20695871114730835
train: epoch 123, loss 0.05541516840457916, acc=0.9831666946411133, loss=0.05541516840457916
test: epoch 123, loss 0.20321223139762878, acc=0.9333333373069763, loss=0.20321223139762878
train: epoch 124, loss 0.04815471172332764, acc=0.9856111407279968, loss=0.04815471172332764
test: epoch 124, loss 0.20542564988136292, acc=0.9333333373069763, loss=0.20542564988136292
train: epoch 125, loss 0.04839715361595154, acc=0.9832777976989746, loss=0.04839715361595154
test: epoch 125, loss 0.21845746040344238, acc=0.9333333373069763, loss=0.21845746040344238
train: epoch 126, loss 0.05022187903523445, acc=0.9847777485847473, loss=0.05022187903523445
test: epoch 126, loss 0.10326866805553436, acc=0.9333333373069763, loss=0.10326866805553436
train: epoch 127, loss 0.05103858932852745, acc=0.9853888750076294, loss=0.05103858932852745
test: epoch 127, loss 0.27318429946899414, acc=0.9305555820465088, loss=0.27318429946899414
train: epoch 128, loss 0.057923074811697006, acc=0.980222225189209, loss=0.057923074811697006
test: epoch 128, loss 0.1625327616930008, acc=0.9333333373069763, loss=0.1625327616930008
train: epoch 129, loss 0.04346810281276703, acc=0.9853888750076294, loss=0.04346810281276703
test: epoch 129, loss 0.14374852180480957, acc=0.9333333373069763, loss=0.14374852180480957
train: epoch 130, loss 0.048742081969976425, acc=0.9854999780654907, loss=0.048742081969976425
test: epoch 130, loss 0.19524160027503967, acc=0.9333333373069763, loss=0.19524160027503967
train: epoch 131, loss 0.04349316284060478, acc=0.9871110916137695, loss=0.04349316284060478
test: epoch 131, loss 0.18377502262592316, acc=0.9333333373069763, loss=0.18377502262592316
train: epoch 132, loss 0.04552021995186806, acc=0.9847221970558167, loss=0.04552021995186806
test: epoch 132, loss 0.15620937943458557, acc=0.9333333373069763, loss=0.15620937943458557
train: epoch 133, loss 0.042864348739385605, acc=0.9868333339691162, loss=0.042864348739385605
test: epoch 133, loss 0.21578645706176758, acc=0.9333333373069763, loss=0.21578645706176758
train: epoch 134, loss 0.058745063841342926, acc=0.9816666841506958, loss=0.058745063841342926
test: epoch 134, loss 0.21572615206241608, acc=0.9333333373069763, loss=0.21572615206241608
train: epoch 135, loss 0.05367667227983475, acc=0.9830555319786072, loss=0.05367667227983475
test: epoch 135, loss 0.24177958071231842, acc=0.9333333373069763, loss=0.24177958071231842
train: epoch 136, loss 0.040020640939474106, acc=0.9875555634498596, loss=0.040020640939474106
test: epoch 136, loss 0.21675649285316467, acc=0.9333333373069763, loss=0.21675649285316467
train: epoch 137, loss 0.04836738109588623, acc=0.9845555424690247, loss=0.04836738109588623
test: epoch 137, loss 0.27035754919052124, acc=0.9333333373069763, loss=0.27035754919052124
train: epoch 138, loss 0.048445768654346466, acc=0.9836666584014893, loss=0.048445768654346466
test: epoch 138, loss 0.2104022204875946, acc=0.9305555820465088, loss=0.2104022204875946
train: epoch 139, loss 0.039333634078502655, acc=0.9860555529594421, loss=0.039333634078502655
test: epoch 139, loss 0.2502594590187073, acc=0.9305555820465088, loss=0.2502594590187073
train: epoch 140, loss 0.0569419264793396, acc=0.9824444651603699, loss=0.0569419264793396
test: epoch 140, loss 0.20322822034358978, acc=0.9333333373069763, loss=0.20322822034358978
train: epoch 141, loss 0.05176127701997757, acc=0.9847221970558167, loss=0.05176127701997757
test: epoch 141, loss 0.16633455455303192, acc=0.9333333373069763, loss=0.16633455455303192
train: epoch 142, loss 0.050234343856573105, acc=0.9837222099304199, loss=0.050234343856573105
test: epoch 142, loss 0.1892896294593811, acc=0.9333333373069763, loss=0.1892896294593811
train: epoch 143, loss 0.0411941297352314, acc=0.9869444370269775, loss=0.0411941297352314
test: epoch 143, loss 0.23682929575443268, acc=0.9305555820465088, loss=0.23682929575443268
train: epoch 144, loss 0.06637076288461685, acc=0.9793333411216736, loss=0.06637076288461685
test: epoch 144, loss 0.19078047573566437, acc=0.9333333373069763, loss=0.19078047573566437
train: epoch 145, loss 0.04947285354137421, acc=0.9853333234786987, loss=0.04947285354137421
test: epoch 145, loss 0.23339565098285675, acc=0.9305555820465088, loss=0.23339565098285675
train: epoch 146, loss 0.04372363165020943, acc=0.9859444499015808, loss=0.04372363165020943
test: epoch 146, loss 0.1714322715997696, acc=0.9333333373069763, loss=0.1714322715997696
train: epoch 147, loss 0.05428266525268555, acc=0.984499990940094, loss=0.05428266525268555
test: epoch 147, loss 0.18146224319934845, acc=0.9333333373069763, loss=0.18146224319934845
train: epoch 148, loss 0.040254440158605576, acc=0.9872778058052063, loss=0.040254440158605576
test: epoch 148, loss 0.2437272071838379, acc=0.9305555820465088, loss=0.2437272071838379
train: epoch 149, loss 0.050981611013412476, acc=0.9853333234786987, loss=0.050981611013412476
test: epoch 149, loss 0.19672870635986328, acc=0.9333333373069763, loss=0.19672870635986328
train: epoch 150, loss 0.041959311813116074, acc=0.9871666431427002, loss=0.041959311813116074
test: epoch 150, loss 0.2076866179704666, acc=0.9333333373069763, loss=0.2076866179704666
