# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=2.0", "--temp_decay=1", "--one_hot=1", "--n_layers=1"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=356197679, receiver_embed_dim=128, save_run=0, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=356197679, receiver_embed_dim=128, save_run=False, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.511002540588379, acc=0.05122222378849983, loss=3.511002540588379
test: epoch 1, loss 3.2462708950042725, acc=0.05833333358168602, loss=3.2462708950042725
train: epoch 2, loss 3.4018197059631348, acc=0.05488888919353485, loss=3.4018197059631348
test: epoch 2, loss 3.737260103225708, acc=0.06111111119389534, loss=3.737260103225708
train: epoch 3, loss 2.878110408782959, acc=0.12472222000360489, loss=2.878110408782959
test: epoch 3, loss 6.312700271606445, acc=0.04722222313284874, loss=6.312700271606445
train: epoch 4, loss 2.4639365673065186, acc=0.18211111426353455, loss=2.4639365673065186
test: epoch 4, loss 7.505512237548828, acc=0.03611111268401146, loss=7.505512237548828
train: epoch 5, loss 2.2588651180267334, acc=0.2195555567741394, loss=2.2588651180267334
test: epoch 5, loss 8.163504600524902, acc=0.04444444552063942, loss=8.163504600524902
train: epoch 6, loss 2.12753963470459, acc=0.2548888921737671, loss=2.12753963470459
test: epoch 6, loss 8.690862655639648, acc=0.0416666679084301, loss=8.690862655639648
train: epoch 7, loss 2.0378479957580566, acc=0.2706666588783264, loss=2.0378479957580566
test: epoch 7, loss 8.643305778503418, acc=0.05000000074505806, loss=8.643305778503418
train: epoch 8, loss 1.9659934043884277, acc=0.28966665267944336, loss=1.9659934043884277
test: epoch 8, loss 8.980749130249023, acc=0.04722222313284874, loss=8.980749130249023
train: epoch 9, loss 1.9085203409194946, acc=0.30961111187934875, loss=1.9085203409194946
test: epoch 9, loss 9.316694259643555, acc=0.05833333358168602, loss=9.316694259643555
train: epoch 10, loss 1.854383111000061, acc=0.3255000114440918, loss=1.854383111000061
test: epoch 10, loss 9.742711067199707, acc=0.0555555559694767, loss=9.742711067199707
train: epoch 11, loss 1.8033255338668823, acc=0.34599998593330383, loss=1.8033255338668823
test: epoch 11, loss 9.852357864379883, acc=0.07500000298023224, loss=9.852357864379883
train: epoch 12, loss 1.773574948310852, acc=0.35377776622772217, loss=1.773574948310852
test: epoch 12, loss 9.890656471252441, acc=0.06111111119389534, loss=9.890656471252441
train: epoch 13, loss 1.720828652381897, acc=0.3721666634082794, loss=1.720828652381897
test: epoch 13, loss 9.738975524902344, acc=0.05833333358168602, loss=9.738975524902344
train: epoch 14, loss 1.6799793243408203, acc=0.38688889145851135, loss=1.6799793243408203
test: epoch 14, loss 9.582778930664062, acc=0.06388889253139496, loss=9.582778930664062
train: epoch 15, loss 1.6436426639556885, acc=0.3890555500984192, loss=1.6436426639556885
test: epoch 15, loss 9.191620826721191, acc=0.0694444477558136, loss=9.191620826721191
train: epoch 16, loss 1.6079930067062378, acc=0.41244444251060486, loss=1.6079930067062378
test: epoch 16, loss 8.70541763305664, acc=0.06388889253139496, loss=8.70541763305664
train: epoch 17, loss 1.5728094577789307, acc=0.42705556750297546, loss=1.5728094577789307
test: epoch 17, loss 8.373248100280762, acc=0.0694444477558136, loss=8.373248100280762
train: epoch 18, loss 1.5382906198501587, acc=0.43849998712539673, loss=1.5382906198501587
test: epoch 18, loss 8.21982479095459, acc=0.0694444477558136, loss=8.21982479095459
train: epoch 19, loss 1.4956880807876587, acc=0.4546111226081848, loss=1.4956880807876587
test: epoch 19, loss 7.849496841430664, acc=0.07777778059244156, loss=7.849496841430664
train: epoch 20, loss 1.4627143144607544, acc=0.4657222330570221, loss=1.4627143144607544
test: epoch 20, loss 7.659853935241699, acc=0.0694444477558136, loss=7.659853935241699
train: epoch 21, loss 1.4352813959121704, acc=0.48616665601730347, loss=1.4352813959121704
test: epoch 21, loss 7.018129825592041, acc=0.0972222238779068, loss=7.018129825592041
train: epoch 22, loss 1.41061532497406, acc=0.49050000309944153, loss=1.41061532497406
test: epoch 22, loss 6.6590046882629395, acc=0.10833333432674408, loss=6.6590046882629395
train: epoch 23, loss 1.3698879480361938, acc=0.5009444355964661, loss=1.3698879480361938
test: epoch 23, loss 6.614006996154785, acc=0.11666666716337204, loss=6.614006996154785
train: epoch 24, loss 1.3398479223251343, acc=0.5157777667045593, loss=1.3398479223251343
test: epoch 24, loss 6.495362281799316, acc=0.11388888955116272, loss=6.495362281799316
train: epoch 25, loss 1.3171261548995972, acc=0.5270000100135803, loss=1.3171261548995972
test: epoch 25, loss 6.305427551269531, acc=0.14444445073604584, loss=6.305427551269531
train: epoch 26, loss 1.2860223054885864, acc=0.5391111373901367, loss=1.2860223054885864
test: epoch 26, loss 6.247340202331543, acc=0.1388888955116272, loss=6.247340202331543
train: epoch 27, loss 1.2398709058761597, acc=0.5520555377006531, loss=1.2398709058761597
test: epoch 27, loss 6.296472549438477, acc=0.13055555522441864, loss=6.296472549438477
train: epoch 28, loss 1.2170056104660034, acc=0.5695555806159973, loss=1.2170056104660034
test: epoch 28, loss 6.045472145080566, acc=0.15000000596046448, loss=6.045472145080566
train: epoch 29, loss 1.1994500160217285, acc=0.5772777795791626, loss=1.1994500160217285
test: epoch 29, loss 6.019829750061035, acc=0.1527777761220932, loss=6.019829750061035
train: epoch 30, loss 1.1743627786636353, acc=0.5903888940811157, loss=1.1743627786636353
test: epoch 30, loss 6.039480209350586, acc=0.15833333134651184, loss=6.039480209350586
train: epoch 31, loss 1.1308659315109253, acc=0.6049444675445557, loss=1.1308659315109253
test: epoch 31, loss 6.243282318115234, acc=0.16111111640930176, loss=6.243282318115234
train: epoch 32, loss 1.1208021640777588, acc=0.6193333268165588, loss=1.1208021640777588
test: epoch 32, loss 6.159200191497803, acc=0.16111111640930176, loss=6.159200191497803
train: epoch 33, loss 1.0883545875549316, acc=0.6304444670677185, loss=1.0883545875549316
test: epoch 33, loss 6.250697135925293, acc=0.17222222685813904, loss=6.250697135925293
train: epoch 34, loss 1.0546900033950806, acc=0.6439999938011169, loss=1.0546900033950806
test: epoch 34, loss 6.097546577453613, acc=0.1805555522441864, loss=6.097546577453613
train: epoch 35, loss 1.0271943807601929, acc=0.6573888659477234, loss=1.0271943807601929
test: epoch 35, loss 5.83491849899292, acc=0.1944444477558136, loss=5.83491849899292
train: epoch 36, loss 0.9899285435676575, acc=0.6699444651603699, loss=0.9899285435676575
test: epoch 36, loss 5.90969705581665, acc=0.19722221791744232, loss=5.90969705581665
train: epoch 37, loss 0.9600642919540405, acc=0.687333345413208, loss=0.9600642919540405
test: epoch 37, loss 6.108846187591553, acc=0.1944444477558136, loss=6.108846187591553
train: epoch 38, loss 0.9377955198287964, acc=0.6952221989631653, loss=0.9377955198287964
test: epoch 38, loss 6.035056114196777, acc=0.2083333283662796, loss=6.035056114196777
train: epoch 39, loss 0.8924596309661865, acc=0.7146111130714417, loss=0.8924596309661865
test: epoch 39, loss 6.248193740844727, acc=0.21944443881511688, loss=6.248193740844727
train: epoch 40, loss 0.8691427707672119, acc=0.7239444255828857, loss=0.8691427707672119
test: epoch 40, loss 6.193641662597656, acc=0.21944443881511688, loss=6.193641662597656
train: epoch 41, loss 0.8218240737915039, acc=0.7493333220481873, loss=0.8218240737915039
test: epoch 41, loss 6.246885776519775, acc=0.21944443881511688, loss=6.246885776519775
train: epoch 42, loss 0.7977782487869263, acc=0.7559999823570251, loss=0.7977782487869263
test: epoch 42, loss 6.114078998565674, acc=0.22499999403953552, loss=6.114078998565674
train: epoch 43, loss 0.7626556754112244, acc=0.7721111178398132, loss=0.7626556754112244
test: epoch 43, loss 6.202838897705078, acc=0.2527777850627899, loss=6.202838897705078
train: epoch 44, loss 0.7373621463775635, acc=0.7906110882759094, loss=0.7373621463775635
test: epoch 44, loss 6.0685553550720215, acc=0.25, loss=6.0685553550720215
train: epoch 45, loss 0.6829716563224792, acc=0.8002222180366516, loss=0.6829716563224792
test: epoch 45, loss 5.980915069580078, acc=0.2527777850627899, loss=5.980915069580078
train: epoch 46, loss 0.6653928756713867, acc=0.8116666674613953, loss=0.6653928756713867
test: epoch 46, loss 5.808496952056885, acc=0.26944443583488464, loss=5.808496952056885
train: epoch 47, loss 0.6246329545974731, acc=0.8298888802528381, loss=0.6246329545974731
test: epoch 47, loss 5.69188117980957, acc=0.25, loss=5.69188117980957
train: epoch 48, loss 0.6001976728439331, acc=0.8397777676582336, loss=0.6001976728439331
test: epoch 48, loss 5.820705890655518, acc=0.2666666805744171, loss=5.820705890655518
train: epoch 49, loss 0.5953737497329712, acc=0.8452222347259521, loss=0.5953737497329712
test: epoch 49, loss 5.5597333908081055, acc=0.27222222089767456, loss=5.5597333908081055
train: epoch 50, loss 0.550145149230957, acc=0.8613333106040955, loss=0.550145149230957
test: epoch 50, loss 5.487435817718506, acc=0.2777777910232544, loss=5.487435817718506
train: epoch 51, loss 0.5264006853103638, acc=0.8669999837875366, loss=0.5264006853103638
test: epoch 51, loss 5.580941677093506, acc=0.2777777910232544, loss=5.580941677093506
train: epoch 52, loss 0.49779012799263, acc=0.8779444694519043, loss=0.49779012799263
test: epoch 52, loss 5.397608280181885, acc=0.2944444417953491, loss=5.397608280181885
train: epoch 53, loss 0.46056830883026123, acc=0.8855000138282776, loss=0.46056830883026123
test: epoch 53, loss 5.228460311889648, acc=0.28611111640930176, loss=5.228460311889648
train: epoch 54, loss 0.4339357018470764, acc=0.8940555453300476, loss=0.4339357018470764
test: epoch 54, loss 5.071177005767822, acc=0.2916666567325592, loss=5.071177005767822
train: epoch 55, loss 0.4197184145450592, acc=0.899055540561676, loss=0.4197184145450592
test: epoch 55, loss 4.97654390335083, acc=0.2916666567325592, loss=4.97654390335083
train: epoch 56, loss 0.3971826434135437, acc=0.905055582523346, loss=0.3971826434135437
test: epoch 56, loss 4.778677940368652, acc=0.2916666567325592, loss=4.778677940368652
train: epoch 57, loss 0.3721974790096283, acc=0.9152777791023254, loss=0.3721974790096283
test: epoch 57, loss 4.7171759605407715, acc=0.2916666567325592, loss=4.7171759605407715
train: epoch 58, loss 0.3582141697406769, acc=0.9190555810928345, loss=0.3582141697406769
test: epoch 58, loss 4.538559436798096, acc=0.2888889014720917, loss=4.538559436798096
train: epoch 59, loss 0.3312585949897766, acc=0.9230555295944214, loss=0.3312585949897766
test: epoch 59, loss 4.6345319747924805, acc=0.2944444417953491, loss=4.6345319747924805
train: epoch 60, loss 0.3203553855419159, acc=0.9243333339691162, loss=0.3203553855419159
test: epoch 60, loss 4.439557075500488, acc=0.2916666567325592, loss=4.439557075500488
train: epoch 61, loss 0.31352323293685913, acc=0.9304999709129333, loss=0.31352323293685913
test: epoch 61, loss 4.544780731201172, acc=0.2944444417953491, loss=4.544780731201172
train: epoch 62, loss 0.2974829375743866, acc=0.9355555772781372, loss=0.2974829375743866
test: epoch 62, loss 4.542570114135742, acc=0.2888889014720917, loss=4.542570114135742
train: epoch 63, loss 0.28911006450653076, acc=0.9365000128746033, loss=0.28911006450653076
test: epoch 63, loss 4.784450054168701, acc=0.28333333134651184, loss=4.784450054168701
train: epoch 64, loss 0.2641936242580414, acc=0.9430555701255798, loss=0.2641936242580414
test: epoch 64, loss 4.629113674163818, acc=0.28611111640930176, loss=4.629113674163818
train: epoch 65, loss 0.250483900308609, acc=0.9461110830307007, loss=0.250483900308609
test: epoch 65, loss 4.411938190460205, acc=0.2944444417953491, loss=4.411938190460205
train: epoch 66, loss 0.2501853406429291, acc=0.9469444155693054, loss=0.2501853406429291
test: epoch 66, loss 4.1840620040893555, acc=0.2805555462837219, loss=4.1840620040893555
train: epoch 67, loss 0.226394385099411, acc=0.9508333206176758, loss=0.226394385099411
test: epoch 67, loss 4.328939437866211, acc=0.3027777671813965, loss=4.328939437866211
train: epoch 68, loss 0.22229765355587006, acc=0.9521111249923706, loss=0.22229765355587006
test: epoch 68, loss 4.426508903503418, acc=0.2916666567325592, loss=4.426508903503418
train: epoch 69, loss 0.21935878694057465, acc=0.9544444680213928, loss=0.21935878694057465
test: epoch 69, loss 4.2673749923706055, acc=0.28611111640930176, loss=4.2673749923706055
train: epoch 70, loss 0.20953097939491272, acc=0.9582222104072571, loss=0.20953097939491272
test: epoch 70, loss 4.155324935913086, acc=0.2944444417953491, loss=4.155324935913086
train: epoch 71, loss 0.20781458914279938, acc=0.9564444422721863, loss=0.20781458914279938
test: epoch 71, loss 4.1073431968688965, acc=0.2916666567325592, loss=4.1073431968688965
train: epoch 72, loss 0.20042046904563904, acc=0.9595000147819519, loss=0.20042046904563904
test: epoch 72, loss 4.008029937744141, acc=0.30000001192092896, loss=4.008029937744141
train: epoch 73, loss 0.19178888201713562, acc=0.9593333601951599, loss=0.19178888201713562
test: epoch 73, loss 4.010023593902588, acc=0.29722222685813904, loss=4.010023593902588
train: epoch 74, loss 0.18623019754886627, acc=0.9619444608688354, loss=0.18623019754886627
test: epoch 74, loss 3.8846957683563232, acc=0.29722222685813904, loss=3.8846957683563232
train: epoch 75, loss 0.19052402675151825, acc=0.9631111025810242, loss=0.19052402675151825
test: epoch 75, loss 3.8848366737365723, acc=0.29722222685813904, loss=3.8848366737365723
train: epoch 76, loss 0.17167504131793976, acc=0.9673333168029785, loss=0.17167504131793976
test: epoch 76, loss 3.8255603313446045, acc=0.29722222685813904, loss=3.8255603313446045
train: epoch 77, loss 0.161676287651062, acc=0.9667778015136719, loss=0.161676287651062
test: epoch 77, loss 3.828691005706787, acc=0.3222222328186035, loss=3.828691005706787
train: epoch 78, loss 0.16330809891223907, acc=0.9692777991294861, loss=0.16330809891223907
test: epoch 78, loss 3.6624302864074707, acc=0.3027777671813965, loss=3.6624302864074707
train: epoch 79, loss 0.16408121585845947, acc=0.9677222371101379, loss=0.16408121585845947
test: epoch 79, loss 3.757079601287842, acc=0.3027777671813965, loss=3.757079601287842
train: epoch 80, loss 0.15221934020519257, acc=0.968500018119812, loss=0.15221934020519257
test: epoch 80, loss 3.574800729751587, acc=0.31388887763023376, loss=3.574800729751587
train: epoch 81, loss 0.16580839455127716, acc=0.9668333530426025, loss=0.16580839455127716
test: epoch 81, loss 3.493161678314209, acc=0.2944444417953491, loss=3.493161678314209
train: epoch 82, loss 0.14728258550167084, acc=0.9715555310249329, loss=0.14728258550167084
test: epoch 82, loss 3.527043342590332, acc=0.2944444417953491, loss=3.527043342590332
train: epoch 83, loss 0.14259545505046844, acc=0.9729999899864197, loss=0.14259545505046844
test: epoch 83, loss 3.681976079940796, acc=0.2888889014720917, loss=3.681976079940796
train: epoch 84, loss 0.13915787637233734, acc=0.9732221961021423, loss=0.13915787637233734
test: epoch 84, loss 3.496535301208496, acc=0.27222222089767456, loss=3.496535301208496
train: epoch 85, loss 0.13584910333156586, acc=0.9739999771118164, loss=0.13584910333156586
test: epoch 85, loss 3.618635416030884, acc=0.2916666567325592, loss=3.618635416030884
train: epoch 86, loss 0.13255178928375244, acc=0.9745555520057678, loss=0.13255178928375244
test: epoch 86, loss 3.5809168815612793, acc=0.2916666567325592, loss=3.5809168815612793
train: epoch 87, loss 0.12277863174676895, acc=0.9750555753707886, loss=0.12277863174676895
test: epoch 87, loss 3.571596384048462, acc=0.2888889014720917, loss=3.571596384048462
train: epoch 88, loss 0.11324361711740494, acc=0.9763888716697693, loss=0.11324361711740494
test: epoch 88, loss 3.2818031311035156, acc=0.2916666567325592, loss=3.2818031311035156
train: epoch 89, loss 0.11984105408191681, acc=0.9748888611793518, loss=0.11984105408191681
test: epoch 89, loss 3.195176362991333, acc=0.29722222685813904, loss=3.195176362991333
train: epoch 90, loss 0.12600845098495483, acc=0.977222204208374, loss=0.12600845098495483
test: epoch 90, loss 3.2751717567443848, acc=0.2944444417953491, loss=3.2751717567443848
train: epoch 91, loss 0.10518024116754532, acc=0.9785000085830688, loss=0.10518024116754532
test: epoch 91, loss 3.2192575931549072, acc=0.2944444417953491, loss=3.2192575931549072
train: epoch 92, loss 0.11268144845962524, acc=0.9779999852180481, loss=0.11268144845962524
test: epoch 92, loss 3.3182740211486816, acc=0.29722222685813904, loss=3.3182740211486816
train: epoch 93, loss 0.10818663984537125, acc=0.9796666502952576, loss=0.10818663984537125
test: epoch 93, loss 3.2986509799957275, acc=0.3027777671813965, loss=3.2986509799957275
train: epoch 94, loss 0.12386108189821243, acc=0.9779999852180481, loss=0.12386108189821243
test: epoch 94, loss 3.2305760383605957, acc=0.29722222685813904, loss=3.2305760383605957
train: epoch 95, loss 0.10195428878068924, acc=0.9796110987663269, loss=0.10195428878068924
test: epoch 95, loss 3.0624020099639893, acc=0.30000001192092896, loss=3.0624020099639893
train: epoch 96, loss 0.08954287320375443, acc=0.9821110963821411, loss=0.08954287320375443
test: epoch 96, loss 3.0292351245880127, acc=0.2777777910232544, loss=3.0292351245880127
train: epoch 97, loss 0.09788111597299576, acc=0.980222225189209, loss=0.09788111597299576
test: epoch 97, loss 3.075047492980957, acc=0.29722222685813904, loss=3.075047492980957
train: epoch 98, loss 0.11153583228588104, acc=0.9809444546699524, loss=0.11153583228588104
test: epoch 98, loss 3.143605947494507, acc=0.2916666567325592, loss=3.143605947494507
train: epoch 99, loss 0.08992528170347214, acc=0.9819999933242798, loss=0.08992528170347214
test: epoch 99, loss 3.1662509441375732, acc=0.3027777671813965, loss=3.1662509441375732
train: epoch 100, loss 0.08875972032546997, acc=0.9833333492279053, loss=0.08875972032546997
test: epoch 100, loss 3.161220073699951, acc=0.30000001192092896, loss=3.161220073699951
train: epoch 101, loss 0.08403041213750839, acc=0.984333336353302, loss=0.08403041213750839
test: epoch 101, loss 3.083125114440918, acc=0.31388887763023376, loss=3.083125114440918
train: epoch 102, loss 0.09502989798784256, acc=0.9816111326217651, loss=0.09502989798784256
test: epoch 102, loss 3.061617851257324, acc=0.3305555582046509, loss=3.061617851257324
train: epoch 103, loss 0.08814792335033417, acc=0.9840555787086487, loss=0.08814792335033417
test: epoch 103, loss 3.1418709754943848, acc=0.3027777671813965, loss=3.1418709754943848
train: epoch 104, loss 0.0942583903670311, acc=0.9825000166893005, loss=0.0942583903670311
test: epoch 104, loss 3.0520427227020264, acc=0.30000001192092896, loss=3.0520427227020264
train: epoch 105, loss 0.08098097145557404, acc=0.9836666584014893, loss=0.08098097145557404
test: epoch 105, loss 2.9384078979492188, acc=0.2944444417953491, loss=2.9384078979492188
train: epoch 106, loss 0.08872739225625992, acc=0.9841111302375793, loss=0.08872739225625992
test: epoch 106, loss 3.1396613121032715, acc=0.29722222685813904, loss=3.1396613121032715
train: epoch 107, loss 0.08209104835987091, acc=0.9849444627761841, loss=0.08209104835987091
test: epoch 107, loss 2.8469486236572266, acc=0.31111112236976624, loss=2.8469486236572266
train: epoch 108, loss 0.07329608500003815, acc=0.9853888750076294, loss=0.07329608500003815
test: epoch 108, loss 2.9773683547973633, acc=0.31111112236976624, loss=2.9773683547973633
train: epoch 109, loss 0.07328653335571289, acc=0.9850000143051147, loss=0.07328653335571289
test: epoch 109, loss 3.011124849319458, acc=0.2944444417953491, loss=3.011124849319458
train: epoch 110, loss 0.0731021836400032, acc=0.9863333106040955, loss=0.0731021836400032
test: epoch 110, loss 3.1493070125579834, acc=0.3055555522441864, loss=3.1493070125579834
train: epoch 111, loss 0.0723501592874527, acc=0.984333336353302, loss=0.0723501592874527
test: epoch 111, loss 3.050370931625366, acc=0.31388887763023376, loss=3.050370931625366
train: epoch 112, loss 0.06491556763648987, acc=0.9872778058052063, loss=0.06491556763648987
test: epoch 112, loss 2.9023749828338623, acc=0.3055555522441864, loss=2.9023749828338623
train: epoch 113, loss 0.0778251513838768, acc=0.9855555295944214, loss=0.0778251513838768
test: epoch 113, loss 2.853790283203125, acc=0.31111112236976624, loss=2.853790283203125
train: epoch 114, loss 0.06883791089057922, acc=0.9857777953147888, loss=0.06883791089057922
test: epoch 114, loss 2.7896006107330322, acc=0.2888889014720917, loss=2.7896006107330322
train: epoch 115, loss 0.06545129418373108, acc=0.9861111044883728, loss=0.06545129418373108
test: epoch 115, loss 3.0836074352264404, acc=0.2916666567325592, loss=3.0836074352264404
train: epoch 116, loss 0.0629982128739357, acc=0.987333357334137, loss=0.0629982128739357
test: epoch 116, loss 2.776777982711792, acc=0.2888889014720917, loss=2.776777982711792
train: epoch 117, loss 0.06301141530275345, acc=0.9874444603919983, loss=0.06301141530275345
test: epoch 117, loss 2.91369366645813, acc=0.26944443583488464, loss=2.91369366645813
train: epoch 118, loss 0.07246870547533035, acc=0.9864444732666016, loss=0.07246870547533035
test: epoch 118, loss 3.0227842330932617, acc=0.2944444417953491, loss=3.0227842330932617
train: epoch 119, loss 0.07042670249938965, acc=0.9866111278533936, loss=0.07042670249938965
test: epoch 119, loss 2.95465087890625, acc=0.2916666567325592, loss=2.95465087890625
train: epoch 120, loss 0.06979233026504517, acc=0.9883888959884644, loss=0.06979233026504517
test: epoch 120, loss 2.811335563659668, acc=0.2916666567325592, loss=2.811335563659668
train: epoch 121, loss 0.057646654546260834, acc=0.9878333210945129, loss=0.057646654546260834
test: epoch 121, loss 3.017085075378418, acc=0.30000001192092896, loss=3.017085075378418
train: epoch 122, loss 0.05923386290669441, acc=0.9879999756813049, loss=0.05923386290669441
test: epoch 122, loss 2.9577596187591553, acc=0.3055555522441864, loss=2.9577596187591553
train: epoch 123, loss 0.05985398218035698, acc=0.9880555272102356, loss=0.05985398218035698
test: epoch 123, loss 2.793689727783203, acc=0.30000001192092896, loss=2.793689727783203
train: epoch 124, loss 0.06036948412656784, acc=0.9888888597488403, loss=0.06036948412656784
test: epoch 124, loss 3.029385566711426, acc=0.2805555462837219, loss=3.029385566711426
train: epoch 125, loss 0.059612635523080826, acc=0.9877777695655823, loss=0.059612635523080826
test: epoch 125, loss 2.9927291870117188, acc=0.30000001192092896, loss=2.9927291870117188
train: epoch 126, loss 0.06558598577976227, acc=0.9877777695655823, loss=0.06558598577976227
test: epoch 126, loss 3.0429940223693848, acc=0.2944444417953491, loss=3.0429940223693848
train: epoch 127, loss 0.052405036985874176, acc=0.9895555377006531, loss=0.052405036985874176
test: epoch 127, loss 2.8102264404296875, acc=0.28611111640930176, loss=2.8102264404296875
train: epoch 128, loss 0.05631483346223831, acc=0.9894999861717224, loss=0.05631483346223831
test: epoch 128, loss 2.789889335632324, acc=0.29722222685813904, loss=2.789889335632324
train: epoch 129, loss 0.06570520997047424, acc=0.9879999756813049, loss=0.06570520997047424
test: epoch 129, loss 2.7638626098632812, acc=0.2888889014720917, loss=2.7638626098632812
train: epoch 130, loss 0.05697297304868698, acc=0.9893888831138611, loss=0.05697297304868698
test: epoch 130, loss 2.6975505352020264, acc=0.28611111640930176, loss=2.6975505352020264
train: epoch 131, loss 0.04925813153386116, acc=0.9905555844306946, loss=0.04925813153386116
test: epoch 131, loss 2.832231283187866, acc=0.28611111640930176, loss=2.832231283187866
train: epoch 132, loss 0.05466899648308754, acc=0.9893333315849304, loss=0.05466899648308754
test: epoch 132, loss 2.725477933883667, acc=0.3027777671813965, loss=2.725477933883667
train: epoch 133, loss 0.05310981720685959, acc=0.9890555739402771, loss=0.05310981720685959
test: epoch 133, loss 2.7373135089874268, acc=0.3055555522441864, loss=2.7373135089874268
train: epoch 134, loss 0.05024861544370651, acc=0.9902222156524658, loss=0.05024861544370651
test: epoch 134, loss 2.6944642066955566, acc=0.32499998807907104, loss=2.6944642066955566
train: epoch 135, loss 0.05708766356110573, acc=0.9904444217681885, loss=0.05708766356110573
test: epoch 135, loss 2.7431411743164062, acc=0.32499998807907104, loss=2.7431411743164062
train: epoch 136, loss 0.05047687888145447, acc=0.9902777671813965, loss=0.05047687888145447
test: epoch 136, loss 2.6765804290771484, acc=0.3083333373069763, loss=2.6765804290771484
train: epoch 137, loss 0.049671512097120285, acc=0.9903333187103271, loss=0.049671512097120285
test: epoch 137, loss 2.7316246032714844, acc=0.3055555522441864, loss=2.7316246032714844
train: epoch 138, loss 0.0562230721116066, acc=0.9891666769981384, loss=0.0562230721116066
test: epoch 138, loss 2.7276451587677, acc=0.28333333134651184, loss=2.7276451587677
train: epoch 139, loss 0.04890422523021698, acc=0.9908888936042786, loss=0.04890422523021698
test: epoch 139, loss 2.686523199081421, acc=0.29722222685813904, loss=2.686523199081421
train: epoch 140, loss 0.04739462211728096, acc=0.9910555481910706, loss=0.04739462211728096
test: epoch 140, loss 2.7440133094787598, acc=0.31111112236976624, loss=2.7440133094787598
train: epoch 141, loss 0.048839591443538666, acc=0.9921666383743286, loss=0.048839591443538666
test: epoch 141, loss 2.673891305923462, acc=0.3166666626930237, loss=2.673891305923462
train: epoch 142, loss 0.05007756128907204, acc=0.9909444451332092, loss=0.05007756128907204
test: epoch 142, loss 2.637784481048584, acc=0.3166666626930237, loss=2.637784481048584
train: epoch 143, loss 0.0452372170984745, acc=0.9905555844306946, loss=0.0452372170984745
test: epoch 143, loss 2.648470878601074, acc=0.29722222685813904, loss=2.648470878601074
train: epoch 144, loss 0.0503075011074543, acc=0.9912222027778625, loss=0.0503075011074543
test: epoch 144, loss 2.7205452919006348, acc=0.30000001192092896, loss=2.7205452919006348
train: epoch 145, loss 0.04520920291543007, acc=0.99144446849823, loss=0.04520920291543007
test: epoch 145, loss 2.6994030475616455, acc=0.2916666567325592, loss=2.6994030475616455
train: epoch 146, loss 0.046358730643987656, acc=0.9909999966621399, loss=0.046358730643987656
test: epoch 146, loss 2.780125617980957, acc=0.29722222685813904, loss=2.780125617980957
train: epoch 147, loss 0.04140015318989754, acc=0.991777777671814, loss=0.04140015318989754
test: epoch 147, loss 2.6708121299743652, acc=0.31388887763023376, loss=2.6708121299743652
train: epoch 148, loss 0.04517969489097595, acc=0.9898889064788818, loss=0.04517969489097595
test: epoch 148, loss 2.850851058959961, acc=0.2916666567325592, loss=2.850851058959961
train: epoch 149, loss 0.04472663626074791, acc=0.9908333420753479, loss=0.04472663626074791
test: epoch 149, loss 2.779230833053589, acc=0.2750000059604645, loss=2.779230833053589
train: epoch 150, loss 0.04249987006187439, acc=0.992555558681488, loss=0.04249987006187439
test: epoch 150, loss 2.740144968032837, acc=0.29722222685813904, loss=2.740144968032837
