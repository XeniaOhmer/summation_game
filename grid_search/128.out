# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=1.5", "--temp_decay=1", "--one_hot=0", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=1838748319, receiver_embed_dim=128, save_run=0, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=1838748319, receiver_embed_dim=128, save_run=False, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.4745168685913086, acc=0.1455555558204651, loss=2.4745168685913086
test: epoch 1, loss 4.541255474090576, acc=0.07222222536802292, loss=4.541255474090576
train: epoch 2, loss 1.777657389640808, acc=0.2795555591583252, loss=1.777657389640808
test: epoch 2, loss 3.099794626235962, acc=0.11666666716337204, loss=3.099794626235962
train: epoch 3, loss 1.4826217889785767, acc=0.37505555152893066, loss=1.4826217889785767
test: epoch 3, loss 2.224684953689575, acc=0.23888888955116272, loss=2.224684953689575
train: epoch 4, loss 1.3149362802505493, acc=0.4483333230018616, loss=1.3149362802505493
test: epoch 4, loss 2.5935676097869873, acc=0.21666666865348816, loss=2.5935676097869873
train: epoch 5, loss 1.1807302236557007, acc=0.5031111240386963, loss=1.1807302236557007
test: epoch 5, loss 3.0104587078094482, acc=0.16388888657093048, loss=3.0104587078094482
train: epoch 6, loss 1.0535032749176025, acc=0.5569999814033508, loss=1.0535032749176025
test: epoch 6, loss 2.402696371078491, acc=0.25833332538604736, loss=2.402696371078491
train: epoch 7, loss 1.004784345626831, acc=0.5840555429458618, loss=1.004784345626831
test: epoch 7, loss 2.331040143966675, acc=0.22499999403953552, loss=2.331040143966675
train: epoch 8, loss 0.9234927296638489, acc=0.6192222237586975, loss=0.9234927296638489
test: epoch 8, loss 1.9043570756912231, acc=0.31388887763023376, loss=1.9043570756912231
train: epoch 9, loss 0.8506882786750793, acc=0.6483888626098633, loss=0.8506882786750793
test: epoch 9, loss 2.646057605743408, acc=0.2750000059604645, loss=2.646057605743408
train: epoch 10, loss 0.8390568494796753, acc=0.6586111187934875, loss=0.8390568494796753
test: epoch 10, loss 1.893517255783081, acc=0.3472222089767456, loss=1.893517255783081
train: epoch 11, loss 0.7864375114440918, acc=0.6830000281333923, loss=0.7864375114440918
test: epoch 11, loss 1.877811074256897, acc=0.35555556416511536, loss=1.877811074256897
train: epoch 12, loss 0.772436797618866, acc=0.6786666512489319, loss=0.772436797618866
test: epoch 12, loss 2.1028575897216797, acc=0.2777777910232544, loss=2.1028575897216797
train: epoch 13, loss 0.7135087251663208, acc=0.7071666717529297, loss=0.7135087251663208
test: epoch 13, loss 2.512544870376587, acc=0.25833332538604736, loss=2.512544870376587
train: epoch 14, loss 0.7091264128684998, acc=0.7114999890327454, loss=0.7091264128684998
test: epoch 14, loss 2.1250133514404297, acc=0.35555556416511536, loss=2.1250133514404297
train: epoch 15, loss 0.6760029196739197, acc=0.7239444255828857, loss=0.6760029196739197
test: epoch 15, loss 1.9102604389190674, acc=0.3916666805744171, loss=1.9102604389190674
train: epoch 16, loss 0.6450627446174622, acc=0.7357222437858582, loss=0.6450627446174622
test: epoch 16, loss 1.8165090084075928, acc=0.33888888359069824, loss=1.8165090084075928
train: epoch 17, loss 0.598710298538208, acc=0.7546666860580444, loss=0.598710298538208
test: epoch 17, loss 1.9092402458190918, acc=0.39722222089767456, loss=1.9092402458190918
train: epoch 18, loss 0.5988368988037109, acc=0.7581111192703247, loss=0.5988368988037109
test: epoch 18, loss 1.8806194067001343, acc=0.2888889014720917, loss=1.8806194067001343
train: epoch 19, loss 0.5846734642982483, acc=0.762333333492279, loss=0.5846734642982483
test: epoch 19, loss 1.9724674224853516, acc=0.3333333432674408, loss=1.9724674224853516
train: epoch 20, loss 0.5774673223495483, acc=0.7618333101272583, loss=0.5774673223495483
test: epoch 20, loss 1.7500251531600952, acc=0.375, loss=1.7500251531600952
train: epoch 21, loss 0.5523235201835632, acc=0.7741666436195374, loss=0.5523235201835632
test: epoch 21, loss 1.449331521987915, acc=0.4583333432674408, loss=1.449331521987915
train: epoch 22, loss 0.5618767738342285, acc=0.7715555429458618, loss=0.5618767738342285
test: epoch 22, loss 1.8604178428649902, acc=0.36666667461395264, loss=1.8604178428649902
train: epoch 23, loss 0.5238672494888306, acc=0.7892777919769287, loss=0.5238672494888306
test: epoch 23, loss 2.107487440109253, acc=0.29722222685813904, loss=2.107487440109253
train: epoch 24, loss 0.534885048866272, acc=0.7818889021873474, loss=0.534885048866272
test: epoch 24, loss 1.6752948760986328, acc=0.3638888895511627, loss=1.6752948760986328
train: epoch 25, loss 0.5592758655548096, acc=0.7719444632530212, loss=0.5592758655548096
test: epoch 25, loss 1.7224032878875732, acc=0.4277777671813965, loss=1.7224032878875732
train: epoch 26, loss 0.5036150813102722, acc=0.7967222332954407, loss=0.5036150813102722
test: epoch 26, loss 1.796666145324707, acc=0.40833333134651184, loss=1.796666145324707
train: epoch 27, loss 0.4776889979839325, acc=0.808055579662323, loss=0.4776889979839325
test: epoch 27, loss 1.6864522695541382, acc=0.38055557012557983, loss=1.6864522695541382
train: epoch 28, loss 0.46967536211013794, acc=0.8113889098167419, loss=0.46967536211013794
test: epoch 28, loss 1.7037492990493774, acc=0.3722222149372101, loss=1.7037492990493774
train: epoch 29, loss 0.46634480357170105, acc=0.8151666522026062, loss=0.46634480357170105
test: epoch 29, loss 1.4719586372375488, acc=0.3777777850627899, loss=1.4719586372375488
train: epoch 30, loss 0.4529482126235962, acc=0.8195555806159973, loss=0.4529482126235962
test: epoch 30, loss 2.213183641433716, acc=0.3055555522441864, loss=2.213183641433716
train: epoch 31, loss 0.44622987508773804, acc=0.8220555782318115, loss=0.44622987508773804
test: epoch 31, loss 1.4395989179611206, acc=0.4888888895511627, loss=1.4395989179611206
train: epoch 32, loss 0.4683872163295746, acc=0.8144999742507935, loss=0.4683872163295746
test: epoch 32, loss 1.7060092687606812, acc=0.43888887763023376, loss=1.7060092687606812
train: epoch 33, loss 0.42094117403030396, acc=0.8315555453300476, loss=0.42094117403030396
test: epoch 33, loss 1.4398666620254517, acc=0.40833333134651184, loss=1.4398666620254517
train: epoch 34, loss 0.41113170981407166, acc=0.8362777829170227, loss=0.41113170981407166
test: epoch 34, loss 1.924174427986145, acc=0.3888888955116272, loss=1.924174427986145
train: epoch 35, loss 0.4264129400253296, acc=0.8293333053588867, loss=0.4264129400253296
test: epoch 35, loss 1.5253889560699463, acc=0.45277777314186096, loss=1.5253889560699463
train: epoch 36, loss 0.4021085202693939, acc=0.8414999842643738, loss=0.4021085202693939
test: epoch 36, loss 1.5247160196304321, acc=0.4694444537162781, loss=1.5247160196304321
train: epoch 37, loss 0.396433562040329, acc=0.8437777757644653, loss=0.396433562040329
test: epoch 37, loss 1.5635371208190918, acc=0.41111111640930176, loss=1.5635371208190918
train: epoch 38, loss 0.3987712264060974, acc=0.8422777652740479, loss=0.3987712264060974
test: epoch 38, loss 1.304530143737793, acc=0.5222222208976746, loss=1.304530143737793
train: epoch 39, loss 0.3734109401702881, acc=0.8541111350059509, loss=0.3734109401702881
test: epoch 39, loss 1.9890183210372925, acc=0.34166666865348816, loss=1.9890183210372925
train: epoch 40, loss 0.3967120051383972, acc=0.8455555438995361, loss=0.3967120051383972
test: epoch 40, loss 1.8193490505218506, acc=0.35555556416511536, loss=1.8193490505218506
train: epoch 41, loss 0.3736838400363922, acc=0.8495000004768372, loss=0.3736838400363922
test: epoch 41, loss 1.8385956287384033, acc=0.4277777671813965, loss=1.8385956287384033
train: epoch 42, loss 0.3440738022327423, acc=0.86644446849823, loss=0.3440738022327423
test: epoch 42, loss 1.9276174306869507, acc=0.35277777910232544, loss=1.9276174306869507
train: epoch 43, loss 0.3617446720600128, acc=0.8568888902664185, loss=0.3617446720600128
test: epoch 43, loss 1.3387165069580078, acc=0.4749999940395355, loss=1.3387165069580078
train: epoch 44, loss 0.3369651436805725, acc=0.8682777881622314, loss=0.3369651436805725
test: epoch 44, loss 1.306357741355896, acc=0.5027777552604675, loss=1.306357741355896
train: epoch 45, loss 0.3508661687374115, acc=0.8633333444595337, loss=0.3508661687374115
test: epoch 45, loss 1.4419736862182617, acc=0.36944442987442017, loss=1.4419736862182617
train: epoch 46, loss 0.38083693385124207, acc=0.8479999899864197, loss=0.38083693385124207
test: epoch 46, loss 1.5434553623199463, acc=0.4888888895511627, loss=1.5434553623199463
train: epoch 47, loss 0.34071025252342224, acc=0.8676666617393494, loss=0.34071025252342224
test: epoch 47, loss 1.6975294351577759, acc=0.4277777671813965, loss=1.6975294351577759
train: epoch 48, loss 0.3102264702320099, acc=0.8806666731834412, loss=0.3102264702320099
test: epoch 48, loss 1.3796229362487793, acc=0.5, loss=1.3796229362487793
train: epoch 49, loss 0.324382483959198, acc=0.8727222084999084, loss=0.324382483959198
test: epoch 49, loss 1.6722218990325928, acc=0.5, loss=1.6722218990325928
train: epoch 50, loss 0.3434238135814667, acc=0.86772221326828, loss=0.3434238135814667
test: epoch 50, loss 1.5841325521469116, acc=0.5305555462837219, loss=1.5841325521469116
train: epoch 51, loss 0.32018736004829407, acc=0.8746111392974854, loss=0.32018736004829407
test: epoch 51, loss 1.363187313079834, acc=0.46388888359069824, loss=1.363187313079834
train: epoch 52, loss 0.3094710111618042, acc=0.8774999976158142, loss=0.3094710111618042
test: epoch 52, loss 1.4037325382232666, acc=0.5055555701255798, loss=1.4037325382232666
train: epoch 53, loss 0.3128790259361267, acc=0.8767777681350708, loss=0.3128790259361267
test: epoch 53, loss 1.1749018430709839, acc=0.5527777671813965, loss=1.1749018430709839
train: epoch 54, loss 0.3127762973308563, acc=0.8756111264228821, loss=0.3127762973308563
test: epoch 54, loss 1.2991359233856201, acc=0.5138888955116272, loss=1.2991359233856201
train: epoch 55, loss 0.3099975883960724, acc=0.8770555257797241, loss=0.3099975883960724
test: epoch 55, loss 1.609683632850647, acc=0.49166667461395264, loss=1.609683632850647
train: epoch 56, loss 0.2964113652706146, acc=0.882888913154602, loss=0.2964113652706146
test: epoch 56, loss 1.6403928995132446, acc=0.42500001192092896, loss=1.6403928995132446
train: epoch 57, loss 0.30384355783462524, acc=0.8836666941642761, loss=0.30384355783462524
test: epoch 57, loss 1.6694852113723755, acc=0.45277777314186096, loss=1.6694852113723755
train: epoch 58, loss 0.32054129242897034, acc=0.8766666650772095, loss=0.32054129242897034
test: epoch 58, loss 1.4969229698181152, acc=0.4888888895511627, loss=1.4969229698181152
train: epoch 59, loss 0.25722736120224, acc=0.8995000123977661, loss=0.25722736120224
test: epoch 59, loss 1.6027374267578125, acc=0.5222222208976746, loss=1.6027374267578125
train: epoch 60, loss 0.2873668372631073, acc=0.8879444599151611, loss=0.2873668372631073
test: epoch 60, loss 1.8590216636657715, acc=0.4027777910232544, loss=1.8590216636657715
train: epoch 61, loss 0.3279781639575958, acc=0.8751111030578613, loss=0.3279781639575958
test: epoch 61, loss 1.521668553352356, acc=0.5388888716697693, loss=1.521668553352356
train: epoch 62, loss 0.2797805666923523, acc=0.8924444317817688, loss=0.2797805666923523
test: epoch 62, loss 1.2270824909210205, acc=0.5694444179534912, loss=1.2270824909210205
train: epoch 63, loss 0.2749673128128052, acc=0.8949999809265137, loss=0.2749673128128052
test: epoch 63, loss 1.01603102684021, acc=0.5722222328186035, loss=1.01603102684021
train: epoch 64, loss 0.28026244044303894, acc=0.8901110887527466, loss=0.28026244044303894
test: epoch 64, loss 1.5085219144821167, acc=0.4749999940395355, loss=1.5085219144821167
train: epoch 65, loss 0.26930102705955505, acc=0.8965555429458618, loss=0.26930102705955505
test: epoch 65, loss 1.3449827432632446, acc=0.5305555462837219, loss=1.3449827432632446
train: epoch 66, loss 0.2922293245792389, acc=0.886888861656189, loss=0.2922293245792389
test: epoch 66, loss 1.389080286026001, acc=0.519444465637207, loss=1.389080286026001
train: epoch 67, loss 0.2711421549320221, acc=0.8955555558204651, loss=0.2711421549320221
test: epoch 67, loss 1.4245198965072632, acc=0.5361111164093018, loss=1.4245198965072632
train: epoch 68, loss 0.2769434452056885, acc=0.8924999833106995, loss=0.2769434452056885
test: epoch 68, loss 1.2954062223434448, acc=0.5638889074325562, loss=1.2954062223434448
train: epoch 69, loss 0.2587015926837921, acc=0.9027777910232544, loss=0.2587015926837921
test: epoch 69, loss 1.5636646747589111, acc=0.5444444417953491, loss=1.5636646747589111
train: epoch 70, loss 0.2695823609828949, acc=0.8978888988494873, loss=0.2695823609828949
test: epoch 70, loss 1.5539398193359375, acc=0.5527777671813965, loss=1.5539398193359375
train: epoch 71, loss 0.28001394867897034, acc=0.8931666612625122, loss=0.28001394867897034
test: epoch 71, loss 1.7192027568817139, acc=0.4555555582046509, loss=1.7192027568817139
train: epoch 72, loss 0.2510254979133606, acc=0.9035000205039978, loss=0.2510254979133606
test: epoch 72, loss 1.6920164823532104, acc=0.519444465637207, loss=1.6920164823532104
train: epoch 73, loss 0.24502761662006378, acc=0.9047222137451172, loss=0.24502761662006378
test: epoch 73, loss 1.234283685684204, acc=0.5472221970558167, loss=1.234283685684204
train: epoch 74, loss 0.25490060448646545, acc=0.902388870716095, loss=0.25490060448646545
test: epoch 74, loss 1.2043163776397705, acc=0.5805555582046509, loss=1.2043163776397705
train: epoch 75, loss 0.27994754910469055, acc=0.8923333287239075, loss=0.27994754910469055
test: epoch 75, loss 1.0300935506820679, acc=0.6138888597488403, loss=1.0300935506820679
train: epoch 76, loss 0.24222059547901154, acc=0.9043333530426025, loss=0.24222059547901154
test: epoch 76, loss 1.3197230100631714, acc=0.4833333194255829, loss=1.3197230100631714
train: epoch 77, loss 0.24608609080314636, acc=0.9062222242355347, loss=0.24608609080314636
test: epoch 77, loss 1.392024040222168, acc=0.5138888955116272, loss=1.392024040222168
train: epoch 78, loss 0.24548879265785217, acc=0.9039999842643738, loss=0.24548879265785217
test: epoch 78, loss 1.1881741285324097, acc=0.5777778029441833, loss=1.1881741285324097
train: epoch 79, loss 0.2385542392730713, acc=0.9071666598320007, loss=0.2385542392730713
test: epoch 79, loss 1.487186074256897, acc=0.42222222685813904, loss=1.487186074256897
train: epoch 80, loss 0.24927785992622375, acc=0.9056110978126526, loss=0.24927785992622375
test: epoch 80, loss 1.4330776929855347, acc=0.4722222089767456, loss=1.4330776929855347
train: epoch 81, loss 0.23183949291706085, acc=0.9089444279670715, loss=0.23183949291706085
test: epoch 81, loss 1.6313531398773193, acc=0.4555555582046509, loss=1.6313531398773193
train: epoch 82, loss 0.24299651384353638, acc=0.9078333377838135, loss=0.24299651384353638
test: epoch 82, loss 1.3451545238494873, acc=0.5583333373069763, loss=1.3451545238494873
train: epoch 83, loss 0.2502667307853699, acc=0.9035555720329285, loss=0.2502667307853699
test: epoch 83, loss 1.4116085767745972, acc=0.5166666507720947, loss=1.4116085767745972
train: epoch 84, loss 0.21423141658306122, acc=0.9175000190734863, loss=0.21423141658306122
test: epoch 84, loss 1.2318187952041626, acc=0.46388888359069824, loss=1.2318187952041626
train: epoch 85, loss 0.239085853099823, acc=0.9118333458900452, loss=0.239085853099823
test: epoch 85, loss 1.166321039199829, acc=0.6138888597488403, loss=1.166321039199829
train: epoch 86, loss 0.2662813365459442, acc=0.8975555300712585, loss=0.2662813365459442
test: epoch 86, loss 1.502750039100647, acc=0.4722222089767456, loss=1.502750039100647
train: epoch 87, loss 0.22244398295879364, acc=0.9146666526794434, loss=0.22244398295879364
test: epoch 87, loss 1.3935446739196777, acc=0.5138888955116272, loss=1.3935446739196777
train: epoch 88, loss 0.24737489223480225, acc=0.9063888788223267, loss=0.24737489223480225
test: epoch 88, loss 1.256243109703064, acc=0.5138888955116272, loss=1.256243109703064
train: epoch 89, loss 0.2512744963169098, acc=0.9029444456100464, loss=0.2512744963169098
test: epoch 89, loss 1.0387780666351318, acc=0.5527777671813965, loss=1.0387780666351318
train: epoch 90, loss 0.20934240520000458, acc=0.9199444651603699, loss=0.20934240520000458
test: epoch 90, loss 1.2571780681610107, acc=0.5638889074325562, loss=1.2571780681610107
train: epoch 91, loss 0.21144957840442657, acc=0.9190555810928345, loss=0.21144957840442657
test: epoch 91, loss 1.1725257635116577, acc=0.49166667461395264, loss=1.1725257635116577
train: epoch 92, loss 0.22332781553268433, acc=0.9117777943611145, loss=0.22332781553268433
test: epoch 92, loss 1.0244460105895996, acc=0.6083333492279053, loss=1.0244460105895996
train: epoch 93, loss 0.23157896101474762, acc=0.9096666574478149, loss=0.23157896101474762
test: epoch 93, loss 1.2752405405044556, acc=0.5583333373069763, loss=1.2752405405044556
train: epoch 94, loss 0.24138255417346954, acc=0.9096666574478149, loss=0.24138255417346954
test: epoch 94, loss 1.2563484907150269, acc=0.5444444417953491, loss=1.2563484907150269
train: epoch 95, loss 0.23646588623523712, acc=0.910277783870697, loss=0.23646588623523712
test: epoch 95, loss 1.2825959920883179, acc=0.5555555820465088, loss=1.2825959920883179
train: epoch 96, loss 0.2003822773694992, acc=0.9240555763244629, loss=0.2003822773694992
test: epoch 96, loss 1.1148806810379028, acc=0.5555555820465088, loss=1.1148806810379028
train: epoch 97, loss 0.2041631042957306, acc=0.9190000295639038, loss=0.2041631042957306
test: epoch 97, loss 1.2091766595840454, acc=0.5555555820465088, loss=1.2091766595840454
train: epoch 98, loss 0.22789044678211212, acc=0.9125000238418579, loss=0.22789044678211212
test: epoch 98, loss 1.2298431396484375, acc=0.6083333492279053, loss=1.2298431396484375
train: epoch 99, loss 0.25964492559432983, acc=0.9012777805328369, loss=0.25964492559432983
test: epoch 99, loss 1.2204898595809937, acc=0.5527777671813965, loss=1.2204898595809937
train: epoch 100, loss 0.1912340223789215, acc=0.9248889088630676, loss=0.1912340223789215
test: epoch 100, loss 1.1842975616455078, acc=0.5972222089767456, loss=1.1842975616455078
train: epoch 101, loss 0.23827065527439117, acc=0.9092777967453003, loss=0.23827065527439117
test: epoch 101, loss 1.2512239217758179, acc=0.519444465637207, loss=1.2512239217758179
train: epoch 102, loss 0.18973301351070404, acc=0.9263888597488403, loss=0.18973301351070404
test: epoch 102, loss 1.5346330404281616, acc=0.44999998807907104, loss=1.5346330404281616
train: epoch 103, loss 0.22607778012752533, acc=0.9154999852180481, loss=0.22607778012752533
test: epoch 103, loss 1.6256299018859863, acc=0.49166667461395264, loss=1.6256299018859863
train: epoch 104, loss 0.18847008049488068, acc=0.9281666874885559, loss=0.18847008049488068
test: epoch 104, loss 1.3372728824615479, acc=0.5638889074325562, loss=1.3372728824615479
train: epoch 105, loss 0.2222709059715271, acc=0.9154444336891174, loss=0.2222709059715271
test: epoch 105, loss 1.6254994869232178, acc=0.4555555582046509, loss=1.6254994869232178
train: epoch 106, loss 0.2138456404209137, acc=0.9176111221313477, loss=0.2138456404209137
test: epoch 106, loss 1.1803553104400635, acc=0.550000011920929, loss=1.1803553104400635
train: epoch 107, loss 0.1937493532896042, acc=0.9263333082199097, loss=0.1937493532896042
test: epoch 107, loss 1.7959181070327759, acc=0.5111111402511597, loss=1.7959181070327759
train: epoch 108, loss 0.19851624965667725, acc=0.9245555400848389, loss=0.19851624965667725
test: epoch 108, loss 1.2889070510864258, acc=0.5472221970558167, loss=1.2889070510864258
train: epoch 109, loss 0.20145870745182037, acc=0.9248889088630676, loss=0.20145870745182037
test: epoch 109, loss 1.2478339672088623, acc=0.5666666626930237, loss=1.2478339672088623
train: epoch 110, loss 0.19049571454524994, acc=0.9278888702392578, loss=0.19049571454524994
test: epoch 110, loss 1.2587089538574219, acc=0.6305555701255798, loss=1.2587089538574219
train: epoch 111, loss 0.21370744705200195, acc=0.9179444313049316, loss=0.21370744705200195
test: epoch 111, loss 1.7513628005981445, acc=0.5555555820465088, loss=1.7513628005981445
train: epoch 112, loss 0.18907535076141357, acc=0.9266111254692078, loss=0.18907535076141357
test: epoch 112, loss 1.571753978729248, acc=0.5138888955116272, loss=1.571753978729248
train: epoch 113, loss 0.1990724354982376, acc=0.9242777824401855, loss=0.1990724354982376
test: epoch 113, loss 1.3537437915802002, acc=0.4749999940395355, loss=1.3537437915802002
train: epoch 114, loss 0.1921694576740265, acc=0.9279999732971191, loss=0.1921694576740265
test: epoch 114, loss 1.345882534980774, acc=0.5722222328186035, loss=1.345882534980774
train: epoch 115, loss 0.17885231971740723, acc=0.9312777519226074, loss=0.17885231971740723
test: epoch 115, loss 1.434425950050354, acc=0.5222222208976746, loss=1.434425950050354
train: epoch 116, loss 0.22138039767742157, acc=0.9164999723434448, loss=0.22138039767742157
test: epoch 116, loss 1.0607595443725586, acc=0.6305555701255798, loss=1.0607595443725586
train: epoch 117, loss 0.19269220530986786, acc=0.9278333187103271, loss=0.19269220530986786
test: epoch 117, loss 1.4094204902648926, acc=0.5083333253860474, loss=1.4094204902648926
train: epoch 118, loss 0.19588658213615417, acc=0.9265555739402771, loss=0.19588658213615417
test: epoch 118, loss 1.4852285385131836, acc=0.5416666865348816, loss=1.4852285385131836
train: epoch 119, loss 0.18956024944782257, acc=0.9272222518920898, loss=0.18956024944782257
test: epoch 119, loss 1.6911652088165283, acc=0.5277777910232544, loss=1.6911652088165283
train: epoch 120, loss 0.1803189516067505, acc=0.9323889017105103, loss=0.1803189516067505
test: epoch 120, loss 1.5960839986801147, acc=0.5027777552604675, loss=1.5960839986801147
train: epoch 121, loss 0.1949310302734375, acc=0.9273889064788818, loss=0.1949310302734375
test: epoch 121, loss 1.0329461097717285, acc=0.5722222328186035, loss=1.0329461097717285
train: epoch 122, loss 0.18730074167251587, acc=0.9269999861717224, loss=0.18730074167251587
test: epoch 122, loss 1.2048169374465942, acc=0.5805555582046509, loss=1.2048169374465942
train: epoch 123, loss 0.18848270177841187, acc=0.9275000095367432, loss=0.18848270177841187
test: epoch 123, loss 1.3271311521530151, acc=0.5388888716697693, loss=1.3271311521530151
train: epoch 124, loss 0.18922795355319977, acc=0.9282222390174866, loss=0.18922795355319977
test: epoch 124, loss 1.365035057067871, acc=0.519444465637207, loss=1.365035057067871
train: epoch 125, loss 0.17567075788974762, acc=0.9316666722297668, loss=0.17567075788974762
test: epoch 125, loss 1.3225911855697632, acc=0.5666666626930237, loss=1.3225911855697632
train: epoch 126, loss 0.18069428205490112, acc=0.929722249507904, loss=0.18069428205490112
test: epoch 126, loss 1.150347113609314, acc=0.6138888597488403, loss=1.150347113609314
train: epoch 127, loss 0.19084499776363373, acc=0.92894446849823, loss=0.19084499776363373
test: epoch 127, loss 1.7201294898986816, acc=0.5416666865348816, loss=1.7201294898986816
train: epoch 128, loss 0.1876312792301178, acc=0.9299444556236267, loss=0.1876312792301178
test: epoch 128, loss 1.1294703483581543, acc=0.625, loss=1.1294703483581543
train: epoch 129, loss 0.18939924240112305, acc=0.9277222156524658, loss=0.18939924240112305
test: epoch 129, loss 1.1347905397415161, acc=0.6111111044883728, loss=1.1347905397415161
train: epoch 130, loss 0.1827760636806488, acc=0.9320555329322815, loss=0.1827760636806488
test: epoch 130, loss 1.3597837686538696, acc=0.5555555820465088, loss=1.3597837686538696
train: epoch 131, loss 0.19310778379440308, acc=0.9276111125946045, loss=0.19310778379440308
test: epoch 131, loss 1.1940250396728516, acc=0.5111111402511597, loss=1.1940250396728516
train: epoch 132, loss 0.17074576020240784, acc=0.9350000023841858, loss=0.17074576020240784
test: epoch 132, loss 1.0760324001312256, acc=0.5305555462837219, loss=1.0760324001312256
train: epoch 133, loss 0.18749436736106873, acc=0.9330000281333923, loss=0.18749436736106873
test: epoch 133, loss 1.6196858882904053, acc=0.5, loss=1.6196858882904053
train: epoch 134, loss 0.19303447008132935, acc=0.9268333315849304, loss=0.19303447008132935
test: epoch 134, loss 1.151587724685669, acc=0.5833333134651184, loss=1.151587724685669
train: epoch 135, loss 0.1537846326828003, acc=0.9433333277702332, loss=0.1537846326828003
test: epoch 135, loss 1.062711477279663, acc=0.5055555701255798, loss=1.062711477279663
train: epoch 136, loss 0.21801261603832245, acc=0.9190000295639038, loss=0.21801261603832245
test: epoch 136, loss 1.1490648984909058, acc=0.5138888955116272, loss=1.1490648984909058
train: epoch 137, loss 0.16966629028320312, acc=0.9353333115577698, loss=0.16966629028320312
test: epoch 137, loss 1.1872702836990356, acc=0.6138888597488403, loss=1.1872702836990356
train: epoch 138, loss 0.175344318151474, acc=0.9318888783454895, loss=0.175344318151474
test: epoch 138, loss 1.236405849456787, acc=0.5222222208976746, loss=1.236405849456787
train: epoch 139, loss 0.19435852766036987, acc=0.9280555844306946, loss=0.19435852766036987
test: epoch 139, loss 1.3685009479522705, acc=0.46388888359069824, loss=1.3685009479522705
train: epoch 140, loss 0.17609426379203796, acc=0.9321666955947876, loss=0.17609426379203796
test: epoch 140, loss 1.2894479036331177, acc=0.5222222208976746, loss=1.2894479036331177
train: epoch 141, loss 0.17978347837924957, acc=0.9321110844612122, loss=0.17978347837924957
test: epoch 141, loss 1.1190478801727295, acc=0.5861111283302307, loss=1.1190478801727295
train: epoch 142, loss 0.1853223741054535, acc=0.9281666874885559, loss=0.1853223741054535
test: epoch 142, loss 1.3187274932861328, acc=0.5916666388511658, loss=1.3187274932861328
train: epoch 143, loss 0.16683298349380493, acc=0.937666654586792, loss=0.16683298349380493
test: epoch 143, loss 1.4672553539276123, acc=0.5277777910232544, loss=1.4672553539276123
train: epoch 144, loss 0.17543770372867584, acc=0.9364444613456726, loss=0.17543770372867584
test: epoch 144, loss 1.1621732711791992, acc=0.6083333492279053, loss=1.1621732711791992
train: epoch 145, loss 0.17146801948547363, acc=0.9357777833938599, loss=0.17146801948547363
test: epoch 145, loss 1.4686181545257568, acc=0.5055555701255798, loss=1.4686181545257568
train: epoch 146, loss 0.18779192864894867, acc=0.9287222027778625, loss=0.18779192864894867
test: epoch 146, loss 1.291611909866333, acc=0.5611110925674438, loss=1.291611909866333
train: epoch 147, loss 0.17548991739749908, acc=0.9340555667877197, loss=0.17548991739749908
test: epoch 147, loss 1.1370973587036133, acc=0.6638888716697693, loss=1.1370973587036133
train: epoch 148, loss 0.16159817576408386, acc=0.9382777810096741, loss=0.16159817576408386
test: epoch 148, loss 1.143699049949646, acc=0.5388888716697693, loss=1.143699049949646
train: epoch 149, loss 0.2023908495903015, acc=0.9265000224113464, loss=0.2023908495903015
test: epoch 149, loss 1.2985676527023315, acc=0.6166666746139526, loss=1.2985676527023315
train: epoch 150, loss 0.1548922210931778, acc=0.940833330154419, loss=0.1548922210931778
test: epoch 150, loss 1.3151121139526367, acc=0.5361111164093018, loss=1.3151121139526367
