# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=1", "--temp_decay=1", "--one_hot=0", "--n_layers=1"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=253454098, receiver_embed_dim=64, save_run=0, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=253454098, receiver_embed_dim=64, save_run=False, temp_decay=1.0, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.263793468475342, acc=0.06566666811704636, loss=3.263793468475342
test: epoch 1, loss 3.7054057121276855, acc=0.05000000074505806, loss=3.7054057121276855
train: epoch 2, loss 2.917567491531372, acc=0.10038889199495316, loss=2.917567491531372
test: epoch 2, loss 3.8906047344207764, acc=0.05000000074505806, loss=3.8906047344207764
train: epoch 3, loss 2.8037052154541016, acc=0.11444444209337234, loss=2.8037052154541016
test: epoch 3, loss 3.9599616527557373, acc=0.05277777835726738, loss=3.9599616527557373
train: epoch 4, loss 2.741922616958618, acc=0.11811111122369766, loss=2.741922616958618
test: epoch 4, loss 4.08711576461792, acc=0.05000000074505806, loss=4.08711576461792
train: epoch 5, loss 2.689119815826416, acc=0.1288333386182785, loss=2.689119815826416
test: epoch 5, loss 4.182706832885742, acc=0.05000000074505806, loss=4.182706832885742
train: epoch 6, loss 2.658177137374878, acc=0.1357777714729309, loss=2.658177137374878
test: epoch 6, loss 4.2137770652771, acc=0.05277777835726738, loss=4.2137770652771
train: epoch 7, loss 2.6254942417144775, acc=0.14083333313465118, loss=2.6254942417144775
test: epoch 7, loss 4.373355388641357, acc=0.0555555559694767, loss=4.373355388641357
train: epoch 8, loss 2.6060924530029297, acc=0.14116667211055756, loss=2.6060924530029297
test: epoch 8, loss 4.293421745300293, acc=0.05000000074505806, loss=4.293421745300293
train: epoch 9, loss 2.5934112071990967, acc=0.14016667008399963, loss=2.5934112071990967
test: epoch 9, loss 4.326131820678711, acc=0.05000000074505806, loss=4.326131820678711
train: epoch 10, loss 2.5708959102630615, acc=0.1461111158132553, loss=2.5708959102630615
test: epoch 10, loss 4.231169700622559, acc=0.05833333358168602, loss=4.231169700622559
train: epoch 11, loss 2.551194667816162, acc=0.1480555534362793, loss=2.551194667816162
test: epoch 11, loss 4.319401741027832, acc=0.05000000074505806, loss=4.319401741027832
train: epoch 12, loss 2.5444822311401367, acc=0.15127778053283691, loss=2.5444822311401367
test: epoch 12, loss 4.298799514770508, acc=0.05000000074505806, loss=4.298799514770508
train: epoch 13, loss 2.5195465087890625, acc=0.15877777338027954, loss=2.5195465087890625
test: epoch 13, loss 4.4073333740234375, acc=0.05277777835726738, loss=4.4073333740234375
train: epoch 14, loss 2.5105795860290527, acc=0.15649999678134918, loss=2.5105795860290527
test: epoch 14, loss 4.313513278961182, acc=0.05833333358168602, loss=4.313513278961182
train: epoch 15, loss 2.4932291507720947, acc=0.16055555641651154, loss=2.4932291507720947
test: epoch 15, loss 4.3361968994140625, acc=0.05833333358168602, loss=4.3361968994140625
train: epoch 16, loss 2.500417947769165, acc=0.15988889336585999, loss=2.500417947769165
test: epoch 16, loss 4.170653820037842, acc=0.0555555559694767, loss=4.170653820037842
train: epoch 17, loss 2.48116397857666, acc=0.16205555200576782, loss=2.48116397857666
test: epoch 17, loss 4.1087260246276855, acc=0.05833333358168602, loss=4.1087260246276855
train: epoch 18, loss 2.4647185802459717, acc=0.1631111055612564, loss=2.4647185802459717
test: epoch 18, loss 4.207844257354736, acc=0.06111111119389534, loss=4.207844257354736
train: epoch 19, loss 2.4602901935577393, acc=0.16766667366027832, loss=2.4602901935577393
test: epoch 19, loss 4.0959978103637695, acc=0.06666667014360428, loss=4.0959978103637695
train: epoch 20, loss 2.449753761291504, acc=0.1684444397687912, loss=2.449753761291504
test: epoch 20, loss 4.191396713256836, acc=0.06111111119389534, loss=4.191396713256836
train: epoch 21, loss 2.4355123043060303, acc=0.1691666692495346, loss=2.4355123043060303
test: epoch 21, loss 4.272798538208008, acc=0.07500000298023224, loss=4.272798538208008
train: epoch 22, loss 2.4269678592681885, acc=0.1697777807712555, loss=2.4269678592681885
test: epoch 22, loss 4.127361297607422, acc=0.07222222536802292, loss=4.127361297607422
train: epoch 23, loss 2.4317147731781006, acc=0.16716666519641876, loss=2.4317147731781006
test: epoch 23, loss 4.160478591918945, acc=0.06111111119389534, loss=4.160478591918945
train: epoch 24, loss 2.4157845973968506, acc=0.1733333319425583, loss=2.4157845973968506
test: epoch 24, loss 4.132756233215332, acc=0.0555555559694767, loss=4.132756233215332
train: epoch 25, loss 2.407092571258545, acc=0.1761111170053482, loss=2.407092571258545
test: epoch 25, loss 4.158257961273193, acc=0.06111111119389534, loss=4.158257961273193
train: epoch 26, loss 2.3987183570861816, acc=0.17416666448116302, loss=2.3987183570861816
test: epoch 26, loss 4.225252151489258, acc=0.05833333358168602, loss=4.225252151489258
train: epoch 27, loss 2.3846330642700195, acc=0.17622222006320953, loss=2.3846330642700195
test: epoch 27, loss 4.198886394500732, acc=0.05000000074505806, loss=4.198886394500732
train: epoch 28, loss 2.388049602508545, acc=0.17872221767902374, loss=2.388049602508545
test: epoch 28, loss 4.22770881652832, acc=0.05277777835726738, loss=4.22770881652832
train: epoch 29, loss 2.3840315341949463, acc=0.17955555021762848, loss=2.3840315341949463
test: epoch 29, loss 4.221686840057373, acc=0.05833333358168602, loss=4.221686840057373
train: epoch 30, loss 2.3875911235809326, acc=0.1811666637659073, loss=2.3875911235809326
test: epoch 30, loss 4.112927436828613, acc=0.04722222313284874, loss=4.112927436828613
train: epoch 31, loss 2.369558811187744, acc=0.18388888239860535, loss=2.369558811187744
test: epoch 31, loss 4.161046981811523, acc=0.05833333358168602, loss=4.161046981811523
train: epoch 32, loss 2.3480796813964844, acc=0.18727777898311615, loss=2.3480796813964844
test: epoch 32, loss 4.230457782745361, acc=0.04722222313284874, loss=4.230457782745361
train: epoch 33, loss 2.360919237136841, acc=0.18666666746139526, loss=2.360919237136841
test: epoch 33, loss 4.211738109588623, acc=0.05000000074505806, loss=4.211738109588623
train: epoch 34, loss 2.347334384918213, acc=0.18799999356269836, loss=2.347334384918213
test: epoch 34, loss 4.189412593841553, acc=0.0555555559694767, loss=4.189412593841553
train: epoch 35, loss 2.3367488384246826, acc=0.1904444396495819, loss=2.3367488384246826
test: epoch 35, loss 4.213367462158203, acc=0.0416666679084301, loss=4.213367462158203
train: epoch 36, loss 2.3401451110839844, acc=0.1941666603088379, loss=2.3401451110839844
test: epoch 36, loss 4.084017753601074, acc=0.05000000074505806, loss=4.084017753601074
train: epoch 37, loss 2.3217124938964844, acc=0.19788889586925507, loss=2.3217124938964844
test: epoch 37, loss 4.3967671394348145, acc=0.04444444552063942, loss=4.3967671394348145
train: epoch 38, loss 2.3253190517425537, acc=0.19127777218818665, loss=2.3253190517425537
test: epoch 38, loss 4.1267828941345215, acc=0.0555555559694767, loss=4.1267828941345215
train: epoch 39, loss 2.321626901626587, acc=0.19522222876548767, loss=2.321626901626587
test: epoch 39, loss 4.360174179077148, acc=0.04722222313284874, loss=4.360174179077148
train: epoch 40, loss 2.3070785999298096, acc=0.19672222435474396, loss=2.3070785999298096
test: epoch 40, loss 4.160017490386963, acc=0.06111111119389534, loss=4.160017490386963
train: epoch 41, loss 2.309605598449707, acc=0.20088888704776764, loss=2.309605598449707
test: epoch 41, loss 4.154923439025879, acc=0.04722222313284874, loss=4.154923439025879
train: epoch 42, loss 2.3227694034576416, acc=0.19938889145851135, loss=2.3227694034576416
test: epoch 42, loss 4.135404109954834, acc=0.05000000074505806, loss=4.135404109954834
train: epoch 43, loss 2.300734043121338, acc=0.1996111124753952, loss=2.300734043121338
test: epoch 43, loss 4.279158115386963, acc=0.04722222313284874, loss=4.279158115386963
train: epoch 44, loss 2.2915093898773193, acc=0.20399999618530273, loss=2.2915093898773193
test: epoch 44, loss 4.2065911293029785, acc=0.05000000074505806, loss=4.2065911293029785
train: epoch 45, loss 2.297879457473755, acc=0.20333333313465118, loss=2.297879457473755
test: epoch 45, loss 4.122954845428467, acc=0.05000000074505806, loss=4.122954845428467
train: epoch 46, loss 2.283750057220459, acc=0.2047777771949768, loss=2.283750057220459
test: epoch 46, loss 4.096205711364746, acc=0.0555555559694767, loss=4.096205711364746
train: epoch 47, loss 2.28228759765625, acc=0.20550000667572021, loss=2.28228759765625
test: epoch 47, loss 4.170004844665527, acc=0.04722222313284874, loss=4.170004844665527
train: epoch 48, loss 2.276381015777588, acc=0.20705555379390717, loss=2.276381015777588
test: epoch 48, loss 3.946955680847168, acc=0.0555555559694767, loss=3.946955680847168
train: epoch 49, loss 2.2905149459838867, acc=0.20027777552604675, loss=2.2905149459838867
test: epoch 49, loss 4.050918102264404, acc=0.05833333358168602, loss=4.050918102264404
train: epoch 50, loss 2.264197587966919, acc=0.2092222273349762, loss=2.264197587966919
test: epoch 50, loss 3.986968755722046, acc=0.05000000074505806, loss=3.986968755722046
train: epoch 51, loss 2.2817041873931885, acc=0.2099444419145584, loss=2.2817041873931885
test: epoch 51, loss 4.026673316955566, acc=0.05833333358168602, loss=4.026673316955566
train: epoch 52, loss 2.255220413208008, acc=0.21288888156414032, loss=2.255220413208008
test: epoch 52, loss 4.124378204345703, acc=0.05277777835726738, loss=4.124378204345703
train: epoch 53, loss 2.26861310005188, acc=0.21155555546283722, loss=2.26861310005188
test: epoch 53, loss 4.2834014892578125, acc=0.04444444552063942, loss=4.2834014892578125
train: epoch 54, loss 2.2540996074676514, acc=0.21611110866069794, loss=2.2540996074676514
test: epoch 54, loss 4.145503044128418, acc=0.05277777835726738, loss=4.145503044128418
train: epoch 55, loss 2.2591404914855957, acc=0.2112777829170227, loss=2.2591404914855957
test: epoch 55, loss 3.9998562335968018, acc=0.04444444552063942, loss=3.9998562335968018
train: epoch 56, loss 2.262756824493408, acc=0.2061111181974411, loss=2.262756824493408
test: epoch 56, loss 3.9839236736297607, acc=0.05000000074505806, loss=3.9839236736297607
train: epoch 57, loss 2.2460715770721436, acc=0.21655555069446564, loss=2.2460715770721436
test: epoch 57, loss 4.167758464813232, acc=0.05000000074505806, loss=4.167758464813232
train: epoch 58, loss 2.244396686553955, acc=0.2166111171245575, loss=2.244396686553955
test: epoch 58, loss 4.014256477355957, acc=0.05277777835726738, loss=4.014256477355957
train: epoch 59, loss 2.2374768257141113, acc=0.21738888323307037, loss=2.2374768257141113
test: epoch 59, loss 4.174566268920898, acc=0.04722222313284874, loss=4.174566268920898
train: epoch 60, loss 2.225247859954834, acc=0.21605555713176727, loss=2.225247859954834
test: epoch 60, loss 4.1359734535217285, acc=0.04722222313284874, loss=4.1359734535217285
train: epoch 61, loss 2.2225875854492188, acc=0.22144444286823273, loss=2.2225875854492188
test: epoch 61, loss 4.063077449798584, acc=0.04444444552063942, loss=4.063077449798584
train: epoch 62, loss 2.226181983947754, acc=0.22022221982479095, loss=2.226181983947754
test: epoch 62, loss 4.110088348388672, acc=0.04722222313284874, loss=4.110088348388672
train: epoch 63, loss 2.2169206142425537, acc=0.2216111123561859, loss=2.2169206142425537
test: epoch 63, loss 4.0318708419799805, acc=0.05277777835726738, loss=4.0318708419799805
train: epoch 64, loss 2.230560302734375, acc=0.21855555474758148, loss=2.230560302734375
test: epoch 64, loss 4.147851467132568, acc=0.04722222313284874, loss=4.147851467132568
train: epoch 65, loss 2.203951835632324, acc=0.22483333945274353, loss=2.203951835632324
test: epoch 65, loss 3.992979049682617, acc=0.05000000074505806, loss=3.992979049682617
train: epoch 66, loss 2.209846019744873, acc=0.22027777135372162, loss=2.209846019744873
test: epoch 66, loss 4.011739730834961, acc=0.06666667014360428, loss=4.011739730834961
train: epoch 67, loss 2.2118070125579834, acc=0.21894444525241852, loss=2.2118070125579834
test: epoch 67, loss 4.11117696762085, acc=0.05000000074505806, loss=4.11117696762085
train: epoch 68, loss 2.2061967849731445, acc=0.21994444727897644, loss=2.2061967849731445
test: epoch 68, loss 4.018556594848633, acc=0.04722222313284874, loss=4.018556594848633
train: epoch 69, loss 2.200747489929199, acc=0.2207222282886505, loss=2.200747489929199
test: epoch 69, loss 4.168996334075928, acc=0.04722222313284874, loss=4.168996334075928
train: epoch 70, loss 2.189328908920288, acc=0.22538888454437256, loss=2.189328908920288
test: epoch 70, loss 4.116024494171143, acc=0.0694444477558136, loss=4.116024494171143
train: epoch 71, loss 2.1885643005371094, acc=0.21938888728618622, loss=2.1885643005371094
test: epoch 71, loss 4.1755242347717285, acc=0.05277777835726738, loss=4.1755242347717285
train: epoch 72, loss 2.2038002014160156, acc=0.22505556046962738, loss=2.2038002014160156
test: epoch 72, loss 4.156239986419678, acc=0.04722222313284874, loss=4.156239986419678
train: epoch 73, loss 2.1914846897125244, acc=0.228444442152977, loss=2.1914846897125244
test: epoch 73, loss 4.153360366821289, acc=0.04444444552063942, loss=4.153360366821289
train: epoch 74, loss 2.1937830448150635, acc=0.22277778387069702, loss=2.1937830448150635
test: epoch 74, loss 4.0934929847717285, acc=0.05833333358168602, loss=4.0934929847717285
train: epoch 75, loss 2.1810109615325928, acc=0.228444442152977, loss=2.1810109615325928
test: epoch 75, loss 4.046253204345703, acc=0.04444444552063942, loss=4.046253204345703
train: epoch 76, loss 2.1839916706085205, acc=0.22511111199855804, loss=2.1839916706085205
test: epoch 76, loss 4.065735816955566, acc=0.06111111119389534, loss=4.065735816955566
train: epoch 77, loss 2.1811087131500244, acc=0.22627778351306915, loss=2.1811087131500244
test: epoch 77, loss 4.021601676940918, acc=0.04722222313284874, loss=4.021601676940918
train: epoch 78, loss 2.1636228561401367, acc=0.22588889300823212, loss=2.1636228561401367
test: epoch 78, loss 4.16436243057251, acc=0.04722222313284874, loss=4.16436243057251
train: epoch 79, loss 2.1728687286376953, acc=0.22966666519641876, loss=2.1728687286376953
test: epoch 79, loss 4.056807518005371, acc=0.06388889253139496, loss=4.056807518005371
train: epoch 80, loss 2.17637038230896, acc=0.23061111569404602, loss=2.17637038230896
test: epoch 80, loss 4.070146560668945, acc=0.04444444552063942, loss=4.070146560668945
train: epoch 81, loss 2.1683127880096436, acc=0.23133333027362823, loss=2.1683127880096436
test: epoch 81, loss 4.041653156280518, acc=0.05000000074505806, loss=4.041653156280518
train: epoch 82, loss 2.1524720191955566, acc=0.23333333432674408, loss=2.1524720191955566
test: epoch 82, loss 4.21787166595459, acc=0.05000000074505806, loss=4.21787166595459
train: epoch 83, loss 2.163534641265869, acc=0.23516666889190674, loss=2.163534641265869
test: epoch 83, loss 3.9861278533935547, acc=0.04722222313284874, loss=3.9861278533935547
train: epoch 84, loss 2.1643354892730713, acc=0.23422221839427948, loss=2.1643354892730713
test: epoch 84, loss 4.105474472045898, acc=0.04444444552063942, loss=4.105474472045898
train: epoch 85, loss 2.1834633350372314, acc=0.2316666692495346, loss=2.1834633350372314
test: epoch 85, loss 4.0390520095825195, acc=0.05277777835726738, loss=4.0390520095825195
train: epoch 86, loss 2.1594808101654053, acc=0.2312222272157669, loss=2.1594808101654053
test: epoch 86, loss 4.245482444763184, acc=0.05000000074505806, loss=4.245482444763184
train: epoch 87, loss 2.157198667526245, acc=0.23572222888469696, loss=2.157198667526245
test: epoch 87, loss 4.117048740386963, acc=0.05000000074505806, loss=4.117048740386963
train: epoch 88, loss 2.137809991836548, acc=0.23222222924232483, loss=2.137809991836548
test: epoch 88, loss 3.961963415145874, acc=0.05000000074505806, loss=3.961963415145874
train: epoch 89, loss 2.1492350101470947, acc=0.23716667294502258, loss=2.1492350101470947
test: epoch 89, loss 4.052098274230957, acc=0.06111111119389534, loss=4.052098274230957
train: epoch 90, loss 2.142669916152954, acc=0.2377222180366516, loss=2.142669916152954
test: epoch 90, loss 4.091823577880859, acc=0.0555555559694767, loss=4.091823577880859
train: epoch 91, loss 2.1466434001922607, acc=0.23955555260181427, loss=2.1466434001922607
test: epoch 91, loss 4.10698938369751, acc=0.06111111119389534, loss=4.10698938369751
train: epoch 92, loss 2.151735782623291, acc=0.23927778005599976, loss=2.151735782623291
test: epoch 92, loss 4.012566089630127, acc=0.06388889253139496, loss=4.012566089630127
train: epoch 93, loss 2.127241849899292, acc=0.23794443905353546, loss=2.127241849899292
test: epoch 93, loss 3.8901524543762207, acc=0.0694444477558136, loss=3.8901524543762207
train: epoch 94, loss 2.148719310760498, acc=0.23544444143772125, loss=2.148719310760498
test: epoch 94, loss 4.093104362487793, acc=0.05000000074505806, loss=4.093104362487793
train: epoch 95, loss 2.141191244125366, acc=0.2408333271741867, loss=2.141191244125366
test: epoch 95, loss 4.061598777770996, acc=0.04722222313284874, loss=4.061598777770996
train: epoch 96, loss 2.140827178955078, acc=0.24022221565246582, loss=2.140827178955078
test: epoch 96, loss 4.092239856719971, acc=0.05000000074505806, loss=4.092239856719971
train: epoch 97, loss 2.1199984550476074, acc=0.2352222204208374, loss=2.1199984550476074
test: epoch 97, loss 3.9331042766571045, acc=0.06666667014360428, loss=3.9331042766571045
train: epoch 98, loss 2.117490530014038, acc=0.2408333271741867, loss=2.117490530014038
test: epoch 98, loss 3.9858100414276123, acc=0.06111111119389534, loss=3.9858100414276123
train: epoch 99, loss 2.1171228885650635, acc=0.24461111426353455, loss=2.1171228885650635
test: epoch 99, loss 4.19193696975708, acc=0.04722222313284874, loss=4.19193696975708
train: epoch 100, loss 2.1247856616973877, acc=0.2408333271741867, loss=2.1247856616973877
test: epoch 100, loss 3.9749839305877686, acc=0.05833333358168602, loss=3.9749839305877686
train: epoch 101, loss 2.1206579208374023, acc=0.24016666412353516, loss=2.1206579208374023
test: epoch 101, loss 3.895240068435669, acc=0.05833333358168602, loss=3.895240068435669
train: epoch 102, loss 2.1029675006866455, acc=0.2507777810096741, loss=2.1029675006866455
test: epoch 102, loss 3.87947678565979, acc=0.05833333358168602, loss=3.87947678565979
train: epoch 103, loss 2.1055681705474854, acc=0.24627777934074402, loss=2.1055681705474854
test: epoch 103, loss 3.8909459114074707, acc=0.05277777835726738, loss=3.8909459114074707
train: epoch 104, loss 2.1125905513763428, acc=0.2461666613817215, loss=2.1125905513763428
test: epoch 104, loss 3.986246109008789, acc=0.0555555559694767, loss=3.986246109008789
train: epoch 105, loss 2.1162893772125244, acc=0.24222221970558167, loss=2.1162893772125244
test: epoch 105, loss 3.9386637210845947, acc=0.04722222313284874, loss=3.9386637210845947
train: epoch 106, loss 2.1095783710479736, acc=0.2486666738986969, loss=2.1095783710479736
test: epoch 106, loss 4.0765862464904785, acc=0.05833333358168602, loss=4.0765862464904785
train: epoch 107, loss 2.100722551345825, acc=0.24494443833827972, loss=2.100722551345825
test: epoch 107, loss 3.9240610599517822, acc=0.06388889253139496, loss=3.9240610599517822
train: epoch 108, loss 2.1019978523254395, acc=0.24583333730697632, loss=2.1019978523254395
test: epoch 108, loss 3.805582046508789, acc=0.04444444552063942, loss=3.805582046508789
train: epoch 109, loss 2.115025758743286, acc=0.2434999942779541, loss=2.115025758743286
test: epoch 109, loss 3.810086727142334, acc=0.07500000298023224, loss=3.810086727142334
train: epoch 110, loss 2.099266290664673, acc=0.25083333253860474, loss=2.099266290664673
test: epoch 110, loss 3.9445862770080566, acc=0.05000000074505806, loss=3.9445862770080566
train: epoch 111, loss 2.1187915802001953, acc=0.25138887763023376, loss=2.1187915802001953
test: epoch 111, loss 3.9868476390838623, acc=0.03888889029622078, loss=3.9868476390838623
train: epoch 112, loss 2.119825601577759, acc=0.24666666984558105, loss=2.119825601577759
test: epoch 112, loss 3.8870580196380615, acc=0.04444444552063942, loss=3.8870580196380615
train: epoch 113, loss 2.0841240882873535, acc=0.24783332645893097, loss=2.0841240882873535
test: epoch 113, loss 3.973573923110962, acc=0.04722222313284874, loss=3.973573923110962
train: epoch 114, loss 2.08601450920105, acc=0.24972222745418549, loss=2.08601450920105
test: epoch 114, loss 3.9714980125427246, acc=0.0555555559694767, loss=3.9714980125427246
train: epoch 115, loss 2.1082794666290283, acc=0.2427777796983719, loss=2.1082794666290283
test: epoch 115, loss 3.9134786128997803, acc=0.05277777835726738, loss=3.9134786128997803
train: epoch 116, loss 2.073897361755371, acc=0.24683333933353424, loss=2.073897361755371
test: epoch 116, loss 4.063220977783203, acc=0.0416666679084301, loss=4.063220977783203
train: epoch 117, loss 2.0812056064605713, acc=0.24772222340106964, loss=2.0812056064605713
test: epoch 117, loss 4.015913009643555, acc=0.06388889253139496, loss=4.015913009643555
train: epoch 118, loss 2.0849833488464355, acc=0.24933333694934845, loss=2.0849833488464355
test: epoch 118, loss 4.063570022583008, acc=0.04444444552063942, loss=4.063570022583008
train: epoch 119, loss 2.0828561782836914, acc=0.24488888680934906, loss=2.0828561782836914
test: epoch 119, loss 3.8131930828094482, acc=0.05833333358168602, loss=3.8131930828094482
train: epoch 120, loss 2.0802156925201416, acc=0.2486666738986969, loss=2.0802156925201416
test: epoch 120, loss 4.030182838439941, acc=0.05277777835726738, loss=4.030182838439941
train: epoch 121, loss 2.0690038204193115, acc=0.25733333826065063, loss=2.0690038204193115
test: epoch 121, loss 3.996161699295044, acc=0.04722222313284874, loss=3.996161699295044
train: epoch 122, loss 2.0838353633880615, acc=0.2562222182750702, loss=2.0838353633880615
test: epoch 122, loss 4.057565689086914, acc=0.05277777835726738, loss=4.057565689086914
train: epoch 123, loss 2.07108473777771, acc=0.2516666650772095, loss=2.07108473777771
test: epoch 123, loss 4.116489410400391, acc=0.04722222313284874, loss=4.116489410400391
train: epoch 124, loss 2.077120780944824, acc=0.25244444608688354, loss=2.077120780944824
test: epoch 124, loss 3.9701390266418457, acc=0.0555555559694767, loss=3.9701390266418457
train: epoch 125, loss 2.0642762184143066, acc=0.2573888897895813, loss=2.0642762184143066
test: epoch 125, loss 4.034416675567627, acc=0.04444444552063942, loss=4.034416675567627
train: epoch 126, loss 2.07246732711792, acc=0.2516666650772095, loss=2.07246732711792
test: epoch 126, loss 3.9081168174743652, acc=0.0555555559694767, loss=3.9081168174743652
train: epoch 127, loss 2.0833020210266113, acc=0.2528333365917206, loss=2.0833020210266113
test: epoch 127, loss 4.0293707847595215, acc=0.04722222313284874, loss=4.0293707847595215
train: epoch 128, loss 2.061765432357788, acc=0.25183331966400146, loss=2.061765432357788
test: epoch 128, loss 3.8822011947631836, acc=0.05277777835726738, loss=3.8822011947631836
train: epoch 129, loss 2.0653977394104004, acc=0.2557222247123718, loss=2.0653977394104004
test: epoch 129, loss 3.816995620727539, acc=0.05000000074505806, loss=3.816995620727539
train: epoch 130, loss 2.0598955154418945, acc=0.25644445419311523, loss=2.0598955154418945
test: epoch 130, loss 3.9590766429901123, acc=0.05277777835726738, loss=3.9590766429901123
train: epoch 131, loss 2.0566110610961914, acc=0.25716665387153625, loss=2.0566110610961914
test: epoch 131, loss 3.8795695304870605, acc=0.04722222313284874, loss=3.8795695304870605
train: epoch 132, loss 2.066927433013916, acc=0.2544444501399994, loss=2.066927433013916
test: epoch 132, loss 3.9939792156219482, acc=0.06666667014360428, loss=3.9939792156219482
train: epoch 133, loss 2.0446970462799072, acc=0.25861111283302307, loss=2.0446970462799072
test: epoch 133, loss 4.046749591827393, acc=0.04722222313284874, loss=4.046749591827393
train: epoch 134, loss 2.0519227981567383, acc=0.26177778840065, loss=2.0519227981567383
test: epoch 134, loss 4.0607123374938965, acc=0.04444444552063942, loss=4.0607123374938965
train: epoch 135, loss 2.0706069469451904, acc=0.2569444477558136, loss=2.0706069469451904
test: epoch 135, loss 3.8892626762390137, acc=0.06111111119389534, loss=3.8892626762390137
train: epoch 136, loss 2.0573556423187256, acc=0.25955554842948914, loss=2.0573556423187256
test: epoch 136, loss 3.832002878189087, acc=0.04444444552063942, loss=3.832002878189087
train: epoch 137, loss 2.048711061477661, acc=0.26383334398269653, loss=2.048711061477661
test: epoch 137, loss 3.968066453933716, acc=0.0416666679084301, loss=3.968066453933716
train: epoch 138, loss 2.0633704662323, acc=0.26422223448753357, loss=2.0633704662323
test: epoch 138, loss 3.998389720916748, acc=0.06666667014360428, loss=3.998389720916748
train: epoch 139, loss 2.030015707015991, acc=0.2608333230018616, loss=2.030015707015991
test: epoch 139, loss 3.961104154586792, acc=0.05000000074505806, loss=3.961104154586792
train: epoch 140, loss 2.0531206130981445, acc=0.25999999046325684, loss=2.0531206130981445
test: epoch 140, loss 3.951026201248169, acc=0.04722222313284874, loss=3.951026201248169
train: epoch 141, loss 2.054165840148926, acc=0.2648888826370239, loss=2.054165840148926
test: epoch 141, loss 4.130428791046143, acc=0.05277777835726738, loss=4.130428791046143
train: epoch 142, loss 2.0485434532165527, acc=0.2602222263813019, loss=2.0485434532165527
test: epoch 142, loss 3.835955858230591, acc=0.05277777835726738, loss=3.835955858230591
train: epoch 143, loss 2.032266855239868, acc=0.26483333110809326, loss=2.032266855239868
test: epoch 143, loss 3.9889540672302246, acc=0.0555555559694767, loss=3.9889540672302246
train: epoch 144, loss 2.021392583847046, acc=0.26649999618530273, loss=2.021392583847046
test: epoch 144, loss 4.089104652404785, acc=0.05000000074505806, loss=4.089104652404785
train: epoch 145, loss 2.0671188831329346, acc=0.26216667890548706, loss=2.0671188831329346
test: epoch 145, loss 4.045973300933838, acc=0.05000000074505806, loss=4.045973300933838
train: epoch 146, loss 2.0325706005096436, acc=0.2611111104488373, loss=2.0325706005096436
test: epoch 146, loss 4.044098854064941, acc=0.0555555559694767, loss=4.044098854064941
train: epoch 147, loss 2.0241823196411133, acc=0.2648888826370239, loss=2.0241823196411133
test: epoch 147, loss 4.044666290283203, acc=0.05000000074505806, loss=4.044666290283203
train: epoch 148, loss 2.034083843231201, acc=0.261555552482605, loss=2.034083843231201
test: epoch 148, loss 3.928887128829956, acc=0.05277777835726738, loss=3.928887128829956
train: epoch 149, loss 2.02618408203125, acc=0.26555556058883667, loss=2.02618408203125
test: epoch 149, loss 4.057750701904297, acc=0.07222222536802292, loss=4.057750701904297
train: epoch 150, loss 2.0161216259002686, acc=0.2666666805744171, loss=2.0161216259002686
test: epoch 150, loss 4.019158363342285, acc=0.06111111119389534, loss=4.019158363342285
