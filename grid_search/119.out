# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=1", "--temp_decay=0.995", "--one_hot=1", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=1384206517, receiver_embed_dim=128, save_run=0, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1384206517, receiver_embed_dim=128, save_run=False, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.9730889797210693, acc=0.07988888770341873, loss=2.9730889797210693
test: epoch 1, loss 2.6252968311309814, acc=0.11388888955116272, loss=2.6252968311309814
train: epoch 2, loss 1.9845303297042847, acc=0.23733332753181458, loss=1.9845303297042847
test: epoch 2, loss 1.9389293193817139, acc=0.2527777850627899, loss=1.9389293193817139
train: epoch 3, loss 1.4766433238983154, acc=0.3961666524410248, loss=1.4766433238983154
test: epoch 3, loss 1.8241456747055054, acc=0.3027777671813965, loss=1.8241456747055054
train: epoch 4, loss 1.2384369373321533, acc=0.4816666543483734, loss=1.2384369373321533
test: epoch 4, loss 1.818617820739746, acc=0.31111112236976624, loss=1.818617820739746
train: epoch 5, loss 1.0799360275268555, acc=0.5447221994400024, loss=1.0799360275268555
test: epoch 5, loss 1.5523390769958496, acc=0.35555556416511536, loss=1.5523390769958496
train: epoch 6, loss 0.9644282460212708, acc=0.582277774810791, loss=0.9644282460212708
test: epoch 6, loss 1.5210471153259277, acc=0.39444443583488464, loss=1.5210471153259277
train: epoch 7, loss 0.8958706855773926, acc=0.6147778034210205, loss=0.8958706855773926
test: epoch 7, loss 1.5099903345108032, acc=0.4027777910232544, loss=1.5099903345108032
train: epoch 8, loss 0.8388703465461731, acc=0.6421666741371155, loss=0.8388703465461731
test: epoch 8, loss 1.5203821659088135, acc=0.3888888955116272, loss=1.5203821659088135
train: epoch 9, loss 0.7962188720703125, acc=0.6601666808128357, loss=0.7962188720703125
test: epoch 9, loss 1.5069390535354614, acc=0.4194444417953491, loss=1.5069390535354614
train: epoch 10, loss 0.7830316424369812, acc=0.6615555286407471, loss=0.7830316424369812
test: epoch 10, loss 1.6363071203231812, acc=0.4138889014720917, loss=1.6363071203231812
train: epoch 11, loss 0.7531115412712097, acc=0.6801666617393494, loss=0.7531115412712097
test: epoch 11, loss 1.5427851676940918, acc=0.3916666805744171, loss=1.5427851676940918
train: epoch 12, loss 0.7361708283424377, acc=0.6875, loss=0.7361708283424377
test: epoch 12, loss 1.654321312904358, acc=0.38333332538604736, loss=1.654321312904358
train: epoch 13, loss 0.7234525680541992, acc=0.6887221932411194, loss=0.7234525680541992
test: epoch 13, loss 1.7612310647964478, acc=0.4000000059604645, loss=1.7612310647964478
train: epoch 14, loss 0.7046058773994446, acc=0.6966111063957214, loss=0.7046058773994446
test: epoch 14, loss 1.6357345581054688, acc=0.4194444417953491, loss=1.6357345581054688
train: epoch 15, loss 0.6855239868164062, acc=0.7057222127914429, loss=0.6855239868164062
test: epoch 15, loss 1.447035789489746, acc=0.43611112236976624, loss=1.447035789489746
train: epoch 16, loss 0.6735978126525879, acc=0.7114444375038147, loss=0.6735978126525879
test: epoch 16, loss 1.6522208452224731, acc=0.4611110985279083, loss=1.6522208452224731
train: epoch 17, loss 0.6511456966400146, acc=0.7203888893127441, loss=0.6511456966400146
test: epoch 17, loss 1.5016218423843384, acc=0.45277777314186096, loss=1.5016218423843384
train: epoch 18, loss 0.6378263831138611, acc=0.7222777605056763, loss=0.6378263831138611
test: epoch 18, loss 1.4116489887237549, acc=0.5027777552604675, loss=1.4116489887237549
train: epoch 19, loss 0.6262804269790649, acc=0.7285000085830688, loss=0.6262804269790649
test: epoch 19, loss 1.3362650871276855, acc=0.5027777552604675, loss=1.3362650871276855
train: epoch 20, loss 0.5996443629264832, acc=0.742888867855072, loss=0.5996443629264832
test: epoch 20, loss 1.370554804801941, acc=0.5388888716697693, loss=1.370554804801941
train: epoch 21, loss 0.596143364906311, acc=0.7438333630561829, loss=0.596143364906311
test: epoch 21, loss 1.2848416566848755, acc=0.5333333611488342, loss=1.2848416566848755
train: epoch 22, loss 0.577856183052063, acc=0.7513333559036255, loss=0.577856183052063
test: epoch 22, loss 1.1838462352752686, acc=0.5527777671813965, loss=1.1838462352752686
train: epoch 23, loss 0.5867799520492554, acc=0.7494444251060486, loss=0.5867799520492554
test: epoch 23, loss 1.2299216985702515, acc=0.5388888716697693, loss=1.2299216985702515
train: epoch 24, loss 0.5674837827682495, acc=0.7562777996063232, loss=0.5674837827682495
test: epoch 24, loss 1.294837236404419, acc=0.5638889074325562, loss=1.294837236404419
train: epoch 25, loss 0.5513949394226074, acc=0.7639999985694885, loss=0.5513949394226074
test: epoch 25, loss 1.3420602083206177, acc=0.574999988079071, loss=1.3420602083206177
train: epoch 26, loss 0.546142578125, acc=0.7645000219345093, loss=0.546142578125
test: epoch 26, loss 1.146836757659912, acc=0.5666666626930237, loss=1.146836757659912
train: epoch 27, loss 0.5496217012405396, acc=0.7633333206176758, loss=0.5496217012405396
test: epoch 27, loss 1.2056183815002441, acc=0.5777778029441833, loss=1.2056183815002441
train: epoch 28, loss 0.5273505449295044, acc=0.7693333625793457, loss=0.5273505449295044
test: epoch 28, loss 1.1850672960281372, acc=0.5722222328186035, loss=1.1850672960281372
train: epoch 29, loss 0.5345656871795654, acc=0.7680000066757202, loss=0.5345656871795654
test: epoch 29, loss 1.157402515411377, acc=0.5777778029441833, loss=1.157402515411377
train: epoch 30, loss 0.5420925617218018, acc=0.7663888931274414, loss=0.5420925617218018
test: epoch 30, loss 1.2802375555038452, acc=0.5722222328186035, loss=1.2802375555038452
train: epoch 31, loss 0.5324130058288574, acc=0.7676110863685608, loss=0.5324130058288574
test: epoch 31, loss 1.2416410446166992, acc=0.550000011920929, loss=1.2416410446166992
train: epoch 32, loss 0.5296340584754944, acc=0.7695000171661377, loss=0.5296340584754944
test: epoch 32, loss 1.1510026454925537, acc=0.5666666626930237, loss=1.1510026454925537
train: epoch 33, loss 0.543488085269928, acc=0.7618333101272583, loss=0.543488085269928
test: epoch 33, loss 1.2073853015899658, acc=0.5694444179534912, loss=1.2073853015899658
train: epoch 34, loss 0.5408975481987, acc=0.7661111354827881, loss=0.5408975481987
test: epoch 34, loss 1.1248462200164795, acc=0.5416666865348816, loss=1.1248462200164795
train: epoch 35, loss 0.5439305901527405, acc=0.7645000219345093, loss=0.5439305901527405
test: epoch 35, loss 1.2252949476242065, acc=0.574999988079071, loss=1.2252949476242065
train: epoch 36, loss 0.527292013168335, acc=0.7684999704360962, loss=0.527292013168335
test: epoch 36, loss 1.129945993423462, acc=0.5805555582046509, loss=1.129945993423462
train: epoch 37, loss 0.5131120085716248, acc=0.7730555534362793, loss=0.5131120085716248
test: epoch 37, loss 1.3496392965316772, acc=0.574999988079071, loss=1.3496392965316772
train: epoch 38, loss 0.5181447863578796, acc=0.7720555663108826, loss=0.5181447863578796
test: epoch 38, loss 1.2122900485992432, acc=0.5777778029441833, loss=1.2122900485992432
train: epoch 39, loss 0.514134407043457, acc=0.7746111154556274, loss=0.514134407043457
test: epoch 39, loss 1.299221396446228, acc=0.5555555820465088, loss=1.299221396446228
train: epoch 40, loss 0.5078330039978027, acc=0.7749999761581421, loss=0.5078330039978027
test: epoch 40, loss 1.1990633010864258, acc=0.5694444179534912, loss=1.1990633010864258
train: epoch 41, loss 0.5275424718856812, acc=0.7647777795791626, loss=0.5275424718856812
test: epoch 41, loss 1.224591612815857, acc=0.5777778029441833, loss=1.224591612815857
train: epoch 42, loss 0.5083386301994324, acc=0.7785000205039978, loss=0.5083386301994324
test: epoch 42, loss 1.124416470527649, acc=0.5777778029441833, loss=1.124416470527649
train: epoch 43, loss 0.5181763172149658, acc=0.7721111178398132, loss=0.5181763172149658
test: epoch 43, loss 1.171406865119934, acc=0.5777778029441833, loss=1.171406865119934
train: epoch 44, loss 0.5100231170654297, acc=0.7748333215713501, loss=0.5100231170654297
test: epoch 44, loss 1.1306726932525635, acc=0.5722222328186035, loss=1.1306726932525635
train: epoch 45, loss 0.5219357013702393, acc=0.7746111154556274, loss=0.5219357013702393
test: epoch 45, loss 1.1824383735656738, acc=0.5638889074325562, loss=1.1824383735656738
train: epoch 46, loss 0.5115900635719299, acc=0.778166651725769, loss=0.5115900635719299
test: epoch 46, loss 1.2480968236923218, acc=0.5722222328186035, loss=1.2480968236923218
train: epoch 47, loss 0.5055498480796814, acc=0.7773333191871643, loss=0.5055498480796814
test: epoch 47, loss 1.3029394149780273, acc=0.5555555820465088, loss=1.3029394149780273
train: epoch 48, loss 0.5016102194786072, acc=0.7801666855812073, loss=0.5016102194786072
test: epoch 48, loss 1.048241138458252, acc=0.5777778029441833, loss=1.048241138458252
train: epoch 49, loss 0.5068051815032959, acc=0.7790555357933044, loss=0.5068051815032959
test: epoch 49, loss 1.2246928215026855, acc=0.574999988079071, loss=1.2246928215026855
train: epoch 50, loss 0.49240103363990784, acc=0.7839444279670715, loss=0.49240103363990784
test: epoch 50, loss 1.2301989793777466, acc=0.574999988079071, loss=1.2301989793777466
train: epoch 51, loss 0.5058309435844421, acc=0.7766666412353516, loss=0.5058309435844421
test: epoch 51, loss 1.2594804763793945, acc=0.5694444179534912, loss=1.2594804763793945
train: epoch 52, loss 0.5044260025024414, acc=0.7825000286102295, loss=0.5044260025024414
test: epoch 52, loss 1.2740601301193237, acc=0.5777778029441833, loss=1.2740601301193237
train: epoch 53, loss 0.49683842062950134, acc=0.7819444537162781, loss=0.49683842062950134
test: epoch 53, loss 1.2177683115005493, acc=0.5777778029441833, loss=1.2177683115005493
train: epoch 54, loss 0.4877873361110687, acc=0.7845555543899536, loss=0.4877873361110687
test: epoch 54, loss 1.1771111488342285, acc=0.5777778029441833, loss=1.1771111488342285
train: epoch 55, loss 0.5209899544715881, acc=0.7718333601951599, loss=0.5209899544715881
test: epoch 55, loss 1.2284247875213623, acc=0.5777778029441833, loss=1.2284247875213623
train: epoch 56, loss 0.49498245120048523, acc=0.7798888683319092, loss=0.49498245120048523
test: epoch 56, loss 1.3113393783569336, acc=0.5694444179534912, loss=1.3113393783569336
train: epoch 57, loss 0.4871528744697571, acc=0.784500002861023, loss=0.4871528744697571
test: epoch 57, loss 1.2139543294906616, acc=0.5722222328186035, loss=1.2139543294906616
train: epoch 58, loss 0.5020803213119507, acc=0.7795000076293945, loss=0.5020803213119507
test: epoch 58, loss 1.1199058294296265, acc=0.574999988079071, loss=1.1199058294296265
train: epoch 59, loss 0.489043653011322, acc=0.7839444279670715, loss=0.489043653011322
test: epoch 59, loss 1.2323797941207886, acc=0.5722222328186035, loss=1.2323797941207886
train: epoch 60, loss 0.48706650733947754, acc=0.7847777605056763, loss=0.48706650733947754
test: epoch 60, loss 1.127766489982605, acc=0.5861111283302307, loss=1.127766489982605
train: epoch 61, loss 0.48929810523986816, acc=0.7868888974189758, loss=0.48929810523986816
test: epoch 61, loss 1.1183656454086304, acc=0.5722222328186035, loss=1.1183656454086304
train: epoch 62, loss 0.47348901629447937, acc=0.7889444231987, loss=0.47348901629447937
test: epoch 62, loss 1.0903762578964233, acc=0.605555534362793, loss=1.0903762578964233
train: epoch 63, loss 0.47688084840774536, acc=0.7894444465637207, loss=0.47688084840774536
test: epoch 63, loss 1.0991497039794922, acc=0.605555534362793, loss=1.0991497039794922
train: epoch 64, loss 0.48374953866004944, acc=0.7862222194671631, loss=0.48374953866004944
test: epoch 64, loss 1.077093482017517, acc=0.6083333492279053, loss=1.077093482017517
train: epoch 65, loss 0.482273131608963, acc=0.7911111116409302, loss=0.482273131608963
test: epoch 65, loss 1.014915108680725, acc=0.6416666507720947, loss=1.014915108680725
train: epoch 66, loss 0.4643946588039398, acc=0.7937222123146057, loss=0.4643946588039398
test: epoch 66, loss 1.095492959022522, acc=0.6361111402511597, loss=1.095492959022522
train: epoch 67, loss 0.4383162260055542, acc=0.8034999966621399, loss=0.4383162260055542
test: epoch 67, loss 1.087684154510498, acc=0.644444465637207, loss=1.087684154510498
train: epoch 68, loss 0.44998472929000854, acc=0.8004999756813049, loss=0.44998472929000854
test: epoch 68, loss 1.0835036039352417, acc=0.6416666507720947, loss=1.0835036039352417
train: epoch 69, loss 0.4563470184803009, acc=0.7956666946411133, loss=0.4563470184803009
test: epoch 69, loss 1.0213836431503296, acc=0.6388888955116272, loss=1.0213836431503296
train: epoch 70, loss 0.44590264558792114, acc=0.7982777953147888, loss=0.44590264558792114
test: epoch 70, loss 0.9910258054733276, acc=0.644444465637207, loss=0.9910258054733276
train: epoch 71, loss 0.43785396218299866, acc=0.800000011920929, loss=0.43785396218299866
test: epoch 71, loss 1.0941678285598755, acc=0.644444465637207, loss=1.0941678285598755
train: epoch 72, loss 0.43842747807502747, acc=0.8001111149787903, loss=0.43842747807502747
test: epoch 72, loss 1.0133212804794312, acc=0.644444465637207, loss=1.0133212804794312
train: epoch 73, loss 0.4315228760242462, acc=0.8009999990463257, loss=0.4315228760242462
test: epoch 73, loss 1.1078605651855469, acc=0.644444465637207, loss=1.1078605651855469
train: epoch 74, loss 0.44347822666168213, acc=0.7991111278533936, loss=0.44347822666168213
test: epoch 74, loss 1.0753757953643799, acc=0.6361111402511597, loss=1.0753757953643799
train: epoch 75, loss 0.43624454736709595, acc=0.8009999990463257, loss=0.43624454736709595
test: epoch 75, loss 1.0428152084350586, acc=0.644444465637207, loss=1.0428152084350586
train: epoch 76, loss 0.42831143736839294, acc=0.80394446849823, loss=0.42831143736839294
test: epoch 76, loss 1.0813021659851074, acc=0.644444465637207, loss=1.0813021659851074
train: epoch 77, loss 0.4370793104171753, acc=0.799833357334137, loss=0.4370793104171753
test: epoch 77, loss 1.016514778137207, acc=0.644444465637207, loss=1.016514778137207
train: epoch 78, loss 0.4256758391857147, acc=0.8056111335754395, loss=0.4256758391857147
test: epoch 78, loss 1.0543755292892456, acc=0.644444465637207, loss=1.0543755292892456
train: epoch 79, loss 0.4459763765335083, acc=0.8019999861717224, loss=0.4459763765335083
test: epoch 79, loss 1.0226727724075317, acc=0.6416666507720947, loss=1.0226727724075317
train: epoch 80, loss 0.44641590118408203, acc=0.8035555481910706, loss=0.44641590118408203
test: epoch 80, loss 1.053481101989746, acc=0.6416666507720947, loss=1.053481101989746
train: epoch 81, loss 0.4310949444770813, acc=0.8077777624130249, loss=0.4310949444770813
test: epoch 81, loss 1.0121835470199585, acc=0.644444465637207, loss=1.0121835470199585
train: epoch 82, loss 0.42476940155029297, acc=0.8069999814033508, loss=0.42476940155029297
test: epoch 82, loss 1.0692692995071411, acc=0.644444465637207, loss=1.0692692995071411
train: epoch 83, loss 0.4276789128780365, acc=0.8098333477973938, loss=0.4276789128780365
test: epoch 83, loss 0.969528317451477, acc=0.644444465637207, loss=0.969528317451477
train: epoch 84, loss 0.4376101493835449, acc=0.8044999837875366, loss=0.4376101493835449
test: epoch 84, loss 1.0788676738739014, acc=0.644444465637207, loss=1.0788676738739014
train: epoch 85, loss 0.4128492772579193, acc=0.8127777576446533, loss=0.4128492772579193
test: epoch 85, loss 1.05159592628479, acc=0.6416666507720947, loss=1.05159592628479
train: epoch 86, loss 0.4263193607330322, acc=0.8086110949516296, loss=0.4263193607330322
test: epoch 86, loss 1.0670559406280518, acc=0.6416666507720947, loss=1.0670559406280518
train: epoch 87, loss 0.4265255033969879, acc=0.8084999918937683, loss=0.4265255033969879
test: epoch 87, loss 0.9719838500022888, acc=0.644444465637207, loss=0.9719838500022888
train: epoch 88, loss 0.4222555160522461, acc=0.8099444508552551, loss=0.4222555160522461
test: epoch 88, loss 1.021767497062683, acc=0.6416666507720947, loss=1.021767497062683
train: epoch 89, loss 0.4138900935649872, acc=0.8122777938842773, loss=0.4138900935649872
test: epoch 89, loss 1.105452537536621, acc=0.644444465637207, loss=1.105452537536621
train: epoch 90, loss 0.41768401861190796, acc=0.8086110949516296, loss=0.41768401861190796
test: epoch 90, loss 1.1285076141357422, acc=0.644444465637207, loss=1.1285076141357422
train: epoch 91, loss 0.4126121401786804, acc=0.8137221932411194, loss=0.4126121401786804
test: epoch 91, loss 1.0233688354492188, acc=0.644444465637207, loss=1.0233688354492188
train: epoch 92, loss 0.4223524332046509, acc=0.8109999895095825, loss=0.4223524332046509
test: epoch 92, loss 0.9170112013816833, acc=0.6472222208976746, loss=0.9170112013816833
train: epoch 93, loss 0.41015031933784485, acc=0.8132222294807434, loss=0.41015031933784485
test: epoch 93, loss 1.0835872888565063, acc=0.6472222208976746, loss=1.0835872888565063
train: epoch 94, loss 0.4105227589607239, acc=0.8144999742507935, loss=0.4105227589607239
test: epoch 94, loss 0.9913939237594604, acc=0.6416666507720947, loss=0.9913939237594604
train: epoch 95, loss 0.3950977325439453, acc=0.8212777972221375, loss=0.3950977325439453
test: epoch 95, loss 1.152883768081665, acc=0.6416666507720947, loss=1.152883768081665
train: epoch 96, loss 0.40218794345855713, acc=0.8207777738571167, loss=0.40218794345855713
test: epoch 96, loss 1.0811313390731812, acc=0.6499999761581421, loss=1.0811313390731812
train: epoch 97, loss 0.4035150408744812, acc=0.8218888640403748, loss=0.4035150408744812
test: epoch 97, loss 1.0381622314453125, acc=0.6527777910232544, loss=1.0381622314453125
train: epoch 98, loss 0.40113410353660583, acc=0.8193888664245605, loss=0.40113410353660583
test: epoch 98, loss 0.9881587028503418, acc=0.6499999761581421, loss=0.9881587028503418
train: epoch 99, loss 0.39906030893325806, acc=0.8203333616256714, loss=0.39906030893325806
test: epoch 99, loss 1.077649712562561, acc=0.6499999761581421, loss=1.077649712562561
train: epoch 100, loss 0.4050556421279907, acc=0.820277750492096, loss=0.4050556421279907
test: epoch 100, loss 0.9379696249961853, acc=0.6611111164093018, loss=0.9379696249961853
train: epoch 101, loss 0.36977237462997437, acc=0.8336666822433472, loss=0.36977237462997437
test: epoch 101, loss 0.8882728219032288, acc=0.6916666626930237, loss=0.8882728219032288
train: epoch 102, loss 0.3681153953075409, acc=0.8367778062820435, loss=0.3681153953075409
test: epoch 102, loss 1.0384232997894287, acc=0.6888889074325562, loss=1.0384232997894287
train: epoch 103, loss 0.3522294759750366, acc=0.8389999866485596, loss=0.3522294759750366
test: epoch 103, loss 0.8800106048583984, acc=0.6916666626930237, loss=0.8800106048583984
train: epoch 104, loss 0.36688899993896484, acc=0.8366666436195374, loss=0.36688899993896484
test: epoch 104, loss 1.017217993736267, acc=0.6861110925674438, loss=1.017217993736267
train: epoch 105, loss 0.36297473311424255, acc=0.8331666588783264, loss=0.36297473311424255
test: epoch 105, loss 0.8830214142799377, acc=0.6861110925674438, loss=0.8830214142799377
train: epoch 106, loss 0.3503693640232086, acc=0.8374999761581421, loss=0.3503693640232086
test: epoch 106, loss 1.0185884237289429, acc=0.6861110925674438, loss=1.0185884237289429
train: epoch 107, loss 0.35711389780044556, acc=0.8381111025810242, loss=0.35711389780044556
test: epoch 107, loss 0.9629640579223633, acc=0.6888889074325562, loss=0.9629640579223633
train: epoch 108, loss 0.35819557309150696, acc=0.8366666436195374, loss=0.35819557309150696
test: epoch 108, loss 0.9345664978027344, acc=0.6888889074325562, loss=0.9345664978027344
train: epoch 109, loss 0.35239043831825256, acc=0.8388888835906982, loss=0.35239043831825256
test: epoch 109, loss 1.018377661705017, acc=0.6888889074325562, loss=1.018377661705017
train: epoch 110, loss 0.353963702917099, acc=0.8396111130714417, loss=0.353963702917099
test: epoch 110, loss 1.0217729806900024, acc=0.6888889074325562, loss=1.0217729806900024
train: epoch 111, loss 0.36098313331604004, acc=0.8366666436195374, loss=0.36098313331604004
test: epoch 111, loss 0.8405570387840271, acc=0.6944444179534912, loss=0.8405570387840271
train: epoch 112, loss 0.32991182804107666, acc=0.8445000052452087, loss=0.32991182804107666
test: epoch 112, loss 0.8775964975357056, acc=0.7055555582046509, loss=0.8775964975357056
train: epoch 113, loss 0.3527791202068329, acc=0.8411666750907898, loss=0.3527791202068329
test: epoch 113, loss 0.8934726715087891, acc=0.7083333134651184, loss=0.8934726715087891
train: epoch 114, loss 0.330342173576355, acc=0.8447222113609314, loss=0.330342173576355
test: epoch 114, loss 0.998533308506012, acc=0.7027778029441833, loss=0.998533308506012
train: epoch 115, loss 0.3298357129096985, acc=0.8442222476005554, loss=0.3298357129096985
test: epoch 115, loss 0.7280576229095459, acc=0.730555534362793, loss=0.7280576229095459
train: epoch 116, loss 0.33014652132987976, acc=0.8491666913032532, loss=0.33014652132987976
test: epoch 116, loss 0.7317270040512085, acc=0.7361111044883728, loss=0.7317270040512085
train: epoch 117, loss 0.31865882873535156, acc=0.8532222509384155, loss=0.31865882873535156
test: epoch 117, loss 0.7835322022438049, acc=0.7388888597488403, loss=0.7835322022438049
train: epoch 118, loss 0.30502748489379883, acc=0.8597221970558167, loss=0.30502748489379883
test: epoch 118, loss 0.5925596356391907, acc=0.7472222447395325, loss=0.5925596356391907
train: epoch 119, loss 0.29953432083129883, acc=0.8603333234786987, loss=0.29953432083129883
test: epoch 119, loss 0.7365121245384216, acc=0.7472222447395325, loss=0.7365121245384216
train: epoch 120, loss 0.30164435505867004, acc=0.8608888983726501, loss=0.30164435505867004
test: epoch 120, loss 0.8800501823425293, acc=0.7472222447395325, loss=0.8800501823425293
train: epoch 121, loss 0.3066082000732422, acc=0.8632222414016724, loss=0.3066082000732422
test: epoch 121, loss 0.7626583576202393, acc=0.7472222447395325, loss=0.7626583576202393
train: epoch 122, loss 0.3013688623905182, acc=0.8658333420753479, loss=0.3013688623905182
test: epoch 122, loss 0.7168144583702087, acc=0.7527777552604675, loss=0.7168144583702087
train: epoch 123, loss 0.29921528697013855, acc=0.8650000095367432, loss=0.29921528697013855
test: epoch 123, loss 0.7552281022071838, acc=0.7555555701255798, loss=0.7552281022071838
train: epoch 124, loss 0.31176942586898804, acc=0.8622221946716309, loss=0.31176942586898804
test: epoch 124, loss 0.5895869135856628, acc=0.7777777910232544, loss=0.5895869135856628
train: epoch 125, loss 0.3070753514766693, acc=0.863111138343811, loss=0.3070753514766693
test: epoch 125, loss 0.5793807506561279, acc=0.7805555462837219, loss=0.5793807506561279
train: epoch 126, loss 0.2792510688304901, acc=0.8680555820465088, loss=0.2792510688304901
test: epoch 126, loss 0.5696536898612976, acc=0.7833333611488342, loss=0.5696536898612976
train: epoch 127, loss 0.28054672479629517, acc=0.8669999837875366, loss=0.28054672479629517
test: epoch 127, loss 0.5621389150619507, acc=0.7972221970558167, loss=0.5621389150619507
train: epoch 128, loss 0.2717466950416565, acc=0.8686110973358154, loss=0.2717466950416565
test: epoch 128, loss 0.6058620810508728, acc=0.7972221970558167, loss=0.6058620810508728
train: epoch 129, loss 0.27491453289985657, acc=0.8685555458068848, loss=0.27491453289985657
test: epoch 129, loss 0.5566394329071045, acc=0.7972221970558167, loss=0.5566394329071045
train: epoch 130, loss 0.280009001493454, acc=0.8666666746139526, loss=0.280009001493454
test: epoch 130, loss 0.5454447269439697, acc=0.7972221970558167, loss=0.5454447269439697
train: epoch 131, loss 0.2728192210197449, acc=0.867222249507904, loss=0.2728192210197449
test: epoch 131, loss 0.5571808218955994, acc=0.7972221970558167, loss=0.5571808218955994
train: epoch 132, loss 0.27540209889411926, acc=0.8691666722297668, loss=0.27540209889411926
test: epoch 132, loss 0.5374708771705627, acc=0.7972221970558167, loss=0.5374708771705627
train: epoch 133, loss 0.26987046003341675, acc=0.8693888783454895, loss=0.26987046003341675
test: epoch 133, loss 0.5084753632545471, acc=0.800000011920929, loss=0.5084753632545471
train: epoch 134, loss 0.2718524634838104, acc=0.8667222261428833, loss=0.2718524634838104
test: epoch 134, loss 0.5652830600738525, acc=0.7611111402511597, loss=0.5652830600738525
train: epoch 135, loss 0.289960116147995, acc=0.8671666383743286, loss=0.289960116147995
test: epoch 135, loss 0.5278167128562927, acc=0.7972221970558167, loss=0.5278167128562927
train: epoch 136, loss 0.27654123306274414, acc=0.8702777624130249, loss=0.27654123306274414
test: epoch 136, loss 0.4905613362789154, acc=0.7972221970558167, loss=0.4905613362789154
train: epoch 137, loss 0.2747802734375, acc=0.8706111311912537, loss=0.2747802734375
test: epoch 137, loss 0.5192664265632629, acc=0.7972221970558167, loss=0.5192664265632629
train: epoch 138, loss 0.28205448389053345, acc=0.8670555353164673, loss=0.28205448389053345
test: epoch 138, loss 0.49952393770217896, acc=0.7972221970558167, loss=0.49952393770217896
train: epoch 139, loss 0.2817022502422333, acc=0.8684444427490234, loss=0.2817022502422333
test: epoch 139, loss 0.533996045589447, acc=0.7972221970558167, loss=0.533996045589447
train: epoch 140, loss 0.2760215401649475, acc=0.8711110949516296, loss=0.2760215401649475
test: epoch 140, loss 0.4713178873062134, acc=0.7972221970558167, loss=0.4713178873062134
train: epoch 141, loss 0.27930426597595215, acc=0.8691111207008362, loss=0.27930426597595215
test: epoch 141, loss 0.5719423294067383, acc=0.7944444417953491, loss=0.5719423294067383
train: epoch 142, loss 0.26856881380081177, acc=0.8698333501815796, loss=0.26856881380081177
test: epoch 142, loss 0.5500094294548035, acc=0.7972221970558167, loss=0.5500094294548035
train: epoch 143, loss 0.2717583179473877, acc=0.8692777752876282, loss=0.2717583179473877
test: epoch 143, loss 0.5191981792449951, acc=0.7972221970558167, loss=0.5191981792449951
train: epoch 144, loss 0.2813418209552765, acc=0.8690555691719055, loss=0.2813418209552765
test: epoch 144, loss 0.5102091431617737, acc=0.8027777671813965, loss=0.5102091431617737
train: epoch 145, loss 0.27849751710891724, acc=0.8690000176429749, loss=0.27849751710891724
test: epoch 145, loss 0.46401694416999817, acc=0.8166666626930237, loss=0.46401694416999817
train: epoch 146, loss 0.2687050402164459, acc=0.8708333373069763, loss=0.2687050402164459
test: epoch 146, loss 0.4391423165798187, acc=0.8222222328186035, loss=0.4391423165798187
train: epoch 147, loss 0.27183619141578674, acc=0.8716111183166504, loss=0.27183619141578674
test: epoch 147, loss 0.4373917281627655, acc=0.8222222328186035, loss=0.4373917281627655
train: epoch 148, loss 0.2628251016139984, acc=0.8703888654708862, loss=0.2628251016139984
test: epoch 148, loss 0.4756529629230499, acc=0.8194444179534912, loss=0.4756529629230499
train: epoch 149, loss 0.25502631068229675, acc=0.8727777600288391, loss=0.25502631068229675
test: epoch 149, loss 0.4344415068626404, acc=0.824999988079071, loss=0.4344415068626404
train: epoch 150, loss 0.2568728029727936, acc=0.8730555772781372, loss=0.2568728029727936
test: epoch 150, loss 0.4390197992324829, acc=0.824999988079071, loss=0.4390197992324829
