# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=2.0", "--temp_decay=0.99", "--one_hot=0", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=467339231, receiver_embed_dim=128, save_run=0, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=467339231, receiver_embed_dim=128, save_run=False, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.2644734382629395, acc=0.1780555546283722, loss=2.2644734382629395
test: epoch 1, loss 7.825540542602539, acc=0.05833333358168602, loss=7.825540542602539
train: epoch 2, loss 1.57560396194458, acc=0.3467777669429779, loss=1.57560396194458
test: epoch 2, loss 6.758155822753906, acc=0.05000000074505806, loss=6.758155822753906
train: epoch 3, loss 1.2748373746871948, acc=0.45133334398269653, loss=1.2748373746871948
test: epoch 3, loss 3.8312442302703857, acc=0.1527777761220932, loss=3.8312442302703857
train: epoch 4, loss 1.1056509017944336, acc=0.5381666421890259, loss=1.1056509017944336
test: epoch 4, loss 3.647707939147949, acc=0.21111111342906952, loss=3.647707939147949
train: epoch 5, loss 0.9648494124412537, acc=0.5987777709960938, loss=0.9648494124412537
test: epoch 5, loss 6.087621688842773, acc=0.09166666865348816, loss=6.087621688842773
train: epoch 6, loss 0.8811721801757812, acc=0.6370555758476257, loss=0.8811721801757812
test: epoch 6, loss 3.6606059074401855, acc=0.22499999403953552, loss=3.6606059074401855
train: epoch 7, loss 0.8381773233413696, acc=0.656166672706604, loss=0.8381773233413696
test: epoch 7, loss 3.017371416091919, acc=0.19722221791744232, loss=3.017371416091919
train: epoch 8, loss 0.7890538573265076, acc=0.675611138343811, loss=0.7890538573265076
test: epoch 8, loss 3.6447784900665283, acc=0.21944443881511688, loss=3.6447784900665283
train: epoch 9, loss 0.7365258932113647, acc=0.7035555839538574, loss=0.7365258932113647
test: epoch 9, loss 2.968055009841919, acc=0.23888888955116272, loss=2.968055009841919
train: epoch 10, loss 0.7086135745048523, acc=0.7089444398880005, loss=0.7086135745048523
test: epoch 10, loss 3.5547266006469727, acc=0.2777777910232544, loss=3.5547266006469727
train: epoch 11, loss 0.6633257269859314, acc=0.7335000038146973, loss=0.6633257269859314
test: epoch 11, loss 2.7616348266601562, acc=0.2666666805744171, loss=2.7616348266601562
train: epoch 12, loss 0.6510022282600403, acc=0.7391666769981384, loss=0.6510022282600403
test: epoch 12, loss 3.247833013534546, acc=0.2638888955116272, loss=3.247833013534546
train: epoch 13, loss 0.6169960498809814, acc=0.7519444227218628, loss=0.6169960498809814
test: epoch 13, loss 3.3101718425750732, acc=0.23055554926395416, loss=3.3101718425750732
train: epoch 14, loss 0.617863655090332, acc=0.7518888711929321, loss=0.617863655090332
test: epoch 14, loss 3.2110602855682373, acc=0.23333333432674408, loss=3.2110602855682373
train: epoch 15, loss 0.5841659307479858, acc=0.7651666402816772, loss=0.5841659307479858
test: epoch 15, loss 2.348137140274048, acc=0.2916666567325592, loss=2.348137140274048
train: epoch 16, loss 0.5736036896705627, acc=0.768833339214325, loss=0.5736036896705627
test: epoch 16, loss 2.8486831188201904, acc=0.3083333373069763, loss=2.8486831188201904
train: epoch 17, loss 0.5382106900215149, acc=0.7845555543899536, loss=0.5382106900215149
test: epoch 17, loss 2.3053410053253174, acc=0.2361111044883728, loss=2.3053410053253174
train: epoch 18, loss 0.5413908958435059, acc=0.7821111083030701, loss=0.5413908958435059
test: epoch 18, loss 2.420728921890259, acc=0.28611111640930176, loss=2.420728921890259
train: epoch 19, loss 0.5341066122055054, acc=0.7876666784286499, loss=0.5341066122055054
test: epoch 19, loss 1.9764844179153442, acc=0.3499999940395355, loss=1.9764844179153442
train: epoch 20, loss 0.4979878067970276, acc=0.8001111149787903, loss=0.4979878067970276
test: epoch 20, loss 2.31210994720459, acc=0.26944443583488464, loss=2.31210994720459
train: epoch 21, loss 0.5244423151016235, acc=0.7886666655540466, loss=0.5244423151016235
test: epoch 21, loss 2.5667223930358887, acc=0.3333333432674408, loss=2.5667223930358887
train: epoch 22, loss 0.4882121980190277, acc=0.8066111207008362, loss=0.4882121980190277
test: epoch 22, loss 2.4247829914093018, acc=0.25833332538604736, loss=2.4247829914093018
train: epoch 23, loss 0.52740079164505, acc=0.7902777791023254, loss=0.52740079164505
test: epoch 23, loss 2.0845937728881836, acc=0.38333332538604736, loss=2.0845937728881836
train: epoch 24, loss 0.5049180388450623, acc=0.8000555634498596, loss=0.5049180388450623
test: epoch 24, loss 1.645298957824707, acc=0.3638888895511627, loss=1.645298957824707
train: epoch 25, loss 0.4836582541465759, acc=0.8081666827201843, loss=0.4836582541465759
test: epoch 25, loss 1.7445708513259888, acc=0.4277777671813965, loss=1.7445708513259888
train: epoch 26, loss 0.49770328402519226, acc=0.8030555844306946, loss=0.49770328402519226
test: epoch 26, loss 1.7657626867294312, acc=0.3583333194255829, loss=1.7657626867294312
train: epoch 27, loss 0.483029842376709, acc=0.8083333373069763, loss=0.483029842376709
test: epoch 27, loss 2.2613821029663086, acc=0.30000001192092896, loss=2.2613821029663086
train: epoch 28, loss 0.4836065471172333, acc=0.8062777519226074, loss=0.4836065471172333
test: epoch 28, loss 1.7946689128875732, acc=0.34166666865348816, loss=1.7946689128875732
train: epoch 29, loss 0.451904833316803, acc=0.8233333230018616, loss=0.451904833316803
test: epoch 29, loss 2.724801778793335, acc=0.31111112236976624, loss=2.724801778793335
train: epoch 30, loss 0.4914853274822235, acc=0.8061666488647461, loss=0.4914853274822235
test: epoch 30, loss 1.5336846113204956, acc=0.3638888895511627, loss=1.5336846113204956
train: epoch 31, loss 0.44932085275650024, acc=0.8179444670677185, loss=0.44932085275650024
test: epoch 31, loss 2.054415225982666, acc=0.3583333194255829, loss=2.054415225982666
train: epoch 32, loss 0.4563189446926117, acc=0.8183888792991638, loss=0.4563189446926117
test: epoch 32, loss 1.665968894958496, acc=0.39444443583488464, loss=1.665968894958496
train: epoch 33, loss 0.5030505061149597, acc=0.7963333129882812, loss=0.5030505061149597
test: epoch 33, loss 1.7196316719055176, acc=0.3333333432674408, loss=1.7196316719055176
train: epoch 34, loss 0.461388498544693, acc=0.8163333535194397, loss=0.461388498544693
test: epoch 34, loss 1.6689778566360474, acc=0.3916666805744171, loss=1.6689778566360474
train: epoch 35, loss 0.40960273146629333, acc=0.8392778038978577, loss=0.40960273146629333
test: epoch 35, loss 1.551496982574463, acc=0.46666666865348816, loss=1.551496982574463
train: epoch 36, loss 0.4652370810508728, acc=0.8168333172798157, loss=0.4652370810508728
test: epoch 36, loss 1.6088236570358276, acc=0.4027777910232544, loss=1.6088236570358276
train: epoch 37, loss 0.42707329988479614, acc=0.8303889036178589, loss=0.42707329988479614
test: epoch 37, loss 2.1088953018188477, acc=0.3305555582046509, loss=2.1088953018188477
train: epoch 38, loss 0.43457964062690735, acc=0.8284444212913513, loss=0.43457964062690735
test: epoch 38, loss 2.111569881439209, acc=0.5027777552604675, loss=2.111569881439209
train: epoch 39, loss 0.43698054552078247, acc=0.8279444575309753, loss=0.43698054552078247
test: epoch 39, loss 1.2501200437545776, acc=0.519444465637207, loss=1.2501200437545776
train: epoch 40, loss 0.4113588333129883, acc=0.836388885974884, loss=0.4113588333129883
test: epoch 40, loss 1.4266741275787354, acc=0.4555555582046509, loss=1.4266741275787354
train: epoch 41, loss 0.43063896894454956, acc=0.8265555500984192, loss=0.43063896894454956
test: epoch 41, loss 1.4880971908569336, acc=0.3916666805744171, loss=1.4880971908569336
train: epoch 42, loss 0.41544660925865173, acc=0.8355555534362793, loss=0.41544660925865173
test: epoch 42, loss 1.3775687217712402, acc=0.4583333432674408, loss=1.3775687217712402
train: epoch 43, loss 0.43394744396209717, acc=0.8299444317817688, loss=0.43394744396209717
test: epoch 43, loss 1.3857598304748535, acc=0.4416666626930237, loss=1.3857598304748535
train: epoch 44, loss 0.40339335799217224, acc=0.8399999737739563, loss=0.40339335799217224
test: epoch 44, loss 1.8866628408432007, acc=0.48055556416511536, loss=1.8866628408432007
train: epoch 45, loss 0.4490765333175659, acc=0.8216111063957214, loss=0.4490765333175659
test: epoch 45, loss 1.1502106189727783, acc=0.47777777910232544, loss=1.1502106189727783
train: epoch 46, loss 0.42194217443466187, acc=0.8332777619361877, loss=0.42194217443466187
test: epoch 46, loss 1.3050466775894165, acc=0.4277777671813965, loss=1.3050466775894165
train: epoch 47, loss 0.3908017575740814, acc=0.8457221984863281, loss=0.3908017575740814
test: epoch 47, loss 1.5090988874435425, acc=0.48055556416511536, loss=1.5090988874435425
train: epoch 48, loss 0.399796724319458, acc=0.8405555486679077, loss=0.399796724319458
test: epoch 48, loss 1.2457607984542847, acc=0.44999998807907104, loss=1.2457607984542847
train: epoch 49, loss 0.4181494116783142, acc=0.8368889093399048, loss=0.4181494116783142
test: epoch 49, loss 1.0971393585205078, acc=0.49444442987442017, loss=1.0971393585205078
train: epoch 50, loss 0.3900785446166992, acc=0.8461111187934875, loss=0.3900785446166992
test: epoch 50, loss 1.2191112041473389, acc=0.4722222089767456, loss=1.2191112041473389
train: epoch 51, loss 0.40137431025505066, acc=0.8426111340522766, loss=0.40137431025505066
test: epoch 51, loss 1.3026049137115479, acc=0.47777777910232544, loss=1.3026049137115479
train: epoch 52, loss 0.3934227228164673, acc=0.8455555438995361, loss=0.3934227228164673
test: epoch 52, loss 1.1279051303863525, acc=0.4833333194255829, loss=1.1279051303863525
train: epoch 53, loss 0.4022262990474701, acc=0.8426666855812073, loss=0.4022262990474701
test: epoch 53, loss 1.0573166608810425, acc=0.5416666865348816, loss=1.0573166608810425
train: epoch 54, loss 0.4127390384674072, acc=0.8349444270133972, loss=0.4127390384674072
test: epoch 54, loss 1.2961561679840088, acc=0.5333333611488342, loss=1.2961561679840088
train: epoch 55, loss 0.4012683033943176, acc=0.8389444351196289, loss=0.4012683033943176
test: epoch 55, loss 1.0286344289779663, acc=0.5083333253860474, loss=1.0286344289779663
train: epoch 56, loss 0.38135161995887756, acc=0.8453888893127441, loss=0.38135161995887756
test: epoch 56, loss 1.281550645828247, acc=0.4583333432674408, loss=1.281550645828247
train: epoch 57, loss 0.40466561913490295, acc=0.8412222266197205, loss=0.40466561913490295
test: epoch 57, loss 1.2887176275253296, acc=0.5305555462837219, loss=1.2887176275253296
train: epoch 58, loss 0.4071992039680481, acc=0.8410000205039978, loss=0.4071992039680481
test: epoch 58, loss 1.5018856525421143, acc=0.5111111402511597, loss=1.5018856525421143
train: epoch 59, loss 0.3912040591239929, acc=0.8471111059188843, loss=0.3912040591239929
test: epoch 59, loss 0.9020288586616516, acc=0.625, loss=0.9020288586616516
train: epoch 60, loss 0.3847070336341858, acc=0.8475000262260437, loss=0.3847070336341858
test: epoch 60, loss 0.8892841339111328, acc=0.605555534362793, loss=0.8892841339111328
train: epoch 61, loss 0.3774382472038269, acc=0.8491111397743225, loss=0.3774382472038269
test: epoch 61, loss 0.9846483469009399, acc=0.5722222328186035, loss=0.9846483469009399
train: epoch 62, loss 0.3786766529083252, acc=0.8470555543899536, loss=0.3786766529083252
test: epoch 62, loss 1.2125219106674194, acc=0.5472221970558167, loss=1.2125219106674194
train: epoch 63, loss 0.4000132083892822, acc=0.8430555462837219, loss=0.4000132083892822
test: epoch 63, loss 1.1849751472473145, acc=0.4861111044883728, loss=1.1849751472473145
train: epoch 64, loss 0.3846214711666107, acc=0.8492777943611145, loss=0.3846214711666107
test: epoch 64, loss 1.101072907447815, acc=0.5722222328186035, loss=1.101072907447815
train: epoch 65, loss 0.365329772233963, acc=0.8562777638435364, loss=0.365329772233963
test: epoch 65, loss 1.050590991973877, acc=0.6000000238418579, loss=1.050590991973877
train: epoch 66, loss 0.4108370542526245, acc=0.8366110920906067, loss=0.4108370542526245
test: epoch 66, loss 0.8252029418945312, acc=0.6499999761581421, loss=0.8252029418945312
train: epoch 67, loss 0.37356916069984436, acc=0.8486666679382324, loss=0.37356916069984436
test: epoch 67, loss 0.7588075399398804, acc=0.6833333373069763, loss=0.7588075399398804
train: epoch 68, loss 0.34763169288635254, acc=0.8629444241523743, loss=0.34763169288635254
test: epoch 68, loss 0.7196925282478333, acc=0.6833333373069763, loss=0.7196925282478333
train: epoch 69, loss 0.368861585855484, acc=0.8471666574478149, loss=0.368861585855484
test: epoch 69, loss 0.8231170773506165, acc=0.6722221970558167, loss=0.8231170773506165
train: epoch 70, loss 0.373684287071228, acc=0.8483889102935791, loss=0.373684287071228
test: epoch 70, loss 0.8607262969017029, acc=0.6583333611488342, loss=0.8607262969017029
train: epoch 71, loss 0.37090441584587097, acc=0.8521666526794434, loss=0.37090441584587097
test: epoch 71, loss 0.8578082919120789, acc=0.644444465637207, loss=0.8578082919120789
train: epoch 72, loss 0.356812983751297, acc=0.8573333621025085, loss=0.356812983751297
test: epoch 72, loss 0.7992535829544067, acc=0.6694444417953491, loss=0.7992535829544067
train: epoch 73, loss 0.3612977862358093, acc=0.8559444546699524, loss=0.3612977862358093
test: epoch 73, loss 0.9134799838066101, acc=0.5972222089767456, loss=0.9134799838066101
train: epoch 74, loss 0.3702346980571747, acc=0.8570555448532104, loss=0.3702346980571747
test: epoch 74, loss 0.8258857727050781, acc=0.6694444417953491, loss=0.8258857727050781
train: epoch 75, loss 0.3470120429992676, acc=0.859666645526886, loss=0.3470120429992676
test: epoch 75, loss 0.6975536942481995, acc=0.6499999761581421, loss=0.6975536942481995
train: epoch 76, loss 0.4013037383556366, acc=0.8395000100135803, loss=0.4013037383556366
test: epoch 76, loss 0.7209467887878418, acc=0.7361111044883728, loss=0.7209467887878418
train: epoch 77, loss 0.3567698299884796, acc=0.8579999804496765, loss=0.3567698299884796
test: epoch 77, loss 0.8081288933753967, acc=0.6777777671813965, loss=0.8081288933753967
train: epoch 78, loss 0.34724828600883484, acc=0.86772221326828, loss=0.34724828600883484
test: epoch 78, loss 0.7258033156394958, acc=0.7222222089767456, loss=0.7258033156394958
train: epoch 79, loss 0.3868064284324646, acc=0.8500555753707886, loss=0.3868064284324646
test: epoch 79, loss 0.8151670694351196, acc=0.6194444298744202, loss=0.8151670694351196
train: epoch 80, loss 0.3626934587955475, acc=0.8551111221313477, loss=0.3626934587955475
test: epoch 80, loss 0.6518819332122803, acc=0.7083333134651184, loss=0.6518819332122803
train: epoch 81, loss 0.3807053565979004, acc=0.8488888740539551, loss=0.3807053565979004
test: epoch 81, loss 0.7161639928817749, acc=0.6944444179534912, loss=0.7161639928817749
train: epoch 82, loss 0.35892266035079956, acc=0.8583889007568359, loss=0.35892266035079956
test: epoch 82, loss 0.7204866409301758, acc=0.6777777671813965, loss=0.7204866409301758
train: epoch 83, loss 0.34245017170906067, acc=0.8656111359596252, loss=0.34245017170906067
test: epoch 83, loss 1.1212328672409058, acc=0.6194444298744202, loss=1.1212328672409058
train: epoch 84, loss 0.34285226464271545, acc=0.8668888807296753, loss=0.34285226464271545
test: epoch 84, loss 0.6825238466262817, acc=0.7027778029441833, loss=0.6825238466262817
train: epoch 85, loss 0.35770466923713684, acc=0.8613333106040955, loss=0.35770466923713684
test: epoch 85, loss 0.5650411248207092, acc=0.7138888835906982, loss=0.5650411248207092
train: epoch 86, loss 0.34499892592430115, acc=0.8623889088630676, loss=0.34499892592430115
test: epoch 86, loss 0.6074175834655762, acc=0.6972222328186035, loss=0.6074175834655762
train: epoch 87, loss 0.35312700271606445, acc=0.8598333597183228, loss=0.35312700271606445
test: epoch 87, loss 0.582318902015686, acc=0.7166666388511658, loss=0.582318902015686
train: epoch 88, loss 0.3437778353691101, acc=0.8646110892295837, loss=0.3437778353691101
test: epoch 88, loss 0.657087504863739, acc=0.699999988079071, loss=0.657087504863739
train: epoch 89, loss 0.3475389778614044, acc=0.8644999861717224, loss=0.3475389778614044
test: epoch 89, loss 0.7088744044303894, acc=0.699999988079071, loss=0.7088744044303894
train: epoch 90, loss 0.395669162273407, acc=0.8422222137451172, loss=0.395669162273407
test: epoch 90, loss 0.8189243078231812, acc=0.7138888835906982, loss=0.8189243078231812
train: epoch 91, loss 0.3632529675960541, acc=0.856166660785675, loss=0.3632529675960541
test: epoch 91, loss 0.5971303582191467, acc=0.7138888835906982, loss=0.5971303582191467
train: epoch 92, loss 0.37557661533355713, acc=0.8505555391311646, loss=0.37557661533355713
test: epoch 92, loss 0.8050337433815002, acc=0.7194444537162781, loss=0.8050337433815002
train: epoch 93, loss 0.3599013090133667, acc=0.8579999804496765, loss=0.3599013090133667
test: epoch 93, loss 0.5176065564155579, acc=0.7749999761581421, loss=0.5176065564155579
train: epoch 94, loss 0.39118948578834534, acc=0.8416110873222351, loss=0.39118948578834534
test: epoch 94, loss 0.5840546488761902, acc=0.7555555701255798, loss=0.5840546488761902
train: epoch 95, loss 0.35747230052948, acc=0.8568333387374878, loss=0.35747230052948
test: epoch 95, loss 0.6166154146194458, acc=0.7194444537162781, loss=0.6166154146194458
train: epoch 96, loss 0.4052000045776367, acc=0.8407222032546997, loss=0.4052000045776367
test: epoch 96, loss 0.6538764238357544, acc=0.7277777791023254, loss=0.6538764238357544
train: epoch 97, loss 0.3629404306411743, acc=0.8565000295639038, loss=0.3629404306411743
test: epoch 97, loss 0.5765055418014526, acc=0.7944444417953491, loss=0.5765055418014526
train: epoch 98, loss 0.43825283646583557, acc=0.8247777819633484, loss=0.43825283646583557
test: epoch 98, loss 0.5523702502250671, acc=0.7527777552604675, loss=0.5523702502250671
train: epoch 99, loss 0.3701780438423157, acc=0.8513333201408386, loss=0.3701780438423157
test: epoch 99, loss 0.5464584827423096, acc=0.7749999761581421, loss=0.5464584827423096
train: epoch 100, loss 0.3550752103328705, acc=0.8608333468437195, loss=0.3550752103328705
test: epoch 100, loss 0.8349073529243469, acc=0.6583333611488342, loss=0.8349073529243469
train: epoch 101, loss 0.3366127014160156, acc=0.8653333187103271, loss=0.3366127014160156
test: epoch 101, loss 0.42494910955429077, acc=0.8111110925674438, loss=0.42494910955429077
train: epoch 102, loss 0.3567254841327667, acc=0.8561111092567444, loss=0.3567254841327667
test: epoch 102, loss 0.5334010720252991, acc=0.7527777552604675, loss=0.5334010720252991
train: epoch 103, loss 0.3686175048351288, acc=0.8517777919769287, loss=0.3686175048351288
test: epoch 103, loss 0.4294189512729645, acc=0.8111110925674438, loss=0.4294189512729645
train: epoch 104, loss 0.3435320258140564, acc=0.8633333444595337, loss=0.3435320258140564
test: epoch 104, loss 0.584109365940094, acc=0.7444444298744202, loss=0.584109365940094
train: epoch 105, loss 0.3593464195728302, acc=0.8601111173629761, loss=0.3593464195728302
test: epoch 105, loss 0.44625523686408997, acc=0.7916666865348816, loss=0.44625523686408997
train: epoch 106, loss 0.37259435653686523, acc=0.8459444642066956, loss=0.37259435653686523
test: epoch 106, loss 0.5522676110267639, acc=0.7638888955116272, loss=0.5522676110267639
train: epoch 107, loss 0.33843591809272766, acc=0.8607777953147888, loss=0.33843591809272766
test: epoch 107, loss 0.5344780087471008, acc=0.7722222208976746, loss=0.5344780087471008
train: epoch 108, loss 0.3790718615055084, acc=0.8419444561004639, loss=0.3790718615055084
test: epoch 108, loss 0.5739212036132812, acc=0.7722222208976746, loss=0.5739212036132812
train: epoch 109, loss 0.36574938893318176, acc=0.8495555520057678, loss=0.36574938893318176
test: epoch 109, loss 0.4257645905017853, acc=0.8138889074325562, loss=0.4257645905017853
train: epoch 110, loss 0.3382219970226288, acc=0.8549444675445557, loss=0.3382219970226288
test: epoch 110, loss 0.5122451782226562, acc=0.8083333373069763, loss=0.5122451782226562
train: epoch 111, loss 0.3417547047138214, acc=0.8613888621330261, loss=0.3417547047138214
test: epoch 111, loss 0.531958818435669, acc=0.7583333253860474, loss=0.531958818435669
train: epoch 112, loss 0.39193034172058105, acc=0.8360555768013, loss=0.39193034172058105
test: epoch 112, loss 0.4829555153846741, acc=0.7888888716697693, loss=0.4829555153846741
train: epoch 113, loss 0.36720630526542664, acc=0.8564444184303284, loss=0.36720630526542664
test: epoch 113, loss 0.46039727330207825, acc=0.7888888716697693, loss=0.46039727330207825
train: epoch 114, loss 0.3009350001811981, acc=0.8802777528762817, loss=0.3009350001811981
test: epoch 114, loss 0.4393603205680847, acc=0.8277778029441833, loss=0.4393603205680847
train: epoch 115, loss 0.3474538028240204, acc=0.8616111278533936, loss=0.3474538028240204
test: epoch 115, loss 0.5403216481208801, acc=0.7833333611488342, loss=0.5403216481208801
train: epoch 116, loss 0.31622567772865295, acc=0.8714444637298584, loss=0.31622567772865295
test: epoch 116, loss 0.3826305568218231, acc=0.7888888716697693, loss=0.3826305568218231
train: epoch 117, loss 0.31489691138267517, acc=0.8702222108840942, loss=0.31489691138267517
test: epoch 117, loss 0.45521339774131775, acc=0.8083333373069763, loss=0.45521339774131775
train: epoch 118, loss 0.3310662508010864, acc=0.8702222108840942, loss=0.3310662508010864
test: epoch 118, loss 0.43977242708206177, acc=0.7805555462837219, loss=0.43977242708206177
train: epoch 119, loss 0.3486524820327759, acc=0.8523333072662354, loss=0.3486524820327759
test: epoch 119, loss 0.4223621189594269, acc=0.8222222328186035, loss=0.4223621189594269
train: epoch 120, loss 0.3656558394432068, acc=0.8568888902664185, loss=0.3656558394432068
test: epoch 120, loss 0.5089805722236633, acc=0.7749999761581421, loss=0.5089805722236633
train: epoch 121, loss 0.48041877150535583, acc=0.8100000023841858, loss=0.48041877150535583
test: epoch 121, loss 0.5042563676834106, acc=0.8055555820465088, loss=0.5042563676834106
train: epoch 122, loss 0.3837184011936188, acc=0.8437777757644653, loss=0.3837184011936188
test: epoch 122, loss 0.5680508017539978, acc=0.7944444417953491, loss=0.5680508017539978
train: epoch 123, loss 0.3975781202316284, acc=0.8432777523994446, loss=0.3975781202316284
test: epoch 123, loss 0.5297775268554688, acc=0.7888888716697693, loss=0.5297775268554688
train: epoch 124, loss 0.327804297208786, acc=0.8649444580078125, loss=0.327804297208786
test: epoch 124, loss 0.5038356781005859, acc=0.7972221970558167, loss=0.5038356781005859
train: epoch 125, loss 0.32528814673423767, acc=0.8639444708824158, loss=0.32528814673423767
test: epoch 125, loss 0.48053717613220215, acc=0.8111110925674438, loss=0.48053717613220215
train: epoch 126, loss 0.37019744515419006, acc=0.8443889021873474, loss=0.37019744515419006
test: epoch 126, loss 0.42947837710380554, acc=0.8138889074325562, loss=0.42947837710380554
train: epoch 127, loss 0.36163243651390076, acc=0.8498333096504211, loss=0.36163243651390076
test: epoch 127, loss 0.4314638078212738, acc=0.7972221970558167, loss=0.4314638078212738
train: epoch 128, loss 0.4080364406108856, acc=0.8266111016273499, loss=0.4080364406108856
test: epoch 128, loss 0.47341692447662354, acc=0.7638888955116272, loss=0.47341692447662354
train: epoch 129, loss 0.6012070178985596, acc=0.7803333401679993, loss=0.6012070178985596
test: epoch 129, loss 0.72259920835495, acc=0.6916666626930237, loss=0.72259920835495
train: epoch 130, loss 0.5964590907096863, acc=0.730555534362793, loss=0.5964590907096863
test: epoch 130, loss 0.6822268962860107, acc=0.6888889074325562, loss=0.6822268962860107
train: epoch 131, loss 0.5878925323486328, acc=0.7372778058052063, loss=0.5878925323486328
test: epoch 131, loss 0.6941624879837036, acc=0.6888889074325562, loss=0.6941624879837036
train: epoch 132, loss 0.6270592212677002, acc=0.7095555663108826, loss=0.6270592212677002
test: epoch 132, loss 0.7163438200950623, acc=0.675000011920929, loss=0.7163438200950623
train: epoch 133, loss 0.6415038704872131, acc=0.6864444613456726, loss=0.6415038704872131
test: epoch 133, loss 0.8247643709182739, acc=0.6083333492279053, loss=0.8247643709182739
train: epoch 134, loss 0.6899430155754089, acc=0.680055558681488, loss=0.6899430155754089
test: epoch 134, loss 0.9412307739257812, acc=0.6000000238418579, loss=0.9412307739257812
train: epoch 135, loss 0.7173634171485901, acc=0.6627777814865112, loss=0.7173634171485901
test: epoch 135, loss 1.2193949222564697, acc=0.550000011920929, loss=1.2193949222564697
train: epoch 136, loss 0.6593503952026367, acc=0.6836110949516296, loss=0.6593503952026367
test: epoch 136, loss 0.6798983216285706, acc=0.6472222208976746, loss=0.6798983216285706
train: epoch 137, loss 0.5644318461418152, acc=0.7292777895927429, loss=0.5644318461418152
test: epoch 137, loss 0.6269211769104004, acc=0.7138888835906982, loss=0.6269211769104004
train: epoch 138, loss 0.5417430996894836, acc=0.761388897895813, loss=0.5417430996894836
test: epoch 138, loss 0.7372831702232361, acc=0.699999988079071, loss=0.7372831702232361
train: epoch 139, loss 0.5672126412391663, acc=0.7497222423553467, loss=0.5672126412391663
test: epoch 139, loss 0.5150567889213562, acc=0.7444444298744202, loss=0.5150567889213562
train: epoch 140, loss 0.48751187324523926, acc=0.7713333368301392, loss=0.48751187324523926
test: epoch 140, loss 0.5159369707107544, acc=0.7472222447395325, loss=0.5159369707107544
train: epoch 141, loss 0.5628721117973328, acc=0.7456111311912537, loss=0.5628721117973328
test: epoch 141, loss 0.7107119560241699, acc=0.6666666865348816, loss=0.7107119560241699
train: epoch 142, loss 0.5483043193817139, acc=0.7600555419921875, loss=0.5483043193817139
test: epoch 142, loss 0.710822343826294, acc=0.7027778029441833, loss=0.710822343826294
train: epoch 143, loss 0.4806661307811737, acc=0.7947221994400024, loss=0.4806661307811737
test: epoch 143, loss 0.6081002354621887, acc=0.7388888597488403, loss=0.6081002354621887
train: epoch 144, loss 0.44397494196891785, acc=0.8153333067893982, loss=0.44397494196891785
test: epoch 144, loss 0.5869216918945312, acc=0.7416666746139526, loss=0.5869216918945312
train: epoch 145, loss 0.4217914640903473, acc=0.8212777972221375, loss=0.4217914640903473
test: epoch 145, loss 0.6034683585166931, acc=0.7416666746139526, loss=0.6034683585166931
train: epoch 146, loss 0.473545104265213, acc=0.8003333210945129, loss=0.473545104265213
test: epoch 146, loss 0.5954985618591309, acc=0.7250000238418579, loss=0.5954985618591309
train: epoch 147, loss 0.5040382742881775, acc=0.7897777557373047, loss=0.5040382742881775
test: epoch 147, loss 0.6343373656272888, acc=0.675000011920929, loss=0.6343373656272888
train: epoch 148, loss 0.5257099866867065, acc=0.7624444365501404, loss=0.5257099866867065
test: epoch 148, loss 0.6214302778244019, acc=0.699999988079071, loss=0.6214302778244019
train: epoch 149, loss 0.5213980078697205, acc=0.7553333044052124, loss=0.5213980078697205
test: epoch 149, loss 0.6885011792182922, acc=0.6916666626930237, loss=0.6885011792182922
train: epoch 150, loss 0.4954204857349396, acc=0.7682777643203735, loss=0.4954204857349396
test: epoch 150, loss 0.6926174163818359, acc=0.6972222328186035, loss=0.6926174163818359
