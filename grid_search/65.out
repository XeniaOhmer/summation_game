# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=1", "--temp_decay=0.995", "--one_hot=1", "--n_layers=3"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=1, optimizer='adam', preemptable=False, random_seed=1247644946, receiver_embed_dim=64, save_run=0, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=3, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=True, optimizer='adam', preemptable=False, random_seed=1247644946, receiver_embed_dim=64, save_run=False, temp_decay=0.995, temperature=1.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.1059226989746094, acc=0.07388889044523239, loss=3.1059226989746094
test: epoch 1, loss 2.912325859069824, acc=0.10833333432674408, loss=2.912325859069824
train: epoch 2, loss 2.037008047103882, acc=0.23327778279781342, loss=2.037008047103882
test: epoch 2, loss 2.1677305698394775, acc=0.20000000298023224, loss=2.1677305698394775
train: epoch 3, loss 1.5606944561004639, acc=0.36105555295944214, loss=1.5606944561004639
test: epoch 3, loss 1.87528657913208, acc=0.22777777910232544, loss=1.87528657913208
train: epoch 4, loss 1.3240866661071777, acc=0.4498888850212097, loss=1.3240866661071777
test: epoch 4, loss 1.543359637260437, acc=0.3361110985279083, loss=1.543359637260437
train: epoch 5, loss 1.1536872386932373, acc=0.5150555372238159, loss=1.1536872386932373
test: epoch 5, loss 1.6046148538589478, acc=0.32777777314186096, loss=1.6046148538589478
train: epoch 6, loss 1.0525294542312622, acc=0.5528888702392578, loss=1.0525294542312622
test: epoch 6, loss 1.537165641784668, acc=0.3583333194255829, loss=1.537165641784668
train: epoch 7, loss 0.9524238109588623, acc=0.60188889503479, loss=0.9524238109588623
test: epoch 7, loss 1.5464621782302856, acc=0.3444444537162781, loss=1.5464621782302856
train: epoch 8, loss 0.9114117622375488, acc=0.6174444556236267, loss=0.9114117622375488
test: epoch 8, loss 1.4744446277618408, acc=0.39722222089767456, loss=1.4744446277618408
train: epoch 9, loss 0.8528226613998413, acc=0.643666684627533, loss=0.8528226613998413
test: epoch 9, loss 1.5470342636108398, acc=0.3888888955116272, loss=1.5470342636108398
train: epoch 10, loss 0.8116085529327393, acc=0.6586666703224182, loss=0.8116085529327393
test: epoch 10, loss 1.55426025390625, acc=0.4166666567325592, loss=1.55426025390625
train: epoch 11, loss 0.7664780616760254, acc=0.6722777485847473, loss=0.7664780616760254
test: epoch 11, loss 1.6153502464294434, acc=0.3861111104488373, loss=1.6153502464294434
train: epoch 12, loss 0.7396439909934998, acc=0.6881111264228821, loss=0.7396439909934998
test: epoch 12, loss 1.411083698272705, acc=0.41111111640930176, loss=1.411083698272705
train: epoch 13, loss 0.7131442427635193, acc=0.6945555806159973, loss=0.7131442427635193
test: epoch 13, loss 1.6058975458145142, acc=0.3722222149372101, loss=1.6058975458145142
train: epoch 14, loss 0.691439151763916, acc=0.7051666378974915, loss=0.691439151763916
test: epoch 14, loss 1.4502959251403809, acc=0.4416666626930237, loss=1.4502959251403809
train: epoch 15, loss 0.6814789175987244, acc=0.7091666460037231, loss=0.6814789175987244
test: epoch 15, loss 1.3398528099060059, acc=0.4472222328186035, loss=1.3398528099060059
train: epoch 16, loss 0.6469772458076477, acc=0.7300000190734863, loss=0.6469772458076477
test: epoch 16, loss 1.4351911544799805, acc=0.43611112236976624, loss=1.4351911544799805
train: epoch 17, loss 0.6461190581321716, acc=0.7334444522857666, loss=0.6461190581321716
test: epoch 17, loss 1.3781406879425049, acc=0.4166666567325592, loss=1.3781406879425049
train: epoch 18, loss 0.6099474430084229, acc=0.7482222318649292, loss=0.6099474430084229
test: epoch 18, loss 1.3560209274291992, acc=0.4972222149372101, loss=1.3560209274291992
train: epoch 19, loss 0.5823308825492859, acc=0.7689444422721863, loss=0.5823308825492859
test: epoch 19, loss 1.4082677364349365, acc=0.49166667461395264, loss=1.4082677364349365
train: epoch 20, loss 0.5776286721229553, acc=0.7662777900695801, loss=0.5776286721229553
test: epoch 20, loss 1.2764352560043335, acc=0.5249999761581421, loss=1.2764352560043335
train: epoch 21, loss 0.5481310486793518, acc=0.7838333249092102, loss=0.5481310486793518
test: epoch 21, loss 1.3957661390304565, acc=0.5111111402511597, loss=1.3957661390304565
train: epoch 22, loss 0.5429369807243347, acc=0.7860555648803711, loss=0.5429369807243347
test: epoch 22, loss 1.2922712564468384, acc=0.5, loss=1.2922712564468384
train: epoch 23, loss 0.515984296798706, acc=0.7985555529594421, loss=0.515984296798706
test: epoch 23, loss 1.2821741104125977, acc=0.5444444417953491, loss=1.2821741104125977
train: epoch 24, loss 0.5041661858558655, acc=0.8025555610656738, loss=0.5041661858558655
test: epoch 24, loss 1.302646279335022, acc=0.550000011920929, loss=1.302646279335022
train: epoch 25, loss 0.4884478747844696, acc=0.8131666779518127, loss=0.4884478747844696
test: epoch 25, loss 1.1932941675186157, acc=0.5361111164093018, loss=1.1932941675186157
train: epoch 26, loss 0.4831230938434601, acc=0.8104444742202759, loss=0.4831230938434601
test: epoch 26, loss 1.3305994272232056, acc=0.5333333611488342, loss=1.3305994272232056
train: epoch 27, loss 0.46558576822280884, acc=0.8161666393280029, loss=0.46558576822280884
test: epoch 27, loss 1.3253229856491089, acc=0.5083333253860474, loss=1.3253229856491089
train: epoch 28, loss 0.45550933480262756, acc=0.8230000138282776, loss=0.45550933480262756
test: epoch 28, loss 1.3266422748565674, acc=0.5472221970558167, loss=1.3266422748565674
train: epoch 29, loss 0.45389479398727417, acc=0.8267222046852112, loss=0.45389479398727417
test: epoch 29, loss 1.3605507612228394, acc=0.5472221970558167, loss=1.3605507612228394
train: epoch 30, loss 0.4385530948638916, acc=0.8324999809265137, loss=0.4385530948638916
test: epoch 30, loss 1.3422117233276367, acc=0.550000011920929, loss=1.3422117233276367
train: epoch 31, loss 0.43908870220184326, acc=0.8314999938011169, loss=0.43908870220184326
test: epoch 31, loss 1.3465244770050049, acc=0.5444444417953491, loss=1.3465244770050049
train: epoch 32, loss 0.4473385214805603, acc=0.832277774810791, loss=0.4473385214805603
test: epoch 32, loss 1.4114046096801758, acc=0.5472221970558167, loss=1.4114046096801758
train: epoch 33, loss 0.4342614710330963, acc=0.8316666483879089, loss=0.4342614710330963
test: epoch 33, loss 1.5018221139907837, acc=0.5416666865348816, loss=1.5018221139907837
train: epoch 34, loss 0.4247857630252838, acc=0.8381111025810242, loss=0.4247857630252838
test: epoch 34, loss 1.3723067045211792, acc=0.5472221970558167, loss=1.3723067045211792
train: epoch 35, loss 0.4300203323364258, acc=0.8381111025810242, loss=0.4300203323364258
test: epoch 35, loss 1.3984718322753906, acc=0.5416666865348816, loss=1.3984718322753906
train: epoch 36, loss 0.43663468956947327, acc=0.8338888883590698, loss=0.43663468956947327
test: epoch 36, loss 1.385642409324646, acc=0.550000011920929, loss=1.385642409324646
train: epoch 37, loss 0.4174841642379761, acc=0.8426111340522766, loss=0.4174841642379761
test: epoch 37, loss 1.4365800619125366, acc=0.550000011920929, loss=1.4365800619125366
train: epoch 38, loss 0.4111645221710205, acc=0.8418889045715332, loss=0.4111645221710205
test: epoch 38, loss 1.2612278461456299, acc=0.550000011920929, loss=1.2612278461456299
train: epoch 39, loss 0.41312405467033386, acc=0.8389999866485596, loss=0.41312405467033386
test: epoch 39, loss 1.4878222942352295, acc=0.519444465637207, loss=1.4878222942352295
train: epoch 40, loss 0.4406675398349762, acc=0.8303889036178589, loss=0.4406675398349762
test: epoch 40, loss 1.3655890226364136, acc=0.5472221970558167, loss=1.3655890226364136
train: epoch 41, loss 0.4138009548187256, acc=0.8439444303512573, loss=0.4138009548187256
test: epoch 41, loss 1.4099875688552856, acc=0.5694444179534912, loss=1.4099875688552856
train: epoch 42, loss 0.41109710931777954, acc=0.8428333401679993, loss=0.41109710931777954
test: epoch 42, loss 1.2775760889053345, acc=0.5666666626930237, loss=1.2775760889053345
train: epoch 43, loss 0.41819924116134644, acc=0.8381111025810242, loss=0.41819924116134644
test: epoch 43, loss 1.1004831790924072, acc=0.5638889074325562, loss=1.1004831790924072
train: epoch 44, loss 0.4082411825656891, acc=0.8431110978126526, loss=0.4082411825656891
test: epoch 44, loss 1.4292316436767578, acc=0.5388888716697693, loss=1.4292316436767578
train: epoch 45, loss 0.4253888726234436, acc=0.8392778038978577, loss=0.4253888726234436
test: epoch 45, loss 1.2613130807876587, acc=0.5361111164093018, loss=1.2613130807876587
train: epoch 46, loss 0.4021592140197754, acc=0.8468888998031616, loss=0.4021592140197754
test: epoch 46, loss 1.2740962505340576, acc=0.574999988079071, loss=1.2740962505340576
train: epoch 47, loss 0.4090261161327362, acc=0.844944417476654, loss=0.4090261161327362
test: epoch 47, loss 1.2500087022781372, acc=0.519444465637207, loss=1.2500087022781372
train: epoch 48, loss 0.4109295904636383, acc=0.842555582523346, loss=0.4109295904636383
test: epoch 48, loss 1.2303823232650757, acc=0.5777778029441833, loss=1.2303823232650757
train: epoch 49, loss 0.41350075602531433, acc=0.8420000076293945, loss=0.41350075602531433
test: epoch 49, loss 1.2500038146972656, acc=0.5805555582046509, loss=1.2500038146972656
train: epoch 50, loss 0.40717238187789917, acc=0.8435555696487427, loss=0.40717238187789917
test: epoch 50, loss 1.2580105066299438, acc=0.5666666626930237, loss=1.2580105066299438
train: epoch 51, loss 0.42914509773254395, acc=0.8335000276565552, loss=0.42914509773254395
test: epoch 51, loss 1.131052017211914, acc=0.5722222328186035, loss=1.131052017211914
train: epoch 52, loss 0.39811164140701294, acc=0.8458333611488342, loss=0.39811164140701294
test: epoch 52, loss 1.207732915878296, acc=0.5805555582046509, loss=1.207732915878296
train: epoch 53, loss 0.4162869155406952, acc=0.8401111364364624, loss=0.4162869155406952
test: epoch 53, loss 1.1059014797210693, acc=0.5777778029441833, loss=1.1059014797210693
train: epoch 54, loss 0.4039286673069, acc=0.843833327293396, loss=0.4039286673069
test: epoch 54, loss 1.3184720277786255, acc=0.5694444179534912, loss=1.3184720277786255
train: epoch 55, loss 0.403314471244812, acc=0.8430555462837219, loss=0.403314471244812
test: epoch 55, loss 1.2543755769729614, acc=0.574999988079071, loss=1.2543755769729614
train: epoch 56, loss 0.39429718255996704, acc=0.8471111059188843, loss=0.39429718255996704
test: epoch 56, loss 1.3354207277297974, acc=0.5777778029441833, loss=1.3354207277297974
train: epoch 57, loss 0.4171089828014374, acc=0.8448888659477234, loss=0.4171089828014374
test: epoch 57, loss 1.26679265499115, acc=0.5472221970558167, loss=1.26679265499115
train: epoch 58, loss 0.4164724349975586, acc=0.8405555486679077, loss=0.4164724349975586
test: epoch 58, loss 1.3117735385894775, acc=0.5777778029441833, loss=1.3117735385894775
train: epoch 59, loss 0.410054475069046, acc=0.8448333144187927, loss=0.410054475069046
test: epoch 59, loss 1.1859922409057617, acc=0.5666666626930237, loss=1.1859922409057617
train: epoch 60, loss 0.39524418115615845, acc=0.8497777581214905, loss=0.39524418115615845
test: epoch 60, loss 1.346780776977539, acc=0.5638889074325562, loss=1.346780776977539
train: epoch 61, loss 0.4150969982147217, acc=0.8426111340522766, loss=0.4150969982147217
test: epoch 61, loss 1.270716905593872, acc=0.574999988079071, loss=1.270716905593872
train: epoch 62, loss 0.40282660722732544, acc=0.8463333249092102, loss=0.40282660722732544
test: epoch 62, loss 1.3346812725067139, acc=0.5777778029441833, loss=1.3346812725067139
train: epoch 63, loss 0.4011484384536743, acc=0.846666693687439, loss=0.4011484384536743
test: epoch 63, loss 1.1723724603652954, acc=0.574999988079071, loss=1.1723724603652954
train: epoch 64, loss 0.3782719373703003, acc=0.855222225189209, loss=0.3782719373703003
test: epoch 64, loss 1.33549165725708, acc=0.574999988079071, loss=1.33549165725708
train: epoch 65, loss 0.39112669229507446, acc=0.8513333201408386, loss=0.39112669229507446
test: epoch 65, loss 1.2648602724075317, acc=0.574999988079071, loss=1.2648602724075317
train: epoch 66, loss 0.3938169777393341, acc=0.8495000004768372, loss=0.3938169777393341
test: epoch 66, loss 1.2350374460220337, acc=0.5777778029441833, loss=1.2350374460220337
train: epoch 67, loss 0.40816178917884827, acc=0.8458889126777649, loss=0.40816178917884827
test: epoch 67, loss 1.2405014038085938, acc=0.5777778029441833, loss=1.2405014038085938
train: epoch 68, loss 0.3810502886772156, acc=0.8551666736602783, loss=0.3810502886772156
test: epoch 68, loss 1.4589942693710327, acc=0.5777778029441833, loss=1.4589942693710327
train: epoch 69, loss 0.3966183364391327, acc=0.8453888893127441, loss=0.3966183364391327
test: epoch 69, loss 1.2181594371795654, acc=0.5777778029441833, loss=1.2181594371795654
train: epoch 70, loss 0.40063002705574036, acc=0.8457777500152588, loss=0.40063002705574036
test: epoch 70, loss 1.3308626413345337, acc=0.574999988079071, loss=1.3308626413345337
train: epoch 71, loss 0.4005165100097656, acc=0.8448333144187927, loss=0.4005165100097656
test: epoch 71, loss 1.036954641342163, acc=0.5722222328186035, loss=1.036954641342163
train: epoch 72, loss 0.3965809643268585, acc=0.8478888869285583, loss=0.3965809643268585
test: epoch 72, loss 1.2873764038085938, acc=0.5805555582046509, loss=1.2873764038085938
train: epoch 73, loss 0.39435073733329773, acc=0.8484444618225098, loss=0.39435073733329773
test: epoch 73, loss 1.2231676578521729, acc=0.5777778029441833, loss=1.2231676578521729
train: epoch 74, loss 0.37891995906829834, acc=0.8533889055252075, loss=0.37891995906829834
test: epoch 74, loss 1.2126097679138184, acc=0.5777778029441833, loss=1.2126097679138184
train: epoch 75, loss 0.4127187430858612, acc=0.8413333296775818, loss=0.4127187430858612
test: epoch 75, loss 1.2645835876464844, acc=0.5777778029441833, loss=1.2645835876464844
train: epoch 76, loss 0.39444318413734436, acc=0.8502222299575806, loss=0.39444318413734436
test: epoch 76, loss 1.3996753692626953, acc=0.5777778029441833, loss=1.3996753692626953
train: epoch 77, loss 0.3883329927921295, acc=0.8508889079093933, loss=0.3883329927921295
test: epoch 77, loss 1.2417584657669067, acc=0.5777778029441833, loss=1.2417584657669067
train: epoch 78, loss 0.38369235396385193, acc=0.8530555367469788, loss=0.38369235396385193
test: epoch 78, loss 1.21916663646698, acc=0.5777778029441833, loss=1.21916663646698
train: epoch 79, loss 0.38549062609672546, acc=0.8522777557373047, loss=0.38549062609672546
test: epoch 79, loss 1.2442532777786255, acc=0.5777778029441833, loss=1.2442532777786255
train: epoch 80, loss 0.3831198513507843, acc=0.8511666655540466, loss=0.3831198513507843
test: epoch 80, loss 1.3143744468688965, acc=0.5777778029441833, loss=1.3143744468688965
train: epoch 81, loss 0.3852965235710144, acc=0.8528888821601868, loss=0.3852965235710144
test: epoch 81, loss 1.2973334789276123, acc=0.5777778029441833, loss=1.2973334789276123
train: epoch 82, loss 0.3963432013988495, acc=0.8475000262260437, loss=0.3963432013988495
test: epoch 82, loss 1.2442381381988525, acc=0.574999988079071, loss=1.2442381381988525
train: epoch 83, loss 0.3993857800960541, acc=0.8483333587646484, loss=0.3993857800960541
test: epoch 83, loss 1.1280356645584106, acc=0.5777778029441833, loss=1.1280356645584106
train: epoch 84, loss 0.38545361161231995, acc=0.8527222275733948, loss=0.38545361161231995
test: epoch 84, loss 1.213292121887207, acc=0.5805555582046509, loss=1.213292121887207
train: epoch 85, loss 0.38697201013565063, acc=0.8531110882759094, loss=0.38697201013565063
test: epoch 85, loss 1.1081773042678833, acc=0.5638889074325562, loss=1.1081773042678833
train: epoch 86, loss 0.3939533829689026, acc=0.8519444465637207, loss=0.3939533829689026
test: epoch 86, loss 1.0974633693695068, acc=0.5777778029441833, loss=1.0974633693695068
train: epoch 87, loss 0.37618139386177063, acc=0.8538333177566528, loss=0.37618139386177063
test: epoch 87, loss 1.2964026927947998, acc=0.5777778029441833, loss=1.2964026927947998
train: epoch 88, loss 0.3765391409397125, acc=0.8563888669013977, loss=0.3765391409397125
test: epoch 88, loss 1.2246720790863037, acc=0.5777778029441833, loss=1.2246720790863037
train: epoch 89, loss 0.3741544485092163, acc=0.8574444651603699, loss=0.3741544485092163
test: epoch 89, loss 1.4302982091903687, acc=0.5777778029441833, loss=1.4302982091903687
train: epoch 90, loss 0.3805881142616272, acc=0.8558333516120911, loss=0.3805881142616272
test: epoch 90, loss 1.203743815422058, acc=0.5777778029441833, loss=1.203743815422058
train: epoch 91, loss 0.3860824704170227, acc=0.8525000214576721, loss=0.3860824704170227
test: epoch 91, loss 1.2148656845092773, acc=0.5777778029441833, loss=1.2148656845092773
train: epoch 92, loss 0.3705250918865204, acc=0.8588888645172119, loss=0.3705250918865204
test: epoch 92, loss 1.1916122436523438, acc=0.5777778029441833, loss=1.1916122436523438
train: epoch 93, loss 0.3868829011917114, acc=0.8537222146987915, loss=0.3868829011917114
test: epoch 93, loss 1.2036590576171875, acc=0.5777778029441833, loss=1.2036590576171875
train: epoch 94, loss 0.37599462270736694, acc=0.8566111326217651, loss=0.37599462270736694
test: epoch 94, loss 1.2710281610488892, acc=0.5777778029441833, loss=1.2710281610488892
train: epoch 95, loss 0.3604961633682251, acc=0.8641111254692078, loss=0.3604961633682251
test: epoch 95, loss 1.2342649698257446, acc=0.5777778029441833, loss=1.2342649698257446
train: epoch 96, loss 0.3734937608242035, acc=0.8586111068725586, loss=0.3734937608242035
test: epoch 96, loss 1.145194411277771, acc=0.5777778029441833, loss=1.145194411277771
train: epoch 97, loss 0.3716702461242676, acc=0.8587222099304199, loss=0.3716702461242676
test: epoch 97, loss 1.217787504196167, acc=0.5722222328186035, loss=1.217787504196167
train: epoch 98, loss 0.3795742094516754, acc=0.8558889031410217, loss=0.3795742094516754
test: epoch 98, loss 1.1591635942459106, acc=0.5777778029441833, loss=1.1591635942459106
train: epoch 99, loss 0.3810584843158722, acc=0.8548333048820496, loss=0.3810584843158722
test: epoch 99, loss 1.266414761543274, acc=0.5777778029441833, loss=1.266414761543274
train: epoch 100, loss 0.36108633875846863, acc=0.863277792930603, loss=0.36108633875846863
test: epoch 100, loss 1.2808496952056885, acc=0.5777778029441833, loss=1.2808496952056885
train: epoch 101, loss 0.3504250943660736, acc=0.8665555715560913, loss=0.3504250943660736
test: epoch 101, loss 1.383111834526062, acc=0.5777778029441833, loss=1.383111834526062
train: epoch 102, loss 0.3582487106323242, acc=0.8640555739402771, loss=0.3582487106323242
test: epoch 102, loss 1.2893388271331787, acc=0.5777778029441833, loss=1.2893388271331787
train: epoch 103, loss 0.3602563440799713, acc=0.862500011920929, loss=0.3602563440799713
test: epoch 103, loss 1.3291258811950684, acc=0.5777778029441833, loss=1.3291258811950684
train: epoch 104, loss 0.3927753269672394, acc=0.8530555367469788, loss=0.3927753269672394
test: epoch 104, loss 1.2265479564666748, acc=0.5833333134651184, loss=1.2265479564666748
train: epoch 105, loss 0.3589475750923157, acc=0.8628888726234436, loss=0.3589475750923157
test: epoch 105, loss 1.3358086347579956, acc=0.5777778029441833, loss=1.3358086347579956
train: epoch 106, loss 0.37198546528816223, acc=0.8576666712760925, loss=0.37198546528816223
test: epoch 106, loss 1.2466357946395874, acc=0.5861111283302307, loss=1.2466357946395874
train: epoch 107, loss 0.36239874362945557, acc=0.8641666769981384, loss=0.36239874362945557
test: epoch 107, loss 1.3654025793075562, acc=0.5861111283302307, loss=1.3654025793075562
train: epoch 108, loss 0.34902000427246094, acc=0.8681111335754395, loss=0.34902000427246094
test: epoch 108, loss 1.0501655340194702, acc=0.5833333134651184, loss=1.0501655340194702
train: epoch 109, loss 0.3384108543395996, acc=0.8702777624130249, loss=0.3384108543395996
test: epoch 109, loss 1.2491636276245117, acc=0.5861111283302307, loss=1.2491636276245117
train: epoch 110, loss 0.36242902278900146, acc=0.8615000247955322, loss=0.36242902278900146
test: epoch 110, loss 1.290540337562561, acc=0.5861111283302307, loss=1.290540337562561
train: epoch 111, loss 0.35307276248931885, acc=0.867111086845398, loss=0.35307276248931885
test: epoch 111, loss 1.250076174736023, acc=0.5861111283302307, loss=1.250076174736023
train: epoch 112, loss 0.36585333943367004, acc=0.8622221946716309, loss=0.36585333943367004
test: epoch 112, loss 1.2418429851531982, acc=0.5694444179534912, loss=1.2418429851531982
train: epoch 113, loss 0.3409128487110138, acc=0.8691666722297668, loss=0.3409128487110138
test: epoch 113, loss 1.318185567855835, acc=0.5861111283302307, loss=1.318185567855835
train: epoch 114, loss 0.3676542341709137, acc=0.8605555295944214, loss=0.3676542341709137
test: epoch 114, loss 1.1986336708068848, acc=0.5861111283302307, loss=1.1986336708068848
train: epoch 115, loss 0.3526083528995514, acc=0.8650000095367432, loss=0.3526083528995514
test: epoch 115, loss 1.3042176961898804, acc=0.5861111283302307, loss=1.3042176961898804
train: epoch 116, loss 0.3599700629711151, acc=0.8609444499015808, loss=0.3599700629711151
test: epoch 116, loss 1.3524198532104492, acc=0.5861111283302307, loss=1.3524198532104492
train: epoch 117, loss 0.3501041531562805, acc=0.8642777800559998, loss=0.3501041531562805
test: epoch 117, loss 1.2129982709884644, acc=0.5861111283302307, loss=1.2129982709884644
train: epoch 118, loss 0.33766090869903564, acc=0.8708333373069763, loss=0.33766090869903564
test: epoch 118, loss 1.2710734605789185, acc=0.5861111283302307, loss=1.2710734605789185
train: epoch 119, loss 0.3765546977519989, acc=0.859499990940094, loss=0.3765546977519989
test: epoch 119, loss 1.2204667329788208, acc=0.5861111283302307, loss=1.2204667329788208
train: epoch 120, loss 0.3533762991428375, acc=0.8654444217681885, loss=0.3533762991428375
test: epoch 120, loss 1.2535678148269653, acc=0.5861111283302307, loss=1.2535678148269653
train: epoch 121, loss 0.34948307275772095, acc=0.866777777671814, loss=0.34948307275772095
test: epoch 121, loss 1.2158581018447876, acc=0.5861111283302307, loss=1.2158581018447876
train: epoch 122, loss 0.35469284653663635, acc=0.8659444451332092, loss=0.35469284653663635
test: epoch 122, loss 1.2619514465332031, acc=0.5861111283302307, loss=1.2619514465332031
train: epoch 123, loss 0.3506704270839691, acc=0.8673333525657654, loss=0.3506704270839691
test: epoch 123, loss 1.2691620588302612, acc=0.5861111283302307, loss=1.2691620588302612
train: epoch 124, loss 0.33471643924713135, acc=0.8726111054420471, loss=0.33471643924713135
test: epoch 124, loss 1.2631839513778687, acc=0.5861111283302307, loss=1.2631839513778687
train: epoch 125, loss 0.3515980839729309, acc=0.8646110892295837, loss=0.3515980839729309
test: epoch 125, loss 1.2048629522323608, acc=0.5861111283302307, loss=1.2048629522323608
train: epoch 126, loss 0.35014617443084717, acc=0.8641111254692078, loss=0.35014617443084717
test: epoch 126, loss 1.1827632188796997, acc=0.5861111283302307, loss=1.1827632188796997
train: epoch 127, loss 0.34311696887016296, acc=0.8668888807296753, loss=0.34311696887016296
test: epoch 127, loss 1.2158281803131104, acc=0.5861111283302307, loss=1.2158281803131104
train: epoch 128, loss 0.32737764716148376, acc=0.8719444274902344, loss=0.32737764716148376
test: epoch 128, loss 1.2419849634170532, acc=0.5861111283302307, loss=1.2419849634170532
train: epoch 129, loss 0.34506282210350037, acc=0.8681666851043701, loss=0.34506282210350037
test: epoch 129, loss 1.1878941059112549, acc=0.5861111283302307, loss=1.1878941059112549
train: epoch 130, loss 0.3323952555656433, acc=0.8737221956253052, loss=0.3323952555656433
test: epoch 130, loss 1.286124348640442, acc=0.5861111283302307, loss=1.286124348640442
train: epoch 131, loss 0.34440216422080994, acc=0.867388904094696, loss=0.34440216422080994
test: epoch 131, loss 1.2204937934875488, acc=0.5861111283302307, loss=1.2204937934875488
train: epoch 132, loss 0.33542558550834656, acc=0.8707777857780457, loss=0.33542558550834656
test: epoch 132, loss 1.3275090456008911, acc=0.5833333134651184, loss=1.3275090456008911
train: epoch 133, loss 0.3484640419483185, acc=0.8677777647972107, loss=0.3484640419483185
test: epoch 133, loss 1.3097211122512817, acc=0.5833333134651184, loss=1.3097211122512817
train: epoch 134, loss 0.3445364534854889, acc=0.8687222003936768, loss=0.3445364534854889
test: epoch 134, loss 1.164894938468933, acc=0.5861111283302307, loss=1.164894938468933
train: epoch 135, loss 0.35251256823539734, acc=0.8636666536331177, loss=0.35251256823539734
test: epoch 135, loss 1.2153784036636353, acc=0.5861111283302307, loss=1.2153784036636353
train: epoch 136, loss 0.3492177724838257, acc=0.8660555481910706, loss=0.3492177724838257
test: epoch 136, loss 1.3893165588378906, acc=0.5861111283302307, loss=1.3893165588378906
train: epoch 137, loss 0.34755557775497437, acc=0.8686666488647461, loss=0.34755557775497437
test: epoch 137, loss 1.2523438930511475, acc=0.5861111283302307, loss=1.2523438930511475
train: epoch 138, loss 0.3473767340183258, acc=0.867388904094696, loss=0.3473767340183258
test: epoch 138, loss 1.2706953287124634, acc=0.5861111283302307, loss=1.2706953287124634
train: epoch 139, loss 0.35092270374298096, acc=0.8624444603919983, loss=0.35092270374298096
test: epoch 139, loss 1.3302465677261353, acc=0.5861111283302307, loss=1.3302465677261353
train: epoch 140, loss 0.33464592695236206, acc=0.870555579662323, loss=0.33464592695236206
test: epoch 140, loss 1.3267481327056885, acc=0.5861111283302307, loss=1.3267481327056885
train: epoch 141, loss 0.33211687207221985, acc=0.8738889098167419, loss=0.33211687207221985
test: epoch 141, loss 1.3672094345092773, acc=0.5861111283302307, loss=1.3672094345092773
train: epoch 142, loss 0.32509565353393555, acc=0.8745555281639099, loss=0.32509565353393555
test: epoch 142, loss 1.3217028379440308, acc=0.5861111283302307, loss=1.3217028379440308
train: epoch 143, loss 0.3412519693374634, acc=0.8681111335754395, loss=0.3412519693374634
test: epoch 143, loss 1.2890630960464478, acc=0.5861111283302307, loss=1.2890630960464478
train: epoch 144, loss 0.35723549127578735, acc=0.8662777543067932, loss=0.35723549127578735
test: epoch 144, loss 1.157090425491333, acc=0.5861111283302307, loss=1.157090425491333
train: epoch 145, loss 0.33195510506629944, acc=0.8694999814033508, loss=0.33195510506629944
test: epoch 145, loss 1.4390827417373657, acc=0.5861111283302307, loss=1.4390827417373657
train: epoch 146, loss 0.3253125250339508, acc=0.8735555410385132, loss=0.3253125250339508
test: epoch 146, loss 1.4395465850830078, acc=0.5861111283302307, loss=1.4395465850830078
train: epoch 147, loss 0.33517587184906006, acc=0.8703333139419556, loss=0.33517587184906006
test: epoch 147, loss 1.3512262105941772, acc=0.5861111283302307, loss=1.3512262105941772
train: epoch 148, loss 0.34670084714889526, acc=0.8678333163261414, loss=0.34670084714889526
test: epoch 148, loss 1.3486226797103882, acc=0.5861111283302307, loss=1.3486226797103882
train: epoch 149, loss 0.35332348942756653, acc=0.8658333420753479, loss=0.35332348942756653
test: epoch 149, loss 1.260221004486084, acc=0.5861111283302307, loss=1.260221004486084
train: epoch 150, loss 0.3397192358970642, acc=0.8700000047683716, loss=0.3397192358970642
test: epoch 150, loss 1.2972780466079712, acc=0.5861111283302307, loss=1.2972780466079712
