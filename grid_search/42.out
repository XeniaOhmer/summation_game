# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=0.995", "--one_hot=0", "--n_layers=1"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=1589762200, receiver_embed_dim=32, save_run=0, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=1589762200, receiver_embed_dim=32, save_run=False, temp_decay=0.995, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.2136433124542236, acc=0.0806666687130928, loss=3.2136433124542236
test: epoch 1, loss 4.593443393707275, acc=0.04444444552063942, loss=4.593443393707275
train: epoch 2, loss 2.6370108127593994, acc=0.15711110830307007, loss=2.6370108127593994
test: epoch 2, loss 5.7269978523254395, acc=0.0416666679084301, loss=5.7269978523254395
train: epoch 3, loss 2.446641683578491, acc=0.17927777767181396, loss=2.446641683578491
test: epoch 3, loss 6.698214054107666, acc=0.03888889029622078, loss=6.698214054107666
train: epoch 4, loss 2.3395514488220215, acc=0.1996111124753952, loss=2.3395514488220215
test: epoch 4, loss 7.373804569244385, acc=0.03888889029622078, loss=7.373804569244385
train: epoch 5, loss 2.2681658267974854, acc=0.21905554831027985, loss=2.2681658267974854
test: epoch 5, loss 7.892176628112793, acc=0.0416666679084301, loss=7.892176628112793
train: epoch 6, loss 2.2139055728912354, acc=0.22527778148651123, loss=2.2139055728912354
test: epoch 6, loss 8.259420394897461, acc=0.03888889029622078, loss=8.259420394897461
train: epoch 7, loss 2.161634922027588, acc=0.234333336353302, loss=2.161634922027588
test: epoch 7, loss 8.845881462097168, acc=0.03611111268401146, loss=8.845881462097168
train: epoch 8, loss 2.132441759109497, acc=0.24116666615009308, loss=2.132441759109497
test: epoch 8, loss 9.12126350402832, acc=0.03611111268401146, loss=9.12126350402832
train: epoch 9, loss 2.098634958267212, acc=0.24977777898311615, loss=2.098634958267212
test: epoch 9, loss 9.471200942993164, acc=0.03611111268401146, loss=9.471200942993164
train: epoch 10, loss 2.0726711750030518, acc=0.2512222230434418, loss=2.0726711750030518
test: epoch 10, loss 9.52387523651123, acc=0.03611111268401146, loss=9.52387523651123
train: epoch 11, loss 2.053016185760498, acc=0.25655555725097656, loss=2.053016185760498
test: epoch 11, loss 9.588449478149414, acc=0.03888889029622078, loss=9.588449478149414
train: epoch 12, loss 2.02238130569458, acc=0.26338890194892883, loss=2.02238130569458
test: epoch 12, loss 9.977973937988281, acc=0.04444444552063942, loss=9.977973937988281
train: epoch 13, loss 2.005340576171875, acc=0.26561111211776733, loss=2.005340576171875
test: epoch 13, loss 10.248579978942871, acc=0.03611111268401146, loss=10.248579978942871
train: epoch 14, loss 1.9911518096923828, acc=0.27205556631088257, loss=1.9911518096923828
test: epoch 14, loss 10.346653938293457, acc=0.03333333507180214, loss=10.346653938293457
train: epoch 15, loss 1.98057222366333, acc=0.27772220969200134, loss=1.98057222366333
test: epoch 15, loss 10.294262886047363, acc=0.03888889029622078, loss=10.294262886047363
train: epoch 16, loss 1.9571975469589233, acc=0.2792222201824188, loss=1.9571975469589233
test: epoch 16, loss 10.437634468078613, acc=0.03888889029622078, loss=10.437634468078613
train: epoch 17, loss 1.9476656913757324, acc=0.2863333225250244, loss=1.9476656913757324
test: epoch 17, loss 10.404348373413086, acc=0.03611111268401146, loss=10.404348373413086
train: epoch 18, loss 1.9349796772003174, acc=0.28316667675971985, loss=1.9349796772003174
test: epoch 18, loss 10.195768356323242, acc=0.03333333507180214, loss=10.195768356323242
train: epoch 19, loss 1.9288766384124756, acc=0.2820555567741394, loss=1.9288766384124756
test: epoch 19, loss 10.452498435974121, acc=0.03611111268401146, loss=10.452498435974121
train: epoch 20, loss 1.908306360244751, acc=0.2913888990879059, loss=1.908306360244751
test: epoch 20, loss 10.366798400878906, acc=0.03055555559694767, loss=10.366798400878906
train: epoch 21, loss 1.907692313194275, acc=0.29088887572288513, loss=1.907692313194275
test: epoch 21, loss 10.463555335998535, acc=0.03333333507180214, loss=10.463555335998535
train: epoch 22, loss 1.904402256011963, acc=0.28744444251060486, loss=1.904402256011963
test: epoch 22, loss 10.385030746459961, acc=0.03333333507180214, loss=10.385030746459961
train: epoch 23, loss 1.8905611038208008, acc=0.2894444465637207, loss=1.8905611038208008
test: epoch 23, loss 10.18761157989502, acc=0.03888889029622078, loss=10.18761157989502
train: epoch 24, loss 1.8868992328643799, acc=0.29605555534362793, loss=1.8868992328643799
test: epoch 24, loss 10.350120544433594, acc=0.03055555559694767, loss=10.350120544433594
train: epoch 25, loss 1.879477858543396, acc=0.2985000014305115, loss=1.879477858543396
test: epoch 25, loss 10.517650604248047, acc=0.02777777798473835, loss=10.517650604248047
train: epoch 26, loss 1.858867883682251, acc=0.3033333420753479, loss=1.858867883682251
test: epoch 26, loss 10.609667778015137, acc=0.03055555559694767, loss=10.609667778015137
train: epoch 27, loss 1.8626785278320312, acc=0.3009999990463257, loss=1.8626785278320312
test: epoch 27, loss 10.556824684143066, acc=0.03055555559694767, loss=10.556824684143066
train: epoch 28, loss 1.8647717237472534, acc=0.30649998784065247, loss=1.8647717237472534
test: epoch 28, loss 10.485600471496582, acc=0.03611111268401146, loss=10.485600471496582
train: epoch 29, loss 1.8604214191436768, acc=0.30077776312828064, loss=1.8604214191436768
test: epoch 29, loss 10.574687004089355, acc=0.03055555559694767, loss=10.574687004089355
train: epoch 30, loss 1.8498262166976929, acc=0.3076111078262329, loss=1.8498262166976929
test: epoch 30, loss 10.77583122253418, acc=0.03611111268401146, loss=10.77583122253418
train: epoch 31, loss 1.8410776853561401, acc=0.30872222781181335, loss=1.8410776853561401
test: epoch 31, loss 10.312002182006836, acc=0.03333333507180214, loss=10.312002182006836
train: epoch 32, loss 1.8425896167755127, acc=0.3073333203792572, loss=1.8425896167755127
test: epoch 32, loss 10.244010925292969, acc=0.03333333507180214, loss=10.244010925292969
train: epoch 33, loss 1.8453662395477295, acc=0.31005555391311646, loss=1.8453662395477295
test: epoch 33, loss 10.165227890014648, acc=0.0416666679084301, loss=10.165227890014648
train: epoch 34, loss 1.8372629880905151, acc=0.3108333349227905, loss=1.8372629880905151
test: epoch 34, loss 9.746684074401855, acc=0.03055555559694767, loss=9.746684074401855
train: epoch 35, loss 1.818088173866272, acc=0.316222220659256, loss=1.818088173866272
test: epoch 35, loss 10.313085556030273, acc=0.05000000074505806, loss=10.313085556030273
train: epoch 36, loss 1.828619122505188, acc=0.308944433927536, loss=1.828619122505188
test: epoch 36, loss 10.264934539794922, acc=0.03055555559694767, loss=10.264934539794922
train: epoch 37, loss 1.813549280166626, acc=0.31583333015441895, loss=1.813549280166626
test: epoch 37, loss 9.952826499938965, acc=0.02777777798473835, loss=9.952826499938965
train: epoch 38, loss 1.7990800142288208, acc=0.316777765750885, loss=1.7990800142288208
test: epoch 38, loss 10.177398681640625, acc=0.02500000037252903, loss=10.177398681640625
train: epoch 39, loss 1.803324818611145, acc=0.32249999046325684, loss=1.803324818611145
test: epoch 39, loss 10.208516120910645, acc=0.05833333358168602, loss=10.208516120910645
train: epoch 40, loss 1.8021515607833862, acc=0.3269444406032562, loss=1.8021515607833862
test: epoch 40, loss 9.730515480041504, acc=0.04722222313284874, loss=9.730515480041504
train: epoch 41, loss 1.8076245784759521, acc=0.3228333294391632, loss=1.8076245784759521
test: epoch 41, loss 10.112645149230957, acc=0.03888889029622078, loss=10.112645149230957
train: epoch 42, loss 1.8003008365631104, acc=0.32294443249702454, loss=1.8003008365631104
test: epoch 42, loss 10.234262466430664, acc=0.03888889029622078, loss=10.234262466430664
train: epoch 43, loss 1.7999768257141113, acc=0.32216668128967285, loss=1.7999768257141113
test: epoch 43, loss 9.900300979614258, acc=0.03888889029622078, loss=9.900300979614258
train: epoch 44, loss 1.7963312864303589, acc=0.3230000138282776, loss=1.7963312864303589
test: epoch 44, loss 10.012239456176758, acc=0.02777777798473835, loss=10.012239456176758
train: epoch 45, loss 1.798675298690796, acc=0.3277222216129303, loss=1.798675298690796
test: epoch 45, loss 9.71219539642334, acc=0.0416666679084301, loss=9.71219539642334
train: epoch 46, loss 1.7905361652374268, acc=0.3262222111225128, loss=1.7905361652374268
test: epoch 46, loss 9.318000793457031, acc=0.04444444552063942, loss=9.318000793457031
train: epoch 47, loss 1.7929211854934692, acc=0.32644444704055786, loss=1.7929211854934692
test: epoch 47, loss 9.61638069152832, acc=0.0416666679084301, loss=9.61638069152832
train: epoch 48, loss 1.7828423976898193, acc=0.32616665959358215, loss=1.7828423976898193
test: epoch 48, loss 9.32288932800293, acc=0.03888889029622078, loss=9.32288932800293
train: epoch 49, loss 1.7863171100616455, acc=0.33116665482521057, loss=1.7863171100616455
test: epoch 49, loss 8.975353240966797, acc=0.0555555559694767, loss=8.975353240966797
train: epoch 50, loss 1.780532717704773, acc=0.32794445753097534, loss=1.780532717704773
test: epoch 50, loss 9.566665649414062, acc=0.05000000074505806, loss=9.566665649414062
train: epoch 51, loss 1.8038196563720703, acc=0.32511112093925476, loss=1.8038196563720703
test: epoch 51, loss 9.680161476135254, acc=0.04444444552063942, loss=9.680161476135254
train: epoch 52, loss 1.792350172996521, acc=0.32733333110809326, loss=1.792350172996521
test: epoch 52, loss 9.237954139709473, acc=0.0416666679084301, loss=9.237954139709473
train: epoch 53, loss 1.7821053266525269, acc=0.33177778124809265, loss=1.7821053266525269
test: epoch 53, loss 9.02607536315918, acc=0.0416666679084301, loss=9.02607536315918
train: epoch 54, loss 1.802325963973999, acc=0.32777777314186096, loss=1.802325963973999
test: epoch 54, loss 8.778193473815918, acc=0.04722222313284874, loss=8.778193473815918
train: epoch 55, loss 1.7867375612258911, acc=0.3374444544315338, loss=1.7867375612258911
test: epoch 55, loss 8.726200103759766, acc=0.04722222313284874, loss=8.726200103759766
train: epoch 56, loss 1.7907609939575195, acc=0.3230000138282776, loss=1.7907609939575195
test: epoch 56, loss 8.817337989807129, acc=0.04444444552063942, loss=8.817337989807129
train: epoch 57, loss 1.7833764553070068, acc=0.33161109685897827, loss=1.7833764553070068
test: epoch 57, loss 8.887020111083984, acc=0.04444444552063942, loss=8.887020111083984
train: epoch 58, loss 1.790888786315918, acc=0.3306666612625122, loss=1.790888786315918
test: epoch 58, loss 8.739344596862793, acc=0.0416666679084301, loss=8.739344596862793
train: epoch 59, loss 1.7906018495559692, acc=0.33383333683013916, loss=1.7906018495559692
test: epoch 59, loss 8.255805015563965, acc=0.04444444552063942, loss=8.255805015563965
train: epoch 60, loss 1.7818615436553955, acc=0.3338888883590698, loss=1.7818615436553955
test: epoch 60, loss 7.800173282623291, acc=0.04444444552063942, loss=7.800173282623291
train: epoch 61, loss 1.7908093929290771, acc=0.335999995470047, loss=1.7908093929290771
test: epoch 61, loss 8.27393913269043, acc=0.04444444552063942, loss=8.27393913269043
train: epoch 62, loss 1.7871593236923218, acc=0.3356666564941406, loss=1.7871593236923218
test: epoch 62, loss 8.437861442565918, acc=0.03333333507180214, loss=8.437861442565918
train: epoch 63, loss 1.7772166728973389, acc=0.33444443345069885, loss=1.7772166728973389
test: epoch 63, loss 8.214018821716309, acc=0.05000000074505806, loss=8.214018821716309
train: epoch 64, loss 1.7864965200424194, acc=0.3340555429458618, loss=1.7864965200424194
test: epoch 64, loss 7.944995403289795, acc=0.03055555559694767, loss=7.944995403289795
train: epoch 65, loss 1.7821282148361206, acc=0.33116665482521057, loss=1.7821282148361206
test: epoch 65, loss 7.953179359436035, acc=0.0416666679084301, loss=7.953179359436035
train: epoch 66, loss 1.790831208229065, acc=0.33899998664855957, loss=1.790831208229065
test: epoch 66, loss 7.862384796142578, acc=0.03611111268401146, loss=7.862384796142578
train: epoch 67, loss 1.804604411125183, acc=0.3316666781902313, loss=1.804604411125183
test: epoch 67, loss 7.601934909820557, acc=0.05277777835726738, loss=7.601934909820557
train: epoch 68, loss 1.7979055643081665, acc=0.3346666693687439, loss=1.7979055643081665
test: epoch 68, loss 7.707374572753906, acc=0.05277777835726738, loss=7.707374572753906
train: epoch 69, loss 1.8022418022155762, acc=0.32677778601646423, loss=1.8022418022155762
test: epoch 69, loss 7.666957855224609, acc=0.02777777798473835, loss=7.666957855224609
train: epoch 70, loss 1.792920708656311, acc=0.32811111211776733, loss=1.792920708656311
test: epoch 70, loss 7.825228214263916, acc=0.03888889029622078, loss=7.825228214263916
train: epoch 71, loss 1.796514630317688, acc=0.33399999141693115, loss=1.796514630317688
test: epoch 71, loss 7.589990615844727, acc=0.03888889029622078, loss=7.589990615844727
train: epoch 72, loss 1.7965905666351318, acc=0.3357222080230713, loss=1.7965905666351318
test: epoch 72, loss 7.065731048583984, acc=0.03333333507180214, loss=7.065731048583984
train: epoch 73, loss 1.8003720045089722, acc=0.3310000002384186, loss=1.8003720045089722
test: epoch 73, loss 7.369795799255371, acc=0.02222222276031971, loss=7.369795799255371
train: epoch 74, loss 1.7969324588775635, acc=0.32677778601646423, loss=1.7969324588775635
test: epoch 74, loss 7.10988187789917, acc=0.03611111268401146, loss=7.10988187789917
train: epoch 75, loss 1.8108158111572266, acc=0.33561110496520996, loss=1.8108158111572266
test: epoch 75, loss 6.844191551208496, acc=0.0416666679084301, loss=6.844191551208496
train: epoch 76, loss 1.8102978467941284, acc=0.32633334398269653, loss=1.8102978467941284
test: epoch 76, loss 6.9204254150390625, acc=0.0416666679084301, loss=6.9204254150390625
train: epoch 77, loss 1.8180667161941528, acc=0.33355554938316345, loss=1.8180667161941528
test: epoch 77, loss 6.678915023803711, acc=0.0416666679084301, loss=6.678915023803711
train: epoch 78, loss 1.807554006576538, acc=0.33633333444595337, loss=1.807554006576538
test: epoch 78, loss 6.450183868408203, acc=0.04722222313284874, loss=6.450183868408203
train: epoch 79, loss 1.809156060218811, acc=0.33161109685897827, loss=1.809156060218811
test: epoch 79, loss 6.8684000968933105, acc=0.0416666679084301, loss=6.8684000968933105
train: epoch 80, loss 1.7950584888458252, acc=0.3348333239555359, loss=1.7950584888458252
test: epoch 80, loss 6.587109565734863, acc=0.0416666679084301, loss=6.587109565734863
train: epoch 81, loss 1.8208118677139282, acc=0.335833340883255, loss=1.8208118677139282
test: epoch 81, loss 6.648015975952148, acc=0.03055555559694767, loss=6.648015975952148
train: epoch 82, loss 1.8005298376083374, acc=0.32749998569488525, loss=1.8005298376083374
test: epoch 82, loss 6.716516494750977, acc=0.03055555559694767, loss=6.716516494750977
train: epoch 83, loss 1.8396869897842407, acc=0.32588890194892883, loss=1.8396869897842407
test: epoch 83, loss 6.58196496963501, acc=0.03333333507180214, loss=6.58196496963501
train: epoch 84, loss 1.8199716806411743, acc=0.32938888669013977, loss=1.8199716806411743
test: epoch 84, loss 6.408618450164795, acc=0.03888889029622078, loss=6.408618450164795
train: epoch 85, loss 1.8235442638397217, acc=0.3330555558204651, loss=1.8235442638397217
test: epoch 85, loss 6.653111457824707, acc=0.02777777798473835, loss=6.653111457824707
train: epoch 86, loss 1.8233007192611694, acc=0.3286111056804657, loss=1.8233007192611694
test: epoch 86, loss 6.540143013000488, acc=0.02777777798473835, loss=6.540143013000488
train: epoch 87, loss 1.8306258916854858, acc=0.3266666531562805, loss=1.8306258916854858
test: epoch 87, loss 6.3954572677612305, acc=0.03611111268401146, loss=6.3954572677612305
train: epoch 88, loss 1.8334306478500366, acc=0.3308333456516266, loss=1.8334306478500366
test: epoch 88, loss 6.325867652893066, acc=0.03611111268401146, loss=6.325867652893066
train: epoch 89, loss 1.8172390460968018, acc=0.33044445514678955, loss=1.8172390460968018
test: epoch 89, loss 6.536221027374268, acc=0.03888889029622078, loss=6.536221027374268
train: epoch 90, loss 1.8511162996292114, acc=0.3215000033378601, loss=1.8511162996292114
test: epoch 90, loss 5.924829483032227, acc=0.02777777798473835, loss=5.924829483032227
train: epoch 91, loss 1.821875810623169, acc=0.3305000066757202, loss=1.821875810623169
test: epoch 91, loss 6.325057029724121, acc=0.03055555559694767, loss=6.325057029724121
train: epoch 92, loss 1.8425973653793335, acc=0.3271111249923706, loss=1.8425973653793335
test: epoch 92, loss 5.830626010894775, acc=0.03055555559694767, loss=5.830626010894775
train: epoch 93, loss 1.8296083211898804, acc=0.3216666579246521, loss=1.8296083211898804
test: epoch 93, loss 6.125641822814941, acc=0.03055555559694767, loss=6.125641822814941
train: epoch 94, loss 1.843685269355774, acc=0.320166677236557, loss=1.843685269355774
test: epoch 94, loss 5.758671283721924, acc=0.03055555559694767, loss=5.758671283721924
train: epoch 95, loss 1.854364037513733, acc=0.32216668128967285, loss=1.854364037513733
test: epoch 95, loss 5.775394916534424, acc=0.02222222276031971, loss=5.775394916534424
train: epoch 96, loss 1.8662720918655396, acc=0.3228333294391632, loss=1.8662720918655396
test: epoch 96, loss 5.582148551940918, acc=0.03055555559694767, loss=5.582148551940918
train: epoch 97, loss 1.8603668212890625, acc=0.3200555443763733, loss=1.8603668212890625
test: epoch 97, loss 5.589970111846924, acc=0.04444444552063942, loss=5.589970111846924
train: epoch 98, loss 1.8475192785263062, acc=0.3219444453716278, loss=1.8475192785263062
test: epoch 98, loss 5.529869079589844, acc=0.03333333507180214, loss=5.529869079589844
train: epoch 99, loss 1.853469967842102, acc=0.32155555486679077, loss=1.853469967842102
test: epoch 99, loss 5.391042709350586, acc=0.03611111268401146, loss=5.391042709350586
train: epoch 100, loss 1.863883376121521, acc=0.3218333423137665, loss=1.863883376121521
test: epoch 100, loss 5.351790904998779, acc=0.03888889029622078, loss=5.351790904998779
train: epoch 101, loss 1.8482009172439575, acc=0.32100000977516174, loss=1.8482009172439575
test: epoch 101, loss 5.4933857917785645, acc=0.05277777835726738, loss=5.4933857917785645
train: epoch 102, loss 1.8630987405776978, acc=0.31877776980400085, loss=1.8630987405776978
test: epoch 102, loss 5.239490509033203, acc=0.02500000037252903, loss=5.239490509033203
train: epoch 103, loss 1.8711822032928467, acc=0.32499998807907104, loss=1.8711822032928467
test: epoch 103, loss 5.285492897033691, acc=0.02500000037252903, loss=5.285492897033691
train: epoch 104, loss 1.8792113065719604, acc=0.316388875246048, loss=1.8792113065719604
test: epoch 104, loss 5.291173934936523, acc=0.03333333507180214, loss=5.291173934936523
train: epoch 105, loss 1.8652044534683228, acc=0.3160000145435333, loss=1.8652044534683228
test: epoch 105, loss 5.303435802459717, acc=0.02777777798473835, loss=5.303435802459717
train: epoch 106, loss 1.8730401992797852, acc=0.316444456577301, loss=1.8730401992797852
test: epoch 106, loss 5.310842514038086, acc=0.03055555559694767, loss=5.310842514038086
train: epoch 107, loss 1.892094612121582, acc=0.3151666522026062, loss=1.892094612121582
test: epoch 107, loss 5.351456165313721, acc=0.03333333507180214, loss=5.351456165313721
train: epoch 108, loss 1.8808355331420898, acc=0.3191111087799072, loss=1.8808355331420898
test: epoch 108, loss 4.970363616943359, acc=0.03611111268401146, loss=4.970363616943359
train: epoch 109, loss 1.9046611785888672, acc=0.31299999356269836, loss=1.9046611785888672
test: epoch 109, loss 5.066802978515625, acc=0.02500000037252903, loss=5.066802978515625
train: epoch 110, loss 1.8757296800613403, acc=0.3112777769565582, loss=1.8757296800613403
test: epoch 110, loss 5.0226287841796875, acc=0.03055555559694767, loss=5.0226287841796875
train: epoch 111, loss 1.8912876844406128, acc=0.31477779150009155, loss=1.8912876844406128
test: epoch 111, loss 4.940194606781006, acc=0.02777777798473835, loss=4.940194606781006
train: epoch 112, loss 1.891219139099121, acc=0.3151666522026062, loss=1.891219139099121
test: epoch 112, loss 4.9125165939331055, acc=0.04722222313284874, loss=4.9125165939331055
train: epoch 113, loss 1.8892532587051392, acc=0.3070555627346039, loss=1.8892532587051392
test: epoch 113, loss 4.6927571296691895, acc=0.05833333358168602, loss=4.6927571296691895
train: epoch 114, loss 1.873962163925171, acc=0.30649998784065247, loss=1.873962163925171
test: epoch 114, loss 4.572059631347656, acc=0.03611111268401146, loss=4.572059631347656
train: epoch 115, loss 1.9067597389221191, acc=0.3078888952732086, loss=1.9067597389221191
test: epoch 115, loss 4.947724342346191, acc=0.03055555559694767, loss=4.947724342346191
train: epoch 116, loss 1.9050740003585815, acc=0.30816665291786194, loss=1.9050740003585815
test: epoch 116, loss 4.4386067390441895, acc=0.03888889029622078, loss=4.4386067390441895
train: epoch 117, loss 1.8907642364501953, acc=0.3120555579662323, loss=1.8907642364501953
test: epoch 117, loss 4.720412254333496, acc=0.03055555559694767, loss=4.720412254333496
train: epoch 118, loss 1.9110316038131714, acc=0.3019999861717224, loss=1.9110316038131714
test: epoch 118, loss 4.704395771026611, acc=0.03333333507180214, loss=4.704395771026611
train: epoch 119, loss 1.912800908088684, acc=0.3034999966621399, loss=1.912800908088684
test: epoch 119, loss 4.634011268615723, acc=0.03333333507180214, loss=4.634011268615723
train: epoch 120, loss 1.9118045568466187, acc=0.3032222092151642, loss=1.9118045568466187
test: epoch 120, loss 4.832918643951416, acc=0.05000000074505806, loss=4.832918643951416
train: epoch 121, loss 1.9110422134399414, acc=0.3037777841091156, loss=1.9110422134399414
test: epoch 121, loss 4.46087646484375, acc=0.0416666679084301, loss=4.46087646484375
train: epoch 122, loss 1.919023871421814, acc=0.30872222781181335, loss=1.919023871421814
test: epoch 122, loss 4.4414873123168945, acc=0.0555555559694767, loss=4.4414873123168945
train: epoch 123, loss 1.9096006155014038, acc=0.30816665291786194, loss=1.9096006155014038
test: epoch 123, loss 4.334748268127441, acc=0.05833333358168602, loss=4.334748268127441
train: epoch 124, loss 1.926594614982605, acc=0.29827776551246643, loss=1.926594614982605
test: epoch 124, loss 4.2827653884887695, acc=0.07222222536802292, loss=4.2827653884887695
train: epoch 125, loss 1.9326575994491577, acc=0.3036110997200012, loss=1.9326575994491577
test: epoch 125, loss 4.25406551361084, acc=0.04444444552063942, loss=4.25406551361084
train: epoch 126, loss 1.9280848503112793, acc=0.30033332109451294, loss=1.9280848503112793
test: epoch 126, loss 4.389874458312988, acc=0.0555555559694767, loss=4.389874458312988
train: epoch 127, loss 1.9279508590698242, acc=0.2978888750076294, loss=1.9279508590698242
test: epoch 127, loss 4.308251857757568, acc=0.05000000074505806, loss=4.308251857757568
train: epoch 128, loss 1.9647753238677979, acc=0.2948888838291168, loss=1.9647753238677979
test: epoch 128, loss 4.317784309387207, acc=0.04444444552063942, loss=4.317784309387207
train: epoch 129, loss 1.9570969343185425, acc=0.2940555512905121, loss=1.9570969343185425
test: epoch 129, loss 4.378175258636475, acc=0.04444444552063942, loss=4.378175258636475
train: epoch 130, loss 1.9434229135513306, acc=0.29899999499320984, loss=1.9434229135513306
test: epoch 130, loss 4.204990863800049, acc=0.04722222313284874, loss=4.204990863800049
train: epoch 131, loss 1.9698976278305054, acc=0.3001111149787903, loss=1.9698976278305054
test: epoch 131, loss 4.353300094604492, acc=0.05000000074505806, loss=4.353300094604492
train: epoch 132, loss 1.9529130458831787, acc=0.2974444329738617, loss=1.9529130458831787
test: epoch 132, loss 4.252366542816162, acc=0.0555555559694767, loss=4.252366542816162
train: epoch 133, loss 1.9495141506195068, acc=0.29527777433395386, loss=1.9495141506195068
test: epoch 133, loss 4.343506813049316, acc=0.06111111119389534, loss=4.343506813049316
train: epoch 134, loss 1.9411157369613647, acc=0.2958333194255829, loss=1.9411157369613647
test: epoch 134, loss 4.270610809326172, acc=0.0416666679084301, loss=4.270610809326172
train: epoch 135, loss 1.9584308862686157, acc=0.2937777638435364, loss=1.9584308862686157
test: epoch 135, loss 4.022217750549316, acc=0.06666667014360428, loss=4.022217750549316
train: epoch 136, loss 1.988612174987793, acc=0.2924444377422333, loss=1.988612174987793
test: epoch 136, loss 3.9428718090057373, acc=0.0555555559694767, loss=3.9428718090057373
train: epoch 137, loss 1.9825248718261719, acc=0.292888879776001, loss=1.9825248718261719
test: epoch 137, loss 4.095465660095215, acc=0.06388889253139496, loss=4.095465660095215
train: epoch 138, loss 1.9549918174743652, acc=0.28788888454437256, loss=1.9549918174743652
test: epoch 138, loss 4.153393745422363, acc=0.0555555559694767, loss=4.153393745422363
train: epoch 139, loss 1.992562174797058, acc=0.28999999165534973, loss=1.992562174797058
test: epoch 139, loss 4.0106940269470215, acc=0.05833333358168602, loss=4.0106940269470215
train: epoch 140, loss 1.9981540441513062, acc=0.285055547952652, loss=1.9981540441513062
test: epoch 140, loss 4.033527851104736, acc=0.05833333358168602, loss=4.033527851104736
train: epoch 141, loss 1.9769705533981323, acc=0.28966665267944336, loss=1.9769705533981323
test: epoch 141, loss 4.152502059936523, acc=0.06388889253139496, loss=4.152502059936523
train: epoch 142, loss 1.9878215789794922, acc=0.2832222282886505, loss=1.9878215789794922
test: epoch 142, loss 3.844825267791748, acc=0.0555555559694767, loss=3.844825267791748
train: epoch 143, loss 1.9863752126693726, acc=0.28450000286102295, loss=1.9863752126693726
test: epoch 143, loss 4.076530933380127, acc=0.06666667014360428, loss=4.076530933380127
train: epoch 144, loss 2.0020976066589355, acc=0.2801666557788849, loss=2.0020976066589355
test: epoch 144, loss 4.0496392250061035, acc=0.06666667014360428, loss=4.0496392250061035
train: epoch 145, loss 1.9798675775527954, acc=0.2837222218513489, loss=1.9798675775527954
test: epoch 145, loss 4.001004695892334, acc=0.06666667014360428, loss=4.001004695892334
train: epoch 146, loss 1.9985946416854858, acc=0.2800000011920929, loss=1.9985946416854858
test: epoch 146, loss 4.101459980010986, acc=0.05000000074505806, loss=4.101459980010986
train: epoch 147, loss 2.0056912899017334, acc=0.2780555486679077, loss=2.0056912899017334
test: epoch 147, loss 3.722630262374878, acc=0.04722222313284874, loss=3.722630262374878
train: epoch 148, loss 2.0102052688598633, acc=0.28272223472595215, loss=2.0102052688598633
test: epoch 148, loss 3.8768670558929443, acc=0.05000000074505806, loss=3.8768670558929443
train: epoch 149, loss 2.0096561908721924, acc=0.28172221779823303, loss=2.0096561908721924
test: epoch 149, loss 4.080674171447754, acc=0.04722222313284874, loss=4.080674171447754
train: epoch 150, loss 2.0412516593933105, acc=0.273333340883255, loss=2.0412516593933105
test: epoch 150, loss 3.9606475830078125, acc=0.05833333358168602, loss=3.9606475830078125
