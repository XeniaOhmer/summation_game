# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=32", "--temperature=2.0", "--temp_decay=0.99", "--one_hot=0", "--n_layers=1"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=1778477756, receiver_embed_dim=32, save_run=0, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=1778477756, receiver_embed_dim=32, save_run=False, temp_decay=0.99, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.145153284072876, acc=0.08516667038202286, loss=3.145153284072876
test: epoch 1, loss 4.636044979095459, acc=0.0416666679084301, loss=4.636044979095459
train: epoch 2, loss 2.617694854736328, acc=0.15594445168972015, loss=2.617694854736328
test: epoch 2, loss 5.685903072357178, acc=0.04444444552063942, loss=5.685903072357178
train: epoch 3, loss 2.4566547870635986, acc=0.1756666600704193, loss=2.4566547870635986
test: epoch 3, loss 6.276898384094238, acc=0.04722222313284874, loss=6.276898384094238
train: epoch 4, loss 2.346121072769165, acc=0.19877777993679047, loss=2.346121072769165
test: epoch 4, loss 6.94389009475708, acc=0.03888889029622078, loss=6.94389009475708
train: epoch 5, loss 2.280930757522583, acc=0.216888889670372, loss=2.280930757522583
test: epoch 5, loss 7.441306114196777, acc=0.0416666679084301, loss=7.441306114196777
train: epoch 6, loss 2.2239434719085693, acc=0.22077777981758118, loss=2.2239434719085693
test: epoch 6, loss 7.878764629364014, acc=0.03888889029622078, loss=7.878764629364014
train: epoch 7, loss 2.1790902614593506, acc=0.23116666078567505, loss=2.1790902614593506
test: epoch 7, loss 8.007866859436035, acc=0.03611111268401146, loss=8.007866859436035
train: epoch 8, loss 2.150191307067871, acc=0.23427778482437134, loss=2.150191307067871
test: epoch 8, loss 8.450814247131348, acc=0.04444444552063942, loss=8.450814247131348
train: epoch 9, loss 2.1150763034820557, acc=0.2412777841091156, loss=2.1150763034820557
test: epoch 9, loss 8.68991470336914, acc=0.04444444552063942, loss=8.68991470336914
train: epoch 10, loss 2.0987350940704346, acc=0.2520555555820465, loss=2.0987350940704346
test: epoch 10, loss 8.677961349487305, acc=0.0416666679084301, loss=8.677961349487305
train: epoch 11, loss 2.077848196029663, acc=0.24933333694934845, loss=2.077848196029663
test: epoch 11, loss 8.828529357910156, acc=0.05000000074505806, loss=8.828529357910156
train: epoch 12, loss 2.059420108795166, acc=0.25850000977516174, loss=2.059420108795166
test: epoch 12, loss 8.946598052978516, acc=0.04722222313284874, loss=8.946598052978516
train: epoch 13, loss 2.0505855083465576, acc=0.25555557012557983, loss=2.0505855083465576
test: epoch 13, loss 9.119351387023926, acc=0.0416666679084301, loss=9.119351387023926
train: epoch 14, loss 2.0244300365448, acc=0.2657777667045593, loss=2.0244300365448
test: epoch 14, loss 9.069936752319336, acc=0.0416666679084301, loss=9.069936752319336
train: epoch 15, loss 2.022826910018921, acc=0.262111097574234, loss=2.022826910018921
test: epoch 15, loss 9.126209259033203, acc=0.04722222313284874, loss=9.126209259033203
train: epoch 16, loss 2.0222008228302, acc=0.2579444348812103, loss=2.0222008228302
test: epoch 16, loss 9.303689002990723, acc=0.03888889029622078, loss=9.303689002990723
train: epoch 17, loss 2.006681442260742, acc=0.26516667008399963, loss=2.006681442260742
test: epoch 17, loss 9.4144868850708, acc=0.04722222313284874, loss=9.4144868850708
train: epoch 18, loss 1.9957923889160156, acc=0.2701111137866974, loss=1.9957923889160156
test: epoch 18, loss 9.545951843261719, acc=0.04444444552063942, loss=9.545951843261719
train: epoch 19, loss 1.994969367980957, acc=0.26588889956474304, loss=1.994969367980957
test: epoch 19, loss 9.197481155395508, acc=0.04722222313284874, loss=9.197481155395508
train: epoch 20, loss 1.9852887392044067, acc=0.2681666612625122, loss=1.9852887392044067
test: epoch 20, loss 9.143835067749023, acc=0.05000000074505806, loss=9.143835067749023
train: epoch 21, loss 1.9823551177978516, acc=0.265500009059906, loss=1.9823551177978516
test: epoch 21, loss 9.007410049438477, acc=0.04722222313284874, loss=9.007410049438477
train: epoch 22, loss 1.9708837270736694, acc=0.27300000190734863, loss=1.9708837270736694
test: epoch 22, loss 9.098941802978516, acc=0.0416666679084301, loss=9.098941802978516
train: epoch 23, loss 1.9827795028686523, acc=0.26944443583488464, loss=1.9827795028686523
test: epoch 23, loss 8.715150833129883, acc=0.03888889029622078, loss=8.715150833129883
train: epoch 24, loss 1.9785982370376587, acc=0.26883333921432495, loss=1.9785982370376587
test: epoch 24, loss 8.639763832092285, acc=0.04722222313284874, loss=8.639763832092285
train: epoch 25, loss 1.9642733335494995, acc=0.2746666669845581, loss=1.9642733335494995
test: epoch 25, loss 8.478306770324707, acc=0.04444444552063942, loss=8.478306770324707
train: epoch 26, loss 1.9652037620544434, acc=0.27444443106651306, loss=1.9652037620544434
test: epoch 26, loss 8.676445007324219, acc=0.03888889029622078, loss=8.676445007324219
train: epoch 27, loss 1.9649419784545898, acc=0.28005555272102356, loss=1.9649419784545898
test: epoch 27, loss 8.497896194458008, acc=0.04444444552063942, loss=8.497896194458008
train: epoch 28, loss 1.972617745399475, acc=0.2750000059604645, loss=1.972617745399475
test: epoch 28, loss 8.298700332641602, acc=0.04444444552063942, loss=8.298700332641602
train: epoch 29, loss 1.9683119058609009, acc=0.28005555272102356, loss=1.9683119058609009
test: epoch 29, loss 7.987188339233398, acc=0.04444444552063942, loss=7.987188339233398
train: epoch 30, loss 1.957992434501648, acc=0.27738890051841736, loss=1.957992434501648
test: epoch 30, loss 7.841660022735596, acc=0.05277777835726738, loss=7.841660022735596
train: epoch 31, loss 1.9761030673980713, acc=0.28172221779823303, loss=1.9761030673980713
test: epoch 31, loss 7.8172502517700195, acc=0.05277777835726738, loss=7.8172502517700195
train: epoch 32, loss 1.972373127937317, acc=0.2777777910232544, loss=1.972373127937317
test: epoch 32, loss 7.923680305480957, acc=0.05000000074505806, loss=7.923680305480957
train: epoch 33, loss 1.9693697690963745, acc=0.27122223377227783, loss=1.9693697690963745
test: epoch 33, loss 7.880286693572998, acc=0.04722222313284874, loss=7.880286693572998
train: epoch 34, loss 1.9658093452453613, acc=0.2780555486679077, loss=1.9658093452453613
test: epoch 34, loss 7.5658464431762695, acc=0.05000000074505806, loss=7.5658464431762695
train: epoch 35, loss 1.9890130758285522, acc=0.2765555679798126, loss=1.9890130758285522
test: epoch 35, loss 7.3318376541137695, acc=0.04722222313284874, loss=7.3318376541137695
train: epoch 36, loss 1.9790518283843994, acc=0.27477777004241943, loss=1.9790518283843994
test: epoch 36, loss 7.295874118804932, acc=0.04444444552063942, loss=7.295874118804932
train: epoch 37, loss 1.9734405279159546, acc=0.281333327293396, loss=1.9734405279159546
test: epoch 37, loss 6.877396106719971, acc=0.04444444552063942, loss=6.877396106719971
train: epoch 38, loss 1.9832887649536133, acc=0.27516666054725647, loss=1.9832887649536133
test: epoch 38, loss 6.966284275054932, acc=0.04444444552063942, loss=6.966284275054932
train: epoch 39, loss 1.9913783073425293, acc=0.2778888940811157, loss=1.9913783073425293
test: epoch 39, loss 6.92601203918457, acc=0.04722222313284874, loss=6.92601203918457
train: epoch 40, loss 1.9778504371643066, acc=0.27783334255218506, loss=1.9778504371643066
test: epoch 40, loss 6.78277587890625, acc=0.05277777835726738, loss=6.78277587890625
train: epoch 41, loss 1.9905149936676025, acc=0.27772220969200134, loss=1.9905149936676025
test: epoch 41, loss 6.691567897796631, acc=0.05277777835726738, loss=6.691567897796631
train: epoch 42, loss 1.9972772598266602, acc=0.27711111307144165, loss=1.9972772598266602
test: epoch 42, loss 6.249260902404785, acc=0.05000000074505806, loss=6.249260902404785
train: epoch 43, loss 1.9923913478851318, acc=0.27861112356185913, loss=1.9923913478851318
test: epoch 43, loss 6.424678802490234, acc=0.05277777835726738, loss=6.424678802490234
train: epoch 44, loss 1.9979642629623413, acc=0.27149999141693115, loss=1.9979642629623413
test: epoch 44, loss 6.299545764923096, acc=0.04444444552063942, loss=6.299545764923096
train: epoch 45, loss 2.0005836486816406, acc=0.2722777724266052, loss=2.0005836486816406
test: epoch 45, loss 6.181197166442871, acc=0.05000000074505806, loss=6.181197166442871
train: epoch 46, loss 1.996661901473999, acc=0.2791111171245575, loss=1.996661901473999
test: epoch 46, loss 6.322962284088135, acc=0.04722222313284874, loss=6.322962284088135
train: epoch 47, loss 1.995951771736145, acc=0.2740555703639984, loss=1.995951771736145
test: epoch 47, loss 6.042306900024414, acc=0.04722222313284874, loss=6.042306900024414
train: epoch 48, loss 2.005321741104126, acc=0.269222229719162, loss=2.005321741104126
test: epoch 48, loss 5.897185802459717, acc=0.04444444552063942, loss=5.897185802459717
train: epoch 49, loss 2.012237548828125, acc=0.27205556631088257, loss=2.012237548828125
test: epoch 49, loss 5.80694580078125, acc=0.05000000074505806, loss=5.80694580078125
train: epoch 50, loss 2.034982919692993, acc=0.2713888883590698, loss=2.034982919692993
test: epoch 50, loss 5.831916332244873, acc=0.04444444552063942, loss=5.831916332244873
train: epoch 51, loss 2.0221686363220215, acc=0.2724444568157196, loss=2.0221686363220215
test: epoch 51, loss 5.633387565612793, acc=0.03888889029622078, loss=5.633387565612793
train: epoch 52, loss 2.0362110137939453, acc=0.2653888761997223, loss=2.0362110137939453
test: epoch 52, loss 5.635794162750244, acc=0.03611111268401146, loss=5.635794162750244
train: epoch 53, loss 2.044126510620117, acc=0.26216667890548706, loss=2.044126510620117
test: epoch 53, loss 5.539551734924316, acc=0.0416666679084301, loss=5.539551734924316
train: epoch 54, loss 2.048138380050659, acc=0.26544445753097534, loss=2.048138380050659
test: epoch 54, loss 5.267716407775879, acc=0.05277777835726738, loss=5.267716407775879
train: epoch 55, loss 2.0492725372314453, acc=0.2624444365501404, loss=2.0492725372314453
test: epoch 55, loss 5.042603492736816, acc=0.0416666679084301, loss=5.042603492736816
train: epoch 56, loss 2.0601892471313477, acc=0.26688888669013977, loss=2.0601892471313477
test: epoch 56, loss 4.9547858238220215, acc=0.05000000074505806, loss=4.9547858238220215
train: epoch 57, loss 2.05169677734375, acc=0.26866665482521057, loss=2.05169677734375
test: epoch 57, loss 4.9362311363220215, acc=0.03888889029622078, loss=4.9362311363220215
train: epoch 58, loss 2.0704970359802246, acc=0.26383334398269653, loss=2.0704970359802246
test: epoch 58, loss 4.900447368621826, acc=0.04444444552063942, loss=4.900447368621826
train: epoch 59, loss 2.0714051723480225, acc=0.25822222232818604, loss=2.0714051723480225
test: epoch 59, loss 4.906797409057617, acc=0.0416666679084301, loss=4.906797409057617
train: epoch 60, loss 2.085108995437622, acc=0.25699999928474426, loss=2.085108995437622
test: epoch 60, loss 4.574342250823975, acc=0.05000000074505806, loss=4.574342250823975
train: epoch 61, loss 2.077803373336792, acc=0.2603333294391632, loss=2.077803373336792
test: epoch 61, loss 4.661752223968506, acc=0.04444444552063942, loss=4.661752223968506
train: epoch 62, loss 2.088432788848877, acc=0.2567777633666992, loss=2.088432788848877
test: epoch 62, loss 4.453263282775879, acc=0.04444444552063942, loss=4.453263282775879
train: epoch 63, loss 2.0919830799102783, acc=0.2529444396495819, loss=2.0919830799102783
test: epoch 63, loss 4.449389457702637, acc=0.03888889029622078, loss=4.449389457702637
train: epoch 64, loss 2.0962138175964355, acc=0.2546111047267914, loss=2.0962138175964355
test: epoch 64, loss 4.3683576583862305, acc=0.04444444552063942, loss=4.3683576583862305
train: epoch 65, loss 2.100476026535034, acc=0.2556111216545105, loss=2.100476026535034
test: epoch 65, loss 4.336157321929932, acc=0.0416666679084301, loss=4.336157321929932
train: epoch 66, loss 2.1268725395202637, acc=0.2418888956308365, loss=2.1268725395202637
test: epoch 66, loss 4.2067413330078125, acc=0.0416666679084301, loss=4.2067413330078125
train: epoch 67, loss 2.100076913833618, acc=0.24711111187934875, loss=2.100076913833618
test: epoch 67, loss 4.1619672775268555, acc=0.03888889029622078, loss=4.1619672775268555
train: epoch 68, loss 2.109436511993408, acc=0.24950000643730164, loss=2.109436511993408
test: epoch 68, loss 4.2789716720581055, acc=0.06111111119389534, loss=4.2789716720581055
train: epoch 69, loss 2.1269662380218506, acc=0.25094443559646606, loss=2.1269662380218506
test: epoch 69, loss 4.148097038269043, acc=0.05277777835726738, loss=4.148097038269043
train: epoch 70, loss 2.1510419845581055, acc=0.24338889122009277, loss=2.1510419845581055
test: epoch 70, loss 3.9023208618164062, acc=0.05000000074505806, loss=3.9023208618164062
train: epoch 71, loss 2.1396710872650146, acc=0.24077777564525604, loss=2.1396710872650146
test: epoch 71, loss 4.178633689880371, acc=0.0416666679084301, loss=4.178633689880371
train: epoch 72, loss 2.150707244873047, acc=0.24238888919353485, loss=2.150707244873047
test: epoch 72, loss 4.062814712524414, acc=0.05833333358168602, loss=4.062814712524414
train: epoch 73, loss 2.1541566848754883, acc=0.23999999463558197, loss=2.1541566848754883
test: epoch 73, loss 4.115599155426025, acc=0.05000000074505806, loss=4.115599155426025
train: epoch 74, loss 2.1606743335723877, acc=0.23677778244018555, loss=2.1606743335723877
test: epoch 74, loss 3.919374704360962, acc=0.05277777835726738, loss=3.919374704360962
train: epoch 75, loss 2.1808738708496094, acc=0.24088889360427856, loss=2.1808738708496094
test: epoch 75, loss 3.9925127029418945, acc=0.04722222313284874, loss=3.9925127029418945
train: epoch 76, loss 2.1652774810791016, acc=0.23661111295223236, loss=2.1652774810791016
test: epoch 76, loss 3.921645164489746, acc=0.05277777835726738, loss=3.921645164489746
train: epoch 77, loss 2.174100160598755, acc=0.23605555295944214, loss=2.174100160598755
test: epoch 77, loss 3.9044923782348633, acc=0.04722222313284874, loss=3.9044923782348633
train: epoch 78, loss 2.1735236644744873, acc=0.2374444454908371, loss=2.1735236644744873
test: epoch 78, loss 3.778160810470581, acc=0.05833333358168602, loss=3.778160810470581
train: epoch 79, loss 2.1921117305755615, acc=0.23544444143772125, loss=2.1921117305755615
test: epoch 79, loss 3.8290042877197266, acc=0.04444444552063942, loss=3.8290042877197266
train: epoch 80, loss 2.1763195991516113, acc=0.23416666686534882, loss=2.1763195991516113
test: epoch 80, loss 3.6234865188598633, acc=0.0555555559694767, loss=3.6234865188598633
train: epoch 81, loss 2.216820240020752, acc=0.22877778112888336, loss=2.216820240020752
test: epoch 81, loss 3.6833620071411133, acc=0.04722222313284874, loss=3.6833620071411133
train: epoch 82, loss 2.207852602005005, acc=0.22805555164813995, loss=2.207852602005005
test: epoch 82, loss 3.6586880683898926, acc=0.05833333358168602, loss=3.6586880683898926
train: epoch 83, loss 2.2022392749786377, acc=0.22538888454437256, loss=2.2022392749786377
test: epoch 83, loss 3.6591665744781494, acc=0.05000000074505806, loss=3.6591665744781494
train: epoch 84, loss 2.203993797302246, acc=0.22316665947437286, loss=2.203993797302246
test: epoch 84, loss 3.6780030727386475, acc=0.05277777835726738, loss=3.6780030727386475
train: epoch 85, loss 2.232450008392334, acc=0.22188888490200043, loss=2.232450008392334
test: epoch 85, loss 3.5796780586242676, acc=0.05833333358168602, loss=3.5796780586242676
train: epoch 86, loss 2.257422685623169, acc=0.2182222157716751, loss=2.257422685623169
test: epoch 86, loss 3.5405192375183105, acc=0.05277777835726738, loss=3.5405192375183105
train: epoch 87, loss 2.2461836338043213, acc=0.21449999511241913, loss=2.2461836338043213
test: epoch 87, loss 3.471487283706665, acc=0.0694444477558136, loss=3.471487283706665
train: epoch 88, loss 2.231513023376465, acc=0.21855555474758148, loss=2.231513023376465
test: epoch 88, loss 3.3827619552612305, acc=0.08888889104127884, loss=3.3827619552612305
train: epoch 89, loss 2.255587339401245, acc=0.21238888800144196, loss=2.255587339401245
test: epoch 89, loss 3.488492965698242, acc=0.06388889253139496, loss=3.488492965698242
train: epoch 90, loss 2.2480173110961914, acc=0.21477778255939484, loss=2.2480173110961914
test: epoch 90, loss 3.4669899940490723, acc=0.06388889253139496, loss=3.4669899940490723
train: epoch 91, loss 2.25443696975708, acc=0.21294444799423218, loss=2.25443696975708
test: epoch 91, loss 3.482619047164917, acc=0.06666667014360428, loss=3.482619047164917
train: epoch 92, loss 2.2483906745910645, acc=0.2101111114025116, loss=2.2483906745910645
test: epoch 92, loss 3.4364969730377197, acc=0.05833333358168602, loss=3.4364969730377197
train: epoch 93, loss 2.2519659996032715, acc=0.2103888839483261, loss=2.2519659996032715
test: epoch 93, loss 3.3850483894348145, acc=0.0694444477558136, loss=3.3850483894348145
train: epoch 94, loss 2.279270648956299, acc=0.20755556225776672, loss=2.279270648956299
test: epoch 94, loss 3.280172109603882, acc=0.07222222536802292, loss=3.280172109603882
train: epoch 95, loss 2.284405469894409, acc=0.2047777771949768, loss=2.284405469894409
test: epoch 95, loss 3.38427734375, acc=0.0694444477558136, loss=3.38427734375
train: epoch 96, loss 2.276571273803711, acc=0.20794443786144257, loss=2.276571273803711
test: epoch 96, loss 3.3321926593780518, acc=0.08611111342906952, loss=3.3321926593780518
train: epoch 97, loss 2.2788197994232178, acc=0.20277777314186096, loss=2.2788197994232178
test: epoch 97, loss 3.321882486343384, acc=0.0694444477558136, loss=3.321882486343384
train: epoch 98, loss 2.3045225143432617, acc=0.20572222769260406, loss=2.3045225143432617
test: epoch 98, loss 3.261573076248169, acc=0.09444444626569748, loss=3.261573076248169
train: epoch 99, loss 2.2863051891326904, acc=0.20177777111530304, loss=2.2863051891326904
test: epoch 99, loss 3.176386833190918, acc=0.0833333358168602, loss=3.176386833190918
train: epoch 100, loss 2.28544282913208, acc=0.19861111044883728, loss=2.28544282913208
test: epoch 100, loss 3.225961446762085, acc=0.0694444477558136, loss=3.225961446762085
train: epoch 101, loss 2.2800984382629395, acc=0.20322221517562866, loss=2.2800984382629395
test: epoch 101, loss 3.216773271560669, acc=0.06666667014360428, loss=3.216773271560669
train: epoch 102, loss 2.289506435394287, acc=0.20233333110809326, loss=2.289506435394287
test: epoch 102, loss 3.1334962844848633, acc=0.08611111342906952, loss=3.1334962844848633
train: epoch 103, loss 2.2834649085998535, acc=0.20355555415153503, loss=2.2834649085998535
test: epoch 103, loss 3.169825553894043, acc=0.08888889104127884, loss=3.169825553894043
train: epoch 104, loss 2.2936418056488037, acc=0.20505554974079132, loss=2.2936418056488037
test: epoch 104, loss 3.153886318206787, acc=0.07500000298023224, loss=3.153886318206787
train: epoch 105, loss 2.2862510681152344, acc=0.20244444906711578, loss=2.2862510681152344
test: epoch 105, loss 3.259523630142212, acc=0.08055555820465088, loss=3.259523630142212
train: epoch 106, loss 2.2869961261749268, acc=0.19927777349948883, loss=2.2869961261749268
test: epoch 106, loss 3.169733762741089, acc=0.06666667014360428, loss=3.169733762741089
train: epoch 107, loss 2.2668285369873047, acc=0.2022777795791626, loss=2.2668285369873047
test: epoch 107, loss 3.1303908824920654, acc=0.07777778059244156, loss=3.1303908824920654
train: epoch 108, loss 2.2690746784210205, acc=0.20527777075767517, loss=2.2690746784210205
test: epoch 108, loss 3.1905031204223633, acc=0.07222222536802292, loss=3.1905031204223633
train: epoch 109, loss 2.274413824081421, acc=0.20011110603809357, loss=2.274413824081421
test: epoch 109, loss 3.1977505683898926, acc=0.07222222536802292, loss=3.1977505683898926
train: epoch 110, loss 2.274967670440674, acc=0.20633333921432495, loss=2.274967670440674
test: epoch 110, loss 3.1384410858154297, acc=0.06666667014360428, loss=3.1384410858154297
train: epoch 111, loss 2.277667284011841, acc=0.20200000703334808, loss=2.277667284011841
test: epoch 111, loss 3.1811892986297607, acc=0.07777778059244156, loss=3.1811892986297607
train: epoch 112, loss 2.267476797103882, acc=0.2036111056804657, loss=2.267476797103882
test: epoch 112, loss 3.14070987701416, acc=0.0833333358168602, loss=3.14070987701416
train: epoch 113, loss 2.2687065601348877, acc=0.20494444668293, loss=2.2687065601348877
test: epoch 113, loss 3.2069509029388428, acc=0.07500000298023224, loss=3.2069509029388428
train: epoch 114, loss 2.278140068054199, acc=0.20350000262260437, loss=2.278140068054199
test: epoch 114, loss 3.0166454315185547, acc=0.08888889104127884, loss=3.0166454315185547
train: epoch 115, loss 2.2770578861236572, acc=0.20144444704055786, loss=2.2770578861236572
test: epoch 115, loss 3.116053581237793, acc=0.07777778059244156, loss=3.116053581237793
train: epoch 116, loss 2.2768876552581787, acc=0.20411111414432526, loss=2.2768876552581787
test: epoch 116, loss 3.2673428058624268, acc=0.07777778059244156, loss=3.2673428058624268
train: epoch 117, loss 2.300259590148926, acc=0.20844444632530212, loss=2.300259590148926
test: epoch 117, loss 3.0679855346679688, acc=0.06666667014360428, loss=3.0679855346679688
train: epoch 118, loss 2.251305341720581, acc=0.2067222148180008, loss=2.251305341720581
test: epoch 118, loss 3.1625194549560547, acc=0.09166666865348816, loss=3.1625194549560547
train: epoch 119, loss 2.2813079357147217, acc=0.20016667246818542, loss=2.2813079357147217
test: epoch 119, loss 3.147608518600464, acc=0.07500000298023224, loss=3.147608518600464
train: epoch 120, loss 2.2532002925872803, acc=0.20605555176734924, loss=2.2532002925872803
test: epoch 120, loss 3.2428689002990723, acc=0.06111111119389534, loss=3.2428689002990723
train: epoch 121, loss 2.264566421508789, acc=0.20200000703334808, loss=2.264566421508789
test: epoch 121, loss 3.2636325359344482, acc=0.0694444477558136, loss=3.2636325359344482
train: epoch 122, loss 2.25545072555542, acc=0.20888888835906982, loss=2.25545072555542
test: epoch 122, loss 3.1707801818847656, acc=0.06111111119389534, loss=3.1707801818847656
train: epoch 123, loss 2.243056535720825, acc=0.20561110973358154, loss=2.243056535720825
test: epoch 123, loss 3.130462646484375, acc=0.08055555820465088, loss=3.130462646484375
train: epoch 124, loss 2.241114616394043, acc=0.2056666612625122, loss=2.241114616394043
test: epoch 124, loss 3.2420763969421387, acc=0.06388889253139496, loss=3.2420763969421387
train: epoch 125, loss 2.272395372390747, acc=0.20661111176013947, loss=2.272395372390747
test: epoch 125, loss 3.154115915298462, acc=0.07777778059244156, loss=3.154115915298462
train: epoch 126, loss 2.2513465881347656, acc=0.20172221958637238, loss=2.2513465881347656
test: epoch 126, loss 3.200127124786377, acc=0.07500000298023224, loss=3.200127124786377
train: epoch 127, loss 2.259549617767334, acc=0.20838889479637146, loss=2.259549617767334
test: epoch 127, loss 3.1322953701019287, acc=0.07222222536802292, loss=3.1322953701019287
train: epoch 128, loss 2.252335786819458, acc=0.20288889110088348, loss=2.252335786819458
test: epoch 128, loss 3.1438121795654297, acc=0.06388889253139496, loss=3.1438121795654297
train: epoch 129, loss 2.2429592609405518, acc=0.2047777771949768, loss=2.2429592609405518
test: epoch 129, loss 3.0965042114257812, acc=0.0833333358168602, loss=3.0965042114257812
train: epoch 130, loss 2.24017333984375, acc=0.20772221684455872, loss=2.24017333984375
test: epoch 130, loss 3.23201847076416, acc=0.07222222536802292, loss=3.23201847076416
train: epoch 131, loss 2.238119602203369, acc=0.20283333957195282, loss=2.238119602203369
test: epoch 131, loss 3.1027462482452393, acc=0.08611111342906952, loss=3.1027462482452393
train: epoch 132, loss 2.236436605453491, acc=0.20544444024562836, loss=2.236436605453491
test: epoch 132, loss 3.169328212738037, acc=0.07777778059244156, loss=3.169328212738037
train: epoch 133, loss 2.263676643371582, acc=0.20955555140972137, loss=2.263676643371582
test: epoch 133, loss 3.0637638568878174, acc=0.08611111342906952, loss=3.0637638568878174
train: epoch 134, loss 2.2492074966430664, acc=0.20472222566604614, loss=2.2492074966430664
test: epoch 134, loss 3.1595683097839355, acc=0.05833333358168602, loss=3.1595683097839355
train: epoch 135, loss 2.2207915782928467, acc=0.20855554938316345, loss=2.2207915782928467
test: epoch 135, loss 3.164595603942871, acc=0.04444444552063942, loss=3.164595603942871
train: epoch 136, loss 2.24214243888855, acc=0.20972222089767456, loss=2.24214243888855
test: epoch 136, loss 3.1613106727600098, acc=0.05277777835726738, loss=3.1613106727600098
train: epoch 137, loss 2.252087116241455, acc=0.21033333241939545, loss=2.252087116241455
test: epoch 137, loss 3.1460633277893066, acc=0.05277777835726738, loss=3.1460633277893066
train: epoch 138, loss 2.23765230178833, acc=0.2101111114025116, loss=2.23765230178833
test: epoch 138, loss 3.1126859188079834, acc=0.07500000298023224, loss=3.1126859188079834
train: epoch 139, loss 2.238163709640503, acc=0.20738889276981354, loss=2.238163709640503
test: epoch 139, loss 3.0778470039367676, acc=0.07222222536802292, loss=3.0778470039367676
train: epoch 140, loss 2.2301361560821533, acc=0.21133333444595337, loss=2.2301361560821533
test: epoch 140, loss 3.1987602710723877, acc=0.06388889253139496, loss=3.1987602710723877
train: epoch 141, loss 2.2500503063201904, acc=0.20661111176013947, loss=2.2500503063201904
test: epoch 141, loss 3.1182963848114014, acc=0.05277777835726738, loss=3.1182963848114014
train: epoch 142, loss 2.2224388122558594, acc=0.2136666625738144, loss=2.2224388122558594
test: epoch 142, loss 3.281127691268921, acc=0.07500000298023224, loss=3.281127691268921
train: epoch 143, loss 2.2390687465667725, acc=0.20838889479637146, loss=2.2390687465667725
test: epoch 143, loss 3.179964542388916, acc=0.0694444477558136, loss=3.179964542388916
train: epoch 144, loss 2.2422971725463867, acc=0.21027778089046478, loss=2.2422971725463867
test: epoch 144, loss 3.1776745319366455, acc=0.0694444477558136, loss=3.1776745319366455
train: epoch 145, loss 2.2263426780700684, acc=0.2099444419145584, loss=2.2263426780700684
test: epoch 145, loss 3.196014165878296, acc=0.05277777835726738, loss=3.196014165878296
train: epoch 146, loss 2.230950355529785, acc=0.2139444500207901, loss=2.230950355529785
test: epoch 146, loss 3.168687582015991, acc=0.06111111119389534, loss=3.168687582015991
train: epoch 147, loss 2.2166547775268555, acc=0.2089444398880005, loss=2.2166547775268555
test: epoch 147, loss 3.1227011680603027, acc=0.08611111342906952, loss=3.1227011680603027
train: epoch 148, loss 2.225806713104248, acc=0.2134999930858612, loss=2.225806713104248
test: epoch 148, loss 3.1235263347625732, acc=0.0694444477558136, loss=3.1235263347625732
train: epoch 149, loss 2.2370758056640625, acc=0.21122221648693085, loss=2.2370758056640625
test: epoch 149, loss 3.1502292156219482, acc=0.0833333358168602, loss=3.1502292156219482
train: epoch 150, loss 2.244614362716675, acc=0.2062777727842331, loss=2.244614362716675
test: epoch 150, loss 3.1095616817474365, acc=0.08611111342906952, loss=3.1095616817474365
