# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=64", "--temperature=2.0", "--temp_decay=1", "--one_hot=0", "--n_layers=1"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=2032904085, receiver_embed_dim=64, save_run=0, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=2032904085, receiver_embed_dim=64, save_run=False, temp_decay=1.0, temperature=2.0, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.0918021202087402, acc=0.092777781188488, loss=3.0918021202087402
test: epoch 1, loss 5.341821670532227, acc=0.0416666679084301, loss=5.341821670532227
train: epoch 2, loss 2.5419933795928955, acc=0.17011110484600067, loss=2.5419933795928955
test: epoch 2, loss 6.6230387687683105, acc=0.04444444552063942, loss=6.6230387687683105
train: epoch 3, loss 2.3728935718536377, acc=0.1926666647195816, loss=2.3728935718536377
test: epoch 3, loss 7.533679962158203, acc=0.03888889029622078, loss=7.533679962158203
train: epoch 4, loss 2.2736642360687256, acc=0.21166667342185974, loss=2.2736642360687256
test: epoch 4, loss 8.286160469055176, acc=0.03888889029622078, loss=8.286160469055176
train: epoch 5, loss 2.205578088760376, acc=0.22405555844306946, loss=2.205578088760376
test: epoch 5, loss 8.655852317810059, acc=0.03888889029622078, loss=8.655852317810059
train: epoch 6, loss 2.150076389312744, acc=0.2383333295583725, loss=2.150076389312744
test: epoch 6, loss 9.09762954711914, acc=0.03611111268401146, loss=9.09762954711914
train: epoch 7, loss 2.104689121246338, acc=0.24622222781181335, loss=2.104689121246338
test: epoch 7, loss 9.556218147277832, acc=0.03888889029622078, loss=9.556218147277832
train: epoch 8, loss 2.069134473800659, acc=0.2516111135482788, loss=2.069134473800659
test: epoch 8, loss 9.934784889221191, acc=0.04444444552063942, loss=9.934784889221191
train: epoch 9, loss 2.0329439640045166, acc=0.2630000114440918, loss=2.0329439640045166
test: epoch 9, loss 10.250401496887207, acc=0.03611111268401146, loss=10.250401496887207
train: epoch 10, loss 2.0072100162506104, acc=0.2663888931274414, loss=2.0072100162506104
test: epoch 10, loss 10.588188171386719, acc=0.03888889029622078, loss=10.588188171386719
train: epoch 11, loss 1.959233283996582, acc=0.2764444351196289, loss=1.959233283996582
test: epoch 11, loss 11.004556655883789, acc=0.03611111268401146, loss=11.004556655883789
train: epoch 12, loss 1.9539966583251953, acc=0.2750000059604645, loss=1.9539966583251953
test: epoch 12, loss 11.288217544555664, acc=0.02777777798473835, loss=11.288217544555664
train: epoch 13, loss 1.9374358654022217, acc=0.27988889813423157, loss=1.9374358654022217
test: epoch 13, loss 11.109313011169434, acc=0.03055555559694767, loss=11.109313011169434
train: epoch 14, loss 1.9048892259597778, acc=0.29338890314102173, loss=1.9048892259597778
test: epoch 14, loss 11.71239948272705, acc=0.03333333507180214, loss=11.71239948272705
train: epoch 15, loss 1.8967112302780151, acc=0.29483333230018616, loss=1.8967112302780151
test: epoch 15, loss 12.191337585449219, acc=0.03333333507180214, loss=12.191337585449219
train: epoch 16, loss 1.8662084341049194, acc=0.2998333275318146, loss=1.8662084341049194
test: epoch 16, loss 12.315165519714355, acc=0.03611111268401146, loss=12.315165519714355
train: epoch 17, loss 1.8548922538757324, acc=0.3072222173213959, loss=1.8548922538757324
test: epoch 17, loss 12.169195175170898, acc=0.03611111268401146, loss=12.169195175170898
train: epoch 18, loss 1.835096001625061, acc=0.3081111013889313, loss=1.835096001625061
test: epoch 18, loss 12.650749206542969, acc=0.03611111268401146, loss=12.650749206542969
train: epoch 19, loss 1.8224996328353882, acc=0.31361111998558044, loss=1.8224996328353882
test: epoch 19, loss 12.48837661743164, acc=0.03333333507180214, loss=12.48837661743164
train: epoch 20, loss 1.8050175905227661, acc=0.3136666715145111, loss=1.8050175905227661
test: epoch 20, loss 12.733635902404785, acc=0.03055555559694767, loss=12.733635902404785
train: epoch 21, loss 1.7999480962753296, acc=0.3142777681350708, loss=1.7999480962753296
test: epoch 21, loss 13.000782012939453, acc=0.03055555559694767, loss=13.000782012939453
train: epoch 22, loss 1.7805321216583252, acc=0.32555556297302246, loss=1.7805321216583252
test: epoch 22, loss 13.456494331359863, acc=0.02777777798473835, loss=13.456494331359863
train: epoch 23, loss 1.7662299871444702, acc=0.32616665959358215, loss=1.7662299871444702
test: epoch 23, loss 13.672051429748535, acc=0.02222222276031971, loss=13.672051429748535
train: epoch 24, loss 1.7615877389907837, acc=0.3316666781902313, loss=1.7615877389907837
test: epoch 24, loss 13.589599609375, acc=0.02777777798473835, loss=13.589599609375
train: epoch 25, loss 1.7530003786087036, acc=0.33161109685897827, loss=1.7530003786087036
test: epoch 25, loss 13.413432121276855, acc=0.02222222276031971, loss=13.413432121276855
train: epoch 26, loss 1.7387868165969849, acc=0.33649998903274536, loss=1.7387868165969849
test: epoch 26, loss 14.004108428955078, acc=0.02500000037252903, loss=14.004108428955078
train: epoch 27, loss 1.7357659339904785, acc=0.34238889813423157, loss=1.7357659339904785
test: epoch 27, loss 14.124460220336914, acc=0.02500000037252903, loss=14.124460220336914
train: epoch 28, loss 1.7107326984405518, acc=0.3457222282886505, loss=1.7107326984405518
test: epoch 28, loss 13.881502151489258, acc=0.02777777798473835, loss=13.881502151489258
train: epoch 29, loss 1.6964517831802368, acc=0.34511110186576843, loss=1.6964517831802368
test: epoch 29, loss 14.638864517211914, acc=0.02777777798473835, loss=14.638864517211914
train: epoch 30, loss 1.6922496557235718, acc=0.35422220826148987, loss=1.6922496557235718
test: epoch 30, loss 14.671738624572754, acc=0.03055555559694767, loss=14.671738624572754
train: epoch 31, loss 1.6833230257034302, acc=0.3527222275733948, loss=1.6833230257034302
test: epoch 31, loss 14.772245407104492, acc=0.02777777798473835, loss=14.772245407104492
train: epoch 32, loss 1.685433030128479, acc=0.35233333706855774, loss=1.685433030128479
test: epoch 32, loss 14.54992961883545, acc=0.02777777798473835, loss=14.54992961883545
train: epoch 33, loss 1.6620564460754395, acc=0.3582777678966522, loss=1.6620564460754395
test: epoch 33, loss 14.884871482849121, acc=0.03333333507180214, loss=14.884871482849121
train: epoch 34, loss 1.655160903930664, acc=0.3658333420753479, loss=1.655160903930664
test: epoch 34, loss 14.712090492248535, acc=0.03055555559694767, loss=14.712090492248535
train: epoch 35, loss 1.6596471071243286, acc=0.35983332991600037, loss=1.6596471071243286
test: epoch 35, loss 14.874645233154297, acc=0.03055555559694767, loss=14.874645233154297
train: epoch 36, loss 1.6367449760437012, acc=0.3692222237586975, loss=1.6367449760437012
test: epoch 36, loss 15.333601951599121, acc=0.02777777798473835, loss=15.333601951599121
train: epoch 37, loss 1.6463598012924194, acc=0.37416666746139526, loss=1.6463598012924194
test: epoch 37, loss 15.306055068969727, acc=0.02500000037252903, loss=15.306055068969727
train: epoch 38, loss 1.6250526905059814, acc=0.3717777729034424, loss=1.6250526905059814
test: epoch 38, loss 15.340717315673828, acc=0.03611111268401146, loss=15.340717315673828
train: epoch 39, loss 1.625203251838684, acc=0.3743889033794403, loss=1.625203251838684
test: epoch 39, loss 15.862117767333984, acc=0.02500000037252903, loss=15.862117767333984
train: epoch 40, loss 1.6036466360092163, acc=0.3790000081062317, loss=1.6036466360092163
test: epoch 40, loss 15.551826477050781, acc=0.03055555559694767, loss=15.551826477050781
train: epoch 41, loss 1.5991692543029785, acc=0.3776666522026062, loss=1.5991692543029785
test: epoch 41, loss 15.66195011138916, acc=0.02500000037252903, loss=15.66195011138916
train: epoch 42, loss 1.5959736108779907, acc=0.38172221183776855, loss=1.5959736108779907
test: epoch 42, loss 15.728470802307129, acc=0.02500000037252903, loss=15.728470802307129
train: epoch 43, loss 1.5898255109786987, acc=0.38644444942474365, loss=1.5898255109786987
test: epoch 43, loss 16.075050354003906, acc=0.02222222276031971, loss=16.075050354003906
train: epoch 44, loss 1.5803616046905518, acc=0.39027777314186096, loss=1.5803616046905518
test: epoch 44, loss 16.00152015686035, acc=0.02222222276031971, loss=16.00152015686035
train: epoch 45, loss 1.5799721479415894, acc=0.3853333294391632, loss=1.5799721479415894
test: epoch 45, loss 16.11681365966797, acc=0.03055555559694767, loss=16.11681365966797
train: epoch 46, loss 1.5731806755065918, acc=0.39444443583488464, loss=1.5731806755065918
test: epoch 46, loss 15.709896087646484, acc=0.03055555559694767, loss=15.709896087646484
train: epoch 47, loss 1.5495373010635376, acc=0.39488887786865234, loss=1.5495373010635376
test: epoch 47, loss 16.248397827148438, acc=0.02777777798473835, loss=16.248397827148438
train: epoch 48, loss 1.5575796365737915, acc=0.3963888883590698, loss=1.5575796365737915
test: epoch 48, loss 16.29399871826172, acc=0.02222222276031971, loss=16.29399871826172
train: epoch 49, loss 1.5561468601226807, acc=0.3990555703639984, loss=1.5561468601226807
test: epoch 49, loss 16.141019821166992, acc=0.02222222276031971, loss=16.141019821166992
train: epoch 50, loss 1.536944031715393, acc=0.4003888964653015, loss=1.536944031715393
test: epoch 50, loss 16.345388412475586, acc=0.02500000037252903, loss=16.345388412475586
train: epoch 51, loss 1.553691029548645, acc=0.40183332562446594, loss=1.553691029548645
test: epoch 51, loss 16.85201072692871, acc=0.02222222276031971, loss=16.85201072692871
train: epoch 52, loss 1.541496753692627, acc=0.40094444155693054, loss=1.541496753692627
test: epoch 52, loss 17.17720603942871, acc=0.01944444514811039, loss=17.17720603942871
train: epoch 53, loss 1.5284888744354248, acc=0.4187777638435364, loss=1.5284888744354248
test: epoch 53, loss 17.283004760742188, acc=0.01666666753590107, loss=17.283004760742188
train: epoch 54, loss 1.5181405544281006, acc=0.40833333134651184, loss=1.5181405544281006
test: epoch 54, loss 17.059606552124023, acc=0.02222222276031971, loss=17.059606552124023
train: epoch 55, loss 1.517995834350586, acc=0.41438889503479004, loss=1.517995834350586
test: epoch 55, loss 17.495346069335938, acc=0.01666666753590107, loss=17.495346069335938
train: epoch 56, loss 1.516296148300171, acc=0.41761112213134766, loss=1.516296148300171
test: epoch 56, loss 17.540761947631836, acc=0.02222222276031971, loss=17.540761947631836
train: epoch 57, loss 1.4978035688400269, acc=0.4147222340106964, loss=1.4978035688400269
test: epoch 57, loss 17.20802116394043, acc=0.02222222276031971, loss=17.20802116394043
train: epoch 58, loss 1.495803952217102, acc=0.4169444441795349, loss=1.495803952217102
test: epoch 58, loss 17.3302001953125, acc=0.01666666753590107, loss=17.3302001953125
train: epoch 59, loss 1.498793363571167, acc=0.4256666600704193, loss=1.498793363571167
test: epoch 59, loss 17.168325424194336, acc=0.02500000037252903, loss=17.168325424194336
train: epoch 60, loss 1.489999532699585, acc=0.4261666536331177, loss=1.489999532699585
test: epoch 60, loss 17.538009643554688, acc=0.01666666753590107, loss=17.538009643554688
train: epoch 61, loss 1.48517906665802, acc=0.42516666650772095, loss=1.48517906665802
test: epoch 61, loss 17.795217514038086, acc=0.01666666753590107, loss=17.795217514038086
train: epoch 62, loss 1.475683331489563, acc=0.42149999737739563, loss=1.475683331489563
test: epoch 62, loss 17.449533462524414, acc=0.01666666753590107, loss=17.449533462524414
train: epoch 63, loss 1.4661842584609985, acc=0.42500001192092896, loss=1.4661842584609985
test: epoch 63, loss 17.5679874420166, acc=0.02500000037252903, loss=17.5679874420166
train: epoch 64, loss 1.464517593383789, acc=0.43138888478279114, loss=1.464517593383789
test: epoch 64, loss 17.23111915588379, acc=0.02777777798473835, loss=17.23111915588379
train: epoch 65, loss 1.4780735969543457, acc=0.4295555651187897, loss=1.4780735969543457
test: epoch 65, loss 17.094768524169922, acc=0.02500000037252903, loss=17.094768524169922
train: epoch 66, loss 1.4506568908691406, acc=0.43433332443237305, loss=1.4506568908691406
test: epoch 66, loss 18.138704299926758, acc=0.01666666753590107, loss=18.138704299926758
train: epoch 67, loss 1.4566861391067505, acc=0.4320000112056732, loss=1.4566861391067505
test: epoch 67, loss 18.175630569458008, acc=0.03055555559694767, loss=18.175630569458008
train: epoch 68, loss 1.4502333402633667, acc=0.43799999356269836, loss=1.4502333402633667
test: epoch 68, loss 17.975740432739258, acc=0.01666666753590107, loss=17.975740432739258
train: epoch 69, loss 1.4463404417037964, acc=0.43877777457237244, loss=1.4463404417037964
test: epoch 69, loss 17.765655517578125, acc=0.02777777798473835, loss=17.765655517578125
train: epoch 70, loss 1.4521636962890625, acc=0.43761110305786133, loss=1.4521636962890625
test: epoch 70, loss 18.241840362548828, acc=0.02777777798473835, loss=18.241840362548828
train: epoch 71, loss 1.4364746809005737, acc=0.44522222876548767, loss=1.4364746809005737
test: epoch 71, loss 17.29891586303711, acc=0.02777777798473835, loss=17.29891586303711
train: epoch 72, loss 1.4215660095214844, acc=0.4450555443763733, loss=1.4215660095214844
test: epoch 72, loss 18.66654396057129, acc=0.01666666753590107, loss=18.66654396057129
train: epoch 73, loss 1.425229787826538, acc=0.4465000033378601, loss=1.425229787826538
test: epoch 73, loss 18.15987777709961, acc=0.02500000037252903, loss=18.15987777709961
train: epoch 74, loss 1.410935640335083, acc=0.44627776741981506, loss=1.410935640335083
test: epoch 74, loss 17.625417709350586, acc=0.02222222276031971, loss=17.625417709350586
train: epoch 75, loss 1.4289400577545166, acc=0.44038888812065125, loss=1.4289400577545166
test: epoch 75, loss 17.553958892822266, acc=0.02777777798473835, loss=17.553958892822266
train: epoch 76, loss 1.4093716144561768, acc=0.4456111192703247, loss=1.4093716144561768
test: epoch 76, loss 18.53295135498047, acc=0.01666666753590107, loss=18.53295135498047
train: epoch 77, loss 1.4126782417297363, acc=0.4514999985694885, loss=1.4126782417297363
test: epoch 77, loss 18.2373104095459, acc=0.01666666753590107, loss=18.2373104095459
train: epoch 78, loss 1.3969179391860962, acc=0.4516666531562805, loss=1.3969179391860962
test: epoch 78, loss 18.538387298583984, acc=0.01944444514811039, loss=18.538387298583984
train: epoch 79, loss 1.4088760614395142, acc=0.4514999985694885, loss=1.4088760614395142
test: epoch 79, loss 18.99510955810547, acc=0.013888888992369175, loss=18.99510955810547
train: epoch 80, loss 1.3986196517944336, acc=0.453000009059906, loss=1.3986196517944336
test: epoch 80, loss 18.49143409729004, acc=0.013888888992369175, loss=18.49143409729004
train: epoch 81, loss 1.3868341445922852, acc=0.46327778697013855, loss=1.3868341445922852
test: epoch 81, loss 18.704753875732422, acc=0.01666666753590107, loss=18.704753875732422
train: epoch 82, loss 1.3835220336914062, acc=0.45722222328186035, loss=1.3835220336914062
test: epoch 82, loss 19.043737411499023, acc=0.013888888992369175, loss=19.043737411499023
train: epoch 83, loss 1.379368782043457, acc=0.4654444456100464, loss=1.379368782043457
test: epoch 83, loss 18.73150634765625, acc=0.013888888992369175, loss=18.73150634765625
train: epoch 84, loss 1.3964005708694458, acc=0.45911112427711487, loss=1.3964005708694458
test: epoch 84, loss 19.046661376953125, acc=0.013888888992369175, loss=19.046661376953125
train: epoch 85, loss 1.3813235759735107, acc=0.46227777004241943, loss=1.3813235759735107
test: epoch 85, loss 19.347917556762695, acc=0.013888888992369175, loss=19.347917556762695
train: epoch 86, loss 1.3812754154205322, acc=0.4680555462837219, loss=1.3812754154205322
test: epoch 86, loss 20.004289627075195, acc=0.013888888992369175, loss=20.004289627075195
train: epoch 87, loss 1.362013816833496, acc=0.46433332562446594, loss=1.362013816833496
test: epoch 87, loss 20.183090209960938, acc=0.013888888992369175, loss=20.183090209960938
train: epoch 88, loss 1.3770910501480103, acc=0.46522220969200134, loss=1.3770910501480103
test: epoch 88, loss 19.69052505493164, acc=0.013888888992369175, loss=19.69052505493164
train: epoch 89, loss 1.3773070573806763, acc=0.4638333320617676, loss=1.3773070573806763
test: epoch 89, loss 19.566560745239258, acc=0.013888888992369175, loss=19.566560745239258
train: epoch 90, loss 1.3550699949264526, acc=0.46827778220176697, loss=1.3550699949264526
test: epoch 90, loss 20.2701358795166, acc=0.01666666753590107, loss=20.2701358795166
train: epoch 91, loss 1.3579113483428955, acc=0.48205554485321045, loss=1.3579113483428955
test: epoch 91, loss 20.076705932617188, acc=0.01666666753590107, loss=20.076705932617188
train: epoch 92, loss 1.3549578189849854, acc=0.4745555520057678, loss=1.3549578189849854
test: epoch 92, loss 20.29280662536621, acc=0.013888888992369175, loss=20.29280662536621
train: epoch 93, loss 1.3382086753845215, acc=0.47555556893348694, loss=1.3382086753845215
test: epoch 93, loss 20.6164608001709, acc=0.013888888992369175, loss=20.6164608001709
train: epoch 94, loss 1.3427011966705322, acc=0.47822222113609314, loss=1.3427011966705322
test: epoch 94, loss 20.17397689819336, acc=0.013888888992369175, loss=20.17397689819336
train: epoch 95, loss 1.3372387886047363, acc=0.4750555455684662, loss=1.3372387886047363
test: epoch 95, loss 19.79503631591797, acc=0.013888888992369175, loss=19.79503631591797
train: epoch 96, loss 1.3325376510620117, acc=0.4776666760444641, loss=1.3325376510620117
test: epoch 96, loss 19.7608585357666, acc=0.013888888992369175, loss=19.7608585357666
train: epoch 97, loss 1.3385202884674072, acc=0.4827222228050232, loss=1.3385202884674072
test: epoch 97, loss 19.501689910888672, acc=0.013888888992369175, loss=19.501689910888672
train: epoch 98, loss 1.3351852893829346, acc=0.4757777750492096, loss=1.3351852893829346
test: epoch 98, loss 19.41196060180664, acc=0.01666666753590107, loss=19.41196060180664
train: epoch 99, loss 1.3242769241333008, acc=0.48399999737739563, loss=1.3242769241333008
test: epoch 99, loss 19.640108108520508, acc=0.013888888992369175, loss=19.640108108520508
train: epoch 100, loss 1.3275920152664185, acc=0.48794445395469666, loss=1.3275920152664185
test: epoch 100, loss 19.3450870513916, acc=0.013888888992369175, loss=19.3450870513916
train: epoch 101, loss 1.3211342096328735, acc=0.4850555658340454, loss=1.3211342096328735
test: epoch 101, loss 19.29470443725586, acc=0.013888888992369175, loss=19.29470443725586
train: epoch 102, loss 1.3198890686035156, acc=0.4868333339691162, loss=1.3198890686035156
test: epoch 102, loss 20.024934768676758, acc=0.013888888992369175, loss=20.024934768676758
train: epoch 103, loss 1.3130342960357666, acc=0.4873333275318146, loss=1.3130342960357666
test: epoch 103, loss 20.914073944091797, acc=0.013888888992369175, loss=20.914073944091797
train: epoch 104, loss 1.3051886558532715, acc=0.48677778244018555, loss=1.3051886558532715
test: epoch 104, loss 19.06821060180664, acc=0.013888888992369175, loss=19.06821060180664
train: epoch 105, loss 1.309657096862793, acc=0.49183332920074463, loss=1.309657096862793
test: epoch 105, loss 19.945913314819336, acc=0.013888888992369175, loss=19.945913314819336
train: epoch 106, loss 1.3148648738861084, acc=0.49283334612846375, loss=1.3148648738861084
test: epoch 106, loss 19.522579193115234, acc=0.013888888992369175, loss=19.522579193115234
train: epoch 107, loss 1.305404782295227, acc=0.4959999918937683, loss=1.305404782295227
test: epoch 107, loss 19.358964920043945, acc=0.02777777798473835, loss=19.358964920043945
train: epoch 108, loss 1.2995755672454834, acc=0.49666666984558105, loss=1.2995755672454834
test: epoch 108, loss 19.23830795288086, acc=0.013888888992369175, loss=19.23830795288086
train: epoch 109, loss 1.3004388809204102, acc=0.4893333315849304, loss=1.3004388809204102
test: epoch 109, loss 19.744314193725586, acc=0.013888888992369175, loss=19.744314193725586
train: epoch 110, loss 1.28911554813385, acc=0.5035555362701416, loss=1.28911554813385
test: epoch 110, loss 19.797765731811523, acc=0.01944444514811039, loss=19.797765731811523
train: epoch 111, loss 1.2988877296447754, acc=0.5036666393280029, loss=1.2988877296447754
test: epoch 111, loss 19.489673614501953, acc=0.01944444514811039, loss=19.489673614501953
train: epoch 112, loss 1.2910429239273071, acc=0.4970555603504181, loss=1.2910429239273071
test: epoch 112, loss 18.78058433532715, acc=0.013888888992369175, loss=18.78058433532715
train: epoch 113, loss 1.3021856546401978, acc=0.49694445729255676, loss=1.3021856546401978
test: epoch 113, loss 19.42656135559082, acc=0.013888888992369175, loss=19.42656135559082
train: epoch 114, loss 1.2843518257141113, acc=0.5, loss=1.2843518257141113
test: epoch 114, loss 19.487720489501953, acc=0.013888888992369175, loss=19.487720489501953
train: epoch 115, loss 1.2750625610351562, acc=0.5029444694519043, loss=1.2750625610351562
test: epoch 115, loss 20.179609298706055, acc=0.013888888992369175, loss=20.179609298706055
train: epoch 116, loss 1.2712968587875366, acc=0.5093888640403748, loss=1.2712968587875366
test: epoch 116, loss 20.32448959350586, acc=0.01666666753590107, loss=20.32448959350586
train: epoch 117, loss 1.2808409929275513, acc=0.5046111345291138, loss=1.2808409929275513
test: epoch 117, loss 19.892488479614258, acc=0.01666666753590107, loss=19.892488479614258
train: epoch 118, loss 1.2763389348983765, acc=0.504277765750885, loss=1.2763389348983765
test: epoch 118, loss 20.208295822143555, acc=0.01666666753590107, loss=20.208295822143555
train: epoch 119, loss 1.273938536643982, acc=0.5068888664245605, loss=1.273938536643982
test: epoch 119, loss 19.71087646484375, acc=0.01666666753590107, loss=19.71087646484375
train: epoch 120, loss 1.2704546451568604, acc=0.5106111168861389, loss=1.2704546451568604
test: epoch 120, loss 20.090438842773438, acc=0.01666666753590107, loss=20.090438842773438
train: epoch 121, loss 1.2618882656097412, acc=0.5113333463668823, loss=1.2618882656097412
test: epoch 121, loss 20.643577575683594, acc=0.01666666753590107, loss=20.643577575683594
train: epoch 122, loss 1.2683886289596558, acc=0.5088889002799988, loss=1.2683886289596558
test: epoch 122, loss 20.578962326049805, acc=0.013888888992369175, loss=20.578962326049805
train: epoch 123, loss 1.25551438331604, acc=0.5112777948379517, loss=1.25551438331604
test: epoch 123, loss 19.865053176879883, acc=0.013888888992369175, loss=19.865053176879883
train: epoch 124, loss 1.2670865058898926, acc=0.5094444155693054, loss=1.2670865058898926
test: epoch 124, loss 19.03886604309082, acc=0.01666666753590107, loss=19.03886604309082
train: epoch 125, loss 1.2502832412719727, acc=0.5231666564941406, loss=1.2502832412719727
test: epoch 125, loss 20.13252067565918, acc=0.01666666753590107, loss=20.13252067565918
train: epoch 126, loss 1.2453724145889282, acc=0.5184444189071655, loss=1.2453724145889282
test: epoch 126, loss 20.23112678527832, acc=0.01666666753590107, loss=20.23112678527832
train: epoch 127, loss 1.2526935338974, acc=0.5202222466468811, loss=1.2526935338974
test: epoch 127, loss 19.479570388793945, acc=0.01666666753590107, loss=19.479570388793945
train: epoch 128, loss 1.2446123361587524, acc=0.5220555663108826, loss=1.2446123361587524
test: epoch 128, loss 20.535001754760742, acc=0.01666666753590107, loss=20.535001754760742
train: epoch 129, loss 1.2456015348434448, acc=0.5171111226081848, loss=1.2456015348434448
test: epoch 129, loss 20.40775489807129, acc=0.01666666753590107, loss=20.40775489807129
train: epoch 130, loss 1.2444813251495361, acc=0.5172222256660461, loss=1.2444813251495361
test: epoch 130, loss 20.54795265197754, acc=0.01666666753590107, loss=20.54795265197754
train: epoch 131, loss 1.2397866249084473, acc=0.5202777981758118, loss=1.2397866249084473
test: epoch 131, loss 20.987966537475586, acc=0.01666666753590107, loss=20.987966537475586
train: epoch 132, loss 1.2468771934509277, acc=0.5210000276565552, loss=1.2468771934509277
test: epoch 132, loss 21.49668312072754, acc=0.01666666753590107, loss=21.49668312072754
train: epoch 133, loss 1.2402418851852417, acc=0.5195555686950684, loss=1.2402418851852417
test: epoch 133, loss 20.92261505126953, acc=0.01666666753590107, loss=20.92261505126953
train: epoch 134, loss 1.2325630187988281, acc=0.5176110863685608, loss=1.2325630187988281
test: epoch 134, loss 21.005680084228516, acc=0.01666666753590107, loss=21.005680084228516
train: epoch 135, loss 1.226986289024353, acc=0.5257222056388855, loss=1.226986289024353
test: epoch 135, loss 20.749032974243164, acc=0.01666666753590107, loss=20.749032974243164
train: epoch 136, loss 1.235175371170044, acc=0.5287777781486511, loss=1.235175371170044
test: epoch 136, loss 22.02768325805664, acc=0.01666666753590107, loss=22.02768325805664
train: epoch 137, loss 1.2302868366241455, acc=0.5236111283302307, loss=1.2302868366241455
test: epoch 137, loss 21.06646156311035, acc=0.01666666753590107, loss=21.06646156311035
train: epoch 138, loss 1.2165178060531616, acc=0.5296666622161865, loss=1.2165178060531616
test: epoch 138, loss 21.091205596923828, acc=0.01666666753590107, loss=21.091205596923828
train: epoch 139, loss 1.2206298112869263, acc=0.5253333449363708, loss=1.2206298112869263
test: epoch 139, loss 21.43926429748535, acc=0.01666666753590107, loss=21.43926429748535
train: epoch 140, loss 1.2106459140777588, acc=0.5364999771118164, loss=1.2106459140777588
test: epoch 140, loss 21.30210304260254, acc=0.01666666753590107, loss=21.30210304260254
train: epoch 141, loss 1.2207367420196533, acc=0.5297777652740479, loss=1.2207367420196533
test: epoch 141, loss 20.837060928344727, acc=0.01666666753590107, loss=20.837060928344727
train: epoch 142, loss 1.2165943384170532, acc=0.5357778072357178, loss=1.2165943384170532
test: epoch 142, loss 21.14027214050293, acc=0.01666666753590107, loss=21.14027214050293
train: epoch 143, loss 1.204774260520935, acc=0.5400555729866028, loss=1.204774260520935
test: epoch 143, loss 20.404720306396484, acc=0.01666666753590107, loss=20.404720306396484
train: epoch 144, loss 1.2059096097946167, acc=0.5282222032546997, loss=1.2059096097946167
test: epoch 144, loss 21.238414764404297, acc=0.01666666753590107, loss=21.238414764404297
train: epoch 145, loss 1.2064989805221558, acc=0.5350555777549744, loss=1.2064989805221558
test: epoch 145, loss 20.961069107055664, acc=0.01666666753590107, loss=20.961069107055664
train: epoch 146, loss 1.2069549560546875, acc=0.5383333563804626, loss=1.2069549560546875
test: epoch 146, loss 21.956518173217773, acc=0.01666666753590107, loss=21.956518173217773
train: epoch 147, loss 1.18709397315979, acc=0.5389999747276306, loss=1.18709397315979
test: epoch 147, loss 21.699602127075195, acc=0.01666666753590107, loss=21.699602127075195
train: epoch 148, loss 1.1989022493362427, acc=0.5419999957084656, loss=1.1989022493362427
test: epoch 148, loss 20.70224380493164, acc=0.01666666753590107, loss=20.70224380493164
train: epoch 149, loss 1.1826404333114624, acc=0.5412777662277222, loss=1.1826404333114624
test: epoch 149, loss 20.877168655395508, acc=0.01666666753590107, loss=20.877168655395508
train: epoch 150, loss 1.186859369277954, acc=0.5400000214576721, loss=1.186859369277954
test: epoch 150, loss 21.337984085083008, acc=0.01666666753590107, loss=21.337984085083008
