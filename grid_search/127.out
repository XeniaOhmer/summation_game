# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=1.5", "--temp_decay=1", "--one_hot=0", "--n_layers=2"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=94566743, receiver_embed_dim=128, save_run=0, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=2, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=94566743, receiver_embed_dim=128, save_run=False, temp_decay=1.0, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 2.54685640335083, acc=0.13383333384990692, loss=2.54685640335083
test: epoch 1, loss 4.062458038330078, acc=0.0694444477558136, loss=4.062458038330078
train: epoch 2, loss 2.021636486053467, acc=0.2296111136674881, loss=2.021636486053467
test: epoch 2, loss 3.4696714878082275, acc=0.12222222238779068, loss=3.4696714878082275
train: epoch 3, loss 1.787583827972412, acc=0.28955554962158203, loss=1.787583827972412
test: epoch 3, loss 3.4873850345611572, acc=0.10833333432674408, loss=3.4873850345611572
train: epoch 4, loss 1.6521507501602173, acc=0.3327222168445587, loss=1.6521507501602173
test: epoch 4, loss 3.3673810958862305, acc=0.1111111119389534, loss=3.3673810958862305
train: epoch 5, loss 1.5606359243392944, acc=0.3643888831138611, loss=1.5606359243392944
test: epoch 5, loss 2.7801408767700195, acc=0.13333334028720856, loss=2.7801408767700195
train: epoch 6, loss 1.4707037210464478, acc=0.40450000762939453, loss=1.4707037210464478
test: epoch 6, loss 2.9310431480407715, acc=0.14444445073604584, loss=2.9310431480407715
train: epoch 7, loss 1.3997447490692139, acc=0.42544445395469666, loss=1.3997447490692139
test: epoch 7, loss 3.151392936706543, acc=0.11388888955116272, loss=3.151392936706543
train: epoch 8, loss 1.356391429901123, acc=0.45177778601646423, loss=1.356391429901123
test: epoch 8, loss 2.710824489593506, acc=0.14444445073604584, loss=2.710824489593506
train: epoch 9, loss 1.2943434715270996, acc=0.4698888957500458, loss=1.2943434715270996
test: epoch 9, loss 2.9210751056671143, acc=0.1527777761220932, loss=2.9210751056671143
train: epoch 10, loss 1.2518666982650757, acc=0.4888888895511627, loss=1.2518666982650757
test: epoch 10, loss 3.0338122844696045, acc=0.1666666716337204, loss=3.0338122844696045
train: epoch 11, loss 1.199519395828247, acc=0.5145555734634399, loss=1.199519395828247
test: epoch 11, loss 2.8301374912261963, acc=0.13333334028720856, loss=2.8301374912261963
train: epoch 12, loss 1.1735516786575317, acc=0.5239444375038147, loss=1.1735516786575317
test: epoch 12, loss 2.7175498008728027, acc=0.14722222089767456, loss=2.7175498008728027
train: epoch 13, loss 1.150098443031311, acc=0.5358333587646484, loss=1.150098443031311
test: epoch 13, loss 2.8007588386535645, acc=0.15555556118488312, loss=2.8007588386535645
train: epoch 14, loss 1.121748685836792, acc=0.5482777953147888, loss=1.121748685836792
test: epoch 14, loss 3.4601359367370605, acc=0.1388888955116272, loss=3.4601359367370605
train: epoch 15, loss 1.0531617403030396, acc=0.5780555605888367, loss=1.0531617403030396
test: epoch 15, loss 3.8739259243011475, acc=0.12777778506278992, loss=3.8739259243011475
train: epoch 16, loss 1.0612682104110718, acc=0.5751110911369324, loss=1.0612682104110718
test: epoch 16, loss 2.7536144256591797, acc=0.14722222089767456, loss=2.7536144256591797
train: epoch 17, loss 1.0321370363235474, acc=0.5847222208976746, loss=1.0321370363235474
test: epoch 17, loss 3.0829861164093018, acc=0.16388888657093048, loss=3.0829861164093018
train: epoch 18, loss 0.9919594526290894, acc=0.6041111350059509, loss=0.9919594526290894
test: epoch 18, loss 3.3393325805664062, acc=0.11388888955116272, loss=3.3393325805664062
train: epoch 19, loss 0.9732007384300232, acc=0.609499990940094, loss=0.9732007384300232
test: epoch 19, loss 3.222399950027466, acc=0.1388888955116272, loss=3.222399950027466
train: epoch 20, loss 0.9551095962524414, acc=0.6195555329322815, loss=0.9551095962524414
test: epoch 20, loss 3.171649694442749, acc=0.13055555522441864, loss=3.171649694442749
train: epoch 21, loss 0.9290124177932739, acc=0.6297222375869751, loss=0.9290124177932739
test: epoch 21, loss 3.6678755283355713, acc=0.1388888955116272, loss=3.6678755283355713
train: epoch 22, loss 0.926005482673645, acc=0.6339444518089294, loss=0.926005482673645
test: epoch 22, loss 2.5791969299316406, acc=0.18333333730697632, loss=2.5791969299316406
train: epoch 23, loss 0.9096222519874573, acc=0.6426666378974915, loss=0.9096222519874573
test: epoch 23, loss 2.7247867584228516, acc=0.17222222685813904, loss=2.7247867584228516
train: epoch 24, loss 0.8725109696388245, acc=0.659166693687439, loss=0.8725109696388245
test: epoch 24, loss 3.0898916721343994, acc=0.1388888955116272, loss=3.0898916721343994
train: epoch 25, loss 0.8724048137664795, acc=0.6521666646003723, loss=0.8724048137664795
test: epoch 25, loss 2.61623477935791, acc=0.1944444477558136, loss=2.61623477935791
train: epoch 26, loss 0.8615567684173584, acc=0.6588888764381409, loss=0.8615567684173584
test: epoch 26, loss 3.3857262134552, acc=0.17499999701976776, loss=3.3857262134552
train: epoch 27, loss 0.8311327695846558, acc=0.6744999885559082, loss=0.8311327695846558
test: epoch 27, loss 2.9566731452941895, acc=0.125, loss=2.9566731452941895
train: epoch 28, loss 0.7945347428321838, acc=0.6875555515289307, loss=0.7945347428321838
test: epoch 28, loss 3.16042423248291, acc=0.13055555522441864, loss=3.16042423248291
train: epoch 29, loss 0.7876903414726257, acc=0.6856666803359985, loss=0.7876903414726257
test: epoch 29, loss 3.433300495147705, acc=0.19722221791744232, loss=3.433300495147705
train: epoch 30, loss 0.7846798300743103, acc=0.6884999871253967, loss=0.7846798300743103
test: epoch 30, loss 3.0816245079040527, acc=0.17777778208255768, loss=3.0816245079040527
train: epoch 31, loss 0.7694135904312134, acc=0.6965000033378601, loss=0.7694135904312134
test: epoch 31, loss 2.570709228515625, acc=0.18888889253139496, loss=2.570709228515625
train: epoch 32, loss 0.7622263431549072, acc=0.698722243309021, loss=0.7622263431549072
test: epoch 32, loss 3.6623246669769287, acc=0.17222222685813904, loss=3.6623246669769287
train: epoch 33, loss 0.7699283361434937, acc=0.7016111016273499, loss=0.7699283361434937
test: epoch 33, loss 2.6858694553375244, acc=0.21111111342906952, loss=2.6858694553375244
train: epoch 34, loss 0.7465822100639343, acc=0.7086666822433472, loss=0.7465822100639343
test: epoch 34, loss 2.5112721920013428, acc=0.1944444477558136, loss=2.5112721920013428
train: epoch 35, loss 0.7317501306533813, acc=0.7152222394943237, loss=0.7317501306533813
test: epoch 35, loss 2.811586380004883, acc=0.2222222238779068, loss=2.811586380004883
train: epoch 36, loss 0.7281606793403625, acc=0.7159444689750671, loss=0.7281606793403625
test: epoch 36, loss 2.976754903793335, acc=0.2222222238779068, loss=2.976754903793335
train: epoch 37, loss 0.7337532639503479, acc=0.7161111235618591, loss=0.7337532639503479
test: epoch 37, loss 3.1638054847717285, acc=0.15555556118488312, loss=3.1638054847717285
train: epoch 38, loss 0.7165249586105347, acc=0.7192222476005554, loss=0.7165249586105347
test: epoch 38, loss 3.346619129180908, acc=0.09444444626569748, loss=3.346619129180908
train: epoch 39, loss 0.6945815682411194, acc=0.7329444289207458, loss=0.6945815682411194
test: epoch 39, loss 2.9996321201324463, acc=0.21111111342906952, loss=2.9996321201324463
train: epoch 40, loss 0.6860712766647339, acc=0.7361666560173035, loss=0.6860712766647339
test: epoch 40, loss 3.2252261638641357, acc=0.1388888955116272, loss=3.2252261638641357
train: epoch 41, loss 0.6813843250274658, acc=0.7342222332954407, loss=0.6813843250274658
test: epoch 41, loss 2.8784024715423584, acc=0.12777778506278992, loss=2.8784024715423584
train: epoch 42, loss 0.6898490190505981, acc=0.7361666560173035, loss=0.6898490190505981
test: epoch 42, loss 3.9487216472625732, acc=0.09444444626569748, loss=3.9487216472625732
train: epoch 43, loss 0.6574280261993408, acc=0.7456666827201843, loss=0.6574280261993408
test: epoch 43, loss 2.6713263988494873, acc=0.28611111640930176, loss=2.6713263988494873
train: epoch 44, loss 0.6455453634262085, acc=0.750166654586792, loss=0.6455453634262085
test: epoch 44, loss 3.0063233375549316, acc=0.20277777314186096, loss=3.0063233375549316
train: epoch 45, loss 0.6608840227127075, acc=0.7461110949516296, loss=0.6608840227127075
test: epoch 45, loss 2.99310040473938, acc=0.20555555820465088, loss=2.99310040473938
train: epoch 46, loss 0.6556429266929626, acc=0.7489444613456726, loss=0.6556429266929626
test: epoch 46, loss 3.3546841144561768, acc=0.21388888359069824, loss=3.3546841144561768
train: epoch 47, loss 0.6325724720954895, acc=0.7511110901832581, loss=0.6325724720954895
test: epoch 47, loss 3.0143795013427734, acc=0.2083333283662796, loss=3.0143795013427734
train: epoch 48, loss 0.6422547101974487, acc=0.7547222375869751, loss=0.6422547101974487
test: epoch 48, loss 3.0363614559173584, acc=0.12222222238779068, loss=3.0363614559173584
train: epoch 49, loss 0.633114218711853, acc=0.7586666941642761, loss=0.633114218711853
test: epoch 49, loss 2.9678454399108887, acc=0.18333333730697632, loss=2.9678454399108887
train: epoch 50, loss 0.6183043718338013, acc=0.7599999904632568, loss=0.6183043718338013
test: epoch 50, loss 2.319140672683716, acc=0.2083333283662796, loss=2.319140672683716
train: epoch 51, loss 0.6240243911743164, acc=0.7628333568572998, loss=0.6240243911743164
test: epoch 51, loss 2.656165838241577, acc=0.2944444417953491, loss=2.656165838241577
train: epoch 52, loss 0.6078566312789917, acc=0.7649999856948853, loss=0.6078566312789917
test: epoch 52, loss 2.150017738342285, acc=0.2944444417953491, loss=2.150017738342285
train: epoch 53, loss 0.5872592926025391, acc=0.7714999914169312, loss=0.5872592926025391
test: epoch 53, loss 2.7793216705322266, acc=0.26944443583488464, loss=2.7793216705322266
train: epoch 54, loss 0.6046953201293945, acc=0.7634999752044678, loss=0.6046953201293945
test: epoch 54, loss 4.80340051651001, acc=0.20000000298023224, loss=4.80340051651001
train: epoch 55, loss 0.5885653495788574, acc=0.7728333473205566, loss=0.5885653495788574
test: epoch 55, loss 2.3026371002197266, acc=0.28333333134651184, loss=2.3026371002197266
train: epoch 56, loss 0.5891187787055969, acc=0.7706111073493958, loss=0.5891187787055969
test: epoch 56, loss 2.645602226257324, acc=0.14166666567325592, loss=2.645602226257324
train: epoch 57, loss 0.5923163294792175, acc=0.7733333110809326, loss=0.5923163294792175
test: epoch 57, loss 2.207521438598633, acc=0.32499998807907104, loss=2.207521438598633
train: epoch 58, loss 0.5829532742500305, acc=0.7741110920906067, loss=0.5829532742500305
test: epoch 58, loss 3.3853085041046143, acc=0.125, loss=3.3853085041046143
train: epoch 59, loss 0.5654283165931702, acc=0.7818889021873474, loss=0.5654283165931702
test: epoch 59, loss 2.361345052719116, acc=0.23888888955116272, loss=2.361345052719116
train: epoch 60, loss 0.5661675930023193, acc=0.7804999947547913, loss=0.5661675930023193
test: epoch 60, loss 2.907836675643921, acc=0.12777778506278992, loss=2.907836675643921
train: epoch 61, loss 0.5738649964332581, acc=0.782444417476654, loss=0.5738649964332581
test: epoch 61, loss 2.8304989337921143, acc=0.21111111342906952, loss=2.8304989337921143
train: epoch 62, loss 0.5574872493743896, acc=0.7838888764381409, loss=0.5574872493743896
test: epoch 62, loss 2.9923720359802246, acc=0.2222222238779068, loss=2.9923720359802246
train: epoch 63, loss 0.5533652901649475, acc=0.7887222170829773, loss=0.5533652901649475
test: epoch 63, loss 3.4311282634735107, acc=0.18611110746860504, loss=3.4311282634735107
train: epoch 64, loss 0.5617278218269348, acc=0.7838888764381409, loss=0.5617278218269348
test: epoch 64, loss 3.1767077445983887, acc=0.17499999701976776, loss=3.1767077445983887
train: epoch 65, loss 0.5498770475387573, acc=0.7901111245155334, loss=0.5498770475387573
test: epoch 65, loss 2.6721084117889404, acc=0.30000001192092896, loss=2.6721084117889404
train: epoch 66, loss 0.5362866520881653, acc=0.7922777533531189, loss=0.5362866520881653
test: epoch 66, loss 2.64079213142395, acc=0.24722221493721008, loss=2.64079213142395
train: epoch 67, loss 0.5256596207618713, acc=0.7982222437858582, loss=0.5256596207618713
test: epoch 67, loss 3.1384122371673584, acc=0.18333333730697632, loss=3.1384122371673584
train: epoch 68, loss 0.5251770615577698, acc=0.8021666407585144, loss=0.5251770615577698
test: epoch 68, loss 3.182432174682617, acc=0.25555557012557983, loss=3.182432174682617
train: epoch 69, loss 0.5463195443153381, acc=0.7901111245155334, loss=0.5463195443153381
test: epoch 69, loss 2.4509077072143555, acc=0.2611111104488373, loss=2.4509077072143555
train: epoch 70, loss 0.5307022929191589, acc=0.7921666502952576, loss=0.5307022929191589
test: epoch 70, loss 2.643402576446533, acc=0.24444444477558136, loss=2.643402576446533
train: epoch 71, loss 0.5343073606491089, acc=0.7964444160461426, loss=0.5343073606491089
test: epoch 71, loss 2.785067081451416, acc=0.3305555582046509, loss=2.785067081451416
train: epoch 72, loss 0.5042493939399719, acc=0.8041666746139526, loss=0.5042493939399719
test: epoch 72, loss 3.0684473514556885, acc=0.20555555820465088, loss=3.0684473514556885
train: epoch 73, loss 0.5060974955558777, acc=0.8038333058357239, loss=0.5060974955558777
test: epoch 73, loss 2.510350227355957, acc=0.27222222089767456, loss=2.510350227355957
train: epoch 74, loss 0.5299380421638489, acc=0.8012222051620483, loss=0.5299380421638489
test: epoch 74, loss 2.2585551738739014, acc=0.2611111104488373, loss=2.2585551738739014
train: epoch 75, loss 0.5029624104499817, acc=0.8041666746139526, loss=0.5029624104499817
test: epoch 75, loss 2.384633779525757, acc=0.3472222089767456, loss=2.384633779525757
train: epoch 76, loss 0.5044397115707397, acc=0.8061110973358154, loss=0.5044397115707397
test: epoch 76, loss 4.1911540031433105, acc=0.3027777671813965, loss=4.1911540031433105
train: epoch 77, loss 0.49787190556526184, acc=0.8105555772781372, loss=0.49787190556526184
test: epoch 77, loss 3.1748814582824707, acc=0.14166666567325592, loss=3.1748814582824707
train: epoch 78, loss 0.49092137813568115, acc=0.8098888993263245, loss=0.49092137813568115
test: epoch 78, loss 2.602078676223755, acc=0.2666666805744171, loss=2.602078676223755
train: epoch 79, loss 0.5005335807800293, acc=0.8122777938842773, loss=0.5005335807800293
test: epoch 79, loss 2.6979777812957764, acc=0.2805555462837219, loss=2.6979777812957764
train: epoch 80, loss 0.4779587984085083, acc=0.8157222270965576, loss=0.4779587984085083
test: epoch 80, loss 2.53690505027771, acc=0.2777777910232544, loss=2.53690505027771
train: epoch 81, loss 0.48741841316223145, acc=0.8109444379806519, loss=0.48741841316223145
test: epoch 81, loss 3.4566867351531982, acc=0.18888889253139496, loss=3.4566867351531982
train: epoch 82, loss 0.4797932505607605, acc=0.8116111159324646, loss=0.4797932505607605
test: epoch 82, loss 2.093623638153076, acc=0.2527777850627899, loss=2.093623638153076
train: epoch 83, loss 0.4708096981048584, acc=0.8172222375869751, loss=0.4708096981048584
test: epoch 83, loss 3.8665771484375, acc=0.23333333432674408, loss=3.8665771484375
train: epoch 84, loss 0.470694899559021, acc=0.8221111297607422, loss=0.470694899559021
test: epoch 84, loss 1.8371013402938843, acc=0.3027777671813965, loss=1.8371013402938843
train: epoch 85, loss 0.45535746216773987, acc=0.827833354473114, loss=0.45535746216773987
test: epoch 85, loss 2.651571750640869, acc=0.3222222328186035, loss=2.651571750640869
train: epoch 86, loss 0.47038137912750244, acc=0.8204444646835327, loss=0.47038137912750244
test: epoch 86, loss 2.5744926929473877, acc=0.27222222089767456, loss=2.5744926929473877
train: epoch 87, loss 0.4555305242538452, acc=0.8263888955116272, loss=0.4555305242538452
test: epoch 87, loss 2.651521921157837, acc=0.32499998807907104, loss=2.651521921157837
train: epoch 88, loss 0.4842795431613922, acc=0.8141666650772095, loss=0.4842795431613922
test: epoch 88, loss 2.151968002319336, acc=0.24166665971279144, loss=2.151968002319336
train: epoch 89, loss 0.45479723811149597, acc=0.823722243309021, loss=0.45479723811149597
test: epoch 89, loss 2.6648483276367188, acc=0.3027777671813965, loss=2.6648483276367188
train: epoch 90, loss 0.44147542119026184, acc=0.8312777876853943, loss=0.44147542119026184
test: epoch 90, loss 2.232044219970703, acc=0.3888888955116272, loss=2.232044219970703
train: epoch 91, loss 0.44346848130226135, acc=0.831944465637207, loss=0.44346848130226135
test: epoch 91, loss 2.5009803771972656, acc=0.36944442987442017, loss=2.5009803771972656
train: epoch 92, loss 0.4482022225856781, acc=0.8278889060020447, loss=0.4482022225856781
test: epoch 92, loss 2.6941943168640137, acc=0.26944443583488464, loss=2.6941943168640137
train: epoch 93, loss 0.44059404730796814, acc=0.8305555582046509, loss=0.44059404730796814
test: epoch 93, loss 2.5279366970062256, acc=0.24722221493721008, loss=2.5279366970062256
train: epoch 94, loss 0.4241851270198822, acc=0.8373333215713501, loss=0.4241851270198822
test: epoch 94, loss 2.851365804672241, acc=0.2666666805744171, loss=2.851365804672241
train: epoch 95, loss 0.4184378385543823, acc=0.8368333578109741, loss=0.4184378385543823
test: epoch 95, loss 2.4214730262756348, acc=0.2944444417953491, loss=2.4214730262756348
train: epoch 96, loss 0.4195592999458313, acc=0.8374999761581421, loss=0.4195592999458313
test: epoch 96, loss 2.346172571182251, acc=0.3222222328186035, loss=2.346172571182251
train: epoch 97, loss 0.4187096059322357, acc=0.8359444737434387, loss=0.4187096059322357
test: epoch 97, loss 2.6737728118896484, acc=0.25, loss=2.6737728118896484
train: epoch 98, loss 0.4343976378440857, acc=0.8305000066757202, loss=0.4343976378440857
test: epoch 98, loss 2.4628236293792725, acc=0.31388887763023376, loss=2.4628236293792725
train: epoch 99, loss 0.4164458215236664, acc=0.840666651725769, loss=0.4164458215236664
test: epoch 99, loss 2.4024646282196045, acc=0.3444444537162781, loss=2.4024646282196045
train: epoch 100, loss 0.40600958466529846, acc=0.8423888683319092, loss=0.40600958466529846
test: epoch 100, loss 2.7529215812683105, acc=0.3027777671813965, loss=2.7529215812683105
train: epoch 101, loss 0.4199662208557129, acc=0.8414444327354431, loss=0.4199662208557129
test: epoch 101, loss 2.1860485076904297, acc=0.3305555582046509, loss=2.1860485076904297
train: epoch 102, loss 0.41758689284324646, acc=0.8437777757644653, loss=0.41758689284324646
test: epoch 102, loss 2.7136194705963135, acc=0.3166666626930237, loss=2.7136194705963135
train: epoch 103, loss 0.40700772404670715, acc=0.8467222452163696, loss=0.40700772404670715
test: epoch 103, loss 2.5393524169921875, acc=0.35277777910232544, loss=2.5393524169921875
train: epoch 104, loss 0.40370291471481323, acc=0.8445000052452087, loss=0.40370291471481323
test: epoch 104, loss 2.5244009494781494, acc=0.3083333373069763, loss=2.5244009494781494
train: epoch 105, loss 0.39124366641044617, acc=0.8501666784286499, loss=0.39124366641044617
test: epoch 105, loss 4.276977062225342, acc=0.2666666805744171, loss=4.276977062225342
train: epoch 106, loss 0.3979555368423462, acc=0.8474444150924683, loss=0.3979555368423462
test: epoch 106, loss 3.499746084213257, acc=0.2805555462837219, loss=3.499746084213257
train: epoch 107, loss 0.40362632274627686, acc=0.8440555334091187, loss=0.40362632274627686
test: epoch 107, loss 3.598525047302246, acc=0.24722221493721008, loss=3.598525047302246
train: epoch 108, loss 0.4017867147922516, acc=0.8450555801391602, loss=0.4017867147922516
test: epoch 108, loss 2.9015684127807617, acc=0.21944443881511688, loss=2.9015684127807617
train: epoch 109, loss 0.3873511850833893, acc=0.8536666631698608, loss=0.3873511850833893
test: epoch 109, loss 2.783250331878662, acc=0.22499999403953552, loss=2.783250331878662
train: epoch 110, loss 0.4045140743255615, acc=0.843833327293396, loss=0.4045140743255615
test: epoch 110, loss 2.2828421592712402, acc=0.25, loss=2.2828421592712402
train: epoch 111, loss 0.39615339040756226, acc=0.8486666679382324, loss=0.39615339040756226
test: epoch 111, loss 2.9487128257751465, acc=0.2638888955116272, loss=2.9487128257751465
train: epoch 112, loss 0.38600054383277893, acc=0.8533333539962769, loss=0.38600054383277893
test: epoch 112, loss 2.899888277053833, acc=0.23055554926395416, loss=2.899888277053833
train: epoch 113, loss 0.3930923640727997, acc=0.8500555753707886, loss=0.3930923640727997
test: epoch 113, loss 2.4273440837860107, acc=0.3027777671813965, loss=2.4273440837860107
train: epoch 114, loss 0.39438164234161377, acc=0.8492777943611145, loss=0.39438164234161377
test: epoch 114, loss 2.281609535217285, acc=0.36666667461395264, loss=2.281609535217285
train: epoch 115, loss 0.38200700283050537, acc=0.8551111221313477, loss=0.38200700283050537
test: epoch 115, loss 3.0909810066223145, acc=0.25, loss=3.0909810066223145
train: epoch 116, loss 0.39440953731536865, acc=0.8491111397743225, loss=0.39440953731536865
test: epoch 116, loss 2.0439646244049072, acc=0.3583333194255829, loss=2.0439646244049072
train: epoch 117, loss 0.3781205117702484, acc=0.8521666526794434, loss=0.3781205117702484
test: epoch 117, loss 2.8380753993988037, acc=0.30000001192092896, loss=2.8380753993988037
train: epoch 118, loss 0.37796300649642944, acc=0.8560000061988831, loss=0.37796300649642944
test: epoch 118, loss 2.7667124271392822, acc=0.39722222089767456, loss=2.7667124271392822
train: epoch 119, loss 0.38495609164237976, acc=0.8533333539962769, loss=0.38495609164237976
test: epoch 119, loss 3.1141669750213623, acc=0.2750000059604645, loss=3.1141669750213623
train: epoch 120, loss 0.3795364499092102, acc=0.8518333435058594, loss=0.3795364499092102
test: epoch 120, loss 3.5170035362243652, acc=0.2611111104488373, loss=3.5170035362243652
train: epoch 121, loss 0.3824063837528229, acc=0.8562777638435364, loss=0.3824063837528229
test: epoch 121, loss 2.2848422527313232, acc=0.33888888359069824, loss=2.2848422527313232
train: epoch 122, loss 0.3699799180030823, acc=0.8592222332954407, loss=0.3699799180030823
test: epoch 122, loss 2.821648120880127, acc=0.3027777671813965, loss=2.821648120880127
train: epoch 123, loss 0.3693789541721344, acc=0.8585555553436279, loss=0.3693789541721344
test: epoch 123, loss 2.9821407794952393, acc=0.29722222685813904, loss=2.9821407794952393
train: epoch 124, loss 0.3771074712276459, acc=0.855222225189209, loss=0.3771074712276459
test: epoch 124, loss 2.166565418243408, acc=0.4027777910232544, loss=2.166565418243408
train: epoch 125, loss 0.3571910262107849, acc=0.8653333187103271, loss=0.3571910262107849
test: epoch 125, loss 2.594177484512329, acc=0.3472222089767456, loss=2.594177484512329
train: epoch 126, loss 0.3644435405731201, acc=0.8627777695655823, loss=0.3644435405731201
test: epoch 126, loss 3.2454373836517334, acc=0.30000001192092896, loss=3.2454373836517334
train: epoch 127, loss 0.3644489347934723, acc=0.8608333468437195, loss=0.3644489347934723
test: epoch 127, loss 2.6459169387817383, acc=0.25555557012557983, loss=2.6459169387817383
train: epoch 128, loss 0.3740667998790741, acc=0.8592777848243713, loss=0.3740667998790741
test: epoch 128, loss 3.795480489730835, acc=0.2750000059604645, loss=3.795480489730835
train: epoch 129, loss 0.3359227180480957, acc=0.8703333139419556, loss=0.3359227180480957
test: epoch 129, loss 2.88271427154541, acc=0.22777777910232544, loss=2.88271427154541
train: epoch 130, loss 0.37435010075569153, acc=0.8587777614593506, loss=0.37435010075569153
test: epoch 130, loss 2.412727117538452, acc=0.3583333194255829, loss=2.412727117538452
train: epoch 131, loss 0.364130437374115, acc=0.8575555682182312, loss=0.364130437374115
test: epoch 131, loss 2.553088665008545, acc=0.3055555522441864, loss=2.553088665008545
train: epoch 132, loss 0.348891019821167, acc=0.8666666746139526, loss=0.348891019821167
test: epoch 132, loss 3.8907554149627686, acc=0.21111111342906952, loss=3.8907554149627686
train: epoch 133, loss 0.33363598585128784, acc=0.8694999814033508, loss=0.33363598585128784
test: epoch 133, loss 3.6929891109466553, acc=0.26944443583488464, loss=3.6929891109466553
train: epoch 134, loss 0.35701698064804077, acc=0.863111138343811, loss=0.35701698064804077
test: epoch 134, loss 2.7609903812408447, acc=0.30000001192092896, loss=2.7609903812408447
train: epoch 135, loss 0.36091920733451843, acc=0.8632222414016724, loss=0.36091920733451843
test: epoch 135, loss 3.667264938354492, acc=0.2777777910232544, loss=3.667264938354492
train: epoch 136, loss 0.34616416692733765, acc=0.8680555820465088, loss=0.34616416692733765
test: epoch 136, loss 2.3825511932373047, acc=0.35277777910232544, loss=2.3825511932373047
train: epoch 137, loss 0.36848413944244385, acc=0.8611666560173035, loss=0.36848413944244385
test: epoch 137, loss 2.468980550765991, acc=0.35555556416511536, loss=2.468980550765991
train: epoch 138, loss 0.34996673464775085, acc=0.8672778010368347, loss=0.34996673464775085
test: epoch 138, loss 3.891754150390625, acc=0.2611111104488373, loss=3.891754150390625
train: epoch 139, loss 0.34938329458236694, acc=0.8681111335754395, loss=0.34938329458236694
test: epoch 139, loss 2.830373764038086, acc=0.33888888359069824, loss=2.830373764038086
train: epoch 140, loss 0.3407929837703705, acc=0.8703888654708862, loss=0.3407929837703705
test: epoch 140, loss 2.894824266433716, acc=0.31111112236976624, loss=2.894824266433716
train: epoch 141, loss 0.3479272425174713, acc=0.8652222156524658, loss=0.3479272425174713
test: epoch 141, loss 2.2482552528381348, acc=0.42222222685813904, loss=2.2482552528381348
train: epoch 142, loss 0.34515631198883057, acc=0.8687777519226074, loss=0.34515631198883057
test: epoch 142, loss 2.4811325073242188, acc=0.3305555582046509, loss=2.4811325073242188
train: epoch 143, loss 0.3386261761188507, acc=0.8721666932106018, loss=0.3386261761188507
test: epoch 143, loss 1.8965650796890259, acc=0.3888888955116272, loss=1.8965650796890259
train: epoch 144, loss 0.3470878303050995, acc=0.8693888783454895, loss=0.3470878303050995
test: epoch 144, loss 2.681447982788086, acc=0.3472222089767456, loss=2.681447982788086
train: epoch 145, loss 0.34146252274513245, acc=0.8690555691719055, loss=0.34146252274513245
test: epoch 145, loss 3.090381383895874, acc=0.28611111640930176, loss=3.090381383895874
train: epoch 146, loss 0.331010639667511, acc=0.8742777705192566, loss=0.331010639667511
test: epoch 146, loss 2.1020145416259766, acc=0.32777777314186096, loss=2.1020145416259766
train: epoch 147, loss 0.3442215919494629, acc=0.8697777986526489, loss=0.3442215919494629
test: epoch 147, loss 3.0392043590545654, acc=0.32777777314186096, loss=3.0392043590545654
train: epoch 148, loss 0.3289475440979004, acc=0.8734999895095825, loss=0.3289475440979004
test: epoch 148, loss 1.9910537004470825, acc=0.40833333134651184, loss=1.9910537004470825
train: epoch 149, loss 0.31684985756874084, acc=0.8788333535194397, loss=0.31684985756874084
test: epoch 149, loss 2.3179080486297607, acc=0.38333332538604736, loss=2.3179080486297607
train: epoch 150, loss 0.35553425550460815, acc=0.8628888726234436, loss=0.35553425550460815
test: epoch 150, loss 4.52029275894165, acc=0.25, loss=4.52029275894165
