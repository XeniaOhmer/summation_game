# ["--N=20", "--n_epochs=150", "--batch_size=32", "--lr=0.001", "--n_symbols=200", "--receiver_embed_dim=128", "--temperature=1.5", "--temp_decay=0.995", "--one_hot=0", "--n_layers=1"]
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=0, optimizer='adam', preemptable=False, random_seed=1189502640, receiver_embed_dim=128, save_run=0, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
Namespace(N=20, batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, data_scaling=50, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, early_stopping_acc=0.99, fp16=False, load_from_checkpoint=None, lr=0.001, max_len=1, n_epochs=150, n_layers=1, n_runs=1, n_summands=2, n_symbols=200, no_cuda=False, one_hot=False, optimizer='adam', preemptable=False, random_seed=1189502640, receiver_embed_dim=128, save_run=False, temp_decay=0.995, temperature=1.5, tensorboard=False, tensorboard_dir='runs/', test_split=0.1, update_freq=1, validation_freq=1, vocab_size=10)
train: epoch 1, loss 3.034702777862549, acc=0.09177777916193008, loss=3.034702777862549
test: epoch 1, loss 4.818416595458984, acc=0.04444444552063942, loss=4.818416595458984
train: epoch 2, loss 2.6158320903778076, acc=0.1446666717529297, loss=2.6158320903778076
test: epoch 2, loss 5.839868068695068, acc=0.04722222313284874, loss=5.839868068695068
train: epoch 3, loss 2.486724853515625, acc=0.15861110389232635, loss=2.486724853515625
test: epoch 3, loss 6.307348728179932, acc=0.0416666679084301, loss=6.307348728179932
train: epoch 4, loss 2.4185402393341064, acc=0.17177778482437134, loss=2.4185402393341064
test: epoch 4, loss 6.472364902496338, acc=0.0416666679084301, loss=6.472364902496338
train: epoch 5, loss 2.372994899749756, acc=0.17888888716697693, loss=2.372994899749756
test: epoch 5, loss 6.490705966949463, acc=0.0416666679084301, loss=6.490705966949463
train: epoch 6, loss 2.332606077194214, acc=0.18872222304344177, loss=2.332606077194214
test: epoch 6, loss 6.7600603103637695, acc=0.03888889029622078, loss=6.7600603103637695
train: epoch 7, loss 2.30258846282959, acc=0.19099999964237213, loss=2.30258846282959
test: epoch 7, loss 7.043930530548096, acc=0.03333333507180214, loss=7.043930530548096
train: epoch 8, loss 2.288214921951294, acc=0.20311111211776733, loss=2.288214921951294
test: epoch 8, loss 6.757659435272217, acc=0.03888889029622078, loss=6.757659435272217
train: epoch 9, loss 2.2676897048950195, acc=0.2027222216129303, loss=2.2676897048950195
test: epoch 9, loss 6.877808570861816, acc=0.03888889029622078, loss=6.877808570861816
train: epoch 10, loss 2.243520736694336, acc=0.20855554938316345, loss=2.243520736694336
test: epoch 10, loss 6.852457046508789, acc=0.03611111268401146, loss=6.852457046508789
train: epoch 11, loss 2.2210395336151123, acc=0.21444444358348846, loss=2.2210395336151123
test: epoch 11, loss 7.060154438018799, acc=0.03055555559694767, loss=7.060154438018799
train: epoch 12, loss 2.195131778717041, acc=0.2201666682958603, loss=2.195131778717041
test: epoch 12, loss 7.1953558921813965, acc=0.03333333507180214, loss=7.1953558921813965
train: epoch 13, loss 2.2099716663360596, acc=0.21477778255939484, loss=2.2099716663360596
test: epoch 13, loss 7.073848724365234, acc=0.03888889029622078, loss=7.073848724365234
train: epoch 14, loss 2.199718952178955, acc=0.21449999511241913, loss=2.199718952178955
test: epoch 14, loss 6.808848857879639, acc=0.03888889029622078, loss=6.808848857879639
train: epoch 15, loss 2.18169903755188, acc=0.2235555499792099, loss=2.18169903755188
test: epoch 15, loss 7.108165264129639, acc=0.03333333507180214, loss=7.108165264129639
train: epoch 16, loss 2.1626298427581787, acc=0.2182222157716751, loss=2.1626298427581787
test: epoch 16, loss 7.261595726013184, acc=0.0416666679084301, loss=7.261595726013184
train: epoch 17, loss 2.152188539505005, acc=0.22849999368190765, loss=2.152188539505005
test: epoch 17, loss 7.052637100219727, acc=0.03055555559694767, loss=7.052637100219727
train: epoch 18, loss 2.1516025066375732, acc=0.22983333468437195, loss=2.1516025066375732
test: epoch 18, loss 7.0348334312438965, acc=0.03611111268401146, loss=7.0348334312438965
train: epoch 19, loss 2.1383299827575684, acc=0.23288889229297638, loss=2.1383299827575684
test: epoch 19, loss 6.921309471130371, acc=0.03888889029622078, loss=6.921309471130371
train: epoch 20, loss 2.139803409576416, acc=0.23644444346427917, loss=2.139803409576416
test: epoch 20, loss 6.947976589202881, acc=0.0416666679084301, loss=6.947976589202881
train: epoch 21, loss 2.131333351135254, acc=0.23283334076404572, loss=2.131333351135254
test: epoch 21, loss 7.042792797088623, acc=0.0416666679084301, loss=7.042792797088623
train: epoch 22, loss 2.1215415000915527, acc=0.23377777636051178, loss=2.1215415000915527
test: epoch 22, loss 6.785511016845703, acc=0.0416666679084301, loss=6.785511016845703
train: epoch 23, loss 2.126683235168457, acc=0.23649999499320984, loss=2.126683235168457
test: epoch 23, loss 6.895367622375488, acc=0.03611111268401146, loss=6.895367622375488
train: epoch 24, loss 2.1135241985321045, acc=0.23972222208976746, loss=2.1135241985321045
test: epoch 24, loss 6.580048561096191, acc=0.03888889029622078, loss=6.580048561096191
train: epoch 25, loss 2.1118898391723633, acc=0.23444443941116333, loss=2.1118898391723633
test: epoch 25, loss 6.481755256652832, acc=0.0416666679084301, loss=6.481755256652832
train: epoch 26, loss 2.098856210708618, acc=0.23977777361869812, loss=2.098856210708618
test: epoch 26, loss 6.475480079650879, acc=0.03333333507180214, loss=6.475480079650879
train: epoch 27, loss 2.100944995880127, acc=0.24050000309944153, loss=2.100944995880127
test: epoch 27, loss 6.658362865447998, acc=0.02500000037252903, loss=6.658362865447998
train: epoch 28, loss 2.0998659133911133, acc=0.23588888347148895, loss=2.0998659133911133
test: epoch 28, loss 6.8202338218688965, acc=0.02500000037252903, loss=6.8202338218688965
train: epoch 29, loss 2.0908772945404053, acc=0.24372221529483795, loss=2.0908772945404053
test: epoch 29, loss 6.4993438720703125, acc=0.03055555559694767, loss=6.4993438720703125
train: epoch 30, loss 2.0882561206817627, acc=0.23938888311386108, loss=2.0882561206817627
test: epoch 30, loss 6.3841376304626465, acc=0.03611111268401146, loss=6.3841376304626465
train: epoch 31, loss 2.092275857925415, acc=0.24627777934074402, loss=2.092275857925415
test: epoch 31, loss 6.423299312591553, acc=0.03055555559694767, loss=6.423299312591553
train: epoch 32, loss 2.081491231918335, acc=0.24372221529483795, loss=2.081491231918335
test: epoch 32, loss 6.3184814453125, acc=0.03611111268401146, loss=6.3184814453125
train: epoch 33, loss 2.071244955062866, acc=0.24500000476837158, loss=2.071244955062866
test: epoch 33, loss 6.219541549682617, acc=0.0416666679084301, loss=6.219541549682617
train: epoch 34, loss 2.0778164863586426, acc=0.2426111102104187, loss=2.0778164863586426
test: epoch 34, loss 6.496973991394043, acc=0.03055555559694767, loss=6.496973991394043
train: epoch 35, loss 2.0716288089752197, acc=0.24677777290344238, loss=2.0716288089752197
test: epoch 35, loss 6.237425327301025, acc=0.03611111268401146, loss=6.237425327301025
train: epoch 36, loss 2.076937198638916, acc=0.24283333122730255, loss=2.076937198638916
test: epoch 36, loss 6.171058654785156, acc=0.03055555559694767, loss=6.171058654785156
train: epoch 37, loss 2.085538387298584, acc=0.2504444420337677, loss=2.085538387298584
test: epoch 37, loss 6.1506171226501465, acc=0.02777777798473835, loss=6.1506171226501465
train: epoch 38, loss 2.082510471343994, acc=0.24622222781181335, loss=2.082510471343994
test: epoch 38, loss 5.909573078155518, acc=0.03055555559694767, loss=5.909573078155518
train: epoch 39, loss 2.0704288482666016, acc=0.24677777290344238, loss=2.0704288482666016
test: epoch 39, loss 6.141999244689941, acc=0.02777777798473835, loss=6.141999244689941
train: epoch 40, loss 2.072050094604492, acc=0.24950000643730164, loss=2.072050094604492
test: epoch 40, loss 6.033298015594482, acc=0.02222222276031971, loss=6.033298015594482
train: epoch 41, loss 2.0696024894714355, acc=0.250166654586792, loss=2.0696024894714355
test: epoch 41, loss 5.895818710327148, acc=0.02777777798473835, loss=5.895818710327148
train: epoch 42, loss 2.0613059997558594, acc=0.24811111390590668, loss=2.0613059997558594
test: epoch 42, loss 5.880181789398193, acc=0.02222222276031971, loss=5.880181789398193
train: epoch 43, loss 2.069126605987549, acc=0.25183331966400146, loss=2.069126605987549
test: epoch 43, loss 6.00436544418335, acc=0.03333333507180214, loss=6.00436544418335
train: epoch 44, loss 2.077829122543335, acc=0.2443888932466507, loss=2.077829122543335
test: epoch 44, loss 5.773576736450195, acc=0.03055555559694767, loss=5.773576736450195
train: epoch 45, loss 2.079571008682251, acc=0.24855555593967438, loss=2.079571008682251
test: epoch 45, loss 5.652853965759277, acc=0.03611111268401146, loss=5.652853965759277
train: epoch 46, loss 2.0856401920318604, acc=0.2473333328962326, loss=2.0856401920318604
test: epoch 46, loss 6.132702827453613, acc=0.02777777798473835, loss=6.132702827453613
train: epoch 47, loss 2.0574629306793213, acc=0.253555566072464, loss=2.0574629306793213
test: epoch 47, loss 5.566751003265381, acc=0.03055555559694767, loss=5.566751003265381
train: epoch 48, loss 2.0534794330596924, acc=0.2516111135482788, loss=2.0534794330596924
test: epoch 48, loss 5.751007080078125, acc=0.03333333507180214, loss=5.751007080078125
train: epoch 49, loss 2.0657076835632324, acc=0.2525555491447449, loss=2.0657076835632324
test: epoch 49, loss 5.8981032371521, acc=0.02777777798473835, loss=5.8981032371521
train: epoch 50, loss 2.0753321647644043, acc=0.25272223353385925, loss=2.0753321647644043
test: epoch 50, loss 5.605964660644531, acc=0.02500000037252903, loss=5.605964660644531
train: epoch 51, loss 2.069716453552246, acc=0.2442222237586975, loss=2.069716453552246
test: epoch 51, loss 5.490310192108154, acc=0.02777777798473835, loss=5.490310192108154
train: epoch 52, loss 2.0677201747894287, acc=0.24983333051204681, loss=2.0677201747894287
test: epoch 52, loss 5.448881149291992, acc=0.02500000037252903, loss=5.448881149291992
train: epoch 53, loss 2.072654962539673, acc=0.2495555579662323, loss=2.072654962539673
test: epoch 53, loss 5.570788860321045, acc=0.04444444552063942, loss=5.570788860321045
train: epoch 54, loss 2.0749151706695557, acc=0.2492777705192566, loss=2.0749151706695557
test: epoch 54, loss 5.215165138244629, acc=0.02777777798473835, loss=5.215165138244629
train: epoch 55, loss 2.0714099407196045, acc=0.24344444274902344, loss=2.0714099407196045
test: epoch 55, loss 5.317937850952148, acc=0.03333333507180214, loss=5.317937850952148
train: epoch 56, loss 2.082731246948242, acc=0.25033333897590637, loss=2.082731246948242
test: epoch 56, loss 5.558568000793457, acc=0.03333333507180214, loss=5.558568000793457
train: epoch 57, loss 2.0798187255859375, acc=0.25227779150009155, loss=2.0798187255859375
test: epoch 57, loss 5.418521404266357, acc=0.03055555559694767, loss=5.418521404266357
train: epoch 58, loss 2.0840444564819336, acc=0.24833333492279053, loss=2.0840444564819336
test: epoch 58, loss 5.240459442138672, acc=0.03611111268401146, loss=5.240459442138672
train: epoch 59, loss 2.0726354122161865, acc=0.2417222261428833, loss=2.0726354122161865
test: epoch 59, loss 5.133193016052246, acc=0.02500000037252903, loss=5.133193016052246
train: epoch 60, loss 2.085559129714966, acc=0.2495555579662323, loss=2.085559129714966
test: epoch 60, loss 5.2016215324401855, acc=0.03888889029622078, loss=5.2016215324401855
train: epoch 61, loss 2.094360589981079, acc=0.2491111159324646, loss=2.094360589981079
test: epoch 61, loss 5.073681354522705, acc=0.02777777798473835, loss=5.073681354522705
train: epoch 62, loss 2.0677084922790527, acc=0.24783332645893097, loss=2.0677084922790527
test: epoch 62, loss 5.173070907592773, acc=0.03333333507180214, loss=5.173070907592773
train: epoch 63, loss 2.0866217613220215, acc=0.2548333406448364, loss=2.0866217613220215
test: epoch 63, loss 4.882857322692871, acc=0.03333333507180214, loss=4.882857322692871
train: epoch 64, loss 2.0816638469696045, acc=0.24816666543483734, loss=2.0816638469696045
test: epoch 64, loss 4.864984035491943, acc=0.03888889029622078, loss=4.864984035491943
train: epoch 65, loss 2.0939760208129883, acc=0.24272222816944122, loss=2.0939760208129883
test: epoch 65, loss 4.974234580993652, acc=0.0416666679084301, loss=4.974234580993652
train: epoch 66, loss 2.0898184776306152, acc=0.24533332884311676, loss=2.0898184776306152
test: epoch 66, loss 4.821206569671631, acc=0.04444444552063942, loss=4.821206569671631
train: epoch 67, loss 2.108703374862671, acc=0.24222221970558167, loss=2.108703374862671
test: epoch 67, loss 4.720322608947754, acc=0.0416666679084301, loss=4.720322608947754
train: epoch 68, loss 2.0922398567199707, acc=0.2483888864517212, loss=2.0922398567199707
test: epoch 68, loss 4.66386079788208, acc=0.0416666679084301, loss=4.66386079788208
train: epoch 69, loss 2.084273338317871, acc=0.2452777773141861, loss=2.084273338317871
test: epoch 69, loss 4.963384628295898, acc=0.03333333507180214, loss=4.963384628295898
train: epoch 70, loss 2.08054518699646, acc=0.2529444396495819, loss=2.08054518699646
test: epoch 70, loss 4.896147727966309, acc=0.04444444552063942, loss=4.896147727966309
train: epoch 71, loss 2.0939583778381348, acc=0.2473333328962326, loss=2.0939583778381348
test: epoch 71, loss 4.7814435958862305, acc=0.03888889029622078, loss=4.7814435958862305
train: epoch 72, loss 2.0936543941497803, acc=0.2452777773141861, loss=2.0936543941497803
test: epoch 72, loss 4.683922290802002, acc=0.0416666679084301, loss=4.683922290802002
train: epoch 73, loss 2.1047914028167725, acc=0.24405555427074432, loss=2.1047914028167725
test: epoch 73, loss 4.658213138580322, acc=0.04722222313284874, loss=4.658213138580322
train: epoch 74, loss 2.0779507160186768, acc=0.23955555260181427, loss=2.0779507160186768
test: epoch 74, loss 4.6671366691589355, acc=0.04722222313284874, loss=4.6671366691589355
train: epoch 75, loss 2.0972726345062256, acc=0.24533332884311676, loss=2.0972726345062256
test: epoch 75, loss 4.548821926116943, acc=0.05833333358168602, loss=4.548821926116943
train: epoch 76, loss 2.088167905807495, acc=0.24477778375148773, loss=2.088167905807495
test: epoch 76, loss 4.8257927894592285, acc=0.05000000074505806, loss=4.8257927894592285
train: epoch 77, loss 2.104332447052002, acc=0.24311110377311707, loss=2.104332447052002
test: epoch 77, loss 4.361668586730957, acc=0.0555555559694767, loss=4.361668586730957
train: epoch 78, loss 2.108217477798462, acc=0.2434999942779541, loss=2.108217477798462
test: epoch 78, loss 4.510359287261963, acc=0.05833333358168602, loss=4.510359287261963
train: epoch 79, loss 2.131706714630127, acc=0.24150000512599945, loss=2.131706714630127
test: epoch 79, loss 4.385458946228027, acc=0.03611111268401146, loss=4.385458946228027
train: epoch 80, loss 2.1108994483947754, acc=0.24211111664772034, loss=2.1108994483947754
test: epoch 80, loss 4.367562770843506, acc=0.05277777835726738, loss=4.367562770843506
train: epoch 81, loss 2.1132850646972656, acc=0.23855555057525635, loss=2.1132850646972656
test: epoch 81, loss 4.338379383087158, acc=0.0555555559694767, loss=4.338379383087158
train: epoch 82, loss 2.113247871398926, acc=0.23766666650772095, loss=2.113247871398926
test: epoch 82, loss 4.4206929206848145, acc=0.05833333358168602, loss=4.4206929206848145
train: epoch 83, loss 2.1104483604431152, acc=0.2368333339691162, loss=2.1104483604431152
test: epoch 83, loss 4.344724655151367, acc=0.0694444477558136, loss=4.344724655151367
train: epoch 84, loss 2.1088716983795166, acc=0.24061110615730286, loss=2.1088716983795166
test: epoch 84, loss 4.230453014373779, acc=0.04444444552063942, loss=4.230453014373779
train: epoch 85, loss 2.1407177448272705, acc=0.23549999296665192, loss=2.1407177448272705
test: epoch 85, loss 4.287026882171631, acc=0.04444444552063942, loss=4.287026882171631
train: epoch 86, loss 2.1090598106384277, acc=0.2347777783870697, loss=2.1090598106384277
test: epoch 86, loss 4.312436580657959, acc=0.0416666679084301, loss=4.312436580657959
train: epoch 87, loss 2.129318952560425, acc=0.23355555534362793, loss=2.129318952560425
test: epoch 87, loss 4.369438648223877, acc=0.0416666679084301, loss=4.369438648223877
train: epoch 88, loss 2.1379740238189697, acc=0.23333333432674408, loss=2.1379740238189697
test: epoch 88, loss 4.352889060974121, acc=0.04444444552063942, loss=4.352889060974121
train: epoch 89, loss 2.122950315475464, acc=0.23761111497879028, loss=2.122950315475464
test: epoch 89, loss 4.197144031524658, acc=0.04722222313284874, loss=4.197144031524658
train: epoch 90, loss 2.1460988521575928, acc=0.23083333671092987, loss=2.1460988521575928
test: epoch 90, loss 4.2769775390625, acc=0.04722222313284874, loss=4.2769775390625
train: epoch 91, loss 2.1387598514556885, acc=0.23383332788944244, loss=2.1387598514556885
test: epoch 91, loss 4.18256139755249, acc=0.05000000074505806, loss=4.18256139755249
train: epoch 92, loss 2.1602516174316406, acc=0.22538888454437256, loss=2.1602516174316406
test: epoch 92, loss 4.11690616607666, acc=0.05000000074505806, loss=4.11690616607666
train: epoch 93, loss 2.1695611476898193, acc=0.224722221493721, loss=2.1695611476898193
test: epoch 93, loss 3.9639487266540527, acc=0.05833333358168602, loss=3.9639487266540527
train: epoch 94, loss 2.1656720638275146, acc=0.22494444251060486, loss=2.1656720638275146
test: epoch 94, loss 4.061901092529297, acc=0.04722222313284874, loss=4.061901092529297
train: epoch 95, loss 2.1458330154418945, acc=0.22883333265781403, loss=2.1458330154418945
test: epoch 95, loss 3.9191761016845703, acc=0.05277777835726738, loss=3.9191761016845703
train: epoch 96, loss 2.1428163051605225, acc=0.23083333671092987, loss=2.1428163051605225
test: epoch 96, loss 3.8411166667938232, acc=0.04722222313284874, loss=3.8411166667938232
train: epoch 97, loss 2.1579396724700928, acc=0.2300555557012558, loss=2.1579396724700928
test: epoch 97, loss 3.9285855293273926, acc=0.0555555559694767, loss=3.9285855293273926
train: epoch 98, loss 2.168205738067627, acc=0.22905555367469788, loss=2.168205738067627
test: epoch 98, loss 3.8672356605529785, acc=0.06111111119389534, loss=3.8672356605529785
train: epoch 99, loss 2.156334638595581, acc=0.22750000655651093, loss=2.156334638595581
test: epoch 99, loss 3.8357205390930176, acc=0.04444444552063942, loss=3.8357205390930176
train: epoch 100, loss 2.1639857292175293, acc=0.22816666960716248, loss=2.1639857292175293
test: epoch 100, loss 3.79439377784729, acc=0.06388889253139496, loss=3.79439377784729
train: epoch 101, loss 2.1583540439605713, acc=0.2251666635274887, loss=2.1583540439605713
test: epoch 101, loss 3.6933093070983887, acc=0.06388889253139496, loss=3.6933093070983887
train: epoch 102, loss 2.1792595386505127, acc=0.22366666793823242, loss=2.1792595386505127
test: epoch 102, loss 3.691044569015503, acc=0.05277777835726738, loss=3.691044569015503
train: epoch 103, loss 2.164780616760254, acc=0.2240000069141388, loss=2.164780616760254
test: epoch 103, loss 3.8619792461395264, acc=0.0416666679084301, loss=3.8619792461395264
train: epoch 104, loss 2.168833017349243, acc=0.21861110627651215, loss=2.168833017349243
test: epoch 104, loss 3.8051629066467285, acc=0.0555555559694767, loss=3.8051629066467285
train: epoch 105, loss 2.1818761825561523, acc=0.22349999845027924, loss=2.1818761825561523
test: epoch 105, loss 3.781602621078491, acc=0.03611111268401146, loss=3.781602621078491
train: epoch 106, loss 2.170334815979004, acc=0.2278333306312561, loss=2.170334815979004
test: epoch 106, loss 3.7373757362365723, acc=0.04722222313284874, loss=3.7373757362365723
train: epoch 107, loss 2.1982369422912598, acc=0.22377777099609375, loss=2.1982369422912598
test: epoch 107, loss 3.6907477378845215, acc=0.06388889253139496, loss=3.6907477378845215
train: epoch 108, loss 2.176968574523926, acc=0.2248888909816742, loss=2.176968574523926
test: epoch 108, loss 3.7367465496063232, acc=0.0555555559694767, loss=3.7367465496063232
train: epoch 109, loss 2.192466974258423, acc=0.22322222590446472, loss=2.192466974258423
test: epoch 109, loss 3.9190897941589355, acc=0.05833333358168602, loss=3.9190897941589355
train: epoch 110, loss 2.2079546451568604, acc=0.21461111307144165, loss=2.2079546451568604
test: epoch 110, loss 3.6577160358428955, acc=0.05833333358168602, loss=3.6577160358428955
train: epoch 111, loss 2.1922783851623535, acc=0.2170555591583252, loss=2.1922783851623535
test: epoch 111, loss 3.6161890029907227, acc=0.06666667014360428, loss=3.6161890029907227
train: epoch 112, loss 2.2056519985198975, acc=0.21716666221618652, loss=2.2056519985198975
test: epoch 112, loss 3.6909570693969727, acc=0.06388889253139496, loss=3.6909570693969727
train: epoch 113, loss 2.2038357257843018, acc=0.21422222256660461, loss=2.2038357257843018
test: epoch 113, loss 3.551262140274048, acc=0.05833333358168602, loss=3.551262140274048
train: epoch 114, loss 2.1886789798736572, acc=0.21861110627651215, loss=2.1886789798736572
test: epoch 114, loss 3.6556642055511475, acc=0.04722222313284874, loss=3.6556642055511475
train: epoch 115, loss 2.191318988800049, acc=0.2148333340883255, loss=2.191318988800049
test: epoch 115, loss 3.7353198528289795, acc=0.06388889253139496, loss=3.7353198528289795
train: epoch 116, loss 2.2147858142852783, acc=0.2112777829170227, loss=2.2147858142852783
test: epoch 116, loss 3.5478713512420654, acc=0.05000000074505806, loss=3.5478713512420654
train: epoch 117, loss 2.206641674041748, acc=0.21111111342906952, loss=2.206641674041748
test: epoch 117, loss 3.455610513687134, acc=0.05277777835726738, loss=3.455610513687134
train: epoch 118, loss 2.217978000640869, acc=0.21655555069446564, loss=2.217978000640869
test: epoch 118, loss 3.5225749015808105, acc=0.05833333358168602, loss=3.5225749015808105
train: epoch 119, loss 2.199315071105957, acc=0.21561111509799957, loss=2.199315071105957
test: epoch 119, loss 3.556917428970337, acc=0.05000000074505806, loss=3.556917428970337
train: epoch 120, loss 2.1942944526672363, acc=0.21377778053283691, loss=2.1942944526672363
test: epoch 120, loss 3.5492806434631348, acc=0.06666667014360428, loss=3.5492806434631348
train: epoch 121, loss 2.223794937133789, acc=0.20411111414432526, loss=2.223794937133789
test: epoch 121, loss 3.362436056137085, acc=0.0694444477558136, loss=3.362436056137085
train: epoch 122, loss 2.205402374267578, acc=0.21183332800865173, loss=2.205402374267578
test: epoch 122, loss 3.443756103515625, acc=0.0833333358168602, loss=3.443756103515625
train: epoch 123, loss 2.211468458175659, acc=0.20933333039283752, loss=2.211468458175659
test: epoch 123, loss 3.5758056640625, acc=0.06111111119389534, loss=3.5758056640625
train: epoch 124, loss 2.217846632003784, acc=0.2083333283662796, loss=2.217846632003784
test: epoch 124, loss 3.5972723960876465, acc=0.05000000074505806, loss=3.5972723960876465
train: epoch 125, loss 2.221468210220337, acc=0.2105555534362793, loss=2.221468210220337
test: epoch 125, loss 3.5665805339813232, acc=0.05277777835726738, loss=3.5665805339813232
train: epoch 126, loss 2.2385690212249756, acc=0.20600000023841858, loss=2.2385690212249756
test: epoch 126, loss 3.3994128704071045, acc=0.05277777835726738, loss=3.3994128704071045
train: epoch 127, loss 2.2213542461395264, acc=0.20794443786144257, loss=2.2213542461395264
test: epoch 127, loss 3.4083399772644043, acc=0.07500000298023224, loss=3.4083399772644043
train: epoch 128, loss 2.2353289127349854, acc=0.20649999380111694, loss=2.2353289127349854
test: epoch 128, loss 3.4309134483337402, acc=0.0694444477558136, loss=3.4309134483337402
train: epoch 129, loss 2.2508227825164795, acc=0.2040555626153946, loss=2.2508227825164795
test: epoch 129, loss 3.3318541049957275, acc=0.07222222536802292, loss=3.3318541049957275
train: epoch 130, loss 2.232712507247925, acc=0.2027222216129303, loss=2.232712507247925
test: epoch 130, loss 3.3693716526031494, acc=0.0694444477558136, loss=3.3693716526031494
train: epoch 131, loss 2.2388713359832764, acc=0.20266667008399963, loss=2.2388713359832764
test: epoch 131, loss 3.3513176441192627, acc=0.0555555559694767, loss=3.3513176441192627
train: epoch 132, loss 2.242246627807617, acc=0.20288889110088348, loss=2.242246627807617
test: epoch 132, loss 3.3042080402374268, acc=0.07500000298023224, loss=3.3042080402374268
train: epoch 133, loss 2.2573888301849365, acc=0.20438888669013977, loss=2.2573888301849365
test: epoch 133, loss 3.2743747234344482, acc=0.05833333358168602, loss=3.2743747234344482
train: epoch 134, loss 2.246215581893921, acc=0.2021111100912094, loss=2.246215581893921
test: epoch 134, loss 3.2980964183807373, acc=0.0694444477558136, loss=3.2980964183807373
train: epoch 135, loss 2.2453854084014893, acc=0.19805555045604706, loss=2.2453854084014893
test: epoch 135, loss 3.2813379764556885, acc=0.06388889253139496, loss=3.2813379764556885
train: epoch 136, loss 2.2622103691101074, acc=0.19816666841506958, loss=2.2622103691101074
test: epoch 136, loss 3.2364563941955566, acc=0.08055555820465088, loss=3.2364563941955566
train: epoch 137, loss 2.2382125854492188, acc=0.20288889110088348, loss=2.2382125854492188
test: epoch 137, loss 3.3571062088012695, acc=0.05277777835726738, loss=3.3571062088012695
train: epoch 138, loss 2.2408175468444824, acc=0.1991666704416275, loss=2.2408175468444824
test: epoch 138, loss 3.3139760494232178, acc=0.06111111119389534, loss=3.3139760494232178
train: epoch 139, loss 2.2536513805389404, acc=0.19994445145130157, loss=2.2536513805389404
test: epoch 139, loss 3.3214046955108643, acc=0.06666667014360428, loss=3.3214046955108643
train: epoch 140, loss 2.2560672760009766, acc=0.19766665995121002, loss=2.2560672760009766
test: epoch 140, loss 3.3159866333007812, acc=0.06388889253139496, loss=3.3159866333007812
train: epoch 141, loss 2.2483694553375244, acc=0.1979999989271164, loss=2.2483694553375244
test: epoch 141, loss 3.2918355464935303, acc=0.0555555559694767, loss=3.2918355464935303
train: epoch 142, loss 2.2436890602111816, acc=0.20499999821186066, loss=2.2436890602111816
test: epoch 142, loss 3.270663261413574, acc=0.07500000298023224, loss=3.270663261413574
train: epoch 143, loss 2.2587192058563232, acc=0.2000555545091629, loss=2.2587192058563232
test: epoch 143, loss 3.319091796875, acc=0.06666667014360428, loss=3.319091796875
train: epoch 144, loss 2.239316701889038, acc=0.20105555653572083, loss=2.239316701889038
test: epoch 144, loss 3.1763627529144287, acc=0.07222222536802292, loss=3.1763627529144287
train: epoch 145, loss 2.2430222034454346, acc=0.20127777755260468, loss=2.2430222034454346
test: epoch 145, loss 3.26460862159729, acc=0.07500000298023224, loss=3.26460862159729
train: epoch 146, loss 2.248568296432495, acc=0.1948888897895813, loss=2.248568296432495
test: epoch 146, loss 3.3418262004852295, acc=0.05833333358168602, loss=3.3418262004852295
train: epoch 147, loss 2.239083766937256, acc=0.19905555248260498, loss=2.239083766937256
test: epoch 147, loss 3.264817953109741, acc=0.07222222536802292, loss=3.264817953109741
train: epoch 148, loss 2.2326502799987793, acc=0.1982777714729309, loss=2.2326502799987793
test: epoch 148, loss 3.1833655834198, acc=0.0833333358168602, loss=3.1833655834198
train: epoch 149, loss 2.2384259700775146, acc=0.1996111124753952, loss=2.2384259700775146
test: epoch 149, loss 3.252363443374634, acc=0.07500000298023224, loss=3.252363443374634
train: epoch 150, loss 2.2452640533447266, acc=0.19505555927753448, loss=2.2452640533447266
test: epoch 150, loss 3.263949394226074, acc=0.0694444477558136, loss=3.263949394226074
